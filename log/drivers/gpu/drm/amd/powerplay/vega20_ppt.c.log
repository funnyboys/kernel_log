commit 774e335b878c1edf5e8e5d0138adaf86a892f025
Author: Evan Quan <evan.quan@amd.com>
Date:   Tue Apr 7 14:37:42 2020 +0800

    drm/amd/powerplay: properly set the dpm_enabled state
    
    On the ASIC powered down(in baco or system suspend),
    the dpm_enabled will be set as false. Then all access
    (e.g. df state setting issued on RAS error event) to
    SMU will be blocked.
    
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 3f1044326dcb..61923530b2e4 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1796,7 +1796,7 @@ static int vega20_get_power_profile_mode(struct smu_context *smu, char *buf)
 			"PD_Data_error_rate_coeff"};
 	int result = 0;
 
-	if (!smu->pm_enabled || !buf)
+	if (!buf)
 		return -EINVAL;
 
 	size += sprintf(buf + size, "%16s %s %s %s %s %s %s %s %s %s %s\n",
@@ -1887,8 +1887,6 @@ static int vega20_set_power_profile_mode(struct smu_context *smu, long *input, u
 
 	smu->power_profile_mode = input[size];
 
-	if (!smu->pm_enabled)
-		return ret;
 	if (smu->power_profile_mode > PP_SMC_POWER_PROFILE_CUSTOM) {
 		pr_err("Invalid power profile mode %d\n", smu->power_profile_mode);
 		return -EINVAL;

commit 49e78c820a025a2c6e849b34fe113727194a7034
Author: Evan Quan <evan.quan@amd.com>
Date:   Fri Mar 27 15:33:00 2020 +0800

    drm/amd/powerplay: move the ASIC specific nbio operation out of smu_v11_0.c
    
    This is ASIC specific and should be placed in _ppt.c of each ASIC.
    
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 49ff3756bd9f..3f1044326dcb 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -35,6 +35,7 @@
 #include "vega20_ppt.h"
 #include "vega20_pptable.h"
 #include "vega20_ppsmc.h"
+#include "nbio/nbio_7_4_offset.h"
 #include "nbio/nbio_7_4_sh_mask.h"
 #include "asic_reg/thm/thm_11_0_2_offset.h"
 #include "asic_reg/thm/thm_11_0_2_sh_mask.h"
@@ -3174,6 +3175,17 @@ static int vega20_update_pcie_parameters(struct smu_context *smu,
 	return ret;
 }
 
+static bool vega20_is_baco_supported(struct smu_context *smu)
+{
+	struct amdgpu_device *adev = smu->adev;
+	uint32_t val;
+
+	if (!smu_v11_0_baco_is_support(smu))
+		return false;
+
+	val = RREG32_SOC15(NBIO, 0, mmRCC_BIF_STRAP0);
+	return (val & RCC_BIF_STRAP0__STRAP_PX_CAPABLE_MASK) ? true : false;
+}
 
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.tables_init = vega20_tables_init,
@@ -3262,7 +3274,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.register_irq_handler = smu_v11_0_register_irq_handler,
 	.set_azalia_d3_pme = smu_v11_0_set_azalia_d3_pme,
 	.get_max_sustainable_clocks_by_dc = smu_v11_0_get_max_sustainable_clocks_by_dc,
-	.baco_is_support= smu_v11_0_baco_is_support,
+	.baco_is_support= vega20_is_baco_supported,
 	.baco_get_state = smu_v11_0_baco_get_state,
 	.baco_set_state = smu_v11_0_baco_set_state,
 	.baco_enter = smu_v11_0_baco_enter,

commit f88ef3ca869d04e4d66468a478b6b817772ce243
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Tue Mar 10 18:03:05 2020 +0800

    drm/amdgpu/swsmu: clean up unused header in swsmu
    
    clean up unused header in swsmu driver stack:
    1. pp_debug.h
    2. amd_pcie.h
    3. soc15_common.h
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index d7fa8c02c166..49ff3756bd9f 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -21,7 +21,6 @@
  *
  */
 
-#include "pp_debug.h"
 #include <linux/firmware.h>
 #include "amdgpu.h"
 #include "amdgpu_smu.h"

commit ae458c7b9dcc9284eec81c86ef0deab5a087d136
Author: Matt Coffin <mcoffin13@gmail.com>
Date:   Wed Feb 26 16:16:13 2020 -0700

    drm/amdgpu/powerplay: Remove deprecated smc_read_arg
    
    The new interface reads the argument in the call to send the message, so
    this is no longer needed, and shouldn't be used for concurrency safety
    reasons.
    
    Signed-off-by: Matt Coffin <mcoffin13@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index fb3f3ce6a113..d7fa8c02c166 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3243,7 +3243,6 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.notify_memory_pool_location = smu_v11_0_notify_memory_pool_location,
 	.system_features_control = smu_v11_0_system_features_control,
 	.send_smc_msg_with_param = smu_v11_0_send_msg_with_param,
-	.read_smc_arg = smu_v11_0_read_arg,
 	.init_display_count = smu_v11_0_init_display_count,
 	.set_allowed_mask = smu_v11_0_set_allowed_mask,
 	.get_enabled_mask = smu_v11_0_get_enabled_mask,

commit 1c58267cbe46f0b5741628a72d10b5464712a012
Author: Matt Coffin <mcoffin13@gmail.com>
Date:   Wed Feb 26 16:16:12 2020 -0700

    drm/amdgpu/powerplay: Refactor SMU message handling for safety
    
    Move the responsibility for reading argument registers into the
    smu_send_smc_msg* implementations, so that adding a message-sending lock
    to protect the SMU registers will result in the lock still being held
    when the argument is read.
    
    v2: transition smu_v12_0, it's asics, and vega20
    
    Signed-off-by: Matt Coffin <mcoffin13@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 4ad8d6c14ee5..fb3f3ce6a113 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -587,7 +587,7 @@ static int vega20_check_powerplay_table(struct smu_context *smu)
 
 static int vega20_run_btc_afll(struct smu_context *smu)
 {
-	return smu_send_smc_msg(smu, SMU_MSG_RunAfllBtc);
+	return smu_send_smc_msg(smu, SMU_MSG_RunAfllBtc, NULL);
 }
 
 #define FEATURE_MASK(feature) (1ULL << feature)
@@ -670,13 +670,13 @@ vega20_set_single_dpm_table(struct smu_context *smu,
 
 	ret = smu_send_smc_msg_with_param(smu,
 			SMU_MSG_GetDpmFreqByIndex,
-			(clk_id << 16 | 0xFF));
+			(clk_id << 16 | 0xFF),
+			&num_of_levels);
 	if (ret) {
 		pr_err("[GetNumOfDpmLevel] failed to get dpm levels!");
 		return ret;
 	}
 
-	smu_read_smc_arg(smu, &num_of_levels);
 	if (!num_of_levels) {
 		pr_err("[GetNumOfDpmLevel] number of clk levels is invalid!");
 		return -EINVAL;
@@ -687,12 +687,12 @@ vega20_set_single_dpm_table(struct smu_context *smu,
 	for (i = 0; i < num_of_levels; i++) {
 		ret = smu_send_smc_msg_with_param(smu,
 				SMU_MSG_GetDpmFreqByIndex,
-				(clk_id << 16 | i));
+				(clk_id << 16 | i),
+				&clk);
 		if (ret) {
 			pr_err("[GetDpmFreqByIndex] failed to get dpm freq by index!");
 			return ret;
 		}
-		smu_read_smc_arg(smu, &clk);
 		if (!clk) {
 			pr_err("[GetDpmFreqByIndex] clk value is invalid!");
 			return -EINVAL;
@@ -1200,7 +1200,8 @@ static int vega20_upload_dpm_level(struct smu_context *smu, bool max,
 			single_dpm_table->dpm_state.soft_min_level;
 		ret = smu_send_smc_msg_with_param(smu,
 			(max ? SMU_MSG_SetSoftMaxByFreq : SMU_MSG_SetSoftMinByFreq),
-			(PPCLK_GFXCLK << 16) | (freq & 0xffff));
+			(PPCLK_GFXCLK << 16) | (freq & 0xffff),
+			NULL);
 		if (ret) {
 			pr_err("Failed to set soft %s gfxclk !\n",
 						max ? "max" : "min");
@@ -1215,7 +1216,8 @@ static int vega20_upload_dpm_level(struct smu_context *smu, bool max,
 			single_dpm_table->dpm_state.soft_min_level;
 		ret = smu_send_smc_msg_with_param(smu,
 			(max ? SMU_MSG_SetSoftMaxByFreq : SMU_MSG_SetSoftMinByFreq),
-			(PPCLK_UCLK << 16) | (freq & 0xffff));
+			(PPCLK_UCLK << 16) | (freq & 0xffff),
+			NULL);
 		if (ret) {
 			pr_err("Failed to set soft %s memclk !\n",
 						max ? "max" : "min");
@@ -1230,7 +1232,8 @@ static int vega20_upload_dpm_level(struct smu_context *smu, bool max,
 			single_dpm_table->dpm_state.soft_min_level;
 		ret = smu_send_smc_msg_with_param(smu,
 			(max ? SMU_MSG_SetSoftMaxByFreq : SMU_MSG_SetSoftMinByFreq),
-			(PPCLK_SOCCLK << 16) | (freq & 0xffff));
+			(PPCLK_SOCCLK << 16) | (freq & 0xffff),
+			NULL);
 		if (ret) {
 			pr_err("Failed to set soft %s socclk !\n",
 						max ? "max" : "min");
@@ -1245,7 +1248,8 @@ static int vega20_upload_dpm_level(struct smu_context *smu, bool max,
 			single_dpm_table->dpm_state.soft_min_level;
 		ret = smu_send_smc_msg_with_param(smu,
 			(max ? SMU_MSG_SetSoftMaxByFreq : SMU_MSG_SetSoftMinByFreq),
-			(PPCLK_FCLK << 16) | (freq & 0xffff));
+			(PPCLK_FCLK << 16) | (freq & 0xffff),
+			NULL);
 		if (ret) {
 			pr_err("Failed to set soft %s fclk !\n",
 						max ? "max" : "min");
@@ -1260,7 +1264,8 @@ static int vega20_upload_dpm_level(struct smu_context *smu, bool max,
 		if (!max) {
 			ret = smu_send_smc_msg_with_param(smu,
 				SMU_MSG_SetHardMinByFreq,
-				(PPCLK_DCEFCLK << 16) | (freq & 0xffff));
+				(PPCLK_DCEFCLK << 16) | (freq & 0xffff),
+				NULL);
 			if (ret) {
 				pr_err("Failed to set hard min dcefclk !\n");
 				return ret;
@@ -1421,7 +1426,9 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 		}
 
 		ret = smu_send_smc_msg_with_param(smu,
-				SMU_MSG_SetMinLinkDpmByIndex, soft_min_level);
+				SMU_MSG_SetMinLinkDpmByIndex,
+				soft_min_level,
+				NULL);
 		if (ret)
 			pr_err("Failed to set min link dpm level!\n");
 
@@ -1477,13 +1484,13 @@ static int vega20_overdrive_get_gfx_clk_base_voltage(struct smu_context *smu,
 
 	ret = smu_send_smc_msg_with_param(smu,
 			SMU_MSG_GetAVFSVoltageByDpm,
-			((AVFS_CURVE << 24) | (OD8_HOTCURVE_TEMPERATURE << 16) | freq));
+			((AVFS_CURVE << 24) | (OD8_HOTCURVE_TEMPERATURE << 16) | freq),
+			voltage);
 	if (ret) {
 		pr_err("[GetBaseVoltage] failed to get GFXCLK AVFS voltage from SMU!");
 		return ret;
 	}
 
-	smu_read_smc_arg(smu, voltage);
 	*voltage = *voltage / VOLTAGE_SCALE;
 
 	return 0;
@@ -1956,8 +1963,10 @@ static int vega20_set_power_profile_mode(struct smu_context *smu, long *input, u
 	workload_type = smu_workload_get_type(smu, smu->power_profile_mode);
 	if (workload_type < 0)
 		return -EINVAL;
-	smu_send_smc_msg_with_param(smu, SMU_MSG_SetWorkloadMask,
-				    1 << workload_type);
+	smu_send_smc_msg_with_param(smu,
+			SMU_MSG_SetWorkloadMask,
+			1 << workload_type,
+			NULL);
 
 	return ret;
 }
@@ -2029,7 +2038,8 @@ vega20_set_uclk_to_highest_dpm_level(struct smu_context *smu,
 		dpm_table->dpm_state.hard_min_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
 		ret = smu_send_smc_msg_with_param(smu,
 				SMU_MSG_SetHardMinByFreq,
-				(PPCLK_UCLK << 16) | dpm_table->dpm_state.hard_min_level);
+				(PPCLK_UCLK << 16) | dpm_table->dpm_state.hard_min_level,
+				NULL);
 		if (ret) {
 			pr_err("[%s] Set hard min uclk failed!", __func__);
 				return ret;
@@ -2047,7 +2057,7 @@ static int vega20_pre_display_config_changed(struct smu_context *smu)
 	if (!smu->smu_dpm.dpm_context)
 		return -EINVAL;
 
-	smu_send_smc_msg_with_param(smu, SMU_MSG_NumOfDisplays, 0);
+	smu_send_smc_msg_with_param(smu, SMU_MSG_NumOfDisplays, 0, NULL);
 	ret = vega20_set_uclk_to_highest_dpm_level(smu,
 						   &dpm_table->mem_table);
 	if (ret)
@@ -2074,7 +2084,8 @@ static int vega20_display_config_changed(struct smu_context *smu)
 	    smu_feature_is_supported(smu, SMU_FEATURE_DPM_SOCCLK_BIT)) {
 		smu_send_smc_msg_with_param(smu,
 					    SMU_MSG_NumOfDisplays,
-					    smu->display_config->num_display);
+					    smu->display_config->num_display,
+					    NULL);
 	}
 
 	return ret;
@@ -2247,7 +2258,8 @@ vega20_notify_smc_display_config(struct smu_context *smu)
 			if (smu_feature_is_supported(smu, SMU_FEATURE_DS_DCEFCLK_BIT)) {
 				ret = smu_send_smc_msg_with_param(smu,
 								  SMU_MSG_SetMinDeepSleepDcefclk,
-								  min_clocks.dcef_clock_in_sr/100);
+								  min_clocks.dcef_clock_in_sr/100,
+								  NULL);
 				if (ret) {
 					pr_err("Attempt to set divider for DCEFCLK Failed!");
 					return ret;
@@ -2262,7 +2274,8 @@ vega20_notify_smc_display_config(struct smu_context *smu)
 		memtable->dpm_state.hard_min_level = min_clocks.memory_clock/100;
 		ret = smu_send_smc_msg_with_param(smu,
 						  SMU_MSG_SetHardMinByFreq,
-						  (PPCLK_UCLK << 16) | memtable->dpm_state.hard_min_level);
+						  (PPCLK_UCLK << 16) | memtable->dpm_state.hard_min_level,
+						  NULL);
 		if (ret) {
 			pr_err("[%s] Set hard min uclk failed!", __func__);
 			return ret;
@@ -2853,8 +2866,10 @@ static int vega20_set_thermal_fan_table(struct smu_context *smu)
 	struct smu_table_context *table_context = &smu->smu_table;
 	PPTable_t *pptable = table_context->driver_pptable;
 
-	ret = smu_send_smc_msg_with_param(smu, SMU_MSG_SetFanTemperatureTarget,
-			(uint32_t)pptable->FanTargetTemperature);
+	ret = smu_send_smc_msg_with_param(smu,
+			SMU_MSG_SetFanTemperatureTarget,
+			(uint32_t)pptable->FanTargetTemperature,
+			NULL);
 
 	return ret;
 }
@@ -2864,15 +2879,13 @@ static int vega20_get_fan_speed_rpm(struct smu_context *smu,
 {
 	int ret;
 
-	ret = smu_send_smc_msg(smu, SMU_MSG_GetCurrentRpm);
+	ret = smu_send_smc_msg(smu, SMU_MSG_GetCurrentRpm, speed);
 
 	if (ret) {
 		pr_err("Attempt to get current RPM from SMC Failed!\n");
 		return ret;
 	}
 
-	smu_read_smc_arg(smu, speed);
-
 	return 0;
 }
 
@@ -3137,7 +3150,7 @@ static int vega20_set_df_cstate(struct smu_context *smu,
 		return -EINVAL;
 	}
 
-	return smu_send_smc_msg_with_param(smu, SMU_MSG_DFCstateControl, state);
+	return smu_send_smc_msg_with_param(smu, SMU_MSG_DFCstateControl, state, NULL);
 }
 
 static int vega20_update_pcie_parameters(struct smu_context *smu,
@@ -3155,7 +3168,8 @@ static int vega20_update_pcie_parameters(struct smu_context *smu,
 					pptable->PcieLaneCount[i] : pcie_width_cap);
 		ret = smu_send_smc_msg_with_param(smu,
 					  SMU_MSG_OverridePcieParameters,
-					  smu_pcie_arg);
+					  smu_pcie_arg,
+					  NULL);
 	}
 
 	return ret;

commit 93c5f1f66c6ad4a3b180c1644f74e1b3b4be7864
Author: Matt Coffin <mcoffin13@gmail.com>
Date:   Sat Jan 25 13:04:05 2020 -0500

    drm/amdgpu/smu_v11_0: Correct behavior of restoring default tables (v2)
    
    Previously, the syfs functionality for restoring the default powerplay
    table was sourcing it's information from the currently-staged powerplay
    table.
    
    This patch adds a step to cache the first overdrive table that we see on
    boot, so that it can be used later to "restore" the powerplay table
    
    v2: sqaush my original with Matt's fix
    
    Bug: https://gitlab.freedesktop.org/drm/amd/issues/1020
    Signed-off-by: Matt Coffin <mcoffin13@gmail.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org # 5.5.x

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 38febd5ca4da..4ad8d6c14ee5 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1706,22 +1706,11 @@ static int vega20_set_default_od_settings(struct smu_context *smu,
 	struct smu_table_context *table_context = &smu->smu_table;
 	int ret;
 
-	if (initialize) {
-		if (table_context->overdrive_table)
-			return -EINVAL;
-
-		table_context->overdrive_table = kzalloc(sizeof(OverDriveTable_t), GFP_KERNEL);
-
-		if (!table_context->overdrive_table)
-			return -ENOMEM;
-
-		ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE, 0,
-				       table_context->overdrive_table, false);
-		if (ret) {
-			pr_err("Failed to export over drive table!\n");
-			return ret;
-		}
+	ret = smu_v11_0_set_default_od_settings(smu, initialize, sizeof(OverDriveTable_t));
+	if (ret)
+		return ret;
 
+	if (initialize) {
 		ret = vega20_set_default_od8_setttings(smu);
 		if (ret)
 			return ret;
@@ -2778,12 +2767,11 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 		break;
 
 	case PP_OD_RESTORE_DEFAULT_TABLE:
-		ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE, 0, table_context->overdrive_table, false);
-		if (ret) {
-			pr_err("Failed to export over drive table!\n");
-			return ret;
+		if (!(table_context->overdrive_table && table_context->boot_overdrive_table)) {
+			pr_err("Overdrive table was not initialized!\n");
+			return -EINVAL;
 		}
-
+		memcpy(table_context->overdrive_table, table_context->boot_overdrive_table, sizeof(OverDriveTable_t));
 		break;
 
 	case PP_OD_COMMIT_DPM_TABLE:

commit ce0d0ec3390c5cf997e4ca43bd2047fa41e77bf1
Author: Evan Quan <evan.quan@amd.com>
Date:   Tue Dec 31 10:39:34 2019 +0800

    drm/amd/powerplay: unified VRAM address for driver table interaction with SMU V2
    
    By this, we can avoid to pass in the VRAM address on every table
    transferring. That puts extra unnecessary traffics on SMU on
    some cases(e.g. polling the amdgpu_pm_info sysfs interface).
    
    V2: document what the driver table is for and how it works
    
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 27bdcdeb08d9..38febd5ca4da 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3236,6 +3236,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.check_fw_version = smu_v11_0_check_fw_version,
 	.write_pptable = smu_v11_0_write_pptable,
 	.set_min_dcef_deep_sleep = smu_v11_0_set_min_dcef_deep_sleep,
+	.set_driver_table_location = smu_v11_0_set_driver_table_location,
 	.set_tool_table_location = smu_v11_0_set_tool_table_location,
 	.notify_memory_pool_location = smu_v11_0_notify_memory_pool_location,
 	.system_features_control = smu_v11_0_system_features_control,

commit 9fa1ed5bf628a871be52bb2d84ade8b108db8902
Author: Evan Quan <evan.quan@amd.com>
Date:   Tue Dec 31 10:33:19 2019 +0800

    drm/amd/powerplay: cache the watermark settings on system memory
    
    So that we do not need to allocate a piece of VRAM for it. This
    is a preparation for coming change which unifies the VRAM address
    for all driver tables interaction with SMU.
    
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 534c46bc0146..27bdcdeb08d9 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -338,6 +338,10 @@ static int vega20_tables_init(struct smu_context *smu, struct smu_table *tables)
 		return -ENOMEM;
 	smu_table->metrics_time = 0;
 
+	smu_table->watermarks_table = kzalloc(sizeof(Watermarks_t), GFP_KERNEL);
+	if (!smu_table->watermarks_table)
+		return -ENOMEM;
+
 	return 0;
 }
 

commit 337443d0e29054c95879a6a3149b29cc8fbd04df
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Fri Dec 20 16:34:42 2019 -0500

    drm/amdgpu/smu: make the set_performance_level logic easier to follow
    
    Have every asic provide a callback for this rather than a mix
    of generic and asic specific code.
    
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 250ff5aa1305..534c46bc0146 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3194,6 +3194,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_od_percentage = vega20_get_od_percentage,
 	.get_power_profile_mode = vega20_get_power_profile_mode,
 	.set_power_profile_mode = vega20_set_power_profile_mode,
+	.set_performance_level = smu_v11_0_set_performance_level,
 	.set_od_percentage = vega20_set_od_percentage,
 	.set_default_od_settings = vega20_set_default_od_settings,
 	.od_edit_dpm_table = vega20_odn_edit_dpm_table,

commit 0371e2fba42158cb55f6d2c8cf4c9c0821677c0c
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Tue Dec 17 09:51:40 2019 -0500

    drm/amdgpu/smu: add metrics table lock for vega20 (v2)
    
    To protect access to the metrics table.
    
    v2: unlock on error
    
    Bug: https://gitlab.freedesktop.org/drm/amd/issues/900
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 2b1c3f8a0415..250ff5aa1305 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1678,17 +1678,20 @@ static int vega20_get_metrics_table(struct smu_context *smu,
 	struct smu_table_context *smu_table= &smu->smu_table;
 	int ret = 0;
 
+	mutex_lock(&smu->metrics_lock);
 	if (!smu_table->metrics_time || time_after(jiffies, smu_table->metrics_time + HZ / 1000)) {
 		ret = smu_update_table(smu, SMU_TABLE_SMU_METRICS, 0,
 				(void *)smu_table->metrics_table, false);
 		if (ret) {
 			pr_info("Failed to export SMU metrics table!\n");
+			mutex_unlock(&smu->metrics_lock);
 			return ret;
 		}
 		smu_table->metrics_time = jiffies;
 	}
 
 	memcpy(metrics_table, smu_table->metrics_table, sizeof(SmuMetrics_t));
+	mutex_unlock(&smu->metrics_lock);
 
 	return ret;
 }

commit 19796597d10405210e3364d145ff460390bf0930
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Mon Dec 16 15:05:22 2019 -0500

    drm/amdgpu/smu: fix spelling
    
    s/dispaly/display/g
    
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 12bcc3e3ba99..2b1c3f8a0415 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2232,7 +2232,7 @@ static int vega20_apply_clocks_adjust_rules(struct smu_context *smu)
 }
 
 static int
-vega20_notify_smc_dispaly_config(struct smu_context *smu)
+vega20_notify_smc_display_config(struct smu_context *smu)
 {
 	struct vega20_dpm_table *dpm_table = smu->smu_dpm.dpm_context;
 	struct vega20_single_dpm_table *memtable = &dpm_table->mem_table;
@@ -3200,7 +3200,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.pre_display_config_changed = vega20_pre_display_config_changed,
 	.display_config_changed = vega20_display_config_changed,
 	.apply_clocks_adjust_rules = vega20_apply_clocks_adjust_rules,
-	.notify_smc_dispaly_config = vega20_notify_smc_dispaly_config,
+	.notify_smc_display_config = vega20_notify_smc_display_config,
 	.force_dpm_limit_value = vega20_force_dpm_limit_value,
 	.unforce_dpm_levels = vega20_unforce_dpm_levels,
 	.get_profiling_clk_mask = vega20_get_profiling_clk_mask,

commit f275cde7066a27ab7afa0a1d95390dbf237726a2
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Mon Dec 2 15:04:35 2019 +0800

    drm/amdgpu/powerplay: unify smu send message function
    
    Drop smu_send_smc_msg function from ASIC specify structure.
    Reuse smu_send_smc_msg_with_param function for smu_send_smc_msg.
    Set paramer to 0 for smu_send_msg function, otherwise it will send
    with previous paramer value (Not a certain value).
    Materialize msg type for smu send message function definition.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 02ede5c8b73a..12bcc3e3ba99 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3231,7 +3231,6 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.set_tool_table_location = smu_v11_0_set_tool_table_location,
 	.notify_memory_pool_location = smu_v11_0_notify_memory_pool_location,
 	.system_features_control = smu_v11_0_system_features_control,
-	.send_smc_msg = smu_v11_0_send_msg,
 	.send_smc_msg_with_param = smu_v11_0_send_msg_with_param,
 	.read_smc_arg = smu_v11_0_read_arg,
 	.init_display_count = smu_v11_0_init_display_count,

commit 11520f27085bbab7dcb2b5998dec7e7abe3a5bd1
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Mon Oct 28 15:20:03 2019 -0400

    drm/amdgpu: split swSMU baco_reset into enter and exit
    
    BACO - Bus Active, Chip Off
    
    So we can use it for power savings rather than just reset.
    
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 0b4892833808..02ede5c8b73a 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3257,7 +3257,8 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.baco_is_support= smu_v11_0_baco_is_support,
 	.baco_get_state = smu_v11_0_baco_get_state,
 	.baco_set_state = smu_v11_0_baco_set_state,
-	.baco_reset = smu_v11_0_baco_reset,
+	.baco_enter = smu_v11_0_baco_enter,
+	.baco_exit = smu_v11_0_baco_exit,
 	.get_dpm_ultimate_freq = smu_v11_0_get_dpm_ultimate_freq,
 	.set_soft_freq_limited_range = smu_v11_0_set_soft_freq_limited_range,
 	.override_pcie_parameters = smu_v11_0_override_pcie_parameters,

commit 73abde4d864b381be8b36d460d127fd479a560d3
Author: Matt Coffin <mcoffin13@gmail.com>
Date:   Mon Nov 11 11:36:31 2019 -0700

    drm/amdgpu/smu_v11: Unify and fix power limits
    
    [Why]
    On Navi10, and presumably arcterus, updating pp_table via sysfs would
    not re-scale the maximum possible power limit one can set. On navi10,
    the SMU code ignored the power percentage overdrive setting entirely,
    and would not allow you to exceed the default power limit at all.
    
    [How]
    Adding a function to the SMU interface to get the pptable version of the
    default power limit allows ASIC-specific code to provide the correct
    maximum-settable power limit for the current pptable.
    
    v3: fix spelling (Alex)
    
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Signed-off-by: Matt Coffin <mcoffin13@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 5b21386f558d..0b4892833808 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -466,7 +466,6 @@ static int vega20_store_powerplay_table(struct smu_context *smu)
 	       sizeof(PPTable_t));
 
 	table_context->thermal_controller_type = powerplay_table->ucThermalControllerType;
-	table_context->TDPODLimit = le32_to_cpu(powerplay_table->OverDrive8Table.ODSettingsMax[ATOM_VEGA20_ODSETTING_POWERPERCENTAGE]);
 
 	return 0;
 }

commit 2c874ad9d6293cd387b13304894e4322ec3eab6f
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Tue Nov 5 18:16:38 2019 +0800

    drm/amd/swSMU: fix smu workload bit map error
    
    fix workload bit (WORKLOAD_PPLIB_COMPUTE_BIT) map error
    on vega20 and navi asic.
    
    fix commit:
    drm/amd/powerplay: add function get_workload_type_map for swsmu
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Kenneth Feng <kenneth.feng@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 7c8933f987d1..5b21386f558d 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -221,7 +221,7 @@ static struct smu_11_0_cmn2aisc_mapping vega20_workload_map[PP_SMC_POWER_PROFILE
 	WORKLOAD_MAP(PP_SMC_POWER_PROFILE_POWERSAVING,		WORKLOAD_PPLIB_POWER_SAVING_BIT),
 	WORKLOAD_MAP(PP_SMC_POWER_PROFILE_VIDEO,		WORKLOAD_PPLIB_VIDEO_BIT),
 	WORKLOAD_MAP(PP_SMC_POWER_PROFILE_VR,			WORKLOAD_PPLIB_VR_BIT),
-	WORKLOAD_MAP(PP_SMC_POWER_PROFILE_COMPUTE,		WORKLOAD_PPLIB_CUSTOM_BIT),
+	WORKLOAD_MAP(PP_SMC_POWER_PROFILE_COMPUTE,		WORKLOAD_PPLIB_COMPUTE_BIT),
 	WORKLOAD_MAP(PP_SMC_POWER_PROFILE_CUSTOM,		WORKLOAD_PPLIB_CUSTOM_BIT),
 };
 

commit 6c45e480fe23d779df5cb95ce55cf9d4f4fb51cb
Author: Evan Quan <evan.quan@amd.com>
Date:   Thu Oct 17 19:59:29 2019 +0800

    drm/amd/powerplay: clear the swSMU code layer
    
    With this cleanup, the APIs from amdgpu_smu.c will map to
    ASIC specific ones directly. Those can be shared around
    all SMU V11/V12 ASICs will be put in smu_v11_0.c and
    smu_v12_0.c respectively.
    
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index f077db127d04..7c8933f987d1 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2248,7 +2248,7 @@ vega20_notify_smc_dispaly_config(struct smu_context *smu)
 	if (smu_feature_is_supported(smu, SMU_FEATURE_DPM_DCEFCLK_BIT)) {
 		clock_req.clock_type = amd_pp_dcef_clock;
 		clock_req.clock_freq_in_khz = min_clocks.dcef_clock * 10;
-		if (!smu->funcs->display_clock_voltage_request(smu, &clock_req)) {
+		if (!smu_v11_0_display_clock_voltage_request(smu, &clock_req)) {
 			if (smu_feature_is_supported(smu, SMU_FEATURE_DS_DCEFCLK_BIT)) {
 				ret = smu_send_smc_msg_with_param(smu,
 								  SMU_MSG_SetMinDeepSleepDcefclk,
@@ -3031,7 +3031,7 @@ static int vega20_read_sensor(struct smu_context *smu,
 		*size = 4;
 		break;
 	default:
-		ret = smu_smc_read_sensor(smu, sensor, data, size);
+		ret = smu_v11_0_read_sensor(smu, sensor, data, size);
 	}
 	mutex_unlock(&smu->sensor_lock);
 
@@ -3212,7 +3212,56 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.set_watermarks_table = vega20_set_watermarks_table,
 	.get_thermal_temperature_range = vega20_get_thermal_temperature_range,
 	.set_df_cstate = vega20_set_df_cstate,
-	.update_pcie_parameters = vega20_update_pcie_parameters
+	.update_pcie_parameters = vega20_update_pcie_parameters,
+	.init_microcode = smu_v11_0_init_microcode,
+	.load_microcode = smu_v11_0_load_microcode,
+	.init_smc_tables = smu_v11_0_init_smc_tables,
+	.fini_smc_tables = smu_v11_0_fini_smc_tables,
+	.init_power = smu_v11_0_init_power,
+	.fini_power = smu_v11_0_fini_power,
+	.check_fw_status = smu_v11_0_check_fw_status,
+	.setup_pptable = smu_v11_0_setup_pptable,
+	.get_vbios_bootup_values = smu_v11_0_get_vbios_bootup_values,
+	.get_clk_info_from_vbios = smu_v11_0_get_clk_info_from_vbios,
+	.check_pptable = smu_v11_0_check_pptable,
+	.parse_pptable = smu_v11_0_parse_pptable,
+	.populate_smc_tables = smu_v11_0_populate_smc_pptable,
+	.check_fw_version = smu_v11_0_check_fw_version,
+	.write_pptable = smu_v11_0_write_pptable,
+	.set_min_dcef_deep_sleep = smu_v11_0_set_min_dcef_deep_sleep,
+	.set_tool_table_location = smu_v11_0_set_tool_table_location,
+	.notify_memory_pool_location = smu_v11_0_notify_memory_pool_location,
+	.system_features_control = smu_v11_0_system_features_control,
+	.send_smc_msg = smu_v11_0_send_msg,
+	.send_smc_msg_with_param = smu_v11_0_send_msg_with_param,
+	.read_smc_arg = smu_v11_0_read_arg,
+	.init_display_count = smu_v11_0_init_display_count,
+	.set_allowed_mask = smu_v11_0_set_allowed_mask,
+	.get_enabled_mask = smu_v11_0_get_enabled_mask,
+	.notify_display_change = smu_v11_0_notify_display_change,
+	.set_power_limit = smu_v11_0_set_power_limit,
+	.get_current_clk_freq = smu_v11_0_get_current_clk_freq,
+	.init_max_sustainable_clocks = smu_v11_0_init_max_sustainable_clocks,
+	.start_thermal_control = smu_v11_0_start_thermal_control,
+	.stop_thermal_control = smu_v11_0_stop_thermal_control,
+	.set_deep_sleep_dcefclk = smu_v11_0_set_deep_sleep_dcefclk,
+	.display_clock_voltage_request = smu_v11_0_display_clock_voltage_request,
+	.get_fan_control_mode = smu_v11_0_get_fan_control_mode,
+	.set_fan_control_mode = smu_v11_0_set_fan_control_mode,
+	.set_fan_speed_percent = smu_v11_0_set_fan_speed_percent,
+	.set_fan_speed_rpm = smu_v11_0_set_fan_speed_rpm,
+	.set_xgmi_pstate = smu_v11_0_set_xgmi_pstate,
+	.gfx_off_control = smu_v11_0_gfx_off_control,
+	.register_irq_handler = smu_v11_0_register_irq_handler,
+	.set_azalia_d3_pme = smu_v11_0_set_azalia_d3_pme,
+	.get_max_sustainable_clocks_by_dc = smu_v11_0_get_max_sustainable_clocks_by_dc,
+	.baco_is_support= smu_v11_0_baco_is_support,
+	.baco_get_state = smu_v11_0_baco_get_state,
+	.baco_set_state = smu_v11_0_baco_set_state,
+	.baco_reset = smu_v11_0_baco_reset,
+	.get_dpm_ultimate_freq = smu_v11_0_get_dpm_ultimate_freq,
+	.set_soft_freq_limited_range = smu_v11_0_set_soft_freq_limited_range,
+	.override_pcie_parameters = smu_v11_0_override_pcie_parameters,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 18c1d3cee4c5935ebcfa0b434e4a8ef6d78496ad
Author: Evan Quan <evan.quan@amd.com>
Date:   Thu Oct 17 14:15:41 2019 +0800

    drm/amd/powerplay: split out those internal used swSMU APIs V2
    
    Those swSMU APIs used internally are moved to smu_internal.h while
    others are kept in amdgpu_smu.h.
    
    V2: give a better name smu_internal.h for the place to hold
        those internal APIs
    
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index e9ded2bae2ac..f077db127d04 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -25,6 +25,7 @@
 #include <linux/firmware.h>
 #include "amdgpu.h"
 #include "amdgpu_smu.h"
+#include "smu_internal.h"
 #include "atomfirmware.h"
 #include "amdgpu_atomfirmware.h"
 #include "smu_v11_0.h"

commit 3697b339c64f82af195fd3cc6492ef26b6dfcd47
Author: Evan Quan <evan.quan@amd.com>
Date:   Wed Oct 16 14:43:07 2019 +0800

    drm/amd/powerplay: add lock protection for swSMU APIs V2
    
    This is a quick and low risk fix. Those APIs which
    are exposed to other IPs or to support sysfs/hwmon
    interfaces or DAL will have lock protection. Meanwhile
    no lock protection is enforced for swSMU internal used
    APIs. Future optimization is needed.
    
    V2: strip the lock protection for all swSMU internal APIs
    
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Acked-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Acked-by: Feifei Xu <Feifei.Xu@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index bebf38ca4be7..e9ded2bae2ac 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -635,7 +635,6 @@ amd_pm_state_type vega20_get_current_power_state(struct smu_context *smu)
 	    !smu_dpm_ctx->dpm_current_power_state)
 		return -EINVAL;
 
-	mutex_lock(&(smu->mutex));
 	switch (smu_dpm_ctx->dpm_current_power_state->classification.ui_label) {
 	case SMU_STATE_UI_LABEL_BATTERY:
 		pm_type = POWER_STATE_TYPE_BATTERY;
@@ -653,7 +652,6 @@ amd_pm_state_type vega20_get_current_power_state(struct smu_context *smu)
 			pm_type = POWER_STATE_TYPE_DEFAULT;
 		break;
 	}
-	mutex_unlock(&(smu->mutex));
 
 	return pm_type;
 }
@@ -1277,8 +1275,6 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 	uint32_t soft_min_level, soft_max_level, hard_min_level;
 	int ret = 0;
 
-	mutex_lock(&(smu->mutex));
-
 	soft_min_level = mask ? (ffs(mask) - 1) : 0;
 	soft_max_level = mask ? (fls(mask) - 1) : 0;
 
@@ -1431,7 +1427,6 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 		break;
 	}
 
-	mutex_unlock(&(smu->mutex));
 	return ret;
 }
 
@@ -1446,8 +1441,6 @@ static int vega20_get_clock_by_type_with_latency(struct smu_context *smu,
 
 	dpm_table = smu_dpm->dpm_context;
 
-	mutex_lock(&smu->mutex);
-
 	switch (clk_type) {
 	case SMU_GFXCLK:
 		single_dpm_table = &(dpm_table->gfx_table);
@@ -1469,7 +1462,6 @@ static int vega20_get_clock_by_type_with_latency(struct smu_context *smu,
 		ret = -EINVAL;
 	}
 
-	mutex_unlock(&smu->mutex);
 	return ret;
 }
 
@@ -2542,8 +2534,6 @@ static int vega20_set_od_percentage(struct smu_context *smu,
 	int feature_enabled;
 	PPCLK_e clk_id;
 
-	mutex_lock(&(smu->mutex));
-
 	dpm_table = smu_dpm->dpm_context;
 	golden_table = smu_dpm->golden_dpm_context;
 
@@ -2593,11 +2583,10 @@ static int vega20_set_od_percentage(struct smu_context *smu,
 	}
 
 	ret = smu_handle_task(smu, smu_dpm->dpm_level,
-			      AMD_PP_TASK_READJUST_POWER_STATE);
+			      AMD_PP_TASK_READJUST_POWER_STATE,
+			      false);
 
 set_od_failed:
-	mutex_unlock(&(smu->mutex));
-
 	return ret;
 }
 
@@ -2822,10 +2811,9 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 	}
 
 	if (type == PP_OD_COMMIT_DPM_TABLE) {
-		mutex_lock(&(smu->mutex));
 		ret = smu_handle_task(smu, smu_dpm->dpm_level,
-				      AMD_PP_TASK_READJUST_POWER_STATE);
-		mutex_unlock(&(smu->mutex));
+				      AMD_PP_TASK_READJUST_POWER_STATE,
+				      false);
 	}
 
 	return ret;

commit 372120f0a5922655eb2579a50d6aafad474fd14c
Author: Kenneth Feng <kenneth.feng@amd.com>
Date:   Fri Oct 11 17:51:34 2019 +0800

    drm/amd/powerplay: bug fix for pcie parameters override
    
    Bug fix for pcie paramerers override on swsmu.
    Below is a scenario to have this problem.
    pptable definition on pcie dpm:
    0 -> pcie gen speed:1, pcie lanes: *16
    1 -> pcie gen speed:4, pcie lanes: *16
    Then if we have a system only have the capbility:
    pcie gen speed: 3, pcie lanes: *8,
    we will override dpm 1 to pcie gen speed 3, pcie lanes *8.
    But the code skips the dpm 0 configuration.
    So the real pcie dpm parameters are:
    0 -> pcie gen speed:1, pcie lanes: *16
    1 -> pcie gen speed:3, pcie lanes: *8
    Then the wrong pcie lanes will be toggled.
    
    Signed-off-by: Kenneth Feng <kenneth.feng@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 3fc6ad088e19..bebf38ca4be7 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3157,6 +3157,28 @@ static int vega20_set_df_cstate(struct smu_context *smu,
 	return smu_send_smc_msg_with_param(smu, SMU_MSG_DFCstateControl, state);
 }
 
+static int vega20_update_pcie_parameters(struct smu_context *smu,
+				     uint32_t pcie_gen_cap,
+				     uint32_t pcie_width_cap)
+{
+	PPTable_t *pptable = smu->smu_table.driver_pptable;
+	int ret, i;
+	uint32_t smu_pcie_arg;
+
+	for (i = 0; i < NUM_LINK_LEVELS; i++) {
+		smu_pcie_arg = (i << 16) |
+			((pptable->PcieGenSpeed[i] <= pcie_gen_cap) ? (pptable->PcieGenSpeed[i] << 8) :
+				(pcie_gen_cap << 8)) | ((pptable->PcieLaneCount[i] <= pcie_width_cap) ?
+					pptable->PcieLaneCount[i] : pcie_width_cap);
+		ret = smu_send_smc_msg_with_param(smu,
+					  SMU_MSG_OverridePcieParameters,
+					  smu_pcie_arg);
+	}
+
+	return ret;
+}
+
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.tables_init = vega20_tables_init,
 	.alloc_dpm_context = vega20_allocate_dpm_context,
@@ -3201,6 +3223,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.set_watermarks_table = vega20_set_watermarks_table,
 	.get_thermal_temperature_range = vega20_get_thermal_temperature_range,
 	.set_df_cstate = vega20_set_df_cstate,
+	.update_pcie_parameters = vega20_update_pcie_parameters
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 7e899409fd5e9abccee8435d9401b8ca12cebcae
Author: Evan Quan <evan.quan@amd.com>
Date:   Thu Oct 10 11:40:37 2019 +0800

    drm/amd/powerplay: enable df cstate control on swSMU routine
    
    Currently this is only supported on Vega20 with 40.50 and later
    SMC firmware.
    
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Reviewed-by: Kenneth Feng <kenneth.feng@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index f655ebd9ba22..3fc6ad088e19 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -143,6 +143,7 @@ static struct smu_11_0_cmn2aisc_mapping vega20_message_map[SMU_MSG_MAX_COUNT] =
 	MSG_MAP(PrepareMp1ForShutdown),
 	MSG_MAP(SetMGpuFanBoostLimitRpm),
 	MSG_MAP(GetAVFSVoltageByDpm),
+	MSG_MAP(DFCstateControl),
 };
 
 static struct smu_11_0_cmn2aisc_mapping vega20_clk_map[SMU_CLK_COUNT] = {
@@ -3135,6 +3136,27 @@ static int vega20_get_thermal_temperature_range(struct smu_context *smu,
 	return 0;
 }
 
+static int vega20_set_df_cstate(struct smu_context *smu,
+				enum pp_df_cstate state)
+{
+	uint32_t smu_version;
+	int ret;
+
+	ret = smu_get_smc_version(smu, NULL, &smu_version);
+	if (ret) {
+		pr_err("Failed to get smu version!\n");
+		return ret;
+	}
+
+	/* PPSMC_MSG_DFCstateControl is supported with 40.50 and later fws */
+	if (smu_version < 0x283200) {
+		pr_err("Df cstate control is supported with 40.50 and later SMC fw!\n");
+		return -EINVAL;
+	}
+
+	return smu_send_smc_msg_with_param(smu, SMU_MSG_DFCstateControl, state);
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.tables_init = vega20_tables_init,
 	.alloc_dpm_context = vega20_allocate_dpm_context,
@@ -3177,7 +3199,8 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_fan_speed_percent = vega20_get_fan_speed_percent,
 	.get_fan_speed_rpm = vega20_get_fan_speed_rpm,
 	.set_watermarks_table = vega20_set_watermarks_table,
-	.get_thermal_temperature_range = vega20_get_thermal_temperature_range
+	.get_thermal_temperature_range = vega20_get_thermal_temperature_range,
+	.set_df_cstate = vega20_set_df_cstate,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 95f71bfad2c8015e46bce2c23b6f532afc6ab820
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Thu Sep 26 16:22:13 2019 +0800

    drm/amd/powerplay: add sensor lock support for smu
    
    when multithreading access sysfs of amdgpu_pm_info at the sametime.
    the swsmu driver cause smu firmware hang.
    
    eg:
    single thread access:
    Message A + Param A ==> right
    Message B + Param B ==> right
    Message C + Param C ==> right
    multithreading access:
    Message A + Param B ==> error
    Message B + Param A ==> error
    Message C + Param C ==> right
    
    the patch will add sensor lock(mutex) to avoid this error.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Kenneth Feng <kenneth.feng@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 9082da1578d1..f655ebd9ba22 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3017,6 +3017,7 @@ static int vega20_read_sensor(struct smu_context *smu,
 	if(!data || !size)
 		return -EINVAL;
 
+	mutex_lock(&smu->sensor_lock);
 	switch (sensor) {
 	case AMDGPU_PP_SENSOR_MAX_FAN_RPM:
 		*(uint32_t *)data = pptable->FanMaximumRpm;
@@ -3042,6 +3043,7 @@ static int vega20_read_sensor(struct smu_context *smu,
 	default:
 		ret = smu_smc_read_sensor(smu, sensor, data, size);
 	}
+	mutex_unlock(&smu->sensor_lock);
 
 	return ret;
 }

commit 04c572a0df02892f29625a1d4e2bc1e65b741cf2
Author: Evan Quan <evan.quan@amd.com>
Date:   Thu Sep 5 12:22:42 2019 +0800

    drm/amd/powerplay: issue DC-BTC for arcturus on SMU init
    
    Need to perform DC-BTC for arcturus on bootup.
    
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 45a3778afdd3..9082da1578d1 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3145,7 +3145,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_smu_table_index = vega20_get_smu_table_index,
 	.get_smu_power_index = vega20_get_pwr_src_index,
 	.get_workload_type = vega20_get_workload_type,
-	.run_afll_btc = vega20_run_btc_afll,
+	.run_btc = vega20_run_btc_afll,
 	.get_allowed_feature_mask = vega20_get_allowed_feature_mask,
 	.get_current_power_state = vega20_get_current_power_state,
 	.set_default_dpm_table = vega20_set_default_dpm_table,

commit 871e5e7219e720e7993c12e47197709d92cbf244
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Tue Sep 3 16:02:33 2019 +0800

    drm/amd/powerplay: replace smu->table_count with SMU_TABLE_COUNT in smu (v2)
    
    fix bellow patch issue:
    drm/amd/powerplay: introduce smu table id type to handle the smu table
    for each asic
    ----
    "This patch introduces new smu table type, it's to handle the
     different smu table
     defines for each asic with the same smu ip."
    
    before:
    use smu->table_count to represent the actual table count in smc firmware
    use actual table count to check smu function parameter about smu table
    after:
    use logic table count "SMU_TABLE_COUNT" to check function parameter
    because table id already mapped in smu driver,
    and smu function will use logic table id not actual table id to check func parameter.
    
    v2: squash in warning fix
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Acked-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index e754e0349df9..45a3778afdd3 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3180,8 +3180,5 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 
 void vega20_set_ppt_funcs(struct smu_context *smu)
 {
-	struct smu_table_context *smu_table = &smu->smu_table;
-
 	smu->ppt_funcs = &vega20_ppt_funcs;
-	smu_table->table_count = TABLE_COUNT;
 }

commit f78c47f669086503844ea0d78b64a18c0e6f3e77
Author: Evan Quan <evan.quan@amd.com>
Date:   Fri Aug 30 17:30:46 2019 +0800

    drm/amd/powerplay: guard manual mode prerequisite for clock level force
    
    Force clock level is for dpm manual mode only.
    
    Reported-by: Candice Li <candice.li@amd.com>
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Jack Gui <Jack.Gui@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 64386ee3f878..e754e0349df9 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1274,14 +1274,8 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 	struct vega20_dpm_table *dpm_table;
 	struct vega20_single_dpm_table *single_dpm_table;
 	uint32_t soft_min_level, soft_max_level, hard_min_level;
-	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
 	int ret = 0;
 
-	if (smu_dpm->dpm_level != AMD_DPM_FORCED_LEVEL_MANUAL) {
-		pr_info("force clock level is for dpm manual mode only.\n");
-		return -EINVAL;
-	}
-
 	mutex_lock(&(smu->mutex));
 
 	soft_min_level = mask ? (ffs(mask) - 1) : 0;

commit 951e15c2b58436b30e435f3169c97e9f4e265b58
Author: Kent Russell <kent.russell@amd.com>
Date:   Fri Aug 23 09:13:18 2019 -0400

    drm/powerplay: Fix Vega20 power reading again
    
    For the 40.46 SMU release, they changed CurrSocketPower to
    AverageSocketPower, but this was changed back in 40.47 so just check if
    it's 40.46 and make the appropriate change
    
    Tested with 40.45, 40.46 and 40.47 successfully
    
    Signed-off-by: Kent Russell <kent.russell@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index e25f5db5014b..64386ee3f878 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2932,10 +2932,11 @@ static int vega20_get_gpu_power(struct smu_context *smu, uint32_t *value)
 	if (ret)
 		return ret;
 
-	if (smu_version < 0x282e00)
-		*value = metrics.CurrSocketPower << 8;
-	else
+	/* For the 40.46 release, they changed the value name */
+	if (smu_version == 0x282e00)
 		*value = metrics.AverageSocketPower << 8;
+	else
+		*value = metrics.CurrSocketPower << 8;
 
 	return 0;
 }

commit 32e40ffbced3b14ceac1ae13a1a66c5849a6d2d3
Author: Kent Russell <kent.russell@amd.com>
Date:   Thu Aug 22 08:17:40 2019 -0400

    drm/powerplay: Fix Vega20 Average Power value v4
    
    The SMU changed reading from CurrSocketPower to AverageSocketPower, so
    reflect this accordingly. This fixes the issue where Average Power
    Consumption was being reported as 0 from SMU 40.46-onward
    
    v2: Fixed headline prefix
    v3: Add check for SMU version for proper compatibility
    v4: Style fix
    
    Signed-off-by: Kent Russell <kent.russell@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 7ab93f27b15e..e25f5db5014b 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2917,6 +2917,7 @@ static int vega20_get_fan_speed_percent(struct smu_context *smu,
 
 static int vega20_get_gpu_power(struct smu_context *smu, uint32_t *value)
 {
+	uint32_t smu_version;
 	int ret = 0;
 	SmuMetrics_t metrics;
 
@@ -2927,7 +2928,14 @@ static int vega20_get_gpu_power(struct smu_context *smu, uint32_t *value)
 	if (ret)
 		return ret;
 
-	*value = metrics.CurrSocketPower << 8;
+	ret = smu_get_smc_version(smu, NULL, &smu_version);
+	if (ret)
+		return ret;
+
+	if (smu_version < 0x282e00)
+		*value = metrics.CurrSocketPower << 8;
+	else
+		*value = metrics.AverageSocketPower << 8;
 
 	return 0;
 }

commit a056ddce9b15a117949e59ad44bea5b3d12f17b5
Author: Evan Quan <evan.quan@amd.com>
Date:   Fri Aug 16 17:11:46 2019 +0800

    drm/amd/powerplay: correct SW smu11 thermal range settings
    
    Problems with current settings:
    1. The min value was overrided to 0 on Vega20 & Navi10. While
       the expected should be -273.15 C.
    2. The thermal min/max threshold was output in wrong unit on
       Navi10 & Arcturus. As TEMP_RANGE_MIN/MAX is already in
       millicelsius. And "*1000" in smu_v11_0_start_thermal_control
       makes the output wrongly.
    
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Reviewed-by: Kenneth Feng <kenneth.feng@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index a23c16ceef74..7ab93f27b15e 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3113,14 +3113,18 @@ static int vega20_get_thermal_temperature_range(struct smu_context *smu,
 	if (!range || !powerplay_table)
 		return -EINVAL;
 
-	/* The unit is temperature */
-	range->min = 0;
-	range->max = powerplay_table->usSoftwareShutdownTemp;
-	range->edge_emergency_max = (pptable->TedgeLimit + CTF_OFFSET_EDGE);
-	range->hotspot_crit_max = pptable->ThotspotLimit;
-	range->hotspot_emergency_max = (pptable->ThotspotLimit + CTF_OFFSET_HOTSPOT);
-	range->mem_crit_max = pptable->ThbmLimit;
-	range->mem_emergency_max = (pptable->ThbmLimit + CTF_OFFSET_HBM);
+	range->max = powerplay_table->usSoftwareShutdownTemp *
+		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
+	range->edge_emergency_max = (pptable->TedgeLimit + CTF_OFFSET_EDGE) *
+		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
+	range->hotspot_crit_max = pptable->ThotspotLimit *
+		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
+	range->hotspot_emergency_max = (pptable->ThotspotLimit + CTF_OFFSET_HOTSPOT) *
+		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
+	range->mem_crit_max = pptable->ThbmLimit *
+		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
+	range->mem_emergency_max = (pptable->ThbmLimit + CTF_OFFSET_HBM) *
+		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
 
 
 	return 0;

commit 9b4e63f4513bbd626b2490ce81435a38d7bc3902
Author: Kenneth Feng <kenneth.feng@amd.com>
Date:   Tue Jul 23 12:16:25 2019 +0800

    drm/amd/powerplay: change smu_read_sensor sequence in smu
    
    change the smu_read_sensor sequence to:
    
    asic specific sensor read -> smu v11 specific sensor read -> smu v11 common sensor read
    
    Signed-off-by: Kenneth Feng <kenneth.feng@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index f71a385d1896..a23c16ceef74 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3011,6 +3011,9 @@ static int vega20_read_sensor(struct smu_context *smu,
 	struct smu_table_context *table_context = &smu->smu_table;
 	PPTable_t *pptable = table_context->driver_pptable;
 
+	if(!data || !size)
+		return -EINVAL;
+
 	switch (sensor) {
 	case AMDGPU_PP_SENSOR_MAX_FAN_RPM:
 		*(uint32_t *)data = pptable->FanMaximumRpm;
@@ -3034,7 +3037,7 @@ static int vega20_read_sensor(struct smu_context *smu,
 		*size = 4;
 		break;
 	default:
-		return -EINVAL;
+		ret = smu_smc_read_sensor(smu, sensor, data, size);
 	}
 
 	return ret;

commit 1b41b769e137222eb003395ab2c76db50c799edd
Author: tiancyin <tianci.yin@amd.com>
Date:   Thu Aug 8 11:57:28 2019 +0800

    drm/amd/powerplay: re-define smu interface version for smu v11
    
    [why]
    navi14 share same defination of smu interface version with navi10,
    anyone of them update the version may break the other one's
    version checking.
    
    [how]
    create different version defination, so that they can
    update their version separately.
    
    Reviewed-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: tiancyin <tianci.yin@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 0102e24063d4..f71a385d1896 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3173,6 +3173,5 @@ void vega20_set_ppt_funcs(struct smu_context *smu)
 	struct smu_table_context *smu_table = &smu->smu_table;
 
 	smu->ppt_funcs = &vega20_ppt_funcs;
-	smu->smc_if_version = SMU11_DRIVER_IF_VERSION;
 	smu_table->table_count = TABLE_COUNT;
 }

commit 98eb03bbf0175f009a74c80ac12b91a9680292f4
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Thu Jul 25 11:47:44 2019 +0800

    drm/amd/powerplay: implment sysfs feature status function in smu
    
    1. Unified feature enable status format in sysfs
    2. Rename ppfeature to pp_features to adapt other pp sysfs node name
    3. this function support all asic, not asic related function.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Kenneth Feng <kenneth.feng@amd.com>
    Acked-by: Rui Huang <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 95afc153a924..0102e24063d4 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2858,157 +2858,6 @@ static int vega20_dpm_set_vce_enable(struct smu_context *smu, bool enable)
 	return smu_feature_set_enabled(smu, SMU_FEATURE_DPM_VCE_BIT, enable);
 }
 
-static int vega20_get_enabled_smc_features(struct smu_context *smu,
-		uint64_t *features_enabled)
-{
-	uint32_t feature_mask[2] = {0, 0};
-	int ret = 0;
-
-	ret = smu_feature_get_enabled_mask(smu, feature_mask, 2);
-	if (ret)
-		return ret;
-
-	*features_enabled = ((((uint64_t)feature_mask[0] << SMU_FEATURES_LOW_SHIFT) & SMU_FEATURES_LOW_MASK) |
-			(((uint64_t)feature_mask[1] << SMU_FEATURES_HIGH_SHIFT) & SMU_FEATURES_HIGH_MASK));
-
-	return ret;
-}
-
-static int vega20_enable_smc_features(struct smu_context *smu,
-		bool enable, uint64_t feature_mask)
-{
-	uint32_t smu_features_low, smu_features_high;
-	int ret = 0;
-
-	smu_features_low = (uint32_t)((feature_mask & SMU_FEATURES_LOW_MASK) >> SMU_FEATURES_LOW_SHIFT);
-	smu_features_high = (uint32_t)((feature_mask & SMU_FEATURES_HIGH_MASK) >> SMU_FEATURES_HIGH_SHIFT);
-
-	if (enable) {
-		ret = smu_send_smc_msg_with_param(smu, SMU_MSG_EnableSmuFeaturesLow,
-						  smu_features_low);
-		if (ret)
-			return ret;
-		ret = smu_send_smc_msg_with_param(smu, SMU_MSG_EnableSmuFeaturesHigh,
-						  smu_features_high);
-		if (ret)
-			return ret;
-	} else {
-		ret = smu_send_smc_msg_with_param(smu, SMU_MSG_DisableSmuFeaturesLow,
-						  smu_features_low);
-		if (ret)
-			return ret;
-		ret = smu_send_smc_msg_with_param(smu, SMU_MSG_DisableSmuFeaturesHigh,
-						  smu_features_high);
-		if (ret)
-			return ret;
-	}
-
-	return 0;
-
-}
-
-static int vega20_get_ppfeature_status(struct smu_context *smu, char *buf)
-{
-	static const char *ppfeature_name[] = {
-				"DPM_PREFETCHER",
-				"GFXCLK_DPM",
-				"UCLK_DPM",
-				"SOCCLK_DPM",
-				"UVD_DPM",
-				"VCE_DPM",
-				"ULV",
-				"MP0CLK_DPM",
-				"LINK_DPM",
-				"DCEFCLK_DPM",
-				"GFXCLK_DS",
-				"SOCCLK_DS",
-				"LCLK_DS",
-				"PPT",
-				"TDC",
-				"THERMAL",
-				"GFX_PER_CU_CG",
-				"RM",
-				"DCEFCLK_DS",
-				"ACDC",
-				"VR0HOT",
-				"VR1HOT",
-				"FW_CTF",
-				"LED_DISPLAY",
-				"FAN_CONTROL",
-				"GFX_EDC",
-				"GFXOFF",
-				"CG",
-				"FCLK_DPM",
-				"FCLK_DS",
-				"MP1CLK_DS",
-				"MP0CLK_DS",
-				"XGMI",
-				"ECC"};
-	static const char *output_title[] = {
-				"FEATURES",
-				"BITMASK",
-				"ENABLEMENT"};
-	uint64_t features_enabled;
-	int i;
-	int ret = 0;
-	int size = 0;
-
-	ret = vega20_get_enabled_smc_features(smu, &features_enabled);
-	if (ret)
-		return ret;
-
-	size += sprintf(buf + size, "Current ppfeatures: 0x%016llx\n", features_enabled);
-	size += sprintf(buf + size, "%-19s %-22s %s\n",
-				output_title[0],
-				output_title[1],
-				output_title[2]);
-	for (i = 0; i < GNLD_FEATURES_MAX; i++) {
-		size += sprintf(buf + size, "%-19s 0x%016llx %6s\n",
-					ppfeature_name[i],
-					1ULL << i,
-					(features_enabled & (1ULL << i)) ? "Y" : "N");
-	}
-
-	return size;
-}
-
-static int vega20_set_ppfeature_status(struct smu_context *smu, uint64_t new_ppfeature_masks)
-{
-	uint64_t features_enabled;
-	uint64_t features_to_enable;
-	uint64_t features_to_disable;
-	int ret = 0;
-
-	if (new_ppfeature_masks >= (1ULL << GNLD_FEATURES_MAX))
-		return -EINVAL;
-
-	ret = vega20_get_enabled_smc_features(smu, &features_enabled);
-	if (ret)
-		return ret;
-
-	features_to_disable =
-		features_enabled & ~new_ppfeature_masks;
-	features_to_enable =
-		~features_enabled & new_ppfeature_masks;
-
-	pr_debug("features_to_disable 0x%llx\n", features_to_disable);
-	pr_debug("features_to_enable 0x%llx\n", features_to_enable);
-
-	if (features_to_disable) {
-		ret = vega20_enable_smc_features(smu, false, features_to_disable);
-		if (ret)
-			return ret;
-	}
-
-	if (features_to_enable) {
-		ret = vega20_enable_smc_features(smu, true, features_to_enable);
-		if (ret)
-			return ret;
-	}
-
-	return 0;
-}
-
 static bool vega20_is_dpm_running(struct smu_context *smu)
 {
 	int ret = 0;
@@ -3311,8 +3160,6 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.force_dpm_limit_value = vega20_force_dpm_limit_value,
 	.unforce_dpm_levels = vega20_unforce_dpm_levels,
 	.get_profiling_clk_mask = vega20_get_profiling_clk_mask,
-	.set_ppfeature_status = vega20_set_ppfeature_status,
-	.get_ppfeature_status = vega20_get_ppfeature_status,
 	.is_dpm_running = vega20_is_dpm_running,
 	.set_thermal_fan_table = vega20_set_thermal_fan_table,
 	.get_fan_speed_percent = vega20_get_fan_speed_percent,

commit 7a81637105345dce2bae7bef69125f0d40570a36
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Mon Jun 3 15:58:31 2019 +0800

    drm/amd/powerplay: add callback function of get_thermal_temperature_range
    
    1. the thermal temperature is asic related data, move the code logic to
    xxx_ppt.c.
    2. replace data structure PP_TemperatureRange with
    smu_temperature_range.
    3. change temperature uint from temp*1000 to temp (temperature uint).
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Signed-off-by: Kenneth Feng <kenneth.feng@amd.com>
    Acked-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 03e310426ffb..95afc153a924 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -463,7 +463,6 @@ static int vega20_store_powerplay_table(struct smu_context *smu)
 	memcpy(table_context->driver_pptable, &powerplay_table->smcPPTable,
 	       sizeof(PPTable_t));
 
-	table_context->software_shutdown_temp = powerplay_table->usSoftwareShutdownTemp;
 	table_context->thermal_controller_type = powerplay_table->ucThermalControllerType;
 	table_context->TDPODLimit = le32_to_cpu(powerplay_table->OverDrive8Table.ODSettingsMax[ATOM_VEGA20_ODSETTING_POWERPERCENTAGE]);
 
@@ -3252,35 +3251,24 @@ static int vega20_set_watermarks_table(struct smu_context *smu,
 	return 0;
 }
 
-static const struct smu_temperature_range vega20_thermal_policy[] =
-{
-	{-273150,  99000, 99000, -273150, 99000, 99000, -273150, 99000, 99000},
-	{ 120000, 120000, 120000, 120000, 120000, 120000, 120000, 120000, 120000},
-};
-
 static int vega20_get_thermal_temperature_range(struct smu_context *smu,
 						struct smu_temperature_range *range)
 {
-
+	struct smu_table_context *table_context = &smu->smu_table;
+	ATOM_Vega20_POWERPLAYTABLE *powerplay_table = table_context->power_play_table;
 	PPTable_t *pptable = smu->smu_table.driver_pptable;
 
-	if (!range)
+	if (!range || !powerplay_table)
 		return -EINVAL;
 
-	memcpy(range, &vega20_thermal_policy[0], sizeof(struct smu_temperature_range));
-
-	range->max = pptable->TedgeLimit *
-		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
-	range->edge_emergency_max = (pptable->TedgeLimit + CTF_OFFSET_EDGE) *
-		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
-	range->hotspot_crit_max = pptable->ThotspotLimit *
-		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
-	range->hotspot_emergency_max = (pptable->ThotspotLimit + CTF_OFFSET_HOTSPOT) *
-		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
-	range->mem_crit_max = pptable->ThbmLimit *
-		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
-	range->mem_emergency_max = (pptable->ThbmLimit + CTF_OFFSET_HBM)*
-		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
+	/* The unit is temperature */
+	range->min = 0;
+	range->max = powerplay_table->usSoftwareShutdownTemp;
+	range->edge_emergency_max = (pptable->TedgeLimit + CTF_OFFSET_EDGE);
+	range->hotspot_crit_max = pptable->ThotspotLimit;
+	range->hotspot_emergency_max = (pptable->ThotspotLimit + CTF_OFFSET_HOTSPOT);
+	range->mem_crit_max = pptable->ThbmLimit;
+	range->mem_emergency_max = (pptable->ThbmLimit + CTF_OFFSET_HBM);
 
 
 	return 0;

commit 95ccc155081be9cea95202d290fe06637f47c8de
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Thu Jul 18 15:25:04 2019 -0500

    drm/amdgpu/smu: move fan rpm query into the asic specific code
    
    On vega20, there is an SMU message to query it.  On navi, it's fetched
    from the metrics table.
    
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index afcd33941f07..03e310426ffb 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3033,6 +3033,23 @@ static int vega20_set_thermal_fan_table(struct smu_context *smu)
 	return ret;
 }
 
+static int vega20_get_fan_speed_rpm(struct smu_context *smu,
+				    uint32_t *speed)
+{
+	int ret;
+
+	ret = smu_send_smc_msg(smu, SMU_MSG_GetCurrentRpm);
+
+	if (ret) {
+		pr_err("Attempt to get current RPM from SMC Failed!\n");
+		return ret;
+	}
+
+	smu_read_smc_arg(smu, speed);
+
+	return 0;
+}
+
 static int vega20_get_fan_speed_percent(struct smu_context *smu,
 					uint32_t *speed)
 {
@@ -3040,7 +3057,7 @@ static int vega20_get_fan_speed_percent(struct smu_context *smu,
 	uint32_t current_rpm = 0, percent = 0;
 	PPTable_t *pptable = smu->smu_table.driver_pptable;
 
-	ret = smu_get_current_rpm(smu, &current_rpm);
+	ret = vega20_get_fan_speed_rpm(smu, &current_rpm);
 	if (ret)
 		return ret;
 
@@ -3311,6 +3328,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.is_dpm_running = vega20_is_dpm_running,
 	.set_thermal_fan_table = vega20_set_thermal_fan_table,
 	.get_fan_speed_percent = vega20_get_fan_speed_percent,
+	.get_fan_speed_rpm = vega20_get_fan_speed_rpm,
 	.set_watermarks_table = vega20_set_watermarks_table,
 	.get_thermal_temperature_range = vega20_get_thermal_temperature_range
 };

commit b629167d686787507f35a8bfb46b8b12f4f26eb7
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Fri Jul 19 16:06:29 2019 +0800

    drm/amd/powerplay: remove redundancy debug log in smu
    
    remove redundacy debug log in smu.
    eg:
    [ 6897.969447] amdgpu: [powerplay] smu 11 clk dpm feature 1 is not enabled
    [ 6897.969448] amdgpu: [powerplay] smu 11 clk dpm feature 1 is not enabled
    [ 6897.969448] amdgpu: [powerplay] smu 11 clk dpm feature 1 is not enabled
    [ 6899.024114] amdgpu: [powerplay] Unsupported SMU message: 38
    [ 6899.024151] amdgpu: [powerplay] smu 11 clk dpm feature 1 is not enabled
    [ 6899.024151] amdgpu: [powerplay] smu 11 clk dpm feature 1 is not enabled
    [ 6899.024152] amdgpu: [powerplay] smu 11 clk dpm feature 1 is not enabled
    [ 6900.078296] amdgpu: [powerplay] Unsupported SMU message: 38
    [ 6900.078332] amdgpu: [powerplay] smu 11 clk dpm feature 1 is not enabled
    [ 6900.078332] amdgpu: [powerplay] smu 11 clk dpm feature 1 is not enabled
    [ 6900.078333] amdgpu: [powerplay] smu 11 clk dpm feature 1 is not enabled
    [ 6901.133230] amdgpu: [powerplay] Unsupported SMU message: 38
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Kenneth Feng <kenneth.feng@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 080956ea0570..afcd33941f07 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -232,7 +232,6 @@ static int vega20_get_smu_table_index(struct smu_context *smc, uint32_t index)
 
 	mapping = vega20_table_map[index];
 	if (!(mapping.valid_mapping)) {
-		pr_warn("Unsupported SMU table: %d\n", index);
 		return -EINVAL;
 	}
 
@@ -248,7 +247,6 @@ static int vega20_get_pwr_src_index(struct smu_context *smc, uint32_t index)
 
 	mapping = vega20_pwr_src_map[index];
 	if (!(mapping.valid_mapping)) {
-		pr_warn("Unsupported power source: %d\n", index);
 		return -EINVAL;
 	}
 
@@ -264,7 +262,6 @@ static int vega20_get_smu_feature_index(struct smu_context *smc, uint32_t index)
 
 	mapping = vega20_feature_mask_map[index];
 	if (!(mapping.valid_mapping)) {
-		pr_warn("Unsupported SMU feature: %d\n", index);
 		return -EINVAL;
 	}
 
@@ -280,7 +277,6 @@ static int vega20_get_smu_clk_index(struct smu_context *smc, uint32_t index)
 
 	mapping = vega20_clk_map[index];
 	if (!(mapping.valid_mapping)) {
-		pr_warn("Unsupported SMU clock: %d\n", index);
 		return -EINVAL;
 	}
 
@@ -296,7 +292,6 @@ static int vega20_get_smu_msg_index(struct smu_context *smc, uint32_t index)
 
 	mapping = vega20_message_map[index];
 	if (!(mapping.valid_mapping)) {
-		pr_warn("Unsupported SMU message: %d\n", index);
 		return -EINVAL;
 	}
 
@@ -312,7 +307,6 @@ static int vega20_get_workload_type(struct smu_context *smu, enum PP_SMC_POWER_P
 
 	mapping = vega20_workload_map[profile];
 	if (!(mapping.valid_mapping)) {
-		pr_warn("Unsupported SMU workload: %d\n", (int)profile);
 		return -EINVAL;
 	}
 

commit c06403045aad6ae2edd935f6309e0c72e118c6de
Author: Evan Quan <evan.quan@amd.com>
Date:   Thu Jul 11 14:36:44 2019 +0800

    drm/amd/powerplay: input check for unsupported message/clock index
    
    This can avoid them to be handled in a wrong way without notice.
    Since not all SMU messages/clocks are supported on every SMU11 ASIC.
    
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Reviewed-by: Feifei Xu <Feifei.Xu@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index af54fee0aed2..080956ea0570 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -231,8 +231,10 @@ static int vega20_get_smu_table_index(struct smu_context *smc, uint32_t index)
 		return -EINVAL;
 
 	mapping = vega20_table_map[index];
-	if (!(mapping.valid_mapping))
+	if (!(mapping.valid_mapping)) {
+		pr_warn("Unsupported SMU table: %d\n", index);
 		return -EINVAL;
+	}
 
 	return mapping.map_to;
 }
@@ -245,8 +247,10 @@ static int vega20_get_pwr_src_index(struct smu_context *smc, uint32_t index)
 		return -EINVAL;
 
 	mapping = vega20_pwr_src_map[index];
-	if (!(mapping.valid_mapping))
+	if (!(mapping.valid_mapping)) {
+		pr_warn("Unsupported power source: %d\n", index);
 		return -EINVAL;
+	}
 
 	return mapping.map_to;
 }
@@ -259,8 +263,10 @@ static int vega20_get_smu_feature_index(struct smu_context *smc, uint32_t index)
 		return -EINVAL;
 
 	mapping = vega20_feature_mask_map[index];
-	if (!(mapping.valid_mapping))
+	if (!(mapping.valid_mapping)) {
+		pr_warn("Unsupported SMU feature: %d\n", index);
 		return -EINVAL;
+	}
 
 	return mapping.map_to;
 }
@@ -273,8 +279,10 @@ static int vega20_get_smu_clk_index(struct smu_context *smc, uint32_t index)
 		return -EINVAL;
 
 	mapping = vega20_clk_map[index];
-	if (!(mapping.valid_mapping))
+	if (!(mapping.valid_mapping)) {
+		pr_warn("Unsupported SMU clock: %d\n", index);
 		return -EINVAL;
+	}
 
 	return mapping.map_to;
 }
@@ -287,8 +295,10 @@ static int vega20_get_smu_msg_index(struct smu_context *smc, uint32_t index)
 		return -EINVAL;
 
 	mapping = vega20_message_map[index];
-	if (!(mapping.valid_mapping))
+	if (!(mapping.valid_mapping)) {
+		pr_warn("Unsupported SMU message: %d\n", index);
 		return -EINVAL;
+	}
 
 	return mapping.map_to;
 }
@@ -301,8 +311,10 @@ static int vega20_get_workload_type(struct smu_context *smu, enum PP_SMC_POWER_P
 		return -EINVAL;
 
 	mapping = vega20_workload_map[profile];
-	if (!(mapping.valid_mapping))
+	if (!(mapping.valid_mapping)) {
+		pr_warn("Unsupported SMU workload: %d\n", (int)profile);
 		return -EINVAL;
+	}
 
 	return mapping.map_to;
 }
@@ -1778,7 +1790,7 @@ static int vega20_get_power_profile_mode(struct smu_context *smu, char *buf)
 {
 	DpmActivityMonitorCoeffInt_t activity_monitor;
 	uint32_t i, size = 0;
-	uint16_t workload_type = 0;
+	int16_t workload_type = 0;
 	static const char *profile_name[] = {
 					"BOOTUP_DEFAULT",
 					"3D_FULL_SCREEN",
@@ -1811,6 +1823,9 @@ static int vega20_get_power_profile_mode(struct smu_context *smu, char *buf)
 	for (i = 0; i <= PP_SMC_POWER_PROFILE_CUSTOM; i++) {
 		/* conv PP_SMC_POWER_PROFILE* to WORKLOAD_PPLIB_*_BIT */
 		workload_type = smu_workload_get_type(smu, i);
+		if (workload_type < 0)
+			return -EINVAL;
+
 		result = smu_update_table(smu,
 					  SMU_TABLE_ACTIVITY_MONITOR_COEFF, workload_type,
 					  (void *)(&activity_monitor), false);
@@ -1963,6 +1978,8 @@ static int vega20_set_power_profile_mode(struct smu_context *smu, long *input, u
 
 	/* conv PP_SMC_POWER_PROFILE* to WORKLOAD_PPLIB_*_BIT */
 	workload_type = smu_workload_get_type(smu, smu->power_profile_mode);
+	if (workload_type < 0)
+		return -EINVAL;
 	smu_send_smc_msg_with_param(smu, SMU_MSG_SetWorkloadMask,
 				    1 << workload_type);
 

commit 7e01a2ec96bf8a149c5e83d0352cf6ea286275cf
Author: Evan Quan <evan.quan@amd.com>
Date:   Thu Jul 11 10:23:17 2019 +0800

    drm/amd/powerplay: correct SW SMU valid mapping check
    
    Current implementation is not actually able to detect
    invalid message/table/workload mapping.
    
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Reviewed-by: Feifei Xu <Feifei.Xu@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index bb9bb09cfc7a..af54fee0aed2 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -47,7 +47,7 @@
 #define CTF_OFFSET_HBM			5
 
 #define MSG_MAP(msg) \
-	[SMU_MSG_##msg] = PPSMC_MSG_##msg
+	[SMU_MSG_##msg] = {1, PPSMC_MSG_##msg}
 
 #define SMC_DPM_FEATURE (FEATURE_DPM_PREFETCHER_MASK | \
 			 FEATURE_DPM_GFXCLK_MASK | \
@@ -59,7 +59,7 @@
 			 FEATURE_DPM_LINK_MASK | \
 			 FEATURE_DPM_DCEFCLK_MASK)
 
-static int vega20_message_map[SMU_MSG_MAX_COUNT] = {
+static struct smu_11_0_cmn2aisc_mapping vega20_message_map[SMU_MSG_MAX_COUNT] = {
 	MSG_MAP(TestMessage),
 	MSG_MAP(GetSmuVersion),
 	MSG_MAP(GetDriverIfVersion),
@@ -145,7 +145,7 @@ static int vega20_message_map[SMU_MSG_MAX_COUNT] = {
 	MSG_MAP(GetAVFSVoltageByDpm),
 };
 
-static int vega20_clk_map[SMU_CLK_COUNT] = {
+static struct smu_11_0_cmn2aisc_mapping vega20_clk_map[SMU_CLK_COUNT] = {
 	CLK_MAP(GFXCLK, PPCLK_GFXCLK),
 	CLK_MAP(VCLK, PPCLK_VCLK),
 	CLK_MAP(DCLK, PPCLK_DCLK),
@@ -159,7 +159,7 @@ static int vega20_clk_map[SMU_CLK_COUNT] = {
 	CLK_MAP(FCLK, PPCLK_FCLK),
 };
 
-static int vega20_feature_mask_map[SMU_FEATURE_COUNT] = {
+static struct smu_11_0_cmn2aisc_mapping vega20_feature_mask_map[SMU_FEATURE_COUNT] = {
 	FEA_MAP(DPM_PREFETCHER),
 	FEA_MAP(DPM_GFXCLK),
 	FEA_MAP(DPM_UCLK),
@@ -195,7 +195,7 @@ static int vega20_feature_mask_map[SMU_FEATURE_COUNT] = {
 	FEA_MAP(XGMI),
 };
 
-static int vega20_table_map[SMU_TABLE_COUNT] = {
+static struct smu_11_0_cmn2aisc_mapping vega20_table_map[SMU_TABLE_COUNT] = {
 	TAB_MAP(PPTABLE),
 	TAB_MAP(WATERMARKS),
 	TAB_MAP(AVFS),
@@ -208,12 +208,12 @@ static int vega20_table_map[SMU_TABLE_COUNT] = {
 	TAB_MAP(OVERDRIVE),
 };
 
-static int vega20_pwr_src_map[SMU_POWER_SOURCE_COUNT] = {
+static struct smu_11_0_cmn2aisc_mapping vega20_pwr_src_map[SMU_POWER_SOURCE_COUNT] = {
 	PWR_MAP(AC),
 	PWR_MAP(DC),
 };
 
-static int vega20_workload_map[] = {
+static struct smu_11_0_cmn2aisc_mapping vega20_workload_map[PP_SMC_POWER_PROFILE_COUNT] = {
 	WORKLOAD_MAP(PP_SMC_POWER_PROFILE_BOOTUP_DEFAULT,	WORKLOAD_DEFAULT_BIT),
 	WORKLOAD_MAP(PP_SMC_POWER_PROFILE_FULLSCREEN3D,		WORKLOAD_PPLIB_FULL_SCREEN_3D_BIT),
 	WORKLOAD_MAP(PP_SMC_POWER_PROFILE_POWERSAVING,		WORKLOAD_PPLIB_POWER_SAVING_BIT),
@@ -225,79 +225,86 @@ static int vega20_workload_map[] = {
 
 static int vega20_get_smu_table_index(struct smu_context *smc, uint32_t index)
 {
-	int val;
+	struct smu_11_0_cmn2aisc_mapping mapping;
+
 	if (index >= SMU_TABLE_COUNT)
 		return -EINVAL;
 
-	val = vega20_table_map[index];
-	if (val >= TABLE_COUNT)
+	mapping = vega20_table_map[index];
+	if (!(mapping.valid_mapping))
 		return -EINVAL;
 
-	return val;
+	return mapping.map_to;
 }
 
 static int vega20_get_pwr_src_index(struct smu_context *smc, uint32_t index)
 {
-	int val;
+	struct smu_11_0_cmn2aisc_mapping mapping;
+
 	if (index >= SMU_POWER_SOURCE_COUNT)
 		return -EINVAL;
 
-	val = vega20_pwr_src_map[index];
-	if (val >= POWER_SOURCE_COUNT)
+	mapping = vega20_pwr_src_map[index];
+	if (!(mapping.valid_mapping))
 		return -EINVAL;
 
-	return val;
+	return mapping.map_to;
 }
 
 static int vega20_get_smu_feature_index(struct smu_context *smc, uint32_t index)
 {
-	int val;
+	struct smu_11_0_cmn2aisc_mapping mapping;
+
 	if (index >= SMU_FEATURE_COUNT)
 		return -EINVAL;
 
-	val = vega20_feature_mask_map[index];
-	if (val > 64)
+	mapping = vega20_feature_mask_map[index];
+	if (!(mapping.valid_mapping))
 		return -EINVAL;
 
-	return val;
+	return mapping.map_to;
 }
 
 static int vega20_get_smu_clk_index(struct smu_context *smc, uint32_t index)
 {
-	int val;
+	struct smu_11_0_cmn2aisc_mapping mapping;
+
 	if (index >= SMU_CLK_COUNT)
 		return -EINVAL;
 
-	val = vega20_clk_map[index];
-	if (val >= PPCLK_COUNT)
+	mapping = vega20_clk_map[index];
+	if (!(mapping.valid_mapping))
 		return -EINVAL;
 
-	return val;
+	return mapping.map_to;
 }
 
 static int vega20_get_smu_msg_index(struct smu_context *smc, uint32_t index)
 {
-	int val;
+	struct smu_11_0_cmn2aisc_mapping mapping;
 
 	if (index >= SMU_MSG_MAX_COUNT)
 		return -EINVAL;
 
-	val = vega20_message_map[index];
-	if (val > PPSMC_Message_Count)
+	mapping = vega20_message_map[index];
+	if (!(mapping.valid_mapping))
 		return -EINVAL;
 
-	return val;
+	return mapping.map_to;
 }
 
 static int vega20_get_workload_type(struct smu_context *smu, enum PP_SMC_POWER_PROFILE profile)
 {
-	int val;
+	struct smu_11_0_cmn2aisc_mapping mapping;
+
 	if (profile > PP_SMC_POWER_PROFILE_CUSTOM)
 		return -EINVAL;
 
-	val = vega20_workload_map[profile];
+	mapping = vega20_workload_map[profile];
+	if (!(mapping.valid_mapping))
+		return -EINVAL;
 
-	return val;
+	return mapping.map_to;
 }
 
 static int vega20_tables_init(struct smu_context *smu, struct smu_table *tables)

commit 0d9d78b57bf32fdc4baf6eb8853e65059dcd5e06
Author: Evan Quan <evan.quan@amd.com>
Date:   Thu Jul 11 15:13:17 2019 +0800

    drm/amd/powerplay: correct smu_update_table usage
    
    The interface was used in a confusing way. In profile mode scenario,
    the 2nd parameter of the interface was used in a different way from
    other scenarios.
    
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 6d267aeacda3..bb9bb09cfc7a 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1680,7 +1680,7 @@ static int vega20_get_metrics_table(struct smu_context *smu,
 	int ret = 0;
 
 	if (!smu_table->metrics_time || time_after(jiffies, smu_table->metrics_time + HZ / 1000)) {
-		ret = smu_update_table(smu, SMU_TABLE_SMU_METRICS,
+		ret = smu_update_table(smu, SMU_TABLE_SMU_METRICS, 0,
 				(void *)smu_table->metrics_table, false);
 		if (ret) {
 			pr_info("Failed to export SMU metrics table!\n");
@@ -1709,7 +1709,7 @@ static int vega20_set_default_od_settings(struct smu_context *smu,
 		if (!table_context->overdrive_table)
 			return -ENOMEM;
 
-		ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE,
+		ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE, 0,
 				       table_context->overdrive_table, false);
 		if (ret) {
 			pr_err("Failed to export over drive table!\n");
@@ -1721,7 +1721,7 @@ static int vega20_set_default_od_settings(struct smu_context *smu,
 			return ret;
 	}
 
-	ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE,
+	ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE, 0,
 			       table_context->overdrive_table, true);
 	if (ret) {
 		pr_err("Failed to import over drive table!\n");
@@ -1805,7 +1805,7 @@ static int vega20_get_power_profile_mode(struct smu_context *smu, char *buf)
 		/* conv PP_SMC_POWER_PROFILE* to WORKLOAD_PPLIB_*_BIT */
 		workload_type = smu_workload_get_type(smu, i);
 		result = smu_update_table(smu,
-					  SMU_TABLE_ACTIVITY_MONITOR_COEFF | workload_type << 16,
+					  SMU_TABLE_ACTIVITY_MONITOR_COEFF, workload_type,
 					  (void *)(&activity_monitor), false);
 		if (result) {
 			pr_err("[%s] Failed to get activity monitor!", __func__);
@@ -1891,7 +1891,7 @@ static int vega20_set_power_profile_mode(struct smu_context *smu, long *input, u
 
 	if (smu->power_profile_mode == PP_SMC_POWER_PROFILE_CUSTOM) {
 		ret = smu_update_table(smu,
-				       SMU_TABLE_ACTIVITY_MONITOR_COEFF | WORKLOAD_PPLIB_CUSTOM_BIT << 16,
+				       SMU_TABLE_ACTIVITY_MONITOR_COEFF, WORKLOAD_PPLIB_CUSTOM_BIT,
 				       (void *)(&activity_monitor), false);
 		if (ret) {
 			pr_err("[%s] Failed to get activity monitor!", __func__);
@@ -1946,7 +1946,7 @@ static int vega20_set_power_profile_mode(struct smu_context *smu, long *input, u
 		}
 
 		ret = smu_update_table(smu,
-				       SMU_TABLE_ACTIVITY_MONITOR_COEFF | WORKLOAD_PPLIB_CUSTOM_BIT << 16,
+				       SMU_TABLE_ACTIVITY_MONITOR_COEFF, WORKLOAD_PPLIB_CUSTOM_BIT,
 				       (void *)(&activity_monitor), true);
 		if (ret) {
 			pr_err("[%s] Failed to set activity monitor!", __func__);
@@ -2495,7 +2495,7 @@ static int vega20_update_od8_settings(struct smu_context *smu,
 	struct smu_table_context *table_context = &smu->smu_table;
 	int ret;
 
-	ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE,
+	ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE, 0,
 			       table_context->overdrive_table, false);
 	if (ret) {
 		pr_err("Failed to export over drive table!\n");
@@ -2506,7 +2506,7 @@ static int vega20_update_od8_settings(struct smu_context *smu,
 	if (ret)
 		return ret;
 
-	ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE,
+	ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE, 0,
 			       table_context->overdrive_table, true);
 	if (ret) {
 		pr_err("Failed to import over drive table!\n");
@@ -2770,7 +2770,7 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 		break;
 
 	case PP_OD_RESTORE_DEFAULT_TABLE:
-		ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE, table_context->overdrive_table, false);
+		ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE, 0, table_context->overdrive_table, false);
 		if (ret) {
 			pr_err("Failed to export over drive table!\n");
 			return ret;
@@ -2779,7 +2779,7 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 		break;
 
 	case PP_OD_COMMIT_DPM_TABLE:
-		ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE, table_context->overdrive_table, true);
+		ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE, 0, table_context->overdrive_table, true);
 		if (ret) {
 			pr_err("Failed to import over drive table!\n");
 			return ret;

commit 7ef65bbd01fd59b749e8bd5b19d0c01e315fef8d
Author: Evan Quan <evan.quan@amd.com>
Date:   Fri Jul 12 10:32:02 2019 +0800

    drm/amd/powerplay: avoid access before allocation
    
    No access before allocation.
    
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Reviewed-by: Feifei Xu <Feifei.Xu@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 3c605257b89c..6d267aeacda3 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -441,7 +441,6 @@ static int vega20_store_powerplay_table(struct smu_context *smu)
 {
 	ATOM_Vega20_POWERPLAYTABLE *powerplay_table = NULL;
 	struct smu_table_context *table_context = &smu->smu_table;
-	int ret;
 
 	if (!table_context->power_play_table)
 		return -EINVAL;
@@ -455,9 +454,7 @@ static int vega20_store_powerplay_table(struct smu_context *smu)
 	table_context->thermal_controller_type = powerplay_table->ucThermalControllerType;
 	table_context->TDPODLimit = le32_to_cpu(powerplay_table->OverDrive8Table.ODSettingsMax[ATOM_VEGA20_ODSETTING_POWERPERCENTAGE]);
 
-	ret = vega20_setup_od8_information(smu);
-
-	return ret;
+	return 0;
 }
 
 static int vega20_append_powerplay_table(struct smu_context *smu)
@@ -1507,6 +1504,12 @@ static int vega20_set_default_od8_setttings(struct smu_context *smu)
 
 	smu->od_settings = (void *)od8_settings;
 
+	ret = vega20_setup_od8_information(smu);
+	if (ret) {
+		pr_err("Retrieve board OD limits failed!\n");
+		return ret;
+	}
+
 	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_SOCCLK_BIT)) {
 		if (od8_settings->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_GFXCLK_LIMITS] &&
 		    od8_settings->od_settings_max[OD8_SETTING_GFXCLK_FMAX] > 0 &&

commit 366cf03ec00f18e802f304c2cc057cac842e1244
Author: Evan Quan <evan.quan@amd.com>
Date:   Fri Jul 12 10:07:31 2019 +0800

    drm/amd/powerplay: fix memory allocation failure check V2
    
    Fix memory allocation failure check.
    
    - V2: fix one more similar error
    
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 9204e4e50d09..3c605257b89c 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -319,7 +319,7 @@ static int vega20_tables_init(struct smu_context *smu, struct smu_table *tables)
 	               AMDGPU_GEM_DOMAIN_VRAM);
 
 	smu_table->metrics_table = kzalloc(sizeof(SmuMetrics_t), GFP_KERNEL);
-	if (smu_table->metrics_table)
+	if (!smu_table->metrics_table)
 		return -ENOMEM;
 	smu_table->metrics_time = 0;
 
@@ -1502,7 +1502,7 @@ static int vega20_set_default_od8_setttings(struct smu_context *smu)
 
 	od8_settings = kzalloc(sizeof(struct vega20_od8_settings), GFP_KERNEL);
 
-	if (od8_settings)
+	if (!od8_settings)
 		return -ENOMEM;
 
 	smu->od_settings = (void *)od8_settings;

commit d72e04d97efdd518514018bf96169bf68922eed6
Author: Nathan Chancellor <natechancellor@gmail.com>
Date:   Wed Jul 3 22:52:17 2019 -0700

    drm/amd/powerplay: Use proper enums in vega20_print_clk_levels
    
    clang warns:
    
    drivers/gpu/drm/amd/amdgpu/../powerplay/vega20_ppt.c:995:39: warning:
    implicit conversion from enumeration type 'PPCLK_e' to different
    enumeration type 'enum smu_clk_type' [-Wenum-conversion]
                    ret = smu_get_current_clk_freq(smu, PPCLK_SOCCLK, &now);
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~
    drivers/gpu/drm/amd/amdgpu/../powerplay/vega20_ppt.c:1016:39: warning:
    implicit conversion from enumeration type 'PPCLK_e' to different
    enumeration type 'enum smu_clk_type' [-Wenum-conversion]
                    ret = smu_get_current_clk_freq(smu, PPCLK_FCLK, &now);
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~
    drivers/gpu/drm/amd/amdgpu/../powerplay/vega20_ppt.c:1031:39: warning:
    implicit conversion from enumeration type 'PPCLK_e' to different
    enumeration type 'enum smu_clk_type' [-Wenum-conversion]
                    ret = smu_get_current_clk_freq(smu, PPCLK_DCEFCLK, &now);
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~
    
    The values are mapped one to one in vega20_get_smu_clk_index so just use
    the proper enums here.
    
    Fixes: 096761014227 ("drm/amd/powerplay: support sysfs to get socclk, fclk, dcefclk")
    Link: https://github.com/ClangBuiltLinux/linux/issues/587
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index a76a22a18eb4..9204e4e50d09 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -992,7 +992,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 		break;
 
 	case SMU_SOCCLK:
-		ret = smu_get_current_clk_freq(smu, PPCLK_SOCCLK, &now);
+		ret = smu_get_current_clk_freq(smu, SMU_SOCCLK, &now);
 		if (ret) {
 			pr_err("Attempt to get current socclk Failed!");
 			return ret;
@@ -1013,7 +1013,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 		break;
 
 	case SMU_FCLK:
-		ret = smu_get_current_clk_freq(smu, PPCLK_FCLK, &now);
+		ret = smu_get_current_clk_freq(smu, SMU_FCLK, &now);
 		if (ret) {
 			pr_err("Attempt to get current fclk Failed!");
 			return ret;
@@ -1028,7 +1028,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 		break;
 
 	case SMU_DCEFCLK:
-		ret = smu_get_current_clk_freq(smu, PPCLK_DCEFCLK, &now);
+		ret = smu_get_current_clk_freq(smu, SMU_DCEFCLK, &now);
 		if (ret) {
 			pr_err("Attempt to get current dcefclk Failed!");
 			return ret;

commit de48ebdd5b0a582f870778271ad9dbfa663d65cc
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Jul 8 16:07:59 2019 +0200

    drm/amd/powerplay: vega20: fix uninitialized variable use
    
    If smu_get_current_rpm() fails, we can't use the output,
    as that may be uninitialized:
    
    drivers/gpu/drm/amd/amdgpu/../powerplay/vega20_ppt.c:3023:8: error: variable 'current_rpm' is used uninitialized whenever '?:' condition is false [-Werror,-Wsometimes-uninitialized]
            ret = smu_get_current_rpm(smu, &current_rpm);
                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    drivers/gpu/drm/amd/amdgpu/../powerplay/inc/amdgpu_smu.h:735:3: note: expanded from macro 'smu_get_current_rpm'
            ((smu)->funcs->get_current_rpm ? (smu)->funcs->get_current_rpm((smu), (speed)) : 0)
             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    drivers/gpu/drm/amd/amdgpu/../powerplay/vega20_ppt.c:3024:12: note: uninitialized use occurs here
            percent = current_rpm * 100 / pptable->FanMaximumRpm;
                      ^~~~~~~~~~~
    drivers/gpu/drm/amd/amdgpu/../powerplay/vega20_ppt.c:3023:8: note: remove the '?:' if its condition is always true
            ret = smu_get_current_rpm(smu, &current_rpm);
                  ^
    drivers/gpu/drm/amd/amdgpu/../powerplay/inc/amdgpu_smu.h:735:3: note: expanded from macro 'smu_get_current_rpm'
            ((smu)->funcs->get_current_rpm ? (smu)->funcs->get_current_rpm((smu), (speed)) : 0)
             ^
    drivers/gpu/drm/amd/amdgpu/../powerplay/vega20_ppt.c:3020:22: note: initialize the variable 'current_rpm' to silence this warning
            uint32_t current_rpm;
    
    Propagate the error code in that case.
    
    Fixes: ee0db82027ee ("drm/amd/powerplay: move PPTable_t uses into asic level")
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 3d8938854aa7..a76a22a18eb4 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3020,10 +3020,13 @@ static int vega20_get_fan_speed_percent(struct smu_context *smu,
 	PPTable_t *pptable = smu->smu_table.driver_pptable;
 
 	ret = smu_get_current_rpm(smu, &current_rpm);
+	if (ret)
+		return ret;
+
 	percent = current_rpm * 100 / pptable->FanMaximumRpm;
 	*speed = percent > 100 ? 100 : percent;
 
-	return ret;
+	return 0;
 }
 
 static int vega20_get_gpu_power(struct smu_context *smu, uint32_t *value)

commit 985863d00a8feb597a38df38f8fc2f70e980156f
Author: Nathan Chancellor <natechancellor@gmail.com>
Date:   Wed Jul 3 22:52:18 2019 -0700

    drm/amd/powerplay: Zero initialize current_rpm in vega20_get_fan_speed_percent
    
    clang warns (trimmed for brevity):
    
    drivers/gpu/drm/amd/amdgpu/../powerplay/vega20_ppt.c:3023:8: warning:
    variable 'current_rpm' is used uninitialized whenever '?:' condition is
    false [-Wsometimes-uninitialized]
            ret = smu_get_current_rpm(smu, &current_rpm);
                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    
    smu_get_current_rpm expands to a ternary operator conditional on
    smu->funcs->get_current_rpm being not NULL. When this is false,
    current_rpm will be uninitialized. Zero initialize current_rpm to
    avoid using random stack values if that ever happens.
    
    Fixes: ee0db82027ee ("drm/amd/powerplay: move PPTable_t uses into asic level")
    Link: https://github.com/ClangBuiltLinux/linux/issues/588
    Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 0f14fe14ecd8..3d8938854aa7 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3016,8 +3016,7 @@ static int vega20_get_fan_speed_percent(struct smu_context *smu,
 					uint32_t *speed)
 {
 	int ret = 0;
-	uint32_t percent = 0;
-	uint32_t current_rpm;
+	uint32_t current_rpm = 0, percent = 0;
 	PPTable_t *pptable = smu->smu_table.driver_pptable;
 
 	ret = smu_get_current_rpm(smu, &current_rpm);

commit 44ff0ae6b15e78565199a4c295de2a5bac425922
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Tue Jun 25 08:48:15 2019 -0500

    drm/amdgpu/powerplay: FEATURE_MASK is 64 bit so use ULL
    
    ULL is needed for 32 bit arches.
    
    Reviewed-by: Nicholas Kazlauskas <nicholas.kazlauskas@amd.com>
    Reviewed-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 2fc4e2a6fd82..0f14fe14ecd8 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -576,7 +576,7 @@ static int vega20_run_btc_afll(struct smu_context *smu)
 	return smu_send_smc_msg(smu, SMU_MSG_RunAfllBtc);
 }
 
-#define FEATURE_MASK(feature) (1UL << feature)
+#define FEATURE_MASK(feature) (1ULL << feature)
 static int
 vega20_get_allowed_feature_mask(struct smu_context *smu,
 				  uint32_t *feature_mask, uint32_t num)

commit 591745854893330adc3bd44389045ba0011f6efe
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Thu May 30 00:51:44 2019 -0500

    drm/amdgpu/powerplay/vega20: use correct table index
    
    Use the SMU_* variant so we look up the correct index.
    
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index ea744447e604..2fc4e2a6fd82 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1802,7 +1802,7 @@ static int vega20_get_power_profile_mode(struct smu_context *smu, char *buf)
 		/* conv PP_SMC_POWER_PROFILE* to WORKLOAD_PPLIB_*_BIT */
 		workload_type = smu_workload_get_type(smu, i);
 		result = smu_update_table(smu,
-					  TABLE_ACTIVITY_MONITOR_COEFF | workload_type << 16,
+					  SMU_TABLE_ACTIVITY_MONITOR_COEFF | workload_type << 16,
 					  (void *)(&activity_monitor), false);
 		if (result) {
 			pr_err("[%s] Failed to get activity monitor!", __func__);
@@ -1888,7 +1888,7 @@ static int vega20_set_power_profile_mode(struct smu_context *smu, long *input, u
 
 	if (smu->power_profile_mode == PP_SMC_POWER_PROFILE_CUSTOM) {
 		ret = smu_update_table(smu,
-				       TABLE_ACTIVITY_MONITOR_COEFF | WORKLOAD_PPLIB_CUSTOM_BIT << 16,
+				       SMU_TABLE_ACTIVITY_MONITOR_COEFF | WORKLOAD_PPLIB_CUSTOM_BIT << 16,
 				       (void *)(&activity_monitor), false);
 		if (ret) {
 			pr_err("[%s] Failed to get activity monitor!", __func__);
@@ -1943,7 +1943,7 @@ static int vega20_set_power_profile_mode(struct smu_context *smu, long *input, u
 		}
 
 		ret = smu_update_table(smu,
-				       TABLE_ACTIVITY_MONITOR_COEFF | WORKLOAD_PPLIB_CUSTOM_BIT << 16,
+				       SMU_TABLE_ACTIVITY_MONITOR_COEFF | WORKLOAD_PPLIB_CUSTOM_BIT << 16,
 				       (void *)(&activity_monitor), true);
 		if (ret) {
 			pr_err("[%s] Failed to set activity monitor!", __func__);
@@ -2767,7 +2767,7 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 		break;
 
 	case PP_OD_RESTORE_DEFAULT_TABLE:
-		ret = smu_update_table(smu, TABLE_OVERDRIVE, table_context->overdrive_table, false);
+		ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE, table_context->overdrive_table, false);
 		if (ret) {
 			pr_err("Failed to export over drive table!\n");
 			return ret;
@@ -2776,7 +2776,7 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 		break;
 
 	case PP_OD_COMMIT_DPM_TABLE:
-		ret = smu_update_table(smu, TABLE_OVERDRIVE, table_context->overdrive_table, true);
+		ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE, table_context->overdrive_table, true);
 		if (ret) {
 			pr_err("Failed to import over drive table!\n");
 			return ret;

commit 0c83d32c565c9f40cb686df5ad65ade8ec85a876
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Mon Jun 17 13:17:27 2019 -0500

    drm/amd/powerplay: simplified od_settings for each asic
    
    the od_settings is asic related data, so move it to asic file.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 33634f3b7fae..ea744447e604 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -365,6 +365,7 @@ static int vega20_setup_od8_information(struct smu_context *smu)
 {
 	ATOM_Vega20_POWERPLAYTABLE *powerplay_table = NULL;
 	struct smu_table_context *table_context = &smu->smu_table;
+	struct vega20_od8_settings *od8_settings = (struct vega20_od8_settings *)smu->od_settings;
 
 	uint32_t od_feature_count, od_feature_array_size,
 		 od_setting_count, od_setting_array_size;
@@ -385,13 +386,13 @@ static int vega20_setup_od8_information(struct smu_context *smu)
 
 		od_feature_array_size = sizeof(uint8_t) * od_feature_count;
 
-		if (table_context->od_feature_capabilities)
+		if (od8_settings->od_feature_capabilities)
 			return -EINVAL;
 
-		table_context->od_feature_capabilities = kmemdup(&powerplay_table->OverDrive8Table.ODFeatureCapabilities,
+		od8_settings->od_feature_capabilities = kmemdup(&powerplay_table->OverDrive8Table.ODFeatureCapabilities,
 								 od_feature_array_size,
 								 GFP_KERNEL);
-		if (!table_context->od_feature_capabilities)
+		if (!od8_settings->od_feature_capabilities)
 			return -ENOMEM;
 
 		/* Setup correct ODSettingCount, and store ODSettingArray from
@@ -404,31 +405,31 @@ static int vega20_setup_od8_information(struct smu_context *smu)
 
 		od_setting_array_size = sizeof(uint32_t) * od_setting_count;
 
-		if (table_context->od_settings_max)
+		if (od8_settings->od_settings_max)
 			return -EINVAL;
 
-		table_context->od_settings_max = kmemdup(&powerplay_table->OverDrive8Table.ODSettingsMax,
+		od8_settings->od_settings_max = kmemdup(&powerplay_table->OverDrive8Table.ODSettingsMax,
 							 od_setting_array_size,
 							 GFP_KERNEL);
 
-		if (!table_context->od_settings_max) {
-			kfree(table_context->od_feature_capabilities);
-			table_context->od_feature_capabilities = NULL;
+		if (!od8_settings->od_settings_max) {
+			kfree(od8_settings->od_feature_capabilities);
+			od8_settings->od_feature_capabilities = NULL;
 			return -ENOMEM;
 		}
 
-		if (table_context->od_settings_min)
+		if (od8_settings->od_settings_min)
 			return -EINVAL;
 
-		table_context->od_settings_min = kmemdup(&powerplay_table->OverDrive8Table.ODSettingsMin,
+		od8_settings->od_settings_min = kmemdup(&powerplay_table->OverDrive8Table.ODSettingsMin,
 							 od_setting_array_size,
 							 GFP_KERNEL);
 
-		if (!table_context->od_settings_min) {
-			kfree(table_context->od_feature_capabilities);
-			table_context->od_feature_capabilities = NULL;
-			kfree(table_context->od_settings_max);
-			table_context->od_settings_max = NULL;
+		if (!od8_settings->od_settings_min) {
+			kfree(od8_settings->od_feature_capabilities);
+			od8_settings->od_feature_capabilities = NULL;
+			kfree(od8_settings->od_settings_max);
+			od8_settings->od_settings_max = NULL;
 			return -ENOMEM;
 		}
 	}
@@ -940,7 +941,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
 	struct vega20_dpm_table *dpm_table = NULL;
 	struct vega20_od8_settings *od8_settings =
-		(struct vega20_od8_settings *)table_context->od8_settings;
+		(struct vega20_od8_settings *)smu->od_settings;
 	OverDriveTable_t *od_table =
 		(OverDriveTable_t *)(table_context->overdrive_table);
 	PPTable_t *pptable = (PPTable_t *)table_context->driver_pptable;
@@ -1496,22 +1497,22 @@ static int vega20_set_default_od8_setttings(struct smu_context *smu)
 	PPTable_t *smc_pptable = table_context->driver_pptable;
 	int i, ret;
 
-	if (table_context->od8_settings)
+	if (smu->od_settings)
 		return -EINVAL;
 
-	table_context->od8_settings = kzalloc(sizeof(struct vega20_od8_settings), GFP_KERNEL);
+	od8_settings = kzalloc(sizeof(struct vega20_od8_settings), GFP_KERNEL);
 
-	if (!table_context->od8_settings)
+	if (od8_settings)
 		return -ENOMEM;
 
-	od8_settings = (struct vega20_od8_settings *)table_context->od8_settings;
+	smu->od_settings = (void *)od8_settings;
 
 	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_SOCCLK_BIT)) {
-		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_GFXCLK_LIMITS] &&
-		    table_context->od_settings_max[OD8_SETTING_GFXCLK_FMAX] > 0 &&
-		    table_context->od_settings_min[OD8_SETTING_GFXCLK_FMIN] > 0 &&
-		    (table_context->od_settings_max[OD8_SETTING_GFXCLK_FMAX] >=
-		     table_context->od_settings_min[OD8_SETTING_GFXCLK_FMIN])) {
+		if (od8_settings->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_GFXCLK_LIMITS] &&
+		    od8_settings->od_settings_max[OD8_SETTING_GFXCLK_FMAX] > 0 &&
+		    od8_settings->od_settings_min[OD8_SETTING_GFXCLK_FMIN] > 0 &&
+		    (od8_settings->od_settings_max[OD8_SETTING_GFXCLK_FMAX] >=
+		     od8_settings->od_settings_min[OD8_SETTING_GFXCLK_FMIN])) {
 			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMIN].feature_id =
 				OD8_GFXCLK_LIMITS;
 			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMAX].feature_id =
@@ -1522,13 +1523,13 @@ static int vega20_set_default_od8_setttings(struct smu_context *smu)
 				od_table->GfxclkFmax;
 		}
 
-		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_GFXCLK_CURVE] &&
-		    (table_context->od_settings_min[OD8_SETTING_GFXCLK_VOLTAGE1] >=
+		if (od8_settings->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_GFXCLK_CURVE] &&
+		    (od8_settings->od_settings_min[OD8_SETTING_GFXCLK_VOLTAGE1] >=
 		     smc_pptable->MinVoltageGfx / VOLTAGE_SCALE) &&
-		    (table_context->od_settings_max[OD8_SETTING_GFXCLK_VOLTAGE3] <=
+		    (od8_settings->od_settings_max[OD8_SETTING_GFXCLK_VOLTAGE3] <=
 		     smc_pptable->MaxVoltageGfx / VOLTAGE_SCALE) &&
-		    (table_context->od_settings_min[OD8_SETTING_GFXCLK_VOLTAGE1] <=
-		     table_context->od_settings_max[OD8_SETTING_GFXCLK_VOLTAGE3])) {
+		    (od8_settings->od_settings_min[OD8_SETTING_GFXCLK_VOLTAGE1] <=
+		     od8_settings->od_settings_max[OD8_SETTING_GFXCLK_VOLTAGE3])) {
 			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ1].feature_id =
 				OD8_GFXCLK_CURVE;
 			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE1].feature_id =
@@ -1580,11 +1581,11 @@ static int vega20_set_default_od8_setttings(struct smu_context *smu)
 	}
 
 	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_UCLK_BIT)) {
-		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_UCLK_MAX] &&
-		    table_context->od_settings_min[OD8_SETTING_UCLK_FMAX] > 0 &&
-		    table_context->od_settings_max[OD8_SETTING_UCLK_FMAX] > 0 &&
-		    (table_context->od_settings_max[OD8_SETTING_UCLK_FMAX] >=
-		     table_context->od_settings_min[OD8_SETTING_UCLK_FMAX])) {
+		if (od8_settings->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_UCLK_MAX] &&
+		    od8_settings->od_settings_min[OD8_SETTING_UCLK_FMAX] > 0 &&
+		    od8_settings->od_settings_max[OD8_SETTING_UCLK_FMAX] > 0 &&
+		    (od8_settings->od_settings_max[OD8_SETTING_UCLK_FMAX] >=
+		     od8_settings->od_settings_min[OD8_SETTING_UCLK_FMAX])) {
 			od8_settings->od8_settings_array[OD8_SETTING_UCLK_FMAX].feature_id =
 				OD8_UCLK_MAX;
 			od8_settings->od8_settings_array[OD8_SETTING_UCLK_FMAX].default_value =
@@ -1592,11 +1593,11 @@ static int vega20_set_default_od8_setttings(struct smu_context *smu)
 		}
 	}
 
-	if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_POWER_LIMIT] &&
-	    table_context->od_settings_min[OD8_SETTING_POWER_PERCENTAGE] > 0 &&
-	    table_context->od_settings_min[OD8_SETTING_POWER_PERCENTAGE] <= 100 &&
-	    table_context->od_settings_max[OD8_SETTING_POWER_PERCENTAGE] > 0 &&
-	    table_context->od_settings_max[OD8_SETTING_POWER_PERCENTAGE] <= 100) {
+	if (od8_settings->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_POWER_LIMIT] &&
+	    od8_settings->od_settings_min[OD8_SETTING_POWER_PERCENTAGE] > 0 &&
+	    od8_settings->od_settings_min[OD8_SETTING_POWER_PERCENTAGE] <= 100 &&
+	    od8_settings->od_settings_max[OD8_SETTING_POWER_PERCENTAGE] > 0 &&
+	    od8_settings->od_settings_max[OD8_SETTING_POWER_PERCENTAGE] <= 100) {
 		od8_settings->od8_settings_array[OD8_SETTING_POWER_PERCENTAGE].feature_id =
 			OD8_POWER_LIMIT;
 		od8_settings->od8_settings_array[OD8_SETTING_POWER_PERCENTAGE].default_value =
@@ -1604,22 +1605,22 @@ static int vega20_set_default_od8_setttings(struct smu_context *smu)
 	}
 
 	if (smu_feature_is_enabled(smu, SMU_FEATURE_FAN_CONTROL_BIT)) {
-		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_FAN_ACOUSTIC_LIMIT] &&
-		    table_context->od_settings_min[OD8_SETTING_FAN_ACOUSTIC_LIMIT] > 0 &&
-		    table_context->od_settings_max[OD8_SETTING_FAN_ACOUSTIC_LIMIT] > 0 &&
-		    (table_context->od_settings_max[OD8_SETTING_FAN_ACOUSTIC_LIMIT] >=
-		     table_context->od_settings_min[OD8_SETTING_FAN_ACOUSTIC_LIMIT])) {
+		if (od8_settings->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_FAN_ACOUSTIC_LIMIT] &&
+		    od8_settings->od_settings_min[OD8_SETTING_FAN_ACOUSTIC_LIMIT] > 0 &&
+		    od8_settings->od_settings_max[OD8_SETTING_FAN_ACOUSTIC_LIMIT] > 0 &&
+		    (od8_settings->od_settings_max[OD8_SETTING_FAN_ACOUSTIC_LIMIT] >=
+		     od8_settings->od_settings_min[OD8_SETTING_FAN_ACOUSTIC_LIMIT])) {
 			od8_settings->od8_settings_array[OD8_SETTING_FAN_ACOUSTIC_LIMIT].feature_id =
 				OD8_ACOUSTIC_LIMIT_SCLK;
 			od8_settings->od8_settings_array[OD8_SETTING_FAN_ACOUSTIC_LIMIT].default_value =
 				od_table->FanMaximumRpm;
 		}
 
-		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_FAN_SPEED_MIN] &&
-		    table_context->od_settings_min[OD8_SETTING_FAN_MIN_SPEED] > 0 &&
-		    table_context->od_settings_max[OD8_SETTING_FAN_MIN_SPEED] > 0 &&
-		    (table_context->od_settings_max[OD8_SETTING_FAN_MIN_SPEED] >=
-		     table_context->od_settings_min[OD8_SETTING_FAN_MIN_SPEED])) {
+		if (od8_settings->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_FAN_SPEED_MIN] &&
+		    od8_settings->od_settings_min[OD8_SETTING_FAN_MIN_SPEED] > 0 &&
+		    od8_settings->od_settings_max[OD8_SETTING_FAN_MIN_SPEED] > 0 &&
+		    (od8_settings->od_settings_max[OD8_SETTING_FAN_MIN_SPEED] >=
+		     od8_settings->od_settings_min[OD8_SETTING_FAN_MIN_SPEED])) {
 			od8_settings->od8_settings_array[OD8_SETTING_FAN_MIN_SPEED].feature_id =
 				OD8_FAN_SPEED_MIN;
 			od8_settings->od8_settings_array[OD8_SETTING_FAN_MIN_SPEED].default_value =
@@ -1628,22 +1629,22 @@ static int vega20_set_default_od8_setttings(struct smu_context *smu)
 	}
 
 	if (smu_feature_is_enabled(smu, SMU_FEATURE_THERMAL_BIT)) {
-		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_TEMPERATURE_FAN] &&
-		    table_context->od_settings_min[OD8_SETTING_FAN_TARGET_TEMP] > 0 &&
-		    table_context->od_settings_max[OD8_SETTING_FAN_TARGET_TEMP] > 0 &&
-		    (table_context->od_settings_max[OD8_SETTING_FAN_TARGET_TEMP] >=
-		     table_context->od_settings_min[OD8_SETTING_FAN_TARGET_TEMP])) {
+		if (od8_settings->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_TEMPERATURE_FAN] &&
+		    od8_settings->od_settings_min[OD8_SETTING_FAN_TARGET_TEMP] > 0 &&
+		    od8_settings->od_settings_max[OD8_SETTING_FAN_TARGET_TEMP] > 0 &&
+		    (od8_settings->od_settings_max[OD8_SETTING_FAN_TARGET_TEMP] >=
+		     od8_settings->od_settings_min[OD8_SETTING_FAN_TARGET_TEMP])) {
 			od8_settings->od8_settings_array[OD8_SETTING_FAN_TARGET_TEMP].feature_id =
 				OD8_TEMPERATURE_FAN;
 			od8_settings->od8_settings_array[OD8_SETTING_FAN_TARGET_TEMP].default_value =
 				od_table->FanTargetTemperature;
 		}
 
-		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_TEMPERATURE_SYSTEM] &&
-		    table_context->od_settings_min[OD8_SETTING_OPERATING_TEMP_MAX] > 0 &&
-		    table_context->od_settings_max[OD8_SETTING_OPERATING_TEMP_MAX] > 0 &&
-		    (table_context->od_settings_max[OD8_SETTING_OPERATING_TEMP_MAX] >=
-		     table_context->od_settings_min[OD8_SETTING_OPERATING_TEMP_MAX])) {
+		if (od8_settings->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_TEMPERATURE_SYSTEM] &&
+		    od8_settings->od_settings_min[OD8_SETTING_OPERATING_TEMP_MAX] > 0 &&
+		    od8_settings->od_settings_max[OD8_SETTING_OPERATING_TEMP_MAX] > 0 &&
+		    (od8_settings->od_settings_max[OD8_SETTING_OPERATING_TEMP_MAX] >=
+		     od8_settings->od_settings_min[OD8_SETTING_OPERATING_TEMP_MAX])) {
 			od8_settings->od8_settings_array[OD8_SETTING_OPERATING_TEMP_MAX].feature_id =
 				OD8_TEMPERATURE_SYSTEM;
 			od8_settings->od8_settings_array[OD8_SETTING_OPERATING_TEMP_MAX].default_value =
@@ -1654,9 +1655,9 @@ static int vega20_set_default_od8_setttings(struct smu_context *smu)
 	for (i = 0; i < OD8_SETTING_COUNT; i++) {
 		if (od8_settings->od8_settings_array[i].feature_id) {
 			od8_settings->od8_settings_array[i].min_value =
-				table_context->od_settings_min[i];
+				od8_settings->od_settings_min[i];
 			od8_settings->od8_settings_array[i].max_value =
-				table_context->od_settings_max[i];
+				od8_settings->od_settings_max[i];
 			od8_settings->od8_settings_array[i].current_value =
 				od8_settings->od8_settings_array[i].default_value;
 		} else {
@@ -2415,7 +2416,7 @@ static int vega20_update_specified_od8_value(struct smu_context *smu,
 	OverDriveTable_t *od_table =
 		(OverDriveTable_t *)(table_context->overdrive_table);
 	struct vega20_od8_settings *od8_settings =
-		(struct vega20_od8_settings *)table_context->od8_settings;
+		(struct vega20_od8_settings *)smu->od_settings;
 
 	switch (index) {
 	case OD8_SETTING_GFXCLK_FMIN:
@@ -2596,7 +2597,7 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 	struct vega20_dpm_table *dpm_table = NULL;
 	struct vega20_single_dpm_table *single_dpm_table;
 	struct vega20_od8_settings *od8_settings =
-		(struct vega20_od8_settings *)table_context->od8_settings;
+		(struct vega20_od8_settings *)smu->od_settings;
 	struct pp_clock_levels_with_latency clocks;
 	int32_t input_index, input_clk, input_vol, i;
 	int od8_id;
@@ -2643,10 +2644,10 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 
 			if (input_index == 0 && od_table->GfxclkFmin != input_clk) {
 				od_table->GfxclkFmin = input_clk;
-				table_context->od_gfxclk_update = true;
+				od8_settings->od_gfxclk_update = true;
 			} else if (input_index == 1 && od_table->GfxclkFmax != input_clk) {
 				od_table->GfxclkFmax = input_clk;
-				table_context->od_gfxclk_update = true;
+				od8_settings->od_gfxclk_update = true;
 			}
 		}
 
@@ -2691,7 +2692,7 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 			}
 
 			if (input_index == 1 && od_table->UclkFmax != input_clk) {
-				table_context->od_gfxclk_update = true;
+				od8_settings->od_gfxclk_update = true;
 				od_table->UclkFmax = input_clk;
 			}
 		}
@@ -2782,8 +2783,8 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 		}
 
 		/* retrieve updated gfxclk table */
-		if (table_context->od_gfxclk_update) {
-			table_context->od_gfxclk_update = false;
+		if (od8_settings->od_gfxclk_update) {
+			od8_settings->od_gfxclk_update = false;
 			single_dpm_table = &(dpm_table->gfx_table);
 
 			if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_GFXCLK_BIT)) {

commit 8f30a16d3ac15f61aa7a02b77191aafe44912654
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Tue May 21 15:37:24 2019 +0800

    drm/amd/powerplay: move od_default_setting callback to asic file
    
    the set default od_setting is asic related function,
    so move thic code to vega20_ppt file.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index b2fe65c33e9e..33634f3b7fae 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1689,6 +1689,44 @@ static int vega20_get_metrics_table(struct smu_context *smu,
 
 	return ret;
 }
+
+static int vega20_set_default_od_settings(struct smu_context *smu,
+					  bool initialize)
+{
+	struct smu_table_context *table_context = &smu->smu_table;
+	int ret;
+
+	if (initialize) {
+		if (table_context->overdrive_table)
+			return -EINVAL;
+
+		table_context->overdrive_table = kzalloc(sizeof(OverDriveTable_t), GFP_KERNEL);
+
+		if (!table_context->overdrive_table)
+			return -ENOMEM;
+
+		ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE,
+				       table_context->overdrive_table, false);
+		if (ret) {
+			pr_err("Failed to export over drive table!\n");
+			return ret;
+		}
+
+		ret = vega20_set_default_od8_setttings(smu);
+		if (ret)
+			return ret;
+	}
+
+	ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE,
+			       table_context->overdrive_table, true);
+	if (ret) {
+		pr_err("Failed to import over drive table!\n");
+		return ret;
+	}
+
+	return 0;
+}
+
 static int vega20_get_od_percentage(struct smu_context *smu,
 				    enum smu_clk_type clk_type)
 {
@@ -3228,11 +3266,11 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.print_clk_levels = vega20_print_clk_levels,
 	.force_clk_levels = vega20_force_clk_levels,
 	.get_clock_by_type_with_latency = vega20_get_clock_by_type_with_latency,
-	.set_default_od8_settings = vega20_set_default_od8_setttings,
 	.get_od_percentage = vega20_get_od_percentage,
 	.get_power_profile_mode = vega20_get_power_profile_mode,
 	.set_power_profile_mode = vega20_set_power_profile_mode,
 	.set_od_percentage = vega20_set_od_percentage,
+	.set_default_od_settings = vega20_set_default_od_settings,
 	.od_edit_dpm_table = vega20_odn_edit_dpm_table,
 	.dpm_set_uvd_enable = vega20_dpm_set_uvd_enable,
 	.dpm_set_vce_enable = vega20_dpm_set_vce_enable,

commit a259714bb26a5d107d5d0d742afd509c350441f4
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Tue May 21 15:19:22 2019 +0800

    drm/amd/powerplay: move od8_setting helper function to vega20_ppt
    
    these callback functions is only used for vega20 asic, to be compatible
    other asics,need to move this code to vega20_ppt file
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index a6d73162e3ed..b2fe65c33e9e 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2446,6 +2446,34 @@ static int vega20_update_specified_od8_value(struct smu_context *smu,
 	return 0;
 }
 
+static int vega20_update_od8_settings(struct smu_context *smu,
+				      uint32_t index,
+				      uint32_t value)
+{
+	struct smu_table_context *table_context = &smu->smu_table;
+	int ret;
+
+	ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE,
+			       table_context->overdrive_table, false);
+	if (ret) {
+		pr_err("Failed to export over drive table!\n");
+		return ret;
+	}
+
+	ret = vega20_update_specified_od8_value(smu, index, value);
+	if (ret)
+		return ret;
+
+	ret = smu_update_table(smu, SMU_TABLE_OVERDRIVE,
+			       table_context->overdrive_table, true);
+	if (ret) {
+		pr_err("Failed to import over drive table!\n");
+		return ret;
+	}
+
+	return 0;
+}
+
 static int vega20_set_od_percentage(struct smu_context *smu,
 				    enum smu_clk_type clk_type,
 				    uint32_t value)
@@ -2492,7 +2520,7 @@ static int vega20_set_od_percentage(struct smu_context *smu,
 	od_clk /= 100;
 	od_clk += golden_dpm_table->dpm_levels[golden_dpm_table->count - 1].value;
 
-	ret = smu_update_od8_settings(smu, index, od_clk);
+	ret = vega20_update_od8_settings(smu, index, od_clk);
 	if (ret) {
 		pr_err("[Setoverdrive] failed to set od clk!\n");
 		goto set_od_failed;
@@ -3204,7 +3232,6 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_od_percentage = vega20_get_od_percentage,
 	.get_power_profile_mode = vega20_get_power_profile_mode,
 	.set_power_profile_mode = vega20_set_power_profile_mode,
-	.update_specified_od8_value = vega20_update_specified_od8_value,
 	.set_od_percentage = vega20_set_od_percentage,
 	.od_edit_dpm_table = vega20_odn_edit_dpm_table,
 	.dpm_set_uvd_enable = vega20_dpm_set_uvd_enable,

commit c7a063a2f21b2ec83f4a3ea2494dc10b52dc3589
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Thu May 16 18:24:08 2019 +0800

    drm/amd/powerplay: fix clk type name error OD_SCLK OD_MCLK
    
    use sw-smu clk type name to replace legacy clk type name
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index d8406415c235..a6d73162e3ed 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1690,7 +1690,7 @@ static int vega20_get_metrics_table(struct smu_context *smu,
 	return ret;
 }
 static int vega20_get_od_percentage(struct smu_context *smu,
-				    enum pp_clock_type type)
+				    enum smu_clk_type clk_type)
 {
 	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
 	struct vega20_dpm_table *dpm_table = NULL;
@@ -1702,12 +1702,12 @@ static int vega20_get_od_percentage(struct smu_context *smu,
 	dpm_table = smu_dpm->dpm_context;
 	golden_table = smu_dpm->golden_dpm_context;
 
-	switch (type) {
-	case OD_SCLK:
+	switch (clk_type) {
+	case SMU_OD_SCLK:
 		single_dpm_table = &(dpm_table->gfx_table);
 		golden_dpm_table = &(golden_table->gfx_table);
 		break;
-	case OD_MCLK:
+	case SMU_OD_MCLK:
 		single_dpm_table = &(dpm_table->mem_table);
 		golden_dpm_table = &(golden_table->mem_table);
 		break;
@@ -2447,7 +2447,7 @@ static int vega20_update_specified_od8_value(struct smu_context *smu,
 }
 
 static int vega20_set_od_percentage(struct smu_context *smu,
-				    enum pp_clock_type type,
+				    enum smu_clk_type clk_type,
 				    uint32_t value)
 {
 	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
@@ -2465,15 +2465,15 @@ static int vega20_set_od_percentage(struct smu_context *smu,
 	dpm_table = smu_dpm->dpm_context;
 	golden_table = smu_dpm->golden_dpm_context;
 
-	switch (type) {
-	case OD_SCLK:
+	switch (clk_type) {
+	case SMU_OD_SCLK:
 		single_dpm_table = &(dpm_table->gfx_table);
 		golden_dpm_table = &(golden_table->gfx_table);
 		feature_enabled = smu_feature_is_enabled(smu, SMU_FEATURE_DPM_GFXCLK_BIT);
 		clk_id = PPCLK_GFXCLK;
 		index = OD8_SETTING_GFXCLK_FMAX;
 		break;
-	case OD_MCLK:
+	case SMU_OD_MCLK:
 		single_dpm_table = &(dpm_table->mem_table);
 		golden_dpm_table = &(golden_table->mem_table);
 		feature_enabled = smu_feature_is_enabled(smu, SMU_FEATURE_DPM_UCLK_BIT);

commit e211580da9a4767b1902a17f0cbed580000f2b66
Author: Hawking Zhang <Hawking.Zhang@amd.com>
Date:   Mon Jun 10 21:39:29 2019 +0800

    drm/amd/powerplay: move get_thermal_temperature_range to ppt funcs
    
    The thermal policy could be ASIC specific ones and depends on structures
    in pptable. As a result, get_thermal_temperature_range should be implemented
    as ppt funcs instead of smu funcs
    
    Signed-off-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 8c196e252d27..d8406415c235 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -36,10 +36,16 @@
 #include "vega20_pptable.h"
 #include "vega20_ppsmc.h"
 #include "nbio/nbio_7_4_sh_mask.h"
+#include "asic_reg/thm/thm_11_0_2_offset.h"
+#include "asic_reg/thm/thm_11_0_2_sh_mask.h"
 
 #define smnPCIE_LC_SPEED_CNTL			0x11140290
 #define smnPCIE_LC_LINK_WIDTH_CNTL		0x11140288
 
+#define CTF_OFFSET_EDGE			5
+#define CTF_OFFSET_HOTSPOT		5
+#define CTF_OFFSET_HBM			5
+
 #define MSG_MAP(msg) \
 	[SMU_MSG_##msg] = PPSMC_MSG_##msg
 
@@ -3023,17 +3029,17 @@ static int vega20_thermal_get_temperature(struct smu_context *smu,
 				CG_MULT_THERMAL_STATUS__CTF_TEMP__SHIFT;
 
 		temp = temp & 0x1ff;
-		temp *= SMU11_TEMPERATURE_UNITS_PER_CENTIGRADES;
+		temp *= SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
 
 		*value = temp;
 		break;
 	case AMDGPU_PP_SENSOR_EDGE_TEMP:
 		*value = metrics.TemperatureEdge *
-			PP_TEMPERATURE_UNITS_PER_CENTIGRADES;
+			SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
 		break;
 	case AMDGPU_PP_SENSOR_MEM_TEMP:
 		*value = metrics.TemperatureHBM *
-			PP_TEMPERATURE_UNITS_PER_CENTIGRADES;
+			SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
 		break;
 	default:
 		pr_err("Invalid sensor for retrieving temp\n");
@@ -3139,6 +3145,40 @@ static int vega20_set_watermarks_table(struct smu_context *smu,
 	return 0;
 }
 
+static const struct smu_temperature_range vega20_thermal_policy[] =
+{
+	{-273150,  99000, 99000, -273150, 99000, 99000, -273150, 99000, 99000},
+	{ 120000, 120000, 120000, 120000, 120000, 120000, 120000, 120000, 120000},
+};
+
+static int vega20_get_thermal_temperature_range(struct smu_context *smu,
+						struct smu_temperature_range *range)
+{
+
+	PPTable_t *pptable = smu->smu_table.driver_pptable;
+
+	if (!range)
+		return -EINVAL;
+
+	memcpy(range, &vega20_thermal_policy[0], sizeof(struct smu_temperature_range));
+
+	range->max = pptable->TedgeLimit *
+		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
+	range->edge_emergency_max = (pptable->TedgeLimit + CTF_OFFSET_EDGE) *
+		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
+	range->hotspot_crit_max = pptable->ThotspotLimit *
+		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
+	range->hotspot_emergency_max = (pptable->ThotspotLimit + CTF_OFFSET_HOTSPOT) *
+		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
+	range->mem_crit_max = pptable->ThbmLimit *
+		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
+	range->mem_emergency_max = (pptable->ThbmLimit + CTF_OFFSET_HBM)*
+		SMU_TEMPERATURE_UNITS_PER_CENTIGRADES;
+
+
+	return 0;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.tables_init = vega20_tables_init,
 	.alloc_dpm_context = vega20_allocate_dpm_context,
@@ -3183,6 +3223,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.set_thermal_fan_table = vega20_set_thermal_fan_table,
 	.get_fan_speed_percent = vega20_get_fan_speed_percent,
 	.set_watermarks_table = vega20_set_watermarks_table,
+	.get_thermal_temperature_range = vega20_get_thermal_temperature_range
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 4dc9c8bf3474955cd721991a415df8e2b9e73b84
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Fri May 17 14:12:51 2019 +0800

    drm/amd/powerplay: move function thermal_get_temperature to veag20_ppt
    
    the fcuntion thermal_get_temperature will be access SmuMetrics_t data,
    the data structure is asic related, so move vega20_ppt to implement.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 80f7d980d63f..8c196e252d27 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3000,6 +3000,48 @@ static int vega20_get_current_activity_percent(struct smu_context *smu,
 	return 0;
 }
 
+static int vega20_thermal_get_temperature(struct smu_context *smu,
+					     enum amd_pp_sensors sensor,
+					     uint32_t *value)
+{
+	struct amdgpu_device *adev = smu->adev;
+	SmuMetrics_t metrics;
+	uint32_t temp = 0;
+	int ret = 0;
+
+	if (!value)
+		return -EINVAL;
+
+	ret = vega20_get_metrics_table(smu, &metrics);
+	if (ret)
+		return ret;
+
+	switch (sensor) {
+	case AMDGPU_PP_SENSOR_HOTSPOT_TEMP:
+		temp = RREG32_SOC15(THM, 0, mmCG_MULT_THERMAL_STATUS);
+		temp = (temp & CG_MULT_THERMAL_STATUS__CTF_TEMP_MASK) >>
+				CG_MULT_THERMAL_STATUS__CTF_TEMP__SHIFT;
+
+		temp = temp & 0x1ff;
+		temp *= SMU11_TEMPERATURE_UNITS_PER_CENTIGRADES;
+
+		*value = temp;
+		break;
+	case AMDGPU_PP_SENSOR_EDGE_TEMP:
+		*value = metrics.TemperatureEdge *
+			PP_TEMPERATURE_UNITS_PER_CENTIGRADES;
+		break;
+	case AMDGPU_PP_SENSOR_MEM_TEMP:
+		*value = metrics.TemperatureHBM *
+			PP_TEMPERATURE_UNITS_PER_CENTIGRADES;
+		break;
+	default:
+		pr_err("Invalid sensor for retrieving temp\n");
+		return -EINVAL;
+	}
+
+	return 0;
+}
 static int vega20_read_sensor(struct smu_context *smu,
 				 enum amd_pp_sensors sensor,
 				 void *data, uint32_t *size)
@@ -3024,6 +3066,12 @@ static int vega20_read_sensor(struct smu_context *smu,
 		ret = vega20_get_gpu_power(smu, (uint32_t *)data);
 		*size = 4;
 		break;
+	case AMDGPU_PP_SENSOR_HOTSPOT_TEMP:
+	case AMDGPU_PP_SENSOR_EDGE_TEMP:
+	case AMDGPU_PP_SENSOR_MEM_TEMP:
+		ret = vega20_thermal_get_temperature(smu, sensor, (uint32_t *)data);
+		*size = 4;
+		break;
 	default:
 		return -EINVAL;
 	}

commit 62b9a88c0ef97ca3373da53b3d499ffabbd13c94
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Fri May 17 14:02:15 2019 +0800

    drm/amd/powerplay: move function get_metrics_table to vega20_ppt
    
    the SmuMetrics_t table is asic related data structure.
    so move vega20_ppt file to implement.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index b509325cbe91..80f7d980d63f 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -294,8 +294,10 @@ static int vega20_get_workload_type(struct smu_context *smu, enum PP_SMC_POWER_P
 	return val;
 }
 
-static void vega20_tables_init(struct smu_context *smu, struct smu_table *tables)
+static int vega20_tables_init(struct smu_context *smu, struct smu_table *tables)
 {
+	struct smu_table_context *smu_table = &smu->smu_table;
+
 	SMU_TABLE_INIT(tables, SMU_TABLE_PPTABLE, sizeof(PPTable_t),
 		       PAGE_SIZE, AMDGPU_GEM_DOMAIN_VRAM);
 	SMU_TABLE_INIT(tables, SMU_TABLE_WATERMARKS, sizeof(Watermarks_t),
@@ -309,6 +311,13 @@ static void vega20_tables_init(struct smu_context *smu, struct smu_table *tables
 	SMU_TABLE_INIT(tables, SMU_TABLE_ACTIVITY_MONITOR_COEFF,
 		       sizeof(DpmActivityMonitorCoeffInt_t), PAGE_SIZE,
 	               AMDGPU_GEM_DOMAIN_VRAM);
+
+	smu_table->metrics_table = kzalloc(sizeof(SmuMetrics_t), GFP_KERNEL);
+	if (smu_table->metrics_table)
+		return -ENOMEM;
+	smu_table->metrics_time = 0;
+
+	return 0;
 }
 
 static int vega20_allocate_dpm_context(struct smu_context *smu)
@@ -1654,6 +1663,26 @@ static int vega20_set_default_od8_setttings(struct smu_context *smu)
 	return 0;
 }
 
+static int vega20_get_metrics_table(struct smu_context *smu,
+				    SmuMetrics_t *metrics_table)
+{
+	struct smu_table_context *smu_table= &smu->smu_table;
+	int ret = 0;
+
+	if (!smu_table->metrics_time || time_after(jiffies, smu_table->metrics_time + HZ / 1000)) {
+		ret = smu_update_table(smu, SMU_TABLE_SMU_METRICS,
+				(void *)smu_table->metrics_table, false);
+		if (ret) {
+			pr_info("Failed to export SMU metrics table!\n");
+			return ret;
+		}
+		smu_table->metrics_time = jiffies;
+	}
+
+	memcpy(metrics_table, smu_table->metrics_table, sizeof(SmuMetrics_t));
+
+	return ret;
+}
 static int vega20_get_od_percentage(struct smu_context *smu,
 				    enum pp_clock_type type)
 {
@@ -2933,8 +2962,7 @@ static int vega20_get_gpu_power(struct smu_context *smu, uint32_t *value)
 	if (!value)
 		return -EINVAL;
 
-	ret = smu_update_table(smu, SMU_TABLE_SMU_METRICS, (void *)&metrics,
-			       false);
+	ret = vega20_get_metrics_table(smu, &metrics);
 	if (ret)
 		return ret;
 
@@ -2953,8 +2981,7 @@ static int vega20_get_current_activity_percent(struct smu_context *smu,
 	if (!value)
 		return -EINVAL;
 
-	ret = smu_update_table(smu, SMU_TABLE_SMU_METRICS,
-			       (void *)&metrics, false);
+	ret = vega20_get_metrics_table(smu, &metrics);
 	if (ret)
 		return ret;
 

commit a38470f0f8dcd639262d7e2eeaa26b8e0947d811
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Wed May 15 12:59:58 2019 +0800

    drm/amd/powerplay: move power_dpm_force_performance_level to amdgpu_smu file
    
    because this callback is not asic related function, so move it to top
    code level to support more asic (eg: navi10)
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 472fe87d73f4..b509325cbe91 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2334,46 +2334,6 @@ static int vega20_unforce_dpm_levels(struct smu_context *smu)
 	return ret;
 }
 
-static enum amd_dpm_forced_level vega20_get_performance_level(struct smu_context *smu)
-{
-	struct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);
-	if (!smu_dpm_ctx->dpm_context)
-		return -EINVAL;
-
-	if (smu_dpm_ctx->dpm_level != smu_dpm_ctx->saved_dpm_level) {
-		mutex_lock(&(smu->mutex));
-		smu_dpm_ctx->saved_dpm_level = smu_dpm_ctx->dpm_level;
-		mutex_unlock(&(smu->mutex));
-	}
-	return smu_dpm_ctx->dpm_level;
-}
-
-static int
-vega20_force_performance_level(struct smu_context *smu, enum amd_dpm_forced_level level)
-{
-	int ret = 0;
-	int i;
-	struct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);
-
-	if (!smu_dpm_ctx->dpm_context)
-		return -EINVAL;
-
-	for (i = 0; i < smu->adev->num_ip_blocks; i++) {
-		if (smu->adev->ip_blocks[i].version->type == AMD_IP_BLOCK_TYPE_SMC)
-			break;
-	}
-
-	mutex_lock(&smu->mutex);
-
-	smu->adev->ip_blocks[i].version->funcs->enable_umd_pstate(smu, &level);
-	ret = smu_handle_task(smu, level,
-			      AMD_PP_TASK_READJUST_POWER_STATE);
-
-	mutex_unlock(&smu->mutex);
-
-	return ret;
-}
-
 static int vega20_update_specified_od8_value(struct smu_context *smu,
 					     uint32_t index,
 					     uint32_t value)
@@ -3129,8 +3089,6 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_od_percentage = vega20_get_od_percentage,
 	.get_power_profile_mode = vega20_get_power_profile_mode,
 	.set_power_profile_mode = vega20_set_power_profile_mode,
-	.get_performance_level = vega20_get_performance_level,
-	.force_performance_level = vega20_force_performance_level,
 	.update_specified_od8_value = vega20_update_specified_od8_value,
 	.set_od_percentage = vega20_set_od_percentage,
 	.od_edit_dpm_table = vega20_odn_edit_dpm_table,

commit 564c4c7f00266a92fd3521983164b1014e6bc7e9
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Fri Jun 21 11:26:18 2019 -0500

    drm/amd/powerplay: simplify the interface of get_gpu_power
    
    this callback function is only call in read_sensor in smu_v11_0.c,
    so move this code to {asic}_ppt.c to implement as asic related function.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 93c6545ec4e8..472fe87d73f4 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3033,6 +3033,10 @@ static int vega20_read_sensor(struct smu_context *smu,
 						(uint32_t *)data);
 		*size = 4;
 		break;
+	case AMDGPU_PP_SENSOR_GPU_POWER:
+		ret = vega20_get_gpu_power(smu, (uint32_t *)data);
+		*size = 4;
+		break;
 	default:
 		return -EINVAL;
 	}
@@ -3145,7 +3149,6 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.is_dpm_running = vega20_is_dpm_running,
 	.set_thermal_fan_table = vega20_set_thermal_fan_table,
 	.get_fan_speed_percent = vega20_get_fan_speed_percent,
-	.get_gpu_power = vega20_get_gpu_power,
 	.set_watermarks_table = vega20_set_watermarks_table,
 };
 

commit d573bb214dd2578f7a09c116c3ea9bf99cb4d4fd
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Fri Jun 21 11:25:00 2019 -0500

    drm/amd/powerplay: simplify the interface of get_current_activity_percent
    
    this callback function is only call in read_sensor in smu_v11_0.c,
    so move this code to {asic}_ppt.c to implement as asic related function.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 55d6be88744b..93c6545ec4e8 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2927,26 +2927,6 @@ static int vega20_set_ppfeature_status(struct smu_context *smu, uint64_t new_ppf
 	return 0;
 }
 
-static int vega20_read_sensor(struct smu_context *smu,
-			      enum amd_pp_sensors sensor,
-			      void *data, uint32_t *size)
-{
-	int ret = 0;
-	struct smu_table_context *table_context = &smu->smu_table;
-	PPTable_t *pptable = table_context->driver_pptable;
-
-	switch (sensor) {
-	case AMDGPU_PP_SENSOR_MAX_FAN_RPM:
-		*(uint32_t *)data = pptable->FanMaximumRpm;
-		*size = 4;
-		break;
-	default:
-		return -EINVAL;
-	}
-
-	return ret;
-}
-
 static bool vega20_is_dpm_running(struct smu_context *smu)
 {
 	int ret = 0;
@@ -3033,6 +3013,33 @@ static int vega20_get_current_activity_percent(struct smu_context *smu,
 	return 0;
 }
 
+static int vega20_read_sensor(struct smu_context *smu,
+				 enum amd_pp_sensors sensor,
+				 void *data, uint32_t *size)
+{
+	int ret = 0;
+	struct smu_table_context *table_context = &smu->smu_table;
+	PPTable_t *pptable = table_context->driver_pptable;
+
+	switch (sensor) {
+	case AMDGPU_PP_SENSOR_MAX_FAN_RPM:
+		*(uint32_t *)data = pptable->FanMaximumRpm;
+		*size = 4;
+		break;
+	case AMDGPU_PP_SENSOR_MEM_LOAD:
+	case AMDGPU_PP_SENSOR_GPU_LOAD:
+		ret = vega20_get_current_activity_percent(smu,
+						sensor,
+						(uint32_t *)data);
+		*size = 4;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return ret;
+}
+
 static int vega20_set_watermarks_table(struct smu_context *smu,
 				       void *watermarks, struct
 				       dm_pp_wm_sets_with_clock_ranges_soc15
@@ -3139,7 +3146,6 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.set_thermal_fan_table = vega20_set_thermal_fan_table,
 	.get_fan_speed_percent = vega20_get_fan_speed_percent,
 	.get_gpu_power = vega20_get_gpu_power,
-	.get_current_activity_percent = vega20_get_current_activity_percent,
 	.set_watermarks_table = vega20_set_watermarks_table,
 };
 

commit 6c6187ece013f220c7d29805f012cb88968ce880
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Fri Jun 21 11:19:15 2019 -0500

    drm/amd/powerplay: add function get_workload_type_map for swsmu
    
    1.add new callback function get_workload_byte for smu
    2.remove old workload map function
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 0b6f64fbd240..55d6be88744b 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -207,6 +207,16 @@ static int vega20_pwr_src_map[SMU_POWER_SOURCE_COUNT] = {
 	PWR_MAP(DC),
 };
 
+static int vega20_workload_map[] = {
+	WORKLOAD_MAP(PP_SMC_POWER_PROFILE_BOOTUP_DEFAULT,	WORKLOAD_DEFAULT_BIT),
+	WORKLOAD_MAP(PP_SMC_POWER_PROFILE_FULLSCREEN3D,		WORKLOAD_PPLIB_FULL_SCREEN_3D_BIT),
+	WORKLOAD_MAP(PP_SMC_POWER_PROFILE_POWERSAVING,		WORKLOAD_PPLIB_POWER_SAVING_BIT),
+	WORKLOAD_MAP(PP_SMC_POWER_PROFILE_VIDEO,		WORKLOAD_PPLIB_VIDEO_BIT),
+	WORKLOAD_MAP(PP_SMC_POWER_PROFILE_VR,			WORKLOAD_PPLIB_VR_BIT),
+	WORKLOAD_MAP(PP_SMC_POWER_PROFILE_COMPUTE,		WORKLOAD_PPLIB_CUSTOM_BIT),
+	WORKLOAD_MAP(PP_SMC_POWER_PROFILE_CUSTOM,		WORKLOAD_PPLIB_CUSTOM_BIT),
+};
+
 static int vega20_get_smu_table_index(struct smu_context *smc, uint32_t index)
 {
 	int val;
@@ -273,6 +283,17 @@ static int vega20_get_smu_msg_index(struct smu_context *smc, uint32_t index)
 	return val;
 }
 
+static int vega20_get_workload_type(struct smu_context *smu, enum PP_SMC_POWER_PROFILE profile)
+{
+	int val;
+	if (profile > PP_SMC_POWER_PROFILE_CUSTOM)
+		return -EINVAL;
+
+	val = vega20_workload_map[profile];
+
+	return val;
+}
+
 static void vega20_tables_init(struct smu_context *smu, struct smu_table *tables)
 {
 	SMU_TABLE_INIT(tables, SMU_TABLE_PPTABLE, sizeof(PPTable_t),
@@ -1669,37 +1690,6 @@ static int vega20_get_od_percentage(struct smu_context *smu,
 	return value;
 }
 
-static int vega20_conv_profile_to_workload(struct smu_context *smu, int power_profile)
-{
-	int pplib_workload = 0;
-
-	switch (power_profile) {
-	case PP_SMC_POWER_PROFILE_BOOTUP_DEFAULT:
-		pplib_workload = WORKLOAD_DEFAULT_BIT;
-		break;
-	case PP_SMC_POWER_PROFILE_FULLSCREEN3D:
-		pplib_workload = WORKLOAD_PPLIB_FULL_SCREEN_3D_BIT;
-		break;
-	case PP_SMC_POWER_PROFILE_POWERSAVING:
-		pplib_workload = WORKLOAD_PPLIB_POWER_SAVING_BIT;
-		break;
-	case PP_SMC_POWER_PROFILE_VIDEO:
-		pplib_workload = WORKLOAD_PPLIB_VIDEO_BIT;
-		break;
-	case PP_SMC_POWER_PROFILE_VR:
-		pplib_workload = WORKLOAD_PPLIB_VR_BIT;
-		break;
-	case PP_SMC_POWER_PROFILE_COMPUTE:
-		pplib_workload = WORKLOAD_PPLIB_COMPUTE_BIT;
-		break;
-	case PP_SMC_POWER_PROFILE_CUSTOM:
-		pplib_workload = WORKLOAD_PPLIB_CUSTOM_BIT;
-		break;
-	}
-
-	return pplib_workload;
-}
-
 static int vega20_get_power_profile_mode(struct smu_context *smu, char *buf)
 {
 	DpmActivityMonitorCoeffInt_t activity_monitor;
@@ -1736,7 +1726,7 @@ static int vega20_get_power_profile_mode(struct smu_context *smu, char *buf)
 
 	for (i = 0; i <= PP_SMC_POWER_PROFILE_CUSTOM; i++) {
 		/* conv PP_SMC_POWER_PROFILE* to WORKLOAD_PPLIB_*_BIT */
-		workload_type = smu_conv_profile_to_workload(smu, i);
+		workload_type = smu_workload_get_type(smu, i);
 		result = smu_update_table(smu,
 					  TABLE_ACTIVITY_MONITOR_COEFF | workload_type << 16,
 					  (void *)(&activity_monitor), false);
@@ -1888,7 +1878,7 @@ static int vega20_set_power_profile_mode(struct smu_context *smu, long *input, u
 	}
 
 	/* conv PP_SMC_POWER_PROFILE* to WORKLOAD_PPLIB_*_BIT */
-	workload_type = smu_conv_profile_to_workload(smu, smu->power_profile_mode);
+	workload_type = smu_workload_get_type(smu, smu->power_profile_mode);
 	smu_send_smc_msg_with_param(smu, SMU_MSG_SetWorkloadMask,
 				    1 << workload_type);
 
@@ -3114,6 +3104,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_smu_feature_index = vega20_get_smu_feature_index,
 	.get_smu_table_index = vega20_get_smu_table_index,
 	.get_smu_power_index = vega20_get_pwr_src_index,
+	.get_workload_type = vega20_get_workload_type,
 	.run_afll_btc = vega20_run_btc_afll,
 	.get_allowed_feature_mask = vega20_get_allowed_feature_mask,
 	.get_current_power_state = vega20_get_current_power_state,
@@ -3125,7 +3116,6 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_clock_by_type_with_latency = vega20_get_clock_by_type_with_latency,
 	.set_default_od8_settings = vega20_set_default_od8_setttings,
 	.get_od_percentage = vega20_get_od_percentage,
-	.conv_profile_to_workload = vega20_conv_profile_to_workload,
 	.get_power_profile_mode = vega20_get_power_profile_mode,
 	.set_power_profile_mode = vega20_set_power_profile_mode,
 	.get_performance_level = vega20_get_performance_level,

commit 1316b713618cbbef3141c630bf47214bfe0d1b82
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Tue Apr 23 14:45:54 2019 +0800

    drm/amd/powerplay: remove upload_dpm_level function for vega20
    
    the function upload_dpm_level is an internal function,
    so remove public interface.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index d4379c99489c..0b6f64fbd240 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2329,13 +2329,13 @@ static int vega20_unforce_dpm_levels(struct smu_context *smu)
 	dpm_table->soc_table.dpm_state.soft_max_level =
 		dpm_table->soc_table.dpm_levels[soft_max_level].value;
 
-	ret = smu_upload_dpm_level(smu, false, 0xFFFFFFFF);
+	ret = vega20_upload_dpm_level(smu, false, 0xFFFFFFFF);
 	if (ret) {
 		pr_err("Failed to upload DPM Bootup Levels!");
 		return ret;
 	}
 
-	ret = smu_upload_dpm_level(smu, true, 0xFFFFFFFF);
+	ret = vega20_upload_dpm_level(smu, true, 0xFFFFFFFF);
 	if (ret) {
 		pr_err("Failed to upload DPM Max Levels!");
 		return ret;
@@ -3142,7 +3142,6 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.notify_smc_dispaly_config = vega20_notify_smc_dispaly_config,
 	.force_dpm_limit_value = vega20_force_dpm_limit_value,
 	.unforce_dpm_levels = vega20_unforce_dpm_levels,
-	.upload_dpm_level = vega20_upload_dpm_level,
 	.get_profiling_clk_mask = vega20_get_profiling_clk_mask,
 	.set_ppfeature_status = vega20_set_ppfeature_status,
 	.get_ppfeature_status = vega20_get_ppfeature_status,

commit 6b1b7b5bf03db9fb2cac485eee5289edf2bc5b61
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Tue Apr 23 11:20:46 2019 +0800

    drm/amd/powerplay: move read sensor of UVD[VCE]_POWER to amdgpu_smu file
    
    This part of code is asic unrelated and moves to top code level.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 63697fd3445f..d4379c99489c 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2946,14 +2946,6 @@ static int vega20_read_sensor(struct smu_context *smu,
 	PPTable_t *pptable = table_context->driver_pptable;
 
 	switch (sensor) {
-	case AMDGPU_PP_SENSOR_UVD_POWER:
-		*(uint32_t *)data = smu_feature_is_enabled(smu, SMU_FEATURE_DPM_UVD_BIT) ? 1 : 0;
-		*size = 4;
-		break;
-	case AMDGPU_PP_SENSOR_VCE_POWER:
-		*(uint32_t *)data = smu_feature_is_enabled(smu, SMU_FEATURE_DPM_VCE_BIT) ? 1 : 0;
-		*size = 4;
-		break;
 	case AMDGPU_PP_SENSOR_MAX_FAN_RPM:
 		*(uint32_t *)data = pptable->FanMaximumRpm;
 		*size = 4;

commit 0a6430da0c7c6603aeb99b5b91418e6665c77561
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Tue Apr 23 14:16:52 2019 +0800

    drm/amd/powerplay: add function display_configuration_changed for navi10
    
    1.add callback function to support navi10 asic.
    2.Remove unnecessary logical code.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index aea14f1a6395..63697fd3445f 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1992,17 +1992,9 @@ static int vega20_display_config_changed(struct smu_context *smu)
 {
 	int ret = 0;
 
-	if (!smu->funcs)
-		return -EINVAL;
-
-	if (!smu->smu_dpm.dpm_context ||
-	    !smu->smu_table.tables ||
-	    !smu->smu_table.tables[TABLE_WATERMARKS].cpu_addr)
-		return -EINVAL;
-
 	if ((smu->watermarks_bitmap & WATERMARKS_EXIST) &&
 	    !(smu->watermarks_bitmap & WATERMARKS_LOADED)) {
-		ret = smu->funcs->write_watermarks_table(smu);
+		ret = smu_write_watermarks_table(smu);
 		if (ret) {
 			pr_err("Failed to update WMTABLE!");
 			return ret;

commit a43913ea50a545c437b6e264b46fe3a0485f54f0
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Fri Apr 19 14:05:58 2019 +0800

    drm/amd/powerplay: add function get_clock_by_type_with_latency for navi10
    
    add callback function get_clock_by_type_with_latency for navi10 asic
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 582b99d8f832..aea14f1a6395 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1395,7 +1395,7 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 }
 
 static int vega20_get_clock_by_type_with_latency(struct smu_context *smu,
-						 enum amd_pp_clock_type type,
+						 enum smu_clk_type clk_type,
 						 struct pp_clock_levels_with_latency *clocks)
 {
 	int ret;
@@ -1407,20 +1407,20 @@ static int vega20_get_clock_by_type_with_latency(struct smu_context *smu,
 
 	mutex_lock(&smu->mutex);
 
-	switch (type) {
-	case amd_pp_sys_clock:
+	switch (clk_type) {
+	case SMU_GFXCLK:
 		single_dpm_table = &(dpm_table->gfx_table);
 		ret = vega20_get_clk_table(smu, clocks, single_dpm_table);
 		break;
-	case amd_pp_mem_clock:
+	case SMU_MCLK:
 		single_dpm_table = &(dpm_table->mem_table);
 		ret = vega20_get_clk_table(smu, clocks, single_dpm_table);
 		break;
-	case amd_pp_dcef_clock:
+	case SMU_DCEFCLK:
 		single_dpm_table = &(dpm_table->dcef_table);
 		ret = vega20_get_clk_table(smu, clocks, single_dpm_table);
 		break;
-	case amd_pp_soc_clock:
+	case SMU_SOCCLK:
 		single_dpm_table = &(dpm_table->soc_table);
 		ret = vega20_get_clk_table(smu, clocks, single_dpm_table);
 		break;

commit db439ca21b81f0c1f1b0f1f1b6f0efc8af3a0cf4
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Fri Apr 19 10:31:18 2019 +0800

    drm/amd/powerplay: add function force_clk_levels for navi10
    
    add sysfs interface of force_clk_levels sysfs for navi10.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index d5ddf9c80818..582b99d8f832 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1223,7 +1223,7 @@ static int vega20_upload_dpm_level(struct smu_context *smu, bool max,
 }
 
 static int vega20_force_clk_levels(struct smu_context *smu,
-			enum pp_clock_type type, uint32_t mask)
+			enum  smu_clk_type clk_type, uint32_t mask)
 {
 	struct vega20_dpm_table *dpm_table;
 	struct vega20_single_dpm_table *single_dpm_table;
@@ -1243,8 +1243,8 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 
 	dpm_table = smu->smu_dpm.dpm_context;
 
-	switch (type) {
-	case PP_SCLK:
+	switch (clk_type) {
+	case SMU_SCLK:
 		single_dpm_table = &(dpm_table->gfx_table);
 
 		if (soft_max_level >= single_dpm_table->count) {
@@ -1271,7 +1271,7 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 
 		break;
 
-	case PP_MCLK:
+	case SMU_MCLK:
 		single_dpm_table = &(dpm_table->mem_table);
 
 		if (soft_max_level >= single_dpm_table->count) {
@@ -1298,7 +1298,7 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 
 		break;
 
-	case PP_SOCCLK:
+	case SMU_SOCCLK:
 		single_dpm_table = &(dpm_table->soc_table);
 
 		if (soft_max_level >= single_dpm_table->count) {
@@ -1325,7 +1325,7 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 
 		break;
 
-	case PP_FCLK:
+	case SMU_FCLK:
 		single_dpm_table = &(dpm_table->fclk_table);
 
 		if (soft_max_level >= single_dpm_table->count) {
@@ -1352,7 +1352,7 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 
 		break;
 
-	case PP_DCEFCLK:
+	case SMU_DCEFCLK:
 		hard_min_level = soft_min_level;
 		single_dpm_table = &(dpm_table->dcef_table);
 
@@ -1372,7 +1372,7 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 
 		break;
 
-	case PP_PCIE:
+	case SMU_PCIE:
 		if (soft_min_level >= NUM_LINK_LEVELS ||
 		    soft_max_level >= NUM_LINK_LEVELS) {
 			ret = -EINVAL;

commit b1e7e224192fb5d9f8534c35fe14fb5bf30cb08e
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Thu Apr 18 15:06:34 2019 +0800

    drm/amd/powerplay: add function print_clk_levels for navi10
    
    add sysfs interface of print_clk_levels sysfs for navi10.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 22e13a98148e..d5ddf9c80818 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -892,7 +892,7 @@ static int vega20_get_clk_table(struct smu_context *smu,
 }
 
 static int vega20_print_clk_levels(struct smu_context *smu,
-			enum pp_clock_type type, char *buf)
+			enum smu_clk_type type, char *buf)
 {
 	int i, now, size = 0;
 	int ret = 0;
@@ -912,7 +912,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 	dpm_table = smu_dpm->dpm_context;
 
 	switch (type) {
-	case PP_SCLK:
+	case SMU_SCLK:
 		ret = smu_get_current_clk_freq(smu, SMU_GFXCLK, &now);
 		if (ret) {
 			pr_err("Attempt to get current gfx clk Failed!");
@@ -933,7 +933,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 					? "*" : "");
 		break;
 
-	case PP_MCLK:
+	case SMU_MCLK:
 		ret = smu_get_current_clk_freq(smu, SMU_UCLK, &now);
 		if (ret) {
 			pr_err("Attempt to get current mclk Failed!");
@@ -954,7 +954,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 				? "*" : "");
 		break;
 
-	case PP_SOCCLK:
+	case SMU_SOCCLK:
 		ret = smu_get_current_clk_freq(smu, PPCLK_SOCCLK, &now);
 		if (ret) {
 			pr_err("Attempt to get current socclk Failed!");
@@ -975,7 +975,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 				? "*" : "");
 		break;
 
-	case PP_FCLK:
+	case SMU_FCLK:
 		ret = smu_get_current_clk_freq(smu, PPCLK_FCLK, &now);
 		if (ret) {
 			pr_err("Attempt to get current fclk Failed!");
@@ -990,7 +990,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 				? "*" : "");
 		break;
 
-	case PP_DCEFCLK:
+	case SMU_DCEFCLK:
 		ret = smu_get_current_clk_freq(smu, PPCLK_DCEFCLK, &now);
 		if (ret) {
 			pr_err("Attempt to get current dcefclk Failed!");
@@ -1010,7 +1010,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 				(clocks.data[i].clocks_in_khz == now * 10) ? "*" : "");
 		break;
 
-	case PP_PCIE:
+	case SMU_PCIE:
 		gen_speed = (RREG32_PCIE(smnPCIE_LC_SPEED_CNTL) &
 			     PSWUSP0_PCIE_LC_SPEED_CNTL__LC_CURRENT_DATA_RATE_MASK)
 			>> PSWUSP0_PCIE_LC_SPEED_CNTL__LC_CURRENT_DATA_RATE__SHIFT;
@@ -1035,7 +1035,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 					"*" : "");
 		break;
 
-	case OD_SCLK:
+	case SMU_OD_SCLK:
 		if (od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMIN].feature_id &&
 		    od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMAX].feature_id) {
 			size = sprintf(buf, "%s:\n", "OD_SCLK");
@@ -1047,7 +1047,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 
 		break;
 
-	case OD_MCLK:
+	case SMU_OD_MCLK:
 		if (od8_settings->od8_settings_array[OD8_SETTING_UCLK_FMAX].feature_id) {
 			size = sprintf(buf, "%s:\n", "OD_MCLK");
 			size += sprintf(buf + size, "1: %10uMhz\n",
@@ -1056,7 +1056,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 
 		break;
 
-	case OD_VDDC_CURVE:
+	case SMU_OD_VDDC_CURVE:
 		if (od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ1].feature_id &&
 		    od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ2].feature_id &&
 		    od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ3].feature_id &&
@@ -1077,7 +1077,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 
 		break;
 
-	case OD_RANGE:
+	case SMU_OD_RANGE:
 		size = sprintf(buf, "%s:\n", "OD_RANGE");
 
 		if (od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMIN].feature_id &&

commit 6a36e3e57c0cbcb9168cc1564ff37179cb110b52
Author: Huang Rui <ray.huang@amd.com>
Date:   Mon Apr 1 18:06:36 2019 +0800

    drm/amd/powerplay: move getting MAX_FAN_RPM value to asic level
    
    Getting MAX_FAN_RPM value needs to be read by pptable, so it should be moved to
    asic level.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index f11ff0335e49..22e13a98148e 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2950,6 +2950,8 @@ static int vega20_read_sensor(struct smu_context *smu,
 			      void *data, uint32_t *size)
 {
 	int ret = 0;
+	struct smu_table_context *table_context = &smu->smu_table;
+	PPTable_t *pptable = table_context->driver_pptable;
 
 	switch (sensor) {
 	case AMDGPU_PP_SENSOR_UVD_POWER:
@@ -2960,6 +2962,10 @@ static int vega20_read_sensor(struct smu_context *smu,
 		*(uint32_t *)data = smu_feature_is_enabled(smu, SMU_FEATURE_DPM_VCE_BIT) ? 1 : 0;
 		*size = 4;
 		break;
+	case AMDGPU_PP_SENSOR_MAX_FAN_RPM:
+		*(uint32_t *)data = pptable->FanMaximumRpm;
+		*size = 4;
+		break;
 	default:
 		return -EINVAL;
 	}

commit 8890fe5f435333c9f6ea7cd6b6de964c669602f4
Author: Huang Rui <ray.huang@amd.com>
Date:   Sun Mar 31 15:53:42 2019 +0800

    drm/amd/powerplay: introduce smu power source type to handle AC/DC source for each asic
    
    This patch introduces new smu power source type, it's to handle the different
    AC/DC source defines for each asic with the same smu ip.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 07abb047bf6b..f11ff0335e49 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -202,6 +202,11 @@ static int vega20_table_map[SMU_TABLE_COUNT] = {
 	TAB_MAP(OVERDRIVE),
 };
 
+static int vega20_pwr_src_map[SMU_POWER_SOURCE_COUNT] = {
+	PWR_MAP(AC),
+	PWR_MAP(DC),
+};
+
 static int vega20_get_smu_table_index(struct smu_context *smc, uint32_t index)
 {
 	int val;
@@ -215,6 +220,19 @@ static int vega20_get_smu_table_index(struct smu_context *smc, uint32_t index)
 	return val;
 }
 
+static int vega20_get_pwr_src_index(struct smu_context *smc, uint32_t index)
+{
+	int val;
+	if (index >= SMU_POWER_SOURCE_COUNT)
+		return -EINVAL;
+
+	val = vega20_pwr_src_map[index];
+	if (val >= POWER_SOURCE_COUNT)
+		return -EINVAL;
+
+	return val;
+}
+
 static int vega20_get_smu_feature_index(struct smu_context *smc, uint32_t index)
 {
 	int val;
@@ -3105,6 +3123,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_smu_clk_index = vega20_get_smu_clk_index,
 	.get_smu_feature_index = vega20_get_smu_feature_index,
 	.get_smu_table_index = vega20_get_smu_table_index,
+	.get_smu_power_index = vega20_get_pwr_src_index,
 	.run_afll_btc = vega20_run_btc_afll,
 	.get_allowed_feature_mask = vega20_get_allowed_feature_mask,
 	.get_current_power_state = vega20_get_current_power_state,

commit 973849042e0101d6dea1a4c00fdb2007128f86a6
Author: Huang Rui <ray.huang@amd.com>
Date:   Sun Mar 31 15:15:49 2019 +0800

    drm/amd/powerplay: move Watermarks_t uses into asic level
    
    This patch moves the rest of Watermarks_t uses into asic level. It's to avoid
    the conflicts with different asic.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 74b675c49537..07abb047bf6b 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -3035,6 +3035,66 @@ static int vega20_get_current_activity_percent(struct smu_context *smu,
 	return 0;
 }
 
+static int vega20_set_watermarks_table(struct smu_context *smu,
+				       void *watermarks, struct
+				       dm_pp_wm_sets_with_clock_ranges_soc15
+				       *clock_ranges)
+{
+	int i;
+	Watermarks_t *table = watermarks;
+
+	if (!table || !clock_ranges)
+		return -EINVAL;
+
+	if (clock_ranges->num_wm_dmif_sets > 4 ||
+	    clock_ranges->num_wm_mcif_sets > 4)
+		return -EINVAL;
+
+	for (i = 0; i < clock_ranges->num_wm_dmif_sets; i++) {
+		table->WatermarkRow[1][i].MinClock =
+			cpu_to_le16((uint16_t)
+			(clock_ranges->wm_dmif_clocks_ranges[i].wm_min_dcfclk_clk_in_khz /
+			1000));
+		table->WatermarkRow[1][i].MaxClock =
+			cpu_to_le16((uint16_t)
+			(clock_ranges->wm_dmif_clocks_ranges[i].wm_max_dcfclk_clk_in_khz /
+			1000));
+		table->WatermarkRow[1][i].MinUclk =
+			cpu_to_le16((uint16_t)
+			(clock_ranges->wm_dmif_clocks_ranges[i].wm_min_mem_clk_in_khz /
+			1000));
+		table->WatermarkRow[1][i].MaxUclk =
+			cpu_to_le16((uint16_t)
+			(clock_ranges->wm_dmif_clocks_ranges[i].wm_max_mem_clk_in_khz /
+			1000));
+		table->WatermarkRow[1][i].WmSetting = (uint8_t)
+				clock_ranges->wm_dmif_clocks_ranges[i].wm_set_id;
+	}
+
+	for (i = 0; i < clock_ranges->num_wm_mcif_sets; i++) {
+		table->WatermarkRow[0][i].MinClock =
+			cpu_to_le16((uint16_t)
+			(clock_ranges->wm_mcif_clocks_ranges[i].wm_min_socclk_clk_in_khz /
+			1000));
+		table->WatermarkRow[0][i].MaxClock =
+			cpu_to_le16((uint16_t)
+			(clock_ranges->wm_mcif_clocks_ranges[i].wm_max_socclk_clk_in_khz /
+			1000));
+		table->WatermarkRow[0][i].MinUclk =
+			cpu_to_le16((uint16_t)
+			(clock_ranges->wm_mcif_clocks_ranges[i].wm_min_mem_clk_in_khz /
+			1000));
+		table->WatermarkRow[0][i].MaxUclk =
+			cpu_to_le16((uint16_t)
+			(clock_ranges->wm_mcif_clocks_ranges[i].wm_max_mem_clk_in_khz /
+			1000));
+		table->WatermarkRow[0][i].WmSetting = (uint8_t)
+				clock_ranges->wm_mcif_clocks_ranges[i].wm_set_id;
+	}
+
+	return 0;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.tables_init = vega20_tables_init,
 	.alloc_dpm_context = vega20_allocate_dpm_context,
@@ -3082,6 +3142,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_fan_speed_percent = vega20_get_fan_speed_percent,
 	.get_gpu_power = vega20_get_gpu_power,
 	.get_current_activity_percent = vega20_get_current_activity_percent,
+	.set_watermarks_table = vega20_set_watermarks_table,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 8b1f4c87a30e6497ea646737e0b4d8ef854878a5
Author: Huang Rui <ray.huang@amd.com>
Date:   Sun Mar 31 14:53:23 2019 +0800

    drm/amd/powerplay: move SmuMetrics_t uses into asic level
    
    This patch moves the rest of SmuMetrics_t uses into asic level. It's to avoid the
    conflicts with different asic.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 2367bcc45468..74b675c49537 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2987,6 +2987,54 @@ static int vega20_get_fan_speed_percent(struct smu_context *smu,
 	return ret;
 }
 
+static int vega20_get_gpu_power(struct smu_context *smu, uint32_t *value)
+{
+	int ret = 0;
+	SmuMetrics_t metrics;
+
+	if (!value)
+		return -EINVAL;
+
+	ret = smu_update_table(smu, SMU_TABLE_SMU_METRICS, (void *)&metrics,
+			       false);
+	if (ret)
+		return ret;
+
+	*value = metrics.CurrSocketPower << 8;
+
+	return 0;
+}
+
+static int vega20_get_current_activity_percent(struct smu_context *smu,
+					       enum amd_pp_sensors sensor,
+					       uint32_t *value)
+{
+	int ret = 0;
+	SmuMetrics_t metrics;
+
+	if (!value)
+		return -EINVAL;
+
+	ret = smu_update_table(smu, SMU_TABLE_SMU_METRICS,
+			       (void *)&metrics, false);
+	if (ret)
+		return ret;
+
+	switch (sensor) {
+	case AMDGPU_PP_SENSOR_GPU_LOAD:
+		*value = metrics.AverageGfxActivity;
+		break;
+	case AMDGPU_PP_SENSOR_MEM_LOAD:
+		*value = metrics.AverageUclkActivity;
+		break;
+	default:
+		pr_err("Invalid sensor for retrieving clock activity\n");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.tables_init = vega20_tables_init,
 	.alloc_dpm_context = vega20_allocate_dpm_context,
@@ -3032,6 +3080,8 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.is_dpm_running = vega20_is_dpm_running,
 	.set_thermal_fan_table = vega20_set_thermal_fan_table,
 	.get_fan_speed_percent = vega20_get_fan_speed_percent,
+	.get_gpu_power = vega20_get_gpu_power,
+	.get_current_activity_percent = vega20_get_current_activity_percent,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit ee0db82027eef38d869d22cfa24a18d78b590db9
Author: Huang Rui <ray.huang@amd.com>
Date:   Sun Mar 31 13:25:04 2019 +0800

    drm/amd/powerplay: move PPTable_t uses into asic level
    
    This patch moves the rest of PPTable_t uses into asic level. It's to avoid the
    conflicts with different asic.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index d71b682002bd..2367bcc45468 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2960,6 +2960,33 @@ static bool vega20_is_dpm_running(struct smu_context *smu)
 	return !!(feature_enabled & SMC_DPM_FEATURE);
 }
 
+static int vega20_set_thermal_fan_table(struct smu_context *smu)
+{
+	int ret;
+	struct smu_table_context *table_context = &smu->smu_table;
+	PPTable_t *pptable = table_context->driver_pptable;
+
+	ret = smu_send_smc_msg_with_param(smu, SMU_MSG_SetFanTemperatureTarget,
+			(uint32_t)pptable->FanTargetTemperature);
+
+	return ret;
+}
+
+static int vega20_get_fan_speed_percent(struct smu_context *smu,
+					uint32_t *speed)
+{
+	int ret = 0;
+	uint32_t percent = 0;
+	uint32_t current_rpm;
+	PPTable_t *pptable = smu->smu_table.driver_pptable;
+
+	ret = smu_get_current_rpm(smu, &current_rpm);
+	percent = current_rpm * 100 / pptable->FanMaximumRpm;
+	*speed = percent > 100 ? 100 : percent;
+
+	return ret;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.tables_init = vega20_tables_init,
 	.alloc_dpm_context = vega20_allocate_dpm_context,
@@ -3003,6 +3030,8 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.set_ppfeature_status = vega20_set_ppfeature_status,
 	.get_ppfeature_status = vega20_get_ppfeature_status,
 	.is_dpm_running = vega20_is_dpm_running,
+	.set_thermal_fan_table = vega20_set_thermal_fan_table,
+	.get_fan_speed_percent = vega20_get_fan_speed_percent,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 22c9c6ca9658f75b45806eaf551c0b2736979fe3
Author: Huang Rui <ray.huang@amd.com>
Date:   Sun Mar 31 11:53:28 2019 +0800

    drm/amd/powerplay: add tables_init interface for each asic
    
    The smc tables defines should be in the asic level.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 17a954bd5aa4..d71b682002bd 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -255,6 +255,23 @@ static int vega20_get_smu_msg_index(struct smu_context *smc, uint32_t index)
 	return val;
 }
 
+static void vega20_tables_init(struct smu_context *smu, struct smu_table *tables)
+{
+	SMU_TABLE_INIT(tables, SMU_TABLE_PPTABLE, sizeof(PPTable_t),
+		       PAGE_SIZE, AMDGPU_GEM_DOMAIN_VRAM);
+	SMU_TABLE_INIT(tables, SMU_TABLE_WATERMARKS, sizeof(Watermarks_t),
+		       PAGE_SIZE, AMDGPU_GEM_DOMAIN_VRAM);
+	SMU_TABLE_INIT(tables, SMU_TABLE_SMU_METRICS, sizeof(SmuMetrics_t),
+		       PAGE_SIZE, AMDGPU_GEM_DOMAIN_VRAM);
+	SMU_TABLE_INIT(tables, SMU_TABLE_OVERDRIVE, sizeof(OverDriveTable_t),
+		       PAGE_SIZE, AMDGPU_GEM_DOMAIN_VRAM);
+	SMU_TABLE_INIT(tables, SMU_TABLE_PMSTATUSLOG, SMU11_TOOL_SIZE,
+		       PAGE_SIZE, AMDGPU_GEM_DOMAIN_VRAM);
+	SMU_TABLE_INIT(tables, SMU_TABLE_ACTIVITY_MONITOR_COEFF,
+		       sizeof(DpmActivityMonitorCoeffInt_t), PAGE_SIZE,
+	               AMDGPU_GEM_DOMAIN_VRAM);
+}
+
 static int vega20_allocate_dpm_context(struct smu_context *smu)
 {
 	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
@@ -2944,6 +2961,7 @@ static bool vega20_is_dpm_running(struct smu_context *smu)
 }
 
 static const struct pptable_funcs vega20_ppt_funcs = {
+	.tables_init = vega20_tables_init,
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
 	.check_powerplay_table = vega20_check_powerplay_table,

commit cdb0c632e4d0a6e882e585f458cb3448799d8ed7
Author: Huang Rui <ray.huang@amd.com>
Date:   Fri Mar 29 18:07:23 2019 +0800

    drm/amd/powerplay: init table_count for smu tables on asic level
    
    TABLE_COUNT should be inited in asic level. Because the value may be different
    on each asic even on the same ip.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 7cafbc942b2a..17a954bd5aa4 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2989,6 +2989,9 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 
 void vega20_set_ppt_funcs(struct smu_context *smu)
 {
+	struct smu_table_context *smu_table = &smu->smu_table;
+
 	smu->ppt_funcs = &vega20_ppt_funcs;
 	smu->smc_if_version = SMU11_DRIVER_IF_VERSION;
+	smu_table->table_count = TABLE_COUNT;
 }

commit 2436911bdb2c58f387af59e4e9dcd55c8f667868
Author: Huang Rui <ray.huang@amd.com>
Date:   Fri Mar 29 17:52:11 2019 +0800

    drm/amd/powerplay: introduce smu table id type to handle the smu table for each asic
    
    This patch introduces new smu table type, it's to handle the different smu table
    defines for each asic with the same smu ip.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 718fd4dec531..7cafbc942b2a 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -189,6 +189,32 @@ static int vega20_feature_mask_map[SMU_FEATURE_COUNT] = {
 	FEA_MAP(XGMI),
 };
 
+static int vega20_table_map[SMU_TABLE_COUNT] = {
+	TAB_MAP(PPTABLE),
+	TAB_MAP(WATERMARKS),
+	TAB_MAP(AVFS),
+	TAB_MAP(AVFS_PSM_DEBUG),
+	TAB_MAP(AVFS_FUSE_OVERRIDE),
+	TAB_MAP(PMSTATUSLOG),
+	TAB_MAP(SMU_METRICS),
+	TAB_MAP(DRIVER_SMU_CONFIG),
+	TAB_MAP(ACTIVITY_MONITOR_COEFF),
+	TAB_MAP(OVERDRIVE),
+};
+
+static int vega20_get_smu_table_index(struct smu_context *smc, uint32_t index)
+{
+	int val;
+	if (index >= SMU_TABLE_COUNT)
+		return -EINVAL;
+
+	val = vega20_table_map[index];
+	if (val >= TABLE_COUNT)
+		return -EINVAL;
+
+	return val;
+}
+
 static int vega20_get_smu_feature_index(struct smu_context *smc, uint32_t index)
 {
 	int val;
@@ -2925,6 +2951,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_smu_msg_index = vega20_get_smu_msg_index,
 	.get_smu_clk_index = vega20_get_smu_clk_index,
 	.get_smu_feature_index = vega20_get_smu_feature_index,
+	.get_smu_table_index = vega20_get_smu_table_index,
 	.run_afll_btc = vega20_run_btc_afll,
 	.get_allowed_feature_mask = vega20_get_allowed_feature_mask,
 	.get_current_power_state = vega20_get_current_power_state,

commit ffcb08dfaa3ae80292f89ee36b4604d3751ea4da
Author: Huang Rui <ray.huang@amd.com>
Date:   Wed May 29 23:14:33 2019 -0500

    drm/amd/powerplay: introduce smu feature type to handle feature mask for each asic
    
    This patch introduces new smu feature type, it's to handle the different feature
    mask defines for each asic with the same smu ip.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index b3fc9c034aa0..718fd4dec531 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -153,6 +153,55 @@ static int vega20_clk_map[SMU_CLK_COUNT] = {
 	CLK_MAP(FCLK, PPCLK_FCLK),
 };
 
+static int vega20_feature_mask_map[SMU_FEATURE_COUNT] = {
+	FEA_MAP(DPM_PREFETCHER),
+	FEA_MAP(DPM_GFXCLK),
+	FEA_MAP(DPM_UCLK),
+	FEA_MAP(DPM_SOCCLK),
+	FEA_MAP(DPM_UVD),
+	FEA_MAP(DPM_VCE),
+	FEA_MAP(ULV),
+	FEA_MAP(DPM_MP0CLK),
+	FEA_MAP(DPM_LINK),
+	FEA_MAP(DPM_DCEFCLK),
+	FEA_MAP(DS_GFXCLK),
+	FEA_MAP(DS_SOCCLK),
+	FEA_MAP(DS_LCLK),
+	FEA_MAP(PPT),
+	FEA_MAP(TDC),
+	FEA_MAP(THERMAL),
+	FEA_MAP(GFX_PER_CU_CG),
+	FEA_MAP(RM),
+	FEA_MAP(DS_DCEFCLK),
+	FEA_MAP(ACDC),
+	FEA_MAP(VR0HOT),
+	FEA_MAP(VR1HOT),
+	FEA_MAP(FW_CTF),
+	FEA_MAP(LED_DISPLAY),
+	FEA_MAP(FAN_CONTROL),
+	FEA_MAP(GFX_EDC),
+	FEA_MAP(GFXOFF),
+	FEA_MAP(CG),
+	FEA_MAP(DPM_FCLK),
+	FEA_MAP(DS_FCLK),
+	FEA_MAP(DS_MP1CLK),
+	FEA_MAP(DS_MP0CLK),
+	FEA_MAP(XGMI),
+};
+
+static int vega20_get_smu_feature_index(struct smu_context *smc, uint32_t index)
+{
+	int val;
+	if (index >= SMU_FEATURE_COUNT)
+		return -EINVAL;
+
+	val = vega20_feature_mask_map[index];
+	if (val > 64)
+		return -EINVAL;
+
+	return val;
+}
+
 static int vega20_get_smu_clk_index(struct smu_context *smc, uint32_t index)
 {
 	int val;
@@ -565,7 +614,7 @@ static int vega20_set_default_dpm_table(struct smu_context *smu)
 	/* socclk */
 	single_dpm_table = &(dpm_table->soc_table);
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_SOCCLK_BIT)) {
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_SOCCLK_BIT)) {
 		ret = vega20_set_single_dpm_table(smu, single_dpm_table,
 						  PPCLK_SOCCLK);
 		if (ret) {
@@ -581,7 +630,7 @@ static int vega20_set_default_dpm_table(struct smu_context *smu)
 	/* gfxclk */
 	single_dpm_table = &(dpm_table->gfx_table);
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_GFXCLK_BIT)) {
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_GFXCLK_BIT)) {
 		ret = vega20_set_single_dpm_table(smu, single_dpm_table,
 						  PPCLK_GFXCLK);
 		if (ret) {
@@ -597,7 +646,7 @@ static int vega20_set_default_dpm_table(struct smu_context *smu)
 	/* memclk */
 	single_dpm_table = &(dpm_table->mem_table);
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT)) {
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_UCLK_BIT)) {
 		ret = vega20_set_single_dpm_table(smu, single_dpm_table,
 						  PPCLK_UCLK);
 		if (ret) {
@@ -613,7 +662,7 @@ static int vega20_set_default_dpm_table(struct smu_context *smu)
 	/* eclk */
 	single_dpm_table = &(dpm_table->eclk_table);
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_VCE_BIT)) {
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_VCE_BIT)) {
 		ret = vega20_set_single_dpm_table(smu, single_dpm_table, PPCLK_ECLK);
 		if (ret) {
 			pr_err("[SetupDefaultDpmTable] failed to get eclk dpm levels!");
@@ -628,7 +677,7 @@ static int vega20_set_default_dpm_table(struct smu_context *smu)
 	/* vclk */
 	single_dpm_table = &(dpm_table->vclk_table);
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_UVD_BIT)) {
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_UVD_BIT)) {
 		ret = vega20_set_single_dpm_table(smu, single_dpm_table, PPCLK_VCLK);
 		if (ret) {
 			pr_err("[SetupDefaultDpmTable] failed to get vclk dpm levels!");
@@ -643,7 +692,7 @@ static int vega20_set_default_dpm_table(struct smu_context *smu)
 	/* dclk */
 	single_dpm_table = &(dpm_table->dclk_table);
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_UVD_BIT)) {
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_UVD_BIT)) {
 		ret = vega20_set_single_dpm_table(smu, single_dpm_table, PPCLK_DCLK);
 		if (ret) {
 			pr_err("[SetupDefaultDpmTable] failed to get dclk dpm levels!");
@@ -658,7 +707,7 @@ static int vega20_set_default_dpm_table(struct smu_context *smu)
 	/* dcefclk */
 	single_dpm_table = &(dpm_table->dcef_table);
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_DCEFCLK_BIT)) {
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_DCEFCLK_BIT)) {
 		ret = vega20_set_single_dpm_table(smu, single_dpm_table,
 						  PPCLK_DCEFCLK);
 		if (ret) {
@@ -674,7 +723,7 @@ static int vega20_set_default_dpm_table(struct smu_context *smu)
 	/* pixclk */
 	single_dpm_table = &(dpm_table->pixel_table);
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_DCEFCLK_BIT)) {
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_DCEFCLK_BIT)) {
 		ret = vega20_set_single_dpm_table(smu, single_dpm_table,
 						  PPCLK_PIXCLK);
 		if (ret) {
@@ -689,7 +738,7 @@ static int vega20_set_default_dpm_table(struct smu_context *smu)
 	/* dispclk */
 	single_dpm_table = &(dpm_table->display_table);
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_DCEFCLK_BIT)) {
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_DCEFCLK_BIT)) {
 		ret = vega20_set_single_dpm_table(smu, single_dpm_table,
 						  PPCLK_DISPCLK);
 		if (ret) {
@@ -704,7 +753,7 @@ static int vega20_set_default_dpm_table(struct smu_context *smu)
 	/* phyclk */
 	single_dpm_table = &(dpm_table->phy_table);
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_DCEFCLK_BIT)) {
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_DCEFCLK_BIT)) {
 		ret = vega20_set_single_dpm_table(smu, single_dpm_table,
 						  PPCLK_PHYCLK);
 		if (ret) {
@@ -1034,7 +1083,7 @@ static int vega20_upload_dpm_level(struct smu_context *smu, bool max,
 
 	dpm_table = smu->smu_dpm.dpm_context;
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_GFXCLK_BIT) &&
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_GFXCLK_BIT) &&
 	    (feature_mask & FEATURE_DPM_GFXCLK_MASK)) {
 		single_dpm_table = &(dpm_table->gfx_table);
 		freq = max ? single_dpm_table->dpm_state.soft_max_level :
@@ -1049,7 +1098,7 @@ static int vega20_upload_dpm_level(struct smu_context *smu, bool max,
 		}
 	}
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT) &&
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_UCLK_BIT) &&
 	    (feature_mask & FEATURE_DPM_UCLK_MASK)) {
 		single_dpm_table = &(dpm_table->mem_table);
 		freq = max ? single_dpm_table->dpm_state.soft_max_level :
@@ -1064,7 +1113,7 @@ static int vega20_upload_dpm_level(struct smu_context *smu, bool max,
 		}
 	}
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_SOCCLK_BIT) &&
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_SOCCLK_BIT) &&
 	    (feature_mask & FEATURE_DPM_SOCCLK_MASK)) {
 		single_dpm_table = &(dpm_table->soc_table);
 		freq = max ? single_dpm_table->dpm_state.soft_max_level :
@@ -1079,7 +1128,7 @@ static int vega20_upload_dpm_level(struct smu_context *smu, bool max,
 		}
 	}
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_FCLK_BIT) &&
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_FCLK_BIT) &&
 	    (feature_mask & FEATURE_DPM_FCLK_MASK)) {
 		single_dpm_table = &(dpm_table->fclk_table);
 		freq = max ? single_dpm_table->dpm_state.soft_max_level :
@@ -1094,7 +1143,7 @@ static int vega20_upload_dpm_level(struct smu_context *smu, bool max,
 		}
 	}
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_DCEFCLK_BIT) &&
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_DCEFCLK_BIT) &&
 	    (feature_mask & FEATURE_DPM_DCEFCLK_MASK)) {
 		single_dpm_table = &(dpm_table->dcef_table);
 		freq = single_dpm_table->dpm_state.hard_min_level;
@@ -1360,7 +1409,7 @@ static int vega20_set_default_od8_setttings(struct smu_context *smu)
 
 	od8_settings = (struct vega20_od8_settings *)table_context->od8_settings;
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_SOCCLK_BIT)) {
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_SOCCLK_BIT)) {
 		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_GFXCLK_LIMITS] &&
 		    table_context->od_settings_max[OD8_SETTING_GFXCLK_FMAX] > 0 &&
 		    table_context->od_settings_min[OD8_SETTING_GFXCLK_FMIN] > 0 &&
@@ -1433,7 +1482,7 @@ static int vega20_set_default_od8_setttings(struct smu_context *smu)
 		}
 	}
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT)) {
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_UCLK_BIT)) {
 		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_UCLK_MAX] &&
 		    table_context->od_settings_min[OD8_SETTING_UCLK_FMAX] > 0 &&
 		    table_context->od_settings_max[OD8_SETTING_UCLK_FMAX] > 0 &&
@@ -1457,7 +1506,7 @@ static int vega20_set_default_od8_setttings(struct smu_context *smu)
 			od_table->OverDrivePct;
 	}
 
-	if (smu_feature_is_enabled(smu, FEATURE_FAN_CONTROL_BIT)) {
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_FAN_CONTROL_BIT)) {
 		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_FAN_ACOUSTIC_LIMIT] &&
 		    table_context->od_settings_min[OD8_SETTING_FAN_ACOUSTIC_LIMIT] > 0 &&
 		    table_context->od_settings_max[OD8_SETTING_FAN_ACOUSTIC_LIMIT] > 0 &&
@@ -1481,7 +1530,7 @@ static int vega20_set_default_od8_setttings(struct smu_context *smu)
 		}
 	}
 
-	if (smu_feature_is_enabled(smu, FEATURE_THERMAL_BIT)) {
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_THERMAL_BIT)) {
 		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_TEMPERATURE_FAN] &&
 		    table_context->od_settings_min[OD8_SETTING_FAN_TARGET_TEMP] > 0 &&
 		    table_context->od_settings_max[OD8_SETTING_FAN_TARGET_TEMP] > 0 &&
@@ -1838,7 +1887,7 @@ vega20_set_uclk_to_highest_dpm_level(struct smu_context *smu,
 	if (!smu_dpm_ctx->dpm_context)
 		return -EINVAL;
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT)) {
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_UCLK_BIT)) {
 		if (dpm_table->count <= 0) {
 			pr_err("[%s] Dpm table has no entry!", __func__);
 				return -EINVAL;
@@ -1901,8 +1950,8 @@ static int vega20_display_config_changed(struct smu_context *smu)
 	}
 
 	if ((smu->watermarks_bitmap & WATERMARKS_EXIST) &&
-	    smu_feature_is_supported(smu, FEATURE_DPM_DCEFCLK_BIT) &&
-	    smu_feature_is_supported(smu, FEATURE_DPM_SOCCLK_BIT)) {
+	    smu_feature_is_supported(smu, SMU_FEATURE_DPM_DCEFCLK_BIT) &&
+	    smu_feature_is_supported(smu, SMU_FEATURE_DPM_SOCCLK_BIT)) {
 		smu_send_smc_msg_with_param(smu,
 					    SMU_MSG_NumOfDisplays,
 					    smu->display_config->num_display);
@@ -2071,11 +2120,11 @@ vega20_notify_smc_dispaly_config(struct smu_context *smu)
 	min_clocks.dcef_clock_in_sr = smu->display_config->min_dcef_deep_sleep_set_clk;
 	min_clocks.memory_clock = smu->display_config->min_mem_set_clock;
 
-	if (smu_feature_is_supported(smu, FEATURE_DPM_DCEFCLK_BIT)) {
+	if (smu_feature_is_supported(smu, SMU_FEATURE_DPM_DCEFCLK_BIT)) {
 		clock_req.clock_type = amd_pp_dcef_clock;
 		clock_req.clock_freq_in_khz = min_clocks.dcef_clock * 10;
 		if (!smu->funcs->display_clock_voltage_request(smu, &clock_req)) {
-			if (smu_feature_is_supported(smu, FEATURE_DS_DCEFCLK_BIT)) {
+			if (smu_feature_is_supported(smu, SMU_FEATURE_DS_DCEFCLK_BIT)) {
 				ret = smu_send_smc_msg_with_param(smu,
 								  SMU_MSG_SetMinDeepSleepDcefclk,
 								  min_clocks.dcef_clock_in_sr/100);
@@ -2089,7 +2138,7 @@ vega20_notify_smc_dispaly_config(struct smu_context *smu)
 		}
 	}
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT)) {
+	if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_UCLK_BIT)) {
 		memtable->dpm_state.hard_min_level = min_clocks.memory_clock/100;
 		ret = smu_send_smc_msg_with_param(smu,
 						  SMU_MSG_SetHardMinByFreq,
@@ -2382,14 +2431,14 @@ static int vega20_set_od_percentage(struct smu_context *smu,
 	case OD_SCLK:
 		single_dpm_table = &(dpm_table->gfx_table);
 		golden_dpm_table = &(golden_table->gfx_table);
-		feature_enabled = smu_feature_is_enabled(smu, FEATURE_DPM_GFXCLK_BIT);
+		feature_enabled = smu_feature_is_enabled(smu, SMU_FEATURE_DPM_GFXCLK_BIT);
 		clk_id = PPCLK_GFXCLK;
 		index = OD8_SETTING_GFXCLK_FMAX;
 		break;
 	case OD_MCLK:
 		single_dpm_table = &(dpm_table->mem_table);
 		golden_dpm_table = &(golden_table->mem_table);
-		feature_enabled = smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT);
+		feature_enabled = smu_feature_is_enabled(smu, SMU_FEATURE_DPM_UCLK_BIT);
 		clk_id = PPCLK_UCLK;
 		index = OD8_SETTING_UCLK_FMAX;
 		break;
@@ -2633,7 +2682,7 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 			table_context->od_gfxclk_update = false;
 			single_dpm_table = &(dpm_table->gfx_table);
 
-			if (smu_feature_is_enabled(smu, FEATURE_DPM_GFXCLK_BIT)) {
+			if (smu_feature_is_enabled(smu, SMU_FEATURE_DPM_GFXCLK_BIT)) {
 				ret = vega20_set_single_dpm_table(smu, single_dpm_table,
 								  PPCLK_GFXCLK);
 				if (ret) {
@@ -2664,24 +2713,24 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 
 static int vega20_dpm_set_uvd_enable(struct smu_context *smu, bool enable)
 {
-	if (!smu_feature_is_supported(smu, FEATURE_DPM_UVD_BIT))
+	if (!smu_feature_is_supported(smu, SMU_FEATURE_DPM_UVD_BIT))
 		return 0;
 
-	if (enable == smu_feature_is_enabled(smu, FEATURE_DPM_UVD_BIT))
+	if (enable == smu_feature_is_enabled(smu, SMU_FEATURE_DPM_UVD_BIT))
 		return 0;
 
-	return smu_feature_set_enabled(smu, FEATURE_DPM_UVD_BIT, enable);
+	return smu_feature_set_enabled(smu, SMU_FEATURE_DPM_UVD_BIT, enable);
 }
 
 static int vega20_dpm_set_vce_enable(struct smu_context *smu, bool enable)
 {
-	if (!smu_feature_is_supported(smu, FEATURE_DPM_VCE_BIT))
+	if (!smu_feature_is_supported(smu, SMU_FEATURE_DPM_VCE_BIT))
 		return 0;
 
-	if (enable == smu_feature_is_enabled(smu, FEATURE_DPM_VCE_BIT))
+	if (enable == smu_feature_is_enabled(smu, SMU_FEATURE_DPM_VCE_BIT))
 		return 0;
 
-	return smu_feature_set_enabled(smu, FEATURE_DPM_VCE_BIT, enable);
+	return smu_feature_set_enabled(smu, SMU_FEATURE_DPM_VCE_BIT, enable);
 }
 
 static int vega20_get_enabled_smc_features(struct smu_context *smu,
@@ -2843,11 +2892,11 @@ static int vega20_read_sensor(struct smu_context *smu,
 
 	switch (sensor) {
 	case AMDGPU_PP_SENSOR_UVD_POWER:
-		*(uint32_t *)data = smu_feature_is_enabled(smu, FEATURE_DPM_UVD_BIT) ? 1 : 0;
+		*(uint32_t *)data = smu_feature_is_enabled(smu, SMU_FEATURE_DPM_UVD_BIT) ? 1 : 0;
 		*size = 4;
 		break;
 	case AMDGPU_PP_SENSOR_VCE_POWER:
-		*(uint32_t *)data = smu_feature_is_enabled(smu, FEATURE_DPM_VCE_BIT) ? 1 : 0;
+		*(uint32_t *)data = smu_feature_is_enabled(smu, SMU_FEATURE_DPM_VCE_BIT) ? 1 : 0;
 		*size = 4;
 		break;
 	default:
@@ -2875,6 +2924,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.append_powerplay_table = vega20_append_powerplay_table,
 	.get_smu_msg_index = vega20_get_smu_msg_index,
 	.get_smu_clk_index = vega20_get_smu_clk_index,
+	.get_smu_feature_index = vega20_get_smu_feature_index,
 	.run_afll_btc = vega20_run_btc_afll,
 	.get_allowed_feature_mask = vega20_get_allowed_feature_mask,
 	.get_current_power_state = vega20_get_current_power_state,

commit 0de94acf90e3ac61a11782cbb2394799bba4c96d
Author: Huang Rui <ray.huang@amd.com>
Date:   Sun Mar 24 19:22:07 2019 +0800

    drm/amd/powerplay: introduce smu clk type to handle ppclk for each asic
    
    This patch introduces new smu clk type, it's to handle the different ppclk
    defines for each asic with the same smu ip.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 7e6148ab134b..b3fc9c034aa0 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -139,6 +139,33 @@ static int vega20_message_map[SMU_MSG_MAX_COUNT] = {
 	MSG_MAP(GetAVFSVoltageByDpm),
 };
 
+static int vega20_clk_map[SMU_CLK_COUNT] = {
+	CLK_MAP(GFXCLK, PPCLK_GFXCLK),
+	CLK_MAP(VCLK, PPCLK_VCLK),
+	CLK_MAP(DCLK, PPCLK_DCLK),
+	CLK_MAP(ECLK, PPCLK_ECLK),
+	CLK_MAP(SOCCLK, PPCLK_SOCCLK),
+	CLK_MAP(UCLK, PPCLK_UCLK),
+	CLK_MAP(DCEFCLK, PPCLK_DCEFCLK),
+	CLK_MAP(DISPCLK, PPCLK_DISPCLK),
+	CLK_MAP(PIXCLK, PPCLK_PIXCLK),
+	CLK_MAP(PHYCLK, PPCLK_PHYCLK),
+	CLK_MAP(FCLK, PPCLK_FCLK),
+};
+
+static int vega20_get_smu_clk_index(struct smu_context *smc, uint32_t index)
+{
+	int val;
+	if (index >= SMU_CLK_COUNT)
+		return -EINVAL;
+
+	val = vega20_clk_map[index];
+	if (val >= PPCLK_COUNT)
+		return -EINVAL;
+
+	return val;
+}
+
 static int vega20_get_smu_msg_index(struct smu_context *smc, uint32_t index)
 {
 	int val;
@@ -776,7 +803,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 
 	switch (type) {
 	case PP_SCLK:
-		ret = smu_get_current_clk_freq(smu, PPCLK_GFXCLK, &now);
+		ret = smu_get_current_clk_freq(smu, SMU_GFXCLK, &now);
 		if (ret) {
 			pr_err("Attempt to get current gfx clk Failed!");
 			return ret;
@@ -797,7 +824,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 		break;
 
 	case PP_MCLK:
-		ret = smu_get_current_clk_freq(smu, PPCLK_UCLK, &now);
+		ret = smu_get_current_clk_freq(smu, SMU_UCLK, &now);
 		if (ret) {
 			pr_err("Attempt to get current mclk Failed!");
 			return ret;
@@ -2847,6 +2874,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.check_powerplay_table = vega20_check_powerplay_table,
 	.append_powerplay_table = vega20_append_powerplay_table,
 	.get_smu_msg_index = vega20_get_smu_msg_index,
+	.get_smu_clk_index = vega20_get_smu_clk_index,
 	.run_afll_btc = vega20_run_btc_afll,
 	.get_allowed_feature_mask = vega20_get_allowed_feature_mask,
 	.get_current_power_state = vega20_get_current_power_state,

commit 74c958a3766cd1948978a60cc995c17145a5eed8
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Tue Mar 19 17:20:09 2019 +0800

    drm/amd/powerplay: optimization feature mask function for asic
    
    1.change function return value type: from "unallowed" to "allowed"
    2.replace feature mask number with feature macro, the code will clear.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kenneth Feng <kenneth.feng@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index e070c7e7cdb7..7e6148ab134b 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -402,16 +402,42 @@ static int vega20_run_btc_afll(struct smu_context *smu)
 	return smu_send_smc_msg(smu, SMU_MSG_RunAfllBtc);
 }
 
+#define FEATURE_MASK(feature) (1UL << feature)
 static int
-vega20_get_unallowed_feature_mask(struct smu_context *smu,
+vega20_get_allowed_feature_mask(struct smu_context *smu,
 				  uint32_t *feature_mask, uint32_t num)
 {
 	if (num > 2)
 		return -EINVAL;
 
-	feature_mask[0] = 0xE0041C00;
-	feature_mask[1] = 0xFFFFFFFE; /* bit32~bit63 is Unsupported */
-
+	memset(feature_mask, 0, sizeof(uint32_t) * num);
+
+	*(uint64_t *)feature_mask |= FEATURE_MASK(FEATURE_DPM_PREFETCHER_BIT)
+				| FEATURE_MASK(FEATURE_DPM_GFXCLK_BIT)
+				| FEATURE_MASK(FEATURE_DPM_UCLK_BIT)
+				| FEATURE_MASK(FEATURE_DPM_SOCCLK_BIT)
+				| FEATURE_MASK(FEATURE_DPM_UVD_BIT)
+				| FEATURE_MASK(FEATURE_DPM_VCE_BIT)
+				| FEATURE_MASK(FEATURE_ULV_BIT)
+				| FEATURE_MASK(FEATURE_DPM_MP0CLK_BIT)
+				| FEATURE_MASK(FEATURE_DPM_LINK_BIT)
+				| FEATURE_MASK(FEATURE_DPM_DCEFCLK_BIT)
+				| FEATURE_MASK(FEATURE_PPT_BIT)
+				| FEATURE_MASK(FEATURE_TDC_BIT)
+				| FEATURE_MASK(FEATURE_THERMAL_BIT)
+				| FEATURE_MASK(FEATURE_GFX_PER_CU_CG_BIT)
+				| FEATURE_MASK(FEATURE_RM_BIT)
+				| FEATURE_MASK(FEATURE_ACDC_BIT)
+				| FEATURE_MASK(FEATURE_VR0HOT_BIT)
+				| FEATURE_MASK(FEATURE_VR1HOT_BIT)
+				| FEATURE_MASK(FEATURE_FW_CTF_BIT)
+				| FEATURE_MASK(FEATURE_LED_DISPLAY_BIT)
+				| FEATURE_MASK(FEATURE_FAN_CONTROL_BIT)
+				| FEATURE_MASK(FEATURE_GFX_EDC_BIT)
+				| FEATURE_MASK(FEATURE_GFXOFF_BIT)
+				| FEATURE_MASK(FEATURE_CG_BIT)
+				| FEATURE_MASK(FEATURE_DPM_FCLK_BIT)
+				| FEATURE_MASK(FEATURE_XGMI_BIT);
 	return 0;
 }
 
@@ -2822,7 +2848,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.append_powerplay_table = vega20_append_powerplay_table,
 	.get_smu_msg_index = vega20_get_smu_msg_index,
 	.run_afll_btc = vega20_run_btc_afll,
-	.get_unallowed_feature_mask = vega20_get_unallowed_feature_mask,
+	.get_allowed_feature_mask = vega20_get_allowed_feature_mask,
 	.get_current_power_state = vega20_get_current_power_state,
 	.set_default_dpm_table = vega20_set_default_dpm_table,
 	.set_power_state = NULL,

commit e17980535bca652e733eed910c0a434a5524885d
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Tue Mar 5 15:42:16 2019 +0800

    drm/amd/powerplay: move the function of is_dpm_running to asic file
    
    the function os is_dpm_running is aisc related function,
    so move them to asic file.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 06f91969cf76..e070c7e7cdb7 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -43,6 +43,16 @@
 #define MSG_MAP(msg) \
 	[SMU_MSG_##msg] = PPSMC_MSG_##msg
 
+#define SMC_DPM_FEATURE (FEATURE_DPM_PREFETCHER_MASK | \
+			 FEATURE_DPM_GFXCLK_MASK | \
+			 FEATURE_DPM_UCLK_MASK | \
+			 FEATURE_DPM_SOCCLK_MASK | \
+			 FEATURE_DPM_UVD_MASK | \
+			 FEATURE_DPM_VCE_MASK | \
+			 FEATURE_DPM_MP0CLK_MASK | \
+			 FEATURE_DPM_LINK_MASK | \
+			 FEATURE_DPM_DCEFCLK_MASK)
+
 static int vega20_message_map[SMU_MSG_MAX_COUNT] = {
 	MSG_MAP(TestMessage),
 	MSG_MAP(GetSmuVersion),
@@ -2794,6 +2804,17 @@ static int vega20_read_sensor(struct smu_context *smu,
 	return ret;
 }
 
+static bool vega20_is_dpm_running(struct smu_context *smu)
+{
+	int ret = 0;
+	uint32_t feature_mask[2];
+	unsigned long feature_enabled;
+	ret = smu_feature_get_enabled_mask(smu, feature_mask, 2);
+	feature_enabled = (unsigned long)((uint64_t)feature_mask[0] |
+			   ((uint64_t)feature_mask[1] << 32));
+	return !!(feature_enabled & SMC_DPM_FEATURE);
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
@@ -2832,6 +2853,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_profiling_clk_mask = vega20_get_profiling_clk_mask,
 	.set_ppfeature_status = vega20_set_ppfeature_status,
 	.get_ppfeature_status = vega20_get_ppfeature_status,
+	.is_dpm_running = vega20_is_dpm_running,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 6d22f1aa924c6012e4107b40b111c21b9d2b5c0d
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Tue Mar 5 14:16:12 2019 +0800

    drm/amd/powerplay: move the function of read_sensor to asic file
    
    The read_sensor functions has asic related parts code,
    so move them to asic file to implement.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 31c104233323..06f91969cf76 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2772,6 +2772,28 @@ static int vega20_set_ppfeature_status(struct smu_context *smu, uint64_t new_ppf
 	return 0;
 }
 
+static int vega20_read_sensor(struct smu_context *smu,
+			      enum amd_pp_sensors sensor,
+			      void *data, uint32_t *size)
+{
+	int ret = 0;
+
+	switch (sensor) {
+	case AMDGPU_PP_SENSOR_UVD_POWER:
+		*(uint32_t *)data = smu_feature_is_enabled(smu, FEATURE_DPM_UVD_BIT) ? 1 : 0;
+		*size = 4;
+		break;
+	case AMDGPU_PP_SENSOR_VCE_POWER:
+		*(uint32_t *)data = smu_feature_is_enabled(smu, FEATURE_DPM_VCE_BIT) ? 1 : 0;
+		*size = 4;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return ret;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
@@ -2799,6 +2821,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.od_edit_dpm_table = vega20_odn_edit_dpm_table,
 	.dpm_set_uvd_enable = vega20_dpm_set_uvd_enable,
 	.dpm_set_vce_enable = vega20_dpm_set_vce_enable,
+	.read_sensor = vega20_read_sensor,
 	.pre_display_config_changed = vega20_pre_display_config_changed,
 	.display_config_changed = vega20_display_config_changed,
 	.apply_clocks_adjust_rules = vega20_apply_clocks_adjust_rules,

commit 86eb3ed3d393678a0ba625138658b755adbda357
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Wed May 29 23:11:28 2019 -0500

    drm/amd/powerplay: move the function of uvd&vce dpm to asic file
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 10a70f8c7e9b..31c104233323 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2599,6 +2599,28 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 	return ret;
 }
 
+static int vega20_dpm_set_uvd_enable(struct smu_context *smu, bool enable)
+{
+	if (!smu_feature_is_supported(smu, FEATURE_DPM_UVD_BIT))
+		return 0;
+
+	if (enable == smu_feature_is_enabled(smu, FEATURE_DPM_UVD_BIT))
+		return 0;
+
+	return smu_feature_set_enabled(smu, FEATURE_DPM_UVD_BIT, enable);
+}
+
+static int vega20_dpm_set_vce_enable(struct smu_context *smu, bool enable)
+{
+	if (!smu_feature_is_supported(smu, FEATURE_DPM_VCE_BIT))
+		return 0;
+
+	if (enable == smu_feature_is_enabled(smu, FEATURE_DPM_VCE_BIT))
+		return 0;
+
+	return smu_feature_set_enabled(smu, FEATURE_DPM_VCE_BIT, enable);
+}
+
 static int vega20_get_enabled_smc_features(struct smu_context *smu,
 		uint64_t *features_enabled)
 {
@@ -2775,6 +2797,8 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.update_specified_od8_value = vega20_update_specified_od8_value,
 	.set_od_percentage = vega20_set_od_percentage,
 	.od_edit_dpm_table = vega20_odn_edit_dpm_table,
+	.dpm_set_uvd_enable = vega20_dpm_set_uvd_enable,
+	.dpm_set_vce_enable = vega20_dpm_set_vce_enable,
 	.pre_display_config_changed = vega20_pre_display_config_changed,
 	.display_config_changed = vega20_display_config_changed,
 	.apply_clocks_adjust_rules = vega20_apply_clocks_adjust_rules,

commit 667273c166e98e3e38e6ac1f2b69950309bc42a5
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Wed May 29 23:09:06 2019 -0500

    drm/amd/powerplay: move the function of get[set]_power_profile to asic file
    
    The callback of get[set]_power_profile is asic related function,
    so move theme into vega20_ppt file.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 3243928b6ee2..10a70f8c7e9b 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1527,6 +1527,201 @@ static int vega20_conv_profile_to_workload(struct smu_context *smu, int power_pr
 	return pplib_workload;
 }
 
+static int vega20_get_power_profile_mode(struct smu_context *smu, char *buf)
+{
+	DpmActivityMonitorCoeffInt_t activity_monitor;
+	uint32_t i, size = 0;
+	uint16_t workload_type = 0;
+	static const char *profile_name[] = {
+					"BOOTUP_DEFAULT",
+					"3D_FULL_SCREEN",
+					"POWER_SAVING",
+					"VIDEO",
+					"VR",
+					"COMPUTE",
+					"CUSTOM"};
+	static const char *title[] = {
+			"PROFILE_INDEX(NAME)",
+			"CLOCK_TYPE(NAME)",
+			"FPS",
+			"UseRlcBusy",
+			"MinActiveFreqType",
+			"MinActiveFreq",
+			"BoosterFreqType",
+			"BoosterFreq",
+			"PD_Data_limit_c",
+			"PD_Data_error_coeff",
+			"PD_Data_error_rate_coeff"};
+	int result = 0;
+
+	if (!smu->pm_enabled || !buf)
+		return -EINVAL;
+
+	size += sprintf(buf + size, "%16s %s %s %s %s %s %s %s %s %s %s\n",
+			title[0], title[1], title[2], title[3], title[4], title[5],
+			title[6], title[7], title[8], title[9], title[10]);
+
+	for (i = 0; i <= PP_SMC_POWER_PROFILE_CUSTOM; i++) {
+		/* conv PP_SMC_POWER_PROFILE* to WORKLOAD_PPLIB_*_BIT */
+		workload_type = smu_conv_profile_to_workload(smu, i);
+		result = smu_update_table(smu,
+					  TABLE_ACTIVITY_MONITOR_COEFF | workload_type << 16,
+					  (void *)(&activity_monitor), false);
+		if (result) {
+			pr_err("[%s] Failed to get activity monitor!", __func__);
+			return result;
+		}
+
+		size += sprintf(buf + size, "%2d %14s%s:\n",
+			i, profile_name[i], (i == smu->power_profile_mode) ? "*" : " ");
+
+		size += sprintf(buf + size, "%19s %d(%13s) %7d %7d %7d %7d %7d %7d %7d %7d %7d\n",
+			" ",
+			0,
+			"GFXCLK",
+			activity_monitor.Gfx_FPS,
+			activity_monitor.Gfx_UseRlcBusy,
+			activity_monitor.Gfx_MinActiveFreqType,
+			activity_monitor.Gfx_MinActiveFreq,
+			activity_monitor.Gfx_BoosterFreqType,
+			activity_monitor.Gfx_BoosterFreq,
+			activity_monitor.Gfx_PD_Data_limit_c,
+			activity_monitor.Gfx_PD_Data_error_coeff,
+			activity_monitor.Gfx_PD_Data_error_rate_coeff);
+
+		size += sprintf(buf + size, "%19s %d(%13s) %7d %7d %7d %7d %7d %7d %7d %7d %7d\n",
+			" ",
+			1,
+			"SOCCLK",
+			activity_monitor.Soc_FPS,
+			activity_monitor.Soc_UseRlcBusy,
+			activity_monitor.Soc_MinActiveFreqType,
+			activity_monitor.Soc_MinActiveFreq,
+			activity_monitor.Soc_BoosterFreqType,
+			activity_monitor.Soc_BoosterFreq,
+			activity_monitor.Soc_PD_Data_limit_c,
+			activity_monitor.Soc_PD_Data_error_coeff,
+			activity_monitor.Soc_PD_Data_error_rate_coeff);
+
+		size += sprintf(buf + size, "%19s %d(%13s) %7d %7d %7d %7d %7d %7d %7d %7d %7d\n",
+			" ",
+			2,
+			"UCLK",
+			activity_monitor.Mem_FPS,
+			activity_monitor.Mem_UseRlcBusy,
+			activity_monitor.Mem_MinActiveFreqType,
+			activity_monitor.Mem_MinActiveFreq,
+			activity_monitor.Mem_BoosterFreqType,
+			activity_monitor.Mem_BoosterFreq,
+			activity_monitor.Mem_PD_Data_limit_c,
+			activity_monitor.Mem_PD_Data_error_coeff,
+			activity_monitor.Mem_PD_Data_error_rate_coeff);
+
+		size += sprintf(buf + size, "%19s %d(%13s) %7d %7d %7d %7d %7d %7d %7d %7d %7d\n",
+			" ",
+			3,
+			"FCLK",
+			activity_monitor.Fclk_FPS,
+			activity_monitor.Fclk_UseRlcBusy,
+			activity_monitor.Fclk_MinActiveFreqType,
+			activity_monitor.Fclk_MinActiveFreq,
+			activity_monitor.Fclk_BoosterFreqType,
+			activity_monitor.Fclk_BoosterFreq,
+			activity_monitor.Fclk_PD_Data_limit_c,
+			activity_monitor.Fclk_PD_Data_error_coeff,
+			activity_monitor.Fclk_PD_Data_error_rate_coeff);
+	}
+
+	return size;
+}
+
+static int vega20_set_power_profile_mode(struct smu_context *smu, long *input, uint32_t size)
+{
+	DpmActivityMonitorCoeffInt_t activity_monitor;
+	int workload_type = 0, ret = 0;
+
+	smu->power_profile_mode = input[size];
+
+	if (!smu->pm_enabled)
+		return ret;
+	if (smu->power_profile_mode > PP_SMC_POWER_PROFILE_CUSTOM) {
+		pr_err("Invalid power profile mode %d\n", smu->power_profile_mode);
+		return -EINVAL;
+	}
+
+	if (smu->power_profile_mode == PP_SMC_POWER_PROFILE_CUSTOM) {
+		ret = smu_update_table(smu,
+				       TABLE_ACTIVITY_MONITOR_COEFF | WORKLOAD_PPLIB_CUSTOM_BIT << 16,
+				       (void *)(&activity_monitor), false);
+		if (ret) {
+			pr_err("[%s] Failed to get activity monitor!", __func__);
+			return ret;
+		}
+
+		switch (input[0]) {
+		case 0: /* Gfxclk */
+			activity_monitor.Gfx_FPS = input[1];
+			activity_monitor.Gfx_UseRlcBusy = input[2];
+			activity_monitor.Gfx_MinActiveFreqType = input[3];
+			activity_monitor.Gfx_MinActiveFreq = input[4];
+			activity_monitor.Gfx_BoosterFreqType = input[5];
+			activity_monitor.Gfx_BoosterFreq = input[6];
+			activity_monitor.Gfx_PD_Data_limit_c = input[7];
+			activity_monitor.Gfx_PD_Data_error_coeff = input[8];
+			activity_monitor.Gfx_PD_Data_error_rate_coeff = input[9];
+			break;
+		case 1: /* Socclk */
+			activity_monitor.Soc_FPS = input[1];
+			activity_monitor.Soc_UseRlcBusy = input[2];
+			activity_monitor.Soc_MinActiveFreqType = input[3];
+			activity_monitor.Soc_MinActiveFreq = input[4];
+			activity_monitor.Soc_BoosterFreqType = input[5];
+			activity_monitor.Soc_BoosterFreq = input[6];
+			activity_monitor.Soc_PD_Data_limit_c = input[7];
+			activity_monitor.Soc_PD_Data_error_coeff = input[8];
+			activity_monitor.Soc_PD_Data_error_rate_coeff = input[9];
+			break;
+		case 2: /* Uclk */
+			activity_monitor.Mem_FPS = input[1];
+			activity_monitor.Mem_UseRlcBusy = input[2];
+			activity_monitor.Mem_MinActiveFreqType = input[3];
+			activity_monitor.Mem_MinActiveFreq = input[4];
+			activity_monitor.Mem_BoosterFreqType = input[5];
+			activity_monitor.Mem_BoosterFreq = input[6];
+			activity_monitor.Mem_PD_Data_limit_c = input[7];
+			activity_monitor.Mem_PD_Data_error_coeff = input[8];
+			activity_monitor.Mem_PD_Data_error_rate_coeff = input[9];
+			break;
+		case 3: /* Fclk */
+			activity_monitor.Fclk_FPS = input[1];
+			activity_monitor.Fclk_UseRlcBusy = input[2];
+			activity_monitor.Fclk_MinActiveFreqType = input[3];
+			activity_monitor.Fclk_MinActiveFreq = input[4];
+			activity_monitor.Fclk_BoosterFreqType = input[5];
+			activity_monitor.Fclk_BoosterFreq = input[6];
+			activity_monitor.Fclk_PD_Data_limit_c = input[7];
+			activity_monitor.Fclk_PD_Data_error_coeff = input[8];
+			activity_monitor.Fclk_PD_Data_error_rate_coeff = input[9];
+			break;
+		}
+
+		ret = smu_update_table(smu,
+				       TABLE_ACTIVITY_MONITOR_COEFF | WORKLOAD_PPLIB_CUSTOM_BIT << 16,
+				       (void *)(&activity_monitor), true);
+		if (ret) {
+			pr_err("[%s] Failed to set activity monitor!", __func__);
+			return ret;
+		}
+	}
+
+	/* conv PP_SMC_POWER_PROFILE* to WORKLOAD_PPLIB_*_BIT */
+	workload_type = smu_conv_profile_to_workload(smu, smu->power_profile_mode);
+	smu_send_smc_msg_with_param(smu, SMU_MSG_SetWorkloadMask,
+				    1 << workload_type);
+
+	return ret;
+}
+
 static int
 vega20_get_profiling_clk_mask(struct smu_context *smu,
 			      enum amd_dpm_forced_level level,
@@ -2573,6 +2768,8 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.set_default_od8_settings = vega20_set_default_od8_setttings,
 	.get_od_percentage = vega20_get_od_percentage,
 	.conv_profile_to_workload = vega20_conv_profile_to_workload,
+	.get_power_profile_mode = vega20_get_power_profile_mode,
+	.set_power_profile_mode = vega20_set_power_profile_mode,
 	.get_performance_level = vega20_get_performance_level,
 	.force_performance_level = vega20_force_performance_level,
 	.update_specified_od8_value = vega20_update_specified_od8_value,

commit 940680c3b48a5d90896e638cb6ec3bf1a2cebcfa
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Mon Mar 4 19:50:02 2019 +0800

    drm/amd/powerplay: move the funciton of conv_profile_to_workload to asic file
    
    the function of conv_profile_to_workload is asic related function,
    so move them into vega20_ppt file
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 62497ad66a39..3243928b6ee2 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1496,6 +1496,37 @@ static int vega20_get_od_percentage(struct smu_context *smu,
 	return value;
 }
 
+static int vega20_conv_profile_to_workload(struct smu_context *smu, int power_profile)
+{
+	int pplib_workload = 0;
+
+	switch (power_profile) {
+	case PP_SMC_POWER_PROFILE_BOOTUP_DEFAULT:
+		pplib_workload = WORKLOAD_DEFAULT_BIT;
+		break;
+	case PP_SMC_POWER_PROFILE_FULLSCREEN3D:
+		pplib_workload = WORKLOAD_PPLIB_FULL_SCREEN_3D_BIT;
+		break;
+	case PP_SMC_POWER_PROFILE_POWERSAVING:
+		pplib_workload = WORKLOAD_PPLIB_POWER_SAVING_BIT;
+		break;
+	case PP_SMC_POWER_PROFILE_VIDEO:
+		pplib_workload = WORKLOAD_PPLIB_VIDEO_BIT;
+		break;
+	case PP_SMC_POWER_PROFILE_VR:
+		pplib_workload = WORKLOAD_PPLIB_VR_BIT;
+		break;
+	case PP_SMC_POWER_PROFILE_COMPUTE:
+		pplib_workload = WORKLOAD_PPLIB_COMPUTE_BIT;
+		break;
+	case PP_SMC_POWER_PROFILE_CUSTOM:
+		pplib_workload = WORKLOAD_PPLIB_CUSTOM_BIT;
+		break;
+	}
+
+	return pplib_workload;
+}
+
 static int
 vega20_get_profiling_clk_mask(struct smu_context *smu,
 			      enum amd_dpm_forced_level level,
@@ -2541,6 +2572,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_clock_by_type_with_latency = vega20_get_clock_by_type_with_latency,
 	.set_default_od8_settings = vega20_set_default_od8_setttings,
 	.get_od_percentage = vega20_get_od_percentage,
+	.conv_profile_to_workload = vega20_conv_profile_to_workload,
 	.get_performance_level = vega20_get_performance_level,
 	.force_performance_level = vega20_force_performance_level,
 	.update_specified_od8_value = vega20_update_specified_od8_value,

commit b9341521700dddea0c5d80d904c2c2f4d100323f
Author: Markus Elfring <elfring@users.sourceforge.net>
Date:   Mon Jun 17 14:24:14 2019 +0200

    drm/amd/powerplay: Delete a redundant memory setting in vega20_set_default_od8_setttings()
    
    The memory was set to zero already by a call of the function kzalloc.
    Thus remove an extra call of the function memset for this purpose.
    
    This issue was detected by using the Coccinelle software.
    
    Signed-off-by: Markus Elfring <elfring@users.sourceforge.net>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 4aa8f5a69c4c..62497ad66a39 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1295,7 +1295,6 @@ static int vega20_set_default_od8_setttings(struct smu_context *smu)
 	if (!table_context->od8_settings)
 		return -ENOMEM;
 
-	memset(table_context->od8_settings, 0, sizeof(struct vega20_od8_settings));
 	od8_settings = (struct vega20_od8_settings *)table_context->od8_settings;
 
 	if (smu_feature_is_enabled(smu, FEATURE_DPM_SOCCLK_BIT)) {

commit 1b9557fcaa42a45920821b0c6455088bb341f477
Author: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
Date:   Wed May 15 16:17:05 2019 -0400

    drm/amd/powerplay: Fix maybe-uninitialized in get_ppfeature_status
    
    This fixes the warning below
    
    error: feature_mask may be used uninitialized in this function [-Werror=maybe-uninitialized]
      *features_enabled = ((((uint64_t)feature_mask[0] << SMU_FEATURES_LOW_SHIFT) & SMU_FEATURES_LOW_MASK) |
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        (((uint64_t)feature_mask[1] << SMU_FEATURES_HIGH_SHIFT) & SMU_FEATURES_HIGH_MASK));
        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index b39f3d439332..4aa8f5a69c4c 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2377,7 +2377,7 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 static int vega20_get_enabled_smc_features(struct smu_context *smu,
 		uint64_t *features_enabled)
 {
-	uint32_t feature_mask[2];
+	uint32_t feature_mask[2] = {0, 0};
 	int ret = 0;
 
 	ret = smu_feature_get_enabled_mask(smu, feature_mask, 2);

commit fe75a323713e9ed254c4e3d27b391b2416cee237
Author: Evan Quan <evan.quan@amd.com>
Date:   Mon May 13 15:32:21 2019 +0800

    drm/amd/powerplay: support ppfeatures sysfs interface on sw smu routine
    
    Support ppfeatures sysfs interface on Vega20 sw smu routine.
    
    Signed-off-by: Evan Quan <evan.quan@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 8fafcbdb1dfd..b39f3d439332 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2374,6 +2374,157 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 	return ret;
 }
 
+static int vega20_get_enabled_smc_features(struct smu_context *smu,
+		uint64_t *features_enabled)
+{
+	uint32_t feature_mask[2];
+	int ret = 0;
+
+	ret = smu_feature_get_enabled_mask(smu, feature_mask, 2);
+	if (ret)
+		return ret;
+
+	*features_enabled = ((((uint64_t)feature_mask[0] << SMU_FEATURES_LOW_SHIFT) & SMU_FEATURES_LOW_MASK) |
+			(((uint64_t)feature_mask[1] << SMU_FEATURES_HIGH_SHIFT) & SMU_FEATURES_HIGH_MASK));
+
+	return ret;
+}
+
+static int vega20_enable_smc_features(struct smu_context *smu,
+		bool enable, uint64_t feature_mask)
+{
+	uint32_t smu_features_low, smu_features_high;
+	int ret = 0;
+
+	smu_features_low = (uint32_t)((feature_mask & SMU_FEATURES_LOW_MASK) >> SMU_FEATURES_LOW_SHIFT);
+	smu_features_high = (uint32_t)((feature_mask & SMU_FEATURES_HIGH_MASK) >> SMU_FEATURES_HIGH_SHIFT);
+
+	if (enable) {
+		ret = smu_send_smc_msg_with_param(smu, SMU_MSG_EnableSmuFeaturesLow,
+						  smu_features_low);
+		if (ret)
+			return ret;
+		ret = smu_send_smc_msg_with_param(smu, SMU_MSG_EnableSmuFeaturesHigh,
+						  smu_features_high);
+		if (ret)
+			return ret;
+	} else {
+		ret = smu_send_smc_msg_with_param(smu, SMU_MSG_DisableSmuFeaturesLow,
+						  smu_features_low);
+		if (ret)
+			return ret;
+		ret = smu_send_smc_msg_with_param(smu, SMU_MSG_DisableSmuFeaturesHigh,
+						  smu_features_high);
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+
+}
+
+static int vega20_get_ppfeature_status(struct smu_context *smu, char *buf)
+{
+	static const char *ppfeature_name[] = {
+				"DPM_PREFETCHER",
+				"GFXCLK_DPM",
+				"UCLK_DPM",
+				"SOCCLK_DPM",
+				"UVD_DPM",
+				"VCE_DPM",
+				"ULV",
+				"MP0CLK_DPM",
+				"LINK_DPM",
+				"DCEFCLK_DPM",
+				"GFXCLK_DS",
+				"SOCCLK_DS",
+				"LCLK_DS",
+				"PPT",
+				"TDC",
+				"THERMAL",
+				"GFX_PER_CU_CG",
+				"RM",
+				"DCEFCLK_DS",
+				"ACDC",
+				"VR0HOT",
+				"VR1HOT",
+				"FW_CTF",
+				"LED_DISPLAY",
+				"FAN_CONTROL",
+				"GFX_EDC",
+				"GFXOFF",
+				"CG",
+				"FCLK_DPM",
+				"FCLK_DS",
+				"MP1CLK_DS",
+				"MP0CLK_DS",
+				"XGMI",
+				"ECC"};
+	static const char *output_title[] = {
+				"FEATURES",
+				"BITMASK",
+				"ENABLEMENT"};
+	uint64_t features_enabled;
+	int i;
+	int ret = 0;
+	int size = 0;
+
+	ret = vega20_get_enabled_smc_features(smu, &features_enabled);
+	if (ret)
+		return ret;
+
+	size += sprintf(buf + size, "Current ppfeatures: 0x%016llx\n", features_enabled);
+	size += sprintf(buf + size, "%-19s %-22s %s\n",
+				output_title[0],
+				output_title[1],
+				output_title[2]);
+	for (i = 0; i < GNLD_FEATURES_MAX; i++) {
+		size += sprintf(buf + size, "%-19s 0x%016llx %6s\n",
+					ppfeature_name[i],
+					1ULL << i,
+					(features_enabled & (1ULL << i)) ? "Y" : "N");
+	}
+
+	return size;
+}
+
+static int vega20_set_ppfeature_status(struct smu_context *smu, uint64_t new_ppfeature_masks)
+{
+	uint64_t features_enabled;
+	uint64_t features_to_enable;
+	uint64_t features_to_disable;
+	int ret = 0;
+
+	if (new_ppfeature_masks >= (1ULL << GNLD_FEATURES_MAX))
+		return -EINVAL;
+
+	ret = vega20_get_enabled_smc_features(smu, &features_enabled);
+	if (ret)
+		return ret;
+
+	features_to_disable =
+		features_enabled & ~new_ppfeature_masks;
+	features_to_enable =
+		~features_enabled & new_ppfeature_masks;
+
+	pr_debug("features_to_disable 0x%llx\n", features_to_disable);
+	pr_debug("features_to_enable 0x%llx\n", features_to_enable);
+
+	if (features_to_disable) {
+		ret = vega20_enable_smc_features(smu, false, features_to_disable);
+		if (ret)
+			return ret;
+	}
+
+	if (features_to_enable) {
+		ret = vega20_enable_smc_features(smu, true, features_to_enable);
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
@@ -2404,6 +2555,8 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.unforce_dpm_levels = vega20_unforce_dpm_levels,
 	.upload_dpm_level = vega20_upload_dpm_level,
 	.get_profiling_clk_mask = vega20_get_profiling_clk_mask,
+	.set_ppfeature_status = vega20_set_ppfeature_status,
+	.get_ppfeature_status = vega20_get_ppfeature_status,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 8513027a73c2f2d9a4d4c82e3e805b2f9219767f
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Thu Mar 21 12:19:57 2019 +0300

    drm/amd/powerplay: Off by one in vega20_get_smu_msg_index()
    
    The > should be >= so that we don't read one element beyond the end of
    the vega20_message_map[] array.
    
    Fixes: 78031c2c4dcd ("drm/amd/powerplay: implement smu vega20_message_map for vega20")
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 41e6f49c9cb6..8fafcbdb1dfd 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -132,7 +132,8 @@ static int vega20_message_map[SMU_MSG_MAX_COUNT] = {
 static int vega20_get_smu_msg_index(struct smu_context *smc, uint32_t index)
 {
 	int val;
-	if (index > SMU_MSG_MAX_COUNT)
+
+	if (index >= SMU_MSG_MAX_COUNT)
 		return -EINVAL;
 
 	val = vega20_message_map[index];

commit 5ea8b4725f42c22c37b370eebb5d33b4236f5301
Author: Nathan Chancellor <natechancellor@gmail.com>
Date:   Tue Mar 19 17:58:42 2019 -0700

    drm/amd/powerplay: Zero initialize num_of_levels in vega20_set_single_dpm_table
    
    When building with -Wsometimes-uninitialized, Clang warns:
    
    drivers/gpu/drm/amd/amdgpu/../powerplay/vega20_ppt.c:456:2: warning:
    variable 'num_of_levels' is used uninitialized whenever '?:' condition
    is false [-Wsometimes-uninitialized]
            smu_read_smc_arg(smu, &num_of_levels);
            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    drivers/gpu/drm/amd/amdgpu/../powerplay/inc/amdgpu_smu.h:608:3: note:
    expanded from macro 'smu_read_smc_arg'
            ((smu)->funcs->read_smc_arg? (smu)->funcs->read_smc_arg((smu), (arg)) : 0)
             ^~~~~~~~~~~~~~~~~~~~~~~~~~
    drivers/gpu/drm/amd/amdgpu/../powerplay/vega20_ppt.c:457:7: note:
    uninitialized use occurs here
            if (!num_of_levels) {
                 ^~~~~~~~~~~~~
    drivers/gpu/drm/amd/amdgpu/../powerplay/vega20_ppt.c:456:2: note: remove
    the '?:' if its condition is always true
            smu_read_smc_arg(smu, &num_of_levels);
            ^
    drivers/gpu/drm/amd/amdgpu/../powerplay/inc/amdgpu_smu.h:608:3: note:
    expanded from macro 'smu_read_smc_arg'
            ((smu)->funcs->read_smc_arg? (smu)->funcs->read_smc_arg((smu), (arg)) : 0)
             ^
    drivers/gpu/drm/amd/amdgpu/../powerplay/vega20_ppt.c:446:27: note:
    initialize the variable 'num_of_levels' to silence this warning
            uint32_t i, num_of_levels, clk;
                                     ^
                                      = 0
    1 warning generated.
    
    The if statement it mentions as potentially problematic is currently
    always true because the read_smc_arg callback is assigned at the
    bottom of this file but Clang can't tell that. If the callback were
    ever to disappear, num_of_levels would never be initialized. Just
    zero initialize it to ensure that the intent behind this code
    remains the same.
    
    Link: https://github.com/ClangBuiltLinux/linux/issues/425
    Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 7e9e8ad9a300..41e6f49c9cb6 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -443,7 +443,7 @@ vega20_set_single_dpm_table(struct smu_context *smu,
 			    PPCLK_e clk_id)
 {
 	int ret = 0;
-	uint32_t i, num_of_levels, clk;
+	uint32_t i, num_of_levels = 0, clk;
 
 	ret = smu_send_smc_msg_with_param(smu,
 			SMU_MSG_GetDpmFreqByIndex,

commit 1fb4f15548240df4f4bd9a855ee09942d6accc74
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Mon Mar 11 11:00:48 2019 +0800

    drm/amd/powerplay: move the smc_if_version to asic file
    
    each asic may be has different smc if version,
    so move its to asic file to implement.
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index c2135baf7976..7e9e8ad9a300 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -2408,4 +2408,5 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 void vega20_set_ppt_funcs(struct smu_context *smu)
 {
 	smu->ppt_funcs = &vega20_ppt_funcs;
+	smu->smc_if_version = SMU11_DRIVER_IF_VERSION;
 }

commit 96e1b2c2f2639a83baaa61fed6ceccd76b99fa8b
Author: Kevin Wang <kevin1.wang@amd.com>
Date:   Wed Mar 6 19:45:16 2019 +0800

    drm/amd/powerplay: simplify sw-smu message map macro
    
    simplify macro of MSG_MAP for sw-smu
    
    Signed-off-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index b71ecbe66ab4..c2135baf7976 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -40,93 +40,93 @@
 #define smnPCIE_LC_SPEED_CNTL			0x11140290
 #define smnPCIE_LC_LINK_WIDTH_CNTL		0x11140288
 
-#define MSG_MAP(msg, index) \
-	[SMU_MSG_##msg] = index
+#define MSG_MAP(msg) \
+	[SMU_MSG_##msg] = PPSMC_MSG_##msg
 
 static int vega20_message_map[SMU_MSG_MAX_COUNT] = {
-	MSG_MAP(TestMessage,			PPSMC_MSG_TestMessage),
-	MSG_MAP(GetSmuVersion,			PPSMC_MSG_GetSmuVersion),
-	MSG_MAP(GetDriverIfVersion,		PPSMC_MSG_GetDriverIfVersion),
-	MSG_MAP(SetAllowedFeaturesMaskLow,	PPSMC_MSG_SetAllowedFeaturesMaskLow),
-	MSG_MAP(SetAllowedFeaturesMaskHigh,	PPSMC_MSG_SetAllowedFeaturesMaskHigh),
-	MSG_MAP(EnableAllSmuFeatures,		PPSMC_MSG_EnableAllSmuFeatures),
-	MSG_MAP(DisableAllSmuFeatures,		PPSMC_MSG_DisableAllSmuFeatures),
-	MSG_MAP(EnableSmuFeaturesLow,		PPSMC_MSG_EnableSmuFeaturesLow),
-	MSG_MAP(EnableSmuFeaturesHigh,		PPSMC_MSG_EnableSmuFeaturesHigh),
-	MSG_MAP(DisableSmuFeaturesLow,		PPSMC_MSG_DisableSmuFeaturesLow),
-	MSG_MAP(DisableSmuFeaturesHigh,		PPSMC_MSG_DisableSmuFeaturesHigh),
-	MSG_MAP(GetEnabledSmuFeaturesLow,	PPSMC_MSG_GetEnabledSmuFeaturesLow),
-	MSG_MAP(GetEnabledSmuFeaturesHigh,	PPSMC_MSG_GetEnabledSmuFeaturesHigh),
-	MSG_MAP(SetWorkloadMask,		PPSMC_MSG_SetWorkloadMask),
-	MSG_MAP(SetPptLimit,			PPSMC_MSG_SetPptLimit),
-	MSG_MAP(SetDriverDramAddrHigh,		PPSMC_MSG_SetDriverDramAddrHigh),
-	MSG_MAP(SetDriverDramAddrLow,		PPSMC_MSG_SetDriverDramAddrLow),
-	MSG_MAP(SetToolsDramAddrHigh,		PPSMC_MSG_SetToolsDramAddrHigh),
-	MSG_MAP(SetToolsDramAddrLow,		PPSMC_MSG_SetToolsDramAddrLow),
-	MSG_MAP(TransferTableSmu2Dram,		PPSMC_MSG_TransferTableSmu2Dram),
-	MSG_MAP(TransferTableDram2Smu,		PPSMC_MSG_TransferTableDram2Smu),
-	MSG_MAP(UseDefaultPPTable,		PPSMC_MSG_UseDefaultPPTable),
-	MSG_MAP(UseBackupPPTable,		PPSMC_MSG_UseBackupPPTable),
-	MSG_MAP(RunBtc,				PPSMC_MSG_RunBtc),
-	MSG_MAP(RequestI2CBus,			PPSMC_MSG_RequestI2CBus),
-	MSG_MAP(ReleaseI2CBus,			PPSMC_MSG_ReleaseI2CBus),
-	MSG_MAP(SetFloorSocVoltage,		PPSMC_MSG_SetFloorSocVoltage),
-	MSG_MAP(SoftReset,			PPSMC_MSG_SoftReset),
-	MSG_MAP(StartBacoMonitor,		PPSMC_MSG_StartBacoMonitor),
-	MSG_MAP(CancelBacoMonitor,		PPSMC_MSG_CancelBacoMonitor),
-	MSG_MAP(EnterBaco,			PPSMC_MSG_EnterBaco),
-	MSG_MAP(SetSoftMinByFreq,		PPSMC_MSG_SetSoftMinByFreq),
-	MSG_MAP(SetSoftMaxByFreq,		PPSMC_MSG_SetSoftMaxByFreq),
-	MSG_MAP(SetHardMinByFreq,		PPSMC_MSG_SetHardMinByFreq),
-	MSG_MAP(SetHardMaxByFreq,		PPSMC_MSG_SetHardMaxByFreq),
-	MSG_MAP(GetMinDpmFreq,			PPSMC_MSG_GetMinDpmFreq),
-	MSG_MAP(GetMaxDpmFreq,			PPSMC_MSG_GetMaxDpmFreq),
-	MSG_MAP(GetDpmFreqByIndex,		PPSMC_MSG_GetDpmFreqByIndex),
-	MSG_MAP(GetDpmClockFreq,		PPSMC_MSG_GetDpmClockFreq),
-	MSG_MAP(GetSsVoltageByDpm,		PPSMC_MSG_GetSsVoltageByDpm),
-	MSG_MAP(SetMemoryChannelConfig,		PPSMC_MSG_SetMemoryChannelConfig),
-	MSG_MAP(SetGeminiMode,			PPSMC_MSG_SetGeminiMode),
-	MSG_MAP(SetGeminiApertureHigh,		PPSMC_MSG_SetGeminiApertureHigh),
-	MSG_MAP(SetGeminiApertureLow,		PPSMC_MSG_SetGeminiApertureLow),
-	MSG_MAP(SetMinLinkDpmByIndex,		PPSMC_MSG_SetMinLinkDpmByIndex),
-	MSG_MAP(OverridePcieParameters,		PPSMC_MSG_OverridePcieParameters),
-	MSG_MAP(OverDriveSetPercentage,		PPSMC_MSG_OverDriveSetPercentage),
-	MSG_MAP(SetMinDeepSleepDcefclk,		PPSMC_MSG_SetMinDeepSleepDcefclk),
-	MSG_MAP(ReenableAcDcInterrupt,		PPSMC_MSG_ReenableAcDcInterrupt),
-	MSG_MAP(NotifyPowerSource,		PPSMC_MSG_NotifyPowerSource),
-	MSG_MAP(SetUclkFastSwitch,		PPSMC_MSG_SetUclkFastSwitch),
-	MSG_MAP(SetUclkDownHyst,		PPSMC_MSG_SetUclkDownHyst),
-	MSG_MAP(GetCurrentRpm,			PPSMC_MSG_GetCurrentRpm),
-	MSG_MAP(SetVideoFps,			PPSMC_MSG_SetVideoFps),
-	MSG_MAP(SetTjMax,			PPSMC_MSG_SetTjMax),
-	MSG_MAP(SetFanTemperatureTarget,	PPSMC_MSG_SetFanTemperatureTarget),
-	MSG_MAP(PrepareMp1ForUnload,		PPSMC_MSG_PrepareMp1ForUnload),
-	MSG_MAP(DramLogSetDramAddrHigh,		PPSMC_MSG_DramLogSetDramAddrHigh),
-	MSG_MAP(DramLogSetDramAddrLow,		PPSMC_MSG_DramLogSetDramAddrLow),
-	MSG_MAP(DramLogSetDramSize,		PPSMC_MSG_DramLogSetDramSize),
-	MSG_MAP(SetFanMaxRpm,			PPSMC_MSG_SetFanMaxRpm),
-	MSG_MAP(SetFanMinPwm,			PPSMC_MSG_SetFanMinPwm),
-	MSG_MAP(ConfigureGfxDidt,		PPSMC_MSG_ConfigureGfxDidt),
-	MSG_MAP(NumOfDisplays,			PPSMC_MSG_NumOfDisplays),
-	MSG_MAP(RemoveMargins,			PPSMC_MSG_RemoveMargins),
-	MSG_MAP(ReadSerialNumTop32,		PPSMC_MSG_ReadSerialNumTop32),
-	MSG_MAP(ReadSerialNumBottom32,		PPSMC_MSG_ReadSerialNumBottom32),
-	MSG_MAP(SetSystemVirtualDramAddrHigh,	PPSMC_MSG_SetSystemVirtualDramAddrHigh),
-	MSG_MAP(SetSystemVirtualDramAddrLow,	PPSMC_MSG_SetSystemVirtualDramAddrLow),
-	MSG_MAP(WaflTest,			PPSMC_MSG_WaflTest),
-	MSG_MAP(SetFclkGfxClkRatio,		PPSMC_MSG_SetFclkGfxClkRatio),
-	MSG_MAP(AllowGfxOff,			PPSMC_MSG_AllowGfxOff),
-	MSG_MAP(DisallowGfxOff,			PPSMC_MSG_DisallowGfxOff),
-	MSG_MAP(GetPptLimit,			PPSMC_MSG_GetPptLimit),
-	MSG_MAP(GetDcModeMaxDpmFreq,		PPSMC_MSG_GetDcModeMaxDpmFreq),
-	MSG_MAP(GetDebugData,			PPSMC_MSG_GetDebugData),
-	MSG_MAP(SetXgmiMode,			PPSMC_MSG_SetXgmiMode),
-	MSG_MAP(RunAfllBtc,			PPSMC_MSG_RunAfllBtc),
-	MSG_MAP(ExitBaco,			PPSMC_MSG_ExitBaco),
-	MSG_MAP(PrepareMp1ForReset,		PPSMC_MSG_PrepareMp1ForReset),
-	MSG_MAP(PrepareMp1ForShutdown,		PPSMC_MSG_PrepareMp1ForShutdown),
-	MSG_MAP(SetMGpuFanBoostLimitRpm,	PPSMC_MSG_SetMGpuFanBoostLimitRpm),
-	MSG_MAP(GetAVFSVoltageByDpm,		PPSMC_MSG_GetAVFSVoltageByDpm),
+	MSG_MAP(TestMessage),
+	MSG_MAP(GetSmuVersion),
+	MSG_MAP(GetDriverIfVersion),
+	MSG_MAP(SetAllowedFeaturesMaskLow),
+	MSG_MAP(SetAllowedFeaturesMaskHigh),
+	MSG_MAP(EnableAllSmuFeatures),
+	MSG_MAP(DisableAllSmuFeatures),
+	MSG_MAP(EnableSmuFeaturesLow),
+	MSG_MAP(EnableSmuFeaturesHigh),
+	MSG_MAP(DisableSmuFeaturesLow),
+	MSG_MAP(DisableSmuFeaturesHigh),
+	MSG_MAP(GetEnabledSmuFeaturesLow),
+	MSG_MAP(GetEnabledSmuFeaturesHigh),
+	MSG_MAP(SetWorkloadMask),
+	MSG_MAP(SetPptLimit),
+	MSG_MAP(SetDriverDramAddrHigh),
+	MSG_MAP(SetDriverDramAddrLow),
+	MSG_MAP(SetToolsDramAddrHigh),
+	MSG_MAP(SetToolsDramAddrLow),
+	MSG_MAP(TransferTableSmu2Dram),
+	MSG_MAP(TransferTableDram2Smu),
+	MSG_MAP(UseDefaultPPTable),
+	MSG_MAP(UseBackupPPTable),
+	MSG_MAP(RunBtc),
+	MSG_MAP(RequestI2CBus),
+	MSG_MAP(ReleaseI2CBus),
+	MSG_MAP(SetFloorSocVoltage),
+	MSG_MAP(SoftReset),
+	MSG_MAP(StartBacoMonitor),
+	MSG_MAP(CancelBacoMonitor),
+	MSG_MAP(EnterBaco),
+	MSG_MAP(SetSoftMinByFreq),
+	MSG_MAP(SetSoftMaxByFreq),
+	MSG_MAP(SetHardMinByFreq),
+	MSG_MAP(SetHardMaxByFreq),
+	MSG_MAP(GetMinDpmFreq),
+	MSG_MAP(GetMaxDpmFreq),
+	MSG_MAP(GetDpmFreqByIndex),
+	MSG_MAP(GetDpmClockFreq),
+	MSG_MAP(GetSsVoltageByDpm),
+	MSG_MAP(SetMemoryChannelConfig),
+	MSG_MAP(SetGeminiMode),
+	MSG_MAP(SetGeminiApertureHigh),
+	MSG_MAP(SetGeminiApertureLow),
+	MSG_MAP(SetMinLinkDpmByIndex),
+	MSG_MAP(OverridePcieParameters),
+	MSG_MAP(OverDriveSetPercentage),
+	MSG_MAP(SetMinDeepSleepDcefclk),
+	MSG_MAP(ReenableAcDcInterrupt),
+	MSG_MAP(NotifyPowerSource),
+	MSG_MAP(SetUclkFastSwitch),
+	MSG_MAP(SetUclkDownHyst),
+	MSG_MAP(GetCurrentRpm),
+	MSG_MAP(SetVideoFps),
+	MSG_MAP(SetTjMax),
+	MSG_MAP(SetFanTemperatureTarget),
+	MSG_MAP(PrepareMp1ForUnload),
+	MSG_MAP(DramLogSetDramAddrHigh),
+	MSG_MAP(DramLogSetDramAddrLow),
+	MSG_MAP(DramLogSetDramSize),
+	MSG_MAP(SetFanMaxRpm),
+	MSG_MAP(SetFanMinPwm),
+	MSG_MAP(ConfigureGfxDidt),
+	MSG_MAP(NumOfDisplays),
+	MSG_MAP(RemoveMargins),
+	MSG_MAP(ReadSerialNumTop32),
+	MSG_MAP(ReadSerialNumBottom32),
+	MSG_MAP(SetSystemVirtualDramAddrHigh),
+	MSG_MAP(SetSystemVirtualDramAddrLow),
+	MSG_MAP(WaflTest),
+	MSG_MAP(SetFclkGfxClkRatio),
+	MSG_MAP(AllowGfxOff),
+	MSG_MAP(DisallowGfxOff),
+	MSG_MAP(GetPptLimit),
+	MSG_MAP(GetDcModeMaxDpmFreq),
+	MSG_MAP(GetDebugData),
+	MSG_MAP(SetXgmiMode),
+	MSG_MAP(RunAfllBtc),
+	MSG_MAP(ExitBaco),
+	MSG_MAP(PrepareMp1ForReset),
+	MSG_MAP(PrepareMp1ForShutdown),
+	MSG_MAP(SetMGpuFanBoostLimitRpm),
+	MSG_MAP(GetAVFSVoltageByDpm),
 };
 
 static int vega20_get_smu_msg_index(struct smu_context *smc, uint32_t index)

commit db65e887fea55ba3e5ce77f7b129a0cde0e1f050
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Mon Mar 4 10:46:27 2019 +0800

    drm/amd/powerplay: fix pcie sysfs interface when set wrong value
    
    The operation of mutex_unlock smu->mutex should be done when forced
    level is larger than NUM_LINK_LEVELS in the function of force_clk_levels.
    
    Reported-by: Julia Lawall <julia.lawall@lip6.fr>
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index c66ad3b223d3..b71ecbe66ab4 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1200,8 +1200,10 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 
 	case PP_PCIE:
 		if (soft_min_level >= NUM_LINK_LEVELS ||
-		    soft_max_level >= NUM_LINK_LEVELS)
-			return -EINVAL;
+		    soft_max_level >= NUM_LINK_LEVELS) {
+			ret = -EINVAL;
+			break;
+		}
 
 		ret = smu_send_smc_msg_with_param(smu,
 				SMU_MSG_SetMinLinkDpmByIndex, soft_min_level);

commit 24bf582e27a8ac5ffab6c2f1b9541ebaeb250a3d
Author: kbuild test robot <fengguang.wu@intel.com>
Date:   Sat Mar 2 07:50:36 2019 +0100

    drm/amd/powerplay: fix memdup.cocci warnings
    
    Simplify the code a bit by using kmemdup instead of kzalloc and memcpy.
    
    Generated by: scripts/coccinelle/api/memdup.cocci
    
    CC: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Likun Gao <Likun.Gao@amd.com>
    Acked-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: kbuild test robot <fengguang.wu@intel.com>
    Signed-off-by: Julia Lawall <julia.lawall@lip6.fr>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index f7188a7fb194..c66ad3b223d3 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -204,14 +204,12 @@ static int vega20_setup_od8_information(struct smu_context *smu)
 		if (table_context->od_feature_capabilities)
 			return -EINVAL;
 
-		table_context->od_feature_capabilities = kzalloc(od_feature_array_size, GFP_KERNEL);
+		table_context->od_feature_capabilities = kmemdup(&powerplay_table->OverDrive8Table.ODFeatureCapabilities,
+								 od_feature_array_size,
+								 GFP_KERNEL);
 		if (!table_context->od_feature_capabilities)
 			return -ENOMEM;
 
-		memcpy(table_context->od_feature_capabilities,
-		       &powerplay_table->OverDrive8Table.ODFeatureCapabilities,
-		       od_feature_array_size);
-
 		/* Setup correct ODSettingCount, and store ODSettingArray from
 		 * powerplay table to od_settings_max and od_setting_min */
 		od_setting_count =
@@ -225,7 +223,9 @@ static int vega20_setup_od8_information(struct smu_context *smu)
 		if (table_context->od_settings_max)
 			return -EINVAL;
 
-		table_context->od_settings_max = kzalloc(od_setting_array_size, GFP_KERNEL);
+		table_context->od_settings_max = kmemdup(&powerplay_table->OverDrive8Table.ODSettingsMax,
+							 od_setting_array_size,
+							 GFP_KERNEL);
 
 		if (!table_context->od_settings_max) {
 			kfree(table_context->od_feature_capabilities);
@@ -233,14 +233,12 @@ static int vega20_setup_od8_information(struct smu_context *smu)
 			return -ENOMEM;
 		}
 
-		memcpy(table_context->od_settings_max,
-		       &powerplay_table->OverDrive8Table.ODSettingsMax,
-		       od_setting_array_size);
-
 		if (table_context->od_settings_min)
 			return -EINVAL;
 
-		table_context->od_settings_min = kzalloc(od_setting_array_size, GFP_KERNEL);
+		table_context->od_settings_min = kmemdup(&powerplay_table->OverDrive8Table.ODSettingsMin,
+							 od_setting_array_size,
+							 GFP_KERNEL);
 
 		if (!table_context->od_settings_min) {
 			kfree(table_context->od_feature_capabilities);
@@ -249,10 +247,6 @@ static int vega20_setup_od8_information(struct smu_context *smu)
 			table_context->od_settings_max = NULL;
 			return -ENOMEM;
 		}
-
-		memcpy(table_context->od_settings_min,
-		       &powerplay_table->OverDrive8Table.ODSettingsMin,
-		       od_setting_array_size);
 	}
 
 	return 0;

commit 07740adcbcd326060e142f6af674a036a5106c6f
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Fri Feb 1 13:22:33 2019 +0800

    drm/amd/powerplay: add od condition for power limit
    
    Add condition to judge whether overdrive is enabled and correct power
    limit value for overdrive used by power limit interface.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 6763dcd21cf1..f7188a7fb194 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -274,6 +274,7 @@ static int vega20_store_powerplay_table(struct smu_context *smu)
 
 	table_context->software_shutdown_temp = powerplay_table->usSoftwareShutdownTemp;
 	table_context->thermal_controller_type = powerplay_table->ucThermalControllerType;
+	table_context->TDPODLimit = le32_to_cpu(powerplay_table->OverDrive8Table.ODSettingsMax[ATOM_VEGA20_ODSETTING_POWERPERCENTAGE]);
 
 	ret = vega20_setup_od8_information(smu);
 

commit 04cfc0c80d8a9a727929b589954757823c22e445
Author: Huang Rui <ray.huang@amd.com>
Date:   Mon Feb 25 19:43:00 2019 +0800

    drm/amd/powerplay: fix the issue of checking on message mapping
    
    The vega20_message_map[index] scope should be in PPSMC_Message_Count not in
    SMU_MSG_MAX_COUNT.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index e6db56d158eb..6763dcd21cf1 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -131,10 +131,15 @@ static int vega20_message_map[SMU_MSG_MAX_COUNT] = {
 
 static int vega20_get_smu_msg_index(struct smu_context *smc, uint32_t index)
 {
-	if (index > SMU_MSG_MAX_COUNT || index > PPSMC_Message_Count)
+	int val;
+	if (index > SMU_MSG_MAX_COUNT)
 		return -EINVAL;
-	return vega20_message_map[index];
 
+	val = vega20_message_map[index];
+	if (val > PPSMC_Message_Count)
+		return -EINVAL;
+
+	return val;
 }
 
 static int vega20_allocate_dpm_context(struct smu_context *smu)

commit 1aae3164351e352d13328a71f45703fb0b00820c
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Thu Feb 21 11:09:31 2019 +0800

    drm/amd/powerplay: support sysfs to set/get pcie
    
    Add sys interface to set and get pcie info for smu.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Gui Chengming <Jack.Gui@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index fa65b7509bc4..e6db56d158eb 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -35,6 +35,10 @@
 #include "vega20_ppt.h"
 #include "vega20_pptable.h"
 #include "vega20_ppsmc.h"
+#include "nbio/nbio_7_4_sh_mask.h"
+
+#define smnPCIE_LC_SPEED_CNTL			0x11140290
+#define smnPCIE_LC_LINK_WIDTH_CNTL		0x11140288
 
 #define MSG_MAP(msg, index) \
 	[SMU_MSG_##msg] = index
@@ -718,6 +722,8 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 {
 	int i, now, size = 0;
 	int ret = 0;
+	uint32_t gen_speed, lane_width;
+	struct amdgpu_device *adev = smu->adev;
 	struct pp_clock_levels_with_latency clocks;
 	struct vega20_single_dpm_table *single_dpm_table;
 	struct smu_table_context *table_context = &smu->smu_table;
@@ -727,6 +733,7 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 		(struct vega20_od8_settings *)table_context->od8_settings;
 	OverDriveTable_t *od_table =
 		(OverDriveTable_t *)(table_context->overdrive_table);
+	PPTable_t *pptable = (PPTable_t *)table_context->driver_pptable;
 
 	dpm_table = smu_dpm->dpm_context;
 
@@ -830,6 +837,28 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 		break;
 
 	case PP_PCIE:
+		gen_speed = (RREG32_PCIE(smnPCIE_LC_SPEED_CNTL) &
+			     PSWUSP0_PCIE_LC_SPEED_CNTL__LC_CURRENT_DATA_RATE_MASK)
+			>> PSWUSP0_PCIE_LC_SPEED_CNTL__LC_CURRENT_DATA_RATE__SHIFT;
+		lane_width = (RREG32_PCIE(smnPCIE_LC_LINK_WIDTH_CNTL) &
+			      PCIE_LC_LINK_WIDTH_CNTL__LC_LINK_WIDTH_RD_MASK)
+			>> PCIE_LC_LINK_WIDTH_CNTL__LC_LINK_WIDTH_RD__SHIFT;
+		for (i = 0; i < NUM_LINK_LEVELS; i++)
+			size += sprintf(buf + size, "%d: %s %s %dMhz %s\n", i,
+					(pptable->PcieGenSpeed[i] == 0) ? "2.5GT/s," :
+					(pptable->PcieGenSpeed[i] == 1) ? "5.0GT/s," :
+					(pptable->PcieGenSpeed[i] == 2) ? "8.0GT/s," :
+					(pptable->PcieGenSpeed[i] == 3) ? "16.0GT/s," : "",
+					(pptable->PcieLaneCount[i] == 1) ? "x1" :
+					(pptable->PcieLaneCount[i] == 2) ? "x2" :
+					(pptable->PcieLaneCount[i] == 3) ? "x4" :
+					(pptable->PcieLaneCount[i] == 4) ? "x8" :
+					(pptable->PcieLaneCount[i] == 5) ? "x12" :
+					(pptable->PcieLaneCount[i] == 6) ? "x16" : "",
+					pptable->LclkFreq[i],
+					(gen_speed == pptable->PcieGenSpeed[i]) &&
+					(lane_width == pptable->PcieLaneCount[i]) ?
+					"*" : "");
 		break;
 
 	case OD_SCLK:
@@ -1170,6 +1199,15 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 		break;
 
 	case PP_PCIE:
+		if (soft_min_level >= NUM_LINK_LEVELS ||
+		    soft_max_level >= NUM_LINK_LEVELS)
+			return -EINVAL;
+
+		ret = smu_send_smc_msg_with_param(smu,
+				SMU_MSG_SetMinLinkDpmByIndex, soft_min_level);
+		if (ret)
+			pr_err("Failed to set min link dpm level!\n");
+
 		break;
 
 	default:

commit 4b77faaf8c3be77a3f435333d62905989f0a3a40
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Wed Feb 20 13:42:55 2019 +0800

    drm/amd/powerplay: support sysfs to set socclk, fclk, dcefclk
    
    Add sys interface to set socclk, fclk and dcefclk for smu.
    Add feature_mask parameter for smu_upload_dpm_level as socclk, fclk and
    dcefclk have dependency, without feature_mask to point out specific clk
    will make it fail to set some clk.
    Fix the function of smu_unforce_dpm_levels.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Gui Chengming <Jack.Gui@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 88803ad2cdd8..fa65b7509bc4 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -931,7 +931,8 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 	return size;
 }
 
-static int vega20_upload_dpm_level(struct smu_context *smu, bool max)
+static int vega20_upload_dpm_level(struct smu_context *smu, bool max,
+				   uint32_t feature_mask)
 {
 	struct vega20_dpm_table *dpm_table;
 	struct vega20_single_dpm_table *single_dpm_table;
@@ -940,7 +941,8 @@ static int vega20_upload_dpm_level(struct smu_context *smu, bool max)
 
 	dpm_table = smu->smu_dpm.dpm_context;
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_GFXCLK_BIT)) {
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_GFXCLK_BIT) &&
+	    (feature_mask & FEATURE_DPM_GFXCLK_MASK)) {
 		single_dpm_table = &(dpm_table->gfx_table);
 		freq = max ? single_dpm_table->dpm_state.soft_max_level :
 			single_dpm_table->dpm_state.soft_min_level;
@@ -954,7 +956,8 @@ static int vega20_upload_dpm_level(struct smu_context *smu, bool max)
 		}
 	}
 
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT)) {
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT) &&
+	    (feature_mask & FEATURE_DPM_UCLK_MASK)) {
 		single_dpm_table = &(dpm_table->mem_table);
 		freq = max ? single_dpm_table->dpm_state.soft_max_level :
 			single_dpm_table->dpm_state.soft_min_level;
@@ -968,6 +971,51 @@ static int vega20_upload_dpm_level(struct smu_context *smu, bool max)
 		}
 	}
 
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_SOCCLK_BIT) &&
+	    (feature_mask & FEATURE_DPM_SOCCLK_MASK)) {
+		single_dpm_table = &(dpm_table->soc_table);
+		freq = max ? single_dpm_table->dpm_state.soft_max_level :
+			single_dpm_table->dpm_state.soft_min_level;
+		ret = smu_send_smc_msg_with_param(smu,
+			(max ? SMU_MSG_SetSoftMaxByFreq : SMU_MSG_SetSoftMinByFreq),
+			(PPCLK_SOCCLK << 16) | (freq & 0xffff));
+		if (ret) {
+			pr_err("Failed to set soft %s socclk !\n",
+						max ? "max" : "min");
+			return ret;
+		}
+	}
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_FCLK_BIT) &&
+	    (feature_mask & FEATURE_DPM_FCLK_MASK)) {
+		single_dpm_table = &(dpm_table->fclk_table);
+		freq = max ? single_dpm_table->dpm_state.soft_max_level :
+			single_dpm_table->dpm_state.soft_min_level;
+		ret = smu_send_smc_msg_with_param(smu,
+			(max ? SMU_MSG_SetSoftMaxByFreq : SMU_MSG_SetSoftMinByFreq),
+			(PPCLK_FCLK << 16) | (freq & 0xffff));
+		if (ret) {
+			pr_err("Failed to set soft %s fclk !\n",
+						max ? "max" : "min");
+			return ret;
+		}
+	}
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_DCEFCLK_BIT) &&
+	    (feature_mask & FEATURE_DPM_DCEFCLK_MASK)) {
+		single_dpm_table = &(dpm_table->dcef_table);
+		freq = single_dpm_table->dpm_state.hard_min_level;
+		if (!max) {
+			ret = smu_send_smc_msg_with_param(smu,
+				SMU_MSG_SetHardMinByFreq,
+				(PPCLK_DCEFCLK << 16) | (freq & 0xffff));
+			if (ret) {
+				pr_err("Failed to set hard min dcefclk !\n");
+				return ret;
+			}
+		}
+	}
+
 	return ret;
 }
 
@@ -976,7 +1024,7 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 {
 	struct vega20_dpm_table *dpm_table;
 	struct vega20_single_dpm_table *single_dpm_table;
-	uint32_t soft_min_level, soft_max_level;
+	uint32_t soft_min_level, soft_max_level, hard_min_level;
 	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
 	int ret = 0;
 
@@ -1008,13 +1056,13 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 		single_dpm_table->dpm_state.soft_max_level =
 			single_dpm_table->dpm_levels[soft_max_level].value;
 
-		ret = vega20_upload_dpm_level(smu, false);
+		ret = vega20_upload_dpm_level(smu, false, FEATURE_DPM_GFXCLK_MASK);
 		if (ret) {
 			pr_err("Failed to upload boot level to lowest!\n");
 			break;
 		}
 
-		ret = vega20_upload_dpm_level(smu, true);
+		ret = vega20_upload_dpm_level(smu, true, FEATURE_DPM_GFXCLK_MASK);
 		if (ret)
 			pr_err("Failed to upload dpm max level to highest!\n");
 
@@ -1035,18 +1083,92 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 		single_dpm_table->dpm_state.soft_max_level =
 			single_dpm_table->dpm_levels[soft_max_level].value;
 
-		ret = vega20_upload_dpm_level(smu, false);
+		ret = vega20_upload_dpm_level(smu, false, FEATURE_DPM_UCLK_MASK);
+		if (ret) {
+			pr_err("Failed to upload boot level to lowest!\n");
+			break;
+		}
+
+		ret = vega20_upload_dpm_level(smu, true, FEATURE_DPM_UCLK_MASK);
+		if (ret)
+			pr_err("Failed to upload dpm max level to highest!\n");
+
+		break;
+
+	case PP_SOCCLK:
+		single_dpm_table = &(dpm_table->soc_table);
+
+		if (soft_max_level >= single_dpm_table->count) {
+			pr_err("Clock level specified %d is over max allowed %d\n",
+					soft_max_level, single_dpm_table->count - 1);
+			ret = -EINVAL;
+			break;
+		}
+
+		single_dpm_table->dpm_state.soft_min_level =
+			single_dpm_table->dpm_levels[soft_min_level].value;
+		single_dpm_table->dpm_state.soft_max_level =
+			single_dpm_table->dpm_levels[soft_max_level].value;
+
+		ret = vega20_upload_dpm_level(smu, false, FEATURE_DPM_SOCCLK_MASK);
 		if (ret) {
 			pr_err("Failed to upload boot level to lowest!\n");
 			break;
 		}
 
-		ret = vega20_upload_dpm_level(smu, true);
+		ret = vega20_upload_dpm_level(smu, true, FEATURE_DPM_SOCCLK_MASK);
 		if (ret)
 			pr_err("Failed to upload dpm max level to highest!\n");
 
 		break;
 
+	case PP_FCLK:
+		single_dpm_table = &(dpm_table->fclk_table);
+
+		if (soft_max_level >= single_dpm_table->count) {
+			pr_err("Clock level specified %d is over max allowed %d\n",
+					soft_max_level, single_dpm_table->count - 1);
+			ret = -EINVAL;
+			break;
+		}
+
+		single_dpm_table->dpm_state.soft_min_level =
+			single_dpm_table->dpm_levels[soft_min_level].value;
+		single_dpm_table->dpm_state.soft_max_level =
+			single_dpm_table->dpm_levels[soft_max_level].value;
+
+		ret = vega20_upload_dpm_level(smu, false, FEATURE_DPM_FCLK_MASK);
+		if (ret) {
+			pr_err("Failed to upload boot level to lowest!\n");
+			break;
+		}
+
+		ret = vega20_upload_dpm_level(smu, true, FEATURE_DPM_FCLK_MASK);
+		if (ret)
+			pr_err("Failed to upload dpm max level to highest!\n");
+
+		break;
+
+	case PP_DCEFCLK:
+		hard_min_level = soft_min_level;
+		single_dpm_table = &(dpm_table->dcef_table);
+
+		if (hard_min_level >= single_dpm_table->count) {
+			pr_err("Clock level specified %d is over max allowed %d\n",
+					hard_min_level, single_dpm_table->count - 1);
+			ret = -EINVAL;
+			break;
+		}
+
+		single_dpm_table->dpm_state.hard_min_level =
+			single_dpm_table->dpm_levels[hard_min_level].value;
+
+		ret = vega20_upload_dpm_level(smu, false, FEATURE_DPM_DCEFCLK_MASK);
+		if (ret)
+			pr_err("Failed to upload boot level to lowest!\n");
+
+		break;
+
 	case PP_PCIE:
 		break;
 
@@ -1722,14 +1844,23 @@ static int vega20_force_dpm_limit_value(struct smu_context *smu, bool highest)
 		dpm_table->mem_table.dpm_state.soft_max_level =
 		dpm_table->mem_table.dpm_levels[soft_level].value;
 
-	ret = vega20_upload_dpm_level(smu, false);
+	if (highest)
+		soft_level = vega20_find_highest_dpm_level(&(dpm_table->soc_table));
+	else
+		soft_level = vega20_find_lowest_dpm_level(&(dpm_table->soc_table));
+
+	dpm_table->soc_table.dpm_state.soft_min_level =
+		dpm_table->soc_table.dpm_state.soft_max_level =
+		dpm_table->soc_table.dpm_levels[soft_level].value;
+
+	ret = vega20_upload_dpm_level(smu, false, 0xFFFFFFFF);
 	if (ret) {
 		pr_err("Failed to upload boot level to %s!\n",
 				highest ? "highest" : "lowest");
 		return ret;
 	}
 
-	ret = vega20_upload_dpm_level(smu, true);
+	ret = vega20_upload_dpm_level(smu, true, 0xFFFFFFFF);
 	if (ret) {
 		pr_err("Failed to upload dpm max level to %s!\n!",
 				highest ? "highest" : "lowest");
@@ -1739,6 +1870,49 @@ static int vega20_force_dpm_limit_value(struct smu_context *smu, bool highest)
 	return ret;
 }
 
+static int vega20_unforce_dpm_levels(struct smu_context *smu)
+{
+	uint32_t soft_min_level, soft_max_level;
+	int ret = 0;
+	struct vega20_dpm_table *dpm_table =
+		(struct vega20_dpm_table *)smu->smu_dpm.dpm_context;
+
+	soft_min_level = vega20_find_lowest_dpm_level(&(dpm_table->gfx_table));
+	soft_max_level = vega20_find_highest_dpm_level(&(dpm_table->gfx_table));
+	dpm_table->gfx_table.dpm_state.soft_min_level =
+		dpm_table->gfx_table.dpm_levels[soft_min_level].value;
+	dpm_table->gfx_table.dpm_state.soft_max_level =
+		dpm_table->gfx_table.dpm_levels[soft_max_level].value;
+
+	soft_min_level = vega20_find_lowest_dpm_level(&(dpm_table->mem_table));
+	soft_max_level = vega20_find_highest_dpm_level(&(dpm_table->mem_table));
+	dpm_table->mem_table.dpm_state.soft_min_level =
+		dpm_table->gfx_table.dpm_levels[soft_min_level].value;
+	dpm_table->mem_table.dpm_state.soft_max_level =
+		dpm_table->gfx_table.dpm_levels[soft_max_level].value;
+
+	soft_min_level = vega20_find_lowest_dpm_level(&(dpm_table->soc_table));
+	soft_max_level = vega20_find_highest_dpm_level(&(dpm_table->soc_table));
+	dpm_table->soc_table.dpm_state.soft_min_level =
+		dpm_table->soc_table.dpm_levels[soft_min_level].value;
+	dpm_table->soc_table.dpm_state.soft_max_level =
+		dpm_table->soc_table.dpm_levels[soft_max_level].value;
+
+	ret = smu_upload_dpm_level(smu, false, 0xFFFFFFFF);
+	if (ret) {
+		pr_err("Failed to upload DPM Bootup Levels!");
+		return ret;
+	}
+
+	ret = smu_upload_dpm_level(smu, true, 0xFFFFFFFF);
+	if (ret) {
+		pr_err("Failed to upload DPM Max Levels!");
+		return ret;
+	}
+
+	return ret;
+}
+
 static enum amd_dpm_forced_level vega20_get_performance_level(struct smu_context *smu)
 {
 	struct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);
@@ -2186,6 +2360,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.apply_clocks_adjust_rules = vega20_apply_clocks_adjust_rules,
 	.notify_smc_dispaly_config = vega20_notify_smc_dispaly_config,
 	.force_dpm_limit_value = vega20_force_dpm_limit_value,
+	.unforce_dpm_levels = vega20_unforce_dpm_levels,
 	.upload_dpm_level = vega20_upload_dpm_level,
 	.get_profiling_clk_mask = vega20_get_profiling_clk_mask,
 };

commit 0967610142275c3aa1b73d923505cb8e73916af5
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Tue Feb 19 18:18:46 2019 +0800

    drm/amd/powerplay: support sysfs to get socclk, fclk, dcefclk
    
    Add sys interface to get socclk, fclk and dcefclk for smu.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Gui Chengming <Jack.Gui@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 6aa94ee81b59..88803ad2cdd8 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -773,6 +773,62 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 				? "*" : "");
 		break;
 
+	case PP_SOCCLK:
+		ret = smu_get_current_clk_freq(smu, PPCLK_SOCCLK, &now);
+		if (ret) {
+			pr_err("Attempt to get current socclk Failed!");
+			return ret;
+		}
+
+		single_dpm_table = &(dpm_table->soc_table);
+		ret = vega20_get_clk_table(smu, &clocks, single_dpm_table);
+		if (ret) {
+			pr_err("Attempt to get socclk levels Failed!");
+			return ret;
+		}
+
+		for (i = 0; i < clocks.num_levels; i++)
+			size += sprintf(buf + size, "%d: %uMhz %s\n",
+				i, clocks.data[i].clocks_in_khz / 1000,
+				(clocks.data[i].clocks_in_khz == now * 10)
+				? "*" : "");
+		break;
+
+	case PP_FCLK:
+		ret = smu_get_current_clk_freq(smu, PPCLK_FCLK, &now);
+		if (ret) {
+			pr_err("Attempt to get current fclk Failed!");
+			return ret;
+		}
+
+		single_dpm_table = &(dpm_table->fclk_table);
+		for (i = 0; i < single_dpm_table->count; i++)
+			size += sprintf(buf + size, "%d: %uMhz %s\n",
+				i, single_dpm_table->dpm_levels[i].value,
+				(single_dpm_table->dpm_levels[i].value == now / 100)
+				? "*" : "");
+		break;
+
+	case PP_DCEFCLK:
+		ret = smu_get_current_clk_freq(smu, PPCLK_DCEFCLK, &now);
+		if (ret) {
+			pr_err("Attempt to get current dcefclk Failed!");
+			return ret;
+		}
+
+		single_dpm_table = &(dpm_table->dcef_table);
+		ret = vega20_get_clk_table(smu, &clocks, single_dpm_table);
+		if (ret) {
+			pr_err("Attempt to get dcefclk levels Failed!");
+			return ret;
+		}
+
+		for (i = 0; i < clocks.num_levels; i++)
+			size += sprintf(buf + size, "%d: %uMhz %s\n",
+				i, clocks.data[i].clocks_in_khz / 1000,
+				(clocks.data[i].clocks_in_khz == now * 10) ? "*" : "");
+		break;
+
 	case PP_PCIE:
 		break;
 

commit cbbf388fa26bff77e2a1be56dadee1eb41aa110d
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Mon Jan 28 12:19:57 2019 +0800

    drm/amd/powerplay: set dpm table of vclk/dclk/eclk for smu11 (v2)
    
    Set default dpm table fo vclk, dclk and eclk.
    Open clk adjust rules for vclk, dclk.
    
    v2: Open clk adjust rules for eclk.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 300462aff83a..6aa94ee81b59 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -542,11 +542,10 @@ static int vega20_set_default_dpm_table(struct smu_context *smu)
 	}
 	vega20_init_single_dpm_state(&(single_dpm_table->dpm_state));
 
-#if 0
 	/* eclk */
 	single_dpm_table = &(dpm_table->eclk_table);
 
-	if (feature->fea_enabled[FEATURE_DPM_VCE_BIT]) {
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_VCE_BIT)) {
 		ret = vega20_set_single_dpm_table(smu, single_dpm_table, PPCLK_ECLK);
 		if (ret) {
 			pr_err("[SetupDefaultDpmTable] failed to get eclk dpm levels!");
@@ -554,14 +553,14 @@ static int vega20_set_default_dpm_table(struct smu_context *smu)
 		}
 	} else {
 		single_dpm_table->count = 1;
-		single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.eclock / 100;
+		single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.eclk / 100;
 	}
 	vega20_init_single_dpm_state(&(single_dpm_table->dpm_state));
 
 	/* vclk */
 	single_dpm_table = &(dpm_table->vclk_table);
 
-	if (feature->fea_enabled[FEATURE_DPM_UVD_BIT]) {
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_UVD_BIT)) {
 		ret = vega20_set_single_dpm_table(smu, single_dpm_table, PPCLK_VCLK);
 		if (ret) {
 			pr_err("[SetupDefaultDpmTable] failed to get vclk dpm levels!");
@@ -569,14 +568,14 @@ static int vega20_set_default_dpm_table(struct smu_context *smu)
 		}
 	} else {
 		single_dpm_table->count = 1;
-		single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.vclock / 100;
+		single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.vclk / 100;
 	}
 	vega20_init_single_dpm_state(&(single_dpm_table->dpm_state));
 
 	/* dclk */
 	single_dpm_table = &(dpm_table->dclk_table);
 
-	if (feature->fea_enabled[FEATURE_DPM_UVD_BIT]) {
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_UVD_BIT)) {
 		ret = vega20_set_single_dpm_table(smu, single_dpm_table, PPCLK_DCLK);
 		if (ret) {
 			pr_err("[SetupDefaultDpmTable] failed to get dclk dpm levels!");
@@ -584,10 +583,9 @@ static int vega20_set_default_dpm_table(struct smu_context *smu)
 		}
 	} else {
 		single_dpm_table->count = 1;
-		single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.dclock / 100;
+		single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.dclk / 100;
 	}
 	vega20_init_single_dpm_state(&(single_dpm_table->dpm_state));
-#endif
 
 	/* dcefclk */
 	single_dpm_table = &(dpm_table->dcef_table);
@@ -1483,7 +1481,6 @@ static int vega20_apply_clocks_adjust_rules(struct smu_context *smu)
 	if (smu->display_config->nb_pstate_switch_disable)
 		dpm_table->dpm_state.hard_min_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
 
-#if 0
 	/* vclk */
 	dpm_table = &(dpm_ctx->vclk_table);
 	dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[0].value;
@@ -1517,7 +1514,6 @@ static int vega20_apply_clocks_adjust_rules(struct smu_context *smu)
 			dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
 			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
 		}
-#endif
 
 	/* socclk */
 	dpm_table = &(dpm_ctx->soc_table);
@@ -1536,7 +1532,6 @@ static int vega20_apply_clocks_adjust_rules(struct smu_context *smu)
 			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
 		}
 
-#if 0
 	/* eclk */
 	dpm_table = &(dpm_ctx->eclk_table);
 	dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[0].value;
@@ -1553,7 +1548,6 @@ static int vega20_apply_clocks_adjust_rules(struct smu_context *smu)
 			dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
 			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
 		}
-#endif
 	return 0;
 }
 

commit bc0fcffd36baa1cbbf2a6e951e4f1acad3aa8c90
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Thu Jan 24 19:53:40 2019 +0800

    drm/amd/powerplay: Unify smu handle task function (v2)
    
    Unify power stade adjust function into smu_handle_task by the judgment
    of task_id.
    Move functions which have no relationship with smu version into the file
    of amdgpu_smu.
    Modified the function of smu_display_config_changed into two part.
    Unify some similiar function.
    
    v2: Correct the operation of upload dpm level when force dpm limit value.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index a90bf77dd9eb..300462aff83a 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -877,71 +877,39 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 	return size;
 }
 
-static int vega20_upload_dpm_min_level(struct smu_context *smu)
+static int vega20_upload_dpm_level(struct smu_context *smu, bool max)
 {
 	struct vega20_dpm_table *dpm_table;
 	struct vega20_single_dpm_table *single_dpm_table;
-	uint32_t min_freq;
+	uint32_t freq;
 	int ret = 0;
 
 	dpm_table = smu->smu_dpm.dpm_context;
 
 	if (smu_feature_is_enabled(smu, FEATURE_DPM_GFXCLK_BIT)) {
 		single_dpm_table = &(dpm_table->gfx_table);
-		min_freq = single_dpm_table->dpm_state.soft_min_level;
+		freq = max ? single_dpm_table->dpm_state.soft_max_level :
+			single_dpm_table->dpm_state.soft_min_level;
 		ret = smu_send_smc_msg_with_param(smu,
-			SMU_MSG_SetSoftMinByFreq,
-			(PPCLK_GFXCLK << 16) | (min_freq & 0xffff));
+			(max ? SMU_MSG_SetSoftMaxByFreq : SMU_MSG_SetSoftMinByFreq),
+			(PPCLK_GFXCLK << 16) | (freq & 0xffff));
 		if (ret) {
-			pr_err("Failed to set soft min gfxclk !\n");
+			pr_err("Failed to set soft %s gfxclk !\n",
+						max ? "max" : "min");
 			return ret;
 		}
 	}
 
 	if (smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT)) {
 		single_dpm_table = &(dpm_table->mem_table);
-		min_freq = single_dpm_table->dpm_state.soft_min_level;
+		freq = max ? single_dpm_table->dpm_state.soft_max_level :
+			single_dpm_table->dpm_state.soft_min_level;
 		ret = smu_send_smc_msg_with_param(smu,
-			SMU_MSG_SetSoftMinByFreq,
-			(PPCLK_UCLK << 16) | (min_freq & 0xffff));
+			(max ? SMU_MSG_SetSoftMaxByFreq : SMU_MSG_SetSoftMinByFreq),
+			(PPCLK_UCLK << 16) | (freq & 0xffff));
 		if (ret) {
-			pr_err("Failed to set soft min memclk !\n");
-			return ret;
-		}
-	}
-
-	return ret;
-}
-
-static int vega20_upload_dpm_max_level(struct smu_context *smu)
-{
-	struct vega20_dpm_table *dpm_table;
-	struct vega20_single_dpm_table *single_dpm_table;
-	uint32_t max_freq;
-	int ret = 0;
-
-	dpm_table = smu->smu_dpm.dpm_context;
-
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_GFXCLK_BIT)) {
-		single_dpm_table = &(dpm_table->gfx_table);
-		max_freq = single_dpm_table->dpm_state.soft_max_level;
-		ret = smu_send_smc_msg_with_param(smu,
-			SMU_MSG_SetSoftMaxByFreq,
-			(PPCLK_GFXCLK << 16) | (max_freq & 0xffff));
-		if (ret) {
-			pr_err("Failed to set soft max gfxclk !\n");
-			return ret;
-		}
-	}
-
-	if (smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT)) {
-		single_dpm_table = &(dpm_table->mem_table);
-		max_freq = single_dpm_table->dpm_state.soft_max_level;
-		ret = smu_send_smc_msg_with_param(smu,
-			SMU_MSG_SetSoftMaxByFreq,
-			(PPCLK_UCLK << 16) | (max_freq & 0xffff));
-		if (ret) {
-			pr_err("Failed to set soft max memclk !\n");
+			pr_err("Failed to set soft %s memclk !\n",
+						max ? "max" : "min");
 			return ret;
 		}
 	}
@@ -986,13 +954,13 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 		single_dpm_table->dpm_state.soft_max_level =
 			single_dpm_table->dpm_levels[soft_max_level].value;
 
-		ret = vega20_upload_dpm_min_level(smu);
+		ret = vega20_upload_dpm_level(smu, false);
 		if (ret) {
 			pr_err("Failed to upload boot level to lowest!\n");
 			break;
 		}
 
-		ret = vega20_upload_dpm_max_level(smu);
+		ret = vega20_upload_dpm_level(smu, true);
 		if (ret)
 			pr_err("Failed to upload dpm max level to highest!\n");
 
@@ -1013,13 +981,13 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 		single_dpm_table->dpm_state.soft_max_level =
 			single_dpm_table->dpm_levels[soft_max_level].value;
 
-		ret = vega20_upload_dpm_min_level(smu);
+		ret = vega20_upload_dpm_level(smu, false);
 		if (ret) {
 			pr_err("Failed to upload boot level to lowest!\n");
 			break;
 		}
 
-		ret = vega20_upload_dpm_max_level(smu);
+		ret = vega20_upload_dpm_level(smu, true);
 		if (ret)
 			pr_err("Failed to upload dpm max level to highest!\n");
 
@@ -1389,11 +1357,26 @@ vega20_set_uclk_to_highest_dpm_level(struct smu_context *smu,
 	return ret;
 }
 
-static int vega20_display_config_changed(struct smu_context *smu)
+static int vega20_pre_display_config_changed(struct smu_context *smu)
 {
 	int ret = 0;
 	struct vega20_dpm_table *dpm_table = smu->smu_dpm.dpm_context;
 
+	if (!smu->smu_dpm.dpm_context)
+		return -EINVAL;
+
+	smu_send_smc_msg_with_param(smu, SMU_MSG_NumOfDisplays, 0);
+	ret = vega20_set_uclk_to_highest_dpm_level(smu,
+						   &dpm_table->mem_table);
+	if (ret)
+		pr_err("Failed to set uclk to highest dpm level");
+	return ret;
+}
+
+static int vega20_display_config_changed(struct smu_context *smu)
+{
+	int ret = 0;
+
 	if (!smu->funcs)
 		return -EINVAL;
 
@@ -1402,14 +1385,6 @@ static int vega20_display_config_changed(struct smu_context *smu)
 	    !smu->smu_table.tables[TABLE_WATERMARKS].cpu_addr)
 		return -EINVAL;
 
-	smu_send_smc_msg_with_param(smu, SMU_MSG_NumOfDisplays, 0);
-	ret = vega20_set_uclk_to_highest_dpm_level(smu,
-						   &dpm_table->mem_table);
-	if (ret) {
-		pr_err("Failed to set uclk to highest dpm level");
-		return ret;
-	}
-
 	if ((smu->watermarks_bitmap & WATERMARKS_EXIST) &&
 	    !(smu->watermarks_bitmap & WATERMARKS_LOADED)) {
 		ret = smu->funcs->write_watermarks_table(smu);
@@ -1672,85 +1647,42 @@ static uint32_t vega20_find_highest_dpm_level(struct vega20_single_dpm_table *ta
 	return i;
 }
 
-static int vega20_force_dpm_highest(struct smu_context *smu)
+static int vega20_force_dpm_limit_value(struct smu_context *smu, bool highest)
 {
 	uint32_t soft_level;
 	int ret = 0;
-	struct vega20_dpm_table *dpm_table = (struct vega20_dpm_table *)smu->smu_dpm.dpm_context;
+	struct vega20_dpm_table *dpm_table =
+		(struct vega20_dpm_table *)smu->smu_dpm.dpm_context;
 
-	soft_level = vega20_find_highest_dpm_level(&(dpm_table->gfx_table));
+	if (highest)
+		soft_level = vega20_find_highest_dpm_level(&(dpm_table->gfx_table));
+	else
+		soft_level = vega20_find_lowest_dpm_level(&(dpm_table->gfx_table));
 
 	dpm_table->gfx_table.dpm_state.soft_min_level =
 		dpm_table->gfx_table.dpm_state.soft_max_level =
 		dpm_table->gfx_table.dpm_levels[soft_level].value;
 
-	soft_level = vega20_find_highest_dpm_level(&(dpm_table->mem_table));
+	if (highest)
+		soft_level = vega20_find_highest_dpm_level(&(dpm_table->mem_table));
+	else
+		soft_level = vega20_find_lowest_dpm_level(&(dpm_table->mem_table));
 
 	dpm_table->mem_table.dpm_state.soft_min_level =
 		dpm_table->mem_table.dpm_state.soft_max_level =
 		dpm_table->mem_table.dpm_levels[soft_level].value;
 
-	ret = vega20_upload_dpm_min_level(smu);
+	ret = vega20_upload_dpm_level(smu, false);
 	if (ret) {
-		pr_err("Failed to upload boot level to highest!");
+		pr_err("Failed to upload boot level to %s!\n",
+				highest ? "highest" : "lowest");
 		return ret;
 	}
 
-	ret = vega20_upload_dpm_max_level(smu);
+	ret = vega20_upload_dpm_level(smu, true);
 	if (ret) {
-		pr_err("Failed to upload dpm max level to highest!");
-		return ret;
-	}
-
-	return ret;
-}
-
-static int vega20_force_dpm_lowest(struct smu_context *smu)
-{
-	uint32_t soft_level;
-	int ret = 0;
-	struct vega20_dpm_table *dpm_table = (struct vega20_dpm_table *)smu->smu_dpm.dpm_context;
-
-	soft_level = vega20_find_lowest_dpm_level(&(dpm_table->gfx_table));
-
-	dpm_table->gfx_table.dpm_state.soft_min_level =
-		dpm_table->gfx_table.dpm_state.soft_max_level =
-		dpm_table->gfx_table.dpm_levels[soft_level].value;
-
-	soft_level = vega20_find_lowest_dpm_level(&(dpm_table->mem_table));
-
-	dpm_table->mem_table.dpm_state.soft_min_level =
-		dpm_table->mem_table.dpm_state.soft_max_level =
-		dpm_table->mem_table.dpm_levels[soft_level].value;
-
-	ret = vega20_upload_dpm_min_level(smu);
-	if (ret) {
-		pr_err("Failed to upload boot level to lowest!");
-		return ret;
-	}
-
-	ret = vega20_upload_dpm_max_level(smu);
-	if (ret) {
-		pr_err("Failed to upload dpm max level to lowest!");
-		return ret;
-	}
-
-	return ret;
-}
-
-static int vega20_unforce_dpm_levels(struct smu_context *smu)
-{
-	int ret = 0;
-
-	ret = vega20_upload_dpm_min_level(smu);
-	if (ret) {
-		pr_err("Failed to upload DPM Bootup Levels!");
-		return ret;
-	}
-
-	ret = vega20_upload_dpm_max_level(smu);
-	if (ret) {
-		pr_err("Failed to upload DPM Max Levels!");
+		pr_err("Failed to upload dpm max level to %s!\n!",
+				highest ? "highest" : "lowest");
 		return ret;
 	}
 
@@ -1771,78 +1703,6 @@ static enum amd_dpm_forced_level vega20_get_performance_level(struct smu_context
 	return smu_dpm_ctx->dpm_level;
 }
 
-static int vega20_adjust_power_state_dynamic(struct smu_context *smu,
-					     enum amd_dpm_forced_level level)
-{
-	int ret = 0;
-	int index = 0;
-	uint32_t sclk_mask, mclk_mask, soc_mask;
-	long workload;
-	struct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);
-
-	ret = vega20_display_config_changed(smu);
-	if (ret) {
-		pr_err("Failed to change display config!");
-		return ret;
-	}
-	ret = vega20_apply_clocks_adjust_rules(smu);
-	if (ret) {
-		pr_err("Failed to apply clocks adjust rules!");
-		return ret;
-	}
-	ret = vega20_notify_smc_dispaly_config(smu);
-	if (ret) {
-		pr_err("Failed to notify smc display config!");
-		return ret;
-	}
-
-	switch (level) {
-	case AMD_DPM_FORCED_LEVEL_HIGH:
-		ret = vega20_force_dpm_highest(smu);
-		break;
-	case AMD_DPM_FORCED_LEVEL_LOW:
-		ret = vega20_force_dpm_lowest(smu);
-		break;
-
-	case AMD_DPM_FORCED_LEVEL_AUTO:
-		ret = vega20_unforce_dpm_levels(smu);
-		break;
-
-	case AMD_DPM_FORCED_LEVEL_PROFILE_STANDARD:
-	case AMD_DPM_FORCED_LEVEL_PROFILE_MIN_SCLK:
-	case AMD_DPM_FORCED_LEVEL_PROFILE_MIN_MCLK:
-	case AMD_DPM_FORCED_LEVEL_PROFILE_PEAK:
-		ret = vega20_get_profiling_clk_mask(smu, level,
-						    &sclk_mask,
-						    &mclk_mask,
-						    &soc_mask);
-		if (ret)
-			return ret;
-		vega20_force_clk_levels(smu, PP_SCLK, 1 << sclk_mask);
-		vega20_force_clk_levels(smu, PP_MCLK, 1 << mclk_mask);
-		break;
-
-	case AMD_DPM_FORCED_LEVEL_MANUAL:
-	case AMD_DPM_FORCED_LEVEL_PROFILE_EXIT:
-	default:
-		break;
-	}
-
-	if (!ret)
-		smu_dpm_ctx->dpm_level = level;
-
-	if (smu_dpm_ctx->dpm_level != AMD_DPM_FORCED_LEVEL_MANUAL) {
-		index = fls(smu->workload_mask);
-		index = index > 0 && index <= WORKLOAD_POLICY_MAX ? index - 1 : 0;
-		workload = smu->workload_setting[index];
-
-		if (smu->power_profile_mode != workload)
-			smu->funcs->set_power_profile_mode(smu, &workload, 0);
-	}
-
-	return ret;
-}
-
 static int
 vega20_force_performance_level(struct smu_context *smu, enum amd_dpm_forced_level level)
 {
@@ -1861,7 +1721,8 @@ vega20_force_performance_level(struct smu_context *smu, enum amd_dpm_forced_leve
 	mutex_lock(&smu->mutex);
 
 	smu->adev->ip_blocks[i].version->funcs->enable_umd_pstate(smu, &level);
-	ret = vega20_adjust_power_state_dynamic(smu, level);
+	ret = smu_handle_task(smu, level,
+			      AMD_PP_TASK_READJUST_POWER_STATE);
 
 	mutex_unlock(&smu->mutex);
 
@@ -2009,7 +1870,8 @@ static int vega20_set_od_percentage(struct smu_context *smu,
 		single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.gfxclk / 100;
 	}
 
-	ret = vega20_adjust_power_state_dynamic(smu, smu_dpm->dpm_level);
+	ret = smu_handle_task(smu, smu_dpm->dpm_level,
+			      AMD_PP_TASK_READJUST_POWER_STATE);
 
 set_od_failed:
 	mutex_unlock(&(smu->mutex));
@@ -2239,7 +2101,8 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 
 	if (type == PP_OD_COMMIT_DPM_TABLE) {
 		mutex_lock(&(smu->mutex));
-		ret = vega20_adjust_power_state_dynamic(smu, smu_dpm->dpm_level);
+		ret = smu_handle_task(smu, smu_dpm->dpm_level,
+				      AMD_PP_TASK_READJUST_POWER_STATE);
 		mutex_unlock(&(smu->mutex));
 	}
 
@@ -2268,6 +2131,13 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.update_specified_od8_value = vega20_update_specified_od8_value,
 	.set_od_percentage = vega20_set_od_percentage,
 	.od_edit_dpm_table = vega20_odn_edit_dpm_table,
+	.pre_display_config_changed = vega20_pre_display_config_changed,
+	.display_config_changed = vega20_display_config_changed,
+	.apply_clocks_adjust_rules = vega20_apply_clocks_adjust_rules,
+	.notify_smc_dispaly_config = vega20_notify_smc_dispaly_config,
+	.force_dpm_limit_value = vega20_force_dpm_limit_value,
+	.upload_dpm_level = vega20_upload_dpm_level,
+	.get_profiling_clk_mask = vega20_get_profiling_clk_mask,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 1507418667f8b0893c90fa8bd4ff965cd4bc14ea
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Wed Jan 23 13:37:39 2019 +0800

    drm/amd/powerplay: dpm clk can be set only when performance level is manual
    
    Add condition to make dpm clk can not be set when perfomance level isn't
    equal to manual.
    Add mutex lock to smu when set dpm clk.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 2833bd8a8078..a90bf77dd9eb 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -955,7 +955,15 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 	struct vega20_dpm_table *dpm_table;
 	struct vega20_single_dpm_table *single_dpm_table;
 	uint32_t soft_min_level, soft_max_level;
-	int ret;
+	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
+	int ret = 0;
+
+	if (smu_dpm->dpm_level != AMD_DPM_FORCED_LEVEL_MANUAL) {
+		pr_info("force clock level is for dpm manual mode only.\n");
+		return -EINVAL;
+	}
+
+	mutex_lock(&(smu->mutex));
 
 	soft_min_level = mask ? (ffs(mask) - 1) : 0;
 	soft_max_level = mask ? (fls(mask) - 1) : 0;
@@ -969,7 +977,8 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 		if (soft_max_level >= single_dpm_table->count) {
 			pr_err("Clock level specified %d is over max allowed %d\n",
 					soft_max_level, single_dpm_table->count - 1);
-			return -EINVAL;
+			ret = -EINVAL;
+			break;
 		}
 
 		single_dpm_table->dpm_state.soft_min_level =
@@ -980,14 +989,12 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 		ret = vega20_upload_dpm_min_level(smu);
 		if (ret) {
 			pr_err("Failed to upload boot level to lowest!\n");
-			return ret;
+			break;
 		}
 
 		ret = vega20_upload_dpm_max_level(smu);
-		if (ret) {
+		if (ret)
 			pr_err("Failed to upload dpm max level to highest!\n");
-			return ret;
-		}
 
 		break;
 
@@ -997,7 +1004,8 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 		if (soft_max_level >= single_dpm_table->count) {
 			pr_err("Clock level specified %d is over max allowed %d\n",
 					soft_max_level, single_dpm_table->count - 1);
-			return -EINVAL;
+			ret = -EINVAL;
+			break;
 		}
 
 		single_dpm_table->dpm_state.soft_min_level =
@@ -1008,14 +1016,12 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 		ret = vega20_upload_dpm_min_level(smu);
 		if (ret) {
 			pr_err("Failed to upload boot level to lowest!\n");
-			return ret;
+			break;
 		}
 
 		ret = vega20_upload_dpm_max_level(smu);
-		if (ret) {
+		if (ret)
 			pr_err("Failed to upload dpm max level to highest!\n");
-			return ret;
-		}
 
 		break;
 
@@ -1026,7 +1032,8 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 		break;
 	}
 
-	return 0;
+	mutex_unlock(&(smu->mutex));
+	return ret;
 }
 
 static int vega20_get_clock_by_type_with_latency(struct smu_context *smu,

commit c16df976a2fe2ea145bf20343efb3e74f073e9e7
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Wed Jan 23 11:10:59 2019 +0800

    drm/amd/powerplay: adjust power state when set od_clk
    
    Expose the function of adjust_power_state_dynamic to make it common to
    other functions.
    Add the operate of adjust powet state when set od percentage or
    overdrive commit dpm table.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index ff44ef89204a..2833bd8a8078 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1764,44 +1764,35 @@ static enum amd_dpm_forced_level vega20_get_performance_level(struct smu_context
 	return smu_dpm_ctx->dpm_level;
 }
 
-static int
-vega20_force_performance_level(struct smu_context *smu, enum amd_dpm_forced_level level)
+static int vega20_adjust_power_state_dynamic(struct smu_context *smu,
+					     enum amd_dpm_forced_level level)
 {
 	int ret = 0;
 	int index = 0;
-	int i = 0;
 	uint32_t sclk_mask, mclk_mask, soc_mask;
 	long workload;
 	struct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);
-	if (!smu_dpm_ctx->dpm_context)
-		return -EINVAL;
 
-	for (i = 0; i < smu->adev->num_ip_blocks; i++) {
-		if (smu->adev->ip_blocks[i].version->type == AMD_IP_BLOCK_TYPE_SMC)
-			break;
-	}
-	mutex_lock(&smu->mutex);
-	smu->adev->ip_blocks[i].version->funcs->enable_umd_pstate(smu, &level);
 	ret = vega20_display_config_changed(smu);
 	if (ret) {
 		pr_err("Failed to change display config!");
-		goto failed;
+		return ret;
 	}
 	ret = vega20_apply_clocks_adjust_rules(smu);
 	if (ret) {
 		pr_err("Failed to apply clocks adjust rules!");
-		goto failed;
+		return ret;
 	}
 	ret = vega20_notify_smc_dispaly_config(smu);
 	if (ret) {
 		pr_err("Failed to notify smc display config!");
-		goto failed;
+		return ret;
 	}
+
 	switch (level) {
 	case AMD_DPM_FORCED_LEVEL_HIGH:
 		ret = vega20_force_dpm_highest(smu);
 		break;
-
 	case AMD_DPM_FORCED_LEVEL_LOW:
 		ret = vega20_force_dpm_lowest(smu);
 		break;
@@ -1819,7 +1810,7 @@ vega20_force_performance_level(struct smu_context *smu, enum amd_dpm_forced_leve
 						    &mclk_mask,
 						    &soc_mask);
 		if (ret)
-			goto failed;
+			return ret;
 		vega20_force_clk_levels(smu, PP_SCLK, 1 << sclk_mask);
 		vega20_force_clk_levels(smu, PP_MCLK, 1 << mclk_mask);
 		break;
@@ -1842,8 +1833,31 @@ vega20_force_performance_level(struct smu_context *smu, enum amd_dpm_forced_leve
 			smu->funcs->set_power_profile_mode(smu, &workload, 0);
 	}
 
-failed:
+	return ret;
+}
+
+static int
+vega20_force_performance_level(struct smu_context *smu, enum amd_dpm_forced_level level)
+{
+	int ret = 0;
+	int i;
+	struct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);
+
+	if (!smu_dpm_ctx->dpm_context)
+		return -EINVAL;
+
+	for (i = 0; i < smu->adev->num_ip_blocks; i++) {
+		if (smu->adev->ip_blocks[i].version->type == AMD_IP_BLOCK_TYPE_SMC)
+			break;
+	}
+
+	mutex_lock(&smu->mutex);
+
+	smu->adev->ip_blocks[i].version->funcs->enable_umd_pstate(smu, &level);
+	ret = vega20_adjust_power_state_dynamic(smu, level);
+
 	mutex_unlock(&smu->mutex);
+
 	return ret;
 }
 
@@ -1934,9 +1948,12 @@ static int vega20_set_od_percentage(struct smu_context *smu,
 	struct vega20_single_dpm_table *single_dpm_table;
 	struct vega20_single_dpm_table *golden_dpm_table;
 	uint32_t od_clk, index;
-	int ret, feature_enabled;
+	int ret = 0;
+	int feature_enabled;
 	PPCLK_e clk_id;
 
+	mutex_lock(&(smu->mutex));
+
 	dpm_table = smu_dpm->dpm_context;
 	golden_table = smu_dpm->golden_dpm_context;
 
@@ -1956,10 +1973,13 @@ static int vega20_set_od_percentage(struct smu_context *smu,
 		index = OD8_SETTING_UCLK_FMAX;
 		break;
 	default:
-		return -EINVAL;
+		ret = -EINVAL;
 		break;
 	}
 
+	if (ret)
+		goto set_od_failed;
+
 	od_clk = golden_dpm_table->dpm_levels[golden_dpm_table->count - 1].value * value;
 	od_clk /= 100;
 	od_clk += golden_dpm_table->dpm_levels[golden_dpm_table->count - 1].value;
@@ -1967,7 +1987,7 @@ static int vega20_set_od_percentage(struct smu_context *smu,
 	ret = smu_update_od8_settings(smu, index, od_clk);
 	if (ret) {
 		pr_err("[Setoverdrive] failed to set od clk!\n");
-		return ret;
+		goto set_od_failed;
 	}
 
 	if (feature_enabled) {
@@ -1975,14 +1995,19 @@ static int vega20_set_od_percentage(struct smu_context *smu,
 						  clk_id);
 		if (ret) {
 			pr_err("[Setoverdrive] failed to refresh dpm table!\n");
-			return ret;
+			goto set_od_failed;
 		}
 	} else {
 		single_dpm_table->count = 1;
 		single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.gfxclk / 100;
 	}
 
-	return 0;
+	ret = vega20_adjust_power_state_dynamic(smu, smu_dpm->dpm_level);
+
+set_od_failed:
+	mutex_unlock(&(smu->mutex));
+
+	return ret;
 }
 
 static int vega20_odn_edit_dpm_table(struct smu_context *smu,
@@ -1999,7 +2024,8 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 		(struct vega20_od8_settings *)table_context->od8_settings;
 	struct pp_clock_levels_with_latency clocks;
 	int32_t input_index, input_clk, input_vol, i;
-	int od8_id, ret;
+	int od8_id;
+	int ret = 0;
 
 	dpm_table = smu_dpm->dpm_context;
 
@@ -2204,7 +2230,13 @@ static int vega20_odn_edit_dpm_table(struct smu_context *smu,
 		return -EINVAL;
 	}
 
-	return 0;
+	if (type == PP_OD_COMMIT_DPM_TABLE) {
+		mutex_lock(&(smu->mutex));
+		ret = vega20_adjust_power_state_dynamic(smu, smu_dpm->dpm_level);
+		mutex_unlock(&(smu->mutex));
+	}
+
+	return ret;
 }
 
 static const struct pptable_funcs vega20_ppt_funcs = {

commit e388cc474d361469126882f454cbd8881ab3b259
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Mon Jan 21 14:58:38 2019 +0800

    drm/amd/powerplay: add sys interface to set pp_od_clk_voltage for smu
    
    Add sys interface to set pp_od_clk_voltage for smu.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index d025f54285ed..ff44ef89204a 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1985,6 +1985,228 @@ static int vega20_set_od_percentage(struct smu_context *smu,
 	return 0;
 }
 
+static int vega20_odn_edit_dpm_table(struct smu_context *smu,
+				     enum PP_OD_DPM_TABLE_COMMAND type,
+				     long *input, uint32_t size)
+{
+	struct smu_table_context *table_context = &smu->smu_table;
+	OverDriveTable_t *od_table =
+		(OverDriveTable_t *)(table_context->overdrive_table);
+	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
+	struct vega20_dpm_table *dpm_table = NULL;
+	struct vega20_single_dpm_table *single_dpm_table;
+	struct vega20_od8_settings *od8_settings =
+		(struct vega20_od8_settings *)table_context->od8_settings;
+	struct pp_clock_levels_with_latency clocks;
+	int32_t input_index, input_clk, input_vol, i;
+	int od8_id, ret;
+
+	dpm_table = smu_dpm->dpm_context;
+
+	if (!input) {
+		pr_warn("NULL user input for clock and voltage\n");
+		return -EINVAL;
+	}
+
+	switch (type) {
+	case PP_OD_EDIT_SCLK_VDDC_TABLE:
+		if (!(od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMIN].feature_id &&
+		      od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMAX].feature_id)) {
+			pr_info("Sclk min/max frequency overdrive not supported\n");
+			return -EOPNOTSUPP;
+		}
+
+		for (i = 0; i < size; i += 2) {
+			if (i + 2 > size) {
+				pr_info("invalid number of input parameters %d\n", size);
+				return -EINVAL;
+			}
+
+			input_index = input[i];
+			input_clk = input[i + 1];
+
+			if (input_index != 0 && input_index != 1) {
+				pr_info("Invalid index %d\n", input_index);
+				pr_info("Support min/max sclk frequency settingonly which index by 0/1\n");
+				return -EINVAL;
+			}
+
+			if (input_clk < od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMIN].min_value ||
+			    input_clk > od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMAX].max_value) {
+				pr_info("clock freq %d is not within allowed range [%d - %d]\n",
+					input_clk,
+					od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMIN].min_value,
+					od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMAX].max_value);
+				return -EINVAL;
+			}
+
+			if (input_index == 0 && od_table->GfxclkFmin != input_clk) {
+				od_table->GfxclkFmin = input_clk;
+				table_context->od_gfxclk_update = true;
+			} else if (input_index == 1 && od_table->GfxclkFmax != input_clk) {
+				od_table->GfxclkFmax = input_clk;
+				table_context->od_gfxclk_update = true;
+			}
+		}
+
+		break;
+
+	case PP_OD_EDIT_MCLK_VDDC_TABLE:
+		if (!od8_settings->od8_settings_array[OD8_SETTING_UCLK_FMAX].feature_id) {
+			pr_info("Mclk max frequency overdrive not supported\n");
+			return -EOPNOTSUPP;
+		}
+
+		single_dpm_table = &(dpm_table->mem_table);
+		ret = vega20_get_clk_table(smu, &clocks, single_dpm_table);
+		if (ret) {
+			pr_err("Attempt to get memory clk levels Failed!");
+			return ret;
+		}
+
+		for (i = 0; i < size; i += 2) {
+			if (i + 2 > size) {
+				pr_info("invalid number of input parameters %d\n",
+					 size);
+				return -EINVAL;
+			}
+
+			input_index = input[i];
+			input_clk = input[i + 1];
+
+			if (input_index != 1) {
+				pr_info("Invalid index %d\n", input_index);
+				pr_info("Support max Mclk frequency setting only which index by 1\n");
+				return -EINVAL;
+			}
+
+			if (input_clk < clocks.data[0].clocks_in_khz / 1000 ||
+			    input_clk > od8_settings->od8_settings_array[OD8_SETTING_UCLK_FMAX].max_value) {
+				pr_info("clock freq %d is not within allowed range [%d - %d]\n",
+					input_clk,
+					clocks.data[0].clocks_in_khz / 1000,
+					od8_settings->od8_settings_array[OD8_SETTING_UCLK_FMAX].max_value);
+				return -EINVAL;
+			}
+
+			if (input_index == 1 && od_table->UclkFmax != input_clk) {
+				table_context->od_gfxclk_update = true;
+				od_table->UclkFmax = input_clk;
+			}
+		}
+
+		break;
+
+	case PP_OD_EDIT_VDDC_CURVE:
+		if (!(od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ1].feature_id &&
+		      od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ2].feature_id &&
+		      od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ3].feature_id &&
+		      od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE1].feature_id &&
+		      od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE2].feature_id &&
+		      od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE3].feature_id)) {
+			pr_info("Voltage curve calibrate not supported\n");
+			return -EOPNOTSUPP;
+		}
+
+		for (i = 0; i < size; i += 3) {
+			if (i + 3 > size) {
+				pr_info("invalid number of input parameters %d\n",
+					size);
+				return -EINVAL;
+			}
+
+			input_index = input[i];
+			input_clk = input[i + 1];
+			input_vol = input[i + 2];
+
+			if (input_index > 2) {
+				pr_info("Setting for point %d is not supported\n",
+					input_index + 1);
+				pr_info("Three supported points index by 0, 1, 2\n");
+				return -EINVAL;
+			}
+
+			od8_id = OD8_SETTING_GFXCLK_FREQ1 + 2 * input_index;
+			if (input_clk < od8_settings->od8_settings_array[od8_id].min_value ||
+			    input_clk > od8_settings->od8_settings_array[od8_id].max_value) {
+				pr_info("clock freq %d is not within allowed range [%d - %d]\n",
+					input_clk,
+					od8_settings->od8_settings_array[od8_id].min_value,
+					od8_settings->od8_settings_array[od8_id].max_value);
+				return -EINVAL;
+			}
+
+			od8_id = OD8_SETTING_GFXCLK_VOLTAGE1 + 2 * input_index;
+			if (input_vol < od8_settings->od8_settings_array[od8_id].min_value ||
+			    input_vol > od8_settings->od8_settings_array[od8_id].max_value) {
+				pr_info("clock voltage %d is not within allowed range [%d- %d]\n",
+					input_vol,
+					od8_settings->od8_settings_array[od8_id].min_value,
+					od8_settings->od8_settings_array[od8_id].max_value);
+				return -EINVAL;
+			}
+
+			switch (input_index) {
+			case 0:
+				od_table->GfxclkFreq1 = input_clk;
+				od_table->GfxclkVolt1 = input_vol * VOLTAGE_SCALE;
+				break;
+			case 1:
+				od_table->GfxclkFreq2 = input_clk;
+				od_table->GfxclkVolt2 = input_vol * VOLTAGE_SCALE;
+				break;
+			case 2:
+				od_table->GfxclkFreq3 = input_clk;
+				od_table->GfxclkVolt3 = input_vol * VOLTAGE_SCALE;
+				break;
+			}
+		}
+
+		break;
+
+	case PP_OD_RESTORE_DEFAULT_TABLE:
+		ret = smu_update_table(smu, TABLE_OVERDRIVE, table_context->overdrive_table, false);
+		if (ret) {
+			pr_err("Failed to export over drive table!\n");
+			return ret;
+		}
+
+		break;
+
+	case PP_OD_COMMIT_DPM_TABLE:
+		ret = smu_update_table(smu, TABLE_OVERDRIVE, table_context->overdrive_table, true);
+		if (ret) {
+			pr_err("Failed to import over drive table!\n");
+			return ret;
+		}
+
+		/* retrieve updated gfxclk table */
+		if (table_context->od_gfxclk_update) {
+			table_context->od_gfxclk_update = false;
+			single_dpm_table = &(dpm_table->gfx_table);
+
+			if (smu_feature_is_enabled(smu, FEATURE_DPM_GFXCLK_BIT)) {
+				ret = vega20_set_single_dpm_table(smu, single_dpm_table,
+								  PPCLK_GFXCLK);
+				if (ret) {
+					pr_err("[Setoverdrive] failed to refresh dpm table!\n");
+					return ret;
+				}
+			} else {
+				single_dpm_table->count = 1;
+				single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.gfxclk / 100;
+			}
+		}
+
+		break;
+
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
@@ -2006,6 +2228,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.force_performance_level = vega20_force_performance_level,
 	.update_specified_od8_value = vega20_update_specified_od8_value,
 	.set_od_percentage = vega20_set_od_percentage,
+	.od_edit_dpm_table = vega20_odn_edit_dpm_table,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit e9c5b46e3c50f58403aeca6d6419b9235d2518b2
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Fri Jan 18 16:15:14 2019 +0800

    drm/amd/powerplay: add sys interface for set sclk_od/mclk_od for smu
    
    Add sys interface for set pp_sclk_od and pp_mclk_od for smu.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index d5469fccfffc..d025f54285ed 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1924,6 +1924,67 @@ static int vega20_update_specified_od8_value(struct smu_context *smu,
 	return 0;
 }
 
+static int vega20_set_od_percentage(struct smu_context *smu,
+				    enum pp_clock_type type,
+				    uint32_t value)
+{
+	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
+	struct vega20_dpm_table *dpm_table = NULL;
+	struct vega20_dpm_table *golden_table = NULL;
+	struct vega20_single_dpm_table *single_dpm_table;
+	struct vega20_single_dpm_table *golden_dpm_table;
+	uint32_t od_clk, index;
+	int ret, feature_enabled;
+	PPCLK_e clk_id;
+
+	dpm_table = smu_dpm->dpm_context;
+	golden_table = smu_dpm->golden_dpm_context;
+
+	switch (type) {
+	case OD_SCLK:
+		single_dpm_table = &(dpm_table->gfx_table);
+		golden_dpm_table = &(golden_table->gfx_table);
+		feature_enabled = smu_feature_is_enabled(smu, FEATURE_DPM_GFXCLK_BIT);
+		clk_id = PPCLK_GFXCLK;
+		index = OD8_SETTING_GFXCLK_FMAX;
+		break;
+	case OD_MCLK:
+		single_dpm_table = &(dpm_table->mem_table);
+		golden_dpm_table = &(golden_table->mem_table);
+		feature_enabled = smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT);
+		clk_id = PPCLK_UCLK;
+		index = OD8_SETTING_UCLK_FMAX;
+		break;
+	default:
+		return -EINVAL;
+		break;
+	}
+
+	od_clk = golden_dpm_table->dpm_levels[golden_dpm_table->count - 1].value * value;
+	od_clk /= 100;
+	od_clk += golden_dpm_table->dpm_levels[golden_dpm_table->count - 1].value;
+
+	ret = smu_update_od8_settings(smu, index, od_clk);
+	if (ret) {
+		pr_err("[Setoverdrive] failed to set od clk!\n");
+		return ret;
+	}
+
+	if (feature_enabled) {
+		ret = vega20_set_single_dpm_table(smu, single_dpm_table,
+						  clk_id);
+		if (ret) {
+			pr_err("[Setoverdrive] failed to refresh dpm table!\n");
+			return ret;
+		}
+	} else {
+		single_dpm_table->count = 1;
+		single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.gfxclk / 100;
+	}
+
+	return 0;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
@@ -1944,6 +2005,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_performance_level = vega20_get_performance_level,
 	.force_performance_level = vega20_force_performance_level,
 	.update_specified_od8_value = vega20_update_specified_od8_value,
+	.set_od_percentage = vega20_set_od_percentage,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 31535a40802dc96d6ad3aabd957a7283c6996685
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Fri Jan 18 15:00:15 2019 +0800

    drm/amd/powerplay: add function to update overdrive settings
    
    Add function of smu_update_specified_od8_value to modify specified
    overdrive value.
    Add fucntion of smu_update_od8_settings to update overdrive table.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 904b8fc93a20..d5469fccfffc 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1847,6 +1847,83 @@ vega20_force_performance_level(struct smu_context *smu, enum amd_dpm_forced_leve
 	return ret;
 }
 
+static int vega20_update_specified_od8_value(struct smu_context *smu,
+					     uint32_t index,
+					     uint32_t value)
+{
+	struct smu_table_context *table_context = &smu->smu_table;
+	OverDriveTable_t *od_table =
+		(OverDriveTable_t *)(table_context->overdrive_table);
+	struct vega20_od8_settings *od8_settings =
+		(struct vega20_od8_settings *)table_context->od8_settings;
+
+	switch (index) {
+	case OD8_SETTING_GFXCLK_FMIN:
+		od_table->GfxclkFmin = (uint16_t)value;
+		break;
+
+	case OD8_SETTING_GFXCLK_FMAX:
+		if (value < od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMAX].min_value ||
+		    value > od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMAX].max_value)
+			return -EINVAL;
+		od_table->GfxclkFmax = (uint16_t)value;
+		break;
+
+	case OD8_SETTING_GFXCLK_FREQ1:
+		od_table->GfxclkFreq1 = (uint16_t)value;
+		break;
+
+	case OD8_SETTING_GFXCLK_VOLTAGE1:
+		od_table->GfxclkVolt1 = (uint16_t)value;
+		break;
+
+	case OD8_SETTING_GFXCLK_FREQ2:
+		od_table->GfxclkFreq2 = (uint16_t)value;
+		break;
+
+	case OD8_SETTING_GFXCLK_VOLTAGE2:
+		od_table->GfxclkVolt2 = (uint16_t)value;
+		break;
+
+	case OD8_SETTING_GFXCLK_FREQ3:
+		od_table->GfxclkFreq3 = (uint16_t)value;
+		break;
+
+	case OD8_SETTING_GFXCLK_VOLTAGE3:
+		od_table->GfxclkVolt3 = (uint16_t)value;
+		break;
+
+	case OD8_SETTING_UCLK_FMAX:
+		if (value < od8_settings->od8_settings_array[OD8_SETTING_UCLK_FMAX].min_value ||
+		    value > od8_settings->od8_settings_array[OD8_SETTING_UCLK_FMAX].max_value)
+			return -EINVAL;
+		od_table->UclkFmax = (uint16_t)value;
+		break;
+
+	case OD8_SETTING_POWER_PERCENTAGE:
+		od_table->OverDrivePct = (int16_t)value;
+		break;
+
+	case OD8_SETTING_FAN_ACOUSTIC_LIMIT:
+		od_table->FanMaximumRpm = (uint16_t)value;
+		break;
+
+	case OD8_SETTING_FAN_MIN_SPEED:
+		od_table->FanMinimumPwm = (uint16_t)value;
+		break;
+
+	case OD8_SETTING_FAN_TARGET_TEMP:
+		od_table->FanTargetTemperature = (uint16_t)value;
+		break;
+
+	case OD8_SETTING_OPERATING_TEMP_MAX:
+		od_table->MaxOpTemp = (uint16_t)value;
+		break;
+	}
+
+	return 0;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
@@ -1866,6 +1943,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_od_percentage = vega20_get_od_percentage,
 	.get_performance_level = vega20_get_performance_level,
 	.force_performance_level = vega20_force_performance_level,
+	.update_specified_od8_value = vega20_update_specified_od8_value,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit dfbd118742549cac24184e4e5e359b0731274cb8
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Fri Jan 18 12:53:27 2019 +0800

    drm/amd/powerplay: add sys interface for pcie for smu
    
    Add sys interface for set/get PCIE info for SMU.
    The related operate will do nothing as vega20 do not support it now.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 911296d1f7cc..904b8fc93a20 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -775,6 +775,9 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 				? "*" : "");
 		break;
 
+	case PP_PCIE:
+		break;
+
 	case OD_SCLK:
 		if (od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMIN].feature_id &&
 		    od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMAX].feature_id) {
@@ -1016,6 +1019,9 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 
 		break;
 
+	case PP_PCIE:
+		break;
+
 	default:
 		break;
 	}

commit 9a431038e30a45c470c5f949824a76538809662d
Author: Chengming Gui <Jack.Gui@amd.com>
Date:   Fri Jan 18 11:27:25 2019 +0800

    drm/amd/powerplay: implement power_dpm_force_performance_level for SMU11
    
    add get_performance_level and force_performance_level
    to implement the sys interface for SMU11.
    
    Signed-off-by: Chengming Gui <Jack.Gui@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 5de0eabbeb29..911296d1f7cc 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1744,6 +1744,103 @@ static int vega20_unforce_dpm_levels(struct smu_context *smu)
 	return ret;
 }
 
+static enum amd_dpm_forced_level vega20_get_performance_level(struct smu_context *smu)
+{
+	struct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);
+	if (!smu_dpm_ctx->dpm_context)
+		return -EINVAL;
+
+	if (smu_dpm_ctx->dpm_level != smu_dpm_ctx->saved_dpm_level) {
+		mutex_lock(&(smu->mutex));
+		smu_dpm_ctx->saved_dpm_level = smu_dpm_ctx->dpm_level;
+		mutex_unlock(&(smu->mutex));
+	}
+	return smu_dpm_ctx->dpm_level;
+}
+
+static int
+vega20_force_performance_level(struct smu_context *smu, enum amd_dpm_forced_level level)
+{
+	int ret = 0;
+	int index = 0;
+	int i = 0;
+	uint32_t sclk_mask, mclk_mask, soc_mask;
+	long workload;
+	struct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);
+	if (!smu_dpm_ctx->dpm_context)
+		return -EINVAL;
+
+	for (i = 0; i < smu->adev->num_ip_blocks; i++) {
+		if (smu->adev->ip_blocks[i].version->type == AMD_IP_BLOCK_TYPE_SMC)
+			break;
+	}
+	mutex_lock(&smu->mutex);
+	smu->adev->ip_blocks[i].version->funcs->enable_umd_pstate(smu, &level);
+	ret = vega20_display_config_changed(smu);
+	if (ret) {
+		pr_err("Failed to change display config!");
+		goto failed;
+	}
+	ret = vega20_apply_clocks_adjust_rules(smu);
+	if (ret) {
+		pr_err("Failed to apply clocks adjust rules!");
+		goto failed;
+	}
+	ret = vega20_notify_smc_dispaly_config(smu);
+	if (ret) {
+		pr_err("Failed to notify smc display config!");
+		goto failed;
+	}
+	switch (level) {
+	case AMD_DPM_FORCED_LEVEL_HIGH:
+		ret = vega20_force_dpm_highest(smu);
+		break;
+
+	case AMD_DPM_FORCED_LEVEL_LOW:
+		ret = vega20_force_dpm_lowest(smu);
+		break;
+
+	case AMD_DPM_FORCED_LEVEL_AUTO:
+		ret = vega20_unforce_dpm_levels(smu);
+		break;
+
+	case AMD_DPM_FORCED_LEVEL_PROFILE_STANDARD:
+	case AMD_DPM_FORCED_LEVEL_PROFILE_MIN_SCLK:
+	case AMD_DPM_FORCED_LEVEL_PROFILE_MIN_MCLK:
+	case AMD_DPM_FORCED_LEVEL_PROFILE_PEAK:
+		ret = vega20_get_profiling_clk_mask(smu, level,
+						    &sclk_mask,
+						    &mclk_mask,
+						    &soc_mask);
+		if (ret)
+			goto failed;
+		vega20_force_clk_levels(smu, PP_SCLK, 1 << sclk_mask);
+		vega20_force_clk_levels(smu, PP_MCLK, 1 << mclk_mask);
+		break;
+
+	case AMD_DPM_FORCED_LEVEL_MANUAL:
+	case AMD_DPM_FORCED_LEVEL_PROFILE_EXIT:
+	default:
+		break;
+	}
+
+	if (!ret)
+		smu_dpm_ctx->dpm_level = level;
+
+	if (smu_dpm_ctx->dpm_level != AMD_DPM_FORCED_LEVEL_MANUAL) {
+		index = fls(smu->workload_mask);
+		index = index > 0 && index <= WORKLOAD_POLICY_MAX ? index - 1 : 0;
+		workload = smu->workload_setting[index];
+
+		if (smu->power_profile_mode != workload)
+			smu->funcs->set_power_profile_mode(smu, &workload, 0);
+	}
+
+failed:
+	mutex_unlock(&smu->mutex);
+	return ret;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
@@ -1761,6 +1858,8 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_clock_by_type_with_latency = vega20_get_clock_by_type_with_latency,
 	.set_default_od8_settings = vega20_set_default_od8_setttings,
 	.get_od_percentage = vega20_get_od_percentage,
+	.get_performance_level = vega20_get_performance_level,
+	.force_performance_level = vega20_force_performance_level,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit f277ff0feacc09c11b26654df9d2b8f1b339cbd8
Author: Chengming Gui <Jack.Gui@amd.com>
Date:   Fri Jan 18 10:15:22 2019 +0800

    drm/amd/powerplay: add vega20_unforce_dpm_levels for SMU11.
    
    add vega20_unforce_dpm_levels to support sys interface for SMU11.
    
    Signed-off-by: Chengming Gui <Jack.Gui@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 15fc30fe75dd..5de0eabbeb29 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1725,6 +1725,25 @@ static int vega20_force_dpm_lowest(struct smu_context *smu)
 	return ret;
 }
 
+static int vega20_unforce_dpm_levels(struct smu_context *smu)
+{
+	int ret = 0;
+
+	ret = vega20_upload_dpm_min_level(smu);
+	if (ret) {
+		pr_err("Failed to upload DPM Bootup Levels!");
+		return ret;
+	}
+
+	ret = vega20_upload_dpm_max_level(smu);
+	if (ret) {
+		pr_err("Failed to upload DPM Max Levels!");
+		return ret;
+	}
+
+	return ret;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,

commit 78ff4a33ca67d0c50dd57b507169c5988e8c9fcb
Author: Chengming Gui <Jack.Gui@amd.com>
Date:   Fri Jan 18 10:09:46 2019 +0800

    drm/amd/powerplay: add vega20_find/force_higest/lowest_dpm for SMU11 (v2)
    
    add vega20_find_highest_dpm_level, vega20_find_lowest_dpm_level,
        vega20_force_highest_dpm and vega20_force_lowest_dpm functions
        to support sys interface for SMU11.
    
    v2: fix highest/lowest implementation changes error.
    
    Signed-off-by: Chengming Gui <Jack.Gui@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 0440e5c7a66e..15fc30fe75dd 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1614,6 +1614,117 @@ vega20_notify_smc_dispaly_config(struct smu_context *smu)
 	return 0;
 }
 
+static uint32_t vega20_find_lowest_dpm_level(struct vega20_single_dpm_table *table)
+{
+	uint32_t i;
+
+	for (i = 0; i < table->count; i++) {
+		if (table->dpm_levels[i].enabled)
+			break;
+	}
+	if (i >= table->count) {
+		i = 0;
+		table->dpm_levels[i].enabled = true;
+	}
+
+	return i;
+}
+
+static uint32_t vega20_find_highest_dpm_level(struct vega20_single_dpm_table *table)
+{
+	int i = 0;
+
+	if (!table) {
+		pr_err("[%s] DPM Table does not exist!", __func__);
+		return 0;
+	}
+	if (table->count <= 0) {
+		pr_err("[%s] DPM Table has no entry!", __func__);
+		return 0;
+	}
+	if (table->count > MAX_REGULAR_DPM_NUMBER) {
+		pr_err("[%s] DPM Table has too many entries!", __func__);
+		return MAX_REGULAR_DPM_NUMBER - 1;
+	}
+
+	for (i = table->count - 1; i >= 0; i--) {
+		if (table->dpm_levels[i].enabled)
+			break;
+	}
+	if (i < 0) {
+		i = 0;
+		table->dpm_levels[i].enabled = true;
+	}
+
+	return i;
+}
+
+static int vega20_force_dpm_highest(struct smu_context *smu)
+{
+	uint32_t soft_level;
+	int ret = 0;
+	struct vega20_dpm_table *dpm_table = (struct vega20_dpm_table *)smu->smu_dpm.dpm_context;
+
+	soft_level = vega20_find_highest_dpm_level(&(dpm_table->gfx_table));
+
+	dpm_table->gfx_table.dpm_state.soft_min_level =
+		dpm_table->gfx_table.dpm_state.soft_max_level =
+		dpm_table->gfx_table.dpm_levels[soft_level].value;
+
+	soft_level = vega20_find_highest_dpm_level(&(dpm_table->mem_table));
+
+	dpm_table->mem_table.dpm_state.soft_min_level =
+		dpm_table->mem_table.dpm_state.soft_max_level =
+		dpm_table->mem_table.dpm_levels[soft_level].value;
+
+	ret = vega20_upload_dpm_min_level(smu);
+	if (ret) {
+		pr_err("Failed to upload boot level to highest!");
+		return ret;
+	}
+
+	ret = vega20_upload_dpm_max_level(smu);
+	if (ret) {
+		pr_err("Failed to upload dpm max level to highest!");
+		return ret;
+	}
+
+	return ret;
+}
+
+static int vega20_force_dpm_lowest(struct smu_context *smu)
+{
+	uint32_t soft_level;
+	int ret = 0;
+	struct vega20_dpm_table *dpm_table = (struct vega20_dpm_table *)smu->smu_dpm.dpm_context;
+
+	soft_level = vega20_find_lowest_dpm_level(&(dpm_table->gfx_table));
+
+	dpm_table->gfx_table.dpm_state.soft_min_level =
+		dpm_table->gfx_table.dpm_state.soft_max_level =
+		dpm_table->gfx_table.dpm_levels[soft_level].value;
+
+	soft_level = vega20_find_lowest_dpm_level(&(dpm_table->mem_table));
+
+	dpm_table->mem_table.dpm_state.soft_min_level =
+		dpm_table->mem_table.dpm_state.soft_max_level =
+		dpm_table->mem_table.dpm_levels[soft_level].value;
+
+	ret = vega20_upload_dpm_min_level(smu);
+	if (ret) {
+		pr_err("Failed to upload boot level to lowest!");
+		return ret;
+	}
+
+	ret = vega20_upload_dpm_max_level(smu);
+	if (ret) {
+		pr_err("Failed to upload dpm max level to lowest!");
+		return ret;
+	}
+
+	return ret;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,

commit 4dd35181ee4482ed3de0205ca7568ee0d838f34a
Author: Chengming Gui <Jack.Gui@amd.com>
Date:   Fri Jan 18 10:01:10 2019 +0800

    drm/amd/powerplay: add vega20_notify_smc_display_config functions for SMU11
    
    add vega20_notify_smc_display_config functions to
    support sys interface for SMU11.
    
    Signed-off-by: Chengming Gui <Jack.Gui@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 7f351c80f04e..0440e5c7a66e 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1569,6 +1569,51 @@ static int vega20_apply_clocks_adjust_rules(struct smu_context *smu)
 	return 0;
 }
 
+static int
+vega20_notify_smc_dispaly_config(struct smu_context *smu)
+{
+	struct vega20_dpm_table *dpm_table = smu->smu_dpm.dpm_context;
+	struct vega20_single_dpm_table *memtable = &dpm_table->mem_table;
+	struct smu_clocks min_clocks = {0};
+	struct pp_display_clock_request clock_req;
+	int ret = 0;
+
+	min_clocks.dcef_clock = smu->display_config->min_dcef_set_clk;
+	min_clocks.dcef_clock_in_sr = smu->display_config->min_dcef_deep_sleep_set_clk;
+	min_clocks.memory_clock = smu->display_config->min_mem_set_clock;
+
+	if (smu_feature_is_supported(smu, FEATURE_DPM_DCEFCLK_BIT)) {
+		clock_req.clock_type = amd_pp_dcef_clock;
+		clock_req.clock_freq_in_khz = min_clocks.dcef_clock * 10;
+		if (!smu->funcs->display_clock_voltage_request(smu, &clock_req)) {
+			if (smu_feature_is_supported(smu, FEATURE_DS_DCEFCLK_BIT)) {
+				ret = smu_send_smc_msg_with_param(smu,
+								  SMU_MSG_SetMinDeepSleepDcefclk,
+								  min_clocks.dcef_clock_in_sr/100);
+				if (ret) {
+					pr_err("Attempt to set divider for DCEFCLK Failed!");
+					return ret;
+				}
+			}
+		} else {
+			pr_info("Attempt to set Hard Min for DCEFCLK Failed!");
+		}
+	}
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT)) {
+		memtable->dpm_state.hard_min_level = min_clocks.memory_clock/100;
+		ret = smu_send_smc_msg_with_param(smu,
+						  SMU_MSG_SetHardMinByFreq,
+						  (PPCLK_UCLK << 16) | memtable->dpm_state.hard_min_level);
+		if (ret) {
+			pr_err("[%s] Set hard min uclk failed!", __func__);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,

commit 3fa36a7df967bd9f665fc61984b1708ed45dffe8
Author: Chengming Gui <Jack.Gui@amd.com>
Date:   Fri Jan 18 09:47:23 2019 +0800

    drm/amd/powerplay: add apply_clock_adjust_rules for SMU11.
    
    add apply_clock_adjust_rules to support sys interface for SMU11.
    
    Signed-off-by: Chengming Gui <Jack.Gui@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 0b13c9319fa9..7f351c80f04e 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1418,6 +1418,157 @@ static int vega20_display_config_changed(struct smu_context *smu)
 	return ret;
 }
 
+static int vega20_apply_clocks_adjust_rules(struct smu_context *smu)
+{
+	struct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);
+	struct vega20_dpm_table *dpm_ctx = (struct vega20_dpm_table *)(smu_dpm_ctx->dpm_context);
+	struct vega20_single_dpm_table *dpm_table;
+	bool vblank_too_short = false;
+	bool disable_mclk_switching;
+	uint32_t i, latency;
+
+	disable_mclk_switching = ((1 < smu->display_config->num_display) &&
+				  !smu->display_config->multi_monitor_in_sync) || vblank_too_short;
+	latency = smu->display_config->dce_tolerable_mclk_in_active_latency;
+
+	/* gfxclk */
+	dpm_table = &(dpm_ctx->gfx_table);
+	dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[0].value;
+	dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+	dpm_table->dpm_state.hard_min_level = dpm_table->dpm_levels[0].value;
+	dpm_table->dpm_state.hard_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+
+		if (VEGA20_UMD_PSTATE_GFXCLK_LEVEL < dpm_table->count) {
+			dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[VEGA20_UMD_PSTATE_GFXCLK_LEVEL].value;
+			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[VEGA20_UMD_PSTATE_GFXCLK_LEVEL].value;
+		}
+
+		if (smu_dpm_ctx->dpm_level == AMD_DPM_FORCED_LEVEL_PROFILE_MIN_SCLK) {
+			dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[0].value;
+			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[0].value;
+		}
+
+		if (smu_dpm_ctx->dpm_level == AMD_DPM_FORCED_LEVEL_PROFILE_PEAK) {
+			dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+		}
+
+	/* memclk */
+	dpm_table = &(dpm_ctx->mem_table);
+	dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[0].value;
+	dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+	dpm_table->dpm_state.hard_min_level = dpm_table->dpm_levels[0].value;
+	dpm_table->dpm_state.hard_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+
+		if (VEGA20_UMD_PSTATE_MCLK_LEVEL < dpm_table->count) {
+			dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[VEGA20_UMD_PSTATE_MCLK_LEVEL].value;
+			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[VEGA20_UMD_PSTATE_MCLK_LEVEL].value;
+		}
+
+		if (smu_dpm_ctx->dpm_level == AMD_DPM_FORCED_LEVEL_PROFILE_MIN_MCLK) {
+			dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[0].value;
+			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[0].value;
+		}
+
+		if (smu_dpm_ctx->dpm_level == AMD_DPM_FORCED_LEVEL_PROFILE_PEAK) {
+			dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+		}
+
+	/* honour DAL's UCLK Hardmin */
+	if (dpm_table->dpm_state.hard_min_level < (smu->display_config->min_mem_set_clock / 100))
+		dpm_table->dpm_state.hard_min_level = smu->display_config->min_mem_set_clock / 100;
+
+	/* Hardmin is dependent on displayconfig */
+	if (disable_mclk_switching) {
+		dpm_table->dpm_state.hard_min_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+		for (i = 0; i < smu_dpm_ctx->mclk_latency_table->count - 1; i++) {
+			if (smu_dpm_ctx->mclk_latency_table->entries[i].latency <= latency) {
+				if (dpm_table->dpm_levels[i].value >= (smu->display_config->min_mem_set_clock / 100)) {
+					dpm_table->dpm_state.hard_min_level = dpm_table->dpm_levels[i].value;
+					break;
+				}
+			}
+		}
+	}
+
+	if (smu->display_config->nb_pstate_switch_disable)
+		dpm_table->dpm_state.hard_min_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+
+#if 0
+	/* vclk */
+	dpm_table = &(dpm_ctx->vclk_table);
+	dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[0].value;
+	dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+	dpm_table->dpm_state.hard_min_level = dpm_table->dpm_levels[0].value;
+	dpm_table->dpm_state.hard_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+
+		if (VEGA20_UMD_PSTATE_UVDCLK_LEVEL < dpm_table->count) {
+			dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[VEGA20_UMD_PSTATE_UVDCLK_LEVEL].value;
+			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[VEGA20_UMD_PSTATE_UVDCLK_LEVEL].value;
+		}
+
+		if (smu_dpm_ctx->dpm_level == AMD_DPM_FORCED_LEVEL_PROFILE_PEAK) {
+			dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+		}
+
+	/* dclk */
+	dpm_table = &(dpm_ctx->dclk_table);
+	dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[0].value;
+	dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+	dpm_table->dpm_state.hard_min_level = dpm_table->dpm_levels[0].value;
+	dpm_table->dpm_state.hard_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+
+		if (VEGA20_UMD_PSTATE_UVDCLK_LEVEL < dpm_table->count) {
+			dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[VEGA20_UMD_PSTATE_UVDCLK_LEVEL].value;
+			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[VEGA20_UMD_PSTATE_UVDCLK_LEVEL].value;
+		}
+
+		if (smu_dpm_ctx->dpm_level == AMD_DPM_FORCED_LEVEL_PROFILE_PEAK) {
+			dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+		}
+#endif
+
+	/* socclk */
+	dpm_table = &(dpm_ctx->soc_table);
+	dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[0].value;
+	dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+	dpm_table->dpm_state.hard_min_level = dpm_table->dpm_levels[0].value;
+	dpm_table->dpm_state.hard_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+
+		if (VEGA20_UMD_PSTATE_SOCCLK_LEVEL < dpm_table->count) {
+			dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[VEGA20_UMD_PSTATE_SOCCLK_LEVEL].value;
+			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[VEGA20_UMD_PSTATE_SOCCLK_LEVEL].value;
+		}
+
+		if (smu_dpm_ctx->dpm_level == AMD_DPM_FORCED_LEVEL_PROFILE_PEAK) {
+			dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+		}
+
+#if 0
+	/* eclk */
+	dpm_table = &(dpm_ctx->eclk_table);
+	dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[0].value;
+	dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+	dpm_table->dpm_state.hard_min_level = dpm_table->dpm_levels[0].value;
+	dpm_table->dpm_state.hard_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+
+		if (VEGA20_UMD_PSTATE_VCEMCLK_LEVEL < dpm_table->count) {
+			dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[VEGA20_UMD_PSTATE_VCEMCLK_LEVEL].value;
+			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[VEGA20_UMD_PSTATE_VCEMCLK_LEVEL].value;
+		}
+
+		if (smu_dpm_ctx->dpm_level == AMD_DPM_FORCED_LEVEL_PROFILE_PEAK) {
+			dpm_table->dpm_state.soft_min_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+			dpm_table->dpm_state.soft_max_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+		}
+#endif
+	return 0;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,

commit 4ebbe6192e7cd09eed63c87d9845d4e8227a27cb
Author: Chengming Gui <Jack.Gui@amd.com>
Date:   Thu Jan 17 18:45:16 2019 +0800

    drm/amd/powerplay: add display_config_changed for SMU11.
    
    add display_config_changed to support sys interface for SMU11.
    
    Signed-off-by: Chengming Gui <Jack.Gui@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 1908b91f22c6..0b13c9319fa9 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1376,6 +1376,48 @@ vega20_set_uclk_to_highest_dpm_level(struct smu_context *smu,
 	return ret;
 }
 
+static int vega20_display_config_changed(struct smu_context *smu)
+{
+	int ret = 0;
+	struct vega20_dpm_table *dpm_table = smu->smu_dpm.dpm_context;
+
+	if (!smu->funcs)
+		return -EINVAL;
+
+	if (!smu->smu_dpm.dpm_context ||
+	    !smu->smu_table.tables ||
+	    !smu->smu_table.tables[TABLE_WATERMARKS].cpu_addr)
+		return -EINVAL;
+
+	smu_send_smc_msg_with_param(smu, SMU_MSG_NumOfDisplays, 0);
+	ret = vega20_set_uclk_to_highest_dpm_level(smu,
+						   &dpm_table->mem_table);
+	if (ret) {
+		pr_err("Failed to set uclk to highest dpm level");
+		return ret;
+	}
+
+	if ((smu->watermarks_bitmap & WATERMARKS_EXIST) &&
+	    !(smu->watermarks_bitmap & WATERMARKS_LOADED)) {
+		ret = smu->funcs->write_watermarks_table(smu);
+		if (ret) {
+			pr_err("Failed to update WMTABLE!");
+			return ret;
+		}
+		smu->watermarks_bitmap |= WATERMARKS_LOADED;
+	}
+
+	if ((smu->watermarks_bitmap & WATERMARKS_EXIST) &&
+	    smu_feature_is_supported(smu, FEATURE_DPM_DCEFCLK_BIT) &&
+	    smu_feature_is_supported(smu, FEATURE_DPM_SOCCLK_BIT)) {
+		smu_send_smc_msg_with_param(smu,
+					    SMU_MSG_NumOfDisplays,
+					    smu->display_config->num_display);
+	}
+
+	return ret;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,

commit e0aa879479368b9dd09f75adc7a442cc777ce5b7
Author: Chengming Gui <Jack.Gui@amd.com>
Date:   Thu Jan 17 18:40:15 2019 +0800

    drm/amd/powerplay: add set_uclk_to_highest_level for SMU11
    
    add set_uclk_to_highest_level to support sys interface for SMU11.
    
    Signed-off-by: Chengming Gui <Jack.Gui@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 62ca0ef050f4..1908b91f22c6 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1307,12 +1307,16 @@ vega20_get_profiling_clk_mask(struct smu_context *smu,
 			      uint32_t *soc_mask)
 {
 	struct vega20_dpm_table *dpm_table = (struct vega20_dpm_table *)smu->smu_dpm.dpm_context;
+	struct vega20_single_dpm_table *gfx_dpm_table;
+	struct vega20_single_dpm_table *mem_dpm_table;
+	struct vega20_single_dpm_table *soc_dpm_table;
+
 	if (!smu->smu_dpm.dpm_context)
 		return -EINVAL;
 
-	struct vega20_single_dpm_table *gfx_dpm_table = &(dpm_table->gfx_table);
-	struct vega20_single_dpm_table *mem_dpm_table = &(dpm_table->mem_table);
-	struct vega20_single_dpm_table *soc_dpm_table = &(dpm_table->soc_table);
+	gfx_dpm_table = &dpm_table->gfx_table;
+	mem_dpm_table = &dpm_table->mem_table;
+	soc_dpm_table = &dpm_table->soc_table;
 
 	*sclk_mask = 0;
 	*mclk_mask = 0;
@@ -1339,6 +1343,39 @@ vega20_get_profiling_clk_mask(struct smu_context *smu,
 	return 0;
 }
 
+static int
+vega20_set_uclk_to_highest_dpm_level(struct smu_context *smu,
+				     struct vega20_single_dpm_table *dpm_table)
+{
+	int ret = 0;
+	struct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);
+	if (!smu_dpm_ctx->dpm_context)
+		return -EINVAL;
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT)) {
+		if (dpm_table->count <= 0) {
+			pr_err("[%s] Dpm table has no entry!", __func__);
+				return -EINVAL;
+		}
+
+		if (dpm_table->count > NUM_UCLK_DPM_LEVELS) {
+			pr_err("[%s] Dpm table has too many entries!", __func__);
+				return -EINVAL;
+		}
+
+		dpm_table->dpm_state.hard_min_level = dpm_table->dpm_levels[dpm_table->count - 1].value;
+		ret = smu_send_smc_msg_with_param(smu,
+				SMU_MSG_SetHardMinByFreq,
+				(PPCLK_UCLK << 16) | dpm_table->dpm_state.hard_min_level);
+		if (ret) {
+			pr_err("[%s] Set hard min uclk failed!", __func__);
+				return ret;
+		}
+	}
+
+	return ret;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,

commit 7598b596720369a28d51cc5f8083b741aef9b4b7
Author: Chengming Gui <Jack.Gui@amd.com>
Date:   Thu Jan 17 18:10:52 2019 +0800

    drm/amd/powerplay: add get_profiling_clk_mask functions for SMU11
    
    add get_profiling_clk_masking_clk_mask
    to support sys interface for SMU11.
    
    Signed-off-by: Chengming Gui <Jack.Gui@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 04ff56143eba..62ca0ef050f4 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1299,6 +1299,46 @@ static int vega20_get_od_percentage(struct smu_context *smu,
 	return value;
 }
 
+static int
+vega20_get_profiling_clk_mask(struct smu_context *smu,
+			      enum amd_dpm_forced_level level,
+			      uint32_t *sclk_mask,
+			      uint32_t *mclk_mask,
+			      uint32_t *soc_mask)
+{
+	struct vega20_dpm_table *dpm_table = (struct vega20_dpm_table *)smu->smu_dpm.dpm_context;
+	if (!smu->smu_dpm.dpm_context)
+		return -EINVAL;
+
+	struct vega20_single_dpm_table *gfx_dpm_table = &(dpm_table->gfx_table);
+	struct vega20_single_dpm_table *mem_dpm_table = &(dpm_table->mem_table);
+	struct vega20_single_dpm_table *soc_dpm_table = &(dpm_table->soc_table);
+
+	*sclk_mask = 0;
+	*mclk_mask = 0;
+	*soc_mask  = 0;
+
+	if (gfx_dpm_table->count > VEGA20_UMD_PSTATE_GFXCLK_LEVEL &&
+	    mem_dpm_table->count > VEGA20_UMD_PSTATE_MCLK_LEVEL &&
+	    soc_dpm_table->count > VEGA20_UMD_PSTATE_SOCCLK_LEVEL) {
+		*sclk_mask = VEGA20_UMD_PSTATE_GFXCLK_LEVEL;
+		*mclk_mask = VEGA20_UMD_PSTATE_MCLK_LEVEL;
+		*soc_mask  = VEGA20_UMD_PSTATE_SOCCLK_LEVEL;
+	}
+
+	if (level == AMD_DPM_FORCED_LEVEL_PROFILE_MIN_SCLK) {
+		*sclk_mask = 0;
+	} else if (level == AMD_DPM_FORCED_LEVEL_PROFILE_MIN_MCLK) {
+		*mclk_mask = 0;
+	} else if (level == AMD_DPM_FORCED_LEVEL_PROFILE_PEAK) {
+		*sclk_mask = gfx_dpm_table->count - 1;
+		*mclk_mask = mem_dpm_table->count - 1;
+		*soc_mask  = soc_dpm_table->count - 1;
+	}
+
+	return 0;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,

commit 8554e67d6e22b0bc3ba213b87a0b6e1ae0fd838c
Author: Chengming Gui <Jack.Gui@amd.com>
Date:   Fri Jan 4 17:42:09 2019 +0800

    drm/amd/powerplay: implement power_dpm_state sys interface for SMU11
    
    Add functions to get/set dpm state for SMU11.
    
    Signed-off-by: Chengming Gui <Jack.Gui@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Acked-by: Kevin Wang <kevin.wang@amd.com>
    Reviewd-by: Evan Quan <evan.quan@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index b9f4e7b7b12b..04ff56143eba 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -31,6 +31,7 @@
 #include "smu11_driver_if.h"
 #include "soc15_common.h"
 #include "atom.h"
+#include "power_state.h"
 #include "vega20_ppt.h"
 #include "vega20_pptable.h"
 #include "vega20_ppsmc.h"
@@ -154,6 +155,16 @@ static int vega20_allocate_dpm_context(struct smu_context *smu)
 
 	smu_dpm->dpm_context_size = sizeof(struct vega20_dpm_table);
 
+	smu_dpm->dpm_current_power_state = kzalloc(sizeof(struct smu_power_state),
+				       GFP_KERNEL);
+	if (!smu_dpm->dpm_current_power_state)
+		return -ENOMEM;
+
+	smu_dpm->dpm_request_power_state = kzalloc(sizeof(struct smu_power_state),
+				       GFP_KERNEL);
+	if (!smu_dpm->dpm_request_power_state)
+		return -ENOMEM;
+
 	return 0;
 }
 
@@ -389,6 +400,39 @@ vega20_get_unallowed_feature_mask(struct smu_context *smu,
 	return 0;
 }
 
+static enum
+amd_pm_state_type vega20_get_current_power_state(struct smu_context *smu)
+{
+	enum amd_pm_state_type pm_type;
+	struct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);
+
+	if (!smu_dpm_ctx->dpm_context ||
+	    !smu_dpm_ctx->dpm_current_power_state)
+		return -EINVAL;
+
+	mutex_lock(&(smu->mutex));
+	switch (smu_dpm_ctx->dpm_current_power_state->classification.ui_label) {
+	case SMU_STATE_UI_LABEL_BATTERY:
+		pm_type = POWER_STATE_TYPE_BATTERY;
+		break;
+	case SMU_STATE_UI_LABEL_BALLANCED:
+		pm_type = POWER_STATE_TYPE_BALANCED;
+		break;
+	case SMU_STATE_UI_LABEL_PERFORMANCE:
+		pm_type = POWER_STATE_TYPE_PERFORMANCE;
+		break;
+	default:
+		if (smu_dpm_ctx->dpm_current_power_state->classification.flags & SMU_STATE_CLASSIFICATION_FLAG_BOOT)
+			pm_type = POWER_STATE_TYPE_INTERNAL_BOOT;
+		else
+			pm_type = POWER_STATE_TYPE_DEFAULT;
+		break;
+	}
+	mutex_unlock(&(smu->mutex));
+
+	return pm_type;
+}
+
 static int
 vega20_set_single_dpm_table(struct smu_context *smu,
 			    struct vega20_single_dpm_table *single_dpm_table,
@@ -1263,7 +1307,9 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_smu_msg_index = vega20_get_smu_msg_index,
 	.run_afll_btc = vega20_run_btc_afll,
 	.get_unallowed_feature_mask = vega20_get_unallowed_feature_mask,
+	.get_current_power_state = vega20_get_current_power_state,
 	.set_default_dpm_table = vega20_set_default_dpm_table,
+	.set_power_state = NULL,
 	.populate_umd_state_clk = vega20_populate_umd_state_clk,
 	.print_clk_levels = vega20_print_clk_levels,
 	.force_clk_levels = vega20_force_clk_levels,

commit c4d74f5372da05875b62f4089da5e77367c0c778
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Mon Jan 14 17:22:09 2019 +0800

    drm/amd/powerplay: get overdrive clock and voltage information
    
    Add sys interface to get overdrive clock and voltage information for
    smu11.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 42eb82832b3e..b9f4e7b7b12b 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -678,8 +678,13 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 	int ret = 0;
 	struct pp_clock_levels_with_latency clocks;
 	struct vega20_single_dpm_table *single_dpm_table;
+	struct smu_table_context *table_context = &smu->smu_table;
 	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
 	struct vega20_dpm_table *dpm_table = NULL;
+	struct vega20_od8_settings *od8_settings =
+		(struct vega20_od8_settings *)table_context->od8_settings;
+	OverDriveTable_t *od_table =
+		(OverDriveTable_t *)(table_context->overdrive_table);
 
 	dpm_table = smu_dpm->dpm_context;
 
@@ -725,6 +730,100 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 				(clocks.data[i].clocks_in_khz == now * 10)
 				? "*" : "");
 		break;
+
+	case OD_SCLK:
+		if (od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMIN].feature_id &&
+		    od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMAX].feature_id) {
+			size = sprintf(buf, "%s:\n", "OD_SCLK");
+			size += sprintf(buf + size, "0: %10uMhz\n",
+					od_table->GfxclkFmin);
+			size += sprintf(buf + size, "1: %10uMhz\n",
+					od_table->GfxclkFmax);
+		}
+
+		break;
+
+	case OD_MCLK:
+		if (od8_settings->od8_settings_array[OD8_SETTING_UCLK_FMAX].feature_id) {
+			size = sprintf(buf, "%s:\n", "OD_MCLK");
+			size += sprintf(buf + size, "1: %10uMhz\n",
+					 od_table->UclkFmax);
+		}
+
+		break;
+
+	case OD_VDDC_CURVE:
+		if (od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ1].feature_id &&
+		    od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ2].feature_id &&
+		    od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ3].feature_id &&
+		    od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE1].feature_id &&
+		    od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE2].feature_id &&
+		    od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE3].feature_id) {
+			size = sprintf(buf, "%s:\n", "OD_VDDC_CURVE");
+			size += sprintf(buf + size, "0: %10uMhz %10dmV\n",
+					od_table->GfxclkFreq1,
+					od_table->GfxclkVolt1 / VOLTAGE_SCALE);
+			size += sprintf(buf + size, "1: %10uMhz %10dmV\n",
+					od_table->GfxclkFreq2,
+					od_table->GfxclkVolt2 / VOLTAGE_SCALE);
+			size += sprintf(buf + size, "2: %10uMhz %10dmV\n",
+					od_table->GfxclkFreq3,
+					od_table->GfxclkVolt3 / VOLTAGE_SCALE);
+		}
+
+		break;
+
+	case OD_RANGE:
+		size = sprintf(buf, "%s:\n", "OD_RANGE");
+
+		if (od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMIN].feature_id &&
+		    od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMAX].feature_id) {
+			size += sprintf(buf + size, "SCLK: %7uMhz %10uMhz\n",
+					od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMIN].min_value,
+					od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMAX].max_value);
+		}
+
+		if (od8_settings->od8_settings_array[OD8_SETTING_UCLK_FMAX].feature_id) {
+			single_dpm_table = &(dpm_table->mem_table);
+			ret = vega20_get_clk_table(smu, &clocks, single_dpm_table);
+			if (ret) {
+				pr_err("Attempt to get memory clk levels Failed!");
+				return ret;
+			}
+
+			size += sprintf(buf + size, "MCLK: %7uMhz %10uMhz\n",
+					clocks.data[0].clocks_in_khz / 1000,
+					od8_settings->od8_settings_array[OD8_SETTING_UCLK_FMAX].max_value);
+		}
+
+		if (od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ1].feature_id &&
+		    od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ2].feature_id &&
+		    od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ3].feature_id &&
+		    od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE1].feature_id &&
+		    od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE2].feature_id &&
+		    od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE3].feature_id) {
+			size += sprintf(buf + size, "VDDC_CURVE_SCLK[0]: %7uMhz %10uMhz\n",
+					od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ1].min_value,
+					od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ1].max_value);
+			size += sprintf(buf + size, "VDDC_CURVE_VOLT[0]: %7dmV %11dmV\n",
+					od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE1].min_value,
+					od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE1].max_value);
+			size += sprintf(buf + size, "VDDC_CURVE_SCLK[1]: %7uMhz %10uMhz\n",
+					od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ2].min_value,
+					od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ2].max_value);
+			size += sprintf(buf + size, "VDDC_CURVE_VOLT[1]: %7dmV %11dmV\n",
+					od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE2].min_value,
+					od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE2].max_value);
+			size += sprintf(buf + size, "VDDC_CURVE_SCLK[2]: %7uMhz %10uMhz\n",
+					od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ3].min_value,
+					od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ3].max_value);
+			size += sprintf(buf + size, "VDDC_CURVE_VOLT[2]: %7dmV %11dmV\n",
+					od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE3].min_value,
+					od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE3].max_value);
+		}
+
+		break;
+
 	default:
 		break;
 	}

commit 6d7c830271ad5c54a3ee04fef0420ec89d6e37fd
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Fri Jan 11 18:47:14 2019 +0800

    drm/amd/powerplay: print overdrive percentage information for smu11
    
    Add function to get sclk or mclk overdrive percentage information for smu11.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index aa7f41a59e82..42eb82832b3e 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -1120,6 +1120,42 @@ static int vega20_set_default_od8_setttings(struct smu_context *smu)
 	return 0;
 }
 
+static int vega20_get_od_percentage(struct smu_context *smu,
+				    enum pp_clock_type type)
+{
+	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
+	struct vega20_dpm_table *dpm_table = NULL;
+	struct vega20_dpm_table *golden_table = NULL;
+	struct vega20_single_dpm_table *single_dpm_table;
+	struct vega20_single_dpm_table *golden_dpm_table;
+	int value, golden_value;
+
+	dpm_table = smu_dpm->dpm_context;
+	golden_table = smu_dpm->golden_dpm_context;
+
+	switch (type) {
+	case OD_SCLK:
+		single_dpm_table = &(dpm_table->gfx_table);
+		golden_dpm_table = &(golden_table->gfx_table);
+		break;
+	case OD_MCLK:
+		single_dpm_table = &(dpm_table->mem_table);
+		golden_dpm_table = &(golden_table->mem_table);
+		break;
+	default:
+		return -EINVAL;
+		break;
+	}
+
+	value = single_dpm_table->dpm_levels[single_dpm_table->count - 1].value;
+	golden_value = golden_dpm_table->dpm_levels[golden_dpm_table->count - 1].value;
+
+	value -= golden_value;
+	value = DIV_ROUND_UP(value * 100, golden_value);
+
+	return value;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
@@ -1134,6 +1170,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.force_clk_levels = vega20_force_clk_levels,
 	.get_clock_by_type_with_latency = vega20_get_clock_by_type_with_latency,
 	.set_default_od8_settings = vega20_set_default_od8_setttings,
+	.get_od_percentage = vega20_get_od_percentage,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 95add9591adab7002e203d5c1c57796e752b15e5
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Fri Jan 11 17:42:47 2019 +0800

    drm/amd/powerplay: add golden dpm table to backup default DPM table (v2)
    
    Backup default DPM table into golden dpm table.
    
    v2: fix dpm_context and golden_dpm_context kfree two times issue.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index c398899320d1..aa7f41a59e82 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -136,11 +136,22 @@ static int vega20_allocate_dpm_context(struct smu_context *smu)
 {
 	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
 
+	if (smu_dpm->dpm_context)
+		return -EINVAL;
+
 	smu_dpm->dpm_context = kzalloc(sizeof(struct vega20_dpm_table),
 				       GFP_KERNEL);
 	if (!smu_dpm->dpm_context)
 		return -ENOMEM;
 
+	if (smu_dpm->golden_dpm_context)
+		return -EINVAL;
+
+	smu_dpm->golden_dpm_context = kzalloc(sizeof(struct vega20_dpm_table),
+					      GFP_KERNEL);
+	if (!smu_dpm->golden_dpm_context)
+		return -ENOMEM;
+
 	smu_dpm->dpm_context_size = sizeof(struct vega20_dpm_table);
 
 	return 0;
@@ -610,6 +621,9 @@ static int vega20_set_default_dpm_table(struct smu_context *smu)
 	}
 	vega20_init_single_dpm_state(&(single_dpm_table->dpm_state));
 
+	memcpy(smu_dpm->golden_dpm_context, dpm_table,
+	       sizeof(struct vega20_dpm_table));
+
 	return 0;
 }
 

commit 2c80abe3816bf573858261c84bcc12c06ac93a5e
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Wed Jan 9 19:11:58 2019 +0800

    drm/amd/powerplay: add function to set default overdrive settings
    
    Add function of vega20_set_default_od8_setttings for vega20 with smu11
    arch to setup default overdrive value.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index df34953767e2..c398899320d1 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -904,6 +904,208 @@ static int vega20_get_clock_by_type_with_latency(struct smu_context *smu,
 	return ret;
 }
 
+static int vega20_overdrive_get_gfx_clk_base_voltage(struct smu_context *smu,
+						     uint32_t *voltage,
+						     uint32_t freq)
+{
+	int ret;
+
+	ret = smu_send_smc_msg_with_param(smu,
+			SMU_MSG_GetAVFSVoltageByDpm,
+			((AVFS_CURVE << 24) | (OD8_HOTCURVE_TEMPERATURE << 16) | freq));
+	if (ret) {
+		pr_err("[GetBaseVoltage] failed to get GFXCLK AVFS voltage from SMU!");
+		return ret;
+	}
+
+	smu_read_smc_arg(smu, voltage);
+	*voltage = *voltage / VOLTAGE_SCALE;
+
+	return 0;
+}
+
+static int vega20_set_default_od8_setttings(struct smu_context *smu)
+{
+	struct smu_table_context *table_context = &smu->smu_table;
+	OverDriveTable_t *od_table = (OverDriveTable_t *)(table_context->overdrive_table);
+	struct vega20_od8_settings *od8_settings = NULL;
+	PPTable_t *smc_pptable = table_context->driver_pptable;
+	int i, ret;
+
+	if (table_context->od8_settings)
+		return -EINVAL;
+
+	table_context->od8_settings = kzalloc(sizeof(struct vega20_od8_settings), GFP_KERNEL);
+
+	if (!table_context->od8_settings)
+		return -ENOMEM;
+
+	memset(table_context->od8_settings, 0, sizeof(struct vega20_od8_settings));
+	od8_settings = (struct vega20_od8_settings *)table_context->od8_settings;
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_SOCCLK_BIT)) {
+		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_GFXCLK_LIMITS] &&
+		    table_context->od_settings_max[OD8_SETTING_GFXCLK_FMAX] > 0 &&
+		    table_context->od_settings_min[OD8_SETTING_GFXCLK_FMIN] > 0 &&
+		    (table_context->od_settings_max[OD8_SETTING_GFXCLK_FMAX] >=
+		     table_context->od_settings_min[OD8_SETTING_GFXCLK_FMIN])) {
+			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMIN].feature_id =
+				OD8_GFXCLK_LIMITS;
+			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMAX].feature_id =
+				OD8_GFXCLK_LIMITS;
+			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMIN].default_value =
+				od_table->GfxclkFmin;
+			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FMAX].default_value =
+				od_table->GfxclkFmax;
+		}
+
+		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_GFXCLK_CURVE] &&
+		    (table_context->od_settings_min[OD8_SETTING_GFXCLK_VOLTAGE1] >=
+		     smc_pptable->MinVoltageGfx / VOLTAGE_SCALE) &&
+		    (table_context->od_settings_max[OD8_SETTING_GFXCLK_VOLTAGE3] <=
+		     smc_pptable->MaxVoltageGfx / VOLTAGE_SCALE) &&
+		    (table_context->od_settings_min[OD8_SETTING_GFXCLK_VOLTAGE1] <=
+		     table_context->od_settings_max[OD8_SETTING_GFXCLK_VOLTAGE3])) {
+			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ1].feature_id =
+				OD8_GFXCLK_CURVE;
+			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE1].feature_id =
+				OD8_GFXCLK_CURVE;
+			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ2].feature_id =
+				OD8_GFXCLK_CURVE;
+			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE2].feature_id =
+				OD8_GFXCLK_CURVE;
+			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ3].feature_id =
+				OD8_GFXCLK_CURVE;
+			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE3].feature_id =
+				OD8_GFXCLK_CURVE;
+
+			od_table->GfxclkFreq1 = od_table->GfxclkFmin;
+			od_table->GfxclkFreq2 = (od_table->GfxclkFmin + od_table->GfxclkFmax) / 2;
+			od_table->GfxclkFreq3 = od_table->GfxclkFmax;
+			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ1].default_value =
+				od_table->GfxclkFreq1;
+			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ2].default_value =
+				od_table->GfxclkFreq2;
+			od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_FREQ3].default_value =
+				od_table->GfxclkFreq3;
+
+			ret = vega20_overdrive_get_gfx_clk_base_voltage(smu,
+				&od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE1].default_value,
+				od_table->GfxclkFreq1);
+			if (ret)
+				od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE1].default_value = 0;
+			od_table->GfxclkVolt1 =
+				od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE1].default_value
+				* VOLTAGE_SCALE;
+			ret = vega20_overdrive_get_gfx_clk_base_voltage(smu,
+				&od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE2].default_value,
+				od_table->GfxclkFreq2);
+			if (ret)
+				od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE2].default_value = 0;
+			od_table->GfxclkVolt2 =
+				od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE2].default_value
+				* VOLTAGE_SCALE;
+			ret = vega20_overdrive_get_gfx_clk_base_voltage(smu,
+				&od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE3].default_value,
+				od_table->GfxclkFreq3);
+			if (ret)
+				od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE3].default_value = 0;
+			od_table->GfxclkVolt3 =
+				od8_settings->od8_settings_array[OD8_SETTING_GFXCLK_VOLTAGE3].default_value
+				* VOLTAGE_SCALE;
+		}
+	}
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT)) {
+		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_UCLK_MAX] &&
+		    table_context->od_settings_min[OD8_SETTING_UCLK_FMAX] > 0 &&
+		    table_context->od_settings_max[OD8_SETTING_UCLK_FMAX] > 0 &&
+		    (table_context->od_settings_max[OD8_SETTING_UCLK_FMAX] >=
+		     table_context->od_settings_min[OD8_SETTING_UCLK_FMAX])) {
+			od8_settings->od8_settings_array[OD8_SETTING_UCLK_FMAX].feature_id =
+				OD8_UCLK_MAX;
+			od8_settings->od8_settings_array[OD8_SETTING_UCLK_FMAX].default_value =
+				od_table->UclkFmax;
+		}
+	}
+
+	if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_POWER_LIMIT] &&
+	    table_context->od_settings_min[OD8_SETTING_POWER_PERCENTAGE] > 0 &&
+	    table_context->od_settings_min[OD8_SETTING_POWER_PERCENTAGE] <= 100 &&
+	    table_context->od_settings_max[OD8_SETTING_POWER_PERCENTAGE] > 0 &&
+	    table_context->od_settings_max[OD8_SETTING_POWER_PERCENTAGE] <= 100) {
+		od8_settings->od8_settings_array[OD8_SETTING_POWER_PERCENTAGE].feature_id =
+			OD8_POWER_LIMIT;
+		od8_settings->od8_settings_array[OD8_SETTING_POWER_PERCENTAGE].default_value =
+			od_table->OverDrivePct;
+	}
+
+	if (smu_feature_is_enabled(smu, FEATURE_FAN_CONTROL_BIT)) {
+		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_FAN_ACOUSTIC_LIMIT] &&
+		    table_context->od_settings_min[OD8_SETTING_FAN_ACOUSTIC_LIMIT] > 0 &&
+		    table_context->od_settings_max[OD8_SETTING_FAN_ACOUSTIC_LIMIT] > 0 &&
+		    (table_context->od_settings_max[OD8_SETTING_FAN_ACOUSTIC_LIMIT] >=
+		     table_context->od_settings_min[OD8_SETTING_FAN_ACOUSTIC_LIMIT])) {
+			od8_settings->od8_settings_array[OD8_SETTING_FAN_ACOUSTIC_LIMIT].feature_id =
+				OD8_ACOUSTIC_LIMIT_SCLK;
+			od8_settings->od8_settings_array[OD8_SETTING_FAN_ACOUSTIC_LIMIT].default_value =
+				od_table->FanMaximumRpm;
+		}
+
+		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_FAN_SPEED_MIN] &&
+		    table_context->od_settings_min[OD8_SETTING_FAN_MIN_SPEED] > 0 &&
+		    table_context->od_settings_max[OD8_SETTING_FAN_MIN_SPEED] > 0 &&
+		    (table_context->od_settings_max[OD8_SETTING_FAN_MIN_SPEED] >=
+		     table_context->od_settings_min[OD8_SETTING_FAN_MIN_SPEED])) {
+			od8_settings->od8_settings_array[OD8_SETTING_FAN_MIN_SPEED].feature_id =
+				OD8_FAN_SPEED_MIN;
+			od8_settings->od8_settings_array[OD8_SETTING_FAN_MIN_SPEED].default_value =
+				od_table->FanMinimumPwm * smc_pptable->FanMaximumRpm / 100;
+		}
+	}
+
+	if (smu_feature_is_enabled(smu, FEATURE_THERMAL_BIT)) {
+		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_TEMPERATURE_FAN] &&
+		    table_context->od_settings_min[OD8_SETTING_FAN_TARGET_TEMP] > 0 &&
+		    table_context->od_settings_max[OD8_SETTING_FAN_TARGET_TEMP] > 0 &&
+		    (table_context->od_settings_max[OD8_SETTING_FAN_TARGET_TEMP] >=
+		     table_context->od_settings_min[OD8_SETTING_FAN_TARGET_TEMP])) {
+			od8_settings->od8_settings_array[OD8_SETTING_FAN_TARGET_TEMP].feature_id =
+				OD8_TEMPERATURE_FAN;
+			od8_settings->od8_settings_array[OD8_SETTING_FAN_TARGET_TEMP].default_value =
+				od_table->FanTargetTemperature;
+		}
+
+		if (table_context->od_feature_capabilities[ATOM_VEGA20_ODFEATURE_TEMPERATURE_SYSTEM] &&
+		    table_context->od_settings_min[OD8_SETTING_OPERATING_TEMP_MAX] > 0 &&
+		    table_context->od_settings_max[OD8_SETTING_OPERATING_TEMP_MAX] > 0 &&
+		    (table_context->od_settings_max[OD8_SETTING_OPERATING_TEMP_MAX] >=
+		     table_context->od_settings_min[OD8_SETTING_OPERATING_TEMP_MAX])) {
+			od8_settings->od8_settings_array[OD8_SETTING_OPERATING_TEMP_MAX].feature_id =
+				OD8_TEMPERATURE_SYSTEM;
+			od8_settings->od8_settings_array[OD8_SETTING_OPERATING_TEMP_MAX].default_value =
+				od_table->MaxOpTemp;
+		}
+	}
+
+	for (i = 0; i < OD8_SETTING_COUNT; i++) {
+		if (od8_settings->od8_settings_array[i].feature_id) {
+			od8_settings->od8_settings_array[i].min_value =
+				table_context->od_settings_min[i];
+			od8_settings->od8_settings_array[i].max_value =
+				table_context->od_settings_max[i];
+			od8_settings->od8_settings_array[i].current_value =
+				od8_settings->od8_settings_array[i].default_value;
+		} else {
+			od8_settings->od8_settings_array[i].min_value = 0;
+			od8_settings->od8_settings_array[i].max_value = 0;
+			od8_settings->od8_settings_array[i].current_value = 0;
+		}
+	}
+
+	return 0;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
@@ -917,6 +1119,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.print_clk_levels = vega20_print_clk_levels,
 	.force_clk_levels = vega20_force_clk_levels,
 	.get_clock_by_type_with_latency = vega20_get_clock_by_type_with_latency,
+	.set_default_od8_settings = vega20_set_default_od8_setttings,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit b55ca3bdaf0bbfd14ad6619a991fbd324ae1ad4b
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Tue Jan 8 14:18:02 2019 +0800

    drm/amd/powerplay: add function to store overdrive information for smu11
    
    Add vega20_setup_od8_information function to store overdrive information
    from powerplay_table to smu_table which will used when setting od8.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Kevin Wang <kevin1.wang@amd.com>
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index ed0fbe755bfb..df34953767e2 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -146,10 +146,92 @@ static int vega20_allocate_dpm_context(struct smu_context *smu)
 	return 0;
 }
 
+static int vega20_setup_od8_information(struct smu_context *smu)
+{
+	ATOM_Vega20_POWERPLAYTABLE *powerplay_table = NULL;
+	struct smu_table_context *table_context = &smu->smu_table;
+
+	uint32_t od_feature_count, od_feature_array_size,
+		 od_setting_count, od_setting_array_size;
+
+	if (!table_context->power_play_table)
+		return -EINVAL;
+
+	powerplay_table = table_context->power_play_table;
+
+	if (powerplay_table->OverDrive8Table.ucODTableRevision == 1) {
+		/* Setup correct ODFeatureCount, and store ODFeatureArray from
+		 * powerplay table to od_feature_capabilities */
+		od_feature_count =
+			(le32_to_cpu(powerplay_table->OverDrive8Table.ODFeatureCount) >
+			 ATOM_VEGA20_ODFEATURE_COUNT) ?
+			ATOM_VEGA20_ODFEATURE_COUNT :
+			le32_to_cpu(powerplay_table->OverDrive8Table.ODFeatureCount);
+
+		od_feature_array_size = sizeof(uint8_t) * od_feature_count;
+
+		if (table_context->od_feature_capabilities)
+			return -EINVAL;
+
+		table_context->od_feature_capabilities = kzalloc(od_feature_array_size, GFP_KERNEL);
+		if (!table_context->od_feature_capabilities)
+			return -ENOMEM;
+
+		memcpy(table_context->od_feature_capabilities,
+		       &powerplay_table->OverDrive8Table.ODFeatureCapabilities,
+		       od_feature_array_size);
+
+		/* Setup correct ODSettingCount, and store ODSettingArray from
+		 * powerplay table to od_settings_max and od_setting_min */
+		od_setting_count =
+			(le32_to_cpu(powerplay_table->OverDrive8Table.ODSettingCount) >
+			 ATOM_VEGA20_ODSETTING_COUNT) ?
+			ATOM_VEGA20_ODSETTING_COUNT :
+			le32_to_cpu(powerplay_table->OverDrive8Table.ODSettingCount);
+
+		od_setting_array_size = sizeof(uint32_t) * od_setting_count;
+
+		if (table_context->od_settings_max)
+			return -EINVAL;
+
+		table_context->od_settings_max = kzalloc(od_setting_array_size, GFP_KERNEL);
+
+		if (!table_context->od_settings_max) {
+			kfree(table_context->od_feature_capabilities);
+			table_context->od_feature_capabilities = NULL;
+			return -ENOMEM;
+		}
+
+		memcpy(table_context->od_settings_max,
+		       &powerplay_table->OverDrive8Table.ODSettingsMax,
+		       od_setting_array_size);
+
+		if (table_context->od_settings_min)
+			return -EINVAL;
+
+		table_context->od_settings_min = kzalloc(od_setting_array_size, GFP_KERNEL);
+
+		if (!table_context->od_settings_min) {
+			kfree(table_context->od_feature_capabilities);
+			table_context->od_feature_capabilities = NULL;
+			kfree(table_context->od_settings_max);
+			table_context->od_settings_max = NULL;
+			return -ENOMEM;
+		}
+
+		memcpy(table_context->od_settings_min,
+		       &powerplay_table->OverDrive8Table.ODSettingsMin,
+		       od_setting_array_size);
+	}
+
+	return 0;
+}
+
 static int vega20_store_powerplay_table(struct smu_context *smu)
 {
 	ATOM_Vega20_POWERPLAYTABLE *powerplay_table = NULL;
 	struct smu_table_context *table_context = &smu->smu_table;
+	int ret;
 
 	if (!table_context->power_play_table)
 		return -EINVAL;
@@ -162,7 +244,9 @@ static int vega20_store_powerplay_table(struct smu_context *smu)
 	table_context->software_shutdown_temp = powerplay_table->usSoftwareShutdownTemp;
 	table_context->thermal_controller_type = powerplay_table->ucThermalControllerType;
 
-	return 0;
+	ret = vega20_setup_od8_information(smu);
+
+	return ret;
 }
 
 static int vega20_append_powerplay_table(struct smu_context *smu)

commit e5e4e22391c2a7e792964aeb3278eecfd2a7638b
Author: Huang Rui <ray.huang@amd.com>
Date:   Mon Jan 14 11:55:45 2019 +0800

    drm/amd/powerplay: add interface to get clock by type with latency for display (v2)
    
    This patch adds get clock by type with latency, display will use it to get
    current clocks with latency.
    
    v2: fix the missed mutex lock before return.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 55e1b8d7faf5..ed0fbe755bfb 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -782,6 +782,44 @@ static int vega20_force_clk_levels(struct smu_context *smu,
 	return 0;
 }
 
+static int vega20_get_clock_by_type_with_latency(struct smu_context *smu,
+						 enum amd_pp_clock_type type,
+						 struct pp_clock_levels_with_latency *clocks)
+{
+	int ret;
+	struct vega20_single_dpm_table *single_dpm_table;
+	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
+	struct vega20_dpm_table *dpm_table = NULL;
+
+	dpm_table = smu_dpm->dpm_context;
+
+	mutex_lock(&smu->mutex);
+
+	switch (type) {
+	case amd_pp_sys_clock:
+		single_dpm_table = &(dpm_table->gfx_table);
+		ret = vega20_get_clk_table(smu, clocks, single_dpm_table);
+		break;
+	case amd_pp_mem_clock:
+		single_dpm_table = &(dpm_table->mem_table);
+		ret = vega20_get_clk_table(smu, clocks, single_dpm_table);
+		break;
+	case amd_pp_dcef_clock:
+		single_dpm_table = &(dpm_table->dcef_table);
+		ret = vega20_get_clk_table(smu, clocks, single_dpm_table);
+		break;
+	case amd_pp_soc_clock:
+		single_dpm_table = &(dpm_table->soc_table);
+		ret = vega20_get_clk_table(smu, clocks, single_dpm_table);
+		break;
+	default:
+		ret = -EINVAL;
+	}
+
+	mutex_unlock(&smu->mutex);
+	return ret;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
@@ -794,7 +832,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.populate_umd_state_clk = vega20_populate_umd_state_clk,
 	.print_clk_levels = vega20_print_clk_levels,
 	.force_clk_levels = vega20_force_clk_levels,
-
+	.get_clock_by_type_with_latency = vega20_get_clock_by_type_with_latency,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 2f613c7068e5ff6ec8b2ed32826b466ed676c0a1
Author: Kevin Wang <Kevin1.Wang@amd.com>
Date:   Tue Jan 15 12:37:35 2019 +0800

    drm/amd/powerplay: implement sensor of thermal_get_temperature for smu11
    
    add sensor interface of thermal temperature for debugfs and hwmon.
    
    Signed-off-by: Kevin Wang <Kevin1.Wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 16eb5a14bebc..55e1b8d7faf5 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -794,6 +794,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.populate_umd_state_clk = vega20_populate_umd_state_clk,
 	.print_clk_levels = vega20_print_clk_levels,
 	.force_clk_levels = vega20_force_clk_levels,
+
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 7292fd7d2bec15a5ce7a0afe84e4cd2d77f42f39
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Mon Jan 7 15:59:56 2019 +0800

    drm/amd/powerplay: force clock levels for smu11
    
    Add function to set sclk or mclk level for smu11.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index ff000afd246b..16eb5a14bebc 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -705,6 +705,83 @@ static int vega20_upload_dpm_max_level(struct smu_context *smu)
 	return ret;
 }
 
+static int vega20_force_clk_levels(struct smu_context *smu,
+			enum pp_clock_type type, uint32_t mask)
+{
+	struct vega20_dpm_table *dpm_table;
+	struct vega20_single_dpm_table *single_dpm_table;
+	uint32_t soft_min_level, soft_max_level;
+	int ret;
+
+	soft_min_level = mask ? (ffs(mask) - 1) : 0;
+	soft_max_level = mask ? (fls(mask) - 1) : 0;
+
+	dpm_table = smu->smu_dpm.dpm_context;
+
+	switch (type) {
+	case PP_SCLK:
+		single_dpm_table = &(dpm_table->gfx_table);
+
+		if (soft_max_level >= single_dpm_table->count) {
+			pr_err("Clock level specified %d is over max allowed %d\n",
+					soft_max_level, single_dpm_table->count - 1);
+			return -EINVAL;
+		}
+
+		single_dpm_table->dpm_state.soft_min_level =
+			single_dpm_table->dpm_levels[soft_min_level].value;
+		single_dpm_table->dpm_state.soft_max_level =
+			single_dpm_table->dpm_levels[soft_max_level].value;
+
+		ret = vega20_upload_dpm_min_level(smu);
+		if (ret) {
+			pr_err("Failed to upload boot level to lowest!\n");
+			return ret;
+		}
+
+		ret = vega20_upload_dpm_max_level(smu);
+		if (ret) {
+			pr_err("Failed to upload dpm max level to highest!\n");
+			return ret;
+		}
+
+		break;
+
+	case PP_MCLK:
+		single_dpm_table = &(dpm_table->mem_table);
+
+		if (soft_max_level >= single_dpm_table->count) {
+			pr_err("Clock level specified %d is over max allowed %d\n",
+					soft_max_level, single_dpm_table->count - 1);
+			return -EINVAL;
+		}
+
+		single_dpm_table->dpm_state.soft_min_level =
+			single_dpm_table->dpm_levels[soft_min_level].value;
+		single_dpm_table->dpm_state.soft_max_level =
+			single_dpm_table->dpm_levels[soft_max_level].value;
+
+		ret = vega20_upload_dpm_min_level(smu);
+		if (ret) {
+			pr_err("Failed to upload boot level to lowest!\n");
+			return ret;
+		}
+
+		ret = vega20_upload_dpm_max_level(smu);
+		if (ret) {
+			pr_err("Failed to upload dpm max level to highest!\n");
+			return ret;
+		}
+
+		break;
+
+	default:
+		break;
+	}
+
+	return 0;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
@@ -716,6 +793,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.set_default_dpm_table = vega20_set_default_dpm_table,
 	.populate_umd_state_clk = vega20_populate_umd_state_clk,
 	.print_clk_levels = vega20_print_clk_levels,
+	.force_clk_levels = vega20_force_clk_levels,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 0a49887de95c1173eeadebb15eed82397ae03e26
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Mon Jan 7 14:56:07 2019 +0800

    drm/amd/powerplay: upload dpm level for smu11
    
    Add function to support gfx_clk and mem_clk upload min and max dpm level for smu11.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Evan Quan <evan.quan@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 171cfc87989d..ff000afd246b 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -633,6 +633,78 @@ static int vega20_print_clk_levels(struct smu_context *smu,
 	return size;
 }
 
+static int vega20_upload_dpm_min_level(struct smu_context *smu)
+{
+	struct vega20_dpm_table *dpm_table;
+	struct vega20_single_dpm_table *single_dpm_table;
+	uint32_t min_freq;
+	int ret = 0;
+
+	dpm_table = smu->smu_dpm.dpm_context;
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_GFXCLK_BIT)) {
+		single_dpm_table = &(dpm_table->gfx_table);
+		min_freq = single_dpm_table->dpm_state.soft_min_level;
+		ret = smu_send_smc_msg_with_param(smu,
+			SMU_MSG_SetSoftMinByFreq,
+			(PPCLK_GFXCLK << 16) | (min_freq & 0xffff));
+		if (ret) {
+			pr_err("Failed to set soft min gfxclk !\n");
+			return ret;
+		}
+	}
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT)) {
+		single_dpm_table = &(dpm_table->mem_table);
+		min_freq = single_dpm_table->dpm_state.soft_min_level;
+		ret = smu_send_smc_msg_with_param(smu,
+			SMU_MSG_SetSoftMinByFreq,
+			(PPCLK_UCLK << 16) | (min_freq & 0xffff));
+		if (ret) {
+			pr_err("Failed to set soft min memclk !\n");
+			return ret;
+		}
+	}
+
+	return ret;
+}
+
+static int vega20_upload_dpm_max_level(struct smu_context *smu)
+{
+	struct vega20_dpm_table *dpm_table;
+	struct vega20_single_dpm_table *single_dpm_table;
+	uint32_t max_freq;
+	int ret = 0;
+
+	dpm_table = smu->smu_dpm.dpm_context;
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_GFXCLK_BIT)) {
+		single_dpm_table = &(dpm_table->gfx_table);
+		max_freq = single_dpm_table->dpm_state.soft_max_level;
+		ret = smu_send_smc_msg_with_param(smu,
+			SMU_MSG_SetSoftMaxByFreq,
+			(PPCLK_GFXCLK << 16) | (max_freq & 0xffff));
+		if (ret) {
+			pr_err("Failed to set soft max gfxclk !\n");
+			return ret;
+		}
+	}
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT)) {
+		single_dpm_table = &(dpm_table->mem_table);
+		max_freq = single_dpm_table->dpm_state.soft_max_level;
+		ret = smu_send_smc_msg_with_param(smu,
+			SMU_MSG_SetSoftMaxByFreq,
+			(PPCLK_UCLK << 16) | (max_freq & 0xffff));
+		if (ret) {
+			pr_err("Failed to set soft max memclk !\n");
+			return ret;
+		}
+	}
+
+	return ret;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,

commit 74ba3553b2bb26adb36dd7d0b13b85bca64f3ef2
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Fri Jan 4 16:00:48 2019 +0800

    drm/amd/powerplay: add function to start thermal control
    
    Add function to start thermal control for smu11 when smu hw_init.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 45f3276a6fee..171cfc87989d 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -160,6 +160,7 @@ static int vega20_store_powerplay_table(struct smu_context *smu)
 	       sizeof(PPTable_t));
 
 	table_context->software_shutdown_temp = powerplay_table->usSoftwareShutdownTemp;
+	table_context->thermal_controller_type = powerplay_table->ucThermalControllerType;
 
 	return 0;
 }

commit 3941b2dbed9b1e2adfc93e479ecc0d28ed9026ba
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Fri Jan 4 16:23:23 2019 +0800

    drm/amd/powerplay: add function to get thermal range
    
    Add the function to get the min and max thermal value for vega20 with
    smu11 architecture.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index d34e1facd79c..45f3276a6fee 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -159,6 +159,8 @@ static int vega20_store_powerplay_table(struct smu_context *smu)
 	memcpy(table_context->driver_pptable, &powerplay_table->smcPPTable,
 	       sizeof(PPTable_t));
 
+	table_context->software_shutdown_temp = powerplay_table->usSoftwareShutdownTemp;
+
 	return 0;
 }
 

commit 86ac88030725d34a2746b46185ee6b15bf42cdfe
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Tue Jan 15 10:56:55 2019 +0800

    drm/amd/powerplay: print clock levels for smu11 (v2)
    
    Add function to print current levels for smu11.
    
    v2: expose get_current_clk_freq for smu v11. (Kevin)
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Signed-off-by: Kevin Wang <Kevin1.Wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index d794290b2839..d34e1facd79c 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -552,6 +552,84 @@ static int vega20_populate_umd_state_clk(struct smu_context *smu)
 	return 0;
 }
 
+static int vega20_get_clk_table(struct smu_context *smu,
+			struct pp_clock_levels_with_latency *clocks,
+			struct vega20_single_dpm_table *dpm_table)
+{
+	int i, count;
+
+	count = (dpm_table->count > MAX_NUM_CLOCKS) ? MAX_NUM_CLOCKS : dpm_table->count;
+	clocks->num_levels = count;
+
+	for (i = 0; i < count; i++) {
+		clocks->data[i].clocks_in_khz =
+			dpm_table->dpm_levels[i].value * 1000;
+		clocks->data[i].latency_in_us = 0;
+	}
+
+	return 0;
+}
+
+static int vega20_print_clk_levels(struct smu_context *smu,
+			enum pp_clock_type type, char *buf)
+{
+	int i, now, size = 0;
+	int ret = 0;
+	struct pp_clock_levels_with_latency clocks;
+	struct vega20_single_dpm_table *single_dpm_table;
+	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
+	struct vega20_dpm_table *dpm_table = NULL;
+
+	dpm_table = smu_dpm->dpm_context;
+
+	switch (type) {
+	case PP_SCLK:
+		ret = smu_get_current_clk_freq(smu, PPCLK_GFXCLK, &now);
+		if (ret) {
+			pr_err("Attempt to get current gfx clk Failed!");
+			return ret;
+		}
+
+		single_dpm_table = &(dpm_table->gfx_table);
+		ret = vega20_get_clk_table(smu, &clocks, single_dpm_table);
+		if (ret) {
+			pr_err("Attempt to get gfx clk levels Failed!");
+			return ret;
+		}
+
+		for (i = 0; i < clocks.num_levels; i++)
+			size += sprintf(buf + size, "%d: %uMhz %s\n", i,
+					clocks.data[i].clocks_in_khz / 1000,
+					(clocks.data[i].clocks_in_khz == now * 10)
+					? "*" : "");
+		break;
+
+	case PP_MCLK:
+		ret = smu_get_current_clk_freq(smu, PPCLK_UCLK, &now);
+		if (ret) {
+			pr_err("Attempt to get current mclk Failed!");
+			return ret;
+		}
+
+		single_dpm_table = &(dpm_table->mem_table);
+		ret = vega20_get_clk_table(smu, &clocks, single_dpm_table);
+		if (ret) {
+			pr_err("Attempt to get memory clk levels Failed!");
+			return ret;
+		}
+
+		for (i = 0; i < clocks.num_levels; i++)
+			size += sprintf(buf + size, "%d: %uMhz %s\n",
+				i, clocks.data[i].clocks_in_khz / 1000,
+				(clocks.data[i].clocks_in_khz == now * 10)
+				? "*" : "");
+		break;
+	default:
+		break;
+	}
+	return size;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
@@ -562,6 +640,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_unallowed_feature_mask = vega20_get_unallowed_feature_mask,
 	.set_default_dpm_table = vega20_set_default_dpm_table,
 	.populate_umd_state_clk = vega20_populate_umd_state_clk,
+	.print_clk_levels = vega20_print_clk_levels,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 133438fa4e60d017b2c45b9fca64bcc4fc64007f
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Mon Dec 24 19:49:38 2018 +0800

    drm/amd/powerplay: add function to populate umd state clk.
    
    Add vega20_populate_umd_state_clk function to set pstate_sclk and pstate_mclk.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index bca4085696d2..d794290b2839 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -526,6 +526,32 @@ static int vega20_set_default_dpm_table(struct smu_context *smu)
 	return 0;
 }
 
+static int vega20_populate_umd_state_clk(struct smu_context *smu)
+{
+	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
+	struct vega20_dpm_table *dpm_table = NULL;
+	struct vega20_single_dpm_table *gfx_table = NULL;
+	struct vega20_single_dpm_table *mem_table = NULL;
+
+	dpm_table = smu_dpm->dpm_context;
+	gfx_table = &(dpm_table->gfx_table);
+	mem_table = &(dpm_table->mem_table);
+
+	smu->pstate_sclk = gfx_table->dpm_levels[0].value;
+	smu->pstate_mclk = mem_table->dpm_levels[0].value;
+
+	if (gfx_table->count > VEGA20_UMD_PSTATE_GFXCLK_LEVEL &&
+	    mem_table->count > VEGA20_UMD_PSTATE_MCLK_LEVEL) {
+		smu->pstate_sclk = gfx_table->dpm_levels[VEGA20_UMD_PSTATE_GFXCLK_LEVEL].value;
+		smu->pstate_mclk = mem_table->dpm_levels[VEGA20_UMD_PSTATE_MCLK_LEVEL].value;
+	}
+
+	smu->pstate_sclk = smu->pstate_sclk * 100;
+	smu->pstate_mclk = smu->pstate_mclk * 100;
+
+	return 0;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
@@ -535,6 +561,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.run_afll_btc = vega20_run_btc_afll,
 	.get_unallowed_feature_mask = vega20_get_unallowed_feature_mask,
 	.set_default_dpm_table = vega20_set_default_dpm_table,
+	.populate_umd_state_clk = vega20_populate_umd_state_clk,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit d6a4aa825a65ee7ec0293666fd1572e4621ad13d
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Thu Dec 20 20:31:55 2018 +0800

    drm/amd/powerplay: set defalut dpm table for smu
    
    Add smu_set_default_dpm_table function to set dpm table for smu11.
    Modified the sequence to populate smc pptable, as it should be done after
    related dpm feature is enabled.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 4b756e84115b..bca4085696d2 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -291,6 +291,241 @@ vega20_get_unallowed_feature_mask(struct smu_context *smu,
 	return 0;
 }
 
+static int
+vega20_set_single_dpm_table(struct smu_context *smu,
+			    struct vega20_single_dpm_table *single_dpm_table,
+			    PPCLK_e clk_id)
+{
+	int ret = 0;
+	uint32_t i, num_of_levels, clk;
+
+	ret = smu_send_smc_msg_with_param(smu,
+			SMU_MSG_GetDpmFreqByIndex,
+			(clk_id << 16 | 0xFF));
+	if (ret) {
+		pr_err("[GetNumOfDpmLevel] failed to get dpm levels!");
+		return ret;
+	}
+
+	smu_read_smc_arg(smu, &num_of_levels);
+	if (!num_of_levels) {
+		pr_err("[GetNumOfDpmLevel] number of clk levels is invalid!");
+		return -EINVAL;
+	}
+
+	single_dpm_table->count = num_of_levels;
+
+	for (i = 0; i < num_of_levels; i++) {
+		ret = smu_send_smc_msg_with_param(smu,
+				SMU_MSG_GetDpmFreqByIndex,
+				(clk_id << 16 | i));
+		if (ret) {
+			pr_err("[GetDpmFreqByIndex] failed to get dpm freq by index!");
+			return ret;
+		}
+		smu_read_smc_arg(smu, &clk);
+		if (!clk) {
+			pr_err("[GetDpmFreqByIndex] clk value is invalid!");
+			return -EINVAL;
+		}
+		single_dpm_table->dpm_levels[i].value = clk;
+		single_dpm_table->dpm_levels[i].enabled = true;
+	}
+	return 0;
+}
+
+static void vega20_init_single_dpm_state(struct vega20_dpm_state *dpm_state)
+{
+	dpm_state->soft_min_level = 0x0;
+	dpm_state->soft_max_level = 0xffff;
+        dpm_state->hard_min_level = 0x0;
+        dpm_state->hard_max_level = 0xffff;
+}
+
+static int vega20_set_default_dpm_table(struct smu_context *smu)
+{
+	int ret;
+
+	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
+	struct vega20_dpm_table *dpm_table = NULL;
+	struct vega20_single_dpm_table *single_dpm_table;
+
+	dpm_table = smu_dpm->dpm_context;
+
+	/* socclk */
+	single_dpm_table = &(dpm_table->soc_table);
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_SOCCLK_BIT)) {
+		ret = vega20_set_single_dpm_table(smu, single_dpm_table,
+						  PPCLK_SOCCLK);
+		if (ret) {
+			pr_err("[SetupDefaultDpmTable] failed to get socclk dpm levels!");
+			return ret;
+		}
+	} else {
+		single_dpm_table->count = 1;
+		single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.socclk / 100;
+	}
+	vega20_init_single_dpm_state(&(single_dpm_table->dpm_state));
+
+	/* gfxclk */
+	single_dpm_table = &(dpm_table->gfx_table);
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_GFXCLK_BIT)) {
+		ret = vega20_set_single_dpm_table(smu, single_dpm_table,
+						  PPCLK_GFXCLK);
+		if (ret) {
+			pr_err("[SetupDefaultDpmTable] failed to get gfxclk dpm levels!");
+			return ret;
+		}
+	} else {
+		single_dpm_table->count = 1;
+		single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.gfxclk / 100;
+	}
+	vega20_init_single_dpm_state(&(single_dpm_table->dpm_state));
+
+	/* memclk */
+	single_dpm_table = &(dpm_table->mem_table);
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_UCLK_BIT)) {
+		ret = vega20_set_single_dpm_table(smu, single_dpm_table,
+						  PPCLK_UCLK);
+		if (ret) {
+			pr_err("[SetupDefaultDpmTable] failed to get memclk dpm levels!");
+			return ret;
+		}
+	} else {
+		single_dpm_table->count = 1;
+		single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.uclk / 100;
+	}
+	vega20_init_single_dpm_state(&(single_dpm_table->dpm_state));
+
+#if 0
+	/* eclk */
+	single_dpm_table = &(dpm_table->eclk_table);
+
+	if (feature->fea_enabled[FEATURE_DPM_VCE_BIT]) {
+		ret = vega20_set_single_dpm_table(smu, single_dpm_table, PPCLK_ECLK);
+		if (ret) {
+			pr_err("[SetupDefaultDpmTable] failed to get eclk dpm levels!");
+			return ret;
+		}
+	} else {
+		single_dpm_table->count = 1;
+		single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.eclock / 100;
+	}
+	vega20_init_single_dpm_state(&(single_dpm_table->dpm_state));
+
+	/* vclk */
+	single_dpm_table = &(dpm_table->vclk_table);
+
+	if (feature->fea_enabled[FEATURE_DPM_UVD_BIT]) {
+		ret = vega20_set_single_dpm_table(smu, single_dpm_table, PPCLK_VCLK);
+		if (ret) {
+			pr_err("[SetupDefaultDpmTable] failed to get vclk dpm levels!");
+			return ret;
+		}
+	} else {
+		single_dpm_table->count = 1;
+		single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.vclock / 100;
+	}
+	vega20_init_single_dpm_state(&(single_dpm_table->dpm_state));
+
+	/* dclk */
+	single_dpm_table = &(dpm_table->dclk_table);
+
+	if (feature->fea_enabled[FEATURE_DPM_UVD_BIT]) {
+		ret = vega20_set_single_dpm_table(smu, single_dpm_table, PPCLK_DCLK);
+		if (ret) {
+			pr_err("[SetupDefaultDpmTable] failed to get dclk dpm levels!");
+			return ret;
+		}
+	} else {
+		single_dpm_table->count = 1;
+		single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.dclock / 100;
+	}
+	vega20_init_single_dpm_state(&(single_dpm_table->dpm_state));
+#endif
+
+	/* dcefclk */
+	single_dpm_table = &(dpm_table->dcef_table);
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_DCEFCLK_BIT)) {
+		ret = vega20_set_single_dpm_table(smu, single_dpm_table,
+						  PPCLK_DCEFCLK);
+		if (ret) {
+			pr_err("[SetupDefaultDpmTable] failed to get dcefclk dpm levels!");
+			return ret;
+		}
+	} else {
+		single_dpm_table->count = 1;
+		single_dpm_table->dpm_levels[0].value = smu->smu_table.boot_values.dcefclk / 100;
+	}
+	vega20_init_single_dpm_state(&(single_dpm_table->dpm_state));
+
+	/* pixclk */
+	single_dpm_table = &(dpm_table->pixel_table);
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_DCEFCLK_BIT)) {
+		ret = vega20_set_single_dpm_table(smu, single_dpm_table,
+						  PPCLK_PIXCLK);
+		if (ret) {
+			pr_err("[SetupDefaultDpmTable] failed to get pixclk dpm levels!");
+			return ret;
+		}
+	} else {
+		single_dpm_table->count = 0;
+	}
+	vega20_init_single_dpm_state(&(single_dpm_table->dpm_state));
+
+	/* dispclk */
+	single_dpm_table = &(dpm_table->display_table);
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_DCEFCLK_BIT)) {
+		ret = vega20_set_single_dpm_table(smu, single_dpm_table,
+						  PPCLK_DISPCLK);
+		if (ret) {
+			pr_err("[SetupDefaultDpmTable] failed to get dispclk dpm levels!");
+			return ret;
+		}
+	} else {
+		single_dpm_table->count = 0;
+	}
+	vega20_init_single_dpm_state(&(single_dpm_table->dpm_state));
+
+	/* phyclk */
+	single_dpm_table = &(dpm_table->phy_table);
+
+	if (smu_feature_is_enabled(smu, FEATURE_DPM_DCEFCLK_BIT)) {
+		ret = vega20_set_single_dpm_table(smu, single_dpm_table,
+						  PPCLK_PHYCLK);
+		if (ret) {
+			pr_err("[SetupDefaultDpmTable] failed to get phyclk dpm levels!");
+			return ret;
+		}
+	} else {
+		single_dpm_table->count = 0;
+	}
+	vega20_init_single_dpm_state(&(single_dpm_table->dpm_state));
+
+	/* fclk */
+	single_dpm_table = &(dpm_table->fclk_table);
+
+	if (smu_feature_is_enabled(smu,FEATURE_DPM_FCLK_BIT)) {
+		ret = vega20_set_single_dpm_table(smu, single_dpm_table,
+						  PPCLK_FCLK);
+		if (ret) {
+			pr_err("[SetupDefaultDpmTable] failed to get fclk dpm levels!");
+			return ret;
+		}
+	} else {
+		single_dpm_table->count = 0;
+	}
+	vega20_init_single_dpm_state(&(single_dpm_table->dpm_state));
+
+	return 0;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
@@ -299,6 +534,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.get_smu_msg_index = vega20_get_smu_msg_index,
 	.run_afll_btc = vega20_run_btc_afll,
 	.get_unallowed_feature_mask = vega20_get_unallowed_feature_mask,
+	.set_default_dpm_table = vega20_set_default_dpm_table,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 6b816d7316397b5898609e8da31c33790ef34ea0
Author: Kevin Wang <Kevin1.Wang@amd.com>
Date:   Wed Dec 26 17:36:25 2018 +0800

    drm/amd/powerplay: implement smu feature functions
    
    each ip will support different smu feature,
    the driver use bitmap to management this feature.
    
    bitmap:
    -allowed: sw driver to enable & disable some feature when driver init.
    -suppored: the feature is supproed.
    -enabled: the feature is enabled.
    
    Signed-off-by: Kevin Wang <Kevin1.Wang@amd.com>
    Reviewed-by: Huang Rui <Ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 57d5f0b17df4..4b756e84115b 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -278,6 +278,19 @@ static int vega20_run_btc_afll(struct smu_context *smu)
 	return smu_send_smc_msg(smu, SMU_MSG_RunAfllBtc);
 }
 
+static int
+vega20_get_unallowed_feature_mask(struct smu_context *smu,
+				  uint32_t *feature_mask, uint32_t num)
+{
+	if (num > 2)
+		return -EINVAL;
+
+	feature_mask[0] = 0xE0041C00;
+	feature_mask[1] = 0xFFFFFFFE; /* bit32~bit63 is Unsupported */
+
+	return 0;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
@@ -285,6 +298,7 @@ static const struct pptable_funcs vega20_ppt_funcs = {
 	.append_powerplay_table = vega20_append_powerplay_table,
 	.get_smu_msg_index = vega20_get_smu_msg_index,
 	.run_afll_btc = vega20_run_btc_afll,
+	.get_unallowed_feature_mask = vega20_get_unallowed_feature_mask,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit f6a6b9526cf0f4247ecc10d8634db8325640fa6e
Author: Kevin Wang <Kevin1.Wang@amd.com>
Date:   Mon Dec 24 18:17:15 2018 +0800

    drm/amd/powerplay: implement smu_run_afll_btc function
    
    Add smu_run_afll_btc function to send msg to smc to start run afll btc.
    
    Signed-off-by: Kevin Wang <Kevin1.Wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index e2cac464240d..57d5f0b17df4 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -273,12 +273,18 @@ static int vega20_check_powerplay_table(struct smu_context *smu)
 	return 0;
 }
 
+static int vega20_run_btc_afll(struct smu_context *smu)
+{
+	return smu_send_smc_msg(smu, SMU_MSG_RunAfllBtc);
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
 	.check_powerplay_table = vega20_check_powerplay_table,
 	.append_powerplay_table = vega20_append_powerplay_table,
 	.get_smu_msg_index = vega20_get_smu_msg_index,
+	.run_afll_btc = vega20_run_btc_afll,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit d76c9e2412667e54740a52c7c582b02351ad633c
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Wed Dec 26 11:07:57 2018 +0800

    drm/amd/powerplay: Change the allocate method of dpm context for smu11.
    
    Change the allocate method of dpm context as dpm_table is different bewteen
    vega20 and smu11.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 6cdbb4ffe62e..e2cac464240d 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -132,6 +132,20 @@ static int vega20_get_smu_msg_index(struct smu_context *smc, uint32_t index)
 
 }
 
+static int vega20_allocate_dpm_context(struct smu_context *smu)
+{
+	struct smu_dpm_context *smu_dpm = &smu->smu_dpm;
+
+	smu_dpm->dpm_context = kzalloc(sizeof(struct vega20_dpm_table),
+				       GFP_KERNEL);
+	if (!smu_dpm->dpm_context)
+		return -ENOMEM;
+
+	smu_dpm->dpm_context_size = sizeof(struct vega20_dpm_table);
+
+	return 0;
+}
+
 static int vega20_store_powerplay_table(struct smu_context *smu)
 {
 	ATOM_Vega20_POWERPLAYTABLE *powerplay_table = NULL;
@@ -260,6 +274,7 @@ static int vega20_check_powerplay_table(struct smu_context *smu)
 }
 
 static const struct pptable_funcs vega20_ppt_funcs = {
+	.alloc_dpm_context = vega20_allocate_dpm_context,
 	.store_powerplay_table = vega20_store_powerplay_table,
 	.check_powerplay_table = vega20_check_powerplay_table,
 	.append_powerplay_table = vega20_append_powerplay_table,

commit c58952737623ed39848a7a997ae0d7c6580a42bc
Author: Huang Rui <ray.huang@amd.com>
Date:   Thu Dec 20 23:06:08 2018 +0800

    drm/amd/powerplay: add append_powerplay_table function
    
    It needs to add append_powerplay_table function to program the smc_dpm_table for
    PPTable_t.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Kevin Wang <Kevin1.Wang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 5e561ad88d7b..6cdbb4ffe62e 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -148,6 +148,97 @@ static int vega20_store_powerplay_table(struct smu_context *smu)
 	return 0;
 }
 
+static int vega20_append_powerplay_table(struct smu_context *smu)
+{
+	struct smu_table_context *table_context = &smu->smu_table;
+	PPTable_t *smc_pptable = table_context->driver_pptable;
+	struct atom_smc_dpm_info_v4_4 *smc_dpm_table;
+	int index, i, ret;
+
+	index = get_index_into_master_table(atom_master_list_of_data_tables_v2_1,
+					   smc_dpm_info);
+
+	ret = smu_get_atom_data_table(smu, index, NULL, NULL, NULL,
+				      (uint8_t **)&smc_dpm_table);
+	if (ret)
+		return ret;
+
+	smc_pptable->MaxVoltageStepGfx = smc_dpm_table->maxvoltagestepgfx;
+	smc_pptable->MaxVoltageStepSoc = smc_dpm_table->maxvoltagestepsoc;
+
+	smc_pptable->VddGfxVrMapping = smc_dpm_table->vddgfxvrmapping;
+	smc_pptable->VddSocVrMapping = smc_dpm_table->vddsocvrmapping;
+	smc_pptable->VddMem0VrMapping = smc_dpm_table->vddmem0vrmapping;
+	smc_pptable->VddMem1VrMapping = smc_dpm_table->vddmem1vrmapping;
+
+	smc_pptable->GfxUlvPhaseSheddingMask = smc_dpm_table->gfxulvphasesheddingmask;
+	smc_pptable->SocUlvPhaseSheddingMask = smc_dpm_table->soculvphasesheddingmask;
+	smc_pptable->ExternalSensorPresent = smc_dpm_table->externalsensorpresent;
+
+	smc_pptable->GfxMaxCurrent = smc_dpm_table->gfxmaxcurrent;
+	smc_pptable->GfxOffset = smc_dpm_table->gfxoffset;
+	smc_pptable->Padding_TelemetryGfx = smc_dpm_table->padding_telemetrygfx;
+
+	smc_pptable->SocMaxCurrent = smc_dpm_table->socmaxcurrent;
+	smc_pptable->SocOffset = smc_dpm_table->socoffset;
+	smc_pptable->Padding_TelemetrySoc = smc_dpm_table->padding_telemetrysoc;
+
+	smc_pptable->Mem0MaxCurrent = smc_dpm_table->mem0maxcurrent;
+	smc_pptable->Mem0Offset = smc_dpm_table->mem0offset;
+	smc_pptable->Padding_TelemetryMem0 = smc_dpm_table->padding_telemetrymem0;
+
+	smc_pptable->Mem1MaxCurrent = smc_dpm_table->mem1maxcurrent;
+	smc_pptable->Mem1Offset = smc_dpm_table->mem1offset;
+	smc_pptable->Padding_TelemetryMem1 = smc_dpm_table->padding_telemetrymem1;
+
+	smc_pptable->AcDcGpio = smc_dpm_table->acdcgpio;
+	smc_pptable->AcDcPolarity = smc_dpm_table->acdcpolarity;
+	smc_pptable->VR0HotGpio = smc_dpm_table->vr0hotgpio;
+	smc_pptable->VR0HotPolarity = smc_dpm_table->vr0hotpolarity;
+
+	smc_pptable->VR1HotGpio = smc_dpm_table->vr1hotgpio;
+	smc_pptable->VR1HotPolarity = smc_dpm_table->vr1hotpolarity;
+	smc_pptable->Padding1 = smc_dpm_table->padding1;
+	smc_pptable->Padding2 = smc_dpm_table->padding2;
+
+	smc_pptable->LedPin0 = smc_dpm_table->ledpin0;
+	smc_pptable->LedPin1 = smc_dpm_table->ledpin1;
+	smc_pptable->LedPin2 = smc_dpm_table->ledpin2;
+
+	smc_pptable->PllGfxclkSpreadEnabled = smc_dpm_table->pllgfxclkspreadenabled;
+	smc_pptable->PllGfxclkSpreadPercent = smc_dpm_table->pllgfxclkspreadpercent;
+	smc_pptable->PllGfxclkSpreadFreq = smc_dpm_table->pllgfxclkspreadfreq;
+
+	smc_pptable->UclkSpreadEnabled = 0;
+	smc_pptable->UclkSpreadPercent = smc_dpm_table->uclkspreadpercent;
+	smc_pptable->UclkSpreadFreq = smc_dpm_table->uclkspreadfreq;
+
+	smc_pptable->FclkSpreadEnabled = smc_dpm_table->fclkspreadenabled;
+	smc_pptable->FclkSpreadPercent = smc_dpm_table->fclkspreadpercent;
+	smc_pptable->FclkSpreadFreq = smc_dpm_table->fclkspreadfreq;
+
+	smc_pptable->FllGfxclkSpreadEnabled = smc_dpm_table->fllgfxclkspreadenabled;
+	smc_pptable->FllGfxclkSpreadPercent = smc_dpm_table->fllgfxclkspreadpercent;
+	smc_pptable->FllGfxclkSpreadFreq = smc_dpm_table->fllgfxclkspreadfreq;
+
+	for (i = 0; i < I2C_CONTROLLER_NAME_COUNT; i++) {
+		smc_pptable->I2cControllers[i].Enabled =
+			smc_dpm_table->i2ccontrollers[i].enabled;
+		smc_pptable->I2cControllers[i].SlaveAddress =
+			smc_dpm_table->i2ccontrollers[i].slaveaddress;
+		smc_pptable->I2cControllers[i].ControllerPort =
+			smc_dpm_table->i2ccontrollers[i].controllerport;
+		smc_pptable->I2cControllers[i].ThermalThrottler =
+			smc_dpm_table->i2ccontrollers[i].thermalthrottler;
+		smc_pptable->I2cControllers[i].I2cProtocol =
+			smc_dpm_table->i2ccontrollers[i].i2cprotocol;
+		smc_pptable->I2cControllers[i].I2cSpeed =
+			smc_dpm_table->i2ccontrollers[i].i2cspeed;
+	}
+
+	return 0;
+}
+
 static int vega20_check_powerplay_table(struct smu_context *smu)
 {
 	ATOM_Vega20_POWERPLAYTABLE *powerplay_table = NULL;
@@ -171,6 +262,7 @@ static int vega20_check_powerplay_table(struct smu_context *smu)
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.store_powerplay_table = vega20_store_powerplay_table,
 	.check_powerplay_table = vega20_check_powerplay_table,
+	.append_powerplay_table = vega20_append_powerplay_table,
 	.get_smu_msg_index = vega20_get_smu_msg_index,
 };
 

commit 78031c2c4dcdee689610dbf64dd77e0e3cc11051
Author: Kevin Wang <Kevin1.Wang@amd.com>
Date:   Wed Dec 19 15:46:24 2018 +0800

    drm/amd/powerplay: implement smu vega20_message_map for vega20
    
    This patch implements smu vega20_message_map to map the PPSMC messages from
    smu11 to specific asic.
    
    Signed-off-by: Kevin Wang <Kevin1.Wang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 7bc3e4ec3414..5e561ad88d7b 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -28,13 +28,109 @@
 #include "atomfirmware.h"
 #include "amdgpu_atomfirmware.h"
 #include "smu_v11_0.h"
-#include "smu_v11_0_ppsmc.h"
 #include "smu11_driver_if.h"
 #include "soc15_common.h"
 #include "atom.h"
 #include "vega20_ppt.h"
 #include "vega20_pptable.h"
-#include "vega20_ppt.h"
+#include "vega20_ppsmc.h"
+
+#define MSG_MAP(msg, index) \
+	[SMU_MSG_##msg] = index
+
+static int vega20_message_map[SMU_MSG_MAX_COUNT] = {
+	MSG_MAP(TestMessage,			PPSMC_MSG_TestMessage),
+	MSG_MAP(GetSmuVersion,			PPSMC_MSG_GetSmuVersion),
+	MSG_MAP(GetDriverIfVersion,		PPSMC_MSG_GetDriverIfVersion),
+	MSG_MAP(SetAllowedFeaturesMaskLow,	PPSMC_MSG_SetAllowedFeaturesMaskLow),
+	MSG_MAP(SetAllowedFeaturesMaskHigh,	PPSMC_MSG_SetAllowedFeaturesMaskHigh),
+	MSG_MAP(EnableAllSmuFeatures,		PPSMC_MSG_EnableAllSmuFeatures),
+	MSG_MAP(DisableAllSmuFeatures,		PPSMC_MSG_DisableAllSmuFeatures),
+	MSG_MAP(EnableSmuFeaturesLow,		PPSMC_MSG_EnableSmuFeaturesLow),
+	MSG_MAP(EnableSmuFeaturesHigh,		PPSMC_MSG_EnableSmuFeaturesHigh),
+	MSG_MAP(DisableSmuFeaturesLow,		PPSMC_MSG_DisableSmuFeaturesLow),
+	MSG_MAP(DisableSmuFeaturesHigh,		PPSMC_MSG_DisableSmuFeaturesHigh),
+	MSG_MAP(GetEnabledSmuFeaturesLow,	PPSMC_MSG_GetEnabledSmuFeaturesLow),
+	MSG_MAP(GetEnabledSmuFeaturesHigh,	PPSMC_MSG_GetEnabledSmuFeaturesHigh),
+	MSG_MAP(SetWorkloadMask,		PPSMC_MSG_SetWorkloadMask),
+	MSG_MAP(SetPptLimit,			PPSMC_MSG_SetPptLimit),
+	MSG_MAP(SetDriverDramAddrHigh,		PPSMC_MSG_SetDriverDramAddrHigh),
+	MSG_MAP(SetDriverDramAddrLow,		PPSMC_MSG_SetDriverDramAddrLow),
+	MSG_MAP(SetToolsDramAddrHigh,		PPSMC_MSG_SetToolsDramAddrHigh),
+	MSG_MAP(SetToolsDramAddrLow,		PPSMC_MSG_SetToolsDramAddrLow),
+	MSG_MAP(TransferTableSmu2Dram,		PPSMC_MSG_TransferTableSmu2Dram),
+	MSG_MAP(TransferTableDram2Smu,		PPSMC_MSG_TransferTableDram2Smu),
+	MSG_MAP(UseDefaultPPTable,		PPSMC_MSG_UseDefaultPPTable),
+	MSG_MAP(UseBackupPPTable,		PPSMC_MSG_UseBackupPPTable),
+	MSG_MAP(RunBtc,				PPSMC_MSG_RunBtc),
+	MSG_MAP(RequestI2CBus,			PPSMC_MSG_RequestI2CBus),
+	MSG_MAP(ReleaseI2CBus,			PPSMC_MSG_ReleaseI2CBus),
+	MSG_MAP(SetFloorSocVoltage,		PPSMC_MSG_SetFloorSocVoltage),
+	MSG_MAP(SoftReset,			PPSMC_MSG_SoftReset),
+	MSG_MAP(StartBacoMonitor,		PPSMC_MSG_StartBacoMonitor),
+	MSG_MAP(CancelBacoMonitor,		PPSMC_MSG_CancelBacoMonitor),
+	MSG_MAP(EnterBaco,			PPSMC_MSG_EnterBaco),
+	MSG_MAP(SetSoftMinByFreq,		PPSMC_MSG_SetSoftMinByFreq),
+	MSG_MAP(SetSoftMaxByFreq,		PPSMC_MSG_SetSoftMaxByFreq),
+	MSG_MAP(SetHardMinByFreq,		PPSMC_MSG_SetHardMinByFreq),
+	MSG_MAP(SetHardMaxByFreq,		PPSMC_MSG_SetHardMaxByFreq),
+	MSG_MAP(GetMinDpmFreq,			PPSMC_MSG_GetMinDpmFreq),
+	MSG_MAP(GetMaxDpmFreq,			PPSMC_MSG_GetMaxDpmFreq),
+	MSG_MAP(GetDpmFreqByIndex,		PPSMC_MSG_GetDpmFreqByIndex),
+	MSG_MAP(GetDpmClockFreq,		PPSMC_MSG_GetDpmClockFreq),
+	MSG_MAP(GetSsVoltageByDpm,		PPSMC_MSG_GetSsVoltageByDpm),
+	MSG_MAP(SetMemoryChannelConfig,		PPSMC_MSG_SetMemoryChannelConfig),
+	MSG_MAP(SetGeminiMode,			PPSMC_MSG_SetGeminiMode),
+	MSG_MAP(SetGeminiApertureHigh,		PPSMC_MSG_SetGeminiApertureHigh),
+	MSG_MAP(SetGeminiApertureLow,		PPSMC_MSG_SetGeminiApertureLow),
+	MSG_MAP(SetMinLinkDpmByIndex,		PPSMC_MSG_SetMinLinkDpmByIndex),
+	MSG_MAP(OverridePcieParameters,		PPSMC_MSG_OverridePcieParameters),
+	MSG_MAP(OverDriveSetPercentage,		PPSMC_MSG_OverDriveSetPercentage),
+	MSG_MAP(SetMinDeepSleepDcefclk,		PPSMC_MSG_SetMinDeepSleepDcefclk),
+	MSG_MAP(ReenableAcDcInterrupt,		PPSMC_MSG_ReenableAcDcInterrupt),
+	MSG_MAP(NotifyPowerSource,		PPSMC_MSG_NotifyPowerSource),
+	MSG_MAP(SetUclkFastSwitch,		PPSMC_MSG_SetUclkFastSwitch),
+	MSG_MAP(SetUclkDownHyst,		PPSMC_MSG_SetUclkDownHyst),
+	MSG_MAP(GetCurrentRpm,			PPSMC_MSG_GetCurrentRpm),
+	MSG_MAP(SetVideoFps,			PPSMC_MSG_SetVideoFps),
+	MSG_MAP(SetTjMax,			PPSMC_MSG_SetTjMax),
+	MSG_MAP(SetFanTemperatureTarget,	PPSMC_MSG_SetFanTemperatureTarget),
+	MSG_MAP(PrepareMp1ForUnload,		PPSMC_MSG_PrepareMp1ForUnload),
+	MSG_MAP(DramLogSetDramAddrHigh,		PPSMC_MSG_DramLogSetDramAddrHigh),
+	MSG_MAP(DramLogSetDramAddrLow,		PPSMC_MSG_DramLogSetDramAddrLow),
+	MSG_MAP(DramLogSetDramSize,		PPSMC_MSG_DramLogSetDramSize),
+	MSG_MAP(SetFanMaxRpm,			PPSMC_MSG_SetFanMaxRpm),
+	MSG_MAP(SetFanMinPwm,			PPSMC_MSG_SetFanMinPwm),
+	MSG_MAP(ConfigureGfxDidt,		PPSMC_MSG_ConfigureGfxDidt),
+	MSG_MAP(NumOfDisplays,			PPSMC_MSG_NumOfDisplays),
+	MSG_MAP(RemoveMargins,			PPSMC_MSG_RemoveMargins),
+	MSG_MAP(ReadSerialNumTop32,		PPSMC_MSG_ReadSerialNumTop32),
+	MSG_MAP(ReadSerialNumBottom32,		PPSMC_MSG_ReadSerialNumBottom32),
+	MSG_MAP(SetSystemVirtualDramAddrHigh,	PPSMC_MSG_SetSystemVirtualDramAddrHigh),
+	MSG_MAP(SetSystemVirtualDramAddrLow,	PPSMC_MSG_SetSystemVirtualDramAddrLow),
+	MSG_MAP(WaflTest,			PPSMC_MSG_WaflTest),
+	MSG_MAP(SetFclkGfxClkRatio,		PPSMC_MSG_SetFclkGfxClkRatio),
+	MSG_MAP(AllowGfxOff,			PPSMC_MSG_AllowGfxOff),
+	MSG_MAP(DisallowGfxOff,			PPSMC_MSG_DisallowGfxOff),
+	MSG_MAP(GetPptLimit,			PPSMC_MSG_GetPptLimit),
+	MSG_MAP(GetDcModeMaxDpmFreq,		PPSMC_MSG_GetDcModeMaxDpmFreq),
+	MSG_MAP(GetDebugData,			PPSMC_MSG_GetDebugData),
+	MSG_MAP(SetXgmiMode,			PPSMC_MSG_SetXgmiMode),
+	MSG_MAP(RunAfllBtc,			PPSMC_MSG_RunAfllBtc),
+	MSG_MAP(ExitBaco,			PPSMC_MSG_ExitBaco),
+	MSG_MAP(PrepareMp1ForReset,		PPSMC_MSG_PrepareMp1ForReset),
+	MSG_MAP(PrepareMp1ForShutdown,		PPSMC_MSG_PrepareMp1ForShutdown),
+	MSG_MAP(SetMGpuFanBoostLimitRpm,	PPSMC_MSG_SetMGpuFanBoostLimitRpm),
+	MSG_MAP(GetAVFSVoltageByDpm,		PPSMC_MSG_GetAVFSVoltageByDpm),
+};
+
+static int vega20_get_smu_msg_index(struct smu_context *smc, uint32_t index)
+{
+	if (index > SMU_MSG_MAX_COUNT || index > PPSMC_Message_Count)
+		return -EINVAL;
+	return vega20_message_map[index];
+
+}
 
 static int vega20_store_powerplay_table(struct smu_context *smu)
 {
@@ -75,6 +171,7 @@ static int vega20_check_powerplay_table(struct smu_context *smu)
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.store_powerplay_table = vega20_store_powerplay_table,
 	.check_powerplay_table = vega20_check_powerplay_table,
+	.get_smu_msg_index = vega20_get_smu_msg_index,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit c6eef2d01d05beff75e6139909bf1f2dc88bd72a
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Fri Dec 14 16:18:21 2018 +0800

    drm/amd/powerplay: add function to check pptable for smu11
    
    Add smu_v11_0_check_pptable function for smu11.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <Kevin1.Wang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 292f18c0c90d..7bc3e4ec3414 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -52,8 +52,29 @@ static int vega20_store_powerplay_table(struct smu_context *smu)
 	return 0;
 }
 
+static int vega20_check_powerplay_table(struct smu_context *smu)
+{
+	ATOM_Vega20_POWERPLAYTABLE *powerplay_table = NULL;
+	struct smu_table_context *table_context = &smu->smu_table;
+
+	powerplay_table = table_context->power_play_table;
+
+	if (powerplay_table->sHeader.format_revision < ATOM_VEGA20_TABLE_REVISION_VEGA20) {
+		pr_err("Unsupported PPTable format!");
+		return -EINVAL;
+	}
+
+	if (!powerplay_table->sHeader.structuresize) {
+		pr_err("Invalid PowerPlay Table!");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
 static const struct pptable_funcs vega20_ppt_funcs = {
 	.store_powerplay_table = vega20_store_powerplay_table,
+	.check_powerplay_table = vega20_check_powerplay_table,
 };
 
 void vega20_set_ppt_funcs(struct smu_context *smu)

commit 3e333c6ca1f5e82aa0024dca4015ca1aa69b222b
Author: Likun Gao <Likun.Gao@amd.com>
Date:   Tue Dec 18 22:56:48 2018 +0800

    drm/amd/powerplay: add function to parse pptable for smu11
    
    Add smu_v11_0_parse_pptable function for smu11.
    
    Signed-off-by: Likun Gao <Likun.Gao@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Kevin Wang <Kevin1.Wang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
index 7522cc7edd43..292f18c0c90d 100644
--- a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -38,6 +38,17 @@
 
 static int vega20_store_powerplay_table(struct smu_context *smu)
 {
+	ATOM_Vega20_POWERPLAYTABLE *powerplay_table = NULL;
+	struct smu_table_context *table_context = &smu->smu_table;
+
+	if (!table_context->power_play_table)
+		return -EINVAL;
+
+	powerplay_table = table_context->power_play_table;
+
+	memcpy(table_context->driver_pptable, &powerplay_table->smcPPTable,
+	       sizeof(PPTable_t));
+
 	return 0;
 }
 

commit 74e07f9d3b77034cd1546617afce1d014a68d1ca
Author: Huang Rui <ray.huang@amd.com>
Date:   Tue Dec 18 20:23:17 2018 +0800

    drm/amd/powerplay: add vega20 pptable function file
    
    This patch adds the vega20_ppt.c to support ATOM_Vega20_POWERPLAYTABLE format
    for vega20 on smu11. It will be used to implement to asic specific pptable
    helpers.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Likun Gao <Likun.Gao@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/powerplay/vega20_ppt.c b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
new file mode 100644
index 000000000000..7522cc7edd43
--- /dev/null
+++ b/drivers/gpu/drm/amd/powerplay/vega20_ppt.c
@@ -0,0 +1,51 @@
+/*
+ * Copyright 2019 Advanced Micro Devices, Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "pp_debug.h"
+#include <linux/firmware.h>
+#include "amdgpu.h"
+#include "amdgpu_smu.h"
+#include "atomfirmware.h"
+#include "amdgpu_atomfirmware.h"
+#include "smu_v11_0.h"
+#include "smu_v11_0_ppsmc.h"
+#include "smu11_driver_if.h"
+#include "soc15_common.h"
+#include "atom.h"
+#include "vega20_ppt.h"
+#include "vega20_pptable.h"
+#include "vega20_ppt.h"
+
+static int vega20_store_powerplay_table(struct smu_context *smu)
+{
+	return 0;
+}
+
+static const struct pptable_funcs vega20_ppt_funcs = {
+	.store_powerplay_table = vega20_store_powerplay_table,
+};
+
+void vega20_set_ppt_funcs(struct smu_context *smu)
+{
+	smu->ppt_funcs = &vega20_ppt_funcs;
+}
