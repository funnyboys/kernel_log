commit eb1b4573c080469fbacce953805e22a670193344
Author: Yongqiang Sun <yongqiang.sun@amd.com>
Date:   Thu Mar 5 13:47:26 2020 -0500

    drm/amd/display: DPP DTO isn't update properly.
    
    [Why]
    before update dpp DTO, we check dppclks in context to determine it is
    changed or not, but dppclks in context will be updated anyways after
    flip is done, so compare dppclks in context will always get an equal
    result.
    
    [How]
    Add pipe dpp clks in dccg and compare values between dccg and context.
    
    Signed-off-by: Yongqiang Sun <yongqiang.sun@amd.com>
    Reviewed-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
index 50bffbfdd394..62cc2651e00c 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
@@ -70,6 +70,8 @@ void dccg2_update_dpp_dto(struct dccg *dccg, int dpp_inst, int req_dppclk)
 		REG_UPDATE(DPPCLK_DTO_CTRL,
 				DPPCLK_DTO_ENABLE[dpp_inst], 0);
 	}
+
+	dccg->pipe_dppclk_khz[dpp_inst] = req_dppclk;
 }
 
 void dccg2_get_dccg_ref_freq(struct dccg *dccg,

commit 760ef473f2fccdf8ca9bc0773960e16d4ce6f3d2
Author: Sung Lee <sung.lee@amd.com>
Date:   Thu Dec 5 11:58:20 2019 -0500

    drm/amd/display: Formula refactor for calculating DPP CLK DTO
    
    [Why]
    Previous formula for calculating DPP CLK DTO was
    hard to understand.
    
    [How]
    Replace with easier to understand formula that produces
    same results.
    
    Signed-off-by: Sung Lee <sung.lee@amd.com>
    Reviewed-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
index 1e1151356e60..50bffbfdd394 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
@@ -50,20 +50,20 @@ void dccg2_update_dpp_dto(struct dccg *dccg, int dpp_inst, int req_dppclk)
 
 	if (dccg->ref_dppclk && req_dppclk) {
 		int ref_dppclk = dccg->ref_dppclk;
+		int modulo, phase;
 
-		ASSERT(req_dppclk <= ref_dppclk);
-		/* need to clamp to 8 bits */
-		if (ref_dppclk > 0xff) {
-			int divider = (ref_dppclk + 0xfe) / 0xff;
+		// phase / modulo = dpp pipe clk / dpp global clk
+		modulo = 0xff;   // use FF at the end
+		phase = ((modulo * req_dppclk) + ref_dppclk - 1) / ref_dppclk;
 
-			ref_dppclk /= divider;
-			req_dppclk = (req_dppclk + divider - 1) / divider;
-			if (req_dppclk > ref_dppclk)
-				req_dppclk = ref_dppclk;
+		if (phase > 0xff) {
+			ASSERT(false);
+			phase = 0xff;
 		}
+
 		REG_SET_2(DPPCLK_DTO_PARAM[dpp_inst], 0,
-				DPPCLK0_DTO_PHASE, req_dppclk,
-				DPPCLK0_DTO_MODULO, ref_dppclk);
+				DPPCLK0_DTO_PHASE, phase,
+				DPPCLK0_DTO_MODULO, modulo);
 		REG_UPDATE(DPPCLK_DTO_CTRL,
 				DPPCLK_DTO_ENABLE[dpp_inst], 1);
 	} else {

commit 799c5b9cb91ca759df65707d2820b5fe1ee5383c
Author: Wesley Chalmers <Wesley.Chalmers@amd.com>
Date:   Mon Aug 26 15:02:47 2019 -0400

    drm/amd/display: Revert fixup DPP programming sequence
    
    [WHY]
    This change was made because DTO programming was double-buffered, which
    is itself an issue. After deactivating the DTO double buffer, this
    change becomes unnecessary.
    
    Signed-off-by: Wesley Chalmers <Wesley.Chalmers@amd.com>
    Reviewed-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Acked-by: Anthony Koo <Anthony.Koo@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
index 206436632275..1e1151356e60 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
@@ -44,16 +44,12 @@
 #define DC_LOGGER \
 	dccg->ctx->logger
 
-void dccg2_update_dpp_dto(struct dccg *dccg,
-		int dpp_inst,
-		int req_dppclk,
-		bool reduce_divider_only)
+void dccg2_update_dpp_dto(struct dccg *dccg, int dpp_inst, int req_dppclk)
 {
 	struct dcn_dccg *dccg_dcn = TO_DCN_DCCG(dccg);
 
 	if (dccg->ref_dppclk && req_dppclk) {
 		int ref_dppclk = dccg->ref_dppclk;
-		int current_phase, current_modulo;
 
 		ASSERT(req_dppclk <= ref_dppclk);
 		/* need to clamp to 8 bits */
@@ -65,28 +61,9 @@ void dccg2_update_dpp_dto(struct dccg *dccg,
 			if (req_dppclk > ref_dppclk)
 				req_dppclk = ref_dppclk;
 		}
-
-		REG_GET_2(DPPCLK_DTO_PARAM[dpp_inst],
-				DPPCLK0_DTO_PHASE, &current_phase,
-				DPPCLK0_DTO_MODULO, &current_modulo);
-
-		if (reduce_divider_only) {
-			// requested phase/modulo greater than current
-			if (req_dppclk * current_modulo >= current_phase * ref_dppclk) {
-				REG_SET_2(DPPCLK_DTO_PARAM[dpp_inst], 0,
-						DPPCLK0_DTO_PHASE, req_dppclk,
-						DPPCLK0_DTO_MODULO, ref_dppclk);
-			} else {
-				REG_SET_2(DPPCLK_DTO_PARAM[dpp_inst], 0,
-						DPPCLK0_DTO_PHASE, current_phase,
-						DPPCLK0_DTO_MODULO, current_modulo);
-			}
-		} else {
-			REG_SET_2(DPPCLK_DTO_PARAM[dpp_inst], 0,
-					DPPCLK0_DTO_PHASE, req_dppclk,
-					DPPCLK0_DTO_MODULO, ref_dppclk);
-		}
-
+		REG_SET_2(DPPCLK_DTO_PARAM[dpp_inst], 0,
+				DPPCLK0_DTO_PHASE, req_dppclk,
+				DPPCLK0_DTO_MODULO, ref_dppclk);
 		REG_UPDATE(DPPCLK_DTO_CTRL,
 				DPPCLK_DTO_ENABLE[dpp_inst], 1);
 	} else {

commit 6bd0a112ec129615d23aa5d8d3dd0be0243989aa
Author: Wesley Chalmers <Wesley.Chalmers@amd.com>
Date:   Mon Sep 16 15:42:38 2019 -0500

    drm/amd/display: Do not double-buffer DTO adjustments
    
    [WHY]
    When changing DPP global ref clock, DTO adjustments must take effect
    immediately, or else underflow may occur.
    It appears the original decision to double-buffer DTO adjustments was made to
    prevent underflows that occur when raising DPP ref clock (which is not
    double-buffered), but that same decision causes similar issues when
    lowering DPP global ref clock. The better solution is to order the
    adjustments according to whether clocks are being raised or lowered.
    
    Signed-off-by: Wesley Chalmers <Wesley.Chalmers@amd.com>
    Reviewed-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Acked-by: Anthony Koo <Anthony.Koo@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
index 16476ed25536..206436632275 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
@@ -119,32 +119,6 @@ void dccg2_get_dccg_ref_freq(struct dccg *dccg,
 
 void dccg2_init(struct dccg *dccg)
 {
-	struct dcn_dccg *dccg_dcn = TO_DCN_DCCG(dccg);
-
-	// Fallthrough intentional to program all available dpp_dto's
-	switch (dccg_dcn->base.ctx->dc->res_pool->pipe_count) {
-	case 6:
-		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[5], 1);
-		/* Fall through */
-	case 5:
-		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[4], 1);
-		/* Fall through */
-	case 4:
-		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[3], 1);
-		/* Fall through */
-	case 3:
-		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[2], 1);
-		/* Fall through */
-	case 2:
-		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[1], 1);
-		/* Fall through */
-	case 1:
-		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[0], 1);
-		break;
-	default:
-		ASSERT(false);
-		break;
-	}
 }
 
 static const struct dccg_funcs dccg2_funcs = {

commit f7f38ffef56b0138f902efd261a6d90680fec2d3
Author: Jun Lei <Jun.Lei@amd.com>
Date:   Mon Jul 15 10:41:47 2019 -0400

    drm/amd/display: fixup DPP programming sequence
    
    [why]
    DC does not correct account for the fact that DPP DTO is double buffered while DPP ref is not.
    This means that when DPP ref clock is lowered when it's "safe to lower", the DPP blocks that need
    an increased divider will temporarily have actual DPP clock drop below minimum while DTO
    double buffering takes effect.  This results in temporary underflow.
    
    [how]
    To fix this, DPP clock cannot be programmed atomically, but rather be broken up into the DTO and the
    ref.  Each has a separate "safe to lower" logic.  When doing "prepare" the ref and dividers may only increase.
    When doing "optimize", both may decrease.  It is guaranteed that we won't exceed max DPP clock because
    we do not use dividers larger than 1.
    
    Signed-off-by: Jun Lei <Jun.Lei@amd.com>
    Reviewed-by: Eric Yang <eric.yang2@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
index 31aa6ee5cd5b..16476ed25536 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
@@ -44,12 +44,16 @@
 #define DC_LOGGER \
 	dccg->ctx->logger
 
-void dccg2_update_dpp_dto(struct dccg *dccg, int dpp_inst, int req_dppclk)
+void dccg2_update_dpp_dto(struct dccg *dccg,
+		int dpp_inst,
+		int req_dppclk,
+		bool reduce_divider_only)
 {
 	struct dcn_dccg *dccg_dcn = TO_DCN_DCCG(dccg);
 
 	if (dccg->ref_dppclk && req_dppclk) {
 		int ref_dppclk = dccg->ref_dppclk;
+		int current_phase, current_modulo;
 
 		ASSERT(req_dppclk <= ref_dppclk);
 		/* need to clamp to 8 bits */
@@ -61,9 +65,28 @@ void dccg2_update_dpp_dto(struct dccg *dccg, int dpp_inst, int req_dppclk)
 			if (req_dppclk > ref_dppclk)
 				req_dppclk = ref_dppclk;
 		}
-		REG_SET_2(DPPCLK_DTO_PARAM[dpp_inst], 0,
-				DPPCLK0_DTO_PHASE, req_dppclk,
-				DPPCLK0_DTO_MODULO, ref_dppclk);
+
+		REG_GET_2(DPPCLK_DTO_PARAM[dpp_inst],
+				DPPCLK0_DTO_PHASE, &current_phase,
+				DPPCLK0_DTO_MODULO, &current_modulo);
+
+		if (reduce_divider_only) {
+			// requested phase/modulo greater than current
+			if (req_dppclk * current_modulo >= current_phase * ref_dppclk) {
+				REG_SET_2(DPPCLK_DTO_PARAM[dpp_inst], 0,
+						DPPCLK0_DTO_PHASE, req_dppclk,
+						DPPCLK0_DTO_MODULO, ref_dppclk);
+			} else {
+				REG_SET_2(DPPCLK_DTO_PARAM[dpp_inst], 0,
+						DPPCLK0_DTO_PHASE, current_phase,
+						DPPCLK0_DTO_MODULO, current_modulo);
+			}
+		} else {
+			REG_SET_2(DPPCLK_DTO_PARAM[dpp_inst], 0,
+					DPPCLK0_DTO_PHASE, req_dppclk,
+					DPPCLK0_DTO_MODULO, ref_dppclk);
+		}
+
 		REG_UPDATE(DPPCLK_DTO_CTRL,
 				DPPCLK_DTO_ENABLE[dpp_inst], 1);
 	} else {

commit 9e87891799dc4b203ad680ff431bfcce679c89be
Author: Gustavo A. R. Silva <gustavo@embeddedor.com>
Date:   Thu Jul 25 19:13:51 2019 -0500

    drm/amd/display: Mark expected switch fall-throughs
    
    In preparation to enabling -Wimplicit-fallthrough, mark switch
    cases where we are expecting to fall through.
    
    Warning level 3 was used: -Wimplicit-fallthrough=3
    
    This patch is part of the ongoing efforts to enable -Wimplicit-fallthrough.
    
    Signed-off-by: Gustavo A. R. Silva <gustavo@embeddedor.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
index 51a3dfe97f0e..31aa6ee5cd5b 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
@@ -102,14 +102,19 @@ void dccg2_init(struct dccg *dccg)
 	switch (dccg_dcn->base.ctx->dc->res_pool->pipe_count) {
 	case 6:
 		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[5], 1);
+		/* Fall through */
 	case 5:
 		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[4], 1);
+		/* Fall through */
 	case 4:
 		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[3], 1);
+		/* Fall through */
 	case 3:
 		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[2], 1);
+		/* Fall through */
 	case 2:
 		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[1], 1);
+		/* Fall through */
 	case 1:
 		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[0], 1);
 		break;

commit d7929c1e13e3788e7cb741d75b5baec5e53eff21
Merge: 8ac875db0fdc 80d42db02b3a
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Tue Jun 25 08:42:25 2019 -0500

    Merge branch 'drm-next' into drm-next-5.3
    
    Backmerge drm-next and fix up conflicts due to drmP.h removal.
    
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

commit fcee01b9f82d44a4f62791f710ede954731df1bf
Author: Harry Wentland <harry.wentland@amd.com>
Date:   Tue May 7 14:57:07 2019 -0500

    drm/amd/display: Add DCN2 clk mgr
    
    Adds support for handling of clocking relevant to the DCN2 block,
    including programming of the DCCG (Display Controller Clock Generator)
    block:
    
    HW Blocks:
    
        +--------+       +--------+
        |  DIO   |       |  DCCG  |
        +--------+       +--------+
    
    Signed-off-by: Harry Wentland <harry.wentland@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
new file mode 100644
index 000000000000..23362dd4b6d3
--- /dev/null
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_dccg.c
@@ -0,0 +1,157 @@
+/*
+ * Copyright 2018 Advanced Micro Devices, Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: AMD
+ *
+ */
+
+#include "reg_helper.h"
+#include "core_types.h"
+#include "dcn20_dccg.h"
+
+#define TO_DCN_DCCG(dccg)\
+	container_of(dccg, struct dcn_dccg, base)
+
+#define REG(reg) \
+	(dccg_dcn->regs->reg)
+
+#undef FN
+#define FN(reg_name, field_name) \
+	dccg_dcn->dccg_shift->field_name, dccg_dcn->dccg_mask->field_name
+
+#define CTX \
+	dccg_dcn->base.ctx
+#define DC_LOGGER \
+	dccg->ctx->logger
+
+void dccg2_update_dpp_dto(struct dccg *dccg, int dpp_inst, int req_dppclk)
+{
+	struct dcn_dccg *dccg_dcn = TO_DCN_DCCG(dccg);
+
+	if (dccg->ref_dppclk && req_dppclk) {
+		int ref_dppclk = dccg->ref_dppclk;
+
+		ASSERT(req_dppclk <= ref_dppclk);
+		/* need to clamp to 8 bits */
+		if (ref_dppclk > 0xff) {
+			int divider = (ref_dppclk + 0xfe) / 0xff;
+
+			ref_dppclk /= divider;
+			req_dppclk = (req_dppclk + divider - 1) / divider;
+			if (req_dppclk > ref_dppclk)
+				req_dppclk = ref_dppclk;
+		}
+		REG_SET_2(DPPCLK_DTO_PARAM[dpp_inst], 0,
+				DPPCLK0_DTO_PHASE, req_dppclk,
+				DPPCLK0_DTO_MODULO, ref_dppclk);
+		REG_UPDATE(DPPCLK_DTO_CTRL,
+				DPPCLK_DTO_ENABLE[dpp_inst], 1);
+	} else {
+		REG_UPDATE(DPPCLK_DTO_CTRL,
+				DPPCLK_DTO_ENABLE[dpp_inst], 0);
+	}
+}
+
+void dccg2_get_dccg_ref_freq(struct dccg *dccg,
+		unsigned int xtalin_freq_inKhz,
+		unsigned int *dccg_ref_freq_inKhz)
+{
+	struct dcn_dccg *dccg_dcn = TO_DCN_DCCG(dccg);
+	uint32_t clk_en = 0;
+	uint32_t clk_sel = 0;
+
+	REG_GET_2(REFCLK_CNTL, REFCLK_CLOCK_EN, &clk_en, REFCLK_SRC_SEL, &clk_sel);
+
+	if (clk_en != 0) {
+		// DCN20 has never been validated for non-xtalin as reference
+		// frequency.  There's actually no way for DC to determine what
+		// frequency a non-xtalin source is.
+		ASSERT_CRITICAL(false);
+	}
+
+	*dccg_ref_freq_inKhz = xtalin_freq_inKhz;
+
+	return;
+}
+
+void dccg2_init(struct dccg *dccg)
+{
+	struct dcn_dccg *dccg_dcn = TO_DCN_DCCG(dccg);
+
+	// Fallthrough intentional to program all available dpp_dto's
+	switch (dccg_dcn->base.ctx->dc->res_pool->pipe_count) {
+	case 6:
+		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[5], 1);
+	case 5:
+		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[4], 1);
+	case 4:
+		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[3], 1);
+	case 3:
+		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[2], 1);
+	case 2:
+		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[1], 1);
+	case 1:
+		REG_UPDATE(DPPCLK_DTO_CTRL, DPPCLK_DTO_DB_EN[0], 1);
+		break;
+	default:
+		ASSERT(false);
+		break;
+	}
+}
+
+static const struct dccg_funcs dccg2_funcs = {
+	.update_dpp_dto = dccg2_update_dpp_dto,
+	.get_dccg_ref_freq = dccg2_get_dccg_ref_freq,
+	.dccg_init = dccg2_init
+};
+
+struct dccg *dccg2_create(
+	struct dc_context *ctx,
+	const struct dccg_registers *regs,
+	const struct dccg_shift *dccg_shift,
+	const struct dccg_mask *dccg_mask)
+{
+	struct dcn_dccg *dccg_dcn = kzalloc(sizeof(*dccg_dcn), GFP_KERNEL);
+	struct dccg *base;
+
+	if (dccg_dcn == NULL) {
+		BREAK_TO_DEBUGGER();
+		return NULL;
+	}
+
+	base = &dccg_dcn->base;
+	base->ctx = ctx;
+	base->funcs = &dccg2_funcs;
+
+	dccg_dcn->regs = regs;
+	dccg_dcn->dccg_shift = dccg_shift;
+	dccg_dcn->dccg_mask = dccg_mask;
+
+	return &dccg_dcn->base;
+}
+
+void dcn_dccg_destroy(struct dccg **dccg)
+{
+	struct dcn_dccg *dccg_dcn = TO_DCN_DCCG(*dccg);
+
+	kfree(dccg_dcn);
+	*dccg = NULL;
+}
