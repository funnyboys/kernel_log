commit 3ba01817365c5a2c07a8be09117f3e22e16f5c80
Author: Yongqiang Sun <yongqiang.sun@amd.com>
Date:   Sat Apr 18 19:22:55 2020 -0400

    drm/amd/display: Move panel_cntl specific register from abm to panel_cntl.
    
    [Why]
    panel_cntl specific register should be access in panel_cntl object.
    
    [How]
    Move these register access from abm to panel_cntl.
    
    Signed-off-by: Yongqiang Sun <yongqiang.sun@amd.com>
    Reviewed-by: Anthony Koo <Anthony.Koo@amd.com>
    Acked-by: Aurabindo Pillai <aurabindo.pillai@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 3a290ccaeb82..da5333d165ac 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -961,9 +961,7 @@ void dcn20_blank_pixel_data(
 	width = width / odm_cnt;
 
 	if (blank) {
-		if (stream_res->abm)
-			stream_res->abm->funcs->set_abm_immediate_disable(stream_res->abm,
-					stream->link->panel_cntl->inst);
+		dc->hwss.set_abm_immediate_disable(pipe_ctx);
 
 		if (dc->debug.visual_confirm != VISUAL_CONFIRM_DISABLE) {
 			test_pattern = CONTROLLER_DP_TEST_PATTERN_COLORSQUARES;
@@ -2042,9 +2040,7 @@ static void dcn20_reset_back_end_for_pipe(
 	 */
 	if (pipe_ctx->top_pipe == NULL) {
 
-		if (pipe_ctx->stream_res.abm)
-			pipe_ctx->stream_res.abm->funcs->set_abm_immediate_disable(pipe_ctx->stream_res.abm,
-					pipe_ctx->stream->link->panel_cntl->inst);
+		dc->hwss.set_abm_immediate_disable(pipe_ctx);
 
 		pipe_ctx->stream_res.tg->funcs->disable_crtc(pipe_ctx->stream_res.tg);
 

commit 18400f91c1c17777d98013ea15d620e7b4ac1cf4
Author: Yongqiang Sun <yongqiang.sun@amd.com>
Date:   Wed Apr 22 18:07:59 2020 -0400

    drm/amd/display: Add panel cntl id for set backlight level.
    
    [Why & How]
    Add panel cntl instance when calling set backlight.
    
    Signed-off-by: Yongqiang Sun <yongqiang.sun@amd.com>
    Reviewed-by: Anthony Koo <Anthony.Koo@amd.com>
    Acked-by: Aurabindo Pillai <aurabindo.pillai@amd.com>
    Acked-by: Tony Cheng <Tony.Cheng@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index bd2ccf8eb9cf..3a290ccaeb82 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -962,7 +962,8 @@ void dcn20_blank_pixel_data(
 
 	if (blank) {
 		if (stream_res->abm)
-			stream_res->abm->funcs->set_abm_immediate_disable(stream_res->abm);
+			stream_res->abm->funcs->set_abm_immediate_disable(stream_res->abm,
+					stream->link->panel_cntl->inst);
 
 		if (dc->debug.visual_confirm != VISUAL_CONFIRM_DISABLE) {
 			test_pattern = CONTROLLER_DP_TEST_PATTERN_COLORSQUARES;
@@ -997,7 +998,8 @@ void dcn20_blank_pixel_data(
 
 	if (!blank)
 		if (stream_res->abm) {
-			stream_res->abm->funcs->set_pipe(stream_res->abm, stream_res->tg->inst + 1);
+			stream_res->abm->funcs->set_pipe(stream_res->abm, stream_res->tg->inst + 1,
+					stream->link->panel_cntl->inst);
 			stream_res->abm->funcs->set_abm_level(stream_res->abm, stream->abm_level);
 		}
 }
@@ -2041,7 +2043,8 @@ static void dcn20_reset_back_end_for_pipe(
 	if (pipe_ctx->top_pipe == NULL) {
 
 		if (pipe_ctx->stream_res.abm)
-			pipe_ctx->stream_res.abm->funcs->set_abm_immediate_disable(pipe_ctx->stream_res.abm);
+			pipe_ctx->stream_res.abm->funcs->set_abm_immediate_disable(pipe_ctx->stream_res.abm,
+					pipe_ctx->stream->link->panel_cntl->inst);
 
 		pipe_ctx->stream_res.tg->funcs->disable_crtc(pipe_ctx->stream_res.tg);
 

commit 3ebd17f53556fff2809793b5d2c2259a1f2714dd
Author: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Date:   Wed Apr 22 18:07:52 2020 -0400

    drm/amd/display: check if REFCLK_CNTL register is present
    
    Check before programming the register since it isn't present on
    all IPs using this code.
    
    Signed-off-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Reviewed-by: Eric Bernstein <Eric.Bernstein@amd.com>
    Acked-by: Aurabindo Pillai <aurabindo.pillai@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 6ad4ed7da629..bd2ccf8eb9cf 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -2304,7 +2304,8 @@ void dcn20_fpga_init_hw(struct dc *dc)
 
 	REG_UPDATE(DCHUBBUB_GLOBAL_TIMER_CNTL, DCHUBBUB_GLOBAL_TIMER_REFDIV, 2);
 	REG_UPDATE(DCHUBBUB_GLOBAL_TIMER_CNTL, DCHUBBUB_GLOBAL_TIMER_ENABLE, 1);
-	REG_WRITE(REFCLK_CNTL, 0);
+	if (REG(REFCLK_CNTL))
+		REG_WRITE(REFCLK_CNTL, 0);
 	//
 
 

commit 68c10ac91f88babd7c8e273e5cdae892111ba334
Author: Aric Cyr <aric.cyr@amd.com>
Date:   Sun Apr 5 15:35:16 2020 -0400

    drm/amd/display: Update MPCC if requested
    
    Don't skip MPCC tree updates if requested.
    
    Signed-off-by: Aric Cyr <aric.cyr@amd.com>
    Reviewed-by: Joshua Aberback <Joshua.Aberback@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index efc7fb4cf44d..6ad4ed7da629 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -2175,7 +2175,8 @@ void dcn20_update_mpcc(struct dc *dc, struct pipe_ctx *pipe_ctx)
 	mpcc_id = hubp->inst;
 
 	/* If there is no full update, don't need to touch MPC tree*/
-	if (!pipe_ctx->plane_state->update_flags.bits.full_update) {
+	if (!pipe_ctx->plane_state->update_flags.bits.full_update &&
+		!pipe_ctx->update_flags.bits.mpcc) {
 		mpc->funcs->update_blending(mpc, &blnd_cfg, mpcc_id);
 		return;
 	}

commit 868149c9a072cbdc22a73ce25a487f9fbfa171ef
Author: Joshua Aberback <joshua.aberback@amd.com>
Date:   Mon Mar 30 15:49:02 2020 -0400

    drm/amd/display: Force watermark value propagation
    
    [Why]
    The HUBBUB watermark registers are in an area that cannot be power
    gated, but the HUBP copies of the watermark values are in areas that can
    be power gated. When we power on a pipe, it will not automatically take
    the HUBBUB values, we need to force propagation by writing to a
    watermark register.
    
    [How]
     - new HUBBUB function to re-write current value in a WM register
     - touch WM register after enabling the plane in program_pipe
    
    Signed-off-by: Joshua Aberback <joshua.aberback@amd.com>
    Reviewed-by: Jun Lei <Jun.Lei@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 7e65c774c800..efc7fb4cf44d 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1478,8 +1478,11 @@ static void dcn20_program_pipe(
 	if (pipe_ctx->update_flags.bits.odm)
 		hws->funcs.update_odm(dc, context, pipe_ctx);
 
-	if (pipe_ctx->update_flags.bits.enable)
+	if (pipe_ctx->update_flags.bits.enable) {
 		dcn20_enable_plane(dc, pipe_ctx, context);
+		if (dc->res_pool->hubbub->funcs->force_wm_propagate_to_pipes)
+			dc->res_pool->hubbub->funcs->force_wm_propagate_to_pipes(dc->res_pool->hubbub);
+	}
 
 	if (pipe_ctx->update_flags.raw || pipe_ctx->plane_state->update_flags.raw || pipe_ctx->stream->update_flags.raw)
 		dcn20_update_dchubp_dpp(dc, pipe_ctx, context);

commit b34659deb66bfe937b36aeeb53ed9b89c4048c8d
Author: Nicholas Kazlauskas <nicholas.kazlauskas@amd.com>
Date:   Sun Apr 5 16:40:56 2020 -0400

    drm/amd/display: Program viewport when source pos changes for DCN20 hw seq
    
    [Why]
    For medium updates that change nothing but the source rect position
    the viewport doesn't change on DCN20.
    
    We're missing the check for the position update bit that was there in
    the DCN10 hardware sequencer.
    
    [How]
    Check the position bit along with the scaling bit like we were doing
    with DCN20.
    
    We shouldn't actually hit a case where context != current_state in
    our programming/commit model but guard against it anyway since it was
    guarded for the other bits.
    
    Signed-off-by: Nicholas Kazlauskas <nicholas.kazlauskas@amd.com>
    Reviewed-by: Zhan Liu <Zhan.Liu@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 674e4b8abdfb..7e65c774c800 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1373,6 +1373,7 @@ static void dcn20_update_dchubp_dpp(
 	}
 
 	if (pipe_ctx->update_flags.bits.viewport ||
+			(context == dc->current_state && plane_state->update_flags.bits.position_change) ||
 			(context == dc->current_state && plane_state->update_flags.bits.scaling_change) ||
 			(context == dc->current_state && pipe_ctx->stream->update_flags.bits.scaling)) {
 

commit c97c8d77b11fcf4c18c2f67dd3878781b1b5c2ff
Author: Nicholas Kazlauskas <nicholas.kazlauskas@amd.com>
Date:   Sun Apr 5 16:40:47 2020 -0400

    drm/amd/display: Don't change mpcc tree for medium updates on DCN20 hwseq
    
    [Why]
    Overlay planes disappear when the plane's alpha blending mode or global
    opacity is modified.
    
    These are considered UPDATE_TYPE_MEDIUM and trigger the update_mpcc path
    in the DCN hardware sequencer.
    
    On DCN10 we have an "optimization" to avoid touching the blending tree
    on these updates, but this is actually required behavior based on how
    update_mpcc is structured.
    
    For full updates we acquire a MPCC for the plane, remove it if it
    already exists then reinsert it after with insert_plane.
    
    The call to insert_plane can take an optional mpcc to insert the new one
    above to preserve the current blending order. The update_mpcc hwseq
    function doesn't do this so the overlay gets sent to the very bottom
    of the tree.
    
    [How]
    Copy the check over from DCN10 to DCN20. The only time we need to
    actually touch the tree really is the full update, so this is also
    an optimization on top of the fix.
    
    Fixing the logic for insert_plane is rather simple (cache the bot_mpcc
    and pass it to insert_plane) but is a change that impacts most display
    usecases.
    
    For now stick with the optimization.
    
    Signed-off-by: Nicholas Kazlauskas <nicholas.kazlauskas@amd.com>
    Reviewed-by: Chris Park <Chris.Park@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 233318260da4..674e4b8abdfb 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -2170,6 +2170,12 @@ void dcn20_update_mpcc(struct dc *dc, struct pipe_ctx *pipe_ctx)
 	 */
 	mpcc_id = hubp->inst;
 
+	/* If there is no full update, don't need to touch MPC tree*/
+	if (!pipe_ctx->plane_state->update_flags.bits.full_update) {
+		mpc->funcs->update_blending(mpc, &blnd_cfg, mpcc_id);
+		return;
+	}
+
 	/* check if this MPCC is already being used */
 	new_mpcc = mpc->funcs->get_mpcc_for_dpp(mpc_tree_params, mpcc_id);
 	/* remove MPCC if being used */

commit 2f752e914d943c199f3255b4aba3358fd78cc8c9
Author: Nikola Cornij <nikola.cornij@amd.com>
Date:   Thu Mar 5 16:32:35 2020 -0500

    drm/amd/display: Remove connect DIG FE to its BE during timing programming
    
    [why]
    Causes regression with MST DSC displays not lighting up after DPMS
    
    [how]
    Revert commit 8cc426d79be1c3 ("drm/amd/display: Program DSC during timing programming")
    
    Signed-off-by: Nikola Cornij <nikola.cornij@amd.com>
    Reviewed-by: Aric Cyr <Aric.Cyr@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 69eb7b3697d2..233318260da4 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -623,13 +623,6 @@ enum dc_status dcn20_enable_stream_timing(
 
 	/* TODO check if timing_changed, disable stream if timing changed */
 
-	/* Have to setup DSC here to make sure the bandwidth sent to DIG BE won't be bigger than
-	 * what the link and/or DIG BE can handle. VBID[6]/CompressedStream_flag will be automatically
-	 * set at a later time when the video is enabled (DP_VID_STREAM_EN = 1).
-	 */
-	if (pipe_ctx->stream->timing.flags.DSC)
-		dp_set_dsc_on_stream(pipe_ctx, true);
-
 	for (odm_pipe = pipe_ctx->next_odm_pipe; odm_pipe; odm_pipe = odm_pipe->next_odm_pipe) {
 		opp_inst[opp_cnt] = odm_pipe->stream_res.opp->inst;
 		opp_cnt++;

commit 1ef893e2749292be0c3f41f404bc44e5d6a5f742
Author: Yongqiang Sun <yongqiang.sun@amd.com>
Date:   Thu Feb 27 15:36:00 2020 -0500

    drm/amd/display: workaround for HDMI hotplug in DPMSOFF state
    
    [Why]
    When hotplug a HDMI monitor during entering S0i3 or DPMSOFF state due to
    entering infinite loop when calling vbios to program pixel clocks. In
    this scenario, pll is enabled but phy is not, and there is not a
    programing guide for this case.
    
    [How]
    Before we having the proper programing guide, before disable pll, doing
    a phy enable and disable to avoid the issue.
    
    Signed-off-by: Yongqiang Sun <yongqiang.sun@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 03f0c9914520..69eb7b3697d2 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -654,6 +654,9 @@ enum dc_status dcn20_enable_stream_timing(
 		return DC_ERROR_UNEXPECTED;
 	}
 
+	if (dc->hwseq->funcs.PLAT_58856_wa && (!dc_is_dp_signal(stream->signal)))
+		dc->hwseq->funcs.PLAT_58856_wa(context, pipe_ctx);
+
 	pipe_ctx->stream_res.tg->funcs->program_timing(
 			pipe_ctx->stream_res.tg,
 			&stream->timing,

commit 8cc426d79be1c360f2cc53a469a9eb7c737ccad9
Author: Nikola Cornij <nikola.cornij@amd.com>
Date:   Wed Feb 26 14:53:54 2020 -0500

    drm/amd/display: Program DSC during timing programming
    
    [why]
    Link or DIG BE can't be exposed to a higher stream bandwidth than they
    can handle. When DSC is required to fit the stream into the link
    bandwidth, DSC has to be programmed during timing programming to ensure
    this. Without it, intermittent issues such as black screen after S3 or a
    hot-plug can be seen.
    
    [how]
    Move DSC programming from enabling stream on link to timing setup.
    
    Signed-off-by: Nikola Cornij <nikola.cornij@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index b0f61bd7c208..03f0c9914520 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -623,6 +623,13 @@ enum dc_status dcn20_enable_stream_timing(
 
 	/* TODO check if timing_changed, disable stream if timing changed */
 
+	/* Have to setup DSC here to make sure the bandwidth sent to DIG BE won't be bigger than
+	 * what the link and/or DIG BE can handle. VBID[6]/CompressedStream_flag will be automatically
+	 * set at a later time when the video is enabled (DP_VID_STREAM_EN = 1).
+	 */
+	if (pipe_ctx->stream->timing.flags.DSC)
+		dp_set_dsc_on_stream(pipe_ctx, true);
+
 	for (odm_pipe = pipe_ctx->next_odm_pipe; odm_pipe; odm_pipe = odm_pipe->next_odm_pipe) {
 		opp_inst[opp_cnt] = odm_pipe->stream_res.opp->inst;
 		opp_cnt++;

commit 4c631826e0bcfaefe580faeb4ef6651e5ebe57c1
Author: Yongqiang Sun <yongqiang.sun@amd.com>
Date:   Wed Feb 26 14:25:29 2020 -0500

    drm/amd/display: Not check wm and clk change flag in optimized bandwidth.
    
    [Why]
    System isn't able to enter S0i3 due to not send display count 0 to smu.
    When dpms off, clk changed flag is cleared alreay, and it is checked
    when doing optimized bandwidth, and update clocks is bypassed due to the
    flag is unset.
    
    [How]
    Remove check flag incide the function since watermark values and clocks
    values are checked during update to determine whether to perform it, no
    need to check it again outside the function.
    
    Signed-off-by: Yongqiang Sun <yongqiang.sun@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 045ba08c85b4..b0f61bd7c208 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1660,22 +1660,16 @@ void dcn20_optimize_bandwidth(
 {
 	struct hubbub *hubbub = dc->res_pool->hubbub;
 
-	if (dc->wm_optimized_required || IS_DIAG_DC(dc->ctx->dce_environment)) {
-		/* program dchubbub watermarks */
-		hubbub->funcs->program_watermarks(hubbub,
-						&context->bw_ctx.bw.dcn.watermarks,
-						dc->res_pool->ref_clocks.dchub_ref_clock_inKhz / 1000,
-						true);
-		dc->wm_optimized_required = false;
-	}
-
-	if (dc->clk_optimized_required || IS_DIAG_DC(dc->ctx->dce_environment)) {
-		dc->clk_mgr->funcs->update_clocks(
-				dc->clk_mgr,
-				context,
-				true);
-		dc->clk_optimized_required = false;
-	}
+	/* program dchubbub watermarks */
+	hubbub->funcs->program_watermarks(hubbub,
+					&context->bw_ctx.bw.dcn.watermarks,
+					dc->res_pool->ref_clocks.dchub_ref_clock_inKhz / 1000,
+					true);
+
+	dc->clk_mgr->funcs->update_clocks(
+			dc->clk_mgr,
+			context,
+			true);
 }
 
 bool dcn20_update_bandwidth(

commit ffa121419257d72ea520bf31e15d12effb50c039
Author: Sung Lee <sung.lee@amd.com>
Date:   Fri Feb 21 14:50:55 2020 -0500

    drm/amd/display: Set clock optimization required after update clocks
    
    [WHY]
    We see an issue that caused clk_optimized_required to be set true in
    certain cases, causing passive flips to fail. This is because of a typo
    where wm_optimized_required was set twice.
    
    [HOW]
    Set clk_optimized_required to false after updating clocks.
    
    Signed-off-by: Sung Lee <sung.lee@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 49f5af9e3016..045ba08c85b4 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1674,7 +1674,7 @@ void dcn20_optimize_bandwidth(
 				dc->clk_mgr,
 				context,
 				true);
-		dc->wm_optimized_required = false;
+		dc->clk_optimized_required = false;
 	}
 }
 

commit 10b4e64e58b4a9d7669bc6682b3fd12ae62744b2
Author: Wenjing Liu <Wenjing.Liu@amd.com>
Date:   Tue Feb 11 10:27:21 2020 -0500

    drm/amd/display: program DPG_OFFSET_SEGMENT for odm_pipe
    
    [why]
    When test pattern is enabled with ODM combine, test pattern is generated
    by piecing multiple DPGs image together.  The current code will program
    all DPGs with horizontal offset of 0. This will cause all DPGs to output
    the beginning of the pattern. Instead each DPG should program a
    horizontal offset of its x position to form a continous pattern when
    pieced together.
    
    Signed-off-by: Wenjing Liu <Wenjing.Liu@amd.com>
    Reviewed-by: Nikola Cornij <Nikola.Cornij@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 97c0c8ced8e5..49f5af9e3016 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -307,7 +307,8 @@ void dcn20_init_blank(
 			COLOR_DEPTH_UNDEFINED,
 			&black_color,
 			otg_active_width,
-			otg_active_height);
+			otg_active_height,
+			0);
 
 	if (num_opps == 2) {
 		bottom_opp->funcs->opp_set_disp_pattern_generator(
@@ -317,7 +318,8 @@ void dcn20_init_blank(
 				COLOR_DEPTH_UNDEFINED,
 				&black_color,
 				otg_active_width,
-				otg_active_height);
+				otg_active_height,
+				0);
 	}
 
 	hws->funcs.wait_for_blank_complete(opp);
@@ -974,7 +976,8 @@ void dcn20_blank_pixel_data(
 			stream->timing.display_color_depth,
 			&black_color,
 			width,
-			height);
+			height,
+			0);
 
 	for (odm_pipe = pipe_ctx->next_odm_pipe; odm_pipe; odm_pipe = odm_pipe->next_odm_pipe) {
 		odm_pipe->stream_res.opp->funcs->opp_set_disp_pattern_generator(
@@ -985,7 +988,8 @@ void dcn20_blank_pixel_data(
 				stream->timing.display_color_depth,
 				&black_color,
 				width,
-				height);
+				height,
+				0);
 	}
 
 	if (!blank)

commit d9758768a672e9e665cba4171c022e5069b71aff
Author: George Shen <george.shen@amd.com>
Date:   Thu Jan 30 15:57:36 2020 -0500

    drm/amd/display: Temporarily disable stutter on MPO transition
    
    [Why]
    Underflow sometimes occurs during transition into MPO with stutter
    enabled.
    
    [How]
    When transitioning into MPO, disable stutter. Re-enable stutter within
    one frame.
    
    Signed-off-by: George Shen <george.shen@amd.com>
    Signed-off-by: Tony Cheng <tony.cheng@amd.com>
    Reviewed-by: Eric Yang <eric.yang2@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Acked-by: Harry Wentland <harry.wentland@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index cf13b1db1025..97c0c8ced8e5 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1584,6 +1584,7 @@ void dcn20_post_unlock_program_front_end(
 {
 	int i;
 	const unsigned int TIMEOUT_FOR_PIPE_ENABLE_MS = 100;
+	struct dce_hwseq *hwseq = dc->hwseq;
 
 	DC_LOGGER_INIT(dc->ctx->logger);
 
@@ -1611,8 +1612,24 @@ void dcn20_post_unlock_program_front_end(
 	}
 
 	/* WA to apply WM setting*/
-	if (dc->hwseq->wa.DEGVIDCN21)
+	if (hwseq->wa.DEGVIDCN21)
 		dc->res_pool->hubbub->funcs->apply_DEDCN21_147_wa(dc->res_pool->hubbub);
+
+
+	/* WA for stutter underflow during MPO transitions when adding 2nd plane */
+	if (hwseq->wa.disallow_self_refresh_during_multi_plane_transition) {
+
+		if (dc->current_state->stream_status[0].plane_count == 1 &&
+				context->stream_status[0].plane_count > 1) {
+
+			struct timing_generator *tg = dc->res_pool->timing_generators[0];
+
+			dc->res_pool->hubbub->funcs->allow_self_refresh_control(dc->res_pool->hubbub, false);
+
+			hwseq->wa_state.disallow_self_refresh_during_multi_plane_transition_applied = true;
+			hwseq->wa_state.disallow_self_refresh_during_multi_plane_transition_applied_on_frame = tg->funcs->get_frame_count(tg);
+		}
+	}
 }
 
 void dcn20_prepare_bandwidth(

commit 89e94bc57429305e089f149a6e7083e5f36f39c4
Author: Yongqiang Sun <yongqiang.sun@amd.com>
Date:   Fri Feb 14 12:55:55 2020 -0500

    drm/amd/display: optimize prgoram wm and clks
    
    [Why]
    In some display configuration like 1080P monitor playing a 1080P video,
    if user use ALT+F4 to exit Movie and TV, there is a chance clocks are
    same only water mark changed. Current clock optimization machanism will
    result in water mark keeps high after exit Movie and TV app.
    
    [How]
    Return if watermark need to be optimized when doing program watermark,
    perform the optimization after.
    
    Signed-off-by: Yongqiang Sun <yongqiang.sun@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Acked-by: Harry Wentland <harry.wentland@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index b9ec40a31f5c..cf13b1db1025 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1627,7 +1627,7 @@ void dcn20_prepare_bandwidth(
 			false);
 
 	/* program dchubbub watermarks */
-	hubbub->funcs->program_watermarks(hubbub,
+	dc->wm_optimized_required = hubbub->funcs->program_watermarks(hubbub,
 					&context->bw_ctx.bw.dcn.watermarks,
 					dc->res_pool->ref_clocks.dchub_ref_clock_inKhz / 1000,
 					false);
@@ -1639,16 +1639,22 @@ void dcn20_optimize_bandwidth(
 {
 	struct hubbub *hubbub = dc->res_pool->hubbub;
 
-	/* program dchubbub watermarks */
-	hubbub->funcs->program_watermarks(hubbub,
-					&context->bw_ctx.bw.dcn.watermarks,
-					dc->res_pool->ref_clocks.dchub_ref_clock_inKhz / 1000,
-					true);
+	if (dc->wm_optimized_required || IS_DIAG_DC(dc->ctx->dce_environment)) {
+		/* program dchubbub watermarks */
+		hubbub->funcs->program_watermarks(hubbub,
+						&context->bw_ctx.bw.dcn.watermarks,
+						dc->res_pool->ref_clocks.dchub_ref_clock_inKhz / 1000,
+						true);
+		dc->wm_optimized_required = false;
+	}
 
-	dc->clk_mgr->funcs->update_clocks(
-			dc->clk_mgr,
-			context,
-			true);
+	if (dc->clk_optimized_required || IS_DIAG_DC(dc->ctx->dce_environment)) {
+		dc->clk_mgr->funcs->update_clocks(
+				dc->clk_mgr,
+				context,
+				true);
+		dc->wm_optimized_required = false;
+	}
 }
 
 bool dcn20_update_bandwidth(

commit 9edf202d27df185e04f348c30d19a63f0ebe18d8
Author: Jing Zhou <Jing.Zhou@amd.com>
Date:   Tue Jan 21 18:05:35 2020 +0800

    drm/amd/display: external monitor abm enabled in modern standby
    
    [why]
    Resume from modern standby, edp stream disabled
    but abm keep enabled. External monitor select OTG
    source 0 which ABM enabled.
    [how]
    Disable abm before disable crtc when reset path
    mode not call core link disable stream.
    
    Signed-off-by: Jing Zhou <Jing.Zhou@amd.com>
    Reviewed-by: Anthony Koo <Anthony.Koo@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 52ef4d333112..b9ec40a31f5c 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -2011,6 +2011,10 @@ static void dcn20_reset_back_end_for_pipe(
 	 * parent pipe.
 	 */
 	if (pipe_ctx->top_pipe == NULL) {
+
+		if (pipe_ctx->stream_res.abm)
+			pipe_ctx->stream_res.abm->funcs->set_abm_immediate_disable(pipe_ctx->stream_res.abm);
+
 		pipe_ctx->stream_res.tg->funcs->disable_crtc(pipe_ctx->stream_res.tg);
 
 		pipe_ctx->stream_res.tg->funcs->enable_optc_clock(pipe_ctx->stream_res.tg, false);

commit 71b81f1275e0b5713fae86004be72719a2fa73b7
Author: Wenjing Liu <Wenjing.Liu@amd.com>
Date:   Wed Jan 22 11:54:54 2020 -0500

    drm/amd/display: decouple global lock out of pipe control lock
    
    [why]
    hwss should not guess what type of pipe lock is needed.
    The caller of the lock function should know
    the right type of pipe lock.
    Decouple the setup of global lock outside of pipe control lock
    logic.
    
    Signed-off-by: Wenjing Liu <Wenjing.Liu@amd.com>
    Reviewed-by: Anthony Koo <Anthony.Koo@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 9713f452debf..52ef4d333112 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1094,7 +1094,6 @@ void dcn20_pipe_control_lock(
 	bool lock)
 {
 	bool flip_immediate = false;
-	bool dig_update_required = false;
 
 	/* use TG master update lock to lock everything on the TG
 	 * therefore only top pipe need to lock
@@ -1132,19 +1131,6 @@ void dcn20_pipe_control_lock(
 		    (!flip_immediate && pipe->stream_res.gsl_group > 0))
 			dcn20_setup_gsl_group_as_lock(dc, pipe, flip_immediate);
 
-	if (pipe->stream && pipe->stream->update_flags.bits.dsc_changed)
-		dig_update_required = true;
-
-	/* Need double buffer lock mode in order to synchronize front end pipe
-	 * updates with dig updates.
-	 */
-	if (dig_update_required) {
-		if (lock) {
-			pipe->stream_res.tg->funcs->lock_doublebuffer_enable(
-					pipe->stream_res.tg);
-		}
-	}
-
 	if (pipe->plane_state != NULL && pipe->plane_state->triplebuffer_flips) {
 		if (lock)
 			pipe->stream_res.tg->funcs->triplebuffer_lock(pipe->stream_res.tg);
@@ -1156,19 +1142,6 @@ void dcn20_pipe_control_lock(
 		else
 			pipe->stream_res.tg->funcs->unlock(pipe->stream_res.tg);
 	}
-
-	if (dig_update_required) {
-		if (!lock) {
-			pipe->stream_res.tg->funcs->wait_for_state(pipe->stream_res.tg,
-					CRTC_STATE_VACTIVE);
-			pipe->stream_res.tg->funcs->wait_for_state(pipe->stream_res.tg,
-					CRTC_STATE_VBLANK);
-			pipe->stream_res.tg->funcs->wait_for_state(pipe->stream_res.tg,
-					CRTC_STATE_VACTIVE);
-			pipe->stream_res.tg->funcs->lock_doublebuffer_disable(
-					pipe->stream_res.tg);
-		}
-	}
 }
 
 static void dcn20_detect_pipe_changes(struct pipe_ctx *old_pipe, struct pipe_ctx *new_pipe)

commit 3ba28b639d653d58e918eb854de26f0d01cc7d5b
Author: Aric Cyr <aric.cyr@amd.com>
Date:   Sat Jan 18 14:03:55 2020 -0500

    drm/amd/display: Fix GSL acquire
    
    [Why]
    After locking refactor GSL is not acquired properly
    resulting in immediate flip issues.
    
    [How]
    Do not copy old GSL state anymore since GSL is acquired
    earlier now.
    
    Signed-off-by: Aric Cyr <aric.cyr@amd.com>
    Reviewed-by: Anthony Koo <Anthony.Koo@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 129a91e8f250..9713f452debf 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1562,12 +1562,6 @@ void dcn20_program_front_end_for_ctx(
 		}
 	}
 
-	/* Carry over GSL groups in case the context is changing. */
-	for (i = 0; i < dc->res_pool->pipe_count; i++)
-		if (context->res_ctx.pipe_ctx[i].stream == dc->current_state->res_ctx.pipe_ctx[i].stream)
-			context->res_ctx.pipe_ctx[i].stream_res.gsl_group =
-				dc->current_state->res_ctx.pipe_ctx[i].stream_res.gsl_group;
-
 	/* Set pipe update flags and lock pipes */
 	for (i = 0; i < dc->res_pool->pipe_count; i++)
 		dcn20_detect_pipe_changes(&dc->current_state->res_ctx.pipe_ctx[i],

commit 009114f6df84150a567b05537aa29b9d660e419b
Author: Anthony Koo <Anthony.Koo@amd.com>
Date:   Tue Jan 14 17:04:24 2020 -0500

    drm/amd/display: Added locking for atomic update stream and update planes
    
    [Why]
    Screen flickering when HDR switches between FP16 and ARGB2101010
    
    [How]
    Moved pipe_control_lock so stream update and plane update occur atomically
    
    Signed-off-by: Anthony Koo <Anthony.Koo@amd.com>
    Signed-off-by: Lucy Li <lucy.li@amd.com>
    Reviewed-by: Aric Cyr <Aric.Cyr@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index f36c4d1b7c30..129a91e8f250 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1088,40 +1088,18 @@ void dcn20_enable_plane(
 //	}
 }
 
-
-void dcn20_pipe_control_lock_global(
-		struct dc *dc,
-		struct pipe_ctx *pipe,
-		bool lock)
-{
-	if (lock) {
-		pipe->stream_res.tg->funcs->lock_doublebuffer_enable(
-				pipe->stream_res.tg);
-		pipe->stream_res.tg->funcs->lock(pipe->stream_res.tg);
-	} else {
-		pipe->stream_res.tg->funcs->unlock(pipe->stream_res.tg);
-		pipe->stream_res.tg->funcs->wait_for_state(pipe->stream_res.tg,
-				CRTC_STATE_VACTIVE);
-		pipe->stream_res.tg->funcs->wait_for_state(pipe->stream_res.tg,
-				CRTC_STATE_VBLANK);
-		pipe->stream_res.tg->funcs->wait_for_state(pipe->stream_res.tg,
-				CRTC_STATE_VACTIVE);
-		pipe->stream_res.tg->funcs->lock_doublebuffer_disable(
-				pipe->stream_res.tg);
-	}
-}
-
 void dcn20_pipe_control_lock(
 	struct dc *dc,
 	struct pipe_ctx *pipe,
 	bool lock)
 {
 	bool flip_immediate = false;
+	bool dig_update_required = false;
 
 	/* use TG master update lock to lock everything on the TG
 	 * therefore only top pipe need to lock
 	 */
-	if (pipe->top_pipe)
+	if (!pipe || pipe->top_pipe)
 		return;
 
 	if (pipe->plane_state != NULL)
@@ -1154,6 +1132,19 @@ void dcn20_pipe_control_lock(
 		    (!flip_immediate && pipe->stream_res.gsl_group > 0))
 			dcn20_setup_gsl_group_as_lock(dc, pipe, flip_immediate);
 
+	if (pipe->stream && pipe->stream->update_flags.bits.dsc_changed)
+		dig_update_required = true;
+
+	/* Need double buffer lock mode in order to synchronize front end pipe
+	 * updates with dig updates.
+	 */
+	if (dig_update_required) {
+		if (lock) {
+			pipe->stream_res.tg->funcs->lock_doublebuffer_enable(
+					pipe->stream_res.tg);
+		}
+	}
+
 	if (pipe->plane_state != NULL && pipe->plane_state->triplebuffer_flips) {
 		if (lock)
 			pipe->stream_res.tg->funcs->triplebuffer_lock(pipe->stream_res.tg);
@@ -1165,6 +1156,19 @@ void dcn20_pipe_control_lock(
 		else
 			pipe->stream_res.tg->funcs->unlock(pipe->stream_res.tg);
 	}
+
+	if (dig_update_required) {
+		if (!lock) {
+			pipe->stream_res.tg->funcs->wait_for_state(pipe->stream_res.tg,
+					CRTC_STATE_VACTIVE);
+			pipe->stream_res.tg->funcs->wait_for_state(pipe->stream_res.tg,
+					CRTC_STATE_VBLANK);
+			pipe->stream_res.tg->funcs->wait_for_state(pipe->stream_res.tg,
+					CRTC_STATE_VACTIVE);
+			pipe->stream_res.tg->funcs->lock_doublebuffer_disable(
+					pipe->stream_res.tg);
+		}
+	}
 }
 
 static void dcn20_detect_pipe_changes(struct pipe_ctx *old_pipe, struct pipe_ctx *new_pipe)
@@ -1536,26 +1540,28 @@ static void dcn20_program_pipe(
 	}
 }
 
-static bool does_pipe_need_lock(struct pipe_ctx *pipe)
-{
-	if ((pipe->plane_state && pipe->plane_state->update_flags.raw)
-			|| pipe->update_flags.raw)
-		return true;
-	if (pipe->bottom_pipe)
-		return does_pipe_need_lock(pipe->bottom_pipe);
-
-	return false;
-}
-
 void dcn20_program_front_end_for_ctx(
 		struct dc *dc,
 		struct dc_state *context)
 {
 	int i;
 	struct dce_hwseq *hws = dc->hwseq;
-	bool pipe_locked[MAX_PIPES] = {false};
 	DC_LOGGER_INIT(dc->ctx->logger);
 
+	for (i = 0; i < dc->res_pool->pipe_count; i++) {
+		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
+
+		if (!pipe_ctx->top_pipe && !pipe_ctx->prev_odm_pipe && pipe_ctx->plane_state) {
+			ASSERT(!pipe_ctx->plane_state->triplebuffer_flips);
+			if (dc->hwss.program_triplebuffer != NULL &&
+				!dc->debug.disable_tri_buf) {
+				/*turn off triple buffer for full update*/
+				dc->hwss.program_triplebuffer(
+					dc, pipe_ctx, pipe_ctx->plane_state->triplebuffer_flips);
+			}
+		}
+	}
+
 	/* Carry over GSL groups in case the context is changing. */
 	for (i = 0; i < dc->res_pool->pipe_count; i++)
 		if (context->res_ctx.pipe_ctx[i].stream == dc->current_state->res_ctx.pipe_ctx[i].stream)
@@ -1566,17 +1572,6 @@ void dcn20_program_front_end_for_ctx(
 	for (i = 0; i < dc->res_pool->pipe_count; i++)
 		dcn20_detect_pipe_changes(&dc->current_state->res_ctx.pipe_ctx[i],
 				&context->res_ctx.pipe_ctx[i]);
-	for (i = 0; i < dc->res_pool->pipe_count; i++)
-		if (!context->res_ctx.pipe_ctx[i].top_pipe &&
-				does_pipe_need_lock(&context->res_ctx.pipe_ctx[i])) {
-			struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
-
-			if (pipe_ctx->update_flags.bits.tg_changed || pipe_ctx->update_flags.bits.enable)
-				dc->hwss.pipe_control_lock(dc, pipe_ctx, true);
-			if (!pipe_ctx->update_flags.bits.enable)
-				dc->hwss.pipe_control_lock(dc, &dc->current_state->res_ctx.pipe_ctx[i], true);
-			pipe_locked[i] = true;
-		}
 
 	/* OTG blank before disabling all front ends */
 	for (i = 0; i < dc->res_pool->pipe_count; i++)
@@ -1614,17 +1609,6 @@ void dcn20_program_front_end_for_ctx(
 				hws->funcs.program_all_writeback_pipes_in_tree(dc, pipe->stream, context);
 		}
 	}
-
-	/* Unlock all locked pipes */
-	for (i = 0; i < dc->res_pool->pipe_count; i++)
-		if (pipe_locked[i]) {
-			struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
-
-			if (pipe_ctx->update_flags.bits.tg_changed || pipe_ctx->update_flags.bits.enable)
-				dc->hwss.pipe_control_lock(dc, pipe_ctx, false);
-			if (!pipe_ctx->update_flags.bits.enable)
-				dc->hwss.pipe_control_lock(dc, &dc->current_state->res_ctx.pipe_ctx[i], false);
-		}
 }
 
 void dcn20_post_unlock_program_front_end(
@@ -1664,7 +1648,6 @@ void dcn20_post_unlock_program_front_end(
 		dc->res_pool->hubbub->funcs->apply_DEDCN21_147_wa(dc->res_pool->hubbub);
 }
 
-
 void dcn20_prepare_bandwidth(
 		struct dc *dc,
 		struct dc_state *context)

commit bbf5f6c3f83bedd71006473849138a446ad4d9a3
Author: Anthony Koo <Anthony.Koo@amd.com>
Date:   Tue Jan 14 16:23:31 2020 -0500

    drm/amd/display: Split program front end part that occur outside lock
    
    [Why]
    Eventually want to lock at a higher level in stack.
    To do this, we need to be able to isolate the parts that need to be done
    after pipe unlock.
    
    [How]
    Split out programming that is done post unlock.
    
    Signed-off-by: Anthony Koo <Anthony.Koo@amd.com>
    Reviewed-by: Aric Cyr <Aric.Cyr@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index a444fed94184..f36c4d1b7c30 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1551,7 +1551,6 @@ void dcn20_program_front_end_for_ctx(
 		struct dc *dc,
 		struct dc_state *context)
 {
-	const unsigned int TIMEOUT_FOR_PIPE_ENABLE_MS = 100;
 	int i;
 	struct dce_hwseq *hws = dc->hwseq;
 	bool pipe_locked[MAX_PIPES] = {false};
@@ -1626,6 +1625,16 @@ void dcn20_program_front_end_for_ctx(
 			if (!pipe_ctx->update_flags.bits.enable)
 				dc->hwss.pipe_control_lock(dc, &dc->current_state->res_ctx.pipe_ctx[i], false);
 		}
+}
+
+void dcn20_post_unlock_program_front_end(
+		struct dc *dc,
+		struct dc_state *context)
+{
+	int i;
+	const unsigned int TIMEOUT_FOR_PIPE_ENABLE_MS = 100;
+
+	DC_LOGGER_INIT(dc->ctx->logger);
 
 	for (i = 0; i < dc->res_pool->pipe_count; i++)
 		if (context->res_ctx.pipe_ctx[i].update_flags.bits.disable)

commit 0b464c857cc0e143f58938a1f506ab159837bcb3
Author: Sung Lee <sung.lee@amd.com>
Date:   Wed Jan 15 11:55:06 2020 -0500

    drm/amd/display: Do not set optimized_require to false after plane disable
    
    [WHY]
    The optimized_require flag is needed to set watermarks and clocks lower
    in certain conditions. This flag is set to true and then set to false
    while programming front end in dcn20.
    
    [HOW]
    Do not set the flag to false while disabling plane.
    
    Signed-off-by: Sung Lee <sung.lee@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index cfbbaffa8654..a444fed94184 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -572,7 +572,6 @@ void dcn20_plane_atomic_disable(struct dc *dc, struct pipe_ctx *pipe_ctx)
 	dpp->funcs->dpp_dppclk_control(dpp, false, false);
 
 	hubp->power_gated = true;
-	dc->optimized_required = false; /* We're powering off, no need to optimize */
 
 	hws->funcs.plane_atomic_power_down(dc,
 			pipe_ctx->plane_res.dpp,

commit 31635887cb8d899584484620b597e401b2350a79
Author: Wenjing Liu <Wenjing.Liu@amd.com>
Date:   Mon Dec 23 16:05:05 2019 -0500

    drm/amd/display: skip opp blank or unblank if test pattern enabled
    
    [why]
    DPG is used to generate both blank and test automation test pattern.
    When test automation is running the requested test pattern can be
    overriden by the blank or unblank call because it is using the same
    hardware.
    
    [how]
    When test pattern is requested, skip blank or unblank.
    
    Signed-off-by: Wenjing Liu <Wenjing.Liu@amd.com>
    Reviewed-by: Nikola Cornij <Nikola.Cornij@amd.com>
    Acked-by: Harry Wentland <harry.wentland@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index f07899e270f5..cfbbaffa8654 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -945,6 +945,9 @@ void dcn20_blank_pixel_data(
 	int width = stream->timing.h_addressable + stream->timing.h_border_left + stream->timing.h_border_right;
 	int height = stream->timing.v_addressable + stream->timing.v_border_bottom + stream->timing.v_border_top;
 
+	if (stream->link->test_pattern_enabled)
+		return;
+
 	/* get opp dpg blank color */
 	color_space_to_black_color(dc, color_space, &black_color);
 

commit 38259bacd727a2a9e0c767bc6bc50ebb61501023
Author: Martin Tsai <martin.tsai@amd.com>
Date:   Thu Dec 26 16:19:47 2019 +0800

    drm/amd/display: Use mdelay to avoid context switch
    
    [why]
    The rapid msleep operation causes the white line garbage when
    DAL check flip pending status in SetVidPnSourceVisibility.
    To execute this msleep will induce context switch, and longer
    delay could cause worse garbage situation.
    
    [how]
    To replace msleep with mdelay.
    
    Signed-off-by: Martin Tsai <martin.tsai@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Harry Wentland <harry.wentland@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 89920924a154..f07899e270f5 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1642,9 +1642,9 @@ void dcn20_program_front_end_for_ctx(
 			struct hubp *hubp = pipe->plane_res.hubp;
 			int j = 0;
 
-			for (j = 0; j < TIMEOUT_FOR_PIPE_ENABLE_MS
+			for (j = 0; j < TIMEOUT_FOR_PIPE_ENABLE_MS*1000
 					&& hubp->funcs->hubp_is_flip_pending(hubp); j++)
-				msleep(1);
+				mdelay(1);
 		}
 	}
 

commit 5b5abe9526073ccbf3032d27b5864520829cdd9c
Author: Anthony Koo <Anthony.Koo@amd.com>
Date:   Mon Dec 9 17:26:34 2019 -0500

    drm/amd/display: make PSR static screen entry within 30 ms
    
    [Why]
    With different refresh rate panels, the PSR entry/exit time is
    different since it is dependent on 2 frame entry time today
    
    [How]
    Make static screen num frame entry time to be calculated
    such that entry time is within 30 ms instead of fixed num
    frames.
    
    Signed-off-by: Anthony Koo <Anthony.Koo@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Aric Cyr <Aric.Cyr@amd.com>
    Acked-by: Harry Wentland <harry.wentland@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 5b9cbedaa0de..89920924a154 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -686,9 +686,13 @@ enum dc_status dcn20_enable_stream_timing(
 	// DRR should set trigger event to monitor surface update event
 	if (stream->adjust.v_total_min != 0 && stream->adjust.v_total_max != 0)
 		event_triggers = 0x80;
+	/* Event triggers and num frames initialized for DRR, but can be
+	 * later updated for PSR use. Note DRR trigger events are generated
+	 * regardless of whether num frames met.
+	 */
 	if (pipe_ctx->stream_res.tg->funcs->set_static_screen_control)
 		pipe_ctx->stream_res.tg->funcs->set_static_screen_control(
-				pipe_ctx->stream_res.tg, event_triggers);
+				pipe_ctx->stream_res.tg, event_triggers, 2);
 
 	/* TODO program crtc source select for non-virtual signal*/
 	/* TODO program FMT */

commit 0bb803699a7b632874d8b655f2225c6bd0d53116
Author: zhengbin <zhengbin13@huawei.com>
Date:   Tue Dec 24 11:27:38 2019 +0800

    drm/amd/display: use true, false for bool variable in dcn20_hwseq.c
    
    Fixes coccicheck warning:
    
    drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c:186:6-14: WARNING: Assignment of 0/1 to bool variable
    drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c:189:2-10: WARNING: Assignment of 0/1 to bool variable
    
    Reported-by: Hulk Robot <hulkci@huawei.com>
    Signed-off-by: zhengbin <zhengbin13@huawei.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index aa00fbe49c6e..5b9cbedaa0de 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -183,10 +183,10 @@ void dcn20_enable_power_gating_plane(
 	struct dce_hwseq *hws,
 	bool enable)
 {
-	bool force_on = 1; /* disable power gating */
+	bool force_on = true; /* disable power gating */
 
 	if (enable)
-		force_on = 0;
+		force_on = false;
 
 	/* DCHUBP0/1/2/3/4/5 */
 	REG_UPDATE(DOMAIN0_PG_CONFIG, DOMAIN0_POWER_FORCEON, force_on);

commit 1380c1bf5b9c31baf820ab545bbabf6b39bfdc0d
Author: Noah Abradjian <noah.abradjian@amd.com>
Date:   Fri Nov 29 13:48:36 2019 -0500

    drm/amd/display: Remove reliance on pipe indexing
    
    [Why]
    In certain instances, there was a reliance on pipe indexing being accurate. However, this
    assumption fails with harvesting of pipes 1 or 2, which can occur in production B6 parts.
    HW hang would occur as a result.
    
    [How]
    Use hubp index for mpcc, and do mpc_init for all theoretical pipes (including disabled ones).
    
    Signed-off-by: Noah Abradjian <noah.abradjian@amd.com>
    Reviewed-by: Yongqiang Sun <yongqiang.sun@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 3706299906e4..aa00fbe49c6e 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1356,7 +1356,7 @@ static void dcn20_update_dchubp_dpp(
 			|| plane_state->update_flags.bits.global_alpha_change
 			|| plane_state->update_flags.bits.per_pixel_alpha_change) {
 		// MPCC inst is equal to pipe index in practice
-		int mpcc_inst = pipe_ctx->pipe_idx;
+		int mpcc_inst = hubp->inst;
 		int opp_inst;
 		int opp_count = dc->res_pool->pipe_count;
 

commit efca090560815fdda03f5403e3f9cae2c8eca301
Author: Paul Hsieh <paul.hsieh@amd.com>
Date:   Thu Nov 28 10:44:39 2019 +0800

    drm/amd/display: check link status before disable stream
    
    [Why]
    1. Set second screen only then unplug external monitor
    2. Enter to S4 then plug in external monitor
    3. Resume from S4, eDP will not turn off when OS set
       second screen only
    Sometimes OS will not set eDP power up cause eDP dpms_off
    keep true then driver skipp disable stream
    
    [How]
    When drvier try to disable stream, add link status condition
    
    Signed-off-by: Paul Hsieh <paul.hsieh@amd.com>
    Reviewed-by: Anthony Koo <Anthony.Koo@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index fb667546db09..3706299906e4 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -2002,6 +2002,7 @@ static void dcn20_reset_back_end_for_pipe(
 		struct dc_state *context)
 {
 	int i;
+	struct dc_link *link;
 	DC_LOGGER_INIT(dc->ctx->logger);
 	if (pipe_ctx->stream_res.stream_enc == NULL) {
 		pipe_ctx->stream = NULL;
@@ -2009,8 +2010,14 @@ static void dcn20_reset_back_end_for_pipe(
 	}
 
 	if (!IS_FPGA_MAXIMUS_DC(dc->ctx->dce_environment)) {
-		/* DPMS may already disable */
-		if (!pipe_ctx->stream->dpms_off)
+		link = pipe_ctx->stream->link;
+		/* DPMS may already disable or */
+		/* dpms_off status is incorrect due to fastboot
+		 * feature. When system resume from S4 with second
+		 * screen only, the dpms_off would be true but
+		 * VBIOS lit up eDP, so check link status too.
+		 */
+		if (!pipe_ctx->stream->dpms_off || link->link_status.link_active)
 			core_link_disable_stream(pipe_ctx);
 		else if (pipe_ctx->stream_res.audio)
 			dc->hwss.disable_audio_stream(pipe_ctx);

commit 6a652f6d127dac1c67c413c3309258c874535dd1
Author: Charlene Liu <charlene.liu@amd.com>
Date:   Wed Nov 20 21:23:47 2019 -0500

    drm/amd/display: Add warmup escape call support
    
    Add warmup escape support, for diags, in a way that is possible to
    choose a new or an existing sequence. For achieving this goal, this
    commit adds separated MCIF buffer as VCN request.
    
    Signed-off-by: Charlene Liu <charlene.liu@amd.com>
    Reviewed-by: Chris Park <Chris.Park@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index e1e274018049..fb667546db09 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1740,7 +1740,6 @@ bool dcn20_update_bandwidth(
 
 void dcn20_enable_writeback(
 		struct dc *dc,
-		const struct dc_stream_status *stream_status,
 		struct dc_writeback_info *wb_info,
 		struct dc_state *context)
 {
@@ -1754,8 +1753,7 @@ void dcn20_enable_writeback(
 	mcif_wb = dc->res_pool->mcif_wb[wb_info->dwb_pipe_inst];
 
 	/* set the OPTC source mux */
-	ASSERT(stream_status->primary_otg_inst < MAX_PIPES);
-	optc = dc->res_pool->timing_generators[stream_status->primary_otg_inst];
+	optc = dc->res_pool->timing_generators[dwb->otg_inst];
 	optc->funcs->set_dwb_source(optc, wb_info->dwb_pipe_inst);
 	/* set MCIF_WB buffer and arbitration configuration */
 	mcif_wb->funcs->config_mcif_buf(mcif_wb, &wb_info->mcif_buf_params, wb_info->dwb_params.dest_height);

commit 74cc5f02eb67c1a725f6a11407990836f6f5ddd2
Author: Aric Cyr <aric.cyr@amd.com>
Date:   Sat Nov 23 17:15:51 2019 -0500

    drm/amd/display: Remove integer scaling code from DC and fix cursor
    
    [Why]
    Scaling better handled by upper layers before pipe splitting.
    
    [How]
    Remove DC code for integer scaling and force cursor update if
    viewport or scaling changes occur to prevent underflow from
    invalid cursor position.
    
    Signed-off-by: Aric Cyr <aric.cyr@amd.com>
    Reviewed-by: Aric Cyr <Aric.Cyr@amd.com>
    Acked-by: Anthony Koo <Anthony.Koo@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 8d779062a4e8..e1e274018049 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1394,7 +1394,8 @@ static void dcn20_update_dchubp_dpp(
 	}
 
 	/* Any updates are handled in dc interface, just need to apply existing for plane enable */
-	if ((pipe_ctx->update_flags.bits.enable || pipe_ctx->update_flags.bits.opp_changed)
+	if ((pipe_ctx->update_flags.bits.enable || pipe_ctx->update_flags.bits.opp_changed ||
+			pipe_ctx->update_flags.bits.scaler || pipe_ctx->update_flags.bits.viewport)
 			&& pipe_ctx->stream->cursor_attributes.address.quad_part != 0) {
 		dc->hwss.set_cursor_position(pipe_ctx);
 		dc->hwss.set_cursor_attribute(pipe_ctx);

commit cf27a6d15d950ed1beb3926469c9eaa6907bbf88
Author: Eric Yang <Eric.Yang2@amd.com>
Date:   Mon Nov 18 15:41:19 2019 -0500

    drm/amd/display: update chroma viewport wa
    
    [Why]
    Need previously implemented chroma vp wa to work for rotation cases.
    
    [How]
    Implement rotation specific wa.
    
    Signed-off-by: Eric Yang <Eric.Yang2@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index cafbd08f1cf2..8d779062a4e8 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1305,6 +1305,7 @@ static void dcn20_update_dchubp_dpp(
 	struct hubp *hubp = pipe_ctx->plane_res.hubp;
 	struct dpp *dpp = pipe_ctx->plane_res.dpp;
 	struct dc_plane_state *plane_state = pipe_ctx->plane_state;
+	bool viewport_changed = false;
 
 	if (pipe_ctx->update_flags.bits.dppclk)
 		dpp->funcs->dpp_dppclk_control(dpp, false, true);
@@ -1383,12 +1384,14 @@ static void dcn20_update_dchubp_dpp(
 
 	if (pipe_ctx->update_flags.bits.viewport ||
 			(context == dc->current_state && plane_state->update_flags.bits.scaling_change) ||
-			(context == dc->current_state && pipe_ctx->stream->update_flags.bits.scaling))
+			(context == dc->current_state && pipe_ctx->stream->update_flags.bits.scaling)) {
+
 		hubp->funcs->mem_program_viewport(
 			hubp,
 			&pipe_ctx->plane_res.scl_data.viewport,
-			&pipe_ctx->plane_res.scl_data.viewport_c,
-			plane_state->rotation);
+			&pipe_ctx->plane_res.scl_data.viewport_c);
+		viewport_changed = true;
+	}
 
 	/* Any updates are handled in dc interface, just need to apply existing for plane enable */
 	if ((pipe_ctx->update_flags.bits.enable || pipe_ctx->update_flags.bits.opp_changed)
@@ -1441,9 +1444,14 @@ static void dcn20_update_dchubp_dpp(
 		hubp->power_gated = false;
 	}
 
+	if (hubp->funcs->apply_PLAT_54186_wa && viewport_changed)
+		hubp->funcs->apply_PLAT_54186_wa(hubp, &plane_state->address);
+
 	if (pipe_ctx->update_flags.bits.enable || plane_state->update_flags.bits.addr_update)
 		hws->funcs.update_plane_addr(dc, pipe_ctx);
 
+
+
 	if (pipe_ctx->update_flags.bits.enable)
 		hubp->funcs->set_blank(hubp, false);
 }

commit 0120e8b8451c6a0fdc564ba9b30d75fd6995bbc4
Author: Noah Abradjian <noah.abradjian@amd.com>
Date:   Fri Nov 22 11:47:52 2019 -0500

    drm/amd/display: Use pipe_count for num of opps
    
    [Why]
    There is one opp per pipe. For certain RN parts, the fourth pipe is disabled, so there is no opp for it.
    res_cap->num_opp is hardcoded to 4, so if we use that to iterate over opps we will crash.
    
    [How]
    Use the pipe_count value instead, which is not hardcoded and so will have the correct number.
    
    Signed-off-by: Noah Abradjian <noah.abradjian@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 32878a65bdd7..cafbd08f1cf2 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1357,7 +1357,7 @@ static void dcn20_update_dchubp_dpp(
 		// MPCC inst is equal to pipe index in practice
 		int mpcc_inst = pipe_ctx->pipe_idx;
 		int opp_inst;
-		int opp_count = dc->res_pool->res_cap->num_opp;
+		int opp_count = dc->res_pool->pipe_count;
 
 		for (opp_inst = 0; opp_inst < opp_count; opp_inst++) {
 			if (dc->res_pool->opps[opp_inst]->mpcc_disconnect_pending[mpcc_inst]) {

commit e66164105d2f4779387b80d726680ec9875b970f
Author: Reza Amini <Reza.Amini@amd.com>
Date:   Fri Nov 15 17:39:12 2019 -0500

    drm/amd/display: Implement DePQ for DCN2
    
    [Why]
    Need support for more color management in 10bit
    surface.
    
    [How]
    Provide support for DePQ for 10bit surface
    
    Signed-off-by: Reza Amini <Reza.Amini@amd.com>
    Reviewed-by: Krunoslav Kovac <Krunoslav.Kovac@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 6a0d280bafba..32878a65bdd7 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -878,6 +878,11 @@ bool dcn20_set_input_transfer_func(struct dc *dc,
 					IPP_DEGAMMA_MODE_BYPASS);
 			break;
 		case TRANSFER_FUNCTION_PQ:
+			dpp_base->funcs->dpp_set_degamma(dpp_base, IPP_DEGAMMA_MODE_USER_PWL);
+			cm_helper_translate_curve_to_degamma_hw_format(tf, &dpp_base->degamma_params);
+			dpp_base->funcs->dpp_program_degamma_pwl(dpp_base, &dpp_base->degamma_params);
+			result = true;
+			break;
 		default:
 			result = false;
 			break;

commit 8b0fbb368c96df747d958bfb0842da9842e6d0a3
Author: Noah Abradjian <noah.abradjian@amd.com>
Date:   Wed Nov 13 16:56:06 2019 -0500

    drm/amd/display: Modify logic for when to wait for mpcc idle
    
    [Why]
    I was advised that we may need to check for mpcc idle in more cases
    than just when opp_changed is true. Also, mpcc_inst is equal to
    pipe_idx, so remove for loop.
    
    [How]
    Remove opp_changed flag check and mpcc_inst loop.
    
    Signed-off-by: Noah Abradjian <noah.abradjian@amd.com>
    Reviewed-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 3b8b9944d972..6a0d280bafba 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1349,16 +1349,16 @@ static void dcn20_update_dchubp_dpp(
 	if (pipe_ctx->update_flags.bits.mpcc
 			|| plane_state->update_flags.bits.global_alpha_change
 			|| plane_state->update_flags.bits.per_pixel_alpha_change) {
-		/* Need mpcc to be idle if changing opp */
-		if (pipe_ctx->update_flags.bits.opp_changed) {
-			struct pipe_ctx *old_pipe_ctx = &dc->current_state->res_ctx.pipe_ctx[pipe_ctx->pipe_idx];
-			int mpcc_inst;
-
-			for (mpcc_inst = 0; mpcc_inst < MAX_PIPES; mpcc_inst++) {
-				if (!old_pipe_ctx->stream_res.opp->mpcc_disconnect_pending[mpcc_inst])
-					continue;
+		// MPCC inst is equal to pipe index in practice
+		int mpcc_inst = pipe_ctx->pipe_idx;
+		int opp_inst;
+		int opp_count = dc->res_pool->res_cap->num_opp;
+
+		for (opp_inst = 0; opp_inst < opp_count; opp_inst++) {
+			if (dc->res_pool->opps[opp_inst]->mpcc_disconnect_pending[mpcc_inst]) {
 				dc->res_pool->mpc->funcs->wait_for_idle(dc->res_pool->mpc, mpcc_inst);
-				old_pipe_ctx->stream_res.opp->mpcc_disconnect_pending[mpcc_inst] = false;
+				dc->res_pool->opps[opp_inst]->mpcc_disconnect_pending[mpcc_inst] = false;
+				break;
 			}
 		}
 		hws->funcs.update_mpcc(dc, pipe_ctx);

commit 9a35b016b99fb39891102c17e65f0b63d1d90d94
Author: Noah Abradjian <noah.abradjian@amd.com>
Date:   Wed Nov 13 13:55:53 2019 -0500

    drm/amd/display: Remove flag check in mpcc update
    
    [Why]
    MPCC programming was being missed during certain split pipe enables due
    to full_update flag not being true. This caused a momentary flash on
    half the screen. After discussion, determined we should not have that
    flag check within update_mpcc, as it should always perform full
    programming when called.
    
    [How]
    Remove flag check. We call update_blending within insert_plane, so we
    do not need to replace its call from the if block.
    
    Signed-off-by: Noah Abradjian <noah.abradjian@amd.com>
    Reviewed-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 392542f84ca2..3b8b9944d972 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -2158,12 +2158,6 @@ void dcn20_update_mpcc(struct dc *dc, struct pipe_ctx *pipe_ctx)
 	 */
 	mpcc_id = hubp->inst;
 
-	/* If there is no full update, don't need to touch MPC tree*/
-	if (!pipe_ctx->plane_state->update_flags.bits.full_update) {
-		mpc->funcs->update_blending(mpc, &blnd_cfg, mpcc_id);
-		return;
-	}
-
 	/* check if this MPCC is already being used */
 	new_mpcc = mpc->funcs->get_mpcc_for_dpp(mpc_tree_params, mpcc_id);
 	/* remove MPCC if being used */

commit 1ba2a48305715f5832fac023ddc0d4ceba7a8491
Author: Michael Strauss <michael.strauss@amd.com>
Date:   Sun Nov 10 15:22:15 2019 -0500

    drm/amd/display: Disable chroma viewport w/a when rotated 180 degrees
    
    [WHY]
    Previous Renoir chroma viewport workaround fixed an MPO flicker by
    increasing the chroma viewport size. However, when the MPO plane is
    rotated 180 degrees, the viewport is read in reverse. Since the workaround
    increases viewport size, when reading in reverse it causes a vertical
    chroma offset.
    
    [HOW]
    Pass rotation value to viewport set functions
    Temporarily disable the chroma viewport w/a when hubp is rotated 180 degrees
    
    Signed-off-by: Michael Strauss <michael.strauss@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 619af3b3029d..392542f84ca2 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1382,7 +1382,8 @@ static void dcn20_update_dchubp_dpp(
 		hubp->funcs->mem_program_viewport(
 			hubp,
 			&pipe_ctx->plane_res.scl_data.viewport,
-			&pipe_ctx->plane_res.scl_data.viewport_c);
+			&pipe_ctx->plane_res.scl_data.viewport_c,
+			plane_state->rotation);
 
 	/* Any updates are handled in dc interface, just need to apply existing for plane enable */
 	if ((pipe_ctx->update_flags.bits.enable || pipe_ctx->update_flags.bits.opp_changed)

commit f42ea55be1114768e36c4e8dff4400ca811309cf
Author: Anthony Koo <Anthony.Koo@amd.com>
Date:   Tue Nov 5 13:17:30 2019 -0500

    drm/amd/display: add separate of private hwss functions
    
    [Why]
    Some function pointers in the hwss function pointer table are
    meant to be hw sequencer entry points to be called from dc.
    
    However some of those function pointers are not meant to
    be entry points, but instead used as a code reuse/inheritance
    tool called directly by other hwss functions, not by dc.
    
    Therefore, we want a more clear separation of which functions
    we determine to be interface functions vs the functions we
    use within hwss.
    
    [How]
    DC interface functions will be stored in:
        struct hw_sequencer_funcs
    Functions used within HWSS will be stored in:
        struct hwseq_private_funcs
    
    Signed-off-by: Anthony Koo <Anthony.Koo@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index d5c18fb4436a..619af3b3029d 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -272,6 +272,7 @@ void dcn20_init_blank(
 		struct dc *dc,
 		struct timing_generator *tg)
 {
+	struct dce_hwseq *hws = dc->hwseq;
 	enum dc_color_space color_space;
 	struct tg_color black_color = {0};
 	struct output_pixel_processor *opp = NULL;
@@ -319,7 +320,7 @@ void dcn20_init_blank(
 				otg_active_height);
 	}
 
-	dc->hwss.wait_for_blank_complete(opp);
+	hws->funcs.wait_for_blank_complete(opp);
 }
 
 void dcn20_dsc_pg_control(
@@ -552,6 +553,7 @@ void dcn20_hubp_pg_control(
  */
 void dcn20_plane_atomic_disable(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
+	struct dce_hwseq *hws = dc->hwseq;
 	struct hubp *hubp = pipe_ctx->plane_res.hubp;
 	struct dpp *dpp = pipe_ctx->plane_res.dpp;
 
@@ -572,7 +574,7 @@ void dcn20_plane_atomic_disable(struct dc *dc, struct pipe_ctx *pipe_ctx)
 	hubp->power_gated = true;
 	dc->optimized_required = false; /* We're powering off, no need to optimize */
 
-	dc->hwss.plane_atomic_power_down(dc,
+	hws->funcs.plane_atomic_power_down(dc,
 			pipe_ctx->plane_res.dpp,
 			pipe_ctx->plane_res.hubp);
 
@@ -603,6 +605,7 @@ enum dc_status dcn20_enable_stream_timing(
 		struct dc_state *context,
 		struct dc *dc)
 {
+	struct dce_hwseq *hws = dc->hwseq;
 	struct dc_stream_state *stream = pipe_ctx->stream;
 	struct drr_params params = {0};
 	unsigned int event_triggers = 0;
@@ -662,7 +665,7 @@ enum dc_status dcn20_enable_stream_timing(
 			pipe_ctx->stream_res.opp,
 			true);
 
-	dc->hwss.blank_pixel_data(dc, pipe_ctx, true);
+	hws->funcs.blank_pixel_data(dc, pipe_ctx, true);
 
 	/* VTG is  within DCHUB command block. DCFCLK is always on */
 	if (false == pipe_ctx->stream_res.tg->funcs->enable_crtc(pipe_ctx->stream_res.tg)) {
@@ -670,7 +673,7 @@ enum dc_status dcn20_enable_stream_timing(
 		return DC_ERROR_UNEXPECTED;
 	}
 
-	dc->hwss.wait_for_blank_complete(pipe_ctx->stream_res.opp);
+	hws->funcs.wait_for_blank_complete(pipe_ctx->stream_res.opp);
 
 	params.vertical_total_min = stream->adjust.v_total_min;
 	params.vertical_total_max = stream->adjust.v_total_max;
@@ -820,6 +823,7 @@ bool dcn20_set_input_transfer_func(struct dc *dc,
 				struct pipe_ctx *pipe_ctx,
 				const struct dc_plane_state *plane_state)
 {
+	struct dce_hwseq *hws = dc->hwseq;
 	struct dpp *dpp_base = pipe_ctx->plane_res.dpp;
 	const struct dc_transfer_func *tf = NULL;
 	bool result = true;
@@ -828,8 +832,8 @@ bool dcn20_set_input_transfer_func(struct dc *dc,
 	if (dpp_base == NULL || plane_state == NULL)
 		return false;
 
-	dc->hwss.set_shaper_3dlut(pipe_ctx, plane_state);
-	dc->hwss.set_blend_lut(pipe_ctx, plane_state);
+	hws->funcs.set_shaper_3dlut(pipe_ctx, plane_state);
+	hws->funcs.set_blend_lut(pipe_ctx, plane_state);
 
 	if (plane_state->in_transfer_func)
 		tf = plane_state->in_transfer_func;
@@ -1292,6 +1296,7 @@ static void dcn20_update_dchubp_dpp(
 	struct pipe_ctx *pipe_ctx,
 	struct dc_state *context)
 {
+	struct dce_hwseq *hws = dc->hwseq;
 	struct hubp *hubp = pipe_ctx->plane_res.hubp;
 	struct dpp *dpp = pipe_ctx->plane_res.dpp;
 	struct dc_plane_state *plane_state = pipe_ctx->plane_state;
@@ -1356,7 +1361,7 @@ static void dcn20_update_dchubp_dpp(
 				old_pipe_ctx->stream_res.opp->mpcc_disconnect_pending[mpcc_inst] = false;
 			}
 		}
-		dc->hwss.update_mpcc(dc, pipe_ctx);
+		hws->funcs.update_mpcc(dc, pipe_ctx);
 	}
 
 	if (pipe_ctx->update_flags.bits.scaler ||
@@ -1431,7 +1436,7 @@ static void dcn20_update_dchubp_dpp(
 	}
 
 	if (pipe_ctx->update_flags.bits.enable || plane_state->update_flags.bits.addr_update)
-		dc->hwss.update_plane_addr(dc, pipe_ctx);
+		hws->funcs.update_plane_addr(dc, pipe_ctx);
 
 	if (pipe_ctx->update_flags.bits.enable)
 		hubp->funcs->set_blank(hubp, false);
@@ -1443,10 +1448,11 @@ static void dcn20_program_pipe(
 		struct pipe_ctx *pipe_ctx,
 		struct dc_state *context)
 {
+	struct dce_hwseq *hws = dc->hwseq;
 	/* Only need to unblank on top pipe */
 	if ((pipe_ctx->update_flags.bits.enable || pipe_ctx->stream->update_flags.bits.abm_level)
 			&& !pipe_ctx->top_pipe && !pipe_ctx->prev_odm_pipe)
-		dc->hwss.blank_pixel_data(dc, pipe_ctx, !pipe_ctx->plane_state->visible);
+		hws->funcs.blank_pixel_data(dc, pipe_ctx, !pipe_ctx->plane_state->visible);
 
 	if (pipe_ctx->update_flags.bits.global_sync) {
 		pipe_ctx->stream_res.tg->funcs->program_global_sync(
@@ -1459,12 +1465,12 @@ static void dcn20_program_pipe(
 		pipe_ctx->stream_res.tg->funcs->set_vtg_params(
 				pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);
 
-		if (dc->hwss.setup_vupdate_interrupt)
-			dc->hwss.setup_vupdate_interrupt(dc, pipe_ctx);
+		if (hws->funcs.setup_vupdate_interrupt)
+			hws->funcs.setup_vupdate_interrupt(dc, pipe_ctx);
 	}
 
 	if (pipe_ctx->update_flags.bits.odm)
-		dc->hwss.update_odm(dc, context, pipe_ctx);
+		hws->funcs.update_odm(dc, context, pipe_ctx);
 
 	if (pipe_ctx->update_flags.bits.enable)
 		dcn20_enable_plane(dc, pipe_ctx, context);
@@ -1474,19 +1480,19 @@ static void dcn20_program_pipe(
 
 	if (pipe_ctx->update_flags.bits.enable
 			|| pipe_ctx->plane_state->update_flags.bits.hdr_mult)
-		dc->hwss.set_hdr_multiplier(pipe_ctx);
+		hws->funcs.set_hdr_multiplier(pipe_ctx);
 
 	if (pipe_ctx->update_flags.bits.enable ||
 			pipe_ctx->plane_state->update_flags.bits.in_transfer_func_change ||
 			pipe_ctx->plane_state->update_flags.bits.gamma_change)
-		dc->hwss.set_input_transfer_func(dc, pipe_ctx, pipe_ctx->plane_state);
+		hws->funcs.set_input_transfer_func(dc, pipe_ctx, pipe_ctx->plane_state);
 
 	/* dcn10_translate_regamma_to_hw_format takes 750us to finish
 	 * only do gamma programming for powering on, internal memcmp to avoid
 	 * updating on slave planes
 	 */
 	if (pipe_ctx->update_flags.bits.enable || pipe_ctx->stream->update_flags.bits.out_tf)
-		dc->hwss.set_output_transfer_func(dc, pipe_ctx, pipe_ctx->stream);
+		hws->funcs.set_output_transfer_func(dc, pipe_ctx, pipe_ctx->stream);
 
 	/* If the pipe has been enabled or has a different opp, we
 	 * should reprogram the fmt. This deals with cases where
@@ -1526,6 +1532,7 @@ void dcn20_program_front_end_for_ctx(
 {
 	const unsigned int TIMEOUT_FOR_PIPE_ENABLE_MS = 100;
 	int i;
+	struct dce_hwseq *hws = dc->hwseq;
 	bool pipe_locked[MAX_PIPES] = {false};
 	DC_LOGGER_INIT(dc->ctx->logger);
 
@@ -1557,13 +1564,13 @@ void dcn20_program_front_end_for_ctx(
 				&& !context->res_ctx.pipe_ctx[i].top_pipe
 				&& !context->res_ctx.pipe_ctx[i].prev_odm_pipe
 				&& context->res_ctx.pipe_ctx[i].stream)
-			dc->hwss.blank_pixel_data(dc, &context->res_ctx.pipe_ctx[i], true);
+			hws->funcs.blank_pixel_data(dc, &context->res_ctx.pipe_ctx[i], true);
 
 	/* Disconnect mpcc */
 	for (i = 0; i < dc->res_pool->pipe_count; i++)
 		if (context->res_ctx.pipe_ctx[i].update_flags.bits.disable
 				|| context->res_ctx.pipe_ctx[i].update_flags.bits.opp_changed) {
-			dc->hwss.plane_atomic_disconnect(dc, &dc->current_state->res_ctx.pipe_ctx[i]);
+			hws->funcs.plane_atomic_disconnect(dc, &dc->current_state->res_ctx.pipe_ctx[i]);
 			DC_LOG_DC("Reset mpcc for pipe %d\n", dc->current_state->res_ctx.pipe_ctx[i].pipe_idx);
 		}
 
@@ -1583,8 +1590,8 @@ void dcn20_program_front_end_for_ctx(
 			pipe = &context->res_ctx.pipe_ctx[i];
 			if (!pipe->prev_odm_pipe && pipe->stream->num_wb_info > 0
 					&& (pipe->update_flags.raw || pipe->plane_state->update_flags.raw || pipe->stream->update_flags.raw)
-					&& dc->hwss.program_all_writeback_pipes_in_tree)
-				dc->hwss.program_all_writeback_pipes_in_tree(dc, pipe->stream, context);
+					&& hws->funcs.program_all_writeback_pipes_in_tree)
+				hws->funcs.program_all_writeback_pipes_in_tree(dc, pipe->stream, context);
 		}
 	}
 
@@ -1669,6 +1676,7 @@ bool dcn20_update_bandwidth(
 		struct dc_state *context)
 {
 	int i;
+	struct dce_hwseq *hws = dc->hwseq;
 
 	/* recalculate DML parameters */
 	if (!dc->res_pool->funcs->validate_bandwidth(dc, context, false))
@@ -1698,10 +1706,10 @@ bool dcn20_update_bandwidth(
 					pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);
 
 			if (pipe_ctx->prev_odm_pipe == NULL)
-				dc->hwss.blank_pixel_data(dc, pipe_ctx, blank);
+				hws->funcs.blank_pixel_data(dc, pipe_ctx, blank);
 
-			if (dc->hwss.setup_vupdate_interrupt)
-				dc->hwss.setup_vupdate_interrupt(dc, pipe_ctx);
+			if (hws->funcs.setup_vupdate_interrupt)
+				hws->funcs.setup_vupdate_interrupt(dc, pipe_ctx);
 		}
 
 		pipe_ctx->plane_res.hubp->funcs->hubp_setup(
@@ -1938,6 +1946,7 @@ void dcn20_unblank_stream(struct pipe_ctx *pipe_ctx,
 	struct encoder_unblank_param params = { { 0 } };
 	struct dc_stream_state *stream = pipe_ctx->stream;
 	struct dc_link *link = stream->link;
+	struct dce_hwseq *hws = link->dc->hwseq;
 	struct pipe_ctx *odm_pipe;
 
 	params.opp_cnt = 1;
@@ -1958,7 +1967,7 @@ void dcn20_unblank_stream(struct pipe_ctx *pipe_ctx,
 	}
 
 	if (link->local_sink && link->local_sink->sink_signal == SIGNAL_TYPE_EDP) {
-		link->dc->hwss.edp_backlight_control(link, true);
+		hws->funcs.edp_backlight_control(link, true);
 	}
 }
 
@@ -2046,6 +2055,7 @@ void dcn20_reset_hw_ctx_wrap(
 		struct dc_state *context)
 {
 	int i;
+	struct dce_hwseq *hws = dc->hwseq;
 
 	/* Reset Back End*/
 	for (i = dc->res_pool->pipe_count - 1; i >= 0 ; i--) {
@@ -2064,8 +2074,8 @@ void dcn20_reset_hw_ctx_wrap(
 			struct clock_source *old_clk = pipe_ctx_old->clock_source;
 
 			dcn20_reset_back_end_for_pipe(dc, pipe_ctx_old, dc->current_state);
-			if (dc->hwss.enable_stream_gating)
-				dc->hwss.enable_stream_gating(dc, pipe_ctx);
+			if (hws->funcs.enable_stream_gating)
+				hws->funcs.enable_stream_gating(dc, pipe_ctx);
 			if (old_clk)
 				old_clk->funcs->cs_power_down(old_clk);
 		}
@@ -2096,6 +2106,7 @@ void dcn20_get_mpctree_visual_confirm_color(
 
 void dcn20_update_mpcc(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
+	struct dce_hwseq *hws = dc->hwseq;
 	struct hubp *hubp = pipe_ctx->plane_res.hubp;
 	struct mpcc_blnd_cfg blnd_cfg = { {0} };
 	bool per_pixel_alpha = pipe_ctx->plane_state->per_pixel_alpha;
@@ -2106,10 +2117,10 @@ void dcn20_update_mpcc(struct dc *dc, struct pipe_ctx *pipe_ctx)
 
 	// input to MPCC is always RGB, by default leave black_color at 0
 	if (dc->debug.visual_confirm == VISUAL_CONFIRM_HDR) {
-		dc->hwss.get_hdr_visual_confirm_color(
+		hws->funcs.get_hdr_visual_confirm_color(
 				pipe_ctx, &blnd_cfg.black_color);
 	} else if (dc->debug.visual_confirm == VISUAL_CONFIRM_SURFACE) {
-		dc->hwss.get_surface_visual_confirm_color(
+		hws->funcs.get_surface_visual_confirm_color(
 				pipe_ctx, &blnd_cfg.black_color);
 	} else if (dc->debug.visual_confirm == VISUAL_CONFIRM_MPCTREE) {
 		dcn20_get_mpctree_visual_confirm_color(
@@ -2265,13 +2276,13 @@ void dcn20_fpga_init_hw(struct dc *dc)
 		res_pool->dccg->funcs->dccg_init(res_pool->dccg);
 
 	//Enable ability to power gate / don't force power on permanently
-	dc->hwss.enable_power_gating_plane(hws, true);
+	hws->funcs.enable_power_gating_plane(hws, true);
 
 	// Specific to FPGA dccg and registers
 	REG_WRITE(RBBMIF_TIMEOUT_DIS, 0xFFFFFFFF);
 	REG_WRITE(RBBMIF_TIMEOUT_DIS_2, 0xFFFFFFFF);
 
-	dc->hwss.dccg_init(hws);
+	hws->funcs.dccg_init(hws);
 
 	REG_UPDATE(DCHUBBUB_GLOBAL_TIMER_CNTL, DCHUBBUB_GLOBAL_TIMER_REFDIV, 2);
 	REG_UPDATE(DCHUBBUB_GLOBAL_TIMER_CNTL, DCHUBBUB_GLOBAL_TIMER_ENABLE, 1);
@@ -2335,7 +2346,7 @@ void dcn20_fpga_init_hw(struct dc *dc)
 		dc->res_pool->opps[i]->mpcc_disconnect_pending[pipe_ctx->plane_res.mpcc_inst] = true;
 		pipe_ctx->stream_res.opp = dc->res_pool->opps[i];
 		/*to do*/
-		dc->hwss.plane_atomic_disconnect(dc, pipe_ctx);
+		hws->funcs.plane_atomic_disconnect(dc, pipe_ctx);
 	}
 
 	/* initialize DWB pointer to MCIF_WB */

commit 0e29be9e0bbbf9cb3d718c5c48382b1420ce0749
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Fri Nov 15 10:02:44 2019 -0500

    drm/amd/display: re-enable wait in pipelock, but add timeout
    
    Removing this causes hangs in some games, so re-add it, but add
    a timeout so we don't hang while switching flip types.
    
    Bug: https://bugzilla.kernel.org/show_bug.cgi?id=205169
    Bug: https://bugs.freedesktop.org/show_bug.cgi?id=112266
    Reviewed-by: Harry Wentland <harry.wentland@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 03e4aafb237b..d5c18fb4436a 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1112,6 +1112,25 @@ void dcn20_pipe_control_lock(
 	if (pipe->plane_state != NULL)
 		flip_immediate = pipe->plane_state->flip_immediate;
 
+	if (flip_immediate && lock) {
+		const int TIMEOUT_FOR_FLIP_PENDING = 100000;
+		int i;
+
+		for (i = 0; i < TIMEOUT_FOR_FLIP_PENDING; ++i) {
+			if (!pipe->plane_res.hubp->funcs->hubp_is_flip_pending(pipe->plane_res.hubp))
+				break;
+			udelay(1);
+		}
+
+		if (pipe->bottom_pipe != NULL) {
+			for (i = 0; i < TIMEOUT_FOR_FLIP_PENDING; ++i) {
+				if (!pipe->bottom_pipe->plane_res.hubp->funcs->hubp_is_flip_pending(pipe->bottom_pipe->plane_res.hubp))
+					break;
+				udelay(1);
+			}
+		}
+	}
+
 	/* In flip immediate and pipe splitting case, we need to use GSL
 	 * for synchronization. Only do setup on locking and on flip type change.
 	 */

commit 78c7738211e027f122ada3f59c2c5e8a83ee3c59
Author: Anthony Koo <Anthony.Koo@amd.com>
Date:   Tue Oct 29 15:05:56 2019 -0400

    drm/amd/display: cleanup of function pointer tables
    
    [Why]
    It is becoming increasingly hard to figure out which
    function is called on the different DCN versions
    
    [How]
    1. Make function pointer table init in its own init.c file
    2. Remove other scenarios in hwseq.c file that need to
    include headers of other DCN versions. (If needed,
    it should have been done via the function pointers)
    
    Signed-off-by: Anthony Koo <Anthony.Koo@amd.com>
    Reviewed-by: Aric Cyr <Aric.Cyr@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 868099fbe8ba..03e4aafb237b 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -25,15 +25,15 @@
 #include <linux/delay.h>
 
 #include "dm_services.h"
+#include "basics/dc_common.h"
 #include "dm_helpers.h"
 #include "core_types.h"
 #include "resource.h"
-#include "dcn20/dcn20_resource.h"
-#include "dce110/dce110_hw_sequencer.h"
-#include "dcn10/dcn10_hw_sequencer.h"
+#include "dcn20_resource.h"
 #include "dcn20_hwseq.h"
 #include "dce/dce_hwseq.h"
-#include "dcn20/dcn20_dsc.h"
+#include "dcn20_dsc.h"
+#include "dcn20_optc.h"
 #include "abm.h"
 #include "clk_mgr.h"
 #include "dmcu.h"
@@ -43,10 +43,9 @@
 #include "ipp.h"
 #include "mpc.h"
 #include "mcif_wb.h"
+#include "dchubbub.h"
 #include "reg_helper.h"
 #include "dcn10/dcn10_cm_common.h"
-#include "dcn10/dcn10_hubbub.h"
-#include "dcn10/dcn10_optc.h"
 #include "dc_link_dp.h"
 #include "vm_helper.h"
 #include "dccg.h"
@@ -62,7 +61,125 @@
 #define FN(reg_name, field_name) \
 	hws->shifts->field_name, hws->masks->field_name
 
-static void dcn20_enable_power_gating_plane(
+static int find_free_gsl_group(const struct dc *dc)
+{
+	if (dc->res_pool->gsl_groups.gsl_0 == 0)
+		return 1;
+	if (dc->res_pool->gsl_groups.gsl_1 == 0)
+		return 2;
+	if (dc->res_pool->gsl_groups.gsl_2 == 0)
+		return 3;
+
+	return 0;
+}
+
+/* NOTE: This is not a generic setup_gsl function (hence the suffix as_lock)
+ * This is only used to lock pipes in pipe splitting case with immediate flip
+ * Ordinary MPC/OTG locks suppress VUPDATE which doesn't help with immediate,
+ * so we get tearing with freesync since we cannot flip multiple pipes
+ * atomically.
+ * We use GSL for this:
+ * - immediate flip: find first available GSL group if not already assigned
+ *                   program gsl with that group, set current OTG as master
+ *                   and always us 0x4 = AND of flip_ready from all pipes
+ * - vsync flip: disable GSL if used
+ *
+ * Groups in stream_res are stored as +1 from HW registers, i.e.
+ * gsl_0 <=> pipe_ctx->stream_res.gsl_group == 1
+ * Using a magic value like -1 would require tracking all inits/resets
+ */
+static void dcn20_setup_gsl_group_as_lock(
+		const struct dc *dc,
+		struct pipe_ctx *pipe_ctx,
+		bool enable)
+{
+	struct gsl_params gsl;
+	int group_idx;
+
+	memset(&gsl, 0, sizeof(struct gsl_params));
+
+	if (enable) {
+		/* return if group already assigned since GSL was set up
+		 * for vsync flip, we would unassign so it can't be "left over"
+		 */
+		if (pipe_ctx->stream_res.gsl_group > 0)
+			return;
+
+		group_idx = find_free_gsl_group(dc);
+		ASSERT(group_idx != 0);
+		pipe_ctx->stream_res.gsl_group = group_idx;
+
+		/* set gsl group reg field and mark resource used */
+		switch (group_idx) {
+		case 1:
+			gsl.gsl0_en = 1;
+			dc->res_pool->gsl_groups.gsl_0 = 1;
+			break;
+		case 2:
+			gsl.gsl1_en = 1;
+			dc->res_pool->gsl_groups.gsl_1 = 1;
+			break;
+		case 3:
+			gsl.gsl2_en = 1;
+			dc->res_pool->gsl_groups.gsl_2 = 1;
+			break;
+		default:
+			BREAK_TO_DEBUGGER();
+			return; // invalid case
+		}
+		gsl.gsl_master_en = 1;
+	} else {
+		group_idx = pipe_ctx->stream_res.gsl_group;
+		if (group_idx == 0)
+			return; // if not in use, just return
+
+		pipe_ctx->stream_res.gsl_group = 0;
+
+		/* unset gsl group reg field and mark resource free */
+		switch (group_idx) {
+		case 1:
+			gsl.gsl0_en = 0;
+			dc->res_pool->gsl_groups.gsl_0 = 0;
+			break;
+		case 2:
+			gsl.gsl1_en = 0;
+			dc->res_pool->gsl_groups.gsl_1 = 0;
+			break;
+		case 3:
+			gsl.gsl2_en = 0;
+			dc->res_pool->gsl_groups.gsl_2 = 0;
+			break;
+		default:
+			BREAK_TO_DEBUGGER();
+			return;
+		}
+		gsl.gsl_master_en = 0;
+	}
+
+	/* at this point we want to program whether it's to enable or disable */
+	if (pipe_ctx->stream_res.tg->funcs->set_gsl != NULL &&
+		pipe_ctx->stream_res.tg->funcs->set_gsl_source_select != NULL) {
+		pipe_ctx->stream_res.tg->funcs->set_gsl(
+			pipe_ctx->stream_res.tg,
+			&gsl);
+
+		pipe_ctx->stream_res.tg->funcs->set_gsl_source_select(
+			pipe_ctx->stream_res.tg, group_idx,	enable ? 4 : 0);
+	} else
+		BREAK_TO_DEBUGGER();
+}
+
+void dcn20_set_flip_control_gsl(
+		struct pipe_ctx *pipe_ctx,
+		bool flip_immediate)
+{
+	if (pipe_ctx && pipe_ctx->plane_res.hubp->funcs->hubp_set_flip_control_surface_gsl)
+		pipe_ctx->plane_res.hubp->funcs->hubp_set_flip_control_surface_gsl(
+				pipe_ctx->plane_res.hubp, flip_immediate);
+
+}
+
+void dcn20_enable_power_gating_plane(
 	struct dce_hwseq *hws,
 	bool enable)
 {
@@ -126,44 +243,6 @@ void dcn20_dccg_init(struct dce_hwseq *hws)
 	/* This value is dependent on the hardware pipeline delay so set once per SOC */
 	REG_WRITE(DISPCLK_FREQ_CHANGE_CNTL, 0x801003c);
 }
-void dcn20_display_init(struct dc *dc)
-{
-	struct dce_hwseq *hws = dc->hwseq;
-
-	/* RBBMIF
-	 * disable RBBMIF timeout detection for all clients
-	 * Ensure RBBMIF does not drop register accesses due to the per-client timeout
-	 */
-	REG_WRITE(RBBMIF_TIMEOUT_DIS, 0xFFFFFFFF);
-	REG_WRITE(RBBMIF_TIMEOUT_DIS_2, 0xFFFFFFFF);
-
-	/* DCCG */
-	dcn20_dccg_init(hws);
-
-	REG_UPDATE(DC_MEM_GLOBAL_PWR_REQ_CNTL, DC_MEM_GLOBAL_PWR_REQ_DIS, 0);
-
-	/* DCHUB/MMHUBBUB
-	 * set global timer refclk divider
-	 * 100Mhz refclk -> 2
-	 * 27Mhz refclk ->  1
-	 * 48Mhz refclk ->  1
-	 */
-	REG_UPDATE(DCHUBBUB_GLOBAL_TIMER_CNTL, DCHUBBUB_GLOBAL_TIMER_REFDIV, 2);
-	REG_UPDATE(DCHUBBUB_GLOBAL_TIMER_CNTL, DCHUBBUB_GLOBAL_TIMER_ENABLE, 1);
-	REG_WRITE(REFCLK_CNTL, 0);
-
-	/* OPTC
-	 * OTG_CONTROL.OTG_DISABLE_POINT_CNTL = 0x3; will be set during optc2_enable_crtc
-	 */
-
-	/* AZ
-	 * default value is 0x64 for 100Mhz ref clock, if the ref clock is 100Mhz, no need to program this regiser,
-	 * if not, it should be programmed according to the ref clock
-	 */
-	REG_UPDATE(AZALIA_AUDIO_DTO, AZALIA_AUDIO_DTO_MODULE, 0x64);
-	/* Enable controller clock gating */
-	REG_WRITE(AZALIA_CONTROLLER_CLOCK_GATING, 0x1);
-}
 
 void dcn20_disable_vga(
 	struct dce_hwseq *hws)
@@ -176,15 +255,15 @@ void dcn20_disable_vga(
 	REG_WRITE(D6VGA_CONTROL, 0);
 }
 
-void dcn20_program_tripleBuffer(
+void dcn20_program_triple_buffer(
 	const struct dc *dc,
 	struct pipe_ctx *pipe_ctx,
-	bool enableTripleBuffer)
+	bool enable_triple_buffer)
 {
 	if (pipe_ctx->plane_res.hubp && pipe_ctx->plane_res.hubp->funcs) {
 		pipe_ctx->plane_res.hubp->funcs->hubp_enable_tripleBuffer(
 			pipe_ctx->plane_res.hubp,
-			enableTripleBuffer);
+			enable_triple_buffer);
 	}
 }
 
@@ -240,10 +319,10 @@ void dcn20_init_blank(
 				otg_active_height);
 	}
 
-	dcn20_hwss_wait_for_blank_complete(opp);
+	dc->hwss.wait_for_blank_complete(opp);
 }
 
-static void dcn20_dsc_pg_control(
+void dcn20_dsc_pg_control(
 		struct dce_hwseq *hws,
 		unsigned int dsc_inst,
 		bool power_on)
@@ -320,7 +399,7 @@ static void dcn20_dsc_pg_control(
 		REG_SET(DC_IP_REQUEST_CNTL, 0, IP_REQUEST_EN, 0);
 }
 
-static void dcn20_dpp_pg_control(
+void dcn20_dpp_pg_control(
 		struct dce_hwseq *hws,
 		unsigned int dpp_inst,
 		bool power_on)
@@ -394,7 +473,7 @@ static void dcn20_dpp_pg_control(
 }
 
 
-static void dcn20_hubp_pg_control(
+void dcn20_hubp_pg_control(
 		struct dce_hwseq *hws,
 		unsigned int hubp_inst,
 		bool power_on)
@@ -471,7 +550,7 @@ static void dcn20_hubp_pg_control(
 /* disable HW used by plane.
  * note:  cannot disable until disconnect is complete
  */
-static void dcn20_plane_atomic_disable(struct dc *dc, struct pipe_ctx *pipe_ctx)
+void dcn20_plane_atomic_disable(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
 	struct hubp *hubp = pipe_ctx->plane_res.hubp;
 	struct dpp *dpp = pipe_ctx->plane_res.dpp;
@@ -591,7 +670,7 @@ enum dc_status dcn20_enable_stream_timing(
 		return DC_ERROR_UNEXPECTED;
 	}
 
-	dcn20_hwss_wait_for_blank_complete(pipe_ctx->stream_res.opp);
+	dc->hwss.wait_for_blank_complete(pipe_ctx->stream_res.opp);
 
 	params.vertical_total_min = stream->adjust.v_total_min;
 	params.vertical_total_max = stream->adjust.v_total_max;
@@ -647,7 +726,7 @@ void dcn20_program_output_csc(struct dc *dc,
 	}
 }
 
-bool dcn20_set_output_transfer_func(struct pipe_ctx *pipe_ctx,
+bool dcn20_set_output_transfer_func(struct dc *dc, struct pipe_ctx *pipe_ctx,
 				const struct dc_stream_state *stream)
 {
 	int mpcc_id = pipe_ctx->plane_res.hubp->inst;
@@ -737,8 +816,9 @@ bool dcn20_set_shaper_3dlut(
 	return result;
 }
 
-bool dcn20_set_input_transfer_func(struct pipe_ctx *pipe_ctx,
-					  const struct dc_plane_state *plane_state)
+bool dcn20_set_input_transfer_func(struct dc *dc,
+				struct pipe_ctx *pipe_ctx,
+				const struct dc_plane_state *plane_state)
 {
 	struct dpp *dpp_base = pipe_ctx->plane_res.dpp;
 	const struct dc_transfer_func *tf = NULL;
@@ -748,8 +828,8 @@ bool dcn20_set_input_transfer_func(struct pipe_ctx *pipe_ctx,
 	if (dpp_base == NULL || plane_state == NULL)
 		return false;
 
-	dcn20_set_shaper_3dlut(pipe_ctx, plane_state);
-	dcn20_set_blend_lut(pipe_ctx, plane_state);
+	dc->hwss.set_shaper_3dlut(pipe_ctx, plane_state);
+	dc->hwss.set_blend_lut(pipe_ctx, plane_state);
 
 	if (plane_state->in_transfer_func)
 		tf = plane_state->in_transfer_func;
@@ -814,7 +894,7 @@ bool dcn20_set_input_transfer_func(struct pipe_ctx *pipe_ctx,
 	return result;
 }
 
-static void dcn20_update_odm(struct dc *dc, struct dc_state *context, struct pipe_ctx *pipe_ctx)
+void dcn20_update_odm(struct dc *dc, struct dc_state *context, struct pipe_ctx *pipe_ctx)
 {
 	struct pipe_ctx *odm_pipe;
 	int opp_cnt = 1;
@@ -1237,7 +1317,7 @@ static void dcn20_update_dchubp_dpp(
 
 		if (dpp->funcs->dpp_program_bias_and_scale) {
 			//TODO :for CNVC set scale and bias registers if necessary
-			dcn10_build_prescale_params(&bns_params, plane_state);
+			build_prescale_params(&bns_params, plane_state);
 			dpp->funcs->dpp_program_bias_and_scale(dpp, &bns_params);
 		}
 	}
@@ -1361,7 +1441,7 @@ static void dcn20_program_pipe(
 				pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);
 
 		if (dc->hwss.setup_vupdate_interrupt)
-			dc->hwss.setup_vupdate_interrupt(pipe_ctx);
+			dc->hwss.setup_vupdate_interrupt(dc, pipe_ctx);
 	}
 
 	if (pipe_ctx->update_flags.bits.odm)
@@ -1375,19 +1455,19 @@ static void dcn20_program_pipe(
 
 	if (pipe_ctx->update_flags.bits.enable
 			|| pipe_ctx->plane_state->update_flags.bits.hdr_mult)
-		set_hdr_multiplier(pipe_ctx);
+		dc->hwss.set_hdr_multiplier(pipe_ctx);
 
 	if (pipe_ctx->update_flags.bits.enable ||
 			pipe_ctx->plane_state->update_flags.bits.in_transfer_func_change ||
 			pipe_ctx->plane_state->update_flags.bits.gamma_change)
-		dc->hwss.set_input_transfer_func(pipe_ctx, pipe_ctx->plane_state);
+		dc->hwss.set_input_transfer_func(dc, pipe_ctx, pipe_ctx->plane_state);
 
 	/* dcn10_translate_regamma_to_hw_format takes 750us to finish
 	 * only do gamma programming for powering on, internal memcmp to avoid
 	 * updating on slave planes
 	 */
 	if (pipe_ctx->update_flags.bits.enable || pipe_ctx->stream->update_flags.bits.out_tf)
-		dc->hwss.set_output_transfer_func(pipe_ctx, pipe_ctx->stream);
+		dc->hwss.set_output_transfer_func(dc, pipe_ctx, pipe_ctx->stream);
 
 	/* If the pipe has been enabled or has a different opp, we
 	 * should reprogram the fmt. This deals with cases where
@@ -1421,7 +1501,7 @@ static bool does_pipe_need_lock(struct pipe_ctx *pipe)
 	return false;
 }
 
-static void dcn20_program_front_end_for_ctx(
+void dcn20_program_front_end_for_ctx(
 		struct dc *dc,
 		struct dc_state *context)
 {
@@ -1602,7 +1682,7 @@ bool dcn20_update_bandwidth(
 				dc->hwss.blank_pixel_data(dc, pipe_ctx, blank);
 
 			if (dc->hwss.setup_vupdate_interrupt)
-				dc->hwss.setup_vupdate_interrupt(pipe_ctx);
+				dc->hwss.setup_vupdate_interrupt(dc, pipe_ctx);
 		}
 
 		pipe_ctx->plane_res.hubp->funcs->hubp_setup(
@@ -1616,7 +1696,7 @@ bool dcn20_update_bandwidth(
 	return true;
 }
 
-static void dcn20_enable_writeback(
+void dcn20_enable_writeback(
 		struct dc *dc,
 		const struct dc_stream_status *stream_status,
 		struct dc_writeback_info *wb_info,
@@ -1660,7 +1740,7 @@ void dcn20_disable_writeback(
 	mcif_wb->funcs->disable_mcif(mcif_wb);
 }
 
-bool dcn20_hwss_wait_for_blank_complete(
+bool dcn20_wait_for_blank_complete(
 		struct output_pixel_processor *opp)
 {
 	int counter;
@@ -1689,7 +1769,7 @@ bool dcn20_dmdata_status_done(struct pipe_ctx *pipe_ctx)
 	return hubp->funcs->dmdata_status_done(hubp);
 }
 
-static void dcn20_disable_stream_gating(struct dc *dc, struct pipe_ctx *pipe_ctx)
+void dcn20_disable_stream_gating(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
 	struct dce_hwseq *hws = dc->hwseq;
 
@@ -1704,7 +1784,7 @@ static void dcn20_disable_stream_gating(struct dc *dc, struct pipe_ctx *pipe_ctx
 	}
 }
 
-static void dcn20_enable_stream_gating(struct dc *dc, struct pipe_ctx *pipe_ctx)
+void dcn20_enable_stream_gating(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
 	struct dce_hwseq *hws = dc->hwseq;
 
@@ -1739,12 +1819,7 @@ void dcn20_set_dmdata_attributes(struct pipe_ctx *pipe_ctx)
 	hubp->funcs->dmdata_set_attributes(hubp, &attr);
 }
 
-void dcn20_disable_stream(struct pipe_ctx *pipe_ctx)
-{
-	dce110_disable_stream(pipe_ctx);
-}
-
-static void dcn20_init_vm_ctx(
+void dcn20_init_vm_ctx(
 		struct dce_hwseq *hws,
 		struct dc *dc,
 		struct dc_virtual_addr_space_config *va_config,
@@ -1766,7 +1841,7 @@ static void dcn20_init_vm_ctx(
 	dc->res_pool->hubbub->funcs->init_vm_ctx(dc->res_pool->hubbub, &config, vmid);
 }
 
-static int dcn20_init_sys_ctx(struct dce_hwseq *hws, struct dc *dc, struct dc_phy_addr_space_config *pa_config)
+int dcn20_init_sys_ctx(struct dce_hwseq *hws, struct dc *dc, struct dc_phy_addr_space_config *pa_config)
 {
 	struct dcn_hubbub_phys_addr_config config;
 
@@ -1810,8 +1885,7 @@ static bool patch_address_for_sbs_tb_stereo(
 	return false;
 }
 
-
-static void dcn20_update_plane_addr(const struct dc *dc, struct pipe_ctx *pipe_ctx)
+void dcn20_update_plane_addr(const struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
 	bool addr_patched = false;
 	PHYSICAL_ADDRESS_LOC addr;
@@ -1857,7 +1931,7 @@ void dcn20_unblank_stream(struct pipe_ctx *pipe_ctx,
 	params.link_settings.link_rate = link_settings->link_rate;
 
 	if (dc_is_dp_signal(pipe_ctx->stream->signal)) {
-		if (optc1_is_two_pixels_per_containter(&stream->timing) || params.opp_cnt > 1)
+		if (optc2_is_two_pixels_per_containter(&stream->timing) || params.opp_cnt > 1)
 			params.timing.pix_clk_100hz /= 2;
 		pipe_ctx->stream_res.stream_enc->funcs->dp_set_odm_combine(
 				pipe_ctx->stream_res.stream_enc, params.opp_cnt > 1);
@@ -1869,10 +1943,10 @@ void dcn20_unblank_stream(struct pipe_ctx *pipe_ctx,
 	}
 }
 
-void dcn20_setup_vupdate_interrupt(struct pipe_ctx *pipe_ctx)
+void dcn20_setup_vupdate_interrupt(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
 	struct timing_generator *tg = pipe_ctx->stream_res.tg;
-	int start_line = get_vupdate_offset_from_vsync(pipe_ctx);
+	int start_line = dc->hwss.get_vupdate_offset_from_vsync(pipe_ctx);
 
 	if (start_line < 0)
 		start_line = 0;
@@ -1948,7 +2022,7 @@ static void dcn20_reset_back_end_for_pipe(
 					pipe_ctx->pipe_idx, pipe_ctx->stream_res.tg->inst);
 }
 
-static void dcn20_reset_hw_ctx_wrap(
+void dcn20_reset_hw_ctx_wrap(
 		struct dc *dc,
 		struct dc_state *context)
 {
@@ -2001,7 +2075,7 @@ void dcn20_get_mpctree_visual_confirm_color(
 	*color = pipe_colors[top_pipe->pipe_idx];
 }
 
-static void dcn20_update_mpcc(struct dc *dc, struct pipe_ctx *pipe_ctx)
+void dcn20_update_mpcc(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
 	struct hubp *hubp = pipe_ctx->plane_res.hubp;
 	struct mpcc_blnd_cfg blnd_cfg = { {0} };
@@ -2013,10 +2087,10 @@ static void dcn20_update_mpcc(struct dc *dc, struct pipe_ctx *pipe_ctx)
 
 	// input to MPCC is always RGB, by default leave black_color at 0
 	if (dc->debug.visual_confirm == VISUAL_CONFIRM_HDR) {
-		dcn10_get_hdr_visual_confirm_color(
+		dc->hwss.get_hdr_visual_confirm_color(
 				pipe_ctx, &blnd_cfg.black_color);
 	} else if (dc->debug.visual_confirm == VISUAL_CONFIRM_SURFACE) {
-		dcn10_get_surface_visual_confirm_color(
+		dc->hwss.get_surface_visual_confirm_color(
 				pipe_ctx, &blnd_cfg.black_color);
 	} else if (dc->debug.visual_confirm == VISUAL_CONFIRM_MPCTREE) {
 		dcn20_get_mpctree_visual_confirm_color(
@@ -2083,125 +2157,7 @@ static void dcn20_update_mpcc(struct dc *dc, struct pipe_ctx *pipe_ctx)
 	hubp->mpcc_id = mpcc_id;
 }
 
-static int find_free_gsl_group(const struct dc *dc)
-{
-	if (dc->res_pool->gsl_groups.gsl_0 == 0)
-		return 1;
-	if (dc->res_pool->gsl_groups.gsl_1 == 0)
-		return 2;
-	if (dc->res_pool->gsl_groups.gsl_2 == 0)
-		return 3;
-
-	return 0;
-}
-
-/* NOTE: This is not a generic setup_gsl function (hence the suffix as_lock)
- * This is only used to lock pipes in pipe splitting case with immediate flip
- * Ordinary MPC/OTG locks suppress VUPDATE which doesn't help with immediate,
- * so we get tearing with freesync since we cannot flip multiple pipes
- * atomically.
- * We use GSL for this:
- * - immediate flip: find first available GSL group if not already assigned
- *                   program gsl with that group, set current OTG as master
- *                   and always us 0x4 = AND of flip_ready from all pipes
- * - vsync flip: disable GSL if used
- *
- * Groups in stream_res are stored as +1 from HW registers, i.e.
- * gsl_0 <=> pipe_ctx->stream_res.gsl_group == 1
- * Using a magic value like -1 would require tracking all inits/resets
- */
-void dcn20_setup_gsl_group_as_lock(
-		const struct dc *dc,
-		struct pipe_ctx *pipe_ctx,
-		bool enable)
-{
-	struct gsl_params gsl;
-	int group_idx;
-
-	memset(&gsl, 0, sizeof(struct gsl_params));
-
-	if (enable) {
-		/* return if group already assigned since GSL was set up
-		 * for vsync flip, we would unassign so it can't be "left over"
-		 */
-		if (pipe_ctx->stream_res.gsl_group > 0)
-			return;
-
-		group_idx = find_free_gsl_group(dc);
-		ASSERT(group_idx != 0);
-		pipe_ctx->stream_res.gsl_group = group_idx;
-
-		/* set gsl group reg field and mark resource used */
-		switch (group_idx) {
-		case 1:
-			gsl.gsl0_en = 1;
-			dc->res_pool->gsl_groups.gsl_0 = 1;
-			break;
-		case 2:
-			gsl.gsl1_en = 1;
-			dc->res_pool->gsl_groups.gsl_1 = 1;
-			break;
-		case 3:
-			gsl.gsl2_en = 1;
-			dc->res_pool->gsl_groups.gsl_2 = 1;
-			break;
-		default:
-			BREAK_TO_DEBUGGER();
-			return; // invalid case
-		}
-		gsl.gsl_master_en = 1;
-	} else {
-		group_idx = pipe_ctx->stream_res.gsl_group;
-		if (group_idx == 0)
-			return; // if not in use, just return
-
-		pipe_ctx->stream_res.gsl_group = 0;
-
-		/* unset gsl group reg field and mark resource free */
-		switch (group_idx) {
-		case 1:
-			gsl.gsl0_en = 0;
-			dc->res_pool->gsl_groups.gsl_0 = 0;
-			break;
-		case 2:
-			gsl.gsl1_en = 0;
-			dc->res_pool->gsl_groups.gsl_1 = 0;
-			break;
-		case 3:
-			gsl.gsl2_en = 0;
-			dc->res_pool->gsl_groups.gsl_2 = 0;
-			break;
-		default:
-			BREAK_TO_DEBUGGER();
-			return;
-		}
-		gsl.gsl_master_en = 0;
-	}
-
-	/* at this point we want to program whether it's to enable or disable */
-	if (pipe_ctx->stream_res.tg->funcs->set_gsl != NULL &&
-		pipe_ctx->stream_res.tg->funcs->set_gsl_source_select != NULL) {
-		pipe_ctx->stream_res.tg->funcs->set_gsl(
-			pipe_ctx->stream_res.tg,
-			&gsl);
-
-		pipe_ctx->stream_res.tg->funcs->set_gsl_source_select(
-			pipe_ctx->stream_res.tg, group_idx,	enable ? 4 : 0);
-	} else
-		BREAK_TO_DEBUGGER();
-}
-
-static void dcn20_set_flip_control_gsl(
-		struct pipe_ctx *pipe_ctx,
-		bool flip_immediate)
-{
-	if (pipe_ctx && pipe_ctx->plane_res.hubp->funcs->hubp_set_flip_control_surface_gsl)
-		pipe_ctx->plane_res.hubp->funcs->hubp_set_flip_control_surface_gsl(
-				pipe_ctx->plane_res.hubp, flip_immediate);
-
-}
-
-static void dcn20_enable_stream(struct pipe_ctx *pipe_ctx)
+void dcn20_enable_stream(struct pipe_ctx *pipe_ctx)
 {
 	enum dc_lane_count lane_count =
 		pipe_ctx->stream->link->cur_link_settings.lane_count;
@@ -2249,7 +2205,7 @@ static void dcn20_enable_stream(struct pipe_ctx *pipe_ctx)
 	}
 }
 
-static void dcn20_program_dmdata_engine(struct pipe_ctx *pipe_ctx)
+void dcn20_program_dmdata_engine(struct pipe_ctx *pipe_ctx)
 {
 	struct dc_stream_state    *stream     = pipe_ctx->stream;
 	struct hubp               *hubp       = pipe_ctx->plane_res.hubp;
@@ -2275,7 +2231,7 @@ static void dcn20_program_dmdata_engine(struct pipe_ctx *pipe_ctx)
 						hubp->inst, mode);
 }
 
-static void dcn20_fpga_init_hw(struct dc *dc)
+void dcn20_fpga_init_hw(struct dc *dc)
 {
 	int i, j;
 	struct dce_hwseq *hws = dc->hwseq;
@@ -2296,7 +2252,7 @@ static void dcn20_fpga_init_hw(struct dc *dc)
 	REG_WRITE(RBBMIF_TIMEOUT_DIS, 0xFFFFFFFF);
 	REG_WRITE(RBBMIF_TIMEOUT_DIS_2, 0xFFFFFFFF);
 
-	dcn20_dccg_init(hws);
+	dc->hwss.dccg_init(hws);
 
 	REG_UPDATE(DCHUBBUB_GLOBAL_TIMER_CNTL, DCHUBBUB_GLOBAL_TIMER_REFDIV, 2);
 	REG_UPDATE(DCHUBBUB_GLOBAL_TIMER_CNTL, DCHUBBUB_GLOBAL_TIMER_ENABLE, 1);
@@ -2360,7 +2316,7 @@ static void dcn20_fpga_init_hw(struct dc *dc)
 		dc->res_pool->opps[i]->mpcc_disconnect_pending[pipe_ctx->plane_res.mpcc_inst] = true;
 		pipe_ctx->stream_res.opp = dc->res_pool->opps[i];
 		/*to do*/
-		hwss1_plane_atomic_disconnect(dc, pipe_ctx);
+		dc->hwss.plane_atomic_disconnect(dc, pipe_ctx);
 	}
 
 	/* initialize DWB pointer to MCIF_WB */
@@ -2389,53 +2345,3 @@ static void dcn20_fpga_init_hw(struct dc *dc)
 		tg->funcs->tg_init(tg);
 	}
 }
-
-void dcn20_hw_sequencer_construct(struct dc *dc)
-{
-	dcn10_hw_sequencer_construct(dc);
-	dc->hwss.unblank_stream = dcn20_unblank_stream;
-	dc->hwss.update_plane_addr = dcn20_update_plane_addr;
-	dc->hwss.enable_stream_timing = dcn20_enable_stream_timing;
-	dc->hwss.program_triplebuffer = dcn20_program_tripleBuffer;
-	dc->hwss.set_input_transfer_func = dcn20_set_input_transfer_func;
-	dc->hwss.set_output_transfer_func = dcn20_set_output_transfer_func;
-	dc->hwss.apply_ctx_for_surface = NULL;
-	dc->hwss.program_front_end_for_ctx = dcn20_program_front_end_for_ctx;
-	dc->hwss.pipe_control_lock = dcn20_pipe_control_lock;
-	dc->hwss.pipe_control_lock_global = dcn20_pipe_control_lock_global;
-	dc->hwss.optimize_bandwidth = dcn20_optimize_bandwidth;
-	dc->hwss.prepare_bandwidth = dcn20_prepare_bandwidth;
-	dc->hwss.update_bandwidth = dcn20_update_bandwidth;
-	dc->hwss.enable_writeback = dcn20_enable_writeback;
-	dc->hwss.disable_writeback = dcn20_disable_writeback;
-	dc->hwss.program_output_csc = dcn20_program_output_csc;
-	dc->hwss.update_odm = dcn20_update_odm;
-	dc->hwss.blank_pixel_data = dcn20_blank_pixel_data;
-	dc->hwss.dmdata_status_done = dcn20_dmdata_status_done;
-	dc->hwss.program_dmdata_engine = dcn20_program_dmdata_engine;
-	dc->hwss.enable_stream = dcn20_enable_stream;
-	dc->hwss.disable_stream = dcn20_disable_stream;
-	dc->hwss.init_sys_ctx = dcn20_init_sys_ctx;
-	dc->hwss.init_vm_ctx = dcn20_init_vm_ctx;
-	dc->hwss.disable_stream_gating = dcn20_disable_stream_gating;
-	dc->hwss.enable_stream_gating = dcn20_enable_stream_gating;
-	dc->hwss.setup_vupdate_interrupt = dcn20_setup_vupdate_interrupt;
-	dc->hwss.reset_hw_ctx_wrap = dcn20_reset_hw_ctx_wrap;
-	dc->hwss.update_mpcc = dcn20_update_mpcc;
-	dc->hwss.set_flip_control_gsl = dcn20_set_flip_control_gsl;
-	dc->hwss.init_blank = dcn20_init_blank;
-	dc->hwss.disable_plane = dcn20_disable_plane;
-	dc->hwss.plane_atomic_disable = dcn20_plane_atomic_disable;
-	dc->hwss.enable_power_gating_plane = dcn20_enable_power_gating_plane;
-	dc->hwss.dpp_pg_control = dcn20_dpp_pg_control;
-	dc->hwss.hubp_pg_control = dcn20_hubp_pg_control;
-	dc->hwss.dsc_pg_control = dcn20_dsc_pg_control;
-	dc->hwss.disable_vga = dcn20_disable_vga;
-
-	if (IS_FPGA_MAXIMUS_DC(dc->ctx->dce_environment)) {
-		dc->hwss.init_hw = dcn20_fpga_init_hw;
-		dc->hwss.init_pipes = NULL;
-	}
-
-
-}

commit 46250a0cba4ce9c9754b922ef89a2aa484209164
Author: Michael Strauss <michael.strauss@amd.com>
Date:   Sun Nov 3 09:35:03 2019 -0500

    drm/amd/display: Avoid conflict between HDR multiplier and 3dlut
    
    [WHY]
    There can be a conflict between OS HDR multiplier and 3dlut HDR
    multiplier, which are both sent to DC.
    
    [HOW]
    Instead of having dc determine which HDR multiplier to use, make the
    decision in dm and send only the intended value in a surface update.
    Store the current OS HDR multiplier and determine whether to use it or
    the 3dlut's multiplier before sending the surface update to dc. Send
    multiplier to dc in fixed31_32 format, dc then converts it to hw format.
    
    Signed-off-by: Michael Strauss <michael.strauss@amd.com>
    Reviewed-by: Krunoslav Kovac <Krunoslav.Kovac@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 4d36b9e415f1..868099fbe8ba 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -734,14 +734,6 @@ bool dcn20_set_shaper_3dlut(
 	else
 		result = dpp_base->funcs->dpp_program_3dlut(dpp_base, NULL);
 
-	if (plane_state->lut3d_func &&
-		plane_state->lut3d_func->state.bits.initialized == 1 &&
-		plane_state->lut3d_func->hdr_multiplier != 0)
-		dpp_base->funcs->dpp_set_hdr_multiplier(dpp_base,
-				plane_state->lut3d_func->hdr_multiplier);
-	else
-		dpp_base->funcs->dpp_set_hdr_multiplier(dpp_base, 0x1f000);
-
 	return result;
 }
 
@@ -1382,7 +1374,7 @@ static void dcn20_program_pipe(
 		dcn20_update_dchubp_dpp(dc, pipe_ctx, context);
 
 	if (pipe_ctx->update_flags.bits.enable
-			|| pipe_ctx->plane_state->update_flags.bits.sdr_white_level)
+			|| pipe_ctx->plane_state->update_flags.bits.hdr_mult)
 		set_hdr_multiplier(pipe_ctx);
 
 	if (pipe_ctx->update_flags.bits.enable ||

commit 2057b7e1cf77bdf090a3571a8d2ca00a76f34a9e
Author: Wenjing Liu <Wenjing.Liu@amd.com>
Date:   Tue Oct 15 15:12:57 2019 -0400

    drm/amd/display: add color space option when sending link test pattern
    
    [why]
    In the TEST_MSIC dpcd register field definition, the test equipment
    has the option to choose between YCbCr601 or YCbCr709.
    We will apply corresponding YCbCr coefficient based on this test
    request.
    
    [how]
    Add a new input parameter in dc_link_dp_set_test_pattern to allow the
    selection between different color space.
    
    Signed-off-by: Wenjing Liu <Wenjing.Liu@amd.com>
    Reviewed-by: Nikola Cornij <Nikola.Cornij@amd.com>
    Acked-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 0046a099c9e9..4d36b9e415f1 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -223,6 +223,7 @@ void dcn20_init_blank(
 	opp->funcs->opp_set_disp_pattern_generator(
 			opp,
 			CONTROLLER_DP_TEST_PATTERN_SOLID_COLOR,
+			CONTROLLER_DP_COLOR_SPACE_UDEFINED,
 			COLOR_DEPTH_UNDEFINED,
 			&black_color,
 			otg_active_width,
@@ -232,6 +233,7 @@ void dcn20_init_blank(
 		bottom_opp->funcs->opp_set_disp_pattern_generator(
 				bottom_opp,
 				CONTROLLER_DP_TEST_PATTERN_SOLID_COLOR,
+				CONTROLLER_DP_COLOR_SPACE_UDEFINED,
 				COLOR_DEPTH_UNDEFINED,
 				&black_color,
 				otg_active_width,
@@ -851,6 +853,7 @@ void dcn20_blank_pixel_data(
 	struct dc_stream_state *stream = pipe_ctx->stream;
 	enum dc_color_space color_space = stream->output_color_space;
 	enum controller_dp_test_pattern test_pattern = CONTROLLER_DP_TEST_PATTERN_SOLID_COLOR;
+	enum controller_dp_color_space test_pattern_color_space = CONTROLLER_DP_COLOR_SPACE_UDEFINED;
 	struct pipe_ctx *odm_pipe;
 	int odm_cnt = 1;
 
@@ -869,8 +872,10 @@ void dcn20_blank_pixel_data(
 		if (stream_res->abm)
 			stream_res->abm->funcs->set_abm_immediate_disable(stream_res->abm);
 
-		if (dc->debug.visual_confirm != VISUAL_CONFIRM_DISABLE)
+		if (dc->debug.visual_confirm != VISUAL_CONFIRM_DISABLE) {
 			test_pattern = CONTROLLER_DP_TEST_PATTERN_COLORSQUARES;
+			test_pattern_color_space = CONTROLLER_DP_COLOR_SPACE_RGB;
+		}
 	} else {
 		test_pattern = CONTROLLER_DP_TEST_PATTERN_VIDEOMODE;
 	}
@@ -878,6 +883,7 @@ void dcn20_blank_pixel_data(
 	stream_res->opp->funcs->opp_set_disp_pattern_generator(
 			stream_res->opp,
 			test_pattern,
+			test_pattern_color_space,
 			stream->timing.display_color_depth,
 			&black_color,
 			width,
@@ -888,6 +894,7 @@ void dcn20_blank_pixel_data(
 				odm_pipe->stream_res.opp,
 				dc->debug.visual_confirm != VISUAL_CONFIRM_DISABLE && blank ?
 						CONTROLLER_DP_TEST_PATTERN_COLORRAMP : test_pattern,
+				test_pattern_color_space,
 				stream->timing.display_color_depth,
 				&black_color,
 				width,

commit 1da37801a8b0fffb024fea594c7f1d7867ed8aa0
Author: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
Date:   Wed Nov 6 14:38:55 2019 -0500

    drm/amd/display: Drop CONFIG_DRM_AMD_DC_DCN2_0 and DSC_SUPPORTED
    
    [Why]
    
    DCN2 and DSC are stable enough to be build by default. So drop the flags.
    
    [How]
    
    Remove them using the unifdef tool. The following commands were executed
    in sequence:
    
    $ find -name '*.c' -exec unifdef -m -DCONFIG_DRM_AMD_DC_DSC_SUPPORT -DCONFIG_DRM_AMD_DC_DCN2_0 -UCONFIG_TRIM_DRM_AMD_DC_DCN2_0 '{}' ';'
    $ find -name '*.h' -exec unifdef -m -DCONFIG_DRM_AMD_DC_DSC_SUPPORT -DCONFIG_DRM_AMD_DC_DCN2_0 -UCONFIG_TRIM_DRM_AMD_DC_DCN2_0 '{}' ';'
    
    In addition:
    
    * Remove from kconfig, and replace any dependencies with DCN1_0.
    * Remove from any makefiles.
    * Fix and cleanup NV defninitions in dal_asic_id.h
    * Expand DCN1 ifdef to include DCN2 code in the following files:
        * clk_mgr/clk_mgr.c: dc_clk_mgr_create()
        * core/dc_resources.c: dc_create_resource_pool()
        * dce/dce_dmcu.c: dcn20_*lock_phy()
        * dce/dce_dmcu.c: dcn20_funcs
        * dce/dce_dmcu.c: dcn20_dmcu_create()
        * gpio/hw_factory.c: dal_hw_factory_init()
        * gpio/hw_translate.c: dal_hw_translate_init()
    
    Signed-off-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 921a36668ced..0046a099c9e9 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -33,9 +33,7 @@
 #include "dcn10/dcn10_hw_sequencer.h"
 #include "dcn20_hwseq.h"
 #include "dce/dce_hwseq.h"
-#ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
 #include "dcn20/dcn20_dsc.h"
-#endif
 #include "abm.h"
 #include "clk_mgr.h"
 #include "dmcu.h"
@@ -243,7 +241,6 @@ void dcn20_init_blank(
 	dcn20_hwss_wait_for_blank_complete(opp);
 }
 
-#ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
 static void dcn20_dsc_pg_control(
 		struct dce_hwseq *hws,
 		unsigned int dsc_inst,
@@ -320,7 +317,6 @@ static void dcn20_dsc_pg_control(
 	if (org_ip_request_cntl == 0)
 		REG_SET(DC_IP_REQUEST_CNTL, 0, IP_REQUEST_EN, 0);
 }
-#endif
 
 static void dcn20_dpp_pg_control(
 		struct dce_hwseq *hws,
@@ -1696,7 +1692,6 @@ bool dcn20_dmdata_status_done(struct pipe_ctx *pipe_ctx)
 
 static void dcn20_disable_stream_gating(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
-#ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
 	struct dce_hwseq *hws = dc->hwseq;
 
 	if (pipe_ctx->stream_res.dsc) {
@@ -1708,12 +1703,10 @@ static void dcn20_disable_stream_gating(struct dc *dc, struct pipe_ctx *pipe_ctx
 			odm_pipe = odm_pipe->next_odm_pipe;
 		}
 	}
-#endif
 }
 
 static void dcn20_enable_stream_gating(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
-#ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
 	struct dce_hwseq *hws = dc->hwseq;
 
 	if (pipe_ctx->stream_res.dsc) {
@@ -1725,7 +1718,6 @@ static void dcn20_enable_stream_gating(struct dc *dc, struct pipe_ctx *pipe_ctx)
 			odm_pipe = odm_pipe->next_odm_pipe;
 		}
 	}
-#endif
 }
 
 void dcn20_set_dmdata_attributes(struct pipe_ctx *pipe_ctx)
@@ -1924,11 +1916,9 @@ static void dcn20_reset_back_end_for_pipe(
 			}
 		}
 	}
-#ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
 	else if (pipe_ctx->stream_res.dsc) {
 		dp_set_dsc_enable(pipe_ctx, false);
 	}
-#endif
 
 	/* by upper caller loop, parent pipe: pipe0, will be reset last.
 	 * back end share by all pipes and will be disable only when disable
@@ -2440,11 +2430,7 @@ void dcn20_hw_sequencer_construct(struct dc *dc)
 	dc->hwss.enable_power_gating_plane = dcn20_enable_power_gating_plane;
 	dc->hwss.dpp_pg_control = dcn20_dpp_pg_control;
 	dc->hwss.hubp_pg_control = dcn20_hubp_pg_control;
-#ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
 	dc->hwss.dsc_pg_control = dcn20_dsc_pg_control;
-#else
-	dc->hwss.dsc_pg_control = NULL;
-#endif
 	dc->hwss.disable_vga = dcn20_disable_vga;
 
 	if (IS_FPGA_MAXIMUS_DC(dc->ctx->dce_environment)) {

commit 1ea8751bd28d1ec2b36a56ec6bc1ac28903d09b4
Author: Noah Abradjian <noah.abradjian@amd.com>
Date:   Fri Sep 27 16:30:57 2019 -0400

    drm/amd/display: Make clk mgr the only dto update point
    
    [Why]
    
    * Clk Mgr DTO update point did not cover all needed updates, as it included a
      check for plane_state which does not exist yet when the updater is called on
      driver startup
    * This resulted in another update path in the pipe programming sequence, based
      on a dppclk update flag
    * However, this alternate path allowed for stray DTO updates, some of which would
      occur in the wrong order during dppclk lowering and cause underflow
    
    [How]
    
    * Remove plane_state check and use of plane_res.dpp->inst, getting rid
      of sequence dependencies (this results in extra dto programming for unused
      pipes but that doesn't cause issues and is a small cost)
    * Allow DTOs to be updated even if global clock is equal, to account for
      edge case exposed by diags tests
    * Remove update_dpp_dto call in pipe programming sequence (leave update to
      dppclk_control there, as that update is necessary and shouldn't occur in clk
      mgr)
    * Remove call to optimize_bandwidth when committing state, as it is not needed
      and resulted in sporadic underflows even with other fixes in place
    
    Signed-off-by: Noah Abradjian <noah.abradjian@amd.com>
    Reviewed-by: Jun Lei <Jun.Lei@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index e237ec39d193..921a36668ced 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1202,15 +1202,9 @@ static void dcn20_update_dchubp_dpp(
 	struct dpp *dpp = pipe_ctx->plane_res.dpp;
 	struct dc_plane_state *plane_state = pipe_ctx->plane_state;
 
-	if (pipe_ctx->update_flags.bits.dppclk) {
+	if (pipe_ctx->update_flags.bits.dppclk)
 		dpp->funcs->dpp_dppclk_control(dpp, false, true);
 
-		dc->res_pool->dccg->funcs->update_dpp_dto(
-				dc->res_pool->dccg,
-				dpp->inst,
-				pipe_ctx->plane_res.bw.dppclk_khz);
-	}
-
 	/* TODO: Need input parameter to tell current DCHUB pipe tie to which OTG
 	 * VTG is within DCHUBBUB which is commond block share by each pipe HUBP.
 	 * VTG is 1:1 mapping with OTG. Each pipe HUBP will select which VTG

commit 123c53a97a5500d07bf8a4adb95032dfc70af69e
Author: Jun Lei <Jun.Lei@amd.com>
Date:   Wed Sep 25 09:46:38 2019 -0400

    drm/amd/display: add odm visual confirm
    
    [why]
    Hard to determine if pipe combine is done with MPC or ODM
    
    [how]
    Add new visual confirm type, this will mark each MPCC tree
    with a different color
    
    Signed-off-by: Jun Lei <Jun.Lei@amd.com>
    Reviewed-by: Yongqiang Sun <yongqiang.sun@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 6229a8ca0013..e237ec39d193 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1996,6 +1996,28 @@ static void dcn20_reset_hw_ctx_wrap(
 	}
 }
 
+void dcn20_get_mpctree_visual_confirm_color(
+		struct pipe_ctx *pipe_ctx,
+		struct tg_color *color)
+{
+	const struct tg_color pipe_colors[6] = {
+			{MAX_TG_COLOR_VALUE, 0, 0}, // red
+			{MAX_TG_COLOR_VALUE, 0, MAX_TG_COLOR_VALUE}, // yellow
+			{0, MAX_TG_COLOR_VALUE, 0}, // blue
+			{MAX_TG_COLOR_VALUE / 2, 0, MAX_TG_COLOR_VALUE / 2}, // purple
+			{0, 0, MAX_TG_COLOR_VALUE}, // green
+			{MAX_TG_COLOR_VALUE, MAX_TG_COLOR_VALUE * 2 / 3, 0}, // orange
+	};
+
+	struct pipe_ctx *top_pipe = pipe_ctx;
+
+	while (top_pipe->top_pipe) {
+		top_pipe = top_pipe->top_pipe;
+	}
+
+	*color = pipe_colors[top_pipe->pipe_idx];
+}
+
 static void dcn20_update_mpcc(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
 	struct hubp *hubp = pipe_ctx->plane_res.hubp;
@@ -2013,6 +2035,9 @@ static void dcn20_update_mpcc(struct dc *dc, struct pipe_ctx *pipe_ctx)
 	} else if (dc->debug.visual_confirm == VISUAL_CONFIRM_SURFACE) {
 		dcn10_get_surface_visual_confirm_color(
 				pipe_ctx, &blnd_cfg.black_color);
+	} else if (dc->debug.visual_confirm == VISUAL_CONFIRM_MPCTREE) {
+		dcn20_get_mpctree_visual_confirm_color(
+				pipe_ctx, &blnd_cfg.black_color);
 	}
 
 	if (per_pixel_alpha)

commit f93e29f083ff263b1507675d2aaa98917e9351c8
Author: Lewis Huang <Lewis.Huang@amd.com>
Date:   Sat Jul 6 16:02:25 2019 -0500

    drm/amd/display: Temporary workaround to toggle watermark setting
    
    [Why]
    Watermarks not propagated to DCHUBP after it is powered on
    
    [How]
    Add temoprary function apply_DEDCN21_147_wa to apply wm settings for Renoir
    
    Signed-off-by: Lewis Huang <Lewis.Huang@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Reviewed-by: Roman Li <Roman.Li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index ce2530509e12..6229a8ca0013 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1533,6 +1533,10 @@ static void dcn20_program_front_end_for_ctx(
 				msleep(1);
 		}
 	}
+
+	/* WA to apply WM setting*/
+	if (dc->hwseq->wa.DEGVIDCN21)
+		dc->res_pool->hubbub->funcs->apply_DEDCN21_147_wa(dc->res_pool->hubbub);
 }
 
 

commit ce10a0f39b1949e9262f9dabbede65bf598516ec
Author: Charlene Liu <charlene.liu@amd.com>
Date:   Tue Sep 17 20:28:40 2019 -0400

    drm/amd/display: use vbios message to call smu for dpm level
    
    [Description]
    use vbios message to call smu for dpm level
    also only program dmdata in vsyncflip as HW requirement.
    
    Signed-off-by: Charlene Liu <charlene.liu@amd.com>
    Reviewed-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 2dce3e4b5e51..ce2530509e12 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -2209,8 +2209,10 @@ static void dcn20_enable_stream(struct pipe_ctx *pipe_ctx)
 	link->link_enc->funcs->connect_dig_be_to_fe(link->link_enc,
 						    pipe_ctx->stream_res.stream_enc->id, true);
 
-	if (link->dc->hwss.program_dmdata_engine)
-		link->dc->hwss.program_dmdata_engine(pipe_ctx);
+	if (pipe_ctx->plane_state && pipe_ctx->plane_state->flip_immediate != 1) {
+		if (link->dc->hwss.program_dmdata_engine)
+			link->dc->hwss.program_dmdata_engine(pipe_ctx);
+	}
 
 	link->dc->hwss.update_info_frame(pipe_ctx);
 

commit edb922b022c0c94805c4ffad202b3edff83d76f0
Author: Julian Parkin <julian.parkin@amd.com>
Date:   Thu Aug 29 17:06:05 2019 -0400

    drm/amd/display: Program DWB watermarks from correct state
    
    [Why]
    When diags adds a DWB via a stream update, we calculate MMHUBBUB
    paramaters, but dc->current_state has not yet been updated
    when the DWB programming happens. This leads to overflow on
    high bandwidth tests since the incorrect MMHUBBUB arbitration
    parameters are programmed.
    
    [How]
    Pass the updated context down to the (enable|update)_writeback functions
    so that they can use the correct watermarks when programming MMHUBBUB.
    
    Signed-off-by: Julian Parkin <julian.parkin@amd.com>
    Reviewed-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 4a0038293569..2dce3e4b5e51 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1626,7 +1626,8 @@ bool dcn20_update_bandwidth(
 static void dcn20_enable_writeback(
 		struct dc *dc,
 		const struct dc_stream_status *stream_status,
-		struct dc_writeback_info *wb_info)
+		struct dc_writeback_info *wb_info,
+		struct dc_state *context)
 {
 	struct dwbc *dwb;
 	struct mcif_wb *mcif_wb;
@@ -1643,7 +1644,7 @@ static void dcn20_enable_writeback(
 	optc->funcs->set_dwb_source(optc, wb_info->dwb_pipe_inst);
 	/* set MCIF_WB buffer and arbitration configuration */
 	mcif_wb->funcs->config_mcif_buf(mcif_wb, &wb_info->mcif_buf_params, wb_info->dwb_params.dest_height);
-	mcif_wb->funcs->config_mcif_arb(mcif_wb, &dc->current_state->bw_ctx.bw.dcn.bw_writeback.mcif_wb_arb[wb_info->dwb_pipe_inst]);
+	mcif_wb->funcs->config_mcif_arb(mcif_wb, &context->bw_ctx.bw.dcn.bw_writeback.mcif_wb_arb[wb_info->dwb_pipe_inst]);
 	/* Enable MCIF_WB */
 	mcif_wb->funcs->enable_mcif(mcif_wb);
 	/* Enable DWB */

commit 377c9d047379140bcb31bb3bd800898bd143829a
Author: Julian Parkin <julian.parkin@amd.com>
Date:   Thu Aug 22 16:32:05 2019 -0400

    drm/amd/display: Reprogram FMT on pipe change
    
    [Why]
    When planes are added or removed from a stream, the change
    in pipe usage from dynamic MPC combine can cause a second
    stream using ODM combine to pick a different pipe to combine with.
    
    In this scenario, a different OPP is connected to the ODM without
    programming its FMT.
    
    [How]
    Reprogram the FMT in dcn20_program_pipe whenever a pipe is
    newly enabled, or when its opp changes.
    
    Signed-off-by: Julian Parkin <julian.parkin@amd.com>
    Reviewed-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 1b4aac185f3f..4a0038293569 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1399,6 +1399,26 @@ static void dcn20_program_pipe(
 	 */
 	if (pipe_ctx->update_flags.bits.enable || pipe_ctx->stream->update_flags.bits.out_tf)
 		dc->hwss.set_output_transfer_func(pipe_ctx, pipe_ctx->stream);
+
+	/* If the pipe has been enabled or has a different opp, we
+	 * should reprogram the fmt. This deals with cases where
+	 * interation between mpc and odm combine on different streams
+	 * causes a different pipe to be chosen to odm combine with.
+	 */
+	if (pipe_ctx->update_flags.bits.enable
+	    || pipe_ctx->update_flags.bits.opp_changed) {
+
+		pipe_ctx->stream_res.opp->funcs->opp_set_dyn_expansion(
+			pipe_ctx->stream_res.opp,
+			COLOR_SPACE_YCBCR601,
+			pipe_ctx->stream->timing.display_color_depth,
+			pipe_ctx->stream->signal);
+
+		pipe_ctx->stream_res.opp->funcs->opp_program_fmt(
+			pipe_ctx->stream_res.opp,
+			&pipe_ctx->stream->bit_depth_params,
+			&pipe_ctx->stream->clamping);
+	}
 }
 
 static bool does_pipe_need_lock(struct pipe_ctx *pipe)

commit 1caba4e83b9d8a322375de04d2cfe23d7ccc1b89
Author: Aric Cyr <aric.cyr@amd.com>
Date:   Fri Sep 6 16:24:54 2019 -0400

    drm/amd/display: Update V_UPDATE whenever VSTARTUP changes
    
    [Why]
    If VSTARTUP changes due to bandwidth requirements, we must
    recalculate and update VLINE2 as well for proper flip reporting.
    
    [How]
    After all calls to program_global_sync which reconfigures
    VSTARTUP, also make sure to update V_UPDATE (i.e. VLINE2 on DCNx).
    
    Signed-off-by: Aric Cyr <aric.cyr@amd.com>
    Reviewed-by: Sivapiriyan Kumarasamy <Sivapiriyan.Kumarasamy@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 84aae9c05781..1b4aac185f3f 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1370,6 +1370,9 @@ static void dcn20_program_pipe(
 
 		pipe_ctx->stream_res.tg->funcs->set_vtg_params(
 				pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);
+
+		if (dc->hwss.setup_vupdate_interrupt)
+			dc->hwss.setup_vupdate_interrupt(pipe_ctx);
 	}
 
 	if (pipe_ctx->update_flags.bits.odm)
@@ -1581,8 +1584,12 @@ bool dcn20_update_bandwidth(
 
 			pipe_ctx->stream_res.tg->funcs->set_vtg_params(
 					pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);
+
 			if (pipe_ctx->prev_odm_pipe == NULL)
 				dc->hwss.blank_pixel_data(dc, pipe_ctx, blank);
+
+			if (dc->hwss.setup_vupdate_interrupt)
+				dc->hwss.setup_vupdate_interrupt(pipe_ctx);
 		}
 
 		pipe_ctx->plane_res.hubp->funcs->hubp_setup(

commit 799c5b9cb91ca759df65707d2820b5fe1ee5383c
Author: Wesley Chalmers <Wesley.Chalmers@amd.com>
Date:   Mon Aug 26 15:02:47 2019 -0400

    drm/amd/display: Revert fixup DPP programming sequence
    
    [WHY]
    This change was made because DTO programming was double-buffered, which
    is itself an issue. After deactivating the DTO double buffer, this
    change becomes unnecessary.
    
    Signed-off-by: Wesley Chalmers <Wesley.Chalmers@amd.com>
    Reviewed-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Acked-by: Anthony Koo <Anthony.Koo@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 4bb5ad19c4cf..84aae9c05781 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1208,8 +1208,7 @@ static void dcn20_update_dchubp_dpp(
 		dc->res_pool->dccg->funcs->update_dpp_dto(
 				dc->res_pool->dccg,
 				dpp->inst,
-				pipe_ctx->plane_res.bw.dppclk_khz,
-				false);
+				pipe_ctx->plane_res.bw.dppclk_khz);
 	}
 
 	/* TODO: Need input parameter to tell current DCHUB pipe tie to which OTG

commit a14e9e0292e29939ef078ab7f5a337edcd796ca1
Author: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Date:   Mon Aug 26 15:04:18 2019 -0400

    drm/amd/display: add vtg update after global sync update
    
    Global sync update was missing vtg update resulting in underflow if
    vstartup decreased a significant amount.
    
    Signed-off-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Reviewed-by: Jaehyun Chung <Jaehyun.Chung@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index faaf8841c61e..4bb5ad19c4cf 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1361,7 +1361,7 @@ static void dcn20_program_pipe(
 			&& !pipe_ctx->top_pipe && !pipe_ctx->prev_odm_pipe)
 		dc->hwss.blank_pixel_data(dc, pipe_ctx, !pipe_ctx->plane_state->visible);
 
-	if (pipe_ctx->update_flags.bits.global_sync)
+	if (pipe_ctx->update_flags.bits.global_sync) {
 		pipe_ctx->stream_res.tg->funcs->program_global_sync(
 				pipe_ctx->stream_res.tg,
 				pipe_ctx->pipe_dlg_param.vready_offset,
@@ -1369,6 +1369,10 @@ static void dcn20_program_pipe(
 				pipe_ctx->pipe_dlg_param.vupdate_offset,
 				pipe_ctx->pipe_dlg_param.vupdate_width);
 
+		pipe_ctx->stream_res.tg->funcs->set_vtg_params(
+				pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);
+	}
+
 	if (pipe_ctx->update_flags.bits.odm)
 		dc->hwss.update_odm(dc, context, pipe_ctx);
 

commit 747012382937e4b6eb34ba730e815f9da836e454
Author: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Date:   Thu Aug 22 14:12:57 2019 -0400

    drm/amd/display: add additional flag consideration for surface update
    
    Surface dchub/dpp update would not trigger if a stream update was the
    only cause. This change now allows stream flags to trigger this update.
    
    Signed-off-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 81740e0c4c4e..faaf8841c61e 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1375,7 +1375,7 @@ static void dcn20_program_pipe(
 	if (pipe_ctx->update_flags.bits.enable)
 		dcn20_enable_plane(dc, pipe_ctx, context);
 
-	if (pipe_ctx->update_flags.raw || pipe_ctx->plane_state->update_flags.raw)
+	if (pipe_ctx->update_flags.raw || pipe_ctx->plane_state->update_flags.raw || pipe_ctx->stream->update_flags.raw)
 		dcn20_update_dchubp_dpp(dc, pipe_ctx, context);
 
 	if (pipe_ctx->update_flags.bits.enable

commit ff344c8d2a404e441b83182d0bd68d97e37894eb
Author: Vitaly Prosyak <vitaly.prosyak@amd.com>
Date:   Fri Aug 9 12:36:08 2019 -0500

    drm/amd/display: Reuse dcn2 registers
    
    [Why & How]
    Use dcn2 blender, shaper, 3dlut registers
    
    Signed-off-by: Vitaly Prosyak <vitaly.prosyak@amd.com>
    Reviewed-by: Charlene Liu <Charlene.Liu@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Acked-by: Vitaly Prosyak <Vitaly.Prosyak@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index b5b5d9145f6a..81740e0c4c4e 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -508,7 +508,7 @@ static void dcn20_plane_atomic_disable(struct dc *dc, struct pipe_ctx *pipe_ctx)
 }
 
 
-static void dcn20_disable_plane(struct dc *dc, struct pipe_ctx *pipe_ctx)
+void dcn20_disable_plane(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
 	DC_LOGGER_INIT(dc->ctx->logger);
 
@@ -688,7 +688,7 @@ bool dcn20_set_output_transfer_func(struct pipe_ctx *pipe_ctx,
 	return true;
 }
 
-static bool dcn20_set_blend_lut(
+bool dcn20_set_blend_lut(
 	struct pipe_ctx *pipe_ctx, const struct dc_plane_state *plane_state)
 {
 	struct dpp *dpp_base = pipe_ctx->plane_res.dpp;
@@ -710,7 +710,7 @@ static bool dcn20_set_blend_lut(
 	return result;
 }
 
-static bool dcn20_set_shaper_3dlut(
+bool dcn20_set_shaper_3dlut(
 	struct pipe_ctx *pipe_ctx, const struct dc_plane_state *plane_state)
 {
 	struct dpp *dpp_base = pipe_ctx->plane_res.dpp;
@@ -923,7 +923,7 @@ static void dcn20_power_on_plane(
 	}
 }
 
-static void dcn20_enable_plane(
+void dcn20_enable_plane(
 	struct dc *dc,
 	struct pipe_ctx *pipe_ctx,
 	struct dc_state *context)
@@ -1021,7 +1021,7 @@ void dcn20_pipe_control_lock_global(
 	}
 }
 
-static void dcn20_pipe_control_lock(
+void dcn20_pipe_control_lock(
 	struct dc *dc,
 	struct pipe_ctx *pipe,
 	bool lock)

commit b6e881c947417e75272d3568cedf31f5ef016dcb
Author: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Date:   Fri Sep 13 18:00:28 2019 -0500

    drm/amd/display: update navi to use new surface programming behaviour
    
    New behaviour will track global updates and update any hw that isn't
    related to current stream being updated.
    
    This should fix any issues caused by pipe split pipes being taken
    by other streams.
    
    Signed-off-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Reviewed-by: Charlene Liu <Charlene.Liu@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 1212da12c414..b5b5d9145f6a 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -508,7 +508,7 @@ static void dcn20_plane_atomic_disable(struct dc *dc, struct pipe_ctx *pipe_ctx)
 }
 
 
-void dcn20_disable_plane(struct dc *dc, struct pipe_ctx *pipe_ctx)
+static void dcn20_disable_plane(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
 	DC_LOGGER_INIT(dc->ctx->logger);
 
@@ -923,7 +923,7 @@ static void dcn20_power_on_plane(
 	}
 }
 
-void dcn20_enable_plane(
+static void dcn20_enable_plane(
 	struct dc *dc,
 	struct pipe_ctx *pipe_ctx,
 	struct dc_state *context)
@@ -999,72 +999,6 @@ void dcn20_enable_plane(
 }
 
 
-static void dcn20_program_pipe(
-		struct dc *dc,
-		struct pipe_ctx *pipe_ctx,
-		struct dc_state *context)
-{
-	pipe_ctx->plane_state->update_flags.bits.full_update =
-			context->commit_hints.full_update_needed ? 1 : pipe_ctx->plane_state->update_flags.bits.full_update;
-
-	if (pipe_ctx->plane_state->update_flags.bits.full_update)
-		dcn20_enable_plane(dc, pipe_ctx, context);
-
-	update_dchubp_dpp(dc, pipe_ctx, context);
-
-	set_hdr_multiplier(pipe_ctx);
-
-	if (pipe_ctx->plane_state->update_flags.bits.full_update ||
-			pipe_ctx->plane_state->update_flags.bits.in_transfer_func_change ||
-			pipe_ctx->plane_state->update_flags.bits.gamma_change)
-		dc->hwss.set_input_transfer_func(pipe_ctx, pipe_ctx->plane_state);
-
-	/* dcn10_translate_regamma_to_hw_format takes 750us to finish
-	 * only do gamma programming for full update.
-	 * TODO: This can be further optimized/cleaned up
-	 * Always call this for now since it does memcmp inside before
-	 * doing heavy calculation and programming
-	 */
-	if (pipe_ctx->plane_state->update_flags.bits.full_update)
-		dc->hwss.set_output_transfer_func(pipe_ctx, pipe_ctx->stream);
-}
-
-static void dcn20_program_all_pipe_in_tree(
-		struct dc *dc,
-		struct pipe_ctx *pipe_ctx,
-		struct dc_state *context)
-{
-	if (pipe_ctx->top_pipe == NULL && !pipe_ctx->prev_odm_pipe) {
-		bool blank = !is_pipe_tree_visible(pipe_ctx);
-
-		pipe_ctx->stream_res.tg->funcs->program_global_sync(
-				pipe_ctx->stream_res.tg,
-				pipe_ctx->pipe_dlg_param.vready_offset,
-				pipe_ctx->pipe_dlg_param.vstartup_start,
-				pipe_ctx->pipe_dlg_param.vupdate_offset,
-				pipe_ctx->pipe_dlg_param.vupdate_width);
-
-		pipe_ctx->stream_res.tg->funcs->set_vtg_params(
-				pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);
-
-		dc->hwss.blank_pixel_data(dc, pipe_ctx, blank);
-
-		if (dc->hwss.update_odm)
-			dc->hwss.update_odm(dc, context, pipe_ctx);
-	}
-
-	if (pipe_ctx->plane_state != NULL)
-		dcn20_program_pipe(dc, pipe_ctx, context);
-
-	if (pipe_ctx->bottom_pipe != NULL) {
-		ASSERT(pipe_ctx->bottom_pipe != pipe_ctx);
-		dcn20_program_all_pipe_in_tree(dc, pipe_ctx->bottom_pipe, context);
-	} else if (pipe_ctx->next_odm_pipe != NULL) {
-		ASSERT(pipe_ctx->next_odm_pipe != pipe_ctx);
-		dcn20_program_all_pipe_in_tree(dc, pipe_ctx->next_odm_pipe, context);
-	}
-}
-
 void dcn20_pipe_control_lock_global(
 		struct dc *dc,
 		struct pipe_ctx *pipe,
@@ -1087,7 +1021,7 @@ void dcn20_pipe_control_lock_global(
 	}
 }
 
-void dcn20_pipe_control_lock(
+static void dcn20_pipe_control_lock(
 	struct dc *dc,
 	struct pipe_ctx *pipe,
 	bool lock)
@@ -1124,114 +1058,436 @@ void dcn20_pipe_control_lock(
 	}
 }
 
-static void dcn20_apply_ctx_for_surface(
-		struct dc *dc,
-		const struct dc_stream_state *stream,
-		int num_planes,
-		struct dc_state *context)
+static void dcn20_detect_pipe_changes(struct pipe_ctx *old_pipe, struct pipe_ctx *new_pipe)
 {
-	const unsigned int TIMEOUT_FOR_PIPE_ENABLE_MS = 100;
-	int i;
-	struct timing_generator *tg;
-	bool removed_pipe[6] = { false };
-	bool interdependent_update = false;
-	struct pipe_ctx *top_pipe_to_program =
-			find_top_pipe_for_stream(dc, context, stream);
-	struct pipe_ctx *prev_top_pipe_to_program =
-			find_top_pipe_for_stream(dc, dc->current_state, stream);
-	DC_LOGGER_INIT(dc->ctx->logger);
+	new_pipe->update_flags.raw = 0;
 
-	if (!top_pipe_to_program)
+	/* Exit on unchanged, unused pipe */
+	if (!old_pipe->plane_state && !new_pipe->plane_state)
 		return;
+	/* Detect pipe enable/disable */
+	if (!old_pipe->plane_state && new_pipe->plane_state) {
+		new_pipe->update_flags.bits.enable = 1;
+		new_pipe->update_flags.bits.mpcc = 1;
+		new_pipe->update_flags.bits.dppclk = 1;
+		new_pipe->update_flags.bits.hubp_interdependent = 1;
+		new_pipe->update_flags.bits.hubp_rq_dlg_ttu = 1;
+		new_pipe->update_flags.bits.gamut_remap = 1;
+		new_pipe->update_flags.bits.scaler = 1;
+		new_pipe->update_flags.bits.viewport = 1;
+		if (!new_pipe->top_pipe && !new_pipe->prev_odm_pipe) {
+			new_pipe->update_flags.bits.odm = 1;
+			new_pipe->update_flags.bits.global_sync = 1;
+		}
+		return;
+	}
+	if (old_pipe->plane_state && !new_pipe->plane_state) {
+		new_pipe->update_flags.bits.disable = 1;
+		return;
+	}
 
-	/* Carry over GSL groups in case the context is changing. */
-	for (i = 0; i < dc->res_pool->pipe_count; i++) {
-		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
-		struct pipe_ctx *old_pipe_ctx =
-			&dc->current_state->res_ctx.pipe_ctx[i];
+	/* Detect top pipe only changes */
+	if (!new_pipe->top_pipe && !new_pipe->prev_odm_pipe) {
+		/* Detect odm changes */
+		if ((old_pipe->next_odm_pipe && new_pipe->next_odm_pipe
+			&& old_pipe->next_odm_pipe->pipe_idx != new_pipe->next_odm_pipe->pipe_idx)
+				|| (!old_pipe->next_odm_pipe && new_pipe->next_odm_pipe)
+				|| (old_pipe->next_odm_pipe && !new_pipe->next_odm_pipe)
+				|| old_pipe->stream_res.opp != new_pipe->stream_res.opp)
+			new_pipe->update_flags.bits.odm = 1;
+
+		/* Detect global sync changes */
+		if (old_pipe->pipe_dlg_param.vready_offset != new_pipe->pipe_dlg_param.vready_offset
+				|| old_pipe->pipe_dlg_param.vstartup_start != new_pipe->pipe_dlg_param.vstartup_start
+				|| old_pipe->pipe_dlg_param.vupdate_offset != new_pipe->pipe_dlg_param.vupdate_offset
+				|| old_pipe->pipe_dlg_param.vupdate_width != new_pipe->pipe_dlg_param.vupdate_width)
+			new_pipe->update_flags.bits.global_sync = 1;
+	}
 
-		if (pipe_ctx->stream == stream &&
-		    pipe_ctx->stream == old_pipe_ctx->stream)
-			pipe_ctx->stream_res.gsl_group =
-				old_pipe_ctx->stream_res.gsl_group;
+	/*
+	 * Detect opp / tg change, only set on change, not on enable
+	 * Assume mpcc inst = pipe index, if not this code needs to be updated
+	 * since mpcc is what is affected by these. In fact all of our sequence
+	 * makes this assumption at the moment with how hubp reset is matched to
+	 * same index mpcc reset.
+	 */
+	if (old_pipe->stream_res.opp != new_pipe->stream_res.opp)
+		new_pipe->update_flags.bits.opp_changed = 1;
+	if (old_pipe->stream_res.tg != new_pipe->stream_res.tg)
+		new_pipe->update_flags.bits.tg_changed = 1;
+
+	/* Detect mpcc blending changes, only dpp inst and bot matter here */
+	if (old_pipe->plane_res.dpp != new_pipe->plane_res.dpp
+			|| old_pipe->stream_res.opp != new_pipe->stream_res.opp
+			|| (!old_pipe->bottom_pipe && new_pipe->bottom_pipe)
+			|| (old_pipe->bottom_pipe && !new_pipe->bottom_pipe)
+			|| (old_pipe->bottom_pipe && new_pipe->bottom_pipe
+				&& old_pipe->bottom_pipe->plane_res.mpcc_inst
+					!= new_pipe->bottom_pipe->plane_res.mpcc_inst))
+		new_pipe->update_flags.bits.mpcc = 1;
+
+	/* Detect dppclk change */
+	if (old_pipe->plane_res.bw.dppclk_khz != new_pipe->plane_res.bw.dppclk_khz)
+		new_pipe->update_flags.bits.dppclk = 1;
+
+	/* Check for scl update */
+	if (memcmp(&old_pipe->plane_res.scl_data, &new_pipe->plane_res.scl_data, sizeof(struct scaler_data)))
+			new_pipe->update_flags.bits.scaler = 1;
+	/* Check for vp update */
+	if (memcmp(&old_pipe->plane_res.scl_data.viewport, &new_pipe->plane_res.scl_data.viewport, sizeof(struct rect))
+			|| memcmp(&old_pipe->plane_res.scl_data.viewport_c,
+				&new_pipe->plane_res.scl_data.viewport_c, sizeof(struct rect)))
+		new_pipe->update_flags.bits.viewport = 1;
+
+	/* Detect dlg/ttu/rq updates */
+	{
+		struct _vcs_dpi_display_dlg_regs_st old_dlg_attr = old_pipe->dlg_regs;
+		struct _vcs_dpi_display_ttu_regs_st old_ttu_attr = old_pipe->ttu_regs;
+		struct _vcs_dpi_display_dlg_regs_st *new_dlg_attr = &new_pipe->dlg_regs;
+		struct _vcs_dpi_display_ttu_regs_st *new_ttu_attr = &new_pipe->ttu_regs;
+
+		/* Detect pipe interdependent updates */
+		if (old_dlg_attr.dst_y_prefetch != new_dlg_attr->dst_y_prefetch ||
+				old_dlg_attr.vratio_prefetch != new_dlg_attr->vratio_prefetch ||
+				old_dlg_attr.vratio_prefetch_c != new_dlg_attr->vratio_prefetch_c ||
+				old_dlg_attr.dst_y_per_vm_vblank != new_dlg_attr->dst_y_per_vm_vblank ||
+				old_dlg_attr.dst_y_per_row_vblank != new_dlg_attr->dst_y_per_row_vblank ||
+				old_dlg_attr.dst_y_per_vm_flip != new_dlg_attr->dst_y_per_vm_flip ||
+				old_dlg_attr.dst_y_per_row_flip != new_dlg_attr->dst_y_per_row_flip ||
+				old_dlg_attr.refcyc_per_meta_chunk_vblank_l != new_dlg_attr->refcyc_per_meta_chunk_vblank_l ||
+				old_dlg_attr.refcyc_per_meta_chunk_vblank_c != new_dlg_attr->refcyc_per_meta_chunk_vblank_c ||
+				old_dlg_attr.refcyc_per_meta_chunk_flip_l != new_dlg_attr->refcyc_per_meta_chunk_flip_l ||
+				old_dlg_attr.refcyc_per_line_delivery_pre_l != new_dlg_attr->refcyc_per_line_delivery_pre_l ||
+				old_dlg_attr.refcyc_per_line_delivery_pre_c != new_dlg_attr->refcyc_per_line_delivery_pre_c ||
+				old_ttu_attr.refcyc_per_req_delivery_pre_l != new_ttu_attr->refcyc_per_req_delivery_pre_l ||
+				old_ttu_attr.refcyc_per_req_delivery_pre_c != new_ttu_attr->refcyc_per_req_delivery_pre_c ||
+				old_ttu_attr.refcyc_per_req_delivery_pre_cur0 != new_ttu_attr->refcyc_per_req_delivery_pre_cur0 ||
+				old_ttu_attr.refcyc_per_req_delivery_pre_cur1 != new_ttu_attr->refcyc_per_req_delivery_pre_cur1 ||
+				old_ttu_attr.min_ttu_vblank != new_ttu_attr->min_ttu_vblank ||
+				old_ttu_attr.qos_level_flip != new_ttu_attr->qos_level_flip) {
+			old_dlg_attr.dst_y_prefetch = new_dlg_attr->dst_y_prefetch;
+			old_dlg_attr.vratio_prefetch = new_dlg_attr->vratio_prefetch;
+			old_dlg_attr.vratio_prefetch_c = new_dlg_attr->vratio_prefetch_c;
+			old_dlg_attr.dst_y_per_vm_vblank = new_dlg_attr->dst_y_per_vm_vblank;
+			old_dlg_attr.dst_y_per_row_vblank = new_dlg_attr->dst_y_per_row_vblank;
+			old_dlg_attr.dst_y_per_vm_flip = new_dlg_attr->dst_y_per_vm_flip;
+			old_dlg_attr.dst_y_per_row_flip = new_dlg_attr->dst_y_per_row_flip;
+			old_dlg_attr.refcyc_per_meta_chunk_vblank_l = new_dlg_attr->refcyc_per_meta_chunk_vblank_l;
+			old_dlg_attr.refcyc_per_meta_chunk_vblank_c = new_dlg_attr->refcyc_per_meta_chunk_vblank_c;
+			old_dlg_attr.refcyc_per_meta_chunk_flip_l = new_dlg_attr->refcyc_per_meta_chunk_flip_l;
+			old_dlg_attr.refcyc_per_line_delivery_pre_l = new_dlg_attr->refcyc_per_line_delivery_pre_l;
+			old_dlg_attr.refcyc_per_line_delivery_pre_c = new_dlg_attr->refcyc_per_line_delivery_pre_c;
+			old_ttu_attr.refcyc_per_req_delivery_pre_l = new_ttu_attr->refcyc_per_req_delivery_pre_l;
+			old_ttu_attr.refcyc_per_req_delivery_pre_c = new_ttu_attr->refcyc_per_req_delivery_pre_c;
+			old_ttu_attr.refcyc_per_req_delivery_pre_cur0 = new_ttu_attr->refcyc_per_req_delivery_pre_cur0;
+			old_ttu_attr.refcyc_per_req_delivery_pre_cur1 = new_ttu_attr->refcyc_per_req_delivery_pre_cur1;
+			old_ttu_attr.min_ttu_vblank = new_ttu_attr->min_ttu_vblank;
+			old_ttu_attr.qos_level_flip = new_ttu_attr->qos_level_flip;
+			new_pipe->update_flags.bits.hubp_interdependent = 1;
+		}
+		/* Detect any other updates to ttu/rq/dlg */
+		if (memcmp(&old_dlg_attr, &new_pipe->dlg_regs, sizeof(old_dlg_attr)) ||
+				memcmp(&old_ttu_attr, &new_pipe->ttu_regs, sizeof(old_ttu_attr)) ||
+				memcmp(&old_pipe->rq_regs, &new_pipe->rq_regs, sizeof(old_pipe->rq_regs)))
+			new_pipe->update_flags.bits.hubp_rq_dlg_ttu = 1;
 	}
+}
 
-	tg = top_pipe_to_program->stream_res.tg;
+static void dcn20_update_dchubp_dpp(
+	struct dc *dc,
+	struct pipe_ctx *pipe_ctx,
+	struct dc_state *context)
+{
+	struct hubp *hubp = pipe_ctx->plane_res.hubp;
+	struct dpp *dpp = pipe_ctx->plane_res.dpp;
+	struct dc_plane_state *plane_state = pipe_ctx->plane_state;
 
-	interdependent_update = top_pipe_to_program->plane_state &&
-		top_pipe_to_program->plane_state->update_flags.bits.full_update;
+	if (pipe_ctx->update_flags.bits.dppclk) {
+		dpp->funcs->dpp_dppclk_control(dpp, false, true);
 
-	if (interdependent_update)
-		lock_all_pipes(dc, context, true);
-	else
-		dcn20_pipe_control_lock(dc, top_pipe_to_program, true);
+		dc->res_pool->dccg->funcs->update_dpp_dto(
+				dc->res_pool->dccg,
+				dpp->inst,
+				pipe_ctx->plane_res.bw.dppclk_khz,
+				false);
+	}
 
-	if (num_planes == 0) {
-		/* OTG blank before remove all front end */
-		dc->hwss.blank_pixel_data(dc, top_pipe_to_program, true);
+	/* TODO: Need input parameter to tell current DCHUB pipe tie to which OTG
+	 * VTG is within DCHUBBUB which is commond block share by each pipe HUBP.
+	 * VTG is 1:1 mapping with OTG. Each pipe HUBP will select which VTG
+	 */
+	if (pipe_ctx->update_flags.bits.hubp_rq_dlg_ttu) {
+		hubp->funcs->hubp_vtg_sel(hubp, pipe_ctx->stream_res.tg->inst);
+
+		hubp->funcs->hubp_setup(
+			hubp,
+			&pipe_ctx->dlg_regs,
+			&pipe_ctx->ttu_regs,
+			&pipe_ctx->rq_regs,
+			&pipe_ctx->pipe_dlg_param);
+	}
+	if (pipe_ctx->update_flags.bits.hubp_interdependent)
+		hubp->funcs->hubp_setup_interdependent(
+			hubp,
+			&pipe_ctx->dlg_regs,
+			&pipe_ctx->ttu_regs);
+
+	if (pipe_ctx->update_flags.bits.enable ||
+			plane_state->update_flags.bits.bpp_change ||
+			plane_state->update_flags.bits.input_csc_change ||
+			plane_state->update_flags.bits.color_space_change ||
+			plane_state->update_flags.bits.coeff_reduction_change) {
+		struct dc_bias_and_scale bns_params = {0};
+
+		// program the input csc
+		dpp->funcs->dpp_setup(dpp,
+				plane_state->format,
+				EXPANSION_MODE_ZERO,
+				plane_state->input_csc_color_matrix,
+				plane_state->color_space,
+				NULL);
+
+		if (dpp->funcs->dpp_program_bias_and_scale) {
+			//TODO :for CNVC set scale and bias registers if necessary
+			dcn10_build_prescale_params(&bns_params, plane_state);
+			dpp->funcs->dpp_program_bias_and_scale(dpp, &bns_params);
+		}
 	}
 
-	/* Disconnect unused mpcc */
-	for (i = 0; i < dc->res_pool->pipe_count; i++) {
-		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
-		struct pipe_ctx *old_pipe_ctx =
-				&dc->current_state->res_ctx.pipe_ctx[i];
-		/*
-		 * Powergate reused pipes that are not powergated
-		 * fairly hacky right now, using opp_id as indicator
-		 * TODO: After move dc_post to dc_update, this will
-		 * be removed.
-		 */
-		if (pipe_ctx->plane_state && !old_pipe_ctx->plane_state) {
-			if (old_pipe_ctx->stream_res.tg == tg &&
-			    old_pipe_ctx->plane_res.hubp &&
-			    old_pipe_ctx->plane_res.hubp->opp_id != OPP_ID_INVALID)
-				dc->hwss.disable_plane(dc, old_pipe_ctx);
+	if (pipe_ctx->update_flags.bits.mpcc
+			|| plane_state->update_flags.bits.global_alpha_change
+			|| plane_state->update_flags.bits.per_pixel_alpha_change) {
+		/* Need mpcc to be idle if changing opp */
+		if (pipe_ctx->update_flags.bits.opp_changed) {
+			struct pipe_ctx *old_pipe_ctx = &dc->current_state->res_ctx.pipe_ctx[pipe_ctx->pipe_idx];
+			int mpcc_inst;
+
+			for (mpcc_inst = 0; mpcc_inst < MAX_PIPES; mpcc_inst++) {
+				if (!old_pipe_ctx->stream_res.opp->mpcc_disconnect_pending[mpcc_inst])
+					continue;
+				dc->res_pool->mpc->funcs->wait_for_idle(dc->res_pool->mpc, mpcc_inst);
+				old_pipe_ctx->stream_res.opp->mpcc_disconnect_pending[mpcc_inst] = false;
+			}
 		}
+		dc->hwss.update_mpcc(dc, pipe_ctx);
+	}
 
-		if ((!pipe_ctx->plane_state ||
-		     pipe_ctx->stream_res.tg != old_pipe_ctx->stream_res.tg) &&
-		     old_pipe_ctx->plane_state &&
-		     old_pipe_ctx->stream_res.tg == tg) {
+	if (pipe_ctx->update_flags.bits.scaler ||
+			plane_state->update_flags.bits.scaling_change ||
+			plane_state->update_flags.bits.position_change ||
+			plane_state->update_flags.bits.per_pixel_alpha_change ||
+			pipe_ctx->stream->update_flags.bits.scaling) {
+		pipe_ctx->plane_res.scl_data.lb_params.alpha_en = pipe_ctx->plane_state->per_pixel_alpha;
+		ASSERT(pipe_ctx->plane_res.scl_data.lb_params.depth == LB_PIXEL_DEPTH_30BPP);
+		/* scaler configuration */
+		pipe_ctx->plane_res.dpp->funcs->dpp_set_scaler(
+				pipe_ctx->plane_res.dpp, &pipe_ctx->plane_res.scl_data);
+	}
 
-			dc->hwss.plane_atomic_disconnect(dc, old_pipe_ctx);
-			removed_pipe[i] = true;
+	if (pipe_ctx->update_flags.bits.viewport ||
+			(context == dc->current_state && plane_state->update_flags.bits.scaling_change) ||
+			(context == dc->current_state && pipe_ctx->stream->update_flags.bits.scaling))
+		hubp->funcs->mem_program_viewport(
+			hubp,
+			&pipe_ctx->plane_res.scl_data.viewport,
+			&pipe_ctx->plane_res.scl_data.viewport_c);
+
+	/* Any updates are handled in dc interface, just need to apply existing for plane enable */
+	if ((pipe_ctx->update_flags.bits.enable || pipe_ctx->update_flags.bits.opp_changed)
+			&& pipe_ctx->stream->cursor_attributes.address.quad_part != 0) {
+		dc->hwss.set_cursor_position(pipe_ctx);
+		dc->hwss.set_cursor_attribute(pipe_ctx);
+
+		if (dc->hwss.set_cursor_sdr_white_level)
+			dc->hwss.set_cursor_sdr_white_level(pipe_ctx);
+	}
 
-			DC_LOG_DC("Reset mpcc for pipe %d\n",
-					old_pipe_ctx->pipe_idx);
-		}
+	/* Any updates are handled in dc interface, just need
+	 * to apply existing for plane enable / opp change */
+	if (pipe_ctx->update_flags.bits.enable || pipe_ctx->update_flags.bits.opp_changed
+			|| pipe_ctx->stream->update_flags.bits.gamut_remap
+			|| pipe_ctx->stream->update_flags.bits.out_csc) {
+			/* dpp/cm gamut remap*/
+			dc->hwss.program_gamut_remap(pipe_ctx);
+
+		/*call the dcn2 method which uses mpc csc*/
+		dc->hwss.program_output_csc(dc,
+				pipe_ctx,
+				pipe_ctx->stream->output_color_space,
+				pipe_ctx->stream->csc_color_matrix.matrix,
+				hubp->opp_id);
 	}
 
-	if (num_planes > 0)
-		dcn20_program_all_pipe_in_tree(dc, top_pipe_to_program, context);
+	if (pipe_ctx->update_flags.bits.enable ||
+			pipe_ctx->update_flags.bits.opp_changed ||
+			plane_state->update_flags.bits.pixel_format_change ||
+			plane_state->update_flags.bits.horizontal_mirror_change ||
+			plane_state->update_flags.bits.rotation_change ||
+			plane_state->update_flags.bits.swizzle_change ||
+			plane_state->update_flags.bits.dcc_change ||
+			plane_state->update_flags.bits.bpp_change ||
+			plane_state->update_flags.bits.scaling_change ||
+			plane_state->update_flags.bits.plane_size_change) {
+		struct plane_size size = plane_state->plane_size;
+
+		size.surface_size = pipe_ctx->plane_res.scl_data.viewport;
+		hubp->funcs->hubp_program_surface_config(
+			hubp,
+			plane_state->format,
+			&plane_state->tiling_info,
+			&size,
+			plane_state->rotation,
+			&plane_state->dcc,
+			plane_state->horizontal_mirror,
+			0);
+		hubp->power_gated = false;
+	}
+
+	if (pipe_ctx->update_flags.bits.enable || plane_state->update_flags.bits.addr_update)
+		dc->hwss.update_plane_addr(dc, pipe_ctx);
+
+	if (pipe_ctx->update_flags.bits.enable)
+		hubp->funcs->set_blank(hubp, false);
+}
+
+
+static void dcn20_program_pipe(
+		struct dc *dc,
+		struct pipe_ctx *pipe_ctx,
+		struct dc_state *context)
+{
+	/* Only need to unblank on top pipe */
+	if ((pipe_ctx->update_flags.bits.enable || pipe_ctx->stream->update_flags.bits.abm_level)
+			&& !pipe_ctx->top_pipe && !pipe_ctx->prev_odm_pipe)
+		dc->hwss.blank_pixel_data(dc, pipe_ctx, !pipe_ctx->plane_state->visible);
+
+	if (pipe_ctx->update_flags.bits.global_sync)
+		pipe_ctx->stream_res.tg->funcs->program_global_sync(
+				pipe_ctx->stream_res.tg,
+				pipe_ctx->pipe_dlg_param.vready_offset,
+				pipe_ctx->pipe_dlg_param.vstartup_start,
+				pipe_ctx->pipe_dlg_param.vupdate_offset,
+				pipe_ctx->pipe_dlg_param.vupdate_width);
+
+	if (pipe_ctx->update_flags.bits.odm)
+		dc->hwss.update_odm(dc, context, pipe_ctx);
+
+	if (pipe_ctx->update_flags.bits.enable)
+		dcn20_enable_plane(dc, pipe_ctx, context);
+
+	if (pipe_ctx->update_flags.raw || pipe_ctx->plane_state->update_flags.raw)
+		dcn20_update_dchubp_dpp(dc, pipe_ctx, context);
+
+	if (pipe_ctx->update_flags.bits.enable
+			|| pipe_ctx->plane_state->update_flags.bits.sdr_white_level)
+		set_hdr_multiplier(pipe_ctx);
+
+	if (pipe_ctx->update_flags.bits.enable ||
+			pipe_ctx->plane_state->update_flags.bits.in_transfer_func_change ||
+			pipe_ctx->plane_state->update_flags.bits.gamma_change)
+		dc->hwss.set_input_transfer_func(pipe_ctx, pipe_ctx->plane_state);
+
+	/* dcn10_translate_regamma_to_hw_format takes 750us to finish
+	 * only do gamma programming for powering on, internal memcmp to avoid
+	 * updating on slave planes
+	 */
+	if (pipe_ctx->update_flags.bits.enable || pipe_ctx->stream->update_flags.bits.out_tf)
+		dc->hwss.set_output_transfer_func(pipe_ctx, pipe_ctx->stream);
+}
+
+static bool does_pipe_need_lock(struct pipe_ctx *pipe)
+{
+	if ((pipe->plane_state && pipe->plane_state->update_flags.raw)
+			|| pipe->update_flags.raw)
+		return true;
+	if (pipe->bottom_pipe)
+		return does_pipe_need_lock(pipe->bottom_pipe);
 
-	/* Program secondary blending tree and writeback pipes */
-	if ((stream->num_wb_info > 0) && (dc->hwss.program_all_writeback_pipes_in_tree))
-		dc->hwss.program_all_writeback_pipes_in_tree(dc, stream, context);
+	return false;
+}
 
-	if (interdependent_update)
-		for (i = 0; i < dc->res_pool->pipe_count; i++) {
+static void dcn20_program_front_end_for_ctx(
+		struct dc *dc,
+		struct dc_state *context)
+{
+	const unsigned int TIMEOUT_FOR_PIPE_ENABLE_MS = 100;
+	int i;
+	bool pipe_locked[MAX_PIPES] = {false};
+	DC_LOGGER_INIT(dc->ctx->logger);
+
+	/* Carry over GSL groups in case the context is changing. */
+	for (i = 0; i < dc->res_pool->pipe_count; i++)
+		if (context->res_ctx.pipe_ctx[i].stream == dc->current_state->res_ctx.pipe_ctx[i].stream)
+			context->res_ctx.pipe_ctx[i].stream_res.gsl_group =
+				dc->current_state->res_ctx.pipe_ctx[i].stream_res.gsl_group;
+
+	/* Set pipe update flags and lock pipes */
+	for (i = 0; i < dc->res_pool->pipe_count; i++)
+		dcn20_detect_pipe_changes(&dc->current_state->res_ctx.pipe_ctx[i],
+				&context->res_ctx.pipe_ctx[i]);
+	for (i = 0; i < dc->res_pool->pipe_count; i++)
+		if (!context->res_ctx.pipe_ctx[i].top_pipe &&
+				does_pipe_need_lock(&context->res_ctx.pipe_ctx[i])) {
 			struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
 
-			/* Skip inactive pipes and ones already updated */
-			if (!pipe_ctx->stream || pipe_ctx->stream == stream ||
-			    !pipe_ctx->plane_state || !tg->funcs->is_tg_enabled(tg))
-				continue;
+			if (pipe_ctx->update_flags.bits.tg_changed || pipe_ctx->update_flags.bits.enable)
+				dc->hwss.pipe_control_lock(dc, pipe_ctx, true);
+			if (!pipe_ctx->update_flags.bits.enable)
+				dc->hwss.pipe_control_lock(dc, &dc->current_state->res_ctx.pipe_ctx[i], true);
+			pipe_locked[i] = true;
+		}
 
-			pipe_ctx->plane_res.hubp->funcs->hubp_setup_interdependent(
-				pipe_ctx->plane_res.hubp,
-				&pipe_ctx->dlg_regs,
-				&pipe_ctx->ttu_regs);
+	/* OTG blank before disabling all front ends */
+	for (i = 0; i < dc->res_pool->pipe_count; i++)
+		if (context->res_ctx.pipe_ctx[i].update_flags.bits.disable
+				&& !context->res_ctx.pipe_ctx[i].top_pipe
+				&& !context->res_ctx.pipe_ctx[i].prev_odm_pipe
+				&& context->res_ctx.pipe_ctx[i].stream)
+			dc->hwss.blank_pixel_data(dc, &context->res_ctx.pipe_ctx[i], true);
+
+	/* Disconnect mpcc */
+	for (i = 0; i < dc->res_pool->pipe_count; i++)
+		if (context->res_ctx.pipe_ctx[i].update_flags.bits.disable
+				|| context->res_ctx.pipe_ctx[i].update_flags.bits.opp_changed) {
+			dc->hwss.plane_atomic_disconnect(dc, &dc->current_state->res_ctx.pipe_ctx[i]);
+			DC_LOG_DC("Reset mpcc for pipe %d\n", dc->current_state->res_ctx.pipe_ctx[i].pipe_idx);
 		}
 
-	if (interdependent_update)
-		lock_all_pipes(dc, context, false);
-	else
-		dcn20_pipe_control_lock(dc, top_pipe_to_program, false);
+	/*
+	 * Program all updated pipes, order matters for mpcc setup. Start with
+	 * top pipe and program all pipes that follow in order
+	 */
+	for (i = 0; i < dc->res_pool->pipe_count; i++) {
+		struct pipe_ctx *pipe = &context->res_ctx.pipe_ctx[i];
 
+		if (pipe->plane_state && !pipe->top_pipe) {
+			while (pipe) {
+				dcn20_program_pipe(dc, pipe, context);
+				pipe = pipe->bottom_pipe;
+			}
+			/* Program secondary blending tree and writeback pipes */
+			pipe = &context->res_ctx.pipe_ctx[i];
+			if (!pipe->prev_odm_pipe && pipe->stream->num_wb_info > 0
+					&& (pipe->update_flags.raw || pipe->plane_state->update_flags.raw || pipe->stream->update_flags.raw)
+					&& dc->hwss.program_all_writeback_pipes_in_tree)
+				dc->hwss.program_all_writeback_pipes_in_tree(dc, pipe->stream, context);
+		}
+	}
+
+	/* Unlock all locked pipes */
 	for (i = 0; i < dc->res_pool->pipe_count; i++)
-		if (removed_pipe[i])
-			dcn20_disable_plane(dc, &dc->current_state->res_ctx.pipe_ctx[i]);
+		if (pipe_locked[i]) {
+			struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
+
+			if (pipe_ctx->update_flags.bits.tg_changed || pipe_ctx->update_flags.bits.enable)
+				dc->hwss.pipe_control_lock(dc, pipe_ctx, false);
+			if (!pipe_ctx->update_flags.bits.enable)
+				dc->hwss.pipe_control_lock(dc, &dc->current_state->res_ctx.pipe_ctx[i], false);
+		}
+
+	for (i = 0; i < dc->res_pool->pipe_count; i++)
+		if (context->res_ctx.pipe_ctx[i].update_flags.bits.disable)
+			dc->hwss.disable_plane(dc, &dc->current_state->res_ctx.pipe_ctx[i]);
 
 	/*
 	 * If we are enabling a pipe, we need to wait for pending clear as this is a critical
@@ -1239,13 +1495,16 @@ static void dcn20_apply_ctx_for_surface(
 	 * will cause HW to perform an "immediate enable" (as opposed to "vsync enable") which
 	 * is unsupported on DCN.
 	 */
-	i = 0;
-	if (num_planes > 0 && top_pipe_to_program &&
-			(prev_top_pipe_to_program == NULL || prev_top_pipe_to_program->plane_state == NULL)) {
-		while (i < TIMEOUT_FOR_PIPE_ENABLE_MS &&
-				top_pipe_to_program->plane_res.hubp->funcs->hubp_is_flip_pending(top_pipe_to_program->plane_res.hubp)) {
-			i += 1;
-			msleep(1);
+	for (i = 0; i < dc->res_pool->pipe_count; i++) {
+		struct pipe_ctx *pipe = &context->res_ctx.pipe_ctx[i];
+
+		if (pipe->plane_state && !pipe->top_pipe && pipe->update_flags.bits.enable) {
+			struct hubp *hubp = pipe->plane_res.hubp;
+			int j = 0;
+
+			for (j = 0; j < TIMEOUT_FOR_PIPE_ENABLE_MS
+					&& hubp->funcs->hubp_is_flip_pending(hubp); j++)
+				msleep(1);
 		}
 	}
 }
@@ -2095,7 +2354,8 @@ void dcn20_hw_sequencer_construct(struct dc *dc)
 	dc->hwss.program_triplebuffer = dcn20_program_tripleBuffer;
 	dc->hwss.set_input_transfer_func = dcn20_set_input_transfer_func;
 	dc->hwss.set_output_transfer_func = dcn20_set_output_transfer_func;
-	dc->hwss.apply_ctx_for_surface = dcn20_apply_ctx_for_surface;
+	dc->hwss.apply_ctx_for_surface = NULL;
+	dc->hwss.program_front_end_for_ctx = dcn20_program_front_end_for_ctx;
 	dc->hwss.pipe_control_lock = dcn20_pipe_control_lock;
 	dc->hwss.pipe_control_lock_global = dcn20_pipe_control_lock_global;
 	dc->hwss.optimize_bandwidth = dcn20_optimize_bandwidth;

commit da26ded3b2fff646d28559004195abe353bce49b
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Mon Aug 26 16:57:07 2019 +0800

    drm/amdgpu/display: fix build error without CONFIG_DRM_AMD_DC_DSC_SUPPORT
    
    If CONFIG_DRM_AMD_DC_DSC_SUPPORT is not set, build fails:
    
    drivers/gpu/drm/amd/amdgpu/../display/dc/dcn20/dcn20_hwseq.c: In function dcn20_hw_sequencer_construct:
    drivers/gpu/drm/amd/amdgpu/../display/dc/dcn20/dcn20_hwseq.c:2099:28:
     error: dcn20_dsc_pg_control undeclared (first use in this function); did you mean dcn20_dpp_pg_control?
      dc->hwss.dsc_pg_control = dcn20_dsc_pg_control;
                                ^~~~~~~~~~~~~~~~~~~~
                                dcn20_dpp_pg_control
    
    Use CONFIG_DRM_AMD_DC_DSC_SUPPORT to guard this.
    
    Reported-by: Hulk Robot <hulkci@huawei.com>
    Fixes: 8a31820b1218 ("drm/amd/display: Make init_hw and init_pipes generic for seamless boot")
    Reviewed-by: Harry Wentland <harry.wentland@amd.com>
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index d1c56fe9c301..1212da12c414 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -2124,7 +2124,11 @@ void dcn20_hw_sequencer_construct(struct dc *dc)
 	dc->hwss.enable_power_gating_plane = dcn20_enable_power_gating_plane;
 	dc->hwss.dpp_pg_control = dcn20_dpp_pg_control;
 	dc->hwss.hubp_pg_control = dcn20_hubp_pg_control;
+#ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
 	dc->hwss.dsc_pg_control = dcn20_dsc_pg_control;
+#else
+	dc->hwss.dsc_pg_control = NULL;
+#endif
 	dc->hwss.disable_vga = dcn20_disable_vga;
 
 	if (IS_FPGA_MAXIMUS_DC(dc->ctx->dce_environment)) {

commit 617089d5837a3aa4167a9c4afb34929e0d52805d
Author: Jun Lei <Jun.Lei@amd.com>
Date:   Tue Jul 23 16:56:03 2019 -0400

    drm/amd/display: revert wait in pipelock
    
    [why]
    Previous workaround to prevent a vsync flip to be converted
    to immediate flip is no longer needed, and is risky because
    there are cases where it can result in infinite loop.
    
    [how]
    Remove wait loop (which is potentially infinite) before locking
    pipe
    
    Signed-off-by: Jun Lei <Jun.Lei@amd.com>
    Reviewed-by: Charlene Liu <Charlene.Liu@amd.com>
    Reviewed-by: Eric Yang <eric.yang2@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 161805bb89d3..d1c56fe9c301 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1103,17 +1103,6 @@ void dcn20_pipe_control_lock(
 	if (pipe->plane_state != NULL)
 		flip_immediate = pipe->plane_state->flip_immediate;
 
-	if (flip_immediate && lock) {
-		while (pipe->plane_res.hubp->funcs->hubp_is_flip_pending(pipe->plane_res.hubp))	{
-			udelay(1);
-		}
-
-		if (pipe->bottom_pipe != NULL)
-			while (pipe->bottom_pipe->plane_res.hubp->funcs->hubp_is_flip_pending(pipe->bottom_pipe->plane_res.hubp))	{
-				udelay(1);
-			}
-	}
-
 	/* In flip immediate and pipe splitting case, we need to use GSL
 	 * for synchronization. Only do setup on locking and on flip type change.
 	 */

commit 470e2ca569bf780f832e3020ceb5afdef16a9084
Author: Bayan Zabihiyan <bayan.zabihiyan@amd.com>
Date:   Thu Aug 8 11:08:52 2019 -0400

    drm/amd/display: Expose OTG_V_TOTAL_MID for HW Diags
    
    [Why]
    Existing HW Features, HW Diags test requested that the
    registers be exposed.
    
    [How]
    Add V_TOTAL_MID to existing DC structures.
    Make sure values are passed down throughout DC
    Add Register definition.
    Program the additional registers
    Add additional Logic for V_TOTAL_CONTROL.
    
    Signed-off-by: Bayan Zabihiyan <bayan.zabihiyan@amd.com>
    Reviewed-by: Charlene Liu <Charlene.Liu@amd.com>
    Acked-by: Anthony Koo <Anthony.Koo@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 0fb0a356323b..161805bb89d3 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -597,6 +597,8 @@ enum dc_status dcn20_enable_stream_timing(
 
 	params.vertical_total_min = stream->adjust.v_total_min;
 	params.vertical_total_max = stream->adjust.v_total_max;
+	params.vertical_total_mid = stream->adjust.v_total_mid;
+	params.vertical_total_mid_frame_num = stream->adjust.v_total_mid_frame_num;
 	if (pipe_ctx->stream_res.tg->funcs->set_drr)
 		pipe_ctx->stream_res.tg->funcs->set_drr(
 			pipe_ctx->stream_res.tg, &params);

commit 285e30049708c40a8b0221438d0300cb19a68eff
Author: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Date:   Tue Aug 6 15:10:33 2019 -0400

    drm/amd/display: fix dcn20 odm dpp programming
    
    dcn20 requires special casing for odm.
    This change treats odm as alternative to mpc tree on dcn20.
    
    This is planned to be fixed in a future refactor
    
    Signed-off-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Reviewed-by: Charlene Liu <Charlene.Liu@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index e7302587b786..0fb0a356323b 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1054,8 +1054,13 @@ static void dcn20_program_all_pipe_in_tree(
 	if (pipe_ctx->plane_state != NULL)
 		dcn20_program_pipe(dc, pipe_ctx, context);
 
-	if (pipe_ctx->bottom_pipe != NULL && pipe_ctx->bottom_pipe != pipe_ctx)
+	if (pipe_ctx->bottom_pipe != NULL) {
+		ASSERT(pipe_ctx->bottom_pipe != pipe_ctx);
 		dcn20_program_all_pipe_in_tree(dc, pipe_ctx->bottom_pipe, context);
+	} else if (pipe_ctx->next_odm_pipe != NULL) {
+		ASSERT(pipe_ctx->next_odm_pipe != pipe_ctx);
+		dcn20_program_all_pipe_in_tree(dc, pipe_ctx->next_odm_pipe, context);
+	}
 }
 
 void dcn20_pipe_control_lock_global(

commit 436d96357fa956c4723b3400d88ae47cb0e2f4cd
Author: Zi Yu Liao <ziyu.liao@amd.com>
Date:   Tue Aug 6 11:58:09 2019 -0400

    drm/amd/display: fix stuck test pattern on right half of display
    
    [why]
    With visual confirm enabled, displays where ODM combine is enabled
    has a test pattern stuck on the right half of the display even
    though the display is unblanked.
    
    [how]
    Add a condition to not show the colour ramp test pattern when the
    display is unblanked.
    
    Signed-off-by: Zi Yu Liao <ziyu.liao@amd.com>
    Reviewed-by: Eric Yang <eric.yang2@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index dc5747e34c50..e7302587b786 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -888,7 +888,7 @@ void dcn20_blank_pixel_data(
 	for (odm_pipe = pipe_ctx->next_odm_pipe; odm_pipe; odm_pipe = odm_pipe->next_odm_pipe) {
 		odm_pipe->stream_res.opp->funcs->opp_set_disp_pattern_generator(
 				odm_pipe->stream_res.opp,
-				dc->debug.visual_confirm != VISUAL_CONFIRM_DISABLE ?
+				dc->debug.visual_confirm != VISUAL_CONFIRM_DISABLE && blank ?
 						CONTROLLER_DP_TEST_PATTERN_COLORRAMP : test_pattern,
 				stream->timing.display_color_depth,
 				&black_color,

commit ee80de548b47940d4519dbf9f9388a179e99d91a
Author: Jaehyun Chung <jaehyun.chung@amd.com>
Date:   Mon Jul 29 14:48:32 2019 -0400

    drm/amd/display: Add VM page fault handle implementation
    
    [How] Allocate memory for default page and program memory block addr
    into default page addr register.
    
    Signed-off-by: Jaehyun Chung <jaehyun.chung@amd.com>
    Reviewed-by: Jun Lei <Jun.Lei@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 32ddda8600a2..dc5747e34c50 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1504,6 +1504,7 @@ static int dcn20_init_sys_ctx(struct dce_hwseq *hws, struct dc *dc, struct dc_ph
 	config.gart_config.page_table_start_addr = pa_config->gart_config.page_table_start_addr;
 	config.gart_config.page_table_end_addr = pa_config->gart_config.page_table_end_addr;
 	config.gart_config.page_table_base_addr = pa_config->gart_config.page_table_base_addr;
+	config.page_table_default_page_addr = pa_config->page_table_default_page_addr;
 
 	return dc->res_pool->hubbub->funcs->init_dchub_sys_ctx(dc->res_pool->hubbub, &config);
 }

commit 1f3324603e39d6a5a7f9f378c980dab390d9a1d5
Author: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Date:   Wed Jul 31 14:08:45 2019 -0400

    drm/amd/display: fix dp stream enable
    
    A previous odm change broke stream enable by always setting
    n_multiply as if odm was on.
    
    This fixes the check for odm by making sure opp count is >1
    rather than not 0.
    
    Signed-off-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Reviewed-by: Charlene Liu <Charlene.Liu@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 56e69a3f67fa..32ddda8600a2 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1581,10 +1581,10 @@ void dcn20_unblank_stream(struct pipe_ctx *pipe_ctx,
 	params.link_settings.link_rate = link_settings->link_rate;
 
 	if (dc_is_dp_signal(pipe_ctx->stream->signal)) {
-		if (optc1_is_two_pixels_per_containter(&stream->timing) || params.opp_cnt)
+		if (optc1_is_two_pixels_per_containter(&stream->timing) || params.opp_cnt > 1)
 			params.timing.pix_clk_100hz /= 2;
 		pipe_ctx->stream_res.stream_enc->funcs->dp_set_odm_combine(
-				pipe_ctx->stream_res.stream_enc, params.opp_cnt);
+				pipe_ctx->stream_res.stream_enc, params.opp_cnt > 1);
 		pipe_ctx->stream_res.stream_enc->funcs->dp_unblank(pipe_ctx->stream_res.stream_enc, &params);
 	}
 

commit 89cb5614736b9b5d3b833ca2237d10da6b4b0395
Author: Zi Yu Liao <ziyu.liao@amd.com>
Date:   Tue Jul 30 15:36:53 2019 -0400

    drm/amd/display: fix MPO HUBP underflow with Scatter Gather
    
    [why]
    With Scatter Gather enabled, HUBP underflows during MPO enabled video
    playback. hubp_init has a register write that fixes this problem, but
    the register is cleared when HUBP gets power gated.
    
    [how]
    Make a call to hubp_init during enable_plane, so that the fix can
    be applied after HUBP powers back on again.
    
    Signed-off-by: Zi Yu Liao <ziyu.liao@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index e9d8a7610160..56e69a3f67fa 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -934,6 +934,9 @@ void dcn20_enable_plane(
 	/* enable DCFCLK current DCHUB */
 	pipe_ctx->plane_res.hubp->funcs->hubp_clk_cntl(pipe_ctx->plane_res.hubp, true);
 
+	/* initialize HUBP on power up */
+	pipe_ctx->plane_res.hubp->funcs->hubp_init(pipe_ctx->plane_res.hubp);
+
 	/* make sure OPP_PIPE_CLOCK_EN = 1 */
 	pipe_ctx->stream_res.opp->funcs->opp_pipe_clock_control(
 			pipe_ctx->stream_res.opp,

commit 574304041bb9508a4e73533e8d1702b0e713d321
Author: Su Sung Chung <Su.Chung@amd.com>
Date:   Thu Jul 25 14:43:55 2019 -0400

    drm/amd/display: fix audio endpoint not getting disabled issue
    
    [Why]
    Disable_audio_stream gets enum option as a paramenter which will decide
    if we free acquired resources or not. However checks for the option is
    guarded by the other condition which check if audio stream is getting
    diabled more than once. With both conditions combined, if we attempt to
    disable audio stream twice in a row, first with keep and second with
    free as an option, we will never free any resources, which will make
    system think there is audio endpoint connected even after we plug out
    the device
    
    [How]
    Get rid of option as parameter to disable_audio_stream and move the part
    of the code that free acquired resources to outside where to keep or to
    free resources is actually determined
    
    Signed-off-by: Su Sung Chung <Su.Chung@amd.com>
    Reviewed-by: Jun Lei <Jun.Lei@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index e49325940fd3..e9d8a7610160 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1461,9 +1461,9 @@ void dcn20_set_dmdata_attributes(struct pipe_ctx *pipe_ctx)
 	hubp->funcs->dmdata_set_attributes(hubp, &attr);
 }
 
-void dcn20_disable_stream(struct pipe_ctx *pipe_ctx, int option)
+void dcn20_disable_stream(struct pipe_ctx *pipe_ctx)
 {
-	dce110_disable_stream(pipe_ctx, option);
+	dce110_disable_stream(pipe_ctx);
 }
 
 static void dcn20_init_vm_ctx(
@@ -1617,9 +1617,23 @@ static void dcn20_reset_back_end_for_pipe(
 	if (!IS_FPGA_MAXIMUS_DC(dc->ctx->dce_environment)) {
 		/* DPMS may already disable */
 		if (!pipe_ctx->stream->dpms_off)
-			core_link_disable_stream(pipe_ctx, FREE_ACQUIRED_RESOURCE);
-		else if (pipe_ctx->stream_res.audio) {
-			dc->hwss.disable_audio_stream(pipe_ctx, FREE_ACQUIRED_RESOURCE);
+			core_link_disable_stream(pipe_ctx);
+		else if (pipe_ctx->stream_res.audio)
+			dc->hwss.disable_audio_stream(pipe_ctx);
+
+		/* free acquired resources */
+		if (pipe_ctx->stream_res.audio) {
+			/*disable az_endpoint*/
+			pipe_ctx->stream_res.audio->funcs->az_disable(pipe_ctx->stream_res.audio);
+
+			/*free audio*/
+			if (dc->caps.dynamic_audio == true) {
+				/*we have to dynamic arbitrate the audio endpoints*/
+				/*we free the resource, need reset is_audio_acquired*/
+				update_audio_usage(&dc->current_state->res_ctx, dc->res_pool,
+						pipe_ctx->stream_res.audio, false);
+				pipe_ctx->stream_res.audio = NULL;
+			}
 		}
 	}
 #ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT

commit b1f6d01c4a3b7eeb2eb035e79d425cd6a696fa45
Author: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Date:   Tue Aug 6 17:17:28 2019 -0400

    drm/amd/display: re structure odm to allow 4 to 1 support
    
    Currently odm is handled using top_bottom pipe by special casing
    the differing opps to differentiate from mpc combine.
    
    Since top/bottom pipe list was made to track mpc muxing this creates
    difficulties in adding a 4 pipe odm case support.
    
    Rather than continue using mpc combine list, this change reworks odm
    to use it's own linked list to keep track of odm combine pipes. This
    also opens up options for using mpo with odm, if a practical use case
    is ever found.
    
    Signed-off-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Reviewed-by: Charlene Liu <Charlene.Liu@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index e146d1d8d45e..e49325940fd3 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -529,11 +529,9 @@ enum dc_status dcn20_enable_stream_timing(
 	struct dc_stream_state *stream = pipe_ctx->stream;
 	struct drr_params params = {0};
 	unsigned int event_triggers = 0;
-
-
-#if defined(CONFIG_DRM_AMD_DC_DCN2_0)
-	struct pipe_ctx *odm_pipe = dc_res_get_odm_bottom_pipe(pipe_ctx);
-#endif
+	struct pipe_ctx *odm_pipe;
+	int opp_cnt = 1;
+	int opp_inst[MAX_PIPES] = { pipe_ctx->stream_res.opp->inst };
 
 	/* by upper caller loop, pipe0 is parent pipe and be called first.
 	 * back end is set up by for pipe0. Other children pipe share back end
@@ -544,14 +542,17 @@ enum dc_status dcn20_enable_stream_timing(
 
 	/* TODO check if timing_changed, disable stream if timing changed */
 
-	if (odm_pipe) {
-		int opp_inst[2] = { pipe_ctx->stream_res.opp->inst, odm_pipe->stream_res.opp->inst };
+	for (odm_pipe = pipe_ctx->next_odm_pipe; odm_pipe; odm_pipe = odm_pipe->next_odm_pipe) {
+		opp_inst[opp_cnt] = odm_pipe->stream_res.opp->inst;
+		opp_cnt++;
+	}
 
+	if (opp_cnt > 1)
 		pipe_ctx->stream_res.tg->funcs->set_odm_combine(
 				pipe_ctx->stream_res.tg,
-				opp_inst, 2,
+				opp_inst, opp_cnt,
 				&pipe_ctx->stream->timing);
-	}
+
 	/* HW program guide assume display already disable
 	 * by unplug sequence. OTG assume stop.
 	 */
@@ -575,7 +576,7 @@ enum dc_status dcn20_enable_stream_timing(
 			pipe_ctx->stream->signal,
 			true);
 
-	if (odm_pipe)
+	for (odm_pipe = pipe_ctx->next_odm_pipe; odm_pipe; odm_pipe = odm_pipe->next_odm_pipe)
 		odm_pipe->stream_res.opp->funcs->opp_pipe_clock_control(
 				odm_pipe->stream_res.opp,
 				true);
@@ -661,7 +662,7 @@ bool dcn20_set_output_transfer_func(struct pipe_ctx *pipe_ctx,
 	 */
 	if (mpc->funcs->power_on_mpc_mem_pwr)
 		mpc->funcs->power_on_mpc_mem_pwr(mpc, mpcc_id, true);
-	if ((pipe_ctx->top_pipe == NULL || dc_res_is_odm_head_pipe(pipe_ctx))
+	if (pipe_ctx->top_pipe == NULL
 			&& mpc->funcs->set_output_gamma && stream->out_transfer_func) {
 		if (stream->out_transfer_func->type == TF_TYPE_HWPWL)
 			params = &stream->out_transfer_func->pwl;
@@ -823,17 +824,21 @@ bool dcn20_set_input_transfer_func(struct pipe_ctx *pipe_ctx,
 
 static void dcn20_update_odm(struct dc *dc, struct dc_state *context, struct pipe_ctx *pipe_ctx)
 {
-	struct pipe_ctx *combine_pipe = dc_res_get_odm_bottom_pipe(pipe_ctx);
+	struct pipe_ctx *odm_pipe;
+	int opp_cnt = 1;
+	int opp_inst[MAX_PIPES] = { pipe_ctx->stream_res.opp->inst };
 
-	if (combine_pipe) {
-		int opp_inst[2] = { pipe_ctx->stream_res.opp->inst,
-				combine_pipe->stream_res.opp->inst };
+	for (odm_pipe = pipe_ctx->next_odm_pipe; odm_pipe; odm_pipe = odm_pipe->next_odm_pipe) {
+		opp_inst[opp_cnt] = odm_pipe->stream_res.opp->inst;
+		opp_cnt++;
+	}
 
+	if (opp_cnt > 1)
 		pipe_ctx->stream_res.tg->funcs->set_odm_combine(
 				pipe_ctx->stream_res.tg,
-				opp_inst, 2,
+				opp_inst, opp_cnt,
 				&pipe_ctx->stream->timing);
-	} else
+	else
 		pipe_ctx->stream_res.tg->funcs->set_odm_bypass(
 				pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);
 }
@@ -848,7 +853,8 @@ void dcn20_blank_pixel_data(
 	struct dc_stream_state *stream = pipe_ctx->stream;
 	enum dc_color_space color_space = stream->output_color_space;
 	enum controller_dp_test_pattern test_pattern = CONTROLLER_DP_TEST_PATTERN_SOLID_COLOR;
-	struct pipe_ctx *bot_odm_pipe = dc_res_get_odm_bottom_pipe(pipe_ctx);
+	struct pipe_ctx *odm_pipe;
+	int odm_cnt = 1;
 
 	int width = stream->timing.h_addressable + stream->timing.h_border_left + stream->timing.h_border_right;
 	int height = stream->timing.v_addressable + stream->timing.v_border_bottom + stream->timing.v_border_top;
@@ -856,8 +862,10 @@ void dcn20_blank_pixel_data(
 	/* get opp dpg blank color */
 	color_space_to_black_color(dc, color_space, &black_color);
 
-	if (bot_odm_pipe)
-		width = width / 2;
+	for (odm_pipe = pipe_ctx->next_odm_pipe; odm_pipe; odm_pipe = odm_pipe->next_odm_pipe)
+		odm_cnt++;
+
+	width = width / odm_cnt;
 
 	if (blank) {
 		if (stream_res->abm)
@@ -877,9 +885,9 @@ void dcn20_blank_pixel_data(
 			width,
 			height);
 
-	if (bot_odm_pipe) {
-		bot_odm_pipe->stream_res.opp->funcs->opp_set_disp_pattern_generator(
-				bot_odm_pipe->stream_res.opp,
+	for (odm_pipe = pipe_ctx->next_odm_pipe; odm_pipe; odm_pipe = odm_pipe->next_odm_pipe) {
+		odm_pipe->stream_res.opp->funcs->opp_set_disp_pattern_generator(
+				odm_pipe->stream_res.opp,
 				dc->debug.visual_confirm != VISUAL_CONFIRM_DISABLE ?
 						CONTROLLER_DP_TEST_PATTERN_COLORRAMP : test_pattern,
 				stream->timing.display_color_depth,
@@ -1021,7 +1029,7 @@ static void dcn20_program_all_pipe_in_tree(
 		struct pipe_ctx *pipe_ctx,
 		struct dc_state *context)
 {
-	if (pipe_ctx->top_pipe == NULL) {
+	if (pipe_ctx->top_pipe == NULL && !pipe_ctx->prev_odm_pipe) {
 		bool blank = !is_pipe_tree_visible(pipe_ctx);
 
 		pipe_ctx->stream_res.tg->funcs->program_global_sync(
@@ -1312,8 +1320,8 @@ bool dcn20_update_bandwidth(
 
 			pipe_ctx->stream_res.tg->funcs->set_vtg_params(
 					pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);
-
-			dc->hwss.blank_pixel_data(dc, pipe_ctx, blank);
+			if (pipe_ctx->prev_odm_pipe == NULL)
+				dc->hwss.blank_pixel_data(dc, pipe_ctx, blank);
 		}
 
 		pipe_ctx->plane_res.hubp->funcs->hubp_setup(
@@ -1403,12 +1411,15 @@ static void dcn20_disable_stream_gating(struct dc *dc, struct pipe_ctx *pipe_ctx
 {
 #ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
 	struct dce_hwseq *hws = dc->hwseq;
-	struct pipe_ctx *bot_odm_pipe = dc_res_get_odm_bottom_pipe(pipe_ctx);
 
 	if (pipe_ctx->stream_res.dsc) {
+		struct pipe_ctx *odm_pipe = pipe_ctx->next_odm_pipe;
+
 		dcn20_dsc_pg_control(hws, pipe_ctx->stream_res.dsc->inst, true);
-		if (bot_odm_pipe)
-			dcn20_dsc_pg_control(hws, bot_odm_pipe->stream_res.dsc->inst, true);
+		while (odm_pipe) {
+			dcn20_dsc_pg_control(hws, odm_pipe->stream_res.dsc->inst, true);
+			odm_pipe = odm_pipe->next_odm_pipe;
+		}
 	}
 #endif
 }
@@ -1417,12 +1428,15 @@ static void dcn20_enable_stream_gating(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
 #ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
 	struct dce_hwseq *hws = dc->hwseq;
-	struct pipe_ctx *bot_odm_pipe = dc_res_get_odm_bottom_pipe(pipe_ctx);
 
 	if (pipe_ctx->stream_res.dsc) {
+		struct pipe_ctx *odm_pipe = pipe_ctx->next_odm_pipe;
+
 		dcn20_dsc_pg_control(hws, pipe_ctx->stream_res.dsc->inst, false);
-		if (bot_odm_pipe)
-			dcn20_dsc_pg_control(hws, bot_odm_pipe->stream_res.dsc->inst, false);
+		while (odm_pipe) {
+			dcn20_dsc_pg_control(hws, odm_pipe->stream_res.dsc->inst, false);
+			odm_pipe = odm_pipe->next_odm_pipe;
+		}
 	}
 #endif
 }
@@ -1552,18 +1566,22 @@ void dcn20_unblank_stream(struct pipe_ctx *pipe_ctx,
 	struct encoder_unblank_param params = { { 0 } };
 	struct dc_stream_state *stream = pipe_ctx->stream;
 	struct dc_link *link = stream->link;
-	params.odm = dc_res_get_odm_bottom_pipe(pipe_ctx);
+	struct pipe_ctx *odm_pipe;
 
+	params.opp_cnt = 1;
+	for (odm_pipe = pipe_ctx->next_odm_pipe; odm_pipe; odm_pipe = odm_pipe->next_odm_pipe) {
+		params.opp_cnt++;
+	}
 	/* only 3 items below are used by unblank */
 	params.timing = pipe_ctx->stream->timing;
 
 	params.link_settings.link_rate = link_settings->link_rate;
 
 	if (dc_is_dp_signal(pipe_ctx->stream->signal)) {
-		if (optc1_is_two_pixels_per_containter(&stream->timing) || params.odm)
+		if (optc1_is_two_pixels_per_containter(&stream->timing) || params.opp_cnt)
 			params.timing.pix_clk_100hz /= 2;
 		pipe_ctx->stream_res.stream_enc->funcs->dp_set_odm_combine(
-				pipe_ctx->stream_res.stream_enc, params.odm);
+				pipe_ctx->stream_res.stream_enc, params.opp_cnt);
 		pipe_ctx->stream_res.stream_enc->funcs->dp_unblank(pipe_ctx->stream_res.stream_enc, &params);
 	}
 
@@ -1654,7 +1672,7 @@ static void dcn20_reset_hw_ctx_wrap(
 		if (!pipe_ctx_old->stream)
 			continue;
 
-		if (pipe_ctx_old->top_pipe)
+		if (pipe_ctx_old->top_pipe || pipe_ctx_old->prev_odm_pipe)
 			continue;
 
 		if (!pipe_ctx->stream ||

commit 4c3cfe14c04eac5e96f1aef7e2b84ce56a61e897
Author: David Francis <David.Francis@amd.com>
Date:   Thu May 23 14:06:08 2019 -0400

    Revert "drm/amd/display: add global master update lock for DCN2"
    
    This reverts commit 6c5be4ac630805d3a3b20157a0c6421ef815fe78.
    
    This commit was accidentally promoted twice
    
    Signed-off-by: David Francis <David.Francis@amd.com>
    Reviewed-by: Roman Li <Roman.Li@amd.com>
    Reviewed-by: Harry Wentland <harry.wentland@amd.com>
    Reviewed-by: Nicholas Kazlauskas <nicholas.kazlauskas@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index fa8a73f6c8e3..e146d1d8d45e 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -575,10 +575,6 @@ enum dc_status dcn20_enable_stream_timing(
 			pipe_ctx->stream->signal,
 			true);
 
-	if (pipe_ctx->stream_res.tg->funcs->setup_global_lock)
-		pipe_ctx->stream_res.tg->funcs->setup_global_lock(
-				pipe_ctx->stream_res.tg);
-
 	if (odm_pipe)
 		odm_pipe->stream_res.opp->funcs->opp_pipe_clock_control(
 				odm_pipe->stream_res.opp,

commit 79e005204f75b54db9e42a39b3f66fac2ba190b9
Author: Charlene Liu <charlene.liu@amd.com>
Date:   Mon Jul 29 11:59:33 2019 -0400

    drm/amd/display: enable dcn_mem_pwr as golden setting updates
    
    Enable dcn_mem_pwr as golden setting updates
    
    Signed-off-by: Charlene Liu <charlene.liu@amd.com>
    Reviewed-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 4e9ac051d3d8..fa8a73f6c8e3 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -142,8 +142,7 @@ void dcn20_display_init(struct dc *dc)
 	/* DCCG */
 	dcn20_dccg_init(hws);
 
-	/* Disable all memory low power mode. All memories are enabled. */
-	REG_UPDATE(DC_MEM_GLOBAL_PWR_REQ_CNTL, DC_MEM_GLOBAL_PWR_REQ_DIS, 1);
+	REG_UPDATE(DC_MEM_GLOBAL_PWR_REQ_CNTL, DC_MEM_GLOBAL_PWR_REQ_DIS, 0);
 
 	/* DCHUB/MMHUBBUB
 	 * set global timer refclk divider

commit 544618596fd58848f5f881e265a09320e91f2e97
Author: Charlene Liu <charlene.liu@amd.com>
Date:   Wed Jul 24 18:14:46 2019 -0400

    drm/amd/display: wake up ogam mem pwr before programming ocsc
    
    [Description]
    OGAM_MEM_PWR could stay in light up when driver woke up to update gamma.
    either disable MEM_LOW power feature or set to OGAM_bypass could make artificial color distortion goes away.
    Easy reproduce after LOW_MEM Power feature enables and resume from S3.
    
    Signed-off-by: Charlene Liu <charlene.liu@amd.com>
    Reviewed-by: Julian Parkin <jparkin@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 5904d4d329df..4e9ac051d3d8 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -631,6 +631,10 @@ void dcn20_program_output_csc(struct dc *dc,
 {
 	struct mpc *mpc = dc->res_pool->mpc;
 	enum mpc_output_csc_mode ocsc_mode = MPC_OUTPUT_CSC_COEF_A;
+	int mpcc_id = pipe_ctx->plane_res.hubp->inst;
+
+	if (mpc->funcs->power_on_mpc_mem_pwr)
+		mpc->funcs->power_on_mpc_mem_pwr(mpc, mpcc_id, true);
 
 	if (pipe_ctx->stream->csc_color_matrix.enable_adjustment == true) {
 		if (mpc->funcs->set_output_csc != NULL)
@@ -660,6 +664,8 @@ bool dcn20_set_output_transfer_func(struct pipe_ctx *pipe_ctx,
 	 * if programming for all pipes is required then remove condition
 	 * pipe_ctx->top_pipe == NULL ,but then fix the diagnostic.
 	 */
+	if (mpc->funcs->power_on_mpc_mem_pwr)
+		mpc->funcs->power_on_mpc_mem_pwr(mpc, mpcc_id, true);
 	if ((pipe_ctx->top_pipe == NULL || dc_res_is_odm_head_pipe(pipe_ctx))
 			&& mpc->funcs->set_output_gamma && stream->out_transfer_func) {
 		if (stream->out_transfer_func->type == TF_TYPE_HWPWL)

commit 2b162fd3024997b97c95290b0a8ed08d914f115d
Author: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Date:   Fri Jul 19 11:43:39 2019 -0400

    drm/amd/display: update optc odm interface for more than 2 opps
    
    Current optc odm interface only accepts 2 opps, we need to
    expand this to allow 4 to 1 odm combine.
    
    Signed-off-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Reviewed-by: Charlene Liu <Charlene.Liu@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index c3635f5cd990..5904d4d329df 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -545,12 +545,14 @@ enum dc_status dcn20_enable_stream_timing(
 
 	/* TODO check if timing_changed, disable stream if timing changed */
 
-	if (odm_pipe)
+	if (odm_pipe) {
+		int opp_inst[2] = { pipe_ctx->stream_res.opp->inst, odm_pipe->stream_res.opp->inst };
+
 		pipe_ctx->stream_res.tg->funcs->set_odm_combine(
 				pipe_ctx->stream_res.tg,
-				odm_pipe->stream_res.opp->inst,
-				pipe_ctx->stream->timing.h_addressable/2,
-				pipe_ctx->stream->timing.pixel_encoding);
+				opp_inst, 2,
+				&pipe_ctx->stream->timing);
+	}
 	/* HW program guide assume display already disable
 	 * by unplug sequence. OTG assume stop.
 	 */
@@ -822,13 +824,15 @@ static void dcn20_update_odm(struct dc *dc, struct dc_state *context, struct pip
 {
 	struct pipe_ctx *combine_pipe = dc_res_get_odm_bottom_pipe(pipe_ctx);
 
-	if (combine_pipe)
+	if (combine_pipe) {
+		int opp_inst[2] = { pipe_ctx->stream_res.opp->inst,
+				combine_pipe->stream_res.opp->inst };
+
 		pipe_ctx->stream_res.tg->funcs->set_odm_combine(
 				pipe_ctx->stream_res.tg,
-				combine_pipe->stream_res.opp->inst,
-				pipe_ctx->plane_res.scl_data.h_active,
-				pipe_ctx->stream->timing.pixel_encoding);
-	else
+				opp_inst, 2,
+				&pipe_ctx->stream->timing);
+	} else
 		pipe_ctx->stream_res.tg->funcs->set_odm_bypass(
 				pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);
 }

commit 8a31820b12187c7e31c52e8a00075359d9efac52
Author: Martin Leung <martin.leung@amd.com>
Date:   Tue Jul 9 15:15:17 2019 -0400

    drm/amd/display: Make init_hw and init_pipes generic for seamless boot
    
    [Why]
    For seamless boot the init_hw sequence must be split into
    actual hardware vs pipes, in order to defer pipe initialization to set mode
    and skip of pipe-destructive sequences
    
    [How]
    made dcn10_init_hw and dcn10_init_pipes generic for future dcns to inherit
    deleted dcn20 specific versions. This is part 1 of a 2 partimplementation
    of seamless boot
    
    Signed-off-by: Martin Leung <martin.leung@amd.com>
    Reviewed-by: Jun Lei <Jun.Lei@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index c11de6f0fe5c..c3635f5cd990 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -64,23 +64,7 @@
 #define FN(reg_name, field_name) \
 	hws->shifts->field_name, hws->masks->field_name
 
-static void bios_golden_init(struct dc *dc)
-{
-	struct dc_bios *bp = dc->ctx->dc_bios;
-	int i;
-
-	/* initialize dcn global */
-	bp->funcs->enable_disp_power_gating(bp,
-			CONTROLLER_ID_D0, ASIC_PIPE_INIT);
-
-	for (i = 0; i < dc->res_pool->pipe_count; i++) {
-		/* initialize dcn per pipe */
-		bp->funcs->enable_disp_power_gating(bp,
-				CONTROLLER_ID_D0 + i, ASIC_PIPE_DISABLE);
-	}
-}
-
-static void enable_power_gating_plane(
+static void dcn20_enable_power_gating_plane(
 	struct dce_hwseq *hws,
 	bool enable)
 {
@@ -184,7 +168,7 @@ void dcn20_display_init(struct dc *dc)
 	REG_WRITE(AZALIA_CONTROLLER_CLOCK_GATING, 0x1);
 }
 
-static void disable_vga(
+void dcn20_disable_vga(
 	struct dce_hwseq *hws)
 {
 	REG_WRITE(D1VGA_CONTROL, 0);
@@ -487,29 +471,6 @@ static void dcn20_hubp_pg_control(
 }
 
 
-
-static void dcn20_plane_atomic_power_down(struct dc *dc, struct pipe_ctx *pipe_ctx)
-{
-	struct dce_hwseq *hws = dc->hwseq;
-	struct dpp *dpp = pipe_ctx->plane_res.dpp;
-
-	DC_LOGGER_INIT(dc->ctx->logger);
-
-	if (REG(DC_IP_REQUEST_CNTL)) {
-		REG_SET(DC_IP_REQUEST_CNTL, 0,
-				IP_REQUEST_EN, 1);
-		dcn20_dpp_pg_control(hws, dpp->inst, false);
-		dcn20_hubp_pg_control(hws, pipe_ctx->plane_res.hubp->inst, false);
-		dpp->funcs->dpp_reset(dpp);
-		REG_SET(DC_IP_REQUEST_CNTL, 0,
-				IP_REQUEST_EN, 0);
-		DC_LOG_DEBUG(
-				"Power gated front end %d\n", pipe_ctx->pipe_idx);
-	}
-}
-
-
-
 /* disable HW used by plane.
  * note:  cannot disable until disconnect is complete
  */
@@ -535,7 +496,9 @@ static void dcn20_plane_atomic_disable(struct dc *dc, struct pipe_ctx *pipe_ctx)
 	hubp->power_gated = true;
 	dc->optimized_required = false; /* We're powering off, no need to optimize */
 
-	dcn20_plane_atomic_power_down(dc, pipe_ctx);
+	dc->hwss.plane_atomic_power_down(dc,
+			pipe_ctx->plane_res.dpp,
+			pipe_ctx->plane_res.hubp);
 
 	pipe_ctx->stream = NULL;
 	memset(&pipe_ctx->stream_res, 0, sizeof(pipe_ctx->stream_res));
@@ -559,204 +522,6 @@ void dcn20_disable_plane(struct dc *dc, struct pipe_ctx *pipe_ctx)
 					pipe_ctx->pipe_idx);
 }
 
-static void dcn20_init_hw(struct dc *dc)
-{
-	int i, j;
-	struct abm *abm = dc->res_pool->abm;
-	struct dmcu *dmcu = dc->res_pool->dmcu;
-	struct dce_hwseq *hws = dc->hwseq;
-	struct dc_bios *dcb = dc->ctx->dc_bios;
-	struct resource_pool *res_pool = dc->res_pool;
-	struct dc_state  *context = dc->current_state;
-
-	if (dc->clk_mgr && dc->clk_mgr->funcs->init_clocks)
-		dc->clk_mgr->funcs->init_clocks(dc->clk_mgr);
-
-	// Initialize the dccg
-	if (res_pool->dccg->funcs->dccg_init)
-		res_pool->dccg->funcs->dccg_init(res_pool->dccg);
-
-	//Enable ability to power gate / don't force power on permanently
-	enable_power_gating_plane(dc->hwseq, true);
-
-	if (IS_FPGA_MAXIMUS_DC(dc->ctx->dce_environment)) {
-		REG_WRITE(RBBMIF_TIMEOUT_DIS, 0xFFFFFFFF);
-		REG_WRITE(RBBMIF_TIMEOUT_DIS_2, 0xFFFFFFFF);
-
-		dcn20_dccg_init(hws);
-
-		REG_UPDATE(DCHUBBUB_GLOBAL_TIMER_CNTL, DCHUBBUB_GLOBAL_TIMER_REFDIV, 2);
-		REG_UPDATE(DCHUBBUB_GLOBAL_TIMER_CNTL, DCHUBBUB_GLOBAL_TIMER_ENABLE, 1);
-		REG_WRITE(REFCLK_CNTL, 0);
-	} else {
-		if (!dcb->funcs->is_accelerated_mode(dcb)) {
-			bios_golden_init(dc);
-			if (dc->ctx->dc_bios->fw_info_valid) {
-				res_pool->ref_clocks.xtalin_clock_inKhz =
-						dc->ctx->dc_bios->fw_info.pll_info.crystal_frequency;
-
-				if (!IS_FPGA_MAXIMUS_DC(dc->ctx->dce_environment)) {
-					if (res_pool->dccg && res_pool->hubbub) {
-
-						(res_pool->dccg->funcs->get_dccg_ref_freq)(res_pool->dccg,
-								dc->ctx->dc_bios->fw_info.pll_info.crystal_frequency,
-								&res_pool->ref_clocks.dccg_ref_clock_inKhz);
-
-						(res_pool->hubbub->funcs->get_dchub_ref_freq)(res_pool->hubbub,
-								res_pool->ref_clocks.dccg_ref_clock_inKhz,
-								&res_pool->ref_clocks.dchub_ref_clock_inKhz);
-					} else {
-						// Not all ASICs have DCCG sw component
-						res_pool->ref_clocks.dccg_ref_clock_inKhz =
-								res_pool->ref_clocks.xtalin_clock_inKhz;
-						res_pool->ref_clocks.dchub_ref_clock_inKhz =
-								res_pool->ref_clocks.xtalin_clock_inKhz;
-					}
-				}
-			} else
-				ASSERT_CRITICAL(false);
-			disable_vga(dc->hwseq);
-		}
-
-		for (i = 0; i < dc->link_count; i++) {
-			/* Power up AND update implementation according to the
-			 * required signal (which may be different from the
-			 * default signal on connector).
-			 */
-			struct dc_link *link = dc->links[i];
-
-			link->link_enc->funcs->hw_init(link->link_enc);
-		}
-	}
-
-#ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
-	/* Power gate DSCs */
-	for (i = 0; i < res_pool->res_cap->num_dsc; i++)
-		dcn20_dsc_pg_control(hws, res_pool->dscs[i]->inst, false);
-#endif
-
-	/* Blank pixel data with OPP DPG */
-	for (i = 0; i < dc->res_pool->timing_generator_count; i++) {
-		struct timing_generator *tg = dc->res_pool->timing_generators[i];
-
-		if (tg->funcs->is_tg_enabled(tg)) {
-			dcn20_init_blank(dc, tg);
-		}
-	}
-
-	for (i = 0; i < res_pool->timing_generator_count; i++) {
-		struct timing_generator *tg = dc->res_pool->timing_generators[i];
-
-		if (tg->funcs->is_tg_enabled(tg))
-			tg->funcs->lock(tg);
-	}
-
-	for (i = 0; i < dc->res_pool->pipe_count; i++) {
-		struct dpp *dpp = res_pool->dpps[i];
-
-		dpp->funcs->dpp_reset(dpp);
-	}
-
-	/* Reset all MPCC muxes */
-	res_pool->mpc->funcs->mpc_init(res_pool->mpc);
-
-	/* initialize OPP mpc_tree parameter */
-	for (i = 0; i < dc->res_pool->res_cap->num_opp; i++) {
-		res_pool->opps[i]->mpc_tree_params.opp_id = res_pool->opps[i]->inst;
-		res_pool->opps[i]->mpc_tree_params.opp_list = NULL;
-		for (j = 0; j < MAX_PIPES; j++)
-			res_pool->opps[i]->mpcc_disconnect_pending[j] = false;
-	}
-
-	for (i = 0; i < dc->res_pool->pipe_count; i++) {
-		struct timing_generator *tg = dc->res_pool->timing_generators[i];
-		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
-		struct hubp *hubp = dc->res_pool->hubps[i];
-		struct dpp *dpp = dc->res_pool->dpps[i];
-
-		pipe_ctx->stream_res.tg = tg;
-		pipe_ctx->pipe_idx = i;
-
-		pipe_ctx->plane_res.hubp = hubp;
-		pipe_ctx->plane_res.dpp = dpp;
-		pipe_ctx->plane_res.mpcc_inst = dpp->inst;
-		hubp->mpcc_id = dpp->inst;
-		hubp->opp_id = OPP_ID_INVALID;
-		hubp->power_gated = false;
-		pipe_ctx->stream_res.opp = NULL;
-
-		hubp->funcs->hubp_init(hubp);
-
-		//dc->res_pool->opps[i]->mpc_tree_params.opp_id = dc->res_pool->opps[i]->inst;
-		//dc->res_pool->opps[i]->mpc_tree_params.opp_list = NULL;
-		dc->res_pool->opps[i]->mpcc_disconnect_pending[pipe_ctx->plane_res.mpcc_inst] = true;
-		pipe_ctx->stream_res.opp = dc->res_pool->opps[i];
-		/*to do*/
-		hwss1_plane_atomic_disconnect(dc, pipe_ctx);
-	}
-
-	/* initialize DWB pointer to MCIF_WB */
-	for (i = 0; i < res_pool->res_cap->num_dwb; i++)
-		res_pool->dwbc[i]->mcif = res_pool->mcif_wb[i];
-
-	for (i = 0; i < dc->res_pool->timing_generator_count; i++) {
-		struct timing_generator *tg = dc->res_pool->timing_generators[i];
-
-		if (tg->funcs->is_tg_enabled(tg))
-			tg->funcs->unlock(tg);
-	}
-
-	for (i = 0; i < dc->res_pool->pipe_count; i++) {
-		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
-
-		dc->hwss.disable_plane(dc, pipe_ctx);
-
-		pipe_ctx->stream_res.tg = NULL;
-		pipe_ctx->plane_res.hubp = NULL;
-	}
-
-	for (i = 0; i < dc->res_pool->timing_generator_count; i++) {
-		struct timing_generator *tg = dc->res_pool->timing_generators[i];
-
-		tg->funcs->tg_init(tg);
-	}
-
-	/* end of FPGA. Below if real ASIC */
-	if (IS_FPGA_MAXIMUS_DC(dc->ctx->dce_environment))
-		return;
-
-
-	for (i = 0; i < res_pool->audio_count; i++) {
-		struct audio *audio = res_pool->audios[i];
-
-		audio->funcs->hw_init(audio);
-	}
-
-	if (abm != NULL) {
-		abm->funcs->init_backlight(abm);
-		abm->funcs->abm_init(abm);
-	}
-
-	if (dmcu != NULL)
-		dmcu->funcs->dmcu_init(dmcu);
-
-	if (abm != NULL && dmcu != NULL)
-		abm->dmcu_is_running = dmcu->funcs->is_dmcu_initialized(dmcu);
-
-	/* power AFMT HDMI memory TODO: may move to dis/en output save power*/
-	REG_WRITE(DIO_MEM_PWR_CTRL, 0);
-
-	if (!dc->debug.disable_clock_gate) {
-		/* enable all DCN clock gating */
-		REG_WRITE(DCCG_GATE_DISABLE_CNTL, 0);
-
-		REG_WRITE(DCCG_GATE_DISABLE_CNTL2, 0);
-
-		REG_UPDATE(DCFCLK_CNTL, DCFCLK_GATE_DIS, 0);
-	}
-
-}
-
 enum dc_status dcn20_enable_stream_timing(
 		struct pipe_ctx *pipe_ctx,
 		struct dc_state *context,
@@ -1409,7 +1174,7 @@ static void dcn20_apply_ctx_for_surface(
 			if (old_pipe_ctx->stream_res.tg == tg &&
 			    old_pipe_ctx->plane_res.hubp &&
 			    old_pipe_ctx->plane_res.hubp->opp_id != OPP_ID_INVALID)
-				dcn20_disable_plane(dc, old_pipe_ctx);
+				dc->hwss.disable_plane(dc, old_pipe_ctx);
 		}
 
 		if ((!pipe_ctx->plane_state ||
@@ -2169,14 +1934,126 @@ static void dcn20_program_dmdata_engine(struct pipe_ctx *pipe_ctx)
 						hubp->inst, mode);
 }
 
+static void dcn20_fpga_init_hw(struct dc *dc)
+{
+	int i, j;
+	struct dce_hwseq *hws = dc->hwseq;
+	struct resource_pool *res_pool = dc->res_pool;
+	struct dc_state  *context = dc->current_state;
+
+	if (dc->clk_mgr && dc->clk_mgr->funcs->init_clocks)
+		dc->clk_mgr->funcs->init_clocks(dc->clk_mgr);
+
+	// Initialize the dccg
+	if (res_pool->dccg->funcs->dccg_init)
+		res_pool->dccg->funcs->dccg_init(res_pool->dccg);
+
+	//Enable ability to power gate / don't force power on permanently
+	dc->hwss.enable_power_gating_plane(hws, true);
+
+	// Specific to FPGA dccg and registers
+	REG_WRITE(RBBMIF_TIMEOUT_DIS, 0xFFFFFFFF);
+	REG_WRITE(RBBMIF_TIMEOUT_DIS_2, 0xFFFFFFFF);
+
+	dcn20_dccg_init(hws);
+
+	REG_UPDATE(DCHUBBUB_GLOBAL_TIMER_CNTL, DCHUBBUB_GLOBAL_TIMER_REFDIV, 2);
+	REG_UPDATE(DCHUBBUB_GLOBAL_TIMER_CNTL, DCHUBBUB_GLOBAL_TIMER_ENABLE, 1);
+	REG_WRITE(REFCLK_CNTL, 0);
+	//
+
+
+	/* Blank pixel data with OPP DPG */
+	for (i = 0; i < dc->res_pool->timing_generator_count; i++) {
+		struct timing_generator *tg = dc->res_pool->timing_generators[i];
+
+		if (tg->funcs->is_tg_enabled(tg))
+			dcn20_init_blank(dc, tg);
+	}
+
+	for (i = 0; i < res_pool->timing_generator_count; i++) {
+		struct timing_generator *tg = dc->res_pool->timing_generators[i];
+
+		if (tg->funcs->is_tg_enabled(tg))
+			tg->funcs->lock(tg);
+	}
+
+	for (i = 0; i < dc->res_pool->pipe_count; i++) {
+		struct dpp *dpp = res_pool->dpps[i];
+
+		dpp->funcs->dpp_reset(dpp);
+	}
+
+	/* Reset all MPCC muxes */
+	res_pool->mpc->funcs->mpc_init(res_pool->mpc);
+
+	/* initialize OPP mpc_tree parameter */
+	for (i = 0; i < dc->res_pool->res_cap->num_opp; i++) {
+		res_pool->opps[i]->mpc_tree_params.opp_id = res_pool->opps[i]->inst;
+		res_pool->opps[i]->mpc_tree_params.opp_list = NULL;
+		for (j = 0; j < MAX_PIPES; j++)
+			res_pool->opps[i]->mpcc_disconnect_pending[j] = false;
+	}
+
+	for (i = 0; i < dc->res_pool->pipe_count; i++) {
+		struct timing_generator *tg = dc->res_pool->timing_generators[i];
+		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
+		struct hubp *hubp = dc->res_pool->hubps[i];
+		struct dpp *dpp = dc->res_pool->dpps[i];
+
+		pipe_ctx->stream_res.tg = tg;
+		pipe_ctx->pipe_idx = i;
+
+		pipe_ctx->plane_res.hubp = hubp;
+		pipe_ctx->plane_res.dpp = dpp;
+		pipe_ctx->plane_res.mpcc_inst = dpp->inst;
+		hubp->mpcc_id = dpp->inst;
+		hubp->opp_id = OPP_ID_INVALID;
+		hubp->power_gated = false;
+		pipe_ctx->stream_res.opp = NULL;
+
+		hubp->funcs->hubp_init(hubp);
+
+		//dc->res_pool->opps[i]->mpc_tree_params.opp_id = dc->res_pool->opps[i]->inst;
+		//dc->res_pool->opps[i]->mpc_tree_params.opp_list = NULL;
+		dc->res_pool->opps[i]->mpcc_disconnect_pending[pipe_ctx->plane_res.mpcc_inst] = true;
+		pipe_ctx->stream_res.opp = dc->res_pool->opps[i];
+		/*to do*/
+		hwss1_plane_atomic_disconnect(dc, pipe_ctx);
+	}
+
+	/* initialize DWB pointer to MCIF_WB */
+	for (i = 0; i < res_pool->res_cap->num_dwb; i++)
+		res_pool->dwbc[i]->mcif = res_pool->mcif_wb[i];
+
+	for (i = 0; i < dc->res_pool->timing_generator_count; i++) {
+		struct timing_generator *tg = dc->res_pool->timing_generators[i];
+
+		if (tg->funcs->is_tg_enabled(tg))
+			tg->funcs->unlock(tg);
+	}
+
+	for (i = 0; i < dc->res_pool->pipe_count; i++) {
+		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
+
+		dc->hwss.disable_plane(dc, pipe_ctx);
+
+		pipe_ctx->stream_res.tg = NULL;
+		pipe_ctx->plane_res.hubp = NULL;
+	}
+
+	for (i = 0; i < dc->res_pool->timing_generator_count; i++) {
+		struct timing_generator *tg = dc->res_pool->timing_generators[i];
+
+		tg->funcs->tg_init(tg);
+	}
+}
+
 void dcn20_hw_sequencer_construct(struct dc *dc)
 {
 	dcn10_hw_sequencer_construct(dc);
-	dc->hwss.init_hw = dcn20_init_hw;
-	dc->hwss.init_pipes = NULL;
 	dc->hwss.unblank_stream = dcn20_unblank_stream;
 	dc->hwss.update_plane_addr = dcn20_update_plane_addr;
-	dc->hwss.disable_plane = dcn20_disable_plane,
 	dc->hwss.enable_stream_timing = dcn20_enable_stream_timing;
 	dc->hwss.program_triplebuffer = dcn20_program_tripleBuffer;
 	dc->hwss.set_input_transfer_func = dcn20_set_input_transfer_func;
@@ -2204,5 +2081,19 @@ void dcn20_hw_sequencer_construct(struct dc *dc)
 	dc->hwss.reset_hw_ctx_wrap = dcn20_reset_hw_ctx_wrap;
 	dc->hwss.update_mpcc = dcn20_update_mpcc;
 	dc->hwss.set_flip_control_gsl = dcn20_set_flip_control_gsl;
-	dc->hwss.did_underflow_occur = dcn10_did_underflow_occur;
+	dc->hwss.init_blank = dcn20_init_blank;
+	dc->hwss.disable_plane = dcn20_disable_plane;
+	dc->hwss.plane_atomic_disable = dcn20_plane_atomic_disable;
+	dc->hwss.enable_power_gating_plane = dcn20_enable_power_gating_plane;
+	dc->hwss.dpp_pg_control = dcn20_dpp_pg_control;
+	dc->hwss.hubp_pg_control = dcn20_hubp_pg_control;
+	dc->hwss.dsc_pg_control = dcn20_dsc_pg_control;
+	dc->hwss.disable_vga = dcn20_disable_vga;
+
+	if (IS_FPGA_MAXIMUS_DC(dc->ctx->dce_environment)) {
+		dc->hwss.init_hw = dcn20_fpga_init_hw;
+		dc->hwss.init_pipes = NULL;
+	}
+
+
 }

commit 986936d1a9b29bd40be2acdf91d9e99ecda3bf33
Author: Jun Lei <Jun.Lei@amd.com>
Date:   Tue Jul 16 13:02:41 2019 -0400

    drm/amd/display: wait for pending complete when enabling a plane
    
    [why]
    When planes are enabled, they must be enabled using VSYNC update (not immediate).
    However, before the VUPDATE occurs, DM may call with an "immediate" flip which is address
    only.  This operation would normally be okay, but if the locking for immediate flip happens
    to occur before the VUPDATE associated with the initial plane enablement, it will cause HW
    to hang.
    
    [how]
    HWSS should enforce plane enable in HW to be synchronous with the call that enables the plane.
    
    Signed-off-by: Jun Lei <Jun.Lei@amd.com>
    Reviewed-by: Eric Yang <eric.yang2@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index fb7cde33c88b..c11de6f0fe5c 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1353,13 +1353,15 @@ static void dcn20_apply_ctx_for_surface(
 		int num_planes,
 		struct dc_state *context)
 {
-
+	const unsigned int TIMEOUT_FOR_PIPE_ENABLE_MS = 100;
 	int i;
 	struct timing_generator *tg;
 	bool removed_pipe[6] = { false };
 	bool interdependent_update = false;
 	struct pipe_ctx *top_pipe_to_program =
 			find_top_pipe_for_stream(dc, context, stream);
+	struct pipe_ctx *prev_top_pipe_to_program =
+			find_top_pipe_for_stream(dc, dc->current_state, stream);
 	DC_LOGGER_INIT(dc->ctx->logger);
 
 	if (!top_pipe_to_program)
@@ -1453,6 +1455,22 @@ static void dcn20_apply_ctx_for_surface(
 	for (i = 0; i < dc->res_pool->pipe_count; i++)
 		if (removed_pipe[i])
 			dcn20_disable_plane(dc, &dc->current_state->res_ctx.pipe_ctx[i]);
+
+	/*
+	 * If we are enabling a pipe, we need to wait for pending clear as this is a critical
+	 * part of the enable operation otherwise, DM may request an immediate flip which
+	 * will cause HW to perform an "immediate enable" (as opposed to "vsync enable") which
+	 * is unsupported on DCN.
+	 */
+	i = 0;
+	if (num_planes > 0 && top_pipe_to_program &&
+			(prev_top_pipe_to_program == NULL || prev_top_pipe_to_program->plane_state == NULL)) {
+		while (i < TIMEOUT_FOR_PIPE_ENABLE_MS &&
+				top_pipe_to_program->plane_res.hubp->funcs->hubp_is_flip_pending(top_pipe_to_program->plane_res.hubp)) {
+			i += 1;
+			msleep(1);
+		}
+	}
 }
 
 

commit 9adc8050bf3ca3e49c65e13259a4c310640542f1
Author: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Date:   Fri Jul 12 15:06:06 2019 -0400

    drm/amd/display: make firmware info only load once during dc_bios create
    
    Currently every time DC wants to access firmware info we make a call
    into VBIOS. This makes no sense as there is nothing that can change
    runtime inside fw info and can cause issues when calling unstable
    bios during bringup.
    
    This change eliminate this behavior by only calling bios once for fw
    info and keeping it stored as part of dc_bios.
    
    Signed-off-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Reviewed-by: Chris Park <Chris.Park@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 27d143418cc7..fb7cde33c88b 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -568,7 +568,6 @@ static void dcn20_init_hw(struct dc *dc)
 	struct dc_bios *dcb = dc->ctx->dc_bios;
 	struct resource_pool *res_pool = dc->res_pool;
 	struct dc_state  *context = dc->current_state;
-	struct dc_firmware_info fw_info = { { 0 } };
 
 	if (dc->clk_mgr && dc->clk_mgr->funcs->init_clocks)
 		dc->clk_mgr->funcs->init_clocks(dc->clk_mgr);
@@ -592,15 +591,15 @@ static void dcn20_init_hw(struct dc *dc)
 	} else {
 		if (!dcb->funcs->is_accelerated_mode(dcb)) {
 			bios_golden_init(dc);
-			if (dc->ctx->dc_bios->funcs->get_firmware_info(
-					dc->ctx->dc_bios, &fw_info) == BP_RESULT_OK) {
-				res_pool->ref_clocks.xtalin_clock_inKhz = fw_info.pll_info.crystal_frequency;
+			if (dc->ctx->dc_bios->fw_info_valid) {
+				res_pool->ref_clocks.xtalin_clock_inKhz =
+						dc->ctx->dc_bios->fw_info.pll_info.crystal_frequency;
 
 				if (!IS_FPGA_MAXIMUS_DC(dc->ctx->dce_environment)) {
 					if (res_pool->dccg && res_pool->hubbub) {
 
 						(res_pool->dccg->funcs->get_dccg_ref_freq)(res_pool->dccg,
-								fw_info.pll_info.crystal_frequency,
+								dc->ctx->dc_bios->fw_info.pll_info.crystal_frequency,
 								&res_pool->ref_clocks.dccg_ref_clock_inKhz);
 
 						(res_pool->hubbub->funcs->get_dchub_ref_freq)(res_pool->hubbub,

commit 38df070135297746804bf8537ac2e8c66bb37bd5
Author: Wenjing Liu <Wenjing.Liu@amd.com>
Date:   Wed Jul 10 18:31:38 2019 -0400

    drm/amd/display: reset drr programming on pipe reset
    
    [why]
    drr is still enabled after driver is unloaded causing black screen
    
    [how]
    disable drr during pipe reset.
    
    Signed-off-by: Wenjing Liu <Wenjing.Liu@amd.com>
    Reviewed-by: Jun Lei <Jun.Lei@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 38b3c89b2a59..27d143418cc7 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1834,6 +1834,10 @@ static void dcn20_reset_back_end_for_pipe(
 		if (pipe_ctx->stream_res.tg->funcs->set_odm_bypass)
 			pipe_ctx->stream_res.tg->funcs->set_odm_bypass(
 					pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);
+
+		if (pipe_ctx->stream_res.tg->funcs->set_drr)
+			pipe_ctx->stream_res.tg->funcs->set_drr(
+					pipe_ctx->stream_res.tg, NULL);
 	}
 
 	for (i = 0; i < dc->res_pool->pipe_count; i++)

commit d3b9f39d8417ee2f2cd87b5e5410015ce6f78491
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Fri Jul 26 11:04:39 2019 -0500

    drm/amdgpu/display: fix the build without CONFIG_DRM_AMD_DC_DSC_SUPPORT
    
    Some code was missing the CONFIG_DRM_AMD_DC_DSC_SUPPORT guard.
    
    Reviewed-by: Nicholas Kazlauskas <nicholas.kazlauskas@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 69e4d0d96c7f..38b3c89b2a59 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -630,9 +630,11 @@ static void dcn20_init_hw(struct dc *dc)
 		}
 	}
 
+#ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
 	/* Power gate DSCs */
 	for (i = 0; i < res_pool->res_cap->num_dsc; i++)
 		dcn20_dsc_pg_control(hws, res_pool->dscs[i]->inst, false);
+#endif
 
 	/* Blank pixel data with OPP DPG */
 	for (i = 0; i < dc->res_pool->timing_generator_count; i++) {

commit 21ffcc94d5b3dc024fedac700f1e7f9dacf4ab4f
Author: Nicholas Kazlauskas <nicholas.kazlauskas@amd.com>
Date:   Thu Jul 11 12:32:43 2019 -0400

    drm/amd/display: Copy GSL groups when committing a new context
    
    [Why]
    DC configures the GSL group for the pipe when pipe_split is enabled
    and we're switching flip types (buffered <-> immediate flip) on DCN2.
    
    In order to record what GSL group the pipe is using DC stores it in
    the pipe's stream_res. DM is not aware of this internal grouping, nor
    is DC resource.
    
    So when DM creates a dc_state context and passes it to DC the current
    GSL group is lost - DM never knew about it in the first place.
    
    After 3 immediate flips we run out of GSL groups and we're no longer
    able to correctly perform *any* flip for multi-pipe scenarios.
    
    [How]
    The gsl_group needs to be copied to the new context.
    
    DM has no insight into GSL grouping and could even potentially create
    a brand new context without referencing current hardware state. So this
    makes the most sense to have happen in DC.
    
    There are two places where DC can apply a new context:
    - dc_commit_state
    - dc_commit_updates_for_stream
    
    But what's shared between both of these is apply_ctx_for_surface.
    
    This logic only matters for DCN2, so it can be placed in
    dcn20_apply_ctx_for_surface. Before doing any locking (where the GSL
    group is setup) we can copy over the GSL groups before committing the
    new context.
    
    Signed-off-by: Nicholas Kazlauskas <nicholas.kazlauskas@amd.com>
    Reviewed-by: Hersen Wu <hersen.wu@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 6764ad845cd4..69e4d0d96c7f 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1364,6 +1364,18 @@ static void dcn20_apply_ctx_for_surface(
 	if (!top_pipe_to_program)
 		return;
 
+	/* Carry over GSL groups in case the context is changing. */
+	for (i = 0; i < dc->res_pool->pipe_count; i++) {
+		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
+		struct pipe_ctx *old_pipe_ctx =
+			&dc->current_state->res_ctx.pipe_ctx[i];
+
+		if (pipe_ctx->stream == stream &&
+		    pipe_ctx->stream == old_pipe_ctx->stream)
+			pipe_ctx->stream_res.gsl_group =
+				old_pipe_ctx->stream_res.gsl_group;
+	}
+
 	tg = top_pipe_to_program->stream_res.tg;
 
 	interdependent_update = top_pipe_to_program->plane_state &&

commit 46825fcfbe162609393976e18f106dafddca6f67
Author: Tony Cheng <tony.cheng@amd.com>
Date:   Sun Jun 23 12:07:02 2019 -0500

    drm/amd/display: avoid power gate domains that doesn't exist
    
    Signed-off-by: Tony Cheng <tony.cheng@amd.com>
    Reviewed-by: Yongqiang Sun <yongqiang.sun@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index b61774d2e8b2..6764ad845cd4 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -94,25 +94,31 @@ static void enable_power_gating_plane(
 	REG_UPDATE(DOMAIN2_PG_CONFIG, DOMAIN2_POWER_FORCEON, force_on);
 	REG_UPDATE(DOMAIN4_PG_CONFIG, DOMAIN4_POWER_FORCEON, force_on);
 	REG_UPDATE(DOMAIN6_PG_CONFIG, DOMAIN6_POWER_FORCEON, force_on);
-	REG_UPDATE(DOMAIN8_PG_CONFIG, DOMAIN8_POWER_FORCEON, force_on);
-	/*Do not power gate DCHUB5, should be left at HW default, power on permanently*/
-	/*REG_UPDATE(DOMAIN10_PG_CONFIG, DOMAIN10_POWER_FORCEON, force_on);*/
+	if (REG(DOMAIN8_PG_CONFIG))
+		REG_UPDATE(DOMAIN8_PG_CONFIG, DOMAIN8_POWER_FORCEON, force_on);
+	if (REG(DOMAIN10_PG_CONFIG))
+		REG_UPDATE(DOMAIN10_PG_CONFIG, DOMAIN8_POWER_FORCEON, force_on);
 
 	/* DPP0/1/2/3/4/5 */
 	REG_UPDATE(DOMAIN1_PG_CONFIG, DOMAIN1_POWER_FORCEON, force_on);
 	REG_UPDATE(DOMAIN3_PG_CONFIG, DOMAIN3_POWER_FORCEON, force_on);
 	REG_UPDATE(DOMAIN5_PG_CONFIG, DOMAIN5_POWER_FORCEON, force_on);
 	REG_UPDATE(DOMAIN7_PG_CONFIG, DOMAIN7_POWER_FORCEON, force_on);
-	REG_UPDATE(DOMAIN9_PG_CONFIG, DOMAIN9_POWER_FORCEON, force_on);
-	/*Do not power gate DPP5, should be left at HW default, power on permanently*/
-	/*REG_UPDATE(DOMAIN11_PG_CONFIG, DOMAIN11_POWER_FORCEON, force_on);*/
+	if (REG(DOMAIN9_PG_CONFIG))
+		REG_UPDATE(DOMAIN9_PG_CONFIG, DOMAIN9_POWER_FORCEON, force_on);
+	if (REG(DOMAIN11_PG_CONFIG))
+		REG_UPDATE(DOMAIN11_PG_CONFIG, DOMAIN9_POWER_FORCEON, force_on);
 
+	/* DCS0/1/2/3/4/5 */
 	REG_UPDATE(DOMAIN16_PG_CONFIG, DOMAIN16_POWER_FORCEON, force_on);
 	REG_UPDATE(DOMAIN17_PG_CONFIG, DOMAIN17_POWER_FORCEON, force_on);
 	REG_UPDATE(DOMAIN18_PG_CONFIG, DOMAIN18_POWER_FORCEON, force_on);
-	REG_UPDATE(DOMAIN19_PG_CONFIG, DOMAIN19_POWER_FORCEON, force_on);
-	REG_UPDATE(DOMAIN20_PG_CONFIG, DOMAIN20_POWER_FORCEON, force_on);
-	REG_UPDATE(DOMAIN21_PG_CONFIG, DOMAIN21_POWER_FORCEON, force_on);
+	if (REG(DOMAIN19_PG_CONFIG))
+		REG_UPDATE(DOMAIN19_PG_CONFIG, DOMAIN19_POWER_FORCEON, force_on);
+	if (REG(DOMAIN20_PG_CONFIG))
+		REG_UPDATE(DOMAIN20_PG_CONFIG, DOMAIN20_POWER_FORCEON, force_on);
+	if (REG(DOMAIN21_PG_CONFIG))
+		REG_UPDATE(DOMAIN21_PG_CONFIG, DOMAIN21_POWER_FORCEON, force_on);
 }
 
 void dcn20_dccg_init(struct dce_hwseq *hws)

commit 057fc695e934a77bae0c6c7f3be01251774b61cf
Author: Jun Lei <Jun.Lei@amd.com>
Date:   Mon Jul 8 15:15:42 2019 -0400

    drm/amd/display: support "dummy pstate"
    
    [why]
    Existing support in DC for pstate only accounts for a single latency.  This is sufficient when the
    variance of latency is small, or that pstate support isn't necessary for correct ASIC functionality.
    
    Newer ASICs violate both existing assumptions.  PState support is mandatory of correct ASIC
    functionality, but not all latencies have to be supported.  Existing code supports a "full p state" which
    allows memory clock to change, but is hard for DCN to support (as it requires very large buffers).
    New code will now fall back to a "dummy p state" support when "full p state" cannot be support.
    This easy p state support should always be allowed.
    
    [how]
    Define a new latency in socBB.  Add fallback logic to support it.  Note DML is also updated to ensure
    that fallback will always work.
    
    Signed-off-by: Jun Lei <Jun.Lei@amd.com>
    Reviewed-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 76ce622e1421..b61774d2e8b2 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1443,16 +1443,16 @@ void dcn20_prepare_bandwidth(
 {
 	struct hubbub *hubbub = dc->res_pool->hubbub;
 
+	dc->clk_mgr->funcs->update_clocks(
+			dc->clk_mgr,
+			context,
+			false);
+
 	/* program dchubbub watermarks */
 	hubbub->funcs->program_watermarks(hubbub,
 					&context->bw_ctx.bw.dcn.watermarks,
 					dc->res_pool->ref_clocks.dchub_ref_clock_inKhz / 1000,
 					false);
-
-	dc->clk_mgr->funcs->update_clocks(
-			dc->clk_mgr,
-			context,
-			false);
 }
 
 void dcn20_optimize_bandwidth(

commit f591344e89dca887afeb5bbe21fa199687fd4a5f
Author: Julian Parkin <julian.parkin@amd.com>
Date:   Wed Jul 3 13:59:26 2019 -0400

    drm/amd/display: Clean up dynamic metadata logic
    
     [Why]
    Code to enable DCN20 dynamic metadata feature is duplicated in two places
    and was added to DCE110 enable stream.
    
    [How]
    Create DCN20 specific enable stream function for clarity, and add a hardware
    sequencer function to program dynamic metadata to avoid the duplicate
    code.
    
    Signed-off-by: Julian Parkin <julian.parkin@amd.com>
    Reviewed-by: Charlene Liu <Charlene.Liu@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 566cd4cdfef4..76ce622e1421 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -2056,6 +2056,78 @@ static void dcn20_set_flip_control_gsl(
 
 }
 
+static void dcn20_enable_stream(struct pipe_ctx *pipe_ctx)
+{
+	enum dc_lane_count lane_count =
+		pipe_ctx->stream->link->cur_link_settings.lane_count;
+
+	struct dc_crtc_timing *timing = &pipe_ctx->stream->timing;
+	struct dc_link *link = pipe_ctx->stream->link;
+
+	uint32_t active_total_with_borders;
+	uint32_t early_control = 0;
+	struct timing_generator *tg = pipe_ctx->stream_res.tg;
+
+	/* For MST, there are multiply stream go to only one link.
+	 * connect DIG back_end to front_end while enable_stream and
+	 * disconnect them during disable_stream
+	 * BY this, it is logic clean to separate stream and link
+	 */
+	link->link_enc->funcs->connect_dig_be_to_fe(link->link_enc,
+						    pipe_ctx->stream_res.stream_enc->id, true);
+
+	if (link->dc->hwss.program_dmdata_engine)
+		link->dc->hwss.program_dmdata_engine(pipe_ctx);
+
+	link->dc->hwss.update_info_frame(pipe_ctx);
+
+	/* enable early control to avoid corruption on DP monitor*/
+	active_total_with_borders =
+			timing->h_addressable
+				+ timing->h_border_left
+				+ timing->h_border_right;
+
+	if (lane_count != 0)
+		early_control = active_total_with_borders % lane_count;
+
+	if (early_control == 0)
+		early_control = lane_count;
+
+	tg->funcs->set_early_control(tg, early_control);
+
+	/* enable audio only within mode set */
+	if (pipe_ctx->stream_res.audio != NULL) {
+		if (dc_is_dp_signal(pipe_ctx->stream->signal))
+			pipe_ctx->stream_res.stream_enc->funcs->dp_audio_enable(pipe_ctx->stream_res.stream_enc);
+	}
+}
+
+static void dcn20_program_dmdata_engine(struct pipe_ctx *pipe_ctx)
+{
+	struct dc_stream_state    *stream     = pipe_ctx->stream;
+	struct hubp               *hubp       = pipe_ctx->plane_res.hubp;
+	bool                       enable     = false;
+	struct stream_encoder     *stream_enc = pipe_ctx->stream_res.stream_enc;
+	enum dynamic_metadata_mode mode       = dc_is_dp_signal(stream->signal)
+							? dmdata_dp
+							: dmdata_hdmi;
+
+	/* if using dynamic meta, don't set up generic infopackets */
+	if (pipe_ctx->stream->dmdata_address.quad_part != 0) {
+		pipe_ctx->stream_res.encoder_info_frame.hdrsmd.valid = false;
+		enable = true;
+	}
+
+	if (!hubp)
+		return;
+
+	if (!stream_enc || !stream_enc->funcs->set_dynamic_metadata)
+		return;
+
+	stream_enc->funcs->set_dynamic_metadata(stream_enc, enable,
+						hubp->inst, mode);
+}
+
 void dcn20_hw_sequencer_construct(struct dc *dc)
 {
 	dcn10_hw_sequencer_construct(dc);
@@ -2080,6 +2152,8 @@ void dcn20_hw_sequencer_construct(struct dc *dc)
 	dc->hwss.update_odm = dcn20_update_odm;
 	dc->hwss.blank_pixel_data = dcn20_blank_pixel_data;
 	dc->hwss.dmdata_status_done = dcn20_dmdata_status_done;
+	dc->hwss.program_dmdata_engine = dcn20_program_dmdata_engine;
+	dc->hwss.enable_stream = dcn20_enable_stream;
 	dc->hwss.disable_stream = dcn20_disable_stream;
 	dc->hwss.init_sys_ctx = dcn20_init_sys_ctx;
 	dc->hwss.init_vm_ctx = dcn20_init_vm_ctx;

commit 473e0ecbb4f62e0a971b47b27ec778371653f5ac
Author: Ilya Bakoulin <Ilya.Bakoulin@amd.com>
Date:   Wed Jun 26 14:52:46 2019 -0400

    drm/amd/display: Fixes for some MPO cases
    
    [Why]
    Alpha could be improperly applied (only affecting half the
    frame) for some source pixel formats.
    
    [How]
    Change how alpha is enabled in MPC/DPP LB and change the
    bottom plane blend mode in MPC.
    
    Signed-off-by: Ilya Bakoulin <Ilya.Bakoulin@amd.com>
    Reviewed-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 64ebfdbbba9b..566cd4cdfef4 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1863,7 +1863,7 @@ static void dcn20_update_mpcc(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
 	struct hubp *hubp = pipe_ctx->plane_res.hubp;
 	struct mpcc_blnd_cfg blnd_cfg = { {0} };
-	bool per_pixel_alpha = pipe_ctx->plane_state->per_pixel_alpha && pipe_ctx->bottom_pipe;
+	bool per_pixel_alpha = pipe_ctx->plane_state->per_pixel_alpha;
 	int mpcc_id;
 	struct mpcc *new_mpcc;
 	struct mpc *mpc = dc->res_pool->mpc;

commit a2080098692173cf27282f686e341b184f9d68e3
Author: Vitaly Prosyak <vitaly.prosyak@amd.com>
Date:   Fri Jun 21 10:13:16 2019 -0500

    drm/amd/display: Add MPC 3DLUT resource management
    
    [Why & How]
    Number of 3DLUT's in MPC are not equal to number of pipes.
    Resource management is required.
    Activate on FPGA entire tm solution  which includes
    the following :hdr multiplier, shaper, 3dlut.
    
    Signed-off-by: Vitaly Prosyak <vitaly.prosyak@amd.com>
    Reviewed-by: Charlene Liu <Charlene.Liu@amd.com>
    Acked-by: Gary Kattan <Gary.Kattan@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 9daab57a96ea..64ebfdbbba9b 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -952,14 +952,14 @@ static bool dcn20_set_shaper_3dlut(
 
 	result = dpp_base->funcs->dpp_program_shaper_lut(dpp_base, shaper_lut);
 	if (plane_state->lut3d_func &&
-		plane_state->lut3d_func->initialized == true)
+		plane_state->lut3d_func->state.bits.initialized == 1)
 		result = dpp_base->funcs->dpp_program_3dlut(dpp_base,
 								&plane_state->lut3d_func->lut_3d);
 	else
 		result = dpp_base->funcs->dpp_program_3dlut(dpp_base, NULL);
 
 	if (plane_state->lut3d_func &&
-		plane_state->lut3d_func->initialized == true &&
+		plane_state->lut3d_func->state.bits.initialized == 1 &&
 		plane_state->lut3d_func->hdr_multiplier != 0)
 		dpp_base->funcs->dpp_set_hdr_multiplier(dpp_base,
 				plane_state->lut3d_func->hdr_multiplier);

commit 4c6a9618076c2690a361e8bc32549720f2f42305
Author: Alvin Lee <alvin.lee2@amd.com>
Date:   Mon Jun 24 09:49:44 2019 -0400

    drm/amd/display: Wait for flip to complete
    
    [why]
    In pipe split issue occurs when we program immediate flip while vsync flip is pending
    
    [how]
    Don't program immediate flip until flip is no longer pending
    
    Signed-off-by: Alvin Lee <alvin.lee2@amd.com>
    Reviewed-by: Jaehyun Chung <Jaehyun.Chung@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 5ecf965bc3f5..9daab57a96ea 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1308,6 +1308,17 @@ void dcn20_pipe_control_lock(
 	if (pipe->plane_state != NULL)
 		flip_immediate = pipe->plane_state->flip_immediate;
 
+	if (flip_immediate && lock) {
+		while (pipe->plane_res.hubp->funcs->hubp_is_flip_pending(pipe->plane_res.hubp))	{
+			udelay(1);
+		}
+
+		if (pipe->bottom_pipe != NULL)
+			while (pipe->bottom_pipe->plane_res.hubp->funcs->hubp_is_flip_pending(pipe->bottom_pipe->plane_res.hubp))	{
+				udelay(1);
+			}
+	}
+
 	/* In flip immediate and pipe splitting case, we need to use GSL
 	 * for synchronization. Only do setup on locking and on flip type change.
 	 */

commit 75c35000235f3662f2810e9a59b0c8eed045432e
Author: Nikola Cornij <nikola.cornij@amd.com>
Date:   Wed Jun 19 14:30:52 2019 -0400

    drm/amd/display: Power-gate all DSCs at driver init time
    
    [why]
    DSC should be powered-on only on as-needed basis, i.e. if the mode
    requires it
    
    [how]
    Loop over all the DSCs at driver init time and power-gate each
    
    Signed-off-by: Nikola Cornij <nikola.cornij@amd.com>
    Reviewed-by: Nevenko Stupar <Nevenko.Stupar@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index ddf15a3715e0..5ecf965bc3f5 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -624,6 +624,10 @@ static void dcn20_init_hw(struct dc *dc)
 		}
 	}
 
+	/* Power gate DSCs */
+	for (i = 0; i < res_pool->res_cap->num_dsc; i++)
+		dcn20_dsc_pg_control(hws, res_pool->dscs[i]->inst, false);
+
 	/* Blank pixel data with OPP DPG */
 	for (i = 0; i < dc->res_pool->timing_generator_count; i++) {
 		struct timing_generator *tg = dc->res_pool->timing_generators[i];

commit 606b355170b56549890e8202a2b62f97d28b395e
Author: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Date:   Wed Jun 5 16:35:08 2019 -0400

    drm/amd/display: add hdmi2.1 dsc pps packet programming
    
    This change adds EMP packet programming for enabling dsc with
    hdmi. The packets are structured according to VESA HDMI 2.1x
    r2 spec, section 10.10.2.2.
    
    Signed-off-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Reviewed-by: Charlene Liu <Charlene.Liu@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 5fc4e0954eee..ddf15a3715e0 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1783,8 +1783,9 @@ static void dcn20_reset_back_end_for_pipe(
 		}
 	}
 #ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
-	else if (pipe_ctx->stream_res.dsc)
+	else if (pipe_ctx->stream_res.dsc) {
 		dp_set_dsc_enable(pipe_ctx, false);
+	}
 #endif
 
 	/* by upper caller loop, parent pipe: pipe0, will be reset last.

commit 29344d152d0a7a54945606d9065c5de79161f100
Author: Wenjing Liu <Wenjing.Liu@amd.com>
Date:   Tue Jun 11 18:18:36 2019 -0400

    drm/amd/display: wait for the whole frame after global unlock
    
    [why]
    The current code will not wait for the entire frame
     after global unlock.
    This causes dsc dynamic target bpp update corruption when
    there is a surface update immediately happens after this.
    
    [how]
    Wait for the entire whole frame after unlock before continuing
    the rest of stream and surface update.
    
    Signed-off-by: Wenjing Liu <Wenjing.Liu@amd.com>
    Reviewed-by: Jun Lei <Jun.Lei@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 9fa11c001f1b..5fc4e0954eee 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1281,6 +1281,8 @@ void dcn20_pipe_control_lock_global(
 				CRTC_STATE_VACTIVE);
 		pipe->stream_res.tg->funcs->wait_for_state(pipe->stream_res.tg,
 				CRTC_STATE_VBLANK);
+		pipe->stream_res.tg->funcs->wait_for_state(pipe->stream_res.tg,
+				CRTC_STATE_VACTIVE);
 		pipe->stream_res.tg->funcs->lock_doublebuffer_disable(
 				pipe->stream_res.tg);
 	}

commit c70b4016306a10b2c6e5d5da96a1f04a6248900f
Author: Charlene Liu <charlene.liu@amd.com>
Date:   Wed Jun 5 15:21:03 2019 -0400

    drm/amd/display: Split out common HUBP registers and code
    
    There are shared regs and code across DCN generations. Pull them out
    into a shared common location.
    
    Also, expose some dcn20 init functions.
    
    Signed-off-by: Charlene Liu <charlene.liu@amd.com>
    Reviewed-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 710727e5d0f8..9fa11c001f1b 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -115,7 +115,7 @@ static void enable_power_gating_plane(
 	REG_UPDATE(DOMAIN21_PG_CONFIG, DOMAIN21_POWER_FORCEON, force_on);
 }
 
-static void dcn20_dccg_init(struct dce_hwseq *hws)
+void dcn20_dccg_init(struct dce_hwseq *hws)
 {
 	/*
 	 * set MICROSECOND_TIME_BASE_DIV
@@ -138,6 +138,45 @@ static void dcn20_dccg_init(struct dce_hwseq *hws)
 	/* This value is dependent on the hardware pipeline delay so set once per SOC */
 	REG_WRITE(DISPCLK_FREQ_CHANGE_CNTL, 0x801003c);
 }
+void dcn20_display_init(struct dc *dc)
+{
+	struct dce_hwseq *hws = dc->hwseq;
+
+	/* RBBMIF
+	 * disable RBBMIF timeout detection for all clients
+	 * Ensure RBBMIF does not drop register accesses due to the per-client timeout
+	 */
+	REG_WRITE(RBBMIF_TIMEOUT_DIS, 0xFFFFFFFF);
+	REG_WRITE(RBBMIF_TIMEOUT_DIS_2, 0xFFFFFFFF);
+
+	/* DCCG */
+	dcn20_dccg_init(hws);
+
+	/* Disable all memory low power mode. All memories are enabled. */
+	REG_UPDATE(DC_MEM_GLOBAL_PWR_REQ_CNTL, DC_MEM_GLOBAL_PWR_REQ_DIS, 1);
+
+	/* DCHUB/MMHUBBUB
+	 * set global timer refclk divider
+	 * 100Mhz refclk -> 2
+	 * 27Mhz refclk ->  1
+	 * 48Mhz refclk ->  1
+	 */
+	REG_UPDATE(DCHUBBUB_GLOBAL_TIMER_CNTL, DCHUBBUB_GLOBAL_TIMER_REFDIV, 2);
+	REG_UPDATE(DCHUBBUB_GLOBAL_TIMER_CNTL, DCHUBBUB_GLOBAL_TIMER_ENABLE, 1);
+	REG_WRITE(REFCLK_CNTL, 0);
+
+	/* OPTC
+	 * OTG_CONTROL.OTG_DISABLE_POINT_CNTL = 0x3; will be set during optc2_enable_crtc
+	 */
+
+	/* AZ
+	 * default value is 0x64 for 100Mhz ref clock, if the ref clock is 100Mhz, no need to program this regiser,
+	 * if not, it should be programmed according to the ref clock
+	 */
+	REG_UPDATE(AZALIA_AUDIO_DTO, AZALIA_AUDIO_DTO_MODULE, 0x64);
+	/* Enable controller clock gating */
+	REG_WRITE(AZALIA_CONTROLLER_CLOCK_GATING, 0x1);
+}
 
 static void disable_vga(
 	struct dce_hwseq *hws)
@@ -163,7 +202,7 @@ void dcn20_program_tripleBuffer(
 }
 
 /* Blank pixel data during initialization */
-static void dcn20_init_blank(
+void dcn20_init_blank(
 		struct dc *dc,
 		struct timing_generator *tg)
 {

commit 6d988a557ee8bd0970c46aea94396ff4815724cd
Author: Jun Lei <Jun.Lei@amd.com>
Date:   Wed Jun 5 10:53:40 2019 -0400

    drm/amd/display: swap system aperture high/low
    
    [why]
    Currently logical values are swapped in HW, causing
    system aperture to be undefined, so VA and PA cannot co-exist
    
    [how]
    program values correctly
    
    Signed-off-by: Jun Lei <Jun.Lei@amd.com>
    Reviewed-by: Yongqiang Sun <yongqiang.sun@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 94f2f9fc6956..710727e5d0f8 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1153,8 +1153,8 @@ void dcn20_enable_plane(
 
 		apt.sys_default.quad_part = 0;
 
-		apt.sys_high.quad_part = dc->vm_pa_config.system_aperture.start_addr;
-		apt.sys_low.quad_part = dc->vm_pa_config.system_aperture.end_addr;
+		apt.sys_low.quad_part = dc->vm_pa_config.system_aperture.start_addr;
+		apt.sys_high.quad_part = dc->vm_pa_config.system_aperture.end_addr;
 
 		// Program system aperture settings
 		pipe_ctx->plane_res.hubp->funcs->hubp_set_vm_system_aperture_settings(pipe_ctx->plane_res.hubp, &apt);

commit ec16ac6b4264dffefe3cd137038e138e79e07848
Author: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Date:   Thu May 30 15:47:51 2019 -0400

    drm/amd/display: fix dsc disable
    
    A regression caused dsc to never get disabled in certain situations.
    
    Signed-off-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Reviewed-by: Nikola Cornij <Nikola.Cornij@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 0b84a322b8a2..94f2f9fc6956 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1740,8 +1740,11 @@ static void dcn20_reset_back_end_for_pipe(
 		else if (pipe_ctx->stream_res.audio) {
 			dc->hwss.disable_audio_stream(pipe_ctx, FREE_ACQUIRED_RESOURCE);
 		}
-
 	}
+#ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
+	else if (pipe_ctx->stream_res.dsc)
+		dp_set_dsc_enable(pipe_ctx, false);
+#endif
 
 	/* by upper caller loop, parent pipe: pipe0, will be reset last.
 	 * back end share by all pipes and will be disable only when disable

commit 41a5a2a8531f95d18bb4efddea581ccb469e8ee5
Author: hersen wu <hersenxs.wu@amd.com>
Date:   Wed Jun 26 13:06:07 2019 -0400

    drm/amd/display: init res_pool dccg_ref, dchub_ref with xtalin_freq
    
    [WHY] dc sw clock implementation of navi10 and raven are not exact the
    same. dcccg, dchub reference clock initialization is done after dc calls
    vbios dispcontroller_init table. for raven family, before
    dispcontroller_init is called by dc, the ref clk values are referred
    by sw clock implementation and program asic register using wrong
    values. this causes dchub pstate error. This need provide valid ref
    clk values. for navi10, since dispcontroller_init is not called,
    dchubbub_global_timer_enable = 0, hubbub2_get_dchub_ref_freq will
    hit aeert. this need remove hubbub2_get_dchub_ref_freq from this
    location and move to dcn20_init_hw.
    
    [HOW] for all asic, initialize dccg, dchub ref clk with data from
    vbios firmware table by default. for raven asic family, use these data
    from vbios, for asic which support sw dccg component, like navi10,
    read ref clk by sw dccg functions and update the ref clk.
    
    Signed-off-by: hersen wu <hersenxs.wu@amd.com>
    Reviewed-by: Jun Lei <Jun.Lei@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 6925d25d2457..0b84a322b8a2 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -523,6 +523,7 @@ static void dcn20_init_hw(struct dc *dc)
 	struct dc_bios *dcb = dc->ctx->dc_bios;
 	struct resource_pool *res_pool = dc->res_pool;
 	struct dc_state  *context = dc->current_state;
+	struct dc_firmware_info fw_info = { { 0 } };
 
 	if (dc->clk_mgr && dc->clk_mgr->funcs->init_clocks)
 		dc->clk_mgr->funcs->init_clocks(dc->clk_mgr);
@@ -546,6 +547,30 @@ static void dcn20_init_hw(struct dc *dc)
 	} else {
 		if (!dcb->funcs->is_accelerated_mode(dcb)) {
 			bios_golden_init(dc);
+			if (dc->ctx->dc_bios->funcs->get_firmware_info(
+					dc->ctx->dc_bios, &fw_info) == BP_RESULT_OK) {
+				res_pool->ref_clocks.xtalin_clock_inKhz = fw_info.pll_info.crystal_frequency;
+
+				if (!IS_FPGA_MAXIMUS_DC(dc->ctx->dce_environment)) {
+					if (res_pool->dccg && res_pool->hubbub) {
+
+						(res_pool->dccg->funcs->get_dccg_ref_freq)(res_pool->dccg,
+								fw_info.pll_info.crystal_frequency,
+								&res_pool->ref_clocks.dccg_ref_clock_inKhz);
+
+						(res_pool->hubbub->funcs->get_dchub_ref_freq)(res_pool->hubbub,
+								res_pool->ref_clocks.dccg_ref_clock_inKhz,
+								&res_pool->ref_clocks.dchub_ref_clock_inKhz);
+					} else {
+						// Not all ASICs have DCCG sw component
+						res_pool->ref_clocks.dccg_ref_clock_inKhz =
+								res_pool->ref_clocks.xtalin_clock_inKhz;
+						res_pool->ref_clocks.dchub_ref_clock_inKhz =
+								res_pool->ref_clocks.xtalin_clock_inKhz;
+					}
+				}
+			} else
+				ASSERT_CRITICAL(false);
 			disable_vga(dc->hwseq);
 		}
 

commit c602b36fe245f2114153f6690d1222ce1a51e942
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Jul 8 15:53:18 2019 +0200

    drm/amd/display: dcn20: include linux/delay.h
    
    Without this header, we get a compiler error in some configurations:
    
    .../dc/dcn20/dcn20_hwseq.c: In function 'dcn20_hwss_wait_for_blank_complete':
    .../dc/dcn20/dcn20_hwseq.c:1493:3: error: implicit declaration of function 'udelay' [-Werror=implicit-function-declaration]
    
    Note: the use of udelay itself may be problematic, as can occupy
    the CPU for 200ms in a busy-loop here.
    
    Fixes: 7ed4e6352c16 ("drm/amd/display: Add DCN2 HW Sequencer and Resource")
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 4b0d8b9f61da..6925d25d2457 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -22,6 +22,7 @@
  * Authors: AMD
  *
  */
+#include <linux/delay.h>
 
 #include "dm_services.h"
 #include "dm_helpers.h"

commit 1a7d296d162ede31d170fdb9205ce07c8cb7dfac
Author: Thomas Lim <Thomas.Lim@amd.com>
Date:   Mon Apr 29 16:05:42 2019 -0400

    drm/amd/display: Add Underflow Asserts to dc
    
    [Why]
    For debugging underflow issues it can be useful to have asserts when the
    underflow initially occurs.
    
    [How]
    Read the underflow status registers after actions that have a high risk
    of causing underflow and assert that no underflow occurred. If underflow
    occurred, clear the bit.
    
    Signed-off-by: Thomas Lim <Thomas.Lim@amd.com>
    Reviewed-by: Eric Yang <eric.yang2@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 20bc3b9fe879..4b0d8b9f61da 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -2003,4 +2003,5 @@ void dcn20_hw_sequencer_construct(struct dc *dc)
 	dc->hwss.reset_hw_ctx_wrap = dcn20_reset_hw_ctx_wrap;
 	dc->hwss.update_mpcc = dcn20_update_mpcc;
 	dc->hwss.set_flip_control_gsl = dcn20_set_flip_control_gsl;
+	dc->hwss.did_underflow_occur = dcn10_did_underflow_occur;
 }

commit bda9afdacf8942c313a47cc95582737345a91c5e
Author: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Date:   Wed May 22 18:05:41 2019 -0400

    drm/amd/display: move vmid determination logic to a module
    
    Currently vmid is decided internally inside dc. With the introduction
    of new asics we are required to coordinate vmid use with external
    components.
    
    This change converts vmid logic to a DAL module allowing vmid to be
    passed in as a parameter to DC.
    
    Signed-off-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Reviewed-by: Charlene Liu <Charlene.Liu@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index d55b15fbfe99..20bc3b9fe879 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1122,15 +1122,13 @@ void dcn20_enable_plane(
 		print_rq_dlg_ttu(dc, pipe_ctx);
 	}
 */
-	if (dc->vm_config.valid) {
+	if (dc->vm_pa_config.valid) {
 		struct vm_system_aperture_param apt;
 
 		apt.sys_default.quad_part = 0;
-		apt.sys_high.quad_part = 0;
-		apt.sys_low.quad_part = 0;
 
-		apt.sys_high.quad_part = dc->vm_config.pa_config.system_aperture.start_addr;
-		apt.sys_low.quad_part = dc->vm_config.pa_config.system_aperture.end_addr;
+		apt.sys_high.quad_part = dc->vm_pa_config.system_aperture.start_addr;
+		apt.sys_low.quad_part = dc->vm_pa_config.system_aperture.end_addr;
 
 		// Program system aperture settings
 		pipe_ctx->plane_res.hubp->funcs->hubp_set_vm_system_aperture_settings(pipe_ctx->plane_res.hubp, &apt);
@@ -1565,26 +1563,43 @@ void dcn20_disable_stream(struct pipe_ctx *pipe_ctx, int option)
 	dce110_disable_stream(pipe_ctx, option);
 }
 
-static void dcn20_init_dchub(struct dce_hwseq *hws, struct dc *dc, struct dc_addr_space_config *config)
+static void dcn20_init_vm_ctx(
+		struct dce_hwseq *hws,
+		struct dc *dc,
+		struct dc_virtual_addr_space_config *va_config,
+		int vmid)
 {
-	struct hubbub_addr_config hubbub_config;
-
-	hubbub_config.pa_config.system_aperture.fb_top = config->pa_config.system_aperture.fb_top;
-	hubbub_config.pa_config.system_aperture.fb_offset = config->pa_config.system_aperture.fb_offset;
-	hubbub_config.pa_config.system_aperture.fb_base = config->pa_config.system_aperture.fb_base;
-	hubbub_config.pa_config.system_aperture.agp_top = config->pa_config.system_aperture.agp_top;
-	hubbub_config.pa_config.system_aperture.agp_bot = config->pa_config.system_aperture.agp_bot;
-	hubbub_config.pa_config.system_aperture.agp_base = config->pa_config.system_aperture.agp_base;
-	hubbub_config.pa_config.gart_config.page_table_start_addr = config->pa_config.gart_config.page_table_start_addr;
-	hubbub_config.pa_config.gart_config.page_table_end_addr = config->pa_config.gart_config.page_table_end_addr;
-	hubbub_config.pa_config.gart_config.page_table_base_addr = config->pa_config.gart_config.page_table_base_addr;
-
-	hubbub_config.va_config.page_table_start_addr = config->va_config.page_table_start_addr;
-	hubbub_config.va_config.page_table_end_addr = config->va_config.page_table_end_addr;
-	hubbub_config.va_config.page_table_block_size = config->va_config.page_table_block_size_in_bytes;
-	hubbub_config.va_config.page_table_depth = config->va_config.page_table_depth;
-
-	dc->res_pool->hubbub->funcs->init_dchub(dc->res_pool->hubbub, &hubbub_config);
+	struct dcn_hubbub_virt_addr_config config;
+
+	if (vmid == 0) {
+		ASSERT(0); /* VMID cannot be 0 for vm context */
+		return;
+	}
+
+	config.page_table_start_addr = va_config->page_table_start_addr;
+	config.page_table_end_addr = va_config->page_table_end_addr;
+	config.page_table_block_size = va_config->page_table_block_size_in_bytes;
+	config.page_table_depth = va_config->page_table_depth;
+	config.page_table_base_addr = va_config->page_table_base_addr;
+
+	dc->res_pool->hubbub->funcs->init_vm_ctx(dc->res_pool->hubbub, &config, vmid);
+}
+
+static int dcn20_init_sys_ctx(struct dce_hwseq *hws, struct dc *dc, struct dc_phy_addr_space_config *pa_config)
+{
+	struct dcn_hubbub_phys_addr_config config;
+
+	config.system_aperture.fb_top = pa_config->system_aperture.fb_top;
+	config.system_aperture.fb_offset = pa_config->system_aperture.fb_offset;
+	config.system_aperture.fb_base = pa_config->system_aperture.fb_base;
+	config.system_aperture.agp_top = pa_config->system_aperture.agp_top;
+	config.system_aperture.agp_bot = pa_config->system_aperture.agp_bot;
+	config.system_aperture.agp_base = pa_config->system_aperture.agp_base;
+	config.gart_config.page_table_start_addr = pa_config->gart_config.page_table_start_addr;
+	config.gart_config.page_table_end_addr = pa_config->gart_config.page_table_end_addr;
+	config.gart_config.page_table_base_addr = pa_config->gart_config.page_table_base_addr;
+
+	return dc->res_pool->hubbub->funcs->init_dchub_sys_ctx(dc->res_pool->hubbub, &config);
 }
 
 static bool patch_address_for_sbs_tb_stereo(
@@ -1619,30 +1634,19 @@ static void dcn20_update_plane_addr(const struct dc *dc, struct pipe_ctx *pipe_c
 	bool addr_patched = false;
 	PHYSICAL_ADDRESS_LOC addr;
 	struct dc_plane_state *plane_state = pipe_ctx->plane_state;
-	uint8_t vmid;
 
 	if (plane_state == NULL)
 		return;
 
 	addr_patched = patch_address_for_sbs_tb_stereo(pipe_ctx, &addr);
 
-	// Call Helper to assign correct VMID to this PTB
-	vmid = get_vmid_for_ptb(dc->vm_helper,
-			plane_state->address.page_table_base.quad_part,
-			pipe_ctx->pipe_idx);
-
-	// Call hubbub to program PTB of VMID only if its VA
-	// PA PTB is a one-time setup at init
-	if (vmid > 0 && dc->res_pool->hubbub->funcs->setup_vmid_ptb)
-		dc->res_pool->hubbub->funcs->setup_vmid_ptb(dc->res_pool->hubbub,
-				plane_state->address.page_table_base.quad_part,
-				vmid);
+	// Call Helper to track VMID use
+	vm_helper_mark_vmid_used(dc->vm_helper, plane_state->address.vmid, pipe_ctx->plane_res.hubp->inst);
 
 	pipe_ctx->plane_res.hubp->funcs->hubp_program_surface_flip_and_addr(
 			pipe_ctx->plane_res.hubp,
 			&plane_state->address,
-			plane_state->flip_immediate,
-			vmid);
+			plane_state->flip_immediate);
 
 	plane_state->status.requested_address = plane_state->address;
 
@@ -1991,7 +1995,8 @@ void dcn20_hw_sequencer_construct(struct dc *dc)
 	dc->hwss.blank_pixel_data = dcn20_blank_pixel_data;
 	dc->hwss.dmdata_status_done = dcn20_dmdata_status_done;
 	dc->hwss.disable_stream = dcn20_disable_stream;
-	dc->hwss.init_dchub = dcn20_init_dchub;
+	dc->hwss.init_sys_ctx = dcn20_init_sys_ctx;
+	dc->hwss.init_vm_ctx = dcn20_init_vm_ctx;
 	dc->hwss.disable_stream_gating = dcn20_disable_stream_gating;
 	dc->hwss.enable_stream_gating = dcn20_enable_stream_gating;
 	dc->hwss.setup_vupdate_interrupt = dcn20_setup_vupdate_interrupt;

commit 043f5bb630c18edaaaad9c55ee60f8828e416ff4
Author: Wesley Chalmers <Wesley.Chalmers@amd.com>
Date:   Thu May 23 11:54:12 2019 -0400

    drm/amd/display: Use macro for invalid OPP ID
    
    [WHY]
    This is meant to make it clearer that 0xf is not a valid OPP ID, and
    that code making use of OPP IDs should not accept this value.
    
    Signed-off-by: Wesley Chalmers <Wesley.Chalmers@amd.com>
    Reviewed-by: Charlene Liu <Charlene.Liu@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 2cbffe2809b6..d55b15fbfe99 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -605,7 +605,7 @@ static void dcn20_init_hw(struct dc *dc)
 		pipe_ctx->plane_res.dpp = dpp;
 		pipe_ctx->plane_res.mpcc_inst = dpp->inst;
 		hubp->mpcc_id = dpp->inst;
-		hubp->opp_id = 0xf;
+		hubp->opp_id = OPP_ID_INVALID;
 		hubp->power_gated = false;
 		pipe_ctx->stream_res.opp = NULL;
 
@@ -1307,7 +1307,7 @@ static void dcn20_apply_ctx_for_surface(
 		if (pipe_ctx->plane_state && !old_pipe_ctx->plane_state) {
 			if (old_pipe_ctx->stream_res.tg == tg &&
 			    old_pipe_ctx->plane_res.hubp &&
-			    old_pipe_ctx->plane_res.hubp->opp_id != 0xf)
+			    old_pipe_ctx->plane_res.hubp->opp_id != OPP_ID_INVALID)
 				dcn20_disable_plane(dc, old_pipe_ctx);
 		}
 

commit 3979efcec6272848fca96496c53096f6ee8aa32f
Author: Jun Lei <Jun.Lei@amd.com>
Date:   Mon May 13 15:09:13 2019 -0400

    drm/amd/display: Add missing VM conversion from hw values
    
    [why]
    VM implemenation is missing conversion from HW values in hubbub
    DM not passing actual PTB during flip
    
    [how]
    add proper HW conversion from logical values
    fix cases where we programmed VA even though we are in PA
    plumb in PTB from DM
    
    Signed-off-by: Jun Lei <Jun.Lei@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 914071393d1c..2cbffe2809b6 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1631,8 +1631,9 @@ static void dcn20_update_plane_addr(const struct dc *dc, struct pipe_ctx *pipe_c
 			plane_state->address.page_table_base.quad_part,
 			pipe_ctx->pipe_idx);
 
-	// Call hubbub to program PTB of VMID
-	if (dc->res_pool->hubbub->funcs->setup_vmid_ptb)
+	// Call hubbub to program PTB of VMID only if its VA
+	// PA PTB is a one-time setup at init
+	if (vmid > 0 && dc->res_pool->hubbub->funcs->setup_vmid_ptb)
 		dc->res_pool->hubbub->funcs->setup_vmid_ptb(dc->res_pool->hubbub,
 				plane_state->address.page_table_base.quad_part,
 				vmid);

commit 98ce8cc1b47ab74e96e08e7b70dc278104f98f36
Author: Nikola Cornij <nikola.cornij@amd.com>
Date:   Wed May 8 14:36:03 2019 -0400

    drm/amd/display: Enable DSC power-gating for DSC streams
    
    [why]
    Currently DSC power gating is disabled by default because the power
    transition doesn't happen, causing a crash on some systems
    
    [how]
    Fix the lack of power state transition and enable DSC power gating
    by default.
    
    Signed-off-by: Nikola Cornij <nikola.cornij@amd.com>
    Reviewed-by: Martin Leung <Martin.Leung@amd.com>
    Reviewed-by: Nevenko Stupar <Nevenko.Stupar@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index f788a39a1df1..914071393d1c 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -222,6 +222,7 @@ static void dcn20_dsc_pg_control(
 {
 	uint32_t power_gate = power_on ? 0 : 1;
 	uint32_t pwr_status = power_on ? 0 : 2;
+	uint32_t org_ip_request_cntl = 0;
 
 	if (hws->ctx->dc->debug.disable_dsc_power_gate)
 		return;
@@ -229,6 +230,10 @@ static void dcn20_dsc_pg_control(
 	if (REG(DOMAIN16_PG_CONFIG) == 0)
 		return;
 
+	REG_GET(DC_IP_REQUEST_CNTL, IP_REQUEST_EN, &org_ip_request_cntl);
+	if (org_ip_request_cntl == 0)
+		REG_SET(DC_IP_REQUEST_CNTL, 0, IP_REQUEST_EN, 1);
+
 	switch (dsc_inst) {
 	case 0: /* DSC0 */
 		REG_UPDATE(DOMAIN16_PG_CONFIG,
@@ -282,6 +287,9 @@ static void dcn20_dsc_pg_control(
 		BREAK_TO_DEBUGGER();
 		break;
 	}
+
+	if (org_ip_request_cntl == 0)
+		REG_SET(DC_IP_REQUEST_CNTL, 0, IP_REQUEST_EN, 0);
 }
 #endif
 

commit 324707fdf83a5c25a99b2ac2500f530d530c89d2
Author: Joshua Aberback <joshua.aberback@amd.com>
Date:   Mon Apr 29 17:27:12 2019 -0400

    drm/amd/display: Set test pattern on blank when using Visual Confirm
    
    [Why]
    We want a test pattern to show up on screen when we're blanked and have
    visual confirm enabled, for debugging. Raven does this, it's a mistake that
    Navi does not.
    
    [How]
     - in "blank_pixel_data", set appropriate DPG pattern for visual confirm
     - refactor DPG calls out of "enable_stream_timing"
    
    Signed-off-by: Joshua Aberback <joshua.aberback@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index f9b0ea75eeb4..f788a39a1df1 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -679,13 +679,8 @@ enum dc_status dcn20_enable_stream_timing(
 		struct dc *dc)
 {
 	struct dc_stream_state *stream = pipe_ctx->stream;
-	enum dc_color_space color_space;
-	struct tg_color black_color = {0};
 	struct drr_params params = {0};
 	unsigned int event_triggers = 0;
-	int width = stream->timing.h_addressable + stream->timing.h_border_left + stream->timing.h_border_right;
-	int height = stream->timing.v_addressable + stream->timing.v_border_bottom + stream->timing.v_border_top;
-	enum controller_dp_test_pattern dpg_pattern = CONTROLLER_DP_TEST_PATTERN_SOLID_COLOR;
 
 
 #if defined(CONFIG_DRM_AMD_DC_DCN2_0)
@@ -734,44 +729,16 @@ enum dc_status dcn20_enable_stream_timing(
 		pipe_ctx->stream_res.tg->funcs->setup_global_lock(
 				pipe_ctx->stream_res.tg);
 
-	/* program otg blank color */
-	color_space = stream->output_color_space;
-	color_space_to_black_color(dc, color_space, &black_color);
-
-	if (odm_pipe) {
-
-		if (dc->debug.visual_confirm != VISUAL_CONFIRM_DISABLE)
-			dpg_pattern = CONTROLLER_DP_TEST_PATTERN_COLORRAMP;
-
-		width /= 2;
-
+	if (odm_pipe)
 		odm_pipe->stream_res.opp->funcs->opp_pipe_clock_control(
 				odm_pipe->stream_res.opp,
 				true);
 
-		odm_pipe->stream_res.opp->funcs->opp_set_disp_pattern_generator(
-				odm_pipe->stream_res.opp,
-				dpg_pattern,
-				stream->timing.display_color_depth,
-				&black_color,
-				width,
-				height);
-	}
-
-	if (dc->debug.visual_confirm != VISUAL_CONFIRM_DISABLE)
-		dpg_pattern = CONTROLLER_DP_TEST_PATTERN_COLORSQUARES;
-
 	pipe_ctx->stream_res.opp->funcs->opp_pipe_clock_control(
 			pipe_ctx->stream_res.opp,
 			true);
 
-	pipe_ctx->stream_res.opp->funcs->opp_set_disp_pattern_generator(
-			pipe_ctx->stream_res.opp,
-			dpg_pattern,
-			stream->timing.display_color_depth,
-			&black_color,
-			width,
-			height);
+	dc->hwss.blank_pixel_data(dc, pipe_ctx, true);
 
 	/* VTG is  within DCHUB command block. DCFCLK is always on */
 	if (false == pipe_ctx->stream_res.tg->funcs->enable_crtc(pipe_ctx->stream_res.tg)) {
@@ -1022,19 +989,17 @@ void dcn20_blank_pixel_data(
 		struct pipe_ctx *pipe_ctx,
 		bool blank)
 {
-	enum dc_color_space color_space;
 	struct tg_color black_color = {0};
 	struct stream_resource *stream_res = &pipe_ctx->stream_res;
 	struct dc_stream_state *stream = pipe_ctx->stream;
+	enum dc_color_space color_space = stream->output_color_space;
 	enum controller_dp_test_pattern test_pattern = CONTROLLER_DP_TEST_PATTERN_SOLID_COLOR;
 	struct pipe_ctx *bot_odm_pipe = dc_res_get_odm_bottom_pipe(pipe_ctx);
 
-
 	int width = stream->timing.h_addressable + stream->timing.h_border_left + stream->timing.h_border_right;
 	int height = stream->timing.v_addressable + stream->timing.v_border_bottom + stream->timing.v_border_top;
 
-	/* program opp dpg blank color */
-	color_space = stream->output_color_space;
+	/* get opp dpg blank color */
 	color_space_to_black_color(dc, color_space, &black_color);
 
 	if (bot_odm_pipe)
@@ -1043,9 +1008,12 @@ void dcn20_blank_pixel_data(
 	if (blank) {
 		if (stream_res->abm)
 			stream_res->abm->funcs->set_abm_immediate_disable(stream_res->abm);
-	} else
-		test_pattern = CONTROLLER_DP_TEST_PATTERN_VIDEOMODE;
 
+		if (dc->debug.visual_confirm != VISUAL_CONFIRM_DISABLE)
+			test_pattern = CONTROLLER_DP_TEST_PATTERN_COLORSQUARES;
+	} else {
+		test_pattern = CONTROLLER_DP_TEST_PATTERN_VIDEOMODE;
+	}
 
 	stream_res->opp->funcs->opp_set_disp_pattern_generator(
 			stream_res->opp,
@@ -1058,7 +1026,8 @@ void dcn20_blank_pixel_data(
 	if (bot_odm_pipe) {
 		bot_odm_pipe->stream_res.opp->funcs->opp_set_disp_pattern_generator(
 				bot_odm_pipe->stream_res.opp,
-				test_pattern,
+				dc->debug.visual_confirm != VISUAL_CONFIRM_DISABLE ?
+						CONTROLLER_DP_TEST_PATTERN_COLORRAMP : test_pattern,
 				stream->timing.display_color_depth,
 				&black_color,
 				width,

commit ad141db915a8b402fd29e553d4f0b9e870141ca6
Author: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Date:   Mon Apr 8 14:56:29 2019 -0400

    drm/amd/display: add null checks and set update flags for DCN2
    
    * add plane state null checks
    * add and set update surface flags
    
    Signed-off-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
    Reviewed-by: Eric Bernstein <Eric.Bernstein@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index ea56f15a51fb..f9b0ea75eeb4 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -492,7 +492,7 @@ static void dcn20_plane_atomic_disable(struct dc *dc, struct pipe_ctx *pipe_ctx)
 }
 
 
-static void dcn20_disable_plane(struct dc *dc, struct pipe_ctx *pipe_ctx)
+void dcn20_disable_plane(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
 	DC_LOGGER_INIT(dc->ctx->logger);
 
@@ -501,8 +501,6 @@ static void dcn20_disable_plane(struct dc *dc, struct pipe_ctx *pipe_ctx)
 
 	dcn20_plane_atomic_disable(dc, pipe_ctx);
 
-	//apply_DEGVIDCN10_253_wa(dc);
-
 	DC_LOG_DC("Power down front end %d\n",
 					pipe_ctx->pipe_idx);
 }
@@ -1092,7 +1090,7 @@ static void dcn20_power_on_plane(
 	}
 }
 
-static void dcn20_enable_plane(
+void dcn20_enable_plane(
 	struct dc *dc,
 	struct pipe_ctx *pipe_ctx,
 	struct dc_state *context)
@@ -1167,7 +1165,7 @@ static void dcn20_enable_plane(
 }
 
 
-void dcn20_program_pipe(
+static void dcn20_program_pipe(
 		struct dc *dc,
 		struct pipe_ctx *pipe_ctx,
 		struct dc_state *context)

commit 97ae9b967517ad5aac265a9966d8ebfc9ee450d2
Author: Joshua Aberback <joshua.aberback@amd.com>
Date:   Tue Apr 23 16:50:50 2019 -0400

    drm/amd/display: Remove OPP clock programming on plane disable
    
    [Why]
    Plane disable gets calls when we enable blank. On DCN2, we blank by using
    DPG to display a black colour instead of using OTG blank. DPG runs off the
    OPP clock, therefore we shouldn't disable the OPP clock when disabling the
    plane. We do need to disable the OPP clock when disabling the entire pipe,
    that will be addressed in a separate commit.
    
    Signed-off-by: Joshua Aberback <joshua.aberback@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index c7ae538611f7..ea56f15a51fb 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -463,7 +463,6 @@ static void dcn20_plane_atomic_disable(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
 	struct hubp *hubp = pipe_ctx->plane_res.hubp;
 	struct dpp *dpp = pipe_ctx->plane_res.dpp;
-	int opp_id = hubp->opp_id;
 
 	dc->hwss.wait_for_mpcc_disconnect(dc, dc->res_pool, pipe_ctx);
 
@@ -479,11 +478,6 @@ static void dcn20_plane_atomic_disable(struct dc *dc, struct pipe_ctx *pipe_ctx)
 
 	dpp->funcs->dpp_dppclk_control(dpp, false, false);
 
-	if (opp_id != 0xf && pipe_ctx->stream_res.opp->mpc_tree_params.opp_list == NULL)
-		pipe_ctx->stream_res.opp->funcs->opp_pipe_clock_control(
-				pipe_ctx->stream_res.opp,
-				false);
-
 	hubp->power_gated = true;
 	dc->optimized_required = false; /* We're powering off, no need to optimize */
 

commit 6bd8d7d3f75be1c327f3fd63e6f03ca68faffb33
Author: Aric Cyr <aric.cyr@amd.com>
Date:   Mon Apr 22 17:45:11 2019 -0400

    drm/amd/display: Intermittent DCN2 pipe hang on mode change
    
    [Why]
    GSL is being used to synchronize pipes when vsync is off but
    on transition to vsync on during a mode change GSL is not
    being reset correctly.
    
    [How]
    Disable GSL on any plane that is disabled.
    
    Signed-off-by: Aric Cyr <aric.cyr@amd.com>
    Reviewed-by: Krunoslav Kovac <Krunoslav.Kovac@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index f9eae47f7be3..c7ae538611f7 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -467,6 +467,14 @@ static void dcn20_plane_atomic_disable(struct dc *dc, struct pipe_ctx *pipe_ctx)
 
 	dc->hwss.wait_for_mpcc_disconnect(dc, dc->res_pool, pipe_ctx);
 
+	/* In flip immediate with pipe splitting case GSL is used for
+	 * synchronization so we must disable it when the plane is disabled.
+	 */
+	if (pipe_ctx->stream_res.gsl_group != 0)
+		dcn20_setup_gsl_group_as_lock(dc, pipe_ctx, false);
+
+	dc->hwss.set_flip_control_gsl(pipe_ctx, false);
+
 	hubp->funcs->hubp_clk_cntl(hubp, false);
 
 	dpp->funcs->dpp_dppclk_control(dpp, false, false);
@@ -1900,14 +1908,14 @@ static int find_free_gsl_group(const struct dc *dc)
 void dcn20_setup_gsl_group_as_lock(
 		const struct dc *dc,
 		struct pipe_ctx *pipe_ctx,
-		bool flip_immediate)
+		bool enable)
 {
 	struct gsl_params gsl;
 	int group_idx;
 
 	memset(&gsl, 0, sizeof(struct gsl_params));
 
-	if (flip_immediate) {
+	if (enable) {
 		/* return if group already assigned since GSL was set up
 		 * for vsync flip, we would unassign so it can't be "left over"
 		 */
@@ -1973,8 +1981,7 @@ void dcn20_setup_gsl_group_as_lock(
 			&gsl);
 
 		pipe_ctx->stream_res.tg->funcs->set_gsl_source_select(
-			pipe_ctx->stream_res.tg, group_idx,
-			flip_immediate ? 4 : 0);
+			pipe_ctx->stream_res.tg, group_idx,	enable ? 4 : 0);
 	} else
 		BREAK_TO_DEBUGGER();
 }

commit 7fad39ca4a1cd721864a3b7da19b2489e73dbf42
Author: Eryk Brol <eryk.brol@amd.com>
Date:   Mon Apr 15 16:09:01 2019 -0400

    drm/amd/display: Change DCN2 vupdate start programming
    
    [Why]
    In order to ensure that incoming flips are latched and
    complete immediately, we need to program the vupdate
    interrupt to come during the back porch of each frame.
    
    [How]
    Program the vupdate start_line to be in the back porch
    like it's done for DCN1.
    
    Signed-off-by: Eryk Brol <eryk.brol@amd.com>
    Reviewed-by: Aric Cyr <Aric.Cyr@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index e7580e6e0fb6..f9eae47f7be3 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1704,13 +1704,10 @@ void dcn20_unblank_stream(struct pipe_ctx *pipe_ctx,
 void dcn20_setup_vupdate_interrupt(struct pipe_ctx *pipe_ctx)
 {
 	struct timing_generator *tg = pipe_ctx->stream_res.tg;
-	int start_position = get_vupdate_offset_from_vsync(pipe_ctx);
-	uint32_t start_line;
+	int start_line = get_vupdate_offset_from_vsync(pipe_ctx);
 
-	if (start_position < 0)
-		start_line = pipe_ctx->stream->timing.v_total + start_position - 1;
-	else
-		start_line = start_position;
+	if (start_line < 0)
+		start_line = 0;
 
 	if (tg->funcs->setup_vertical_interrupt2)
 		tg->funcs->setup_vertical_interrupt2(tg, start_line);

commit 4850ce697f9892df083bd7b3ec7c715404dd4279
Author: Charlene Liu <charlene.liu@amd.com>
Date:   Tue May 7 15:12:02 2019 -0500

    drm/amd/display: Add hubp_init entry to hubp vtable
    
    Different HW will need to init HUBP differently. For now, add a vtable
    entry, and hook a NO-OP for DCN1 and DCN2.
    
    In addition, future HW will need to access the HUBPREQ_DEBUG and
    CUR_TTU_CNTL0 register for hubp_init. Add that here.
    
    Signed-off-by: Charlene Liu <charlene.liu@amd.com>
    Reviewed-by: Jun Lei <Jun.Lei@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Acked-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 2ea72e965c1b..e7580e6e0fb6 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -601,6 +601,8 @@ static void dcn20_init_hw(struct dc *dc)
 		hubp->power_gated = false;
 		pipe_ctx->stream_res.opp = NULL;
 
+		hubp->funcs->hubp_init(hubp);
+
 		//dc->res_pool->opps[i]->mpc_tree_params.opp_id = dc->res_pool->opps[i]->inst;
 		//dc->res_pool->opps[i]->mpc_tree_params.opp_list = NULL;
 		dc->res_pool->opps[i]->mpcc_disconnect_pending[pipe_ctx->plane_res.mpcc_inst] = true;
@@ -1224,7 +1226,7 @@ static void dcn20_program_all_pipe_in_tree(
 		dcn20_program_all_pipe_in_tree(dc, pipe_ctx->bottom_pipe, context);
 }
 
-static void dcn20_pipe_control_lock_global(
+void dcn20_pipe_control_lock_global(
 		struct dc *dc,
 		struct pipe_ctx *pipe,
 		bool lock)
@@ -1244,7 +1246,7 @@ static void dcn20_pipe_control_lock_global(
 	}
 }
 
-static void dcn20_pipe_control_lock(
+void dcn20_pipe_control_lock(
 	struct dc *dc,
 	struct pipe_ctx *pipe,
 	bool lock)

commit fbc9ca671f4ffbc0c873de17cf2305ca438cb09e
Author: Ilya Bakoulin <Ilya.Bakoulin@amd.com>
Date:   Tue Apr 9 11:50:38 2019 -0400

    drm/amd/display: Fix ODM combine data format
    
    [Why]
    OPTC data format was left at its default value (444) when enabling
    ODM combine. This caused issues with FPGA capture.
    
    [How]
    Write the OPTC_DATA_FORMAT field when enabling ODM combine.
    
    Signed-off-by: Ilya Bakoulin <Ilya.Bakoulin@amd.com>
    Reviewed-by: Eric Bernstein <Eric.Bernstein@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Acked-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index fbcb4d860e7a..2ea72e965c1b 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -703,7 +703,8 @@ enum dc_status dcn20_enable_stream_timing(
 		pipe_ctx->stream_res.tg->funcs->set_odm_combine(
 				pipe_ctx->stream_res.tg,
 				odm_pipe->stream_res.opp->inst,
-				pipe_ctx->stream->timing.h_addressable/2);
+				pipe_ctx->stream->timing.h_addressable/2,
+				pipe_ctx->stream->timing.pixel_encoding);
 	/* HW program guide assume display already disable
 	 * by unplug sequence. OTG assume stop.
 	 */
@@ -1007,7 +1008,8 @@ static void dcn20_update_odm(struct dc *dc, struct dc_state *context, struct pip
 		pipe_ctx->stream_res.tg->funcs->set_odm_combine(
 				pipe_ctx->stream_res.tg,
 				combine_pipe->stream_res.opp->inst,
-				pipe_ctx->plane_res.scl_data.h_active);
+				pipe_ctx->plane_res.scl_data.h_active,
+				pipe_ctx->stream->timing.pixel_encoding);
 	else
 		pipe_ctx->stream_res.tg->funcs->set_odm_bypass(
 				pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);

commit 6c5be4ac630805d3a3b20157a0c6421ef815fe78
Author: Wenjing Liu <Wenjing.Liu@amd.com>
Date:   Tue Mar 5 19:28:10 2019 -0500

    drm/amd/display: add global master update lock for DCN2
    
    [why]
    when an update programming sequence requires both
    front end and back end pipe to be updated synchronously,
    a global update lock needs to be set to ensure that
    we don't get a frame with only front end update but
    not the back end update.
    
    [how]
    setup global lock parameters on enable_stream_timing.
    enable global lock when pipe_control_lock_global is called.
    disable global lock when pipe_control_lock is called.
    
    Signed-off-by: Wenjing Liu <Wenjing.Liu@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index dc34ce28505c..fbcb4d860e7a 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -727,6 +727,10 @@ enum dc_status dcn20_enable_stream_timing(
 			pipe_ctx->stream->signal,
 			true);
 
+	if (pipe_ctx->stream_res.tg->funcs->setup_global_lock)
+		pipe_ctx->stream_res.tg->funcs->setup_global_lock(
+				pipe_ctx->stream_res.tg);
+
 	/* program otg blank color */
 	color_space = stream->output_color_space;
 	color_space_to_black_color(dc, color_space, &black_color);

commit 254eb07cb090374d0e1e90790395ead77f6f6ad5
Author: Joshua Aberback <joshua.aberback@amd.com>
Date:   Mon Apr 1 15:18:29 2019 -0400

    drm/amd/display: Optimize bandwidth validation by adding early return
    
    We can split validation into three parts: getting voltage level, getting
    watermarks, and rq/dlg calculations. The voltage level is enough to answer
    the question "do we support this state", and the rest of it is to determine
    what hardware programming is needed to support the state. Most of the calls
    to validate_bandwidth only care about the first part, so we added an early
    return in that case
    
    Signed-off-by: Joshua Aberback <joshua.aberback@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 542f144f807f..dc34ce28505c 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1415,9 +1415,8 @@ bool dcn20_update_bandwidth(
 	int i;
 
 	/* recalculate DML parameters */
-	if (!dc->res_pool->funcs->validate_bandwidth(dc, context, false)) {
+	if (!dc->res_pool->funcs->validate_bandwidth(dc, context, false))
 		return false;
-	}
 
 	/* apply updated bandwidth parameters */
 	dc->hwss.prepare_bandwidth(dc, context);

commit db5378c1dcff3391dac42d714e6064c80702fa3d
Author: Wenjing Liu <Wenjing.Liu@amd.com>
Date:   Thu Mar 28 11:27:05 2019 -0400

    drm/amd/display: isolate global double buffer lock programming
    
    [why]
    Global optic double buffer lock is currently disabled due to
    incorrect programming sequence that affects non global lock.
    
    [how]
    Isolate global lock programming sequence out of non global lock
    programming sequence, so it can be enabled without affecting
    non global lock.
    
    Signed-off-by: Wenjing Liu <Wenjing.Liu@amd.com>
    Reviewed-by: Jun Lei <Jun.Lei@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 0cad51ece06e..542f144f807f 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -727,10 +727,6 @@ enum dc_status dcn20_enable_stream_timing(
 			pipe_ctx->stream->signal,
 			true);
 
-	if (pipe_ctx->stream_res.tg->funcs->setup_global_lock)
-		pipe_ctx->stream_res.tg->funcs->setup_global_lock(
-				pipe_ctx->stream_res.tg);
-
 	/* program otg blank color */
 	color_space = stream->output_color_space;
 	color_space_to_black_color(dc, color_space, &black_color);
@@ -1227,10 +1223,19 @@ static void dcn20_pipe_control_lock_global(
 		struct pipe_ctx *pipe,
 		bool lock)
 {
-	if (lock)
-		pipe->stream_res.tg->funcs->lock_global(pipe->stream_res.tg);
-	else
+	if (lock) {
+		pipe->stream_res.tg->funcs->lock_doublebuffer_enable(
+				pipe->stream_res.tg);
+		pipe->stream_res.tg->funcs->lock(pipe->stream_res.tg);
+	} else {
 		pipe->stream_res.tg->funcs->unlock(pipe->stream_res.tg);
+		pipe->stream_res.tg->funcs->wait_for_state(pipe->stream_res.tg,
+				CRTC_STATE_VACTIVE);
+		pipe->stream_res.tg->funcs->wait_for_state(pipe->stream_res.tg,
+				CRTC_STATE_VBLANK);
+		pipe->stream_res.tg->funcs->lock_doublebuffer_disable(
+				pipe->stream_res.tg);
+	}
 }
 
 static void dcn20_pipe_control_lock(

commit 2e2e73fc632d34b0cec612dc5df0ba64cc98df9a
Author: Joshua Aberback <joshua.aberback@amd.com>
Date:   Tue Mar 26 15:04:31 2019 -0400

    drm/amd/display: Remove dependency on pipe->plane for immedaite flip status
    
    [Why]
    dcn20_apply_ctx_for_surface can be called with 0 planes, which means we
    should blank the display. In this case when we get down to
    dcn20_setup_gsl_group_as_lock, pipe_ctx->plane_state is NULL, but we don't
    check for it. However, this function is only called by
    dcn20_pipe_control_lock, and in that function we alraedy have a local for
    the immediate flip status, which is what we care about in the plane state.
    
    [How]
     - pass in immediate flip status as parameter
    
    Signed-off-by: Joshua Aberback <joshua.aberback@amd.com>
    Reviewed-by: Krunoslav Kovac <Krunoslav.Kovac@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index ccb9f277911a..0cad51ece06e 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1255,7 +1255,7 @@ static void dcn20_pipe_control_lock(
 	if (lock && pipe->bottom_pipe != NULL)
 		if ((flip_immediate && pipe->stream_res.gsl_group == 0) ||
 		    (!flip_immediate && pipe->stream_res.gsl_group > 0))
-			dcn20_setup_gsl_group_as_lock(dc, pipe);
+			dcn20_setup_gsl_group_as_lock(dc, pipe, flip_immediate);
 
 	if (pipe->plane_state != NULL && pipe->plane_state->triplebuffer_flips) {
 		if (lock)
@@ -1890,14 +1890,15 @@ static int find_free_gsl_group(const struct dc *dc)
  */
 void dcn20_setup_gsl_group_as_lock(
 		const struct dc *dc,
-		struct pipe_ctx *pipe_ctx)
+		struct pipe_ctx *pipe_ctx,
+		bool flip_immediate)
 {
 	struct gsl_params gsl;
 	int group_idx;
 
 	memset(&gsl, 0, sizeof(struct gsl_params));
 
-	if (pipe_ctx->plane_state->flip_immediate) {
+	if (flip_immediate) {
 		/* return if group already assigned since GSL was set up
 		 * for vsync flip, we would unassign so it can't be "left over"
 		 */
@@ -1964,7 +1965,7 @@ void dcn20_setup_gsl_group_as_lock(
 
 		pipe_ctx->stream_res.tg->funcs->set_gsl_source_select(
 			pipe_ctx->stream_res.tg, group_idx,
-			pipe_ctx->plane_state->flip_immediate ? 4 : 0);
+			flip_immediate ? 4 : 0);
 	} else
 		BREAK_TO_DEBUGGER();
 }

commit 4e0cbbbfbc37fd5a8bdf653a1ebb7b271a506e2d
Author: Leo Li <sunpeng.li@amd.com>
Date:   Wed Mar 20 09:52:14 2019 -0400

    drm/amd/display: Clean up locking in dcn*_apply_ctx_for_surface()
    
    [Why]
    
    dcn*_disable_plane() doesn't unlock the pipe anymore, making the extra
    lock unnecessary.
    
    In addition - during full plane updates - all necessary pipes should be
    locked/unlocked together when modifying hubp to avoid tearing in
    pipesplit setups.
    
    [How]
    
    Remove redundant locks, and add function to lock all pipes. If an
    interdependent pipe update is required, lock down all pipes. Otherwise,
    lock only the top pipe for the updated pipe tree.
    
    Signed-off-by: Leo Li <sunpeng.li@amd.com>
    Acked-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index f2e5e4928119..ccb9f277911a 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1270,8 +1270,6 @@ static void dcn20_pipe_control_lock(
 	}
 }
 
-
-
 static void dcn20_apply_ctx_for_surface(
 		struct dc *dc,
 		const struct dc_stream_state *stream,
@@ -1282,6 +1280,7 @@ static void dcn20_apply_ctx_for_surface(
 	int i;
 	struct timing_generator *tg;
 	bool removed_pipe[6] = { false };
+	bool interdependent_update = false;
 	struct pipe_ctx *top_pipe_to_program =
 			find_top_pipe_for_stream(dc, context, stream);
 	DC_LOGGER_INIT(dc->ctx->logger);
@@ -1291,7 +1290,13 @@ static void dcn20_apply_ctx_for_surface(
 
 	tg = top_pipe_to_program->stream_res.tg;
 
-	dcn20_pipe_control_lock(dc, top_pipe_to_program, true);
+	interdependent_update = top_pipe_to_program->plane_state &&
+		top_pipe_to_program->plane_state->update_flags.bits.full_update;
+
+	if (interdependent_update)
+		lock_all_pipes(dc, context, true);
+	else
+		dcn20_pipe_control_lock(dc, top_pipe_to_program, true);
 
 	if (num_planes == 0) {
 		/* OTG blank before remove all front end */
@@ -1311,16 +1316,9 @@ static void dcn20_apply_ctx_for_surface(
 		 */
 		if (pipe_ctx->plane_state && !old_pipe_ctx->plane_state) {
 			if (old_pipe_ctx->stream_res.tg == tg &&
-				old_pipe_ctx->plane_res.hubp &&
-				old_pipe_ctx->plane_res.hubp->opp_id != 0xf) {
+			    old_pipe_ctx->plane_res.hubp &&
+			    old_pipe_ctx->plane_res.hubp->opp_id != 0xf)
 				dcn20_disable_plane(dc, old_pipe_ctx);
-
-				/*
-				 * power down fe will unlock when calling reset, need
-				 * to lock it back here. Messy, need rework.
-				 */
-				pipe_ctx->stream_res.tg->funcs->lock(pipe_ctx->stream_res.tg);
-			}
 		}
 
 		if ((!pipe_ctx->plane_state ||
@@ -1343,35 +1341,25 @@ static void dcn20_apply_ctx_for_surface(
 	if ((stream->num_wb_info > 0) && (dc->hwss.program_all_writeback_pipes_in_tree))
 		dc->hwss.program_all_writeback_pipes_in_tree(dc, stream, context);
 
-	dcn20_pipe_control_lock(dc, top_pipe_to_program, false);
-
-	if (top_pipe_to_program->plane_state &&
-			top_pipe_to_program->plane_state->update_flags.bits.full_update)
+	if (interdependent_update)
 		for (i = 0; i < dc->res_pool->pipe_count; i++) {
 			struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
 
 			/* Skip inactive pipes and ones already updated */
-			if (!pipe_ctx->stream || pipe_ctx->stream == stream
-					|| !pipe_ctx->plane_state)
+			if (!pipe_ctx->stream || pipe_ctx->stream == stream ||
+			    !pipe_ctx->plane_state || !tg->funcs->is_tg_enabled(tg))
 				continue;
 
-			pipe_ctx->stream_res.tg->funcs->lock(pipe_ctx->stream_res.tg);
-
 			pipe_ctx->plane_res.hubp->funcs->hubp_setup_interdependent(
 				pipe_ctx->plane_res.hubp,
 				&pipe_ctx->dlg_regs,
 				&pipe_ctx->ttu_regs);
 		}
 
-	for (i = 0; i < dc->res_pool->pipe_count; i++) {
-		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
-
-		if (!pipe_ctx->stream || pipe_ctx->stream == stream
-				|| !pipe_ctx->plane_state)
-			continue;
-
-		dcn20_pipe_control_lock(dc, pipe_ctx, false);
-	}
+	if (interdependent_update)
+		lock_all_pipes(dc, context, false);
+	else
+		dcn20_pipe_control_lock(dc, top_pipe_to_program, false);
 
 	for (i = 0; i < dc->res_pool->pipe_count; i++)
 		if (removed_pipe[i])

commit 1b394e92a149db7ec277b7cc995888304149a5b1
Author: Leo Li <sunpeng.li@amd.com>
Date:   Fri Mar 15 13:50:26 2019 -0400

    drm/amd/display: Disconnect DCN2 mpcc when changing tg
    
    A previous fix was done for DCN1 that needed to be ported to DCN2:
    commit 60c677534e73 ("drm/amd/display: Disconnect mpcc when changing tg")
    
    Signed-off-by: Leo Li <sunpeng.li@amd.com>
    Acked-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index f6e25f75a0a9..f2e5e4928119 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1323,9 +1323,10 @@ static void dcn20_apply_ctx_for_surface(
 			}
 		}
 
-		if (!pipe_ctx->plane_state &&
-			old_pipe_ctx->plane_state &&
-			old_pipe_ctx->stream_res.tg == tg) {
+		if ((!pipe_ctx->plane_state ||
+		     pipe_ctx->stream_res.tg != old_pipe_ctx->stream_res.tg) &&
+		     old_pipe_ctx->plane_state &&
+		     old_pipe_ctx->stream_res.tg == tg) {
 
 			dc->hwss.plane_atomic_disconnect(dc, old_pipe_ctx);
 			removed_pipe[i] = true;

commit 45021f8ea536b5d40decf35af6f91116dd112787
Author: Anthony Koo <Anthony.Koo@amd.com>
Date:   Fri May 10 14:57:48 2019 -0400

    drm/amd/display: do not power on eDP power rail early
    
    [Why]
    Modern Standby may toggle display adapter state between D0
    and D3 state unpredictably.
    But events that cause transition to D0 are not always resulting
    in a display light up scenario.
    
    Modern eDP panels should be able to power on panel logic
    quickly upon VDD going high. Based on spec, the T3 time
    between VDD on and HPD high can be between 0 and 80 ms.
    
    Doing any tricky sorts of optimization by powering on panel
    VDD early during D0 transition on can negatively impact other
    features due to unnecessary power drain and toggling when
    final system state does not intend for the panel to be lit up.
    
    We need OEMs to source higher end panels that have T3 time
    close to 0 if they want quick S3/Modern Standby resume times.
    
    [How]
    Remove panel VDD power on in init_hw
    
    Signed-off-by: Anthony Koo <Anthony.Koo@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 2a34447112e9..f6e25f75a0a9 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -547,9 +547,6 @@ static void dcn20_init_hw(struct dc *dc)
 			 */
 			struct dc_link *link = dc->links[i];
 
-			if (link->link_enc->connector.id == CONNECTOR_ID_EDP)
-				dc->hwss.edp_power_control(link, true);
-
 			link->link_enc->funcs->hw_init(link->link_enc);
 		}
 	}

commit 98b5b65eb8b7136489ba42ae4598f5ed799fa936
Author: Paul Hsieh <paul.hsieh@amd.com>
Date:   Tue May 7 17:58:58 2019 +0800

    drm/amd/display: disable PSR/ABM before destroy DMCU struct
    
    [Why]
    1. DMCU is not running on some platform but driver still send ABM
       command. It may cause assert due to DMCU is not alive.
    2. To make sure PSR disable when driver disable
    
    [How]
    1. Add dmcu_is_running in ABM struct, driver can check this flag to
       determine driver should send ABM command or not.
    2. Send PSR disable command when destroy PSR
    
    Signed-off-by: Paul Hsieh <paul.hsieh@amd.com>
    Reviewed-by: Anthony Koo <Anthony.Koo@amd.com>
    Acked-by: Leo Li <sunpeng.li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 5bed89547410..2a34447112e9 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -657,6 +657,9 @@ static void dcn20_init_hw(struct dc *dc)
 	if (dmcu != NULL)
 		dmcu->funcs->dmcu_init(dmcu);
 
+	if (abm != NULL && dmcu != NULL)
+		abm->dmcu_is_running = dmcu->funcs->is_dmcu_initialized(dmcu);
+
 	/* power AFMT HDMI memory TODO: may move to dis/en output save power*/
 	REG_WRITE(DIO_MEM_PWR_CTRL, 0);
 

commit 3972c3508594310eb868f0e57c44cf0b6fccf7b2
Author: Joshua Aberback <joshua.aberback@amd.com>
Date:   Mon Apr 29 17:21:19 2019 -0400

    drm/amd/display: Program VTG params after programming Global Sync for DCN2
    
    [Why]
    VTG has a parameter FP2, which is defined as:
        if VSTARTUP is before VSYNC:
            FP2 = number of lines in between VSTARTUP and VSYNC
        else
            FP2 = 0
    Currently, FP2 is only programmed during "program_timing". However, the
    position of VSTARTUP is affected by the prefetching requirements on all pipes,
    so the position might change when we do memory request control on another pipe, so we need
    to make sure that FP2 stays up-to-date whenever we adjust VSTARTUP.
    
    [How]
     - refactor VTG_CONTROL programming into a new function "set_vtg_params"
     - call it after calling "program_global_sync"
       - make sure it's called after because it relies on the cached dlg params
    
    Signed-off-by: Joshua Aberback <joshua.aberback@amd.com>
    Reviewed-by: Tony Cheng <Tony.Cheng@amd.com>
    Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
    Acked-by: Jun Lei <Jun.Lei@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 1fd89cc218a5..5bed89547410 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1206,6 +1206,9 @@ static void dcn20_program_all_pipe_in_tree(
 				pipe_ctx->pipe_dlg_param.vupdate_offset,
 				pipe_ctx->pipe_dlg_param.vupdate_width);
 
+		pipe_ctx->stream_res.tg->funcs->set_vtg_params(
+				pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);
+
 		dc->hwss.blank_pixel_data(dc, pipe_ctx, blank);
 
 		if (dc->hwss.update_odm)
@@ -1442,6 +1445,9 @@ bool dcn20_update_bandwidth(
 					pipe_ctx->pipe_dlg_param.vupdate_offset,
 					pipe_ctx->pipe_dlg_param.vupdate_width);
 
+			pipe_ctx->stream_res.tg->funcs->set_vtg_params(
+					pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);
+
 			dc->hwss.blank_pixel_data(dc, pipe_ctx, blank);
 		}
 

commit 97bda0322b8a91aa8d534763e709571b2334e585
Author: Harry Wentland <harry.wentland@amd.com>
Date:   Mon Feb 25 13:26:34 2019 -0500

    drm/amd/display: Add DSC support for Navi (v2)
    
    Add support for DCN2 DSC (Display Stream Compression)
    
    HW Blocks:
    
     +--------++------+       +----------+
     | HUBBUB || HUBP |  <--  | MMHUBBUB |
     +--------++------+       +----------+
            |                     ^
            v                     |
        +--------+            +--------+
        |  DPP   |            |  DWB   |
        +--------+            +--------+
            |
            v                      ^
        +--------+                 |
        |  MPC   |                 |
        +--------+                 |
            |                      |
            v                      |
        +-------+      +-------+   |
        |  OPP  | <--> |  DSC  |   |
        +-------+      +-------+   |
            |                      |
            v                      |
        +--------+                /
        |  OPTC  |  --------------
        +--------+
            |
            v
        +--------+       +--------+
        |  DIO   |       |  DCCG  |
        +--------+       +--------+
    
    v2: rebase (Alex)
    
    Signed-off-by: Harry Wentland <harry.wentland@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 3d5eb20ea9ba..1fd89cc218a5 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -32,6 +32,9 @@
 #include "dcn10/dcn10_hw_sequencer.h"
 #include "dcn20_hwseq.h"
 #include "dce/dce_hwseq.h"
+#ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
+#include "dcn20/dcn20_dsc.h"
+#endif
 #include "abm.h"
 #include "clk_mgr.h"
 #include "dmcu.h"
@@ -211,6 +214,76 @@ static void dcn20_init_blank(
 	dcn20_hwss_wait_for_blank_complete(opp);
 }
 
+#ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
+static void dcn20_dsc_pg_control(
+		struct dce_hwseq *hws,
+		unsigned int dsc_inst,
+		bool power_on)
+{
+	uint32_t power_gate = power_on ? 0 : 1;
+	uint32_t pwr_status = power_on ? 0 : 2;
+
+	if (hws->ctx->dc->debug.disable_dsc_power_gate)
+		return;
+
+	if (REG(DOMAIN16_PG_CONFIG) == 0)
+		return;
+
+	switch (dsc_inst) {
+	case 0: /* DSC0 */
+		REG_UPDATE(DOMAIN16_PG_CONFIG,
+				DOMAIN16_POWER_GATE, power_gate);
+
+		REG_WAIT(DOMAIN16_PG_STATUS,
+				DOMAIN16_PGFSM_PWR_STATUS, pwr_status,
+				1, 1000);
+		break;
+	case 1: /* DSC1 */
+		REG_UPDATE(DOMAIN17_PG_CONFIG,
+				DOMAIN17_POWER_GATE, power_gate);
+
+		REG_WAIT(DOMAIN17_PG_STATUS,
+				DOMAIN17_PGFSM_PWR_STATUS, pwr_status,
+				1, 1000);
+		break;
+	case 2: /* DSC2 */
+		REG_UPDATE(DOMAIN18_PG_CONFIG,
+				DOMAIN18_POWER_GATE, power_gate);
+
+		REG_WAIT(DOMAIN18_PG_STATUS,
+				DOMAIN18_PGFSM_PWR_STATUS, pwr_status,
+				1, 1000);
+		break;
+	case 3: /* DSC3 */
+		REG_UPDATE(DOMAIN19_PG_CONFIG,
+				DOMAIN19_POWER_GATE, power_gate);
+
+		REG_WAIT(DOMAIN19_PG_STATUS,
+				DOMAIN19_PGFSM_PWR_STATUS, pwr_status,
+				1, 1000);
+		break;
+	case 4: /* DSC4 */
+		REG_UPDATE(DOMAIN20_PG_CONFIG,
+				DOMAIN20_POWER_GATE, power_gate);
+
+		REG_WAIT(DOMAIN20_PG_STATUS,
+				DOMAIN20_PGFSM_PWR_STATUS, pwr_status,
+				1, 1000);
+		break;
+	case 5: /* DSC5 */
+		REG_UPDATE(DOMAIN21_PG_CONFIG,
+				DOMAIN21_POWER_GATE, power_gate);
+
+		REG_WAIT(DOMAIN21_PG_STATUS,
+				DOMAIN21_PGFSM_PWR_STATUS, pwr_status,
+				1, 1000);
+		break;
+	default:
+		BREAK_TO_DEBUGGER();
+		break;
+	}
+}
+#endif
 
 static void dcn20_dpp_pg_control(
 		struct dce_hwseq *hws,
@@ -1457,10 +1530,30 @@ bool dcn20_dmdata_status_done(struct pipe_ctx *pipe_ctx)
 
 static void dcn20_disable_stream_gating(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
+#ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
+	struct dce_hwseq *hws = dc->hwseq;
+	struct pipe_ctx *bot_odm_pipe = dc_res_get_odm_bottom_pipe(pipe_ctx);
+
+	if (pipe_ctx->stream_res.dsc) {
+		dcn20_dsc_pg_control(hws, pipe_ctx->stream_res.dsc->inst, true);
+		if (bot_odm_pipe)
+			dcn20_dsc_pg_control(hws, bot_odm_pipe->stream_res.dsc->inst, true);
+	}
+#endif
 }
 
 static void dcn20_enable_stream_gating(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
+#ifdef CONFIG_DRM_AMD_DC_DSC_SUPPORT
+	struct dce_hwseq *hws = dc->hwseq;
+	struct pipe_ctx *bot_odm_pipe = dc_res_get_odm_bottom_pipe(pipe_ctx);
+
+	if (pipe_ctx->stream_res.dsc) {
+		dcn20_dsc_pg_control(hws, pipe_ctx->stream_res.dsc->inst, false);
+		if (bot_odm_pipe)
+			dcn20_dsc_pg_control(hws, bot_odm_pipe->stream_res.dsc->inst, false);
+	}
+#endif
 }
 
 void dcn20_set_dmdata_attributes(struct pipe_ctx *pipe_ctx)

commit e249428256e2b6d18936d139a3f9a2893ed74955
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Mon Apr 22 16:41:54 2019 -0500

    drm/amd/display: updates for dcn20_update_bandwidth
    
    Pass extra parameter to validate_bandwidth() callback.
    
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index 487a07cbeb93..3d5eb20ea9ba 100644
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -1345,7 +1345,7 @@ bool dcn20_update_bandwidth(
 	int i;
 
 	/* recalculate DML parameters */
-	if (!dc->res_pool->funcs->validate_bandwidth(dc, context)) {
+	if (!dc->res_pool->funcs->validate_bandwidth(dc, context, false)) {
 		return false;
 	}
 

commit 7ed4e6352c16fe018864bc4e626c48e27a0cefee
Author: Harry Wentland <harry.wentland@amd.com>
Date:   Fri Feb 22 16:52:08 2019 -0500

    drm/amd/display: Add DCN2 HW Sequencer and Resource
    
    Add DCN2 resource definition and HW Sequencer changes.
    
    Signed-off-by: Harry Wentland <harry.wentland@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
new file mode 100644
index 000000000000..487a07cbeb93
--- /dev/null
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@ -0,0 +1,1926 @@
+/*
+ * Copyright 2016 Advanced Micro Devices, Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: AMD
+ *
+ */
+
+#include "dm_services.h"
+#include "dm_helpers.h"
+#include "core_types.h"
+#include "resource.h"
+#include "dcn20/dcn20_resource.h"
+#include "dce110/dce110_hw_sequencer.h"
+#include "dcn10/dcn10_hw_sequencer.h"
+#include "dcn20_hwseq.h"
+#include "dce/dce_hwseq.h"
+#include "abm.h"
+#include "clk_mgr.h"
+#include "dmcu.h"
+#include "hubp.h"
+#include "timing_generator.h"
+#include "opp.h"
+#include "ipp.h"
+#include "mpc.h"
+#include "mcif_wb.h"
+#include "reg_helper.h"
+#include "dcn10/dcn10_cm_common.h"
+#include "dcn10/dcn10_hubbub.h"
+#include "dcn10/dcn10_optc.h"
+#include "dc_link_dp.h"
+#include "vm_helper.h"
+#include "dccg.h"
+
+#define DC_LOGGER_INIT(logger)
+
+#define CTX \
+	hws->ctx
+#define REG(reg)\
+	hws->regs->reg
+
+#undef FN
+#define FN(reg_name, field_name) \
+	hws->shifts->field_name, hws->masks->field_name
+
+static void bios_golden_init(struct dc *dc)
+{
+	struct dc_bios *bp = dc->ctx->dc_bios;
+	int i;
+
+	/* initialize dcn global */
+	bp->funcs->enable_disp_power_gating(bp,
+			CONTROLLER_ID_D0, ASIC_PIPE_INIT);
+
+	for (i = 0; i < dc->res_pool->pipe_count; i++) {
+		/* initialize dcn per pipe */
+		bp->funcs->enable_disp_power_gating(bp,
+				CONTROLLER_ID_D0 + i, ASIC_PIPE_DISABLE);
+	}
+}
+
+static void enable_power_gating_plane(
+	struct dce_hwseq *hws,
+	bool enable)
+{
+	bool force_on = 1; /* disable power gating */
+
+	if (enable)
+		force_on = 0;
+
+	/* DCHUBP0/1/2/3/4/5 */
+	REG_UPDATE(DOMAIN0_PG_CONFIG, DOMAIN0_POWER_FORCEON, force_on);
+	REG_UPDATE(DOMAIN2_PG_CONFIG, DOMAIN2_POWER_FORCEON, force_on);
+	REG_UPDATE(DOMAIN4_PG_CONFIG, DOMAIN4_POWER_FORCEON, force_on);
+	REG_UPDATE(DOMAIN6_PG_CONFIG, DOMAIN6_POWER_FORCEON, force_on);
+	REG_UPDATE(DOMAIN8_PG_CONFIG, DOMAIN8_POWER_FORCEON, force_on);
+	/*Do not power gate DCHUB5, should be left at HW default, power on permanently*/
+	/*REG_UPDATE(DOMAIN10_PG_CONFIG, DOMAIN10_POWER_FORCEON, force_on);*/
+
+	/* DPP0/1/2/3/4/5 */
+	REG_UPDATE(DOMAIN1_PG_CONFIG, DOMAIN1_POWER_FORCEON, force_on);
+	REG_UPDATE(DOMAIN3_PG_CONFIG, DOMAIN3_POWER_FORCEON, force_on);
+	REG_UPDATE(DOMAIN5_PG_CONFIG, DOMAIN5_POWER_FORCEON, force_on);
+	REG_UPDATE(DOMAIN7_PG_CONFIG, DOMAIN7_POWER_FORCEON, force_on);
+	REG_UPDATE(DOMAIN9_PG_CONFIG, DOMAIN9_POWER_FORCEON, force_on);
+	/*Do not power gate DPP5, should be left at HW default, power on permanently*/
+	/*REG_UPDATE(DOMAIN11_PG_CONFIG, DOMAIN11_POWER_FORCEON, force_on);*/
+
+	REG_UPDATE(DOMAIN16_PG_CONFIG, DOMAIN16_POWER_FORCEON, force_on);
+	REG_UPDATE(DOMAIN17_PG_CONFIG, DOMAIN17_POWER_FORCEON, force_on);
+	REG_UPDATE(DOMAIN18_PG_CONFIG, DOMAIN18_POWER_FORCEON, force_on);
+	REG_UPDATE(DOMAIN19_PG_CONFIG, DOMAIN19_POWER_FORCEON, force_on);
+	REG_UPDATE(DOMAIN20_PG_CONFIG, DOMAIN20_POWER_FORCEON, force_on);
+	REG_UPDATE(DOMAIN21_PG_CONFIG, DOMAIN21_POWER_FORCEON, force_on);
+}
+
+static void dcn20_dccg_init(struct dce_hwseq *hws)
+{
+	/*
+	 * set MICROSECOND_TIME_BASE_DIV
+	 * 100Mhz refclk -> 0x120264
+	 * 27Mhz refclk -> 0x12021b
+	 * 48Mhz refclk -> 0x120230
+	 *
+	 */
+	REG_WRITE(MICROSECOND_TIME_BASE_DIV, 0x120264);
+
+	/*
+	 * set MILLISECOND_TIME_BASE_DIV
+	 * 100Mhz refclk -> 0x1186a0
+	 * 27Mhz refclk -> 0x106978
+	 * 48Mhz refclk -> 0x10bb80
+	 *
+	 */
+	REG_WRITE(MILLISECOND_TIME_BASE_DIV, 0x1186a0);
+
+	/* This value is dependent on the hardware pipeline delay so set once per SOC */
+	REG_WRITE(DISPCLK_FREQ_CHANGE_CNTL, 0x801003c);
+}
+
+static void disable_vga(
+	struct dce_hwseq *hws)
+{
+	REG_WRITE(D1VGA_CONTROL, 0);
+	REG_WRITE(D2VGA_CONTROL, 0);
+	REG_WRITE(D3VGA_CONTROL, 0);
+	REG_WRITE(D4VGA_CONTROL, 0);
+	REG_WRITE(D5VGA_CONTROL, 0);
+	REG_WRITE(D6VGA_CONTROL, 0);
+}
+
+void dcn20_program_tripleBuffer(
+	const struct dc *dc,
+	struct pipe_ctx *pipe_ctx,
+	bool enableTripleBuffer)
+{
+	if (pipe_ctx->plane_res.hubp && pipe_ctx->plane_res.hubp->funcs) {
+		pipe_ctx->plane_res.hubp->funcs->hubp_enable_tripleBuffer(
+			pipe_ctx->plane_res.hubp,
+			enableTripleBuffer);
+	}
+}
+
+/* Blank pixel data during initialization */
+static void dcn20_init_blank(
+		struct dc *dc,
+		struct timing_generator *tg)
+{
+	enum dc_color_space color_space;
+	struct tg_color black_color = {0};
+	struct output_pixel_processor *opp = NULL;
+	struct output_pixel_processor *bottom_opp = NULL;
+	uint32_t num_opps, opp_id_src0, opp_id_src1;
+	uint32_t otg_active_width, otg_active_height;
+
+	/* program opp dpg blank color */
+	color_space = COLOR_SPACE_SRGB;
+	color_space_to_black_color(dc, color_space, &black_color);
+
+	/* get the OTG active size */
+	tg->funcs->get_otg_active_size(tg,
+			&otg_active_width,
+			&otg_active_height);
+
+	/* get the OPTC source */
+	tg->funcs->get_optc_source(tg, &num_opps, &opp_id_src0, &opp_id_src1);
+	ASSERT(opp_id_src0 < dc->res_pool->res_cap->num_opp);
+	opp = dc->res_pool->opps[opp_id_src0];
+
+	if (num_opps == 2) {
+		otg_active_width = otg_active_width / 2;
+		ASSERT(opp_id_src1 < dc->res_pool->res_cap->num_opp);
+		bottom_opp = dc->res_pool->opps[opp_id_src1];
+	}
+
+	opp->funcs->opp_set_disp_pattern_generator(
+			opp,
+			CONTROLLER_DP_TEST_PATTERN_SOLID_COLOR,
+			COLOR_DEPTH_UNDEFINED,
+			&black_color,
+			otg_active_width,
+			otg_active_height);
+
+	if (num_opps == 2) {
+		bottom_opp->funcs->opp_set_disp_pattern_generator(
+				bottom_opp,
+				CONTROLLER_DP_TEST_PATTERN_SOLID_COLOR,
+				COLOR_DEPTH_UNDEFINED,
+				&black_color,
+				otg_active_width,
+				otg_active_height);
+	}
+
+	dcn20_hwss_wait_for_blank_complete(opp);
+}
+
+
+static void dcn20_dpp_pg_control(
+		struct dce_hwseq *hws,
+		unsigned int dpp_inst,
+		bool power_on)
+{
+	uint32_t power_gate = power_on ? 0 : 1;
+	uint32_t pwr_status = power_on ? 0 : 2;
+
+	if (hws->ctx->dc->debug.disable_dpp_power_gate)
+		return;
+	if (REG(DOMAIN1_PG_CONFIG) == 0)
+		return;
+
+	switch (dpp_inst) {
+	case 0: /* DPP0 */
+		REG_UPDATE(DOMAIN1_PG_CONFIG,
+				DOMAIN1_POWER_GATE, power_gate);
+
+		REG_WAIT(DOMAIN1_PG_STATUS,
+				DOMAIN1_PGFSM_PWR_STATUS, pwr_status,
+				1, 1000);
+		break;
+	case 1: /* DPP1 */
+		REG_UPDATE(DOMAIN3_PG_CONFIG,
+				DOMAIN3_POWER_GATE, power_gate);
+
+		REG_WAIT(DOMAIN3_PG_STATUS,
+				DOMAIN3_PGFSM_PWR_STATUS, pwr_status,
+				1, 1000);
+		break;
+	case 2: /* DPP2 */
+		REG_UPDATE(DOMAIN5_PG_CONFIG,
+				DOMAIN5_POWER_GATE, power_gate);
+
+		REG_WAIT(DOMAIN5_PG_STATUS,
+				DOMAIN5_PGFSM_PWR_STATUS, pwr_status,
+				1, 1000);
+		break;
+	case 3: /* DPP3 */
+		REG_UPDATE(DOMAIN7_PG_CONFIG,
+				DOMAIN7_POWER_GATE, power_gate);
+
+		REG_WAIT(DOMAIN7_PG_STATUS,
+				DOMAIN7_PGFSM_PWR_STATUS, pwr_status,
+				1, 1000);
+		break;
+	case 4: /* DPP4 */
+		REG_UPDATE(DOMAIN9_PG_CONFIG,
+				DOMAIN9_POWER_GATE, power_gate);
+
+		REG_WAIT(DOMAIN9_PG_STATUS,
+				DOMAIN9_PGFSM_PWR_STATUS, pwr_status,
+				1, 1000);
+		break;
+	case 5: /* DPP5 */
+		/*
+		 * Do not power gate DPP5, should be left at HW default, power on permanently.
+		 * PG on Pipe5 is De-featured, attempting to put it to PG state may result in hard
+		 * reset.
+		 * REG_UPDATE(DOMAIN11_PG_CONFIG,
+		 *		DOMAIN11_POWER_GATE, power_gate);
+		 *
+		 * REG_WAIT(DOMAIN11_PG_STATUS,
+		 *		DOMAIN11_PGFSM_PWR_STATUS, pwr_status,
+		 * 		1, 1000);
+		 */
+		break;
+	default:
+		BREAK_TO_DEBUGGER();
+		break;
+	}
+}
+
+
+static void dcn20_hubp_pg_control(
+		struct dce_hwseq *hws,
+		unsigned int hubp_inst,
+		bool power_on)
+{
+	uint32_t power_gate = power_on ? 0 : 1;
+	uint32_t pwr_status = power_on ? 0 : 2;
+
+	if (hws->ctx->dc->debug.disable_hubp_power_gate)
+		return;
+	if (REG(DOMAIN0_PG_CONFIG) == 0)
+		return;
+
+	switch (hubp_inst) {
+	case 0: /* DCHUBP0 */
+		REG_UPDATE(DOMAIN0_PG_CONFIG,
+				DOMAIN0_POWER_GATE, power_gate);
+
+		REG_WAIT(DOMAIN0_PG_STATUS,
+				DOMAIN0_PGFSM_PWR_STATUS, pwr_status,
+				1, 1000);
+		break;
+	case 1: /* DCHUBP1 */
+		REG_UPDATE(DOMAIN2_PG_CONFIG,
+				DOMAIN2_POWER_GATE, power_gate);
+
+		REG_WAIT(DOMAIN2_PG_STATUS,
+				DOMAIN2_PGFSM_PWR_STATUS, pwr_status,
+				1, 1000);
+		break;
+	case 2: /* DCHUBP2 */
+		REG_UPDATE(DOMAIN4_PG_CONFIG,
+				DOMAIN4_POWER_GATE, power_gate);
+
+		REG_WAIT(DOMAIN4_PG_STATUS,
+				DOMAIN4_PGFSM_PWR_STATUS, pwr_status,
+				1, 1000);
+		break;
+	case 3: /* DCHUBP3 */
+		REG_UPDATE(DOMAIN6_PG_CONFIG,
+				DOMAIN6_POWER_GATE, power_gate);
+
+		REG_WAIT(DOMAIN6_PG_STATUS,
+				DOMAIN6_PGFSM_PWR_STATUS, pwr_status,
+				1, 1000);
+		break;
+	case 4: /* DCHUBP4 */
+		REG_UPDATE(DOMAIN8_PG_CONFIG,
+				DOMAIN8_POWER_GATE, power_gate);
+
+		REG_WAIT(DOMAIN8_PG_STATUS,
+				DOMAIN8_PGFSM_PWR_STATUS, pwr_status,
+				1, 1000);
+		break;
+	case 5: /* DCHUBP5 */
+		/*
+		 * Do not power gate DCHUB5, should be left at HW default, power on permanently.
+		 * PG on Pipe5 is De-featured, attempting to put it to PG state may result in hard
+		 * reset.
+		 * REG_UPDATE(DOMAIN10_PG_CONFIG,
+		 *		DOMAIN10_POWER_GATE, power_gate);
+		 *
+		 * REG_WAIT(DOMAIN10_PG_STATUS,
+		 *		DOMAIN10_PGFSM_PWR_STATUS, pwr_status,
+		 *		1, 1000);
+		 */
+		break;
+	default:
+		BREAK_TO_DEBUGGER();
+		break;
+	}
+}
+
+
+
+static void dcn20_plane_atomic_power_down(struct dc *dc, struct pipe_ctx *pipe_ctx)
+{
+	struct dce_hwseq *hws = dc->hwseq;
+	struct dpp *dpp = pipe_ctx->plane_res.dpp;
+
+	DC_LOGGER_INIT(dc->ctx->logger);
+
+	if (REG(DC_IP_REQUEST_CNTL)) {
+		REG_SET(DC_IP_REQUEST_CNTL, 0,
+				IP_REQUEST_EN, 1);
+		dcn20_dpp_pg_control(hws, dpp->inst, false);
+		dcn20_hubp_pg_control(hws, pipe_ctx->plane_res.hubp->inst, false);
+		dpp->funcs->dpp_reset(dpp);
+		REG_SET(DC_IP_REQUEST_CNTL, 0,
+				IP_REQUEST_EN, 0);
+		DC_LOG_DEBUG(
+				"Power gated front end %d\n", pipe_ctx->pipe_idx);
+	}
+}
+
+
+
+/* disable HW used by plane.
+ * note:  cannot disable until disconnect is complete
+ */
+static void dcn20_plane_atomic_disable(struct dc *dc, struct pipe_ctx *pipe_ctx)
+{
+	struct hubp *hubp = pipe_ctx->plane_res.hubp;
+	struct dpp *dpp = pipe_ctx->plane_res.dpp;
+	int opp_id = hubp->opp_id;
+
+	dc->hwss.wait_for_mpcc_disconnect(dc, dc->res_pool, pipe_ctx);
+
+	hubp->funcs->hubp_clk_cntl(hubp, false);
+
+	dpp->funcs->dpp_dppclk_control(dpp, false, false);
+
+	if (opp_id != 0xf && pipe_ctx->stream_res.opp->mpc_tree_params.opp_list == NULL)
+		pipe_ctx->stream_res.opp->funcs->opp_pipe_clock_control(
+				pipe_ctx->stream_res.opp,
+				false);
+
+	hubp->power_gated = true;
+	dc->optimized_required = false; /* We're powering off, no need to optimize */
+
+	dcn20_plane_atomic_power_down(dc, pipe_ctx);
+
+	pipe_ctx->stream = NULL;
+	memset(&pipe_ctx->stream_res, 0, sizeof(pipe_ctx->stream_res));
+	memset(&pipe_ctx->plane_res, 0, sizeof(pipe_ctx->plane_res));
+	pipe_ctx->top_pipe = NULL;
+	pipe_ctx->bottom_pipe = NULL;
+	pipe_ctx->plane_state = NULL;
+}
+
+
+static void dcn20_disable_plane(struct dc *dc, struct pipe_ctx *pipe_ctx)
+{
+	DC_LOGGER_INIT(dc->ctx->logger);
+
+	if (!pipe_ctx->plane_res.hubp || pipe_ctx->plane_res.hubp->power_gated)
+		return;
+
+	dcn20_plane_atomic_disable(dc, pipe_ctx);
+
+	//apply_DEGVIDCN10_253_wa(dc);
+
+	DC_LOG_DC("Power down front end %d\n",
+					pipe_ctx->pipe_idx);
+}
+
+static void dcn20_init_hw(struct dc *dc)
+{
+	int i, j;
+	struct abm *abm = dc->res_pool->abm;
+	struct dmcu *dmcu = dc->res_pool->dmcu;
+	struct dce_hwseq *hws = dc->hwseq;
+	struct dc_bios *dcb = dc->ctx->dc_bios;
+	struct resource_pool *res_pool = dc->res_pool;
+	struct dc_state  *context = dc->current_state;
+
+	if (dc->clk_mgr && dc->clk_mgr->funcs->init_clocks)
+		dc->clk_mgr->funcs->init_clocks(dc->clk_mgr);
+
+	// Initialize the dccg
+	if (res_pool->dccg->funcs->dccg_init)
+		res_pool->dccg->funcs->dccg_init(res_pool->dccg);
+
+	//Enable ability to power gate / don't force power on permanently
+	enable_power_gating_plane(dc->hwseq, true);
+
+	if (IS_FPGA_MAXIMUS_DC(dc->ctx->dce_environment)) {
+		REG_WRITE(RBBMIF_TIMEOUT_DIS, 0xFFFFFFFF);
+		REG_WRITE(RBBMIF_TIMEOUT_DIS_2, 0xFFFFFFFF);
+
+		dcn20_dccg_init(hws);
+
+		REG_UPDATE(DCHUBBUB_GLOBAL_TIMER_CNTL, DCHUBBUB_GLOBAL_TIMER_REFDIV, 2);
+		REG_UPDATE(DCHUBBUB_GLOBAL_TIMER_CNTL, DCHUBBUB_GLOBAL_TIMER_ENABLE, 1);
+		REG_WRITE(REFCLK_CNTL, 0);
+	} else {
+		if (!dcb->funcs->is_accelerated_mode(dcb)) {
+			bios_golden_init(dc);
+			disable_vga(dc->hwseq);
+		}
+
+		for (i = 0; i < dc->link_count; i++) {
+			/* Power up AND update implementation according to the
+			 * required signal (which may be different from the
+			 * default signal on connector).
+			 */
+			struct dc_link *link = dc->links[i];
+
+			if (link->link_enc->connector.id == CONNECTOR_ID_EDP)
+				dc->hwss.edp_power_control(link, true);
+
+			link->link_enc->funcs->hw_init(link->link_enc);
+		}
+	}
+
+	/* Blank pixel data with OPP DPG */
+	for (i = 0; i < dc->res_pool->timing_generator_count; i++) {
+		struct timing_generator *tg = dc->res_pool->timing_generators[i];
+
+		if (tg->funcs->is_tg_enabled(tg)) {
+			dcn20_init_blank(dc, tg);
+		}
+	}
+
+	for (i = 0; i < res_pool->timing_generator_count; i++) {
+		struct timing_generator *tg = dc->res_pool->timing_generators[i];
+
+		if (tg->funcs->is_tg_enabled(tg))
+			tg->funcs->lock(tg);
+	}
+
+	for (i = 0; i < dc->res_pool->pipe_count; i++) {
+		struct dpp *dpp = res_pool->dpps[i];
+
+		dpp->funcs->dpp_reset(dpp);
+	}
+
+	/* Reset all MPCC muxes */
+	res_pool->mpc->funcs->mpc_init(res_pool->mpc);
+
+	/* initialize OPP mpc_tree parameter */
+	for (i = 0; i < dc->res_pool->res_cap->num_opp; i++) {
+		res_pool->opps[i]->mpc_tree_params.opp_id = res_pool->opps[i]->inst;
+		res_pool->opps[i]->mpc_tree_params.opp_list = NULL;
+		for (j = 0; j < MAX_PIPES; j++)
+			res_pool->opps[i]->mpcc_disconnect_pending[j] = false;
+	}
+
+	for (i = 0; i < dc->res_pool->pipe_count; i++) {
+		struct timing_generator *tg = dc->res_pool->timing_generators[i];
+		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
+		struct hubp *hubp = dc->res_pool->hubps[i];
+		struct dpp *dpp = dc->res_pool->dpps[i];
+
+		pipe_ctx->stream_res.tg = tg;
+		pipe_ctx->pipe_idx = i;
+
+		pipe_ctx->plane_res.hubp = hubp;
+		pipe_ctx->plane_res.dpp = dpp;
+		pipe_ctx->plane_res.mpcc_inst = dpp->inst;
+		hubp->mpcc_id = dpp->inst;
+		hubp->opp_id = 0xf;
+		hubp->power_gated = false;
+		pipe_ctx->stream_res.opp = NULL;
+
+		//dc->res_pool->opps[i]->mpc_tree_params.opp_id = dc->res_pool->opps[i]->inst;
+		//dc->res_pool->opps[i]->mpc_tree_params.opp_list = NULL;
+		dc->res_pool->opps[i]->mpcc_disconnect_pending[pipe_ctx->plane_res.mpcc_inst] = true;
+		pipe_ctx->stream_res.opp = dc->res_pool->opps[i];
+		/*to do*/
+		hwss1_plane_atomic_disconnect(dc, pipe_ctx);
+	}
+
+	/* initialize DWB pointer to MCIF_WB */
+	for (i = 0; i < res_pool->res_cap->num_dwb; i++)
+		res_pool->dwbc[i]->mcif = res_pool->mcif_wb[i];
+
+	for (i = 0; i < dc->res_pool->timing_generator_count; i++) {
+		struct timing_generator *tg = dc->res_pool->timing_generators[i];
+
+		if (tg->funcs->is_tg_enabled(tg))
+			tg->funcs->unlock(tg);
+	}
+
+	for (i = 0; i < dc->res_pool->pipe_count; i++) {
+		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
+
+		dc->hwss.disable_plane(dc, pipe_ctx);
+
+		pipe_ctx->stream_res.tg = NULL;
+		pipe_ctx->plane_res.hubp = NULL;
+	}
+
+	for (i = 0; i < dc->res_pool->timing_generator_count; i++) {
+		struct timing_generator *tg = dc->res_pool->timing_generators[i];
+
+		tg->funcs->tg_init(tg);
+	}
+
+	/* end of FPGA. Below if real ASIC */
+	if (IS_FPGA_MAXIMUS_DC(dc->ctx->dce_environment))
+		return;
+
+
+	for (i = 0; i < res_pool->audio_count; i++) {
+		struct audio *audio = res_pool->audios[i];
+
+		audio->funcs->hw_init(audio);
+	}
+
+	if (abm != NULL) {
+		abm->funcs->init_backlight(abm);
+		abm->funcs->abm_init(abm);
+	}
+
+	if (dmcu != NULL)
+		dmcu->funcs->dmcu_init(dmcu);
+
+	/* power AFMT HDMI memory TODO: may move to dis/en output save power*/
+	REG_WRITE(DIO_MEM_PWR_CTRL, 0);
+
+	if (!dc->debug.disable_clock_gate) {
+		/* enable all DCN clock gating */
+		REG_WRITE(DCCG_GATE_DISABLE_CNTL, 0);
+
+		REG_WRITE(DCCG_GATE_DISABLE_CNTL2, 0);
+
+		REG_UPDATE(DCFCLK_CNTL, DCFCLK_GATE_DIS, 0);
+	}
+
+}
+
+enum dc_status dcn20_enable_stream_timing(
+		struct pipe_ctx *pipe_ctx,
+		struct dc_state *context,
+		struct dc *dc)
+{
+	struct dc_stream_state *stream = pipe_ctx->stream;
+	enum dc_color_space color_space;
+	struct tg_color black_color = {0};
+	struct drr_params params = {0};
+	unsigned int event_triggers = 0;
+	int width = stream->timing.h_addressable + stream->timing.h_border_left + stream->timing.h_border_right;
+	int height = stream->timing.v_addressable + stream->timing.v_border_bottom + stream->timing.v_border_top;
+	enum controller_dp_test_pattern dpg_pattern = CONTROLLER_DP_TEST_PATTERN_SOLID_COLOR;
+
+
+#if defined(CONFIG_DRM_AMD_DC_DCN2_0)
+	struct pipe_ctx *odm_pipe = dc_res_get_odm_bottom_pipe(pipe_ctx);
+#endif
+
+	/* by upper caller loop, pipe0 is parent pipe and be called first.
+	 * back end is set up by for pipe0. Other children pipe share back end
+	 * with pipe 0. No program is needed.
+	 */
+	if (pipe_ctx->top_pipe != NULL)
+		return DC_OK;
+
+	/* TODO check if timing_changed, disable stream if timing changed */
+
+	if (odm_pipe)
+		pipe_ctx->stream_res.tg->funcs->set_odm_combine(
+				pipe_ctx->stream_res.tg,
+				odm_pipe->stream_res.opp->inst,
+				pipe_ctx->stream->timing.h_addressable/2);
+	/* HW program guide assume display already disable
+	 * by unplug sequence. OTG assume stop.
+	 */
+	pipe_ctx->stream_res.tg->funcs->enable_optc_clock(pipe_ctx->stream_res.tg, true);
+
+	if (false == pipe_ctx->clock_source->funcs->program_pix_clk(
+			pipe_ctx->clock_source,
+			&pipe_ctx->stream_res.pix_clk_params,
+			&pipe_ctx->pll_settings)) {
+		BREAK_TO_DEBUGGER();
+		return DC_ERROR_UNEXPECTED;
+	}
+
+	pipe_ctx->stream_res.tg->funcs->program_timing(
+			pipe_ctx->stream_res.tg,
+			&stream->timing,
+			pipe_ctx->pipe_dlg_param.vready_offset,
+			pipe_ctx->pipe_dlg_param.vstartup_start,
+			pipe_ctx->pipe_dlg_param.vupdate_offset,
+			pipe_ctx->pipe_dlg_param.vupdate_width,
+			pipe_ctx->stream->signal,
+			true);
+
+	if (pipe_ctx->stream_res.tg->funcs->setup_global_lock)
+		pipe_ctx->stream_res.tg->funcs->setup_global_lock(
+				pipe_ctx->stream_res.tg);
+
+	/* program otg blank color */
+	color_space = stream->output_color_space;
+	color_space_to_black_color(dc, color_space, &black_color);
+
+	if (odm_pipe) {
+
+		if (dc->debug.visual_confirm != VISUAL_CONFIRM_DISABLE)
+			dpg_pattern = CONTROLLER_DP_TEST_PATTERN_COLORRAMP;
+
+		width /= 2;
+
+		odm_pipe->stream_res.opp->funcs->opp_pipe_clock_control(
+				odm_pipe->stream_res.opp,
+				true);
+
+		odm_pipe->stream_res.opp->funcs->opp_set_disp_pattern_generator(
+				odm_pipe->stream_res.opp,
+				dpg_pattern,
+				stream->timing.display_color_depth,
+				&black_color,
+				width,
+				height);
+	}
+
+	if (dc->debug.visual_confirm != VISUAL_CONFIRM_DISABLE)
+		dpg_pattern = CONTROLLER_DP_TEST_PATTERN_COLORSQUARES;
+
+	pipe_ctx->stream_res.opp->funcs->opp_pipe_clock_control(
+			pipe_ctx->stream_res.opp,
+			true);
+
+	pipe_ctx->stream_res.opp->funcs->opp_set_disp_pattern_generator(
+			pipe_ctx->stream_res.opp,
+			dpg_pattern,
+			stream->timing.display_color_depth,
+			&black_color,
+			width,
+			height);
+
+	/* VTG is  within DCHUB command block. DCFCLK is always on */
+	if (false == pipe_ctx->stream_res.tg->funcs->enable_crtc(pipe_ctx->stream_res.tg)) {
+		BREAK_TO_DEBUGGER();
+		return DC_ERROR_UNEXPECTED;
+	}
+
+	dcn20_hwss_wait_for_blank_complete(pipe_ctx->stream_res.opp);
+
+	params.vertical_total_min = stream->adjust.v_total_min;
+	params.vertical_total_max = stream->adjust.v_total_max;
+	if (pipe_ctx->stream_res.tg->funcs->set_drr)
+		pipe_ctx->stream_res.tg->funcs->set_drr(
+			pipe_ctx->stream_res.tg, &params);
+
+	// DRR should set trigger event to monitor surface update event
+	if (stream->adjust.v_total_min != 0 && stream->adjust.v_total_max != 0)
+		event_triggers = 0x80;
+	if (pipe_ctx->stream_res.tg->funcs->set_static_screen_control)
+		pipe_ctx->stream_res.tg->funcs->set_static_screen_control(
+				pipe_ctx->stream_res.tg, event_triggers);
+
+	/* TODO program crtc source select for non-virtual signal*/
+	/* TODO program FMT */
+	/* TODO setup link_enc */
+	/* TODO set stream attributes */
+	/* TODO program audio */
+	/* TODO enable stream if timing changed */
+	/* TODO unblank stream if DP */
+
+	return DC_OK;
+}
+
+void dcn20_program_output_csc(struct dc *dc,
+		struct pipe_ctx *pipe_ctx,
+		enum dc_color_space colorspace,
+		uint16_t *matrix,
+		int opp_id)
+{
+	struct mpc *mpc = dc->res_pool->mpc;
+	enum mpc_output_csc_mode ocsc_mode = MPC_OUTPUT_CSC_COEF_A;
+
+	if (pipe_ctx->stream->csc_color_matrix.enable_adjustment == true) {
+		if (mpc->funcs->set_output_csc != NULL)
+			mpc->funcs->set_output_csc(mpc,
+					opp_id,
+					matrix,
+					ocsc_mode);
+	} else {
+		if (mpc->funcs->set_ocsc_default != NULL)
+			mpc->funcs->set_ocsc_default(mpc,
+					opp_id,
+					colorspace,
+					ocsc_mode);
+	}
+}
+
+bool dcn20_set_output_transfer_func(struct pipe_ctx *pipe_ctx,
+				const struct dc_stream_state *stream)
+{
+	int mpcc_id = pipe_ctx->plane_res.hubp->inst;
+	struct mpc *mpc = pipe_ctx->stream_res.opp->ctx->dc->res_pool->mpc;
+	struct pwl_params *params = NULL;
+	/*
+	 * program OGAM only for the top pipe
+	 * if there is a pipe split then fix diagnostic is required:
+	 * how to pass OGAM parameter for stream.
+	 * if programming for all pipes is required then remove condition
+	 * pipe_ctx->top_pipe == NULL ,but then fix the diagnostic.
+	 */
+	if ((pipe_ctx->top_pipe == NULL || dc_res_is_odm_head_pipe(pipe_ctx))
+			&& mpc->funcs->set_output_gamma && stream->out_transfer_func) {
+		if (stream->out_transfer_func->type == TF_TYPE_HWPWL)
+			params = &stream->out_transfer_func->pwl;
+		else if (pipe_ctx->stream->out_transfer_func->type ==
+			TF_TYPE_DISTRIBUTED_POINTS &&
+			cm_helper_translate_curve_to_hw_format(
+			stream->out_transfer_func,
+			&mpc->blender_params, false))
+			params = &mpc->blender_params;
+		/*
+		 * there is no ROM
+		 */
+		if (stream->out_transfer_func->type == TF_TYPE_PREDEFINED)
+			BREAK_TO_DEBUGGER();
+	}
+	/*
+	 * if above if is not executed then 'params' equal to 0 and set in bypass
+	 */
+	mpc->funcs->set_output_gamma(mpc, mpcc_id, params);
+
+	return true;
+}
+
+static bool dcn20_set_blend_lut(
+	struct pipe_ctx *pipe_ctx, const struct dc_plane_state *plane_state)
+{
+	struct dpp *dpp_base = pipe_ctx->plane_res.dpp;
+	bool result = true;
+	struct pwl_params *blend_lut = NULL;
+
+	if (plane_state->blend_tf) {
+		if (plane_state->blend_tf->type == TF_TYPE_HWPWL)
+			blend_lut = &plane_state->blend_tf->pwl;
+		else if (plane_state->blend_tf->type == TF_TYPE_DISTRIBUTED_POINTS) {
+			cm_helper_translate_curve_to_hw_format(
+					plane_state->blend_tf,
+					&dpp_base->regamma_params, false);
+			blend_lut = &dpp_base->regamma_params;
+		}
+	}
+	result = dpp_base->funcs->dpp_program_blnd_lut(dpp_base, blend_lut);
+
+	return result;
+}
+
+static bool dcn20_set_shaper_3dlut(
+	struct pipe_ctx *pipe_ctx, const struct dc_plane_state *plane_state)
+{
+	struct dpp *dpp_base = pipe_ctx->plane_res.dpp;
+	bool result = true;
+	struct pwl_params *shaper_lut = NULL;
+
+	if (plane_state->in_shaper_func) {
+		if (plane_state->in_shaper_func->type == TF_TYPE_HWPWL)
+			shaper_lut = &plane_state->in_shaper_func->pwl;
+		else if (plane_state->in_shaper_func->type == TF_TYPE_DISTRIBUTED_POINTS) {
+			cm_helper_translate_curve_to_hw_format(
+					plane_state->in_shaper_func,
+					&dpp_base->shaper_params, true);
+			shaper_lut = &dpp_base->shaper_params;
+		}
+	}
+
+	result = dpp_base->funcs->dpp_program_shaper_lut(dpp_base, shaper_lut);
+	if (plane_state->lut3d_func &&
+		plane_state->lut3d_func->initialized == true)
+		result = dpp_base->funcs->dpp_program_3dlut(dpp_base,
+								&plane_state->lut3d_func->lut_3d);
+	else
+		result = dpp_base->funcs->dpp_program_3dlut(dpp_base, NULL);
+
+	if (plane_state->lut3d_func &&
+		plane_state->lut3d_func->initialized == true &&
+		plane_state->lut3d_func->hdr_multiplier != 0)
+		dpp_base->funcs->dpp_set_hdr_multiplier(dpp_base,
+				plane_state->lut3d_func->hdr_multiplier);
+	else
+		dpp_base->funcs->dpp_set_hdr_multiplier(dpp_base, 0x1f000);
+
+	return result;
+}
+
+bool dcn20_set_input_transfer_func(struct pipe_ctx *pipe_ctx,
+					  const struct dc_plane_state *plane_state)
+{
+	struct dpp *dpp_base = pipe_ctx->plane_res.dpp;
+	const struct dc_transfer_func *tf = NULL;
+	bool result = true;
+	bool use_degamma_ram = false;
+
+	if (dpp_base == NULL || plane_state == NULL)
+		return false;
+
+	dcn20_set_shaper_3dlut(pipe_ctx, plane_state);
+	dcn20_set_blend_lut(pipe_ctx, plane_state);
+
+	if (plane_state->in_transfer_func)
+		tf = plane_state->in_transfer_func;
+
+
+	if (tf == NULL) {
+		dpp_base->funcs->dpp_set_degamma(dpp_base,
+				IPP_DEGAMMA_MODE_BYPASS);
+		return true;
+	}
+
+	if (tf->type == TF_TYPE_HWPWL || tf->type == TF_TYPE_DISTRIBUTED_POINTS)
+		use_degamma_ram = true;
+
+	if (use_degamma_ram == true) {
+		if (tf->type == TF_TYPE_HWPWL)
+			dpp_base->funcs->dpp_program_degamma_pwl(dpp_base,
+					&tf->pwl);
+		else if (tf->type == TF_TYPE_DISTRIBUTED_POINTS) {
+			cm_helper_translate_curve_to_degamma_hw_format(tf,
+					&dpp_base->degamma_params);
+			dpp_base->funcs->dpp_program_degamma_pwl(dpp_base,
+				&dpp_base->degamma_params);
+		}
+		return true;
+	}
+	/* handle here the optimized cases when de-gamma ROM could be used.
+	 *
+	 */
+	if (tf->type == TF_TYPE_PREDEFINED) {
+		switch (tf->tf) {
+		case TRANSFER_FUNCTION_SRGB:
+			dpp_base->funcs->dpp_set_degamma(dpp_base,
+					IPP_DEGAMMA_MODE_HW_sRGB);
+			break;
+		case TRANSFER_FUNCTION_BT709:
+			dpp_base->funcs->dpp_set_degamma(dpp_base,
+					IPP_DEGAMMA_MODE_HW_xvYCC);
+			break;
+		case TRANSFER_FUNCTION_LINEAR:
+			dpp_base->funcs->dpp_set_degamma(dpp_base,
+					IPP_DEGAMMA_MODE_BYPASS);
+			break;
+		case TRANSFER_FUNCTION_PQ:
+		default:
+			result = false;
+			break;
+		}
+	} else if (tf->type == TF_TYPE_BYPASS)
+		dpp_base->funcs->dpp_set_degamma(dpp_base,
+				IPP_DEGAMMA_MODE_BYPASS);
+	else {
+		/*
+		 * if we are here, we did not handle correctly.
+		 * fix is required for this use case
+		 */
+		BREAK_TO_DEBUGGER();
+		dpp_base->funcs->dpp_set_degamma(dpp_base,
+				IPP_DEGAMMA_MODE_BYPASS);
+	}
+
+	return result;
+}
+
+static void dcn20_update_odm(struct dc *dc, struct dc_state *context, struct pipe_ctx *pipe_ctx)
+{
+	struct pipe_ctx *combine_pipe = dc_res_get_odm_bottom_pipe(pipe_ctx);
+
+	if (combine_pipe)
+		pipe_ctx->stream_res.tg->funcs->set_odm_combine(
+				pipe_ctx->stream_res.tg,
+				combine_pipe->stream_res.opp->inst,
+				pipe_ctx->plane_res.scl_data.h_active);
+	else
+		pipe_ctx->stream_res.tg->funcs->set_odm_bypass(
+				pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);
+}
+
+void dcn20_blank_pixel_data(
+		struct dc *dc,
+		struct pipe_ctx *pipe_ctx,
+		bool blank)
+{
+	enum dc_color_space color_space;
+	struct tg_color black_color = {0};
+	struct stream_resource *stream_res = &pipe_ctx->stream_res;
+	struct dc_stream_state *stream = pipe_ctx->stream;
+	enum controller_dp_test_pattern test_pattern = CONTROLLER_DP_TEST_PATTERN_SOLID_COLOR;
+	struct pipe_ctx *bot_odm_pipe = dc_res_get_odm_bottom_pipe(pipe_ctx);
+
+
+	int width = stream->timing.h_addressable + stream->timing.h_border_left + stream->timing.h_border_right;
+	int height = stream->timing.v_addressable + stream->timing.v_border_bottom + stream->timing.v_border_top;
+
+	/* program opp dpg blank color */
+	color_space = stream->output_color_space;
+	color_space_to_black_color(dc, color_space, &black_color);
+
+	if (bot_odm_pipe)
+		width = width / 2;
+
+	if (blank) {
+		if (stream_res->abm)
+			stream_res->abm->funcs->set_abm_immediate_disable(stream_res->abm);
+	} else
+		test_pattern = CONTROLLER_DP_TEST_PATTERN_VIDEOMODE;
+
+
+	stream_res->opp->funcs->opp_set_disp_pattern_generator(
+			stream_res->opp,
+			test_pattern,
+			stream->timing.display_color_depth,
+			&black_color,
+			width,
+			height);
+
+	if (bot_odm_pipe) {
+		bot_odm_pipe->stream_res.opp->funcs->opp_set_disp_pattern_generator(
+				bot_odm_pipe->stream_res.opp,
+				test_pattern,
+				stream->timing.display_color_depth,
+				&black_color,
+				width,
+				height);
+	}
+
+	if (!blank)
+		if (stream_res->abm) {
+			stream_res->abm->funcs->set_pipe(stream_res->abm, stream_res->tg->inst + 1);
+			stream_res->abm->funcs->set_abm_level(stream_res->abm, stream->abm_level);
+		}
+}
+
+
+static void dcn20_power_on_plane(
+	struct dce_hwseq *hws,
+	struct pipe_ctx *pipe_ctx)
+{
+	DC_LOGGER_INIT(hws->ctx->logger);
+	if (REG(DC_IP_REQUEST_CNTL)) {
+		REG_SET(DC_IP_REQUEST_CNTL, 0,
+				IP_REQUEST_EN, 1);
+		dcn20_dpp_pg_control(hws, pipe_ctx->plane_res.dpp->inst, true);
+		dcn20_hubp_pg_control(hws, pipe_ctx->plane_res.hubp->inst, true);
+		REG_SET(DC_IP_REQUEST_CNTL, 0,
+				IP_REQUEST_EN, 0);
+		DC_LOG_DEBUG(
+				"Un-gated front end for pipe %d\n", pipe_ctx->plane_res.hubp->inst);
+	}
+}
+
+static void dcn20_enable_plane(
+	struct dc *dc,
+	struct pipe_ctx *pipe_ctx,
+	struct dc_state *context)
+{
+	//if (dc->debug.sanity_checks) {
+	//	dcn10_verify_allow_pstate_change_high(dc);
+	//}
+	dcn20_power_on_plane(dc->hwseq, pipe_ctx);
+
+	/* enable DCFCLK current DCHUB */
+	pipe_ctx->plane_res.hubp->funcs->hubp_clk_cntl(pipe_ctx->plane_res.hubp, true);
+
+	/* make sure OPP_PIPE_CLOCK_EN = 1 */
+	pipe_ctx->stream_res.opp->funcs->opp_pipe_clock_control(
+			pipe_ctx->stream_res.opp,
+			true);
+
+/* TODO: enable/disable in dm as per update type.
+	if (plane_state) {
+		DC_LOG_DC(dc->ctx->logger,
+				"Pipe:%d 0x%x: addr hi:0x%x, "
+				"addr low:0x%x, "
+				"src: %d, %d, %d,"
+				" %d; dst: %d, %d, %d, %d;\n",
+				pipe_ctx->pipe_idx,
+				plane_state,
+				plane_state->address.grph.addr.high_part,
+				plane_state->address.grph.addr.low_part,
+				plane_state->src_rect.x,
+				plane_state->src_rect.y,
+				plane_state->src_rect.width,
+				plane_state->src_rect.height,
+				plane_state->dst_rect.x,
+				plane_state->dst_rect.y,
+				plane_state->dst_rect.width,
+				plane_state->dst_rect.height);
+
+		DC_LOG_DC(dc->ctx->logger,
+				"Pipe %d: width, height, x, y         format:%d\n"
+				"viewport:%d, %d, %d, %d\n"
+				"recout:  %d, %d, %d, %d\n",
+				pipe_ctx->pipe_idx,
+				plane_state->format,
+				pipe_ctx->plane_res.scl_data.viewport.width,
+				pipe_ctx->plane_res.scl_data.viewport.height,
+				pipe_ctx->plane_res.scl_data.viewport.x,
+				pipe_ctx->plane_res.scl_data.viewport.y,
+				pipe_ctx->plane_res.scl_data.recout.width,
+				pipe_ctx->plane_res.scl_data.recout.height,
+				pipe_ctx->plane_res.scl_data.recout.x,
+				pipe_ctx->plane_res.scl_data.recout.y);
+		print_rq_dlg_ttu(dc, pipe_ctx);
+	}
+*/
+	if (dc->vm_config.valid) {
+		struct vm_system_aperture_param apt;
+
+		apt.sys_default.quad_part = 0;
+		apt.sys_high.quad_part = 0;
+		apt.sys_low.quad_part = 0;
+
+		apt.sys_high.quad_part = dc->vm_config.pa_config.system_aperture.start_addr;
+		apt.sys_low.quad_part = dc->vm_config.pa_config.system_aperture.end_addr;
+
+		// Program system aperture settings
+		pipe_ctx->plane_res.hubp->funcs->hubp_set_vm_system_aperture_settings(pipe_ctx->plane_res.hubp, &apt);
+	}
+
+//	if (dc->debug.sanity_checks) {
+//		dcn10_verify_allow_pstate_change_high(dc);
+//	}
+}
+
+
+void dcn20_program_pipe(
+		struct dc *dc,
+		struct pipe_ctx *pipe_ctx,
+		struct dc_state *context)
+{
+	pipe_ctx->plane_state->update_flags.bits.full_update =
+			context->commit_hints.full_update_needed ? 1 : pipe_ctx->plane_state->update_flags.bits.full_update;
+
+	if (pipe_ctx->plane_state->update_flags.bits.full_update)
+		dcn20_enable_plane(dc, pipe_ctx, context);
+
+	update_dchubp_dpp(dc, pipe_ctx, context);
+
+	set_hdr_multiplier(pipe_ctx);
+
+	if (pipe_ctx->plane_state->update_flags.bits.full_update ||
+			pipe_ctx->plane_state->update_flags.bits.in_transfer_func_change ||
+			pipe_ctx->plane_state->update_flags.bits.gamma_change)
+		dc->hwss.set_input_transfer_func(pipe_ctx, pipe_ctx->plane_state);
+
+	/* dcn10_translate_regamma_to_hw_format takes 750us to finish
+	 * only do gamma programming for full update.
+	 * TODO: This can be further optimized/cleaned up
+	 * Always call this for now since it does memcmp inside before
+	 * doing heavy calculation and programming
+	 */
+	if (pipe_ctx->plane_state->update_flags.bits.full_update)
+		dc->hwss.set_output_transfer_func(pipe_ctx, pipe_ctx->stream);
+}
+
+static void dcn20_program_all_pipe_in_tree(
+		struct dc *dc,
+		struct pipe_ctx *pipe_ctx,
+		struct dc_state *context)
+{
+	if (pipe_ctx->top_pipe == NULL) {
+		bool blank = !is_pipe_tree_visible(pipe_ctx);
+
+		pipe_ctx->stream_res.tg->funcs->program_global_sync(
+				pipe_ctx->stream_res.tg,
+				pipe_ctx->pipe_dlg_param.vready_offset,
+				pipe_ctx->pipe_dlg_param.vstartup_start,
+				pipe_ctx->pipe_dlg_param.vupdate_offset,
+				pipe_ctx->pipe_dlg_param.vupdate_width);
+
+		dc->hwss.blank_pixel_data(dc, pipe_ctx, blank);
+
+		if (dc->hwss.update_odm)
+			dc->hwss.update_odm(dc, context, pipe_ctx);
+	}
+
+	if (pipe_ctx->plane_state != NULL)
+		dcn20_program_pipe(dc, pipe_ctx, context);
+
+	if (pipe_ctx->bottom_pipe != NULL && pipe_ctx->bottom_pipe != pipe_ctx)
+		dcn20_program_all_pipe_in_tree(dc, pipe_ctx->bottom_pipe, context);
+}
+
+static void dcn20_pipe_control_lock_global(
+		struct dc *dc,
+		struct pipe_ctx *pipe,
+		bool lock)
+{
+	if (lock)
+		pipe->stream_res.tg->funcs->lock_global(pipe->stream_res.tg);
+	else
+		pipe->stream_res.tg->funcs->unlock(pipe->stream_res.tg);
+}
+
+static void dcn20_pipe_control_lock(
+	struct dc *dc,
+	struct pipe_ctx *pipe,
+	bool lock)
+{
+	bool flip_immediate = false;
+
+	/* use TG master update lock to lock everything on the TG
+	 * therefore only top pipe need to lock
+	 */
+	if (pipe->top_pipe)
+		return;
+
+	if (pipe->plane_state != NULL)
+		flip_immediate = pipe->plane_state->flip_immediate;
+
+	/* In flip immediate and pipe splitting case, we need to use GSL
+	 * for synchronization. Only do setup on locking and on flip type change.
+	 */
+	if (lock && pipe->bottom_pipe != NULL)
+		if ((flip_immediate && pipe->stream_res.gsl_group == 0) ||
+		    (!flip_immediate && pipe->stream_res.gsl_group > 0))
+			dcn20_setup_gsl_group_as_lock(dc, pipe);
+
+	if (pipe->plane_state != NULL && pipe->plane_state->triplebuffer_flips) {
+		if (lock)
+			pipe->stream_res.tg->funcs->triplebuffer_lock(pipe->stream_res.tg);
+		else
+			pipe->stream_res.tg->funcs->triplebuffer_unlock(pipe->stream_res.tg);
+	} else {
+		if (lock)
+			pipe->stream_res.tg->funcs->lock(pipe->stream_res.tg);
+		else
+			pipe->stream_res.tg->funcs->unlock(pipe->stream_res.tg);
+	}
+}
+
+
+
+static void dcn20_apply_ctx_for_surface(
+		struct dc *dc,
+		const struct dc_stream_state *stream,
+		int num_planes,
+		struct dc_state *context)
+{
+
+	int i;
+	struct timing_generator *tg;
+	bool removed_pipe[6] = { false };
+	struct pipe_ctx *top_pipe_to_program =
+			find_top_pipe_for_stream(dc, context, stream);
+	DC_LOGGER_INIT(dc->ctx->logger);
+
+	if (!top_pipe_to_program)
+		return;
+
+	tg = top_pipe_to_program->stream_res.tg;
+
+	dcn20_pipe_control_lock(dc, top_pipe_to_program, true);
+
+	if (num_planes == 0) {
+		/* OTG blank before remove all front end */
+		dc->hwss.blank_pixel_data(dc, top_pipe_to_program, true);
+	}
+
+	/* Disconnect unused mpcc */
+	for (i = 0; i < dc->res_pool->pipe_count; i++) {
+		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
+		struct pipe_ctx *old_pipe_ctx =
+				&dc->current_state->res_ctx.pipe_ctx[i];
+		/*
+		 * Powergate reused pipes that are not powergated
+		 * fairly hacky right now, using opp_id as indicator
+		 * TODO: After move dc_post to dc_update, this will
+		 * be removed.
+		 */
+		if (pipe_ctx->plane_state && !old_pipe_ctx->plane_state) {
+			if (old_pipe_ctx->stream_res.tg == tg &&
+				old_pipe_ctx->plane_res.hubp &&
+				old_pipe_ctx->plane_res.hubp->opp_id != 0xf) {
+				dcn20_disable_plane(dc, old_pipe_ctx);
+
+				/*
+				 * power down fe will unlock when calling reset, need
+				 * to lock it back here. Messy, need rework.
+				 */
+				pipe_ctx->stream_res.tg->funcs->lock(pipe_ctx->stream_res.tg);
+			}
+		}
+
+		if (!pipe_ctx->plane_state &&
+			old_pipe_ctx->plane_state &&
+			old_pipe_ctx->stream_res.tg == tg) {
+
+			dc->hwss.plane_atomic_disconnect(dc, old_pipe_ctx);
+			removed_pipe[i] = true;
+
+			DC_LOG_DC("Reset mpcc for pipe %d\n",
+					old_pipe_ctx->pipe_idx);
+		}
+	}
+
+	if (num_planes > 0)
+		dcn20_program_all_pipe_in_tree(dc, top_pipe_to_program, context);
+
+	/* Program secondary blending tree and writeback pipes */
+	if ((stream->num_wb_info > 0) && (dc->hwss.program_all_writeback_pipes_in_tree))
+		dc->hwss.program_all_writeback_pipes_in_tree(dc, stream, context);
+
+	dcn20_pipe_control_lock(dc, top_pipe_to_program, false);
+
+	if (top_pipe_to_program->plane_state &&
+			top_pipe_to_program->plane_state->update_flags.bits.full_update)
+		for (i = 0; i < dc->res_pool->pipe_count; i++) {
+			struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
+
+			/* Skip inactive pipes and ones already updated */
+			if (!pipe_ctx->stream || pipe_ctx->stream == stream
+					|| !pipe_ctx->plane_state)
+				continue;
+
+			pipe_ctx->stream_res.tg->funcs->lock(pipe_ctx->stream_res.tg);
+
+			pipe_ctx->plane_res.hubp->funcs->hubp_setup_interdependent(
+				pipe_ctx->plane_res.hubp,
+				&pipe_ctx->dlg_regs,
+				&pipe_ctx->ttu_regs);
+		}
+
+	for (i = 0; i < dc->res_pool->pipe_count; i++) {
+		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
+
+		if (!pipe_ctx->stream || pipe_ctx->stream == stream
+				|| !pipe_ctx->plane_state)
+			continue;
+
+		dcn20_pipe_control_lock(dc, pipe_ctx, false);
+	}
+
+	for (i = 0; i < dc->res_pool->pipe_count; i++)
+		if (removed_pipe[i])
+			dcn20_disable_plane(dc, &dc->current_state->res_ctx.pipe_ctx[i]);
+}
+
+
+void dcn20_prepare_bandwidth(
+		struct dc *dc,
+		struct dc_state *context)
+{
+	struct hubbub *hubbub = dc->res_pool->hubbub;
+
+	/* program dchubbub watermarks */
+	hubbub->funcs->program_watermarks(hubbub,
+					&context->bw_ctx.bw.dcn.watermarks,
+					dc->res_pool->ref_clocks.dchub_ref_clock_inKhz / 1000,
+					false);
+
+	dc->clk_mgr->funcs->update_clocks(
+			dc->clk_mgr,
+			context,
+			false);
+}
+
+void dcn20_optimize_bandwidth(
+		struct dc *dc,
+		struct dc_state *context)
+{
+	struct hubbub *hubbub = dc->res_pool->hubbub;
+
+	/* program dchubbub watermarks */
+	hubbub->funcs->program_watermarks(hubbub,
+					&context->bw_ctx.bw.dcn.watermarks,
+					dc->res_pool->ref_clocks.dchub_ref_clock_inKhz / 1000,
+					true);
+
+	dc->clk_mgr->funcs->update_clocks(
+			dc->clk_mgr,
+			context,
+			true);
+}
+
+bool dcn20_update_bandwidth(
+		struct dc *dc,
+		struct dc_state *context)
+{
+	int i;
+
+	/* recalculate DML parameters */
+	if (!dc->res_pool->funcs->validate_bandwidth(dc, context)) {
+		return false;
+	}
+
+	/* apply updated bandwidth parameters */
+	dc->hwss.prepare_bandwidth(dc, context);
+
+	/* update hubp configs for all pipes */
+	for (i = 0; i < dc->res_pool->pipe_count; i++) {
+		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
+
+		if (pipe_ctx->plane_state == NULL)
+			continue;
+
+		if (pipe_ctx->top_pipe == NULL) {
+			bool blank = !is_pipe_tree_visible(pipe_ctx);
+
+			pipe_ctx->stream_res.tg->funcs->program_global_sync(
+					pipe_ctx->stream_res.tg,
+					pipe_ctx->pipe_dlg_param.vready_offset,
+					pipe_ctx->pipe_dlg_param.vstartup_start,
+					pipe_ctx->pipe_dlg_param.vupdate_offset,
+					pipe_ctx->pipe_dlg_param.vupdate_width);
+
+			dc->hwss.blank_pixel_data(dc, pipe_ctx, blank);
+		}
+
+		pipe_ctx->plane_res.hubp->funcs->hubp_setup(
+				pipe_ctx->plane_res.hubp,
+					&pipe_ctx->dlg_regs,
+					&pipe_ctx->ttu_regs,
+					&pipe_ctx->rq_regs,
+					&pipe_ctx->pipe_dlg_param);
+	}
+
+	return true;
+}
+
+static void dcn20_enable_writeback(
+		struct dc *dc,
+		const struct dc_stream_status *stream_status,
+		struct dc_writeback_info *wb_info)
+{
+	struct dwbc *dwb;
+	struct mcif_wb *mcif_wb;
+	struct timing_generator *optc;
+
+	ASSERT(wb_info->dwb_pipe_inst < MAX_DWB_PIPES);
+	ASSERT(wb_info->wb_enabled);
+	dwb = dc->res_pool->dwbc[wb_info->dwb_pipe_inst];
+	mcif_wb = dc->res_pool->mcif_wb[wb_info->dwb_pipe_inst];
+
+	/* set the OPTC source mux */
+	ASSERT(stream_status->primary_otg_inst < MAX_PIPES);
+	optc = dc->res_pool->timing_generators[stream_status->primary_otg_inst];
+	optc->funcs->set_dwb_source(optc, wb_info->dwb_pipe_inst);
+	/* set MCIF_WB buffer and arbitration configuration */
+	mcif_wb->funcs->config_mcif_buf(mcif_wb, &wb_info->mcif_buf_params, wb_info->dwb_params.dest_height);
+	mcif_wb->funcs->config_mcif_arb(mcif_wb, &dc->current_state->bw_ctx.bw.dcn.bw_writeback.mcif_wb_arb[wb_info->dwb_pipe_inst]);
+	/* Enable MCIF_WB */
+	mcif_wb->funcs->enable_mcif(mcif_wb);
+	/* Enable DWB */
+	dwb->funcs->enable(dwb, &wb_info->dwb_params);
+	/* TODO: add sequence to enable/disable warmup */
+}
+
+void dcn20_disable_writeback(
+		struct dc *dc,
+		unsigned int dwb_pipe_inst)
+{
+	struct dwbc *dwb;
+	struct mcif_wb *mcif_wb;
+
+	ASSERT(dwb_pipe_inst < MAX_DWB_PIPES);
+	dwb = dc->res_pool->dwbc[dwb_pipe_inst];
+	mcif_wb = dc->res_pool->mcif_wb[dwb_pipe_inst];
+
+	dwb->funcs->disable(dwb);
+	mcif_wb->funcs->disable_mcif(mcif_wb);
+}
+
+bool dcn20_hwss_wait_for_blank_complete(
+		struct output_pixel_processor *opp)
+{
+	int counter;
+
+	for (counter = 0; counter < 1000; counter++) {
+		if (opp->funcs->dpg_is_blanked(opp))
+			break;
+
+		udelay(100);
+	}
+
+	if (counter == 1000) {
+		dm_error("DC: failed to blank crtc!\n");
+		return false;
+	}
+
+	return true;
+}
+
+bool dcn20_dmdata_status_done(struct pipe_ctx *pipe_ctx)
+{
+	struct hubp *hubp = pipe_ctx->plane_res.hubp;
+
+	if (!hubp)
+		return false;
+	return hubp->funcs->dmdata_status_done(hubp);
+}
+
+static void dcn20_disable_stream_gating(struct dc *dc, struct pipe_ctx *pipe_ctx)
+{
+}
+
+static void dcn20_enable_stream_gating(struct dc *dc, struct pipe_ctx *pipe_ctx)
+{
+}
+
+void dcn20_set_dmdata_attributes(struct pipe_ctx *pipe_ctx)
+{
+	struct dc_dmdata_attributes attr = { 0 };
+	struct hubp *hubp = pipe_ctx->plane_res.hubp;
+
+	attr.dmdata_mode = DMDATA_HW_MODE;
+	attr.dmdata_size =
+		dc_is_hdmi_signal(pipe_ctx->stream->signal) ? 32 : 36;
+	attr.address.quad_part =
+			pipe_ctx->stream->dmdata_address.quad_part;
+	attr.dmdata_dl_delta = 0;
+	attr.dmdata_qos_mode = 0;
+	attr.dmdata_qos_level = 0;
+	attr.dmdata_repeat = 1; /* always repeat */
+	attr.dmdata_updated = 1;
+	attr.dmdata_sw_data = NULL;
+
+	hubp->funcs->dmdata_set_attributes(hubp, &attr);
+}
+
+void dcn20_disable_stream(struct pipe_ctx *pipe_ctx, int option)
+{
+	dce110_disable_stream(pipe_ctx, option);
+}
+
+static void dcn20_init_dchub(struct dce_hwseq *hws, struct dc *dc, struct dc_addr_space_config *config)
+{
+	struct hubbub_addr_config hubbub_config;
+
+	hubbub_config.pa_config.system_aperture.fb_top = config->pa_config.system_aperture.fb_top;
+	hubbub_config.pa_config.system_aperture.fb_offset = config->pa_config.system_aperture.fb_offset;
+	hubbub_config.pa_config.system_aperture.fb_base = config->pa_config.system_aperture.fb_base;
+	hubbub_config.pa_config.system_aperture.agp_top = config->pa_config.system_aperture.agp_top;
+	hubbub_config.pa_config.system_aperture.agp_bot = config->pa_config.system_aperture.agp_bot;
+	hubbub_config.pa_config.system_aperture.agp_base = config->pa_config.system_aperture.agp_base;
+	hubbub_config.pa_config.gart_config.page_table_start_addr = config->pa_config.gart_config.page_table_start_addr;
+	hubbub_config.pa_config.gart_config.page_table_end_addr = config->pa_config.gart_config.page_table_end_addr;
+	hubbub_config.pa_config.gart_config.page_table_base_addr = config->pa_config.gart_config.page_table_base_addr;
+
+	hubbub_config.va_config.page_table_start_addr = config->va_config.page_table_start_addr;
+	hubbub_config.va_config.page_table_end_addr = config->va_config.page_table_end_addr;
+	hubbub_config.va_config.page_table_block_size = config->va_config.page_table_block_size_in_bytes;
+	hubbub_config.va_config.page_table_depth = config->va_config.page_table_depth;
+
+	dc->res_pool->hubbub->funcs->init_dchub(dc->res_pool->hubbub, &hubbub_config);
+}
+
+static bool patch_address_for_sbs_tb_stereo(
+		struct pipe_ctx *pipe_ctx, PHYSICAL_ADDRESS_LOC *addr)
+{
+	struct dc_plane_state *plane_state = pipe_ctx->plane_state;
+	bool sec_split = pipe_ctx->top_pipe &&
+			pipe_ctx->top_pipe->plane_state == pipe_ctx->plane_state;
+	if (sec_split && plane_state->address.type == PLN_ADDR_TYPE_GRPH_STEREO &&
+			(pipe_ctx->stream->timing.timing_3d_format ==
+			TIMING_3D_FORMAT_SIDE_BY_SIDE ||
+			pipe_ctx->stream->timing.timing_3d_format ==
+			TIMING_3D_FORMAT_TOP_AND_BOTTOM)) {
+		*addr = plane_state->address.grph_stereo.left_addr;
+		plane_state->address.grph_stereo.left_addr =
+				plane_state->address.grph_stereo.right_addr;
+		return true;
+	}
+
+	if (pipe_ctx->stream->view_format != VIEW_3D_FORMAT_NONE &&
+			plane_state->address.type != PLN_ADDR_TYPE_GRPH_STEREO) {
+		plane_state->address.type = PLN_ADDR_TYPE_GRPH_STEREO;
+		plane_state->address.grph_stereo.right_addr =
+				plane_state->address.grph_stereo.left_addr;
+	}
+	return false;
+}
+
+
+static void dcn20_update_plane_addr(const struct dc *dc, struct pipe_ctx *pipe_ctx)
+{
+	bool addr_patched = false;
+	PHYSICAL_ADDRESS_LOC addr;
+	struct dc_plane_state *plane_state = pipe_ctx->plane_state;
+	uint8_t vmid;
+
+	if (plane_state == NULL)
+		return;
+
+	addr_patched = patch_address_for_sbs_tb_stereo(pipe_ctx, &addr);
+
+	// Call Helper to assign correct VMID to this PTB
+	vmid = get_vmid_for_ptb(dc->vm_helper,
+			plane_state->address.page_table_base.quad_part,
+			pipe_ctx->pipe_idx);
+
+	// Call hubbub to program PTB of VMID
+	if (dc->res_pool->hubbub->funcs->setup_vmid_ptb)
+		dc->res_pool->hubbub->funcs->setup_vmid_ptb(dc->res_pool->hubbub,
+				plane_state->address.page_table_base.quad_part,
+				vmid);
+
+	pipe_ctx->plane_res.hubp->funcs->hubp_program_surface_flip_and_addr(
+			pipe_ctx->plane_res.hubp,
+			&plane_state->address,
+			plane_state->flip_immediate,
+			vmid);
+
+	plane_state->status.requested_address = plane_state->address;
+
+	if (plane_state->flip_immediate)
+		plane_state->status.current_address = plane_state->address;
+
+	if (addr_patched)
+		pipe_ctx->plane_state->address.grph_stereo.left_addr = addr;
+}
+
+void dcn20_unblank_stream(struct pipe_ctx *pipe_ctx,
+		struct dc_link_settings *link_settings)
+{
+	struct encoder_unblank_param params = { { 0 } };
+	struct dc_stream_state *stream = pipe_ctx->stream;
+	struct dc_link *link = stream->link;
+	params.odm = dc_res_get_odm_bottom_pipe(pipe_ctx);
+
+	/* only 3 items below are used by unblank */
+	params.timing = pipe_ctx->stream->timing;
+
+	params.link_settings.link_rate = link_settings->link_rate;
+
+	if (dc_is_dp_signal(pipe_ctx->stream->signal)) {
+		if (optc1_is_two_pixels_per_containter(&stream->timing) || params.odm)
+			params.timing.pix_clk_100hz /= 2;
+		pipe_ctx->stream_res.stream_enc->funcs->dp_set_odm_combine(
+				pipe_ctx->stream_res.stream_enc, params.odm);
+		pipe_ctx->stream_res.stream_enc->funcs->dp_unblank(pipe_ctx->stream_res.stream_enc, &params);
+	}
+
+	if (link->local_sink && link->local_sink->sink_signal == SIGNAL_TYPE_EDP) {
+		link->dc->hwss.edp_backlight_control(link, true);
+	}
+}
+
+void dcn20_setup_vupdate_interrupt(struct pipe_ctx *pipe_ctx)
+{
+	struct timing_generator *tg = pipe_ctx->stream_res.tg;
+	int start_position = get_vupdate_offset_from_vsync(pipe_ctx);
+	uint32_t start_line;
+
+	if (start_position < 0)
+		start_line = pipe_ctx->stream->timing.v_total + start_position - 1;
+	else
+		start_line = start_position;
+
+	if (tg->funcs->setup_vertical_interrupt2)
+		tg->funcs->setup_vertical_interrupt2(tg, start_line);
+}
+
+static void dcn20_reset_back_end_for_pipe(
+		struct dc *dc,
+		struct pipe_ctx *pipe_ctx,
+		struct dc_state *context)
+{
+	int i;
+	DC_LOGGER_INIT(dc->ctx->logger);
+	if (pipe_ctx->stream_res.stream_enc == NULL) {
+		pipe_ctx->stream = NULL;
+		return;
+	}
+
+	if (!IS_FPGA_MAXIMUS_DC(dc->ctx->dce_environment)) {
+		/* DPMS may already disable */
+		if (!pipe_ctx->stream->dpms_off)
+			core_link_disable_stream(pipe_ctx, FREE_ACQUIRED_RESOURCE);
+		else if (pipe_ctx->stream_res.audio) {
+			dc->hwss.disable_audio_stream(pipe_ctx, FREE_ACQUIRED_RESOURCE);
+		}
+
+	}
+
+	/* by upper caller loop, parent pipe: pipe0, will be reset last.
+	 * back end share by all pipes and will be disable only when disable
+	 * parent pipe.
+	 */
+	if (pipe_ctx->top_pipe == NULL) {
+		pipe_ctx->stream_res.tg->funcs->disable_crtc(pipe_ctx->stream_res.tg);
+
+		pipe_ctx->stream_res.tg->funcs->enable_optc_clock(pipe_ctx->stream_res.tg, false);
+		if (pipe_ctx->stream_res.tg->funcs->set_odm_bypass)
+			pipe_ctx->stream_res.tg->funcs->set_odm_bypass(
+					pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);
+	}
+
+	for (i = 0; i < dc->res_pool->pipe_count; i++)
+		if (&dc->current_state->res_ctx.pipe_ctx[i] == pipe_ctx)
+			break;
+
+	if (i == dc->res_pool->pipe_count)
+		return;
+
+	pipe_ctx->stream = NULL;
+	DC_LOG_DEBUG("Reset back end for pipe %d, tg:%d\n",
+					pipe_ctx->pipe_idx, pipe_ctx->stream_res.tg->inst);
+}
+
+static void dcn20_reset_hw_ctx_wrap(
+		struct dc *dc,
+		struct dc_state *context)
+{
+	int i;
+
+	/* Reset Back End*/
+	for (i = dc->res_pool->pipe_count - 1; i >= 0 ; i--) {
+		struct pipe_ctx *pipe_ctx_old =
+			&dc->current_state->res_ctx.pipe_ctx[i];
+		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
+
+		if (!pipe_ctx_old->stream)
+			continue;
+
+		if (pipe_ctx_old->top_pipe)
+			continue;
+
+		if (!pipe_ctx->stream ||
+				pipe_need_reprogram(pipe_ctx_old, pipe_ctx)) {
+			struct clock_source *old_clk = pipe_ctx_old->clock_source;
+
+			dcn20_reset_back_end_for_pipe(dc, pipe_ctx_old, dc->current_state);
+			if (dc->hwss.enable_stream_gating)
+				dc->hwss.enable_stream_gating(dc, pipe_ctx);
+			if (old_clk)
+				old_clk->funcs->cs_power_down(old_clk);
+		}
+	}
+}
+
+static void dcn20_update_mpcc(struct dc *dc, struct pipe_ctx *pipe_ctx)
+{
+	struct hubp *hubp = pipe_ctx->plane_res.hubp;
+	struct mpcc_blnd_cfg blnd_cfg = { {0} };
+	bool per_pixel_alpha = pipe_ctx->plane_state->per_pixel_alpha && pipe_ctx->bottom_pipe;
+	int mpcc_id;
+	struct mpcc *new_mpcc;
+	struct mpc *mpc = dc->res_pool->mpc;
+	struct mpc_tree *mpc_tree_params = &(pipe_ctx->stream_res.opp->mpc_tree_params);
+
+	// input to MPCC is always RGB, by default leave black_color at 0
+	if (dc->debug.visual_confirm == VISUAL_CONFIRM_HDR) {
+		dcn10_get_hdr_visual_confirm_color(
+				pipe_ctx, &blnd_cfg.black_color);
+	} else if (dc->debug.visual_confirm == VISUAL_CONFIRM_SURFACE) {
+		dcn10_get_surface_visual_confirm_color(
+				pipe_ctx, &blnd_cfg.black_color);
+	}
+
+	if (per_pixel_alpha)
+		blnd_cfg.alpha_mode = MPCC_ALPHA_BLEND_MODE_PER_PIXEL_ALPHA;
+	else
+		blnd_cfg.alpha_mode = MPCC_ALPHA_BLEND_MODE_GLOBAL_ALPHA;
+
+	blnd_cfg.overlap_only = false;
+	blnd_cfg.global_gain = 0xff;
+
+	if (pipe_ctx->plane_state->global_alpha)
+		blnd_cfg.global_alpha = pipe_ctx->plane_state->global_alpha_value;
+	else
+		blnd_cfg.global_alpha = 0xff;
+
+	blnd_cfg.background_color_bpc = 4;
+	blnd_cfg.bottom_gain_mode = 0;
+	blnd_cfg.top_gain = 0x1f000;
+	blnd_cfg.bottom_inside_gain = 0x1f000;
+	blnd_cfg.bottom_outside_gain = 0x1f000;
+	blnd_cfg.pre_multiplied_alpha = per_pixel_alpha;
+
+	/*
+	 * TODO: remove hack
+	 * Note: currently there is a bug in init_hw such that
+	 * on resume from hibernate, BIOS sets up MPCC0, and
+	 * we do mpcc_remove but the mpcc cannot go to idle
+	 * after remove. This cause us to pick mpcc1 here,
+	 * which causes a pstate hang for yet unknown reason.
+	 */
+	mpcc_id = hubp->inst;
+
+	/* If there is no full update, don't need to touch MPC tree*/
+	if (!pipe_ctx->plane_state->update_flags.bits.full_update) {
+		mpc->funcs->update_blending(mpc, &blnd_cfg, mpcc_id);
+		return;
+	}
+
+	/* check if this MPCC is already being used */
+	new_mpcc = mpc->funcs->get_mpcc_for_dpp(mpc_tree_params, mpcc_id);
+	/* remove MPCC if being used */
+	if (new_mpcc != NULL)
+		mpc->funcs->remove_mpcc(mpc, mpc_tree_params, new_mpcc);
+	else
+		if (dc->debug.sanity_checks)
+			mpc->funcs->assert_mpcc_idle_before_connect(
+					dc->res_pool->mpc, mpcc_id);
+
+	/* Call MPC to insert new plane */
+	new_mpcc = mpc->funcs->insert_plane(dc->res_pool->mpc,
+			mpc_tree_params,
+			&blnd_cfg,
+			NULL,
+			NULL,
+			hubp->inst,
+			mpcc_id);
+
+	ASSERT(new_mpcc != NULL);
+	hubp->opp_id = pipe_ctx->stream_res.opp->inst;
+	hubp->mpcc_id = mpcc_id;
+}
+
+static int find_free_gsl_group(const struct dc *dc)
+{
+	if (dc->res_pool->gsl_groups.gsl_0 == 0)
+		return 1;
+	if (dc->res_pool->gsl_groups.gsl_1 == 0)
+		return 2;
+	if (dc->res_pool->gsl_groups.gsl_2 == 0)
+		return 3;
+
+	return 0;
+}
+
+/* NOTE: This is not a generic setup_gsl function (hence the suffix as_lock)
+ * This is only used to lock pipes in pipe splitting case with immediate flip
+ * Ordinary MPC/OTG locks suppress VUPDATE which doesn't help with immediate,
+ * so we get tearing with freesync since we cannot flip multiple pipes
+ * atomically.
+ * We use GSL for this:
+ * - immediate flip: find first available GSL group if not already assigned
+ *                   program gsl with that group, set current OTG as master
+ *                   and always us 0x4 = AND of flip_ready from all pipes
+ * - vsync flip: disable GSL if used
+ *
+ * Groups in stream_res are stored as +1 from HW registers, i.e.
+ * gsl_0 <=> pipe_ctx->stream_res.gsl_group == 1
+ * Using a magic value like -1 would require tracking all inits/resets
+ */
+void dcn20_setup_gsl_group_as_lock(
+		const struct dc *dc,
+		struct pipe_ctx *pipe_ctx)
+{
+	struct gsl_params gsl;
+	int group_idx;
+
+	memset(&gsl, 0, sizeof(struct gsl_params));
+
+	if (pipe_ctx->plane_state->flip_immediate) {
+		/* return if group already assigned since GSL was set up
+		 * for vsync flip, we would unassign so it can't be "left over"
+		 */
+		if (pipe_ctx->stream_res.gsl_group > 0)
+			return;
+
+		group_idx = find_free_gsl_group(dc);
+		ASSERT(group_idx != 0);
+		pipe_ctx->stream_res.gsl_group = group_idx;
+
+		/* set gsl group reg field and mark resource used */
+		switch (group_idx) {
+		case 1:
+			gsl.gsl0_en = 1;
+			dc->res_pool->gsl_groups.gsl_0 = 1;
+			break;
+		case 2:
+			gsl.gsl1_en = 1;
+			dc->res_pool->gsl_groups.gsl_1 = 1;
+			break;
+		case 3:
+			gsl.gsl2_en = 1;
+			dc->res_pool->gsl_groups.gsl_2 = 1;
+			break;
+		default:
+			BREAK_TO_DEBUGGER();
+			return; // invalid case
+		}
+		gsl.gsl_master_en = 1;
+	} else {
+		group_idx = pipe_ctx->stream_res.gsl_group;
+		if (group_idx == 0)
+			return; // if not in use, just return
+
+		pipe_ctx->stream_res.gsl_group = 0;
+
+		/* unset gsl group reg field and mark resource free */
+		switch (group_idx) {
+		case 1:
+			gsl.gsl0_en = 0;
+			dc->res_pool->gsl_groups.gsl_0 = 0;
+			break;
+		case 2:
+			gsl.gsl1_en = 0;
+			dc->res_pool->gsl_groups.gsl_1 = 0;
+			break;
+		case 3:
+			gsl.gsl2_en = 0;
+			dc->res_pool->gsl_groups.gsl_2 = 0;
+			break;
+		default:
+			BREAK_TO_DEBUGGER();
+			return;
+		}
+		gsl.gsl_master_en = 0;
+	}
+
+	/* at this point we want to program whether it's to enable or disable */
+	if (pipe_ctx->stream_res.tg->funcs->set_gsl != NULL &&
+		pipe_ctx->stream_res.tg->funcs->set_gsl_source_select != NULL) {
+		pipe_ctx->stream_res.tg->funcs->set_gsl(
+			pipe_ctx->stream_res.tg,
+			&gsl);
+
+		pipe_ctx->stream_res.tg->funcs->set_gsl_source_select(
+			pipe_ctx->stream_res.tg, group_idx,
+			pipe_ctx->plane_state->flip_immediate ? 4 : 0);
+	} else
+		BREAK_TO_DEBUGGER();
+}
+
+static void dcn20_set_flip_control_gsl(
+		struct pipe_ctx *pipe_ctx,
+		bool flip_immediate)
+{
+	if (pipe_ctx && pipe_ctx->plane_res.hubp->funcs->hubp_set_flip_control_surface_gsl)
+		pipe_ctx->plane_res.hubp->funcs->hubp_set_flip_control_surface_gsl(
+				pipe_ctx->plane_res.hubp, flip_immediate);
+
+}
+
+void dcn20_hw_sequencer_construct(struct dc *dc)
+{
+	dcn10_hw_sequencer_construct(dc);
+	dc->hwss.init_hw = dcn20_init_hw;
+	dc->hwss.init_pipes = NULL;
+	dc->hwss.unblank_stream = dcn20_unblank_stream;
+	dc->hwss.update_plane_addr = dcn20_update_plane_addr;
+	dc->hwss.disable_plane = dcn20_disable_plane,
+	dc->hwss.enable_stream_timing = dcn20_enable_stream_timing;
+	dc->hwss.program_triplebuffer = dcn20_program_tripleBuffer;
+	dc->hwss.set_input_transfer_func = dcn20_set_input_transfer_func;
+	dc->hwss.set_output_transfer_func = dcn20_set_output_transfer_func;
+	dc->hwss.apply_ctx_for_surface = dcn20_apply_ctx_for_surface;
+	dc->hwss.pipe_control_lock = dcn20_pipe_control_lock;
+	dc->hwss.pipe_control_lock_global = dcn20_pipe_control_lock_global;
+	dc->hwss.optimize_bandwidth = dcn20_optimize_bandwidth;
+	dc->hwss.prepare_bandwidth = dcn20_prepare_bandwidth;
+	dc->hwss.update_bandwidth = dcn20_update_bandwidth;
+	dc->hwss.enable_writeback = dcn20_enable_writeback;
+	dc->hwss.disable_writeback = dcn20_disable_writeback;
+	dc->hwss.program_output_csc = dcn20_program_output_csc;
+	dc->hwss.update_odm = dcn20_update_odm;
+	dc->hwss.blank_pixel_data = dcn20_blank_pixel_data;
+	dc->hwss.dmdata_status_done = dcn20_dmdata_status_done;
+	dc->hwss.disable_stream = dcn20_disable_stream;
+	dc->hwss.init_dchub = dcn20_init_dchub;
+	dc->hwss.disable_stream_gating = dcn20_disable_stream_gating;
+	dc->hwss.enable_stream_gating = dcn20_enable_stream_gating;
+	dc->hwss.setup_vupdate_interrupt = dcn20_setup_vupdate_interrupt;
+	dc->hwss.reset_hw_ctx_wrap = dcn20_reset_hw_ctx_wrap;
+	dc->hwss.update_mpcc = dcn20_update_mpcc;
+	dc->hwss.set_flip_control_gsl = dcn20_set_flip_control_gsl;
+}
