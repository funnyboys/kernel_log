commit 2cba3944ec3710aab90fc84aec5a27a7ad47fc0a
Author: Zheng Bin <zhengbin13@huawei.com>
Date:   Thu Apr 30 10:26:51 2020 +0800

    drm/amdgpu: remove set but not used variable 'priority'
    
    Fixes gcc '-Wunused-but-set-variable' warning:
    
    drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c:1211:26: warning: variable ‘priority’ set but not used
    
    It is not used since commit 33abcb1f5a17 ("drm/amdgpu:
    set compute queue priority at mqd_init")
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reported-by: Hulk Robot <hulkci@huawei.com>
    Signed-off-by: Zheng Bin <zhengbin13@huawei.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 7653f62b1b2d..19070226a945 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1208,7 +1208,6 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 {
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct drm_sched_entity *entity = p->entity;
-	enum drm_sched_priority priority;
 	struct amdgpu_bo_list_entry *e;
 	struct amdgpu_job *job;
 	uint64_t seq;
@@ -1258,7 +1257,6 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 
 	trace_amdgpu_cs_ioctl(job);
 	amdgpu_vm_bo_trace_cs(&fpriv->vm, &p->ticket);
-	priority = job->base.s_priority;
 	drm_sched_entity_push_job(&job->base, entity);
 
 	amdgpu_vm_move_to_lru_tail(p->adev, &fpriv->vm);

commit 9ecefb19c3a6626c27ea7ee72d431f22462e1d54
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Apr 1 11:18:21 2020 +0200

    drm/amdgpu: cleanup IB pool handling a bit
    
    Fix the coding style, move and rename the definitions to
    better match what they are supposed to be doing.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 3eee5c7d83e0..7653f62b1b2d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -924,7 +924,8 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 
 		ring = to_amdgpu_ring(entity->rq->sched);
 		r =  amdgpu_ib_get(adev, vm, ring->funcs->parse_cs ?
-				   chunk_ib->ib_bytes : 0, AMDGPU_IB_POOL_NORMAL, ib);
+				   chunk_ib->ib_bytes : 0,
+				   AMDGPU_IB_POOL_DELAYED, ib);
 		if (r) {
 			DRM_ERROR("Failed to get ib !\n");
 			return r;

commit 0bb5d5b03f78aeb5f87d47877eb15532875c64da
Author: Luben Tuikov <luben.tuikov@amd.com>
Date:   Wed Apr 22 17:56:56 2020 -0400

    drm/amdgpu: Move to a per-IB secure flag (TMZ)
    
    Move from a per-CS secure flag (TMZ) to a per-IB
    secure flag.
    
    Signed-off-by: Luben Tuikov <luben.tuikov@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 99de770a8e9f..3eee5c7d83e0 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -232,8 +232,6 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, union drm_amdgpu_cs
 	if (ret)
 		goto free_all_kdata;
 
-	p->job->secure = cs->in.flags & AMDGPU_CS_FLAGS_SECURE;
-
 	if (p->ctx->vram_lost_counter != p->job->vram_lost_counter) {
 		ret = -ECANCELED;
 		goto free_all_kdata;

commit cb5fae143d79d255251921066dbf8eae16383639
Author: Huang Rui <ray.huang@amd.com>
Date:   Thu Aug 8 20:05:15 2019 +0800

    drm/amdgpu: job is secure iff CS is secure (v5)
    
    Mark a job as secure, if and only if the command
    submission flag has the secure flag set.
    
    v2: fix the null job pointer while in vmid 0
    submission.
    v3: Context --> Command submission.
    v4: filling cs parser with cs->in.flags
    v5: move the job secure flag setting out of amdgpu_cs_submit()
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Luben Tuikov <luben.tuikov@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 3eee5c7d83e0..99de770a8e9f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -232,6 +232,8 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, union drm_amdgpu_cs
 	if (ret)
 		goto free_all_kdata;
 
+	p->job->secure = cs->in.flags & AMDGPU_CS_FLAGS_SECURE;
+
 	if (p->ctx->vram_lost_counter != p->job->vram_lost_counter) {
 		ret = -ECANCELED;
 		goto free_all_kdata;

commit c8e42d57859d5055bfe3313cfd5dc025097b753e
Author: xinhui pan <xinhui.pan@amd.com>
Date:   Thu Mar 26 08:38:29 2020 +0800

    drm/amdgpu: implement more ib pools (v2)
    
    We have three ib pools, they are normal, VM, direct pools.
    
    Any jobs which schedule IBs without dependence on gpu scheduler should
    use DIRECT pool.
    
    Any jobs schedule direct VM update IBs should use VM pool.
    
    Any other jobs use NORMAL pool.
    
    v2: squash in coding style fix
    
    Signed-off-by: xinhui pan <xinhui.pan@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index af91627b19b0..3eee5c7d83e0 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -924,7 +924,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 
 		ring = to_amdgpu_ring(entity->rq->sched);
 		r =  amdgpu_ib_get(adev, vm, ring->funcs->parse_cs ?
-				   chunk_ib->ib_bytes : 0, ib);
+				   chunk_ib->ib_bytes : 0, AMDGPU_IB_POOL_NORMAL, ib);
 		if (r) {
 			DRM_ERROR("Failed to get ib !\n");
 			return r;

commit 69ddce0970d9d1de63bed9c24eefa0814db29a5a
Merge: 9e12da086e5e 5d11e37c021f
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri Mar 13 09:09:11 2020 +1000

    Merge tag 'amd-drm-next-5.7-2020-03-10' of git://people.freedesktop.org/~agd5f/linux into drm-next
    
    amd-drm-next-5.7-2020-03-10:
    
    amdgpu:
    - SR-IOV fixes
    - Fix up fallout from drm load/unload callback removal
    - Navi, renoir power management watermark fixes
    - Refactor smu parameter handling
    - Display FEC fixes
    - Display DCC fixes
    - HDCP fixes
    - Add support for USB-C PD firmware updates
    - Pollock detection fix
    - Rework compute ring priority handling
    - RAS fixes
    - Misc cleanups
    
    amdkfd:
    - Consolidate more gfx config details in amdgpu
    - Consolidate bo alloc flags
    - Improve code comments
    - SDMA MQD fixes
    - Misc cleanups
    
    gpu scheduler:
    - Add suport for modifying the sched list
    
    uapi:
    - Clarify comments about GEM_CREATE flags that are not used by userspace.
      The kernel driver has always prevented userspace from using these.
      They are only used internally in the kernel driver.
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    
    From: Alex Deucher <alexdeucher@gmail.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20200310212748.4519-1-alexander.deucher@amd.com

commit 33abcb1f5a1719b1c18867e5bf24fb70efe98804
Author: Nirmoy Das <nirmoy.das@amd.com>
Date:   Thu Feb 27 13:59:08 2020 +0100

    drm/amdgpu: set compute queue priority at mqd_init
    
    We were changing compute ring priority while rings were being used
    before every job submission which is not recommended. This patch
    sets compute queue priority at mqd initialization for gfx8, gfx9 and
    gfx10.
    
    Policy: make queue 0 of each pipe as high priority compute queue
    
    High/normal priority compute sched lists are generated from set of high/normal
    priority compute queues. At context creation, entity of compute queue
    get a sched list from high or normal priority depending on ctx->priority
    
    Signed-off-by: Nirmoy Das <nirmoy.das@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Acked-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index f397ff97b4e4..8304d0c87899 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1205,7 +1205,6 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct drm_sched_entity *entity = p->entity;
 	enum drm_sched_priority priority;
-	struct amdgpu_ring *ring;
 	struct amdgpu_bo_list_entry *e;
 	struct amdgpu_job *job;
 	uint64_t seq;
@@ -1258,9 +1257,6 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	priority = job->base.s_priority;
 	drm_sched_entity_push_job(&job->base, entity);
 
-	ring = to_amdgpu_ring(entity->rq->sched);
-	amdgpu_ring_priority_get(ring, priority);
-
 	amdgpu_vm_move_to_lru_tail(p->adev, &fpriv->vm);
 
 	ttm_eu_fence_buffer_objects(&p->ticket, &p->validated, p->fence);

commit 83794ee6c13b41c7db86ccfcaa20dc360b08fdb6
Merge: 05f3a6f5e478 60347451ddb0
Author: Maxime Ripard <maxime@cerno.tech>
Date:   Wed Mar 4 08:56:28 2020 +0100

    Merge drm/drm-next into drm-misc-next
    
    Daniel needs a few commits from drm-next.
    
    Signed-off-by: Maxime Ripard <maxime@cerno.tech>

commit 4993ba02635f69ec35d20e4b3f07c51e8a2a7171
Author: Christian König <christian.koenig@amd.com>
Date:   Mon May 6 16:35:26 2019 +0200

    drm/amdgpu: use allowed_domains for exported DMA-bufs
    
    Avoid that we ping/pong the buffers when we stop to pin DMA-buf
    exports by using the allowed domains for exported buffers.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Link: https://patchwork.freedesktop.org/patch/353996/?series=73646&rev=1

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index a52a084158b1..41bd2dad842c 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -28,6 +28,7 @@
 #include <linux/file.h>
 #include <linux/pagemap.h>
 #include <linux/sync_file.h>
+#include <linux/dma-buf.h>
 
 #include <drm/amdgpu_drm.h>
 #include <drm/drm_syncobj.h>
@@ -415,7 +416,9 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 	/* Don't move this buffer if we have depleted our allowance
 	 * to move it. Don't move anything if the threshold is zero.
 	 */
-	if (p->bytes_moved < p->bytes_moved_threshold) {
+	if (p->bytes_moved < p->bytes_moved_threshold &&
+	    (!bo->tbo.base.dma_buf ||
+	    list_empty(&bo->tbo.base.dma_buf->attachments))) {
 		if (!amdgpu_gmc_vram_full_visible(&adev->gmc) &&
 		    (bo->flags & AMDGPU_GEM_CREATE_CPU_ACCESS_REQUIRED)) {
 			/* And don't move a CPU_ACCESS_REQUIRED BO to limited

commit 5d3196605d00b513a735b358f5e4f2d1b65f6c3a
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Dec 16 16:07:06 2019 +0100

    drm/amdgpu: rework job synchronization v2
    
    For unlocked page table updates we need to be able
    to sync to fences of a specific VM.
    
    v2: use SYNC_ALWAYS in the UVD code
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 474548049e45..f397ff97b4e4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -658,10 +658,12 @@ static int amdgpu_cs_sync_rings(struct amdgpu_cs_parser *p)
 	list_for_each_entry(e, &p->validated, tv.head) {
 		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(e->tv.bo);
 		struct dma_resv *resv = bo->tbo.base.resv;
+		enum amdgpu_sync_mode sync_mode;
 
-		r = amdgpu_sync_resv(p->adev, &p->job->sync, resv, &fpriv->vm,
-				     amdgpu_bo_explicit_sync(bo));
-
+		sync_mode = amdgpu_bo_explicit_sync(bo) ?
+			AMDGPU_SYNC_EXPLICIT : AMDGPU_SYNC_NE_OWNER;
+		r = amdgpu_sync_resv(p->adev, &p->job->sync, resv, sync_mode,
+				     &fpriv->vm);
 		if (r)
 			return r;
 	}

commit 114fbc31952eb5179da738cf0dd71318d7048bf6
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Dec 16 14:55:27 2019 +0100

    drm/amdgpu: use the VM as job owner
    
    For HMM we need to rework how VM synchronization works, so instead of the filp use VM as job owner.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index a52a084158b1..474548049e45 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -651,6 +651,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 
 static int amdgpu_cs_sync_rings(struct amdgpu_cs_parser *p)
 {
+	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_bo_list_entry *e;
 	int r;
 
@@ -658,7 +659,7 @@ static int amdgpu_cs_sync_rings(struct amdgpu_cs_parser *p)
 		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(e->tv.bo);
 		struct dma_resv *resv = bo->tbo.base.resv;
 
-		r = amdgpu_sync_resv(p->adev, &p->job->sync, resv, p->filp,
+		r = amdgpu_sync_resv(p->adev, &p->job->sync, resv, &fpriv->vm,
 				     amdgpu_bo_explicit_sync(bo));
 
 		if (r)
@@ -1211,7 +1212,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	job = p->job;
 	p->job = NULL;
 
-	r = drm_sched_job_init(&job->base, entity, p->filp);
+	r = drm_sched_job_init(&job->base, entity, &fpriv->vm);
 	if (r)
 		goto error_unlock;
 

commit 971fe55545de2f67463def381df57d803dddf61d
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Dec 16 14:54:31 2019 +0100

    drm/amdgpu: drop amdgpu_job.owner
    
    Entirely unused.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 7a8772b7caf7..a52a084158b1 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1234,7 +1234,6 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 		goto error_abort;
 	}
 
-	job->owner = p->filp;
 	p->fence = dma_fence_get(&job->base.s_fence->finished);
 
 	amdgpu_ctx_add_fence(p->ctx, entity, p->fence, &seq);

commit 55414ad5c983ed708d778ea7b29e80f89750ff73
Author: Nirmoy Das <nirmoy.das@amd.com>
Date:   Thu Jan 9 12:07:22 2020 +0100

    drm/amdgpu: error out on entity with no run queue
    
    Disabled HW IP's entity initialized with NULL rq. We should not
    process any submit request from userspace for a disabled HW IP.
    
    Signed-off-by: Nirmoy Das <nirmoy.das@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 5b330f69194b..7a8772b7caf7 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -909,6 +909,11 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		if (parser->entity && parser->entity != entity)
 			return -EINVAL;
 
+		/* Return if there is no run queue associated with this entity.
+		 * Possibly because of disabled HW IP*/
+		if (entity->rq == NULL)
+			return -EINVAL;
+
 		parser->entity = entity;
 
 		ring = to_amdgpu_ring(entity->rq->sched);

commit be452c4e8d1434a0095a9baa6523bb9772258d59
Merge: d2e532286d4f ad808910be68
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Tue Dec 17 18:47:46 2019 +0100

    Merge tag 'drm-next-5.6-2019-12-11' of git://people.freedesktop.org/~agd5f/linux into drm-next
    
    drm-next-5.6-2019-12-11:
    
    amdgpu:
    - Add MST atomic routines
    - Add support for DMCUB (new helper microengine for displays)
    - Add OEM i2c support in DC
    - Use vstartup for vblank events on DCN
    - Simplify Kconfig for DC
    - Renoir fixes for DC
    - Clean up function pointers in DC
    - Initial support for HDCP 2.x
    - Misc code cleanups
    - GFX10 fixes
    - Rework JPEG engine handling for VCN
    - Add clock and power gating support for JPEG
    - BACO support for Arcturus
    - Cleanup PSP ring handling
    - Add framework for using BACO with runtime pm to save power
    - Move core pci state handling out of the driver for pm ops
    - Allow guest power control in 1 VF case with SR-IOV
    - SR-IOV fixes
    - RAS fixes
    - Support for power metrics on renoir
    - Golden settings updates for gfx10
    - Enable gfxoff on supported navi10 skus
    - Update MAINTAINERS
    
    amdkfd:
    - Clean up generational gfx code
    - Fixes for gfx10
    - DIQ fixes
    - Share more code with amdgpu
    
    radeon:
    - PPC DMA fix
    - Register checker fixes for r1xx/r2xx
    - Misc cleanups
    
    From: Alex Deucher <alexdeucher@gmail.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20191211223020.7510-1-alexander.deucher@amd.com

commit e095fc17bbd216ccac7fe06132067ae6e91f01c3
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Nov 29 11:33:54 2019 +0100

    drm/amdgpu: explicitely sync to VM updates v2
    
    Allows us to reduce the overhead while syncing to fences a bit.
    
    v2: also drop adev parameter from the functions
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index a169ff16277f..06fb535a504f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -797,29 +797,23 @@ static int amdgpu_cs_vm_handling(struct amdgpu_cs_parser *p)
 	if (r)
 		return r;
 
-	r = amdgpu_sync_fence(adev, &p->job->sync,
-			      fpriv->prt_va->last_pt_update, false);
+	r = amdgpu_sync_vm_fence(&p->job->sync, fpriv->prt_va->last_pt_update);
 	if (r)
 		return r;
 
 	if (amdgpu_mcbp || amdgpu_sriov_vf(adev)) {
-		struct dma_fence *f;
-
 		bo_va = fpriv->csa_va;
 		BUG_ON(!bo_va);
 		r = amdgpu_vm_bo_update(adev, bo_va, false);
 		if (r)
 			return r;
 
-		f = bo_va->last_pt_update;
-		r = amdgpu_sync_fence(adev, &p->job->sync, f, false);
+		r = amdgpu_sync_vm_fence(&p->job->sync, bo_va->last_pt_update);
 		if (r)
 			return r;
 	}
 
 	amdgpu_bo_list_for_each_entry(e, p->bo_list) {
-		struct dma_fence *f;
-
 		/* ignore duplicates */
 		bo = ttm_to_amdgpu_bo(e->tv.bo);
 		if (!bo)
@@ -833,8 +827,7 @@ static int amdgpu_cs_vm_handling(struct amdgpu_cs_parser *p)
 		if (r)
 			return r;
 
-		f = bo_va->last_pt_update;
-		r = amdgpu_sync_fence(adev, &p->job->sync, f, false);
+		r = amdgpu_sync_vm_fence(&p->job->sync, bo_va->last_pt_update);
 		if (r)
 			return r;
 	}
@@ -847,7 +840,7 @@ static int amdgpu_cs_vm_handling(struct amdgpu_cs_parser *p)
 	if (r)
 		return r;
 
-	r = amdgpu_sync_fence(adev, &p->job->sync, vm->last_update, false);
+	r = amdgpu_sync_vm_fence(&p->job->sync, vm->last_update);
 	if (r)
 		return r;
 
@@ -989,7 +982,7 @@ static int amdgpu_cs_process_fence_dep(struct amdgpu_cs_parser *p,
 			dma_fence_put(old);
 		}
 
-		r = amdgpu_sync_fence(p->adev, &p->job->sync, fence, true);
+		r = amdgpu_sync_fence(&p->job->sync, fence, true);
 		dma_fence_put(fence);
 		if (r)
 			return r;
@@ -1011,7 +1004,7 @@ static int amdgpu_syncobj_lookup_and_add_to_sync(struct amdgpu_cs_parser *p,
 		return r;
 	}
 
-	r = amdgpu_sync_fence(p->adev, &p->job->sync, fence, true);
+	r = amdgpu_sync_fence(&p->job->sync, fence, true);
 	dma_fence_put(fence);
 
 	return r;

commit aa32f1169148beb90d71494e2f2a1999ba7b5366
Merge: d5bb349dbbe2 93f4e735b6d9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Nov 30 10:33:14 2019 -0800

    Merge tag 'for-linus-hmm' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma
    
    Pull hmm updates from Jason Gunthorpe:
     "This is another round of bug fixing and cleanup. This time the focus
      is on the driver pattern to use mmu notifiers to monitor a VA range.
      This code is lifted out of many drivers and hmm_mirror directly into
      the mmu_notifier core and written using the best ideas from all the
      driver implementations.
    
      This removes many bugs from the drivers and has a very pleasing
      diffstat. More drivers can still be converted, but that is for another
      cycle.
    
       - A shared branch with RDMA reworking the RDMA ODP implementation
    
       - New mmu_interval_notifier API. This is focused on the use case of
         monitoring a VA and simplifies the process for drivers
    
       - A common seq-count locking scheme built into the
         mmu_interval_notifier API usable by drivers that call
         get_user_pages() or hmm_range_fault() with the VA range
    
       - Conversion of mlx5 ODP, hfi1, radeon, nouveau, AMD GPU, and Xen
         GntDev drivers to the new API. This deletes a lot of wonky driver
         code.
    
       - Two improvements for hmm_range_fault(), from testing done by Ralph"
    
    * tag 'for-linus-hmm' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma:
      mm/hmm: remove hmm_range_dma_map and hmm_range_dma_unmap
      mm/hmm: make full use of walk_page_range()
      xen/gntdev: use mmu_interval_notifier_insert
      mm/hmm: remove hmm_mirror and related
      drm/amdgpu: Use mmu_interval_notifier instead of hmm_mirror
      drm/amdgpu: Use mmu_interval_insert instead of hmm_mirror
      drm/amdgpu: Call find_vma under mmap_sem
      nouveau: use mmu_interval_notifier instead of hmm_mirror
      nouveau: use mmu_notifier directly for invalidate_range_start
      drm/radeon: use mmu_interval_notifier_insert
      RDMA/hfi1: Use mmu_interval_notifier_insert for user_exp_rcv
      RDMA/odp: Use mmu_interval_notifier_insert()
      mm/hmm: define the pre-processor related parts of hmm.h even if disabled
      mm/hmm: allow hmm_range to be used with a mmu_interval_notifier or hmm_mirror
      mm/mmu_notifier: add an interval tree notifier
      mm/mmu_notifier: define the header pre-processor parts even if disabled
      mm/hmm: allow snapshot of the special zero page

commit 81fa1af31b5d79047821def6abdcb97a735d8a52
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Tue Nov 12 16:22:29 2019 -0400

    drm/amdgpu: Use mmu_interval_notifier instead of hmm_mirror
    
    Convert the collision-retry lock around hmm_range_fault to use the one now
    provided by the mmu_interval notifier.
    
    Although this driver does not seem to use the collision retry lock that
    hmm provides correctly, it can still be converted over to use the
    mmu_interval_notifier api instead of hmm_mirror without too much trouble.
    
    This also deletes another place where a driver is associating additional
    data (struct amdgpu_mn) with a mmu_struct.
    
    Link: https://lore.kernel.org/r/20191112202231.3856-13-jgg@ziepe.ca
    Signed-off-by: Philip Yang <Philip.Yang@amd.com>
    Reviewed-by: Philip Yang <Philip.Yang@amd.com>
    Tested-by: Philip Yang <Philip.Yang@amd.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 82823d9a8ba8..22c989bca751 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -603,8 +603,6 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		e->tv.num_shared = 2;
 
 	amdgpu_bo_list_get_list(p->bo_list, &p->validated);
-	if (p->bo_list->first_userptr != p->bo_list->num_entries)
-		p->mn = amdgpu_mn_get(p->adev, AMDGPU_MN_TYPE_GFX);
 
 	INIT_LIST_HEAD(&duplicates);
 	amdgpu_vm_get_pd_bo(&fpriv->vm, &p->validated, &p->vm_pd);
@@ -1287,11 +1285,11 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	if (r)
 		goto error_unlock;
 
-	/* No memory allocation is allowed while holding the mn lock.
-	 * p->mn is hold until amdgpu_cs_submit is finished and fence is added
-	 * to BOs.
+	/* No memory allocation is allowed while holding the notifier lock.
+	 * The lock is held until amdgpu_cs_submit is finished and fence is
+	 * added to BOs.
 	 */
-	amdgpu_mn_lock(p->mn);
+	mutex_lock(&p->adev->notifier_lock);
 
 	/* If userptr are invalidated after amdgpu_cs_parser_bos(), return
 	 * -EAGAIN, drmIoctl in libdrm will restart the amdgpu_cs_ioctl.
@@ -1334,13 +1332,13 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	amdgpu_vm_move_to_lru_tail(p->adev, &fpriv->vm);
 
 	ttm_eu_fence_buffer_objects(&p->ticket, &p->validated, p->fence);
-	amdgpu_mn_unlock(p->mn);
+	mutex_unlock(&p->adev->notifier_lock);
 
 	return 0;
 
 error_abort:
 	drm_sched_job_cleanup(&job->base);
-	amdgpu_mn_unlock(p->mn);
+	mutex_unlock(&p->adev->notifier_lock);
 
 error_unlock:
 	amdgpu_job_free(job);

commit 633aa7e53a66b39b7205d4d2a221cda7eeb087c9
Merge: 57c2af791b6c fae7d7d5f374
Author: Dave Airlie <airlied@redhat.com>
Date:   Mon Nov 4 09:27:41 2019 +1000

    Merge tag 'drm-misc-next-2019-10-31' of git://anongit.freedesktop.org/drm/drm-misc into drm-next
    
    drm-misc-next for 5.5:
    
    UAPI Changes:
    -dma-buf: Introduce and revert dma-buf heap (Andrew/John/Sean)
    
    Cross-subsystem Changes:
    - None
    
    Core Changes:
    -dma-buf: add dynamic mapping to allow exporters to choose dma_resv lock
              state on mmap/munmap (Christian)
    -vram: add prepare/cleanup fb helpers to vram helpers (Thomas)
    -ttm: always keep bo's on the lru + ttm cleanups (Christian)
    -sched: allow a free_job routine to sleep (Steven)
    -fb_helper: remove unused drm_fb_helper_defio_init() (Thomas)
    
    Driver Changes:
    -bochs/hibmc/vboxvideo: Use new vram helpers for prepare/cleanup fb (Thomas)
    -amdgpu: Implement dma-buf import/export without drm helpers (Christian)
    -panfrost: Simplify devfreq integration in driver (Steven)
    
    Cc: Christian König <christian.koenig@amd.com>
    Cc: Thomas Zimmermann <tzimmermann@suse.de>
    Cc: Steven Price <steven.price@arm.com>
    Cc: Andrew F. Davis <afd@ti.com>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Sean Paul <seanpaul@chromium.org>
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    
    From: Sean Paul <sean@poorly.run>
    Link: https://patchwork.freedesktop.org/patch/msgid/20191031193015.GA243509@art_vandelay

commit 9165fb879f62a73577867180e890f410f3a239ad
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Sep 19 12:56:15 2019 +0200

    drm/ttm: always keep BOs on the LRU
    
    This allows blocking for BOs to become available
    in the memory management.
    
    Amdgpu is doing this for quite a while now during CS. Now
    apply the new behavior to all drivers using TTM.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Thomas Hellstrom <thellstrom@vmware.com>
    Link: https://patchwork.freedesktop.org/patch/332878/

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 2e53feed40e2..253158fc378f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -650,7 +650,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	}
 
 	r = ttm_eu_reserve_buffers(&p->ticket, &p->validated, true,
-				   &duplicates, false);
+				   &duplicates);
 	if (unlikely(r != 0)) {
 		if (r != -ERESTARTSYS)
 			DRM_ERROR("ttm_eu_reserve_buffers failed.\n");

commit 209620b422945ee03cebb03f726e706d537b692d
Author: Philip Yang <Philip.Yang@amd.com>
Date:   Thu Oct 3 14:18:25 2019 -0400

    drm/amdgpu: user pages array memory leak fix
    
    user_pages array should always be freed after validation regardless if
    user pages are changed after bo is created because with HMM change parse
    bo always allocate user pages array to get user pages for userptr bo.
    
    v2: remove unused local variable and amend commit
    
    v3: add back get user pages in gem_userptr_ioctl, to detect application
    bug where an userptr VMA is not ananymous memory and reject it.
    
    Bugzilla: https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1844962
    
    Signed-off-by: Philip Yang <Philip.Yang@amd.com>
    Tested-by: Joe Barnett <thejoe@gmail.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org # 5.3

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 2e53feed40e2..82823d9a8ba8 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -536,7 +536,6 @@ static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 
 	list_for_each_entry(lobj, validated, tv.head) {
 		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(lobj->tv.bo);
-		bool binding_userptr = false;
 		struct mm_struct *usermm;
 
 		usermm = amdgpu_ttm_tt_get_usermm(bo->tbo.ttm);
@@ -553,7 +552,6 @@ static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 
 			amdgpu_ttm_tt_set_user_pages(bo->tbo.ttm,
 						     lobj->user_pages);
-			binding_userptr = true;
 		}
 
 		if (p->evictable == lobj)
@@ -563,10 +561,8 @@ static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 		if (r)
 			return r;
 
-		if (binding_userptr) {
-			kvfree(lobj->user_pages);
-			lobj->user_pages = NULL;
-		}
+		kvfree(lobj->user_pages);
+		lobj->user_pages = NULL;
 	}
 	return 0;
 }

commit 06f7f57e87d09900a7c3109a357b73521ab40771
Author: Philip Yang <Philip.Yang@amd.com>
Date:   Thu Oct 3 14:18:25 2019 -0400

    drm/amdgpu: user pages array memory leak fix
    
    user_pages array should always be freed after validation regardless if
    user pages are changed after bo is created because with HMM change parse
    bo always allocate user pages array to get user pages for userptr bo.
    
    v2: remove unused local variable and amend commit
    
    v3: add back get user pages in gem_userptr_ioctl, to detect application
    bug where an userptr VMA is not ananymous memory and reject it.
    
    Bugzilla: https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1844962
    
    Signed-off-by: Philip Yang <Philip.Yang@amd.com>
    Tested-by: Joe Barnett <thejoe@gmail.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 49b767b7238f..6cfaa984cc3d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -474,7 +474,6 @@ static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 
 	list_for_each_entry(lobj, validated, tv.head) {
 		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(lobj->tv.bo);
-		bool binding_userptr = false;
 		struct mm_struct *usermm;
 
 		usermm = amdgpu_ttm_tt_get_usermm(bo->tbo.ttm);
@@ -491,17 +490,14 @@ static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 
 			amdgpu_ttm_tt_set_user_pages(bo->tbo.ttm,
 						     lobj->user_pages);
-			binding_userptr = true;
 		}
 
 		r = amdgpu_cs_validate(p, bo);
 		if (r)
 			return r;
 
-		if (binding_userptr) {
-			kvfree(lobj->user_pages);
-			lobj->user_pages = NULL;
-		}
+		kvfree(lobj->user_pages);
+		lobj->user_pages = NULL;
 	}
 	return 0;
 }

commit 807e2994092c0bd863c0141c99f5e3f807d4c7f8
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Mar 14 09:10:01 2019 +0100

    drm/amdgpu: allow direct submission of PDE updates v2
    
    For handling PDE updates directly in the fault handler.
    
    v2: fix typo in comment
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index f6537476b542..49b767b7238f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -847,7 +847,7 @@ static int amdgpu_cs_vm_handling(struct amdgpu_cs_parser *p)
 	if (r)
 		return r;
 
-	r = amdgpu_vm_update_directories(adev, vm);
+	r = amdgpu_vm_update_pdes(adev, vm, false);
 	if (r)
 		return r;
 

commit 7c6e68c777f109484559a35b125a773439bbd319
Author: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
Date:   Fri Sep 13 17:40:32 2019 -0500

    drm/amdgpu: Avoid HW GPU reset for RAS.
    
    Problem:
    Under certain conditions, when some IP bocks take a RAS error,
    we can get into a situation where a GPU reset is not possible
    due to issues in RAS in SMU/PSP.
    
    Temporary fix until proper solution in PSP/SMU is ready:
    When uncorrectable error happens the DF will unconditionally
    broadcast error event packets to all its clients/slave upon
    receiving fatal error event and freeze all its outbound queues,
    err_event_athub interrupt  will be triggered.
    In such case and we use this interrupt
    to issue GPU reset. THe GPU reset code is modified for such case to avoid HW
    reset, only stops schedulers, deatches all in progress and not yet scheduled
    job's fences, set error code on them and signals.
    Also reject any new incoming job submissions from user space.
    All this is done to notify the applications of the problem.
    
    v2:
    Extract amdgpu_amdkfd_pre/post_reset from amdgpu_device_lock/unlock_adev
    Move amdgpu_job_stop_all_jobs_on_sched to amdgpu_job.c
    Remove print param from amdgpu_ras_query_error_count
    
    v3:
    Update based on prevoius bug fixing patch to properly call amdgpu_amdkfd_pre_reset
    for other XGMI hive memebers.
    
    Signed-off-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Acked-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Reviewed-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 324919d57c89..f6537476b542 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -35,6 +35,7 @@
 #include "amdgpu_trace.h"
 #include "amdgpu_gmc.h"
 #include "amdgpu_gem.h"
+#include "amdgpu_ras.h"
 
 static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 				      struct drm_amdgpu_cs_chunk_fence *data,
@@ -1290,6 +1291,9 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	bool reserved_buffers = false;
 	int i, r;
 
+	if (amdgpu_ras_intr_triggered())
+		return -EHWPOISON;
+
 	if (!adev->accel_working)
 		return -EBUSY;
 

commit 43ce6bab7b9ea8615b18b4a6c88e9b8a122080e3
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Aug 30 14:42:10 2019 +0200

    drm/amdgpu: remove amdgpu_cs_try_evict
    
    Trying to evict things from the current working set doesn't work that
    well anymore because of per VM BOs.
    
    Rely on reserving VRAM for page tables to avoid contention.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 2e53feed40e2..324919d57c89 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -449,75 +449,12 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 	return r;
 }
 
-/* Last resort, try to evict something from the current working set */
-static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
-				struct amdgpu_bo *validated)
-{
-	uint32_t domain = validated->allowed_domains;
-	struct ttm_operation_ctx ctx = { true, false };
-	int r;
-
-	if (!p->evictable)
-		return false;
-
-	for (;&p->evictable->tv.head != &p->validated;
-	     p->evictable = list_prev_entry(p->evictable, tv.head)) {
-
-		struct amdgpu_bo_list_entry *candidate = p->evictable;
-		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(candidate->tv.bo);
-		struct amdgpu_device *adev = amdgpu_ttm_adev(bo->tbo.bdev);
-		bool update_bytes_moved_vis;
-		uint32_t other;
-
-		/* If we reached our current BO we can forget it */
-		if (bo == validated)
-			break;
-
-		/* We can't move pinned BOs here */
-		if (bo->pin_count)
-			continue;
-
-		other = amdgpu_mem_type_to_domain(bo->tbo.mem.mem_type);
-
-		/* Check if this BO is in one of the domains we need space for */
-		if (!(other & domain))
-			continue;
-
-		/* Check if we can move this BO somewhere else */
-		other = bo->allowed_domains & ~domain;
-		if (!other)
-			continue;
-
-		/* Good we can try to move this BO somewhere else */
-		update_bytes_moved_vis =
-				!amdgpu_gmc_vram_full_visible(&adev->gmc) &&
-				amdgpu_bo_in_cpu_visible_vram(bo);
-		amdgpu_bo_placement_from_domain(bo, other);
-		r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
-		p->bytes_moved += ctx.bytes_moved;
-		if (update_bytes_moved_vis)
-			p->bytes_moved_vis += ctx.bytes_moved;
-
-		if (unlikely(r))
-			break;
-
-		p->evictable = list_prev_entry(p->evictable, tv.head);
-		list_move(&candidate->tv.head, &p->validated);
-
-		return true;
-	}
-
-	return false;
-}
-
 static int amdgpu_cs_validate(void *param, struct amdgpu_bo *bo)
 {
 	struct amdgpu_cs_parser *p = param;
 	int r;
 
-	do {
-		r = amdgpu_cs_bo_validate(p, bo);
-	} while (r == -ENOMEM && amdgpu_cs_try_evict(p, bo));
+	r = amdgpu_cs_bo_validate(p, bo);
 	if (r)
 		return r;
 
@@ -556,9 +493,6 @@ static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 			binding_userptr = true;
 		}
 
-		if (p->evictable == lobj)
-			p->evictable = NULL;
-
 		r = amdgpu_cs_validate(p, bo);
 		if (r)
 			return r;
@@ -661,9 +595,6 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 					  &p->bytes_moved_vis_threshold);
 	p->bytes_moved = 0;
 	p->bytes_moved_vis = 0;
-	p->evictable = list_last_entry(&p->validated,
-				       struct amdgpu_bo_list_entry,
-				       tv.head);
 
 	r = amdgpu_vm_validate_pt_bos(p->adev, &fpriv->vm,
 				      amdgpu_cs_validate, p);

commit 578d2342ec702e5fb8a77983fabb3754ae3e9660
Merge: c87237110f25 b4d857ded1c5
Author: Dave Airlie <airlied@redhat.com>
Date:   Tue Aug 27 17:22:15 2019 +1000

    Merge tag 'drm-next-5.4-2019-08-23' of git://people.freedesktop.org/~agd5f/linux into drm-next
    
    drm-next-5.4-2019-08-23:
    
    amdgpu:
    - Enable power features on Navi12
    - Enable power features on Arcturus
    - RAS updates
    - Initial Renoir APU support
    - Enable power featyres on Renoir
    - DC gamma fixes
    - DCN2 fixes
    - GPU reset support for Picasso
    - Misc cleanups and fixes
    
    scheduler:
    - Possible race fix
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    From: Alex Deucher <alexdeucher@gmail.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190823202620.3870-1-alexander.deucher@amd.com

commit 5a6a4c9d1b6743268480b5b5661a35c38d4df424
Author: Nicolai Hähnle <nicolai.haehnle@amd.com>
Date:   Tue Aug 20 15:39:53 2019 +0200

    drm/amdgpu: prevent memory leaks in AMDGPU_CS ioctl
    
    Error out if the AMDGPU_CS ioctl is called with multiple SYNCOBJ_OUT and/or
    TIMELINE_SIGNAL chunks, since otherwise the last chunk wins while the
    allocated array as well as the reference counts of sync objects are leaked.
    
    Signed-off-by: Nicolai Hähnle <nicolai.haehnle@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 9ccf32c5456a..2fcdc6029413 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1143,6 +1143,9 @@ static int amdgpu_cs_process_syncobj_out_dep(struct amdgpu_cs_parser *p,
 	num_deps = chunk->length_dw * 4 /
 		sizeof(struct drm_amdgpu_cs_chunk_sem);
 
+	if (p->post_deps)
+		return -EINVAL;
+
 	p->post_deps = kmalloc_array(num_deps, sizeof(*p->post_deps),
 				     GFP_KERNEL);
 	p->num_post_deps = 0;
@@ -1166,8 +1169,7 @@ static int amdgpu_cs_process_syncobj_out_dep(struct amdgpu_cs_parser *p,
 
 
 static int amdgpu_cs_process_syncobj_timeline_out_dep(struct amdgpu_cs_parser *p,
-						      struct amdgpu_cs_chunk
-						      *chunk)
+						      struct amdgpu_cs_chunk *chunk)
 {
 	struct drm_amdgpu_cs_chunk_syncobj *syncobj_deps;
 	unsigned num_deps;
@@ -1177,6 +1179,9 @@ static int amdgpu_cs_process_syncobj_timeline_out_dep(struct amdgpu_cs_parser *p
 	num_deps = chunk->length_dw * 4 /
 		sizeof(struct drm_amdgpu_cs_chunk_syncobj);
 
+	if (p->post_deps)
+		return -EINVAL;
+
 	p->post_deps = kmalloc_array(num_deps, sizeof(*p->post_deps),
 				     GFP_KERNEL);
 	p->num_post_deps = 0;

commit 5f680625d9765a2f936707465659acac8e44f514
Merge: 8120ed5ebd2a d777478599f7
Author: Dave Airlie <airlied@redhat.com>
Date:   Wed Aug 21 15:38:43 2019 +1000

    Merge tag 'drm-misc-next-2019-08-19' of git://anongit.freedesktop.org/drm/drm-misc into drm-next
    
    drm-misc-next for 5.4:
    
    UAPI Changes:
    
    Cross-subsystem Changes:
    
    Core Changes:
      - dma-buf: add reservation_object_fences helper, relax
                 reservation_object_add_shared_fence, remove
                 reservation_object seq number (and then
                 restored)
      - dma-fence: Shrinkage of the dma_fence structure,
                   Merge dma_fence_signal and dma_fence_signal_locked,
                   Store the timestamp in struct dma_fence in a union with
                   cb_list
    
    Driver Changes:
      - More dt-bindings YAML conversions
      - More removal of drmP.h includes
      - dw-hdmi: Support get_eld and various i2s improvements
      - gm12u320: Few fixes
      - meson: Global cleanup
      - panfrost: Few refactors, Support for GPU heap allocations
      - sun4i: Support for DDC enable GPIO
      - New panels: TI nspire, NEC NL8048HL11, LG Philips LB035Q02,
                    Sharp LS037V7DW01, Sony ACX565AKM, Toppoly TD028TTEC1
                    Toppoly TD043MTEA1
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    [airlied: fixup dma_resv rename fallout]
    
    From: Maxime Ripard <maxime.ripard@bootlin.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190819141923.7l2adietcr2pioct@flea

commit 52791eeec1d9f4a7e7fe08aaba0b1553149d93bc
Author: Christian König <christian.koenig@amd.com>
Date:   Sun Aug 11 10:06:32 2019 +0200

    dma-buf: rename reservation_object to dma_resv
    
    Be more consistent with the naming of the other DMA-buf objects.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chris Wilson <chris@chris-wilson.co.uk>
    Link: https://patchwork.freedesktop.org/patch/323401/

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index e748cd284780..22236d367e26 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -730,7 +730,7 @@ static int amdgpu_cs_sync_rings(struct amdgpu_cs_parser *p)
 
 	list_for_each_entry(e, &p->validated, tv.head) {
 		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(e->tv.bo);
-		struct reservation_object *resv = bo->tbo.base.resv;
+		struct dma_resv *resv = bo->tbo.base.resv;
 
 		r = amdgpu_sync_resv(p->adev, &p->job->sync, resv, p->filp,
 				     amdgpu_bo_explicit_sync(bo));
@@ -1729,7 +1729,7 @@ int amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 	*map = mapping;
 
 	/* Double check that the BO is reserved by this CS */
-	if (reservation_object_locking_ctx((*bo)->tbo.base.resv) != &parser->ticket)
+	if (dma_resv_locking_ctx((*bo)->tbo.base.resv) != &parser->ticket)
 		return -EINVAL;
 
 	if (!((*bo)->flags & AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS)) {

commit b0383c0653c4bd2d2732c5767ec8fa223b3d6efd
Merge: dce14e36aea2 cc8f12996e24
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri Aug 9 16:04:15 2019 +1000

    Merge tag 'drm-misc-next-2019-08-08' of git://anongit.freedesktop.org/drm/drm-misc into drm-next
    
    drm-misc-next for 5.4:
    
    UAPI Changes:
     - HDCP: Add a Content protection type property
    
    Cross-subsystem Changes:
    
    Core Changes:
     - Continue to rework the include dependencies
     - fb: Remove the unused drm_gem_fbdev_fb_create function
     - drm-dp-helper: Make the link rate calculation more tolerant to
                      non-explicitly defined, yet supported, rates
     - fb-helper: Map DRM client buffer only when required, and instanciate a
                  shadow buffer when the device has a dirty function or says so
     - connector: Add a helper to link the DDC adapter used by that connector to
                  the userspace
     - vblank: Switch from DRM_WAIT_ON to wait_event_interruptible_timeout
     - dma-buf: Fix a stack corruption
     - ttm: Embed a drm_gem_object struct to make ttm_buffer_object a
            superclass of GEM, and convert drivers to use it.
     - hdcp: Improvements to report the content protection type to the
             userspace
    
    Driver Changes:
     - Remove drm_gem_prime_import/export from being defined in the drivers
     - Drop DRM_AUTH usage from drivers
     - Continue to drop drmP.h
     - Convert drivers to the connector ddc helper
    
     - ingenic: Add support for more panel-related cases
     - komeda: Support for dual-link
     - lima: Reduce logging
     - mpag200: Fix the cursor support
     - panfrost: Export GPU features register to userspace through an ioctl
     - pl111: Remove the CLD pads wiring support from the DT
     - rockchip: Rework to use DRM PSR helpers, fix a bug in the VOP_WIN_GET
                 macro
     - sun4i: Improve support for color encoding and range
     - tinydrm: Rework SPI support, improve MIPI-DBI support, move to drm/tiny
     - vkms: Rework of the CRC tracking
    
     - bridges:
       - sii902x: Add support for audio graph card
       - tc358767: Rework AUX data handling code
       - ti-sn65dsi86: Add Debugfs and proper DSI mode flags support
    
     - panels
       - Support for GiantPlus GPM940B0, Sharp LQ070Y3DG3B, Ortustech
         COM37H3M, Novatek NT39016, Sharp LS020B1DD01D, Raydium RM67191,
         Boe Himax8279d, Sharp LD-D5116Z01B
       - Conversion of the device tree bindings to the YAML description
       - jh057n00900: Rework the enable / disable path
    
     - fbdev:
       - ssd1307fb: Support more devices based on that controller
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    
    From: Maxime Ripard <maxime.ripard@bootlin.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190808121423.xzpedzkpyecvsiy4@flea

commit 5a5011a72489545343a1599362e9ec126d7bd297
Author: Gerd Hoffmann <kraxel@redhat.com>
Date:   Mon Aug 5 16:01:15 2019 +0200

    drm/amdgpu: switch driver from bo->resv to bo->base.resv
    
    Signed-off-by: Gerd Hoffmann <kraxel@redhat.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20190805140119.7337-14-kraxel@redhat.com

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index cce0575119b0..e748cd284780 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -402,7 +402,7 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 	struct ttm_operation_ctx ctx = {
 		.interruptible = true,
 		.no_wait_gpu = false,
-		.resv = bo->tbo.resv,
+		.resv = bo->tbo.base.resv,
 		.flags = 0
 	};
 	uint32_t domain;
@@ -730,7 +730,7 @@ static int amdgpu_cs_sync_rings(struct amdgpu_cs_parser *p)
 
 	list_for_each_entry(e, &p->validated, tv.head) {
 		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(e->tv.bo);
-		struct reservation_object *resv = bo->tbo.resv;
+		struct reservation_object *resv = bo->tbo.base.resv;
 
 		r = amdgpu_sync_resv(p->adev, &p->job->sync, resv, p->filp,
 				     amdgpu_bo_explicit_sync(bo));
@@ -1729,7 +1729,7 @@ int amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 	*map = mapping;
 
 	/* Double check that the BO is reserved by this CS */
-	if (reservation_object_locking_ctx((*bo)->tbo.resv) != &parser->ticket)
+	if (reservation_object_locking_ctx((*bo)->tbo.base.resv) != &parser->ticket)
 		return -EINVAL;
 
 	if (!((*bo)->flags & AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS)) {

commit 0dbd555a011c2d096a7b7e40c83c5776a7df367c
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Jul 31 09:41:50 2019 +0200

    dma-buf: add more reservation object locking wrappers
    
    Complete the abstraction of the ww_mutex inside the reservation object.
    
    This allows us to add more handling and debugging to the reservation
    object in the future.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chris Wilson <chris@chris-wilson.co.uk>
    Link: https://patchwork.freedesktop.org/patch/320761/

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index e069de8b54e6..cce0575119b0 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1729,7 +1729,7 @@ int amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 	*map = mapping;
 
 	/* Double check that the BO is reserved by this CS */
-	if (READ_ONCE((*bo)->tbo.resv->lock.ctx) != &parser->ticket)
+	if (reservation_object_locking_ctx((*bo)->tbo.resv) != &parser->ticket)
 		return -EINVAL;
 
 	if (!((*bo)->flags & AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS)) {

commit 67d0859e2758ef992fd32499747ce4b1038a63c0
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Jul 30 11:17:03 2019 +0200

    drm/amdgpu: fix error handling in amdgpu_cs_process_fence_dep
    
    We always need to drop the ctx reference and should check
    for errors first and then dereference the fence pointer.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index e069de8b54e6..4e4094f842e7 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1044,29 +1044,27 @@ static int amdgpu_cs_process_fence_dep(struct amdgpu_cs_parser *p,
 			return r;
 		}
 
-		fence = amdgpu_ctx_get_fence(ctx, entity,
-					     deps[i].handle);
+		fence = amdgpu_ctx_get_fence(ctx, entity, deps[i].handle);
+		amdgpu_ctx_put(ctx);
+
+		if (IS_ERR(fence))
+			return PTR_ERR(fence);
+		else if (!fence)
+			continue;
 
 		if (chunk->chunk_id == AMDGPU_CHUNK_ID_SCHEDULED_DEPENDENCIES) {
-			struct drm_sched_fence *s_fence = to_drm_sched_fence(fence);
+			struct drm_sched_fence *s_fence;
 			struct dma_fence *old = fence;
 
+			s_fence = to_drm_sched_fence(fence);
 			fence = dma_fence_get(&s_fence->scheduled);
 			dma_fence_put(old);
 		}
 
-		if (IS_ERR(fence)) {
-			r = PTR_ERR(fence);
-			amdgpu_ctx_put(ctx);
+		r = amdgpu_sync_fence(p->adev, &p->job->sync, fence, true);
+		dma_fence_put(fence);
+		if (r)
 			return r;
-		} else if (fence) {
-			r = amdgpu_sync_fence(p->adev, &p->job->sync, fence,
-					true);
-			dma_fence_put(fence);
-			amdgpu_ctx_put(ctx);
-			if (r)
-				return r;
-		}
 	}
 	return 0;
 }

commit e5eaa7cc0c0359cfe17b0027a6ac5eda7a9635db
Author: Philip Yang <Philip.Yang@amd.com>
Date:   Tue Jul 2 18:39:45 2019 -0400

    drm/amdgpu: Prepare for hmm_range_register API change (v2)
    
    An upcoming change in the hmm_range_register API requires passing in
    a pointer to an hmm_mirror instead of mm_struct. To access the
    hmm_mirror we need pass bo instead of ttm to amdgpu_ttm_tt_get_user_pages
    because mirror is part of amdgpu_mn structure, which is accessible from bo.
    
    v2: fix building without CONFIG_HMM_MIRROR (Arnd)
    
    Signed-off-by: Philip Yang <Philip.Yang@amd.com>
    Signed-off-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 37adce981fa3..e069de8b54e6 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -633,7 +633,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 			return -ENOMEM;
 		}
 
-		r = amdgpu_ttm_tt_get_user_pages(bo->tbo.ttm, e->user_pages);
+		r = amdgpu_ttm_tt_get_user_pages(bo, e->user_pages);
 		if (r) {
 			kvfree(e->user_pages);
 			e->user_pages = NULL;

commit d7929c1e13e3788e7cb741d75b5baec5e53eff21
Merge: 8ac875db0fdc 80d42db02b3a
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Tue Jun 25 08:42:25 2019 -0500

    Merge branch 'drm-next' into drm-next-5.3
    
    Backmerge drm-next and fix up conflicts due to drmP.h removal.
    
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

commit f92d5c6123f4f06a3660e4c398e1d453d1d29a9d
Author: Jack Xiao <Jack.Xiao@amd.com>
Date:   Thu Jan 10 15:50:10 2019 +0800

    drm/amdgpu: enable the static csa when mcbp enabled
    
    CSA is the Context Save Area for preemption.
    
    Acked-by: Hawking Zhang <Hawking.Zhang@amd.com>
    Signed-off-by: Jack Xiao <Jack.Xiao@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 3e2da24cd17a..c25e1ebc76c3 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -872,7 +872,7 @@ static int amdgpu_cs_vm_handling(struct amdgpu_cs_parser *p)
 	if (r)
 		return r;
 
-	if (amdgpu_sriov_vf(adev)) {
+	if (amdgpu_mcbp || amdgpu_sriov_vf(adev)) {
 		struct dma_fence *f;
 
 		bo_va = fpriv->csa_va;
@@ -961,7 +961,8 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		if (chunk->chunk_id != AMDGPU_CHUNK_ID_IB)
 			continue;
 
-		if (chunk_ib->ip_type == AMDGPU_HW_IP_GFX && amdgpu_sriov_vf(adev)) {
+		if (chunk_ib->ip_type == AMDGPU_HW_IP_GFX &&
+		    (amdgpu_mcbp || amdgpu_sriov_vf(adev))) {
 			if (chunk_ib->flags & AMDGPU_IB_FLAG_PREEMPT) {
 				if (chunk_ib->flags & AMDGPU_IB_FLAG_CE)
 					ce_preempt++;

commit 2454fcea338ad821a39d471bc7db5a58ba41b742
Merge: 561564bea324 51e857af9f3f
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Fri Jun 14 11:31:13 2019 +0200

    Merge tag 'drm-misc-next-2019-06-14' of git://anongit.freedesktop.org/drm/drm-misc into drm-next
    
    drm-misc-next for v5.3:
    
    UAPI Changes:
    
    Cross-subsystem Changes:
    - Add code to signal all dma-fences when freed with pending signals.
    - Annotate reservation object access in CONFIG_DEBUG_MUTEXES
    
    Core Changes:
    - Assorted documentation fixes.
    - Use irqsave/restore spinlock to add crc entry.
    - Move code around to drm_client, for internal modeset clients.
    - Make drm_crtc.h and drm_debugfs.h self-contained.
    - Remove drm_fb_helper_connector.
    - Add bootsplash to todo.
    - Fix lock ordering in pan_display_legacy.
    - Support pinning buffers to current location in gem-vram.
    - Remove the now unused locking functions from gem-vram.
    - Remove the now unused kmap-object argument from vram helpers.
    - Stop checking return value of debugfs_create.
    - Add atomic encoder enable/disable helpers.
    - pass drm_atomic_state to atomic connector check.
    - Add atomic support for bridge enable/disable.
    - Add self refresh helpers to core.
    
    Driver Changes:
    - Add extra delay to make MTP SDM845 work.
    - Small fixes to virtio, vkms, sii902x, sii9234, ast, mcde, analogix, rockchip.
    - Add zpos and ?BGR8888 support to meson.
    - More removals of drm_os_linux and drmP headers for amd, radeon, sti, r128, r128, savage, sis.
    - Allow synopsis to unwedge the i2c hdmi bus.
    - Add orientation quirks for GPD panels.
    - Edid cleanups and fixing handling for edid < 1.2.
    - Add runtime pm to stm.
    - Handle s/r in dw-hdmi.
    - Add hooks for power on/off to dsi for stm.
    - Remove virtio dirty tracking code, done in drm core.
    - Rework BO handling in ast and mgag200.
    
    Tiny conflict in drivers/gpu/drm/amd/display/dc/clk_mgr/clk_mgr.c,
    needed #include <linux/slab.h> to make it compile.
    
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    From: Maarten Lankhorst <maarten.lankhorst@linux.intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/0e01de30-9797-853c-732f-4a5bd6e61445@linux.intel.com

commit 55c2e5a1600cfa9bb7afb445318d6ba1730251a5
Author: Christian König <christian.koenig@amd.com>
Date:   Fri May 10 16:09:48 2019 +0200

    drm/amdgpu: stop removing BOs from the LRU v3
    
    This avoids OOM situations when we have lots of threads
    submitting at the same time.
    
    v3: apply this to the whole driver, not just CS
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Tested-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 20f2955d2a55..3e2da24cd17a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -648,7 +648,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	}
 
 	r = ttm_eu_reserve_buffers(&p->ticket, &p->validated, true,
-				   &duplicates, true);
+				   &duplicates, false);
 	if (unlikely(r != 0)) {
 		if (r != -ERESTARTSYS)
 			DRM_ERROR("ttm_eu_reserve_buffers failed.\n");

commit a3e7738d577162557e03176aed1594746fc2388e
Author: Christian König <christian.koenig@amd.com>
Date:   Fri May 17 09:31:44 2019 +0200

    drm/amdgpu: drop some validation failure messages
    
    The messages about amdgpu_cs_list_validate are duplicated because the
    caller will complain into the logs as well and we can also get
    interrupted by a signal here.
    
    Also fix the the caller to not report -EAGAIN from validation.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Tested-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index fff558cf385b..20f2955d2a55 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -671,16 +671,12 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	}
 
 	r = amdgpu_cs_list_validate(p, &duplicates);
-	if (r) {
-		DRM_ERROR("amdgpu_cs_list_validate(duplicates) failed.\n");
+	if (r)
 		goto error_validate;
-	}
 
 	r = amdgpu_cs_list_validate(p, &p->validated);
-	if (r) {
-		DRM_ERROR("amdgpu_cs_list_validate(validated) failed.\n");
+	if (r)
 		goto error_validate;
-	}
 
 	amdgpu_cs_report_moved_bytes(p->adev, p->bytes_moved,
 				     p->bytes_moved_vis);
@@ -1383,7 +1379,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	if (r) {
 		if (r == -ENOMEM)
 			DRM_ERROR("Not enough memory for command submission!\n");
-		else if (r != -ERESTARTSYS)
+		else if (r != -ERESTARTSYS && r != -EAGAIN)
 			DRM_ERROR("Failed to process the buffer list %d!\n", r);
 		goto out;
 	}

commit fdf2f6c56e5e289c7d7e726b676aba25643b39a0
Author: Sam Ravnborg <sam@ravnborg.org>
Date:   Mon Jun 10 00:07:56 2019 +0200

    drm/amd: drop use of drmP.h in amdgpu/amdgpu*
    
    Drop use of drmP.h in all files named amdgpu*
    in drm/amd/amdgpu/
    
    Fix fallout.
    
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: "Christian König" <christian.koenig@amd.com>
    Cc: "David (ChunMing) Zhou" <David1.Zhou@amd.com>
    Cc: David Airlie <airlied@linux.ie>
    Cc: Daniel Vetter <daniel@ffwll.ch>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190609220757.10862-10-sam@ravnborg.org

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 2f6239b6be6f..7cd24c1d7919 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -24,9 +24,11 @@
  * Authors:
  *    Jerome Glisse <glisse@freedesktop.org>
  */
+
+#include <linux/file.h>
 #include <linux/pagemap.h>
 #include <linux/sync_file.h>
-#include <drm/drmP.h>
+
 #include <drm/amdgpu_drm.h>
 #include <drm/drm_syncobj.h>
 #include "amdgpu.h"

commit 6e58ab7ac7fac61acd7705a8abf1632462c1512a
Author: Christian König <christian.koenig@amd.com>
Date:   Fri May 10 14:15:08 2019 +0200

    drm/ttm: Make LRU removal optional v2
    
    We are already doing this for DMA-buf imports and also for
    amdgpu VM BOs for quite a while now.
    
    If this doesn't run into any problems we are probably going
    to stop removing BOs from the LRU altogether.
    
    v2: drop BUG_ON from ttm_bo_add_to_lru
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Tested-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index d72cc583ebd1..fff558cf385b 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -648,7 +648,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	}
 
 	r = ttm_eu_reserve_buffers(&p->ticket, &p->validated, true,
-				   &duplicates);
+				   &duplicates, true);
 	if (unlikely(r != 0)) {
 		if (r != -ERESTARTSYS)
 			DRM_ERROR("ttm_eu_reserve_buffers failed.\n");

commit 899fbde1464639e3d12eaffdad8481a59b367fcb
Author: Philip Yang <Philip.Yang@amd.com>
Date:   Thu Dec 13 15:35:28 2018 -0500

    drm/amdgpu: replace get_user_pages with HMM mirror helpers
    
    Use HMM helper function hmm_vma_fault() to get physical pages backing
    userptr and start CPU page table update track of those pages. Then use
    hmm_vma_range_done() to check if those pages are updated before
    amdgpu_cs_submit for gfx or before user queues are resumed for kfd.
    
    If userptr pages are updated, for gfx, amdgpu_cs_ioctl will restart
    from scratch, for kfd, restore worker is rescheduled to retry.
    
    HMM simplify the CPU page table concurrent update check, so remove
    guptasklock, mmu_invalidations, last_set_pages fields from
    amdgpu_ttm_tt struct.
    
    HMM does not pin the page (increase page ref count), so remove related
    operations like release_pages(), put_page(), mark_page_dirty().
    
    Signed-off-by: Philip Yang <Philip.Yang@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 8cee09c60c99..d72cc583ebd1 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -52,7 +52,6 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 	p->uf_entry.tv.bo = &bo->tbo;
 	/* One for TTM and one for the CS job */
 	p->uf_entry.tv.num_shared = 2;
-	p->uf_entry.user_pages = NULL;
 
 	drm_gem_object_put_unlocked(gobj);
 
@@ -542,14 +541,14 @@ static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 		if (usermm && usermm != current->mm)
 			return -EPERM;
 
-		/* Check if we have user pages and nobody bound the BO already */
-		if (amdgpu_ttm_tt_userptr_needs_pages(bo->tbo.ttm) &&
-		    lobj->user_pages) {
+		if (amdgpu_ttm_tt_is_userptr(bo->tbo.ttm) &&
+		    lobj->user_invalidated && lobj->user_pages) {
 			amdgpu_bo_placement_from_domain(bo,
 							AMDGPU_GEM_DOMAIN_CPU);
 			r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
 			if (r)
 				return r;
+
 			amdgpu_ttm_tt_set_user_pages(bo->tbo.ttm,
 						     lobj->user_pages);
 			binding_userptr = true;
@@ -580,7 +579,6 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	struct amdgpu_bo *gds;
 	struct amdgpu_bo *gws;
 	struct amdgpu_bo *oa;
-	unsigned tries = 10;
 	int r;
 
 	INIT_LIST_HEAD(&p->validated);
@@ -616,79 +614,45 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	if (p->uf_entry.tv.bo && !ttm_to_amdgpu_bo(p->uf_entry.tv.bo)->parent)
 		list_add(&p->uf_entry.tv.head, &p->validated);
 
-	while (1) {
-		struct list_head need_pages;
-
-		r = ttm_eu_reserve_buffers(&p->ticket, &p->validated, true,
-					   &duplicates);
-		if (unlikely(r != 0)) {
-			if (r != -ERESTARTSYS)
-				DRM_ERROR("ttm_eu_reserve_buffers failed.\n");
-			goto error_free_pages;
-		}
-
-		INIT_LIST_HEAD(&need_pages);
-		amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
-			struct amdgpu_bo *bo = ttm_to_amdgpu_bo(e->tv.bo);
-
-			if (amdgpu_ttm_tt_userptr_invalidated(bo->tbo.ttm,
-				 &e->user_invalidated) && e->user_pages) {
-
-				/* We acquired a page array, but somebody
-				 * invalidated it. Free it and try again
-				 */
-				release_pages(e->user_pages,
-					      bo->tbo.ttm->num_pages);
-				kvfree(e->user_pages);
-				e->user_pages = NULL;
-			}
-
-			if (amdgpu_ttm_tt_userptr_needs_pages(bo->tbo.ttm) &&
-			    !e->user_pages) {
-				list_del(&e->tv.head);
-				list_add(&e->tv.head, &need_pages);
-
-				amdgpu_bo_unreserve(bo);
-			}
+	/* Get userptr backing pages. If pages are updated after registered
+	 * in amdgpu_gem_userptr_ioctl(), amdgpu_cs_list_validate() will do
+	 * amdgpu_ttm_backend_bind() to flush and invalidate new pages
+	 */
+	amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
+		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(e->tv.bo);
+		bool userpage_invalidated = false;
+		int i;
+
+		e->user_pages = kvmalloc_array(bo->tbo.ttm->num_pages,
+					sizeof(struct page *),
+					GFP_KERNEL | __GFP_ZERO);
+		if (!e->user_pages) {
+			DRM_ERROR("calloc failure\n");
+			return -ENOMEM;
 		}
 
-		if (list_empty(&need_pages))
-			break;
-
-		/* Unreserve everything again. */
-		ttm_eu_backoff_reservation(&p->ticket, &p->validated);
-
-		/* We tried too many times, just abort */
-		if (!--tries) {
-			r = -EDEADLK;
-			DRM_ERROR("deadlock in %s\n", __func__);
-			goto error_free_pages;
+		r = amdgpu_ttm_tt_get_user_pages(bo->tbo.ttm, e->user_pages);
+		if (r) {
+			kvfree(e->user_pages);
+			e->user_pages = NULL;
+			return r;
 		}
 
-		/* Fill the page arrays for all userptrs. */
-		list_for_each_entry(e, &need_pages, tv.head) {
-			struct ttm_tt *ttm = e->tv.bo->ttm;
-
-			e->user_pages = kvmalloc_array(ttm->num_pages,
-							 sizeof(struct page*),
-							 GFP_KERNEL | __GFP_ZERO);
-			if (!e->user_pages) {
-				r = -ENOMEM;
-				DRM_ERROR("calloc failure in %s\n", __func__);
-				goto error_free_pages;
-			}
-
-			r = amdgpu_ttm_tt_get_user_pages(ttm, e->user_pages);
-			if (r) {
-				DRM_ERROR("amdgpu_ttm_tt_get_user_pages failed.\n");
-				kvfree(e->user_pages);
-				e->user_pages = NULL;
-				goto error_free_pages;
+		for (i = 0; i < bo->tbo.ttm->num_pages; i++) {
+			if (bo->tbo.ttm->pages[i] != e->user_pages[i]) {
+				userpage_invalidated = true;
+				break;
 			}
 		}
+		e->user_invalidated = userpage_invalidated;
+	}
 
-		/* And try again. */
-		list_splice(&need_pages, &p->validated);
+	r = ttm_eu_reserve_buffers(&p->ticket, &p->validated, true,
+				   &duplicates);
+	if (unlikely(r != 0)) {
+		if (r != -ERESTARTSYS)
+			DRM_ERROR("ttm_eu_reserve_buffers failed.\n");
+		goto out;
 	}
 
 	amdgpu_cs_get_threshold_for_moves(p->adev, &p->bytes_moved_threshold,
@@ -757,17 +721,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 error_validate:
 	if (r)
 		ttm_eu_backoff_reservation(&p->ticket, &p->validated);
-
-error_free_pages:
-
-	amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
-		if (!e->user_pages)
-			continue;
-
-		release_pages(e->user_pages, e->tv.bo->ttm->num_pages);
-		kvfree(e->user_pages);
-	}
-
+out:
 	return r;
 }
 
@@ -1326,7 +1280,6 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	struct amdgpu_bo_list_entry *e;
 	struct amdgpu_job *job;
 	uint64_t seq;
-
 	int r;
 
 	job = p->job;
@@ -1336,15 +1289,23 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	if (r)
 		goto error_unlock;
 
-	/* No memory allocation is allowed while holding the mn lock */
+	/* No memory allocation is allowed while holding the mn lock.
+	 * p->mn is hold until amdgpu_cs_submit is finished and fence is added
+	 * to BOs.
+	 */
 	amdgpu_mn_lock(p->mn);
+
+	/* If userptr are invalidated after amdgpu_cs_parser_bos(), return
+	 * -EAGAIN, drmIoctl in libdrm will restart the amdgpu_cs_ioctl.
+	 */
 	amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
 		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(e->tv.bo);
 
-		if (amdgpu_ttm_tt_userptr_needs_pages(bo->tbo.ttm)) {
-			r = -ERESTARTSYS;
-			goto error_abort;
-		}
+		r |= !amdgpu_ttm_tt_get_user_pages_done(bo->tbo.ttm);
+	}
+	if (r) {
+		r = -EAGAIN;
+		goto error_abort;
 	}
 
 	job->owner = p->filp;
@@ -1440,6 +1401,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 out:
 	amdgpu_cs_parser_fini(&parser, r, reserved_buffers);
+
 	return r;
 }
 

commit 742b48aed44b7f347e82d2d5c48f68110731ac78
Author: Leo Liu <leo.liu@amd.com>
Date:   Wed May 8 11:13:53 2019 -0400

    drm/amdgpu: check no_user_fence flag for engines
    
    To replace checking ring type and make them generic
    
    Signed-off-by: Leo Liu <leo.liu@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 2f6239b6be6f..8cee09c60c99 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1054,11 +1054,9 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		j++;
 	}
 
-	/* UVD & VCE fw doesn't support user fences */
+	/* MM engine doesn't support user fences */
 	ring = to_amdgpu_ring(parser->entity->rq->sched);
-	if (parser->job->uf_addr && (
-	    ring->funcs->type == AMDGPU_RING_TYPE_UVD ||
-	    ring->funcs->type == AMDGPU_RING_TYPE_VCE))
+	if (parser->job->uf_addr && ring->funcs->no_user_fence)
 		return -EINVAL;
 
 	return amdgpu_ctx_wait_prev_fence(parser->ctx, parser->entity);

commit 2624dd154bcc53ac2de16ecae9746ba867b6ca70
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Mon Apr 1 17:51:00 2019 +0800

    drm/amdgpu: add timeline support in amdgpu CS v3
    
    syncobj wait/signal operation is appending in command submission.
    v2: separate to two kinds in/out_deps functions
    v3: fix checking for timeline syncobj
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Cc: Tobias Hector <Tobias.Hector@amd.com>
    Cc: Jason Ekstrand <jason@jlekstrand.net>
    Cc: Dave Airlie <airlied@redhat.com>
    Cc: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Lionel Landwerlin <lionel.g.landwerlin@intel.com>
    Reviewed-by: Lionel Landwerlin <lionel.g.landwerlin@intel.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 52a5e4fdc95b..2f6239b6be6f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -215,6 +215,8 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, union drm_amdgpu_cs
 		case AMDGPU_CHUNK_ID_SYNCOBJ_IN:
 		case AMDGPU_CHUNK_ID_SYNCOBJ_OUT:
 		case AMDGPU_CHUNK_ID_SCHEDULED_DEPENDENCIES:
+		case AMDGPU_CHUNK_ID_SYNCOBJ_TIMELINE_WAIT:
+		case AMDGPU_CHUNK_ID_SYNCOBJ_TIMELINE_SIGNAL:
 			break;
 
 		default:
@@ -804,9 +806,11 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error,
 		ttm_eu_backoff_reservation(&parser->ticket,
 					   &parser->validated);
 
-	for (i = 0; i < parser->num_post_dep_syncobjs; i++)
-		drm_syncobj_put(parser->post_dep_syncobjs[i]);
-	kfree(parser->post_dep_syncobjs);
+	for (i = 0; i < parser->num_post_deps; i++) {
+		drm_syncobj_put(parser->post_deps[i].syncobj);
+		kfree(parser->post_deps[i].chain);
+	}
+	kfree(parser->post_deps);
 
 	dma_fence_put(parser->fence);
 
@@ -1117,13 +1121,18 @@ static int amdgpu_cs_process_fence_dep(struct amdgpu_cs_parser *p,
 }
 
 static int amdgpu_syncobj_lookup_and_add_to_sync(struct amdgpu_cs_parser *p,
-						 uint32_t handle)
+						 uint32_t handle, u64 point,
+						 u64 flags)
 {
-	int r;
 	struct dma_fence *fence;
-	r = drm_syncobj_find_fence(p->filp, handle, 0, 0, &fence);
-	if (r)
+	int r;
+
+	r = drm_syncobj_find_fence(p->filp, handle, point, flags, &fence);
+	if (r) {
+		DRM_ERROR("syncobj %u failed to find fence @ %llu (%d)!\n",
+			  handle, point, r);
 		return r;
+	}
 
 	r = amdgpu_sync_fence(p->adev, &p->job->sync, fence, true);
 	dma_fence_put(fence);
@@ -1134,46 +1143,118 @@ static int amdgpu_syncobj_lookup_and_add_to_sync(struct amdgpu_cs_parser *p,
 static int amdgpu_cs_process_syncobj_in_dep(struct amdgpu_cs_parser *p,
 					    struct amdgpu_cs_chunk *chunk)
 {
+	struct drm_amdgpu_cs_chunk_sem *deps;
 	unsigned num_deps;
 	int i, r;
-	struct drm_amdgpu_cs_chunk_sem *deps;
 
 	deps = (struct drm_amdgpu_cs_chunk_sem *)chunk->kdata;
 	num_deps = chunk->length_dw * 4 /
 		sizeof(struct drm_amdgpu_cs_chunk_sem);
+	for (i = 0; i < num_deps; ++i) {
+		r = amdgpu_syncobj_lookup_and_add_to_sync(p, deps[i].handle,
+							  0, 0);
+		if (r)
+			return r;
+	}
+
+	return 0;
+}
+
 
+static int amdgpu_cs_process_syncobj_timeline_in_dep(struct amdgpu_cs_parser *p,
+						     struct amdgpu_cs_chunk *chunk)
+{
+	struct drm_amdgpu_cs_chunk_syncobj *syncobj_deps;
+	unsigned num_deps;
+	int i, r;
+
+	syncobj_deps = (struct drm_amdgpu_cs_chunk_syncobj *)chunk->kdata;
+	num_deps = chunk->length_dw * 4 /
+		sizeof(struct drm_amdgpu_cs_chunk_syncobj);
 	for (i = 0; i < num_deps; ++i) {
-		r = amdgpu_syncobj_lookup_and_add_to_sync(p, deps[i].handle);
+		r = amdgpu_syncobj_lookup_and_add_to_sync(p,
+							  syncobj_deps[i].handle,
+							  syncobj_deps[i].point,
+							  syncobj_deps[i].flags);
 		if (r)
 			return r;
 	}
+
 	return 0;
 }
 
 static int amdgpu_cs_process_syncobj_out_dep(struct amdgpu_cs_parser *p,
 					     struct amdgpu_cs_chunk *chunk)
 {
+	struct drm_amdgpu_cs_chunk_sem *deps;
 	unsigned num_deps;
 	int i;
-	struct drm_amdgpu_cs_chunk_sem *deps;
+
 	deps = (struct drm_amdgpu_cs_chunk_sem *)chunk->kdata;
 	num_deps = chunk->length_dw * 4 /
 		sizeof(struct drm_amdgpu_cs_chunk_sem);
 
-	p->post_dep_syncobjs = kmalloc_array(num_deps,
-					     sizeof(struct drm_syncobj *),
-					     GFP_KERNEL);
-	p->num_post_dep_syncobjs = 0;
+	p->post_deps = kmalloc_array(num_deps, sizeof(*p->post_deps),
+				     GFP_KERNEL);
+	p->num_post_deps = 0;
 
-	if (!p->post_dep_syncobjs)
+	if (!p->post_deps)
 		return -ENOMEM;
 
+
 	for (i = 0; i < num_deps; ++i) {
-		p->post_dep_syncobjs[i] = drm_syncobj_find(p->filp, deps[i].handle);
-		if (!p->post_dep_syncobjs[i])
+		p->post_deps[i].syncobj =
+			drm_syncobj_find(p->filp, deps[i].handle);
+		if (!p->post_deps[i].syncobj)
 			return -EINVAL;
-		p->num_post_dep_syncobjs++;
+		p->post_deps[i].chain = NULL;
+		p->post_deps[i].point = 0;
+		p->num_post_deps++;
 	}
+
+	return 0;
+}
+
+
+static int amdgpu_cs_process_syncobj_timeline_out_dep(struct amdgpu_cs_parser *p,
+						      struct amdgpu_cs_chunk
+						      *chunk)
+{
+	struct drm_amdgpu_cs_chunk_syncobj *syncobj_deps;
+	unsigned num_deps;
+	int i;
+
+	syncobj_deps = (struct drm_amdgpu_cs_chunk_syncobj *)chunk->kdata;
+	num_deps = chunk->length_dw * 4 /
+		sizeof(struct drm_amdgpu_cs_chunk_syncobj);
+
+	p->post_deps = kmalloc_array(num_deps, sizeof(*p->post_deps),
+				     GFP_KERNEL);
+	p->num_post_deps = 0;
+
+	if (!p->post_deps)
+		return -ENOMEM;
+
+	for (i = 0; i < num_deps; ++i) {
+		struct amdgpu_cs_post_dep *dep = &p->post_deps[i];
+
+		dep->chain = NULL;
+		if (syncobj_deps[i].point) {
+			dep->chain = kmalloc(sizeof(*dep->chain), GFP_KERNEL);
+			if (!dep->chain)
+				return -ENOMEM;
+		}
+
+		dep->syncobj = drm_syncobj_find(p->filp,
+						syncobj_deps[i].handle);
+		if (!dep->syncobj) {
+			kfree(dep->chain);
+			return -EINVAL;
+		}
+		dep->point = syncobj_deps[i].point;
+		p->num_post_deps++;
+	}
+
 	return 0;
 }
 
@@ -1187,19 +1268,33 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 
 		chunk = &p->chunks[i];
 
-		if (chunk->chunk_id == AMDGPU_CHUNK_ID_DEPENDENCIES ||
-		    chunk->chunk_id == AMDGPU_CHUNK_ID_SCHEDULED_DEPENDENCIES) {
+		switch (chunk->chunk_id) {
+		case AMDGPU_CHUNK_ID_DEPENDENCIES:
+		case AMDGPU_CHUNK_ID_SCHEDULED_DEPENDENCIES:
 			r = amdgpu_cs_process_fence_dep(p, chunk);
 			if (r)
 				return r;
-		} else if (chunk->chunk_id == AMDGPU_CHUNK_ID_SYNCOBJ_IN) {
+			break;
+		case AMDGPU_CHUNK_ID_SYNCOBJ_IN:
 			r = amdgpu_cs_process_syncobj_in_dep(p, chunk);
 			if (r)
 				return r;
-		} else if (chunk->chunk_id == AMDGPU_CHUNK_ID_SYNCOBJ_OUT) {
+			break;
+		case AMDGPU_CHUNK_ID_SYNCOBJ_OUT:
 			r = amdgpu_cs_process_syncobj_out_dep(p, chunk);
 			if (r)
 				return r;
+			break;
+		case AMDGPU_CHUNK_ID_SYNCOBJ_TIMELINE_WAIT:
+			r = amdgpu_cs_process_syncobj_timeline_in_dep(p, chunk);
+			if (r)
+				return r;
+			break;
+		case AMDGPU_CHUNK_ID_SYNCOBJ_TIMELINE_SIGNAL:
+			r = amdgpu_cs_process_syncobj_timeline_out_dep(p, chunk);
+			if (r)
+				return r;
+			break;
 		}
 	}
 
@@ -1210,8 +1305,17 @@ static void amdgpu_cs_post_dependencies(struct amdgpu_cs_parser *p)
 {
 	int i;
 
-	for (i = 0; i < p->num_post_dep_syncobjs; ++i)
-		drm_syncobj_replace_fence(p->post_dep_syncobjs[i], p->fence);
+	for (i = 0; i < p->num_post_deps; ++i) {
+		if (p->post_deps[i].chain && p->post_deps[i].point) {
+			drm_syncobj_add_point(p->post_deps[i].syncobj,
+					      p->post_deps[i].chain,
+					      p->fence, p->post_deps[i].point);
+			p->post_deps[i].chain = NULL;
+		} else {
+			drm_syncobj_replace_fence(p->post_deps[i].syncobj,
+						  p->fence);
+		}
+	}
 }
 
 static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,

commit 67dd1a36334ffce82bebeb2d633e152aa436d370
Author: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
Date:   Thu Jan 31 15:44:22 2019 -0500

    drm/amdgpu: Add AMDGPU_CHUNK_ID_SCHEDULED_DEPENDENCIES
    
    New chunk for dependency on start of job's execution instead on
    the end. This is used for GPU deadlock prevention when
    userspace uses mid-IB fences to wait for mid-IB work on other rings.
    
    v2: Fix typo in AMDGPU_CHUNK_ID_SCHEDULED_DEPENDENCIES
    v3: Bump KMS version
    v4: put old fence AFTER acquiring the scheduled fence.
    
    Signed-off-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Suggested-by: Christian Koenig <Christian.Koenig@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 1c49b8266d69..52a5e4fdc95b 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -214,6 +214,7 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, union drm_amdgpu_cs
 		case AMDGPU_CHUNK_ID_DEPENDENCIES:
 		case AMDGPU_CHUNK_ID_SYNCOBJ_IN:
 		case AMDGPU_CHUNK_ID_SYNCOBJ_OUT:
+		case AMDGPU_CHUNK_ID_SCHEDULED_DEPENDENCIES:
 			break;
 
 		default:
@@ -1090,6 +1091,15 @@ static int amdgpu_cs_process_fence_dep(struct amdgpu_cs_parser *p,
 
 		fence = amdgpu_ctx_get_fence(ctx, entity,
 					     deps[i].handle);
+
+		if (chunk->chunk_id == AMDGPU_CHUNK_ID_SCHEDULED_DEPENDENCIES) {
+			struct drm_sched_fence *s_fence = to_drm_sched_fence(fence);
+			struct dma_fence *old = fence;
+
+			fence = dma_fence_get(&s_fence->scheduled);
+			dma_fence_put(old);
+		}
+
 		if (IS_ERR(fence)) {
 			r = PTR_ERR(fence);
 			amdgpu_ctx_put(ctx);
@@ -1177,7 +1187,8 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 
 		chunk = &p->chunks[i];
 
-		if (chunk->chunk_id == AMDGPU_CHUNK_ID_DEPENDENCIES) {
+		if (chunk->chunk_id == AMDGPU_CHUNK_ID_DEPENDENCIES ||
+		    chunk->chunk_id == AMDGPU_CHUNK_ID_SCHEDULED_DEPENDENCIES) {
 			r = amdgpu_cs_process_fence_dep(p, chunk);
 			if (r)
 				return r;

commit 0fe4e2d5cd931ad2ff99d61cfdd5c6dc0c3ec60b
Merge: 3954e1d0310e 9ddf32a8df9e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jan 5 18:25:19 2019 -0800

    Merge tag 'drm-next-2019-01-05' of git://anongit.freedesktop.org/drm/drm
    
    Pull drm fixes from Dave Airlie:
     "Happy New Year, just decloaking from leave to get some stuff from the
      last week in before rc1:
    
      core:
       - two regression fixes for damage blob and atomic
    
      i915 gvt:
       - Some missed GVT fixes from the original pull
    
      amdgpu:
       - new PCI IDs
       - SR-IOV fixes
       - DC fixes
       - Vega20 fixes"
    
    * tag 'drm-next-2019-01-05' of git://anongit.freedesktop.org/drm/drm: (53 commits)
      drm: Put damage blob when destroy plane state
      drm: fix null pointer dereference on null state pointer
      drm/amdgpu: Add new VegaM pci id
      drm/ttm: Use drm_debug_printer for all ttm_bo_mem_space_debug output
      drm/amdgpu: add Vega20 PSP ASD firmware loading
      drm/amd/display: Fix MST dp_blank REG_WAIT timeout
      drm/amd/display: validate extended dongle caps
      drm/amd/display: Use div_u64 for flip timestamp ns to ms
      drm/amdgpu/uvd:Change uvd ring name convention
      drm/amd/powerplay: add Vega20 LCLK DPM level setting support
      drm/amdgpu: print process info when job timeout
      drm/amdgpu/nbio7.4: add hw bug workaround for vega20
      drm/amdgpu/nbio6.1: add hw bug workaround for vega10/12
      drm/amd/display: Optimize passive update planes.
      drm/amd/display: verify lane status before exiting verify link cap
      drm/amd/display: Fix bug with not updating VSP infoframe
      drm/amd/display: Add retry to read ddc_clock pin
      drm/amd/display: Don't skip link training for empty dongle
      drm/amd/display: Wait edp HPD to high in detect_sink
      drm/amd/display: fix surface update sequence
      ...

commit 4971f090aa7f6ce5daa094ce4334f6618f93a7eb
Merge: c76cd634eb5b 2a3c83f5fe07
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 25 11:48:26 2018 -0800

    Merge tag 'drm-next-2018-12-14' of git://anongit.freedesktop.org/drm/drm
    
    Pull drm updates from Dave Airlie:
     "Core:
       - shared fencing staging removal
       - drop transactional atomic helpers and move helpers to new location
       - DP/MST atomic cleanup
       - Leasing cleanups and drop EXPORT_SYMBOL
       - Convert drivers to atomic helpers and generic fbdev.
       - removed deprecated obj_ref/unref in favour of get/put
       - Improve dumb callback documentation
       - MODESET_LOCK_BEGIN/END helpers
    
      panels:
       - CDTech panels, Banana Pi Panel, DLC1010GIG,
       - Olimex LCD-O-LinuXino, Samsung S6D16D0, Truly NT35597 WQXGA,
       - Himax HX8357D, simulated RTSM AEMv8.
       - GPD Win2 panel
       - AUO G101EVN010
    
      vgem:
       - render node support
    
      ttm:
       - move global init out of drivers
       - fix LRU handling for ghost objects
       - Support for simultaneous submissions to multiple engines
    
      scheduler:
       - timeout/fault handling changes to help GPU recovery
       - helpers for hw with preemption support
    
      i915:
       - Scaler/Watermark fixes
       - DP MST + powerwell fixes
       - PSR fixes
       - Break long get/put shmemfs pages
       - Icelake fixes
       - Icelake DSI video mode enablement
       - Engine workaround improvements
    
      amdgpu:
       - freesync support
       - GPU reset enabled on CI, VI, SOC15 dGPUs
       - ABM support in DC
       - KFD support for vega12/polaris12
       - SDMA paging queue on vega
       - More amdkfd code sharing
       - DCC scanout on GFX9
       - DC kerneldoc
       - Updated SMU firmware for GFX8 chips
       - XGMI PSP + hive reset support
       - GPU reset
       - DC trace support
       - Powerplay updates for newer Polaris
       - Cursor plane update fast path
       - kfd dma-buf support
    
      virtio-gpu:
       - add EDID support
    
      vmwgfx:
       - pageflip with damage support
    
      nouveau:
       - Initial Turing TU104/TU106 modesetting support
    
      msm:
       - a2xx gpu support for apq8060 and imx5
       - a2xx gpummu support
       - mdp4 display support for apq8060
       - DPU fixes and cleanups
       - enhanced profiling support
       - debug object naming interface
       - get_iova/page pinning decoupling
    
      tegra:
       - Tegra194 host1x, VIC and display support enabled
       - Audio over HDMI for Tegra186 and Tegra194
    
      exynos:
       - DMA/IOMMU refactoring
       - plane alpha + blend mode support
       - Color format fixes for mixer driver
    
      rcar-du:
       - R8A7744 and R8A77470 support
       - R8A77965 LVDS support
    
      imx:
       - fbdev emulation fix
       - multi-tiled scalling fixes
       - SPDX identifiers
    
      rockchip
       - dw_hdmi support
       - dw-mipi-dsi + dual dsi support
       - mailbox read size fix
    
      qxl:
       - fix cursor pinning
    
      vc4:
       - YUV support (scaling + cursor)
    
      v3d:
       - enable TFU (Texture Formatting Unit)
    
      mali-dp:
       - add support for linear tiled formats
    
      sun4i:
       - Display Engine 3 support
       - H6 DE3 mixer 0 support
       - H6 display engine support
       - dw-hdmi support
       - H6 HDMI phy support
       - implicit fence waiting
       - BGRX8888 support
    
      meson:
       - Overlay plane support
       - implicit fence waiting
       - HDMI 1.4 4k modes
    
      bridge:
       - i2c fixes for sii902x"
    
    * tag 'drm-next-2018-12-14' of git://anongit.freedesktop.org/drm/drm: (1403 commits)
      drm/amd/display: Add fast path for cursor plane updates
      drm/amdgpu: Enable GPU recovery by default for CI
      drm/amd/display: Fix duplicating scaling/underscan connector state
      drm/amd/display: Fix unintialized max_bpc state values
      Revert "drm/amd/display: Set RMX_ASPECT as default"
      drm/amdgpu: Fix stub function name
      drm/msm/dpu: Fix clock issue after bind failure
      drm/msm/dpu: Clean up dpu_media_info.h static inline functions
      drm/msm/dpu: Further cleanups for static inline functions
      drm/msm/dpu: Cleanup the debugfs functions
      drm/msm/dpu: Remove dpu_irq and unused functions
      drm/msm: Make irq_postinstall optional
      drm/msm/dpu: Cleanup callers of dpu_hw_blk_init
      drm/msm/dpu: Remove unused functions
      drm/msm/dpu: Remove dpu_crtc_is_enabled()
      drm/msm/dpu: Remove dpu_crtc_get_mixer_height
      drm/msm/dpu: Remove dpu_dbg
      drm/msm: dpu: Remove crtc_lock
      drm/msm: dpu: Remove vblank_requested flag from dpu_crtc
      drm/msm: dpu: Separate crtc assignment from vblank enable
      ...

commit 4e9177134e7dd992dd96875143413dbc303f355e
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Dec 3 14:05:34 2018 +0100

    drm/amdgpu: fix NULL fence handling in amdgpu_cs_fence_to_handle_ioctl
    
    When the fence is already signaled it is perfectly normal to get a NULL
    fence here. But since we can't export that we need to use a stub fence.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 5dc3ee372e2f..149b3065119b 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1428,6 +1428,9 @@ int amdgpu_cs_fence_to_handle_ioctl(struct drm_device *dev, void *data,
 	if (IS_ERR(fence))
 		return PTR_ERR(fence);
 
+	if (!fence)
+		fence = dma_fence_get_stub();
+
 	switch (info->in.what) {
 	case AMDGPU_FENCE_TO_HANDLE_GET_SYNCOBJ:
 		r = drm_syncobj_create(&syncobj, 0, fence);

commit e7df065a697783ecb5c6eaa5692d78dcfceb71dd
Merge: e69aa5f9b97f 674e78acae0d
Author: Dave Airlie <airlied@redhat.com>
Date:   Thu Dec 13 09:49:04 2018 +1000

    Merge branch 'drm-next-4.21' of git://people.freedesktop.org/~agd5f/linux into drm-next
    
    [airlied: make etnaviv build again]
    
    amdgpu:
    - DC trace support
    - More DC documentation
    - XGMI hive reset support
    - Rework IH interaction with KFD
    - Misc fixes and cleanups
    - Powerplay updates for newer polaris variants
    - Add cursor plane update fast path
    - Enable gpu reset by default on CI parts
    - Fix config with KFD/HSA not enabled
    
    amdkfd:
    - Limit vram overcommit
    - dmabuf support
    - Support for doorbell BOs
    
    ttm:
    - Support for simultaneous submissions to multiple engines
    
    scheduler:
    - Add helpers for hw with preemption support
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    From: Alex Deucher <alexdeucher@gmail.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20181207233119.16861-1-alexander.deucher@amd.com

commit c554206077428af56cc2e0314b86b41cd030458c
Author: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
Date:   Thu Dec 6 15:51:37 2018 -0500

    drm/amdgpu: Fix DEBUG_LOCKS_WARN_ON(depth <= 0) in amdgpu_ctx.lock
    
    If CS is submitted using guilty ctx, we terminate amdgpu_cs_parser_init
    before locking ctx->lock, latter in amdgpu_cs_parser_fini we still are
    trying to release the lock just becase parser->ctx != NULL.
    
    Signed-off-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 663043c8f0f5..0acc8dee2cb8 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -124,14 +124,14 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, union drm_amdgpu_cs
 		goto free_chunk;
 	}
 
+	mutex_lock(&p->ctx->lock);
+
 	/* skip guilty context job */
 	if (atomic_read(&p->ctx->guilty) == 1) {
 		ret = -ECANCELED;
 		goto free_chunk;
 	}
 
-	mutex_lock(&p->ctx->lock);
-
 	/* get chunks */
 	chunk_array_user = u64_to_user_ptr(cs->in.chunks);
 	if (copy_from_user(chunk_array, chunk_array_user,

commit 07daa8a0784e3085c4c8e282a83dd8c92bf59b53
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Sep 24 13:35:08 2018 +0200

    drm/amdgpu: always reserve one more shared slot for pipelined BO moves
    
    This allows us to drop the extra reserve in TTM.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 8cc640abe3de..4a6a1d4a88ea 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -50,7 +50,8 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 	bo = amdgpu_bo_ref(gem_to_amdgpu_bo(gobj));
 	p->uf_entry.priority = 0;
 	p->uf_entry.tv.bo = &bo->tbo;
-	p->uf_entry.tv.num_shared = 1;
+	/* One for TTM and one for the CS job */
+	p->uf_entry.tv.num_shared = 2;
 	p->uf_entry.user_pages = NULL;
 
 	drm_gem_object_put_unlocked(gobj);
@@ -598,8 +599,9 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 			return r;
 	}
 
+	/* One for TTM and one for the CS job */
 	amdgpu_bo_list_for_each_entry(e, p->bo_list)
-		e->tv.num_shared = 1;
+		e->tv.num_shared = 2;
 
 	amdgpu_bo_list_get_list(p->bo_list, &p->validated);
 	if (p->bo_list->first_userptr != p->bo_list->num_entries)

commit 0aa7aa24cc11720a05b4492345f0adba8373c226
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Sep 21 18:09:59 2018 +0200

    drm/amdgpu: always reserve two slots for the VM
    
    And drop the now superflous extra reservations.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index ce58af62d523..8cc640abe3de 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -964,10 +964,6 @@ static int amdgpu_cs_vm_handling(struct amdgpu_cs_parser *p)
 	if (r)
 		return r;
 
-	r = reservation_object_reserve_shared(vm->root.base.bo->tbo.resv, 1);
-	if (r)
-		return r;
-
 	p->job->vm_pd_addr = amdgpu_gmc_pd_addr(vm->root.base.bo);
 
 	if (amdgpu_vm_debug) {

commit 049aca4363d8af87cab8d53de5401602db3b9999
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Sep 19 16:54:35 2018 +0200

    drm/amdgpu: fix using shared fence for exported BOs v2
    
    It is perfectly possible that the BO list is created before the BO is
    exported. While at it clean up setting shared to one instead of true.
    
    v2: add comment and simplify logic
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index a4b2ac541475..ce58af62d523 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -598,6 +598,9 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 			return r;
 	}
 
+	amdgpu_bo_list_for_each_entry(e, p->bo_list)
+		e->tv.num_shared = 1;
+
 	amdgpu_bo_list_get_list(p->bo_list, &p->validated);
 	if (p->bo_list->first_userptr != p->bo_list->num_entries)
 		p->mn = amdgpu_mn_get(p->adev, AMDGPU_MN_TYPE_GFX);
@@ -717,8 +720,14 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	gws = p->bo_list->gws_obj;
 	oa = p->bo_list->oa_obj;
 
-	amdgpu_bo_list_for_each_entry(e, p->bo_list)
-		e->bo_va = amdgpu_vm_bo_find(vm, ttm_to_amdgpu_bo(e->tv.bo));
+	amdgpu_bo_list_for_each_entry(e, p->bo_list) {
+		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(e->tv.bo);
+
+		/* Make sure we use the exclusive slot for shared BOs */
+		if (bo->prime_shared_count)
+			e->tv.num_shared = 0;
+		e->bo_va = amdgpu_vm_bo_find(vm, bo);
+	}
 
 	if (gds) {
 		p->job->gds_base = amdgpu_bo_gpu_offset(gds) >> PAGE_SHIFT;

commit a9f34c70fd168b164aadffd46bb757ded52e25b9
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Sep 19 16:25:08 2018 +0200

    drm/ttm: allow reserving more than one shared slot v3
    
    Let's support simultaneous submissions to multiple engines.
    
    v2: rename the field to num_shared and fix up all users
    v3: rebased
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 024dfbd87f11..a4b2ac541475 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -50,7 +50,7 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 	bo = amdgpu_bo_ref(gem_to_amdgpu_bo(gobj));
 	p->uf_entry.priority = 0;
 	p->uf_entry.tv.bo = &bo->tbo;
-	p->uf_entry.tv.shared = true;
+	p->uf_entry.tv.num_shared = 1;
 	p->uf_entry.user_pages = NULL;
 
 	drm_gem_object_put_unlocked(gobj);

commit 0b258ed1a219a9776e8f6967eb34837ae0332e64
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Nov 14 14:24:27 2018 +0100

    drm: revert "expand replace_fence to support timeline point v2"
    
    This reverts commit 9a09a42369a4a37a959c051d8e1a1f948c1529a4.
    
    The whole interface isn't thought through. Since this function can't
    fail we actually can't allocate an object to store the sync point.
    
    Sorry, I should have taken the lead on this from the very beginning and
    reviewed it more thoughtfully. Going to propose a new interface as a
    follow up change.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Link: https://patchwork.freedesktop.org/patch/265580/

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 024dfbd87f11..dc54e9efd910 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1193,7 +1193,7 @@ static void amdgpu_cs_post_dependencies(struct amdgpu_cs_parser *p)
 	int i;
 
 	for (i = 0; i < p->num_post_dep_syncobjs; ++i)
-		drm_syncobj_replace_fence(p->post_dep_syncobjs[i], 0, p->fence);
+		drm_syncobj_replace_fence(p->post_dep_syncobjs[i], p->fence);
 }
 
 static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,

commit 9235dd441af43599b9cdcce599a3da4083fcad3c
Merge: d7563c55ef9f 36b486bc6821
Author: Dave Airlie <airlied@redhat.com>
Date:   Mon Nov 19 11:07:52 2018 +1000

    Merge branch 'drm-next-4.21' of git://people.freedesktop.org/~agd5f/linux into drm-next
    
    New features for 4.21:
    amdgpu:
    - Support for SDMA paging queue on vega
    - Put compute EOP buffers into vram for better performance
    - Share more code with amdkfd
    - Support for scanout with DCC on gfx9
    - Initial kerneldoc for DC
    - Updated SMU firmware support for gfx8 chips
    - Rework CSA handling for eventual support for preemption
    - XGMI PSP support
    - Clean up RLC handling
    - Enable GPU reset by default on VI, SOC15 dGPUs
    - Ring and IB test cleanups
    
    amdkfd:
    - Share more code with amdgpu
    
    ttm:
    - Move global init out of the drivers
    
    scheduler:
    - Track if schedulers are ready for work
    - Timeout/fault handling changes to facilitate GPU recovery
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    From: Alex Deucher <alexdeucher@gmail.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20181114165113.3751-1-alexander.deucher@amd.com

commit e0519696cc31c111f11e7c67bd663dbb88d6673f
Author: Samuel Pitoiset <samuel.pitoiset@gmail.com>
Date:   Mon Oct 29 12:23:06 2018 +0100

    drm/amdgpu: print an error when the parser can't be initialized
    
    Similar to other error messages, might help for tracking down
    issues.
    
    Signed-off-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 5d768f95de24..fd12e9162f3c 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1284,7 +1284,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 	r = amdgpu_cs_parser_init(&parser, data);
 	if (r) {
-		DRM_ERROR("Failed to initialize parser !\n");
+		DRM_ERROR("Failed to initialize parser %d!\n", r);
 		goto out;
 	}
 

commit 26efecf9558895a89c2920d258601b4afba10fd0
Author: Sharat Masetty <smasetty@codeaurora.org>
Date:   Mon Oct 29 15:02:28 2018 +0530

    drm/scheduler: Add drm_sched_job_cleanup
    
    This patch adds a new API to clean up the scheduler job resources. This
    is primarliy needed in cases the job was created but was not queued to
    the scheduler queue. Additionally with this change, the layer which
    creates the scheduler job also gets to free up the job's resources and
    this entails moving the dma_fence_put(finished_fence) to the drivers
    ops free handler routines.
    
    Signed-off-by: Sharat Masetty <smasetty@codeaurora.org>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Acked-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 663043c8f0f5..5d768f95de24 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1260,8 +1260,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	return 0;
 
 error_abort:
-	dma_fence_put(&job->base.s_fence->finished);
-	job->base.s_fence = NULL;
+	drm_sched_job_cleanup(&job->base);
 	amdgpu_mn_unlock(p->mn);
 
 error_unlock:

commit ca05359f1e64cf8303ee532e50efe4ab7563d4a9
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Sep 19 16:12:25 2018 +0200

    dma-buf: allow reserving more than one shared fence slot
    
    Let's support simultaneous submissions to multiple engines.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Link: https://patchwork.kernel.org/patch/10626149/

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 8e9a65a15875..35bc8fc3bc70 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -955,7 +955,7 @@ static int amdgpu_cs_vm_handling(struct amdgpu_cs_parser *p)
 	if (r)
 		return r;
 
-	r = reservation_object_reserve_shared(vm->root.base.bo->tbo.resv);
+	r = reservation_object_reserve_shared(vm->root.base.bo->tbo.resv, 1);
 	if (r)
 		return r;
 

commit 649fdce23cdf516e69aa8c18f4b44c62127f0e83
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Mon Oct 15 16:55:47 2018 +0800

    drm: add flags to drm_syncobj_find_fence
    
    flags can be used by driver to decide whether need to block wait submission.
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    SIgned-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Link: https://patchwork.kernel.org/patch/10641339/

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 663043c8f0f5..8e9a65a15875 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1104,7 +1104,7 @@ static int amdgpu_syncobj_lookup_and_add_to_sync(struct amdgpu_cs_parser *p,
 {
 	int r;
 	struct dma_fence *fence;
-	r = drm_syncobj_find_fence(p->filp, handle, 0, &fence);
+	r = drm_syncobj_find_fence(p->filp, handle, 0, 0, &fence);
 	if (r)
 		return r;
 

commit bf78296ab1cb215d0609ac6cff4e43e941e51265
Merge: 18eb2f6e19d7 6bf4ca7fbc85
Author: Dave Airlie <airlied@redhat.com>
Date:   Thu Sep 27 11:06:46 2018 +1000

    BackMerge v4.19-rc5 into drm-next
    
    Sean Paul requested an -rc5 backmerge from some sun4i fixes.
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>

commit 36c9c3c91128e2b892c9be0dd9ee9bd82cbe82ad
Merge: 0320ac5188ea 846311ae68f3
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri Sep 21 09:52:34 2018 +1000

    Merge branch 'drm-next-4.20' of git://people.freedesktop.org/~agd5f/linux into drm-next
    
    This is a new pull for drm-next on top of last weeks with the following
    changes:
    - Fixed 64 bit divide
    - Fixed vram type on vega20
    - Misc vega20 fixes
    - Misc DC fixes
    - Fix GDS/GWS/OA domain handling
    
    Previous changes from last week:
    amdgpu/kfd:
    - Picasso (new APU) support
    - Raven2 (new APU) support
    - Vega20 enablement
    - ACP powergating improvements
    - Add ABGR/XBGR display support
    - VCN JPEG engine support
    - Initial xGMI support
    - Use load balancing for engine scheduling
    - Lots of new documentation
    - Rework and clean up i2c and aux handling in DC
    - Add DP YCbCr 4:2:0 support in DC
    - Add DMCU firmware loading for Raven (used for ABM and PSR)
    - New debugfs features in DC
    - LVDS support in DC
    - Implement wave kill for gfx/compute (light weight reset for shaders)
    - Use AGP aperture to avoid gart mappings when possible
    - GPUVM performance improvements
    - Bulk moves for more efficient GPUVM LRU handling
    - Merge amdgpu and amdkfd into one module
    - Enable gfxoff and stutter mode on Raven
    - Misc cleanups
    
    Scheduler:
    - Load balancing support
    - Bug fixes
    
    ttm:
    - Bulk move functionality
    - Bug fixes
    
    radeon:
    - Misc cleanups
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    
    From: Alex Deucher <alexdeucher@gmail.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20180920150438.12693-1-alexander.deucher@amd.com

commit 77a2faa55c1a497f4e7e89eabd11830f0e3cb3dd
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Sep 14 16:06:31 2018 +0200

    drm/amdgpu: fix up GDS/GWS/OA shifting
    
    That only worked by pure coincident. Completely remove the shifting and
    always apply correct PAGE_SHIFT.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index d762d78e5102..8836186eb5ef 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -721,16 +721,16 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		e->bo_va = amdgpu_vm_bo_find(vm, ttm_to_amdgpu_bo(e->tv.bo));
 
 	if (gds) {
-		p->job->gds_base = amdgpu_bo_gpu_offset(gds);
-		p->job->gds_size = amdgpu_bo_size(gds);
+		p->job->gds_base = amdgpu_bo_gpu_offset(gds) >> PAGE_SHIFT;
+		p->job->gds_size = amdgpu_bo_size(gds) >> PAGE_SHIFT;
 	}
 	if (gws) {
-		p->job->gws_base = amdgpu_bo_gpu_offset(gws);
-		p->job->gws_size = amdgpu_bo_size(gws);
+		p->job->gws_base = amdgpu_bo_gpu_offset(gws) >> PAGE_SHIFT;
+		p->job->gws_size = amdgpu_bo_size(gws) >> PAGE_SHIFT;
 	}
 	if (oa) {
-		p->job->oa_base = amdgpu_bo_gpu_offset(oa);
-		p->job->oa_size = amdgpu_bo_size(oa);
+		p->job->oa_base = amdgpu_bo_gpu_offset(oa) >> PAGE_SHIFT;
+		p->job->oa_size = amdgpu_bo_size(oa) >> PAGE_SHIFT;
 	}
 
 	if (!r && p->uf_entry.tv.bo) {

commit 2dc7bad71cd310dc94d1c9907909324dd2b0618f
Merge: b1c1566822ab 169cc4c7a14e
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri Sep 14 09:43:06 2018 +1000

    Merge tag 'drm-misc-next-2018-09-13' of git://anongit.freedesktop.org/drm/drm-misc into drm-next
    
    drm-misc-next for 4.20:
    
    UAPI Changes:
    - Add host endian variants for the most common formats (Gerd)
    - Fail ADDFB2 for big-endian drivers that don't advertise BE quirk (Gerd)
    - clear smem_start in fbdev for drm drivers to avoid leaking fb addr (Daniel)
    
    Cross-subsystem Changes:
    
    Core Changes:
    - fix drm_mode_addfb() on big endian machines (Gerd)
    - add timeline point to syncobj find+replace (Chunming)
    - more drmP.h removal effort (Daniel)
    - split uapi portions of drm_atomic.c into drm_atomic_uapi.c (Daniel)
    
    Driver Changes:
    - bochs: Convert open-coded portions to use helpers (Peter)
    - vkms: Add cursor support (Haneen)
    - udmabuf: Lots of fixups (mostly cosmetic afaict) (Gerd)
    - qxl: Convert to use fbdev helper (Peter)
    
    Cc: Gerd Hoffmann <kraxel@redhat.com>
    Cc: Chunming Zhou <david1.zhou@amd.com>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Cc: Peter Wu <peter@lekensteyn.nl>
    Cc: Haneen Mohammed <hamohammed.sa@gmail.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    
    From: Sean Paul <sean@poorly.run>
    Link: https://patchwork.freedesktop.org/patch/msgid/20180913130254.GA156437@art_vandelay

commit e83dfe4d869358549bb259ab581ae4f0450c6580
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Sep 10 16:07:57 2018 +0200

    drm/amdgpu: remove amdgpu_bo_list_entry.robj (v2)
    
    We can get that just by casting tv.bo.
    
    v2: squash in kfd fix (Alex)
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 1081fd00b059..d762d78e5102 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -39,6 +39,7 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 				      uint32_t *offset)
 {
 	struct drm_gem_object *gobj;
+	struct amdgpu_bo *bo;
 	unsigned long size;
 	int r;
 
@@ -46,21 +47,21 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 	if (gobj == NULL)
 		return -EINVAL;
 
-	p->uf_entry.robj = amdgpu_bo_ref(gem_to_amdgpu_bo(gobj));
+	bo = amdgpu_bo_ref(gem_to_amdgpu_bo(gobj));
 	p->uf_entry.priority = 0;
-	p->uf_entry.tv.bo = &p->uf_entry.robj->tbo;
+	p->uf_entry.tv.bo = &bo->tbo;
 	p->uf_entry.tv.shared = true;
 	p->uf_entry.user_pages = NULL;
 
 	drm_gem_object_put_unlocked(gobj);
 
-	size = amdgpu_bo_size(p->uf_entry.robj);
+	size = amdgpu_bo_size(bo);
 	if (size != PAGE_SIZE || (data->offset + 8) > size) {
 		r = -EINVAL;
 		goto error_unref;
 	}
 
-	if (amdgpu_ttm_tt_get_usermm(p->uf_entry.robj->tbo.ttm)) {
+	if (amdgpu_ttm_tt_get_usermm(bo->tbo.ttm)) {
 		r = -EINVAL;
 		goto error_unref;
 	}
@@ -70,7 +71,7 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 	return 0;
 
 error_unref:
-	amdgpu_bo_unref(&p->uf_entry.robj);
+	amdgpu_bo_unref(&bo);
 	return r;
 }
 
@@ -229,7 +230,7 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, union drm_amdgpu_cs
 		goto free_all_kdata;
 	}
 
-	if (p->uf_entry.robj)
+	if (p->uf_entry.tv.bo)
 		p->job->uf_addr = uf_offset;
 	kfree(chunk_array);
 
@@ -458,13 +459,13 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 	     p->evictable = list_prev_entry(p->evictable, tv.head)) {
 
 		struct amdgpu_bo_list_entry *candidate = p->evictable;
-		struct amdgpu_bo *bo = candidate->robj;
+		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(candidate->tv.bo);
 		struct amdgpu_device *adev = amdgpu_ttm_adev(bo->tbo.bdev);
 		bool update_bytes_moved_vis;
 		uint32_t other;
 
 		/* If we reached our current BO we can forget it */
-		if (candidate->robj == validated)
+		if (bo == validated)
 			break;
 
 		/* We can't move pinned BOs here */
@@ -529,7 +530,7 @@ static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 	int r;
 
 	list_for_each_entry(lobj, validated, tv.head) {
-		struct amdgpu_bo *bo = lobj->robj;
+		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(lobj->tv.bo);
 		bool binding_userptr = false;
 		struct mm_struct *usermm;
 
@@ -604,7 +605,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	INIT_LIST_HEAD(&duplicates);
 	amdgpu_vm_get_pd_bo(&fpriv->vm, &p->validated, &p->vm_pd);
 
-	if (p->uf_entry.robj && !p->uf_entry.robj->parent)
+	if (p->uf_entry.tv.bo && !ttm_to_amdgpu_bo(p->uf_entry.tv.bo)->parent)
 		list_add(&p->uf_entry.tv.head, &p->validated);
 
 	while (1) {
@@ -620,7 +621,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 
 		INIT_LIST_HEAD(&need_pages);
 		amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
-			struct amdgpu_bo *bo = e->robj;
+			struct amdgpu_bo *bo = ttm_to_amdgpu_bo(e->tv.bo);
 
 			if (amdgpu_ttm_tt_userptr_invalidated(bo->tbo.ttm,
 				 &e->user_invalidated) && e->user_pages) {
@@ -639,7 +640,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 				list_del(&e->tv.head);
 				list_add(&e->tv.head, &need_pages);
 
-				amdgpu_bo_unreserve(e->robj);
+				amdgpu_bo_unreserve(bo);
 			}
 		}
 
@@ -658,7 +659,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 
 		/* Fill the page arrays for all userptrs. */
 		list_for_each_entry(e, &need_pages, tv.head) {
-			struct ttm_tt *ttm = e->robj->tbo.ttm;
+			struct ttm_tt *ttm = e->tv.bo->ttm;
 
 			e->user_pages = kvmalloc_array(ttm->num_pages,
 							 sizeof(struct page*),
@@ -717,7 +718,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	oa = p->bo_list->oa_obj;
 
 	amdgpu_bo_list_for_each_entry(e, p->bo_list)
-		e->bo_va = amdgpu_vm_bo_find(vm, e->robj);
+		e->bo_va = amdgpu_vm_bo_find(vm, ttm_to_amdgpu_bo(e->tv.bo));
 
 	if (gds) {
 		p->job->gds_base = amdgpu_bo_gpu_offset(gds);
@@ -732,8 +733,8 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		p->job->oa_size = amdgpu_bo_size(oa);
 	}
 
-	if (!r && p->uf_entry.robj) {
-		struct amdgpu_bo *uf = p->uf_entry.robj;
+	if (!r && p->uf_entry.tv.bo) {
+		struct amdgpu_bo *uf = ttm_to_amdgpu_bo(p->uf_entry.tv.bo);
 
 		r = amdgpu_ttm_alloc_gart(&uf->tbo);
 		p->job->uf_addr += amdgpu_bo_gpu_offset(uf);
@@ -749,8 +750,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		if (!e->user_pages)
 			continue;
 
-		release_pages(e->user_pages,
-			      e->robj->tbo.ttm->num_pages);
+		release_pages(e->user_pages, e->tv.bo->ttm->num_pages);
 		kvfree(e->user_pages);
 	}
 
@@ -763,9 +763,11 @@ static int amdgpu_cs_sync_rings(struct amdgpu_cs_parser *p)
 	int r;
 
 	list_for_each_entry(e, &p->validated, tv.head) {
-		struct reservation_object *resv = e->robj->tbo.resv;
+		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(e->tv.bo);
+		struct reservation_object *resv = bo->tbo.resv;
+
 		r = amdgpu_sync_resv(p->adev, &p->job->sync, resv, p->filp,
-				     amdgpu_bo_explicit_sync(e->robj));
+				     amdgpu_bo_explicit_sync(bo));
 
 		if (r)
 			return r;
@@ -808,7 +810,11 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error,
 	kfree(parser->chunks);
 	if (parser->job)
 		amdgpu_job_free(parser->job);
-	amdgpu_bo_unref(&parser->uf_entry.robj);
+	if (parser->uf_entry.tv.bo) {
+		struct amdgpu_bo *uf = ttm_to_amdgpu_bo(parser->uf_entry.tv.bo);
+
+		amdgpu_bo_unref(&uf);
+	}
 }
 
 static int amdgpu_cs_vm_handling(struct amdgpu_cs_parser *p)
@@ -919,7 +925,7 @@ static int amdgpu_cs_vm_handling(struct amdgpu_cs_parser *p)
 		struct dma_fence *f;
 
 		/* ignore duplicates */
-		bo = e->robj;
+		bo = ttm_to_amdgpu_bo(e->tv.bo);
 		if (!bo)
 			continue;
 
@@ -958,11 +964,13 @@ static int amdgpu_cs_vm_handling(struct amdgpu_cs_parser *p)
 	if (amdgpu_vm_debug) {
 		/* Invalidate all BOs to test for userspace bugs */
 		amdgpu_bo_list_for_each_entry(e, p->bo_list) {
+			struct amdgpu_bo *bo = ttm_to_amdgpu_bo(e->tv.bo);
+
 			/* ignore duplicates */
-			if (!e->robj)
+			if (!bo)
 				continue;
 
-			amdgpu_vm_bo_invalidate(adev, e->robj, false);
+			amdgpu_vm_bo_invalidate(adev, bo, false);
 		}
 	}
 
@@ -1211,7 +1219,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	/* No memory allocation is allowed while holding the mn lock */
 	amdgpu_mn_lock(p->mn);
 	amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
-		struct amdgpu_bo *bo = e->robj;
+		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(e->tv.bo);
 
 		if (amdgpu_ttm_tt_userptr_needs_pages(bo->tbo.ttm)) {
 			r = -ERESTARTSYS;

commit 7e7bf8de432db3de912050856e641458de72a7b1
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Tue Sep 11 17:22:40 2018 +0800

    drm/amdgpu: move cs dependencies front a bit
    
    cs dependencies handling doesn't need in vm resv
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index c5cc648a1b4e..1081fd00b059 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1285,6 +1285,12 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	if (r)
 		goto out;
 
+	r = amdgpu_cs_dependencies(adev, &parser);
+	if (r) {
+		DRM_ERROR("Failed in the dependencies handling %d!\n", r);
+		goto out;
+	}
+
 	r = amdgpu_cs_parser_bos(&parser, data);
 	if (r) {
 		if (r == -ENOMEM)
@@ -1296,12 +1302,6 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 	reserved_buffers = true;
 
-	r = amdgpu_cs_dependencies(adev, &parser);
-	if (r) {
-		DRM_ERROR("Failed in the dependencies handling %d!\n", r);
-		goto out;
-	}
-
 	for (i = 0; i < parser.job->num_ibs; i++)
 		trace_amdgpu_cs(&parser, i);
 

commit 0165de983272d1fae0809ed9db47c46a412279bc
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Sep 10 15:52:55 2018 +0200

    drm/amdgpu: fix error handling in amdgpu_cs_user_fence_chunk
    
    Slowly leaking memory one page at a time :)
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 1b5a0a73d770..b31d121a876b 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -39,6 +39,7 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 {
 	struct drm_gem_object *gobj;
 	unsigned long size;
+	int r;
 
 	gobj = drm_gem_object_lookup(p->filp, data->handle);
 	if (gobj == NULL)
@@ -50,20 +51,26 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 	p->uf_entry.tv.shared = true;
 	p->uf_entry.user_pages = NULL;
 
-	size = amdgpu_bo_size(p->uf_entry.robj);
-	if (size != PAGE_SIZE || (data->offset + 8) > size)
-		return -EINVAL;
-
-	*offset = data->offset;
-
 	drm_gem_object_put_unlocked(gobj);
 
+	size = amdgpu_bo_size(p->uf_entry.robj);
+	if (size != PAGE_SIZE || (data->offset + 8) > size) {
+		r = -EINVAL;
+		goto error_unref;
+	}
+
 	if (amdgpu_ttm_tt_get_usermm(p->uf_entry.robj->tbo.ttm)) {
-		amdgpu_bo_unref(&p->uf_entry.robj);
-		return -EINVAL;
+		r = -EINVAL;
+		goto error_unref;
 	}
 
+	*offset = data->offset;
+
 	return 0;
+
+error_unref:
+	amdgpu_bo_unref(&p->uf_entry.robj);
+	return r;
 }
 
 static int amdgpu_cs_bo_handles_chunk(struct amdgpu_cs_parser *p,

commit 7893499e3022542f6522847837487019ea83f142
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Sep 10 15:52:55 2018 +0200

    drm/amdgpu: fix error handling in amdgpu_cs_user_fence_chunk
    
    Slowly leaking memory one page at a time :)
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 135d9d8c9506..c5cc648a1b4e 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -40,6 +40,7 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 {
 	struct drm_gem_object *gobj;
 	unsigned long size;
+	int r;
 
 	gobj = drm_gem_object_lookup(p->filp, data->handle);
 	if (gobj == NULL)
@@ -51,20 +52,26 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 	p->uf_entry.tv.shared = true;
 	p->uf_entry.user_pages = NULL;
 
-	size = amdgpu_bo_size(p->uf_entry.robj);
-	if (size != PAGE_SIZE || (data->offset + 8) > size)
-		return -EINVAL;
-
-	*offset = data->offset;
-
 	drm_gem_object_put_unlocked(gobj);
 
+	size = amdgpu_bo_size(p->uf_entry.robj);
+	if (size != PAGE_SIZE || (data->offset + 8) > size) {
+		r = -EINVAL;
+		goto error_unref;
+	}
+
 	if (amdgpu_ttm_tt_get_usermm(p->uf_entry.robj->tbo.ttm)) {
-		amdgpu_bo_unref(&p->uf_entry.robj);
-		return -EINVAL;
+		r = -EINVAL;
+		goto error_unref;
 	}
 
+	*offset = data->offset;
+
 	return 0;
+
+error_unref:
+	amdgpu_bo_unref(&p->uf_entry.robj);
+	return r;
 }
 
 static int amdgpu_cs_bo_handles_chunk(struct amdgpu_cs_parser *p,

commit b463d4e53ca9bdbf227e19b477fbfcdedaa14c84
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Sep 3 10:51:51 2018 +0200

    drm/amdgpu: fix amdgpu_mn_unlock() in the CS error path
    
    Avoid unlocking a lock we never locked.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index b6e9df11115d..1b5a0a73d770 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1262,10 +1262,10 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 error_abort:
 	dma_fence_put(&job->base.s_fence->finished);
 	job->base.s_fence = NULL;
+	amdgpu_mn_unlock(p->mn);
 
 error_unlock:
 	amdgpu_job_free(job);
-	amdgpu_mn_unlock(p->mn);
 	return r;
 }
 

commit ad9a5b78f585e9a9bd5ad06dfaf1269659a99f43
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Aug 27 18:22:31 2018 +0200

    drm/amdgpu: correctly sign extend 48bit addresses v3
    
    Correct sign extend the GMC addresses to 48bit.
    
    v2: sign extending turned out easier than thought.
    v3: clean up the defines and move them into amdgpu_gmc.h as well
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 04a2733b5ccc..135d9d8c9506 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -835,7 +835,7 @@ static int amdgpu_cs_vm_handling(struct amdgpu_cs_parser *p)
 			if (chunk->chunk_id != AMDGPU_CHUNK_ID_IB)
 				continue;
 
-			va_start = chunk_ib->va_start & AMDGPU_VA_HOLE_MASK;
+			va_start = chunk_ib->va_start & AMDGPU_GMC_HOLE_MASK;
 			r = amdgpu_cs_find_mapping(p, va_start, &aobj, &m);
 			if (r) {
 				DRM_ERROR("IB va_start is invalid\n");

commit 0a53b69cce846b42adf03ccee49ae0a37a731c20
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Sep 3 10:51:51 2018 +0200

    drm/amdgpu: fix amdgpu_mn_unlock() in the CS error path
    
    Avoid unlocking a lock we never locked.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 349dcc37ee64..04a2733b5ccc 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1247,10 +1247,10 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 error_abort:
 	dma_fence_put(&job->base.s_fence->finished);
 	job->base.s_fence = NULL;
+	amdgpu_mn_unlock(p->mn);
 
 error_unlock:
 	amdgpu_job_free(job);
-	amdgpu_mn_unlock(p->mn);
 	return r;
 }
 

commit 9a09a42369a4a37a959c051d8e1a1f948c1529a4
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Thu Aug 30 14:48:30 2018 +0800

    drm: expand replace_fence to support timeline point v2
    
    we can place a fence to a timeline point after expanded.
    v2: change func parameter order
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Link: https://patchwork.freedesktop.org/patch/246543/

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 5db7b1b460da..d68b73ff92d2 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1191,7 +1191,7 @@ static void amdgpu_cs_post_dependencies(struct amdgpu_cs_parser *p)
 	int i;
 
 	for (i = 0; i < p->num_post_dep_syncobjs; ++i)
-		drm_syncobj_replace_fence(p->post_dep_syncobjs[i], p->fence);
+		drm_syncobj_replace_fence(p->post_dep_syncobjs[i], 0, p->fence);
 }
 
 static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,

commit 0a6730ea27b68c7ac4171c29a816c29d26a9637a
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Thu Aug 30 14:48:29 2018 +0800

    drm: expand drm_syncobj_find_fence to support timeline point v2
    
    we can fetch timeline point fence after expanded.
    v2: The parameter fence is the result of the function and should come last.
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Link: https://patchwork.freedesktop.org/patch/246541/

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 502b94fb116a..5db7b1b460da 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1102,7 +1102,7 @@ static int amdgpu_syncobj_lookup_and_add_to_sync(struct amdgpu_cs_parser *p,
 {
 	int r;
 	struct dma_fence *fence;
-	r = drm_syncobj_find_fence(p->filp, handle, &fence);
+	r = drm_syncobj_find_fence(p->filp, handle, 0, &fence);
 	if (r)
 		return r;
 

commit b995795bf09b6bb7847a2a9fc8e6b5b4ab0ce20c
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Aug 30 10:04:53 2018 +0200

    drm/amdgpu: fix "use bulk moves for efficient VM LRU handling" v2
    
    First step to fix the LRU corruption, we accidentially tried to move things
    on the LRU after dropping the lock.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Tested-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index dd734970e167..349dcc37ee64 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1237,6 +1237,8 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	ring = to_amdgpu_ring(entity->rq->sched);
 	amdgpu_ring_priority_get(ring, priority);
 
+	amdgpu_vm_move_to_lru_tail(p->adev, &fpriv->vm);
+
 	ttm_eu_fence_buffer_objects(&p->ticket, &p->validated, p->fence);
 	amdgpu_mn_unlock(p->mn);
 
@@ -1258,7 +1260,6 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	union drm_amdgpu_cs *cs = data;
 	struct amdgpu_cs_parser parser = {};
 	bool reserved_buffers = false;
-	struct amdgpu_fpriv *fpriv;
 	int i, r;
 
 	if (!adev->accel_working)
@@ -1303,8 +1304,6 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 	r = amdgpu_cs_submit(&parser, cs);
 
-	fpriv = filp->driver_priv;
-	amdgpu_vm_move_to_lru_tail(adev, &fpriv->vm);
 out:
 	amdgpu_cs_parser_fini(&parser, r, reserved_buffers);
 	return r;

commit 4f9ea1d0d1ed914092d9e03d87d80fa7e63ecc8f
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Aug 24 14:48:02 2018 +0200

    drm/amdgpu: fix holding mn_lock while allocating memory
    
    We can't hold the mn_lock while allocating memory.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index adc6a43e2333..dd734970e167 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1194,26 +1194,24 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 
 	int r;
 
+	job = p->job;
+	p->job = NULL;
+
+	r = drm_sched_job_init(&job->base, entity, p->filp);
+	if (r)
+		goto error_unlock;
+
+	/* No memory allocation is allowed while holding the mn lock */
 	amdgpu_mn_lock(p->mn);
 	amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
 		struct amdgpu_bo *bo = e->robj;
 
 		if (amdgpu_ttm_tt_userptr_needs_pages(bo->tbo.ttm)) {
-			amdgpu_mn_unlock(p->mn);
-			return -ERESTARTSYS;
+			r = -ERESTARTSYS;
+			goto error_abort;
 		}
 	}
 
-	job = p->job;
-	p->job = NULL;
-
-	r = drm_sched_job_init(&job->base, entity, p->filp);
-	if (r) {
-		amdgpu_job_free(job);
-		amdgpu_mn_unlock(p->mn);
-		return r;
-	}
-
 	job->owner = p->filp;
 	p->fence = dma_fence_get(&job->base.s_fence->finished);
 
@@ -1243,6 +1241,15 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	amdgpu_mn_unlock(p->mn);
 
 	return 0;
+
+error_abort:
+	dma_fence_put(&job->base.s_fence->finished);
+	job->base.s_fence = NULL;
+
+error_unlock:
+	amdgpu_job_free(job);
+	amdgpu_mn_unlock(p->mn);
+	return r;
 }
 
 int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)

commit 85eff20020a656b2d13b33dc4681523508fee037
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Aug 24 14:23:33 2018 +0200

    drm/amdgpu: amdgpu_ctx_add_fence can't fail
    
    No more waiting for a fence done here.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index b62bbe71662d..adc6a43e2333 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1217,15 +1217,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	job->owner = p->filp;
 	p->fence = dma_fence_get(&job->base.s_fence->finished);
 
-	r = amdgpu_ctx_add_fence(p->ctx, entity, p->fence, &seq);
-	if (r) {
-		dma_fence_put(p->fence);
-		dma_fence_put(&job->base.s_fence->finished);
-		amdgpu_job_free(job);
-		amdgpu_mn_unlock(p->mn);
-		return r;
-	}
-
+	amdgpu_ctx_add_fence(p->ctx, entity, p->fence, &seq);
 	amdgpu_cs_post_dependencies(p);
 
 	if ((job->preamble_status & AMDGPU_PREAMBLE_IB_PRESENT) &&

commit 4a2de54dc1d7668fa364d8483420ba64b120963b
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Aug 24 14:48:02 2018 +0200

    drm/amdgpu: fix holding mn_lock while allocating memory
    
    We can't hold the mn_lock while allocating memory.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 09703c87d676..b6e9df11115d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1203,26 +1203,24 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 
 	int r;
 
+	job = p->job;
+	p->job = NULL;
+
+	r = drm_sched_job_init(&job->base, entity, p->filp);
+	if (r)
+		goto error_unlock;
+
+	/* No memory allocation is allowed while holding the mn lock */
 	amdgpu_mn_lock(p->mn);
 	amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
 		struct amdgpu_bo *bo = e->robj;
 
 		if (amdgpu_ttm_tt_userptr_needs_pages(bo->tbo.ttm)) {
-			amdgpu_mn_unlock(p->mn);
-			return -ERESTARTSYS;
+			r = -ERESTARTSYS;
+			goto error_abort;
 		}
 	}
 
-	job = p->job;
-	p->job = NULL;
-
-	r = drm_sched_job_init(&job->base, entity, p->filp);
-	if (r) {
-		amdgpu_job_free(job);
-		amdgpu_mn_unlock(p->mn);
-		return r;
-	}
-
 	job->owner = p->filp;
 	p->fence = dma_fence_get(&job->base.s_fence->finished);
 
@@ -1260,6 +1258,15 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	amdgpu_mn_unlock(p->mn);
 
 	return 0;
+
+error_abort:
+	dma_fence_put(&job->base.s_fence->finished);
+	job->base.s_fence = NULL;
+
+error_unlock:
+	amdgpu_job_free(job);
+	amdgpu_mn_unlock(p->mn);
+	return r;
 }
 
 int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)

commit f921661bd4a112f80d57bbfb3e792da63787f4b0
Author: Huang Rui <ray.huang@amd.com>
Date:   Mon Aug 6 10:57:08 2018 +0800

    drm/amdgpu: use bulk moves for efficient VM LRU handling (v6)
    
    I continue to work for bulk moving that based on the proposal by Christian.
    
    Background:
    amdgpu driver will move all PD/PT and PerVM BOs into idle list. Then move all of
    them on the end of LRU list one by one. Thus, that cause so many BOs moved to
    the end of the LRU, and impact performance seriously.
    
    Then Christian provided a workaround to not move PD/PT BOs on LRU with below
    patch:
    Commit 0bbf32026cf5ba41e9922b30e26e1bed1ecd38ae ("drm/amdgpu: band aid
    validating VM PTs")
    
    However, the final solution should bulk move all PD/PT and PerVM BOs on the LRU
    instead of one by one.
    
    Whenever amdgpu_vm_validate_pt_bos() is called and we have BOs which need to be
    validated we move all BOs together to the end of the LRU without dropping the
    lock for the LRU.
    
    While doing so we note the beginning and end of this block in the LRU list.
    
    Now when amdgpu_vm_validate_pt_bos() is called and we don't have anything to do,
    we don't move every BO one by one, but instead cut the LRU list into pieces so
    that we bulk move everything to the end in just one operation.
    
    Test data:
    +--------------+-----------------+-----------+---------------------------------------+
    |              |The Talos        |Clpeak(OCL)|BusSpeedReadback(OCL)                  |
    |              |Principle(Vulkan)|           |                                       |
    +------------------------------------------------------------------------------------+
    |              |                 |           |0.319 ms(1k) 0.314 ms(2K) 0.308 ms(4K) |
    | Original     |  147.7 FPS      |  76.86 us |0.307 ms(8K) 0.310 ms(16K)             |
    +------------------------------------------------------------------------------------+
    | Orignial + WA|                 |           |0.254 ms(1K) 0.241 ms(2K)              |
    |(don't move   |  162.1 FPS      |  42.15 us |0.230 ms(4K) 0.223 ms(8K) 0.204 ms(16K)|
    |PT BOs on LRU)|                 |           |                                       |
    +------------------------------------------------------------------------------------+
    | Bulk move    |  163.1 FPS      |  40.52 us |0.244 ms(1K) 0.252 ms(2K) 0.213 ms(4K) |
    |              |                 |           |0.214 ms(8K) 0.225 ms(16K)             |
    +--------------+-----------------+-----------+---------------------------------------+
    
    After test them with above three benchmarks include vulkan and opencl. We can
    see the visible improvement than original, and even better than original with
    workaround.
    
    v2: move all BOs include idle, relocated, and moved list to the end of LRU and
    put them together.
    v3: remove unused parameter and use list_for_each_entry instead of the one with
    save entry.
    v4: move the amdgpu_vm_move_to_lru_tail after command submission, at that time,
    all bo will be back on idle list.
    v5: remove amdgpu_vm_move_to_lru_tail_by_list(), use bulk_moveable instread of
    validated, and move ttm_bo_bulk_move_lru_tail() also into
    amdgpu_vm_move_to_lru_tail().
    v6: clean up and fix return value.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Tested-by: Mike Lothian <mike@fireburn.co.uk>
    Tested-by: Dieter Nützel <Dieter@nuetzel-hh.de>
    Acked-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index fd3902983195..b62bbe71662d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1259,6 +1259,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	union drm_amdgpu_cs *cs = data;
 	struct amdgpu_cs_parser parser = {};
 	bool reserved_buffers = false;
+	struct amdgpu_fpriv *fpriv;
 	int i, r;
 
 	if (!adev->accel_working)
@@ -1303,6 +1304,8 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 	r = amdgpu_cs_submit(&parser, cs);
 
+	fpriv = filp->driver_priv;
+	amdgpu_vm_move_to_lru_tail(adev, &fpriv->vm);
 out:
 	amdgpu_cs_parser_fini(&parser, r, reserved_buffers);
 	return r;

commit 11c3a249ff7a1c710011bd06a451956f2a40c30c
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Aug 22 12:22:14 2018 +0200

    drm/amdgpu: add amdgpu_gmc_pd_addr helper
    
    Add a helper to get the root PD address and remove the workarounds from
    the GMC9 code for that.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 5b70a30967ec..fd3902983195 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -946,7 +946,7 @@ static int amdgpu_cs_vm_handling(struct amdgpu_cs_parser *p)
 	if (r)
 		return r;
 
-	p->job->vm_pd_addr = amdgpu_bo_gpu_offset(vm->root.base.bo);
+	p->job->vm_pd_addr = amdgpu_gmc_pd_addr(vm->root.base.bo);
 
 	if (amdgpu_vm_debug) {
 		/* Invalidate all BOs to test for userspace bugs */

commit 9a02ece43ee49efdfad19a3ca90c02d20f491031
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Aug 17 15:07:13 2018 +0200

    drm/amdgpu: cleanup VM handling in the CS a bit
    
    Add a helper function for getting the root PD addr and cleanup join the
    two VM related functions and cleanup the function name.
    
    No functional change.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 313ac971eaaf..5b70a30967ec 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -804,8 +804,9 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error,
 	amdgpu_bo_unref(&parser->uf_entry.robj);
 }
 
-static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
+static int amdgpu_cs_vm_handling(struct amdgpu_cs_parser *p)
 {
+	struct amdgpu_ring *ring = to_amdgpu_ring(p->entity->rq->sched);
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_device *adev = p->adev;
 	struct amdgpu_vm *vm = &fpriv->vm;
@@ -814,6 +815,71 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 	struct amdgpu_bo *bo;
 	int r;
 
+	/* Only for UVD/VCE VM emulation */
+	if (ring->funcs->parse_cs || ring->funcs->patch_cs_in_place) {
+		unsigned i, j;
+
+		for (i = 0, j = 0; i < p->nchunks && j < p->job->num_ibs; i++) {
+			struct drm_amdgpu_cs_chunk_ib *chunk_ib;
+			struct amdgpu_bo_va_mapping *m;
+			struct amdgpu_bo *aobj = NULL;
+			struct amdgpu_cs_chunk *chunk;
+			uint64_t offset, va_start;
+			struct amdgpu_ib *ib;
+			uint8_t *kptr;
+
+			chunk = &p->chunks[i];
+			ib = &p->job->ibs[j];
+			chunk_ib = chunk->kdata;
+
+			if (chunk->chunk_id != AMDGPU_CHUNK_ID_IB)
+				continue;
+
+			va_start = chunk_ib->va_start & AMDGPU_VA_HOLE_MASK;
+			r = amdgpu_cs_find_mapping(p, va_start, &aobj, &m);
+			if (r) {
+				DRM_ERROR("IB va_start is invalid\n");
+				return r;
+			}
+
+			if ((va_start + chunk_ib->ib_bytes) >
+			    (m->last + 1) * AMDGPU_GPU_PAGE_SIZE) {
+				DRM_ERROR("IB va_start+ib_bytes is invalid\n");
+				return -EINVAL;
+			}
+
+			/* the IB should be reserved at this point */
+			r = amdgpu_bo_kmap(aobj, (void **)&kptr);
+			if (r) {
+				return r;
+			}
+
+			offset = m->start * AMDGPU_GPU_PAGE_SIZE;
+			kptr += va_start - offset;
+
+			if (ring->funcs->parse_cs) {
+				memcpy(ib->ptr, kptr, chunk_ib->ib_bytes);
+				amdgpu_bo_kunmap(aobj);
+
+				r = amdgpu_ring_parse_cs(ring, p, j);
+				if (r)
+					return r;
+			} else {
+				ib->ptr = (uint32_t *)kptr;
+				r = amdgpu_ring_patch_cs_in_place(ring, p, j);
+				amdgpu_bo_kunmap(aobj);
+				if (r)
+					return r;
+			}
+
+			j++;
+		}
+	}
+
+	if (!p->job->vm)
+		return amdgpu_cs_sync_rings(p);
+
+
 	r = amdgpu_vm_clear_freed(adev, vm, NULL);
 	if (r)
 		return r;
@@ -876,6 +942,12 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 	if (r)
 		return r;
 
+	r = reservation_object_reserve_shared(vm->root.base.bo->tbo.resv);
+	if (r)
+		return r;
+
+	p->job->vm_pd_addr = amdgpu_bo_gpu_offset(vm->root.base.bo);
+
 	if (amdgpu_vm_debug) {
 		/* Invalidate all BOs to test for userspace bugs */
 		amdgpu_bo_list_for_each_entry(e, p->bo_list) {
@@ -887,90 +959,6 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 		}
 	}
 
-	return r;
-}
-
-static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
-				 struct amdgpu_cs_parser *p)
-{
-	struct amdgpu_ring *ring = to_amdgpu_ring(p->entity->rq->sched);
-	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
-	struct amdgpu_vm *vm = &fpriv->vm;
-	int r;
-
-	/* Only for UVD/VCE VM emulation */
-	if (ring->funcs->parse_cs || ring->funcs->patch_cs_in_place) {
-		unsigned i, j;
-
-		for (i = 0, j = 0; i < p->nchunks && j < p->job->num_ibs; i++) {
-			struct drm_amdgpu_cs_chunk_ib *chunk_ib;
-			struct amdgpu_bo_va_mapping *m;
-			struct amdgpu_bo *aobj = NULL;
-			struct amdgpu_cs_chunk *chunk;
-			uint64_t offset, va_start;
-			struct amdgpu_ib *ib;
-			uint8_t *kptr;
-
-			chunk = &p->chunks[i];
-			ib = &p->job->ibs[j];
-			chunk_ib = chunk->kdata;
-
-			if (chunk->chunk_id != AMDGPU_CHUNK_ID_IB)
-				continue;
-
-			va_start = chunk_ib->va_start & AMDGPU_VA_HOLE_MASK;
-			r = amdgpu_cs_find_mapping(p, va_start, &aobj, &m);
-			if (r) {
-				DRM_ERROR("IB va_start is invalid\n");
-				return r;
-			}
-
-			if ((va_start + chunk_ib->ib_bytes) >
-			    (m->last + 1) * AMDGPU_GPU_PAGE_SIZE) {
-				DRM_ERROR("IB va_start+ib_bytes is invalid\n");
-				return -EINVAL;
-			}
-
-			/* the IB should be reserved at this point */
-			r = amdgpu_bo_kmap(aobj, (void **)&kptr);
-			if (r) {
-				return r;
-			}
-
-			offset = m->start * AMDGPU_GPU_PAGE_SIZE;
-			kptr += va_start - offset;
-
-			if (ring->funcs->parse_cs) {
-				memcpy(ib->ptr, kptr, chunk_ib->ib_bytes);
-				amdgpu_bo_kunmap(aobj);
-
-				r = amdgpu_ring_parse_cs(ring, p, j);
-				if (r)
-					return r;
-			} else {
-				ib->ptr = (uint32_t *)kptr;
-				r = amdgpu_ring_patch_cs_in_place(ring, p, j);
-				amdgpu_bo_kunmap(aobj);
-				if (r)
-					return r;
-			}
-
-			j++;
-		}
-	}
-
-	if (p->job->vm) {
-		p->job->vm_pd_addr = amdgpu_bo_gpu_offset(vm->root.base.bo);
-
-		r = amdgpu_bo_vm_update_pte(p);
-		if (r)
-			return r;
-
-		r = reservation_object_reserve_shared(vm->root.base.bo->tbo.resv);
-		if (r)
-			return r;
-	}
-
 	return amdgpu_cs_sync_rings(p);
 }
 
@@ -1309,7 +1297,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	for (i = 0; i < parser.job->num_ibs; i++)
 		trace_amdgpu_cs(&parser, i);
 
-	r = amdgpu_cs_ib_vm_chunk(adev, &parser);
+	r = amdgpu_cs_vm_handling(&parser);
 	if (r)
 		goto out;
 

commit 0d346a14c634120046d194377e2cb5b387a6c1c6
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Jul 19 14:22:25 2018 +0200

    drm/amdgpu: use entity instead of ring for CS
    
    Further demangle ring from entity handling.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 55667ab4fbf5..313ac971eaaf 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -893,13 +893,13 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 				 struct amdgpu_cs_parser *p)
 {
+	struct amdgpu_ring *ring = to_amdgpu_ring(p->entity->rq->sched);
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_vm *vm = &fpriv->vm;
-	struct amdgpu_ring *ring = p->ring;
 	int r;
 
 	/* Only for UVD/VCE VM emulation */
-	if (p->ring->funcs->parse_cs || p->ring->funcs->patch_cs_in_place) {
+	if (ring->funcs->parse_cs || ring->funcs->patch_cs_in_place) {
 		unsigned i, j;
 
 		for (i = 0, j = 0; i < p->nchunks && j < p->job->num_ibs; i++) {
@@ -940,7 +940,7 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 			offset = m->start * AMDGPU_GPU_PAGE_SIZE;
 			kptr += va_start - offset;
 
-			if (p->ring->funcs->parse_cs) {
+			if (ring->funcs->parse_cs) {
 				memcpy(ib->ptr, kptr, chunk_ib->ib_bytes);
 				amdgpu_bo_kunmap(aobj);
 
@@ -979,14 +979,15 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 {
 	struct amdgpu_fpriv *fpriv = parser->filp->driver_priv;
 	struct amdgpu_vm *vm = &fpriv->vm;
-	int i, j;
 	int r, ce_preempt = 0, de_preempt = 0;
+	struct amdgpu_ring *ring;
+	int i, j;
 
 	for (i = 0, j = 0; i < parser->nchunks && j < parser->job->num_ibs; i++) {
 		struct amdgpu_cs_chunk *chunk;
 		struct amdgpu_ib *ib;
 		struct drm_amdgpu_cs_chunk_ib *chunk_ib;
-		struct amdgpu_ring *ring;
+		struct drm_sched_entity *entity;
 
 		chunk = &parser->chunks[i];
 		ib = &parser->job->ibs[j];
@@ -1008,9 +1009,9 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 				return -EINVAL;
 		}
 
-		r = amdgpu_ctx_get_ring(parser->ctx, chunk_ib->ip_type,
-					chunk_ib->ip_instance, chunk_ib->ring,
-					&ring);
+		r = amdgpu_ctx_get_entity(parser->ctx, chunk_ib->ip_type,
+					  chunk_ib->ip_instance, chunk_ib->ring,
+					  &entity);
 		if (r)
 			return r;
 
@@ -1018,14 +1019,14 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 			parser->job->preamble_status |=
 				AMDGPU_PREAMBLE_IB_PRESENT;
 
-		if (parser->ring && parser->ring != ring)
+		if (parser->entity && parser->entity != entity)
 			return -EINVAL;
 
-		parser->ring = ring;
+		parser->entity = entity;
 
-		r =  amdgpu_ib_get(adev, vm,
-					ring->funcs->parse_cs ? chunk_ib->ib_bytes : 0,
-					ib);
+		ring = to_amdgpu_ring(entity->rq->sched);
+		r =  amdgpu_ib_get(adev, vm, ring->funcs->parse_cs ?
+				   chunk_ib->ib_bytes : 0, ib);
 		if (r) {
 			DRM_ERROR("Failed to get ib !\n");
 			return r;
@@ -1039,12 +1040,13 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 	}
 
 	/* UVD & VCE fw doesn't support user fences */
+	ring = to_amdgpu_ring(parser->entity->rq->sched);
 	if (parser->job->uf_addr && (
-	    parser->ring->funcs->type == AMDGPU_RING_TYPE_UVD ||
-	    parser->ring->funcs->type == AMDGPU_RING_TYPE_VCE))
+	    ring->funcs->type == AMDGPU_RING_TYPE_UVD ||
+	    ring->funcs->type == AMDGPU_RING_TYPE_VCE))
 		return -EINVAL;
 
-	return amdgpu_ctx_wait_prev_fence(parser->ctx, parser->ring->idx);
+	return amdgpu_ctx_wait_prev_fence(parser->ctx, parser->entity);
 }
 
 static int amdgpu_cs_process_fence_dep(struct amdgpu_cs_parser *p,
@@ -1060,23 +1062,23 @@ static int amdgpu_cs_process_fence_dep(struct amdgpu_cs_parser *p,
 		sizeof(struct drm_amdgpu_cs_chunk_dep);
 
 	for (i = 0; i < num_deps; ++i) {
-		struct amdgpu_ring *ring;
 		struct amdgpu_ctx *ctx;
+		struct drm_sched_entity *entity;
 		struct dma_fence *fence;
 
 		ctx = amdgpu_ctx_get(fpriv, deps[i].ctx_id);
 		if (ctx == NULL)
 			return -EINVAL;
 
-		r = amdgpu_ctx_get_ring(ctx, deps[i].ip_type,
-					deps[i].ip_instance,
-					deps[i].ring, &ring);
+		r = amdgpu_ctx_get_entity(ctx, deps[i].ip_type,
+					  deps[i].ip_instance,
+					  deps[i].ring, &entity);
 		if (r) {
 			amdgpu_ctx_put(ctx);
 			return r;
 		}
 
-		fence = amdgpu_ctx_get_fence(ctx, ring,
+		fence = amdgpu_ctx_get_fence(ctx, entity,
 					     deps[i].handle);
 		if (IS_ERR(fence)) {
 			r = PTR_ERR(fence);
@@ -1195,9 +1197,9 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 			    union drm_amdgpu_cs *cs)
 {
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
-	struct amdgpu_ring *ring = p->ring;
-	struct drm_sched_entity *entity = &p->ctx->rings[ring->idx].entity;
+	struct drm_sched_entity *entity = p->entity;
 	enum drm_sched_priority priority;
+	struct amdgpu_ring *ring;
 	struct amdgpu_bo_list_entry *e;
 	struct amdgpu_job *job;
 	uint64_t seq;
@@ -1227,7 +1229,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	job->owner = p->filp;
 	p->fence = dma_fence_get(&job->base.s_fence->finished);
 
-	r = amdgpu_ctx_add_fence(p->ctx, ring, p->fence, &seq);
+	r = amdgpu_ctx_add_fence(p->ctx, entity, p->fence, &seq);
 	if (r) {
 		dma_fence_put(p->fence);
 		dma_fence_put(&job->base.s_fence->finished);
@@ -1332,7 +1334,7 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 {
 	union drm_amdgpu_wait_cs *wait = data;
 	unsigned long timeout = amdgpu_gem_timeout(wait->in.timeout);
-	struct amdgpu_ring *ring = NULL;
+	struct drm_sched_entity *entity;
 	struct amdgpu_ctx *ctx;
 	struct dma_fence *fence;
 	long r;
@@ -1341,14 +1343,14 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 	if (ctx == NULL)
 		return -EINVAL;
 
-	r = amdgpu_ctx_get_ring(ctx, wait->in.ip_type, wait->in.ip_instance,
-				wait->in.ring, &ring);
+	r = amdgpu_ctx_get_entity(ctx, wait->in.ip_type, wait->in.ip_instance,
+				  wait->in.ring, &entity);
 	if (r) {
 		amdgpu_ctx_put(ctx);
 		return r;
 	}
 
-	fence = amdgpu_ctx_get_fence(ctx, ring, wait->in.handle);
+	fence = amdgpu_ctx_get_fence(ctx, entity, wait->in.handle);
 	if (IS_ERR(fence))
 		r = PTR_ERR(fence);
 	else if (fence) {
@@ -1380,7 +1382,7 @@ static struct dma_fence *amdgpu_cs_get_fence(struct amdgpu_device *adev,
 					     struct drm_file *filp,
 					     struct drm_amdgpu_fence *user)
 {
-	struct amdgpu_ring *ring;
+	struct drm_sched_entity *entity;
 	struct amdgpu_ctx *ctx;
 	struct dma_fence *fence;
 	int r;
@@ -1389,14 +1391,14 @@ static struct dma_fence *amdgpu_cs_get_fence(struct amdgpu_device *adev,
 	if (ctx == NULL)
 		return ERR_PTR(-EINVAL);
 
-	r = amdgpu_ctx_get_ring(ctx, user->ip_type, user->ip_instance,
-				user->ring, &ring);
+	r = amdgpu_ctx_get_entity(ctx, user->ip_type, user->ip_instance,
+				  user->ring, &entity);
 	if (r) {
 		amdgpu_ctx_put(ctx);
 		return ERR_PTR(r);
 	}
 
-	fence = amdgpu_ctx_get_fence(ctx, ring, user->seq_no);
+	fence = amdgpu_ctx_get_fence(ctx, entity, user->seq_no);
 	amdgpu_ctx_put(ctx);
 
 	return fence;

commit 869a53d4d7d7976d039b9389aa90b6f3d29ed234
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jul 16 15:19:20 2018 +0200

    drm/amdgpu: remove the queue manager
    
    Not needed any more since that is now done by the scheduler.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index dc3b2f980d87..55667ab4fbf5 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1008,8 +1008,9 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 				return -EINVAL;
 		}
 
-		r = amdgpu_queue_mgr_map(adev, &parser->ctx->queue_mgr, chunk_ib->ip_type,
-					 chunk_ib->ip_instance, chunk_ib->ring, &ring);
+		r = amdgpu_ctx_get_ring(parser->ctx, chunk_ib->ip_type,
+					chunk_ib->ip_instance, chunk_ib->ring,
+					&ring);
 		if (r)
 			return r;
 
@@ -1067,10 +1068,9 @@ static int amdgpu_cs_process_fence_dep(struct amdgpu_cs_parser *p,
 		if (ctx == NULL)
 			return -EINVAL;
 
-		r = amdgpu_queue_mgr_map(p->adev, &ctx->queue_mgr,
-					 deps[i].ip_type,
-					 deps[i].ip_instance,
-					 deps[i].ring, &ring);
+		r = amdgpu_ctx_get_ring(ctx, deps[i].ip_type,
+					deps[i].ip_instance,
+					deps[i].ring, &ring);
 		if (r) {
 			amdgpu_ctx_put(ctx);
 			return r;
@@ -1331,7 +1331,6 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 			 struct drm_file *filp)
 {
 	union drm_amdgpu_wait_cs *wait = data;
-	struct amdgpu_device *adev = dev->dev_private;
 	unsigned long timeout = amdgpu_gem_timeout(wait->in.timeout);
 	struct amdgpu_ring *ring = NULL;
 	struct amdgpu_ctx *ctx;
@@ -1342,9 +1341,8 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 	if (ctx == NULL)
 		return -EINVAL;
 
-	r = amdgpu_queue_mgr_map(adev, &ctx->queue_mgr,
-				 wait->in.ip_type, wait->in.ip_instance,
-				 wait->in.ring, &ring);
+	r = amdgpu_ctx_get_ring(ctx, wait->in.ip_type, wait->in.ip_instance,
+				wait->in.ring, &ring);
 	if (r) {
 		amdgpu_ctx_put(ctx);
 		return r;
@@ -1391,8 +1389,8 @@ static struct dma_fence *amdgpu_cs_get_fence(struct amdgpu_device *adev,
 	if (ctx == NULL)
 		return ERR_PTR(-EINVAL);
 
-	r = amdgpu_queue_mgr_map(adev, &ctx->queue_mgr, user->ip_type,
-				 user->ip_instance, user->ring, &ring);
+	r = amdgpu_ctx_get_ring(ctx, user->ip_type, user->ip_instance,
+				user->ring, &ring);
 	if (r) {
 		amdgpu_ctx_put(ctx);
 		return ERR_PTR(r);

commit 2cddc50e98193f2c4aab10d05550b5ffe7587e73
Author: Huang Rui <ray.huang@amd.com>
Date:   Mon Aug 13 11:41:35 2018 -0500

    drm/amdgpu: move gem definitions into amdgpu_gem header
    
    Demangle amdgpu.h.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 09703c87d676..dc3b2f980d87 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -32,6 +32,7 @@
 #include "amdgpu.h"
 #include "amdgpu_trace.h"
 #include "amdgpu_gmc.h"
+#include "amdgpu_gem.h"
 
 static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 				      struct drm_amdgpu_cs_chunk_fence *data,

commit 9296435729dc8a2fd28b42391ff9f1ff310ebb7b
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Aug 21 15:09:39 2018 +0200

    drm/amdgpu: fix preamble handling
    
    At this point the command submission can still be interrupted.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 502b94fb116a..09703c87d676 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1012,13 +1012,9 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		if (r)
 			return r;
 
-		if (chunk_ib->flags & AMDGPU_IB_FLAG_PREAMBLE) {
-			parser->job->preamble_status |= AMDGPU_PREAMBLE_IB_PRESENT;
-			if (!parser->ctx->preamble_presented) {
-				parser->job->preamble_status |= AMDGPU_PREAMBLE_IB_PRESENT_FIRST;
-				parser->ctx->preamble_presented = true;
-			}
-		}
+		if (chunk_ib->flags & AMDGPU_IB_FLAG_PREAMBLE)
+			parser->job->preamble_status |=
+				AMDGPU_PREAMBLE_IB_PRESENT;
 
 		if (parser->ring && parser->ring != ring)
 			return -EINVAL;
@@ -1241,6 +1237,12 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 
 	amdgpu_cs_post_dependencies(p);
 
+	if ((job->preamble_status & AMDGPU_PREAMBLE_IB_PRESENT) &&
+	    !p->ctx->preamble_presented) {
+		job->preamble_status |= AMDGPU_PREAMBLE_IB_PRESENT_FIRST;
+		p->ctx->preamble_presented = true;
+	}
+
 	cs->out.handle = seq;
 	job->uf_sequence = seq;
 

commit d98ff24e8e9be3329eea7c84d5e244d0c1cd0ab3
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Aug 21 15:09:39 2018 +0200

    drm/amdgpu: fix preamble handling
    
    At this point the command submission can still be interrupted.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 502b94fb116a..09703c87d676 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1012,13 +1012,9 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		if (r)
 			return r;
 
-		if (chunk_ib->flags & AMDGPU_IB_FLAG_PREAMBLE) {
-			parser->job->preamble_status |= AMDGPU_PREAMBLE_IB_PRESENT;
-			if (!parser->ctx->preamble_presented) {
-				parser->job->preamble_status |= AMDGPU_PREAMBLE_IB_PRESENT_FIRST;
-				parser->ctx->preamble_presented = true;
-			}
-		}
+		if (chunk_ib->flags & AMDGPU_IB_FLAG_PREAMBLE)
+			parser->job->preamble_status |=
+				AMDGPU_PREAMBLE_IB_PRESENT;
 
 		if (parser->ring && parser->ring != ring)
 			return -EINVAL;
@@ -1241,6 +1237,12 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 
 	amdgpu_cs_post_dependencies(p);
 
+	if ((job->preamble_status & AMDGPU_PREAMBLE_IB_PRESENT) &&
+	    !p->ctx->preamble_presented) {
+		job->preamble_status |= AMDGPU_PREAMBLE_IB_PRESENT_FIRST;
+		p->ctx->preamble_presented = true;
+	}
+
 	cs->out.handle = seq;
 	job->uf_sequence = seq;
 

commit 4a102ad4ba0daf886dcf0927ce2a7f6c3b3a615c
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jul 30 16:44:14 2018 +0200

    drm/amdgpu: create an empty bo_list if no handle is provided
    
    Instead of having extra handling just create an empty bo_list when no
    handle is provided.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming  Zhou <david1.zhou@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 1d7292ab2b62..502b94fb116a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -561,6 +561,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 				union drm_amdgpu_cs *cs)
 {
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
+	struct amdgpu_vm *vm = &fpriv->vm;
 	struct amdgpu_bo_list_entry *e;
 	struct list_head duplicates;
 	struct amdgpu_bo *gds;
@@ -580,13 +581,17 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 				       &p->bo_list);
 		if (r)
 			return r;
+	} else if (!p->bo_list) {
+		/* Create a empty bo_list when no handle is provided */
+		r = amdgpu_bo_list_create(p->adev, p->filp, NULL, 0,
+					  &p->bo_list);
+		if (r)
+			return r;
 	}
 
-	if (p->bo_list) {
-		amdgpu_bo_list_get_list(p->bo_list, &p->validated);
-		if (p->bo_list->first_userptr != p->bo_list->num_entries)
-			p->mn = amdgpu_mn_get(p->adev, AMDGPU_MN_TYPE_GFX);
-	}
+	amdgpu_bo_list_get_list(p->bo_list, &p->validated);
+	if (p->bo_list->first_userptr != p->bo_list->num_entries)
+		p->mn = amdgpu_mn_get(p->adev, AMDGPU_MN_TYPE_GFX);
 
 	INIT_LIST_HEAD(&duplicates);
 	amdgpu_vm_get_pd_bo(&fpriv->vm, &p->validated, &p->vm_pd);
@@ -605,10 +610,6 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 			goto error_free_pages;
 		}
 
-		/* Without a BO list we don't have userptr BOs */
-		if (!p->bo_list)
-			break;
-
 		INIT_LIST_HEAD(&need_pages);
 		amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
 			struct amdgpu_bo *bo = e->robj;
@@ -703,21 +704,12 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	amdgpu_cs_report_moved_bytes(p->adev, p->bytes_moved,
 				     p->bytes_moved_vis);
 
-	if (p->bo_list) {
-		struct amdgpu_vm *vm = &fpriv->vm;
-		struct amdgpu_bo_list_entry *e;
+	gds = p->bo_list->gds_obj;
+	gws = p->bo_list->gws_obj;
+	oa = p->bo_list->oa_obj;
 
-		gds = p->bo_list->gds_obj;
-		gws = p->bo_list->gws_obj;
-		oa = p->bo_list->oa_obj;
-
-		amdgpu_bo_list_for_each_entry(e, p->bo_list)
-			e->bo_va = amdgpu_vm_bo_find(vm, e->robj);
-	} else {
-		gds = p->adev->gds.gds_gfx_bo;
-		gws = p->adev->gds.gws_gfx_bo;
-		oa = p->adev->gds.oa_gfx_bo;
-	}
+	amdgpu_bo_list_for_each_entry(e, p->bo_list)
+		e->bo_va = amdgpu_vm_bo_find(vm, e->robj);
 
 	if (gds) {
 		p->job->gds_base = amdgpu_bo_gpu_offset(gds);
@@ -745,15 +737,13 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 
 error_free_pages:
 
-	if (p->bo_list) {
-		amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
-			if (!e->user_pages)
-				continue;
+	amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
+		if (!e->user_pages)
+			continue;
 
-			release_pages(e->user_pages,
-				      e->robj->tbo.ttm->num_pages);
-			kvfree(e->user_pages);
-		}
+		release_pages(e->user_pages,
+			      e->robj->tbo.ttm->num_pages);
+		kvfree(e->user_pages);
 	}
 
 	return r;
@@ -815,9 +805,10 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error,
 
 static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 {
-	struct amdgpu_device *adev = p->adev;
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
+	struct amdgpu_device *adev = p->adev;
 	struct amdgpu_vm *vm = &fpriv->vm;
+	struct amdgpu_bo_list_entry *e;
 	struct amdgpu_bo_va *bo_va;
 	struct amdgpu_bo *bo;
 	int r;
@@ -850,31 +841,26 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 			return r;
 	}
 
-	if (p->bo_list) {
-		struct amdgpu_bo_list_entry *e;
-
-		amdgpu_bo_list_for_each_entry(e, p->bo_list) {
-			struct dma_fence *f;
-
-			/* ignore duplicates */
-			bo = e->robj;
-			if (!bo)
-				continue;
+	amdgpu_bo_list_for_each_entry(e, p->bo_list) {
+		struct dma_fence *f;
 
-			bo_va = e->bo_va;
-			if (bo_va == NULL)
-				continue;
+		/* ignore duplicates */
+		bo = e->robj;
+		if (!bo)
+			continue;
 
-			r = amdgpu_vm_bo_update(adev, bo_va, false);
-			if (r)
-				return r;
+		bo_va = e->bo_va;
+		if (bo_va == NULL)
+			continue;
 
-			f = bo_va->last_pt_update;
-			r = amdgpu_sync_fence(adev, &p->job->sync, f, false);
-			if (r)
-				return r;
-		}
+		r = amdgpu_vm_bo_update(adev, bo_va, false);
+		if (r)
+			return r;
 
+		f = bo_va->last_pt_update;
+		r = amdgpu_sync_fence(adev, &p->job->sync, f, false);
+		if (r)
+			return r;
 	}
 
 	r = amdgpu_vm_handle_moved(adev, vm);
@@ -889,9 +875,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 	if (r)
 		return r;
 
-	if (amdgpu_vm_debug && p->bo_list) {
-		struct amdgpu_bo_list_entry *e;
-
+	if (amdgpu_vm_debug) {
 		/* Invalidate all BOs to test for userspace bugs */
 		amdgpu_bo_list_for_each_entry(e, p->bo_list) {
 			/* ignore duplicates */
@@ -1217,22 +1201,19 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	struct amdgpu_ring *ring = p->ring;
 	struct drm_sched_entity *entity = &p->ctx->rings[ring->idx].entity;
 	enum drm_sched_priority priority;
+	struct amdgpu_bo_list_entry *e;
 	struct amdgpu_job *job;
 	uint64_t seq;
 
 	int r;
 
 	amdgpu_mn_lock(p->mn);
-	if (p->bo_list) {
-		struct amdgpu_bo_list_entry *e;
+	amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
+		struct amdgpu_bo *bo = e->robj;
 
-		amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
-			struct amdgpu_bo *bo = e->robj;
-
-			if (amdgpu_ttm_tt_userptr_needs_pages(bo->tbo.ttm)) {
-				amdgpu_mn_unlock(p->mn);
-				return -ERESTARTSYS;
-			}
+		if (amdgpu_ttm_tt_userptr_needs_pages(bo->tbo.ttm)) {
+			amdgpu_mn_unlock(p->mn);
+			return -ERESTARTSYS;
 		}
 	}
 

commit 39f7f69a6054bb9777b47b6afdb5ce2fae30dbee
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jul 30 15:37:46 2018 +0200

    drm/amdgpu: add bo_list iterators
    
    Add helpers to iterate over all entries in a bo_list.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming  Zhou <david1.zhou@amd.com>
    Acked-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index f7154f3ed807..1d7292ab2b62 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -563,10 +563,10 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_bo_list_entry *e;
 	struct list_head duplicates;
-	unsigned i, tries = 10;
 	struct amdgpu_bo *gds;
 	struct amdgpu_bo *gws;
 	struct amdgpu_bo *oa;
+	unsigned tries = 10;
 	int r;
 
 	INIT_LIST_HEAD(&p->validated);
@@ -596,7 +596,6 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 
 	while (1) {
 		struct list_head need_pages;
-		unsigned i;
 
 		r = ttm_eu_reserve_buffers(&p->ticket, &p->validated, true,
 					   &duplicates);
@@ -611,12 +610,8 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 			break;
 
 		INIT_LIST_HEAD(&need_pages);
-		for (i = p->bo_list->first_userptr;
-		     i < p->bo_list->num_entries; ++i) {
-			struct amdgpu_bo *bo;
-
-			e = &p->bo_list->array[i];
-			bo = e->robj;
+		amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
+			struct amdgpu_bo *bo = e->robj;
 
 			if (amdgpu_ttm_tt_userptr_invalidated(bo->tbo.ttm,
 				 &e->user_invalidated) && e->user_pages) {
@@ -710,16 +705,14 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 
 	if (p->bo_list) {
 		struct amdgpu_vm *vm = &fpriv->vm;
-		unsigned i;
+		struct amdgpu_bo_list_entry *e;
 
 		gds = p->bo_list->gds_obj;
 		gws = p->bo_list->gws_obj;
 		oa = p->bo_list->oa_obj;
-		for (i = 0; i < p->bo_list->num_entries; i++) {
-			struct amdgpu_bo *bo = p->bo_list->array[i].robj;
 
-			p->bo_list->array[i].bo_va = amdgpu_vm_bo_find(vm, bo);
-		}
+		amdgpu_bo_list_for_each_entry(e, p->bo_list)
+			e->bo_va = amdgpu_vm_bo_find(vm, e->robj);
 	} else {
 		gds = p->adev->gds.gds_gfx_bo;
 		gws = p->adev->gds.gws_gfx_bo;
@@ -753,10 +746,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 error_free_pages:
 
 	if (p->bo_list) {
-		for (i = p->bo_list->first_userptr;
-		     i < p->bo_list->num_entries; ++i) {
-			e = &p->bo_list->array[i];
-
+		amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
 			if (!e->user_pages)
 				continue;
 
@@ -830,7 +820,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 	struct amdgpu_vm *vm = &fpriv->vm;
 	struct amdgpu_bo_va *bo_va;
 	struct amdgpu_bo *bo;
-	int i, r;
+	int r;
 
 	r = amdgpu_vm_clear_freed(adev, vm, NULL);
 	if (r)
@@ -861,15 +851,17 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 	}
 
 	if (p->bo_list) {
-		for (i = 0; i < p->bo_list->num_entries; i++) {
+		struct amdgpu_bo_list_entry *e;
+
+		amdgpu_bo_list_for_each_entry(e, p->bo_list) {
 			struct dma_fence *f;
 
 			/* ignore duplicates */
-			bo = p->bo_list->array[i].robj;
+			bo = e->robj;
 			if (!bo)
 				continue;
 
-			bo_va = p->bo_list->array[i].bo_va;
+			bo_va = e->bo_va;
 			if (bo_va == NULL)
 				continue;
 
@@ -898,14 +890,15 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 		return r;
 
 	if (amdgpu_vm_debug && p->bo_list) {
+		struct amdgpu_bo_list_entry *e;
+
 		/* Invalidate all BOs to test for userspace bugs */
-		for (i = 0; i < p->bo_list->num_entries; i++) {
+		amdgpu_bo_list_for_each_entry(e, p->bo_list) {
 			/* ignore duplicates */
-			bo = p->bo_list->array[i].robj;
-			if (!bo)
+			if (!e->robj)
 				continue;
 
-			amdgpu_vm_bo_invalidate(adev, bo, false);
+			amdgpu_vm_bo_invalidate(adev, e->robj, false);
 		}
 	}
 
@@ -1225,16 +1218,16 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	struct drm_sched_entity *entity = &p->ctx->rings[ring->idx].entity;
 	enum drm_sched_priority priority;
 	struct amdgpu_job *job;
-	unsigned i;
 	uint64_t seq;
 
 	int r;
 
 	amdgpu_mn_lock(p->mn);
 	if (p->bo_list) {
-		for (i = p->bo_list->first_userptr;
-		     i < p->bo_list->num_entries; ++i) {
-			struct amdgpu_bo *bo = p->bo_list->array[i].robj;
+		struct amdgpu_bo_list_entry *e;
+
+		amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
+			struct amdgpu_bo *bo = e->robj;
 
 			if (amdgpu_ttm_tt_userptr_needs_pages(bo->tbo.ttm)) {
 				amdgpu_mn_unlock(p->mn);

commit 81c6dabcc990c341793368db985ee8aca5713b16
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jul 30 13:46:04 2018 +0200

    drm/amdgpu: always recreate bo_list
    
    The bo_list handle is allocated by OP_CREATE, so in OP_UPDATE here we just
    re-create the bo_list object and replace the handle. This way we don't
    need locking to protect the bo_list because it's always re-created when
    changed.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming  Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 0295666968da..f7154f3ed807 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -580,9 +580,6 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 				       &p->bo_list);
 		if (r)
 			return r;
-
-	} else if (p->bo_list) {
-		mutex_lock(&p->bo_list->lock);
 	}
 
 	if (p->bo_list) {

commit 8ab19ea619aeed8ca4a36c124e8edfd9b9491aba
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Jul 27 16:56:34 2018 +0200

    drm/amdgpu: add new amdgpu_vm_bo_trace_cs() function v2
    
    This allows us to trace all VM ranges which should be valid inside a CS.
    
    v2: dump mappings without BO as well
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming  Zhou <david1.zhou@amd.com>
    Reviewed-and-tested-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com> (v1)
    Reviewed-by: Huang Rui <ray.huang@amd.com> (v1)
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index d41cea78e4aa..0295666968da 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1223,6 +1223,7 @@ static void amdgpu_cs_post_dependencies(struct amdgpu_cs_parser *p)
 static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 			    union drm_amdgpu_cs *cs)
 {
+	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_ring *ring = p->ring;
 	struct drm_sched_entity *entity = &p->ctx->rings[ring->idx].entity;
 	enum drm_sched_priority priority;
@@ -1275,6 +1276,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	amdgpu_job_free_resources(job);
 
 	trace_amdgpu_cs_ioctl(job);
+	amdgpu_vm_bo_trace_cs(&fpriv->vm, &p->ticket);
 	priority = job->base.s_priority;
 	drm_sched_entity_push_job(&job->base, entity);
 

commit 0cb7c1f03bfb3991120313c5927c1749041ef800
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jul 30 16:18:54 2018 +0200

    drm/amdgpu: return error if both BOs and bo_list handle is given
    
    Return -EINVAL when both the BOs as well as a list handle is provided in
    the IOCTL.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming  Zhou <david1.zhou@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 8a49c3b97bd4..d41cea78e4aa 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -572,14 +572,17 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	INIT_LIST_HEAD(&p->validated);
 
 	/* p->bo_list could already be assigned if AMDGPU_CHUNK_ID_BO_HANDLES is present */
-	if (p->bo_list) {
-		mutex_lock(&p->bo_list->lock);
+	if (cs->in.bo_list_handle) {
+		if (p->bo_list)
+			return -EINVAL;
 
-	} else if (cs->in.bo_list_handle) {
 		r = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle,
 				       &p->bo_list);
 		if (r)
 			return r;
+
+	} else if (p->bo_list) {
+		mutex_lock(&p->bo_list->lock);
 	}
 
 	if (p->bo_list) {

commit 52c054caf83012fe9fe858ee86d90b4ea2cc3cca
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Jul 27 15:32:04 2018 +0200

    drm/amdgpu: add proper error handling to amdgpu_bo_list_get
    
    Otherwise we silently don't use a BO list when the handle is invalid.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 533b2e7656c0..8a49c3b97bd4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -572,11 +572,16 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	INIT_LIST_HEAD(&p->validated);
 
 	/* p->bo_list could already be assigned if AMDGPU_CHUNK_ID_BO_HANDLES is present */
-	if (!p->bo_list)
-		p->bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
-	else
+	if (p->bo_list) {
 		mutex_lock(&p->bo_list->lock);
 
+	} else if (cs->in.bo_list_handle) {
+		r = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle,
+				       &p->bo_list);
+		if (r)
+			return r;
+	}
+
 	if (p->bo_list) {
 		amdgpu_bo_list_get_list(p->bo_list, &p->validated);
 		if (p->bo_list->first_userptr != p->bo_list->num_entries)

commit 9d248517d4bd807c7690d55d0b6f54618fc60942
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jul 23 16:01:39 2018 +0200

    drm/amdgpu: add support for inplace IB patching for MM engines v2
    
    We are going to need that for the second UVD instance on Vega20.
    
    v2: rename to patch_cs_in_place
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-and-tested-by: James Zhu <James.Zhu@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 178d9ce4eba1..533b2e7656c0 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -916,7 +916,7 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 	int r;
 
 	/* Only for UVD/VCE VM emulation */
-	if (p->ring->funcs->parse_cs) {
+	if (p->ring->funcs->parse_cs || p->ring->funcs->patch_cs_in_place) {
 		unsigned i, j;
 
 		for (i = 0, j = 0; i < p->nchunks && j < p->job->num_ibs; i++) {
@@ -957,12 +957,20 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 			offset = m->start * AMDGPU_GPU_PAGE_SIZE;
 			kptr += va_start - offset;
 
-			memcpy(ib->ptr, kptr, chunk_ib->ib_bytes);
-			amdgpu_bo_kunmap(aobj);
-
-			r = amdgpu_ring_parse_cs(ring, p, j);
-			if (r)
-				return r;
+			if (p->ring->funcs->parse_cs) {
+				memcpy(ib->ptr, kptr, chunk_ib->ib_bytes);
+				amdgpu_bo_kunmap(aobj);
+
+				r = amdgpu_ring_parse_cs(ring, p, j);
+				if (r)
+					return r;
+			} else {
+				ib->ptr = (uint32_t *)kptr;
+				r = amdgpu_ring_patch_cs_in_place(ring, p, j);
+				amdgpu_bo_kunmap(aobj);
+				if (r)
+					return r;
+			}
 
 			j++;
 		}

commit 068c330419ffb3422a43cb7d34351f1ef033950f
Author: Nayan Deshmukh <nayan26deshmukh@gmail.com>
Date:   Fri Jul 20 17:51:06 2018 +0530

    drm/scheduler: remove sched field from the entity
    
    The scheduler of the entity is decided by the run queue on which
    it is queued. This patch avoids us the effort required to maintain
    a sync between rq and sched field when we start shifting entites
    among different rqs.
    
    Signed-off-by: Nayan Deshmukh <nayan26deshmukh@gmail.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Eric Anholt <eric@anholt.net>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 4d4575b3bba7..178d9ce4eba1 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1262,7 +1262,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	priority = job->base.s_priority;
 	drm_sched_entity_push_job(&job->base, entity);
 
-	ring = to_amdgpu_ring(entity->sched);
+	ring = to_amdgpu_ring(entity->rq->sched);
 	amdgpu_ring_priority_get(ring, priority);
 
 	ttm_eu_fence_buffer_objects(&p->ticket, &p->validated, p->fence);

commit cdc50176597cb44ce25eb7331c450058775b8d2a
Author: Nayan Deshmukh <nayan26deshmukh@gmail.com>
Date:   Fri Jul 20 17:51:05 2018 +0530

    drm/scheduler: modify API to avoid redundancy
    
    entity has a scheduler field and we don't need the sched argument
    in any of the functions where entity is provided.
    
    Signed-off-by: Nayan Deshmukh <nayan26deshmukh@gmail.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Eric Anholt <eric@anholt.net>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index c5d81d6a90e0..4d4575b3bba7 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1232,7 +1232,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	job = p->job;
 	p->job = NULL;
 
-	r = drm_sched_job_init(&job->base, &ring->sched, entity, p->filp);
+	r = drm_sched_job_init(&job->base, entity, p->filp);
 	if (r) {
 		amdgpu_job_free(job);
 		amdgpu_mn_unlock(p->mn);

commit c704ab18e0a26a5dc7e947af6e8e01585380518b
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jul 16 16:12:24 2018 +0200

    drm/amdgpu: consistenly name amdgpu_bo_ functions
    
    Just rename functions, no functional change.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 7c5cc33d0cda..c5d81d6a90e0 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -419,7 +419,7 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 	}
 
 retry:
-	amdgpu_ttm_placement_from_domain(bo, domain);
+	amdgpu_bo_placement_from_domain(bo, domain);
 	r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
 
 	p->bytes_moved += ctx.bytes_moved;
@@ -478,7 +478,7 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 		update_bytes_moved_vis =
 				!amdgpu_gmc_vram_full_visible(&adev->gmc) &&
 				amdgpu_bo_in_cpu_visible_vram(bo);
-		amdgpu_ttm_placement_from_domain(bo, other);
+		amdgpu_bo_placement_from_domain(bo, other);
 		r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
 		p->bytes_moved += ctx.bytes_moved;
 		if (update_bytes_moved_vis)
@@ -532,8 +532,8 @@ static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 		/* Check if we have user pages and nobody bound the BO already */
 		if (amdgpu_ttm_tt_userptr_needs_pages(bo->tbo.ttm) &&
 		    lobj->user_pages) {
-			amdgpu_ttm_placement_from_domain(bo,
-							 AMDGPU_GEM_DOMAIN_CPU);
+			amdgpu_bo_placement_from_domain(bo,
+							AMDGPU_GEM_DOMAIN_CPU);
 			r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
 			if (r)
 				return r;
@@ -1655,7 +1655,7 @@ int amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 
 	if (!((*bo)->flags & AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS)) {
 		(*bo)->flags |= AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS;
-		amdgpu_ttm_placement_from_domain(*bo, (*bo)->allowed_domains);
+		amdgpu_bo_placement_from_domain(*bo, (*bo)->allowed_domains);
 		r = ttm_bo_validate(&(*bo)->tbo, &(*bo)->placement, &ctx);
 		if (r)
 			return r;

commit b5286801705b39e44b824520714d503f882fef1c
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jul 16 14:58:48 2018 +0200

    drm/amdgpu: change ring priority after pushing the job (v2)
    
    Pushing a job can change the ring assignment of an entity.
    
    v2: squash in:
    "drm/amdgpu: fix job priority handling" (Christian)
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 72dc9b36b937..7c5cc33d0cda 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1209,6 +1209,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 {
 	struct amdgpu_ring *ring = p->ring;
 	struct drm_sched_entity *entity = &p->ctx->rings[ring->idx].entity;
+	enum drm_sched_priority priority;
 	struct amdgpu_job *job;
 	unsigned i;
 	uint64_t seq;
@@ -1256,11 +1257,14 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	job->uf_sequence = seq;
 
 	amdgpu_job_free_resources(job);
-	amdgpu_ring_priority_get(p->ring, job->base.s_priority);
 
 	trace_amdgpu_cs_ioctl(job);
+	priority = job->base.s_priority;
 	drm_sched_entity_push_job(&job->base, entity);
 
+	ring = to_amdgpu_ring(entity->sched);
+	amdgpu_ring_priority_get(ring, priority);
+
 	ttm_eu_fence_buffer_objects(&p->ticket, &p->validated, p->fence);
 	amdgpu_mn_unlock(p->mn);
 

commit 3320b8d2acd3d480d0dd4835d970067354eac915
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Jul 13 15:08:44 2018 +0200

    drm/amdgpu: remove job->ring
    
    We can easily get that from the scheduler.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Acked-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 6eb7ee859ffd..72dc9b36b937 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -912,11 +912,11 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 {
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_vm *vm = &fpriv->vm;
-	struct amdgpu_ring *ring = p->job->ring;
+	struct amdgpu_ring *ring = p->ring;
 	int r;
 
 	/* Only for UVD/VCE VM emulation */
-	if (p->job->ring->funcs->parse_cs) {
+	if (p->ring->funcs->parse_cs) {
 		unsigned i, j;
 
 		for (i = 0, j = 0; i < p->nchunks && j < p->job->num_ibs; i++) {
@@ -1030,10 +1030,10 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 			}
 		}
 
-		if (parser->job->ring && parser->job->ring != ring)
+		if (parser->ring && parser->ring != ring)
 			return -EINVAL;
 
-		parser->job->ring = ring;
+		parser->ring = ring;
 
 		r =  amdgpu_ib_get(adev, vm,
 					ring->funcs->parse_cs ? chunk_ib->ib_bytes : 0,
@@ -1052,11 +1052,11 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 
 	/* UVD & VCE fw doesn't support user fences */
 	if (parser->job->uf_addr && (
-	    parser->job->ring->funcs->type == AMDGPU_RING_TYPE_UVD ||
-	    parser->job->ring->funcs->type == AMDGPU_RING_TYPE_VCE))
+	    parser->ring->funcs->type == AMDGPU_RING_TYPE_UVD ||
+	    parser->ring->funcs->type == AMDGPU_RING_TYPE_VCE))
 		return -EINVAL;
 
-	return amdgpu_ctx_wait_prev_fence(parser->ctx, parser->job->ring->idx);
+	return amdgpu_ctx_wait_prev_fence(parser->ctx, parser->ring->idx);
 }
 
 static int amdgpu_cs_process_fence_dep(struct amdgpu_cs_parser *p,
@@ -1207,7 +1207,7 @@ static void amdgpu_cs_post_dependencies(struct amdgpu_cs_parser *p)
 static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 			    union drm_amdgpu_cs *cs)
 {
-	struct amdgpu_ring *ring = p->job->ring;
+	struct amdgpu_ring *ring = p->ring;
 	struct drm_sched_entity *entity = &p->ctx->rings[ring->idx].entity;
 	struct amdgpu_job *job;
 	unsigned i;
@@ -1256,7 +1256,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	job->uf_sequence = seq;
 
 	amdgpu_job_free_resources(job);
-	amdgpu_ring_priority_get(job->ring, job->base.s_priority);
+	amdgpu_ring_priority_get(p->ring, job->base.s_priority);
 
 	trace_amdgpu_cs_ioctl(job);
 	drm_sched_entity_push_job(&job->base, entity);

commit eb3961a57424a5c3dae44576d1c88e64a818d871
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Jul 13 09:58:49 2018 +0200

    drm/amdgpu: remove fence context from the job
    
    Can be obtained directly from the fence as well.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Acked-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 6d8df76b5a5d..6eb7ee859ffd 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1239,7 +1239,6 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	}
 
 	job->owner = p->filp;
-	job->fence_ctx = entity->fence_context;
 	p->fence = dma_fence_get(&job->base.s_fence->finished);
 
 	r = amdgpu_ctx_add_fence(p->ctx, ring, p->fence, &seq);

commit 964d0fbf6301d3dc8dfad19ffab5a06d002d27f1
Author: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
Date:   Fri Jul 6 14:16:54 2018 -0400

    drm/amdgpu: Allow to create BO lists in CS ioctl v3
    
    This change is to support MESA performace optimization.
    Modify CS IOCTL to allow its input as command buffer and an array of
    buffer handles to create a temporay bo list and then destroy it
    when IOCTL completes.
    This saves on calling for BO_LIST create and destry IOCTLs in MESA
    and by this improves performance.
    
    v2: Avoid inserting the temp list into idr struct.
    
    v3:
    Remove idr alloation from amdgpu_bo_list_create.
    Remove useless argument from amdgpu_cs_parser_fini
    Minor cosmetic stuff.
    
    v4: Revert amdgpu_bo_list_destroy back to static
    
    Signed-off-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 5a2a5ba29f9a..6d8df76b5a5d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -66,11 +66,35 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 	return 0;
 }
 
-static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
+static int amdgpu_cs_bo_handles_chunk(struct amdgpu_cs_parser *p,
+				      struct drm_amdgpu_bo_list_in *data)
+{
+	int r;
+	struct drm_amdgpu_bo_list_entry *info = NULL;
+
+	r = amdgpu_bo_create_list_entry_array(data, &info);
+	if (r)
+		return r;
+
+	r = amdgpu_bo_list_create(p->adev, p->filp, info, data->bo_number,
+				  &p->bo_list);
+	if (r)
+		goto error_free;
+
+	kvfree(info);
+	return 0;
+
+error_free:
+	if (info)
+		kvfree(info);
+
+	return r;
+}
+
+static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, union drm_amdgpu_cs *cs)
 {
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_vm *vm = &fpriv->vm;
-	union drm_amdgpu_cs *cs = data;
 	uint64_t *chunk_array_user;
 	uint64_t *chunk_array;
 	unsigned size, num_ibs = 0;
@@ -164,6 +188,19 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 
 			break;
 
+		case AMDGPU_CHUNK_ID_BO_HANDLES:
+			size = sizeof(struct drm_amdgpu_bo_list_in);
+			if (p->chunks[i].length_dw * sizeof(uint32_t) < size) {
+				ret = -EINVAL;
+				goto free_partial_kdata;
+			}
+
+			ret = amdgpu_cs_bo_handles_chunk(p, p->chunks[i].kdata);
+			if (ret)
+				goto free_partial_kdata;
+
+			break;
+
 		case AMDGPU_CHUNK_ID_DEPENDENCIES:
 		case AMDGPU_CHUNK_ID_SYNCOBJ_IN:
 		case AMDGPU_CHUNK_ID_SYNCOBJ_OUT:
@@ -534,7 +571,12 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 
 	INIT_LIST_HEAD(&p->validated);
 
-	p->bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
+	/* p->bo_list could already be assigned if AMDGPU_CHUNK_ID_BO_HANDLES is present */
+	if (!p->bo_list)
+		p->bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
+	else
+		mutex_lock(&p->bo_list->lock);
+
 	if (p->bo_list) {
 		amdgpu_bo_list_get_list(p->bo_list, &p->validated);
 		if (p->bo_list->first_userptr != p->bo_list->num_entries)

commit a5ccfe5c20740f2fbf00291490cdf8d2373ec255
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Wed Jul 11 12:00:40 2018 +0200

    drm/amdgpu: Make pin_size values atomic
    
    Concurrent execution of the non-atomic arithmetic could result in
    completely bogus values.
    
    v2:
    * Rebased on v2 of the previous patch
    
    Cc: stable@vger.kernel.org
    Bugzilla: https://bugs.freedesktop.org/106872
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 9881a1e55df3..5a2a5ba29f9a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -262,7 +262,7 @@ static void amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev,
 		return;
 	}
 
-	total_vram = adev->gmc.real_vram_size - adev->vram_pin_size;
+	total_vram = adev->gmc.real_vram_size - atomic64_read(&adev->vram_pin_size);
 	used_vram = amdgpu_vram_mgr_usage(&adev->mman.bdev.man[TTM_PL_VRAM]);
 	free_vram = used_vram >= total_vram ? 0 : total_vram - used_vram;
 

commit efaa96463929684ceca4be96d0959e9ced1fa093
Author: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
Date:   Thu Jun 28 22:55:27 2018 -0400

    drm/amdgpu: Present amdgpu_task_info in VM_FAULTS.
    
    Extract and present the reposnsible process and thread when
    VM_FAULT happens.
    
    v2: Use getter and setter functions.
    
    Signed-off-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Acked-by: Jim Qu <Jim.Qu@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 1bc02816989d..9881a1e55df3 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -187,6 +187,10 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	if (p->uf_entry.robj)
 		p->job->uf_addr = uf_offset;
 	kfree(chunk_array);
+
+	/* Use this opportunity to fill in task info for the vm */
+	amdgpu_vm_set_task_info(vm);
+
 	return 0;
 
 free_all_kdata:

commit 02374bbd3bfa38cc6922fe56736716308c48f538
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Mon Jun 25 11:07:17 2018 +0200

    drm/amdgpu: Reserve VM root shared fence slot for command submission (v3)
    
    Without this, there could not be enough slots, which could trigger the
    BUG_ON in reservation_object_add_shared_fence.
    
    v2:
    * Jump to the error label instead of returning directly (Jerry Zhang)
    v3:
    * Reserve slots for command submission after VM updates (Christian König)
    
    Cc: stable@vger.kernel.org
    Bugzilla: https://bugs.freedesktop.org/106418
    Reported-by: mikhail.v.gavrilov@gmail.com
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 7a625f3989a0..1bc02816989d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -928,6 +928,10 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 		r = amdgpu_bo_vm_update_pte(p);
 		if (r)
 			return r;
+
+		r = reservation_object_reserve_shared(vm->root.base.bo->tbo.resv);
+		if (r)
+			return r;
 	}
 
 	return amdgpu_cs_sync_rings(p);

commit c8c5e569c5b0c9ad523c35497af2ae5788a29581
Author: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
Date:   Tue Jun 12 14:28:20 2018 -0400

    drm/amdgpu: Consolidate visible vs. real vram check v2.
    
    Move all instnaces of this check into a function in amdgpu_gmc.h
    Rename the original function to a more proper name.
    
    v2:
    Add more places to cleanup.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 82312a7bc6ad..7a625f3989a0 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -31,6 +31,7 @@
 #include <drm/drm_syncobj.h>
 #include "amdgpu.h"
 #include "amdgpu_trace.h"
+#include "amdgpu_gmc.h"
 
 static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 				      struct drm_amdgpu_cs_chunk_fence *data,
@@ -302,7 +303,7 @@ static void amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev,
 	*max_bytes = us_to_bytes(adev, adev->mm_stats.accum_us);
 
 	/* Do the same for visible VRAM if half of it is free */
-	if (adev->gmc.visible_vram_size < adev->gmc.real_vram_size) {
+	if (!amdgpu_gmc_vram_full_visible(&adev->gmc)) {
 		u64 total_vis_vram = adev->gmc.visible_vram_size;
 		u64 used_vis_vram =
 			amdgpu_vram_mgr_vis_usage(&adev->mman.bdev.man[TTM_PL_VRAM]);
@@ -359,7 +360,7 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 	 * to move it. Don't move anything if the threshold is zero.
 	 */
 	if (p->bytes_moved < p->bytes_moved_threshold) {
-		if (adev->gmc.visible_vram_size < adev->gmc.real_vram_size &&
+		if (!amdgpu_gmc_vram_full_visible(&adev->gmc) &&
 		    (bo->flags & AMDGPU_GEM_CREATE_CPU_ACCESS_REQUIRED)) {
 			/* And don't move a CPU_ACCESS_REQUIRED BO to limited
 			 * visible VRAM if we've depleted our allowance to do
@@ -381,7 +382,7 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 	r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
 
 	p->bytes_moved += ctx.bytes_moved;
-	if (adev->gmc.visible_vram_size < adev->gmc.real_vram_size &&
+	if (!amdgpu_gmc_vram_full_visible(&adev->gmc) &&
 	    amdgpu_bo_in_cpu_visible_vram(bo))
 		p->bytes_moved_vis += ctx.bytes_moved;
 
@@ -434,8 +435,8 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 
 		/* Good we can try to move this BO somewhere else */
 		update_bytes_moved_vis =
-			adev->gmc.visible_vram_size < adev->gmc.real_vram_size &&
-			amdgpu_bo_in_cpu_visible_vram(bo);
+				!amdgpu_gmc_vram_full_visible(&adev->gmc) &&
+				amdgpu_bo_in_cpu_visible_vram(bo);
 		amdgpu_ttm_placement_from_domain(bo, other);
 		r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
 		p->bytes_moved += ctx.bytes_moved;

commit 01d98506eca24f1a6b67374ffb65c2e62a56e8e7
Author: Emily Deng <Emily.Deng@amd.com>
Date:   Wed May 30 10:04:25 2018 +0800

    drm/amdgpu: To get gds, gws and oa from adev->gds (v2)
    
    As now enabled per vm bo feature, the user mode driver won't supply the
    bo_list generally, for this case, the gdb_base, gds_size, gws_base, gws_size and
    oa_base, oa_size won't be set.
    
    v2: fix warning (Chunming)
    
    Signed-off-by: Emily Deng <Emily.Deng@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 9c1d491d742e..82312a7bc6ad 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -522,6 +522,9 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	struct amdgpu_bo_list_entry *e;
 	struct list_head duplicates;
 	unsigned i, tries = 10;
+	struct amdgpu_bo *gds;
+	struct amdgpu_bo *gws;
+	struct amdgpu_bo *oa;
 	int r;
 
 	INIT_LIST_HEAD(&p->validated);
@@ -652,31 +655,36 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 
 	amdgpu_cs_report_moved_bytes(p->adev, p->bytes_moved,
 				     p->bytes_moved_vis);
+
 	if (p->bo_list) {
-		struct amdgpu_bo *gds = p->bo_list->gds_obj;
-		struct amdgpu_bo *gws = p->bo_list->gws_obj;
-		struct amdgpu_bo *oa = p->bo_list->oa_obj;
 		struct amdgpu_vm *vm = &fpriv->vm;
 		unsigned i;
 
+		gds = p->bo_list->gds_obj;
+		gws = p->bo_list->gws_obj;
+		oa = p->bo_list->oa_obj;
 		for (i = 0; i < p->bo_list->num_entries; i++) {
 			struct amdgpu_bo *bo = p->bo_list->array[i].robj;
 
 			p->bo_list->array[i].bo_va = amdgpu_vm_bo_find(vm, bo);
 		}
+	} else {
+		gds = p->adev->gds.gds_gfx_bo;
+		gws = p->adev->gds.gws_gfx_bo;
+		oa = p->adev->gds.oa_gfx_bo;
+	}
 
-		if (gds) {
-			p->job->gds_base = amdgpu_bo_gpu_offset(gds);
-			p->job->gds_size = amdgpu_bo_size(gds);
-		}
-		if (gws) {
-			p->job->gws_base = amdgpu_bo_gpu_offset(gws);
-			p->job->gws_size = amdgpu_bo_size(gws);
-		}
-		if (oa) {
-			p->job->oa_base = amdgpu_bo_gpu_offset(oa);
-			p->job->oa_size = amdgpu_bo_size(oa);
-		}
+	if (gds) {
+		p->job->gds_base = amdgpu_bo_gpu_offset(gds);
+		p->job->gds_size = amdgpu_bo_size(gds);
+	}
+	if (gws) {
+		p->job->gws_base = amdgpu_bo_gpu_offset(gws);
+		p->job->gws_size = amdgpu_bo_size(gws);
+	}
+	if (oa) {
+		p->job->oa_base = amdgpu_bo_gpu_offset(oa);
+		p->job->oa_size = amdgpu_bo_size(oa);
 	}
 
 	if (!r && p->uf_entry.robj) {

commit 95d2c3e15da613afd53b4b8f2cdb352dc7d12221
Merge: b8a71080ad28 8344c53f5705
Author: Dave Airlie <airlied@redhat.com>
Date:   Wed May 16 08:21:51 2018 +1000

    Merge branch 'drm-next-4.18' of git://people.freedesktop.org/~agd5f/linux into drm-next
    
    Main changes for 4.18.  I'd like to do a separate pull for vega20 later
    this week or next.  Highlights:
    - Reserve pre-OS scanout buffer during init for seemless transition from
      console to driver
    - VEGAM support
    - Improved GPU scheduler documentation
    - Initial gfxoff support for raven
    - SR-IOV fixes
    - Default to non-AGP on PowerPC for radeon
    - Fine grained clock voltage control for vega10
    - Power profiles for vega10
    - Further clean up of powerplay/driver interface
    - Underlay fixes
    - Display link bw updates
    - Gamma fixes
    - Scatter/Gather display support on CZ/ST
    - Misc bug fixes and clean ups
    
    [airlied: fixup v3d vs scheduler API change]
    
    Link: https://patchwork.freedesktop.org/patch/msgid/20180515185450.1113-1-alexander.deucher@amd.com
    Signed-off-by: Dave Airlie <airlied@redhat.com>

commit 1afd30efeddbb1b32cf35d3bf6477b35690eeca6
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Apr 10 13:42:29 2018 +0200

    drm/amdgpu: revert "add new bo flag that indicates BOs don't need fallback (v2)"
    
    This reverts commit 6f51d28bfe8e1a676de5cd877639245bed3cc818.
    
    Makes fallback handling to complicated. This is just a feature for the
    GEM interface and shouldn't leak into the core BO create function.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 68af2f878bc9..e1756b68a17b 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -385,8 +385,7 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 	    amdgpu_bo_in_cpu_visible_vram(bo))
 		p->bytes_moved_vis += ctx.bytes_moved;
 
-	if (unlikely(r == -ENOMEM) && domain != bo->allowed_domains &&
-	    !(bo->flags & AMDGPU_GEM_CREATE_NO_FALLBACK)) {
+	if (unlikely(r == -ENOMEM) && domain != bo->allowed_domains) {
 		domain = bo->allowed_domains;
 		goto retry;
 	}

commit 5422a28fe86f9f77480471385e0a416c27a9ca72
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Apr 5 16:42:03 2018 +0200

    drm/amdgpu: fix and cleanup cpu visible VRAM handling
    
    The detection if a BO was placed in CPU visible VRAM was incorrect.
    
    Fix it and merge it with the correct detection in amdgpu_ttm.c
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index de69ab12bb55..68af2f878bc9 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -382,8 +382,7 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 
 	p->bytes_moved += ctx.bytes_moved;
 	if (adev->gmc.visible_vram_size < adev->gmc.real_vram_size &&
-	    bo->tbo.mem.mem_type == TTM_PL_VRAM &&
-	    bo->tbo.mem.start < adev->gmc.visible_vram_size >> PAGE_SHIFT)
+	    amdgpu_bo_in_cpu_visible_vram(bo))
 		p->bytes_moved_vis += ctx.bytes_moved;
 
 	if (unlikely(r == -ENOMEM) && domain != bo->allowed_domains &&
@@ -437,8 +436,7 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 		/* Good we can try to move this BO somewhere else */
 		update_bytes_moved_vis =
 			adev->gmc.visible_vram_size < adev->gmc.real_vram_size &&
-			bo->tbo.mem.mem_type == TTM_PL_VRAM &&
-			bo->tbo.mem.start < adev->gmc.visible_vram_size >> PAGE_SHIFT;
+			amdgpu_bo_in_cpu_visible_vram(bo);
 		amdgpu_ttm_placement_from_domain(bo, other);
 		r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
 		p->bytes_moved += ctx.bytes_moved;

commit f1018f50d48395b4a189bf8ea9af1e4441209cfd
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Apr 5 14:46:41 2018 +0200

    drm/amdgpu: use ctx bytes_moved
    
    Instead of the global (inaccurate) counter.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index d7d7ce1507ec..de69ab12bb55 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -412,7 +412,6 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 		struct amdgpu_bo_list_entry *candidate = p->evictable;
 		struct amdgpu_bo *bo = candidate->robj;
 		struct amdgpu_device *adev = amdgpu_ttm_adev(bo->tbo.bdev);
-		u64 initial_bytes_moved, bytes_moved;
 		bool update_bytes_moved_vis;
 		uint32_t other;
 
@@ -436,18 +435,15 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 			continue;
 
 		/* Good we can try to move this BO somewhere else */
-		amdgpu_ttm_placement_from_domain(bo, other);
 		update_bytes_moved_vis =
 			adev->gmc.visible_vram_size < adev->gmc.real_vram_size &&
 			bo->tbo.mem.mem_type == TTM_PL_VRAM &&
 			bo->tbo.mem.start < adev->gmc.visible_vram_size >> PAGE_SHIFT;
-		initial_bytes_moved = atomic64_read(&adev->num_bytes_moved);
+		amdgpu_ttm_placement_from_domain(bo, other);
 		r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
-		bytes_moved = atomic64_read(&adev->num_bytes_moved) -
-			initial_bytes_moved;
-		p->bytes_moved += bytes_moved;
+		p->bytes_moved += ctx.bytes_moved;
 		if (update_bytes_moved_vis)
-			p->bytes_moved_vis += bytes_moved;
+			p->bytes_moved_vis += ctx.bytes_moved;
 
 		if (unlikely(r))
 			break;

commit 552825b28ddac200b6080d9e79f4121b68e1517d
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Mon Apr 2 11:20:44 2018 +0800

    drm/amdgpu: add new bo flag that indicates BOs don't need fallback (v2)
    
    user cases:
    1. KFD wraps amdgpu_bo_create, they have no fallback case which is different
    with amdgpu_gem_object_create.
    since upstream branch has no amdgpu_amdkfd_gpuvm.c, which need KFD
    guys add this flag to __alloc_memory_of_gpu:
    +       flags |= AMDGPU_GEM_CREATE_NO_FALLBACK;
    2. UMD can specify this flag for their allocation as well if they like.
    
    v2: squash in merge conflict fix (Chunming)
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Acked-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Cc: felix.kuehling@amd.com
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index dc34b50e6b29..d7d7ce1507ec 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -386,7 +386,8 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 	    bo->tbo.mem.start < adev->gmc.visible_vram_size >> PAGE_SHIFT)
 		p->bytes_moved_vis += ctx.bytes_moved;
 
-	if (unlikely(r == -ENOMEM) && domain != bo->allowed_domains) {
+	if (unlikely(r == -ENOMEM) && domain != bo->allowed_domains &&
+	    !(bo->flags & AMDGPU_GEM_CREATE_NO_FALLBACK)) {
 		domain = bo->allowed_domains;
 		goto retry;
 	}

commit e52482dec8366a98ac380b3bdc1a4abb8a390914
Author: Felix Kuehling <Felix.Kuehling@amd.com>
Date:   Fri Mar 23 15:32:28 2018 -0400

    drm/amdgpu: Add MMU notifier type for KFD userptr
    
    This commit adds the notion of MMU notifier types GFX and HSA. GFX
    continues to work like MMU notifiers did before. HSA adds support for
    KFD userptr BOs. The implementation of KFD userptr eviction is a stub
    for now.
    
    Signed-off-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Reviewed-by: Oded Gabbay <oded.gabbay@gmail.com>
    Signed-off-by: Oded Gabbay <oded.gabbay@gmail.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index dc34b50e6b29..8e66f3702b7c 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -536,7 +536,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	if (p->bo_list) {
 		amdgpu_bo_list_get_list(p->bo_list, &p->validated);
 		if (p->bo_list->first_userptr != p->bo_list->num_entries)
-			p->mn = amdgpu_mn_get(p->adev);
+			p->mn = amdgpu_mn_get(p->adev, AMDGPU_MN_TYPE_GFX);
 	}
 
 	INIT_LIST_HEAD(&duplicates);

commit d330fca11500bebaf7f25b60b7b087bbe8ad0b7f
Author: Roger He <Hongbo.He@amd.com>
Date:   Tue Feb 6 11:22:57 2018 +0800

    drm/ttm: use bit flag to replace allow_reserved_eviction in ttm_operation_ctx
    
    for saving memory and more bit flag can be used in future
    
    Signed-off-by: Roger He <Hongbo.He@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index eaa3cb0c3ad1..dc34b50e6b29 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -346,8 +346,8 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 	struct ttm_operation_ctx ctx = {
 		.interruptible = true,
 		.no_wait_gpu = false,
-		.allow_reserved_eviction = false,
-		.resv = bo->tbo.resv
+		.resv = bo->tbo.resv,
+		.flags = 0
 	};
 	uint32_t domain;
 	int r;

commit a20ee0b1f8b42e2568f3a4408003d22b2dfcc706
Author: Bas Nieuwenhuizen <basni@chromium.org>
Date:   Wed Jan 31 13:58:55 2018 +0100

    drm/amdgpu: Fix always_valid bos multiple LRU insertions.
    
    If these bos are evicted and are in the validated list
    things blow up, so do not put them in there. Notably,
    that tries to add the bo to the LRU twice, which results
    in a BUG_ON in ttm_bo.c.
    
    While for the bo_list an alternative would be to not allow
    always valid bos in there, that does not work for the user
    fence.
    
    v2: Fixed whitespace issue pointed out by checkpatch.pl
    
    Signed-off-by: Bas Nieuwenhuizen <basni@chromium.org>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index fb12a7c6eeac..eaa3cb0c3ad1 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -542,7 +542,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	INIT_LIST_HEAD(&duplicates);
 	amdgpu_vm_get_pd_bo(&fpriv->vm, &p->validated, &p->vm_pd);
 
-	if (p->uf_entry.robj)
+	if (p->uf_entry.robj && !p->uf_entry.robj->parent)
 		list_add(&p->uf_entry.tv.head, &p->validated);
 
 	while (1) {

commit 770d13b19fdf365a99e559f1d47f1380910a947d
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Jan 12 14:52:22 2018 +0100

    drm/amdgpu: move struct amdgpu_mc into amdgpu_gmc.h
    
    And rename it to amdgpu_gmc as well.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Samuel Li <Samuel.Li@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index e80fc38141b5..fb12a7c6eeac 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -257,7 +257,7 @@ static void amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev,
 		return;
 	}
 
-	total_vram = adev->mc.real_vram_size - adev->vram_pin_size;
+	total_vram = adev->gmc.real_vram_size - adev->vram_pin_size;
 	used_vram = amdgpu_vram_mgr_usage(&adev->mman.bdev.man[TTM_PL_VRAM]);
 	free_vram = used_vram >= total_vram ? 0 : total_vram - used_vram;
 
@@ -302,8 +302,8 @@ static void amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev,
 	*max_bytes = us_to_bytes(adev, adev->mm_stats.accum_us);
 
 	/* Do the same for visible VRAM if half of it is free */
-	if (adev->mc.visible_vram_size < adev->mc.real_vram_size) {
-		u64 total_vis_vram = adev->mc.visible_vram_size;
+	if (adev->gmc.visible_vram_size < adev->gmc.real_vram_size) {
+		u64 total_vis_vram = adev->gmc.visible_vram_size;
 		u64 used_vis_vram =
 			amdgpu_vram_mgr_vis_usage(&adev->mman.bdev.man[TTM_PL_VRAM]);
 
@@ -359,7 +359,7 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 	 * to move it. Don't move anything if the threshold is zero.
 	 */
 	if (p->bytes_moved < p->bytes_moved_threshold) {
-		if (adev->mc.visible_vram_size < adev->mc.real_vram_size &&
+		if (adev->gmc.visible_vram_size < adev->gmc.real_vram_size &&
 		    (bo->flags & AMDGPU_GEM_CREATE_CPU_ACCESS_REQUIRED)) {
 			/* And don't move a CPU_ACCESS_REQUIRED BO to limited
 			 * visible VRAM if we've depleted our allowance to do
@@ -381,9 +381,9 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 	r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
 
 	p->bytes_moved += ctx.bytes_moved;
-	if (adev->mc.visible_vram_size < adev->mc.real_vram_size &&
+	if (adev->gmc.visible_vram_size < adev->gmc.real_vram_size &&
 	    bo->tbo.mem.mem_type == TTM_PL_VRAM &&
-	    bo->tbo.mem.start < adev->mc.visible_vram_size >> PAGE_SHIFT)
+	    bo->tbo.mem.start < adev->gmc.visible_vram_size >> PAGE_SHIFT)
 		p->bytes_moved_vis += ctx.bytes_moved;
 
 	if (unlikely(r == -ENOMEM) && domain != bo->allowed_domains) {
@@ -437,9 +437,9 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 		/* Good we can try to move this BO somewhere else */
 		amdgpu_ttm_placement_from_domain(bo, other);
 		update_bytes_moved_vis =
-			adev->mc.visible_vram_size < adev->mc.real_vram_size &&
+			adev->gmc.visible_vram_size < adev->gmc.real_vram_size &&
 			bo->tbo.mem.mem_type == TTM_PL_VRAM &&
-			bo->tbo.mem.start < adev->mc.visible_vram_size >> PAGE_SHIFT;
+			bo->tbo.mem.start < adev->gmc.visible_vram_size >> PAGE_SHIFT;
 		initial_bytes_moved = atomic64_read(&adev->num_bytes_moved);
 		r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
 		bytes_moved = atomic64_read(&adev->num_bytes_moved) -

commit 0abc6878fc2d6990d8b0851b55d3c77ecfdd74e6
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Sep 1 20:37:57 2017 +0200

    drm/amdgpu: update VM PDs after the PTs
    
    Necessary for the next patch.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Acked-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 5e539fc5b05f..e80fc38141b5 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -778,10 +778,6 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 	struct amdgpu_bo *bo;
 	int i, r;
 
-	r = amdgpu_vm_update_directories(adev, vm);
-	if (r)
-		return r;
-
 	r = amdgpu_vm_clear_freed(adev, vm, NULL);
 	if (r)
 		return r;
@@ -839,6 +835,10 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 	if (r)
 		return r;
 
+	r = amdgpu_vm_update_directories(adev, vm);
+	if (r)
+		return r;
+
 	r = amdgpu_sync_fence(adev, &p->job->sync, vm->last_update, false);
 	if (r)
 		return r;

commit 9251859a9adb8e5906402acc9d705149d937bf8b
Author: Roger He <Hongbo.He@amd.com>
Date:   Fri Dec 8 13:31:52 2017 +0800

    drm/amdgpu: set allow_reserved_eviction and resv when bo allocation and cs
    
    enable eviction of other per VM BOs during allocation and allows
    reaping of deleted BOs during CS.
    
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Roger He <Hongbo.He@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 44523a88ebb2..5e539fc5b05f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -343,7 +343,12 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 				 struct amdgpu_bo *bo)
 {
 	struct amdgpu_device *adev = amdgpu_ttm_adev(bo->tbo.bdev);
-	struct ttm_operation_ctx ctx = { true, false };
+	struct ttm_operation_ctx ctx = {
+		.interruptible = true,
+		.no_wait_gpu = false,
+		.allow_reserved_eviction = false,
+		.resv = bo->tbo.resv
+	};
 	uint32_t domain;
 	int r;
 

commit 1b1f42d8fde4fef1ed7873bf5aa91755f8c3de35
Author: Lucas Stach <l.stach@pengutronix.de>
Date:   Wed Dec 6 17:49:39 2017 +0100

    drm: move amd_gpu_scheduler into common location
    
    This moves and renames the AMDGPU scheduler to a common location in DRM
    in order to facilitate re-use by other drivers. This is mostly a straight
    forward rename with no code changes.
    
    One notable exception is the function to_drm_sched_fence(), which is no
    longer a inline header function to avoid the need to export the
    drm_sched_fence_ops_scheduled and drm_sched_fence_ops_finished structures.
    
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Tested-by: Dieter Nützel <Dieter@nuetzel-hh.de>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Lucas Stach <l.stach@pengutronix.de>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 4cea9ab237ac..44523a88ebb2 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1150,7 +1150,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 			    union drm_amdgpu_cs *cs)
 {
 	struct amdgpu_ring *ring = p->job->ring;
-	struct amd_sched_entity *entity = &p->ctx->rings[ring->idx].entity;
+	struct drm_sched_entity *entity = &p->ctx->rings[ring->idx].entity;
 	struct amdgpu_job *job;
 	unsigned i;
 	uint64_t seq;
@@ -1173,7 +1173,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	job = p->job;
 	p->job = NULL;
 
-	r = amd_sched_job_init(&job->base, &ring->sched, entity, p->filp);
+	r = drm_sched_job_init(&job->base, &ring->sched, entity, p->filp);
 	if (r) {
 		amdgpu_job_free(job);
 		amdgpu_mn_unlock(p->mn);
@@ -1202,7 +1202,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	amdgpu_ring_priority_get(job->ring, job->base.s_priority);
 
 	trace_amdgpu_cs_ioctl(job);
-	amd_sched_entity_push_job(&job->base, entity);
+	drm_sched_entity_push_job(&job->base, entity);
 
 	ttm_eu_fence_buffer_objects(&p->ticket, &p->validated, p->fence);
 	amdgpu_mn_unlock(p->mn);

commit cebb52b7bc325863600aff930407bba773010938
Author: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
Date:   Mon Nov 13 14:47:52 2017 -0500

    drm/amdgpu: Get rid of dep_sync as a seperate object.
    
    Instead mark fence as explicit in it's amdgpu_sync_entry.
    
    v2:
    Fix use after free bug and add new parameter description.
    Signed-off-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 93d3cef66503..4cea9ab237ac 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -786,7 +786,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 		return r;
 
 	r = amdgpu_sync_fence(adev, &p->job->sync,
-			      fpriv->prt_va->last_pt_update);
+			      fpriv->prt_va->last_pt_update, false);
 	if (r)
 		return r;
 
@@ -800,7 +800,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 			return r;
 
 		f = bo_va->last_pt_update;
-		r = amdgpu_sync_fence(adev, &p->job->sync, f);
+		r = amdgpu_sync_fence(adev, &p->job->sync, f, false);
 		if (r)
 			return r;
 	}
@@ -823,7 +823,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 				return r;
 
 			f = bo_va->last_pt_update;
-			r = amdgpu_sync_fence(adev, &p->job->sync, f);
+			r = amdgpu_sync_fence(adev, &p->job->sync, f, false);
 			if (r)
 				return r;
 		}
@@ -834,7 +834,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 	if (r)
 		return r;
 
-	r = amdgpu_sync_fence(adev, &p->job->sync, vm->last_update);
+	r = amdgpu_sync_fence(adev, &p->job->sync, vm->last_update, false);
 	if (r)
 		return r;
 
@@ -1038,8 +1038,8 @@ static int amdgpu_cs_process_fence_dep(struct amdgpu_cs_parser *p,
 			amdgpu_ctx_put(ctx);
 			return r;
 		} else if (fence) {
-			r = amdgpu_sync_fence(p->adev, &p->job->dep_sync,
-					      fence);
+			r = amdgpu_sync_fence(p->adev, &p->job->sync, fence,
+					true);
 			dma_fence_put(fence);
 			amdgpu_ctx_put(ctx);
 			if (r)
@@ -1058,7 +1058,7 @@ static int amdgpu_syncobj_lookup_and_add_to_sync(struct amdgpu_cs_parser *p,
 	if (r)
 		return r;
 
-	r = amdgpu_sync_fence(p->adev, &p->job->dep_sync, fence);
+	r = amdgpu_sync_fence(p->adev, &p->job->sync, fence, true);
 	dma_fence_put(fence);
 
 	return r;

commit bb7939b2030ab55acd203c86160c37db22f5796a
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Nov 6 15:37:01 2017 +0100

    drm/amdgpu: fix VA hole handling on Vega10 v3
    
    Similar to the CPU address space the VA on Vega10 has a hole in it.
    
    v2: use dev_dbg instead of dev_err
    v3: add some more comments to explain how the hw works
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    CC: stable@vger.kernel.org
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 5e89d7a7178f..93d3cef66503 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -870,8 +870,8 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 			struct amdgpu_bo_va_mapping *m;
 			struct amdgpu_bo *aobj = NULL;
 			struct amdgpu_cs_chunk *chunk;
+			uint64_t offset, va_start;
 			struct amdgpu_ib *ib;
-			uint64_t offset;
 			uint8_t *kptr;
 
 			chunk = &p->chunks[i];
@@ -881,14 +881,14 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 			if (chunk->chunk_id != AMDGPU_CHUNK_ID_IB)
 				continue;
 
-			r = amdgpu_cs_find_mapping(p, chunk_ib->va_start,
-						   &aobj, &m);
+			va_start = chunk_ib->va_start & AMDGPU_VA_HOLE_MASK;
+			r = amdgpu_cs_find_mapping(p, va_start, &aobj, &m);
 			if (r) {
 				DRM_ERROR("IB va_start is invalid\n");
 				return r;
 			}
 
-			if ((chunk_ib->va_start + chunk_ib->ib_bytes) >
+			if ((va_start + chunk_ib->ib_bytes) >
 			    (m->last + 1) * AMDGPU_GPU_PAGE_SIZE) {
 				DRM_ERROR("IB va_start+ib_bytes is invalid\n");
 				return -EINVAL;
@@ -901,7 +901,7 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 			}
 
 			offset = m->start * AMDGPU_GPU_PAGE_SIZE;
-			kptr += chunk_ib->va_start - offset;
+			kptr += va_start - offset;
 
 			memcpy(ib->ptr, kptr, chunk_ib->ib_bytes);
 			amdgpu_bo_kunmap(aobj);

commit 6af046d26f34278eacd6ecddb37170624f6d4251
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Apr 27 18:20:47 2017 +0200

    drm/amdgpu: use the new TTM bytes moved counter v2
    
    Instead of the global statistics use the per context bytes moved counter.
    
    v2: rebased
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Tested-by: Dieter Nützel <Dieter@nuetzel-hh.de>
    Tested-by: Michel Dänzer <michel.daenzer@amd.com>
    Acked-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index faab662ce680..5e89d7a7178f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -344,7 +344,6 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 {
 	struct amdgpu_device *adev = amdgpu_ttm_adev(bo->tbo.bdev);
 	struct ttm_operation_ctx ctx = { true, false };
-	u64 initial_bytes_moved, bytes_moved;
 	uint32_t domain;
 	int r;
 
@@ -374,15 +373,13 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 
 retry:
 	amdgpu_ttm_placement_from_domain(bo, domain);
-	initial_bytes_moved = atomic64_read(&adev->num_bytes_moved);
 	r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
-	bytes_moved = atomic64_read(&adev->num_bytes_moved) -
-		      initial_bytes_moved;
-	p->bytes_moved += bytes_moved;
+
+	p->bytes_moved += ctx.bytes_moved;
 	if (adev->mc.visible_vram_size < adev->mc.real_vram_size &&
 	    bo->tbo.mem.mem_type == TTM_PL_VRAM &&
 	    bo->tbo.mem.start < adev->mc.visible_vram_size >> PAGE_SHIFT)
-		p->bytes_moved_vis += bytes_moved;
+		p->bytes_moved_vis += ctx.bytes_moved;
 
 	if (unlikely(r == -ENOMEM) && domain != bo->allowed_domains) {
 		domain = bo->allowed_domains;

commit 19be5570107108fba772bc2e3a1eb22ec32fb021
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Apr 12 14:24:39 2017 +0200

    drm/ttm: add operation ctx to ttm_bo_validate v2
    
    Give moving a BO into place an operation context to work with.
    
    v2: rebased
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Tested-by: Dieter Nützel <Dieter@nuetzel-hh.de>
    Tested-by: Michel Dänzer <michel.daenzer@amd.com>
    Acked-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 743875ad4404..faab662ce680 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -343,6 +343,7 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 				 struct amdgpu_bo *bo)
 {
 	struct amdgpu_device *adev = amdgpu_ttm_adev(bo->tbo.bdev);
+	struct ttm_operation_ctx ctx = { true, false };
 	u64 initial_bytes_moved, bytes_moved;
 	uint32_t domain;
 	int r;
@@ -374,7 +375,7 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 retry:
 	amdgpu_ttm_placement_from_domain(bo, domain);
 	initial_bytes_moved = atomic64_read(&adev->num_bytes_moved);
-	r = ttm_bo_validate(&bo->tbo, &bo->placement, true, false);
+	r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
 	bytes_moved = atomic64_read(&adev->num_bytes_moved) -
 		      initial_bytes_moved;
 	p->bytes_moved += bytes_moved;
@@ -396,6 +397,7 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 				struct amdgpu_bo *validated)
 {
 	uint32_t domain = validated->allowed_domains;
+	struct ttm_operation_ctx ctx = { true, false };
 	int r;
 
 	if (!p->evictable)
@@ -437,7 +439,7 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 			bo->tbo.mem.mem_type == TTM_PL_VRAM &&
 			bo->tbo.mem.start < adev->mc.visible_vram_size >> PAGE_SHIFT;
 		initial_bytes_moved = atomic64_read(&adev->num_bytes_moved);
-		r = ttm_bo_validate(&bo->tbo, &bo->placement, true, false);
+		r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
 		bytes_moved = atomic64_read(&adev->num_bytes_moved) -
 			initial_bytes_moved;
 		p->bytes_moved += bytes_moved;
@@ -476,6 +478,7 @@ static int amdgpu_cs_validate(void *param, struct amdgpu_bo *bo)
 static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 			    struct list_head *validated)
 {
+	struct ttm_operation_ctx ctx = { true, false };
 	struct amdgpu_bo_list_entry *lobj;
 	int r;
 
@@ -493,8 +496,7 @@ static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 		    lobj->user_pages) {
 			amdgpu_ttm_placement_from_domain(bo,
 							 AMDGPU_GEM_DOMAIN_CPU);
-			r = ttm_bo_validate(&bo->tbo, &bo->placement, true,
-					    false);
+			r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
 			if (r)
 				return r;
 			amdgpu_ttm_tt_set_user_pages(bo->tbo.ttm,
@@ -1575,6 +1577,7 @@ int amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 			   struct amdgpu_bo_va_mapping **map)
 {
 	struct amdgpu_fpriv *fpriv = parser->filp->driver_priv;
+	struct ttm_operation_ctx ctx = { false, false };
 	struct amdgpu_vm *vm = &fpriv->vm;
 	struct amdgpu_bo_va_mapping *mapping;
 	int r;
@@ -1595,8 +1598,7 @@ int amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 	if (!((*bo)->flags & AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS)) {
 		(*bo)->flags |= AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS;
 		amdgpu_ttm_placement_from_domain(*bo, (*bo)->allowed_domains);
-		r = ttm_bo_validate(&(*bo)->tbo, &(*bo)->placement, false,
-				    false);
+		r = ttm_bo_validate(&(*bo)->tbo, &(*bo)->placement, &ctx);
 		if (r)
 			return r;
 	}

commit 6f16b4fb60011cbc7d4530e112739ea4416c6ea6
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Mon Nov 13 10:51:57 2017 +0800

    drm/amdgpu: use dep_sync for CS dependency/syncobj
    
    Otherwise, they could be optimized by scheduled fence.
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index bc3a7500fbbd..743875ad4404 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1039,7 +1039,7 @@ static int amdgpu_cs_process_fence_dep(struct amdgpu_cs_parser *p,
 			amdgpu_ctx_put(ctx);
 			return r;
 		} else if (fence) {
-			r = amdgpu_sync_fence(p->adev, &p->job->sync,
+			r = amdgpu_sync_fence(p->adev, &p->job->dep_sync,
 					      fence);
 			dma_fence_put(fence);
 			amdgpu_ctx_put(ctx);
@@ -1059,7 +1059,7 @@ static int amdgpu_syncobj_lookup_and_add_to_sync(struct amdgpu_cs_parser *p,
 	if (r)
 		return r;
 
-	r = amdgpu_sync_fence(p->adev, &p->job->sync, fence);
+	r = amdgpu_sync_fence(p->adev, &p->job->dep_sync, fence);
 	dma_fence_put(fence);
 
 	return r;

commit c5835bbb1195996c6c5bf2bf2cdbae08c936fc93
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Oct 27 15:43:14 2017 +0200

    drm/amdgpu: rename amdgpu_ttm_bind to amdgpu_ttm_alloc_gart
    
    We actually don't bind here, but rather allocate GART space if necessary.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 43df84c13f21..bc3a7500fbbd 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -684,7 +684,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	if (!r && p->uf_entry.robj) {
 		struct amdgpu_bo *uf = p->uf_entry.robj;
 
-		r = amdgpu_ttm_bind(&uf->tbo);
+		r = amdgpu_ttm_alloc_gart(&uf->tbo);
 		p->job->uf_addr += amdgpu_bo_gpu_offset(uf);
 	}
 
@@ -1601,5 +1601,5 @@ int amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 			return r;
 	}
 
-	return amdgpu_ttm_bind(&(*bo)->tbo);
+	return amdgpu_ttm_alloc_gart(&(*bo)->tbo);
 }

commit 4ff23be3d50a142ed0787fa6f276afc02ac2577d
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Oct 16 17:24:21 2017 +0200

    drm/amdgpu: remove extra parameter from amdgpu_ttm_bind() v2
    
    We always use the BO mem now.
    
    v2: minor rebase
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index bf1aad00bb8d..43df84c13f21 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -684,7 +684,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	if (!r && p->uf_entry.robj) {
 		struct amdgpu_bo *uf = p->uf_entry.robj;
 
-		r = amdgpu_ttm_bind(&uf->tbo, &uf->tbo.mem);
+		r = amdgpu_ttm_bind(&uf->tbo);
 		p->job->uf_addr += amdgpu_bo_gpu_offset(uf);
 	}
 
@@ -1601,5 +1601,5 @@ int amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 			return r;
 	}
 
-	return amdgpu_ttm_bind(&(*bo)->tbo, &(*bo)->tbo.mem);
+	return amdgpu_ttm_bind(&(*bo)->tbo);
 }

commit a4176cb484ac457a08b44c93da06fce09c6e281c
Author: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
Date:   Tue Oct 24 13:30:16 2017 -0400

    drm/amdgpu: Remove job->s_entity to avoid keeping reference to stale pointer.
    
    Signed-off-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 16947bad5b49..bf1aad00bb8d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1203,7 +1203,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	amdgpu_ring_priority_get(job->ring, job->base.s_priority);
 
 	trace_amdgpu_cs_ioctl(job);
-	amd_sched_entity_push_job(&job->base);
+	amd_sched_entity_push_job(&job->base, entity);
 
 	ttm_eu_fence_buffer_objects(&p->ticket, &p->validated, p->fence);
 	amdgpu_mn_unlock(p->mn);

commit 7716ea564f6538236c34749cdf3a6351c2844c1a
Author: Monk Liu <Monk.Liu@amd.com>
Date:   Tue Oct 17 12:08:02 2017 +0800

    drm/amdgpu:skip job for guilty ctx in parser_init
    
    Signed-off-by: Monk Liu <Monk.Liu@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index b4b3ecf9f96d..16947bad5b49 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -90,6 +90,12 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		goto free_chunk;
 	}
 
+	/* skip guilty context job */
+	if (atomic_read(&p->ctx->guilty) == 1) {
+		ret = -ECANCELED;
+		goto free_chunk;
+	}
+
 	mutex_lock(&p->ctx->lock);
 
 	/* get chunks */

commit d1f6dc1a9a106a73510181cfad9b4a7a0b140990
Author: Andrey Grodzovsky <Andrey.Grodzovsky@amd.com>
Date:   Thu Oct 19 14:29:46 2017 -0400

    drm/amdgpu: Avoid accessing job->entity after the job is scheduled.
    
    Bug: amdgpu_job_free_cb was accessing s_job->s_entity when the allocated
    amdgpu_ctx (and the entity inside it) were already deallocated from
    amdgpu_cs_parser_fini.
    
    Fix: Save job's priority on it's creation instead of accessing it from
    s_entity later on.
    
    Signed-off-by: Andrey Grodzovsky <Andrey.Grodzovsky@amd.com>
    Reviewed-by: Andres Rodriguez <andresx7@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 57abf7abd7a9..b4b3ecf9f96d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1194,8 +1194,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	job->uf_sequence = seq;
 
 	amdgpu_job_free_resources(job);
-	amdgpu_ring_priority_get(job->ring,
-				 amd_sched_get_job_priority(&job->base));
+	amdgpu_ring_priority_get(job->ring, job->base.s_priority);
 
 	trace_amdgpu_cs_ioctl(job);
 	amd_sched_entity_push_job(&job->base);

commit 6edc6910ba4cd6eab309263539c8f09b8ad772bf
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Nov 24 11:39:30 2017 +0100

    drm/amdgpu: don't try to move pinned BOs
    
    Never try to move pinned BOs during CS.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index a57cec737c18..57abf7abd7a9 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -409,6 +409,10 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 		if (candidate->robj == validated)
 			break;
 
+		/* We can't move pinned BOs here */
+		if (bo->pin_count)
+			continue;
+
 		other = amdgpu_mem_type_to_domain(bo->tbo.mem.mem_type);
 
 		/* Check if this BO is in one of the domains we need space for */

commit c353bfc6ebc1073f2f0af72a15f8f18db7193d2e
Merge: 1d3bc6363a7d 98ecf1a30897
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Nov 23 21:04:56 2017 -1000

    Merge tag 'drm-for-v4.15-part2' of git://people.freedesktop.org/~airlied/linux
    
    Pull more drm updates from Dave Airlie:
     "Fixes/cleanups for rc1, non-desktop flags for VR
    
       - remove the MSM dt-bindings file Rob managed to push in the previous
         pull.
    
       - add a property/edid quirk to denote HMD devices, I had these
         hanging around for a few weeks and Keith had done some work on
         them, they are fairly self contained and small, and only affect
         people using HTC Vive VR headsets so far.
    
       - amdgpu, tegra, tilcdc, fsl fixes
    
       - some imx-drm cleanups I missed, these seemed pretty small, and no
         reason to hold off.
    
      I have one TTM regression fix (fixes bochs-vga in qemu) sitting
      locally awaiting review I'll probably send that in a separate pull
      request tomorrow"
    
    * tag 'drm-for-v4.15-part2' of git://people.freedesktop.org/~airlied/linux: (33 commits)
      dt-bindings: remove file that was added accidentally
      drm/edid: quirk HTC vive headset as non-desktop. [v2]
      drm/fb: add support for not enabling fbcon on non-desktop displays [v2]
      drm: add connector info/property for non-desktop displays [v2]
      drm/amdgpu: fix rmmod KCQ disable failed error
      drm/amdgpu: fix kernel hang when starting VNC server
      drm/amdgpu: don't skip attributes when powerplay is enabled
      drm/amd/pp: fix typecast error in powerplay.
      drm/tilcdc: Remove obsolete "ti,tilcdc,slave" dts binding support
      drm/tegra: sor: Reimplement pad clock
      Revert "drm/radeon: dont switch vt on suspend"
      drm/amd/amdgpu: fix over-bound accessing in amdgpu_cs_wait_any_fence
      drm/amd/powerplay: fix unfreeze level smc message for smu7
      drm/amdgpu:fix memleak
      drm/amdgpu:fix memleak in takedown
      drm/amd/pp: fix dpm randomly failed on Vega10
      drm/amdgpu: set f_mapping on exported DMA-bufs
      drm/amdgpu: Properly allocate VM invalidate eng v2
      drm/fsl-dcu: enable IRQ before drm_atomic_helper_resume()
      drm/fsl-dcu: avoid disabling pixel clock twice on suspend
      ...

commit eb174c77e258f93b0f1046afd23a0aede68be3f2
Author: Roger He <Hongbo.He@amd.com>
Date:   Fri Nov 17 12:45:18 2017 +0800

    drm/amd/amdgpu: fix over-bound accessing in amdgpu_cs_wait_any_fence
    
    Fixes an oops in amdgpu_cs_wait_any_fence.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Roger He <Hongbo.He@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 146e05f21d35..bdef497a6a26 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1498,7 +1498,7 @@ static int amdgpu_cs_wait_any_fence(struct amdgpu_device *adev,
 	wait->out.status = (r > 0);
 	wait->out.first_signaled = first;
 
-	if (array[first])
+	if (first < fence_count && array[first])
 		r = array[first]->error;
 	else
 		r = 0;

commit e60e1ee60630cafef5e430c2ae364877e061d980
Merge: 5d352e69c60e f150891fd987
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Nov 15 20:42:10 2017 -0800

    Merge tag 'drm-for-v4.15' of git://people.freedesktop.org/~airlied/linux
    
    Pull drm updates from Dave Airlie:
     "This is the main drm pull request for v4.15.
    
      Core:
       - Atomic object lifetime fixes
       - Atomic iterator improvements
       - Sparse/smatch fixes
       - Legacy kms ioctls to be interruptible
       - EDID override improvements
       - fb/gem helper cleanups
       - Simple outreachy patches
       - Documentation improvements
       - Fix dma-buf rcu races
       - DRM mode object leasing for improving VR use cases.
       - vgaarb improvements for non-x86 platforms.
    
      New driver:
       - tve200: Faraday Technology TVE200 block.
    
         This "TV Encoder" encodes a ITU-T BT.656 stream and can be found in
         the StorLink SL3516 (later Cortina Systems CS3516) as well as the
         Grain Media GM8180.
    
      New bridges:
       - SiI9234 support
    
      New panels:
       - S6E63J0X03, OTM8009A, Seiko 43WVF1G, 7" rpi touch panel, Toshiba
         LT089AC19000, Innolux AT043TN24
    
      i915:
       - Remove Coffeelake from alpha support
       - Cannonlake workarounds
       - Infoframe refactoring for DisplayPort
       - VBT updates
       - DisplayPort vswing/emph/buffer translation refactoring
       - CCS fixes
       - Restore GPU clock boost on missed vblanks
       - Scatter list updates for userptr allocations
       - Gen9+ transition watermarks
       - Display IPC (Isochronous Priority Control)
       - Private PAT management
       - GVT: improved error handling and pci config sanitizing
       - Execlist refactoring
       - Transparent Huge Page support
       - User defined priorities support
       - HuC/GuC firmware refactoring
       - DP MST fixes
       - eDP power sequencing fixes
       - Use RCU instead of stop_machine
       - PSR state tracking support
       - Eviction fixes
       - BDW DP aux channel timeout fixes
       - LSPCON fixes
       - Cannonlake PLL fixes
    
      amdgpu:
       - Per VM BO support
       - Powerplay cleanups
       - CI powerplay support
       - PASID mgr for kfd
       - SR-IOV fixes
       - initial GPU reset for vega10
       - Prime mmap support
       - TTM updates
       - Clock query interface for Raven
       - Fence to handle ioctl
       - UVD encode ring support on Polaris
       - Transparent huge page DMA support
       - Compute LRU pipe tweaks
       - BO flag to allow buffers to opt out of implicit sync
       - CTX priority setting API
       - VRAM lost infrastructure plumbing
    
      qxl:
       - fix flicker since atomic rework
    
      amdkfd:
       - Further improvements from internal AMD tree
       - Usermode events
       - Drop radeon support
    
      nouveau:
       - Pascal temperature sensor support
       - Improved BAR2 handling
       - MMU rework to support Pascal MMU
    
      exynos:
       - Improved HDMI/mixer support
       - HDMI audio interface support
    
      tegra:
       - Prep work for tegra186
       - Cleanup/fixes
    
      msm:
       - Preemption support for a5xx
       - Display fixes for 8x96 (snapdragon 820)
       - Async cursor plane fixes
       - FW loading rework
       - GPU debugging improvements
    
      vc4:
       - Prep for DSI panels
       - fix T-format tiling scanout
       - New madvise ioctl
    
      Rockchip:
       - LVDS support
    
      omapdrm:
       - omap4 HDMI CEC support
    
      etnaviv:
       - GPU performance counters groundwork
    
      sun4i:
       - refactor driver load + TCON backend
       - HDMI improvements
       - A31 support
       - Misc fixes
    
      udl:
       - Probe/EDID read fixes.
    
      tilcdc:
       - Misc fixes.
    
      pl111:
       - Support more variants
    
      adv7511:
       - Improve EDID handling.
       - HDMI CEC support
    
      sii8620:
       - Add remote control support"
    
    * tag 'drm-for-v4.15' of git://people.freedesktop.org/~airlied/linux: (1480 commits)
      drm/rockchip: analogix_dp: Use mutex rather than spinlock
      drm/mode_object: fix documentation for object lookups.
      drm/i915: Reorder context-close to avoid calling i915_vma_close() under RCU
      drm/i915: Move init_clock_gating() back to where it was
      drm/i915: Prune the reservation shared fence array
      drm/i915: Idle the GPU before shinking everything
      drm/i915: Lock llist_del_first() vs llist_del_all()
      drm/i915: Calculate ironlake intermediate watermarks correctly, v2.
      drm/i915: Disable lazy PPGTT page table optimization for vGPU
      drm/i915/execlists: Remove the priority "optimisation"
      drm/i915: Filter out spurious execlists context-switch interrupts
      drm/amdgpu: use irq-safe lock for kiq->ring_lock
      drm/amdgpu: bypass lru touch for KIQ ring submission
      drm/amdgpu: Potential uninitialized variable in amdgpu_vm_update_directories()
      drm/amdgpu: potential uninitialized variable in amdgpu_vce_ring_parse_cs()
      drm/amd/powerplay: initialize a variable before using it
      drm/amd/powerplay: suppress KASAN out of bounds warning in vega10_populate_all_memory_levels
      drm/amd/amdgpu: fix evicted VRAM bo adjudgement condition
      drm/vblank: Tune drm_crtc_accurate_vblank_count() WARN down to a debug
      drm/rockchip: add CONFIG_OF dependency for lvds
      ...

commit c6f92f9fbe7dbcc8903a67229aa88b4077ae4422
Author: Mel Gorman <mgorman@techsingularity.net>
Date:   Wed Nov 15 17:37:55 2017 -0800

    mm: remove cold parameter for release_pages
    
    All callers of release_pages claim the pages being released are cache
    hot.  As no one cares about the hotness of pages being released to the
    allocator, just ditch the parameter.
    
    No performance impact is expected as the overhead is marginal.  The
    parameter is removed simply because it is a bit stupid to have a useless
    parameter copied everywhere.
    
    Link: http://lkml.kernel.org/r/20171018075952.10627-7-mgorman@techsingularity.net
    Signed-off-by: Mel Gorman <mgorman@techsingularity.net>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 60d8bedb694d..cd664832f9e8 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -553,8 +553,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 				 * invalidated it. Free it and try again
 				 */
 				release_pages(e->user_pages,
-					      e->robj->tbo.ttm->num_pages,
-					      false);
+					      e->robj->tbo.ttm->num_pages);
 				kvfree(e->user_pages);
 				e->user_pages = NULL;
 			}
@@ -691,8 +690,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 				continue;
 
 			release_pages(e->user_pages,
-				      e->robj->tbo.ttm->num_pages,
-				      false);
+				      e->robj->tbo.ttm->num_pages);
 			kvfree(e->user_pages);
 		}
 	}

commit cdadab89f8cc37dd6101e2bbab50037d72e0e1d0
Author: Emily Deng <Emily.Deng@amd.com>
Date:   Thu Nov 9 17:18:18 2017 +0800

    drm/amdgpu: Fix null pointer issue in amdgpu_cs_wait_any_fence
    
    The array[first] may be null when the fence has already been signaled.
    
    BUG: SWDEV-136239
    
    Signed-off-by: Emily Deng <Emily.Deng@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index f7fceb63413c..146e05f21d35 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1497,8 +1497,11 @@ static int amdgpu_cs_wait_any_fence(struct amdgpu_device *adev,
 	memset(wait, 0, sizeof(*wait));
 	wait->out.status = (r > 0);
 	wait->out.first_signaled = first;
-	/* set return value 0 to indicate success */
-	r = array[first]->error;
+
+	if (array[first])
+		r = array[first]->error;
+	else
+		r = 0;
 
 err_free_fence_array:
 	for (i = 0; i < fence_count; i++)

commit 4b6b691ee38abae8842aed61d442dfb315c45789
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Oct 16 10:32:04 2017 +0200

    drm/amdgpu: linear validate first then bind to GART
    
    For VM emulation for old UVD/VCE we need to validate the BO with linear
    VRAM flag set first and then eventually bind it to GART.
    
    Validating with linear VRAM flag set can move the BO to GART making
    UVD/VCE read/write from an unbound GART BO.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    CC: stable@vger.kernel.org
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 32cf83e2f2d9..f7fceb63413c 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1582,14 +1582,14 @@ int amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 	if (READ_ONCE((*bo)->tbo.resv->lock.ctx) != &parser->ticket)
 		return -EINVAL;
 
-	r = amdgpu_ttm_bind(&(*bo)->tbo, &(*bo)->tbo.mem);
-	if (unlikely(r))
-		return r;
-
-	if ((*bo)->flags & AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS)
-		return 0;
+	if (!((*bo)->flags & AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS)) {
+		(*bo)->flags |= AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS;
+		amdgpu_ttm_placement_from_domain(*bo, (*bo)->allowed_domains);
+		r = ttm_bo_validate(&(*bo)->tbo, &(*bo)->placement, false,
+				    false);
+		if (r)
+			return r;
+	}
 
-	(*bo)->flags |= AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS;
-	amdgpu_ttm_placement_from_domain(*bo, (*bo)->allowed_domains);
-	return ttm_bo_validate(&(*bo)->tbo, &(*bo)->placement, false, false);
+	return amdgpu_ttm_bind(&(*bo)->tbo, &(*bo)->tbo.mem);
 }

commit c70b78a71e9a283240f72dfdfff8fd2388db51da
Author: Monk Liu <Monk.Liu@amd.com>
Date:   Mon Oct 16 20:02:08 2017 +0800

    drm/amdgpu:fix duplicated setting job's vram_lost
    
    Signed-off-by: Monk Liu <Monk.Liu@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 52dd78ee8fd0..32cf83e2f2d9 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -172,7 +172,6 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	if (ret)
 		goto free_all_kdata;
 
-	p->job->vram_lost_counter = atomic_read(&p->adev->vram_lost_counter);
 	if (p->ctx->vram_lost_counter != p->job->vram_lost_counter) {
 		ret = -ECANCELED;
 		goto free_all_kdata;

commit c5795c555bbaca51192ffc6164bb85845ecdf717
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Oct 12 12:16:33 2017 +0200

    drm/amdgpu: minor CS optimization
    
    We only need to loop over all IBs for old UVD/VCE command stream patching.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index dfd37785563f..52dd78ee8fd0 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -853,36 +853,37 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_vm *vm = &fpriv->vm;
 	struct amdgpu_ring *ring = p->job->ring;
-	int i, j, r;
-
-	for (i = 0, j = 0; i < p->nchunks && j < p->job->num_ibs; i++) {
-
-		struct amdgpu_cs_chunk *chunk;
-		struct amdgpu_ib *ib;
-		struct drm_amdgpu_cs_chunk_ib *chunk_ib;
-
-		chunk = &p->chunks[i];
-		ib = &p->job->ibs[j];
-		chunk_ib = (struct drm_amdgpu_cs_chunk_ib *)chunk->kdata;
+	int r;
 
-		if (chunk->chunk_id != AMDGPU_CHUNK_ID_IB)
-			continue;
+	/* Only for UVD/VCE VM emulation */
+	if (p->job->ring->funcs->parse_cs) {
+		unsigned i, j;
 
-		if (p->job->ring->funcs->parse_cs) {
+		for (i = 0, j = 0; i < p->nchunks && j < p->job->num_ibs; i++) {
+			struct drm_amdgpu_cs_chunk_ib *chunk_ib;
 			struct amdgpu_bo_va_mapping *m;
 			struct amdgpu_bo *aobj = NULL;
+			struct amdgpu_cs_chunk *chunk;
+			struct amdgpu_ib *ib;
 			uint64_t offset;
 			uint8_t *kptr;
 
+			chunk = &p->chunks[i];
+			ib = &p->job->ibs[j];
+			chunk_ib = chunk->kdata;
+
+			if (chunk->chunk_id != AMDGPU_CHUNK_ID_IB)
+				continue;
+
 			r = amdgpu_cs_find_mapping(p, chunk_ib->va_start,
-					&aobj, &m);
+						   &aobj, &m);
 			if (r) {
 				DRM_ERROR("IB va_start is invalid\n");
 				return r;
 			}
 
 			if ((chunk_ib->va_start + chunk_ib->ib_bytes) >
-				(m->last + 1) * AMDGPU_GPU_PAGE_SIZE) {
+			    (m->last + 1) * AMDGPU_GPU_PAGE_SIZE) {
 				DRM_ERROR("IB va_start+ib_bytes is invalid\n");
 				return -EINVAL;
 			}
@@ -899,12 +900,12 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 			memcpy(ib->ptr, kptr, chunk_ib->ib_bytes);
 			amdgpu_bo_kunmap(aobj);
 
-			/* Only for UVD/VCE VM emulation */
 			r = amdgpu_ring_parse_cs(ring, p, j);
 			if (r)
 				return r;
+
+			j++;
 		}
-		j++;
 	}
 
 	if (p->job->vm) {

commit 26eedf6daec4e7937c8f0f1dde5e9b8e3dcebfd3
Author: Andrey Grodzovsky <Andrey.Grodzovsky@amd.com>
Date:   Wed Oct 11 17:02:02 2017 -0400

    drm/amdgpu: Fix extra call to amdgpu_ctx_put.
    
    In amdgpu_cs_parser_init() in case of error handling
    amdgpu_ctx_put() is called without setting p->ctx to NULL after that,
    later amdgpu_cs_parser_fini() also calls amdgpu_ctx_put() again and
    mess up the reference count.
    
    Signed-off-by: Andrey Grodzovsky <Andrey.Grodzovsky@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 2ae5d523ca10..dfd37785563f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -97,7 +97,7 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	if (copy_from_user(chunk_array, chunk_array_user,
 			   sizeof(uint64_t)*cs->in.num_chunks)) {
 		ret = -EFAULT;
-		goto put_ctx;
+		goto free_chunk;
 	}
 
 	p->nchunks = cs->in.num_chunks;
@@ -105,7 +105,7 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 			    GFP_KERNEL);
 	if (!p->chunks) {
 		ret = -ENOMEM;
-		goto put_ctx;
+		goto free_chunk;
 	}
 
 	for (i = 0; i < p->nchunks; i++) {
@@ -191,8 +191,6 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	kfree(p->chunks);
 	p->chunks = NULL;
 	p->nchunks = 0;
-put_ctx:
-	amdgpu_ctx_put(p->ctx);
 free_chunk:
 	kfree(chunk_array);
 

commit 7a0a48ddf63bc9944b9690c6fa043ea4305f7f79
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Oct 9 15:51:10 2017 +0200

    drm/amdgpu: set -ECANCELED when dropping jobs
    
    And return from the wait functions the fence error code.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Nicolai Hähnle <nicolai.haehnle@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index b355189533d2..2ae5d523ca10 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1298,6 +1298,8 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 		r = PTR_ERR(fence);
 	else if (fence) {
 		r = dma_fence_wait_timeout(fence, true, timeout);
+		if (r > 0 && fence->error)
+			r = fence->error;
 		dma_fence_put(fence);
 	} else
 		r = 1;
@@ -1435,6 +1437,9 @@ static int amdgpu_cs_wait_all_fences(struct amdgpu_device *adev,
 
 		if (r == 0)
 			break;
+
+		if (fence->error)
+			return fence->error;
 	}
 
 	memset(wait, 0, sizeof(*wait));
@@ -1495,7 +1500,7 @@ static int amdgpu_cs_wait_any_fence(struct amdgpu_device *adev,
 	wait->out.status = (r > 0);
 	wait->out.first_signaled = first;
 	/* set return value 0 to indicate success */
-	r = 0;
+	r = array[first]->error;
 
 err_free_fence_array:
 	for (i = 0; i < fence_count; i++)

commit e55f2b646df3318e24f12b8388ab6e5cccb3e92d
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Oct 9 15:18:43 2017 +0200

    drm/amdgpu: move the VRAM lost counter per context
    
    Instead of per device track the VRAM lost per context and return ECANCELED
    instead of ENODEV.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Nicolai Hähnle <nicolai.haehnle@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 9daa7cac0ffb..b355189533d2 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -172,7 +172,11 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	if (ret)
 		goto free_all_kdata;
 
-	p->job->vram_lost_counter = fpriv->vram_lost_counter;
+	p->job->vram_lost_counter = atomic_read(&p->adev->vram_lost_counter);
+	if (p->ctx->vram_lost_counter != p->job->vram_lost_counter) {
+		ret = -ECANCELED;
+		goto free_all_kdata;
+	}
 
 	if (p->uf_entry.robj)
 		p->job->uf_addr = uf_offset;
@@ -1205,7 +1209,6 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 {
 	struct amdgpu_device *adev = dev->dev_private;
-	struct amdgpu_fpriv *fpriv = filp->driver_priv;
 	union drm_amdgpu_cs *cs = data;
 	struct amdgpu_cs_parser parser = {};
 	bool reserved_buffers = false;
@@ -1213,8 +1216,6 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 	if (!adev->accel_working)
 		return -EBUSY;
-	if (amdgpu_kms_vram_lost(adev, fpriv))
-		return -ENODEV;
 
 	parser.adev = adev;
 	parser.filp = filp;

commit 14e47f93c5cc4a1237dbacc137e174706093b69c
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Oct 9 15:04:41 2017 +0200

    drm/amdgpu: keep copy of VRAM lost counter in job
    
    Instead of reading the current counter from fpriv.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Nicolai Hähnle <nicolai.haehnle@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 0c07df72743c..9daa7cac0ffb 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -172,6 +172,8 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	if (ret)
 		goto free_all_kdata;
 
+	p->job->vram_lost_counter = fpriv->vram_lost_counter;
+
 	if (p->uf_entry.robj)
 		p->job->uf_addr = uf_offset;
 	kfree(chunk_array);

commit 396bcb41e035df7b98fb150ca950bf213e70ae7b
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Oct 9 14:45:09 2017 +0200

    drm/amdgpu: partial revert VRAM lost handling v2
    
    Keep blocking the CS, but revert everything else. Mapping BOs and info IOCTL
    are harmless and can still happen even when VRAM content ist lost.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Nicolai Hähnle <nicolai.haehnle@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 5de092eab0fa..0c07df72743c 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1272,16 +1272,12 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 {
 	union drm_amdgpu_wait_cs *wait = data;
 	struct amdgpu_device *adev = dev->dev_private;
-	struct amdgpu_fpriv *fpriv = filp->driver_priv;
 	unsigned long timeout = amdgpu_gem_timeout(wait->in.timeout);
 	struct amdgpu_ring *ring = NULL;
 	struct amdgpu_ctx *ctx;
 	struct dma_fence *fence;
 	long r;
 
-	if (amdgpu_kms_vram_lost(adev, fpriv))
-		return -ENODEV;
-
 	ctx = amdgpu_ctx_get(filp->driver_priv, wait->in.ctx_id);
 	if (ctx == NULL)
 		return -EINVAL;
@@ -1350,16 +1346,12 @@ int amdgpu_cs_fence_to_handle_ioctl(struct drm_device *dev, void *data,
 				    struct drm_file *filp)
 {
 	struct amdgpu_device *adev = dev->dev_private;
-	struct amdgpu_fpriv *fpriv = filp->driver_priv;
 	union drm_amdgpu_fence_to_handle *info = data;
 	struct dma_fence *fence;
 	struct drm_syncobj *syncobj;
 	struct sync_file *sync_file;
 	int fd, r;
 
-	if (amdgpu_kms_vram_lost(adev, fpriv))
-		return -ENODEV;
-
 	fence = amdgpu_cs_get_fence(adev, filp, &info->in.fence);
 	if (IS_ERR(fence))
 		return PTR_ERR(fence);
@@ -1521,15 +1513,12 @@ int amdgpu_cs_wait_fences_ioctl(struct drm_device *dev, void *data,
 				struct drm_file *filp)
 {
 	struct amdgpu_device *adev = dev->dev_private;
-	struct amdgpu_fpriv *fpriv = filp->driver_priv;
 	union drm_amdgpu_wait_fences *wait = data;
 	uint32_t fence_count = wait->in.fence_count;
 	struct drm_amdgpu_fence *fences_user;
 	struct drm_amdgpu_fence *fences;
 	int r;
 
-	if (amdgpu_kms_vram_lost(adev, fpriv))
-		return -ENODEV;
 	/* Get the fences from userspace */
 	fences = kmalloc_array(fence_count, sizeof(struct drm_amdgpu_fence),
 			GFP_KERNEL);

commit 0ae94444c08a0adf2fab4aab26be0646ee445a19
Author: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
Date:   Tue Oct 10 16:50:17 2017 -0400

    drm/amdgpu: Move old fence waiting before reservation lock is aquired v2
    
    Helps avoiding deadlock during GPU reset.
    Added mutex to amdgpu_ctx to preserve order of fences on a ring.
    
    v2:
    Put waiting logic in a function in a seperate function in amdgpu_ctx.c
    
    Signed-off-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 9166d5e1e557..5de092eab0fa 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -90,6 +90,8 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		goto free_chunk;
 	}
 
+	mutex_lock(&p->ctx->lock);
+
 	/* get chunks */
 	chunk_array_user = u64_to_user_ptr(cs->in.chunks);
 	if (copy_from_user(chunk_array, chunk_array_user,
@@ -737,8 +739,10 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error,
 
 	dma_fence_put(parser->fence);
 
-	if (parser->ctx)
+	if (parser->ctx) {
+		mutex_unlock(&parser->ctx->lock);
 		amdgpu_ctx_put(parser->ctx);
+	}
 	if (parser->bo_list)
 		amdgpu_bo_list_put(parser->bo_list);
 
@@ -895,9 +899,7 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 			r = amdgpu_ring_parse_cs(ring, p, j);
 			if (r)
 				return r;
-
 		}
-
 		j++;
 	}
 
@@ -985,7 +987,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 	    parser->job->ring->funcs->type == AMDGPU_RING_TYPE_VCE))
 		return -EINVAL;
 
-	return 0;
+	return amdgpu_ctx_wait_prev_fence(parser->ctx, parser->job->ring->idx);
 }
 
 static int amdgpu_cs_process_fence_dep(struct amdgpu_cs_parser *p,

commit ad864d243826cedc53404a1c0db7d1e38ddceb84
Author: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
Date:   Tue Oct 10 16:50:16 2017 -0400

    drm/amdgpu: Refactor amdgpu_cs_ib_vm_chunk and amdgpu_cs_ib_fill.
    
    This enables old fence waiting before reservation lock is aquired
    which in turn is part of a bigger solution to deadlock happening
    when gpu reset with VRAM recovery accures during intensive rendering.
    
    Signed-off-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index fe7dd44ac9fe..9166d5e1e557 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -845,15 +845,60 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_vm *vm = &fpriv->vm;
 	struct amdgpu_ring *ring = p->job->ring;
-	int i, r;
+	int i, j, r;
+
+	for (i = 0, j = 0; i < p->nchunks && j < p->job->num_ibs; i++) {
+
+		struct amdgpu_cs_chunk *chunk;
+		struct amdgpu_ib *ib;
+		struct drm_amdgpu_cs_chunk_ib *chunk_ib;
+
+		chunk = &p->chunks[i];
+		ib = &p->job->ibs[j];
+		chunk_ib = (struct drm_amdgpu_cs_chunk_ib *)chunk->kdata;
+
+		if (chunk->chunk_id != AMDGPU_CHUNK_ID_IB)
+			continue;
+
+		if (p->job->ring->funcs->parse_cs) {
+			struct amdgpu_bo_va_mapping *m;
+			struct amdgpu_bo *aobj = NULL;
+			uint64_t offset;
+			uint8_t *kptr;
+
+			r = amdgpu_cs_find_mapping(p, chunk_ib->va_start,
+					&aobj, &m);
+			if (r) {
+				DRM_ERROR("IB va_start is invalid\n");
+				return r;
+			}
 
-	/* Only for UVD/VCE VM emulation */
-	if (ring->funcs->parse_cs) {
-		for (i = 0; i < p->job->num_ibs; i++) {
-			r = amdgpu_ring_parse_cs(ring, p, i);
+			if ((chunk_ib->va_start + chunk_ib->ib_bytes) >
+				(m->last + 1) * AMDGPU_GPU_PAGE_SIZE) {
+				DRM_ERROR("IB va_start+ib_bytes is invalid\n");
+				return -EINVAL;
+			}
+
+			/* the IB should be reserved at this point */
+			r = amdgpu_bo_kmap(aobj, (void **)&kptr);
+			if (r) {
+				return r;
+			}
+
+			offset = m->start * AMDGPU_GPU_PAGE_SIZE;
+			kptr += chunk_ib->va_start - offset;
+
+			memcpy(ib->ptr, kptr, chunk_ib->ib_bytes);
+			amdgpu_bo_kunmap(aobj);
+
+			/* Only for UVD/VCE VM emulation */
+			r = amdgpu_ring_parse_cs(ring, p, j);
 			if (r)
 				return r;
+
 		}
+
+		j++;
 	}
 
 	if (p->job->vm) {
@@ -919,54 +964,18 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 
 		parser->job->ring = ring;
 
-		if (ring->funcs->parse_cs) {
-			struct amdgpu_bo_va_mapping *m;
-			struct amdgpu_bo *aobj = NULL;
-			uint64_t offset;
-			uint8_t *kptr;
-
-			r = amdgpu_cs_find_mapping(parser, chunk_ib->va_start,
-						   &aobj, &m);
-			if (r) {
-				DRM_ERROR("IB va_start is invalid\n");
-				return r;
-			}
-
-			if ((chunk_ib->va_start + chunk_ib->ib_bytes) >
-			    (m->last + 1) * AMDGPU_GPU_PAGE_SIZE) {
-				DRM_ERROR("IB va_start+ib_bytes is invalid\n");
-				return -EINVAL;
-			}
-
-			/* the IB should be reserved at this point */
-			r = amdgpu_bo_kmap(aobj, (void **)&kptr);
-			if (r) {
-				return r;
-			}
-
-			offset = m->start * AMDGPU_GPU_PAGE_SIZE;
-			kptr += chunk_ib->va_start - offset;
-
-			r =  amdgpu_ib_get(adev, vm, chunk_ib->ib_bytes, ib);
-			if (r) {
-				DRM_ERROR("Failed to get ib !\n");
-				return r;
-			}
-
-			memcpy(ib->ptr, kptr, chunk_ib->ib_bytes);
-			amdgpu_bo_kunmap(aobj);
-		} else {
-			r =  amdgpu_ib_get(adev, vm, 0, ib);
-			if (r) {
-				DRM_ERROR("Failed to get ib !\n");
-				return r;
-			}
-
+		r =  amdgpu_ib_get(adev, vm,
+					ring->funcs->parse_cs ? chunk_ib->ib_bytes : 0,
+					ib);
+		if (r) {
+			DRM_ERROR("Failed to get ib !\n");
+			return r;
 		}
 
 		ib->gpu_addr = chunk_ib->va_start;
 		ib->length_dw = chunk_ib->ib_bytes / 4;
 		ib->flags = chunk_ib->flags;
+
 		j++;
 	}
 
@@ -1212,6 +1221,10 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		goto out;
 	}
 
+	r = amdgpu_cs_ib_fill(adev, &parser);
+	if (r)
+		goto out;
+
 	r = amdgpu_cs_parser_bos(&parser, data);
 	if (r) {
 		if (r == -ENOMEM)
@@ -1222,9 +1235,6 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	}
 
 	reserved_buffers = true;
-	r = amdgpu_cs_ib_fill(adev, &parser);
-	if (r)
-		goto out;
 
 	r = amdgpu_cs_dependencies(adev, &parser);
 	if (r) {

commit b2ff0e8ac4ce1fb647ae40feb4cf26bc9301e0c9
Author: Andres Rodriguez <andresx7@gmail.com>
Date:   Mon Feb 20 17:53:19 2017 -0500

    drm/amdgpu: add framework for HW specific priority settings v9
    
    Add an initial framework for changing the HW priorities of rings. The
    framework allows requesting priority changes for the lifetime of an
    amdgpu_job. After the job completes the priority will decay to the next
    lowest priority for which a request is still valid.
    
    A new ring function set_priority() can now be populated to take care of
    the HW specific programming sequence for priority changes.
    
    v2: set priority before emitting IB, and take a ref on amdgpu_job
    v3: use AMD_SCHED_PRIORITY_* instead of AMDGPU_CTX_PRIORITY_*
    v4: plug amdgpu_ring_restore_priority_cb into amdgpu_job_free_cb
    v5: use atomic for tracking job priorities instead of last_job
    v6: rename amdgpu_ring_priority_[get/put]() and align parameters
    v7: replace spinlocks with mutexes for KIQ compatibility
    v8: raise ring priority during cs_ioctl, instead of job_run
    v9: priority_get() before push_job()
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Acked-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Andres Rodriguez <andresx7@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 38027a00f8ab..fe7dd44ac9fe 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1177,6 +1177,8 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	job->uf_sequence = seq;
 
 	amdgpu_job_free_resources(job);
+	amdgpu_ring_priority_get(job->ring,
+				 amd_sched_get_job_priority(&job->base));
 
 	trace_amdgpu_cs_ioctl(job);
 	amd_sched_entity_push_job(&job->base);

commit 177ae09b5d699a5ebd1cafcee78889db968abf54
Author: Andres Rodriguez <andresx7@gmail.com>
Date:   Fri Sep 15 20:44:06 2017 -0400

    drm/amdgpu: introduce AMDGPU_GEM_CREATE_EXPLICIT_SYNC v2
    
    Introduce a flag to signal that access to a BO will be synchronized
    through an external mechanism.
    
    Currently all buffers shared between contexts are subject to implicit
    synchronization. However, this is only required for protocols that
    currently don't support an explicit synchronization mechanism (DRI2/3).
    
    This patch introduces the AMDGPU_GEM_CREATE_EXPLICIT_SYNC, so that
    users can specify when it is safe to disable implicit sync.
    
    v2: only disable explicit sync in amdgpu_cs_ioctl
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Andres Rodriguez <andresx7@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index ab83dfcabb41..38027a00f8ab 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -705,7 +705,8 @@ static int amdgpu_cs_sync_rings(struct amdgpu_cs_parser *p)
 
 	list_for_each_entry(e, &p->validated, tv.head) {
 		struct reservation_object *resv = e->robj->tbo.resv;
-		r = amdgpu_sync_resv(p->adev, &p->job->sync, resv, p->filp);
+		r = amdgpu_sync_resv(p->adev, &p->job->sync, resv, p->filp,
+				     amdgpu_bo_explicit_sync(e->robj));
 
 		if (r)
 			return r;

commit 7ca24cf2d2269bde25e21c02a77fe81995a081ae
Author: Marek Olšák <marek.olsak@amd.com>
Date:   Tue Sep 12 22:42:14 2017 +0200

    drm/amdgpu: add FENCE_TO_HANDLE ioctl that returns syncobj or sync_file
    
    for being able to convert an amdgpu fence into one of the handles.
    Mesa will use this.
    
    Reviewed-by: Dave Airlie <airlied@redhat.com>
    Signed-off-by: Marek Olšák <marek.olsak@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index c6a214f1e991..ab83dfcabb41 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -25,6 +25,7 @@
  *    Jerome Glisse <glisse@freedesktop.org>
  */
 #include <linux/pagemap.h>
+#include <linux/sync_file.h>
 #include <drm/drmP.h>
 #include <drm/amdgpu_drm.h>
 #include <drm/drm_syncobj.h>
@@ -1330,6 +1331,66 @@ static struct dma_fence *amdgpu_cs_get_fence(struct amdgpu_device *adev,
 	return fence;
 }
 
+int amdgpu_cs_fence_to_handle_ioctl(struct drm_device *dev, void *data,
+				    struct drm_file *filp)
+{
+	struct amdgpu_device *adev = dev->dev_private;
+	struct amdgpu_fpriv *fpriv = filp->driver_priv;
+	union drm_amdgpu_fence_to_handle *info = data;
+	struct dma_fence *fence;
+	struct drm_syncobj *syncobj;
+	struct sync_file *sync_file;
+	int fd, r;
+
+	if (amdgpu_kms_vram_lost(adev, fpriv))
+		return -ENODEV;
+
+	fence = amdgpu_cs_get_fence(adev, filp, &info->in.fence);
+	if (IS_ERR(fence))
+		return PTR_ERR(fence);
+
+	switch (info->in.what) {
+	case AMDGPU_FENCE_TO_HANDLE_GET_SYNCOBJ:
+		r = drm_syncobj_create(&syncobj, 0, fence);
+		dma_fence_put(fence);
+		if (r)
+			return r;
+		r = drm_syncobj_get_handle(filp, syncobj, &info->out.handle);
+		drm_syncobj_put(syncobj);
+		return r;
+
+	case AMDGPU_FENCE_TO_HANDLE_GET_SYNCOBJ_FD:
+		r = drm_syncobj_create(&syncobj, 0, fence);
+		dma_fence_put(fence);
+		if (r)
+			return r;
+		r = drm_syncobj_get_fd(syncobj, (int*)&info->out.handle);
+		drm_syncobj_put(syncobj);
+		return r;
+
+	case AMDGPU_FENCE_TO_HANDLE_GET_SYNC_FILE_FD:
+		fd = get_unused_fd_flags(O_CLOEXEC);
+		if (fd < 0) {
+			dma_fence_put(fence);
+			return fd;
+		}
+
+		sync_file = sync_file_create(fence);
+		dma_fence_put(fence);
+		if (!sync_file) {
+			put_unused_fd(fd);
+			return -ENOMEM;
+		}
+
+		fd_install(fd, sync_file->file);
+		info->out.handle = fd;
+		return 0;
+
+	default:
+		return -EINVAL;
+	}
+}
+
 /**
  * amdgpu_cs_wait_all_fence - wait on all fences to signal
  *

commit eb01abc7c4fd1faa26d0787f410894d9c704eb60
Author: Monk Liu <Monk.Liu@amd.com>
Date:   Fri Sep 15 13:40:31 2017 +0800

    drm/amdgpu:make ctx_add_fence interruptible(v2)
    
    otherwise a gpu hang will make application couldn't be killed
    under timedout=0 mode
    
    v2:
    Fix memoryleak job/job->s_fence issue
    unlock mn
    remove the ERROR msg after waiting being interrupted
    
    Signed-off-by: Monk Liu <Monk.Liu@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 9f1202a4182f..c6a214f1e991 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1129,6 +1129,8 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	struct amd_sched_entity *entity = &p->ctx->rings[ring->idx].entity;
 	struct amdgpu_job *job;
 	unsigned i;
+	uint64_t seq;
+
 	int r;
 
 	amdgpu_mn_lock(p->mn);
@@ -1158,10 +1160,20 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	job->fence_ctx = entity->fence_context;
 	p->fence = dma_fence_get(&job->base.s_fence->finished);
 
+	r = amdgpu_ctx_add_fence(p->ctx, ring, p->fence, &seq);
+	if (r) {
+		dma_fence_put(p->fence);
+		dma_fence_put(&job->base.s_fence->finished);
+		amdgpu_job_free(job);
+		amdgpu_mn_unlock(p->mn);
+		return r;
+	}
+
 	amdgpu_cs_post_dependencies(p);
 
-	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring, p->fence);
-	job->uf_sequence = cs->out.handle;
+	cs->out.handle = seq;
+	job->uf_sequence = seq;
+
 	amdgpu_job_free_resources(job);
 
 	trace_amdgpu_cs_ioctl(job);

commit 4e55eb3879fea6d8c7d414cebaa5bff1da58b4a1
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Sep 11 16:54:59 2017 +0200

    drm/amdgpu: fix amdgpu_vm_handle_moved as well v2
    
    There is no guarantee that the last BO_VA actually needed an update.
    
    Additional to that all command submissions must wait for moved BOs to
    be cleared, not just the first one.
    
    v2: Don't overwrite any newer fence.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index ff61073b7181..9f1202a4182f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -814,7 +814,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 
 	}
 
-	r = amdgpu_vm_handle_moved(adev, vm, &p->job->sync);
+	r = amdgpu_vm_handle_moved(adev, vm);
 	if (r)
 		return r;
 

commit 47e0cd6b1dbbbff7591fe7eecc20bac5ca674351
Merge: 7846b12fe0b5 3d138c14c417
Author: Dave Airlie <airlied@redhat.com>
Date:   Wed Sep 13 14:34:11 2017 +1000

    Merge branch 'drm-next-4.14' of git://people.freedesktop.org/~agd5f/linux into drm-next
    
    A few fixes for 4.14.  Nothing too major.

commit 3d138c14c4174a2c80874a96935c87eee7c82ecf
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Sep 5 15:10:50 2017 +0200

    drm/amdgpu: revert "fix deadlock of reservation between cs and gpu reset v2"
    
    This reverts commit 10e709cb296c98424c03408d23e3addeddcd4088.
    
    The patch doesn't work at all:
    1. The CS can still be blocked because of amdgpu_ctx_add_fence().
    2. The order of submission isn't correct any more.
    3. We could end up using freed up memory because we now drop the
       ctx reference to early.
    
    This needs to be fixed cleanly by doing the context handling after the BO
    handling, but this is a larger task just avoid the obvious crashes for now.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Monk Liu monk.liu@amd.com
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index baa90df90aea..ba10a83535d3 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1153,7 +1153,6 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring, p->fence);
 	job->uf_sequence = cs->out.handle;
 	amdgpu_job_free_resources(job);
-	amdgpu_cs_parser_fini(p, 0, true);
 
 	trace_amdgpu_cs_ioctl(job);
 	amd_sched_entity_push_job(&job->base);
@@ -1211,10 +1210,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		goto out;
 
 	r = amdgpu_cs_submit(&parser, cs);
-	if (r)
-		goto out;
 
-	return 0;
 out:
 	amdgpu_cs_parser_fini(&parser, r, reserved_buffers);
 	return r;

commit d5884513a31df072879c89c80306d544467ee770
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Sep 8 14:09:41 2017 +0200

    drm/amdgpu: fix VM sync with always valid BOs v2
    
    All users of a VM must always wait for updates with always
    valid BOs to be completed.
    
    v2: remove debugging leftovers, rename struct member
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Roger He <Hongbo.He@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 5f19227b35e9..ff61073b7181 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -761,10 +761,6 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 	if (r)
 		return r;
 
-	r = amdgpu_sync_fence(adev, &p->job->sync, vm->last_dir_update);
-	if (r)
-		return r;
-
 	r = amdgpu_vm_clear_freed(adev, vm, NULL);
 	if (r)
 		return r;
@@ -819,6 +815,12 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 	}
 
 	r = amdgpu_vm_handle_moved(adev, vm, &p->job->sync);
+	if (r)
+		return r;
+
+	r = amdgpu_sync_fence(adev, &p->job->sync, vm->last_update);
+	if (r)
+		return r;
 
 	if (amdgpu_vm_debug && p->bo_list) {
 		/* Invalidate all BOs to test for userspace bugs */

commit aebc5e6f50f770ec9392c3ca804f18b30797dfa7
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Sep 6 16:55:16 2017 +0200

    drm/amdgpu: rework amdgpu_cs_find_mapping
    
    Use the VM instead of the BO list to find the BO for a virtual address.
    
    This fixes UVD/VCE in physical mode with VM local BOs.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Leo Liu <leo.liu@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index c30110a3024a..5f19227b35e9 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1479,46 +1479,24 @@ int amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 			   uint64_t addr, struct amdgpu_bo **bo,
 			   struct amdgpu_bo_va_mapping **map)
 {
+	struct amdgpu_fpriv *fpriv = parser->filp->driver_priv;
+	struct amdgpu_vm *vm = &fpriv->vm;
 	struct amdgpu_bo_va_mapping *mapping;
-	unsigned i;
 	int r;
 
-	if (!parser->bo_list)
-		return 0;
-
 	addr /= AMDGPU_GPU_PAGE_SIZE;
 
-	for (i = 0; i < parser->bo_list->num_entries; i++) {
-		struct amdgpu_bo_list_entry *lobj;
-
-		lobj = &parser->bo_list->array[i];
-		if (!lobj->bo_va)
-			continue;
-
-		list_for_each_entry(mapping, &lobj->bo_va->valids, list) {
-			if (mapping->start > addr ||
-			    addr > mapping->last)
-				continue;
-
-			*bo = lobj->bo_va->base.bo;
-			*map = mapping;
-			goto found;
-		}
-
-		list_for_each_entry(mapping, &lobj->bo_va->invalids, list) {
-			if (mapping->start > addr ||
-			    addr > mapping->last)
-				continue;
+	mapping = amdgpu_vm_bo_lookup_mapping(vm, addr);
+	if (!mapping || !mapping->bo_va || !mapping->bo_va->base.bo)
+		return -EINVAL;
 
-			*bo = lobj->bo_va->base.bo;
-			*map = mapping;
-			goto found;
-		}
-	}
+	*bo = mapping->bo_va->base.bo;
+	*map = mapping;
 
-	return -EINVAL;
+	/* Double check that the BO is reserved by this CS */
+	if (READ_ONCE((*bo)->tbo.resv->lock.ctx) != &parser->ticket)
+		return -EINVAL;
 
-found:
 	r = amdgpu_ttm_bind(&(*bo)->tbo, &(*bo)->tbo.mem);
 	if (unlikely(r))
 		return r;

commit 9cca0b8e5df0ac438c65eec5044bfa089d16fbbe
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Sep 6 16:15:28 2017 +0200

    drm/amdgpu: move amdgpu_cs_sysvm_access_required into find_mapping
    
    When we need to find the mapping we need sysvm access anyway.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Leo Liu <leo.liu@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index c2310d4eebc8..c30110a3024a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -921,11 +921,11 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 			uint64_t offset;
 			uint8_t *kptr;
 
-			m = amdgpu_cs_find_mapping(parser, chunk_ib->va_start,
-						   &aobj);
-			if (!aobj) {
+			r = amdgpu_cs_find_mapping(parser, chunk_ib->va_start,
+						   &aobj, &m);
+			if (r) {
 				DRM_ERROR("IB va_start is invalid\n");
-				return -EINVAL;
+				return r;
 			}
 
 			if ((chunk_ib->va_start + chunk_ib->ib_bytes) >
@@ -1475,15 +1475,16 @@ int amdgpu_cs_wait_fences_ioctl(struct drm_device *dev, void *data,
  * virtual memory address. Returns allocation structure when found, NULL
  * otherwise.
  */
-struct amdgpu_bo_va_mapping *
-amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
-		       uint64_t addr, struct amdgpu_bo **bo)
+int amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
+			   uint64_t addr, struct amdgpu_bo **bo,
+			   struct amdgpu_bo_va_mapping **map)
 {
 	struct amdgpu_bo_va_mapping *mapping;
 	unsigned i;
+	int r;
 
 	if (!parser->bo_list)
-		return NULL;
+		return 0;
 
 	addr /= AMDGPU_GPU_PAGE_SIZE;
 
@@ -1500,7 +1501,8 @@ amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 				continue;
 
 			*bo = lobj->bo_va->base.bo;
-			return mapping;
+			*map = mapping;
+			goto found;
 		}
 
 		list_for_each_entry(mapping, &lobj->bo_va->invalids, list) {
@@ -1509,44 +1511,22 @@ amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 				continue;
 
 			*bo = lobj->bo_va->base.bo;
-			return mapping;
+			*map = mapping;
+			goto found;
 		}
 	}
 
-	return NULL;
-}
+	return -EINVAL;
 
-/**
- * amdgpu_cs_sysvm_access_required - make BOs accessible by the system VM
- *
- * @parser: command submission parser context
- *
- * Helper for UVD/VCE VM emulation, make sure BOs are accessible by the system VM.
- */
-int amdgpu_cs_sysvm_access_required(struct amdgpu_cs_parser *parser)
-{
-	unsigned i;
-	int r;
+found:
+	r = amdgpu_ttm_bind(&(*bo)->tbo, &(*bo)->tbo.mem);
+	if (unlikely(r))
+		return r;
 
-	if (!parser->bo_list)
+	if ((*bo)->flags & AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS)
 		return 0;
 
-	for (i = 0; i < parser->bo_list->num_entries; i++) {
-		struct amdgpu_bo *bo = parser->bo_list->array[i].robj;
-
-		r = amdgpu_ttm_bind(&bo->tbo, &bo->tbo.mem);
-		if (unlikely(r))
-			return r;
-
-		if (bo->flags & AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS)
-			continue;
-
-		bo->flags |= AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS;
-		amdgpu_ttm_placement_from_domain(bo, bo->allowed_domains);
-		r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false);
-		if (unlikely(r))
-			return r;
-	}
-
-	return 0;
+	(*bo)->flags |= AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS;
+	amdgpu_ttm_placement_from_domain(*bo, (*bo)->allowed_domains);
+	return ttm_bo_validate(&(*bo)->tbo, &(*bo)->placement, false, false);
 }

commit 3fe89771cb0a65d3b686bcafb5b7e3ebae0ea604
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Sep 12 14:25:14 2017 -0400

    drm/amdgpu: stop reserving the BO in the MMU callback v3
    
    Instead take the callback lock during the final parts of CS.
    
    This should solve the last remaining locking order problems with BO reservations.
    
    v2: rebase, make dummy functions static inline
    v3: add one more missing inline and comments
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 4877df83b801..c2310d4eebc8 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -513,8 +513,11 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	INIT_LIST_HEAD(&p->validated);
 
 	p->bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
-	if (p->bo_list)
+	if (p->bo_list) {
 		amdgpu_bo_list_get_list(p->bo_list, &p->validated);
+		if (p->bo_list->first_userptr != p->bo_list->num_entries)
+			p->mn = amdgpu_mn_get(p->adev);
+	}
 
 	INIT_LIST_HEAD(&duplicates);
 	amdgpu_vm_get_pd_bo(&fpriv->vm, &p->validated, &p->vm_pd);
@@ -722,11 +725,7 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error,
 {
 	unsigned i;
 
-	if (!error)
-		ttm_eu_fence_buffer_objects(&parser->ticket,
-					    &parser->validated,
-					    parser->fence);
-	else if (backoff)
+	if (error && backoff)
 		ttm_eu_backoff_reservation(&parser->ticket,
 					   &parser->validated);
 
@@ -1127,14 +1126,29 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	struct amdgpu_ring *ring = p->job->ring;
 	struct amd_sched_entity *entity = &p->ctx->rings[ring->idx].entity;
 	struct amdgpu_job *job;
+	unsigned i;
 	int r;
 
+	amdgpu_mn_lock(p->mn);
+	if (p->bo_list) {
+		for (i = p->bo_list->first_userptr;
+		     i < p->bo_list->num_entries; ++i) {
+			struct amdgpu_bo *bo = p->bo_list->array[i].robj;
+
+			if (amdgpu_ttm_tt_userptr_needs_pages(bo->tbo.ttm)) {
+				amdgpu_mn_unlock(p->mn);
+				return -ERESTARTSYS;
+			}
+		}
+	}
+
 	job = p->job;
 	p->job = NULL;
 
 	r = amd_sched_job_init(&job->base, &ring->sched, entity, p->filp);
 	if (r) {
 		amdgpu_job_free(job);
+		amdgpu_mn_unlock(p->mn);
 		return r;
 	}
 
@@ -1150,6 +1164,10 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 
 	trace_amdgpu_cs_ioctl(job);
 	amd_sched_entity_push_job(&job->base);
+
+	ttm_eu_fence_buffer_objects(&p->ticket, &p->validated, p->fence);
+	amdgpu_mn_unlock(p->mn);
+
 	return 0;
 }
 

commit 1b0c0f9dc5ca6c0c8be21eeac92c7aa77bbf1d33
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Sep 5 14:36:44 2017 +0200

    drm/amdgpu: move userptr BOs to CPU domain during CS v2
    
    Instead of moving them in the MMU notifier move them during CS.
    
    v2: still mark pages as accessed/dirty
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com> (v1)
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 4d3f8fbfa59d..4877df83b801 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -475,6 +475,12 @@ static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 		/* Check if we have user pages and nobody bound the BO already */
 		if (amdgpu_ttm_tt_userptr_needs_pages(bo->tbo.ttm) &&
 		    lobj->user_pages) {
+			amdgpu_ttm_placement_from_domain(bo,
+							 AMDGPU_GEM_DOMAIN_CPU);
+			r = ttm_bo_validate(&bo->tbo, &bo->placement, true,
+					    false);
+			if (r)
+				return r;
 			amdgpu_ttm_tt_set_user_pages(bo->tbo.ttm,
 						     lobj->user_pages);
 			binding_userptr = true;

commit ca666a3c298f838346ccea46ff542c605e68deb5
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Sep 5 14:30:05 2017 +0200

    drm/amdgpu: stop using BO status for user pages
    
    Instead use a counter to figure out if we need to set new pages or not.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 283a216ee758..4d3f8fbfa59d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -473,7 +473,8 @@ static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 			return -EPERM;
 
 		/* Check if we have user pages and nobody bound the BO already */
-		if (lobj->user_pages && bo->tbo.ttm->state != tt_bound) {
+		if (amdgpu_ttm_tt_userptr_needs_pages(bo->tbo.ttm) &&
+		    lobj->user_pages) {
 			amdgpu_ttm_tt_set_user_pages(bo->tbo.ttm,
 						     lobj->user_pages);
 			binding_userptr = true;
@@ -534,23 +535,25 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		INIT_LIST_HEAD(&need_pages);
 		for (i = p->bo_list->first_userptr;
 		     i < p->bo_list->num_entries; ++i) {
+			struct amdgpu_bo *bo;
 
 			e = &p->bo_list->array[i];
+			bo = e->robj;
 
-			if (amdgpu_ttm_tt_userptr_invalidated(e->robj->tbo.ttm,
+			if (amdgpu_ttm_tt_userptr_invalidated(bo->tbo.ttm,
 				 &e->user_invalidated) && e->user_pages) {
 
 				/* We acquired a page array, but somebody
 				 * invalidated it. Free it and try again
 				 */
 				release_pages(e->user_pages,
-					      e->robj->tbo.ttm->num_pages,
+					      bo->tbo.ttm->num_pages,
 					      false);
 				kvfree(e->user_pages);
 				e->user_pages = NULL;
 			}
 
-			if (e->robj->tbo.ttm->state != tt_bound &&
+			if (amdgpu_ttm_tt_userptr_needs_pages(bo->tbo.ttm) &&
 			    !e->user_pages) {
 				list_del(&e->tv.head);
 				list_add(&e->tv.head, &need_pages);

commit b72cf4fca2bb786e20864b5e8755105aa9626fb4
Author: Christian König <christian.koenig@amd.com>
Date:   Sun Sep 3 15:22:06 2017 +0200

    drm/amdgpu: move taking mmap_sem into get_user_pages v2
    
    This didn't helped as intended, just simplify the code.
    
    v2: unlock mmap_sem in the error path as well
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 3fe816f6beca..283a216ee758 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -500,18 +500,14 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_bo_list_entry *e;
 	struct list_head duplicates;
-	bool need_mmap_lock = false;
 	unsigned i, tries = 10;
 	int r;
 
 	INIT_LIST_HEAD(&p->validated);
 
 	p->bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
-	if (p->bo_list) {
-		need_mmap_lock = p->bo_list->first_userptr !=
-			p->bo_list->num_entries;
+	if (p->bo_list)
 		amdgpu_bo_list_get_list(p->bo_list, &p->validated);
-	}
 
 	INIT_LIST_HEAD(&duplicates);
 	amdgpu_vm_get_pd_bo(&fpriv->vm, &p->validated, &p->vm_pd);
@@ -519,9 +515,6 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	if (p->uf_entry.robj)
 		list_add(&p->uf_entry.tv.head, &p->validated);
 
-	if (need_mmap_lock)
-		down_read(&current->mm->mmap_sem);
-
 	while (1) {
 		struct list_head need_pages;
 		unsigned i;
@@ -674,9 +667,6 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 
 error_free_pages:
 
-	if (need_mmap_lock)
-		up_read(&current->mm->mmap_sem);
-
 	if (p->bo_list) {
 		for (i = p->bo_list->first_userptr;
 		     i < p->bo_list->num_entries; ++i) {

commit aa4ec7ce7ec52c7230cfa73b06d79288b45fe1c9
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Sep 5 15:10:50 2017 +0200

    drm/amdgpu: revert "fix deadlock of reservation between cs and gpu reset v2"
    
    This reverts commit 10e709cb296c98424c03408d23e3addeddcd4088.
    
    The patch doesn't work at all:
    1. The CS can still be blocked because of amdgpu_ctx_add_fence().
    2. The order of submission isn't correct any more.
    3. We could end up using freed up memory because we now drop the
       ctx reference to early.
    
    This needs to be fixed cleanly by doing the context handling after the BO
    handling, but this is a larger task just avoid the obvious crashes for now.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Monk Liu monk.liu@amd.com
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index e58db0c69c6a..3fe816f6beca 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1148,7 +1148,6 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring, p->fence);
 	job->uf_sequence = cs->out.handle;
 	amdgpu_job_free_resources(job);
-	amdgpu_cs_parser_fini(p, 0, true);
 
 	trace_amdgpu_cs_ioctl(job);
 	amd_sched_entity_push_job(&job->base);
@@ -1206,10 +1205,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		goto out;
 
 	r = amdgpu_cs_submit(&parser, cs);
-	if (r)
-		goto out;
 
-	return 0;
 out:
 	amdgpu_cs_parser_fini(&parser, r, reserved_buffers);
 	return r;

commit a216ab09955d6b77f3af4f0aba9255c5ddf382f5
Author: Christian König <christian.koenig@amd.com>
Date:   Sat Sep 2 13:21:31 2017 +0200

    drm/amdgpu: fix userptr put_page handling
    
    Move calling put_page into the unpopulate callback. Otherwise we mess up the pages
    reference count when it is unbound multiple times.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 233b6f2f8427..e58db0c69c6a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -474,10 +474,8 @@ static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 
 		/* Check if we have user pages and nobody bound the BO already */
 		if (lobj->user_pages && bo->tbo.ttm->state != tt_bound) {
-			size_t size = sizeof(struct page *);
-
-			size *= bo->tbo.ttm->num_pages;
-			memcpy(bo->tbo.ttm->pages, lobj->user_pages, size);
+			amdgpu_ttm_tt_set_user_pages(bo->tbo.ttm,
+						     lobj->user_pages);
 			binding_userptr = true;
 		}
 

commit a2138eaf97b4e053b229fe07e1bb4ecbe07e6769
Author: Monk Liu <monk.liu@amd.com>
Date:   Fri Aug 11 17:49:48 2017 +0800

    drm/amdgpu: fix wait_any_fence
    
    first is incorrect if hit NULL/signaled fence
    
    Signed-off-by: Monk Liu <monk.liu@amd.com>
    Reviewed-by: Chunming Zhou <David1.Zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index b57adc0723cb..233b6f2f8427 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1384,6 +1384,7 @@ static int amdgpu_cs_wait_any_fence(struct amdgpu_device *adev,
 			array[i] = fence;
 		} else { /* NULL, the fence has been already signaled */
 			r = 1;
+			first = i;
 			goto out;
 		}
 	}

commit 73fb16e7ebee12953de32a7a2552e0cf2bf74ebf
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Aug 16 11:13:48 2017 +0200

    drm/amdgpu: add support for per VM BOs v2
    
    Per VM BOs are handled like VM PDs and PTs. They are always valid and don't
    need to be specified in the BO lists.
    
    v2: validate PDs/PTs first
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 8bf178a912f2..b57adc0723cb 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -822,7 +822,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 
 	}
 
-	r = amdgpu_vm_clear_moved(adev, vm, &p->job->sync);
+	r = amdgpu_vm_handle_moved(adev, vm, &p->job->sync);
 
 	if (amdgpu_vm_debug && p->bo_list) {
 		/* Invalidate all BOs to test for userspace bugs */

commit 3f3333f8a0e90ac26f84ed7b0aa344efce695c08
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Aug 3 14:02:13 2017 +0200

    drm/amdgpu: track evicted page tables v2
    
    Instead of validating all page tables when one was evicted,
    track which one needs a validation.
    
    v2: simplify amdgpu_vm_ready as well
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com> (v1)
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index d6ddd5562c16..8bf178a912f2 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -636,9 +636,6 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 
 	amdgpu_cs_report_moved_bytes(p->adev, p->bytes_moved,
 				     p->bytes_moved_vis);
-	fpriv->vm.last_eviction_counter =
-		atomic64_read(&p->adev->num_evictions);
-
 	if (p->bo_list) {
 		struct amdgpu_bo *gds = p->bo_list->gds_obj;
 		struct amdgpu_bo *gws = p->bo_list->gws_obj;
@@ -835,7 +832,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 			if (!bo)
 				continue;
 
-			amdgpu_vm_bo_invalidate(adev, bo);
+			amdgpu_vm_bo_invalidate(adev, bo, false);
 		}
 	}
 
@@ -860,7 +857,7 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 	}
 
 	if (p->job->vm) {
-		p->job->vm_pd_addr = amdgpu_bo_gpu_offset(vm->root.bo);
+		p->job->vm_pd_addr = amdgpu_bo_gpu_offset(vm->root.base.bo);
 
 		r = amdgpu_bo_vm_update_pte(p);
 		if (r)

commit 06f10a537ec1d5fe68dc889a9a5d11afa49e6e0d
Author: Christophe JAILLET <christophe.jaillet@wanadoo.fr>
Date:   Wed Aug 23 07:52:36 2017 +0200

    drm/amdgpu: check memory allocation failure
    
    Check memory allocation failure and return -ENOMEM in such a case.
    
    'num_post_dep_syncobjs' still has to be set to 0 before the test in order
    to have it initialized if 'amdgpu_cs_parser_fini()' is called to free
    resources.
    
    The calling graph would be, in such a case!
       failure in amdgpu_cs_process_syncobj_out_dep()
          ---> error code returned by amdgpu_cs_dependencies()
             --> amdgpu_cs_parser_fini() is called
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Christophe JAILLET <christophe.jaillet@wanadoo.fr>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 269b835571eb..d6ddd5562c16 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1079,6 +1079,9 @@ static int amdgpu_cs_process_syncobj_out_dep(struct amdgpu_cs_parser *p,
 					     GFP_KERNEL);
 	p->num_post_dep_syncobjs = 0;
 
+	if (!p->post_dep_syncobjs)
+		return -ENOMEM;
+
 	for (i = 0; i < num_deps; ++i) {
 		p->post_dep_syncobjs[i] = drm_syncobj_find(p->filp, deps[i].handle);
 		if (!p->post_dep_syncobjs[i])

commit afaf59237843bf89823c33143beca6b262dff0ca
Author: Jason Ekstrand <jason@jlekstrand.net>
Date:   Fri Aug 25 10:52:19 2017 -0700

    drm/syncobj: Rename fence_get to find_fence
    
    The function has far more in common with drm_syncobj_find than with
    any in the get/put functions.
    
    Signed-off-by: Jason Ekstrand <jason@jlekstrand.net>
    Acked-by: Christian König <christian.koenig@amd.com> (v1)
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 15d4a28d73bb..269b835571eb 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1035,7 +1035,7 @@ static int amdgpu_syncobj_lookup_and_add_to_sync(struct amdgpu_cs_parser *p,
 {
 	int r;
 	struct dma_fence *fence;
-	r = drm_syncobj_fence_get(p->filp, handle, &fence);
+	r = drm_syncobj_find_fence(p->filp, handle, &fence);
 	if (r)
 		return r;
 

commit a1d6b1901a2154e9f44f39738491f0afc3f8608e
Author: Christophe JAILLET <christophe.jaillet@wanadoo.fr>
Date:   Wed Aug 23 07:52:36 2017 +0200

    drm/amdgpu: check memory allocation failure
    
    Check memory allocation failure and return -ENOMEM in such a case.
    
    'num_post_dep_syncobjs' still has to be set to 0 before the test in order
    to have it initialized if 'amdgpu_cs_parser_fini()' is called to free
    resources.
    
    The calling graph would be, in such a case!
       failure in amdgpu_cs_process_syncobj_out_dep()
          ---> error code returned by amdgpu_cs_dependencies()
             --> amdgpu_cs_parser_fini() is called
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Christophe JAILLET <christophe.jaillet@wanadoo.fr>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 15d4a28d73bb..baa90df90aea 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1079,6 +1079,9 @@ static int amdgpu_cs_process_syncobj_out_dep(struct amdgpu_cs_parser *p,
 					     GFP_KERNEL);
 	p->num_post_dep_syncobjs = 0;
 
+	if (!p->post_dep_syncobjs)
+		return -ENOMEM;
+
 	for (i = 0; i < num_deps; ++i) {
 		p->post_dep_syncobjs[i] = drm_syncobj_find(p->filp, deps[i].handle);
 		if (!p->post_dep_syncobjs[i])

commit 27c7b9aeecd7c06a3b527795807c19a0bbe25c1e
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Aug 1 11:27:36 2017 +0200

    drm/amdgpu: rename VM invalidated to moved
    
    That better describes what happens here with the BO.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 75e7141c8de4..15d4a28d73bb 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -825,7 +825,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 
 	}
 
-	r = amdgpu_vm_clear_invalids(adev, vm, &p->job->sync);
+	r = amdgpu_vm_clear_moved(adev, vm, &p->job->sync);
 
 	if (amdgpu_vm_debug && p->bo_list) {
 		/* Invalidate all BOs to test for userspace bugs */

commit ec681545afe5a448b43a2fe5c206ee48e19dabb3
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Aug 1 10:51:43 2017 +0200

    drm/amdgpu: separate bo_va structure
    
    Split that into vm_bo_base and bo_va to allow other uses as well.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 3c64248673ee..75e7141c8de4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1487,7 +1487,7 @@ amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 			    addr > mapping->last)
 				continue;
 
-			*bo = lobj->bo_va->bo;
+			*bo = lobj->bo_va->base.bo;
 			return mapping;
 		}
 
@@ -1496,7 +1496,7 @@ amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 			    addr > mapping->last)
 				continue;
 
-			*bo = lobj->bo_va->bo;
+			*bo = lobj->bo_va->base.bo;
 			return mapping;
 		}
 	}

commit 0f4b3c68626199cd5ce619e2a3105d44b81f2753
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jul 31 15:32:40 2017 +0200

    drm/amdgpu: cleanup static CSA handling
    
    Move the CSA bo_va from the VM to the fpriv structure.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 7e71a511990e..3c64248673ee 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -787,7 +787,8 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 
 	if (amdgpu_sriov_vf(adev)) {
 		struct dma_fence *f;
-		bo_va = vm->csa_bo_va;
+
+		bo_va = fpriv->csa_va;
 		BUG_ON(!bo_va);
 		r = amdgpu_vm_bo_update(adev, bo_va, false);
 		if (r)

commit 3c848bb38aca1f7fd23edeb867b89d714a2e6ce2
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Aug 7 17:46:49 2017 +0200

    drm/amdgpu: move vram usage tracking into the vram manager v2
    
    Looks like a better place for this.
    
    v2: use atomic64_t members instead
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 825784b3b193..7e71a511990e 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -246,7 +246,7 @@ static void amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev,
 	}
 
 	total_vram = adev->mc.real_vram_size - adev->vram_pin_size;
-	used_vram = atomic64_read(&adev->vram_usage);
+	used_vram = amdgpu_vram_mgr_usage(&adev->mman.bdev.man[TTM_PL_VRAM]);
 	free_vram = used_vram >= total_vram ? 0 : total_vram - used_vram;
 
 	spin_lock(&adev->mm_stats.lock);
@@ -292,7 +292,8 @@ static void amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev,
 	/* Do the same for visible VRAM if half of it is free */
 	if (adev->mc.visible_vram_size < adev->mc.real_vram_size) {
 		u64 total_vis_vram = adev->mc.visible_vram_size;
-		u64 used_vis_vram = atomic64_read(&adev->vram_vis_usage);
+		u64 used_vis_vram =
+			amdgpu_vram_mgr_vis_usage(&adev->mman.bdev.man[TTM_PL_VRAM]);
 
 		if (used_vis_vram < total_vis_vram) {
 			u64 free_vis_vram = total_vis_vram - used_vis_vram;

commit b636922553ee2c47b9e3955c5665b8996dfcdbd7
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Aug 3 11:44:01 2017 -0400

    drm/amdgpu: only move VM BOs in the LRU during validation v2
    
    This should save us a bunch of command submission overhead.
    
    v2: move the LRU move to the right place to avoid the move for the root BO
        and handle the shadow BOs as well. This turned out to be a bug fix because
        the move needs to happen before the kmap.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Acked-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index c05479ec825a..825784b3b193 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -673,10 +673,8 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	}
 
 error_validate:
-	if (r) {
-		amdgpu_vm_move_pt_bos_in_lru(p->adev, &fpriv->vm);
+	if (r)
 		ttm_eu_backoff_reservation(&p->ticket, &p->validated);
-	}
 
 error_free_pages:
 
@@ -724,21 +722,18 @@ static int amdgpu_cs_sync_rings(struct amdgpu_cs_parser *p)
  * If error is set than unvalidate buffer, otherwise just free memory
  * used by parsing context.
  **/
-static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bool backoff)
+static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error,
+				  bool backoff)
 {
-	struct amdgpu_fpriv *fpriv = parser->filp->driver_priv;
 	unsigned i;
 
-	if (!error) {
-		amdgpu_vm_move_pt_bos_in_lru(parser->adev, &fpriv->vm);
-
+	if (!error)
 		ttm_eu_fence_buffer_objects(&parser->ticket,
 					    &parser->validated,
 					    parser->fence);
-	} else if (backoff) {
+	else if (backoff)
 		ttm_eu_backoff_reservation(&parser->ticket,
 					   &parser->validated);
-	}
 
 	for (i = 0; i < parser->num_post_dep_syncobjs; i++)
 		drm_syncobj_put(parser->post_dep_syncobjs[i]);

commit 6d7d9c5aa212d069b5271cd6bb8a9e05a3e1b986
Author: Kent Russell <kent.russell@amd.com>
Date:   Tue Aug 8 07:58:01 2017 -0400

    drm/amdgpu: Fix preferred typo
    
    Change "prefered" to "preferred"
    
    Signed-off-by: Kent Russell <kent.russell@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index da8209945ef2..c05479ec825a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -348,11 +348,11 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 			 * that.
 			 */
 			if (p->bytes_moved_vis < p->bytes_moved_vis_threshold)
-				domain = bo->prefered_domains;
+				domain = bo->preferred_domains;
 			else
 				domain = bo->allowed_domains;
 		} else {
-			domain = bo->prefered_domains;
+			domain = bo->preferred_domains;
 		}
 	} else {
 		domain = bo->allowed_domains;

commit f62facc2eb78ebbedae70e394ac034ab9407a244
Author: Cihangir Akturk <cakturk@gmail.com>
Date:   Thu Aug 3 14:58:16 2017 +0300

    drm/amdgpu: switch to drm_*{get,put} helpers
    
    drm_*_reference() and drm_*_unreference() functions are just
    compatibility alias for drm_*_get() and drm_*_put() and should not be
    used by new code. So convert all users of compatibility functions to use
    the new APIs.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Cihangir Akturk <cakturk@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 381b4f99648d..da8209945ef2 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -54,7 +54,7 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 
 	*offset = data->offset;
 
-	drm_gem_object_unreference_unlocked(gobj);
+	drm_gem_object_put_unlocked(gobj);
 
 	if (amdgpu_ttm_tt_get_usermm(p->uf_entry.robj->tbo.ttm)) {
 		amdgpu_bo_unref(&p->uf_entry.robj);

commit 7ecc245a8ce32ffcaa6a3e5795e0b14db8e076fc
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Jul 26 17:02:52 2017 +0200

    drm/amdgpu: consistent use u64_to_user_ptr
    
    Instead of open coding the conversion from u64 to pointers.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 33789510e663..381b4f99648d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -90,7 +90,7 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	}
 
 	/* get chunks */
-	chunk_array_user = (uint64_t __user *)(uintptr_t)(cs->in.chunks);
+	chunk_array_user = u64_to_user_ptr(cs->in.chunks);
 	if (copy_from_user(chunk_array, chunk_array_user,
 			   sizeof(uint64_t)*cs->in.num_chunks)) {
 		ret = -EFAULT;
@@ -110,7 +110,7 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		struct drm_amdgpu_cs_chunk user_chunk;
 		uint32_t __user *cdata;
 
-		chunk_ptr = (void __user *)(uintptr_t)chunk_array[i];
+		chunk_ptr = u64_to_user_ptr(chunk_array[i]);
 		if (copy_from_user(&user_chunk, chunk_ptr,
 				       sizeof(struct drm_amdgpu_cs_chunk))) {
 			ret = -EFAULT;
@@ -121,7 +121,7 @@ static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		p->chunks[i].length_dw = user_chunk.length_dw;
 
 		size = p->chunks[i].length_dw;
-		cdata = (void __user *)(uintptr_t)user_chunk.chunk_data;
+		cdata = u64_to_user_ptr(user_chunk.chunk_data);
 
 		p->chunks[i].kdata = kvmalloc_array(size, sizeof(uint32_t), GFP_KERNEL);
 		if (p->chunks[i].kdata == NULL) {
@@ -1437,7 +1437,7 @@ int amdgpu_cs_wait_fences_ioctl(struct drm_device *dev, void *data,
 	if (fences == NULL)
 		return -ENOMEM;
 
-	fences_user = (void __user *)(uintptr_t)(wait->in.fences);
+	fences_user = u64_to_user_ptr(wait->in.fences);
 	if (copy_from_user(fences, fences_user,
 		sizeof(struct drm_amdgpu_fence) * fence_count)) {
 		r = -EFAULT;

commit 00f06b246a3056bbaa901a90a5a93c9f81ab8e36
Author: John Brooks <john@fastquake.com>
Date:   Tue Jun 27 22:33:18 2017 -0400

    drm/amdgpu: Throttle visible VRAM moves separately
    
    The BO move throttling code is designed to allow VRAM to fill quickly if it
    is relatively empty. However, this does not take into account situations
    where the visible VRAM is smaller than total VRAM, and total VRAM may not
    be close to full but the visible VRAM segment is under pressure. In such
    situations, visible VRAM would experience unrestricted swapping and
    performance would drop.
    
    Add a separate counter specifically for moves involving visible VRAM, and
    check it before moving BOs there.
    
    v2: Only perform calculations for separate counter if visible VRAM is
        smaller than total VRAM. (Michel Dänzer)
    v3: [Michel Dänzer]
    * Use BO's location rather than the AMDGPU_GEM_CREATE_CPU_ACCESS_REQUIRED
      flag to determine whether to account a move for visible VRAM in most
      cases.
    * Use a single
    
            if (adev->mc.visible_vram_size < adev->mc.real_vram_size) {
    
      block in amdgpu_cs_get_threshold_for_moves.
    
    Fixes: 95844d20ae02 (drm/amdgpu: throttle buffer migrations at CS using a fixed MBps limit (v2))
    Signed-off-by: John Brooks <john@fastquake.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 5599c01b265d..33789510e663 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -223,10 +223,11 @@ static s64 bytes_to_us(struct amdgpu_device *adev, u64 bytes)
  * ticks. The accumulated microseconds (us) are converted to bytes and
  * returned.
  */
-static u64 amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev)
+static void amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev,
+					      u64 *max_bytes,
+					      u64 *max_vis_bytes)
 {
 	s64 time_us, increment_us;
-	u64 max_bytes;
 	u64 free_vram, total_vram, used_vram;
 
 	/* Allow a maximum of 200 accumulated ms. This is basically per-IB
@@ -238,8 +239,11 @@ static u64 amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev)
 	 */
 	const s64 us_upper_bound = 200000;
 
-	if (!adev->mm_stats.log2_max_MBps)
-		return 0;
+	if (!adev->mm_stats.log2_max_MBps) {
+		*max_bytes = 0;
+		*max_vis_bytes = 0;
+		return;
+	}
 
 	total_vram = adev->mc.real_vram_size - adev->vram_pin_size;
 	used_vram = atomic64_read(&adev->vram_usage);
@@ -280,23 +284,45 @@ static u64 amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev)
 		adev->mm_stats.accum_us = max(min_us, adev->mm_stats.accum_us);
 	}
 
-	/* This returns 0 if the driver is in debt to disallow (optional)
+	/* This is set to 0 if the driver is in debt to disallow (optional)
 	 * buffer moves.
 	 */
-	max_bytes = us_to_bytes(adev, adev->mm_stats.accum_us);
+	*max_bytes = us_to_bytes(adev, adev->mm_stats.accum_us);
+
+	/* Do the same for visible VRAM if half of it is free */
+	if (adev->mc.visible_vram_size < adev->mc.real_vram_size) {
+		u64 total_vis_vram = adev->mc.visible_vram_size;
+		u64 used_vis_vram = atomic64_read(&adev->vram_vis_usage);
+
+		if (used_vis_vram < total_vis_vram) {
+			u64 free_vis_vram = total_vis_vram - used_vis_vram;
+			adev->mm_stats.accum_us_vis = min(adev->mm_stats.accum_us_vis +
+							  increment_us, us_upper_bound);
+
+			if (free_vis_vram >= total_vis_vram / 2)
+				adev->mm_stats.accum_us_vis =
+					max(bytes_to_us(adev, free_vis_vram / 2),
+					    adev->mm_stats.accum_us_vis);
+		}
+
+		*max_vis_bytes = us_to_bytes(adev, adev->mm_stats.accum_us_vis);
+	} else {
+		*max_vis_bytes = 0;
+	}
 
 	spin_unlock(&adev->mm_stats.lock);
-	return max_bytes;
 }
 
 /* Report how many bytes have really been moved for the last command
  * submission. This can result in a debt that can stop buffer migrations
  * temporarily.
  */
-void amdgpu_cs_report_moved_bytes(struct amdgpu_device *adev, u64 num_bytes)
+void amdgpu_cs_report_moved_bytes(struct amdgpu_device *adev, u64 num_bytes,
+				  u64 num_vis_bytes)
 {
 	spin_lock(&adev->mm_stats.lock);
 	adev->mm_stats.accum_us -= bytes_to_us(adev, num_bytes);
+	adev->mm_stats.accum_us_vis -= bytes_to_us(adev, num_vis_bytes);
 	spin_unlock(&adev->mm_stats.lock);
 }
 
@@ -304,7 +330,7 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 				 struct amdgpu_bo *bo)
 {
 	struct amdgpu_device *adev = amdgpu_ttm_adev(bo->tbo.bdev);
-	u64 initial_bytes_moved;
+	u64 initial_bytes_moved, bytes_moved;
 	uint32_t domain;
 	int r;
 
@@ -314,17 +340,35 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 	/* Don't move this buffer if we have depleted our allowance
 	 * to move it. Don't move anything if the threshold is zero.
 	 */
-	if (p->bytes_moved < p->bytes_moved_threshold)
-		domain = bo->prefered_domains;
-	else
+	if (p->bytes_moved < p->bytes_moved_threshold) {
+		if (adev->mc.visible_vram_size < adev->mc.real_vram_size &&
+		    (bo->flags & AMDGPU_GEM_CREATE_CPU_ACCESS_REQUIRED)) {
+			/* And don't move a CPU_ACCESS_REQUIRED BO to limited
+			 * visible VRAM if we've depleted our allowance to do
+			 * that.
+			 */
+			if (p->bytes_moved_vis < p->bytes_moved_vis_threshold)
+				domain = bo->prefered_domains;
+			else
+				domain = bo->allowed_domains;
+		} else {
+			domain = bo->prefered_domains;
+		}
+	} else {
 		domain = bo->allowed_domains;
+	}
 
 retry:
 	amdgpu_ttm_placement_from_domain(bo, domain);
 	initial_bytes_moved = atomic64_read(&adev->num_bytes_moved);
 	r = ttm_bo_validate(&bo->tbo, &bo->placement, true, false);
-	p->bytes_moved += atomic64_read(&adev->num_bytes_moved) -
-		initial_bytes_moved;
+	bytes_moved = atomic64_read(&adev->num_bytes_moved) -
+		      initial_bytes_moved;
+	p->bytes_moved += bytes_moved;
+	if (adev->mc.visible_vram_size < adev->mc.real_vram_size &&
+	    bo->tbo.mem.mem_type == TTM_PL_VRAM &&
+	    bo->tbo.mem.start < adev->mc.visible_vram_size >> PAGE_SHIFT)
+		p->bytes_moved_vis += bytes_moved;
 
 	if (unlikely(r == -ENOMEM) && domain != bo->allowed_domains) {
 		domain = bo->allowed_domains;
@@ -350,7 +394,8 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 		struct amdgpu_bo_list_entry *candidate = p->evictable;
 		struct amdgpu_bo *bo = candidate->robj;
 		struct amdgpu_device *adev = amdgpu_ttm_adev(bo->tbo.bdev);
-		u64 initial_bytes_moved;
+		u64 initial_bytes_moved, bytes_moved;
+		bool update_bytes_moved_vis;
 		uint32_t other;
 
 		/* If we reached our current BO we can forget it */
@@ -370,10 +415,17 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 
 		/* Good we can try to move this BO somewhere else */
 		amdgpu_ttm_placement_from_domain(bo, other);
+		update_bytes_moved_vis =
+			adev->mc.visible_vram_size < adev->mc.real_vram_size &&
+			bo->tbo.mem.mem_type == TTM_PL_VRAM &&
+			bo->tbo.mem.start < adev->mc.visible_vram_size >> PAGE_SHIFT;
 		initial_bytes_moved = atomic64_read(&adev->num_bytes_moved);
 		r = ttm_bo_validate(&bo->tbo, &bo->placement, true, false);
-		p->bytes_moved += atomic64_read(&adev->num_bytes_moved) -
+		bytes_moved = atomic64_read(&adev->num_bytes_moved) -
 			initial_bytes_moved;
+		p->bytes_moved += bytes_moved;
+		if (update_bytes_moved_vis)
+			p->bytes_moved_vis += bytes_moved;
 
 		if (unlikely(r))
 			break;
@@ -554,8 +606,10 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		list_splice(&need_pages, &p->validated);
 	}
 
-	p->bytes_moved_threshold = amdgpu_cs_get_threshold_for_moves(p->adev);
+	amdgpu_cs_get_threshold_for_moves(p->adev, &p->bytes_moved_threshold,
+					  &p->bytes_moved_vis_threshold);
 	p->bytes_moved = 0;
+	p->bytes_moved_vis = 0;
 	p->evictable = list_last_entry(&p->validated,
 				       struct amdgpu_bo_list_entry,
 				       tv.head);
@@ -579,8 +633,8 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		goto error_validate;
 	}
 
-	amdgpu_cs_report_moved_bytes(p->adev, p->bytes_moved);
-
+	amdgpu_cs_report_moved_bytes(p->adev, p->bytes_moved,
+				     p->bytes_moved_vis);
 	fpriv->vm.last_eviction_counter =
 		atomic64_read(&p->adev->num_evictions);
 

commit 00fc2c26bc46a64545cdf95a1511461ea9acecb4
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Wed Jul 5 21:12:44 2017 +0100

    drm: Remove unused drm_file parameter to drm_syncobj_replace_fence()
    
    the drm_file parameter is unused, so remove it.
    
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Dave Airlie <airlied@redhat.com>
    Reviewed-by: Jason Ekstrand <jason@jlekstrand.net>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 546a77e6fdff..5599c01b265d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1069,10 +1069,8 @@ static void amdgpu_cs_post_dependencies(struct amdgpu_cs_parser *p)
 {
 	int i;
 
-	for (i = 0; i < p->num_post_dep_syncobjs; ++i) {
-		drm_syncobj_replace_fence(p->filp, p->post_dep_syncobjs[i],
-					  p->fence);
-	}
+	for (i = 0; i < p->num_post_dep_syncobjs; ++i)
+		drm_syncobj_replace_fence(p->post_dep_syncobjs[i], p->fence);
 }
 
 static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,

commit 9211c784c64e56a87a6ef66e65506bc82fdb7076
Author: Alex Xie <AlexBin.Xie@amd.com>
Date:   Tue Jun 20 16:35:04 2017 -0400

    drm/amdgpu: Make amdgpu_cs_parser_init static (v2)
    
    The function is called only once inside the .c file.
    v2: update the commit message (Michel)
    
    Signed-off-by: Alex Xie <AlexBin.Xie@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 144b251bd7c8..546a77e6fdff 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -64,7 +64,7 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 	return 0;
 }
 
-int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
+static int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 {
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_vm *vm = &fpriv->vm;

commit 9f69c0fd4d581ff03d7b3123cd1324f7492627a8
Author: Alex Xie <AlexBin.Xie@amd.com>
Date:   Tue Jun 20 16:33:02 2017 -0400

    drm/amdgpu/cs: fix a typo in a comment
    
    Signed-off-by: Alex Xie <AlexBin.Xie@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index aeee6840e82b..144b251bd7c8 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -497,7 +497,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 				 &e->user_invalidated) && e->user_pages) {
 
 				/* We acquired a page array, but somebody
-				 * invalidated it. Free it an try again
+				 * invalidated it. Free it and try again
 				 */
 				release_pages(e->user_pages,
 					      e->robj->tbo.ttm->num_pages,

commit 660e855813f78b7fe63ff1ebc4f2ca07d94add0b
Author: Dave Airlie <airlied@redhat.com>
Date:   Mon Mar 13 22:18:15 2017 +0000

    amdgpu: use drm sync objects for shared semaphores (v6)
    
    This creates a new command submission chunk for amdgpu
    to add in and out sync objects around the submission.
    
    Sync objects are managed via the drm syncobj ioctls.
    
    The command submission interface is enhanced with two new
    chunks, one for syncobj pre submission dependencies,
    and one for post submission sync obj signalling,
    and just takes a list of handles for each.
    
    This is based on work originally done by David Zhou at AMD,
    with input from Christian Konig on what things should look like.
    
    In theory VkFences could be backed with sync objects and
    just get passed into the cs as syncobj handles as well.
    
    NOTE: this interface addition needs a version bump to expose
    it to userspace.
    
    TODO: update to dep_sync when rebasing onto amdgpu master.
    (with this - r-b from Christian)
    
    v1.1: keep file reference on import.
    v2: move to using syncobjs
    v2.1: change some APIs to just use p pointer.
    v3: make more robust against CS failures, we now add the
    wait sems but only remove them once the CS job has been
    submitted.
    v4: rewrite names of API and base on new syncobj code.
    v5: move post deps earlier, rename some apis
    v6: lookup post deps earlier, and just replace fences
    in post deps stage (Christian)
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 29469e6b58b8..aeee6840e82b 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -27,6 +27,7 @@
 #include <linux/pagemap.h>
 #include <drm/drmP.h>
 #include <drm/amdgpu_drm.h>
+#include <drm/drm_syncobj.h>
 #include "amdgpu.h"
 #include "amdgpu_trace.h"
 
@@ -154,6 +155,8 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 			break;
 
 		case AMDGPU_CHUNK_ID_DEPENDENCIES:
+		case AMDGPU_CHUNK_ID_SYNCOBJ_IN:
+		case AMDGPU_CHUNK_ID_SYNCOBJ_OUT:
 			break;
 
 		default:
@@ -682,6 +685,11 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
 		ttm_eu_backoff_reservation(&parser->ticket,
 					   &parser->validated);
 	}
+
+	for (i = 0; i < parser->num_post_dep_syncobjs; i++)
+		drm_syncobj_put(parser->post_dep_syncobjs[i]);
+	kfree(parser->post_dep_syncobjs);
+
 	dma_fence_put(parser->fence);
 
 	if (parser->ctx)
@@ -971,6 +979,64 @@ static int amdgpu_cs_process_fence_dep(struct amdgpu_cs_parser *p,
 	return 0;
 }
 
+static int amdgpu_syncobj_lookup_and_add_to_sync(struct amdgpu_cs_parser *p,
+						 uint32_t handle)
+{
+	int r;
+	struct dma_fence *fence;
+	r = drm_syncobj_fence_get(p->filp, handle, &fence);
+	if (r)
+		return r;
+
+	r = amdgpu_sync_fence(p->adev, &p->job->sync, fence);
+	dma_fence_put(fence);
+
+	return r;
+}
+
+static int amdgpu_cs_process_syncobj_in_dep(struct amdgpu_cs_parser *p,
+					    struct amdgpu_cs_chunk *chunk)
+{
+	unsigned num_deps;
+	int i, r;
+	struct drm_amdgpu_cs_chunk_sem *deps;
+
+	deps = (struct drm_amdgpu_cs_chunk_sem *)chunk->kdata;
+	num_deps = chunk->length_dw * 4 /
+		sizeof(struct drm_amdgpu_cs_chunk_sem);
+
+	for (i = 0; i < num_deps; ++i) {
+		r = amdgpu_syncobj_lookup_and_add_to_sync(p, deps[i].handle);
+		if (r)
+			return r;
+	}
+	return 0;
+}
+
+static int amdgpu_cs_process_syncobj_out_dep(struct amdgpu_cs_parser *p,
+					     struct amdgpu_cs_chunk *chunk)
+{
+	unsigned num_deps;
+	int i;
+	struct drm_amdgpu_cs_chunk_sem *deps;
+	deps = (struct drm_amdgpu_cs_chunk_sem *)chunk->kdata;
+	num_deps = chunk->length_dw * 4 /
+		sizeof(struct drm_amdgpu_cs_chunk_sem);
+
+	p->post_dep_syncobjs = kmalloc_array(num_deps,
+					     sizeof(struct drm_syncobj *),
+					     GFP_KERNEL);
+	p->num_post_dep_syncobjs = 0;
+
+	for (i = 0; i < num_deps; ++i) {
+		p->post_dep_syncobjs[i] = drm_syncobj_find(p->filp, deps[i].handle);
+		if (!p->post_dep_syncobjs[i])
+			return -EINVAL;
+		p->num_post_dep_syncobjs++;
+	}
+	return 0;
+}
+
 static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 				  struct amdgpu_cs_parser *p)
 {
@@ -985,12 +1051,30 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 			r = amdgpu_cs_process_fence_dep(p, chunk);
 			if (r)
 				return r;
+		} else if (chunk->chunk_id == AMDGPU_CHUNK_ID_SYNCOBJ_IN) {
+			r = amdgpu_cs_process_syncobj_in_dep(p, chunk);
+			if (r)
+				return r;
+		} else if (chunk->chunk_id == AMDGPU_CHUNK_ID_SYNCOBJ_OUT) {
+			r = amdgpu_cs_process_syncobj_out_dep(p, chunk);
+			if (r)
+				return r;
 		}
 	}
 
 	return 0;
 }
 
+static void amdgpu_cs_post_dependencies(struct amdgpu_cs_parser *p)
+{
+	int i;
+
+	for (i = 0; i < p->num_post_dep_syncobjs; ++i) {
+		drm_syncobj_replace_fence(p->filp, p->post_dep_syncobjs[i],
+					  p->fence);
+	}
+}
+
 static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 			    union drm_amdgpu_cs *cs)
 {
@@ -1011,6 +1095,9 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	job->owner = p->filp;
 	job->fence_ctx = entity->fence_context;
 	p->fence = dma_fence_get(&job->base.s_fence->finished);
+
+	amdgpu_cs_post_dependencies(p);
+
 	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring, p->fence);
 	job->uf_sequence = cs->out.handle;
 	amdgpu_job_free_resources(job);
@@ -1018,7 +1105,6 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 
 	trace_amdgpu_cs_ioctl(job);
 	amd_sched_entity_push_job(&job->base);
-
 	return 0;
 }
 

commit 6f0308ebc196f18607f45cc753521eb8448dfdfd
Author: Dave Airlie <airlied@redhat.com>
Date:   Thu Mar 9 03:45:52 2017 +0000

    amdgpu/cs: split out fence dependency checking (v2)
    
    This just splits out the fence depenency checking into it's
    own function to make it easier to add semaphore dependencies.
    
    v2: rebase onto other changes.
    
    v1-Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index a37bdf4f8e9b..29469e6b58b8 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -923,59 +923,68 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 	return 0;
 }
 
-static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
-				  struct amdgpu_cs_parser *p)
+static int amdgpu_cs_process_fence_dep(struct amdgpu_cs_parser *p,
+				       struct amdgpu_cs_chunk *chunk)
 {
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
-	int i, j, r;
+	unsigned num_deps;
+	int i, r;
+	struct drm_amdgpu_cs_chunk_dep *deps;
 
-	for (i = 0; i < p->nchunks; ++i) {
-		struct drm_amdgpu_cs_chunk_dep *deps;
-		struct amdgpu_cs_chunk *chunk;
-		unsigned num_deps;
+	deps = (struct drm_amdgpu_cs_chunk_dep *)chunk->kdata;
+	num_deps = chunk->length_dw * 4 /
+		sizeof(struct drm_amdgpu_cs_chunk_dep);
 
-		chunk = &p->chunks[i];
+	for (i = 0; i < num_deps; ++i) {
+		struct amdgpu_ring *ring;
+		struct amdgpu_ctx *ctx;
+		struct dma_fence *fence;
 
-		if (chunk->chunk_id != AMDGPU_CHUNK_ID_DEPENDENCIES)
-			continue;
+		ctx = amdgpu_ctx_get(fpriv, deps[i].ctx_id);
+		if (ctx == NULL)
+			return -EINVAL;
 
-		deps = (struct drm_amdgpu_cs_chunk_dep *)chunk->kdata;
-		num_deps = chunk->length_dw * 4 /
-			sizeof(struct drm_amdgpu_cs_chunk_dep);
+		r = amdgpu_queue_mgr_map(p->adev, &ctx->queue_mgr,
+					 deps[i].ip_type,
+					 deps[i].ip_instance,
+					 deps[i].ring, &ring);
+		if (r) {
+			amdgpu_ctx_put(ctx);
+			return r;
+		}
 
-		for (j = 0; j < num_deps; ++j) {
-			struct amdgpu_ring *ring;
-			struct amdgpu_ctx *ctx;
-			struct dma_fence *fence;
+		fence = amdgpu_ctx_get_fence(ctx, ring,
+					     deps[i].handle);
+		if (IS_ERR(fence)) {
+			r = PTR_ERR(fence);
+			amdgpu_ctx_put(ctx);
+			return r;
+		} else if (fence) {
+			r = amdgpu_sync_fence(p->adev, &p->job->sync,
+					      fence);
+			dma_fence_put(fence);
+			amdgpu_ctx_put(ctx);
+			if (r)
+				return r;
+		}
+	}
+	return 0;
+}
 
-			ctx = amdgpu_ctx_get(fpriv, deps[j].ctx_id);
-			if (ctx == NULL)
-				return -EINVAL;
+static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
+				  struct amdgpu_cs_parser *p)
+{
+	int i, r;
 
-			r = amdgpu_queue_mgr_map(adev, &ctx->queue_mgr,
-						 deps[j].ip_type,
-						 deps[j].ip_instance,
-						 deps[j].ring, &ring);
-			if (r) {
-				amdgpu_ctx_put(ctx);
-				return r;
-			}
+	for (i = 0; i < p->nchunks; ++i) {
+		struct amdgpu_cs_chunk *chunk;
 
-			fence = amdgpu_ctx_get_fence(ctx, ring,
-						     deps[j].handle);
-			if (IS_ERR(fence)) {
-				r = PTR_ERR(fence);
-				amdgpu_ctx_put(ctx);
-				return r;
+		chunk = &p->chunks[i];
 
-			} else if (fence) {
-				r = amdgpu_sync_fence(adev, &p->job->sync,
-						      fence);
-				dma_fence_put(fence);
-				amdgpu_ctx_put(ctx);
-				if (r)
-					return r;
-			}
+		if (chunk->chunk_id == AMDGPU_CHUNK_ID_DEPENDENCIES) {
+			r = amdgpu_cs_process_fence_dep(p, chunk);
+			if (r)
+				return r;
 		}
 	}
 

commit 04d4fb5fa63876d8e7cf67f2788aecfafc6a28a7
Merge: bfda9aa15317 a1924005a2e9
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri Jun 16 09:54:02 2017 +1000

    Merge branch 'drm-next-4.13' of git://people.freedesktop.org/~agd5f/linux into drm-next
    
    New radeon and amdgpu features for 4.13:
    - Lots of Vega10 bug fixes
    - Preliminary Raven support
    - KIQ support for compute rings
    - MEC queue management rework from Andres
    - Audio support for DCE6
    - SR-IOV improvements
    - Improved module parameters for controlling radeon vs amdgpu support
      for SI and CIK
    - Bug fixes
    - General code cleanups
    
    [airlied: dropped drmP.h header from one file was needed and build broke]
    
    * 'drm-next-4.13' of git://people.freedesktop.org/~agd5f/linux: (362 commits)
      drm/amdgpu: Fix compiler warnings
      drm/amdgpu: vm_update_ptes remove code duplication
      drm/amd/amdgpu: Port VCN over to new SOC15 macros
      drm/amd/amdgpu: Port PSP v10.0 over to new SOC15 macros
      drm/amd/amdgpu: Port PSP v3.1 over to new SOC15 macros
      drm/amd/amdgpu: Port NBIO v7.0 driver over to new SOC15 macros
      drm/amd/amdgpu: Port NBIO v6.1 driver over to new SOC15 macros
      drm/amd/amdgpu: Port UVD 7.0 over to new SOC15 macros
      drm/amd/amdgpu: Port MMHUB over to new SOC15 macros
      drm/amd/amdgpu: Cleanup gfxhub read-modify-write patterns
      drm/amd/amdgpu: Port GFXHUB over to new SOC15 macros
      drm/amd/amdgpu: Add offset variant to SOC15 macros
      drm/amd/powerplay: add avfs control for Vega10
      drm/amdgpu: add virtual display support for raven
      drm/amdgpu/gfx9: fix compute ring doorbell index
      drm/amd/amdgpu: Rename KIQ ring to avoid spaces
      drm/amd/amdgpu: gfx9 tidy ups (v2)
      drm/amdgpu: add contiguous flag in ucode bo create
      drm/amdgpu: fix missed gpu info firmware when cache firmware during S3
      drm/amdgpu: export test ib debugfs interface
      ...

commit eb0f0373e575822cf35949627b92533c7c41629c
Author: Alex Xie <AlexBin.Xie@amd.com>
Date:   Thu Jun 8 14:53:26 2017 -0400

    drm/amdgpu: fix a typo in comment
    
    Signed-off-by: Alex Xie <AlexBin.Xie@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index b17635c1b711..7a70a2d0187f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -525,7 +525,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 			goto error_free_pages;
 		}
 
-		/* Fill the page arrays for all useptrs. */
+		/* Fill the page arrays for all userptrs. */
 		list_for_each_entry(e, &need_pages, tv.head) {
 			struct ttm_tt *ttm = e->robj->tbo.ttm;
 

commit effd924d2f3b9c52d5bd8137c3803e83f719a290
Author: Andres Rodriguez <andresx7@gmail.com>
Date:   Thu Feb 16 00:47:32 2017 -0500

    drm/amdgpu: untie user ring ids from kernel ring ids v6
    
    Add amdgpu_queue_mgr, a mechanism that allows disjointing usermode's
    ring ids from the kernel's ring ids.
    
    The queue manager maintains a per-file descriptor map of user ring ids
    to amdgpu_ring pointers. Once a map is created it is permanent (this is
    required to maintain FIFO execution guarantees for a context's ring).
    
    Different queue map policies can be configured for each HW IP.
    Currently all HW IPs use the identity mapper, i.e. kernel ring id is
    equal to the user ring id.
    
    The purpose of this mechanism is to distribute the load across multiple
    queues more effectively for HW IPs that support multiple rings.
    Userspace clients are unable to check whether a specific resource is in
    use by a different client. Therefore, it is up to the kernel driver to
    make the optimal choice.
    
    v2: remove amdgpu_queue_mapper_funcs
    v3: made amdgpu_queue_mgr per context instead of per-fd
    v4: add context_put on error paths
    v5: rebase and include new IPs UVD_ENC & VCN_*
    v6: drop unused amdgpu_ring_is_valid_index (Alex)
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Andres Rodriguez <andresx7@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 9a0b2e5f3c11..b17635c1b711 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -30,90 +30,6 @@
 #include "amdgpu.h"
 #include "amdgpu_trace.h"
 
-int amdgpu_cs_get_ring(struct amdgpu_device *adev, u32 ip_type,
-		       u32 ip_instance, u32 ring,
-		       struct amdgpu_ring **out_ring)
-{
-	/* Right now all IPs have only one instance - multiple rings. */
-	if (ip_instance != 0) {
-		DRM_ERROR("invalid ip instance: %d\n", ip_instance);
-		return -EINVAL;
-	}
-
-	switch (ip_type) {
-	default:
-		DRM_ERROR("unknown ip type: %d\n", ip_type);
-		return -EINVAL;
-	case AMDGPU_HW_IP_GFX:
-		if (ring < adev->gfx.num_gfx_rings) {
-			*out_ring = &adev->gfx.gfx_ring[ring];
-		} else {
-			DRM_ERROR("only %d gfx rings are supported now\n",
-				  adev->gfx.num_gfx_rings);
-			return -EINVAL;
-		}
-		break;
-	case AMDGPU_HW_IP_COMPUTE:
-		if (ring < adev->gfx.num_compute_rings) {
-			*out_ring = &adev->gfx.compute_ring[ring];
-		} else {
-			DRM_ERROR("only %d compute rings are supported now\n",
-				  adev->gfx.num_compute_rings);
-			return -EINVAL;
-		}
-		break;
-	case AMDGPU_HW_IP_DMA:
-		if (ring < adev->sdma.num_instances) {
-			*out_ring = &adev->sdma.instance[ring].ring;
-		} else {
-			DRM_ERROR("only %d SDMA rings are supported\n",
-				  adev->sdma.num_instances);
-			return -EINVAL;
-		}
-		break;
-	case AMDGPU_HW_IP_UVD:
-		*out_ring = &adev->uvd.ring;
-		break;
-	case AMDGPU_HW_IP_VCE:
-		if (ring < adev->vce.num_rings){
-			*out_ring = &adev->vce.ring[ring];
-		} else {
-			DRM_ERROR("only %d VCE rings are supported\n", adev->vce.num_rings);
-			return -EINVAL;
-		}
-		break;
-	case AMDGPU_HW_IP_UVD_ENC:
-		if (ring < adev->uvd.num_enc_rings){
-			*out_ring = &adev->uvd.ring_enc[ring];
-		} else {
-			DRM_ERROR("only %d UVD ENC rings are supported\n",
-				adev->uvd.num_enc_rings);
-			return -EINVAL;
-		}
-		break;
-	case AMDGPU_HW_IP_VCN_DEC:
-		*out_ring = &adev->vcn.ring_dec;
-		break;
-	case AMDGPU_HW_IP_VCN_ENC:
-		if (ring < adev->vcn.num_enc_rings){
-			*out_ring = &adev->vcn.ring_enc[ring];
-		} else {
-			DRM_ERROR("only %d VCN ENC rings are supported\n",
-				adev->vcn.num_enc_rings);
-			return -EINVAL;
-		}
-		break;
-	}
-
-	if (!(*out_ring && (*out_ring)->adev)) {
-		DRM_ERROR("Ring %d is not initialized on IP %d\n",
-			  ring, ip_type);
-		return -EINVAL;
-	}
-
-	return 0;
-}
-
 static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 				      struct drm_amdgpu_cs_chunk_fence *data,
 				      uint32_t *offset)
@@ -928,9 +844,8 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 				return -EINVAL;
 		}
 
-		r = amdgpu_cs_get_ring(adev, chunk_ib->ip_type,
-				       chunk_ib->ip_instance, chunk_ib->ring,
-				       &ring);
+		r = amdgpu_queue_mgr_map(adev, &parser->ctx->queue_mgr, chunk_ib->ip_type,
+					 chunk_ib->ip_instance, chunk_ib->ring, &ring);
 		if (r)
 			return r;
 
@@ -1032,16 +947,19 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 			struct amdgpu_ctx *ctx;
 			struct dma_fence *fence;
 
-			r = amdgpu_cs_get_ring(adev, deps[j].ip_type,
-					       deps[j].ip_instance,
-					       deps[j].ring, &ring);
-			if (r)
-				return r;
-
 			ctx = amdgpu_ctx_get(fpriv, deps[j].ctx_id);
 			if (ctx == NULL)
 				return -EINVAL;
 
+			r = amdgpu_queue_mgr_map(adev, &ctx->queue_mgr,
+						 deps[j].ip_type,
+						 deps[j].ip_instance,
+						 deps[j].ring, &ring);
+			if (r) {
+				amdgpu_ctx_put(ctx);
+				return r;
+			}
+
 			fence = amdgpu_ctx_get_fence(ctx, ring,
 						     deps[j].handle);
 			if (IS_ERR(fence)) {
@@ -1177,15 +1095,19 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 
 	if (amdgpu_kms_vram_lost(adev, fpriv))
 		return -ENODEV;
-	r = amdgpu_cs_get_ring(adev, wait->in.ip_type, wait->in.ip_instance,
-			       wait->in.ring, &ring);
-	if (r)
-		return r;
 
 	ctx = amdgpu_ctx_get(filp->driver_priv, wait->in.ctx_id);
 	if (ctx == NULL)
 		return -EINVAL;
 
+	r = amdgpu_queue_mgr_map(adev, &ctx->queue_mgr,
+				 wait->in.ip_type, wait->in.ip_instance,
+				 wait->in.ring, &ring);
+	if (r) {
+		amdgpu_ctx_put(ctx);
+		return r;
+	}
+
 	fence = amdgpu_ctx_get_fence(ctx, ring, wait->in.handle);
 	if (IS_ERR(fence))
 		r = PTR_ERR(fence);
@@ -1221,15 +1143,17 @@ static struct dma_fence *amdgpu_cs_get_fence(struct amdgpu_device *adev,
 	struct dma_fence *fence;
 	int r;
 
-	r = amdgpu_cs_get_ring(adev, user->ip_type, user->ip_instance,
-			       user->ring, &ring);
-	if (r)
-		return ERR_PTR(r);
-
 	ctx = amdgpu_ctx_get(filp->driver_priv, user->ctx_id);
 	if (ctx == NULL)
 		return ERR_PTR(-EINVAL);
 
+	r = amdgpu_queue_mgr_map(adev, &ctx->queue_mgr, user->ip_type,
+				 user->ip_instance, user->ring, &ring);
+	if (r) {
+		amdgpu_ctx_put(ctx);
+		return ERR_PTR(r);
+	}
+
 	fence = amdgpu_ctx_get_fence(ctx, ring, user->seq_no);
 	amdgpu_ctx_put(ctx);
 

commit f1892138abcb6d58359189f3b0a6c95f10613513
Author: Chunming Zhou <David1.Zhou@amd.com>
Date:   Mon May 15 16:48:27 2017 +0800

    drm/amdgpu: return -ENODEV to user space when vram is lost v2
    
    below ioctl will return -ENODEV:
    amdgpu_cs_ioctl
    amdgpu_cs_wait_ioctl
    amdgpu_cs_wait_fences_ioctl
    amdgpu_gem_va_ioctl
    amdgpu_info_ioctl
    
    v2: only for map and replace cases in amdgpu_gem_va_ioctl
    
    Signed-off-by: Chunming Zhou <David1.Zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 1375a896e87b..9a0b2e5f3c11 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1097,6 +1097,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 {
 	struct amdgpu_device *adev = dev->dev_private;
+	struct amdgpu_fpriv *fpriv = filp->driver_priv;
 	union drm_amdgpu_cs *cs = data;
 	struct amdgpu_cs_parser parser = {};
 	bool reserved_buffers = false;
@@ -1104,6 +1105,8 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 	if (!adev->accel_working)
 		return -EBUSY;
+	if (amdgpu_kms_vram_lost(adev, fpriv))
+		return -ENODEV;
 
 	parser.adev = adev;
 	parser.filp = filp;
@@ -1165,12 +1168,15 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 {
 	union drm_amdgpu_wait_cs *wait = data;
 	struct amdgpu_device *adev = dev->dev_private;
+	struct amdgpu_fpriv *fpriv = filp->driver_priv;
 	unsigned long timeout = amdgpu_gem_timeout(wait->in.timeout);
 	struct amdgpu_ring *ring = NULL;
 	struct amdgpu_ctx *ctx;
 	struct dma_fence *fence;
 	long r;
 
+	if (amdgpu_kms_vram_lost(adev, fpriv))
+		return -ENODEV;
 	r = amdgpu_cs_get_ring(adev, wait->in.ip_type, wait->in.ip_instance,
 			       wait->in.ring, &ring);
 	if (r)
@@ -1344,12 +1350,15 @@ int amdgpu_cs_wait_fences_ioctl(struct drm_device *dev, void *data,
 				struct drm_file *filp)
 {
 	struct amdgpu_device *adev = dev->dev_private;
+	struct amdgpu_fpriv *fpriv = filp->driver_priv;
 	union drm_amdgpu_wait_fences *wait = data;
 	uint32_t fence_count = wait->in.fence_count;
 	struct drm_amdgpu_fence *fences_user;
 	struct drm_amdgpu_fence *fences;
 	int r;
 
+	if (amdgpu_kms_vram_lost(adev, fpriv))
+		return -ENODEV;
 	/* Get the fences from userspace */
 	fences = kmalloc_array(fence_count, sizeof(struct drm_amdgpu_fence),
 			GFP_KERNEL);

commit f93aa00c0bdc85ebd9ace72e34997cf4ba56e839
Author: Leo Liu <leo.liu@amd.com>
Date:   Tue Feb 21 11:24:09 2017 -0500

    drm/amdgpu: get cs support for AMDGPU_HW_IP_VCN_ENC
    
    Signed-off-by: Leo Liu <leo.liu@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 60948a7bd247..1375a896e87b 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -94,6 +94,15 @@ int amdgpu_cs_get_ring(struct amdgpu_device *adev, u32 ip_type,
 	case AMDGPU_HW_IP_VCN_DEC:
 		*out_ring = &adev->vcn.ring_dec;
 		break;
+	case AMDGPU_HW_IP_VCN_ENC:
+		if (ring < adev->vcn.num_enc_rings){
+			*out_ring = &adev->vcn.ring_enc[ring];
+		} else {
+			DRM_ERROR("only %d VCN ENC rings are supported\n",
+				adev->vcn.num_enc_rings);
+			return -EINVAL;
+		}
+		break;
 	}
 
 	if (!(*out_ring && (*out_ring)->adev)) {

commit fc739f82c5050ec9dc9a13cdcbc4ebb0dd590c37
Author: Leo Liu <leo.liu@amd.com>
Date:   Wed Jan 25 15:05:53 2017 -0500

    drm/amdgpu: get cs support of AMDGPU_HW_IP_VCN_DEC
    
    Signed-off-by: Leo Liu <leo.liu@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 4e6b9501ab0a..60948a7bd247 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -91,6 +91,9 @@ int amdgpu_cs_get_ring(struct amdgpu_device *adev, u32 ip_type,
 			return -EINVAL;
 		}
 		break;
+	case AMDGPU_HW_IP_VCN_DEC:
+		*out_ring = &adev->vcn.ring_dec;
+		break;
 	}
 
 	if (!(*out_ring && (*out_ring)->adev)) {

commit 2098105ec65cb364f3d77baa446b2ad5ba6bc7b9
Author: Michal Hocko <mhocko@kernel.org>
Date:   Wed May 17 14:23:12 2017 +0200

    drm: drop drm_[cm]alloc* helpers
    
    Now that drm_[cm]alloc* helpers are simple one line wrappers around
    kvmalloc_array and drm_free_large is just kvfree alias we can drop
    them and replace by their native forms.
    
    This shouldn't introduce any functional change.
    
    Changes since v1
    - fix typo in drivers/gpu//drm/etnaviv/etnaviv_gem.c - noticed by 0day
      build robot
    
    Suggested-by: Daniel Vetter <daniel@ffwll.ch>
    Signed-off-by: Michal Hocko <mhocko@suse.com>drm: drop drm_[cm]alloc* helpers
    [danvet: Fixup vgem which grew another user very recently.]
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Acked-by: Christian König <christian.koenig@amd.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20170517122312.GK18247@dhcp22.suse.cz

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 4e6b9501ab0a..5b3e0f63a115 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -194,7 +194,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		size = p->chunks[i].length_dw;
 		cdata = (void __user *)(uintptr_t)user_chunk.chunk_data;
 
-		p->chunks[i].kdata = drm_malloc_ab(size, sizeof(uint32_t));
+		p->chunks[i].kdata = kvmalloc_array(size, sizeof(uint32_t), GFP_KERNEL);
 		if (p->chunks[i].kdata == NULL) {
 			ret = -ENOMEM;
 			i--;
@@ -247,7 +247,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	i = p->nchunks - 1;
 free_partial_kdata:
 	for (; i >= 0; i--)
-		drm_free_large(p->chunks[i].kdata);
+		kvfree(p->chunks[i].kdata);
 	kfree(p->chunks);
 	p->chunks = NULL;
 	p->nchunks = 0;
@@ -505,7 +505,7 @@ static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 			return r;
 
 		if (binding_userptr) {
-			drm_free_large(lobj->user_pages);
+			kvfree(lobj->user_pages);
 			lobj->user_pages = NULL;
 		}
 	}
@@ -571,7 +571,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 				release_pages(e->user_pages,
 					      e->robj->tbo.ttm->num_pages,
 					      false);
-				drm_free_large(e->user_pages);
+				kvfree(e->user_pages);
 				e->user_pages = NULL;
 			}
 
@@ -601,8 +601,9 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		list_for_each_entry(e, &need_pages, tv.head) {
 			struct ttm_tt *ttm = e->robj->tbo.ttm;
 
-			e->user_pages = drm_calloc_large(ttm->num_pages,
-							 sizeof(struct page*));
+			e->user_pages = kvmalloc_array(ttm->num_pages,
+							 sizeof(struct page*),
+							 GFP_KERNEL | __GFP_ZERO);
 			if (!e->user_pages) {
 				r = -ENOMEM;
 				DRM_ERROR("calloc failure in %s\n", __func__);
@@ -612,7 +613,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 			r = amdgpu_ttm_tt_get_user_pages(ttm, e->user_pages);
 			if (r) {
 				DRM_ERROR("amdgpu_ttm_tt_get_user_pages failed.\n");
-				drm_free_large(e->user_pages);
+				kvfree(e->user_pages);
 				e->user_pages = NULL;
 				goto error_free_pages;
 			}
@@ -708,7 +709,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 			release_pages(e->user_pages,
 				      e->robj->tbo.ttm->num_pages,
 				      false);
-			drm_free_large(e->user_pages);
+			kvfree(e->user_pages);
 		}
 	}
 
@@ -761,7 +762,7 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
 		amdgpu_bo_list_put(parser->bo_list);
 
 	for (i = 0; i < parser->nchunks; i++)
-		drm_free_large(parser->chunks[i].kdata);
+		kvfree(parser->chunks[i].kdata);
 	kfree(parser->chunks);
 	if (parser->job)
 		amdgpu_job_free(parser->job);

commit 10e709cb296c98424c03408d23e3addeddcd4088
Author: Chunming Zhou <David1.Zhou@amd.com>
Date:   Thu Apr 27 15:13:52 2017 +0800

    drm/amdgpu: fix deadlock of reservation between cs and gpu reset v2
    
    the case could happen when gpu reset:
    1. when gpu reset, cs can be continue until sw queue is full, then push job will wait with holding pd reservation.
    2. gpu_reset routine will also need pd reservation to restore page table from their shadow.
    3. cs is waiting for gpu_reset complete, but gpu reset is waiting for cs releases reservation.
    
    v2: handle amdgpu_cs_submit error path.
    
    Signed-off-by: Chunming Zhou <David1.Zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Reviewed-by: Monk Liu <monk.liu@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index ec71b9320561..4e6b9501ab0a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1074,6 +1074,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring, p->fence);
 	job->uf_sequence = cs->out.handle;
 	amdgpu_job_free_resources(job);
+	amdgpu_cs_parser_fini(p, 0, true);
 
 	trace_amdgpu_cs_ioctl(job);
 	amd_sched_entity_push_job(&job->base);
@@ -1129,7 +1130,10 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		goto out;
 
 	r = amdgpu_cs_submit(&parser, cs);
+	if (r)
+		goto out;
 
+	return 0;
 out:
 	amdgpu_cs_parser_fini(&parser, r, reserved_buffers);
 	return r;

commit 32df87dff04833bbf53f1750f6c6048192ed29bf
Author: Chunming Zhou <David1.Zhou@amd.com>
Date:   Fri Apr 7 17:05:45 2017 +0800

    drm/amdgpu: fix fence memory leak in wait_all_fence V2
    
    V2: remove **array method, directly fence_put after fence wait.
    
    Signed-off-by: Chunming Zhou <David1.Zhou@amd.com>
    Reviewed-by: Christian König <chrstian.koenig@amd.com>
    Reviewed-by: Ken Wang <Qingqing.Wang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 9cd4e1e05b97..ec71b9320561 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1242,6 +1242,7 @@ static int amdgpu_cs_wait_all_fences(struct amdgpu_device *adev,
 			continue;
 
 		r = dma_fence_wait_timeout(fence, true, timeout);
+		dma_fence_put(fence);
 		if (r < 0)
 			return r;
 

commit f4e7c7c1b4ed4c28caf679bc94ca5aa096310c10
Author: Alex Xie <AlexBin.Xie@amd.com>
Date:   Wed Apr 5 16:54:34 2017 -0400

    drm/amdgpu: use uintptr_t instead of unsigned long to store pointer
    
    Signed-off-by: Alex Xie <AlexBin.Xie@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 9c7f7ed07ea0..9cd4e1e05b97 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -161,7 +161,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	}
 
 	/* get chunks */
-	chunk_array_user = (uint64_t __user *)(unsigned long)(cs->in.chunks);
+	chunk_array_user = (uint64_t __user *)(uintptr_t)(cs->in.chunks);
 	if (copy_from_user(chunk_array, chunk_array_user,
 			   sizeof(uint64_t)*cs->in.num_chunks)) {
 		ret = -EFAULT;
@@ -181,7 +181,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		struct drm_amdgpu_cs_chunk user_chunk;
 		uint32_t __user *cdata;
 
-		chunk_ptr = (void __user *)(unsigned long)chunk_array[i];
+		chunk_ptr = (void __user *)(uintptr_t)chunk_array[i];
 		if (copy_from_user(&user_chunk, chunk_ptr,
 				       sizeof(struct drm_amdgpu_cs_chunk))) {
 			ret = -EFAULT;
@@ -192,7 +192,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		p->chunks[i].length_dw = user_chunk.length_dw;
 
 		size = p->chunks[i].length_dw;
-		cdata = (void __user *)(unsigned long)user_chunk.chunk_data;
+		cdata = (void __user *)(uintptr_t)user_chunk.chunk_data;
 
 		p->chunks[i].kdata = drm_malloc_ab(size, sizeof(uint32_t));
 		if (p->chunks[i].kdata == NULL) {
@@ -1339,7 +1339,7 @@ int amdgpu_cs_wait_fences_ioctl(struct drm_device *dev, void *data,
 	if (fences == NULL)
 		return -ENOMEM;
 
-	fences_user = (void __user *)(unsigned long)(wait->in.fences);
+	fences_user = (void __user *)(uintptr_t)(wait->in.fences);
 	if (copy_from_user(fences, fences_user,
 		sizeof(struct drm_amdgpu_fence) * fence_count)) {
 		r = -EFAULT;

commit a9f87f6452543505108d7d9b36d948534ea28b0b
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Mar 30 14:03:59 2017 +0200

    drm/amdgpu: use a 64bit interval tree for VM management v2
    
    This only makes a difference for 32-bit systems. The idea is to have a
    fixed virtual address space size with 4-level page tables and to
    minimize differences between 32 and 64-bit systems.
    
    v2: Update commit message.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 97f661372a1c..9c7f7ed07ea0 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -949,7 +949,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 			}
 
 			if ((chunk_ib->va_start + chunk_ib->ib_bytes) >
-			    (m->it.last + 1) * AMDGPU_GPU_PAGE_SIZE) {
+			    (m->last + 1) * AMDGPU_GPU_PAGE_SIZE) {
 				DRM_ERROR("IB va_start+ib_bytes is invalid\n");
 				return -EINVAL;
 			}
@@ -960,7 +960,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 				return r;
 			}
 
-			offset = ((uint64_t)m->it.start) * AMDGPU_GPU_PAGE_SIZE;
+			offset = m->start * AMDGPU_GPU_PAGE_SIZE;
 			kptr += chunk_ib->va_start - offset;
 
 			r =  amdgpu_ib_get(adev, vm, chunk_ib->ib_bytes, ib);
@@ -1388,8 +1388,8 @@ amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 			continue;
 
 		list_for_each_entry(mapping, &lobj->bo_va->valids, list) {
-			if (mapping->it.start > addr ||
-			    addr > mapping->it.last)
+			if (mapping->start > addr ||
+			    addr > mapping->last)
 				continue;
 
 			*bo = lobj->bo_va->bo;
@@ -1397,8 +1397,8 @@ amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 		}
 
 		list_for_each_entry(mapping, &lobj->bo_va->invalids, list) {
-			if (mapping->it.start > addr ||
-			    addr > mapping->it.last)
+			if (mapping->start > addr ||
+			    addr > mapping->last)
 				continue;
 
 			*bo = lobj->bo_va->bo;

commit e51a3226d48fd02b37090a01c17587944743389a
Author: Harry Wentland <harry.wentland@amd.com>
Date:   Tue Mar 28 11:29:53 2017 -0400

    drm/amdgpu: Couple small warning fixes
    
    Signed-off-by: Harry Wentland <harry.wentland@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index c40c1a16e72e..97f661372a1c 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -904,11 +904,12 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 			continue;
 
 		if (chunk_ib->ip_type == AMDGPU_HW_IP_GFX && amdgpu_sriov_vf(adev)) {
-			if (chunk_ib->flags & AMDGPU_IB_FLAG_PREEMPT)
+			if (chunk_ib->flags & AMDGPU_IB_FLAG_PREEMPT) {
 				if (chunk_ib->flags & AMDGPU_IB_FLAG_CE)
 					ce_preempt++;
 				else
 					de_preempt++;
+			}
 
 			/* each GFX command submit allows 0 or 1 IB preemptible for CE & DE */
 			if (ce_preempt > 1 || de_preempt > 1)

commit e9d672b2910a8d5e528d859dce9ad9baa748087a
Author: Monk Liu <Monk.Liu@amd.com>
Date:   Wed Mar 15 12:18:57 2017 +0800

    drm/amdgpu:changes in gfx DMAframe scheme (v2)
    
    1) Adapt to vulkan:
    Now use double SWITCH BUFFER to replace the 128 nops w/a,
    because when vulkan introduced, umd can insert 7 ~ 16 IBs
    per submit which makes 256 DW size cannot hold the whole
    DMAframe (if we still insert those 128 nops), CP team suggests
    use double SWITCH_BUFFERs, instead of tricky 128 NOPs w/a.
    
    2) To fix the CE VM fault issue when MCBP introduced:
    Need one more COND_EXEC wrapping IB part (original one us
    for VM switch part).
    
    this change can fix vm fault issue caused by below scenario
    without this change:
    
    >CE passed original COND_EXEC (no MCBP issued this moment),
     proceed as normal.
    
    >DE catch up to this COND_EXEC, but this time MCBP issued,
     thus DE treats all following packages as NOP. The following
     VM switch packages now looks just as NOP to DE, so DE
     dosen't do VM flush at all.
    
    >Now CE proceeds to the first IBc, and triggers VM fault,
     because DE didn't do VM flush for this DMAframe.
    
    3) change estimated alloc size for gfx9.
    with new DMAframe scheme, we need modify emit_frame_size
    for gfx9
    
    4) No need to insert 128 nops after gfx8 vm flush anymore
    because there was double SWITCH_BUFFER append to vm flush,
    and for gfx7 we already use double SWITCH_BUFFER following
    after vm_flush so no change needed for it.
    
    5) Change emit_frame_size for gfx8
    
    v2: squash in BUG removal from Monk
    
    Signed-off-by: Monk Liu <Monk.Liu@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 2957404bd44a..c40c1a16e72e 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -912,7 +912,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 
 			/* each GFX command submit allows 0 or 1 IB preemptible for CE & DE */
 			if (ce_preempt > 1 || de_preempt > 1)
-				BUG();
+				return -EINVAL;
 		}
 
 		r = amdgpu_cs_get_ring(adev, chunk_ib->ip_type,

commit 65333e4429c60b8bbbb7a9213cb5612761499acd
Author: Monk Liu <Monk.Liu@amd.com>
Date:   Mon Mar 27 15:14:53 2017 +0800

    drm/amdgpu:fix the check in cs_ib_fill for SRIOV
    
    1,the check is only appliable for SRIOV GFX engine.
    2,use chunk_ib instead of ib.
    
    Signed-off-by: Monk Liu <Monk.Liu@amd.com>
    Reviewed-by: Ken Wang <Qingqing.wang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index cf44388b5bce..2957404bd44a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -903,17 +903,18 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		if (chunk->chunk_id != AMDGPU_CHUNK_ID_IB)
 			continue;
 
-		if (ib->flags & AMDGPU_IB_FLAG_PREEMPT) {
-			if (ib->flags & AMDGPU_IB_FLAG_CE)
-				ce_preempt++;
-			else
-				de_preempt++;
+		if (chunk_ib->ip_type == AMDGPU_HW_IP_GFX && amdgpu_sriov_vf(adev)) {
+			if (chunk_ib->flags & AMDGPU_IB_FLAG_PREEMPT)
+				if (chunk_ib->flags & AMDGPU_IB_FLAG_CE)
+					ce_preempt++;
+				else
+					de_preempt++;
+
+			/* each GFX command submit allows 0 or 1 IB preemptible for CE & DE */
+			if (ce_preempt > 1 || de_preempt > 1)
+				BUG();
 		}
 
-		/* only one preemptible IB per submit for me/ce */
-		if (ce_preempt > 1 || de_preempt > 1)
-			return -EINVAL;
-
 		r = amdgpu_cs_get_ring(adev, chunk_ib->ip_type,
 				       chunk_ib->ip_instance, chunk_ib->ring,
 				       &ring);

commit 9a1b3af10d6268a98076a4397cb1d47c4713efc7
Author: Monk Liu <Monk.Liu@amd.com>
Date:   Wed Mar 8 15:51:13 2017 +0800

    drm/amdgpu:protect cs submit
    
    to prevent submit two or more IBs with PREEMPT flags.
    
    Signed-off-by: Monk Liu <Monk.Liu@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 63d690542761..cf44388b5bce 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -888,7 +888,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 	struct amdgpu_fpriv *fpriv = parser->filp->driver_priv;
 	struct amdgpu_vm *vm = &fpriv->vm;
 	int i, j;
-	int r;
+	int r, ce_preempt = 0, de_preempt = 0;
 
 	for (i = 0, j = 0; i < parser->nchunks && j < parser->job->num_ibs; i++) {
 		struct amdgpu_cs_chunk *chunk;
@@ -903,6 +903,17 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		if (chunk->chunk_id != AMDGPU_CHUNK_ID_IB)
 			continue;
 
+		if (ib->flags & AMDGPU_IB_FLAG_PREEMPT) {
+			if (ib->flags & AMDGPU_IB_FLAG_CE)
+				ce_preempt++;
+			else
+				de_preempt++;
+		}
+
+		/* only one preemptible IB per submit for me/ce */
+		if (ce_preempt > 1 || de_preempt > 1)
+			return -EINVAL;
+
 		r = amdgpu_cs_get_ring(adev, chunk_ib->ip_type,
 				       chunk_ib->ip_instance, chunk_ib->ring,
 				       &ring);

commit 2a9ceb8daab01a4ee27383e4d344e4a8b781c165
Author: Monk Liu <Monk.Liu@amd.com>
Date:   Tue Mar 28 11:00:03 2017 +0800

    drm/amdgpu:fix cs_ib_fill
    
    should use chunk_ib instead of ib, otherwise the logic
    is incorrect.
    
    Signed-off-by: Monk Liu <Monk.Liu@amd.com>
    Reviewed-by: Ken Wang <Qingqing.wang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index bf64a0d1c1f4..63d690542761 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -909,7 +909,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		if (r)
 			return r;
 
-		if (ib->flags & AMDGPU_IB_FLAG_PREAMBLE) {
+		if (chunk_ib->flags & AMDGPU_IB_FLAG_PREAMBLE) {
 			parser->job->preamble_status |= AMDGPU_PREAMBLE_IB_PRESENT;
 			if (!parser->ctx->preamble_presented) {
 				parser->job->preamble_status |= AMDGPU_PREAMBLE_IB_PRESENT_FIRST;

commit 194d2161131b35f9cd4cf3e355f2d7cd3b296898
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Oct 12 15:13:52 2016 +0200

    drm/amdgpu: handle multi level PD updates V2
    
    Update all levels of the page directory.
    
    V2:
    a. sub level pdes always are written to incorrect place.
    b. sub levels need to update regardless of parent updates.
    
    Signed-off-by: Christian König <christian.koenig@amd.com> (V1)
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com> (V1)
    Signed-off-by: Chunming Zhou <David1.Zhou@amd.com> (V2)
    Acked-by: Alex Deucher <alexander.deucher@amd.com> (V2)
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 2e11b48d92e7..bf64a0d1c1f4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -777,7 +777,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 	struct amdgpu_bo *bo;
 	int i, r;
 
-	r = amdgpu_vm_update_page_directory(adev, vm);
+	r = amdgpu_vm_update_directories(adev, vm);
 	if (r)
 		return r;
 

commit 67003a15b736988bcb0c5f871be353d702a862ba
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Oct 12 14:46:26 2016 +0200

    drm/amdgpu: generalize page table level
    
    No functional change, but the base for multi level page tables.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index e68a3a511847..2e11b48d92e7 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -872,7 +872,7 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 	}
 
 	if (p->job->vm) {
-		p->job->vm_pd_addr = amdgpu_bo_gpu_offset(vm->page_directory);
+		p->job->vm_pd_addr = amdgpu_bo_gpu_offset(vm->root.bo);
 
 		r = amdgpu_bo_vm_update_pte(p);
 		if (r)

commit a24960f321dc5b59db3428733da5021af9bc7973
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Oct 12 13:20:52 2016 +0200

    drm/amdgpu: rename page_directory_fence to last_dir_update
    
    Decribes better what this is used for.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index e83a6dcf2f68..e68a3a511847 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -781,7 +781,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 	if (r)
 		return r;
 
-	r = amdgpu_sync_fence(adev, &p->job->sync, vm->page_directory_fence);
+	r = amdgpu_sync_fence(adev, &p->job->sync, vm->last_dir_update);
 	if (r)
 		return r;
 

commit f34678187a339702256c70c88c3db2d1975484ce
Author: Nicolai Hähnle <nicolai.haehnle@amd.com>
Date:   Thu Mar 23 19:36:31 2017 +0100

    drm/amdgpu: add optional fence out-parameter to amdgpu_vm_clear_freed
    
    We will add the fence to freed buffer objects in a later commit, to ensure
    that the underlying memory can only be re-used after all references in
    page tables have been cleared.
    
    Signed-off-by: Nicolai Hähnle <nicolai.haehnle@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 419fab50dc54..e83a6dcf2f68 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -785,7 +785,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 	if (r)
 		return r;
 
-	r = amdgpu_vm_clear_freed(adev, vm);
+	r = amdgpu_vm_clear_freed(adev, vm, NULL);
 	if (r)
 		return r;
 

commit 166c8178fb25e2b933184a4d695cdb4fe08de427
Author: Leo Liu <leo.liu@amd.com>
Date:   Tue Jan 10 11:57:24 2017 -0500

    drm/amdgpu: get cs support of AMDGPU_HW_IP_UVD_ENC
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Leo Liu <leo.liu@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 89dcb07ab213..419fab50dc54 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -82,6 +82,15 @@ int amdgpu_cs_get_ring(struct amdgpu_device *adev, u32 ip_type,
 			return -EINVAL;
 		}
 		break;
+	case AMDGPU_HW_IP_UVD_ENC:
+		if (ring < adev->uvd.num_enc_rings){
+			*out_ring = &adev->uvd.ring_enc[ring];
+		} else {
+			DRM_ERROR("only %d UVD ENC rings are supported\n",
+				adev->uvd.num_enc_rings);
+			return -EINVAL;
+		}
+		break;
 	}
 
 	if (!(*out_ring && (*out_ring)->adev)) {

commit b85891bd6d1bf887b3398f4c44b7a30b37f4485e
Author: Junwei Zhang <Jerry.Zhang@amd.com>
Date:   Mon Jan 16 13:59:01 2017 +0800

    drm/amdgpu: IOCTL interface for PRT support v4
    
    Till GFX8 we can only enable PRT support globally, but with the next hardware
    generation we can do this on a per page basis.
    
    Keep the interface consistent by adding PRT mappings and enable
    support globally on current hardware when the first mapping is made.
    
    v2: disable PRT support delayed and on all error paths
    v3: PRT and other permissions are mutal exclusive,
        PRT mappings don't need a BO.
    v4: update PRT mappings durign CS as well, make va_flags 64bit
    
    Signed-off-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Nicolai Hähnle <nicolai.haehnle@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 99424cb8020b..89dcb07ab213 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -759,10 +759,11 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
 	amdgpu_bo_unref(&parser->uf_entry.robj);
 }
 
-static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
-				   struct amdgpu_vm *vm)
+static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p)
 {
 	struct amdgpu_device *adev = p->adev;
+	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
+	struct amdgpu_vm *vm = &fpriv->vm;
 	struct amdgpu_bo_va *bo_va;
 	struct amdgpu_bo *bo;
 	int i, r;
@@ -779,6 +780,15 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 	if (r)
 		return r;
 
+	r = amdgpu_vm_bo_update(adev, fpriv->prt_va, false);
+	if (r)
+		return r;
+
+	r = amdgpu_sync_fence(adev, &p->job->sync,
+			      fpriv->prt_va->last_pt_update);
+	if (r)
+		return r;
+
 	if (amdgpu_sriov_vf(adev)) {
 		struct dma_fence *f;
 		bo_va = vm->csa_bo_va;
@@ -855,7 +865,7 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 	if (p->job->vm) {
 		p->job->vm_pd_addr = amdgpu_bo_gpu_offset(vm->page_directory);
 
-		r = amdgpu_bo_vm_update_pte(p, vm);
+		r = amdgpu_bo_vm_update_pte(p);
 		if (r)
 			return r;
 	}

commit 607523d19c9d67ba4cf7bdaced644f11ed04992c
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri Mar 10 12:13:04 2017 +1000

    drm/amdgpu: fix parser init error path to avoid crash in parser fini
    
    If we don't reset the chunk info in the error path, the subsequent
    fini path will double free.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index d2d0f60ff36d..99424cb8020b 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -240,6 +240,8 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	for (; i >= 0; i--)
 		drm_free_large(p->chunks[i].kdata);
 	kfree(p->chunks);
+	p->chunks = NULL;
+	p->nchunks = 0;
 put_ctx:
 	amdgpu_ctx_put(p->ctx);
 free_chunk:

commit 94000cc32988a0674923309d35ab9c2405c4b39b
Merge: a5eb76d9c892 7089db84e356
Author: Dave Airlie <airlied@redhat.com>
Date:   Thu Feb 23 12:10:12 2017 +1000

    Merge tag 'v4.10-rc8' into drm-next
    
    Linux 4.10-rc8
    
    Backmerge Linus rc8 to fix some conflicts, but also
    to avoid pulling it in via a fixes pull from someone.

commit fad061270ac43ff9eed315f0eae7c40b694592de
Author: Samuel Pitoiset <samuel.pitoiset@gmail.com>
Date:   Thu Feb 9 11:33:37 2017 +0100

    drm/amdgpu: report the number of bytes moved at buffer creation
    
    Like ttm_bo_validate(), ttm_bo_init() might need to move BO and
    the number of bytes moved by TTM should be reported. This can help
    the throttle buffer migration mechanism to make a better decision.
    
    v2: fix computation
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index cf2e8c4e9b8b..57301f5936fa 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -344,8 +344,7 @@ static u64 amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev)
  * submission. This can result in a debt that can stop buffer migrations
  * temporarily.
  */
-static void amdgpu_cs_report_moved_bytes(struct amdgpu_device *adev,
-					 u64 num_bytes)
+void amdgpu_cs_report_moved_bytes(struct amdgpu_device *adev, u64 num_bytes)
 {
 	spin_lock(&adev->mm_stats.lock);
 	adev->mm_stats.accum_us -= bytes_to_us(adev, num_bytes);

commit 034041f33498ba57d9fd1d3e4aea7e40ea4988da
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Wed Jan 11 16:11:48 2017 -0500

    drm/amdgpu: use the num_rings variable for checking vce rings
    
    Difference families may have different numbers of rings. Use
    the variable rather than a hardcoded number.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 8d019ca7d9c7..cf2e8c4e9b8b 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -75,10 +75,10 @@ int amdgpu_cs_get_ring(struct amdgpu_device *adev, u32 ip_type,
 		*out_ring = &adev->uvd.ring;
 		break;
 	case AMDGPU_HW_IP_VCE:
-		if (ring < 2){
+		if (ring < adev->vce.num_rings){
 			*out_ring = &adev->vce.ring[ring];
 		} else {
-			DRM_ERROR("only two VCE rings are supported\n");
+			DRM_ERROR("only %d VCE rings are supported\n", adev->vce.num_rings);
 			return -EINVAL;
 		}
 		break;

commit 2493664f0594d4140a5025de8e419ca2c16ccee9
Author: Monk Liu <Monk.Liu@amd.com>
Date:   Mon Jan 9 15:54:32 2017 +0800

    drm/amdgpu:invoke CSA functions (v2)
    
    Make sure the CSA is mapped.
    
    v2: agd: rebase.
    
    Signed-off-by: Monk Liu <Monk.Liu@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 29d6d84d1c28..8d019ca7d9c7 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -771,6 +771,20 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 	if (r)
 		return r;
 
+	if (amdgpu_sriov_vf(adev)) {
+		struct dma_fence *f;
+		bo_va = vm->csa_bo_va;
+		BUG_ON(!bo_va);
+		r = amdgpu_vm_bo_update(adev, bo_va, false);
+		if (r)
+			return r;
+
+		f = bo_va->last_pt_update;
+		r = amdgpu_sync_fence(adev, &p->job->sync, f);
+		if (r)
+			return r;
+	}
+
 	if (p->bo_list) {
 		for (i = 0; i < p->bo_list->num_entries; i++) {
 			struct dma_fence *f;

commit c5f21c9f878b8dcd54d0b9739c025ca73cb4c091
Author: Ding Pixel <pding@amd.com>
Date:   Wed Jan 18 17:26:38 2017 +0800

    drm/amdgpu: check ring being ready before using
    
    Return success when the ring is properly initialized, otherwise return
    failure.
    
    Tonga SRIOV VF doesn't have UVD and VCE engines, the initialization of
    these IPs is bypassed. The system crashes if application submit IB to
    their rings which are not ready to use. It could be a common issue if
    IP having ring buffer is disabled for some reason on specific ASIC, so
    it should check the ring being ready to use.
    
    Bug: amdgpu_test crashes system on Tonga VF.
    
    Signed-off-by: Ding Pixel <Pixel.Ding@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 29d6d84d1c28..41e41f90265d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -83,6 +83,13 @@ int amdgpu_cs_get_ring(struct amdgpu_device *adev, u32 ip_type,
 		}
 		break;
 	}
+
+	if (!(*out_ring && (*out_ring)->adev)) {
+		DRM_ERROR("Ring %d is not initialized on IP %d\n",
+			  ring, ip_type);
+		return -EINVAL;
+	}
+
 	return 0;
 }
 

commit 1cd99a8d97c90e04d526d843f2be950f6e4e3bd2
Author: Alex Xie <AlexBin.Xie@amd.com>
Date:   Wed Nov 30 17:19:40 2016 -0500

    drm/amd/amdgpu: validate the shadow BO.
    
    Fixes a rare NULL pointer dereference in amdgpu_ttm_bind.
    
    The issue was found by Nicolai Haehnle.
    The patch was tested by Nicolai Haehnle.
    
    Signed-off-by: Alex Xie <AlexBin.Xie@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 5a277495d6a3..29d6d84d1c28 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -451,7 +451,7 @@ static int amdgpu_cs_validate(void *param, struct amdgpu_bo *bo)
 		return r;
 
 	if (bo->shadow)
-		r = amdgpu_cs_bo_validate(p, bo);
+		r = amdgpu_cs_bo_validate(p, bo->shadow);
 
 	return r;
 }

commit 47ecd3c4e09ee8dfd1dbd2728278ccec78ab43b9
Author: Huang Rui <ray.huang@amd.com>
Date:   Mon Oct 31 17:00:21 2016 +0800

    drm/amdgpu: remove amdgpu_cs_handle_lockup
    
    In fence waiting, it never return -EDEADLK yet, so drop this function
    here.
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 15c56c825b86..5a277495d6a3 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -841,16 +841,6 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 	return amdgpu_cs_sync_rings(p);
 }
 
-static int amdgpu_cs_handle_lockup(struct amdgpu_device *adev, int r)
-{
-	if (r == -EDEADLK) {
-		r = amdgpu_gpu_reset(adev);
-		if (!r)
-			r = -EAGAIN;
-	}
-	return r;
-}
-
 static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 			     struct amdgpu_cs_parser *parser)
 {
@@ -1088,7 +1078,6 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 out:
 	amdgpu_cs_parser_fini(&parser, r, reserved_buffers);
-	r = amdgpu_cs_handle_lockup(adev, r);
 	return r;
 }
 

commit a414cd708b1617d6b31acdc74a6cfecbae2a172f
Author: Huang Rui <ray.huang@amd.com>
Date:   Sun Oct 30 23:05:47 2016 +0800

    drm/amdgpu: cleanup amdgpu_cs_ioctl to make code logicality clear
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 78da52f90099..15c56c825b86 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1054,29 +1054,29 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	r = amdgpu_cs_parser_init(&parser, data);
 	if (r) {
 		DRM_ERROR("Failed to initialize parser !\n");
-		amdgpu_cs_parser_fini(&parser, r, false);
-		r = amdgpu_cs_handle_lockup(adev, r);
-		return r;
-	}
-	r = amdgpu_cs_parser_bos(&parser, data);
-	if (r == -ENOMEM)
-		DRM_ERROR("Not enough memory for command submission!\n");
-	else if (r && r != -ERESTARTSYS)
-		DRM_ERROR("Failed to process the buffer list %d!\n", r);
-	else if (!r) {
-		reserved_buffers = true;
-		r = amdgpu_cs_ib_fill(adev, &parser);
+		goto out;
 	}
 
-	if (!r) {
-		r = amdgpu_cs_dependencies(adev, &parser);
-		if (r)
-			DRM_ERROR("Failed in the dependencies handling %d!\n", r);
+	r = amdgpu_cs_parser_bos(&parser, data);
+	if (r) {
+		if (r == -ENOMEM)
+			DRM_ERROR("Not enough memory for command submission!\n");
+		else if (r != -ERESTARTSYS)
+			DRM_ERROR("Failed to process the buffer list %d!\n", r);
+		goto out;
 	}
 
+	reserved_buffers = true;
+	r = amdgpu_cs_ib_fill(adev, &parser);
 	if (r)
 		goto out;
 
+	r = amdgpu_cs_dependencies(adev, &parser);
+	if (r) {
+		DRM_ERROR("Failed in the dependencies handling %d!\n", r);
+		goto out;
+	}
+
 	for (i = 0; i < parser.job->num_ibs; i++)
 		trace_amdgpu_cs(&parser, i);
 

commit 3e91168a6a76f7e21c44f04ebf953589ca59f03c
Merge: db8feb6979e9 4b514e10157a
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri Nov 11 09:28:44 2016 +1000

    Merge tag 'topic/drm-misc-2016-11-10' of git://anongit.freedesktop.org/drm-intel into drm-next
    
    - better atomic state debugging from Rob
    - fence prep from gustavo
    - sumits flushed out his backlog of pending dma-buf/fence patches from
      various people
    - drm_mm leak debugging plus trying to appease Kconfig (Chris)
    - a few misc things all over
    
    * tag 'topic/drm-misc-2016-11-10' of git://anongit.freedesktop.org/drm-intel: (35 commits)
      drm: Make DRM_DEBUG_MM depend on STACKTRACE_SUPPORT
      drm/i915: Restrict DRM_DEBUG_MM automatic selection
      drm: Restrict stackdepot usage to builtin drm.ko
      drm/msm: module param to dump state on error irq
      drm/msm/mdp5: add atomic_print_state support
      drm/atomic: add debugfs file to dump out atomic state
      drm/atomic: add new drm_debug bit to dump atomic state
      drm: add helpers to go from plane state to drm_rect
      drm: add helper for printing to log or seq_file
      drm: helper macros to print composite types
      reservation: revert "wait only with non-zero timeout specified (v3)" v2
      drm/ttm: fix ttm_bo_wait
      dma-buf/fence: revert "don't wait when specified timeout is zero" (v2)
      dma-buf/fence: make timeout handling in fence_default_wait consistent (v2)
      drm/amdgpu: add the interface of waiting multiple fences (v4)
      dma-buf: return index of the first signaled fence (v2)
      MAINTAINERS: update Sync File Framework files
      dma-buf/sw_sync: put fence reference from the fence creation
      dma-buf/sw_sync: mark sync_timeline_create() static
      drm: Add stackdepot include for DRM_DEBUG_MM
      ...

commit eef18a827a9ec58aa9fc1ccfb7e65ff04ebc25f3
Author: Junwei Zhang <Jerry.Zhang@amd.com>
Date:   Fri Nov 4 16:16:10 2016 -0400

    drm/amdgpu: add the interface of waiting multiple fences (v4)
    
    v2: agd: rebase and squash in all the previous optimizations and
    changes so everything compiles.
    v3: squash in Slava's 32bit build fix
    v4: rebase on drm-next (fence -> dma_fence),
        squash in Monk's ioctl update patch
    
    Signed-off-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Reviewed-by: Monk Liu <monk.liu@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Sumit Semwal <sumit.semwal@linaro.org>
     [sumits: fix checkpatch warnings]
    Link: http://patchwork.freedesktop.org/patch/msgid/1478290570-30982-2-git-send-email-alexander.deucher@amd.com

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index a024217896fd..b4bc83aa5999 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1139,6 +1139,180 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 	return 0;
 }
 
+/**
+ * amdgpu_cs_get_fence - helper to get fence from drm_amdgpu_fence
+ *
+ * @adev: amdgpu device
+ * @filp: file private
+ * @user: drm_amdgpu_fence copied from user space
+ */
+static struct dma_fence *amdgpu_cs_get_fence(struct amdgpu_device *adev,
+					     struct drm_file *filp,
+					     struct drm_amdgpu_fence *user)
+{
+	struct amdgpu_ring *ring;
+	struct amdgpu_ctx *ctx;
+	struct dma_fence *fence;
+	int r;
+
+	r = amdgpu_cs_get_ring(adev, user->ip_type, user->ip_instance,
+			       user->ring, &ring);
+	if (r)
+		return ERR_PTR(r);
+
+	ctx = amdgpu_ctx_get(filp->driver_priv, user->ctx_id);
+	if (ctx == NULL)
+		return ERR_PTR(-EINVAL);
+
+	fence = amdgpu_ctx_get_fence(ctx, ring, user->seq_no);
+	amdgpu_ctx_put(ctx);
+
+	return fence;
+}
+
+/**
+ * amdgpu_cs_wait_all_fence - wait on all fences to signal
+ *
+ * @adev: amdgpu device
+ * @filp: file private
+ * @wait: wait parameters
+ * @fences: array of drm_amdgpu_fence
+ */
+static int amdgpu_cs_wait_all_fences(struct amdgpu_device *adev,
+				     struct drm_file *filp,
+				     union drm_amdgpu_wait_fences *wait,
+				     struct drm_amdgpu_fence *fences)
+{
+	uint32_t fence_count = wait->in.fence_count;
+	unsigned int i;
+	long r = 1;
+
+	for (i = 0; i < fence_count; i++) {
+		struct dma_fence *fence;
+		unsigned long timeout = amdgpu_gem_timeout(wait->in.timeout_ns);
+
+		fence = amdgpu_cs_get_fence(adev, filp, &fences[i]);
+		if (IS_ERR(fence))
+			return PTR_ERR(fence);
+		else if (!fence)
+			continue;
+
+		r = dma_fence_wait_timeout(fence, true, timeout);
+		if (r < 0)
+			return r;
+
+		if (r == 0)
+			break;
+	}
+
+	memset(wait, 0, sizeof(*wait));
+	wait->out.status = (r > 0);
+
+	return 0;
+}
+
+/**
+ * amdgpu_cs_wait_any_fence - wait on any fence to signal
+ *
+ * @adev: amdgpu device
+ * @filp: file private
+ * @wait: wait parameters
+ * @fences: array of drm_amdgpu_fence
+ */
+static int amdgpu_cs_wait_any_fence(struct amdgpu_device *adev,
+				    struct drm_file *filp,
+				    union drm_amdgpu_wait_fences *wait,
+				    struct drm_amdgpu_fence *fences)
+{
+	unsigned long timeout = amdgpu_gem_timeout(wait->in.timeout_ns);
+	uint32_t fence_count = wait->in.fence_count;
+	uint32_t first = ~0;
+	struct dma_fence **array;
+	unsigned int i;
+	long r;
+
+	/* Prepare the fence array */
+	array = kcalloc(fence_count, sizeof(struct dma_fence *), GFP_KERNEL);
+
+	if (array == NULL)
+		return -ENOMEM;
+
+	for (i = 0; i < fence_count; i++) {
+		struct dma_fence *fence;
+
+		fence = amdgpu_cs_get_fence(adev, filp, &fences[i]);
+		if (IS_ERR(fence)) {
+			r = PTR_ERR(fence);
+			goto err_free_fence_array;
+		} else if (fence) {
+			array[i] = fence;
+		} else { /* NULL, the fence has been already signaled */
+			r = 1;
+			goto out;
+		}
+	}
+
+	r = dma_fence_wait_any_timeout(array, fence_count, true, timeout,
+				       &first);
+	if (r < 0)
+		goto err_free_fence_array;
+
+out:
+	memset(wait, 0, sizeof(*wait));
+	wait->out.status = (r > 0);
+	wait->out.first_signaled = first;
+	/* set return value 0 to indicate success */
+	r = 0;
+
+err_free_fence_array:
+	for (i = 0; i < fence_count; i++)
+		dma_fence_put(array[i]);
+	kfree(array);
+
+	return r;
+}
+
+/**
+ * amdgpu_cs_wait_fences_ioctl - wait for multiple command submissions to finish
+ *
+ * @dev: drm device
+ * @data: data from userspace
+ * @filp: file private
+ */
+int amdgpu_cs_wait_fences_ioctl(struct drm_device *dev, void *data,
+				struct drm_file *filp)
+{
+	struct amdgpu_device *adev = dev->dev_private;
+	union drm_amdgpu_wait_fences *wait = data;
+	uint32_t fence_count = wait->in.fence_count;
+	struct drm_amdgpu_fence *fences_user;
+	struct drm_amdgpu_fence *fences;
+	int r;
+
+	/* Get the fences from userspace */
+	fences = kmalloc_array(fence_count, sizeof(struct drm_amdgpu_fence),
+			GFP_KERNEL);
+	if (fences == NULL)
+		return -ENOMEM;
+
+	fences_user = (void __user *)(unsigned long)(wait->in.fences);
+	if (copy_from_user(fences, fences_user,
+		sizeof(struct drm_amdgpu_fence) * fence_count)) {
+		r = -EFAULT;
+		goto err_free_fences;
+	}
+
+	if (wait->in.wait_all)
+		r = amdgpu_cs_wait_all_fences(adev, filp, wait, fences);
+	else
+		r = amdgpu_cs_wait_any_fence(adev, filp, wait, fences);
+
+err_free_fences:
+	kfree(fences);
+
+	return r;
+}
+
 /**
  * amdgpu_cs_find_bo_va - find bo_va for VM address
  *

commit 7b624ad8fea1be7ff4c22643e212191aa6a2a3c2
Merge: dc345c46774b bc33b0ca11e3
Author: Dave Airlie <airlied@redhat.com>
Date:   Mon Nov 7 09:37:09 2016 +1000

    Backmerge tag 'v4.9-rc4' into drm-next
    
    Linux 4.9-rc4
    
    This is needed for nouveau development.

commit 220196b38483be6d84a295d318d48595f65da443
Merge: a1873c62710b 56df51d00320
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri Oct 28 11:33:52 2016 +1000

    Merge tag 'topic/drm-misc-2016-10-27' of git://anongit.freedesktop.org/git/drm-intel into drm-next
    
    Pull request already again to get the s/fence/dma_fence/ stuff in and
    allow everyone to resync. Otherwise really just misc stuff all over, and a
    new bridge driver.
    
    * tag 'topic/drm-misc-2016-10-27' of git://anongit.freedesktop.org/git/drm-intel:
      drm/bridge: fix platform_no_drv_owner.cocci warnings
      drm/bridge: fix semicolon.cocci warnings
      drm: Print some debug/error info during DP dual mode detect
      drm: mark drm_of_component_match_add dummy inline
      drm/bridge: add Silicon Image SiI8620 driver
      dt-bindings: add Silicon Image SiI8620 bridge bindings
      video: add header file for Mobile High-Definition Link (MHL) interface
      drm: convert DT component matching to component_match_add_release()
      dma-buf: Rename struct fence to dma_fence
      dma-buf/fence: add an lockdep_assert_held()
      drm/dp: Factor out helper to distinguish between branch and sink devices
      drm/edid: Only print the bad edid when aborting
      drm/msm: add missing header dependencies
      drm/msm/adreno: move function declarations to header file
      drm/i2c/tda998x: mark symbol static where possible
      doc: add missing docbook parameter for fence-array
      drm: RIP mode_config->rotation_property
      drm/msm/mdp5: Advertize 180 degree rotation
      drm/msm/mdp5: Use per-plane rotation property

commit 45088efc8529de969de91dcefb6284f8d7837cd6
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Oct 5 16:49:19 2016 +0200

    drm/amdgpu: improve parse_cs handling a bit
    
    This way we can use parse_cs and still keep VM mode enabled.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-and-Tested by: Leo Liu <leo.liu@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 04b7aaf770e4..cf03f9f01f40 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -822,13 +822,14 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 
 	/* Only for UVD/VCE VM emulation */
 	if (ring->funcs->parse_cs) {
-		p->job->vm = NULL;
 		for (i = 0; i < p->job->num_ibs; i++) {
 			r = amdgpu_ring_parse_cs(ring, p, i);
 			if (r)
 				return r;
 		}
-	} else {
+	}
+
+	if (p->job->vm) {
 		p->job->vm_pd_addr = amdgpu_bo_gpu_offset(vm->page_directory);
 
 		r = amdgpu_bo_vm_update_pte(p, vm);
@@ -917,7 +918,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 			offset = ((uint64_t)m->it.start) * AMDGPU_GPU_PAGE_SIZE;
 			kptr += chunk_ib->va_start - offset;
 
-			r =  amdgpu_ib_get(adev, NULL, chunk_ib->ib_bytes, ib);
+			r =  amdgpu_ib_get(adev, vm, chunk_ib->ib_bytes, ib);
 			if (r) {
 				DRM_ERROR("Failed to get ib !\n");
 				return r;
@@ -932,9 +933,9 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 				return r;
 			}
 
-			ib->gpu_addr = chunk_ib->va_start;
 		}
 
+		ib->gpu_addr = chunk_ib->va_start;
 		ib->length_dw = chunk_ib->ib_bytes / 4;
 		ib->flags = chunk_ib->flags;
 		j++;

commit 21cd942e5c471941769cd0515164b169d012ad8a
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Oct 5 15:36:39 2016 +0200

    drm/amdgpu: move the ring type into the funcs structure (v2)
    
    It's constant, so it doesn't make to much sense to keep it
    with the variable data.
    
    v2: update vce and uvd phys mode ring structures as well
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index a13e551e67cf..04b7aaf770e4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -942,8 +942,8 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 
 	/* UVD & VCE fw doesn't support user fences */
 	if (parser->job->uf_addr && (
-	    parser->job->ring->type == AMDGPU_RING_TYPE_UVD ||
-	    parser->job->ring->type == AMDGPU_RING_TYPE_VCE))
+	    parser->job->ring->funcs->type == AMDGPU_RING_TYPE_UVD ||
+	    parser->job->ring->funcs->type == AMDGPU_RING_TYPE_VCE))
 		return -EINVAL;
 
 	return 0;

commit f7da30d979d4c6af4b7f4fe3094e581d8c5812d7
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Sep 28 12:03:04 2016 +0200

    drm/amdgpu: move PT validation back into VM code v2
    
    Saves a bunch of CPU cycles when swapping things back in and
    allows us to split the VM headers into a separate file.
    
    v2: rename parameters
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 504ae09d3991..a13e551e67cf 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -388,9 +388,9 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 
 /* Last resort, try to evict something from the current working set */
 static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
-				struct amdgpu_bo_list_entry *lobj)
+				struct amdgpu_bo *validated)
 {
-	uint32_t domain = lobj->robj->allowed_domains;
+	uint32_t domain = validated->allowed_domains;
 	int r;
 
 	if (!p->evictable)
@@ -406,7 +406,7 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 		uint32_t other;
 
 		/* If we reached our current BO we can forget it */
-		if (candidate == lobj)
+		if (candidate->robj == validated)
 			break;
 
 		other = amdgpu_mem_type_to_domain(bo->tbo.mem.mem_type);
@@ -439,6 +439,23 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 	return false;
 }
 
+static int amdgpu_cs_validate(void *param, struct amdgpu_bo *bo)
+{
+	struct amdgpu_cs_parser *p = param;
+	int r;
+
+	do {
+		r = amdgpu_cs_bo_validate(p, bo);
+	} while (r == -ENOMEM && amdgpu_cs_try_evict(p, bo));
+	if (r)
+		return r;
+
+	if (bo->shadow)
+		r = amdgpu_cs_bo_validate(p, bo);
+
+	return r;
+}
+
 static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 			    struct list_head *validated)
 {
@@ -466,18 +483,10 @@ static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 		if (p->evictable == lobj)
 			p->evictable = NULL;
 
-		do {
-			r = amdgpu_cs_bo_validate(p, bo);
-		} while (r == -ENOMEM && amdgpu_cs_try_evict(p, lobj));
+		r = amdgpu_cs_validate(p, bo);
 		if (r)
 			return r;
 
-		if (bo->shadow) {
-			r = amdgpu_cs_bo_validate(p, bo);
-			if (r)
-				return r;
-		}
-
 		if (binding_userptr) {
 			drm_free_large(lobj->user_pages);
 			lobj->user_pages = NULL;
@@ -595,14 +604,19 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		list_splice(&need_pages, &p->validated);
 	}
 
-	amdgpu_vm_get_pt_bos(p->adev, &fpriv->vm, &duplicates);
-
 	p->bytes_moved_threshold = amdgpu_cs_get_threshold_for_moves(p->adev);
 	p->bytes_moved = 0;
 	p->evictable = list_last_entry(&p->validated,
 				       struct amdgpu_bo_list_entry,
 				       tv.head);
 
+	r = amdgpu_vm_validate_pt_bos(p->adev, &fpriv->vm,
+				      amdgpu_cs_validate, p);
+	if (r) {
+		DRM_ERROR("amdgpu_vm_validate_pt_bos() failed.\n");
+		goto error_validate;
+	}
+
 	r = amdgpu_cs_list_validate(p, &duplicates);
 	if (r) {
 		DRM_ERROR("amdgpu_cs_list_validate(duplicates) failed.\n");

commit a7d64de659946e852cd8f2a9691a21ddbb4ebc86
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Sep 15 14:58:48 2016 +0200

    drm/amdgpu: remove adev pointer from struct amdgpu_bo v2
    
    It's completely pointless to have two pointers to the
    device in the same structure.
    
    v2: rename function to amdgpu_ttm_adev, fix typos
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 187c3662b72c..504ae09d3991 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -355,6 +355,7 @@ static void amdgpu_cs_report_moved_bytes(struct amdgpu_device *adev,
 static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 				 struct amdgpu_bo *bo)
 {
+	struct amdgpu_device *adev = amdgpu_ttm_adev(bo->tbo.bdev);
 	u64 initial_bytes_moved;
 	uint32_t domain;
 	int r;
@@ -372,9 +373,9 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 
 retry:
 	amdgpu_ttm_placement_from_domain(bo, domain);
-	initial_bytes_moved = atomic64_read(&bo->adev->num_bytes_moved);
+	initial_bytes_moved = atomic64_read(&adev->num_bytes_moved);
 	r = ttm_bo_validate(&bo->tbo, &bo->placement, true, false);
-	p->bytes_moved += atomic64_read(&bo->adev->num_bytes_moved) -
+	p->bytes_moved += atomic64_read(&adev->num_bytes_moved) -
 		initial_bytes_moved;
 
 	if (unlikely(r == -ENOMEM) && domain != bo->allowed_domains) {
@@ -400,6 +401,7 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 
 		struct amdgpu_bo_list_entry *candidate = p->evictable;
 		struct amdgpu_bo *bo = candidate->robj;
+		struct amdgpu_device *adev = amdgpu_ttm_adev(bo->tbo.bdev);
 		u64 initial_bytes_moved;
 		uint32_t other;
 
@@ -420,9 +422,9 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 
 		/* Good we can try to move this BO somewhere else */
 		amdgpu_ttm_placement_from_domain(bo, other);
-		initial_bytes_moved = atomic64_read(&bo->adev->num_bytes_moved);
+		initial_bytes_moved = atomic64_read(&adev->num_bytes_moved);
 		r = ttm_bo_validate(&bo->tbo, &bo->placement, true, false);
-		p->bytes_moved += atomic64_read(&bo->adev->num_bytes_moved) -
+		p->bytes_moved += atomic64_read(&adev->num_bytes_moved) -
 			initial_bytes_moved;
 
 		if (unlikely(r))

commit 03f48dd5d2085b978353a804635b6d34e77a5635
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Aug 15 17:00:22 2016 +0200

    drm/amdgpu: add AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS flag v3
    
    Add a flag noting that a BO must be created using linear VRAM
    and set this flag on all in kernel users where appropriate.
    
    Hopefully I haven't missed anything.
    
    v2: add it in a few more places, fix CPU mapping.
    v3: rename to VRAM_CONTIGUOUS, fix typo in CS code.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Edward O'Callaghan <funfunctor@folklore1984.net>
    Tested-by: Mike Lothian <mike@fireburn.co.uk>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index b0f6e6957536..187c3662b72c 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1195,6 +1195,15 @@ int amdgpu_cs_sysvm_access_required(struct amdgpu_cs_parser *parser)
 		r = amdgpu_ttm_bind(&bo->tbo, &bo->tbo.mem);
 		if (unlikely(r))
 			return r;
+
+		if (bo->flags & AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS)
+			continue;
+
+		bo->flags |= AMDGPU_GEM_CREATE_VRAM_CONTIGUOUS;
+		amdgpu_ttm_placement_from_domain(bo, bo->allowed_domains);
+		r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false);
+		if (unlikely(r))
+			return r;
 	}
 
 	return 0;

commit f54d1867005c3323f5d8ad83eed823e84226c429
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Tue Oct 25 13:00:45 2016 +0100

    dma-buf: Rename struct fence to dma_fence
    
    I plan to usurp the short name of struct fence for a core kernel struct,
    and so I need to rename the specialised fence/timeline for DMA
    operations to make room.
    
    A consensus was reached in
    https://lists.freedesktop.org/archives/dri-devel/2016-July/113083.html
    that making clear this fence applies to DMA operations was a good thing.
    Since then the patch has grown a bit as usage increases, so hopefully it
    remains a good thing!
    
    (v2...: rebase, rerun spatch)
    v3: Compile on msm, spotted a manual fixup that I broke.
    v4: Try again for msm, sorry Daniel
    
    coccinelle script:
    @@
    
    @@
    - struct fence
    + struct dma_fence
    @@
    
    @@
    - struct fence_ops
    + struct dma_fence_ops
    @@
    
    @@
    - struct fence_cb
    + struct dma_fence_cb
    @@
    
    @@
    - struct fence_array
    + struct dma_fence_array
    @@
    
    @@
    - enum fence_flag_bits
    + enum dma_fence_flag_bits
    @@
    
    @@
    (
    - fence_init
    + dma_fence_init
    |
    - fence_release
    + dma_fence_release
    |
    - fence_free
    + dma_fence_free
    |
    - fence_get
    + dma_fence_get
    |
    - fence_get_rcu
    + dma_fence_get_rcu
    |
    - fence_put
    + dma_fence_put
    |
    - fence_signal
    + dma_fence_signal
    |
    - fence_signal_locked
    + dma_fence_signal_locked
    |
    - fence_default_wait
    + dma_fence_default_wait
    |
    - fence_add_callback
    + dma_fence_add_callback
    |
    - fence_remove_callback
    + dma_fence_remove_callback
    |
    - fence_enable_sw_signaling
    + dma_fence_enable_sw_signaling
    |
    - fence_is_signaled_locked
    + dma_fence_is_signaled_locked
    |
    - fence_is_signaled
    + dma_fence_is_signaled
    |
    - fence_is_later
    + dma_fence_is_later
    |
    - fence_later
    + dma_fence_later
    |
    - fence_wait_timeout
    + dma_fence_wait_timeout
    |
    - fence_wait_any_timeout
    + dma_fence_wait_any_timeout
    |
    - fence_wait
    + dma_fence_wait
    |
    - fence_context_alloc
    + dma_fence_context_alloc
    |
    - fence_array_create
    + dma_fence_array_create
    |
    - to_fence_array
    + to_dma_fence_array
    |
    - fence_is_array
    + dma_fence_is_array
    |
    - trace_fence_emit
    + trace_dma_fence_emit
    |
    - FENCE_TRACE
    + DMA_FENCE_TRACE
    |
    - FENCE_WARN
    + DMA_FENCE_WARN
    |
    - FENCE_ERR
    + DMA_FENCE_ERR
    )
     (
     ...
     )
    
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Reviewed-by: Gustavo Padovan <gustavo.padovan@collabora.co.uk>
    Acked-by: Sumit Semwal <sumit.semwal@linaro.org>
    Acked-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Link: http://patchwork.freedesktop.org/patch/msgid/20161025120045.28839-1-chris@chris-wilson.co.uk

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index b0f6e6957536..5d582265e929 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -719,7 +719,7 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
 		ttm_eu_backoff_reservation(&parser->ticket,
 					   &parser->validated);
 	}
-	fence_put(parser->fence);
+	dma_fence_put(parser->fence);
 
 	if (parser->ctx)
 		amdgpu_ctx_put(parser->ctx);
@@ -756,7 +756,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 
 	if (p->bo_list) {
 		for (i = 0; i < p->bo_list->num_entries; i++) {
-			struct fence *f;
+			struct dma_fence *f;
 
 			/* ignore duplicates */
 			bo = p->bo_list->array[i].robj;
@@ -956,7 +956,7 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 		for (j = 0; j < num_deps; ++j) {
 			struct amdgpu_ring *ring;
 			struct amdgpu_ctx *ctx;
-			struct fence *fence;
+			struct dma_fence *fence;
 
 			r = amdgpu_cs_get_ring(adev, deps[j].ip_type,
 					       deps[j].ip_instance,
@@ -978,7 +978,7 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 			} else if (fence) {
 				r = amdgpu_sync_fence(adev, &p->job->sync,
 						      fence);
-				fence_put(fence);
+				dma_fence_put(fence);
 				amdgpu_ctx_put(ctx);
 				if (r)
 					return r;
@@ -1008,7 +1008,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 
 	job->owner = p->filp;
 	job->fence_ctx = entity->fence_context;
-	p->fence = fence_get(&job->base.s_fence->finished);
+	p->fence = dma_fence_get(&job->base.s_fence->finished);
 	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring, p->fence);
 	job->uf_sequence = cs->out.handle;
 	amdgpu_job_free_resources(job);
@@ -1091,7 +1091,7 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 	unsigned long timeout = amdgpu_gem_timeout(wait->in.timeout);
 	struct amdgpu_ring *ring = NULL;
 	struct amdgpu_ctx *ctx;
-	struct fence *fence;
+	struct dma_fence *fence;
 	long r;
 
 	r = amdgpu_cs_get_ring(adev, wait->in.ip_type, wait->in.ip_instance,
@@ -1107,8 +1107,8 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 	if (IS_ERR(fence))
 		r = PTR_ERR(fence);
 	else if (fence) {
-		r = fence_wait_timeout(fence, true, timeout);
-		fence_put(fence);
+		r = dma_fence_wait_timeout(fence, true, timeout);
+		dma_fence_put(fence);
 	} else
 		r = 1;
 

commit 57d7f9b64ad9d4d9c87ed1d6b58e5bfabf2dfc6c
Author: jimqu <Jim.Qu@amd.com>
Date:   Thu Oct 20 14:58:04 2016 +0800

    drm/amdgpu: avoid drm error log during S3 on RHEL7.3
    
    Signed-off-by: JimQu <Jim.Qu@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index b0f6e6957536..82dc8d20e28a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -519,7 +519,8 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		r = ttm_eu_reserve_buffers(&p->ticket, &p->validated, true,
 					   &duplicates);
 		if (unlikely(r != 0)) {
-			DRM_ERROR("ttm_eu_reserve_buffers failed.\n");
+			if (r != -ERESTARTSYS)
+				DRM_ERROR("ttm_eu_reserve_buffers failed.\n");
 			goto error_free_pages;
 		}
 

commit bb990bb09235a3cc38fd4600d48c7bfb7a0a167c
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Sep 9 16:32:33 2016 +0200

    drm/amdgpu: add a custom GTT memory manager v2
    
    Only allocate address space when we really need it.
    
    v2: fix a typo, add correct function description,
        stop leaking the node in the error case.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index b8412bcbad2a..b0f6e6957536 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -648,7 +648,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	if (!r && p->uf_entry.robj) {
 		struct amdgpu_bo *uf = p->uf_entry.robj;
 
-		r = amdgpu_ttm_bind(uf->tbo.ttm, &uf->tbo.mem);
+		r = amdgpu_ttm_bind(&uf->tbo, &uf->tbo.mem);
 		p->job->uf_addr += amdgpu_bo_gpu_offset(uf);
 	}
 
@@ -1192,7 +1192,7 @@ int amdgpu_cs_sysvm_access_required(struct amdgpu_cs_parser *parser)
 	for (i = 0; i < parser->bo_list->num_entries; i++) {
 		struct amdgpu_bo *bo = parser->bo_list->array[i].robj;
 
-		r = amdgpu_ttm_bind(bo->tbo.ttm, &bo->tbo.mem);
+		r = amdgpu_ttm_bind(&bo->tbo, &bo->tbo.mem);
 		if (unlikely(r))
 			return r;
 	}

commit aa29040b437be9e4255062aa38bcbe7cb50da8c1
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Sep 9 11:21:43 2016 +0200

    drm/amdgpu: validate size and offset of user fence BO
    
    We need to validate the offset to make sure that we don't write after the BO.
    
    Additional to that a page should be enough and can make address space
    handling much easier.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 9480be45b45f..b8412bcbad2a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -91,6 +91,7 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 				      uint32_t *offset)
 {
 	struct drm_gem_object *gobj;
+	unsigned long size;
 
 	gobj = drm_gem_object_lookup(p->filp, data->handle);
 	if (gobj == NULL)
@@ -101,6 +102,11 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 	p->uf_entry.tv.bo = &p->uf_entry.robj->tbo;
 	p->uf_entry.tv.shared = true;
 	p->uf_entry.user_pages = NULL;
+
+	size = amdgpu_bo_size(p->uf_entry.robj);
+	if (size != PAGE_SIZE || (data->offset + 8) > size)
+		return -EINVAL;
+
 	*offset = data->offset;
 
 	drm_gem_object_unreference_unlocked(gobj);

commit 761c2e82054fda665bcdec95b9daf3d468c5fd5b
Author: Baoyou Xie <baoyou.xie@linaro.org>
Date:   Sat Sep 3 13:57:14 2016 +0800

    drm/amdgpu: mark symbols static where possible
    
    We get a few warnings when building kernel with W=1:
    drivers/gpu/drm/amd/amdgpu/cz_smc.c:51:5: warning: no previous prototype for 'cz_send_msg_to_smc_async' [-Wmissing-prototypes]
    drivers/gpu/drm/amd/amdgpu/cz_smc.c:143:5: warning: no previous prototype for 'cz_write_smc_sram_dword' [-Wmissing-prototypes]
    drivers/gpu/drm/amd/amdgpu/iceland_smc.c:124:6: warning: no previous prototype for 'iceland_start_smc' [-Wmissing-prototypes]
    drivers/gpu/drm/amd/amdgpu/gfx_v8_0.c:3926:6: warning: no previous prototype for 'gfx_v8_0_rlc_stop' [-Wmissing-prototypes]
    drivers/gpu/drm/amd/amdgpu/amdgpu_job.c:94:6: warning: no previous prototype for 'amdgpu_job_free_cb' [-Wmissing-prototypes]
    ....
    
    In fact, these functions are only used in the file in which they are
    declared and don't need a declaration, but can be made static.
    So this patch marks these functions with 'static'.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Acked-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Edward O'Callaghan <funfunctor@folklore1984.net>
    Signed-off-by: Baoyou Xie <baoyou.xie@linaro.org>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index f7dccb10d965..9480be45b45f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -431,7 +431,7 @@ static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
 	return false;
 }
 
-int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
+static int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 			    struct list_head *validated)
 {
 	struct amdgpu_bo_list_entry *lobj;

commit c855e25090cdafffb87119028eb018030a46dd9e
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Sep 5 17:00:57 2016 +0200

    drm/amdgpu: bind GTT on demand
    
    We don't really need the GTT table any more most of the time. So bind it
    only on demand.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Acked-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 61b7e25535bf..f7dccb10d965 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -639,8 +639,12 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		}
 	}
 
-	if (p->uf_entry.robj)
-		p->job->uf_addr += amdgpu_bo_gpu_offset(p->uf_entry.robj);
+	if (!r && p->uf_entry.robj) {
+		struct amdgpu_bo *uf = p->uf_entry.robj;
+
+		r = amdgpu_ttm_bind(uf->tbo.ttm, &uf->tbo.mem);
+		p->job->uf_addr += amdgpu_bo_gpu_offset(uf);
+	}
 
 error_validate:
 	if (r) {
@@ -1163,3 +1167,29 @@ amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 
 	return NULL;
 }
+
+/**
+ * amdgpu_cs_sysvm_access_required - make BOs accessible by the system VM
+ *
+ * @parser: command submission parser context
+ *
+ * Helper for UVD/VCE VM emulation, make sure BOs are accessible by the system VM.
+ */
+int amdgpu_cs_sysvm_access_required(struct amdgpu_cs_parser *parser)
+{
+	unsigned i;
+	int r;
+
+	if (!parser->bo_list)
+		return 0;
+
+	for (i = 0; i < parser->bo_list->num_entries; i++) {
+		struct amdgpu_bo *bo = parser->bo_list->array[i].robj;
+
+		r = amdgpu_ttm_bind(bo->tbo.ttm, &bo->tbo.mem);
+		if (unlikely(r))
+			return r;
+	}
+
+	return 0;
+}

commit 753ad49c9fdfc732972b0d03f2889f473ed35e59
Author: Monk Liu <Monk.Liu@amd.com>
Date:   Fri Aug 26 13:28:28 2016 +0800

    drm/amdgpu:implement CONTEXT_CONTROL (v5)
    
    v1:
    for gfx8, use CONTEXT_CONTROL package to dynamically
    skip preamble CEIB and other load_xxx command in sequence.
    
    v2:
    support GFX7 as well.
    remove cntxcntl in compute ring funcs because CPC doesn't
    support this packet.
    
    v3: fix reduntant judgement in cntxcntl.
    v4: some cleanups, don't change cs_submit()
    v5: keep old MESA supported & bump up KMS version.
    
    Signed-off-by: Monk Liu <Monk.Liu@amd.com>
    Ack-by: Chunming Zhou <David1.Zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 56bde6436a1f..61b7e25535bf 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -850,6 +850,14 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		if (r)
 			return r;
 
+		if (ib->flags & AMDGPU_IB_FLAG_PREAMBLE) {
+			parser->job->preamble_status |= AMDGPU_PREAMBLE_IB_PRESENT;
+			if (!parser->ctx->preamble_presented) {
+				parser->job->preamble_status |= AMDGPU_PREAMBLE_IB_PRESENT_FIRST;
+				parser->ctx->preamble_presented = true;
+			}
+		}
+
 		if (parser->job->ring && parser->job->ring != ring)
 			return -EINVAL;
 

commit 3aecd24c65b9539b6faac2a52a9aaa7bc90f4677
Author: Monk Liu <Monk.Liu@amd.com>
Date:   Thu Aug 25 15:40:48 2016 +0800

    drm/amdgpu: change job->ctx field name
    
    job->ctx actually is a fence_context of the entity
    it belongs to, naming it as ctx is too vague, and
    we'll need add amdgpu_ctx into the job structure
    later.
    
    Signed-off-by: Monk Liu <Monk.Liu@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index e29e7b9ca3a6..56bde6436a1f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -989,7 +989,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	}
 
 	job->owner = p->filp;
-	job->ctx = entity->fence_context;
+	job->fence_ctx = entity->fence_context;
 	p->fence = fence_get(&job->base.s_fence->finished);
 	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring, p->fence);
 	job->uf_sequence = cs->out.handle;

commit 662bfa61fff1de4dd96029d556d7b301e27c3556
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Sep 1 12:13:18 2016 +0200

    drm/amdgpu: prevent command submission failures under memory pressure v2
    
    As last resort try to evict BOs from the current working set into other
    memory domains. This effectively prevents command submission failures when
    VM page tables have been swapped out.
    
    v2: fix typos
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index d7a957376a90..e29e7b9ca3a6 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -379,6 +379,58 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 	return r;
 }
 
+/* Last resort, try to evict something from the current working set */
+static bool amdgpu_cs_try_evict(struct amdgpu_cs_parser *p,
+				struct amdgpu_bo_list_entry *lobj)
+{
+	uint32_t domain = lobj->robj->allowed_domains;
+	int r;
+
+	if (!p->evictable)
+		return false;
+
+	for (;&p->evictable->tv.head != &p->validated;
+	     p->evictable = list_prev_entry(p->evictable, tv.head)) {
+
+		struct amdgpu_bo_list_entry *candidate = p->evictable;
+		struct amdgpu_bo *bo = candidate->robj;
+		u64 initial_bytes_moved;
+		uint32_t other;
+
+		/* If we reached our current BO we can forget it */
+		if (candidate == lobj)
+			break;
+
+		other = amdgpu_mem_type_to_domain(bo->tbo.mem.mem_type);
+
+		/* Check if this BO is in one of the domains we need space for */
+		if (!(other & domain))
+			continue;
+
+		/* Check if we can move this BO somewhere else */
+		other = bo->allowed_domains & ~domain;
+		if (!other)
+			continue;
+
+		/* Good we can try to move this BO somewhere else */
+		amdgpu_ttm_placement_from_domain(bo, other);
+		initial_bytes_moved = atomic64_read(&bo->adev->num_bytes_moved);
+		r = ttm_bo_validate(&bo->tbo, &bo->placement, true, false);
+		p->bytes_moved += atomic64_read(&bo->adev->num_bytes_moved) -
+			initial_bytes_moved;
+
+		if (unlikely(r))
+			break;
+
+		p->evictable = list_prev_entry(p->evictable, tv.head);
+		list_move(&candidate->tv.head, &p->validated);
+
+		return true;
+	}
+
+	return false;
+}
+
 int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 			    struct list_head *validated)
 {
@@ -403,9 +455,15 @@ int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 			binding_userptr = true;
 		}
 
-		r = amdgpu_cs_bo_validate(p, bo);
+		if (p->evictable == lobj)
+			p->evictable = NULL;
+
+		do {
+			r = amdgpu_cs_bo_validate(p, bo);
+		} while (r == -ENOMEM && amdgpu_cs_try_evict(p, lobj));
 		if (r)
 			return r;
+
 		if (bo->shadow) {
 			r = amdgpu_cs_bo_validate(p, bo);
 			if (r)
@@ -533,6 +591,9 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 
 	p->bytes_moved_threshold = amdgpu_cs_get_threshold_for_moves(p->adev);
 	p->bytes_moved = 0;
+	p->evictable = list_last_entry(&p->validated,
+				       struct amdgpu_bo_list_entry,
+				       tv.head);
 
 	r = amdgpu_cs_list_validate(p, &duplicates);
 	if (r) {

commit 1abdc3d73dd9dc2f3dc619d466d378e70cbcc24a
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Aug 31 17:28:11 2016 +0200

    drm/amdgpu: only try again if we actually run into -ENOMEM
    
    All other errors can't be fixed by using a different memory domain.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 82927570333a..d7a957376a90 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -371,11 +371,9 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 	p->bytes_moved += atomic64_read(&bo->adev->num_bytes_moved) -
 		initial_bytes_moved;
 
-	if (unlikely(r)) {
-		if (r != -ERESTARTSYS && domain != bo->allowed_domains) {
-			domain = bo->allowed_domains;
-			goto retry;
-		}
+	if (unlikely(r == -ENOMEM) && domain != bo->allowed_domains) {
+		domain = bo->allowed_domains;
+		goto retry;
 	}
 
 	return r;

commit 95844d20ae024b5d553c9923a0d3145c3956bf69
Author: Marek Olšák <marek.olsak@amd.com>
Date:   Wed Aug 17 23:49:27 2016 +0200

    drm/amdgpu: throttle buffer migrations at CS using a fixed MBps limit (v2)
    
    The old mechanism used a per-submission limit that didn't take previous
    submissions within the same time frame into account. It also filled VRAM
    slowly when VRAM usage dropped due to a big eviction or buffer deallocation.
    
    This new method establishes a configurable MBps limit that is obeyed when
    VRAM usage is very high. When VRAM usage is not very high, it gives
    the driver the freedom to fill it quickly. The result is more consistent
    performance.
    
    It can't keep the BO move rate low if lots of evictions are happening due
    to VRAM fragmentation, or if a big buffer is being migrated.
    
    The amdgpu.moverate parameter can be used to set a non-default limit.
    Measurements can be done to find out which amdgpu.moverate setting gives
    the best results.
    
    Mainly APUs and cards with small VRAM will benefit from this. For F1 2015,
    anything with 2 GB VRAM or less will benefit.
    
    Some benchmark results - F1 2015 (Tonga 2GB):
    
    Limit      MinFPS AvgFPS
    Old code:  14     32.6
    128 MB/s:  28     41
    64 MB/s:   15.5   43
    32 MB/s:   28.7   43.4
    8 MB/s:    27.8   44.4
    8 MB/s:    21.9   42.8 (different run)
    
    Random drops in Min FPS can still occur (due to fragmented VRAM?), but
    the average FPS is much better. 8 MB/s is probably a good limit for this
    game & the current VRAM management. The random FPS drops are still to be
    tackled.
    
    v2: use a spinlock
    
    Signed-off-by: Marek Olšák <marek.olsak@amd.com>
    Acked-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index d80e5d3a4add..82927570333a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -235,56 +235,115 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	return ret;
 }
 
-/* Returns how many bytes TTM can move per IB.
+/* Convert microseconds to bytes. */
+static u64 us_to_bytes(struct amdgpu_device *adev, s64 us)
+{
+	if (us <= 0 || !adev->mm_stats.log2_max_MBps)
+		return 0;
+
+	/* Since accum_us is incremented by a million per second, just
+	 * multiply it by the number of MB/s to get the number of bytes.
+	 */
+	return us << adev->mm_stats.log2_max_MBps;
+}
+
+static s64 bytes_to_us(struct amdgpu_device *adev, u64 bytes)
+{
+	if (!adev->mm_stats.log2_max_MBps)
+		return 0;
+
+	return bytes >> adev->mm_stats.log2_max_MBps;
+}
+
+/* Returns how many bytes TTM can move right now. If no bytes can be moved,
+ * it returns 0. If it returns non-zero, it's OK to move at least one buffer,
+ * which means it can go over the threshold once. If that happens, the driver
+ * will be in debt and no other buffer migrations can be done until that debt
+ * is repaid.
+ *
+ * This approach allows moving a buffer of any size (it's important to allow
+ * that).
+ *
+ * The currency is simply time in microseconds and it increases as the clock
+ * ticks. The accumulated microseconds (us) are converted to bytes and
+ * returned.
  */
 static u64 amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev)
 {
-	u64 real_vram_size = adev->mc.real_vram_size;
-	u64 vram_usage = atomic64_read(&adev->vram_usage);
+	s64 time_us, increment_us;
+	u64 max_bytes;
+	u64 free_vram, total_vram, used_vram;
 
-	/* This function is based on the current VRAM usage.
+	/* Allow a maximum of 200 accumulated ms. This is basically per-IB
+	 * throttling.
 	 *
-	 * - If all of VRAM is free, allow relocating the number of bytes that
-	 *   is equal to 1/4 of the size of VRAM for this IB.
+	 * It means that in order to get full max MBps, at least 5 IBs per
+	 * second must be submitted and not more than 200ms apart from each
+	 * other.
+	 */
+	const s64 us_upper_bound = 200000;
 
-	 * - If more than one half of VRAM is occupied, only allow relocating
-	 *   1 MB of data for this IB.
-	 *
-	 * - From 0 to one half of used VRAM, the threshold decreases
-	 *   linearly.
-	 *         __________________
-	 * 1/4 of -|\               |
-	 * VRAM    | \              |
-	 *         |  \             |
-	 *         |   \            |
-	 *         |    \           |
-	 *         |     \          |
-	 *         |      \         |
-	 *         |       \________|1 MB
-	 *         |----------------|
-	 *    VRAM 0 %             100 %
-	 *         used            used
-	 *
-	 * Note: It's a threshold, not a limit. The threshold must be crossed
-	 * for buffer relocations to stop, so any buffer of an arbitrary size
-	 * can be moved as long as the threshold isn't crossed before
-	 * the relocation takes place. We don't want to disable buffer
-	 * relocations completely.
+	if (!adev->mm_stats.log2_max_MBps)
+		return 0;
+
+	total_vram = adev->mc.real_vram_size - adev->vram_pin_size;
+	used_vram = atomic64_read(&adev->vram_usage);
+	free_vram = used_vram >= total_vram ? 0 : total_vram - used_vram;
+
+	spin_lock(&adev->mm_stats.lock);
+
+	/* Increase the amount of accumulated us. */
+	time_us = ktime_to_us(ktime_get());
+	increment_us = time_us - adev->mm_stats.last_update_us;
+	adev->mm_stats.last_update_us = time_us;
+	adev->mm_stats.accum_us = min(adev->mm_stats.accum_us + increment_us,
+                                      us_upper_bound);
+
+	/* This prevents the short period of low performance when the VRAM
+	 * usage is low and the driver is in debt or doesn't have enough
+	 * accumulated us to fill VRAM quickly.
 	 *
-	 * The idea is that buffers should be placed in VRAM at creation time
-	 * and TTM should only do a minimum number of relocations during
-	 * command submission. In practice, you need to submit at least
-	 * a dozen IBs to move all buffers to VRAM if they are in GTT.
+	 * The situation can occur in these cases:
+	 * - a lot of VRAM is freed by userspace
+	 * - the presence of a big buffer causes a lot of evictions
+	 *   (solution: split buffers into smaller ones)
 	 *
-	 * Also, things can get pretty crazy under memory pressure and actual
-	 * VRAM usage can change a lot, so playing safe even at 50% does
-	 * consistently increase performance.
+	 * If 128 MB or 1/8th of VRAM is free, start filling it now by setting
+	 * accum_us to a positive number.
 	 */
+	if (free_vram >= 128 * 1024 * 1024 || free_vram >= total_vram / 8) {
+		s64 min_us;
+
+		/* Be more aggresive on dGPUs. Try to fill a portion of free
+		 * VRAM now.
+		 */
+		if (!(adev->flags & AMD_IS_APU))
+			min_us = bytes_to_us(adev, free_vram / 4);
+		else
+			min_us = 0; /* Reset accum_us on APUs. */
+
+		adev->mm_stats.accum_us = max(min_us, adev->mm_stats.accum_us);
+	}
 
-	u64 half_vram = real_vram_size >> 1;
-	u64 half_free_vram = vram_usage >= half_vram ? 0 : half_vram - vram_usage;
-	u64 bytes_moved_threshold = half_free_vram >> 1;
-	return max(bytes_moved_threshold, 1024*1024ull);
+	/* This returns 0 if the driver is in debt to disallow (optional)
+	 * buffer moves.
+	 */
+	max_bytes = us_to_bytes(adev, adev->mm_stats.accum_us);
+
+	spin_unlock(&adev->mm_stats.lock);
+	return max_bytes;
+}
+
+/* Report how many bytes have really been moved for the last command
+ * submission. This can result in a debt that can stop buffer migrations
+ * temporarily.
+ */
+static void amdgpu_cs_report_moved_bytes(struct amdgpu_device *adev,
+					 u64 num_bytes)
+{
+	spin_lock(&adev->mm_stats.lock);
+	adev->mm_stats.accum_us -= bytes_to_us(adev, num_bytes);
+	spin_unlock(&adev->mm_stats.lock);
 }
 
 static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
@@ -297,15 +356,10 @@ static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
 	if (bo->pin_count)
 		return 0;
 
-	/* Avoid moving this one if we have moved too many buffers
-	 * for this IB already.
-	 *
-	 * Note that this allows moving at least one buffer of
-	 * any size, because it doesn't take the current "bo"
-	 * into account. We don't want to disallow buffer moves
-	 * completely.
+	/* Don't move this buffer if we have depleted our allowance
+	 * to move it. Don't move anything if the threshold is zero.
 	 */
-	if (p->bytes_moved <= p->bytes_moved_threshold)
+	if (p->bytes_moved < p->bytes_moved_threshold)
 		domain = bo->prefered_domains;
 	else
 		domain = bo->allowed_domains;
@@ -494,6 +548,8 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		goto error_validate;
 	}
 
+	amdgpu_cs_report_moved_bytes(p->adev, p->bytes_moved);
+
 	fpriv->vm.last_eviction_counter =
 		atomic64_read(&p->adev->num_evictions);
 

commit 99e124f402d6d649498e2aa3cbcf4563a37fea0e
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Aug 16 14:43:17 2016 +0200

    drm/amdgpu: cleanup amdgpu_vm_bo_update params
    
    Make it more obvious what we are doing here.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 396a412d70d4..d80e5d3a4add 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -642,7 +642,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 			if (bo_va == NULL)
 				continue;
 
-			r = amdgpu_vm_bo_update(adev, bo_va, &bo->tbo.mem);
+			r = amdgpu_vm_bo_update(adev, bo_va, false);
 			if (r)
 				return r;
 

commit 14fd833efa3f13619623501de5e2221dfdab7f7f
Author: Chunming Zhou <David1.Zhou@amd.com>
Date:   Thu Aug 4 13:05:46 2016 +0800

    drm/amdgpu: validate shadow as well when validating bo
    
    Signed-off-by: Chunming Zhou <David1.Zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 8eb93dff69d6..396a412d70d4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -287,18 +287,56 @@ static u64 amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev)
 	return max(bytes_moved_threshold, 1024*1024ull);
 }
 
+static int amdgpu_cs_bo_validate(struct amdgpu_cs_parser *p,
+				 struct amdgpu_bo *bo)
+{
+	u64 initial_bytes_moved;
+	uint32_t domain;
+	int r;
+
+	if (bo->pin_count)
+		return 0;
+
+	/* Avoid moving this one if we have moved too many buffers
+	 * for this IB already.
+	 *
+	 * Note that this allows moving at least one buffer of
+	 * any size, because it doesn't take the current "bo"
+	 * into account. We don't want to disallow buffer moves
+	 * completely.
+	 */
+	if (p->bytes_moved <= p->bytes_moved_threshold)
+		domain = bo->prefered_domains;
+	else
+		domain = bo->allowed_domains;
+
+retry:
+	amdgpu_ttm_placement_from_domain(bo, domain);
+	initial_bytes_moved = atomic64_read(&bo->adev->num_bytes_moved);
+	r = ttm_bo_validate(&bo->tbo, &bo->placement, true, false);
+	p->bytes_moved += atomic64_read(&bo->adev->num_bytes_moved) -
+		initial_bytes_moved;
+
+	if (unlikely(r)) {
+		if (r != -ERESTARTSYS && domain != bo->allowed_domains) {
+			domain = bo->allowed_domains;
+			goto retry;
+		}
+	}
+
+	return r;
+}
+
 int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 			    struct list_head *validated)
 {
 	struct amdgpu_bo_list_entry *lobj;
-	u64 initial_bytes_moved;
 	int r;
 
 	list_for_each_entry(lobj, validated, tv.head) {
 		struct amdgpu_bo *bo = lobj->robj;
 		bool binding_userptr = false;
 		struct mm_struct *usermm;
-		uint32_t domain;
 
 		usermm = amdgpu_ttm_tt_get_usermm(bo->tbo.ttm);
 		if (usermm && usermm != current->mm)
@@ -313,35 +351,13 @@ int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 			binding_userptr = true;
 		}
 
-		if (bo->pin_count)
-			continue;
-
-		/* Avoid moving this one if we have moved too many buffers
-		 * for this IB already.
-		 *
-		 * Note that this allows moving at least one buffer of
-		 * any size, because it doesn't take the current "bo"
-		 * into account. We don't want to disallow buffer moves
-		 * completely.
-		 */
-		if (p->bytes_moved <= p->bytes_moved_threshold)
-			domain = bo->prefered_domains;
-		else
-			domain = bo->allowed_domains;
-
-	retry:
-		amdgpu_ttm_placement_from_domain(bo, domain);
-		initial_bytes_moved = atomic64_read(&bo->adev->num_bytes_moved);
-		r = ttm_bo_validate(&bo->tbo, &bo->placement, true, false);
-		p->bytes_moved += atomic64_read(&bo->adev->num_bytes_moved) -
-			       initial_bytes_moved;
-
-		if (unlikely(r)) {
-			if (r != -ERESTARTSYS && domain != bo->allowed_domains) {
-				domain = bo->allowed_domains;
-				goto retry;
-			}
+		r = amdgpu_cs_bo_validate(p, bo);
+		if (r)
 			return r;
+		if (bo->shadow) {
+			r = amdgpu_cs_bo_validate(p, bo);
+			if (r)
+				return r;
 		}
 
 		if (binding_userptr) {

commit f10379503e2b1814e27957899bcdfd0132a1915e
Author: Marek Olšák <marek.olsak@amd.com>
Date:   Sat Jul 30 00:48:39 2016 +0200

    drm/amdgpu: print more accurate error messages on IB submission failure
    
    It's useful for debugging.
    
    Signed-off-by: Marek Olšák <marek.olsak@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 0307ff5887c5..8eb93dff69d6 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -386,8 +386,10 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 
 		r = ttm_eu_reserve_buffers(&p->ticket, &p->validated, true,
 					   &duplicates);
-		if (unlikely(r != 0))
+		if (unlikely(r != 0)) {
+			DRM_ERROR("ttm_eu_reserve_buffers failed.\n");
 			goto error_free_pages;
+		}
 
 		/* Without a BO list we don't have userptr BOs */
 		if (!p->bo_list)
@@ -427,9 +429,10 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		/* Unreserve everything again. */
 		ttm_eu_backoff_reservation(&p->ticket, &p->validated);
 
-		/* We tried to often, just abort */
+		/* We tried too many times, just abort */
 		if (!--tries) {
 			r = -EDEADLK;
+			DRM_ERROR("deadlock in %s\n", __func__);
 			goto error_free_pages;
 		}
 
@@ -441,11 +444,13 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 							 sizeof(struct page*));
 			if (!e->user_pages) {
 				r = -ENOMEM;
+				DRM_ERROR("calloc failure in %s\n", __func__);
 				goto error_free_pages;
 			}
 
 			r = amdgpu_ttm_tt_get_user_pages(ttm, e->user_pages);
 			if (r) {
+				DRM_ERROR("amdgpu_ttm_tt_get_user_pages failed.\n");
 				drm_free_large(e->user_pages);
 				e->user_pages = NULL;
 				goto error_free_pages;
@@ -462,12 +467,16 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	p->bytes_moved = 0;
 
 	r = amdgpu_cs_list_validate(p, &duplicates);
-	if (r)
+	if (r) {
+		DRM_ERROR("amdgpu_cs_list_validate(duplicates) failed.\n");
 		goto error_validate;
+	}
 
 	r = amdgpu_cs_list_validate(p, &p->validated);
-	if (r)
+	if (r) {
+		DRM_ERROR("amdgpu_cs_list_validate(validated) failed.\n");
 		goto error_validate;
+	}
 
 	fpriv->vm.last_eviction_counter =
 		atomic64_read(&p->adev->num_evictions);

commit 595a9cd68c132e474ee5daf97067d4d15c618739
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Jun 30 10:52:03 2016 +0200

    drm/amdgpu: remove fence parameter from amd_sched_job_init
    
    We return the fence as part of the job structur anyway,
    no need to do this twice.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 0db32e3b13c0..0307ff5887c5 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -836,15 +836,13 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 {
 	struct amdgpu_ring *ring = p->job->ring;
 	struct amd_sched_entity *entity = &p->ctx->rings[ring->idx].entity;
-	struct fence *fence;
 	struct amdgpu_job *job;
 	int r;
 
 	job = p->job;
 	p->job = NULL;
 
-	r = amd_sched_job_init(&job->base, &ring->sched,
-			       entity, p->filp, &fence);
+	r = amd_sched_job_init(&job->base, &ring->sched, entity, p->filp);
 	if (r) {
 		amdgpu_job_free(job);
 		return r;
@@ -852,8 +850,8 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 
 	job->owner = p->filp;
 	job->ctx = entity->fence_context;
-	p->fence = fence_get(fence);
-	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring, fence);
+	p->fence = fence_get(&job->base.s_fence->finished);
+	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring, p->fence);
 	job->uf_sequence = cs->out.handle;
 	amdgpu_job_free_resources(job);
 

commit a5fb4ec29c74a16ce1c269e52bc85ca86ee41e81
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Jun 29 15:10:31 2016 +0200

    drm/amdgpu: earlier free SA resources
    
    Keep the time we don't have a fence associated with the resource smaller.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 475c95f670f8..0db32e3b13c0 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -855,6 +855,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	p->fence = fence_get(fence);
 	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring, fence);
 	job->uf_sequence = cs->out.handle;
+	amdgpu_job_free_resources(job);
 
 	trace_amdgpu_cs_ioctl(job);
 	amd_sched_entity_push_job(&job->base);

commit b5f5acbc87052e1bd8ada6915e1dedd856da767d
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Jun 29 13:26:41 2016 +0200

    drm/amdgpu: fix user fence handling once more
    
    Same problem as with the VM page tables. The user fence address must be
    determined before the job is scheduled, not when the IB is executed.
    
    This fixes a security problem where user fences could be used to overwrite
    any part of VRAM.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 95b248159947..475c95f670f8 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -216,11 +216,8 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	if (ret)
 		goto free_all_kdata;
 
-	if (p->uf_entry.robj) {
-		p->job->uf_bo = amdgpu_bo_ref(p->uf_entry.robj);
-		p->job->uf_offset = uf_offset;
-	}
-
+	if (p->uf_entry.robj)
+		p->job->uf_addr = uf_offset;
 	kfree(chunk_array);
 	return 0;
 
@@ -502,6 +499,9 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		}
 	}
 
+	if (p->uf_entry.robj)
+		p->job->uf_addr += amdgpu_bo_gpu_offset(p->uf_entry.robj);
+
 error_validate:
 	if (r) {
 		amdgpu_vm_move_pt_bos_in_lru(p->adev, &fpriv->vm);
@@ -767,7 +767,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 	}
 
 	/* UVD & VCE fw doesn't support user fences */
-	if (parser->job->uf_bo && (
+	if (parser->job->uf_addr && (
 	    parser->job->ring->type == AMDGPU_RING_TYPE_UVD ||
 	    parser->job->ring->type == AMDGPU_RING_TYPE_VCE))
 		return -EINVAL;

commit 9a79588c42bf89cff48fdc6db4aab4aeb9d862b6
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Jun 22 14:25:55 2016 +0200

    drm/amdgpu: don't update page tables for VM emulation
    
    It's just overhead to do so and allocating a VMID
    when we don't need one is actually a bit dangerous.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index cf97a87f76a6..95b248159947 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -656,20 +656,21 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 
 	/* Only for UVD/VCE VM emulation */
 	if (ring->funcs->parse_cs) {
+		p->job->vm = NULL;
 		for (i = 0; i < p->job->num_ibs; i++) {
 			r = amdgpu_ring_parse_cs(ring, p, i);
 			if (r)
 				return r;
 		}
-	}
-
-	p->job->vm_pd_addr = amdgpu_bo_gpu_offset(vm->page_directory);
+	} else {
+		p->job->vm_pd_addr = amdgpu_bo_gpu_offset(vm->page_directory);
 
-	r = amdgpu_bo_vm_update_pte(p, vm);
-	if (!r)
-		amdgpu_cs_sync_rings(p);
+		r = amdgpu_bo_vm_update_pte(p, vm);
+		if (r)
+			return r;
+	}
 
-	return r;
+	return amdgpu_cs_sync_rings(p);
 }
 
 static int amdgpu_cs_handle_lockup(struct amdgpu_device *adev, int r)

commit 5a712a8727200fc617072bed2ccd8ba8e1b50408
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Jun 21 16:28:15 2016 +0200

    drm/amdgpu: validate VM PTs only on eviction
    
    We don't need to validate them again if the eviction counter didn't changed.
    
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index de171ccf2b9c..cf97a87f76a6 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -459,7 +459,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		list_splice(&need_pages, &p->validated);
 	}
 
-	amdgpu_vm_get_pt_bos(&fpriv->vm, &duplicates);
+	amdgpu_vm_get_pt_bos(p->adev, &fpriv->vm, &duplicates);
 
 	p->bytes_moved_threshold = amdgpu_cs_get_threshold_for_moves(p->adev);
 	p->bytes_moved = 0;
@@ -472,6 +472,9 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	if (r)
 		goto error_validate;
 
+	fpriv->vm.last_eviction_counter =
+		atomic64_read(&p->adev->num_evictions);
+
 	if (p->bo_list) {
 		struct amdgpu_bo *gds = p->bo_list->gds_obj;
 		struct amdgpu_bo *gws = p->bo_list->gws_obj;

commit 281d144ddd4f6b3944c32ab0f346b03f0de0e6b8
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Jun 15 13:44:04 2016 +0200

    drm/amdgpu: save the PD addr before scheduling the job
    
    When we pipeline evictions the page directory could already be
    moving somewhere else when grab_id is called.
    
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 523da20e6ea0..de171ccf2b9c 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -660,6 +660,8 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 		}
 	}
 
+	p->job->vm_pd_addr = amdgpu_bo_gpu_offset(vm->page_directory);
+
 	r = amdgpu_bo_vm_update_pte(p, vm);
 	if (!r)
 		amdgpu_cs_sync_rings(p);

commit c5f74f7802775b9ccdb0a4fd90e0c7d0b03da9fa
Author: Christian König <christian.koenig@amd.com>
Date:   Thu May 19 09:54:15 2016 +0200

    drm/amdgpu: fix and cleanup job destruction
    
    Remove the job reference counting and just properly destroy it from a
    work item which blocks on any potential running timeout handler.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Monk.Liu <monk.liu@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 72694d7f11f5..523da20e6ea0 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -838,8 +838,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	p->job = NULL;
 
 	r = amd_sched_job_init(&job->base, &ring->sched,
-			       entity, amdgpu_job_free_func,
-			       p->filp, &fence);
+			       entity, p->filp, &fence);
 	if (r) {
 		amdgpu_job_free(job);
 		return r;

commit 0e51a772e2014db55b969c06814e8fe01d167ba2
Author: Christian König <christian.koenig@amd.com>
Date:   Wed May 18 14:19:32 2016 +0200

    drm/amdgpu: properly abstract scheduler timeout handling
    
    The driver shouldn't mess with the scheduler internals.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Monk.Liu <monk.liu@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 9bc8f1d99733..72694d7f11f5 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -838,8 +838,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	p->job = NULL;
 
 	r = amd_sched_job_init(&job->base, &ring->sched,
-			       entity, amdgpu_job_timeout_func,
-			       amdgpu_job_free_func,
+			       entity, amdgpu_job_free_func,
 			       p->filp, &fence);
 	if (r) {
 		amdgpu_job_free(job);

commit a8ad0bd84f986072314595d05444719fdf29e412
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Mon May 9 11:04:54 2016 +0100

    drm: Remove unused drm_device from drm_gem_object_lookup()
    
    drm_gem_object_lookup() has never required the drm_device for its file
    local translation of the user handle to the GEM object. Let's remove the
    unused parameter and save some space.
    
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: dri-devel@lists.freedesktop.org
    Cc: Dave Airlie <airlied@redhat.com>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    [danvet: Fixup kerneldoc too.]
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 2bbeeb07c187..9bc8f1d99733 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -92,8 +92,7 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 {
 	struct drm_gem_object *gobj;
 
-	gobj = drm_gem_object_lookup(p->adev->ddev, p->filp,
-				     data->handle);
+	gobj = drm_gem_object_lookup(p->filp, data->handle);
 	if (gobj == NULL)
 		return -EINVAL;
 

commit 758ac17f963f3497aae4e767d3a9eb68fea71f71
Author: Christian König <christian.koenig@amd.com>
Date:   Fri May 6 22:14:00 2016 +0200

    drm/amdgpu: fix and cleanup user fence handling v2
    
    We leaked the BO in the error pass, additional to that we only have
    one user fence for all IBs in a job.
    
    v2: remove white space changes
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 9ab2f0886a14..2bbeeb07c187 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -87,33 +87,30 @@ int amdgpu_cs_get_ring(struct amdgpu_device *adev, u32 ip_type,
 }
 
 static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
-				      struct amdgpu_user_fence *uf,
-				      struct drm_amdgpu_cs_chunk_fence *fence_data)
+				      struct drm_amdgpu_cs_chunk_fence *data,
+				      uint32_t *offset)
 {
 	struct drm_gem_object *gobj;
-	uint32_t handle;
 
-	handle = fence_data->handle;
 	gobj = drm_gem_object_lookup(p->adev->ddev, p->filp,
-				     fence_data->handle);
+				     data->handle);
 	if (gobj == NULL)
 		return -EINVAL;
 
-	uf->bo = amdgpu_bo_ref(gem_to_amdgpu_bo(gobj));
-	uf->offset = fence_data->offset;
-
-	if (amdgpu_ttm_tt_get_usermm(uf->bo->tbo.ttm)) {
-		drm_gem_object_unreference_unlocked(gobj);
-		return -EINVAL;
-	}
-
-	p->uf_entry.robj = amdgpu_bo_ref(uf->bo);
+	p->uf_entry.robj = amdgpu_bo_ref(gem_to_amdgpu_bo(gobj));
 	p->uf_entry.priority = 0;
 	p->uf_entry.tv.bo = &p->uf_entry.robj->tbo;
 	p->uf_entry.tv.shared = true;
 	p->uf_entry.user_pages = NULL;
+	*offset = data->offset;
 
 	drm_gem_object_unreference_unlocked(gobj);
+
+	if (amdgpu_ttm_tt_get_usermm(p->uf_entry.robj->tbo.ttm)) {
+		amdgpu_bo_unref(&p->uf_entry.robj);
+		return -EINVAL;
+	}
+
 	return 0;
 }
 
@@ -124,8 +121,8 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	union drm_amdgpu_cs *cs = data;
 	uint64_t *chunk_array_user;
 	uint64_t *chunk_array;
-	struct amdgpu_user_fence uf = {};
 	unsigned size, num_ibs = 0;
+	uint32_t uf_offset = 0;
 	int i;
 	int ret;
 
@@ -200,7 +197,8 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 				goto free_partial_kdata;
 			}
 
-			ret = amdgpu_cs_user_fence_chunk(p, &uf, (void *)p->chunks[i].kdata);
+			ret = amdgpu_cs_user_fence_chunk(p, p->chunks[i].kdata,
+							 &uf_offset);
 			if (ret)
 				goto free_partial_kdata;
 
@@ -219,7 +217,10 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	if (ret)
 		goto free_all_kdata;
 
-	p->job->uf = uf;
+	if (p->uf_entry.robj) {
+		p->job->uf_bo = amdgpu_bo_ref(p->uf_entry.robj);
+		p->job->uf_offset = uf_offset;
+	}
 
 	kfree(chunk_array);
 	return 0;
@@ -377,7 +378,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	INIT_LIST_HEAD(&duplicates);
 	amdgpu_vm_get_pd_bo(&fpriv->vm, &p->validated, &p->vm_pd);
 
-	if (p->job->uf.bo)
+	if (p->uf_entry.robj)
 		list_add(&p->uf_entry.tv.head, &p->validated);
 
 	if (need_mmap_lock)
@@ -760,17 +761,11 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		j++;
 	}
 
-	/* wrap the last IB with user fence */
-	if (parser->job->uf.bo) {
-		struct amdgpu_ib *ib = &parser->job->ibs[parser->job->num_ibs - 1];
-
-		/* UVD & VCE fw doesn't support user fences */
-		if (parser->job->ring->type == AMDGPU_RING_TYPE_UVD ||
-		    parser->job->ring->type == AMDGPU_RING_TYPE_VCE)
-			return -EINVAL;
-
-		ib->user = &parser->job->uf;
-	}
+	/* UVD & VCE fw doesn't support user fences */
+	if (parser->job->uf_bo && (
+	    parser->job->ring->type == AMDGPU_RING_TYPE_UVD ||
+	    parser->job->ring->type == AMDGPU_RING_TYPE_VCE))
+		return -EINVAL;
 
 	return 0;
 }
@@ -856,7 +851,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	job->ctx = entity->fence_context;
 	p->fence = fence_get(fence);
 	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring, fence);
-	job->ibs[job->num_ibs - 1].sequence = cs->out.handle;
+	job->uf_sequence = cs->out.handle;
 
 	trace_amdgpu_cs_ioctl(job);
 	amd_sched_entity_push_job(&job->base);

commit d88bf583bd06eecb31f82871c90ef6a5a09b5766
Author: Christian König <christian.koenig@amd.com>
Date:   Fri May 6 17:50:03 2016 +0200

    drm/amdgpu: move VM fields into job
    
    They are the same for all IBs.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 2895d63c9979..9ab2f0886a14 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -473,6 +473,9 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		goto error_validate;
 
 	if (p->bo_list) {
+		struct amdgpu_bo *gds = p->bo_list->gds_obj;
+		struct amdgpu_bo *gws = p->bo_list->gws_obj;
+		struct amdgpu_bo *oa = p->bo_list->oa_obj;
 		struct amdgpu_vm *vm = &fpriv->vm;
 		unsigned i;
 
@@ -481,6 +484,19 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 
 			p->bo_list->array[i].bo_va = amdgpu_vm_bo_find(vm, bo);
 		}
+
+		if (gds) {
+			p->job->gds_base = amdgpu_bo_gpu_offset(gds);
+			p->job->gds_size = amdgpu_bo_size(gds);
+		}
+		if (gws) {
+			p->job->gws_base = amdgpu_bo_gpu_offset(gws);
+			p->job->gws_size = amdgpu_bo_size(gws);
+		}
+		if (oa) {
+			p->job->oa_base = amdgpu_bo_gpu_offset(oa);
+			p->job->oa_size = amdgpu_bo_size(oa);
+		}
 	}
 
 error_validate:
@@ -744,26 +760,6 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		j++;
 	}
 
-	/* add GDS resources to first IB */
-	if (parser->bo_list) {
-		struct amdgpu_bo *gds = parser->bo_list->gds_obj;
-		struct amdgpu_bo *gws = parser->bo_list->gws_obj;
-		struct amdgpu_bo *oa = parser->bo_list->oa_obj;
-		struct amdgpu_ib *ib = &parser->job->ibs[0];
-
-		if (gds) {
-			ib->gds_base = amdgpu_bo_gpu_offset(gds);
-			ib->gds_size = amdgpu_bo_size(gds);
-		}
-		if (gws) {
-			ib->gws_base = amdgpu_bo_gpu_offset(gws);
-			ib->gws_size = amdgpu_bo_size(gws);
-		}
-		if (oa) {
-			ib->oa_base = amdgpu_bo_gpu_offset(oa);
-			ib->oa_size = amdgpu_bo_size(oa);
-		}
-	}
 	/* wrap the last IB with user fence */
 	if (parser->job->uf.bo) {
 		struct amdgpu_ib *ib = &parser->job->ibs[parser->job->num_ibs - 1];

commit 92f250989b7098f4b52d50183a7b2fc4e010731b
Author: Christian König <christian.koenig@amd.com>
Date:   Fri May 6 15:57:42 2016 +0200

    drm/amdgpu: move the context from the IBs into the job
    
    We only have one context for all IBs.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 87ec1136a0bb..2895d63c9979 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -741,7 +741,6 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 
 		ib->length_dw = chunk_ib->ib_bytes / 4;
 		ib->flags = chunk_ib->flags;
-		ib->ctx = parser->ctx->rings[ring->idx].entity.fence_context;
 		j++;
 	}
 
@@ -840,6 +839,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 			    union drm_amdgpu_cs *cs)
 {
 	struct amdgpu_ring *ring = p->job->ring;
+	struct amd_sched_entity *entity = &p->ctx->rings[ring->idx].entity;
 	struct fence *fence;
 	struct amdgpu_job *job;
 	int r;
@@ -848,16 +848,16 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	p->job = NULL;
 
 	r = amd_sched_job_init(&job->base, &ring->sched,
-						&p->ctx->rings[ring->idx].entity,
-						amdgpu_job_timeout_func,
-						amdgpu_job_free_func,
-						p->filp, &fence);
+			       entity, amdgpu_job_timeout_func,
+			       amdgpu_job_free_func,
+			       p->filp, &fence);
 	if (r) {
 		amdgpu_job_free(job);
 		return r;
 	}
 
 	job->owner = p->filp;
+	job->ctx = entity->fence_context;
 	p->fence = fence_get(fence);
 	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring, fence);
 	job->ibs[job->num_ibs - 1].sequence = cs->out.handle;

commit aa3b73f67bda66637f17c3d847a8a36d3649f3f8
Author: Christian König <christian.koenig@amd.com>
Date:   Tue May 3 15:17:40 2016 +0200

    drm/amdgpu: use fence_context to judge ctx switch v2
    
    Use of the ctx pointer is not safe, because they are likely already
    be assigned to another ctx when doing comparing.
    
    v2: recreate from scratch, avoid all unnecessary changes.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Monk.Liu <monk.liu@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 1a065961981a..87ec1136a0bb 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -741,7 +741,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 
 		ib->length_dw = chunk_ib->ib_bytes / 4;
 		ib->flags = chunk_ib->flags;
-		ib->ctx = parser->ctx;
+		ib->ctx = parser->ctx->rings[ring->idx].entity.fence_context;
 		j++;
 	}
 

commit c5637837ba5d5b5e962e73f5a1a7c5456fa85a68
Author: Monk Liu <Monk.Liu@amd.com>
Date:   Tue Apr 19 20:11:32 2016 +0800

    drm/amdgpu: keep vm in job instead of ib (v2)
    
    ib.vm is a legacy way to get vm, after scheduler
    implemented vm should be get from job, and all ibs
    from one job share the same vm, no need to keep ib.vm
    just move vm field to job.
    
    this patch as well add job as paramter to ib_schedule
    so it can get vm from job->vm.
    
    v2: agd: sqaush in:
    drm/amdgpu: check if ring emit_vm_flush exists in vm flush
    
    No vm flush on engines that don't support VM.
    
    bug:
    https://bugs.freedesktop.org/show_bug.cgi?id=95195
    
    Signed-off-by: Monk Liu <Monk.Liu@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 2ebba295d0e4..1a065961981a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -120,6 +120,7 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 {
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
+	struct amdgpu_vm *vm = &fpriv->vm;
 	union drm_amdgpu_cs *cs = data;
 	uint64_t *chunk_array_user;
 	uint64_t *chunk_array;
@@ -214,7 +215,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		}
 	}
 
-	ret = amdgpu_job_alloc(p->adev, num_ibs, &p->job);
+	ret = amdgpu_job_alloc(p->adev, num_ibs, &p->job, vm);
 	if (ret)
 		goto free_all_kdata;
 

commit b76af4a41927994e130500659866efbd992deb9d
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Apr 15 17:19:17 2016 +0200

    drm/amdgpu: remove sorting of CS BOs
    
    Not needed any more.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index d7e0b0b9a1bc..2ebba295d0e4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -24,7 +24,6 @@
  * Authors:
  *    Jerome Glisse <glisse@freedesktop.org>
  */
-#include <linux/list_sort.h>
 #include <linux/pagemap.h>
 #include <drm/drmP.h>
 #include <drm/amdgpu_drm.h>
@@ -527,16 +526,6 @@ static int amdgpu_cs_sync_rings(struct amdgpu_cs_parser *p)
 	return 0;
 }
 
-static int cmp_size_smaller_first(void *priv, struct list_head *a,
-				  struct list_head *b)
-{
-	struct amdgpu_bo_list_entry *la = list_entry(a, struct amdgpu_bo_list_entry, tv.head);
-	struct amdgpu_bo_list_entry *lb = list_entry(b, struct amdgpu_bo_list_entry, tv.head);
-
-	/* Sort A before B if A is smaller. */
-	return (int)la->robj->tbo.num_pages - (int)lb->robj->tbo.num_pages;
-}
-
 /**
  * cs_parser_fini() - clean parser states
  * @parser:	parser structure holding parsing context.
@@ -553,18 +542,6 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
 	if (!error) {
 		amdgpu_vm_move_pt_bos_in_lru(parser->adev, &fpriv->vm);
 
-		/* Sort the buffer list from the smallest to largest buffer,
-		 * which affects the order of buffers in the LRU list.
-		 * This assures that the smallest buffers are added first
-		 * to the LRU list, so they are likely to be later evicted
-		 * first, instead of large buffers whose eviction is more
-		 * expensive.
-		 *
-		 * This slightly lowers the number of bytes moved by TTM
-		 * per frame under memory pressure.
-		 */
-		list_sort(NULL, &parser->validated, cmp_size_smaller_first);
-
 		ttm_eu_fence_buffer_objects(&parser->ticket,
 					    &parser->validated,
 					    parser->fence);

commit b6723c8da55af5309cf06e71a5228f3c02846c5a
Author: Monk Liu <Monk.Liu@amd.com>
Date:   Thu Mar 10 12:14:44 2016 +0800

    drm/amdgpu: use ref to keep job alive
    
    this is to fix fatal page fault error that occured if:
    job is signaled/released after its timeout work is already
    put to the global queue (in this case the cancel_delayed_work
    will return false), which will lead to NX-protection error
    page fault during job_timeout_func.
    
    Signed-off-by: Monk Liu <Monk.Liu@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 9025671d21c3..d7e0b0b9a1bc 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -872,6 +872,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	r = amd_sched_job_init(&job->base, &ring->sched,
 						&p->ctx->rings[ring->idx].entity,
 						amdgpu_job_timeout_func,
+						amdgpu_job_free_func,
 						p->filp, &fence);
 	if (r) {
 		amdgpu_job_free(job);

commit 0de2479c953ae07fd11e7b1bc8d4fc831e6842bb
Author: Monk Liu <Monk.Liu@amd.com>
Date:   Fri Mar 4 18:51:02 2016 +0800

    drm/amdgpu: rework TDR in scheduler (v2)
    
    Add two callbacks to scheduler to maintain jobs, and invoked for
    job timeout calculations. Now TDR measures time gap from
    job is processed by hw.
    
    v2:
    fix typo
    
    Signed-off-by: Monk Liu <Monk.Liu@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 23266b454aec..9025671d21c3 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -871,6 +871,7 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 
 	r = amd_sched_job_init(&job->base, &ring->sched,
 						&p->ctx->rings[ring->idx].entity,
+						amdgpu_job_timeout_func,
 						p->filp, &fence);
 	if (r) {
 		amdgpu_job_free(job);

commit e686941a32d31d22ce7c8b7faf9cce17816f7c4d
Author: Monk Liu <Monk.Liu@amd.com>
Date:   Mon Mar 7 12:49:55 2016 +0800

    drm/amdgpu: use sched_job_init to initialize sched_job
    
    Consolidate job initialization in one place rather than
    duplicating it in multiple places.
    
    Signed-off-by: Monk Liu <Monk.Liu@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 9392e50a7ba4..23266b454aec 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -862,27 +862,24 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 			    union drm_amdgpu_cs *cs)
 {
 	struct amdgpu_ring *ring = p->job->ring;
-	struct amd_sched_fence *fence;
+	struct fence *fence;
 	struct amdgpu_job *job;
+	int r;
 
 	job = p->job;
 	p->job = NULL;
 
-	job->base.sched = &ring->sched;
-	job->base.s_entity = &p->ctx->rings[ring->idx].entity;
-	job->owner = p->filp;
-
-	fence = amd_sched_fence_create(job->base.s_entity, p->filp);
-	if (!fence) {
+	r = amd_sched_job_init(&job->base, &ring->sched,
+						&p->ctx->rings[ring->idx].entity,
+						p->filp, &fence);
+	if (r) {
 		amdgpu_job_free(job);
-		return -ENOMEM;
+		return r;
 	}
 
-	job->base.s_fence = fence;
-	p->fence = fence_get(&fence->base);
-
-	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring,
-					      &fence->base);
+	job->owner = p->filp;
+	p->fence = fence_get(fence);
+	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring, fence);
 	job->ibs[job->num_ibs - 1].sequence = cs->out.handle;
 
 	trace_amdgpu_cs_ioctl(job);

commit 568d7c764ae01f3706085ac8f0d8a8ac7e826bd7
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Thu Mar 17 15:30:49 2016 +1100

    drm/amdgpu: release_pages requires linux/pagemap.h
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Reviewed-by: Christian König <christian.koenig@amd.com.
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 4f5ef4149e87..9392e50a7ba4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -25,6 +25,7 @@
  *    Jerome Glisse <glisse@freedesktop.org>
  */
 #include <linux/list_sort.h>
+#include <linux/pagemap.h>
 #include <drm/drmP.h>
 #include <drm/amdgpu_drm.h>
 #include "amdgpu.h"

commit 2f568dbd6b944c2e8c0c54b53c2211c23995e6a4
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Feb 23 12:36:59 2016 +0100

    drm/amdgpu: move get_user_pages out of amdgpu_ttm_tt_pin_userptr v6
    
    That avoids lock inversion between the BO reservation lock
    and the anon_vma lock.
    
    v2:
    * Changed amdgpu_bo_list_entry.user_pages to an array of pointers
    * Lock mmap_sem only for get_user_pages
    * Added invalidation of unbound userpointer BOs
    * Fixed memory leak and page reference leak
    
    v3 (chk):
    * Revert locking mmap_sem only for_get user_pages
    * Revert adding invalidation of unbound userpointer BOs
    * Sanitize and fix error handling
    
    v4 (chk):
    * Init userpages pointer everywhere.
    * Fix error handling when get_user_pages() fails.
    * Add invalidation of unbound userpointer BOs again.
    
    v5 (chk):
    * Add maximum number of tries.
    
    v6 (chk):
    * Fix error handling when we run out of tries.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com> (v4)
    Acked-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 7833dfb1ff6e..4f5ef4149e87 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -111,6 +111,7 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 	p->uf_entry.priority = 0;
 	p->uf_entry.tv.bo = &p->uf_entry.robj->tbo;
 	p->uf_entry.tv.shared = true;
+	p->uf_entry.user_pages = NULL;
 
 	drm_gem_object_unreference_unlocked(gobj);
 	return 0;
@@ -297,6 +298,7 @@ int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 
 	list_for_each_entry(lobj, validated, tv.head) {
 		struct amdgpu_bo *bo = lobj->robj;
+		bool binding_userptr = false;
 		struct mm_struct *usermm;
 		uint32_t domain;
 
@@ -304,6 +306,15 @@ int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 		if (usermm && usermm != current->mm)
 			return -EPERM;
 
+		/* Check if we have user pages and nobody bound the BO already */
+		if (lobj->user_pages && bo->tbo.ttm->state != tt_bound) {
+			size_t size = sizeof(struct page *);
+
+			size *= bo->tbo.ttm->num_pages;
+			memcpy(bo->tbo.ttm->pages, lobj->user_pages, size);
+			binding_userptr = true;
+		}
+
 		if (bo->pin_count)
 			continue;
 
@@ -334,6 +345,11 @@ int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 			}
 			return r;
 		}
+
+		if (binding_userptr) {
+			drm_free_large(lobj->user_pages);
+			lobj->user_pages = NULL;
+		}
 	}
 	return 0;
 }
@@ -342,8 +358,10 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 				union drm_amdgpu_cs *cs)
 {
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
+	struct amdgpu_bo_list_entry *e;
 	struct list_head duplicates;
 	bool need_mmap_lock = false;
+	unsigned i, tries = 10;
 	int r;
 
 	INIT_LIST_HEAD(&p->validated);
@@ -364,9 +382,81 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	if (need_mmap_lock)
 		down_read(&current->mm->mmap_sem);
 
-	r = ttm_eu_reserve_buffers(&p->ticket, &p->validated, true, &duplicates);
-	if (unlikely(r != 0))
-		goto error_reserve;
+	while (1) {
+		struct list_head need_pages;
+		unsigned i;
+
+		r = ttm_eu_reserve_buffers(&p->ticket, &p->validated, true,
+					   &duplicates);
+		if (unlikely(r != 0))
+			goto error_free_pages;
+
+		/* Without a BO list we don't have userptr BOs */
+		if (!p->bo_list)
+			break;
+
+		INIT_LIST_HEAD(&need_pages);
+		for (i = p->bo_list->first_userptr;
+		     i < p->bo_list->num_entries; ++i) {
+
+			e = &p->bo_list->array[i];
+
+			if (amdgpu_ttm_tt_userptr_invalidated(e->robj->tbo.ttm,
+				 &e->user_invalidated) && e->user_pages) {
+
+				/* We acquired a page array, but somebody
+				 * invalidated it. Free it an try again
+				 */
+				release_pages(e->user_pages,
+					      e->robj->tbo.ttm->num_pages,
+					      false);
+				drm_free_large(e->user_pages);
+				e->user_pages = NULL;
+			}
+
+			if (e->robj->tbo.ttm->state != tt_bound &&
+			    !e->user_pages) {
+				list_del(&e->tv.head);
+				list_add(&e->tv.head, &need_pages);
+
+				amdgpu_bo_unreserve(e->robj);
+			}
+		}
+
+		if (list_empty(&need_pages))
+			break;
+
+		/* Unreserve everything again. */
+		ttm_eu_backoff_reservation(&p->ticket, &p->validated);
+
+		/* We tried to often, just abort */
+		if (!--tries) {
+			r = -EDEADLK;
+			goto error_free_pages;
+		}
+
+		/* Fill the page arrays for all useptrs. */
+		list_for_each_entry(e, &need_pages, tv.head) {
+			struct ttm_tt *ttm = e->robj->tbo.ttm;
+
+			e->user_pages = drm_calloc_large(ttm->num_pages,
+							 sizeof(struct page*));
+			if (!e->user_pages) {
+				r = -ENOMEM;
+				goto error_free_pages;
+			}
+
+			r = amdgpu_ttm_tt_get_user_pages(ttm, e->user_pages);
+			if (r) {
+				drm_free_large(e->user_pages);
+				e->user_pages = NULL;
+				goto error_free_pages;
+			}
+		}
+
+		/* And try again. */
+		list_splice(&need_pages, &p->validated);
+	}
 
 	amdgpu_vm_get_pt_bos(&fpriv->vm, &duplicates);
 
@@ -398,10 +488,26 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		ttm_eu_backoff_reservation(&p->ticket, &p->validated);
 	}
 
-error_reserve:
+error_free_pages:
+
 	if (need_mmap_lock)
 		up_read(&current->mm->mmap_sem);
 
+	if (p->bo_list) {
+		for (i = p->bo_list->first_userptr;
+		     i < p->bo_list->num_entries; ++i) {
+			e = &p->bo_list->array[i];
+
+			if (!e->user_pages)
+				continue;
+
+			release_pages(e->user_pages,
+				      e->robj->tbo.ttm->num_pages,
+				      false);
+			drm_free_large(e->user_pages);
+		}
+	}
+
 	return r;
 }
 

commit 211dff5518d938d0c11205af3113d2c7a292dd98
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Feb 22 15:40:59 2016 +0100

    drm/amdgpu: group userptr in the BO list v2
    
    We need them together with the next patch.
    
    v2: Don't take bo reference twice
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 52c3eb96b199..7833dfb1ff6e 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -350,7 +350,8 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 
 	p->bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
 	if (p->bo_list) {
-		need_mmap_lock = p->bo_list->has_userptr;
+		need_mmap_lock = p->bo_list->first_userptr !=
+			p->bo_list->num_entries;
 		amdgpu_bo_list_get_list(p->bo_list, &p->validated);
 	}
 

commit e86f9ceee19ec028ae79a09fe1eaabf315d67969
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Feb 8 12:13:05 2016 +0100

    drm/amdgpu: move sync into job object
    
    No need to keep that for every IB.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index a5311623a489..52c3eb96b199 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -411,7 +411,7 @@ static int amdgpu_cs_sync_rings(struct amdgpu_cs_parser *p)
 
 	list_for_each_entry(e, &p->validated, tv.head) {
 		struct reservation_object *resv = e->robj->tbo.resv;
-		r = amdgpu_sync_resv(p->adev, &p->job->ibs[0].sync, resv, p->filp);
+		r = amdgpu_sync_resv(p->adev, &p->job->sync, resv, p->filp);
 
 		if (r)
 			return r;
@@ -491,7 +491,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 	if (r)
 		return r;
 
-	r = amdgpu_sync_fence(adev, &p->job->ibs[0].sync, vm->page_directory_fence);
+	r = amdgpu_sync_fence(adev, &p->job->sync, vm->page_directory_fence);
 	if (r)
 		return r;
 
@@ -517,14 +517,14 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 				return r;
 
 			f = bo_va->last_pt_update;
-			r = amdgpu_sync_fence(adev, &p->job->ibs[0].sync, f);
+			r = amdgpu_sync_fence(adev, &p->job->sync, f);
 			if (r)
 				return r;
 		}
 
 	}
 
-	r = amdgpu_vm_clear_invalids(adev, vm, &p->job->ibs[0].sync);
+	r = amdgpu_vm_clear_invalids(adev, vm, &p->job->sync);
 
 	if (amdgpu_vm_debug && p->bo_list) {
 		/* Invalidate all BOs to test for userspace bugs */
@@ -698,11 +698,8 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 				  struct amdgpu_cs_parser *p)
 {
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
-	struct amdgpu_ib *ib;
 	int i, j, r;
 
-	/* Add dependencies to first IB */
-	ib = &p->job->ibs[0];
 	for (i = 0; i < p->nchunks; ++i) {
 		struct drm_amdgpu_cs_chunk_dep *deps;
 		struct amdgpu_cs_chunk *chunk;
@@ -740,7 +737,8 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 				return r;
 
 			} else if (fence) {
-				r = amdgpu_sync_fence(adev, &ib->sync, fence);
+				r = amdgpu_sync_fence(adev, &p->job->sync,
+						      fence);
 				fence_put(fence);
 				amdgpu_ctx_put(ctx);
 				if (r)

commit d71518b5aa7c9c298ffbd12ddd23297e3373a37b
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Feb 1 12:20:25 2016 +0100

    drm/amdgpu: cleanup in kernel job submission
    
    Add a job_alloc_with_ib helper and proper job submission.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index d928165bfc33..a5311623a489 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -752,12 +752,6 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 	return 0;
 }
 
-static int amdgpu_cs_free_job(struct amdgpu_job *job)
-{
-	amdgpu_job_free(job);
-	return 0;
-}
-
 static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 			    union drm_amdgpu_cs *cs)
 {
@@ -771,12 +765,10 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	job->base.sched = &ring->sched;
 	job->base.s_entity = &p->ctx->rings[ring->idx].entity;
 	job->owner = p->filp;
-	job->free_job = amdgpu_cs_free_job;
 
 	fence = amd_sched_fence_create(job->base.s_entity, p->filp);
 	if (!fence) {
-		amdgpu_cs_free_job(job);
-		kfree(job);
+		amdgpu_job_free(job);
 		return -ENOMEM;
 	}
 

commit b07c60c0652c497af0c42c1278941f7c5a187fe9
Author: Christian König <christian.koenig@amd.com>
Date:   Sun Jan 31 12:29:04 2016 +0100

    drm/amdgpu: move ring from IBs into job
    
    We can't submit to multiple rings at the same time anyway.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 8f3b72f5c91c..d928165bfc33 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -542,26 +542,25 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 }
 
 static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
-				 struct amdgpu_cs_parser *parser)
+				 struct amdgpu_cs_parser *p)
 {
-	struct amdgpu_fpriv *fpriv = parser->filp->driver_priv;
+	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_vm *vm = &fpriv->vm;
-	struct amdgpu_ring *ring;
+	struct amdgpu_ring *ring = p->job->ring;
 	int i, r;
 
 	/* Only for UVD/VCE VM emulation */
-	for (i = 0; i < parser->job->num_ibs; i++) {
-		ring = parser->job->ibs[i].ring;
-		if (ring->funcs->parse_cs) {
-			r = amdgpu_ring_parse_cs(ring, parser, i);
+	if (ring->funcs->parse_cs) {
+		for (i = 0; i < p->job->num_ibs; i++) {
+			r = amdgpu_ring_parse_cs(ring, p, i);
 			if (r)
 				return r;
 		}
 	}
 
-	r = amdgpu_bo_vm_update_pte(parser, vm);
+	r = amdgpu_bo_vm_update_pte(p, vm);
 	if (!r)
-		amdgpu_cs_sync_rings(parser);
+		amdgpu_cs_sync_rings(p);
 
 	return r;
 }
@@ -603,6 +602,11 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		if (r)
 			return r;
 
+		if (parser->job->ring && parser->job->ring != ring)
+			return -EINVAL;
+
+		parser->job->ring = ring;
+
 		if (ring->funcs->parse_cs) {
 			struct amdgpu_bo_va_mapping *m;
 			struct amdgpu_bo *aobj = NULL;
@@ -631,7 +635,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 			offset = ((uint64_t)m->it.start) * AMDGPU_GPU_PAGE_SIZE;
 			kptr += chunk_ib->va_start - offset;
 
-			r =  amdgpu_ib_get(ring, NULL, chunk_ib->ib_bytes, ib);
+			r =  amdgpu_ib_get(adev, NULL, chunk_ib->ib_bytes, ib);
 			if (r) {
 				DRM_ERROR("Failed to get ib !\n");
 				return r;
@@ -640,7 +644,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 			memcpy(ib->ptr, kptr, chunk_ib->ib_bytes);
 			amdgpu_bo_kunmap(aobj);
 		} else {
-			r =  amdgpu_ib_get(ring, vm, 0, ib);
+			r =  amdgpu_ib_get(adev, vm, 0, ib);
 			if (r) {
 				DRM_ERROR("Failed to get ib !\n");
 				return r;
@@ -680,8 +684,8 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		struct amdgpu_ib *ib = &parser->job->ibs[parser->job->num_ibs - 1];
 
 		/* UVD & VCE fw doesn't support user fences */
-		if (ib->ring->type == AMDGPU_RING_TYPE_UVD ||
-		    ib->ring->type == AMDGPU_RING_TYPE_VCE)
+		if (parser->job->ring->type == AMDGPU_RING_TYPE_UVD ||
+		    parser->job->ring->type == AMDGPU_RING_TYPE_VCE)
 			return -EINVAL;
 
 		ib->user = &parser->job->uf;
@@ -757,7 +761,7 @@ static int amdgpu_cs_free_job(struct amdgpu_job *job)
 static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 			    union drm_amdgpu_cs *cs)
 {
-	struct amdgpu_ring * ring = p->job->ibs->ring;
+	struct amdgpu_ring *ring = p->job->ring;
 	struct amd_sched_fence *fence;
 	struct amdgpu_job *job;
 
@@ -766,7 +770,6 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 
 	job->base.sched = &ring->sched;
 	job->base.s_entity = &p->ctx->rings[ring->idx].entity;
-	job->adev = p->adev;
 	job->owner = p->filp;
 	job->free_job = amdgpu_cs_free_job;
 

commit 4c0b242cf27094b666df6604420417e201260af9
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Feb 1 11:20:37 2016 +0100

    drm/amdgpu: cleanup user fence handling in the CS
    
    Don't keep that around twice.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index e9d88771783b..8f3b72f5c91c 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -87,6 +87,7 @@ int amdgpu_cs_get_ring(struct amdgpu_device *adev, u32 ip_type,
 }
 
 static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
+				      struct amdgpu_user_fence *uf,
 				      struct drm_amdgpu_cs_chunk_fence *fence_data)
 {
 	struct drm_gem_object *gobj;
@@ -98,15 +99,15 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 	if (gobj == NULL)
 		return -EINVAL;
 
-	p->uf.bo = amdgpu_bo_ref(gem_to_amdgpu_bo(gobj));
-	p->uf.offset = fence_data->offset;
+	uf->bo = amdgpu_bo_ref(gem_to_amdgpu_bo(gobj));
+	uf->offset = fence_data->offset;
 
-	if (amdgpu_ttm_tt_get_usermm(p->uf.bo->tbo.ttm)) {
+	if (amdgpu_ttm_tt_get_usermm(uf->bo->tbo.ttm)) {
 		drm_gem_object_unreference_unlocked(gobj);
 		return -EINVAL;
 	}
 
-	p->uf_entry.robj = amdgpu_bo_ref(p->uf.bo);
+	p->uf_entry.robj = amdgpu_bo_ref(uf->bo);
 	p->uf_entry.priority = 0;
 	p->uf_entry.tv.bo = &p->uf_entry.robj->tbo;
 	p->uf_entry.tv.shared = true;
@@ -117,10 +118,11 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 
 int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 {
+	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	union drm_amdgpu_cs *cs = data;
 	uint64_t *chunk_array_user;
 	uint64_t *chunk_array;
-	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
+	struct amdgpu_user_fence uf = {};
 	unsigned size, num_ibs = 0;
 	int i;
 	int ret;
@@ -196,7 +198,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 				goto free_partial_kdata;
 			}
 
-			ret = amdgpu_cs_user_fence_chunk(p, (void *)p->chunks[i].kdata);
+			ret = amdgpu_cs_user_fence_chunk(p, &uf, (void *)p->chunks[i].kdata);
 			if (ret)
 				goto free_partial_kdata;
 
@@ -215,6 +217,8 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	if (ret)
 		goto free_all_kdata;
 
+	p->job->uf = uf;
+
 	kfree(chunk_array);
 	return 0;
 
@@ -353,7 +357,7 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 	INIT_LIST_HEAD(&duplicates);
 	amdgpu_vm_get_pd_bo(&fpriv->vm, &p->validated, &p->vm_pd);
 
-	if (p->uf.bo)
+	if (p->job->uf.bo)
 		list_add(&p->uf_entry.tv.head, &p->validated);
 
 	if (need_mmap_lock)
@@ -472,7 +476,6 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
 	kfree(parser->chunks);
 	if (parser->job)
 		amdgpu_job_free(parser->job);
-	amdgpu_bo_unref(&parser->uf.bo);
 	amdgpu_bo_unref(&parser->uf_entry.robj);
 }
 
@@ -673,7 +676,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		}
 	}
 	/* wrap the last IB with user fence */
-	if (parser->uf.bo) {
+	if (parser->job->uf.bo) {
 		struct amdgpu_ib *ib = &parser->job->ibs[parser->job->num_ibs - 1];
 
 		/* UVD & VCE fw doesn't support user fences */
@@ -681,7 +684,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		    ib->ring->type == AMDGPU_RING_TYPE_VCE)
 			return -EINVAL;
 
-		ib->user = &parser->uf;
+		ib->user = &parser->job->uf;
 	}
 
 	return 0;
@@ -767,12 +770,6 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	job->owner = p->filp;
 	job->free_job = amdgpu_cs_free_job;
 
-	if (job->ibs[job->num_ibs - 1].user) {
-		job->uf = p->uf;
-		job->ibs[job->num_ibs - 1].user = &job->uf;
-		p->uf.bo = NULL;
-	}
-
 	fence = amd_sched_fence_create(job->base.s_entity, p->filp);
 	if (!fence) {
 		amdgpu_cs_free_job(job);

commit 50838c8cc413de8da39c4c216ae05410845d5a44
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Feb 3 13:44:52 2016 +0100

    drm/amdgpu: add proper job alloc/free functions
    
    And use them in the CS instead of allocating IBs and jobs separately.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 55179efccfcf..e9d88771783b 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -121,7 +121,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	uint64_t *chunk_array_user;
 	uint64_t *chunk_array;
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
-	unsigned size;
+	unsigned size, num_ibs = 0;
 	int i;
 	int ret;
 
@@ -186,7 +186,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 
 		switch (p->chunks[i].chunk_id) {
 		case AMDGPU_CHUNK_ID_IB:
-			p->num_ibs++;
+			++num_ibs;
 			break;
 
 		case AMDGPU_CHUNK_ID_FENCE:
@@ -211,16 +211,9 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		}
 	}
 
-	if (p->num_ibs == 0) {
-		ret = -EINVAL;
+	ret = amdgpu_job_alloc(p->adev, num_ibs, &p->job);
+	if (ret)
 		goto free_all_kdata;
-	}
-
-	p->ibs = kcalloc(p->num_ibs, sizeof(struct amdgpu_ib), GFP_KERNEL);
-	if (!p->ibs) {
-		ret = -ENOMEM;
-		goto free_all_kdata;
-	}
 
 	kfree(chunk_array);
 	return 0;
@@ -414,7 +407,7 @@ static int amdgpu_cs_sync_rings(struct amdgpu_cs_parser *p)
 
 	list_for_each_entry(e, &p->validated, tv.head) {
 		struct reservation_object *resv = e->robj->tbo.resv;
-		r = amdgpu_sync_resv(p->adev, &p->ibs[0].sync, resv, p->filp);
+		r = amdgpu_sync_resv(p->adev, &p->job->ibs[0].sync, resv, p->filp);
 
 		if (r)
 			return r;
@@ -477,10 +470,8 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
 	for (i = 0; i < parser->nchunks; i++)
 		drm_free_large(parser->chunks[i].kdata);
 	kfree(parser->chunks);
-	if (parser->ibs)
-		for (i = 0; i < parser->num_ibs; i++)
-			amdgpu_ib_free(parser->adev, &parser->ibs[i]);
-	kfree(parser->ibs);
+	if (parser->job)
+		amdgpu_job_free(parser->job);
 	amdgpu_bo_unref(&parser->uf.bo);
 	amdgpu_bo_unref(&parser->uf_entry.robj);
 }
@@ -497,7 +488,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 	if (r)
 		return r;
 
-	r = amdgpu_sync_fence(adev, &p->ibs[0].sync, vm->page_directory_fence);
+	r = amdgpu_sync_fence(adev, &p->job->ibs[0].sync, vm->page_directory_fence);
 	if (r)
 		return r;
 
@@ -523,14 +514,14 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 				return r;
 
 			f = bo_va->last_pt_update;
-			r = amdgpu_sync_fence(adev, &p->ibs[0].sync, f);
+			r = amdgpu_sync_fence(adev, &p->job->ibs[0].sync, f);
 			if (r)
 				return r;
 		}
 
 	}
 
-	r = amdgpu_vm_clear_invalids(adev, vm, &p->ibs[0].sync);
+	r = amdgpu_vm_clear_invalids(adev, vm, &p->job->ibs[0].sync);
 
 	if (amdgpu_vm_debug && p->bo_list) {
 		/* Invalidate all BOs to test for userspace bugs */
@@ -556,8 +547,8 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 	int i, r;
 
 	/* Only for UVD/VCE VM emulation */
-	for (i = 0; i < parser->num_ibs; i++) {
-		ring = parser->ibs[i].ring;
+	for (i = 0; i < parser->job->num_ibs; i++) {
+		ring = parser->job->ibs[i].ring;
 		if (ring->funcs->parse_cs) {
 			r = amdgpu_ring_parse_cs(ring, parser, i);
 			if (r)
@@ -590,14 +581,14 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 	int i, j;
 	int r;
 
-	for (i = 0, j = 0; i < parser->nchunks && j < parser->num_ibs; i++) {
+	for (i = 0, j = 0; i < parser->nchunks && j < parser->job->num_ibs; i++) {
 		struct amdgpu_cs_chunk *chunk;
 		struct amdgpu_ib *ib;
 		struct drm_amdgpu_cs_chunk_ib *chunk_ib;
 		struct amdgpu_ring *ring;
 
 		chunk = &parser->chunks[i];
-		ib = &parser->ibs[j];
+		ib = &parser->job->ibs[j];
 		chunk_ib = (struct drm_amdgpu_cs_chunk_ib *)chunk->kdata;
 
 		if (chunk->chunk_id != AMDGPU_CHUNK_ID_IB)
@@ -666,7 +657,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		struct amdgpu_bo *gds = parser->bo_list->gds_obj;
 		struct amdgpu_bo *gws = parser->bo_list->gws_obj;
 		struct amdgpu_bo *oa = parser->bo_list->oa_obj;
-		struct amdgpu_ib *ib = &parser->ibs[0];
+		struct amdgpu_ib *ib = &parser->job->ibs[0];
 
 		if (gds) {
 			ib->gds_base = amdgpu_bo_gpu_offset(gds);
@@ -683,7 +674,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 	}
 	/* wrap the last IB with user fence */
 	if (parser->uf.bo) {
-		struct amdgpu_ib *ib = &parser->ibs[parser->num_ibs - 1];
+		struct amdgpu_ib *ib = &parser->job->ibs[parser->job->num_ibs - 1];
 
 		/* UVD & VCE fw doesn't support user fences */
 		if (ib->ring->type == AMDGPU_RING_TYPE_UVD ||
@@ -704,7 +695,7 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 	int i, j, r;
 
 	/* Add dependencies to first IB */
-	ib = &p->ibs[0];
+	ib = &p->job->ibs[0];
 	for (i = 0; i < p->nchunks; ++i) {
 		struct drm_amdgpu_cs_chunk_dep *deps;
 		struct amdgpu_cs_chunk *chunk;
@@ -756,26 +747,19 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 
 static int amdgpu_cs_free_job(struct amdgpu_job *job)
 {
-	int i;
-	if (job->ibs)
-		for (i = 0; i < job->num_ibs; i++)
-			amdgpu_ib_free(job->adev, &job->ibs[i]);
-	kfree(job->ibs);
-	if (job->uf.bo)
-		amdgpu_bo_unref(&job->uf.bo);
+	amdgpu_job_free(job);
 	return 0;
 }
 
 static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 			    union drm_amdgpu_cs *cs)
 {
-	struct amdgpu_ring * ring = p->ibs->ring;
+	struct amdgpu_ring * ring = p->job->ibs->ring;
 	struct amd_sched_fence *fence;
 	struct amdgpu_job *job;
 
-	job = kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
-	if (!job)
-		return -ENOMEM;
+	job = p->job;
+	p->job = NULL;
 
 	job->base.sched = &ring->sched;
 	job->base.s_entity = &p->ctx->rings[ring->idx].entity;
@@ -783,11 +767,6 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	job->owner = p->filp;
 	job->free_job = amdgpu_cs_free_job;
 
-	job->ibs = p->ibs;
-	job->num_ibs = p->num_ibs;
-	p->ibs = NULL;
-	p->num_ibs = 0;
-
 	if (job->ibs[job->num_ibs - 1].user) {
 		job->uf = p->uf;
 		job->ibs[job->num_ibs - 1].user = &job->uf;
@@ -854,7 +833,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	if (r)
 		goto out;
 
-	for (i = 0; i < parser.num_ibs; i++)
+	for (i = 0; i < parser.job->num_ibs; i++)
 		trace_amdgpu_cs(&parser, i);
 
 	r = amdgpu_cs_ib_vm_chunk(adev, &parser);

commit 4acabfe3793eb9bf89f71cc0cef23dfb2a812916
Author: Christian König <christian.koenig@amd.com>
Date:   Sun Jan 31 11:32:04 2016 +0100

    drm/amdgpu: fix num_ibs check
    
    Specifying no IBs on command submission is invalid, stop crashing
    badly when somebody tries it.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucer@amd.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index e7e384264202..55179efccfcf 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -211,6 +211,10 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		}
 	}
 
+	if (p->num_ibs == 0) {
+		ret = -EINVAL;
+		goto free_all_kdata;
+	}
 
 	p->ibs = kcalloc(p->num_ibs, sizeof(struct amdgpu_ib), GFP_KERNEL);
 	if (!p->ibs) {
@@ -551,9 +555,6 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 	struct amdgpu_ring *ring;
 	int i, r;
 
-	if (parser->num_ibs == 0)
-		return 0;
-
 	/* Only for UVD/VCE VM emulation */
 	for (i = 0; i < parser->num_ibs; i++) {
 		ring = parser->ibs[i].ring;
@@ -660,9 +661,6 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		j++;
 	}
 
-	if (!parser->num_ibs)
-		return 0;
-
 	/* add GDS resources to first IB */
 	if (parser->bo_list) {
 		struct amdgpu_bo *gds = parser->bo_list->gds_obj;
@@ -705,9 +703,6 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 	struct amdgpu_ib *ib;
 	int i, j, r;
 
-	if (!p->num_ibs)
-		return 0;
-
 	/* Add dependencies to first IB */
 	ib = &p->ibs[0];
 	for (i = 0; i < p->nchunks; ++i) {
@@ -866,8 +861,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	if (r)
 		goto out;
 
-	if (parser.num_ibs)
-		r = amdgpu_cs_submit(&parser, cs);
+	r = amdgpu_cs_submit(&parser, cs);
 
 out:
 	amdgpu_cs_parser_fini(&parser, r, reserved_buffers);

commit cc325d1913475655b81c0417ba04c84f168ac78c
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Feb 8 11:08:35 2016 +0100

    drm/amdgpu: check userptrs mm earlier
    
    Instead of when we try to bind it check the usermm when
    we try to use it in the IOCTLs.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index a795af3ab0ad..e7e384264202 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -101,7 +101,7 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 	p->uf.bo = amdgpu_bo_ref(gem_to_amdgpu_bo(gobj));
 	p->uf.offset = fence_data->offset;
 
-	if (amdgpu_ttm_tt_has_userptr(p->uf.bo->tbo.ttm)) {
+	if (amdgpu_ttm_tt_get_usermm(p->uf.bo->tbo.ttm)) {
 		drm_gem_object_unreference_unlocked(gobj);
 		return -EINVAL;
 	}
@@ -296,8 +296,13 @@ int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 
 	list_for_each_entry(lobj, validated, tv.head) {
 		struct amdgpu_bo *bo = lobj->robj;
+		struct mm_struct *usermm;
 		uint32_t domain;
 
+		usermm = amdgpu_ttm_tt_get_usermm(bo->tbo.ttm);
+		if (usermm && usermm != current->mm)
+			return -EPERM;
+
 		if (bo->pin_count)
 			continue;
 

commit cd75dc6887f1e1fddc4ee8ef5ae4e40529607379
Author: Christian König <christian.koenig@amd.com>
Date:   Sun Jan 31 11:30:55 2016 +0100

    drm/amdgpu: separate pushing CS to scheduler
    
    Move that out of the main IOCTL function.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index ddeba55c3b7d..a795af3ab0ad 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -766,6 +766,54 @@ static int amdgpu_cs_free_job(struct amdgpu_job *job)
 	return 0;
 }
 
+static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
+			    union drm_amdgpu_cs *cs)
+{
+	struct amdgpu_ring * ring = p->ibs->ring;
+	struct amd_sched_fence *fence;
+	struct amdgpu_job *job;
+
+	job = kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
+	if (!job)
+		return -ENOMEM;
+
+	job->base.sched = &ring->sched;
+	job->base.s_entity = &p->ctx->rings[ring->idx].entity;
+	job->adev = p->adev;
+	job->owner = p->filp;
+	job->free_job = amdgpu_cs_free_job;
+
+	job->ibs = p->ibs;
+	job->num_ibs = p->num_ibs;
+	p->ibs = NULL;
+	p->num_ibs = 0;
+
+	if (job->ibs[job->num_ibs - 1].user) {
+		job->uf = p->uf;
+		job->ibs[job->num_ibs - 1].user = &job->uf;
+		p->uf.bo = NULL;
+	}
+
+	fence = amd_sched_fence_create(job->base.s_entity, p->filp);
+	if (!fence) {
+		amdgpu_cs_free_job(job);
+		kfree(job);
+		return -ENOMEM;
+	}
+
+	job->base.s_fence = fence;
+	p->fence = fence_get(&fence->base);
+
+	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring,
+					      &fence->base);
+	job->ibs[job->num_ibs - 1].sequence = cs->out.handle;
+
+	trace_amdgpu_cs_ioctl(job);
+	amd_sched_entity_push_job(&job->base);
+
+	return 0;
+}
+
 int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 {
 	struct amdgpu_device *adev = dev->dev_private;
@@ -813,52 +861,8 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	if (r)
 		goto out;
 
-	if (parser.num_ibs) {
-		struct amdgpu_ring * ring = parser.ibs->ring;
-		struct amd_sched_fence *fence;
-		struct amdgpu_job *job;
-
-		job = kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
-		if (!job) {
-			r = -ENOMEM;
-			goto out;
-		}
-
-		job->base.sched = &ring->sched;
-		job->base.s_entity = &parser.ctx->rings[ring->idx].entity;
-		job->adev = parser.adev;
-		job->owner = parser.filp;
-		job->free_job = amdgpu_cs_free_job;
-
-		job->ibs = parser.ibs;
-		job->num_ibs = parser.num_ibs;
-		parser.ibs = NULL;
-		parser.num_ibs = 0;
-
-		if (job->ibs[job->num_ibs - 1].user) {
-			job->uf = parser.uf;
-			job->ibs[job->num_ibs - 1].user = &job->uf;
-			parser.uf.bo = NULL;
-		}
-
-		fence = amd_sched_fence_create(job->base.s_entity,
-					       parser.filp);
-		if (!fence) {
-			r = -ENOMEM;
-			amdgpu_cs_free_job(job);
-			kfree(job);
-			goto out;
-		}
-		job->base.s_fence = fence;
-		parser.fence = fence_get(&fence->base);
-
-		cs->out.handle = amdgpu_ctx_add_fence(parser.ctx, ring,
-						      &fence->base);
-		job->ibs[job->num_ibs - 1].sequence = cs->out.handle;
-
-		trace_amdgpu_cs_ioctl(job);
-		amd_sched_entity_push_job(&job->base);
-	}
+	if (parser.num_ibs)
+		r = amdgpu_cs_submit(&parser, cs);
 
 out:
 	amdgpu_cs_parser_fini(&parser, r, reserved_buffers);

commit cadf97b196a1e5b2db2606d53f77714e3e9cf4bb
Author: Chunming Zhou <David1.Zhou@amd.com>
Date:   Fri Jan 15 11:25:00 2016 +0800

    drm/amdgpu: clean up non-scheduler code path (v2)
    
    Non-scheduler code is longer supported.
    
    v2: agd: rebased on upstream
    
    Signed-off-by: Chunming Zhou <David1.Zhou@amd.com>
    Reviewed-by: Ken Wang  <Qingqing.Wang@amd.com>
    Reviewed-by: Monk Liu <monk.liu@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 0479ad5a66ed..ddeba55c3b7d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -813,7 +813,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	if (r)
 		goto out;
 
-	if (amdgpu_enable_scheduler && parser.num_ibs) {
+	if (parser.num_ibs) {
 		struct amdgpu_ring * ring = parser.ibs->ring;
 		struct amd_sched_fence *fence;
 		struct amdgpu_job *job;
@@ -858,15 +858,6 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 		trace_amdgpu_cs_ioctl(job);
 		amd_sched_entity_push_job(&job->base);
-
-	} else {
-		struct amdgpu_fence *fence;
-
-		r = amdgpu_ib_schedule(adev, parser.num_ibs, parser.ibs,
-				       parser.filp);
-		fence = parser.ibs[parser.num_ibs - 1].fence;
-		parser.fence = fence_get(&fence->base);
-		cs->out.handle = parser.ibs[parser.num_ibs - 1].sequence;
 	}
 
 out:

commit a8480309df2aa8b39e8f67b5202db8cebaff4b72
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Jan 5 16:03:39 2016 +0100

    drm/amdgpu: try to find BO VAs only for the BOs in the list
    
    The other ones don't have any VAs assigned anyway or are uninteresting to us.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index ac26e52d5923..0479ad5a66ed 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -290,8 +290,6 @@ static u64 amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev)
 int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 			    struct list_head *validated)
 {
-	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
-	struct amdgpu_vm *vm = &fpriv->vm;
 	struct amdgpu_bo_list_entry *lobj;
 	u64 initial_bytes_moved;
 	int r;
@@ -300,7 +298,6 @@ int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 		struct amdgpu_bo *bo = lobj->robj;
 		uint32_t domain;
 
-		lobj->bo_va = amdgpu_vm_bo_find(vm, bo);
 		if (bo->pin_count)
 			continue;
 
@@ -374,6 +371,19 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 		goto error_validate;
 
 	r = amdgpu_cs_list_validate(p, &p->validated);
+	if (r)
+		goto error_validate;
+
+	if (p->bo_list) {
+		struct amdgpu_vm *vm = &fpriv->vm;
+		unsigned i;
+
+		for (i = 0; i < p->bo_list->num_entries; i++) {
+			struct amdgpu_bo *bo = p->bo_list->array[i].robj;
+
+			p->bo_list->array[i].bo_va = amdgpu_vm_bo_find(vm, bo);
+		}
+	}
 
 error_validate:
 	if (r) {

commit 15486fd20cbe45cf56805ee5a67f7b25642efa9d
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Dec 22 16:06:12 2015 +0100

    drm/amdgpu: search only the BO list for VM mappings
    
    Make UVD/VCE VM emulation more efficient.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index a610465c5e0b..ac26e52d5923 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -928,30 +928,36 @@ struct amdgpu_bo_va_mapping *
 amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 		       uint64_t addr, struct amdgpu_bo **bo)
 {
-	struct amdgpu_bo_list_entry *reloc;
 	struct amdgpu_bo_va_mapping *mapping;
+	unsigned i;
+
+	if (!parser->bo_list)
+		return NULL;
 
 	addr /= AMDGPU_GPU_PAGE_SIZE;
 
-	list_for_each_entry(reloc, &parser->validated, tv.head) {
-		if (!reloc->bo_va)
+	for (i = 0; i < parser->bo_list->num_entries; i++) {
+		struct amdgpu_bo_list_entry *lobj;
+
+		lobj = &parser->bo_list->array[i];
+		if (!lobj->bo_va)
 			continue;
 
-		list_for_each_entry(mapping, &reloc->bo_va->valids, list) {
+		list_for_each_entry(mapping, &lobj->bo_va->valids, list) {
 			if (mapping->it.start > addr ||
 			    addr > mapping->it.last)
 				continue;
 
-			*bo = reloc->bo_va->bo;
+			*bo = lobj->bo_va->bo;
 			return mapping;
 		}
 
-		list_for_each_entry(mapping, &reloc->bo_va->invalids, list) {
+		list_for_each_entry(mapping, &lobj->bo_va->invalids, list) {
 			if (mapping->it.start > addr ||
 			    addr > mapping->it.last)
 				continue;
 
-			*bo = reloc->bo_va->bo;
+			*bo = lobj->bo_va->bo;
 			return mapping;
 		}
 	}

commit 1ea863fd736eed8217a0b7bc5d0bd0de6b267b80
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Dec 18 22:13:12 2015 +0100

    drm/amdgpu: keep the prefered/allowed domains in the BO
    
    Stop copying that to the bo list entry, it doesn't change anyway.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index d249e9e0a4ea..a610465c5e0b 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -107,8 +107,6 @@ static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
 	}
 
 	p->uf_entry.robj = amdgpu_bo_ref(p->uf.bo);
-	p->uf_entry.prefered_domains = AMDGPU_GEM_DOMAIN_GTT;
-	p->uf_entry.allowed_domains = AMDGPU_GEM_DOMAIN_GTT;
 	p->uf_entry.priority = 0;
 	p->uf_entry.tv.bo = &p->uf_entry.robj->tbo;
 	p->uf_entry.tv.shared = true;
@@ -315,9 +313,9 @@ int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 		 * completely.
 		 */
 		if (p->bytes_moved <= p->bytes_moved_threshold)
-			domain = lobj->prefered_domains;
+			domain = bo->prefered_domains;
 		else
-			domain = lobj->allowed_domains;
+			domain = bo->allowed_domains;
 
 	retry:
 		amdgpu_ttm_placement_from_domain(bo, domain);
@@ -327,8 +325,8 @@ int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 			       initial_bytes_moved;
 
 		if (unlikely(r)) {
-			if (r != -ERESTARTSYS && domain != lobj->allowed_domains) {
-				domain = lobj->allowed_domains;
+			if (r != -ERESTARTSYS && domain != bo->allowed_domains) {
+				domain = bo->allowed_domains;
 				goto retry;
 			}
 			return r;

commit 636ce25c30010a8f393f5a1e67d5d4b7b66739e7
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Dec 18 21:26:47 2015 +0100

    drm/amdgpu: cleanup bo list bucket handling
    
    Move that into the BO list. No functional change.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 5986da26a492..d249e9e0a4ea 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -30,47 +30,6 @@
 #include "amdgpu.h"
 #include "amdgpu_trace.h"
 
-#define AMDGPU_CS_MAX_PRIORITY		32u
-#define AMDGPU_CS_NUM_BUCKETS		(AMDGPU_CS_MAX_PRIORITY + 1)
-
-/* This is based on the bucket sort with O(n) time complexity.
- * An item with priority "i" is added to bucket[i]. The lists are then
- * concatenated in descending order.
- */
-struct amdgpu_cs_buckets {
-	struct list_head bucket[AMDGPU_CS_NUM_BUCKETS];
-};
-
-static void amdgpu_cs_buckets_init(struct amdgpu_cs_buckets *b)
-{
-	unsigned i;
-
-	for (i = 0; i < AMDGPU_CS_NUM_BUCKETS; i++)
-		INIT_LIST_HEAD(&b->bucket[i]);
-}
-
-static void amdgpu_cs_buckets_add(struct amdgpu_cs_buckets *b,
-				  struct list_head *item, unsigned priority)
-{
-	/* Since buffers which appear sooner in the relocation list are
-	 * likely to be used more often than buffers which appear later
-	 * in the list, the sort mustn't change the ordering of buffers
-	 * with the same priority, i.e. it must be stable.
-	 */
-	list_add_tail(item, &b->bucket[min(priority, AMDGPU_CS_MAX_PRIORITY)]);
-}
-
-static void amdgpu_cs_buckets_get_list(struct amdgpu_cs_buckets *b,
-				       struct list_head *out_list)
-{
-	unsigned i;
-
-	/* Connect the sorted buckets in the output list. */
-	for (i = 0; i < AMDGPU_CS_NUM_BUCKETS; i++) {
-		list_splice(&b->bucket[i], out_list);
-	}
-}
-
 int amdgpu_cs_get_ring(struct amdgpu_device *adev, u32 ip_type,
 		       u32 ip_instance, u32 ring,
 		       struct amdgpu_ring **out_ring)
@@ -382,22 +341,16 @@ static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
 				union drm_amdgpu_cs *cs)
 {
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
-	struct amdgpu_cs_buckets buckets;
 	struct list_head duplicates;
 	bool need_mmap_lock = false;
-	int i, r;
+	int r;
 
 	INIT_LIST_HEAD(&p->validated);
 
 	p->bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
 	if (p->bo_list) {
 		need_mmap_lock = p->bo_list->has_userptr;
-		amdgpu_cs_buckets_init(&buckets);
-		for (i = 0; i < p->bo_list->num_entries; i++)
-			amdgpu_cs_buckets_add(&buckets, &p->bo_list->array[i].tv.head,
-					      p->bo_list->array[i].priority);
-
-		amdgpu_cs_buckets_get_list(&buckets, &p->validated);
+		amdgpu_bo_list_get_list(p->bo_list, &p->validated);
 	}
 
 	INIT_LIST_HEAD(&duplicates);

commit 2a7d9bdabec21825ef77f5705e463342a9d7fcea
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Dec 18 20:33:52 2015 +0100

    drm/amdgpu: cleanup amdgpu_cs_parser_relocs
    
    Rename it to amdgpu_cs_parser_bos and move validation and bo list init there.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 03ec5e86d1a1..5986da26a492 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -181,15 +181,12 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		goto free_chunk;
 	}
 
-	p->bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
-
 	/* get chunks */
-	INIT_LIST_HEAD(&p->validated);
 	chunk_array_user = (uint64_t __user *)(unsigned long)(cs->in.chunks);
 	if (copy_from_user(chunk_array, chunk_array_user,
 			   sizeof(uint64_t)*cs->in.num_chunks)) {
 		ret = -EFAULT;
-		goto put_bo_list;
+		goto put_ctx;
 	}
 
 	p->nchunks = cs->in.num_chunks;
@@ -197,7 +194,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 			    GFP_KERNEL);
 	if (!p->chunks) {
 		ret = -ENOMEM;
-		goto put_bo_list;
+		goto put_ctx;
 	}
 
 	for (i = 0; i < p->nchunks; i++) {
@@ -273,9 +270,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	for (; i >= 0; i--)
 		drm_free_large(p->chunks[i].kdata);
 	kfree(p->chunks);
-put_bo_list:
-	if (p->bo_list)
-		amdgpu_bo_list_put(p->bo_list);
+put_ctx:
 	amdgpu_ctx_put(p->ctx);
 free_chunk:
 	kfree(chunk_array);
@@ -383,7 +378,8 @@ int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 	return 0;
 }
 
-static int amdgpu_cs_parser_relocs(struct amdgpu_cs_parser *p)
+static int amdgpu_cs_parser_bos(struct amdgpu_cs_parser *p,
+				union drm_amdgpu_cs *cs)
 {
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_cs_buckets buckets;
@@ -391,12 +387,15 @@ static int amdgpu_cs_parser_relocs(struct amdgpu_cs_parser *p)
 	bool need_mmap_lock = false;
 	int i, r;
 
+	INIT_LIST_HEAD(&p->validated);
+
+	p->bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
 	if (p->bo_list) {
 		need_mmap_lock = p->bo_list->has_userptr;
 		amdgpu_cs_buckets_init(&buckets);
 		for (i = 0; i < p->bo_list->num_entries; i++)
 			amdgpu_cs_buckets_add(&buckets, &p->bo_list->array[i].tv.head,
-								  p->bo_list->array[i].priority);
+					      p->bo_list->array[i].priority);
 
 		amdgpu_cs_buckets_get_list(&buckets, &p->validated);
 	}
@@ -827,7 +826,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		r = amdgpu_cs_handle_lockup(adev, r);
 		return r;
 	}
-	r = amdgpu_cs_parser_relocs(&parser);
+	r = amdgpu_cs_parser_bos(&parser, data);
 	if (r == -ENOMEM)
 		DRM_ERROR("Not enough memory for command submission!\n");
 	else if (r && r != -ERESTARTSYS)

commit c3cca41e6249e9775adfc0ad8bc1af6fc434da9f
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Dec 15 14:41:33 2015 +0100

    drm/amdgpu: cleanup amdgpu_cs_parser structure
    
    Remove unused user_ptr field, group fields by usage.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index c63efd7972d5..03ec5e86d1a1 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -217,7 +217,6 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 
 		size = p->chunks[i].length_dw;
 		cdata = (void __user *)(unsigned long)user_chunk.chunk_data;
-		p->chunks[i].user_ptr = cdata;
 
 		p->chunks[i].kdata = drm_malloc_ab(size, sizeof(uint32_t));
 		if (p->chunks[i].kdata == NULL) {

commit 36409d122cb84fa8f25a42b95a32c6090790e571
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Dec 21 20:31:35 2015 +0100

    drm/amdgpu: cleanup amdgpu_cs_list_validate
    
    No need to actually check the current placement. Just use the allowed domains
    when the threshold is reached.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 2f80da016d57..c63efd7972d5 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -342,48 +342,44 @@ int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_vm *vm = &fpriv->vm;
 	struct amdgpu_bo_list_entry *lobj;
-	struct amdgpu_bo *bo;
 	u64 initial_bytes_moved;
 	int r;
 
 	list_for_each_entry(lobj, validated, tv.head) {
-		bo = lobj->robj;
-		if (!bo->pin_count) {
-			u32 domain = lobj->prefered_domains;
-			u32 current_domain =
-				amdgpu_mem_type_to_domain(bo->tbo.mem.mem_type);
-
-			/* Check if this buffer will be moved and don't move it
-			 * if we have moved too many buffers for this IB already.
-			 *
-			 * Note that this allows moving at least one buffer of
-			 * any size, because it doesn't take the current "bo"
-			 * into account. We don't want to disallow buffer moves
-			 * completely.
-			 */
-			if ((lobj->allowed_domains & current_domain) != 0 &&
-			    (domain & current_domain) == 0 && /* will be moved */
-			    p->bytes_moved > p->bytes_moved_threshold) {
-				/* don't move it */
-				domain = current_domain;
-			}
+		struct amdgpu_bo *bo = lobj->robj;
+		uint32_t domain;
 
-		retry:
-			amdgpu_ttm_placement_from_domain(bo, domain);
-			initial_bytes_moved = atomic64_read(&bo->adev->num_bytes_moved);
-			r = ttm_bo_validate(&bo->tbo, &bo->placement, true, false);
-			p->bytes_moved += atomic64_read(&bo->adev->num_bytes_moved) -
-				       initial_bytes_moved;
-
-			if (unlikely(r)) {
-				if (r != -ERESTARTSYS && domain != lobj->allowed_domains) {
-					domain = lobj->allowed_domains;
-					goto retry;
-				}
-				return r;
+		lobj->bo_va = amdgpu_vm_bo_find(vm, bo);
+		if (bo->pin_count)
+			continue;
+
+		/* Avoid moving this one if we have moved too many buffers
+		 * for this IB already.
+		 *
+		 * Note that this allows moving at least one buffer of
+		 * any size, because it doesn't take the current "bo"
+		 * into account. We don't want to disallow buffer moves
+		 * completely.
+		 */
+		if (p->bytes_moved <= p->bytes_moved_threshold)
+			domain = lobj->prefered_domains;
+		else
+			domain = lobj->allowed_domains;
+
+	retry:
+		amdgpu_ttm_placement_from_domain(bo, domain);
+		initial_bytes_moved = atomic64_read(&bo->adev->num_bytes_moved);
+		r = ttm_bo_validate(&bo->tbo, &bo->placement, true, false);
+		p->bytes_moved += atomic64_read(&bo->adev->num_bytes_moved) -
+			       initial_bytes_moved;
+
+		if (unlikely(r)) {
+			if (r != -ERESTARTSYS && domain != lobj->allowed_domains) {
+				domain = lobj->allowed_domains;
+				goto retry;
 			}
+			return r;
 		}
-		lobj->bo_va = amdgpu_vm_bo_find(vm, bo);
 	}
 	return 0;
 }

commit f69f90a113f283b33b7b750204d708711a42b396
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Dec 21 19:47:42 2015 +0100

    drm/amdgpu: fix amdgpu_cs_get_threshold_for_moves handling
    
    The threshold should only be computed once.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index b882e8175615..2f80da016d57 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -336,14 +336,14 @@ static u64 amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev)
 	return max(bytes_moved_threshold, 1024*1024ull);
 }
 
-int amdgpu_cs_list_validate(struct amdgpu_device *adev,
-			    struct amdgpu_vm *vm,
+int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p,
 			    struct list_head *validated)
 {
+	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
+	struct amdgpu_vm *vm = &fpriv->vm;
 	struct amdgpu_bo_list_entry *lobj;
 	struct amdgpu_bo *bo;
-	u64 bytes_moved = 0, initial_bytes_moved;
-	u64 bytes_moved_threshold = amdgpu_cs_get_threshold_for_moves(adev);
+	u64 initial_bytes_moved;
 	int r;
 
 	list_for_each_entry(lobj, validated, tv.head) {
@@ -363,16 +363,16 @@ int amdgpu_cs_list_validate(struct amdgpu_device *adev,
 			 */
 			if ((lobj->allowed_domains & current_domain) != 0 &&
 			    (domain & current_domain) == 0 && /* will be moved */
-			    bytes_moved > bytes_moved_threshold) {
+			    p->bytes_moved > p->bytes_moved_threshold) {
 				/* don't move it */
 				domain = current_domain;
 			}
 
 		retry:
 			amdgpu_ttm_placement_from_domain(bo, domain);
-			initial_bytes_moved = atomic64_read(&adev->num_bytes_moved);
+			initial_bytes_moved = atomic64_read(&bo->adev->num_bytes_moved);
 			r = ttm_bo_validate(&bo->tbo, &bo->placement, true, false);
-			bytes_moved += atomic64_read(&adev->num_bytes_moved) -
+			p->bytes_moved += atomic64_read(&bo->adev->num_bytes_moved) -
 				       initial_bytes_moved;
 
 			if (unlikely(r)) {
@@ -421,11 +421,14 @@ static int amdgpu_cs_parser_relocs(struct amdgpu_cs_parser *p)
 
 	amdgpu_vm_get_pt_bos(&fpriv->vm, &duplicates);
 
-	r = amdgpu_cs_list_validate(p->adev, &fpriv->vm, &duplicates);
+	p->bytes_moved_threshold = amdgpu_cs_get_threshold_for_moves(p->adev);
+	p->bytes_moved = 0;
+
+	r = amdgpu_cs_list_validate(p, &duplicates);
 	if (r)
 		goto error_validate;
 
-	r = amdgpu_cs_list_validate(p->adev, &fpriv->vm, &p->validated);
+	r = amdgpu_cs_list_validate(p, &p->validated);
 
 error_validate:
 	if (r) {

commit 28b8d66e0c1cc6c02b8159ae44aec359e12feefa
Author: Nicolai Hähnle <nicolai.haehnle@amd.com>
Date:   Wed Jan 27 11:04:19 2016 -0500

    drm/amdgpu: only move pt bos in LRU list on success
    
    This fixes a race condition in the error case: since the pt bos have not
    necessarily been reserved in case of an error, we could move a pt bo that
    is currently in the middle of being evicted/moved by another process,
    which then resulted in a BUG_ON in ttm_bo_add_to_lru.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Nicolai Hähnle <nicolai.haehnle@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 6f89f8e034d0..b882e8175615 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -478,9 +478,9 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
 	struct amdgpu_fpriv *fpriv = parser->filp->driver_priv;
 	unsigned i;
 
-	amdgpu_vm_move_pt_bos_in_lru(parser->adev, &fpriv->vm);
-
 	if (!error) {
+		amdgpu_vm_move_pt_bos_in_lru(parser->adev, &fpriv->vm);
+
 		/* Sort the buffer list from the smallest to largest buffer,
 		 * which affects the order of buffers in the LRU list.
 		 * This assures that the smallest buffers are added first

commit d8e0cae645504a787b05abfb91afee8cd7fa1701
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jan 11 15:35:22 2016 +0100

    drm/amdgpu: validate duplicates first
    
    Most VM BOs end up in the duplicates list, validate it
    first make -ENOMEM less likely.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <David1.Zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 1fffc338f69d..6f89f8e034d0 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -421,11 +421,11 @@ static int amdgpu_cs_parser_relocs(struct amdgpu_cs_parser *p)
 
 	amdgpu_vm_get_pt_bos(&fpriv->vm, &duplicates);
 
-	r = amdgpu_cs_list_validate(p->adev, &fpriv->vm, &p->validated);
+	r = amdgpu_cs_list_validate(p->adev, &fpriv->vm, &duplicates);
 	if (r)
 		goto error_validate;
 
-	r = amdgpu_cs_list_validate(p->adev, &fpriv->vm, &duplicates);
+	r = amdgpu_cs_list_validate(p->adev, &fpriv->vm, &p->validated);
 
 error_validate:
 	if (r) {

commit eceb8a1562db6fc3e1c21cd54a4be0189aa1d0e3
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jan 11 15:35:21 2016 +0100

    drm/amdgpu: move VM page tables to the LRU end on CS v2
    
    This makes it less likely to run into an ENOMEM because
    VM page tables are evicted last.
    
    v2: move the BOs in the LRU tail after validation
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index ce0254d4dcd7..1fffc338f69d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -428,8 +428,10 @@ static int amdgpu_cs_parser_relocs(struct amdgpu_cs_parser *p)
 	r = amdgpu_cs_list_validate(p->adev, &fpriv->vm, &duplicates);
 
 error_validate:
-	if (r)
+	if (r) {
+		amdgpu_vm_move_pt_bos_in_lru(p->adev, &fpriv->vm);
 		ttm_eu_backoff_reservation(&p->ticket, &p->validated);
+	}
 
 error_reserve:
 	if (need_mmap_lock)
@@ -473,8 +475,11 @@ static int cmp_size_smaller_first(void *priv, struct list_head *a,
  **/
 static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bool backoff)
 {
+	struct amdgpu_fpriv *fpriv = parser->filp->driver_priv;
 	unsigned i;
 
+	amdgpu_vm_move_pt_bos_in_lru(parser->adev, &fpriv->vm);
+
 	if (!error) {
 		/* Sort the buffer list from the smallest to largest buffer,
 		 * which affects the order of buffers in the LRU list.

commit 20f8e032e6dc7053ab803f488e2a8839cd2f69a6
Merge: ade1ba734607 5b726e06d6e8
Author: Dave Airlie <airlied@redhat.com>
Date:   Thu Dec 24 08:08:47 2015 +1000

    Backmerge drm-fixes merge into Linus's tree into drm-next.
    
    This merges '5b726e06d6e8309e5c9ef4109a32caf27c71dfc8' into drm-next
    
    Just to resolve some merges to make Daniel's life easier.
    
    Signed-off-by: DAve Airlie <airlied@redhat.com>

commit fd3e14ffbd9ec7593ba4dafc9452a91373a4df05
Merge: 911619953687 eafbbd9883d0
Author: Dave Airlie <airlied@redhat.com>
Date:   Wed Dec 23 14:15:26 2015 +1000

    Merge branch 'drm-next-4.5' of git://people.freedesktop.org/~agd5f/linux into drm-next
    
    [airlied: fixup build problems on arm - added errno.h include]
    * 'drm-next-4.5' of git://people.freedesktop.org/~agd5f/linux: (152 commits)
      amd/powerplay: fix copy paste typo in hardwaremanager.c
      amd/powerplay: disable powerplay by default initially
      amd/powerplay: don't enable ucode fan control if vbios has no fan table
      drm/amd/powerplay: show gpu load when print gpu performance for Cz. (v2)
      drm/amd/powerplay: check whether need to enable thermal control. (v2)
      drm/amd/powerplay: add point check to avoid NULL point hang.
      drm/amdgpu/powerplay: Program a calculated value as Deep Sleep clock.
      drm/amd/powerplay: Don't return an error if fan table is missing
      drm/powerplay/hwmgr: log errors in tonga_hwmgr_backend_init
      drm/powerplay: add debugging output to processpptables.c
      drm/powerplay: add debugging output to tonga_processpptables.c
      amd/powerplay: Add structures required to report configuration change
      amd/powerplay: Fix get dal power level
      amd\powerplay Implement get dal power level
      drm/amd/powerplay: display gpu load when print performance for tonga.
      drm/amdgpu/powerplay: enable sysfs and debugfs interfaces late
      drm/amd/powerplay: move shared function of vi to hwmgr. (v2)
      drm/amd/powerplay: check whether enable dpm in powerplay.
      drm/amd/powerplay: fix bug that dpm funcs in debugfs/sysfs missing.
      drm/amd/powerplay: fix boolreturn.cocci warnings
      ...

commit ee1782c3f27fec5462363af48f27811b049155ab
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Dec 11 21:01:23 2015 +0100

    drm/amdgpu: keep the PTs validation list in the VM v2
    
    This avoids allocating it on the fly.
    
    v2: fix grammar in comment
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 3fb21ecd29e0..6ce595ff1aff 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -396,11 +396,7 @@ static int amdgpu_cs_parser_relocs(struct amdgpu_cs_parser *p)
 	if (unlikely(r != 0))
 		goto error_reserve;
 
-	p->vm_bos = amdgpu_vm_get_pt_bos(&fpriv->vm, &duplicates);
-	if (!p->vm_bos) {
-		r = -ENOMEM;
-		goto error_validate;
-	}
+	amdgpu_vm_get_pt_bos(&fpriv->vm, &duplicates);
 
 	r = amdgpu_cs_list_validate(p->adev, &fpriv->vm, &p->validated);
 	if (r)
@@ -483,7 +479,6 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
 	if (parser->bo_list)
 		amdgpu_bo_list_put(parser->bo_list);
 
-	drm_free_large(parser->vm_bos);
 	for (i = 0; i < parser->nchunks; i++)
 		drm_free_large(parser->chunks[i].kdata);
 	kfree(parser->chunks);

commit 56467ebfb254836dc30eb45d4ac8a46a400bfad6
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Dec 11 15:16:32 2015 +0100

    drm/amdgpu: split VM PD and PT handling during CS
    
    This way we avoid the extra allocation for the page directory entry.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 9591c13781bd..3fb21ecd29e0 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -387,8 +387,7 @@ static int amdgpu_cs_parser_relocs(struct amdgpu_cs_parser *p)
 	}
 
 	INIT_LIST_HEAD(&duplicates);
-	p->vm_bos = amdgpu_vm_get_bos(p->adev, &fpriv->vm,
-				      &p->validated, &duplicates);
+	amdgpu_vm_get_pd_bo(&fpriv->vm, &p->validated, &p->vm_pd);
 
 	if (need_mmap_lock)
 		down_read(&current->mm->mmap_sem);
@@ -397,6 +396,12 @@ static int amdgpu_cs_parser_relocs(struct amdgpu_cs_parser *p)
 	if (unlikely(r != 0))
 		goto error_reserve;
 
+	p->vm_bos = amdgpu_vm_get_pt_bos(&fpriv->vm, &duplicates);
+	if (!p->vm_bos) {
+		r = -ENOMEM;
+		goto error_validate;
+	}
+
 	r = amdgpu_cs_list_validate(p->adev, &fpriv->vm, &p->validated);
 	if (r)
 		goto error_validate;

commit 3c0eea6c35d932c4d25070868067dc9cd9ceab91
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Dec 11 14:39:05 2015 +0100

    drm/amdgpu: put VM page tables directly into duplicates list
    
    They share the reservation object with the page directory anyway.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 1d44d508d4d4..9591c13781bd 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -386,13 +386,13 @@ static int amdgpu_cs_parser_relocs(struct amdgpu_cs_parser *p)
 		amdgpu_cs_buckets_get_list(&buckets, &p->validated);
 	}
 
+	INIT_LIST_HEAD(&duplicates);
 	p->vm_bos = amdgpu_vm_get_bos(p->adev, &fpriv->vm,
-				      &p->validated);
+				      &p->validated, &duplicates);
 
 	if (need_mmap_lock)
 		down_read(&current->mm->mmap_sem);
 
-	INIT_LIST_HEAD(&duplicates);
 	r = ttm_eu_reserve_buffers(&p->ticket, &p->validated, true, &duplicates);
 	if (unlikely(r != 0))
 		goto error_reserve;

commit 91acbeb68ab10c0c0f65f30b5b7fddbde4c97dd2
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Dec 14 16:42:31 2015 +0100

    drm/amdgpu: fix user fence handling
    
    This fixes a random corruption under memory pressure. We need to fence
    the BO for the user fence as well, otherwise it might be swapped out
    and the GPU could write the fence value to an undesired location.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 4f352ec9dec4..25a3e2485cc2 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -127,6 +127,37 @@ int amdgpu_cs_get_ring(struct amdgpu_device *adev, u32 ip_type,
 	return 0;
 }
 
+static int amdgpu_cs_user_fence_chunk(struct amdgpu_cs_parser *p,
+				      struct drm_amdgpu_cs_chunk_fence *fence_data)
+{
+	struct drm_gem_object *gobj;
+	uint32_t handle;
+
+	handle = fence_data->handle;
+	gobj = drm_gem_object_lookup(p->adev->ddev, p->filp,
+				     fence_data->handle);
+	if (gobj == NULL)
+		return -EINVAL;
+
+	p->uf.bo = amdgpu_bo_ref(gem_to_amdgpu_bo(gobj));
+	p->uf.offset = fence_data->offset;
+
+	if (amdgpu_ttm_tt_has_userptr(p->uf.bo->tbo.ttm)) {
+		drm_gem_object_unreference_unlocked(gobj);
+		return -EINVAL;
+	}
+
+	p->uf_entry.robj = amdgpu_bo_ref(p->uf.bo);
+	p->uf_entry.prefered_domains = AMDGPU_GEM_DOMAIN_GTT;
+	p->uf_entry.allowed_domains = AMDGPU_GEM_DOMAIN_GTT;
+	p->uf_entry.priority = 0;
+	p->uf_entry.tv.bo = &p->uf_entry.robj->tbo;
+	p->uf_entry.tv.shared = true;
+
+	drm_gem_object_unreference_unlocked(gobj);
+	return 0;
+}
+
 int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 {
 	union drm_amdgpu_cs *cs = data;
@@ -207,28 +238,15 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 
 		case AMDGPU_CHUNK_ID_FENCE:
 			size = sizeof(struct drm_amdgpu_cs_chunk_fence);
-			if (p->chunks[i].length_dw * sizeof(uint32_t) >= size) {
-				uint32_t handle;
-				struct drm_gem_object *gobj;
-				struct drm_amdgpu_cs_chunk_fence *fence_data;
-
-				fence_data = (void *)p->chunks[i].kdata;
-				handle = fence_data->handle;
-				gobj = drm_gem_object_lookup(p->adev->ddev,
-							     p->filp, handle);
-				if (gobj == NULL) {
-					ret = -EINVAL;
-					goto free_partial_kdata;
-				}
-
-				p->uf.bo = gem_to_amdgpu_bo(gobj);
-				amdgpu_bo_ref(p->uf.bo);
-				drm_gem_object_unreference_unlocked(gobj);
-				p->uf.offset = fence_data->offset;
-			} else {
+			if (p->chunks[i].length_dw * sizeof(uint32_t) < size) {
 				ret = -EINVAL;
 				goto free_partial_kdata;
 			}
+
+			ret = amdgpu_cs_user_fence_chunk(p, (void *)p->chunks[i].kdata);
+			if (ret)
+				goto free_partial_kdata;
+
 			break;
 
 		case AMDGPU_CHUNK_ID_DEPENDENCIES:
@@ -391,6 +409,9 @@ static int amdgpu_cs_parser_relocs(struct amdgpu_cs_parser *p)
 	p->vm_bos = amdgpu_vm_get_bos(p->adev, &fpriv->vm,
 				      &p->validated);
 
+	if (p->uf.bo)
+		list_add(&p->uf_entry.tv.head, &p->validated);
+
 	if (need_mmap_lock)
 		down_read(&current->mm->mmap_sem);
 
@@ -488,8 +509,8 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
 		for (i = 0; i < parser->num_ibs; i++)
 			amdgpu_ib_free(parser->adev, &parser->ibs[i]);
 	kfree(parser->ibs);
-	if (parser->uf.bo)
-		amdgpu_bo_unref(&parser->uf.bo);
+	amdgpu_bo_unref(&parser->uf.bo);
+	amdgpu_bo_unref(&parser->uf_entry.robj);
 }
 
 static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,

commit f3f1769283b8dbf047c678da95b72194ac2477a1
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Dec 3 19:55:52 2015 +0100

    drm/amdgpu: take a BO reference for the user fence
    
    No need for a GEM reference here.
    
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 1d44d508d4d4..4f352ec9dec4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -222,6 +222,8 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 				}
 
 				p->uf.bo = gem_to_amdgpu_bo(gobj);
+				amdgpu_bo_ref(p->uf.bo);
+				drm_gem_object_unreference_unlocked(gobj);
 				p->uf.offset = fence_data->offset;
 			} else {
 				ret = -EINVAL;
@@ -487,7 +489,7 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
 			amdgpu_ib_free(parser->adev, &parser->ibs[i]);
 	kfree(parser->ibs);
 	if (parser->uf.bo)
-		drm_gem_object_unreference_unlocked(&parser->uf.bo->gem_base);
+		amdgpu_bo_unref(&parser->uf.bo);
 }
 
 static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
@@ -776,7 +778,7 @@ static int amdgpu_cs_free_job(struct amdgpu_job *job)
 			amdgpu_ib_free(job->adev, &job->ibs[i]);
 	kfree(job->ibs);
 	if (job->uf.bo)
-		drm_gem_object_unreference_unlocked(&job->uf.bo->gem_base);
+		amdgpu_bo_unref(&job->uf.bo);
 	return 0;
 }
 

commit e98c1b0de6fe73f488df62d83d83f377b1b6e2b8
Author: Chunming Zhou <David1.Zhou@amd.com>
Date:   Fri Nov 13 15:22:04 2015 +0800

    drm/amdgpu: remove vm->mutex
    
    Signed-off-by: Chunming Zhou <David1.Zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 3afcf0237c25..1d44d508d4d4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -784,8 +784,6 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 {
 	struct amdgpu_device *adev = dev->dev_private;
 	union drm_amdgpu_cs *cs = data;
-	struct amdgpu_fpriv *fpriv = filp->driver_priv;
-	struct amdgpu_vm *vm = &fpriv->vm;
 	struct amdgpu_cs_parser parser = {};
 	bool reserved_buffers = false;
 	int i, r;
@@ -803,7 +801,6 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		r = amdgpu_cs_handle_lockup(adev, r);
 		return r;
 	}
-	mutex_lock(&vm->mutex);
 	r = amdgpu_cs_parser_relocs(&parser);
 	if (r == -ENOMEM)
 		DRM_ERROR("Not enough memory for command submission!\n");
@@ -888,7 +885,6 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 out:
 	amdgpu_cs_parser_fini(&parser, r, reserved_buffers);
-	mutex_unlock(&vm->mutex);
 	r = amdgpu_cs_handle_lockup(adev, r);
 	return r;
 }

commit 984810fc45389c545719fbb4219e8a12b27032a4
Author: Christian König <christian.koenig@amd.com>
Date:   Sat Nov 14 21:05:35 2015 +0100

    drm/amdgpu: cleanup scheduler command submission
    
    Unify the two code path again, cause they do pretty much the same thing.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <davdi1.zhou@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 6096effd6a56..3afcf0237c25 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -439,8 +439,18 @@ static int cmp_size_smaller_first(void *priv, struct list_head *a,
 	return (int)la->robj->tbo.num_pages - (int)lb->robj->tbo.num_pages;
 }
 
-static void amdgpu_cs_parser_fini_early(struct amdgpu_cs_parser *parser, int error, bool backoff)
+/**
+ * cs_parser_fini() - clean parser states
+ * @parser:	parser structure holding parsing context.
+ * @error:	error number
+ *
+ * If error is set than unvalidate buffer, otherwise just free memory
+ * used by parsing context.
+ **/
+static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bool backoff)
 {
+	unsigned i;
+
 	if (!error) {
 		/* Sort the buffer list from the smallest to largest buffer,
 		 * which affects the order of buffers in the LRU list.
@@ -455,17 +465,13 @@ static void amdgpu_cs_parser_fini_early(struct amdgpu_cs_parser *parser, int err
 		list_sort(NULL, &parser->validated, cmp_size_smaller_first);
 
 		ttm_eu_fence_buffer_objects(&parser->ticket,
-				&parser->validated,
-				&parser->ibs[parser->num_ibs-1].fence->base);
+					    &parser->validated,
+					    parser->fence);
 	} else if (backoff) {
 		ttm_eu_backoff_reservation(&parser->ticket,
 					   &parser->validated);
 	}
-}
-
-static void amdgpu_cs_parser_fini_late(struct amdgpu_cs_parser *parser)
-{
-	unsigned i;
+	fence_put(parser->fence);
 
 	if (parser->ctx)
 		amdgpu_ctx_put(parser->ctx);
@@ -484,20 +490,6 @@ static void amdgpu_cs_parser_fini_late(struct amdgpu_cs_parser *parser)
 		drm_gem_object_unreference_unlocked(&parser->uf.bo->gem_base);
 }
 
-/**
- * cs_parser_fini() - clean parser states
- * @parser:	parser structure holding parsing context.
- * @error:	error number
- *
- * If error is set than unvalidate buffer, otherwise just free memory
- * used by parsing context.
- **/
-static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bool backoff)
-{
-       amdgpu_cs_parser_fini_early(parser, error, backoff);
-       amdgpu_cs_parser_fini_late(parser);
-}
-
 static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 				   struct amdgpu_vm *vm)
 {
@@ -582,15 +574,9 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 	}
 
 	r = amdgpu_bo_vm_update_pte(parser, vm);
-	if (r) {
-		goto out;
-	}
-	amdgpu_cs_sync_rings(parser);
-	if (!amdgpu_enable_scheduler)
-		r = amdgpu_ib_schedule(adev, parser->num_ibs, parser->ibs,
-				       parser->filp);
+	if (!r)
+		amdgpu_cs_sync_rings(parser);
 
-out:
 	return r;
 }
 
@@ -881,7 +867,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 			goto out;
 		}
 		job->base.s_fence = fence;
-		fence_get(&fence->base);
+		parser.fence = fence_get(&fence->base);
 
 		cs->out.handle = amdgpu_ctx_add_fence(parser.ctx, ring,
 						      &fence->base);
@@ -890,17 +876,16 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		trace_amdgpu_cs_ioctl(job);
 		amd_sched_entity_push_job(&job->base);
 
-		list_sort(NULL, &parser.validated, cmp_size_smaller_first);
-		ttm_eu_fence_buffer_objects(&parser.ticket, &parser.validated,
-					    &fence->base);
-		fence_put(&fence->base);
+	} else {
+		struct amdgpu_fence *fence;
 
-		amdgpu_cs_parser_fini_late(&parser);
-		mutex_unlock(&vm->mutex);
-		return 0;
+		r = amdgpu_ib_schedule(adev, parser.num_ibs, parser.ibs,
+				       parser.filp);
+		fence = parser.ibs[parser.num_ibs - 1].fence;
+		parser.fence = fence_get(&fence->base);
+		cs->out.handle = parser.ibs[parser.num_ibs - 1].sequence;
 	}
 
-	cs->out.handle = parser.ibs[parser.num_ibs - 1].sequence;
 out:
 	amdgpu_cs_parser_fini(&parser, r, reserved_buffers);
 	mutex_unlock(&vm->mutex);

commit 5d82730af746abca2aa74e00de6370d338df7e95
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Nov 13 13:04:50 2015 +0100

    drm/amdgpu: fix handling order in scheduler CS
    
    We need to clear parser.ibs and num_ibs before amd_sched_fence_create,
    otherwise the IB could be freed twice if fence creates fails.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 44cf977ae4f6..6096effd6a56 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -858,11 +858,14 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		job->base.sched = &ring->sched;
 		job->base.s_entity = &parser.ctx->rings[ring->idx].entity;
 		job->adev = parser.adev;
-		job->ibs = parser.ibs;
-		job->num_ibs = parser.num_ibs;
 		job->owner = parser.filp;
 		job->free_job = amdgpu_cs_free_job;
 
+		job->ibs = parser.ibs;
+		job->num_ibs = parser.num_ibs;
+		parser.ibs = NULL;
+		parser.num_ibs = 0;
+
 		if (job->ibs[job->num_ibs - 1].user) {
 			job->uf = parser.uf;
 			job->ibs[job->num_ibs - 1].user = &job->uf;
@@ -884,9 +887,6 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 						      &fence->base);
 		job->ibs[job->num_ibs - 1].sequence = cs->out.handle;
 
-		parser.ibs = NULL;
-		parser.num_ibs = 0;
-
 		trace_amdgpu_cs_ioctl(job);
 		amd_sched_entity_push_job(&job->base);
 

commit e284022163716ecf11c37fd1057c35d689ef2c11
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Nov 5 19:49:48 2015 +0100

    drm/amdgpu: fix incorrect mutex usage v3
    
    Before this patch the scheduler fence was created when we push the job
    into the queue, so we could only get the fence after pushing it.
    
    The mutex now was necessary to prevent the thread pushing the jobs to
    the hardware from running faster than the thread pushing the jobs into
    the queue.
    
    Otherwise the thread pushing jobs into the queue would have accessed
    possible freed up memory when it tries to get a reference to the fence.
    
    So what you get in the end is thread A:
    mutex_lock(&job->lock);
    ...
    Kick of thread B.
    ...
    mutex_unlock(&job->lock);
    
    And thread B:
    mutex_lock(&job->lock);
    ....
    mutex_unlock(&job->lock);
    kfree(job);
    
    I'm actually not sure if I'm still up to date on this, but this usage
    pattern used to be not allowed with mutexes. See here as well
    https://lwn.net/Articles/575460/.
    
    v2: remove unrelated changes, fix missing owner
    v3: rebased, add more commit message
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 2ae73d5232dd..44cf977ae4f6 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -845,8 +845,9 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		goto out;
 
 	if (amdgpu_enable_scheduler && parser.num_ibs) {
-		struct amdgpu_job *job;
 		struct amdgpu_ring * ring = parser.ibs->ring;
+		struct amd_sched_fence *fence;
+		struct amdgpu_job *job;
 
 		job = kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
 		if (!job) {
@@ -859,37 +860,41 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		job->adev = parser.adev;
 		job->ibs = parser.ibs;
 		job->num_ibs = parser.num_ibs;
-		job->base.owner = parser.filp;
-		mutex_init(&job->job_lock);
+		job->owner = parser.filp;
+		job->free_job = amdgpu_cs_free_job;
+
 		if (job->ibs[job->num_ibs - 1].user) {
 			job->uf = parser.uf;
 			job->ibs[job->num_ibs - 1].user = &job->uf;
 			parser.uf.bo = NULL;
 		}
 
-		parser.ibs = NULL;
-		parser.num_ibs = 0;
-
-		job->free_job = amdgpu_cs_free_job;
-		mutex_lock(&job->job_lock);
-		r = amd_sched_entity_push_job(&job->base);
-		if (r) {
-			mutex_unlock(&job->job_lock);
+		fence = amd_sched_fence_create(job->base.s_entity,
+					       parser.filp);
+		if (!fence) {
+			r = -ENOMEM;
 			amdgpu_cs_free_job(job);
 			kfree(job);
 			goto out;
 		}
-		cs->out.handle =
-			amdgpu_ctx_add_fence(parser.ctx, ring,
-					     &job->base.s_fence->base);
+		job->base.s_fence = fence;
+		fence_get(&fence->base);
+
+		cs->out.handle = amdgpu_ctx_add_fence(parser.ctx, ring,
+						      &fence->base);
 		job->ibs[job->num_ibs - 1].sequence = cs->out.handle;
 
-		list_sort(NULL, &parser.validated, cmp_size_smaller_first);
-		ttm_eu_fence_buffer_objects(&parser.ticket,
-				&parser.validated,
-				&job->base.s_fence->base);
+		parser.ibs = NULL;
+		parser.num_ibs = 0;
+
 		trace_amdgpu_cs_ioctl(job);
-		mutex_unlock(&job->job_lock);
+		amd_sched_entity_push_job(&job->base);
+
+		list_sort(NULL, &parser.validated, cmp_size_smaller_first);
+		ttm_eu_fence_buffer_objects(&parser.ticket, &parser.validated,
+					    &fence->base);
+		fence_put(&fence->base);
+
 		amdgpu_cs_parser_fini_late(&parser);
 		mutex_unlock(&vm->mutex);
 		return 0;

commit 7034decf6a5b1ff778d83ff9d7ce1f0b404804e4
Author: Chunming Zhou <David1.Zhou@amd.com>
Date:   Wed Nov 11 14:56:00 2015 +0800

    drm/amdgpu: add command submission workflow tracepoint
    
    OGL needs these tracepoints to investigate performance issue.
    
    Change-Id: I5e58187d061253f7d665dfce8e4e163ba91d3e2b
    Signed-off-by: Chunming Zhou <David1.Zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index bf32096b8eb7..2ae73d5232dd 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -888,7 +888,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		ttm_eu_fence_buffer_objects(&parser.ticket,
 				&parser.validated,
 				&job->base.s_fence->base);
-
+		trace_amdgpu_cs_ioctl(job);
 		mutex_unlock(&job->job_lock);
 		amdgpu_cs_parser_fini_late(&parser);
 		mutex_unlock(&vm->mutex);

commit 7e52a81c2f0326a85d3ebc005829bcd604731c6d
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Nov 4 15:44:39 2015 +0100

    drm/amdgpu: cleanup amdgpu_cs_parser handling
    
    No need any more to allocate that structure dynamically, just put it on the
    stack. This is a start to cleanup some of the scheduler fallouts.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index ecc82dfe83f8..bf32096b8eb7 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -127,30 +127,6 @@ int amdgpu_cs_get_ring(struct amdgpu_device *adev, u32 ip_type,
 	return 0;
 }
 
-struct amdgpu_cs_parser *amdgpu_cs_parser_create(struct amdgpu_device *adev,
-                                               struct drm_file *filp,
-                                               struct amdgpu_ctx *ctx,
-                                               struct amdgpu_ib *ibs,
-                                               uint32_t num_ibs)
-{
-	struct amdgpu_cs_parser *parser;
-	int i;
-
-	parser = kzalloc(sizeof(struct amdgpu_cs_parser), GFP_KERNEL);
-	if (!parser)
-		return NULL;
-
-	parser->adev = adev;
-	parser->filp = filp;
-	parser->ctx = ctx;
-	parser->ibs = ibs;
-	parser->num_ibs = num_ibs;
-	for (i = 0; i < num_ibs; i++)
-		ibs[i].ctx = ctx;
-
-	return parser;
-}
-
 int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 {
 	union drm_amdgpu_cs *cs = data;
@@ -490,6 +466,7 @@ static void amdgpu_cs_parser_fini_early(struct amdgpu_cs_parser *parser, int err
 static void amdgpu_cs_parser_fini_late(struct amdgpu_cs_parser *parser)
 {
 	unsigned i;
+
 	if (parser->ctx)
 		amdgpu_ctx_put(parser->ctx);
 	if (parser->bo_list)
@@ -505,7 +482,6 @@ static void amdgpu_cs_parser_fini_late(struct amdgpu_cs_parser *parser)
 	kfree(parser->ibs);
 	if (parser->uf.bo)
 		drm_gem_object_unreference_unlocked(&parser->uf.bo->gem_base);
-	kfree(parser);
 }
 
 /**
@@ -824,36 +800,36 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	union drm_amdgpu_cs *cs = data;
 	struct amdgpu_fpriv *fpriv = filp->driver_priv;
 	struct amdgpu_vm *vm = &fpriv->vm;
-	struct amdgpu_cs_parser *parser;
+	struct amdgpu_cs_parser parser = {};
 	bool reserved_buffers = false;
 	int i, r;
 
 	if (!adev->accel_working)
 		return -EBUSY;
 
-	parser = amdgpu_cs_parser_create(adev, filp, NULL, NULL, 0);
-	if (!parser)
-		return -ENOMEM;
-	r = amdgpu_cs_parser_init(parser, data);
+	parser.adev = adev;
+	parser.filp = filp;
+
+	r = amdgpu_cs_parser_init(&parser, data);
 	if (r) {
 		DRM_ERROR("Failed to initialize parser !\n");
-		amdgpu_cs_parser_fini(parser, r, false);
+		amdgpu_cs_parser_fini(&parser, r, false);
 		r = amdgpu_cs_handle_lockup(adev, r);
 		return r;
 	}
 	mutex_lock(&vm->mutex);
-	r = amdgpu_cs_parser_relocs(parser);
+	r = amdgpu_cs_parser_relocs(&parser);
 	if (r == -ENOMEM)
 		DRM_ERROR("Not enough memory for command submission!\n");
 	else if (r && r != -ERESTARTSYS)
 		DRM_ERROR("Failed to process the buffer list %d!\n", r);
 	else if (!r) {
 		reserved_buffers = true;
-		r = amdgpu_cs_ib_fill(adev, parser);
+		r = amdgpu_cs_ib_fill(adev, &parser);
 	}
 
 	if (!r) {
-		r = amdgpu_cs_dependencies(adev, parser);
+		r = amdgpu_cs_dependencies(adev, &parser);
 		if (r)
 			DRM_ERROR("Failed in the dependencies handling %d!\n", r);
 	}
@@ -861,36 +837,38 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	if (r)
 		goto out;
 
-	for (i = 0; i < parser->num_ibs; i++)
-		trace_amdgpu_cs(parser, i);
+	for (i = 0; i < parser.num_ibs; i++)
+		trace_amdgpu_cs(&parser, i);
 
-	r = amdgpu_cs_ib_vm_chunk(adev, parser);
+	r = amdgpu_cs_ib_vm_chunk(adev, &parser);
 	if (r)
 		goto out;
 
-	if (amdgpu_enable_scheduler && parser->num_ibs) {
+	if (amdgpu_enable_scheduler && parser.num_ibs) {
 		struct amdgpu_job *job;
-		struct amdgpu_ring * ring =  parser->ibs->ring;
+		struct amdgpu_ring * ring = parser.ibs->ring;
+
 		job = kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
 		if (!job) {
 			r = -ENOMEM;
 			goto out;
 		}
+
 		job->base.sched = &ring->sched;
-		job->base.s_entity = &parser->ctx->rings[ring->idx].entity;
-		job->adev = parser->adev;
-		job->ibs = parser->ibs;
-		job->num_ibs = parser->num_ibs;
-		job->base.owner = parser->filp;
+		job->base.s_entity = &parser.ctx->rings[ring->idx].entity;
+		job->adev = parser.adev;
+		job->ibs = parser.ibs;
+		job->num_ibs = parser.num_ibs;
+		job->base.owner = parser.filp;
 		mutex_init(&job->job_lock);
 		if (job->ibs[job->num_ibs - 1].user) {
-			job->uf = parser->uf;
+			job->uf = parser.uf;
 			job->ibs[job->num_ibs - 1].user = &job->uf;
-			parser->uf.bo = NULL;
+			parser.uf.bo = NULL;
 		}
 
-		parser->ibs = NULL;
-		parser->num_ibs = 0;
+		parser.ibs = NULL;
+		parser.num_ibs = 0;
 
 		job->free_job = amdgpu_cs_free_job;
 		mutex_lock(&job->job_lock);
@@ -902,24 +880,24 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 			goto out;
 		}
 		cs->out.handle =
-			amdgpu_ctx_add_fence(parser->ctx, ring,
+			amdgpu_ctx_add_fence(parser.ctx, ring,
 					     &job->base.s_fence->base);
 		job->ibs[job->num_ibs - 1].sequence = cs->out.handle;
 
-		list_sort(NULL, &parser->validated, cmp_size_smaller_first);
-		ttm_eu_fence_buffer_objects(&parser->ticket,
-				&parser->validated,
+		list_sort(NULL, &parser.validated, cmp_size_smaller_first);
+		ttm_eu_fence_buffer_objects(&parser.ticket,
+				&parser.validated,
 				&job->base.s_fence->base);
 
 		mutex_unlock(&job->job_lock);
-		amdgpu_cs_parser_fini_late(parser);
+		amdgpu_cs_parser_fini_late(&parser);
 		mutex_unlock(&vm->mutex);
 		return 0;
 	}
 
-	cs->out.handle = parser->ibs[parser->num_ibs - 1].sequence;
+	cs->out.handle = parser.ibs[parser.num_ibs - 1].sequence;
 out:
-	amdgpu_cs_parser_fini(parser, r, reserved_buffers);
+	amdgpu_cs_parser_fini(&parser, r, reserved_buffers);
 	mutex_unlock(&vm->mutex);
 	r = amdgpu_cs_handle_lockup(adev, r);
 	return r;

commit e4a58a28b50f30e72292b6659d94410cbf7355ad
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Nov 5 17:00:25 2015 +0100

    drm/amdgpu: fix leaking the IBs on error
    
    Fixing a memory leak when the scheduler is enabled.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index dfc4d02c7a38..ecc82dfe83f8 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -499,16 +499,12 @@ static void amdgpu_cs_parser_fini_late(struct amdgpu_cs_parser *parser)
 	for (i = 0; i < parser->nchunks; i++)
 		drm_free_large(parser->chunks[i].kdata);
 	kfree(parser->chunks);
-	if (!amdgpu_enable_scheduler)
-	{
-		if (parser->ibs)
-			for (i = 0; i < parser->num_ibs; i++)
-				amdgpu_ib_free(parser->adev, &parser->ibs[i]);
-		kfree(parser->ibs);
-		if (parser->uf.bo)
-			drm_gem_object_unreference_unlocked(&parser->uf.bo->gem_base);
-	}
-
+	if (parser->ibs)
+		for (i = 0; i < parser->num_ibs; i++)
+			amdgpu_ib_free(parser->adev, &parser->ibs[i]);
+	kfree(parser->ibs);
+	if (parser->uf.bo)
+		drm_gem_object_unreference_unlocked(&parser->uf.bo->gem_base);
 	kfree(parser);
 }
 
@@ -888,11 +884,14 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		job->base.owner = parser->filp;
 		mutex_init(&job->job_lock);
 		if (job->ibs[job->num_ibs - 1].user) {
-			memcpy(&job->uf,  &parser->uf,
-			       sizeof(struct amdgpu_user_fence));
+			job->uf = parser->uf;
 			job->ibs[job->num_ibs - 1].user = &job->uf;
+			parser->uf.bo = NULL;
 		}
 
+		parser->ibs = NULL;
+		parser->num_ibs = 0;
+
 		job->free_job = amdgpu_cs_free_job;
 		mutex_lock(&job->job_lock);
 		r = amd_sched_entity_push_job(&job->base);
@@ -905,7 +904,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		cs->out.handle =
 			amdgpu_ctx_add_fence(parser->ctx, ring,
 					     &job->base.s_fence->base);
-		parser->ibs[parser->num_ibs - 1].sequence = cs->out.handle;
+		job->ibs[job->num_ibs - 1].sequence = cs->out.handle;
 
 		list_sort(NULL, &parser->validated, cmp_size_smaller_first);
 		ttm_eu_fence_buffer_objects(&parser->ticket,

commit 793423ffcb229ae5654b382a1356906f81da2018
Merge: bf248ca1f5c7 a95e264254dc
Author: Dave Airlie <airlied@redhat.com>
Date:   Thu Nov 5 10:57:25 2015 +1000

    Merge branch 'drm-next-4.4' of git://people.freedesktop.org/~agd5f/linux into drm-next
    
    - Updated register headers for GFX 8.1 for Stoney
    - Add some new CZ revisions
    - minor pageflip optimizations
    - Fencing clean up
    - Warning fix
    - More fence cleanup
    - oops fix
    - Fiji fixes
    
    * 'drm-next-4.4' of git://people.freedesktop.org/~agd5f/linux: (29 commits)
      drm/amdgpu: group together common fence implementation
      drm/amdgpu: remove AMDGPU_FENCE_OWNER_MOVE
      drm/amdgpu: remove now unused fence functions
      drm/amdgpu: fix fence fallback check
      drm/amdgpu: fix stoping the scheduler timeout
      drm/amdgpu: cleanup on error in amdgpu_cs_ioctl()
      drm/amdgpu: update Fiji's Golden setting
      drm/amdgpu: update Fiji's rev id
      drm/amdgpu: extract common code in vi_common_early_init
      drm/amd/scheduler: don't oops on failure to load
      drm/amdgpu: don't oops on failure to load (v2)
      drm/amdgpu: don't VT switch on suspend
      drm/amdgpu: Make amdgpu_mn functions inline
      drm/amdgpu: remove amdgpu_fence_ref/unref
      drm/amdgpu: use common fence for sync
      drm/amdgpu: use the new fence_is_later
      drm/amdgpu: use common fences for VMID management v2
      drm/amdgpu: move ring_from_fence to common code
      drm/amdgpu: switch to common fence_wait_any_timeout v2
      drm/amdgpu: remove unneeded fence functions
      ...

commit 4cfdcd9cecc05646b08805ba449811a645b3f4a8
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Wed Nov 4 16:25:09 2015 +0300

    drm/amdgpu: cleanup on error in amdgpu_cs_ioctl()
    
    We recently changed the locking in this function and now there is a
    missing unlock on error.  Also there are some other resources that we
    should probably release as well...
    
    Fixes: f48b2659f521 ('drm/amdgpu: fix the broken vm->mutex V2')
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 8727c3099554..233ac9c64eb3 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -875,8 +875,10 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		struct amdgpu_job *job;
 		struct amdgpu_ring * ring =  parser->ibs->ring;
 		job = kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
-		if (!job)
-			return -ENOMEM;
+		if (!job) {
+			r = -ENOMEM;
+			goto out;
+		}
 		job->base.sched = &ring->sched;
 		job->base.s_entity = &parser->ctx->rings[ring->idx].entity;
 		job->adev = parser->adev;

commit f1a04d82585032d906e6a7d5b16d38a369033bd0
Merge: 974e59ba0bc3 ed885b210752
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri Oct 30 09:48:28 2015 +1000

    Merge branch 'drm-next-4.4' of git://people.freedesktop.org/~agd5f/linux into drm-next
    
    More amdgpu and radeon stuff for drm-next.  Stoney support is the big change.
    The rest is just bug fixes and code cleanups.  The Stoney stuff is pretty
    low impact with respect to existing chips.
    
    * 'drm-next-4.4' of git://people.freedesktop.org/~agd5f/linux:
      drm/amdgpu: change VM size default to 64GB
      drm/amdgpu: add Stoney pci ids
      drm/amdgpu: update the core VI support for Stoney
      drm/amdgpu: add VCE support for Stoney (v2)
      drm/amdgpu: add UVD support for Stoney
      drm/amdgpu: add GFX support for Stoney (v2)
      drm/amdgpu: add SDMA support for Stoney (v2)
      drm/amdgpu: add DCE support for Stoney
      drm/amdgpu: Update SMC/DPM for Stoney
      drm/amdgpu: add GMC support for Stoney
      drm/amdgpu: add Stoney chip family
      drm/amdgpu: fix the broken vm->mutex V2
      drm/amdgpu: remove the unnecessary parameter adev for amdgpu_fence_wait_any()
      drm/amdgpu: remove the exclusive lock
      drm/amdgpu: remove old lockup detection infrastructure
      drm: fix trivial typos
      drm/amdgpu/dce: simplify suspend/resume
      drm/amdgpu/gfx8: set TC_WB_ACTION_EN in RELEASE_MEM packet
      drm/radeon: Use rdev->gem.mutex to protect hyperz/cmask owners

commit f48b2659f521301753f9b3b67e308a79c6110346
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Fri Oct 16 14:06:19 2015 +0800

    drm/amdgpu: fix the broken vm->mutex V2
    
    fix the vm->mutex and ww_mutex confilcts.
    vm->mutex is always token first, then ww_mutex.
    
    V2: remove unneccessary checking for pt bo.
    
    Change-Id: Iea56e183752c02831126d06d2f5b7a474a6e4743
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 5fdc0394561e..8727c3099554 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -608,7 +608,6 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 		}
 	}
 
-	mutex_lock(&vm->mutex);
 	r = amdgpu_bo_vm_update_pte(parser, vm);
 	if (r) {
 		goto out;
@@ -619,7 +618,6 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 				       parser->filp);
 
 out:
-	mutex_unlock(&vm->mutex);
 	return r;
 }
 
@@ -827,6 +825,8 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 {
 	struct amdgpu_device *adev = dev->dev_private;
 	union drm_amdgpu_cs *cs = data;
+	struct amdgpu_fpriv *fpriv = filp->driver_priv;
+	struct amdgpu_vm *vm = &fpriv->vm;
 	struct amdgpu_cs_parser *parser;
 	bool reserved_buffers = false;
 	int i, r;
@@ -844,7 +844,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		r = amdgpu_cs_handle_lockup(adev, r);
 		return r;
 	}
-
+	mutex_lock(&vm->mutex);
 	r = amdgpu_cs_parser_relocs(parser);
 	if (r == -ENOMEM)
 		DRM_ERROR("Not enough memory for command submission!\n");
@@ -911,12 +911,14 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 		mutex_unlock(&job->job_lock);
 		amdgpu_cs_parser_fini_late(parser);
+		mutex_unlock(&vm->mutex);
 		return 0;
 	}
 
 	cs->out.handle = parser->ibs[parser->num_ibs - 1].sequence;
 out:
 	amdgpu_cs_parser_fini(parser, r, reserved_buffers);
+	mutex_unlock(&vm->mutex);
 	r = amdgpu_cs_handle_lockup(adev, r);
 	return r;
 }

commit 0c418f10104d4aa1d6b83698790898dc9ef1c12d
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Sep 1 15:13:53 2015 +0200

    drm/amdgpu: remove the exclusive lock
    
    Finally getting rid of it.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 25012c790f8f..5fdc0394561e 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -831,11 +831,8 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	bool reserved_buffers = false;
 	int i, r;
 
-	down_read(&adev->exclusive_lock);
-	if (!adev->accel_working) {
-		up_read(&adev->exclusive_lock);
+	if (!adev->accel_working)
 		return -EBUSY;
-	}
 
 	parser = amdgpu_cs_parser_create(adev, filp, NULL, NULL, 0);
 	if (!parser)
@@ -843,8 +840,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	r = amdgpu_cs_parser_init(parser, data);
 	if (r) {
 		DRM_ERROR("Failed to initialize parser !\n");
-		kfree(parser);
-		up_read(&adev->exclusive_lock);
+		amdgpu_cs_parser_fini(parser, r, false);
 		r = amdgpu_cs_handle_lockup(adev, r);
 		return r;
 	}
@@ -915,14 +911,12 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 		mutex_unlock(&job->job_lock);
 		amdgpu_cs_parser_fini_late(parser);
-		up_read(&adev->exclusive_lock);
 		return 0;
 	}
 
 	cs->out.handle = parser->ibs[parser->num_ibs - 1].sequence;
 out:
 	amdgpu_cs_parser_fini(parser, r, reserved_buffers);
-	up_read(&adev->exclusive_lock);
 	r = amdgpu_cs_handle_lockup(adev, r);
 	return r;
 }

commit 48f87dd146a480c723774962eca675873a8aa1da
Merge: 6b62b3e13467 06d1ee32a4d2
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri Oct 16 10:10:32 2015 +1000

    Merge commit '06d1ee32a4d25356a710b49d5e95dbdd68bdf505' of git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux into drm-next
    
    Backmerge the drm-fixes pull from Linus's tree into drm-next.
    
    This is to fix some conflicts and make future pulls cleaner

commit b495bd3a54e732e846bfde49ba2ea93b62b1de91
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Sep 10 14:00:35 2015 +0200

    drm/amdgpu: add option to clear VM page tables after every submit
    
    This makes it much easier to find when userspace misses to send some buffers.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 29fc45ce64dd..25012c790f8f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -567,9 +567,24 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 			if (r)
 				return r;
 		}
+
+	}
+
+	r = amdgpu_vm_clear_invalids(adev, vm, &p->ibs[0].sync);
+
+	if (amdgpu_vm_debug && p->bo_list) {
+		/* Invalidate all BOs to test for userspace bugs */
+		for (i = 0; i < p->bo_list->num_entries; i++) {
+			/* ignore duplicates */
+			bo = p->bo_list->array[i].robj;
+			if (!bo)
+				continue;
+
+			amdgpu_vm_bo_invalidate(adev, bo);
+		}
 	}
 
-	return amdgpu_vm_clear_invalids(adev, vm, &p->ibs[0].sync);
+	return r;
 }
 
 static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,

commit c113ea1c4f4a7592f17e53d658873b83af0dbb4b
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Thu Oct 8 16:30:37 2015 -0400

    drm/amdgpu: rework sdma structures
    
    Rework the sdma structures in the driver to
    consolidate all of the sdma info into a single
    structure and allow for asics that may have
    different numbers of sdma instances.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 749420f1ea6f..29fc45ce64dd 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -104,10 +104,11 @@ int amdgpu_cs_get_ring(struct amdgpu_device *adev, u32 ip_type,
 		}
 		break;
 	case AMDGPU_HW_IP_DMA:
-		if (ring < 2) {
-			*out_ring = &adev->sdma[ring].ring;
+		if (ring < adev->sdma.num_instances) {
+			*out_ring = &adev->sdma.instance[ring].ring;
 		} else {
-			DRM_ERROR("only two SDMA rings are supported\n");
+			DRM_ERROR("only %d SDMA rings are supported\n",
+				  adev->sdma.num_instances);
 			return -EINVAL;
 		}
 		break;

commit 028423b0d8fa27c30a46da4af2a5cab230369de6
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Oct 7 09:41:27 2015 +0200

    drm/amdgpu: fix 32-bit compiler warning
    
    The new amdgpu driver passes a user space pointer in a 64-bit structure
    member, which is the correct way to do it, but it attempts to
    directly cast it to a __user pointer in the kernel, which causes
    a warning in three places:
    
    drm/amd/amdgpu/amdgpu_cs.c: In function 'amdgpu_cs_parser_init':
    drm/amd/amdgpu/amdgpu_cs.c:180:21: warning: cast to pointer from integer of different size [-Wint-to-pointer-cast]
      chunk_array_user = (uint64_t __user *)(cs->in.chunks);
    
    This changes all three to add an intermediate cast to 'unsigned long'
    as other drivers do. This avoids the warning and works correctly on
    both 32-bit and 64-bit architectures.
    
    Fixes: e60b344f6c0eff ("drm/amdgpu: optimize amdgpu_parser_init")
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index cb3c274edb0a..fd16652aa277 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -177,7 +177,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 
 	/* get chunks */
 	INIT_LIST_HEAD(&p->validated);
-	chunk_array_user = (uint64_t __user *)(cs->in.chunks);
+	chunk_array_user = (uint64_t __user *)(unsigned long)(cs->in.chunks);
 	if (copy_from_user(chunk_array, chunk_array_user,
 			   sizeof(uint64_t)*cs->in.num_chunks)) {
 		ret = -EFAULT;
@@ -197,7 +197,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		struct drm_amdgpu_cs_chunk user_chunk;
 		uint32_t __user *cdata;
 
-		chunk_ptr = (void __user *)chunk_array[i];
+		chunk_ptr = (void __user *)(unsigned long)chunk_array[i];
 		if (copy_from_user(&user_chunk, chunk_ptr,
 				       sizeof(struct drm_amdgpu_cs_chunk))) {
 			ret = -EFAULT;
@@ -208,7 +208,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		p->chunks[i].length_dw = user_chunk.length_dw;
 
 		size = p->chunks[i].length_dw;
-		cdata = (void __user *)user_chunk.chunk_data;
+		cdata = (void __user *)(unsigned long)user_chunk.chunk_data;
 		p->chunks[i].user_ptr = cdata;
 
 		p->chunks[i].kdata = drm_malloc_ab(size, sizeof(uint32_t));

commit 54313503f9a3c34a9e45aad7654976b7f50b9ae7
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Fri Sep 25 14:36:55 2015 +0300

    drm/amdgpu: signedness bug in amdgpu_cs_parser_init()
    
    The "i" variable should be signed or it leads to a crash in the error
    handling code.
    
    Fixes: 1d263474c441 ('drm/amdgpu: unwind properly in amdgpu_cs_parser_init()')
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 749420f1ea6f..cb3c274edb0a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -156,7 +156,8 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	uint64_t *chunk_array_user;
 	uint64_t *chunk_array;
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
-	unsigned size, i;
+	unsigned size;
+	int i;
 	int ret;
 
 	if (cs->in.num_chunks == 0)

commit 1d263474c4416efb6d0feca98fe6d462b0d28f56
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Wed Sep 23 13:59:28 2015 +0300

    drm/amdgpu: unwind properly in amdgpu_cs_parser_init()
    
    The amdgpu_cs_parser_init() function doesn't clean up after itself but
    instead the caller uses a free everything function amdgpu_cs_parser_fini()
    on failure.  This style of error handling is often buggy.  In this
    example, we call "drm_free_large(parser->chunks[i].kdata);" when it is
    an unintialized pointer or when "parser->chunks" is NULL.
    
    I fixed this bug by adding unwind code so that it frees everything that
    it allocates.
    
    I also mode some other very minor changes:
    1) Renamed "r" to "ret".
    2) Moved the chunk_array allocation to the start of the function.
    3) Removed some initializers which are no longer needed.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reported-by: Ilja Van Sprundel <ivansprundel@ioactive.com>
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index b74b6a8e80a6..749420f1ea6f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -154,42 +154,41 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 {
 	union drm_amdgpu_cs *cs = data;
 	uint64_t *chunk_array_user;
-	uint64_t *chunk_array = NULL;
+	uint64_t *chunk_array;
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	unsigned size, i;
-	int r = 0;
+	int ret;
 
-	if (!cs->in.num_chunks)
-		goto out;
+	if (cs->in.num_chunks == 0)
+		return 0;
+
+	chunk_array = kmalloc_array(cs->in.num_chunks, sizeof(uint64_t), GFP_KERNEL);
+	if (!chunk_array)
+		return -ENOMEM;
 
 	p->ctx = amdgpu_ctx_get(fpriv, cs->in.ctx_id);
 	if (!p->ctx) {
-		r = -EINVAL;
-		goto out;
+		ret = -EINVAL;
+		goto free_chunk;
 	}
+
 	p->bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
 
 	/* get chunks */
 	INIT_LIST_HEAD(&p->validated);
-	chunk_array = kmalloc_array(cs->in.num_chunks, sizeof(uint64_t), GFP_KERNEL);
-	if (chunk_array == NULL) {
-		r = -ENOMEM;
-		goto out;
-	}
-
 	chunk_array_user = (uint64_t __user *)(cs->in.chunks);
 	if (copy_from_user(chunk_array, chunk_array_user,
 			   sizeof(uint64_t)*cs->in.num_chunks)) {
-		r = -EFAULT;
-		goto out;
+		ret = -EFAULT;
+		goto put_bo_list;
 	}
 
 	p->nchunks = cs->in.num_chunks;
 	p->chunks = kmalloc_array(p->nchunks, sizeof(struct amdgpu_cs_chunk),
 			    GFP_KERNEL);
-	if (p->chunks == NULL) {
-		r = -ENOMEM;
-		goto out;
+	if (!p->chunks) {
+		ret = -ENOMEM;
+		goto put_bo_list;
 	}
 
 	for (i = 0; i < p->nchunks; i++) {
@@ -200,8 +199,9 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		chunk_ptr = (void __user *)chunk_array[i];
 		if (copy_from_user(&user_chunk, chunk_ptr,
 				       sizeof(struct drm_amdgpu_cs_chunk))) {
-			r = -EFAULT;
-			goto out;
+			ret = -EFAULT;
+			i--;
+			goto free_partial_kdata;
 		}
 		p->chunks[i].chunk_id = user_chunk.chunk_id;
 		p->chunks[i].length_dw = user_chunk.length_dw;
@@ -212,13 +212,14 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 
 		p->chunks[i].kdata = drm_malloc_ab(size, sizeof(uint32_t));
 		if (p->chunks[i].kdata == NULL) {
-			r = -ENOMEM;
-			goto out;
+			ret = -ENOMEM;
+			i--;
+			goto free_partial_kdata;
 		}
 		size *= sizeof(uint32_t);
 		if (copy_from_user(p->chunks[i].kdata, cdata, size)) {
-			r = -EFAULT;
-			goto out;
+			ret = -EFAULT;
+			goto free_partial_kdata;
 		}
 
 		switch (p->chunks[i].chunk_id) {
@@ -238,15 +239,15 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 				gobj = drm_gem_object_lookup(p->adev->ddev,
 							     p->filp, handle);
 				if (gobj == NULL) {
-					r = -EINVAL;
-					goto out;
+					ret = -EINVAL;
+					goto free_partial_kdata;
 				}
 
 				p->uf.bo = gem_to_amdgpu_bo(gobj);
 				p->uf.offset = fence_data->offset;
 			} else {
-				r = -EINVAL;
-				goto out;
+				ret = -EINVAL;
+				goto free_partial_kdata;
 			}
 			break;
 
@@ -254,19 +255,35 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 			break;
 
 		default:
-			r = -EINVAL;
-			goto out;
+			ret = -EINVAL;
+			goto free_partial_kdata;
 		}
 	}
 
 
 	p->ibs = kcalloc(p->num_ibs, sizeof(struct amdgpu_ib), GFP_KERNEL);
-	if (!p->ibs)
-		r = -ENOMEM;
+	if (!p->ibs) {
+		ret = -ENOMEM;
+		goto free_all_kdata;
+	}
 
-out:
 	kfree(chunk_array);
-	return r;
+	return 0;
+
+free_all_kdata:
+	i = p->nchunks - 1;
+free_partial_kdata:
+	for (; i >= 0; i--)
+		drm_free_large(p->chunks[i].kdata);
+	kfree(p->chunks);
+put_bo_list:
+	if (p->bo_list)
+		amdgpu_bo_list_put(p->bo_list);
+	amdgpu_ctx_put(p->ctx);
+free_chunk:
+	kfree(chunk_array);
+
+	return ret;
 }
 
 /* Returns how many bytes TTM can move per IB.
@@ -810,7 +827,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	r = amdgpu_cs_parser_init(parser, data);
 	if (r) {
 		DRM_ERROR("Failed to initialize parser !\n");
-		amdgpu_cs_parser_fini(parser, r, false);
+		kfree(parser);
 		up_read(&adev->exclusive_lock);
 		r = amdgpu_cs_handle_lockup(adev, r);
 		return r;

commit 4f839a243d3b0d8b1a14f4778a87ec4d8ddbf15f
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Sep 8 20:22:31 2015 +0200

    drm/amdgpu: more scheduler cleanups v2
    
    Embed the scheduler into the ring structure instead of allocating it.
    Use the ring name directly instead of the id.
    
    v2: rebased, whitespace cleanup
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Reviewed-by: Chunming Zhou<david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 6f39b2d2106d..b74b6a8e80a6 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -848,7 +848,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		job = kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
 		if (!job)
 			return -ENOMEM;
-		job->base.sched = ring->sched;
+		job->base.sched = &ring->sched;
 		job->base.s_entity = &parser->ctx->rings[ring->idx].entity;
 		job->adev = parser->adev;
 		job->ibs = parser->ibs;

commit 9b398fa5c24eb05fc60fafd8543cc03e9170f054
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Sep 7 18:16:49 2015 +0200

    drm/amdgpu: rename fence->scheduler to sched v2
    
    Just to be consistent with the other members.
    
    v2: rename the ring member as well.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com> (v1)
    Reviewed-by: Chunming Zhou<david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 546968a83b08..6f39b2d2106d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -848,7 +848,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		job = kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
 		if (!job)
 			return -ENOMEM;
-		job->base.sched = ring->scheduler;
+		job->base.sched = ring->sched;
 		job->base.s_entity = &parser->ctx->rings[ring->idx].entity;
 		job->adev = parser->adev;
 		job->ibs = parser->ibs;

commit a6db8a33e164ae72fb5429ab637e8cfee057a722
Author: Junwei Zhang <Jerry.Zhang@amd.com>
Date:   Wed Sep 9 09:21:19 2015 +0800

    drm/amdgpu: refine the scheduler job type conversion
    
    Use container_of rather than casting.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: David Zhou <david1.zhou@amd.com>
    Signed-off-by: Junwei Zhang <Jerry.Zhang@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 4c1698861c42..546968a83b08 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -863,7 +863,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 		job->free_job = amdgpu_cs_free_job;
 		mutex_lock(&job->job_lock);
-		r = amd_sched_entity_push_job((struct amd_sched_job *)job);
+		r = amd_sched_entity_push_job(&job->base);
 		if (r) {
 			mutex_unlock(&job->job_lock);
 			amdgpu_cs_free_job(job);

commit 4c7eb91cae88fd2aa101750d6825b4176f85ffb2
Author: Junwei Zhang <Jerry.Zhang@amd.com>
Date:   Wed Sep 9 09:05:55 2015 +0800

    drm/amdgpu: refine the job naming for amdgpu_job and amdgpu_sched_job
    
    Use consistent naming across functions.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: David Zhou <david1.zhou@amd.com>
    Signed-off-by: Junwei Zhang <Jerry.Zhang@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 4b92e3836684..4c1698861c42 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -778,15 +778,15 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 	return 0;
 }
 
-static int amdgpu_cs_free_job(struct amdgpu_job *sched_job)
+static int amdgpu_cs_free_job(struct amdgpu_job *job)
 {
 	int i;
-	if (sched_job->ibs)
-		for (i = 0; i < sched_job->num_ibs; i++)
-			amdgpu_ib_free(sched_job->adev, &sched_job->ibs[i]);
-	kfree(sched_job->ibs);
-	if (sched_job->uf.bo)
-		drm_gem_object_unreference_unlocked(&sched_job->uf.bo->gem_base);
+	if (job->ibs)
+		for (i = 0; i < job->num_ibs; i++)
+			amdgpu_ib_free(job->adev, &job->ibs[i]);
+	kfree(job->ibs);
+	if (job->uf.bo)
+		drm_gem_object_unreference_unlocked(&job->uf.bo->gem_base);
 	return 0;
 }
 

commit a5b750583eb4af69da1e659c7684b6d370b2ae97
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Sep 3 16:40:39 2015 +0200

    drm/amdgpu: validate duplicates in the CS as well
    
    This allows for multiple BOs to have the same reservation object.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 3b355aeb62fd..4b92e3836684 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -321,25 +321,17 @@ static u64 amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev)
 	return max(bytes_moved_threshold, 1024*1024ull);
 }
 
-int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p)
+int amdgpu_cs_list_validate(struct amdgpu_device *adev,
+			    struct amdgpu_vm *vm,
+			    struct list_head *validated)
 {
-	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
-	struct amdgpu_vm *vm = &fpriv->vm;
-	struct amdgpu_device *adev = p->adev;
 	struct amdgpu_bo_list_entry *lobj;
-	struct list_head duplicates;
 	struct amdgpu_bo *bo;
 	u64 bytes_moved = 0, initial_bytes_moved;
 	u64 bytes_moved_threshold = amdgpu_cs_get_threshold_for_moves(adev);
 	int r;
 
-	INIT_LIST_HEAD(&duplicates);
-	r = ttm_eu_reserve_buffers(&p->ticket, &p->validated, true, &duplicates);
-	if (unlikely(r != 0)) {
-		return r;
-	}
-
-	list_for_each_entry(lobj, &p->validated, tv.head) {
+	list_for_each_entry(lobj, validated, tv.head) {
 		bo = lobj->robj;
 		if (!bo->pin_count) {
 			u32 domain = lobj->prefered_domains;
@@ -373,7 +365,6 @@ int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p)
 					domain = lobj->allowed_domains;
 					goto retry;
 				}
-				ttm_eu_backoff_reservation(&p->ticket, &p->validated);
 				return r;
 			}
 		}
@@ -386,6 +377,7 @@ static int amdgpu_cs_parser_relocs(struct amdgpu_cs_parser *p)
 {
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_cs_buckets buckets;
+	struct list_head duplicates;
 	bool need_mmap_lock = false;
 	int i, r;
 
@@ -405,8 +397,22 @@ static int amdgpu_cs_parser_relocs(struct amdgpu_cs_parser *p)
 	if (need_mmap_lock)
 		down_read(&current->mm->mmap_sem);
 
-	r = amdgpu_cs_list_validate(p);
+	INIT_LIST_HEAD(&duplicates);
+	r = ttm_eu_reserve_buffers(&p->ticket, &p->validated, true, &duplicates);
+	if (unlikely(r != 0))
+		goto error_reserve;
+
+	r = amdgpu_cs_list_validate(p->adev, &fpriv->vm, &p->validated);
+	if (r)
+		goto error_validate;
+
+	r = amdgpu_cs_list_validate(p->adev, &fpriv->vm, &duplicates);
+
+error_validate:
+	if (r)
+		ttm_eu_backoff_reservation(&p->ticket, &p->validated);
 
+error_reserve:
 	if (need_mmap_lock)
 		up_read(&current->mm->mmap_sem);
 

commit 270e869d846af143f60b7404e01e785d18420007
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Sep 2 20:25:48 2015 +0200

    drm/amdgpu: fix buffer placement under memory pressure
    
    Some buffers (UVD/VM page tables) must be placed in VRAM,
    but the byte restriction for moving buffers didn't took this
    into account.
    
    Port of radeon commit 4b09556660bfe1b43d72ca858524c6baf2c6cb1d.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 6a206f15635f..3b355aeb62fd 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -354,7 +354,7 @@ int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p)
 			 * into account. We don't want to disallow buffer moves
 			 * completely.
 			 */
-			if (current_domain != AMDGPU_GEM_DOMAIN_CPU &&
+			if ((lobj->allowed_domains & current_domain) != 0 &&
 			    (domain & current_domain) == 0 && /* will be moved */
 			    bytes_moved > bytes_moved_threshold) {
 				/* don't move it */

commit 84f76ea6b03a766931e5d6d650af5ab980c6c4f4
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Mon Aug 24 12:47:36 2015 +0800

    drm/amdgpu: add owner for sched fence
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 82e14321e9c7..6a206f15635f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -847,7 +847,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		job->adev = parser->adev;
 		job->ibs = parser->ibs;
 		job->num_ibs = parser->num_ibs;
-		job->owner = parser->filp;
+		job->base.owner = parser->filp;
 		mutex_init(&job->job_lock);
 		if (job->ibs[job->num_ibs - 1].user) {
 			memcpy(&job->uf,  &parser->uf,

commit 6c859274f363be9dc13f8849bdc59bb64f922f26
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Aug 20 16:12:50 2015 +0200

    drm/amdgpu: fix and cleanup amd_sched_entity_push_job
    
    Calling schedule() is probably the worse things we can do.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 780c0113e8f8..82e14321e9c7 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -857,7 +857,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 		job->free_job = amdgpu_cs_free_job;
 		mutex_lock(&job->job_lock);
-		r = amd_sched_push_job((struct amd_sched_job *)job);
+		r = amd_sched_entity_push_job((struct amd_sched_job *)job);
 		if (r) {
 			mutex_unlock(&job->job_lock);
 			amdgpu_cs_free_job(job);

commit 3a185a33a2d291883bd1d0691d22901c345b12c9
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Aug 20 17:35:34 2015 +0200

    drm/amdgpu: remove the context from amdgpu_job
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 5d335522625e..780c0113e8f8 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -775,7 +775,6 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 static int amdgpu_cs_free_job(struct amdgpu_job *sched_job)
 {
 	int i;
-	amdgpu_ctx_put(sched_job->ctx);
 	if (sched_job->ibs)
 		for (i = 0; i < sched_job->num_ibs; i++)
 			amdgpu_ib_free(sched_job->adev, &sched_job->ibs[i]);
@@ -849,7 +848,6 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		job->ibs = parser->ibs;
 		job->num_ibs = parser->num_ibs;
 		job->owner = parser->filp;
-		job->ctx = amdgpu_ctx_get_ref(parser->ctx);
 		mutex_init(&job->job_lock);
 		if (job->ibs[job->num_ibs - 1].user) {
 			memcpy(&job->uf,  &parser->uf,
@@ -867,7 +865,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 			goto out;
 		}
 		cs->out.handle =
-			amdgpu_ctx_add_fence(job->ctx, ring,
+			amdgpu_ctx_add_fence(parser->ctx, ring,
 					     &job->base.s_fence->base);
 		parser->ibs[parser->num_ibs - 1].sequence = cs->out.handle;
 

commit eb98d1c54d1e058f406f3f4acf15684ad26f9676
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Aug 20 17:28:36 2015 +0200

    drm/amdgpu: fix user fences when scheduler is enabled
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index f91849b12a0f..5d335522625e 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -869,6 +869,8 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		cs->out.handle =
 			amdgpu_ctx_add_fence(job->ctx, ring,
 					     &job->base.s_fence->base);
+		parser->ibs[parser->num_ibs - 1].sequence = cs->out.handle;
+
 		list_sort(NULL, &parser->validated, cmp_size_smaller_first);
 		ttm_eu_fence_buffer_objects(&parser->ticket,
 				&parser->validated,

commit ce882e6dc241ab8dded0eeeb33a86482d44a5689
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Aug 19 15:00:55 2015 +0200

    drm/amdgpu: remove v_seq handling from the scheduler v2
    
    Simply not used any more. Only keep 32bit atomic for fence sequence numbering.
    
    v2: trivial rebase
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com> (v1)
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com> (v1)
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com> (v1)

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index dc8d2829c1e9..f91849b12a0f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -866,11 +866,9 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 			kfree(job);
 			goto out;
 		}
-		job->ibs[parser->num_ibs - 1].sequence =
+		cs->out.handle =
 			amdgpu_ctx_add_fence(job->ctx, ring,
-					     &job->base.s_fence->base,
-					     job->base.s_fence->v_seq);
-		cs->out.handle = job->base.s_fence->v_seq;
+					     &job->base.s_fence->base);
 		list_sort(NULL, &parser->validated, cmp_size_smaller_first);
 		ttm_eu_fence_buffer_objects(&parser->ticket,
 				&parser->validated,

commit 26a6980cf40c67182bc36fa0b088ebed79796110
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Aug 18 21:09:33 2015 +0200

    drm/amdgpu: fix CS error handling v2
    
    Stop double freeing the the BO list by pulling the content
    of amdgpu_cs_parser_prepare_job() into the IOCTL function again.
    
    v2: better commit message
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com> (v1)
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index a592df574939..dc8d2829c1e9 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -772,44 +772,6 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 	return 0;
 }
 
-static int amdgpu_cs_parser_prepare_job(struct amdgpu_cs_parser *sched_job)
-{
-	int r, i;
-	struct amdgpu_cs_parser *parser = sched_job;
-	struct amdgpu_device *adev = sched_job->adev;
-	bool reserved_buffers = false;
-
-	r = amdgpu_cs_parser_relocs(parser);
-	if (r) {
-		if (r != -ERESTARTSYS) {
-			if (r == -ENOMEM)
-				DRM_ERROR("Not enough memory for command submission!\n");
-			else
-				DRM_ERROR("Failed to process the buffer list %d!\n", r);
-		}
-	}
-
-	if (!r) {
-		reserved_buffers = true;
-		r = amdgpu_cs_ib_fill(adev, parser);
-	}
-	if (!r) {
-		r = amdgpu_cs_dependencies(adev, parser);
-		if (r)
-			DRM_ERROR("Failed in the dependencies handling %d!\n", r);
-	}
-	if (r) {
-		amdgpu_cs_parser_fini(parser, r, reserved_buffers);
-		return r;
-	}
-
-	for (i = 0; i < parser->num_ibs; i++)
-		trace_amdgpu_cs(parser, i);
-
-	r = amdgpu_cs_ib_vm_chunk(adev, parser);
-	return r;
-}
-
 static int amdgpu_cs_free_job(struct amdgpu_job *sched_job)
 {
 	int i;
@@ -828,7 +790,8 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	struct amdgpu_device *adev = dev->dev_private;
 	union drm_amdgpu_cs *cs = data;
 	struct amdgpu_cs_parser *parser;
-	int r;
+	bool reserved_buffers = false;
+	int i, r;
 
 	down_read(&adev->exclusive_lock);
 	if (!adev->accel_working) {
@@ -848,7 +811,29 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		return r;
 	}
 
-	r = amdgpu_cs_parser_prepare_job(parser);
+	r = amdgpu_cs_parser_relocs(parser);
+	if (r == -ENOMEM)
+		DRM_ERROR("Not enough memory for command submission!\n");
+	else if (r && r != -ERESTARTSYS)
+		DRM_ERROR("Failed to process the buffer list %d!\n", r);
+	else if (!r) {
+		reserved_buffers = true;
+		r = amdgpu_cs_ib_fill(adev, parser);
+	}
+
+	if (!r) {
+		r = amdgpu_cs_dependencies(adev, parser);
+		if (r)
+			DRM_ERROR("Failed in the dependencies handling %d!\n", r);
+	}
+
+	if (r)
+		goto out;
+
+	for (i = 0; i < parser->num_ibs; i++)
+		trace_amdgpu_cs(parser, i);
+
+	r = amdgpu_cs_ib_vm_chunk(adev, parser);
 	if (r)
 		goto out;
 
@@ -899,7 +884,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 	cs->out.handle = parser->ibs[parser->num_ibs - 1].sequence;
 out:
-	amdgpu_cs_parser_fini(parser, r, true);
+	amdgpu_cs_parser_fini(parser, r, reserved_buffers);
 	up_read(&adev->exclusive_lock);
 	r = amdgpu_cs_handle_lockup(adev, r);
 	return r;

commit b203dd95949ec8d5e30d53446408eb9a4d1bdc62
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Aug 18 18:23:16 2015 +0200

    drm/amdgpu: fix zeroing all IB fields manually v2
    
    The problem now is that we don't necessarily call amdgpu_ib_get()
    in some error paths and so work with uninitialized data.
    
    Better require that the memory is already zeroed.
    
    v2: better commit message
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com> (v1)
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 2cf7f52a5650..a592df574939 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -260,7 +260,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	}
 
 
-	p->ibs = kmalloc_array(p->num_ibs, sizeof(struct amdgpu_ib), GFP_KERNEL);
+	p->ibs = kcalloc(p->num_ibs, sizeof(struct amdgpu_ib), GFP_KERNEL);
 	if (!p->ibs)
 		r = -ENOMEM;
 

commit a3348bb801bac5c9a81fb3da4b1a2f0479e97923
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Tue Aug 18 16:25:46 2015 +0800

    drm/amdgpu: don't need to use bo_list_clone any more
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 77fc7cd0fac3..2cf7f52a5650 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -156,7 +156,6 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	uint64_t *chunk_array_user;
 	uint64_t *chunk_array = NULL;
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
-	struct amdgpu_bo_list *bo_list = NULL;
 	unsigned size, i;
 	int r = 0;
 
@@ -168,20 +167,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		r = -EINVAL;
 		goto out;
 	}
-	bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
-	if (!amdgpu_enable_scheduler)
-		p->bo_list = bo_list;
-	else {
-		if (bo_list && !bo_list->has_userptr) {
-			p->bo_list = amdgpu_bo_list_clone(bo_list);
-			amdgpu_bo_list_put(bo_list);
-			if (!p->bo_list)
-				return -ENOMEM;
-		} else if (bo_list && bo_list->has_userptr)
-			p->bo_list = bo_list;
-		else
-			p->bo_list = NULL;
-	}
+	p->bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
 
 	/* get chunks */
 	INIT_LIST_HEAD(&p->validated);
@@ -481,12 +467,9 @@ static void amdgpu_cs_parser_fini_late(struct amdgpu_cs_parser *parser)
 	unsigned i;
 	if (parser->ctx)
 		amdgpu_ctx_put(parser->ctx);
-	if (parser->bo_list) {
-		if (amdgpu_enable_scheduler && !parser->bo_list->has_userptr)
-			amdgpu_bo_list_free(parser->bo_list);
-		else
-			amdgpu_bo_list_put(parser->bo_list);
-	}
+	if (parser->bo_list)
+		amdgpu_bo_list_put(parser->bo_list);
+
 	drm_free_large(parser->vm_bos);
 	for (i = 0; i < parser->nchunks; i++)
 		drm_free_large(parser->chunks[i].kdata);

commit 3c4adead8480f81df687a181d1e54a39b91b9363
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Tue Aug 18 16:19:13 2015 +0800

    drm/amdgpu: some clean up for cs_ioctl
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 7b4823deef33..77fc7cd0fac3 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -827,32 +827,6 @@ static int amdgpu_cs_parser_prepare_job(struct amdgpu_cs_parser *sched_job)
 	return r;
 }
 
-static struct amdgpu_ring *amdgpu_cs_parser_get_ring(
-	struct amdgpu_device *adev,
-	struct amdgpu_cs_parser *parser)
-{
-	int i, r;
-
-	struct amdgpu_cs_chunk *chunk;
-	struct drm_amdgpu_cs_chunk_ib *chunk_ib;
-	struct amdgpu_ring *ring;
-	for (i = 0; i < parser->nchunks; i++) {
-		chunk = &parser->chunks[i];
-		chunk_ib = (struct drm_amdgpu_cs_chunk_ib *)chunk->kdata;
-
-		if (chunk->chunk_id != AMDGPU_CHUNK_ID_IB)
-			continue;
-
-		r = amdgpu_cs_get_ring(adev, chunk_ib->ip_type,
-				       chunk_ib->ip_instance, chunk_ib->ring,
-				       &ring);
-		if (r)
-			return NULL;
-		break;
-	}
-	return ring;
-}
-
 static int amdgpu_cs_free_job(struct amdgpu_job *sched_job)
 {
 	int i;
@@ -897,8 +871,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 	if (amdgpu_enable_scheduler && parser->num_ibs) {
 		struct amdgpu_job *job;
-		struct amdgpu_ring * ring =
-			amdgpu_cs_parser_get_ring(adev, parser);
+		struct amdgpu_ring * ring =  parser->ibs->ring;
 		job = kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
 		if (!job)
 			return -ENOMEM;

commit 4fe6311734986220e40afe4bf72d62383c1e8d6c
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Tue Aug 18 16:12:15 2015 +0800

    drm/amdgpu: prepare job should be common code path
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index c8de4b6194e8..7b4823deef33 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -891,13 +891,14 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		return r;
 	}
 
+	r = amdgpu_cs_parser_prepare_job(parser);
+	if (r)
+		goto out;
+
 	if (amdgpu_enable_scheduler && parser->num_ibs) {
 		struct amdgpu_job *job;
 		struct amdgpu_ring * ring =
 			amdgpu_cs_parser_get_ring(adev, parser);
-		r = amdgpu_cs_parser_prepare_job(parser);
-		if (r)
-			goto out;
 		job = kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
 		if (!job)
 			return -ENOMEM;
@@ -939,9 +940,6 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		up_read(&adev->exclusive_lock);
 		return 0;
 	}
-	r = amdgpu_cs_parser_prepare_job(parser);
-	if (r)
-		goto out;
 
 	cs->out.handle = parser->ibs[parser->num_ibs - 1].sequence;
 out:

commit bb977d3711ed1de1601b463e7fd5a43d82a2b077
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Tue Aug 18 15:16:40 2015 +0800

    drm/amdgpu: abstract amdgpu_job for scheduler
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index e4424b4db5d3..c8de4b6194e8 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -126,19 +126,6 @@ int amdgpu_cs_get_ring(struct amdgpu_device *adev, u32 ip_type,
 	return 0;
 }
 
-static void amdgpu_job_work_func(struct work_struct *work)
-{
-	struct amdgpu_cs_parser *sched_job =
-		container_of(work, struct amdgpu_cs_parser,
-			     job_work);
-	mutex_lock(&sched_job->job_lock);
-	if (sched_job->free_job)
-		sched_job->free_job(sched_job);
-	mutex_unlock(&sched_job->job_lock);
-	/* after processing job, free memory */
-	fence_put(&sched_job->s_fence->base);
-	kfree(sched_job);
-}
 struct amdgpu_cs_parser *amdgpu_cs_parser_create(struct amdgpu_device *adev,
                                                struct drm_file *filp,
                                                struct amdgpu_ctx *ctx,
@@ -157,10 +144,6 @@ struct amdgpu_cs_parser *amdgpu_cs_parser_create(struct amdgpu_device *adev,
 	parser->ctx = ctx;
 	parser->ibs = ibs;
 	parser->num_ibs = num_ibs;
-	if (amdgpu_enable_scheduler) {
-		mutex_init(&parser->job_lock);
-		INIT_WORK(&parser->job_work, amdgpu_job_work_func);
-	}
 	for (i = 0; i < num_ibs; i++)
 		ibs[i].ctx = ctx;
 
@@ -508,15 +491,17 @@ static void amdgpu_cs_parser_fini_late(struct amdgpu_cs_parser *parser)
 	for (i = 0; i < parser->nchunks; i++)
 		drm_free_large(parser->chunks[i].kdata);
 	kfree(parser->chunks);
-	if (parser->ibs)
-		for (i = 0; i < parser->num_ibs; i++)
-			amdgpu_ib_free(parser->adev, &parser->ibs[i]);
-	kfree(parser->ibs);
-	if (parser->uf.bo)
-		drm_gem_object_unreference_unlocked(&parser->uf.bo->gem_base);
-
 	if (!amdgpu_enable_scheduler)
-		kfree(parser);
+	{
+		if (parser->ibs)
+			for (i = 0; i < parser->num_ibs; i++)
+				amdgpu_ib_free(parser->adev, &parser->ibs[i]);
+		kfree(parser->ibs);
+		if (parser->uf.bo)
+			drm_gem_object_unreference_unlocked(&parser->uf.bo->gem_base);
+	}
+
+	kfree(parser);
 }
 
 /**
@@ -533,12 +518,6 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
        amdgpu_cs_parser_fini_late(parser);
 }
 
-static int amdgpu_cs_parser_free_job(struct amdgpu_cs_parser *sched_job)
-{
-       amdgpu_cs_parser_fini_late(sched_job);
-       return 0;
-}
-
 static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 				   struct amdgpu_vm *vm)
 {
@@ -874,6 +853,19 @@ static struct amdgpu_ring *amdgpu_cs_parser_get_ring(
 	return ring;
 }
 
+static int amdgpu_cs_free_job(struct amdgpu_job *sched_job)
+{
+	int i;
+	amdgpu_ctx_put(sched_job->ctx);
+	if (sched_job->ibs)
+		for (i = 0; i < sched_job->num_ibs; i++)
+			amdgpu_ib_free(sched_job->adev, &sched_job->ibs[i]);
+	kfree(sched_job->ibs);
+	if (sched_job->uf.bo)
+		drm_gem_object_unreference_unlocked(&sched_job->uf.bo->gem_base);
+	return 0;
+}
+
 int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 {
 	struct amdgpu_device *adev = dev->dev_private;
@@ -900,33 +892,50 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	}
 
 	if (amdgpu_enable_scheduler && parser->num_ibs) {
+		struct amdgpu_job *job;
 		struct amdgpu_ring * ring =
 			amdgpu_cs_parser_get_ring(adev, parser);
 		r = amdgpu_cs_parser_prepare_job(parser);
 		if (r)
 			goto out;
-		parser->ring = ring;
-		parser->free_job = amdgpu_cs_parser_free_job;
-		mutex_lock(&parser->job_lock);
-		r = amd_sched_push_job(ring->scheduler,
-				       &parser->ctx->rings[ring->idx].entity,
-				       parser,
-				       &parser->s_fence);
+		job = kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
+		if (!job)
+			return -ENOMEM;
+		job->base.sched = ring->scheduler;
+		job->base.s_entity = &parser->ctx->rings[ring->idx].entity;
+		job->adev = parser->adev;
+		job->ibs = parser->ibs;
+		job->num_ibs = parser->num_ibs;
+		job->owner = parser->filp;
+		job->ctx = amdgpu_ctx_get_ref(parser->ctx);
+		mutex_init(&job->job_lock);
+		if (job->ibs[job->num_ibs - 1].user) {
+			memcpy(&job->uf,  &parser->uf,
+			       sizeof(struct amdgpu_user_fence));
+			job->ibs[job->num_ibs - 1].user = &job->uf;
+		}
+
+		job->free_job = amdgpu_cs_free_job;
+		mutex_lock(&job->job_lock);
+		r = amd_sched_push_job((struct amd_sched_job *)job);
 		if (r) {
-			mutex_unlock(&parser->job_lock);
+			mutex_unlock(&job->job_lock);
+			amdgpu_cs_free_job(job);
+			kfree(job);
 			goto out;
 		}
-		parser->ibs[parser->num_ibs - 1].sequence =
-			amdgpu_ctx_add_fence(parser->ctx, ring,
-					     &parser->s_fence->base,
-					     parser->s_fence->v_seq);
-		cs->out.handle = parser->s_fence->v_seq;
+		job->ibs[parser->num_ibs - 1].sequence =
+			amdgpu_ctx_add_fence(job->ctx, ring,
+					     &job->base.s_fence->base,
+					     job->base.s_fence->v_seq);
+		cs->out.handle = job->base.s_fence->v_seq;
 		list_sort(NULL, &parser->validated, cmp_size_smaller_first);
 		ttm_eu_fence_buffer_objects(&parser->ticket,
 				&parser->validated,
-				&parser->s_fence->base);
+				&job->base.s_fence->base);
 
-		mutex_unlock(&parser->job_lock);
+		mutex_unlock(&job->job_lock);
+		amdgpu_cs_parser_fini_late(parser);
 		up_read(&adev->exclusive_lock);
 		return 0;
 	}

commit 05906dec7d7daf197b9b773295c95ad6b9af2a5a
Author: Bas Nieuwenhuizen <bas@basnieuwenhuizen.nl>
Date:   Fri Aug 14 20:08:40 2015 +0200

    drm/amdgpu: wait on page directory changes. v2
    
    Pagetables can be moved and therefore the page directory update can be necessary
    for the current cs even if none of the the bo's are moved. In that scenario
    there is no fence between the sdma0 and gfx ring, so we add one.
    
    v2 (chk): rebased
    
    Signed-off-by: Bas Nieuwenhuizen <bas@basnieuwenhuizen.nl>
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 11edac725210..e4424b4db5d3 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -551,6 +551,10 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 	if (r)
 		return r;
 
+	r = amdgpu_sync_fence(adev, &p->ibs[0].sync, vm->page_directory_fence);
+	if (r)
+		return r;
+
 	r = amdgpu_vm_clear_freed(adev, vm);
 	if (r)
 		return r;

commit c3b95d4f9e460704e184ded7af60b9c4898f6181
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Fri Aug 14 14:55:27 2015 +0800

    drm/amdgpu: move prepare work out of scheduler to cs_ioctl
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 07e3380ee0f2..11edac725210 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -533,12 +533,6 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
        amdgpu_cs_parser_fini_late(parser);
 }
 
-static int amdgpu_cs_parser_run_job(struct amdgpu_cs_parser *sched_job)
-{
-       amdgpu_cs_parser_fini_early(sched_job, 0, true);
-       return 0;
-}
-
 static int amdgpu_cs_parser_free_job(struct amdgpu_cs_parser *sched_job)
 {
        amdgpu_cs_parser_fini_late(sched_job);
@@ -904,14 +898,10 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	if (amdgpu_enable_scheduler && parser->num_ibs) {
 		struct amdgpu_ring * ring =
 			amdgpu_cs_parser_get_ring(adev, parser);
-		if (ring->is_pte_ring || (parser->bo_list && parser->bo_list->has_userptr)) {
-			r = amdgpu_cs_parser_prepare_job(parser);
-			if (r)
-				goto out;
-		} else
-			parser->prepare_job = amdgpu_cs_parser_prepare_job;
+		r = amdgpu_cs_parser_prepare_job(parser);
+		if (r)
+			goto out;
 		parser->ring = ring;
-		parser->run_job = amdgpu_cs_parser_run_job;
 		parser->free_job = amdgpu_cs_parser_free_job;
 		mutex_lock(&parser->job_lock);
 		r = amd_sched_push_job(ring->scheduler,
@@ -927,6 +917,11 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 					     &parser->s_fence->base,
 					     parser->s_fence->v_seq);
 		cs->out.handle = parser->s_fence->v_seq;
+		list_sort(NULL, &parser->validated, cmp_size_smaller_first);
+		ttm_eu_fence_buffer_objects(&parser->ticket,
+				&parser->validated,
+				&parser->s_fence->base);
+
 		mutex_unlock(&parser->job_lock);
 		up_read(&adev->exclusive_lock);
 		return 0;

commit 1939e3e265d2fb984b56829c51f5843bfc6d5292
Author: monk.liu <monk.liu@amd.com>
Date:   Thu Aug 13 16:19:54 2015 +0800

    drm/amdgpu: drop bo_list_clone when no scheduler
    
    bo_list_clone() will take a lot of time when bo_list hold too much
    elements, like above 7000
    
    Signed-off-by: Monk.Liu <monk.liu@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Jammy Zhou <jammy.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 8796938216d6..07e3380ee0f2 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -186,15 +186,19 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		goto out;
 	}
 	bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
-	if (bo_list && !bo_list->has_userptr) {
-		p->bo_list = amdgpu_bo_list_clone(bo_list);
-		amdgpu_bo_list_put(bo_list);
-		if (!p->bo_list)
-			return -ENOMEM;
-	} else if (bo_list && bo_list->has_userptr)
+	if (!amdgpu_enable_scheduler)
 		p->bo_list = bo_list;
-	else
-		p->bo_list = NULL;
+	else {
+		if (bo_list && !bo_list->has_userptr) {
+			p->bo_list = amdgpu_bo_list_clone(bo_list);
+			amdgpu_bo_list_put(bo_list);
+			if (!p->bo_list)
+				return -ENOMEM;
+		} else if (bo_list && bo_list->has_userptr)
+			p->bo_list = bo_list;
+		else
+			p->bo_list = NULL;
+	}
 
 	/* get chunks */
 	INIT_LIST_HEAD(&p->validated);
@@ -495,7 +499,7 @@ static void amdgpu_cs_parser_fini_late(struct amdgpu_cs_parser *parser)
 	if (parser->ctx)
 		amdgpu_ctx_put(parser->ctx);
 	if (parser->bo_list) {
-		if (!parser->bo_list->has_userptr)
+		if (amdgpu_enable_scheduler && !parser->bo_list->has_userptr)
 			amdgpu_bo_list_free(parser->bo_list);
 		else
 			amdgpu_bo_list_put(parser->bo_list);

commit 281b42230175608dec0cd8dab9908250e7aa36a9
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Wed Aug 12 12:58:31 2015 +0800

    drm/amdgpu: add reference for **fence
    
    fix fence is released when pass to **fence sometimes.
    add reference for it.
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index f428288d8363..8796938216d6 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -136,6 +136,7 @@ static void amdgpu_job_work_func(struct work_struct *work)
 		sched_job->free_job(sched_job);
 	mutex_unlock(&sched_job->job_lock);
 	/* after processing job, free memory */
+	fence_put(&sched_job->s_fence->base);
 	kfree(sched_job);
 }
 struct amdgpu_cs_parser *amdgpu_cs_parser_create(struct amdgpu_device *adev,

commit f556cb0caeec1ba9b8e5e2aa85b47e76277f5d4b
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Sun Aug 2 11:18:04 2015 +0800

    drm/amd: add scheduler fence implementation (v2)
    
    scheduler fence is based on kernel fence framework.
    
    v2: squash in Christian's build fix
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index b1dc7e1ed271..f428288d8363 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -899,8 +899,6 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	if (amdgpu_enable_scheduler && parser->num_ibs) {
 		struct amdgpu_ring * ring =
 			amdgpu_cs_parser_get_ring(adev, parser);
-		parser->ibs[parser->num_ibs - 1].sequence = atomic64_inc_return(
-			&parser->ctx->rings[ring->idx].entity.last_queued_v_seq);
 		if (ring->is_pte_ring || (parser->bo_list && parser->bo_list->has_userptr)) {
 			r = amdgpu_cs_parser_prepare_job(parser);
 			if (r)
@@ -910,10 +908,21 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		parser->ring = ring;
 		parser->run_job = amdgpu_cs_parser_run_job;
 		parser->free_job = amdgpu_cs_parser_free_job;
-		amd_sched_push_job(ring->scheduler,
-				   &parser->ctx->rings[ring->idx].entity,
-				   parser);
-		cs->out.handle = parser->ibs[parser->num_ibs - 1].sequence;
+		mutex_lock(&parser->job_lock);
+		r = amd_sched_push_job(ring->scheduler,
+				       &parser->ctx->rings[ring->idx].entity,
+				       parser,
+				       &parser->s_fence);
+		if (r) {
+			mutex_unlock(&parser->job_lock);
+			goto out;
+		}
+		parser->ibs[parser->num_ibs - 1].sequence =
+			amdgpu_ctx_add_fence(parser->ctx, ring,
+					     &parser->s_fence->base,
+					     parser->s_fence->v_seq);
+		cs->out.handle = parser->s_fence->v_seq;
+		mutex_unlock(&parser->job_lock);
 		up_read(&adev->exclusive_lock);
 		return 0;
 	}

commit 91404fb20825418fd9ab8e6533bc336e1ffc748e
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Aug 5 18:33:21 2015 +0200

    drm/amdgpu: merge amd_sched_entity and amd_context_entity v2
    
    Avoiding a couple of casts.
    
    v2: rename c_entity to entity as well
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index d26688ddaa20..b1dc7e1ed271 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -900,7 +900,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		struct amdgpu_ring * ring =
 			amdgpu_cs_parser_get_ring(adev, parser);
 		parser->ibs[parser->num_ibs - 1].sequence = atomic64_inc_return(
-			&parser->ctx->rings[ring->idx].c_entity.last_queued_v_seq);
+			&parser->ctx->rings[ring->idx].entity.last_queued_v_seq);
 		if (ring->is_pte_ring || (parser->bo_list && parser->bo_list->has_userptr)) {
 			r = amdgpu_cs_parser_prepare_job(parser);
 			if (r)
@@ -911,7 +911,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		parser->run_job = amdgpu_cs_parser_run_job;
 		parser->free_job = amdgpu_cs_parser_free_job;
 		amd_sched_push_job(ring->scheduler,
-				   &parser->ctx->rings[ring->idx].c_entity,
+				   &parser->ctx->rings[ring->idx].entity,
 				   parser);
 		cs->out.handle = parser->ibs[parser->num_ibs - 1].sequence;
 		up_read(&adev->exclusive_lock);

commit 4cd7f42cf8f57512b13a13bb7dcbeabb644f5264
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Aug 5 18:18:52 2015 +0200

    drm/amdgpu: fix coding style in a couple of places
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index f72a8583b1a9..d26688ddaa20 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -528,15 +528,13 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
        amdgpu_cs_parser_fini_late(parser);
 }
 
-static int amdgpu_cs_parser_run_job(
-	struct amdgpu_cs_parser *sched_job)
+static int amdgpu_cs_parser_run_job(struct amdgpu_cs_parser *sched_job)
 {
        amdgpu_cs_parser_fini_early(sched_job, 0, true);
        return 0;
 }
 
-static int amdgpu_cs_parser_free_job(
-	struct amdgpu_cs_parser *sched_job)
+static int amdgpu_cs_parser_free_job(struct amdgpu_cs_parser *sched_job)
 {
        amdgpu_cs_parser_fini_late(sched_job);
        return 0;

commit 80de5913cf31c86d64547af0715de4822c9b1abe
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Wed Aug 5 19:07:08 2015 +0800

    Revert "drm/amdgpu: return new seq_no for amd_sched_push_job"
    
    This reverts commit d1d33da8eb86b8ca41dd9ed95738030df5267b95.
    
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>
    
    Conflicts:
            drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
            drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index aa1bc24b7edb..f72a8583b1a9 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -901,6 +901,8 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	if (amdgpu_enable_scheduler && parser->num_ibs) {
 		struct amdgpu_ring * ring =
 			amdgpu_cs_parser_get_ring(adev, parser);
+		parser->ibs[parser->num_ibs - 1].sequence = atomic64_inc_return(
+			&parser->ctx->rings[ring->idx].c_entity.last_queued_v_seq);
 		if (ring->is_pte_ring || (parser->bo_list && parser->bo_list->has_userptr)) {
 			r = amdgpu_cs_parser_prepare_job(parser);
 			if (r)
@@ -910,8 +912,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		parser->ring = ring;
 		parser->run_job = amdgpu_cs_parser_run_job;
 		parser->free_job = amdgpu_cs_parser_free_job;
-		parser->ibs[parser->num_ibs - 1].sequence =
-				   amd_sched_push_job(ring->scheduler,
+		amd_sched_push_job(ring->scheduler,
 				   &parser->ctx->rings[ring->idx].c_entity,
 				   parser);
 		cs->out.handle = parser->ibs[parser->num_ibs - 1].sequence;

commit 34cb581a7d99401cad0e1c43b528690885435f5b
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Aug 4 11:54:48 2015 +0200

    drm/amdgpu: fix bo list handling in CS
    
    We didn't initialized the mutex in the cloned bo list resulting in nice
    warnings from lockdep. Also fixes error handling in this function.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index d4cc232ccff3..aa1bc24b7edb 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -186,11 +186,10 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	}
 	bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
 	if (bo_list && !bo_list->has_userptr) {
-		p->bo_list = kzalloc(sizeof(struct amdgpu_bo_list), GFP_KERNEL);
+		p->bo_list = amdgpu_bo_list_clone(bo_list);
+		amdgpu_bo_list_put(bo_list);
 		if (!p->bo_list)
 			return -ENOMEM;
-		amdgpu_bo_list_copy(p->adev, p->bo_list, bo_list);
-		amdgpu_bo_list_put(bo_list);
 	} else if (bo_list && bo_list->has_userptr)
 		p->bo_list = bo_list;
 	else

commit 351dba73691fc632b269f531bbce80157f79c5b3
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Aug 3 20:39:12 2015 +0200

    drm/amdgpu: reorder the code to avoid forward declerations
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 468f884271b3..d4cc232ccff3 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -41,11 +41,6 @@ struct amdgpu_cs_buckets {
 	struct list_head bucket[AMDGPU_CS_NUM_BUCKETS];
 };
 
-static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser,
-				  int error, bool backoff);
-static void amdgpu_cs_parser_fini_early(struct amdgpu_cs_parser *parser, int error, bool backoff);
-static void amdgpu_cs_parser_fini_late(struct amdgpu_cs_parser *parser);
-
 static void amdgpu_cs_buckets_init(struct amdgpu_cs_buckets *b)
 {
 	unsigned i;
@@ -470,34 +465,6 @@ static int cmp_size_smaller_first(void *priv, struct list_head *a,
 	return (int)la->robj->tbo.num_pages - (int)lb->robj->tbo.num_pages;
 }
 
-/**
- * cs_parser_fini() - clean parser states
- * @parser:	parser structure holding parsing context.
- * @error:	error number
- *
- * If error is set than unvalidate buffer, otherwise just free memory
- * used by parsing context.
- **/
-static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bool backoff)
-{
-       amdgpu_cs_parser_fini_early(parser, error, backoff);
-       amdgpu_cs_parser_fini_late(parser);
-}
-
-static int amdgpu_cs_parser_run_job(
-	struct amdgpu_cs_parser *sched_job)
-{
-       amdgpu_cs_parser_fini_early(sched_job, 0, true);
-       return 0;
-}
-
-static int amdgpu_cs_parser_free_job(
-	struct amdgpu_cs_parser *sched_job)
-{
-       amdgpu_cs_parser_fini_late(sched_job);
-       return 0;
-}
-
 static void amdgpu_cs_parser_fini_early(struct amdgpu_cs_parser *parser, int error, bool backoff)
 {
 	if (!error) {
@@ -548,6 +515,34 @@ static void amdgpu_cs_parser_fini_late(struct amdgpu_cs_parser *parser)
 		kfree(parser);
 }
 
+/**
+ * cs_parser_fini() - clean parser states
+ * @parser:	parser structure holding parsing context.
+ * @error:	error number
+ *
+ * If error is set than unvalidate buffer, otherwise just free memory
+ * used by parsing context.
+ **/
+static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bool backoff)
+{
+       amdgpu_cs_parser_fini_early(parser, error, backoff);
+       amdgpu_cs_parser_fini_late(parser);
+}
+
+static int amdgpu_cs_parser_run_job(
+	struct amdgpu_cs_parser *sched_job)
+{
+       amdgpu_cs_parser_fini_early(sched_job, 0, true);
+       return 0;
+}
+
+static int amdgpu_cs_parser_free_job(
+	struct amdgpu_cs_parser *sched_job)
+{
+       amdgpu_cs_parser_fini_late(sched_job);
+       return 0;
+}
+
 static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 				   struct amdgpu_vm *vm)
 {

commit ea199cc9f825f3ef5aab3db5f00dcc639f8a8b02
Author: Jammy Zhou <Jammy.Zhou@amd.com>
Date:   Fri Jul 31 16:47:28 2015 +0800

    drm/amdgpu: return new seq_no for amd_sched_push_job
    
    It is clean to update last_queued_v_seq in the scheduler module
    
    Signed-off-by: Jammy Zhou <Jammy.Zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index fda7792d9e08..468f884271b3 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -907,8 +907,6 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	if (amdgpu_enable_scheduler && parser->num_ibs) {
 		struct amdgpu_ring * ring =
 			amdgpu_cs_parser_get_ring(adev, parser);
-		parser->ibs[parser->num_ibs - 1].sequence = atomic64_inc_return(
-			&parser->ctx->rings[ring->idx].c_entity.last_queued_v_seq);
 		if (ring->is_pte_ring || (parser->bo_list && parser->bo_list->has_userptr)) {
 			r = amdgpu_cs_parser_prepare_job(parser);
 			if (r)
@@ -918,7 +916,8 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		parser->ring = ring;
 		parser->run_job = amdgpu_cs_parser_run_job;
 		parser->free_job = amdgpu_cs_parser_free_job;
-		amd_sched_push_job(ring->scheduler,
+		parser->ibs[parser->num_ibs - 1].sequence =
+				   amd_sched_push_job(ring->scheduler,
 				   &parser->ctx->rings[ring->idx].c_entity,
 				   parser);
 		cs->out.handle = parser->ibs[parser->num_ibs - 1].sequence;

commit dd01d071957ded58d9bae3d3bf6061ada1d84692
Author: Jammy Zhou <Jammy.Zhou@amd.com>
Date:   Thu Jul 30 17:19:52 2015 +0800

    drm/amdgpu: some code refinement v2
    
    Fix the code alignment, etc.
    
    v2: rebase the code
    
    Signed-off-by: Jammy Zhou <Jammy.Zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index aee59110735f..fda7792d9e08 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -817,14 +817,14 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 
 static int amdgpu_cs_parser_prepare_job(struct amdgpu_cs_parser *sched_job)
 {
-        int r, i;
+	int r, i;
 	struct amdgpu_cs_parser *parser = sched_job;
 	struct amdgpu_device *adev = sched_job->adev;
-        bool reserved_buffers = false;
+	bool reserved_buffers = false;
 
-        r = amdgpu_cs_parser_relocs(parser);
-        if (r) {
-                if (r != -ERESTARTSYS) {
+	r = amdgpu_cs_parser_relocs(parser);
+	if (r) {
+		if (r != -ERESTARTSYS) {
 			if (r == -ENOMEM)
 				DRM_ERROR("Not enough memory for command submission!\n");
 			else
@@ -841,16 +841,16 @@ static int amdgpu_cs_parser_prepare_job(struct amdgpu_cs_parser *sched_job)
 		if (r)
 			DRM_ERROR("Failed in the dependencies handling %d!\n", r);
 	}
-        if (r) {
-                amdgpu_cs_parser_fini(parser, r, reserved_buffers);
-               return r;
-        }
+	if (r) {
+		amdgpu_cs_parser_fini(parser, r, reserved_buffers);
+		return r;
+	}
 
-        for (i = 0; i < parser->num_ibs; i++)
-                trace_amdgpu_cs(parser, i);
+	for (i = 0; i < parser->num_ibs; i++)
+		trace_amdgpu_cs(parser, i);
 
-       r = amdgpu_cs_ib_vm_chunk(adev, parser);
-       return r;
+	r = amdgpu_cs_ib_vm_chunk(adev, parser);
+	return r;
 }
 
 static struct amdgpu_ring *amdgpu_cs_parser_get_ring(

commit bb1e38a4bead5025ecca90544f0f733f59996b13
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Mon Aug 3 18:19:38 2015 +0800

    drm/amdgpu: use kernel fence for last_pt_update
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>
    Reviewed-by: Jammy Zhou <jammy.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index fe81b46266d9..aee59110735f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -581,7 +581,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 			if (r)
 				return r;
 
-			f = &bo_va->last_pt_update->base;
+			f = bo_va->last_pt_update;
 			r = amdgpu_sync_fence(adev, &p->ibs[0].sync, f);
 			if (r)
 				return r;

commit 7fc11959018f8ba2d92025679a72339da18a74ad
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Jul 30 11:53:42 2015 +0200

    drm/amdgpu: stop using addr to check for BO move v3
    
    It is theoretically possible that a swapped out BO gets the
    same GTT address, but different backing pages while being swapped in.
    
    Instead just use another VA state to note updated areas.
    Ported from not upstream yet radeon commit with the same name.
    
    v2: fix some bugs in the original implementation found in the radeon code.
    v3: squash in VCE/UVD fix
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 40e85bfcdf91..fe81b46266d9 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1009,7 +1009,16 @@ amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
 		if (!reloc->bo_va)
 			continue;
 
-		list_for_each_entry(mapping, &reloc->bo_va->mappings, list) {
+		list_for_each_entry(mapping, &reloc->bo_va->valids, list) {
+			if (mapping->it.start > addr ||
+			    addr > mapping->it.last)
+				continue;
+
+			*bo = reloc->bo_va->bo;
+			return mapping;
+		}
+
+		list_for_each_entry(mapping, &reloc->bo_va->invalids, list) {
 			if (mapping->it.start > addr ||
 			    addr > mapping->it.last)
 				continue;

commit d1ff9086c1b8e67390161599006a34056b437a72
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Thu Jul 30 17:59:43 2015 +0800

    drm/amdgpu: fix seq in ctx_add_fence
    
    if enabling scheduler, then the queued seq is assigned
    when pushing job before emitting job.
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index c41360e443be..40e85bfcdf91 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -739,7 +739,6 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 			ib->oa_size = amdgpu_bo_size(oa);
 		}
 	}
-
 	/* wrap the last IB with user fence */
 	if (parser->uf.bo) {
 		struct amdgpu_ib *ib = &parser->ibs[parser->num_ibs - 1];
@@ -908,7 +907,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	if (amdgpu_enable_scheduler && parser->num_ibs) {
 		struct amdgpu_ring * ring =
 			amdgpu_cs_parser_get_ring(adev, parser);
-		parser->uf.sequence = atomic64_inc_return(
+		parser->ibs[parser->num_ibs - 1].sequence = atomic64_inc_return(
 			&parser->ctx->rings[ring->idx].c_entity.last_queued_v_seq);
 		if (ring->is_pte_ring || (parser->bo_list && parser->bo_list->has_userptr)) {
 			r = amdgpu_cs_parser_prepare_job(parser);
@@ -922,7 +921,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		amd_sched_push_job(ring->scheduler,
 				   &parser->ctx->rings[ring->idx].c_entity,
 				   parser);
-		cs->out.handle = parser->uf.sequence;
+		cs->out.handle = parser->ibs[parser->num_ibs - 1].sequence;
 		up_read(&adev->exclusive_lock);
 		return 0;
 	}

commit afe10081498fdf2c5b92c7fcc534e49544218fb9
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Tue Jul 28 16:11:52 2015 +0800

    drm/amdgpu: add check for callback
    
    it is possible that the callback isn't defined sometimes.
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 9ff4d2756a6f..c41360e443be 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -137,7 +137,8 @@ static void amdgpu_job_work_func(struct work_struct *work)
 		container_of(work, struct amdgpu_cs_parser,
 			     job_work);
 	mutex_lock(&sched_job->job_lock);
-	sched_job->free_job(sched_job);
+	if (sched_job->free_job)
+		sched_job->free_job(sched_job);
 	mutex_unlock(&sched_job->job_lock);
 	/* after processing job, free memory */
 	kfree(sched_job);

commit 4274f5d45cf11f88d7380702a7147b70553ddd6e
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Tue Jul 21 16:04:39 2015 +0800

    drm/amdgpu: prepare job before push to sw queue for pte ring
    
    user mode will still use pte ring as a normal ring.
    if the prepare job generates another command(update pte) on its ring in scheduler,
    then will kill scheduler which is going to waiting later job but pending running job.
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Acked-by: Christian K?nig <christian.koenig@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 5f2403898b06..9ff4d2756a6f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -909,7 +909,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 			amdgpu_cs_parser_get_ring(adev, parser);
 		parser->uf.sequence = atomic64_inc_return(
 			&parser->ctx->rings[ring->idx].c_entity.last_queued_v_seq);
-		if ((parser->bo_list && parser->bo_list->has_userptr)) {
+		if (ring->is_pte_ring || (parser->bo_list && parser->bo_list->has_userptr)) {
 			r = amdgpu_cs_parser_prepare_job(parser);
 			if (r)
 				goto out;

commit 4b559c90bc1870313f02cceef680884519af6b2b
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Tue Jul 21 15:53:04 2015 +0800

    drm/amdgpu: make sure the fence is emitted before ring to get it.
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Acked-by: Christian K?nig <christian.koenig@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index f9d4fe985668..5f2403898b06 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -915,7 +915,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 				goto out;
 		} else
 			parser->prepare_job = amdgpu_cs_parser_prepare_job;
-
+		parser->ring = ring;
 		parser->run_job = amdgpu_cs_parser_run_job;
 		parser->free_job = amdgpu_cs_parser_free_job;
 		amd_sched_push_job(ring->scheduler,
@@ -965,24 +965,16 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 	ctx = amdgpu_ctx_get(filp->driver_priv, wait->in.ctx_id);
 	if (ctx == NULL)
 		return -EINVAL;
-	if (amdgpu_enable_scheduler) {
-		r = amd_sched_wait_ts(&ctx->rings[ring->idx].c_entity,
-				      wait->in.handle, true, timeout);
-		if (r)
-			return r;
-		r = 1;
-	} else {
-		fence = amdgpu_ctx_get_fence(ctx, ring, wait->in.handle);
-		if (IS_ERR(fence))
-			r = PTR_ERR(fence);
 
-		else if (fence) {
-			r = fence_wait_timeout(fence, true, timeout);
-			fence_put(fence);
+	fence = amdgpu_ctx_get_fence(ctx, ring, wait->in.handle);
+	if (IS_ERR(fence))
+		r = PTR_ERR(fence);
+	else if (fence) {
+		r = fence_wait_timeout(fence, true, timeout);
+		fence_put(fence);
+	} else
+		r = 1;
 
-		} else
-			r = 1;
-	}
 	amdgpu_ctx_put(ctx);
 	if (r < 0)
 		return r;

commit 049fc527b4641f99e573b26f1a726a3eadd0cc25
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Tue Jul 21 14:36:51 2015 +0800

    drm/amdgpu: dispatch jobs in cs
    
    BO validation is moved to scheduler except usrptr which must be validated
    in user process
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Acked-by: Christian K?nig <christian.koenig@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index bc0a70415485..f9d4fe985668 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -41,6 +41,11 @@ struct amdgpu_cs_buckets {
 	struct list_head bucket[AMDGPU_CS_NUM_BUCKETS];
 };
 
+static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser,
+				  int error, bool backoff);
+static void amdgpu_cs_parser_fini_early(struct amdgpu_cs_parser *parser, int error, bool backoff);
+static void amdgpu_cs_parser_fini_late(struct amdgpu_cs_parser *parser);
+
 static void amdgpu_cs_buckets_init(struct amdgpu_cs_buckets *b)
 {
 	unsigned i;
@@ -126,12 +131,52 @@ int amdgpu_cs_get_ring(struct amdgpu_device *adev, u32 ip_type,
 	return 0;
 }
 
+static void amdgpu_job_work_func(struct work_struct *work)
+{
+	struct amdgpu_cs_parser *sched_job =
+		container_of(work, struct amdgpu_cs_parser,
+			     job_work);
+	mutex_lock(&sched_job->job_lock);
+	sched_job->free_job(sched_job);
+	mutex_unlock(&sched_job->job_lock);
+	/* after processing job, free memory */
+	kfree(sched_job);
+}
+struct amdgpu_cs_parser *amdgpu_cs_parser_create(struct amdgpu_device *adev,
+                                               struct drm_file *filp,
+                                               struct amdgpu_ctx *ctx,
+                                               struct amdgpu_ib *ibs,
+                                               uint32_t num_ibs)
+{
+	struct amdgpu_cs_parser *parser;
+	int i;
+
+	parser = kzalloc(sizeof(struct amdgpu_cs_parser), GFP_KERNEL);
+	if (!parser)
+		return NULL;
+
+	parser->adev = adev;
+	parser->filp = filp;
+	parser->ctx = ctx;
+	parser->ibs = ibs;
+	parser->num_ibs = num_ibs;
+	if (amdgpu_enable_scheduler) {
+		mutex_init(&parser->job_lock);
+		INIT_WORK(&parser->job_work, amdgpu_job_work_func);
+	}
+	for (i = 0; i < num_ibs; i++)
+		ibs[i].ctx = ctx;
+
+	return parser;
+}
+
 int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 {
 	union drm_amdgpu_cs *cs = data;
 	uint64_t *chunk_array_user;
 	uint64_t *chunk_array = NULL;
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
+	struct amdgpu_bo_list *bo_list = NULL;
 	unsigned size, i;
 	int r = 0;
 
@@ -143,7 +188,17 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		r = -EINVAL;
 		goto out;
 	}
-	p->bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
+	bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
+	if (bo_list && !bo_list->has_userptr) {
+		p->bo_list = kzalloc(sizeof(struct amdgpu_bo_list), GFP_KERNEL);
+		if (!p->bo_list)
+			return -ENOMEM;
+		amdgpu_bo_list_copy(p->adev, p->bo_list, bo_list);
+		amdgpu_bo_list_put(bo_list);
+	} else if (bo_list && bo_list->has_userptr)
+		p->bo_list = bo_list;
+	else
+		p->bo_list = NULL;
 
 	/* get chunks */
 	INIT_LIST_HEAD(&p->validated);
@@ -424,8 +479,26 @@ static int cmp_size_smaller_first(void *priv, struct list_head *a,
  **/
 static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bool backoff)
 {
-	unsigned i;
+       amdgpu_cs_parser_fini_early(parser, error, backoff);
+       amdgpu_cs_parser_fini_late(parser);
+}
 
+static int amdgpu_cs_parser_run_job(
+	struct amdgpu_cs_parser *sched_job)
+{
+       amdgpu_cs_parser_fini_early(sched_job, 0, true);
+       return 0;
+}
+
+static int amdgpu_cs_parser_free_job(
+	struct amdgpu_cs_parser *sched_job)
+{
+       amdgpu_cs_parser_fini_late(sched_job);
+       return 0;
+}
+
+static void amdgpu_cs_parser_fini_early(struct amdgpu_cs_parser *parser, int error, bool backoff)
+{
 	if (!error) {
 		/* Sort the buffer list from the smallest to largest buffer,
 		 * which affects the order of buffers in the LRU list.
@@ -446,11 +519,19 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
 		ttm_eu_backoff_reservation(&parser->ticket,
 					   &parser->validated);
 	}
+}
 
+static void amdgpu_cs_parser_fini_late(struct amdgpu_cs_parser *parser)
+{
+	unsigned i;
 	if (parser->ctx)
 		amdgpu_ctx_put(parser->ctx);
-	if (parser->bo_list)
-		amdgpu_bo_list_put(parser->bo_list);
+	if (parser->bo_list) {
+		if (!parser->bo_list->has_userptr)
+			amdgpu_bo_list_free(parser->bo_list);
+		else
+			amdgpu_bo_list_put(parser->bo_list);
+	}
 	drm_free_large(parser->vm_bos);
 	for (i = 0; i < parser->nchunks; i++)
 		drm_free_large(parser->chunks[i].kdata);
@@ -461,6 +542,9 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
 	kfree(parser->ibs);
 	if (parser->uf.bo)
 		drm_gem_object_unreference_unlocked(&parser->uf.bo->gem_base);
+
+	if (!amdgpu_enable_scheduler)
+		kfree(parser);
 }
 
 static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
@@ -533,9 +617,9 @@ static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
 		goto out;
 	}
 	amdgpu_cs_sync_rings(parser);
-
-	r = amdgpu_ib_schedule(adev, parser->num_ibs, parser->ibs,
-			       parser->filp);
+	if (!amdgpu_enable_scheduler)
+		r = amdgpu_ib_schedule(adev, parser->num_ibs, parser->ibs,
+				       parser->filp);
 
 out:
 	mutex_unlock(&vm->mutex);
@@ -731,35 +815,16 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 	return 0;
 }
 
-int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
+static int amdgpu_cs_parser_prepare_job(struct amdgpu_cs_parser *sched_job)
 {
-	struct amdgpu_device *adev = dev->dev_private;
-	union drm_amdgpu_cs *cs = data;
-	struct amdgpu_cs_parser parser;
-	int r, i;
-	bool reserved_buffers = false;
-
-	down_read(&adev->exclusive_lock);
-	if (!adev->accel_working) {
-		up_read(&adev->exclusive_lock);
-		return -EBUSY;
-	}
-	/* initialize parser */
-	memset(&parser, 0, sizeof(struct amdgpu_cs_parser));
-	parser.filp = filp;
-	parser.adev = adev;
-	r = amdgpu_cs_parser_init(&parser, data);
-	if (r) {
-		DRM_ERROR("Failed to initialize parser !\n");
-		amdgpu_cs_parser_fini(&parser, r, false);
-		up_read(&adev->exclusive_lock);
-		r = amdgpu_cs_handle_lockup(adev, r);
-		return r;
-	}
-
-	r = amdgpu_cs_parser_relocs(&parser);
-	if (r) {
-		if (r != -ERESTARTSYS) {
+        int r, i;
+	struct amdgpu_cs_parser *parser = sched_job;
+	struct amdgpu_device *adev = sched_job->adev;
+        bool reserved_buffers = false;
+
+        r = amdgpu_cs_parser_relocs(parser);
+        if (r) {
+                if (r != -ERESTARTSYS) {
 			if (r == -ENOMEM)
 				DRM_ERROR("Not enough memory for command submission!\n");
 			else
@@ -769,33 +834,104 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 
 	if (!r) {
 		reserved_buffers = true;
-		r = amdgpu_cs_ib_fill(adev, &parser);
+		r = amdgpu_cs_ib_fill(adev, parser);
 	}
-
 	if (!r) {
-		r = amdgpu_cs_dependencies(adev, &parser);
+		r = amdgpu_cs_dependencies(adev, parser);
 		if (r)
 			DRM_ERROR("Failed in the dependencies handling %d!\n", r);
 	}
+        if (r) {
+                amdgpu_cs_parser_fini(parser, r, reserved_buffers);
+               return r;
+        }
+
+        for (i = 0; i < parser->num_ibs; i++)
+                trace_amdgpu_cs(parser, i);
+
+       r = amdgpu_cs_ib_vm_chunk(adev, parser);
+       return r;
+}
+
+static struct amdgpu_ring *amdgpu_cs_parser_get_ring(
+	struct amdgpu_device *adev,
+	struct amdgpu_cs_parser *parser)
+{
+	int i, r;
+
+	struct amdgpu_cs_chunk *chunk;
+	struct drm_amdgpu_cs_chunk_ib *chunk_ib;
+	struct amdgpu_ring *ring;
+	for (i = 0; i < parser->nchunks; i++) {
+		chunk = &parser->chunks[i];
+		chunk_ib = (struct drm_amdgpu_cs_chunk_ib *)chunk->kdata;
+
+		if (chunk->chunk_id != AMDGPU_CHUNK_ID_IB)
+			continue;
+
+		r = amdgpu_cs_get_ring(adev, chunk_ib->ip_type,
+				       chunk_ib->ip_instance, chunk_ib->ring,
+				       &ring);
+		if (r)
+			return NULL;
+		break;
+	}
+	return ring;
+}
+
+int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
+{
+	struct amdgpu_device *adev = dev->dev_private;
+	union drm_amdgpu_cs *cs = data;
+	struct amdgpu_cs_parser *parser;
+	int r;
+
+	down_read(&adev->exclusive_lock);
+	if (!adev->accel_working) {
+		up_read(&adev->exclusive_lock);
+		return -EBUSY;
+	}
 
+	parser = amdgpu_cs_parser_create(adev, filp, NULL, NULL, 0);
+	if (!parser)
+		return -ENOMEM;
+	r = amdgpu_cs_parser_init(parser, data);
 	if (r) {
-		amdgpu_cs_parser_fini(&parser, r, reserved_buffers);
+		DRM_ERROR("Failed to initialize parser !\n");
+		amdgpu_cs_parser_fini(parser, r, false);
 		up_read(&adev->exclusive_lock);
 		r = amdgpu_cs_handle_lockup(adev, r);
 		return r;
 	}
 
-	for (i = 0; i < parser.num_ibs; i++)
-		trace_amdgpu_cs(&parser, i);
-
-	r = amdgpu_cs_ib_vm_chunk(adev, &parser);
-	if (r) {
-		goto out;
+	if (amdgpu_enable_scheduler && parser->num_ibs) {
+		struct amdgpu_ring * ring =
+			amdgpu_cs_parser_get_ring(adev, parser);
+		parser->uf.sequence = atomic64_inc_return(
+			&parser->ctx->rings[ring->idx].c_entity.last_queued_v_seq);
+		if ((parser->bo_list && parser->bo_list->has_userptr)) {
+			r = amdgpu_cs_parser_prepare_job(parser);
+			if (r)
+				goto out;
+		} else
+			parser->prepare_job = amdgpu_cs_parser_prepare_job;
+
+		parser->run_job = amdgpu_cs_parser_run_job;
+		parser->free_job = amdgpu_cs_parser_free_job;
+		amd_sched_push_job(ring->scheduler,
+				   &parser->ctx->rings[ring->idx].c_entity,
+				   parser);
+		cs->out.handle = parser->uf.sequence;
+		up_read(&adev->exclusive_lock);
+		return 0;
 	}
+	r = amdgpu_cs_parser_prepare_job(parser);
+	if (r)
+		goto out;
 
-	cs->out.handle = parser.ibs[parser.num_ibs - 1].sequence;
+	cs->out.handle = parser->ibs[parser->num_ibs - 1].sequence;
 out:
-	amdgpu_cs_parser_fini(&parser, r, true);
+	amdgpu_cs_parser_fini(parser, r, true);
 	up_read(&adev->exclusive_lock);
 	r = amdgpu_cs_handle_lockup(adev, r);
 	return r;
@@ -829,18 +965,24 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 	ctx = amdgpu_ctx_get(filp->driver_priv, wait->in.ctx_id);
 	if (ctx == NULL)
 		return -EINVAL;
-
-	fence = amdgpu_ctx_get_fence(ctx, ring, wait->in.handle);
-	if (IS_ERR(fence))
-		r = PTR_ERR(fence);
-
-	else if (fence) {
-		r = fence_wait_timeout(fence, true, timeout);
-		fence_put(fence);
-
-	} else
+	if (amdgpu_enable_scheduler) {
+		r = amd_sched_wait_ts(&ctx->rings[ring->idx].c_entity,
+				      wait->in.handle, true, timeout);
+		if (r)
+			return r;
 		r = 1;
+	} else {
+		fence = amdgpu_ctx_get_fence(ctx, ring, wait->in.handle);
+		if (IS_ERR(fence))
+			r = PTR_ERR(fence);
 
+		else if (fence) {
+			r = fence_wait_timeout(fence, true, timeout);
+			fence_put(fence);
+
+		} else
+			r = 1;
+	}
 	amdgpu_ctx_put(ctx);
 	if (r < 0)
 		return r;

commit e60b344f6c0eff03362b5083db746ef5442c4b36
Author: monk.liu <monk.liu@amd.com>
Date:   Fri Jul 17 18:39:25 2015 +0800

    drm/amdgpu: optimize amdgpu_parser_init
    
    use kmalloc_array instead of kcalloc where appropriate and other
    cleanups.
    
    Signed-off-by: monk.liu <monk.liu@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 4794e14976ca..bc0a70415485 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -147,13 +147,13 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 
 	/* get chunks */
 	INIT_LIST_HEAD(&p->validated);
-	chunk_array = kcalloc(cs->in.num_chunks, sizeof(uint64_t), GFP_KERNEL);
+	chunk_array = kmalloc_array(cs->in.num_chunks, sizeof(uint64_t), GFP_KERNEL);
 	if (chunk_array == NULL) {
 		r = -ENOMEM;
 		goto out;
 	}
 
-	chunk_array_user = (uint64_t *)(unsigned long)(cs->in.chunks);
+	chunk_array_user = (uint64_t __user *)(cs->in.chunks);
 	if (copy_from_user(chunk_array, chunk_array_user,
 			   sizeof(uint64_t)*cs->in.num_chunks)) {
 		r = -EFAULT;
@@ -161,7 +161,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	}
 
 	p->nchunks = cs->in.num_chunks;
-	p->chunks = kcalloc(p->nchunks, sizeof(struct amdgpu_cs_chunk),
+	p->chunks = kmalloc_array(p->nchunks, sizeof(struct amdgpu_cs_chunk),
 			    GFP_KERNEL);
 	if (p->chunks == NULL) {
 		r = -ENOMEM;
@@ -173,7 +173,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		struct drm_amdgpu_cs_chunk user_chunk;
 		uint32_t __user *cdata;
 
-		chunk_ptr = (void __user *)(unsigned long)chunk_array[i];
+		chunk_ptr = (void __user *)chunk_array[i];
 		if (copy_from_user(&user_chunk, chunk_ptr,
 				       sizeof(struct drm_amdgpu_cs_chunk))) {
 			r = -EFAULT;
@@ -183,7 +183,7 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		p->chunks[i].length_dw = user_chunk.length_dw;
 
 		size = p->chunks[i].length_dw;
-		cdata = (void __user *)(unsigned long)user_chunk.chunk_data;
+		cdata = (void __user *)user_chunk.chunk_data;
 		p->chunks[i].user_ptr = cdata;
 
 		p->chunks[i].kdata = drm_malloc_ab(size, sizeof(uint32_t));
@@ -235,11 +235,10 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		}
 	}
 
-	p->ibs = kcalloc(p->num_ibs, sizeof(struct amdgpu_ib), GFP_KERNEL);
-	if (!p->ibs) {
+
+	p->ibs = kmalloc_array(p->num_ibs, sizeof(struct amdgpu_ib), GFP_KERNEL);
+	if (!p->ibs)
 		r = -ENOMEM;
-		goto out;
-	}
 
 out:
 	kfree(chunk_array);

commit 5430a3ffb0b1902e8aea4ed2ba256b1263126e8d
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Jul 21 18:02:21 2015 +0200

    drm/amdgpu: fix UVD/VCE fence handling
    
    We need to return the sequence number to userspace
    even when we don't use user fences.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index cef8360698be..4794e14976ca 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -794,7 +794,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		goto out;
 	}
 
-	cs->out.handle = parser.uf.sequence;
+	cs->out.handle = parser.ibs[parser.num_ibs - 1].sequence;
 out:
 	amdgpu_cs_parser_fini(&parser, r, true);
 	up_read(&adev->exclusive_lock);

commit 21c16bf634e62cf9673946f509b469e7f0953ecf
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Jul 7 17:24:49 2015 +0200

    drm/amdgpu: add user fence context map v2
    
    This is a prerequisite for the GPU scheduler to make the order
    of submission independent from the order of execution.
    
    v2: properly implement the locking
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 53e6a10fe9f9..cef8360698be 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -698,9 +698,9 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 			sizeof(struct drm_amdgpu_cs_chunk_dep);
 
 		for (j = 0; j < num_deps; ++j) {
-			struct amdgpu_fence *fence;
 			struct amdgpu_ring *ring;
 			struct amdgpu_ctx *ctx;
+			struct fence *fence;
 
 			r = amdgpu_cs_get_ring(adev, deps[j].ip_type,
 					       deps[j].ip_instance,
@@ -712,20 +712,20 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 			if (ctx == NULL)
 				return -EINVAL;
 
-			r = amdgpu_fence_recreate(ring, p->filp,
-						  deps[j].handle,
-						  &fence);
-			if (r) {
+			fence = amdgpu_ctx_get_fence(ctx, ring,
+						     deps[j].handle);
+			if (IS_ERR(fence)) {
+				r = PTR_ERR(fence);
 				amdgpu_ctx_put(ctx);
 				return r;
-			}
-
-			r = amdgpu_sync_fence(adev, &ib->sync, &fence->base);
-			amdgpu_fence_unref(&fence);
-			amdgpu_ctx_put(ctx);
 
-			if (r)
-				return r;
+			} else if (fence) {
+				r = amdgpu_sync_fence(adev, &ib->sync, fence);
+				fence_put(fence);
+				amdgpu_ctx_put(ctx);
+				if (r)
+					return r;
+			}
 		}
 	}
 
@@ -773,8 +773,11 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		r = amdgpu_cs_ib_fill(adev, &parser);
 	}
 
-	if (!r)
+	if (!r) {
 		r = amdgpu_cs_dependencies(adev, &parser);
+		if (r)
+			DRM_ERROR("Failed in the dependencies handling %d!\n", r);
+	}
 
 	if (r) {
 		amdgpu_cs_parser_fini(&parser, r, reserved_buffers);
@@ -791,7 +794,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		goto out;
 	}
 
-	cs->out.handle = parser.ibs[parser.num_ibs - 1].fence->seq;
+	cs->out.handle = parser.uf.sequence;
 out:
 	amdgpu_cs_parser_fini(&parser, r, true);
 	up_read(&adev->exclusive_lock);
@@ -814,30 +817,31 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 	union drm_amdgpu_wait_cs *wait = data;
 	struct amdgpu_device *adev = dev->dev_private;
 	unsigned long timeout = amdgpu_gem_timeout(wait->in.timeout);
-	struct amdgpu_fence *fence = NULL;
 	struct amdgpu_ring *ring = NULL;
 	struct amdgpu_ctx *ctx;
+	struct fence *fence;
 	long r;
 
+	r = amdgpu_cs_get_ring(adev, wait->in.ip_type, wait->in.ip_instance,
+			       wait->in.ring, &ring);
+	if (r)
+		return r;
+
 	ctx = amdgpu_ctx_get(filp->driver_priv, wait->in.ctx_id);
 	if (ctx == NULL)
 		return -EINVAL;
 
-	r = amdgpu_cs_get_ring(adev, wait->in.ip_type, wait->in.ip_instance,
-			       wait->in.ring, &ring);
-	if (r) {
-		amdgpu_ctx_put(ctx);
-		return r;
-	}
+	fence = amdgpu_ctx_get_fence(ctx, ring, wait->in.handle);
+	if (IS_ERR(fence))
+		r = PTR_ERR(fence);
 
-	r = amdgpu_fence_recreate(ring, filp, wait->in.handle, &fence);
-	if (r) {
-		amdgpu_ctx_put(ctx);
-		return r;
-	}
+	else if (fence) {
+		r = fence_wait_timeout(fence, true, timeout);
+		fence_put(fence);
+
+	} else
+		r = 1;
 
-	r = fence_wait_timeout(&fence->base, true, timeout);
-	amdgpu_fence_unref(&fence);
 	amdgpu_ctx_put(ctx);
 	if (r < 0)
 		return r;

commit 91e1a5207edec9e4f888e44478a9a254186e0ba8
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jul 6 22:06:40 2015 +0200

    drm/amdgpu: deal with foreign fences in amdgpu_sync
    
    This also requires some error handling from the callers of that function.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 1f040d85ac47..53e6a10fe9f9 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -482,6 +482,8 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 
 	if (p->bo_list) {
 		for (i = 0; i < p->bo_list->num_entries; i++) {
+			struct fence *f;
+
 			/* ignore duplicates */
 			bo = p->bo_list->array[i].robj;
 			if (!bo)
@@ -495,7 +497,10 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 			if (r)
 				return r;
 
-			amdgpu_sync_fence(&p->ibs[0].sync, bo_va->last_pt_update);
+			f = &bo_va->last_pt_update->base;
+			r = amdgpu_sync_fence(adev, &p->ibs[0].sync, f);
+			if (r)
+				return r;
 		}
 	}
 
@@ -715,9 +720,12 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 				return r;
 			}
 
-			amdgpu_sync_fence(&ib->sync, fence);
+			r = amdgpu_sync_fence(adev, &ib->sync, &fence->base);
 			amdgpu_fence_unref(&fence);
 			amdgpu_ctx_put(ctx);
+
+			if (r)
+				return r;
 		}
 	}
 

commit 5c2327beed49efa3198b8468e78b1182eb0b764b
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Jul 7 17:27:03 2015 +0200

    drm/amdgpu: stop context leak in the error path
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 469b6f2364bc..1f040d85ac47 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -817,12 +817,16 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 
 	r = amdgpu_cs_get_ring(adev, wait->in.ip_type, wait->in.ip_instance,
 			       wait->in.ring, &ring);
-	if (r)
+	if (r) {
+		amdgpu_ctx_put(ctx);
 		return r;
+	}
 
 	r = amdgpu_fence_recreate(ring, filp, wait->in.handle, &fence);
-	if (r)
+	if (r) {
+		amdgpu_ctx_put(ctx);
 		return r;
+	}
 
 	r = fence_wait_timeout(&fence->base, true, timeout);
 	amdgpu_fence_unref(&fence);

commit 76a1ea618f01b2bf5a325832d1c273c039c4ea81
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jul 6 19:42:10 2015 +0200

    drm/amdgpu: validate the context id in the dependencies
    
    Just to make sure userspace don't send nonsense to the kernel.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index d63135bf29c0..469b6f2364bc 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -669,6 +669,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 				  struct amdgpu_cs_parser *p)
 {
+	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_ib *ib;
 	int i, j, r;
 
@@ -694,6 +695,7 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 		for (j = 0; j < num_deps; ++j) {
 			struct amdgpu_fence *fence;
 			struct amdgpu_ring *ring;
+			struct amdgpu_ctx *ctx;
 
 			r = amdgpu_cs_get_ring(adev, deps[j].ip_type,
 					       deps[j].ip_instance,
@@ -701,14 +703,21 @@ static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
 			if (r)
 				return r;
 
+			ctx = amdgpu_ctx_get(fpriv, deps[j].ctx_id);
+			if (ctx == NULL)
+				return -EINVAL;
+
 			r = amdgpu_fence_recreate(ring, p->filp,
 						  deps[j].handle,
 						  &fence);
-			if (r)
+			if (r) {
+				amdgpu_ctx_put(ctx);
 				return r;
+			}
 
 			amdgpu_sync_fence(&ib->sync, fence);
 			amdgpu_fence_unref(&fence);
+			amdgpu_ctx_put(ctx);
 		}
 	}
 

commit 2b48d323b26c37555df3447e11ab9e962eccdc26
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Jun 19 17:31:29 2015 +0200

    drm/amdgpu: add optional dependencies to the CS IOCTL v2
    
    v2: remove unrelated whitespace change, fix C comment
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 84ba1d1bf327..d63135bf29c0 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -226,6 +226,9 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 			}
 			break;
 
+		case AMDGPU_CHUNK_ID_DEPENDENCIES:
+			break;
+
 		default:
 			r = -EINVAL;
 			goto out;
@@ -663,6 +666,55 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 	return 0;
 }
 
+static int amdgpu_cs_dependencies(struct amdgpu_device *adev,
+				  struct amdgpu_cs_parser *p)
+{
+	struct amdgpu_ib *ib;
+	int i, j, r;
+
+	if (!p->num_ibs)
+		return 0;
+
+	/* Add dependencies to first IB */
+	ib = &p->ibs[0];
+	for (i = 0; i < p->nchunks; ++i) {
+		struct drm_amdgpu_cs_chunk_dep *deps;
+		struct amdgpu_cs_chunk *chunk;
+		unsigned num_deps;
+
+		chunk = &p->chunks[i];
+
+		if (chunk->chunk_id != AMDGPU_CHUNK_ID_DEPENDENCIES)
+			continue;
+
+		deps = (struct drm_amdgpu_cs_chunk_dep *)chunk->kdata;
+		num_deps = chunk->length_dw * 4 /
+			sizeof(struct drm_amdgpu_cs_chunk_dep);
+
+		for (j = 0; j < num_deps; ++j) {
+			struct amdgpu_fence *fence;
+			struct amdgpu_ring *ring;
+
+			r = amdgpu_cs_get_ring(adev, deps[j].ip_type,
+					       deps[j].ip_instance,
+					       deps[j].ring, &ring);
+			if (r)
+				return r;
+
+			r = amdgpu_fence_recreate(ring, p->filp,
+						  deps[j].handle,
+						  &fence);
+			if (r)
+				return r;
+
+			amdgpu_sync_fence(&ib->sync, fence);
+			amdgpu_fence_unref(&fence);
+		}
+	}
+
+	return 0;
+}
+
 int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 {
 	struct amdgpu_device *adev = dev->dev_private;
@@ -697,11 +749,16 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 			else
 				DRM_ERROR("Failed to process the buffer list %d!\n", r);
 		}
-	} else {
+	}
+
+	if (!r) {
 		reserved_buffers = true;
 		r = amdgpu_cs_ib_fill(adev, &parser);
 	}
 
+	if (!r)
+		r = amdgpu_cs_dependencies(adev, &parser);
+
 	if (r) {
 		amdgpu_cs_parser_fini(&parser, r, reserved_buffers);
 		up_read(&adev->exclusive_lock);

commit 03507c4f2f63d8d98c2455cf4d192589fac553c7
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Jun 19 17:00:19 2015 +0200

    drm/amdgpu: recreate fence from user seq
    
    And use common fence infrastructure for the wait.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 86b78c799176..84ba1d1bf327 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -739,9 +739,9 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 {
 	union drm_amdgpu_wait_cs *wait = data;
 	struct amdgpu_device *adev = dev->dev_private;
-	uint64_t seq[AMDGPU_MAX_RINGS] = {0};
-	struct amdgpu_ring *ring = NULL;
 	unsigned long timeout = amdgpu_gem_timeout(wait->in.timeout);
+	struct amdgpu_fence *fence = NULL;
+	struct amdgpu_ring *ring = NULL;
 	struct amdgpu_ctx *ctx;
 	long r;
 
@@ -754,9 +754,12 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 	if (r)
 		return r;
 
-	seq[ring->idx] = wait->in.handle;
+	r = amdgpu_fence_recreate(ring, filp, wait->in.handle, &fence);
+	if (r)
+		return r;
 
-	r = amdgpu_fence_wait_seq_timeout(adev, seq, true, timeout);
+	r = fence_wait_timeout(&fence->base, true, timeout);
+	amdgpu_fence_unref(&fence);
 	amdgpu_ctx_put(ctx);
 	if (r < 0)
 		return r;

commit 9a5e8fb1c8372ea4b58a76bbb82cb97683bb204b
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Jun 23 17:07:03 2015 +0200

    drm/amdgpu: add chunk id validity check
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 7cd567b268fd..86b78c799176 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -181,8 +181,6 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		}
 		p->chunks[i].chunk_id = user_chunk.chunk_id;
 		p->chunks[i].length_dw = user_chunk.length_dw;
-		if (p->chunks[i].chunk_id == AMDGPU_CHUNK_ID_IB)
-			p->num_ibs++;
 
 		size = p->chunks[i].length_dw;
 		cdata = (void __user *)(unsigned long)user_chunk.chunk_data;
@@ -199,7 +197,12 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 			goto out;
 		}
 
-		if (p->chunks[i].chunk_id == AMDGPU_CHUNK_ID_FENCE) {
+		switch (p->chunks[i].chunk_id) {
+		case AMDGPU_CHUNK_ID_IB:
+			p->num_ibs++;
+			break;
+
+		case AMDGPU_CHUNK_ID_FENCE:
 			size = sizeof(struct drm_amdgpu_cs_chunk_fence);
 			if (p->chunks[i].length_dw * sizeof(uint32_t) >= size) {
 				uint32_t handle;
@@ -221,6 +224,11 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 				r = -EINVAL;
 				goto out;
 			}
+			break;
+
+		default:
+			r = -EINVAL;
+			goto out;
 		}
 	}
 

commit b8682ac253bdab6c15678f926bdc028b2e5dc0d2
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jun 22 14:54:32 2015 +0200

    drm/amdgpu: fix crash on invalid CS IOCTL
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index f09b2cba40ca..7cd567b268fd 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -445,8 +445,9 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
 	for (i = 0; i < parser->nchunks; i++)
 		drm_free_large(parser->chunks[i].kdata);
 	kfree(parser->chunks);
-	for (i = 0; i < parser->num_ibs; i++)
-		amdgpu_ib_free(parser->adev, &parser->ibs[i]);
+	if (parser->ibs)
+		for (i = 0; i < parser->num_ibs; i++)
+			amdgpu_ib_free(parser->adev, &parser->ibs[i]);
 	kfree(parser->ibs);
 	if (parser->uf.bo)
 		drm_gem_object_unreference_unlocked(&parser->uf.bo->gem_base);

commit 4802ce11778664a69b308c5aa9b95350b76793be
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Jun 10 17:20:11 2015 +0200

    drm/amdgpu: fix UVD/VCE VM emulation
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index f6b224a69b3a..f09b2cba40ca 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -564,21 +564,33 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 			return r;
 
 		if (ring->funcs->parse_cs) {
+			struct amdgpu_bo_va_mapping *m;
 			struct amdgpu_bo *aobj = NULL;
-			void *kptr;
+			uint64_t offset;
+			uint8_t *kptr;
 
-			amdgpu_cs_find_mapping(parser, chunk_ib->va_start, &aobj);
+			m = amdgpu_cs_find_mapping(parser, chunk_ib->va_start,
+						   &aobj);
 			if (!aobj) {
 				DRM_ERROR("IB va_start is invalid\n");
 				return -EINVAL;
 			}
 
+			if ((chunk_ib->va_start + chunk_ib->ib_bytes) >
+			    (m->it.last + 1) * AMDGPU_GPU_PAGE_SIZE) {
+				DRM_ERROR("IB va_start+ib_bytes is invalid\n");
+				return -EINVAL;
+			}
+
 			/* the IB should be reserved at this point */
-			r = amdgpu_bo_kmap(aobj, &kptr);
+			r = amdgpu_bo_kmap(aobj, (void **)&kptr);
 			if (r) {
 				return r;
 			}
 
+			offset = ((uint64_t)m->it.start) * AMDGPU_GPU_PAGE_SIZE;
+			kptr += chunk_ib->va_start - offset;
+
 			r =  amdgpu_ib_get(ring, NULL, chunk_ib->ib_bytes, ib);
 			if (r) {
 				DRM_ERROR("Failed to get ib !\n");

commit 3ccec53c294cbec2af44b6b24f70349637c45428
Author: Marek Olšák <marek.olsak@amd.com>
Date:   Tue Jun 2 17:44:49 2015 +0200

    drm/amdgpu: only support IBs in the buffer list (v2)
    
    amdgpu_cs_find_mapping doesn't work without all buffers being validated,
    so the TTM validation must be done first.
    
    v2: only use amdgpu_cs_find_mapping for UVD/VCE VM emulation
    
    Signed-off-by: Marek Olšák <marek.olsak@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index fefa48a59a7d..f6b224a69b3a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -230,11 +230,6 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 		goto out;
 	}
 
-	p->ib_bos = kcalloc(p->num_ibs, sizeof(struct amdgpu_bo_list_entry),
-			    GFP_KERNEL);
-	if (!p->ib_bos)
-		r = -ENOMEM;
-
 out:
 	kfree(chunk_array);
 	return r;
@@ -373,13 +368,6 @@ static int amdgpu_cs_parser_relocs(struct amdgpu_cs_parser *p)
 	p->vm_bos = amdgpu_vm_get_bos(p->adev, &fpriv->vm,
 				      &p->validated);
 
-	for (i = 0; i < p->num_ibs; i++) {
-		if (!p->ib_bos[i].robj)
-			continue;
-
-		list_add(&p->ib_bos[i].tv.head, &p->validated);
-	}
-
 	if (need_mmap_lock)
 		down_read(&current->mm->mmap_sem);
 
@@ -457,15 +445,9 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
 	for (i = 0; i < parser->nchunks; i++)
 		drm_free_large(parser->chunks[i].kdata);
 	kfree(parser->chunks);
-	for (i = 0; i < parser->num_ibs; i++) {
-		struct amdgpu_bo *bo = parser->ib_bos[i].robj;
+	for (i = 0; i < parser->num_ibs; i++)
 		amdgpu_ib_free(parser->adev, &parser->ibs[i]);
-
-		if (bo)
-			drm_gem_object_unreference_unlocked(&bo->gem_base);
-	}
 	kfree(parser->ibs);
-	kfree(parser->ib_bos);
 	if (parser->uf.bo)
 		drm_gem_object_unreference_unlocked(&parser->uf.bo->gem_base);
 }
@@ -505,21 +487,6 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 		}
 	}
 
-	for (i = 0; i < p->num_ibs; i++) {
-		bo = p->ib_bos[i].robj;
-		if (!bo)
-			continue;
-
-		bo_va = p->ib_bos[i].bo_va;
-		if (!bo_va)
-			continue;
-
-		r = amdgpu_vm_bo_update(adev, bo_va, &bo->tbo.mem);
-		if (r)
-			return r;
-
-		amdgpu_sync_fence(&p->ibs[0].sync, bo_va->last_pt_update);
-	}
 	return amdgpu_vm_clear_invalids(adev, vm, &p->ibs[0].sync);
 }
 
@@ -581,11 +548,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		struct amdgpu_cs_chunk *chunk;
 		struct amdgpu_ib *ib;
 		struct drm_amdgpu_cs_chunk_ib *chunk_ib;
-		struct amdgpu_bo_list_entry *ib_bo;
 		struct amdgpu_ring *ring;
-		struct drm_gem_object *gobj;
-		struct amdgpu_bo *aobj;
-		void *kptr;
 
 		chunk = &parser->chunks[i];
 		ib = &parser->ibs[j];
@@ -594,66 +557,49 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		if (chunk->chunk_id != AMDGPU_CHUNK_ID_IB)
 			continue;
 
-		gobj = drm_gem_object_lookup(adev->ddev, parser->filp, chunk_ib->handle);
-		if (gobj == NULL)
-			return -ENOENT;
-		aobj = gem_to_amdgpu_bo(gobj);
-
 		r = amdgpu_cs_get_ring(adev, chunk_ib->ip_type,
 				       chunk_ib->ip_instance, chunk_ib->ring,
 				       &ring);
-		if (r) {
-			drm_gem_object_unreference_unlocked(gobj);
+		if (r)
 			return r;
-		}
 
 		if (ring->funcs->parse_cs) {
-			r = amdgpu_bo_reserve(aobj, false);
-			if (r) {
-				drm_gem_object_unreference_unlocked(gobj);
-				return r;
+			struct amdgpu_bo *aobj = NULL;
+			void *kptr;
+
+			amdgpu_cs_find_mapping(parser, chunk_ib->va_start, &aobj);
+			if (!aobj) {
+				DRM_ERROR("IB va_start is invalid\n");
+				return -EINVAL;
 			}
 
+			/* the IB should be reserved at this point */
 			r = amdgpu_bo_kmap(aobj, &kptr);
 			if (r) {
-				amdgpu_bo_unreserve(aobj);
-				drm_gem_object_unreference_unlocked(gobj);
 				return r;
 			}
 
 			r =  amdgpu_ib_get(ring, NULL, chunk_ib->ib_bytes, ib);
 			if (r) {
 				DRM_ERROR("Failed to get ib !\n");
-				amdgpu_bo_unreserve(aobj);
-				drm_gem_object_unreference_unlocked(gobj);
 				return r;
 			}
 
 			memcpy(ib->ptr, kptr, chunk_ib->ib_bytes);
 			amdgpu_bo_kunmap(aobj);
-			amdgpu_bo_unreserve(aobj);
 		} else {
 			r =  amdgpu_ib_get(ring, vm, 0, ib);
 			if (r) {
 				DRM_ERROR("Failed to get ib !\n");
-				drm_gem_object_unreference_unlocked(gobj);
 				return r;
 			}
 
 			ib->gpu_addr = chunk_ib->va_start;
 		}
-		ib->length_dw = chunk_ib->ib_bytes / 4;
 
+		ib->length_dw = chunk_ib->ib_bytes / 4;
 		ib->flags = chunk_ib->flags;
 		ib->ctx = parser->ctx;
-
-		ib_bo = &parser->ib_bos[j];
-		ib_bo->robj = aobj;
-		ib_bo->prefered_domains = aobj->initial_domain;
-		ib_bo->allowed_domains = aobj->initial_domain;
-		ib_bo->priority = 0;
-		ib_bo->tv.bo = &aobj->tbo;
-		ib_bo->tv.shared = true;
 		j++;
 	}
 
@@ -702,6 +648,7 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 	union drm_amdgpu_cs *cs = data;
 	struct amdgpu_cs_parser parser;
 	int r, i;
+	bool reserved_buffers = false;
 
 	down_read(&adev->exclusive_lock);
 	if (!adev->accel_working) {
@@ -721,15 +668,21 @@ int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 		return r;
 	}
 
-	r = amdgpu_cs_ib_fill(adev, &parser);
-	if (!r) {
-		r = amdgpu_cs_parser_relocs(&parser);
-		if (r && r != -ERESTARTSYS)
-			DRM_ERROR("Failed to parse relocation %d!\n", r);
+	r = amdgpu_cs_parser_relocs(&parser);
+	if (r) {
+		if (r != -ERESTARTSYS) {
+			if (r == -ENOMEM)
+				DRM_ERROR("Not enough memory for command submission!\n");
+			else
+				DRM_ERROR("Failed to process the buffer list %d!\n", r);
+		}
+	} else {
+		reserved_buffers = true;
+		r = amdgpu_cs_ib_fill(adev, &parser);
 	}
 
 	if (r) {
-		amdgpu_cs_parser_fini(&parser, r, false);
+		amdgpu_cs_parser_fini(&parser, r, reserved_buffers);
 		up_read(&adev->exclusive_lock);
 		r = amdgpu_cs_handle_lockup(adev, r);
 		return r;

commit cfe2c9780756b63af695078c110b755876b09dfc
Author: monk.liu <monk.liu@amd.com>
Date:   Tue May 26 15:01:54 2015 +0800

    drm/amdgpu: sync fence of clear_invalids (v2)
    
    bo_va may un-initialized, fix it.
    
    Signed-off-by: monk.liu <monk.liu@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Jammy Zhou <jammy.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index ecb30a1a73cc..fefa48a59a7d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -520,7 +520,7 @@ static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
 
 		amdgpu_sync_fence(&p->ibs[0].sync, bo_va->last_pt_update);
 	}
-	return amdgpu_vm_clear_invalids(adev, vm);
+	return amdgpu_vm_clear_invalids(adev, vm, &p->ibs[0].sync);
 }
 
 static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,

commit 3cb485f34049b7f3a00f6f73d2325e0858f64ddb
Author: Christian König <christian.koenig@amd.com>
Date:   Mon May 11 15:34:59 2015 +0200

    drm/amdgpu: fix context switch
    
    Properly protect the state and also handle submission failures.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>
    Reviewed-by: Monk Liu <monk.liu@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index de17f845a84b..ecb30a1a73cc 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -138,7 +138,11 @@ int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
 	if (!cs->in.num_chunks)
 		goto out;
 
-	p->ctx_id = cs->in.ctx_id;
+	p->ctx = amdgpu_ctx_get(fpriv, cs->in.ctx_id);
+	if (!p->ctx) {
+		r = -EINVAL;
+		goto out;
+	}
 	p->bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
 
 	/* get chunks */
@@ -445,6 +449,8 @@ static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bo
 					   &parser->validated);
 	}
 
+	if (parser->ctx)
+		amdgpu_ctx_put(parser->ctx);
 	if (parser->bo_list)
 		amdgpu_bo_list_put(parser->bo_list);
 	drm_free_large(parser->vm_bos);
@@ -639,13 +645,7 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		ib->length_dw = chunk_ib->ib_bytes / 4;
 
 		ib->flags = chunk_ib->flags;
-
-		if ((ib->ring->current_filp != parser->filp) ||
-		    (ib->ring->current_ctx != parser->ctx_id)) {
-			ib->ring->need_ctx_switch = true;
-			ib->ring->current_ctx = parser->ctx_id;
-			ib->ring->current_filp = parser->filp;
-		}
+		ib->ctx = parser->ctx;
 
 		ib_bo = &parser->ib_bos[j];
 		ib_bo->robj = aobj;

commit de807f818b953f11b9a132a2d1997711a79bbfa3
Author: Jammy Zhou <Jammy.Zhou@amd.com>
Date:   Mon May 11 23:41:41 2015 +0800

    drm/amdgpu: add flags for amdgpu_ib structure
    
    Signed-off-by: Jammy Zhou <Jammy.Zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 1035e443700f..de17f845a84b 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -638,10 +638,8 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 		}
 		ib->length_dw = chunk_ib->ib_bytes / 4;
 
-		if (chunk_ib->flags & AMDGPU_IB_FLAG_CE)
-			ib->is_const_ib = true;
-		if (chunk_ib->flags & AMDGPU_IB_FLAG_GDS)
-			ib->gds_needed = true;
+		ib->flags = chunk_ib->flags;
+
 		if ((ib->ring->current_filp != parser->filp) ||
 		    (ib->ring->current_ctx != parser->ctx_id)) {
 			ib->ring->need_ctx_switch = true;

commit 72efa7ebdea084b96f25021d0ba9c29074c2906f
Author: Jammy Zhou <Jammy.Zhou@amd.com>
Date:   Fri May 8 22:18:47 2015 +0800

    drm/amdgpu: check context id for context switching (v2)
    
    check the filp is not robust, and sometimes different contexts may
    have same filp value.
    
    v2: check both filp and ctx_id
    
    Signed-off-by: Jammy Zhou <Jammy.Zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 86b93245bf9d..1035e443700f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -642,8 +642,10 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 			ib->is_const_ib = true;
 		if (chunk_ib->flags & AMDGPU_IB_FLAG_GDS)
 			ib->gds_needed = true;
-		if (ib->ring->current_filp != parser->filp) {
+		if ((ib->ring->current_filp != parser->filp) ||
+		    (ib->ring->current_ctx != parser->ctx_id)) {
 			ib->ring->need_ctx_switch = true;
+			ib->ring->current_ctx = parser->ctx_id;
 			ib->ring->current_filp = parser->filp;
 		}
 

commit 66b3cf2ab38f47db2d07fe24a00972fbf822cd74
Author: Jammy Zhou <Jammy.Zhou@amd.com>
Date:   Fri May 8 17:29:40 2015 +0800

    drm/amdgpu: add ctx_id to the WAIT_CS IOCTL (v4)
    
    It is required to support fence per context.
    
    v2: add amdgpu_ctx_get/put
    v3: improve get/put
    v4: squash hlock fix
    
    Signed-off-by: Jammy Zhou <Jammy.Zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index ffbe9aa9f232..86b93245bf9d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -768,8 +768,13 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 	uint64_t seq[AMDGPU_MAX_RINGS] = {0};
 	struct amdgpu_ring *ring = NULL;
 	unsigned long timeout = amdgpu_gem_timeout(wait->in.timeout);
+	struct amdgpu_ctx *ctx;
 	long r;
 
+	ctx = amdgpu_ctx_get(filp->driver_priv, wait->in.ctx_id);
+	if (ctx == NULL)
+		return -EINVAL;
+
 	r = amdgpu_cs_get_ring(adev, wait->in.ip_type, wait->in.ip_instance,
 			       wait->in.ring, &ring);
 	if (r)
@@ -778,6 +783,7 @@ int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
 	seq[ring->idx] = wait->in.handle;
 
 	r = amdgpu_fence_wait_seq_timeout(adev, seq, true, timeout);
+	amdgpu_ctx_put(ctx);
 	if (r < 0)
 		return r;
 

commit 840d51445f1527bda37b5d48a203ecff7988ad2b
Author: monk.liu <monk.liu@amd.com>
Date:   Mon Apr 27 15:19:20 2015 +0800

    drm/amdgpu: fix bug occurs when bo_list is NULL
    
    Still need to handle ibs BO and validate them even bo_list is NULL
    
    Signed-off-by: Monk.Liu <monk.liu@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 70a90312d0a4..ffbe9aa9f232 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -353,19 +353,19 @@ static int amdgpu_cs_parser_relocs(struct amdgpu_cs_parser *p)
 {
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_cs_buckets buckets;
-	bool need_mmap_lock;
+	bool need_mmap_lock = false;
 	int i, r;
 
-	if (p->bo_list == NULL)
-		return 0;
+	if (p->bo_list) {
+		need_mmap_lock = p->bo_list->has_userptr;
+		amdgpu_cs_buckets_init(&buckets);
+		for (i = 0; i < p->bo_list->num_entries; i++)
+			amdgpu_cs_buckets_add(&buckets, &p->bo_list->array[i].tv.head,
+								  p->bo_list->array[i].priority);
 
-	need_mmap_lock = p->bo_list->has_userptr;
-	amdgpu_cs_buckets_init(&buckets);
-	for (i = 0; i < p->bo_list->num_entries; i++)
-		amdgpu_cs_buckets_add(&buckets, &p->bo_list->array[i].tv.head,
-					      p->bo_list->array[i].priority);
+		amdgpu_cs_buckets_get_list(&buckets, &p->validated);
+	}
 
-	amdgpu_cs_buckets_get_list(&buckets, &p->validated);
 	p->vm_bos = amdgpu_vm_get_bos(p->adev, &fpriv->vm,
 				      &p->validated);
 

commit d38ceaf99ed015f2a0b9af3499791bd3a3daae21
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Mon Apr 20 16:55:21 2015 -0400

    drm/amdgpu: add core driver (v4)
    
    This adds the non-asic specific core driver code.
    
    v2: remove extra kconfig option
    v3: implement minor fixes from Fengguang Wu
    v4: fix cast in amdgpu_ucode.c
    
    Acked-by: Christian König <christian.koenig@amd.com>
    Acked-by: Jammy Zhou <Jammy.Zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
new file mode 100644
index 000000000000..70a90312d0a4
--- /dev/null
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -0,0 +1,825 @@
+/*
+ * Copyright 2008 Jerome Glisse.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * PRECISION INSIGHT AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * Authors:
+ *    Jerome Glisse <glisse@freedesktop.org>
+ */
+#include <linux/list_sort.h>
+#include <drm/drmP.h>
+#include <drm/amdgpu_drm.h>
+#include "amdgpu.h"
+#include "amdgpu_trace.h"
+
+#define AMDGPU_CS_MAX_PRIORITY		32u
+#define AMDGPU_CS_NUM_BUCKETS		(AMDGPU_CS_MAX_PRIORITY + 1)
+
+/* This is based on the bucket sort with O(n) time complexity.
+ * An item with priority "i" is added to bucket[i]. The lists are then
+ * concatenated in descending order.
+ */
+struct amdgpu_cs_buckets {
+	struct list_head bucket[AMDGPU_CS_NUM_BUCKETS];
+};
+
+static void amdgpu_cs_buckets_init(struct amdgpu_cs_buckets *b)
+{
+	unsigned i;
+
+	for (i = 0; i < AMDGPU_CS_NUM_BUCKETS; i++)
+		INIT_LIST_HEAD(&b->bucket[i]);
+}
+
+static void amdgpu_cs_buckets_add(struct amdgpu_cs_buckets *b,
+				  struct list_head *item, unsigned priority)
+{
+	/* Since buffers which appear sooner in the relocation list are
+	 * likely to be used more often than buffers which appear later
+	 * in the list, the sort mustn't change the ordering of buffers
+	 * with the same priority, i.e. it must be stable.
+	 */
+	list_add_tail(item, &b->bucket[min(priority, AMDGPU_CS_MAX_PRIORITY)]);
+}
+
+static void amdgpu_cs_buckets_get_list(struct amdgpu_cs_buckets *b,
+				       struct list_head *out_list)
+{
+	unsigned i;
+
+	/* Connect the sorted buckets in the output list. */
+	for (i = 0; i < AMDGPU_CS_NUM_BUCKETS; i++) {
+		list_splice(&b->bucket[i], out_list);
+	}
+}
+
+int amdgpu_cs_get_ring(struct amdgpu_device *adev, u32 ip_type,
+		       u32 ip_instance, u32 ring,
+		       struct amdgpu_ring **out_ring)
+{
+	/* Right now all IPs have only one instance - multiple rings. */
+	if (ip_instance != 0) {
+		DRM_ERROR("invalid ip instance: %d\n", ip_instance);
+		return -EINVAL;
+	}
+
+	switch (ip_type) {
+	default:
+		DRM_ERROR("unknown ip type: %d\n", ip_type);
+		return -EINVAL;
+	case AMDGPU_HW_IP_GFX:
+		if (ring < adev->gfx.num_gfx_rings) {
+			*out_ring = &adev->gfx.gfx_ring[ring];
+		} else {
+			DRM_ERROR("only %d gfx rings are supported now\n",
+				  adev->gfx.num_gfx_rings);
+			return -EINVAL;
+		}
+		break;
+	case AMDGPU_HW_IP_COMPUTE:
+		if (ring < adev->gfx.num_compute_rings) {
+			*out_ring = &adev->gfx.compute_ring[ring];
+		} else {
+			DRM_ERROR("only %d compute rings are supported now\n",
+				  adev->gfx.num_compute_rings);
+			return -EINVAL;
+		}
+		break;
+	case AMDGPU_HW_IP_DMA:
+		if (ring < 2) {
+			*out_ring = &adev->sdma[ring].ring;
+		} else {
+			DRM_ERROR("only two SDMA rings are supported\n");
+			return -EINVAL;
+		}
+		break;
+	case AMDGPU_HW_IP_UVD:
+		*out_ring = &adev->uvd.ring;
+		break;
+	case AMDGPU_HW_IP_VCE:
+		if (ring < 2){
+			*out_ring = &adev->vce.ring[ring];
+		} else {
+			DRM_ERROR("only two VCE rings are supported\n");
+			return -EINVAL;
+		}
+		break;
+	}
+	return 0;
+}
+
+int amdgpu_cs_parser_init(struct amdgpu_cs_parser *p, void *data)
+{
+	union drm_amdgpu_cs *cs = data;
+	uint64_t *chunk_array_user;
+	uint64_t *chunk_array = NULL;
+	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
+	unsigned size, i;
+	int r = 0;
+
+	if (!cs->in.num_chunks)
+		goto out;
+
+	p->ctx_id = cs->in.ctx_id;
+	p->bo_list = amdgpu_bo_list_get(fpriv, cs->in.bo_list_handle);
+
+	/* get chunks */
+	INIT_LIST_HEAD(&p->validated);
+	chunk_array = kcalloc(cs->in.num_chunks, sizeof(uint64_t), GFP_KERNEL);
+	if (chunk_array == NULL) {
+		r = -ENOMEM;
+		goto out;
+	}
+
+	chunk_array_user = (uint64_t *)(unsigned long)(cs->in.chunks);
+	if (copy_from_user(chunk_array, chunk_array_user,
+			   sizeof(uint64_t)*cs->in.num_chunks)) {
+		r = -EFAULT;
+		goto out;
+	}
+
+	p->nchunks = cs->in.num_chunks;
+	p->chunks = kcalloc(p->nchunks, sizeof(struct amdgpu_cs_chunk),
+			    GFP_KERNEL);
+	if (p->chunks == NULL) {
+		r = -ENOMEM;
+		goto out;
+	}
+
+	for (i = 0; i < p->nchunks; i++) {
+		struct drm_amdgpu_cs_chunk __user **chunk_ptr = NULL;
+		struct drm_amdgpu_cs_chunk user_chunk;
+		uint32_t __user *cdata;
+
+		chunk_ptr = (void __user *)(unsigned long)chunk_array[i];
+		if (copy_from_user(&user_chunk, chunk_ptr,
+				       sizeof(struct drm_amdgpu_cs_chunk))) {
+			r = -EFAULT;
+			goto out;
+		}
+		p->chunks[i].chunk_id = user_chunk.chunk_id;
+		p->chunks[i].length_dw = user_chunk.length_dw;
+		if (p->chunks[i].chunk_id == AMDGPU_CHUNK_ID_IB)
+			p->num_ibs++;
+
+		size = p->chunks[i].length_dw;
+		cdata = (void __user *)(unsigned long)user_chunk.chunk_data;
+		p->chunks[i].user_ptr = cdata;
+
+		p->chunks[i].kdata = drm_malloc_ab(size, sizeof(uint32_t));
+		if (p->chunks[i].kdata == NULL) {
+			r = -ENOMEM;
+			goto out;
+		}
+		size *= sizeof(uint32_t);
+		if (copy_from_user(p->chunks[i].kdata, cdata, size)) {
+			r = -EFAULT;
+			goto out;
+		}
+
+		if (p->chunks[i].chunk_id == AMDGPU_CHUNK_ID_FENCE) {
+			size = sizeof(struct drm_amdgpu_cs_chunk_fence);
+			if (p->chunks[i].length_dw * sizeof(uint32_t) >= size) {
+				uint32_t handle;
+				struct drm_gem_object *gobj;
+				struct drm_amdgpu_cs_chunk_fence *fence_data;
+
+				fence_data = (void *)p->chunks[i].kdata;
+				handle = fence_data->handle;
+				gobj = drm_gem_object_lookup(p->adev->ddev,
+							     p->filp, handle);
+				if (gobj == NULL) {
+					r = -EINVAL;
+					goto out;
+				}
+
+				p->uf.bo = gem_to_amdgpu_bo(gobj);
+				p->uf.offset = fence_data->offset;
+			} else {
+				r = -EINVAL;
+				goto out;
+			}
+		}
+	}
+
+	p->ibs = kcalloc(p->num_ibs, sizeof(struct amdgpu_ib), GFP_KERNEL);
+	if (!p->ibs) {
+		r = -ENOMEM;
+		goto out;
+	}
+
+	p->ib_bos = kcalloc(p->num_ibs, sizeof(struct amdgpu_bo_list_entry),
+			    GFP_KERNEL);
+	if (!p->ib_bos)
+		r = -ENOMEM;
+
+out:
+	kfree(chunk_array);
+	return r;
+}
+
+/* Returns how many bytes TTM can move per IB.
+ */
+static u64 amdgpu_cs_get_threshold_for_moves(struct amdgpu_device *adev)
+{
+	u64 real_vram_size = adev->mc.real_vram_size;
+	u64 vram_usage = atomic64_read(&adev->vram_usage);
+
+	/* This function is based on the current VRAM usage.
+	 *
+	 * - If all of VRAM is free, allow relocating the number of bytes that
+	 *   is equal to 1/4 of the size of VRAM for this IB.
+
+	 * - If more than one half of VRAM is occupied, only allow relocating
+	 *   1 MB of data for this IB.
+	 *
+	 * - From 0 to one half of used VRAM, the threshold decreases
+	 *   linearly.
+	 *         __________________
+	 * 1/4 of -|\               |
+	 * VRAM    | \              |
+	 *         |  \             |
+	 *         |   \            |
+	 *         |    \           |
+	 *         |     \          |
+	 *         |      \         |
+	 *         |       \________|1 MB
+	 *         |----------------|
+	 *    VRAM 0 %             100 %
+	 *         used            used
+	 *
+	 * Note: It's a threshold, not a limit. The threshold must be crossed
+	 * for buffer relocations to stop, so any buffer of an arbitrary size
+	 * can be moved as long as the threshold isn't crossed before
+	 * the relocation takes place. We don't want to disable buffer
+	 * relocations completely.
+	 *
+	 * The idea is that buffers should be placed in VRAM at creation time
+	 * and TTM should only do a minimum number of relocations during
+	 * command submission. In practice, you need to submit at least
+	 * a dozen IBs to move all buffers to VRAM if they are in GTT.
+	 *
+	 * Also, things can get pretty crazy under memory pressure and actual
+	 * VRAM usage can change a lot, so playing safe even at 50% does
+	 * consistently increase performance.
+	 */
+
+	u64 half_vram = real_vram_size >> 1;
+	u64 half_free_vram = vram_usage >= half_vram ? 0 : half_vram - vram_usage;
+	u64 bytes_moved_threshold = half_free_vram >> 1;
+	return max(bytes_moved_threshold, 1024*1024ull);
+}
+
+int amdgpu_cs_list_validate(struct amdgpu_cs_parser *p)
+{
+	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
+	struct amdgpu_vm *vm = &fpriv->vm;
+	struct amdgpu_device *adev = p->adev;
+	struct amdgpu_bo_list_entry *lobj;
+	struct list_head duplicates;
+	struct amdgpu_bo *bo;
+	u64 bytes_moved = 0, initial_bytes_moved;
+	u64 bytes_moved_threshold = amdgpu_cs_get_threshold_for_moves(adev);
+	int r;
+
+	INIT_LIST_HEAD(&duplicates);
+	r = ttm_eu_reserve_buffers(&p->ticket, &p->validated, true, &duplicates);
+	if (unlikely(r != 0)) {
+		return r;
+	}
+
+	list_for_each_entry(lobj, &p->validated, tv.head) {
+		bo = lobj->robj;
+		if (!bo->pin_count) {
+			u32 domain = lobj->prefered_domains;
+			u32 current_domain =
+				amdgpu_mem_type_to_domain(bo->tbo.mem.mem_type);
+
+			/* Check if this buffer will be moved and don't move it
+			 * if we have moved too many buffers for this IB already.
+			 *
+			 * Note that this allows moving at least one buffer of
+			 * any size, because it doesn't take the current "bo"
+			 * into account. We don't want to disallow buffer moves
+			 * completely.
+			 */
+			if (current_domain != AMDGPU_GEM_DOMAIN_CPU &&
+			    (domain & current_domain) == 0 && /* will be moved */
+			    bytes_moved > bytes_moved_threshold) {
+				/* don't move it */
+				domain = current_domain;
+			}
+
+		retry:
+			amdgpu_ttm_placement_from_domain(bo, domain);
+			initial_bytes_moved = atomic64_read(&adev->num_bytes_moved);
+			r = ttm_bo_validate(&bo->tbo, &bo->placement, true, false);
+			bytes_moved += atomic64_read(&adev->num_bytes_moved) -
+				       initial_bytes_moved;
+
+			if (unlikely(r)) {
+				if (r != -ERESTARTSYS && domain != lobj->allowed_domains) {
+					domain = lobj->allowed_domains;
+					goto retry;
+				}
+				ttm_eu_backoff_reservation(&p->ticket, &p->validated);
+				return r;
+			}
+		}
+		lobj->bo_va = amdgpu_vm_bo_find(vm, bo);
+	}
+	return 0;
+}
+
+static int amdgpu_cs_parser_relocs(struct amdgpu_cs_parser *p)
+{
+	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
+	struct amdgpu_cs_buckets buckets;
+	bool need_mmap_lock;
+	int i, r;
+
+	if (p->bo_list == NULL)
+		return 0;
+
+	need_mmap_lock = p->bo_list->has_userptr;
+	amdgpu_cs_buckets_init(&buckets);
+	for (i = 0; i < p->bo_list->num_entries; i++)
+		amdgpu_cs_buckets_add(&buckets, &p->bo_list->array[i].tv.head,
+					      p->bo_list->array[i].priority);
+
+	amdgpu_cs_buckets_get_list(&buckets, &p->validated);
+	p->vm_bos = amdgpu_vm_get_bos(p->adev, &fpriv->vm,
+				      &p->validated);
+
+	for (i = 0; i < p->num_ibs; i++) {
+		if (!p->ib_bos[i].robj)
+			continue;
+
+		list_add(&p->ib_bos[i].tv.head, &p->validated);
+	}
+
+	if (need_mmap_lock)
+		down_read(&current->mm->mmap_sem);
+
+	r = amdgpu_cs_list_validate(p);
+
+	if (need_mmap_lock)
+		up_read(&current->mm->mmap_sem);
+
+	return r;
+}
+
+static int amdgpu_cs_sync_rings(struct amdgpu_cs_parser *p)
+{
+	struct amdgpu_bo_list_entry *e;
+	int r;
+
+	list_for_each_entry(e, &p->validated, tv.head) {
+		struct reservation_object *resv = e->robj->tbo.resv;
+		r = amdgpu_sync_resv(p->adev, &p->ibs[0].sync, resv, p->filp);
+
+		if (r)
+			return r;
+	}
+	return 0;
+}
+
+static int cmp_size_smaller_first(void *priv, struct list_head *a,
+				  struct list_head *b)
+{
+	struct amdgpu_bo_list_entry *la = list_entry(a, struct amdgpu_bo_list_entry, tv.head);
+	struct amdgpu_bo_list_entry *lb = list_entry(b, struct amdgpu_bo_list_entry, tv.head);
+
+	/* Sort A before B if A is smaller. */
+	return (int)la->robj->tbo.num_pages - (int)lb->robj->tbo.num_pages;
+}
+
+/**
+ * cs_parser_fini() - clean parser states
+ * @parser:	parser structure holding parsing context.
+ * @error:	error number
+ *
+ * If error is set than unvalidate buffer, otherwise just free memory
+ * used by parsing context.
+ **/
+static void amdgpu_cs_parser_fini(struct amdgpu_cs_parser *parser, int error, bool backoff)
+{
+	unsigned i;
+
+	if (!error) {
+		/* Sort the buffer list from the smallest to largest buffer,
+		 * which affects the order of buffers in the LRU list.
+		 * This assures that the smallest buffers are added first
+		 * to the LRU list, so they are likely to be later evicted
+		 * first, instead of large buffers whose eviction is more
+		 * expensive.
+		 *
+		 * This slightly lowers the number of bytes moved by TTM
+		 * per frame under memory pressure.
+		 */
+		list_sort(NULL, &parser->validated, cmp_size_smaller_first);
+
+		ttm_eu_fence_buffer_objects(&parser->ticket,
+				&parser->validated,
+				&parser->ibs[parser->num_ibs-1].fence->base);
+	} else if (backoff) {
+		ttm_eu_backoff_reservation(&parser->ticket,
+					   &parser->validated);
+	}
+
+	if (parser->bo_list)
+		amdgpu_bo_list_put(parser->bo_list);
+	drm_free_large(parser->vm_bos);
+	for (i = 0; i < parser->nchunks; i++)
+		drm_free_large(parser->chunks[i].kdata);
+	kfree(parser->chunks);
+	for (i = 0; i < parser->num_ibs; i++) {
+		struct amdgpu_bo *bo = parser->ib_bos[i].robj;
+		amdgpu_ib_free(parser->adev, &parser->ibs[i]);
+
+		if (bo)
+			drm_gem_object_unreference_unlocked(&bo->gem_base);
+	}
+	kfree(parser->ibs);
+	kfree(parser->ib_bos);
+	if (parser->uf.bo)
+		drm_gem_object_unreference_unlocked(&parser->uf.bo->gem_base);
+}
+
+static int amdgpu_bo_vm_update_pte(struct amdgpu_cs_parser *p,
+				   struct amdgpu_vm *vm)
+{
+	struct amdgpu_device *adev = p->adev;
+	struct amdgpu_bo_va *bo_va;
+	struct amdgpu_bo *bo;
+	int i, r;
+
+	r = amdgpu_vm_update_page_directory(adev, vm);
+	if (r)
+		return r;
+
+	r = amdgpu_vm_clear_freed(adev, vm);
+	if (r)
+		return r;
+
+	if (p->bo_list) {
+		for (i = 0; i < p->bo_list->num_entries; i++) {
+			/* ignore duplicates */
+			bo = p->bo_list->array[i].robj;
+			if (!bo)
+				continue;
+
+			bo_va = p->bo_list->array[i].bo_va;
+			if (bo_va == NULL)
+				continue;
+
+			r = amdgpu_vm_bo_update(adev, bo_va, &bo->tbo.mem);
+			if (r)
+				return r;
+
+			amdgpu_sync_fence(&p->ibs[0].sync, bo_va->last_pt_update);
+		}
+	}
+
+	for (i = 0; i < p->num_ibs; i++) {
+		bo = p->ib_bos[i].robj;
+		if (!bo)
+			continue;
+
+		bo_va = p->ib_bos[i].bo_va;
+		if (!bo_va)
+			continue;
+
+		r = amdgpu_vm_bo_update(adev, bo_va, &bo->tbo.mem);
+		if (r)
+			return r;
+
+		amdgpu_sync_fence(&p->ibs[0].sync, bo_va->last_pt_update);
+	}
+	return amdgpu_vm_clear_invalids(adev, vm);
+}
+
+static int amdgpu_cs_ib_vm_chunk(struct amdgpu_device *adev,
+				 struct amdgpu_cs_parser *parser)
+{
+	struct amdgpu_fpriv *fpriv = parser->filp->driver_priv;
+	struct amdgpu_vm *vm = &fpriv->vm;
+	struct amdgpu_ring *ring;
+	int i, r;
+
+	if (parser->num_ibs == 0)
+		return 0;
+
+	/* Only for UVD/VCE VM emulation */
+	for (i = 0; i < parser->num_ibs; i++) {
+		ring = parser->ibs[i].ring;
+		if (ring->funcs->parse_cs) {
+			r = amdgpu_ring_parse_cs(ring, parser, i);
+			if (r)
+				return r;
+		}
+	}
+
+	mutex_lock(&vm->mutex);
+	r = amdgpu_bo_vm_update_pte(parser, vm);
+	if (r) {
+		goto out;
+	}
+	amdgpu_cs_sync_rings(parser);
+
+	r = amdgpu_ib_schedule(adev, parser->num_ibs, parser->ibs,
+			       parser->filp);
+
+out:
+	mutex_unlock(&vm->mutex);
+	return r;
+}
+
+static int amdgpu_cs_handle_lockup(struct amdgpu_device *adev, int r)
+{
+	if (r == -EDEADLK) {
+		r = amdgpu_gpu_reset(adev);
+		if (!r)
+			r = -EAGAIN;
+	}
+	return r;
+}
+
+static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
+			     struct amdgpu_cs_parser *parser)
+{
+	struct amdgpu_fpriv *fpriv = parser->filp->driver_priv;
+	struct amdgpu_vm *vm = &fpriv->vm;
+	int i, j;
+	int r;
+
+	for (i = 0, j = 0; i < parser->nchunks && j < parser->num_ibs; i++) {
+		struct amdgpu_cs_chunk *chunk;
+		struct amdgpu_ib *ib;
+		struct drm_amdgpu_cs_chunk_ib *chunk_ib;
+		struct amdgpu_bo_list_entry *ib_bo;
+		struct amdgpu_ring *ring;
+		struct drm_gem_object *gobj;
+		struct amdgpu_bo *aobj;
+		void *kptr;
+
+		chunk = &parser->chunks[i];
+		ib = &parser->ibs[j];
+		chunk_ib = (struct drm_amdgpu_cs_chunk_ib *)chunk->kdata;
+
+		if (chunk->chunk_id != AMDGPU_CHUNK_ID_IB)
+			continue;
+
+		gobj = drm_gem_object_lookup(adev->ddev, parser->filp, chunk_ib->handle);
+		if (gobj == NULL)
+			return -ENOENT;
+		aobj = gem_to_amdgpu_bo(gobj);
+
+		r = amdgpu_cs_get_ring(adev, chunk_ib->ip_type,
+				       chunk_ib->ip_instance, chunk_ib->ring,
+				       &ring);
+		if (r) {
+			drm_gem_object_unreference_unlocked(gobj);
+			return r;
+		}
+
+		if (ring->funcs->parse_cs) {
+			r = amdgpu_bo_reserve(aobj, false);
+			if (r) {
+				drm_gem_object_unreference_unlocked(gobj);
+				return r;
+			}
+
+			r = amdgpu_bo_kmap(aobj, &kptr);
+			if (r) {
+				amdgpu_bo_unreserve(aobj);
+				drm_gem_object_unreference_unlocked(gobj);
+				return r;
+			}
+
+			r =  amdgpu_ib_get(ring, NULL, chunk_ib->ib_bytes, ib);
+			if (r) {
+				DRM_ERROR("Failed to get ib !\n");
+				amdgpu_bo_unreserve(aobj);
+				drm_gem_object_unreference_unlocked(gobj);
+				return r;
+			}
+
+			memcpy(ib->ptr, kptr, chunk_ib->ib_bytes);
+			amdgpu_bo_kunmap(aobj);
+			amdgpu_bo_unreserve(aobj);
+		} else {
+			r =  amdgpu_ib_get(ring, vm, 0, ib);
+			if (r) {
+				DRM_ERROR("Failed to get ib !\n");
+				drm_gem_object_unreference_unlocked(gobj);
+				return r;
+			}
+
+			ib->gpu_addr = chunk_ib->va_start;
+		}
+		ib->length_dw = chunk_ib->ib_bytes / 4;
+
+		if (chunk_ib->flags & AMDGPU_IB_FLAG_CE)
+			ib->is_const_ib = true;
+		if (chunk_ib->flags & AMDGPU_IB_FLAG_GDS)
+			ib->gds_needed = true;
+		if (ib->ring->current_filp != parser->filp) {
+			ib->ring->need_ctx_switch = true;
+			ib->ring->current_filp = parser->filp;
+		}
+
+		ib_bo = &parser->ib_bos[j];
+		ib_bo->robj = aobj;
+		ib_bo->prefered_domains = aobj->initial_domain;
+		ib_bo->allowed_domains = aobj->initial_domain;
+		ib_bo->priority = 0;
+		ib_bo->tv.bo = &aobj->tbo;
+		ib_bo->tv.shared = true;
+		j++;
+	}
+
+	if (!parser->num_ibs)
+		return 0;
+
+	/* add GDS resources to first IB */
+	if (parser->bo_list) {
+		struct amdgpu_bo *gds = parser->bo_list->gds_obj;
+		struct amdgpu_bo *gws = parser->bo_list->gws_obj;
+		struct amdgpu_bo *oa = parser->bo_list->oa_obj;
+		struct amdgpu_ib *ib = &parser->ibs[0];
+
+		if (gds) {
+			ib->gds_base = amdgpu_bo_gpu_offset(gds);
+			ib->gds_size = amdgpu_bo_size(gds);
+		}
+		if (gws) {
+			ib->gws_base = amdgpu_bo_gpu_offset(gws);
+			ib->gws_size = amdgpu_bo_size(gws);
+		}
+		if (oa) {
+			ib->oa_base = amdgpu_bo_gpu_offset(oa);
+			ib->oa_size = amdgpu_bo_size(oa);
+		}
+	}
+
+	/* wrap the last IB with user fence */
+	if (parser->uf.bo) {
+		struct amdgpu_ib *ib = &parser->ibs[parser->num_ibs - 1];
+
+		/* UVD & VCE fw doesn't support user fences */
+		if (ib->ring->type == AMDGPU_RING_TYPE_UVD ||
+		    ib->ring->type == AMDGPU_RING_TYPE_VCE)
+			return -EINVAL;
+
+		ib->user = &parser->uf;
+	}
+
+	return 0;
+}
+
+int amdgpu_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
+{
+	struct amdgpu_device *adev = dev->dev_private;
+	union drm_amdgpu_cs *cs = data;
+	struct amdgpu_cs_parser parser;
+	int r, i;
+
+	down_read(&adev->exclusive_lock);
+	if (!adev->accel_working) {
+		up_read(&adev->exclusive_lock);
+		return -EBUSY;
+	}
+	/* initialize parser */
+	memset(&parser, 0, sizeof(struct amdgpu_cs_parser));
+	parser.filp = filp;
+	parser.adev = adev;
+	r = amdgpu_cs_parser_init(&parser, data);
+	if (r) {
+		DRM_ERROR("Failed to initialize parser !\n");
+		amdgpu_cs_parser_fini(&parser, r, false);
+		up_read(&adev->exclusive_lock);
+		r = amdgpu_cs_handle_lockup(adev, r);
+		return r;
+	}
+
+	r = amdgpu_cs_ib_fill(adev, &parser);
+	if (!r) {
+		r = amdgpu_cs_parser_relocs(&parser);
+		if (r && r != -ERESTARTSYS)
+			DRM_ERROR("Failed to parse relocation %d!\n", r);
+	}
+
+	if (r) {
+		amdgpu_cs_parser_fini(&parser, r, false);
+		up_read(&adev->exclusive_lock);
+		r = amdgpu_cs_handle_lockup(adev, r);
+		return r;
+	}
+
+	for (i = 0; i < parser.num_ibs; i++)
+		trace_amdgpu_cs(&parser, i);
+
+	r = amdgpu_cs_ib_vm_chunk(adev, &parser);
+	if (r) {
+		goto out;
+	}
+
+	cs->out.handle = parser.ibs[parser.num_ibs - 1].fence->seq;
+out:
+	amdgpu_cs_parser_fini(&parser, r, true);
+	up_read(&adev->exclusive_lock);
+	r = amdgpu_cs_handle_lockup(adev, r);
+	return r;
+}
+
+/**
+ * amdgpu_cs_wait_ioctl - wait for a command submission to finish
+ *
+ * @dev: drm device
+ * @data: data from userspace
+ * @filp: file private
+ *
+ * Wait for the command submission identified by handle to finish.
+ */
+int amdgpu_cs_wait_ioctl(struct drm_device *dev, void *data,
+			 struct drm_file *filp)
+{
+	union drm_amdgpu_wait_cs *wait = data;
+	struct amdgpu_device *adev = dev->dev_private;
+	uint64_t seq[AMDGPU_MAX_RINGS] = {0};
+	struct amdgpu_ring *ring = NULL;
+	unsigned long timeout = amdgpu_gem_timeout(wait->in.timeout);
+	long r;
+
+	r = amdgpu_cs_get_ring(adev, wait->in.ip_type, wait->in.ip_instance,
+			       wait->in.ring, &ring);
+	if (r)
+		return r;
+
+	seq[ring->idx] = wait->in.handle;
+
+	r = amdgpu_fence_wait_seq_timeout(adev, seq, true, timeout);
+	if (r < 0)
+		return r;
+
+	memset(wait, 0, sizeof(*wait));
+	wait->out.status = (r == 0);
+
+	return 0;
+}
+
+/**
+ * amdgpu_cs_find_bo_va - find bo_va for VM address
+ *
+ * @parser: command submission parser context
+ * @addr: VM address
+ * @bo: resulting BO of the mapping found
+ *
+ * Search the buffer objects in the command submission context for a certain
+ * virtual memory address. Returns allocation structure when found, NULL
+ * otherwise.
+ */
+struct amdgpu_bo_va_mapping *
+amdgpu_cs_find_mapping(struct amdgpu_cs_parser *parser,
+		       uint64_t addr, struct amdgpu_bo **bo)
+{
+	struct amdgpu_bo_list_entry *reloc;
+	struct amdgpu_bo_va_mapping *mapping;
+
+	addr /= AMDGPU_GPU_PAGE_SIZE;
+
+	list_for_each_entry(reloc, &parser->validated, tv.head) {
+		if (!reloc->bo_va)
+			continue;
+
+		list_for_each_entry(mapping, &reloc->bo_va->mappings, list) {
+			if (mapping->it.start > addr ||
+			    addr > mapping->it.last)
+				continue;
+
+			*bo = reloc->bo_va->bo;
+			return mapping;
+		}
+	}
+
+	return NULL;
+}
