commit de51a5019ff32960218da8fd899fa3f361b031e9
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Sep 18 19:42:14 2019 +0200

    drm/amdgpu: fix error handling in amdgpu_bo_list_create
    
    We need to drop normal and userptr BOs separately.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 61e38e43ad1d..85b0515c0fdc 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -140,7 +140,12 @@ int amdgpu_bo_list_create(struct amdgpu_device *adev, struct drm_file *filp,
 	return 0;
 
 error_free:
-	while (i--) {
+	for (i = 0; i < last_entry; ++i) {
+		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(array[i].tv.bo);
+
+		amdgpu_bo_unref(&bo);
+	}
+	for (i = first_userptr; i < num_entries; ++i) {
 		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(array[i].tv.bo);
 
 		amdgpu_bo_unref(&bo);

commit 083164dbdb17c5ea4ad92c1782b59c9d75567790
Author: Nirmoy Das <nirmoy.das@amd.com>
Date:   Fri Oct 4 11:53:37 2019 +0200

    drm/amdgpu: fix memory leak
    
    cleanup error handling code and make sure temporary info array
    with the handles are freed by amdgpu_bo_list_put() on
    idr_replace()'s failure.
    
    Signed-off-by: Nirmoy Das <nirmoy.das@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 7bcf86c61999..61e38e43ad1d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -270,7 +270,7 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 
 	r = amdgpu_bo_create_list_entry_array(&args->in, &info);
 	if (r)
-		goto error_free;
+		return r;
 
 	switch (args->in.operation) {
 	case AMDGPU_BO_LIST_OP_CREATE:
@@ -283,8 +283,7 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 		r = idr_alloc(&fpriv->bo_list_handles, list, 1, 0, GFP_KERNEL);
 		mutex_unlock(&fpriv->bo_list_lock);
 		if (r < 0) {
-			amdgpu_bo_list_put(list);
-			return r;
+			goto error_put_list;
 		}
 
 		handle = r;
@@ -306,9 +305,8 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 		mutex_unlock(&fpriv->bo_list_lock);
 
 		if (IS_ERR(old)) {
-			amdgpu_bo_list_put(list);
 			r = PTR_ERR(old);
-			goto error_free;
+			goto error_put_list;
 		}
 
 		amdgpu_bo_list_put(old);
@@ -325,8 +323,10 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 
 	return 0;
 
+error_put_list:
+	amdgpu_bo_list_put(list);
+
 error_free:
-	if (info)
-		kvfree(info);
+	kvfree(info);
 	return r;
 }

commit 2454fcea338ad821a39d471bc7db5a58ba41b742
Merge: 561564bea324 51e857af9f3f
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Fri Jun 14 11:31:13 2019 +0200

    Merge tag 'drm-misc-next-2019-06-14' of git://anongit.freedesktop.org/drm/drm-misc into drm-next
    
    drm-misc-next for v5.3:
    
    UAPI Changes:
    
    Cross-subsystem Changes:
    - Add code to signal all dma-fences when freed with pending signals.
    - Annotate reservation object access in CONFIG_DEBUG_MUTEXES
    
    Core Changes:
    - Assorted documentation fixes.
    - Use irqsave/restore spinlock to add crc entry.
    - Move code around to drm_client, for internal modeset clients.
    - Make drm_crtc.h and drm_debugfs.h self-contained.
    - Remove drm_fb_helper_connector.
    - Add bootsplash to todo.
    - Fix lock ordering in pan_display_legacy.
    - Support pinning buffers to current location in gem-vram.
    - Remove the now unused locking functions from gem-vram.
    - Remove the now unused kmap-object argument from vram helpers.
    - Stop checking return value of debugfs_create.
    - Add atomic encoder enable/disable helpers.
    - pass drm_atomic_state to atomic connector check.
    - Add atomic support for bridge enable/disable.
    - Add self refresh helpers to core.
    
    Driver Changes:
    - Add extra delay to make MTP SDM845 work.
    - Small fixes to virtio, vkms, sii902x, sii9234, ast, mcde, analogix, rockchip.
    - Add zpos and ?BGR8888 support to meson.
    - More removals of drm_os_linux and drmP headers for amd, radeon, sti, r128, r128, savage, sis.
    - Allow synopsis to unwedge the i2c hdmi bus.
    - Add orientation quirks for GPD panels.
    - Edid cleanups and fixing handling for edid < 1.2.
    - Add runtime pm to stm.
    - Handle s/r in dw-hdmi.
    - Add hooks for power on/off to dsi for stm.
    - Remove virtio dirty tracking code, done in drm core.
    - Rework BO handling in ast and mgag200.
    
    Tiny conflict in drivers/gpu/drm/amd/display/dc/clk_mgr/clk_mgr.c,
    needed #include <linux/slab.h> to make it compile.
    
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    From: Maarten Lankhorst <maarten.lankhorst@linux.intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/0e01de30-9797-853c-732f-4a5bd6e61445@linux.intel.com

commit fdf2f6c56e5e289c7d7e726b676aba25643b39a0
Author: Sam Ravnborg <sam@ravnborg.org>
Date:   Mon Jun 10 00:07:56 2019 +0200

    drm/amd: drop use of drmP.h in amdgpu/amdgpu*
    
    Drop use of drmP.h in all files named amdgpu*
    in drm/amd/amdgpu/
    
    Fix fallout.
    
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: "Christian König" <christian.koenig@amd.com>
    Cc: "David (ChunMing) Zhou" <David1.Zhou@amd.com>
    Cc: David Airlie <airlied@linux.ie>
    Cc: Daniel Vetter <daniel@ffwll.ch>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190609220757.10862-10-sam@ravnborg.org

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 5c79da8e1150..7d2f37434c1a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -28,7 +28,8 @@
  *    Christian König <deathsimple@vodafone.de>
  */
 
-#include <drm/drmP.h>
+#include <linux/uaccess.h>
+
 #include "amdgpu.h"
 #include "amdgpu_trace.h"
 

commit dca29491c37fd9d685bca7da4fbc1f93e7aa552e
Author: Christian König <christian.koenig@amd.com>
Date:   Fri May 10 19:56:30 2019 +0200

    drm/amdgpu: remove static GDS, GWS and OA allocation
    
    As far as we know this was never used by userspace and so should be removed.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Marek Olšák <marek.olsak@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 5c79da8e1150..d497467b7fc6 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -81,9 +81,9 @@ int amdgpu_bo_list_create(struct amdgpu_device *adev, struct drm_file *filp,
 		return -ENOMEM;
 
 	kref_init(&list->refcount);
-	list->gds_obj = adev->gds.gds_gfx_bo;
-	list->gws_obj = adev->gds.gws_gfx_bo;
-	list->oa_obj = adev->gds.oa_gfx_bo;
+	list->gds_obj = NULL;
+	list->gws_obj = NULL;
+	list->oa_obj = NULL;
 
 	array = amdgpu_bo_list_array_entry(list, 0);
 	memset(array, 0, num_entries * sizeof(struct amdgpu_bo_list_entry));

commit 049aca4363d8af87cab8d53de5401602db3b9999
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Sep 19 16:54:35 2018 +0200

    drm/amdgpu: fix using shared fence for exported BOs v2
    
    It is perfectly possible that the BO list is created before the BO is
    exported. While at it clean up setting shared to one instead of true.
    
    v2: add comment and simplify logic
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index b75d30ee80c6..5c79da8e1150 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -118,7 +118,6 @@ int amdgpu_bo_list_create(struct amdgpu_device *adev, struct drm_file *filp,
 		entry->priority = min(info[i].bo_priority,
 				      AMDGPU_BO_LIST_MAX_PRIORITY);
 		entry->tv.bo = &bo->tbo;
-		entry->tv.num_shared = !bo->prime_shared_count;
 
 		if (bo->preferred_domains == AMDGPU_GEM_DOMAIN_GDS)
 			list->gds_obj = bo;

commit a9f34c70fd168b164aadffd46bb757ded52e25b9
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Sep 19 16:25:08 2018 +0200

    drm/ttm: allow reserving more than one shared slot v3
    
    Let's support simultaneous submissions to multiple engines.
    
    v2: rename the field to num_shared and fix up all users
    v3: rebased
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 14d2982a47cc..b75d30ee80c6 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -118,7 +118,7 @@ int amdgpu_bo_list_create(struct amdgpu_device *adev, struct drm_file *filp,
 		entry->priority = min(info[i].bo_priority,
 				      AMDGPU_BO_LIST_MAX_PRIORITY);
 		entry->tv.bo = &bo->tbo;
-		entry->tv.shared = !bo->prime_shared_count;
+		entry->tv.num_shared = !bo->prime_shared_count;
 
 		if (bo->preferred_domains == AMDGPU_GEM_DOMAIN_GDS)
 			list->gds_obj = bo;

commit e83dfe4d869358549bb259ab581ae4f0450c6580
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Sep 10 16:07:57 2018 +0200

    drm/amdgpu: remove amdgpu_bo_list_entry.robj (v2)
    
    We can get that just by casting tv.bo.
    
    v2: squash in kfd fix (Alex)
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index b80243d3972e..14d2982a47cc 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -49,8 +49,11 @@ static void amdgpu_bo_list_free(struct kref *ref)
 						   refcount);
 	struct amdgpu_bo_list_entry *e;
 
-	amdgpu_bo_list_for_each_entry(e, list)
-		amdgpu_bo_unref(&e->robj);
+	amdgpu_bo_list_for_each_entry(e, list) {
+		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(e->tv.bo);
+
+		amdgpu_bo_unref(&bo);
+	}
 
 	call_rcu(&list->rhead, amdgpu_bo_list_free_rcu);
 }
@@ -112,21 +115,20 @@ int amdgpu_bo_list_create(struct amdgpu_device *adev, struct drm_file *filp,
 			entry = &array[last_entry++];
 		}
 
-		entry->robj = bo;
 		entry->priority = min(info[i].bo_priority,
 				      AMDGPU_BO_LIST_MAX_PRIORITY);
-		entry->tv.bo = &entry->robj->tbo;
-		entry->tv.shared = !entry->robj->prime_shared_count;
-
-		if (entry->robj->preferred_domains == AMDGPU_GEM_DOMAIN_GDS)
-			list->gds_obj = entry->robj;
-		if (entry->robj->preferred_domains == AMDGPU_GEM_DOMAIN_GWS)
-			list->gws_obj = entry->robj;
-		if (entry->robj->preferred_domains == AMDGPU_GEM_DOMAIN_OA)
-			list->oa_obj = entry->robj;
-
-		total_size += amdgpu_bo_size(entry->robj);
-		trace_amdgpu_bo_list_set(list, entry->robj);
+		entry->tv.bo = &bo->tbo;
+		entry->tv.shared = !bo->prime_shared_count;
+
+		if (bo->preferred_domains == AMDGPU_GEM_DOMAIN_GDS)
+			list->gds_obj = bo;
+		if (bo->preferred_domains == AMDGPU_GEM_DOMAIN_GWS)
+			list->gws_obj = bo;
+		if (bo->preferred_domains == AMDGPU_GEM_DOMAIN_OA)
+			list->oa_obj = bo;
+
+		total_size += amdgpu_bo_size(bo);
+		trace_amdgpu_bo_list_set(list, bo);
 	}
 
 	list->first_userptr = first_userptr;
@@ -138,8 +140,11 @@ int amdgpu_bo_list_create(struct amdgpu_device *adev, struct drm_file *filp,
 	return 0;
 
 error_free:
-	while (i--)
-		amdgpu_bo_unref(&array[i].robj);
+	while (i--) {
+		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(array[i].tv.bo);
+
+		amdgpu_bo_unref(&bo);
+	}
 	kvfree(list);
 	return r;
 
@@ -191,9 +196,10 @@ void amdgpu_bo_list_get_list(struct amdgpu_bo_list *list,
 	 * with the same priority, i.e. it must be stable.
 	 */
 	amdgpu_bo_list_for_each_entry(e, list) {
+		struct amdgpu_bo *bo = ttm_to_amdgpu_bo(e->tv.bo);
 		unsigned priority = e->priority;
 
-		if (!e->robj->parent)
+		if (!bo->parent)
 			list_add_tail(&e->tv.head, &bucket[priority]);
 
 		e->user_pages = NULL;

commit ff30e9e8509cb877dc7cbc776b36c70f5bdd290f
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Fri Aug 10 18:50:32 2018 +0800

    drm/amdgpu: fix integer overflow test in amdgpu_bo_list_create()
    
    We accidentally left out the size of the amdgpu_bo_list struct.  It
    could lead to memory corruption on 32 bit systems.  You'd have to
    pick the absolute maximum and set "num_entries == 59652323" then size
    would wrap to 16 bytes.
    
    Fixes: 920990cb080a ("drm/amdgpu: allocate the bo_list array after the list")
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Bas Nieuwenhuizen <basni@chromium.org>
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index d472a2c8399f..b80243d3972e 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -67,7 +67,8 @@ int amdgpu_bo_list_create(struct amdgpu_device *adev, struct drm_file *filp,
 	unsigned i;
 	int r;
 
-	if (num_entries > SIZE_MAX / sizeof(struct amdgpu_bo_list_entry))
+	if (num_entries > (SIZE_MAX - sizeof(struct amdgpu_bo_list))
+				/ sizeof(struct amdgpu_bo_list_entry))
 		return -EINVAL;
 
 	size = sizeof(struct amdgpu_bo_list);

commit 920990cb080a44203bf6c8eb706e79ad23241ad3
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jul 30 16:16:01 2018 +0200

    drm/amdgpu: allocate the bo_list array after the list
    
    This avoids multiple allocations for the head and the array.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming  Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 096bcf4a6334..d472a2c8399f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -35,13 +35,15 @@
 #define AMDGPU_BO_LIST_MAX_PRIORITY	32u
 #define AMDGPU_BO_LIST_NUM_BUCKETS	(AMDGPU_BO_LIST_MAX_PRIORITY + 1)
 
-static int amdgpu_bo_list_set(struct amdgpu_device *adev,
-				     struct drm_file *filp,
-				     struct amdgpu_bo_list *list,
-				     struct drm_amdgpu_bo_list_entry *info,
-				     unsigned num_entries);
+static void amdgpu_bo_list_free_rcu(struct rcu_head *rcu)
+{
+	struct amdgpu_bo_list *list = container_of(rcu, struct amdgpu_bo_list,
+						   rhead);
+
+	kvfree(list);
+}
 
-static void amdgpu_bo_list_release_rcu(struct kref *ref)
+static void amdgpu_bo_list_free(struct kref *ref)
 {
 	struct amdgpu_bo_list *list = container_of(ref, struct amdgpu_bo_list,
 						   refcount);
@@ -50,67 +52,36 @@ static void amdgpu_bo_list_release_rcu(struct kref *ref)
 	amdgpu_bo_list_for_each_entry(e, list)
 		amdgpu_bo_unref(&e->robj);
 
-	kvfree(list->array);
-	kfree_rcu(list, rhead);
+	call_rcu(&list->rhead, amdgpu_bo_list_free_rcu);
 }
 
-int amdgpu_bo_list_create(struct amdgpu_device *adev,
-				 struct drm_file *filp,
-				 struct drm_amdgpu_bo_list_entry *info,
-				 unsigned num_entries,
-				 struct amdgpu_bo_list **list_out)
+int amdgpu_bo_list_create(struct amdgpu_device *adev, struct drm_file *filp,
+			  struct drm_amdgpu_bo_list_entry *info,
+			  unsigned num_entries, struct amdgpu_bo_list **result)
 {
+	unsigned last_entry = 0, first_userptr = num_entries;
+	struct amdgpu_bo_list_entry *array;
 	struct amdgpu_bo_list *list;
+	uint64_t total_size = 0;
+	size_t size;
+	unsigned i;
 	int r;
 
+	if (num_entries > SIZE_MAX / sizeof(struct amdgpu_bo_list_entry))
+		return -EINVAL;
 
-	list = kzalloc(sizeof(struct amdgpu_bo_list), GFP_KERNEL);
+	size = sizeof(struct amdgpu_bo_list);
+	size += num_entries * sizeof(struct amdgpu_bo_list_entry);
+	list = kvmalloc(size, GFP_KERNEL);
 	if (!list)
 		return -ENOMEM;
 
-	/* initialize bo list*/
 	kref_init(&list->refcount);
-	r = amdgpu_bo_list_set(adev, filp, list, info, num_entries);
-	if (r) {
-		kfree(list);
-		return r;
-	}
-
-	*list_out = list;
-	return 0;
-}
-
-static void amdgpu_bo_list_destroy(struct amdgpu_fpriv *fpriv, int id)
-{
-	struct amdgpu_bo_list *list;
-
-	mutex_lock(&fpriv->bo_list_lock);
-	list = idr_remove(&fpriv->bo_list_handles, id);
-	mutex_unlock(&fpriv->bo_list_lock);
-	if (list)
-		kref_put(&list->refcount, amdgpu_bo_list_release_rcu);
-}
-
-static int amdgpu_bo_list_set(struct amdgpu_device *adev,
-				     struct drm_file *filp,
-				     struct amdgpu_bo_list *list,
-				     struct drm_amdgpu_bo_list_entry *info,
-				     unsigned num_entries)
-{
-	struct amdgpu_bo_list_entry *array;
-	struct amdgpu_bo *gds_obj = adev->gds.gds_gfx_bo;
-	struct amdgpu_bo *gws_obj = adev->gds.gws_gfx_bo;
-	struct amdgpu_bo *oa_obj = adev->gds.oa_gfx_bo;
-
-	unsigned last_entry = 0, first_userptr = num_entries;
-	struct amdgpu_bo_list_entry *e;
-	uint64_t total_size = 0;
-	unsigned i;
-	int r;
+	list->gds_obj = adev->gds.gds_gfx_bo;
+	list->gws_obj = adev->gds.gws_gfx_bo;
+	list->oa_obj = adev->gds.oa_gfx_bo;
 
-	array = kvmalloc_array(num_entries, sizeof(struct amdgpu_bo_list_entry), GFP_KERNEL);
-	if (!array)
-		return -ENOMEM;
+	array = amdgpu_bo_list_array_entry(list, 0);
 	memset(array, 0, num_entries * sizeof(struct amdgpu_bo_list_entry));
 
 	for (i = 0; i < num_entries; ++i) {
@@ -147,36 +118,41 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 		entry->tv.shared = !entry->robj->prime_shared_count;
 
 		if (entry->robj->preferred_domains == AMDGPU_GEM_DOMAIN_GDS)
-			gds_obj = entry->robj;
+			list->gds_obj = entry->robj;
 		if (entry->robj->preferred_domains == AMDGPU_GEM_DOMAIN_GWS)
-			gws_obj = entry->robj;
+			list->gws_obj = entry->robj;
 		if (entry->robj->preferred_domains == AMDGPU_GEM_DOMAIN_OA)
-			oa_obj = entry->robj;
+			list->oa_obj = entry->robj;
 
 		total_size += amdgpu_bo_size(entry->robj);
 		trace_amdgpu_bo_list_set(list, entry->robj);
 	}
 
-	amdgpu_bo_list_for_each_entry(e, list)
-		amdgpu_bo_unref(&list->array[i].robj);
-
-	kvfree(list->array);
-
-	list->gds_obj = gds_obj;
-	list->gws_obj = gws_obj;
-	list->oa_obj = oa_obj;
 	list->first_userptr = first_userptr;
-	list->array = array;
 	list->num_entries = num_entries;
 
 	trace_amdgpu_cs_bo_status(list->num_entries, total_size);
+
+	*result = list;
 	return 0;
 
 error_free:
 	while (i--)
 		amdgpu_bo_unref(&array[i].robj);
-	kvfree(array);
+	kvfree(list);
 	return r;
+
+}
+
+static void amdgpu_bo_list_destroy(struct amdgpu_fpriv *fpriv, int id)
+{
+	struct amdgpu_bo_list *list;
+
+	mutex_lock(&fpriv->bo_list_lock);
+	list = idr_remove(&fpriv->bo_list_handles, id);
+	mutex_unlock(&fpriv->bo_list_lock);
+	if (list)
+		kref_put(&list->refcount, amdgpu_bo_list_free);
 }
 
 int amdgpu_bo_list_get(struct amdgpu_fpriv *fpriv, int id,
@@ -229,7 +205,7 @@ void amdgpu_bo_list_get_list(struct amdgpu_bo_list *list,
 
 void amdgpu_bo_list_put(struct amdgpu_bo_list *list)
 {
-	kref_put(&list->refcount, amdgpu_bo_list_release_rcu);
+	kref_put(&list->refcount, amdgpu_bo_list_free);
 }
 
 int amdgpu_bo_create_list_entry_array(struct drm_amdgpu_bo_list_in *in,

commit 39f7f69a6054bb9777b47b6afdb5ce2fae30dbee
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jul 30 15:37:46 2018 +0200

    drm/amdgpu: add bo_list iterators
    
    Add helpers to iterate over all entries in a bo_list.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming  Zhou <david1.zhou@amd.com>
    Acked-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 5335f1b5459f..096bcf4a6334 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -43,12 +43,12 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 
 static void amdgpu_bo_list_release_rcu(struct kref *ref)
 {
-	unsigned i;
 	struct amdgpu_bo_list *list = container_of(ref, struct amdgpu_bo_list,
 						   refcount);
+	struct amdgpu_bo_list_entry *e;
 
-	for (i = 0; i < list->num_entries; ++i)
-		amdgpu_bo_unref(&list->array[i].robj);
+	amdgpu_bo_list_for_each_entry(e, list)
+		amdgpu_bo_unref(&e->robj);
 
 	kvfree(list->array);
 	kfree_rcu(list, rhead);
@@ -103,6 +103,7 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 	struct amdgpu_bo *oa_obj = adev->gds.oa_gfx_bo;
 
 	unsigned last_entry = 0, first_userptr = num_entries;
+	struct amdgpu_bo_list_entry *e;
 	uint64_t total_size = 0;
 	unsigned i;
 	int r;
@@ -156,7 +157,7 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 		trace_amdgpu_bo_list_set(list, entry->robj);
 	}
 
-	for (i = 0; i < list->num_entries; ++i)
+	amdgpu_bo_list_for_each_entry(e, list)
 		amdgpu_bo_unref(&list->array[i].robj);
 
 	kvfree(list->array);
@@ -201,6 +202,7 @@ void amdgpu_bo_list_get_list(struct amdgpu_bo_list *list,
 	 * concatenated in descending order.
 	 */
 	struct list_head bucket[AMDGPU_BO_LIST_NUM_BUCKETS];
+	struct amdgpu_bo_list_entry *e;
 	unsigned i;
 
 	for (i = 0; i < AMDGPU_BO_LIST_NUM_BUCKETS; i++)
@@ -211,14 +213,13 @@ void amdgpu_bo_list_get_list(struct amdgpu_bo_list *list,
 	 * in the list, the sort mustn't change the ordering of buffers
 	 * with the same priority, i.e. it must be stable.
 	 */
-	for (i = 0; i < list->num_entries; i++) {
-		unsigned priority = list->array[i].priority;
+	amdgpu_bo_list_for_each_entry(e, list) {
+		unsigned priority = e->priority;
 
-		if (!list->array[i].robj->parent)
-			list_add_tail(&list->array[i].tv.head,
-				      &bucket[priority]);
+		if (!e->robj->parent)
+			list_add_tail(&e->tv.head, &bucket[priority]);
 
-		list->array[i].user_pages = NULL;
+		e->user_pages = NULL;
 	}
 
 	/* Connect the sorted buckets in the output list. */

commit a0f208453b97565dab8c334ff013aa5ab3c66d0c
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jul 30 14:17:41 2018 +0200

    drm/amdgpu: nuke amdgpu_bo_list_free
    
    The RCU grace period is harmless and avoiding it is not worth the effort
    of doubling the implementation.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming  Zhou <david1.zhou@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 556040e45931..5335f1b5459f 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -231,17 +231,6 @@ void amdgpu_bo_list_put(struct amdgpu_bo_list *list)
 	kref_put(&list->refcount, amdgpu_bo_list_release_rcu);
 }
 
-void amdgpu_bo_list_free(struct amdgpu_bo_list *list)
-{
-	unsigned i;
-
-	for (i = 0; i < list->num_entries; ++i)
-		amdgpu_bo_unref(&list->array[i].robj);
-
-	kvfree(list->array);
-	kfree(list);
-}
-
 int amdgpu_bo_create_list_entry_array(struct drm_amdgpu_bo_list_in *in,
 				      struct drm_amdgpu_bo_list_entry **info_param)
 {
@@ -310,7 +299,7 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 		r = idr_alloc(&fpriv->bo_list_handles, list, 1, 0, GFP_KERNEL);
 		mutex_unlock(&fpriv->bo_list_lock);
 		if (r < 0) {
-			amdgpu_bo_list_free(list);
+			amdgpu_bo_list_put(list);
 			return r;
 		}
 

commit 81c6dabcc990c341793368db985ee8aca5713b16
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jul 30 13:46:04 2018 +0200

    drm/amdgpu: always recreate bo_list
    
    The bo_list handle is allocated by OP_CREATE, so in OP_UPDATE here we just
    re-create the bo_list object and replace the handle. This way we don't
    need locking to protect the bo_list because it's always re-created when
    changed.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming  Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 6728448167ba..556040e45931 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -50,7 +50,6 @@ static void amdgpu_bo_list_release_rcu(struct kref *ref)
 	for (i = 0; i < list->num_entries; ++i)
 		amdgpu_bo_unref(&list->array[i].robj);
 
-	mutex_destroy(&list->lock);
 	kvfree(list->array);
 	kfree_rcu(list, rhead);
 }
@@ -70,7 +69,6 @@ int amdgpu_bo_list_create(struct amdgpu_device *adev,
 		return -ENOMEM;
 
 	/* initialize bo list*/
-	mutex_init(&list->lock);
 	kref_init(&list->refcount);
 	r = amdgpu_bo_list_set(adev, filp, list, info, num_entries);
 	if (r) {
@@ -188,7 +186,6 @@ int amdgpu_bo_list_get(struct amdgpu_fpriv *fpriv, int id,
 
 	if (*result && kref_get_unless_zero(&(*result)->refcount)) {
 		rcu_read_unlock();
-		mutex_lock(&(*result)->lock);
 		return 0;
 	}
 
@@ -231,7 +228,6 @@ void amdgpu_bo_list_get_list(struct amdgpu_bo_list *list,
 
 void amdgpu_bo_list_put(struct amdgpu_bo_list *list)
 {
-	mutex_unlock(&list->lock);
 	kref_put(&list->refcount, amdgpu_bo_list_release_rcu);
 }
 
@@ -242,7 +238,6 @@ void amdgpu_bo_list_free(struct amdgpu_bo_list *list)
 	for (i = 0; i < list->num_entries; ++i)
 		amdgpu_bo_unref(&list->array[i].robj);
 
-	mutex_destroy(&list->lock);
 	kvfree(list->array);
 	kfree(list);
 }
@@ -297,7 +292,7 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 	union drm_amdgpu_bo_list *args = data;
 	uint32_t handle = args->in.list_handle;
 	struct drm_amdgpu_bo_list_entry *info = NULL;
-	struct amdgpu_bo_list *list;
+	struct amdgpu_bo_list *list, *old;
 	int r;
 
 	r = amdgpu_bo_create_list_entry_array(&args->in, &info);
@@ -328,16 +323,22 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 		break;
 
 	case AMDGPU_BO_LIST_OP_UPDATE:
-		r = amdgpu_bo_list_get(fpriv, handle, &list);
+		r = amdgpu_bo_list_create(adev, filp, info, args->in.bo_number,
+					  &list);
 		if (r)
 			goto error_free;
 
-		r = amdgpu_bo_list_set(adev, filp, list, info,
-					      args->in.bo_number);
-		amdgpu_bo_list_put(list);
-		if (r)
+		mutex_lock(&fpriv->bo_list_lock);
+		old = idr_replace(&fpriv->bo_list_handles, list, handle);
+		mutex_unlock(&fpriv->bo_list_lock);
+
+		if (IS_ERR(old)) {
+			amdgpu_bo_list_put(list);
+			r = PTR_ERR(old);
 			goto error_free;
+		}
 
+		amdgpu_bo_list_put(old);
 		break;
 
 	default:

commit 275105ce7be37a2cc80eb1b60e6526355f54df94
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jul 30 15:33:34 2018 +0200

    drm/amdgpu: fix total size calculation
    
    long might only be 32bit in size and we can easily use more than 4GB
    here.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming  Zhou <david1.zhou@amd.com>
    Acked-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 944868e47119..6728448167ba 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -105,9 +105,9 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 	struct amdgpu_bo *oa_obj = adev->gds.oa_gfx_bo;
 
 	unsigned last_entry = 0, first_userptr = num_entries;
+	uint64_t total_size = 0;
 	unsigned i;
 	int r;
-	unsigned long total_size = 0;
 
 	array = kvmalloc_array(num_entries, sizeof(struct amdgpu_bo_list_entry), GFP_KERNEL);
 	if (!array)

commit 52c054caf83012fe9fe858ee86d90b4ea2cc3cca
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Jul 27 15:32:04 2018 +0200

    drm/amdgpu: add proper error handling to amdgpu_bo_list_get
    
    Otherwise we silently don't use a BO list when the handle is invalid.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 7679c068c89a..944868e47119 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -180,27 +180,20 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 	return r;
 }
 
-struct amdgpu_bo_list *
-amdgpu_bo_list_get(struct amdgpu_fpriv *fpriv, int id)
+int amdgpu_bo_list_get(struct amdgpu_fpriv *fpriv, int id,
+		       struct amdgpu_bo_list **result)
 {
-	struct amdgpu_bo_list *result;
-
 	rcu_read_lock();
-	result = idr_find(&fpriv->bo_list_handles, id);
+	*result = idr_find(&fpriv->bo_list_handles, id);
 
-	if (result) {
-		if (kref_get_unless_zero(&result->refcount)) {
-			rcu_read_unlock();
-			mutex_lock(&result->lock);
-		} else {
-			rcu_read_unlock();
-			result = NULL;
-		}
-	} else {
+	if (*result && kref_get_unless_zero(&(*result)->refcount)) {
 		rcu_read_unlock();
+		mutex_lock(&(*result)->lock);
+		return 0;
 	}
 
-	return result;
+	rcu_read_unlock();
+	return -ENOENT;
 }
 
 void amdgpu_bo_list_get_list(struct amdgpu_bo_list *list,
@@ -335,9 +328,8 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 		break;
 
 	case AMDGPU_BO_LIST_OP_UPDATE:
-		r = -ENOENT;
-		list = amdgpu_bo_list_get(fpriv, handle);
-		if (!list)
+		r = amdgpu_bo_list_get(fpriv, handle, &list);
+		if (r)
 			goto error_free;
 
 		r = amdgpu_bo_list_set(adev, filp, list, info,

commit 964d0fbf6301d3dc8dfad19ffab5a06d002d27f1
Author: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
Date:   Fri Jul 6 14:16:54 2018 -0400

    drm/amdgpu: Allow to create BO lists in CS ioctl v3
    
    This change is to support MESA performace optimization.
    Modify CS IOCTL to allow its input as command buffer and an array of
    buffer handles to create a temporay bo list and then destroy it
    when IOCTL completes.
    This saves on calling for BO_LIST create and destry IOCTLs in MESA
    and by this improves performance.
    
    v2: Avoid inserting the temp list into idr struct.
    
    v3:
    Remove idr alloation from amdgpu_bo_list_create.
    Remove useless argument from amdgpu_cs_parser_fini
    Minor cosmetic stuff.
    
    v4: Revert amdgpu_bo_list_destroy back to static
    
    Signed-off-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 92be7f6de197..7679c068c89a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -55,15 +55,15 @@ static void amdgpu_bo_list_release_rcu(struct kref *ref)
 	kfree_rcu(list, rhead);
 }
 
-static int amdgpu_bo_list_create(struct amdgpu_device *adev,
+int amdgpu_bo_list_create(struct amdgpu_device *adev,
 				 struct drm_file *filp,
 				 struct drm_amdgpu_bo_list_entry *info,
 				 unsigned num_entries,
-				 int *id)
+				 struct amdgpu_bo_list **list_out)
 {
-	int r;
-	struct amdgpu_fpriv *fpriv = filp->driver_priv;
 	struct amdgpu_bo_list *list;
+	int r;
+
 
 	list = kzalloc(sizeof(struct amdgpu_bo_list), GFP_KERNEL);
 	if (!list)
@@ -78,16 +78,7 @@ static int amdgpu_bo_list_create(struct amdgpu_device *adev,
 		return r;
 	}
 
-	/* idr alloc should be called only after initialization of bo list. */
-	mutex_lock(&fpriv->bo_list_lock);
-	r = idr_alloc(&fpriv->bo_list_handles, list, 1, 0, GFP_KERNEL);
-	mutex_unlock(&fpriv->bo_list_lock);
-	if (r < 0) {
-		amdgpu_bo_list_free(list);
-		return r;
-	}
-	*id = r;
-
+	*list_out = list;
 	return 0;
 }
 
@@ -263,55 +254,79 @@ void amdgpu_bo_list_free(struct amdgpu_bo_list *list)
 	kfree(list);
 }
 
-int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
-				struct drm_file *filp)
+int amdgpu_bo_create_list_entry_array(struct drm_amdgpu_bo_list_in *in,
+				      struct drm_amdgpu_bo_list_entry **info_param)
 {
+	const void __user *uptr = u64_to_user_ptr(in->bo_info_ptr);
 	const uint32_t info_size = sizeof(struct drm_amdgpu_bo_list_entry);
-
-	struct amdgpu_device *adev = dev->dev_private;
-	struct amdgpu_fpriv *fpriv = filp->driver_priv;
-	union drm_amdgpu_bo_list *args = data;
-	uint32_t handle = args->in.list_handle;
-	const void __user *uptr = u64_to_user_ptr(args->in.bo_info_ptr);
-
 	struct drm_amdgpu_bo_list_entry *info;
-	struct amdgpu_bo_list *list;
-
 	int r;
 
-	info = kvmalloc_array(args->in.bo_number,
-			     sizeof(struct drm_amdgpu_bo_list_entry), GFP_KERNEL);
+	info = kvmalloc_array(in->bo_number, info_size, GFP_KERNEL);
 	if (!info)
 		return -ENOMEM;
 
 	/* copy the handle array from userspace to a kernel buffer */
 	r = -EFAULT;
-	if (likely(info_size == args->in.bo_info_size)) {
-		unsigned long bytes = args->in.bo_number *
-			args->in.bo_info_size;
+	if (likely(info_size == in->bo_info_size)) {
+		unsigned long bytes = in->bo_number *
+			in->bo_info_size;
 
 		if (copy_from_user(info, uptr, bytes))
 			goto error_free;
 
 	} else {
-		unsigned long bytes = min(args->in.bo_info_size, info_size);
+		unsigned long bytes = min(in->bo_info_size, info_size);
 		unsigned i;
 
-		memset(info, 0, args->in.bo_number * info_size);
-		for (i = 0; i < args->in.bo_number; ++i) {
+		memset(info, 0, in->bo_number * info_size);
+		for (i = 0; i < in->bo_number; ++i) {
 			if (copy_from_user(&info[i], uptr, bytes))
 				goto error_free;
 
-			uptr += args->in.bo_info_size;
+			uptr += in->bo_info_size;
 		}
 	}
 
+	*info_param = info;
+	return 0;
+
+error_free:
+	kvfree(info);
+	return r;
+}
+
+int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
+				struct drm_file *filp)
+{
+	struct amdgpu_device *adev = dev->dev_private;
+	struct amdgpu_fpriv *fpriv = filp->driver_priv;
+	union drm_amdgpu_bo_list *args = data;
+	uint32_t handle = args->in.list_handle;
+	struct drm_amdgpu_bo_list_entry *info = NULL;
+	struct amdgpu_bo_list *list;
+	int r;
+
+	r = amdgpu_bo_create_list_entry_array(&args->in, &info);
+	if (r)
+		goto error_free;
+
 	switch (args->in.operation) {
 	case AMDGPU_BO_LIST_OP_CREATE:
 		r = amdgpu_bo_list_create(adev, filp, info, args->in.bo_number,
-					  &handle);
+					  &list);
 		if (r)
 			goto error_free;
+
+		mutex_lock(&fpriv->bo_list_lock);
+		r = idr_alloc(&fpriv->bo_list_handles, list, 1, 0, GFP_KERNEL);
+		mutex_unlock(&fpriv->bo_list_lock);
+		if (r < 0) {
+			amdgpu_bo_list_free(list);
+			return r;
+		}
+
+		handle = r;
 		break;
 
 	case AMDGPU_BO_LIST_OP_DESTROY:
@@ -345,6 +360,7 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 	return 0;
 
 error_free:
-	kvfree(info);
+	if (info)
+		kvfree(info);
 	return r;
 }

commit a20ee0b1f8b42e2568f3a4408003d22b2dfcc706
Author: Bas Nieuwenhuizen <basni@chromium.org>
Date:   Wed Jan 31 13:58:55 2018 +0100

    drm/amdgpu: Fix always_valid bos multiple LRU insertions.
    
    If these bos are evicted and are in the validated list
    things blow up, so do not put them in there. Notably,
    that tries to add the bo to the LRU twice, which results
    in a BUG_ON in ttm_bo.c.
    
    While for the bo_list an alternative would be to not allow
    always valid bos in there, that does not work for the user
    fence.
    
    v2: Fixed whitespace issue pointed out by checkpatch.pl
    
    Signed-off-by: Bas Nieuwenhuizen <basni@chromium.org>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 59089e027f4d..92be7f6de197 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -233,8 +233,10 @@ void amdgpu_bo_list_get_list(struct amdgpu_bo_list *list,
 	for (i = 0; i < list->num_entries; i++) {
 		unsigned priority = list->array[i].priority;
 
-		list_add_tail(&list->array[i].tv.head,
-			      &bucket[priority]);
+		if (!list->array[i].robj->parent)
+			list_add_tail(&list->array[i].tv.head,
+				      &bucket[priority]);
+
 		list->array[i].user_pages = NULL;
 	}
 

commit 6d7d9c5aa212d069b5271cd6bb8a9e05a3e1b986
Author: Kent Russell <kent.russell@amd.com>
Date:   Tue Aug 8 07:58:01 2017 -0400

    drm/amdgpu: Fix preferred typo
    
    Change "prefered" to "preferred"
    
    Signed-off-by: Kent Russell <kent.russell@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 75c6107eaccf..59089e027f4d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -156,11 +156,11 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 		entry->tv.bo = &entry->robj->tbo;
 		entry->tv.shared = !entry->robj->prime_shared_count;
 
-		if (entry->robj->prefered_domains == AMDGPU_GEM_DOMAIN_GDS)
+		if (entry->robj->preferred_domains == AMDGPU_GEM_DOMAIN_GDS)
 			gds_obj = entry->robj;
-		if (entry->robj->prefered_domains == AMDGPU_GEM_DOMAIN_GWS)
+		if (entry->robj->preferred_domains == AMDGPU_GEM_DOMAIN_GWS)
 			gws_obj = entry->robj;
-		if (entry->robj->prefered_domains == AMDGPU_GEM_DOMAIN_OA)
+		if (entry->robj->preferred_domains == AMDGPU_GEM_DOMAIN_OA)
 			oa_obj = entry->robj;
 
 		total_size += amdgpu_bo_size(entry->robj);

commit f62facc2eb78ebbedae70e394ac034ab9407a244
Author: Cihangir Akturk <cakturk@gmail.com>
Date:   Thu Aug 3 14:58:16 2017 +0300

    drm/amdgpu: switch to drm_*{get,put} helpers
    
    drm_*_reference() and drm_*_unreference() functions are just
    compatibility alias for drm_*_get() and drm_*_put() and should not be
    used by new code. So convert all users of compatibility functions to use
    the new APIs.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Cihangir Akturk <cakturk@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index ccd7697792ab..75c6107eaccf 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -136,7 +136,7 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 		}
 
 		bo = amdgpu_bo_ref(gem_to_amdgpu_bo(gobj));
-		drm_gem_object_unreference_unlocked(gobj);
+		drm_gem_object_put_unlocked(gobj);
 
 		usermm = amdgpu_ttm_tt_get_usermm(bo->tbo.ttm);
 		if (usermm) {

commit 7ecc245a8ce32ffcaa6a3e5795e0b14db8e076fc
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Jul 26 17:02:52 2017 +0200

    drm/amdgpu: consistent use u64_to_user_ptr
    
    Instead of open coding the conversion from u64 to pointers.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index d324e1c24028..ccd7697792ab 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -270,7 +270,7 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 	struct amdgpu_fpriv *fpriv = filp->driver_priv;
 	union drm_amdgpu_bo_list *args = data;
 	uint32_t handle = args->in.list_handle;
-	const void __user *uptr = (const void*)(uintptr_t)args->in.bo_info_ptr;
+	const void __user *uptr = u64_to_user_ptr(args->in.bo_info_ptr);
 
 	struct drm_amdgpu_bo_list_entry *info;
 	struct amdgpu_bo_list *list;

commit 564f04586dbd8cf85305297b2c68773e7419cd66
Author: Alex Xie <AlexBin.Xie@amd.com>
Date:   Thu Jul 20 00:02:08 2017 -0400

    drm/amdgpu: Fix blocking in RCU critical section(v2)
    
    In RCU read-side critical sections, blocking or sleeping is prohibited.
    
    v2: Unlock RCU for the code path where result==NULL. (David Zhou)
        Update subject
    
    Tested-by and reported by: Dave Airlie <airlied@redhat.com>
    
    [  141.965723] =============================
    [  141.965724] WARNING: suspicious RCU usage
    [  141.965726] 4.12.0-rc7 #221 Not tainted
    [  141.965727] -----------------------------
    [  141.965728] /home/airlied/devel/kernel/linux-2.6/include/linux/rcupdate.h:531
    Illegal context switch in RCU read-side critical section!
    [  141.965730]
                   other info that might help us debug this:
    
    [  141.965731]
                   rcu_scheduler_active = 2, debug_locks = 0
    [  141.965732] 1 lock held by amdgpu_cs:0/1332:
    [  141.965733]  #0:  (rcu_read_lock){......}, at: [<ffffffffa01a0d07>]
    amdgpu_bo_list_get+0x0/0x109 [amdgpu]
    [  141.965774]
                   stack backtrace:
    [  141.965776] CPU: 6 PID: 1332 Comm: amdgpu_cs:0 Not tainted 4.12.0-rc7 #221
    [  141.965777] Hardware name: To be filled by O.E.M. To be filled by
    O.E.M./M5A97 R2.0, BIOS 2603 06/26/2015
    [  141.965778] Call Trace:
    [  141.965782]  dump_stack+0x68/0x92
    [  141.965785]  lockdep_rcu_suspicious+0xf7/0x100
    [  141.965788]  ___might_sleep+0x56/0x1fc
    [  141.965790]  __might_sleep+0x68/0x6f
    [  141.965793]  __mutex_lock+0x4e/0x7b5
    [  141.965817]  ? amdgpu_bo_list_get+0xa4/0x109 [amdgpu]
    [  141.965820]  ? lock_acquire+0x125/0x1b9
    [  141.965844]  ? amdgpu_bo_list_set+0x464/0x464 [amdgpu]
    [  141.965846]  mutex_lock_nested+0x16/0x18
    [  141.965848]  ? mutex_lock_nested+0x16/0x18
    [  141.965872]  amdgpu_bo_list_get+0xa4/0x109 [amdgpu]
    [  141.965895]  amdgpu_cs_ioctl+0x4a0/0x17dd [amdgpu]
    [  141.965898]  ? radix_tree_node_alloc.constprop.11+0x77/0xab
    [  141.965916]  drm_ioctl+0x264/0x393 [drm]
    [  141.965939]  ? amdgpu_cs_find_mapping+0x83/0x83 [amdgpu]
    [  141.965942]  ? trace_hardirqs_on_caller+0x16a/0x186
    
    Signed-off-by: Alex Xie <AlexBin.Xie@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index a71b875d0503..d324e1c24028 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -198,12 +198,16 @@ amdgpu_bo_list_get(struct amdgpu_fpriv *fpriv, int id)
 	result = idr_find(&fpriv->bo_list_handles, id);
 
 	if (result) {
-		if (kref_get_unless_zero(&result->refcount))
+		if (kref_get_unless_zero(&result->refcount)) {
+			rcu_read_unlock();
 			mutex_lock(&result->lock);
-		else
+		} else {
+			rcu_read_unlock();
 			result = NULL;
+		}
+	} else {
+		rcu_read_unlock();
 	}
-	rcu_read_unlock();
 
 	return result;
 }

commit a5d20c405a37db7e59089422e795ad58feb37638
Author: Alex Xie <AlexBin.Xie@amd.com>
Date:   Wed Jul 5 18:02:04 2017 -0400

    drm/amdgpu: Free resources of bo_list when idr_alloc fails
    
    Signed-off-by: Alex Xie <AlexBin.Xie@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian König<christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index f621ee115c98..a71b875d0503 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -83,7 +83,7 @@ static int amdgpu_bo_list_create(struct amdgpu_device *adev,
 	r = idr_alloc(&fpriv->bo_list_handles, list, 1, 0, GFP_KERNEL);
 	mutex_unlock(&fpriv->bo_list_lock);
 	if (r < 0) {
-		kfree(list);
+		amdgpu_bo_list_free(list);
 		return r;
 	}
 	*id = r;

commit 5ac55629d6b3fcde69f46aa772c6e83be0bdcbbf
Author: Alex Xie <AlexBin.Xie@amd.com>
Date:   Fri Jun 16 09:07:29 2017 -0400

    drm/amdgpu: Optimize mutex usage (v4)
    
    In original function amdgpu_bo_list_get, the waiting
    for result->lock can be quite long while mutex
    bo_list_lock was holding. It can make other tasks
    waiting for bo_list_lock for long period.
    
    Secondly, this patch allows several tasks(readers of idr)
    to proceed at the same time.
    
    v2: use rcu and kref (Dave Airlie and Christian König)
    v3: update v1 commit message (Michel Dänzer)
    v4: rebase on upstream (Alex Deucher)
    
    Signed-off-by: Alex Xie <AlexBin.Xie@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 7b5c3bb2142e..f621ee115c98 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -41,6 +41,20 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 				     struct drm_amdgpu_bo_list_entry *info,
 				     unsigned num_entries);
 
+static void amdgpu_bo_list_release_rcu(struct kref *ref)
+{
+	unsigned i;
+	struct amdgpu_bo_list *list = container_of(ref, struct amdgpu_bo_list,
+						   refcount);
+
+	for (i = 0; i < list->num_entries; ++i)
+		amdgpu_bo_unref(&list->array[i].robj);
+
+	mutex_destroy(&list->lock);
+	kvfree(list->array);
+	kfree_rcu(list, rhead);
+}
+
 static int amdgpu_bo_list_create(struct amdgpu_device *adev,
 				 struct drm_file *filp,
 				 struct drm_amdgpu_bo_list_entry *info,
@@ -57,7 +71,7 @@ static int amdgpu_bo_list_create(struct amdgpu_device *adev,
 
 	/* initialize bo list*/
 	mutex_init(&list->lock);
-
+	kref_init(&list->refcount);
 	r = amdgpu_bo_list_set(adev, filp, list, info, num_entries);
 	if (r) {
 		kfree(list);
@@ -83,14 +97,9 @@ static void amdgpu_bo_list_destroy(struct amdgpu_fpriv *fpriv, int id)
 
 	mutex_lock(&fpriv->bo_list_lock);
 	list = idr_remove(&fpriv->bo_list_handles, id);
-	if (list) {
-		/* Another user may have a reference to this list still */
-		mutex_lock(&list->lock);
-		mutex_unlock(&list->lock);
-		amdgpu_bo_list_free(list);
-	}
-
 	mutex_unlock(&fpriv->bo_list_lock);
+	if (list)
+		kref_put(&list->refcount, amdgpu_bo_list_release_rcu);
 }
 
 static int amdgpu_bo_list_set(struct amdgpu_device *adev,
@@ -185,11 +194,17 @@ amdgpu_bo_list_get(struct amdgpu_fpriv *fpriv, int id)
 {
 	struct amdgpu_bo_list *result;
 
-	mutex_lock(&fpriv->bo_list_lock);
+	rcu_read_lock();
 	result = idr_find(&fpriv->bo_list_handles, id);
-	if (result)
-		mutex_lock(&result->lock);
-	mutex_unlock(&fpriv->bo_list_lock);
+
+	if (result) {
+		if (kref_get_unless_zero(&result->refcount))
+			mutex_lock(&result->lock);
+		else
+			result = NULL;
+	}
+	rcu_read_unlock();
+
 	return result;
 }
 
@@ -227,6 +242,7 @@ void amdgpu_bo_list_get_list(struct amdgpu_bo_list *list,
 void amdgpu_bo_list_put(struct amdgpu_bo_list *list)
 {
 	mutex_unlock(&list->lock);
+	kref_put(&list->refcount, amdgpu_bo_list_release_rcu);
 }
 
 void amdgpu_bo_list_free(struct amdgpu_bo_list *list)

commit 99eea4df901907b9121ad1c726d86c352a5eaca5
Author: Alex Xie <AlexBin.Xie@amd.com>
Date:   Fri Jun 16 00:23:41 2017 -0400

    drm/amdgpu: Optimization of AMDGPU_BO_LIST_OP_CREATE (v2)
    
    v2: Remove duplication of zeroing of bo list (Christian König)
        Move idr_alloc function to end of ioctl (Christian König)
        Call kfree bo_list when amdgpu_bo_list_set return error.
        Combine the previous two patches into this patch.
        Add amdgpu_bo_list_set function prototype.
    
    Signed-off-by: Alex Xie <AlexBin.Xie@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 9f0247cdda5e..7b5c3bb2142e 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -35,33 +35,45 @@
 #define AMDGPU_BO_LIST_MAX_PRIORITY	32u
 #define AMDGPU_BO_LIST_NUM_BUCKETS	(AMDGPU_BO_LIST_MAX_PRIORITY + 1)
 
-static int amdgpu_bo_list_create(struct amdgpu_fpriv *fpriv,
-				 struct amdgpu_bo_list **result,
+static int amdgpu_bo_list_set(struct amdgpu_device *adev,
+				     struct drm_file *filp,
+				     struct amdgpu_bo_list *list,
+				     struct drm_amdgpu_bo_list_entry *info,
+				     unsigned num_entries);
+
+static int amdgpu_bo_list_create(struct amdgpu_device *adev,
+				 struct drm_file *filp,
+				 struct drm_amdgpu_bo_list_entry *info,
+				 unsigned num_entries,
 				 int *id)
 {
 	int r;
+	struct amdgpu_fpriv *fpriv = filp->driver_priv;
+	struct amdgpu_bo_list *list;
 
-	*result = kzalloc(sizeof(struct amdgpu_bo_list), GFP_KERNEL);
-	if (!*result)
+	list = kzalloc(sizeof(struct amdgpu_bo_list), GFP_KERNEL);
+	if (!list)
 		return -ENOMEM;
 
+	/* initialize bo list*/
+	mutex_init(&list->lock);
+
+	r = amdgpu_bo_list_set(adev, filp, list, info, num_entries);
+	if (r) {
+		kfree(list);
+		return r;
+	}
+
+	/* idr alloc should be called only after initialization of bo list. */
 	mutex_lock(&fpriv->bo_list_lock);
-	r = idr_alloc(&fpriv->bo_list_handles, *result,
-		      1, 0, GFP_KERNEL);
+	r = idr_alloc(&fpriv->bo_list_handles, list, 1, 0, GFP_KERNEL);
+	mutex_unlock(&fpriv->bo_list_lock);
 	if (r < 0) {
-		mutex_unlock(&fpriv->bo_list_lock);
-		kfree(*result);
+		kfree(list);
 		return r;
 	}
 	*id = r;
 
-	mutex_init(&(*result)->lock);
-	(*result)->num_entries = 0;
-	(*result)->array = NULL;
-
-	mutex_lock(&(*result)->lock);
-	mutex_unlock(&fpriv->bo_list_lock);
-
 	return 0;
 }
 
@@ -77,6 +89,7 @@ static void amdgpu_bo_list_destroy(struct amdgpu_fpriv *fpriv, int id)
 		mutex_unlock(&list->lock);
 		amdgpu_bo_list_free(list);
 	}
+
 	mutex_unlock(&fpriv->bo_list_lock);
 }
 
@@ -273,16 +286,10 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 
 	switch (args->in.operation) {
 	case AMDGPU_BO_LIST_OP_CREATE:
-		r = amdgpu_bo_list_create(fpriv, &list, &handle);
+		r = amdgpu_bo_list_create(adev, filp, info, args->in.bo_number,
+					  &handle);
 		if (r)
 			goto error_free;
-
-		r = amdgpu_bo_list_set(adev, filp, list, info,
-					      args->in.bo_number);
-		amdgpu_bo_list_put(list);
-		if (r)
-			goto error_free;
-
 		break;
 
 	case AMDGPU_BO_LIST_OP_DESTROY:

commit 2098105ec65cb364f3d77baa446b2ad5ba6bc7b9
Author: Michal Hocko <mhocko@kernel.org>
Date:   Wed May 17 14:23:12 2017 +0200

    drm: drop drm_[cm]alloc* helpers
    
    Now that drm_[cm]alloc* helpers are simple one line wrappers around
    kvmalloc_array and drm_free_large is just kvfree alias we can drop
    them and replace by their native forms.
    
    This shouldn't introduce any functional change.
    
    Changes since v1
    - fix typo in drivers/gpu//drm/etnaviv/etnaviv_gem.c - noticed by 0day
      build robot
    
    Suggested-by: Daniel Vetter <daniel@ffwll.ch>
    Signed-off-by: Michal Hocko <mhocko@suse.com>drm: drop drm_[cm]alloc* helpers
    [danvet: Fixup vgem which grew another user very recently.]
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Acked-by: Christian König <christian.koenig@amd.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20170517122312.GK18247@dhcp22.suse.cz

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index a6649874e6ce..9f0247cdda5e 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -96,7 +96,7 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 	int r;
 	unsigned long total_size = 0;
 
-	array = drm_malloc_ab(num_entries, sizeof(struct amdgpu_bo_list_entry));
+	array = kvmalloc_array(num_entries, sizeof(struct amdgpu_bo_list_entry), GFP_KERNEL);
 	if (!array)
 		return -ENOMEM;
 	memset(array, 0, num_entries * sizeof(struct amdgpu_bo_list_entry));
@@ -148,7 +148,7 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 	for (i = 0; i < list->num_entries; ++i)
 		amdgpu_bo_unref(&list->array[i].robj);
 
-	drm_free_large(list->array);
+	kvfree(list->array);
 
 	list->gds_obj = gds_obj;
 	list->gws_obj = gws_obj;
@@ -163,7 +163,7 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 error_free:
 	while (i--)
 		amdgpu_bo_unref(&array[i].robj);
-	drm_free_large(array);
+	kvfree(array);
 	return r;
 }
 
@@ -224,7 +224,7 @@ void amdgpu_bo_list_free(struct amdgpu_bo_list *list)
 		amdgpu_bo_unref(&list->array[i].robj);
 
 	mutex_destroy(&list->lock);
-	drm_free_large(list->array);
+	kvfree(list->array);
 	kfree(list);
 }
 
@@ -244,8 +244,8 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 
 	int r;
 
-	info = drm_malloc_ab(args->in.bo_number,
-			     sizeof(struct drm_amdgpu_bo_list_entry));
+	info = kvmalloc_array(args->in.bo_number,
+			     sizeof(struct drm_amdgpu_bo_list_entry), GFP_KERNEL);
 	if (!info)
 		return -ENOMEM;
 
@@ -311,11 +311,11 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 
 	memset(args, 0, sizeof(*args));
 	args->out.list_handle = handle;
-	drm_free_large(info);
+	kvfree(info);
 
 	return 0;
 
 error_free:
-	drm_free_large(info);
+	kvfree(info);
 	return r;
 }

commit ec2c467efe9b9d781e08a4ac827c5106e3c775c4
Author: Alex Xie <AlexBin.Xie@amd.com>
Date:   Wed Apr 5 16:33:00 2017 -0400

    drm/amdgpu: Avoid using signed integer to store pointer value
    
    Signed-off-by: Alex Xie <AlexBin.Xie@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 0218cea6be4d..a6649874e6ce 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -237,7 +237,7 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 	struct amdgpu_fpriv *fpriv = filp->driver_priv;
 	union drm_amdgpu_bo_list *args = data;
 	uint32_t handle = args->in.list_handle;
-	const void __user *uptr = (const void*)(long)args->in.bo_info_ptr;
+	const void __user *uptr = (const void*)(uintptr_t)args->in.bo_info_ptr;
 
 	struct drm_amdgpu_bo_list_entry *info;
 	struct amdgpu_bo_list *list;

commit d3e709e63e97e5f3f129b639991cfe266da60bae
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Thu Dec 22 13:30:22 2016 -0500

    idr: Return the deleted entry from idr_remove
    
    It is a relatively common idiom (8 instances) to first look up an IDR
    entry, and then remove it from the tree if it is found, possibly doing
    further operations upon the entry afterwards.  If we change idr_remove()
    to return the removed object, all of these users can save themselves a
    walk of the IDR tree.
    
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index c02db01f6583..0218cea6be4d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -70,10 +70,10 @@ static void amdgpu_bo_list_destroy(struct amdgpu_fpriv *fpriv, int id)
 	struct amdgpu_bo_list *list;
 
 	mutex_lock(&fpriv->bo_list_lock);
-	list = idr_find(&fpriv->bo_list_handles, id);
+	list = idr_remove(&fpriv->bo_list_handles, id);
 	if (list) {
+		/* Another user may have a reference to this list still */
 		mutex_lock(&list->lock);
-		idr_remove(&fpriv->bo_list_handles, id);
 		mutex_unlock(&list->lock);
 		amdgpu_bo_list_free(list);
 	}

commit 8e94a46c1770884166b31adc99eba7da65a446a7
Author: Mario Kleiner <mario.kleiner.de@gmail.com>
Date:   Wed Nov 9 02:25:15 2016 +0100

    drm/amdgpu: Attach exclusive fence to prime exported bo's. (v5)
    
    External clients which import our bo's wait only
    for exclusive dmabuf-fences, not on shared ones,
    ditto for bo's which we import from external
    providers and write to.
    
    Therefore attach exclusive fences on prime shared buffers
    if our exported buffer gets imported by an external
    client, or if we import a buffer from an external
    exporter.
    
    See discussion in thread:
    https://lists.freedesktop.org/archives/dri-devel/2016-October/122370.html
    
    Prime export tested on Intel iGPU + AMD Tonga dGPU as
    DRI3/Present Prime render offload, and with the Tonga
    standalone as primary gpu.
    
    v2: Add a wait for all shared fences before prime export,
        as suggested by Christian Koenig.
    
    v3: - Mark buffer prime_exported in amdgpu_gem_prime_pin,
        so we only use the exclusive fence when exporting a
        bo to external clients like a separate iGPU, but not
        when exporting/importing from/to ourselves as part of
        regular DRI3 fd passing.
    
        - Propagate failure of reservation_object_wait_rcu back
        to caller.
    
    v4: - Switch to a prime_shared_count counter instead of a
          flag, which gets in/decremented on prime_pin/unpin, so
          we can switch back to shared fences if all clients
          detach from our exported bo.
    
        - Also switch to exclusive fence for prime imported bo's.
    
    v5: - Drop lret, instead use int ret -> long ret, as proposed
          by Christian.
    
    Bugzilla: https://bugs.freedesktop.org/show_bug.cgi?id=95472
    Tested-by: Mike Lothian <mike@fireburn.co.uk> (v1)
    Signed-off-by: Mario Kleiner <mario.kleiner.de@gmail.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>.
    Cc: Christian König <christian.koenig@amd.com>
    Cc: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 651115dcce12..c02db01f6583 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -132,7 +132,7 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 		entry->priority = min(info[i].bo_priority,
 				      AMDGPU_BO_LIST_MAX_PRIORITY);
 		entry->tv.bo = &entry->robj->tbo;
-		entry->tv.shared = true;
+		entry->tv.shared = !entry->robj->prime_shared_count;
 
 		if (entry->robj->prefered_domains == AMDGPU_GEM_DOMAIN_GDS)
 			gds_obj = entry->robj;

commit 15da301d88c8c9669a1d8ef44d729a505617abeb
Author: David Mao <david.mao@amd.com>
Date:   Tue Jun 7 17:48:52 2016 +0800

    drm/amd/amdgpu : adding new tracepoints to track memory information.
    
     - adding amdgpu_cs_bo_status to track total size and
       total entry count of bo for each submission.
     - adding amdgpu_ttm_bo_move to track the bo eviction
       including the size of bo and the location before/after the move
    
    Signed-off-by: David Mao <David.Mao@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 823bf5e0b0c8..651115dcce12 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -94,6 +94,7 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 	unsigned last_entry = 0, first_userptr = num_entries;
 	unsigned i;
 	int r;
+	unsigned long total_size = 0;
 
 	array = drm_malloc_ab(num_entries, sizeof(struct amdgpu_bo_list_entry));
 	if (!array)
@@ -140,6 +141,7 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 		if (entry->robj->prefered_domains == AMDGPU_GEM_DOMAIN_OA)
 			oa_obj = entry->robj;
 
+		total_size += amdgpu_bo_size(entry->robj);
 		trace_amdgpu_bo_list_set(list, entry->robj);
 	}
 
@@ -155,6 +157,7 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 	list->array = array;
 	list->num_entries = num_entries;
 
+	trace_amdgpu_cs_bo_status(list->num_entries, total_size);
 	return 0;
 
 error_free:

commit a8ad0bd84f986072314595d05444719fdf29e412
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Mon May 9 11:04:54 2016 +0100

    drm: Remove unused drm_device from drm_gem_object_lookup()
    
    drm_gem_object_lookup() has never required the drm_device for its file
    local translation of the user handle to the GEM object. Let's remove the
    unused parameter and save some space.
    
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: dri-devel@lists.freedesktop.org
    Cc: Dave Airlie <airlied@redhat.com>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    [danvet: Fixup kerneldoc too.]
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 35d0856738ae..823bf5e0b0c8 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -106,7 +106,7 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 		struct amdgpu_bo *bo;
 		struct mm_struct *usermm;
 
-		gobj = drm_gem_object_lookup(adev->ddev, filp, info[i].bo_handle);
+		gobj = drm_gem_object_lookup(filp, info[i].bo_handle);
 		if (!gobj) {
 			r = -ENOENT;
 			goto error_free;

commit edf600dac65eecb6c8bcf21fa986db30ee21a2ac
Author: Christian König <christian.koenig@amd.com>
Date:   Tue May 3 15:54:54 2016 +0200

    drm/amd: cleanup remaining spaces and tabs v2
    
    This is the result of running the following commands:
    find drivers/gpu/drm/amd/ -name "*.h" -exec sed -i 's/[ \t]\+$//' {} \;
    find drivers/gpu/drm/amd/ -name "*.c" -exec sed -i 's/[ \t]\+$//' {} \;
    find drivers/gpu/drm/amd/ -name "*.h" -exec sed -i 's/ \+\t/\t/' {} \;
    find drivers/gpu/drm/amd/ -name "*.c" -exec sed -i 's/ \+\t/\t/' {} \;
    
    v2: drop changes to DAL and internal headers
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index eacd810fc09b..35d0856738ae 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -263,7 +263,7 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 		for (i = 0; i < args->in.bo_number; ++i) {
 			if (copy_from_user(&info[i], uptr, bytes))
 				goto error_free;
-			
+
 			uptr += args->in.bo_info_size;
 		}
 	}
@@ -271,7 +271,7 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 	switch (args->in.operation) {
 	case AMDGPU_BO_LIST_OP_CREATE:
 		r = amdgpu_bo_list_create(fpriv, &list, &handle);
-		if (r) 
+		if (r)
 			goto error_free;
 
 		r = amdgpu_bo_list_set(adev, filp, list, info,
@@ -281,7 +281,7 @@ int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
 			goto error_free;
 
 		break;
-		
+
 	case AMDGPU_BO_LIST_OP_DESTROY:
 		amdgpu_bo_list_destroy(fpriv, handle);
 		handle = 0;

commit 2f568dbd6b944c2e8c0c54b53c2211c23995e6a4
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Feb 23 12:36:59 2016 +0100

    drm/amdgpu: move get_user_pages out of amdgpu_ttm_tt_pin_userptr v6
    
    That avoids lock inversion between the BO reservation lock
    and the anon_vma lock.
    
    v2:
    * Changed amdgpu_bo_list_entry.user_pages to an array of pointers
    * Lock mmap_sem only for get_user_pages
    * Added invalidation of unbound userpointer BOs
    * Fixed memory leak and page reference leak
    
    v3 (chk):
    * Revert locking mmap_sem only for_get user_pages
    * Revert adding invalidation of unbound userpointer BOs
    * Sanitize and fix error handling
    
    v4 (chk):
    * Init userpages pointer everywhere.
    * Fix error handling when get_user_pages() fails.
    * Add invalidation of unbound userpointer BOs again.
    
    v5 (chk):
    * Add maximum number of tries.
    
    v6 (chk):
    * Fix error handling when we run out of tries.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com> (v4)
    Acked-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 9763e52886fe..eacd810fc09b 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -200,6 +200,7 @@ void amdgpu_bo_list_get_list(struct amdgpu_bo_list *list,
 
 		list_add_tail(&list->array[i].tv.head,
 			      &bucket[priority]);
+		list->array[i].user_pages = NULL;
 	}
 
 	/* Connect the sorted buckets in the output list. */

commit 211dff5518d938d0c11205af3113d2c7a292dd98
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Feb 22 15:40:59 2016 +0100

    drm/amdgpu: group userptr in the BO list v2
    
    We need them together with the next patch.
    
    v2: Don't take bo reference twice
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 4792f9d0b7d4..9763e52886fe 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -91,7 +91,7 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 	struct amdgpu_bo *gws_obj = adev->gds.gws_gfx_bo;
 	struct amdgpu_bo *oa_obj = adev->gds.oa_gfx_bo;
 
-	bool has_userptr = false;
+	unsigned last_entry = 0, first_userptr = num_entries;
 	unsigned i;
 	int r;
 
@@ -101,8 +101,9 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 	memset(array, 0, num_entries * sizeof(struct amdgpu_bo_list_entry));
 
 	for (i = 0; i < num_entries; ++i) {
-		struct amdgpu_bo_list_entry *entry = &array[i];
+		struct amdgpu_bo_list_entry *entry;
 		struct drm_gem_object *gobj;
+		struct amdgpu_bo *bo;
 		struct mm_struct *usermm;
 
 		gobj = drm_gem_object_lookup(adev->ddev, filp, info[i].bo_handle);
@@ -111,19 +112,24 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 			goto error_free;
 		}
 
-		entry->robj = amdgpu_bo_ref(gem_to_amdgpu_bo(gobj));
+		bo = amdgpu_bo_ref(gem_to_amdgpu_bo(gobj));
 		drm_gem_object_unreference_unlocked(gobj);
-		entry->priority = min(info[i].bo_priority,
-				      AMDGPU_BO_LIST_MAX_PRIORITY);
-		usermm = amdgpu_ttm_tt_get_usermm(entry->robj->tbo.ttm);
+
+		usermm = amdgpu_ttm_tt_get_usermm(bo->tbo.ttm);
 		if (usermm) {
 			if (usermm != current->mm) {
-				amdgpu_bo_unref(&entry->robj);
+				amdgpu_bo_unref(&bo);
 				r = -EPERM;
 				goto error_free;
 			}
-			has_userptr = true;
+			entry = &array[--first_userptr];
+		} else {
+			entry = &array[last_entry++];
 		}
+
+		entry->robj = bo;
+		entry->priority = min(info[i].bo_priority,
+				      AMDGPU_BO_LIST_MAX_PRIORITY);
 		entry->tv.bo = &entry->robj->tbo;
 		entry->tv.shared = true;
 
@@ -145,7 +151,7 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 	list->gds_obj = gds_obj;
 	list->gws_obj = gws_obj;
 	list->oa_obj = oa_obj;
-	list->has_userptr = has_userptr;
+	list->first_userptr = first_userptr;
 	list->array = array;
 	list->num_entries = num_entries;
 

commit 70eacc72dbbc229013fee54550c03179f9a513d8
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Feb 22 15:11:56 2016 +0100

    drm/amdgpu: fix error handling in amdgpu_bo_list_set
    
    Don't leak BOs in case of some error.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 90d6fc1618aa..4792f9d0b7d4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -118,6 +118,7 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 		usermm = amdgpu_ttm_tt_get_usermm(entry->robj->tbo.ttm);
 		if (usermm) {
 			if (usermm != current->mm) {
+				amdgpu_bo_unref(&entry->robj);
 				r = -EPERM;
 				goto error_free;
 			}
@@ -151,6 +152,8 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 	return 0;
 
 error_free:
+	while (i--)
+		amdgpu_bo_unref(&array[i].robj);
 	drm_free_large(array);
 	return r;
 }

commit cc325d1913475655b81c0417ba04c84f168ac78c
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Feb 8 11:08:35 2016 +0100

    drm/amdgpu: check userptrs mm earlier
    
    Instead of when we try to bind it check the usermm when
    we try to use it in the IOCTLs.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index c4341dd4b6a4..90d6fc1618aa 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -93,6 +93,7 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 
 	bool has_userptr = false;
 	unsigned i;
+	int r;
 
 	array = drm_malloc_ab(num_entries, sizeof(struct amdgpu_bo_list_entry));
 	if (!array)
@@ -102,17 +103,26 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 	for (i = 0; i < num_entries; ++i) {
 		struct amdgpu_bo_list_entry *entry = &array[i];
 		struct drm_gem_object *gobj;
+		struct mm_struct *usermm;
 
 		gobj = drm_gem_object_lookup(adev->ddev, filp, info[i].bo_handle);
-		if (!gobj)
+		if (!gobj) {
+			r = -ENOENT;
 			goto error_free;
+		}
 
 		entry->robj = amdgpu_bo_ref(gem_to_amdgpu_bo(gobj));
 		drm_gem_object_unreference_unlocked(gobj);
 		entry->priority = min(info[i].bo_priority,
 				      AMDGPU_BO_LIST_MAX_PRIORITY);
-		if (amdgpu_ttm_tt_has_userptr(entry->robj->tbo.ttm))
+		usermm = amdgpu_ttm_tt_get_usermm(entry->robj->tbo.ttm);
+		if (usermm) {
+			if (usermm != current->mm) {
+				r = -EPERM;
+				goto error_free;
+			}
 			has_userptr = true;
+		}
 		entry->tv.bo = &entry->robj->tbo;
 		entry->tv.shared = true;
 
@@ -142,7 +152,7 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 
 error_free:
 	drm_free_large(array);
-	return -ENOENT;
+	return r;
 }
 
 struct amdgpu_bo_list *

commit 1ea863fd736eed8217a0b7bc5d0bd0de6b267b80
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Dec 18 22:13:12 2015 +0100

    drm/amdgpu: keep the prefered/allowed domains in the BO
    
    Stop copying that to the bo list entry, it doesn't change anyway.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 9da4bd02cec3..c4341dd4b6a4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -111,23 +111,16 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 		drm_gem_object_unreference_unlocked(gobj);
 		entry->priority = min(info[i].bo_priority,
 				      AMDGPU_BO_LIST_MAX_PRIORITY);
-		entry->prefered_domains = entry->robj->initial_domain;
-		entry->allowed_domains = entry->prefered_domains;
-		if (entry->allowed_domains == AMDGPU_GEM_DOMAIN_VRAM)
-			entry->allowed_domains |= AMDGPU_GEM_DOMAIN_GTT;
-		if (amdgpu_ttm_tt_has_userptr(entry->robj->tbo.ttm)) {
+		if (amdgpu_ttm_tt_has_userptr(entry->robj->tbo.ttm))
 			has_userptr = true;
-			entry->prefered_domains = AMDGPU_GEM_DOMAIN_GTT;
-			entry->allowed_domains = AMDGPU_GEM_DOMAIN_GTT;
-		}
 		entry->tv.bo = &entry->robj->tbo;
 		entry->tv.shared = true;
 
-		if (entry->prefered_domains == AMDGPU_GEM_DOMAIN_GDS)
+		if (entry->robj->prefered_domains == AMDGPU_GEM_DOMAIN_GDS)
 			gds_obj = entry->robj;
-		if (entry->prefered_domains == AMDGPU_GEM_DOMAIN_GWS)
+		if (entry->robj->prefered_domains == AMDGPU_GEM_DOMAIN_GWS)
 			gws_obj = entry->robj;
-		if (entry->prefered_domains == AMDGPU_GEM_DOMAIN_OA)
+		if (entry->robj->prefered_domains == AMDGPU_GEM_DOMAIN_OA)
 			oa_obj = entry->robj;
 
 		trace_amdgpu_bo_list_set(list, entry->robj);

commit 636ce25c30010a8f393f5a1e67d5d4b7b66739e7
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Dec 18 21:26:47 2015 +0100

    drm/amdgpu: cleanup bo list bucket handling
    
    Move that into the BO list. No functional change.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index f82a2dd83874..9da4bd02cec3 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -32,6 +32,9 @@
 #include "amdgpu.h"
 #include "amdgpu_trace.h"
 
+#define AMDGPU_BO_LIST_MAX_PRIORITY	32u
+#define AMDGPU_BO_LIST_NUM_BUCKETS	(AMDGPU_BO_LIST_MAX_PRIORITY + 1)
+
 static int amdgpu_bo_list_create(struct amdgpu_fpriv *fpriv,
 				 struct amdgpu_bo_list **result,
 				 int *id)
@@ -106,7 +109,8 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 
 		entry->robj = amdgpu_bo_ref(gem_to_amdgpu_bo(gobj));
 		drm_gem_object_unreference_unlocked(gobj);
-		entry->priority = info[i].bo_priority;
+		entry->priority = min(info[i].bo_priority,
+				      AMDGPU_BO_LIST_MAX_PRIORITY);
 		entry->prefered_domains = entry->robj->initial_domain;
 		entry->allowed_domains = entry->prefered_domains;
 		if (entry->allowed_domains == AMDGPU_GEM_DOMAIN_VRAM)
@@ -161,6 +165,36 @@ amdgpu_bo_list_get(struct amdgpu_fpriv *fpriv, int id)
 	return result;
 }
 
+void amdgpu_bo_list_get_list(struct amdgpu_bo_list *list,
+			     struct list_head *validated)
+{
+	/* This is based on the bucket sort with O(n) time complexity.
+	 * An item with priority "i" is added to bucket[i]. The lists are then
+	 * concatenated in descending order.
+	 */
+	struct list_head bucket[AMDGPU_BO_LIST_NUM_BUCKETS];
+	unsigned i;
+
+	for (i = 0; i < AMDGPU_BO_LIST_NUM_BUCKETS; i++)
+		INIT_LIST_HEAD(&bucket[i]);
+
+	/* Since buffers which appear sooner in the relocation list are
+	 * likely to be used more often than buffers which appear later
+	 * in the list, the sort mustn't change the ordering of buffers
+	 * with the same priority, i.e. it must be stable.
+	 */
+	for (i = 0; i < list->num_entries; i++) {
+		unsigned priority = list->array[i].priority;
+
+		list_add_tail(&list->array[i].tv.head,
+			      &bucket[priority]);
+	}
+
+	/* Connect the sorted buckets in the output list. */
+	for (i = 0; i < AMDGPU_BO_LIST_NUM_BUCKETS; i++)
+		list_splice(&bucket[i], validated);
+}
+
 void amdgpu_bo_list_put(struct amdgpu_bo_list *list)
 {
 	mutex_unlock(&list->lock);

commit ec74407ac047c150080758f2a4cec47393a6c0f8
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Jun 10 14:45:21 2015 +0200

    drm/amdgpu: add amdgpu_bo_list_set trace point
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Alex Deucher <aleander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 36d34e0afbc3..f82a2dd83874 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -30,6 +30,7 @@
 
 #include <drm/drmP.h>
 #include "amdgpu.h"
+#include "amdgpu_trace.h"
 
 static int amdgpu_bo_list_create(struct amdgpu_fpriv *fpriv,
 				 struct amdgpu_bo_list **result,
@@ -124,6 +125,8 @@ static int amdgpu_bo_list_set(struct amdgpu_device *adev,
 			gws_obj = entry->robj;
 		if (entry->prefered_domains == AMDGPU_GEM_DOMAIN_OA)
 			oa_obj = entry->robj;
+
+		trace_amdgpu_bo_list_set(list, entry->robj);
 	}
 
 	for (i = 0; i < list->num_entries; ++i)

commit decee87a88c05980ebc545c19d4ff252052ddc3e
Author: monk.liu <monk.liu@amd.com>
Date:   Mon Apr 27 10:38:16 2015 +0800

    drm/amdgpu: let bo_list handler start from 1
    
    this could prevent mis-understanding, because libdrm side will consider
    no bo_list created if handleis zero
    
    Signed-off-by: monk.liu <monk.liu@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
index 819fb861ac04..36d34e0afbc3 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -43,7 +43,7 @@ static int amdgpu_bo_list_create(struct amdgpu_fpriv *fpriv,
 
 	mutex_lock(&fpriv->bo_list_lock);
 	r = idr_alloc(&fpriv->bo_list_handles, *result,
-		      0, 0, GFP_KERNEL);
+		      1, 0, GFP_KERNEL);
 	if (r < 0) {
 		mutex_unlock(&fpriv->bo_list_lock);
 		kfree(*result);

commit d38ceaf99ed015f2a0b9af3499791bd3a3daae21
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Mon Apr 20 16:55:21 2015 -0400

    drm/amdgpu: add core driver (v4)
    
    This adds the non-asic specific core driver code.
    
    v2: remove extra kconfig option
    v3: implement minor fixes from Fengguang Wu
    v4: fix cast in amdgpu_ucode.c
    
    Acked-by: Christian König <christian.koenig@amd.com>
    Acked-by: Jammy Zhou <Jammy.Zhou@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
new file mode 100644
index 000000000000..819fb861ac04
--- /dev/null
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -0,0 +1,268 @@
+/*
+ * Copyright 2015 Advanced Micro Devices, Inc.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sub license, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDERS, AUTHORS AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM,
+ * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
+ * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
+ * USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ */
+/*
+ * Authors:
+ *    Christian König <deathsimple@vodafone.de>
+ */
+
+#include <drm/drmP.h>
+#include "amdgpu.h"
+
+static int amdgpu_bo_list_create(struct amdgpu_fpriv *fpriv,
+				 struct amdgpu_bo_list **result,
+				 int *id)
+{
+	int r;
+
+	*result = kzalloc(sizeof(struct amdgpu_bo_list), GFP_KERNEL);
+	if (!*result)
+		return -ENOMEM;
+
+	mutex_lock(&fpriv->bo_list_lock);
+	r = idr_alloc(&fpriv->bo_list_handles, *result,
+		      0, 0, GFP_KERNEL);
+	if (r < 0) {
+		mutex_unlock(&fpriv->bo_list_lock);
+		kfree(*result);
+		return r;
+	}
+	*id = r;
+
+	mutex_init(&(*result)->lock);
+	(*result)->num_entries = 0;
+	(*result)->array = NULL;
+
+	mutex_lock(&(*result)->lock);
+	mutex_unlock(&fpriv->bo_list_lock);
+
+	return 0;
+}
+
+static void amdgpu_bo_list_destroy(struct amdgpu_fpriv *fpriv, int id)
+{
+	struct amdgpu_bo_list *list;
+
+	mutex_lock(&fpriv->bo_list_lock);
+	list = idr_find(&fpriv->bo_list_handles, id);
+	if (list) {
+		mutex_lock(&list->lock);
+		idr_remove(&fpriv->bo_list_handles, id);
+		mutex_unlock(&list->lock);
+		amdgpu_bo_list_free(list);
+	}
+	mutex_unlock(&fpriv->bo_list_lock);
+}
+
+static int amdgpu_bo_list_set(struct amdgpu_device *adev,
+				     struct drm_file *filp,
+				     struct amdgpu_bo_list *list,
+				     struct drm_amdgpu_bo_list_entry *info,
+				     unsigned num_entries)
+{
+	struct amdgpu_bo_list_entry *array;
+	struct amdgpu_bo *gds_obj = adev->gds.gds_gfx_bo;
+	struct amdgpu_bo *gws_obj = adev->gds.gws_gfx_bo;
+	struct amdgpu_bo *oa_obj = adev->gds.oa_gfx_bo;
+
+	bool has_userptr = false;
+	unsigned i;
+
+	array = drm_malloc_ab(num_entries, sizeof(struct amdgpu_bo_list_entry));
+	if (!array)
+		return -ENOMEM;
+	memset(array, 0, num_entries * sizeof(struct amdgpu_bo_list_entry));
+
+	for (i = 0; i < num_entries; ++i) {
+		struct amdgpu_bo_list_entry *entry = &array[i];
+		struct drm_gem_object *gobj;
+
+		gobj = drm_gem_object_lookup(adev->ddev, filp, info[i].bo_handle);
+		if (!gobj)
+			goto error_free;
+
+		entry->robj = amdgpu_bo_ref(gem_to_amdgpu_bo(gobj));
+		drm_gem_object_unreference_unlocked(gobj);
+		entry->priority = info[i].bo_priority;
+		entry->prefered_domains = entry->robj->initial_domain;
+		entry->allowed_domains = entry->prefered_domains;
+		if (entry->allowed_domains == AMDGPU_GEM_DOMAIN_VRAM)
+			entry->allowed_domains |= AMDGPU_GEM_DOMAIN_GTT;
+		if (amdgpu_ttm_tt_has_userptr(entry->robj->tbo.ttm)) {
+			has_userptr = true;
+			entry->prefered_domains = AMDGPU_GEM_DOMAIN_GTT;
+			entry->allowed_domains = AMDGPU_GEM_DOMAIN_GTT;
+		}
+		entry->tv.bo = &entry->robj->tbo;
+		entry->tv.shared = true;
+
+		if (entry->prefered_domains == AMDGPU_GEM_DOMAIN_GDS)
+			gds_obj = entry->robj;
+		if (entry->prefered_domains == AMDGPU_GEM_DOMAIN_GWS)
+			gws_obj = entry->robj;
+		if (entry->prefered_domains == AMDGPU_GEM_DOMAIN_OA)
+			oa_obj = entry->robj;
+	}
+
+	for (i = 0; i < list->num_entries; ++i)
+		amdgpu_bo_unref(&list->array[i].robj);
+
+	drm_free_large(list->array);
+
+	list->gds_obj = gds_obj;
+	list->gws_obj = gws_obj;
+	list->oa_obj = oa_obj;
+	list->has_userptr = has_userptr;
+	list->array = array;
+	list->num_entries = num_entries;
+
+	return 0;
+
+error_free:
+	drm_free_large(array);
+	return -ENOENT;
+}
+
+struct amdgpu_bo_list *
+amdgpu_bo_list_get(struct amdgpu_fpriv *fpriv, int id)
+{
+	struct amdgpu_bo_list *result;
+
+	mutex_lock(&fpriv->bo_list_lock);
+	result = idr_find(&fpriv->bo_list_handles, id);
+	if (result)
+		mutex_lock(&result->lock);
+	mutex_unlock(&fpriv->bo_list_lock);
+	return result;
+}
+
+void amdgpu_bo_list_put(struct amdgpu_bo_list *list)
+{
+	mutex_unlock(&list->lock);
+}
+
+void amdgpu_bo_list_free(struct amdgpu_bo_list *list)
+{
+	unsigned i;
+
+	for (i = 0; i < list->num_entries; ++i)
+		amdgpu_bo_unref(&list->array[i].robj);
+
+	mutex_destroy(&list->lock);
+	drm_free_large(list->array);
+	kfree(list);
+}
+
+int amdgpu_bo_list_ioctl(struct drm_device *dev, void *data,
+				struct drm_file *filp)
+{
+	const uint32_t info_size = sizeof(struct drm_amdgpu_bo_list_entry);
+
+	struct amdgpu_device *adev = dev->dev_private;
+	struct amdgpu_fpriv *fpriv = filp->driver_priv;
+	union drm_amdgpu_bo_list *args = data;
+	uint32_t handle = args->in.list_handle;
+	const void __user *uptr = (const void*)(long)args->in.bo_info_ptr;
+
+	struct drm_amdgpu_bo_list_entry *info;
+	struct amdgpu_bo_list *list;
+
+	int r;
+
+	info = drm_malloc_ab(args->in.bo_number,
+			     sizeof(struct drm_amdgpu_bo_list_entry));
+	if (!info)
+		return -ENOMEM;
+
+	/* copy the handle array from userspace to a kernel buffer */
+	r = -EFAULT;
+	if (likely(info_size == args->in.bo_info_size)) {
+		unsigned long bytes = args->in.bo_number *
+			args->in.bo_info_size;
+
+		if (copy_from_user(info, uptr, bytes))
+			goto error_free;
+
+	} else {
+		unsigned long bytes = min(args->in.bo_info_size, info_size);
+		unsigned i;
+
+		memset(info, 0, args->in.bo_number * info_size);
+		for (i = 0; i < args->in.bo_number; ++i) {
+			if (copy_from_user(&info[i], uptr, bytes))
+				goto error_free;
+			
+			uptr += args->in.bo_info_size;
+		}
+	}
+
+	switch (args->in.operation) {
+	case AMDGPU_BO_LIST_OP_CREATE:
+		r = amdgpu_bo_list_create(fpriv, &list, &handle);
+		if (r) 
+			goto error_free;
+
+		r = amdgpu_bo_list_set(adev, filp, list, info,
+					      args->in.bo_number);
+		amdgpu_bo_list_put(list);
+		if (r)
+			goto error_free;
+
+		break;
+		
+	case AMDGPU_BO_LIST_OP_DESTROY:
+		amdgpu_bo_list_destroy(fpriv, handle);
+		handle = 0;
+		break;
+
+	case AMDGPU_BO_LIST_OP_UPDATE:
+		r = -ENOENT;
+		list = amdgpu_bo_list_get(fpriv, handle);
+		if (!list)
+			goto error_free;
+
+		r = amdgpu_bo_list_set(adev, filp, list, info,
+					      args->in.bo_number);
+		amdgpu_bo_list_put(list);
+		if (r)
+			goto error_free;
+
+		break;
+
+	default:
+		r = -EINVAL;
+		goto error_free;
+	}
+
+	memset(args, 0, sizeof(*args));
+	args->out.list_handle = handle;
+	drm_free_large(info);
+
+	return 0;
+
+error_free:
+	drm_free_large(info);
+	return r;
+}
