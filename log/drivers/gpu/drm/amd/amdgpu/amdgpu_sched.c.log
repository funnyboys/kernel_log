commit f867723b41f871c88388462c007976bb9a4c72da
Author: Sam Ravnborg <sam@ravnborg.org>
Date:   Mon Jun 10 00:07:51 2019 +0200

    drm/amd: drop use of drmP.h in amdgpu.h
    
    Delete the unused drmP.h from amdgpu.h.
    Fix fallout in various files.
    
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: "Christian König" <christian.koenig@amd.com>
    Cc: "David (ChunMing) Zhou" <David1.Zhou@amd.com>
    Cc: David Airlie <airlied@linux.ie>
    Cc: Daniel Vetter <daniel@ffwll.ch>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190609220757.10862-5-sam@ravnborg.org

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 639297250c21..c799691dfa84 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -23,8 +23,11 @@
  */
 
 #include <linux/fdtable.h>
+#include <linux/file.h>
 #include <linux/pid.h>
+
 #include <drm/amdgpu_drm.h>
+
 #include "amdgpu.h"
 
 #include "amdgpu_vm.h"

commit 95ce0bce20fe67c750c0c26491a8c6819daeab94
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Apr 14 12:49:44 2019 -0400

    amdgpu: switch to fdget()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 0767a93e4d91..639297250c21 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -53,26 +53,25 @@ static int amdgpu_sched_process_priority_override(struct amdgpu_device *adev,
 						  int fd,
 						  enum drm_sched_priority priority)
 {
-	struct file *filp = fget(fd);
+	struct fd f = fdget(fd);
 	struct amdgpu_fpriv *fpriv;
 	struct amdgpu_ctx *ctx;
 	uint32_t id;
 	int r;
 
-	if (!filp)
+	if (!f.file)
 		return -EINVAL;
 
-	r = amdgpu_file_to_fpriv(filp, &fpriv);
+	r = amdgpu_file_to_fpriv(f.file, &fpriv);
 	if (r) {
-		fput(filp);
+		fdput(f);
 		return r;
 	}
 
 	idr_for_each_entry(&fpriv->ctx_mgr.ctx_handles, ctx, id)
 		amdgpu_ctx_priority_override(ctx, priority);
 
-	fput(filp);
-
+	fdput(f);
 	return 0;
 }
 
@@ -81,30 +80,30 @@ static int amdgpu_sched_context_priority_override(struct amdgpu_device *adev,
 						  unsigned ctx_id,
 						  enum drm_sched_priority priority)
 {
-	struct file *filp = fget(fd);
+	struct fd f = fdget(fd);
 	struct amdgpu_fpriv *fpriv;
 	struct amdgpu_ctx *ctx;
 	int r;
 
-	if (!filp)
+	if (!f.file)
 		return -EINVAL;
 
-	r = amdgpu_file_to_fpriv(filp, &fpriv);
+	r = amdgpu_file_to_fpriv(f.file, &fpriv);
 	if (r) {
-		fput(filp);
+		fdput(f);
 		return r;
 	}
 
 	ctx = amdgpu_ctx_get(fpriv, ctx_id);
 
 	if (!ctx) {
-		fput(filp);
+		fdput(f);
 		return -EINVAL;
 	}
 
 	amdgpu_ctx_priority_override(ctx, priority);
 	amdgpu_ctx_put(ctx);
-	fput(filp);
+	fdput(f);
 
 	return 0;
 }

commit b5bb37eddb63b16b7ab959598d108b1c444be77d
Author: Bas Nieuwenhuizen <bas@basnieuwenhuizen.nl>
Date:   Wed Jan 30 02:53:22 2019 +0100

    drm/amdgpu: Add command to override the context priority.
    
    Given a master fd we can then override the priority of the context
    in another fd.
    
    Using these overrides was recommended by Christian instead of trying
    to submit from a master fd, and I am adding a way to override a
    single context instead of the entire process so we can only upgrade
    a single Vulkan queue and not effectively the entire process.
    
    Reused the flags field as it was checked to be 0 anyways, so nothing
    used it. This is source-incompatible (due to the name change), but
    ABI compatible.
    
    Signed-off-by: Bas Nieuwenhuizen <bas@basnieuwenhuizen.nl>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 0b70410488b6..0767a93e4d91 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -76,6 +76,39 @@ static int amdgpu_sched_process_priority_override(struct amdgpu_device *adev,
 	return 0;
 }
 
+static int amdgpu_sched_context_priority_override(struct amdgpu_device *adev,
+						  int fd,
+						  unsigned ctx_id,
+						  enum drm_sched_priority priority)
+{
+	struct file *filp = fget(fd);
+	struct amdgpu_fpriv *fpriv;
+	struct amdgpu_ctx *ctx;
+	int r;
+
+	if (!filp)
+		return -EINVAL;
+
+	r = amdgpu_file_to_fpriv(filp, &fpriv);
+	if (r) {
+		fput(filp);
+		return r;
+	}
+
+	ctx = amdgpu_ctx_get(fpriv, ctx_id);
+
+	if (!ctx) {
+		fput(filp);
+		return -EINVAL;
+	}
+
+	amdgpu_ctx_priority_override(ctx, priority);
+	amdgpu_ctx_put(ctx);
+	fput(filp);
+
+	return 0;
+}
+
 int amdgpu_sched_ioctl(struct drm_device *dev, void *data,
 		       struct drm_file *filp)
 {
@@ -85,7 +118,7 @@ int amdgpu_sched_ioctl(struct drm_device *dev, void *data,
 	int r;
 
 	priority = amdgpu_to_sched_priority(args->in.priority);
-	if (args->in.flags || priority == DRM_SCHED_PRIORITY_INVALID)
+	if (priority == DRM_SCHED_PRIORITY_INVALID)
 		return -EINVAL;
 
 	switch (args->in.op) {
@@ -94,6 +127,12 @@ int amdgpu_sched_ioctl(struct drm_device *dev, void *data,
 							   args->in.fd,
 							   priority);
 		break;
+	case AMDGPU_SCHED_OP_CONTEXT_PRIORITY_OVERRIDE:
+		r = amdgpu_sched_context_priority_override(adev,
+							   args->in.fd,
+							   args->in.ctx_id,
+							   priority);
+		break;
 	default:
 		DRM_ERROR("Invalid sched op specified: %d\n", args->in.op);
 		r = -EINVAL;

commit 021830d24ba55a578f602979274965344c8e6284
Author: Bas Nieuwenhuizen <bas@basnieuwenhuizen.nl>
Date:   Wed Jan 30 02:53:21 2019 +0100

    drm/amdgpu: Check if fd really is an amdgpu fd.
    
    Otherwise we interpret the file private data as drm & amdgpu data
    while it might not be, possibly allowing one to get memory corruption.
    
    Signed-off-by: Bas Nieuwenhuizen <bas@basnieuwenhuizen.nl>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 1cafe8d83a4d..0b70410488b6 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -54,16 +54,20 @@ static int amdgpu_sched_process_priority_override(struct amdgpu_device *adev,
 						  enum drm_sched_priority priority)
 {
 	struct file *filp = fget(fd);
-	struct drm_file *file;
 	struct amdgpu_fpriv *fpriv;
 	struct amdgpu_ctx *ctx;
 	uint32_t id;
+	int r;
 
 	if (!filp)
 		return -EINVAL;
 
-	file = filp->private_data;
-	fpriv = file->driver_priv;
+	r = amdgpu_file_to_fpriv(filp, &fpriv);
+	if (r) {
+		fput(filp);
+		return r;
+	}
+
 	idr_for_each_entry(&fpriv->ctx_mgr.ctx_handles, ctx, id)
 		amdgpu_ctx_priority_override(ctx, priority);
 

commit c4aed87630d41ee54e2ee23d4583c3dd423296dd
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Aug 17 19:38:33 2018 +0200

    drm/amdgpu: fix incorrect use of drm_file->pid
    
    That's the PID of the creator of the file (usually the X server) and not
    the end user of the file.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    CC: stable@vger.kernel.org

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index cb62a90d0686..1cafe8d83a4d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -55,7 +55,6 @@ static int amdgpu_sched_process_priority_override(struct amdgpu_device *adev,
 {
 	struct file *filp = fget(fd);
 	struct drm_file *file;
-	struct pid *pid;
 	struct amdgpu_fpriv *fpriv;
 	struct amdgpu_ctx *ctx;
 	uint32_t id;
@@ -63,20 +62,10 @@ static int amdgpu_sched_process_priority_override(struct amdgpu_device *adev,
 	if (!filp)
 		return -EINVAL;
 
-	pid = get_pid(((struct drm_file *)filp->private_data)->pid);
-
-	mutex_lock(&adev->ddev->filelist_mutex);
-	list_for_each_entry(file, &adev->ddev->filelist, lhead) {
-		if (file->pid != pid)
-			continue;
-
-		fpriv = file->driver_priv;
-		idr_for_each_entry(&fpriv->ctx_mgr.ctx_handles, ctx, id)
-				amdgpu_ctx_priority_override(ctx, priority);
-	}
-	mutex_unlock(&adev->ddev->filelist_mutex);
-
-	put_pid(pid);
+	file = filp->private_data;
+	fpriv = file->driver_priv;
+	idr_for_each_entry(&fpriv->ctx_mgr.ctx_handles, ctx, id)
+		amdgpu_ctx_priority_override(ctx, priority);
 
 	fput(filp);
 

commit bce31d4c1ae8865d6382e3a27b07b4bb8e020ade
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Aug 17 19:36:08 2018 +0200

    drm/amdgpu: fix incorrect use of fcheck
    
    The usage isn't RCU protected.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    CC: stable@vger.kernel.org

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 86a0715d9431..cb62a90d0686 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -53,7 +53,7 @@ static int amdgpu_sched_process_priority_override(struct amdgpu_device *adev,
 						  int fd,
 						  enum drm_sched_priority priority)
 {
-	struct file *filp = fcheck(fd);
+	struct file *filp = fget(fd);
 	struct drm_file *file;
 	struct pid *pid;
 	struct amdgpu_fpriv *fpriv;
@@ -78,6 +78,8 @@ static int amdgpu_sched_process_priority_override(struct amdgpu_device *adev,
 
 	put_pid(pid);
 
+	fput(filp);
+
 	return 0;
 }
 

commit 1b1f42d8fde4fef1ed7873bf5aa91755f8c3de35
Author: Lucas Stach <l.stach@pengutronix.de>
Date:   Wed Dec 6 17:49:39 2017 +0100

    drm: move amd_gpu_scheduler into common location
    
    This moves and renames the AMDGPU scheduler to a common location in DRM
    in order to facilitate re-use by other drivers. This is mostly a straight
    forward rename with no code changes.
    
    One notable exception is the function to_drm_sched_fence(), which is no
    longer a inline header function to avoid the need to export the
    drm_sched_fence_ops_scheduled and drm_sched_fence_ops_finished structures.
    
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Tested-by: Dieter Nützel <Dieter@nuetzel-hh.de>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Lucas Stach <l.stach@pengutronix.de>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 290cc3f9c433..86a0715d9431 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -29,29 +29,29 @@
 
 #include "amdgpu_vm.h"
 
-enum amd_sched_priority amdgpu_to_sched_priority(int amdgpu_priority)
+enum drm_sched_priority amdgpu_to_sched_priority(int amdgpu_priority)
 {
 	switch (amdgpu_priority) {
 	case AMDGPU_CTX_PRIORITY_VERY_HIGH:
-		return AMD_SCHED_PRIORITY_HIGH_HW;
+		return DRM_SCHED_PRIORITY_HIGH_HW;
 	case AMDGPU_CTX_PRIORITY_HIGH:
-		return AMD_SCHED_PRIORITY_HIGH_SW;
+		return DRM_SCHED_PRIORITY_HIGH_SW;
 	case AMDGPU_CTX_PRIORITY_NORMAL:
-		return AMD_SCHED_PRIORITY_NORMAL;
+		return DRM_SCHED_PRIORITY_NORMAL;
 	case AMDGPU_CTX_PRIORITY_LOW:
 	case AMDGPU_CTX_PRIORITY_VERY_LOW:
-		return AMD_SCHED_PRIORITY_LOW;
+		return DRM_SCHED_PRIORITY_LOW;
 	case AMDGPU_CTX_PRIORITY_UNSET:
-		return AMD_SCHED_PRIORITY_UNSET;
+		return DRM_SCHED_PRIORITY_UNSET;
 	default:
 		WARN(1, "Invalid context priority %d\n", amdgpu_priority);
-		return AMD_SCHED_PRIORITY_INVALID;
+		return DRM_SCHED_PRIORITY_INVALID;
 	}
 }
 
 static int amdgpu_sched_process_priority_override(struct amdgpu_device *adev,
 						  int fd,
-						  enum amd_sched_priority priority)
+						  enum drm_sched_priority priority)
 {
 	struct file *filp = fcheck(fd);
 	struct drm_file *file;
@@ -86,11 +86,11 @@ int amdgpu_sched_ioctl(struct drm_device *dev, void *data,
 {
 	union drm_amdgpu_sched *args = data;
 	struct amdgpu_device *adev = dev->dev_private;
-	enum amd_sched_priority priority;
+	enum drm_sched_priority priority;
 	int r;
 
 	priority = amdgpu_to_sched_priority(args->in.priority);
-	if (args->in.flags || priority == AMD_SCHED_PRIORITY_INVALID)
+	if (args->in.flags || priority == DRM_SCHED_PRIORITY_INVALID)
 		return -EINVAL;
 
 	switch (args->in.op) {

commit 8bc4c256f4995d315eb9cce6e47b4885c79ff661
Author: Andres Rodriguez <andresx7@gmail.com>
Date:   Fri Oct 13 14:58:14 2017 -0400

    drm/amdgpu: rename context priority levels
    
    Don't leak implementation details about how each priority behaves to
    usermode. This allows greater flexibility in the future.
    
    Squash into c2636dc53abd8269a0930bccd564f2f195dba729
    
    Signed-off-by: Andres Rodriguez <andresx7@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index cd123306eda7..290cc3f9c433 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -32,14 +32,14 @@
 enum amd_sched_priority amdgpu_to_sched_priority(int amdgpu_priority)
 {
 	switch (amdgpu_priority) {
-	case AMDGPU_CTX_PRIORITY_HIGH_HW:
+	case AMDGPU_CTX_PRIORITY_VERY_HIGH:
 		return AMD_SCHED_PRIORITY_HIGH_HW;
-	case AMDGPU_CTX_PRIORITY_HIGH_SW:
+	case AMDGPU_CTX_PRIORITY_HIGH:
 		return AMD_SCHED_PRIORITY_HIGH_SW;
 	case AMDGPU_CTX_PRIORITY_NORMAL:
 		return AMD_SCHED_PRIORITY_NORMAL;
-	case AMDGPU_CTX_PRIORITY_LOW_SW:
-	case AMDGPU_CTX_PRIORITY_LOW_HW:
+	case AMDGPU_CTX_PRIORITY_LOW:
+	case AMDGPU_CTX_PRIORITY_VERY_LOW:
 		return AMD_SCHED_PRIORITY_LOW;
 	case AMDGPU_CTX_PRIORITY_UNSET:
 		return AMD_SCHED_PRIORITY_UNSET;

commit 52c6a62c64fac03a434cdacf6ef671c6a9e9000f
Author: Andres Rodriguez <andresx7@gmail.com>
Date:   Mon Jun 26 16:17:13 2017 -0400

    drm/amdgpu: add interface for editing a foreign process's priority v3
    
    The AMDGPU_SCHED_OP_PROCESS_PRIORITY_OVERRIDE ioctls are used to set
    the priority of a different process in the current system.
    
    When a request is dropped, the process's contexts will be
    restored to the priority specified at context creation time.
    
    A request can be dropped by setting the override priority to
    AMDGPU_CTX_PRIORITY_UNSET.
    
    An fd is used to identify the remote process. This is simpler than
    passing a pid number, which is vulnerable to re-use, etc.
    
    This functionality is limited to DRM_MASTER since abuse of this
    interface can have a negative impact on the system's performance.
    
    v2: removed unused output structure
    v3: change refcounted interface for a regular set operation
    
    Signed-off-by: Andres Rodriguez <andresx7@gmail.com>
    Acked-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
new file mode 100644
index 000000000000..cd123306eda7
--- /dev/null
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -0,0 +1,109 @@
+/*
+ * Copyright 2017 Valve Corporation
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Andres Rodriguez <andresx7@gmail.com>
+ */
+
+#include <linux/fdtable.h>
+#include <linux/pid.h>
+#include <drm/amdgpu_drm.h>
+#include "amdgpu.h"
+
+#include "amdgpu_vm.h"
+
+enum amd_sched_priority amdgpu_to_sched_priority(int amdgpu_priority)
+{
+	switch (amdgpu_priority) {
+	case AMDGPU_CTX_PRIORITY_HIGH_HW:
+		return AMD_SCHED_PRIORITY_HIGH_HW;
+	case AMDGPU_CTX_PRIORITY_HIGH_SW:
+		return AMD_SCHED_PRIORITY_HIGH_SW;
+	case AMDGPU_CTX_PRIORITY_NORMAL:
+		return AMD_SCHED_PRIORITY_NORMAL;
+	case AMDGPU_CTX_PRIORITY_LOW_SW:
+	case AMDGPU_CTX_PRIORITY_LOW_HW:
+		return AMD_SCHED_PRIORITY_LOW;
+	case AMDGPU_CTX_PRIORITY_UNSET:
+		return AMD_SCHED_PRIORITY_UNSET;
+	default:
+		WARN(1, "Invalid context priority %d\n", amdgpu_priority);
+		return AMD_SCHED_PRIORITY_INVALID;
+	}
+}
+
+static int amdgpu_sched_process_priority_override(struct amdgpu_device *adev,
+						  int fd,
+						  enum amd_sched_priority priority)
+{
+	struct file *filp = fcheck(fd);
+	struct drm_file *file;
+	struct pid *pid;
+	struct amdgpu_fpriv *fpriv;
+	struct amdgpu_ctx *ctx;
+	uint32_t id;
+
+	if (!filp)
+		return -EINVAL;
+
+	pid = get_pid(((struct drm_file *)filp->private_data)->pid);
+
+	mutex_lock(&adev->ddev->filelist_mutex);
+	list_for_each_entry(file, &adev->ddev->filelist, lhead) {
+		if (file->pid != pid)
+			continue;
+
+		fpriv = file->driver_priv;
+		idr_for_each_entry(&fpriv->ctx_mgr.ctx_handles, ctx, id)
+				amdgpu_ctx_priority_override(ctx, priority);
+	}
+	mutex_unlock(&adev->ddev->filelist_mutex);
+
+	put_pid(pid);
+
+	return 0;
+}
+
+int amdgpu_sched_ioctl(struct drm_device *dev, void *data,
+		       struct drm_file *filp)
+{
+	union drm_amdgpu_sched *args = data;
+	struct amdgpu_device *adev = dev->dev_private;
+	enum amd_sched_priority priority;
+	int r;
+
+	priority = amdgpu_to_sched_priority(args->in.priority);
+	if (args->in.flags || priority == AMD_SCHED_PRIORITY_INVALID)
+		return -EINVAL;
+
+	switch (args->in.op) {
+	case AMDGPU_SCHED_OP_PROCESS_PRIORITY_OVERRIDE:
+		r = amdgpu_sched_process_priority_override(adev,
+							   args->in.fd,
+							   priority);
+		break;
+	default:
+		DRM_ERROR("Invalid sched op specified: %d\n", args->in.op);
+		r = -EINVAL;
+		break;
+	}
+
+	return r;
+}

commit 0856cab1a6298d9cbf037dc683ce514cadb28040
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Feb 1 12:31:01 2016 +0100

    drm/amdgpu: rename amdgpu_sched.c to amdgpu_job.c
    
    That's probably a better matching name.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
deleted file mode 100644
index bbdda727f89a..000000000000
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ /dev/null
@@ -1,151 +0,0 @@
-/*
- * Copyright 2015 Advanced Micro Devices, Inc.
- *
- * Permission is hereby granted, free of charge, to any person obtaining a
- * copy of this software and associated documentation files (the "Software"),
- * to deal in the Software without restriction, including without limitation
- * the rights to use, copy, modify, merge, publish, distribute, sublicense,
- * and/or sell copies of the Software, and to permit persons to whom the
- * Software is furnished to do so, subject to the following conditions:
- *
- * The above copyright notice and this permission notice shall be included in
- * all copies or substantial portions of the Software.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
- * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
- * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
- * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
- * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
- * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
- * OTHER DEALINGS IN THE SOFTWARE.
- *
- *
- */
-#include <linux/kthread.h>
-#include <linux/wait.h>
-#include <linux/sched.h>
-#include <drm/drmP.h>
-#include "amdgpu.h"
-#include "amdgpu_trace.h"
-
-int amdgpu_job_alloc(struct amdgpu_device *adev, unsigned num_ibs,
-		     struct amdgpu_job **job)
-{
-	size_t size = sizeof(struct amdgpu_job);
-
-	if (num_ibs == 0)
-		return -EINVAL;
-
-	size += sizeof(struct amdgpu_ib) * num_ibs;
-
-	*job = kzalloc(size, GFP_KERNEL);
-	if (!*job)
-		return -ENOMEM;
-
-	(*job)->adev = adev;
-	(*job)->ibs = (void *)&(*job)[1];
-	(*job)->num_ibs = num_ibs;
-
-	return 0;
-}
-
-int amdgpu_job_alloc_with_ib(struct amdgpu_device *adev, unsigned size,
-			     struct amdgpu_job **job)
-{
-	int r;
-
-	r = amdgpu_job_alloc(adev, 1, job);
-	if (r)
-		return r;
-
-	r = amdgpu_ib_get(adev, NULL, size, &(*job)->ibs[0]);
-	if (r)
-		kfree(*job);
-
-	return r;
-}
-
-void amdgpu_job_free(struct amdgpu_job *job)
-{
-	unsigned i;
-
-	for (i = 0; i < job->num_ibs; ++i)
-		amdgpu_ib_free(job->adev, &job->ibs[i]);
-
-	amdgpu_bo_unref(&job->uf.bo);
-	kfree(job);
-}
-
-int amdgpu_job_submit(struct amdgpu_job *job, struct amdgpu_ring *ring,
-		      void *owner, struct fence **f)
-{
-	struct amdgpu_device *adev = job->adev;
-
-	job->ring = ring;
-	job->base.sched = &ring->sched;
-	job->base.s_entity = &adev->kernel_ctx.rings[ring->idx].entity;
-	job->base.s_fence = amd_sched_fence_create(job->base.s_entity, owner);
-	if (!job->base.s_fence)
-		return -ENOMEM;
-
-	*f = fence_get(&job->base.s_fence->base);
-
-	job->owner = owner;
-	amd_sched_entity_push_job(&job->base);
-
-	return 0;
-}
-
-static struct fence *amdgpu_sched_dependency(struct amd_sched_job *sched_job)
-{
-	struct amdgpu_job *job = to_amdgpu_job(sched_job);
-	struct amdgpu_sync *sync = &job->ibs->sync;
-	struct amdgpu_vm *vm = job->ibs->vm;
-
-	struct fence *fence = amdgpu_sync_get_fence(sync);
-
-	if (fence == NULL && vm && !job->ibs->grabbed_vmid) {
-		struct amdgpu_ring *ring = job->ring;
-		int r;
-
-		r = amdgpu_vm_grab_id(vm, ring, sync,
-				      &job->base.s_fence->base);
-		if (r)
-			DRM_ERROR("Error getting VM ID (%d)\n", r);
-		else
-			job->ibs->grabbed_vmid = true;
-
-		fence = amdgpu_sync_get_fence(sync);
-	}
-
-	return fence;
-}
-
-static struct fence *amdgpu_sched_run_job(struct amd_sched_job *sched_job)
-{
-	struct fence *fence = NULL;
-	struct amdgpu_job *job;
-	int r;
-
-	if (!sched_job) {
-		DRM_ERROR("job is null\n");
-		return NULL;
-	}
-	job = to_amdgpu_job(sched_job);
-	trace_amdgpu_sched_run_job(job);
-	r = amdgpu_ib_schedule(job->ring, job->num_ibs, job->ibs,
-			       job->owner, &fence);
-	if (r) {
-		DRM_ERROR("Error scheduling IBs (%d)\n", r);
-		goto err;
-	}
-
-err:
-	amdgpu_job_free(job);
-	return fence;
-}
-
-struct amd_sched_backend_ops amdgpu_sched_ops = {
-	.dependency = amdgpu_sched_dependency,
-	.run_job = amdgpu_sched_run_job,
-};

commit d71518b5aa7c9c298ffbd12ddd23297e3373a37b
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Feb 1 12:20:25 2016 +0100

    drm/amdgpu: cleanup in kernel job submission
    
    Add a job_alloc_with_ib helper and proper job submission.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index cabb0fc28610..bbdda727f89a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -45,11 +45,26 @@ int amdgpu_job_alloc(struct amdgpu_device *adev, unsigned num_ibs,
 	(*job)->adev = adev;
 	(*job)->ibs = (void *)&(*job)[1];
 	(*job)->num_ibs = num_ibs;
-	(*job)->free_job = NULL;
 
 	return 0;
 }
 
+int amdgpu_job_alloc_with_ib(struct amdgpu_device *adev, unsigned size,
+			     struct amdgpu_job **job)
+{
+	int r;
+
+	r = amdgpu_job_alloc(adev, 1, job);
+	if (r)
+		return r;
+
+	r = amdgpu_ib_get(adev, NULL, size, &(*job)->ibs[0]);
+	if (r)
+		kfree(*job);
+
+	return r;
+}
+
 void amdgpu_job_free(struct amdgpu_job *job)
 {
 	unsigned i;
@@ -58,7 +73,27 @@ void amdgpu_job_free(struct amdgpu_job *job)
 		amdgpu_ib_free(job->adev, &job->ibs[i]);
 
 	amdgpu_bo_unref(&job->uf.bo);
-	/* TODO: Free the job structure here as well */
+	kfree(job);
+}
+
+int amdgpu_job_submit(struct amdgpu_job *job, struct amdgpu_ring *ring,
+		      void *owner, struct fence **f)
+{
+	struct amdgpu_device *adev = job->adev;
+
+	job->ring = ring;
+	job->base.sched = &ring->sched;
+	job->base.s_entity = &adev->kernel_ctx.rings[ring->idx].entity;
+	job->base.s_fence = amd_sched_fence_create(job->base.s_entity, owner);
+	if (!job->base.s_fence)
+		return -ENOMEM;
+
+	*f = fence_get(&job->base.s_fence->base);
+
+	job->owner = owner;
+	amd_sched_entity_push_job(&job->base);
+
+	return 0;
 }
 
 static struct fence *amdgpu_sched_dependency(struct amd_sched_job *sched_job)
@@ -106,10 +141,7 @@ static struct fence *amdgpu_sched_run_job(struct amd_sched_job *sched_job)
 	}
 
 err:
-	if (job->free_job)
-		job->free_job(job);
-
-	kfree(job);
+	amdgpu_job_free(job);
 	return fence;
 }
 
@@ -117,35 +149,3 @@ struct amd_sched_backend_ops amdgpu_sched_ops = {
 	.dependency = amdgpu_sched_dependency,
 	.run_job = amdgpu_sched_run_job,
 };
-
-int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
-					 struct amdgpu_ring *ring,
-					 struct amdgpu_ib *ibs,
-					 unsigned num_ibs,
-					 int (*free_job)(struct amdgpu_job *),
-					 void *owner,
-					 struct fence **f)
-{
-	struct amdgpu_job *job =
-		kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
-	if (!job)
-		return -ENOMEM;
-	job->base.sched = &ring->sched;
-	job->base.s_entity = &adev->kernel_ctx.rings[ring->idx].entity;
-	job->base.s_fence = amd_sched_fence_create(job->base.s_entity, owner);
-	if (!job->base.s_fence) {
-		kfree(job);
-		return -ENOMEM;
-	}
-	*f = fence_get(&job->base.s_fence->base);
-
-	job->adev = adev;
-	job->ring = ring;
-	job->ibs = ibs;
-	job->num_ibs = num_ibs;
-	job->owner = owner;
-	job->free_job = free_job;
-	amd_sched_entity_push_job(&job->base);
-
-	return 0;
-}

commit ec72b8006c1e69f633e3def3e3b3c7c6318d271c
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Feb 1 11:56:35 2016 +0100

    drm/amdgpu: directly return fence from ib_schedule
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 84453c1c4b07..cabb0fc28610 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -88,7 +88,7 @@ static struct fence *amdgpu_sched_dependency(struct amd_sched_job *sched_job)
 
 static struct fence *amdgpu_sched_run_job(struct amd_sched_job *sched_job)
 {
-	struct amdgpu_fence *fence = NULL;
+	struct fence *fence = NULL;
 	struct amdgpu_job *job;
 	int r;
 
@@ -98,21 +98,19 @@ static struct fence *amdgpu_sched_run_job(struct amd_sched_job *sched_job)
 	}
 	job = to_amdgpu_job(sched_job);
 	trace_amdgpu_sched_run_job(job);
-	r = amdgpu_ib_schedule(job->ring, job->num_ibs, job->ibs, job->owner);
+	r = amdgpu_ib_schedule(job->ring, job->num_ibs, job->ibs,
+			       job->owner, &fence);
 	if (r) {
 		DRM_ERROR("Error scheduling IBs (%d)\n", r);
 		goto err;
 	}
 
-	fence = job->ibs[job->num_ibs - 1].fence;
-	fence_get(&fence->base);
-
 err:
 	if (job->free_job)
 		job->free_job(job);
 
 	kfree(job);
-	return fence ? &fence->base : NULL;
+	return fence;
 }
 
 struct amd_sched_backend_ops amdgpu_sched_ops = {

commit b07c60c0652c497af0c42c1278941f7c5a187fe9
Author: Christian König <christian.koenig@amd.com>
Date:   Sun Jan 31 12:29:04 2016 +0100

    drm/amdgpu: move ring from IBs into job
    
    We can't submit to multiple rings at the same time anyway.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 10d098e33707..84453c1c4b07 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -70,7 +70,7 @@ static struct fence *amdgpu_sched_dependency(struct amd_sched_job *sched_job)
 	struct fence *fence = amdgpu_sync_get_fence(sync);
 
 	if (fence == NULL && vm && !job->ibs->grabbed_vmid) {
-		struct amdgpu_ring *ring = job->ibs->ring;
+		struct amdgpu_ring *ring = job->ring;
 		int r;
 
 		r = amdgpu_vm_grab_id(vm, ring, sync,
@@ -98,7 +98,7 @@ static struct fence *amdgpu_sched_run_job(struct amd_sched_job *sched_job)
 	}
 	job = to_amdgpu_job(sched_job);
 	trace_amdgpu_sched_run_job(job);
-	r = amdgpu_ib_schedule(job->adev, job->num_ibs, job->ibs, job->owner);
+	r = amdgpu_ib_schedule(job->ring, job->num_ibs, job->ibs, job->owner);
 	if (r) {
 		DRM_ERROR("Error scheduling IBs (%d)\n", r);
 		goto err;
@@ -142,6 +142,7 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 	*f = fence_get(&job->base.s_fence->base);
 
 	job->adev = adev;
+	job->ring = ring;
 	job->ibs = ibs;
 	job->num_ibs = num_ibs;
 	job->owner = owner;

commit 50838c8cc413de8da39c4c216ae05410845d5a44
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Feb 3 13:44:52 2016 +0100

    drm/amdgpu: add proper job alloc/free functions
    
    And use them in the CS instead of allocating IBs and jobs separately.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 76a1f823d983..10d098e33707 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -28,6 +28,39 @@
 #include "amdgpu.h"
 #include "amdgpu_trace.h"
 
+int amdgpu_job_alloc(struct amdgpu_device *adev, unsigned num_ibs,
+		     struct amdgpu_job **job)
+{
+	size_t size = sizeof(struct amdgpu_job);
+
+	if (num_ibs == 0)
+		return -EINVAL;
+
+	size += sizeof(struct amdgpu_ib) * num_ibs;
+
+	*job = kzalloc(size, GFP_KERNEL);
+	if (!*job)
+		return -ENOMEM;
+
+	(*job)->adev = adev;
+	(*job)->ibs = (void *)&(*job)[1];
+	(*job)->num_ibs = num_ibs;
+	(*job)->free_job = NULL;
+
+	return 0;
+}
+
+void amdgpu_job_free(struct amdgpu_job *job)
+{
+	unsigned i;
+
+	for (i = 0; i < job->num_ibs; ++i)
+		amdgpu_ib_free(job->adev, &job->ibs[i]);
+
+	amdgpu_bo_unref(&job->uf.bo);
+	/* TODO: Free the job structure here as well */
+}
+
 static struct fence *amdgpu_sched_dependency(struct amd_sched_job *sched_job)
 {
 	struct amdgpu_job *job = to_amdgpu_job(sched_job);

commit 94dd0a4ae0b1af997b1f45793e5fd5b47f4ffc18
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jan 18 17:01:42 2016 +0100

    drm/amdgpu: merge vm_grab_id and vm_fence v2
    
    No need for an extra function any more.
    
    v2: comment cleanups
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index b22a95f0571c..76a1f823d983 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -38,19 +38,14 @@ static struct fence *amdgpu_sched_dependency(struct amd_sched_job *sched_job)
 
 	if (fence == NULL && vm && !job->ibs->grabbed_vmid) {
 		struct amdgpu_ring *ring = job->ibs->ring;
-		struct amdgpu_device *adev = ring->adev;
 		int r;
 
-		mutex_lock(&adev->vm_manager.lock);
-		r = amdgpu_vm_grab_id(vm, ring, sync);
-		if (r) {
+		r = amdgpu_vm_grab_id(vm, ring, sync,
+				      &job->base.s_fence->base);
+		if (r)
 			DRM_ERROR("Error getting VM ID (%d)\n", r);
-		} else {
-			fence = &job->base.s_fence->base;
-			amdgpu_vm_fence(ring->adev, vm, fence);
+		else
 			job->ibs->grabbed_vmid = true;
-		}
-		mutex_unlock(&adev->vm_manager.lock);
 
 		fence = amdgpu_sync_get_fence(sync);
 	}

commit 8d0a7cea824a2784150ef7f25a1e88f18a2a8f69
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Nov 3 20:58:50 2015 +0100

    drm/amdgpu: grab VMID before submitting job v5
    
    This allows the scheduler to handle the dependencies on ID contention as well.
    
    v2: grab id only once
    v3: use a separate lock for the VMIDs
    v4: cleanup after semaphore removal
    v5: minor coding style change
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index dd9fac302e55..b22a95f0571c 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -31,7 +31,31 @@
 static struct fence *amdgpu_sched_dependency(struct amd_sched_job *sched_job)
 {
 	struct amdgpu_job *job = to_amdgpu_job(sched_job);
-	return amdgpu_sync_get_fence(&job->ibs->sync);
+	struct amdgpu_sync *sync = &job->ibs->sync;
+	struct amdgpu_vm *vm = job->ibs->vm;
+
+	struct fence *fence = amdgpu_sync_get_fence(sync);
+
+	if (fence == NULL && vm && !job->ibs->grabbed_vmid) {
+		struct amdgpu_ring *ring = job->ibs->ring;
+		struct amdgpu_device *adev = ring->adev;
+		int r;
+
+		mutex_lock(&adev->vm_manager.lock);
+		r = amdgpu_vm_grab_id(vm, ring, sync);
+		if (r) {
+			DRM_ERROR("Error getting VM ID (%d)\n", r);
+		} else {
+			fence = &job->base.s_fence->base;
+			amdgpu_vm_fence(ring->adev, vm, fence);
+			job->ibs->grabbed_vmid = true;
+		}
+		mutex_unlock(&adev->vm_manager.lock);
+
+		fence = amdgpu_sync_get_fence(sync);
+	}
+
+	return fence;
 }
 
 static struct fence *amdgpu_sched_run_job(struct amd_sched_job *sched_job)

commit cadf97b196a1e5b2db2606d53f77714e3e9cf4bb
Author: Chunming Zhou <David1.Zhou@amd.com>
Date:   Fri Jan 15 11:25:00 2016 +0800

    drm/amdgpu: clean up non-scheduler code path (v2)
    
    Non-scheduler code is longer supported.
    
    v2: agd: rebased on upstream
    
    Signed-off-by: Chunming Zhou <David1.Zhou@amd.com>
    Reviewed-by: Ken Wang  <Qingqing.Wang@amd.com>
    Reviewed-by: Monk Liu <monk.liu@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 438c05254695..dd9fac302e55 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -76,33 +76,25 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 					 void *owner,
 					 struct fence **f)
 {
-	int r = 0;
-	if (amdgpu_enable_scheduler) {
-		struct amdgpu_job *job =
-			kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
-		if (!job)
-			return -ENOMEM;
-		job->base.sched = &ring->sched;
-		job->base.s_entity = &adev->kernel_ctx.rings[ring->idx].entity;
-		job->base.s_fence = amd_sched_fence_create(job->base.s_entity, owner);
-		if (!job->base.s_fence) {
-			kfree(job);
-			return -ENOMEM;
-		}
-		*f = fence_get(&job->base.s_fence->base);
-
-		job->adev = adev;
-		job->ibs = ibs;
-		job->num_ibs = num_ibs;
-		job->owner = owner;
-		job->free_job = free_job;
-		amd_sched_entity_push_job(&job->base);
-	} else {
-		r = amdgpu_ib_schedule(adev, num_ibs, ibs, owner);
-		if (r)
-			return r;
-		*f = fence_get(&ibs[num_ibs - 1].fence->base);
+	struct amdgpu_job *job =
+		kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
+	if (!job)
+		return -ENOMEM;
+	job->base.sched = &ring->sched;
+	job->base.s_entity = &adev->kernel_ctx.rings[ring->idx].entity;
+	job->base.s_fence = amd_sched_fence_create(job->base.s_entity, owner);
+	if (!job->base.s_fence) {
+		kfree(job);
+		return -ENOMEM;
 	}
+	*f = fence_get(&job->base.s_fence->base);
+
+	job->adev = adev;
+	job->ibs = ibs;
+	job->num_ibs = num_ibs;
+	job->owner = owner;
+	job->free_job = free_job;
+	amd_sched_entity_push_job(&job->base);
 
 	return 0;
 }

commit e284022163716ecf11c37fd1057c35d689ef2c11
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Nov 5 19:49:48 2015 +0100

    drm/amdgpu: fix incorrect mutex usage v3
    
    Before this patch the scheduler fence was created when we push the job
    into the queue, so we could only get the fence after pushing it.
    
    The mutex now was necessary to prevent the thread pushing the jobs to
    the hardware from running faster than the thread pushing the jobs into
    the queue.
    
    Otherwise the thread pushing jobs into the queue would have accessed
    possible freed up memory when it tries to get a reference to the fence.
    
    So what you get in the end is thread A:
    mutex_lock(&job->lock);
    ...
    Kick of thread B.
    ...
    mutex_unlock(&job->lock);
    
    And thread B:
    mutex_lock(&job->lock);
    ....
    mutex_unlock(&job->lock);
    kfree(job);
    
    I'm actually not sure if I'm still up to date on this, but this usage
    pattern used to be not allowed with mutexes. See here as well
    https://lwn.net/Articles/575460/.
    
    v2: remove unrelated changes, fix missing owner
    v3: rebased, add more commit message
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 8ef9e4415fcc..438c05254695 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -45,12 +45,8 @@ static struct fence *amdgpu_sched_run_job(struct amd_sched_job *sched_job)
 		return NULL;
 	}
 	job = to_amdgpu_job(sched_job);
-	mutex_lock(&job->job_lock);
 	trace_amdgpu_sched_run_job(job);
-	r = amdgpu_ib_schedule(job->adev,
-			       job->num_ibs,
-			       job->ibs,
-			       job->base.owner);
+	r = amdgpu_ib_schedule(job->adev, job->num_ibs, job->ibs, job->owner);
 	if (r) {
 		DRM_ERROR("Error scheduling IBs (%d)\n", r);
 		goto err;
@@ -63,7 +59,6 @@ static struct fence *amdgpu_sched_run_job(struct amd_sched_job *sched_job)
 	if (job->free_job)
 		job->free_job(job);
 
-	mutex_unlock(&job->job_lock);
 	kfree(job);
 	return fence ? &fence->base : NULL;
 }
@@ -89,21 +84,19 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 			return -ENOMEM;
 		job->base.sched = &ring->sched;
 		job->base.s_entity = &adev->kernel_ctx.rings[ring->idx].entity;
+		job->base.s_fence = amd_sched_fence_create(job->base.s_entity, owner);
+		if (!job->base.s_fence) {
+			kfree(job);
+			return -ENOMEM;
+		}
+		*f = fence_get(&job->base.s_fence->base);
+
 		job->adev = adev;
 		job->ibs = ibs;
 		job->num_ibs = num_ibs;
-		job->base.owner = owner;
-		mutex_init(&job->job_lock);
+		job->owner = owner;
 		job->free_job = free_job;
-		mutex_lock(&job->job_lock);
-		r = amd_sched_entity_push_job(&job->base);
-		if (r) {
-			mutex_unlock(&job->job_lock);
-			kfree(job);
-			return r;
-		}
-		*f = fence_get(&job->base.s_fence->base);
-		mutex_unlock(&job->job_lock);
+		amd_sched_entity_push_job(&job->base);
 	} else {
 		r = amdgpu_ib_schedule(adev, num_ibs, ibs, owner);
 		if (r)

commit 4a562283376197722b295d27633134401bbc80f5
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Nov 6 14:09:21 2015 +0100

    drm/amdgpu: cleanup scheduler fence get/put dance
    
    The code was correct, but getting two references when the ownership
    is linearly moved on is a bit awkward and just overhead.
    
    Signed: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 67f778f6eedb..8ef9e4415fcc 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -64,7 +64,6 @@ static struct fence *amdgpu_sched_run_job(struct amd_sched_job *sched_job)
 		job->free_job(job);
 
 	mutex_unlock(&job->job_lock);
-	fence_put(&job->base.s_fence->base);
 	kfree(job);
 	return fence ? &fence->base : NULL;
 }

commit 7034decf6a5b1ff778d83ff9d7ce1f0b404804e4
Author: Chunming Zhou <David1.Zhou@amd.com>
Date:   Wed Nov 11 14:56:00 2015 +0800

    drm/amdgpu: add command submission workflow tracepoint
    
    OGL needs these tracepoints to investigate performance issue.
    
    Change-Id: I5e58187d061253f7d665dfce8e4e163ba91d3e2b
    Signed-off-by: Chunming Zhou <David1.Zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index dcf4a8aca680..67f778f6eedb 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -26,6 +26,7 @@
 #include <linux/sched.h>
 #include <drm/drmP.h>
 #include "amdgpu.h"
+#include "amdgpu_trace.h"
 
 static struct fence *amdgpu_sched_dependency(struct amd_sched_job *sched_job)
 {
@@ -45,6 +46,7 @@ static struct fence *amdgpu_sched_run_job(struct amd_sched_job *sched_job)
 	}
 	job = to_amdgpu_job(sched_job);
 	mutex_lock(&job->job_lock);
+	trace_amdgpu_sched_run_job(job);
 	r = amdgpu_ib_schedule(job->adev,
 			       job->num_ibs,
 			       job->ibs,

commit 6ef68c17d40e1e7e291ca513627a0d2a13ae095f
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Oct 22 15:16:22 2015 +0200

    drm/amdgpu: remove amdgpu_fence_ref/unref
    
    Just move the remaining users to fence_put/get.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 2e946b2cad88..dcf4a8aca680 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -54,7 +54,8 @@ static struct fence *amdgpu_sched_run_job(struct amd_sched_job *sched_job)
 		goto err;
 	}
 
-	fence = amdgpu_fence_ref(job->ibs[job->num_ibs - 1].fence);
+	fence = job->ibs[job->num_ibs - 1].fence;
+	fence_get(&fence->base);
 
 err:
 	if (job->free_job)

commit 4f839a243d3b0d8b1a14f4778a87ec4d8ddbf15f
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Sep 8 20:22:31 2015 +0200

    drm/amdgpu: more scheduler cleanups v2
    
    Embed the scheduler into the ring structure instead of allocating it.
    Use the ring name directly instead of the id.
    
    v2: rebased, whitespace cleanup
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Reviewed-by: Chunming Zhou<david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index d1984fc5dfc4..2e946b2cad88 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -85,7 +85,7 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 			kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
 		if (!job)
 			return -ENOMEM;
-		job->base.sched = ring->sched;
+		job->base.sched = &ring->sched;
 		job->base.s_entity = &adev->kernel_ctx.rings[ring->idx].entity;
 		job->adev = adev;
 		job->ibs = ibs;

commit 9b398fa5c24eb05fc60fafd8543cc03e9170f054
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Sep 7 18:16:49 2015 +0200

    drm/amdgpu: rename fence->scheduler to sched v2
    
    Just to be consistent with the other members.
    
    v2: rename the ring member as well.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com> (v1)
    Reviewed-by: Chunming Zhou<david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 58408da122c5..d1984fc5dfc4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -85,7 +85,7 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 			kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
 		if (!job)
 			return -ENOMEM;
-		job->base.sched = ring->scheduler;
+		job->base.sched = ring->sched;
 		job->base.s_entity = &adev->kernel_ctx.rings[ring->idx].entity;
 		job->adev = adev;
 		job->ibs = ibs;

commit a6db8a33e164ae72fb5429ab637e8cfee057a722
Author: Junwei Zhang <Jerry.Zhang@amd.com>
Date:   Wed Sep 9 09:21:19 2015 +0800

    drm/amdgpu: refine the scheduler job type conversion
    
    Use container_of rather than casting.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: David Zhou <david1.zhou@amd.com>
    Signed-off-by: Junwei Zhang <Jerry.Zhang@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index af1a3dabd190..58408da122c5 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -29,7 +29,7 @@
 
 static struct fence *amdgpu_sched_dependency(struct amd_sched_job *sched_job)
 {
-	struct amdgpu_job *job = (struct amdgpu_job *)sched_job;
+	struct amdgpu_job *job = to_amdgpu_job(sched_job);
 	return amdgpu_sync_get_fence(&job->ibs->sync);
 }
 
@@ -43,7 +43,7 @@ static struct fence *amdgpu_sched_run_job(struct amd_sched_job *sched_job)
 		DRM_ERROR("job is null\n");
 		return NULL;
 	}
-	job = (struct amdgpu_job *)sched_job;
+	job = to_amdgpu_job(sched_job);
 	mutex_lock(&job->job_lock);
 	r = amdgpu_ib_schedule(job->adev,
 			       job->num_ibs,
@@ -94,7 +94,7 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 		mutex_init(&job->job_lock);
 		job->free_job = free_job;
 		mutex_lock(&job->job_lock);
-		r = amd_sched_entity_push_job((struct amd_sched_job *)job);
+		r = amd_sched_entity_push_job(&job->base);
 		if (r) {
 			mutex_unlock(&job->job_lock);
 			kfree(job);

commit 4c7eb91cae88fd2aa101750d6825b4176f85ffb2
Author: Junwei Zhang <Jerry.Zhang@amd.com>
Date:   Wed Sep 9 09:05:55 2015 +0800

    drm/amdgpu: refine the job naming for amdgpu_job and amdgpu_sched_job
    
    Use consistent naming across functions.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: David Zhou <david1.zhou@amd.com>
    Signed-off-by: Junwei Zhang <Jerry.Zhang@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 5724a81fbf5e..af1a3dabd190 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -27,42 +27,42 @@
 #include <drm/drmP.h>
 #include "amdgpu.h"
 
-static struct fence *amdgpu_sched_dependency(struct amd_sched_job *job)
+static struct fence *amdgpu_sched_dependency(struct amd_sched_job *sched_job)
 {
-	struct amdgpu_job *sched_job = (struct amdgpu_job *)job;
-	return amdgpu_sync_get_fence(&sched_job->ibs->sync);
+	struct amdgpu_job *job = (struct amdgpu_job *)sched_job;
+	return amdgpu_sync_get_fence(&job->ibs->sync);
 }
 
-static struct fence *amdgpu_sched_run_job(struct amd_sched_job *job)
+static struct fence *amdgpu_sched_run_job(struct amd_sched_job *sched_job)
 {
 	struct amdgpu_fence *fence = NULL;
-	struct amdgpu_job *sched_job;
+	struct amdgpu_job *job;
 	int r;
 
-	if (!job) {
+	if (!sched_job) {
 		DRM_ERROR("job is null\n");
 		return NULL;
 	}
-	sched_job = (struct amdgpu_job *)job;
-	mutex_lock(&sched_job->job_lock);
-	r = amdgpu_ib_schedule(sched_job->adev,
-			       sched_job->num_ibs,
-			       sched_job->ibs,
-			       sched_job->base.owner);
+	job = (struct amdgpu_job *)sched_job;
+	mutex_lock(&job->job_lock);
+	r = amdgpu_ib_schedule(job->adev,
+			       job->num_ibs,
+			       job->ibs,
+			       job->base.owner);
 	if (r) {
 		DRM_ERROR("Error scheduling IBs (%d)\n", r);
 		goto err;
 	}
 
-	fence = amdgpu_fence_ref(sched_job->ibs[sched_job->num_ibs - 1].fence);
+	fence = amdgpu_fence_ref(job->ibs[job->num_ibs - 1].fence);
 
 err:
-	if (sched_job->free_job)
-		sched_job->free_job(sched_job);
+	if (job->free_job)
+		job->free_job(job);
 
-	mutex_unlock(&sched_job->job_lock);
-	fence_put(&sched_job->base.s_fence->base);
-	kfree(sched_job);
+	mutex_unlock(&job->job_lock);
+	fence_put(&job->base.s_fence->base);
+	kfree(job);
 	return fence ? &fence->base : NULL;
 }
 

commit 1886d1a9caed20f457dd69a926c7f8b54c2d5f48
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Aug 31 17:28:28 2015 +0200

    drm/amdgpu: remove process_job callback from the scheduler
    
    Just free the resources immediately after submitting the job.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Junwei Zhang <Jerry.Zhang@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index de98fbd2971e..5724a81fbf5e 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -35,8 +35,8 @@ static struct fence *amdgpu_sched_dependency(struct amd_sched_job *job)
 
 static struct fence *amdgpu_sched_run_job(struct amd_sched_job *job)
 {
+	struct amdgpu_fence *fence = NULL;
 	struct amdgpu_job *sched_job;
-	struct amdgpu_fence *fence;
 	int r;
 
 	if (!job) {
@@ -49,41 +49,26 @@ static struct fence *amdgpu_sched_run_job(struct amd_sched_job *job)
 			       sched_job->num_ibs,
 			       sched_job->ibs,
 			       sched_job->base.owner);
-	if (r)
+	if (r) {
+		DRM_ERROR("Error scheduling IBs (%d)\n", r);
 		goto err;
+	}
+
 	fence = amdgpu_fence_ref(sched_job->ibs[sched_job->num_ibs - 1].fence);
 
+err:
 	if (sched_job->free_job)
 		sched_job->free_job(sched_job);
 
 	mutex_unlock(&sched_job->job_lock);
-	return &fence->base;
-
-err:
-	DRM_ERROR("Run job error\n");
-	mutex_unlock(&sched_job->job_lock);
-	job->sched->ops->process_job(job);
-	return NULL;
-}
-
-static void amdgpu_sched_process_job(struct amd_sched_job *job)
-{
-	struct amdgpu_job *sched_job;
-
-	if (!job) {
-		DRM_ERROR("job is null\n");
-		return;
-	}
-	sched_job = (struct amdgpu_job *)job;
-	/* after processing job, free memory */
 	fence_put(&sched_job->base.s_fence->base);
 	kfree(sched_job);
+	return fence ? &fence->base : NULL;
 }
 
 struct amd_sched_backend_ops amdgpu_sched_ops = {
 	.dependency = amdgpu_sched_dependency,
 	.run_job = amdgpu_sched_run_job,
-	.process_job = amdgpu_sched_process_job
 };
 
 int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,

commit e61235db62c5e68e56e59bea62b88f9f3d7a3cf5
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Aug 25 11:05:36 2015 +0200

    drm/amdgpu: add scheduler dependency callback v2
    
    This way the scheduler doesn't wait in it's work thread any more.
    
    v2: fix race conditions
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index f93fb3541488..de98fbd2971e 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -27,6 +27,12 @@
 #include <drm/drmP.h>
 #include "amdgpu.h"
 
+static struct fence *amdgpu_sched_dependency(struct amd_sched_job *job)
+{
+	struct amdgpu_job *sched_job = (struct amdgpu_job *)job;
+	return amdgpu_sync_get_fence(&sched_job->ibs->sync);
+}
+
 static struct fence *amdgpu_sched_run_job(struct amd_sched_job *job)
 {
 	struct amdgpu_job *sched_job;
@@ -75,6 +81,7 @@ static void amdgpu_sched_process_job(struct amd_sched_job *job)
 }
 
 struct amd_sched_backend_ops amdgpu_sched_ops = {
+	.dependency = amdgpu_sched_dependency,
 	.run_job = amdgpu_sched_run_job,
 	.process_job = amdgpu_sched_process_job
 };

commit bd755d08709f05a81104e8f81d721b5cc353a2b3
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Aug 24 14:57:26 2015 +0200

    drm/amdgpu: remove extra parameters from scheduler callbacks
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 757058d539f4..f93fb3541488 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -27,13 +27,11 @@
 #include <drm/drmP.h>
 #include "amdgpu.h"
 
-static struct fence *amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
-					  struct amd_sched_entity *entity,
-					  struct amd_sched_job *job)
+static struct fence *amdgpu_sched_run_job(struct amd_sched_job *job)
 {
-	int r = 0;
 	struct amdgpu_job *sched_job;
 	struct amdgpu_fence *fence;
+	int r;
 
 	if (!job) {
 		DRM_ERROR("job is null\n");
@@ -58,12 +56,11 @@ static struct fence *amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 err:
 	DRM_ERROR("Run job error\n");
 	mutex_unlock(&sched_job->job_lock);
-	sched->ops->process_job(sched, (struct amd_sched_job *)sched_job);
+	job->sched->ops->process_job(job);
 	return NULL;
 }
 
-static void amdgpu_sched_process_job(struct amd_gpu_scheduler *sched,
-				     struct amd_sched_job *job)
+static void amdgpu_sched_process_job(struct amd_sched_job *job)
 {
 	struct amdgpu_job *sched_job;
 

commit 3c62338c26bf2677c8285b406cd769b92ee0dc10
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Thu Aug 20 18:33:59 2015 +0800

    drm/amdgpu: fix last_vm_update fence is not effetive for sched fence
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 4f5c0874ad2a..757058d539f4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -119,5 +119,6 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 			return r;
 		*f = fence_get(&ibs[num_ibs - 1].fence->base);
 	}
+
 	return 0;
 }

commit 84f76ea6b03a766931e5d6d650af5ab980c6c4f4
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Mon Aug 24 12:47:36 2015 +0800

    drm/amdgpu: add owner for sched fence
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 1aa72edbce9a..4f5c0874ad2a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -44,7 +44,7 @@ static struct fence *amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 	r = amdgpu_ib_schedule(sched_job->adev,
 			       sched_job->num_ibs,
 			       sched_job->ibs,
-			       sched_job->owner);
+			       sched_job->base.owner);
 	if (r)
 		goto err;
 	fence = amdgpu_fence_ref(sched_job->ibs[sched_job->num_ibs - 1].fence);
@@ -101,7 +101,7 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 		job->adev = adev;
 		job->ibs = ibs;
 		job->num_ibs = num_ibs;
-		job->owner = owner;
+		job->base.owner = owner;
 		mutex_init(&job->job_lock);
 		job->free_job = free_job;
 		mutex_lock(&job->job_lock);

commit 6c859274f363be9dc13f8849bdc59bb64f922f26
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Aug 20 16:12:50 2015 +0200

    drm/amdgpu: fix and cleanup amd_sched_entity_push_job
    
    Calling schedule() is probably the worse things we can do.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 964b54381feb..1aa72edbce9a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -105,7 +105,7 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 		mutex_init(&job->job_lock);
 		job->free_job = free_job;
 		mutex_lock(&job->job_lock);
-		r = amd_sched_push_job((struct amd_sched_job *)job);
+		r = amd_sched_entity_push_job((struct amd_sched_job *)job);
 		if (r) {
 			mutex_unlock(&job->job_lock);
 			kfree(job);

commit ce882e6dc241ab8dded0eeeb33a86482d44a5689
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Aug 19 15:00:55 2015 +0200

    drm/amdgpu: remove v_seq handling from the scheduler v2
    
    Simply not used any more. Only keep 32bit atomic for fence sequence numbering.
    
    v2: trivial rebase
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com> (v1)
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com> (v1)
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com> (v1)

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 06d7bf51db9a..964b54381feb 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -111,7 +111,6 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 			kfree(job);
 			return r;
 		}
-		ibs[num_ibs - 1].sequence = job->base.s_fence->v_seq;
 		*f = fence_get(&job->base.s_fence->base);
 		mutex_unlock(&job->job_lock);
 	} else {

commit bf7ebaeed4dca7c0a7f9d9a44efbd9f74cf22c5d
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Aug 18 15:30:26 2015 +0200

    drm/amdgpu: free the job immediately after dispatching it
    
    Fixes a whole bunch of lockdep warnings.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 5b1ae18f5e8d..06d7bf51db9a 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -49,6 +49,9 @@ static struct fence *amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 		goto err;
 	fence = amdgpu_fence_ref(sched_job->ibs[sched_job->num_ibs - 1].fence);
 
+	if (sched_job->free_job)
+		sched_job->free_job(sched_job);
+
 	mutex_unlock(&sched_job->job_lock);
 	return &fence->base;
 
@@ -69,10 +72,6 @@ static void amdgpu_sched_process_job(struct amd_gpu_scheduler *sched,
 		return;
 	}
 	sched_job = (struct amdgpu_job *)job;
-	mutex_lock(&sched_job->job_lock);
-	if (sched_job->free_job)
-		sched_job->free_job(sched_job);
-	mutex_unlock(&sched_job->job_lock);
 	/* after processing job, free memory */
 	fence_put(&sched_job->base.s_fence->base);
 	kfree(sched_job);

commit bb977d3711ed1de1601b463e7fd5a43d82a2b077
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Tue Aug 18 15:16:40 2015 +0800

    drm/amdgpu: abstract amdgpu_job for scheduler
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index a86e38158afa..5b1ae18f5e8d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -27,81 +27,58 @@
 #include <drm/drmP.h>
 #include "amdgpu.h"
 
-static int amdgpu_sched_prepare_job(struct amd_gpu_scheduler *sched,
-				    struct amd_sched_entity *entity,
-				    struct amd_sched_job *job)
-{
-	int r = 0;
-	struct amdgpu_cs_parser *sched_job;
-	if (!job || !job->data) {
-		DRM_ERROR("job is null\n");
-		return -EINVAL;
-	}
-
-	sched_job = (struct amdgpu_cs_parser *)job->data;
-	if (sched_job->prepare_job) {
-		r = sched_job->prepare_job(sched_job);
-		if (r) {
-			DRM_ERROR("Prepare job error\n");
-			schedule_work(&sched_job->job_work);
-		}
-	}
-	return r;
-}
-
 static struct fence *amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 					  struct amd_sched_entity *entity,
 					  struct amd_sched_job *job)
 {
 	int r = 0;
-	struct amdgpu_cs_parser *sched_job;
+	struct amdgpu_job *sched_job;
 	struct amdgpu_fence *fence;
 
-	if (!job || !job->data) {
+	if (!job) {
 		DRM_ERROR("job is null\n");
 		return NULL;
 	}
-	sched_job = (struct amdgpu_cs_parser *)job->data;
+	sched_job = (struct amdgpu_job *)job;
 	mutex_lock(&sched_job->job_lock);
 	r = amdgpu_ib_schedule(sched_job->adev,
 			       sched_job->num_ibs,
 			       sched_job->ibs,
-			       sched_job->filp);
+			       sched_job->owner);
 	if (r)
 		goto err;
 	fence = amdgpu_fence_ref(sched_job->ibs[sched_job->num_ibs - 1].fence);
 
-	if (sched_job->run_job) {
-		r = sched_job->run_job(sched_job);
-		if (r)
-			goto err;
-	}
-
 	mutex_unlock(&sched_job->job_lock);
 	return &fence->base;
 
 err:
 	DRM_ERROR("Run job error\n");
 	mutex_unlock(&sched_job->job_lock);
-	schedule_work(&sched_job->job_work);
+	sched->ops->process_job(sched, (struct amd_sched_job *)sched_job);
 	return NULL;
 }
 
 static void amdgpu_sched_process_job(struct amd_gpu_scheduler *sched,
 				     struct amd_sched_job *job)
 {
-	struct amdgpu_cs_parser *sched_job;
+	struct amdgpu_job *sched_job;
 
-	if (!job || !job->data) {
+	if (!job) {
 		DRM_ERROR("job is null\n");
 		return;
 	}
-	sched_job = (struct amdgpu_cs_parser *)job->data;
-	schedule_work(&sched_job->job_work);
+	sched_job = (struct amdgpu_job *)job;
+	mutex_lock(&sched_job->job_lock);
+	if (sched_job->free_job)
+		sched_job->free_job(sched_job);
+	mutex_unlock(&sched_job->job_lock);
+	/* after processing job, free memory */
+	fence_put(&sched_job->base.s_fence->base);
+	kfree(sched_job);
 }
 
 struct amd_sched_backend_ops amdgpu_sched_ops = {
-	.prepare_job = amdgpu_sched_prepare_job,
 	.run_job = amdgpu_sched_run_job,
 	.process_job = amdgpu_sched_process_job
 };
@@ -110,31 +87,34 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 					 struct amdgpu_ring *ring,
 					 struct amdgpu_ib *ibs,
 					 unsigned num_ibs,
-					 int (*free_job)(struct amdgpu_cs_parser *),
+					 int (*free_job)(struct amdgpu_job *),
 					 void *owner,
 					 struct fence **f)
 {
 	int r = 0;
 	if (amdgpu_enable_scheduler) {
-		struct amdgpu_cs_parser *sched_job =
-			amdgpu_cs_parser_create(adev, owner, &adev->kernel_ctx,
-						ibs, num_ibs);
-		if(!sched_job) {
+		struct amdgpu_job *job =
+			kzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);
+		if (!job)
 			return -ENOMEM;
-		}
-		sched_job->free_job = free_job;
-		mutex_lock(&sched_job->job_lock);
-		r = amd_sched_push_job(ring->scheduler,
-				       &adev->kernel_ctx.rings[ring->idx].entity,
-				       sched_job, &sched_job->s_fence);
+		job->base.sched = ring->scheduler;
+		job->base.s_entity = &adev->kernel_ctx.rings[ring->idx].entity;
+		job->adev = adev;
+		job->ibs = ibs;
+		job->num_ibs = num_ibs;
+		job->owner = owner;
+		mutex_init(&job->job_lock);
+		job->free_job = free_job;
+		mutex_lock(&job->job_lock);
+		r = amd_sched_push_job((struct amd_sched_job *)job);
 		if (r) {
-			mutex_unlock(&sched_job->job_lock);
-			kfree(sched_job);
+			mutex_unlock(&job->job_lock);
+			kfree(job);
 			return r;
 		}
-		ibs[num_ibs - 1].sequence = sched_job->s_fence->v_seq;
-		*f = fence_get(&sched_job->s_fence->base);
-		mutex_unlock(&sched_job->job_lock);
+		ibs[num_ibs - 1].sequence = job->base.s_fence->v_seq;
+		*f = fence_get(&job->base.s_fence->base);
+		mutex_unlock(&job->job_lock);
 	} else {
 		r = amdgpu_ib_schedule(adev, num_ibs, ibs, owner);
 		if (r)

commit 281b42230175608dec0cd8dab9908250e7aa36a9
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Wed Aug 12 12:58:31 2015 +0800

    drm/amdgpu: add reference for **fence
    
    fix fence is released when pass to **fence sometimes.
    add reference for it.
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index d2e5f3b90a3c..a86e38158afa 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -133,13 +133,13 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 			return r;
 		}
 		ibs[num_ibs - 1].sequence = sched_job->s_fence->v_seq;
-		*f = &sched_job->s_fence->base;
+		*f = fence_get(&sched_job->s_fence->base);
 		mutex_unlock(&sched_job->job_lock);
 	} else {
 		r = amdgpu_ib_schedule(adev, num_ibs, ibs, owner);
 		if (r)
 			return r;
-		*f = &ibs[num_ibs - 1].fence->base;
+		*f = fence_get(&ibs[num_ibs - 1].fence->base);
 	}
 	return 0;
 }

commit 05caae8515e12073f4a3beb048e0d289cbe687b7
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Aug 10 14:04:12 2015 +0200

    drm/amdgpu: remove amd_sched_wait_emit v2
    
    Not used any more.
    
    v2: remove amd_sched_emit as well.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 6a7e83edcaa7..d2e5f3b90a3c 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -77,8 +77,6 @@ static struct fence *amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 			goto err;
 	}
 
-	amd_sched_emit(entity, sched_job->ibs[sched_job->num_ibs - 1].sequence);
-
 	mutex_unlock(&sched_job->job_lock);
 	return &fence->base;
 

commit f556cb0caeec1ba9b8e5e2aa85b47e76277f5d4b
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Sun Aug 2 11:18:04 2015 +0800

    drm/amd: add scheduler fence implementation (v2)
    
    scheduler fence is based on kernel fence framework.
    
    v2: squash in Christian's build fix
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index d82f2481bd0e..6a7e83edcaa7 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -118,7 +118,6 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 {
 	int r = 0;
 	if (amdgpu_enable_scheduler) {
-		uint64_t v_seq;
 		struct amdgpu_cs_parser *sched_job =
 			amdgpu_cs_parser_create(adev, owner, &adev->kernel_ctx,
 						ibs, num_ibs);
@@ -126,22 +125,23 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 			return -ENOMEM;
 		}
 		sched_job->free_job = free_job;
-		v_seq = atomic64_inc_return(&adev->kernel_ctx.rings[ring->idx].entity.last_queued_v_seq);
-		ibs[num_ibs - 1].sequence = v_seq;
-		amd_sched_push_job(ring->scheduler,
-				   &adev->kernel_ctx.rings[ring->idx].entity,
-				   sched_job);
-		r = amd_sched_wait_emit(
-			&adev->kernel_ctx.rings[ring->idx].entity,
-			v_seq,
-			false,
-			-1);
-		if (r)
-			WARN(true, "emit timeout\n");
-	} else
+		mutex_lock(&sched_job->job_lock);
+		r = amd_sched_push_job(ring->scheduler,
+				       &adev->kernel_ctx.rings[ring->idx].entity,
+				       sched_job, &sched_job->s_fence);
+		if (r) {
+			mutex_unlock(&sched_job->job_lock);
+			kfree(sched_job);
+			return r;
+		}
+		ibs[num_ibs - 1].sequence = sched_job->s_fence->v_seq;
+		*f = &sched_job->s_fence->base;
+		mutex_unlock(&sched_job->job_lock);
+	} else {
 		r = amdgpu_ib_schedule(adev, num_ibs, ibs, owner);
-	if (r)
-		return r;
-	*f = &ibs[num_ibs - 1].fence->base;
+		if (r)
+			return r;
+		*f = &ibs[num_ibs - 1].fence->base;
+	}
 	return 0;
 }

commit 4af9f07ccdac96e16f7a0ddaf983891a29ebd11a
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Mon Aug 3 12:57:31 2015 +0800

    drm/amdgpu: use kernel submit helper in vm
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index d13d01511694..d82f2481bd0e 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -121,7 +121,7 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 		uint64_t v_seq;
 		struct amdgpu_cs_parser *sched_job =
 			amdgpu_cs_parser_create(adev, owner, &adev->kernel_ctx,
-						ibs, 1);
+						ibs, num_ibs);
 		if(!sched_job) {
 			return -ENOMEM;
 		}
@@ -139,7 +139,7 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 		if (r)
 			WARN(true, "emit timeout\n");
 	} else
-		r = amdgpu_ib_schedule(adev, 1, ibs, owner);
+		r = amdgpu_ib_schedule(adev, num_ibs, ibs, owner);
 	if (r)
 		return r;
 	*f = &ibs[num_ibs - 1].fence->base;

commit 953e8fd4e734857f6dabbaf325035bf10c4a9c7a
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Thu Aug 6 15:19:12 2015 +0800

    drm/amdgpu: use amd_sched_job in its backend ops
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 039bd1f748f0..d13d01511694 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -29,10 +29,16 @@
 
 static int amdgpu_sched_prepare_job(struct amd_gpu_scheduler *sched,
 				    struct amd_sched_entity *entity,
-				    void *job)
+				    struct amd_sched_job *job)
 {
 	int r = 0;
-	struct amdgpu_cs_parser *sched_job = (struct amdgpu_cs_parser *)job;
+	struct amdgpu_cs_parser *sched_job;
+	if (!job || !job->data) {
+		DRM_ERROR("job is null\n");
+		return -EINVAL;
+	}
+
+	sched_job = (struct amdgpu_cs_parser *)job->data;
 	if (sched_job->prepare_job) {
 		r = sched_job->prepare_job(sched_job);
 		if (r) {
@@ -51,11 +57,11 @@ static struct fence *amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 	struct amdgpu_cs_parser *sched_job;
 	struct amdgpu_fence *fence;
 
-	if (!job || !job->job) {
+	if (!job || !job->data) {
 		DRM_ERROR("job is null\n");
 		return NULL;
 	}
-	sched_job = (struct amdgpu_cs_parser *)job->job;
+	sched_job = (struct amdgpu_cs_parser *)job->data;
 	mutex_lock(&sched_job->job_lock);
 	r = amdgpu_ib_schedule(sched_job->adev,
 			       sched_job->num_ibs,
@@ -83,22 +89,16 @@ static struct fence *amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 	return NULL;
 }
 
-static void amdgpu_sched_process_job(struct amd_gpu_scheduler *sched, void *job)
+static void amdgpu_sched_process_job(struct amd_gpu_scheduler *sched,
+				     struct amd_sched_job *job)
 {
-	struct amdgpu_cs_parser *sched_job = NULL;
-	struct amdgpu_fence *fence = NULL;
-	struct amdgpu_ring *ring = NULL;
-	struct amdgpu_device *adev = NULL;
+	struct amdgpu_cs_parser *sched_job;
 
-	if (!job)
-		return;
-	sched_job = (struct amdgpu_cs_parser *)job;
-	fence = sched_job->ibs[sched_job->num_ibs - 1].fence;
-	if (!fence)
+	if (!job || !job->data) {
+		DRM_ERROR("job is null\n");
 		return;
-	ring = fence->ring;
-	adev = ring->adev;
-
+	}
+	sched_job = (struct amdgpu_cs_parser *)job->data;
 	schedule_work(&sched_job->job_work);
 }
 

commit 6f0e54a964932d3d5252ac1ff7ab153c984a5d51
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Aug 5 21:22:10 2015 +0200

    drm/amdgpu: cleanup and fix scheduler fence handling v2
    
    v2: rebased
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com> (v1)
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 787b93db6796..039bd1f748f0 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -43,16 +43,9 @@ static int amdgpu_sched_prepare_job(struct amd_gpu_scheduler *sched,
 	return r;
 }
 
-static void amdgpu_fence_sched_cb(struct fence *f, struct fence_cb *cb)
-{
-	struct amd_sched_job *sched_job =
-		container_of(cb, struct amd_sched_job, cb);
-	amd_sched_process_job(sched_job);
-}
-
-static void amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
-				 struct amd_sched_entity *entity,
-				 struct amd_sched_job *job)
+static struct fence *amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
+					  struct amd_sched_entity *entity,
+					  struct amd_sched_job *job)
 {
 	int r = 0;
 	struct amdgpu_cs_parser *sched_job;
@@ -60,7 +53,7 @@ static void amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 
 	if (!job || !job->job) {
 		DRM_ERROR("job is null\n");
-		return;
+		return NULL;
 	}
 	sched_job = (struct amdgpu_cs_parser *)job->job;
 	mutex_lock(&sched_job->job_lock);
@@ -70,12 +63,7 @@ static void amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 			       sched_job->filp);
 	if (r)
 		goto err;
-	fence = sched_job->ibs[sched_job->num_ibs - 1].fence;
-	if (fence_add_callback(&fence->base,
-			       &job->cb, amdgpu_fence_sched_cb)) {
-		DRM_ERROR("fence add callback failed\n");
-		goto err;
-	}
+	fence = amdgpu_fence_ref(sched_job->ibs[sched_job->num_ibs - 1].fence);
 
 	if (sched_job->run_job) {
 		r = sched_job->run_job(sched_job);
@@ -86,11 +74,13 @@ static void amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 	amd_sched_emit(entity, sched_job->ibs[sched_job->num_ibs - 1].sequence);
 
 	mutex_unlock(&sched_job->job_lock);
-	return;
+	return &fence->base;
+
 err:
 	DRM_ERROR("Run job error\n");
 	mutex_unlock(&sched_job->job_lock);
 	schedule_work(&sched_job->job_work);
+	return NULL;
 }
 
 static void amdgpu_sched_process_job(struct amd_gpu_scheduler *sched, void *job)

commit 91404fb20825418fd9ab8e6533bc336e1ffc748e
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Aug 5 18:33:21 2015 +0200

    drm/amdgpu: merge amd_sched_entity and amd_context_entity v2
    
    Avoiding a couple of casts.
    
    v2: rename c_entity to entity as well
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 71a4a7e4b1ae..787b93db6796 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -28,7 +28,7 @@
 #include "amdgpu.h"
 
 static int amdgpu_sched_prepare_job(struct amd_gpu_scheduler *sched,
-				    struct amd_context_entity *c_entity,
+				    struct amd_sched_entity *entity,
 				    void *job)
 {
 	int r = 0;
@@ -51,7 +51,7 @@ static void amdgpu_fence_sched_cb(struct fence *f, struct fence_cb *cb)
 }
 
 static void amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
-				 struct amd_context_entity *c_entity,
+				 struct amd_sched_entity *entity,
 				 struct amd_sched_job *job)
 {
 	int r = 0;
@@ -83,7 +83,7 @@ static void amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 			goto err;
 	}
 
-	amd_sched_emit(c_entity, sched_job->ibs[sched_job->num_ibs - 1].sequence);
+	amd_sched_emit(entity, sched_job->ibs[sched_job->num_ibs - 1].sequence);
 
 	mutex_unlock(&sched_job->job_lock);
 	return;
@@ -136,13 +136,13 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 			return -ENOMEM;
 		}
 		sched_job->free_job = free_job;
-		v_seq = atomic64_inc_return(&adev->kernel_ctx.rings[ring->idx].c_entity.last_queued_v_seq);
+		v_seq = atomic64_inc_return(&adev->kernel_ctx.rings[ring->idx].entity.last_queued_v_seq);
 		ibs[num_ibs - 1].sequence = v_seq;
 		amd_sched_push_job(ring->scheduler,
-				   &adev->kernel_ctx.rings[ring->idx].c_entity,
+				   &adev->kernel_ctx.rings[ring->idx].entity,
 				   sched_job);
 		r = amd_sched_wait_emit(
-			&adev->kernel_ctx.rings[ring->idx].c_entity,
+			&adev->kernel_ctx.rings[ring->idx].entity,
 			v_seq,
 			false,
 			-1);

commit 4cef92670bc908aaa48771fc9c72f4bcfb7d6a35
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Wed Aug 5 19:52:14 2015 +0800

    drm/amdgpu: process sched job exactly triggered by fence signal
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 0fcf020917d0..71a4a7e4b1ae 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -45,19 +45,24 @@ static int amdgpu_sched_prepare_job(struct amd_gpu_scheduler *sched,
 
 static void amdgpu_fence_sched_cb(struct fence *f, struct fence_cb *cb)
 {
-	struct amdgpu_fence *fence =
-		container_of(cb, struct amdgpu_fence, cb);
-	amd_sched_isr(fence->ring->scheduler);
+	struct amd_sched_job *sched_job =
+		container_of(cb, struct amd_sched_job, cb);
+	amd_sched_process_job(sched_job);
 }
 
 static void amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 				 struct amd_context_entity *c_entity,
-				 void *job)
+				 struct amd_sched_job *job)
 {
 	int r = 0;
-	struct amdgpu_cs_parser *sched_job = (struct amdgpu_cs_parser *)job;
+	struct amdgpu_cs_parser *sched_job;
 	struct amdgpu_fence *fence;
 
+	if (!job || !job->job) {
+		DRM_ERROR("job is null\n");
+		return;
+	}
+	sched_job = (struct amdgpu_cs_parser *)job->job;
 	mutex_lock(&sched_job->job_lock);
 	r = amdgpu_ib_schedule(sched_job->adev,
 			       sched_job->num_ibs,
@@ -67,8 +72,10 @@ static void amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 		goto err;
 	fence = sched_job->ibs[sched_job->num_ibs - 1].fence;
 	if (fence_add_callback(&fence->base,
-			       &fence->cb, amdgpu_fence_sched_cb))
+			       &job->cb, amdgpu_fence_sched_cb)) {
+		DRM_ERROR("fence add callback failed\n");
 		goto err;
+	}
 
 	if (sched_job->run_job) {
 		r = sched_job->run_job(sched_job);

commit 80de5913cf31c86d64547af0715de4822c9b1abe
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Wed Aug 5 19:07:08 2015 +0800

    Revert "drm/amdgpu: return new seq_no for amd_sched_push_job"
    
    This reverts commit d1d33da8eb86b8ca41dd9ed95738030df5267b95.
    
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>
    
    Conflicts:
            drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
            drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 995901b9e428..0fcf020917d0 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -121,6 +121,7 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 {
 	int r = 0;
 	if (amdgpu_enable_scheduler) {
+		uint64_t v_seq;
 		struct amdgpu_cs_parser *sched_job =
 			amdgpu_cs_parser_create(adev, owner, &adev->kernel_ctx,
 						ibs, 1);
@@ -128,12 +129,16 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 			return -ENOMEM;
 		}
 		sched_job->free_job = free_job;
-		ibs[num_ibs - 1].sequence = amd_sched_push_job(ring->scheduler,
+		v_seq = atomic64_inc_return(&adev->kernel_ctx.rings[ring->idx].c_entity.last_queued_v_seq);
+		ibs[num_ibs - 1].sequence = v_seq;
+		amd_sched_push_job(ring->scheduler,
 				   &adev->kernel_ctx.rings[ring->idx].c_entity,
 				   sched_job);
 		r = amd_sched_wait_emit(
 			&adev->kernel_ctx.rings[ring->idx].c_entity,
-			ibs[num_ibs - 1].sequence, false, -1);
+			v_seq,
+			false,
+			-1);
 		if (r)
 			WARN(true, "emit timeout\n");
 	} else

commit 47f38501f11fa45d8a7797f1965448c1e20049d4
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Aug 4 17:51:05 2015 +0200

    drm/amdgpu: cleanup amdgpu_ctx inti/fini v2
    
    Cleanup the kernel context handling.
    
    v2: rebased
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com> (v1)

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 9f2f19cc4625..995901b9e428 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -122,19 +122,17 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 	int r = 0;
 	if (amdgpu_enable_scheduler) {
 		struct amdgpu_cs_parser *sched_job =
-			amdgpu_cs_parser_create(adev,
-						owner,
-						adev->kernel_ctx,
+			amdgpu_cs_parser_create(adev, owner, &adev->kernel_ctx,
 						ibs, 1);
 		if(!sched_job) {
 			return -ENOMEM;
 		}
 		sched_job->free_job = free_job;
 		ibs[num_ibs - 1].sequence = amd_sched_push_job(ring->scheduler,
-				   &adev->kernel_ctx->rings[ring->idx].c_entity,
+				   &adev->kernel_ctx.rings[ring->idx].c_entity,
 				   sched_job);
 		r = amd_sched_wait_emit(
-			&adev->kernel_ctx->rings[ring->idx].c_entity,
+			&adev->kernel_ctx.rings[ring->idx].c_entity,
 			ibs[num_ibs - 1].sequence, false, -1);
 		if (r)
 			WARN(true, "emit timeout\n");

commit 7484667c6a8a9122d139a287454bc9c8799c3def
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Tue Aug 4 11:30:09 2015 +0800

    drm/amdgpu: move sched job process from isr to fence callback
    
    This way can avoid interrupt lost, and can process sched job exactly.
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 83138a6c54b5..9f2f19cc4625 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -43,12 +43,20 @@ static int amdgpu_sched_prepare_job(struct amd_gpu_scheduler *sched,
 	return r;
 }
 
+static void amdgpu_fence_sched_cb(struct fence *f, struct fence_cb *cb)
+{
+	struct amdgpu_fence *fence =
+		container_of(cb, struct amdgpu_fence, cb);
+	amd_sched_isr(fence->ring->scheduler);
+}
+
 static void amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 				 struct amd_context_entity *c_entity,
 				 void *job)
 {
 	int r = 0;
 	struct amdgpu_cs_parser *sched_job = (struct amdgpu_cs_parser *)job;
+	struct amdgpu_fence *fence;
 
 	mutex_lock(&sched_job->job_lock);
 	r = amdgpu_ib_schedule(sched_job->adev,
@@ -57,6 +65,11 @@ static void amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 			       sched_job->filp);
 	if (r)
 		goto err;
+	fence = sched_job->ibs[sched_job->num_ibs - 1].fence;
+	if (fence_add_callback(&fence->base,
+			       &fence->cb, amdgpu_fence_sched_cb))
+		goto err;
+
 	if (sched_job->run_job) {
 		r = sched_job->run_job(sched_job);
 		if (r)

commit f95b7e3e8664fbea4e60f15e7e8a975e4b2b7c3f
Author: Jammy Zhou <Jammy.Zhou@amd.com>
Date:   Fri Jul 31 17:18:15 2015 +0800

    drm/amdgpu: add amd_sched_commit
    
    This function is to update last_emitted_v_seq and wake up the waiters.
    
    It should be called by driver in the run_job backend function
    
    Signed-off-by: Jammy Zhou <Jammy.Zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 8c01c51aac41..83138a6c54b5 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -62,9 +62,8 @@ static void amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 		if (r)
 			goto err;
 	}
-	atomic64_set(&c_entity->last_emitted_v_seq,
-		     sched_job->ibs[sched_job->num_ibs - 1].sequence);
-	wake_up_all(&c_entity->wait_emit);
+
+	amd_sched_emit(c_entity, sched_job->ibs[sched_job->num_ibs - 1].sequence);
 
 	mutex_unlock(&sched_job->job_lock);
 	return;

commit ea199cc9f825f3ef5aab3db5f00dcc639f8a8b02
Author: Jammy Zhou <Jammy.Zhou@amd.com>
Date:   Fri Jul 31 16:47:28 2015 +0800

    drm/amdgpu: return new seq_no for amd_sched_push_job
    
    It is clean to update last_queued_v_seq in the scheduler module
    
    Signed-off-by: Jammy Zhou <Jammy.Zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 788dd348a650..8c01c51aac41 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -109,7 +109,6 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 {
 	int r = 0;
 	if (amdgpu_enable_scheduler) {
-		uint64_t v_seq;
 		struct amdgpu_cs_parser *sched_job =
 			amdgpu_cs_parser_create(adev,
 						owner,
@@ -119,16 +118,12 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 			return -ENOMEM;
 		}
 		sched_job->free_job = free_job;
-		v_seq = atomic64_inc_return(&adev->kernel_ctx->rings[ring->idx].c_entity.last_queued_v_seq);
-		ibs[num_ibs - 1].sequence = v_seq;
-		amd_sched_push_job(ring->scheduler,
+		ibs[num_ibs - 1].sequence = amd_sched_push_job(ring->scheduler,
 				   &adev->kernel_ctx->rings[ring->idx].c_entity,
 				   sched_job);
 		r = amd_sched_wait_emit(
 			&adev->kernel_ctx->rings[ring->idx].c_entity,
-			v_seq,
-			false,
-			-1);
+			ibs[num_ibs - 1].sequence, false, -1);
 		if (r)
 			WARN(true, "emit timeout\n");
 	} else

commit dd01d071957ded58d9bae3d3bf6061ada1d84692
Author: Jammy Zhou <Jammy.Zhou@amd.com>
Date:   Thu Jul 30 17:19:52 2015 +0800

    drm/amdgpu: some code refinement v2
    
    Fix the code alignment, etc.
    
    v2: rebase the code
    
    Signed-off-by: Jammy Zhou <Jammy.Zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 0f55c05c80b1..788dd348a650 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -33,11 +33,12 @@ static int amdgpu_sched_prepare_job(struct amd_gpu_scheduler *sched,
 {
 	int r = 0;
 	struct amdgpu_cs_parser *sched_job = (struct amdgpu_cs_parser *)job;
-	if (sched_job->prepare_job)
+	if (sched_job->prepare_job) {
 		r = sched_job->prepare_job(sched_job);
-	if (r) {
-		DRM_ERROR("Prepare job error\n");
-		schedule_work(&sched_job->job_work);
+		if (r) {
+			DRM_ERROR("Prepare job error\n");
+			schedule_work(&sched_job->job_work);
+		}
 	}
 	return r;
 }

commit 03d3a3e634894259a27979f4a372273162611e78
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Mon Aug 3 20:02:43 2015 +0800

    drm/amdgpu: fix null pointer by previous cleanup
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 23a17ec239c0..0f55c05c80b1 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -79,7 +79,6 @@ static void amdgpu_sched_process_job(struct amd_gpu_scheduler *sched, void *job)
 	struct amdgpu_fence *fence = NULL;
 	struct amdgpu_ring *ring = NULL;
 	struct amdgpu_device *adev = NULL;
-	struct amd_context_entity *c_entity = NULL;
 
 	if (!job)
 		return;
@@ -90,9 +89,6 @@ static void amdgpu_sched_process_job(struct amd_gpu_scheduler *sched, void *job)
 	ring = fence->ring;
 	adev = ring->adev;
 
-	/* wake up users waiting for time stamp */
-	wake_up_all(&c_entity->wait_queue);
-
 	schedule_work(&sched_job->job_work);
 }
 

commit 1763552ee8a7f39a1788d24e27b50d4dee383520
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Mon Aug 3 11:43:19 2015 +0800

    drm/amdgpu: add kernel fence in ib_submit_kernel_helper
    
    every sbumission should be able to get a fence.
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>
    Reviewed-by: Jammy Zhou <jammy.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 161c83ad9349..23a17ec239c0 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -107,7 +107,8 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 					 struct amdgpu_ib *ibs,
 					 unsigned num_ibs,
 					 int (*free_job)(struct amdgpu_cs_parser *),
-					 void *owner)
+					 void *owner,
+					 struct fence **f)
 {
 	int r = 0;
 	if (amdgpu_enable_scheduler) {
@@ -135,5 +136,8 @@ int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
 			WARN(true, "emit timeout\n");
 	} else
 		r = amdgpu_ib_schedule(adev, 1, ibs, owner);
-	return r;
+	if (r)
+		return r;
+	*f = &ibs[num_ibs - 1].fence->base;
+	return 0;
 }

commit 1d7dd229f5dded247bc8800f8f4551d3d6314afa
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Jul 31 14:31:49 2015 +0200

    drm/amdgpu: clean up amd sched wait_ts and wait_signal
    
    Remove code not used at the moment.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index d682fabca958..161c83ad9349 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -90,12 +90,6 @@ static void amdgpu_sched_process_job(struct amd_gpu_scheduler *sched, void *job)
 	ring = fence->ring;
 	adev = ring->adev;
 
-	if (sched_job->ctx) {
-		c_entity = &sched_job->ctx->rings[ring->idx].c_entity;
-		atomic64_set(&c_entity->last_signaled_v_seq,
-			     sched_job->ibs[sched_job->num_ibs - 1].sequence);
-	}
-
 	/* wake up users waiting for time stamp */
 	wake_up_all(&c_entity->wait_queue);
 

commit 3c704e934d07bcb5fdf9725db190e2ae60fba1bd
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Wed Jul 29 10:33:14 2015 +0800

    drm/amdgpu: add helper function for kernel submission
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index b913c22dd6b2..d682fabca958 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -108,3 +108,38 @@ struct amd_sched_backend_ops amdgpu_sched_ops = {
 	.process_job = amdgpu_sched_process_job
 };
 
+int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
+					 struct amdgpu_ring *ring,
+					 struct amdgpu_ib *ibs,
+					 unsigned num_ibs,
+					 int (*free_job)(struct amdgpu_cs_parser *),
+					 void *owner)
+{
+	int r = 0;
+	if (amdgpu_enable_scheduler) {
+		uint64_t v_seq;
+		struct amdgpu_cs_parser *sched_job =
+			amdgpu_cs_parser_create(adev,
+						owner,
+						adev->kernel_ctx,
+						ibs, 1);
+		if(!sched_job) {
+			return -ENOMEM;
+		}
+		sched_job->free_job = free_job;
+		v_seq = atomic64_inc_return(&adev->kernel_ctx->rings[ring->idx].c_entity.last_queued_v_seq);
+		ibs[num_ibs - 1].sequence = v_seq;
+		amd_sched_push_job(ring->scheduler,
+				   &adev->kernel_ctx->rings[ring->idx].c_entity,
+				   sched_job);
+		r = amd_sched_wait_emit(
+			&adev->kernel_ctx->rings[ring->idx].c_entity,
+			v_seq,
+			false,
+			-1);
+		if (r)
+			WARN(true, "emit timeout\n");
+	} else
+		r = amdgpu_ib_schedule(adev, 1, ibs, owner);
+	return r;
+}

commit d1ff9086c1b8e67390161599006a34056b437a72
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Thu Jul 30 17:59:43 2015 +0800

    drm/amdgpu: fix seq in ctx_add_fence
    
    if enabling scheduler, then the queued seq is assigned
    when pushing job before emitting job.
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian K?nig <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 46ec915c9344..b913c22dd6b2 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -62,7 +62,7 @@ static void amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 			goto err;
 	}
 	atomic64_set(&c_entity->last_emitted_v_seq,
-		     sched_job->uf.sequence);
+		     sched_job->ibs[sched_job->num_ibs - 1].sequence);
 	wake_up_all(&c_entity->wait_emit);
 
 	mutex_unlock(&sched_job->job_lock);
@@ -93,7 +93,7 @@ static void amdgpu_sched_process_job(struct amd_gpu_scheduler *sched, void *job)
 	if (sched_job->ctx) {
 		c_entity = &sched_job->ctx->rings[ring->idx].c_entity;
 		atomic64_set(&c_entity->last_signaled_v_seq,
-			     sched_job->uf.sequence);
+			     sched_job->ibs[sched_job->num_ibs - 1].sequence);
 	}
 
 	/* wake up users waiting for time stamp */

commit 4b559c90bc1870313f02cceef680884519af6b2b
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Tue Jul 21 15:53:04 2015 +0800

    drm/amdgpu: make sure the fence is emitted before ring to get it.
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Acked-by: Christian K?nig <christian.koenig@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
index 1f7bf31da7fc..46ec915c9344 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -56,12 +56,15 @@ static void amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
 			       sched_job->filp);
 	if (r)
 		goto err;
-
 	if (sched_job->run_job) {
 		r = sched_job->run_job(sched_job);
 		if (r)
 			goto err;
 	}
+	atomic64_set(&c_entity->last_emitted_v_seq,
+		     sched_job->uf.sequence);
+	wake_up_all(&c_entity->wait_emit);
+
 	mutex_unlock(&sched_job->job_lock);
 	return;
 err:

commit c1b69ed0c62f9d86599600f4c1a3bd82db1b7362
Author: Chunming Zhou <david1.zhou@amd.com>
Date:   Tue Jul 21 13:45:14 2015 +0800

    drm/amdgpu: add backend implementation of gpu scheduler (v2)
    
    v2: fix rebase breakage
    
    Signed-off-by: Chunming Zhou <david1.zhou@amd.com>
    Acked-by: Christian K?nig <christian.koenig@amd.com>
    Reviewed-by: Jammy Zhou <Jammy.Zhou@amd.com>

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
new file mode 100644
index 000000000000..1f7bf31da7fc
--- /dev/null
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sched.c
@@ -0,0 +1,107 @@
+/*
+ * Copyright 2015 Advanced Micro Devices, Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ *
+ */
+#include <linux/kthread.h>
+#include <linux/wait.h>
+#include <linux/sched.h>
+#include <drm/drmP.h>
+#include "amdgpu.h"
+
+static int amdgpu_sched_prepare_job(struct amd_gpu_scheduler *sched,
+				    struct amd_context_entity *c_entity,
+				    void *job)
+{
+	int r = 0;
+	struct amdgpu_cs_parser *sched_job = (struct amdgpu_cs_parser *)job;
+	if (sched_job->prepare_job)
+		r = sched_job->prepare_job(sched_job);
+	if (r) {
+		DRM_ERROR("Prepare job error\n");
+		schedule_work(&sched_job->job_work);
+	}
+	return r;
+}
+
+static void amdgpu_sched_run_job(struct amd_gpu_scheduler *sched,
+				 struct amd_context_entity *c_entity,
+				 void *job)
+{
+	int r = 0;
+	struct amdgpu_cs_parser *sched_job = (struct amdgpu_cs_parser *)job;
+
+	mutex_lock(&sched_job->job_lock);
+	r = amdgpu_ib_schedule(sched_job->adev,
+			       sched_job->num_ibs,
+			       sched_job->ibs,
+			       sched_job->filp);
+	if (r)
+		goto err;
+
+	if (sched_job->run_job) {
+		r = sched_job->run_job(sched_job);
+		if (r)
+			goto err;
+	}
+	mutex_unlock(&sched_job->job_lock);
+	return;
+err:
+	DRM_ERROR("Run job error\n");
+	mutex_unlock(&sched_job->job_lock);
+	schedule_work(&sched_job->job_work);
+}
+
+static void amdgpu_sched_process_job(struct amd_gpu_scheduler *sched, void *job)
+{
+	struct amdgpu_cs_parser *sched_job = NULL;
+	struct amdgpu_fence *fence = NULL;
+	struct amdgpu_ring *ring = NULL;
+	struct amdgpu_device *adev = NULL;
+	struct amd_context_entity *c_entity = NULL;
+
+	if (!job)
+		return;
+	sched_job = (struct amdgpu_cs_parser *)job;
+	fence = sched_job->ibs[sched_job->num_ibs - 1].fence;
+	if (!fence)
+		return;
+	ring = fence->ring;
+	adev = ring->adev;
+
+	if (sched_job->ctx) {
+		c_entity = &sched_job->ctx->rings[ring->idx].c_entity;
+		atomic64_set(&c_entity->last_signaled_v_seq,
+			     sched_job->uf.sequence);
+	}
+
+	/* wake up users waiting for time stamp */
+	wake_up_all(&c_entity->wait_queue);
+
+	schedule_work(&sched_job->job_work);
+}
+
+struct amd_sched_backend_ops amdgpu_sched_ops = {
+	.prepare_job = amdgpu_sched_prepare_job,
+	.run_job = amdgpu_sched_run_job,
+	.process_job = amdgpu_sched_process_job
+};
+
