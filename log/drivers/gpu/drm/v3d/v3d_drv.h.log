commit 0df3ac7657c92756a26c164133380edbce672f7a
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Wed Apr 15 09:39:45 2020 +0200

    drm/v3d: Delete v3d_dev->pdev
    
    We already have it in v3d_dev->drm.dev with zero additional pointer
    chasing. Personally I don't like duplicated pointers like this
    because:
    - reviewers need to check whether the pointer is for the same or
    different objects if there's multiple
    - compilers have an easier time too
    
    To avoid having to pull in some big headers I implemented the casting
    function as a macro instead of a static inline. Typechecking thanks to
    container_of still assured.
    
    But also a bit a bikeshed, so feel free to ignore.
    
    v2: More parens for v3d_to_pdev macro (checkpatch)
    
    Acked-by: Eric Anholt <eric@anholt.net>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    Cc: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20200415074034.175360-11-daniel.vetter@ffwll.ch

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index 4d2d1f2fe1af..8a390738d65b 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -46,7 +46,6 @@ struct v3d_dev {
 	int ver;
 	bool single_irq_line;
 
-	struct platform_device *pdev;
 	void __iomem *hub_regs;
 	void __iomem *core_regs[3];
 	void __iomem *bridge_regs;
@@ -128,6 +127,8 @@ v3d_has_csd(struct v3d_dev *v3d)
 	return v3d->ver >= 41;
 }
 
+#define v3d_to_pdev(v3d) to_platform_device((v3d)->drm.dev)
+
 /* The per-fd struct, which tracks the MMU mappings. */
 struct v3d_file_priv {
 	struct v3d_dev *v3d;

commit bc662528e29ae751e0d43c18c9e4cd71a20ef0d4
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Wed Apr 15 09:39:44 2020 +0200

    drm/v3d: Delete v3d_dev->dev
    
    We already have it in v3d_dev->drm.dev with zero additional pointer
    chasing. Personally I don't like duplicated pointers like this
    because:
    - reviewers need to check whether the pointer is for the same or
      different objects if there's multiple
    - compilers have an easier time too
    
    But also a bit a bikeshed, so feel free to ignore.
    
    Acked-by: Eric Anholt <eric@anholt.net>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    Cc: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20200415074034.175360-10-daniel.vetter@ffwll.ch

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index 112d80aed5f6..4d2d1f2fe1af 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -14,7 +14,6 @@
 #include "uapi/drm/v3d_drm.h"
 
 struct clk;
-struct device;
 struct platform_device;
 struct reset_control;
 
@@ -47,7 +46,6 @@ struct v3d_dev {
 	int ver;
 	bool single_irq_line;
 
-	struct device *dev;
 	struct platform_device *pdev;
 	void __iomem *hub_regs;
 	void __iomem *core_regs[3];

commit af25c16bd1c6e7e73d67271c0fe6e0d5078759f1
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Wed Apr 15 09:39:42 2020 +0200

    drm/v3d: Don't set drm_device->dev_private
    
    And switch the helper over to container_of, which is a bunch faster
    than chasing a pointer. Plus allows gcc to see through this maze.
    
    Acked-by: Eric Anholt <eric@anholt.net>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    Cc: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20200415074034.175360-8-daniel.vetter@ffwll.ch

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index e0775c884553..112d80aed5f6 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -121,7 +121,7 @@ struct v3d_dev {
 static inline struct v3d_dev *
 to_v3d_dev(struct drm_device *dev)
 {
-	return (struct v3d_dev *)dev->dev_private;
+	return container_of(dev, struct v3d_dev, drm);
 }
 
 static inline bool

commit 7ce84471e3c72e23020b046714358b45a7ffe9ab
Author: Wambui Karuga <wambui.karugax@gmail.com>
Date:   Tue Mar 10 16:31:21 2020 +0300

    drm: convert .debugfs_init() hook to return void.
    
    As a result of commit 987d65d01356 (drm: debugfs: make
    drm_debugfs_create_files() never fail) and changes to various debugfs
    functions in drm/core and across various drivers, there is no need for
    the drm_driver.debugfs_init() hook to have a return value. Therefore,
    declare it as void.
    
    This also includes refactoring all users of the .debugfs_init() hook to
    return void across the subsystem.
    
    v2: include changes to the hook and drivers that use it in one patch to
    prevent driver breakage and enable individual successful compilation of
    this change.
    
    References: https://lists.freedesktop.org/archives/dri-devel/2020-February/257183.html
    Signed-off-by: Wambui Karuga <wambui.karugax@gmail.com>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Link: https://patchwork.freedesktop.org/patch/msgid/20200310133121.27913-18-wambui.karugax@gmail.com

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index ac2603334587..e0775c884553 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -316,7 +316,7 @@ struct drm_gem_object *v3d_prime_import_sg_table(struct drm_device *dev,
 						 struct sg_table *sgt);
 
 /* v3d_debugfs.c */
-int v3d_debugfs_init(struct drm_minor *minor);
+void v3d_debugfs_init(struct drm_minor *minor);
 
 /* v3d_fence.c */
 extern const struct dma_fence_ops v3d_fence_ops;

commit 9daee6141cc9c75b09659b02b1cb9eeb2f5e16cc
Author: James Hughes <james.hughes@raspberrypi.com>
Date:   Mon Feb 17 15:31:45 2020 +0000

    drm/v3d: Replace wait_for macros to remove use of msleep
    
    The wait_for macro's for Broadcom V3D driver used msleep, which is
    inappropriate due to its inaccuracy at low values (minimum wait time
    is about 30ms on the Raspberry Pi).  This sleep was triggering in
    v3d_clean_caches(), causing us to only be able to dispatch ~33 compute
    jobs per second.
    
    This patch replaces the macro with the one from the Intel i915 version
    which uses usleep_range to provide more accurate waits.
    
    v2: Split from the vc4 patch so that we can confidently apply to
        stable (by anholt)
    
    Signed-off-by: James Hughes <james.hughes@raspberrypi.com>
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20200217153145.13780-1-james.hughes@raspberrypi.com
    Link: https://github.com/raspberrypi/linux/issues/3460
    Fixes: 57692c94dcbe ("drm/v3d: Introduce a new DRM driver for Broadcom V3D V3.x+")

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index 9a35c555ec52..ac2603334587 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -254,27 +254,42 @@ struct v3d_csd_job {
 };
 
 /**
- * _wait_for - magic (register) wait macro
+ * __wait_for - magic wait macro
  *
- * Does the right thing for modeset paths when run under kdgb or similar atomic
- * contexts. Note that it's important that we check the condition again after
- * having timed out, since the timeout could be due to preemption or similar and
- * we've never had a chance to check the condition before the timeout.
+ * Macro to help avoid open coding check/wait/timeout patterns. Note that it's
+ * important that we check the condition again after having timed out, since the
+ * timeout could be due to preemption or similar and we've never had a chance to
+ * check the condition before the timeout.
  */
-#define wait_for(COND, MS) ({ \
-	unsigned long timeout__ = jiffies + msecs_to_jiffies(MS) + 1;	\
-	int ret__ = 0;							\
-	while (!(COND)) {						\
-		if (time_after(jiffies, timeout__)) {			\
-			if (!(COND))					\
-				ret__ = -ETIMEDOUT;			\
+#define __wait_for(OP, COND, US, Wmin, Wmax) ({ \
+	const ktime_t end__ = ktime_add_ns(ktime_get_raw(), 1000ll * (US)); \
+	long wait__ = (Wmin); /* recommended min for usleep is 10 us */	\
+	int ret__;							\
+	might_sleep();							\
+	for (;;) {							\
+		const bool expired__ = ktime_after(ktime_get_raw(), end__); \
+		OP;							\
+		/* Guarantee COND check prior to timeout */		\
+		barrier();						\
+		if (COND) {						\
+			ret__ = 0;					\
 			break;						\
 		}							\
-		msleep(1);					\
+		if (expired__) {					\
+			ret__ = -ETIMEDOUT;				\
+			break;						\
+		}							\
+		usleep_range(wait__, wait__ * 2);			\
+		if (wait__ < (Wmax))					\
+			wait__ <<= 1;					\
 	}								\
 	ret__;								\
 })
 
+#define _wait_for(COND, US, Wmin, Wmax)	__wait_for(, (COND), (US), (Wmin), \
+						   (Wmax))
+#define wait_for(COND, MS)		_wait_for((COND), (MS) * 1000, 10, 1000)
+
 static inline unsigned long nsecs_to_jiffies_timeout(const u64 n)
 {
 	/* nsecs_to_jiffies64() does not guard against overflow */

commit 220989e7097a5cc083624dc1c925c1c255247574
Author: Sam Ravnborg <sam@ravnborg.org>
Date:   Tue Jul 16 08:42:03 2019 +0200

    drm/v3d: drop use of drmP.h
    
    Drop use of the deprecated drmP.h header file.
    Made v3d_drv.h self-contained with only sufficient
    include files.
    Fixed fallout in remaining files.
    
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>
    Acked-by: Emil Velikov <emil.velikov@collabora.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Eric Anholt <eric@anholt.net>
    Cc: David Airlie <airlied@linux.ie>
    Cc: Daniel Vetter <daniel@ffwll.ch>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190716064220.18157-3-sam@ravnborg.org

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index 9aad9da1eb11..9a35c555ec52 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -1,14 +1,23 @@
 // SPDX-License-Identifier: GPL-2.0+
 /* Copyright (C) 2015-2018 Broadcom */
 
-#include <linux/mm_types.h>
-#include <drm/drmP.h>
+#include <linux/delay.h>
+#include <linux/mutex.h>
+#include <linux/spinlock_types.h>
+#include <linux/workqueue.h>
+
 #include <drm/drm_encoder.h>
 #include <drm/drm_gem.h>
 #include <drm/drm_gem_shmem_helper.h>
 #include <drm/gpu_scheduler.h>
+
 #include "uapi/drm/v3d_drm.h"
 
+struct clk;
+struct device;
+struct platform_device;
+struct reset_control;
+
 #define GMP_GRANULARITY (128 * 1024)
 
 /* Enum for each of the V3D queues. */

commit 38c2c7917adc8fb4ed9114b92923af9abe091af5
Author: Eric Anholt <eric@anholt.net>
Date:   Thu Apr 18 17:10:14 2019 -0700

    drm/v3d: Fix and extend MMU error handling.
    
    We were setting the wrong flags to enable PTI errors, so we were
    seeing reads to invalid PTEs show up as write errors.  Also, we
    weren't turning on the interrupts.  The AXI IDs we were dumping
    included the outstanding write number and so they looked basically
    random.  And the VIO_ADDR decoding was based on the MMU VA_WIDTH for
    the first platform I worked on and was wrong on others.  In short,
    this was a thorough mess from early HW enabling.
    
    Tested on V3D 4.1 and 4.2 with intentional L2T, CLE, PTB, and TLB
    faults.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190419001014.23579-4-eric@anholt.net
    Reviewed-by: Paul Kocialkowski <paul.kocialkowski@bootlin.com>

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index 47b86a25629e..9aad9da1eb11 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -57,6 +57,8 @@ struct v3d_dev {
 	 */
 	void *mmu_scratch;
 	dma_addr_t mmu_scratch_paddr;
+	/* virtual address bits from V3D to the MMU. */
+	int va_width;
 
 	/* Number of V3D cores. */
 	u32 cores;

commit dffa9b7a78c4361e55e21b3acb54e0d34ad15ea0
Author: Eric Anholt <eric@anholt.net>
Date:   Tue Apr 16 15:58:56 2019 -0700

    drm/v3d: Add missing implicit synchronization.
    
    It is the expectation of existing userspace (X11 + Mesa, in
    particular) that jobs submitted to the kernel against a shared BO will
    get implicitly synchronized by their submission order.  If we want to
    allow clever userspace to disable implicit synchronization, we should
    do that under its own submit flag (as amdgpu and lima do).
    
    Note that we currently only implicitly sync for the rendering pass,
    not binning -- if you texture-from-pixmap in the binning vertex shader
    (vertex coordinate generation), you'll miss out on synchronization.
    
    Fixes flickering when multiple clients are running in parallel,
    particularly GL apps and compositors.
    
    v2: Fix a missing refcount on the CSD done fence for L2 cleaning.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190416225856.20264-6-eric@anholt.net
    Acked-by: Rob Clark <robdclark@gmail.com>

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index 3d816e1674a0..47b86a25629e 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -182,8 +182,10 @@ struct v3d_job {
 	struct drm_gem_object **bo;
 	u32 bo_count;
 
-	/* An optional fence userspace can pass in for the job to depend on. */
-	struct dma_fence *in_fence;
+	/* Array of struct dma_fence * to block on before submitting this job.
+	 */
+	struct xarray deps;
+	unsigned long last_dep;
 
 	/* v3d fence to be signaled by IRQ handler when the job is complete. */
 	struct dma_fence *irq_fence;
@@ -215,11 +217,6 @@ struct v3d_bin_job {
 struct v3d_render_job {
 	struct v3d_job base;
 
-	/* Optional fence for the binner, to depend on before starting
-	 * our job.
-	 */
-	struct dma_fence *bin_done_fence;
-
 	/* GPU virtual addresses of the start/end of the CL job. */
 	u32 start, end;
 

commit d223f98f02099b002903b9b22b56febae16ef80d
Author: Eric Anholt <eric@anholt.net>
Date:   Tue Apr 16 15:58:54 2019 -0700

    drm/v3d: Add support for compute shader dispatch.
    
    The compute shader dispatch interface is pretty simple -- just pass in
    the regs that userspace has passed us, with no CLs to run.  However,
    with no CL to run it means that we need to do manual cache flushing of
    the L2 after the HW execution completes (for SSBO, atomic, and
    image_load_store writes that are the output of compute shaders).
    
    This doesn't yet expose the L2 cache's ability to have a region of the
    address space not write back to memory (which could be used for
    shared_var storage).
    
    So far, the Mesa side has been tested on V3D v4.2 simpenrose (passing
    the ES31 tests), and on the kernel side on 7278 (failing atomic
    compswap tests in a way that doesn't reproduce on simpenrose).
    
    v2: Fix excessive allocation for the clean_job (reported by Dan
        Carpenter).  Keep refs on jobs until clean_job is finished, to
        avoid spurious MMU errors if the output BOs are freed by userspace
        before L2 cleaning is finished.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190416225856.20264-4-eric@anholt.net
    Acked-by: Rob Clark <robdclark@gmail.com>

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index f82f8be04bd8..3d816e1674a0 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -16,9 +16,11 @@ enum v3d_queue {
 	V3D_BIN,
 	V3D_RENDER,
 	V3D_TFU,
+	V3D_CSD,
+	V3D_CACHE_CLEAN,
 };
 
-#define V3D_MAX_QUEUES (V3D_TFU + 1)
+#define V3D_MAX_QUEUES (V3D_CACHE_CLEAN + 1)
 
 struct v3d_queue_state {
 	struct drm_gpu_scheduler sched;
@@ -70,6 +72,7 @@ struct v3d_dev {
 	struct v3d_bin_job *bin_job;
 	struct v3d_render_job *render_job;
 	struct v3d_tfu_job *tfu_job;
+	struct v3d_csd_job *csd_job;
 
 	struct v3d_queue_state queue[V3D_MAX_QUEUES];
 
@@ -92,6 +95,12 @@ struct v3d_dev {
 	 */
 	struct mutex sched_lock;
 
+	/* Lock taken during a cache clean and when initiating an L2
+	 * flush, to keep L2 flushes from interfering with the
+	 * synchronous L2 cleans.
+	 */
+	struct mutex cache_clean_lock;
+
 	struct {
 		u32 num_allocated;
 		u32 pages_allocated;
@@ -104,6 +113,12 @@ to_v3d_dev(struct drm_device *dev)
 	return (struct v3d_dev *)dev->dev_private;
 }
 
+static inline bool
+v3d_has_csd(struct v3d_dev *v3d)
+{
+	return v3d->ver >= 41;
+}
+
 /* The per-fd struct, which tracks the MMU mappings. */
 struct v3d_file_priv {
 	struct v3d_dev *v3d;
@@ -222,6 +237,14 @@ struct v3d_tfu_job {
 	struct drm_v3d_submit_tfu args;
 };
 
+struct v3d_csd_job {
+	struct v3d_job base;
+
+	u32 timedout_batches;
+
+	struct drm_v3d_submit_csd args;
+};
+
 /**
  * _wait_for - magic (register) wait macro
  *
@@ -283,11 +306,14 @@ int v3d_submit_cl_ioctl(struct drm_device *dev, void *data,
 			struct drm_file *file_priv);
 int v3d_submit_tfu_ioctl(struct drm_device *dev, void *data,
 			 struct drm_file *file_priv);
+int v3d_submit_csd_ioctl(struct drm_device *dev, void *data,
+			 struct drm_file *file_priv);
 int v3d_wait_bo_ioctl(struct drm_device *dev, void *data,
 		      struct drm_file *file_priv);
 void v3d_job_put(struct v3d_job *job);
 void v3d_reset(struct v3d_dev *v3d);
 void v3d_invalidate_caches(struct v3d_dev *v3d);
+void v3d_clean_caches(struct v3d_dev *v3d);
 
 /* v3d_irq.c */
 int v3d_irq_init(struct v3d_dev *v3d);

commit a783a09ee76d6259296dc6aeea2b6884fa526980
Author: Eric Anholt <eric@anholt.net>
Date:   Tue Apr 16 15:58:53 2019 -0700

    drm/v3d: Refactor job management.
    
    The CL submission had two jobs embedded in an exec struct.  When I
    added TFU support, I had to replicate some of the exec stuff and some
    of the job stuff.  As I went to add CSD, it became clear that actually
    what was in exec should just be in the two CL jobs, and it would let
    us share a lot more code between the 4 queues.
    
    v2: Fix missing error path in TFU ioctl's bo[] allocation.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190416225856.20264-3-eric@anholt.net
    Acked-by: Rob Clark <robdclark@gmail.com>

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index 67c323e781f9..f82f8be04bd8 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -67,8 +67,8 @@ struct v3d_dev {
 
 	struct work_struct overflow_mem_work;
 
-	struct v3d_exec_info *bin_job;
-	struct v3d_exec_info *render_job;
+	struct v3d_bin_job *bin_job;
+	struct v3d_render_job *render_job;
 	struct v3d_tfu_job *tfu_job;
 
 	struct v3d_queue_state queue[V3D_MAX_QUEUES];
@@ -117,7 +117,7 @@ struct v3d_bo {
 	struct drm_mm_node node;
 
 	/* List entry for the BO's position in
-	 * v3d_exec_info->unref_list
+	 * v3d_render_job->unref_list
 	 */
 	struct list_head unref_head;
 };
@@ -157,7 +157,15 @@ to_v3d_fence(struct dma_fence *fence)
 struct v3d_job {
 	struct drm_sched_job base;
 
-	struct v3d_exec_info *exec;
+	struct kref refcount;
+
+	struct v3d_dev *v3d;
+
+	/* This is the array of BOs that were looked up at the start
+	 * of submission.
+	 */
+	struct drm_gem_object **bo;
+	u32 bo_count;
 
 	/* An optional fence userspace can pass in for the job to depend on. */
 	struct dma_fence *in_fence;
@@ -165,59 +173,53 @@ struct v3d_job {
 	/* v3d fence to be signaled by IRQ handler when the job is complete. */
 	struct dma_fence *irq_fence;
 
+	/* scheduler fence for when the job is considered complete and
+	 * the BO reservations can be released.
+	 */
+	struct dma_fence *done_fence;
+
+	/* Callback for the freeing of the job on refcount going to 0. */
+	void (*free)(struct kref *ref);
+};
+
+struct v3d_bin_job {
+	struct v3d_job base;
+
 	/* GPU virtual addresses of the start/end of the CL job. */
 	u32 start, end;
 
 	u32 timedout_ctca, timedout_ctra;
-};
 
-struct v3d_exec_info {
-	struct v3d_dev *v3d;
+	/* Corresponding render job, for attaching our overflow memory. */
+	struct v3d_render_job *render;
+
+	/* Submitted tile memory allocation start/size, tile state. */
+	u32 qma, qms, qts;
+};
 
-	struct v3d_job bin, render;
+struct v3d_render_job {
+	struct v3d_job base;
 
-	/* Fence for when the scheduler considers the binner to be
-	 * done, for render to depend on.
+	/* Optional fence for the binner, to depend on before starting
+	 * our job.
 	 */
 	struct dma_fence *bin_done_fence;
 
-	/* Fence for when the scheduler considers the render to be
-	 * done, for when the BOs reservations should be complete.
-	 */
-	struct dma_fence *render_done_fence;
-
-	struct kref refcount;
+	/* GPU virtual addresses of the start/end of the CL job. */
+	u32 start, end;
 
-	/* This is the array of BOs that were looked up at the start of exec. */
-	struct drm_gem_object **bo;
-	u32 bo_count;
+	u32 timedout_ctca, timedout_ctra;
 
 	/* List of overflow BOs used in the job that need to be
 	 * released once the job is complete.
 	 */
 	struct list_head unref_list;
-
-	/* Submitted tile memory allocation start/size, tile state. */
-	u32 qma, qms, qts;
 };
 
 struct v3d_tfu_job {
-	struct drm_sched_job base;
+	struct v3d_job base;
 
 	struct drm_v3d_submit_tfu args;
-
-	/* An optional fence userspace can pass in for the job to depend on. */
-	struct dma_fence *in_fence;
-
-	/* v3d fence to be signaled by IRQ handler when the job is complete. */
-	struct dma_fence *irq_fence;
-
-	struct v3d_dev *v3d;
-
-	struct kref refcount;
-
-	/* This is the array of BOs that were looked up at the start of exec. */
-	struct drm_gem_object *bo[4];
 };
 
 /**
@@ -283,8 +285,7 @@ int v3d_submit_tfu_ioctl(struct drm_device *dev, void *data,
 			 struct drm_file *file_priv);
 int v3d_wait_bo_ioctl(struct drm_device *dev, void *data,
 		      struct drm_file *file_priv);
-void v3d_exec_put(struct v3d_exec_info *exec);
-void v3d_tfu_job_put(struct v3d_tfu_job *exec);
+void v3d_job_put(struct v3d_job *job);
 void v3d_reset(struct v3d_dev *v3d);
 void v3d_invalidate_caches(struct v3d_dev *v3d);
 

commit d4c3022a23d2f56057b67e9711199e68a1615567
Author: Eric Anholt <eric@anholt.net>
Date:   Tue Apr 16 15:58:52 2019 -0700

    drm/v3d: Switch the type of job-> to reduce casting.
    
    All consumers wanted drm_gem_object * now.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190416225856.20264-2-eric@anholt.net
    Acked-by: Rob Clark <robdclark@gmail.com>

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index e9d4a2fdcf44..67c323e781f9 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -189,7 +189,7 @@ struct v3d_exec_info {
 	struct kref refcount;
 
 	/* This is the array of BOs that were looked up at the start of exec. */
-	struct v3d_bo **bo;
+	struct drm_gem_object **bo;
 	u32 bo_count;
 
 	/* List of overflow BOs used in the job that need to be
@@ -217,7 +217,7 @@ struct v3d_tfu_job {
 	struct kref refcount;
 
 	/* This is the array of BOs that were looked up at the start of exec. */
-	struct v3d_bo *bo[4];
+	struct drm_gem_object *bo[4];
 };
 
 /**

commit 3f0b646e1a54248bcd5304f1de71091dad4e7b1e
Author: Eric Anholt <eric@anholt.net>
Date:   Wed Mar 13 16:52:09 2019 -0700

    drm/v3d: Rename the fence signaled from IRQs to "irq_fence".
    
    We have another thing called the "done fence" that tracks when the
    scheduler considers the job done, and having the shared name was
    confusing.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190313235211.28995-2-eric@anholt.net
    Reviewed-by: Dave Emett <david.emett@broadcom.com>

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index 7b0fe6240f7d..e9d4a2fdcf44 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -163,7 +163,7 @@ struct v3d_job {
 	struct dma_fence *in_fence;
 
 	/* v3d fence to be signaled by IRQ handler when the job is complete. */
-	struct dma_fence *done_fence;
+	struct dma_fence *irq_fence;
 
 	/* GPU virtual addresses of the start/end of the CL job. */
 	u32 start, end;
@@ -210,7 +210,7 @@ struct v3d_tfu_job {
 	struct dma_fence *in_fence;
 
 	/* v3d fence to be signaled by IRQ handler when the job is complete. */
-	struct dma_fence *done_fence;
+	struct dma_fence *irq_fence;
 
 	struct v3d_dev *v3d;
 

commit 40609d4820b21ff0bb0a58e196601a6747fd55b7
Author: Eric Anholt <eric@anholt.net>
Date:   Thu Mar 14 09:34:51 2019 -0700

    drm/v3d: Use the new shmem helpers to reduce driver boilerplate.
    
    The new shmem helpers from Noralf and Rob abstract out a bunch of our
    BO creation and mapping code.
    
    v2: Use the new sgt getter, and flag pages as dirty before freeing.
    v3: Remove the mismatched put_pages.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190314163451.13431-1-eric@anholt.net
    Reviewed-by: Rob Herring <robh@kernel.org> (v2)

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index 65906c05dc9c..7b0fe6240f7d 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -5,6 +5,7 @@
 #include <drm/drmP.h>
 #include <drm/drm_encoder.h>
 #include <drm/drm_gem.h>
+#include <drm/drm_gem_shmem_helper.h>
 #include <drm/gpu_scheduler.h>
 #include "uapi/drm/v3d_drm.h"
 
@@ -111,16 +112,10 @@ struct v3d_file_priv {
 };
 
 struct v3d_bo {
-	struct drm_gem_object base;
-
-	struct mutex lock;
+	struct drm_gem_shmem_object base;
 
 	struct drm_mm_node node;
 
-	u32 pages_refcount;
-	struct page **pages;
-	struct sg_table *sgt;
-
 	/* List entry for the BO's position in
 	 * v3d_exec_info->unref_list
 	 */
@@ -258,6 +253,7 @@ static inline unsigned long nsecs_to_jiffies_timeout(const u64 n)
 }
 
 /* v3d_bo.c */
+struct drm_gem_object *v3d_create_object(struct drm_device *dev, size_t size);
 void v3d_free_object(struct drm_gem_object *gem_obj);
 struct v3d_bo *v3d_bo_create(struct drm_device *dev, struct drm_file *file_priv,
 			     size_t size);
@@ -267,10 +263,6 @@ int v3d_mmap_bo_ioctl(struct drm_device *dev, void *data,
 		      struct drm_file *file_priv);
 int v3d_get_bo_offset_ioctl(struct drm_device *dev, void *data,
 			    struct drm_file *file_priv);
-vm_fault_t v3d_gem_fault(struct vm_fault *vmf);
-int v3d_mmap(struct file *filp, struct vm_area_struct *vma);
-int v3d_prime_mmap(struct drm_gem_object *obj, struct vm_area_struct *vma);
-struct sg_table *v3d_prime_get_sg_table(struct drm_gem_object *obj);
 struct drm_gem_object *v3d_prime_import_sg_table(struct drm_device *dev,
 						 struct dma_buf_attachment *attach,
 						 struct sg_table *sgt);

commit a83e47e421ec5c4c5d6cae099cd54e3ce5b2bd06
Author: Eric Anholt <eric@anholt.net>
Date:   Fri Mar 8 08:17:15 2019 -0800

    drm/v3d: Remove some dead members of struct v3d_bo.
    
    vmas was from the previous model of page table management (one per
    fd), and vaddr was left over from vc4.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190308161716.2466-4-eric@anholt.net
    Acked-by: Rob Herring <robh@kernel.org>

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index b5efac7894ca..65906c05dc9c 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -110,12 +110,6 @@ struct v3d_file_priv {
 	struct drm_sched_entity sched_entity[V3D_MAX_QUEUES];
 };
 
-/* Tracks a mapping of a BO into a per-fd address space */
-struct v3d_vma {
-	struct v3d_page_table *pt;
-	struct list_head list; /* entry in v3d_bo.vmas */
-};
-
 struct v3d_bo {
 	struct drm_gem_object base;
 
@@ -126,9 +120,6 @@ struct v3d_bo {
 	u32 pages_refcount;
 	struct page **pages;
 	struct sg_table *sgt;
-	void *vaddr;
-
-	struct list_head vmas;    /* list of v3d_vma */
 
 	/* List entry for the BO's position in
 	 * v3d_exec_info->unref_list

commit eea9b97b4504607a0805c71b20d2c3e93c8711a7
Author: Eric Anholt <eric@anholt.net>
Date:   Fri Mar 8 09:43:36 2019 -0800

    drm/v3d: Add support for V3D v4.2.
    
    No compatible string for it yet, just the version-dependent changes.
    They've now tied the hub and the core interrupt lines into a single
    interrupt line coming out of the block.  It also turns out I made a
    mistake in modeling the V3D v3.3 and v4.1 bridge as a part of V3D
    itself -- the bridge is going away in favor of an external reset
    controller in a larger HW module.
    
    v2: Use consistent checks for whether we're on 4.2, and fix a leak in
        an error path.
    v3: Use more general means of determining if the current 4.2 changes
        are in place, as apparently other platforms may switch back (noted
        by Dave).  Update the binding doc.
    v4: Improve error handling for IRQ init.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190308174336.7866-2-eric@anholt.net
    Reviewed-by: Dave Emett <david.emett@broadcom.com>

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index bb58ecb9d9c5..b5efac7894ca 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -33,6 +33,7 @@ struct v3d_dev {
 	 * and revision.
 	 */
 	int ver;
+	bool single_irq_line;
 
 	struct device *dev;
 	struct platform_device *pdev;
@@ -41,6 +42,7 @@ struct v3d_dev {
 	void __iomem *bridge_regs;
 	void __iomem *gca_regs;
 	struct clk *clk;
+	struct reset_control *reset;
 
 	/* Virtual and DMA addresses of the single shared page table. */
 	volatile u32 *pt;

commit fc22771547e7e8a63679f0218e943d72b107de65
Author: Eric Anholt <eric@anholt.net>
Date:   Fri Mar 8 09:43:35 2019 -0800

    drm/v3d: Handle errors from IRQ setup.
    
    Noted in review by Dave Emett for V3D 4.2 support.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190308174336.7866-1-eric@anholt.net
    Reviewed-by: Dave Emett <david.emett@broadcom.com>

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index d856159bd007..bb58ecb9d9c5 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -304,7 +304,7 @@ void v3d_reset(struct v3d_dev *v3d);
 void v3d_invalidate_caches(struct v3d_dev *v3d);
 
 /* v3d_irq.c */
-void v3d_irq_init(struct v3d_dev *v3d);
+int v3d_irq_init(struct v3d_dev *v3d);
 void v3d_irq_enable(struct v3d_dev *v3d);
 void v3d_irq_disable(struct v3d_dev *v3d);
 void v3d_irq_reset(struct v3d_dev *v3d);

commit 8d668309769dbb20942bdfa04b0e66ea8c84e720
Author: Rob Herring <robh@kernel.org>
Date:   Sat Feb 2 09:41:57 2019 -0600

    drm: v3d: Switch to use drm_gem_object reservation_object
    
    Now that the base struct drm_gem_object has a reservation_object, use it
    and remove the private BO one.
    
    Cc: Eric Anholt <eric@anholt.net>
    Cc: Daniel Vetter <daniel@ffwll.ch>
    Cc: David Airlie <airlied@linux.ie>
    Cc: dri-devel@lists.freedesktop.org
    Signed-off-by: Rob Herring <robh@kernel.org>
    Acked-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190202154158.10443-5-robh@kernel.org
    Signed-off-by: Maxime Ripard <maxime.ripard@bootlin.com>

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index fdda3037f7af..d856159bd007 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -1,7 +1,6 @@
 // SPDX-License-Identifier: GPL-2.0+
 /* Copyright (C) 2015-2018 Broadcom */
 
-#include <linux/reservation.h>
 #include <linux/mm_types.h>
 #include <drm/drmP.h>
 #include <drm/drm_encoder.h>
@@ -133,10 +132,6 @@ struct v3d_bo {
 	 * v3d_exec_info->unref_list
 	 */
 	struct list_head unref_head;
-
-	/* normally (resv == &_resv) except for imported bo's */
-	struct reservation_object *resv;
-	struct reservation_object _resv;
 };
 
 static inline struct v3d_bo *
@@ -281,7 +276,6 @@ int v3d_get_bo_offset_ioctl(struct drm_device *dev, void *data,
 			    struct drm_file *file_priv);
 vm_fault_t v3d_gem_fault(struct vm_fault *vmf);
 int v3d_mmap(struct file *filp, struct vm_area_struct *vma);
-struct reservation_object *v3d_prime_res_obj(struct drm_gem_object *obj);
 int v3d_prime_mmap(struct drm_gem_object *obj, struct vm_area_struct *vma);
 struct sg_table *v3d_prime_get_sg_table(struct drm_gem_object *obj);
 struct drm_gem_object *v3d_prime_import_sg_table(struct drm_device *dev,

commit 2aa34fd5c7754824cf5488b61ac644f30d3c5c85
Author: Eric Anholt <eric@anholt.net>
Date:   Mon Dec 3 14:24:34 2018 -0800

    drm/v3d: Drop unused v3d_flush_caches().
    
    Now that I've specified how the end-of-pipeline flushing should work,
    we're never going to use this function.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Reviewed-by: Dave Emett <david.emett@broadcom.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20181203222438.25417-2-eric@anholt.net

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index dcb772a19191..fdda3037f7af 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -308,7 +308,6 @@ void v3d_exec_put(struct v3d_exec_info *exec);
 void v3d_tfu_job_put(struct v3d_tfu_job *exec);
 void v3d_reset(struct v3d_dev *v3d);
 void v3d_invalidate_caches(struct v3d_dev *v3d);
-void v3d_flush_caches(struct v3d_dev *v3d);
 
 /* v3d_irq.c */
 void v3d_irq_init(struct v3d_dev *v3d);

commit 1584f16ca96ef124aad79efa3303cff5f3530e2c
Author: Eric Anholt <eric@anholt.net>
Date:   Wed Nov 28 15:09:25 2018 -0800

    drm/v3d: Add support for submitting jobs to the TFU.
    
    The TFU can copy from raster, UIF, and SAND input images to UIF output
    images, with optional mipmap generation.  This will certainly be
    useful for media EGL image input, but is also useful immediately for
    mipmap generation without bogging the V3D core down.
    
    For now we only run the queue 1 job deep, and don't have any hang
    recovery (though I don't think we should need it, with TFU).  Queuing
    multiple jobs in the HW will require synchronizing the YUV coefficient
    regs updates since they don't get FIFOed with the job.
    
    v2: Change the ioctl to IOW instead of IOWR, always set COEF0, explain
        why TFU is AUTH, clarify the syncing docs, drop the unused TFU
        interrupt regs (you're expected to use the hub's), don't take
        &bo->base for NULL bos.
    v3: Fix a little whitespace alignment (noticed by checkpatch), rebase
        on drm_sched_job_cleanup() changes.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Reviewed-by: Dave Emett <david.emett@broadcom.com> (v2)
    Link: https://patchwork.freedesktop.org/patch/264607/

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index cbe5be0c47eb..dcb772a19191 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -7,19 +7,18 @@
 #include <drm/drm_encoder.h>
 #include <drm/drm_gem.h>
 #include <drm/gpu_scheduler.h>
+#include "uapi/drm/v3d_drm.h"
 
 #define GMP_GRANULARITY (128 * 1024)
 
-/* Enum for each of the V3D queues.  We maintain various queue
- * tracking as an array because at some point we'll want to support
- * the TFU (texture formatting unit) as another queue.
- */
+/* Enum for each of the V3D queues. */
 enum v3d_queue {
 	V3D_BIN,
 	V3D_RENDER,
+	V3D_TFU,
 };
 
-#define V3D_MAX_QUEUES (V3D_RENDER + 1)
+#define V3D_MAX_QUEUES (V3D_TFU + 1)
 
 struct v3d_queue_state {
 	struct drm_gpu_scheduler sched;
@@ -68,6 +67,7 @@ struct v3d_dev {
 
 	struct v3d_exec_info *bin_job;
 	struct v3d_exec_info *render_job;
+	struct v3d_tfu_job *tfu_job;
 
 	struct v3d_queue_state queue[V3D_MAX_QUEUES];
 
@@ -218,6 +218,25 @@ struct v3d_exec_info {
 	u32 qma, qms, qts;
 };
 
+struct v3d_tfu_job {
+	struct drm_sched_job base;
+
+	struct drm_v3d_submit_tfu args;
+
+	/* An optional fence userspace can pass in for the job to depend on. */
+	struct dma_fence *in_fence;
+
+	/* v3d fence to be signaled by IRQ handler when the job is complete. */
+	struct dma_fence *done_fence;
+
+	struct v3d_dev *v3d;
+
+	struct kref refcount;
+
+	/* This is the array of BOs that were looked up at the start of exec. */
+	struct v3d_bo *bo[4];
+};
+
 /**
  * _wait_for - magic (register) wait macro
  *
@@ -281,9 +300,12 @@ int v3d_gem_init(struct drm_device *dev);
 void v3d_gem_destroy(struct drm_device *dev);
 int v3d_submit_cl_ioctl(struct drm_device *dev, void *data,
 			struct drm_file *file_priv);
+int v3d_submit_tfu_ioctl(struct drm_device *dev, void *data,
+			 struct drm_file *file_priv);
 int v3d_wait_bo_ioctl(struct drm_device *dev, void *data,
 		      struct drm_file *file_priv);
 void v3d_exec_put(struct v3d_exec_info *exec);
+void v3d_tfu_job_put(struct v3d_tfu_job *exec);
 void v3d_reset(struct v3d_dev *v3d);
 void v3d_invalidate_caches(struct v3d_dev *v3d);
 void v3d_flush_caches(struct v3d_dev *v3d);

commit 34c2c4f632f232ed2fdb66d4e42cc72d322273fe
Author: Eric Anholt <eric@anholt.net>
Date:   Fri Sep 28 16:21:23 2018 -0700

    drm/v3d: Fix a use-after-free race accessing the scheduler's fences.
    
    Once we push the job, the scheduler could run it and free it.  So, if
    we want to reference their fences, we need to grab them before then.
    I haven't seen this happen in many days of conformance test runtime,
    but let's still close the race.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Fixes: 57692c94dcbe ("drm/v3d: Introduce a new DRM driver for Broadcom V3D V3.x+")
    Link: https://patchwork.freedesktop.org/patch/254119/
    Reviewed-by: Boris Brezillon <boris.brezillon@bootlin.com>

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index e6fed696ad86..cbe5be0c47eb 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -198,6 +198,11 @@ struct v3d_exec_info {
 	 */
 	struct dma_fence *bin_done_fence;
 
+	/* Fence for when the scheduler considers the render to be
+	 * done, for when the BOs reservations should be complete.
+	 */
+	struct dma_fence *render_done_fence;
+
 	struct kref refcount;
 
 	/* This is the array of BOs that were looked up at the start of exec. */

commit 624bb0c08b8298cbc6a16f9c68edc93f767716ec
Author: Eric Anholt <eric@anholt.net>
Date:   Tue Jul 3 10:05:12 2018 -0700

    drm/v3d: Delay the scheduler timeout if we're still making progress.
    
    GTF-GLES2.gtf.GL.acos.acos_float_vert_xvary submits jobs that take 4
    seconds at maximum resolution, but we still want to reset quickly if a
    job is really hung.  Sample the CL's current address and the return
    address (since we call into tile lists repeatedly) and if either has
    changed then assume we've made progress.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Cc: Lucas Stach <l.stach@pengutronix.de>
    Link: https://patchwork.freedesktop.org/patch/msgid/20180703170515.6298-1-eric@anholt.net
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Acked-by: Daniel Vetter <daniel@ffwll.ch>

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index 282763c9c7f6..e6fed696ad86 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -184,6 +184,8 @@ struct v3d_job {
 
 	/* GPU virtual addresses of the start/end of the CL job. */
 	u32 start, end;
+
+	u32 timedout_ctca, timedout_ctra;
 };
 
 struct v3d_exec_info {

commit 408633d2e740221204100efb9c3eed71f39aacd0
Author: Souptick Joarder <jrdr.linux@gmail.com>
Date:   Wed Jul 4 20:25:57 2018 +0530

    drm/v3d: use new return type vm_fault_t in v3d_gem_fault
    
    Instead of converting an errno into a vm_fault_t ourselves, use
    vmf_insert_mixed() which returns a vm_fault_t directly.
    
    Signed-off-by: Souptick Joarder <jrdr.linux@gmail.com>
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20180704145556.GA11036@jordon-HP-15-Notebook-PC
    Reviewed-by: Matthew Wilcox <willy@infradead.org>

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index f32ac8c98f37..282763c9c7f6 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -2,6 +2,7 @@
 /* Copyright (C) 2015-2018 Broadcom */
 
 #include <linux/reservation.h>
+#include <linux/mm_types.h>
 #include <drm/drmP.h>
 #include <drm/drm_encoder.h>
 #include <drm/drm_gem.h>
@@ -252,7 +253,7 @@ int v3d_mmap_bo_ioctl(struct drm_device *dev, void *data,
 		      struct drm_file *file_priv);
 int v3d_get_bo_offset_ioctl(struct drm_device *dev, void *data,
 			    struct drm_file *file_priv);
-int v3d_gem_fault(struct vm_fault *vmf);
+vm_fault_t v3d_gem_fault(struct vm_fault *vmf);
 int v3d_mmap(struct file *filp, struct vm_area_struct *vma);
 struct reservation_object *v3d_prime_res_obj(struct drm_gem_object *obj);
 int v3d_prime_mmap(struct drm_gem_object *obj, struct vm_area_struct *vma);

commit 14d1d190869685d3a1e8a3f63924e20594557cb2
Author: Eric Anholt <eric@anholt.net>
Date:   Tue Jun 5 12:03:01 2018 -0700

    drm/v3d: Remove the bad signaled() implementation.
    
    Since our seqno value comes from a counter associated with the GPU
    ring, not the entity (aka client), they'll be completed out of order.
    There's actually no need for this code at all, since we don't have
    enable_signaling() and thus DMA_FENCE_SIGNALED_BIT will be set before
    we could be called.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20180605190302.18279-2-eric@anholt.net
    Reviewed-by: Lucas Stach <l.stach@pengutronix.de>

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index 26005abd9c5d..f32ac8c98f37 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -25,7 +25,6 @@ struct v3d_queue_state {
 
 	u64 fence_context;
 	u64 emit_seqno;
-	u64 finished_seqno;
 };
 
 struct v3d_dev {

commit 7122b68b8a9692dcc3acf89595f04c492872115f
Author: Eric Anholt <eric@anholt.net>
Date:   Wed Jun 6 10:48:51 2018 -0700

    drm/v3d: Take a lock across GPU scheduler job creation and queuing.
    
    Between creation and queueing of a job, you need to prevent any other
    job from being created and queued.  Otherwise the scheduler's fences
    may be signaled out of seqno order.
    
    v2: move mutex unlock to the error label.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Fixes: 57692c94dcbe ("drm/v3d: Introduce a new DRM driver for Broadcom V3D V3.x+")
    Link: https://patchwork.freedesktop.org/patch/msgid/20180606174851.12433-1-eric@anholt.net
    Reviewed-by: Lucas Stach <l.stach@pengutronix.de>

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
index a043ac3aae98..26005abd9c5d 100644
--- a/drivers/gpu/drm/v3d/v3d_drv.h
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -85,6 +85,11 @@ struct v3d_dev {
 	 */
 	struct mutex reset_lock;
 
+	/* Lock taken when creating and pushing the GPU scheduler
+	 * jobs, to keep the sched-fence seqnos in order.
+	 */
+	struct mutex sched_lock;
+
 	struct {
 		u32 num_allocated;
 		u32 pages_allocated;

commit 57692c94dcbe99a1e0444409a3da13fb3443562c
Author: Eric Anholt <eric@anholt.net>
Date:   Mon Apr 30 11:10:58 2018 -0700

    drm/v3d: Introduce a new DRM driver for Broadcom V3D V3.x+
    
    This driver will be used to support Mesa on the Broadcom 7268 and 7278
    platforms.
    
    V3D 3.3 introduces an MMU, which means we no longer need CMA or vc4's
    complicated CL/shader validation scheme.  This massively changes the
    GEM behavior, so I've forked off to a new driver.
    
    v2: Mark SUBMIT_CL as needing DRM_AUTH.  coccinelle fixes from kbuild
        test robot. Drop personal git link from MAINTAINERS.  Don't
        double-map dma-buf imported BOs.  Add kerneldoc about needing MMU
        eviction.  Drop prime vmap/unmap stubs.  Delay mmap offset setup
        to mmap time.  Use drm_dev_init instead of _alloc.  Use
        ktime_get() for wait_bo timeouts.  Drop drm_can_sleep() usage,
        since we don't modeset.  Switch page tables back to WC (debug
        change to coherent had slipped in).  Switch
        drm_gem_object_unreference_unlocked() to
        drm_gem_object_put_unlocked().  Simplify overflow mem handling by
        not sharing overflow mem between jobs.
    v3: no changes
    v4: align submit_cl to 64 bits (review by airlied), check zero flags in
        other ioctls.
    
    Signed-off-by: Eric Anholt <eric@anholt.net>
    Acked-by: Daniel Vetter <daniel.vetter@ffwll.ch> (v4)
    Acked-by: Dave Airlie <airlied@linux.ie> (v3, requested submit_cl change)
    Link: https://patchwork.freedesktop.org/patch/msgid/20180430181058.30181-3-eric@anholt.net

diff --git a/drivers/gpu/drm/v3d/v3d_drv.h b/drivers/gpu/drm/v3d/v3d_drv.h
new file mode 100644
index 000000000000..a043ac3aae98
--- /dev/null
+++ b/drivers/gpu/drm/v3d/v3d_drv.h
@@ -0,0 +1,294 @@
+// SPDX-License-Identifier: GPL-2.0+
+/* Copyright (C) 2015-2018 Broadcom */
+
+#include <linux/reservation.h>
+#include <drm/drmP.h>
+#include <drm/drm_encoder.h>
+#include <drm/drm_gem.h>
+#include <drm/gpu_scheduler.h>
+
+#define GMP_GRANULARITY (128 * 1024)
+
+/* Enum for each of the V3D queues.  We maintain various queue
+ * tracking as an array because at some point we'll want to support
+ * the TFU (texture formatting unit) as another queue.
+ */
+enum v3d_queue {
+	V3D_BIN,
+	V3D_RENDER,
+};
+
+#define V3D_MAX_QUEUES (V3D_RENDER + 1)
+
+struct v3d_queue_state {
+	struct drm_gpu_scheduler sched;
+
+	u64 fence_context;
+	u64 emit_seqno;
+	u64 finished_seqno;
+};
+
+struct v3d_dev {
+	struct drm_device drm;
+
+	/* Short representation (e.g. 33, 41) of the V3D tech version
+	 * and revision.
+	 */
+	int ver;
+
+	struct device *dev;
+	struct platform_device *pdev;
+	void __iomem *hub_regs;
+	void __iomem *core_regs[3];
+	void __iomem *bridge_regs;
+	void __iomem *gca_regs;
+	struct clk *clk;
+
+	/* Virtual and DMA addresses of the single shared page table. */
+	volatile u32 *pt;
+	dma_addr_t pt_paddr;
+
+	/* Virtual and DMA addresses of the MMU's scratch page.  When
+	 * a read or write is invalid in the MMU, it will be
+	 * redirected here.
+	 */
+	void *mmu_scratch;
+	dma_addr_t mmu_scratch_paddr;
+
+	/* Number of V3D cores. */
+	u32 cores;
+
+	/* Allocator managing the address space.  All units are in
+	 * number of pages.
+	 */
+	struct drm_mm mm;
+	spinlock_t mm_lock;
+
+	struct work_struct overflow_mem_work;
+
+	struct v3d_exec_info *bin_job;
+	struct v3d_exec_info *render_job;
+
+	struct v3d_queue_state queue[V3D_MAX_QUEUES];
+
+	/* Spinlock used to synchronize the overflow memory
+	 * management against bin job submission.
+	 */
+	spinlock_t job_lock;
+
+	/* Protects bo_stats */
+	struct mutex bo_lock;
+
+	/* Lock taken when resetting the GPU, to keep multiple
+	 * processes from trying to park the scheduler threads and
+	 * reset at once.
+	 */
+	struct mutex reset_lock;
+
+	struct {
+		u32 num_allocated;
+		u32 pages_allocated;
+	} bo_stats;
+};
+
+static inline struct v3d_dev *
+to_v3d_dev(struct drm_device *dev)
+{
+	return (struct v3d_dev *)dev->dev_private;
+}
+
+/* The per-fd struct, which tracks the MMU mappings. */
+struct v3d_file_priv {
+	struct v3d_dev *v3d;
+
+	struct drm_sched_entity sched_entity[V3D_MAX_QUEUES];
+};
+
+/* Tracks a mapping of a BO into a per-fd address space */
+struct v3d_vma {
+	struct v3d_page_table *pt;
+	struct list_head list; /* entry in v3d_bo.vmas */
+};
+
+struct v3d_bo {
+	struct drm_gem_object base;
+
+	struct mutex lock;
+
+	struct drm_mm_node node;
+
+	u32 pages_refcount;
+	struct page **pages;
+	struct sg_table *sgt;
+	void *vaddr;
+
+	struct list_head vmas;    /* list of v3d_vma */
+
+	/* List entry for the BO's position in
+	 * v3d_exec_info->unref_list
+	 */
+	struct list_head unref_head;
+
+	/* normally (resv == &_resv) except for imported bo's */
+	struct reservation_object *resv;
+	struct reservation_object _resv;
+};
+
+static inline struct v3d_bo *
+to_v3d_bo(struct drm_gem_object *bo)
+{
+	return (struct v3d_bo *)bo;
+}
+
+struct v3d_fence {
+	struct dma_fence base;
+	struct drm_device *dev;
+	/* v3d seqno for signaled() test */
+	u64 seqno;
+	enum v3d_queue queue;
+};
+
+static inline struct v3d_fence *
+to_v3d_fence(struct dma_fence *fence)
+{
+	return (struct v3d_fence *)fence;
+}
+
+#define V3D_READ(offset) readl(v3d->hub_regs + offset)
+#define V3D_WRITE(offset, val) writel(val, v3d->hub_regs + offset)
+
+#define V3D_BRIDGE_READ(offset) readl(v3d->bridge_regs + offset)
+#define V3D_BRIDGE_WRITE(offset, val) writel(val, v3d->bridge_regs + offset)
+
+#define V3D_GCA_READ(offset) readl(v3d->gca_regs + offset)
+#define V3D_GCA_WRITE(offset, val) writel(val, v3d->gca_regs + offset)
+
+#define V3D_CORE_READ(core, offset) readl(v3d->core_regs[core] + offset)
+#define V3D_CORE_WRITE(core, offset, val) writel(val, v3d->core_regs[core] + offset)
+
+struct v3d_job {
+	struct drm_sched_job base;
+
+	struct v3d_exec_info *exec;
+
+	/* An optional fence userspace can pass in for the job to depend on. */
+	struct dma_fence *in_fence;
+
+	/* v3d fence to be signaled by IRQ handler when the job is complete. */
+	struct dma_fence *done_fence;
+
+	/* GPU virtual addresses of the start/end of the CL job. */
+	u32 start, end;
+};
+
+struct v3d_exec_info {
+	struct v3d_dev *v3d;
+
+	struct v3d_job bin, render;
+
+	/* Fence for when the scheduler considers the binner to be
+	 * done, for render to depend on.
+	 */
+	struct dma_fence *bin_done_fence;
+
+	struct kref refcount;
+
+	/* This is the array of BOs that were looked up at the start of exec. */
+	struct v3d_bo **bo;
+	u32 bo_count;
+
+	/* List of overflow BOs used in the job that need to be
+	 * released once the job is complete.
+	 */
+	struct list_head unref_list;
+
+	/* Submitted tile memory allocation start/size, tile state. */
+	u32 qma, qms, qts;
+};
+
+/**
+ * _wait_for - magic (register) wait macro
+ *
+ * Does the right thing for modeset paths when run under kdgb or similar atomic
+ * contexts. Note that it's important that we check the condition again after
+ * having timed out, since the timeout could be due to preemption or similar and
+ * we've never had a chance to check the condition before the timeout.
+ */
+#define wait_for(COND, MS) ({ \
+	unsigned long timeout__ = jiffies + msecs_to_jiffies(MS) + 1;	\
+	int ret__ = 0;							\
+	while (!(COND)) {						\
+		if (time_after(jiffies, timeout__)) {			\
+			if (!(COND))					\
+				ret__ = -ETIMEDOUT;			\
+			break;						\
+		}							\
+		msleep(1);					\
+	}								\
+	ret__;								\
+})
+
+static inline unsigned long nsecs_to_jiffies_timeout(const u64 n)
+{
+	/* nsecs_to_jiffies64() does not guard against overflow */
+	if (NSEC_PER_SEC % HZ &&
+	    div_u64(n, NSEC_PER_SEC) >= MAX_JIFFY_OFFSET / HZ)
+		return MAX_JIFFY_OFFSET;
+
+	return min_t(u64, MAX_JIFFY_OFFSET, nsecs_to_jiffies64(n) + 1);
+}
+
+/* v3d_bo.c */
+void v3d_free_object(struct drm_gem_object *gem_obj);
+struct v3d_bo *v3d_bo_create(struct drm_device *dev, struct drm_file *file_priv,
+			     size_t size);
+int v3d_create_bo_ioctl(struct drm_device *dev, void *data,
+			struct drm_file *file_priv);
+int v3d_mmap_bo_ioctl(struct drm_device *dev, void *data,
+		      struct drm_file *file_priv);
+int v3d_get_bo_offset_ioctl(struct drm_device *dev, void *data,
+			    struct drm_file *file_priv);
+int v3d_gem_fault(struct vm_fault *vmf);
+int v3d_mmap(struct file *filp, struct vm_area_struct *vma);
+struct reservation_object *v3d_prime_res_obj(struct drm_gem_object *obj);
+int v3d_prime_mmap(struct drm_gem_object *obj, struct vm_area_struct *vma);
+struct sg_table *v3d_prime_get_sg_table(struct drm_gem_object *obj);
+struct drm_gem_object *v3d_prime_import_sg_table(struct drm_device *dev,
+						 struct dma_buf_attachment *attach,
+						 struct sg_table *sgt);
+
+/* v3d_debugfs.c */
+int v3d_debugfs_init(struct drm_minor *minor);
+
+/* v3d_fence.c */
+extern const struct dma_fence_ops v3d_fence_ops;
+struct dma_fence *v3d_fence_create(struct v3d_dev *v3d, enum v3d_queue queue);
+
+/* v3d_gem.c */
+int v3d_gem_init(struct drm_device *dev);
+void v3d_gem_destroy(struct drm_device *dev);
+int v3d_submit_cl_ioctl(struct drm_device *dev, void *data,
+			struct drm_file *file_priv);
+int v3d_wait_bo_ioctl(struct drm_device *dev, void *data,
+		      struct drm_file *file_priv);
+void v3d_exec_put(struct v3d_exec_info *exec);
+void v3d_reset(struct v3d_dev *v3d);
+void v3d_invalidate_caches(struct v3d_dev *v3d);
+void v3d_flush_caches(struct v3d_dev *v3d);
+
+/* v3d_irq.c */
+void v3d_irq_init(struct v3d_dev *v3d);
+void v3d_irq_enable(struct v3d_dev *v3d);
+void v3d_irq_disable(struct v3d_dev *v3d);
+void v3d_irq_reset(struct v3d_dev *v3d);
+
+/* v3d_mmu.c */
+int v3d_mmu_get_offset(struct drm_file *file_priv, struct v3d_bo *bo,
+		       u32 *offset);
+int v3d_mmu_set_page_table(struct v3d_dev *v3d);
+void v3d_mmu_insert_ptes(struct v3d_bo *bo);
+void v3d_mmu_remove_ptes(struct v3d_bo *bo);
+
+/* v3d_sched.c */
+int v3d_sched_init(struct v3d_dev *v3d);
+void v3d_sched_fini(struct v3d_dev *v3d);
