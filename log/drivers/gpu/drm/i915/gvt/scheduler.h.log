commit bec3df930fbd40fcc7bcead43a39cfd3c5b0419f
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Fri May 8 11:14:09 2020 +0800

    drm/i915/gvt: Support PPGTT table load command
    
    The PPGTT in context image can be overridden by LRI cmd with another
    PPGTT's pdps. In such case, the load mm is used instead of the one in
    the context image. So we need to load its shadow mm in GVT and replace
    ppgtt pointers in command.
    
    This feature is used by guest IGD driver to share gfx VM between
    different contexts. Verified by IGT "gem_ctx_clone" test.
    
    v4:
    - consolidate shadow mm handlers (Yan)
    - fix cmd shadow mm pin error path
    
    v3: (Zhenyu Wang)
    - Cleanup PDP register offset check
    - Add debug check for guest context ppgtt update
    - Skip 3-level ppgtt guest handling code. The reason is that all
      guests now use 4-level ppgtt table and the only left case for
      3-level table is ancient aliasing ppgtt case. But those guest
      kernel has no use of PPGTT LRI command. So 3-level ppgtt guest
      for this feature becomes simply un-testable.
    
    v2: (Zhenyu Wang)
    - Change to list for handling possible multiple ppgtt table loads
      in one submission. Make sure shadow mm is to replace for each one.
    
    Reviewed-by: Yan Zhao <yan.y.zhao@intel.com>
    Cc: Yan Zhao <yan.y.zhao@intel.com>
    Signed-off-by: Tina Zhang <tina.zhang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20200508031409.2562-1-zhenyuw@linux.intel.com

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index bf7fc0ca4cb1..15d317f2a4a4 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -87,6 +87,7 @@ struct intel_vgpu_workload {
 	int status;
 
 	struct intel_vgpu_mm *shadow_mm;
+	struct list_head lri_shadow_mm; /* For PPGTT load cmd */
 
 	/* different submission model may need different handler */
 	int (*prepare)(struct intel_vgpu_workload *);

commit 8fde41076f6df53db84cb13051efed6482986ce3
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Wed Mar 4 11:23:06 2020 +0800

    drm/i915/gvt: Wean gvt off dev_priv->engine[]
    
    Stop trying to escape out of the gvt layer to find the engine that we
    initially setup for use with gvt. Record the engines during initialisation
    and use them henceforth.
    
    add/remove: 1/4 grow/shrink: 22/28 up/down: 341/-1410 (-1069)
    
    [Zhenyu: rebase, fix nonpriv register check fault, fix gvt engine
    thread run failure.]
    
    Cc: Ding Zhuocheng <zhuocheng.ding@intel.com>
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Acked-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20200304032307.2983-2-zhenyuw@linux.intel.com

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index c50d14a9ce85..bf7fc0ca4cb1 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -79,7 +79,7 @@ struct intel_shadow_wa_ctx {
 
 struct intel_vgpu_workload {
 	struct intel_vgpu *vgpu;
-	int ring_id;
+	const struct intel_engine_cs *engine;
 	struct i915_request *req;
 	/* if this workload has been dispatched to i915? */
 	bool dispatched;
@@ -129,8 +129,8 @@ struct intel_vgpu_shadow_bb {
 	bool ppgtt;
 };
 
-#define workload_q_head(vgpu, ring_id) \
-	(&(vgpu->submission.workload_q_head[ring_id]))
+#define workload_q_head(vgpu, e) \
+	(&(vgpu)->submission.workload_q_head[(e)->id])
 
 void intel_vgpu_queue_workload(struct intel_vgpu_workload *workload);
 
@@ -155,7 +155,8 @@ extern const struct intel_vgpu_submission_ops
 intel_vgpu_execlist_submission_ops;
 
 struct intel_vgpu_workload *
-intel_vgpu_create_workload(struct intel_vgpu *vgpu, int ring_id,
+intel_vgpu_create_workload(struct intel_vgpu *vgpu,
+			   const struct intel_engine_cs *engine,
 			   struct execlist_ctx_descriptor_format *desc);
 
 void intel_vgpu_destroy_workload(struct intel_vgpu_workload *workload);

commit 15e7f52a4596b496ce3da2fa4c1f94c6fb0023f2
Author: Xiaolin Zhang <xiaolin.zhang@intel.com>
Date:   Mon Jun 3 10:55:53 2019 +0800

    drm/i915/gvt: save RING_HEAD into vreg when vgpu switched out
    
    Save RING_HEAD into vgpu reg when vgpu switched out and report
    it's value back to guest.
    
    v6: addressed comment for ring head wrap count support. (Zhenyu)
    v5: ring head wrap count support.
    v4: updated HEAD/TAIL with guest value, not host value. (Yan Zhao)
    v3: save RING HEAD/TAIL vgpu reg in save_ring_hw_state. (Zhenyu Wang)
    v2: save RING_TAIL as well during vgpu mmio switch to meet ring_is_idle
    condition. (Fred Gao)
    v1: based on input from Weinan. (Weinan Li)
    
    [zhenyuw: Include this fix for possible future guest kernel that
    would utilize RING_HEAD for hangcheck.]
    
    Reviewed-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Signed-off-by: Xiaolin Zhang <xiaolin.zhang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 90c6756f5453..c50d14a9ce85 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -100,6 +100,7 @@ struct intel_vgpu_workload {
 	struct execlist_ctx_descriptor_format ctx_desc;
 	struct execlist_ring_context *ring_context;
 	unsigned long rb_head, rb_tail, rb_ctl, rb_start, rb_len;
+	unsigned long guest_rb_head;
 	bool restore_inhibit;
 	struct intel_vgpu_elsp_dwords elsp_dwords;
 	bool emulate_schedule_in;

commit 3a891a62679424e5625a551b9af9c33af6ea59b3
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Mon Apr 1 17:26:39 2019 +0100

    drm/i915: Move intel_engine_mask_t around for use by i915_request_types.h
    
    We want to use intel_engine_mask_t inside i915_request.h, which means
    extracting it from the general header file mess and placing it inside a
    types.h. A knock on effect is that the compiler wants to warn about
    type-contraction of ALL_ENGINES into intel_engine_maskt_t, so prepare
    for the worst.
    
    v2: Use intel_engine_mask_t consistently
    v3: Move I915_NUM_ENGINES to its natural home at the end of the enum
    
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Tvrtko Ursulin <tvrtko.ursulin@intel.com>
    Cc: Mika Kuoppala <mika.kuoppala@linux.intel.com>
    Cc: John Harrison <John.C.Harrison@Intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190401162641.10963-1-chris@chris-wilson.co.uk
    Reviewed-by: Tvrtko Ursulin <tvrtko.ursulin@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 0635b2c4bed7..90c6756f5453 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -142,12 +142,12 @@ void intel_gvt_wait_vgpu_idle(struct intel_vgpu *vgpu);
 int intel_vgpu_setup_submission(struct intel_vgpu *vgpu);
 
 void intel_vgpu_reset_submission(struct intel_vgpu *vgpu,
-				 unsigned long engine_mask);
+				 intel_engine_mask_t engine_mask);
 
 void intel_vgpu_clean_submission(struct intel_vgpu *vgpu);
 
 int intel_vgpu_select_submission_ops(struct intel_vgpu *vgpu,
-				     unsigned long engine_mask,
+				     intel_engine_mask_t engine_mask,
 				     unsigned int interface);
 
 extern const struct intel_vgpu_submission_ops
@@ -160,6 +160,6 @@ intel_vgpu_create_workload(struct intel_vgpu *vgpu, int ring_id,
 void intel_vgpu_destroy_workload(struct intel_vgpu_workload *workload);
 
 void intel_vgpu_clean_workloads(struct intel_vgpu *vgpu,
-				unsigned long engine_mask);
+				intel_engine_mask_t engine_mask);
 
 #endif

commit c06de56121e3ac0f0f1f4a081c041654ffcacd62
Merge: 8d451a4b6e9f a3b22b9f11d9
Author: Dave Airlie <airlied@redhat.com>
Date:   Mon Feb 18 13:27:15 2019 +1000

    Merge v5.0-rc7 into drm-next
    
    Backmerging for nouveau and imx that needed some fixes for next pulls.
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>

commit 2e679d48f38c378650db403b4ba2248adf0691b2
Author: Jani Nikula <jani.nikula@intel.com>
Date:   Mon Jan 21 11:51:41 2019 +0200

    drm/i915/gvt: switch to kernel types
    
    Mixed C99 and kernel types use is getting ugly. Prefer kernel types.
    
    sed -i 's/\buint\(8\|16\|32\|64\)_t\b/u\1/g'
    
    Acked-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Signed-off-by: Jani Nikula <jani.nikula@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index ca5529d0e48e..1e9eec6a32fe 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -61,7 +61,7 @@ struct shadow_indirect_ctx {
 	unsigned long guest_gma;
 	unsigned long shadow_gma;
 	void *shadow_va;
-	uint32_t size;
+	u32 size;
 };
 
 #define PER_CTX_ADDR_MASK 0xfffff000

commit f0e9943725186ddbdc9718a559c26c5f507262f2
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Sat Dec 29 11:13:10 2018 +0800

    drm/i915/gvt: Fix workload request allocation before request add
    
    In commit 6bb2a2af8b1b ("drm/i915/gvt: Fix crash after request->hw_context change"),
    forgot to handle workload scan path in ELSP handler case which was to
    optimize scanning earlier instead of in gvt submission thread, so request
    alloc and add was splitting then which is against right process.
    
    This trys to do a partial revert of that commit which still has workload
    request alloc helper and make sure shadow state population is handled after
    request alloc for target state buffer.
    
    v3: Fix missed workload status setting in request alloc error path
    v2: Fix dispatch workload err path that should add request after alloc anyway.
    
    Fixes: 6bb2a2af8b1b ("drm/i915/gvt: Fix crash after request->hw_context change")
    Cc: Bin Yang <bin.yang@intel.com>
    Cc: Chris Wilson <chris@chris-wilson.co.uk>
    Tested-by: Bin Yang <bin.yang@intel.com>
    Reviewed-by: Xiaolin Zhang <xiaolin.zhang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index ca5529d0e48e..2065cba59aab 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -83,6 +83,7 @@ struct intel_vgpu_workload {
 	struct i915_request *req;
 	/* if this workload has been dispatched to i915? */
 	bool dispatched;
+	bool shadow;      /* if workload has done shadow of guest request */
 	int status;
 
 	struct intel_vgpu_mm *shadow_mm;

commit f9090d4c22130c861b9e00e063812ac69d93a4a2
Author: Hang Yuan <hang.yuan@linux.intel.com>
Date:   Tue Aug 7 18:29:21 2018 +0800

    drm/i915/gvt: free workload in vgpu release
    
    Some workloads may be prepared in vgpu's queue but not be scheduled
    to run yet. If vgpu is released at this time, they will not be freed
    in workload complete callback and so need to be freed in vgpu release
    operation.
    
    Add new vgpu_release operation in gvt_ops to stop vgpu and release
    runtime resources. gvt_ops vgpu_deactivate operation will only stop
    vgpu.
    
    v2: add new gvt ops to clean vgpu running status (Xiong Zhang)
    
    Signed-off-by: Hang Yuan <hang.yuan@linux.intel.com>
    Reviewed-by: Xiong Zhang <xiong.y.zhang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 21eddab4a9cd..ca5529d0e48e 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -158,4 +158,7 @@ intel_vgpu_create_workload(struct intel_vgpu *vgpu, int ring_id,
 
 void intel_vgpu_destroy_workload(struct intel_vgpu_workload *workload);
 
+void intel_vgpu_clean_workloads(struct intel_vgpu *vgpu,
+				unsigned long engine_mask);
+
 #endif

commit 1fc44d9b1afb0afe46acd99bdfdf793805a850e1
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Thu May 17 22:26:32 2018 +0100

    drm/i915: Store a pointer to intel_context in i915_request
    
    To ease the frequent and ugly pointer dance of
    &request->gem_context->engine[request->engine->id] during request
    submission, store that pointer as request->hw_context. One major
    advantage that we will exploit later is that this decouples the logical
    context state from the engine itself.
    
    v2: Set mock_context->ops so we don't crash and burn in selftests.
        Cleanups from Tvrtko.
    
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Tvrtko Ursulin <tvrtko.ursulin@intel.com>
    Acked-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Reviewed-by: Tvrtko Ursulin <tvrtko.ursulin@intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20180517212633.24934-3-chris@chris-wilson.co.uk

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 6c644782193e..21eddab4a9cd 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -83,7 +83,6 @@ struct intel_vgpu_workload {
 	struct i915_request *req;
 	/* if this workload has been dispatched to i915? */
 	bool dispatched;
-	bool shadowed;
 	int status;
 
 	struct intel_vgpu_mm *shadow_mm;

commit 96bebe39b2f4533af14c509061cd2b551ca81e8d
Author: Zhao Yan <yan.y.zhao@intel.com>
Date:   Wed Apr 4 13:57:09 2018 +0800

    drm/i915/gvt: scan non-privileged batch buffer for debug purpose
    
    For perfomance purpose, scanning of non-privileged batch buffer is turned
    off by default. But for debugging purpose, it can be turned on via debugfs.
    After scanning, we submit the original non-privileged batch buffer into
    hardware, so that the scanning is only a peeking window of guest submitted
    commands and will not affect the execution results.
    
    v4:
    - refine debugfs print format&content (zhenyu wang)
    - print engine id instread of engine name to prevent potential memory leak
      in debugfs warning message. (zhenyu wang)
    
    v3:
    - change vgpu->scan_nonprivbb from type bool to u32, so it is able to
      selectively turn on/off scanning of non-privileged batch buffer on engine
      level. e.g.
      if vgpu->scan_nonprivbb=3, then it will scan non-privileged batch buffer
      on engine 0 and 1.
    - in debugfs interface to set vgpu->scan_nonprivbb, print warning message
      to warn user and explicitly tell state change in kernel log (zhenyu wang)
    v2:
    - rebase
    - update comments for start_gma_offset (henry)
    
    Signed-off-by: Zhao Yan <yan.y.zhao@intel.com>
    Reviewed-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 486ed57a4ad1..6c644782193e 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -125,6 +125,7 @@ struct intel_vgpu_shadow_bb {
 	unsigned int clflush;
 	bool accessing;
 	unsigned long bb_offset;
+	bool ppgtt;
 };
 
 #define workload_q_head(vgpu, ring_id) \

commit 2b4f44eec2be2688511c2b617d0e1b4f94c45ba4
Merge: 33d009cd8894 3eb2ce825ea1
Author: Dave Airlie <airlied@redhat.com>
Date:   Wed Mar 28 14:30:41 2018 +1000

    Backmerge tag 'v4.16-rc7' into drm-next
    
    Linux 4.16-rc7
    
    This was requested by Daniel, and things were getting
    a bit hard to reconcile, most of the conflicts were
    trivial though.

commit ef75c685869ea2059f85855a7dc00148a704c36c
Author: fred gao <fred.gao@intel.com>
Date:   Thu Mar 15 13:21:10 2018 +0800

    drm/i915/gvt: Correct the privilege shadow batch buffer address
    
    Once the ring buffer is copied to ring_scan_buffer and scanned,
    the shadow batch buffer start address is only updated into
    ring_scan_buffer, not the real ring address allocated through
    intel_ring_begin in later copy_workload_to_ring_buffer.
    
    This patch is only to set the right shadow batch buffer address
    from Ring buffer, not include the shadow_wa_ctx.
    
    v2:
    - refine some comments. (Zhenyu)
    v3:
    - fix typo in title. (Zhenyu)
    v4:
    - remove the unnecessary comments. (Zhenyu)
    - add comments in bb_start_cmd_va update. (Zhenyu)
    
    Fixes: 0a53bc07f044 ("drm/i915/gvt: Separate cmd scan from request allocation")
    Cc: stable@vger.kernel.org  # v4.15
    Cc: Zhenyu Wang <zhenyuw@linux.intel.com>
    Cc: Yulei Zhang <yulei.zhang@intel.com>
    Signed-off-by: fred gao <fred.gao@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 2603336b7c6d..a79a4f60637e 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -124,6 +124,7 @@ struct intel_vgpu_shadow_bb {
 	u32 *bb_start_cmd_va;
 	unsigned int clflush;
 	bool accessing;
+	unsigned long bb_offset;
 };
 
 #define workload_q_head(vgpu, ring_id) \

commit fa3dd623e559e8e7004179f9594b090318df0d05
Author: Min He <min.he@intel.com>
Date:   Fri Mar 2 10:00:25 2018 +0800

    drm/i915/gvt: keep oa config in shadow ctx
    
    When populating shadow ctx from guest, we should handle oa related
    registers in hw ctx, so that they will not be overlapped by guest oa
    configs. This patch made it possible to capture oa data from host for
    both host and guests.
    
    Signed-off-by: Min He <min.he@intel.com>
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index ff175a98b19e..2603336b7c6d 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -110,6 +110,10 @@ struct intel_vgpu_workload {
 	/* shadow batch buffer */
 	struct list_head shadow_bb;
 	struct intel_shadow_wa_ctx wa_ctx;
+
+	/* oa registers */
+	u32 oactxctrl;
+	u32 flex_mmio[7];
 };
 
 struct intel_vgpu_shadow_bb {

commit bba73071b6f71be0a101658d7c13866e30b264a6
Merge: c71b53cc66c5 f073d78eeb8e
Author: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>
Date:   Thu Mar 1 11:14:24 2018 +0200

    Merge drm-next into drm-intel-next-queued (this time for real)
    
    To pull in the HDCP changes, especially wait_for changes to drm/i915
    that Chris wants to build on top of.
    
    Signed-off-by: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>

commit e61e0f51ba7974bb575cdc23220b573e5cd4ff2a
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Wed Feb 21 09:56:36 2018 +0000

    drm/i915: Rename drm_i915_gem_request to i915_request
    
    We want to de-emphasize the link between the request (dependency,
    execution and fence tracking) from GEM and so rename the struct from
    drm_i915_gem_request to i915_request. That is we may implement the GEM
    user interface on top of requests, but they are an abstraction for
    tracking execution rather than an implementation detail of GEM. (Since
    they are not tied to HW, we keep the i915 prefix as opposed to intel.)
    
    In short, the spatch:
    @@
    
    @@
    - struct drm_i915_gem_request
    + struct i915_request
    
    A corollary to contracting the type name, we also harmonise on using
    'rq' shorthand for local variables where space if of the essence and
    repetition makes 'request' unwieldy. For globals and struct members,
    'request' is still much preferred for its clarity.
    
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>
    Cc: Mika Kuoppala <mika.kuoppala@linux.intel.com>
    Cc: Tvrtko Ursulin <tvrtko.ursulin@intel.com>
    Cc: Michał Winiarski <michal.winiarski@intel.com>
    Cc: Michal Wajdeczko <michal.wajdeczko@intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20180221095636.6649-1-chris@chris-wilson.co.uk
    Reviewed-by: Mika Kuoppala <mika.kuoppala@linux.intel.com>
    Reviewed-by: Michał Winiarski <michal.winiarski@intel.com>
    Acked-by: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 3de77dfa7c59..899831b089d4 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -80,7 +80,7 @@ struct intel_shadow_wa_ctx {
 struct intel_vgpu_workload {
 	struct intel_vgpu *vgpu;
 	int ring_id;
-	struct drm_i915_gem_request *req;
+	struct i915_request *req;
 	/* if this workload has been dispatched to i915? */
 	bool dispatched;
 	bool shadowed;

commit 7569a06dc80ec05c96783f541fa706ea3bebec79
Author: Weinan Li <weinan.z.li@intel.com>
Date:   Fri Jan 26 15:09:07 2018 +0800

    drm/i915/gvt: refine intel_vgpu_submission_ops as per engine ops
    
    Using per engine ops will be more flexible, here refine sub-ops(init,
    clean) as per engine operation align with reset operation. This change also
    will be used in next fix patch for VM engine reset.
    
    Cc: Fred Gao <fred.gao@intel.com>
    Cc: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Weinan Li <weinan.z.li@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Rodrigo Vivi <rodrigo.vivi@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 3de77dfa7c59..ff175a98b19e 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -141,6 +141,7 @@ void intel_vgpu_reset_submission(struct intel_vgpu *vgpu,
 void intel_vgpu_clean_submission(struct intel_vgpu *vgpu);
 
 int intel_vgpu_select_submission_ops(struct intel_vgpu *vgpu,
+				     unsigned long engine_mask,
 				     unsigned int interface);
 
 extern const struct intel_vgpu_submission_ops

commit 59a716c6477c2a095adf274e8f76b9889af7bc7b
Author: Changbin Du <changbin.du@intel.com>
Date:   Wed Nov 29 15:40:06 2017 +0800

    drm/i915/gvt: Convert macro queue_workload to a function
    
    Convert the macro to a function which should always be preferred.
    
    Signed-off-by: Changbin Du <changbin.du@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index e4a9f9acd4a9..3de77dfa7c59 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -125,12 +125,7 @@ struct intel_vgpu_shadow_bb {
 #define workload_q_head(vgpu, ring_id) \
 	(&(vgpu->submission.workload_q_head[ring_id]))
 
-#define queue_workload(workload) do { \
-	list_add_tail(&workload->list, \
-	workload_q_head(workload->vgpu, workload->ring_id)); \
-	wake_up(&workload->vgpu->gvt-> \
-	scheduler.waitq[workload->ring_id]); \
-} while (0)
+void intel_vgpu_queue_workload(struct intel_vgpu_workload *workload);
 
 int intel_gvt_init_workload_scheduler(struct intel_gvt *gvt);
 

commit f52c380a48f527930c86ea6fd7242873c93ba682
Author: Zhi Wang <zhi.wang.linux@gmail.com>
Date:   Sun Sep 24 21:53:03 2017 +0800

    drm/i915/gvt: Refine shadow batch buffer
    
    1) Use standard i915 GEM object sequence to access the shadow batch buffer.
    2) Manage i915 vma life cycle to solve one FIXME.
    
    v2:
    - Refine code structure.
    - Refine the usage of GEM APIs.
    - Add the missing lock/unlock in release_shadow_batch_buffer.
    
    Test on my SKL NuC.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index e0b5730a3018..e4a9f9acd4a9 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -112,13 +112,14 @@ struct intel_vgpu_workload {
 	struct intel_shadow_wa_ctx wa_ctx;
 };
 
-/* Intel shadow batch buffer is a i915 gem object */
-struct intel_shadow_bb_entry {
+struct intel_vgpu_shadow_bb {
 	struct list_head list;
 	struct drm_i915_gem_object *obj;
+	struct i915_vma *vma;
 	void *va;
-	unsigned long len;
 	u32 *bb_start_cmd_va;
+	unsigned int clflush;
+	bool accessing;
 };
 
 #define workload_q_head(vgpu, ring_id) \

commit 06bb372f9ace47296aeaaca8e130d948ea2855cf
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Wed Sep 13 01:41:35 2017 +0800

    drm/i915/gvt: Introduce intel_vgpu_reset_submission
    
    Introduce an generic API to reset vGPU virtual submission interface.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 8652acda6436..e0b5730a3018 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -139,6 +139,9 @@ void intel_gvt_wait_vgpu_idle(struct intel_vgpu *vgpu);
 
 int intel_vgpu_setup_submission(struct intel_vgpu *vgpu);
 
+void intel_vgpu_reset_submission(struct intel_vgpu *vgpu,
+				 unsigned long engine_mask);
+
 void intel_vgpu_clean_submission(struct intel_vgpu *vgpu);
 
 int intel_vgpu_select_submission_ops(struct intel_vgpu *vgpu,

commit ad1d36369b07f6b9db81897802ee5d8764eaa922
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Wed Sep 13 00:31:29 2017 +0800

    drm/i915/gvt: Introduce vGPU submission ops
    
    Introduce vGPU submission ops to support easy switching submission mode
    of one vGPU between different OSes.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 2dc729320a61..8652acda6436 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -141,6 +141,12 @@ int intel_vgpu_setup_submission(struct intel_vgpu *vgpu);
 
 void intel_vgpu_clean_submission(struct intel_vgpu *vgpu);
 
+int intel_vgpu_select_submission_ops(struct intel_vgpu *vgpu,
+				     unsigned int interface);
+
+extern const struct intel_vgpu_submission_ops
+intel_vgpu_execlist_submission_ops;
+
 struct intel_vgpu_workload *
 intel_vgpu_create_workload(struct intel_vgpu *vgpu, int ring_id,
 			   struct execlist_ctx_descriptor_format *desc);

commit d0d51282b88e11a1aa71040b21a9a8cae584a1d4
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Tue Sep 12 22:39:08 2017 +0800

    drm/i915/gvt: Remove one extra declaration in scheduler.h
    
    Now the function has been moved into scheduler.c. The extra declaration
    is not necessary.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 79199693697b..2dc729320a61 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -147,5 +147,4 @@ intel_vgpu_create_workload(struct intel_vgpu *vgpu, int ring_id,
 
 void intel_vgpu_destroy_workload(struct intel_vgpu_workload *workload);
 
-void release_shadow_wa_ctx(struct intel_shadow_wa_ctx *wa_ctx);
 #endif

commit 6d76303553bab75ffc53993c56aad06251d8de60
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Tue Sep 12 22:33:12 2017 +0800

    drm/i915/gvt: Move common vGPU workload creation into scheduler.c
    
    Move common vGPU workload creation functions into scheduler.c since
    they are not specific to execlist emulation.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 3fe4702cda06..79199693697b 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -142,7 +142,8 @@ int intel_vgpu_setup_submission(struct intel_vgpu *vgpu);
 void intel_vgpu_clean_submission(struct intel_vgpu *vgpu);
 
 struct intel_vgpu_workload *
-intel_vgpu_create_workload(struct intel_vgpu *vgpu);
+intel_vgpu_create_workload(struct intel_vgpu *vgpu, int ring_id,
+			   struct execlist_ctx_descriptor_format *desc);
 
 void intel_vgpu_destroy_workload(struct intel_vgpu_workload *workload);
 

commit 21527a8dafc40fc499ae57492c1c5d0098cbcf08
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Tue Sep 12 21:42:09 2017 +0800

    drm/i915/gvt: Factor out vGPU workload creation/destroy
    
    Factor out vGPU workload creation/destroy functions since they are not
    specific to execlist emulation.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 3ca0087f10b2..3fe4702cda06 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -141,5 +141,10 @@ int intel_vgpu_setup_submission(struct intel_vgpu *vgpu);
 
 void intel_vgpu_clean_submission(struct intel_vgpu *vgpu);
 
+struct intel_vgpu_workload *
+intel_vgpu_create_workload(struct intel_vgpu *vgpu);
+
+void intel_vgpu_destroy_workload(struct intel_vgpu_workload *workload);
+
 void release_shadow_wa_ctx(struct intel_shadow_wa_ctx *wa_ctx);
 #endif

commit 1406a14b0ed977fc18f43398b391e4bb5d744174
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Sun Sep 10 21:15:18 2017 +0800

    drm/i915/gvt: Introduce intel_vgpu_submission
    
    Introduce intel_vgpu_submission to hold all members related to submission
    in struct intel_vgpu before.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index c216aefaa73e..3ca0087f10b2 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -122,7 +122,7 @@ struct intel_shadow_bb_entry {
 };
 
 #define workload_q_head(vgpu, ring_id) \
-	(&(vgpu->workload_q_head[ring_id]))
+	(&(vgpu->submission.workload_q_head[ring_id]))
 
 #define queue_workload(workload) do { \
 	list_add_tail(&workload->list, \

commit 874b6a910e6cc094629bd2634d14061cf5eb7690
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Sun Sep 10 20:08:18 2017 +0800

    drm/i915/gvt: Rename intel_vgpu_{init, clean}_gvt_context()
    
    To move workload related functions into scheduler.c, an expected way is
    to collect all the init/clean functions related to vGPU workload
    submission into fewer functions.
    
    Rename intel_vgpu_{init, clean}_gvt_context() for above usage in future.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 2d694f6c0907..c216aefaa73e 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -137,9 +137,9 @@ void intel_gvt_clean_workload_scheduler(struct intel_gvt *gvt);
 
 void intel_gvt_wait_vgpu_idle(struct intel_vgpu *vgpu);
 
-int intel_vgpu_init_gvt_context(struct intel_vgpu *vgpu);
+int intel_vgpu_setup_submission(struct intel_vgpu *vgpu);
 
-void intel_vgpu_clean_gvt_context(struct intel_vgpu *vgpu);
+void intel_vgpu_clean_submission(struct intel_vgpu *vgpu);
 
 void release_shadow_wa_ctx(struct intel_shadow_wa_ctx *wa_ctx);
 #endif

commit 7a88cbd8d65d622c00bd76ba4ae1d893b292c91c
Merge: 0a4334c9e540 0b07194bb55e
Author: Dave Airlie <airlied@redhat.com>
Date:   Thu Nov 2 12:40:41 2017 +1000

    Backmerge tag 'v4.14-rc7' into drm-next
    
    Linux 4.14-rc7
    
    Requested by Ben Skeggs for nouveau to avoid major conflicts,
    and things were getting a bit conflicty already, esp around amdgpu
    reverts.

commit 8f63fc2bc64716c16e269ab951130eeda78fe37a
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Thu Oct 19 13:54:06 2017 +0800

    drm/i915/gvt: properly check per_ctx bb valid state
    
    Need to check valid state for per_ctx bb and bypass batch buffer
    combine for scan if necessary. Otherwise adding invalid MI batch
    buffer start cmd for per_ctx bb will cause scan failure, which is
    taken as -EFAULT now so vGPU would be put in failsafe. This trys
    to fix that by checking per_ctx bb valid state. Also remove old
    invalid WARNING that indirect ctx bb shouldn't depend on valid
    per_ctx bb.
    
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 0d431a968a32..93a49eb0209e 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -68,6 +68,7 @@ struct shadow_indirect_ctx {
 struct shadow_per_ctx {
 	unsigned long guest_gma;
 	unsigned long shadow_gma;
+	unsigned valid;
 };
 
 struct intel_shadow_wa_ctx {

commit a3cfdca920b274618d6046d85a474308ee28e5bb
Author: fred gao <fred.gao@intel.com>
Date:   Fri Aug 18 15:41:07 2017 +0800

    drm/i915/gvt: Add error handling for intel_gvt_scan_and_shadow_workload
    
    When an error occurs after shadow_indirect_ctx, this patch is to do the
    proper cleanup and rollback to the original states for shadowed indirect
    context before the workload is abandoned.
    
    v2:
    - split the mixed several error paths for better review. (Zhenyu)
    
    v3:
    - no return check for clean up functions. (Changbin)
    
    v4:
    - expose and reuse the existing release_shadow_wa_ctx. (Zhenyu)
    
    v5:
    - move the release function to scheduler.c file. (Zhenyu)
    
    v6:
    - move error handling code of intel_gvt_scan_and_shadow_workload
      to here. (Zhenyu)
    
    Signed-off-by: fred gao <fred.gao@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 0d431a968a32..f36b85fd6d01 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -140,4 +140,5 @@ int intel_vgpu_init_gvt_context(struct intel_vgpu *vgpu);
 
 void intel_vgpu_clean_gvt_context(struct intel_vgpu *vgpu);
 
+void release_shadow_wa_ctx(struct intel_shadow_wa_ctx *wa_ctx);
 #endif

commit d0302e74003bf1f0fc41c06948b745204c4704ea
Author: Ping Gao <ping.a.gao@intel.com>
Date:   Thu Jun 29 12:22:43 2017 +0800

    drm/i915/gvt: Audit and shadow workload during ELSP writing
    
    Let the workload audit and shadow ahead of vGPU scheduling, that
    will eliminate GPU idle time and improve performance for multi-VM.
    
    The performance of Heaven running simultaneously in 3VMs has
    improved 20% after this patch.
    
    v2:Remove condition current->vgpu==vgpu when shadow during ELSP
    writing.
    
    Signed-off-by: Ping Gao <ping.a.gao@intel.com>
    Reviewed-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 9b6bf51e9b9b..0d431a968a32 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -82,6 +82,7 @@ struct intel_vgpu_workload {
 	struct drm_i915_gem_request *req;
 	/* if this workload has been dispatched to i915? */
 	bool dispatched;
+	bool shadowed;
 	int status;
 
 	struct intel_vgpu_mm *shadow_mm;

commit 0e86cc9ccc3bf557348befaddf5cb613cf3c4458
Author: Changbin Du <changbin.du@intel.com>
Date:   Thu May 4 10:52:38 2017 +0800

    drm/i915/gvt: implement per-vm mmio switching optimization
    
    Commit ab9da627906a ("drm/i915: make context status notifier head be
    per engine") gives us a chance to inspect every single request. Then
    we can eliminate unnecessary mmio switching for same vGPU. We only
    need mmio switching for different VMs (including host).
    
    This patch introduced a new general API intel_gvt_switch_mmio() to
    replace the old intel_gvt_load/restore_render_mmio(). This function
    can be further optimized for vGPU to vGPU switching.
    
    To support individual ring switch, we track the owner who occupy
    each ring. When another VM or host request a ring we do the mmio
    context switching. Otherwise no need to switch the ring.
    
    This optimization is very useful if only one guest has plenty of
    workloads and the host is mostly idle. The best case is no mmio
    switching will happen.
    
    v2:
      o fix missing ring switch issue. (chuanxiao)
      o support individual ring switch.
    
    Signed-off-by: Changbin Du <changbin.du@intel.com>
    Reviewed-by: Chuanxiao Dong <chuanxiao.dong@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 2cd725c0573e..9b6bf51e9b9b 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -42,6 +42,10 @@ struct intel_gvt_workload_scheduler {
 	struct intel_vgpu_workload *current_workload[I915_NUM_ENGINES];
 	bool need_reschedule;
 
+	spinlock_t mmio_context_lock;
+	/* can be null when owner is host */
+	struct intel_vgpu *engine_owner[I915_NUM_ENGINES];
+
 	wait_queue_head_t workload_complete_wq;
 	struct task_struct *thread[I915_NUM_ENGINES];
 	wait_queue_head_t waitq[I915_NUM_ENGINES];

commit c10c12558c8bb375798b7643c762dbcc93db081a
Author: Tina Zhang <tina.zhang@intel.com>
Date:   Fri Mar 17 03:08:51 2017 -0400

    drm/i915/gvt: remove workload from intel_shadow_wa_ctx structure
    
    intel_shadow_wa_ctx is a field of intel_vgpu_workload. container_of() can
    be used to refine the relation-ship between intel_shadow_wa_ctx and
    intel_vgpu_workload. This patch removes the useless dereference.
    
    v2. add "drm/i915/gvt" prefix. (Zhenyu)
    
    Signed-off-by: Tina Zhang <tina.zhang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 2833dfa8c9ae..2cd725c0573e 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -67,7 +67,6 @@ struct shadow_per_ctx {
 };
 
 struct intel_shadow_wa_ctx {
-	struct intel_vgpu_workload *workload;
 	struct shadow_indirect_ctx indirect_ctx;
 	struct shadow_per_ctx per_ctx;
 

commit 62f0a11e2339e1ba154600d1f49ef5d5d84eaae4
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Fri Jan 6 19:58:16 2017 +0000

    drm/i915/gvt: Fix relocation of shadow bb
    
    set_gma_to_bb_cmd() is completely bogus - it is (incorrectly) applying
    the rules to read a GTT offset from a command as opposed to writing the
    GTT offset. And to cap it all set_gma_to_bb_cmd() is called within a list
    iterator of the most strange construction.
    
    Fixes: be1da7070aea ("drm/i915/gvt: vGPU command scanner")
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Zhenyu Wang <zhenyuw@linux.intel.com>
    Cc: Zhi Wang <zhi.a.wang@intel.com>
    Cc: Yulei Zhang <yulei.zhang@intel.com>
    Cc: <drm-intel-fixes@lists.freedesktop.org> # v4.10-rc1+
    Tested-by: Tina Zhang <tina.zhang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 3b30c28bff51..2833dfa8c9ae 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -113,7 +113,7 @@ struct intel_shadow_bb_entry {
 	struct drm_i915_gem_object *obj;
 	void *va;
 	unsigned long len;
-	void *bb_start_cmd_va;
+	u32 *bb_start_cmd_va;
 };
 
 #define workload_q_head(vgpu, ring_id) \

commit be1da7070aeaee23ff659c1a8cd992789ff86da4
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Tue May 3 18:26:57 2016 -0400

    drm/i915/gvt: vGPU command scanner
    
    This patch introduces a command scanner to scan guest command buffers.
    
    Signed-off-by: Yulei Zhang <yulei.zhang@intel.com>
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 2500438d7aa7..3b30c28bff51 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -50,6 +50,29 @@ struct intel_gvt_workload_scheduler {
 	struct intel_gvt_sched_policy_ops *sched_ops;
 };
 
+#define INDIRECT_CTX_ADDR_MASK 0xffffffc0
+#define INDIRECT_CTX_SIZE_MASK 0x3f
+struct shadow_indirect_ctx {
+	struct drm_i915_gem_object *obj;
+	unsigned long guest_gma;
+	unsigned long shadow_gma;
+	void *shadow_va;
+	uint32_t size;
+};
+
+#define PER_CTX_ADDR_MASK 0xfffff000
+struct shadow_per_ctx {
+	unsigned long guest_gma;
+	unsigned long shadow_gma;
+};
+
+struct intel_shadow_wa_ctx {
+	struct intel_vgpu_workload *workload;
+	struct shadow_indirect_ctx indirect_ctx;
+	struct shadow_per_ctx per_ctx;
+
+};
+
 struct intel_vgpu_workload {
 	struct intel_vgpu *vgpu;
 	int ring_id;
@@ -65,16 +88,32 @@ struct intel_vgpu_workload {
 	int (*complete)(struct intel_vgpu_workload *);
 	struct list_head list;
 
+	DECLARE_BITMAP(pending_events, INTEL_GVT_EVENT_MAX);
+	void *shadow_ring_buffer_va;
+
 	/* execlist context information */
 	struct execlist_ctx_descriptor_format ctx_desc;
 	struct execlist_ring_context *ring_context;
-	unsigned long rb_head, rb_tail, rb_ctl, rb_start;
+	unsigned long rb_head, rb_tail, rb_ctl, rb_start, rb_len;
 	bool restore_inhibit;
 	struct intel_vgpu_elsp_dwords elsp_dwords;
 	bool emulate_schedule_in;
 	atomic_t shadow_ctx_active;
 	wait_queue_head_t shadow_ctx_status_wq;
 	u64 ring_context_gpa;
+
+	/* shadow batch buffer */
+	struct list_head shadow_bb;
+	struct intel_shadow_wa_ctx wa_ctx;
+};
+
+/* Intel shadow batch buffer is a i915 gem object */
+struct intel_shadow_bb_entry {
+	struct list_head list;
+	struct drm_i915_gem_object *obj;
+	void *va;
+	unsigned long len;
+	void *bb_start_cmd_va;
 };
 
 #define workload_q_head(vgpu, ring_id) \

commit 4b63960ebd3f4c41caca6a8dca68751b34e61e9b
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Sun May 1 17:09:58 2016 -0400

    drm/i915/gvt: vGPU schedule policy framework
    
    This patch introduces a vGPU schedule policy framework, with a timer based
    schedule policy module for now
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 9206cc02c8a8..2500438d7aa7 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -45,6 +45,9 @@ struct intel_gvt_workload_scheduler {
 	wait_queue_head_t workload_complete_wq;
 	struct task_struct *thread[I915_NUM_ENGINES];
 	wait_queue_head_t waitq[I915_NUM_ENGINES];
+
+	void *sched_data;
+	struct intel_gvt_sched_policy_ops *sched_ops;
 };
 
 struct intel_vgpu_workload {

commit e473405783c064a9d859d108010581bae8e9af40
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Sun May 1 07:42:16 2016 -0400

    drm/i915/gvt: vGPU workload scheduler
    
    This patch introduces the vGPU workload scheduler routines.
    
    GVT workload scheduler is responsible for picking and executing GVT workload
    from current scheduled vGPU. Before the workload is submitted to host i915,
    the guest execlist context will be shadowed in the host GVT shadow context.
    the instructions in guest ring buffer will be copied into GVT shadow ring
    buffer. Then GVT-g workload scheduler will scan the instructions in guest
    ring buffer and submit it to host i915.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
index 8884749f0bd4..9206cc02c8a8 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.h
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -19,13 +19,32 @@
  * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
  * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
  * SOFTWARE.
+ *
+ * Authors:
+ *    Zhi Wang <zhi.a.wang@intel.com>
+ *
+ * Contributors:
+ *    Ping Gao <ping.a.gao@intel.com>
+ *    Tina Zhang <tina.zhang@intel.com>
+ *    Chanbin Du <changbin.du@intel.com>
+ *    Min He <min.he@intel.com>
+ *    Bing Niu <bing.niu@intel.com>
+ *    Zhenyu Wang <zhenyuw@linux.intel.com>
+ *
  */
 
 #ifndef _GVT_SCHEDULER_H_
 #define _GVT_SCHEDULER_H_
 
 struct intel_gvt_workload_scheduler {
-	struct list_head workload_q_head[I915_NUM_ENGINES];
+	struct intel_vgpu *current_vgpu;
+	struct intel_vgpu *next_vgpu;
+	struct intel_vgpu_workload *current_workload[I915_NUM_ENGINES];
+	bool need_reschedule;
+
+	wait_queue_head_t workload_complete_wq;
+	struct task_struct *thread[I915_NUM_ENGINES];
+	wait_queue_head_t waitq[I915_NUM_ENGINES];
 };
 
 struct intel_vgpu_workload {
@@ -47,6 +66,7 @@ struct intel_vgpu_workload {
 	struct execlist_ctx_descriptor_format ctx_desc;
 	struct execlist_ring_context *ring_context;
 	unsigned long rb_head, rb_tail, rb_ctl, rb_start;
+	bool restore_inhibit;
 	struct intel_vgpu_elsp_dwords elsp_dwords;
 	bool emulate_schedule_in;
 	atomic_t shadow_ctx_active;
@@ -57,8 +77,21 @@ struct intel_vgpu_workload {
 #define workload_q_head(vgpu, ring_id) \
 	(&(vgpu->workload_q_head[ring_id]))
 
-#define queue_workload(workload) \
+#define queue_workload(workload) do { \
 	list_add_tail(&workload->list, \
-	workload_q_head(workload->vgpu, workload->ring_id))
+	workload_q_head(workload->vgpu, workload->ring_id)); \
+	wake_up(&workload->vgpu->gvt-> \
+	scheduler.waitq[workload->ring_id]); \
+} while (0)
+
+int intel_gvt_init_workload_scheduler(struct intel_gvt *gvt);
+
+void intel_gvt_clean_workload_scheduler(struct intel_gvt *gvt);
+
+void intel_gvt_wait_vgpu_idle(struct intel_vgpu *vgpu);
+
+int intel_vgpu_init_gvt_context(struct intel_vgpu *vgpu);
+
+void intel_vgpu_clean_gvt_context(struct intel_vgpu *vgpu);
 
 #endif

commit 28c4c6ca7f794b2d5ac8773d43311e95f6518415
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Sun May 1 05:22:47 2016 -0400

    drm/i915/gvt: vGPU workload submission
    
    This patch introduces the vGPU workload submission logics.
    
    Under virtualization environment, guest will submit workload through
    virtual execlist submit port. The submitted workload load will be wrapped
    into an gvt workload which will be picked by GVT workload scheduler and
    executed on host i915 later.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.h b/drivers/gpu/drm/i915/gvt/scheduler.h
new file mode 100644
index 000000000000..8884749f0bd4
--- /dev/null
+++ b/drivers/gpu/drm/i915/gvt/scheduler.h
@@ -0,0 +1,64 @@
+/*
+ * Copyright(c) 2011-2016 Intel Corporation. All rights reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _GVT_SCHEDULER_H_
+#define _GVT_SCHEDULER_H_
+
+struct intel_gvt_workload_scheduler {
+	struct list_head workload_q_head[I915_NUM_ENGINES];
+};
+
+struct intel_vgpu_workload {
+	struct intel_vgpu *vgpu;
+	int ring_id;
+	struct drm_i915_gem_request *req;
+	/* if this workload has been dispatched to i915? */
+	bool dispatched;
+	int status;
+
+	struct intel_vgpu_mm *shadow_mm;
+
+	/* different submission model may need different handler */
+	int (*prepare)(struct intel_vgpu_workload *);
+	int (*complete)(struct intel_vgpu_workload *);
+	struct list_head list;
+
+	/* execlist context information */
+	struct execlist_ctx_descriptor_format ctx_desc;
+	struct execlist_ring_context *ring_context;
+	unsigned long rb_head, rb_tail, rb_ctl, rb_start;
+	struct intel_vgpu_elsp_dwords elsp_dwords;
+	bool emulate_schedule_in;
+	atomic_t shadow_ctx_active;
+	wait_queue_head_t shadow_ctx_status_wq;
+	u64 ring_context_gpa;
+};
+
+#define workload_q_head(vgpu, ring_id) \
+	(&(vgpu->workload_q_head[ring_id]))
+
+#define queue_workload(workload) \
+	list_add_tail(&workload->list, \
+	workload_q_head(workload->vgpu, workload->ring_id))
+
+#endif
