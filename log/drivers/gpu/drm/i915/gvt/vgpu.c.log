commit cb7ee52284a244fd14caec73df0d49e02891aac4
Author: Aishwarya Ramakrishnan <aishwaryarj100@gmail.com>
Date:   Mon May 18 20:33:36 2020 +0530

    drm/i915/gvt: Use ARRAY_SIZE for vgpu_types
    
    Prefer ARRAY_SIZE instead of using sizeof
    
    Fixes coccicheck warning: Use ARRAY_SIZE
    
    Reviewed-by: Chris Wilson <chris@chris-wilson.co.uk>
    Signed-off-by: Aishwarya Ramakrishnan <aishwaryarj100@gmail.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20200518150336.15265-1-aishwaryarj100@gmail.com

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 1d5ff88078bd..7d361623ff67 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -124,7 +124,7 @@ int intel_gvt_init_vgpu_types(struct intel_gvt *gvt)
 	 */
 	low_avail = gvt_aperture_sz(gvt) - HOST_LOW_GM_SIZE;
 	high_avail = gvt_hidden_sz(gvt) - HOST_HIGH_GM_SIZE;
-	num_types = sizeof(vgpu_types) / sizeof(vgpu_types[0]);
+	num_types = ARRAY_SIZE(vgpu_types);
 
 	gvt->types = kcalloc(num_types, sizeof(struct intel_vgpu_type),
 			     GFP_KERNEL);

commit 5fc0df93fccd4dc8412bfc488ba4ba8268aa12dc
Merge: 700d6ab987f3 7111951b8d49
Author: Dave Airlie <airlied@redhat.com>
Date:   Tue Mar 31 15:15:47 2020 +1000

    Merge v5.6 into drm-next
    
    msm needed rc6, so I just went and merged release
    (msm has been in drm-next outside of this tree)
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>

commit 9001b17698d86f842e2b13e0cafe8021d43209e9
Merge: bda1fb0ed000 217a485c8399
Author: Dave Airlie <airlied@redhat.com>
Date:   Thu Mar 19 10:39:27 2020 +1000

    Merge tag 'drm-intel-next-2020-03-13' of git://anongit.freedesktop.org/drm/drm-intel into drm-next
    
    UAPI Changes:
    
    On i915 we have a new UAPI to allow userspace to specify CS ring buffer size on
    construction (I915_CONTEXT_PARAM_RINGSIZE) and also new sysfs entries exposing
    various engine properties
    
    GVT Changes:
    
    VFIO edid getting expanded to all platforms and a big cleanup around attr
    group, unused vblank complete, kvmgt, Intel engine and dev_priv usages.
    
    i915 Changes:
    
    - new UAPI to allow userspace to specify CS ring buffer size on construction
      (I915_CONTEXT_PARAM_RINGSIZE) -  (Chris)
    - New sysfs entries exposing various engine properties (Chris)
    - Tiger Lake is out of require_force_probe protection (Jose)
    - Changes in many places around active requests, reset and heartbeat (Chris)
    - Stop assigning drm-dev_private pointer (Jani)
    - Many code refactor in many places, including intel_modeset_init,
      increasing use of intel_uncore_*, vgpu, and gvt stuff (Jani)
    - Fixes around display pipe iterators (Anshuman)
    - Tigerlake enabling work (Matt Ropper, Matt Atwood, Ville, Lucas, Daniele,
      Jose, Anusha, Vivek, Swathi, Caz. Kai)
    - Code clean-up like reducing use of drm/i915_drv.h, removing unused
      registers, removing garbage warns, and some other code polishing (Jani, Lucas,
      Ville)
    - Selftests fixes, improvements and additions (Chris, Dan, Aditya, Matt Auld)
    - Fix plane possible_crtcs bit mask (Anshuman)
    - Fixes and cleanup on GLK pre production identification and w/a (Ville)
    - Fix display orientation on few cases (Hans, Ville)
    - dbuf clean-up and improvements for slice arrays handling (Ville)
    - Improvement around min cdclk calculation (Stanislav)
    - Fixes and refactor around display PLLs (Imre)
    - Other execlists and perf fixes (Chris)
    - Documentation fixes (Jani, Chris)
    - Fix build issue (Anshuman)
    - Many more fixes around the locking mechanisms (Chris)
    - Other fixes and debugability info around preemption (Chris, Tvrtko)
    - Add mechanism to submit a context WA on ring submission (Mika)
    - Clear all Eu/L3 resitual context (Prathap)
    - More changes around local memory (Abdiel, Matt, Chris)
    - Fix RPS (Chris)
    - DP MST fix (Lyude)
    - Display FBC fixes (Jose, RK)
    - debugfs cleanup (Tvrtko)
    - More convertion towards drm_debive based loggin (Wambui, Ram)
    - Avoid potential buffer overflow (Takashi)
    - Ice Lake and Elkhart Lake workarounds (Matt Roper)
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    
    From: Rodrigo Vivi <rodrigo.vivi@intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20200314001535.GA2969344@intel.com

commit a61ac1e75105a077ec1efd6923ae3c619f862304
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Fri Mar 6 10:08:10 2020 +0800

    drm/i915/gvt: Wean gvt off using dev_priv
    
    Teach gvt to use intel_gt directly as it currently assumes direct HW
    access.
    
    [Zhenyu: rebase, fix compiling]
    
    Cc: Ding Zhuocheng <zhuocheng.ding@intel.com>
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Acked-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20200304032307.2983-3-zhenyuw@linux.intel.com

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index e31c00b6d7e9..abcde8ce1a9a 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -37,7 +37,7 @@
 
 void populate_pvinfo_page(struct intel_vgpu *vgpu)
 {
-	struct drm_i915_private *i915 = vgpu->gvt->dev_priv;
+	struct drm_i915_private *i915 = vgpu->gvt->gt->i915;
 	/* setup the ballooning information */
 	vgpu_vreg64_t(vgpu, vgtif_reg(magic)) = VGT_MAGIC;
 	vgpu_vreg_t(vgpu, vgtif_reg(version_major)) = 1;
@@ -149,12 +149,12 @@ int intel_gvt_init_vgpu_types(struct intel_gvt *gvt)
 		gvt->types[i].avail_instance = min(low_avail / vgpu_types[i].low_mm,
 						   high_avail / vgpu_types[i].high_mm);
 
-		if (IS_GEN(gvt->dev_priv, 8))
+		if (IS_GEN(gvt->gt->i915, 8))
 			sprintf(gvt->types[i].name, "GVTg_V4_%s",
-						vgpu_types[i].name);
-		else if (IS_GEN(gvt->dev_priv, 9))
+				vgpu_types[i].name);
+		else if (IS_GEN(gvt->gt->i915, 9))
 			sprintf(gvt->types[i].name, "GVTg_V5_%s",
-						vgpu_types[i].name);
+				vgpu_types[i].name);
 
 		gvt_dbg_core("type[%d]: %s avail %u low %u high %u fence %u weight %u res %s\n",
 			     i, gvt->types[i].name,
@@ -271,8 +271,8 @@ void intel_gvt_release_vgpu(struct intel_vgpu *vgpu)
  */
 void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 {
-	struct drm_i915_private *i915 = vgpu->gvt->dev_priv;
 	struct intel_gvt *gvt = vgpu->gvt;
+	struct drm_i915_private *i915 = gvt->gt->i915;
 
 	mutex_lock(&vgpu->vgpu_lock);
 

commit 04d6067f1f19e70a418f92fa3170cf7fe53b7fdf
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Tue Mar 3 13:54:12 2020 +0800

    drm/i915/gvt: Fix unnecessary schedule timer when no vGPU exits
    
    From commit f25a49ab8ab9 ("drm/i915/gvt: Use vgpu_lock to protect per
    vgpu access") the vgpu idr destroy is moved later than vgpu resource
    destroy, then it would fail to stop timer for schedule policy clean
    which to check vgpu idr for any left vGPU. So this trys to destroy
    vgpu idr earlier.
    
    Cc: Colin Xu <colin.xu@intel.com>
    Fixes: f25a49ab8ab9 ("drm/i915/gvt: Use vgpu_lock to protect per vgpu access")
    Acked-by: Colin Xu <colin.xu@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20200229055445.31481-1-zhenyuw@linux.intel.com

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 487af6ea9972..345c2aa3b491 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -272,10 +272,17 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 {
 	struct intel_gvt *gvt = vgpu->gvt;
 
-	mutex_lock(&vgpu->vgpu_lock);
-
 	WARN(vgpu->active, "vGPU is still active!\n");
 
+	/*
+	 * remove idr first so later clean can judge if need to stop
+	 * service if no active vgpu.
+	 */
+	mutex_lock(&gvt->lock);
+	idr_remove(&gvt->vgpu_idr, vgpu->id);
+	mutex_unlock(&gvt->lock);
+
+	mutex_lock(&vgpu->vgpu_lock);
 	intel_gvt_debugfs_remove_vgpu(vgpu);
 	intel_vgpu_clean_sched_policy(vgpu);
 	intel_vgpu_clean_submission(vgpu);
@@ -290,7 +297,6 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 	mutex_unlock(&vgpu->vgpu_lock);
 
 	mutex_lock(&gvt->lock);
-	idr_remove(&gvt->vgpu_idr, vgpu->id);
 	if (idr_is_empty(&gvt->vgpu_idr))
 		intel_gvt_clean_irq(gvt);
 	intel_gvt_update_vgpu_types(gvt);

commit 12d5861973c70fb9a890d81d051de1cb1886eeee
Author: Pankaj Bharadiya <pankaj.laxminarayan.bharadiya@intel.com>
Date:   Thu Feb 20 22:25:07 2020 +0530

    drm/i915/gvt: Make WARN* drm specific where vgpu ptr is available
    
    Drm specific drm_WARN* calls include device information in the
    backtrace, so we know what device the warnings originate from.
    
    Covert all the calls of WARN* with device specific drm_WARN*
    variants in functions where drm_device struct pointer is readily
    available.
    
    The conversion was done automatically with below coccinelle semantic
    patch. checkpatch errors/warnings are fixed manually.
    
    @@
    identifier func, T;
    @@
    func(struct intel_vgpu *T,...) {
    +struct drm_i915_private *i915 = T->gvt->dev_priv;
    <+...
    (
    -WARN(
    +drm_WARN(&i915->drm,
    ...)
    |
    -WARN_ON(
    +drm_WARN_ON(&i915->drm,
    ...)
    |
    -WARN_ONCE(
    +drm_WARN_ONCE(&i915->drm,
    ...)
    |
    -WARN_ON_ONCE(
    +drm_WARN_ON_ONCE(&i915->drm,
    ...)
    )
    ...+>
    
    }
    
    Signed-off-by: Pankaj Bharadiya <pankaj.laxminarayan.bharadiya@intel.com>
    Acked-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20200220165507.16823-9-pankaj.laxminarayan.bharadiya@intel.com

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 1e0865905136..e31c00b6d7e9 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -37,6 +37,7 @@
 
 void populate_pvinfo_page(struct intel_vgpu *vgpu)
 {
+	struct drm_i915_private *i915 = vgpu->gvt->dev_priv;
 	/* setup the ballooning information */
 	vgpu_vreg64_t(vgpu, vgtif_reg(magic)) = VGT_MAGIC;
 	vgpu_vreg_t(vgpu, vgtif_reg(version_major)) = 1;
@@ -69,7 +70,7 @@ void populate_pvinfo_page(struct intel_vgpu *vgpu)
 		vgpu_hidden_gmadr_base(vgpu), vgpu_hidden_sz(vgpu));
 	gvt_dbg_core("fence size %d\n", vgpu_fence_sz(vgpu));
 
-	WARN_ON(sizeof(struct vgt_if) != VGT_PVINFO_SIZE);
+	drm_WARN_ON(&i915->drm, sizeof(struct vgt_if) != VGT_PVINFO_SIZE);
 }
 
 #define VGPU_MAX_WEIGHT 16
@@ -270,11 +271,12 @@ void intel_gvt_release_vgpu(struct intel_vgpu *vgpu)
  */
 void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 {
+	struct drm_i915_private *i915 = vgpu->gvt->dev_priv;
 	struct intel_gvt *gvt = vgpu->gvt;
 
 	mutex_lock(&vgpu->vgpu_lock);
 
-	WARN(vgpu->active, "vGPU is still active!\n");
+	drm_WARN(&i915->drm, vgpu->active, "vGPU is still active!\n");
 
 	intel_gvt_debugfs_remove_vgpu(vgpu);
 	intel_vgpu_clean_sched_policy(vgpu);

commit 3eb55e6f753a379e293395de8d5f3be28351a7f8
Author: Tina Zhang <tina.zhang@intel.com>
Date:   Fri Feb 21 10:32:34 2020 +0800

    drm/i915/gvt: Separate display reset from ALL_ENGINES reset
    
    ALL_ENGINES reset doesn't clobber display with the current gvt-g
    supported platforms. Thus ALL_ENGINES reset shouldn't reset the
    display engine registers emulated by gvt-g.
    
    This fixes guest warning like
    
    [ 14.622026] [drm] Initialized i915 1.6.0 20200114 for 0000:00:03.0 on minor 0
    [ 14.967917] fbcon: i915drmfb (fb0) is primary device
    [ 25.100188] [drm:drm_atomic_helper_wait_for_dependencies [drm_kms_helper]] E RROR [CRTC:51:pipe A] flip_done timed out
    [ 25.100860] -----------[ cut here ]-----------
    [ 25.100861] pll on state mismatch (expected 0, found 1)
    [ 25.101024] WARNING: CPU: 1 PID: 30 at drivers/gpu/drm/i915/display/intel_dis play.c:14382 verify_single_dpll_state.isra.115+0x28f/0x320 [i915]
    [ 25.101025] Modules linked in: intel_rapl_msr intel_rapl_common kvm_intel kvm irqbypass crct10dif_pclmul crc32_pclmul ghash_clmulni_intel i915 aesni_intel cr ypto_simd cryptd glue_helper cec rc_core video drm_kms_helper joydev drm input_l eds i2c_algo_bit serio_raw fb_sys_fops syscopyarea sysfillrect sysimgblt mac_hid qemu_fw_cfg sch_fq_codel parport_pc ppdev lp parport ip_tables x_tables autofs4 e1000 psmouse i2c_piix4 pata_acpi floppy
    [ 25.101052] CPU: 1 PID: 30 Comm: kworker/u4:1 Not tainted 5.5.0+ #1
    [ 25.101053] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1 .12.1-0-ga5cab58 04/01/2014
    [ 25.101055] Workqueue: events_unbound async_run_entry_fn
    [ 25.101092] RIP: 0010:verify_single_dpll_state.isra.115+0x28f/0x320 [i915]
    [ 25.101093] Code: e0 d9 ff e9 a3 fe ff ff 80 3d e9 c2 11 00 00 44 89 f6 48 c7 c7 c0 9d 88 c0 75 3b e8 eb df d9 ff e9 c7 fe ff ff e8 d1 e0 ae c4 <0f> 0b e9 7a fe ff ff 80 3d c0 c2 11 00 00 8d 71 41 89 c2 48 c7 c7
    [ 25.101093] RSP: 0018:ffffb1de80107878 EFLAGS: 00010286
    [ 25.101094] RAX: 0000000000000000 RBX: ffffb1de80107884 RCX: 0000000000000007
    [ 25.101095] RDX: 0000000000000000 RSI: 0000000000000002 RDI: ffff94fdfdd19740
    [ 25.101095] RBP: ffffb1de80107938 R08: 0000000d6bfdc7b4 R09: 000000000000002b
    [ 25.101096] R10: ffff94fdf82dc000 R11: 0000000000000225 R12: 00000000000001f8
    [ 25.101096] R13: ffff94fdb3ca6a90 R14: ffff94fdb3ca0000 R15: 0000000000000000
    [ 25.101097] FS: 0000000000000000(0000) GS:ffff94fdfdd00000(0000) knlGS:00000 00000000000
    [ 25.101098] CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 25.101098] CR2: 00007fbc3e2be9c8 CR3: 000000003339a003 CR4: 0000000000360ee0
    [ 25.101101] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 25.101101] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 25.101102] Call Trace:
    [ 25.101139] intel_atomic_commit_tail+0xde4/0x1520 [i915]
    [ 25.101141] ? flush_workqueue_prep_pwqs+0xfa/0x130
    [ 25.101142] ? flush_workqueue+0x198/0x3c0
    [ 25.101174] intel_atomic_commit+0x2ad/0x320 [i915]
    [ 25.101209] drm_atomic_commit+0x4a/0x50 [drm]
    [ 25.101220] drm_client_modeset_commit_atomic+0x1c4/0x200 [drm]
    [ 25.101231] drm_client_modeset_commit_force+0x47/0x170 [drm]
    [ 25.101250] drm_fb_helper_restore_fbdev_mode_unlocked+0x4e/0xa0 [drm_kms_hel per]
    [ 25.101255] drm_fb_helper_set_par+0x2d/0x60 [drm_kms_helper]
    [ 25.101287] intel_fbdev_set_par+0x1a/0x40 [i915]
    [ 25.101289] ? con_is_visible+0x2e/0x60
    [ 25.101290] fbcon_init+0x378/0x600
    [ 25.101292] visual_init+0xd5/0x130
    [ 25.101296] do_bind_con_driver+0x217/0x430
    [ 25.101297] do_take_over_console+0x7d/0x1b0
    [ 25.101298] do_fbcon_takeover+0x5c/0xb0
    [ 25.101299] fbcon_fb_registered+0x199/0x1a0
    [ 25.101301] register_framebuffer+0x22c/0x330
    [ 25.101306] __drm_fb_helper_initial_config_and_unlock+0x31a/0x520 [drm_kms_h elper]
    [ 25.101311] drm_fb_helper_initial_config+0x35/0x40 [drm_kms_helper]
    [ 25.101341] intel_fbdev_initial_config+0x18/0x30 [i915]
    [ 25.101342] async_run_entry_fn+0x3c/0x150
    [ 25.101343] process_one_work+0x1fd/0x3f0
    [ 25.101344] worker_thread+0x34/0x410
    [ 25.101346] kthread+0x121/0x140
    [ 25.101346] ? process_one_work+0x3f0/0x3f0
    [ 25.101347] ? kthread_park+0x90/0x90
    [ 25.101350] ret_from_fork+0x35/0x40
    [ 25.101351] --[ end trace b5b47d44cd998ba1 ]--
    
    Fixes: 6294b61ba769 ("drm/i915/gvt: add missing display part reset for vGPU reset")
    Signed-off-by: Tina Zhang <tina.zhang@intel.com>
    Reviewed-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20200221023234.28635-1-tina.zhang@intel.com

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 85bd9bf4f6ee..487af6ea9972 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -560,9 +560,9 @@ void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
 
 		intel_vgpu_reset_mmio(vgpu, dmlr);
 		populate_pvinfo_page(vgpu);
-		intel_vgpu_reset_display(vgpu);
 
 		if (dmlr) {
+			intel_vgpu_reset_display(vgpu);
 			intel_vgpu_reset_cfg_space(vgpu);
 			/* only reset the failsafe mode when dmlr reset */
 			vgpu->failsafe = false;

commit c95baf12f5077419db01313ab61c2aac007d40cd
Merge: 690c3df85f10 e24bcd34c1dd
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Thu Feb 20 16:23:37 2020 +0800

    Merge drm-intel-next-queued into gvt-next
    
    Backmerge to pull in
    https://patchwork.freedesktop.org/patch/353621/?series=73544&rev=1
    
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

commit 0178f4ce3c3be4d9784c88ed512816eb653a717b
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Mon Dec 2 15:01:09 2019 +0800

    drm/i915/gvt: Enable vfio edid for all GVT supported platform
    
    All GVT supported platform has virtual display which should be
    able to handle VFIO edid region. Enable this for all supported platform.
    
    Cc: Hang Yuan <hang.yuan@linux.intel.com>
    Cc: Fred Gao <fred.gao@intel.com>
    Reviewed-by: Hang Yuan <hang.yuan@linux.intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20191202070109.73924-3-zhenyuw@linux.intel.com

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index d5a6e4e3d0fd..79107e630049 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -426,9 +426,7 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_clean_sched_policy;
 
-	/*TODO: add more platforms support */
-	if (IS_SKYLAKE(gvt->dev_priv) || IS_KABYLAKE(gvt->dev_priv))
-		ret = intel_gvt_hypervisor_set_edid(vgpu, PORT_D);
+	ret = intel_gvt_hypervisor_set_edid(vgpu, PORT_D);
 	if (ret)
 		goto out_clean_sched_policy;
 

commit 6d44694dc7c72e82e0f45d114a9c9e3f3e2aeab7
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Mon Dec 2 15:01:08 2019 +0800

    drm/i915/gvt: use vgpu lock for active state setting
    
    Need to align with deactivate, should only use vgpu's lock for
    active state setting instead of gvt lock.
    
    Fixes: f25a49ab8ab9 ("drm/i915/gvt: Use vgpu_lock to protect per vgpu access")
    Cc: Colin Xu <colin.xu@intel.com>
    Reviewed-by: Colin Xu <colin.xu@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20191202070109.73924-2-zhenyuw@linux.intel.com

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index d5a6e4e3d0fd..85bd9bf4f6ee 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -212,9 +212,9 @@ static void intel_gvt_update_vgpu_types(struct intel_gvt *gvt)
  */
 void intel_gvt_activate_vgpu(struct intel_vgpu *vgpu)
 {
-	mutex_lock(&vgpu->gvt->lock);
+	mutex_lock(&vgpu->vgpu_lock);
 	vgpu->active = true;
-	mutex_unlock(&vgpu->gvt->lock);
+	mutex_unlock(&vgpu->vgpu_lock);
 }
 
 /**

commit f8871ec8fc73f57295703a8d61c8c33d7ab4805b
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Thu Jun 13 15:34:19 2019 +0200

    drm/i915/gvt: no need to check return value of debugfs_create functions
    
    When calling debugfs functions, there is no need to ever check the
    return value.  The function can work or not, but the code logic should
    never do something different based on this.
    
    Because there is no need to check these functions, a number of local
    functions can be made to return void to simplify things as nothing can
    fail.
    
    Cc: Zhenyu Wang <zhenyuw@linux.intel.com>
    Cc: Zhi Wang <zhi.a.wang@intel.com>
    Cc: Jani Nikula <jani.nikula@linux.intel.com>
    Cc: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>
    Cc: Rodrigo Vivi <rodrigo.vivi@intel.com>
    Cc: David Airlie <airlied@linux.ie>
    Cc: Daniel Vetter <daniel@ffwll.ch>
    Cc: intel-gvt-dev@lists.freedesktop.org
    Cc: intel-gfx@lists.freedesktop.org
    Cc: dri-devel@lists.freedesktop.org
    Reviewed-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 44ce3c2b9ac1..d5a6e4e3d0fd 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -420,9 +420,7 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_clean_submission;
 
-	ret = intel_gvt_debugfs_add_vgpu(vgpu);
-	if (ret)
-		goto out_clean_sched_policy;
+	intel_gvt_debugfs_add_vgpu(vgpu);
 
 	ret = intel_gvt_hypervisor_set_opregion(vgpu);
 	if (ret)

commit 3a891a62679424e5625a551b9af9c33af6ea59b3
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Mon Apr 1 17:26:39 2019 +0100

    drm/i915: Move intel_engine_mask_t around for use by i915_request_types.h
    
    We want to use intel_engine_mask_t inside i915_request.h, which means
    extracting it from the general header file mess and placing it inside a
    types.h. A knock on effect is that the compiler wants to warn about
    type-contraction of ALL_ENGINES into intel_engine_maskt_t, so prepare
    for the worst.
    
    v2: Use intel_engine_mask_t consistently
    v3: Move I915_NUM_ENGINES to its natural home at the end of the enum
    
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Tvrtko Ursulin <tvrtko.ursulin@intel.com>
    Cc: Mika Kuoppala <mika.kuoppala@linux.intel.com>
    Cc: John Harrison <John.C.Harrison@Intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190401162641.10963-1-chris@chris-wilson.co.uk
    Reviewed-by: Tvrtko Ursulin <tvrtko.ursulin@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 314e40121e47..44ce3c2b9ac1 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -526,11 +526,11 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
  * GPU engines. For FLR, engine_mask is ignored.
  */
 void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
-				 unsigned int engine_mask)
+				 intel_engine_mask_t engine_mask)
 {
 	struct intel_gvt *gvt = vgpu->gvt;
 	struct intel_gvt_workload_scheduler *scheduler = &gvt->scheduler;
-	unsigned int resetting_eng = dmlr ? ALL_ENGINES : engine_mask;
+	intel_engine_mask_t resetting_eng = dmlr ? ALL_ENGINES : engine_mask;
 
 	gvt_dbg_core("------------------------------------------\n");
 	gvt_dbg_core("resseting vgpu%d, dmlr %d, engine_mask %08x\n",

commit ca6ac684de5d8091cca4b4eb78c54610101a0033
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Thu Mar 14 22:38:35 2019 +0000

    drm/i915: Mark up vGPU support for full-ppgtt
    
    For compatibility reasons, we only care if the vGPU host provides
    support for full-ppgtt. This is independent of the addressable memory
    size, so remove the conflation of 48b from the capability name.
    
    Based on a patch by Bob Paauwe.
    
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Bob Paauwe <bob.j.paauwe@intel.com>
    Cc: Zhenyu Wang <zhenyuw@linux.intel.com>
    Cc: Zhi Wang <zhi.a.wang@intel.com>
    Reviewed-by: Rodrigo Vivi <rodrigo.vivi@intel.com>
    Reviewed-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190314223839.28258-1-chris@chris-wilson.co.uk

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 720e2b10adaa..314e40121e47 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -44,7 +44,7 @@ void populate_pvinfo_page(struct intel_vgpu *vgpu)
 	vgpu_vreg_t(vgpu, vgtif_reg(display_ready)) = 0;
 	vgpu_vreg_t(vgpu, vgtif_reg(vgt_id)) = vgpu->id;
 
-	vgpu_vreg_t(vgpu, vgtif_reg(vgt_caps)) = VGT_CAPS_FULL_48BIT_PPGTT;
+	vgpu_vreg_t(vgpu, vgtif_reg(vgt_caps)) = VGT_CAPS_FULL_PPGTT;
 	vgpu_vreg_t(vgpu, vgtif_reg(vgt_caps)) |= VGT_CAPS_HWSP_EMULATION;
 	vgpu_vreg_t(vgpu, vgtif_reg(vgt_caps)) |= VGT_CAPS_HUGE_GTT;
 

commit 1b4fd5d38c633344bca57c1dd874c49474c94462
Merge: 7360c9f6b857 39c68e87bc50
Author: Rodrigo Vivi <rodrigo.vivi@intel.com>
Date:   Fri Feb 1 09:03:23 2019 -0800

    Merge tag 'gvt-next-2019-02-01' of https://github.com/intel/gvt-linux into drm-intel-next-queued
    
    gvt-next-2019-02-01
    
    - new VFIO EDID region support (Henry)
    
    Signed-off-by: Rodrigo Vivi <rodrigo.vivi@intel.com>
    From: Zhenyu Wang <zhenyuw@linux.intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190201061523.GE5588@zhen-hp.sh.intel.com

commit 39c68e87bc50a71bcfe93582d9b0673ef30db418
Author: Hang Yuan <hang.yuan@linux.intel.com>
Date:   Wed Jan 30 18:25:54 2019 +0800

    drm/i915/gvt: add VFIO EDID region
    
    Implement VFIO EDID region for vgpu. Support EDID blob update and notify
    guest on link state change via hotplug event.
    
    v3: move struct edid_region to kvmgt.c <zhenyu>
    v2: add EDID sanity check and size update <zhenyu>
    
    Tested-by: Gerd Hoffmann <kraxel@redhat.com>
    Reviewed-by: Gerd Hoffmann <kraxel@redhat.com>
    Signed-off-by: Hang Yuan <hang.yuan@linux.intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index c628be05fbfe..39682b065a71 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -428,6 +428,12 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_clean_sched_policy;
 
+	/*TODO: add more platforms support */
+	if (IS_SKYLAKE(gvt->dev_priv) || IS_KABYLAKE(gvt->dev_priv))
+		ret = intel_gvt_hypervisor_set_edid(vgpu, PORT_D);
+	if (ret)
+		goto out_clean_sched_policy;
+
 	return vgpu;
 
 out_clean_sched_policy:

commit cf819eff907ab49205ece97c96baeb909fd36f4d
Author: Lucas De Marchi <lucas.demarchi@intel.com>
Date:   Wed Dec 12 10:10:43 2018 -0800

    drm/i915: replace IS_GEN<N> with IS_GEN(..., N)
    
    Define IS_GEN() similarly to our IS_GEN_RANGE(). but use gen instead of
    gen_mask to do the comparison. Now callers can pass then gen as a parameter,
    so we don't require one macro for each gen.
    
    The following spatch was used to convert the users of these macros:
    
    @@
    expression e;
    @@
    (
    - IS_GEN2(e)
    + IS_GEN(e, 2)
    |
    - IS_GEN3(e)
    + IS_GEN(e, 3)
    |
    - IS_GEN4(e)
    + IS_GEN(e, 4)
    |
    - IS_GEN5(e)
    + IS_GEN(e, 5)
    |
    - IS_GEN6(e)
    + IS_GEN(e, 6)
    |
    - IS_GEN7(e)
    + IS_GEN(e, 7)
    |
    - IS_GEN8(e)
    + IS_GEN(e, 8)
    |
    - IS_GEN9(e)
    + IS_GEN(e, 9)
    |
    - IS_GEN10(e)
    + IS_GEN(e, 10)
    |
    - IS_GEN11(e)
    + IS_GEN(e, 11)
    )
    
    v2: use IS_GEN rather than GT_GEN and compare to info.gen rather than
        using the bitmask
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@intel.com>
    Reviewed-by: Jani Nikula <jani.nikula@intel.com>
    Signed-off-by: Rodrigo Vivi <rodrigo.vivi@intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20181212181044.15886-2-lucas.demarchi@intel.com

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index c628be05fbfe..e1c860f80eb0 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -148,10 +148,10 @@ int intel_gvt_init_vgpu_types(struct intel_gvt *gvt)
 		gvt->types[i].avail_instance = min(low_avail / vgpu_types[i].low_mm,
 						   high_avail / vgpu_types[i].high_mm);
 
-		if (IS_GEN8(gvt->dev_priv))
+		if (IS_GEN(gvt->dev_priv, 8))
 			sprintf(gvt->types[i].name, "GVTg_V4_%s",
 						vgpu_types[i].name);
-		else if (IS_GEN9(gvt->dev_priv))
+		else if (IS_GEN(gvt->dev_priv, 9))
 			sprintf(gvt->types[i].name, "GVTg_V5_%s",
 						vgpu_types[i].name);
 

commit 7759ca3aac79648d01c9edcb3b00503c02bec2f5
Author: Zhipeng Gong <zhipeng.gong@intel.com>
Date:   Mon Sep 17 15:45:08 2018 +0800

    drm/i915/gvt: clear ggtt entries when destroy vgpu
    
    When one vgpu is destroyed, its ggtt entries are not cleared.
    This patch clears ggtt entries to avoid information leak.
    
    v2: add 'Fixes' tag (Zhenyu)
    
    Fixes: 2707e4446688 ("drm/i915/gvt: vGPU graphics memory virtualization")
    Signed-off-by: Zhipeng Gong <zhipeng.gong@intel.com>
    Reviewed-by: Hang Yuan <hang.yuan@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index a4e8e3cf74fd..c628be05fbfe 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -281,6 +281,7 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 	intel_vgpu_clean_submission(vgpu);
 	intel_vgpu_clean_display(vgpu);
 	intel_vgpu_clean_opregion(vgpu);
+	intel_vgpu_reset_ggtt(vgpu, true);
 	intel_vgpu_clean_gtt(vgpu);
 	intel_gvt_hypervisor_detach_vgpu(vgpu);
 	intel_vgpu_free_resource(vgpu);

commit d6c6113bfe19af514128163a6d176437d45b7325
Author: Hang Yuan <hang.yuan@linux.intel.com>
Date:   Mon Jul 30 10:52:53 2018 +0800

    drm/i915/gvt: initialize dmabuf mutex in vgpu_create
    
    Currently, the mutex used in GVT dmabuf support is not initialized until
    vgpu device is opened. If one vgpu device is opened and then removed, the
    mutex will be used in vgpu remove operation without initialization. This
    patch initializes the mutex in vgpu create operation to avoid the problem.
    
    Fixes: e546e281d33d("drm/i915/gvt: Dmabuf support for GVT-g")
    Signed-off-by: Hang Yuan <hang.yuan@linux.intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index ce0d93bf67fb..a4e8e3cf74fd 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -379,6 +379,7 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	vgpu->gvt = gvt;
 	vgpu->sched_ctl.weight = param->weight;
 	mutex_init(&vgpu->vgpu_lock);
+	mutex_init(&vgpu->dmabuf_lock);
 	INIT_LIST_HEAD(&vgpu->dmabuf_obj_list_head);
 	INIT_RADIX_TREE(&vgpu->page_track_tree, GFP_KERNEL);
 	idr_init(&vgpu->object_idr);

commit f9090d4c22130c861b9e00e063812ac69d93a4a2
Author: Hang Yuan <hang.yuan@linux.intel.com>
Date:   Tue Aug 7 18:29:21 2018 +0800

    drm/i915/gvt: free workload in vgpu release
    
    Some workloads may be prepared in vgpu's queue but not be scheduled
    to run yet. If vgpu is released at this time, they will not be freed
    in workload complete callback and so need to be freed in vgpu release
    operation.
    
    Add new vgpu_release operation in gvt_ops to stop vgpu and release
    runtime resources. gvt_ops vgpu_deactivate operation will only stop
    vgpu.
    
    v2: add new gvt ops to clean vgpu running status (Xiong Zhang)
    
    Signed-off-by: Hang Yuan <hang.yuan@linux.intel.com>
    Reviewed-by: Xiong Zhang <xiong.y.zhang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index f6fa916517c3..ce0d93bf67fb 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -222,7 +222,7 @@ void intel_gvt_activate_vgpu(struct intel_vgpu *vgpu)
  * @vgpu: virtual GPU
  *
  * This function is called when user wants to deactivate a virtual GPU.
- * All virtual GPU runtime information will be destroyed.
+ * The virtual GPU will be stopped.
  *
  */
 void intel_gvt_deactivate_vgpu(struct intel_vgpu *vgpu)
@@ -238,11 +238,29 @@ void intel_gvt_deactivate_vgpu(struct intel_vgpu *vgpu)
 	}
 
 	intel_vgpu_stop_schedule(vgpu);
-	intel_vgpu_dmabuf_cleanup(vgpu);
 
 	mutex_unlock(&vgpu->vgpu_lock);
 }
 
+/**
+ * intel_gvt_release_vgpu - release a virtual GPU
+ * @vgpu: virtual GPU
+ *
+ * This function is called when user wants to release a virtual GPU.
+ * The virtual GPU will be stopped and all runtime information will be
+ * destroyed.
+ *
+ */
+void intel_gvt_release_vgpu(struct intel_vgpu *vgpu)
+{
+	intel_gvt_deactivate_vgpu(vgpu);
+
+	mutex_lock(&vgpu->vgpu_lock);
+	intel_vgpu_clean_workloads(vgpu, ALL_ENGINES);
+	intel_vgpu_dmabuf_cleanup(vgpu);
+	mutex_unlock(&vgpu->vgpu_lock);
+}
+
 /**
  * intel_gvt_destroy_vgpu - destroy a virtual GPU
  * @vgpu: virtual GPU

commit ef8e0ff97ae8168ffe1558a5726a8b348c8228a3
Merge: 294f96ae8aa5 ef821e3f14e8
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri Jul 20 12:29:23 2018 +1000

    Merge tag 'drm-intel-next-2018-07-19' of git://anongit.freedesktop.org/drm/drm-intel into drm-next
    
    On GEM side:
    
    - GuC related fixes (Chris, Michal)
    - GTT read-only pages support (Jon, Chris)
    - More selftests fixes (Chris)
    - More GPU reset improvements (Chris)
    - Flush caches after GGTT writes (Chris)
    - Handle recursive shrinker for vma->last_active allocation (Chris)
    - Other execlists fixes (Chris)
    
    On Display side:
    
    - GLK HDMI fix (Clint)
    - Rework and cleanup around HPD pin (Ville)
    - Preparation work for Display Stream Compression support coming on ICL (Anusha)
    - Nuke LVDS lid notification (Ville)
    - Assume eDP is always connected (Ville)
    - Kill intel panel detection (Ville)
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    
    # gpg: Signature made Fri 20 Jul 2018 01:51:45 AM AEST
    # gpg:                using RSA key FA625F640EEB13CA
    # gpg: Good signature from "Rodrigo Vivi <rodrigo.vivi@intel.com>"
    # gpg:                 aka "Rodrigo Vivi <rodrigo.vivi@gmail.com>"
    # gpg: WARNING: This key is not certified with a trusted signature!
    # gpg:          There is no indication that the signature belongs to the owner.
    # Primary key fingerprint: 6D20 7068 EEDD 6509 1C2C  E2A3 FA62 5F64 0EEB 13CA
    
    # Conflicts:
    #       drivers/gpu/drm/i915/intel_lrc.c
    Link: https://patchwork.freedesktop.org/patch/msgid/20180719171257.GA12199@intel.com

commit aa36ed6d9536ad694995340264b69d57b01da7d3
Author: Changbin Du <changbin.du@intel.com>
Date:   Tue May 15 10:35:46 2018 +0800

    drm/i915: Enable platform support for vGPU huge gtt pages
    
    Now GVTg supports shadowing both 2M/64K huge gtt pages. So let's turn on
    the cap info bit VGT_CAPS_HUGE_GTT.
    
    v2: Split changes in i915 side into a separated patch.
    
    Signed-off-by: Changbin Du <changbin.du@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 889d10f8ee96..aa063b275e81 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -46,6 +46,7 @@ void populate_pvinfo_page(struct intel_vgpu *vgpu)
 
 	vgpu_vreg_t(vgpu, vgtif_reg(vgt_caps)) = VGT_CAPS_FULL_48BIT_PPGTT;
 	vgpu_vreg_t(vgpu, vgtif_reg(vgt_caps)) |= VGT_CAPS_HWSP_EMULATION;
+	vgpu_vreg_t(vgpu, vgtif_reg(vgt_caps)) |= VGT_CAPS_HUGE_GTT;
 
 	vgpu_vreg_t(vgpu, vgtif_reg(avail_rs.mappable_gmadr.base)) =
 		vgpu_aperture_gmadr_base(vgpu);

commit b4d4b0b7defbc226cc2237e08ced62c1c806e301
Merge: 3c8daa7db46d e1cacec9d50d
Author: Dave Airlie <airlied@redhat.com>
Date:   Thu Jun 28 13:10:37 2018 +1000

    Merge tag 'drm-intel-next-2018-06-20' of git://anongit.freedesktop.org/drm/drm-intel into drm-next
    
    Chris is doing many reworks that allow us to get full-ppgtt supported
    on all platforms back to HSW. As well many other fix and improvements,
    Including:
    - Use GEM suspend when aborting initialization (Chris)
    - Change i915_gem_fault to return vm_fault_t (Chris)
    - Expand VMA to Non gem object entities (Chris)
    - Improve logs for load failure, but quite logging on fault injection to avoid noise on CI (Chris)
    - Other page directory handling fixes and improvements for gen6 (Chris)
    - Other gtt clean-up removing redundancies and unused checks (Chris)
    - Reorder aliasing ppgtt fini (Chris)
    - Refactor of unsetting obg->mm.pages (Chris)
    - Apply batch location restrictions before pinning (Chris)
    - Ringbuffer fixes for context restore (Chris)
    - Execlist fixes on freeing error pointer on allocation error (Chris)
    - Make closing request flush mandatory (Chris)
    - Move GEM sanitize from resume_early to resume (Chris)
    - Improve debug dumps (Chris)
    - Silent compiler for selftest (Chris)
    - Other execlists changes to improve hangcheck and reset.
    - Many gtt page directory fixes and improvements (Chris)
    - Reorg context workarounds (Chris)
    - Avoid ERR_PTR dereference on selftest (Chris)
    
    Other GEM related work:
    - Stop trying to reset GPU if reset failed (Mika)
    - Add HW workaround for KBL to fix GPU reset (Mika)
    - Fix context ban and hang accounting for client (Mika)
    - Fixes on OA perf (Michel, Jani)
    - Refactor on GuC log mechanisms (Piotr)
    - Enable provoking vertex fix on Gen9 system (Kenneth)
    
    More ICL patches for Display enabling:
    - ICL - 10-bit support for HDMI (RK)
    - ICL - Start adding TBT PLL (Paulo)
    - ICL - DDI HDMK level selection (Manasi)
    - ICL - GMBUS GPIO pin mapping fix (Mahesh)
    - ICL - Adding DP_AUX_E support (James)
    - ICL - Display interrupts handling (DK)
    
    Other display fixes and improvements:
    - Fix sprite destination color keying on SKL+ (Ville)
    - Fixes and improvements on PCH detection, specially for non PCH systems (Jani)
    - Document PCH_NOP (Lucas)
    - Allow DBLSCAN user modes with eDP/LVDS/DSI (Ville)
    - Opregion and ACPI cleanup and organization (Jani)
    - Kill delays when activation psr (Rodrigo)
    - ...and a consequent fix of the psr activation flow (DK)
    - Fix HDMI infoframe setting (Imre)
    - Fix Display interrupts and modes on old gens (Ville)
    - Start switching to kernel unsigned int types (Jani)
    - Introduction to Amber Lake and Whiskey Lake platforms (Jose)
    - Audio clock fixes for HBR3 (RK)
    - Standardize i915_reg.h definitions according to our doc and checkpatch (Paulo)
    - Remove unused timespec_to_jiffies_timeout function (Arnd)
    - Increase the scope of PSR wake fix for other VBTs out there (Vathsala)
    - Improve debug msgs with prop name/id (Ville)
    - Other clean up on unecessary cursor size defines (Ville)
    - Enforce max hdisplay/hblank_start limits on HSW/BDW (Ville)
    - Make ELD pointers constant (Jani)
    - Fix for PSR VBT parse (Colin)
    - Add warn about unsupported CDCLK rates (Imre)
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    
    # gpg: Signature made Thu 21 Jun 2018 07:12:10 AM AEST
    # gpg:                using RSA key FA625F640EEB13CA
    # gpg: Good signature from "Rodrigo Vivi <rodrigo.vivi@intel.com>"
    # gpg:                 aka "Rodrigo Vivi <rodrigo.vivi@gmail.com>"
    # gpg: WARNING: This key is not certified with a trusted signature!
    # gpg:          There is no indication that the signature belongs to the owner.
    # Primary key fingerprint: 6D20 7068 EEDD 6509 1C2C  E2A3 FA62 5F64 0EEB 13CA
    Link: https://patchwork.freedesktop.org/patch/msgid/20180625165622.GA21761@intel.com

commit 6396bb221514d2876fd6dc0aa2a1f240d99b37bb
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jun 12 14:03:40 2018 -0700

    treewide: kzalloc() -> kcalloc()
    
    The kzalloc() function has a 2-factor argument form, kcalloc(). This
    patch replaces cases of:
    
            kzalloc(a * b, gfp)
    
    with:
            kcalloc(a * b, gfp)
    
    as well as handling cases of:
    
            kzalloc(a * b * c, gfp)
    
    with:
    
            kzalloc(array3_size(a, b, c), gfp)
    
    as it's slightly less ugly than:
    
            kzalloc_array(array_size(a, b), c, gfp)
    
    This does, however, attempt to ignore constant size factors like:
    
            kzalloc(4 * 1024, gfp)
    
    though any constants defined via macros get caught up in the conversion.
    
    Any factors with a sizeof() of "unsigned char", "char", and "u8" were
    dropped, since they're redundant.
    
    The Coccinelle script used for this was:
    
    // Fix redundant parens around sizeof().
    @@
    type TYPE;
    expression THING, E;
    @@
    
    (
      kzalloc(
    -       (sizeof(TYPE)) * E
    +       sizeof(TYPE) * E
      , ...)
    |
      kzalloc(
    -       (sizeof(THING)) * E
    +       sizeof(THING) * E
      , ...)
    )
    
    // Drop single-byte sizes and redundant parens.
    @@
    expression COUNT;
    typedef u8;
    typedef __u8;
    @@
    
    (
      kzalloc(
    -       sizeof(u8) * (COUNT)
    +       COUNT
      , ...)
    |
      kzalloc(
    -       sizeof(__u8) * (COUNT)
    +       COUNT
      , ...)
    |
      kzalloc(
    -       sizeof(char) * (COUNT)
    +       COUNT
      , ...)
    |
      kzalloc(
    -       sizeof(unsigned char) * (COUNT)
    +       COUNT
      , ...)
    |
      kzalloc(
    -       sizeof(u8) * COUNT
    +       COUNT
      , ...)
    |
      kzalloc(
    -       sizeof(__u8) * COUNT
    +       COUNT
      , ...)
    |
      kzalloc(
    -       sizeof(char) * COUNT
    +       COUNT
      , ...)
    |
      kzalloc(
    -       sizeof(unsigned char) * COUNT
    +       COUNT
      , ...)
    )
    
    // 2-factor product with sizeof(type/expression) and identifier or constant.
    @@
    type TYPE;
    expression THING;
    identifier COUNT_ID;
    constant COUNT_CONST;
    @@
    
    (
    - kzalloc
    + kcalloc
      (
    -       sizeof(TYPE) * (COUNT_ID)
    +       COUNT_ID, sizeof(TYPE)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(TYPE) * COUNT_ID
    +       COUNT_ID, sizeof(TYPE)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(TYPE) * (COUNT_CONST)
    +       COUNT_CONST, sizeof(TYPE)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(TYPE) * COUNT_CONST
    +       COUNT_CONST, sizeof(TYPE)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(THING) * (COUNT_ID)
    +       COUNT_ID, sizeof(THING)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(THING) * COUNT_ID
    +       COUNT_ID, sizeof(THING)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(THING) * (COUNT_CONST)
    +       COUNT_CONST, sizeof(THING)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(THING) * COUNT_CONST
    +       COUNT_CONST, sizeof(THING)
      , ...)
    )
    
    // 2-factor product, only identifiers.
    @@
    identifier SIZE, COUNT;
    @@
    
    - kzalloc
    + kcalloc
      (
    -       SIZE * COUNT
    +       COUNT, SIZE
      , ...)
    
    // 3-factor product with 1 sizeof(type) or sizeof(expression), with
    // redundant parens removed.
    @@
    expression THING;
    identifier STRIDE, COUNT;
    type TYPE;
    @@
    
    (
      kzalloc(
    -       sizeof(TYPE) * (COUNT) * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      kzalloc(
    -       sizeof(TYPE) * (COUNT) * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      kzalloc(
    -       sizeof(TYPE) * COUNT * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      kzalloc(
    -       sizeof(TYPE) * COUNT * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(TYPE))
      , ...)
    |
      kzalloc(
    -       sizeof(THING) * (COUNT) * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      kzalloc(
    -       sizeof(THING) * (COUNT) * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      kzalloc(
    -       sizeof(THING) * COUNT * (STRIDE)
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    |
      kzalloc(
    -       sizeof(THING) * COUNT * STRIDE
    +       array3_size(COUNT, STRIDE, sizeof(THING))
      , ...)
    )
    
    // 3-factor product with 2 sizeof(variable), with redundant parens removed.
    @@
    expression THING1, THING2;
    identifier COUNT;
    type TYPE1, TYPE2;
    @@
    
    (
      kzalloc(
    -       sizeof(TYPE1) * sizeof(TYPE2) * COUNT
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(TYPE2))
      , ...)
    |
      kzalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(TYPE2))
      , ...)
    |
      kzalloc(
    -       sizeof(THING1) * sizeof(THING2) * COUNT
    +       array3_size(COUNT, sizeof(THING1), sizeof(THING2))
      , ...)
    |
      kzalloc(
    -       sizeof(THING1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(THING1), sizeof(THING2))
      , ...)
    |
      kzalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * COUNT
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(THING2))
      , ...)
    |
      kzalloc(
    -       sizeof(TYPE1) * sizeof(THING2) * (COUNT)
    +       array3_size(COUNT, sizeof(TYPE1), sizeof(THING2))
      , ...)
    )
    
    // 3-factor product, only identifiers, with redundant parens removed.
    @@
    identifier STRIDE, SIZE, COUNT;
    @@
    
    (
      kzalloc(
    -       (COUNT) * STRIDE * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kzalloc(
    -       COUNT * (STRIDE) * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kzalloc(
    -       COUNT * STRIDE * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kzalloc(
    -       (COUNT) * (STRIDE) * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kzalloc(
    -       COUNT * (STRIDE) * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kzalloc(
    -       (COUNT) * STRIDE * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kzalloc(
    -       (COUNT) * (STRIDE) * (SIZE)
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    |
      kzalloc(
    -       COUNT * STRIDE * SIZE
    +       array3_size(COUNT, STRIDE, SIZE)
      , ...)
    )
    
    // Any remaining multi-factor products, first at least 3-factor products,
    // when they're not all constants...
    @@
    expression E1, E2, E3;
    constant C1, C2, C3;
    @@
    
    (
      kzalloc(C1 * C2 * C3, ...)
    |
      kzalloc(
    -       (E1) * E2 * E3
    +       array3_size(E1, E2, E3)
      , ...)
    |
      kzalloc(
    -       (E1) * (E2) * E3
    +       array3_size(E1, E2, E3)
      , ...)
    |
      kzalloc(
    -       (E1) * (E2) * (E3)
    +       array3_size(E1, E2, E3)
      , ...)
    |
      kzalloc(
    -       E1 * E2 * E3
    +       array3_size(E1, E2, E3)
      , ...)
    )
    
    // And then all remaining 2 factors products when they're not all constants,
    // keeping sizeof() as the second factor argument.
    @@
    expression THING, E1, E2;
    type TYPE;
    constant C1, C2, C3;
    @@
    
    (
      kzalloc(sizeof(THING) * C2, ...)
    |
      kzalloc(sizeof(TYPE) * C2, ...)
    |
      kzalloc(C1 * C2 * C3, ...)
    |
      kzalloc(C1 * C2, ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(TYPE) * (E2)
    +       E2, sizeof(TYPE)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(TYPE) * E2
    +       E2, sizeof(TYPE)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(THING) * (E2)
    +       E2, sizeof(THING)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       sizeof(THING) * E2
    +       E2, sizeof(THING)
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       (E1) * E2
    +       E1, E2
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       (E1) * (E2)
    +       E1, E2
      , ...)
    |
    - kzalloc
    + kcalloc
      (
    -       E1 * E2
    +       E1, E2
      , ...)
    )
    
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 2e0a02a80fe4..572a18c2bfb5 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -121,7 +121,7 @@ int intel_gvt_init_vgpu_types(struct intel_gvt *gvt)
 	high_avail = gvt_hidden_sz(gvt) - HOST_HIGH_GM_SIZE;
 	num_types = sizeof(vgpu_types) / sizeof(vgpu_types[0]);
 
-	gvt->types = kzalloc(num_types * sizeof(struct intel_vgpu_type),
+	gvt->types = kcalloc(num_types, sizeof(struct intel_vgpu_type),
 			     GFP_KERNEL);
 	if (!gvt->types)
 		return -ENOMEM;

commit f25a49ab8ab9c1b5587837c8a386b276403f315c
Author: Colin Xu <colin.xu@intel.com>
Date:   Sat May 19 12:28:54 2018 +0800

    drm/i915/gvt: Use vgpu_lock to protect per vgpu access
    
    The patch set splits out 2 small locks from the original big gvt lock:
      - vgpu_lock protects per-vGPU data and logic, especially the vGPU
        trap emulation path.
      - sched_lock protects gvt scheudler structure, context schedule logic
        and vGPU's schedule data.
    
    Use vgpu_lock to replace the gvt big lock. By doing this, the
    mmio read/write trap path, vgpu virtual event emulation and other
    vgpu related process, would be protected under per vgpu_lock.
    
    v9:
      - Change commit author since the patches are improved a lot compared
        with original version.
        Original author: Pei Zhang <pei.zhang@intel.com>
      - Rebase to latest gvt-staging.
    v8:
      - Correct coding and comment style.
      - Rebase to latest gvt-staging.
    v7:
      - Remove gtt_lock since already proteced by gvt_lock and vgpu_lock.
      - Fix a typo in intel_gvt_deactivate_vgpu, unlock the wrong lock.
    v6:
      - Rebase to latest gvt-staging.
    v5:
      - Rebase to latest gvt-staging.
      - intel_vgpu_page_track_handler should use vgpu_lock.
    v4:
      - Rebase to latest gvt-staging.
      - Protect vgpu->active access with vgpu_lock.
      - Do not wait gpu idle in vgpu_lock.
    v3: update to latest code base
    v2: add gvt->lock in function gvt_check_vblank_emulation
    
    Performance comparison on Kabylake platform.
      - Configuration:
        Host: Ubuntu 16.04.
        Guest 1 & 2: Ubuntu 16.04.
    
    glmark2 score comparison:
      - Configuration:
        Host: glxgears.
        Guests: glmark2.
    +--------------------------------+-----------------+
    | Setup                          | glmark2 score   |
    +--------------------------------+-----------------+
    | unified lock, iommu=on         | 58~62 (avg. 60) |
    +--------------------------------+-----------------+
    | unified lock, iommu=igfx_off   | 57~61 (avg. 59) |
    +--------------------------------+-----------------+
    | per-logic lock, iommu=on       | 60~68 (avg. 64) |
    +--------------------------------+-----------------+
    | per-logic lock, iommu=igfx_off | 61~67 (avg. 64) |
    +--------------------------------+-----------------+
    
    lock_stat comparison:
      - Configuration:
        Stop lock stat immediately after boot up.
        Boot 2 VM Guests.
        Run glmark2 in guests.
        Start perf lock_stat for 20 seconds and stop again.
      - Legend: c - contentions; w - waittime-avg
    +------------+-----------------+-----------+---------------+------------+
    |            | gvt_lock        |sched_lock | vgpu_lock     | gtt_lock   |
    + lock type; +-----------------+-----------+---------------+------------+
    | iommu set  | c     | w       | c  | w    | c    | w      | c   | w    |
    +------------+-------+---------+----+------+------+--------+-----+------+
    | unified;   | 20697 | 839     |N/A | N/A  | N/A  | N/A    | N/A | N/A  |
    | on         |       |         |    |      |      |        |     |      |
    +------------+-------+---------+----+------+------+--------+-----+------+
    | unified;   | 21838 | 658.15  |N/A | N/A  | N/A  | N/A    | N/A | N/A  |
    | igfx_off   |       |         |    |      |      |        |     |      |
    +------------+-------+---------+----+------+------+--------+-----+------+
    | per-logic; | 1553  | 1599.96 |9458|429.97| 5846 | 274.33 | 0   | 0.00 |
    | on         |       |         |    |      |      |        |     |      |
    +------------+-------+---------+----+------+------+--------+-----+------+
    | per-logic; | 1911  | 1678.32 |8335|445.16| 5451 | 244.80 | 0   | 0.00 |
    | igfx_off   |       |         |    |      |      |        |     |      |
    +------------+-------+---------+----+------+------+--------+-----+------+
    
    Signed-off-by: Pei Zhang <pei.zhang@intel.com>
    Signed-off-by: Colin Xu <colin.xu@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index bf75300c1ec1..889d10f8ee96 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -226,22 +226,20 @@ void intel_gvt_activate_vgpu(struct intel_vgpu *vgpu)
  */
 void intel_gvt_deactivate_vgpu(struct intel_vgpu *vgpu)
 {
-	struct intel_gvt *gvt = vgpu->gvt;
-
-	mutex_lock(&gvt->lock);
+	mutex_lock(&vgpu->vgpu_lock);
 
 	vgpu->active = false;
 
 	if (atomic_read(&vgpu->submission.running_workload_num)) {
-		mutex_unlock(&gvt->lock);
+		mutex_unlock(&vgpu->vgpu_lock);
 		intel_gvt_wait_vgpu_idle(vgpu);
-		mutex_lock(&gvt->lock);
+		mutex_lock(&vgpu->vgpu_lock);
 	}
 
 	intel_vgpu_stop_schedule(vgpu);
 	intel_vgpu_dmabuf_cleanup(vgpu);
 
-	mutex_unlock(&gvt->lock);
+	mutex_unlock(&vgpu->vgpu_lock);
 }
 
 /**
@@ -255,14 +253,11 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 {
 	struct intel_gvt *gvt = vgpu->gvt;
 
-	mutex_lock(&gvt->lock);
+	mutex_lock(&vgpu->vgpu_lock);
 
 	WARN(vgpu->active, "vGPU is still active!\n");
 
 	intel_gvt_debugfs_remove_vgpu(vgpu);
-	idr_remove(&gvt->vgpu_idr, vgpu->id);
-	if (idr_is_empty(&gvt->vgpu_idr))
-		intel_gvt_clean_irq(gvt);
 	intel_vgpu_clean_sched_policy(vgpu);
 	intel_vgpu_clean_submission(vgpu);
 	intel_vgpu_clean_display(vgpu);
@@ -272,10 +267,16 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 	intel_vgpu_free_resource(vgpu);
 	intel_vgpu_clean_mmio(vgpu);
 	intel_vgpu_dmabuf_cleanup(vgpu);
-	vfree(vgpu);
+	mutex_unlock(&vgpu->vgpu_lock);
 
+	mutex_lock(&gvt->lock);
+	idr_remove(&gvt->vgpu_idr, vgpu->id);
+	if (idr_is_empty(&gvt->vgpu_idr))
+		intel_gvt_clean_irq(gvt);
 	intel_gvt_update_vgpu_types(gvt);
 	mutex_unlock(&gvt->lock);
+
+	vfree(vgpu);
 }
 
 #define IDLE_VGPU_IDR 0
@@ -301,6 +302,7 @@ struct intel_vgpu *intel_gvt_create_idle_vgpu(struct intel_gvt *gvt)
 
 	vgpu->id = IDLE_VGPU_IDR;
 	vgpu->gvt = gvt;
+	mutex_init(&vgpu->vgpu_lock);
 
 	for (i = 0; i < I915_NUM_ENGINES; i++)
 		INIT_LIST_HEAD(&vgpu->submission.workload_q_head[i]);
@@ -327,7 +329,10 @@ struct intel_vgpu *intel_gvt_create_idle_vgpu(struct intel_gvt *gvt)
  */
 void intel_gvt_destroy_idle_vgpu(struct intel_vgpu *vgpu)
 {
+	mutex_lock(&vgpu->vgpu_lock);
 	intel_vgpu_clean_sched_policy(vgpu);
+	mutex_unlock(&vgpu->vgpu_lock);
+
 	vfree(vgpu);
 }
 
@@ -345,8 +350,6 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (!vgpu)
 		return ERR_PTR(-ENOMEM);
 
-	mutex_lock(&gvt->lock);
-
 	ret = idr_alloc(&gvt->vgpu_idr, vgpu, IDLE_VGPU_IDR + 1, GVT_MAX_VGPU,
 		GFP_KERNEL);
 	if (ret < 0)
@@ -356,6 +359,7 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	vgpu->handle = param->handle;
 	vgpu->gvt = gvt;
 	vgpu->sched_ctl.weight = param->weight;
+	mutex_init(&vgpu->vgpu_lock);
 	INIT_LIST_HEAD(&vgpu->dmabuf_obj_list_head);
 	INIT_RADIX_TREE(&vgpu->page_track_tree, GFP_KERNEL);
 	idr_init(&vgpu->object_idr);
@@ -403,8 +407,6 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_clean_sched_policy;
 
-	mutex_unlock(&gvt->lock);
-
 	return vgpu;
 
 out_clean_sched_policy:
@@ -427,7 +429,6 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	idr_remove(&gvt->vgpu_idr, vgpu->id);
 out_free_vgpu:
 	vfree(vgpu);
-	mutex_unlock(&gvt->lock);
 	return ERR_PTR(ret);
 }
 
@@ -459,12 +460,12 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	param.low_gm_sz = BYTES_TO_MB(param.low_gm_sz);
 	param.high_gm_sz = BYTES_TO_MB(param.high_gm_sz);
 
+	mutex_lock(&gvt->lock);
 	vgpu = __intel_gvt_create_vgpu(gvt, &param);
-	if (IS_ERR(vgpu))
-		return vgpu;
-
-	/* calculate left instance change for types */
-	intel_gvt_update_vgpu_types(gvt);
+	if (!IS_ERR(vgpu))
+		/* calculate left instance change for types */
+		intel_gvt_update_vgpu_types(gvt);
+	mutex_unlock(&gvt->lock);
 
 	return vgpu;
 }
@@ -476,7 +477,7 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
  * @engine_mask: engines to reset for GT reset
  *
  * This function is called when user wants to reset a virtual GPU through
- * device model reset or GT reset. The caller should hold the gvt lock.
+ * device model reset or GT reset. The caller should hold the vgpu lock.
  *
  * vGPU Device Model Level Reset (DMLR) simulates the PCI level reset to reset
  * the whole vGPU to default state as when it is created. This vGPU function
@@ -516,9 +517,9 @@ void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
 	 * scheduler when the reset is triggered by current vgpu.
 	 */
 	if (scheduler->current_vgpu == NULL) {
-		mutex_unlock(&gvt->lock);
+		mutex_unlock(&vgpu->vgpu_lock);
 		intel_gvt_wait_vgpu_idle(vgpu);
-		mutex_lock(&gvt->lock);
+		mutex_lock(&vgpu->vgpu_lock);
 	}
 
 	intel_vgpu_reset_submission(vgpu, resetting_eng);
@@ -558,7 +559,7 @@ void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
  */
 void intel_gvt_reset_vgpu(struct intel_vgpu *vgpu)
 {
-	mutex_lock(&vgpu->gvt->lock);
+	mutex_lock(&vgpu->vgpu_lock);
 	intel_gvt_reset_vgpu_locked(vgpu, true, 0);
-	mutex_unlock(&vgpu->gvt->lock);
+	mutex_unlock(&vgpu->vgpu_lock);
 }

commit 1c6ccad8a4b110bac3f9ff6db954ab5a74c2e861
Author: Tina Zhang <tina.zhang@intel.com>
Date:   Mon May 14 13:59:18 2018 +0800

    drm/i915/gvt: Deliver guest cursor hotspot info
    
    Guest OS driver uses PV info registers to deliver cursor hotspot info
    to host. This patch is used to get cursor hotspot info from virtual
    registers and deliver it to host userspace.
    
    v4->v5:
    - remove CI warning.
    
    v3->v4:
    - return UINT_MAX when x_hot/y_hot is invalid. (Zhenyu)
    - correct version.
    
    v2->v3:
    - add validate_hotspot(). (Zhenyu)
    
    v1->v2:
    - name as cursor_x_hot/cursor_y_hot. (Zhenyu)
    - use i915_reg_t definition instead of magic numbers. (Zhenyu)
    
    Signed-off-by: Tina Zhang <tina.zhang@intel.com>
    Cc: Zhenyu Wang <zhenyuw@linux.intel.com>
    Cc: Zhi Wang <zhi.a.wang@intel.com>
    Cc: Gerd Hoffmann <kraxel@redhat.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 2e0a02a80fe4..bf75300c1ec1 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -58,6 +58,9 @@ void populate_pvinfo_page(struct intel_vgpu *vgpu)
 
 	vgpu_vreg_t(vgpu, vgtif_reg(avail_rs.fence_num)) = vgpu_fence_sz(vgpu);
 
+	vgpu_vreg_t(vgpu, vgtif_reg(cursor_x_hot)) = UINT_MAX;
+	vgpu_vreg_t(vgpu, vgtif_reg(cursor_y_hot)) = UINT_MAX;
+
 	gvt_dbg_core("Populate PVINFO PAGE for vGPU %d\n", vgpu->id);
 	gvt_dbg_core("aperture base [GMADR] 0x%llx size 0x%llx\n",
 		vgpu_aperture_gmadr_base(vgpu), vgpu_aperture_sz(vgpu));

commit 730c8ead53bf3011d33de69ff5a6cebf51e697b5
Author: Zhi Wang <zhi.wang.linux@gmail.com>
Date:   Wed Feb 7 18:12:14 2018 +0800

    drm/i915/gvt: Invalidate vGPU PPGTT mm objects during a vGPU reset.
    
    As different OSes might handling GVT PPGTT creation/destroy notification
    differently during a vGPU reset. A better approach is invalidating all
    vGPU PPGTT mm objects during vGPU reset.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 41f76e86aa1f..2e0a02a80fe4 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -522,6 +522,7 @@ void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
 	/* full GPU reset or device model level reset */
 	if (engine_mask == ALL_ENGINES || dmlr) {
 		intel_vgpu_select_submission_ops(vgpu, ALL_ENGINES, 0);
+		intel_vgpu_invalidate_ppgtt(vgpu);
 		/*fence will not be reset during virtual reset */
 		if (dmlr) {
 			intel_vgpu_reset_gtt(vgpu);

commit e502a2af4c358d14ecf8fce51bf4988ebb4d10b4
Author: Changbin Du <changbin.du@intel.com>
Date:   Tue Jan 30 19:19:53 2018 +0800

    drm/i915/gvt: Provide generic page_track infrastructure for write-protected page
    
    This patch provide generic page_track infrastructure for write-protected
    guest page. The old page_track logic gets rewrote and now stays in a new
    standalone page_track.c. This page track infrastructure can be both used
    by vGUC and GTT shadowing.
    
    The important change is that it uses radix tree instead of hash table.
    We don't have a predictable number of pages that will be tracked.
    
    Here is some performance data (duration in us) of looking up a element:
    Before: (aka. intel_vgpu_find_tracked_page)
     0.091 0.089 0.090 ... 0.093 0.091 0.087 ... 0.292 0.285 0.292 0.291
    After: (aka. intel_vgpu_find_page_track)
     0.104 0.105 0.100 0.102 0.102 0.100 ... 0.101 0.101 0.105 0.105
    
    The hash table has good performance at beginning, but turns bad with
    more pages being tracked even no 3D applications are running. As
    expected, radix tree has stable duration and very quick.
    
    The overall benchmark (tested with Heaven Benchmark) marginally improved
    since this is not the bottleneck. What we benefit more from this change
    is scalability.
    
    Signed-off-by: Changbin Du <changbin.du@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index b87b19d8443c..41f76e86aa1f 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -354,6 +354,7 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	vgpu->gvt = gvt;
 	vgpu->sched_ctl.weight = param->weight;
 	INIT_LIST_HEAD(&vgpu->dmabuf_obj_list_head);
+	INIT_RADIX_TREE(&vgpu->page_track_tree, GFP_KERNEL);
 	idr_init(&vgpu->object_idr);
 	intel_vgpu_init_cfg_space(vgpu, param->primary);
 

commit 7569a06dc80ec05c96783f541fa706ea3bebec79
Author: Weinan Li <weinan.z.li@intel.com>
Date:   Fri Jan 26 15:09:07 2018 +0800

    drm/i915/gvt: refine intel_vgpu_submission_ops as per engine ops
    
    Using per engine ops will be more flexible, here refine sub-ops(init,
    clean) as per engine operation align with reset operation. This change also
    will be used in next fix patch for VM engine reset.
    
    Cc: Fred Gao <fred.gao@intel.com>
    Cc: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Weinan Li <weinan.z.li@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Rodrigo Vivi <rodrigo.vivi@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index a8784fa91289..b87b19d8443c 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -520,8 +520,7 @@ void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
 	intel_vgpu_reset_submission(vgpu, resetting_eng);
 	/* full GPU reset or device model level reset */
 	if (engine_mask == ALL_ENGINES || dmlr) {
-		intel_vgpu_select_submission_ops(vgpu, 0);
-
+		intel_vgpu_select_submission_ops(vgpu, ALL_ENGINES, 0);
 		/*fence will not be reset during virtual reset */
 		if (dmlr) {
 			intel_vgpu_reset_gtt(vgpu);

commit 14b4434bff1aab69f3785bc67276efbff7fffa3d
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Mon Jan 15 16:36:11 2018 +0800

    drm/i915/gvt: cancel virtual vblank timer when no vGPU exists
    
    Stop irq timer for virtual vblank timer emulation if no vGPU exists,
    otherwise it will keep gvt service thread busy to handle virtual vblank
    but no use.
    
    Reviewed-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Signed-off-by: Rodrigo Vivi <rodrigo.vivi@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 4688619f6a1c..a8784fa91289 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -258,6 +258,8 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 
 	intel_gvt_debugfs_remove_vgpu(vgpu);
 	idr_remove(&gvt->vgpu_idr, vgpu->id);
+	if (idr_is_empty(&gvt->vgpu_idr))
+		intel_gvt_clean_irq(gvt);
 	intel_vgpu_clean_sched_policy(vgpu);
 	intel_vgpu_clean_submission(vgpu);
 	intel_vgpu_clean_display(vgpu);

commit 90551a1296d4dbe0dccc4c3cb5e57e7f2c929009
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Tue Dec 19 13:02:51 2017 +0800

    drm/i915/gvt: cleanup usage for typed mmio reg vs. offset
    
    We had previous hack that tried to accept either i915_reg_t or offset
    value to access vGPU virtual/shadow regs which broke that purpose to
    be type safe in context. This one trys to explicitly separate the usage
    of typed mmio reg with real offset.
    
    Old vgpu_vreg(offset) helper is used only for offset now with new
    vgpu_vreg_t(reg) is used for i915_reg_t only. Convert left usage
    of that to new helper.
    
    Also fixed left KASAN warning issues caused by previous hack.
    
    v2: rebase, fixup against recent mmio switch change
    
    Reviewed-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 39926176fbeb..4688619f6a1c 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -38,25 +38,25 @@
 void populate_pvinfo_page(struct intel_vgpu *vgpu)
 {
 	/* setup the ballooning information */
-	vgpu_vreg64(vgpu, vgtif_reg(magic)) = VGT_MAGIC;
-	vgpu_vreg(vgpu, vgtif_reg(version_major)) = 1;
-	vgpu_vreg(vgpu, vgtif_reg(version_minor)) = 0;
-	vgpu_vreg(vgpu, vgtif_reg(display_ready)) = 0;
-	vgpu_vreg(vgpu, vgtif_reg(vgt_id)) = vgpu->id;
+	vgpu_vreg64_t(vgpu, vgtif_reg(magic)) = VGT_MAGIC;
+	vgpu_vreg_t(vgpu, vgtif_reg(version_major)) = 1;
+	vgpu_vreg_t(vgpu, vgtif_reg(version_minor)) = 0;
+	vgpu_vreg_t(vgpu, vgtif_reg(display_ready)) = 0;
+	vgpu_vreg_t(vgpu, vgtif_reg(vgt_id)) = vgpu->id;
 
-	vgpu_vreg(vgpu, vgtif_reg(vgt_caps)) = VGT_CAPS_FULL_48BIT_PPGTT;
-	vgpu_vreg(vgpu, vgtif_reg(vgt_caps)) |= VGT_CAPS_HWSP_EMULATION;
+	vgpu_vreg_t(vgpu, vgtif_reg(vgt_caps)) = VGT_CAPS_FULL_48BIT_PPGTT;
+	vgpu_vreg_t(vgpu, vgtif_reg(vgt_caps)) |= VGT_CAPS_HWSP_EMULATION;
 
-	vgpu_vreg(vgpu, vgtif_reg(avail_rs.mappable_gmadr.base)) =
+	vgpu_vreg_t(vgpu, vgtif_reg(avail_rs.mappable_gmadr.base)) =
 		vgpu_aperture_gmadr_base(vgpu);
-	vgpu_vreg(vgpu, vgtif_reg(avail_rs.mappable_gmadr.size)) =
+	vgpu_vreg_t(vgpu, vgtif_reg(avail_rs.mappable_gmadr.size)) =
 		vgpu_aperture_sz(vgpu);
-	vgpu_vreg(vgpu, vgtif_reg(avail_rs.nonmappable_gmadr.base)) =
+	vgpu_vreg_t(vgpu, vgtif_reg(avail_rs.nonmappable_gmadr.base)) =
 		vgpu_hidden_gmadr_base(vgpu);
-	vgpu_vreg(vgpu, vgtif_reg(avail_rs.nonmappable_gmadr.size)) =
+	vgpu_vreg_t(vgpu, vgtif_reg(avail_rs.nonmappable_gmadr.size)) =
 		vgpu_hidden_sz(vgpu);
 
-	vgpu_vreg(vgpu, vgtif_reg(avail_rs.fence_num)) = vgpu_fence_sz(vgpu);
+	vgpu_vreg_t(vgpu, vgtif_reg(avail_rs.fence_num)) = vgpu_fence_sz(vgpu);
 
 	gvt_dbg_core("Populate PVINFO PAGE for vGPU %d\n", vgpu->id);
 	gvt_dbg_core("aperture base [GMADR] 0x%llx size 0x%llx\n",

commit e546e281d33d1fc275651aa06f0659045db67e68
Author: Tina Zhang <tina.zhang@intel.com>
Date:   Thu Nov 23 16:26:36 2017 +0800

    drm/i915/gvt: Dmabuf support for GVT-g
    
    This patch introduces a guest's framebuffer sharing mechanism based on
    dma-buf subsystem. With this sharing mechanism, guest's framebuffer can
    be shared between guest VM and host.
    
    v17:
    - modify VFIO_DEVICE_GET_GFX_DMABUF interface. (Alex)
    
    v16:
    - add x_hot and y_hot. (Gerd)
    - add flag validation for VFIO_DEVICE_GET_GFX_DMABUF. (Alex)
    - rebase 4.14.0-rc6.
    
    v15:
    - add VFIO_DEVICE_GET_GFX_DMABUF ABI. (Gerd)
    - add intel_vgpu_dmabuf_cleanup() to clean up the vGPU's dmabuf. (Gerd)
    
    v14:
    - add PROBE, DMABUF and REGION flags. (Alex)
    
    v12:
    - refine the lifecycle of dmabuf.
    
    v9:
    - remove dma-buf management. (Alex)
    - track the dma-buf create and release in kernel mode. (Gerd) (Daniel)
    
    v8:
    - refine the dma-buf ioctl definition.(Alex)
    - add a lock to protect the dmabuf list. (Alex)
    
    v7:
    - release dma-buf related allocations in dma-buf's associated release
      function. (Alex)
    - refine ioctl interface for querying plane info or create dma-buf.
      (Alex)
    
    v6:
    - align the dma-buf life cycle with the vfio device. (Alex)
    - add the dma-buf related operations in a separate patch. (Gerd)
    - i915 related changes. (Chris)
    
    v5:
    - fix bug while checking whether the gem obj is gvt's dma-buf when user
      change caching mode or domains. Add a helper function to do it.
      (Xiaoguang)
    - add definition for the query plane and create dma-buf. (Xiaoguang)
    
    v4:
    - fix bug while checking whether the gem obj is gvt's dma-buf when set
      caching mode or doamins. (Xiaoguang)
    
    v3:
    - declare a new flag I915_GEM_OBJECT_IS_GVT_DMABUF in drm_i915_gem_object
      to represent the gem obj for gvt's dma-buf. The tiling mode, caching
      mode and domains can not be changed for this kind of gem object. (Alex)
    - change dma-buf related information to be more generic. So other vendor
      can use the same interface. (Alex)
    
    v2:
    - create a management fd for dma-buf operations. (Alex)
    - alloc gem object's backing storage in gem obj's get_pages() callback.
      (Chris)
    
    Signed-off-by: Tina Zhang <tina.zhang@intel.com>
    Cc: Alex Williamson <alex.williamson@redhat.com>
    Cc: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Cc: Gerd Hoffmann <kraxel@redhat.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index dcdd72260cc9..39926176fbeb 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -236,6 +236,7 @@ void intel_gvt_deactivate_vgpu(struct intel_vgpu *vgpu)
 	}
 
 	intel_vgpu_stop_schedule(vgpu);
+	intel_vgpu_dmabuf_cleanup(vgpu);
 
 	mutex_unlock(&gvt->lock);
 }
@@ -265,6 +266,7 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 	intel_gvt_hypervisor_detach_vgpu(vgpu);
 	intel_vgpu_free_resource(vgpu);
 	intel_vgpu_clean_mmio(vgpu);
+	intel_vgpu_dmabuf_cleanup(vgpu);
 	vfree(vgpu);
 
 	intel_gvt_update_vgpu_types(gvt);
@@ -349,7 +351,8 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	vgpu->handle = param->handle;
 	vgpu->gvt = gvt;
 	vgpu->sched_ctl.weight = param->weight;
-
+	INIT_LIST_HEAD(&vgpu->dmabuf_obj_list_head);
+	idr_init(&vgpu->object_idr);
 	intel_vgpu_init_cfg_space(vgpu, param->primary);
 
 	ret = intel_vgpu_init_mmio(vgpu);

commit b851adeac0858c7d257b32eee2142b1519d45ccf
Author: Tina Zhang <tina.zhang@intel.com>
Date:   Mon Nov 20 15:31:16 2017 +0800

    drm/i915/gvt: Add opregion support
    
    Windows guest driver needs vbt in opregion, to configure the setting
    for display. Without opregion support, the display registers won't
    be set and this blocks display model to get the correct information
    of the guest display plane.
    
    This patch is to provide a virtual opregion for guest. The original
    author of this patch is Xiaoguang Chen.
    
    This patch is split from the "Dma-buf support for GVT-g" patch set,
    with being rebased to the latest gvt-staging branch.
    
    v3:
    - add checking region index during intel_vgpu_rw. (Xiong)
    
    v2:
    - refine intel_vgpu_reg_release_opregion. (Xiong)
    
    Here are the previous version comments:
    
    v18:
    - unmap vgpu's opregion when destroying vgpu.
    
    v16:
    - rebase to 4.14.0-rc6.
    
    Signed-off-by: Bing Niu <bing.niu@intel.com>
    Signed-off-by: Tina Zhang <tina.zhang@intel.com>
    Tested-by: Xiong Zhang <xiong.y.zhang@intel.com>
    Cc: Zhenyu Wang <zhenyuw@linux.intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 2896aafc9520..dcdd72260cc9 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -390,6 +390,10 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_clean_sched_policy;
 
+	ret = intel_gvt_hypervisor_set_opregion(vgpu);
+	if (ret)
+		goto out_clean_sched_policy;
+
 	mutex_unlock(&gvt->lock);
 
 	return vgpu;

commit 4dff110b15aea2f7653957a70921a7be1f45d59b
Author: Xiong Zhang <xiong.y.zhang@intel.com>
Date:   Mon Nov 20 15:31:15 2017 +0800

    drm/i915/gvt: Alloc and Init guest opregion at vgpu creation
    
    Currently guest opregion is allocated and initialised when guest
    write opregion base register. This is too late for kvmgt, so
    move it to vgpu_create time.
    
    Signed-off-by: Xiong Zhang <xiong.y.zhang@intel.com>
    Tested-by: Tina Zhang <tina.zhang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index c6b82d1ba7de..2896aafc9520 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -370,10 +370,14 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_detach_hypervisor_vgpu;
 
-	ret = intel_vgpu_init_display(vgpu, param->resolution);
+	ret = intel_vgpu_init_opregion(vgpu);
 	if (ret)
 		goto out_clean_gtt;
 
+	ret = intel_vgpu_init_display(vgpu, param->resolution);
+	if (ret)
+		goto out_clean_opregion;
+
 	ret = intel_vgpu_setup_submission(vgpu);
 	if (ret)
 		goto out_clean_display;
@@ -396,6 +400,8 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	intel_vgpu_clean_submission(vgpu);
 out_clean_display:
 	intel_vgpu_clean_display(vgpu);
+out_clean_opregion:
+	intel_vgpu_clean_opregion(vgpu);
 out_clean_gtt:
 	intel_vgpu_clean_gtt(vgpu);
 out_detach_hypervisor_vgpu:

commit a2ae95af9646316aaf86e2d18f46de1a5f746f1a
Author: Weinan Li <weinan.z.li@intel.com>
Date:   Fri Oct 20 15:16:46 2017 +0800

    drm/i915/gvt: update CSB and CSB write pointer in virtual HWSP
    
    The engine provides a mirror of the CSB and CSB write pointer in the HWSP.
    Read these status from virtual HWSP in VM can reduce CPU utilization while
    applications have much more short GPU workloads. Here we update the
    corresponding data in virtual HWSP as it in virtual MMIO.
    
    Before read these status from HWSP in GVT-g VM, please ensure the host
    support it by checking the BIT(3) of caps in PVINFO.
    
    Virtual HWSP only support GEN8+ platform, since the HWSP MMIO may change
    follow the platform update, please add the corresponding MMIO emulation
    when enable new platforms in GVT-g.
    
    v3 : Add address audit in HWSP address update.
    
    v4 :
         Separate this patch with enalbe virtual HWSP in VM.
         Use intel_gvt_render_mmio_to_ring_id() to determine ring_id by offset.
    
    v5 : Remove unnessary check about Gen8, GVT-g only support Gen8+.
    
    Signed-off-by: Weinan Li <weinan.z.li@intel.com>
    Cc: Zhenyu Wang <zhenyuw@linux.intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 99dbefadfe91..c6b82d1ba7de 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -43,7 +43,10 @@ void populate_pvinfo_page(struct intel_vgpu *vgpu)
 	vgpu_vreg(vgpu, vgtif_reg(version_minor)) = 0;
 	vgpu_vreg(vgpu, vgtif_reg(display_ready)) = 0;
 	vgpu_vreg(vgpu, vgtif_reg(vgt_id)) = vgpu->id;
+
 	vgpu_vreg(vgpu, vgtif_reg(vgt_caps)) = VGT_CAPS_FULL_48BIT_PPGTT;
+	vgpu_vreg(vgpu, vgtif_reg(vgt_caps)) |= VGT_CAPS_HWSP_EMULATION;
+
 	vgpu_vreg(vgpu, vgtif_reg(avail_rs.mappable_gmadr.base)) =
 		vgpu_aperture_gmadr_base(vgpu);
 	vgpu_vreg(vgpu, vgtif_reg(avail_rs.mappable_gmadr.size)) =

commit bc7b0be316aebac42eb9e8e54c984609555944da
Author: Changbin Du <changbin.du@intel.com>
Date:   Tue Sep 26 16:19:13 2017 +0800

    drm/i915/gvt: Add basic debugfs infrastructure
    
    We need debugfs entry to expose some debug information of gvt and vGPUs.
    The first tool will be added is mmio-diff, which help to find the
    difference values of host and vGPU mmio. It's useful for platform
    enabling.
    
    This patch just add a basic debugfs infrastructure, each vGPU has its own
    sub-folder. Two simple attributes are created as a template.
    .
    ├── num_tracked_mmio
    ├── vgpu1
    |   └── active
    └── vgpu2
        └── active
    
    Signed-off-by: Changbin Du <changbin.du@intel.com>
    Reviewed-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 841b95c6c231..99dbefadfe91 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -252,6 +252,7 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 
 	WARN(vgpu->active, "vGPU is still active!\n");
 
+	intel_gvt_debugfs_remove_vgpu(vgpu);
 	idr_remove(&gvt->vgpu_idr, vgpu->id);
 	intel_vgpu_clean_sched_policy(vgpu);
 	intel_vgpu_clean_submission(vgpu);
@@ -378,10 +379,16 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_clean_submission;
 
+	ret = intel_gvt_debugfs_add_vgpu(vgpu);
+	if (ret)
+		goto out_clean_sched_policy;
+
 	mutex_unlock(&gvt->lock);
 
 	return vgpu;
 
+out_clean_sched_policy:
+	intel_vgpu_clean_sched_policy(vgpu);
 out_clean_submission:
 	intel_vgpu_clean_submission(vgpu);
 out_clean_display:

commit 06bb372f9ace47296aeaaca8e130d948ea2855cf
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Wed Sep 13 01:41:35 2017 +0800

    drm/i915/gvt: Introduce intel_vgpu_reset_submission
    
    Introduce an generic API to reset vGPU virtual submission interface.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index e63abd48bcee..841b95c6c231 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -492,10 +492,10 @@ void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
 		mutex_lock(&gvt->lock);
 	}
 
-	intel_vgpu_reset_execlist(vgpu, resetting_eng);
-
+	intel_vgpu_reset_submission(vgpu, resetting_eng);
 	/* full GPU reset or device model level reset */
 	if (engine_mask == ALL_ENGINES || dmlr) {
+		intel_vgpu_select_submission_ops(vgpu, 0);
 
 		/*fence will not be reset during virtual reset */
 		if (dmlr) {

commit ad1d36369b07f6b9db81897802ee5d8764eaa922
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Wed Sep 13 00:31:29 2017 +0800

    drm/i915/gvt: Introduce vGPU submission ops
    
    Introduce vGPU submission ops to support easy switching submission mode
    of one vGPU between different OSes.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 1c9818d9f1d8..e63abd48bcee 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -255,7 +255,6 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 	idr_remove(&gvt->vgpu_idr, vgpu->id);
 	intel_vgpu_clean_sched_policy(vgpu);
 	intel_vgpu_clean_submission(vgpu);
-	intel_vgpu_clean_execlist(vgpu);
 	intel_vgpu_clean_display(vgpu);
 	intel_vgpu_clean_opregion(vgpu);
 	intel_vgpu_clean_gtt(vgpu);
@@ -371,26 +370,20 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_clean_gtt;
 
-	ret = intel_vgpu_init_execlist(vgpu);
-	if (ret)
-		goto out_clean_display;
-
 	ret = intel_vgpu_setup_submission(vgpu);
 	if (ret)
-		goto out_clean_execlist;
+		goto out_clean_display;
 
 	ret = intel_vgpu_init_sched_policy(vgpu);
 	if (ret)
-		goto out_clean_shadow_ctx;
+		goto out_clean_submission;
 
 	mutex_unlock(&gvt->lock);
 
 	return vgpu;
 
-out_clean_shadow_ctx:
+out_clean_submission:
 	intel_vgpu_clean_submission(vgpu);
-out_clean_execlist:
-	intel_vgpu_clean_execlist(vgpu);
 out_clean_display:
 	intel_vgpu_clean_display(vgpu);
 out_clean_gtt:

commit 91d5d85442b2a65e5f4e1726565c1c1a8ba9976f
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Sun Sep 10 21:33:20 2017 +0800

    drm/i915/gvt: Move tlb_handle_pending into intel_vgpu_submission
    
    Move tlb_handle_pending into intel_vgpu_submssion since it belongs to a
    part of vGPU submission stuffs
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 35a5ec201206..1c9818d9f1d8 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -346,7 +346,6 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	vgpu->handle = param->handle;
 	vgpu->gvt = gvt;
 	vgpu->sched_ctl.weight = param->weight;
-	bitmap_zero(vgpu->tlb_handle_pending, I915_NUM_ENGINES);
 
 	intel_vgpu_init_cfg_space(vgpu, param->primary);
 

commit 1406a14b0ed977fc18f43398b391e4bb5d744174
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Sun Sep 10 21:15:18 2017 +0800

    drm/i915/gvt: Introduce intel_vgpu_submission
    
    Introduce intel_vgpu_submission to hold all members related to submission
    in struct intel_vgpu before.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 3d69871d28e9..35a5ec201206 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -226,7 +226,7 @@ void intel_gvt_deactivate_vgpu(struct intel_vgpu *vgpu)
 
 	vgpu->active = false;
 
-	if (atomic_read(&vgpu->running_workload_num)) {
+	if (atomic_read(&vgpu->submission.running_workload_num)) {
 		mutex_unlock(&gvt->lock);
 		intel_gvt_wait_vgpu_idle(vgpu);
 		mutex_lock(&gvt->lock);
@@ -293,7 +293,7 @@ struct intel_vgpu *intel_gvt_create_idle_vgpu(struct intel_gvt *gvt)
 	vgpu->gvt = gvt;
 
 	for (i = 0; i < I915_NUM_ENGINES; i++)
-		INIT_LIST_HEAD(&vgpu->workload_q_head[i]);
+		INIT_LIST_HEAD(&vgpu->submission.workload_q_head[i]);
 
 	ret = intel_vgpu_init_sched_policy(vgpu);
 	if (ret)

commit 874b6a910e6cc094629bd2634d14061cf5eb7690
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Sun Sep 10 20:08:18 2017 +0800

    drm/i915/gvt: Rename intel_vgpu_{init, clean}_gvt_context()
    
    To move workload related functions into scheduler.c, an expected way is
    to collect all the init/clean functions related to vGPU workload
    submission into fewer functions.
    
    Rename intel_vgpu_{init, clean}_gvt_context() for above usage in future.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 02c61a1ad56a..3d69871d28e9 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -254,7 +254,7 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 
 	idr_remove(&gvt->vgpu_idr, vgpu->id);
 	intel_vgpu_clean_sched_policy(vgpu);
-	intel_vgpu_clean_gvt_context(vgpu);
+	intel_vgpu_clean_submission(vgpu);
 	intel_vgpu_clean_execlist(vgpu);
 	intel_vgpu_clean_display(vgpu);
 	intel_vgpu_clean_opregion(vgpu);
@@ -376,7 +376,7 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_clean_display;
 
-	ret = intel_vgpu_init_gvt_context(vgpu);
+	ret = intel_vgpu_setup_submission(vgpu);
 	if (ret)
 		goto out_clean_execlist;
 
@@ -389,7 +389,7 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	return vgpu;
 
 out_clean_shadow_ctx:
-	intel_vgpu_clean_gvt_context(vgpu);
+	intel_vgpu_clean_submission(vgpu);
 out_clean_execlist:
 	intel_vgpu_clean_execlist(vgpu);
 out_clean_display:

commit 735f463af70e9601881ec879961ec42aef051733
Merge: 3aadb888b1b6 a42894ebb50d
Author: Dave Airlie <airlied@redhat.com>
Date:   Tue Aug 22 10:03:07 2017 +1000

    Merge tag 'drm-intel-next-2017-08-18' of git://anongit.freedesktop.org/git/drm-intel into drm-next
    
    Final pile of features for 4.14
    
    - New ioctl to change NOA configurations, plus prep (Lionel)
    - CCS (color compression) scanout support, based on the fancy new
      modifier additions (Ville&Ben)
    - Document i915 register macro style (Jani)
    - Many more gen10/cnl patches (Rodrigo, Pualo, ...)
    - More gpu reset vs. modeset duct-tape to restore the old way.
    - prep work for cnl: hpd_pin reorg (Rodrigo), support for more power
      wells (Imre), i2c pin reorg (Anusha)
    - drm_syncobj support (Jason Ekstrand)
    - forcewake vs gpu reset fix (Chris)
    - execbuf speedup for the no-relocs fastpath, anv/vk low-overhead ftw (Chris)
    - switch to idr/radixtree instead of the resizing ht for execbuf id->vma
      lookups (Chris)
    
    gvt:
    - MMIO save/restore optimization (Changbin)
    - Split workload scan vs. dispatch for more parallel exec (Ping)
    - vGPU full 48bit ppgtt support (Joonas, Tina)
    - vGPU hw id expose for perf (Zhenyu)
    
    Bunch of work all over to make the igt CI runs more complete/stable.
    Watch https://intel-gfx-ci.01.org/tree/drm-tip/shards-all.html for
    progress in getting this ready. Next week we're going into production
    mode (i.e. will send results to intel-gfx) on hsw, more platforms to
    come.
    
    Also, a new maintainer tram, I'm stepping out. Huge thanks to Jani for
    being an awesome co-maintainer the past few years, and all the best
    for Jani, Joonas&Rodrigo as the new maintainers!
    
    * tag 'drm-intel-next-2017-08-18' of git://anongit.freedesktop.org/git/drm-intel: (179 commits)
      drm/i915: Update DRIVER_DATE to 20170818
      drm/i915/bxt: use NULL for GPIO connection ID
      drm/i915: Mark the GT as busy before idling the previous request
      drm/i915: Trivial grammar fix s/opt of/opt out of/ in comment
      drm/i915: Replace execbuf vma ht with an idr
      drm/i915: Simplify eb_lookup_vmas()
      drm/i915: Convert execbuf to use struct-of-array packing for critical fields
      drm/i915: Check context status before looking up our obj/vma
      drm/i915: Don't use MI_STORE_DWORD_IMM on Sandybridge/vcs
      drm/i915: Stop touching forcewake following a gen6+ engine reset
      MAINTAINERS: drm/i915 has a new maintainer team
      drm/i915: Split pin mapping into per platform functions
      drm/i915/opregion: let user specify override VBT via firmware load
      drm/i915/cnl: Reuse skl_wm_get_hw_state on Cannonlake.
      drm/i915/gen10: implement gen 10 watermarks calculations
      drm/i915/cnl: Fix LSPCON support.
      drm/i915/vbt: ignore extraneous child devices for a port
      drm/i915/cnl: Setup PAT Index.
      drm/i915/edp: Allow alternate fixed mode for eDP if available.
      drm/i915: Add support for drm syncobjs
      ...

commit 6b3816d69628becb7ff35978aa0751798b4a940a
Author: Tina Zhang <tina.zhang@intel.com>
Date:   Mon Aug 14 15:24:14 2017 +0800

    drm/i915/gvt: Fix guest i915 full ppgtt blocking issue
    
    Guest i915 full ppgtt functionality was blocking by an issue, which would
    lead to gpu hardware hang. Guest i915 driver may update the ppgtt table
    just before this workload is going to be submitted to the hardware by
    device model. This case wasn't handled well by device model before, due
    to the small time window between removing old ppgtt entry and adding the
    new one. Errors occur when the workload is executed by hardware during
    that small time window. This patch is to remove this time window by adding
    the new ppgtt entry first and then remove the old one.
    
    Changes in v2:
    - Move VGT_CAPS_FULL_PPGTT introduction to patch 2/4. (Joonas)
    
    Changes since v2:
    - Divide the whole patch set into two separate patch series, with one
      patch in i915 side to check guest i915 full ppgtt capability and enable
      it when this capability is supported by the device model, and the other
      one in gvt side which fixs the blocking issue and enables the device
      model to provide the capability to guest. And this patch focuses on gvt
      side. (Joonas)
    - Change the title from "reorder the shadow ppgtt update process by adding
      entry first" to "Fix guest i915 full ppgtt blocking issue". (Tina)
    
    Changes since v3:
    - Rebase to the latest branch.
    
    Changes since v4:
    - Tested by Tina Zhang.
    
    Changes since v5:
    - Rebase to the latest branch.
    
    v6:
    - Update full 48bit ppgtt definition
    
    Cc: Tina Zhang <tina.zhang@intel.com>
    Signed-off-by: Tina Zhang <tina.zhang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 5b44d123bf24..5896ead8529e 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -43,6 +43,7 @@ void populate_pvinfo_page(struct intel_vgpu *vgpu)
 	vgpu_vreg(vgpu, vgtif_reg(version_minor)) = 0;
 	vgpu_vreg(vgpu, vgtif_reg(display_ready)) = 0;
 	vgpu_vreg(vgpu, vgtif_reg(vgt_id)) = vgpu->id;
+	vgpu_vreg(vgpu, vgtif_reg(vgt_caps)) = VGT_CAPS_FULL_48BIT_PPGTT;
 	vgpu_vreg(vgpu, vgtif_reg(avail_rs.mappable_gmadr.base)) =
 		vgpu_aperture_gmadr_base(vgpu);
 	vgpu_vreg(vgpu, vgtif_reg(avail_rs.mappable_gmadr.size)) =

commit 4d3e67bb6fa26e50eb087799d98ec232acfb630d
Author: Chuanxiao Dong <chuanxiao.dong@intel.com>
Date:   Fri Aug 4 13:08:59 2017 +0800

    drm/i915/gvt: Refine the intel_vgpu_reset_gtt reset function
    
    When doing the VGPU reset, we don't need to do the gtt/ppgtt reset.
    This will make the GVT to do the ppgtt shadow every time for
    a workload and caused really bad performance after a VGPU reset.
    This patch will make sure ppgtt clean only happen at device module
    level reset to fix this.
    
    Signed-off-by: Chuanxiao Dong <chuanxiao.dong@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 90c14e6e3ea0..5b44d123bf24 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -502,11 +502,11 @@ void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
 	/* full GPU reset or device model level reset */
 	if (engine_mask == ALL_ENGINES || dmlr) {
 
-		intel_vgpu_reset_gtt(vgpu, dmlr);
-
 		/*fence will not be reset during virtual reset */
-		if (dmlr)
+		if (dmlr) {
+			intel_vgpu_reset_gtt(vgpu);
 			intel_vgpu_reset_resource(vgpu);
+		}
 
 		intel_vgpu_reset_mmio(vgpu, dmlr);
 		populate_pvinfo_page(vgpu);

commit 6184cc8ddbb318758a000da68c5285fc2dd74338
Author: Chuanxiao Dong <chuanxiao.dong@intel.com>
Date:   Tue Aug 1 17:47:25 2017 +0800

    drm/i915/gvt: change resetting to resetting_eng
    
    Use resetting_eng to identify which engine is resetting
    so the rest ones' workload won't be impacted
    
    v2:
    - use ENGINE_MASK(ring_id) instead of (1 << ring_id). (Zhenyu)
    
    Signed-off-by: Chuanxiao Dong <chuanxiao.dong@intel.com>
    Cc: Zhenyu Wang <zhenyuw@linux.intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 90c14e6e3ea0..3deadcbd5a24 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -480,11 +480,13 @@ void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
 {
 	struct intel_gvt *gvt = vgpu->gvt;
 	struct intel_gvt_workload_scheduler *scheduler = &gvt->scheduler;
+	unsigned int resetting_eng = dmlr ? ALL_ENGINES : engine_mask;
 
 	gvt_dbg_core("------------------------------------------\n");
 	gvt_dbg_core("resseting vgpu%d, dmlr %d, engine_mask %08x\n",
 		     vgpu->id, dmlr, engine_mask);
-	vgpu->resetting = true;
+
+	vgpu->resetting_eng = resetting_eng;
 
 	intel_vgpu_stop_schedule(vgpu);
 	/*
@@ -497,7 +499,7 @@ void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
 		mutex_lock(&gvt->lock);
 	}
 
-	intel_vgpu_reset_execlist(vgpu, dmlr ? ALL_ENGINES : engine_mask);
+	intel_vgpu_reset_execlist(vgpu, resetting_eng);
 
 	/* full GPU reset or device model level reset */
 	if (engine_mask == ALL_ENGINES || dmlr) {
@@ -520,7 +522,7 @@ void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
 		}
 	}
 
-	vgpu->resetting = false;
+	vgpu->resetting_eng = 0;
 	gvt_dbg_core("reset vgpu%d done\n", vgpu->id);
 	gvt_dbg_core("------------------------------------------\n");
 }

commit 615c16a9d8649b9894592d11bc393e684b11e2ea
Author: fred gao <fred.gao@intel.com>
Date:   Thu May 25 15:33:52 2017 +0800

    drm/i915/gvt: Refine virtual reset function
    
    during the emulation of virtual reset:
    1. only reset the engine related mmio ending with MMIO
       offset Master_IRQ, not include display stuff.
    
    2. fences are not required to set default
       value as well to prevent screen flicking.
    
    this will fix the issue of Guest screen hang while running
    Force tdr in Linux guest.
    
    v2:
    - only reset the engine related mmio. (Zhenyu & Zhiyuan)
    v3:
    - IMR/Ring mode registers are not save/restored. (Changbin)
    v4:
    - redefine the MMIO reset offset for easy understanding. (Zhenyu)
    - pvinfo can be reset. (Zhenyu)
    v5:
    - add more comments for mmio reset. (Zhenyu)
    
    Cc: Changbin Du <changbin.du@intel.com>
    Cc: Zhenyu Wang <zhenyuw@linux.intel.com>
    Cc: Lv zhiyuan <zhiyuan.lv@intel.com>
    Cc: Zhang Yulei <yulei.zhang@intel.com>
    Signed-off-by: fred gao <fred.gao@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 6e3cbd8caec2..90c14e6e3ea0 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -501,9 +501,14 @@ void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
 
 	/* full GPU reset or device model level reset */
 	if (engine_mask == ALL_ENGINES || dmlr) {
+
 		intel_vgpu_reset_gtt(vgpu, dmlr);
-		intel_vgpu_reset_resource(vgpu);
-		intel_vgpu_reset_mmio(vgpu);
+
+		/*fence will not be reset during virtual reset */
+		if (dmlr)
+			intel_vgpu_reset_resource(vgpu);
+
+		intel_vgpu_reset_mmio(vgpu, dmlr);
 		populate_pvinfo_page(vgpu);
 		intel_vgpu_reset_display(vgpu);
 

commit 856ee92e8602bd86d34388ac08381c5cb3918756
Merge: a6a5c983b35e 4f7d029b9bf0
Author: Dave Airlie <airlied@redhat.com>
Date:   Wed Apr 19 11:07:14 2017 +1000

    Merge tag 'v4.11-rc7' into drm-next
    
    Backmerge Linux 4.11-rc7 from Linus tree, to fix some
    conflicts that were causing problems with the rerere cache
    in drm-tip.

commit cf082a4a264d5e0bb79f0055be02d255438836a4
Merge: ecf8e89917d6 aa4ce4493c88
Author: Jani Nikula <jani.nikula@intel.com>
Date:   Mon Apr 3 18:14:06 2017 +0300

    Merge tag 'gvt-fixes-2017-04-01' of https://github.com/01org/gvt-linux into drm-intel-fixes
    
    gvt-fixes-2017-04-01
    
    - Fix cfg space in failsafe (Changbin)
    - Fix a race for irq inject with vgpu release (Zhi)
    - Fix golden state firmware load (Zhi)
    
    Link: http://patchwork.freedesktop.org/patch/msgid/20170401080650.6cvqon7nsbziwnyc@zhen-hp.sh.intel.com
    Signed-off-by: Jani Nikula <jani.nikula@intel.com>

commit 729a0cd45c886a8d1ae0b3063b20d525fc729523
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Mon Mar 27 17:41:02 2017 +0800

    drm/i915/gvt: adjust mem size for low resolution type
    
    From commit d1a513be1f0a ("drm/i915/gvt: add resolution definition for vGPU
    type"), small type has been restricted to small resolution, so not
    require larger high GM size any more. Change to smaller 384M for more
    VM creation with vGPU enabled which still perform reasonable workload.
    
    Fixes: d1a513be1f0a ("drm/i915/gvt: add resolution definition for vGPU type")
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    (cherry picked from commit bf39ec335eb8cc51b4e1c9303ef92b380d204bb1)
    Signed-off-by: Jani Nikula <jani.nikula@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 41cfa5ccae84..d8d128625331 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -72,7 +72,7 @@ static struct {
 	char *name;
 } vgpu_types[] = {
 /* Fixed vGPU type table */
-	{ MB_TO_BYTES(64), MB_TO_BYTES(512), 4, GVT_EDID_1024_768, "8" },
+	{ MB_TO_BYTES(64), MB_TO_BYTES(384), 4, GVT_EDID_1024_768, "8" },
 	{ MB_TO_BYTES(128), MB_TO_BYTES(512), 4, GVT_EDID_1920_1200, "4" },
 	{ MB_TO_BYTES(256), MB_TO_BYTES(1024), 4, GVT_EDID_1920_1200, "2" },
 	{ MB_TO_BYTES(512), MB_TO_BYTES(2048), 4, GVT_EDID_1920_1200, "1" },

commit b79c52aef3cdee903017c1e9834b53996d70010e
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Thu Mar 30 01:48:39 2017 +0800

    drm/i915/gvt: Activate/de-activate vGPU in mdev ops.
    
    This patch introduces two functions for activating/de-activating vGPU in
    mdev ops.
    
    A racing condition was found between virtual vblank emulation and KVGMT
    mdev release path. V-blank emulation will emulate and inject V-blank
    interrupt for every active vGPU with holding gvt->lock, while in mdev
    release path, it will directly release hypervisor handle without changing
    vGPU status or taking gvt->lock, so a kernel oops is encountered when
    vblank emulation is injecting a interrupt with a invalid hypervisor
    handle. (Reported by Terrence)
    
    To solve this problem, we factor out vGPU activation/de-activation from
    vGPU creation/destruction path and let KVMGT mdev release ops de-activate
    the vGPU before release hypervisor handle. Once a vGPU is de-activated,
    GVT-g will not emulate v-blank for it or touch the hypervisor handle.
    
    Fixes: 659643f ("drm/i915/gvt/kvmgt: add vfio/mdev support to KVMGT")
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 41cfa5ccae84..2f5792a1ce38 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -179,20 +179,34 @@ static void intel_gvt_update_vgpu_types(struct intel_gvt *gvt)
 }
 
 /**
- * intel_gvt_destroy_vgpu - destroy a virtual GPU
+ * intel_gvt_active_vgpu - activate a virtual GPU
  * @vgpu: virtual GPU
  *
- * This function is called when user wants to destroy a virtual GPU.
+ * This function is called when user wants to activate a virtual GPU.
  *
  */
-void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
+void intel_gvt_activate_vgpu(struct intel_vgpu *vgpu)
+{
+	mutex_lock(&vgpu->gvt->lock);
+	vgpu->active = true;
+	mutex_unlock(&vgpu->gvt->lock);
+}
+
+/**
+ * intel_gvt_deactive_vgpu - deactivate a virtual GPU
+ * @vgpu: virtual GPU
+ *
+ * This function is called when user wants to deactivate a virtual GPU.
+ * All virtual GPU runtime information will be destroyed.
+ *
+ */
+void intel_gvt_deactivate_vgpu(struct intel_vgpu *vgpu)
 {
 	struct intel_gvt *gvt = vgpu->gvt;
 
 	mutex_lock(&gvt->lock);
 
 	vgpu->active = false;
-	idr_remove(&gvt->vgpu_idr, vgpu->id);
 
 	if (atomic_read(&vgpu->running_workload_num)) {
 		mutex_unlock(&gvt->lock);
@@ -201,6 +215,26 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 	}
 
 	intel_vgpu_stop_schedule(vgpu);
+
+	mutex_unlock(&gvt->lock);
+}
+
+/**
+ * intel_gvt_destroy_vgpu - destroy a virtual GPU
+ * @vgpu: virtual GPU
+ *
+ * This function is called when user wants to destroy a virtual GPU.
+ *
+ */
+void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
+{
+	struct intel_gvt *gvt = vgpu->gvt;
+
+	mutex_lock(&gvt->lock);
+
+	WARN(vgpu->active, "vGPU is still active!\n");
+
+	idr_remove(&gvt->vgpu_idr, vgpu->id);
 	intel_vgpu_clean_sched_policy(vgpu);
 	intel_vgpu_clean_gvt_context(vgpu);
 	intel_vgpu_clean_execlist(vgpu);
@@ -277,7 +311,6 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_clean_shadow_ctx;
 
-	vgpu->active = true;
 	mutex_unlock(&gvt->lock);
 
 	return vgpu;

commit afe04fbe6c522e73d5cc61a6660cce0e78630786
Author: Ping Gao <ping.a.gao@intel.com>
Date:   Thu Mar 30 00:36:39 2017 +0800

    drm/i915/gvt: create an idle vGPU
    
    vGPU resource is allocated by scheduler. To account for non-allocated
    free cycles, we create an idle vGPU as the placeholder similar to idle task
    concept, which is useful to handle some corner cases in scheduling policy.
    
    Signed-off-by: Ping Gao <ping.a.gao@intel.com>
    Reviewed-by: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 36c107e2058a..6ba02525e905 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -233,6 +233,59 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 	mutex_unlock(&gvt->lock);
 }
 
+#define IDLE_VGPU_IDR 0
+
+/**
+ * intel_gvt_create_idle_vgpu - create an idle virtual GPU
+ * @gvt: GVT device
+ *
+ * This function is called when user wants to create an idle virtual GPU.
+ *
+ * Returns:
+ * pointer to intel_vgpu, error pointer if failed.
+ */
+struct intel_vgpu *intel_gvt_create_idle_vgpu(struct intel_gvt *gvt)
+{
+	struct intel_vgpu *vgpu;
+	enum intel_engine_id i;
+	int ret;
+
+	vgpu = vzalloc(sizeof(*vgpu));
+	if (!vgpu)
+		return ERR_PTR(-ENOMEM);
+
+	vgpu->id = IDLE_VGPU_IDR;
+	vgpu->gvt = gvt;
+
+	for (i = 0; i < I915_NUM_ENGINES; i++)
+		INIT_LIST_HEAD(&vgpu->workload_q_head[i]);
+
+	ret = intel_vgpu_init_sched_policy(vgpu);
+	if (ret)
+		goto out_free_vgpu;
+
+	vgpu->active = false;
+
+	return vgpu;
+
+out_free_vgpu:
+	vfree(vgpu);
+	return ERR_PTR(ret);
+}
+
+/**
+ * intel_gvt_destroy_vgpu - destroy an idle virtual GPU
+ * @vgpu: virtual GPU
+ *
+ * This function is called when user wants to destroy an idle virtual GPU.
+ *
+ */
+void intel_gvt_destroy_idle_vgpu(struct intel_vgpu *vgpu)
+{
+	intel_vgpu_clean_sched_policy(vgpu);
+	vfree(vgpu);
+}
+
 static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 		struct intel_vgpu_creation_params *param)
 {
@@ -249,7 +302,8 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 
 	mutex_lock(&gvt->lock);
 
-	ret = idr_alloc(&gvt->vgpu_idr, vgpu, 1, GVT_MAX_VGPU, GFP_KERNEL);
+	ret = idr_alloc(&gvt->vgpu_idr, vgpu, IDLE_VGPU_IDR + 1, GVT_MAX_VGPU,
+		GFP_KERNEL);
 	if (ret < 0)
 		goto out_free_vgpu;
 

commit bc90d097ae144fab1f789f8523b621de7125c6a8
Author: Ping Gao <ping.a.gao@intel.com>
Date:   Thu Mar 30 00:36:37 2017 +0800

    drm/i915/gvt: define weight according to vGPU type
    
    The weight defines proportional control of physical GPU resource
    shared between vGPUs. So far the weight is tied to a specific vGPU
    type, i.e when creating multiple vGPUs with different types, they
    will inherit different weights.
    
    e.g. The weight of type GVTg_V5_2 is 8, the weight of type GVTg_V5_4
    is 4, so vGPU of type GVTg_V5_2 has double vGPU resource of vGPU type
    GVTg_V5_4.
    
    TODO: allow user control the weight setting in the future.
    
    Signed-off-by: Ping Gao <ping.a.gao@intel.com>
    Reviewed-by: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index d8d128625331..36c107e2058a 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -64,18 +64,28 @@ void populate_pvinfo_page(struct intel_vgpu *vgpu)
 	WARN_ON(sizeof(struct vgt_if) != VGT_PVINFO_SIZE);
 }
 
+#define VGPU_MAX_WEIGHT 16
+#define VGPU_WEIGHT(vgpu_num)	\
+	(VGPU_MAX_WEIGHT / (vgpu_num))
+
 static struct {
 	unsigned int low_mm;
 	unsigned int high_mm;
 	unsigned int fence;
+
+	/* A vGPU with a weight of 8 will get twice as much GPU as a vGPU
+	 * with a weight of 4 on a contended host, different vGPU type has
+	 * different weight set. Legal weights range from 1 to 16.
+	 */
+	unsigned int weight;
 	enum intel_vgpu_edid edid;
 	char *name;
 } vgpu_types[] = {
 /* Fixed vGPU type table */
-	{ MB_TO_BYTES(64), MB_TO_BYTES(384), 4, GVT_EDID_1024_768, "8" },
-	{ MB_TO_BYTES(128), MB_TO_BYTES(512), 4, GVT_EDID_1920_1200, "4" },
-	{ MB_TO_BYTES(256), MB_TO_BYTES(1024), 4, GVT_EDID_1920_1200, "2" },
-	{ MB_TO_BYTES(512), MB_TO_BYTES(2048), 4, GVT_EDID_1920_1200, "1" },
+	{ MB_TO_BYTES(64), MB_TO_BYTES(384), 4, VGPU_WEIGHT(8), GVT_EDID_1024_768, "8" },
+	{ MB_TO_BYTES(128), MB_TO_BYTES(512), 4, VGPU_WEIGHT(4), GVT_EDID_1920_1200, "4" },
+	{ MB_TO_BYTES(256), MB_TO_BYTES(1024), 4, VGPU_WEIGHT(2), GVT_EDID_1920_1200, "2" },
+	{ MB_TO_BYTES(512), MB_TO_BYTES(2048), 4, VGPU_WEIGHT(1), GVT_EDID_1920_1200, "1" },
 };
 
 /**
@@ -120,6 +130,12 @@ int intel_gvt_init_vgpu_types(struct intel_gvt *gvt)
 		gvt->types[i].low_gm_size = vgpu_types[i].low_mm;
 		gvt->types[i].high_gm_size = vgpu_types[i].high_mm;
 		gvt->types[i].fence = vgpu_types[i].fence;
+
+		if (vgpu_types[i].weight < 1 ||
+					vgpu_types[i].weight > VGPU_MAX_WEIGHT)
+			return -EINVAL;
+
+		gvt->types[i].weight = vgpu_types[i].weight;
 		gvt->types[i].resolution = vgpu_types[i].edid;
 		gvt->types[i].avail_instance = min(low_avail / vgpu_types[i].low_mm,
 						   high_avail / vgpu_types[i].high_mm);
@@ -131,11 +147,12 @@ int intel_gvt_init_vgpu_types(struct intel_gvt *gvt)
 			sprintf(gvt->types[i].name, "GVTg_V5_%s",
 						vgpu_types[i].name);
 
-		gvt_dbg_core("type[%d]: %s avail %u low %u high %u fence %u res %s\n",
+		gvt_dbg_core("type[%d]: %s avail %u low %u high %u fence %u weight %u res %s\n",
 			     i, gvt->types[i].name,
 			     gvt->types[i].avail_instance,
 			     gvt->types[i].low_gm_size,
 			     gvt->types[i].high_gm_size, gvt->types[i].fence,
+			     gvt->types[i].weight,
 			     vgpu_edid_str(gvt->types[i].resolution));
 	}
 
@@ -239,6 +256,7 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	vgpu->id = ret;
 	vgpu->handle = param->handle;
 	vgpu->gvt = gvt;
+	vgpu->sched_ctl.weight = param->weight;
 	bitmap_zero(vgpu->tlb_handle_pending, I915_NUM_ENGINES);
 
 	intel_vgpu_init_cfg_space(vgpu, param->primary);
@@ -325,6 +343,7 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	param.low_gm_sz = type->low_gm_size;
 	param.high_gm_sz = type->high_gm_size;
 	param.fence_sz = type->fence;
+	param.weight = type->weight;
 	param.resolution = type->resolution;
 
 	/* XXX current param based on MB */

commit bf39ec335eb8cc51b4e1c9303ef92b380d204bb1
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Mon Mar 27 17:41:02 2017 +0800

    drm/i915/gvt: adjust mem size for low resolution type
    
    From commit d1a513be1f0a ("drm/i915/gvt: add resolution definition for vGPU
    type"), small type has been restricted to small resolution, so not
    require larger high GM size any more. Change to smaller 384M for more
    VM creation with vGPU enabled which still perform reasonable workload.
    
    Fixes: d1a513be1f0a ("drm/i915/gvt: add resolution definition for vGPU type")
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 41cfa5ccae84..d8d128625331 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -72,7 +72,7 @@ static struct {
 	char *name;
 } vgpu_types[] = {
 /* Fixed vGPU type table */
-	{ MB_TO_BYTES(64), MB_TO_BYTES(512), 4, GVT_EDID_1024_768, "8" },
+	{ MB_TO_BYTES(64), MB_TO_BYTES(384), 4, GVT_EDID_1024_768, "8" },
 	{ MB_TO_BYTES(128), MB_TO_BYTES(512), 4, GVT_EDID_1920_1200, "4" },
 	{ MB_TO_BYTES(256), MB_TO_BYTES(1024), 4, GVT_EDID_1920_1200, "2" },
 	{ MB_TO_BYTES(512), MB_TO_BYTES(2048), 4, GVT_EDID_1920_1200, "1" },

commit d1a513be1f0a25f094e1577d059b9aebaa279bb2
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Fri Feb 24 10:58:21 2017 +0800

    drm/i915/gvt: add resolution definition for vGPU type
    
    This assigns resolution definition for each vGPU type. For smaller
    resource type we should limit max resolution, so e.g limit to 1024x768
    for 64M type, others are still default to 1920x1200.
    
    v2: Fix for actual 1920x1200 resolution
    
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index c27c13c3cc48..41cfa5ccae84 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -68,13 +68,14 @@ static struct {
 	unsigned int low_mm;
 	unsigned int high_mm;
 	unsigned int fence;
+	enum intel_vgpu_edid edid;
 	char *name;
 } vgpu_types[] = {
 /* Fixed vGPU type table */
-	{ MB_TO_BYTES(64), MB_TO_BYTES(512), 4, "8" },
-	{ MB_TO_BYTES(128), MB_TO_BYTES(512), 4, "4" },
-	{ MB_TO_BYTES(256), MB_TO_BYTES(1024), 4, "2" },
-	{ MB_TO_BYTES(512), MB_TO_BYTES(2048), 4, "1" },
+	{ MB_TO_BYTES(64), MB_TO_BYTES(512), 4, GVT_EDID_1024_768, "8" },
+	{ MB_TO_BYTES(128), MB_TO_BYTES(512), 4, GVT_EDID_1920_1200, "4" },
+	{ MB_TO_BYTES(256), MB_TO_BYTES(1024), 4, GVT_EDID_1920_1200, "2" },
+	{ MB_TO_BYTES(512), MB_TO_BYTES(2048), 4, GVT_EDID_1920_1200, "1" },
 };
 
 /**
@@ -119,6 +120,7 @@ int intel_gvt_init_vgpu_types(struct intel_gvt *gvt)
 		gvt->types[i].low_gm_size = vgpu_types[i].low_mm;
 		gvt->types[i].high_gm_size = vgpu_types[i].high_mm;
 		gvt->types[i].fence = vgpu_types[i].fence;
+		gvt->types[i].resolution = vgpu_types[i].edid;
 		gvt->types[i].avail_instance = min(low_avail / vgpu_types[i].low_mm,
 						   high_avail / vgpu_types[i].high_mm);
 
@@ -129,11 +131,12 @@ int intel_gvt_init_vgpu_types(struct intel_gvt *gvt)
 			sprintf(gvt->types[i].name, "GVTg_V5_%s",
 						vgpu_types[i].name);
 
-		gvt_dbg_core("type[%d]: %s avail %u low %u high %u fence %u\n",
+		gvt_dbg_core("type[%d]: %s avail %u low %u high %u fence %u res %s\n",
 			     i, gvt->types[i].name,
 			     gvt->types[i].avail_instance,
 			     gvt->types[i].low_gm_size,
-			     gvt->types[i].high_gm_size, gvt->types[i].fence);
+			     gvt->types[i].high_gm_size, gvt->types[i].fence,
+			     vgpu_edid_str(gvt->types[i].resolution));
 	}
 
 	gvt->num_types = i;
@@ -258,7 +261,7 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_detach_hypervisor_vgpu;
 
-	ret = intel_vgpu_init_display(vgpu);
+	ret = intel_vgpu_init_display(vgpu, param->resolution);
 	if (ret)
 		goto out_clean_gtt;
 
@@ -322,6 +325,7 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	param.low_gm_sz = type->low_gm_size;
 	param.high_gm_sz = type->high_gm_size;
 	param.fence_sz = type->fence;
+	param.resolution = type->resolution;
 
 	/* XXX current param based on MB */
 	param.low_gm_sz = BYTES_TO_MB(param.low_gm_sz);

commit 191020b670f84f5e2edfaa906c3801df20485610
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Thu Feb 23 14:46:23 2017 +0800

    drm/i915/gvt: adjust to fixed vGPU types
    
    Previous vGPU type create tried to determine vGPU type name e.g _1, _2
    based on the number of mdev devices can be created, but different type
    might have very different resource size depending on physical device.
    We need to split type name vs. actual mdev resource and create fixed
    vGPU type with determined size for consistence.
    
    With this we'd like to fix vGPU types for _1, _2, _4 and _8 now, each
    type has fixed defined resource size. Available mdev instances that could
    be created is determined by physical resource, and user should query
    for that before creating.
    
    Cc: Kevin Tian <kevin.tian@intel.com>
    Reviewed-by: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index dcfcce1dc00e..c27c13c3cc48 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -64,6 +64,19 @@ void populate_pvinfo_page(struct intel_vgpu *vgpu)
 	WARN_ON(sizeof(struct vgt_if) != VGT_PVINFO_SIZE);
 }
 
+static struct {
+	unsigned int low_mm;
+	unsigned int high_mm;
+	unsigned int fence;
+	char *name;
+} vgpu_types[] = {
+/* Fixed vGPU type table */
+	{ MB_TO_BYTES(64), MB_TO_BYTES(512), 4, "8" },
+	{ MB_TO_BYTES(128), MB_TO_BYTES(512), 4, "4" },
+	{ MB_TO_BYTES(256), MB_TO_BYTES(1024), 4, "2" },
+	{ MB_TO_BYTES(512), MB_TO_BYTES(2048), 4, "1" },
+};
+
 /**
  * intel_gvt_init_vgpu_types - initialize vGPU type list
  * @gvt : GVT device
@@ -78,9 +91,8 @@ int intel_gvt_init_vgpu_types(struct intel_gvt *gvt)
 	unsigned int min_low;
 
 	/* vGPU type name is defined as GVTg_Vx_y which contains
-	 * physical GPU generation type and 'y' means maximum vGPU
-	 * instances user can create on one physical GPU for this
-	 * type.
+	 * physical GPU generation type (e.g V4 as BDW server, V5 as
+	 * SKL server).
 	 *
 	 * Depend on physical SKU resource, might see vGPU types like
 	 * GVTg_V4_8, GVTg_V4_4, GVTg_V4_2, etc. We can create
@@ -92,7 +104,7 @@ int intel_gvt_init_vgpu_types(struct intel_gvt *gvt)
 	 */
 	low_avail = gvt_aperture_sz(gvt) - HOST_LOW_GM_SIZE;
 	high_avail = gvt_hidden_sz(gvt) - HOST_HIGH_GM_SIZE;
-	num_types = 4;
+	num_types = sizeof(vgpu_types) / sizeof(vgpu_types[0]);
 
 	gvt->types = kzalloc(num_types * sizeof(struct intel_vgpu_type),
 			     GFP_KERNEL);
@@ -101,25 +113,24 @@ int intel_gvt_init_vgpu_types(struct intel_gvt *gvt)
 
 	min_low = MB_TO_BYTES(32);
 	for (i = 0; i < num_types; ++i) {
-		if (low_avail / min_low == 0)
+		if (low_avail / vgpu_types[i].low_mm == 0)
 			break;
-		gvt->types[i].low_gm_size = min_low;
-		gvt->types[i].high_gm_size = max((min_low<<3), MB_TO_BYTES(384U));
-		gvt->types[i].fence = 4;
-		gvt->types[i].max_instance = min(low_avail / min_low,
-						 high_avail / gvt->types[i].high_gm_size);
-		gvt->types[i].avail_instance = gvt->types[i].max_instance;
+
+		gvt->types[i].low_gm_size = vgpu_types[i].low_mm;
+		gvt->types[i].high_gm_size = vgpu_types[i].high_mm;
+		gvt->types[i].fence = vgpu_types[i].fence;
+		gvt->types[i].avail_instance = min(low_avail / vgpu_types[i].low_mm,
+						   high_avail / vgpu_types[i].high_mm);
 
 		if (IS_GEN8(gvt->dev_priv))
-			sprintf(gvt->types[i].name, "GVTg_V4_%u",
-						gvt->types[i].max_instance);
+			sprintf(gvt->types[i].name, "GVTg_V4_%s",
+						vgpu_types[i].name);
 		else if (IS_GEN9(gvt->dev_priv))
-			sprintf(gvt->types[i].name, "GVTg_V5_%u",
-						gvt->types[i].max_instance);
+			sprintf(gvt->types[i].name, "GVTg_V5_%s",
+						vgpu_types[i].name);
 
-		min_low <<= 1;
-		gvt_dbg_core("type[%d]: %s max %u avail %u low %u high %u fence %u\n",
-			     i, gvt->types[i].name, gvt->types[i].max_instance,
+		gvt_dbg_core("type[%d]: %s avail %u low %u high %u fence %u\n",
+			     i, gvt->types[i].name,
 			     gvt->types[i].avail_instance,
 			     gvt->types[i].low_gm_size,
 			     gvt->types[i].high_gm_size, gvt->types[i].fence);
@@ -138,7 +149,7 @@ static void intel_gvt_update_vgpu_types(struct intel_gvt *gvt)
 {
 	int i;
 	unsigned int low_gm_avail, high_gm_avail, fence_avail;
-	unsigned int low_gm_min, high_gm_min, fence_min, total_min;
+	unsigned int low_gm_min, high_gm_min, fence_min;
 
 	/* Need to depend on maxium hw resource size but keep on
 	 * static config for now.
@@ -154,12 +165,11 @@ static void intel_gvt_update_vgpu_types(struct intel_gvt *gvt)
 		low_gm_min = low_gm_avail / gvt->types[i].low_gm_size;
 		high_gm_min = high_gm_avail / gvt->types[i].high_gm_size;
 		fence_min = fence_avail / gvt->types[i].fence;
-		total_min = min(min(low_gm_min, high_gm_min), fence_min);
-		gvt->types[i].avail_instance = min(gvt->types[i].max_instance,
-						   total_min);
+		gvt->types[i].avail_instance = min(min(low_gm_min, high_gm_min),
+						   fence_min);
 
-		gvt_dbg_core("update type[%d]: %s max %u avail %u low %u high %u fence %u\n",
-		       i, gvt->types[i].name, gvt->types[i].max_instance,
+		gvt_dbg_core("update type[%d]: %s avail %u low %u high %u fence %u\n",
+		       i, gvt->types[i].name,
 		       gvt->types[i].avail_instance, gvt->types[i].low_gm_size,
 		       gvt->types[i].high_gm_size, gvt->types[i].fence);
 	}

commit fd64be636708d808852c4c8c1efce0a0a51c24c5
Author: Min He <min.he@intel.com>
Date:   Fri Feb 17 15:02:36 2017 +0800

    drm/i915/gvt: introduced failsafe mode into vgpu
    
    New failsafe mode is introduced, when we detect guest not supporting
    GVT-g.
    In failsafe mode, we will ignore all the MMIO and cfg space read/write
    from guest.
    
    This patch can fix the issue that when guest kernel or graphics driver
    version is too low, there will be a lot of kernel traces in host.
    
    V5: rebased onto latest gvt-staging
    V4: changed coding style by Zhenyu and Ping's advice
    V3: modified coding style and error messages according to Zhenyu's comment
    V2: 1) implemented MMIO/GTT/WP pages read/write logic; 2) used a unified
    function to enter failsafe mode
    
    Signed-off-by: Min He <min.he@intel.com>
    Signed-off-by: Pei Zhang <pei.zhang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 95a97aa0051e..dcfcce1dc00e 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -387,8 +387,12 @@ void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
 		populate_pvinfo_page(vgpu);
 		intel_vgpu_reset_display(vgpu);
 
-		if (dmlr)
+		if (dmlr) {
 			intel_vgpu_reset_cfg_space(vgpu);
+			/* only reset the failsafe mode when dmlr reset */
+			vgpu->failsafe = false;
+			vgpu->pv_notified = false;
+		}
 	}
 
 	vgpu->resetting = false;

commit 6294b61ba769ba2cc4a182c32410aa4a75808fea
Author: Changbin Du <changbin.du@intel.com>
Date:   Tue Feb 14 14:50:18 2017 +0800

    drm/i915/gvt: add missing display part reset for vGPU reset
    
    We also need reset vGPU virtual display emulation. Since all vreg has
    been cleared, we need reset display related vreg to reflect our display
    setting.
    
    Signed-off-by: Changbin Du <changbin.du@intel.com>
    Cc: Ping Gao <ping.a.gao@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 67d471cee79e..95a97aa0051e 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -385,6 +385,7 @@ void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
 		intel_vgpu_reset_resource(vgpu);
 		intel_vgpu_reset_mmio(vgpu);
 		populate_pvinfo_page(vgpu);
+		intel_vgpu_reset_display(vgpu);
 
 		if (dmlr)
 			intel_vgpu_reset_cfg_space(vgpu);

commit 2d6ceb8e654a0ce998762b13f0ba2c275220a244
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Fri Jan 13 15:36:17 2017 +0800

    drm/i915/gvt: fix vgpu type size init
    
    As now gvt init after knowing hw resource info, we can determine vGPU
    type from machine size instead of pre-defined value.
    
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 7295bc8e12fb..67d471cee79e 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -74,7 +74,7 @@ void populate_pvinfo_page(struct intel_vgpu *vgpu)
 int intel_gvt_init_vgpu_types(struct intel_gvt *gvt)
 {
 	unsigned int num_types;
-	unsigned int i, low_avail;
+	unsigned int i, low_avail, high_avail;
 	unsigned int min_low;
 
 	/* vGPU type name is defined as GVTg_Vx_y which contains
@@ -89,9 +89,9 @@ int intel_gvt_init_vgpu_types(struct intel_gvt *gvt)
 	 * to indicate how many vGPU instance can be created for this
 	 * type.
 	 *
-	 * Currently use static size here as we init type earlier..
 	 */
-	low_avail = MB_TO_BYTES(256) - HOST_LOW_GM_SIZE;
+	low_avail = gvt_aperture_sz(gvt) - HOST_LOW_GM_SIZE;
+	high_avail = gvt_hidden_sz(gvt) - HOST_HIGH_GM_SIZE;
 	num_types = 4;
 
 	gvt->types = kzalloc(num_types * sizeof(struct intel_vgpu_type),
@@ -106,7 +106,8 @@ int intel_gvt_init_vgpu_types(struct intel_gvt *gvt)
 		gvt->types[i].low_gm_size = min_low;
 		gvt->types[i].high_gm_size = max((min_low<<3), MB_TO_BYTES(384U));
 		gvt->types[i].fence = 4;
-		gvt->types[i].max_instance = low_avail / min_low;
+		gvt->types[i].max_instance = min(low_avail / min_low,
+						 high_avail / gvt->types[i].high_gm_size);
 		gvt->types[i].avail_instance = gvt->types[i].max_instance;
 
 		if (IS_GEN8(gvt->dev_priv))
@@ -142,9 +143,9 @@ static void intel_gvt_update_vgpu_types(struct intel_gvt *gvt)
 	/* Need to depend on maxium hw resource size but keep on
 	 * static config for now.
 	 */
-	low_gm_avail = MB_TO_BYTES(256) - HOST_LOW_GM_SIZE -
+	low_gm_avail = gvt_aperture_sz(gvt) - HOST_LOW_GM_SIZE -
 		gvt->gm.vgpu_allocated_low_gm_size;
-	high_gm_avail = MB_TO_BYTES(256) * 8UL - HOST_HIGH_GM_SIZE -
+	high_gm_avail = gvt_hidden_sz(gvt) - HOST_HIGH_GM_SIZE -
 		gvt->gm.vgpu_allocated_high_gm_size;
 	fence_avail = gvt_fence_sz(gvt) - HOST_FENCE -
 		gvt->fence.vgpu_allocated_fence_num;

commit cfe65f4037cedb911a840ebcf6dafc5b69e535b4
Author: Changbin Du <changbin.du@intel.com>
Date:   Fri Jan 13 11:16:02 2017 +0800

    drm/i915/gvt: fix vGPU instance reuse issues by vGPU reset function
    
    Our function tests found several issues related to reusing vGPU
    instance. They are qemu reboot failure, guest tdr after reboot, host
    hang when reboot guest. All these issues are caused by dirty status
    inherited from last VM.
    
    This patch fix all these issues by resetting a virtual GPU before VM
    use it. The reset logical is put into a low level function
    _intel_gvt_reset_vgpu(), which supports Device Model Level Reset, Full
    GT Reset and Per-Engine Reset.
    
    vGPU Device Model Level Reset (DMLR) simulates the PCI reset to reset
    the whole vGPU to default state as when it is created, including GTT,
    execlist, scratch pages, cfg space, mmio space, pvinfo page, scheduler
    and fence registers. The ultimate goal of vGPU DMLR is that reuse a
    vGPU instance by different virtual machines. When we reassign a vGPU
    to a virtual machine we must issue such reset first.
    
    Full GT Reset and Per-Engine GT Reset are soft reset flow for GPU engines
    (Render, Blitter, Video, Video Enhancement). It is defined by GPU Spec.
    Unlike the FLR, GT reset only reset particular resource of a vGPU per
    the reset request. Guest driver can issue a GT reset by programming
    the virtual GDRST register to reset specific virtual GPU engine or all
    engines.
    
    Since vGPU DMLR and GT reset can share some code so we implement both
    these two into one single function intel_gvt_reset_vgpu_locked(). The
    parameter dmlr is to identify if we will do FLR or GT reset. The
    parameter engine_mask is to specific the engines that need to be
    resetted. If value ALL_ENGINES is given for engine_mask, it means
    the caller requests a full gt reset that we will reset all virtual
    GPU engines.
    
    Signed-off-by: Changbin Du <changbin.du@intel.com>
    Reviewed-by: Jike Song <jike.song@intel.com>
    Reviewed-by: Kevin Tian <kevin.tian@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 958c3ed1c6c6..7295bc8e12fb 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -327,7 +327,75 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
 }
 
 /**
- * intel_gvt_reset_vgpu - reset a virtual GPU
+ * intel_gvt_reset_vgpu_locked - reset a virtual GPU by DMLR or GT reset
+ * @vgpu: virtual GPU
+ * @dmlr: vGPU Device Model Level Reset or GT Reset
+ * @engine_mask: engines to reset for GT reset
+ *
+ * This function is called when user wants to reset a virtual GPU through
+ * device model reset or GT reset. The caller should hold the gvt lock.
+ *
+ * vGPU Device Model Level Reset (DMLR) simulates the PCI level reset to reset
+ * the whole vGPU to default state as when it is created. This vGPU function
+ * is required both for functionary and security concerns.The ultimate goal
+ * of vGPU FLR is that reuse a vGPU instance by virtual machines. When we
+ * assign a vGPU to a virtual machine we must isse such reset first.
+ *
+ * Full GT Reset and Per-Engine GT Reset are soft reset flow for GPU engines
+ * (Render, Blitter, Video, Video Enhancement). It is defined by GPU Spec.
+ * Unlike the FLR, GT reset only reset particular resource of a vGPU per
+ * the reset request. Guest driver can issue a GT reset by programming the
+ * virtual GDRST register to reset specific virtual GPU engine or all
+ * engines.
+ *
+ * The parameter dev_level is to identify if we will do DMLR or GT reset.
+ * The parameter engine_mask is to specific the engines that need to be
+ * resetted. If value ALL_ENGINES is given for engine_mask, it means
+ * the caller requests a full GT reset that we will reset all virtual
+ * GPU engines. For FLR, engine_mask is ignored.
+ */
+void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
+				 unsigned int engine_mask)
+{
+	struct intel_gvt *gvt = vgpu->gvt;
+	struct intel_gvt_workload_scheduler *scheduler = &gvt->scheduler;
+
+	gvt_dbg_core("------------------------------------------\n");
+	gvt_dbg_core("resseting vgpu%d, dmlr %d, engine_mask %08x\n",
+		     vgpu->id, dmlr, engine_mask);
+	vgpu->resetting = true;
+
+	intel_vgpu_stop_schedule(vgpu);
+	/*
+	 * The current_vgpu will set to NULL after stopping the
+	 * scheduler when the reset is triggered by current vgpu.
+	 */
+	if (scheduler->current_vgpu == NULL) {
+		mutex_unlock(&gvt->lock);
+		intel_gvt_wait_vgpu_idle(vgpu);
+		mutex_lock(&gvt->lock);
+	}
+
+	intel_vgpu_reset_execlist(vgpu, dmlr ? ALL_ENGINES : engine_mask);
+
+	/* full GPU reset or device model level reset */
+	if (engine_mask == ALL_ENGINES || dmlr) {
+		intel_vgpu_reset_gtt(vgpu, dmlr);
+		intel_vgpu_reset_resource(vgpu);
+		intel_vgpu_reset_mmio(vgpu);
+		populate_pvinfo_page(vgpu);
+
+		if (dmlr)
+			intel_vgpu_reset_cfg_space(vgpu);
+	}
+
+	vgpu->resetting = false;
+	gvt_dbg_core("reset vgpu%d done\n", vgpu->id);
+	gvt_dbg_core("------------------------------------------\n");
+}
+
+/**
+ * intel_gvt_reset_vgpu - reset a virtual GPU (Function Level)
  * @vgpu: virtual GPU
  *
  * This function is called when user wants to reset a virtual GPU.
@@ -335,4 +403,7 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
  */
 void intel_gvt_reset_vgpu(struct intel_vgpu *vgpu)
 {
+	mutex_lock(&vgpu->gvt->lock);
+	intel_gvt_reset_vgpu_locked(vgpu, true, 0);
+	mutex_unlock(&vgpu->gvt->lock);
 }

commit cdcc43479c9b929940a1955d2e7bae696d2b9496
Author: Changbin Du <changbin.du@intel.com>
Date:   Fri Jan 13 11:16:00 2017 +0800

    drm/i915/gvt: move mmio init/clean function to mmio.c
    
    Move the mmio space inititation function setup_vgpu_mmio()
    and cleanup function clean_vgpu_mmio() in vgpu.c to dedicated
    source file mmio.c, and rename them as intel_vgpu_init_mmio()
    and intel_vgpu_clean_mmio() respectively.
    
    Signed-off-by: Changbin Du <changbin.du@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 35c274177da8..958c3ed1c6c6 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -35,37 +35,6 @@
 #include "gvt.h"
 #include "i915_pvinfo.h"
 
-static void clean_vgpu_mmio(struct intel_vgpu *vgpu)
-{
-	vfree(vgpu->mmio.vreg);
-	vgpu->mmio.vreg = vgpu->mmio.sreg = NULL;
-}
-
-int setup_vgpu_mmio(struct intel_vgpu *vgpu)
-{
-	struct intel_gvt *gvt = vgpu->gvt;
-	const struct intel_gvt_device_info *info = &gvt->device_info;
-
-	if (vgpu->mmio.vreg)
-		memset(vgpu->mmio.vreg, 0, info->mmio_size * 2);
-	else {
-		vgpu->mmio.vreg = vzalloc(info->mmio_size * 2);
-		if (!vgpu->mmio.vreg)
-			return -ENOMEM;
-	}
-
-	vgpu->mmio.sreg = vgpu->mmio.vreg + info->mmio_size;
-
-	memcpy(vgpu->mmio.vreg, gvt->firmware.mmio, info->mmio_size);
-	memcpy(vgpu->mmio.sreg, gvt->firmware.mmio, info->mmio_size);
-
-	vgpu_vreg(vgpu, GEN6_GT_THREAD_STATUS_REG) = 0;
-
-	/* set the bit 0:2(Core C-State ) to C0 */
-	vgpu_vreg(vgpu, GEN6_GT_CORE_STATUS) = 0;
-	return 0;
-}
-
 void populate_pvinfo_page(struct intel_vgpu *vgpu)
 {
 	/* setup the ballooning information */
@@ -226,7 +195,7 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 	intel_vgpu_clean_gtt(vgpu);
 	intel_gvt_hypervisor_detach_vgpu(vgpu);
 	intel_vgpu_free_resource(vgpu);
-	clean_vgpu_mmio(vgpu);
+	intel_vgpu_clean_mmio(vgpu);
 	vfree(vgpu);
 
 	intel_gvt_update_vgpu_types(gvt);
@@ -260,7 +229,7 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 
 	intel_vgpu_init_cfg_space(vgpu, param->primary);
 
-	ret = setup_vgpu_mmio(vgpu);
+	ret = intel_vgpu_init_mmio(vgpu);
 	if (ret)
 		goto out_clean_idr;
 
@@ -312,7 +281,7 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 out_clean_vgpu_resource:
 	intel_vgpu_free_resource(vgpu);
 out_clean_vgpu_mmio:
-	clean_vgpu_mmio(vgpu);
+	intel_vgpu_clean_mmio(vgpu);
 out_clean_idr:
 	idr_remove(&gvt->vgpu_idr, vgpu->id);
 out_free_vgpu:

commit 536fc234074b09adae1763d8fb5b2d947847ad1d
Author: Changbin Du <changbin.du@intel.com>
Date:   Fri Jan 13 11:15:58 2017 +0800

    drm/i915/gvt: move cfg space inititation function to cfg_space.c
    
    Move the configuration space inititation function setup_vgpu_cfg_space()
    in vgpu.c to dedicated source file cfg_space.c, and rename the function
    as intel_vgpu_init_cfg_space().
    
    Signed-off-by: Changbin Du <changbin.du@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index f0e86123e45b..35c274177da8 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -66,48 +66,6 @@ int setup_vgpu_mmio(struct intel_vgpu *vgpu)
 	return 0;
 }
 
-static void setup_vgpu_cfg_space(struct intel_vgpu *vgpu,
-	struct intel_vgpu_creation_params *param)
-{
-	struct intel_gvt *gvt = vgpu->gvt;
-	const struct intel_gvt_device_info *info = &gvt->device_info;
-	u16 *gmch_ctl;
-	int i;
-
-	memcpy(vgpu_cfg_space(vgpu), gvt->firmware.cfg_space,
-	       info->cfg_space_size);
-
-	if (!param->primary) {
-		vgpu_cfg_space(vgpu)[PCI_CLASS_DEVICE] =
-			INTEL_GVT_PCI_CLASS_VGA_OTHER;
-		vgpu_cfg_space(vgpu)[PCI_CLASS_PROG] =
-			INTEL_GVT_PCI_CLASS_VGA_OTHER;
-	}
-
-	/* Show guest that there isn't any stolen memory.*/
-	gmch_ctl = (u16 *)(vgpu_cfg_space(vgpu) + INTEL_GVT_PCI_GMCH_CONTROL);
-	*gmch_ctl &= ~(BDW_GMCH_GMS_MASK << BDW_GMCH_GMS_SHIFT);
-
-	intel_vgpu_write_pci_bar(vgpu, PCI_BASE_ADDRESS_2,
-				 gvt_aperture_pa_base(gvt), true);
-
-	vgpu_cfg_space(vgpu)[PCI_COMMAND] &= ~(PCI_COMMAND_IO
-					     | PCI_COMMAND_MEMORY
-					     | PCI_COMMAND_MASTER);
-	/*
-	 * Clear the bar upper 32bit and let guest to assign the new value
-	 */
-	memset(vgpu_cfg_space(vgpu) + PCI_BASE_ADDRESS_1, 0, 4);
-	memset(vgpu_cfg_space(vgpu) + PCI_BASE_ADDRESS_3, 0, 4);
-	memset(vgpu_cfg_space(vgpu) + INTEL_GVT_PCI_OPREGION, 0, 4);
-
-	for (i = 0; i < INTEL_GVT_MAX_BAR_NUM; i++) {
-		vgpu->cfg_space.bar[i].size = pci_resource_len(
-					      gvt->dev_priv->drm.pdev, i * 2);
-		vgpu->cfg_space.bar[i].tracked = false;
-	}
-}
-
 void populate_pvinfo_page(struct intel_vgpu *vgpu)
 {
 	/* setup the ballooning information */
@@ -300,7 +258,7 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	vgpu->gvt = gvt;
 	bitmap_zero(vgpu->tlb_handle_pending, I915_NUM_ENGINES);
 
-	setup_vgpu_cfg_space(vgpu, param);
+	intel_vgpu_init_cfg_space(vgpu, param->primary);
 
 	ret = setup_vgpu_mmio(vgpu);
 	if (ret)

commit 4e5378918b5b96e6b93fcadf1ab84a8486ca60a1
Author: Jike Song <jike.song@intel.com>
Date:   Fri Jan 6 15:16:22 2017 +0800

    drm/i915/gvt: destroy the allocated idr on vgpu creating failures
    
    Once idr_alloc gets called data is allocated within the idr list, if
    any error occurs afterwards, we should undo that by idr_remove on the
    error path.
    
    Signed-off-by: Jike Song <jike.song@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 398abb98dd0a..f0e86123e45b 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -304,7 +304,7 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 
 	ret = setup_vgpu_mmio(vgpu);
 	if (ret)
-		goto out_free_vgpu;
+		goto out_clean_idr;
 
 	ret = intel_vgpu_alloc_resource(vgpu, param);
 	if (ret)
@@ -355,6 +355,8 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	intel_vgpu_free_resource(vgpu);
 out_clean_vgpu_mmio:
 	clean_vgpu_mmio(vgpu);
+out_clean_idr:
+	idr_remove(&gvt->vgpu_idr, vgpu->id);
 out_free_vgpu:
 	vfree(vgpu);
 	mutex_unlock(&gvt->lock);

commit 888530b57f88f2bc856f181479df732c9622fa22
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Thu Jan 5 10:26:13 2017 +0800

    drm/i915/gvt: adjust high memory size for default vGPU type
    
    Previous high mem size initialized for vGPU type was too small which caused
    failure for some VMs. This trys to take minimal value of 384MB for each VM and
    enlarge default high mem size to make guest driver happy.
    
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 536d2b9d5777..398abb98dd0a 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -177,7 +177,7 @@ int intel_gvt_init_vgpu_types(struct intel_gvt *gvt)
 		if (low_avail / min_low == 0)
 			break;
 		gvt->types[i].low_gm_size = min_low;
-		gvt->types[i].high_gm_size = 3 * gvt->types[i].low_gm_size;
+		gvt->types[i].high_gm_size = max((min_low<<3), MB_TO_BYTES(384U));
 		gvt->types[i].fence = 4;
 		gvt->types[i].max_instance = low_avail / min_low;
 		gvt->types[i].avail_instance = gvt->types[i].max_instance;
@@ -217,7 +217,7 @@ static void intel_gvt_update_vgpu_types(struct intel_gvt *gvt)
 	 */
 	low_gm_avail = MB_TO_BYTES(256) - HOST_LOW_GM_SIZE -
 		gvt->gm.vgpu_allocated_low_gm_size;
-	high_gm_avail = MB_TO_BYTES(256) * 3 - HOST_HIGH_GM_SIZE -
+	high_gm_avail = MB_TO_BYTES(256) * 8UL - HOST_HIGH_GM_SIZE -
 		gvt->gm.vgpu_allocated_high_gm_size;
 	fence_avail = gvt_fence_sz(gvt) - HOST_FENCE -
 		gvt->fence.vgpu_allocated_fence_num;

commit e992faee1f82cebf39c65b340d7591ab1aa8c742
Author: Du, Changbin <changbin.du@intel.com>
Date:   Mon Nov 21 17:08:14 2016 +0800

    drm/i915/gvt: fix missing init param.primary
    
    Initiate param.primary to 1. We should be primary currently.
    
    Signed-off-by: Du, Changbin <changbin.du@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 4f64845d8a4c..536d2b9d5777 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -378,6 +378,7 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	struct intel_vgpu *vgpu;
 
 	param.handle = 0;
+	param.primary = 1;
 	param.low_gm_sz = type->low_gm_size;
 	param.high_gm_sz = type->high_gm_size;
 	param.fence_sz = type->fence;

commit a3614a868fd31b0e3ba670401a651ae89bb527aa
Author: Xiaoguang Chen <xiaoguang.chen@intel.com>
Date:   Mon Nov 14 13:28:11 2016 +0800

    drm/i915/gvt: clear guest opregion
    
    Since there's no opregion in vgpu so clear the opregion bits in case
    guest access it.
    
    Signed-off-by: Xiaoguang Chen <xiaoguang.chen@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 044125c0f407..4f64845d8a4c 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -99,6 +99,7 @@ static void setup_vgpu_cfg_space(struct intel_vgpu *vgpu,
 	 */
 	memset(vgpu_cfg_space(vgpu) + PCI_BASE_ADDRESS_1, 0, 4);
 	memset(vgpu_cfg_space(vgpu) + PCI_BASE_ADDRESS_3, 0, 4);
+	memset(vgpu_cfg_space(vgpu) + INTEL_GVT_PCI_OPREGION, 0, 4);
 
 	for (i = 0; i < INTEL_GVT_MAX_BAR_NUM; i++) {
 		vgpu->cfg_space.bar[i].size = pci_resource_len(

commit f4b0c2860b530e06ddaa5b5df31ab4171ac6e9eb
Author: Du, Changbin <changbin.du@intel.com>
Date:   Fri Nov 11 10:31:37 2016 +0800

    drm/i915/gvt: fix mem leakage in setup_vgpu_mmio for vgpu reset
    
    Gvt gdrst handler handle_device_reset() invoke function
    setup_vgpu_mmio() to reset mmio status. In this case,
    the virtual mmio memory has been allocated already. The
    new allocation just cause old mmio memory leakage.
    
    Signed-off-by: Du, Changbin <changbin.du@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 3a15feadc1df..044125c0f407 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -46,9 +46,13 @@ int setup_vgpu_mmio(struct intel_vgpu *vgpu)
 	struct intel_gvt *gvt = vgpu->gvt;
 	const struct intel_gvt_device_info *info = &gvt->device_info;
 
-	vgpu->mmio.vreg = vzalloc(info->mmio_size * 2);
-	if (!vgpu->mmio.vreg)
-		return -ENOMEM;
+	if (vgpu->mmio.vreg)
+		memset(vgpu->mmio.vreg, 0, info->mmio_size * 2);
+	else {
+		vgpu->mmio.vreg = vzalloc(info->mmio_size * 2);
+		if (!vgpu->mmio.vreg)
+			return -ENOMEM;
+	}
 
 	vgpu->mmio.sreg = vgpu->mmio.vreg + info->mmio_size;
 

commit 9ec1e66b8084f24d41046bd9711fbd7ec6e3850f
Author: Jike Song <jike.song@intel.com>
Date:   Thu Nov 3 18:38:35 2016 +0800

    drm/i915/gvt: refactor intel_gvt_io_emulation_ops to be intel_gvt_ops
    
    There are currently 4 methods in intel_gvt_io_emulation_ops
    to emulate CFG/MMIO reading/writing for intel vGPU. A possibly
    better scope is: add 3 more methods for vgpu create/destroy/reset
    respectively, and rename the ops to 'intel_gvt_ops', then pass
    it to the MPT module (say the future kvmgt) to use: they are
    all methods for external usage.
    
    Signed-off-by: Jike Song <jike.song@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 9b09f697862c..3a15feadc1df 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -390,3 +390,14 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
 
 	return vgpu;
 }
+
+/**
+ * intel_gvt_reset_vgpu - reset a virtual GPU
+ * @vgpu: virtual GPU
+ *
+ * This function is called when user wants to reset a virtual GPU.
+ *
+ */
+void intel_gvt_reset_vgpu(struct intel_vgpu *vgpu)
+{
+}

commit 8f89743bddec87b7e0eefe9895274653ce341059
Author: Jike Song <jike.song@intel.com>
Date:   Thu Nov 3 18:38:32 2016 +0800

    drm/i915/gvt: remove obsolete code for old kvmgt opregion
    
    Current GVT contains some obsolete logic originally cooked to
    support the old, non-vfio kvmgt, which is actually workarounds.
    We don't support that anymore, so it's safe to remove it and
    make a better framework.
    
    Signed-off-by: Jike Song <jike.song@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index de3c1876aae3..9b09f697862c 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -315,15 +315,9 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_detach_hypervisor_vgpu;
 
-	if (intel_gvt_host.hypervisor_type == INTEL_GVT_HYPERVISOR_KVM) {
-		ret = intel_vgpu_init_opregion(vgpu, 0);
-		if (ret)
-			goto out_clean_gtt;
-	}
-
 	ret = intel_vgpu_init_display(vgpu);
 	if (ret)
-		goto out_clean_opregion;
+		goto out_clean_gtt;
 
 	ret = intel_vgpu_init_execlist(vgpu);
 	if (ret)
@@ -348,8 +342,6 @@ static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	intel_vgpu_clean_execlist(vgpu);
 out_clean_display:
 	intel_vgpu_clean_display(vgpu);
-out_clean_opregion:
-	intel_vgpu_clean_opregion(vgpu);
 out_clean_gtt:
 	intel_vgpu_clean_gtt(vgpu);
 out_detach_hypervisor_vgpu:

commit 1f31c8294880d1ac99b1b477efd9de23b36cd5ec
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Thu Nov 3 18:38:31 2016 +0800

    drm/i915/gvt: add intel vgpu types support
    
    By providing predefined vGPU types, users can choose which type a vgpu
    to create and use, without specifying detailed parameters.
    
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>
    Signed-off-by: Jike Song <jike.song@intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 4f54005b976d..de3c1876aae3 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -132,6 +132,106 @@ void populate_pvinfo_page(struct intel_vgpu *vgpu)
 	WARN_ON(sizeof(struct vgt_if) != VGT_PVINFO_SIZE);
 }
 
+/**
+ * intel_gvt_init_vgpu_types - initialize vGPU type list
+ * @gvt : GVT device
+ *
+ * Initialize vGPU type list based on available resource.
+ *
+ */
+int intel_gvt_init_vgpu_types(struct intel_gvt *gvt)
+{
+	unsigned int num_types;
+	unsigned int i, low_avail;
+	unsigned int min_low;
+
+	/* vGPU type name is defined as GVTg_Vx_y which contains
+	 * physical GPU generation type and 'y' means maximum vGPU
+	 * instances user can create on one physical GPU for this
+	 * type.
+	 *
+	 * Depend on physical SKU resource, might see vGPU types like
+	 * GVTg_V4_8, GVTg_V4_4, GVTg_V4_2, etc. We can create
+	 * different types of vGPU on same physical GPU depending on
+	 * available resource. Each vGPU type will have "avail_instance"
+	 * to indicate how many vGPU instance can be created for this
+	 * type.
+	 *
+	 * Currently use static size here as we init type earlier..
+	 */
+	low_avail = MB_TO_BYTES(256) - HOST_LOW_GM_SIZE;
+	num_types = 4;
+
+	gvt->types = kzalloc(num_types * sizeof(struct intel_vgpu_type),
+			     GFP_KERNEL);
+	if (!gvt->types)
+		return -ENOMEM;
+
+	min_low = MB_TO_BYTES(32);
+	for (i = 0; i < num_types; ++i) {
+		if (low_avail / min_low == 0)
+			break;
+		gvt->types[i].low_gm_size = min_low;
+		gvt->types[i].high_gm_size = 3 * gvt->types[i].low_gm_size;
+		gvt->types[i].fence = 4;
+		gvt->types[i].max_instance = low_avail / min_low;
+		gvt->types[i].avail_instance = gvt->types[i].max_instance;
+
+		if (IS_GEN8(gvt->dev_priv))
+			sprintf(gvt->types[i].name, "GVTg_V4_%u",
+						gvt->types[i].max_instance);
+		else if (IS_GEN9(gvt->dev_priv))
+			sprintf(gvt->types[i].name, "GVTg_V5_%u",
+						gvt->types[i].max_instance);
+
+		min_low <<= 1;
+		gvt_dbg_core("type[%d]: %s max %u avail %u low %u high %u fence %u\n",
+			     i, gvt->types[i].name, gvt->types[i].max_instance,
+			     gvt->types[i].avail_instance,
+			     gvt->types[i].low_gm_size,
+			     gvt->types[i].high_gm_size, gvt->types[i].fence);
+	}
+
+	gvt->num_types = i;
+	return 0;
+}
+
+void intel_gvt_clean_vgpu_types(struct intel_gvt *gvt)
+{
+	kfree(gvt->types);
+}
+
+static void intel_gvt_update_vgpu_types(struct intel_gvt *gvt)
+{
+	int i;
+	unsigned int low_gm_avail, high_gm_avail, fence_avail;
+	unsigned int low_gm_min, high_gm_min, fence_min, total_min;
+
+	/* Need to depend on maxium hw resource size but keep on
+	 * static config for now.
+	 */
+	low_gm_avail = MB_TO_BYTES(256) - HOST_LOW_GM_SIZE -
+		gvt->gm.vgpu_allocated_low_gm_size;
+	high_gm_avail = MB_TO_BYTES(256) * 3 - HOST_HIGH_GM_SIZE -
+		gvt->gm.vgpu_allocated_high_gm_size;
+	fence_avail = gvt_fence_sz(gvt) - HOST_FENCE -
+		gvt->fence.vgpu_allocated_fence_num;
+
+	for (i = 0; i < gvt->num_types; i++) {
+		low_gm_min = low_gm_avail / gvt->types[i].low_gm_size;
+		high_gm_min = high_gm_avail / gvt->types[i].high_gm_size;
+		fence_min = fence_avail / gvt->types[i].fence;
+		total_min = min(min(low_gm_min, high_gm_min), fence_min);
+		gvt->types[i].avail_instance = min(gvt->types[i].max_instance,
+						   total_min);
+
+		gvt_dbg_core("update type[%d]: %s max %u avail %u low %u high %u fence %u\n",
+		       i, gvt->types[i].name, gvt->types[i].max_instance,
+		       gvt->types[i].avail_instance, gvt->types[i].low_gm_size,
+		       gvt->types[i].high_gm_size, gvt->types[i].fence);
+	}
+}
+
 /**
  * intel_gvt_destroy_vgpu - destroy a virtual GPU
  * @vgpu: virtual GPU
@@ -166,20 +266,11 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 	clean_vgpu_mmio(vgpu);
 	vfree(vgpu);
 
+	intel_gvt_update_vgpu_types(gvt);
 	mutex_unlock(&gvt->lock);
 }
 
-/**
- * intel_gvt_create_vgpu - create a virtual GPU
- * @gvt: GVT device
- * @param: vGPU creation parameters
- *
- * This function is called when user wants to create a virtual GPU.
- *
- * Returns:
- * pointer to intel_vgpu, error pointer if failed.
- */
-struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
+static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,
 		struct intel_vgpu_creation_params *param)
 {
 	struct intel_vgpu *vgpu;
@@ -272,3 +363,38 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	mutex_unlock(&gvt->lock);
 	return ERR_PTR(ret);
 }
+
+/**
+ * intel_gvt_create_vgpu - create a virtual GPU
+ * @gvt: GVT device
+ * @type: type of the vGPU to create
+ *
+ * This function is called when user wants to create a virtual GPU.
+ *
+ * Returns:
+ * pointer to intel_vgpu, error pointer if failed.
+ */
+struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
+				struct intel_vgpu_type *type)
+{
+	struct intel_vgpu_creation_params param;
+	struct intel_vgpu *vgpu;
+
+	param.handle = 0;
+	param.low_gm_sz = type->low_gm_size;
+	param.high_gm_sz = type->high_gm_size;
+	param.fence_sz = type->fence;
+
+	/* XXX current param based on MB */
+	param.low_gm_sz = BYTES_TO_MB(param.low_gm_sz);
+	param.high_gm_sz = BYTES_TO_MB(param.high_gm_sz);
+
+	vgpu = __intel_gvt_create_vgpu(gvt, &param);
+	if (IS_ERR(vgpu))
+		return vgpu;
+
+	/* calculate left instance change for types */
+	intel_gvt_update_vgpu_types(gvt);
+
+	return vgpu;
+}

commit 23736d1b1b2321f7e4647d8d5f8ff16fab11d24f
Author: Ping Gao <ping.a.gao@intel.com>
Date:   Wed Oct 26 09:38:52 2016 +0800

    drm/i915/gvt: add full vGPU reset support
    
    Full vGPU reset need to release all the shadow PPGGT pages to avoid
    unnecessary write-protect and also should re-initialize pvinfo after
    resetting vregs to keep pvinfo correct.
    
    Signed-off-by: Ping Gao <ping.a.gao@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 9401436d721f..4f54005b976d 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -41,7 +41,7 @@ static void clean_vgpu_mmio(struct intel_vgpu *vgpu)
 	vgpu->mmio.vreg = vgpu->mmio.sreg = NULL;
 }
 
-static int setup_vgpu_mmio(struct intel_vgpu *vgpu)
+int setup_vgpu_mmio(struct intel_vgpu *vgpu)
 {
 	struct intel_gvt *gvt = vgpu->gvt;
 	const struct intel_gvt_device_info *info = &gvt->device_info;
@@ -103,7 +103,7 @@ static void setup_vgpu_cfg_space(struct intel_vgpu *vgpu,
 	}
 }
 
-static void populate_pvinfo_page(struct intel_vgpu *vgpu)
+void populate_pvinfo_page(struct intel_vgpu *vgpu)
 {
 	/* setup the ballooning information */
 	vgpu_vreg64(vgpu, vgtif_reg(magic)) = VGT_MAGIC;

commit feddf6e866c9cdbdec45b09f0a9566ea538a0da3
Author: Zhenyu Wang <zhenyuw@linux.intel.com>
Date:   Thu Oct 20 17:15:03 2016 +0800

    drm/i915/gvt: clean up intel_gvt.h as interface for i915 core
    
    i915 core should only call functions and structures exposed through
    intel_gvt.h. Remove internal gvt.h and i915_pvinfo.h.
    
    Change for internal intel_gvt structure as private handler which
    not requires to expose gvt internal structure for i915 core.
    
    v2: Fix per Chris's comment
    - carefully handle dev_priv->gvt assignment
    - add necessary bracket for macro helper
    - forward declartion struct intel_gvt
    - keep free operation within same file handling alloc
    
    v3: fix use after free and remove intel_gvt.initialized
    
    v4: change to_gvt() to an inline
    
    Reviewed-by: Chris Wilson <chris@chris-wilson.co.uk>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index e5e0a72336c8..9401436d721f 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -32,6 +32,8 @@
  */
 
 #include "i915_drv.h"
+#include "gvt.h"
+#include "i915_pvinfo.h"
 
 static void clean_vgpu_mmio(struct intel_vgpu *vgpu)
 {

commit 178657139307126b22d226df0823223d6dfe91ba
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Sun May 1 19:02:37 2016 -0400

    drm/i915/gvt: vGPU context switch
    
    As different VM may configure different render MMIOs when executing
    workload, to schedule workloads between different VM, the render MMIOs
    have to be switched.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index c9b8e184f5cb..e5e0a72336c8 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -200,6 +200,7 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	vgpu->id = ret;
 	vgpu->handle = param->handle;
 	vgpu->gvt = gvt;
+	bitmap_zero(vgpu->tlb_handle_pending, I915_NUM_ENGINES);
 
 	setup_vgpu_cfg_space(vgpu, param);
 

commit 4b63960ebd3f4c41caca6a8dca68751b34e61e9b
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Sun May 1 17:09:58 2016 -0400

    drm/i915/gvt: vGPU schedule policy framework
    
    This patch introduces a vGPU schedule policy framework, with a timer based
    schedule policy module for now
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 609ec55bbf5f..c9b8e184f5cb 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -146,6 +146,14 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 	vgpu->active = false;
 	idr_remove(&gvt->vgpu_idr, vgpu->id);
 
+	if (atomic_read(&vgpu->running_workload_num)) {
+		mutex_unlock(&gvt->lock);
+		intel_gvt_wait_vgpu_idle(vgpu);
+		mutex_lock(&gvt->lock);
+	}
+
+	intel_vgpu_stop_schedule(vgpu);
+	intel_vgpu_clean_sched_policy(vgpu);
 	intel_vgpu_clean_gvt_context(vgpu);
 	intel_vgpu_clean_execlist(vgpu);
 	intel_vgpu_clean_display(vgpu);
@@ -231,11 +239,17 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_clean_execlist;
 
+	ret = intel_vgpu_init_sched_policy(vgpu);
+	if (ret)
+		goto out_clean_shadow_ctx;
+
 	vgpu->active = true;
 	mutex_unlock(&gvt->lock);
 
 	return vgpu;
 
+out_clean_shadow_ctx:
+	intel_vgpu_clean_gvt_context(vgpu);
 out_clean_execlist:
 	intel_vgpu_clean_execlist(vgpu);
 out_clean_display:

commit e473405783c064a9d859d108010581bae8e9af40
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Sun May 1 07:42:16 2016 -0400

    drm/i915/gvt: vGPU workload scheduler
    
    This patch introduces the vGPU workload scheduler routines.
    
    GVT workload scheduler is responsible for picking and executing GVT workload
    from current scheduled vGPU. Before the workload is submitted to host i915,
    the guest execlist context will be shadowed in the host GVT shadow context.
    the instructions in guest ring buffer will be copied into GVT shadow ring
    buffer. Then GVT-g workload scheduler will scan the instructions in guest
    ring buffer and submit it to host i915.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 705a23c1ed85..609ec55bbf5f 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -146,6 +146,7 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 	vgpu->active = false;
 	idr_remove(&gvt->vgpu_idr, vgpu->id);
 
+	intel_vgpu_clean_gvt_context(vgpu);
 	intel_vgpu_clean_execlist(vgpu);
 	intel_vgpu_clean_display(vgpu);
 	intel_vgpu_clean_opregion(vgpu);
@@ -226,11 +227,17 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_clean_display;
 
+	ret = intel_vgpu_init_gvt_context(vgpu);
+	if (ret)
+		goto out_clean_execlist;
+
 	vgpu->active = true;
 	mutex_unlock(&gvt->lock);
 
 	return vgpu;
 
+out_clean_execlist:
+	intel_vgpu_clean_execlist(vgpu);
 out_clean_display:
 	intel_vgpu_clean_display(vgpu);
 out_clean_opregion:

commit 28c4c6ca7f794b2d5ac8773d43311e95f6518415
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Sun May 1 05:22:47 2016 -0400

    drm/i915/gvt: vGPU workload submission
    
    This patch introduces the vGPU workload submission logics.
    
    Under virtualization environment, guest will submit workload through
    virtual execlist submit port. The submitted workload load will be wrapped
    into an gvt workload which will be picked by GVT workload scheduler and
    executed on host i915 later.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index e806b0e4035a..705a23c1ed85 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -146,6 +146,7 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 	vgpu->active = false;
 	idr_remove(&gvt->vgpu_idr, vgpu->id);
 
+	intel_vgpu_clean_execlist(vgpu);
 	intel_vgpu_clean_display(vgpu);
 	intel_vgpu_clean_opregion(vgpu);
 	intel_vgpu_clean_gtt(vgpu);

commit 8453d674ae7e63f629a91fe4124df7a7dc9c74cd
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Sun May 1 02:48:25 2016 -0400

    drm/i915/gvt: vGPU execlist virtualization
    
    This patch introduces the vGPU execlist virtualization.
    
    Under virtulization environment, HW execlist interface are fully emulated
    including virtual CSB emulation, virtual execlist emulation. The framework
    will emulate the virtual CSB according to the guest workload running status
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 47ed0a085e4c..e806b0e4035a 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -221,11 +221,17 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_clean_opregion;
 
+	ret = intel_vgpu_init_execlist(vgpu);
+	if (ret)
+		goto out_clean_display;
+
 	vgpu->active = true;
 	mutex_unlock(&gvt->lock);
 
 	return vgpu;
 
+out_clean_display:
+	intel_vgpu_clean_display(vgpu);
 out_clean_opregion:
 	intel_vgpu_clean_opregion(vgpu);
 out_clean_gtt:

commit 04d348ae3f0aea6523bc3b0688b5fc90c1c60d0e
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Mon Apr 25 18:28:56 2016 -0400

    drm/i915/gvt: vGPU display virtualization
    
    This patch introduces the GVT-g display virtualization.
    
    It consists a collection of display MMIO handlers, like power well register
    handler, pipe register handler, plane register handler, which will emulate
    all display MMIOs behavior to support virtual mode setting sequence for
    guest.
    
    Signed-off-by: Bing Niu <bing.niu@intel.com>
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 2d4aaa781757..47ed0a085e4c 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -146,6 +146,7 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 	vgpu->active = false;
 	idr_remove(&gvt->vgpu_idr, vgpu->id);
 
+	intel_vgpu_clean_display(vgpu);
 	intel_vgpu_clean_opregion(vgpu);
 	intel_vgpu_clean_gtt(vgpu);
 	intel_gvt_hypervisor_detach_vgpu(vgpu);
@@ -216,11 +217,17 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
 			goto out_clean_gtt;
 	}
 
+	ret = intel_vgpu_init_display(vgpu);
+	if (ret)
+		goto out_clean_opregion;
+
 	vgpu->active = true;
 	mutex_unlock(&gvt->lock);
 
 	return vgpu;
 
+out_clean_opregion:
+	intel_vgpu_clean_opregion(vgpu);
 out_clean_gtt:
 	intel_vgpu_clean_gtt(vgpu);
 out_detach_hypervisor_vgpu:

commit e39c5add322184de3be052d438dfd24375bfeaea
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Fri Sep 2 13:33:29 2016 +0800

    drm/i915/gvt: vGPU MMIO virtualization
    
    This patch introduces the generic vGPU MMIO emulation intercept
    framework.  The MPT modules will request GVT-g core logic to
    emulate MMIO read/write through IO emulation operations
    callback when hypervisor trapped a guest GTTMMIO read/write.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 53308698929a..2d4aaa781757 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -52,6 +52,11 @@ static int setup_vgpu_mmio(struct intel_vgpu *vgpu)
 
 	memcpy(vgpu->mmio.vreg, gvt->firmware.mmio, info->mmio_size);
 	memcpy(vgpu->mmio.sreg, gvt->firmware.mmio, info->mmio_size);
+
+	vgpu_vreg(vgpu, GEN6_GT_THREAD_STATUS_REG) = 0;
+
+	/* set the bit 0:2(Core C-State ) to C0 */
+	vgpu_vreg(vgpu, GEN6_GT_CORE_STATUS) = 0;
 	return 0;
 }
 

commit 4d60c5fd3f8751ea751d6dc6cfe0c1620420ccf8
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Wed Jul 20 01:14:38 2016 -0400

    drm/i915/gvt: vGPU PCI configuration space virtualization
    
    This patch introduces vGPU PCI configuration space virtualization.
    
    - Adjust the trapped GPFN(Guest Page Frame Number) window of virtual GEN
    PCI BAR 0 when guest initializes PCI BAR 0 address.
    
    - Emulate OpRegion when guest touches OpRegion.
    
    - Pass-through a part of aperture to guest when guest initializes
    aperture BAR.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index a610f5a32947..53308698929a 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -141,6 +141,7 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 	vgpu->active = false;
 	idr_remove(&gvt->vgpu_idr, vgpu->id);
 
+	intel_vgpu_clean_opregion(vgpu);
 	intel_vgpu_clean_gtt(vgpu);
 	intel_gvt_hypervisor_detach_vgpu(vgpu);
 	intel_vgpu_free_resource(vgpu);
@@ -204,11 +205,19 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_detach_hypervisor_vgpu;
 
+	if (intel_gvt_host.hypervisor_type == INTEL_GVT_HYPERVISOR_KVM) {
+		ret = intel_vgpu_init_opregion(vgpu, 0);
+		if (ret)
+			goto out_clean_gtt;
+	}
+
 	vgpu->active = true;
 	mutex_unlock(&gvt->lock);
 
 	return vgpu;
 
+out_clean_gtt:
+	intel_vgpu_clean_gtt(vgpu);
 out_detach_hypervisor_vgpu:
 	intel_gvt_hypervisor_detach_vgpu(vgpu);
 out_clean_vgpu_resource:

commit 2707e44466881d6b0a8ed05a429dcf0940c22f60
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Mon Mar 28 23:23:16 2016 +0800

    drm/i915/gvt: vGPU graphics memory virtualization
    
    The vGPU graphics memory emulation framework is responsible for graphics
    memory table virtualization. Under virtualization environment, a VM will
    populate the page table entry with guest page frame number(GPFN/GFN), while
    HW needs a page table filled with MFN(Machine frame number). The
    relationship between GFN and MFN(Machine frame number) is managed by
    hypervisor, while GEN HW doesn't have such knowledge to translate a GFN.
    
    To solve this gap, shadow GGTT/PPGTT page table is introdcued.
    
    For GGTT, the GFN inside the guest GGTT page table entry will be translated
    into MFN and written into physical GTT MMIO registers when guest write
    virtual GTT MMIO registers.
    
    For PPGTT, a shadow PPGTT page table will be created and write-protected
    translated from guest PPGTT page table.  And the shadow page table root
    pointers will be written into the shadow context after a guest workload
    is shadowed.
    
    vGPU graphics memory emulation framework consists:
    
    - Per-GEN HW platform page table entry bits extract/de-extract routines.
    - GTT MMIO register emulation handlers, which will call hypercall to do
    GFN->MFN translation when guest write GTT MMIO register
    - PPGTT shadow page table routines, e.g. shadow create/destroy/out-of-sync
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 0f1a59b9156a..a610f5a32947 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -141,6 +141,7 @@ void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
 	vgpu->active = false;
 	idr_remove(&gvt->vgpu_idr, vgpu->id);
 
+	intel_vgpu_clean_gtt(vgpu);
 	intel_gvt_hypervisor_detach_vgpu(vgpu);
 	intel_vgpu_free_resource(vgpu);
 	clean_vgpu_mmio(vgpu);
@@ -199,11 +200,17 @@ struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
 	if (ret)
 		goto out_clean_vgpu_resource;
 
+	ret = intel_vgpu_init_gtt(vgpu);
+	if (ret)
+		goto out_detach_hypervisor_vgpu;
+
 	vgpu->active = true;
 	mutex_unlock(&gvt->lock);
 
 	return vgpu;
 
+out_detach_hypervisor_vgpu:
+	intel_gvt_hypervisor_detach_vgpu(vgpu);
 out_clean_vgpu_resource:
 	intel_vgpu_free_resource(vgpu);
 out_clean_vgpu_mmio:

commit 82d375d1b56820fd094da15c82562661b6a8f344
Author: Zhi Wang <zhi.a.wang@intel.com>
Date:   Tue Jul 5 12:40:49 2016 -0400

    drm/i915/gvt: Introduce basic vGPU life cycle management
    
    A vGPU represents a virtual Intel GEN hardware, which consists following
    virtual resources:
    
    - Configuration space (virtualized)
    - HW registers (virtualized)
    - GGTT memory space (partitioned)
    - GPU page table (shadowed)
    - Fence registers (partitioned)
    
    * virtualized: fully emulated by GVT-g.
    * partitioned: Only a part of the HW resource is allowed to be accessed
    by VM.
    * shadowed: Resource needs to be translated and shadowed before getting
    applied into HW.
    
    This patch introduces vGPU life cycle management framework, which is
    responsible for creating/destroying a vGPU and preparing/free resources
    related to a vGPU.
    
    Signed-off-by: Zhi Wang <zhi.a.wang@intel.com>
    Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>

diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
new file mode 100644
index 000000000000..0f1a59b9156a
--- /dev/null
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -0,0 +1,215 @@
+/*
+ * Copyright(c) 2011-2016 Intel Corporation. All rights reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ * Authors:
+ *    Eddie Dong <eddie.dong@intel.com>
+ *    Kevin Tian <kevin.tian@intel.com>
+ *
+ * Contributors:
+ *    Ping Gao <ping.a.gao@intel.com>
+ *    Zhi Wang <zhi.a.wang@intel.com>
+ *    Bing Niu <bing.niu@intel.com>
+ *
+ */
+
+#include "i915_drv.h"
+
+static void clean_vgpu_mmio(struct intel_vgpu *vgpu)
+{
+	vfree(vgpu->mmio.vreg);
+	vgpu->mmio.vreg = vgpu->mmio.sreg = NULL;
+}
+
+static int setup_vgpu_mmio(struct intel_vgpu *vgpu)
+{
+	struct intel_gvt *gvt = vgpu->gvt;
+	const struct intel_gvt_device_info *info = &gvt->device_info;
+
+	vgpu->mmio.vreg = vzalloc(info->mmio_size * 2);
+	if (!vgpu->mmio.vreg)
+		return -ENOMEM;
+
+	vgpu->mmio.sreg = vgpu->mmio.vreg + info->mmio_size;
+
+	memcpy(vgpu->mmio.vreg, gvt->firmware.mmio, info->mmio_size);
+	memcpy(vgpu->mmio.sreg, gvt->firmware.mmio, info->mmio_size);
+	return 0;
+}
+
+static void setup_vgpu_cfg_space(struct intel_vgpu *vgpu,
+	struct intel_vgpu_creation_params *param)
+{
+	struct intel_gvt *gvt = vgpu->gvt;
+	const struct intel_gvt_device_info *info = &gvt->device_info;
+	u16 *gmch_ctl;
+	int i;
+
+	memcpy(vgpu_cfg_space(vgpu), gvt->firmware.cfg_space,
+	       info->cfg_space_size);
+
+	if (!param->primary) {
+		vgpu_cfg_space(vgpu)[PCI_CLASS_DEVICE] =
+			INTEL_GVT_PCI_CLASS_VGA_OTHER;
+		vgpu_cfg_space(vgpu)[PCI_CLASS_PROG] =
+			INTEL_GVT_PCI_CLASS_VGA_OTHER;
+	}
+
+	/* Show guest that there isn't any stolen memory.*/
+	gmch_ctl = (u16 *)(vgpu_cfg_space(vgpu) + INTEL_GVT_PCI_GMCH_CONTROL);
+	*gmch_ctl &= ~(BDW_GMCH_GMS_MASK << BDW_GMCH_GMS_SHIFT);
+
+	intel_vgpu_write_pci_bar(vgpu, PCI_BASE_ADDRESS_2,
+				 gvt_aperture_pa_base(gvt), true);
+
+	vgpu_cfg_space(vgpu)[PCI_COMMAND] &= ~(PCI_COMMAND_IO
+					     | PCI_COMMAND_MEMORY
+					     | PCI_COMMAND_MASTER);
+	/*
+	 * Clear the bar upper 32bit and let guest to assign the new value
+	 */
+	memset(vgpu_cfg_space(vgpu) + PCI_BASE_ADDRESS_1, 0, 4);
+	memset(vgpu_cfg_space(vgpu) + PCI_BASE_ADDRESS_3, 0, 4);
+
+	for (i = 0; i < INTEL_GVT_MAX_BAR_NUM; i++) {
+		vgpu->cfg_space.bar[i].size = pci_resource_len(
+					      gvt->dev_priv->drm.pdev, i * 2);
+		vgpu->cfg_space.bar[i].tracked = false;
+	}
+}
+
+static void populate_pvinfo_page(struct intel_vgpu *vgpu)
+{
+	/* setup the ballooning information */
+	vgpu_vreg64(vgpu, vgtif_reg(magic)) = VGT_MAGIC;
+	vgpu_vreg(vgpu, vgtif_reg(version_major)) = 1;
+	vgpu_vreg(vgpu, vgtif_reg(version_minor)) = 0;
+	vgpu_vreg(vgpu, vgtif_reg(display_ready)) = 0;
+	vgpu_vreg(vgpu, vgtif_reg(vgt_id)) = vgpu->id;
+	vgpu_vreg(vgpu, vgtif_reg(avail_rs.mappable_gmadr.base)) =
+		vgpu_aperture_gmadr_base(vgpu);
+	vgpu_vreg(vgpu, vgtif_reg(avail_rs.mappable_gmadr.size)) =
+		vgpu_aperture_sz(vgpu);
+	vgpu_vreg(vgpu, vgtif_reg(avail_rs.nonmappable_gmadr.base)) =
+		vgpu_hidden_gmadr_base(vgpu);
+	vgpu_vreg(vgpu, vgtif_reg(avail_rs.nonmappable_gmadr.size)) =
+		vgpu_hidden_sz(vgpu);
+
+	vgpu_vreg(vgpu, vgtif_reg(avail_rs.fence_num)) = vgpu_fence_sz(vgpu);
+
+	gvt_dbg_core("Populate PVINFO PAGE for vGPU %d\n", vgpu->id);
+	gvt_dbg_core("aperture base [GMADR] 0x%llx size 0x%llx\n",
+		vgpu_aperture_gmadr_base(vgpu), vgpu_aperture_sz(vgpu));
+	gvt_dbg_core("hidden base [GMADR] 0x%llx size=0x%llx\n",
+		vgpu_hidden_gmadr_base(vgpu), vgpu_hidden_sz(vgpu));
+	gvt_dbg_core("fence size %d\n", vgpu_fence_sz(vgpu));
+
+	WARN_ON(sizeof(struct vgt_if) != VGT_PVINFO_SIZE);
+}
+
+/**
+ * intel_gvt_destroy_vgpu - destroy a virtual GPU
+ * @vgpu: virtual GPU
+ *
+ * This function is called when user wants to destroy a virtual GPU.
+ *
+ */
+void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)
+{
+	struct intel_gvt *gvt = vgpu->gvt;
+
+	mutex_lock(&gvt->lock);
+
+	vgpu->active = false;
+	idr_remove(&gvt->vgpu_idr, vgpu->id);
+
+	intel_gvt_hypervisor_detach_vgpu(vgpu);
+	intel_vgpu_free_resource(vgpu);
+	clean_vgpu_mmio(vgpu);
+	vfree(vgpu);
+
+	mutex_unlock(&gvt->lock);
+}
+
+/**
+ * intel_gvt_create_vgpu - create a virtual GPU
+ * @gvt: GVT device
+ * @param: vGPU creation parameters
+ *
+ * This function is called when user wants to create a virtual GPU.
+ *
+ * Returns:
+ * pointer to intel_vgpu, error pointer if failed.
+ */
+struct intel_vgpu *intel_gvt_create_vgpu(struct intel_gvt *gvt,
+		struct intel_vgpu_creation_params *param)
+{
+	struct intel_vgpu *vgpu;
+	int ret;
+
+	gvt_dbg_core("handle %llu low %llu MB high %llu MB fence %llu\n",
+			param->handle, param->low_gm_sz, param->high_gm_sz,
+			param->fence_sz);
+
+	vgpu = vzalloc(sizeof(*vgpu));
+	if (!vgpu)
+		return ERR_PTR(-ENOMEM);
+
+	mutex_lock(&gvt->lock);
+
+	ret = idr_alloc(&gvt->vgpu_idr, vgpu, 1, GVT_MAX_VGPU, GFP_KERNEL);
+	if (ret < 0)
+		goto out_free_vgpu;
+
+	vgpu->id = ret;
+	vgpu->handle = param->handle;
+	vgpu->gvt = gvt;
+
+	setup_vgpu_cfg_space(vgpu, param);
+
+	ret = setup_vgpu_mmio(vgpu);
+	if (ret)
+		goto out_free_vgpu;
+
+	ret = intel_vgpu_alloc_resource(vgpu, param);
+	if (ret)
+		goto out_clean_vgpu_mmio;
+
+	populate_pvinfo_page(vgpu);
+
+	ret = intel_gvt_hypervisor_attach_vgpu(vgpu);
+	if (ret)
+		goto out_clean_vgpu_resource;
+
+	vgpu->active = true;
+	mutex_unlock(&gvt->lock);
+
+	return vgpu;
+
+out_clean_vgpu_resource:
+	intel_vgpu_free_resource(vgpu);
+out_clean_vgpu_mmio:
+	clean_vgpu_mmio(vgpu);
+out_free_vgpu:
+	vfree(vgpu);
+	mutex_unlock(&gvt->lock);
+	return ERR_PTR(ret);
+}
