commit 9165fb879f62a73577867180e890f410f3a239ad
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Sep 19 12:56:15 2019 +0200

    drm/ttm: always keep BOs on the LRU
    
    This allows blocking for BOs to become available
    in the memory management.
    
    Amdgpu is doing this for quite a while now during CS. Now
    apply the new behavior to all drivers using TTM.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Thomas Hellstrom <thellstrom@vmware.com>
    Link: https://patchwork.freedesktop.org/patch/332878/

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 2abe1eab471f..140d94cc080d 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -542,7 +542,7 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 	u64 bytes_moved_threshold = radeon_bo_get_threshold_for_moves(rdev);
 
 	INIT_LIST_HEAD(&duplicates);
-	r = ttm_eu_reserve_buffers(ticket, head, true, &duplicates, true);
+	r = ttm_eu_reserve_buffers(ticket, head, true, &duplicates);
 	if (unlikely(r != 0)) {
 		return r;
 	}

commit 52791eeec1d9f4a7e7fe08aaba0b1553149d93bc
Author: Christian König <christian.koenig@amd.com>
Date:   Sun Aug 11 10:06:32 2019 +0200

    dma-buf: rename reservation_object to dma_resv
    
    Be more consistent with the naming of the other DMA-buf objects.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chris Wilson <chris@chris-wilson.co.uk>
    Link: https://patchwork.freedesktop.org/patch/323401/

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 9db8ba29ef68..2abe1eab471f 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -183,7 +183,7 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 int radeon_bo_create(struct radeon_device *rdev,
 		     unsigned long size, int byte_align, bool kernel,
 		     u32 domain, u32 flags, struct sg_table *sg,
-		     struct reservation_object *resv,
+		     struct dma_resv *resv,
 		     struct radeon_bo **bo_ptr)
 {
 	struct radeon_bo *bo;
@@ -610,7 +610,7 @@ int radeon_bo_get_surface_reg(struct radeon_bo *bo)
 	int steal;
 	int i;
 
-	reservation_object_assert_held(bo->tbo.base.resv);
+	dma_resv_assert_held(bo->tbo.base.resv);
 
 	if (!bo->tiling_flags)
 		return 0;
@@ -736,7 +736,7 @@ void radeon_bo_get_tiling_flags(struct radeon_bo *bo,
 				uint32_t *tiling_flags,
 				uint32_t *pitch)
 {
-	reservation_object_assert_held(bo->tbo.base.resv);
+	dma_resv_assert_held(bo->tbo.base.resv);
 
 	if (tiling_flags)
 		*tiling_flags = bo->tiling_flags;
@@ -748,7 +748,7 @@ int radeon_bo_check_tiling(struct radeon_bo *bo, bool has_moved,
 				bool force_drop)
 {
 	if (!force_drop)
-		reservation_object_assert_held(bo->tbo.base.resv);
+		dma_resv_assert_held(bo->tbo.base.resv);
 
 	if (!(bo->tiling_flags & RADEON_TILING_SURFACE))
 		return 0;
@@ -870,10 +870,10 @@ int radeon_bo_wait(struct radeon_bo *bo, u32 *mem_type, bool no_wait)
 void radeon_bo_fence(struct radeon_bo *bo, struct radeon_fence *fence,
 		     bool shared)
 {
-	struct reservation_object *resv = bo->tbo.base.resv;
+	struct dma_resv *resv = bo->tbo.base.resv;
 
 	if (shared)
-		reservation_object_add_shared_fence(resv, &fence->base);
+		dma_resv_add_shared_fence(resv, &fence->base);
 	else
-		reservation_object_add_excl_fence(resv, &fence->base);
+		dma_resv_add_excl_fence(resv, &fence->base);
 }

commit 336ac942f115dd076bd7287c7cf03f37c710895c
Author: Gerd Hoffmann <kraxel@redhat.com>
Date:   Mon Aug 5 16:01:13 2019 +0200

    drm/radeon: switch driver from bo->resv to bo->base.resv
    
    Signed-off-by: Gerd Hoffmann <kraxel@redhat.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20190805140119.7337-12-kraxel@redhat.com

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index a319afc81408..9db8ba29ef68 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -262,7 +262,6 @@ int radeon_bo_create(struct radeon_device *rdev,
 	r = ttm_bo_init(&rdev->mman.bdev, &bo->tbo, size, type,
 			&bo->placement, page_align, !kernel, acc_size,
 			sg, resv, &radeon_ttm_bo_destroy);
-	bo->tbo.base.resv = bo->tbo.resv;
 	up_read(&rdev->pm.mclk_lock);
 	if (unlikely(r != 0)) {
 		return r;
@@ -611,7 +610,7 @@ int radeon_bo_get_surface_reg(struct radeon_bo *bo)
 	int steal;
 	int i;
 
-	reservation_object_assert_held(bo->tbo.resv);
+	reservation_object_assert_held(bo->tbo.base.resv);
 
 	if (!bo->tiling_flags)
 		return 0;
@@ -737,7 +736,7 @@ void radeon_bo_get_tiling_flags(struct radeon_bo *bo,
 				uint32_t *tiling_flags,
 				uint32_t *pitch)
 {
-	reservation_object_assert_held(bo->tbo.resv);
+	reservation_object_assert_held(bo->tbo.base.resv);
 
 	if (tiling_flags)
 		*tiling_flags = bo->tiling_flags;
@@ -749,7 +748,7 @@ int radeon_bo_check_tiling(struct radeon_bo *bo, bool has_moved,
 				bool force_drop)
 {
 	if (!force_drop)
-		reservation_object_assert_held(bo->tbo.resv);
+		reservation_object_assert_held(bo->tbo.base.resv);
 
 	if (!(bo->tiling_flags & RADEON_TILING_SURFACE))
 		return 0;
@@ -871,7 +870,7 @@ int radeon_bo_wait(struct radeon_bo *bo, u32 *mem_type, bool no_wait)
 void radeon_bo_fence(struct radeon_bo *bo, struct radeon_fence *fence,
 		     bool shared)
 {
-	struct reservation_object *resv = bo->tbo.resv;
+	struct reservation_object *resv = bo->tbo.base.resv;
 
 	if (shared)
 		reservation_object_add_shared_fence(resv, &fence->base);

commit ce77038fdae385f947757a37573d90f2e83f0271
Author: Gerd Hoffmann <kraxel@redhat.com>
Date:   Mon Aug 5 16:01:06 2019 +0200

    drm/radeon: use embedded gem object
    
    Drop drm_gem_object from radeon_bo, use the
    ttm_buffer_object.base instead.
    
    Build tested only.
    
    Signed-off-by: Gerd Hoffmann <kraxel@redhat.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20190805140119.7337-5-kraxel@redhat.com

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index a668abcbacef..a319afc81408 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -85,9 +85,9 @@ static void radeon_ttm_bo_destroy(struct ttm_buffer_object *tbo)
 	mutex_unlock(&bo->rdev->gem.mutex);
 	radeon_bo_clear_surface_reg(bo);
 	WARN_ON_ONCE(!list_empty(&bo->va));
-	if (bo->gem_base.import_attach)
-		drm_prime_gem_destroy(&bo->gem_base, bo->tbo.sg);
-	drm_gem_object_release(&bo->gem_base);
+	if (bo->tbo.base.import_attach)
+		drm_prime_gem_destroy(&bo->tbo.base, bo->tbo.sg);
+	drm_gem_object_release(&bo->tbo.base);
 	kfree(bo);
 }
 
@@ -209,7 +209,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 	bo = kzalloc(sizeof(struct radeon_bo), GFP_KERNEL);
 	if (bo == NULL)
 		return -ENOMEM;
-	drm_gem_private_object_init(rdev->ddev, &bo->gem_base, size);
+	drm_gem_private_object_init(rdev->ddev, &bo->tbo.base, size);
 	bo->rdev = rdev;
 	bo->surface_reg = -1;
 	INIT_LIST_HEAD(&bo->list);
@@ -262,7 +262,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 	r = ttm_bo_init(&rdev->mman.bdev, &bo->tbo, size, type,
 			&bo->placement, page_align, !kernel, acc_size,
 			sg, resv, &radeon_ttm_bo_destroy);
-	bo->gem_base.resv = bo->tbo.resv;
+	bo->tbo.base.resv = bo->tbo.resv;
 	up_read(&rdev->pm.mclk_lock);
 	if (unlikely(r != 0)) {
 		return r;
@@ -443,13 +443,13 @@ void radeon_bo_force_delete(struct radeon_device *rdev)
 	dev_err(rdev->dev, "Userspace still has active objects !\n");
 	list_for_each_entry_safe(bo, n, &rdev->gem.objects, list) {
 		dev_err(rdev->dev, "%p %p %lu %lu force free\n",
-			&bo->gem_base, bo, (unsigned long)bo->gem_base.size,
-			*((unsigned long *)&bo->gem_base.refcount));
+			&bo->tbo.base, bo, (unsigned long)bo->tbo.base.size,
+			*((unsigned long *)&bo->tbo.base.refcount));
 		mutex_lock(&bo->rdev->gem.mutex);
 		list_del_init(&bo->list);
 		mutex_unlock(&bo->rdev->gem.mutex);
 		/* this should unref the ttm bo */
-		drm_gem_object_put_unlocked(&bo->gem_base);
+		drm_gem_object_put_unlocked(&bo->tbo.base);
 	}
 }
 

commit 0dbd555a011c2d096a7b7e40c83c5776a7df367c
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Jul 31 09:41:50 2019 +0200

    dma-buf: add more reservation object locking wrappers
    
    Complete the abstraction of the ww_mutex inside the reservation object.
    
    This allows us to add more handling and debugging to the reservation
    object in the future.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chris Wilson <chris@chris-wilson.co.uk>
    Link: https://patchwork.freedesktop.org/patch/320761/

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 7a2bad843f8a..a668abcbacef 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -611,7 +611,7 @@ int radeon_bo_get_surface_reg(struct radeon_bo *bo)
 	int steal;
 	int i;
 
-	lockdep_assert_held(&bo->tbo.resv->lock.base);
+	reservation_object_assert_held(bo->tbo.resv);
 
 	if (!bo->tiling_flags)
 		return 0;
@@ -737,7 +737,7 @@ void radeon_bo_get_tiling_flags(struct radeon_bo *bo,
 				uint32_t *tiling_flags,
 				uint32_t *pitch)
 {
-	lockdep_assert_held(&bo->tbo.resv->lock.base);
+	reservation_object_assert_held(bo->tbo.resv);
 
 	if (tiling_flags)
 		*tiling_flags = bo->tiling_flags;
@@ -749,7 +749,7 @@ int radeon_bo_check_tiling(struct radeon_bo *bo, bool has_moved,
 				bool force_drop)
 {
 	if (!force_drop)
-		lockdep_assert_held(&bo->tbo.resv->lock.base);
+		reservation_object_assert_held(bo->tbo.resv);
 
 	if (!(bo->tiling_flags & RADEON_TILING_SURFACE))
 		return 0;

commit c549da2d217ecb7c6d385b4f93b7180cc3a59210
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Thu Jul 25 15:26:52 2019 +0200

    drm/radeon: Fill out gem_object->resv
    
    That way we can ditch our gem_prime_res_obj implementation. Since ttm
    absolutely needs the right reservation object all the boilerplate is
    already there and we just have to wire it up correctly.
    
    Note that gem/prime doesn't care when we do this, as long as we do it
    before the bo is registered and someone can call the handle2fd ioctl
    on it.
    
    Aside: ttm_buffer_object.ttm_resv could probably be ditched in favour
    of always passing a non-NULL resv to ttm_bo_init(). At least for gem
    drivers that would avoid having two of these, on in ttm_buffer_object
    and the other in drm_gem_object, one just there for confusion.
    
    Acked-by: Gerd Hoffmann <kraxel@redhat.com>
    Cc: Gerd Hoffmann <kraxel@redhat.com>
    Reviewed-by: Emil Velikov <emil.velikov@collabora.com>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    Cc: Alex Deucher <alexander.deucher@amd.com>
    Cc: "Christian König" <christian.koenig@amd.com>
    Cc: "David (ChunMing) Zhou" <David1.Zhou@amd.com>
    Cc: amd-gfx@lists.freedesktop.org
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190725132655.11951-2-daniel.vetter@ffwll.ch

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 21f73fc86f38..7a2bad843f8a 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -262,6 +262,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 	r = ttm_bo_init(&rdev->mman.bdev, &bo->tbo, size, type,
 			&bo->placement, page_align, !kernel, acc_size,
 			sg, resv, &radeon_ttm_bo_destroy);
+	bo->gem_base.resv = bo->tbo.resv;
 	up_read(&rdev->pm.mclk_lock);
 	if (unlikely(r != 0)) {
 		return r;

commit 2454fcea338ad821a39d471bc7db5a58ba41b742
Merge: 561564bea324 51e857af9f3f
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Fri Jun 14 11:31:13 2019 +0200

    Merge tag 'drm-misc-next-2019-06-14' of git://anongit.freedesktop.org/drm/drm-misc into drm-next
    
    drm-misc-next for v5.3:
    
    UAPI Changes:
    
    Cross-subsystem Changes:
    - Add code to signal all dma-fences when freed with pending signals.
    - Annotate reservation object access in CONFIG_DEBUG_MUTEXES
    
    Core Changes:
    - Assorted documentation fixes.
    - Use irqsave/restore spinlock to add crc entry.
    - Move code around to drm_client, for internal modeset clients.
    - Make drm_crtc.h and drm_debugfs.h self-contained.
    - Remove drm_fb_helper_connector.
    - Add bootsplash to todo.
    - Fix lock ordering in pan_display_legacy.
    - Support pinning buffers to current location in gem-vram.
    - Remove the now unused locking functions from gem-vram.
    - Remove the now unused kmap-object argument from vram helpers.
    - Stop checking return value of debugfs_create.
    - Add atomic encoder enable/disable helpers.
    - pass drm_atomic_state to atomic connector check.
    - Add atomic support for bridge enable/disable.
    - Add self refresh helpers to core.
    
    Driver Changes:
    - Add extra delay to make MTP SDM845 work.
    - Small fixes to virtio, vkms, sii902x, sii9234, ast, mcde, analogix, rockchip.
    - Add zpos and ?BGR8888 support to meson.
    - More removals of drm_os_linux and drmP headers for amd, radeon, sti, r128, r128, savage, sis.
    - Allow synopsis to unwedge the i2c hdmi bus.
    - Add orientation quirks for GPD panels.
    - Edid cleanups and fixing handling for edid < 1.2.
    - Add runtime pm to stm.
    - Handle s/r in dw-hdmi.
    - Add hooks for power on/off to dsi for stm.
    - Remove virtio dirty tracking code, done in drm core.
    - Rework BO handling in ast and mgag200.
    
    Tiny conflict in drivers/gpu/drm/amd/display/dc/clk_mgr/clk_mgr.c,
    needed #include <linux/slab.h> to make it compile.
    
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    From: Maarten Lankhorst <maarten.lankhorst@linux.intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/0e01de30-9797-853c-732f-4a5bd6e61445@linux.intel.com

commit f91831274e6ed2e6f7514dd16f20816f6753057d
Author: Sam Ravnborg <sam@ravnborg.org>
Date:   Sat Jun 8 10:02:40 2019 +0200

    drm/radeon: drop use of drmP.h (1/2)
    
    Drop use of drmP.h in all .c files named radeon*c.
    To ease review a little drmP.h removal was divided in two commits.
    
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: "Christian König" <christian.koenig@amd.com>
    Cc: "David (ChunMing) Zhou" <David1.Zhou@amd.com>
    Cc: David Airlie <airlied@linux.ie>
    Cc: Daniel Vetter <daniel@ffwll.ch>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190608080241.4958-7-sam@ravnborg.org

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 833e909706a9..1741eb7abb8e 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -29,15 +29,18 @@
  *    Thomas Hellstrom <thomas-at-tungstengraphics-dot-com>
  *    Dave Airlie
  */
+
+#include <linux/io.h>
 #include <linux/list.h>
 #include <linux/slab.h>
-#include <drm/drmP.h>
-#include <drm/radeon_drm.h>
+
 #include <drm/drm_cache.h>
+#include <drm/drm_prime.h>
+#include <drm/radeon_drm.h>
+
 #include "radeon.h"
 #include "radeon_trace.h"
 
-
 int radeon_ttm_init(struct radeon_device *rdev);
 void radeon_ttm_fini(struct radeon_device *rdev);
 static void radeon_bo_clear_surface_reg(struct radeon_bo *bo);

commit 6e58ab7ac7fac61acd7705a8abf1632462c1512a
Author: Christian König <christian.koenig@amd.com>
Date:   Fri May 10 14:15:08 2019 +0200

    drm/ttm: Make LRU removal optional v2
    
    We are already doing this for DMA-buf imports and also for
    amdgpu VM BOs for quite a while now.
    
    If this doesn't run into any problems we are probably going
    to stop removing BOs from the LRU altogether.
    
    v2: drop BUG_ON from ttm_bo_add_to_lru
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Tested-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 833e909706a9..36683de0300b 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -539,7 +539,7 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 	u64 bytes_moved_threshold = radeon_bo_get_threshold_for_moves(rdev);
 
 	INIT_LIST_HEAD(&duplicates);
-	r = ttm_eu_reserve_buffers(ticket, head, true, &duplicates);
+	r = ttm_eu_reserve_buffers(ticket, head, true, &duplicates, true);
 	if (unlikely(r != 0)) {
 		return r;
 	}

commit 584738b7e359e856199ef7093bc1b28dabada054
Author: Yue Haibing <yuehaibing@huawei.com>
Date:   Thu Nov 8 11:53:43 2018 +0000

    drm/radeon: remove set but not used variable 'rdev'
    
    Fixes gcc '-Wunused-but-set-variable' warning:
    
    drivers/gpu/drm/radeon/radeon_object.c: In function 'radeon_bo_unref':
    drivers/gpu/drm/radeon/radeon_object.c:317:24: warning:
     variable 'rdev' set but not used [-Wunused-but-set-variable]
    
    It not used  any more after commit
      e7e31600d3e2 ("drm/radeon: remove taking mclk_lock from radeon_bo_unref")
    
    Signed-off-by: Yue Haibing <yuehaibing@huawei.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 92f6d4002eea..833e909706a9 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -314,11 +314,9 @@ struct radeon_bo *radeon_bo_ref(struct radeon_bo *bo)
 void radeon_bo_unref(struct radeon_bo **bo)
 {
 	struct ttm_buffer_object *tbo;
-	struct radeon_device *rdev;
 
 	if ((*bo) == NULL)
 		return;
-	rdev = (*bo)->rdev;
 	tbo = &((*bo)->tbo);
 	ttm_bo_put(tbo);
 	*bo = NULL;

commit d6257ab531ba0053d6f7c98ef949ab53f9a8ff0a
Author: Paul Menzel <pmenzel+amd-gfx@molgen.mpg.de>
Date:   Tue Jul 31 18:48:41 2018 +0200

    drm/radeon: Do not evict VRAM on APUs with disabled HIBERNATE
    
    Improve commit d796d844 (drm/radeon/kms: make hibernate work on IGPs) to
    only migrate VRAM objects if the Linux kernel is actually built with
    support for hibernation (suspend to disk).
    
    Link: https://bugs.freedesktop.org/show_bug.cgi?id=100941
    Signed-off-by: Paul Menzel <pmenzel@molgen.mpg.de>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index ba2fd295697f..92f6d4002eea 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -421,11 +421,13 @@ int radeon_bo_unpin(struct radeon_bo *bo)
 int radeon_bo_evict_vram(struct radeon_device *rdev)
 {
 	/* late 2.6.33 fix IGP hibernate - we need pm ops to do this correct */
-	if (0 && (rdev->flags & RADEON_IS_IGP)) {
+#ifndef CONFIG_HIBERNATION
+	if (rdev->flags & RADEON_IS_IGP) {
 		if (rdev->mc.igp_sideport_enabled == false)
 			/* Useless to evict on IGP chips */
 			return 0;
 	}
+#endif
 	return ttm_bo_evict_mm(&rdev->mman.bdev, TTM_PL_VRAM);
 }
 

commit 77605e43701578892e98a39383071f1a8503ff8f
Author: Thomas Zimmermann <tzimmermann@suse.de>
Date:   Tue Jul 31 08:16:59 2018 +0200

    drm/radeon: Replace ttm_bo_unref with ttm_bo_put
    
    The function ttm_bo_put releases a reference to a TTM buffer object. The
    function's name is more aligned to the Linux kernel convention of naming
    ref-counting function _get and _put.
    
    A call to ttm_bo_unref takes the address of the TTM BO object's pointer and
    clears the pointer's value to NULL. This is not necessary in most cases and
    sometimes even worked around by the calling code. A call to ttm_bo_put only
    releases the reference without clearing the pointer.
    
    The current behaviour of cleaning the pointer is kept in the calling code,
    but should be removed if not required in a later patch.
    
    Signed-off-by: Thomas Zimmermann <tzimmermann@suse.de>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 1a9d4f547024..ba2fd295697f 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -320,9 +320,8 @@ void radeon_bo_unref(struct radeon_bo **bo)
 		return;
 	rdev = (*bo)->rdev;
 	tbo = &((*bo)->tbo);
-	ttm_bo_unref(&tbo);
-	if (tbo == NULL)
-		*bo = NULL;
+	ttm_bo_put(tbo);
+	*bo = NULL;
 }
 
 int radeon_bo_pin_restricted(struct radeon_bo *bo, u32 domain, u64 max_offset,

commit 269a8b6e342501fa221a398dd2730b7af7e94a5d
Author: Thomas Zimmermann <tzimmermann@suse.de>
Date:   Tue Jul 31 08:16:58 2018 +0200

    drm/radeon: Replace ttm_bo_reference with ttm_bo_get
    
    The function ttm_bo_get acquires a reference on a TTM buffer object. The
    function's name is more aligned to the Linux kernel convention of naming
    ref-counting function _get and _put.
    
    Signed-off-by: Thomas Zimmermann <tzimmermann@suse.de>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index edbb4cd519fd..1a9d4f547024 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -307,7 +307,7 @@ struct radeon_bo *radeon_bo_ref(struct radeon_bo *bo)
 	if (bo == NULL)
 		return NULL;
 
-	ttm_bo_reference(&bo->tbo);
+	ttm_bo_get(&bo->tbo);
 	return bo;
 }
 

commit 0660b58c9038f5ef94b8fe33716449945ea786e5
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Mar 9 14:44:32 2018 +0100

    drm/radeon: fix prime teardown order
    
    We unmapped imported DMA-bufs when the GEM handle was dropped, not when the
    hardware was done with the buffere.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    CC: stable@vger.kernel.org
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 38431f682ed0..edbb4cd519fd 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -82,6 +82,8 @@ static void radeon_ttm_bo_destroy(struct ttm_buffer_object *tbo)
 	mutex_unlock(&bo->rdev->gem.mutex);
 	radeon_bo_clear_surface_reg(bo);
 	WARN_ON_ONCE(!list_empty(&bo->va));
+	if (bo->gem_base.import_attach)
+		drm_prime_gem_destroy(&bo->gem_base, bo->tbo.sg);
 	drm_gem_object_release(&bo->gem_base);
 	kfree(bo);
 }

commit 724daa4fd65d927e406f2cc0661c9a329876267b
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Feb 22 15:52:31 2018 +0100

    drm/ttm: drop persistent_swap_storage from ttm_bo_init and co
    
    Never used as parameter, the only driver actually using this is nouveau
    and there it is initialized after the BO is initialized.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 64ab11d4ea58..38431f682ed0 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -255,8 +255,8 @@ int radeon_bo_create(struct radeon_device *rdev,
 	/* Kernel allocation are uninterruptible */
 	down_read(&rdev->pm.mclk_lock);
 	r = ttm_bo_init(&rdev->mman.bdev, &bo->tbo, size, type,
-			&bo->placement, page_align, !kernel, NULL,
-			acc_size, sg, resv, &radeon_ttm_bo_destroy);
+			&bo->placement, page_align, !kernel, acc_size,
+			sg, resv, &radeon_ttm_bo_destroy);
 	up_read(&rdev->pm.mclk_lock);
 	if (unlikely(r != 0)) {
 		return r;

commit c02216acf4177c4411d33735c81cad687790fa59
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Fri Feb 16 16:26:57 2018 +0100

    radeon: hide pointless #warning when compile testing
    
    In randconfig testing, we sometimes get this warning:
    
    drivers/gpu/drm/radeon/radeon_object.c: In function 'radeon_bo_create':
    drivers/gpu/drm/radeon/radeon_object.c:242:2: error: #warning Please enable CONFIG_MTRR and CONFIG_X86_PAT for better performance thanks to write-combining [-Werror=cpp]
     #warning Please enable CONFIG_MTRR and CONFIG_X86_PAT for better performance \
    
    This is rather annoying since almost all other code produces no build-time
    output unless we have found a real bug. We already fixed this in the
    amdgpu driver in commit 31bb90f1cd08 ("drm/amdgpu: shut up #warning for
    compile testing") by adding a CONFIG_COMPILE_TEST check last year and
    agreed to do the same here, but both Michel and I then forgot about it
    until I came across the issue again now.
    
    For stable kernels, as this is one of very few remaining randconfig
    warnings in 4.14.
    
    Cc: stable@vger.kernel.org
    Link: https://patchwork.kernel.org/patch/9550009/
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index c38fea37a67d..64ab11d4ea58 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -234,9 +234,10 @@ int radeon_bo_create(struct radeon_device *rdev,
 	 * may be slow
 	 * See https://bugs.freedesktop.org/show_bug.cgi?id=88758
 	 */
-
+#ifndef CONFIG_COMPILE_TEST
 #warning Please enable CONFIG_MTRR and CONFIG_X86_PAT for better performance \
 	 thanks to write-combining
+#endif
 
 	if (bo->flags & RADEON_GEM_GTT_WC)
 		DRM_INFO_ONCE("Please enable CONFIG_MTRR and CONFIG_X86_PAT for "

commit a489727fcc7a6da19fce994a0bdcb6c7ae560f7b
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Feb 16 10:08:24 2018 +0100

    drm/radeon: use drm_gem_private_object_init
    
    We use our own backing store and don't need the shmem file.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Acked-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 15404af9d740..c38fea37a67d 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -204,11 +204,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 	bo = kzalloc(sizeof(struct radeon_bo), GFP_KERNEL);
 	if (bo == NULL)
 		return -ENOMEM;
-	r = drm_gem_object_init(rdev->ddev, &bo->gem_base, size);
-	if (unlikely(r)) {
-		kfree(bo);
-		return r;
-	}
+	drm_gem_private_object_init(rdev->ddev, &bo->gem_base, size);
 	bo->rdev = rdev;
 	bo->surface_reg = -1;
 	INIT_LIST_HEAD(&bo->list);

commit 19be5570107108fba772bc2e3a1eb22ec32fb021
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Apr 12 14:24:39 2017 +0200

    drm/ttm: add operation ctx to ttm_bo_validate v2
    
    Give moving a BO into place an operation context to work with.
    
    v2: rebased
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Tested-by: Dieter Nützel <Dieter@nuetzel-hh.de>
    Tested-by: Michel Dänzer <michel.daenzer@amd.com>
    Acked-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 093594976126..15404af9d740 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -329,6 +329,7 @@ void radeon_bo_unref(struct radeon_bo **bo)
 int radeon_bo_pin_restricted(struct radeon_bo *bo, u32 domain, u64 max_offset,
 			     u64 *gpu_addr)
 {
+	struct ttm_operation_ctx ctx = { false, false };
 	int r, i;
 
 	if (radeon_ttm_tt_has_userptr(bo->tbo.ttm))
@@ -371,7 +372,7 @@ int radeon_bo_pin_restricted(struct radeon_bo *bo, u32 domain, u64 max_offset,
 		bo->placements[i].flags |= TTM_PL_FLAG_NO_EVICT;
 	}
 
-	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false);
+	r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
 	if (likely(r == 0)) {
 		bo->pin_count = 1;
 		if (gpu_addr != NULL)
@@ -393,6 +394,7 @@ int radeon_bo_pin(struct radeon_bo *bo, u32 domain, u64 *gpu_addr)
 
 int radeon_bo_unpin(struct radeon_bo *bo)
 {
+	struct ttm_operation_ctx ctx = { false, false };
 	int r, i;
 
 	if (!bo->pin_count) {
@@ -406,7 +408,7 @@ int radeon_bo_unpin(struct radeon_bo *bo)
 		bo->placements[i].lpfn = 0;
 		bo->placements[i].flags &= ~TTM_PL_FLAG_NO_EVICT;
 	}
-	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false);
+	r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
 	if (likely(r == 0)) {
 		if (bo->tbo.mem.mem_type == TTM_PL_VRAM)
 			bo->rdev->vram_pin_size -= radeon_bo_size(bo);
@@ -531,6 +533,7 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 			    struct ww_acquire_ctx *ticket,
 			    struct list_head *head, int ring)
 {
+	struct ttm_operation_ctx ctx = { true, false };
 	struct radeon_bo_list *lobj;
 	struct list_head duplicates;
 	int r;
@@ -572,7 +575,7 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 				radeon_uvd_force_into_uvd_segment(bo, allowed);
 
 			initial_bytes_moved = atomic64_read(&rdev->num_bytes_moved);
-			r = ttm_bo_validate(&bo->tbo, &bo->placement, true, false);
+			r = ttm_bo_validate(&bo->tbo, &bo->placement, &ctx);
 			bytes_moved += atomic64_read(&rdev->num_bytes_moved) -
 				       initial_bytes_moved;
 
@@ -792,6 +795,7 @@ void radeon_bo_move_notify(struct ttm_buffer_object *bo,
 
 int radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
 {
+	struct ttm_operation_ctx ctx = { false, false };
 	struct radeon_device *rdev;
 	struct radeon_bo *rbo;
 	unsigned long offset, size, lpfn;
@@ -823,10 +827,10 @@ int radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
 		    (!rbo->placements[i].lpfn || rbo->placements[i].lpfn > lpfn))
 			rbo->placements[i].lpfn = lpfn;
 	}
-	r = ttm_bo_validate(bo, &rbo->placement, false, false);
+	r = ttm_bo_validate(bo, &rbo->placement, &ctx);
 	if (unlikely(r == -ENOMEM)) {
 		radeon_ttm_placement_from_domain(rbo, RADEON_GEM_DOMAIN_GTT);
-		return ttm_bo_validate(bo, &rbo->placement, false, false);
+		return ttm_bo_validate(bo, &rbo->placement, &ctx);
 	} else if (unlikely(r != 0)) {
 		return r;
 	}

commit 5dcd33459b0039ea0be978ce6ef3e7f5dcc778d8
Author: Kent Russell <kent.russell@amd.com>
Date:   Tue Aug 8 07:50:46 2017 -0400

    drm/radeon: Fix preferred typo
    
    Change "prefered" to "preferred"
    
    Signed-off-by: Kent Russell <kent.russell@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index ad2a2fd171c1..093594976126 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -546,7 +546,7 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 	list_for_each_entry(lobj, head, tv.head) {
 		struct radeon_bo *bo = lobj->robj;
 		if (!bo->pin_count) {
-			u32 domain = lobj->prefered_domains;
+			u32 domain = lobj->preferred_domains;
 			u32 allowed = lobj->allowed_domains;
 			u32 current_domain =
 				radeon_mem_type_to_domain(bo->tbo.mem.mem_type);

commit 07f65bb22fcc97a89f85570001512adb5d7973bd
Author: Cihangir Akturk <cakturk@gmail.com>
Date:   Thu Aug 3 14:58:35 2017 +0300

    drm/radeon: switch to drm_*{get,put} helpers
    
    drm_*_reference() and drm_*_unreference() functions are just
    compatibility alias for drm_*_get() and drm_*_put() adn should not be
    used by new code. So convert all users of compatibility functions to use
    the new APIs.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Cihangir Akturk <cakturk@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 8b722297a05c..ad2a2fd171c1 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -445,7 +445,7 @@ void radeon_bo_force_delete(struct radeon_device *rdev)
 		list_del_init(&bo->list);
 		mutex_unlock(&bo->rdev->gem.mutex);
 		/* this should unref the ttm bo */
-		drm_gem_object_unreference_unlocked(&bo->gem_base);
+		drm_gem_object_put_unlocked(&bo->gem_base);
 	}
 }
 

commit 634b6a8a064576797120b74facf95ba79283b5d5
Author: Julien Isorce <julien.isorce@gmail.com>
Date:   Thu Apr 27 15:10:08 2017 +0100

    drm/radeon: only warn once in radeon_ttm_bo_destroy if va list not empty
    
    Encountered a dozen of exact same backtraces when mesa's
    pb_cache_release_all_buffers is called after that a gpu reset failed.
    
    v2: Remove superfluous error message added in v1.
    
    bug: https://bugs.freedesktop.org/show_bug.cgi?id=96271
    
    Signed-off-by: Julien Isorce <jisorce@oblong.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index bec2ec056de4..8b722297a05c 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -81,7 +81,7 @@ static void radeon_ttm_bo_destroy(struct ttm_buffer_object *tbo)
 	list_del_init(&bo->list);
 	mutex_unlock(&bo->rdev->gem.mutex);
 	radeon_bo_clear_surface_reg(bo);
-	WARN_ON(!list_empty(&bo->va));
+	WARN_ON_ONCE(!list_empty(&bo->va));
 	drm_gem_object_release(&bo->gem_base);
 	kfree(bo);
 }

commit ede2e019adec0b6fd21a54ace92358969f1a1629
Author: Christopher James Halse Rogers <christopher.halse.rogers@canonical.com>
Date:   Mon Apr 3 13:35:23 2017 +1000

    drm/radeon: Refuse to migrate a prime BO to VRAM. (v2)
    
    BOs shared via dma-buf, either imported or exported, cannot sensibly be migrated to VRAM
    without breaking the dma-buf sharing. Refuse userspace requests to migrate to VRAM,
    ensure such BOs are not migrated during command submission, and refuse to pin them
    to VRAM.
    
    v2: Don't pin BOs in GTT. Instead, refuse to migrate BOs to VRAM.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Christopher James Halse Rogers <christopher.halse.rogers@canonical.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 74b276060c20..bec2ec056de4 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -352,6 +352,11 @@ int radeon_bo_pin_restricted(struct radeon_bo *bo, u32 domain, u64 max_offset,
 
 		return 0;
 	}
+	if (bo->prime_shared_count && domain == RADEON_GEM_DOMAIN_VRAM) {
+		/* A BO shared as a dma-buf cannot be sensibly migrated to VRAM */
+		return -EINVAL;
+	}
+
 	radeon_ttm_placement_from_domain(bo, domain);
 	for (i = 0; i < bo->placement.num_placement; i++) {
 		/* force to pin into visible video ram */

commit 66257db7a5276d7f1aff8850388a0eb675ffa2e1
Author: Nicolai Hähnle <nicolai.haehnle@amd.com>
Date:   Thu Dec 15 17:23:49 2016 +0100

    drm/ttm: add evict parameter to ttm_bo_driver::move_notify
    
    Ensure that the driver can listen to evictions even when they don't take the
    path through ttm_bo_driver::move.
    
    This is crucial for amdgpu, which relies on an eviction counter to skip
    re-binding page tables when possible.
    
    Signed-off-by: Nicolai Hähnle <nicolai.haehnle@amd.com>
    Reviewed-by: Chunming Zhou <david1.zhou@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 41b72ce6613f..74b276060c20 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -765,6 +765,7 @@ int radeon_bo_check_tiling(struct radeon_bo *bo, bool has_moved,
 }
 
 void radeon_bo_move_notify(struct ttm_buffer_object *bo,
+			   bool evict,
 			   struct ttm_mem_reg *new_mem)
 {
 	struct radeon_bo *rbo;

commit 7cf321d118a825c1541b43ca45294126fd474efa
Author: Dave Airlie <airlied@redhat.com>
Date:   Mon Oct 24 15:37:48 2016 +1000

    drm/drivers: add support for using the arch wc mapping API.
    
    This fixes a regression in all these drivers since the cache
    mode tracking was fixed for mixed mappings. It uses the new
    arch API to add the VRAM range to the PAT mapping tracking
    tables.
    
    Fixes: 87744ab3832 (mm: fix cache mode tracking in vm_insert_mixed())
    Reviewed-by: Christian König <christian.koenig@amd.com>.
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index be30861afae9..41b72ce6613f 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -446,6 +446,10 @@ void radeon_bo_force_delete(struct radeon_device *rdev)
 
 int radeon_bo_init(struct radeon_device *rdev)
 {
+	/* reserve PAT memory space to WC for VRAM */
+	arch_io_reserve_memtype_wc(rdev->mc.aper_base,
+				   rdev->mc.aper_size);
+
 	/* Add an MTRR for the VRAM */
 	if (!rdev->fastfb_working) {
 		rdev->mc.vram_mtrr = arch_phys_wc_add(rdev->mc.aper_base,
@@ -463,6 +467,7 @@ void radeon_bo_fini(struct radeon_device *rdev)
 {
 	radeon_ttm_fini(rdev);
 	arch_phys_wc_del(rdev->mc.vram_mtrr);
+	arch_io_free_memtype_wc(rdev->mc.aper_base, rdev->mc.aper_size);
 }
 
 /* Returns how many bytes TTM can move per IB.

commit 8aa6d4fc5f470c5e4363c705bbae96ccb1b033b0
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Apr 6 11:12:04 2016 +0200

    drm/ttm: remove lazy parameter from ttm_bo_wait
    
    Not used any more.
    
    Reviewed-by: Sinclair Yeh <syeh@vmware.com>
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 7e0c16c74cf3..be30861afae9 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -838,7 +838,7 @@ int radeon_bo_wait(struct radeon_bo *bo, u32 *mem_type, bool no_wait)
 	if (mem_type)
 		*mem_type = bo->tbo.mem.mem_type;
 
-	r = ttm_bo_wait(&bo->tbo, true, true, no_wait);
+	r = ttm_bo_wait(&bo->tbo, true, no_wait);
 	ttm_bo_unreserve(&bo->tbo);
 	return r;
 }

commit dfd5e50ea43ca4a89de061fb69618299760eb682
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Apr 6 11:12:03 2016 +0200

    drm/ttm: remove use_ticket parameter from ttm_bo_reserve
    
    Not used any more.
    
    Reviewed-by: Sinclair Yeh <syeh@vmware.com>
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 2d901bf28a94..7e0c16c74cf3 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -832,7 +832,7 @@ int radeon_bo_wait(struct radeon_bo *bo, u32 *mem_type, bool no_wait)
 {
 	int r;
 
-	r = ttm_bo_reserve(&bo->tbo, true, no_wait, false, NULL);
+	r = ttm_bo_reserve(&bo->tbo, true, no_wait, NULL);
 	if (unlikely(r != 0))
 		return r;
 	if (mem_type)

commit e1a575ada8d2a3c3f107fdd12ac9215f983a7c80
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Mon Mar 28 16:39:14 2016 +0900

    drm/radeon: Don't move pinned BOs
    
    The purpose of pinning is to prevent a buffer from moving.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index dd46c38676db..2d901bf28a94 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -799,6 +799,10 @@ int radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
 	if ((offset + size) <= rdev->mc.visible_vram_size)
 		return 0;
 
+	/* Can't move a pinned BO to visible VRAM */
+	if (rbo->pin_count > 0)
+		return -EINVAL;
+
 	/* hurrah the memory is not visible ! */
 	radeon_ttm_placement_from_domain(rbo, RADEON_GEM_DOMAIN_VRAM);
 	lpfn =	rdev->mc.visible_vram_size >> PAGE_SHIFT;

commit 3cf8bb1ad1b8266ae12a0fbdfa79cdbdc2168a3f
Author: Jérome Glisse <jglisse@redhat.com>
Date:   Wed Mar 16 12:56:45 2016 +0100

    drm/radeon: fix indentation.
    
    I hate doing this but it hurts my eyes to go over code that does not
    comply with indentation rules. Only thing that is not only space change
    is in atom.c all other files are space indentation issues.
    
    Acked-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Jérôme Glisse <jglisse@redhat.com>
    Cc: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index fb6ad143873f..dd46c38676db 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -214,8 +214,8 @@ int radeon_bo_create(struct radeon_device *rdev,
 	INIT_LIST_HEAD(&bo->list);
 	INIT_LIST_HEAD(&bo->va);
 	bo->initial_domain = domain & (RADEON_GEM_DOMAIN_VRAM |
-	                               RADEON_GEM_DOMAIN_GTT |
-	                               RADEON_GEM_DOMAIN_CPU);
+				       RADEON_GEM_DOMAIN_GTT |
+				       RADEON_GEM_DOMAIN_CPU);
 
 	bo->flags = flags;
 	/* PCI GART is always snooped */
@@ -848,7 +848,7 @@ int radeon_bo_wait(struct radeon_bo *bo, u32 *mem_type, bool no_wait)
  *
  */
 void radeon_bo_fence(struct radeon_bo *bo, struct radeon_fence *fence,
-                     bool shared)
+		     bool shared)
 {
 	struct reservation_object *resv = bo->tbo.resv;
 

commit c5244987394648913ae1a03879c58058a2fc2cee
Author: Oded Gabbay <oded.gabbay@gmail.com>
Date:   Sat Jan 30 07:59:33 2016 +0200

    drm/radeon: mask out WC from BO on unsupported arches
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Oded Gabbay <oded.gabbay@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 84d45633d28c..fb6ad143873f 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -33,6 +33,7 @@
 #include <linux/slab.h>
 #include <drm/drmP.h>
 #include <drm/radeon_drm.h>
+#include <drm/drm_cache.h>
 #include "radeon.h"
 #include "radeon_trace.h"
 
@@ -245,6 +246,12 @@ int radeon_bo_create(struct radeon_device *rdev,
 		DRM_INFO_ONCE("Please enable CONFIG_MTRR and CONFIG_X86_PAT for "
 			      "better performance thanks to write-combining\n");
 	bo->flags &= ~(RADEON_GEM_GTT_WC | RADEON_GEM_GTT_UC);
+#else
+	/* For architectures that don't support WC memory,
+	 * mask out the WC flag from the BO
+	 */
+	if (!drm_arch_can_wc_memory())
+		bo->flags &= ~RADEON_GEM_GTT_WC;
 #endif
 
 	radeon_ttm_placement_from_domain(bo, domain);

commit 938204985c1c46c28a88cb558d9e38610044b67a
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Thu Nov 5 17:25:28 2015 +0900

    drm/radeon: Only prompt for enabling PAT when we'd allow write-combining
    
    No use bothering users about this for whom we disable write-combining for
    other reasons anyway.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index dda2ecfbf056..84d45633d28c 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -241,8 +241,9 @@ int radeon_bo_create(struct radeon_device *rdev,
 #warning Please enable CONFIG_MTRR and CONFIG_X86_PAT for better performance \
 	 thanks to write-combining
 
-	DRM_INFO_ONCE("Please enable CONFIG_MTRR and CONFIG_X86_PAT for "
-		      "better performance thanks to write-combining\n");
+	if (bo->flags & RADEON_GEM_GTT_WC)
+		DRM_INFO_ONCE("Please enable CONFIG_MTRR and CONFIG_X86_PAT for "
+			      "better performance thanks to write-combining\n");
 	bo->flags &= ~(RADEON_GEM_GTT_WC | RADEON_GEM_GTT_UC);
 #endif
 

commit a28bbd5824d4a2af98de45b300ab8d8fb39739fc
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Thu Nov 5 17:25:27 2015 +0900

    drm/radeon: Always disable RADEON_GEM_GTT_UC along with RADEON_GEM_GTT_WC
    
    Write-combining is a CPU feature. From the GPU POV, these both simply
    mean no GPU<->CPU cache coherency.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index a35f5af77c6a..dda2ecfbf056 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -231,7 +231,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 	/* XXX: Write-combined CPU mappings of GTT seem broken on 32-bit
 	 * See https://bugs.freedesktop.org/show_bug.cgi?id=84627
 	 */
-	bo->flags &= ~RADEON_GEM_GTT_WC;
+	bo->flags &= ~(RADEON_GEM_GTT_WC | RADEON_GEM_GTT_UC);
 #elif defined(CONFIG_X86) && !defined(CONFIG_X86_PAT)
 	/* Don't try to enable write-combining when it can't work, or things
 	 * may be slow
@@ -243,7 +243,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 
 	DRM_INFO_ONCE("Please enable CONFIG_MTRR and CONFIG_X86_PAT for "
 		      "better performance thanks to write-combining\n");
-	bo->flags &= ~RADEON_GEM_GTT_WC;
+	bo->flags &= ~(RADEON_GEM_GTT_WC | RADEON_GEM_GTT_UC);
 #endif
 
 	radeon_ttm_placement_from_domain(bo, domain);

commit 96ea47c0ec8c012509116bee8c57414281428fc4
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Thu Nov 5 17:25:26 2015 +0900

    drm/radeon: Disable uncacheable CPU mappings of GTT with RV6xx
    
    They reportedly cause random GPU hangs.
    
    Bugzilla: https://bugs.freedesktop.org/show_bug.cgi?id=91268
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index d3024883b844..a35f5af77c6a 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -221,6 +221,12 @@ int radeon_bo_create(struct radeon_device *rdev,
 	if (!(rdev->flags & RADEON_IS_PCIE))
 		bo->flags &= ~(RADEON_GEM_GTT_WC | RADEON_GEM_GTT_UC);
 
+	/* Write-combined CPU mappings of GTT cause GPU hangs with RV6xx
+	 * See https://bugs.freedesktop.org/show_bug.cgi?id=91268
+	 */
+	if (rdev->family >= CHIP_RV610 && rdev->family <= CHIP_RV635)
+		bo->flags &= ~(RADEON_GEM_GTT_WC | RADEON_GEM_GTT_UC);
+
 #ifdef CONFIG_X86_32
 	/* XXX: Write-combined CPU mappings of GTT seem broken on 32-bit
 	 * See https://bugs.freedesktop.org/show_bug.cgi?id=84627

commit 42192a941e427440e642623c64bda4486c527a54
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Thu Jul 9 23:32:47 2015 +0200

    drm/radeon: Don't take dev->struct_mutex in bo_force_delete
    
    It really doesn't protect anything which doesn't have other locks
    already. Also this is run from driver unload code so not much need for
    locks anyway.
    
    Cc: Alex Deucher <alexander.deucher@amd.com>
    Cc: "Christian König" <christian.koenig@amd.com>
    Reviewed-by: Thierry Reding <treding@nvidia.com>
    Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 676362769b8d..d3024883b844 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -419,7 +419,6 @@ void radeon_bo_force_delete(struct radeon_device *rdev)
 	}
 	dev_err(rdev->dev, "Userspace still has active objects !\n");
 	list_for_each_entry_safe(bo, n, &rdev->gem.objects, list) {
-		mutex_lock(&rdev->ddev->struct_mutex);
 		dev_err(rdev->dev, "%p %p %lu %lu force free\n",
 			&bo->gem_base, bo, (unsigned long)bo->gem_base.size,
 			*((unsigned long *)&bo->gem_base.refcount));
@@ -427,8 +426,7 @@ void radeon_bo_force_delete(struct radeon_device *rdev)
 		list_del_init(&bo->list);
 		mutex_unlock(&bo->rdev->gem.mutex);
 		/* this should unref the ttm bo */
-		drm_gem_object_unreference(&bo->gem_base);
-		mutex_unlock(&rdev->ddev->struct_mutex);
+		drm_gem_object_unreference_unlocked(&bo->gem_base);
 	}
 }
 

commit 12f1384da650bdb835fff63e66fe815ea882fc0e
Author: Christian König <christian.koenig@amd.com>
Date:   Tue Jul 14 15:58:30 2015 +0200

    drm/radeon: fix user ptr race condition
    
    Port of amdgpu patch 9298e52f8b51d1e4acd68f502832f3a97f8cf892.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    CC: stable@vger.kernel.org
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 318165d4855c..676362769b8d 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -75,7 +75,6 @@ static void radeon_ttm_bo_destroy(struct ttm_buffer_object *tbo)
 	bo = container_of(tbo, struct radeon_bo, tbo);
 
 	radeon_update_memory_usage(bo, bo->tbo.mem.mem_type, -1);
-	radeon_mn_unregister(bo);
 
 	mutex_lock(&bo->rdev->gem.mutex);
 	list_del_init(&bo->list);

commit a239118a24b3bf9089751068e431dfb63dc4168b
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Tue Mar 17 11:53:33 2015 -0400

    drm/radeon: drop ttm two ended allocation
    
    radeon_bo_create() calls radeon_ttm_placement_from_domain()
    before ttm_bo_init() is called.  radeon_ttm_placement_from_domain()
    uses the ttm bo size to determine when to select top down
    allocation but since the ttm bo is not initialized yet the
    check is always false.  It only took effect when buffers
    were validated later.  It also seemed to regress suspend
    and resume on some systems possibly due to it not
    taking effect in radeon_bo_create().
    
    radeon_bo_create() and radeon_ttm_placement_from_domain()
    need to be reworked substantially for this to be optimally
    effective.  Re-enable it at that point.
    
    Noticed-by: Oded Gabbay <oded.gabbay@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 43e09942823e..318165d4855c 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -173,17 +173,6 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 		else
 			rbo->placements[i].lpfn = 0;
 	}
-
-	/*
-	 * Use two-ended allocation depending on the buffer size to
-	 * improve fragmentation quality.
-	 * 512kb was measured as the most optimal number.
-	 */
-	if (rbo->tbo.mem.size > 512 * 1024) {
-		for (i = 0; i < c; i++) {
-			rbo->placements[i].flags |= TTM_PL_FLAG_TOPDOWN;
-		}
-	}
 }
 
 int radeon_bo_create(struct radeon_device *rdev,

commit a53fa43873b88bad15a2eb1f01dc5efa689625ce
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Wed Feb 4 10:19:51 2015 +0900

    drm/radeon: Don't try to enable write-combining without PAT
    
    Doing so can cause things to become slow.
    
    Print a warning at compile time and an informative message at runtime in
    that case.
    
    Bugzilla: https://bugs.freedesktop.org/show_bug.cgi?id=88758
    Cc: stable@vger.kernel.org
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 1d955776f4d0..43e09942823e 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -238,6 +238,18 @@ int radeon_bo_create(struct radeon_device *rdev,
 	 * See https://bugs.freedesktop.org/show_bug.cgi?id=84627
 	 */
 	bo->flags &= ~RADEON_GEM_GTT_WC;
+#elif defined(CONFIG_X86) && !defined(CONFIG_X86_PAT)
+	/* Don't try to enable write-combining when it can't work, or things
+	 * may be slow
+	 * See https://bugs.freedesktop.org/show_bug.cgi?id=88758
+	 */
+
+#warning Please enable CONFIG_MTRR and CONFIG_X86_PAT for better performance \
+	 thanks to write-combining
+
+	DRM_INFO_ONCE("Please enable CONFIG_MTRR and CONFIG_X86_PAT for "
+		      "better performance thanks to write-combining\n");
+	bo->flags &= ~RADEON_GEM_GTT_WC;
 #endif
 
 	radeon_ttm_placement_from_domain(bo, domain);

commit bcd705a0defb7a7ccdb2d9bdaa8719b166879ab8
Author: Rickard Strandqvist <rickard_strandqvist@spectrumdigital.se>
Date:   Sun Jan 11 14:17:19 2015 +0100

    gpu: drm: radeon: radeon_object: Remove unused function
    
    Remove the function radeon_bo_fbdev_mmap() that is not used anywhere.
    
    This was partially found by using a static code analysis program called cppcheck.
    
    Signed-off-by: Rickard Strandqvist <rickard_strandqvist@spectrumdigital.se>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 86fc56434b28..1d955776f4d0 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -576,12 +576,6 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 	return 0;
 }
 
-int radeon_bo_fbdev_mmap(struct radeon_bo *bo,
-			     struct vm_area_struct *vma)
-{
-	return ttm_fbdev_mmap(vma, &bo->tbo);
-}
-
 int radeon_bo_get_surface_reg(struct radeon_bo *bo)
 {
 	struct radeon_device *rdev = bo->rdev;

commit da6b51d007da17fd394405055e2f0109ec5f05f4
Author: Dave Airlie <airlied@redhat.com>
Date:   Wed Dec 24 13:11:17 2014 +1000

    Revert "drm/gem: Warn on illegal use of the dumb buffer interface v2"
    
    This reverts commit 355a70183848f21198e9f6296bd646df3478a26d.
    
    This had some bad side effects under normal operation, and should
    have been dropped earlier.
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 7d68223eb469..86fc56434b28 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -529,9 +529,6 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 			u32 current_domain =
 				radeon_mem_type_to_domain(bo->tbo.mem.mem_type);
 
-			WARN_ONCE(bo->gem_base.dumb,
-				  "GPU use of dumb buffer is illegal.\n");
-
 			/* Check if this buffer will be moved and don't move it
 			 * if we have moved too many buffers for this IB already.
 			 *

commit 8c8639447063ddaa7966b0effd6029037fc86599
Merge: 7608867d0c4d b2776bf7149b
Author: Dave Airlie <airlied@redhat.com>
Date:   Mon Dec 8 10:33:52 2014 +1000

    Merge tag 'v3.18' into drm-next
    
    Linux 3.18
    
    Backmerge Linus tree into -next as we had conflicts in i915/radeon/nouveau,
    and everyone was solving them individually.
    
    * tag 'v3.18': (57 commits)
      Linux 3.18
      watchdog: s3c2410_wdt: Fix the mask bit offset for Exynos7
      uapi: fix to export linux/vm_sockets.h
      i2c: cadence: Set the hardware time-out register to maximum value
      i2c: davinci: generate STP always when NACK is received
      ahci: disable MSI on SAMSUNG 0xa800 SSD
      context_tracking: Restore previous state in schedule_user
      slab: fix nodeid bounds check for non-contiguous node IDs
      lib/genalloc.c: export devm_gen_pool_create() for modules
      mm: fix anon_vma_clone() error treatment
      mm: fix swapoff hang after page migration and fork
      fat: fix oops on corrupted vfat fs
      ipc/sem.c: fully initialize sem_array before making it visible
      drivers/input/evdev.c: don't kfree() a vmalloc address
      cxgb4: Fill in supported link mode for SFP modules
      xen-netfront: Remove BUGs on paged skb data which crosses a page boundary
      mm/vmpressure.c: fix race in vmpressure_work_fn()
      mm: frontswap: invalidate expired data on a dup-store failure
      mm: do not overwrite reserved pages counter at show_mem()
      drm/radeon: kernel panic in drm_calc_vbltimestamp_from_scanoutpos with 3.18.0-rc6
      ...
    
    Conflicts:
            drivers/gpu/drm/i915/intel_display.c
            drivers/gpu/drm/nouveau/nouveau_drm.c
            drivers/gpu/drm/radeon/radeon_cs.c

commit 466be3386f1c14451a9a9c0a586a9df5f06eecdf
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Dec 3 15:46:49 2014 +0100

    drm/radeon: remove duplicates check
    
    Completely unnecessary since the ww_mutex used to reserve a buffer
    can detect double reservations from the same thread anyway.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index a4a3ac824b45..0a8ef9ef1519 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -503,18 +503,19 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 			    struct list_head *head, int ring)
 {
 	struct radeon_bo_list *lobj;
-	struct radeon_bo *bo;
+	struct list_head duplicates;
 	int r;
 	u64 bytes_moved = 0, initial_bytes_moved;
 	u64 bytes_moved_threshold = radeon_bo_get_threshold_for_moves(rdev);
 
-	r = ttm_eu_reserve_buffers(ticket, head, true, NULL);
+	INIT_LIST_HEAD(&duplicates);
+	r = ttm_eu_reserve_buffers(ticket, head, true, &duplicates);
 	if (unlikely(r != 0)) {
 		return r;
 	}
 
 	list_for_each_entry(lobj, head, tv.head) {
-		bo = lobj->robj;
+		struct radeon_bo *bo = lobj->robj;
 		if (!bo->pin_count) {
 			u32 domain = lobj->prefered_domains;
 			u32 allowed = lobj->allowed_domains;
@@ -562,6 +563,12 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 		lobj->gpu_offset = radeon_bo_gpu_offset(bo);
 		lobj->tiling_flags = bo->tiling_flags;
 	}
+
+	list_for_each_entry(lobj, &duplicates, tv.head) {
+		lobj->gpu_offset = radeon_bo_gpu_offset(lobj->robj);
+		lobj->tiling_flags = lobj->robj->tiling_flags;
+	}
+
 	return 0;
 }
 

commit aa35071c590461f95d0179cc8e730d49d610f773
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Dec 3 15:46:48 2014 +0100

    drm/ttm: optionally move duplicates to a separate list
    
    This patch adds an optional list_head parameter to ttm_eu_reserve_buffers.
    If specified duplicates in the execbuf list are no longer reported as errors,
    but moved to this list instead.
    
    Reviewed-by: Thomas Hellstrom <thellstrom@vmware.com>
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 4ab07473bb28..a4a3ac824b45 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -508,7 +508,7 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 	u64 bytes_moved = 0, initial_bytes_moved;
 	u64 bytes_moved_threshold = radeon_bo_get_threshold_for_moves(rdev);
 
-	r = ttm_eu_reserve_buffers(ticket, head, true);
+	r = ttm_eu_reserve_buffers(ticket, head, true, NULL);
 	if (unlikely(r != 0)) {
 		return r;
 	}

commit 1d0c094201bd4cae03118a1dfcb45516bb6a3ec7
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Nov 27 14:48:42 2014 +0100

    drm/radeon: rename radeon_cs_reloc to radeon_bo_list
    
    Better match what it is actually doing.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 87b00d902bf7..4ab07473bb28 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -502,7 +502,7 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 			    struct ww_acquire_ctx *ticket,
 			    struct list_head *head, int ring)
 {
-	struct radeon_cs_reloc *lobj;
+	struct radeon_bo_list *lobj;
 	struct radeon_bo *bo;
 	int r;
 	u64 bytes_moved = 0, initial_bytes_moved;

commit a08b588e4199e4200d26027ffcdf3ab2fa906412
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Thu Nov 27 18:00:54 2014 +0900

    drm/radeon: Ignore RADEON_GEM_GTT_WC on 32-bit x86
    
    Bugzilla: https://bugs.freedesktop.org/show_bug.cgi?id=84627
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 99a960a4f302..4c0d786d5c7a 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -213,6 +213,13 @@ int radeon_bo_create(struct radeon_device *rdev,
 	if (!(rdev->flags & RADEON_IS_PCIE))
 		bo->flags &= ~(RADEON_GEM_GTT_WC | RADEON_GEM_GTT_UC);
 
+#ifdef CONFIG_X86_32
+	/* XXX: Write-combined CPU mappings of GTT seem broken on 32-bit
+	 * See https://bugs.freedesktop.org/show_bug.cgi?id=84627
+	 */
+	bo->flags &= ~RADEON_GEM_GTT_WC;
+#endif
+
 	radeon_ttm_placement_from_domain(bo, domain);
 	/* Kernel allocation are uninterruptible */
 	down_read(&rdev->pm.mclk_lock);

commit ed1e8777a56f3523712506d608a29f57ed37b613
Merge: a3a1a6674f7f 2f2624c23511
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri Nov 21 12:17:43 2014 +1000

    Merge branch 'drm-next-3.19' of git://people.freedesktop.org/~agd5f/linux into drm-next
    
    - More CI dpm fixes
    - Initial DPM fan control for SI/CI (disabled by default)
    - GPUVM multi-ring efficiency improvements
    - Some cursor fixes
    
    * 'drm-next-3.19' of git://people.freedesktop.org/~agd5f/linux: (22 commits)
      drm/radeon: update the VM after setting BO address v4
      drm/radeon: sync PT updates as shared v2
      drm/radeon: sync PD updates as shared
      drm/radeon: fence BO_VAs manually
      drm/radeon: use one VMID for each ring
      drm/radeon: track VM update fences separately
      drm/radeon: fence PT updates manually v2
      drm/radeon: split semaphore and sync object handling v2
      drm/radeon: remove unnecessary VM syncs
      drm/radeon: stop re-reserving the BO in radeon_vm_bo_set_addr
      drm/radeon: rework vm_flush parameters
      drm/radeon/ci: disable needless sclk changes
      drm/radeon/ci: force pcie level before sclk and mclk
      drm/radeon/ci: use different smc command for pcie dpm
      drm/radeon/ci: apply disp voltage changes before clk changes
      drm/radeon: fix PCC debugging message for CI DPM
      drm/radeon/dpm: add thermal dpm support for CI
      drm/radeon/dpm: add smc fan control for CI (v2)
      drm/radeon/dpm: add smc fan control for SI (v2)
      drm/radeon: work around a hw bug in MGCG on CIK
      ...

commit 355a70183848f21198e9f6296bd646df3478a26d
Author: Thomas Hellstrom <thellstrom@vmware.com>
Date:   Thu Nov 20 09:56:25 2014 +0100

    drm/gem: Warn on illegal use of the dumb buffer interface v2
    
    It happens on occasion that developers of generic user-space applications
    abuse the dumb buffer API to get hold of drm buffers that they can both
    mmap() and use for GPU acceleration, using the assumptions that dumb buffers
    and buffers available for GPU are
    a) The same type and can be aribtrarily type-casted.
    b) fully coherent.
    
    This patch makes the most widely used drivers warn nicely when that happens,
    the next step will be to fail.
    
    v2: Move drmP.h changes to drm_gem.h. Fix Radeon dumb mmap breakage.
    
    Signed-off-by: Thomas Hellstrom <thellstrom@vmware.com>
    Acked-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 33e6c7a89c32..76eedd6a34f0 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -521,6 +521,9 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 			u32 current_domain =
 				radeon_mem_type_to_domain(bo->tbo.mem.mem_type);
 
+			WARN_ONCE(bo->gem_base.dumb,
+				  "GPU use of dumb buffer is illegal.\n");
+
 			/* Check if this buffer will be moved and don't move it
 			 * if we have moved too many buffers for this IB already.
 			 *

commit 587cdda8f739f4c57c91d3f73a1d5b2851a86cb8
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Nov 19 14:01:23 2014 +0100

    drm/radeon: fence PT updates manually v2
    
    This allows us to add the real execution fence as shared.
    
    v2: fix typo
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 33e6c7a89c32..686e450199c5 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -818,3 +818,22 @@ int radeon_bo_wait(struct radeon_bo *bo, u32 *mem_type, bool no_wait)
 	ttm_bo_unreserve(&bo->tbo);
 	return r;
 }
+
+/**
+ * radeon_bo_fence - add fence to buffer object
+ *
+ * @bo: buffer object in question
+ * @fence: fence to add
+ * @shared: true if fence should be added shared
+ *
+ */
+void radeon_bo_fence(struct radeon_bo *bo, struct radeon_fence *fence,
+                     bool shared)
+{
+	struct reservation_object *resv = bo->tbo.resv;
+
+	if (shared)
+		reservation_object_add_shared_fence(resv, &fence->base);
+	else
+		reservation_object_add_excl_fence(resv, &fence->base);
+}

commit a8b5ebe6b56cca0f12f0f53cdae2f03950f4100f
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Tue Oct 28 18:35:02 2014 +0900

    drm/radeon: Set TTM_PL_FLAG_TOPDOWN also for RADEON_GEM_CPU_ACCESS BOs
    
    I wasn't sure if TTM_PL_FLAG_TOPDOWN works correctly with non-0 lpfn, but
    AFAICT it does.
    
    Reviewed-by: Lauri Kasanen <cand@gmx.com>
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 7f3b1e1b05b0..33e6c7a89c32 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -179,9 +179,7 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 	 * improve fragmentation quality.
 	 * 512kb was measured as the most optimal number.
 	 */
-	if (!((rbo->flags & RADEON_GEM_CPU_ACCESS) &&
-	      (rbo->placements[i].flags & TTM_PL_FLAG_VRAM)) &&
-	    rbo->tbo.mem.size > 512 * 1024) {
+	if (rbo->tbo.mem.size > 512 * 1024) {
 		for (i = 0; i < c; i++) {
 			rbo->placements[i].flags |= TTM_PL_FLAG_TOPDOWN;
 		}

commit c9da4a4b3820782753c1c455242eca7e5a69eedb
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Fri Oct 10 12:28:36 2014 +0900

    drm/radeon: Try placing NO_CPU_ACCESS BOs outside of CPU accessible VRAM
    
    This avoids them getting in the way of BOs which might be accessed by
    the CPU. They can still go to the CPU accessible part of VRAM though if
    there's no space outside of it.
    
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 99a960a4f302..7f3b1e1b05b0 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -99,22 +99,39 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 
 	rbo->placement.placement = rbo->placements;
 	rbo->placement.busy_placement = rbo->placements;
-	if (domain & RADEON_GEM_DOMAIN_VRAM)
+	if (domain & RADEON_GEM_DOMAIN_VRAM) {
+		/* Try placing BOs which don't need CPU access outside of the
+		 * CPU accessible part of VRAM
+		 */
+		if ((rbo->flags & RADEON_GEM_NO_CPU_ACCESS) &&
+		    rbo->rdev->mc.visible_vram_size < rbo->rdev->mc.real_vram_size) {
+			rbo->placements[c].fpfn =
+				rbo->rdev->mc.visible_vram_size >> PAGE_SHIFT;
+			rbo->placements[c++].flags = TTM_PL_FLAG_WC |
+						     TTM_PL_FLAG_UNCACHED |
+						     TTM_PL_FLAG_VRAM;
+		}
+
+		rbo->placements[c].fpfn = 0;
 		rbo->placements[c++].flags = TTM_PL_FLAG_WC |
 					     TTM_PL_FLAG_UNCACHED |
 					     TTM_PL_FLAG_VRAM;
+	}
 
 	if (domain & RADEON_GEM_DOMAIN_GTT) {
 		if (rbo->flags & RADEON_GEM_GTT_UC) {
+			rbo->placements[c].fpfn = 0;
 			rbo->placements[c++].flags = TTM_PL_FLAG_UNCACHED |
 				TTM_PL_FLAG_TT;
 
 		} else if ((rbo->flags & RADEON_GEM_GTT_WC) ||
 			   (rbo->rdev->flags & RADEON_IS_AGP)) {
+			rbo->placements[c].fpfn = 0;
 			rbo->placements[c++].flags = TTM_PL_FLAG_WC |
 				TTM_PL_FLAG_UNCACHED |
 				TTM_PL_FLAG_TT;
 		} else {
+			rbo->placements[c].fpfn = 0;
 			rbo->placements[c++].flags = TTM_PL_FLAG_CACHED |
 						     TTM_PL_FLAG_TT;
 		}
@@ -122,30 +139,35 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 
 	if (domain & RADEON_GEM_DOMAIN_CPU) {
 		if (rbo->flags & RADEON_GEM_GTT_UC) {
+			rbo->placements[c].fpfn = 0;
 			rbo->placements[c++].flags = TTM_PL_FLAG_UNCACHED |
 				TTM_PL_FLAG_SYSTEM;
 
 		} else if ((rbo->flags & RADEON_GEM_GTT_WC) ||
 		    rbo->rdev->flags & RADEON_IS_AGP) {
+			rbo->placements[c].fpfn = 0;
 			rbo->placements[c++].flags = TTM_PL_FLAG_WC |
 				TTM_PL_FLAG_UNCACHED |
 				TTM_PL_FLAG_SYSTEM;
 		} else {
+			rbo->placements[c].fpfn = 0;
 			rbo->placements[c++].flags = TTM_PL_FLAG_CACHED |
 						     TTM_PL_FLAG_SYSTEM;
 		}
 	}
-	if (!c)
+	if (!c) {
+		rbo->placements[c].fpfn = 0;
 		rbo->placements[c++].flags = TTM_PL_MASK_CACHING |
 					     TTM_PL_FLAG_SYSTEM;
+	}
 
 	rbo->placement.num_placement = c;
 	rbo->placement.num_busy_placement = c;
 
 	for (i = 0; i < c; ++i) {
-		rbo->placements[i].fpfn = 0;
 		if ((rbo->flags & RADEON_GEM_CPU_ACCESS) &&
-		    (rbo->placements[i].flags & TTM_PL_FLAG_VRAM))
+		    (rbo->placements[i].flags & TTM_PL_FLAG_VRAM) &&
+		    !rbo->placements[i].fpfn)
 			rbo->placements[i].lpfn =
 				rbo->rdev->mc.visible_vram_size >> PAGE_SHIFT;
 		else
@@ -743,8 +765,8 @@ int radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
 {
 	struct radeon_device *rdev;
 	struct radeon_bo *rbo;
-	unsigned long offset, size;
-	int r;
+	unsigned long offset, size, lpfn;
+	int i, r;
 
 	if (!radeon_ttm_bo_is_radeon_bo(bo))
 		return 0;
@@ -761,7 +783,13 @@ int radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
 
 	/* hurrah the memory is not visible ! */
 	radeon_ttm_placement_from_domain(rbo, RADEON_GEM_DOMAIN_VRAM);
-	rbo->placements[0].lpfn = rdev->mc.visible_vram_size >> PAGE_SHIFT;
+	lpfn =	rdev->mc.visible_vram_size >> PAGE_SHIFT;
+	for (i = 0; i < rbo->placement.num_placement; i++) {
+		/* Force into visible VRAM */
+		if ((rbo->placements[i].flags & TTM_PL_FLAG_VRAM) &&
+		    (!rbo->placements[i].lpfn || rbo->placements[i].lpfn > lpfn))
+			rbo->placements[i].lpfn = lpfn;
+	}
 	r = ttm_bo_validate(bo, &rbo->placement, false, false);
 	if (unlikely(r == -ENOMEM)) {
 		radeon_ttm_placement_from_domain(rbo, RADEON_GEM_DOMAIN_GTT);

commit 831b6966a60fe72d85ae3576056b4e4e0775b112
Author: Maarten Lankhorst <maarten.lankhorst@canonical.com>
Date:   Thu Sep 18 14:11:56 2014 +0200

    drm/radeon: export reservation_object from dmabuf to ttm
    
    Adds an extra argument to radeon_bo_create, which is only used in radeon_prime.c.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 0e82f0223fd4..99a960a4f302 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -167,8 +167,10 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 }
 
 int radeon_bo_create(struct radeon_device *rdev,
-		     unsigned long size, int byte_align, bool kernel, u32 domain,
-		     u32 flags, struct sg_table *sg, struct radeon_bo **bo_ptr)
+		     unsigned long size, int byte_align, bool kernel,
+		     u32 domain, u32 flags, struct sg_table *sg,
+		     struct reservation_object *resv,
+		     struct radeon_bo **bo_ptr)
 {
 	struct radeon_bo *bo;
 	enum ttm_bo_type type;
@@ -216,7 +218,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 	down_read(&rdev->pm.mclk_lock);
 	r = ttm_bo_init(&rdev->mman.bdev, &bo->tbo, size, type,
 			&bo->placement, page_align, !kernel, NULL,
-			acc_size, sg, NULL, &radeon_ttm_bo_destroy);
+			acc_size, sg, resv, &radeon_ttm_bo_destroy);
 	up_read(&rdev->pm.mclk_lock);
 	if (unlikely(r != 0)) {
 		return r;

commit f4f4e3e3e9f3bde110067b9e4487cb267d90055a
Author: Maarten Lankhorst <maarten.lankhorst@canonical.com>
Date:   Thu Jan 9 11:03:15 2014 +0100

    drm/ttm: add reservation_object as argument to ttm_bo_init
    
    This allows importing reservation objects from dma-bufs.
    
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 8abee5fa93bd..0e82f0223fd4 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -216,7 +216,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 	down_read(&rdev->pm.mclk_lock);
 	r = ttm_bo_init(&rdev->mman.bdev, &bo->tbo, size, type,
 			&bo->placement, page_align, !kernel, NULL,
-			acc_size, sg, &radeon_ttm_bo_destroy);
+			acc_size, sg, NULL, &radeon_ttm_bo_destroy);
 	up_read(&rdev->pm.mclk_lock);
 	if (unlikely(r != 0)) {
 		return r;

commit f266f04d33e5265e2f61ffc9d2b2f97214804995
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Thu Aug 28 10:59:05 2014 -0400

    drm/radeon: add RADEON_GEM_NO_CPU_ACCESS BO creation flag (v4)
    
    Allows pinning of buffers in the non-CPU visible portion of
    vram.
    
    v2: incorporate Michel's comments.
    v3: rebase on Michel's patch
    v4: rebase on Michel's v2 patch
    
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 3dbbd65336d5..8abee5fa93bd 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -313,6 +313,7 @@ int radeon_bo_pin_restricted(struct radeon_bo *bo, u32 domain, u64 max_offset,
 	for (i = 0; i < bo->placement.num_placement; i++) {
 		/* force to pin into visible video ram */
 		if ((bo->placements[i].flags & TTM_PL_FLAG_VRAM) &&
+		    !(bo->flags & RADEON_GEM_NO_CPU_ACCESS) &&
 		    (!max_offset || max_offset > bo->rdev->mc.visible_vram_size))
 			bo->placements[i].lpfn =
 				bo->rdev->mc.visible_vram_size >> PAGE_SHIFT;

commit b76ee67a23e83bdad3e25def116c031eb007904d
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Tue Sep 9 10:09:23 2014 +0900

    drm/radeon: Clean up assignment of TTM placement lpfn member for pinning
    
    This sets the lpfn member to 0 instead of the full domain size. TTM uses
    the full domain size when lpfn is 0.
    
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index eef60aaf4e64..3dbbd65336d5 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -311,18 +311,14 @@ int radeon_bo_pin_restricted(struct radeon_bo *bo, u32 domain, u64 max_offset,
 	}
 	radeon_ttm_placement_from_domain(bo, domain);
 	for (i = 0; i < bo->placement.num_placement; i++) {
-		unsigned lpfn = 0;
-
 		/* force to pin into visible video ram */
-		if (bo->placements[i].flags & TTM_PL_FLAG_VRAM)
-			lpfn = bo->rdev->mc.visible_vram_size >> PAGE_SHIFT;
+		if ((bo->placements[i].flags & TTM_PL_FLAG_VRAM) &&
+		    (!max_offset || max_offset > bo->rdev->mc.visible_vram_size))
+			bo->placements[i].lpfn =
+				bo->rdev->mc.visible_vram_size >> PAGE_SHIFT;
 		else
-			lpfn = bo->rdev->mc.gtt_size >> PAGE_SHIFT; /* ??? */
-
-		if (max_offset)
-			lpfn = min (lpfn, (unsigned)(max_offset >> PAGE_SHIFT));
+			bo->placements[i].lpfn = max_offset >> PAGE_SHIFT;
 
-		bo->placements[i].lpfn = lpfn;
 		bo->placements[i].flags |= TTM_PL_FLAG_NO_EVICT;
 	}
 

commit c858403943886a92eece9d0413aa65c48bbe6fa7
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Thu Aug 28 15:56:00 2014 +0900

    drm/radeon: Add RADEON_GEM_CPU_ACCESS BO creation flag
    
    This flag is a hint that userspace expects the BO to be accessed by the
    CPU. We can use that hint to prevent such BOs from ever being stored in
    the CPU inaccessible part of VRAM.
    
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index aadbd36e64b9..eef60aaf4e64 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -144,7 +144,12 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 
 	for (i = 0; i < c; ++i) {
 		rbo->placements[i].fpfn = 0;
-		rbo->placements[i].lpfn = 0;
+		if ((rbo->flags & RADEON_GEM_CPU_ACCESS) &&
+		    (rbo->placements[i].flags & TTM_PL_FLAG_VRAM))
+			rbo->placements[i].lpfn =
+				rbo->rdev->mc.visible_vram_size >> PAGE_SHIFT;
+		else
+			rbo->placements[i].lpfn = 0;
 	}
 
 	/*
@@ -152,7 +157,9 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 	 * improve fragmentation quality.
 	 * 512kb was measured as the most optimal number.
 	 */
-	if (rbo->tbo.mem.size > 512 * 1024) {
+	if (!((rbo->flags & RADEON_GEM_CPU_ACCESS) &&
+	      (rbo->placements[i].flags & TTM_PL_FLAG_VRAM)) &&
+	    rbo->tbo.mem.size > 512 * 1024) {
 		for (i = 0; i < c; i++) {
 			rbo->placements[i].flags |= TTM_PL_FLAG_TOPDOWN;
 		}

commit f2c24b83ae90292d315aa7ac029c6ce7929e01aa
Author: Maarten Lankhorst <maarten.lankhorst@canonical.com>
Date:   Wed Apr 2 17:14:48 2014 +0200

    drm/ttm: flip the switch, and convert to dma_fence
    
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 378fe9ea4d44..aadbd36e64b9 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -781,8 +781,8 @@ int radeon_bo_wait(struct radeon_bo *bo, u32 *mem_type, bool no_wait)
 		return r;
 	if (mem_type)
 		*mem_type = bo->tbo.mem.mem_type;
-	if (bo->tbo.sync_obj)
-		r = ttm_bo_wait(&bo->tbo, true, true, no_wait);
+
+	r = ttm_bo_wait(&bo->tbo, true, true, no_wait);
 	ttm_bo_unreserve(&bo->tbo);
 	return r;
 }

commit 58b4d720c1620bbf09e42b4f218dcb2d0d8cdf3e
Author: Maarten Lankhorst <maarten.lankhorst@canonical.com>
Date:   Thu Jan 9 11:03:08 2014 +0100

    drm/ttm: add interruptible parameter to ttm_eu_reserve_buffers
    
    It seems some drivers really want this as a parameter,
    like vmwgfx.
    
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index cbac963571c0..378fe9ea4d44 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -482,7 +482,7 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 	u64 bytes_moved = 0, initial_bytes_moved;
 	u64 bytes_moved_threshold = radeon_bo_get_threshold_for_moves(rdev);
 
-	r = ttm_eu_reserve_buffers(ticket, head);
+	r = ttm_eu_reserve_buffers(ticket, head, true);
 	if (unlikely(r != 0)) {
 		return r;
 	}

commit dd7cfd641228abb2669d8d047d5ec377b1835900
Author: Maarten Lankhorst <maarten.lankhorst@canonical.com>
Date:   Tue Jan 21 13:07:31 2014 +0100

    drm/ttm: kill fence_lock
    
    No users are left, kill it off! :D
    Conversion to the reservation api is next on the list, after
    that the functionality can be restored with rcu.
    
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index c97a42432e2b..cbac963571c0 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -779,12 +779,10 @@ int radeon_bo_wait(struct radeon_bo *bo, u32 *mem_type, bool no_wait)
 	r = ttm_bo_reserve(&bo->tbo, true, no_wait, false, NULL);
 	if (unlikely(r != 0))
 		return r;
-	spin_lock(&bo->tbo.bdev->fence_lock);
 	if (mem_type)
 		*mem_type = bo->tbo.mem.mem_type;
 	if (bo->tbo.sync_obj)
 		r = ttm_bo_wait(&bo->tbo, true, true, no_wait);
-	spin_unlock(&bo->tbo.bdev->fence_lock);
 	ttm_bo_unreserve(&bo->tbo);
 	return r;
 }

commit 3852752ca89ca00aa13f12a9b9450fd97ff437d4
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Aug 21 12:18:12 2014 +0200

    drm/radeon: allow UVD to use a second 256MB segment
    
    This improves concurrent stream decoding.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 0129c7efae3b..c97a42432e2b 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -491,6 +491,7 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 		bo = lobj->robj;
 		if (!bo->pin_count) {
 			u32 domain = lobj->prefered_domains;
+			u32 allowed = lobj->allowed_domains;
 			u32 current_domain =
 				radeon_mem_type_to_domain(bo->tbo.mem.mem_type);
 
@@ -502,7 +503,7 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 			 * into account. We don't want to disallow buffer moves
 			 * completely.
 			 */
-			if ((lobj->allowed_domains & current_domain) != 0 &&
+			if ((allowed & current_domain) != 0 &&
 			    (domain & current_domain) == 0 && /* will be moved */
 			    bytes_moved > bytes_moved_threshold) {
 				/* don't move it */
@@ -512,7 +513,7 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 		retry:
 			radeon_ttm_placement_from_domain(bo, domain);
 			if (ring == R600_RING_TYPE_UVD_INDEX)
-				radeon_uvd_force_into_uvd_segment(bo);
+				radeon_uvd_force_into_uvd_segment(bo, allowed);
 
 			initial_bytes_moved = atomic64_read(&rdev->num_bytes_moved);
 			r = ttm_bo_validate(&bo->tbo, &bo->placement, true, false);

commit f1217ed09f827e42a49ffa6a5aab672aa6f57a65
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Aug 27 13:16:04 2014 +0200

    drm/ttm: move fpfn and lpfn into each placement v2
    
    This allows us to more fine grained specify where to place the buffer object.
    
    v2: rebased on drm-next, add bochs changes as well
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 287523807989..0129c7efae3b 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -97,40 +97,56 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 {
 	u32 c = 0, i;
 
-	rbo->placement.fpfn = 0;
-	rbo->placement.lpfn = 0;
 	rbo->placement.placement = rbo->placements;
 	rbo->placement.busy_placement = rbo->placements;
 	if (domain & RADEON_GEM_DOMAIN_VRAM)
-		rbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED |
-					TTM_PL_FLAG_VRAM;
+		rbo->placements[c++].flags = TTM_PL_FLAG_WC |
+					     TTM_PL_FLAG_UNCACHED |
+					     TTM_PL_FLAG_VRAM;
+
 	if (domain & RADEON_GEM_DOMAIN_GTT) {
 		if (rbo->flags & RADEON_GEM_GTT_UC) {
-			rbo->placements[c++] = TTM_PL_FLAG_UNCACHED | TTM_PL_FLAG_TT;
+			rbo->placements[c++].flags = TTM_PL_FLAG_UNCACHED |
+				TTM_PL_FLAG_TT;
+
 		} else if ((rbo->flags & RADEON_GEM_GTT_WC) ||
 			   (rbo->rdev->flags & RADEON_IS_AGP)) {
-			rbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED |
+			rbo->placements[c++].flags = TTM_PL_FLAG_WC |
+				TTM_PL_FLAG_UNCACHED |
 				TTM_PL_FLAG_TT;
 		} else {
-			rbo->placements[c++] = TTM_PL_FLAG_CACHED | TTM_PL_FLAG_TT;
+			rbo->placements[c++].flags = TTM_PL_FLAG_CACHED |
+						     TTM_PL_FLAG_TT;
 		}
 	}
+
 	if (domain & RADEON_GEM_DOMAIN_CPU) {
 		if (rbo->flags & RADEON_GEM_GTT_UC) {
-			rbo->placements[c++] = TTM_PL_FLAG_UNCACHED | TTM_PL_FLAG_SYSTEM;
+			rbo->placements[c++].flags = TTM_PL_FLAG_UNCACHED |
+				TTM_PL_FLAG_SYSTEM;
+
 		} else if ((rbo->flags & RADEON_GEM_GTT_WC) ||
 		    rbo->rdev->flags & RADEON_IS_AGP) {
-			rbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED |
+			rbo->placements[c++].flags = TTM_PL_FLAG_WC |
+				TTM_PL_FLAG_UNCACHED |
 				TTM_PL_FLAG_SYSTEM;
 		} else {
-			rbo->placements[c++] = TTM_PL_FLAG_CACHED | TTM_PL_FLAG_SYSTEM;
+			rbo->placements[c++].flags = TTM_PL_FLAG_CACHED |
+						     TTM_PL_FLAG_SYSTEM;
 		}
 	}
 	if (!c)
-		rbo->placements[c++] = TTM_PL_MASK_CACHING | TTM_PL_FLAG_SYSTEM;
+		rbo->placements[c++].flags = TTM_PL_MASK_CACHING |
+					     TTM_PL_FLAG_SYSTEM;
+
 	rbo->placement.num_placement = c;
 	rbo->placement.num_busy_placement = c;
 
+	for (i = 0; i < c; ++i) {
+		rbo->placements[i].fpfn = 0;
+		rbo->placements[i].lpfn = 0;
+	}
+
 	/*
 	 * Use two-ended allocation depending on the buffer size to
 	 * improve fragmentation quality.
@@ -138,7 +154,7 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 	 */
 	if (rbo->tbo.mem.size > 512 * 1024) {
 		for (i = 0; i < c; i++) {
-			rbo->placements[i] |= TTM_PL_FLAG_TOPDOWN;
+			rbo->placements[i].flags |= TTM_PL_FLAG_TOPDOWN;
 		}
 	}
 }
@@ -287,21 +303,22 @@ int radeon_bo_pin_restricted(struct radeon_bo *bo, u32 domain, u64 max_offset,
 		return 0;
 	}
 	radeon_ttm_placement_from_domain(bo, domain);
-	if (domain == RADEON_GEM_DOMAIN_VRAM) {
+	for (i = 0; i < bo->placement.num_placement; i++) {
+		unsigned lpfn = 0;
+
 		/* force to pin into visible video ram */
-		bo->placement.lpfn = bo->rdev->mc.visible_vram_size >> PAGE_SHIFT;
-	}
-	if (max_offset) {
-		u64 lpfn = max_offset >> PAGE_SHIFT;
+		if (bo->placements[i].flags & TTM_PL_FLAG_VRAM)
+			lpfn = bo->rdev->mc.visible_vram_size >> PAGE_SHIFT;
+		else
+			lpfn = bo->rdev->mc.gtt_size >> PAGE_SHIFT; /* ??? */
 
-		if (!bo->placement.lpfn)
-			bo->placement.lpfn = bo->rdev->mc.gtt_size >> PAGE_SHIFT;
+		if (max_offset)
+			lpfn = min (lpfn, (unsigned)(max_offset >> PAGE_SHIFT));
 
-		if (lpfn < bo->placement.lpfn)
-			bo->placement.lpfn = lpfn;
+		bo->placements[i].lpfn = lpfn;
+		bo->placements[i].flags |= TTM_PL_FLAG_NO_EVICT;
 	}
-	for (i = 0; i < bo->placement.num_placement; i++)
-		bo->placements[i] |= TTM_PL_FLAG_NO_EVICT;
+
 	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false);
 	if (likely(r == 0)) {
 		bo->pin_count = 1;
@@ -333,8 +350,10 @@ int radeon_bo_unpin(struct radeon_bo *bo)
 	bo->pin_count--;
 	if (bo->pin_count)
 		return 0;
-	for (i = 0; i < bo->placement.num_placement; i++)
-		bo->placements[i] &= ~TTM_PL_FLAG_NO_EVICT;
+	for (i = 0; i < bo->placement.num_placement; i++) {
+		bo->placements[i].lpfn = 0;
+		bo->placements[i].flags &= ~TTM_PL_FLAG_NO_EVICT;
+	}
 	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false);
 	if (likely(r == 0)) {
 		if (bo->tbo.mem.mem_type == TTM_PL_VRAM)
@@ -735,7 +754,7 @@ int radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
 
 	/* hurrah the memory is not visible ! */
 	radeon_ttm_placement_from_domain(rbo, RADEON_GEM_DOMAIN_VRAM);
-	rbo->placement.lpfn = rdev->mc.visible_vram_size >> PAGE_SHIFT;
+	rbo->placements[0].lpfn = rdev->mc.visible_vram_size >> PAGE_SHIFT;
 	r = ttm_bo_validate(bo, &rbo->placement, false, false);
 	if (unlikely(r == -ENOMEM)) {
 		radeon_ttm_placement_from_domain(rbo, RADEON_GEM_DOMAIN_GTT);

commit 341cb9e426fac32523427c80c67543a16be46605
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Aug 7 09:36:03 2014 +0200

    drm/radeon: add userptr flag to register MMU notifier v3
    
    Whenever userspace mapping related to our userptr change
    we wait for it to become idle and unmap it from GTT.
    
    v2: rebased, fix mutex unlock in error path
    v3: improve commit message
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index c73c1e320585..287523807989 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -75,6 +75,7 @@ static void radeon_ttm_bo_destroy(struct ttm_buffer_object *tbo)
 	bo = container_of(tbo, struct radeon_bo, tbo);
 
 	radeon_update_memory_usage(bo, bo->tbo.mem.mem_type, -1);
+	radeon_mn_unregister(bo);
 
 	mutex_lock(&bo->rdev->gem.mutex);
 	list_del_init(&bo->list);

commit f72a113a71ab08c4df8a5f80ab2f8a140feb81f6
Author: Christian König <christian.koenig@amd.com>
Date:   Thu Aug 7 09:36:00 2014 +0200

    drm/radeon: add userptr support v8
    
    This patch adds an IOCTL for turning a pointer supplied by
    userspace into a buffer object.
    
    It imposes several restrictions upon the memory being mapped:
    
    1. It must be page aligned (both start/end addresses, i.e ptr and size).
    
    2. It must be normal system memory, not a pointer into another map of IO
    space (e.g. it must not be a GTT mmapping of another object).
    
    3. The BO is mapped into GTT, so the maximum amount of memory mapped at
    all times is still the GTT limit.
    
    4. The BO is only mapped readonly for now, so no write support.
    
    5. List of backing pages is only acquired once, so they represent a
    snapshot of the first use.
    
    Exporting and sharing as well as mapping of buffer objects created by
    this function is forbidden and results in an -EPERM.
    
    v2: squash all previous changes into first public version
    v3: fix tabs, map readonly, don't use MM callback any more
    v4: set TTM_PAGE_FLAG_SG so that TTM never messes with the pages,
        pin/unpin pages on bind/unbind instead of populate/unpopulate
    v5: rebased on 3.17-wip, IOCTL renamed to userptr, reject any unknown
        flags, better handle READONLY flag, improve permission check
    v6: fix ptr cast warning, use set_page_dirty/mark_page_accessed on unpin
    v7: add warning about it's availability in the API definition
    v8: drop access_ok check, fix VM mapping bits
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com> (v4)
    Reviewed-by: Jérôme Glisse <jglisse@redhat.com> (v4)
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 480c87d8edc5..c73c1e320585 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -264,6 +264,9 @@ int radeon_bo_pin_restricted(struct radeon_bo *bo, u32 domain, u64 max_offset,
 {
 	int r, i;
 
+	if (radeon_ttm_tt_has_userptr(bo->tbo.ttm))
+		return -EPERM;
+
 	if (bo->pin_count) {
 		bo->pin_count++;
 		if (gpu_addr)

commit 512d8afc5d971be1e32596c6ad0a68abe1373cd9
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Jul 30 21:04:56 2014 +0200

    drm/radeon: add radeon_bo_ref function
    
    To be consistent with radeon_bo_unref, needed in the following patch.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 9505766e46dd..480c87d8edc5 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -236,6 +236,15 @@ void radeon_bo_kunmap(struct radeon_bo *bo)
 	ttm_bo_kunmap(&bo->kmap);
 }
 
+struct radeon_bo *radeon_bo_ref(struct radeon_bo *bo)
+{
+	if (bo == NULL)
+		return NULL;
+
+	ttm_bo_reference(&bo->tbo);
+	return bo;
+}
+
 void radeon_bo_unref(struct radeon_bo **bo)
 {
 	struct ttm_buffer_object *tbo;

commit e7e31600d3e2f8b7726b0521149fc55c62a90467
Author: Christian König <christian.koenig@amd.com>
Date:   Wed Jul 30 21:04:55 2014 +0200

    drm/radeon: remove taking mclk_lock from radeon_bo_unref
    
    It's causing lockdep warnings and why should
    we access the memory that is freed up?
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 78b74c88d145..9505766e46dd 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -245,9 +245,7 @@ void radeon_bo_unref(struct radeon_bo **bo)
 		return;
 	rdev = (*bo)->rdev;
 	tbo = &((*bo)->tbo);
-	down_read(&rdev->pm.mclk_lock);
 	ttm_bo_unref(&tbo);
-	up_read(&rdev->pm.mclk_lock);
 	if (tbo == NULL)
 		*bo = NULL;
 }

commit c265f24d5ca3bf2877e857b93b0246098767e6a9
Author: Christian König <christian.koenig@amd.com>
Date:   Fri Jul 18 09:24:54 2014 +0200

    drm/radeon: remove radeon_bo_clear_va
    
    Won't work anyway, instead WARN_ON if the VA list isn't
    empty when we free the BO.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Tested-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index a00cf17a0510..78b74c88d145 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -46,16 +46,6 @@ static void radeon_bo_clear_surface_reg(struct radeon_bo *bo);
  * function are calling it.
  */
 
-static void radeon_bo_clear_va(struct radeon_bo *bo)
-{
-	struct radeon_bo_va *bo_va, *tmp;
-
-	list_for_each_entry_safe(bo_va, tmp, &bo->va, bo_list) {
-		/* remove from all vm address space */
-		radeon_vm_bo_rmv(bo->rdev, bo_va);
-	}
-}
-
 static void radeon_update_memory_usage(struct radeon_bo *bo,
 				       unsigned mem_type, int sign)
 {
@@ -90,7 +80,7 @@ static void radeon_ttm_bo_destroy(struct ttm_buffer_object *tbo)
 	list_del_init(&bo->list);
 	mutex_unlock(&bo->rdev->gem.mutex);
 	radeon_bo_clear_surface_reg(bo);
-	radeon_bo_clear_va(bo);
+	WARN_ON(!list_empty(&bo->va));
 	drm_gem_object_release(&bo->gem_base);
 	kfree(bo);
 }

commit 71ecc97eaa365b5020cd85a793f4d59c96c81e68
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Thu Jul 17 12:09:25 2014 -0400

    drm/radeon: track pinned memory (v2)
    
    So we know how large an allocation we can allow.
    
    v2: incorporate Michel's comments
    
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 1b05a4de5c0a..a00cf17a0510 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -306,9 +306,13 @@ int radeon_bo_pin_restricted(struct radeon_bo *bo, u32 domain, u64 max_offset,
 		bo->pin_count = 1;
 		if (gpu_addr != NULL)
 			*gpu_addr = radeon_bo_gpu_offset(bo);
-	}
-	if (unlikely(r != 0))
+		if (domain == RADEON_GEM_DOMAIN_VRAM)
+			bo->rdev->vram_pin_size += radeon_bo_size(bo);
+		else
+			bo->rdev->gart_pin_size += radeon_bo_size(bo);
+	} else {
 		dev_err(bo->rdev->dev, "%p pin failed\n", bo);
+	}
 	return r;
 }
 
@@ -331,8 +335,14 @@ int radeon_bo_unpin(struct radeon_bo *bo)
 	for (i = 0; i < bo->placement.num_placement; i++)
 		bo->placements[i] &= ~TTM_PL_FLAG_NO_EVICT;
 	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false);
-	if (unlikely(r != 0))
+	if (likely(r == 0)) {
+		if (bo->tbo.mem.mem_type == TTM_PL_VRAM)
+			bo->rdev->vram_pin_size -= radeon_bo_size(bo);
+		else
+			bo->rdev->gart_pin_size -= radeon_bo_size(bo);
+	} else {
 		dev_err(bo->rdev->dev, "%p validate failed for unpin\n", bo);
+	}
 	return r;
 }
 

commit 02376d8282b88f07d0716da6155094c8760b1a13
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Thu Jul 17 19:01:08 2014 +0900

    drm/radeon: Allow write-combined CPU mappings of BOs in GTT (v2)
    
    v2: fix rebase onto drm-fixes
    
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 6c717b257d6d..1b05a4de5c0a 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -114,15 +114,23 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 		rbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED |
 					TTM_PL_FLAG_VRAM;
 	if (domain & RADEON_GEM_DOMAIN_GTT) {
-		if (rbo->rdev->flags & RADEON_IS_AGP) {
-			rbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_TT;
+		if (rbo->flags & RADEON_GEM_GTT_UC) {
+			rbo->placements[c++] = TTM_PL_FLAG_UNCACHED | TTM_PL_FLAG_TT;
+		} else if ((rbo->flags & RADEON_GEM_GTT_WC) ||
+			   (rbo->rdev->flags & RADEON_IS_AGP)) {
+			rbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED |
+				TTM_PL_FLAG_TT;
 		} else {
 			rbo->placements[c++] = TTM_PL_FLAG_CACHED | TTM_PL_FLAG_TT;
 		}
 	}
 	if (domain & RADEON_GEM_DOMAIN_CPU) {
-		if (rbo->rdev->flags & RADEON_IS_AGP) {
-			rbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_SYSTEM;
+		if (rbo->flags & RADEON_GEM_GTT_UC) {
+			rbo->placements[c++] = TTM_PL_FLAG_UNCACHED | TTM_PL_FLAG_SYSTEM;
+		} else if ((rbo->flags & RADEON_GEM_GTT_WC) ||
+		    rbo->rdev->flags & RADEON_IS_AGP) {
+			rbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED |
+				TTM_PL_FLAG_SYSTEM;
 		} else {
 			rbo->placements[c++] = TTM_PL_FLAG_CACHED | TTM_PL_FLAG_SYSTEM;
 		}
@@ -146,7 +154,7 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 
 int radeon_bo_create(struct radeon_device *rdev,
 		     unsigned long size, int byte_align, bool kernel, u32 domain,
-		     struct sg_table *sg, struct radeon_bo **bo_ptr)
+		     u32 flags, struct sg_table *sg, struct radeon_bo **bo_ptr)
 {
 	struct radeon_bo *bo;
 	enum ttm_bo_type type;
@@ -183,6 +191,12 @@ int radeon_bo_create(struct radeon_device *rdev,
 	bo->initial_domain = domain & (RADEON_GEM_DOMAIN_VRAM |
 	                               RADEON_GEM_DOMAIN_GTT |
 	                               RADEON_GEM_DOMAIN_CPU);
+
+	bo->flags = flags;
+	/* PCI GART is always snooped */
+	if (!(rdev->flags & RADEON_IS_PCIE))
+		bo->flags &= ~(RADEON_GEM_GTT_WC | RADEON_GEM_GTT_UC);
+
 	radeon_ttm_placement_from_domain(bo, domain);
 	/* Kernel allocation are uninterruptible */
 	down_read(&rdev->pm.mclk_lock);

commit ce6758c8bd36bd77519f8f1ace46f8f1ba5decaf
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jun 2 17:33:07 2014 +0200

    drm/radeon: rename alt_domain to allowed_domains
    
    And also domain to prefered_domains. That matches better
    what those values represent.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Cc: Marek Olšák <maraeo@gmail.com>
    Reviewed-by: Marek Olšák <marek.olsak@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 2918087e572f..6c717b257d6d 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -446,7 +446,7 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 	list_for_each_entry(lobj, head, tv.head) {
 		bo = lobj->robj;
 		if (!bo->pin_count) {
-			u32 domain = lobj->domain;
+			u32 domain = lobj->prefered_domains;
 			u32 current_domain =
 				radeon_mem_type_to_domain(bo->tbo.mem.mem_type);
 
@@ -458,7 +458,7 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 			 * into account. We don't want to disallow buffer moves
 			 * completely.
 			 */
-			if ((lobj->alt_domain & current_domain) != 0 &&
+			if ((lobj->allowed_domains & current_domain) != 0 &&
 			    (domain & current_domain) == 0 && /* will be moved */
 			    bytes_moved > bytes_moved_threshold) {
 				/* don't move it */
@@ -476,8 +476,9 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 				       initial_bytes_moved;
 
 			if (unlikely(r)) {
-				if (r != -ERESTARTSYS && domain != lobj->alt_domain) {
-					domain = lobj->alt_domain;
+				if (r != -ERESTARTSYS &&
+				    domain != lobj->allowed_domains) {
+					domain = lobj->allowed_domains;
 					goto retry;
 				}
 				ttm_eu_backoff_reservation(ticket, head);

commit 8d4ad9d4bb0a618c975a32d77087694ec6336f68
Merge: 5ea1f752ae04 9e9a928eed87
Author: Dave Airlie <airlied@redhat.com>
Date:   Thu Jun 5 20:28:59 2014 +1000

    Merge commit '9e9a928eed8796a0a1aaed7e0b676db86ba84594' into drm-next
    
    Merge drm-fixes into drm-next.
    
    Both i915 and radeon need this done for later patches.
    
    Conflicts:
            drivers/gpu/drm/drm_crtc_helper.c
            drivers/gpu/drm/i915/i915_drv.h
            drivers/gpu/drm/i915/i915_gem.c
            drivers/gpu/drm/i915/i915_gem_execbuffer.c
            drivers/gpu/drm/i915/i915_gem_gtt.c

commit 1243235469198fa7d6acbf91a828bfda2bfb120d
Author: Michele CURTI <michele.curti@gmail.com>
Date:   Mon May 19 11:18:52 2014 -0400

    drm/radeon: use NULL instead of zero in object functions
    
    Signed-off-by: Michele Curti <michele.curti@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 19bec0dbfa38..95197aa4de4a 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -722,7 +722,7 @@ int radeon_bo_wait(struct radeon_bo *bo, u32 *mem_type, bool no_wait)
 {
 	int r;
 
-	r = ttm_bo_reserve(&bo->tbo, true, no_wait, false, 0);
+	r = ttm_bo_reserve(&bo->tbo, true, no_wait, false, NULL);
 	if (unlikely(r != 0))
 		return r;
 	spin_lock(&bo->tbo.bdev->fence_lock);

commit 4b09556660bfe1b43d72ca858524c6baf2c6cb1d
Author: Christian König <christian.koenig@amd.com>
Date:   Sat May 10 18:17:09 2014 +0200

    drm/radeon: fix buffer placement under memory pressure v2
    
    Some buffers (UVD/VM page tables) must be placed in VRAM,
    but the byte restriction for moving buffers didn't took this
    into account.
    
    v2: keep closer to the original code
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Marek Olšák <marek.olsak@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 72705fb40d55..4faa4d6f9bb4 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -458,7 +458,7 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 			 * into account. We don't want to disallow buffer moves
 			 * completely.
 			 */
-			if (current_domain != RADEON_GEM_DOMAIN_CPU &&
+			if ((lobj->alt_domain & current_domain) != 0 &&
 			    (domain & current_domain) == 0 && /* will be moved */
 			    bytes_moved > bytes_moved_threshold) {
 				/* don't move it */

commit 544092596e8ac269f70e70961b5e9381909c9b1e
Author: Christian König <christian.koenig@amd.com>
Date:   Mon May 5 18:40:12 2014 +0200

    drm/radeon: also try GART for CPU accessed buffers
    
    Placing them exclusively into VRAM might not work all the time.
    
    Fixes: https://bugs.freedesktop.org/show_bug.cgi?id=78297
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 19bec0dbfa38..72705fb40d55 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -699,22 +699,30 @@ int radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
 	rbo = container_of(bo, struct radeon_bo, tbo);
 	radeon_bo_check_tiling(rbo, 0, 0);
 	rdev = rbo->rdev;
-	if (bo->mem.mem_type == TTM_PL_VRAM) {
-		size = bo->mem.num_pages << PAGE_SHIFT;
-		offset = bo->mem.start << PAGE_SHIFT;
-		if ((offset + size) > rdev->mc.visible_vram_size) {
-			/* hurrah the memory is not visible ! */
-			radeon_ttm_placement_from_domain(rbo, RADEON_GEM_DOMAIN_VRAM);
-			rbo->placement.lpfn = rdev->mc.visible_vram_size >> PAGE_SHIFT;
-			r = ttm_bo_validate(bo, &rbo->placement, false, false);
-			if (unlikely(r != 0))
-				return r;
-			offset = bo->mem.start << PAGE_SHIFT;
-			/* this should not happen */
-			if ((offset + size) > rdev->mc.visible_vram_size)
-				return -EINVAL;
-		}
+	if (bo->mem.mem_type != TTM_PL_VRAM)
+		return 0;
+
+	size = bo->mem.num_pages << PAGE_SHIFT;
+	offset = bo->mem.start << PAGE_SHIFT;
+	if ((offset + size) <= rdev->mc.visible_vram_size)
+		return 0;
+
+	/* hurrah the memory is not visible ! */
+	radeon_ttm_placement_from_domain(rbo, RADEON_GEM_DOMAIN_VRAM);
+	rbo->placement.lpfn = rdev->mc.visible_vram_size >> PAGE_SHIFT;
+	r = ttm_bo_validate(bo, &rbo->placement, false, false);
+	if (unlikely(r == -ENOMEM)) {
+		radeon_ttm_placement_from_domain(rbo, RADEON_GEM_DOMAIN_GTT);
+		return ttm_bo_validate(bo, &rbo->placement, false, false);
+	} else if (unlikely(r != 0)) {
+		return r;
 	}
+
+	offset = bo->mem.start << PAGE_SHIFT;
+	/* this should never happen */
+	if ((offset + size) > rdev->mc.visible_vram_size)
+		return -EINVAL;
+
 	return 0;
 }
 

commit deadcb36f49bee9b3010382ffe4fe4f5c439f1c5
Author: Lauri Kasanen <cand@gmx.com>
Date:   Wed Apr 2 20:33:42 2014 +0300

    drm/radeon: Use two-ended allocation by size, v2
    
    This decreases eviction by up to 20%, by improving the fragmentation
    quality. No harm in normal cases that fit VRAM fully (PTS gaming suite).
    
    In some cases, even the VRAM-fitting cases improved slightly (openarena, urban terror).
    
    512kb was measured as the most optimal threshold for 3d workloads common to radeon.
    Other drivers may need different thresholds according to their workloads.
    
    v2: Nicer formatting
    Signed-off-by: Lauri Kasanen <cand@gmx.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 1375ff85b08a..19bec0dbfa38 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -104,7 +104,7 @@ bool radeon_ttm_bo_is_radeon_bo(struct ttm_buffer_object *bo)
 
 void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 {
-	u32 c = 0;
+	u32 c = 0, i;
 
 	rbo->placement.fpfn = 0;
 	rbo->placement.lpfn = 0;
@@ -131,6 +131,17 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 		rbo->placements[c++] = TTM_PL_MASK_CACHING | TTM_PL_FLAG_SYSTEM;
 	rbo->placement.num_placement = c;
 	rbo->placement.num_busy_placement = c;
+
+	/*
+	 * Use two-ended allocation depending on the buffer size to
+	 * improve fragmentation quality.
+	 * 512kb was measured as the most optimal number.
+	 */
+	if (rbo->tbo.mem.size > 512 * 1024) {
+		for (i = 0; i < c; i++) {
+			rbo->placements[i] |= TTM_PL_FLAG_TOPDOWN;
+		}
+	}
 }
 
 int radeon_bo_create(struct radeon_device *rdev,

commit 44d847b7439bdea0b6c5640446427daa3ebcc7fa
Author: David Herrmann <dh.herrmann@gmail.com>
Date:   Tue Aug 13 19:10:30 2013 +0200

    drm: init TTM dev_mapping in ttm_bo_device_init()
    
    With dev->anon_inode we have a global address_space ready for operation
    right from the beginning. Therefore, there is no need to do a delayed
    setup with TTM. Instead, set dev_mapping during initialization in
    ttm_bo_device_init() and remove any "if (dev_mapping)" conditions.
    
    Cc: Dave Airlie <airlied@redhat.com>
    Cc: Ben Skeggs <bskeggs@redhat.com>
    Cc: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Cc: Alex Deucher <alexdeucher@gmail.com>
    Cc: Thomas Hellstrom <thellstrom@vmware.com>
    Signed-off-by: David Herrmann <dh.herrmann@gmail.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 6a7f3c6ffbbe..1375ff85b08a 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -145,7 +145,6 @@ int radeon_bo_create(struct radeon_device *rdev,
 
 	size = ALIGN(size, PAGE_SIZE);
 
-	rdev->mman.bdev.dev_mapping = rdev->ddev->anon_inode->i_mapping;
 	if (kernel) {
 		type = ttm_bo_type_kernel;
 	} else if (sg) {

commit 6796cb16c088905bf3af40548fda68c09e6f6ee5
Author: David Herrmann <dh.herrmann@gmail.com>
Date:   Fri Jan 3 14:24:19 2014 +0100

    drm: use anon-inode instead of relying on cdevs
    
    DRM drivers share a common address_space across all character-devices of a
    single DRM device. This allows simple buffer eviction and mapping-control.
    However, DRM core currently waits for the first ->open() on any char-dev
    to mark the underlying inode as backing inode of the device. This delayed
    initialization causes ugly conditions all over the place:
      if (dev->dev_mapping)
        do_sth();
    
    To avoid delayed initialization and to stop reusing the inode of the
    char-dev, we allocate an anonymous inode for each DRM device and reset
    filp->f_mapping to it on ->open().
    
    Signed-off-by: David Herrmann <dh.herrmann@gmail.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index ca79431b2c1c..6a7f3c6ffbbe 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -145,7 +145,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 
 	size = ALIGN(size, PAGE_SIZE);
 
-	rdev->mman.bdev.dev_mapping = rdev->ddev->dev_mapping;
+	rdev->mman.bdev.dev_mapping = rdev->ddev->anon_inode->i_mapping;
 	if (kernel) {
 		type = ttm_bo_type_kernel;
 	} else if (sg) {

commit df0af4403aa8df728a62ccb62a61b3244871068f
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Mar 3 12:38:08 2014 +0100

    drm/radeon: remove struct radeon_bo_list
    
    Just move all fields into radeon_cs_reloc, removing unused/duplicated fields.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index ed03f2d15853..ca79431b2c1c 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -422,7 +422,7 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 			    struct ww_acquire_ctx *ticket,
 			    struct list_head *head, int ring)
 {
-	struct radeon_bo_list *lobj;
+	struct radeon_cs_reloc *lobj;
 	struct radeon_bo *bo;
 	int r;
 	u64 bytes_moved = 0, initial_bytes_moved;
@@ -434,7 +434,7 @@ int radeon_bo_list_validate(struct radeon_device *rdev,
 	}
 
 	list_for_each_entry(lobj, head, tv.head) {
-		bo = lobj->bo;
+		bo = lobj->robj;
 		if (!bo->pin_count) {
 			u32 domain = lobj->domain;
 			u32 current_domain =

commit 19dff56a5f4ba1f3a6e28282415a95a48c27bccf
Author: Marek Olšák <marek.olsak@amd.com>
Date:   Sun Mar 2 00:56:22 2014 +0100

    drm/radeon: limit how much memory TTM can move per IB according to VRAM usage
    
    Signed-off-by: Marek Olšák <marek.olsak@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 8399fe021769..ed03f2d15853 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -366,29 +366,105 @@ void radeon_bo_fini(struct radeon_device *rdev)
 	arch_phys_wc_del(rdev->mc.vram_mtrr);
 }
 
-int radeon_bo_list_validate(struct ww_acquire_ctx *ticket,
+/* Returns how many bytes TTM can move per IB.
+ */
+static u64 radeon_bo_get_threshold_for_moves(struct radeon_device *rdev)
+{
+	u64 real_vram_size = rdev->mc.real_vram_size;
+	u64 vram_usage = atomic64_read(&rdev->vram_usage);
+
+	/* This function is based on the current VRAM usage.
+	 *
+	 * - If all of VRAM is free, allow relocating the number of bytes that
+	 *   is equal to 1/4 of the size of VRAM for this IB.
+
+	 * - If more than one half of VRAM is occupied, only allow relocating
+	 *   1 MB of data for this IB.
+	 *
+	 * - From 0 to one half of used VRAM, the threshold decreases
+	 *   linearly.
+	 *         __________________
+	 * 1/4 of -|\               |
+	 * VRAM    | \              |
+	 *         |  \             |
+	 *         |   \            |
+	 *         |    \           |
+	 *         |     \          |
+	 *         |      \         |
+	 *         |       \________|1 MB
+	 *         |----------------|
+	 *    VRAM 0 %             100 %
+	 *         used            used
+	 *
+	 * Note: It's a threshold, not a limit. The threshold must be crossed
+	 * for buffer relocations to stop, so any buffer of an arbitrary size
+	 * can be moved as long as the threshold isn't crossed before
+	 * the relocation takes place. We don't want to disable buffer
+	 * relocations completely.
+	 *
+	 * The idea is that buffers should be placed in VRAM at creation time
+	 * and TTM should only do a minimum number of relocations during
+	 * command submission. In practice, you need to submit at least
+	 * a dozen IBs to move all buffers to VRAM if they are in GTT.
+	 *
+	 * Also, things can get pretty crazy under memory pressure and actual
+	 * VRAM usage can change a lot, so playing safe even at 50% does
+	 * consistently increase performance.
+	 */
+
+	u64 half_vram = real_vram_size >> 1;
+	u64 half_free_vram = vram_usage >= half_vram ? 0 : half_vram - vram_usage;
+	u64 bytes_moved_threshold = half_free_vram >> 1;
+	return max(bytes_moved_threshold, 1024*1024ull);
+}
+
+int radeon_bo_list_validate(struct radeon_device *rdev,
+			    struct ww_acquire_ctx *ticket,
 			    struct list_head *head, int ring)
 {
 	struct radeon_bo_list *lobj;
 	struct radeon_bo *bo;
-	u32 domain;
 	int r;
+	u64 bytes_moved = 0, initial_bytes_moved;
+	u64 bytes_moved_threshold = radeon_bo_get_threshold_for_moves(rdev);
 
 	r = ttm_eu_reserve_buffers(ticket, head);
 	if (unlikely(r != 0)) {
 		return r;
 	}
+
 	list_for_each_entry(lobj, head, tv.head) {
 		bo = lobj->bo;
 		if (!bo->pin_count) {
-			domain = lobj->domain;
-			
+			u32 domain = lobj->domain;
+			u32 current_domain =
+				radeon_mem_type_to_domain(bo->tbo.mem.mem_type);
+
+			/* Check if this buffer will be moved and don't move it
+			 * if we have moved too many buffers for this IB already.
+			 *
+			 * Note that this allows moving at least one buffer of
+			 * any size, because it doesn't take the current "bo"
+			 * into account. We don't want to disallow buffer moves
+			 * completely.
+			 */
+			if (current_domain != RADEON_GEM_DOMAIN_CPU &&
+			    (domain & current_domain) == 0 && /* will be moved */
+			    bytes_moved > bytes_moved_threshold) {
+				/* don't move it */
+				domain = current_domain;
+			}
+
 		retry:
 			radeon_ttm_placement_from_domain(bo, domain);
 			if (ring == R600_RING_TYPE_UVD_INDEX)
 				radeon_uvd_force_into_uvd_segment(bo);
-			r = ttm_bo_validate(&bo->tbo, &bo->placement,
-						true, false);
+
+			initial_bytes_moved = atomic64_read(&rdev->num_bytes_moved);
+			r = ttm_bo_validate(&bo->tbo, &bo->placement, true, false);
+			bytes_moved += atomic64_read(&rdev->num_bytes_moved) -
+				       initial_bytes_moved;
+
 			if (unlikely(r)) {
 				if (r != -ERESTARTSYS && domain != lobj->alt_domain) {
 					domain = lobj->alt_domain;

commit c9b76548899cde2e729e3bca015d7e78ec5baad7
Author: Marek Olšák <marek.olsak@amd.com>
Date:   Sun Mar 2 00:56:21 2014 +0100

    drm/radeon: validate relocations in the order determined by userspace v3
    
    Userspace should set the first 4 bits of drm_radeon_cs_reloc::flags to
    a number from 0 to 15. The higher the number, the higher the priority,
    which means a buffer with a higher number will be validated sooner.
    
    The old behavior is preserved: Buffers used for write are prioritized over
    read-only buffers if the userspace doesn't set the number.
    
    v2: add buffers to buckets directly, then concatenate them
    v3: use a stable sort
    
    Signed-off-by: Marek Olšák <marek.olsak@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 282d6a248396..8399fe021769 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -366,16 +366,6 @@ void radeon_bo_fini(struct radeon_device *rdev)
 	arch_phys_wc_del(rdev->mc.vram_mtrr);
 }
 
-void radeon_bo_list_add_object(struct radeon_bo_list *lobj,
-				struct list_head *head)
-{
-	if (lobj->written) {
-		list_add(&lobj->tv.head, head);
-	} else {
-		list_add_tail(&lobj->tv.head, head);
-	}
-}
-
 int radeon_bo_list_validate(struct ww_acquire_ctx *ticket,
 			    struct list_head *head, int ring)
 {

commit 67e8e3f970ad747d3c854fb40f8ec0cecedd9089
Author: Marek Olšák <marek.olsak@amd.com>
Date:   Sun Mar 2 00:56:18 2014 +0100

    drm/radeon: track memory statistics about VRAM and GTT usage and buffer moves v2
    
    The statistics are:
    - VRAM usage in bytes
    - GTT usage in bytes
    - number of bytes moved by TTM
    
    The last one is actually a counter, so you need to sample it before and after
    command submission and take the difference.
    
    This is useful for finding performance bottlenecks. Userspace queries are
    also added.
    
    v2: use atomic64_t
    
    Signed-off-by: Marek Olšák <marek.olsak@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index dd12bb4025ac..282d6a248396 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -56,11 +56,36 @@ static void radeon_bo_clear_va(struct radeon_bo *bo)
 	}
 }
 
+static void radeon_update_memory_usage(struct radeon_bo *bo,
+				       unsigned mem_type, int sign)
+{
+	struct radeon_device *rdev = bo->rdev;
+	u64 size = (u64)bo->tbo.num_pages << PAGE_SHIFT;
+
+	switch (mem_type) {
+	case TTM_PL_TT:
+		if (sign > 0)
+			atomic64_add(size, &rdev->gtt_usage);
+		else
+			atomic64_sub(size, &rdev->gtt_usage);
+		break;
+	case TTM_PL_VRAM:
+		if (sign > 0)
+			atomic64_add(size, &rdev->vram_usage);
+		else
+			atomic64_sub(size, &rdev->vram_usage);
+		break;
+	}
+}
+
 static void radeon_ttm_bo_destroy(struct ttm_buffer_object *tbo)
 {
 	struct radeon_bo *bo;
 
 	bo = container_of(tbo, struct radeon_bo, tbo);
+
+	radeon_update_memory_usage(bo, bo->tbo.mem.mem_type, -1);
+
 	mutex_lock(&bo->rdev->gem.mutex);
 	list_del_init(&bo->list);
 	mutex_unlock(&bo->rdev->gem.mutex);
@@ -567,14 +592,23 @@ int radeon_bo_check_tiling(struct radeon_bo *bo, bool has_moved,
 }
 
 void radeon_bo_move_notify(struct ttm_buffer_object *bo,
-			   struct ttm_mem_reg *mem)
+			   struct ttm_mem_reg *new_mem)
 {
 	struct radeon_bo *rbo;
+
 	if (!radeon_ttm_bo_is_radeon_bo(bo))
 		return;
+
 	rbo = container_of(bo, struct radeon_bo, tbo);
 	radeon_bo_check_tiling(rbo, 0, 1);
 	radeon_vm_bo_invalidate(rbo->rdev, rbo);
+
+	/* update statistics */
+	if (!new_mem)
+		return;
+
+	radeon_update_memory_usage(rbo, bo->mem.mem_type, -1);
+	radeon_update_memory_usage(rbo, new_mem->mem_type, 1);
 }
 
 int radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)

commit bda72d58a20120aee1f78eb17d7eddb955d6696b
Author: Marek Olšák <marek.olsak@amd.com>
Date:   Sun Mar 2 00:56:17 2014 +0100

    drm/radeon: add a way to get and set initial buffer domains v2
    
    When passing buffers between processes, the receiving process needs to know
    the original buffer domain, so that it doesn't accidentally move the buffer.
    
    v2: reserve the buffer
    
    Signed-off-by: Marek Olšák <marek.olsak@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 08595cf90b01..dd12bb4025ac 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -145,6 +145,9 @@ int radeon_bo_create(struct radeon_device *rdev,
 	bo->surface_reg = -1;
 	INIT_LIST_HEAD(&bo->list);
 	INIT_LIST_HEAD(&bo->va);
+	bo->initial_domain = domain & (RADEON_GEM_DOMAIN_VRAM |
+	                               RADEON_GEM_DOMAIN_GTT |
+	                               RADEON_GEM_DOMAIN_CPU);
 	radeon_ttm_placement_from_domain(bo, domain);
 	/* Kernel allocation are uninterruptible */
 	down_read(&rdev->pm.mclk_lock);

commit 2f43651c18b450bd5b71ede18dce54bfc7b1719b
Author: Rashika Kheria <rashika.kheria@gmail.com>
Date:   Mon Jan 6 20:55:28 2014 +0530

    drivers: gpu: Mark function as static in radeon_object.c
    
    Mark function radeon_bo_clear_va() as static in
    drm/radeon/radeon_object.c because it is not used outside this file.
    
    This eliminates the following warning in drm/radeon/radeon_object.c:
    drivers/gpu/drm/radeon/radeon_object.c:49:6: warning: no previous prototype for ‘radeon_bo_clear_va’ [-Wmissing-prototypes]
    
    Signed-off-by: Rashika Kheria <rashika.kheria@gmail.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index c0fa4aa9ceea..08595cf90b01 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -46,7 +46,7 @@ static void radeon_bo_clear_surface_reg(struct radeon_bo *bo);
  * function are calling it.
  */
 
-void radeon_bo_clear_va(struct radeon_bo *bo)
+static void radeon_bo_clear_va(struct radeon_bo *bo)
 {
 	struct radeon_bo_va *bo_va, *tmp;
 

commit e552df37ad589f75af969d536ee9c70c94cacccf
Author: David Herrmann <dh.herrmann@gmail.com>
Date:   Wed Aug 14 15:07:18 2013 +0200

    drm/radeon: remove stale gem->driver_private access
    
    This field is never read. No need to set it in radeon. Besides, DRM gem
    core clears it during setup, anyway.
    
    Signed-off-by: David Herrmann <dh.herrmann@gmail.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 2020bf4a3830..c0fa4aa9ceea 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -142,7 +142,6 @@ int radeon_bo_create(struct radeon_device *rdev,
 		return r;
 	}
 	bo->rdev = rdev;
-	bo->gem_base.driver_private = NULL;
 	bo->surface_reg = -1;
 	INIT_LIST_HEAD(&bo->list);
 	INIT_LIST_HEAD(&bo->va);

commit 1b6e5fd5f4fc152064f4f71cea0bcfeb49e29b8b
Author: Maarten Lankhorst <maarten.lankhorst@canonical.com>
Date:   Wed Jul 10 12:26:56 2013 +0200

    drm/radeon: add missing ttm_eu_backoff_reservation to radeon_bo_list_validate
    
    Op 10-07-13 12:03, Markus Trippelsdorf schreef:
    > On 2013.07.10 at 11:56 +0200, Maarten Lankhorst wrote:
    >> Op 10-07-13 11:46, Markus Trippelsdorf schreef:
    >>> On 2013.07.10 at 11:29 +0200, Maarten Lankhorst wrote:
    >>>> Op 10-07-13 11:22, Markus Trippelsdorf schreef:
    >>>>> By simply copy/pasting a big document under LibreOffice my system hangs
    >>>>> itself up. Only a hard reset gets it working again.
    >>>>> see also: https://bugs.freedesktop.org/show_bug.cgi?id=66551
    >>>>>
    >>>>> I've bisected the issue to:
    >>>>>
    >>>>> commit ecff665f5e3f1c6909353e00b9420e45ae23d995
    >>>>> Author: Maarten Lankhorst <m.b.lankhorst@gmail.com>
    >>>>> Date:   Thu Jun 27 13:48:17 2013 +0200
    >>>>>
    >>>>>     drm/ttm: make ttm reservation calls behave like reservation calls
    >>>>>
    >>>>>     This commit converts the source of the val_seq counter to
    >>>>>     the ww_mutex api. The reservation objects are converted later,
    >>>>>     because there is still a lockdep splat in nouveau that has to
    >>>>>     resolved first.
    >>>>>
    >>>>>     Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    >>>>>     Reviewed-by: Jerome Glisse <jglisse@redhat.com>
    >>>>>     Signed-off-by: Dave Airlie <airlied@redhat.com>
    >>>> Hey,
    >>>>
    >>>> Can you try current head with CONFIG_PROVE_LOCKING set and post the
    >>>> lockdep splat from dmesg, if any? If there is any locking issue
    >>>> lockdep should warn about it.  Lockdep will turn itself off after the
    >>>> first splat, so if the lockdep splat happens before running the
    >>>> affected parts those will have to be fixed first.
    >>> There was an unrelated EDAC lockdep splat, so I simply disabled it.
    >>>
    >>> This is what I get:
    >>>
    >>> Jul 10 11:40:44 x4 kernel: ================================================
    >>> Jul 10 11:40:44 x4 kernel: [ BUG: lock held when returning to user space! ]
    >>> Jul 10 11:40:44 x4 kernel: 3.10.0-08587-g496322b #35 Not tainted
    >>> Jul 10 11:40:44 x4 kernel: ------------------------------------------------
    >>> Jul 10 11:40:44 x4 kernel: X/211 is leaving the kernel with locks still held!
    >>> Jul 10 11:40:44 x4 kernel: 2 locks held by X/211:
    >>> Jul 10 11:40:44 x4 kernel: #0:  (reservation_ww_class_acquire){+.+.+.}, at: [<ffffffff813279f0>] radeon_bo_list_validate+0x20/0xd0
    >>> Jul 10 11:40:44 x4 kernel: #1:  (reservation_ww_class_mutex){+.+.+.}, at: [<ffffffff81309306>] ttm_eu_reserve_buffers+0x126/0x4b0
    >>> Jul 10 11:40:52 x4 kernel: SysRq : Emergency Sync
    >>> Jul 10 11:40:53 x4 kernel: Emergency Sync complete
    >>>
    >> Thanks, exactly what I thought. I missed a backoff somewhere..
    >>
    >> Does the below patch fix it?
    > Yes. Thank you for your quick reply.
    
    8<------
    If radeon_cs_parser_relocs fails ttm_eu_backoff_reservation doesn't get called.
    This left open a bug where ttm_eu_reserve_buffers succeeded but the bo's were
    not unlocked afterwards:
    
    Jul 10 11:40:44 x4 kernel: ================================================
    Jul 10 11:40:44 x4 kernel: [ BUG: lock held when returning to user space! ]
    Jul 10 11:40:44 x4 kernel: 3.10.0-08587-g496322b #35 Not tainted
    Jul 10 11:40:44 x4 kernel: ------------------------------------------------
    Jul 10 11:40:44 x4 kernel: X/211 is leaving the kernel with locks still held!
    Jul 10 11:40:44 x4 kernel: 2 locks held by X/211:
    Jul 10 11:40:44 x4 kernel: #0:  (reservation_ww_class_acquire){+.+.+.}, at: [<ffffffff813279f0>] radeon_bo_list_validate+0x20/0xd0
    Jul 10 11:40:44 x4 kernel: #1:  (reservation_ww_class_mutex){+.+.+.}, at: [<ffffffff81309306>] ttm_eu_reserve_buffers+0x126/0x4b0
    Jul 10 11:40:52 x4 kernel: SysRq : Emergency Sync
    Jul 10 11:40:53 x4 kernel: Emergency Sync complete
    
    This is a regression caused by commit ecff665f5e.
    "drm/ttm: make ttm reservation calls behave like reservation calls"
    
    Reported-by: Markus Trippelsdorf <markus@trippelsdorf.de>
    Tested-by: Markus Trippelsdorf <markus@trippelsdorf.de>
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 0219d263e2df..2020bf4a3830 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -377,6 +377,7 @@ int radeon_bo_list_validate(struct ww_acquire_ctx *ticket,
 					domain = lobj->alt_domain;
 					goto retry;
 				}
+				ttm_eu_backoff_reservation(ticket, head);
 				return r;
 			}
 		}

commit 977c38d50ee286b8367b65885346dd58eccd0514
Author: Maarten Lankhorst <m.b.lankhorst@gmail.com>
Date:   Thu Jun 27 13:48:26 2013 +0200

    drm/radeon: get rid of ttm_bo_is_reserved usage
    
    Try to use lockdep_assert_held or other alternatives where possible.
    
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Reviewed-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index d850dc66f4da..0219d263e2df 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -400,7 +400,7 @@ int radeon_bo_get_surface_reg(struct radeon_bo *bo)
 	int steal;
 	int i;
 
-	BUG_ON(!radeon_bo_is_reserved(bo));
+	lockdep_assert_held(&bo->tbo.resv->lock.base);
 
 	if (!bo->tiling_flags)
 		return 0;
@@ -526,7 +526,8 @@ void radeon_bo_get_tiling_flags(struct radeon_bo *bo,
 				uint32_t *tiling_flags,
 				uint32_t *pitch)
 {
-	BUG_ON(!radeon_bo_is_reserved(bo));
+	lockdep_assert_held(&bo->tbo.resv->lock.base);
+
 	if (tiling_flags)
 		*tiling_flags = bo->tiling_flags;
 	if (pitch)
@@ -536,7 +537,8 @@ void radeon_bo_get_tiling_flags(struct radeon_bo *bo,
 int radeon_bo_check_tiling(struct radeon_bo *bo, bool has_moved,
 				bool force_drop)
 {
-	BUG_ON(!radeon_bo_is_reserved(bo) && !force_drop);
+	if (!force_drop)
+		lockdep_assert_held(&bo->tbo.resv->lock.base);
 
 	if (!(bo->tiling_flags & RADEON_TILING_SURFACE))
 		return 0;

commit c43f9b16991950c00621641ef2c5cd4a3af2a052
Author: Maarten Lankhorst <m.b.lankhorst@gmail.com>
Date:   Thu Jun 27 13:48:23 2013 +0200

    drm/radeon: inline reservations
    
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Reviewed-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 71287bb7b433..d850dc66f4da 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -619,26 +619,3 @@ int radeon_bo_wait(struct radeon_bo *bo, u32 *mem_type, bool no_wait)
 	ttm_bo_unreserve(&bo->tbo);
 	return r;
 }
-
-
-/**
- * radeon_bo_reserve - reserve bo
- * @bo:		bo structure
- * @no_intr:	don't return -ERESTARTSYS on pending signal
- *
- * Returns:
- * -ERESTARTSYS: A wait for the buffer to become unreserved was interrupted by
- * a signal. Release all buffer reservations and return to user-space.
- */
-int radeon_bo_reserve(struct radeon_bo *bo, bool no_intr)
-{
-	int r;
-
-	r = ttm_bo_reserve(&bo->tbo, !no_intr, false, false, 0);
-	if (unlikely(r != 0)) {
-		if (r != -ERESTARTSYS)
-			dev_err(bo->rdev->dev, "%p reserve failed\n", bo);
-		return r;
-	}
-	return 0;
-}

commit ecff665f5e3f1c6909353e00b9420e45ae23d995
Author: Maarten Lankhorst <m.b.lankhorst@gmail.com>
Date:   Thu Jun 27 13:48:17 2013 +0200

    drm/ttm: make ttm reservation calls behave like reservation calls
    
    This commit converts the source of the val_seq counter to
    the ww_mutex api. The reservation objects are converted later,
    because there is still a lockdep splat in nouveau that has to
    resolved first.
    
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Reviewed-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 07af5a95bb62..71287bb7b433 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -349,14 +349,15 @@ void radeon_bo_list_add_object(struct radeon_bo_list *lobj,
 	}
 }
 
-int radeon_bo_list_validate(struct list_head *head, int ring)
+int radeon_bo_list_validate(struct ww_acquire_ctx *ticket,
+			    struct list_head *head, int ring)
 {
 	struct radeon_bo_list *lobj;
 	struct radeon_bo *bo;
 	u32 domain;
 	int r;
 
-	r = ttm_eu_reserve_buffers(head);
+	r = ttm_eu_reserve_buffers(ticket, head);
 	if (unlikely(r != 0)) {
 		return r;
 	}

commit 07ebea251d08ae851d501f7402359f053d038862
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Mon May 13 23:58:45 2013 +0000

    radeon: Switch to arch_phys_wc_add and add a missing ..._del
    
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 1424ccde2377..07af5a95bb62 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -322,8 +322,8 @@ int radeon_bo_init(struct radeon_device *rdev)
 {
 	/* Add an MTRR for the VRAM */
 	if (!rdev->fastfb_working) {
-		rdev->mc.vram_mtrr = mtrr_add(rdev->mc.aper_base, rdev->mc.aper_size,
-			MTRR_TYPE_WRCOMB, 1);
+		rdev->mc.vram_mtrr = arch_phys_wc_add(rdev->mc.aper_base,
+						      rdev->mc.aper_size);
 	}
 	DRM_INFO("Detected VRAM RAM=%lluM, BAR=%lluM\n",
 		rdev->mc.mc_vram_size >> 20,
@@ -336,6 +336,7 @@ int radeon_bo_init(struct radeon_device *rdev)
 void radeon_bo_fini(struct radeon_device *rdev)
 {
 	radeon_ttm_fini(rdev);
+	arch_phys_wc_del(rdev->mc.vram_mtrr);
 }
 
 void radeon_bo_list_add_object(struct radeon_bo_list *lobj,

commit f2ba57b5eab8817d86d0f108fdf1878e51dc0a37
Author: Christian König <deathsimple@vodafone.de>
Date:   Mon Apr 8 12:41:29 2013 +0200

    drm/radeon: UVD bringup v8
    
    Just everything needed to decode videos using UVD.
    
    v6: just all the bugfixes and support for R7xx-SI merged in one patch
    v7: UVD_CGC_GATE is a write only register, lockup detection fix
    v8: split out VRAM fallback changes, remove support for RV770,
        add support for HEMLOCK, add buffer sizes checks
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 4466477f1e7b..1424ccde2377 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -348,7 +348,7 @@ void radeon_bo_list_add_object(struct radeon_bo_list *lobj,
 	}
 }
 
-int radeon_bo_list_validate(struct list_head *head)
+int radeon_bo_list_validate(struct list_head *head, int ring)
 {
 	struct radeon_bo_list *lobj;
 	struct radeon_bo *bo;
@@ -366,6 +366,8 @@ int radeon_bo_list_validate(struct list_head *head)
 			
 		retry:
 			radeon_ttm_placement_from_domain(bo, domain);
+			if (ring == R600_RING_TYPE_UVD_INDEX)
+				radeon_uvd_force_into_uvd_segment(bo);
 			r = ttm_bo_validate(&bo->tbo, &bo->placement,
 						true, false);
 			if (unlikely(r)) {

commit 4474f3a91f95e3fcc62d97e36f1e8e3392c96ee0
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Apr 8 12:41:28 2013 +0200

    drm/radeon: rework fallback handling v2
    
    Let the CS module decide if we can fall back to VRAM or not.
    
    v2: remove unintended change
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 58e026afec17..4466477f1e7b 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -341,7 +341,7 @@ void radeon_bo_fini(struct radeon_device *rdev)
 void radeon_bo_list_add_object(struct radeon_bo_list *lobj,
 				struct list_head *head)
 {
-	if (lobj->wdomain) {
+	if (lobj->written) {
 		list_add(&lobj->tv.head, head);
 	} else {
 		list_add_tail(&lobj->tv.head, head);
@@ -362,15 +362,15 @@ int radeon_bo_list_validate(struct list_head *head)
 	list_for_each_entry(lobj, head, tv.head) {
 		bo = lobj->bo;
 		if (!bo->pin_count) {
-			domain = lobj->wdomain ? lobj->wdomain : lobj->rdomain;
+			domain = lobj->domain;
 			
 		retry:
 			radeon_ttm_placement_from_domain(bo, domain);
 			r = ttm_bo_validate(&bo->tbo, &bo->placement,
 						true, false);
 			if (unlikely(r)) {
-				if (r != -ERESTARTSYS && domain == RADEON_GEM_DOMAIN_VRAM) {
-					domain |= RADEON_GEM_DOMAIN_GTT;
+				if (r != -ERESTARTSYS && domain != lobj->alt_domain) {
+					domain = lobj->alt_domain;
 					goto retry;
 				}
 				return r;

commit a0a53aa8c7b491a43e2ef66786f9511bae8cbc35
Author: Samuel Li <samuel.li@amd.com>
Date:   Mon Apr 8 17:25:47 2013 -0400

    drm/radeon: Use direct mapping for fast fb access on RS690
    
    This patch allows the CPU to map the stolen vram segment
    directly rather than going through the PCI BAR.  This
    significantly improves performance for certain workloads with
    a properly patched ddx.
    
    Use radeon.fastfb=1 to enable it (disabled by default).
    Currently only supported on RS690, but support for RS780/880
    and newer APUs may be added eventually.
    
    Signed-off-by: Samuel Li <samuel.li@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index d3aface2d12d..58e026afec17 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -321,8 +321,10 @@ void radeon_bo_force_delete(struct radeon_device *rdev)
 int radeon_bo_init(struct radeon_device *rdev)
 {
 	/* Add an MTRR for the VRAM */
-	rdev->mc.vram_mtrr = mtrr_add(rdev->mc.aper_base, rdev->mc.aper_size,
+	if (!rdev->fastfb_working) {
+		rdev->mc.vram_mtrr = mtrr_add(rdev->mc.aper_base, rdev->mc.aper_size,
 			MTRR_TYPE_WRCOMB, 1);
+	}
 	DRM_INFO("Detected VRAM RAM=%lluM, BAR=%lluM\n",
 		rdev->mc.mc_vram_size >> 20,
 		(unsigned long long)rdev->mc.aper_size >> 20);

commit 20707874fd4fd37e09513f508e642fa8bd06365a
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Thu Jan 17 13:10:50 2013 -0500

    Revert "drm/radeon: do not move bo to different placement at each cs"
    
    This reverts commit d025e9e2b890db679f1246037bf65bd4be512627.
    
    This causes corruption for a number of users and needs further
    investigation in the next cycle.
    https://bugzilla.kernel.org/show_bug.cgi?id=52491
    https://bugs.freedesktop.org/show_bug.cgi?id=58659
    http://lists.freedesktop.org/archives/dri-devel/2013-January/032961.html
    
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 883c95d8d90f..d3aface2d12d 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -84,6 +84,7 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 	rbo->placement.fpfn = 0;
 	rbo->placement.lpfn = 0;
 	rbo->placement.placement = rbo->placements;
+	rbo->placement.busy_placement = rbo->placements;
 	if (domain & RADEON_GEM_DOMAIN_VRAM)
 		rbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED |
 					TTM_PL_FLAG_VRAM;
@@ -104,14 +105,6 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 	if (!c)
 		rbo->placements[c++] = TTM_PL_MASK_CACHING | TTM_PL_FLAG_SYSTEM;
 	rbo->placement.num_placement = c;
-
-	c = 0;
-	rbo->placement.busy_placement = rbo->busy_placements;
-	if (rbo->rdev->flags & RADEON_IS_AGP) {
-		rbo->busy_placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_TT;
-	} else {
-		rbo->busy_placements[c++] = TTM_PL_FLAG_CACHED | TTM_PL_FLAG_TT;
-	}
 	rbo->placement.num_busy_placement = c;
 }
 
@@ -357,6 +350,7 @@ int radeon_bo_list_validate(struct list_head *head)
 {
 	struct radeon_bo_list *lobj;
 	struct radeon_bo *bo;
+	u32 domain;
 	int r;
 
 	r = ttm_eu_reserve_buffers(head);
@@ -366,9 +360,17 @@ int radeon_bo_list_validate(struct list_head *head)
 	list_for_each_entry(lobj, head, tv.head) {
 		bo = lobj->bo;
 		if (!bo->pin_count) {
+			domain = lobj->wdomain ? lobj->wdomain : lobj->rdomain;
+			
+		retry:
+			radeon_ttm_placement_from_domain(bo, domain);
 			r = ttm_bo_validate(&bo->tbo, &bo->placement,
 						true, false);
 			if (unlikely(r)) {
+				if (r != -ERESTARTSYS && domain == RADEON_GEM_DOMAIN_VRAM) {
+					domain |= RADEON_GEM_DOMAIN_GTT;
+					goto retry;
+				}
 				return r;
 			}
 		}

commit dd54fee7d440c4a9756cce2c24a50c15e4c17ccb
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri Dec 14 21:04:46 2012 +1000

    radeon: fix regression with eviction since evict caching changes
    
    Since 0d0b3e7443bed6b49cb90fe7ddc4b5578a83a88d
    drm/radeon: use cached memory when evicting for vram on non agp
    
    evicting from TTM would try and evict to TTM instead of system,
    not so good.
    
    This should fix:
    https://bugs.freedesktop.org/show_bug.cgi?id=58272
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 93d3445477be..883c95d8d90f 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -96,9 +96,9 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 	}
 	if (domain & RADEON_GEM_DOMAIN_CPU) {
 		if (rbo->rdev->flags & RADEON_IS_AGP) {
-			rbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_TT;
+			rbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_SYSTEM;
 		} else {
-			rbo->placements[c++] = TTM_PL_FLAG_CACHED | TTM_PL_FLAG_TT;
+			rbo->placements[c++] = TTM_PL_FLAG_CACHED | TTM_PL_FLAG_SYSTEM;
 		}
 	}
 	if (!c)

commit d025e9e2b890db679f1246037bf65bd4be512627
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Thu Nov 29 10:35:41 2012 -0500

    drm/radeon: do not move bo to different placement at each cs
    
    The bo creation placement is where the bo will be. Instead of trying
    to move bo at each command stream let this work to another worker
    thread that will use more advance heuristic.
    
    agd5f: remove leftover unused variable
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index bfb332e616dc..93d3445477be 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -84,7 +84,6 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 	rbo->placement.fpfn = 0;
 	rbo->placement.lpfn = 0;
 	rbo->placement.placement = rbo->placements;
-	rbo->placement.busy_placement = rbo->placements;
 	if (domain & RADEON_GEM_DOMAIN_VRAM)
 		rbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED |
 					TTM_PL_FLAG_VRAM;
@@ -105,6 +104,14 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 	if (!c)
 		rbo->placements[c++] = TTM_PL_MASK_CACHING | TTM_PL_FLAG_SYSTEM;
 	rbo->placement.num_placement = c;
+
+	c = 0;
+	rbo->placement.busy_placement = rbo->busy_placements;
+	if (rbo->rdev->flags & RADEON_IS_AGP) {
+		rbo->busy_placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_TT;
+	} else {
+		rbo->busy_placements[c++] = TTM_PL_FLAG_CACHED | TTM_PL_FLAG_TT;
+	}
 	rbo->placement.num_busy_placement = c;
 }
 
@@ -350,7 +357,6 @@ int radeon_bo_list_validate(struct list_head *head)
 {
 	struct radeon_bo_list *lobj;
 	struct radeon_bo *bo;
-	u32 domain;
 	int r;
 
 	r = ttm_eu_reserve_buffers(head);
@@ -360,17 +366,9 @@ int radeon_bo_list_validate(struct list_head *head)
 	list_for_each_entry(lobj, head, tv.head) {
 		bo = lobj->bo;
 		if (!bo->pin_count) {
-			domain = lobj->wdomain ? lobj->wdomain : lobj->rdomain;
-			
-		retry:
-			radeon_ttm_placement_from_domain(bo, domain);
 			r = ttm_bo_validate(&bo->tbo, &bo->placement,
 						true, false);
 			if (unlikely(r)) {
-				if (r != -ERESTARTSYS && domain == RADEON_GEM_DOMAIN_VRAM) {
-					domain |= RADEON_GEM_DOMAIN_GTT;
-					goto retry;
-				}
 				return r;
 			}
 		}

commit 97a875cbdf89a4638eea57c2b456c7cc4e3e8b21
Author: Maarten Lankhorst <m.b.lankhorst@gmail.com>
Date:   Wed Nov 28 11:25:44 2012 +0000

    drm/ttm: remove no_wait_reserve, v3
    
    All items on the lru list are always reservable, so this is a stupid
    thing to keep. Not only that, it is used in a way which would
    guarantee deadlocks if it were ever to be set to block on reserve.
    
    This is a lot of churn, but mostly because of the removal of the
    argument which can be nested arbitrarily deeply in many places.
    
    No change of code in this patch except removal of the no_wait_reserve
    argument, the previous patch removed the use of no_wait_reserve.
    
    v2:
     - Warn if -EBUSY is returned on reservation, all objects on the list
       should be reservable. Adjusted patch slightly due to conflicts.
    v3:
     - Focus on no_wait_reserve removal only.
    
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Reviewed-by: Thomas Hellstrom <thellstrom@vmware.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index e6ee65cdfb5c..bfb332e616dc 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -250,7 +250,7 @@ int radeon_bo_pin_restricted(struct radeon_bo *bo, u32 domain, u64 max_offset,
 	}
 	for (i = 0; i < bo->placement.num_placement; i++)
 		bo->placements[i] |= TTM_PL_FLAG_NO_EVICT;
-	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false, false);
+	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false);
 	if (likely(r == 0)) {
 		bo->pin_count = 1;
 		if (gpu_addr != NULL)
@@ -279,7 +279,7 @@ int radeon_bo_unpin(struct radeon_bo *bo)
 		return 0;
 	for (i = 0; i < bo->placement.num_placement; i++)
 		bo->placements[i] &= ~TTM_PL_FLAG_NO_EVICT;
-	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false, false);
+	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false);
 	if (unlikely(r != 0))
 		dev_err(bo->rdev->dev, "%p validate failed for unpin\n", bo);
 	return r;
@@ -365,7 +365,7 @@ int radeon_bo_list_validate(struct list_head *head)
 		retry:
 			radeon_ttm_placement_from_domain(bo, domain);
 			r = ttm_bo_validate(&bo->tbo, &bo->placement,
-						true, false, false);
+						true, false);
 			if (unlikely(r)) {
 				if (r != -ERESTARTSYS && domain == RADEON_GEM_DOMAIN_VRAM) {
 					domain |= RADEON_GEM_DOMAIN_GTT;
@@ -585,7 +585,7 @@ int radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
 			/* hurrah the memory is not visible ! */
 			radeon_ttm_placement_from_domain(rbo, RADEON_GEM_DOMAIN_VRAM);
 			rbo->placement.lpfn = rdev->mc.visible_vram_size >> PAGE_SHIFT;
-			r = ttm_bo_validate(bo, &rbo->placement, false, true, false);
+			r = ttm_bo_validate(bo, &rbo->placement, false, false);
 			if (unlikely(r != 0))
 				return r;
 			offset = bo->mem.start << PAGE_SHIFT;

commit 6ed9ccb41209b93409c92eb8c130eada4e0832ef
Author: Maarten Lankhorst <m.b.lankhorst@gmail.com>
Date:   Wed Nov 28 11:25:40 2012 +0000

    drm/radeon: allow move_notify to be called without reservation
    
    The few places that care should have those checks instead.
    This allows destruction of bo backed memory without a reservation.
    It's required for being able to rework the delayed destroy path,
    as it is no longer guaranteed to hold a reservation before unlocking.
    
    However any previous wait is still guaranteed to complete, and it's
    one of the last things to be done before the buffer object is freed.
    
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index fe6fe2527b95..e6ee65cdfb5c 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -530,7 +530,7 @@ void radeon_bo_get_tiling_flags(struct radeon_bo *bo,
 int radeon_bo_check_tiling(struct radeon_bo *bo, bool has_moved,
 				bool force_drop)
 {
-	BUG_ON(!radeon_bo_is_reserved(bo));
+	BUG_ON(!radeon_bo_is_reserved(bo) && !force_drop);
 
 	if (!(bo->tiling_flags & RADEON_TILING_SURFACE))
 		return 0;

commit 1a1494def7eacbd25db05185aa2e81ef90892460
Merge: 8de9e417757f 71bfe916ebe6
Author: Dave Airlie <airlied@redhat.com>
Date:   Sat Dec 8 13:17:07 2012 +1000

    Merge branch 'drm-next-3.8' of git://people.freedesktop.org/~agd5f/linux into drm-next
    
    Alex writes:
    Pretty minor -next pull request.  We some additional new bits waiting
    internally for release.  Hopefully Monday we can get at least some of
    them out.  The others will probably take a few more weeks.
    
    Highlights of the current request:
    - ELD registers for passing audio information to the sound hardware
    - Handle GPUVM page faults more gracefully
    - Misc fixes
    
    Merge radeon test
    * 'drm-next-3.8' of git://people.freedesktop.org/~agd5f/linux: (483 commits)
      drm/radeon: bump driver version for new info ioctl requests
      drm/radeon: fix eDP clk and lane setup for scaled modes
      drm/radeon: add new INFO ioctl requests
      drm/radeon/dce32+: use fractional fb dividers for high clocks
      drm/radeon: use cached memory when evicting for vram on non agp
      drm/radeon: add a CS flag END_OF_FRAME
      drm/radeon: stop page faults from hanging the system (v2)
      drm/radeon/dce4/5: add registers for ELD handling
      drm/radeon/dce3.2: add registers for ELD handling
      radeon: fix pll/ctrc mapping on dce2 and dce3 hardware
      Linux 3.7-rc7
      powerpc/eeh: Do not invalidate PE properly
      Revert "drm/i915: enable rc6 on ilk again"
      ALSA: hda - Fix build without CONFIG_PM
      of/address: sparc: Declare of_iomap as an extern function for sparc again
      PM / QoS: fix wrong error-checking condition
      bnx2x: remove redundant warning log
      vxlan: fix command usage in its doc
      8139cp: revert "set ring address before enabling receiver"
      MPI: Fix compilation on MIPS with GCC 4.4 and newer
      ...
    
    Conflicts:
            drivers/gpu/drm/exynos/exynos_drm_encoder.c
            drivers/gpu/drm/exynos/exynos_drm_fbdev.c
            drivers/gpu/drm/nouveau/core/engine/disp/nv50.c

commit 0d0b3e7443bed6b49cb90fe7ddc4b5578a83a88d
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Wed Nov 28 13:47:55 2012 -0500

    drm/radeon: use cached memory when evicting for vram on non agp
    
    Force the use of cached memory when evicting from vram on non agp
    hardware. Also force write combine on agp hw. This is to insure
    the minimum cache type change when allocating memory and improving
    memory eviction especialy on pci/pcie hw.
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index b91118ccef86..3f9f3bbc4681 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -88,10 +88,20 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 	if (domain & RADEON_GEM_DOMAIN_VRAM)
 		rbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED |
 					TTM_PL_FLAG_VRAM;
-	if (domain & RADEON_GEM_DOMAIN_GTT)
-		rbo->placements[c++] = TTM_PL_MASK_CACHING | TTM_PL_FLAG_TT;
-	if (domain & RADEON_GEM_DOMAIN_CPU)
-		rbo->placements[c++] = TTM_PL_MASK_CACHING | TTM_PL_FLAG_SYSTEM;
+	if (domain & RADEON_GEM_DOMAIN_GTT) {
+		if (rbo->rdev->flags & RADEON_IS_AGP) {
+			rbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_TT;
+		} else {
+			rbo->placements[c++] = TTM_PL_FLAG_CACHED | TTM_PL_FLAG_TT;
+		}
+	}
+	if (domain & RADEON_GEM_DOMAIN_CPU) {
+		if (rbo->rdev->flags & RADEON_IS_AGP) {
+			rbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_TT;
+		} else {
+			rbo->placements[c++] = TTM_PL_FLAG_CACHED | TTM_PL_FLAG_TT;
+		}
+	}
 	if (!c)
 		rbo->placements[c++] = TTM_PL_MASK_CACHING | TTM_PL_FLAG_SYSTEM;
 	rbo->placement.num_placement = c;

commit 0b91c4a1cd7cc368763de2fe25b8ea64ea803c08
Author: Marcin Slusarz <marcin.slusarz@gmail.com>
Date:   Tue Nov 6 21:49:51 2012 +0000

    drm/ttm: remove ttm_buffer_object->buffer_start
    
    All drivers set it to 0 and nothing uses it.
    
    Signed-off-by: Marcin Slusarz <marcin.slusarz@gmail.com>
    Reviewed-by: Thomas Hellstrom <thellstrom@vmware.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 65c55556fd3f..7c4b4bb05a36 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -140,7 +140,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 	/* Kernel allocation are uninterruptible */
 	down_read(&rdev->pm.mclk_lock);
 	r = ttm_bo_init(&rdev->mman.bdev, &bo->tbo, size, type,
-			&bo->placement, page_align, 0, !kernel, NULL,
+			&bo->placement, page_align, !kernel, NULL,
 			acc_size, sg, &radeon_ttm_bo_destroy);
 	up_read(&rdev->pm.mclk_lock);
 	if (unlikely(r != 0)) {

commit 0a46fb5f41dbc7fae20764556ec7bf742cc0763a
Author: Maarten Lankhorst <maarten.lankhorst@canonical.com>
Date:   Fri Oct 12 14:59:17 2012 +0000

    drm/radeon: Use ttm_bo_is_reserved
    
    Signed-off-by: Maarten Lankhorst <maarten.lankhorst@canonical.com>
    Reviewed-by: Thomas Hellstrom <thellstrom@vmware.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index b91118ccef86..65c55556fd3f 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -384,7 +384,7 @@ int radeon_bo_get_surface_reg(struct radeon_bo *bo)
 	int steal;
 	int i;
 
-	BUG_ON(!atomic_read(&bo->tbo.reserved));
+	BUG_ON(!radeon_bo_is_reserved(bo));
 
 	if (!bo->tiling_flags)
 		return 0;
@@ -510,7 +510,7 @@ void radeon_bo_get_tiling_flags(struct radeon_bo *bo,
 				uint32_t *tiling_flags,
 				uint32_t *pitch)
 {
-	BUG_ON(!atomic_read(&bo->tbo.reserved));
+	BUG_ON(!radeon_bo_is_reserved(bo));
 	if (tiling_flags)
 		*tiling_flags = bo->tiling_flags;
 	if (pitch)
@@ -520,7 +520,7 @@ void radeon_bo_get_tiling_flags(struct radeon_bo *bo,
 int radeon_bo_check_tiling(struct radeon_bo *bo, bool has_moved,
 				bool force_drop)
 {
-	BUG_ON(!atomic_read(&bo->tbo.reserved));
+	BUG_ON(!radeon_bo_is_reserved(bo));
 
 	if (!(bo->tiling_flags & RADEON_TILING_SURFACE))
 		return 0;

commit 0fe7158c8a61ffdd71789de054fbee257c34d054
Author: Christian König <deathsimple@vodafone.de>
Date:   Tue Oct 23 15:53:19 2012 +0200

    drm/radeon: move the retry to gem_object_create
    
    When internal users want VRAM we shouldn't return GART memory instead.
    
    Signed-off-by: Christian König <deathsimple@vodafone.de>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index f404944931f5..b91118ccef86 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -123,7 +123,6 @@ int radeon_bo_create(struct radeon_device *rdev,
 	acc_size = ttm_bo_dma_acc_size(&rdev->mman.bdev, size,
 				       sizeof(struct radeon_bo));
 
-retry:
 	bo = kzalloc(sizeof(struct radeon_bo), GFP_KERNEL);
 	if (bo == NULL)
 		return -ENOMEM;
@@ -145,15 +144,6 @@ int radeon_bo_create(struct radeon_device *rdev,
 			acc_size, sg, &radeon_ttm_bo_destroy);
 	up_read(&rdev->pm.mclk_lock);
 	if (unlikely(r != 0)) {
-		if (r != -ERESTARTSYS) {
-			if (domain == RADEON_GEM_DOMAIN_VRAM) {
-				domain |= RADEON_GEM_DOMAIN_GTT;
-				goto retry;
-			}
-			dev_err(rdev->dev,
-				"object_init failed for (%lu, 0x%08X)\n",
-				size, domain);
-		}
 		return r;
 	}
 	*bo_ptr = bo;

commit 6c0d112f1fb4abba724065daa8ffbc9f0e171dc1
Author: Christian König <deathsimple@vodafone.de>
Date:   Tue Oct 23 15:53:18 2012 +0200

    drm/radeon: move size limits to gem_object_create.
    
    Driver internal users shouldn't be limited in their allocation size.
    
    Signed-off-by: Christian König <deathsimple@vodafone.de>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 8b27dd6e3144..f404944931f5 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -105,7 +105,6 @@ int radeon_bo_create(struct radeon_device *rdev,
 	struct radeon_bo *bo;
 	enum ttm_bo_type type;
 	unsigned long page_align = roundup(byte_align, PAGE_SIZE) >> PAGE_SHIFT;
-	unsigned long max_size = 0;
 	size_t acc_size;
 	int r;
 
@@ -121,14 +120,6 @@ int radeon_bo_create(struct radeon_device *rdev,
 	}
 	*bo_ptr = NULL;
 
-	/* maximun bo size is the minimun btw visible vram and gtt size */
-	max_size = min(rdev->mc.visible_vram_size, rdev->mc.gtt_size);
-	if ((page_align << PAGE_SHIFT) >= max_size) {
-		printk(KERN_WARNING "%s:%d alloc size %ldM bigger than %ldMb limit\n",
-			__func__, __LINE__, page_align  >> (20 - PAGE_SHIFT), max_size >> 20);
-		return -ENOMEM;
-	}
-
 	acc_size = ttm_bo_dma_acc_size(&rdev->mman.bdev, size,
 				       sizeof(struct radeon_bo));
 

commit 612a9aab56a93533e76e3ad91642db7033e03b69
Merge: 3a494318b14b 268d28371cd3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Oct 3 23:29:23 2012 -0700

    Merge branch 'drm-next' of git://people.freedesktop.org/~airlied/linux
    
    Pull drm merge (part 1) from Dave Airlie:
     "So first of all my tree and uapi stuff has a conflict mess, its my
      fault as the nouveau stuff didn't hit -next as were trying to rebase
      regressions out of it before we merged.
    
      Highlights:
       - SH mobile modesetting driver and associated helpers
       - some DRM core documentation
       - i915 modesetting rework, haswell hdmi, haswell and vlv fixes, write
         combined pte writing, ilk rc6 support,
       - nouveau: major driver rework into a hw core driver, makes features
         like SLI a lot saner to implement,
       - psb: add eDP/DP support for Cedarview
       - radeon: 2 layer page tables, async VM pte updates, better PLL
         selection for > 2 screens, better ACPI interactions
    
      The rest is general grab bag of fixes.
    
      So why part 1? well I have the exynos pull req which came in a bit
      late but was waiting for me to do something they shouldn't have and it
      looks fairly safe, and David Howells has some more header cleanups
      he'd like me to pull, that seem like a good idea, but I'd like to get
      this merge out of the way so -next dosen't get blocked."
    
    Tons of conflicts mostly due to silly include line changes, but mostly
    mindless.  A few other small semantic conflicts too, noted from Dave's
    pre-merged branch.
    
    * 'drm-next' of git://people.freedesktop.org/~airlied/linux: (447 commits)
      drm/nv98/crypt: fix fuc build with latest envyas
      drm/nouveau/devinit: fixup various issues with subdev ctor/init ordering
      drm/nv41/vm: fix and enable use of "real" pciegart
      drm/nv44/vm: fix and enable use of "real" pciegart
      drm/nv04/dmaobj: fixup vm target handling in preparation for nv4x pcie
      drm/nouveau: store supported dma mask in vmmgr
      drm/nvc0/ibus: initial implementation of subdev
      drm/nouveau/therm: add support for fan-control modes
      drm/nouveau/hwmon: rename pwm0* to pmw1* to follow hwmon's rules
      drm/nouveau/therm: calculate the pwm divisor on nv50+
      drm/nouveau/fan: rewrite the fan tachometer driver to get more precision, faster
      drm/nouveau/therm: move thermal-related functions to the therm subdev
      drm/nouveau/bios: parse the pwm divisor from the perf table
      drm/nouveau/therm: use the EXTDEV table to detect i2c monitoring devices
      drm/nouveau/therm: rework thermal table parsing
      drm/nouveau/gpio: expose the PWM/TOGGLE parameter found in the gpio vbios table
      drm/nouveau: fix pm initialization order
      drm/nouveau/bios: check that fixed tvdac gpio data is valid before using it
      drm/nouveau: log channel debug/error messages from client object rather than drm client
      drm/nouveau: have drm debugging macros build on top of core macros
      ...

commit 760285e7e7ab282c25b5e90816f7c47000557f4f
Author: David Howells <dhowells@redhat.com>
Date:   Tue Oct 2 18:01:07 2012 +0100

    UAPI: (Scripted) Convert #include "..." to #include <path/...> in drivers/gpu/
    
    Convert #include "..." to #include <path/...> in drivers/gpu/.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Dave Airlie <airlied@redhat.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Dave Jones <davej@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 9024e7222839..56ed724b398d 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -32,7 +32,7 @@
 #include <linux/list.h>
 #include <linux/slab.h>
 #include <drm/drmP.h>
-#include "radeon_drm.h"
+#include <drm/radeon_drm.h>
 #include "radeon.h"
 #include "radeon_trace.h"
 

commit e971bd5e45764ff76df0ff110a19bf6b924f84d6
Author: Christian König <deathsimple@vodafone.de>
Date:   Tue Sep 11 16:10:04 2012 +0200

    drm/radeon: rework the VM code a bit more (v2)
    
    Roughly based on how nouveau is handling it. Instead of
    adding the bo_va when the address is set add the bo_va
    when the handle is opened, but set the address to zero
    until userspace tells us where to place it.
    
    This fixes another bunch of problems with glamor.
    
    v2: agd5f: fix build after dropping patch 7/8.
    
    Signed-off-by: Christian König <deathsimple@vodafone.de>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 8d23b7e2ae3d..a236795dc69a 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -52,7 +52,7 @@ void radeon_bo_clear_va(struct radeon_bo *bo)
 
 	list_for_each_entry_safe(bo_va, tmp, &bo->va, bo_list) {
 		/* remove from all vm address space */
-		radeon_vm_bo_rmv(bo->rdev, bo_va->vm, bo);
+		radeon_vm_bo_rmv(bo->rdev, bo_va);
 	}
 }
 

commit d63dfed5e9aa5fbea25a471300ee1b33bdc710d0
Author: Christian König <deathsimple@vodafone.de>
Date:   Tue Sep 11 16:10:01 2012 +0200

    drm/radeon: let bo_reserve take no_intr instead of no_wait param
    
    The no_wait param isn't used anywhere, and actually isn't
    very usefull at all.
    
    Signed-off-by: Christian König <deathsimple@vodafone.de>
    Reviewed-by: Jerome Glisse <jglisse@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 2844e0b204b0..8d23b7e2ae3d 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -627,18 +627,17 @@ int radeon_bo_wait(struct radeon_bo *bo, u32 *mem_type, bool no_wait)
 /**
  * radeon_bo_reserve - reserve bo
  * @bo:		bo structure
- * @no_wait:		don't sleep while trying to reserve (return -EBUSY)
+ * @no_intr:	don't return -ERESTARTSYS on pending signal
  *
  * Returns:
- * -EBUSY: buffer is busy and @no_wait is true
  * -ERESTARTSYS: A wait for the buffer to become unreserved was interrupted by
  * a signal. Release all buffer reservations and return to user-space.
  */
-int radeon_bo_reserve(struct radeon_bo *bo, bool no_wait)
+int radeon_bo_reserve(struct radeon_bo *bo, bool no_intr)
 {
 	int r;
 
-	r = ttm_bo_reserve(&bo->tbo, true, no_wait, false, 0);
+	r = ttm_bo_reserve(&bo->tbo, !no_intr, false, false, 0);
 	if (unlikely(r != 0)) {
 		if (r != -ERESTARTSYS)
 			dev_err(bo->rdev->dev, "%p reserve failed\n", bo);

commit 421ca7ab86aef01b4e22fb171d3d6bad6f1a5b96
Author: Christian König <deathsimple@vodafone.de>
Date:   Tue Sep 11 16:10:00 2012 +0200

    drm/radeon: move and rename radeon_bo_va function
    
    It doesn't really belong into the object functions,
    also rename it to avoid collisions with struct radeon_bo_va.
    
    Signed-off-by: Christian König <deathsimple@vodafone.de>
    Reviewed-by: Jerome Glisse <jglisse@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 9024e7222839..2844e0b204b0 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -646,16 +646,3 @@ int radeon_bo_reserve(struct radeon_bo *bo, bool no_wait)
 	}
 	return 0;
 }
-
-/* object have to be reserved */
-struct radeon_bo_va *radeon_bo_va(struct radeon_bo *rbo, struct radeon_vm *vm)
-{
-	struct radeon_bo_va *bo_va;
-
-	list_for_each_entry(bo_va, &rbo->va, bo_list) {
-		if (bo_va->vm == vm) {
-			return bo_va;
-		}
-	}
-	return NULL;
-}

commit 676bc2e1e4f9072f7a640d5b7c99ffdf9709a6e7
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Tue Aug 21 09:55:01 2012 -0400

    Revert "drm/radeon: fix bo creation retry path"
    
    This reverts commit d1c7871ddb1f588b8eb35affd9ee1a3d5e11cd0c.
    
    ttm_bo_init() destroys the BO on failure. So this patch makes
    the retry path work with freed memory.  This ends up causing
    kernel panics when this path is hit.
    
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 1cb014b571ab..9024e7222839 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -132,6 +132,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 	acc_size = ttm_bo_dma_acc_size(&rdev->mman.bdev, size,
 				       sizeof(struct radeon_bo));
 
+retry:
 	bo = kzalloc(sizeof(struct radeon_bo), GFP_KERNEL);
 	if (bo == NULL)
 		return -ENOMEM;
@@ -145,8 +146,6 @@ int radeon_bo_create(struct radeon_device *rdev,
 	bo->surface_reg = -1;
 	INIT_LIST_HEAD(&bo->list);
 	INIT_LIST_HEAD(&bo->va);
-
-retry:
 	radeon_ttm_placement_from_domain(bo, domain);
 	/* Kernel allocation are uninterruptible */
 	down_read(&rdev->pm.mclk_lock);

commit e43b5ec05afdc232be25aa481315035c1888d389
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Mon Aug 6 12:32:21 2012 -0400

    drm/radeon: fence virtual address and free it once idle v4
    
    Virtual address need to be fenced to know when we can safely remove it.
    This patch also properly clear the pagetable. Previously it was
    serouisly broken.
    
    Kernel 3.5/3.4 need a similar patch but adapted for difference in mutex locking.
    
    v2: For to update pagetable when unbinding bo (don't bailout if
        bo_va->valid is true).
    v3: Add kernel 3.5/3.4 comment.
    v4: Fix compilation warnings.
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 1f1a4c803c1d..1cb014b571ab 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -52,11 +52,7 @@ void radeon_bo_clear_va(struct radeon_bo *bo)
 
 	list_for_each_entry_safe(bo_va, tmp, &bo->va, bo_list) {
 		/* remove from all vm address space */
-		mutex_lock(&bo_va->vm->mutex);
-		list_del(&bo_va->vm_list);
-		mutex_unlock(&bo_va->vm->mutex);
-		list_del(&bo_va->bo_list);
-		kfree(bo_va);
+		radeon_vm_bo_rmv(bo->rdev, bo_va->vm, bo);
 	}
 }
 

commit d1c7871ddb1f588b8eb35affd9ee1a3d5e11cd0c
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Thu Jul 12 18:23:05 2012 -0400

    drm/radeon: fix bo creation retry path
    
    Retry label was at wrong place in function leading to memory
    leak.
    
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Reviewed-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 1f77a5afc011..1f1a4c803c1d 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -136,7 +136,6 @@ int radeon_bo_create(struct radeon_device *rdev,
 	acc_size = ttm_bo_dma_acc_size(&rdev->mman.bdev, size,
 				       sizeof(struct radeon_bo));
 
-retry:
 	bo = kzalloc(sizeof(struct radeon_bo), GFP_KERNEL);
 	if (bo == NULL)
 		return -ENOMEM;
@@ -150,6 +149,8 @@ int radeon_bo_create(struct radeon_device *rdev,
 	bo->surface_reg = -1;
 	INIT_LIST_HEAD(&bo->list);
 	INIT_LIST_HEAD(&bo->va);
+
+retry:
 	radeon_ttm_placement_from_domain(bo, domain);
 	/* Kernel allocation are uninterruptible */
 	down_read(&rdev->pm.mclk_lock);

commit 949c4a34afacfe800fc442afac117aba15284962
Author: Ilija Hadzic <ihadzic@research.bell-labs.com>
Date:   Tue May 15 16:40:10 2012 -0400

    drm: track dev_mapping in more robust and flexible way
    
    Setting dev_mapping (pointer to the address_space structure
    used for memory mappings) to the address_space of the first
    opener's inode and then failing if other openers come in
    through a different inode has a few restrictions that are
    eliminated by this patch.
    
    If we already have valid dev_mapping and we spot an opener
    with different i_node, we force its i_mapping pointer to the
    already established address_space structure (first opener's
    inode). This will make all mappings from drm device hang off
    the same address_space object.
    
    Some benefits (things that now work and didn't work
    before) of this patch are:
    
     * user space can mknod and use any number of device
       nodes and they will all work fine as long as the major
       device number is that of the drm module.
     * user space can even remove the first opener's device
       nodes and mknod the new one and the applications and
       windowing system will still work.
     * GPU drivers can safely assume that dev->dev_mapping is
       correct address_space and just blindly copy it
       into their (private) bdev.dev_mapping
    
    For reference, some discussion that lead to this patch can
    be found here:
    
    http://lists.freedesktop.org/archives/dri-devel/2012-April/022283.html
    
    Signed-off-by: Ilija Hadzic <ihadzic@research.bell-labs.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 6ecb2006e27e..1f77a5afc011 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -115,9 +115,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 
 	size = ALIGN(size, PAGE_SIZE);
 
-	if (unlikely(rdev->mman.bdev.dev_mapping == NULL)) {
-		rdev->mman.bdev.dev_mapping = rdev->ddev->dev_mapping;
-	}
+	rdev->mman.bdev.dev_mapping = rdev->ddev->dev_mapping;
 	if (kernel) {
 		type = ttm_bo_type_kernel;
 	} else if (sg) {

commit db7fce3983ad9b3deebda450121af4aaf6809ce2
Author: Christian König <deathsimple@vodafone.de>
Date:   Fri May 11 14:57:18 2012 +0200

    drm/radeon: replace vmram_mutex with mclk_lock v2
    
    It is a rw_semaphore now and only write locked
    while changing the clock. Also the lock is renamed
    to better reflect what it is protecting.
    
    v2: Keep the ttm_vm_ops on IGPs
    
    Signed-off-by: Christian König <deathsimple@vodafone.de>
    Reviewed-by: Jerome Glisse <jglisse@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 830f1a7b486f..6ecb2006e27e 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -154,11 +154,11 @@ int radeon_bo_create(struct radeon_device *rdev,
 	INIT_LIST_HEAD(&bo->va);
 	radeon_ttm_placement_from_domain(bo, domain);
 	/* Kernel allocation are uninterruptible */
-	mutex_lock(&rdev->vram_mutex);
+	down_read(&rdev->pm.mclk_lock);
 	r = ttm_bo_init(&rdev->mman.bdev, &bo->tbo, size, type,
 			&bo->placement, page_align, 0, !kernel, NULL,
 			acc_size, sg, &radeon_ttm_bo_destroy);
-	mutex_unlock(&rdev->vram_mutex);
+	up_read(&rdev->pm.mclk_lock);
 	if (unlikely(r != 0)) {
 		if (r != -ERESTARTSYS) {
 			if (domain == RADEON_GEM_DOMAIN_VRAM) {
@@ -219,9 +219,9 @@ void radeon_bo_unref(struct radeon_bo **bo)
 		return;
 	rdev = (*bo)->rdev;
 	tbo = &((*bo)->tbo);
-	mutex_lock(&rdev->vram_mutex);
+	down_read(&rdev->pm.mclk_lock);
 	ttm_bo_unref(&tbo);
-	mutex_unlock(&rdev->vram_mutex);
+	up_read(&rdev->pm.mclk_lock);
 	if (tbo == NULL)
 		*bo = NULL;
 }

commit 40f5cf996991577ec65d36cd3599cca7ec5d87d3
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Thu May 10 18:33:13 2012 -0400

    drm/radeon: add PRIME support (v2)
    
    This adds prime->fd and fd->prime support to radeon.
    It passes the sg object to ttm and then populates
    the gart entries using it.
    
    Compile tested only.
    
    v2: stub kmap + use new helpers + add reimporting
    
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Jerome Glisse <jglisse@redhat.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 1affbc954c56..830f1a7b486f 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -104,7 +104,7 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 
 int radeon_bo_create(struct radeon_device *rdev,
 		     unsigned long size, int byte_align, bool kernel, u32 domain,
-		     struct radeon_bo **bo_ptr)
+		     struct sg_table *sg, struct radeon_bo **bo_ptr)
 {
 	struct radeon_bo *bo;
 	enum ttm_bo_type type;
@@ -120,6 +120,8 @@ int radeon_bo_create(struct radeon_device *rdev,
 	}
 	if (kernel) {
 		type = ttm_bo_type_kernel;
+	} else if (sg) {
+		type = ttm_bo_type_sg;
 	} else {
 		type = ttm_bo_type_device;
 	}
@@ -155,7 +157,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 	mutex_lock(&rdev->vram_mutex);
 	r = ttm_bo_init(&rdev->mman.bdev, &bo->tbo, size, type,
 			&bo->placement, page_align, 0, !kernel, NULL,
-			acc_size, NULL, &radeon_ttm_bo_destroy);
+			acc_size, sg, &radeon_ttm_bo_destroy);
 	mutex_unlock(&rdev->vram_mutex);
 	if (unlikely(r != 0)) {
 		if (r != -ERESTARTSYS) {

commit 129b78bfca591e736e56a294f0e357d73d938f7e
Author: Dave Airlie <airlied@redhat.com>
Date:   Mon Apr 2 11:46:06 2012 +0100

    ttm: add prime sharing support to TTM (v2)
    
    This adds the ability for ttm common code to take an SG table
    and use it as the backing for a slave TTM object.
    
    The drivers can then populate their GTT tables using the SG object.
    
    v2: make sure to setup VM for sg bos as well.
    
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Reviewed-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index df6a4dbd93f8..1affbc954c56 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -155,7 +155,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 	mutex_lock(&rdev->vram_mutex);
 	r = ttm_bo_init(&rdev->mman.bdev, &bo->tbo, size, type,
 			&bo->placement, page_align, 0, !kernel, NULL,
-			acc_size, &radeon_ttm_bo_destroy);
+			acc_size, NULL, &radeon_ttm_bo_destroy);
 	mutex_unlock(&rdev->vram_mutex);
 	if (unlikely(r != 0)) {
 		if (r != -ERESTARTSYS) {

commit e199fd422420d1620cf64fd9bdd4ff8bc255cc76
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Thu Mar 29 16:47:43 2012 +0200

    drm/radeon: Don't dereference possibly-NULL pointer.
    
    Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 6f70158d34e4..df6a4dbd93f8 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -241,7 +241,8 @@ int radeon_bo_pin_restricted(struct radeon_bo *bo, u32 domain, u64 max_offset,
 				domain_start = bo->rdev->mc.vram_start;
 			else
 				domain_start = bo->rdev->mc.gtt_start;
-			WARN_ON_ONCE((*gpu_addr - domain_start) > max_offset);
+			WARN_ON_ONCE(max_offset <
+				     (radeon_bo_gpu_offset(bo) - domain_start));
 		}
 
 		return 0;

commit d936622c36273a9ecfbb4aacf26cd29405995159
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Wed Mar 28 08:52:32 2012 +0200

    drm/radeon: Only warn if the intra-domain offset actually exceeds the limit.
    
    Fixes spurious warnings.
    
    Tested-by: Dave Jones <davej@redhat.com>
    Tested-by: Steven Rostedt <rostedt@goodmis.org>
    Tested-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 91541e63d582..6f70158d34e4 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -233,7 +233,17 @@ int radeon_bo_pin_restricted(struct radeon_bo *bo, u32 domain, u64 max_offset,
 		bo->pin_count++;
 		if (gpu_addr)
 			*gpu_addr = radeon_bo_gpu_offset(bo);
-		WARN_ON_ONCE(max_offset != 0);
+
+		if (max_offset != 0) {
+			u64 domain_start;
+
+			if (domain == RADEON_GEM_DOMAIN_VRAM)
+				domain_start = bo->rdev->mc.vram_start;
+			else
+				domain_start = bo->rdev->mc.gtt_start;
+			WARN_ON_ONCE((*gpu_addr - domain_start) > max_offset);
+		}
+
 		return 0;
 	}
 	radeon_ttm_placement_from_domain(bo, domain);

commit c4353016dac10133fa5d8535af83f0c4845a2915
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Wed Mar 14 17:12:41 2012 +0100

    drm/radeon: Restrict offset for legacy hardware cursor.
    
    The hardware only takes 27 bits for the offset, so larger offsets are
    truncated, and the hardware cursor shows random bits other than the intended
    ones.
    
    Bugzilla: https://bugs.freedesktop.org/show_bug.cgi?id=46796
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 342deaccc152..91541e63d582 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -224,7 +224,8 @@ void radeon_bo_unref(struct radeon_bo **bo)
 		*bo = NULL;
 }
 
-int radeon_bo_pin(struct radeon_bo *bo, u32 domain, u64 *gpu_addr)
+int radeon_bo_pin_restricted(struct radeon_bo *bo, u32 domain, u64 max_offset,
+			     u64 *gpu_addr)
 {
 	int r, i;
 
@@ -232,6 +233,7 @@ int radeon_bo_pin(struct radeon_bo *bo, u32 domain, u64 *gpu_addr)
 		bo->pin_count++;
 		if (gpu_addr)
 			*gpu_addr = radeon_bo_gpu_offset(bo);
+		WARN_ON_ONCE(max_offset != 0);
 		return 0;
 	}
 	radeon_ttm_placement_from_domain(bo, domain);
@@ -239,6 +241,15 @@ int radeon_bo_pin(struct radeon_bo *bo, u32 domain, u64 *gpu_addr)
 		/* force to pin into visible video ram */
 		bo->placement.lpfn = bo->rdev->mc.visible_vram_size >> PAGE_SHIFT;
 	}
+	if (max_offset) {
+		u64 lpfn = max_offset >> PAGE_SHIFT;
+
+		if (!bo->placement.lpfn)
+			bo->placement.lpfn = bo->rdev->mc.gtt_size >> PAGE_SHIFT;
+
+		if (lpfn < bo->placement.lpfn)
+			bo->placement.lpfn = lpfn;
+	}
 	for (i = 0; i < bo->placement.num_placement; i++)
 		bo->placements[i] |= TTM_PL_FLAG_NO_EVICT;
 	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false, false);
@@ -252,6 +263,11 @@ int radeon_bo_pin(struct radeon_bo *bo, u32 domain, u64 *gpu_addr)
 	return r;
 }
 
+int radeon_bo_pin(struct radeon_bo *bo, u32 domain, u64 *gpu_addr)
+{
+	return radeon_bo_pin_restricted(bo, domain, 0, gpu_addr);
+}
+
 int radeon_bo_unpin(struct radeon_bo *bo)
 {
 	int r, i;

commit 285484e2d55e76031b45926720c10b1aec8b782a
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Fri Dec 16 17:03:42 2011 -0500

    drm/radeon: add support for evergreen/ni tiling informations v11
    
    evergreen and northern island gpu needs more informations for 2D tiling
    than previous r6xx/r7xx. Add field to tiling ioctl to allow userspace
    to provide those.
    
    The v8 cs checking change to track color view on r6xx/r7xx doesn't
    affect old userspace as old userspace always emited 0 for this register.
    
    v2 fix r6xx/r7xx 2D tiling computation
    v3 fix r6xx/r7xx height align for untiled surface & add support for
       tile split on evergreen and newer
    v4 improve tiling debugging output
    v5 fix tile split code for evergreen and newer
    v6 set proper tile split for crtc register
    v7 fix tile split limit value
    v8 add COLOR_VIEW checking to r6xx/r7xx checker, add evergreen cs
       checking, update safe reg for r600, evergreen and cayman.
       Evergreen checking need some work around for stencil alignment
       issues
    v9 fix tile split value range, fix compressed texture handling and
       mipmap calculation, allow evergreen check to be silencious in
       front of current broken userspace (depth/stencil alignment issue)
    v10 fix eg 3d texture and compressed texture, fix r600 depth array,
        fix r600 color view computation, add support for evergreen stencil
        split
    v11 more verbose debugging in some case
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index d45df1763598..342deaccc152 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -445,8 +445,54 @@ static void radeon_bo_clear_surface_reg(struct radeon_bo *bo)
 int radeon_bo_set_tiling_flags(struct radeon_bo *bo,
 				uint32_t tiling_flags, uint32_t pitch)
 {
+	struct radeon_device *rdev = bo->rdev;
 	int r;
 
+	if (rdev->family >= CHIP_CEDAR) {
+		unsigned bankw, bankh, mtaspect, tilesplit, stilesplit;
+
+		bankw = (tiling_flags >> RADEON_TILING_EG_BANKW_SHIFT) & RADEON_TILING_EG_BANKW_MASK;
+		bankh = (tiling_flags >> RADEON_TILING_EG_BANKH_SHIFT) & RADEON_TILING_EG_BANKH_MASK;
+		mtaspect = (tiling_flags >> RADEON_TILING_EG_MACRO_TILE_ASPECT_SHIFT) & RADEON_TILING_EG_MACRO_TILE_ASPECT_MASK;
+		tilesplit = (tiling_flags >> RADEON_TILING_EG_TILE_SPLIT_SHIFT) & RADEON_TILING_EG_TILE_SPLIT_MASK;
+		stilesplit = (tiling_flags >> RADEON_TILING_EG_STENCIL_TILE_SPLIT_SHIFT) & RADEON_TILING_EG_STENCIL_TILE_SPLIT_MASK;
+		switch (bankw) {
+		case 0:
+		case 1:
+		case 2:
+		case 4:
+		case 8:
+			break;
+		default:
+			return -EINVAL;
+		}
+		switch (bankh) {
+		case 0:
+		case 1:
+		case 2:
+		case 4:
+		case 8:
+			break;
+		default:
+			return -EINVAL;
+		}
+		switch (mtaspect) {
+		case 0:
+		case 1:
+		case 2:
+		case 4:
+		case 8:
+			break;
+		default:
+			return -EINVAL;
+		}
+		if (tilesplit > 6) {
+			return -EINVAL;
+		}
+		if (stilesplit > 6) {
+			return -EINVAL;
+		}
+	}
 	r = radeon_bo_reserve(bo, false);
 	if (unlikely(r != 0))
 		return r;

commit 721604a15b934f0a8d1909acb8017f029128be2f
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Thu Jan 5 22:11:05 2012 -0500

    drm/radeon: GPU virtual memory support v22
    
    Virtual address space are per drm client (opener of /dev/drm).
    Client are in charge of virtual address space, they need to
    map bo into it by calling DRM_RADEON_GEM_VA ioctl.
    
    First 16M of virtual address space is reserved by the kernel.
    
    Once using 2 level page table we should be able to have a small
    vram memory footprint for each pt (there would be one pt for all
    gart, one for all vram and then one first level for each virtual
    address space).
    
    Plan include using the sub allocator for a common vm page table
    area and using memcpy to copy vm page table in & out. Or use
    a gart object and copy things in & out using dma.
    
    v2: agd5f fixes:
    - Add vram base offset for vram pages.  The GPU physical address of a
    vram page is FB_OFFSET + page offset.  FB_OFFSET is 0 on discrete
    cards and the physical bus address of the stolen memory on
    integrated chips.
    - VM_CONTEXT1_PROTECTION_FAULT_DEFAULT_ADDR covers all vmid's >= 1
    
    v3: agd5f:
    - integrate with the semaphore/multi-ring stuff
    
    v4:
    - rebase on top ttm dma & multi-ring stuff
    - userspace is now in charge of the address space
    - no more specific cs vm ioctl, instead cs ioctl has a new
      chunk
    
    v5:
    - properly handle mem == NULL case from move_notify callback
    - fix the vm cleanup path
    
    v6:
    - fix update of page table to only happen on valid mem placement
    
    v7:
    - add tlb flush for each vm context
    - add flags to define mapping property (readable, writeable, snooped)
    - make ring id implicit from ib->fence->ring, up to each asic callback
      to then do ring specific scheduling if vm ib scheduling function
    
    v8:
    - add query for ib limit and kernel reserved virtual space
    - rename vm->size to max_pfn (maximum number of page)
    - update gem_va ioctl to also allow unmap operation
    - bump kernel version to allow userspace to query for vm support
    
    v9:
    - rebuild page table only when bind and incrementaly depending
      on bo referenced by cs and that have been moved
    - allow virtual address space to grow
    - use sa allocator for vram page table
    - return invalid when querying vm limit on non cayman GPU
    - dump vm fault register on lockup
    
    v10: agd5f:
    - Move the vm schedule_ib callback to a standalone function, remove
      the callback and use the existing ib_execute callback for VM IBs.
    
    v11:
    - rebase on top of lastest Linus
    
    v12: agd5f:
    - remove spurious backslash
    - set IB vm_id to 0 in radeon_ib_get()
    
    v13: agd5f:
    - fix handling of RADEON_CHUNK_ID_FLAGS
    
    v14:
    - fix va destruction
    - fix suspend resume
    - forbid bo to have several different va in same vm
    
    v15:
    - rebase
    
    v16:
    - cleanup left over of vm init/fini
    
    v17: agd5f:
    - cs checker
    
    v18: agd5f:
    - reworks the CS ioctl to better support multiple rings and
    VM.  Rather than adding a new chunk id for VM, just re-use the
    IB chunk id and add a new flags for VM mode.  Also define additional
    dwords for the flags chunk id to define the what ring we want to use
    (gfx, compute, uvd, etc.) and the priority.
    
    v19:
    - fix cs fini in weird case of no ib
    - semi working flush fix for ni
    - rebase on top of sa allocator changes
    
    v20: agd5f:
    - further CS ioctl cleanups from Christian's comments
    
    v21: agd5f:
    - integrate CS checker improvements
    
    v22: agd5f:
    - final cleanups for release, only allow VM CS on cayman
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 695b4800329a..d45df1763598 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -46,6 +46,20 @@ static void radeon_bo_clear_surface_reg(struct radeon_bo *bo);
  * function are calling it.
  */
 
+void radeon_bo_clear_va(struct radeon_bo *bo)
+{
+	struct radeon_bo_va *bo_va, *tmp;
+
+	list_for_each_entry_safe(bo_va, tmp, &bo->va, bo_list) {
+		/* remove from all vm address space */
+		mutex_lock(&bo_va->vm->mutex);
+		list_del(&bo_va->vm_list);
+		mutex_unlock(&bo_va->vm->mutex);
+		list_del(&bo_va->bo_list);
+		kfree(bo_va);
+	}
+}
+
 static void radeon_ttm_bo_destroy(struct ttm_buffer_object *tbo)
 {
 	struct radeon_bo *bo;
@@ -55,6 +69,7 @@ static void radeon_ttm_bo_destroy(struct ttm_buffer_object *tbo)
 	list_del_init(&bo->list);
 	mutex_unlock(&bo->rdev->gem.mutex);
 	radeon_bo_clear_surface_reg(bo);
+	radeon_bo_clear_va(bo);
 	drm_gem_object_release(&bo->gem_base);
 	kfree(bo);
 }
@@ -134,6 +149,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 	bo->gem_base.driver_private = NULL;
 	bo->surface_reg = -1;
 	INIT_LIST_HEAD(&bo->list);
+	INIT_LIST_HEAD(&bo->va);
 	radeon_ttm_placement_from_domain(bo, domain);
 	/* Kernel allocation are uninterruptible */
 	mutex_lock(&rdev->vram_mutex);
@@ -487,6 +503,7 @@ void radeon_bo_move_notify(struct ttm_buffer_object *bo,
 		return;
 	rbo = container_of(bo, struct radeon_bo, tbo);
 	radeon_bo_check_tiling(rbo, 0, 1);
+	radeon_vm_bo_invalidate(rbo->rdev, rbo);
 }
 
 int radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
@@ -560,3 +577,16 @@ int radeon_bo_reserve(struct radeon_bo *bo, bool no_wait)
 	}
 	return 0;
 }
+
+/* object have to be reserved */
+struct radeon_bo_va *radeon_bo_va(struct radeon_bo *rbo, struct radeon_vm *vm)
+{
+	struct radeon_bo_va *bo_va;
+
+	list_for_each_entry(bo_va, &rbo->va, bo_list) {
+		if (bo_va->vm == vm) {
+			return bo_va;
+		}
+	}
+	return NULL;
+}

commit 57de4ba959b290f0b8cf36ecd5e7f1b29d4b8a12
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Fri Nov 11 15:42:57 2011 -0500

    drm/ttm: simplify memory accounting for ttm user v2
    
    Provide helper function to compute the kernel memory size needed
    for each buffer object. Move all the accounting inside ttm, simplifying
    driver and avoiding code duplication accross them.
    
    v2 fix accounting of ghost object, one would have thought that i
       would have run into the issue since a longtime but it seems
       ghost object are rare when you have plenty of vram ;)
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Reviewed-by: Thomas Hellstrom <thellstrom@vmware.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 1c851521f458..695b4800329a 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -95,6 +95,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 	enum ttm_bo_type type;
 	unsigned long page_align = roundup(byte_align, PAGE_SIZE) >> PAGE_SHIFT;
 	unsigned long max_size = 0;
+	size_t acc_size;
 	int r;
 
 	size = ALIGN(size, PAGE_SIZE);
@@ -117,6 +118,9 @@ int radeon_bo_create(struct radeon_device *rdev,
 		return -ENOMEM;
 	}
 
+	acc_size = ttm_bo_dma_acc_size(&rdev->mman.bdev, size,
+				       sizeof(struct radeon_bo));
+
 retry:
 	bo = kzalloc(sizeof(struct radeon_bo), GFP_KERNEL);
 	if (bo == NULL)
@@ -134,8 +138,8 @@ int radeon_bo_create(struct radeon_device *rdev,
 	/* Kernel allocation are uninterruptible */
 	mutex_lock(&rdev->vram_mutex);
 	r = ttm_bo_init(&rdev->mman.bdev, &bo->tbo, size, type,
-			&bo->placement, page_align, 0, !kernel, NULL, size,
-			&radeon_ttm_bo_destroy);
+			&bo->placement, page_align, 0, !kernel, NULL,
+			acc_size, &radeon_ttm_bo_destroy);
 	mutex_unlock(&rdev->vram_mutex);
 	if (unlikely(r != 0)) {
 		if (r != -ERESTARTSYS) {

commit 1717c0e23f411147490c7a3312b894f0ea9a5fb1
Author: Dave Airlie <airlied@redhat.com>
Date:   Thu Oct 27 18:28:37 2011 +0200

    Revert "drm/ttm: add a way to bo_wait for either the last read or last write"
    
    This reverts commit dfadbbdb57b3f2bb33e14f129a43047c6f0caefa.
    
    Further upstream discussion between Marek and Thomas decided this wasn't
    fully baked and needed further work, so revert it before it hits mainline.
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index b8f75f5d344b..1c851521f458 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -527,7 +527,7 @@ int radeon_bo_wait(struct radeon_bo *bo, u32 *mem_type, bool no_wait)
 	if (mem_type)
 		*mem_type = bo->tbo.mem.mem_type;
 	if (bo->tbo.sync_obj)
-		r = ttm_bo_wait(&bo->tbo, true, true, no_wait, false);
+		r = ttm_bo_wait(&bo->tbo, true, true, no_wait);
 	spin_unlock(&bo->tbo.bdev->fence_lock);
 	ttm_bo_unreserve(&bo->tbo);
 	return r;

commit 83f30d0e0343ad010afbc3523007b68e8b439694
Author: Dave Airlie <airlied@redhat.com>
Date:   Thu Oct 27 18:15:10 2011 +0200

    Revert "drm/radeon/kms: add a new gem_wait ioctl with read/write flags"
    
    This reverts commit d3ed74027f1dd197b7e08247a40d3bf9be1852b0.
    
    Further upstream discussion between Thomas and Marek decided this needed
    more work and driver specifics. So revert before it goes upstream.
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 138839312e8b..b8f75f5d344b 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -516,8 +516,7 @@ int radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
 	return 0;
 }
 
-int radeon_bo_wait(struct radeon_bo *bo, u32 *mem_type, bool no_wait,
-		   enum ttm_buffer_usage usage)
+int radeon_bo_wait(struct radeon_bo *bo, u32 *mem_type, bool no_wait)
 {
 	int r;
 
@@ -528,7 +527,7 @@ int radeon_bo_wait(struct radeon_bo *bo, u32 *mem_type, bool no_wait,
 	if (mem_type)
 		*mem_type = bo->tbo.mem.mem_type;
 	if (bo->tbo.sync_obj)
-		r = ttm_bo_wait(&bo->tbo, true, true, no_wait, usage);
+		r = ttm_bo_wait(&bo->tbo, true, true, no_wait, false);
 	spin_unlock(&bo->tbo.bdev->fence_lock);
 	ttm_bo_unreserve(&bo->tbo);
 	return r;

commit ce580fab739c815e25d13bae62f96ba7251f6e2e
Author: Andi Kleen <ak@linux.intel.com>
Date:   Thu Oct 13 16:08:47 2011 -0700

    drm/radeon: Move more code out of line
    
    With this patch I'm only about 50k larger with DRM debugging
    enables (why is that enabled by default?!?), and slightly
    smaller without.
    
    [airlied: moved r100.c additions to radeon_ring.c]
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 976c3b1b1b6e..138839312e8b 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -515,3 +515,45 @@ int radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
 	}
 	return 0;
 }
+
+int radeon_bo_wait(struct radeon_bo *bo, u32 *mem_type, bool no_wait,
+		   enum ttm_buffer_usage usage)
+{
+	int r;
+
+	r = ttm_bo_reserve(&bo->tbo, true, no_wait, false, 0);
+	if (unlikely(r != 0))
+		return r;
+	spin_lock(&bo->tbo.bdev->fence_lock);
+	if (mem_type)
+		*mem_type = bo->tbo.mem.mem_type;
+	if (bo->tbo.sync_obj)
+		r = ttm_bo_wait(&bo->tbo, true, true, no_wait, usage);
+	spin_unlock(&bo->tbo.bdev->fence_lock);
+	ttm_bo_unreserve(&bo->tbo);
+	return r;
+}
+
+
+/**
+ * radeon_bo_reserve - reserve bo
+ * @bo:		bo structure
+ * @no_wait:		don't sleep while trying to reserve (return -EBUSY)
+ *
+ * Returns:
+ * -EBUSY: buffer is busy and @no_wait is true
+ * -ERESTARTSYS: A wait for the buffer to become unreserved was interrupted by
+ * a signal. Release all buffer reservations and return to user-space.
+ */
+int radeon_bo_reserve(struct radeon_bo *bo, bool no_wait)
+{
+	int r;
+
+	r = ttm_bo_reserve(&bo->tbo, true, no_wait, false, 0);
+	if (unlikely(r != 0)) {
+		if (r != -ERESTARTSYS)
+			dev_err(bo->rdev->dev, "%p reserve failed\n", bo);
+		return r;
+	}
+	return 0;
+}

commit 91132d6bb6481da7c8280905a5db424885c458d0
Author: Dave Airlie <airlied@redhat.com>
Date:   Tue Mar 1 13:40:06 2011 +1000

    drm/radeon: fix up dereferencing of busy objects.
    
    This could free things twice, just deref the GEM object
    and hope its enough.
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 8758d02cca1a..976c3b1b1b6e 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -278,7 +278,7 @@ void radeon_bo_force_delete(struct radeon_device *rdev)
 		mutex_lock(&bo->rdev->gem.mutex);
 		list_del_init(&bo->list);
 		mutex_unlock(&bo->rdev->gem.mutex);
-		radeon_bo_unref(&bo);
+		/* this should unref the ttm bo */
 		drm_gem_object_unreference(&bo->gem_base);
 		mutex_unlock(&rdev->ddev->struct_mutex);
 	}

commit 31c3603d83a774df4acdfe3a89ce64719d0db0d8
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Fri Feb 18 17:59:18 2011 +0100

    drm/radeon: kill radeon_bo->gobj pointer
    
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 2be18960409e..8758d02cca1a 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -127,7 +127,6 @@ int radeon_bo_create(struct radeon_device *rdev,
 		return r;
 	}
 	bo->rdev = rdev;
-	bo->gobj = &bo->gem_base;
 	bo->gem_base.driver_private = NULL;
 	bo->surface_reg = -1;
 	INIT_LIST_HEAD(&bo->list);
@@ -266,7 +265,6 @@ int radeon_bo_evict_vram(struct radeon_device *rdev)
 void radeon_bo_force_delete(struct radeon_device *rdev)
 {
 	struct radeon_bo *bo, *n;
-	struct drm_gem_object *gobj;
 
 	if (list_empty(&rdev->gem.objects)) {
 		return;
@@ -274,15 +272,14 @@ void radeon_bo_force_delete(struct radeon_device *rdev)
 	dev_err(rdev->dev, "Userspace still has active objects !\n");
 	list_for_each_entry_safe(bo, n, &rdev->gem.objects, list) {
 		mutex_lock(&rdev->ddev->struct_mutex);
-		gobj = bo->gobj;
 		dev_err(rdev->dev, "%p %p %lu %lu force free\n",
-			gobj, bo, (unsigned long)gobj->size,
-			*((unsigned long *)&gobj->refcount));
+			&bo->gem_base, bo, (unsigned long)bo->gem_base.size,
+			*((unsigned long *)&bo->gem_base.refcount));
 		mutex_lock(&bo->rdev->gem.mutex);
 		list_del_init(&bo->list);
 		mutex_unlock(&bo->rdev->gem.mutex);
 		radeon_bo_unref(&bo);
-		drm_gem_object_unreference(gobj);
+		drm_gem_object_unreference(&bo->gem_base);
 		mutex_unlock(&rdev->ddev->struct_mutex);
 	}
 }

commit 7e4d15d90afe46d34b510f3c70217d3469a7dd70
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Fri Feb 18 17:59:17 2011 +0100

    drm/radeon: introduce gem_to_radeon_bo helper
    
    ... and switch it to container_of upcasting.
    
    v2: converted new pageflip code-paths.
    
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 9324c881d640..2be18960409e 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -128,7 +128,7 @@ int radeon_bo_create(struct radeon_device *rdev,
 	}
 	bo->rdev = rdev;
 	bo->gobj = &bo->gem_base;
-	bo->gem_base.driver_private = bo;
+	bo->gem_base.driver_private = NULL;
 	bo->surface_reg = -1;
 	INIT_LIST_HEAD(&bo->list);
 	radeon_ttm_placement_from_domain(bo, domain);
@@ -282,7 +282,6 @@ void radeon_bo_force_delete(struct radeon_device *rdev)
 		list_del_init(&bo->list);
 		mutex_unlock(&bo->rdev->gem.mutex);
 		radeon_bo_unref(&bo);
-		gobj->driver_private = NULL;
 		drm_gem_object_unreference(gobj);
 		mutex_unlock(&rdev->ddev->struct_mutex);
 	}

commit 441921d5309cfe098747d9840fd71bdc6ca2a93b
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Fri Feb 18 17:59:16 2011 +0100

    drm/radeon: embed struct drm_gem_object
    
    Unconditionally initialize the drm gem object - it's not
    worth the trouble not to for the few kernel objects.
    
    This patch only changes the place of the drm gem object,
    access is still done via pointers.
    
    v2: Uncoditionally align the size in radeon_bo_create. At
    least the r600/evergreen blit code didn't to this, angering
    the paranoid gem code.
    
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 7d6b8e88f746..9324c881d640 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -55,6 +55,7 @@ static void radeon_ttm_bo_destroy(struct ttm_buffer_object *tbo)
 	list_del_init(&bo->list);
 	mutex_unlock(&bo->rdev->gem.mutex);
 	radeon_bo_clear_surface_reg(bo);
+	drm_gem_object_release(&bo->gem_base);
 	kfree(bo);
 }
 
@@ -86,7 +87,7 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 	rbo->placement.num_busy_placement = c;
 }
 
-int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
+int radeon_bo_create(struct radeon_device *rdev,
 		     unsigned long size, int byte_align, bool kernel, u32 domain,
 		     struct radeon_bo **bo_ptr)
 {
@@ -96,6 +97,8 @@ int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
 	unsigned long max_size = 0;
 	int r;
 
+	size = ALIGN(size, PAGE_SIZE);
+
 	if (unlikely(rdev->mman.bdev.dev_mapping == NULL)) {
 		rdev->mman.bdev.dev_mapping = rdev->ddev->dev_mapping;
 	}
@@ -118,8 +121,14 @@ int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
 	bo = kzalloc(sizeof(struct radeon_bo), GFP_KERNEL);
 	if (bo == NULL)
 		return -ENOMEM;
+	r = drm_gem_object_init(rdev->ddev, &bo->gem_base, size);
+	if (unlikely(r)) {
+		kfree(bo);
+		return r;
+	}
 	bo->rdev = rdev;
-	bo->gobj = gobj;
+	bo->gobj = &bo->gem_base;
+	bo->gem_base.driver_private = bo;
 	bo->surface_reg = -1;
 	INIT_LIST_HEAD(&bo->list);
 	radeon_ttm_placement_from_domain(bo, domain);
@@ -142,12 +151,9 @@ int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
 		return r;
 	}
 	*bo_ptr = bo;
-	if (gobj) {
-		mutex_lock(&bo->rdev->gem.mutex);
-		list_add_tail(&bo->list, &rdev->gem.objects);
-		mutex_unlock(&bo->rdev->gem.mutex);
-	}
+
 	trace_radeon_bo_create(bo);
+
 	return 0;
 }
 

commit d8c58fabd75021cdd99abcd96513cb088d41092b
Merge: 9c04f015ebc2 b08ebe7e776e
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Thu Dec 16 21:02:15 2010 +0000

    Merge remote branch 'airlied/drm-core-next' into drm-intel-next

commit 99ee7fac189893c90145a22b86bbcfdc98f69a9c
Author: Dave Airlie <airlied@redhat.com>
Date:   Tue Nov 23 11:47:49 2010 +1000

    drm/radeon: add initial tracepoint support.
    
    this adds a bo create, and fence seq tracking tracepoints.
    
    This is just an initial set to play around with, we should investigate
    what others we need would be useful.
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index a8594d289bcf..8bdf0ba2983a 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -34,6 +34,7 @@
 #include <drm/drmP.h>
 #include "radeon_drm.h"
 #include "radeon.h"
+#include "radeon_trace.h"
 
 
 int radeon_ttm_init(struct radeon_device *rdev);
@@ -137,6 +138,7 @@ int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
 		list_add_tail(&bo->list, &rdev->gem.objects);
 		mutex_unlock(&bo->rdev->gem.mutex);
 	}
+	trace_radeon_bo_create(bo);
 	return 0;
 }
 

commit 93225b0d7bc030f4a93165347a65893685822d70
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Fri Dec 3 16:38:19 2010 -0500

    drm/radeon/kms: forbid big bo allocation (fdo 31708) v3
    
    Forbid allocating buffer bigger than visible VRAM or GTT, also
    properly set lpfn field.
    
    v2 - use max macro
       - silence warning
    v3 - don't explicitly set range limit
       - use min macro
    
    Cc: stable <stable@kernel.org>
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 1d067743fee0..a598d0049aa5 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -69,7 +69,7 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 	u32 c = 0;
 
 	rbo->placement.fpfn = 0;
-	rbo->placement.lpfn = rbo->rdev->mc.active_vram_size >> PAGE_SHIFT;
+	rbo->placement.lpfn = 0;
 	rbo->placement.placement = rbo->placements;
 	rbo->placement.busy_placement = rbo->placements;
 	if (domain & RADEON_GEM_DOMAIN_VRAM)
@@ -91,7 +91,8 @@ int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
 {
 	struct radeon_bo *bo;
 	enum ttm_bo_type type;
-	int page_align = roundup(byte_align, PAGE_SIZE) >> PAGE_SHIFT;
+	unsigned long page_align = roundup(byte_align, PAGE_SIZE) >> PAGE_SHIFT;
+	unsigned long max_size = 0;
 	int r;
 
 	if (unlikely(rdev->mman.bdev.dev_mapping == NULL)) {
@@ -104,6 +105,14 @@ int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
 	}
 	*bo_ptr = NULL;
 
+	/* maximun bo size is the minimun btw visible vram and gtt size */
+	max_size = min(rdev->mc.visible_vram_size, rdev->mc.gtt_size);
+	if ((page_align << PAGE_SHIFT) >= max_size) {
+		printk(KERN_WARNING "%s:%d alloc size %ldM bigger than %ldMb limit\n",
+			__func__, __LINE__, page_align  >> (20 - PAGE_SHIFT), max_size >> 20);
+		return -ENOMEM;
+	}
+
 retry:
 	bo = kzalloc(sizeof(struct radeon_bo), GFP_KERNEL);
 	if (bo == NULL)

commit 147666fb3b93b8c484f562da33a37f886ddff768
Author: Thomas Hellstrom <thellstrom@vmware.com>
Date:   Wed Nov 17 12:38:32 2010 +0000

    drm/radeon: Use the ttm execbuf utilities
    
    Rather than re-implementing in the Radeon driver,
    Use the execbuf / cs / pushbuf utilities that comes with TTM.
    This comes with an even greater benefit now that many spinlocks have been
    optimized away...
    
    Signed-off-by: Thomas Hellstrom <thellstrom@vmware.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index e939cb6a91cc..a8594d289bcf 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -293,34 +293,9 @@ void radeon_bo_list_add_object(struct radeon_bo_list *lobj,
 				struct list_head *head)
 {
 	if (lobj->wdomain) {
-		list_add(&lobj->list, head);
+		list_add(&lobj->tv.head, head);
 	} else {
-		list_add_tail(&lobj->list, head);
-	}
-}
-
-int radeon_bo_list_reserve(struct list_head *head)
-{
-	struct radeon_bo_list *lobj;
-	int r;
-
-	list_for_each_entry(lobj, head, list){
-		r = radeon_bo_reserve(lobj->bo, false);
-		if (unlikely(r != 0))
-			return r;
-		lobj->reserved = true;
-	}
-	return 0;
-}
-
-void radeon_bo_list_unreserve(struct list_head *head)
-{
-	struct radeon_bo_list *lobj;
-
-	list_for_each_entry(lobj, head, list) {
-		/* only unreserve object we successfully reserved */
-		if (lobj->reserved && radeon_bo_is_reserved(lobj->bo))
-			radeon_bo_unreserve(lobj->bo);
+		list_add_tail(&lobj->tv.head, head);
 	}
 }
 
@@ -331,14 +306,11 @@ int radeon_bo_list_validate(struct list_head *head)
 	u32 domain;
 	int r;
 
-	list_for_each_entry(lobj, head, list) {
-		lobj->reserved = false;
-	}
-	r = radeon_bo_list_reserve(head);
+	r = ttm_eu_reserve_buffers(head);
 	if (unlikely(r != 0)) {
 		return r;
 	}
-	list_for_each_entry(lobj, head, list) {
+	list_for_each_entry(lobj, head, tv.head) {
 		bo = lobj->bo;
 		if (!bo->pin_count) {
 			domain = lobj->wdomain ? lobj->wdomain : lobj->rdomain;
@@ -361,25 +333,6 @@ int radeon_bo_list_validate(struct list_head *head)
 	return 0;
 }
 
-void radeon_bo_list_fence(struct list_head *head, void *fence)
-{
-	struct radeon_bo_list *lobj;
-	struct radeon_bo *bo;
-	struct radeon_fence *old_fence = NULL;
-
-	list_for_each_entry(lobj, head, list) {
-		bo = lobj->bo;
-		spin_lock(&bo->tbo.bdev->fence_lock);
-		old_fence = (struct radeon_fence *)bo->tbo.sync_obj;
-		bo->tbo.sync_obj = radeon_fence_ref(fence);
-		bo->tbo.sync_obj_arg = NULL;
-		spin_unlock(&bo->tbo.bdev->fence_lock);
-		if (old_fence) {
-			radeon_fence_unref(&old_fence);
-		}
-	}
-}
-
 int radeon_bo_fbdev_mmap(struct radeon_bo *bo,
 			     struct vm_area_struct *vma)
 {

commit 702adba22433c175e8429a47760f35ca16caf1cd
Author: Thomas Hellstrom <thellstrom@vmware.com>
Date:   Wed Nov 17 12:28:29 2010 +0000

    drm/ttm/radeon/nouveau: Kill the bo lock in favour of a bo device fence_lock
    
    The bo lock used only to protect the bo sync object members, and since it
    is a per bo lock, fencing a buffer list will see a lot of locks and unlocks.
    Replace it with a per-device lock that protects the sync object members on
    *all* bos. Reading and setting these members will always be very quick, so
    the risc of heavy lock contention is microscopic. Note that waiting for
    sync objects will always take place outside of this lock.
    
    The bo device fence lock will eventually be replaced with a seqlock /
    rcu mechanism so we can determine that a bo is idle under a
    rcu / read seqlock.
    
    However this change will allow us to batch fencing and unreserving of
    buffers with a minimal amount of locking.
    
    Signed-off-by: Thomas Hellstrom <thellstrom@vmware.com>
    Reviewed-by: Jerome Glisse <j.glisse@gmail.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 1d067743fee0..e939cb6a91cc 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -369,11 +369,11 @@ void radeon_bo_list_fence(struct list_head *head, void *fence)
 
 	list_for_each_entry(lobj, head, list) {
 		bo = lobj->bo;
-		spin_lock(&bo->tbo.lock);
+		spin_lock(&bo->tbo.bdev->fence_lock);
 		old_fence = (struct radeon_fence *)bo->tbo.sync_obj;
 		bo->tbo.sync_obj = radeon_fence_ref(fence);
 		bo->tbo.sync_obj_arg = NULL;
-		spin_unlock(&bo->tbo.lock);
+		spin_unlock(&bo->tbo.bdev->fence_lock);
 		if (old_fence) {
 			radeon_fence_unref(&old_fence);
 		}

commit 268b2510de14f62134d87ba9b4981816192db386
Author: Alex Deucher <alexdeucher@gmail.com>
Date:   Wed Nov 17 19:00:26 2010 -0500

    drm/radeon/kms: fix alignment when allocating buffers
    
    We were previously dropping alignment requests on the floor
    when allocating buffers so we always ended up page aligned.
    Certain tiling modes on 6xx+ require larger alignment which
    wasn't happening before.
    
    Signed-off-by: Alex Deucher <alexdeucher@gmail.com>
    Cc: Jerome Glisse <j.glisse@gmail.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 8eb183466015..1d067743fee0 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -86,11 +86,12 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 }
 
 int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
-			unsigned long size, bool kernel, u32 domain,
-			struct radeon_bo **bo_ptr)
+		     unsigned long size, int byte_align, bool kernel, u32 domain,
+		     struct radeon_bo **bo_ptr)
 {
 	struct radeon_bo *bo;
 	enum ttm_bo_type type;
+	int page_align = roundup(byte_align, PAGE_SIZE) >> PAGE_SHIFT;
 	int r;
 
 	if (unlikely(rdev->mman.bdev.dev_mapping == NULL)) {
@@ -115,7 +116,7 @@ int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
 	/* Kernel allocation are uninterruptible */
 	mutex_lock(&rdev->vram_mutex);
 	r = ttm_bo_init(&rdev->mman.bdev, &bo->tbo, size, type,
-			&bo->placement, 0, 0, !kernel, NULL, size,
+			&bo->placement, page_align, 0, !kernel, NULL, size,
 			&radeon_ttm_bo_destroy);
 	mutex_unlock(&rdev->vram_mutex);
 	if (unlikely(r != 0)) {

commit 2b66b50b12cabc05f05543e792d4c9c2465d5702
Author: Michel Dänzer <daenzer@vmware.com>
Date:   Tue Nov 9 11:50:05 2010 +0100

    drm/radeon/kms: Fix retrying ttm_bo_init() after it failed once.
    
    If ttm_bo_init() returns failure, it already destroyed the BO, so we need to
    retry from scratch.
    
    Signed-off-by: Michel Dänzer <daenzer@vmware.com>
    Tested-by: Markus Trippelsdorf <markus@trippelsdorf.de>
    Cc: stable@kernel.org
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index d7ab91416410..8eb183466015 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -102,6 +102,8 @@ int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
 		type = ttm_bo_type_device;
 	}
 	*bo_ptr = NULL;
+
+retry:
 	bo = kzalloc(sizeof(struct radeon_bo), GFP_KERNEL);
 	if (bo == NULL)
 		return -ENOMEM;
@@ -109,8 +111,6 @@ int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
 	bo->gobj = gobj;
 	bo->surface_reg = -1;
 	INIT_LIST_HEAD(&bo->list);
-
-retry:
 	radeon_ttm_placement_from_domain(bo, domain);
 	/* Kernel allocation are uninterruptible */
 	mutex_lock(&rdev->vram_mutex);

commit b7ae5056c94a8191c1fd0b5697707377516c0c5d
Merge: 2126d0a4a205 6a2a11dbea5d
Author: Dave Airlie <airlied@redhat.com>
Date:   Tue Oct 19 09:48:34 2010 +1000

    Merge branch 'drm-fixes' of /home/airlied/kernel/linux-2.6 into drm-core-next
    
    Conflicts:
            drivers/gpu/drm/i915/intel_fb.c
            drivers/gpu/drm/radeon/r600_blit_kms.c
            drivers/gpu/drm/ttm/ttm_bo.c

commit c919b371cb734f42b1130e706ecee262f8d9261d
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Tue Aug 10 17:41:31 2010 -0400

    drm/radeon/kms: avoid corner case issue with unmappable vram V2
    
    We should not allocate any object into unmappable vram if we
    have no means to access them which on all GPU means having the
    CP running and on newer GPU having the blit utility working.
    
    This patch limit the vram allocation to visible vram until
    we have acceleration up and running.
    
    Note that it's more than unlikely that we run into any issue
    related to that as when acceleration is not woring userspace
    should allocate any object in vram beside front buffer which
    should fit in visible vram.
    
    V2 use real_vram_size as mc_vram_size could be bigger than
       the actual amount of vram
    
    [airlied: fixup r700_cp_stop case]
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 0afd1e62347d..b3b5306bb578 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -69,7 +69,7 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 	u32 c = 0;
 
 	rbo->placement.fpfn = 0;
-	rbo->placement.lpfn = 0;
+	rbo->placement.lpfn = rbo->rdev->mc.active_vram_size >> PAGE_SHIFT;
 	rbo->placement.placement = rbo->placements;
 	rbo->placement.busy_placement = rbo->placements;
 	if (domain & RADEON_GEM_DOMAIN_VRAM)

commit d961db75ce86a84f1f04e91ad1014653ed7d9f46
Author: Ben Skeggs <bskeggs@redhat.com>
Date:   Thu Aug 5 10:48:18 2010 +1000

    drm/ttm: restructure to allow driver to plug in alternate memory manager
    
    Nouveau will need this on GeForce 8 and up to account for the GPU
    reordering physical VRAM for some memory types.
    
    Reviewed-by: Jerome Glisse <jglisse@redhat.com>
    Acked-by: Thomas Hellström <thellstrom@vmware.com>
    Signed-off-by: Ben Skeggs <bskeggs@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 0afd1e62347d..c26106066ec2 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -435,7 +435,7 @@ int radeon_bo_get_surface_reg(struct radeon_bo *bo)
 
 out:
 	radeon_set_surface_reg(rdev, i, bo->tiling_flags, bo->pitch,
-			       bo->tbo.mem.mm_node->start << PAGE_SHIFT,
+			       bo->tbo.mem.start << PAGE_SHIFT,
 			       bo->tbo.num_pages << PAGE_SHIFT);
 	return 0;
 }
@@ -532,7 +532,7 @@ int radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
 	rdev = rbo->rdev;
 	if (bo->mem.mem_type == TTM_PL_VRAM) {
 		size = bo->mem.num_pages << PAGE_SHIFT;
-		offset = bo->mem.mm_node->start << PAGE_SHIFT;
+		offset = bo->mem.start << PAGE_SHIFT;
 		if ((offset + size) > rdev->mc.visible_vram_size) {
 			/* hurrah the memory is not visible ! */
 			radeon_ttm_placement_from_domain(rbo, RADEON_GEM_DOMAIN_VRAM);
@@ -540,7 +540,7 @@ int radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
 			r = ttm_bo_validate(bo, &rbo->placement, false, true, false);
 			if (unlikely(r != 0))
 				return r;
-			offset = bo->mem.mm_node->start << PAGE_SHIFT;
+			offset = bo->mem.start << PAGE_SHIFT;
 			/* this should not happen */
 			if ((offset + size) > rdev->mc.visible_vram_size)
 				return -EINVAL;

commit e376573f7267390f4e1bdc552564b6fb913bce76
Author: Michel Dänzer <daenzer@vmware.com>
Date:   Thu Jul 8 12:43:28 2010 +1000

    drm/radeon: fall back to GTT if bo creation/validation in VRAM fails.
    
    This fixes a problem where on low VRAM cards we'd run out of space for validation.
    
    [airlied: Tested on my M7, Thinkpad T42, compiz works with no problems.]
    
    Signed-off-by: Michel Dänzer <daenzer@vmware.com>
    Cc: stable@kernel.org
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index d5b9373ce06c..0afd1e62347d 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -110,6 +110,7 @@ int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
 	bo->surface_reg = -1;
 	INIT_LIST_HEAD(&bo->list);
 
+retry:
 	radeon_ttm_placement_from_domain(bo, domain);
 	/* Kernel allocation are uninterruptible */
 	mutex_lock(&rdev->vram_mutex);
@@ -118,10 +119,15 @@ int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
 			&radeon_ttm_bo_destroy);
 	mutex_unlock(&rdev->vram_mutex);
 	if (unlikely(r != 0)) {
-		if (r != -ERESTARTSYS)
+		if (r != -ERESTARTSYS) {
+			if (domain == RADEON_GEM_DOMAIN_VRAM) {
+				domain |= RADEON_GEM_DOMAIN_GTT;
+				goto retry;
+			}
 			dev_err(rdev->dev,
 				"object_init failed for (%lu, 0x%08X)\n",
 				size, domain);
+		}
 		return r;
 	}
 	*bo_ptr = bo;
@@ -321,6 +327,7 @@ int radeon_bo_list_validate(struct list_head *head)
 {
 	struct radeon_bo_list *lobj;
 	struct radeon_bo *bo;
+	u32 domain;
 	int r;
 
 	list_for_each_entry(lobj, head, list) {
@@ -333,17 +340,19 @@ int radeon_bo_list_validate(struct list_head *head)
 	list_for_each_entry(lobj, head, list) {
 		bo = lobj->bo;
 		if (!bo->pin_count) {
-			if (lobj->wdomain) {
-				radeon_ttm_placement_from_domain(bo,
-								lobj->wdomain);
-			} else {
-				radeon_ttm_placement_from_domain(bo,
-								lobj->rdomain);
-			}
+			domain = lobj->wdomain ? lobj->wdomain : lobj->rdomain;
+			
+		retry:
+			radeon_ttm_placement_from_domain(bo, domain);
 			r = ttm_bo_validate(&bo->tbo, &bo->placement,
 						true, false, false);
-			if (unlikely(r))
+			if (unlikely(r)) {
+				if (r != -ERESTARTSYS && domain == RADEON_GEM_DOMAIN_VRAM) {
+					domain |= RADEON_GEM_DOMAIN_GTT;
+					goto retry;
+				}
 				return r;
+			}
 		}
 		lobj->gpu_offset = radeon_bo_gpu_offset(bo);
 		lobj->tiling_flags = bo->tiling_flags;

commit e86527533586259875f08fccb173e3347046cc3f
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Wed May 19 16:05:50 2010 +0200

    drm/radeon/kms: record object that have been list reserved
    
    list reservation was too optimistic about ttm object reservation
    and could think that an object reserved by some other process
    as reserved by the list reservation which was false. Thus when
    unreserving the list it might unreserve object that it didn't
    reserved in the list. Sorry if it's hard to follow but this
    kind of things are just causing headheck.
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index a8d18bcae7db..d5b9373ce06c 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -301,6 +301,7 @@ int radeon_bo_list_reserve(struct list_head *head)
 		r = radeon_bo_reserve(lobj->bo, false);
 		if (unlikely(r != 0))
 			return r;
+		lobj->reserved = true;
 	}
 	return 0;
 }
@@ -311,7 +312,7 @@ void radeon_bo_list_unreserve(struct list_head *head)
 
 	list_for_each_entry(lobj, head, list) {
 		/* only unreserve object we successfully reserved */
-		if (radeon_bo_is_reserved(lobj->bo))
+		if (lobj->reserved && radeon_bo_is_reserved(lobj->bo))
 			radeon_bo_unreserve(lobj->bo);
 	}
 }
@@ -322,6 +323,9 @@ int radeon_bo_list_validate(struct list_head *head)
 	struct radeon_bo *bo;
 	int r;
 
+	list_for_each_entry(lobj, head, list) {
+		lobj->reserved = false;
+	}
 	r = radeon_bo_list_reserve(head);
 	if (unlikely(r != 0)) {
 		return r;

commit f4b7fb94c576265ceffc43031805ade32fa80c6a
Author: Dave Airlie <airlied@redhat.com>
Date:   Thu Apr 29 18:37:59 2010 +1000

    drm/radeon/kms: take vram mutex pointer before derefing object.
    
    since derefing the object might free it.
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 06def708b014..a8d18bcae7db 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -168,13 +168,15 @@ void radeon_bo_kunmap(struct radeon_bo *bo)
 void radeon_bo_unref(struct radeon_bo **bo)
 {
 	struct ttm_buffer_object *tbo;
+	struct radeon_device *rdev;
 
 	if ((*bo) == NULL)
 		return;
+	rdev = (*bo)->rdev;
 	tbo = &((*bo)->tbo);
-	mutex_lock(&(*bo)->rdev->vram_mutex);
+	mutex_lock(&rdev->vram_mutex);
 	ttm_bo_unref(&tbo);
-	mutex_unlock(&(*bo)->rdev->vram_mutex);
+	mutex_unlock(&rdev->vram_mutex);
 	if (tbo == NULL)
 		*bo = NULL;
 }

commit 5876dd249e8e47c730cac090bf6edd88e5f04327
Author: Matthew Garrett <mjg@redhat.com>
Date:   Mon Apr 26 15:52:20 2010 -0400

    radeon: Unmap vram pages when reclocking
    
    Touching vram while the card is reclocking can lead to lockups. Unmap
    any pages that could be touched by the CPU and block any accesses to
    vram until the reclocking is complete.
    
    Signed-off-by: Matthew Garrett <mjg@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 6a8617bac142..06def708b014 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -112,9 +112,11 @@ int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
 
 	radeon_ttm_placement_from_domain(bo, domain);
 	/* Kernel allocation are uninterruptible */
+	mutex_lock(&rdev->vram_mutex);
 	r = ttm_bo_init(&rdev->mman.bdev, &bo->tbo, size, type,
 			&bo->placement, 0, 0, !kernel, NULL, size,
 			&radeon_ttm_bo_destroy);
+	mutex_unlock(&rdev->vram_mutex);
 	if (unlikely(r != 0)) {
 		if (r != -ERESTARTSYS)
 			dev_err(rdev->dev,
@@ -170,7 +172,9 @@ void radeon_bo_unref(struct radeon_bo **bo)
 	if ((*bo) == NULL)
 		return;
 	tbo = &((*bo)->tbo);
+	mutex_lock(&(*bo)->rdev->vram_mutex);
 	ttm_bo_unref(&tbo);
+	mutex_unlock(&(*bo)->rdev->vram_mutex);
 	if (tbo == NULL)
 		*bo = NULL;
 }

commit 7547a917fa5f3b2406f52c7dcf7ec9ad3c8532eb
Merge: a8089e849a32 6b8b1786a8c2
Author: Dave Airlie <airlied@redhat.com>
Date:   Tue Apr 20 14:15:09 2010 +1000

    Merge branch 'drm-ttm-unmappable' into drm-core-next
    
    * drm-ttm-unmappable:
      drm/radeon/kms: enable use of unmappable VRAM V2
      drm/ttm: remove io_ field from TTM V6
      drm/vmwgfx: add support for new TTM fault callback V5
      drm/nouveau/kms: add support for new TTM fault callback V5
      drm/radeon/kms: add support for new fault callback V7
      drm/ttm: ttm_fault callback to allow driver to handle bo placement V6
      drm/ttm: split no_wait argument in 2 GPU or reserve wait
    
    Conflicts:
            drivers/gpu/drm/nouveau/nouveau_bo.c

commit 0a2d50e3a8faaf36cde36920431586090411ea15
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Fri Apr 9 14:39:24 2010 +0200

    drm/radeon/kms: add support for new fault callback V7
    
    This add the support for the new fault callback and also the
    infrastructure for supporting unmappable VRAM.
    
    V2 validate BO with no_wait = true
    V3 don't derefence bo->mem.mm_node as it's not NULL only for
       VRAM or GTT
    V4 update to splitted no_wait ttm change
    V5 update to new balanced io_mem_reserve/free change
    V6 callback is responsible for iomapping memory
    V7 move back iomapping to ttm
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 4b441f87f47a..57b3f95c0efa 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -498,11 +498,33 @@ void radeon_bo_move_notify(struct ttm_buffer_object *bo,
 	radeon_bo_check_tiling(rbo, 0, 1);
 }
 
-void radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
+int radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
 {
+	struct radeon_device *rdev;
 	struct radeon_bo *rbo;
+	unsigned long offset, size;
+	int r;
+
 	if (!radeon_ttm_bo_is_radeon_bo(bo))
-		return;
+		return 0;
 	rbo = container_of(bo, struct radeon_bo, tbo);
 	radeon_bo_check_tiling(rbo, 0, 0);
+	rdev = rbo->rdev;
+	if (bo->mem.mem_type == TTM_PL_VRAM) {
+		size = bo->mem.num_pages << PAGE_SHIFT;
+		offset = bo->mem.mm_node->start << PAGE_SHIFT;
+		if ((offset + size) > rdev->mc.visible_vram_size) {
+			/* hurrah the memory is not visible ! */
+			radeon_ttm_placement_from_domain(rbo, RADEON_GEM_DOMAIN_VRAM);
+			rbo->placement.lpfn = rdev->mc.visible_vram_size >> PAGE_SHIFT;
+			r = ttm_bo_validate(bo, &rbo->placement, false, true, false);
+			if (unlikely(r != 0))
+				return r;
+			offset = bo->mem.mm_node->start << PAGE_SHIFT;
+			/* this should not happen */
+			if ((offset + size) > rdev->mc.visible_vram_size)
+				return -EINVAL;
+		}
+	}
+	return 0;
 }

commit 9d87fa2138d06ff400551800d67d522625033e35
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Wed Apr 7 10:21:19 2010 +0000

    drm/ttm: split no_wait argument in 2 GPU or reserve wait
    
    There is case where we want to be able to wait only for the
    GPU while not waiting for other buffer to be unreserved. This
    patch split the no_wait argument all the way down in the whole
    ttm path so that upper level can decide on what to wait on or
    not.
    
    [airlied: squashed these 4 for bisectability reasons.]
    drm/radeon/kms: update to TTM no_wait splitted argument
    drm/nouveau: update to TTM no_wait splitted argument
    drm/vmwgfx: update to TTM no_wait splitted argument
    [vmwgfx patch: Reviewed-by: Thomas Hellstrom <thellstrom@vmware.com>]
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Acked-by: Thomas Hellstrom <thellstrom@vmware.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index dc7e3f449138..4b441f87f47a 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -191,7 +191,7 @@ int radeon_bo_pin(struct radeon_bo *bo, u32 domain, u64 *gpu_addr)
 	}
 	for (i = 0; i < bo->placement.num_placement; i++)
 		bo->placements[i] |= TTM_PL_FLAG_NO_EVICT;
-	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false);
+	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false, false);
 	if (likely(r == 0)) {
 		bo->pin_count = 1;
 		if (gpu_addr != NULL)
@@ -215,7 +215,7 @@ int radeon_bo_unpin(struct radeon_bo *bo)
 		return 0;
 	for (i = 0; i < bo->placement.num_placement; i++)
 		bo->placements[i] &= ~TTM_PL_FLAG_NO_EVICT;
-	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false);
+	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false, false);
 	if (unlikely(r != 0))
 		dev_err(bo->rdev->dev, "%p validate failed for unpin\n", bo);
 	return r;
@@ -330,7 +330,7 @@ int radeon_bo_list_validate(struct list_head *head)
 								lobj->rdomain);
 			}
 			r = ttm_bo_validate(&bo->tbo, &bo->placement,
-						true, false);
+						true, false, false);
 			if (unlikely(r))
 				return r;
 		}

commit 336f5899d287f06d8329e208fc14ce50f7ec9698
Merge: a4ab2773205e db217dece300
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Apr 5 11:37:28 2010 +0900

    Merge branch 'master' into export-slabh

commit 3ca82da3ebe019facd611184385897fa614e6b9e
Author: Michel Dänzer <daenzer@vmware.com>
Date:   Fri Mar 26 19:18:55 2010 +0000

    drm/radeon/kms: Only restrict BO to visible VRAM size when pinning to VRAM.
    
    This prevented radeon.test=1 from testing transfers from/to GTT beyond the
    visible VRAM size.
    
    Signed-off-by: Michel Dänzer <daenzer@vmware.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index fc9d00ac6b15..dc7e3f449138 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -185,8 +185,10 @@ int radeon_bo_pin(struct radeon_bo *bo, u32 domain, u64 *gpu_addr)
 		return 0;
 	}
 	radeon_ttm_placement_from_domain(bo, domain);
-	/* force to pin into visible video ram */
-	bo->placement.lpfn = bo->rdev->mc.visible_vram_size >> PAGE_SHIFT;
+	if (domain == RADEON_GEM_DOMAIN_VRAM) {
+		/* force to pin into visible video ram */
+		bo->placement.lpfn = bo->rdev->mc.visible_vram_size >> PAGE_SHIFT;
+	}
 	for (i = 0; i < bo->placement.num_placement; i++)
 		bo->placements[i] |= TTM_PL_FLAG_NO_EVICT;
 	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false);

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index fc9d00ac6b15..ffce2c9e7c76 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -30,6 +30,7 @@
  *    Dave Airlie
  */
 #include <linux/list.h>
+#include <linux/slab.h>
 #include <drm/drmP.h>
 #include "radeon_drm.h"
 #include "radeon.h"

commit 51e5fcd353a55364984bda3dd1391742e4dec53c
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Fri Feb 19 14:33:54 2010 +0000

    drm/radeon/kms: force pinning buffer into visible VRAM
    
    This patch properly set visible VRAM and enforce any pinned buffer
    to be into visible VRAM. We might later add a flag to release this
    constraint for some newer hw more clever than previous.
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index f1da370928eb..fc9d00ac6b15 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -178,7 +178,6 @@ int radeon_bo_pin(struct radeon_bo *bo, u32 domain, u64 *gpu_addr)
 {
 	int r, i;
 
-	radeon_ttm_placement_from_domain(bo, domain);
 	if (bo->pin_count) {
 		bo->pin_count++;
 		if (gpu_addr)
@@ -186,6 +185,8 @@ int radeon_bo_pin(struct radeon_bo *bo, u32 domain, u64 *gpu_addr)
 		return 0;
 	}
 	radeon_ttm_placement_from_domain(bo, domain);
+	/* force to pin into visible video ram */
+	bo->placement.lpfn = bo->rdev->mc.visible_vram_size >> PAGE_SHIFT;
 	for (i = 0; i < bo->placement.num_placement; i++)
 		bo->placements[i] |= TTM_PL_FLAG_NO_EVICT;
 	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false);

commit 6cb8e1f71c407930f0f07feceeea1da73881038b
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Mon Feb 15 21:36:33 2010 +0100

    drm/radeon/kms: fix bo's fence association
    
    Previous code did associate fence to bo before the fence was emited
    and it also didn't lock protected access to ttm sync_obj member.
    Both of this flaw leads to possible race between different code
    path. This patch fix this by associating fence only once the fence
    is emitted and properly lock protect access to sync_obj member of
    ttm.
    
    Fix:
    https://bugs.freedesktop.org/show_bug.cgi?id=26438
    and likely similar others bugs
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index d72a71bff218..f1da370928eb 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -306,11 +306,10 @@ void radeon_bo_list_unreserve(struct list_head *head)
 	}
 }
 
-int radeon_bo_list_validate(struct list_head *head, void *fence)
+int radeon_bo_list_validate(struct list_head *head)
 {
 	struct radeon_bo_list *lobj;
 	struct radeon_bo *bo;
-	struct radeon_fence *old_fence = NULL;
 	int r;
 
 	r = radeon_bo_list_reserve(head);
@@ -334,32 +333,27 @@ int radeon_bo_list_validate(struct list_head *head, void *fence)
 		}
 		lobj->gpu_offset = radeon_bo_gpu_offset(bo);
 		lobj->tiling_flags = bo->tiling_flags;
-		if (fence) {
-			old_fence = (struct radeon_fence *)bo->tbo.sync_obj;
-			bo->tbo.sync_obj = radeon_fence_ref(fence);
-			bo->tbo.sync_obj_arg = NULL;
-		}
-		if (old_fence) {
-			radeon_fence_unref(&old_fence);
-		}
 	}
 	return 0;
 }
 
-void radeon_bo_list_unvalidate(struct list_head *head, void *fence)
+void radeon_bo_list_fence(struct list_head *head, void *fence)
 {
 	struct radeon_bo_list *lobj;
-	struct radeon_fence *old_fence;
-
-	if (fence)
-		list_for_each_entry(lobj, head, list) {
-			old_fence = to_radeon_fence(lobj->bo->tbo.sync_obj);
-			if (old_fence == fence) {
-				lobj->bo->tbo.sync_obj = NULL;
-				radeon_fence_unref(&old_fence);
-			}
+	struct radeon_bo *bo;
+	struct radeon_fence *old_fence = NULL;
+
+	list_for_each_entry(lobj, head, list) {
+		bo = lobj->bo;
+		spin_lock(&bo->tbo.lock);
+		old_fence = (struct radeon_fence *)bo->tbo.sync_obj;
+		bo->tbo.sync_obj = radeon_fence_ref(fence);
+		bo->tbo.sync_obj_arg = NULL;
+		spin_unlock(&bo->tbo.lock);
+		if (old_fence) {
+			radeon_fence_unref(&old_fence);
 		}
-	radeon_bo_list_unreserve(head);
+	}
 }
 
 int radeon_bo_fbdev_mmap(struct radeon_bo *bo,

commit d796d8446fe0ff4442c1a1d0b10c861f17ac8168
Author: Dave Airlie <airlied@redhat.com>
Date:   Mon Jan 25 13:08:08 2010 +1000

    drm/radeon/kms: make hibernate work on IGPs
    
    This is the least invasive fix without migrating the radeon driver
    to pm_ops from what I can see. We just always migrate VRAM objects
    on IGPs for now and we can fix it up later to migrate depending
    on STR vs STD.
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 4e636de877b2..d72a71bff218 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -220,7 +220,8 @@ int radeon_bo_unpin(struct radeon_bo *bo)
 
 int radeon_bo_evict_vram(struct radeon_device *rdev)
 {
-	if (rdev->flags & RADEON_IS_IGP) {
+	/* late 2.6.33 fix IGP hibernate - we need pm ops to do this correct */
+	if (0 && (rdev->flags & RADEON_IS_IGP)) {
 		if (rdev->mc.igp_sideport_enabled == false)
 			/* Useless to evict on IGP chips */
 			return 0;

commit 06b6476d6b291473d0928ed242158a001d50c0f0
Author: Alex Deucher <alexdeucher@gmail.com>
Date:   Tue Jan 5 11:27:29 2010 -0500

    drm/radeon/kms: detect sideport memory on IGP chips
    
    This detects if the sideport memory is enabled and
    if it is VRAM is evicted on suspend/resume.
    
    This should fix s/r issues on some IGPs.
    
    Signed-off-by: Alex Deucher <alexdeucher@gmail.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index d9ffe1f56e8f..4e636de877b2 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -221,8 +221,9 @@ int radeon_bo_unpin(struct radeon_bo *bo)
 int radeon_bo_evict_vram(struct radeon_device *rdev)
 {
 	if (rdev->flags & RADEON_IS_IGP) {
-		/* Useless to evict on IGP chips */
-		return 0;
+		if (rdev->mc.igp_sideport_enabled == false)
+			/* Useless to evict on IGP chips */
+			return 0;
 	}
 	return ttm_bo_evict_mm(&rdev->mman.bdev, TTM_PL_VRAM);
 }

commit d03d858970a158fa82d9ba0d502bdea0bdb3ad33
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Mon Dec 14 21:02:09 2009 +0100

    drm/radeon/kms: Check if bo we got from ttm are radeon object or not
    
    If they are not radeon object don't do anythings special for them,
    this avoid rare oops than can happen in a complex use case.
    
    [airlied: additional fixups]
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 132130fcd991..d9ffe1f56e8f 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -56,6 +56,13 @@ static void radeon_ttm_bo_destroy(struct ttm_buffer_object *tbo)
 	kfree(bo);
 }
 
+bool radeon_ttm_bo_is_radeon_bo(struct ttm_buffer_object *bo)
+{
+	if (bo->destroy == &radeon_ttm_bo_destroy)
+		return true;
+	return false;
+}
+
 void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 {
 	u32 c = 0;
@@ -483,14 +490,20 @@ int radeon_bo_check_tiling(struct radeon_bo *bo, bool has_moved,
 }
 
 void radeon_bo_move_notify(struct ttm_buffer_object *bo,
-				struct ttm_mem_reg *mem)
+			   struct ttm_mem_reg *mem)
 {
-	struct radeon_bo *rbo = container_of(bo, struct radeon_bo, tbo);
+	struct radeon_bo *rbo;
+	if (!radeon_ttm_bo_is_radeon_bo(bo))
+		return;
+	rbo = container_of(bo, struct radeon_bo, tbo);
 	radeon_bo_check_tiling(rbo, 0, 1);
 }
 
 void radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
 {
-	struct radeon_bo *rbo = container_of(bo, struct radeon_bo, tbo);
+	struct radeon_bo *rbo;
+	if (!radeon_ttm_bo_is_radeon_bo(bo))
+		return;
+	rbo = container_of(bo, struct radeon_bo, tbo);
 	radeon_bo_check_tiling(rbo, 0, 0);
 }

commit 9fb03e63511cc20d413c2896396ba77df3db8411
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Fri Dec 11 15:13:22 2009 +0100

    drm/radeon/kms: If no placement is supplied fallback to system
    
    Do as we did before rework, if no placement is supplied at bo
    creation time, fallback to allocating bo from system ram. This
    will fix most of the creation failed issue report we got since
    the rework get merged.
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 544e18ffaf22..132130fcd991 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -71,6 +71,8 @@ void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 		rbo->placements[c++] = TTM_PL_MASK_CACHING | TTM_PL_FLAG_TT;
 	if (domain & RADEON_GEM_DOMAIN_CPU)
 		rbo->placements[c++] = TTM_PL_MASK_CACHING | TTM_PL_FLAG_SYSTEM;
+	if (!c)
+		rbo->placements[c++] = TTM_PL_MASK_CACHING | TTM_PL_FLAG_SYSTEM;
 	rbo->placement.num_placement = c;
 	rbo->placement.num_busy_placement = c;
 }

commit 1fb107fc46692a000533da3d6904ac28b6b3148d
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Thu Dec 10 17:16:28 2009 +0100

    drm/radeon/kms: Convert radeon to new ttm_bo_init
    
    Now bo init use placement structure like bo validation does.
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 2040937682fd..544e18ffaf22 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -56,25 +56,6 @@ static void radeon_ttm_bo_destroy(struct ttm_buffer_object *tbo)
 	kfree(bo);
 }
 
-static inline u32 radeon_ttm_flags_from_domain(u32 domain)
-{
-	u32 flags = 0;
-
-	if (domain & RADEON_GEM_DOMAIN_VRAM) {
-		flags |= TTM_PL_FLAG_VRAM | TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED;
-	}
-	if (domain & RADEON_GEM_DOMAIN_GTT) {
-		flags |= TTM_PL_FLAG_TT | TTM_PL_MASK_CACHING;
-	}
-	if (domain & RADEON_GEM_DOMAIN_CPU) {
-		flags |= TTM_PL_FLAG_SYSTEM | TTM_PL_MASK_CACHING;
-	}
-	if (!flags) {
-		flags |= TTM_PL_FLAG_SYSTEM | TTM_PL_MASK_CACHING;
-	}
-	return flags;
-}
-
 void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
 {
 	u32 c = 0;
@@ -100,7 +81,6 @@ int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
 {
 	struct radeon_bo *bo;
 	enum ttm_bo_type type;
-	u32 flags;
 	int r;
 
 	if (unlikely(rdev->mman.bdev.dev_mapping == NULL)) {
@@ -120,16 +100,16 @@ int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
 	bo->surface_reg = -1;
 	INIT_LIST_HEAD(&bo->list);
 
-	flags = radeon_ttm_flags_from_domain(domain);
+	radeon_ttm_placement_from_domain(bo, domain);
 	/* Kernel allocation are uninterruptible */
-	r = ttm_buffer_object_init(&rdev->mman.bdev, &bo->tbo, size, type,
-					flags, 0, 0, !kernel, NULL, size,
-					&radeon_ttm_bo_destroy);
+	r = ttm_bo_init(&rdev->mman.bdev, &bo->tbo, size, type,
+			&bo->placement, 0, 0, !kernel, NULL, size,
+			&radeon_ttm_bo_destroy);
 	if (unlikely(r != 0)) {
 		if (r != -ERESTARTSYS)
 			dev_err(rdev->dev,
-				"object_init failed for (%ld, 0x%08X)\n",
-				size, flags);
+				"object_init failed for (%lu, 0x%08X)\n",
+				size, domain);
 		return r;
 	}
 	*bo_ptr = bo;
@@ -199,7 +179,7 @@ int radeon_bo_pin(struct radeon_bo *bo, u32 domain, u64 *gpu_addr)
 	radeon_ttm_placement_from_domain(bo, domain);
 	for (i = 0; i < bo->placement.num_placement; i++)
 		bo->placements[i] |= TTM_PL_FLAG_NO_EVICT;
-	r = ttm_buffer_object_validate(&bo->tbo, &bo->placement, false, false);
+	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false);
 	if (likely(r == 0)) {
 		bo->pin_count = 1;
 		if (gpu_addr != NULL)
@@ -223,7 +203,7 @@ int radeon_bo_unpin(struct radeon_bo *bo)
 		return 0;
 	for (i = 0; i < bo->placement.num_placement; i++)
 		bo->placements[i] &= ~TTM_PL_FLAG_NO_EVICT;
-	r = ttm_buffer_object_validate(&bo->tbo, &bo->placement, false, false);
+	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false);
 	if (unlikely(r != 0))
 		dev_err(bo->rdev->dev, "%p validate failed for unpin\n", bo);
 	return r;
@@ -336,8 +316,7 @@ int radeon_bo_list_validate(struct list_head *head, void *fence)
 				radeon_ttm_placement_from_domain(bo,
 								lobj->rdomain);
 			}
-			r = ttm_buffer_object_validate(&bo->tbo,
-						&bo->placement,
+			r = ttm_bo_validate(&bo->tbo, &bo->placement,
 						true, false);
 			if (unlikely(r))
 				return r;

commit 550e2d9270e2f0a10c3b063899f70e4cca25fe72
Author: Dave Airlie <airlied@redhat.com>
Date:   Wed Dec 9 14:15:38 2009 +1000

    drm/radeon/kms: restore surface registers on resume.
    
    On resume on my rv530 laptop surface cntl was left disabled, so
    wierd stuff would happen with rendering to a tiled front buffer.
    
    This checks if the surface regs are assigned to bos and reprograms
    the surface registers on resume using the same path that clears
    them all on init.
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index ca172adfddb1..2040937682fd 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -378,7 +378,7 @@ int radeon_bo_fbdev_mmap(struct radeon_bo *bo,
 	return ttm_fbdev_mmap(vma, &bo->tbo);
 }
 
-static int radeon_bo_get_surface_reg(struct radeon_bo *bo)
+int radeon_bo_get_surface_reg(struct radeon_bo *bo)
 {
 	struct radeon_device *rdev = bo->rdev;
 	struct radeon_surface_reg *reg;

commit 5cc6fbab9da5680e7e5d2507d0f0c2c52ff18031
Author: Thomas Hellstrom <thellstrom@vmware.com>
Date:   Mon Dec 7 18:36:19 2009 +0100

    drm/radeon: Remove tests for -ERESTART from the TTM code.
    
    Also sets affected TTM calls up to not wait interruptible, since
    that would cause an in-kernel spin until the TTM call succeeds, since
    the Radeon code does not return to user-space when a signal is received.
    
    Modifies interruptible fence waits to return -ERESTARTSYS rather than
    -EBUSY when interrupted by a signal, since that's the (yet undocumented)
    semantics required by the TTM sync object hooks.
    
    Signed-off-by: Thomas Hellstrom <thellstrom@vmware.com>
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index d9b239bce12a..ca172adfddb1 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -121,16 +121,15 @@ int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
 	INIT_LIST_HEAD(&bo->list);
 
 	flags = radeon_ttm_flags_from_domain(domain);
-retry:
+	/* Kernel allocation are uninterruptible */
 	r = ttm_buffer_object_init(&rdev->mman.bdev, &bo->tbo, size, type,
-					flags, 0, 0, true, NULL, size,
+					flags, 0, 0, !kernel, NULL, size,
 					&radeon_ttm_bo_destroy);
 	if (unlikely(r != 0)) {
-		if (r == -ERESTART)
-			goto retry;
-		/* ttm call radeon_ttm_object_object_destroy if error happen */
-		dev_err(rdev->dev, "object_init failed for (%ld, 0x%08X)\n",
-			size, flags);
+		if (r != -ERESTARTSYS)
+			dev_err(rdev->dev,
+				"object_init failed for (%ld, 0x%08X)\n",
+				size, flags);
 		return r;
 	}
 	*bo_ptr = bo;
@@ -200,18 +199,14 @@ int radeon_bo_pin(struct radeon_bo *bo, u32 domain, u64 *gpu_addr)
 	radeon_ttm_placement_from_domain(bo, domain);
 	for (i = 0; i < bo->placement.num_placement; i++)
 		bo->placements[i] |= TTM_PL_FLAG_NO_EVICT;
-retry:
-	r = ttm_buffer_object_validate(&bo->tbo, &bo->placement, true, false);
+	r = ttm_buffer_object_validate(&bo->tbo, &bo->placement, false, false);
 	if (likely(r == 0)) {
 		bo->pin_count = 1;
 		if (gpu_addr != NULL)
 			*gpu_addr = radeon_bo_gpu_offset(bo);
 	}
-	if (unlikely(r != 0)) {
-		if (r == -ERESTART)
-			goto retry;
+	if (unlikely(r != 0))
 		dev_err(bo->rdev->dev, "%p pin failed\n", bo);
-	}
 	return r;
 }
 
@@ -228,15 +223,10 @@ int radeon_bo_unpin(struct radeon_bo *bo)
 		return 0;
 	for (i = 0; i < bo->placement.num_placement; i++)
 		bo->placements[i] &= ~TTM_PL_FLAG_NO_EVICT;
-retry:
-	r = ttm_buffer_object_validate(&bo->tbo, &bo->placement, true, false);
-	if (unlikely(r != 0)) {
-		if (r == -ERESTART)
-			goto retry;
+	r = ttm_buffer_object_validate(&bo->tbo, &bo->placement, false, false);
+	if (unlikely(r != 0))
 		dev_err(bo->rdev->dev, "%p validate failed for unpin\n", bo);
-		return r;
-	}
-	return 0;
+	return r;
 }
 
 int radeon_bo_evict_vram(struct radeon_device *rdev)
@@ -346,15 +336,11 @@ int radeon_bo_list_validate(struct list_head *head, void *fence)
 				radeon_ttm_placement_from_domain(bo,
 								lobj->rdomain);
 			}
-retry:
 			r = ttm_buffer_object_validate(&bo->tbo,
 						&bo->placement,
 						true, false);
-			if (unlikely(r)) {
-				if (r == -ERESTART)
-					goto retry;
+			if (unlikely(r))
 				return r;
-			}
 		}
 		lobj->gpu_offset = radeon_bo_gpu_offset(bo);
 		lobj->tiling_flags = bo->tiling_flags;

commit 312ea8da049a1830aa50c6e00002e50e30df476e
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Mon Dec 7 15:52:58 2009 +0100

    drm/radeon/kms: Convert radeon to new TTM validation API (V2)
    
    This convert radeon to use new TTM validation API, it doesn't
    really take advantage of it beside in the eviction case.
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index bec494384825..d9b239bce12a 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -75,6 +75,25 @@ static inline u32 radeon_ttm_flags_from_domain(u32 domain)
 	return flags;
 }
 
+void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain)
+{
+	u32 c = 0;
+
+	rbo->placement.fpfn = 0;
+	rbo->placement.lpfn = 0;
+	rbo->placement.placement = rbo->placements;
+	rbo->placement.busy_placement = rbo->placements;
+	if (domain & RADEON_GEM_DOMAIN_VRAM)
+		rbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED |
+					TTM_PL_FLAG_VRAM;
+	if (domain & RADEON_GEM_DOMAIN_GTT)
+		rbo->placements[c++] = TTM_PL_MASK_CACHING | TTM_PL_FLAG_TT;
+	if (domain & RADEON_GEM_DOMAIN_CPU)
+		rbo->placements[c++] = TTM_PL_MASK_CACHING | TTM_PL_FLAG_SYSTEM;
+	rbo->placement.num_placement = c;
+	rbo->placement.num_busy_placement = c;
+}
+
 int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
 			unsigned long size, bool kernel, u32 domain,
 			struct radeon_bo **bo_ptr)
@@ -169,24 +188,20 @@ void radeon_bo_unref(struct radeon_bo **bo)
 
 int radeon_bo_pin(struct radeon_bo *bo, u32 domain, u64 *gpu_addr)
 {
-	u32 flags;
-	u32 tmp;
-	int r;
+	int r, i;
 
-	flags = radeon_ttm_flags_from_domain(domain);
+	radeon_ttm_placement_from_domain(bo, domain);
 	if (bo->pin_count) {
 		bo->pin_count++;
 		if (gpu_addr)
 			*gpu_addr = radeon_bo_gpu_offset(bo);
 		return 0;
 	}
-	tmp = bo->tbo.mem.placement;
-	ttm_flag_masked(&tmp, flags, TTM_PL_MASK_MEM);
-	bo->tbo.proposed_placement = tmp | TTM_PL_FLAG_NO_EVICT |
-					TTM_PL_MASK_CACHING;
+	radeon_ttm_placement_from_domain(bo, domain);
+	for (i = 0; i < bo->placement.num_placement; i++)
+		bo->placements[i] |= TTM_PL_FLAG_NO_EVICT;
 retry:
-	r = ttm_buffer_object_validate(&bo->tbo, bo->tbo.proposed_placement,
-					true, false);
+	r = ttm_buffer_object_validate(&bo->tbo, &bo->placement, true, false);
 	if (likely(r == 0)) {
 		bo->pin_count = 1;
 		if (gpu_addr != NULL)
@@ -202,7 +217,7 @@ int radeon_bo_pin(struct radeon_bo *bo, u32 domain, u64 *gpu_addr)
 
 int radeon_bo_unpin(struct radeon_bo *bo)
 {
-	int r;
+	int r, i;
 
 	if (!bo->pin_count) {
 		dev_warn(bo->rdev->dev, "%p unpin not necessary\n", bo);
@@ -211,11 +226,10 @@ int radeon_bo_unpin(struct radeon_bo *bo)
 	bo->pin_count--;
 	if (bo->pin_count)
 		return 0;
-	bo->tbo.proposed_placement = bo->tbo.mem.placement &
-					~TTM_PL_FLAG_NO_EVICT;
+	for (i = 0; i < bo->placement.num_placement; i++)
+		bo->placements[i] &= ~TTM_PL_FLAG_NO_EVICT;
 retry:
-	r = ttm_buffer_object_validate(&bo->tbo, bo->tbo.proposed_placement,
-					true, false);
+	r = ttm_buffer_object_validate(&bo->tbo, &bo->placement, true, false);
 	if (unlikely(r != 0)) {
 		if (r == -ERESTART)
 			goto retry;
@@ -326,15 +340,15 @@ int radeon_bo_list_validate(struct list_head *head, void *fence)
 		bo = lobj->bo;
 		if (!bo->pin_count) {
 			if (lobj->wdomain) {
-				bo->tbo.proposed_placement =
-					radeon_ttm_flags_from_domain(lobj->wdomain);
+				radeon_ttm_placement_from_domain(bo,
+								lobj->wdomain);
 			} else {
-				bo->tbo.proposed_placement =
-					radeon_ttm_flags_from_domain(lobj->rdomain);
+				radeon_ttm_placement_from_domain(bo,
+								lobj->rdomain);
 			}
 retry:
 			r = ttm_buffer_object_validate(&bo->tbo,
-						bo->tbo.proposed_placement,
+						&bo->placement,
 						true, false);
 			if (unlikely(r)) {
 				if (r == -ERESTART)

commit 4c7886791264f03428d5424befb1b96f08fc90f4
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Fri Nov 20 14:29:23 2009 +0100

    drm/radeon/kms: Rework radeon object handling
    
    The locking & protection of radeon object was somewhat messy.
    This patch completely rework it to now use ttm reserve as a
    protection for the radeon object structure member. It also
    shrink down the various radeon object structure by removing
    field which were redondant with the ttm information. Last it
    converts few simple functions to inline which should with
    performances.
    
    airlied: rebase on top of r600 and other changes.
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 98835f51e35e..bec494384825 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -34,74 +34,32 @@
 #include "radeon_drm.h"
 #include "radeon.h"
 
-struct radeon_object {
-	struct ttm_buffer_object	tobj;
-	struct list_head		list;
-	struct radeon_device		*rdev;
-	struct drm_gem_object		*gobj;
-	struct ttm_bo_kmap_obj		kmap;
-	unsigned			pin_count;
-	uint64_t			gpu_addr;
-	void				*kptr;
-	bool				is_iomem;
-	uint32_t			tiling_flags;
-	uint32_t			pitch;
-	int				surface_reg;
-};
 
 int radeon_ttm_init(struct radeon_device *rdev);
 void radeon_ttm_fini(struct radeon_device *rdev);
+static void radeon_bo_clear_surface_reg(struct radeon_bo *bo);
 
 /*
  * To exclude mutual BO access we rely on bo_reserve exclusion, as all
  * function are calling it.
  */
 
-static int radeon_object_reserve(struct radeon_object *robj, bool interruptible)
+static void radeon_ttm_bo_destroy(struct ttm_buffer_object *tbo)
 {
-	return ttm_bo_reserve(&robj->tobj, interruptible, false, false, 0);
-}
+	struct radeon_bo *bo;
 
-static void radeon_object_unreserve(struct radeon_object *robj)
-{
-	ttm_bo_unreserve(&robj->tobj);
+	bo = container_of(tbo, struct radeon_bo, tbo);
+	mutex_lock(&bo->rdev->gem.mutex);
+	list_del_init(&bo->list);
+	mutex_unlock(&bo->rdev->gem.mutex);
+	radeon_bo_clear_surface_reg(bo);
+	kfree(bo);
 }
 
-static void radeon_ttm_object_object_destroy(struct ttm_buffer_object *tobj)
+static inline u32 radeon_ttm_flags_from_domain(u32 domain)
 {
-	struct radeon_object *robj;
-
-	robj = container_of(tobj, struct radeon_object, tobj);
-	list_del_init(&robj->list);
-	radeon_object_clear_surface_reg(robj);
-	kfree(robj);
-}
-
-static inline void radeon_object_gpu_addr(struct radeon_object *robj)
-{
-	/* Default gpu address */
-	robj->gpu_addr = 0xFFFFFFFFFFFFFFFFULL;
-	if (robj->tobj.mem.mm_node == NULL) {
-		return;
-	}
-	robj->gpu_addr = ((u64)robj->tobj.mem.mm_node->start) << PAGE_SHIFT;
-	switch (robj->tobj.mem.mem_type) {
-	case TTM_PL_VRAM:
-		robj->gpu_addr += (u64)robj->rdev->mc.vram_location;
-		break;
-	case TTM_PL_TT:
-		robj->gpu_addr += (u64)robj->rdev->mc.gtt_location;
-		break;
-	default:
-		DRM_ERROR("Unknown placement %d\n", robj->tobj.mem.mem_type);
-		robj->gpu_addr = 0xFFFFFFFFFFFFFFFFULL;
-		return;
-	}
-}
+	u32 flags = 0;
 
-static inline uint32_t radeon_object_flags_from_domain(uint32_t domain)
-{
-	uint32_t flags = 0;
 	if (domain & RADEON_GEM_DOMAIN_VRAM) {
 		flags |= TTM_PL_FLAG_VRAM | TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED;
 	}
@@ -117,17 +75,13 @@ static inline uint32_t radeon_object_flags_from_domain(uint32_t domain)
 	return flags;
 }
 
-int radeon_object_create(struct radeon_device *rdev,
-			 struct drm_gem_object *gobj,
-			 unsigned long size,
-			 bool kernel,
-			 uint32_t domain,
-			 bool interruptible,
-			 struct radeon_object **robj_ptr)
+int radeon_bo_create(struct radeon_device *rdev, struct drm_gem_object *gobj,
+			unsigned long size, bool kernel, u32 domain,
+			struct radeon_bo **bo_ptr)
 {
-	struct radeon_object *robj;
+	struct radeon_bo *bo;
 	enum ttm_bo_type type;
-	uint32_t flags;
+	u32 flags;
 	int r;
 
 	if (unlikely(rdev->mman.bdev.dev_mapping == NULL)) {
@@ -138,207 +92,140 @@ int radeon_object_create(struct radeon_device *rdev,
 	} else {
 		type = ttm_bo_type_device;
 	}
-	*robj_ptr = NULL;
-	robj = kzalloc(sizeof(struct radeon_object), GFP_KERNEL);
-	if (robj == NULL) {
+	*bo_ptr = NULL;
+	bo = kzalloc(sizeof(struct radeon_bo), GFP_KERNEL);
+	if (bo == NULL)
 		return -ENOMEM;
-	}
-	robj->rdev = rdev;
-	robj->gobj = gobj;
-	robj->surface_reg = -1;
-	INIT_LIST_HEAD(&robj->list);
-
-	flags = radeon_object_flags_from_domain(domain);
-	r = ttm_buffer_object_init(&rdev->mman.bdev, &robj->tobj, size, type, flags,
-				   0, 0, false, NULL, size,
-				   &radeon_ttm_object_object_destroy);
+	bo->rdev = rdev;
+	bo->gobj = gobj;
+	bo->surface_reg = -1;
+	INIT_LIST_HEAD(&bo->list);
+
+	flags = radeon_ttm_flags_from_domain(domain);
+retry:
+	r = ttm_buffer_object_init(&rdev->mman.bdev, &bo->tbo, size, type,
+					flags, 0, 0, true, NULL, size,
+					&radeon_ttm_bo_destroy);
 	if (unlikely(r != 0)) {
+		if (r == -ERESTART)
+			goto retry;
 		/* ttm call radeon_ttm_object_object_destroy if error happen */
-		DRM_ERROR("Failed to allocate TTM object (%ld, 0x%08X, %u)\n",
-			  size, flags, 0);
+		dev_err(rdev->dev, "object_init failed for (%ld, 0x%08X)\n",
+			size, flags);
 		return r;
 	}
-	*robj_ptr = robj;
+	*bo_ptr = bo;
 	if (gobj) {
-		list_add_tail(&robj->list, &rdev->gem.objects);
+		mutex_lock(&bo->rdev->gem.mutex);
+		list_add_tail(&bo->list, &rdev->gem.objects);
+		mutex_unlock(&bo->rdev->gem.mutex);
 	}
 	return 0;
 }
 
-int radeon_object_kmap(struct radeon_object *robj, void **ptr)
+int radeon_bo_kmap(struct radeon_bo *bo, void **ptr)
 {
+	bool is_iomem;
 	int r;
 
-	spin_lock(&robj->tobj.lock);
-	if (robj->kptr) {
+	if (bo->kptr) {
 		if (ptr) {
-			*ptr = robj->kptr;
+			*ptr = bo->kptr;
 		}
-		spin_unlock(&robj->tobj.lock);
 		return 0;
 	}
-	spin_unlock(&robj->tobj.lock);
-	r = ttm_bo_kmap(&robj->tobj, 0, robj->tobj.num_pages, &robj->kmap);
+	r = ttm_bo_kmap(&bo->tbo, 0, bo->tbo.num_pages, &bo->kmap);
 	if (r) {
 		return r;
 	}
-	spin_lock(&robj->tobj.lock);
-	robj->kptr = ttm_kmap_obj_virtual(&robj->kmap, &robj->is_iomem);
-	spin_unlock(&robj->tobj.lock);
+	bo->kptr = ttm_kmap_obj_virtual(&bo->kmap, &is_iomem);
 	if (ptr) {
-		*ptr = robj->kptr;
+		*ptr = bo->kptr;
 	}
-	radeon_object_check_tiling(robj, 0, 0);
+	radeon_bo_check_tiling(bo, 0, 0);
 	return 0;
 }
 
-void radeon_object_kunmap(struct radeon_object *robj)
+void radeon_bo_kunmap(struct radeon_bo *bo)
 {
-	spin_lock(&robj->tobj.lock);
-	if (robj->kptr == NULL) {
-		spin_unlock(&robj->tobj.lock);
+	if (bo->kptr == NULL)
 		return;
-	}
-	robj->kptr = NULL;
-	spin_unlock(&robj->tobj.lock);
-	radeon_object_check_tiling(robj, 0, 0);
-	ttm_bo_kunmap(&robj->kmap);
+	bo->kptr = NULL;
+	radeon_bo_check_tiling(bo, 0, 0);
+	ttm_bo_kunmap(&bo->kmap);
 }
 
-void radeon_object_unref(struct radeon_object **robj)
+void radeon_bo_unref(struct radeon_bo **bo)
 {
-	struct ttm_buffer_object *tobj;
+	struct ttm_buffer_object *tbo;
 
-	if ((*robj) == NULL) {
+	if ((*bo) == NULL)
 		return;
-	}
-	tobj = &((*robj)->tobj);
-	ttm_bo_unref(&tobj);
-	if (tobj == NULL) {
-		*robj = NULL;
-	}
-}
-
-int radeon_object_mmap(struct radeon_object *robj, uint64_t *offset)
-{
-	*offset = robj->tobj.addr_space_offset;
-	return 0;
+	tbo = &((*bo)->tbo);
+	ttm_bo_unref(&tbo);
+	if (tbo == NULL)
+		*bo = NULL;
 }
 
-int radeon_object_pin(struct radeon_object *robj, uint32_t domain,
-		      uint64_t *gpu_addr)
+int radeon_bo_pin(struct radeon_bo *bo, u32 domain, u64 *gpu_addr)
 {
-	uint32_t flags;
-	uint32_t tmp;
+	u32 flags;
+	u32 tmp;
 	int r;
 
-	flags = radeon_object_flags_from_domain(domain);
-	spin_lock(&robj->tobj.lock);
-	if (robj->pin_count) {
-		robj->pin_count++;
-		if (gpu_addr != NULL) {
-			*gpu_addr = robj->gpu_addr;
-		}
-		spin_unlock(&robj->tobj.lock);
+	flags = radeon_ttm_flags_from_domain(domain);
+	if (bo->pin_count) {
+		bo->pin_count++;
+		if (gpu_addr)
+			*gpu_addr = radeon_bo_gpu_offset(bo);
 		return 0;
 	}
-	spin_unlock(&robj->tobj.lock);
-	r = radeon_object_reserve(robj, false);
-	if (unlikely(r != 0)) {
-		DRM_ERROR("radeon: failed to reserve object for pinning it.\n");
-		return r;
-	}
-	tmp = robj->tobj.mem.placement;
+	tmp = bo->tbo.mem.placement;
 	ttm_flag_masked(&tmp, flags, TTM_PL_MASK_MEM);
-	robj->tobj.proposed_placement = tmp | TTM_PL_FLAG_NO_EVICT | TTM_PL_MASK_CACHING;
-	r = ttm_buffer_object_validate(&robj->tobj,
-				       robj->tobj.proposed_placement,
-				       false, false);
-	radeon_object_gpu_addr(robj);
-	if (gpu_addr != NULL) {
-		*gpu_addr = robj->gpu_addr;
+	bo->tbo.proposed_placement = tmp | TTM_PL_FLAG_NO_EVICT |
+					TTM_PL_MASK_CACHING;
+retry:
+	r = ttm_buffer_object_validate(&bo->tbo, bo->tbo.proposed_placement,
+					true, false);
+	if (likely(r == 0)) {
+		bo->pin_count = 1;
+		if (gpu_addr != NULL)
+			*gpu_addr = radeon_bo_gpu_offset(bo);
 	}
-	robj->pin_count = 1;
 	if (unlikely(r != 0)) {
-		DRM_ERROR("radeon: failed to pin object.\n");
+		if (r == -ERESTART)
+			goto retry;
+		dev_err(bo->rdev->dev, "%p pin failed\n", bo);
 	}
-	radeon_object_unreserve(robj);
 	return r;
 }
 
-void radeon_object_unpin(struct radeon_object *robj)
+int radeon_bo_unpin(struct radeon_bo *bo)
 {
-	uint32_t flags;
 	int r;
 
-	spin_lock(&robj->tobj.lock);
-	if (!robj->pin_count) {
-		spin_unlock(&robj->tobj.lock);
-		printk(KERN_WARNING "Unpin not necessary for %p !\n", robj);
-		return;
-	}
-	robj->pin_count--;
-	if (robj->pin_count) {
-		spin_unlock(&robj->tobj.lock);
-		return;
-	}
-	spin_unlock(&robj->tobj.lock);
-	r = radeon_object_reserve(robj, false);
-	if (unlikely(r != 0)) {
-		DRM_ERROR("radeon: failed to reserve object for unpinning it.\n");
-		return;
-	}
-	flags = robj->tobj.mem.placement;
-	robj->tobj.proposed_placement = flags & ~TTM_PL_FLAG_NO_EVICT;
-	r = ttm_buffer_object_validate(&robj->tobj,
-				       robj->tobj.proposed_placement,
-				       false, false);
-	if (unlikely(r != 0)) {
-		DRM_ERROR("radeon: failed to unpin buffer.\n");
-	}
-	radeon_object_unreserve(robj);
-}
-
-int radeon_object_wait(struct radeon_object *robj)
-{
-	int r = 0;
-
-	/* FIXME: should use block reservation instead */
-	r = radeon_object_reserve(robj, true);
-	if (unlikely(r != 0)) {
-		DRM_ERROR("radeon: failed to reserve object for waiting.\n");
-		return r;
-	}
-	spin_lock(&robj->tobj.lock);
-	if (robj->tobj.sync_obj) {
-		r = ttm_bo_wait(&robj->tobj, true, true, false);
+	if (!bo->pin_count) {
+		dev_warn(bo->rdev->dev, "%p unpin not necessary\n", bo);
+		return 0;
 	}
-	spin_unlock(&robj->tobj.lock);
-	radeon_object_unreserve(robj);
-	radeon_hdp_flush(robj->rdev);
-	return r;
-}
-
-int radeon_object_busy_domain(struct radeon_object *robj, uint32_t *cur_placement)
-{
-	int r = 0;
-
-	r = radeon_object_reserve(robj, true);
+	bo->pin_count--;
+	if (bo->pin_count)
+		return 0;
+	bo->tbo.proposed_placement = bo->tbo.mem.placement &
+					~TTM_PL_FLAG_NO_EVICT;
+retry:
+	r = ttm_buffer_object_validate(&bo->tbo, bo->tbo.proposed_placement,
+					true, false);
 	if (unlikely(r != 0)) {
-		DRM_ERROR("radeon: failed to reserve object for waiting.\n");
+		if (r == -ERESTART)
+			goto retry;
+		dev_err(bo->rdev->dev, "%p validate failed for unpin\n", bo);
 		return r;
 	}
-	spin_lock(&robj->tobj.lock);
-	*cur_placement = robj->tobj.mem.mem_type;
-	if (robj->tobj.sync_obj) {
-		r = ttm_bo_wait(&robj->tobj, true, true, true);
-	}
-	spin_unlock(&robj->tobj.lock);
-	radeon_object_unreserve(robj);
-	return r;
+	return 0;
 }
 
-int radeon_object_evict_vram(struct radeon_device *rdev)
+int radeon_bo_evict_vram(struct radeon_device *rdev)
 {
 	if (rdev->flags & RADEON_IS_IGP) {
 		/* Useless to evict on IGP chips */
@@ -347,30 +234,32 @@ int radeon_object_evict_vram(struct radeon_device *rdev)
 	return ttm_bo_evict_mm(&rdev->mman.bdev, TTM_PL_VRAM);
 }
 
-void radeon_object_force_delete(struct radeon_device *rdev)
+void radeon_bo_force_delete(struct radeon_device *rdev)
 {
-	struct radeon_object *robj, *n;
+	struct radeon_bo *bo, *n;
 	struct drm_gem_object *gobj;
 
 	if (list_empty(&rdev->gem.objects)) {
 		return;
 	}
-	DRM_ERROR("Userspace still has active objects !\n");
-	list_for_each_entry_safe(robj, n, &rdev->gem.objects, list) {
+	dev_err(rdev->dev, "Userspace still has active objects !\n");
+	list_for_each_entry_safe(bo, n, &rdev->gem.objects, list) {
 		mutex_lock(&rdev->ddev->struct_mutex);
-		gobj = robj->gobj;
-		DRM_ERROR("Force free for (%p,%p,%lu,%lu)\n",
-			  gobj, robj, (unsigned long)gobj->size,
-			  *((unsigned long *)&gobj->refcount));
-		list_del_init(&robj->list);
-		radeon_object_unref(&robj);
+		gobj = bo->gobj;
+		dev_err(rdev->dev, "%p %p %lu %lu force free\n",
+			gobj, bo, (unsigned long)gobj->size,
+			*((unsigned long *)&gobj->refcount));
+		mutex_lock(&bo->rdev->gem.mutex);
+		list_del_init(&bo->list);
+		mutex_unlock(&bo->rdev->gem.mutex);
+		radeon_bo_unref(&bo);
 		gobj->driver_private = NULL;
 		drm_gem_object_unreference(gobj);
 		mutex_unlock(&rdev->ddev->struct_mutex);
 	}
 }
 
-int radeon_object_init(struct radeon_device *rdev)
+int radeon_bo_init(struct radeon_device *rdev)
 {
 	/* Add an MTRR for the VRAM */
 	rdev->mc.vram_mtrr = mtrr_add(rdev->mc.aper_base, rdev->mc.aper_size,
@@ -383,13 +272,13 @@ int radeon_object_init(struct radeon_device *rdev)
 	return radeon_ttm_init(rdev);
 }
 
-void radeon_object_fini(struct radeon_device *rdev)
+void radeon_bo_fini(struct radeon_device *rdev)
 {
 	radeon_ttm_fini(rdev);
 }
 
-void radeon_object_list_add_object(struct radeon_object_list *lobj,
-				   struct list_head *head)
+void radeon_bo_list_add_object(struct radeon_bo_list *lobj,
+				struct list_head *head)
 {
 	if (lobj->wdomain) {
 		list_add(&lobj->list, head);
@@ -398,72 +287,67 @@ void radeon_object_list_add_object(struct radeon_object_list *lobj,
 	}
 }
 
-int radeon_object_list_reserve(struct list_head *head)
+int radeon_bo_list_reserve(struct list_head *head)
 {
-	struct radeon_object_list *lobj;
+	struct radeon_bo_list *lobj;
 	int r;
 
 	list_for_each_entry(lobj, head, list){
-		if (!lobj->robj->pin_count) {
-			r = radeon_object_reserve(lobj->robj, true);
-			if (unlikely(r != 0)) {
-				DRM_ERROR("radeon: failed to reserve object.\n");
-				return r;
-			}
-		} else {
-		}
+		r = radeon_bo_reserve(lobj->bo, false);
+		if (unlikely(r != 0))
+			return r;
 	}
 	return 0;
 }
 
-void radeon_object_list_unreserve(struct list_head *head)
+void radeon_bo_list_unreserve(struct list_head *head)
 {
-	struct radeon_object_list *lobj;
+	struct radeon_bo_list *lobj;
 
 	list_for_each_entry(lobj, head, list) {
-		if (!lobj->robj->pin_count) {
-			radeon_object_unreserve(lobj->robj);
-		}
+		/* only unreserve object we successfully reserved */
+		if (radeon_bo_is_reserved(lobj->bo))
+			radeon_bo_unreserve(lobj->bo);
 	}
 }
 
-int radeon_object_list_validate(struct list_head *head, void *fence)
+int radeon_bo_list_validate(struct list_head *head, void *fence)
 {
-	struct radeon_object_list *lobj;
-	struct radeon_object *robj;
+	struct radeon_bo_list *lobj;
+	struct radeon_bo *bo;
 	struct radeon_fence *old_fence = NULL;
 	int r;
 
-	r = radeon_object_list_reserve(head);
+	r = radeon_bo_list_reserve(head);
 	if (unlikely(r != 0)) {
-		radeon_object_list_unreserve(head);
 		return r;
 	}
 	list_for_each_entry(lobj, head, list) {
-		robj = lobj->robj;
-		if (!robj->pin_count) {
+		bo = lobj->bo;
+		if (!bo->pin_count) {
 			if (lobj->wdomain) {
-				robj->tobj.proposed_placement =
-					radeon_object_flags_from_domain(lobj->wdomain);
+				bo->tbo.proposed_placement =
+					radeon_ttm_flags_from_domain(lobj->wdomain);
 			} else {
-				robj->tobj.proposed_placement =
-					radeon_object_flags_from_domain(lobj->rdomain);
+				bo->tbo.proposed_placement =
+					radeon_ttm_flags_from_domain(lobj->rdomain);
 			}
-			r = ttm_buffer_object_validate(&robj->tobj,
-						       robj->tobj.proposed_placement,
-						       true, false);
+retry:
+			r = ttm_buffer_object_validate(&bo->tbo,
+						bo->tbo.proposed_placement,
+						true, false);
 			if (unlikely(r)) {
-				DRM_ERROR("radeon: failed to validate.\n");
+				if (r == -ERESTART)
+					goto retry;
 				return r;
 			}
-			radeon_object_gpu_addr(robj);
 		}
-		lobj->gpu_offset = robj->gpu_addr;
-		lobj->tiling_flags = robj->tiling_flags;
+		lobj->gpu_offset = radeon_bo_gpu_offset(bo);
+		lobj->tiling_flags = bo->tiling_flags;
 		if (fence) {
-			old_fence = (struct radeon_fence *)robj->tobj.sync_obj;
-			robj->tobj.sync_obj = radeon_fence_ref(fence);
-			robj->tobj.sync_obj_arg = NULL;
+			old_fence = (struct radeon_fence *)bo->tbo.sync_obj;
+			bo->tbo.sync_obj = radeon_fence_ref(fence);
+			bo->tbo.sync_obj_arg = NULL;
 		}
 		if (old_fence) {
 			radeon_fence_unref(&old_fence);
@@ -472,51 +356,44 @@ int radeon_object_list_validate(struct list_head *head, void *fence)
 	return 0;
 }
 
-void radeon_object_list_unvalidate(struct list_head *head)
+void radeon_bo_list_unvalidate(struct list_head *head, void *fence)
 {
-	struct radeon_object_list *lobj;
-	struct radeon_fence *old_fence = NULL;
+	struct radeon_bo_list *lobj;
+	struct radeon_fence *old_fence;
 
-	list_for_each_entry(lobj, head, list) {
-		old_fence = (struct radeon_fence *)lobj->robj->tobj.sync_obj;
-		lobj->robj->tobj.sync_obj = NULL;
-		if (old_fence) {
-			radeon_fence_unref(&old_fence);
+	if (fence)
+		list_for_each_entry(lobj, head, list) {
+			old_fence = to_radeon_fence(lobj->bo->tbo.sync_obj);
+			if (old_fence == fence) {
+				lobj->bo->tbo.sync_obj = NULL;
+				radeon_fence_unref(&old_fence);
+			}
 		}
-	}
-	radeon_object_list_unreserve(head);
-}
-
-void radeon_object_list_clean(struct list_head *head)
-{
-	radeon_object_list_unreserve(head);
+	radeon_bo_list_unreserve(head);
 }
 
-int radeon_object_fbdev_mmap(struct radeon_object *robj,
+int radeon_bo_fbdev_mmap(struct radeon_bo *bo,
 			     struct vm_area_struct *vma)
 {
-	return ttm_fbdev_mmap(vma, &robj->tobj);
+	return ttm_fbdev_mmap(vma, &bo->tbo);
 }
 
-unsigned long radeon_object_size(struct radeon_object *robj)
+static int radeon_bo_get_surface_reg(struct radeon_bo *bo)
 {
-	return robj->tobj.num_pages << PAGE_SHIFT;
-}
-
-int radeon_object_get_surface_reg(struct radeon_object *robj)
-{
-	struct radeon_device *rdev = robj->rdev;
+	struct radeon_device *rdev = bo->rdev;
 	struct radeon_surface_reg *reg;
-	struct radeon_object *old_object;
+	struct radeon_bo *old_object;
 	int steal;
 	int i;
 
-	if (!robj->tiling_flags)
+	BUG_ON(!atomic_read(&bo->tbo.reserved));
+
+	if (!bo->tiling_flags)
 		return 0;
 
-	if (robj->surface_reg >= 0) {
-		reg = &rdev->surface_regs[robj->surface_reg];
-		i = robj->surface_reg;
+	if (bo->surface_reg >= 0) {
+		reg = &rdev->surface_regs[bo->surface_reg];
+		i = bo->surface_reg;
 		goto out;
 	}
 
@@ -524,10 +401,10 @@ int radeon_object_get_surface_reg(struct radeon_object *robj)
 	for (i = 0; i < RADEON_GEM_MAX_SURFACES; i++) {
 
 		reg = &rdev->surface_regs[i];
-		if (!reg->robj)
+		if (!reg->bo)
 			break;
 
-		old_object = reg->robj;
+		old_object = reg->bo;
 		if (old_object->pin_count == 0)
 			steal = i;
 	}
@@ -538,91 +415,101 @@ int radeon_object_get_surface_reg(struct radeon_object *robj)
 			return -ENOMEM;
 		/* find someone with a surface reg and nuke their BO */
 		reg = &rdev->surface_regs[steal];
-		old_object = reg->robj;
+		old_object = reg->bo;
 		/* blow away the mapping */
 		DRM_DEBUG("stealing surface reg %d from %p\n", steal, old_object);
-		ttm_bo_unmap_virtual(&old_object->tobj);
+		ttm_bo_unmap_virtual(&old_object->tbo);
 		old_object->surface_reg = -1;
 		i = steal;
 	}
 
-	robj->surface_reg = i;
-	reg->robj = robj;
+	bo->surface_reg = i;
+	reg->bo = bo;
 
 out:
-	radeon_set_surface_reg(rdev, i, robj->tiling_flags, robj->pitch,
-			       robj->tobj.mem.mm_node->start << PAGE_SHIFT,
-			       robj->tobj.num_pages << PAGE_SHIFT);
+	radeon_set_surface_reg(rdev, i, bo->tiling_flags, bo->pitch,
+			       bo->tbo.mem.mm_node->start << PAGE_SHIFT,
+			       bo->tbo.num_pages << PAGE_SHIFT);
 	return 0;
 }
 
-void radeon_object_clear_surface_reg(struct radeon_object *robj)
+static void radeon_bo_clear_surface_reg(struct radeon_bo *bo)
 {
-	struct radeon_device *rdev = robj->rdev;
+	struct radeon_device *rdev = bo->rdev;
 	struct radeon_surface_reg *reg;
 
-	if (robj->surface_reg == -1)
+	if (bo->surface_reg == -1)
 		return;
 
-	reg = &rdev->surface_regs[robj->surface_reg];
-	radeon_clear_surface_reg(rdev, robj->surface_reg);
+	reg = &rdev->surface_regs[bo->surface_reg];
+	radeon_clear_surface_reg(rdev, bo->surface_reg);
 
-	reg->robj = NULL;
-	robj->surface_reg = -1;
+	reg->bo = NULL;
+	bo->surface_reg = -1;
 }
 
-void radeon_object_set_tiling_flags(struct radeon_object *robj,
-				    uint32_t tiling_flags, uint32_t pitch)
+int radeon_bo_set_tiling_flags(struct radeon_bo *bo,
+				uint32_t tiling_flags, uint32_t pitch)
 {
-	robj->tiling_flags = tiling_flags;
-	robj->pitch = pitch;
+	int r;
+
+	r = radeon_bo_reserve(bo, false);
+	if (unlikely(r != 0))
+		return r;
+	bo->tiling_flags = tiling_flags;
+	bo->pitch = pitch;
+	radeon_bo_unreserve(bo);
+	return 0;
 }
 
-void radeon_object_get_tiling_flags(struct radeon_object *robj,
-				    uint32_t *tiling_flags,
-				    uint32_t *pitch)
+void radeon_bo_get_tiling_flags(struct radeon_bo *bo,
+				uint32_t *tiling_flags,
+				uint32_t *pitch)
 {
+	BUG_ON(!atomic_read(&bo->tbo.reserved));
 	if (tiling_flags)
-		*tiling_flags = robj->tiling_flags;
+		*tiling_flags = bo->tiling_flags;
 	if (pitch)
-		*pitch = robj->pitch;
+		*pitch = bo->pitch;
 }
 
-int radeon_object_check_tiling(struct radeon_object *robj, bool has_moved,
-			       bool force_drop)
+int radeon_bo_check_tiling(struct radeon_bo *bo, bool has_moved,
+				bool force_drop)
 {
-	if (!(robj->tiling_flags & RADEON_TILING_SURFACE))
+	BUG_ON(!atomic_read(&bo->tbo.reserved));
+
+	if (!(bo->tiling_flags & RADEON_TILING_SURFACE))
 		return 0;
 
 	if (force_drop) {
-		radeon_object_clear_surface_reg(robj);
+		radeon_bo_clear_surface_reg(bo);
 		return 0;
 	}
 
-	if (robj->tobj.mem.mem_type != TTM_PL_VRAM) {
+	if (bo->tbo.mem.mem_type != TTM_PL_VRAM) {
 		if (!has_moved)
 			return 0;
 
-		if (robj->surface_reg >= 0)
-			radeon_object_clear_surface_reg(robj);
+		if (bo->surface_reg >= 0)
+			radeon_bo_clear_surface_reg(bo);
 		return 0;
 	}
 
-	if ((robj->surface_reg >= 0) && !has_moved)
+	if ((bo->surface_reg >= 0) && !has_moved)
 		return 0;
 
-	return radeon_object_get_surface_reg(robj);
+	return radeon_bo_get_surface_reg(bo);
 }
 
 void radeon_bo_move_notify(struct ttm_buffer_object *bo,
-			  struct ttm_mem_reg *mem)
+				struct ttm_mem_reg *mem)
 {
-	struct radeon_object *robj = container_of(bo, struct radeon_object, tobj);
-	radeon_object_check_tiling(robj, 0, 1);
+	struct radeon_bo *rbo = container_of(bo, struct radeon_bo, tbo);
+	radeon_bo_check_tiling(rbo, 0, 1);
 }
 
 void radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
 {
-	struct radeon_object *robj = container_of(bo, struct radeon_object, tobj);
-	radeon_object_check_tiling(robj, 0, 0);
+	struct radeon_bo *rbo = container_of(bo, struct radeon_bo, tbo);
+	radeon_bo_check_tiling(rbo, 0, 0);
 }

commit 23956dfa82eab95931aab5fa9886c1e96c41e4dc
Author: Dave Airlie <airlied@redhat.com>
Date:   Mon Nov 23 12:01:09 2009 +1000

    drm/radeon/kms: add HDP flushing for all GPUs.
    
    rendercheck under kms on r600s was failing due to HDP flushing not happening.
    
    This adds HDP flushing to the object wait function for r100->r700 families.
    
    rendercheck passes basic tests on r600 with this change.
    
    Acked-by: Alex Deucher <alexdeucher@gmail.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 1f056dadc5c2..98835f51e35e 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -315,6 +315,7 @@ int radeon_object_wait(struct radeon_object *robj)
 	}
 	spin_unlock(&robj->tobj.lock);
 	radeon_object_unreserve(robj);
+	radeon_hdp_flush(robj->rdev);
 	return r;
 }
 

commit 9d8401fcbb8c8a390b649b9c1b18dab113a918d6
Author: Dave Airlie <airlied@redhat.com>
Date:   Thu Oct 8 09:28:19 2009 +1000

    drm/radeon: use list_for_each_entry instead of list_for_each
    
    This is just a cleanup of the list macro usage.
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 73af463b7a59..1f056dadc5c2 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -400,11 +400,9 @@ void radeon_object_list_add_object(struct radeon_object_list *lobj,
 int radeon_object_list_reserve(struct list_head *head)
 {
 	struct radeon_object_list *lobj;
-	struct list_head *i;
 	int r;
 
-	list_for_each(i, head) {
-		lobj = list_entry(i, struct radeon_object_list, list);
+	list_for_each_entry(lobj, head, list){
 		if (!lobj->robj->pin_count) {
 			r = radeon_object_reserve(lobj->robj, true);
 			if (unlikely(r != 0)) {
@@ -420,13 +418,10 @@ int radeon_object_list_reserve(struct list_head *head)
 void radeon_object_list_unreserve(struct list_head *head)
 {
 	struct radeon_object_list *lobj;
-	struct list_head *i;
 
-	list_for_each(i, head) {
-		lobj = list_entry(i, struct radeon_object_list, list);
+	list_for_each_entry(lobj, head, list) {
 		if (!lobj->robj->pin_count) {
 			radeon_object_unreserve(lobj->robj);
-		} else {
 		}
 	}
 }
@@ -436,7 +431,6 @@ int radeon_object_list_validate(struct list_head *head, void *fence)
 	struct radeon_object_list *lobj;
 	struct radeon_object *robj;
 	struct radeon_fence *old_fence = NULL;
-	struct list_head *i;
 	int r;
 
 	r = radeon_object_list_reserve(head);
@@ -444,8 +438,7 @@ int radeon_object_list_validate(struct list_head *head, void *fence)
 		radeon_object_list_unreserve(head);
 		return r;
 	}
-	list_for_each(i, head) {
-		lobj = list_entry(i, struct radeon_object_list, list);
+	list_for_each_entry(lobj, head, list) {
 		robj = lobj->robj;
 		if (!robj->pin_count) {
 			if (lobj->wdomain) {
@@ -482,10 +475,8 @@ void radeon_object_list_unvalidate(struct list_head *head)
 {
 	struct radeon_object_list *lobj;
 	struct radeon_fence *old_fence = NULL;
-	struct list_head *i;
 
-	list_for_each(i, head) {
-		lobj = list_entry(i, struct radeon_object_list, list);
+	list_for_each_entry(lobj, head, list) {
 		old_fence = (struct radeon_fence *)lobj->robj->tobj.sync_obj;
 		lobj->robj->tobj.sync_obj = NULL;
 		if (old_fence) {

commit c88f9f0c91de55efaece6d9bd9ec920b90244776
Author: Michel Dänzer <daenzer@vmware.com>
Date:   Tue Sep 15 17:09:30 2009 +0200

    drm/radeon/kms: Use surfaces for scanout / cursor byte swapping on big endian.
    
    Signed-off-by: Michel Dänzer <daenzer@vmware.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 1500d5bc7af5..73af463b7a59 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -188,6 +188,7 @@ int radeon_object_kmap(struct radeon_object *robj, void **ptr)
 	if (ptr) {
 		*ptr = robj->kptr;
 	}
+	radeon_object_check_tiling(robj, 0, 0);
 	return 0;
 }
 
@@ -200,6 +201,7 @@ void radeon_object_kunmap(struct radeon_object *robj)
 	}
 	robj->kptr = NULL;
 	spin_unlock(&robj->tobj.lock);
+	radeon_object_check_tiling(robj, 0, 0);
 	ttm_bo_kunmap(&robj->kmap);
 }
 

commit a4d68279b44522a2b2374a6bd4861756bfad40fe
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Fri Sep 11 13:00:43 2009 +0200

    drm/radeon/kms: move mtrr range add and memory information
    
    Move mtrr range and memory information printing to radeon_object_init,
    this are memory information and initialization common to all GPU and
    they better fit in this function. Will also prevent code duplication
    with upcoming init path changes.
    
    airlied: fixed warning introduced
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index b85fb83d7ae8..1500d5bc7af5 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -369,6 +369,14 @@ void radeon_object_force_delete(struct radeon_device *rdev)
 
 int radeon_object_init(struct radeon_device *rdev)
 {
+	/* Add an MTRR for the VRAM */
+	rdev->mc.vram_mtrr = mtrr_add(rdev->mc.aper_base, rdev->mc.aper_size,
+			MTRR_TYPE_WRCOMB, 1);
+	DRM_INFO("Detected VRAM RAM=%lluM, BAR=%lluM\n",
+		rdev->mc.mc_vram_size >> 20,
+		(unsigned long long)rdev->mc.aper_size >> 20);
+	DRM_INFO("RAM width %dbits %cDR\n",
+			rdev->mc.vram_width, rdev->mc.vram_is_ddr ? 'D' : 'S');
 	return radeon_ttm_init(rdev);
 }
 

commit cefb87efc9aa0288849149484870d5ab989fbd59
Author: Dave Airlie <airlied@redhat.com>
Date:   Sun Aug 16 21:05:45 2009 +1000

    drm/radeon/kms: implement bo busy check + current domain
    
    This implements the busy ioctl along with a current domain check.
    returns 0 or -EBUSY
    puts the current domain no matter what the answer.
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index e98cae3bf4a6..b85fb83d7ae8 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -316,6 +316,25 @@ int radeon_object_wait(struct radeon_object *robj)
 	return r;
 }
 
+int radeon_object_busy_domain(struct radeon_object *robj, uint32_t *cur_placement)
+{
+	int r = 0;
+
+	r = radeon_object_reserve(robj, true);
+	if (unlikely(r != 0)) {
+		DRM_ERROR("radeon: failed to reserve object for waiting.\n");
+		return r;
+	}
+	spin_lock(&robj->tobj.lock);
+	*cur_placement = robj->tobj.mem.mem_type;
+	if (robj->tobj.sync_obj) {
+		r = ttm_bo_wait(&robj->tobj, true, true, true);
+	}
+	spin_unlock(&robj->tobj.lock);
+	radeon_object_unreserve(robj);
+	return r;
+}
+
 int radeon_object_evict_vram(struct radeon_device *rdev)
 {
 	if (rdev->flags & RADEON_IS_IGP) {

commit 985fe845aea9cd56fd351800302270444556e45a
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Wed Jul 29 18:55:53 2009 +0200

    drm/radeon/kms: Fix caching mode selection for GTT object
    
    GTT object can either be cached,uncached or wc just let core ttm
    pick the best mode according to how the bo driver and GTT memory
    type was initialized.
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index dd9ac2fed6d6..e98cae3bf4a6 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -106,7 +106,7 @@ static inline uint32_t radeon_object_flags_from_domain(uint32_t domain)
 		flags |= TTM_PL_FLAG_VRAM | TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED;
 	}
 	if (domain & RADEON_GEM_DOMAIN_GTT) {
-		flags |= TTM_PL_FLAG_TT | TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED;
+		flags |= TTM_PL_FLAG_TT | TTM_PL_MASK_CACHING;
 	}
 	if (domain & RADEON_GEM_DOMAIN_CPU) {
 		flags |= TTM_PL_FLAG_SYSTEM | TTM_PL_MASK_CACHING;

commit 3b170c3b2e688665fbc2845ba5bb4304bf38a119
Author: Dave Airlie <airlied@redhat.com>
Date:   Fri Jul 24 13:47:45 2009 +1000

    drm/radeon/kms: allow interruptible waits for objects.
    
    Blocking here isn't something the X server mouse appreciates,
    avoid the block and let userspace retry the waits.
    
    libdrm_radeon userspace library is also expecting EBUSY not ERESTART
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 81573c3a9b43..dd9ac2fed6d6 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -309,7 +309,7 @@ int radeon_object_wait(struct radeon_object *robj)
 	}
 	spin_lock(&robj->tobj.lock);
 	if (robj->tobj.sync_obj) {
-		r = ttm_bo_wait(&robj->tobj, true, false, false);
+		r = ttm_bo_wait(&robj->tobj, true, true, false);
 	}
 	spin_unlock(&robj->tobj.lock);
 	radeon_object_unreserve(robj);

commit 664f86590295217b2319edf88830e87b800f6c4a
Author: Michel Dänzer <daenzer@vmware.com>
Date:   Tue Jul 28 12:30:57 2009 +0200

    drm/radeon: Pay more attention to object placement requested by userspace.
    
    Previously we were basically always setting the GTT and VRAM flags regardless of
    what userspace requested.
    
    Signed-off-by: Michel Dänzer <daenzer@vmware.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 3961a44c5dce..81573c3a9b43 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -103,16 +103,16 @@ static inline uint32_t radeon_object_flags_from_domain(uint32_t domain)
 {
 	uint32_t flags = 0;
 	if (domain & RADEON_GEM_DOMAIN_VRAM) {
-		flags |= TTM_PL_FLAG_VRAM;
+		flags |= TTM_PL_FLAG_VRAM | TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED;
 	}
 	if (domain & RADEON_GEM_DOMAIN_GTT) {
-		flags |= TTM_PL_FLAG_TT;
+		flags |= TTM_PL_FLAG_TT | TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED;
 	}
 	if (domain & RADEON_GEM_DOMAIN_CPU) {
-		flags |= TTM_PL_FLAG_SYSTEM;
+		flags |= TTM_PL_FLAG_SYSTEM | TTM_PL_MASK_CACHING;
 	}
 	if (!flags) {
-		flags |= TTM_PL_FLAG_SYSTEM;
+		flags |= TTM_PL_FLAG_SYSTEM | TTM_PL_MASK_CACHING;
 	}
 	return flags;
 }
@@ -408,7 +408,6 @@ int radeon_object_list_validate(struct list_head *head, void *fence)
 	struct radeon_object *robj;
 	struct radeon_fence *old_fence = NULL;
 	struct list_head *i;
-	uint32_t flags;
 	int r;
 
 	r = radeon_object_list_reserve(head);
@@ -419,16 +418,14 @@ int radeon_object_list_validate(struct list_head *head, void *fence)
 	list_for_each(i, head) {
 		lobj = list_entry(i, struct radeon_object_list, list);
 		robj = lobj->robj;
-		if (lobj->wdomain) {
-			flags = radeon_object_flags_from_domain(lobj->wdomain);
-			flags |= TTM_PL_FLAG_TT;
-		} else {
-			flags = radeon_object_flags_from_domain(lobj->rdomain);
-			flags |= TTM_PL_FLAG_TT;
-			flags |= TTM_PL_FLAG_VRAM;
-		}
 		if (!robj->pin_count) {
-			robj->tobj.proposed_placement = flags | TTM_PL_MASK_CACHING;
+			if (lobj->wdomain) {
+				robj->tobj.proposed_placement =
+					radeon_object_flags_from_domain(lobj->wdomain);
+			} else {
+				robj->tobj.proposed_placement =
+					radeon_object_flags_from_domain(lobj->rdomain);
+			}
 			r = ttm_buffer_object_validate(&robj->tobj,
 						       robj->tobj.proposed_placement,
 						       true, false);

commit e46074effd5510e7a8fe34b93828d98a50835da2
Author: Michel Dänzer <daenzer@vmware.com>
Date:   Tue Jul 28 12:30:55 2009 +0200

    drm/radeon: Don't unreserve twice on failure to validate.
    
    This is done later in radeon_object_list_unvalidate(). Doing it twice triggers
    a BUG in TTM, rendering X on KMS unusable until reboot.
    
    Signed-off-by: Michel Dänzer <daenzer@vmware.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index d5b1fd562d88..3961a44c5dce 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -433,7 +433,6 @@ int radeon_object_list_validate(struct list_head *head, void *fence)
 						       robj->tobj.proposed_placement,
 						       true, false);
 			if (unlikely(r)) {
-				radeon_object_list_unreserve(head);
 				DRM_ERROR("radeon: failed to validate.\n");
 				return r;
 			}

commit e024e11070a0a0dc7163ce1ec2da354a638bdbed
Author: Dave Airlie <airlied@redhat.com>
Date:   Wed Jun 24 09:48:08 2009 +1000

    drm/radeon/kms: add initial colortiling support.
    
    This adds new set/get tiling interfaces where the pitch
    and macro/micro tiling enables can be set. Along with
    a flag to decide if this object should have a surface when mapped.
    
    The only thing we need to allocate with a mapped surface should be
    the frontbuffer. Note rotate scanout shouldn't require one, and
    back/depth shouldn't either, though mesa needs some fixes.
    
    It fixes the TTM interfaces along Thomas's suggestions, and I've tested
    the surface stealing code with two X servers and not seen any lockdep issues.
    
    I've stopped tiling the fbcon frontbuffer, as I don't see there being
    any advantage other than testing, I've left the testing commands in there,
    just flip the fb_tiled to true in radeon_fb.c
    
    Open: Can we integrate endian swapping in with this?
    
    Future features:
    texture tiling - need to relocate texture registers TXOFFSET* with tiling info.
    
    This also merges Michel's cleanup surfaces regs at init time patch
    even though it makes sense on its own, this patch really relies on it.
    
    Some PowerMac firmwares set up a tiling surface at the beginning of VRAM
    which messes us up otherwise.
    that patch is:
    Signed-off-by: Michel Dänzer <daenzer@vmware.com>
    
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index bac0d06c52ac..d5b1fd562d88 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -44,6 +44,9 @@ struct radeon_object {
 	uint64_t			gpu_addr;
 	void				*kptr;
 	bool				is_iomem;
+	uint32_t			tiling_flags;
+	uint32_t			pitch;
+	int				surface_reg;
 };
 
 int radeon_ttm_init(struct radeon_device *rdev);
@@ -70,6 +73,7 @@ static void radeon_ttm_object_object_destroy(struct ttm_buffer_object *tobj)
 
 	robj = container_of(tobj, struct radeon_object, tobj);
 	list_del_init(&robj->list);
+	radeon_object_clear_surface_reg(robj);
 	kfree(robj);
 }
 
@@ -141,6 +145,7 @@ int radeon_object_create(struct radeon_device *rdev,
 	}
 	robj->rdev = rdev;
 	robj->gobj = gobj;
+	robj->surface_reg = -1;
 	INIT_LIST_HEAD(&robj->list);
 
 	flags = radeon_object_flags_from_domain(domain);
@@ -435,6 +440,7 @@ int radeon_object_list_validate(struct list_head *head, void *fence)
 			radeon_object_gpu_addr(robj);
 		}
 		lobj->gpu_offset = robj->gpu_addr;
+		lobj->tiling_flags = robj->tiling_flags;
 		if (fence) {
 			old_fence = (struct radeon_fence *)robj->tobj.sync_obj;
 			robj->tobj.sync_obj = radeon_fence_ref(fence);
@@ -479,3 +485,127 @@ unsigned long radeon_object_size(struct radeon_object *robj)
 {
 	return robj->tobj.num_pages << PAGE_SHIFT;
 }
+
+int radeon_object_get_surface_reg(struct radeon_object *robj)
+{
+	struct radeon_device *rdev = robj->rdev;
+	struct radeon_surface_reg *reg;
+	struct radeon_object *old_object;
+	int steal;
+	int i;
+
+	if (!robj->tiling_flags)
+		return 0;
+
+	if (robj->surface_reg >= 0) {
+		reg = &rdev->surface_regs[robj->surface_reg];
+		i = robj->surface_reg;
+		goto out;
+	}
+
+	steal = -1;
+	for (i = 0; i < RADEON_GEM_MAX_SURFACES; i++) {
+
+		reg = &rdev->surface_regs[i];
+		if (!reg->robj)
+			break;
+
+		old_object = reg->robj;
+		if (old_object->pin_count == 0)
+			steal = i;
+	}
+
+	/* if we are all out */
+	if (i == RADEON_GEM_MAX_SURFACES) {
+		if (steal == -1)
+			return -ENOMEM;
+		/* find someone with a surface reg and nuke their BO */
+		reg = &rdev->surface_regs[steal];
+		old_object = reg->robj;
+		/* blow away the mapping */
+		DRM_DEBUG("stealing surface reg %d from %p\n", steal, old_object);
+		ttm_bo_unmap_virtual(&old_object->tobj);
+		old_object->surface_reg = -1;
+		i = steal;
+	}
+
+	robj->surface_reg = i;
+	reg->robj = robj;
+
+out:
+	radeon_set_surface_reg(rdev, i, robj->tiling_flags, robj->pitch,
+			       robj->tobj.mem.mm_node->start << PAGE_SHIFT,
+			       robj->tobj.num_pages << PAGE_SHIFT);
+	return 0;
+}
+
+void radeon_object_clear_surface_reg(struct radeon_object *robj)
+{
+	struct radeon_device *rdev = robj->rdev;
+	struct radeon_surface_reg *reg;
+
+	if (robj->surface_reg == -1)
+		return;
+
+	reg = &rdev->surface_regs[robj->surface_reg];
+	radeon_clear_surface_reg(rdev, robj->surface_reg);
+
+	reg->robj = NULL;
+	robj->surface_reg = -1;
+}
+
+void radeon_object_set_tiling_flags(struct radeon_object *robj,
+				    uint32_t tiling_flags, uint32_t pitch)
+{
+	robj->tiling_flags = tiling_flags;
+	robj->pitch = pitch;
+}
+
+void radeon_object_get_tiling_flags(struct radeon_object *robj,
+				    uint32_t *tiling_flags,
+				    uint32_t *pitch)
+{
+	if (tiling_flags)
+		*tiling_flags = robj->tiling_flags;
+	if (pitch)
+		*pitch = robj->pitch;
+}
+
+int radeon_object_check_tiling(struct radeon_object *robj, bool has_moved,
+			       bool force_drop)
+{
+	if (!(robj->tiling_flags & RADEON_TILING_SURFACE))
+		return 0;
+
+	if (force_drop) {
+		radeon_object_clear_surface_reg(robj);
+		return 0;
+	}
+
+	if (robj->tobj.mem.mem_type != TTM_PL_VRAM) {
+		if (!has_moved)
+			return 0;
+
+		if (robj->surface_reg >= 0)
+			radeon_object_clear_surface_reg(robj);
+		return 0;
+	}
+
+	if ((robj->surface_reg >= 0) && !has_moved)
+		return 0;
+
+	return radeon_object_get_surface_reg(robj);
+}
+
+void radeon_bo_move_notify(struct ttm_buffer_object *bo,
+			  struct ttm_mem_reg *mem)
+{
+	struct radeon_object *robj = container_of(bo, struct radeon_object, tobj);
+	radeon_object_check_tiling(robj, 0, 1);
+}
+
+void radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo)
+{
+	struct radeon_object *robj = container_of(bo, struct radeon_object, tobj);
+	radeon_object_check_tiling(robj, 0, 0);
+}

commit f92e93eb5f4d56d73215f089580d53597bacd468
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Mon Jun 22 18:15:58 2009 +0200

    drm/radeon: fix radeon kms framebuffer device
    
    smem.start is a physical address which kernel can remap to access
    video memory of the fb buffer. We now pin the fb buffer into vram
    by doing so we are loosing vram but fbdev need to be reworked to
    allow change in framebuffer address.
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@linux.ie>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index 983e8df5e000..bac0d06c52ac 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -223,7 +223,6 @@ int radeon_object_pin(struct radeon_object *robj, uint32_t domain,
 {
 	uint32_t flags;
 	uint32_t tmp;
-	void *fbptr;
 	int r;
 
 	flags = radeon_object_flags_from_domain(domain);
@@ -242,10 +241,6 @@ int radeon_object_pin(struct radeon_object *robj, uint32_t domain,
 		DRM_ERROR("radeon: failed to reserve object for pinning it.\n");
 		return r;
 	}
-	if (robj->rdev->fbdev_robj == robj) {
-		mutex_lock(&robj->rdev->fbdev_info->lock);
-		radeon_object_kunmap(robj);
-	}
 	tmp = robj->tobj.mem.placement;
 	ttm_flag_masked(&tmp, flags, TTM_PL_MASK_MEM);
 	robj->tobj.proposed_placement = tmp | TTM_PL_FLAG_NO_EVICT | TTM_PL_MASK_CACHING;
@@ -261,23 +256,12 @@ int radeon_object_pin(struct radeon_object *robj, uint32_t domain,
 		DRM_ERROR("radeon: failed to pin object.\n");
 	}
 	radeon_object_unreserve(robj);
-	if (robj->rdev->fbdev_robj == robj) {
-		if (!r) {
-			r = radeon_object_kmap(robj, &fbptr);
-		}
-		if (!r) {
-			robj->rdev->fbdev_info->screen_base = fbptr;
-			robj->rdev->fbdev_info->fix.smem_start = (unsigned long)fbptr;
-		}
-		mutex_unlock(&robj->rdev->fbdev_info->lock);
-	}
 	return r;
 }
 
 void radeon_object_unpin(struct radeon_object *robj)
 {
 	uint32_t flags;
-	void *fbptr;
 	int r;
 
 	spin_lock(&robj->tobj.lock);
@@ -297,10 +281,6 @@ void radeon_object_unpin(struct radeon_object *robj)
 		DRM_ERROR("radeon: failed to reserve object for unpinning it.\n");
 		return;
 	}
-	if (robj->rdev->fbdev_robj == robj) {
-		mutex_lock(&robj->rdev->fbdev_info->lock);
-		radeon_object_kunmap(robj);
-	}
 	flags = robj->tobj.mem.placement;
 	robj->tobj.proposed_placement = flags & ~TTM_PL_FLAG_NO_EVICT;
 	r = ttm_buffer_object_validate(&robj->tobj,
@@ -310,16 +290,6 @@ void radeon_object_unpin(struct radeon_object *robj)
 		DRM_ERROR("radeon: failed to unpin buffer.\n");
 	}
 	radeon_object_unreserve(robj);
-	if (robj->rdev->fbdev_robj == robj) {
-		if (!r) {
-			r = radeon_object_kmap(robj, &fbptr);
-		}
-		if (!r) {
-			robj->rdev->fbdev_info->screen_base = fbptr;
-			robj->rdev->fbdev_info->fix.smem_start = (unsigned long)fbptr;
-		}
-		mutex_unlock(&robj->rdev->fbdev_info->lock);
-	}
 }
 
 int radeon_object_wait(struct radeon_object *robj)

commit 771fe6b912fca54f03e8a72eb63058b582775362
Author: Jerome Glisse <jglisse@redhat.com>
Date:   Fri Jun 5 14:42:42 2009 +0200

    drm/radeon: introduce kernel modesetting for radeon hardware
    
    Add kernel modesetting support to radeon driver, use the ttm memory
    manager to manage memory and DRM/GEM to provide userspace API.
    In order to avoid backward compatibility issue and to allow clean
    design and code the radeon kernel modesetting use different code path
    than old radeon/drm driver.
    
    When kernel modesetting is enabled the IOCTL of radeon/drm
    driver are considered as invalid and an error message is printed
    in the log and they return failure.
    
    KMS enabled userspace will use new API to talk with the radeon/drm
    driver. The new API provide functions to create/destroy/share/mmap
    buffer object which are then managed by the kernel memory manager
    (here TTM). In order to submit command to the GPU the userspace
    provide a buffer holding the command stream, along this buffer
    userspace have to provide a list of buffer object used by the
    command stream. The kernel radeon driver will then place buffer
    in GPU accessible memory and will update command stream to reflect
    the position of the different buffers.
    
    The kernel will also perform security check on command stream
    provided by the user, we want to catch and forbid any illegal use
    of the GPU such as DMA into random system memory or into memory
    not owned by the process supplying the command stream. This part
    of the code is still incomplete and this why we propose that patch
    as a staging driver addition, future security might forbid current
    experimental userspace to run.
    
    This code support the following hardware : R1XX,R2XX,R3XX,R4XX,R5XX
    (radeon up to X1950). Works is underway to provide support for R6XX,
    R7XX and newer hardware (radeon from HD2XXX to HD4XXX).
    
    Authors:
        Jerome Glisse <jglisse@redhat.com>
        Dave Airlie <airlied@redhat.com>
        Alex Deucher <alexdeucher@gmail.com>
    
    Signed-off-by: Jerome Glisse <jglisse@redhat.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    Signed-off-by: Alex Deucher <alexdeucher@gmail.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>

diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
new file mode 100644
index 000000000000..983e8df5e000
--- /dev/null
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -0,0 +1,511 @@
+/*
+ * Copyright 2009 Jerome Glisse.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sub license, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDERS, AUTHORS AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM,
+ * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
+ * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
+ * USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ */
+/*
+ * Authors:
+ *    Jerome Glisse <glisse@freedesktop.org>
+ *    Thomas Hellstrom <thomas-at-tungstengraphics-dot-com>
+ *    Dave Airlie
+ */
+#include <linux/list.h>
+#include <drm/drmP.h>
+#include "radeon_drm.h"
+#include "radeon.h"
+
+struct radeon_object {
+	struct ttm_buffer_object	tobj;
+	struct list_head		list;
+	struct radeon_device		*rdev;
+	struct drm_gem_object		*gobj;
+	struct ttm_bo_kmap_obj		kmap;
+	unsigned			pin_count;
+	uint64_t			gpu_addr;
+	void				*kptr;
+	bool				is_iomem;
+};
+
+int radeon_ttm_init(struct radeon_device *rdev);
+void radeon_ttm_fini(struct radeon_device *rdev);
+
+/*
+ * To exclude mutual BO access we rely on bo_reserve exclusion, as all
+ * function are calling it.
+ */
+
+static int radeon_object_reserve(struct radeon_object *robj, bool interruptible)
+{
+	return ttm_bo_reserve(&robj->tobj, interruptible, false, false, 0);
+}
+
+static void radeon_object_unreserve(struct radeon_object *robj)
+{
+	ttm_bo_unreserve(&robj->tobj);
+}
+
+static void radeon_ttm_object_object_destroy(struct ttm_buffer_object *tobj)
+{
+	struct radeon_object *robj;
+
+	robj = container_of(tobj, struct radeon_object, tobj);
+	list_del_init(&robj->list);
+	kfree(robj);
+}
+
+static inline void radeon_object_gpu_addr(struct radeon_object *robj)
+{
+	/* Default gpu address */
+	robj->gpu_addr = 0xFFFFFFFFFFFFFFFFULL;
+	if (robj->tobj.mem.mm_node == NULL) {
+		return;
+	}
+	robj->gpu_addr = ((u64)robj->tobj.mem.mm_node->start) << PAGE_SHIFT;
+	switch (robj->tobj.mem.mem_type) {
+	case TTM_PL_VRAM:
+		robj->gpu_addr += (u64)robj->rdev->mc.vram_location;
+		break;
+	case TTM_PL_TT:
+		robj->gpu_addr += (u64)robj->rdev->mc.gtt_location;
+		break;
+	default:
+		DRM_ERROR("Unknown placement %d\n", robj->tobj.mem.mem_type);
+		robj->gpu_addr = 0xFFFFFFFFFFFFFFFFULL;
+		return;
+	}
+}
+
+static inline uint32_t radeon_object_flags_from_domain(uint32_t domain)
+{
+	uint32_t flags = 0;
+	if (domain & RADEON_GEM_DOMAIN_VRAM) {
+		flags |= TTM_PL_FLAG_VRAM;
+	}
+	if (domain & RADEON_GEM_DOMAIN_GTT) {
+		flags |= TTM_PL_FLAG_TT;
+	}
+	if (domain & RADEON_GEM_DOMAIN_CPU) {
+		flags |= TTM_PL_FLAG_SYSTEM;
+	}
+	if (!flags) {
+		flags |= TTM_PL_FLAG_SYSTEM;
+	}
+	return flags;
+}
+
+int radeon_object_create(struct radeon_device *rdev,
+			 struct drm_gem_object *gobj,
+			 unsigned long size,
+			 bool kernel,
+			 uint32_t domain,
+			 bool interruptible,
+			 struct radeon_object **robj_ptr)
+{
+	struct radeon_object *robj;
+	enum ttm_bo_type type;
+	uint32_t flags;
+	int r;
+
+	if (unlikely(rdev->mman.bdev.dev_mapping == NULL)) {
+		rdev->mman.bdev.dev_mapping = rdev->ddev->dev_mapping;
+	}
+	if (kernel) {
+		type = ttm_bo_type_kernel;
+	} else {
+		type = ttm_bo_type_device;
+	}
+	*robj_ptr = NULL;
+	robj = kzalloc(sizeof(struct radeon_object), GFP_KERNEL);
+	if (robj == NULL) {
+		return -ENOMEM;
+	}
+	robj->rdev = rdev;
+	robj->gobj = gobj;
+	INIT_LIST_HEAD(&robj->list);
+
+	flags = radeon_object_flags_from_domain(domain);
+	r = ttm_buffer_object_init(&rdev->mman.bdev, &robj->tobj, size, type, flags,
+				   0, 0, false, NULL, size,
+				   &radeon_ttm_object_object_destroy);
+	if (unlikely(r != 0)) {
+		/* ttm call radeon_ttm_object_object_destroy if error happen */
+		DRM_ERROR("Failed to allocate TTM object (%ld, 0x%08X, %u)\n",
+			  size, flags, 0);
+		return r;
+	}
+	*robj_ptr = robj;
+	if (gobj) {
+		list_add_tail(&robj->list, &rdev->gem.objects);
+	}
+	return 0;
+}
+
+int radeon_object_kmap(struct radeon_object *robj, void **ptr)
+{
+	int r;
+
+	spin_lock(&robj->tobj.lock);
+	if (robj->kptr) {
+		if (ptr) {
+			*ptr = robj->kptr;
+		}
+		spin_unlock(&robj->tobj.lock);
+		return 0;
+	}
+	spin_unlock(&robj->tobj.lock);
+	r = ttm_bo_kmap(&robj->tobj, 0, robj->tobj.num_pages, &robj->kmap);
+	if (r) {
+		return r;
+	}
+	spin_lock(&robj->tobj.lock);
+	robj->kptr = ttm_kmap_obj_virtual(&robj->kmap, &robj->is_iomem);
+	spin_unlock(&robj->tobj.lock);
+	if (ptr) {
+		*ptr = robj->kptr;
+	}
+	return 0;
+}
+
+void radeon_object_kunmap(struct radeon_object *robj)
+{
+	spin_lock(&robj->tobj.lock);
+	if (robj->kptr == NULL) {
+		spin_unlock(&robj->tobj.lock);
+		return;
+	}
+	robj->kptr = NULL;
+	spin_unlock(&robj->tobj.lock);
+	ttm_bo_kunmap(&robj->kmap);
+}
+
+void radeon_object_unref(struct radeon_object **robj)
+{
+	struct ttm_buffer_object *tobj;
+
+	if ((*robj) == NULL) {
+		return;
+	}
+	tobj = &((*robj)->tobj);
+	ttm_bo_unref(&tobj);
+	if (tobj == NULL) {
+		*robj = NULL;
+	}
+}
+
+int radeon_object_mmap(struct radeon_object *robj, uint64_t *offset)
+{
+	*offset = robj->tobj.addr_space_offset;
+	return 0;
+}
+
+int radeon_object_pin(struct radeon_object *robj, uint32_t domain,
+		      uint64_t *gpu_addr)
+{
+	uint32_t flags;
+	uint32_t tmp;
+	void *fbptr;
+	int r;
+
+	flags = radeon_object_flags_from_domain(domain);
+	spin_lock(&robj->tobj.lock);
+	if (robj->pin_count) {
+		robj->pin_count++;
+		if (gpu_addr != NULL) {
+			*gpu_addr = robj->gpu_addr;
+		}
+		spin_unlock(&robj->tobj.lock);
+		return 0;
+	}
+	spin_unlock(&robj->tobj.lock);
+	r = radeon_object_reserve(robj, false);
+	if (unlikely(r != 0)) {
+		DRM_ERROR("radeon: failed to reserve object for pinning it.\n");
+		return r;
+	}
+	if (robj->rdev->fbdev_robj == robj) {
+		mutex_lock(&robj->rdev->fbdev_info->lock);
+		radeon_object_kunmap(robj);
+	}
+	tmp = robj->tobj.mem.placement;
+	ttm_flag_masked(&tmp, flags, TTM_PL_MASK_MEM);
+	robj->tobj.proposed_placement = tmp | TTM_PL_FLAG_NO_EVICT | TTM_PL_MASK_CACHING;
+	r = ttm_buffer_object_validate(&robj->tobj,
+				       robj->tobj.proposed_placement,
+				       false, false);
+	radeon_object_gpu_addr(robj);
+	if (gpu_addr != NULL) {
+		*gpu_addr = robj->gpu_addr;
+	}
+	robj->pin_count = 1;
+	if (unlikely(r != 0)) {
+		DRM_ERROR("radeon: failed to pin object.\n");
+	}
+	radeon_object_unreserve(robj);
+	if (robj->rdev->fbdev_robj == robj) {
+		if (!r) {
+			r = radeon_object_kmap(robj, &fbptr);
+		}
+		if (!r) {
+			robj->rdev->fbdev_info->screen_base = fbptr;
+			robj->rdev->fbdev_info->fix.smem_start = (unsigned long)fbptr;
+		}
+		mutex_unlock(&robj->rdev->fbdev_info->lock);
+	}
+	return r;
+}
+
+void radeon_object_unpin(struct radeon_object *robj)
+{
+	uint32_t flags;
+	void *fbptr;
+	int r;
+
+	spin_lock(&robj->tobj.lock);
+	if (!robj->pin_count) {
+		spin_unlock(&robj->tobj.lock);
+		printk(KERN_WARNING "Unpin not necessary for %p !\n", robj);
+		return;
+	}
+	robj->pin_count--;
+	if (robj->pin_count) {
+		spin_unlock(&robj->tobj.lock);
+		return;
+	}
+	spin_unlock(&robj->tobj.lock);
+	r = radeon_object_reserve(robj, false);
+	if (unlikely(r != 0)) {
+		DRM_ERROR("radeon: failed to reserve object for unpinning it.\n");
+		return;
+	}
+	if (robj->rdev->fbdev_robj == robj) {
+		mutex_lock(&robj->rdev->fbdev_info->lock);
+		radeon_object_kunmap(robj);
+	}
+	flags = robj->tobj.mem.placement;
+	robj->tobj.proposed_placement = flags & ~TTM_PL_FLAG_NO_EVICT;
+	r = ttm_buffer_object_validate(&robj->tobj,
+				       robj->tobj.proposed_placement,
+				       false, false);
+	if (unlikely(r != 0)) {
+		DRM_ERROR("radeon: failed to unpin buffer.\n");
+	}
+	radeon_object_unreserve(robj);
+	if (robj->rdev->fbdev_robj == robj) {
+		if (!r) {
+			r = radeon_object_kmap(robj, &fbptr);
+		}
+		if (!r) {
+			robj->rdev->fbdev_info->screen_base = fbptr;
+			robj->rdev->fbdev_info->fix.smem_start = (unsigned long)fbptr;
+		}
+		mutex_unlock(&robj->rdev->fbdev_info->lock);
+	}
+}
+
+int radeon_object_wait(struct radeon_object *robj)
+{
+	int r = 0;
+
+	/* FIXME: should use block reservation instead */
+	r = radeon_object_reserve(robj, true);
+	if (unlikely(r != 0)) {
+		DRM_ERROR("radeon: failed to reserve object for waiting.\n");
+		return r;
+	}
+	spin_lock(&robj->tobj.lock);
+	if (robj->tobj.sync_obj) {
+		r = ttm_bo_wait(&robj->tobj, true, false, false);
+	}
+	spin_unlock(&robj->tobj.lock);
+	radeon_object_unreserve(robj);
+	return r;
+}
+
+int radeon_object_evict_vram(struct radeon_device *rdev)
+{
+	if (rdev->flags & RADEON_IS_IGP) {
+		/* Useless to evict on IGP chips */
+		return 0;
+	}
+	return ttm_bo_evict_mm(&rdev->mman.bdev, TTM_PL_VRAM);
+}
+
+void radeon_object_force_delete(struct radeon_device *rdev)
+{
+	struct radeon_object *robj, *n;
+	struct drm_gem_object *gobj;
+
+	if (list_empty(&rdev->gem.objects)) {
+		return;
+	}
+	DRM_ERROR("Userspace still has active objects !\n");
+	list_for_each_entry_safe(robj, n, &rdev->gem.objects, list) {
+		mutex_lock(&rdev->ddev->struct_mutex);
+		gobj = robj->gobj;
+		DRM_ERROR("Force free for (%p,%p,%lu,%lu)\n",
+			  gobj, robj, (unsigned long)gobj->size,
+			  *((unsigned long *)&gobj->refcount));
+		list_del_init(&robj->list);
+		radeon_object_unref(&robj);
+		gobj->driver_private = NULL;
+		drm_gem_object_unreference(gobj);
+		mutex_unlock(&rdev->ddev->struct_mutex);
+	}
+}
+
+int radeon_object_init(struct radeon_device *rdev)
+{
+	return radeon_ttm_init(rdev);
+}
+
+void radeon_object_fini(struct radeon_device *rdev)
+{
+	radeon_ttm_fini(rdev);
+}
+
+void radeon_object_list_add_object(struct radeon_object_list *lobj,
+				   struct list_head *head)
+{
+	if (lobj->wdomain) {
+		list_add(&lobj->list, head);
+	} else {
+		list_add_tail(&lobj->list, head);
+	}
+}
+
+int radeon_object_list_reserve(struct list_head *head)
+{
+	struct radeon_object_list *lobj;
+	struct list_head *i;
+	int r;
+
+	list_for_each(i, head) {
+		lobj = list_entry(i, struct radeon_object_list, list);
+		if (!lobj->robj->pin_count) {
+			r = radeon_object_reserve(lobj->robj, true);
+			if (unlikely(r != 0)) {
+				DRM_ERROR("radeon: failed to reserve object.\n");
+				return r;
+			}
+		} else {
+		}
+	}
+	return 0;
+}
+
+void radeon_object_list_unreserve(struct list_head *head)
+{
+	struct radeon_object_list *lobj;
+	struct list_head *i;
+
+	list_for_each(i, head) {
+		lobj = list_entry(i, struct radeon_object_list, list);
+		if (!lobj->robj->pin_count) {
+			radeon_object_unreserve(lobj->robj);
+		} else {
+		}
+	}
+}
+
+int radeon_object_list_validate(struct list_head *head, void *fence)
+{
+	struct radeon_object_list *lobj;
+	struct radeon_object *robj;
+	struct radeon_fence *old_fence = NULL;
+	struct list_head *i;
+	uint32_t flags;
+	int r;
+
+	r = radeon_object_list_reserve(head);
+	if (unlikely(r != 0)) {
+		radeon_object_list_unreserve(head);
+		return r;
+	}
+	list_for_each(i, head) {
+		lobj = list_entry(i, struct radeon_object_list, list);
+		robj = lobj->robj;
+		if (lobj->wdomain) {
+			flags = radeon_object_flags_from_domain(lobj->wdomain);
+			flags |= TTM_PL_FLAG_TT;
+		} else {
+			flags = radeon_object_flags_from_domain(lobj->rdomain);
+			flags |= TTM_PL_FLAG_TT;
+			flags |= TTM_PL_FLAG_VRAM;
+		}
+		if (!robj->pin_count) {
+			robj->tobj.proposed_placement = flags | TTM_PL_MASK_CACHING;
+			r = ttm_buffer_object_validate(&robj->tobj,
+						       robj->tobj.proposed_placement,
+						       true, false);
+			if (unlikely(r)) {
+				radeon_object_list_unreserve(head);
+				DRM_ERROR("radeon: failed to validate.\n");
+				return r;
+			}
+			radeon_object_gpu_addr(robj);
+		}
+		lobj->gpu_offset = robj->gpu_addr;
+		if (fence) {
+			old_fence = (struct radeon_fence *)robj->tobj.sync_obj;
+			robj->tobj.sync_obj = radeon_fence_ref(fence);
+			robj->tobj.sync_obj_arg = NULL;
+		}
+		if (old_fence) {
+			radeon_fence_unref(&old_fence);
+		}
+	}
+	return 0;
+}
+
+void radeon_object_list_unvalidate(struct list_head *head)
+{
+	struct radeon_object_list *lobj;
+	struct radeon_fence *old_fence = NULL;
+	struct list_head *i;
+
+	list_for_each(i, head) {
+		lobj = list_entry(i, struct radeon_object_list, list);
+		old_fence = (struct radeon_fence *)lobj->robj->tobj.sync_obj;
+		lobj->robj->tobj.sync_obj = NULL;
+		if (old_fence) {
+			radeon_fence_unref(&old_fence);
+		}
+	}
+	radeon_object_list_unreserve(head);
+}
+
+void radeon_object_list_clean(struct list_head *head)
+{
+	radeon_object_list_unreserve(head);
+}
+
+int radeon_object_fbdev_mmap(struct radeon_object *robj,
+			     struct vm_area_struct *vma)
+{
+	return ttm_fbdev_mmap(vma, &robj->tobj);
+}
+
+unsigned long radeon_object_size(struct radeon_object *robj)
+{
+	return robj->tobj.num_pages << PAGE_SHIFT;
+}
