commit 69088a049488171bc05394799b048c8536e7dbab
Author: Bodo Stroesser <bstroesser@ts.fujitsu.com>
Date:   Mon Apr 27 17:08:22 2020 +0200

    scsi: target: Make transport_flags per device
    
    pgr_support and alua_support device attributes show the inverted value of
    the transport_flags:
    
     * TRANSPORT_FLAG_PASSTHROUGH_PGR
     * TRANSPORT_FLAG_PASSTHROUGH_ALUA
    
    These attributes are per device, while the flags are per backend. Rename
    the transport_flags in backend/transport to transport_flags_default and use
    this value to initialize the new transport_flags field in the se_device
    structure.
    
    Now data and attribute both are per se_device.
    
    Link: https://lore.kernel.org/r/20200427150823.15350-4-bstroesser@ts.fujitsu.com
    Reviewed-by: Mike Christie <mchristi@redhat.com>
    Signed-off-by: Bodo Stroesser <bstroesser@ts.fujitsu.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index d24e0a3ba3ff..62aa5fa63ac0 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -582,8 +582,7 @@ int core_tpg_add_lun(
 	if (ret)
 		goto out_kill_ref;
 
-	if (!(dev->transport->transport_flags &
-	     TRANSPORT_FLAG_PASSTHROUGH_ALUA) &&
+	if (!(dev->transport_flags & TRANSPORT_FLAG_PASSTHROUGH_ALUA) &&
 	    !(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))
 		target_attach_tg_pt_gp(lun, dev->t10_alua.default_tg_pt_gp);
 

commit 27f722ccbe1563629275bb7ee30c0e307f5837a2
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Mon Sep 30 16:22:24 2019 -0700

    scsi: target: Remove tpg_list and se_portal_group.se_tpg_node
    
    Maintaining tpg_list without ever iterating over it is not useful. Hence
    remove tpg_list. This patch does not change the behavior of the SCSI target
    code.
    
    Cc: Mike Christie <mchristie@redhat.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.de>
    Cc: Nicholas Bellinger <nab@linux-iscsi.org>
    Link: https://lore.kernel.org/r/20190930232224.58980-1-bvanassche@acm.org
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Mike Christie <mchristi@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index e5a71addbb06..d24e0a3ba3ff 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -32,9 +32,6 @@
 
 extern struct se_device *g_lun0_dev;
 
-static DEFINE_SPINLOCK(tpg_lock);
-static LIST_HEAD(tpg_list);
-
 /*	__core_tpg_get_initiator_node_acl():
  *
  *	mutex_lock(&tpg->acl_node_mutex); must be held when calling
@@ -475,7 +472,6 @@ int core_tpg_register(
 	se_tpg->se_tpg_wwn = se_wwn;
 	atomic_set(&se_tpg->tpg_pr_ref_count, 0);
 	INIT_LIST_HEAD(&se_tpg->acl_node_list);
-	INIT_LIST_HEAD(&se_tpg->se_tpg_node);
 	INIT_LIST_HEAD(&se_tpg->tpg_sess_list);
 	spin_lock_init(&se_tpg->session_lock);
 	mutex_init(&se_tpg->tpg_lun_mutex);
@@ -494,10 +490,6 @@ int core_tpg_register(
 		}
 	}
 
-	spin_lock_bh(&tpg_lock);
-	list_add_tail(&se_tpg->se_tpg_node, &tpg_list);
-	spin_unlock_bh(&tpg_lock);
-
 	pr_debug("TARGET_CORE[%s]: Allocated portal_group for endpoint: %s, "
 		 "Proto: %d, Portal Tag: %u\n", se_tpg->se_tpg_tfo->fabric_name,
 		se_tpg->se_tpg_tfo->tpg_get_wwn(se_tpg) ?
@@ -519,10 +511,6 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 		tfo->tpg_get_wwn(se_tpg) ? tfo->tpg_get_wwn(se_tpg) : NULL,
 		se_tpg->proto_id, tfo->tpg_get_tag(se_tpg));
 
-	spin_lock_bh(&tpg_lock);
-	list_del(&se_tpg->se_tpg_node);
-	spin_unlock_bh(&tpg_lock);
-
 	while (atomic_read(&se_tpg->tpg_pr_ref_count) != 0)
 		cpu_relax();
 

commit 1a59d1b8e05ea6ab45f7e18897de1ef0e6bc3da6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:05 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 156
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version this program is distributed in the
      hope that it will be useful but without any warranty without even
      the implied warranty of merchantability or fitness for a particular
      purpose see the gnu general public license for more details you
      should have received a copy of the gnu general public license along
      with this program if not write to the free software foundation inc
      59 temple place suite 330 boston ma 02111 1307 usa
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 1334 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Richard Fontana <rfontana@redhat.com>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070033.113240726@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index e2ace1059437..e5a71addbb06 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*******************************************************************************
  * Filename:  target_core_tpg.c
  *
@@ -7,20 +8,6 @@
  *
  * Nicholas A. Bellinger <nab@kernel.org>
  *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
- *
  ******************************************************************************/
 
 #include <linux/net.h>

commit a95be3842c51c9ac32fe17faedf2c156ccf81bd7
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Tue Nov 27 15:51:57 2018 -0800

    scsi: target/core: Simplify transport_clear_lun_ref()
    
    Since transport_clear_lun_ref() already waits until the percpu-refcount
    .release() method is called, it is not necessary to wait first until
    percpu_ref_kill_and_confirm() has finished transitioning the refcount into
    atomic mode. Remove the code that waits for percpu_ref_kill_and_confirm()
    to complete and also the completion object that is used by that code.  This
    patch does not change the behavior of the SCSI target code.
    
    Cc: Nicholas Bellinger <nab@linux-iscsi.org>
    Cc: Mike Christie <mchristi@redhat.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: David Disseldorp <ddiss@suse.de>
    Cc: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 16e7a6500be4..e2ace1059437 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -577,7 +577,6 @@ struct se_lun *core_tpg_alloc_lun(
 	}
 	lun->unpacked_lun = unpacked_lun;
 	atomic_set(&lun->lun_acl_count, 0);
-	init_completion(&lun->lun_ref_comp);
 	init_completion(&lun->lun_shutdown_comp);
 	INIT_LIST_HEAD(&lun->lun_deve_list);
 	INIT_LIST_HEAD(&lun->lun_dev_link);

commit 30c7ca9350048486ab32fdb9f5f6ed0603bba39a
Author: David Disseldorp <ddiss@suse.de>
Date:   Fri Nov 23 18:36:12 2018 +0100

    scsi: target: drop unnecessary get_fabric_name() accessor from fabric_ops
    
    All fabrics return a const string. In all cases *except* iSCSI the
    get_fabric_name() string matches fabric_ops.name.
    
    Both fabric_ops.get_fabric_name() and fabric_ops.name are user-facing, with
    the former being used for PR/ALUA state and the latter for ConfigFS
    (config/target/$name), so we unfortunately need to keep both strings around
    for now.  Replace the useless .get_fabric_name() accessor function with a
    const string fabric_name member variable.
    
    Signed-off-by: David Disseldorp <ddiss@suse.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 02e8a5d86658..16e7a6500be4 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -151,7 +151,7 @@ void core_tpg_add_node_to_devs(
 
 		pr_debug("TARGET_CORE[%s]->TPG[%u]_LUN[%llu] - Adding %s"
 			" access for LUN in Demo Mode\n",
-			tpg->se_tpg_tfo->get_fabric_name(),
+			tpg->se_tpg_tfo->fabric_name,
 			tpg->se_tpg_tfo->tpg_get_tag(tpg), lun->unpacked_lun,
 			lun_access_ro ? "READ-ONLY" : "READ-WRITE");
 
@@ -176,7 +176,7 @@ target_set_nacl_queue_depth(struct se_portal_group *tpg,
 
 	if (!acl->queue_depth) {
 		pr_warn("Queue depth for %s Initiator Node: %s is 0,"
-			"defaulting to 1.\n", tpg->se_tpg_tfo->get_fabric_name(),
+			"defaulting to 1.\n", tpg->se_tpg_tfo->fabric_name,
 			acl->initiatorname);
 		acl->queue_depth = 1;
 	}
@@ -227,11 +227,11 @@ static void target_add_node_acl(struct se_node_acl *acl)
 
 	pr_debug("%s_TPG[%hu] - Added %s ACL with TCQ Depth: %d for %s"
 		" Initiator Node: %s\n",
-		tpg->se_tpg_tfo->get_fabric_name(),
+		tpg->se_tpg_tfo->fabric_name,
 		tpg->se_tpg_tfo->tpg_get_tag(tpg),
 		acl->dynamic_node_acl ? "DYNAMIC" : "",
 		acl->queue_depth,
-		tpg->se_tpg_tfo->get_fabric_name(),
+		tpg->se_tpg_tfo->fabric_name,
 		acl->initiatorname);
 }
 
@@ -313,7 +313,7 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 		if (acl->dynamic_node_acl) {
 			acl->dynamic_node_acl = 0;
 			pr_debug("%s_TPG[%u] - Replacing dynamic ACL"
-				" for %s\n", tpg->se_tpg_tfo->get_fabric_name(),
+				" for %s\n", tpg->se_tpg_tfo->fabric_name,
 				tpg->se_tpg_tfo->tpg_get_tag(tpg), initiatorname);
 			mutex_unlock(&tpg->acl_node_mutex);
 			return acl;
@@ -321,7 +321,7 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 
 		pr_err("ACL entry for %s Initiator"
 			" Node %s already exists for TPG %u, ignoring"
-			" request.\n",  tpg->se_tpg_tfo->get_fabric_name(),
+			" request.\n",  tpg->se_tpg_tfo->fabric_name,
 			initiatorname, tpg->se_tpg_tfo->tpg_get_tag(tpg));
 		mutex_unlock(&tpg->acl_node_mutex);
 		return ERR_PTR(-EEXIST);
@@ -380,9 +380,9 @@ void core_tpg_del_initiator_node_acl(struct se_node_acl *acl)
 	core_free_device_list_for_node(acl, tpg);
 
 	pr_debug("%s_TPG[%hu] - Deleted ACL with TCQ Depth: %d for %s"
-		" Initiator Node: %s\n", tpg->se_tpg_tfo->get_fabric_name(),
+		" Initiator Node: %s\n", tpg->se_tpg_tfo->fabric_name,
 		tpg->se_tpg_tfo->tpg_get_tag(tpg), acl->queue_depth,
-		tpg->se_tpg_tfo->get_fabric_name(), acl->initiatorname);
+		tpg->se_tpg_tfo->fabric_name, acl->initiatorname);
 
 	kfree(acl);
 }
@@ -418,7 +418,7 @@ int core_tpg_set_initiator_node_queue_depth(
 
 	pr_debug("Successfully changed queue depth to: %d for Initiator"
 		" Node: %s on %s Target Portal Group: %u\n", acl->queue_depth,
-		acl->initiatorname, tpg->se_tpg_tfo->get_fabric_name(),
+		acl->initiatorname, tpg->se_tpg_tfo->fabric_name,
 		tpg->se_tpg_tfo->tpg_get_tag(tpg));
 
 	return 0;
@@ -512,7 +512,7 @@ int core_tpg_register(
 	spin_unlock_bh(&tpg_lock);
 
 	pr_debug("TARGET_CORE[%s]: Allocated portal_group for endpoint: %s, "
-		 "Proto: %d, Portal Tag: %u\n", se_tpg->se_tpg_tfo->get_fabric_name(),
+		 "Proto: %d, Portal Tag: %u\n", se_tpg->se_tpg_tfo->fabric_name,
 		se_tpg->se_tpg_tfo->tpg_get_wwn(se_tpg) ?
 		se_tpg->se_tpg_tfo->tpg_get_wwn(se_tpg) : NULL,
 		se_tpg->proto_id, se_tpg->se_tpg_tfo->tpg_get_tag(se_tpg));
@@ -528,7 +528,7 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 	LIST_HEAD(node_list);
 
 	pr_debug("TARGET_CORE[%s]: Deallocating portal_group for endpoint: %s, "
-		 "Proto: %d, Portal Tag: %u\n", tfo->get_fabric_name(),
+		 "Proto: %d, Portal Tag: %u\n", tfo->fabric_name,
 		tfo->tpg_get_wwn(se_tpg) ? tfo->tpg_get_wwn(se_tpg) : NULL,
 		se_tpg->proto_id, tfo->tpg_get_tag(se_tpg));
 

commit 6f48655facfd7f7ccfe6d252ac0fe319ab02e4dd
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Sun Aug 6 16:10:03 2017 -0700

    target: Fix node_acl demo-mode + uncached dynamic shutdown regression
    
    This patch fixes a generate_node_acls = 1 + cache_dynamic_acls = 0
    regression, that was introduced by
    
      commit 01d4d673558985d9a118e1e05026633c3e2ade9b
      Author: Nicholas Bellinger <nab@linux-iscsi.org>
      Date:   Wed Dec 7 12:55:54 2016 -0800
    
    which originally had the proper list_del_init() usage, but was
    dropped during list review as it was thought unnecessary by HCH.
    
    However, list_del_init() usage is required during the special
    generate_node_acls = 1 + cache_dynamic_acls = 0 case when
    transport_free_session() does a list_del(&se_nacl->acl_list),
    followed by target_complete_nacl() doing the same thing.
    
    This was manifesting as a general protection fault as reported
    by Justin:
    
    kernel: general protection fault: 0000 [#1] SMP
    kernel: Modules linked in:
    kernel: CPU: 0 PID: 11047 Comm: iscsi_ttx Not tainted 4.13.0-rc2.x86_64.1+ #20
    kernel: Hardware name: Intel Corporation S5500BC/S5500BC, BIOS S5500.86B.01.00.0064.050520141428 05/05/2014
    kernel: task: ffff88026939e800 task.stack: ffffc90007884000
    kernel: RIP: 0010:target_put_nacl+0x49/0xb0
    kernel: RSP: 0018:ffffc90007887d70 EFLAGS: 00010246
    kernel: RAX: dead000000000200 RBX: ffff8802556ca000 RCX: 0000000000000000
    kernel: RDX: dead000000000100 RSI: 0000000000000246 RDI: ffff8802556ce028
    kernel: RBP: ffffc90007887d88 R08: 0000000000000001 R09: 0000000000000000
    kernel: R10: ffffc90007887df8 R11: ffffea0009986900 R12: ffff8802556ce020
    kernel: R13: ffff8802556ce028 R14: ffff8802556ce028 R15: ffffffff88d85540
    kernel: FS:  0000000000000000(0000) GS:ffff88027fc00000(0000) knlGS:0000000000000000
    kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    kernel: CR2: 00007fffe36f5f94 CR3: 0000000009209000 CR4: 00000000003406f0
    kernel: DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    kernel: DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    kernel: Call Trace:
    kernel:  transport_free_session+0x67/0x140
    kernel:  transport_deregister_session+0x7a/0xc0
    kernel:  iscsit_close_session+0x92/0x210
    kernel:  iscsit_close_connection+0x5f9/0x840
    kernel:  iscsit_take_action_for_connection_exit+0xfe/0x110
    kernel:  iscsi_target_tx_thread+0x140/0x1e0
    kernel:  ? wait_woken+0x90/0x90
    kernel:  kthread+0x124/0x160
    kernel:  ? iscsit_thread_get_cpumask+0x90/0x90
    kernel:  ? kthread_create_on_node+0x40/0x40
    kernel:  ret_from_fork+0x22/0x30
    kernel: Code: 00 48 89 fb 4c 8b a7 48 01 00 00 74 68 4d 8d 6c 24 08 4c
    89 ef e8 e8 28 43 00 48 8b 93 20 04 00 00 48 8b 83 28 04 00 00 4c 89
    ef <48> 89 42 08 48 89 10 48 b8 00 01 00 00 00 00 ad de 48 89 83 20
    kernel: RIP: target_put_nacl+0x49/0xb0 RSP: ffffc90007887d70
    kernel: ---[ end trace f12821adbfd46fed ]---
    
    To address this, go ahead and use proper list_del_list() for all
    cases of se_nacl->acl_list deletion.
    
    Reported-by: Justin Maggard <jmaggard01@gmail.com>
    Tested-by: Justin Maggard <jmaggard01@gmail.com>
    Cc: Justin Maggard <jmaggard01@gmail.com>
    Cc: stable@vger.kernel.org # 4.1+
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 36913734c6bc..02e8a5d86658 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -364,7 +364,7 @@ void core_tpg_del_initiator_node_acl(struct se_node_acl *acl)
 	mutex_lock(&tpg->acl_node_mutex);
 	if (acl->dynamic_node_acl)
 		acl->dynamic_node_acl = 0;
-	list_del(&acl->acl_list);
+	list_del_init(&acl->acl_list);
 	mutex_unlock(&tpg->acl_node_mutex);
 
 	target_shutdown_sessions(acl);
@@ -548,7 +548,7 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 	 * in transport_deregister_session().
 	 */
 	list_for_each_entry_safe(nacl, nacl_tmp, &node_list, acl_list) {
-		list_del(&nacl->acl_list);
+		list_del_init(&nacl->acl_list);
 
 		core_tpg_wait_for_nacl_pr_ref(nacl);
 		core_free_device_list_for_node(nacl, se_tpg);

commit 9ae0e9ade56f23765366d2cfad24e65f28df977d
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Thu Jun 1 03:11:18 2017 -0700

    target/configfs: Kill se_lun->lun_link_magic
    
    Instead of using a hardcoded magic value in se_lun when verifying
    a target config_item symlink source during target_fabric_mappedlun_link(),
    go ahead and use target_fabric_port_item_ops directly instead.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Cc: Mike Christie <mchristi@redhat.com>
    Cc: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 310d9e55c6eb..36913734c6bc 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -576,7 +576,6 @@ struct se_lun *core_tpg_alloc_lun(
 		return ERR_PTR(-ENOMEM);
 	}
 	lun->unpacked_lun = unpacked_lun;
-	lun->lun_link_magic = SE_LUN_LINK_MAGIC;
 	atomic_set(&lun->lun_acl_count, 0);
 	init_completion(&lun->lun_ref_comp);
 	init_completion(&lun->lun_shutdown_comp);

commit 46861cdd80e1a862dc65d10833a1450861fabef7
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Tue Apr 25 13:52:45 2017 -0700

    target: Don't force session reset if queue_depth does not change
    
    Keeping in the idempotent nature of target_core_fabric_configfs.c,
    if a queue_depth value is set and it's the same as the existing
    value, don't attempt to force session reinstatement.
    
    Reported-by: Raghu Krishnamurthy <rk@datera.io>
    Cc: Raghu Krishnamurthy <rk@datera.io>
    Tested-by: Gary Guo <ghg@datera.io>
    Cc: Gary Guo <ghg@datera.io>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index dfaef4d3b2d2..310d9e55c6eb 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -397,6 +397,13 @@ int core_tpg_set_initiator_node_queue_depth(
 {
 	struct se_portal_group *tpg = acl->se_tpg;
 
+	/*
+	 * Allow the setting of se_node_acl queue_depth to be idempotent,
+	 * and not force a session shutdown event if the value is not
+	 * changing.
+	 */
+	if (acl->queue_depth == queue_depth)
+		return 0;
 	/*
 	 * User has requested to change the queue depth for a Initiator Node.
 	 * Change the value in the Node's struct se_node_acl, and call

commit 49cb77e297dc611a1b795cfeb79452b3002bd331
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Mon Mar 27 16:12:43 2017 -0700

    target: Avoid mappedlun symlink creation during lun shutdown
    
    This patch closes a race between se_lun deletion during configfs
    unlink in target_fabric_port_unlink() -> core_dev_del_lun()
    -> core_tpg_remove_lun(), when transport_clear_lun_ref() blocks
    waiting for percpu_ref RCU grace period to finish, but a new
    NodeACL mappedlun is added before the RCU grace period has
    completed.
    
    This can happen in target_fabric_mappedlun_link() because it
    only checks for se_lun->lun_se_dev, which is not cleared until
    after transport_clear_lun_ref() percpu_ref RCU grace period
    finishes.
    
    This bug originally manifested as NULL pointer dereference
    OOPsen in target_stat_scsi_att_intr_port_show_attr_dev() on
    v4.1.y code, because it dereferences lun->lun_se_dev without
    a explicit NULL pointer check.
    
    In post v4.1 code with target-core RCU conversion, the code
    in target_stat_scsi_att_intr_port_show_attr_dev() no longer
    uses se_lun->lun_se_dev, but the same race still exists.
    
    To address the bug, go ahead and set se_lun>lun_shutdown as
    early as possible in core_tpg_remove_lun(), and ensure new
    NodeACL mappedlun creation in target_fabric_mappedlun_link()
    fails during se_lun shutdown.
    
    Reported-by: James Shen <jcs@datera.io>
    Cc: James Shen <jcs@datera.io>
    Tested-by: James Shen <jcs@datera.io>
    Cc: stable@vger.kernel.org # 3.10+
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 6fb191914f45..dfaef4d3b2d2 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -642,6 +642,8 @@ void core_tpg_remove_lun(
 	 */
 	struct se_device *dev = rcu_dereference_raw(lun->lun_se_dev);
 
+	lun->lun_shutdown = true;
+
 	core_clear_lun_from_tpg(lun, tpg);
 	/*
 	 * Wait for any active I/O references to percpu se_lun->lun_ref to
@@ -663,6 +665,8 @@ void core_tpg_remove_lun(
 	}
 	if (!(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))
 		hlist_del_rcu(&lun->link);
+
+	lun->lun_shutdown = false;
 	mutex_unlock(&tpg->tpg_lun_mutex);
 
 	percpu_ref_exit(&lun->lun_ref);

commit 530c6891b1220cba780b6c18f4691d85a3435080
Author: Mike Christie <mchristi@redhat.com>
Date:   Wed Mar 1 23:13:24 2017 -0600

    target: allow ALUA setup for some passthrough backends
    
    This patch allows passthrough backends to use the core/base LIO
    ALUA setup and state checks, but still handle the execution of
    commands.
    
    This will allow the target_core_user module to execute STPG and RTPG
    in userspace, and not have to duplicate the ALUA state checks, path
    information (needed so we can check if command is executable on
    specific paths) and setup (rtslib sets/updates the configfs ALUA
    interface like it does for iblock or file).
    
    For STPG, the target_core_user userspace daemon, tcmu-runner will
    still execute the STPG, and to update the core/base LIO state it
    will use the existing configfs interface. For RTPG, tcmu-runner
    will loop over configfs and/or cache the state.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index c0dbfa016575..6fb191914f45 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -602,7 +602,8 @@ int core_tpg_add_lun(
 	if (ret)
 		goto out_kill_ref;
 
-	if (!(dev->transport->transport_flags & TRANSPORT_FLAG_PASSTHROUGH) &&
+	if (!(dev->transport->transport_flags &
+	     TRANSPORT_FLAG_PASSTHROUGH_ALUA) &&
 	    !(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))
 		target_attach_tg_pt_gp(lun, dev->t10_alua.default_tg_pt_gp);
 

commit 821fd6f6cb6500cd04a6c7e8f701f9b311a5c2b3
Merge: ca4c7d7c2b6b c87ba9c49c1f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 2 14:52:05 2017 -0800

    Merge branch 'for-next' of git://git.kernel.org/pub/scm/linux/kernel/git/nab/target-pending
    
    Pull SCSI target updates from Nicholas Bellinger:
     "The highlights this round include:
    
       - enable dual mode (initiator + target) qla2xxx operation. (Quinn +
         Himanshu)
    
       - add a framework for qla2xxx async fabric discovery. (Quinn +
         Himanshu)
    
       - enable iscsi PDU DDP completion offload in cxgbit/T6 NICs. (Varun)
    
       - fix target-core handling of aborted failed commands. (Bart)
    
       - fix a long standing target-core issue NULL pointer dereference with
         active I/O LUN shutdown. (Rob Millner + Bryant + nab)"
    
    * 'for-next' of git://git.kernel.org/pub/scm/linux/kernel/git/nab/target-pending: (44 commits)
      target: Add counters for ABORT_TASK success + failure
      iscsi-target: Fix early login failure statistics misses
      target: Fix NULL dereference during LUN lookup + active I/O shutdown
      target: Delete tmr from list before processing
      target: Fix handling of aborted failed commands
      uapi: fix linux/target_core_user.h userspace compilation errors
      target: export protocol identifier
      qla2xxx: Fix a warning reported by the "smatch" static checker
      target/iscsi: Fix unsolicited data seq_end_offset calculation
      target/cxgbit: add T6 iSCSI DDP completion feature
      target/cxgbit: Enable DDP for T6 only if data sequence and pdu are in order
      target/cxgbit: Use T6 specific macros to get ETH/IP hdr len
      target/cxgbit: use cxgb4_tp_smt_idx() to get smt idx
      target/iscsi: split iscsit_check_dataout_hdr()
      target: Remove command flag CMD_T_DEV_ACTIVE
      target: Remove command flag CMD_T_BUSY
      target: Move session check from target_put_sess_cmd() into target_release_cmd_kref()
      target: Inline transport_cmd_check_stop()
      target: Remove an overly chatty debug message
      target: Stop execution if CMD_T_STOP has been set
      ...

commit bd4e2d2907fa23a11d46217064ecf80470ddae10
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Wed Feb 22 22:06:32 2017 -0800

    target: Fix NULL dereference during LUN lookup + active I/O shutdown
    
    When transport_clear_lun_ref() is shutting down a se_lun via
    configfs with new I/O in-flight, it's possible to trigger a
    NULL pointer dereference in transport_lookup_cmd_lun() due
    to the fact percpu_ref_get() doesn't do any __PERCPU_REF_DEAD
    checking before incrementing lun->lun_ref.count after
    lun->lun_ref has switched to atomic_t mode.
    
    This results in a NULL pointer dereference as LUN shutdown
    code in core_tpg_remove_lun() continues running after the
    existing ->release() -> core_tpg_lun_ref_release() callback
    completes, and clears the RCU protected se_lun->lun_se_dev
    pointer.
    
    During the OOPs, the state of lun->lun_ref in the process
    which triggered the NULL pointer dereference looks like
    the following on v4.1.y stable code:
    
    struct se_lun {
      lun_link_magic = 4294932337,
      lun_status = TRANSPORT_LUN_STATUS_FREE,
    
      .....
    
      lun_se_dev = 0x0,
      lun_sep = 0x0,
    
      .....
    
      lun_ref = {
        count = {
          counter = 1
        },
        percpu_count_ptr = 3,
        release = 0xffffffffa02fa1e0 <core_tpg_lun_ref_release>,
        confirm_switch = 0x0,
        force_atomic = false,
        rcu = {
          next = 0xffff88154fa1a5d0,
          func = 0xffffffff8137c4c0 <percpu_ref_switch_to_atomic_rcu>
        }
      }
    }
    
    To address this bug, use percpu_ref_tryget_live() to ensure
    once __PERCPU_REF_DEAD is visable on all CPUs and ->lun_ref
    has switched to atomic_t, all new I/Os will fail to obtain
    a new lun->lun_ref reference.
    
    Also use an explicit percpu_ref_kill_and_confirm() callback
    to block on ->lun_ref_comp to allow the first stage and
    associated RCU grace period to complete, and then block on
    ->lun_ref_shutdown waiting for the final percpu_ref_put()
    to drop the last reference via transport_lun_remove_cmd()
    before continuing with core_tpg_remove_lun() shutdown.
    
    Reported-by: Rob Millner <rlm@daterainc.com>
    Tested-by: Rob Millner <rlm@daterainc.com>
    Cc: Rob Millner <rlm@daterainc.com>
    Tested-by: Vaibhav Tandon <vst@datera.io>
    Cc: Vaibhav Tandon <vst@datera.io>
    Tested-by: Bryant G. Ly <bryantly@linux.vnet.ibm.com>
    Cc: <stable@vger.kernel.org> # v3.14+
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index d99752c6cd60..2744251178ad 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -445,7 +445,7 @@ static void core_tpg_lun_ref_release(struct percpu_ref *ref)
 {
 	struct se_lun *lun = container_of(ref, struct se_lun, lun_ref);
 
-	complete(&lun->lun_ref_comp);
+	complete(&lun->lun_shutdown_comp);
 }
 
 int core_tpg_register(
@@ -571,6 +571,7 @@ struct se_lun *core_tpg_alloc_lun(
 	lun->lun_link_magic = SE_LUN_LINK_MAGIC;
 	atomic_set(&lun->lun_acl_count, 0);
 	init_completion(&lun->lun_ref_comp);
+	init_completion(&lun->lun_shutdown_comp);
 	INIT_LIST_HEAD(&lun->lun_deve_list);
 	INIT_LIST_HEAD(&lun->lun_dev_link);
 	atomic_set(&lun->lun_tg_pt_secondary_offline, 0);

commit 2bce1a6d2209c8c776a9598741f5aa1991689dcb
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Fri Dec 9 11:00:33 2016 -0800

    IB/srpt: Accept GUIDs as port names
    
    Port and ACL information must be configured before an initiator
    logs in.  Make it possible to configure this information before
    a subnet prefix has been assigned to a port by not only accepting
    GIDs as target port and initiator port names but by also accepting
    port GUIDs.
    
    Add a 'priv' member to struct se_wwn to allow target drivers to
    associate their own data with struct se_wwn.
    
    Reported-by: Doug Ledford <dledford@redhat.com>
    References: http://www.spinics.net/lists/linux-rdma/msg39505.html
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Nicholas Bellinger <nab@linux-iscsi.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index d99752c6cd60..4a8b180c478b 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -448,6 +448,7 @@ static void core_tpg_lun_ref_release(struct percpu_ref *ref)
 	complete(&lun->lun_ref_comp);
 }
 
+/* Does not change se_wwn->priv. */
 int core_tpg_register(
 	struct se_wwn *se_wwn,
 	struct se_portal_group *se_tpg,

commit d94331fab6d4d48280a5cea646352db90777966d
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon May 2 15:45:25 2016 +0200

    target: remove sess_kref and ->shutdown_session
    
    Both of them are unused now that drivers handle any delayed session
    shutdown internally.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index a81a37045403..d99752c6cd60 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -340,26 +340,18 @@ static void target_shutdown_sessions(struct se_node_acl *acl)
 {
 	struct se_session *sess;
 	unsigned long flags;
-	int ret;
 
 restart:
 	spin_lock_irqsave(&acl->nacl_sess_lock, flags);
 	list_for_each_entry(sess, &acl->acl_sess_list, sess_acl_list) {
 		if (sess->sess_tearing_down)
 			continue;
-		if (!target_get_session(sess))
-			continue;
 
 		list_del_init(&sess->sess_acl_list);
-
 		spin_unlock_irqrestore(&acl->nacl_sess_lock, flags);
-		if (acl->se_tpg->se_tpg_tfo->shutdown_session)
-			ret = acl->se_tpg->se_tpg_tfo->shutdown_session(sess);
-		else
-			ret = 1;
-		target_put_session(sess);
-		if (ret)
-			target_put_session(sess);
+
+		if (acl->se_tpg->se_tpg_tfo->close_session)
+			acl->se_tpg->se_tpg_tfo->close_session(sess);
 		goto restart;
 	}
 	spin_unlock_irqrestore(&acl->nacl_sess_lock, flags);

commit 22d11759a4e7018f8cd7914e4e706ca2c96d6c01
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon May 2 15:45:21 2016 +0200

    target: make ->shutdown_session optional
    
    Turns out the template and thus many drivers got the return value wrong:
    0 means the fabrics driver needs to put a session reference, which no
    driver except for the iSCSI target drivers did.  Fortunately none of these
    drivers supports explicit Node ACLs, so the bug was harmless.
    
    Even without that only qla2xxx and iscsi every did real work in
    shutdown_session, so get rid of the boilerplate code in all other
    drivers.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index b1ac600f5b45..a81a37045403 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -353,7 +353,10 @@ static void target_shutdown_sessions(struct se_node_acl *acl)
 		list_del_init(&sess->sess_acl_list);
 
 		spin_unlock_irqrestore(&acl->nacl_sess_lock, flags);
-		ret = acl->se_tpg->se_tpg_tfo->shutdown_session(sess);
+		if (acl->se_tpg->se_tpg_tfo->shutdown_session)
+			ret = acl->se_tpg->se_tpg_tfo->shutdown_session(sess);
+		else
+			ret = 1;
 		target_put_session(sess);
 		if (ret)
 			target_put_session(sess);

commit fba81f8831b20272a97a990e5d47c332e9b1f65d
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon May 2 15:45:20 2016 +0200

    target: remove acl_stop
    
    Ensure we can use list_empty on the sess_acl_list to remove the need for
    this flag.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 88db4938600b..b1ac600f5b45 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -336,30 +336,27 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 	return acl;
 }
 
-static void target_shutdown_sessions(struct se_node_acl *acl, bool acl_stop)
+static void target_shutdown_sessions(struct se_node_acl *acl)
 {
 	struct se_session *sess;
 	unsigned long flags;
 	int ret;
 
-	spin_lock_irqsave(&acl->nacl_sess_lock, flags);
-	if (acl_stop)
-		acl->acl_stop = 1;
 restart:
+	spin_lock_irqsave(&acl->nacl_sess_lock, flags);
 	list_for_each_entry(sess, &acl->acl_sess_list, sess_acl_list) {
 		if (sess->sess_tearing_down)
 			continue;
 		if (!target_get_session(sess))
 			continue;
 
-		list_del(&sess->sess_acl_list);
+		list_del_init(&sess->sess_acl_list);
 
 		spin_unlock_irqrestore(&acl->nacl_sess_lock, flags);
 		ret = acl->se_tpg->se_tpg_tfo->shutdown_session(sess);
 		target_put_session(sess);
 		if (ret)
 			target_put_session(sess);
-		spin_lock_irqsave(&acl->nacl_sess_lock, flags);
 		goto restart;
 	}
 	spin_unlock_irqrestore(&acl->nacl_sess_lock, flags);
@@ -375,7 +372,7 @@ void core_tpg_del_initiator_node_acl(struct se_node_acl *acl)
 	list_del(&acl->acl_list);
 	mutex_unlock(&tpg->acl_node_mutex);
 
-	target_shutdown_sessions(acl, true);
+	target_shutdown_sessions(acl);
 
 	target_put_nacl(acl);
 	/*
@@ -415,7 +412,7 @@ int core_tpg_set_initiator_node_queue_depth(
 	/*
 	 * Shutdown all pending sessions to force session reinstatement.
 	 */
-	target_shutdown_sessions(acl, false);
+	target_shutdown_sessions(acl);
 
 	pr_debug("Successfully changed queue depth to: %d for Initiator"
 		" Node: %s on %s Target Portal Group: %u\n", acl->queue_depth,

commit bc6e6bb470eda42f44bcac96c261cff1216577b3
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon May 2 15:45:19 2016 +0200

    target: consolidate and fix session shutdown
    
    Factor out a helper to shutdown sessions for a Node ACL, and make it
    properly restart the list walk after dropping the lock.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index ddf046080dc3..88db4938600b 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -336,44 +336,47 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 	return acl;
 }
 
-void core_tpg_del_initiator_node_acl(struct se_node_acl *acl)
+static void target_shutdown_sessions(struct se_node_acl *acl, bool acl_stop)
 {
-	struct se_portal_group *tpg = acl->se_tpg;
-	LIST_HEAD(sess_list);
-	struct se_session *sess, *sess_tmp;
+	struct se_session *sess;
 	unsigned long flags;
-	int rc;
-
-	mutex_lock(&tpg->acl_node_mutex);
-	if (acl->dynamic_node_acl) {
-		acl->dynamic_node_acl = 0;
-	}
-	list_del(&acl->acl_list);
-	mutex_unlock(&tpg->acl_node_mutex);
+	int ret;
 
 	spin_lock_irqsave(&acl->nacl_sess_lock, flags);
-	acl->acl_stop = 1;
-
-	list_for_each_entry_safe(sess, sess_tmp, &acl->acl_sess_list,
-				sess_acl_list) {
-		if (sess->sess_tearing_down != 0)
+	if (acl_stop)
+		acl->acl_stop = 1;
+restart:
+	list_for_each_entry(sess, &acl->acl_sess_list, sess_acl_list) {
+		if (sess->sess_tearing_down)
 			continue;
-
 		if (!target_get_session(sess))
 			continue;
-		list_move(&sess->sess_acl_list, &sess_list);
-	}
-	spin_unlock_irqrestore(&acl->nacl_sess_lock, flags);
 
-	list_for_each_entry_safe(sess, sess_tmp, &sess_list, sess_acl_list) {
 		list_del(&sess->sess_acl_list);
 
-		rc = tpg->se_tpg_tfo->shutdown_session(sess);
-		target_put_session(sess);
-		if (!rc)
-			continue;
+		spin_unlock_irqrestore(&acl->nacl_sess_lock, flags);
+		ret = acl->se_tpg->se_tpg_tfo->shutdown_session(sess);
 		target_put_session(sess);
+		if (ret)
+			target_put_session(sess);
+		spin_lock_irqsave(&acl->nacl_sess_lock, flags);
+		goto restart;
 	}
+	spin_unlock_irqrestore(&acl->nacl_sess_lock, flags);
+}
+
+void core_tpg_del_initiator_node_acl(struct se_node_acl *acl)
+{
+	struct se_portal_group *tpg = acl->se_tpg;
+
+	mutex_lock(&tpg->acl_node_mutex);
+	if (acl->dynamic_node_acl)
+		acl->dynamic_node_acl = 0;
+	list_del(&acl->acl_list);
+	mutex_unlock(&tpg->acl_node_mutex);
+
+	target_shutdown_sessions(acl, true);
+
 	target_put_nacl(acl);
 	/*
 	 * Wait for last target_put_nacl() to complete in target_complete_nacl()
@@ -400,11 +403,7 @@ int core_tpg_set_initiator_node_queue_depth(
 	struct se_node_acl *acl,
 	u32 queue_depth)
 {
-	LIST_HEAD(sess_list);
 	struct se_portal_group *tpg = acl->se_tpg;
-	struct se_session *sess, *sess_tmp;
-	unsigned long flags;
-	int rc;
 
 	/*
 	 * User has requested to change the queue depth for a Initiator Node.
@@ -413,30 +412,10 @@ int core_tpg_set_initiator_node_queue_depth(
 	 */
 	target_set_nacl_queue_depth(tpg, acl, queue_depth);
 
-	spin_lock_irqsave(&acl->nacl_sess_lock, flags);
-	list_for_each_entry_safe(sess, sess_tmp, &acl->acl_sess_list,
-				 sess_acl_list) {
-		if (sess->sess_tearing_down != 0)
-			continue;
-		if (!target_get_session(sess))
-			continue;
-		spin_unlock_irqrestore(&acl->nacl_sess_lock, flags);
-
-		/*
-		 * Finally call tpg->se_tpg_tfo->close_session() to force session
-		 * reinstatement to occur if there is an active session for the
-		 * $FABRIC_MOD Initiator Node in question.
-		 */
-		rc = tpg->se_tpg_tfo->shutdown_session(sess);
-		target_put_session(sess);
-		if (!rc) {
-			spin_lock_irqsave(&acl->nacl_sess_lock, flags);
-			continue;
-		}
-		target_put_session(sess);
-		spin_lock_irqsave(&acl->nacl_sess_lock, flags);
-	}
-	spin_unlock_irqrestore(&acl->nacl_sess_lock, flags);
+	/*
+	 * Shutdown all pending sessions to force session reinstatement.
+	 */
+	target_shutdown_sessions(acl, false);
 
 	pr_debug("Successfully changed queue depth to: %d for Initiator"
 		" Node: %s on %s Target Portal Group: %u\n", acl->queue_depth,

commit 03a68b44faff1b3eef5424952044747c9c555f0e
Author: Andy Grover <agrover@redhat.com>
Date:   Thu Feb 25 15:14:32 2016 -0800

    target: Remove enum transport_lunflags_table
    
    se_dev_entry.lun_flags and se_lun.lun_access are only used for keeping
    track of read-write vs. read-only state. Since this is an either/or thing
    we can represent it as bool, and remove the unneeded enum
    transport_lunflags_table, which is left over from when there were more
    flags.
    
    Change code that uses this enum to just use true/false, and make it clear
    through variable and param names that true means read-only, false means
    read-write.
    
    Signed-off-by: Andy Grover <agrover@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 3608b1b5ecf7..ddf046080dc3 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -121,7 +121,7 @@ void core_tpg_add_node_to_devs(
 	struct se_portal_group *tpg,
 	struct se_lun *lun_orig)
 {
-	u32 lun_access = 0;
+	bool lun_access_ro = true;
 	struct se_lun *lun;
 	struct se_device *dev;
 
@@ -137,27 +137,26 @@ void core_tpg_add_node_to_devs(
 		 * demo_mode_write_protect is ON, or READ_ONLY;
 		 */
 		if (!tpg->se_tpg_tfo->tpg_check_demo_mode_write_protect(tpg)) {
-			lun_access = TRANSPORT_LUNFLAGS_READ_WRITE;
+			lun_access_ro = false;
 		} else {
 			/*
 			 * Allow only optical drives to issue R/W in default RO
 			 * demo mode.
 			 */
 			if (dev->transport->get_device_type(dev) == TYPE_DISK)
-				lun_access = TRANSPORT_LUNFLAGS_READ_ONLY;
+				lun_access_ro = true;
 			else
-				lun_access = TRANSPORT_LUNFLAGS_READ_WRITE;
+				lun_access_ro = false;
 		}
 
 		pr_debug("TARGET_CORE[%s]->TPG[%u]_LUN[%llu] - Adding %s"
 			" access for LUN in Demo Mode\n",
 			tpg->se_tpg_tfo->get_fabric_name(),
 			tpg->se_tpg_tfo->tpg_get_tag(tpg), lun->unpacked_lun,
-			(lun_access == TRANSPORT_LUNFLAGS_READ_WRITE) ?
-			"READ-WRITE" : "READ-ONLY");
+			lun_access_ro ? "READ-ONLY" : "READ-WRITE");
 
 		core_enable_device_list_for_node(lun, NULL, lun->unpacked_lun,
-						 lun_access, acl, tpg);
+						 lun_access_ro, acl, tpg);
 		/*
 		 * Check to see if there are any existing persistent reservation
 		 * APTPL pre-registrations that need to be enabled for this dynamic
@@ -522,7 +521,7 @@ int core_tpg_register(
 			return PTR_ERR(se_tpg->tpg_virt_lun0);
 
 		ret = core_tpg_add_lun(se_tpg, se_tpg->tpg_virt_lun0,
-				TRANSPORT_LUNFLAGS_READ_ONLY, g_lun0_dev);
+				true, g_lun0_dev);
 		if (ret < 0) {
 			kfree(se_tpg->tpg_virt_lun0);
 			return ret;
@@ -616,7 +615,7 @@ struct se_lun *core_tpg_alloc_lun(
 int core_tpg_add_lun(
 	struct se_portal_group *tpg,
 	struct se_lun *lun,
-	u32 lun_access,
+	bool lun_access_ro,
 	struct se_device *dev)
 {
 	int ret;
@@ -644,9 +643,9 @@ int core_tpg_add_lun(
 	spin_unlock(&dev->se_port_lock);
 
 	if (dev->dev_flags & DF_READ_ONLY)
-		lun->lun_access = TRANSPORT_LUNFLAGS_READ_ONLY;
+		lun->lun_access_ro = true;
 	else
-		lun->lun_access = lun_access;
+		lun->lun_access_ro = lun_access_ro;
 	if (!(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))
 		hlist_add_head_rcu(&lun->link, &tpg->tpg_lun_hlist);
 	mutex_unlock(&tpg->tpg_lun_mutex);

commit 21aaa23b0ebbd19334fa461370c03cbb076b3295
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Thu Jan 7 22:09:27 2016 -0800

    target: Obtain se_node_acl->acl_kref during get_initiator_node_acl
    
    This patch addresses a long standing race where obtaining
    se_node_acl->acl_kref in __transport_register_session()
    happens a bit too late, and leaves open the potential
    for core_tpg_del_initiator_node_acl() to hit a NULL
    pointer dereference.
    
    Instead, take ->acl_kref in core_tpg_get_initiator_node_acl()
    while se_portal_group->acl_node_mutex is held, and move the
    final target_put_nacl() from transport_deregister_session()
    into transport_free_session() so that fabric driver login
    failure handling using the modern method to still work
    as expected.
    
    Also, update core_tpg_get_initiator_node_acl() to take
    an extra reference for dynamically generated acls for
    demo-mode, before returning to fabric caller.  Also
    update iscsi-target sendtargets special case handling
    to use target_tpg_has_node_acl() when checking if
    demo_mode_discovery == true during discovery lookup.
    
    Note the existing wait_for_completion(&acl->acl_free_comp)
    in core_tpg_del_initiator_node_acl() does not change.
    
    Cc: Sagi Grimberg <sagig@mellanox.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.de>
    Cc: Andy Grover <agrover@redhat.com>
    Cc: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 67be44da29ff..3608b1b5ecf7 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -75,9 +75,21 @@ struct se_node_acl *core_tpg_get_initiator_node_acl(
 	unsigned char *initiatorname)
 {
 	struct se_node_acl *acl;
-
+	/*
+	 * Obtain se_node_acl->acl_kref using fabric driver provided
+	 * initiatorname[] during node acl endpoint lookup driven by
+	 * new se_session login.
+	 *
+	 * The reference is held until se_session shutdown -> release
+	 * occurs via fabric driver invoked transport_deregister_session()
+	 * or transport_free_session() code.
+	 */
 	mutex_lock(&tpg->acl_node_mutex);
 	acl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);
+	if (acl) {
+		if (!kref_get_unless_zero(&acl->acl_kref))
+			acl = NULL;
+	}
 	mutex_unlock(&tpg->acl_node_mutex);
 
 	return acl;
@@ -224,6 +236,25 @@ static void target_add_node_acl(struct se_node_acl *acl)
 		acl->initiatorname);
 }
 
+bool target_tpg_has_node_acl(struct se_portal_group *tpg,
+			     const char *initiatorname)
+{
+	struct se_node_acl *acl;
+	bool found = false;
+
+	mutex_lock(&tpg->acl_node_mutex);
+	list_for_each_entry(acl, &tpg->acl_node_list, acl_list) {
+		if (!strcmp(acl->initiatorname, initiatorname)) {
+			found = true;
+			break;
+		}
+	}
+	mutex_unlock(&tpg->acl_node_mutex);
+
+	return found;
+}
+EXPORT_SYMBOL(target_tpg_has_node_acl);
+
 struct se_node_acl *core_tpg_check_initiator_node_acl(
 	struct se_portal_group *tpg,
 	unsigned char *initiatorname)
@@ -240,6 +271,15 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 	acl = target_alloc_node_acl(tpg, initiatorname);
 	if (!acl)
 		return NULL;
+	/*
+	 * When allocating a dynamically generated node_acl, go ahead
+	 * and take the extra kref now before returning to the fabric
+	 * driver caller.
+	 *
+	 * Note this reference will be released at session shutdown
+	 * time within transport_free_session() code.
+	 */
+	kref_get(&acl->acl_kref);
 	acl->dynamic_node_acl = 1;
 
 	/*

commit d36ad77f702356afb1009d2987b0ab55da4c7d57
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Thu Jan 7 22:15:06 2016 -0800

    target: Convert ACL change queue_depth se_session reference usage
    
    This patch converts core_tpg_set_initiator_node_queue_depth()
    to use struct se_node_acl->acl_sess_list when performing
    explicit se_tpg_tfo->shutdown_session() for active sessions,
    in order for new se_node_acl->queue_depth to take effect.
    
    This follows how core_tpg_del_initiator_node_acl() currently
    works when invoking se_tpg_tfo->shutdown-session(), and ahead
    of the next patch to take se_node_acl->acl_kref during lookup,
    the extra get_initiator_node_acl() can go away. In order to
    achieve this, go ahead and change target_get_session() to use
    kref_get_unless_zero() and propigate up the return value
    to know when a session is already being released.
    
    This is because se_node_acl->acl_group is already protecting
    se_node_acl->acl_group reference via configfs, and shutdown
    within core_tpg_del_initiator_node_acl() won't occur until
    sys_write() to core_tpg_set_initiator_node_queue_depth()
    attribute returns back to user-space.
    
    Also, drop the left-over iscsi-target hack, and obtain
    se_portal_group->session_lock in lio_tpg_shutdown_session()
    internally. Remove iscsi-target wrapper and unused se_tpg +
    force parameters and associated code.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Cc: Sagi Grimberg <sagig@mellanox.com>
    Cc: Hannes Reinecke <hare@suse.de>
    Cc: Andy Grover <agrover@redhat.com>
    Cc: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 62103a8cbe72..67be44da29ff 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -157,28 +157,25 @@ void core_tpg_add_node_to_devs(
 	mutex_unlock(&tpg->tpg_lun_mutex);
 }
 
-/*      core_set_queue_depth_for_node():
- *
- *
- */
-static int core_set_queue_depth_for_node(
-	struct se_portal_group *tpg,
-	struct se_node_acl *acl)
+static void
+target_set_nacl_queue_depth(struct se_portal_group *tpg,
+			    struct se_node_acl *acl, u32 queue_depth)
 {
+	acl->queue_depth = queue_depth;
+
 	if (!acl->queue_depth) {
-		pr_err("Queue depth for %s Initiator Node: %s is 0,"
+		pr_warn("Queue depth for %s Initiator Node: %s is 0,"
 			"defaulting to 1.\n", tpg->se_tpg_tfo->get_fabric_name(),
 			acl->initiatorname);
 		acl->queue_depth = 1;
 	}
-
-	return 0;
 }
 
 static struct se_node_acl *target_alloc_node_acl(struct se_portal_group *tpg,
 		const unsigned char *initiatorname)
 {
 	struct se_node_acl *acl;
+	u32 queue_depth;
 
 	acl = kzalloc(max(sizeof(*acl), tpg->se_tpg_tfo->node_acl_size),
 			GFP_KERNEL);
@@ -193,24 +190,20 @@ static struct se_node_acl *target_alloc_node_acl(struct se_portal_group *tpg,
 	spin_lock_init(&acl->nacl_sess_lock);
 	mutex_init(&acl->lun_entry_mutex);
 	atomic_set(&acl->acl_pr_ref_count, 0);
+
 	if (tpg->se_tpg_tfo->tpg_get_default_depth)
-		acl->queue_depth = tpg->se_tpg_tfo->tpg_get_default_depth(tpg);
+		queue_depth = tpg->se_tpg_tfo->tpg_get_default_depth(tpg);
 	else
-		acl->queue_depth = 1;
+		queue_depth = 1;
+	target_set_nacl_queue_depth(tpg, acl, queue_depth);
+
 	snprintf(acl->initiatorname, TRANSPORT_IQN_LEN, "%s", initiatorname);
 	acl->se_tpg = tpg;
 	acl->acl_index = scsi_get_new_index(SCSI_AUTH_INTR_INDEX);
 
 	tpg->se_tpg_tfo->set_default_node_attributes(acl);
 
-	if (core_set_queue_depth_for_node(tpg, acl) < 0)
-		goto out_free_acl;
-
 	return acl;
-
-out_free_acl:
-	kfree(acl);
-	return NULL;
 }
 
 static void target_add_node_acl(struct se_node_acl *acl)
@@ -327,7 +320,8 @@ void core_tpg_del_initiator_node_acl(struct se_node_acl *acl)
 		if (sess->sess_tearing_down != 0)
 			continue;
 
-		target_get_session(sess);
+		if (!target_get_session(sess))
+			continue;
 		list_move(&sess->sess_acl_list, &sess_list);
 	}
 	spin_unlock_irqrestore(&acl->nacl_sess_lock, flags);
@@ -364,108 +358,52 @@ void core_tpg_del_initiator_node_acl(struct se_node_acl *acl)
  *
  */
 int core_tpg_set_initiator_node_queue_depth(
-	struct se_portal_group *tpg,
-	unsigned char *initiatorname,
-	u32 queue_depth,
-	int force)
+	struct se_node_acl *acl,
+	u32 queue_depth)
 {
-	struct se_session *sess, *init_sess = NULL;
-	struct se_node_acl *acl;
+	LIST_HEAD(sess_list);
+	struct se_portal_group *tpg = acl->se_tpg;
+	struct se_session *sess, *sess_tmp;
 	unsigned long flags;
-	int dynamic_acl = 0;
-
-	mutex_lock(&tpg->acl_node_mutex);
-	acl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);
-	if (!acl) {
-		pr_err("Access Control List entry for %s Initiator"
-			" Node %s does not exists for TPG %hu, ignoring"
-			" request.\n", tpg->se_tpg_tfo->get_fabric_name(),
-			initiatorname, tpg->se_tpg_tfo->tpg_get_tag(tpg));
-		mutex_unlock(&tpg->acl_node_mutex);
-		return -ENODEV;
-	}
-	if (acl->dynamic_node_acl) {
-		acl->dynamic_node_acl = 0;
-		dynamic_acl = 1;
-	}
-	mutex_unlock(&tpg->acl_node_mutex);
-
-	spin_lock_irqsave(&tpg->session_lock, flags);
-	list_for_each_entry(sess, &tpg->tpg_sess_list, sess_list) {
-		if (sess->se_node_acl != acl)
-			continue;
-
-		if (!force) {
-			pr_err("Unable to change queue depth for %s"
-				" Initiator Node: %s while session is"
-				" operational.  To forcefully change the queue"
-				" depth and force session reinstatement"
-				" use the \"force=1\" parameter.\n",
-				tpg->se_tpg_tfo->get_fabric_name(), initiatorname);
-			spin_unlock_irqrestore(&tpg->session_lock, flags);
-
-			mutex_lock(&tpg->acl_node_mutex);
-			if (dynamic_acl)
-				acl->dynamic_node_acl = 1;
-			mutex_unlock(&tpg->acl_node_mutex);
-			return -EEXIST;
-		}
-		/*
-		 * Determine if the session needs to be closed by our context.
-		 */
-		if (!tpg->se_tpg_tfo->shutdown_session(sess))
-			continue;
-
-		init_sess = sess;
-		break;
-	}
+	int rc;
 
 	/*
 	 * User has requested to change the queue depth for a Initiator Node.
 	 * Change the value in the Node's struct se_node_acl, and call
-	 * core_set_queue_depth_for_node() to add the requested queue depth.
-	 *
-	 * Finally call  tpg->se_tpg_tfo->close_session() to force session
-	 * reinstatement to occur if there is an active session for the
-	 * $FABRIC_MOD Initiator Node in question.
+	 * target_set_nacl_queue_depth() to set the new queue depth.
 	 */
-	acl->queue_depth = queue_depth;
+	target_set_nacl_queue_depth(tpg, acl, queue_depth);
+
+	spin_lock_irqsave(&acl->nacl_sess_lock, flags);
+	list_for_each_entry_safe(sess, sess_tmp, &acl->acl_sess_list,
+				 sess_acl_list) {
+		if (sess->sess_tearing_down != 0)
+			continue;
+		if (!target_get_session(sess))
+			continue;
+		spin_unlock_irqrestore(&acl->nacl_sess_lock, flags);
 
-	if (core_set_queue_depth_for_node(tpg, acl) < 0) {
-		spin_unlock_irqrestore(&tpg->session_lock, flags);
 		/*
-		 * Force session reinstatement if
-		 * core_set_queue_depth_for_node() failed, because we assume
-		 * the $FABRIC_MOD has already the set session reinstatement
-		 * bit from tpg->se_tpg_tfo->shutdown_session() called above.
+		 * Finally call tpg->se_tpg_tfo->close_session() to force session
+		 * reinstatement to occur if there is an active session for the
+		 * $FABRIC_MOD Initiator Node in question.
 		 */
-		if (init_sess)
-			tpg->se_tpg_tfo->close_session(init_sess);
-
-		mutex_lock(&tpg->acl_node_mutex);
-		if (dynamic_acl)
-			acl->dynamic_node_acl = 1;
-		mutex_unlock(&tpg->acl_node_mutex);
-		return -EINVAL;
+		rc = tpg->se_tpg_tfo->shutdown_session(sess);
+		target_put_session(sess);
+		if (!rc) {
+			spin_lock_irqsave(&acl->nacl_sess_lock, flags);
+			continue;
+		}
+		target_put_session(sess);
+		spin_lock_irqsave(&acl->nacl_sess_lock, flags);
 	}
-	spin_unlock_irqrestore(&tpg->session_lock, flags);
-	/*
-	 * If the $FABRIC_MOD session for the Initiator Node ACL exists,
-	 * forcefully shutdown the $FABRIC_MOD session/nexus.
-	 */
-	if (init_sess)
-		tpg->se_tpg_tfo->close_session(init_sess);
+	spin_unlock_irqrestore(&acl->nacl_sess_lock, flags);
 
 	pr_debug("Successfully changed queue depth to: %d for Initiator"
-		" Node: %s on %s Target Portal Group: %u\n", queue_depth,
-		initiatorname, tpg->se_tpg_tfo->get_fabric_name(),
+		" Node: %s on %s Target Portal Group: %u\n", acl->queue_depth,
+		acl->initiatorname, tpg->se_tpg_tfo->get_fabric_name(),
 		tpg->se_tpg_tfo->tpg_get_tag(tpg));
 
-	mutex_lock(&tpg->acl_node_mutex);
-	if (dynamic_acl)
-		acl->dynamic_node_acl = 1;
-	mutex_unlock(&tpg->acl_node_mutex);
-
 	return 0;
 }
 EXPORT_SYMBOL(core_tpg_set_initiator_node_queue_depth);

commit dba5ccc7a67713fccb7726057d8df826672a7257
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Tue Jan 5 14:45:03 2016 +0100

    target: Remove an unused variable
    
    The num_node_acls member in struct se_portal_group is modified
    by several functions but is never read. Hence remove it.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Andy Grover <agrover@redhat.com>
    Cc: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 5fb9dd7f08bb..62103a8cbe72 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -219,7 +219,6 @@ static void target_add_node_acl(struct se_node_acl *acl)
 
 	mutex_lock(&tpg->acl_node_mutex);
 	list_add_tail(&acl->acl_list, &tpg->acl_node_list);
-	tpg->num_node_acls++;
 	mutex_unlock(&tpg->acl_node_mutex);
 
 	pr_debug("%s_TPG[%hu] - Added %s ACL with TCQ Depth: %d for %s"
@@ -318,7 +317,6 @@ void core_tpg_del_initiator_node_acl(struct se_node_acl *acl)
 		acl->dynamic_node_acl = 0;
 	}
 	list_del(&acl->acl_list);
-	tpg->num_node_acls--;
 	mutex_unlock(&tpg->acl_node_mutex);
 
 	spin_lock_irqsave(&acl->nacl_sess_lock, flags);
@@ -595,7 +593,6 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 	 */
 	list_for_each_entry_safe(nacl, nacl_tmp, &node_list, acl_list) {
 		list_del(&nacl->acl_list);
-		se_tpg->num_node_acls--;
 
 		core_tpg_wait_for_nacl_pr_ref(nacl);
 		core_free_device_list_for_node(nacl, se_tpg);

commit eeeb9522231118138be418ff527dc8c9050f4707
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Tue Sep 15 17:27:35 2015 -0700

    target: Propigate backend read-only to core_tpg_add_lun
    
    This patch adds a DF_READ_ONLY flag that is used by IBLOCK to
    signal when a backend has been set to read-only mode, in order
    to propigate read-only status up to core_tpg_add_lun() for all
    future LUN fabric exports.
    
    With this is place, existing emulation for reporting read-only
    in spc_emulate_modesense() and normal transport_lookup_cmd_lun()
    TCM_WRITE_PROTECTED status checking just works as expected.
    
    Reported-by: Joeue Deng <joeue404@gmail.com>
    Reported-by: Andy Grover <agrover@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 2d0381dd105c..5fb9dd7f08bb 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -668,7 +668,10 @@ int core_tpg_add_lun(
 	list_add_tail(&lun->lun_dev_link, &dev->dev_sep_list);
 	spin_unlock(&dev->se_port_lock);
 
-	lun->lun_access = lun_access;
+	if (dev->dev_flags & DF_READ_ONLY)
+		lun->lun_access = TRANSPORT_LUNFLAGS_READ_ONLY;
+	else
+		lun->lun_access = lun_access;
 	if (!(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))
 		hlist_add_head_rcu(&lun->link, &tpg->tpg_lun_hlist);
 	mutex_unlock(&tpg->tpg_lun_mutex);

commit e986a35aba67558381d5cec59a14c4d0b20f0d47
Author: Hannes Reinecke <hare@suse.de>
Date:   Thu Jun 18 11:43:38 2015 +0200

    tcm_loop: Send I_T_NEXUS_LOSS_OCCURRED UA
    
    If the virtual SAS link is set to 'offline' we should be
    queueing an I_T_NEXUS_LOSS_OCCURRED UA.
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index babde4ad841f..2d0381dd105c 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -41,6 +41,7 @@
 #include "target_core_internal.h"
 #include "target_core_alua.h"
 #include "target_core_pr.h"
+#include "target_core_ua.h"
 
 extern struct se_device *g_lun0_dev;
 
@@ -83,6 +84,22 @@ struct se_node_acl *core_tpg_get_initiator_node_acl(
 }
 EXPORT_SYMBOL(core_tpg_get_initiator_node_acl);
 
+void core_allocate_nexus_loss_ua(
+	struct se_node_acl *nacl)
+{
+	struct se_dev_entry *deve;
+
+	if (!nacl)
+		return;
+
+	rcu_read_lock();
+	hlist_for_each_entry_rcu(deve, &nacl->lun_entry_hlist, link)
+		core_scsi3_ua_allocate(deve, 0x29,
+			ASCQ_29H_NEXUS_LOSS_OCCURRED);
+	rcu_read_unlock();
+}
+EXPORT_SYMBOL(core_allocate_nexus_loss_ua);
+
 /*	core_tpg_add_node_to_devs():
  *
  *

commit 5c755fe142b421d295e7dd64a9833c12abbfd28e
Merge: 6d7c8e1b3a1f 2ec1e9e20701
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 4 14:13:43 2015 -0700

    Merge branch 'for-next' of git://git.kernel.org/pub/scm/linux/kernel/git/nab/target-pending
    
    Pull SCSI target updates from Nicholas Bellinger:
     "It's been a busy development cycle for target-core in a number of
      different areas.
    
      The fabric API usage for se_node_acl allocation is now within
      target-core code, dropping the external API callers for all fabric
      drivers tree-wide.
    
      There is a new conversion to RCU hlists for se_node_acl and
      se_portal_group LUN mappings, that turns fast-past LUN lookup into a
      completely lockless code-path.  It also removes the original
      hard-coded limitation of 256 LUNs per fabric endpoint.
    
      The configfs attributes for backends can now be shared between core
      and driver code, allowing existing drivers to use common code while
      still allowing flexibility for new backend provided attributes.
    
      The highlights include:
    
       - Merge sbc_verify_dif_* into common code (sagi)
       - Remove iscsi-target support for obsolete IFMarker/OFMarker
         (Christophe Vu-Brugier)
       - Add bidi support in target/user backend (ilias + vangelis + agover)
       - Move se_node_acl allocation into target-core code (hch)
       - Add crc_t10dif_update common helper (akinobu + mkp)
       - Handle target-core odd SGL mapping for data transfer memory
         (akinobu)
       - Move transport ID handling into target-core (hch)
       - Move task tag into struct se_cmd + support 64-bit tags (bart)
       - Convert se_node_acl->device_list[] to RCU hlist (nab + hch +
         paulmck)
       - Convert se_portal_group->tpg_lun_list[] to RCU hlist (nab + hch +
         paulmck)
       - Simplify target backend driver registration (hch)
       - Consolidate + simplify target backend attribute implementations
         (hch + nab)
       - Subsume se_port + t10_alua_tg_pt_gp_member into se_lun (hch)
       - Drop lun_sep_lock for se_lun->lun_se_dev RCU usage (hch + nab)
       - Drop unnecessary core_tpg_register TFO parameter (nab)
       - Use 64-bit LUNs tree-wide (hannes)
       - Drop left-over TARGET_MAX_LUNS_PER_TRANSPORT limit (hannes)"
    
    * 'for-next' of git://git.kernel.org/pub/scm/linux/kernel/git/nab/target-pending: (76 commits)
      target: Bump core version to v5.0
      target: remove target_core_configfs.h
      target: remove unused TARGET_CORE_CONFIG_ROOT define
      target: consolidate version defines
      target: implement WRITE_SAME with UNMAP bit using ->execute_unmap
      target: simplify UNMAP handling
      target: replace se_cmd->execute_rw with a protocol_data field
      target/user: Fix inconsistent kmap_atomic/kunmap_atomic
      target: Send UA when changing LUN inventory
      target: Send UA upon LUN RESET tmr completion
      target: Send UA on ALUA target port group change
      target: Convert se_lun->lun_deve_lock to normal spinlock
      target: use 'se_dev_entry' when allocating UAs
      target: Remove 'ua_nacl' pointer from se_ua structure
      target_core_alua: Correct UA handling when switching states
      xen-scsiback: Fix compile warning for 64-bit LUN
      target: Remove TARGET_MAX_LUNS_PER_TRANSPORT
      target: use 64-bit LUNs
      target: Drop duplicate + unused se_dev_check_wce
      target: Drop unnecessary core_tpg_register TFO parameter
      ...

commit 6de2ce5b8cb6ff3562de34ea2584b0e501373f56
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jun 19 15:14:41 2015 +0200

    target: remove target_core_configfs.h
    
    The remaining defintions are private to the target core and can be merged
    into target_core_internal.h.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Andy Grover <agrover@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index aa39bc89227b..10321a8ffbb0 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -37,7 +37,6 @@
 
 #include <target/target_core_base.h>
 #include <target/target_core_backend.h>
-#include <target/target_core_configfs.h>
 #include <target/target_core_fabric.h>
 
 #include "target_core_internal.h"

commit 196e2e2aa362850bf45bcb14b9517124b23b921e
Author: Hannes Reinecke <hare@suse.de>
Date:   Wed Jun 10 08:41:23 2015 +0200

    target: Remove TARGET_MAX_LUNS_PER_TRANSPORT
    
    LUN allocation is now fully dynamic, so there is no need to
    artificially restrain the number of exported LUNs.
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 82ed8a0f3f0e..aa39bc89227b 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -602,15 +602,6 @@ struct se_lun *core_tpg_alloc_lun(
 {
 	struct se_lun *lun;
 
-	if (unpacked_lun > (TRANSPORT_MAX_LUNS_PER_TPG-1)) {
-		pr_err("%s LUN: %llu exceeds TRANSPORT_MAX_LUNS_PER_TPG"
-			"-1: %u for Target Portal Group: %u\n",
-			tpg->se_tpg_tfo->get_fabric_name(),
-			unpacked_lun, TRANSPORT_MAX_LUNS_PER_TPG-1,
-			tpg->se_tpg_tfo->tpg_get_tag(tpg));
-		return ERR_PTR(-EOVERFLOW);
-	}
-
 	lun = kzalloc(sizeof(*lun), GFP_KERNEL);
 	if (!lun) {
 		pr_err("Unable to allocate se_lun memory\n");

commit f2d30680204f20b815e6796437923fb870b6c193
Author: Hannes Reinecke <hare@suse.de>
Date:   Wed Jun 10 08:41:22 2015 +0200

    target: use 64-bit LUNs
    
    As we're now using a list to hold the LUNs the target core
    can now converted to use 64-bit LUNs internally.
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 2e77eebe1671..82ed8a0f3f0e 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -122,7 +122,7 @@ void core_tpg_add_node_to_devs(
 				lun_access = TRANSPORT_LUNFLAGS_READ_WRITE;
 		}
 
-		pr_debug("TARGET_CORE[%s]->TPG[%u]_LUN[%u] - Adding %s"
+		pr_debug("TARGET_CORE[%s]->TPG[%u]_LUN[%llu] - Adding %s"
 			" access for LUN in Demo Mode\n",
 			tpg->se_tpg_tfo->get_fabric_name(),
 			tpg->se_tpg_tfo->tpg_get_tag(tpg), lun->unpacked_lun,
@@ -598,12 +598,12 @@ EXPORT_SYMBOL(core_tpg_deregister);
 
 struct se_lun *core_tpg_alloc_lun(
 	struct se_portal_group *tpg,
-	u32 unpacked_lun)
+	u64 unpacked_lun)
 {
 	struct se_lun *lun;
 
 	if (unpacked_lun > (TRANSPORT_MAX_LUNS_PER_TPG-1)) {
-		pr_err("%s LUN: %u exceeds TRANSPORT_MAX_LUNS_PER_TPG"
+		pr_err("%s LUN: %llu exceeds TRANSPORT_MAX_LUNS_PER_TPG"
 			"-1: %u for Target Portal Group: %u\n",
 			tpg->se_tpg_tfo->get_fabric_name(),
 			unpacked_lun, TRANSPORT_MAX_LUNS_PER_TPG-1,

commit bc0c94b1404b225b19b6b53a0e508f43e269ed1e
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Wed May 20 21:48:03 2015 -0700

    target: Drop unnecessary core_tpg_register TFO parameter
    
    This patch drops unnecessary target_core_fabric_ops parameter usage
    for core_tpg_register() during fabric driver TFO->fabric_make_tpg()
    se_portal_group creation callback execution.
    
    Instead, use the existing se_wwn->wwn_tf->tf_ops pointer to ensure
    fabric driver is really using the same TFO provided at module_init
    time.
    
    Also go ahead and drop the forward TFO declarations tree-wide, and
    handling the special case for iscsi-target discovery TPG.
    
    Cc: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index b9fcf2c4898e..2e77eebe1671 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -37,6 +37,7 @@
 
 #include <target/target_core_base.h>
 #include <target/target_core_backend.h>
+#include <target/target_core_configfs.h>
 #include <target/target_core_fabric.h>
 
 #include "target_core_internal.h"
@@ -487,16 +488,34 @@ static void core_tpg_lun_ref_release(struct percpu_ref *ref)
 }
 
 int core_tpg_register(
-	const struct target_core_fabric_ops *tfo,
 	struct se_wwn *se_wwn,
 	struct se_portal_group *se_tpg,
 	int proto_id)
 {
 	int ret;
 
+	if (!se_tpg)
+		return -EINVAL;
+	/*
+	 * For the typical case where core_tpg_register() is called by a
+	 * fabric driver from target_core_fabric_ops->fabric_make_tpg()
+	 * configfs context, use the original tf_ops pointer already saved
+	 * by target-core in target_fabric_make_wwn().
+	 *
+	 * Otherwise, for special cases like iscsi-target discovery TPGs
+	 * the caller is responsible for setting ->se_tpg_tfo ahead of
+	 * calling core_tpg_register().
+	 */
+	if (se_wwn)
+		se_tpg->se_tpg_tfo = se_wwn->wwn_tf->tf_ops;
+
+	if (!se_tpg->se_tpg_tfo) {
+		pr_err("Unable to locate se_tpg->se_tpg_tfo pointer\n");
+		return -EINVAL;
+	}
+
 	INIT_HLIST_HEAD(&se_tpg->tpg_lun_hlist);
 	se_tpg->proto_id = proto_id;
-	se_tpg->se_tpg_tfo = tfo;
 	se_tpg->se_tpg_wwn = se_wwn;
 	atomic_set(&se_tpg->tpg_pr_ref_count, 0);
 	INIT_LIST_HEAD(&se_tpg->acl_node_list);
@@ -524,9 +543,10 @@ int core_tpg_register(
 	spin_unlock_bh(&tpg_lock);
 
 	pr_debug("TARGET_CORE[%s]: Allocated portal_group for endpoint: %s, "
-		 "Proto: %d, Portal Tag: %u\n", tfo->get_fabric_name(),
-		tfo->tpg_get_wwn(se_tpg) ? tfo->tpg_get_wwn(se_tpg) : NULL,
-		se_tpg->proto_id, tfo->tpg_get_tag(se_tpg));
+		 "Proto: %d, Portal Tag: %u\n", se_tpg->se_tpg_tfo->get_fabric_name(),
+		se_tpg->se_tpg_tfo->tpg_get_wwn(se_tpg) ?
+		se_tpg->se_tpg_tfo->tpg_get_wwn(se_tpg) : NULL,
+		se_tpg->proto_id, se_tpg->se_tpg_tfo->tpg_get_tag(se_tpg));
 
 	return 0;
 }

commit ba929992522b6d1f866b7021bc50da66f8fdd743
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Fri May 8 10:11:12 2015 +0200

    target: Minimize SCSI header #include directives
    
    Only include SCSI initiator header files in target code that needs
    these header files, namely the SCSI pass-through code and the tcm_loop
    driver. Change SCSI_SENSE_BUFFERSIZE into TRANSPORT_SENSE_BUFFER in
    target code because the former is intended for initiator code and the
    latter for target code. With this patch the only initiator include
    directives in target code that remain are as follows:
    
    $ git grep -nHE 'include .scsi/(scsi.h|scsi_host.h|scsi_device.h|scsi_cmnd.h)' drivers/target drivers/infiniband/ulp/{isert,srpt} drivers/usb/gadget/legacy/tcm_*.[ch] drivers/{vhost,xen} include/{target,trace/events/target.h}
    drivers/target/loopback/tcm_loop.c:29:#include <scsi/scsi.h>
    drivers/target/loopback/tcm_loop.c:31:#include <scsi/scsi_host.h>
    drivers/target/loopback/tcm_loop.c:32:#include <scsi/scsi_device.h>
    drivers/target/loopback/tcm_loop.c:33:#include <scsi/scsi_cmnd.h>
    drivers/target/target_core_pscsi.c:39:#include <scsi/scsi_device.h>
    drivers/target/target_core_pscsi.c:40:#include <scsi/scsi_host.h>
    drivers/xen/xen-scsiback.c:52:#include <scsi/scsi_host.h> /* SG_ALL */
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: James Bottomley <JBottomley@Odin.com>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 47f064415bf6..84de757bd458 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -32,8 +32,7 @@
 #include <linux/export.h>
 #include <net/sock.h>
 #include <net/tcp.h>
-#include <scsi/scsi.h>
-#include <scsi/scsi_cmnd.h>
+#include <scsi/scsi_proto.h>
 
 #include <target/target_core_base.h>
 #include <target/target_core_backend.h>

commit 9e37d042cfcb003b885bb4c531cd6f07f62647d1
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Wed May 20 21:21:08 2015 -0700

    target: Drop se_lun->lun_active for existing percpu lun_ref
    
    With se_port_t and t10_alua_tg_pt_gp_member being absored into se_lun,
    there is no need for an extra atomic_t based reference count for PR
    ALL_TG_PT=1 and ALUA access state transition.
    
    Go ahead and use the existing percpu se_lun->lun_ref instead, and
    convert the two special cases to percpu_ref_tryget_live() to avoid
    se_lun if transport_clear_lun_ref() has already been invoked to
    shutdown the se_lun.
    
    Cc: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 5b30940ccaf2..b9fcf2c4898e 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -607,7 +607,6 @@ struct se_lun *core_tpg_alloc_lun(
 	mutex_init(&lun->lun_tg_pt_md_mutex);
 	INIT_LIST_HEAD(&lun->lun_tg_pt_gp_link);
 	spin_lock_init(&lun->lun_tg_pt_gp_lock);
-	atomic_set(&lun->lun_active, 0);
 	lun->lun_tpg = tpg;
 
 	return lun;
@@ -667,13 +666,16 @@ void core_tpg_remove_lun(
 	struct se_device *dev = rcu_dereference_raw(lun->lun_se_dev);
 
 	core_clear_lun_from_tpg(lun, tpg);
+	/*
+	 * Wait for any active I/O references to percpu se_lun->lun_ref to
+	 * be released.  Also, se_lun->lun_ref is now used by PR and ALUA
+	 * logic when referencing a remote target port during ALL_TGT_PT=1
+	 * and generating UNIT_ATTENTIONs for ALUA access state transition.
+	 */
 	transport_clear_lun_ref(lun);
 
 	mutex_lock(&tpg->tpg_lun_mutex);
 	if (lun->lun_se_dev) {
-		while (atomic_read(&lun->lun_active))
-			cpu_relax();
-
 		target_detach_tg_pt_gp(lun);
 
 		spin_lock(&dev->se_port_lock);

commit 4cc987eaff9144182cde88d6d132420c28d3f81b
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Tue May 19 00:03:07 2015 -0700

    target: Drop lun_sep_lock for se_lun->lun_se_dev RCU usage
    
    With se_port and t10_alua_tg_pt_gp_member being absored into se_lun,
    there is no need for an extra lock to protect se_lun->lun_se_dev
    assignment.
    
    This patch also converts backend drivers to use call_rcu() release
    to allow any se_device readers to complete.  The call_rcu() instead
    of kfree_rcu() is required here because se_device is embedded into
    the backend driver specific structure.
    
    Also, convert se_lun->lun_stats to use atomic_long_t within the
    target_complete_ok_work() completion callback, and add FIXME for
    transport_lookup_tmr_lun() with se_lun->lun_ref.
    
    Finally, update sbp_update_unit_directory() special case usage with
    proper rcu_dereference_raw() and configfs symlink comment.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Chris Boot <bootc@bootc.net>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 499b1399035a..5b30940ccaf2 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -102,7 +102,8 @@ void core_tpg_add_node_to_devs(
 		if (lun_orig && lun != lun_orig)
 			continue;
 
-		dev = lun->lun_se_dev;
+		dev = rcu_dereference_check(lun->lun_se_dev,
+					    lockdep_is_held(&tpg->tpg_lun_mutex));
 		/*
 		 * By default in LIO-Target $FABRIC_MOD,
 		 * demo_mode_write_protect is ON, or READ_ONLY;
@@ -598,7 +599,6 @@ struct se_lun *core_tpg_alloc_lun(
 	lun->unpacked_lun = unpacked_lun;
 	lun->lun_link_magic = SE_LUN_LINK_MAGIC;
 	atomic_set(&lun->lun_acl_count, 0);
-	spin_lock_init(&lun->lun_sep_lock);
 	init_completion(&lun->lun_ref_comp);
 	INIT_LIST_HEAD(&lun->lun_deve_list);
 	INIT_LIST_HEAD(&lun->lun_dev_link);
@@ -636,12 +636,8 @@ int core_tpg_add_lun(
 
 	mutex_lock(&tpg->tpg_lun_mutex);
 
-	spin_lock(&lun->lun_sep_lock);
-	lun->lun_index = dev->dev_index;
-	lun->lun_se_dev = dev;
-	spin_unlock(&lun->lun_sep_lock);
-
 	spin_lock(&dev->se_port_lock);
+	lun->lun_index = dev->dev_index;
 	rcu_assign_pointer(lun->lun_se_dev, dev);
 	dev->export_count++;
 	list_add_tail(&lun->lun_dev_link, &dev->dev_sep_list);
@@ -664,7 +660,11 @@ void core_tpg_remove_lun(
 	struct se_portal_group *tpg,
 	struct se_lun *lun)
 {
-	struct se_device *dev = lun->lun_se_dev;
+	/*
+	 * rcu_dereference_raw protected by se_lun->lun_group symlink
+	 * reference to se_device->dev_group.
+	 */
+	struct se_device *dev = rcu_dereference_raw(lun->lun_se_dev);
 
 	core_clear_lun_from_tpg(lun, tpg);
 	transport_clear_lun_ref(lun);

commit adf653f92f38e80a78bb77e912d49bcc8055330f
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon May 25 21:33:08 2015 -0700

    target: Subsume se_port + t10_alua_tg_pt_gp_member into se_lun
    
    This patch eliminates all se_port + t10_alua_tg_pt_gp_member usage,
    and converts current users to direct se_lun pointer dereference.
    
    This includes the removal of core_export_port(), core_release_port()
    core_dev_export() and core_dev_unexport().  Along with conversion
    of special case se_lun pointer dereference within PR ALL_TG_PT=1
    and ALUA access state transition UNIT_ATTENTION handling.
    
    Also, update core_enable_device_list_for_node() to reference the
    new per se_lun->lun_deve_list when creating a new entry, or
    replacing an existing one via RCU.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index fd531fcf3191..499b1399035a 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -40,6 +40,7 @@
 #include <target/target_core_fabric.h>
 
 #include "target_core_internal.h"
+#include "target_core_alua.h"
 #include "target_core_pr.h"
 
 extern struct se_device *g_lun0_dev;
@@ -484,32 +485,14 @@ static void core_tpg_lun_ref_release(struct percpu_ref *ref)
 	complete(&lun->lun_ref_comp);
 }
 
-static int core_tpg_setup_virtual_lun0(struct se_portal_group *se_tpg)
-{
-	/* Set in core_dev_setup_virtual_lun0() */
-	struct se_device *dev = g_lun0_dev;
-	struct se_lun *lun = &se_tpg->tpg_virt_lun0;
-	u32 lun_access = TRANSPORT_LUNFLAGS_READ_ONLY;
-	int ret;
-
-	lun->unpacked_lun = 0;
-	atomic_set(&lun->lun_acl_count, 0);
-	spin_lock_init(&lun->lun_sep_lock);
-	init_completion(&lun->lun_ref_comp);
-
-	ret = core_tpg_add_lun(se_tpg, lun, lun_access, dev);
-	if (ret < 0)
-		return ret;
-
-	return 0;
-}
-
 int core_tpg_register(
 	const struct target_core_fabric_ops *tfo,
 	struct se_wwn *se_wwn,
 	struct se_portal_group *se_tpg,
 	int proto_id)
 {
+	int ret;
+
 	INIT_HLIST_HEAD(&se_tpg->tpg_lun_hlist);
 	se_tpg->proto_id = proto_id;
 	se_tpg->se_tpg_tfo = tfo;
@@ -523,8 +506,16 @@ int core_tpg_register(
 	mutex_init(&se_tpg->acl_node_mutex);
 
 	if (se_tpg->proto_id >= 0) {
-		if (core_tpg_setup_virtual_lun0(se_tpg) < 0)
-			return -ENOMEM;
+		se_tpg->tpg_virt_lun0 = core_tpg_alloc_lun(se_tpg, 0);
+		if (IS_ERR(se_tpg->tpg_virt_lun0))
+			return PTR_ERR(se_tpg->tpg_virt_lun0);
+
+		ret = core_tpg_add_lun(se_tpg, se_tpg->tpg_virt_lun0,
+				TRANSPORT_LUNFLAGS_READ_ONLY, g_lun0_dev);
+		if (ret < 0) {
+			kfree(se_tpg->tpg_virt_lun0);
+			return ret;
+		}
 	}
 
 	spin_lock_bh(&tpg_lock);
@@ -575,8 +566,10 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 		kfree(nacl);
 	}
 
-	if (se_tpg->proto_id >= 0)
-		core_tpg_remove_lun(se_tpg, &se_tpg->tpg_virt_lun0);
+	if (se_tpg->proto_id >= 0) {
+		core_tpg_remove_lun(se_tpg, se_tpg->tpg_virt_lun0);
+		kfree_rcu(se_tpg->tpg_virt_lun0, rcu_head);
+	}
 
 	return 0;
 }
@@ -607,6 +600,15 @@ struct se_lun *core_tpg_alloc_lun(
 	atomic_set(&lun->lun_acl_count, 0);
 	spin_lock_init(&lun->lun_sep_lock);
 	init_completion(&lun->lun_ref_comp);
+	INIT_LIST_HEAD(&lun->lun_deve_list);
+	INIT_LIST_HEAD(&lun->lun_dev_link);
+	atomic_set(&lun->lun_tg_pt_secondary_offline, 0);
+	spin_lock_init(&lun->lun_deve_lock);
+	mutex_init(&lun->lun_tg_pt_md_mutex);
+	INIT_LIST_HEAD(&lun->lun_tg_pt_gp_link);
+	spin_lock_init(&lun->lun_tg_pt_gp_lock);
+	atomic_set(&lun->lun_active, 0);
+	lun->lun_tpg = tpg;
 
 	return lun;
 }
@@ -622,21 +624,40 @@ int core_tpg_add_lun(
 	ret = percpu_ref_init(&lun->lun_ref, core_tpg_lun_ref_release, 0,
 			      GFP_KERNEL);
 	if (ret < 0)
-		return ret;
+		goto out;
 
-	ret = core_dev_export(dev, tpg, lun);
-	if (ret < 0) {
-		percpu_ref_exit(&lun->lun_ref);
-		return ret;
-	}
+	ret = core_alloc_rtpi(lun, dev);
+	if (ret)
+		goto out_kill_ref;
+
+	if (!(dev->transport->transport_flags & TRANSPORT_FLAG_PASSTHROUGH) &&
+	    !(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))
+		target_attach_tg_pt_gp(lun, dev->t10_alua.default_tg_pt_gp);
 
 	mutex_lock(&tpg->tpg_lun_mutex);
+
+	spin_lock(&lun->lun_sep_lock);
+	lun->lun_index = dev->dev_index;
+	lun->lun_se_dev = dev;
+	spin_unlock(&lun->lun_sep_lock);
+
+	spin_lock(&dev->se_port_lock);
+	rcu_assign_pointer(lun->lun_se_dev, dev);
+	dev->export_count++;
+	list_add_tail(&lun->lun_dev_link, &dev->dev_sep_list);
+	spin_unlock(&dev->se_port_lock);
+
 	lun->lun_access = lun_access;
 	if (!(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))
 		hlist_add_head_rcu(&lun->link, &tpg->tpg_lun_hlist);
 	mutex_unlock(&tpg->tpg_lun_mutex);
 
 	return 0;
+
+out_kill_ref:
+	percpu_ref_exit(&lun->lun_ref);
+out:
+	return ret;
 }
 
 void core_tpg_remove_lun(
@@ -648,9 +669,19 @@ void core_tpg_remove_lun(
 	core_clear_lun_from_tpg(lun, tpg);
 	transport_clear_lun_ref(lun);
 
-	core_dev_unexport(lun->lun_se_dev, tpg, lun);
-
 	mutex_lock(&tpg->tpg_lun_mutex);
+	if (lun->lun_se_dev) {
+		while (atomic_read(&lun->lun_active))
+			cpu_relax();
+
+		target_detach_tg_pt_gp(lun);
+
+		spin_lock(&dev->se_port_lock);
+		list_del(&lun->lun_dev_link);
+		dev->export_count--;
+		rcu_assign_pointer(lun->lun_se_dev, NULL);
+		spin_unlock(&dev->se_port_lock);
+	}
 	if (!(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))
 		hlist_del_rcu(&lun->link);
 	mutex_unlock(&tpg->tpg_lun_mutex);

commit b3eeea6619a0ed4f37138661c49339b21361d397
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Tue May 19 16:16:01 2015 +0200

    target: Simplify LUN shutdown code
    
    Instead of starting a thread from transport_clear_lun_ref() that
    waits for LUN shutdown, wait in that function for LUN shutdown
    to finish. Additionally, change the return type of
    transport_clear_lun_ref() from int to void.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 91f8ddb6d783..fd531fcf3191 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -494,7 +494,6 @@ static int core_tpg_setup_virtual_lun0(struct se_portal_group *se_tpg)
 
 	lun->unpacked_lun = 0;
 	atomic_set(&lun->lun_acl_count, 0);
-	init_completion(&lun->lun_shutdown_comp);
 	spin_lock_init(&lun->lun_sep_lock);
 	init_completion(&lun->lun_ref_comp);
 
@@ -606,7 +605,6 @@ struct se_lun *core_tpg_alloc_lun(
 	lun->unpacked_lun = unpacked_lun;
 	lun->lun_link_magic = SE_LUN_LINK_MAGIC;
 	atomic_set(&lun->lun_acl_count, 0);
-	init_completion(&lun->lun_shutdown_comp);
 	spin_lock_init(&lun->lun_sep_lock);
 	init_completion(&lun->lun_ref_comp);
 

commit 4624773765699ac3f4e0b918306b638cba385713
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Sun May 24 00:48:54 2015 -0700

    target: Drop left-over se_lun->lun_status
    
    Now that se_portal_group->tpg_lun_hlist is a RCU protected hlist,
    go ahead and drop the left-over lun->lun_status usage.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index f66c208386f8..91f8ddb6d783 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -98,8 +98,6 @@ void core_tpg_add_node_to_devs(
 
 	mutex_lock(&tpg->tpg_lun_mutex);
 	hlist_for_each_entry_rcu(lun, &tpg->tpg_lun_hlist, link) {
-		if (lun->lun_status != TRANSPORT_LUN_STATUS_ACTIVE)
-			continue;
 		if (lun_orig && lun != lun_orig)
 			continue;
 
@@ -495,7 +493,6 @@ static int core_tpg_setup_virtual_lun0(struct se_portal_group *se_tpg)
 	int ret;
 
 	lun->unpacked_lun = 0;
-	lun->lun_status = TRANSPORT_LUN_STATUS_FREE;
 	atomic_set(&lun->lun_acl_count, 0);
 	init_completion(&lun->lun_shutdown_comp);
 	spin_lock_init(&lun->lun_sep_lock);
@@ -608,7 +605,6 @@ struct se_lun *core_tpg_alloc_lun(
 	}
 	lun->unpacked_lun = unpacked_lun;
 	lun->lun_link_magic = SE_LUN_LINK_MAGIC;
-	lun->lun_status = TRANSPORT_LUN_STATUS_FREE;
 	atomic_set(&lun->lun_acl_count, 0);
 	init_completion(&lun->lun_shutdown_comp);
 	spin_lock_init(&lun->lun_sep_lock);
@@ -638,7 +634,6 @@ int core_tpg_add_lun(
 
 	mutex_lock(&tpg->tpg_lun_mutex);
 	lun->lun_access = lun_access;
-	lun->lun_status = TRANSPORT_LUN_STATUS_ACTIVE;
 	if (!(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))
 		hlist_add_head_rcu(&lun->link, &tpg->tpg_lun_hlist);
 	mutex_unlock(&tpg->tpg_lun_mutex);
@@ -658,7 +653,6 @@ void core_tpg_remove_lun(
 	core_dev_unexport(lun->lun_se_dev, tpg, lun);
 
 	mutex_lock(&tpg->tpg_lun_mutex);
-	lun->lun_status = TRANSPORT_LUN_STATUS_FREE;
 	if (!(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))
 		hlist_del_rcu(&lun->link);
 	mutex_unlock(&tpg->tpg_lun_mutex);

commit df9766ca9da5d9c1f2bb4eea9c9f16a2e7e8e1a5
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Fri May 22 02:05:19 2015 +0000

    target: Only reset specific dynamic entries during lun_group creation
    
    This patch changes core_tpg_add_node_to_devs() to avoid unnecessarly
    resetting every se_dev_entry in se_node_acl->tpg_lun_hlist when the
    operation is driven by an explicit configfs se_lun->lun_group creation
    via core_dev_add_lun() to only update a single se_lun.
    
    Otherwise for the second core_tpg_check_initiator_node_acl() case, go
    ahead and continue to scan the full set of currently active se_lun in
    se_portal_group->tpg_lun_hlist.
    
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 73c25bda5a25..f66c208386f8 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -89,7 +89,8 @@ EXPORT_SYMBOL(core_tpg_get_initiator_node_acl);
  */
 void core_tpg_add_node_to_devs(
 	struct se_node_acl *acl,
-	struct se_portal_group *tpg)
+	struct se_portal_group *tpg,
+	struct se_lun *lun_orig)
 {
 	u32 lun_access = 0;
 	struct se_lun *lun;
@@ -99,6 +100,8 @@ void core_tpg_add_node_to_devs(
 	hlist_for_each_entry_rcu(lun, &tpg->tpg_lun_hlist, link) {
 		if (lun->lun_status != TRANSPORT_LUN_STATUS_ACTIVE)
 			continue;
+		if (lun_orig && lun != lun_orig)
+			continue;
 
 		dev = lun->lun_se_dev;
 		/*
@@ -238,7 +241,7 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 	 */
 	if ((tpg->se_tpg_tfo->tpg_check_demo_mode_login_only == NULL) ||
 	    (tpg->se_tpg_tfo->tpg_check_demo_mode_login_only(tpg) != 1))
-		core_tpg_add_node_to_devs(acl, tpg);
+		core_tpg_add_node_to_devs(acl, tpg, NULL);
 
 	target_add_node_acl(acl);
 	return acl;

commit 84786546b6ff8d50c3e4c1ea877a872cf55d485a
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Sun Mar 8 08:04:44 2015 +0000

    target: Drop unused se_lun->lun_acl_list
    
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index e7745d21075b..73c25bda5a25 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -495,8 +495,6 @@ static int core_tpg_setup_virtual_lun0(struct se_portal_group *se_tpg)
 	lun->lun_status = TRANSPORT_LUN_STATUS_FREE;
 	atomic_set(&lun->lun_acl_count, 0);
 	init_completion(&lun->lun_shutdown_comp);
-	INIT_LIST_HEAD(&lun->lun_acl_list);
-	spin_lock_init(&lun->lun_acl_lock);
 	spin_lock_init(&lun->lun_sep_lock);
 	init_completion(&lun->lun_ref_comp);
 
@@ -610,8 +608,6 @@ struct se_lun *core_tpg_alloc_lun(
 	lun->lun_status = TRANSPORT_LUN_STATUS_FREE;
 	atomic_set(&lun->lun_acl_count, 0);
 	init_completion(&lun->lun_shutdown_comp);
-	INIT_LIST_HEAD(&lun->lun_acl_list);
-	spin_lock_init(&lun->lun_acl_lock);
 	spin_lock_init(&lun->lun_sep_lock);
 	init_completion(&lun->lun_ref_comp);
 

commit 22793de590ca23a1e49b0ce5353911121fcc32be
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Fri Mar 6 10:23:25 2015 +0000

    target: Convert core_tpg_deregister to use list splice
    
    This patch converts core_tpg_deregister() to perform a list splice
    for any remaining dynamically generated se_node_acls attached to
    se_tpg, before calling kfree(nacl) to free memory.
    
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 229e8278f4fe..e7745d21075b 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -547,6 +547,7 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 {
 	const struct target_core_fabric_ops *tfo = se_tpg->se_tpg_tfo;
 	struct se_node_acl *nacl, *nacl_tmp;
+	LIST_HEAD(node_list);
 
 	pr_debug("TARGET_CORE[%s]: Deallocating portal_group for endpoint: %s, "
 		 "Proto: %d, Portal Tag: %u\n", tfo->get_fabric_name(),
@@ -560,25 +561,22 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 	while (atomic_read(&se_tpg->tpg_pr_ref_count) != 0)
 		cpu_relax();
 
+	mutex_lock(&se_tpg->acl_node_mutex);
+	list_splice_init(&se_tpg->acl_node_list, &node_list);
+	mutex_unlock(&se_tpg->acl_node_mutex);
 	/*
 	 * Release any remaining demo-mode generated se_node_acl that have
 	 * not been released because of TFO->tpg_check_demo_mode_cache() == 1
 	 * in transport_deregister_session().
 	 */
-	mutex_lock(&se_tpg->acl_node_mutex);
-	list_for_each_entry_safe(nacl, nacl_tmp, &se_tpg->acl_node_list,
-			acl_list) {
+	list_for_each_entry_safe(nacl, nacl_tmp, &node_list, acl_list) {
 		list_del(&nacl->acl_list);
 		se_tpg->num_node_acls--;
-		mutex_unlock(&se_tpg->acl_node_mutex);
 
 		core_tpg_wait_for_nacl_pr_ref(nacl);
 		core_free_device_list_for_node(nacl, se_tpg);
 		kfree(nacl);
-
-		mutex_lock(&se_tpg->acl_node_mutex);
 	}
-	mutex_unlock(&se_tpg->acl_node_mutex);
 
 	if (se_tpg->proto_id >= 0)
 		core_tpg_remove_lun(se_tpg, &se_tpg->tpg_virt_lun0);

commit 403edd78a2851ef95b24c0bf5151a4ab640898d7
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Sun Mar 8 22:33:47 2015 +0000

    target: Convert se_tpg->acl_node_lock to ->acl_node_mutex
    
    This patch converts se_tpg->acl_node_lock to struct mutex, so that
    ->acl_node_acl walkers in core_clear_lun_from_tpg() can block when
    calling core_disable_device_list_for_node().
    
    It also updates core_dev_add_lun() to hold ->acl_node_mutex when
    calling core_tpg_add_node_to_devs() to build ->lun_entry_hlist
    for dynamically generated se_node_acl.
    
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 13d34e22a3c4..229e8278f4fe 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -49,7 +49,7 @@ static LIST_HEAD(tpg_list);
 
 /*	__core_tpg_get_initiator_node_acl():
  *
- *	spin_lock_bh(&tpg->acl_node_lock); must be held when calling
+ *	mutex_lock(&tpg->acl_node_mutex); must be held when calling
  */
 struct se_node_acl *__core_tpg_get_initiator_node_acl(
 	struct se_portal_group *tpg,
@@ -75,9 +75,9 @@ struct se_node_acl *core_tpg_get_initiator_node_acl(
 {
 	struct se_node_acl *acl;
 
-	spin_lock_irq(&tpg->acl_node_lock);
+	mutex_lock(&tpg->acl_node_mutex);
 	acl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);
-	spin_unlock_irq(&tpg->acl_node_lock);
+	mutex_unlock(&tpg->acl_node_mutex);
 
 	return acl;
 }
@@ -198,10 +198,10 @@ static void target_add_node_acl(struct se_node_acl *acl)
 {
 	struct se_portal_group *tpg = acl->se_tpg;
 
-	spin_lock_irq(&tpg->acl_node_lock);
+	mutex_lock(&tpg->acl_node_mutex);
 	list_add_tail(&acl->acl_list, &tpg->acl_node_list);
 	tpg->num_node_acls++;
-	spin_unlock_irq(&tpg->acl_node_lock);
+	mutex_unlock(&tpg->acl_node_mutex);
 
 	pr_debug("%s_TPG[%hu] - Added %s ACL with TCQ Depth: %d for %s"
 		" Initiator Node: %s\n",
@@ -257,7 +257,7 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 {
 	struct se_node_acl *acl;
 
-	spin_lock_irq(&tpg->acl_node_lock);
+	mutex_lock(&tpg->acl_node_mutex);
 	acl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);
 	if (acl) {
 		if (acl->dynamic_node_acl) {
@@ -265,7 +265,7 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 			pr_debug("%s_TPG[%u] - Replacing dynamic ACL"
 				" for %s\n", tpg->se_tpg_tfo->get_fabric_name(),
 				tpg->se_tpg_tfo->tpg_get_tag(tpg), initiatorname);
-			spin_unlock_irq(&tpg->acl_node_lock);
+			mutex_unlock(&tpg->acl_node_mutex);
 			return acl;
 		}
 
@@ -273,10 +273,10 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 			" Node %s already exists for TPG %u, ignoring"
 			" request.\n",  tpg->se_tpg_tfo->get_fabric_name(),
 			initiatorname, tpg->se_tpg_tfo->tpg_get_tag(tpg));
-		spin_unlock_irq(&tpg->acl_node_lock);
+		mutex_unlock(&tpg->acl_node_mutex);
 		return ERR_PTR(-EEXIST);
 	}
-	spin_unlock_irq(&tpg->acl_node_lock);
+	mutex_unlock(&tpg->acl_node_mutex);
 
 	acl = target_alloc_node_acl(tpg, initiatorname);
 	if (!acl)
@@ -294,13 +294,13 @@ void core_tpg_del_initiator_node_acl(struct se_node_acl *acl)
 	unsigned long flags;
 	int rc;
 
-	spin_lock_irq(&tpg->acl_node_lock);
+	mutex_lock(&tpg->acl_node_mutex);
 	if (acl->dynamic_node_acl) {
 		acl->dynamic_node_acl = 0;
 	}
 	list_del(&acl->acl_list);
 	tpg->num_node_acls--;
-	spin_unlock_irq(&tpg->acl_node_lock);
+	mutex_unlock(&tpg->acl_node_mutex);
 
 	spin_lock_irqsave(&acl->nacl_sess_lock, flags);
 	acl->acl_stop = 1;
@@ -357,21 +357,21 @@ int core_tpg_set_initiator_node_queue_depth(
 	unsigned long flags;
 	int dynamic_acl = 0;
 
-	spin_lock_irq(&tpg->acl_node_lock);
+	mutex_lock(&tpg->acl_node_mutex);
 	acl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);
 	if (!acl) {
 		pr_err("Access Control List entry for %s Initiator"
 			" Node %s does not exists for TPG %hu, ignoring"
 			" request.\n", tpg->se_tpg_tfo->get_fabric_name(),
 			initiatorname, tpg->se_tpg_tfo->tpg_get_tag(tpg));
-		spin_unlock_irq(&tpg->acl_node_lock);
+		mutex_unlock(&tpg->acl_node_mutex);
 		return -ENODEV;
 	}
 	if (acl->dynamic_node_acl) {
 		acl->dynamic_node_acl = 0;
 		dynamic_acl = 1;
 	}
-	spin_unlock_irq(&tpg->acl_node_lock);
+	mutex_unlock(&tpg->acl_node_mutex);
 
 	spin_lock_irqsave(&tpg->session_lock, flags);
 	list_for_each_entry(sess, &tpg->tpg_sess_list, sess_list) {
@@ -387,10 +387,10 @@ int core_tpg_set_initiator_node_queue_depth(
 				tpg->se_tpg_tfo->get_fabric_name(), initiatorname);
 			spin_unlock_irqrestore(&tpg->session_lock, flags);
 
-			spin_lock_irq(&tpg->acl_node_lock);
+			mutex_lock(&tpg->acl_node_mutex);
 			if (dynamic_acl)
 				acl->dynamic_node_acl = 1;
-			spin_unlock_irq(&tpg->acl_node_lock);
+			mutex_unlock(&tpg->acl_node_mutex);
 			return -EEXIST;
 		}
 		/*
@@ -425,10 +425,10 @@ int core_tpg_set_initiator_node_queue_depth(
 		if (init_sess)
 			tpg->se_tpg_tfo->close_session(init_sess);
 
-		spin_lock_irq(&tpg->acl_node_lock);
+		mutex_lock(&tpg->acl_node_mutex);
 		if (dynamic_acl)
 			acl->dynamic_node_acl = 1;
-		spin_unlock_irq(&tpg->acl_node_lock);
+		mutex_unlock(&tpg->acl_node_mutex);
 		return -EINVAL;
 	}
 	spin_unlock_irqrestore(&tpg->session_lock, flags);
@@ -444,10 +444,10 @@ int core_tpg_set_initiator_node_queue_depth(
 		initiatorname, tpg->se_tpg_tfo->get_fabric_name(),
 		tpg->se_tpg_tfo->tpg_get_tag(tpg));
 
-	spin_lock_irq(&tpg->acl_node_lock);
+	mutex_lock(&tpg->acl_node_mutex);
 	if (dynamic_acl)
 		acl->dynamic_node_acl = 1;
-	spin_unlock_irq(&tpg->acl_node_lock);
+	mutex_unlock(&tpg->acl_node_mutex);
 
 	return 0;
 }
@@ -521,9 +521,9 @@ int core_tpg_register(
 	INIT_LIST_HEAD(&se_tpg->acl_node_list);
 	INIT_LIST_HEAD(&se_tpg->se_tpg_node);
 	INIT_LIST_HEAD(&se_tpg->tpg_sess_list);
-	spin_lock_init(&se_tpg->acl_node_lock);
 	spin_lock_init(&se_tpg->session_lock);
 	mutex_init(&se_tpg->tpg_lun_mutex);
+	mutex_init(&se_tpg->acl_node_mutex);
 
 	if (se_tpg->proto_id >= 0) {
 		if (core_tpg_setup_virtual_lun0(se_tpg) < 0)
@@ -559,25 +559,26 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 
 	while (atomic_read(&se_tpg->tpg_pr_ref_count) != 0)
 		cpu_relax();
+
 	/*
 	 * Release any remaining demo-mode generated se_node_acl that have
 	 * not been released because of TFO->tpg_check_demo_mode_cache() == 1
 	 * in transport_deregister_session().
 	 */
-	spin_lock_irq(&se_tpg->acl_node_lock);
+	mutex_lock(&se_tpg->acl_node_mutex);
 	list_for_each_entry_safe(nacl, nacl_tmp, &se_tpg->acl_node_list,
 			acl_list) {
 		list_del(&nacl->acl_list);
 		se_tpg->num_node_acls--;
-		spin_unlock_irq(&se_tpg->acl_node_lock);
+		mutex_unlock(&se_tpg->acl_node_mutex);
 
 		core_tpg_wait_for_nacl_pr_ref(nacl);
 		core_free_device_list_for_node(nacl, se_tpg);
 		kfree(nacl);
 
-		spin_lock_irq(&se_tpg->acl_node_lock);
+		mutex_lock(&se_tpg->acl_node_mutex);
 	}
-	spin_unlock_irq(&se_tpg->acl_node_lock);
+	mutex_unlock(&se_tpg->acl_node_mutex);
 
 	if (se_tpg->proto_id >= 0)
 		core_tpg_remove_lun(se_tpg, &se_tpg->tpg_virt_lun0);

commit 6bb826121be244a5a3c8bd8b7d45c47df18810b7
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Sun May 10 19:31:10 2015 -0700

    target: Convert se_portal_group->tpg_lun_list[] to RCU hlist
    
    This patch converts the fixed size se_portal_group->tpg_lun_list[]
    to use modern RCU with hlist_head in order to support an arbitary
    number of se_lun ports per target endpoint.
    
    It includes dropping core_tpg_alloc_lun() from core_dev_add_lun(),
    and calling it directly from target_fabric_make_lun() to allocate
    a new se_lun.  And add a new target_fabric_port_release() configfs
    item callback to invoke kfree_rcu() to release memory during
    se_lun->lun_group shutdown.
    
    Also now that se_node_acl->lun_entry_hlist is using RCU, convert
    existing tpg_lun_lock to struct mutex so core_tpg_add_node_to_devs()
    can perform RCU updater logic without releasing ->tpg_lun_mutex.
    
    Also, drop core_tpg_clear_object_luns() and it's single consumer
    in iscsi-target, which is duplicating TPG LUN shutdown logic and
    is current code results in a NOP.
    
    Finally, sbp-target and xen-scsiback fabric driver conversions are
    included, which are required due to the non-standard way they use
    ->tpg_lun_hlist.
    
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Sagi Grimberg <sagig@mellanox.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Chris Boot <bootc@bootc.net>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 0519923ef930..13d34e22a3c4 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -91,19 +91,15 @@ void core_tpg_add_node_to_devs(
 	struct se_node_acl *acl,
 	struct se_portal_group *tpg)
 {
-	int i = 0;
 	u32 lun_access = 0;
 	struct se_lun *lun;
 	struct se_device *dev;
 
-	spin_lock(&tpg->tpg_lun_lock);
-	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
-		lun = tpg->tpg_lun_list[i];
+	mutex_lock(&tpg->tpg_lun_mutex);
+	hlist_for_each_entry_rcu(lun, &tpg->tpg_lun_hlist, link) {
 		if (lun->lun_status != TRANSPORT_LUN_STATUS_ACTIVE)
 			continue;
 
-		spin_unlock(&tpg->tpg_lun_lock);
-
 		dev = lun->lun_se_dev;
 		/*
 		 * By default in LIO-Target $FABRIC_MOD,
@@ -130,7 +126,7 @@ void core_tpg_add_node_to_devs(
 			"READ-WRITE" : "READ-ONLY");
 
 		core_enable_device_list_for_node(lun, NULL, lun->unpacked_lun,
-				lun_access, acl, tpg);
+						 lun_access, acl, tpg);
 		/*
 		 * Check to see if there are any existing persistent reservation
 		 * APTPL pre-registrations that need to be enabled for this dynamic
@@ -138,9 +134,8 @@ void core_tpg_add_node_to_devs(
 		 */
 		core_scsi3_check_aptpl_registration(dev, tpg, lun, acl,
 						    lun->unpacked_lun);
-		spin_lock(&tpg->tpg_lun_lock);
 	}
-	spin_unlock(&tpg->tpg_lun_lock);
+	mutex_unlock(&tpg->tpg_lun_mutex);
 }
 
 /*      core_set_queue_depth_for_node():
@@ -161,34 +156,6 @@ static int core_set_queue_depth_for_node(
 	return 0;
 }
 
-void array_free(void *array, int n)
-{
-	void **a = array;
-	int i;
-
-	for (i = 0; i < n; i++)
-		kfree(a[i]);
-	kfree(a);
-}
-
-static void *array_zalloc(int n, size_t size, gfp_t flags)
-{
-	void **a;
-	int i;
-
-	a = kzalloc(n * sizeof(void*), flags);
-	if (!a)
-		return NULL;
-	for (i = 0; i < n; i++) {
-		a[i] = kzalloc(size, flags);
-		if (!a[i]) {
-			array_free(a, n);
-			return NULL;
-		}
-	}
-	return a;
-}
-
 static struct se_node_acl *target_alloc_node_acl(struct se_portal_group *tpg,
 		const unsigned char *initiatorname)
 {
@@ -284,27 +251,6 @@ void core_tpg_wait_for_nacl_pr_ref(struct se_node_acl *nacl)
 		cpu_relax();
 }
 
-void core_tpg_clear_object_luns(struct se_portal_group *tpg)
-{
-	int i;
-	struct se_lun *lun;
-
-	spin_lock(&tpg->tpg_lun_lock);
-	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
-		lun = tpg->tpg_lun_list[i];
-
-		if ((lun->lun_status != TRANSPORT_LUN_STATUS_ACTIVE) ||
-		    (lun->lun_se_dev == NULL))
-			continue;
-
-		spin_unlock(&tpg->tpg_lun_lock);
-		core_dev_del_lun(tpg, lun);
-		spin_lock(&tpg->tpg_lun_lock);
-	}
-	spin_unlock(&tpg->tpg_lun_lock);
-}
-EXPORT_SYMBOL(core_tpg_clear_object_luns);
-
 struct se_node_acl *core_tpg_add_initiator_node_acl(
 	struct se_portal_group *tpg,
 	const char *initiatorname)
@@ -567,30 +513,7 @@ int core_tpg_register(
 	struct se_portal_group *se_tpg,
 	int proto_id)
 {
-	struct se_lun *lun;
-	u32 i;
-
-	se_tpg->tpg_lun_list = array_zalloc(TRANSPORT_MAX_LUNS_PER_TPG,
-			sizeof(struct se_lun), GFP_KERNEL);
-	if (!se_tpg->tpg_lun_list) {
-		pr_err("Unable to allocate struct se_portal_group->"
-				"tpg_lun_list\n");
-		return -ENOMEM;
-	}
-
-	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
-		lun = se_tpg->tpg_lun_list[i];
-		lun->unpacked_lun = i;
-		lun->lun_link_magic = SE_LUN_LINK_MAGIC;
-		lun->lun_status = TRANSPORT_LUN_STATUS_FREE;
-		atomic_set(&lun->lun_acl_count, 0);
-		init_completion(&lun->lun_shutdown_comp);
-		INIT_LIST_HEAD(&lun->lun_acl_list);
-		spin_lock_init(&lun->lun_acl_lock);
-		spin_lock_init(&lun->lun_sep_lock);
-		init_completion(&lun->lun_ref_comp);
-	}
-
+	INIT_HLIST_HEAD(&se_tpg->tpg_lun_hlist);
 	se_tpg->proto_id = proto_id;
 	se_tpg->se_tpg_tfo = tfo;
 	se_tpg->se_tpg_wwn = se_wwn;
@@ -600,14 +523,11 @@ int core_tpg_register(
 	INIT_LIST_HEAD(&se_tpg->tpg_sess_list);
 	spin_lock_init(&se_tpg->acl_node_lock);
 	spin_lock_init(&se_tpg->session_lock);
-	spin_lock_init(&se_tpg->tpg_lun_lock);
+	mutex_init(&se_tpg->tpg_lun_mutex);
 
 	if (se_tpg->proto_id >= 0) {
-		if (core_tpg_setup_virtual_lun0(se_tpg) < 0) {
-			array_free(se_tpg->tpg_lun_list,
-				   TRANSPORT_MAX_LUNS_PER_TPG);
+		if (core_tpg_setup_virtual_lun0(se_tpg) < 0)
 			return -ENOMEM;
-		}
 	}
 
 	spin_lock_bh(&tpg_lock);
@@ -662,7 +582,6 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 	if (se_tpg->proto_id >= 0)
 		core_tpg_remove_lun(se_tpg, &se_tpg->tpg_virt_lun0);
 
-	array_free(se_tpg->tpg_lun_list, TRANSPORT_MAX_LUNS_PER_TPG);
 	return 0;
 }
 EXPORT_SYMBOL(core_tpg_deregister);
@@ -682,17 +601,20 @@ struct se_lun *core_tpg_alloc_lun(
 		return ERR_PTR(-EOVERFLOW);
 	}
 
-	spin_lock(&tpg->tpg_lun_lock);
-	lun = tpg->tpg_lun_list[unpacked_lun];
-	if (lun->lun_status == TRANSPORT_LUN_STATUS_ACTIVE) {
-		pr_err("TPG Logical Unit Number: %u is already active"
-			" on %s Target Portal Group: %u, ignoring request.\n",
-			unpacked_lun, tpg->se_tpg_tfo->get_fabric_name(),
-			tpg->se_tpg_tfo->tpg_get_tag(tpg));
-		spin_unlock(&tpg->tpg_lun_lock);
-		return ERR_PTR(-EINVAL);
+	lun = kzalloc(sizeof(*lun), GFP_KERNEL);
+	if (!lun) {
+		pr_err("Unable to allocate se_lun memory\n");
+		return ERR_PTR(-ENOMEM);
 	}
-	spin_unlock(&tpg->tpg_lun_lock);
+	lun->unpacked_lun = unpacked_lun;
+	lun->lun_link_magic = SE_LUN_LINK_MAGIC;
+	lun->lun_status = TRANSPORT_LUN_STATUS_FREE;
+	atomic_set(&lun->lun_acl_count, 0);
+	init_completion(&lun->lun_shutdown_comp);
+	INIT_LIST_HEAD(&lun->lun_acl_list);
+	spin_lock_init(&lun->lun_acl_lock);
+	spin_lock_init(&lun->lun_sep_lock);
+	init_completion(&lun->lun_ref_comp);
 
 	return lun;
 }
@@ -716,10 +638,12 @@ int core_tpg_add_lun(
 		return ret;
 	}
 
-	spin_lock(&tpg->tpg_lun_lock);
+	mutex_lock(&tpg->tpg_lun_mutex);
 	lun->lun_access = lun_access;
 	lun->lun_status = TRANSPORT_LUN_STATUS_ACTIVE;
-	spin_unlock(&tpg->tpg_lun_lock);
+	if (!(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))
+		hlist_add_head_rcu(&lun->link, &tpg->tpg_lun_hlist);
+	mutex_unlock(&tpg->tpg_lun_mutex);
 
 	return 0;
 }
@@ -728,14 +652,18 @@ void core_tpg_remove_lun(
 	struct se_portal_group *tpg,
 	struct se_lun *lun)
 {
+	struct se_device *dev = lun->lun_se_dev;
+
 	core_clear_lun_from_tpg(lun, tpg);
 	transport_clear_lun_ref(lun);
 
 	core_dev_unexport(lun->lun_se_dev, tpg, lun);
 
-	spin_lock(&tpg->tpg_lun_lock);
+	mutex_lock(&tpg->tpg_lun_mutex);
 	lun->lun_status = TRANSPORT_LUN_STATUS_FREE;
-	spin_unlock(&tpg->tpg_lun_lock);
+	if (!(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))
+		hlist_del_rcu(&lun->link);
+	mutex_unlock(&tpg->tpg_lun_mutex);
 
 	percpu_ref_exit(&lun->lun_ref);
 }

commit 29a05deebf6c2e3010934fb78ee65cab3d329470
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Sun Mar 22 20:42:19 2015 -0700

    target: Convert se_node_acl->device_list[] to RCU hlist
    
    This patch converts se_node_acl->device_list[] table for mappedluns
    to modern RCU hlist_head usage in order to support an arbitrary number
    of node_acl lun mappings.
    
    It converts transport_lookup_*_lun() fast-path code to use RCU read path
    primitives when looking up se_dev_entry.  It adds a new hlist_head at
    se_node_acl->lun_entry_hlist for this purpose.
    
    For transport_lookup_cmd_lun() code, it works with existing per-cpu
    se_lun->lun_ref when associating se_cmd with se_lun + se_device.
    Also, go ahead and update core_create_device_list_for_node() +
    core_free_device_list_for_node() to use ->lun_entry_hlist.
    
    It also converts se_dev_entry->pr_ref_count access to use modern
    struct kref counting, and updates core_disable_device_list_for_node()
    to kref_put() and block on se_deve->pr_comp waiting for outstanding PR
    special-case PR references to drop, then invoke kfree_rcu() to wait
    for the RCU grace period to complete before releasing memory.
    
    So now that se_node_acl->lun_entry_hlist fast path access uses RCU
    protected pointers, go ahead and convert remaining non-fast path
    RCU updater code using ->lun_entry_lock to struct mutex to allow
    callers to block while walking se_node_acl->lun_entry_hlist.
    
    Finally drop the left-over core_clear_initiator_node_from_tpg() that
    originally cleared lun_access during se_node_acl shutdown, as post
    RCU conversion it now becomes duplicated logic.
    
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Sagi Grimberg <sagig@mellanox.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index c0c1f67facb5..0519923ef930 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -47,42 +47,6 @@ extern struct se_device *g_lun0_dev;
 static DEFINE_SPINLOCK(tpg_lock);
 static LIST_HEAD(tpg_list);
 
-/*	core_clear_initiator_node_from_tpg():
- *
- *
- */
-static void core_clear_initiator_node_from_tpg(
-	struct se_node_acl *nacl,
-	struct se_portal_group *tpg)
-{
-	int i;
-	struct se_dev_entry *deve;
-	struct se_lun *lun;
-
-	spin_lock_irq(&nacl->device_list_lock);
-	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
-		deve = nacl->device_list[i];
-
-		if (!(deve->lun_flags & TRANSPORT_LUNFLAGS_INITIATOR_ACCESS))
-			continue;
-
-		if (!deve->se_lun) {
-			pr_err("%s device entries device pointer is"
-				" NULL, but Initiator has access.\n",
-				tpg->se_tpg_tfo->get_fabric_name());
-			continue;
-		}
-
-		lun = deve->se_lun;
-		spin_unlock_irq(&nacl->device_list_lock);
-		core_disable_device_list_for_node(lun, NULL, deve->mapped_lun,
-			TRANSPORT_LUNFLAGS_NO_ACCESS, nacl, tpg);
-
-		spin_lock_irq(&nacl->device_list_lock);
-	}
-	spin_unlock_irq(&nacl->device_list_lock);
-}
-
 /*	__core_tpg_get_initiator_node_acl():
  *
  *	spin_lock_bh(&tpg->acl_node_lock); must be held when calling
@@ -225,35 +189,6 @@ static void *array_zalloc(int n, size_t size, gfp_t flags)
 	return a;
 }
 
-/*      core_create_device_list_for_node():
- *
- *
- */
-static int core_create_device_list_for_node(struct se_node_acl *nacl)
-{
-	struct se_dev_entry *deve;
-	int i;
-
-	nacl->device_list = array_zalloc(TRANSPORT_MAX_LUNS_PER_TPG,
-			sizeof(struct se_dev_entry), GFP_KERNEL);
-	if (!nacl->device_list) {
-		pr_err("Unable to allocate memory for"
-			" struct se_node_acl->device_list\n");
-		return -ENOMEM;
-	}
-	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
-		deve = nacl->device_list[i];
-
-		atomic_set(&deve->ua_count, 0);
-		atomic_set(&deve->pr_ref_count, 0);
-		spin_lock_init(&deve->ua_lock);
-		INIT_LIST_HEAD(&deve->alua_port_list);
-		INIT_LIST_HEAD(&deve->ua_list);
-	}
-
-	return 0;
-}
-
 static struct se_node_acl *target_alloc_node_acl(struct se_portal_group *tpg,
 		const unsigned char *initiatorname)
 {
@@ -266,10 +201,11 @@ static struct se_node_acl *target_alloc_node_acl(struct se_portal_group *tpg,
 
 	INIT_LIST_HEAD(&acl->acl_list);
 	INIT_LIST_HEAD(&acl->acl_sess_list);
+	INIT_HLIST_HEAD(&acl->lun_entry_hlist);
 	kref_init(&acl->acl_kref);
 	init_completion(&acl->acl_free_comp);
-	spin_lock_init(&acl->device_list_lock);
 	spin_lock_init(&acl->nacl_sess_lock);
+	mutex_init(&acl->lun_entry_mutex);
 	atomic_set(&acl->acl_pr_ref_count, 0);
 	if (tpg->se_tpg_tfo->tpg_get_default_depth)
 		acl->queue_depth = tpg->se_tpg_tfo->tpg_get_default_depth(tpg);
@@ -281,15 +217,11 @@ static struct se_node_acl *target_alloc_node_acl(struct se_portal_group *tpg,
 
 	tpg->se_tpg_tfo->set_default_node_attributes(acl);
 
-	if (core_create_device_list_for_node(acl) < 0)
-		goto out_free_acl;
 	if (core_set_queue_depth_for_node(tpg, acl) < 0)
-		goto out_free_device_list;
+		goto out_free_acl;
 
 	return acl;
 
-out_free_device_list:
-	core_free_device_list_for_node(acl, tpg);
 out_free_acl:
 	kfree(acl);
 	return NULL;
@@ -454,7 +386,6 @@ void core_tpg_del_initiator_node_acl(struct se_node_acl *acl)
 	wait_for_completion(&acl->acl_free_comp);
 
 	core_tpg_wait_for_nacl_pr_ref(acl);
-	core_clear_initiator_node_from_tpg(acl, tpg);
 	core_free_device_list_for_node(acl, tpg);
 
 	pr_debug("%s_TPG[%hu] - Deleted ACL with TCQ Depth: %d for %s"

commit e4aae5af810eaa61c2cd7ba79d95ebfe0d88fe9b
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri May 1 17:47:56 2015 +0200

    target: change core_tpg_register prototype
    
    Remove the unneeded fabric_ptr argument, and change the type argument
    to pass in a SPC protocol identifier.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 42f3bd9561c8..c0c1f67facb5 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -634,8 +634,7 @@ int core_tpg_register(
 	const struct target_core_fabric_ops *tfo,
 	struct se_wwn *se_wwn,
 	struct se_portal_group *se_tpg,
-	void *tpg_fabric_ptr,
-	int se_tpg_type)
+	int proto_id)
 {
 	struct se_lun *lun;
 	u32 i;
@@ -661,8 +660,7 @@ int core_tpg_register(
 		init_completion(&lun->lun_ref_comp);
 	}
 
-	se_tpg->se_tpg_type = se_tpg_type;
-	se_tpg->se_tpg_fabric_ptr = tpg_fabric_ptr;
+	se_tpg->proto_id = proto_id;
 	se_tpg->se_tpg_tfo = tfo;
 	se_tpg->se_tpg_wwn = se_wwn;
 	atomic_set(&se_tpg->tpg_pr_ref_count, 0);
@@ -673,7 +671,7 @@ int core_tpg_register(
 	spin_lock_init(&se_tpg->session_lock);
 	spin_lock_init(&se_tpg->tpg_lun_lock);
 
-	if (se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL) {
+	if (se_tpg->proto_id >= 0) {
 		if (core_tpg_setup_virtual_lun0(se_tpg) < 0) {
 			array_free(se_tpg->tpg_lun_list,
 				   TRANSPORT_MAX_LUNS_PER_TPG);
@@ -685,11 +683,10 @@ int core_tpg_register(
 	list_add_tail(&se_tpg->se_tpg_node, &tpg_list);
 	spin_unlock_bh(&tpg_lock);
 
-	pr_debug("TARGET_CORE[%s]: Allocated %s struct se_portal_group for"
-		" endpoint: %s, Portal Tag: %u\n", tfo->get_fabric_name(),
-		(se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL) ?
-		"Normal" : "Discovery", (tfo->tpg_get_wwn(se_tpg) == NULL) ?
-		"None" : tfo->tpg_get_wwn(se_tpg), tfo->tpg_get_tag(se_tpg));
+	pr_debug("TARGET_CORE[%s]: Allocated portal_group for endpoint: %s, "
+		 "Proto: %d, Portal Tag: %u\n", tfo->get_fabric_name(),
+		tfo->tpg_get_wwn(se_tpg) ? tfo->tpg_get_wwn(se_tpg) : NULL,
+		se_tpg->proto_id, tfo->tpg_get_tag(se_tpg));
 
 	return 0;
 }
@@ -697,14 +694,13 @@ EXPORT_SYMBOL(core_tpg_register);
 
 int core_tpg_deregister(struct se_portal_group *se_tpg)
 {
+	const struct target_core_fabric_ops *tfo = se_tpg->se_tpg_tfo;
 	struct se_node_acl *nacl, *nacl_tmp;
 
-	pr_debug("TARGET_CORE[%s]: Deallocating %s struct se_portal_group"
-		" for endpoint: %s Portal Tag %u\n",
-		(se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL) ?
-		"Normal" : "Discovery", se_tpg->se_tpg_tfo->get_fabric_name(),
-		se_tpg->se_tpg_tfo->tpg_get_wwn(se_tpg),
-		se_tpg->se_tpg_tfo->tpg_get_tag(se_tpg));
+	pr_debug("TARGET_CORE[%s]: Deallocating portal_group for endpoint: %s, "
+		 "Proto: %d, Portal Tag: %u\n", tfo->get_fabric_name(),
+		tfo->tpg_get_wwn(se_tpg) ? tfo->tpg_get_wwn(se_tpg) : NULL,
+		se_tpg->proto_id, tfo->tpg_get_tag(se_tpg));
 
 	spin_lock_bh(&tpg_lock);
 	list_del(&se_tpg->se_tpg_node);
@@ -732,10 +728,9 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 	}
 	spin_unlock_irq(&se_tpg->acl_node_lock);
 
-	if (se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL)
+	if (se_tpg->proto_id >= 0)
 		core_tpg_remove_lun(se_tpg, &se_tpg->tpg_virt_lun0);
 
-	se_tpg->se_tpg_fabric_ptr = NULL;
 	array_free(se_tpg->tpg_lun_list, TRANSPORT_MAX_LUNS_PER_TPG);
 	return 0;
 }

commit 144bc4c2a42a0f42a32c106d53f5bf2724fbf098
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Apr 13 19:51:16 2015 +0200

    target: move node ACL allocation to core code
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 0cd86ff9a792..42f3bd9561c8 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -259,7 +259,8 @@ static struct se_node_acl *target_alloc_node_acl(struct se_portal_group *tpg,
 {
 	struct se_node_acl *acl;
 
-	acl = tpg->se_tpg_tfo->tpg_alloc_fabric_acl(tpg);
+	acl = kzalloc(max(sizeof(*acl), tpg->se_tpg_tfo->node_acl_size),
+			GFP_KERNEL);
 	if (!acl)
 		return NULL;
 
@@ -290,7 +291,7 @@ static struct se_node_acl *target_alloc_node_acl(struct se_portal_group *tpg,
 out_free_device_list:
 	core_free_device_list_for_node(acl, tpg);
 out_free_acl:
-	tpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);
+	kfree(acl);
 	return NULL;
 }
 
@@ -461,7 +462,7 @@ void core_tpg_del_initiator_node_acl(struct se_node_acl *acl)
 		tpg->se_tpg_tfo->tpg_get_tag(tpg), acl->queue_depth,
 		tpg->se_tpg_tfo->get_fabric_name(), acl->initiatorname);
 
-	tpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);
+	kfree(acl);
 }
 
 /*	core_tpg_set_initiator_node_queue_depth():
@@ -725,7 +726,7 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 
 		core_tpg_wait_for_nacl_pr_ref(nacl);
 		core_free_device_list_for_node(nacl, se_tpg);
-		se_tpg->se_tpg_tfo->tpg_release_fabric_acl(se_tpg, nacl);
+		kfree(nacl);
 
 		spin_lock_irq(&se_tpg->acl_node_lock);
 	}

commit e413f4727037e826c55a639c713a221006b6d61d
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Apr 13 19:51:15 2015 +0200

    target: refactor node ACL allocation
    
    Split out two common helpers to share code for allocating and initializing
    node ACLs.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 78dd53ada04a..0cd86ff9a792 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -254,24 +254,12 @@ static int core_create_device_list_for_node(struct se_node_acl *nacl)
 	return 0;
 }
 
-/*	core_tpg_check_initiator_node_acl()
- *
- *
- */
-struct se_node_acl *core_tpg_check_initiator_node_acl(
-	struct se_portal_group *tpg,
-	unsigned char *initiatorname)
+static struct se_node_acl *target_alloc_node_acl(struct se_portal_group *tpg,
+		const unsigned char *initiatorname)
 {
 	struct se_node_acl *acl;
 
-	acl = core_tpg_get_initiator_node_acl(tpg, initiatorname);
-	if (acl)
-		return acl;
-
-	if (!tpg->se_tpg_tfo->tpg_check_demo_mode(tpg))
-		return NULL;
-
-	acl =  tpg->se_tpg_tfo->tpg_alloc_fabric_acl(tpg);
+	acl = tpg->se_tpg_tfo->tpg_alloc_fabric_acl(tpg);
 	if (!acl)
 		return NULL;
 
@@ -289,20 +277,60 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 	snprintf(acl->initiatorname, TRANSPORT_IQN_LEN, "%s", initiatorname);
 	acl->se_tpg = tpg;
 	acl->acl_index = scsi_get_new_index(SCSI_AUTH_INTR_INDEX);
-	acl->dynamic_node_acl = 1;
 
 	tpg->se_tpg_tfo->set_default_node_attributes(acl);
 
-	if (core_create_device_list_for_node(acl) < 0) {
-		tpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);
+	if (core_create_device_list_for_node(acl) < 0)
+		goto out_free_acl;
+	if (core_set_queue_depth_for_node(tpg, acl) < 0)
+		goto out_free_device_list;
+
+	return acl;
+
+out_free_device_list:
+	core_free_device_list_for_node(acl, tpg);
+out_free_acl:
+	tpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);
+	return NULL;
+}
+
+static void target_add_node_acl(struct se_node_acl *acl)
+{
+	struct se_portal_group *tpg = acl->se_tpg;
+
+	spin_lock_irq(&tpg->acl_node_lock);
+	list_add_tail(&acl->acl_list, &tpg->acl_node_list);
+	tpg->num_node_acls++;
+	spin_unlock_irq(&tpg->acl_node_lock);
+
+	pr_debug("%s_TPG[%hu] - Added %s ACL with TCQ Depth: %d for %s"
+		" Initiator Node: %s\n",
+		tpg->se_tpg_tfo->get_fabric_name(),
+		tpg->se_tpg_tfo->tpg_get_tag(tpg),
+		acl->dynamic_node_acl ? "DYNAMIC" : "",
+		acl->queue_depth,
+		tpg->se_tpg_tfo->get_fabric_name(),
+		acl->initiatorname);
+}
+
+struct se_node_acl *core_tpg_check_initiator_node_acl(
+	struct se_portal_group *tpg,
+	unsigned char *initiatorname)
+{
+	struct se_node_acl *acl;
+
+	acl = core_tpg_get_initiator_node_acl(tpg, initiatorname);
+	if (acl)
+		return acl;
+
+	if (!tpg->se_tpg_tfo->tpg_check_demo_mode(tpg))
 		return NULL;
-	}
 
-	if (core_set_queue_depth_for_node(tpg, acl) < 0) {
-		core_free_device_list_for_node(acl, tpg);
-		tpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);
+	acl = target_alloc_node_acl(tpg, initiatorname);
+	if (!acl)
 		return NULL;
-	}
+	acl->dynamic_node_acl = 1;
+
 	/*
 	 * Here we only create demo-mode MappedLUNs from the active
 	 * TPG LUNs if the fabric is not explicitly asking for
@@ -312,16 +340,7 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 	    (tpg->se_tpg_tfo->tpg_check_demo_mode_login_only(tpg) != 1))
 		core_tpg_add_node_to_devs(acl, tpg);
 
-	spin_lock_irq(&tpg->acl_node_lock);
-	list_add_tail(&acl->acl_list, &tpg->acl_node_list);
-	tpg->num_node_acls++;
-	spin_unlock_irq(&tpg->acl_node_lock);
-
-	pr_debug("%s_TPG[%u] - Added DYNAMIC ACL with TCQ Depth: %d for %s"
-		" Initiator Node: %s\n", tpg->se_tpg_tfo->get_fabric_name(),
-		tpg->se_tpg_tfo->tpg_get_tag(tpg), acl->queue_depth,
-		tpg->se_tpg_tfo->get_fabric_name(), initiatorname);
-
+	target_add_node_acl(acl);
 	return acl;
 }
 EXPORT_SYMBOL(core_tpg_check_initiator_node_acl);
@@ -368,7 +387,7 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 				" for %s\n", tpg->se_tpg_tfo->get_fabric_name(),
 				tpg->se_tpg_tfo->tpg_get_tag(tpg), initiatorname);
 			spin_unlock_irq(&tpg->acl_node_lock);
-			goto done;
+			return acl;
 		}
 
 		pr_err("ACL entry for %s Initiator"
@@ -380,51 +399,11 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 	}
 	spin_unlock_irq(&tpg->acl_node_lock);
 
-	acl = tpg->se_tpg_tfo->tpg_alloc_fabric_acl(tpg);
-	if (!acl) {
-		pr_err("struct se_node_acl pointer is NULL\n");
-		return ERR_PTR(-EINVAL);
-	}
-
-	INIT_LIST_HEAD(&acl->acl_list);
-	INIT_LIST_HEAD(&acl->acl_sess_list);
-	kref_init(&acl->acl_kref);
-	init_completion(&acl->acl_free_comp);
-	spin_lock_init(&acl->device_list_lock);
-	spin_lock_init(&acl->nacl_sess_lock);
-	atomic_set(&acl->acl_pr_ref_count, 0);
-	if (tpg->se_tpg_tfo->tpg_get_default_depth)
-		acl->queue_depth = tpg->se_tpg_tfo->tpg_get_default_depth(tpg);
-	else
-		acl->queue_depth = 1;
-	snprintf(acl->initiatorname, TRANSPORT_IQN_LEN, "%s", initiatorname);
-	acl->se_tpg = tpg;
-	acl->acl_index = scsi_get_new_index(SCSI_AUTH_INTR_INDEX);
-
-	tpg->se_tpg_tfo->set_default_node_attributes(acl);
-
-	if (core_create_device_list_for_node(acl) < 0) {
-		tpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);
+	acl = target_alloc_node_acl(tpg, initiatorname);
+	if (!acl)
 		return ERR_PTR(-ENOMEM);
-	}
-
-	if (core_set_queue_depth_for_node(tpg, acl) < 0) {
-		core_free_device_list_for_node(acl, tpg);
-		tpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);
-		return ERR_PTR(-EINVAL);
-	}
-
-	spin_lock_irq(&tpg->acl_node_lock);
-	list_add_tail(&acl->acl_list, &tpg->acl_node_list);
-	tpg->num_node_acls++;
-	spin_unlock_irq(&tpg->acl_node_lock);
-
-done:
-	pr_debug("%s_TPG[%hu] - Added ACL with TCQ Depth: %d for %s"
-		" Initiator Node: %s\n", tpg->se_tpg_tfo->get_fabric_name(),
-		tpg->se_tpg_tfo->tpg_get_tag(tpg), acl->queue_depth,
-		tpg->se_tpg_tfo->get_fabric_name(), initiatorname);
 
+	target_add_node_acl(acl);
 	return acl;
 }
 

commit c7d6a803926bae9bbf4510a18fc8dd8957cc0e01
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Apr 13 19:51:14 2015 +0200

    target: refactor init/drop_nodeacl methods
    
    By always allocating and adding, respectively removing and freeing
    the se_node_acl structure in core code we can remove tons of repeated
    code in the init_nodeacl and drop_nodeacl routines.  Additionally
    this now respects the get_default_queue_depth method in this code
    path as well.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 5a9deb2b24af..78dd53ada04a 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -353,17 +353,11 @@ void core_tpg_clear_object_luns(struct se_portal_group *tpg)
 }
 EXPORT_SYMBOL(core_tpg_clear_object_luns);
 
-/*	core_tpg_add_initiator_node_acl():
- *
- *
- */
 struct se_node_acl *core_tpg_add_initiator_node_acl(
 	struct se_portal_group *tpg,
-	struct se_node_acl *se_nacl,
-	const char *initiatorname,
-	u32 queue_depth)
+	const char *initiatorname)
 {
-	struct se_node_acl *acl = NULL;
+	struct se_node_acl *acl;
 
 	spin_lock_irq(&tpg->acl_node_lock);
 	acl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);
@@ -374,14 +368,6 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 				" for %s\n", tpg->se_tpg_tfo->get_fabric_name(),
 				tpg->se_tpg_tfo->tpg_get_tag(tpg), initiatorname);
 			spin_unlock_irq(&tpg->acl_node_lock);
-			/*
-			 * Release the locally allocated struct se_node_acl
-			 * because * core_tpg_add_initiator_node_acl() returned
-			 * a pointer to an existing demo mode node ACL.
-			 */
-			if (se_nacl)
-				tpg->se_tpg_tfo->tpg_release_fabric_acl(tpg,
-							se_nacl);
 			goto done;
 		}
 
@@ -394,16 +380,11 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 	}
 	spin_unlock_irq(&tpg->acl_node_lock);
 
-	if (!se_nacl) {
+	acl = tpg->se_tpg_tfo->tpg_alloc_fabric_acl(tpg);
+	if (!acl) {
 		pr_err("struct se_node_acl pointer is NULL\n");
 		return ERR_PTR(-EINVAL);
 	}
-	/*
-	 * For v4.x logic the se_node_acl_s is hanging off a fabric
-	 * dependent structure allocated via
-	 * struct target_core_fabric_ops->fabric_make_nodeacl()
-	 */
-	acl = se_nacl;
 
 	INIT_LIST_HEAD(&acl->acl_list);
 	INIT_LIST_HEAD(&acl->acl_sess_list);
@@ -412,7 +393,10 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 	spin_lock_init(&acl->device_list_lock);
 	spin_lock_init(&acl->nacl_sess_lock);
 	atomic_set(&acl->acl_pr_ref_count, 0);
-	acl->queue_depth = queue_depth;
+	if (tpg->se_tpg_tfo->tpg_get_default_depth)
+		acl->queue_depth = tpg->se_tpg_tfo->tpg_get_default_depth(tpg);
+	else
+		acl->queue_depth = 1;
 	snprintf(acl->initiatorname, TRANSPORT_IQN_LEN, "%s", initiatorname);
 	acl->se_tpg = tpg;
 	acl->acl_index = scsi_get_new_index(SCSI_AUTH_INTR_INDEX);
@@ -443,17 +427,10 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 
 	return acl;
 }
-EXPORT_SYMBOL(core_tpg_add_initiator_node_acl);
 
-/*	core_tpg_del_initiator_node_acl():
- *
- *
- */
-int core_tpg_del_initiator_node_acl(
-	struct se_portal_group *tpg,
-	struct se_node_acl *acl,
-	int force)
+void core_tpg_del_initiator_node_acl(struct se_node_acl *acl)
 {
+	struct se_portal_group *tpg = acl->se_tpg;
 	LIST_HEAD(sess_list);
 	struct se_session *sess, *sess_tmp;
 	unsigned long flags;
@@ -505,9 +482,8 @@ int core_tpg_del_initiator_node_acl(
 		tpg->se_tpg_tfo->tpg_get_tag(tpg), acl->queue_depth,
 		tpg->se_tpg_tfo->get_fabric_name(), acl->initiatorname);
 
-	return 0;
+	tpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);
 }
-EXPORT_SYMBOL(core_tpg_del_initiator_node_acl);
 
 /*	core_tpg_set_initiator_node_queue_depth():
  *

commit e1750d20e69477c0d7b26d6e0ba24c3c9ec47530
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Apr 13 19:51:13 2015 +0200

    target: make the tpg_get_default_depth method optional
    
    All fabric drivers except for iSCSI always return 1, so implement
    that as default behavior.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 47f064415bf6..5a9deb2b24af 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -282,7 +282,10 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 	spin_lock_init(&acl->device_list_lock);
 	spin_lock_init(&acl->nacl_sess_lock);
 	atomic_set(&acl->acl_pr_ref_count, 0);
-	acl->queue_depth = tpg->se_tpg_tfo->tpg_get_default_depth(tpg);
+	if (tpg->se_tpg_tfo->tpg_get_default_depth)
+		acl->queue_depth = tpg->se_tpg_tfo->tpg_get_default_depth(tpg);
+	else
+		acl->queue_depth = 1;
 	snprintf(acl->initiatorname, TRANSPORT_IQN_LEN, "%s", initiatorname);
 	acl->se_tpg = tpg;
 	acl->acl_index = scsi_get_new_index(SCSI_AUTH_INTR_INDEX);

commit 9ac8928e6a3e1ed02e632e45aa766129fe6b1802
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Apr 8 20:01:35 2015 +0200

    target: simplify the target template registration API
    
    Instead of calling target_fabric_configfs_init() +
    target_fabric_configfs_register() / target_fabric_configfs_deregister()
    target_fabric_configfs_free() from every target driver, rewrite the API
    so that we have simple register/unregister functions that operate on
    a const operations vector.
    
    This patch also fixes a memory leak in several target drivers. Several
    target drivers namely called target_fabric_configfs_deregister()
    without calling target_fabric_configfs_free().
    
    A large part of this patch is based on earlier changes from
    Bart Van Assche <bart.vanassche@sandisk.com>.
    
    (v2: Add a new TF_CIT_SETUP_DRV macro so that the core configfs code
    can declare attributes as either core only or for drivers)
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 0696de9553d3..47f064415bf6 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -672,7 +672,7 @@ static int core_tpg_setup_virtual_lun0(struct se_portal_group *se_tpg)
 }
 
 int core_tpg_register(
-	struct target_core_fabric_ops *tfo,
+	const struct target_core_fabric_ops *tfo,
 	struct se_wwn *se_wwn,
 	struct se_portal_group *se_tpg,
 	void *tpg_fabric_ptr,

commit c3351dfabf5c78fb5ddc79d0f7b65ebd9e441337
Merge: 848a552893ff 62d3ab49b8a5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 21 13:06:38 2014 -0700

    Merge branch 'for-next' of git://git.kernel.org/pub/scm/linux/kernel/git/nab/target-pending
    
    Pull SCSI target updates from Nicholas Bellinger:
     "Here are the target updates for v3.18-rc2 code.  These where
      originally destined for -rc1, but due to the combination of travel
      last week for KVM Forum and my mistake of taking the three week merge
      window literally, the pull request slipped..  Apologies for that.
    
      Things where reasonably quiet this round.  The highlights include:
    
       - New userspace backend driver (target_core_user.ko) by Shaohua Li
         and Andy Grover
       - A number of cleanups in target, iscsi-taret and qla_target code
         from Joern Engel
       - Fix an OOPs related to queue full handling with CHECK_CONDITION
         status from Quinn Tran
       - Fix to disable TX completion interrupt coalescing in iser-target,
         that was causing problems on some hardware
       - Fix for PR APTPL metadata handling with demo-mode ACLs
    
      I'm most excited about the new backend driver that uses UIO + shared
      memory ring to dispatch I/O and control commands into user-space.
      This was probably the most requested feature by users over the last
      couple of years, and opens up a new area of development + porting of
      existing user-space storage applications to LIO.  Thanks to Shaohua +
      Andy for making this happen.
    
      Also another honorable mention, a new Xen PV SCSI driver was merged
      via the xen/tip.git tree recently, which puts us now at 10 target
      drivers in upstream! Thanks to David Vrabel + Juergen Gross for their
      work to get this code merged"
    
    * 'for-next' of git://git.kernel.org/pub/scm/linux/kernel/git/nab/target-pending: (40 commits)
      target/file: fix inclusive vfs_fsync_range() end
      iser-target: Disable TX completion interrupt coalescing
      target: Add force_pr_aptpl device attribute
      target: Fix APTPL metadata handling for dynamic MappedLUNs
      qla_target: don't delete changed nacls
      target/user: Recalculate pad size inside is_ring_space_avail()
      tcm_loop: Fixup tag handling
      iser-target: Fix smatch warning
      target/user: Fix up smatch warnings in tcmu_netlink_event
      target: Add a user-passthrough backstore
      target: Add documentation on the target userspace pass-through driver
      uio: Export definition of struct uio_device
      target: Remove unneeded check in sbc_parse_cdb
      target: Fix queue full status NULL pointer for SCF_TRANSPORT_TASK_SENSE
      qla_target: rearrange struct qla_tgt_prm
      qla_target: improve qlt_unmap_sg()
      qla_target: make some global functions static
      qla_target: remove unused parameter
      target: simplify core_tmr_abort_task
      target: encapsulate smp_mb__after_atomic()
      ...

commit e24805637d2d270d7975502e9024d473de86afdb
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Sat Oct 4 04:23:15 2014 +0000

    target: Fix APTPL metadata handling for dynamic MappedLUNs
    
    This patch fixes a bug in handling of SPC-3 PR Activate Persistence
    across Target Power Loss (APTPL) logic where re-creation of state for
    MappedLUNs from dynamically generated NodeACLs did not occur during
    I_T Nexus establishment.
    
    It adds the missing core_scsi3_check_aptpl_registration() call during
    core_tpg_check_initiator_node_acl() -> core_tpg_add_node_to_devs() in
    order to replay any pre-loaded APTPL metadata state associated with
    the newly connected SCSI Initiator Port.
    
    Cc: Mike Christie <michaelc@cs.wisc.edu>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 6ec58736d1a4..aa2b2d0998e3 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -40,6 +40,7 @@
 #include <target/target_core_fabric.h>
 
 #include "target_core_internal.h"
+#include "target_core_pr.h"
 
 extern struct se_device *g_lun0_dev;
 
@@ -166,6 +167,13 @@ void core_tpg_add_node_to_devs(
 
 		core_enable_device_list_for_node(lun, NULL, lun->unpacked_lun,
 				lun_access, acl, tpg);
+		/*
+		 * Check to see if there are any existing persistent reservation
+		 * APTPL pre-registrations that need to be enabled for this dynamic
+		 * LUN ACL now..
+		 */
+		core_scsi3_check_aptpl_registration(dev, tpg, lun, acl,
+						    lun->unpacked_lun);
 		spin_lock(&tpg->tpg_lun_lock);
 	}
 	spin_unlock(&tpg->tpg_lun_lock);

commit 9c7d6154bc4b9dfefd580490cdca5f7c72321464
Author: Andy Grover <agrover@redhat.com>
Date:   Mon Jun 30 16:39:46 2014 -0700

    target: Remove core_tpg_release_virtual_lun0 function
    
    Simple and just called from one place.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andy Grover <agrover@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 259604188a90..6ec58736d1a4 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -663,13 +663,6 @@ static int core_tpg_setup_virtual_lun0(struct se_portal_group *se_tpg)
 	return 0;
 }
 
-static void core_tpg_release_virtual_lun0(struct se_portal_group *se_tpg)
-{
-	struct se_lun *lun = &se_tpg->tpg_virt_lun0;
-
-	core_tpg_remove_lun(se_tpg, lun);
-}
-
 int core_tpg_register(
 	struct target_core_fabric_ops *tfo,
 	struct se_wwn *se_wwn,
@@ -773,7 +766,7 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 	spin_unlock_irq(&se_tpg->acl_node_lock);
 
 	if (se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL)
-		core_tpg_release_virtual_lun0(se_tpg);
+		core_tpg_remove_lun(se_tpg, &se_tpg->tpg_virt_lun0);
 
 	se_tpg->se_tpg_fabric_ptr = NULL;
 	array_free(se_tpg->tpg_lun_list, TRANSPORT_MAX_LUNS_PER_TPG);

commit cd9d7cbaec8b622eee4edcd8bf481c4047f74915
Author: Andy Grover <agrover@redhat.com>
Date:   Mon Jun 30 16:39:44 2014 -0700

    target: Change core_dev_del_lun to take a se_lun instead of unpacked_lun
    
    Remove core_tpg_pre_dellun entirely, since we don't need to get/check
    a pointer we already have.
    
    Nothing else can return an error, so core_dev_del_lun can return void.
    
    Rename core_tpg_post_dellun to remove_lun - a clearer name, now that
    pre_dellun is gone.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andy Grover <agrover@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index b596ab509197..259604188a90 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -335,7 +335,7 @@ void core_tpg_clear_object_luns(struct se_portal_group *tpg)
 			continue;
 
 		spin_unlock(&tpg->tpg_lun_lock);
-		core_dev_del_lun(tpg, lun->unpacked_lun);
+		core_dev_del_lun(tpg, lun);
 		spin_lock(&tpg->tpg_lun_lock);
 	}
 	spin_unlock(&tpg->tpg_lun_lock);
@@ -667,7 +667,7 @@ static void core_tpg_release_virtual_lun0(struct se_portal_group *se_tpg)
 {
 	struct se_lun *lun = &se_tpg->tpg_virt_lun0;
 
-	core_tpg_post_dellun(se_tpg, lun);
+	core_tpg_remove_lun(se_tpg, lun);
 }
 
 int core_tpg_register(
@@ -837,37 +837,7 @@ int core_tpg_add_lun(
 	return 0;
 }
 
-struct se_lun *core_tpg_pre_dellun(
-	struct se_portal_group *tpg,
-	u32 unpacked_lun)
-{
-	struct se_lun *lun;
-
-	if (unpacked_lun > (TRANSPORT_MAX_LUNS_PER_TPG-1)) {
-		pr_err("%s LUN: %u exceeds TRANSPORT_MAX_LUNS_PER_TPG"
-			"-1: %u for Target Portal Group: %u\n",
-			tpg->se_tpg_tfo->get_fabric_name(), unpacked_lun,
-			TRANSPORT_MAX_LUNS_PER_TPG-1,
-			tpg->se_tpg_tfo->tpg_get_tag(tpg));
-		return ERR_PTR(-EOVERFLOW);
-	}
-
-	spin_lock(&tpg->tpg_lun_lock);
-	lun = tpg->tpg_lun_list[unpacked_lun];
-	if (lun->lun_status != TRANSPORT_LUN_STATUS_ACTIVE) {
-		pr_err("%s Logical Unit Number: %u is not active on"
-			" Target Portal Group: %u, ignoring request.\n",
-			tpg->se_tpg_tfo->get_fabric_name(), unpacked_lun,
-			tpg->se_tpg_tfo->tpg_get_tag(tpg));
-		spin_unlock(&tpg->tpg_lun_lock);
-		return ERR_PTR(-ENODEV);
-	}
-	spin_unlock(&tpg->tpg_lun_lock);
-
-	return lun;
-}
-
-void core_tpg_post_dellun(
+void core_tpg_remove_lun(
 	struct se_portal_group *tpg,
 	struct se_lun *lun)
 {

commit cc83881f2c57caaf4b14adaffa65595640a59661
Author: Andy Grover <agrover@redhat.com>
Date:   Mon Jun 30 16:39:43 2014 -0700

    target: core_tpg_post_dellun can return void
    
    Nothing in it can raise an error.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andy Grover <agrover@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index fddfae61222f..b596ab509197 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -867,7 +867,7 @@ struct se_lun *core_tpg_pre_dellun(
 	return lun;
 }
 
-int core_tpg_post_dellun(
+void core_tpg_post_dellun(
 	struct se_portal_group *tpg,
 	struct se_lun *lun)
 {
@@ -881,6 +881,4 @@ int core_tpg_post_dellun(
 	spin_unlock(&tpg->tpg_lun_lock);
 
 	percpu_ref_exit(&lun->lun_ref);
-
-	return 0;
 }

commit 2aad2a86f6685c10360ec8a5a55eb9ab7059cb72
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Sep 24 13:31:50 2014 -0400

    percpu_ref: add PERCPU_REF_INIT_* flags
    
    With the recent addition of percpu_ref_reinit(), percpu_ref now can be
    used as a persistent switch which can be turned on and off repeatedly
    where turning off maps to killing the ref and waiting for it to drain;
    however, there currently isn't a way to initialize a percpu_ref in its
    off (killed and drained) state, which can be inconvenient for certain
    persistent switch use cases.
    
    Similarly, percpu_ref_switch_to_atomic/percpu() allow dynamic
    selection of operation mode; however, currently a newly initialized
    percpu_ref is always in percpu mode making it impossible to avoid the
    latency overhead of switching to atomic mode.
    
    This patch adds @flags to percpu_ref_init() and implements the
    following flags.
    
    * PERCPU_REF_INIT_ATOMIC        : start ref in atomic mode
    * PERCPU_REF_INIT_DEAD          : start ref killed and drained
    
    These flags should be able to serve the above two use cases.
    
    v2: target_core_tpg.c conversion was missing.  Fixed.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Kent Overstreet <kmo@daterainc.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Johannes Weiner <hannes@cmpxchg.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 4ab6da338585..be783f717f19 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -819,7 +819,7 @@ int core_tpg_add_lun(
 {
 	int ret;
 
-	ret = percpu_ref_init(&lun->lun_ref, core_tpg_lun_ref_release,
+	ret = percpu_ref_init(&lun->lun_ref, core_tpg_lun_ref_release, 0,
 			      GFP_KERNEL);
 	if (ret < 0)
 		return ret;

commit a34375ef9e65340a138fc0be287de5c940d260fc
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Sep 8 09:51:30 2014 +0900

    percpu-refcount: add @gfp to percpu_ref_init()
    
    Percpu allocator now supports allocation mask.  Add @gfp to
    percpu_ref_init() so that !GFP_KERNEL allocation masks can be used
    with percpu_refs too.
    
    This patch doesn't make any functional difference.
    
    v2: blk-mq conversion was missing.  Updated.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Kent Overstreet <koverstreet@google.com>
    Cc: Benjamin LaHaise <bcrl@kvack.org>
    Cc: Li Zefan <lizefan@huawei.com>
    Cc: Nicholas A. Bellinger <nab@linux-iscsi.org>
    Cc: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index fddfae61222f..4ab6da338585 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -819,7 +819,8 @@ int core_tpg_add_lun(
 {
 	int ret;
 
-	ret = percpu_ref_init(&lun->lun_ref, core_tpg_lun_ref_release);
+	ret = percpu_ref_init(&lun->lun_ref, core_tpg_lun_ref_release,
+			      GFP_KERNEL);
 	if (ret < 0)
 		return ret;
 

commit 9a1049da9bd2cd83fe11d46433e603c193aa9c71
Author: Tejun Heo <tj@kernel.org>
Date:   Sat Jun 28 08:10:14 2014 -0400

    percpu-refcount: require percpu_ref to be exited explicitly
    
    Currently, a percpu_ref undoes percpu_ref_init() automatically by
    freeing the allocated percpu area when the percpu_ref is killed.
    While seemingly convenient, this has the following niggles.
    
    * It's impossible to re-init a released reference counter without
      going through re-allocation.
    
    * In the similar vein, it's impossible to initialize a percpu_ref
      count with static percpu variables.
    
    * We need and have an explicit destructor anyway for failure paths -
      percpu_ref_cancel_init().
    
    This patch removes the automatic percpu counter freeing in
    percpu_ref_kill_rcu() and repurposes percpu_ref_cancel_init() into a
    generic destructor now named percpu_ref_exit().  percpu_ref_destroy()
    is considered but it gets confusing with percpu_ref_kill() while
    "exit" clearly indicates that it's the counterpart of
    percpu_ref_init().
    
    All percpu_ref_cancel_init() users are updated to invoke
    percpu_ref_exit() instead and explicit percpu_ref_exit() calls are
    added to the destruction path of all percpu_ref users.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Benjamin LaHaise <bcrl@kvack.org>
    Cc: Kent Overstreet <kmo@daterainc.com>
    Cc: Christoph Lameter <cl@linux-foundation.org>
    Cc: Benjamin LaHaise <bcrl@kvack.org>
    Cc: Nicholas A. Bellinger <nab@linux-iscsi.org>
    Cc: Li Zefan <lizefan@huawei.com>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index c036595b17cf..fddfae61222f 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -825,7 +825,7 @@ int core_tpg_add_lun(
 
 	ret = core_dev_export(dev, tpg, lun);
 	if (ret < 0) {
-		percpu_ref_cancel_init(&lun->lun_ref);
+		percpu_ref_exit(&lun->lun_ref);
 		return ret;
 	}
 
@@ -880,5 +880,7 @@ int core_tpg_post_dellun(
 	lun->lun_status = TRANSPORT_LUN_STATUS_FREE;
 	spin_unlock(&tpg->tpg_lun_lock);
 
+	percpu_ref_exit(&lun->lun_ref);
+
 	return 0;
 }

commit 4e13c5d0212f25d69a97606b9d5a85edb52a7737
Merge: deb2a1d29bf0 5259a06ef970
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 31 15:31:23 2014 -0800

    Merge branch 'for-next' of git://git.kernel.org/pub/scm/linux/kernel/git/nab/target-pending
    
    Pull SCSI target updates from Nicholas Bellinger:
     "The highlights this round include:
    
      - add support for SCSI Referrals (Hannes)
      - add support for T10 DIF into target core (nab + mkp)
      - add support for T10 DIF emulation in FILEIO + RAMDISK backends (Sagi + nab)
      - add support for T10 DIF -> bio_integrity passthrough in IBLOCK backend (nab)
      - prep changes to iser-target for >= v3.15 T10 DIF support (Sagi)
      - add support for qla2xxx N_Port ID Virtualization - NPIV (Saurav + Quinn)
      - allow percpu_ida_alloc() to receive task state bitmask (Kent)
      - fix >= v3.12 iscsi-target session reset hung task regression (nab)
      - fix >= v3.13 percpu_ref se_lun->lun_ref_active race (nab)
      - fix a long-standing network portal creation race (Andy)"
    
    * 'for-next' of git://git.kernel.org/pub/scm/linux/kernel/git/nab/target-pending: (51 commits)
      target: Fix percpu_ref_put race in transport_lun_remove_cmd
      target/iscsi: Fix network portal creation race
      target: Report bad sector in sense data for DIF errors
      iscsi-target: Convert gfp_t parameter to task state bitmask
      iscsi-target: Fix connection reset hang with percpu_ida_alloc
      percpu_ida: Make percpu_ida_alloc + callers accept task state bitmask
      iscsi-target: Pre-allocate more tags to avoid ack starvation
      qla2xxx: Configure NPIV fc_vport via tcm_qla2xxx_npiv_make_lport
      qla2xxx: Enhancements to enable NPIV support for QLOGIC ISPs with TCM/LIO.
      qla2xxx: Fix scsi_host leak on qlt_lport_register callback failure
      IB/isert: pass scatterlist instead of cmd to fast_reg_mr routine
      IB/isert: Move fastreg descriptor creation to a function
      IB/isert: Avoid frwr notation, user fastreg
      IB/isert: seperate connection protection domains and dma MRs
      tcm_loop: Enable DIF/DIX modes in SCSI host LLD
      target/rd: Add DIF protection into rd_execute_rw
      target/rd: Add support for protection SGL setup + release
      target/rd: Refactor rd_build_device_space + rd_release_device_space
      target/file: Add DIF protection support to fd_execute_rw
      target/file: Add DIF protection init/format support
      ...

commit de06875f089678f4f9f1e8d5e1421fb0ceab12d0
Author: Andy Grover <agrover@redhat.com>
Date:   Tue Nov 26 11:49:24 2013 -0800

    target: Remove extra percpu_ref_init
    
    lun->lun_ref is also initialized in core_tpg_post_addlun, so it doesn't
    need to be done in core_tpg_setup_virtual_lun0.
    
    (nab: Drop left-over percpu_ref_cancel_init in failure path)
    
    Signed-off-by: Andy Grover <agrover@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index f755712a9a0d..2a573de19a9f 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -656,15 +656,9 @@ static int core_tpg_setup_virtual_lun0(struct se_portal_group *se_tpg)
 	spin_lock_init(&lun->lun_sep_lock);
 	init_completion(&lun->lun_ref_comp);
 
-	ret = percpu_ref_init(&lun->lun_ref, core_tpg_lun_ref_release);
-	if (ret < 0)
-		return ret;
-
 	ret = core_tpg_post_addlun(se_tpg, lun, lun_access, dev);
-	if (ret < 0) {
-		percpu_ref_cancel_init(&lun->lun_ref);
+	if (ret < 0)
 		return ret;
-	}
 
 	return 0;
 }

commit 340dbf729c3395cf1317890d033aa9ac7347766c
Author: Andy Grover <agrover@redhat.com>
Date:   Thu Dec 12 16:12:33 2013 -0800

    target: Don't use void* when passing dev in core_tpg_add_lun
    
    Especially since it's actually a device.
    
    Signed-off-by: Andy Grover <agrover@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index a1dbc9488183..d1df39a05d88 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -823,7 +823,7 @@ int core_tpg_add_lun(
 	struct se_portal_group *tpg,
 	struct se_lun *lun,
 	u32 lun_access,
-	void *lun_ptr)
+	struct se_device *dev)
 {
 	int ret;
 
@@ -831,7 +831,7 @@ int core_tpg_add_lun(
 	if (ret < 0)
 		return ret;
 
-	ret = core_dev_export(lun_ptr, tpg, lun);
+	ret = core_dev_export(dev, tpg, lun);
 	if (ret < 0) {
 		percpu_ref_cancel_init(&lun->lun_ref);
 		return ret;

commit d344f8a15637e8b57a0d05a6d50182c11de08606
Author: Andy Grover <agrover@redhat.com>
Date:   Tue Nov 26 12:07:54 2013 -0800

    target: Rename core_tpg_{pre,post}_addlun for clarity
    
    "pre" is really an allocation function. The only time it isn't called is
    for virtual_lun0, which is statically allocated. Renaming that to "alloc"
    lets the other function not need to be "post", and just be called
    core_tpg_add_lun.
    
    (nab: fix minor applying fuzz in core_tpg_setup_virtual_lun0)
    
    Signed-off-by: Andy Grover <agrover@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index f697f8baec54..a1dbc9488183 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -662,7 +662,7 @@ static int core_tpg_setup_virtual_lun0(struct se_portal_group *se_tpg)
 	if (ret < 0)
 		return ret;
 
-	ret = core_tpg_post_addlun(se_tpg, lun, lun_access, dev);
+	ret = core_tpg_add_lun(se_tpg, lun, lun_access, dev);
 	if (ret < 0) {
 		percpu_ref_cancel_init(&lun->lun_ref);
 		return ret;
@@ -789,7 +789,7 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 }
 EXPORT_SYMBOL(core_tpg_deregister);
 
-struct se_lun *core_tpg_pre_addlun(
+struct se_lun *core_tpg_alloc_lun(
 	struct se_portal_group *tpg,
 	u32 unpacked_lun)
 {
@@ -819,7 +819,7 @@ struct se_lun *core_tpg_pre_addlun(
 	return lun;
 }
 
-int core_tpg_post_addlun(
+int core_tpg_add_lun(
 	struct se_portal_group *tpg,
 	struct se_lun *lun,
 	u32 lun_access,

commit a51d5229d10dd3a337b674ce8603437d2996c5c3
Author: Roland Dreier <roland@purestorage.com>
Date:   Sat Nov 23 10:35:58 2013 -0800

    target: Remove write-only stats fields and lock from struct se_node_acl
    
    Commit 04f3b31bff72 ("iscsi-target: Convert iscsi_session statistics to
    atomic_long_t") removed the updating of these fields in iscsi (the only
    fabric driver that ever touched these counters), and the core has no way
    to report or otherwise use the values.  Remove the last remnants of
    these counters.
    
    Signed-off-by: Roland Dreier <roland@purestorage.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index f697f8baec54..f755712a9a0d 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -278,7 +278,6 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 	snprintf(acl->initiatorname, TRANSPORT_IQN_LEN, "%s", initiatorname);
 	acl->se_tpg = tpg;
 	acl->acl_index = scsi_get_new_index(SCSI_AUTH_INTR_INDEX);
-	spin_lock_init(&acl->stats_lock);
 	acl->dynamic_node_acl = 1;
 
 	tpg->se_tpg_tfo->set_default_node_attributes(acl);
@@ -406,7 +405,6 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 	snprintf(acl->initiatorname, TRANSPORT_IQN_LEN, "%s", initiatorname);
 	acl->se_tpg = tpg;
 	acl->acl_index = scsi_get_new_index(SCSI_AUTH_INTR_INDEX);
-	spin_lock_init(&acl->stats_lock);
 
 	tpg->se_tpg_tfo->set_default_node_attributes(acl);
 

commit 4a9a6c8d538eff6d627fa14409c7c25aff652541
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Wed Nov 6 21:05:19 2013 -0800

    target: Drop left-over se_lun->lun_cmd_list shutdown code
    
    Now with percpu refcounting for se_lun in place, go ahead and drop
    the legacy per se_cmd accounting for se_lun shutdown.
    
    This includes __transport_clear_lun_from_sessions(), the associated
    transport_lun_wait_for_tasks() logic, along with a handful of now
    unused se_cmd structure members and ->transport_state bits.
    
    Cc: Kent Overstreet <kmo@daterainc.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index f321af04ef03..f697f8baec54 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -654,9 +654,7 @@ static int core_tpg_setup_virtual_lun0(struct se_portal_group *se_tpg)
 	atomic_set(&lun->lun_acl_count, 0);
 	init_completion(&lun->lun_shutdown_comp);
 	INIT_LIST_HEAD(&lun->lun_acl_list);
-	INIT_LIST_HEAD(&lun->lun_cmd_list);
 	spin_lock_init(&lun->lun_acl_lock);
-	spin_lock_init(&lun->lun_cmd_lock);
 	spin_lock_init(&lun->lun_sep_lock);
 	init_completion(&lun->lun_ref_comp);
 
@@ -706,9 +704,7 @@ int core_tpg_register(
 		atomic_set(&lun->lun_acl_count, 0);
 		init_completion(&lun->lun_shutdown_comp);
 		INIT_LIST_HEAD(&lun->lun_acl_list);
-		INIT_LIST_HEAD(&lun->lun_cmd_list);
 		spin_lock_init(&lun->lun_acl_lock);
-		spin_lock_init(&lun->lun_cmd_lock);
 		spin_lock_init(&lun->lun_sep_lock);
 		init_completion(&lun->lun_ref_comp);
 	}
@@ -849,14 +845,6 @@ int core_tpg_post_addlun(
 	return 0;
 }
 
-static void core_tpg_shutdown_lun(
-	struct se_portal_group *tpg,
-	struct se_lun *lun)
-{
-	core_clear_lun_from_tpg(lun, tpg);
-	transport_clear_lun_ref(lun);
-}
-
 struct se_lun *core_tpg_pre_dellun(
 	struct se_portal_group *tpg,
 	u32 unpacked_lun)
@@ -891,7 +879,8 @@ int core_tpg_post_dellun(
 	struct se_portal_group *tpg,
 	struct se_lun *lun)
 {
-	core_tpg_shutdown_lun(tpg, lun);
+	core_clear_lun_from_tpg(lun, tpg);
+	transport_clear_lun_ref(lun);
 
 	core_dev_unexport(lun->lun_se_dev, tpg, lun);
 

commit 5277797dc4ed873d067477d84e910b39d113f649
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Wed Nov 6 21:03:43 2013 -0800

    target: Add percpu refcounting for se_lun access
    
    This patch adds percpu refcounting for se_lun access that allows the
    association of an se_lun + se_cmd in transport_lookup_cmd_lun() to
    occur without an extra list_head for tracking outstanding I/O during
    se_lun shutdown.
    
    This effectively changes se_lun shutdown logic to wait for outstanding
    I/O percpu references to complete in transport_lun_remove_cmd() using
    se_lun->lun_ref_comp, instead of explicitly draining the per se_lun
    command list and waiting for individual se_cmd descriptor processing
    to complete.
    
    Cc: Kent Overstreet <kmo@daterainc.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index ec992208dc55..f321af04ef03 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -634,6 +634,13 @@ int core_tpg_set_initiator_node_tag(
 }
 EXPORT_SYMBOL(core_tpg_set_initiator_node_tag);
 
+static void core_tpg_lun_ref_release(struct percpu_ref *ref)
+{
+	struct se_lun *lun = container_of(ref, struct se_lun, lun_ref);
+
+	complete(&lun->lun_ref_comp);
+}
+
 static int core_tpg_setup_virtual_lun0(struct se_portal_group *se_tpg)
 {
 	/* Set in core_dev_setup_virtual_lun0() */
@@ -651,11 +658,18 @@ static int core_tpg_setup_virtual_lun0(struct se_portal_group *se_tpg)
 	spin_lock_init(&lun->lun_acl_lock);
 	spin_lock_init(&lun->lun_cmd_lock);
 	spin_lock_init(&lun->lun_sep_lock);
+	init_completion(&lun->lun_ref_comp);
 
-	ret = core_tpg_post_addlun(se_tpg, lun, lun_access, dev);
+	ret = percpu_ref_init(&lun->lun_ref, core_tpg_lun_ref_release);
 	if (ret < 0)
 		return ret;
 
+	ret = core_tpg_post_addlun(se_tpg, lun, lun_access, dev);
+	if (ret < 0) {
+		percpu_ref_cancel_init(&lun->lun_ref);
+		return ret;
+	}
+
 	return 0;
 }
 
@@ -696,6 +710,7 @@ int core_tpg_register(
 		spin_lock_init(&lun->lun_acl_lock);
 		spin_lock_init(&lun->lun_cmd_lock);
 		spin_lock_init(&lun->lun_sep_lock);
+		init_completion(&lun->lun_ref_comp);
 	}
 
 	se_tpg->se_tpg_type = se_tpg_type;
@@ -816,10 +831,16 @@ int core_tpg_post_addlun(
 {
 	int ret;
 
-	ret = core_dev_export(lun_ptr, tpg, lun);
+	ret = percpu_ref_init(&lun->lun_ref, core_tpg_lun_ref_release);
 	if (ret < 0)
 		return ret;
 
+	ret = core_dev_export(lun_ptr, tpg, lun);
+	if (ret < 0) {
+		percpu_ref_cancel_init(&lun->lun_ref);
+		return ret;
+	}
+
 	spin_lock(&tpg->tpg_lun_lock);
 	lun->lun_access = lun_access;
 	lun->lun_status = TRANSPORT_LUN_STATUS_ACTIVE;
@@ -833,7 +854,7 @@ static void core_tpg_shutdown_lun(
 	struct se_lun *lun)
 {
 	core_clear_lun_from_tpg(lun, tpg);
-	transport_clear_lun_from_sessions(lun);
+	transport_clear_lun_ref(lun);
 }
 
 struct se_lun *core_tpg_pre_dellun(

commit b3fde035714b83ef7ddbbd5a520a2150d990349b
Author: Thomas Glanzmann <thomas@glanzmann.de>
Date:   Mon Oct 7 23:13:02 2013 +0200

    target: Export symbol core_tpg_check_initiator_node_acl
    
    Export symbol core_tpg_check_initiator_node_acl and move prototype from the
    private drivers/target/target_core_internal.h to the public
    include/target/target_core_fabric.h
    
    Signed-off-by: Thomas Glanzmann <thomas@glanzmann.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index b9a6ec0aa5fe..ec992208dc55 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -116,6 +116,7 @@ struct se_node_acl *core_tpg_get_initiator_node_acl(
 
 	return acl;
 }
+EXPORT_SYMBOL(core_tpg_get_initiator_node_acl);
 
 /*	core_tpg_add_node_to_devs():
  *

commit 4c76251e8e8f704ed7eace603a8041458a1ed16f
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Thu Sep 5 15:29:12 2013 -0700

    target: Update copyright ownership/year information to 2013
    
    Update copyright ownership/year information for target-core,
    loopback, iscsi-target, tcm_qla2xx, vhost and iser-target.
    
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index aac9d2727e3c..b9a6ec0aa5fe 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -3,7 +3,7 @@
  *
  * This file contains generic Target Portal Group related functions.
  *
- * (c) Copyright 2002-2012 RisingTide Systems LLC.
+ * (c) Copyright 2002-2013 Datera, Inc.
  *
  * Nicholas A. Bellinger <nab@kernel.org>
  *

commit 0fb889b83186e54c0cfa79516599f2267fb553fb
Author: Wei Yongjun <yongjun_wei@trendmicro.com.cn>
Date:   Fri Mar 15 17:19:26 2013 +0800

    target: fix possible memory leak in core_tpg_register()
    
    'se_tpg->tpg_lun_list' is malloced in core_tpg_register() and should be freed
    before leaving from the error handling cases, otherwise it will cause memory
    leak.
    'se_tpg' is malloced out of this function, and will be freed if we return error, so
    remove free for 'se_tpg'.
    
    Signed-off-by: Wei Yongjun <yongjun_wei@trendmicro.com.cn>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 9169d6a5d7e4..aac9d2727e3c 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -711,7 +711,8 @@ int core_tpg_register(
 
 	if (se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL) {
 		if (core_tpg_setup_virtual_lun0(se_tpg) < 0) {
-			kfree(se_tpg);
+			array_free(se_tpg->tpg_lun_list,
+				   TRANSPORT_MAX_LUNS_PER_TPG);
 			return -ENOMEM;
 		}
 	}

commit fcf29481fb8e106daad6688f2e898226ee928992
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Mon Feb 18 18:00:33 2013 -0800

    target: Fix lookup of dynamic NodeACLs during cached demo-mode operation
    
    This patch fixes a bug in core_tpg_check_initiator_node_acl() ->
    core_tpg_get_initiator_node_acl() where a dynamically created
    se_node_acl generated during session login would be skipped during
    subsequent lookup due to the '!acl->dynamic_node_acl' check, causing
    a new se_node_acl to be created with a duplicate ->initiatorname.
    
    This would occur when a fabric endpoint was configured with
    TFO->tpg_check_demo_mode()=1 + TPF->tpg_check_demo_mode_cache()=1
    preventing the release of an existing se_node_acl during se_session
    shutdown.
    
    Also, drop the unnecessary usage of core_tpg_get_initiator_node_acl()
    within core_dev_init_initiator_node_lun_acl() that originally
    required the extra '!acl->dynamic_node_acl' check, and just pass
    the configfs provided se_node_acl pointer instead.
    
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 5192ac0337f7..9169d6a5d7e4 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -111,16 +111,10 @@ struct se_node_acl *core_tpg_get_initiator_node_acl(
 	struct se_node_acl *acl;
 
 	spin_lock_irq(&tpg->acl_node_lock);
-	list_for_each_entry(acl, &tpg->acl_node_list, acl_list) {
-		if (!strcmp(acl->initiatorname, initiatorname) &&
-		    !acl->dynamic_node_acl) {
-			spin_unlock_irq(&tpg->acl_node_lock);
-			return acl;
-		}
-	}
+	acl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);
 	spin_unlock_irq(&tpg->acl_node_lock);
 
-	return NULL;
+	return acl;
 }
 
 /*	core_tpg_add_node_to_devs():

commit 79e62fc3827bd437c304c1810f36896fc1e717b1
Author: Andy Grover <agrover@redhat.com>
Date:   Tue Dec 11 16:30:53 2012 -0800

    target/iscsi_target: Add NodeACL tags for initiator group support
    
    Thanks for reviews, looking a lot better.
    
    ---- 8< ----
    
    Initiator access config could be easier. The way other storage vendors
    have addressed this is to support initiator groups: the admin adds
    initiator WWNs to the group, and then LUN permissions can be granted for
    the entire group at once.
    
    Instead of changing ktarget's configfs interface, this patch keeps
    the configfs interface per-initiator-wwn and just adds a 'tag' field
    for each. This should be enough for user tools like targetcli to group
    initiator ACLs and sync their configurations.
    
    acl_tag is not used internally, but needs to be kept in configfs so that
    all user tools can avoid dependencies on each other.
    
    Code tested to work, although userspace pieces still to be implemented.
    
    Signed-off-by: Andy Grover <agrover@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 0163309e2aba..5192ac0337f7 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -616,6 +616,29 @@ int core_tpg_set_initiator_node_queue_depth(
 }
 EXPORT_SYMBOL(core_tpg_set_initiator_node_queue_depth);
 
+/*	core_tpg_set_initiator_node_tag():
+ *
+ *	Initiator nodeacl tags are not used internally, but may be used by
+ *	userspace to emulate aliases or groups.
+ *	Returns length of newly-set tag or -EINVAL.
+ */
+int core_tpg_set_initiator_node_tag(
+	struct se_portal_group *tpg,
+	struct se_node_acl *acl,
+	const char *new_tag)
+{
+	if (strlen(new_tag) >= MAX_ACL_TAG_SIZE)
+		return -EINVAL;
+
+	if (!strncmp("NULL", new_tag, 4)) {
+		acl->acl_tag[0] = '\0';
+		return 0;
+	}
+
+	return snprintf(acl->acl_tag, MAX_ACL_TAG_SIZE, "%s", new_tag);
+}
+EXPORT_SYMBOL(core_tpg_set_initiator_node_tag);
+
 static int core_tpg_setup_virtual_lun0(struct se_portal_group *se_tpg)
 {
 	/* Set in core_dev_setup_virtual_lun0() */

commit 0ff8754981261a80f4b77db2536dfea92c2d4539
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Tue Dec 4 23:43:57 2012 -0800

    target: Add link_magic for fabric allow_link destination target_items
    
    This patch adds [dev,lun]_link_magic value assignment + checks within generic
    target_fabric_port_link() and target_fabric_mappedlun_link() code to ensure
    destination config_item *target_item sent from configfs_symlink() ->
    config_item_operations->allow_link() is the underlying se_device->dev_group
    and se_lun->lun_group that we expect to symlink.
    
    Reported-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Cc: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Cc: stable@vger.kernel.org
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index d84cc0a8739e..0163309e2aba 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -669,6 +669,7 @@ int core_tpg_register(
 	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
 		lun = se_tpg->tpg_lun_list[i];
 		lun->unpacked_lun = i;
+		lun->lun_link_magic = SE_LUN_LINK_MAGIC;
 		lun->lun_status = TRANSPORT_LUN_STATUS_FREE;
 		atomic_set(&lun->lun_acl_count, 0);
 		init_completion(&lun->lun_shutdown_comp);

commit fd9a11d7076e1d534a760032d2b8f3b59e10f9b5
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Fri Nov 9 14:51:48 2012 -0800

    target: Update copyright information to 2012
    
    v2: Use correct target_core_stat.c 2006 copyright year
    v3: Drop extra unnessary legal verbage from header (hch)
    
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index a531fe282b1e..d84cc0a8739e 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -3,10 +3,7 @@
  *
  * This file contains generic Target Portal Group related functions.
  *
- * Copyright (c) 2002, 2003, 2004, 2005 PyX Technologies, Inc.
- * Copyright (c) 2005, 2006, 2007 SBE, Inc.
- * Copyright (c) 2007-2010 Rising Tide Systems
- * Copyright (c) 2008-2010 Linux-iSCSI.org
+ * (c) Copyright 2002-2012 RisingTide Systems LLC.
  *
  * Nicholas A. Bellinger <nab@kernel.org>
  *

commit 35d1efe80500a55f9aa01b305a6714ec78c33764
Author: Masanari Iida <standby24x7@gmail.com>
Date:   Thu Aug 16 22:43:13 2012 +0900

    target: Fix minor spelling typos in drivers/target
    
    Correct spelling typo in printk and comment within drivers/target.
    
    Signed-off-by: Masanari Iida <standby24x7@gmail.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index b8628a5014b9..a531fe282b1e 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -303,7 +303,7 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 	}
 	/*
 	 * Here we only create demo-mode MappedLUNs from the active
-	 * TPG LUNs if the fabric is not explictly asking for
+	 * TPG LUNs if the fabric is not explicitly asking for
 	 * tpg_check_demo_mode_login_only() == 1.
 	 */
 	if ((tpg->se_tpg_tfo->tpg_check_demo_mode_login_only == NULL) ||

commit e80ac6c4cc073d54daef8ba4ced88347d130d314
Author: Andy Grover <agrover@redhat.com>
Date:   Thu Jul 12 17:34:58 2012 -0700

    target: refactor core_update_device_list_for_node()
    
    Code was almost entirely divided based on value of bool param "enable".
    
    Split it into two functions.
    
    Signed-off-by: Andy Grover <agrover@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 5ca340cff111..b8628a5014b9 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -77,8 +77,8 @@ static void core_clear_initiator_node_from_tpg(
 
 		lun = deve->se_lun;
 		spin_unlock_irq(&nacl->device_list_lock);
-		core_update_device_list_for_node(lun, NULL, deve->mapped_lun,
-			TRANSPORT_LUNFLAGS_NO_ACCESS, nacl, tpg, 0);
+		core_disable_device_list_for_node(lun, NULL, deve->mapped_lun,
+			TRANSPORT_LUNFLAGS_NO_ACCESS, nacl, tpg);
 
 		spin_lock_irq(&nacl->device_list_lock);
 	}
@@ -172,8 +172,8 @@ void core_tpg_add_node_to_devs(
 			(lun_access == TRANSPORT_LUNFLAGS_READ_WRITE) ?
 			"READ-WRITE" : "READ-ONLY");
 
-		core_update_device_list_for_node(lun, NULL, lun->unpacked_lun,
-				lun_access, acl, tpg, 1);
+		core_enable_device_list_for_node(lun, NULL, lun->unpacked_lun,
+				lun_access, acl, tpg);
 		spin_lock(&tpg->tpg_lun_lock);
 	}
 	spin_unlock(&tpg->tpg_lun_lock);

commit cdf88a2fe3825458c584cd751aa843ab3af6a42c
Author: Andy Grover <agrover@redhat.com>
Date:   Thu Jul 12 17:34:57 2012 -0700

    target: Eliminate else using boolean logic
    
    Signed-off-by: Andy Grover <agrover@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 8bd58e284185..5ca340cff111 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -306,10 +306,8 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 	 * TPG LUNs if the fabric is not explictly asking for
 	 * tpg_check_demo_mode_login_only() == 1.
 	 */
-	if ((tpg->se_tpg_tfo->tpg_check_demo_mode_login_only != NULL) &&
-	    (tpg->se_tpg_tfo->tpg_check_demo_mode_login_only(tpg) == 1))
-		do { ; } while (0);
-	else
+	if ((tpg->se_tpg_tfo->tpg_check_demo_mode_login_only == NULL) ||
+	    (tpg->se_tpg_tfo->tpg_check_demo_mode_login_only(tpg) != 1))
 		core_tpg_add_node_to_devs(acl, tpg);
 
 	spin_lock_irq(&tpg->acl_node_lock);

commit c9bfa7d75ba7269c97595f03c3152372e8b37823
Merge: f4c16c581766 f80e8ed39514
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 21 17:37:09 2012 -0700

    Merge branch 'for-next' of git://git.kernel.org/pub/scm/linux/kernel/git/nab/target-pending
    
    Pull scsi-target changes from Nicholas Bellinger:
     "There has been lots of work in existing code in a number of areas this
      past cycle.  The major highlights have been:
    
       * Removal of transport_do_task_sg_chain() from core + fabrics
         (Roland)
       * target-core: Removal of se_task abstraction from target-core and
         enforce hw_max_sectors for pSCSI backends (hch)
       * Re-factoring of iscsi-target tx immediate/response queues (agrover)
       * Conversion of iscsi-target back to using target core memory
         allocation logic (agrover)
    
      We've had one last minute iscsi-target patch go into for-next to
      address a nasty regression bug related to the target core allocation
      logic conversion from agrover that is not included in friday's
      linux-next build, but has been included in this series.
    
      On the new fabric module code front for-3.5, here is a brief status
      update for the three currently in flight this round:
    
       * usb-gadget target driver:
    
      Sebastian Siewior's driver for supporting usb-gadget target mode
      operation.  This will be going out as a separate PULL request from
      target-pending/usb-target-merge with subsystem maintainer ACKs.  There
      is one minor target-core patch in this series required to function.
    
       * sbp ieee-1394/firewire target driver:
    
      Chris Boot's driver for supportting the Serial Block Protocol (SBP)
      across IEEE-1394 Firewire hardware.  This will be going out as a
      separate PULL request from target-pending/sbp-target-merge with two
      additional drivers/firewire/ patches w/ subsystem maintainer ACKs.
    
       * qla2xxx LLD target mode infrastructure changes + tcm_qla2xxx:
    
      The Qlogic >= 24xx series HW target mode LLD infrastructure patch-set
      and tcm_qla2xxx fabric driver.  Support for FC target mode using
      qla2xxx LLD code has been officially submitted by Qlogic to James
      below, and is currently outstanding but not yet merged into
      scsi.git/for-next..
    
        [PATCH 00/22] qla2xxx: Updates for scsi "misc" branch
        http://www.spinics.net/lists/linux-scsi/msg59350.html
    
      Note there are *zero* direct dependencies upon this for-next series
      for the qla2xxx LLD target + tcm_qla2xxx patches submitted above, and
      over the last days the target mode team has been tracking down an
      tcm_qla2xxx specific active I/O shutdown bug that appears to now be
      almost squashed for 3.5-rc-fixes."
    
    * 'for-next' of git://git.kernel.org/pub/scm/linux/kernel/git/nab/target-pending: (47 commits)
      iscsi-target: Fix iov_count calculation bug in iscsit_allocate_iovecs
      iscsi-target: remove dead code in iscsi_check_valuelist_for_support
      target: Handle ATA_16 passthrough for pSCSI backend devices
      target: Add MI_REPORT_TARGET_PGS ext. header + implict_trans_secs attribute
      target: Fix MAINTENANCE_IN service action CDB checks to use lower 5 bits
      target: add support for the WRITE_VERIFY command
      target: make target_put_session void
      target: cleanup transport_execute_tasks()
      target: Remove max_sectors device attribute for modern se_task less code
      target: lock => unlock typo in transport_lun_wait_for_tasks
      target: Enforce hw_max_sectors for SCF_SCSI_DATA_SG_IO_CDB
      target: remove the t_se_count field in struct se_cmd
      target: remove the t_task_cdbs_ex_left field in struct se_cmd
      target: remove the t_task_cdbs_left field in struct se_cmd
      target: remove struct se_task
      target: move the state and execute lists to the command
      target: simplify command to task linkage
      target: always allocate a single task
      target: replace ->execute_task with ->execute_cmd
      target: remove the task_sectors field in struct se_task
      ...

commit cfebf8f42f47327fa54cf05c19b98f4bd5236a26
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Thu May 10 22:05:49 2012 -0700

    target: Drop incorrect se_lun_acl release for dynamic -> explict ACL conversion
    
    This patch removes some potentially problematic legacy code within
    core_clear_initiator_node_from_tpg() that was originally intended to
    release left over se_lun_acl setup during dynamic NodeACL+MappedLUN
    generate when running with TPG demo-mode operation.
    
    Since we now only ever expect to allocate and release se_lun_acl from
    within target_core_fabric_configfs.c:target_fabric_make_mappedlun() and
    target_fabric_drop_mappedlun() context respectively, this code for
    demo-mode release is incorrect and needs to be removed.
    
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Andy Grover <agrover@redhat.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 70c3ffb981e7..e320ec24aa1b 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -60,7 +60,6 @@ static void core_clear_initiator_node_from_tpg(
 	int i;
 	struct se_dev_entry *deve;
 	struct se_lun *lun;
-	struct se_lun_acl *acl, *acl_tmp;
 
 	spin_lock_irq(&nacl->device_list_lock);
 	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
@@ -81,28 +80,7 @@ static void core_clear_initiator_node_from_tpg(
 		core_update_device_list_for_node(lun, NULL, deve->mapped_lun,
 			TRANSPORT_LUNFLAGS_NO_ACCESS, nacl, tpg, 0);
 
-		spin_lock(&lun->lun_acl_lock);
-		list_for_each_entry_safe(acl, acl_tmp,
-					&lun->lun_acl_list, lacl_list) {
-			if (!strcmp(acl->initiatorname, nacl->initiatorname) &&
-			    (acl->mapped_lun == deve->mapped_lun))
-				break;
-		}
-
-		if (!acl) {
-			pr_err("Unable to locate struct se_lun_acl for %s,"
-				" mapped_lun: %u\n", nacl->initiatorname,
-				deve->mapped_lun);
-			spin_unlock(&lun->lun_acl_lock);
-			spin_lock_irq(&nacl->device_list_lock);
-			continue;
-		}
-
-		list_del(&acl->lacl_list);
-		spin_unlock(&lun->lun_acl_lock);
-
 		spin_lock_irq(&nacl->device_list_lock);
-		kfree(acl);
 	}
 	spin_unlock_irq(&nacl->device_list_lock);
 }

commit 58d926187758f76647d68e2f51ce44e6ace81873
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Tue Mar 20 21:26:48 2012 -0700

    target: Remove obsolete DF_READ_ONLY usage
    
    This was used at one time as a hack by FILEIO backend registration to
    allow a struct block_device that was claimed with blkdev_get (by a local
    filesystem mount for example) to be exported as read-only (SCSI WP=1).
    
    Since FILEIO backend registration will no longer attempt to obtain
    exclusive access to an underlying struct block_device here, this flag is
    now obsolete.
    
    Reported-by: Roland Dreier <roland@purestorage.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 70c3ffb981e7..c672a40cbfe2 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -175,10 +175,7 @@ void core_tpg_add_node_to_devs(
 		 * demo_mode_write_protect is ON, or READ_ONLY;
 		 */
 		if (!tpg->se_tpg_tfo->tpg_check_demo_mode_write_protect(tpg)) {
-			if (dev->dev_flags & DF_READ_ONLY)
-				lun_access = TRANSPORT_LUNFLAGS_READ_ONLY;
-			else
-				lun_access = TRANSPORT_LUNFLAGS_READ_WRITE;
+			lun_access = TRANSPORT_LUNFLAGS_READ_WRITE;
 		} else {
 			/*
 			 * Allow only optical drives to issue R/W in default RO

commit 281689051a628e5341ce1efcfafde9d60f2f6fbb
Author: Jrn Engel <joern@logfs.org>
Date:   Thu Mar 15 15:06:58 2012 -0400

    target: remove obvious warnings
    
    Get rid of a bunch of write-only variables.  In a number of cases I
    suspect actual bugs to be present, so I left all of those for a second
    look.
    
    (nab: fix lio-core patch fuzz)
    
    Signed-off-by: Joern Engel <joern@logfs.org>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index c0fecde02fd0..70c3ffb981e7 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -359,7 +359,7 @@ void core_tpg_wait_for_nacl_pr_ref(struct se_node_acl *nacl)
 
 void core_tpg_clear_object_luns(struct se_portal_group *tpg)
 {
-	int i, ret;
+	int i;
 	struct se_lun *lun;
 
 	spin_lock(&tpg->tpg_lun_lock);
@@ -371,7 +371,7 @@ void core_tpg_clear_object_luns(struct se_portal_group *tpg)
 			continue;
 
 		spin_unlock(&tpg->tpg_lun_lock);
-		ret = core_dev_del_lun(tpg, lun->unpacked_lun);
+		core_dev_del_lun(tpg, lun->unpacked_lun);
 		spin_lock(&tpg->tpg_lun_lock);
 	}
 	spin_unlock(&tpg->tpg_lun_lock);
@@ -483,12 +483,11 @@ int core_tpg_del_initiator_node_acl(
 	LIST_HEAD(sess_list);
 	struct se_session *sess, *sess_tmp;
 	unsigned long flags;
-	int dynamic_acl = 0, rc;
+	int rc;
 
 	spin_lock_irq(&tpg->acl_node_lock);
 	if (acl->dynamic_node_acl) {
 		acl->dynamic_node_acl = 0;
-		dynamic_acl = 1;
 	}
 	list_del(&acl->acl_list);
 	tpg->num_node_acls--;

commit f2083241f23722207676025abbb45a301d412e69
Author: Jrn Engel <joern@logfs.org>
Date:   Thu Mar 15 15:05:40 2012 -0400

    target: Use array_zalloc for device_list
    
    Turns an order-8 allocation into slab-sized ones, thereby preventing
    allocation failures with memory fragmentation.
    
    This likely saves memory as well, as the slab allocator can pack objects
    more tightly than the buddy allocator.
    
    (nab: Fix lio-core patch fuzz)
    
    Signed-off-by: Joern Engel <joern@logfs.org>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 146fe47f11c1..c0fecde02fd0 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -64,7 +64,7 @@ static void core_clear_initiator_node_from_tpg(
 
 	spin_lock_irq(&nacl->device_list_lock);
 	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
-		deve = &nacl->device_list[i];
+		deve = nacl->device_list[i];
 
 		if (!(deve->lun_flags & TRANSPORT_LUNFLAGS_INITIATOR_ACCESS))
 			continue;
@@ -259,15 +259,15 @@ static int core_create_device_list_for_node(struct se_node_acl *nacl)
 	struct se_dev_entry *deve;
 	int i;
 
-	nacl->device_list = kzalloc(sizeof(struct se_dev_entry) *
-				TRANSPORT_MAX_LUNS_PER_TPG, GFP_KERNEL);
+	nacl->device_list = array_zalloc(TRANSPORT_MAX_LUNS_PER_TPG,
+			sizeof(struct se_dev_entry), GFP_KERNEL);
 	if (!nacl->device_list) {
 		pr_err("Unable to allocate memory for"
 			" struct se_node_acl->device_list\n");
 		return -ENOMEM;
 	}
 	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
-		deve = &nacl->device_list[i];
+		deve = nacl->device_list[i];
 
 		atomic_set(&deve->ua_count, 0);
 		atomic_set(&deve->pr_ref_count, 0);

commit 4a5a75f32dcbcd0b2685f74fd4ede26edf8765a9
Author: Jrn Engel <joern@logfs.org>
Date:   Thu Mar 15 15:05:12 2012 -0400

    target: Use array_zalloc for tpg_lun_list
    
    Turns an order-10 allocation into slab-sized ones, thereby preventing
    allocation failures with memory fragmentation.
    
    This likely saves memory as well, as the slab allocator can pack objects
    more tightly than the buddy allocator.
    
    Signed-off-by: Joern Engel <joern@logfs.org>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index f3ea385737d5..146fe47f11c1 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -163,7 +163,7 @@ void core_tpg_add_node_to_devs(
 
 	spin_lock(&tpg->tpg_lun_lock);
 	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
-		lun = &tpg->tpg_lun_list[i];
+		lun = tpg->tpg_lun_list[i];
 		if (lun->lun_status != TRANSPORT_LUN_STATUS_ACTIVE)
 			continue;
 
@@ -222,6 +222,34 @@ static int core_set_queue_depth_for_node(
 	return 0;
 }
 
+void array_free(void *array, int n)
+{
+	void **a = array;
+	int i;
+
+	for (i = 0; i < n; i++)
+		kfree(a[i]);
+	kfree(a);
+}
+
+static void *array_zalloc(int n, size_t size, gfp_t flags)
+{
+	void **a;
+	int i;
+
+	a = kzalloc(n * sizeof(void*), flags);
+	if (!a)
+		return NULL;
+	for (i = 0; i < n; i++) {
+		a[i] = kzalloc(size, flags);
+		if (!a[i]) {
+			array_free(a, n);
+			return NULL;
+		}
+	}
+	return a;
+}
+
 /*      core_create_device_list_for_node():
  *
  *
@@ -336,7 +364,7 @@ void core_tpg_clear_object_luns(struct se_portal_group *tpg)
 
 	spin_lock(&tpg->tpg_lun_lock);
 	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
-		lun = &tpg->tpg_lun_list[i];
+		lun = tpg->tpg_lun_list[i];
 
 		if ((lun->lun_status != TRANSPORT_LUN_STATUS_ACTIVE) ||
 		    (lun->lun_se_dev == NULL))
@@ -661,8 +689,8 @@ int core_tpg_register(
 	struct se_lun *lun;
 	u32 i;
 
-	se_tpg->tpg_lun_list = kzalloc((sizeof(struct se_lun) *
-				TRANSPORT_MAX_LUNS_PER_TPG), GFP_KERNEL);
+	se_tpg->tpg_lun_list = array_zalloc(TRANSPORT_MAX_LUNS_PER_TPG,
+			sizeof(struct se_lun), GFP_KERNEL);
 	if (!se_tpg->tpg_lun_list) {
 		pr_err("Unable to allocate struct se_portal_group->"
 				"tpg_lun_list\n");
@@ -670,7 +698,7 @@ int core_tpg_register(
 	}
 
 	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
-		lun = &se_tpg->tpg_lun_list[i];
+		lun = se_tpg->tpg_lun_list[i];
 		lun->unpacked_lun = i;
 		lun->lun_status = TRANSPORT_LUN_STATUS_FREE;
 		atomic_set(&lun->lun_acl_count, 0);
@@ -756,7 +784,7 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 		core_tpg_release_virtual_lun0(se_tpg);
 
 	se_tpg->se_tpg_fabric_ptr = NULL;
-	kfree(se_tpg->tpg_lun_list);
+	array_free(se_tpg->tpg_lun_list, TRANSPORT_MAX_LUNS_PER_TPG);
 	return 0;
 }
 EXPORT_SYMBOL(core_tpg_deregister);
@@ -777,7 +805,7 @@ struct se_lun *core_tpg_pre_addlun(
 	}
 
 	spin_lock(&tpg->tpg_lun_lock);
-	lun = &tpg->tpg_lun_list[unpacked_lun];
+	lun = tpg->tpg_lun_list[unpacked_lun];
 	if (lun->lun_status == TRANSPORT_LUN_STATUS_ACTIVE) {
 		pr_err("TPG Logical Unit Number: %u is already active"
 			" on %s Target Portal Group: %u, ignoring request.\n",
@@ -835,7 +863,7 @@ struct se_lun *core_tpg_pre_dellun(
 	}
 
 	spin_lock(&tpg->tpg_lun_lock);
-	lun = &tpg->tpg_lun_list[unpacked_lun];
+	lun = tpg->tpg_lun_list[unpacked_lun];
 	if (lun->lun_status != TRANSPORT_LUN_STATUS_ACTIVE) {
 		pr_err("%s Logical Unit Number: %u is not active on"
 			" Target Portal Group: %u, ignoring request.\n",

commit 337c060701fb3d27d9945bf7af7ba194ae2153a8
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Sat Mar 10 14:36:21 2012 -0800

    target: Convert se_node_acl->acl_group removal to use ->acl_kref
    
    This patch converts core_tpg_del_initiator_node_acl() shutdown from configfs
    context to use se_node_acl->acl_kref and ->acl_free_comp in order to wait for
    outstanding fabric callbacks to complete via transport_deregister_session()
    callbacks before waking ->acl_free_comp from the last ->acl_kref put.
    
    It also changes core_tpg_del_initiator_node_acl() to setup a local sess_list
    with target_get_session() + acl->acl_stop = 1 for active sessions that will
    be shutdown, and changes transport_deregister_session_configfs() to check
    for ->acl_stop usage.
    
    Cc: Roland Dreier <roland@purestorage.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Joern Engel <joern@logfs.org>
    Cc: Andy Grover <agrover@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index bbed260ec71f..f3ea385737d5 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -452,9 +452,10 @@ int core_tpg_del_initiator_node_acl(
 	struct se_node_acl *acl,
 	int force)
 {
+	LIST_HEAD(sess_list);
 	struct se_session *sess, *sess_tmp;
 	unsigned long flags;
-	int dynamic_acl = 0;
+	int dynamic_acl = 0, rc;
 
 	spin_lock_irq(&tpg->acl_node_lock);
 	if (acl->dynamic_node_acl) {
@@ -465,27 +466,34 @@ int core_tpg_del_initiator_node_acl(
 	tpg->num_node_acls--;
 	spin_unlock_irq(&tpg->acl_node_lock);
 
-	spin_lock_irqsave(&tpg->session_lock, flags);
-	list_for_each_entry_safe(sess, sess_tmp,
-				&tpg->tpg_sess_list, sess_list) {
-		if (sess->se_node_acl != acl)
-			continue;
-		/*
-		 * Determine if the session needs to be closed by our context.
-		 */
-		if (!tpg->se_tpg_tfo->shutdown_session(sess))
+	spin_lock_irqsave(&acl->nacl_sess_lock, flags);
+	acl->acl_stop = 1;
+
+	list_for_each_entry_safe(sess, sess_tmp, &acl->acl_sess_list,
+				sess_acl_list) {
+		if (sess->sess_tearing_down != 0)
 			continue;
 
-		spin_unlock_irqrestore(&tpg->session_lock, flags);
-		/*
-		 * If the $FABRIC_MOD session for the Initiator Node ACL exists,
-		 * forcefully shutdown the $FABRIC_MOD session/nexus.
-		 */
-		tpg->se_tpg_tfo->close_session(sess);
+		target_get_session(sess);
+		list_move(&sess->sess_acl_list, &sess_list);
+	}
+	spin_unlock_irqrestore(&acl->nacl_sess_lock, flags);
+
+	list_for_each_entry_safe(sess, sess_tmp, &sess_list, sess_acl_list) {
+		list_del(&sess->sess_acl_list);
 
-		spin_lock_irqsave(&tpg->session_lock, flags);
+		rc = tpg->se_tpg_tfo->shutdown_session(sess);
+		target_put_session(sess);
+		if (!rc)
+			continue;
+		target_put_session(sess);
 	}
-	spin_unlock_irqrestore(&tpg->session_lock, flags);
+	target_put_nacl(acl);
+	/*
+	 * Wait for last target_put_nacl() to complete in target_complete_nacl()
+	 * for active fabric session transport_deregister_session() callbacks.
+	 */
+	wait_for_completion(&acl->acl_free_comp);
 
 	core_tpg_wait_for_nacl_pr_ref(acl);
 	core_clear_initiator_node_from_tpg(acl, tpg);

commit afb999ffc48f5e7ec18e6f8f9e68aa3d0085862d
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Thu Mar 8 23:45:02 2012 -0800

    target: Add se_node_acl->acl_kref for ->acl_free_comp usage
    
    This patch adds se_node_acl->acl_kref for use with ->acl_free_comp
    during explict se_node_acl release.  It adds kref_init() during
    se_node_acl setup, kref_get() during __transport_register_session()
    -> target_put_nacl() with existing transport_deregister_session()
    fabric callback usage.
    
    It also moves transport_free_session() to release *se_sess memory
    after target_put_nacl() execution in transport_deregister_session()
    
    Cc: Roland Dreier <roland@purestorage.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Joern Engel <joern@logfs.org>
    Cc: Andy Grover <agrover@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 9cdfd061eacf..bbed260ec71f 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -274,6 +274,7 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 
 	INIT_LIST_HEAD(&acl->acl_list);
 	INIT_LIST_HEAD(&acl->acl_sess_list);
+	kref_init(&acl->acl_kref);
 	init_completion(&acl->acl_free_comp);
 	spin_lock_init(&acl->device_list_lock);
 	spin_lock_init(&acl->nacl_sess_lock);
@@ -403,6 +404,7 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 
 	INIT_LIST_HEAD(&acl->acl_list);
 	INIT_LIST_HEAD(&acl->acl_sess_list);
+	kref_init(&acl->acl_kref);
 	init_completion(&acl->acl_free_comp);
 	spin_lock_init(&acl->device_list_lock);
 	spin_lock_init(&acl->nacl_sess_lock);

commit 01468346546a9bcc09035a7e8b71f78af5b7133a
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Sat Mar 10 14:32:52 2012 -0800

    target: Add se_node_acl->acl_free_comp for NodeACL release path
    
    Add se_node_acl->acl_free_comp for NodeACL release path to wait for outstanding
    fabric session shutdown to complete in transport_deregister_session() before
    finishing NodeACL release from configfs process context.
    
    Also make transport_deregister_session() clear the comp_nacl bit
    to skip se_node_acl->acl_free_comp completion for dynamically generated
    NodeACL during fabric session shutdown.
    
    Cc: Roland Dreier <roland@purestorage.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Joern Engel <joern@logfs.org>
    Cc: Andy Grover <agrover@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 32153404da14..9cdfd061eacf 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -274,6 +274,7 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 
 	INIT_LIST_HEAD(&acl->acl_list);
 	INIT_LIST_HEAD(&acl->acl_sess_list);
+	init_completion(&acl->acl_free_comp);
 	spin_lock_init(&acl->device_list_lock);
 	spin_lock_init(&acl->nacl_sess_lock);
 	atomic_set(&acl->acl_pr_ref_count, 0);
@@ -402,6 +403,7 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 
 	INIT_LIST_HEAD(&acl->acl_list);
 	INIT_LIST_HEAD(&acl->acl_sess_list);
+	init_completion(&acl->acl_free_comp);
 	spin_lock_init(&acl->device_list_lock);
 	spin_lock_init(&acl->nacl_sess_lock);
 	atomic_set(&acl->acl_pr_ref_count, 0);

commit 140854cb72525246745b67300d35101ad2875a39
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Wed Aug 31 12:34:39 2011 -0700

    target: Convert session_lock to irqsave
    
    This patch converts the remaining struct se_portal_group->session_lock
    usage to use irqsave+irqrestore to address the following warnings for
    hardware target mode interrupt context usage.  This change generate
    other warnings for current iscsi-target mode still using ->session_lock
    with spin_lock_bh, which will need to be converted in a seperate patch.
    
    [  492.480728] [ INFO: HARDIRQ-safe -> HARDIRQ-unsafe lock order detected ]
    [  492.488194] 3.0.0+ #23
    [  492.490820] ------------------------------------------------------
    [  492.497704] sh/7162 [HC0[0]:SC0[2]:HE0:SE0] is trying to acquire:
    [  492.504493] (&(&se_tpg->session_lock)->rlock){+.....}, at: [<ffffffffa022364d>] transport_deregister_session+0x2d/0x163 [target_core_mod]
      492.518390]
    [  492.518390] and this task is already holding:
    [  492.524897] (&(&ha->hardware_lock)->rlock){-.-...}, at: [<ffffffffa00b9146>] qla_tgt_stop_phase1+0x5e/0x27e [qla2xxx]
    [  492.536856] which would create a new lock dependency:
    [  492.542481] (&(&ha->hardware_lock)->rlock){-.-...} -> (&(&se_tpg->session_lock)->rlock){+.....}
    [  492.552321]
    [  492.552321] but this new dependency connects a HARDIRQ-irq-safe lock:
    [  492.561149] (&(&ha->hardware_lock)->rlock){-.-...}
    [  492.566400] ... which became HARDIRQ-irq-safe at:
    [  492.571841]   [<ffffffff81064720>] __lock_acquire+0x68f/0x921
    [  492.578247]   [<ffffffff81064eff>] lock_acquire+0xe0/0x10d
    [  492.584367]   [<ffffffff813a74c6>] _raw_spin_lock_irqsave+0x44/0x56
    [  492.591358]   [<ffffffffa009b1be>] qla24xx_msix_default+0x5c/0x2aa [qla2xxx]
    [  492.599227]   [<ffffffff81088582>] handle_irq_event_percpu+0x5a/0x197
    [  492.606413]   [<ffffffff810886fb>] handle_irq_event+0x3c/0x5c
    [  492.612822]   [<ffffffff8108a6dc>] handle_edge_irq+0xcc/0xf1
    [  492.619138]   [<ffffffff810039b9>] handle_irq+0x83/0x8e
    [  492.624971]   [<ffffffff8100333e>] do_IRQ+0x48/0xaf
    [  492.630413]   [<ffffffff813a7cd3>] ret_from_intr+0x0/0x1a
    [  492.636437]   [<ffffffff81001dc1>] cpu_idle+0x5b/0x8d
    [  492.642073]   [<ffffffff81392709>] rest_init+0xad/0xb4
    [  492.647809]   [<ffffffff81a1cbbc>] start_kernel+0x366/0x371
    [  492.654030]   [<ffffffff81a1c2b1>] x86_64_start_reservations+0xb8/0xbc
    [  492.661311]   [<ffffffff81a1c3b6>] x86_64_start_kernel+0x101/0x110
    [  492.668204]
    [  492.668205] to a HARDIRQ-irq-unsafe lock:
    [  492.674324] (&(&se_tpg->session_lock)->rlock){+.....}
    [  492.679862] ... which became HARDIRQ-irq-unsafe at:
    [  492.685497] ...  [<ffffffff8106479a>] __lock_acquire+0x709/0x921
    [  492.692209]   [<ffffffff81064eff>] lock_acquire+0xe0/0x10d
    [  492.698330]   [<ffffffff813a75ed>] _raw_spin_lock_bh+0x31/0x40
    [  492.704836]   [<ffffffffa021c208>] core_tpg_del_initiator_node_acl+0x89/0x336 [target_core_mod]
    [  492.714546]   [<ffffffffa02fb075>] tcm_qla2xxx_drop_nodeacl+0x20/0x2d [tcm_qla2xxx]
    [  492.723087]   [<ffffffffa02108d9>] target_fabric_nacl_base_release+0x22/0x24 [target_core_mod]
    [  492.732698]   [<ffffffffa01661c8>] config_item_release+0x7d/0xa3 [configfs]
    [  492.740465]   [<ffffffff811d48fe>] kref_put+0x43/0x4d
    [  492.746101]   [<ffffffffa0166149>] config_item_put+0x19/0x1b [configfs]
    [  492.753481]   [<ffffffffa0164987>] configfs_rmdir+0x1eb/0x258 [configfs]
    [  492.760957]   [<ffffffff810ecc54>] vfs_rmdir+0x79/0xd0
    [  492.766690]   [<ffffffff810eec4a>] do_rmdir+0xc2/0x111
    [  492.772423]   [<ffffffff810eecd0>] sys_rmdir+0x11/0x13
    [  492.778156]   [<ffffffff813ae4d2>] system_call_fastpath+0x16/0x1b
    [  492.784953]
    
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 06336ecd872d..32153404da14 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -449,6 +449,7 @@ int core_tpg_del_initiator_node_acl(
 	int force)
 {
 	struct se_session *sess, *sess_tmp;
+	unsigned long flags;
 	int dynamic_acl = 0;
 
 	spin_lock_irq(&tpg->acl_node_lock);
@@ -460,7 +461,7 @@ int core_tpg_del_initiator_node_acl(
 	tpg->num_node_acls--;
 	spin_unlock_irq(&tpg->acl_node_lock);
 
-	spin_lock_bh(&tpg->session_lock);
+	spin_lock_irqsave(&tpg->session_lock, flags);
 	list_for_each_entry_safe(sess, sess_tmp,
 				&tpg->tpg_sess_list, sess_list) {
 		if (sess->se_node_acl != acl)
@@ -471,16 +472,16 @@ int core_tpg_del_initiator_node_acl(
 		if (!tpg->se_tpg_tfo->shutdown_session(sess))
 			continue;
 
-		spin_unlock_bh(&tpg->session_lock);
+		spin_unlock_irqrestore(&tpg->session_lock, flags);
 		/*
 		 * If the $FABRIC_MOD session for the Initiator Node ACL exists,
 		 * forcefully shutdown the $FABRIC_MOD session/nexus.
 		 */
 		tpg->se_tpg_tfo->close_session(sess);
 
-		spin_lock_bh(&tpg->session_lock);
+		spin_lock_irqsave(&tpg->session_lock, flags);
 	}
-	spin_unlock_bh(&tpg->session_lock);
+	spin_unlock_irqrestore(&tpg->session_lock, flags);
 
 	core_tpg_wait_for_nacl_pr_ref(acl);
 	core_clear_initiator_node_from_tpg(acl, tpg);
@@ -507,6 +508,7 @@ int core_tpg_set_initiator_node_queue_depth(
 {
 	struct se_session *sess, *init_sess = NULL;
 	struct se_node_acl *acl;
+	unsigned long flags;
 	int dynamic_acl = 0;
 
 	spin_lock_irq(&tpg->acl_node_lock);
@@ -525,7 +527,7 @@ int core_tpg_set_initiator_node_queue_depth(
 	}
 	spin_unlock_irq(&tpg->acl_node_lock);
 
-	spin_lock_bh(&tpg->session_lock);
+	spin_lock_irqsave(&tpg->session_lock, flags);
 	list_for_each_entry(sess, &tpg->tpg_sess_list, sess_list) {
 		if (sess->se_node_acl != acl)
 			continue;
@@ -537,7 +539,7 @@ int core_tpg_set_initiator_node_queue_depth(
 				" depth and force session reinstatement"
 				" use the \"force=1\" parameter.\n",
 				tpg->se_tpg_tfo->get_fabric_name(), initiatorname);
-			spin_unlock_bh(&tpg->session_lock);
+			spin_unlock_irqrestore(&tpg->session_lock, flags);
 
 			spin_lock_irq(&tpg->acl_node_lock);
 			if (dynamic_acl)
@@ -567,7 +569,7 @@ int core_tpg_set_initiator_node_queue_depth(
 	acl->queue_depth = queue_depth;
 
 	if (core_set_queue_depth_for_node(tpg, acl) < 0) {
-		spin_unlock_bh(&tpg->session_lock);
+		spin_unlock_irqrestore(&tpg->session_lock, flags);
 		/*
 		 * Force session reinstatement if
 		 * core_set_queue_depth_for_node() failed, because we assume
@@ -583,7 +585,7 @@ int core_tpg_set_initiator_node_queue_depth(
 		spin_unlock_irq(&tpg->acl_node_lock);
 		return -EINVAL;
 	}
-	spin_unlock_bh(&tpg->session_lock);
+	spin_unlock_irqrestore(&tpg->session_lock, flags);
 	/*
 	 * If the $FABRIC_MOD session for the Initiator Node ACL exists,
 	 * forcefully shutdown the $FABRIC_MOD session/nexus.

commit 8d9efe539cf78f6a90947d47100e4a86d907750f
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Wed Jan 11 21:43:38 2012 +0100

    target: fix return code of core_tpg_.*_lun
    
    - core_tpg_pre_addlun()
      returns always ERR_PTR() or the pointer, never NULL. The additional
      check for NULL in core_dev_add_lun() is not required.
    
    - core_tpg_pre_dellun()
      returns always ERR_PTR() or the pointer, never NULL. The check for NULL
      in core_dev_del_lun() is wrong. The third argument (int *) is never
      used, remove it.
    
    - core_dev_add_lun()
      returns always NULL or the pointer, never ERR_PTR. The check for
      IS_ERR() is not required.
    
    (nab: Convert core_dev_add_lun() use err.h macros for failure
    handling to be consistent with the rest of target_core_fabric_configfs.c
    callers)
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index b7668029bb31..06336ecd872d 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -807,8 +807,7 @@ static void core_tpg_shutdown_lun(
 
 struct se_lun *core_tpg_pre_dellun(
 	struct se_portal_group *tpg,
-	u32 unpacked_lun,
-	int *ret)
+	u32 unpacked_lun)
 {
 	struct se_lun *lun;
 

commit c4795fb20edf2fe2c862c8fe9f8b681edeb79ac1
Author: Christoph Hellwig <hch@infradead.org>
Date:   Wed Nov 16 09:46:48 2011 -0500

    target: header reshuffle, part2
    
    This reorganized the headers under include/target into:
    
     - target_core_base.h stays as is with all target-wide data stuctures and defines
     - target_core_backend.h contains the whole interface to I/O backends
     - target_core_fabric.h contains the whole interface to fabric modules
    
    Except for those only the various configfs macro headers stay around.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 0a936fae3d23..b7668029bb31 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -39,10 +39,8 @@
 #include <scsi/scsi_cmnd.h>
 
 #include <target/target_core_base.h>
-#include <target/target_core_device.h>
-#include <target/target_core_tpg.h>
-#include <target/target_core_transport.h>
-#include <target/target_core_fabric_ops.h>
+#include <target/target_core_backend.h>
+#include <target/target_core_fabric.h>
 
 #include "target_core_internal.h"
 

commit e26d99aed42ec6cdc9540d19c77ac5d4dd2c5b00
Author: Christoph Hellwig <hch@infradead.org>
Date:   Mon Nov 14 12:30:30 2011 -0500

    target: reshuffle headers
    
    Create a new headers, drivers/target/target_core_internal.h that is supposed
    to hold all target_core-internal prototypes.  Move all non-exported includes
    from include/target to it, and merge the smaller prototype-only includes
    inside drivers/target into it as well.  Mark functions that were found to
    not be called outside their implementation file static.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 8ddd133025b9..0a936fae3d23 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -44,8 +44,7 @@
 #include <target/target_core_transport.h>
 #include <target/target_core_fabric_ops.h>
 
-#include "target_core_hba.h"
-#include "target_core_stat.h"
+#include "target_core_internal.h"
 
 extern struct se_device *g_lun0_dev;
 

commit c53181af838fb9d82eebbb62b7175b0466d5a7a0
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Tue Aug 30 18:16:43 2011 -0400

    drivers/target: Add export.h to files as required.
    
    So that they have access to EXPORT_SYMBOL variants and THIS_MODULE.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 49fd0a9b0a56..8ddd133025b9 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -32,6 +32,7 @@
 #include <linux/slab.h>
 #include <linux/spinlock.h>
 #include <linux/in.h>
+#include <linux/export.h>
 #include <net/sock.h>
 #include <net/tcp.h>
 #include <scsi/scsi.h>

commit bfb9035c98906aafcd3cf22694fba2550997bf53
Author: Joe Perches <joe@perches.com>
Date:   Wed Aug 17 06:58:04 2011 -0700

    treewide: Correct spelling of successfully in comments
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 162b736c7342..49fd0a9b0a56 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -593,7 +593,7 @@ int core_tpg_set_initiator_node_queue_depth(
 	if (init_sess)
 		tpg->se_tpg_tfo->close_session(init_sess);
 
-	pr_debug("Successfuly changed queue depth to: %d for Initiator"
+	pr_debug("Successfully changed queue depth to: %d for Initiator"
 		" Node: %s on %s Target Portal Group: %u\n", queue_depth,
 		initiatorname, tpg->se_tpg_tfo->get_fabric_name(),
 		tpg->se_tpg_tfo->tpg_get_tag(tpg));

commit 28638887f351d11867562322b7abaa014dd5528a
Author: Roland Dreier <roland@purestorage.com>
Date:   Tue Aug 16 09:40:01 2011 -0700

    target: Convert acl_node_lock to be IRQ-disabling
    
    With qla2xxx, acl_node_lock is taken inside qla2xxx's hardware_lock,
    which is taken in hardirq context.  This means acl_node_lock must become
    an IRQ-disabling lock; in particular this fixes lockdep warnings along
    the lines of
    
        ======================================================
        [ INFO: HARDIRQ-safe -> HARDIRQ-unsafe lock order detected ]
    
         (&(&se_tpg->acl_node_lock)->rlock){+.....}, at: [<ffffffffa026f872>] transport_deregister_session+0x92/0x140 [target_core_mod]
    
        and this task is already holding:
         (&(&ha->hardware_lock)->rlock){-.-...}, at: [<ffffffffa017c5e7>] qla_tgt_stop_phase1+0x57/0x2c0 [qla2xxx]
        which would create a new lock dependency:
         (&(&ha->hardware_lock)->rlock){-.-...} -> (&(&se_tpg->acl_node_lock)->rlock){+.....}
    
        but this new dependency connects a HARDIRQ-irq-safe lock:
         (&(&ha->hardware_lock)->rlock){-.-...}
    
        to a HARDIRQ-irq-unsafe lock:
         (&(&se_tpg->acl_node_lock)->rlock){+.....}
    
    Signed-off-by: Roland Dreier <roland@purestorage.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 718ccd1348b1..162b736c7342 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -137,15 +137,15 @@ struct se_node_acl *core_tpg_get_initiator_node_acl(
 {
 	struct se_node_acl *acl;
 
-	spin_lock_bh(&tpg->acl_node_lock);
+	spin_lock_irq(&tpg->acl_node_lock);
 	list_for_each_entry(acl, &tpg->acl_node_list, acl_list) {
 		if (!strcmp(acl->initiatorname, initiatorname) &&
 		    !acl->dynamic_node_acl) {
-			spin_unlock_bh(&tpg->acl_node_lock);
+			spin_unlock_irq(&tpg->acl_node_lock);
 			return acl;
 		}
 	}
-	spin_unlock_bh(&tpg->acl_node_lock);
+	spin_unlock_irq(&tpg->acl_node_lock);
 
 	return NULL;
 }
@@ -309,10 +309,10 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 	else
 		core_tpg_add_node_to_devs(acl, tpg);
 
-	spin_lock_bh(&tpg->acl_node_lock);
+	spin_lock_irq(&tpg->acl_node_lock);
 	list_add_tail(&acl->acl_list, &tpg->acl_node_list);
 	tpg->num_node_acls++;
-	spin_unlock_bh(&tpg->acl_node_lock);
+	spin_unlock_irq(&tpg->acl_node_lock);
 
 	pr_debug("%s_TPG[%u] - Added DYNAMIC ACL with TCQ Depth: %d for %s"
 		" Initiator Node: %s\n", tpg->se_tpg_tfo->get_fabric_name(),
@@ -362,7 +362,7 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 {
 	struct se_node_acl *acl = NULL;
 
-	spin_lock_bh(&tpg->acl_node_lock);
+	spin_lock_irq(&tpg->acl_node_lock);
 	acl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);
 	if (acl) {
 		if (acl->dynamic_node_acl) {
@@ -370,7 +370,7 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 			pr_debug("%s_TPG[%u] - Replacing dynamic ACL"
 				" for %s\n", tpg->se_tpg_tfo->get_fabric_name(),
 				tpg->se_tpg_tfo->tpg_get_tag(tpg), initiatorname);
-			spin_unlock_bh(&tpg->acl_node_lock);
+			spin_unlock_irq(&tpg->acl_node_lock);
 			/*
 			 * Release the locally allocated struct se_node_acl
 			 * because * core_tpg_add_initiator_node_acl() returned
@@ -386,10 +386,10 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 			" Node %s already exists for TPG %u, ignoring"
 			" request.\n",  tpg->se_tpg_tfo->get_fabric_name(),
 			initiatorname, tpg->se_tpg_tfo->tpg_get_tag(tpg));
-		spin_unlock_bh(&tpg->acl_node_lock);
+		spin_unlock_irq(&tpg->acl_node_lock);
 		return ERR_PTR(-EEXIST);
 	}
-	spin_unlock_bh(&tpg->acl_node_lock);
+	spin_unlock_irq(&tpg->acl_node_lock);
 
 	if (!se_nacl) {
 		pr_err("struct se_node_acl pointer is NULL\n");
@@ -426,10 +426,10 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 		return ERR_PTR(-EINVAL);
 	}
 
-	spin_lock_bh(&tpg->acl_node_lock);
+	spin_lock_irq(&tpg->acl_node_lock);
 	list_add_tail(&acl->acl_list, &tpg->acl_node_list);
 	tpg->num_node_acls++;
-	spin_unlock_bh(&tpg->acl_node_lock);
+	spin_unlock_irq(&tpg->acl_node_lock);
 
 done:
 	pr_debug("%s_TPG[%hu] - Added ACL with TCQ Depth: %d for %s"
@@ -453,14 +453,14 @@ int core_tpg_del_initiator_node_acl(
 	struct se_session *sess, *sess_tmp;
 	int dynamic_acl = 0;
 
-	spin_lock_bh(&tpg->acl_node_lock);
+	spin_lock_irq(&tpg->acl_node_lock);
 	if (acl->dynamic_node_acl) {
 		acl->dynamic_node_acl = 0;
 		dynamic_acl = 1;
 	}
 	list_del(&acl->acl_list);
 	tpg->num_node_acls--;
-	spin_unlock_bh(&tpg->acl_node_lock);
+	spin_unlock_irq(&tpg->acl_node_lock);
 
 	spin_lock_bh(&tpg->session_lock);
 	list_for_each_entry_safe(sess, sess_tmp,
@@ -511,21 +511,21 @@ int core_tpg_set_initiator_node_queue_depth(
 	struct se_node_acl *acl;
 	int dynamic_acl = 0;
 
-	spin_lock_bh(&tpg->acl_node_lock);
+	spin_lock_irq(&tpg->acl_node_lock);
 	acl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);
 	if (!acl) {
 		pr_err("Access Control List entry for %s Initiator"
 			" Node %s does not exists for TPG %hu, ignoring"
 			" request.\n", tpg->se_tpg_tfo->get_fabric_name(),
 			initiatorname, tpg->se_tpg_tfo->tpg_get_tag(tpg));
-		spin_unlock_bh(&tpg->acl_node_lock);
+		spin_unlock_irq(&tpg->acl_node_lock);
 		return -ENODEV;
 	}
 	if (acl->dynamic_node_acl) {
 		acl->dynamic_node_acl = 0;
 		dynamic_acl = 1;
 	}
-	spin_unlock_bh(&tpg->acl_node_lock);
+	spin_unlock_irq(&tpg->acl_node_lock);
 
 	spin_lock_bh(&tpg->session_lock);
 	list_for_each_entry(sess, &tpg->tpg_sess_list, sess_list) {
@@ -541,10 +541,10 @@ int core_tpg_set_initiator_node_queue_depth(
 				tpg->se_tpg_tfo->get_fabric_name(), initiatorname);
 			spin_unlock_bh(&tpg->session_lock);
 
-			spin_lock_bh(&tpg->acl_node_lock);
+			spin_lock_irq(&tpg->acl_node_lock);
 			if (dynamic_acl)
 				acl->dynamic_node_acl = 1;
-			spin_unlock_bh(&tpg->acl_node_lock);
+			spin_unlock_irq(&tpg->acl_node_lock);
 			return -EEXIST;
 		}
 		/*
@@ -579,10 +579,10 @@ int core_tpg_set_initiator_node_queue_depth(
 		if (init_sess)
 			tpg->se_tpg_tfo->close_session(init_sess);
 
-		spin_lock_bh(&tpg->acl_node_lock);
+		spin_lock_irq(&tpg->acl_node_lock);
 		if (dynamic_acl)
 			acl->dynamic_node_acl = 1;
-		spin_unlock_bh(&tpg->acl_node_lock);
+		spin_unlock_irq(&tpg->acl_node_lock);
 		return -EINVAL;
 	}
 	spin_unlock_bh(&tpg->session_lock);
@@ -598,10 +598,10 @@ int core_tpg_set_initiator_node_queue_depth(
 		initiatorname, tpg->se_tpg_tfo->get_fabric_name(),
 		tpg->se_tpg_tfo->tpg_get_tag(tpg));
 
-	spin_lock_bh(&tpg->acl_node_lock);
+	spin_lock_irq(&tpg->acl_node_lock);
 	if (dynamic_acl)
 		acl->dynamic_node_acl = 1;
-	spin_unlock_bh(&tpg->acl_node_lock);
+	spin_unlock_irq(&tpg->acl_node_lock);
 
 	return 0;
 }
@@ -725,20 +725,20 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 	 * not been released because of TFO->tpg_check_demo_mode_cache() == 1
 	 * in transport_deregister_session().
 	 */
-	spin_lock_bh(&se_tpg->acl_node_lock);
+	spin_lock_irq(&se_tpg->acl_node_lock);
 	list_for_each_entry_safe(nacl, nacl_tmp, &se_tpg->acl_node_list,
 			acl_list) {
 		list_del(&nacl->acl_list);
 		se_tpg->num_node_acls--;
-		spin_unlock_bh(&se_tpg->acl_node_lock);
+		spin_unlock_irq(&se_tpg->acl_node_lock);
 
 		core_tpg_wait_for_nacl_pr_ref(nacl);
 		core_free_device_list_for_node(nacl, se_tpg);
 		se_tpg->se_tpg_tfo->tpg_release_fabric_acl(se_tpg, nacl);
 
-		spin_lock_bh(&se_tpg->acl_node_lock);
+		spin_lock_irq(&se_tpg->acl_node_lock);
 	}
-	spin_unlock_bh(&se_tpg->acl_node_lock);
+	spin_unlock_irq(&se_tpg->acl_node_lock);
 
 	if (se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL)
 		core_tpg_release_virtual_lun0(se_tpg);

commit 052605c6caa3e1edf8eee8fe5fe6d53f5721f39a
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Tue Jul 26 17:48:43 2011 -0700

    target: Make standard INQUIRY return 'not connected' for tpg_virt_lun0
    
    This patch changes target_emulate_inquiry_std() to set the 'not connected'
    (0x35) bit in standard INQUIRY response data when we are processing a
    request to a virtual LUN=0 mapping from struct se_device *g_lun0_dev that
    have been setup for us in transport_lookup_cmd_lun().
    
    This addresses an issue where qla2xxx FC clients need to be able
    to create demo-mode I_T FC Nexuses by default, but should not be
    exposing the default set of TPG LUNs to all FC clients.  This includes
    adding an new optional target_core_fabric_ops->tpg_check_demo_mode_login_only()
    caller to allow demo_mode nexuses to skip the old default of bulding
    a demo-mode MappedLUNs list via core_tpg_add_node_to_devs().
    
    (roland: Add missing tpg_check_demo_mode_login_only check in core_dev_add_lun)
    
    Reported-by: Roland Dreier <roland@purestorage.com>
    Cc: Andrew Vasquez <andrew.vasquez@qlogic.com>
    Signed-off-by: Nicholas Bellinger <nab@risingtidesystems.com>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 4f1ba4c5ef11..718ccd1348b1 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -298,8 +298,16 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 		tpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);
 		return NULL;
 	}
-
-	core_tpg_add_node_to_devs(acl, tpg);
+	/*
+	 * Here we only create demo-mode MappedLUNs from the active
+	 * TPG LUNs if the fabric is not explictly asking for
+	 * tpg_check_demo_mode_login_only() == 1.
+	 */
+	if ((tpg->se_tpg_tfo->tpg_check_demo_mode_login_only != NULL) &&
+	    (tpg->se_tpg_tfo->tpg_check_demo_mode_login_only(tpg) == 1))
+		do { ; } while (0);
+	else
+		core_tpg_add_node_to_devs(acl, tpg);
 
 	spin_lock_bh(&tpg->acl_node_lock);
 	list_add_tail(&acl->acl_list, &tpg->acl_node_list);

commit 6708bb27bb2703da238f21f516034263348af5be
Author: Andy Grover <agrover@redhat.com>
Date:   Wed Jun 8 10:36:43 2011 -0700

    target: Follow up core updates from AGrover and HCH (round 4)
    
    This patch contains the squashed version of forth round series cleanups
    from Andy and Christoph following the post heavy lifting in the preceeding:
    'Eliminate usage of struct se_mem' and 'Make all control CDBs scatter-gather'
    changes.  This also includes a conversion of target core and the v3.0
    mainline fabric modules (loopback and tcm_fc) to use pr_debug and the
    CONFIG_DYNAMIC_DEBUG infrastructure!
    
    These have been squashed into this third and final round for v3.1.
    
    target: Remove ifdeffed code in t_g_process_write
    target: Remove direct ramdisk code
    target: Rename task_sg_num to task_sg_nents
    target: Remove custom debug macros for pr_debug. Use pr_err().
    target: Remove custom debug macros in mainline fabrics
    target: Set WSNZ=1 in block limits VPD. Abort if WRITE_SAME sectors = 0
    target: Remove transport do_se_mem_map callback
    target: Further simplify transport_free_pages
    target: Redo task allocation return value handling
    target: Remove extra parentheses
    target: change alloc_task call to take *cdb, not *cmd
    
    (nab: Fix bogus struct file assignments in fd_do_readv and fd_do_writev)
    
    Signed-off-by: Andy Grover <agrover@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 448129f74cf9..4f1ba4c5ef11 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -72,7 +72,7 @@ static void core_clear_initiator_node_from_tpg(
 			continue;
 
 		if (!deve->se_lun) {
-			printk(KERN_ERR "%s device entries device pointer is"
+			pr_err("%s device entries device pointer is"
 				" NULL, but Initiator has access.\n",
 				tpg->se_tpg_tfo->get_fabric_name());
 			continue;
@@ -86,14 +86,13 @@ static void core_clear_initiator_node_from_tpg(
 		spin_lock(&lun->lun_acl_lock);
 		list_for_each_entry_safe(acl, acl_tmp,
 					&lun->lun_acl_list, lacl_list) {
-			if (!(strcmp(acl->initiatorname,
-					nacl->initiatorname)) &&
-			     (acl->mapped_lun == deve->mapped_lun))
+			if (!strcmp(acl->initiatorname, nacl->initiatorname) &&
+			    (acl->mapped_lun == deve->mapped_lun))
 				break;
 		}
 
 		if (!acl) {
-			printk(KERN_ERR "Unable to locate struct se_lun_acl for %s,"
+			pr_err("Unable to locate struct se_lun_acl for %s,"
 				" mapped_lun: %u\n", nacl->initiatorname,
 				deve->mapped_lun);
 			spin_unlock(&lun->lun_acl_lock);
@@ -121,7 +120,7 @@ struct se_node_acl *__core_tpg_get_initiator_node_acl(
 	struct se_node_acl *acl;
 
 	list_for_each_entry(acl, &tpg->acl_node_list, acl_list) {
-		if (!(strcmp(acl->initiatorname, initiatorname)))
+		if (!strcmp(acl->initiatorname, initiatorname))
 			return acl;
 	}
 
@@ -140,8 +139,8 @@ struct se_node_acl *core_tpg_get_initiator_node_acl(
 
 	spin_lock_bh(&tpg->acl_node_lock);
 	list_for_each_entry(acl, &tpg->acl_node_list, acl_list) {
-		if (!(strcmp(acl->initiatorname, initiatorname)) &&
-		   (!(acl->dynamic_node_acl))) {
+		if (!strcmp(acl->initiatorname, initiatorname) &&
+		    !acl->dynamic_node_acl) {
 			spin_unlock_bh(&tpg->acl_node_lock);
 			return acl;
 		}
@@ -177,7 +176,7 @@ void core_tpg_add_node_to_devs(
 		 * By default in LIO-Target $FABRIC_MOD,
 		 * demo_mode_write_protect is ON, or READ_ONLY;
 		 */
-		if (!(tpg->se_tpg_tfo->tpg_check_demo_mode_write_protect(tpg))) {
+		if (!tpg->se_tpg_tfo->tpg_check_demo_mode_write_protect(tpg)) {
 			if (dev->dev_flags & DF_READ_ONLY)
 				lun_access = TRANSPORT_LUNFLAGS_READ_ONLY;
 			else
@@ -193,7 +192,7 @@ void core_tpg_add_node_to_devs(
 				lun_access = TRANSPORT_LUNFLAGS_READ_WRITE;
 		}
 
-		printk(KERN_INFO "TARGET_CORE[%s]->TPG[%u]_LUN[%u] - Adding %s"
+		pr_debug("TARGET_CORE[%s]->TPG[%u]_LUN[%u] - Adding %s"
 			" access for LUN in Demo Mode\n",
 			tpg->se_tpg_tfo->get_fabric_name(),
 			tpg->se_tpg_tfo->tpg_get_tag(tpg), lun->unpacked_lun,
@@ -216,7 +215,7 @@ static int core_set_queue_depth_for_node(
 	struct se_node_acl *acl)
 {
 	if (!acl->queue_depth) {
-		printk(KERN_ERR "Queue depth for %s Initiator Node: %s is 0,"
+		pr_err("Queue depth for %s Initiator Node: %s is 0,"
 			"defaulting to 1.\n", tpg->se_tpg_tfo->get_fabric_name(),
 			acl->initiatorname);
 		acl->queue_depth = 1;
@@ -236,8 +235,8 @@ static int core_create_device_list_for_node(struct se_node_acl *nacl)
 
 	nacl->device_list = kzalloc(sizeof(struct se_dev_entry) *
 				TRANSPORT_MAX_LUNS_PER_TPG, GFP_KERNEL);
-	if (!(nacl->device_list)) {
-		printk(KERN_ERR "Unable to allocate memory for"
+	if (!nacl->device_list) {
+		pr_err("Unable to allocate memory for"
 			" struct se_node_acl->device_list\n");
 		return -ENOMEM;
 	}
@@ -265,14 +264,14 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 	struct se_node_acl *acl;
 
 	acl = core_tpg_get_initiator_node_acl(tpg, initiatorname);
-	if ((acl))
+	if (acl)
 		return acl;
 
-	if (!(tpg->se_tpg_tfo->tpg_check_demo_mode(tpg)))
+	if (!tpg->se_tpg_tfo->tpg_check_demo_mode(tpg))
 		return NULL;
 
 	acl =  tpg->se_tpg_tfo->tpg_alloc_fabric_acl(tpg);
-	if (!(acl))
+	if (!acl)
 		return NULL;
 
 	INIT_LIST_HEAD(&acl->acl_list);
@@ -307,7 +306,7 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 	tpg->num_node_acls++;
 	spin_unlock_bh(&tpg->acl_node_lock);
 
-	printk("%s_TPG[%u] - Added DYNAMIC ACL with TCQ Depth: %d for %s"
+	pr_debug("%s_TPG[%u] - Added DYNAMIC ACL with TCQ Depth: %d for %s"
 		" Initiator Node: %s\n", tpg->se_tpg_tfo->get_fabric_name(),
 		tpg->se_tpg_tfo->tpg_get_tag(tpg), acl->queue_depth,
 		tpg->se_tpg_tfo->get_fabric_name(), initiatorname);
@@ -357,10 +356,10 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 
 	spin_lock_bh(&tpg->acl_node_lock);
 	acl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);
-	if ((acl)) {
+	if (acl) {
 		if (acl->dynamic_node_acl) {
 			acl->dynamic_node_acl = 0;
-			printk(KERN_INFO "%s_TPG[%u] - Replacing dynamic ACL"
+			pr_debug("%s_TPG[%u] - Replacing dynamic ACL"
 				" for %s\n", tpg->se_tpg_tfo->get_fabric_name(),
 				tpg->se_tpg_tfo->tpg_get_tag(tpg), initiatorname);
 			spin_unlock_bh(&tpg->acl_node_lock);
@@ -375,7 +374,7 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 			goto done;
 		}
 
-		printk(KERN_ERR "ACL entry for %s Initiator"
+		pr_err("ACL entry for %s Initiator"
 			" Node %s already exists for TPG %u, ignoring"
 			" request.\n",  tpg->se_tpg_tfo->get_fabric_name(),
 			initiatorname, tpg->se_tpg_tfo->tpg_get_tag(tpg));
@@ -384,8 +383,8 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 	}
 	spin_unlock_bh(&tpg->acl_node_lock);
 
-	if (!(se_nacl)) {
-		printk("struct se_node_acl pointer is NULL\n");
+	if (!se_nacl) {
+		pr_err("struct se_node_acl pointer is NULL\n");
 		return ERR_PTR(-EINVAL);
 	}
 	/*
@@ -425,7 +424,7 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 	spin_unlock_bh(&tpg->acl_node_lock);
 
 done:
-	printk(KERN_INFO "%s_TPG[%hu] - Added ACL with TCQ Depth: %d for %s"
+	pr_debug("%s_TPG[%hu] - Added ACL with TCQ Depth: %d for %s"
 		" Initiator Node: %s\n", tpg->se_tpg_tfo->get_fabric_name(),
 		tpg->se_tpg_tfo->tpg_get_tag(tpg), acl->queue_depth,
 		tpg->se_tpg_tfo->get_fabric_name(), initiatorname);
@@ -463,7 +462,7 @@ int core_tpg_del_initiator_node_acl(
 		/*
 		 * Determine if the session needs to be closed by our context.
 		 */
-		if (!(tpg->se_tpg_tfo->shutdown_session(sess)))
+		if (!tpg->se_tpg_tfo->shutdown_session(sess))
 			continue;
 
 		spin_unlock_bh(&tpg->session_lock);
@@ -481,7 +480,7 @@ int core_tpg_del_initiator_node_acl(
 	core_clear_initiator_node_from_tpg(acl, tpg);
 	core_free_device_list_for_node(acl, tpg);
 
-	printk(KERN_INFO "%s_TPG[%hu] - Deleted ACL with TCQ Depth: %d for %s"
+	pr_debug("%s_TPG[%hu] - Deleted ACL with TCQ Depth: %d for %s"
 		" Initiator Node: %s\n", tpg->se_tpg_tfo->get_fabric_name(),
 		tpg->se_tpg_tfo->tpg_get_tag(tpg), acl->queue_depth,
 		tpg->se_tpg_tfo->get_fabric_name(), acl->initiatorname);
@@ -506,8 +505,8 @@ int core_tpg_set_initiator_node_queue_depth(
 
 	spin_lock_bh(&tpg->acl_node_lock);
 	acl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);
-	if (!(acl)) {
-		printk(KERN_ERR "Access Control List entry for %s Initiator"
+	if (!acl) {
+		pr_err("Access Control List entry for %s Initiator"
 			" Node %s does not exists for TPG %hu, ignoring"
 			" request.\n", tpg->se_tpg_tfo->get_fabric_name(),
 			initiatorname, tpg->se_tpg_tfo->tpg_get_tag(tpg));
@@ -526,7 +525,7 @@ int core_tpg_set_initiator_node_queue_depth(
 			continue;
 
 		if (!force) {
-			printk(KERN_ERR "Unable to change queue depth for %s"
+			pr_err("Unable to change queue depth for %s"
 				" Initiator Node: %s while session is"
 				" operational.  To forcefully change the queue"
 				" depth and force session reinstatement"
@@ -543,7 +542,7 @@ int core_tpg_set_initiator_node_queue_depth(
 		/*
 		 * Determine if the session needs to be closed by our context.
 		 */
-		if (!(tpg->se_tpg_tfo->shutdown_session(sess)))
+		if (!tpg->se_tpg_tfo->shutdown_session(sess))
 			continue;
 
 		init_sess = sess;
@@ -586,7 +585,7 @@ int core_tpg_set_initiator_node_queue_depth(
 	if (init_sess)
 		tpg->se_tpg_tfo->close_session(init_sess);
 
-	printk(KERN_INFO "Successfuly changed queue depth to: %d for Initiator"
+	pr_debug("Successfuly changed queue depth to: %d for Initiator"
 		" Node: %s on %s Target Portal Group: %u\n", queue_depth,
 		initiatorname, tpg->se_tpg_tfo->get_fabric_name(),
 		tpg->se_tpg_tfo->tpg_get_tag(tpg));
@@ -644,8 +643,8 @@ int core_tpg_register(
 
 	se_tpg->tpg_lun_list = kzalloc((sizeof(struct se_lun) *
 				TRANSPORT_MAX_LUNS_PER_TPG), GFP_KERNEL);
-	if (!(se_tpg->tpg_lun_list)) {
-		printk(KERN_ERR "Unable to allocate struct se_portal_group->"
+	if (!se_tpg->tpg_lun_list) {
+		pr_err("Unable to allocate struct se_portal_group->"
 				"tpg_lun_list\n");
 		return -ENOMEM;
 	}
@@ -686,7 +685,7 @@ int core_tpg_register(
 	list_add_tail(&se_tpg->se_tpg_node, &tpg_list);
 	spin_unlock_bh(&tpg_lock);
 
-	printk(KERN_INFO "TARGET_CORE[%s]: Allocated %s struct se_portal_group for"
+	pr_debug("TARGET_CORE[%s]: Allocated %s struct se_portal_group for"
 		" endpoint: %s, Portal Tag: %u\n", tfo->get_fabric_name(),
 		(se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL) ?
 		"Normal" : "Discovery", (tfo->tpg_get_wwn(se_tpg) == NULL) ?
@@ -700,7 +699,7 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 {
 	struct se_node_acl *nacl, *nacl_tmp;
 
-	printk(KERN_INFO "TARGET_CORE[%s]: Deallocating %s struct se_portal_group"
+	pr_debug("TARGET_CORE[%s]: Deallocating %s struct se_portal_group"
 		" for endpoint: %s Portal Tag %u\n",
 		(se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL) ?
 		"Normal" : "Discovery", se_tpg->se_tpg_tfo->get_fabric_name(),
@@ -749,7 +748,7 @@ struct se_lun *core_tpg_pre_addlun(
 	struct se_lun *lun;
 
 	if (unpacked_lun > (TRANSPORT_MAX_LUNS_PER_TPG-1)) {
-		printk(KERN_ERR "%s LUN: %u exceeds TRANSPORT_MAX_LUNS_PER_TPG"
+		pr_err("%s LUN: %u exceeds TRANSPORT_MAX_LUNS_PER_TPG"
 			"-1: %u for Target Portal Group: %u\n",
 			tpg->se_tpg_tfo->get_fabric_name(),
 			unpacked_lun, TRANSPORT_MAX_LUNS_PER_TPG-1,
@@ -760,7 +759,7 @@ struct se_lun *core_tpg_pre_addlun(
 	spin_lock(&tpg->tpg_lun_lock);
 	lun = &tpg->tpg_lun_list[unpacked_lun];
 	if (lun->lun_status == TRANSPORT_LUN_STATUS_ACTIVE) {
-		printk(KERN_ERR "TPG Logical Unit Number: %u is already active"
+		pr_err("TPG Logical Unit Number: %u is already active"
 			" on %s Target Portal Group: %u, ignoring request.\n",
 			unpacked_lun, tpg->se_tpg_tfo->get_fabric_name(),
 			tpg->se_tpg_tfo->tpg_get_tag(tpg));
@@ -808,7 +807,7 @@ struct se_lun *core_tpg_pre_dellun(
 	struct se_lun *lun;
 
 	if (unpacked_lun > (TRANSPORT_MAX_LUNS_PER_TPG-1)) {
-		printk(KERN_ERR "%s LUN: %u exceeds TRANSPORT_MAX_LUNS_PER_TPG"
+		pr_err("%s LUN: %u exceeds TRANSPORT_MAX_LUNS_PER_TPG"
 			"-1: %u for Target Portal Group: %u\n",
 			tpg->se_tpg_tfo->get_fabric_name(), unpacked_lun,
 			TRANSPORT_MAX_LUNS_PER_TPG-1,
@@ -819,7 +818,7 @@ struct se_lun *core_tpg_pre_dellun(
 	spin_lock(&tpg->tpg_lun_lock);
 	lun = &tpg->tpg_lun_list[unpacked_lun];
 	if (lun->lun_status != TRANSPORT_LUN_STATUS_ACTIVE) {
-		printk(KERN_ERR "%s Logical Unit Number: %u is not active on"
+		pr_err("%s Logical Unit Number: %u is not active on"
 			" Target Portal Group: %u, ignoring request.\n",
 			tpg->se_tpg_tfo->get_fabric_name(), unpacked_lun,
 			tpg->se_tpg_tfo->tpg_get_tag(tpg));

commit e3d6f909ed803d92a5ac9b4a2c087e0eae9b90d0
Author: Andy Grover <agrover@redhat.com>
Date:   Tue Jul 19 08:55:10 2011 +0000

    target: Core cleanups from AGrover (round 1)
    
    This patch contains the squashed version of a number of cleanups and
    minor fixes from Andy's initial series (round 1) for target core this
    past spring.  The condensed log looks like:
    
    target: use errno values instead of returning -1 for everything
    target: Rename transport_calc_sg_num to transport_init_task_sg
    target: Fix leak in error path in transport_init_task_sg
    target/pscsi: Remove pscsi_get_sh() usage
    target: Make two runtime checks into WARN_ONs
    target: Remove hba queue depth and convert to spin_lock_irq usage
    target: dev->dev_status_queue_obj is unused
    target: Make struct se_queue_req.cmd type struct se_cmd *
    target: Remove __transport_get_qr_from_queue()
    target: Rename se_dev->g_se_dev_list to se_dev_node
    target: Remove struct se_global
    target: Simplify scsi mib index table code
    target: Make dev_queue_obj a member of se_device instead of a pointer
    target: remove extraneous returns at end of void functions
    target: Ensure transport_dump_vpd_ident_type returns null-terminated str
    target: Function pointers don't need to use '&' to be assigned
    target: Fix comment in __transport_execute_tasks()
    target: Misc style cleanups
    target: rename struct pr_reservation_template to pr_reservation
    target: Remove #defines that just perform indirection
    target: Inline transport_get_task_from_execute_queue()
    target: Minor header comment fixes
    
    Signed-off-by: Andy Grover <agrover@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index 5ec745fed931..448129f74cf9 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -44,6 +44,12 @@
 #include <target/target_core_fabric_ops.h>
 
 #include "target_core_hba.h"
+#include "target_core_stat.h"
+
+extern struct se_device *g_lun0_dev;
+
+static DEFINE_SPINLOCK(tpg_lock);
+static LIST_HEAD(tpg_list);
 
 /*	core_clear_initiator_node_from_tpg():
  *
@@ -68,7 +74,7 @@ static void core_clear_initiator_node_from_tpg(
 		if (!deve->se_lun) {
 			printk(KERN_ERR "%s device entries device pointer is"
 				" NULL, but Initiator has access.\n",
-				TPG_TFO(tpg)->get_fabric_name());
+				tpg->se_tpg_tfo->get_fabric_name());
 			continue;
 		}
 
@@ -171,7 +177,7 @@ void core_tpg_add_node_to_devs(
 		 * By default in LIO-Target $FABRIC_MOD,
 		 * demo_mode_write_protect is ON, or READ_ONLY;
 		 */
-		if (!(TPG_TFO(tpg)->tpg_check_demo_mode_write_protect(tpg))) {
+		if (!(tpg->se_tpg_tfo->tpg_check_demo_mode_write_protect(tpg))) {
 			if (dev->dev_flags & DF_READ_ONLY)
 				lun_access = TRANSPORT_LUNFLAGS_READ_ONLY;
 			else
@@ -181,7 +187,7 @@ void core_tpg_add_node_to_devs(
 			 * Allow only optical drives to issue R/W in default RO
 			 * demo mode.
 			 */
-			if (TRANSPORT(dev)->get_device_type(dev) == TYPE_DISK)
+			if (dev->transport->get_device_type(dev) == TYPE_DISK)
 				lun_access = TRANSPORT_LUNFLAGS_READ_ONLY;
 			else
 				lun_access = TRANSPORT_LUNFLAGS_READ_WRITE;
@@ -189,8 +195,8 @@ void core_tpg_add_node_to_devs(
 
 		printk(KERN_INFO "TARGET_CORE[%s]->TPG[%u]_LUN[%u] - Adding %s"
 			" access for LUN in Demo Mode\n",
-			TPG_TFO(tpg)->get_fabric_name(),
-			TPG_TFO(tpg)->tpg_get_tag(tpg), lun->unpacked_lun,
+			tpg->se_tpg_tfo->get_fabric_name(),
+			tpg->se_tpg_tfo->tpg_get_tag(tpg), lun->unpacked_lun,
 			(lun_access == TRANSPORT_LUNFLAGS_READ_WRITE) ?
 			"READ-WRITE" : "READ-ONLY");
 
@@ -211,7 +217,7 @@ static int core_set_queue_depth_for_node(
 {
 	if (!acl->queue_depth) {
 		printk(KERN_ERR "Queue depth for %s Initiator Node: %s is 0,"
-			"defaulting to 1.\n", TPG_TFO(tpg)->get_fabric_name(),
+			"defaulting to 1.\n", tpg->se_tpg_tfo->get_fabric_name(),
 			acl->initiatorname);
 		acl->queue_depth = 1;
 	}
@@ -233,7 +239,7 @@ static int core_create_device_list_for_node(struct se_node_acl *nacl)
 	if (!(nacl->device_list)) {
 		printk(KERN_ERR "Unable to allocate memory for"
 			" struct se_node_acl->device_list\n");
-		return -1;
+		return -ENOMEM;
 	}
 	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
 		deve = &nacl->device_list[i];
@@ -262,10 +268,10 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 	if ((acl))
 		return acl;
 
-	if (!(TPG_TFO(tpg)->tpg_check_demo_mode(tpg)))
+	if (!(tpg->se_tpg_tfo->tpg_check_demo_mode(tpg)))
 		return NULL;
 
-	acl =  TPG_TFO(tpg)->tpg_alloc_fabric_acl(tpg);
+	acl =  tpg->se_tpg_tfo->tpg_alloc_fabric_acl(tpg);
 	if (!(acl))
 		return NULL;
 
@@ -274,23 +280,23 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 	spin_lock_init(&acl->device_list_lock);
 	spin_lock_init(&acl->nacl_sess_lock);
 	atomic_set(&acl->acl_pr_ref_count, 0);
-	acl->queue_depth = TPG_TFO(tpg)->tpg_get_default_depth(tpg);
+	acl->queue_depth = tpg->se_tpg_tfo->tpg_get_default_depth(tpg);
 	snprintf(acl->initiatorname, TRANSPORT_IQN_LEN, "%s", initiatorname);
 	acl->se_tpg = tpg;
 	acl->acl_index = scsi_get_new_index(SCSI_AUTH_INTR_INDEX);
 	spin_lock_init(&acl->stats_lock);
 	acl->dynamic_node_acl = 1;
 
-	TPG_TFO(tpg)->set_default_node_attributes(acl);
+	tpg->se_tpg_tfo->set_default_node_attributes(acl);
 
 	if (core_create_device_list_for_node(acl) < 0) {
-		TPG_TFO(tpg)->tpg_release_fabric_acl(tpg, acl);
+		tpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);
 		return NULL;
 	}
 
 	if (core_set_queue_depth_for_node(tpg, acl) < 0) {
 		core_free_device_list_for_node(acl, tpg);
-		TPG_TFO(tpg)->tpg_release_fabric_acl(tpg, acl);
+		tpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);
 		return NULL;
 	}
 
@@ -302,9 +308,9 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 	spin_unlock_bh(&tpg->acl_node_lock);
 
 	printk("%s_TPG[%u] - Added DYNAMIC ACL with TCQ Depth: %d for %s"
-		" Initiator Node: %s\n", TPG_TFO(tpg)->get_fabric_name(),
-		TPG_TFO(tpg)->tpg_get_tag(tpg), acl->queue_depth,
-		TPG_TFO(tpg)->get_fabric_name(), initiatorname);
+		" Initiator Node: %s\n", tpg->se_tpg_tfo->get_fabric_name(),
+		tpg->se_tpg_tfo->tpg_get_tag(tpg), acl->queue_depth,
+		tpg->se_tpg_tfo->get_fabric_name(), initiatorname);
 
 	return acl;
 }
@@ -355,8 +361,8 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 		if (acl->dynamic_node_acl) {
 			acl->dynamic_node_acl = 0;
 			printk(KERN_INFO "%s_TPG[%u] - Replacing dynamic ACL"
-				" for %s\n", TPG_TFO(tpg)->get_fabric_name(),
-				TPG_TFO(tpg)->tpg_get_tag(tpg), initiatorname);
+				" for %s\n", tpg->se_tpg_tfo->get_fabric_name(),
+				tpg->se_tpg_tfo->tpg_get_tag(tpg), initiatorname);
 			spin_unlock_bh(&tpg->acl_node_lock);
 			/*
 			 * Release the locally allocated struct se_node_acl
@@ -364,15 +370,15 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 			 * a pointer to an existing demo mode node ACL.
 			 */
 			if (se_nacl)
-				TPG_TFO(tpg)->tpg_release_fabric_acl(tpg,
+				tpg->se_tpg_tfo->tpg_release_fabric_acl(tpg,
 							se_nacl);
 			goto done;
 		}
 
 		printk(KERN_ERR "ACL entry for %s Initiator"
 			" Node %s already exists for TPG %u, ignoring"
-			" request.\n",  TPG_TFO(tpg)->get_fabric_name(),
-			initiatorname, TPG_TFO(tpg)->tpg_get_tag(tpg));
+			" request.\n",  tpg->se_tpg_tfo->get_fabric_name(),
+			initiatorname, tpg->se_tpg_tfo->tpg_get_tag(tpg));
 		spin_unlock_bh(&tpg->acl_node_lock);
 		return ERR_PTR(-EEXIST);
 	}
@@ -400,16 +406,16 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 	acl->acl_index = scsi_get_new_index(SCSI_AUTH_INTR_INDEX);
 	spin_lock_init(&acl->stats_lock);
 
-	TPG_TFO(tpg)->set_default_node_attributes(acl);
+	tpg->se_tpg_tfo->set_default_node_attributes(acl);
 
 	if (core_create_device_list_for_node(acl) < 0) {
-		TPG_TFO(tpg)->tpg_release_fabric_acl(tpg, acl);
+		tpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);
 		return ERR_PTR(-ENOMEM);
 	}
 
 	if (core_set_queue_depth_for_node(tpg, acl) < 0) {
 		core_free_device_list_for_node(acl, tpg);
-		TPG_TFO(tpg)->tpg_release_fabric_acl(tpg, acl);
+		tpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);
 		return ERR_PTR(-EINVAL);
 	}
 
@@ -420,9 +426,9 @@ struct se_node_acl *core_tpg_add_initiator_node_acl(
 
 done:
 	printk(KERN_INFO "%s_TPG[%hu] - Added ACL with TCQ Depth: %d for %s"
-		" Initiator Node: %s\n", TPG_TFO(tpg)->get_fabric_name(),
-		TPG_TFO(tpg)->tpg_get_tag(tpg), acl->queue_depth,
-		TPG_TFO(tpg)->get_fabric_name(), initiatorname);
+		" Initiator Node: %s\n", tpg->se_tpg_tfo->get_fabric_name(),
+		tpg->se_tpg_tfo->tpg_get_tag(tpg), acl->queue_depth,
+		tpg->se_tpg_tfo->get_fabric_name(), initiatorname);
 
 	return acl;
 }
@@ -457,7 +463,7 @@ int core_tpg_del_initiator_node_acl(
 		/*
 		 * Determine if the session needs to be closed by our context.
 		 */
-		if (!(TPG_TFO(tpg)->shutdown_session(sess)))
+		if (!(tpg->se_tpg_tfo->shutdown_session(sess)))
 			continue;
 
 		spin_unlock_bh(&tpg->session_lock);
@@ -465,7 +471,7 @@ int core_tpg_del_initiator_node_acl(
 		 * If the $FABRIC_MOD session for the Initiator Node ACL exists,
 		 * forcefully shutdown the $FABRIC_MOD session/nexus.
 		 */
-		TPG_TFO(tpg)->close_session(sess);
+		tpg->se_tpg_tfo->close_session(sess);
 
 		spin_lock_bh(&tpg->session_lock);
 	}
@@ -476,9 +482,9 @@ int core_tpg_del_initiator_node_acl(
 	core_free_device_list_for_node(acl, tpg);
 
 	printk(KERN_INFO "%s_TPG[%hu] - Deleted ACL with TCQ Depth: %d for %s"
-		" Initiator Node: %s\n", TPG_TFO(tpg)->get_fabric_name(),
-		TPG_TFO(tpg)->tpg_get_tag(tpg), acl->queue_depth,
-		TPG_TFO(tpg)->get_fabric_name(), acl->initiatorname);
+		" Initiator Node: %s\n", tpg->se_tpg_tfo->get_fabric_name(),
+		tpg->se_tpg_tfo->tpg_get_tag(tpg), acl->queue_depth,
+		tpg->se_tpg_tfo->get_fabric_name(), acl->initiatorname);
 
 	return 0;
 }
@@ -503,8 +509,8 @@ int core_tpg_set_initiator_node_queue_depth(
 	if (!(acl)) {
 		printk(KERN_ERR "Access Control List entry for %s Initiator"
 			" Node %s does not exists for TPG %hu, ignoring"
-			" request.\n", TPG_TFO(tpg)->get_fabric_name(),
-			initiatorname, TPG_TFO(tpg)->tpg_get_tag(tpg));
+			" request.\n", tpg->se_tpg_tfo->get_fabric_name(),
+			initiatorname, tpg->se_tpg_tfo->tpg_get_tag(tpg));
 		spin_unlock_bh(&tpg->acl_node_lock);
 		return -ENODEV;
 	}
@@ -525,7 +531,7 @@ int core_tpg_set_initiator_node_queue_depth(
 				" operational.  To forcefully change the queue"
 				" depth and force session reinstatement"
 				" use the \"force=1\" parameter.\n",
-				TPG_TFO(tpg)->get_fabric_name(), initiatorname);
+				tpg->se_tpg_tfo->get_fabric_name(), initiatorname);
 			spin_unlock_bh(&tpg->session_lock);
 
 			spin_lock_bh(&tpg->acl_node_lock);
@@ -537,7 +543,7 @@ int core_tpg_set_initiator_node_queue_depth(
 		/*
 		 * Determine if the session needs to be closed by our context.
 		 */
-		if (!(TPG_TFO(tpg)->shutdown_session(sess)))
+		if (!(tpg->se_tpg_tfo->shutdown_session(sess)))
 			continue;
 
 		init_sess = sess;
@@ -549,7 +555,7 @@ int core_tpg_set_initiator_node_queue_depth(
 	 * Change the value in the Node's struct se_node_acl, and call
 	 * core_set_queue_depth_for_node() to add the requested queue depth.
 	 *
-	 * Finally call  TPG_TFO(tpg)->close_session() to force session
+	 * Finally call  tpg->se_tpg_tfo->close_session() to force session
 	 * reinstatement to occur if there is an active session for the
 	 * $FABRIC_MOD Initiator Node in question.
 	 */
@@ -561,10 +567,10 @@ int core_tpg_set_initiator_node_queue_depth(
 		 * Force session reinstatement if
 		 * core_set_queue_depth_for_node() failed, because we assume
 		 * the $FABRIC_MOD has already the set session reinstatement
-		 * bit from TPG_TFO(tpg)->shutdown_session() called above.
+		 * bit from tpg->se_tpg_tfo->shutdown_session() called above.
 		 */
 		if (init_sess)
-			TPG_TFO(tpg)->close_session(init_sess);
+			tpg->se_tpg_tfo->close_session(init_sess);
 
 		spin_lock_bh(&tpg->acl_node_lock);
 		if (dynamic_acl)
@@ -578,12 +584,12 @@ int core_tpg_set_initiator_node_queue_depth(
 	 * forcefully shutdown the $FABRIC_MOD session/nexus.
 	 */
 	if (init_sess)
-		TPG_TFO(tpg)->close_session(init_sess);
+		tpg->se_tpg_tfo->close_session(init_sess);
 
 	printk(KERN_INFO "Successfuly changed queue depth to: %d for Initiator"
 		" Node: %s on %s Target Portal Group: %u\n", queue_depth,
-		initiatorname, TPG_TFO(tpg)->get_fabric_name(),
-		TPG_TFO(tpg)->tpg_get_tag(tpg));
+		initiatorname, tpg->se_tpg_tfo->get_fabric_name(),
+		tpg->se_tpg_tfo->tpg_get_tag(tpg));
 
 	spin_lock_bh(&tpg->acl_node_lock);
 	if (dynamic_acl)
@@ -597,7 +603,7 @@ EXPORT_SYMBOL(core_tpg_set_initiator_node_queue_depth);
 static int core_tpg_setup_virtual_lun0(struct se_portal_group *se_tpg)
 {
 	/* Set in core_dev_setup_virtual_lun0() */
-	struct se_device *dev = se_global->g_lun0_dev;
+	struct se_device *dev = g_lun0_dev;
 	struct se_lun *lun = &se_tpg->tpg_virt_lun0;
 	u32 lun_access = TRANSPORT_LUNFLAGS_READ_ONLY;
 	int ret;
@@ -614,7 +620,7 @@ static int core_tpg_setup_virtual_lun0(struct se_portal_group *se_tpg)
 
 	ret = core_tpg_post_addlun(se_tpg, lun, lun_access, dev);
 	if (ret < 0)
-		return -1;
+		return ret;
 
 	return 0;
 }
@@ -663,7 +669,7 @@ int core_tpg_register(
 	se_tpg->se_tpg_wwn = se_wwn;
 	atomic_set(&se_tpg->tpg_pr_ref_count, 0);
 	INIT_LIST_HEAD(&se_tpg->acl_node_list);
-	INIT_LIST_HEAD(&se_tpg->se_tpg_list);
+	INIT_LIST_HEAD(&se_tpg->se_tpg_node);
 	INIT_LIST_HEAD(&se_tpg->tpg_sess_list);
 	spin_lock_init(&se_tpg->acl_node_lock);
 	spin_lock_init(&se_tpg->session_lock);
@@ -676,9 +682,9 @@ int core_tpg_register(
 		}
 	}
 
-	spin_lock_bh(&se_global->se_tpg_lock);
-	list_add_tail(&se_tpg->se_tpg_list, &se_global->g_se_tpg_list);
-	spin_unlock_bh(&se_global->se_tpg_lock);
+	spin_lock_bh(&tpg_lock);
+	list_add_tail(&se_tpg->se_tpg_node, &tpg_list);
+	spin_unlock_bh(&tpg_lock);
 
 	printk(KERN_INFO "TARGET_CORE[%s]: Allocated %s struct se_portal_group for"
 		" endpoint: %s, Portal Tag: %u\n", tfo->get_fabric_name(),
@@ -697,13 +703,13 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 	printk(KERN_INFO "TARGET_CORE[%s]: Deallocating %s struct se_portal_group"
 		" for endpoint: %s Portal Tag %u\n",
 		(se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL) ?
-		"Normal" : "Discovery", TPG_TFO(se_tpg)->get_fabric_name(),
-		TPG_TFO(se_tpg)->tpg_get_wwn(se_tpg),
-		TPG_TFO(se_tpg)->tpg_get_tag(se_tpg));
+		"Normal" : "Discovery", se_tpg->se_tpg_tfo->get_fabric_name(),
+		se_tpg->se_tpg_tfo->tpg_get_wwn(se_tpg),
+		se_tpg->se_tpg_tfo->tpg_get_tag(se_tpg));
 
-	spin_lock_bh(&se_global->se_tpg_lock);
-	list_del(&se_tpg->se_tpg_list);
-	spin_unlock_bh(&se_global->se_tpg_lock);
+	spin_lock_bh(&tpg_lock);
+	list_del(&se_tpg->se_tpg_node);
+	spin_unlock_bh(&tpg_lock);
 
 	while (atomic_read(&se_tpg->tpg_pr_ref_count) != 0)
 		cpu_relax();
@@ -721,7 +727,7 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 
 		core_tpg_wait_for_nacl_pr_ref(nacl);
 		core_free_device_list_for_node(nacl, se_tpg);
-		TPG_TFO(se_tpg)->tpg_release_fabric_acl(se_tpg, nacl);
+		se_tpg->se_tpg_tfo->tpg_release_fabric_acl(se_tpg, nacl);
 
 		spin_lock_bh(&se_tpg->acl_node_lock);
 	}
@@ -745,9 +751,9 @@ struct se_lun *core_tpg_pre_addlun(
 	if (unpacked_lun > (TRANSPORT_MAX_LUNS_PER_TPG-1)) {
 		printk(KERN_ERR "%s LUN: %u exceeds TRANSPORT_MAX_LUNS_PER_TPG"
 			"-1: %u for Target Portal Group: %u\n",
-			TPG_TFO(tpg)->get_fabric_name(),
+			tpg->se_tpg_tfo->get_fabric_name(),
 			unpacked_lun, TRANSPORT_MAX_LUNS_PER_TPG-1,
-			TPG_TFO(tpg)->tpg_get_tag(tpg));
+			tpg->se_tpg_tfo->tpg_get_tag(tpg));
 		return ERR_PTR(-EOVERFLOW);
 	}
 
@@ -756,8 +762,8 @@ struct se_lun *core_tpg_pre_addlun(
 	if (lun->lun_status == TRANSPORT_LUN_STATUS_ACTIVE) {
 		printk(KERN_ERR "TPG Logical Unit Number: %u is already active"
 			" on %s Target Portal Group: %u, ignoring request.\n",
-			unpacked_lun, TPG_TFO(tpg)->get_fabric_name(),
-			TPG_TFO(tpg)->tpg_get_tag(tpg));
+			unpacked_lun, tpg->se_tpg_tfo->get_fabric_name(),
+			tpg->se_tpg_tfo->tpg_get_tag(tpg));
 		spin_unlock(&tpg->tpg_lun_lock);
 		return ERR_PTR(-EINVAL);
 	}
@@ -772,8 +778,11 @@ int core_tpg_post_addlun(
 	u32 lun_access,
 	void *lun_ptr)
 {
-	if (core_dev_export(lun_ptr, tpg, lun) < 0)
-		return -1;
+	int ret;
+
+	ret = core_dev_export(lun_ptr, tpg, lun);
+	if (ret < 0)
+		return ret;
 
 	spin_lock(&tpg->tpg_lun_lock);
 	lun->lun_access = lun_access;
@@ -801,9 +810,9 @@ struct se_lun *core_tpg_pre_dellun(
 	if (unpacked_lun > (TRANSPORT_MAX_LUNS_PER_TPG-1)) {
 		printk(KERN_ERR "%s LUN: %u exceeds TRANSPORT_MAX_LUNS_PER_TPG"
 			"-1: %u for Target Portal Group: %u\n",
-			TPG_TFO(tpg)->get_fabric_name(), unpacked_lun,
+			tpg->se_tpg_tfo->get_fabric_name(), unpacked_lun,
 			TRANSPORT_MAX_LUNS_PER_TPG-1,
-			TPG_TFO(tpg)->tpg_get_tag(tpg));
+			tpg->se_tpg_tfo->tpg_get_tag(tpg));
 		return ERR_PTR(-EOVERFLOW);
 	}
 
@@ -812,8 +821,8 @@ struct se_lun *core_tpg_pre_dellun(
 	if (lun->lun_status != TRANSPORT_LUN_STATUS_ACTIVE) {
 		printk(KERN_ERR "%s Logical Unit Number: %u is not active on"
 			" Target Portal Group: %u, ignoring request.\n",
-			TPG_TFO(tpg)->get_fabric_name(), unpacked_lun,
-			TPG_TFO(tpg)->tpg_get_tag(tpg));
+			tpg->se_tpg_tfo->get_fabric_name(), unpacked_lun,
+			tpg->se_tpg_tfo->tpg_get_tag(tpg));
 		spin_unlock(&tpg->tpg_lun_lock);
 		return ERR_PTR(-ENODEV);
 	}

commit 5edc341313a188d94cde7ef87ac31647cea8601a
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Tue Jan 25 22:08:05 2011 +0100

    drivers: remove extraneous includes of smp_lock.h
    
    These were missed the last time I cleaned this up
    globally, because of code moving around or new code
    getting merged.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index c26f67467623..5ec745fed931 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -31,7 +31,6 @@
 #include <linux/timer.h>
 #include <linux/slab.h>
 #include <linux/spinlock.h>
-#include <linux/smp_lock.h>
 #include <linux/in.h>
 #include <net/sock.h>
 #include <net/tcp.h>

commit e89d15eeadb172bd53ca6362bf9ab6b22077224c
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Wed Feb 9 15:35:03 2011 -0800

    [SCSI] target: Remove procfs based target_core_mib.c code
    
    This patch removes the legacy procfs based target_core_mib.c code,
    and moves the necessary scsi_index_tables functions and defines into
    target_core_transport.c and target_core_base.h code to allow existing
    fabric independent statistics to function.
    
    This includes the removal of a handful of 'atomic_t mib_ref_count'
    counters used in struct se_node_acl, se_session and se_hba to prevent
    removal while using seq_list procfs walking logic.
    
    [jejb: fix up compile failures]
    Signed-off-by: Nicholas A. Bellinger <nab@linux-iscsi.org>
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
index abfa81a57115..c26f67467623 100644
--- a/drivers/target/target_core_tpg.c
+++ b/drivers/target/target_core_tpg.c
@@ -275,7 +275,6 @@ struct se_node_acl *core_tpg_check_initiator_node_acl(
 	spin_lock_init(&acl->device_list_lock);
 	spin_lock_init(&acl->nacl_sess_lock);
 	atomic_set(&acl->acl_pr_ref_count, 0);
-	atomic_set(&acl->mib_ref_count, 0);
 	acl->queue_depth = TPG_TFO(tpg)->tpg_get_default_depth(tpg);
 	snprintf(acl->initiatorname, TRANSPORT_IQN_LEN, "%s", initiatorname);
 	acl->se_tpg = tpg;
@@ -318,12 +317,6 @@ void core_tpg_wait_for_nacl_pr_ref(struct se_node_acl *nacl)
 		cpu_relax();
 }
 
-void core_tpg_wait_for_mib_ref(struct se_node_acl *nacl)
-{
-	while (atomic_read(&nacl->mib_ref_count) != 0)
-		cpu_relax();
-}
-
 void core_tpg_clear_object_luns(struct se_portal_group *tpg)
 {
 	int i, ret;
@@ -480,7 +473,6 @@ int core_tpg_del_initiator_node_acl(
 	spin_unlock_bh(&tpg->session_lock);
 
 	core_tpg_wait_for_nacl_pr_ref(acl);
-	core_tpg_wait_for_mib_ref(acl);
 	core_clear_initiator_node_from_tpg(acl, tpg);
 	core_free_device_list_for_node(acl, tpg);
 
@@ -701,6 +693,8 @@ EXPORT_SYMBOL(core_tpg_register);
 
 int core_tpg_deregister(struct se_portal_group *se_tpg)
 {
+	struct se_node_acl *nacl, *nacl_tmp;
+
 	printk(KERN_INFO "TARGET_CORE[%s]: Deallocating %s struct se_portal_group"
 		" for endpoint: %s Portal Tag %u\n",
 		(se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL) ?
@@ -714,6 +708,25 @@ int core_tpg_deregister(struct se_portal_group *se_tpg)
 
 	while (atomic_read(&se_tpg->tpg_pr_ref_count) != 0)
 		cpu_relax();
+	/*
+	 * Release any remaining demo-mode generated se_node_acl that have
+	 * not been released because of TFO->tpg_check_demo_mode_cache() == 1
+	 * in transport_deregister_session().
+	 */
+	spin_lock_bh(&se_tpg->acl_node_lock);
+	list_for_each_entry_safe(nacl, nacl_tmp, &se_tpg->acl_node_list,
+			acl_list) {
+		list_del(&nacl->acl_list);
+		se_tpg->num_node_acls--;
+		spin_unlock_bh(&se_tpg->acl_node_lock);
+
+		core_tpg_wait_for_nacl_pr_ref(nacl);
+		core_free_device_list_for_node(nacl, se_tpg);
+		TPG_TFO(se_tpg)->tpg_release_fabric_acl(se_tpg, nacl);
+
+		spin_lock_bh(&se_tpg->acl_node_lock);
+	}
+	spin_unlock_bh(&se_tpg->acl_node_lock);
 
 	if (se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL)
 		core_tpg_release_virtual_lun0(se_tpg);

commit c66ac9db8d4ad9994a02b3e933ea2ccc643e1fe5
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Fri Dec 17 11:11:26 2010 -0800

    [SCSI] target: Add LIO target core v4.0.0-rc6
    
    LIO target is a full featured in-kernel target framework with the
    following feature set:
    
    High-performance, non-blocking, multithreaded architecture with SIMD
    support.
    
    Advanced SCSI feature set:
    
        * Persistent Reservations (PRs)
        * Asymmetric Logical Unit Assignment (ALUA)
        * Protocol and intra-nexus multiplexing, load-balancing and failover (MC/S)
        * Full Error Recovery (ERL=0,1,2)
        * Active/active task migration and session continuation (ERL=2)
        * Thin LUN provisioning (UNMAP and WRITE_SAMExx)
    
    Multiprotocol target plugins
    
    Storage media independence:
    
        * Virtualization of all storage media; transparent mapping of IO to LUNs
        * No hard limits on number of LUNs per Target; maximum LUN size ~750 TB
        * Backstores: SATA, SAS, SCSI, BluRay, DVD, FLASH, USB, ramdisk, etc.
    
    Standards compliance:
    
        * Full compliance with IETF (RFC 3720)
        * Full implementation of SPC-4 PRs and ALUA
    
    Significant code cleanups done by Christoph Hellwig.
    
    [jejb: fix up for new block bdev exclusive interface. Minor fixes from
     Randy Dunlap and Dan Carpenter.]
    Signed-off-by: Nicholas A. Bellinger <nab@linux-iscsi.org>
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/drivers/target/target_core_tpg.c b/drivers/target/target_core_tpg.c
new file mode 100644
index 000000000000..abfa81a57115
--- /dev/null
+++ b/drivers/target/target_core_tpg.c
@@ -0,0 +1,826 @@
+/*******************************************************************************
+ * Filename:  target_core_tpg.c
+ *
+ * This file contains generic Target Portal Group related functions.
+ *
+ * Copyright (c) 2002, 2003, 2004, 2005 PyX Technologies, Inc.
+ * Copyright (c) 2005, 2006, 2007 SBE, Inc.
+ * Copyright (c) 2007-2010 Rising Tide Systems
+ * Copyright (c) 2008-2010 Linux-iSCSI.org
+ *
+ * Nicholas A. Bellinger <nab@kernel.org>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
+ *
+ ******************************************************************************/
+
+#include <linux/net.h>
+#include <linux/string.h>
+#include <linux/timer.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+#include <linux/smp_lock.h>
+#include <linux/in.h>
+#include <net/sock.h>
+#include <net/tcp.h>
+#include <scsi/scsi.h>
+#include <scsi/scsi_cmnd.h>
+
+#include <target/target_core_base.h>
+#include <target/target_core_device.h>
+#include <target/target_core_tpg.h>
+#include <target/target_core_transport.h>
+#include <target/target_core_fabric_ops.h>
+
+#include "target_core_hba.h"
+
+/*	core_clear_initiator_node_from_tpg():
+ *
+ *
+ */
+static void core_clear_initiator_node_from_tpg(
+	struct se_node_acl *nacl,
+	struct se_portal_group *tpg)
+{
+	int i;
+	struct se_dev_entry *deve;
+	struct se_lun *lun;
+	struct se_lun_acl *acl, *acl_tmp;
+
+	spin_lock_irq(&nacl->device_list_lock);
+	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
+		deve = &nacl->device_list[i];
+
+		if (!(deve->lun_flags & TRANSPORT_LUNFLAGS_INITIATOR_ACCESS))
+			continue;
+
+		if (!deve->se_lun) {
+			printk(KERN_ERR "%s device entries device pointer is"
+				" NULL, but Initiator has access.\n",
+				TPG_TFO(tpg)->get_fabric_name());
+			continue;
+		}
+
+		lun = deve->se_lun;
+		spin_unlock_irq(&nacl->device_list_lock);
+		core_update_device_list_for_node(lun, NULL, deve->mapped_lun,
+			TRANSPORT_LUNFLAGS_NO_ACCESS, nacl, tpg, 0);
+
+		spin_lock(&lun->lun_acl_lock);
+		list_for_each_entry_safe(acl, acl_tmp,
+					&lun->lun_acl_list, lacl_list) {
+			if (!(strcmp(acl->initiatorname,
+					nacl->initiatorname)) &&
+			     (acl->mapped_lun == deve->mapped_lun))
+				break;
+		}
+
+		if (!acl) {
+			printk(KERN_ERR "Unable to locate struct se_lun_acl for %s,"
+				" mapped_lun: %u\n", nacl->initiatorname,
+				deve->mapped_lun);
+			spin_unlock(&lun->lun_acl_lock);
+			spin_lock_irq(&nacl->device_list_lock);
+			continue;
+		}
+
+		list_del(&acl->lacl_list);
+		spin_unlock(&lun->lun_acl_lock);
+
+		spin_lock_irq(&nacl->device_list_lock);
+		kfree(acl);
+	}
+	spin_unlock_irq(&nacl->device_list_lock);
+}
+
+/*	__core_tpg_get_initiator_node_acl():
+ *
+ *	spin_lock_bh(&tpg->acl_node_lock); must be held when calling
+ */
+struct se_node_acl *__core_tpg_get_initiator_node_acl(
+	struct se_portal_group *tpg,
+	const char *initiatorname)
+{
+	struct se_node_acl *acl;
+
+	list_for_each_entry(acl, &tpg->acl_node_list, acl_list) {
+		if (!(strcmp(acl->initiatorname, initiatorname)))
+			return acl;
+	}
+
+	return NULL;
+}
+
+/*	core_tpg_get_initiator_node_acl():
+ *
+ *
+ */
+struct se_node_acl *core_tpg_get_initiator_node_acl(
+	struct se_portal_group *tpg,
+	unsigned char *initiatorname)
+{
+	struct se_node_acl *acl;
+
+	spin_lock_bh(&tpg->acl_node_lock);
+	list_for_each_entry(acl, &tpg->acl_node_list, acl_list) {
+		if (!(strcmp(acl->initiatorname, initiatorname)) &&
+		   (!(acl->dynamic_node_acl))) {
+			spin_unlock_bh(&tpg->acl_node_lock);
+			return acl;
+		}
+	}
+	spin_unlock_bh(&tpg->acl_node_lock);
+
+	return NULL;
+}
+
+/*	core_tpg_add_node_to_devs():
+ *
+ *
+ */
+void core_tpg_add_node_to_devs(
+	struct se_node_acl *acl,
+	struct se_portal_group *tpg)
+{
+	int i = 0;
+	u32 lun_access = 0;
+	struct se_lun *lun;
+	struct se_device *dev;
+
+	spin_lock(&tpg->tpg_lun_lock);
+	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
+		lun = &tpg->tpg_lun_list[i];
+		if (lun->lun_status != TRANSPORT_LUN_STATUS_ACTIVE)
+			continue;
+
+		spin_unlock(&tpg->tpg_lun_lock);
+
+		dev = lun->lun_se_dev;
+		/*
+		 * By default in LIO-Target $FABRIC_MOD,
+		 * demo_mode_write_protect is ON, or READ_ONLY;
+		 */
+		if (!(TPG_TFO(tpg)->tpg_check_demo_mode_write_protect(tpg))) {
+			if (dev->dev_flags & DF_READ_ONLY)
+				lun_access = TRANSPORT_LUNFLAGS_READ_ONLY;
+			else
+				lun_access = TRANSPORT_LUNFLAGS_READ_WRITE;
+		} else {
+			/*
+			 * Allow only optical drives to issue R/W in default RO
+			 * demo mode.
+			 */
+			if (TRANSPORT(dev)->get_device_type(dev) == TYPE_DISK)
+				lun_access = TRANSPORT_LUNFLAGS_READ_ONLY;
+			else
+				lun_access = TRANSPORT_LUNFLAGS_READ_WRITE;
+		}
+
+		printk(KERN_INFO "TARGET_CORE[%s]->TPG[%u]_LUN[%u] - Adding %s"
+			" access for LUN in Demo Mode\n",
+			TPG_TFO(tpg)->get_fabric_name(),
+			TPG_TFO(tpg)->tpg_get_tag(tpg), lun->unpacked_lun,
+			(lun_access == TRANSPORT_LUNFLAGS_READ_WRITE) ?
+			"READ-WRITE" : "READ-ONLY");
+
+		core_update_device_list_for_node(lun, NULL, lun->unpacked_lun,
+				lun_access, acl, tpg, 1);
+		spin_lock(&tpg->tpg_lun_lock);
+	}
+	spin_unlock(&tpg->tpg_lun_lock);
+}
+
+/*      core_set_queue_depth_for_node():
+ *
+ *
+ */
+static int core_set_queue_depth_for_node(
+	struct se_portal_group *tpg,
+	struct se_node_acl *acl)
+{
+	if (!acl->queue_depth) {
+		printk(KERN_ERR "Queue depth for %s Initiator Node: %s is 0,"
+			"defaulting to 1.\n", TPG_TFO(tpg)->get_fabric_name(),
+			acl->initiatorname);
+		acl->queue_depth = 1;
+	}
+
+	return 0;
+}
+
+/*      core_create_device_list_for_node():
+ *
+ *
+ */
+static int core_create_device_list_for_node(struct se_node_acl *nacl)
+{
+	struct se_dev_entry *deve;
+	int i;
+
+	nacl->device_list = kzalloc(sizeof(struct se_dev_entry) *
+				TRANSPORT_MAX_LUNS_PER_TPG, GFP_KERNEL);
+	if (!(nacl->device_list)) {
+		printk(KERN_ERR "Unable to allocate memory for"
+			" struct se_node_acl->device_list\n");
+		return -1;
+	}
+	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
+		deve = &nacl->device_list[i];
+
+		atomic_set(&deve->ua_count, 0);
+		atomic_set(&deve->pr_ref_count, 0);
+		spin_lock_init(&deve->ua_lock);
+		INIT_LIST_HEAD(&deve->alua_port_list);
+		INIT_LIST_HEAD(&deve->ua_list);
+	}
+
+	return 0;
+}
+
+/*	core_tpg_check_initiator_node_acl()
+ *
+ *
+ */
+struct se_node_acl *core_tpg_check_initiator_node_acl(
+	struct se_portal_group *tpg,
+	unsigned char *initiatorname)
+{
+	struct se_node_acl *acl;
+
+	acl = core_tpg_get_initiator_node_acl(tpg, initiatorname);
+	if ((acl))
+		return acl;
+
+	if (!(TPG_TFO(tpg)->tpg_check_demo_mode(tpg)))
+		return NULL;
+
+	acl =  TPG_TFO(tpg)->tpg_alloc_fabric_acl(tpg);
+	if (!(acl))
+		return NULL;
+
+	INIT_LIST_HEAD(&acl->acl_list);
+	INIT_LIST_HEAD(&acl->acl_sess_list);
+	spin_lock_init(&acl->device_list_lock);
+	spin_lock_init(&acl->nacl_sess_lock);
+	atomic_set(&acl->acl_pr_ref_count, 0);
+	atomic_set(&acl->mib_ref_count, 0);
+	acl->queue_depth = TPG_TFO(tpg)->tpg_get_default_depth(tpg);
+	snprintf(acl->initiatorname, TRANSPORT_IQN_LEN, "%s", initiatorname);
+	acl->se_tpg = tpg;
+	acl->acl_index = scsi_get_new_index(SCSI_AUTH_INTR_INDEX);
+	spin_lock_init(&acl->stats_lock);
+	acl->dynamic_node_acl = 1;
+
+	TPG_TFO(tpg)->set_default_node_attributes(acl);
+
+	if (core_create_device_list_for_node(acl) < 0) {
+		TPG_TFO(tpg)->tpg_release_fabric_acl(tpg, acl);
+		return NULL;
+	}
+
+	if (core_set_queue_depth_for_node(tpg, acl) < 0) {
+		core_free_device_list_for_node(acl, tpg);
+		TPG_TFO(tpg)->tpg_release_fabric_acl(tpg, acl);
+		return NULL;
+	}
+
+	core_tpg_add_node_to_devs(acl, tpg);
+
+	spin_lock_bh(&tpg->acl_node_lock);
+	list_add_tail(&acl->acl_list, &tpg->acl_node_list);
+	tpg->num_node_acls++;
+	spin_unlock_bh(&tpg->acl_node_lock);
+
+	printk("%s_TPG[%u] - Added DYNAMIC ACL with TCQ Depth: %d for %s"
+		" Initiator Node: %s\n", TPG_TFO(tpg)->get_fabric_name(),
+		TPG_TFO(tpg)->tpg_get_tag(tpg), acl->queue_depth,
+		TPG_TFO(tpg)->get_fabric_name(), initiatorname);
+
+	return acl;
+}
+EXPORT_SYMBOL(core_tpg_check_initiator_node_acl);
+
+void core_tpg_wait_for_nacl_pr_ref(struct se_node_acl *nacl)
+{
+	while (atomic_read(&nacl->acl_pr_ref_count) != 0)
+		cpu_relax();
+}
+
+void core_tpg_wait_for_mib_ref(struct se_node_acl *nacl)
+{
+	while (atomic_read(&nacl->mib_ref_count) != 0)
+		cpu_relax();
+}
+
+void core_tpg_clear_object_luns(struct se_portal_group *tpg)
+{
+	int i, ret;
+	struct se_lun *lun;
+
+	spin_lock(&tpg->tpg_lun_lock);
+	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
+		lun = &tpg->tpg_lun_list[i];
+
+		if ((lun->lun_status != TRANSPORT_LUN_STATUS_ACTIVE) ||
+		    (lun->lun_se_dev == NULL))
+			continue;
+
+		spin_unlock(&tpg->tpg_lun_lock);
+		ret = core_dev_del_lun(tpg, lun->unpacked_lun);
+		spin_lock(&tpg->tpg_lun_lock);
+	}
+	spin_unlock(&tpg->tpg_lun_lock);
+}
+EXPORT_SYMBOL(core_tpg_clear_object_luns);
+
+/*	core_tpg_add_initiator_node_acl():
+ *
+ *
+ */
+struct se_node_acl *core_tpg_add_initiator_node_acl(
+	struct se_portal_group *tpg,
+	struct se_node_acl *se_nacl,
+	const char *initiatorname,
+	u32 queue_depth)
+{
+	struct se_node_acl *acl = NULL;
+
+	spin_lock_bh(&tpg->acl_node_lock);
+	acl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);
+	if ((acl)) {
+		if (acl->dynamic_node_acl) {
+			acl->dynamic_node_acl = 0;
+			printk(KERN_INFO "%s_TPG[%u] - Replacing dynamic ACL"
+				" for %s\n", TPG_TFO(tpg)->get_fabric_name(),
+				TPG_TFO(tpg)->tpg_get_tag(tpg), initiatorname);
+			spin_unlock_bh(&tpg->acl_node_lock);
+			/*
+			 * Release the locally allocated struct se_node_acl
+			 * because * core_tpg_add_initiator_node_acl() returned
+			 * a pointer to an existing demo mode node ACL.
+			 */
+			if (se_nacl)
+				TPG_TFO(tpg)->tpg_release_fabric_acl(tpg,
+							se_nacl);
+			goto done;
+		}
+
+		printk(KERN_ERR "ACL entry for %s Initiator"
+			" Node %s already exists for TPG %u, ignoring"
+			" request.\n",  TPG_TFO(tpg)->get_fabric_name(),
+			initiatorname, TPG_TFO(tpg)->tpg_get_tag(tpg));
+		spin_unlock_bh(&tpg->acl_node_lock);
+		return ERR_PTR(-EEXIST);
+	}
+	spin_unlock_bh(&tpg->acl_node_lock);
+
+	if (!(se_nacl)) {
+		printk("struct se_node_acl pointer is NULL\n");
+		return ERR_PTR(-EINVAL);
+	}
+	/*
+	 * For v4.x logic the se_node_acl_s is hanging off a fabric
+	 * dependent structure allocated via
+	 * struct target_core_fabric_ops->fabric_make_nodeacl()
+	 */
+	acl = se_nacl;
+
+	INIT_LIST_HEAD(&acl->acl_list);
+	INIT_LIST_HEAD(&acl->acl_sess_list);
+	spin_lock_init(&acl->device_list_lock);
+	spin_lock_init(&acl->nacl_sess_lock);
+	atomic_set(&acl->acl_pr_ref_count, 0);
+	acl->queue_depth = queue_depth;
+	snprintf(acl->initiatorname, TRANSPORT_IQN_LEN, "%s", initiatorname);
+	acl->se_tpg = tpg;
+	acl->acl_index = scsi_get_new_index(SCSI_AUTH_INTR_INDEX);
+	spin_lock_init(&acl->stats_lock);
+
+	TPG_TFO(tpg)->set_default_node_attributes(acl);
+
+	if (core_create_device_list_for_node(acl) < 0) {
+		TPG_TFO(tpg)->tpg_release_fabric_acl(tpg, acl);
+		return ERR_PTR(-ENOMEM);
+	}
+
+	if (core_set_queue_depth_for_node(tpg, acl) < 0) {
+		core_free_device_list_for_node(acl, tpg);
+		TPG_TFO(tpg)->tpg_release_fabric_acl(tpg, acl);
+		return ERR_PTR(-EINVAL);
+	}
+
+	spin_lock_bh(&tpg->acl_node_lock);
+	list_add_tail(&acl->acl_list, &tpg->acl_node_list);
+	tpg->num_node_acls++;
+	spin_unlock_bh(&tpg->acl_node_lock);
+
+done:
+	printk(KERN_INFO "%s_TPG[%hu] - Added ACL with TCQ Depth: %d for %s"
+		" Initiator Node: %s\n", TPG_TFO(tpg)->get_fabric_name(),
+		TPG_TFO(tpg)->tpg_get_tag(tpg), acl->queue_depth,
+		TPG_TFO(tpg)->get_fabric_name(), initiatorname);
+
+	return acl;
+}
+EXPORT_SYMBOL(core_tpg_add_initiator_node_acl);
+
+/*	core_tpg_del_initiator_node_acl():
+ *
+ *
+ */
+int core_tpg_del_initiator_node_acl(
+	struct se_portal_group *tpg,
+	struct se_node_acl *acl,
+	int force)
+{
+	struct se_session *sess, *sess_tmp;
+	int dynamic_acl = 0;
+
+	spin_lock_bh(&tpg->acl_node_lock);
+	if (acl->dynamic_node_acl) {
+		acl->dynamic_node_acl = 0;
+		dynamic_acl = 1;
+	}
+	list_del(&acl->acl_list);
+	tpg->num_node_acls--;
+	spin_unlock_bh(&tpg->acl_node_lock);
+
+	spin_lock_bh(&tpg->session_lock);
+	list_for_each_entry_safe(sess, sess_tmp,
+				&tpg->tpg_sess_list, sess_list) {
+		if (sess->se_node_acl != acl)
+			continue;
+		/*
+		 * Determine if the session needs to be closed by our context.
+		 */
+		if (!(TPG_TFO(tpg)->shutdown_session(sess)))
+			continue;
+
+		spin_unlock_bh(&tpg->session_lock);
+		/*
+		 * If the $FABRIC_MOD session for the Initiator Node ACL exists,
+		 * forcefully shutdown the $FABRIC_MOD session/nexus.
+		 */
+		TPG_TFO(tpg)->close_session(sess);
+
+		spin_lock_bh(&tpg->session_lock);
+	}
+	spin_unlock_bh(&tpg->session_lock);
+
+	core_tpg_wait_for_nacl_pr_ref(acl);
+	core_tpg_wait_for_mib_ref(acl);
+	core_clear_initiator_node_from_tpg(acl, tpg);
+	core_free_device_list_for_node(acl, tpg);
+
+	printk(KERN_INFO "%s_TPG[%hu] - Deleted ACL with TCQ Depth: %d for %s"
+		" Initiator Node: %s\n", TPG_TFO(tpg)->get_fabric_name(),
+		TPG_TFO(tpg)->tpg_get_tag(tpg), acl->queue_depth,
+		TPG_TFO(tpg)->get_fabric_name(), acl->initiatorname);
+
+	return 0;
+}
+EXPORT_SYMBOL(core_tpg_del_initiator_node_acl);
+
+/*	core_tpg_set_initiator_node_queue_depth():
+ *
+ *
+ */
+int core_tpg_set_initiator_node_queue_depth(
+	struct se_portal_group *tpg,
+	unsigned char *initiatorname,
+	u32 queue_depth,
+	int force)
+{
+	struct se_session *sess, *init_sess = NULL;
+	struct se_node_acl *acl;
+	int dynamic_acl = 0;
+
+	spin_lock_bh(&tpg->acl_node_lock);
+	acl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);
+	if (!(acl)) {
+		printk(KERN_ERR "Access Control List entry for %s Initiator"
+			" Node %s does not exists for TPG %hu, ignoring"
+			" request.\n", TPG_TFO(tpg)->get_fabric_name(),
+			initiatorname, TPG_TFO(tpg)->tpg_get_tag(tpg));
+		spin_unlock_bh(&tpg->acl_node_lock);
+		return -ENODEV;
+	}
+	if (acl->dynamic_node_acl) {
+		acl->dynamic_node_acl = 0;
+		dynamic_acl = 1;
+	}
+	spin_unlock_bh(&tpg->acl_node_lock);
+
+	spin_lock_bh(&tpg->session_lock);
+	list_for_each_entry(sess, &tpg->tpg_sess_list, sess_list) {
+		if (sess->se_node_acl != acl)
+			continue;
+
+		if (!force) {
+			printk(KERN_ERR "Unable to change queue depth for %s"
+				" Initiator Node: %s while session is"
+				" operational.  To forcefully change the queue"
+				" depth and force session reinstatement"
+				" use the \"force=1\" parameter.\n",
+				TPG_TFO(tpg)->get_fabric_name(), initiatorname);
+			spin_unlock_bh(&tpg->session_lock);
+
+			spin_lock_bh(&tpg->acl_node_lock);
+			if (dynamic_acl)
+				acl->dynamic_node_acl = 1;
+			spin_unlock_bh(&tpg->acl_node_lock);
+			return -EEXIST;
+		}
+		/*
+		 * Determine if the session needs to be closed by our context.
+		 */
+		if (!(TPG_TFO(tpg)->shutdown_session(sess)))
+			continue;
+
+		init_sess = sess;
+		break;
+	}
+
+	/*
+	 * User has requested to change the queue depth for a Initiator Node.
+	 * Change the value in the Node's struct se_node_acl, and call
+	 * core_set_queue_depth_for_node() to add the requested queue depth.
+	 *
+	 * Finally call  TPG_TFO(tpg)->close_session() to force session
+	 * reinstatement to occur if there is an active session for the
+	 * $FABRIC_MOD Initiator Node in question.
+	 */
+	acl->queue_depth = queue_depth;
+
+	if (core_set_queue_depth_for_node(tpg, acl) < 0) {
+		spin_unlock_bh(&tpg->session_lock);
+		/*
+		 * Force session reinstatement if
+		 * core_set_queue_depth_for_node() failed, because we assume
+		 * the $FABRIC_MOD has already the set session reinstatement
+		 * bit from TPG_TFO(tpg)->shutdown_session() called above.
+		 */
+		if (init_sess)
+			TPG_TFO(tpg)->close_session(init_sess);
+
+		spin_lock_bh(&tpg->acl_node_lock);
+		if (dynamic_acl)
+			acl->dynamic_node_acl = 1;
+		spin_unlock_bh(&tpg->acl_node_lock);
+		return -EINVAL;
+	}
+	spin_unlock_bh(&tpg->session_lock);
+	/*
+	 * If the $FABRIC_MOD session for the Initiator Node ACL exists,
+	 * forcefully shutdown the $FABRIC_MOD session/nexus.
+	 */
+	if (init_sess)
+		TPG_TFO(tpg)->close_session(init_sess);
+
+	printk(KERN_INFO "Successfuly changed queue depth to: %d for Initiator"
+		" Node: %s on %s Target Portal Group: %u\n", queue_depth,
+		initiatorname, TPG_TFO(tpg)->get_fabric_name(),
+		TPG_TFO(tpg)->tpg_get_tag(tpg));
+
+	spin_lock_bh(&tpg->acl_node_lock);
+	if (dynamic_acl)
+		acl->dynamic_node_acl = 1;
+	spin_unlock_bh(&tpg->acl_node_lock);
+
+	return 0;
+}
+EXPORT_SYMBOL(core_tpg_set_initiator_node_queue_depth);
+
+static int core_tpg_setup_virtual_lun0(struct se_portal_group *se_tpg)
+{
+	/* Set in core_dev_setup_virtual_lun0() */
+	struct se_device *dev = se_global->g_lun0_dev;
+	struct se_lun *lun = &se_tpg->tpg_virt_lun0;
+	u32 lun_access = TRANSPORT_LUNFLAGS_READ_ONLY;
+	int ret;
+
+	lun->unpacked_lun = 0;
+	lun->lun_status = TRANSPORT_LUN_STATUS_FREE;
+	atomic_set(&lun->lun_acl_count, 0);
+	init_completion(&lun->lun_shutdown_comp);
+	INIT_LIST_HEAD(&lun->lun_acl_list);
+	INIT_LIST_HEAD(&lun->lun_cmd_list);
+	spin_lock_init(&lun->lun_acl_lock);
+	spin_lock_init(&lun->lun_cmd_lock);
+	spin_lock_init(&lun->lun_sep_lock);
+
+	ret = core_tpg_post_addlun(se_tpg, lun, lun_access, dev);
+	if (ret < 0)
+		return -1;
+
+	return 0;
+}
+
+static void core_tpg_release_virtual_lun0(struct se_portal_group *se_tpg)
+{
+	struct se_lun *lun = &se_tpg->tpg_virt_lun0;
+
+	core_tpg_post_dellun(se_tpg, lun);
+}
+
+int core_tpg_register(
+	struct target_core_fabric_ops *tfo,
+	struct se_wwn *se_wwn,
+	struct se_portal_group *se_tpg,
+	void *tpg_fabric_ptr,
+	int se_tpg_type)
+{
+	struct se_lun *lun;
+	u32 i;
+
+	se_tpg->tpg_lun_list = kzalloc((sizeof(struct se_lun) *
+				TRANSPORT_MAX_LUNS_PER_TPG), GFP_KERNEL);
+	if (!(se_tpg->tpg_lun_list)) {
+		printk(KERN_ERR "Unable to allocate struct se_portal_group->"
+				"tpg_lun_list\n");
+		return -ENOMEM;
+	}
+
+	for (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {
+		lun = &se_tpg->tpg_lun_list[i];
+		lun->unpacked_lun = i;
+		lun->lun_status = TRANSPORT_LUN_STATUS_FREE;
+		atomic_set(&lun->lun_acl_count, 0);
+		init_completion(&lun->lun_shutdown_comp);
+		INIT_LIST_HEAD(&lun->lun_acl_list);
+		INIT_LIST_HEAD(&lun->lun_cmd_list);
+		spin_lock_init(&lun->lun_acl_lock);
+		spin_lock_init(&lun->lun_cmd_lock);
+		spin_lock_init(&lun->lun_sep_lock);
+	}
+
+	se_tpg->se_tpg_type = se_tpg_type;
+	se_tpg->se_tpg_fabric_ptr = tpg_fabric_ptr;
+	se_tpg->se_tpg_tfo = tfo;
+	se_tpg->se_tpg_wwn = se_wwn;
+	atomic_set(&se_tpg->tpg_pr_ref_count, 0);
+	INIT_LIST_HEAD(&se_tpg->acl_node_list);
+	INIT_LIST_HEAD(&se_tpg->se_tpg_list);
+	INIT_LIST_HEAD(&se_tpg->tpg_sess_list);
+	spin_lock_init(&se_tpg->acl_node_lock);
+	spin_lock_init(&se_tpg->session_lock);
+	spin_lock_init(&se_tpg->tpg_lun_lock);
+
+	if (se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL) {
+		if (core_tpg_setup_virtual_lun0(se_tpg) < 0) {
+			kfree(se_tpg);
+			return -ENOMEM;
+		}
+	}
+
+	spin_lock_bh(&se_global->se_tpg_lock);
+	list_add_tail(&se_tpg->se_tpg_list, &se_global->g_se_tpg_list);
+	spin_unlock_bh(&se_global->se_tpg_lock);
+
+	printk(KERN_INFO "TARGET_CORE[%s]: Allocated %s struct se_portal_group for"
+		" endpoint: %s, Portal Tag: %u\n", tfo->get_fabric_name(),
+		(se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL) ?
+		"Normal" : "Discovery", (tfo->tpg_get_wwn(se_tpg) == NULL) ?
+		"None" : tfo->tpg_get_wwn(se_tpg), tfo->tpg_get_tag(se_tpg));
+
+	return 0;
+}
+EXPORT_SYMBOL(core_tpg_register);
+
+int core_tpg_deregister(struct se_portal_group *se_tpg)
+{
+	printk(KERN_INFO "TARGET_CORE[%s]: Deallocating %s struct se_portal_group"
+		" for endpoint: %s Portal Tag %u\n",
+		(se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL) ?
+		"Normal" : "Discovery", TPG_TFO(se_tpg)->get_fabric_name(),
+		TPG_TFO(se_tpg)->tpg_get_wwn(se_tpg),
+		TPG_TFO(se_tpg)->tpg_get_tag(se_tpg));
+
+	spin_lock_bh(&se_global->se_tpg_lock);
+	list_del(&se_tpg->se_tpg_list);
+	spin_unlock_bh(&se_global->se_tpg_lock);
+
+	while (atomic_read(&se_tpg->tpg_pr_ref_count) != 0)
+		cpu_relax();
+
+	if (se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL)
+		core_tpg_release_virtual_lun0(se_tpg);
+
+	se_tpg->se_tpg_fabric_ptr = NULL;
+	kfree(se_tpg->tpg_lun_list);
+	return 0;
+}
+EXPORT_SYMBOL(core_tpg_deregister);
+
+struct se_lun *core_tpg_pre_addlun(
+	struct se_portal_group *tpg,
+	u32 unpacked_lun)
+{
+	struct se_lun *lun;
+
+	if (unpacked_lun > (TRANSPORT_MAX_LUNS_PER_TPG-1)) {
+		printk(KERN_ERR "%s LUN: %u exceeds TRANSPORT_MAX_LUNS_PER_TPG"
+			"-1: %u for Target Portal Group: %u\n",
+			TPG_TFO(tpg)->get_fabric_name(),
+			unpacked_lun, TRANSPORT_MAX_LUNS_PER_TPG-1,
+			TPG_TFO(tpg)->tpg_get_tag(tpg));
+		return ERR_PTR(-EOVERFLOW);
+	}
+
+	spin_lock(&tpg->tpg_lun_lock);
+	lun = &tpg->tpg_lun_list[unpacked_lun];
+	if (lun->lun_status == TRANSPORT_LUN_STATUS_ACTIVE) {
+		printk(KERN_ERR "TPG Logical Unit Number: %u is already active"
+			" on %s Target Portal Group: %u, ignoring request.\n",
+			unpacked_lun, TPG_TFO(tpg)->get_fabric_name(),
+			TPG_TFO(tpg)->tpg_get_tag(tpg));
+		spin_unlock(&tpg->tpg_lun_lock);
+		return ERR_PTR(-EINVAL);
+	}
+	spin_unlock(&tpg->tpg_lun_lock);
+
+	return lun;
+}
+
+int core_tpg_post_addlun(
+	struct se_portal_group *tpg,
+	struct se_lun *lun,
+	u32 lun_access,
+	void *lun_ptr)
+{
+	if (core_dev_export(lun_ptr, tpg, lun) < 0)
+		return -1;
+
+	spin_lock(&tpg->tpg_lun_lock);
+	lun->lun_access = lun_access;
+	lun->lun_status = TRANSPORT_LUN_STATUS_ACTIVE;
+	spin_unlock(&tpg->tpg_lun_lock);
+
+	return 0;
+}
+
+static void core_tpg_shutdown_lun(
+	struct se_portal_group *tpg,
+	struct se_lun *lun)
+{
+	core_clear_lun_from_tpg(lun, tpg);
+	transport_clear_lun_from_sessions(lun);
+}
+
+struct se_lun *core_tpg_pre_dellun(
+	struct se_portal_group *tpg,
+	u32 unpacked_lun,
+	int *ret)
+{
+	struct se_lun *lun;
+
+	if (unpacked_lun > (TRANSPORT_MAX_LUNS_PER_TPG-1)) {
+		printk(KERN_ERR "%s LUN: %u exceeds TRANSPORT_MAX_LUNS_PER_TPG"
+			"-1: %u for Target Portal Group: %u\n",
+			TPG_TFO(tpg)->get_fabric_name(), unpacked_lun,
+			TRANSPORT_MAX_LUNS_PER_TPG-1,
+			TPG_TFO(tpg)->tpg_get_tag(tpg));
+		return ERR_PTR(-EOVERFLOW);
+	}
+
+	spin_lock(&tpg->tpg_lun_lock);
+	lun = &tpg->tpg_lun_list[unpacked_lun];
+	if (lun->lun_status != TRANSPORT_LUN_STATUS_ACTIVE) {
+		printk(KERN_ERR "%s Logical Unit Number: %u is not active on"
+			" Target Portal Group: %u, ignoring request.\n",
+			TPG_TFO(tpg)->get_fabric_name(), unpacked_lun,
+			TPG_TFO(tpg)->tpg_get_tag(tpg));
+		spin_unlock(&tpg->tpg_lun_lock);
+		return ERR_PTR(-ENODEV);
+	}
+	spin_unlock(&tpg->tpg_lun_lock);
+
+	return lun;
+}
+
+int core_tpg_post_dellun(
+	struct se_portal_group *tpg,
+	struct se_lun *lun)
+{
+	core_tpg_shutdown_lun(tpg, lun);
+
+	core_dev_unexport(lun->lun_se_dev, tpg, lun);
+
+	spin_lock(&tpg->tpg_lun_lock);
+	lun->lun_status = TRANSPORT_LUN_STATUS_FREE;
+	spin_unlock(&tpg->tpg_lun_lock);
+
+	return 0;
+}
