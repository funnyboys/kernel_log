commit 5d02a5c1d6e14534ca4729b055c89a2cd022ca00
Author: Keith Busch <kbusch@kernel.org>
Date:   Tue Sep 3 09:22:24 2019 -0600

    nvme: Remove ADMIN_ONLY state
    
    The admin only state was intended to fence off actions that don't
    apply to a non-IO capable controller. The only actual user of this is
    the scan_work, and pci was the only transport to ever set this state.
    The consequence of having this state is placing an additional burden on
    every other action that applies to both live and admin only controllers.
    
    Remove the admin only state and place the admin only burden on the only
    place that actually cares: scan_work.
    
    This also prepares to make it easier to temporarily pause a LIVE state
    so that we don't need to remember which state the controller had been in
    prior to the pause.
    
    Tested-by: Edmund Nadolski <edmund.nadolski@intel.com>
    Reviewed-by: James Smart <james.smart@broadcom.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Keith Busch <kbusch@kernel.org>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 93f08d77c896..a0ec40ab62ee 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -182,8 +182,7 @@ bool nvmf_ip_options_match(struct nvme_ctrl *ctrl,
 static inline bool nvmf_check_ready(struct nvme_ctrl *ctrl, struct request *rq,
 		bool queue_live)
 {
-	if (likely(ctrl->state == NVME_CTRL_LIVE ||
-		   ctrl->state == NVME_CTRL_ADMIN_ONLY))
+	if (likely(ctrl->state == NVME_CTRL_LIVE))
 		return true;
 	return __nvmf_check_ready(ctrl, rq, queue_live);
 }

commit 52b4451a9e5ae1e9ae739db16e8af61c77805389
Author: Israel Rukshin <israelr@mellanox.com>
Date:   Sun Aug 18 12:08:51 2019 +0300

    nvme-fabrics: Add type of service (TOS) configuration
    
    TOS is user-defined and needs to be configured via nvme-cli.
    It must be set before initiating any traffic and once set the TOS
    cannot be changed.
    
    Signed-off-by: Israel Rukshin <israelr@mellanox.com>
    Reviewed-by: Max Gurtovoy <maxg@mellanox.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 3044d8b99a24..93f08d77c896 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -55,6 +55,7 @@ enum {
 	NVMF_OPT_DATA_DIGEST	= 1 << 16,
 	NVMF_OPT_NR_WRITE_QUEUES = 1 << 17,
 	NVMF_OPT_NR_POLL_QUEUES = 1 << 18,
+	NVMF_OPT_TOS		= 1 << 19,
 };
 
 /**
@@ -87,6 +88,7 @@ enum {
  * @data_digest: generate/verify data digest (TCP)
  * @nr_write_queues: number of queues for write I/O
  * @nr_poll_queues: number of queues for polling I/O
+ * @tos: type of service
  */
 struct nvmf_ctrl_options {
 	unsigned		mask;
@@ -108,6 +110,7 @@ struct nvmf_ctrl_options {
 	bool			data_digest;
 	unsigned int		nr_write_queues;
 	unsigned int		nr_poll_queues;
+	int			tos;
 };
 
 /*

commit 9002c4e5ff006c62de09fe2b6966403bdf96afa1
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Feb 18 09:31:03 2019 +0100

    nvme-fabrics: convert to SPDX identifiers
    
    Update license to use SPDX-License-Identifier instead of verbose license
    text.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 478343b73e38..3044d8b99a24 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -1,15 +1,7 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * NVMe over Fabrics common host code.
  * Copyright (c) 2015-2016 HGST, a Western Digital Company.
- *
- * This program is free software; you can redistribute it and/or modify it
- * under the terms and conditions of the GNU General Public License,
- * version 2, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
- * more details.
  */
 #ifndef _NVME_FABRICS_H
 #define _NVME_FABRICS_H 1

commit 89d43802b0e7298bc0b464bdb5fff864074e2218
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Fri Dec 14 11:06:09 2018 -0800

    nvme-fabrics: allow user to pass in nr_poll_queues
    
    This argument will specify how many polling I/O queues to connect when
    creating the controller. These I/O queues will host I/O that is set with
    REQ_HIPRI.
    
    Reviewed-by: Steve Wise <swise@opengridcomputing.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index cad70a9f976a..478343b73e38 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -62,6 +62,7 @@ enum {
 	NVMF_OPT_HDR_DIGEST	= 1 << 15,
 	NVMF_OPT_DATA_DIGEST	= 1 << 16,
 	NVMF_OPT_NR_WRITE_QUEUES = 1 << 17,
+	NVMF_OPT_NR_POLL_QUEUES = 1 << 18,
 };
 
 /**
@@ -93,6 +94,7 @@ enum {
  * @hdr_digest: generate/verify header digest (TCP)
  * @data_digest: generate/verify data digest (TCP)
  * @nr_write_queues: number of queues for write I/O
+ * @nr_poll_queues: number of queues for polling I/O
  */
 struct nvmf_ctrl_options {
 	unsigned		mask;
@@ -113,6 +115,7 @@ struct nvmf_ctrl_options {
 	bool			hdr_digest;
 	bool			data_digest;
 	unsigned int		nr_write_queues;
+	unsigned int		nr_poll_queues;
 };
 
 /*

commit 26c682274e0a7d055e123499eac8ec39d0e04283
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Fri Dec 14 11:06:08 2018 -0800

    nvme-fabrics: allow nvmf_connect_io_queue to poll
    
    Preparation for polling support for fabrics. Polling support
    means that our completion queues are not generating any interrupts
    which means we need to poll for the nvmf io queue connect as well.
    
    Reviewed by Steve Wise <swise@opengridcomputing.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 81b8fd1c0c5d..cad70a9f976a 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -168,7 +168,7 @@ int nvmf_reg_read32(struct nvme_ctrl *ctrl, u32 off, u32 *val);
 int nvmf_reg_read64(struct nvme_ctrl *ctrl, u32 off, u64 *val);
 int nvmf_reg_write32(struct nvme_ctrl *ctrl, u32 off, u32 val);
 int nvmf_connect_admin_queue(struct nvme_ctrl *ctrl);
-int nvmf_connect_io_queue(struct nvme_ctrl *ctrl, u16 qid);
+int nvmf_connect_io_queue(struct nvme_ctrl *ctrl, u16 qid, bool poll);
 int nvmf_register_transport(struct nvmf_transport_ops *ops);
 void nvmf_unregister_transport(struct nvmf_transport_ops *ops);
 void nvmf_free_options(struct nvmf_ctrl_options *opts);

commit 330f6b8a70771f0b059b7bcbc9a28d8023235b55
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Tue Dec 11 23:38:56 2018 -0800

    nvme-fabrics: allow user to set nr_write_queues for separate queue maps
    
    This argument will specify how many I/O queues will be connected in
    create_ctrl in addition to nr_io_queues. With this configuration, I/O
    that carries payload from the host to the target, will use the default
    hctx queue map, and I/O that involves target to host transfers will use
    the read hctx queue map.
    
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 28dc916ef26b..81b8fd1c0c5d 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -61,6 +61,7 @@ enum {
 	NVMF_OPT_DISABLE_SQFLOW = 1 << 14,
 	NVMF_OPT_HDR_DIGEST	= 1 << 15,
 	NVMF_OPT_DATA_DIGEST	= 1 << 16,
+	NVMF_OPT_NR_WRITE_QUEUES = 1 << 17,
 };
 
 /**
@@ -91,6 +92,7 @@ enum {
  * @disable_sqflow: disable controller sq flow control
  * @hdr_digest: generate/verify header digest (TCP)
  * @data_digest: generate/verify data digest (TCP)
+ * @nr_write_queues: number of queues for write I/O
  */
 struct nvmf_ctrl_options {
 	unsigned		mask;
@@ -110,6 +112,7 @@ struct nvmf_ctrl_options {
 	bool			disable_sqflow;
 	bool			hdr_digest;
 	bool			data_digest;
+	unsigned int		nr_write_queues;
 };
 
 /*

commit fa9a1811e094658e53b0c82b6ce0431c4c54fc1b
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Tue Dec 11 23:38:55 2018 -0800

    nvme-fabrics: add missing nvmf_ctrl_options documentation
    
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 524a02a67817..28dc916ef26b 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -88,6 +88,9 @@ enum {
  * @max_reconnects: maximum number of allowed reconnect attempts before removing
  *              the controller, (-1) means reconnect forever, zero means remove
  *              immediately;
+ * @disable_sqflow: disable controller sq flow control
+ * @hdr_digest: generate/verify header digest (TCP)
+ * @data_digest: generate/verify data digest (TCP)
  */
 struct nvmf_ctrl_options {
 	unsigned		mask;

commit 20d44e86321299f61bb782a39aaa30f579823f58
Author: Sagi Grimberg <sagi@lightbitslabs.com>
Date:   Mon Dec 3 17:52:13 2018 -0800

    nvme-fabrics: allow user passing data digest
    
    Data digest is a nvme-tcp specific feature, but nothing prevents other
    transports reusing the concept so do not associate with tcp transport
    solely.
    
    Signed-off-by: Sagi Grimberg <sagi@lightbitslabs.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index a6127f1a9e8e..524a02a67817 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -60,6 +60,7 @@ enum {
 	NVMF_OPT_DUP_CONNECT	= 1 << 13,
 	NVMF_OPT_DISABLE_SQFLOW = 1 << 14,
 	NVMF_OPT_HDR_DIGEST	= 1 << 15,
+	NVMF_OPT_DATA_DIGEST	= 1 << 16,
 };
 
 /**
@@ -105,6 +106,7 @@ struct nvmf_ctrl_options {
 	int			max_reconnects;
 	bool			disable_sqflow;
 	bool			hdr_digest;
+	bool			data_digest;
 };
 
 /*

commit 3b49fa807284ec30669a95fd5f3806e127d29f4d
Author: Sagi Grimberg <sagi@lightbitslabs.com>
Date:   Mon Dec 3 17:52:12 2018 -0800

    nvme-fabrics: allow user passing header digest
    
    Header digest is a nvme-tcp specific feature, but nothing prevents other
    transports reusing the concept so do not associate with tcp transport
    solely.
    
    Signed-off-by: Sagi Grimberg <sagi@lightbitslabs.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index ecd9a006a091..a6127f1a9e8e 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -59,6 +59,7 @@ enum {
 	NVMF_OPT_HOST_ID	= 1 << 12,
 	NVMF_OPT_DUP_CONNECT	= 1 << 13,
 	NVMF_OPT_DISABLE_SQFLOW = 1 << 14,
+	NVMF_OPT_HDR_DIGEST	= 1 << 15,
 };
 
 /**
@@ -103,6 +104,7 @@ struct nvmf_ctrl_options {
 	struct nvmf_host	*host;
 	int			max_reconnects;
 	bool			disable_sqflow;
+	bool			hdr_digest;
 };
 
 /*

commit 8154ed730bc64f68bc28feb20e641c2e8a0eeba5
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Mon Nov 19 14:11:15 2018 -0800

    nvme: disable fabrics SQ flow control when asked by the user
    
    As for now, we don't care about sq_head pointer updates anyway, so
    at least allow the controller to micro-optimize by omiting this update.
    
    Note that we will probably need to support it when a controller
    that requires this comes along.
    
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 6ea6275f332a..ecd9a006a091 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -58,6 +58,7 @@ enum {
 	NVMF_OPT_CTRL_LOSS_TMO	= 1 << 11,
 	NVMF_OPT_HOST_ID	= 1 << 12,
 	NVMF_OPT_DUP_CONNECT	= 1 << 13,
+	NVMF_OPT_DISABLE_SQFLOW = 1 << 14,
 };
 
 /**
@@ -101,6 +102,7 @@ struct nvmf_ctrl_options {
 	unsigned int		kato;
 	struct nvmf_host	*host;
 	int			max_reconnects;
+	bool			disable_sqflow;
 };
 
 /*

commit b7c7be6f6bd28ffea7f608ac2d806b8a4bdc82fe
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Thu Oct 18 17:40:40 2018 -0700

    nvme-fabrics: move controller options matching to fabrics
    
    IP transports will most likely use the same controller options
    matching when detecting a duplicate connect. Move it to
    fabrics.
    
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index aa2fdb2a2e8f..6ea6275f332a 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -166,6 +166,8 @@ blk_status_t nvmf_fail_nonready_command(struct nvme_ctrl *ctrl,
 		struct request *rq);
 bool __nvmf_check_ready(struct nvme_ctrl *ctrl, struct request *rq,
 		bool queue_live);
+bool nvmf_ip_options_match(struct nvme_ctrl *ctrl,
+		struct nvmf_ctrl_options *opts);
 
 static inline bool nvmf_check_ready(struct nvme_ctrl *ctrl, struct request *rq,
 		bool queue_live)

commit 6cdefc6e2ad52170f89a8d0e8b1a1339f91834dc
Author: James Smart <jsmart2021@gmail.com>
Date:   Fri Jul 20 15:49:48 2018 -0700

    nvme: if_ready checks to fail io to deleting controller
    
    The revised if_ready checks skipped over the case of returning error when
    the controller is being deleted.  Instead it was returning BUSY, which
    caused the ios to retry, which caused the ns delete to hang waiting for
    the ios to drain.
    
    Stack trace of hang looks like:
     kworker/u64:2   D    0    74      2 0x80000000
     Workqueue: nvme-delete-wq nvme_delete_ctrl_work [nvme_core]
     Call Trace:
      ? __schedule+0x26d/0x820
      schedule+0x32/0x80
      blk_mq_freeze_queue_wait+0x36/0x80
      ? remove_wait_queue+0x60/0x60
      blk_cleanup_queue+0x72/0x160
      nvme_ns_remove+0x106/0x140 [nvme_core]
      nvme_remove_namespaces+0x7e/0xa0 [nvme_core]
      nvme_delete_ctrl_work+0x4d/0x80 [nvme_core]
      process_one_work+0x160/0x350
      worker_thread+0x1c3/0x3d0
      kthread+0xf5/0x130
      ? process_one_work+0x350/0x350
      ? kthread_bind+0x10/0x10
      ret_from_fork+0x1f/0x30
    
    Extend nvmf_fail_nonready_command() to supply the controller pointer so
    that the controller state can be looked at. Fail any io to a controller
    that is deleting.
    
    Fixes: 3bc32bb1186c ("nvme-fabrics: refactor queue ready check")
    Fixes: 35897b920c8a ("nvme-fabrics: fix and refine state checks in __nvmf_check_ready")
    Signed-off-by: James Smart <james.smart@broadcom.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Tested-by: Ewan D. Milne <emilne@redhat.com>
    Reviewed-by: Ewan D. Milne <emilne@redhat.com>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index e1818a27aa2d..aa2fdb2a2e8f 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -162,7 +162,8 @@ void nvmf_unregister_transport(struct nvmf_transport_ops *ops);
 void nvmf_free_options(struct nvmf_ctrl_options *opts);
 int nvmf_get_address(struct nvme_ctrl *ctrl, char *buf, int size);
 bool nvmf_should_reconnect(struct nvme_ctrl *ctrl);
-blk_status_t nvmf_fail_nonready_command(struct request *rq);
+blk_status_t nvmf_fail_nonready_command(struct nvme_ctrl *ctrl,
+		struct request *rq);
 bool __nvmf_check_ready(struct nvme_ctrl *ctrl, struct request *rq,
 		bool queue_live);
 

commit 278ab3799a2588f97423180947f09ec5b576e79e
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jun 11 17:37:23 2018 +0200

    nvme-fabrics: handle the admin-only case properly in nvmf_check_ready
    
    In the ADMIN_ONLY state we don't have any I/O queues, but we should accept
    all admin commands without further checks.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: James Smart <james.smart@broadcom.com>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 2ea949a3868c..e1818a27aa2d 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -169,7 +169,8 @@ bool __nvmf_check_ready(struct nvme_ctrl *ctrl, struct request *rq,
 static inline bool nvmf_check_ready(struct nvme_ctrl *ctrl, struct request *rq,
 		bool queue_live)
 {
-	if (likely(ctrl->state == NVME_CTRL_LIVE))
+	if (likely(ctrl->state == NVME_CTRL_LIVE ||
+		   ctrl->state == NVME_CTRL_ADMIN_ONLY))
 		return true;
 	return __nvmf_check_ready(ctrl, rq, queue_live);
 }

commit 3bc32bb1186ccaf3177cbf29caa6cc14dc510b7b
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jun 11 17:34:06 2018 +0200

    nvme-fabrics: refactor queue ready check
    
    Move the is_connected check to the fibre channel transport, as it has no
    meaning for other transports.  To facilitate this split out a new
    nvmf_fail_nonready_command helper that is called by the transport when
    it is asked to handle a command on a queue that is not ready.
    
    Also avoid a function call for the queue live fast path by inlining
    the check.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: James Smart <james.smart@broadcom.com>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 7491a0bbf711..2ea949a3868c 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -162,7 +162,16 @@ void nvmf_unregister_transport(struct nvmf_transport_ops *ops);
 void nvmf_free_options(struct nvmf_ctrl_options *opts);
 int nvmf_get_address(struct nvme_ctrl *ctrl, char *buf, int size);
 bool nvmf_should_reconnect(struct nvme_ctrl *ctrl);
-blk_status_t nvmf_check_if_ready(struct nvme_ctrl *ctrl,
-	struct request *rq, bool queue_live, bool is_connected);
+blk_status_t nvmf_fail_nonready_command(struct request *rq);
+bool __nvmf_check_ready(struct nvme_ctrl *ctrl, struct request *rq,
+		bool queue_live);
+
+static inline bool nvmf_check_ready(struct nvme_ctrl *ctrl, struct request *rq,
+		bool queue_live)
+{
+	if (likely(ctrl->state == NVME_CTRL_LIVE))
+		return true;
+	return __nvmf_check_ready(ctrl, rq, queue_live);
+}
 
 #endif /* _NVME_FABRICS_H */

commit 12a0b662210702c6b0ce9f66f0c177ff1dea99cb
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Fri Jun 1 09:11:20 2018 +0200

    nvme: don't hold nvmf_transports_rwsem for more than transport lookups
    
    Only take nvmf_transports_rwsem when doing a lookup of registered
    transports, so that a blocking ->create_ctrl doesn't prevent other
    actions on /dev/nvme-fabrics.
    
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    [hch: increased lock hold time a bit to be safe, added a comment
     and updated the changelog]
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 0cf0460a5c92..7491a0bbf711 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -124,6 +124,9 @@ struct nvmf_ctrl_options {
  *	1. At minimum, 'required_opts' and 'allowed_opts' should
  *	   be set to the same enum parsing options defined earlier.
  *	2. create_ctrl() must be defined (even if it does nothing)
+ *	3. struct nvmf_transport_ops must be statically allocated in the
+ *	   modules .bss section so that a pure module_get on @module
+ *	   prevents the memory from beeing freed.
  */
 struct nvmf_transport_ops {
 	struct list_head	entry;

commit ab4f47a9f4a12603a1806230d44ead2e54158f85
Author: James Smart <jsmart2021@gmail.com>
Date:   Fri May 25 14:02:23 2018 -0700

    nvme: allow duplicate controller if prior controller being deleted
    
    The current checks for whether a new controller request "matches" an
    existing controller ignores controller state and checks identity strings.
    There are cases where an existing controller may be in its last steps of
    deletion when they are "matched" by a new connection.
    
    Change the behavior so that the new connection ignores controllers that
    are deleted.
    
    Signed-off-by: James Smart <james.smart@broadcom.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index ef46c915b7b5..0cf0460a5c92 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -139,7 +139,9 @@ static inline bool
 nvmf_ctlr_matches_baseopts(struct nvme_ctrl *ctrl,
 			struct nvmf_ctrl_options *opts)
 {
-	if (strcmp(opts->subsysnqn, ctrl->opts->subsysnqn) ||
+	if (ctrl->state == NVME_CTRL_DELETING ||
+	    ctrl->state == NVME_CTRL_DEAD ||
+	    strcmp(opts->subsysnqn, ctrl->opts->subsysnqn) ||
 	    strcmp(opts->host->nqn, ctrl->opts->host->nqn) ||
 	    memcmp(&opts->host->id, &ctrl->opts->host->id, sizeof(uuid_t)))
 		return false;

commit bb06ec31452fb2da1594f88035c2ecea4e0652f4
Author: James Smart <jsmart2021@gmail.com>
Date:   Thu Apr 12 09:16:15 2018 -0600

    nvme: expand nvmf_check_if_ready checks
    
    The nvmf_check_if_ready() checks that were added are very simplistic.
    As such, the routine allows a lot of cases to fail ios during windows
    of reset or re-connection. In cases where there are not multi-path
    options present, the error goes back to the callee - the filesystem
    or application. Not good.
    
    The common routine was rewritten and calling syntax slightly expanded
    so that per-transport is_ready routines don't need to be present.
    The transports now call the routine directly. The routine is now a
    fabrics routine rather than an inline function.
    
    The routine now looks at controller state to decide the action to
    take. Some states mandate io failure. Others define the condition where
    a command can be accepted.  When the decision is unclear, a generic
    queue-or-reject check is made to look for failfast or multipath ios and
    only fails the io if it is so marked. Otherwise, the io will be queued
    and wait for the controller state to resolve.
    
    Admin commands issued via ioctl share a live admin queue with commands
    from the transport for controller init. The ioctls could be intermixed
    with the initialization commands. It's possible for the ioctl cmd to
    be issued prior to the controller being enabled. To block this, the
    ioctl admin commands need to be distinguished from admin commands used
    for controller init. Added a USERCMD nvme_req(req)->rq_flags bit to
    reflect this division and set it on ioctls requests.  As the
    nvmf_check_if_ready() routine is called prior to nvme_setup_cmd(),
    ensure that commands allocated by the ioctl path (actually anything
    in core.c) preps the nvme_req(req) before starting the io. This will
    preserve the USERCMD flag during execution and/or retry.
    
    Signed-off-by: James Smart <james.smart@broadcom.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.e>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Keith Busch <keith.busch@intel.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index a3145d90c1d2..ef46c915b7b5 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -157,36 +157,7 @@ void nvmf_unregister_transport(struct nvmf_transport_ops *ops);
 void nvmf_free_options(struct nvmf_ctrl_options *opts);
 int nvmf_get_address(struct nvme_ctrl *ctrl, char *buf, int size);
 bool nvmf_should_reconnect(struct nvme_ctrl *ctrl);
-
-static inline blk_status_t nvmf_check_init_req(struct nvme_ctrl *ctrl,
-		struct request *rq)
-{
-	struct nvme_command *cmd = nvme_req(rq)->cmd;
-
-	/*
-	 * We cannot accept any other command until the connect command has
-	 * completed, so only allow connect to pass.
-	 */
-	if (!blk_rq_is_passthrough(rq) ||
-	    cmd->common.opcode != nvme_fabrics_command ||
-	    cmd->fabrics.fctype != nvme_fabrics_type_connect) {
-		/*
-		 * Connecting state means transport disruption or initial
-		 * establishment, which can take a long time and even might
-		 * fail permanently, fail fast to give upper layers a chance
-		 * to failover.
-		 * Deleting state means that the ctrl will never accept commands
-		 * again, fail it permanently.
-		 */
-		if (ctrl->state == NVME_CTRL_CONNECTING ||
-		    ctrl->state == NVME_CTRL_DELETING) {
-			nvme_req(rq)->status = NVME_SC_ABORT_REQ;
-			return BLK_STS_IOERR;
-		}
-		return BLK_STS_RESOURCE; /* try again later */
-	}
-
-	return BLK_STS_OK;
-}
+blk_status_t nvmf_check_if_ready(struct nvme_ctrl *ctrl,
+	struct request *rq, bool queue_live, bool is_connected);
 
 #endif /* _NVME_FABRICS_H */

commit ad6a0a52e6de3d1161b7999c7903db906ba4cf79
Author: Max Gurtovoy <maxg@mellanox.com>
Date:   Wed Jan 31 18:31:24 2018 +0200

    nvme: rename NVME_CTRL_RECONNECTING state to NVME_CTRL_CONNECTING
    
    In pci transport, this state is used to mark the initialization
    process. This should be also used in other transports as well.
    
    Signed-off-by: Max Gurtovoy <maxg@mellanox.com>
    Reviewed-by: James Smart <james.smart@broadcom.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 25b19f722f5b..a3145d90c1d2 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -171,13 +171,14 @@ static inline blk_status_t nvmf_check_init_req(struct nvme_ctrl *ctrl,
 	    cmd->common.opcode != nvme_fabrics_command ||
 	    cmd->fabrics.fctype != nvme_fabrics_type_connect) {
 		/*
-		 * Reconnecting state means transport disruption, which can take
-		 * a long time and even might fail permanently, fail fast to
-		 * give upper layers a chance to failover.
+		 * Connecting state means transport disruption or initial
+		 * establishment, which can take a long time and even might
+		 * fail permanently, fail fast to give upper layers a chance
+		 * to failover.
 		 * Deleting state means that the ctrl will never accept commands
 		 * again, fail it permanently.
 		 */
-		if (ctrl->state == NVME_CTRL_RECONNECTING ||
+		if (ctrl->state == NVME_CTRL_CONNECTING ||
 		    ctrl->state == NVME_CTRL_DELETING) {
 			nvme_req(rq)->status = NVME_SC_ABORT_REQ;
 			return BLK_STS_IOERR;

commit 0de5cd367c6aa2a31a1c931628f778f79f8ef22e
Author: Roy Shterman <roys@lightbitslabs.com>
Date:   Mon Dec 25 14:18:30 2017 +0200

    nvme-fabrics: protect against module unload during create_ctrl
    
    NVMe transport driver module unload may (and usually does) trigger
    iteration over the active controllers and delete them all (sometimes
    under a mutex).  However, a controller can be created concurrently with
    module unload which can lead to leakage of resources (most important char
    device node leakage) in case the controller creation occured after the
    unload delete and drain sequence.  To protect against this, we take a
    module reference to guarantee that the nvme transport driver is not
    unloaded while creating a controller.
    
    Signed-off-by: Roy Shterman <roys@lightbitslabs.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Max Gurtovoy <maxg@mellanox.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 9ba614953607..25b19f722f5b 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -108,6 +108,7 @@ struct nvmf_ctrl_options {
  *			       fabric implementation of NVMe fabrics.
  * @entry:		Used by the fabrics library to add the new
  *			registration entry to its linked-list internal tree.
+ * @module:             Transport module reference
  * @name:		Name of the NVMe fabric driver implementation.
  * @required_opts:	sysfs command-line options that must be specified
  *			when adding a new NVMe controller.
@@ -126,6 +127,7 @@ struct nvmf_ctrl_options {
  */
 struct nvmf_transport_ops {
 	struct list_head	entry;
+	struct module		*module;
 	const char		*name;
 	int			required_opts;
 	int			allowed_opts;

commit 48832f8d58cfedb2f9bee11bbfbb657efb42e7e7
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Tue Oct 24 15:25:20 2017 +0300

    nvme-fabrics: introduce init command check for a queue that is not alive
    
    When the fabrics queue is not alive and fully functional, no commands
    should be allowed to pass but connect (which moves the queue to a fully
    functional state). Any other command should be failed, with either
    temporary status BLK_STS_RESOUCE or permanent status BLK_STS_IOERR.
    
    This is shared across all fabrics, hence move the check to fabrics
    library.
    
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 42232e731f19..9ba614953607 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -156,4 +156,34 @@ void nvmf_free_options(struct nvmf_ctrl_options *opts);
 int nvmf_get_address(struct nvme_ctrl *ctrl, char *buf, int size);
 bool nvmf_should_reconnect(struct nvme_ctrl *ctrl);
 
+static inline blk_status_t nvmf_check_init_req(struct nvme_ctrl *ctrl,
+		struct request *rq)
+{
+	struct nvme_command *cmd = nvme_req(rq)->cmd;
+
+	/*
+	 * We cannot accept any other command until the connect command has
+	 * completed, so only allow connect to pass.
+	 */
+	if (!blk_rq_is_passthrough(rq) ||
+	    cmd->common.opcode != nvme_fabrics_command ||
+	    cmd->fabrics.fctype != nvme_fabrics_type_connect) {
+		/*
+		 * Reconnecting state means transport disruption, which can take
+		 * a long time and even might fail permanently, fail fast to
+		 * give upper layers a chance to failover.
+		 * Deleting state means that the ctrl will never accept commands
+		 * again, fail it permanently.
+		 */
+		if (ctrl->state == NVME_CTRL_RECONNECTING ||
+		    ctrl->state == NVME_CTRL_DELETING) {
+			nvme_req(rq)->status = NVME_SC_ABORT_REQ;
+			return BLK_STS_IOERR;
+		}
+		return BLK_STS_RESOURCE; /* try again later */
+	}
+
+	return BLK_STS_OK;
+}
+
 #endif /* _NVME_FABRICS_H */

commit 991231dc48ae9bcdd363ee231f10beb771d455c1
Author: James Smart <jsmart2021@gmail.com>
Date:   Fri Oct 20 16:17:07 2017 -0700

    nvme: add helper to compare options to controller
    
    Adds a helper function that compares the host and subsytem
    specified in a connect options list vs a controller.
    
    Signed-off-by: James Smart <james.smart@broadcom.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index a7590cc59ba2..42232e731f19 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -133,6 +133,18 @@ struct nvmf_transport_ops {
 					struct nvmf_ctrl_options *opts);
 };
 
+static inline bool
+nvmf_ctlr_matches_baseopts(struct nvme_ctrl *ctrl,
+			struct nvmf_ctrl_options *opts)
+{
+	if (strcmp(opts->subsysnqn, ctrl->opts->subsysnqn) ||
+	    strcmp(opts->host->nqn, ctrl->opts->host->nqn) ||
+	    memcmp(&opts->host->id, &ctrl->opts->host->id, sizeof(uuid_t)))
+		return false;
+
+	return true;
+}
+
 int nvmf_reg_read32(struct nvme_ctrl *ctrl, u32 off, u32 *val);
 int nvmf_reg_read64(struct nvme_ctrl *ctrl, u32 off, u64 *val);
 int nvmf_reg_write32(struct nvme_ctrl *ctrl, u32 off, u32 val);

commit 3b3387620780fc9699021c85bdce5cb45a763d41
Author: James Smart <jsmart2021@gmail.com>
Date:   Fri Oct 20 16:17:06 2017 -0700

    nvme: add duplicate_connect option
    
    Add the "duplicate_connect" boolean option (presence means true).
    Default is false.
    
    When false, the transport should validate whether a new controller request
    is targeted for the same host transport addressing and target transport
    addressing as an existing controller. If so, the new controller request
    should be rejected.
    
    When true, the callee is explicitly requesting a duplicate controller
    connection to be made and the new request should be attempted.
    
    Signed-off-by: James Smart <james.smart@broadcom.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index bf33663218cd..a7590cc59ba2 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -57,6 +57,7 @@ enum {
 	NVMF_OPT_HOST_TRADDR	= 1 << 10,
 	NVMF_OPT_CTRL_LOSS_TMO	= 1 << 11,
 	NVMF_OPT_HOST_ID	= 1 << 12,
+	NVMF_OPT_DUP_CONNECT	= 1 << 13,
 };
 
 /**
@@ -96,6 +97,7 @@ struct nvmf_ctrl_options {
 	unsigned int		nr_io_queues;
 	unsigned int		reconnect_delay;
 	bool			discovery_nqn;
+	bool			duplicate_connect;
 	unsigned int		kato;
 	struct nvmf_host	*host;
 	int			max_reconnects;

commit 180de0070048340868c7bc841fc12e75556bb629
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jun 26 12:39:02 2017 +0200

    nvme: read the subsystem NQN from Identify Controller
    
    NVMe 1.2.1 or later requires controllers to provide a subsystem NQN in the
    Identify controller data structures.  Use this NQN for the subsysnqn
    sysfs attribute by storing it in the nvme_ctrl structure after verifying
    it.  For older controllers we generate a "fake" NQN per non-normative
    text in the NVMe 1.3 spec.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Keith Busch <keith.busch@intel.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index c8b2f0127ccc..bf33663218cd 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -139,7 +139,6 @@ int nvmf_connect_io_queue(struct nvme_ctrl *ctrl, u16 qid);
 int nvmf_register_transport(struct nvmf_transport_ops *ops);
 void nvmf_unregister_transport(struct nvmf_transport_ops *ops);
 void nvmf_free_options(struct nvmf_ctrl_options *opts);
-const char *nvmf_get_subsysnqn(struct nvme_ctrl *ctrl);
 int nvmf_get_address(struct nvme_ctrl *ctrl, char *buf, int size);
 bool nvmf_should_reconnect(struct nvme_ctrl *ctrl);
 

commit 6bfe04255d5ed5643ee4c2d9b09b337398f8cb6a
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Tue Jun 20 14:23:01 2017 +0200

    nvme: add hostid token to fabric options
    
    Currently we have no way to define a stable host-id but always use the one
    which is randomly generated when we add the host or use the default host.
    
    Provide a "hostid=%s" for user-space to pass in a persistent host-id which
    overrides the randomly generated one.
    
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Keith Busch <keith.busch@intel.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index f1c9bd7ae7ff..c8b2f0127ccc 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -56,6 +56,7 @@ enum {
 	NVMF_OPT_RECONNECT_DELAY = 1 << 9,
 	NVMF_OPT_HOST_TRADDR	= 1 << 10,
 	NVMF_OPT_CTRL_LOSS_TMO	= 1 << 11,
+	NVMF_OPT_HOST_ID	= 1 << 12,
 };
 
 /**

commit fdf9dfa85093f9813bc9818b7920fcf5a0eb3580
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Thu May 4 13:33:15 2017 +0300

    nvme: move nr_reconnects to nvme_ctrl
    
    It is not a user option but rather a variable controller
    attribute.
    
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 29be7600689d..f1c9bd7ae7ff 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -80,7 +80,6 @@ enum {
  * @discovery_nqn: indicates if the subsysnqn is the well-known discovery NQN.
  * @kato:	Keep-alive timeout.
  * @host:	Virtual NVMe host, contains the NQN and Host ID.
- * @nr_reconnects: number of reconnect attempted since the last ctrl failure
  * @max_reconnects: maximum number of allowed reconnect attempts before removing
  *              the controller, (-1) means reconnect forever, zero means remove
  *              immediately;
@@ -98,7 +97,6 @@ struct nvmf_ctrl_options {
 	bool			discovery_nqn;
 	unsigned int		kato;
 	struct nvmf_host	*host;
-	int			nr_reconnects;
 	int			max_reconnects;
 };
 

commit 8e41226324e7c00f2087bfbc9f470d665e92df18
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 17 09:54:27 2017 +0200

    nvme: switch to uuid_t
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Amir Goldstein <amir73il@gmail.com>
    Reviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index f5a9c1fb186f..29be7600689d 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -36,7 +36,7 @@ struct nvmf_host {
 	struct kref		ref;
 	struct list_head	list;
 	char			nqn[NVMF_NQN_SIZE];
-	uuid_be			id;
+	uuid_t			id;
 };
 
 /**

commit 42a45274c225829637b585e1c994a68f59507108
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Sat Mar 18 20:52:36 2017 +0200

    nvme-fabrics: Allow ctrl loss timeout configuration
    
    When a host sense that its controller session is damaged,
    it tries to re-establish it periodically (reconnect every
    reconnect_delay). It may very well be that the controller
    is gone and never coming back, in this case the host will
    try to reconnect forever.
    
    Add a ctrl_loss_tmo to bound the number of reconnect attempts
    to a specific controller (default to a reasonable 10 minutes).
    The timeout configuration is actually translated into number of
    reconnect attempts and not a schedule on its own but rather
    divided with reconnect_delay. This is useful to prevent
    racing flows of remove and reconnect, and it doesn't really
    matter if we remove slightly sooner than what the user requested.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 156018182ce4..f5a9c1fb186f 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -21,6 +21,8 @@
 #define NVMF_MAX_QUEUE_SIZE	1024
 #define NVMF_DEF_QUEUE_SIZE	128
 #define NVMF_DEF_RECONNECT_DELAY	10
+/* default to 600 seconds of reconnect attempts before giving up */
+#define NVMF_DEF_CTRL_LOSS_TMO		600
 
 /*
  * Define a host as seen by the target.  We allocate one at boot, but also
@@ -53,6 +55,7 @@ enum {
 	NVMF_OPT_HOSTNQN	= 1 << 8,
 	NVMF_OPT_RECONNECT_DELAY = 1 << 9,
 	NVMF_OPT_HOST_TRADDR	= 1 << 10,
+	NVMF_OPT_CTRL_LOSS_TMO	= 1 << 11,
 };
 
 /**
@@ -77,6 +80,10 @@ enum {
  * @discovery_nqn: indicates if the subsysnqn is the well-known discovery NQN.
  * @kato:	Keep-alive timeout.
  * @host:	Virtual NVMe host, contains the NQN and Host ID.
+ * @nr_reconnects: number of reconnect attempted since the last ctrl failure
+ * @max_reconnects: maximum number of allowed reconnect attempts before removing
+ *              the controller, (-1) means reconnect forever, zero means remove
+ *              immediately;
  */
 struct nvmf_ctrl_options {
 	unsigned		mask;
@@ -91,6 +98,8 @@ struct nvmf_ctrl_options {
 	bool			discovery_nqn;
 	unsigned int		kato;
 	struct nvmf_host	*host;
+	int			nr_reconnects;
+	int			max_reconnects;
 };
 
 /*
@@ -133,5 +142,6 @@ void nvmf_unregister_transport(struct nvmf_transport_ops *ops);
 void nvmf_free_options(struct nvmf_ctrl_options *opts);
 const char *nvmf_get_subsysnqn(struct nvme_ctrl *ctrl);
 int nvmf_get_address(struct nvme_ctrl *ctrl, char *buf, int size);
+bool nvmf_should_reconnect(struct nvme_ctrl *ctrl);
 
 #endif /* _NVME_FABRICS_H */

commit e5a39dd8238e5d42c830bbd8d31211adf6fea6ca
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Fri Jan 27 09:03:45 2017 +0100

    nvme: make nvmf_register_transport require a create_ctrl callback
    
    nvmf_create_ctrl() relys on the presence of a create_crtl callback in the
    registered nvmf_transport_ops, so make nvmf_register_transport require one.
    
    Update the available call-sites as well to reflect these changes.
    
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 924145c979f1..156018182ce4 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -128,7 +128,7 @@ int nvmf_reg_read64(struct nvme_ctrl *ctrl, u32 off, u64 *val);
 int nvmf_reg_write32(struct nvme_ctrl *ctrl, u32 off, u32 val);
 int nvmf_connect_admin_queue(struct nvme_ctrl *ctrl);
 int nvmf_connect_io_queue(struct nvme_ctrl *ctrl, u16 qid);
-void nvmf_register_transport(struct nvmf_transport_ops *ops);
+int nvmf_register_transport(struct nvmf_transport_ops *ops);
 void nvmf_unregister_transport(struct nvmf_transport_ops *ops);
 void nvmf_free_options(struct nvmf_ctrl_options *opts);
 const char *nvmf_get_subsysnqn(struct nvme_ctrl *ctrl);

commit 513a4befae06c4469abfb836e8f71977de58c636
Merge: 87840a2b7e04 997198ba1ed6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 7 14:42:05 2016 -0700

    Merge branch 'for-4.9/block' of git://git.kernel.dk/linux-block
    
    Pull block layer updates from Jens Axboe:
     "This is the main pull request for block layer changes in 4.9.
    
      As mentioned at the last merge window, I've changed things up and now
      do just one branch for core block layer changes, and driver changes.
      This avoids dependencies between the two branches. Outside of this
      main pull request, there are two topical branches coming as well.
    
      This pull request contains:
    
       - A set of fixes, and a conversion to blk-mq, of nbd. From Josef.
    
       - Set of fixes and updates for lightnvm from Matias, Simon, and Arnd.
         Followup dependency fix from Geert.
    
       - General fixes from Bart, Baoyou, Guoqing, and Linus W.
    
       - CFQ async write starvation fix from Glauber.
    
       - Add supprot for delayed kick of the requeue list, from Mike.
    
       - Pull out the scalable bitmap code from blk-mq-tag.c and make it
         generally available under the name of sbitmap. Only blk-mq-tag uses
         it for now, but the blk-mq scheduling bits will use it as well.
         From Omar.
    
       - bdev thaw error progagation from Pierre.
    
       - Improve the blk polling statistics, and allow the user to clear
         them. From Stephen.
    
       - Set of minor cleanups from Christoph in block/blk-mq.
    
       - Set of cleanups and optimizations from me for block/blk-mq.
    
       - Various nvme/nvmet/nvmeof fixes from the various folks"
    
    * 'for-4.9/block' of git://git.kernel.dk/linux-block: (54 commits)
      fs/block_dev.c: return the right error in thaw_bdev()
      nvme: Pass pointers, not dma addresses, to nvme_get/set_features()
      nvme/scsi: Remove power management support
      nvmet: Make dsm number of ranges zero based
      nvmet: Use direct IO for writes
      admin-cmd: Added smart-log command support.
      nvme-fabrics: Add host_traddr options field to host infrastructure
      nvme-fabrics: revise host transport option descriptions
      nvme-fabrics: rework nvmf_get_address() for variable options
      nbd: use BLK_MQ_F_BLOCKING
      blkcg: Annotate blkg_hint correctly
      cfq: fix starvation of asynchronous writes
      blk-mq: add flag for drivers wanting blocking ->queue_rq()
      blk-mq: remove non-blocking pass in blk_mq_map_request
      blk-mq: get rid of manual run of queue with __blk_mq_run_hw_queue()
      block: export bio_free_pages to other modules
      lightnvm: propagate device_add() error code
      lightnvm: expose device geometry through sysfs
      lightnvm: control life of nvm_dev in driver
      blk-mq: register device instead of disk
      ...

commit 478bcb9388f2c3eedba34ed5811793400047f95d
Author: James Smart <james.smart@broadcom.com>
Date:   Tue Aug 2 10:42:10 2016 +0300

    nvme-fabrics: Add host_traddr options field to host infrastructure
    
    Add the host_traddr field to allow specification of the host-port
    connection info for the transport. Will be used by FC transport.
    
    Signed-off-by: James Smart <james.smart@broadcom.com>
    Acked-by: Johannes Thumshirn <jth@kernel.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 2755efde16ac..8f08c3a3406b 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -52,6 +52,7 @@ enum {
 	NVMF_OPT_KATO		= 1 << 7,
 	NVMF_OPT_HOSTNQN	= 1 << 8,
 	NVMF_OPT_RECONNECT_DELAY = 1 << 9,
+	NVMF_OPT_HOST_TRADDR	= 1 << 10,
 };
 
 /**
@@ -68,6 +69,8 @@ enum {
  *              subsystem which is adding a controller.
  * @trsvcid:	The transport-specific TRSVCID field for a port on the
  *              subsystem which is adding a controller.
+ * @host_traddr: A transport-specific field identifying the NVME host port
+ *              to use for the connection to the controller.
  * @queue_size: Number of IO queue elements.
  * @nr_io_queues: Number of controller IO queues that will be established.
  * @reconnect_delay: Time between two consecutive reconnect attempts.
@@ -81,6 +84,7 @@ struct nvmf_ctrl_options {
 	char			*subsysnqn;
 	char			*traddr;
 	char			*trsvcid;
+	char			*host_traddr;
 	size_t			queue_size;
 	unsigned int		nr_io_queues;
 	unsigned int		reconnect_delay;

commit 4a9f05c57f98e794763650056731a0023ebfab5f
Author: James Smart <james.smart@broadcom.com>
Date:   Tue Aug 2 10:41:20 2016 +0300

    nvme-fabrics: revise host transport option descriptions
    
    Revise some of the comments so not so ethernet-network centric
    
    Signed-off-by: James Smart <james.smart@broadcom.com>
    Acked-by: Johannes Thumshirn <jth@kernel.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 89df52c8be97..2755efde16ac 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -64,9 +64,10 @@ enum {
  *		being added.
  * @subsysnqn:	Hold the fully qualified NQN subystem name (format defined
  *		in the NVMe specification, "NVMe Qualified Names").
- * @traddr:	network address that will be used by the host to communicate
- *		to the added NVMe controller.
- * @trsvcid:	network port used for host-controller communication.
+ * @traddr:	The transport-specific TRADDR field for a port on the
+ *              subsystem which is adding a controller.
+ * @trsvcid:	The transport-specific TRSVCID field for a port on the
+ *              subsystem which is adding a controller.
  * @queue_size: Number of IO queue elements.
  * @nr_io_queues: Number of controller IO queues that will be established.
  * @reconnect_delay: Time between two consecutive reconnect attempts.

commit 7a665d2f60b457c0d77b3e4f01e21c55ffc57069
Author: Daniel Verkamp <daniel.verkamp@intel.com>
Date:   Tue Jun 28 11:20:23 2016 -0700

    nvme-fabrics: change NQN UUID to big-endian format
    
    NVM Express 1.2.1 section 7.9, NVMe Qualified Names, specifies that the
    UUID format of NQN uses a UUID based on RFC 4122.
    
    RFC 4122 specifies that the UUID is encoded in big-endian byte order.
    
    Switch the NVMe over Fabrics host ID field from little-endian UUID to
    big-endian UUID to match the specification.
    
    Signed-off-by: Daniel Verkamp <daniel.verkamp@intel.com>
    Reviewed-by: Jay Freyensee <james_p_freyensee@linux.intel.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 89df52c8be97..46e460aee52d 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -34,7 +34,7 @@ struct nvmf_host {
 	struct kref		ref;
 	struct list_head	list;
 	char			nqn[NVMF_NQN_SIZE];
-	uuid_le			id;
+	uuid_be			id;
 };
 
 /**

commit 6a92967ccbfc20f94055c9a94bf951230cbd0452
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Wed Jun 22 15:06:01 2016 +0300

    nvme-fabrics: Remove tl_retry_count
    
    The timeout before error recovery logic kicks in is
    dictated by the nvme keep-alive, so we don't really need
    a transport layer retry count. transports can retry for
    as much as they like.
    
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index b54067404963..89df52c8be97 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -69,8 +69,6 @@ enum {
  * @trsvcid:	network port used for host-controller communication.
  * @queue_size: Number of IO queue elements.
  * @nr_io_queues: Number of controller IO queues that will be established.
- * @tl_retry_count: Number of transport layer retries for a fabric queue before
- *		     kicking upper layer(s) error recovery.
  * @reconnect_delay: Time between two consecutive reconnect attempts.
  * @discovery_nqn: indicates if the subsysnqn is the well-known discovery NQN.
  * @kato:	Keep-alive timeout.
@@ -84,7 +82,6 @@ struct nvmf_ctrl_options {
 	char			*trsvcid;
 	size_t			queue_size;
 	unsigned int		nr_io_queues;
-	unsigned short		tl_retry_count;
 	unsigned int		reconnect_delay;
 	bool			discovery_nqn;
 	unsigned int		kato;

commit 038bd4cb6766c69b5b9c77507f389cc718a36842
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Mon Jun 13 16:45:28 2016 +0200

    nvme: add keep-alive support
    
    Periodic keep-alive is a mandatory feature in NVMe over Fabrics, and
    optional in NVMe 1.2.1 for PCIe.  This patch adds periodic keep-alive
    sent from the host to verify that the controller is still responsive
    and vice-versa.  The keep-alive timeout is user-defined (with
    keep_alive_tmo connection parameter) and defaults to 5 seconds.
    
    In order to avoid a race condition where the host sends a keep-alive
    competing with the target side keep-alive timeout expiration, the host
    adds a grace period of 10 seconds when publishing the keep-alive timeout
    to the target.
    
    In case a keep-alive failed (or timed out), a transport specific error
    recovery kicks in.
    
    For now only NVMe over Fabrics is wired up to support keep alive, but
    we can add PCIe support easily once controllers actually supporting it
    become available.
    
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Steve Wise <swise@chelsio.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Keith Busch <keith.busch@intel.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
index 120383088bc1..b54067404963 100644
--- a/drivers/nvme/host/fabrics.h
+++ b/drivers/nvme/host/fabrics.h
@@ -49,6 +49,7 @@ enum {
 	NVMF_OPT_QUEUE_SIZE	= 1 << 4,
 	NVMF_OPT_NR_IO_QUEUES	= 1 << 5,
 	NVMF_OPT_TL_RETRY_COUNT	= 1 << 6,
+	NVMF_OPT_KATO		= 1 << 7,
 	NVMF_OPT_HOSTNQN	= 1 << 8,
 	NVMF_OPT_RECONNECT_DELAY = 1 << 9,
 };
@@ -72,6 +73,7 @@ enum {
  *		     kicking upper layer(s) error recovery.
  * @reconnect_delay: Time between two consecutive reconnect attempts.
  * @discovery_nqn: indicates if the subsysnqn is the well-known discovery NQN.
+ * @kato:	Keep-alive timeout.
  * @host:	Virtual NVMe host, contains the NQN and Host ID.
  */
 struct nvmf_ctrl_options {
@@ -85,6 +87,7 @@ struct nvmf_ctrl_options {
 	unsigned short		tl_retry_count;
 	unsigned int		reconnect_delay;
 	bool			discovery_nqn;
+	unsigned int		kato;
 	struct nvmf_host	*host;
 };
 

commit 07bfcd09a288551b4377836a11c6250e1fd01e6d
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jun 13 16:45:26 2016 +0200

    nvme-fabrics: add a generic NVMe over Fabrics library
    
    The NVMe over Fabrics library provides an interface for both transports
    and the nvme core to handle fabrics specific commands and attributes
    independent of the underlying transport.
    
    In addition, the fabrics library adds a misc device interface that allow
    actually creating a fabrics controller, as we can't just autodiscover
    it like in the PCI case.  The nvme-cli utility has been enhanced to use
    this interface to support fabric connect and discovery.
    
    Signed-off-by: Armen Baloyan <armenx.baloyan@intel.com>,
    Signed-off-by: Jay Freyensee <james.p.freyensee@intel.com>,
    Signed-off-by: Ming Lin <ming.l@ssi.samsung.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Keith Busch <keith.busch@intel.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/nvme/host/fabrics.h b/drivers/nvme/host/fabrics.h
new file mode 100644
index 000000000000..120383088bc1
--- /dev/null
+++ b/drivers/nvme/host/fabrics.h
@@ -0,0 +1,132 @@
+/*
+ * NVMe over Fabrics common host code.
+ * Copyright (c) 2015-2016 HGST, a Western Digital Company.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ */
+#ifndef _NVME_FABRICS_H
+#define _NVME_FABRICS_H 1
+
+#include <linux/in.h>
+#include <linux/inet.h>
+
+#define NVMF_MIN_QUEUE_SIZE	16
+#define NVMF_MAX_QUEUE_SIZE	1024
+#define NVMF_DEF_QUEUE_SIZE	128
+#define NVMF_DEF_RECONNECT_DELAY	10
+
+/*
+ * Define a host as seen by the target.  We allocate one at boot, but also
+ * allow the override it when creating controllers.  This is both to provide
+ * persistence of the Host NQN over multiple boots, and to allow using
+ * multiple ones, for example in a container scenario.  Because we must not
+ * use different Host NQNs with the same Host ID we generate a Host ID and
+ * use this structure to keep track of the relation between the two.
+ */
+struct nvmf_host {
+	struct kref		ref;
+	struct list_head	list;
+	char			nqn[NVMF_NQN_SIZE];
+	uuid_le			id;
+};
+
+/**
+ * enum nvmf_parsing_opts - used to define the sysfs parsing options used.
+ */
+enum {
+	NVMF_OPT_ERR		= 0,
+	NVMF_OPT_TRANSPORT	= 1 << 0,
+	NVMF_OPT_NQN		= 1 << 1,
+	NVMF_OPT_TRADDR		= 1 << 2,
+	NVMF_OPT_TRSVCID	= 1 << 3,
+	NVMF_OPT_QUEUE_SIZE	= 1 << 4,
+	NVMF_OPT_NR_IO_QUEUES	= 1 << 5,
+	NVMF_OPT_TL_RETRY_COUNT	= 1 << 6,
+	NVMF_OPT_HOSTNQN	= 1 << 8,
+	NVMF_OPT_RECONNECT_DELAY = 1 << 9,
+};
+
+/**
+ * struct nvmf_ctrl_options - Used to hold the options specified
+ *			      with the parsing opts enum.
+ * @mask:	Used by the fabrics library to parse through sysfs options
+ *		on adding a NVMe controller.
+ * @transport:	Holds the fabric transport "technology name" (for a lack of
+ *		better description) that will be used by an NVMe controller
+ *		being added.
+ * @subsysnqn:	Hold the fully qualified NQN subystem name (format defined
+ *		in the NVMe specification, "NVMe Qualified Names").
+ * @traddr:	network address that will be used by the host to communicate
+ *		to the added NVMe controller.
+ * @trsvcid:	network port used for host-controller communication.
+ * @queue_size: Number of IO queue elements.
+ * @nr_io_queues: Number of controller IO queues that will be established.
+ * @tl_retry_count: Number of transport layer retries for a fabric queue before
+ *		     kicking upper layer(s) error recovery.
+ * @reconnect_delay: Time between two consecutive reconnect attempts.
+ * @discovery_nqn: indicates if the subsysnqn is the well-known discovery NQN.
+ * @host:	Virtual NVMe host, contains the NQN and Host ID.
+ */
+struct nvmf_ctrl_options {
+	unsigned		mask;
+	char			*transport;
+	char			*subsysnqn;
+	char			*traddr;
+	char			*trsvcid;
+	size_t			queue_size;
+	unsigned int		nr_io_queues;
+	unsigned short		tl_retry_count;
+	unsigned int		reconnect_delay;
+	bool			discovery_nqn;
+	struct nvmf_host	*host;
+};
+
+/*
+ * struct nvmf_transport_ops - used to register a specific
+ *			       fabric implementation of NVMe fabrics.
+ * @entry:		Used by the fabrics library to add the new
+ *			registration entry to its linked-list internal tree.
+ * @name:		Name of the NVMe fabric driver implementation.
+ * @required_opts:	sysfs command-line options that must be specified
+ *			when adding a new NVMe controller.
+ * @allowed_opts:	sysfs command-line options that can be specified
+ *			when adding a new NVMe controller.
+ * @create_ctrl():	function pointer that points to a non-NVMe
+ *			implementation-specific fabric technology
+ *			that would go into starting up that fabric
+ *			for the purpose of conneciton to an NVMe controller
+ *			using that fabric technology.
+ *
+ * Notes:
+ *	1. At minimum, 'required_opts' and 'allowed_opts' should
+ *	   be set to the same enum parsing options defined earlier.
+ *	2. create_ctrl() must be defined (even if it does nothing)
+ */
+struct nvmf_transport_ops {
+	struct list_head	entry;
+	const char		*name;
+	int			required_opts;
+	int			allowed_opts;
+	struct nvme_ctrl	*(*create_ctrl)(struct device *dev,
+					struct nvmf_ctrl_options *opts);
+};
+
+int nvmf_reg_read32(struct nvme_ctrl *ctrl, u32 off, u32 *val);
+int nvmf_reg_read64(struct nvme_ctrl *ctrl, u32 off, u64 *val);
+int nvmf_reg_write32(struct nvme_ctrl *ctrl, u32 off, u32 val);
+int nvmf_connect_admin_queue(struct nvme_ctrl *ctrl);
+int nvmf_connect_io_queue(struct nvme_ctrl *ctrl, u16 qid);
+void nvmf_register_transport(struct nvmf_transport_ops *ops);
+void nvmf_unregister_transport(struct nvmf_transport_ops *ops);
+void nvmf_free_options(struct nvmf_ctrl_options *opts);
+const char *nvmf_get_subsysnqn(struct nvme_ctrl *ctrl);
+int nvmf_get_address(struct nvme_ctrl *ctrl, char *buf, int size);
+
+#endif /* _NVME_FABRICS_H */
