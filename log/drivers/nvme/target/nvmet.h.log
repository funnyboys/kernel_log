commit c6e3f13398123a008cd2ee28f93510b113a32791
Author: Israel Rukshin <israelr@mellanox.com>
Date:   Tue May 19 17:06:02 2020 +0300

    nvmet: add metadata support for block devices
    
    Allocate the metadata SGL buffers and set metadata fields for the
    request. Then create a block IO request for the metadata from the
    protection SG list.
    
    Signed-off-by: Israel Rukshin <israelr@mellanox.com>
    Signed-off-by: Max Gurtovoy <maxg@mellanox.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 46b5d2b4ca0a..809691291e73 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -309,6 +309,7 @@ struct nvmet_req {
 	struct nvmet_cq		*cq;
 	struct nvmet_ns		*ns;
 	struct scatterlist	*sg;
+	struct scatterlist	*metadata_sg;
 	struct bio_vec		inline_bvec[NVMET_MAX_INLINE_BIOVEC];
 	union {
 		struct {
@@ -322,8 +323,10 @@ struct nvmet_req {
 		} f;
 	};
 	int			sg_cnt;
+	int			metadata_sg_cnt;
 	/* data length as parsed from the SGL descriptor: */
 	size_t			transfer_len;
+	size_t			metadata_len;
 
 	struct nvmet_port	*port;
 
@@ -394,8 +397,8 @@ void nvmet_req_uninit(struct nvmet_req *req);
 bool nvmet_check_transfer_len(struct nvmet_req *req, size_t len);
 bool nvmet_check_data_len_lte(struct nvmet_req *req, size_t data_len);
 void nvmet_req_complete(struct nvmet_req *req, u16 status);
-int nvmet_req_alloc_sgl(struct nvmet_req *req);
-void nvmet_req_free_sgl(struct nvmet_req *req);
+int nvmet_req_alloc_sgls(struct nvmet_req *req);
+void nvmet_req_free_sgls(struct nvmet_req *req);
 
 void nvmet_execute_keep_alive(struct nvmet_req *req);
 

commit ea52ac1c6605fbd25347fabf46233e260dd92eb2
Author: Israel Rukshin <israelr@mellanox.com>
Date:   Tue May 19 17:06:01 2020 +0300

    nvmet: add metadata/T10-PI support
    
    Expose the namespace metadata format when PI is enabled. The user needs
    to enable the capability per subsystem and per port. The other metadata
    properties are taken from the namespace/bdev.
    
    Usage example:
    echo 1 > /config/nvmet/subsystems/${NAME}/attr_pi_enable
    echo 1 > /config/nvmet/ports/${PORT_NUM}/param_pi_enable
    
    Signed-off-by: Israel Rukshin <israelr@mellanox.com>
    Signed-off-by: Max Gurtovoy <maxg@mellanox.com>
    Reviewed-by: James Smart <james.smart@broadcom.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 29ab0b96bd32..46b5d2b4ca0a 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -145,6 +145,7 @@ struct nvmet_port {
 	bool				enabled;
 	int				inline_data_size;
 	const struct nvmet_fabrics_ops	*tr_ops;
+	bool				pi_enable;
 };
 
 static inline struct nvmet_port *to_nvmet_port(struct config_item *item)
@@ -204,6 +205,7 @@ struct nvmet_ctrl {
 	spinlock_t		error_lock;
 	u64			err_counter;
 	struct nvme_error_slot	slots[NVMET_ERROR_LOG_SLOTS];
+	bool			pi_support;
 };
 
 struct nvmet_subsys_model {
@@ -233,6 +235,7 @@ struct nvmet_subsys {
 	u64			ver;
 	u64			serial;
 	char			*subsysnqn;
+	bool			pi_support;
 
 	struct config_group	group;
 
@@ -284,6 +287,7 @@ struct nvmet_fabrics_ops {
 	unsigned int type;
 	unsigned int msdbd;
 	bool has_keyed_sgls : 1;
+	bool metadata_support : 1;
 	void (*queue_response)(struct nvmet_req *req);
 	int (*add_port)(struct nvmet_port *port);
 	void (*remove_port)(struct nvmet_port *port);
@@ -511,6 +515,14 @@ static inline u32 nvmet_rw_data_len(struct nvmet_req *req)
 			req->ns->blksize_shift;
 }
 
+static inline u32 nvmet_rw_metadata_len(struct nvmet_req *req)
+{
+	if (!IS_ENABLED(CONFIG_BLK_DEV_INTEGRITY))
+		return 0;
+	return ((u32)le16_to_cpu(req->cmd->rw.length) + 1) *
+			req->ns->metadata_size;
+}
+
 static inline u32 nvmet_dsm_len(struct nvmet_req *req)
 {
 	return (le32_to_cpu(req->cmd->dsm.nr) + 1) *
@@ -525,4 +537,11 @@ static inline __le16 to0based(u32 a)
 	return cpu_to_le16(max(1U, min(1U << 16, a)) - 1);
 }
 
+static inline bool nvmet_ns_has_pi(struct nvmet_ns *ns)
+{
+	if (!IS_ENABLED(CONFIG_BLK_DEV_INTEGRITY))
+		return false;
+	return ns->pi_type && ns->metadata_size == sizeof(struct t10_pi_tuple);
+}
+
 #endif /* _NVMET_H */

commit 136cc1ffcf0a3309c59d844cb1a4ddad964ea3d8
Author: Israel Rukshin <israelr@mellanox.com>
Date:   Tue May 19 17:05:59 2020 +0300

    nvmet: rename nvmet_check_data_len to nvmet_check_transfer_len
    
    The function doesn't check only the data length, because the transfer
    length includes also the metadata length in some cases. This is
    preparation for adding metadata (T10-PI) support.
    
    Signed-off-by: Israel Rukshin <israelr@mellanox.com>
    Signed-off-by: Max Gurtovoy <maxg@mellanox.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: James Smart <james.smart@broadcom.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 8bed8a61345e..29ab0b96bd32 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -387,7 +387,7 @@ u16 nvmet_parse_fabrics_cmd(struct nvmet_req *req);
 bool nvmet_req_init(struct nvmet_req *req, struct nvmet_cq *cq,
 		struct nvmet_sq *sq, const struct nvmet_fabrics_ops *ops);
 void nvmet_req_uninit(struct nvmet_req *req);
-bool nvmet_check_data_len(struct nvmet_req *req, size_t data_len);
+bool nvmet_check_transfer_len(struct nvmet_req *req, size_t len);
 bool nvmet_check_data_len_lte(struct nvmet_req *req, size_t data_len);
 void nvmet_req_complete(struct nvmet_req *req, u16 status);
 int nvmet_req_alloc_sgl(struct nvmet_req *req);

commit 26af180c1bd9cdd6f9b96d8df58b51d5900a2978
Author: Israel Rukshin <israelr@mellanox.com>
Date:   Tue May 19 17:05:58 2020 +0300

    nvmet: rename nvmet_rw_len to nvmet_rw_data_len
    
    The function doesn't add the metadata length (only data length is
    calculated). This is preparation for adding metadata (T10-PI) support.
    
    Signed-off-by: Israel Rukshin <israelr@mellanox.com>
    Reviewed-by: Max Gurtovoy <maxg@mellanox.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: James Smart <james.smart@broadcom.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index daef06a3aff4..8bed8a61345e 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -505,7 +505,7 @@ void nvmet_bdev_ns_revalidate(struct nvmet_ns *ns);
 int nvmet_file_ns_revalidate(struct nvmet_ns *ns);
 void nvmet_ns_revalidate(struct nvmet_ns *ns);
 
-static inline u32 nvmet_rw_len(struct nvmet_req *req)
+static inline u32 nvmet_rw_data_len(struct nvmet_req *req)
 {
 	return ((u32)le16_to_cpu(req->cmd->rw.length) + 1) <<
 			req->ns->blksize_shift;

commit d2d1c454a4a44010cac627fd63945ff5e7dd3b4c
Author: Israel Rukshin <israelr@mellanox.com>
Date:   Tue May 19 17:05:57 2020 +0300

    nvmet: add metadata characteristics for a namespace
    
    Fill those namespace fields from the block device format for adding
    metadata (T10-PI) over fabric support with block devices.
    
    Signed-off-by: Israel Rukshin <israelr@mellanox.com>
    Signed-off-by: Max Gurtovoy <maxg@mellanox.com>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 93e0c2aa3e71..daef06a3aff4 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -19,6 +19,7 @@
 #include <linux/rcupdate.h>
 #include <linux/blkdev.h>
 #include <linux/radix-tree.h>
+#include <linux/t10-pi.h>
 
 #define NVMET_ASYNC_EVENTS		4
 #define NVMET_ERROR_LOG_SLOTS		128
@@ -77,6 +78,8 @@ struct nvmet_ns {
 
 	int			use_p2pmem;
 	struct pci_dev		*p2p_dev;
+	int			pi_type;
+	int			metadata_size;
 };
 
 static inline struct nvmet_ns *to_nvmet_ns(struct config_item *item)

commit 463c5fabb8dfca4941c4c50365bb7749ac5c9916
Author: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
Date:   Tue May 19 01:06:27 2020 -0700

    nvmet: add helper to revalidate bdev and file ns
    
    This patch adds a wrapper helper to indicate size change in the bdev &
    file-backed namespace when revalidating ns. This helper is needed in
    order to minimize code repetition in the next patch for configfs.c and
    existing admin-cmd.c. Â 
    
    Signed-off-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Reviewed-by: Sagi Grimberg <sagi@grimbeg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 3d981eb6e100..93e0c2aa3e71 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -500,6 +500,7 @@ u16 nvmet_file_flush(struct nvmet_req *req);
 void nvmet_ns_changed(struct nvmet_subsys *subsys, u32 nsid);
 void nvmet_bdev_ns_revalidate(struct nvmet_ns *ns);
 int nvmet_file_ns_revalidate(struct nvmet_ns *ns);
+void nvmet_ns_revalidate(struct nvmet_ns *ns);
 
 static inline u32 nvmet_rw_len(struct nvmet_req *req)
 {

commit e8cd1ff11d58a21242ea2b85450298f3681768a1
Author: Anthony Iliopoulos <ailiop@suse.com>
Date:   Sun Apr 19 16:48:50 2020 -0700

    nvmet: add ns revalidation support
    
    Add support for detecting capacity changes on nvmet blockdev and file
    backed namespaces. This allows for emulating and testing online resizing
    of nvme devices and filesystems on top.
    
    Signed-off-by: Anthony Iliopoulos <ailiop@suse.com>
    [chaitanya: Fix comments posted on V1]
    Signed-off-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    [hch: reuse code a bit more]
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 421dff3ea143..3d981eb6e100 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -498,6 +498,8 @@ void nvmet_file_ns_disable(struct nvmet_ns *ns);
 u16 nvmet_bdev_flush(struct nvmet_req *req);
 u16 nvmet_file_flush(struct nvmet_req *req);
 void nvmet_ns_changed(struct nvmet_subsys *subsys, u32 nsid);
+void nvmet_bdev_ns_revalidate(struct nvmet_ns *ns);
+int nvmet_file_ns_revalidate(struct nvmet_ns *ns);
 
 static inline u32 nvmet_rw_len(struct nvmet_req *req)
 {

commit 02cb00e233ade7c050e0f476902e63847e78114e
Author: Max Gurtovoy <maxg@mellanox.com>
Date:   Sun Mar 8 12:55:03 2020 +0200

    nvmet: Add get_mdts op for controllers
    
    Some transports, such as RDMA, would like to set the Maximum Data
    Transfer Size (MDTS) according to device/port/ctrl characteristics.
    This will enable the transport to set the optimal MDTS according to
    controller needs and device capabilities. Add a new nvmet transport
    op that is called during ctrl identification. This will not effect
    transports that don't implement this option. The return value of the new
    op is according to the NVMe spec definition for MDTS.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Max Gurtovoy <maxg@mellanox.com>
    Signed-off-by: Israel Rukshin <israelr@mellanox.com>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 42ba2ddd9e96..421dff3ea143 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -289,6 +289,7 @@ struct nvmet_fabrics_ops {
 			struct nvmet_port *port, char *traddr);
 	u16 (*install_queue)(struct nvmet_sq *nvme_sq);
 	void (*discovery_chg)(struct nvmet_port *port);
+	u8 (*get_mdts)(const struct nvmet_ctrl *ctrl);
 };
 
 #define NVMET_MAX_INLINE_BIOVEC	8

commit 013b7ebe5a0d70e2a02fd225174595e79c591b3e
Author: Mark Ruijter <MRuijter@onestopsystems.com>
Date:   Thu Jan 30 10:29:32 2020 -0800

    nvmet: make ctrl model configurable
    
    This patch adds a new target subsys attribute which allows user to
    optionally specify model name which then used in the
    nvmet_execute_identify_ctrl() to fill up the nvme_id_ctrl structure.
    
    The default value for the model is set to "Linux" for backward
    compatibility.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Mark Ruijter <MRuijter@onestopsystems.com>
    [chaitanya.kulkarni@wdc.com
     *Use macro for default model, coding style fixes.
     *Use RCU for accessing model in for configfs and in
      nvmet_execute_identify_ctrl().
    ]
    Signed-off-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Signed-off-by: Keith Busch <kbusch@kernel.org>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index c2d518fb1789..42ba2ddd9e96 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -23,6 +23,7 @@
 #define NVMET_ASYNC_EVENTS		4
 #define NVMET_ERROR_LOG_SLOTS		128
 #define NVMET_NO_ERROR_LOC		((u16)-1)
+#define NVMET_DEFAULT_CTRL_MODEL	"Linux"
 
 /*
  * Supported optional AENs:
@@ -202,6 +203,11 @@ struct nvmet_ctrl {
 	struct nvme_error_slot	slots[NVMET_ERROR_LOG_SLOTS];
 };
 
+struct nvmet_subsys_model {
+	struct rcu_head		rcuhead;
+	char			number[];
+};
+
 struct nvmet_subsys {
 	enum nvme_subsys_type	type;
 
@@ -229,6 +235,8 @@ struct nvmet_subsys {
 
 	struct config_group	namespaces_group;
 	struct config_group	allowed_hosts_group;
+
+	struct nvmet_subsys_model	__rcu *model;
 };
 
 static inline struct nvmet_subsys *to_subsys(struct config_item *item)

commit 94a39d61f80fcd679debda11e1ca02b88d90e67e
Author: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
Date:   Thu Jan 30 10:29:31 2020 -0800

    nvmet: make ctrl-id configurable
    
    This patch adds a new target subsys attribute which allows user to
    optionally specify target controller IDs which then used in the
    nvmet_execute_identify_ctrl() to fill up the nvme_id_ctrl structure.
    
    For example, when using a cluster setup with two nodes, with a dual
    ported NVMe drive and exporting the drive from both the nodes,
    The connection to the host fails due to the same controller ID and
    results in the following error message:-
    
    "nvme nvmeX: Duplicate cntlid XXX with nvmeX, rejecting"
    
    With this patch now user can partition the controller IDs for each
    subsystem by setting up the cntlid_min and cntlid_max. These values
    will be used at the time of the controller ID creation. By partitioning
    the ctrl-ids for each subsystem results in the unique ctrl-id space
    which avoids the collision.
    
    When new attribute is not specified target will fall back to original
    cntlid calculation method.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Signed-off-by: Keith Busch <kbusch@kernel.org>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index eda28b22a2c8..c2d518fb1789 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -211,6 +211,8 @@ struct nvmet_subsys {
 	struct list_head	namespaces;
 	unsigned int		nr_namespaces;
 	unsigned int		max_nsid;
+	u16			cntlid_min;
+	u16			cntlid_max;
 
 	struct list_head	ctrls;
 

commit b716e6889c95f64ba32af492461f6cc9341f3f05
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Sun Jan 26 23:23:28 2020 -0800

    nvmet: fix dsm failure when payload does not match sgl descriptor
    
    The host is allowed to pass the controller an sgl describing a buffer
    that is larger than the dsm payload itself, allow it when executing
    dsm.
    
    Reported-by: Dakshaja Uppalapati <dakshaja@chelsio.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>,
    Reviewed-by: Max Gurtovoy <maxg@mellanox.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Keith Busch <kbusch@kernel.org>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 46df45e837c9..eda28b22a2c8 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -374,6 +374,7 @@ bool nvmet_req_init(struct nvmet_req *req, struct nvmet_cq *cq,
 		struct nvmet_sq *sq, const struct nvmet_fabrics_ops *ops);
 void nvmet_req_uninit(struct nvmet_req *req);
 bool nvmet_check_data_len(struct nvmet_req *req, size_t data_len);
+bool nvmet_check_data_len_lte(struct nvmet_req *req, size_t data_len);
 void nvmet_req_complete(struct nvmet_req *req, u16 status);
 int nvmet_req_alloc_sgl(struct nvmet_req *req);
 void nvmet_req_free_sgl(struct nvmet_req *req);

commit be3f3114ddd58d12f64b872247bb1bc46df56b36
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Oct 23 10:35:45 2019 -0600

    nvmet: Open code nvmet_req_execute()
    
    Now that nvmet_req_execute does nothing, open code it.
    
    Reviewed-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    [split patch, update changelog]
    Signed-off-by: Logan Gunthorpe <logang@deltatee.com>
    Signed-off-by: Keith Busch <kbusch@kernel.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index ff55f1005b35..46df45e837c9 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -374,7 +374,6 @@ bool nvmet_req_init(struct nvmet_req *req, struct nvmet_cq *cq,
 		struct nvmet_sq *sq, const struct nvmet_fabrics_ops *ops);
 void nvmet_req_uninit(struct nvmet_req *req);
 bool nvmet_check_data_len(struct nvmet_req *req, size_t data_len);
-void nvmet_req_execute(struct nvmet_req *req);
 void nvmet_req_complete(struct nvmet_req *req, u16 status);
 int nvmet_req_alloc_sgl(struct nvmet_req *req);
 void nvmet_req_free_sgl(struct nvmet_req *req);

commit e9061c397839eea34207668bfedce0a6c18c5015
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Oct 23 10:35:44 2019 -0600

    nvmet: Remove the data_len field from the nvmet_req struct
    
    Instead of storing the expected length and checking it when it's
    executed, just check the length inside the command themselves.
    
    A new helper, nvmet_check_data_len() is created to help with this
    check.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    [split patch, udpate changelog]
    Signed-off-by: Logan Gunthorpe <logang@deltatee.com>
    Signed-off-by: Keith Busch <kbusch@kernel.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 6ccf2d098d9f..ff55f1005b35 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -304,8 +304,6 @@ struct nvmet_req {
 		} f;
 	};
 	int			sg_cnt;
-	/* data length as parsed from the command: */
-	size_t			data_len;
 	/* data length as parsed from the SGL descriptor: */
 	size_t			transfer_len;
 
@@ -375,6 +373,7 @@ u16 nvmet_parse_fabrics_cmd(struct nvmet_req *req);
 bool nvmet_req_init(struct nvmet_req *req, struct nvmet_cq *cq,
 		struct nvmet_sq *sq, const struct nvmet_fabrics_ops *ops);
 void nvmet_req_uninit(struct nvmet_req *req);
+bool nvmet_check_data_len(struct nvmet_req *req, size_t data_len);
 void nvmet_req_execute(struct nvmet_req *req);
 void nvmet_req_complete(struct nvmet_req *req, u16 status);
 int nvmet_req_alloc_sgl(struct nvmet_req *req);

commit 59ef0eaa7741c3543f98220cc132c61bf0230bce
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Oct 23 10:35:43 2019 -0600

    nvmet: Introduce nvmet_dsm_len() helper
    
    Similar to the nvmet_rw_len helper.
    
    Reviewed-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    [split patch, update changelog]
    Signed-off-by: Logan Gunthorpe <logang@deltatee.com>
    Signed-off-by: Keith Busch <kbusch@kernel.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index c51f8dd01dc4..6ccf2d098d9f 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -495,6 +495,12 @@ static inline u32 nvmet_rw_len(struct nvmet_req *req)
 			req->ns->blksize_shift;
 }
 
+static inline u32 nvmet_dsm_len(struct nvmet_req *req)
+{
+	return (le32_to_cpu(req->cmd->dsm.nr) + 1) *
+		sizeof(struct nvme_dsm_range);
+}
+
 u16 errno_to_nvme_status(struct nvmet_req *req, int errno);
 
 /* Convert a 32-bit number to a 16-bit 0's based number */

commit 3aed86731ee2b23e4dc4d2c6d943d33992cd551b
Author: Logan Gunthorpe <logang@deltatee.com>
Date:   Wed Jul 31 17:35:31 2019 -0600

    nvmet: Fix use-after-free bug when a port is removed
    
    When a port is removed through configfs, any connected controllers
    are still active and can still send commands. This causes a
    use-after-free bug which is detected by KASAN for any admin command
    that dereferences req->port (like in nvmet_execute_identify_ctrl).
    
    To fix this, disconnect all active controllers when a subsystem is
    removed from a port. This ensures there are no active controllers
    when the port is eventually removed.
    
    Signed-off-by: Logan Gunthorpe <logang@deltatee.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Max Gurtovoy <maxg@mellanox.com>
    Reviewed-by : Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 6ee66c610739..c51f8dd01dc4 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -418,6 +418,9 @@ void nvmet_port_send_ana_event(struct nvmet_port *port);
 int nvmet_register_transport(const struct nvmet_fabrics_ops *ops);
 void nvmet_unregister_transport(const struct nvmet_fabrics_ops *ops);
 
+void nvmet_port_del_ctrls(struct nvmet_port *port,
+			  struct nvmet_subsys *subsys);
+
 int nvmet_enable_port(struct nvmet_port *port);
 void nvmet_disable_port(struct nvmet_port *port);
 

commit 9d05a96e298aadb36e3ec971fab8d416e6fb7331
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Fri Jun 28 09:53:30 2019 -0700

    nvmet: export I/O characteristics attributes in Identify
    
    Make the NVMe NAWUN, NAWUPF, NACWU, NPWG, NPWA, NPDG and NOWS attributes
    available to initator systems for the block backend.
    
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index dc270944bb25..6ee66c610739 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -365,6 +365,7 @@ u16 nvmet_set_feat_async_event(struct nvmet_req *req, u32 mask);
 void nvmet_execute_async_event(struct nvmet_req *req);
 
 u16 nvmet_parse_connect_cmd(struct nvmet_req *req);
+void nvmet_bdev_set_limits(struct block_device *bdev, struct nvme_id_ns *id);
 u16 nvmet_bdev_parse_io_cmd(struct nvmet_req *req);
 u16 nvmet_file_parse_io_cmd(struct nvmet_req *req);
 u16 nvmet_parse_admin_cmd(struct nvmet_req *req);
@@ -492,4 +493,11 @@ static inline u32 nvmet_rw_len(struct nvmet_req *req)
 }
 
 u16 errno_to_nvme_status(struct nvmet_req *req, int errno);
+
+/* Convert a 32-bit number to a 16-bit 0's based number */
+static inline __le16 to0based(u32 a)
+{
+	return cpu_to_le16(max(1U, min(1U << 16, a)) - 1);
+}
+
 #endif /* _NVMET_H */

commit 9d09dd8d7626b9124ce4bc081aabcb0590173b27
Author: James Smart <jsmart2021@gmail.com>
Date:   Tue May 14 14:58:02 2019 -0700

    nvmet: add transport discovery change op
    
    Some transports, such as FC-NVME, support discovery controller change
    events without the use of a persistent discovery controller. FC receives
    events via RSCN from the FC Fabric Controller or subsystem FC port.
    
    This patch adds a nvmet transport op that is called whenever a
    discovery change event occurs in the nvmet layer.
    
    To facilitate the callback without adding another layer to cross into
    core.c to reference the transport ops, the port structure snapshots
    the transport ops when the port is enabled and clears them when disabled.
    
    Signed-off-by: James Smart <jsmart2021@gmail.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Arun Easi <aeasi@marvell.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index c25d88fc9dec..dc270944bb25 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -140,6 +140,7 @@ struct nvmet_port {
 	void				*priv;
 	bool				enabled;
 	int				inline_data_size;
+	const struct nvmet_fabrics_ops	*tr_ops;
 };
 
 static inline struct nvmet_port *to_nvmet_port(struct config_item *item)
@@ -277,6 +278,7 @@ struct nvmet_fabrics_ops {
 	void (*disc_traddr)(struct nvmet_req *req,
 			struct nvmet_port *port, char *traddr);
 	u16 (*install_queue)(struct nvmet_sq *nvme_sq);
+	void (*discovery_chg)(struct nvmet_port *port);
 };
 
 #define NVMET_MAX_INLINE_BIOVEC	8

commit fc6c9730725d5cc57c851d0e261a5682bba913a7
Author: Max Gurtovoy <maxg@mellanox.com>
Date:   Mon Apr 8 18:39:59 2019 +0300

    nvmet: rename nvme_completion instances from rsp to cqe
    
    Use NVMe namings for improving code readability.
    
    Signed-off-by: Max Gurtovoy <maxg@mellanox.com>
    Reviewed-by : Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 1653d19b187f..c25d88fc9dec 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -284,7 +284,7 @@ struct nvmet_fabrics_ops {
 
 struct nvmet_req {
 	struct nvme_command	*cmd;
-	struct nvme_completion	*rsp;
+	struct nvme_completion	*cqe;
 	struct nvmet_sq		*sq;
 	struct nvmet_cq		*cq;
 	struct nvmet_ns		*ns;
@@ -322,7 +322,7 @@ extern struct workqueue_struct *buffered_io_wq;
 
 static inline void nvmet_set_result(struct nvmet_req *req, u32 result)
 {
-	req->rsp->result.u32 = cpu_to_le32(result);
+	req->cqe->result.u32 = cpu_to_le32(result);
 }
 
 /*

commit d808b7f759b50acf0784ce6230ffa63e12ef465d
Author: Keith Busch <keith.busch@intel.com>
Date:   Tue Apr 9 10:03:59 2019 -0600

    nvmet: fix discover log page when offsets are used
    
    The nvme target hadn't been taking the Get Log Page offset parameter
    into consideration, and so has been returning corrupted log pages when
    offsets are used. Since many tools, including nvme-cli, split the log
    request to 4k, we've been breaking discovery log responses when more
    than 3 subsystems exist.
    
    Fix the returned data by internally generating the entire discovery
    log page and copying only the requested bytes into the user buffer. The
    command log page offset type has been modified to a native __le64 to
    make it easier to extract the value from a command.
    
    Signed-off-by: Keith Busch <keith.busch@intel.com>
    Tested-by: Minwoo Im <minwoo.im@samsung.com>
    Reviewed-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: James Smart <james.smart@broadcom.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 51e49efd7849..1653d19b187f 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -428,6 +428,7 @@ u16 nvmet_copy_from_sgl(struct nvmet_req *req, off_t off, void *buf,
 u16 nvmet_zero_sgl(struct nvmet_req *req, off_t off, size_t len);
 
 u32 nvmet_get_log_page_len(struct nvme_command *cmd);
+u64 nvmet_get_log_page_offset(struct nvme_command *cmd);
 
 extern struct list_head *nvmet_ports;
 void nvmet_port_disc_changed(struct nvmet_port *port,

commit 77141dc6ceffdbf4dd3470911c838309e23cd55c
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Feb 18 11:36:11 2019 +0100

    nvmet: convert to SPDX identifiers
    
    Update license to use SPDX-License-Identifier instead of verbose license
    text.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 3e4719fdba85..51e49efd7849 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -1,14 +1,6 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * Copyright (c) 2015-2016 HGST, a Western Digital Company.
- *
- * This program is free software; you can redistribute it and/or modify it
- * under the terms and conditions of the GNU General Public License,
- * version 2, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
- * more details.
  */
 
 #ifndef _NVMET_H

commit 5698b805fbf09a5dfa60829f5a179c0568a8dc3b
Author: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
Date:   Mon Dec 17 18:35:29 2018 -0800

    nvmet: use a macro for default error location
    
    This patch defines a new macro NVMET_NO_ERROR_LOC to represent the
    default error location value in the nvme-error-log-page.
    This is a pure cleanup patch and it does not change any functionality.
    
    Signed-off-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 3b5f0bcaf3e8..3e4719fdba85 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -30,6 +30,7 @@
 
 #define NVMET_ASYNC_EVENTS		4
 #define NVMET_ERROR_LOG_SLOTS		128
+#define NVMET_NO_ERROR_LOC		((u16)-1)
 
 /*
  * Supported optional AENs:

commit c6aa3542e01026a94d24713ee2c0dce517e9b6de
Author: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
Date:   Wed Dec 12 15:11:43 2018 -0800

    nvmet: add error log support for file backend
    
    This patch adds support for the file backend to populate the
    error log entries. Here we map the errno to the NVMe status codes.
    
    Signed-off-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index a2a7fd69b66a..3b5f0bcaf3e8 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -494,4 +494,6 @@ static inline u32 nvmet_rw_len(struct nvmet_req *req)
 	return ((u32)le16_to_cpu(req->cmd->rw.length) + 1) <<
 			req->ns->blksize_shift;
 }
+
+u16 errno_to_nvme_status(struct nvmet_req *req, int errno);
 #endif /* _NVMET_H */

commit 76574f37bf4caa7150ea1559cd98e3017b9752d2
Author: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
Date:   Wed Dec 12 15:11:40 2018 -0800

    nvmet: add interface to update error-log page
    
    This patch adds nvmet_req based interface to the nvmet-core so that
    we can update the error log page. We update error log page in
    the request completion path when status is not set to NVME_SC_SUCCESS.
    
    Signed-off-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 61b3cc415905..a2a7fd69b66a 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -327,11 +327,6 @@ struct nvmet_req {
 
 extern struct workqueue_struct *buffered_io_wq;
 
-static inline void nvmet_set_status(struct nvmet_req *req, u16 status)
-{
-	req->rsp->status = cpu_to_le16(status << 1);
-}
-
 static inline void nvmet_set_result(struct nvmet_req *req, u32 result)
 {
 	req->rsp->result.u32 = cpu_to_le32(result);

commit e4a976254ec5ebdcdb3e1e1b40e795b3db6b6dab
Author: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
Date:   Wed Dec 12 15:11:39 2018 -0800

    nvmet: add error-log definitions
    
    This patch adds necessary fields in the target data structures to
    support error log page. For a target controller, we add a new error log
    field to maintain the error log, at any given point we maintain error
    entries equal to NVMET_ERROR_LOG_SLOTS for each controller. In the
    following patch, we also update the error log page entry in the I/O
    completion path so we introduce a spinlock for synchronization of the
    log.
    
    For nvmet_req, we add a new field error_loc to hold the location of
    the error in the command when the actual error occurs for each request
    and a starting LBA if applicable.
    
    Signed-off-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index dafee1af4829..61b3cc415905 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -202,6 +202,10 @@ struct nvmet_ctrl {
 
 	struct device		*p2p_client;
 	struct radix_tree_root	p2p_ns_map;
+
+	spinlock_t		error_lock;
+	u64			err_counter;
+	struct nvme_error_slot	slots[NVMET_ERROR_LOG_SLOTS];
 };
 
 struct nvmet_subsys {
@@ -317,6 +321,8 @@ struct nvmet_req {
 
 	struct pci_dev		*p2p_dev;
 	struct device		*p2p_client;
+	u16			error_loc;
+	u64			error_slba;
 };
 
 extern struct workqueue_struct *buffered_io_wq;

commit b7c8f3663d0e0773aca3324c26bce3ca8343ec14
Author: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
Date:   Wed Dec 12 15:11:37 2018 -0800

    nvme: remove nvme_common command cdw10 array
    
    This is a preparation patch which removes the nvme common command cdw10
    array and replace with individual fields. This is needed for the nvmet
    error log page implementation make is error log page entry offset
    assignment easier.
    
    Signed-off-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 89df51ee5bdf..dafee1af4829 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -349,7 +349,7 @@ struct nvmet_async_event {
 
 static inline void nvmet_clear_aen_bit(struct nvmet_req *req, u32 bn)
 {
-	int rae = le32_to_cpu(req->cmd->common.cdw10[0]) & 1 << 15;
+	int rae = le32_to_cpu(req->cmd->common.cdw10) & 1 << 15;
 
 	if (!rae)
 		clear_bit(bn, &req->sq->ctrl->aen_masked);

commit 1672ddb8d691e4433806373ec4104f37a86efab0
Author: Sagi Grimberg <sagi@lightbitslabs.com>
Date:   Mon Dec 3 17:52:11 2018 -0800

    nvmet: Add install_queue callout
    
    nvmet-tcp will implement it to allocate queue commands which
    are only known at nvmf connect time (sq size).
    
    Signed-off-by: Sagi Grimberg <sagi@lightbitslabs.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 7d8b7a7d572a..89df51ee5bdf 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -279,6 +279,7 @@ struct nvmet_fabrics_ops {
 	void (*delete_ctrl)(struct nvmet_ctrl *ctrl);
 	void (*disc_traddr)(struct nvmet_req *req,
 			struct nvmet_port *port, char *traddr);
+	u16 (*install_queue)(struct nvmet_sq *nvme_sq);
 };
 
 #define NVMET_MAX_INLINE_BIOVEC	8

commit 5a3a6d6965865d0da5c743a0f9c58f84373f88e7
Author: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
Date:   Mon Nov 19 15:16:39 2018 -0800

    nvmet: fix the structure member indentation
    
    This is a cleanup patch which fixes the structure member indentation
    introduced by the p2p:
    
    commit c6925093d0b2 ("nvmet: Optionally use PCI P2P memory").
    We don't change any functionality in this patch.
    
    This is needed so that any future members will also follow the uniform
    indentation.
    
    Signed-off-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Acked-by: Logan Gunthorpe <logang@deltatee.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 547108c41ce9..7d8b7a7d572a 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -200,8 +200,8 @@ struct nvmet_ctrl {
 	char			subsysnqn[NVMF_NQN_FIELD_LEN];
 	char			hostnqn[NVMF_NQN_FIELD_LEN];
 
-	struct device *p2p_client;
-	struct radix_tree_root p2p_ns_map;
+	struct device		*p2p_client;
+	struct radix_tree_root	p2p_ns_map;
 };
 
 struct nvmet_subsys {
@@ -314,8 +314,8 @@ struct nvmet_req {
 	void (*execute)(struct nvmet_req *req);
 	const struct nvmet_fabrics_ops *ops;
 
-	struct pci_dev *p2p_dev;
-	struct device *p2p_client;
+	struct pci_dev		*p2p_dev;
+	struct device		*p2p_client;
 };
 
 extern struct workqueue_struct *buffered_io_wq;

commit e6a622fd6d66b83779357e3400f487fc159a7d83
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Mon Nov 19 14:11:12 2018 -0800

    nvmet: support fabrics sq flow control
    
    Technical proposal 8005 "fabrics SQ flow control" introduces a mode
    where a host and controller agree to omit sq_head pointer updates
    when sending nvme completions.
    
    In case the host indicated desire to operate in this mode (connect attribute)
    the controller will return back a connect completion with sq_head value
    of 0xffff as indication that it will omit sq_head pointer updates.
    
    This mode saves us an atomic update in the I/O path.
    
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    [hch: suggested better implementation]
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 03988fe9d915..547108c41ce9 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -106,6 +106,7 @@ struct nvmet_sq {
 	u16			qid;
 	u16			size;
 	u32			sqhd;
+	bool			sqhd_disabled;
 	struct completion	free_done;
 	struct completion	confirm_done;
 };

commit 03198c4d9fc8e72ba8a5ad74959b61de7f2780a6
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Nov 14 16:46:23 2018 +0100

    nvmet: mark nvmet_genctr static
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 31474940e373..03988fe9d915 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -470,7 +470,6 @@ int __init nvmet_init_discovery(void);
 void nvmet_exit_discovery(void);
 
 extern struct nvmet_subsys *nvmet_disc_subsys;
-extern u64 nvmet_genctr;
 extern struct rw_semaphore nvmet_config_sem;
 
 extern u32 nvmet_ana_group_enabled[NVMET_MAX_ANAGRPS + 1];

commit b662a078576e7d6e235b4e1b94863f0474cd8555
Author: Jay Sternberg <jay.e.sternberg@intel.com>
Date:   Mon Nov 12 13:56:40 2018 -0800

    nvmet: enable Discovery Controller AENs
    
    Add functions to find connections requesting Discovery Change events
    and send a notification to hosts that maintain an explicit persistent
    connection and have and active Asynchronous Event Request pending.
    Only Hosts that have access to the Subsystem effected by the change
    will receive notifications of Discovery Change event.
    
    Call these functions each time there is a configfs change that effects
    the Discover Log Pages.
    
    Set the OAES field in the Identify Controller response to advertise the
    support for Asynchronous Event Notifications.
    
    Signed-off-by: Jay Sternberg <jay.e.sternberg@intel.com>
    Reviewed-by: Phil Cayton <phil.cayton@intel.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 05b98f25d65c..31474940e373 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -139,6 +139,7 @@ struct nvmet_port {
 	struct list_head		subsystems;
 	struct config_group		referrals_group;
 	struct list_head		referrals;
+	struct list_head		global_entry;
 	struct config_group		ana_groups_group;
 	struct nvmet_ana_group		ana_default_group;
 	enum nvme_ana_state		*ana_state;
@@ -422,7 +423,7 @@ int nvmet_enable_port(struct nvmet_port *port);
 void nvmet_disable_port(struct nvmet_port *port);
 
 void nvmet_referral_enable(struct nvmet_port *parent, struct nvmet_port *port);
-void nvmet_referral_disable(struct nvmet_port *port);
+void nvmet_referral_disable(struct nvmet_port *parent, struct nvmet_port *port);
 
 u16 nvmet_copy_to_sgl(struct nvmet_req *req, off_t off, const void *buf,
 		size_t len);
@@ -432,6 +433,14 @@ u16 nvmet_zero_sgl(struct nvmet_req *req, off_t off, size_t len);
 
 u32 nvmet_get_log_page_len(struct nvme_command *cmd);
 
+extern struct list_head *nvmet_ports;
+void nvmet_port_disc_changed(struct nvmet_port *port,
+		struct nvmet_subsys *subsys);
+void nvmet_subsys_disc_changed(struct nvmet_subsys *subsys,
+		struct nvmet_host *host);
+void nvmet_add_async_event(struct nvmet_ctrl *ctrl, u8 event_type,
+		u8 event_info, u8 log_page);
+
 #define NVMET_QUEUE_SIZE	1024
 #define NVMET_NR_QUEUES		128
 #define NVMET_MAX_CMD		NVMET_QUEUE_SIZE

commit 253928eec61a52935584777f0dfba6cdb63967b6
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Mon Nov 12 13:56:39 2018 -0800

    nvmet: allow host connect even if no allowed subsystems are exported
    
    It is perfectly valid that a host connects to a discovery subsystem
    and gets an empty discovery log page since no subsystems are
    provisioned to it. No reason to disallow connecting to the discovery
    subsystem all together.
    
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Jay Sternberg <jay.e.sternberg@intel.com>
    Reviewed-by: Phil Cayton <phil.cayton@intel.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index bc99c700a583..05b98f25d65c 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -468,8 +468,7 @@ extern u32 nvmet_ana_group_enabled[NVMET_MAX_ANAGRPS + 1];
 extern u64 nvmet_ana_chgcnt;
 extern struct rw_semaphore nvmet_ana_sem;
 
-bool nvmet_host_allowed(struct nvmet_req *req, struct nvmet_subsys *subsys,
-		const char *hostnqn);
+bool nvmet_host_allowed(struct nvmet_subsys *subsys, const char *hostnqn);
 
 int nvmet_bdev_ns_enable(struct nvmet_ns *ns);
 int nvmet_file_ns_enable(struct nvmet_ns *ns);

commit f301c2b1368905340133ff8ef4485befdd0b7e2d
Author: Jay Sternberg <jay.e.sternberg@intel.com>
Date:   Mon Nov 12 13:56:37 2018 -0800

    nvmet: add defines for discovery change async events
    
    Add AEN/AER values as defined by the specification
    
    Signed-off-by: Jay Sternberg <jay.e.sternberg@intel.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index a8ee265a3806..bc99c700a583 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -36,6 +36,8 @@
  */
 #define NVMET_AEN_CFG_OPTIONAL \
 	(NVME_AEN_CFG_NS_ATTR | NVME_AEN_CFG_ANA_CHANGE)
+#define NVMET_DISC_AEN_CFG_OPTIONAL \
+	(NVME_AEN_CFG_DISC_CHANGE)
 
 /*
  * Plus mandatory SMART AENs (we'll never send them, but allow enabling them):

commit 90107455cce753c05a5e1e80cb84b09da1c87eef
Author: Jay Sternberg <jay.e.sternberg@intel.com>
Date:   Mon Nov 12 13:56:36 2018 -0800

    nvmet: make kato and AEN processing for use by other controllers
    
    Make common process of get/set features available to other controllers by
    making simple functions static inline and others not static and prototypes
    in nvmet.h file
    
    Also remove static from nvmet_execute_async_event and add prototype to
    nvmet.h to allow used by other controllers
    
    Signed-off-by: Jay Sternberg <jay.e.sternberg@intel.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index c525fb0510c5..a8ee265a3806 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -357,6 +357,12 @@ static inline bool nvmet_aen_bit_disabled(struct nvmet_ctrl *ctrl, u32 bn)
 	return test_and_set_bit(bn, &ctrl->aen_masked);
 }
 
+void nvmet_get_feat_kato(struct nvmet_req *req);
+void nvmet_get_feat_async_event(struct nvmet_req *req);
+u16 nvmet_set_feat_kato(struct nvmet_req *req);
+u16 nvmet_set_feat_async_event(struct nvmet_req *req, u32 mask);
+void nvmet_execute_async_event(struct nvmet_req *req);
+
 u16 nvmet_parse_connect_cmd(struct nvmet_req *req);
 u16 nvmet_bdev_parse_io_cmd(struct nvmet_req *req);
 u16 nvmet_file_parse_io_cmd(struct nvmet_req *req);

commit f9362ac1738a41cc526fde82e76beb034d8c6053
Author: Jay Sternberg <jay.e.sternberg@intel.com>
Date:   Mon Nov 12 13:56:35 2018 -0800

    nvmet: allow Keep Alive for Discovery controller
    
    Per change to specification allowing Discovery controllers to have
    explicit persistent connections, remove restriction on Discovery
    controllers allowing kato on connect.
    
    Signed-off-by: Jay Sternberg <jay.e.sternberg@intel.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 8ddc54fa98c7..c525fb0510c5 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -372,6 +372,8 @@ void nvmet_req_complete(struct nvmet_req *req, u16 status);
 int nvmet_req_alloc_sgl(struct nvmet_req *req);
 void nvmet_req_free_sgl(struct nvmet_req *req);
 
+void nvmet_execute_keep_alive(struct nvmet_req *req);
+
 void nvmet_cq_setup(struct nvmet_ctrl *ctrl, struct nvmet_cq *cq, u16 qid,
 		u16 size);
 void nvmet_sq_setup(struct nvmet_ctrl *ctrl, struct nvmet_sq *sq, u16 qid,
@@ -442,7 +444,7 @@ u32 nvmet_get_log_page_len(struct nvme_command *cmd);
 #define NVMET_DEFAULT_ANA_GRPID	1
 
 #define NVMET_KAS		10
-#define NVMET_DISC_KATO		120
+#define NVMET_DISC_KATO_MS		120000
 
 int __init nvmet_init_configfs(void);
 void __exit nvmet_exit_configfs(void);

commit 7114ddeb40c0ccc584d86df598da4054ca4cd79f
Author: Jay Sternberg <jay.e.sternberg@intel.com>
Date:   Mon Nov 12 13:56:34 2018 -0800

    nvmet: change aen mask functions to use bit numbers
    
    Functions nvmet_aen_disabled and nvmet_clear_aen were using
    values not bit numbers ie 1 << 9 not 9 for bit function clear_bit
    and test_and_set_bit.
    
    Signed-off-by: Jay Sternberg <jay.e.sternberg@intel.com>
    Reviewed-by: Phil Cayton <phil.cayton@intel.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 7efee345d467..8ddc54fa98c7 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -342,19 +342,19 @@ struct nvmet_async_event {
 	u8			log_page;
 };
 
-static inline void nvmet_clear_aen(struct nvmet_req *req, u32 aen_bit)
+static inline void nvmet_clear_aen_bit(struct nvmet_req *req, u32 bn)
 {
 	int rae = le32_to_cpu(req->cmd->common.cdw10[0]) & 1 << 15;
 
 	if (!rae)
-		clear_bit(aen_bit, &req->sq->ctrl->aen_masked);
+		clear_bit(bn, &req->sq->ctrl->aen_masked);
 }
 
-static inline bool nvmet_aen_disabled(struct nvmet_ctrl *ctrl, u32 aen)
+static inline bool nvmet_aen_bit_disabled(struct nvmet_ctrl *ctrl, u32 bn)
 {
-	if (!(READ_ONCE(ctrl->aen_enabled) & aen))
+	if (!(READ_ONCE(ctrl->aen_enabled) & (1 << bn)))
 		return true;
-	return test_and_set_bit(aen, &ctrl->aen_masked);
+	return test_and_set_bit(bn, &ctrl->aen_masked);
 }
 
 u16 nvmet_parse_connect_cmd(struct nvmet_req *req);

commit 6c8312ad509c3aaaa8720fee7abe45b813cd4d87
Author: Jay Sternberg <jay.e.sternberg@intel.com>
Date:   Mon Nov 12 13:56:33 2018 -0800

    nvmet: provide aen bit functions for multiple controller types
    
    Move nvmet_aen_disabled and nvmet_clear_aen in preparation for other types
    of controllers to use, initially the discovery controller.
    
    Signed-off-by: Jay Sternberg <jay.e.sternberg@intel.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 860218edeb6c..7efee345d467 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -342,6 +342,21 @@ struct nvmet_async_event {
 	u8			log_page;
 };
 
+static inline void nvmet_clear_aen(struct nvmet_req *req, u32 aen_bit)
+{
+	int rae = le32_to_cpu(req->cmd->common.cdw10[0]) & 1 << 15;
+
+	if (!rae)
+		clear_bit(aen_bit, &req->sq->ctrl->aen_masked);
+}
+
+static inline bool nvmet_aen_disabled(struct nvmet_ctrl *ctrl, u32 aen)
+{
+	if (!(READ_ONCE(ctrl->aen_enabled) & aen))
+		return true;
+	return test_and_set_bit(aen, &ctrl->aen_masked);
+}
+
 u16 nvmet_parse_connect_cmd(struct nvmet_req *req);
 u16 nvmet_bdev_parse_io_cmd(struct nvmet_req *req);
 u16 nvmet_file_parse_io_cmd(struct nvmet_req *req);

commit c09305ae49970e15cd18828c0f78b766e8cf224f
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Fri Nov 2 10:28:13 2018 -0700

    nvmet: support for traffic based keep-alive
    
    A controller that supports traffic based keep-alive can restart the keep
    alive timer even when no keep-alive was not received in the kato period
    as long as other admin or I/O commands were received.  For each command
    set ctrl->cmd_seen to true, and when keep-alive timer expires, if any
    commands were seen, resched ka_work instead of escalating to a fatal
    error.
    
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index c2b4d9ee6391..860218edeb6c 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -163,6 +163,8 @@ struct nvmet_ctrl {
 	struct nvmet_cq		**cqs;
 	struct nvmet_sq		**sqs;
 
+	bool			cmd_seen;
+
 	struct mutex		lock;
 	u64			cap;
 	u32			cc;

commit bd6bf7c10484f026505814b690104cdef27ed460
Merge: a41efc2a0f68 663569db6476
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 25 06:50:48 2018 -0700

    Merge tag 'pci-v4.20-changes' of git://git.kernel.org/pub/scm/linux/kernel/git/helgaas/pci
    
    Pull PCI updates from Bjorn Helgaas:
    
     - Fix ASPM link_state teardown on removal (Lukas Wunner)
    
     - Fix misleading _OSC ASPM message (Sinan Kaya)
    
     - Make _OSC optional for PCI (Sinan Kaya)
    
     - Don't initialize ASPM link state when ACPI_FADT_NO_ASPM is set
       (Patrick Talbert)
    
     - Remove x86 and arm64 node-local allocation for host bridge structures
       (Punit Agrawal)
    
     - Pay attention to device-specific _PXM node values (Jonathan Cameron)
    
     - Support new Immediate Readiness bit (Felipe Balbi)
    
     - Differentiate between pciehp surprise and safe removal (Lukas Wunner)
    
     - Remove unnecessary pciehp includes (Lukas Wunner)
    
     - Drop pciehp hotplug_slot_ops wrappers (Lukas Wunner)
    
     - Tolerate PCIe Slot Presence Detect being hardwired to zero to
       workaround broken hardware, e.g., the Wilocity switch/wireless device
       (Lukas Wunner)
    
     - Unify pciehp controller & slot structs (Lukas Wunner)
    
     - Constify hotplug_slot_ops (Lukas Wunner)
    
     - Drop hotplug_slot_info (Lukas Wunner)
    
     - Embed hotplug_slot struct into users instead of allocating it
       separately (Lukas Wunner)
    
     - Initialize PCIe port service drivers directly instead of relying on
       initcall ordering (Keith Busch)
    
     - Restore PCI config state after a slot reset (Keith Busch)
    
     - Save/restore DPC config state along with other PCI config state
       (Keith Busch)
    
     - Reference count devices during AER handling to avoid race issue with
       concurrent hot removal (Keith Busch)
    
     - If an Upstream Port reports ERR_FATAL, don't try to read the Port's
       config space because it is probably unreachable (Keith Busch)
    
     - During error handling, use slot-specific reset instead of secondary
       bus reset to avoid link up/down issues on hotplug ports (Keith Busch)
    
     - Restore previous AER/DPC handling that does not remove and
       re-enumerate devices on ERR_FATAL (Keith Busch)
    
     - Notify all drivers that may be affected by error recovery resets
       (Keith Busch)
    
     - Always generate error recovery uevents, even if a driver doesn't have
       error callbacks (Keith Busch)
    
     - Make PCIe link active reporting detection generic (Keith Busch)
    
     - Support D3cold in PCIe hierarchies during system sleep and runtime,
       including hotplug and Thunderbolt ports (Mika Westerberg)
    
     - Handle hpmemsize/hpiosize kernel parameters uniformly, whether slots
       are empty or occupied (Jon Derrick)
    
     - Remove duplicated include from pci/pcie/err.c and unused variable
       from cpqphp (YueHaibing)
    
     - Remove driver pci_cleanup_aer_uncorrect_error_status() calls (Oza
       Pawandeep)
    
     - Uninline PCI bus accessors for better ftracing (Keith Busch)
    
     - Remove unused AER Root Port .error_resume method (Keith Busch)
    
     - Use kfifo in AER instead of a local version (Keith Busch)
    
     - Use threaded IRQ in AER bottom half (Keith Busch)
    
     - Use managed resources in AER core (Keith Busch)
    
     - Reuse pcie_port_find_device() for AER injection (Keith Busch)
    
     - Abstract AER interrupt handling to disconnect error injection (Keith
       Busch)
    
     - Refactor AER injection callbacks to simplify future improvments
       (Keith Busch)
    
     - Remove unused Netronome NFP32xx Device IDs (Jakub Kicinski)
    
     - Use bitmap_zalloc() for dma_alias_mask (Andy Shevchenko)
    
     - Add switch fall-through annotations (Gustavo A. R. Silva)
    
     - Remove unused Switchtec quirk variable (Joshua Abraham)
    
     - Fix pci.c kernel-doc warning (Randy Dunlap)
    
     - Remove trivial PCI wrappers for DMA APIs (Christoph Hellwig)
    
     - Add Intel GPU device IDs to spurious interrupt quirk (Bin Meng)
    
     - Run Switchtec DMA aliasing quirk only on NTB endpoints to avoid
       useless dmesg errors (Logan Gunthorpe)
    
     - Update Switchtec NTB documentation (Wesley Yung)
    
     - Remove redundant "default n" from Kconfig (Bartlomiej Zolnierkiewicz)
    
     - Avoid panic when drivers enable MSI/MSI-X twice (Tonghao Zhang)
    
     - Add PCI support for peer-to-peer DMA (Logan Gunthorpe)
    
     - Add sysfs group for PCI peer-to-peer memory statistics (Logan
       Gunthorpe)
    
     - Add PCI peer-to-peer DMA scatterlist mapping interface (Logan
       Gunthorpe)
    
     - Add PCI configfs/sysfs helpers for use by peer-to-peer users (Logan
       Gunthorpe)
    
     - Add PCI peer-to-peer DMA driver writer's documentation (Logan
       Gunthorpe)
    
     - Add block layer flag to indicate driver support for PCI peer-to-peer
       DMA (Logan Gunthorpe)
    
     - Map Infiniband scatterlists for peer-to-peer DMA if they contain P2P
       memory (Logan Gunthorpe)
    
     - Register nvme-pci CMB buffer as PCI peer-to-peer memory (Logan
       Gunthorpe)
    
     - Add nvme-pci support for PCI peer-to-peer memory in requests (Logan
       Gunthorpe)
    
     - Use PCI peer-to-peer memory in nvme (Stephen Bates, Steve Wise,
       Christoph Hellwig, Logan Gunthorpe)
    
     - Cache VF config space size to optimize enumeration of many VFs
       (KarimAllah Ahmed)
    
     - Remove unnecessary <linux/pci-ats.h> include (Bjorn Helgaas)
    
     - Fix VMD AERSID quirk Device ID matching (Jon Derrick)
    
     - Fix Cadence PHY handling during probe (Alan Douglas)
    
     - Signal Cadence Endpoint interrupts via AXI region 0 instead of last
       region (Alan Douglas)
    
     - Write Cadence Endpoint MSI interrupts with 32 bits of data (Alan
       Douglas)
    
     - Remove redundant controller tests for "device_type == pci" (Rob
       Herring)
    
     - Document R-Car E3 (R8A77990) bindings (Tho Vu)
    
     - Add device tree support for R-Car r8a7744 (Biju Das)
    
     - Drop unused mvebu PCIe capability code (Thomas Petazzoni)
    
     - Add shared PCI bridge emulation code (Thomas Petazzoni)
    
     - Convert mvebu to use shared PCI bridge emulation (Thomas Petazzoni)
    
     - Add aardvark Root Port emulation (Thomas Petazzoni)
    
     - Support 100MHz/200MHz refclocks for i.MX6 (Lucas Stach)
    
     - Add initial power management for i.MX7 (Leonard Crestez)
    
     - Add PME_Turn_Off support for i.MX7 (Leonard Crestez)
    
     - Fix qcom runtime power management error handling (Bjorn Andersson)
    
     - Update TI dra7xx unaligned access errata workaround for host mode as
       well as endpoint mode (Vignesh R)
    
     - Fix kirin section mismatch warning (Nathan Chancellor)
    
     - Remove iproc PAXC slot check to allow VF support (Jitendra Bhivare)
    
     - Quirk Keystone K2G to limit MRRS to 256 (Kishon Vijay Abraham I)
    
     - Update Keystone to use MRRS quirk for host bridge instead of open
       coding (Kishon Vijay Abraham I)
    
     - Refactor Keystone link establishment (Kishon Vijay Abraham I)
    
     - Simplify and speed up Keystone link training (Kishon Vijay Abraham I)
    
     - Remove unused Keystone host_init argument (Kishon Vijay Abraham I)
    
     - Merge Keystone driver files into one (Kishon Vijay Abraham I)
    
     - Remove redundant Keystone platform_set_drvdata() (Kishon Vijay
       Abraham I)
    
     - Rename Keystone functions for uniformity (Kishon Vijay Abraham I)
    
     - Add Keystone device control module DT binding (Kishon Vijay Abraham
       I)
    
     - Use SYSCON API to get Keystone control module device IDs (Kishon
       Vijay Abraham I)
    
     - Clean up Keystone PHY handling (Kishon Vijay Abraham I)
    
     - Use runtime PM APIs to enable Keystone clock (Kishon Vijay Abraham I)
    
     - Clean up Keystone config space access checks (Kishon Vijay Abraham I)
    
     - Get Keystone outbound window count from DT (Kishon Vijay Abraham I)
    
     - Clean up Keystone outbound window configuration (Kishon Vijay Abraham
       I)
    
     - Clean up Keystone DBI setup (Kishon Vijay Abraham I)
    
     - Clean up Keystone ks_pcie_link_up() (Kishon Vijay Abraham I)
    
     - Fix Keystone IRQ status checking (Kishon Vijay Abraham I)
    
     - Add debug messages for all Keystone errors (Kishon Vijay Abraham I)
    
     - Clean up Keystone includes and macros (Kishon Vijay Abraham I)
    
     - Fix Mediatek unchecked return value from devm_pci_remap_iospace()
       (Gustavo A. R. Silva)
    
     - Fix Mediatek endpoint/port matching logic (Honghui Zhang)
    
     - Change Mediatek Root Port Class Code to PCI_CLASS_BRIDGE_PCI (Honghui
       Zhang)
    
     - Remove redundant Mediatek PM domain check (Honghui Zhang)
    
     - Convert Mediatek to pci_host_probe() (Honghui Zhang)
    
     - Fix Mediatek MSI enablement (Honghui Zhang)
    
     - Add Mediatek system PM support for MT2712 and MT7622 (Honghui Zhang)
    
     - Add Mediatek loadable module support (Honghui Zhang)
    
     - Detach VMD resources after stopping root bus to prevent orphan
       resources (Jon Derrick)
    
     - Convert pcitest build process to that used by other tools (iio, perf,
       etc) (Gustavo Pimentel)
    
    * tag 'pci-v4.20-changes' of git://git.kernel.org/pub/scm/linux/kernel/git/helgaas/pci: (140 commits)
      PCI/AER: Refactor error injection fallbacks
      PCI/AER: Abstract AER interrupt handling
      PCI/AER: Reuse existing pcie_port_find_device() interface
      PCI/AER: Use managed resource allocations
      PCI: pcie: Remove redundant 'default n' from Kconfig
      PCI: aardvark: Implement emulated root PCI bridge config space
      PCI: mvebu: Convert to PCI emulated bridge config space
      PCI: mvebu: Drop unused PCI express capability code
      PCI: Introduce PCI bridge emulated config space common logic
      PCI: vmd: Detach resources after stopping root bus
      nvmet: Optionally use PCI P2P memory
      nvmet: Introduce helper functions to allocate and free request SGLs
      nvme-pci: Add support for P2P memory in requests
      nvme-pci: Use PCI p2pmem subsystem to manage the CMB
      IB/core: Ensure we map P2P memory correctly in rdma_rw_ctx_[init|destroy]()
      block: Add PCI P2P flag for request queue
      PCI/P2PDMA: Add P2P DMA driver writer's documentation
      docs-rst: Add a new directory for PCI documentation
      PCI/P2PDMA: Introduce configfs/sysfs enable attribute helpers
      PCI/P2PDMA: Add PCI p2pmem DMA mappings to adjust the bus offset
      ...

commit c6925093d0b28329ad3a486f5b0345c2c192ae9a
Author: Logan Gunthorpe <logang@deltatee.com>
Date:   Thu Oct 4 15:27:47 2018 -0600

    nvmet: Optionally use PCI P2P memory
    
    Create a configfs attribute in each nvme-fabrics namespace to enable P2P
    memory use.  The attribute may be enabled (with a boolean) or a specific
    P2P device may be given (with the device's PCI name).
    
    When enabled, the namespace will ensure the underlying block device
    supports P2P and is compatible with any specified P2P device.  If no device
    was specified it will ensure there is compatible P2P memory somewhere in
    the system.  Enabling a namespace with P2P memory will fail with EINVAL
    (and an appropriate dmesg error) if any of these conditions are not met.
    
    Once a controller is set up on a specific port, the P2P device to use for
    each namespace will be found and stored in a radix tree by namespace ID.
    When memory is allocated for a request, the tree is used to look up the P2P
    device to allocate memory against.  If no device is in the tree (because no
    appropriate device was found), or if allocation of P2P memory fails, fall
    back to using regular memory.
    
    Signed-off-by: Stephen Bates <sbates@raithlin.com>
    Signed-off-by: Steve Wise <swise@opengridcomputing.com>
    [hch: partial rewrite of the initial code]
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Logan Gunthorpe <logang@deltatee.com>
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index e7b7406c4e22..d6be098f342b 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -26,6 +26,7 @@
 #include <linux/configfs.h>
 #include <linux/rcupdate.h>
 #include <linux/blkdev.h>
+#include <linux/radix-tree.h>
 
 #define NVMET_ASYNC_EVENTS		4
 #define NVMET_ERROR_LOG_SLOTS		128
@@ -77,6 +78,9 @@ struct nvmet_ns {
 	struct completion	disable_done;
 	mempool_t		*bvec_pool;
 	struct kmem_cache	*bvec_cache;
+
+	int			use_p2pmem;
+	struct pci_dev		*p2p_dev;
 };
 
 static inline struct nvmet_ns *to_nvmet_ns(struct config_item *item)
@@ -84,6 +88,11 @@ static inline struct nvmet_ns *to_nvmet_ns(struct config_item *item)
 	return container_of(to_config_group(item), struct nvmet_ns, group);
 }
 
+static inline struct device *nvmet_ns_dev(struct nvmet_ns *ns)
+{
+	return ns->bdev ? disk_to_dev(ns->bdev->bd_disk) : NULL;
+}
+
 struct nvmet_cq {
 	u16			qid;
 	u16			size;
@@ -184,6 +193,9 @@ struct nvmet_ctrl {
 
 	char			subsysnqn[NVMF_NQN_FIELD_LEN];
 	char			hostnqn[NVMF_NQN_FIELD_LEN];
+
+	struct device *p2p_client;
+	struct radix_tree_root p2p_ns_map;
 };
 
 struct nvmet_subsys {
@@ -294,6 +306,9 @@ struct nvmet_req {
 
 	void (*execute)(struct nvmet_req *req);
 	const struct nvmet_fabrics_ops *ops;
+
+	struct pci_dev *p2p_dev;
+	struct device *p2p_client;
 };
 
 extern struct workqueue_struct *buffered_io_wq;

commit 5b2322e48c978fd91d50873491b1c3b0a3b0266b
Author: Logan Gunthorpe <logang@deltatee.com>
Date:   Thu Oct 4 15:27:46 2018 -0600

    nvmet: Introduce helper functions to allocate and free request SGLs
    
    Add helpers to allocate and free the SGL in a struct nvmet_req:
    
      int nvmet_req_alloc_sgl(struct nvmet_req *req)
      void nvmet_req_free_sgl(struct nvmet_req *req)
    
    This will be expanded in a future patch to implement peer-to-peer memory
    DMAs and should be common with all target drivers.
    
    The new helpers are used in nvmet-rdma.  Seeing we use req.transfer_len as
    the length of the SGL it is set earlier and cleared on any error.  It also
    seems to be unnecessary to accumulate the length as the map_sgl functions
    should only ever be called once per request.
    
    Signed-off-by: Logan Gunthorpe <logang@deltatee.com>
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Sagi Grimberg <sagi@grimberg.me>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index ec9af4ee03b6..e7b7406c4e22 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -336,6 +336,8 @@ bool nvmet_req_init(struct nvmet_req *req, struct nvmet_cq *cq,
 void nvmet_req_uninit(struct nvmet_req *req);
 void nvmet_req_execute(struct nvmet_req *req);
 void nvmet_req_complete(struct nvmet_req *req, u16 status);
+int nvmet_req_alloc_sgl(struct nvmet_req *req);
+void nvmet_req_free_sgl(struct nvmet_req *req);
 
 void nvmet_cq_setup(struct nvmet_ctrl *ctrl, struct nvmet_cq *cq, u16 qid,
 		u16 size);

commit 73383adfad245bb84e6d6ef7830f01048fcfc217
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Fri Sep 28 15:40:43 2018 -0700

    nvmet: don't split large I/Os unconditionally
    
    If we know that the I/O size exceeds our inline bio vec, no
    point using it and split the rest to begin with. We could
    in theory reuse the inline bio and only allocate the bio_vec,
    but its really not worth optimizing for.
    
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index ec9af4ee03b6..08f7b57a1203 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -264,6 +264,7 @@ struct nvmet_fabrics_ops {
 };
 
 #define NVMET_MAX_INLINE_BIOVEC	8
+#define NVMET_MAX_INLINE_DATA_LEN NVMET_MAX_INLINE_BIOVEC * PAGE_SIZE
 
 struct nvmet_req {
 	struct nvme_command	*cmd;

commit dedf0be544614b6d9d395e78d72cc8c30d03e440
Author: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
Date:   Tue Aug 7 23:01:07 2018 -0700

    nvmet: add ns write protect support
    
    This patch implements the Namespace Write Protect feature described in
    "NVMe TP 4005a Namespace Write Protect". In this version, we implement
    No Write Protect and Write Protect states for target ns which can be
    toggled by set-features commands from the host side.
    
    For write-protect state transition, we need to flush the ns specified
    as a part of command so we also add helpers for carrying out synchronous
    flush operations.
    
    Signed-off-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    [hch: fixed an incorrect endianess conversion, minor cleanups]
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 22941045f46e..ec9af4ee03b6 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -58,6 +58,7 @@ struct nvmet_ns {
 	struct percpu_ref	ref;
 	struct block_device	*bdev;
 	struct file		*file;
+	bool			readonly;
 	u32			nsid;
 	u32			blksize_shift;
 	loff_t			size;
@@ -429,6 +430,9 @@ int nvmet_bdev_ns_enable(struct nvmet_ns *ns);
 int nvmet_file_ns_enable(struct nvmet_ns *ns);
 void nvmet_bdev_ns_disable(struct nvmet_ns *ns);
 void nvmet_file_ns_disable(struct nvmet_ns *ns);
+u16 nvmet_bdev_flush(struct nvmet_req *req);
+u16 nvmet_file_flush(struct nvmet_req *req);
+void nvmet_ns_changed(struct nvmet_subsys *subsys, u32 nsid);
 
 static inline u32 nvmet_rw_len(struct nvmet_req *req)
 {

commit 62ac0d32f74ea511d5813be728dc589d03f866a3
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jun 1 08:59:25 2018 +0200

    nvmet: support configuring ANA groups
    
    Allow creating non-default ANA groups (group ID > 1).  Groups are created
    either by assigning the group ID to a namespace, or by creating a configfs
    group object under a specific port.  All namespaces assigned to a group
    that doesn't have a configfs object for a given port are marked as
    inaccessible.
    
    Allow changing the ANA state on a per-port basis by creating an
    ana_groups directory under each port, and another directory with an
    ana_state file in it.  The default ANA group 1 directory is created
    automatically for each port.
    
    For all changes in ANA configuration the ANA change AEN is sent.  We only
    keep a global changecount instead of additional per-group changecounts to
    keep the implementation as simple as possible.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Keith Busch <keith.busch@intel.com>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index f7d622fc1aa7..22941045f46e 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -30,12 +30,11 @@
 #define NVMET_ASYNC_EVENTS		4
 #define NVMET_ERROR_LOG_SLOTS		128
 
-
 /*
  * Supported optional AENs:
  */
 #define NVMET_AEN_CFG_OPTIONAL \
-	NVME_AEN_CFG_NS_ATTR
+	(NVME_AEN_CFG_NS_ATTR | NVME_AEN_CFG_ANA_CHANGE)
 
 /*
  * Plus mandatory SMART AENs (we'll never send them, but allow enabling them):
@@ -99,6 +98,18 @@ struct nvmet_sq {
 	struct completion	confirm_done;
 };
 
+struct nvmet_ana_group {
+	struct config_group	group;
+	struct nvmet_port	*port;
+	u32			grpid;
+};
+
+static inline struct nvmet_ana_group *to_ana_group(struct config_item *item)
+{
+	return container_of(to_config_group(item), struct nvmet_ana_group,
+			group);
+}
+
 /**
  * struct nvmet_port -	Common structure to keep port
  *				information for the target.
@@ -116,6 +127,8 @@ struct nvmet_port {
 	struct list_head		subsystems;
 	struct config_group		referrals_group;
 	struct list_head		referrals;
+	struct config_group		ana_groups_group;
+	struct nvmet_ana_group		ana_default_group;
 	enum nvme_ana_state		*ana_state;
 	void				*priv;
 	bool				enabled;
@@ -128,6 +141,13 @@ static inline struct nvmet_port *to_nvmet_port(struct config_item *item)
 			group);
 }
 
+static inline struct nvmet_port *ana_groups_to_port(
+		struct config_item *item)
+{
+	return container_of(to_config_group(item), struct nvmet_port,
+			ana_groups_group);
+}
+
 struct nvmet_ctrl {
 	struct nvmet_subsys	*subsys;
 	struct nvmet_cq		**cqs;
@@ -345,6 +365,10 @@ void nvmet_ns_disable(struct nvmet_ns *ns);
 struct nvmet_ns *nvmet_ns_alloc(struct nvmet_subsys *subsys, u32 nsid);
 void nvmet_ns_free(struct nvmet_ns *ns);
 
+void nvmet_send_ana_event(struct nvmet_subsys *subsys,
+		struct nvmet_port *port);
+void nvmet_port_send_ana_event(struct nvmet_port *port);
+
 int nvmet_register_transport(const struct nvmet_fabrics_ops *ops);
 void nvmet_unregister_transport(const struct nvmet_fabrics_ops *ops);
 
@@ -378,7 +402,7 @@ u32 nvmet_get_log_page_len(struct nvme_command *cmd);
  * ANA Group 1 exists without manual intervention, has namespaces assigned to it
  * by default, and is available in an optimized state through all ports.
  */
-#define NVMET_MAX_ANAGRPS	1
+#define NVMET_MAX_ANAGRPS	128
 #define NVMET_DEFAULT_ANA_GRPID	1
 
 #define NVMET_KAS		10

commit 72efd25dcf4f6310e9e6fa85620aa443b27c23fe
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Jul 19 07:35:20 2018 -0700

    nvmet: add minimal ANA support
    
    Add support for Asynchronous Namespace Access as specified in NVMe 1.3
    TP 4004.
    
    Just add a default ANA group 1 that is optimized on all ports.  This is
    (and will remain) the default assignment for any namespace not epxlicitly
    assigned to another ANA group.  The ANA state can be manually changed
    through the configfs interface, including the change state.
    
    Includes fixes and improvements from Hannes Reinecke.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Keith Busch <keith.busch@intel.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 701017f7f3df..f7d622fc1aa7 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -64,6 +64,7 @@ struct nvmet_ns {
 	loff_t			size;
 	u8			nguid[16];
 	uuid_t			uuid;
+	u32			anagrpid;
 
 	bool			buffered_io;
 	bool			enabled;
@@ -115,6 +116,7 @@ struct nvmet_port {
 	struct list_head		subsystems;
 	struct config_group		referrals_group;
 	struct list_head		referrals;
+	enum nvme_ana_state		*ana_state;
 	void				*priv;
 	bool				enabled;
 	int				inline_data_size;
@@ -370,6 +372,15 @@ u32 nvmet_get_log_page_len(struct nvme_command *cmd);
  */
 #define NVMET_MAX_NAMESPACES	1024
 
+/*
+ * 0 is not a valid ANA group ID, so we start numbering at 1.
+ *
+ * ANA Group 1 exists without manual intervention, has namespaces assigned to it
+ * by default, and is available in an optimized state through all ports.
+ */
+#define NVMET_MAX_ANAGRPS	1
+#define NVMET_DEFAULT_ANA_GRPID	1
+
 #define NVMET_KAS		10
 #define NVMET_DISC_KATO		120
 
@@ -383,6 +394,10 @@ extern struct nvmet_subsys *nvmet_disc_subsys;
 extern u64 nvmet_genctr;
 extern struct rw_semaphore nvmet_config_sem;
 
+extern u32 nvmet_ana_group_enabled[NVMET_MAX_ANAGRPS + 1];
+extern u64 nvmet_ana_chgcnt;
+extern struct rw_semaphore nvmet_ana_sem;
+
 bool nvmet_host_allowed(struct nvmet_req *req, struct nvmet_subsys *subsys,
 		const char *hostnqn);
 

commit 793c7cfce02ce88b7bd67d43834c052d16c096e3
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun May 13 19:00:13 2018 +0200

    nvmet: track and limit the number of namespaces per subsystem
    
    TP 4004 introduces a new 'Maximum Number of Allocated Namespaces' field
    in the Identify controller data to help the host size resources.  Put
    an upper limit on the supported namespaces to be able to support this
    value as supporting 32-bits worth of namespaces would lead to very
    large buffers.  The limit is completely arbitrary at this point.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Keith Busch <keith.busch@intel.com>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index de12dcbfd3f3..701017f7f3df 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -170,6 +170,7 @@ struct nvmet_subsys {
 	struct kref		ref;
 
 	struct list_head	namespaces;
+	unsigned int		nr_namespaces;
 	unsigned int		max_nsid;
 
 	struct list_head	ctrls;
@@ -362,6 +363,13 @@ u32 nvmet_get_log_page_len(struct nvme_command *cmd);
 #define NVMET_QUEUE_SIZE	1024
 #define NVMET_NR_QUEUES		128
 #define NVMET_MAX_CMD		NVMET_QUEUE_SIZE
+
+/*
+ * Nice round number that makes a list of nsids fit into a page.
+ * Should become tunable at some point in the future.
+ */
+#define NVMET_MAX_NAMESPACES	1024
+
 #define NVMET_KAS		10
 #define NVMET_DISC_KATO		120
 

commit 4ee43280488b0f6cbd74702725a32f47d03d690b
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Jun 7 15:09:50 2018 +0200

    nvmet: keep a port pointer in nvmet_ctrl
    
    This will be needed for the ANA AEN code.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Keith Busch <keith.busch@intel.com>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 688993855402..de12dcbfd3f3 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -140,6 +140,8 @@ struct nvmet_ctrl {
 	u16			cntlid;
 	u32			kato;
 
+	struct nvmet_port	*port;
+
 	u32			aen_enabled;
 	unsigned long		aen_masked;
 	struct nvmet_req	*async_event_cmds[NVMET_ASYNC_EVENTS];

commit 0d5ee2b2ab4f6776c361bc975c2323bc8b5cf349
Author: Steve Wise <swise@opengridcomputing.com>
Date:   Wed Jun 20 07:15:10 2018 -0700

    nvmet-rdma: support max(16KB, PAGE_SIZE) inline data
    
    The patch enables inline data sizes using up to 4 recv sges, and capping
    the size at 16KB or at least 1 page size.  So on a 4K page system, up to
    16KB is supported, and for a 64K page system 1 page of 64KB is supported.
    
    We avoid > 0 order page allocations for the inline buffers by using
    multiple recv sges, one for each page.  If the device cannot support
    the configured inline data size due to lack of enough recv sges, then
    log a warning and reduce the inline size.
    
    Add a new configfs port attribute, called param_inline_data_size,
    to allow configuring the size of inline data for a given nvmf port.
    The maximum size allowed is still enforced by nvmet-rdma with
    NVMET_RDMA_MAX_INLINE_DATA_SIZE, which is now max(16KB, PAGE_SIZE).
    And the default size, if not specified via configfs, is still PAGE_SIZE.
    This preserves the existing behavior, but allows larger inline sizes
    for small page systems.  If the configured inline data size exceeds
    NVMET_RDMA_MAX_INLINE_DATA_SIZE, a warning is logged and the size is
    reduced.  If param_inline_data_size is set to 0, then inline data is
    disabled for that nvmf port.
    
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Max Gurtovoy <maxg@mellanox.com>
    Signed-off-by: Steve Wise <swise@opengridcomputing.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 5efb98ec95df..688993855402 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -117,6 +117,7 @@ struct nvmet_port {
 	struct list_head		referrals;
 	void				*priv;
 	bool				enabled;
+	int				inline_data_size;
 };
 
 static inline struct nvmet_port *to_nvmet_port(struct config_item *item)
@@ -226,7 +227,6 @@ struct nvmet_req;
 struct nvmet_fabrics_ops {
 	struct module *owner;
 	unsigned int type;
-	unsigned int sqe_inline_size;
 	unsigned int msdbd;
 	bool has_keyed_sgls : 1;
 	void (*queue_response)(struct nvmet_req *req);

commit 55eb942eda2ccbbbea61db4c1a774ba22b618046
Author: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
Date:   Wed Jun 20 00:01:41 2018 -0400

    nvmet: add buffered I/O support for file backed ns
    
    Add a new "buffered_io" attribute, which disabled direct I/O and thus
    enables page cache based caching when enabled.   The attribute can only
    be changed when the namespace is disabled as the file has to be reopend
    for the change to take effect.
    
    The possibly blocking read/write are deferred to a newly introduced
    global workqueue.
    
    Signed-off-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 480dfe10fad9..5efb98ec95df 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -65,6 +65,7 @@ struct nvmet_ns {
 	u8			nguid[16];
 	uuid_t			uuid;
 
+	bool			buffered_io;
 	bool			enabled;
 	struct nvmet_subsys	*subsys;
 	const char		*device_path;
@@ -269,6 +270,8 @@ struct nvmet_req {
 	const struct nvmet_fabrics_ops *ops;
 };
 
+extern struct workqueue_struct *buffered_io_wq;
+
 static inline void nvmet_set_status(struct nvmet_req *req, u16 status)
 {
 	req->rsp->status = cpu_to_le16(status << 1);

commit 55fdd6b6134fc91d4722149fa8e4f2df24c428fe
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 30 15:05:09 2018 +0200

    nvmet: mask pending AENs
    
    Per section 5.2 of the NVMe 1.3 spec:
    
      "When the controller posts a completion queue entry for an outstanding
      Asynchronous Event Request command and thus reports an asynchronous
      event, subsequent events of that event type are automatically masked by
      the controller until the host clears that event. An event is cleared by
      reading the log page associated with that event using the Get Log Page
      command (see section 5.14)."
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index f4d16d9b3582..480dfe10fad9 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -139,6 +139,7 @@ struct nvmet_ctrl {
 	u32			kato;
 
 	u32			aen_enabled;
+	unsigned long		aen_masked;
 	struct nvmet_req	*async_event_cmds[NVMET_ASYNC_EVENTS];
 	unsigned int		nr_async_event_cmds;
 	struct list_head	async_events;

commit c86b8f7b4144affc4daa8b4047cd4da936b087ef
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 30 15:04:47 2018 +0200

    nvmet: add AEN configuration support
    
    AEN configuration via the 'Get Features' and 'Set Features' admin
    command is mandatory, so we should be implemeting handling for it.
    
    Signed-off-by: Hannes Reinecke <hare@suse.com>
    [hch: use WRITE_ONCE, check for invalid values]
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Daniel Verkamp <daniel.verkamp@intel.com>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 8cdc1e550396..f4d16d9b3582 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -30,6 +30,21 @@
 #define NVMET_ASYNC_EVENTS		4
 #define NVMET_ERROR_LOG_SLOTS		128
 
+
+/*
+ * Supported optional AENs:
+ */
+#define NVMET_AEN_CFG_OPTIONAL \
+	NVME_AEN_CFG_NS_ATTR
+
+/*
+ * Plus mandatory SMART AENs (we'll never send them, but allow enabling them):
+ */
+#define NVMET_AEN_CFG_ALL \
+	(NVME_SMART_CRIT_SPARE | NVME_SMART_CRIT_TEMPERATURE | \
+	 NVME_SMART_CRIT_RELIABILITY | NVME_SMART_CRIT_MEDIA | \
+	 NVME_SMART_CRIT_VOLATILE_MEMORY | NVMET_AEN_CFG_OPTIONAL)
+
 /* Helper Macros when NVMe error is NVME_SC_CONNECT_INVALID_PARAM
  * The 16 bit shift is to set IATTR bit to 1, which means offending
  * offset starts in the data section of connect()
@@ -123,6 +138,7 @@ struct nvmet_ctrl {
 	u16			cntlid;
 	u32			kato;
 
+	u32			aen_enabled;
 	struct nvmet_req	*async_event_cmds[NVMET_ASYNC_EVENTS];
 	unsigned int		nr_async_event_cmds;
 	struct list_head	async_events;

commit c16734ea98f5549fed9a1af47e943a45855274e0
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri May 25 17:16:09 2018 +0200

    nvmet: implement the changed namespaces log
    
    Just keep a per-controller buffer of changed namespaces and copy it out
    in the get log page implementation.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Daniel Verkamp <daniel.verkamp@intel.com>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 768abe203298..8cdc1e550396 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -135,6 +135,9 @@ struct nvmet_ctrl {
 
 	const struct nvmet_fabrics_ops *ops;
 
+	__le32			*changed_ns_list;
+	u32			nr_changed_ns;
+
 	char			subsysnqn[NVMF_NQN_FIELD_LEN];
 	char			hostnqn[NVMF_NQN_FIELD_LEN];
 };

commit c7759fff22657d0e03b508f8f3ef97efbb10bc13
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue May 22 11:10:02 2018 +0200

    nvmet: add a new nvmet_zero_sgl helper
    
    Zeroes the SGL in the payload.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 32ebffcf464c..768abe203298 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -330,6 +330,7 @@ u16 nvmet_copy_to_sgl(struct nvmet_req *req, off_t off, const void *buf,
 		size_t len);
 u16 nvmet_copy_from_sgl(struct nvmet_req *req, off_t off, void *buf,
 		size_t len);
+u16 nvmet_zero_sgl(struct nvmet_req *req, off_t off, size_t len);
 
 u32 nvmet_get_log_page_len(struct nvme_command *cmd);
 

commit fe4a97918de02d5c656f29664770e335df12e090
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat May 26 14:11:25 2018 +0200

    nvme-loop: add support for multiple ports
    
    This is useful at least for multipath testing.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 2d09afcfe505..32ebffcf464c 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -85,7 +85,7 @@ struct nvmet_sq {
 /**
  * struct nvmet_port -	Common structure to keep port
  *				information for the target.
- * @entry:		List head for holding a list of these elements.
+ * @entry:		Entry into referrals or transport list.
  * @disc_addr:		Address information is stored in a format defined
  *				for a discovery log page entry.
  * @group:		ConfigFS group for this element's folder.

commit d5eff33ee6f80864d889d64fd3f6ea7b78dd1b24
Author: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
Date:   Wed May 23 00:34:39 2018 -0400

    nvmet: add simple file backed ns support
    
    This patch adds simple file backed namespace support for NVMeOF target.
    
    The new file io-cmd-file.c is responsible for handling the code for I/O
    commands when ns is file backed. Also, we introduce mempools based slow
    path using sync I/Os for file backed ns to ensure forward progress under
    reclaim.
    
    The old block device based implementation is moved to io-cmd-bdev.c and
    use a "nvmet_bdev_" symbol prefix.  The enable/disable calls are also
    move into the respective files.
    
    Signed-off-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
    [hch: updated changelog, fixed double req->ns lookup in bdev case]
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 15fd84ab21f8..2d09afcfe505 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -43,6 +43,7 @@ struct nvmet_ns {
 	struct list_head	dev_link;
 	struct percpu_ref	ref;
 	struct block_device	*bdev;
+	struct file		*file;
 	u32			nsid;
 	u32			blksize_shift;
 	loff_t			size;
@@ -57,6 +58,8 @@ struct nvmet_ns {
 	struct config_group	group;
 
 	struct completion	disable_done;
+	mempool_t		*bvec_pool;
+	struct kmem_cache	*bvec_cache;
 };
 
 static inline struct nvmet_ns *to_nvmet_ns(struct config_item *item)
@@ -222,8 +225,18 @@ struct nvmet_req {
 	struct nvmet_cq		*cq;
 	struct nvmet_ns		*ns;
 	struct scatterlist	*sg;
-	struct bio		inline_bio;
 	struct bio_vec		inline_bvec[NVMET_MAX_INLINE_BIOVEC];
+	union {
+		struct {
+			struct bio      inline_bio;
+		} b;
+		struct {
+			bool			mpool_alloc;
+			struct kiocb            iocb;
+			struct bio_vec          *bvec;
+			struct work_struct      work;
+		} f;
+	};
 	int			sg_cnt;
 	/* data length as parsed from the command: */
 	size_t			data_len;
@@ -263,7 +276,8 @@ struct nvmet_async_event {
 };
 
 u16 nvmet_parse_connect_cmd(struct nvmet_req *req);
-u16 nvmet_parse_io_cmd(struct nvmet_req *req);
+u16 nvmet_bdev_parse_io_cmd(struct nvmet_req *req);
+u16 nvmet_file_parse_io_cmd(struct nvmet_req *req);
 u16 nvmet_parse_admin_cmd(struct nvmet_req *req);
 u16 nvmet_parse_discovery_cmd(struct nvmet_req *req);
 u16 nvmet_parse_fabrics_cmd(struct nvmet_req *req);
@@ -338,4 +352,14 @@ extern struct rw_semaphore nvmet_config_sem;
 bool nvmet_host_allowed(struct nvmet_req *req, struct nvmet_subsys *subsys,
 		const char *hostnqn);
 
+int nvmet_bdev_ns_enable(struct nvmet_ns *ns);
+int nvmet_file_ns_enable(struct nvmet_ns *ns);
+void nvmet_bdev_ns_disable(struct nvmet_ns *ns);
+void nvmet_file_ns_disable(struct nvmet_ns *ns);
+
+static inline u32 nvmet_rw_len(struct nvmet_req *req)
+{
+	return ((u32)le16_to_cpu(req->cmd->rw.length) + 1) <<
+			req->ns->blksize_shift;
+}
 #endif /* _NVMET_H */

commit e929f06d9eaab4dba14e730ef18aa85b76465db9
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Mar 20 20:41:35 2018 +0100

    nvmet: constify struct nvmet_fabrics_ops
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Keith Busch <keith.busch@intel.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 40afb5d6ed91..15fd84ab21f8 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -130,7 +130,7 @@ struct nvmet_ctrl {
 	struct delayed_work	ka_work;
 	struct work_struct	fatal_err_work;
 
-	struct nvmet_fabrics_ops *ops;
+	const struct nvmet_fabrics_ops *ops;
 
 	char			subsysnqn[NVMF_NQN_FIELD_LEN];
 	char			hostnqn[NVMF_NQN_FIELD_LEN];
@@ -233,7 +233,7 @@ struct nvmet_req {
 	struct nvmet_port	*port;
 
 	void (*execute)(struct nvmet_req *req);
-	struct nvmet_fabrics_ops *ops;
+	const struct nvmet_fabrics_ops *ops;
 };
 
 static inline void nvmet_set_status(struct nvmet_req *req, u16 status)
@@ -269,7 +269,7 @@ u16 nvmet_parse_discovery_cmd(struct nvmet_req *req);
 u16 nvmet_parse_fabrics_cmd(struct nvmet_req *req);
 
 bool nvmet_req_init(struct nvmet_req *req, struct nvmet_cq *cq,
-		struct nvmet_sq *sq, struct nvmet_fabrics_ops *ops);
+		struct nvmet_sq *sq, const struct nvmet_fabrics_ops *ops);
 void nvmet_req_uninit(struct nvmet_req *req);
 void nvmet_req_execute(struct nvmet_req *req);
 void nvmet_req_complete(struct nvmet_req *req, u16 status);
@@ -303,8 +303,8 @@ void nvmet_ns_disable(struct nvmet_ns *ns);
 struct nvmet_ns *nvmet_ns_alloc(struct nvmet_subsys *subsys, u32 nsid);
 void nvmet_ns_free(struct nvmet_ns *ns);
 
-int nvmet_register_transport(struct nvmet_fabrics_ops *ops);
-void nvmet_unregister_transport(struct nvmet_fabrics_ops *ops);
+int nvmet_register_transport(const struct nvmet_fabrics_ops *ops);
+void nvmet_unregister_transport(const struct nvmet_fabrics_ops *ops);
 
 int nvmet_enable_port(struct nvmet_port *port);
 void nvmet_disable_port(struct nvmet_port *port);

commit 4c65268588102014837b2d09e5a02557e5d3fc9e
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Wed Jan 24 20:27:10 2018 +0200

    nvmet: don't return "any" ip address in discovery log page
    
    Its perfectly valid to assign a nvmet port to listen on "any"
    IP address (traddr 0.0.0.0 for ipv4 address family) for IP based
    transport ports. However, we must not return this address in
    discovery log entries. Instead we need to return the address
    where the request was accepted on (req->port address).
    
    Since this is nvme transport specific, introduce an optional
    .disc_traddr interface that is designed to check that a
    port in question is bound to "any" IP address and if so, set
    the traddr from the port where the request came from.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 417f6c0331cc..40afb5d6ed91 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -209,6 +209,8 @@ struct nvmet_fabrics_ops {
 	int (*add_port)(struct nvmet_port *port);
 	void (*remove_port)(struct nvmet_port *port);
 	void (*delete_ctrl)(struct nvmet_ctrl *ctrl);
+	void (*disc_traddr)(struct nvmet_req *req,
+			struct nvmet_port *port, char *traddr);
 };
 
 #define NVMET_MAX_INLINE_BIOVEC	8

commit e2c5923c349c1738fe8fda980874d93f6fb2e5b6
Merge: abc36be23635 a04b5de5050a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 14 15:32:19 2017 -0800

    Merge branch 'for-4.15/block' of git://git.kernel.dk/linux-block
    
    Pull core block layer updates from Jens Axboe:
     "This is the main pull request for block storage for 4.15-rc1.
    
      Nothing out of the ordinary in here, and no API changes or anything
      like that. Just various new features for drivers, core changes, etc.
      In particular, this pull request contains:
    
       - A patch series from Bart, closing the whole on blk/scsi-mq queue
         quescing.
    
       - A series from Christoph, building towards hidden gendisks (for
         multipath) and ability to move bio chains around.
    
       - NVMe
            - Support for native multipath for NVMe (Christoph).
            - Userspace notifications for AENs (Keith).
            - Command side-effects support (Keith).
            - SGL support (Chaitanya Kulkarni)
            - FC fixes and improvements (James Smart)
            - Lots of fixes and tweaks (Various)
    
       - bcache
            - New maintainer (Michael Lyle)
            - Writeback control improvements (Michael)
            - Various fixes (Coly, Elena, Eric, Liang, et al)
    
       - lightnvm updates, mostly centered around the pblk interface
         (Javier, Hans, and Rakesh).
    
       - Removal of unused bio/bvec kmap atomic interfaces (me, Christoph)
    
       - Writeback series that fix the much discussed hundreds of millions
         of sync-all units. This goes all the way, as discussed previously
         (me).
    
       - Fix for missing wakeup on writeback timer adjustments (Yafang
         Shao).
    
       - Fix laptop mode on blk-mq (me).
    
       - {mq,name} tupple lookup for IO schedulers, allowing us to have
         alias names. This means you can use 'deadline' on both !mq and on
         mq (where it's called mq-deadline). (me).
    
       - blktrace race fix, oopsing on sg load (me).
    
       - blk-mq optimizations (me).
    
       - Obscure waitqueue race fix for kyber (Omar).
    
       - NBD fixes (Josef).
    
       - Disable writeback throttling by default on bfq, like we do on cfq
         (Luca Miccio).
    
       - Series from Ming that enable us to treat flush requests on blk-mq
         like any other request. This is a really nice cleanup.
    
       - Series from Ming that improves merging on blk-mq with schedulers,
         getting us closer to flipping the switch on scsi-mq again.
    
       - BFQ updates (Paolo).
    
       - blk-mq atomic flags memory ordering fixes (Peter Z).
    
       - Loop cgroup support (Shaohua).
    
       - Lots of minor fixes from lots of different folks, both for core and
         driver code"
    
    * 'for-4.15/block' of git://git.kernel.dk/linux-block: (294 commits)
      nvme: fix visibility of "uuid" ns attribute
      blk-mq: fixup some comment typos and lengths
      ide: ide-atapi: fix compile error with defining macro DEBUG
      blk-mq: improve tag waiting setup for non-shared tags
      brd: remove unused brd_mutex
      blk-mq: only run the hardware queue if IO is pending
      block: avoid null pointer dereference on null disk
      fs: guard_bio_eod() needs to consider partitions
      xtensa/simdisk: fix compile error
      nvme: expose subsys attribute to sysfs
      nvme: create 'slaves' and 'holders' entries for hidden controllers
      block: create 'slaves' and 'holders' entries for hidden gendisks
      nvme: also expose the namespace identification sysfs files for mpath nodes
      nvme: implement multipath access to nvme subsystems
      nvme: track shared namespaces
      nvme: introduce a nvme_ns_ids structure
      nvme: track subsystems
      block, nvme: Introduce blk_mq_req_flags_t
      block, scsi: Make SCSI quiesce and resume work reliably
      block: Add the QUEUE_FLAG_PREEMPT_ONLY request queue flag
      ...

commit 5e62d5c993e6889cd314d5b5de6b670152109a0e
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Nov 9 14:29:58 2017 +0100

    nvmet: better data length validation
    
    Currently the NVMe target stores the expexted data length in req->data_len
    and uses that for data transfer decisions, but that does not take the
    actual transfer length in the SGLs into account.  So this adds a new
    transfer_len field, into which the transport drivers store the actual
    transfer length.  We then check the two match before actually executing
    the command.
    
    The FC transport driver already had such a field, which is removed in
    favour of the common one.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index e342f02845c1..194ebffc688c 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -223,7 +223,10 @@ struct nvmet_req {
 	struct bio		inline_bio;
 	struct bio_vec		inline_bvec[NVMET_MAX_INLINE_BIOVEC];
 	int			sg_cnt;
+	/* data length as parsed from the command: */
 	size_t			data_len;
+	/* data length as parsed from the SGL descriptor: */
+	size_t			transfer_len;
 
 	struct nvmet_port	*port;
 
@@ -266,6 +269,7 @@ u16 nvmet_parse_fabrics_cmd(struct nvmet_req *req);
 bool nvmet_req_init(struct nvmet_req *req, struct nvmet_cq *cq,
 		struct nvmet_sq *sq, struct nvmet_fabrics_ops *ops);
 void nvmet_req_uninit(struct nvmet_req *req);
+void nvmet_req_execute(struct nvmet_req *req);
 void nvmet_req_complete(struct nvmet_req *req, u16 status);
 
 void nvmet_cq_setup(struct nvmet_ctrl *ctrl, struct nvmet_cq *cq, u16 qid,

commit f9cf2a64912d67c9cf49c316a0a0ada0ea7ed1da
Author: James Smart <jsmart2021@gmail.com>
Date:   Wed Oct 18 14:33:59 2017 -0700

    nvmet: synchronize sqhd update
    
    In testing target io in read write mix, we did indeed get into cases where
    sqhd didn't update properly and slowly missed enough updates to shutdown
    the queue.
    
    Protect the updating sqhd by using cmpxchg, and for that turn the sqhd
    field into a u32 so that cmpxchg works on it for all architectures.
    
    Signed-off-by: James Smart <james.smart@broadcom.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 7b8e20adf760..87e429bfcd8a 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -74,7 +74,7 @@ struct nvmet_sq {
 	struct percpu_ref	ref;
 	u16			qid;
 	u16			size;
-	u16			sqhd;
+	u32			sqhd;
 	struct completion	free_done;
 	struct completion	confirm_done;
 };

commit 3375e29c280894f8d5e65c6920630a42db069599
Author: James Smart <jsmart2021@gmail.com>
Date:   Mon Sep 11 16:14:50 2017 -0700

    nvmet: bump NVMET_NR_QUEUES to 128
    
    Raise the max number of IO queues to 128. There are several hosts with
    more than 64 cpus/threads.
    
    Signed-off-by: James Smart <james.smart@broadcom.com>
    Reviewed-by: Max Gurtovoy <maxg@mellanox.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 7b8e20adf760..e342f02845c1 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -314,7 +314,7 @@ u16 nvmet_copy_from_sgl(struct nvmet_req *req, off_t off, void *buf,
 u32 nvmet_get_log_page_len(struct nvme_command *cmd);
 
 #define NVMET_QUEUE_SIZE	1024
-#define NVMET_NR_QUEUES		64
+#define NVMET_NR_QUEUES		128
 #define NVMET_MAX_CMD		NVMET_QUEUE_SIZE
 #define NVMET_KAS		10
 #define NVMET_DISC_KATO		120

commit bb1cc74790eb51f52d23c6e5fd9a3bb16030c3d8
Author: James Smart <jsmart2021@gmail.com>
Date:   Mon Sep 18 09:08:29 2017 -0700

    nvmet: implement valid sqhd values in completions
    
    To support sqhd, for initiators that are following the spec and
    paying attention to sqhd vs their sqtail values:
    
    - add sqhd to struct nvmet_sq
    - initialize sqhd to 0 in nvmet_sq_setup
    - rather than propagate the 0's-based qsize value from the connect message
      which requires a +1 in every sqhd update, and as nothing else references
      it, convert to 1's-based value in nvmt_sq/cq_setup() calls.
    - validate connect message sqsize being non-zero per spec.
    - updated assign sqhd for every completion that goes back.
    
    Also remove handling the NULL sq case in __nvmet_req_complete, as it can't
    happen with the current code.
    
    Signed-off-by: James Smart <james.smart@broadcom.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Max Gurtovoy <maxg@mellanox.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 7d261ab894f4..7b8e20adf760 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -74,6 +74,7 @@ struct nvmet_sq {
 	struct percpu_ref	ref;
 	u16			qid;
 	u16			size;
+	u16			sqhd;
 	struct completion	free_done;
 	struct completion	confirm_done;
 };

commit 28dd5cf70aaac2a12a16847ae0a978f0b0575194
Author: Omri Mann <omri@excelero.com>
Date:   Wed Aug 30 15:22:59 2017 +0300

    nvmet: add support for reporting the host identifier
    
    And fix the Get/Set Log Page implementation to take all 8 bits of the
    feature identifier into account.
    
    Signed-off-by: Omri Mann <omri@excelero.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    [hch: used the UUID API, updated changelog]

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index e3b244c7e443..7d261ab894f4 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -115,6 +115,7 @@ struct nvmet_ctrl {
 	u32			cc;
 	u32			csts;
 
+	uuid_t			hostid;
 	u16			cntlid;
 	u32			kato;
 

commit 2e7f5d2af2155084c6f7c86328d36e698cd84954
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Fri Jul 14 15:36:55 2017 +0200

    nvmet: Move serial number from controller to subsystem
    
    The NVMe specification defines the serial number as:
    
    "Serial Number (SN): Contains the serial number for the NVM subsystem
    that is assigned by the vendor as an ASCII string. Refer to section
    7.10 for unique identifier requirements. Refer to section 1.5 for ASCII
    string requirements"
    
    So move it from the controller to the subsystem, where it belongs.
    
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 747bbdb4f9c6..e3b244c7e443 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -112,7 +112,6 @@ struct nvmet_ctrl {
 
 	struct mutex		lock;
 	u64			cap;
-	u64			serial;
 	u32			cc;
 	u32			csts;
 
@@ -152,6 +151,7 @@ struct nvmet_subsys {
 	u16			max_qid;
 
 	u64			ver;
+	u64			serial;
 	char			*subsysnqn;
 
 	struct config_group	group;

commit 637dc0f38afdd2fdb6e46a913b7f35c17f0c6ae0
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Wed Jun 7 11:45:32 2017 +0200

    nvmet: implement namespace identify descriptor list
    
    A NVMe Identify NS command with a CNS value of '3' is expecting a list
    of Namespace Identification Descriptor structures to be returned to
    the host for the namespace requested in the namespace identify
    command.
    
    This Namespace Identification Descriptor structure consists of the
    type of the namespace identifier, the length of the identifier and the
    actual identifier.
    
    Valid types are NGUID and UUID which we have saved in our nvme_ns
    structure if they have been configured via configfs. If no value has
    been assigened to one of these we return an "invalid opcode" back to
    the host to maintain backward compatibiliy with older implementations
    without Namespace Identify Descriptor list support.
    
    Also as the Namespace Identify Descriptor list is the only mandatory
    feature change between 1.2.1 and 1.3 we can bump the advertised
    version as well.
    
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Max Gurtovoy <maxg@mellanox.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 8ff6e430b30a..747bbdb4f9c6 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -47,6 +47,7 @@ struct nvmet_ns {
 	u32			blksize_shift;
 	loff_t			size;
 	u8			nguid[16];
+	uuid_t			uuid;
 
 	bool			enabled;
 	struct nvmet_subsys	*subsys;

commit 8e41226324e7c00f2087bfbc9f470d665e92df18
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 17 09:54:27 2017 +0200

    nvme: switch to uuid_t
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Amir Goldstein <amir73il@gmail.com>
    Reviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index cfc5c7fb0ab7..8ff6e430b30a 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -21,6 +21,7 @@
 #include <linux/percpu-refcount.h>
 #include <linux/list.h>
 #include <linux/mutex.h>
+#include <linux/uuid.h>
 #include <linux/nvme.h>
 #include <linux/configfs.h>
 #include <linux/rcupdate.h>

commit 549f01ae7b913355bea76100d3f17694bc9ec769
Author: Vijay Immanuel <vijayi@attalasystems.com>
Date:   Mon May 8 16:38:35 2017 -0700

    nvmet: release the sq ref on rdma read errors
    
    On rdma read errors, release the sq ref that was taken
    when the req was initialized. This avoids a hang in
    nvmet_sq_destroy() when the queue is being freed.
    
    Signed-off-by: Vijay Immanuel <vijayi@attalasystems.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 7cb77ba5993b..cfc5c7fb0ab7 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -261,6 +261,7 @@ u16 nvmet_parse_fabrics_cmd(struct nvmet_req *req);
 
 bool nvmet_req_init(struct nvmet_req *req, struct nvmet_cq *cq,
 		struct nvmet_sq *sq, struct nvmet_fabrics_ops *ops);
+void nvmet_req_uninit(struct nvmet_req *req);
 void nvmet_req_complete(struct nvmet_req *req, u16 status);
 
 void nvmet_cq_setup(struct nvmet_ctrl *ctrl, struct nvmet_cq *cq, u16 qid,

commit 64a0ca88eaa66e3d219296b17aa08b78894e42c8
Author: Parav Pandit <parav@mellanox.com>
Date:   Mon Feb 27 23:21:33 2017 -0600

    nvmet: Introduced helper routine for controller status check.
    
    This patch introduces helper function for checking controller
    status during admin and io command processing which returns u16
    status. As to bring consistency on returning status, other
    friend functions also now return u16 status instead of int
    to match the spec.
    
    As part of the theseerror log prints in also prints qid on
    which command error occured.
    
    Signed-off-by: Parav Pandit <parav@mellanox.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index f7ff15f17ca9..7cb77ba5993b 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -253,11 +253,11 @@ struct nvmet_async_event {
 	u8			log_page;
 };
 
-int nvmet_parse_connect_cmd(struct nvmet_req *req);
-int nvmet_parse_io_cmd(struct nvmet_req *req);
-int nvmet_parse_admin_cmd(struct nvmet_req *req);
-int nvmet_parse_discovery_cmd(struct nvmet_req *req);
-int nvmet_parse_fabrics_cmd(struct nvmet_req *req);
+u16 nvmet_parse_connect_cmd(struct nvmet_req *req);
+u16 nvmet_parse_io_cmd(struct nvmet_req *req);
+u16 nvmet_parse_admin_cmd(struct nvmet_req *req);
+u16 nvmet_parse_discovery_cmd(struct nvmet_req *req);
+u16 nvmet_parse_fabrics_cmd(struct nvmet_req *req);
 
 bool nvmet_req_init(struct nvmet_req *req, struct nvmet_cq *cq,
 		struct nvmet_sq *sq, struct nvmet_fabrics_ops *ops);
@@ -278,6 +278,7 @@ u16 nvmet_alloc_ctrl(const char *subsysnqn, const char *hostnqn,
 u16 nvmet_ctrl_find_get(const char *subsysnqn, const char *hostnqn, u16 cntlid,
 		struct nvmet_req *req, struct nvmet_ctrl **ret);
 void nvmet_ctrl_put(struct nvmet_ctrl *ctrl);
+u16 nvmet_check_ctrl_status(struct nvmet_req *req, struct nvme_command *cmd);
 
 struct nvmet_subsys *nvmet_subsys_alloc(const char *subsysnqn,
 		enum nvme_subsys_type type);

commit 427242ce99e43208188f843eed2739d8a99cc967
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Mon Mar 6 18:46:20 2017 +0200

    nvmet: confirm sq percpu has scheduled and switched to atomic
    
    percpu_ref_kill is not enough to prevent subsequent
    percpu_ref_tryget_live from failing. Hence call
    perfcpu_ref_kill_confirm to make it safe.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 1370eee0a3c0..f7ff15f17ca9 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -73,6 +73,7 @@ struct nvmet_sq {
 	u16			qid;
 	u16			size;
 	struct completion	free_done;
+	struct completion	confirm_done;
 };
 
 /**

commit 15fbad96fc5fb1c5a0502e6a10dea671f510de3d
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Mon Nov 14 14:24:21 2016 +0200

    nvmet: Make cntlid globally unique
    
    We usually log the cntlid which is confusing in case
    we have multiple subsystems each with it's own cntlid ida.
    Instead make cntlid ida globally unique and log the initial
    association.
    
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Max Gurtovoy <maxg@mellanox.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index cc7ad06b43a7..1370eee0a3c0 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -142,7 +142,6 @@ struct nvmet_subsys {
 	unsigned int		max_nsid;
 
 	struct list_head	ctrls;
-	struct ida		cntlid_ida;
 
 	struct list_head	hosts;
 	bool			allow_any_host;

commit 344770b07b7ae70639ebf110010eb6156a6e55e9
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Sun Nov 27 22:29:17 2016 +0200

    nvmet: delete controllers deletion upon subsystem release
    
    No reason for them to be kept around if we are
    deleting the subsystem, so instead of passively
    wait for the host to disconnect, actively delete
    the controllers.
    
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Max Gurtovoy <maxg@mellanox.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 23d5eb1c944f..cc7ad06b43a7 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -282,6 +282,7 @@ void nvmet_ctrl_put(struct nvmet_ctrl *ctrl);
 struct nvmet_subsys *nvmet_subsys_alloc(const char *subsysnqn,
 		enum nvme_subsys_type type);
 void nvmet_subsys_put(struct nvmet_subsys *subsys);
+void nvmet_subsys_del_ctrls(struct nvmet_subsys *subsys);
 
 struct nvmet_ns *nvmet_find_namespace(struct nvmet_ctrl *ctrl, __le32 nsid);
 void nvmet_put_namespace(struct nvmet_ns *ns);

commit e4fcf07cca6a3b6c4be00df16f08be894325eaa3
Author: Solganik Alexander <sashas@lightbitslabs.com>
Date:   Sun Oct 30 10:35:15 2016 +0200

    nvmet: Fix possible infinite loop triggered on hot namespace removal
    
    When removing a namespace we delete it from the subsystem namespaces
    list with list_del_init which allows us to know if it is enabled or
    not.
    
    The problem is that list_del_init initialize the list next and does
    not respect the RCU list-traversal we do on the IO path for locating
    a namespace. Instead we need to use list_del_rcu which is allowed to
    run concurrently with the _rcu list-traversal primitives (keeps list
    next intact) and guarantees concurrent nvmet_find_naespace forward
    progress.
    
    By changing that, we cannot rely on ns->dev_link for knowing if the
    namspace is enabled, so add enabled indicator entry to nvmet_ns for
    that.
    
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Solganik Alexander <sashas@lightbitslabs.com>
    Cc: <stable@vger.kernel.org> # v4.8+

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index f9c76441e8c9..23d5eb1c944f 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -47,6 +47,7 @@ struct nvmet_ns {
 	loff_t			size;
 	u8			nguid[16];
 
+	bool			enabled;
 	struct nvmet_subsys	*subsys;
 	const char		*device_path;
 
@@ -61,11 +62,6 @@ static inline struct nvmet_ns *to_nvmet_ns(struct config_item *item)
 	return container_of(to_config_group(item), struct nvmet_ns, group);
 }
 
-static inline bool nvmet_ns_enabled(struct nvmet_ns *ns)
-{
-	return !list_empty_careful(&ns->dev_link);
-}
-
 struct nvmet_cq {
 	u16			qid;
 	u16			size;

commit d49187e97e94e2eb613cb6fed810356972077cc3
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Nov 10 07:32:33 2016 -0800

    nvme: introduce struct nvme_request
    
    This adds a shared per-request structure for all NVMe I/O.  This structure
    is embedded as the first member in all NVMe transport drivers request
    private data and allows to implement common functionality between the
    drivers.
    
    The first use is to replace the current abuse of the SCSI command
    passthrough fields in struct request for the NVMe command passthrough,
    but it will grow a field more fields to allow implementing things
    like common abort handlers in the future.
    
    The passthrough commands are handled by having a pointer to the SQE
    (struct nvme_command) in struct nvme_request, and the union of the
    possible result fields, which had to be turned from an anonymous
    into a named union for that purpose.  This avoids having to pass
    a reference to a full CQE around and thus makes checking the result
    a lot more lightweight.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Keith Busch <keith.busch@intel.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 76b6eedccaf9..f9c76441e8c9 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -238,7 +238,7 @@ static inline void nvmet_set_status(struct nvmet_req *req, u16 status)
 
 static inline void nvmet_set_result(struct nvmet_req *req, u32 result)
 {
-	req->rsp->result = cpu_to_le32(result);
+	req->rsp->result.u32 = cpu_to_le32(result);
 }
 
 /*

commit 28b89118539da03f4b188763e1b2fd1aec0f580a
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Thu Aug 4 11:18:49 2016 +0300

    nvmet: Fix controller serial number inconsistency
    
    The host is allowed to issue identify as many times
    as it wants, we need to stay consistent when reporting
    the serial number for a given controller.
    
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
index 57dd6d834c28..76b6eedccaf9 100644
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@ -113,6 +113,7 @@ struct nvmet_ctrl {
 
 	struct mutex		lock;
 	u64			cap;
+	u64			serial;
 	u32			cc;
 	u32			csts;
 

commit a07b4970f464f13640e28e16dad6cfa33647cc99
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Jun 21 18:04:20 2016 +0200

    nvmet: add a generic NVMe target
    
    This patch introduces a implementation of NVMe subsystems,
    controllers and discovery service which allows to export
    NVMe namespaces across fabrics such as Ethernet, FC etc.
    
    The implementation conforms to the NVMe 1.2.1 specification
    and interoperates with NVMe over fabrics host implementations.
    
    Configuration works using configfs, and is best performed using
    the nvmetcli tool from http://git.infradead.org/users/hch/nvmetcli.git,
    which also has a detailed explanation of the required steps in the
    README file.
    
    Signed-off-by: Armen Baloyan <armenx.baloyan@intel.com>
    Signed-off-by: Anthony Knapp <anthony.j.knapp@intel.com>
    Signed-off-by: Jay Freyensee <james.p.freyensee@intel.com>
    Signed-off-by: Ming Lin <ming.l@ssi.samsung.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Steve Wise <swise@opengridcomputing.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/nvme/target/nvmet.h b/drivers/nvme/target/nvmet.h
new file mode 100644
index 000000000000..57dd6d834c28
--- /dev/null
+++ b/drivers/nvme/target/nvmet.h
@@ -0,0 +1,331 @@
+/*
+ * Copyright (c) 2015-2016 HGST, a Western Digital Company.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ */
+
+#ifndef _NVMET_H
+#define _NVMET_H
+
+#include <linux/dma-mapping.h>
+#include <linux/types.h>
+#include <linux/device.h>
+#include <linux/kref.h>
+#include <linux/percpu-refcount.h>
+#include <linux/list.h>
+#include <linux/mutex.h>
+#include <linux/nvme.h>
+#include <linux/configfs.h>
+#include <linux/rcupdate.h>
+#include <linux/blkdev.h>
+
+#define NVMET_ASYNC_EVENTS		4
+#define NVMET_ERROR_LOG_SLOTS		128
+
+/* Helper Macros when NVMe error is NVME_SC_CONNECT_INVALID_PARAM
+ * The 16 bit shift is to set IATTR bit to 1, which means offending
+ * offset starts in the data section of connect()
+ */
+#define IPO_IATTR_CONNECT_DATA(x)	\
+	(cpu_to_le32((1 << 16) | (offsetof(struct nvmf_connect_data, x))))
+#define IPO_IATTR_CONNECT_SQE(x)	\
+	(cpu_to_le32(offsetof(struct nvmf_connect_command, x)))
+
+struct nvmet_ns {
+	struct list_head	dev_link;
+	struct percpu_ref	ref;
+	struct block_device	*bdev;
+	u32			nsid;
+	u32			blksize_shift;
+	loff_t			size;
+	u8			nguid[16];
+
+	struct nvmet_subsys	*subsys;
+	const char		*device_path;
+
+	struct config_group	device_group;
+	struct config_group	group;
+
+	struct completion	disable_done;
+};
+
+static inline struct nvmet_ns *to_nvmet_ns(struct config_item *item)
+{
+	return container_of(to_config_group(item), struct nvmet_ns, group);
+}
+
+static inline bool nvmet_ns_enabled(struct nvmet_ns *ns)
+{
+	return !list_empty_careful(&ns->dev_link);
+}
+
+struct nvmet_cq {
+	u16			qid;
+	u16			size;
+};
+
+struct nvmet_sq {
+	struct nvmet_ctrl	*ctrl;
+	struct percpu_ref	ref;
+	u16			qid;
+	u16			size;
+	struct completion	free_done;
+};
+
+/**
+ * struct nvmet_port -	Common structure to keep port
+ *				information for the target.
+ * @entry:		List head for holding a list of these elements.
+ * @disc_addr:		Address information is stored in a format defined
+ *				for a discovery log page entry.
+ * @group:		ConfigFS group for this element's folder.
+ * @priv:		Private data for the transport.
+ */
+struct nvmet_port {
+	struct list_head		entry;
+	struct nvmf_disc_rsp_page_entry	disc_addr;
+	struct config_group		group;
+	struct config_group		subsys_group;
+	struct list_head		subsystems;
+	struct config_group		referrals_group;
+	struct list_head		referrals;
+	void				*priv;
+	bool				enabled;
+};
+
+static inline struct nvmet_port *to_nvmet_port(struct config_item *item)
+{
+	return container_of(to_config_group(item), struct nvmet_port,
+			group);
+}
+
+struct nvmet_ctrl {
+	struct nvmet_subsys	*subsys;
+	struct nvmet_cq		**cqs;
+	struct nvmet_sq		**sqs;
+
+	struct mutex		lock;
+	u64			cap;
+	u32			cc;
+	u32			csts;
+
+	u16			cntlid;
+	u32			kato;
+
+	struct nvmet_req	*async_event_cmds[NVMET_ASYNC_EVENTS];
+	unsigned int		nr_async_event_cmds;
+	struct list_head	async_events;
+	struct work_struct	async_event_work;
+
+	struct list_head	subsys_entry;
+	struct kref		ref;
+	struct delayed_work	ka_work;
+	struct work_struct	fatal_err_work;
+
+	struct nvmet_fabrics_ops *ops;
+
+	char			subsysnqn[NVMF_NQN_FIELD_LEN];
+	char			hostnqn[NVMF_NQN_FIELD_LEN];
+};
+
+struct nvmet_subsys {
+	enum nvme_subsys_type	type;
+
+	struct mutex		lock;
+	struct kref		ref;
+
+	struct list_head	namespaces;
+	unsigned int		max_nsid;
+
+	struct list_head	ctrls;
+	struct ida		cntlid_ida;
+
+	struct list_head	hosts;
+	bool			allow_any_host;
+
+	u16			max_qid;
+
+	u64			ver;
+	char			*subsysnqn;
+
+	struct config_group	group;
+
+	struct config_group	namespaces_group;
+	struct config_group	allowed_hosts_group;
+};
+
+static inline struct nvmet_subsys *to_subsys(struct config_item *item)
+{
+	return container_of(to_config_group(item), struct nvmet_subsys, group);
+}
+
+static inline struct nvmet_subsys *namespaces_to_subsys(
+		struct config_item *item)
+{
+	return container_of(to_config_group(item), struct nvmet_subsys,
+			namespaces_group);
+}
+
+struct nvmet_host {
+	struct config_group	group;
+};
+
+static inline struct nvmet_host *to_host(struct config_item *item)
+{
+	return container_of(to_config_group(item), struct nvmet_host, group);
+}
+
+static inline char *nvmet_host_name(struct nvmet_host *host)
+{
+	return config_item_name(&host->group.cg_item);
+}
+
+struct nvmet_host_link {
+	struct list_head	entry;
+	struct nvmet_host	*host;
+};
+
+struct nvmet_subsys_link {
+	struct list_head	entry;
+	struct nvmet_subsys	*subsys;
+};
+
+struct nvmet_req;
+struct nvmet_fabrics_ops {
+	struct module *owner;
+	unsigned int type;
+	unsigned int sqe_inline_size;
+	unsigned int msdbd;
+	bool has_keyed_sgls : 1;
+	void (*queue_response)(struct nvmet_req *req);
+	int (*add_port)(struct nvmet_port *port);
+	void (*remove_port)(struct nvmet_port *port);
+	void (*delete_ctrl)(struct nvmet_ctrl *ctrl);
+};
+
+#define NVMET_MAX_INLINE_BIOVEC	8
+
+struct nvmet_req {
+	struct nvme_command	*cmd;
+	struct nvme_completion	*rsp;
+	struct nvmet_sq		*sq;
+	struct nvmet_cq		*cq;
+	struct nvmet_ns		*ns;
+	struct scatterlist	*sg;
+	struct bio		inline_bio;
+	struct bio_vec		inline_bvec[NVMET_MAX_INLINE_BIOVEC];
+	int			sg_cnt;
+	size_t			data_len;
+
+	struct nvmet_port	*port;
+
+	void (*execute)(struct nvmet_req *req);
+	struct nvmet_fabrics_ops *ops;
+};
+
+static inline void nvmet_set_status(struct nvmet_req *req, u16 status)
+{
+	req->rsp->status = cpu_to_le16(status << 1);
+}
+
+static inline void nvmet_set_result(struct nvmet_req *req, u32 result)
+{
+	req->rsp->result = cpu_to_le32(result);
+}
+
+/*
+ * NVMe command writes actually are DMA reads for us on the target side.
+ */
+static inline enum dma_data_direction
+nvmet_data_dir(struct nvmet_req *req)
+{
+	return nvme_is_write(req->cmd) ? DMA_FROM_DEVICE : DMA_TO_DEVICE;
+}
+
+struct nvmet_async_event {
+	struct list_head	entry;
+	u8			event_type;
+	u8			event_info;
+	u8			log_page;
+};
+
+int nvmet_parse_connect_cmd(struct nvmet_req *req);
+int nvmet_parse_io_cmd(struct nvmet_req *req);
+int nvmet_parse_admin_cmd(struct nvmet_req *req);
+int nvmet_parse_discovery_cmd(struct nvmet_req *req);
+int nvmet_parse_fabrics_cmd(struct nvmet_req *req);
+
+bool nvmet_req_init(struct nvmet_req *req, struct nvmet_cq *cq,
+		struct nvmet_sq *sq, struct nvmet_fabrics_ops *ops);
+void nvmet_req_complete(struct nvmet_req *req, u16 status);
+
+void nvmet_cq_setup(struct nvmet_ctrl *ctrl, struct nvmet_cq *cq, u16 qid,
+		u16 size);
+void nvmet_sq_setup(struct nvmet_ctrl *ctrl, struct nvmet_sq *sq, u16 qid,
+		u16 size);
+void nvmet_sq_destroy(struct nvmet_sq *sq);
+int nvmet_sq_init(struct nvmet_sq *sq);
+
+void nvmet_ctrl_fatal_error(struct nvmet_ctrl *ctrl);
+
+void nvmet_update_cc(struct nvmet_ctrl *ctrl, u32 new);
+u16 nvmet_alloc_ctrl(const char *subsysnqn, const char *hostnqn,
+		struct nvmet_req *req, u32 kato, struct nvmet_ctrl **ctrlp);
+u16 nvmet_ctrl_find_get(const char *subsysnqn, const char *hostnqn, u16 cntlid,
+		struct nvmet_req *req, struct nvmet_ctrl **ret);
+void nvmet_ctrl_put(struct nvmet_ctrl *ctrl);
+
+struct nvmet_subsys *nvmet_subsys_alloc(const char *subsysnqn,
+		enum nvme_subsys_type type);
+void nvmet_subsys_put(struct nvmet_subsys *subsys);
+
+struct nvmet_ns *nvmet_find_namespace(struct nvmet_ctrl *ctrl, __le32 nsid);
+void nvmet_put_namespace(struct nvmet_ns *ns);
+int nvmet_ns_enable(struct nvmet_ns *ns);
+void nvmet_ns_disable(struct nvmet_ns *ns);
+struct nvmet_ns *nvmet_ns_alloc(struct nvmet_subsys *subsys, u32 nsid);
+void nvmet_ns_free(struct nvmet_ns *ns);
+
+int nvmet_register_transport(struct nvmet_fabrics_ops *ops);
+void nvmet_unregister_transport(struct nvmet_fabrics_ops *ops);
+
+int nvmet_enable_port(struct nvmet_port *port);
+void nvmet_disable_port(struct nvmet_port *port);
+
+void nvmet_referral_enable(struct nvmet_port *parent, struct nvmet_port *port);
+void nvmet_referral_disable(struct nvmet_port *port);
+
+u16 nvmet_copy_to_sgl(struct nvmet_req *req, off_t off, const void *buf,
+		size_t len);
+u16 nvmet_copy_from_sgl(struct nvmet_req *req, off_t off, void *buf,
+		size_t len);
+
+u32 nvmet_get_log_page_len(struct nvme_command *cmd);
+
+#define NVMET_QUEUE_SIZE	1024
+#define NVMET_NR_QUEUES		64
+#define NVMET_MAX_CMD		NVMET_QUEUE_SIZE
+#define NVMET_KAS		10
+#define NVMET_DISC_KATO		120
+
+int __init nvmet_init_configfs(void);
+void __exit nvmet_exit_configfs(void);
+
+int __init nvmet_init_discovery(void);
+void nvmet_exit_discovery(void);
+
+extern struct nvmet_subsys *nvmet_disc_subsys;
+extern u64 nvmet_genctr;
+extern struct rw_semaphore nvmet_config_sem;
+
+bool nvmet_host_allowed(struct nvmet_req *req, struct nvmet_subsys *subsys,
+		const char *hostnqn);
+
+#endif /* _NVMET_H */
