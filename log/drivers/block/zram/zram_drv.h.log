commit 1d69a3f8ae77e3dbfdc1356225cce5ea9c366aec
Author: Minchan Kim <minchan@kernel.org>
Date:   Tue Jan 8 15:22:53 2019 -0800

    zram: idle writeback fixes and cleanup
    
    This patch includes some fixes and cleanup for idle-page writeback.
    
    1. writeback_limit interface
    
    Now writeback_limit interface is rather conusing.  For example, once
    writeback limit budget is exausted, admin can see 0 from
    /sys/block/zramX/writeback_limit which is same semantic with disable
    writeback_limit at this moment.  IOW, admin cannot tell that zero came
    from disable writeback limit or exausted writeback limit.
    
    To make the interface clear, let's sepatate enable of writeback limit to
    another knob - /sys/block/zram0/writeback_limit_enable
    
    * before:
      while true :
        # to re-enable writeback limit once previous one is used up
        echo 0 > /sys/block/zram0/writeback_limit
        echo $((200<<20)) > /sys/block/zram0/writeback_limit
        ..
        .. # used up the writeback limit budget
    
    * new
      # To enable writeback limit, from the beginning, admin should
      # enable it.
      echo $((200<<20)) > /sys/block/zram0/writeback_limit
      echo 1 > /sys/block/zram/0/writeback_limit_enable
      while true :
        echo $((200<<20)) > /sys/block/zram0/writeback_limit
        ..
        .. # used up the writeback limit budget
    
    It's much strightforward.
    
    2. fix condition check idle/huge writeback mode check
    
    The mode in writeback_store is not bit opeartion any more so no need to
    use bit operations.  Furthermore, current condition check is broken in
    that it does writeback every pages regardless of huge/idle.
    
    3. clean up idle_store
    
    No need to use goto.
    
    [minchan@kernel.org: missed spin_lock_init]
      Link: http://lkml.kernel.org/r/20190103001601.GA255139@google.com
    Link: http://lkml.kernel.org/r/20181224033529.19450-1-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Suggested-by: John Dias <joaodias@google.com>
    Cc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
    Cc: John Dias <joaodias@google.com>
    Cc: Srinivas Paladugu <srnvs@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 4bd3afd15e83..f2fd46daa760 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -86,7 +86,6 @@ struct zram_stats {
 	atomic64_t bd_count;		/* no. of pages in backing device */
 	atomic64_t bd_reads;		/* no. of reads from backing device */
 	atomic64_t bd_writes;		/* no. of writes from backing device */
-	atomic64_t bd_wb_limit;		/* writeback limit of backing device */
 #endif
 };
 
@@ -114,8 +113,10 @@ struct zram {
 	 */
 	bool claim; /* Protected by bdev->bd_mutex */
 	struct file *backing_dev;
-	bool stop_writeback;
 #ifdef CONFIG_ZRAM_WRITEBACK
+	spinlock_t wb_limit_lock;
+	bool wb_limit_enable;
+	u64 bd_wb_limit;
 	struct block_device *bdev;
 	unsigned int old_block_size;
 	unsigned long *bitmap;

commit bb416d18b850faaa44bd3bb67c9728922c3cce98
Author: Minchan Kim <minchan@kernel.org>
Date:   Fri Dec 28 00:36:54 2018 -0800

    zram: writeback throttle
    
    If there are lots of write IO with flash device, it could have a
    wearout problem of storage. To overcome the problem, admin needs
    to design write limitation to guarantee flash health
    for entire product life.
    
    This patch creates a new knob "writeback_limit" for zram.
    
    writeback_limit's default value is 0 so that it doesn't limit
    any writeback. If admin want to measure writeback count in a
    certain period, he could know it via /sys/block/zram0/bd_stat's
    3rd column.
    
    If admin want to limit writeback as per-day 400M, he could do it
    like below.
    
            MB_SHIFT=20
            4K_SHIFT=12
            echo $((400<<MB_SHIFT>>4K_SHIFT)) > \
                    /sys/block/zram0/writeback_limit.
    
    If admin want to allow further write again, he could do it like below
    
            echo 0 > /sys/block/zram0/writeback_limit
    
    If admin want to see remaining writeback budget,
    
            cat /sys/block/zram0/writeback_limit
    
    The writeback_limit count will reset whenever you reset zram (e.g., system
    reboot, echo 1 > /sys/block/zramX/reset) so keeping how many of writeback
    happened until you reset the zram to allocate extra writeback budget in
    next setting is user's job.
    
    [minchan@kernel.org: v4]
      Link: http://lkml.kernel.org/r/20181203024045.153534-8-minchan@kernel.org
    Link: http://lkml.kernel.org/r/20181127055429.251614-8-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Reviewed-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Joey Pabalinas <joeypabalinas@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index bc477803530d..4bd3afd15e83 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -86,6 +86,7 @@ struct zram_stats {
 	atomic64_t bd_count;		/* no. of pages in backing device */
 	atomic64_t bd_reads;		/* no. of reads from backing device */
 	atomic64_t bd_writes;		/* no. of writes from backing device */
+	atomic64_t bd_wb_limit;		/* writeback limit of backing device */
 #endif
 };
 
@@ -113,6 +114,7 @@ struct zram {
 	 */
 	bool claim; /* Protected by bdev->bd_mutex */
 	struct file *backing_dev;
+	bool stop_writeback;
 #ifdef CONFIG_ZRAM_WRITEBACK
 	struct block_device *bdev;
 	unsigned int old_block_size;

commit 23eddf39b2c28c05cb8f8203d38e61807d701b38
Author: Minchan Kim <minchan@kernel.org>
Date:   Fri Dec 28 00:36:51 2018 -0800

    zram: add bd_stat statistics
    
    bd_stat represents things that happened in the backing device.  Currently
    it supports bd_counts, bd_reads and bd_writes which are helpful to
    understand wearout of flash and memory saving.
    
    [minchan@kernel.org: v4]
      Link: http://lkml.kernel.org/r/20181203024045.153534-7-minchan@kernel.org
    Link: http://lkml.kernel.org/r/20181127055429.251614-7-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Reviewed-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Joey Pabalinas <joeypabalinas@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 1ad74f030b6d..bc477803530d 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -82,6 +82,11 @@ struct zram_stats {
 	atomic_long_t max_used_pages;	/* no. of maximum pages stored */
 	atomic64_t writestall;		/* no. of write slow paths */
 	atomic64_t miss_free;		/* no. of missed free */
+#ifdef	CONFIG_ZRAM_WRITEBACK
+	atomic64_t bd_count;		/* no. of pages in backing device */
+	atomic64_t bd_reads;		/* no. of reads from backing device */
+	atomic64_t bd_writes;		/* no. of writes from backing device */
+#endif
 };
 
 struct zram {

commit a939888ec38bf1f33e4a903056677e92a4844244
Author: Minchan Kim <minchan@kernel.org>
Date:   Fri Dec 28 00:36:47 2018 -0800

    zram: support idle/huge page writeback
    
    Add a new feature "zram idle/huge page writeback".  In the zram-swap use
    case, zram usually has many idle/huge swap pages.  It's pointless to keep
    them in memory (ie, zram).
    
    To solve this problem, this feature introduces idle/huge page writeback to
    the backing device so the goal is to save more memory space on embedded
    systems.
    
    Normal sequence to use idle/huge page writeback feature is as follows,
    
    while (1) {
            # mark allocated zram slot to idle
            echo all > /sys/block/zram0/idle
            # leave system working for several hours
            # Unless there is no access for some blocks on zram,
            # they are still IDLE marked pages.
    
            echo "idle" > /sys/block/zram0/writeback
            or/and
            echo "huge" > /sys/block/zram0/writeback
            # write the IDLE or/and huge marked slot into backing device
            # and free the memory.
    }
    
    Per the discussion at
    https://lore.kernel.org/lkml/20181122065926.GG3441@jagdpanzerIV/T/#u,
    
    This patch removes direct incommpressibe page writeback feature
    (d2afd25114f4 ("zram: write incompressible pages to backing device")).
    
    Below concerns from Sergey:
    == &< ==
    
    "IDLE writeback" is superior to "incompressible writeback".
    
    "incompressible writeback" is completely unpredictable and uncontrollable;
    it depens on data patterns and compression algorithms.  While "IDLE
    writeback" is predictable.
    
    I even suspect, that, *ideally*, we can remove "incompressible writeback".
    "IDLE pages" is a super set which also includes "incompressible" pages.
    So, technically, we still can do "incompressible writeback" from "IDLE
    writeback" path; but a much more reasonable one, based on a page idling
    period.
    
    I understand that you want to keep "direct incompressible writeback"
    around.  ZRAM is especially popular on devices which do suffer from flash
    wearout, so I can see "incompressible writeback" path becoming a dead
    code, long term.
    
    == &< ==
    
    Below concerns from Minchan:
    == &< ==
    
    My concern is if we enable CONFIG_ZRAM_WRITEBACK in this implementation,
    both hugepage/idlepage writeck will turn on.  However someuser want to
    enable only idlepage writeback so we need to introduce turn on/off knob
    for hugepage or new CONFIG_ZRAM_IDLEPAGE_WRITEBACK for those usecase.  I
    don't want to make it complicated *if possible*.
    
    Long term, I imagine we need to make VM aware of new swap hierarchy a
    little bit different with as-is.  For example, first high priority swap
    can return -EIO or -ENOCOMP, swap try to fallback to next lower priority
    swap device.  With that, hugepage writeback will work tranparently.
    
    So we could regard it as regression because incompressible pages doesn't
    go to backing storage automatically.  Instead, user should do it via "echo
    huge" > /sys/block/zram/writeback" manually.
    
    == &< ==
    
    Link: http://lkml.kernel.org/r/20181127055429.251614-6-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Reviewed-by: Joey Pabalinas <joeypabalinas@gmail.com>
    Reviewed-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index a84611b97867..1ad74f030b6d 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -47,6 +47,7 @@ enum zram_pageflags {
 	ZRAM_LOCK = ZRAM_FLAG_SHIFT,
 	ZRAM_SAME,	/* Page consists the same element */
 	ZRAM_WB,	/* page is stored on backing_device */
+	ZRAM_UNDER_WB,	/* page is under writeback */
 	ZRAM_HUGE,	/* Incompressible page */
 	ZRAM_IDLE,	/* not accessed page since last idle marking */
 

commit e82592c4fd7eafe8dec12a70436e93e3afb28556
Author: Minchan Kim <minchan@kernel.org>
Date:   Fri Dec 28 00:36:44 2018 -0800

    zram: introduce ZRAM_IDLE flag
    
    To support idle page writeback with upcoming patches, this patch
    introduces a new ZRAM_IDLE flag.
    
    Userspace can mark zram slots as "idle" via
            "echo all > /sys/block/zramX/idle"
    which marks every allocated zram slot as ZRAM_IDLE.
    User could see it by /sys/kernel/debug/zram/zram0/block_state.
    
              300    75.033841 ...i
              301    63.806904 s..i
              302    63.806919 ..hi
    
    Once there is IO for the slot, the mark will be disappeared.
    
              300    75.033841 ...
              301    63.806904 s..i
              302    63.806919 ..hi
    
    Therefore, 300th block is idle zpage. With this feature,
    user can how many zram has idle pages which are waste of memory.
    
    Link: http://lkml.kernel.org/r/20181127055429.251614-5-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Reviewed-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Reviewed-by: Joey Pabalinas <joeypabalinas@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 4f83f1f14b0a..a84611b97867 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -48,6 +48,7 @@ enum zram_pageflags {
 	ZRAM_SAME,	/* Page consists the same element */
 	ZRAM_WB,	/* page is stored on backing_device */
 	ZRAM_HUGE,	/* Incompressible page */
+	ZRAM_IDLE,	/* not accessed page since last idle marking */
 
 	__NR_ZRAM_PAGEFLAGS,
 };

commit 7e5292831b346bacb05558ca385cae366187314c
Author: Minchan Kim <minchan@kernel.org>
Date:   Fri Dec 28 00:36:40 2018 -0800

    zram: refactor flags and writeback stuff
    
    Rename some variables and restructure some code for better readability in
    writeback and zs_free_page.
    
    Link: http://lkml.kernel.org/r/20181127055429.251614-4-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Reviewed-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Reviewed-by: Joey Pabalinas <joeypabalinas@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index d1095dfdffa8..4f83f1f14b0a 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -30,7 +30,7 @@
 
 
 /*
- * The lower ZRAM_FLAG_SHIFT bits of table.value is for
+ * The lower ZRAM_FLAG_SHIFT bits of table.flags is for
  * object size (excluding header), the higher bits is for
  * zram_pageflags.
  *
@@ -41,7 +41,7 @@
  */
 #define ZRAM_FLAG_SHIFT 24
 
-/* Flags for zram pages (table[page_no].value) */
+/* Flags for zram pages (table[page_no].flags) */
 enum zram_pageflags {
 	/* zram slot is locked */
 	ZRAM_LOCK = ZRAM_FLAG_SHIFT,
@@ -60,7 +60,7 @@ struct zram_table_entry {
 		unsigned long handle;
 		unsigned long element;
 	};
-	unsigned long value;
+	unsigned long flags;
 #ifdef CONFIG_ZRAM_MEMORY_TRACKING
 	ktime_t ac_time;
 #endif
@@ -105,8 +105,8 @@ struct zram {
 	 * zram is claimed so open request will be failed
 	 */
 	bool claim; /* Protected by bdev->bd_mutex */
-#ifdef CONFIG_ZRAM_WRITEBACK
 	struct file *backing_dev;
+#ifdef CONFIG_ZRAM_WRITEBACK
 	struct block_device *bdev;
 	unsigned int old_block_size;
 	unsigned long *bitmap;

commit 3c9959e025472122a61faebb208525cf26b305d1
Author: Minchan Kim <minchan@kernel.org>
Date:   Fri Dec 28 00:36:33 2018 -0800

    zram: fix lockdep warning of free block handling
    
    Patch series "zram idle page writeback", v3.
    
    Inherently, swap device has many idle pages which are rare touched since
    it was allocated.  It is never problem if we use storage device as swap.
    However, it's just waste for zram-swap.
    
    This patchset supports zram idle page writeback feature.
    
    * Admin can define what is idle page "no access since X time ago"
    * Admin can define when zram should writeback them
    * Admin can define when zram should stop writeback to prevent wearout
    
    Details are in each patch's description.
    
    This patch (of 7):
    
      ================================
      WARNING: inconsistent lock state
      4.19.0+ #390 Not tainted
      --------------------------------
      inconsistent {SOFTIRQ-ON-W} -> {IN-SOFTIRQ-W} usage.
      zram_verify/2095 [HC0[0]:SC1[1]:HE1:SE0] takes:
      00000000b1828693 (&(&zram->bitmap_lock)->rlock){+.?.}, at: put_entry_bdev+0x1e/0x50
      {SOFTIRQ-ON-W} state was registered at:
        _raw_spin_lock+0x2c/0x40
        zram_make_request+0x755/0xdc9
        generic_make_request+0x373/0x6a0
        submit_bio+0x6c/0x140
        __swap_writepage+0x3a8/0x480
        shrink_page_list+0x1102/0x1a60
        shrink_inactive_list+0x21b/0x3f0
        shrink_node_memcg.constprop.99+0x4f8/0x7e0
        shrink_node+0x7d/0x2f0
        do_try_to_free_pages+0xe0/0x300
        try_to_free_pages+0x116/0x2b0
        __alloc_pages_slowpath+0x3f4/0xf80
        __alloc_pages_nodemask+0x2a2/0x2f0
        __handle_mm_fault+0x42e/0xb50
        handle_mm_fault+0x55/0xb0
        __do_page_fault+0x235/0x4b0
        page_fault+0x1e/0x30
      irq event stamp: 228412
      hardirqs last  enabled at (228412): [<ffffffff98245846>] __slab_free+0x3e6/0x600
      hardirqs last disabled at (228411): [<ffffffff98245625>] __slab_free+0x1c5/0x600
      softirqs last  enabled at (228396): [<ffffffff98e0031e>] __do_softirq+0x31e/0x427
      softirqs last disabled at (228403): [<ffffffff98072051>] irq_exit+0xd1/0xe0
    
      other info that might help us debug this:
       Possible unsafe locking scenario:
    
             CPU0
             ----
        lock(&(&zram->bitmap_lock)->rlock);
        <Interrupt>
          lock(&(&zram->bitmap_lock)->rlock);
    
       *** DEADLOCK ***
    
      no locks held by zram_verify/2095.
    
      stack backtrace:
      CPU: 5 PID: 2095 Comm: zram_verify Not tainted 4.19.0+ #390
      Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-1 04/01/2014
      Call Trace:
       <IRQ>
       dump_stack+0x67/0x9b
       print_usage_bug+0x1bd/0x1d3
       mark_lock+0x4aa/0x540
       __lock_acquire+0x51d/0x1300
       lock_acquire+0x90/0x180
       _raw_spin_lock+0x2c/0x40
       put_entry_bdev+0x1e/0x50
       zram_free_page+0xf6/0x110
       zram_slot_free_notify+0x42/0xa0
       end_swap_bio_read+0x5b/0x170
       blk_update_request+0x8f/0x340
       scsi_end_request+0x2c/0x1e0
       scsi_io_completion+0x98/0x650
       blk_done_softirq+0x9e/0xd0
       __do_softirq+0xcc/0x427
       irq_exit+0xd1/0xe0
       do_IRQ+0x93/0x120
       common_interrupt+0xf/0xf
       </IRQ>
    
    With writeback feature, zram_slot_free_notify could be called in softirq
    context by end_swap_bio_read.  However, bitmap_lock is not aware of that
    so lockdep yell out:
    
      get_entry_bdev
      spin_lock(bitmap->lock);
      irq
      softirq
      end_swap_bio_read
      zram_slot_free_notify
      zram_slot_lock <-- deadlock prone
      zram_free_page
      put_entry_bdev
      spin_lock(bitmap->lock); <-- deadlock prone
    
    With akpm's suggestion (i.e.  bitmap operation is already atomic), we
    could remove bitmap lock.  It might fail to find a empty slot if serious
    contention happens.  However, it's not severe problem because huge page
    writeback has already possiblity to fail if there is severe memory
    pressure.  Worst case is just keeping the incompressible in memory, not
    storage.
    
    The other problem is zram_slot_lock in zram_slot_slot_free_notify.  To
    make it safe is this patch introduces zram_slot_trylock where
    zram_slot_free_notify uses it.  Although it's rare to be contented, this
    patch adds new debug stat "miss_free" to keep monitoring how often it
    happens.
    
    Link: http://lkml.kernel.org/r/20181127055429.251614-2-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Reviewed-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Reviewed-by: Joey Pabalinas <joeypabalinas@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 72c8584b6dff..d1095dfdffa8 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -79,6 +79,7 @@ struct zram_stats {
 	atomic64_t pages_stored;	/* no. of pages currently stored */
 	atomic_long_t max_used_pages;	/* no. of maximum pages stored */
 	atomic64_t writestall;		/* no. of write slow paths */
+	atomic64_t miss_free;		/* no. of missed free */
 };
 
 struct zram {
@@ -110,7 +111,6 @@ struct zram {
 	unsigned int old_block_size;
 	unsigned long *bitmap;
 	unsigned long nr_pages;
-	spinlock_t bitmap_lock;
 #endif
 #ifdef CONFIG_ZRAM_MEMORY_TRACKING
 	struct dentry *debugfs_dir;

commit c0265342bff4fcaa2cdf13f4596244c18d4a7ae5
Author: Minchan Kim <minchan@kernel.org>
Date:   Thu Jun 7 17:05:49 2018 -0700

    zram: introduce zram memory tracking
    
    zRam as swap is useful for small memory device.  However, swap means
    those pages on zram are mostly cold pages due to VM's LRU algorithm.
    Especially, once init data for application are touched for launching,
    they tend to be not accessed any more and finally swapped out.  zRAM can
    store such cold pages as compressed form but it's pointless to keep in
    memory.  Better idea is app developers free them directly rather than
    remaining them on heap.
    
    This patch tell us last access time of each block of zram via "cat
    /sys/kernel/debug/zram/zram0/block_state".
    
    The output is as follows,
          300    75.033841 .wh
          301    63.806904 s..
          302    63.806919 ..h
    
    First column is zram's block index and 3rh one represents symbol (s:
    same page w: written page to backing store h: huge page) of the block
    state.  Second column represents usec time unit of the block was last
    accessed.  So above example means the 300th block is accessed at
    75.033851 second and it was huge so it was written to the backing store.
    
    Admin can leverage this information to catch cold|incompressible pages
    of process with *pagemap* once part of heaps are swapped out.
    
    I used the feature a few years ago to find memory hoggers in userspace
    to notify them what memory they have wasted without touch for a long
    time.  With it, they could reduce unnecessary memory space.  However, at
    that time, I hacked up zram for the feature but now I need the feature
    again so I decided it would be better to upstream rather than keeping it
    alone.  I hope I submit the userspace tool to use the feature soon.
    
    [akpm@linux-foundation.org: fix i386 printk warning]
    [minchan@kernel.org: use ktime_get_boottime() instead of sched_clock()]
      Link: http://lkml.kernel.org/r/20180420063525.GA253739@rodete-desktop-imager.corp.google.com
    [akpm@linux-foundation.org: documentation tweak]
    [akpm@linux-foundation.org: fix i386 printk warning]
    [minchan@kernel.org: fix compile warning]
      Link: http://lkml.kernel.org/r/20180508104849.GA8209@rodete-desktop-imager.corp.google.com
    [rdunlap@infradead.org: fix printk formats]
      Link: http://lkml.kernel.org/r/3652ccb1-96ef-0b0b-05d1-f661d7733dcc@infradead.org
    Link: http://lkml.kernel.org/r/20180416090946.63057-5-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
    Reviewed-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Acked-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 1075218e88b2..72c8584b6dff 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -61,7 +61,9 @@ struct zram_table_entry {
 		unsigned long element;
 	};
 	unsigned long value;
-	u64 ac_time;
+#ifdef CONFIG_ZRAM_MEMORY_TRACKING
+	ktime_t ac_time;
+#endif
 };
 
 struct zram_stats {
@@ -110,5 +112,8 @@ struct zram {
 	unsigned long nr_pages;
 	spinlock_t bitmap_lock;
 #endif
+#ifdef CONFIG_ZRAM_MEMORY_TRACKING
+	struct dentry *debugfs_dir;
+#endif
 };
 #endif

commit d7eac6b6e1838ef1a1400df4ec55daa34bbc855e
Author: Minchan Kim <minchan@kernel.org>
Date:   Thu Jun 7 17:05:45 2018 -0700

    zram: record accessed second
    
    zRam as swap is useful for small memory device.  However, swap means
    those pages on zram are mostly cold pages due to VM's LRU algorithm.
    Especially, once init data for application are touched for launching,
    they tend to be not accessed any more and finally swapped out.  zRAM can
    store such cold pages as compressed form but it's pointless to keep in
    memory.  Better idea is app developers free them directly rather than
    remaining them on heap.
    
    This patch records last access time of each block of zram so that With
    upcoming zram memory tracking, it could help userspace developers to
    reduce memory footprint.
    
    Link: http://lkml.kernel.org/r/20180416090946.63057-4-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Reviewed-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index ff0547bdb586..1075218e88b2 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -61,6 +61,7 @@ struct zram_table_entry {
 		unsigned long element;
 	};
 	unsigned long value;
+	u64 ac_time;
 };
 
 struct zram_stats {

commit 89e85bce4b02edb7408aebf69d5d1a6692a05f4f
Author: Minchan Kim <minchan@kernel.org>
Date:   Thu Jun 7 17:05:42 2018 -0700

    zram: mark incompressible page as ZRAM_HUGE
    
    Mark incompressible pages so that we could investigate who is the owner
    of the incompressible pages once the page is swapped out via using
    upcoming zram memory tracker feature.
    
    With it, we could prevent such pages to be swapped out by using mlock.
    Otherwise we might remove them.
    
    This patch exposes new stat for huge pages via mm_stat.
    
    Link: http://lkml.kernel.org/r/20180416090946.63057-3-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Reviewed-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 8d8959ceabd1..ff0547bdb586 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -47,6 +47,7 @@ enum zram_pageflags {
 	ZRAM_LOCK = ZRAM_FLAG_SHIFT,
 	ZRAM_SAME,	/* Page consists the same element */
 	ZRAM_WB,	/* page is stored on backing_device */
+	ZRAM_HUGE,	/* Incompressible page */
 
 	__NR_ZRAM_PAGEFLAGS,
 };
@@ -71,6 +72,7 @@ struct zram_stats {
 	atomic64_t invalid_io;	/* non-page-aligned I/O requests */
 	atomic64_t notify_free;	/* no. of swap slot free notifications */
 	atomic64_t same_pages;		/* no. of same element filled pages */
+	atomic64_t huge_pages;		/* no. of huge pages */
 	atomic64_t pages_stored;	/* no. of pages currently stored */
 	atomic_long_t max_used_pages;	/* no. of maximum pages stored */
 	atomic64_t writestall;		/* no. of write slow paths */

commit c4d6c4cc7bfd5ecc18548420b7fb9440cf8416ae
Author: Minchan Kim <minchan@kernel.org>
Date:   Thu Jun 7 17:05:39 2018 -0700

    zram: correct flag name of ZRAM_ACCESS
    
    Patch series "zram memory tracking", v5.
    
    zRam as swap is useful for small memory device.  However, swap means
    those pages on zram are mostly cold pages due to VM's LRU algorithm.
    Especially, once init data for application are touched for launching,
    they tend to be not accessed any more and finally swapped out.  zRAM can
    store such cold pages as compressed form but it's pointless to keep in
    memory.  As well, it's pointless to store incompressible pages to zram
    so better idea is app developers manages them directly like free or
    mlock rather than remaining them on heap.
    
    This patch provides a debugfs /sys/kernel/debug/zram/zram0/block_state
    to represent each block's state so admin can investigate what memory is
    cold|incompressible|same page with using pagemap once the pages are
    swapped out.
    
    The output is as follows:
          300    75.033841 .wh
          301    63.806904 s..
          302    63.806919 ..h
    
    First column is zram's block index and 3rh one represents symbol (s:
    same page w: written page to backing store h: huge page) of the block
    state.  Second column represents usec time unit of the block was last
    accessed.  So above example means the 300th block is accessed at
    75.033851 second and it was huge so it was written to the backing store.
    
    This patch (of 4):
    
    ZRAM_ACCESS is used for locking a slot of zram so correct the name.  It
    is also not a common flag to indicate status of the block so move the
    declare position on top of the flag.  Lastly, let's move the function to
    the top of source code to be able to use it easily without forward
    declaration.
    
    Link: http://lkml.kernel.org/r/20180416090946.63057-2-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Reviewed-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 008861220723..8d8959ceabd1 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -43,9 +43,9 @@
 
 /* Flags for zram pages (table[page_no].value) */
 enum zram_pageflags {
-	/* Page consists the same element */
-	ZRAM_SAME = ZRAM_FLAG_SHIFT,
-	ZRAM_ACCESS,	/* page is now accessed */
+	/* zram slot is locked */
+	ZRAM_LOCK = ZRAM_FLAG_SHIFT,
+	ZRAM_SAME,	/* Page consists the same element */
 	ZRAM_WB,	/* page is stored on backing_device */
 
 	__NR_ZRAM_PAGEFLAGS,

commit 3b54765cca23152ec0cc254b75c877c10f6e2870
Merge: 3fd14cdcc05a 97b1255cb27c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Apr 6 14:19:26 2018 -0700

    Merge branch 'akpm' (patches from Andrew)
    
    Merge updates from Andrew Morton:
    
     - a few misc things
    
     - ocfs2 updates
    
     - the v9fs maintainers have been missing for a long time. I've taken
       over v9fs patch slinging.
    
     - most of MM
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (116 commits)
      mm,oom_reaper: check for MMF_OOM_SKIP before complaining
      mm/ksm: fix interaction with THP
      mm/memblock.c: cast constant ULLONG_MAX to phys_addr_t
      headers: untangle kmemleak.h from mm.h
      include/linux/mmdebug.h: make VM_WARN* non-rvals
      mm/page_isolation.c: make start_isolate_page_range() fail if already isolated
      mm: change return type to vm_fault_t
      mm, oom: remove 3% bonus for CAP_SYS_ADMIN processes
      mm, page_alloc: wakeup kcompactd even if kswapd cannot free more memory
      kernel/fork.c: detect early free of a live mm
      mm: make counting of list_lru_one::nr_items lockless
      mm/swap_state.c: make bool enable_vma_readahead and swap_vma_readahead() static
      block_invalidatepage(): only release page if the full page was invalidated
      mm: kernel-doc: add missing parameter descriptions
      mm/swap.c: remove @cold parameter description for release_pages()
      mm/nommu: remove description of alloc_vm_area
      zram: drop max_zpage_size and use zs_huge_class_size()
      zsmalloc: introduce zs_huge_class_size()
      mm: fix races between swapoff and flush dcache
      fs/direct-io.c: minor cleanups in do_blockdev_direct_IO
      ...

commit 60f5921a9a4f126e081318bd6bb2bc2798b7bba8
Author: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
Date:   Thu Apr 5 16:24:47 2018 -0700

    zram: drop max_zpage_size and use zs_huge_class_size()
    
    Remove ZRAM's enforced "huge object" value and use zsmalloc huge-class
    watermark instead, which makes more sense.
    
    TEST
    - I used a 1G zram device, LZO compression back-end, original
      data set size was 444MB. Looking at zsmalloc classes stats the
      test ended up to be pretty fair.
    
    BASE ZRAM/ZSMALLOC
    =====================
    zram mm_stat
    
    498978816 191482495 199831552        0 199831552    15634        0
    
    zsmalloc classes
    
     class  size almost_full almost_empty obj_allocated   obj_used pages_used pages_per_zspage freeable
    ...
       151  2448           0            0          1240       1240        744                3        0
       168  2720           0            0          4200       4200       2800                2        0
       190  3072           0            0         10100      10100       7575                3        0
       202  3264           0            0           380        380        304                4        0
       254  4096           0            0         10620      10620      10620                1        0
    
     Total                 7           46        106982     106187      48787                         0
    
    PATCHED ZRAM/ZSMALLOC
    =====================
    
    zram mm_stat
    
    498978816 182579184 194248704        0 194248704    15628        0
    
    zsmalloc classes
    
     class  size almost_full almost_empty obj_allocated   obj_used pages_used pages_per_zspage freeable
    ...
       151  2448           0            0          1240       1240        744                3        0
       168  2720           0            0          4200       4200       2800                2        0
       190  3072           0            0         10100      10100       7575                3        0
       202  3264           0            0          7180       7180       5744                4        0
       254  4096           0            0          3820       3820       3820                1        0
    
     Total                 8           45        106959     106193      47424                         0
    
    As we can see, we reduced the number of objects stored in class-4096,
    because a huge number of objects which we previously forcibly stored in
    class-4096 now stored in non-huge class-3264.  This results in lower
    memory consumption:
    
    - zsmalloc now uses 47424 physical pages, which is less than 48787 pages
      zsmalloc used before.
    
    - objects that we store in class-3264 share zspages.  That's why overall
      the number of pages that both class-4096 and class-3264 consumed went
      down from 10924 to 9564.
    
    [sergey.senozhatsky.work@gmail.com: add pool param to zs_huge_class_size()]
      Link: http://lkml.kernel.org/r/20180314081833.1096-3-sergey.senozhatsky@gmail.com
    Link: http://lkml.kernel.org/r/20180306070639.7389-3-sergey.senozhatsky@gmail.com
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Acked-by: Minchan Kim <minchan@kernel.org>
    Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 31762db861e3..d71c8000a964 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -21,22 +21,6 @@
 
 #include "zcomp.h"
 
-/*-- Configurable parameters */
-
-/*
- * Pages that compress to size greater than this are stored
- * uncompressed in memory.
- */
-static const size_t max_zpage_size = PAGE_SIZE / 4 * 3;
-
-/*
- * NOTE: max_zpage_size must be less than or equal to:
- *   ZS_MAX_ALLOC_SIZE. Otherwise, zs_malloc() would
- * always return failure.
- */
-
-/*-- End of configurable params */
-
 #define SECTOR_SHIFT		9
 #define SECTORS_PER_PAGE_SHIFT	(PAGE_SHIFT - SECTOR_SHIFT)
 #define SECTORS_PER_PAGE	(1 << SECTORS_PER_PAGE_SHIFT)

commit 233bde21aa43516baa013ef7ac33f3427056db3e
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Wed Mar 14 15:48:06 2018 -0700

    block: Move SECTOR_SIZE and SECTOR_SHIFT definitions into <linux/blkdev.h>
    
    It happens often while I'm preparing a patch for a block driver that
    I'm wondering: is a definition of SECTOR_SIZE and/or SECTOR_SHIFT
    available for this driver? Do I have to introduce definitions of these
    constants before I can use these constants? To avoid this confusion,
    move the existing definitions of SECTOR_SIZE and SECTOR_SHIFT into the
    <linux/blkdev.h> header file such that these become available for all
    block drivers. Make the SECTOR_SIZE definition in the uapi msdos_fs.h
    header file conditional to avoid that including that header file after
    <linux/blkdev.h> causes the compiler to complain about a SECTOR_SIZE
    redefinition.
    
    Note: the SECTOR_SIZE / SECTOR_SHIFT / SECTOR_BITS definitions have
    not been removed from uapi header files nor from NAND drivers in
    which these constants are used for another purpose than converting
    block layer offsets and sizes into a number of sectors.
    
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Reviewed-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 31762db861e3..1e9bf65c0bfb 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -37,7 +37,6 @@ static const size_t max_zpage_size = PAGE_SIZE / 4 * 3;
 
 /*-- End of configurable params */
 
-#define SECTOR_SHIFT		9
 #define SECTORS_PER_PAGE_SHIFT	(PAGE_SHIFT - SECTOR_SHIFT)
 #define SECTORS_PER_PAGE	(1 << SECTORS_PER_PAGE_SHIFT)
 #define ZRAM_LOGICAL_BLOCK_SHIFT 12

commit db8ffbd4e7634cc537c8d32e73e7ce0f06248645
Author: Minchan Kim <minchan@kernel.org>
Date:   Wed Sep 6 16:20:03 2017 -0700

    zram: write incompressible pages to backing device
    
    This patch enables write IO to transfer data to backing device.  For
    that, it implements write_to_bdev function which creates new bio and
    chaining with parent bio to make the parent bio asynchrnous.
    
    For rw_page which don't have parent bio, it submit owned bio and handle
    IO completion by zram_page_end_io.
    
    Also, this patch defines new flag ZRAM_WB to mark written page for later
    read IO.
    
    [xieyisheng1@huawei.com: fix typo in comment]
      Link: http://lkml.kernel.org/r/1502707447-6944-2-git-send-email-xieyisheng1@huawei.com
    Link: http://lkml.kernel.org/r/1498459987-24562-8-git-send-email-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Signed-off-by: Yisheng Xie <xieyisheng1@huawei.com>
    Cc: Juneho Choi <juno.choi@lge.com>
    Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 707aec0a2681..31762db861e3 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -60,9 +60,10 @@ static const size_t max_zpage_size = PAGE_SIZE / 4 * 3;
 
 /* Flags for zram pages (table[page_no].value) */
 enum zram_pageflags {
-	/* Page consists entirely of zeros */
+	/* Page consists the same element */
 	ZRAM_SAME = ZRAM_FLAG_SHIFT,
 	ZRAM_ACCESS,	/* page is now accessed */
+	ZRAM_WB,	/* page is stored on backing_device */
 
 	__NR_ZRAM_PAGEFLAGS,
 };

commit 1363d4662a0d28dfdb81ef426c88c9a8dbf7c338
Author: Minchan Kim <minchan@kernel.org>
Date:   Wed Sep 6 16:19:57 2017 -0700

    zram: add free space management in backing device
    
    With backing device, zram needs management of free space of backing
    device.
    
    This patch adds bitmap logic to manage free space which is very naive.
    However, it would be simple enough as considering uncompressible pages's
    frequenty in zram.
    
    Link: http://lkml.kernel.org/r/1498459987-24562-6-git-send-email-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Juneho Choi <juno.choi@lge.com>
    Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 113a41118918..707aec0a2681 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -119,6 +119,9 @@ struct zram {
 	struct file *backing_dev;
 	struct block_device *bdev;
 	unsigned int old_block_size;
+	unsigned long *bitmap;
+	unsigned long nr_pages;
+	spinlock_t bitmap_lock;
 #endif
 };
 #endif

commit 013bf95a83ec760a2afc37fabd6bf13a9cdae205
Author: Minchan Kim <minchan@kernel.org>
Date:   Wed Sep 6 16:19:54 2017 -0700

    zram: add interface to specif backing device
    
    For writeback feature, user should set up backing device before the zram
    working.
    
    This patch enables the interface via /sys/block/zramX/backing_dev.
    
    Currently, it supports block device only but it could be enhanced for
    file as well.
    
    Link: http://lkml.kernel.org/r/1498459987-24562-5-git-send-email-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Juneho Choi <juno.choi@lge.com>
    Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index e34e44d02e3e..113a41118918 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -115,5 +115,10 @@ struct zram {
 	 * zram is claimed so open request will be failed
 	 */
 	bool claim; /* Protected by bdev->bd_mutex */
+#ifdef CONFIG_ZRAM_WRITEBACK
+	struct file *backing_dev;
+	struct block_device *bdev;
+	unsigned int old_block_size;
+#endif
 };
 #endif

commit beb6602cf87abee547b2692031185111f625153a
Author: Minchan Kim <minchan@kernel.org>
Date:   Wed May 3 14:55:47 2017 -0700

    zram: remove zram_meta structure
    
    It's redundant now.  Instead, remove it and use zram structure directly.
    
    Link: http://lkml.kernel.org/r/1492052365-16169-5-git-send-email-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index caeff51f1571..e34e44d02e3e 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -92,13 +92,9 @@ struct zram_stats {
 	atomic64_t writestall;		/* no. of write slow paths */
 };
 
-struct zram_meta {
+struct zram {
 	struct zram_table_entry *table;
 	struct zs_pool *mem_pool;
-};
-
-struct zram {
-	struct zram_meta *meta;
 	struct zcomp *comp;
 	struct gendisk *disk;
 	/* Prevent concurrent execution of device init */

commit 8e19d540d107ee897eb9a874844060c94e2376c0
Author: zhouxianrong <zhouxianrong@huawei.com>
Date:   Fri Feb 24 14:59:27 2017 -0800

    zram: extend zero pages to same element pages
    
    The idea is that without doing more calculations we extend zero pages to
    same element pages for zram.  zero page is special case of same element
    page with zero element.
    
    1. the test is done under android 7.0
    2. startup too many applications circularly
    3. sample the zero pages, same pages (none-zero element)
       and total pages in function page_zero_filled
    
    the result is listed as below:
    
    ZERO    SAME    TOTAL
    36214   17842   598196
    
                    ZERO/TOTAL       SAME/TOTAL       (ZERO+SAME)/TOTAL ZERO/SAME
    AVERAGE 0.060631909      0.024990816  0.085622726               2.663825038
    STDEV   0.00674612       0.005887625  0.009707034               2.115881328
    MAX             0.069698422      0.030046087  0.094975336               7.56043956
    MIN             0.03959586       0.007332205  0.056055193               1.928985507
    
    from the above data, the benefit is about 2.5% and up to 3% of total
    swapout pages.
    
    The defect of the patch is that when we recovery a page from non-zero
    element the operations are low efficient for partial read.
    
    This patch extends zero_page to same_page so if there is any user to
    have monitored zero_pages, he will be surprised if the number is
    increased but it's not harmful, I believe.
    
    [minchan@kernel.org: do not free same element pages in zram_meta_free]
      Link: http://lkml.kernel.org/r/20170207065741.GA2567@bbox
    Link: http://lkml.kernel.org/r/1483692145-75357-1-git-send-email-zhouxianrong@huawei.com
    Link: http://lkml.kernel.org/r/1486307804-27903-1-git-send-email-minchan@kernel.org
    Signed-off-by: zhouxianrong <zhouxianrong@huawei.com>
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 2692554b7737..caeff51f1571 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -61,7 +61,7 @@ static const size_t max_zpage_size = PAGE_SIZE / 4 * 3;
 /* Flags for zram pages (table[page_no].value) */
 enum zram_pageflags {
 	/* Page consists entirely of zeros */
-	ZRAM_ZERO = ZRAM_FLAG_SHIFT,
+	ZRAM_SAME = ZRAM_FLAG_SHIFT,
 	ZRAM_ACCESS,	/* page is now accessed */
 
 	__NR_ZRAM_PAGEFLAGS,
@@ -71,7 +71,10 @@ enum zram_pageflags {
 
 /* Allocated for each disk page */
 struct zram_table_entry {
-	unsigned long handle;
+	union {
+		unsigned long handle;
+		unsigned long element;
+	};
 	unsigned long value;
 };
 
@@ -83,7 +86,7 @@ struct zram_stats {
 	atomic64_t failed_writes;	/* can happen when memory is too low */
 	atomic64_t invalid_io;	/* non-page-aligned I/O requests */
 	atomic64_t notify_free;	/* no. of swap slot free notifications */
-	atomic64_t zero_pages;		/* no. of zero filled pages */
+	atomic64_t same_pages;		/* no. of same element filled pages */
 	atomic64_t pages_stored;	/* no. of pages currently stored */
 	atomic_long_t max_used_pages;	/* no. of maximum pages stored */
 	atomic64_t writestall;		/* no. of write slow paths */

commit a09759acaacf6cf738e1bc6c66d41485c87fd371
Author: Minchan Kim <minchan@kernel.org>
Date:   Fri Feb 24 14:56:47 2017 -0800

    zram: remove waitqueue for IO done
    
    zram_reset_device() waits for ongoing writepage pages to be completed by
    zram->refcount logic.  However, it's pointless because before the reset,
    we prevent further opening of zram by zram->claim and flush all of
    pending IO by fsync_bdev so there should be no pending IO at the
    zram_reset_device().
    
    So let's remove that code which is even broken due to the lack of
    wake_up elsewhere.
    
    Link: http://lkml.kernel.org/r/1485145031-11661-1-git-send-email-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Reviewed-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 74fcf10da374..2692554b7737 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -106,9 +106,6 @@ struct zram {
 	unsigned long limit_pages;
 
 	struct zram_stats stats;
-	atomic_t refcount; /* refcount for zram_meta */
-	/* wait all IO under all of cpu are done */
-	wait_queue_head_t io_done;
 	/*
 	 * This is the limit on amount of *uncompressed* worth of data
 	 * we can store in a disk.

commit 415403be37e204632b17bdb6857890fe5a220cea
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Tue Jul 26 15:22:48 2016 -0700

    zram: use crypto api to check alg availability
    
    There is no way to get a string with all the crypto comp algorithms
    supported by the crypto comp engine, so we need to maintain our own
    backends list.  At the same time we additionally need to use
    crypto_has_comp() to make sure that the user has requested a compression
    algorithm that is recognized by the crypto comp engine.  Relying on
    /proc/crypto is not an options here, because it does not show
    not-yet-inserted compression modules.
    
    Example:
    
     modprobe zram
     cat /proc/crypto | grep -i lz4
     modprobe lz4
     cat /proc/crypto | grep -i lz4
    name         : lz4
    driver       : lz4-generic
    module       : lz4
    
    So the user can't tell exactly if the lz4 is really supported from
    /proc/crypto output, unless someone or something has loaded it.
    
    This patch also adds crypto_has_comp() to zcomp_available_show().  We
    store all the compression algorithms names in zcomp's `backends' array,
    regardless the CONFIG_CRYPTO_FOO configuration, but show only those that
    are also supported by crypto engine.  This helps user to know the exact
    list of compression algorithms that can be used.
    
    Example:
      module lz4 is not loaded yet, but is supported by the crypto
      engine. /proc/crypto has no information on this module, while
      zram's `comp_algorithm' lists it:
    
     cat /proc/crypto | grep -i lz4
    
     cat /sys/block/zram0/comp_algorithm
    [lzo] lz4 deflate lz4hc 842
    
    We still use the `backends' array to determine if the requested
    compression backend is known to crypto api.  This array, however, may not
    contain some entries, therefore as the last step we call crypto_has_comp()
    function which attempts to insmod the requested compression algorithm to
    determine if crypto api supports it.  The advantage of this method is that
    now we permit the usage of out-of-tree crypto compression modules
    (implementing S/W or H/W compression).
    
    [sergey.senozhatsky@gmail.com: zram-use-crypto-api-to-check-alg-availability-v3]
      Link: http://lkml.kernel.org/r/20160604024902.11778-4-sergey.senozhatsky@gmail.com
    Link: http://lkml.kernel.org/r/20160531122017.2878-5-sergey.senozhatsky@gmail.com
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Acked-by: Minchan Kim <minchan@kernel.org>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 3f5bf66a27e4..74fcf10da374 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -15,8 +15,9 @@
 #ifndef _ZRAM_DRV_H_
 #define _ZRAM_DRV_H_
 
-#include <linux/spinlock.h>
+#include <linux/rwsem.h>
 #include <linux/zsmalloc.h>
+#include <linux/crypto.h>
 
 #include "zcomp.h"
 
@@ -113,7 +114,7 @@ struct zram {
 	 * we can store in a disk.
 	 */
 	u64 disksize;	/* bytes */
-	char compressor[10];
+	char compressor[CRYPTO_MAX_ALG_NAME];
 	/*
 	 * zram is claimed so open request will be failed
 	 */

commit 623e47fc64f8de480b322b7ed68855f97137e2a5
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Fri May 20 17:00:02 2016 -0700

    zram: introduce per-device debug_stat sysfs node
    
    debug_stat sysfs is read-only and represents various debugging data that
    zram developers may need.  This file is not meant to be used by anyone
    else: its content is not documented and will change any time w/o any
    notice.  Therefore, the output of debug_stat file contains a version
    string.  To avoid any confusion, we will increase the version number
    every time we modify the output.
    
    At the moment this file exports only one value -- the number of
    re-compressions, IOW, the number of times compression fast path has
    failed.  This stat is temporary any will be useful in case if any
    per-cpu compression streams regressions will be reported.
    
    Link: http://lkml.kernel.org/r/20160513230834.GB26763@bbox
    Link: http://lkml.kernel.org/r/20160511134553.12655-1-sergey.senozhatsky@gmail.com
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 06b1636f4722..3f5bf66a27e4 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -85,6 +85,7 @@ struct zram_stats {
 	atomic64_t zero_pages;		/* no. of zero filled pages */
 	atomic64_t pages_stored;	/* no. of pages currently stored */
 	atomic_long_t max_used_pages;	/* no. of maximum pages stored */
+	atomic64_t writestall;		/* no. of write slow paths */
 };
 
 struct zram_meta {

commit 43209ea2d17aae1540d4e28274e36404f72702f2
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Fri May 20 16:59:59 2016 -0700

    zram: remove max_comp_streams internals
    
    Remove the internal part of max_comp_streams interface, since we
    switched to per-cpu streams.  We will keep RW max_comp_streams attr
    around, because:
    
    a) we may (silently) switch back to idle compression streams list and
       don't want to disturb user space
    
    b) max_comp_streams attr must wait for the next 'lay off cycle'; we
       give user space 2 years to adjust before we remove/downgrade the attr,
       and there are already several attrs scheduled for removal in 4.11, so
       it's too late for max_comp_streams.
    
    This slightly change a user visible behaviour:
    
    - First, reading from max_comp_stream file now will always return the
      number of online CPUs.
    
    - Second, writing to max_comp_stream will not take any effect.
    
    Link: http://lkml.kernel.org/r/20160503165546.25201-1-sergey.senozhatsky@gmail.com
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 8e92339686d7..06b1636f4722 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -102,7 +102,6 @@ struct zram {
 	 * the number of pages zram can consume for storing compressed data
 	 */
 	unsigned long limit_pages;
-	int max_comp_streams;
 
 	struct zram_stats stats;
 	atomic_t refcount; /* refcount for zram_meta */

commit 7d3f3938236b4bb878214e6791e76fd8409bdeee
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Tue Sep 8 15:04:35 2015 -0700

    zsmalloc/zram: introduce zs_pool_stats api
    
    `zs_compact_control' accounts the number of migrated objects but it has
    a limited lifespan -- we lose it as soon as zs_compaction() returns back
    to zram.  It worked fine, because (a) zram had it's own counter of
    migrated objects and (b) only zram could trigger compaction.  However,
    this does not work for automatic pool compaction (not issued by zram).
    To account objects migrated during auto-compaction (issued by the
    shrinker) we need to store this number in zs_pool.
    
    Define a new `struct zs_pool_stats' structure to keep zs_pool's stats
    there.  It provides only `num_migrated', as of this writing, but it
    surely can be extended.
    
    A new zsmalloc zs_pool_stats() symbol exports zs_pool's stats back to
    caller.
    
    Use zs_pool_stats() in zram and remove `num_migrated' from zram_stats.
    
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Suggested-by: Minchan Kim <minchan@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 6dbe2df506bf..8e92339686d7 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -78,7 +78,6 @@ struct zram_stats {
 	atomic64_t compr_data_size;	/* compressed size of pages stored */
 	atomic64_t num_reads;	/* failed + successful */
 	atomic64_t num_writes;	/* --do-- */
-	atomic64_t num_migrated;	/* no. of migrated object */
 	atomic64_t failed_reads;	/* can happen when memory is too low */
 	atomic64_t failed_writes;	/* can happen when memory is too low */
 	atomic64_t invalid_io;	/* non-page-aligned I/O requests */

commit f405c445a4866caa43101c231721123805a23bbf
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Thu Jun 25 15:00:21 2015 -0700

    zram: close race by open overriding
    
    [ Original patch from Minchan Kim <minchan@kernel.org> ]
    
    Commit ba6b17d68c8e ("zram: fix umount-reset_store-mount race
    condition") introduced bdev->bd_mutex to protect a race between mount
    and reset.  At that time, we don't have dynamic zram-add/remove feature
    so it was okay.
    
    However, as we introduce dynamic device feature, bd_mutex became
    trouble.
    
            CPU 0
    
    echo 1 > /sys/block/zram<id>/reset
      -> kernfs->s_active(A)
        -> zram:reset_store->bd_mutex(B)
    
            CPU 1
    
    echo <id> > /sys/class/zram/zram-remove
      ->zram:zram_remove: bd_mutex(B)
      -> sysfs_remove_group
        -> kernfs->s_active(A)
    
    IOW, AB -> BA deadlock
    
    The reason we are holding bd_mutex for zram_remove is to prevent
    any incoming open /dev/zram[0-9]. Otherwise, we could remove zram
    others already have opened. But it causes above deadlock problem.
    
    To fix the problem, this patch overrides block_device.open and
    it returns -EBUSY if zram asserts he claims zram to reset so any
    incoming open will be failed so we don't need to hold bd_mutex
    for zram_remove ayn more.
    
    This patch is to prepare for zram-add/remove feature.
    
    [sergey.senozhatsky@gmail.com: simplify reset_store()]
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Acked-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 042994e807cf..6dbe2df506bf 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -115,5 +115,9 @@ struct zram {
 	 */
 	u64 disksize;	/* bytes */
 	char compressor[10];
+	/*
+	 * zram is claimed so open request will be failed
+	 */
+	bool claim; /* Protected by bdev->bd_mutex */
 };
 #endif

commit c3cdb40e66344553898daa3ccd068c03173a3f42
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Thu Jun 25 15:00:11 2015 -0700

    zram: remove max_num_devices limitation
    
    Limiting the number of zram devices to 32 (default max_num_devices value)
    is confusing, let's drop it.  A user with 2TB or 4TB of RAM, for example,
    can request as many devices as he can handle.
    
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Acked-by: Minchan Kim <minchan@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 570c598f4ce9..042994e807cf 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -20,12 +20,6 @@
 
 #include "zcomp.h"
 
-/*
- * Some arbitrary value. This is just to catch
- * invalid value for num_devices module parameter.
- */
-static const unsigned max_num_devices = 32;
-
 /*-- Configurable parameters */
 
 /*

commit 4e3ba87845420e0bfa21e6c4f7f81897aed38f8c
Author: Minchan Kim <minchan@kernel.org>
Date:   Wed Apr 15 16:15:36 2015 -0700

    zram: support compaction
    
    Now that zsmalloc supports compaction, zram can use it.  For the first
    step, this patch exports compact knob via sysfs so user can do compaction
    via "echo 1 > /sys/block/zram0/compact".
    
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Juneho Choi <juno.choi@lge.com>
    Cc: Gunho Lee <gunho.lee@lge.com>
    Cc: Luigi Semenzato <semenzato@google.com>
    Cc: Dan Streetman <ddstreet@ieee.org>
    Cc: Seth Jennings <sjennings@variantweb.net>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 17056e589146..570c598f4ce9 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -84,6 +84,7 @@ struct zram_stats {
 	atomic64_t compr_data_size;	/* compressed size of pages stored */
 	atomic64_t num_reads;	/* failed + successful */
 	atomic64_t num_writes;	/* --do-- */
+	atomic64_t num_migrated;	/* no. of migrated object */
 	atomic64_t failed_reads;	/* can happen when memory is too low */
 	atomic64_t failed_writes;	/* can happen when memory is too low */
 	atomic64_t invalid_io;	/* non-page-aligned I/O requests */

commit ee98016010ae036a5b27300d83bd99ef3fd5776e
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Thu Feb 12 15:00:48 2015 -0800

    zram: remove request_queue from struct zram
    
    `struct zram' contains both `struct gendisk' and `struct request_queue'.
    the latter can be deleted, because zram->disk carries ->queue pointer, and
    ->queue carries zram pointer:
    
    create_device()
            zram->queue->queuedata = zram
            zram->disk->queue = zram->queue
            zram->disk->private_data = zram
    
    so zram->queue is not needed, we can access all necessary data anyway.
    
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 5249f51ccdb3..17056e589146 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -101,7 +101,6 @@ struct zram_meta {
 struct zram {
 	struct zram_meta *meta;
 	struct zcomp *comp;
-	struct request_queue *queue;
 	struct gendisk *disk;
 	/* Prevent concurrent execution of device init */
 	struct rw_semaphore init_lock;

commit 08eee69fcf6baea543a2b4d2a2fcba0e61aa3160
Author: Minchan Kim <minchan@kernel.org>
Date:   Thu Feb 12 15:00:45 2015 -0800

    zram: remove init_lock in zram_make_request
    
    Admin could reset zram during I/O operation going on so we have used
    zram->init_lock as read-side lock in I/O path to prevent sudden zram
    meta freeing.
    
    However, the init_lock is really troublesome.  We can't do call
    zram_meta_alloc under init_lock due to lockdep splat because
    zram_rw_page is one of the function under reclaim path and hold it as
    read_lock while other places in process context hold it as write_lock.
    So, we have used allocation out of the lock to avoid lockdep warn but
    it's not good for readability and fainally, I met another lockdep splat
    between init_lock and cpu_hotplug from kmem_cache_destroy during working
    zsmalloc compaction.  :(
    
    Yes, the ideal is to remove horrible init_lock of zram in rw path.  This
    patch removes it in rw path and instead, add atomic refcount for meta
    lifetime management and completion to free meta in process context.
    It's important to free meta in process context because some of resource
    destruction needs mutex lock, which could be held if we releases the
    resource in reclaim context so it's deadlock, again.
    
    As a bonus, we could remove init_done check in rw path because
    zram_meta_get will do a role for it, instead.
    
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Cc: Ganesh Mahendran <opensource.ganesh@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index b05a816b09ac..5249f51ccdb3 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -100,24 +100,26 @@ struct zram_meta {
 
 struct zram {
 	struct zram_meta *meta;
+	struct zcomp *comp;
 	struct request_queue *queue;
 	struct gendisk *disk;
-	struct zcomp *comp;
-
-	/* Prevent concurrent execution of device init, reset and R/W request */
+	/* Prevent concurrent execution of device init */
 	struct rw_semaphore init_lock;
 	/*
-	 * This is the limit on amount of *uncompressed* worth of data
-	 * we can store in a disk.
+	 * the number of pages zram can consume for storing compressed data
 	 */
-	u64 disksize;	/* bytes */
+	unsigned long limit_pages;
 	int max_comp_streams;
+
 	struct zram_stats stats;
+	atomic_t refcount; /* refcount for zram_meta */
+	/* wait all IO under all of cpu are done */
+	wait_queue_head_t io_done;
 	/*
-	 * the number of pages zram can consume for storing compressed data
+	 * This is the limit on amount of *uncompressed* worth of data
+	 * we can store in a disk.
 	 */
-	unsigned long limit_pages;
-
+	u64 disksize;	/* bytes */
 	char compressor[10];
 };
 #endif

commit d49b1c254c997195872a9e8913660a788298921e
Author: Mahendran Ganesh <opensource.ganesh@gmail.com>
Date:   Fri Dec 12 16:57:04 2014 -0800

    mm/zram: correct ZRAM_ZERO flag bit position
    
    In struct zram_table_entry, the element *value* contains obj size and obj
    zram flags.  Bit 0 to bit (ZRAM_FLAG_SHIFT - 1) represent obj size, and
    bit ZRAM_FLAG_SHIFT to the highest bit of unsigned long represent obj
    zram_flags.  So the first zram flag(ZRAM_ZERO) should be from
    ZRAM_FLAG_SHIFT instead of (ZRAM_FLAG_SHIFT + 1).
    
    This patch fixes this cosmetic issue.
    
    Also fix a typo, "page in now accessed" -> "page is now accessed"
    
    Signed-off-by: Mahendran Ganesh <opensource.ganesh@gmail.com>
    Acked-by: Minchan Kim <minchan@kernel.org>
    Acked-by: Weijie Yang <weijie.yang@samsung.com>
    Acked-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index c6ee271317f5..b05a816b09ac 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -66,8 +66,8 @@ static const size_t max_zpage_size = PAGE_SIZE / 4 * 3;
 /* Flags for zram pages (table[page_no].value) */
 enum zram_pageflags {
 	/* Page consists entirely of zeros */
-	ZRAM_ZERO = ZRAM_FLAG_SHIFT + 1,
-	ZRAM_ACCESS,	/* page in now accessed */
+	ZRAM_ZERO = ZRAM_FLAG_SHIFT,
+	ZRAM_ACCESS,	/* page is now accessed */
 
 	__NR_ZRAM_PAGEFLAGS,
 };

commit 461a8eee6af3b55745be64bea403ed0b743563cf
Author: Minchan Kim <minchan@kernel.org>
Date:   Thu Oct 9 15:29:55 2014 -0700

    zram: report maximum used memory
    
    Normally, zram user could get maximum memory usage zram consumed via
    polling mem_used_total with sysfs in userspace.
    
    But it has a critical problem because user can miss peak memory usage
    during update inverval of polling.  For avoiding that, user should poll it
    with shorter interval(ie, 0.0000000001s) with mlocking to avoid page fault
    delay when memory pressure is heavy.  It would be troublesome.
    
    This patch adds new knob "mem_used_max" so user could see the maximum
    memory usage easily via reading the knob and reset it via "echo 0 >
    /sys/block/zram0/mem_used_max".
    
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Reviewed-by: Dan Streetman <ddstreet@ieee.org>
    Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Cc: <juno.choi@lge.com>
    Cc: <seungho1.park@lge.com>
    Cc: Luigi Semenzato <semenzato@google.com>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Cc: Seth Jennings <sjennings@variantweb.net>
    Reviewed-by: David Horner <ds2horner@gmail.com>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index b7aa9c21553f..c6ee271317f5 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -90,6 +90,7 @@ struct zram_stats {
 	atomic64_t notify_free;	/* no. of swap slot free notifications */
 	atomic64_t zero_pages;		/* no. of zero filled pages */
 	atomic64_t pages_stored;	/* no. of pages currently stored */
+	atomic_long_t max_used_pages;	/* no. of maximum pages stored */
 };
 
 struct zram_meta {

commit 9ada9da9573f3460b156b7755c093e30b258eacb
Author: Minchan Kim <minchan@kernel.org>
Date:   Thu Oct 9 15:29:53 2014 -0700

    zram: zram memory size limitation
    
    Since zram has no control feature to limit memory usage, it makes hard to
    manage system memrory.
    
    This patch adds new knob "mem_limit" via sysfs to set up the a limit so
    that zram could fail allocation once it reaches the limit.
    
    In addition, user could change the limit in runtime so that he could
    manage the memory more dynamically.
    
    Initial state is no limit so it doesn't break old behavior.
    
    [akpm@linux-foundation.org: fix typo, per Sergey]
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Dan Streetman <ddstreet@ieee.org>
    Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Cc: <juno.choi@lge.com>
    Cc: <seungho1.park@lge.com>
    Cc: Luigi Semenzato <semenzato@google.com>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Cc: Seth Jennings <sjennings@variantweb.net>
    Cc: David Horner <ds2horner@gmail.com>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index e0f725c87cc6..b7aa9c21553f 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -112,6 +112,11 @@ struct zram {
 	u64 disksize;	/* bytes */
 	int max_comp_streams;
 	struct zram_stats stats;
+	/*
+	 * the number of pages zram can consume for storing compressed data
+	 */
+	unsigned long limit_pages;
+
 	char compressor[10];
 };
 #endif

commit 0cf1e9d6c34d4c82ac3af8015594849814843d36
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Fri Aug 29 15:18:37 2014 -0700

    zram: fix incorrect stat with failed_reads
    
    Since we allocate a temporary buffer in zram_bvec_read to handle partial
    page operations in commit 924bd88d703e ("Staging: zram: allow partial
    page operations"), our ->failed_reads value may be incorrect as we do
    not increase its value when failing to allocate the temporary buffer.
    
    Let's fix this issue and correct the annotation of failed_reads.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Acked-by: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Acked-by: Jerome Marchand <jmarchan@redhat.com>
    Acked-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 5b0afde729cd..e0f725c87cc6 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -84,7 +84,7 @@ struct zram_stats {
 	atomic64_t compr_data_size;	/* compressed size of pages stored */
 	atomic64_t num_reads;	/* failed + successful */
 	atomic64_t num_writes;	/* --do-- */
-	atomic64_t failed_reads;	/* should NEVER! happen */
+	atomic64_t failed_reads;	/* can happen when memory is too low */
 	atomic64_t failed_writes;	/* can happen when memory is too low */
 	atomic64_t invalid_io;	/* non-page-aligned I/O requests */
 	atomic64_t notify_free;	/* no. of swap slot free notifications */

commit d2d5e762c8990c4031890e03565983a05febd64a
Author: Weijie Yang <weijie.yang@samsung.com>
Date:   Wed Aug 6 16:08:31 2014 -0700

    zram: replace global tb_lock with fine grain lock
    
    Currently, we use a rwlock tb_lock to protect concurrent access to the
    whole zram meta table.  However, according to the actual access model,
    there is only a small chance for upper user to access the same
    table[index], so the current lock granularity is too big.
    
    The idea of optimization is to change the lock granularity from whole
    meta table to per table entry (table -> table[index]), so that we can
    protect concurrent access to the same table[index], meanwhile allow the
    maximum concurrency.
    
    With this in mind, several kinds of locks which could be used as a
    per-entry lock were tested and compared:
    
    Test environment:
    x86-64 Intel Core2 Q8400, system memory 4GB, Ubuntu 12.04,
    kernel v3.15.0-rc3 as base, zram with 4 max_comp_streams LZO.
    
    iozone test:
    iozone -t 4 -R -r 16K -s 200M -I +Z
    (1GB zram with ext4 filesystem, take the average of 10 tests, KB/s)
    
          Test       base      CAS    spinlock    rwlock   bit_spinlock
    -------------------------------------------------------------------
     Initial write  1381094   1425435   1422860   1423075   1421521
           Rewrite  1529479   1641199   1668762   1672855   1654910
              Read  8468009  11324979  11305569  11117273  10997202
           Re-read  8467476  11260914  11248059  11145336  10906486
      Reverse Read  6821393   8106334   8282174   8279195   8109186
       Stride read  7191093   8994306   9153982   8961224   9004434
       Random read  7156353   8957932   9167098   8980465   8940476
    Mixed workload  4172747   5680814   5927825   5489578   5972253
      Random write  1483044   1605588   1594329   1600453   1596010
            Pwrite  1276644   1303108   1311612   1314228   1300960
             Pread  4324337   4632869   4618386   4457870   4500166
    
    To enhance the possibility of access the same table[index] concurrently,
    set zram a small disksize(10MB) and let threads run with large loop
    count.
    
    fio test:
    fio --bs=32k --randrepeat=1 --randseed=100 --refill_buffers
    --scramble_buffers=1 --direct=1 --loops=3000 --numjobs=4
    --filename=/dev/zram0 --name=seq-write --rw=write --stonewall
    --name=seq-read --rw=read --stonewall --name=seq-readwrite
    --rw=rw --stonewall --name=rand-readwrite --rw=randrw --stonewall
    (10MB zram raw block device, take the average of 10 tests, KB/s)
    
        Test     base     CAS    spinlock    rwlock  bit_spinlock
    -------------------------------------------------------------
    seq-write   933789   999357   1003298    995961   1001958
     seq-read  5634130  6577930   6380861   6243912   6230006
       seq-rw  1405687  1638117   1640256   1633903   1634459
      rand-rw  1386119  1614664   1617211   1609267   1612471
    
    All the optimization methods show a higher performance than the base,
    however, it is hard to say which method is the most appropriate.
    
    On the other hand, zram is mostly used on small embedded system, so we
    don't want to increase any memory footprint.
    
    This patch pick the bit_spinlock method, pack object size and page_flag
    into an unsigned long table.value, so as to not increase any memory
    overhead on both 32-bit and 64-bit system.
    
    On the third hand, even though different kinds of locks have different
    performances, we can ignore this difference, because: if zram is used as
    zram swapfile, the swap subsystem can prevent concurrent access to the
    same swapslot; if zram is used as zram-blk for set up filesystem on it,
    the upper filesystem and the page cache also prevent concurrent access
    of the same block mostly.  So we can ignore the different performances
    among locks.
    
    Acked-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Reviewed-by: Davidlohr Bueso <davidlohr@hp.com>
    Signed-off-by: Weijie Yang <weijie.yang@samsung.com>
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index c8161bd8969c..5b0afde729cd 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -50,10 +50,24 @@ static const size_t max_zpage_size = PAGE_SIZE / 4 * 3;
 #define ZRAM_SECTOR_PER_LOGICAL_BLOCK	\
 	(1 << (ZRAM_LOGICAL_BLOCK_SHIFT - SECTOR_SHIFT))
 
-/* Flags for zram pages (table[page_no].flags) */
+
+/*
+ * The lower ZRAM_FLAG_SHIFT bits of table.value is for
+ * object size (excluding header), the higher bits is for
+ * zram_pageflags.
+ *
+ * zram is mainly used for memory efficiency so we want to keep memory
+ * footprint small so we can squeeze size and flags into a field.
+ * The lower ZRAM_FLAG_SHIFT bits is for object size (excluding header),
+ * the higher bits is for zram_pageflags.
+ */
+#define ZRAM_FLAG_SHIFT 24
+
+/* Flags for zram pages (table[page_no].value) */
 enum zram_pageflags {
 	/* Page consists entirely of zeros */
-	ZRAM_ZERO,
+	ZRAM_ZERO = ZRAM_FLAG_SHIFT + 1,
+	ZRAM_ACCESS,	/* page in now accessed */
 
 	__NR_ZRAM_PAGEFLAGS,
 };
@@ -63,9 +77,8 @@ enum zram_pageflags {
 /* Allocated for each disk page */
 struct zram_table_entry {
 	unsigned long handle;
-	u16 size;	/* object size (excluding header) */
-	u8 flags;
-} __aligned(4);
+	unsigned long value;
+};
 
 struct zram_stats {
 	atomic64_t compr_data_size;	/* compressed size of pages stored */
@@ -80,7 +93,6 @@ struct zram_stats {
 };
 
 struct zram_meta {
-	rwlock_t tb_lock;	/* protect table */
 	struct zram_table_entry *table;
 	struct zs_pool *mem_pool;
 };

commit a830eff749eb2bf906783f6bf74a74dad3de3aea
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Wed Aug 6 16:08:27 2014 -0700

    zram: remove unused SECTOR_SIZE define
    
    Drop SECTOR_SIZE define, because it's not used.
    
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Cc: Weijie Yang <weijie.yang@samsung.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 8909f86caf0d..c8161bd8969c 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -43,7 +43,6 @@ static const size_t max_zpage_size = PAGE_SIZE / 4 * 3;
 /*-- End of configurable params */
 
 #define SECTOR_SHIFT		9
-#define SECTOR_SIZE		(1 << SECTOR_SHIFT)
 #define SECTORS_PER_PAGE_SHIFT	(PAGE_SHIFT - SECTOR_SHIFT)
 #define SECTORS_PER_PAGE	(1 << SECTORS_PER_PAGE_SHIFT)
 #define ZRAM_LOGICAL_BLOCK_SHIFT 12

commit cb8f2eec3c5c87e31219c5e58625b8e890004e48
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Wed Aug 6 16:08:25 2014 -0700

    zram: rename struct `table' to `zram_table_entry'
    
    Andrew Morton has recently noted that `struct table' actually represents
    table entry and, thus, should be renamed.  Rename to `zram_table_entry'.
    
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Cc: Weijie Yang <weijie.yang@samsung.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 7f21c145e317..8909f86caf0d 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -62,7 +62,7 @@ enum zram_pageflags {
 /*-- Data structures */
 
 /* Allocated for each disk page */
-struct table {
+struct zram_table_entry {
 	unsigned long handle;
 	u16 size;	/* object size (excluding header) */
 	u8 flags;
@@ -82,7 +82,7 @@ struct zram_stats {
 
 struct zram_meta {
 	rwlock_t tb_lock;	/* protect table */
-	struct table *table;
+	struct zram_table_entry *table;
 	struct zs_pool *mem_pool;
 };
 

commit e46b8a030d76d3c94156c545c3f4c3676d813435
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Mon Apr 7 15:38:17 2014 -0700

    zram: make compression algorithm selection possible
    
    Add and document `comp_algorithm' device attribute.  This attribute allows
    to show supported compression and currently selected compression
    algorithms:
    
            cat /sys/block/zram0/comp_algorithm
            [lzo] lz4
    
    and change selected compression algorithm:
            echo lzo > /sys/block/zram0/comp_algorithm
    
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Acked-by: Minchan Kim <minchan@kernel.org>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index ccf36d11755a..7f21c145e317 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -101,5 +101,6 @@ struct zram {
 	u64 disksize;	/* bytes */
 	int max_comp_streams;
 	struct zram_stats stats;
+	char compressor[10];
 };
 #endif

commit beca3ec71fe5490ee9237dc42400f50402baf83e
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Mon Apr 7 15:38:14 2014 -0700

    zram: add multi stream functionality
    
    Existing zram (zcomp) implementation has only one compression stream
    (buffer and algorithm private part), so in order to prevent data
    corruption only one write (compress operation) can use this compression
    stream, forcing all concurrent write operations to wait for stream lock
    to be released.  This patch changes zcomp to keep a compression streams
    list of user-defined size (via sysfs device attr).  Each write operation
    still exclusively holds compression stream, the difference is that we
    can have N write operations (depending on size of streams list)
    executing in parallel.  See TEST section later in commit message for
    performance data.
    
    Introduce struct zcomp_strm_multi and a set of functions to manage
    zcomp_strm stream access.  zcomp_strm_multi has a list of idle
    zcomp_strm structs, spinlock to protect idle list and wait queue, making
    it possible to perform parallel compressions.
    
    The following set of functions added:
    - zcomp_strm_multi_find()/zcomp_strm_multi_release()
      find and release a compression stream, implement required locking
    - zcomp_strm_multi_create()/zcomp_strm_multi_destroy()
      create and destroy zcomp_strm_multi
    
    zcomp ->strm_find() and ->strm_release() callbacks are set during
    initialisation to zcomp_strm_multi_find()/zcomp_strm_multi_release()
    correspondingly.
    
    Each time zcomp issues a zcomp_strm_multi_find() call, the following set
    of operations performed:
    
    - spin lock strm_lock
    - if idle list is not empty, remove zcomp_strm from idle list, spin
      unlock and return zcomp stream pointer to caller
    - if idle list is empty, current adds itself to wait queue. it will be
      awaken by zcomp_strm_multi_release() caller.
    
    zcomp_strm_multi_release():
    - spin lock strm_lock
    - add zcomp stream to idle list
    - spin unlock, wake up sleeper
    
    Minchan Kim reported that spinlock-based locking scheme has demonstrated
    a severe perfomance regression for single compression stream case,
    comparing to mutex-based (see https://lkml.org/lkml/2014/2/18/16)
    
    base                      spinlock                    mutex
    
    ==Initial write           ==Initial write             ==Initial  write
    records:  5               records:  5                 records:   5
    avg:      1642424.35      avg:      699610.40         avg:       1655583.71
    std:      39890.95(2.43%) std:      232014.19(33.16%) std:       52293.96
    max:      1690170.94      max:      1163473.45        max:       1697164.75
    min:      1568669.52      min:      573429.88         min:       1553410.23
    ==Rewrite                 ==Rewrite                   ==Rewrite
    records:  5               records:  5                 records:   5
    avg:      1611775.39      avg:      501406.64         avg:       1684419.11
    std:      17144.58(1.06%) std:      15354.41(3.06%)   std:       18367.42
    max:      1641800.95      max:      531356.78         max:       1706445.84
    min:      1593515.27      min:      488817.78         min:       1655335.73
    
    When only one compression stream available, mutex with spin on owner
    tends to perform much better than frequent wait_event()/wake_up().  This
    is why single stream implemented as a special case with mutex locking.
    
    Introduce and document zram device attribute max_comp_streams.  This
    attr shows and stores current zcomp's max number of zcomp streams
    (max_strm).  Extend zcomp's zcomp_create() with `max_strm' parameter.
    `max_strm' limits the number of zcomp_strm structs in compression
    backend's idle list (max_comp_streams).
    
    max_comp_streams used during initialisation as follows:
    -- passing to zcomp_create() max_strm equals to 1 will initialise zcomp
    using single compression stream zcomp_strm_single (mutex-based locking).
    -- passing to zcomp_create() max_strm greater than 1 will initialise zcomp
    using multi compression stream zcomp_strm_multi (spinlock-based locking).
    
    default max_comp_streams value is 1, meaning that zram with single stream
    will be initialised.
    
    Later patch will introduce configuration knob to change max_comp_streams
    on already initialised and used zcomp.
    
    TEST
    iozone -t 3 -R -r 16K -s 60M -I +Z
    
           test           base       1 strm (mutex)     3 strm (spinlock)
    -----------------------------------------------------------------------
     Initial write      589286.78       583518.39          718011.05
           Rewrite      604837.97       596776.38         1515125.72
      Random write      584120.11       595714.58         1388850.25
            Pwrite      535731.17       541117.38          739295.27
            Fwrite     1418083.88      1478612.72         1484927.06
    
    Usage example:
    set max_comp_streams to 4
            echo 4 > /sys/block/zram0/max_comp_streams
    
    show current max_comp_streams (default value is 1).
            cat /sys/block/zram0/max_comp_streams
    
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Acked-by: Minchan Kim <minchan@kernel.org>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 45e04f7b713f..ccf36d11755a 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -99,7 +99,7 @@ struct zram {
 	 * we can store in a disk.
 	 */
 	u64 disksize;	/* bytes */
-
+	int max_comp_streams;
 	struct zram_stats stats;
 };
 #endif

commit b7ca232ee7e85ed3b18e39eb20a7f458ee1d6047
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Mon Apr 7 15:38:12 2014 -0700

    zram: use zcomp compressing backends
    
    Do not perform direct LZO compress/decompress calls, initialise
    and use zcomp LZO backend (single compression stream) instead.
    
    [akpm@linux-foundation.org: resolve conflicts with zram-delete-zram_init_device-fix.patch]
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Acked-by: Minchan Kim <minchan@kernel.org>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 1d5b1f5786a8..45e04f7b713f 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -16,9 +16,10 @@
 #define _ZRAM_DRV_H_
 
 #include <linux/spinlock.h>
-#include <linux/mutex.h>
 #include <linux/zsmalloc.h>
 
+#include "zcomp.h"
+
 /*
  * Some arbitrary value. This is just to catch
  * invalid value for num_devices module parameter.
@@ -81,17 +82,16 @@ struct zram_stats {
 
 struct zram_meta {
 	rwlock_t tb_lock;	/* protect table */
-	void *compress_workmem;
-	void *compress_buffer;
 	struct table *table;
 	struct zs_pool *mem_pool;
-	struct mutex buffer_lock; /* protect compress buffers */
 };
 
 struct zram {
 	struct zram_meta *meta;
 	struct request_queue *queue;
 	struct gendisk *disk;
+	struct zcomp *comp;
+
 	/* Prevent concurrent execution of device init, reset and R/W request */
 	struct rw_semaphore init_lock;
 	/*

commit 59fc86a4922f1a1c0f69eac758a7e2b2b138aab4
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Mon Apr 7 15:38:06 2014 -0700

    zram: drop not used table `count' member
    
    struct table `count' member is not used.
    
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Acked-by: Jerome Marchand <jmarchan@redhat.com>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 58d4ac537f65..1d5b1f5786a8 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -64,7 +64,6 @@ enum zram_pageflags {
 struct table {
 	unsigned long handle;
 	u16 size;	/* object size (excluding header) */
-	u8 count;	/* object ref count (not yet used) */
 	u8 flags;
 } __aligned(4);
 

commit 90a7806ea9b9f7cb4751859cc2506e2d80e36ef1
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Mon Apr 7 15:38:03 2014 -0700

    zram: use atomic64_t for all zram stats
    
    This is a preparation patch for stats code duplication removal.
    
    1) use atomic64_t for `pages_zero' and `pages_stored' zram stats.
    
    2) `compr_size' and `pages_zero' struct zram_stats members did not
       follow the existing device attr naming scheme: zram_stats.ATTR has
       ATTR_show() function.  rename them:
    
       -- compr_size -> compr_data_size
       -- pages_zero -> zero_pages
    
    Minchan Kim's note:
     If we really have trouble with atomic stat operation, we could
     change it with percpu_counter so that it could solve atomic overhead and
     unnecessary memory space by introducing unsigned long instead of 64bit
     atomic_t.
    
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Acked-by: Minchan Kim <minchan@kernel.org>
    Acked-by: Jerome Marchand <jmarchan@redhat.com>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 2f173cb1fd0a..58d4ac537f65 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -69,15 +69,15 @@ struct table {
 } __aligned(4);
 
 struct zram_stats {
-	atomic64_t compr_size;	/* compressed size of pages stored */
+	atomic64_t compr_data_size;	/* compressed size of pages stored */
 	atomic64_t num_reads;	/* failed + successful */
 	atomic64_t num_writes;	/* --do-- */
 	atomic64_t failed_reads;	/* should NEVER! happen */
 	atomic64_t failed_writes;	/* can happen when memory is too low */
 	atomic64_t invalid_io;	/* non-page-aligned I/O requests */
 	atomic64_t notify_free;	/* no. of swap slot free notifications */
-	atomic_t pages_zero;		/* no. of zero filled pages */
-	atomic_t pages_stored;	/* no. of pages currently stored */
+	atomic64_t zero_pages;		/* no. of zero filled pages */
+	atomic64_t pages_stored;	/* no. of pages currently stored */
 };
 
 struct zram_meta {

commit b7cccf8b4009bf74df61f3c9d86b95fabd807c11
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Mon Apr 7 15:38:02 2014 -0700

    zram: remove good and bad compress stats
    
    Remove `good' and `bad' compressed sub-requests stats.  RW request may
    cause a number of RW sub-requests.  zram used to account `good' compressed
    sub-queries (with compressed size less than 50% of original size), `bad'
    compressed sub-queries (with compressed size greater that 75% of original
    size), leaving sub-requests with compression size between 50% and 75% of
    original size not accounted and not reported.  zram already accounts each
    sub-request's compression size so we can calculate real device compression
    ratio.
    
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Acked-by: Minchan Kim <minchan@kernel.org>
    Acked-by: Jerome Marchand <jmarchan@redhat.com>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index e81e9cdf4147..2f173cb1fd0a 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -78,8 +78,6 @@ struct zram_stats {
 	atomic64_t notify_free;	/* no. of swap slot free notifications */
 	atomic_t pages_zero;		/* no. of zero filled pages */
 	atomic_t pages_stored;	/* no. of pages currently stored */
-	atomic_t good_compress;	/* % of pages with compression ratio<=50% */
-	atomic_t bad_compress;	/* % of pages with compression ratio>=75% */
 };
 
 struct zram_meta {

commit be2d1d56c82d8cf20e6c77515eb499f8e86eb5be
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Mon Apr 7 15:38:00 2014 -0700

    zram: drop `init_done' struct zram member
    
    Introduce init_done() helper function which allows us to drop `init_done'
    struct zram member.  init_done() uses the fact that ->init_done == 1
    equals to ->meta != NULL.
    
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Acked-by: Minchan Kim <minchan@kernel.org>
    Acked-by: Jerome Marchand <jmarchan@redhat.com>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index ad8aa35bae00..e81e9cdf4147 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -95,7 +95,6 @@ struct zram {
 	struct zram_meta *meta;
 	struct request_queue *queue;
 	struct gendisk *disk;
-	int init_done;
 	/* Prevent concurrent execution of device init, reset and R/W request */
 	struct rw_semaphore init_lock;
 	/*

commit e46e33152eb82b8e2db7ffb3790a2a2653c34513
Author: Minchan Kim <minchan@kernel.org>
Date:   Thu Jan 30 15:46:06 2014 -0800

    zram: remove zram->lock in read path and change it with mutex
    
    Finally, we separated zram->lock dependency from 32bit stat/ table
    handling so there is no reason to use rw_semaphore between read and
    write path so this patch removes the lock from read path totally and
    changes rw_semaphore with mutex.  So, we could do
    
    old:
    
      read-read: OK
      read-write: NO
      write-write: NO
    
    Now:
    
      read-read: OK
      read-write: OK
      write-write: NO
    
    The below data proves mixed workload performs well 11 times and there is
    also enhance on write-write path because current rw-semaphore doesn't
    support SPIN_ON_OWNER.  It's side effect but anyway good thing for us.
    
    Write-related tests perform better (from 61% to 1058%) but read path has
    good/bad(from -2.22% to 1.45%) but they are all marginal within stddev.
    
      CPU 12
      iozone -t -T -l 12 -u 12 -r 16K -s 60M -I +Z -V 0
    
      ==Initial write                ==Initial write
      records: 10                    records: 10
      avg:  516189.16                avg:  839907.96
      std:   22486.53 (4.36%)        std:   47902.17 (5.70%)
      max:  546970.60                max:  909910.35
      min:  481131.54                min:  751148.38
      ==Rewrite                      ==Rewrite
      records: 10                    records: 10
      avg:  509527.98                avg: 1050156.37
      std:   45799.94 (8.99%)        std:   40695.44 (3.88%)
      max:  611574.27                max: 1111929.26
      min:  443679.95                min:  980409.62
      ==Read                         ==Read
      records: 10                    records: 10
      avg: 4408624.17                avg: 4472546.76
      std:  281152.61 (6.38%)        std:  163662.78 (3.66%)
      max: 4867888.66                max: 4727351.03
      min: 4058347.69                min: 4126520.88
      ==Re-read                      ==Re-read
      records: 10                    records: 10
      avg: 4462147.53                avg: 4363257.75
      std:  283546.11 (6.35%)        std:  247292.63 (5.67%)
      max: 4912894.44                max: 4677241.75
      min: 4131386.50                min: 4035235.84
      ==Reverse Read                 ==Reverse Read
      records: 10                    records: 10
      avg: 4565865.97                avg: 4485818.08
      std:  313395.63 (6.86%)        std:  248470.10 (5.54%)
      max: 5232749.16                max: 4789749.94
      min: 4185809.62                min: 3963081.34
      ==Stride read                  ==Stride read
      records: 10                    records: 10
      avg: 4515981.80                avg: 4418806.01
      std:  211192.32 (4.68%)        std:  212837.97 (4.82%)
      max: 4889287.28                max: 4686967.22
      min: 4210362.00                min: 4083041.84
      ==Random read                  ==Random read
      records: 10                    records: 10
      avg: 4410525.23                avg: 4387093.18
      std:  236693.22 (5.37%)        std:  235285.23 (5.36%)
      max: 4713698.47                max: 4669760.62
      min: 4057163.62                min: 3952002.16
      ==Mixed workload               ==Mixed workload
      records: 10                    records: 10
      avg:  243234.25                avg: 2818677.27
      std:   28505.07 (11.72%)       std:  195569.70 (6.94%)
      max:  288905.23                max: 3126478.11
      min:  212473.16                min: 2484150.69
      ==Random write                 ==Random write
      records: 10                    records: 10
      avg:  555887.07                avg: 1053057.79
      std:   70841.98 (12.74%)       std:   35195.36 (3.34%)
      max:  683188.28                max: 1096125.73
      min:  437299.57                min:  992481.93
      ==Pwrite                       ==Pwrite
      records: 10                    records: 10
      avg:  501745.93                avg:  810363.09
      std:   16373.54 (3.26%)        std:   19245.01 (2.37%)
      max:  518724.52                max:  833359.70
      min:  464208.73                min:  765501.87
      ==Pread                        ==Pread
      records: 10                    records: 10
      avg: 4539894.60                avg: 4457680.58
      std:  197094.66 (4.34%)        std:  188965.60 (4.24%)
      max: 4877170.38                max: 4689905.53
      min: 4226326.03                min: 4095739.72
    
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Tested-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index d876300da6c9..ad8aa35bae00 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -88,13 +88,11 @@ struct zram_meta {
 	void *compress_buffer;
 	struct table *table;
 	struct zs_pool *mem_pool;
+	struct mutex buffer_lock; /* protect compress buffers */
 };
 
 struct zram {
 	struct zram_meta *meta;
-	struct rw_semaphore lock; /* protect compression buffers,
-				   * reads and writes
-				   */
 	struct request_queue *queue;
 	struct gendisk *disk;
 	int init_done;

commit f614a9f48dedd2b80d1dc8bae8094842fcdb39dd
Author: Minchan Kim <minchan@kernel.org>
Date:   Thu Jan 30 15:46:04 2014 -0800

    zram: remove workqueue for freeing removed pending slot
    
    Commit a0c516cbfc74 ("zram: don't grab mutex in zram_slot_free_noity")
    introduced free request pending code to avoid scheduling by mutex under
    spinlock and it was a mess which made code lenghty and increased
    overhead.
    
    Now, we don't need zram->lock any more to free slot so this patch
    reverts it and then, tb_lock should protect it.
    
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Tested-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index c3f453f04974..d876300da6c9 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -90,20 +90,11 @@ struct zram_meta {
 	struct zs_pool *mem_pool;
 };
 
-struct zram_slot_free {
-	unsigned long index;
-	struct zram_slot_free *next;
-};
-
 struct zram {
 	struct zram_meta *meta;
 	struct rw_semaphore lock; /* protect compression buffers,
 				   * reads and writes
 				   */
-
-	struct work_struct free_work;  /* handle pending free request */
-	struct zram_slot_free *slot_free_rq; /* list head of free request */
-
 	struct request_queue *queue;
 	struct gendisk *disk;
 	int init_done;
@@ -114,7 +105,6 @@ struct zram {
 	 * we can store in a disk.
 	 */
 	u64 disksize;	/* bytes */
-	spinlock_t slot_free_lock;
 
 	struct zram_stats stats;
 };

commit 92967471b67163bb1654e9b7fe99449ab70a4aaa
Author: Minchan Kim <minchan@kernel.org>
Date:   Thu Jan 30 15:46:03 2014 -0800

    zram: introduce zram->tb_lock
    
    Currently, the zram table is protected by zram->lock but it's rather
    coarse-grained lock and it makes hard for scalibility.
    
    Let's use own rwlock instead of depending on zram->lock.  This patch
    adds new locking so obviously, it would make slow but this patch is just
    prepartion for removing coarse-grained rw_semaphore(ie, zram->lock)
    which is hurdle about zram scalability.
    
    Final patch in this patchset series will remove the lock from read-path
    and change rw_semaphore with mutex in write path.  With bonus, we could
    drop pending slot free mess in next patch.
    
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Tested-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 81b0170de369..c3f453f04974 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -83,6 +83,7 @@ struct zram_stats {
 };
 
 struct zram_meta {
+	rwlock_t tb_lock;	/* protect table */
 	void *compress_workmem;
 	void *compress_buffer;
 	struct table *table;
@@ -96,7 +97,7 @@ struct zram_slot_free {
 
 struct zram {
 	struct zram_meta *meta;
-	struct rw_semaphore lock; /* protect compression buffers, table,
+	struct rw_semaphore lock; /* protect compression buffers,
 				   * reads and writes
 				   */
 

commit deb0bdeb2f3d6b81d37fc778316dae46b6daab56
Author: Minchan Kim <minchan@kernel.org>
Date:   Thu Jan 30 15:46:02 2014 -0800

    zram: use atomic operation for stat
    
    Some of fields in zram->stats are protected by zram->lock which is
    rather coarse-grained so let's use atomic operation without explict
    locking.
    
    This patch is ready for removing dependency of zram->lock in read path
    which is very coarse-grained rw_semaphore.  Of course, this patch adds
    new atomic operation so it might make slow but my 12CPU test couldn't
    spot any regression.  All gain/lose is marginal within stddev.
    
      iozone -t -T -l 12 -u 12 -r 16K -s 60M -I +Z -V 0
    
      ==Initial write                ==Initial write
      records: 50                    records: 50
      avg:  412875.17                avg:  415638.23
      std:   38543.12 (9.34%)        std:   36601.11 (8.81%)
      max:  521262.03                max:  502976.72
      min:  343263.13                min:  351389.12
      ==Rewrite                      ==Rewrite
      records: 50                    records: 50
      avg:  416640.34                avg:  397914.33
      std:   60798.92 (14.59%)       std:   46150.42 (11.60%)
      max:  543057.07                max:  522669.17
      min:  304071.67                min:  316588.77
      ==Read                         ==Read
      records: 50                    records: 50
      avg: 4147338.63                avg: 4070736.51
      std:  179333.25 (4.32%)        std:  223499.89 (5.49%)
      max: 4459295.28                max: 4539514.44
      min: 3753057.53                min: 3444686.31
      ==Re-read                      ==Re-read
      records: 50                    records: 50
      avg: 4096706.71                avg: 4117218.57
      std:  229735.04 (5.61%)        std:  171676.25 (4.17%)
      max: 4430012.09                max: 4459263.94
      min: 2987217.80                min: 3666904.28
      ==Reverse Read                 ==Reverse Read
      records: 50                    records: 50
      avg: 4062763.83                avg: 4078508.32
      std:  186208.46 (4.58%)        std:  172684.34 (4.23%)
      max: 4401358.78                max: 4424757.22
      min: 3381625.00                min: 3679359.94
      ==Stride read                  ==Stride read
      records: 50                    records: 50
      avg: 4094933.49                avg: 4082170.22
      std:  185710.52 (4.54%)        std:  196346.68 (4.81%)
      max: 4478241.25                max: 4460060.97
      min: 3732593.23                min: 3584125.78
      ==Random read                  ==Random read
      records: 50                    records: 50
      avg: 4031070.04                avg: 4074847.49
      std:  192065.51 (4.76%)        std:  206911.33 (5.08%)
      max: 4356931.16                max: 4399442.56
      min: 3481619.62                min: 3548372.44
      ==Mixed workload               ==Mixed workload
      records: 50                    records: 50
      avg:  149925.73                avg:  149675.54
      std:    7701.26 (5.14%)        std:    6902.09 (4.61%)
      max:  191301.56                max:  175162.05
      min:  133566.28                min:  137762.87
      ==Random write                 ==Random write
      records: 50                    records: 50
      avg:  404050.11                avg:  393021.47
      std:   58887.57 (14.57%)       std:   42813.70 (10.89%)
      max:  601798.09                max:  524533.43
      min:  325176.99                min:  313255.34
      ==Pwrite                       ==Pwrite
      records: 50                    records: 50
      avg:  411217.70                avg:  411237.96
      std:   43114.99 (10.48%)       std:   33136.29 (8.06%)
      max:  530766.79                max:  471899.76
      min:  320786.84                min:  317906.94
      ==Pread                        ==Pread
      records: 50                    records: 50
      avg: 4154908.65                avg: 4087121.92
      std:  151272.08 (3.64%)        std:  219505.04 (5.37%)
      max: 4459478.12                max: 4435857.38
      min: 3730512.41                min: 3101101.67
    
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Tested-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 0e46953c08e9..81b0170de369 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -68,10 +68,6 @@ struct table {
 	u8 flags;
 } __aligned(4);
 
-/*
- * All 64bit fields should only be manipulated by 64bit atomic accessors.
- * All modifications to 32bit counter should be protected by zram->lock.
- */
 struct zram_stats {
 	atomic64_t compr_size;	/* compressed size of pages stored */
 	atomic64_t num_reads;	/* failed + successful */
@@ -80,10 +76,10 @@ struct zram_stats {
 	atomic64_t failed_writes;	/* can happen when memory is too low */
 	atomic64_t invalid_io;	/* non-page-aligned I/O requests */
 	atomic64_t notify_free;	/* no. of swap slot free notifications */
-	u32 pages_zero;		/* no. of zero filled pages */
-	u32 pages_stored;	/* no. of pages currently stored */
-	u32 good_compress;	/* % of pages with compression ratio<=50% */
-	u32 bad_compress;	/* % of pages with compression ratio>=75% */
+	atomic_t pages_zero;		/* no. of zero filled pages */
+	atomic_t pages_stored;	/* no. of pages currently stored */
+	atomic_t good_compress;	/* % of pages with compression ratio<=50% */
+	atomic_t bad_compress;	/* % of pages with compression ratio>=75% */
 };
 
 struct zram_meta {
@@ -101,8 +97,8 @@ struct zram_slot_free {
 struct zram {
 	struct zram_meta *meta;
 	struct rw_semaphore lock; /* protect compression buffers, table,
-				   * 32bit stat counters against concurrent
-				   * notifications, reads and writes */
+				   * reads and writes
+				   */
 
 	struct work_struct free_work;  /* handle pending free request */
 	struct zram_slot_free *slot_free_rq; /* list head of free request */

commit 7bfb3de8a1b3bebc2dc68d381efe27448c0584c5
Author: Minchan Kim <minchan@kernel.org>
Date:   Thu Jan 30 15:45:55 2014 -0800

    zram: add copyright
    
    Add my copyright to the zram source code which I maintain.
    
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index 92f70e8f457c..0e46953c08e9 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -2,6 +2,7 @@
  * Compressed RAM block device
  *
  * Copyright (C) 2008, 2009, 2010  Nitin Gupta
+ *               2012, 2013 Minchan Kim
  *
  * This code is released using a dual license strategy: BSD/GPL
  * You can choose the licence that better fits your requirements.

commit 49061236a9c2e18b31617cef10d27ba136068bac
Author: Minchan Kim <minchan@kernel.org>
Date:   Thu Jan 30 15:45:54 2014 -0800

    zram: remove old private project comment
    
    Remove the old private compcache project address so upcoming patches
    should be sent to LKML because we Linux kernel community will take care.
    
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
index d8f6596513c3..92f70e8f457c 100644
--- a/drivers/block/zram/zram_drv.h
+++ b/drivers/block/zram/zram_drv.h
@@ -9,7 +9,6 @@
  * Released under the terms of 3-clause BSD License
  * Released under the terms of GNU General Public License Version 2.0
  *
- * Project home: http://compcache.googlecode.com
  */
 
 #ifndef _ZRAM_DRV_H_

commit cd67e10ac6997c6d1e1504e3c111b693bfdbc148
Author: Minchan Kim <minchan@kernel.org>
Date:   Thu Jan 30 15:45:52 2014 -0800

    zram: promote zram from staging
    
    Zram has lived in staging for a LONG LONG time and have been
    fixed/improved by many contributors so code is clean and stable now.  Of
    course, there are lots of product using zram in real practice.
    
    The major TV companys have used zram as swap since two years ago and
    recently our production team released android smart phone with zram
    which is used as swap, too and recently Android Kitkat start to use zram
    for small memory smart phone.  And there was a report Google released
    their ChromeOS with zram, too and cyanogenmod have been used zram long
    time ago.  And I heard some disto have used zram block device for tmpfs.
    In addition, I saw many report from many other peoples.  For example,
    Lubuntu start to use it.
    
    The benefit of zram is very clear.  With my experience, one of the
    benefit was to remove jitter of video application with backgroud memory
    pressure.  It would be effect of efficient memory usage by compression
    but more issue is whether swap is there or not in the system.  Recent
    mobile platforms have used JAVA so there are many anonymous pages.  But
    embedded system normally are reluctant to use eMMC or SDCard as swap
    because there is wear-leveling and latency issues so if we do not use
    swap, it means we can't reclaim anoymous pages and at last, we could
    encounter OOM kill.  :(
    
    Although we have real storage as swap, it was a problem, too.  Because
    it sometime ends up making system very unresponsible caused by slow swap
    storage performance.
    
    Quote from Luigi on Google
     "Since Chrome OS was mentioned: the main reason why we don't use swap
      to a disk (rotating or SSD) is because it doesn't degrade gracefully
      and leads to a bad interactive experience.  Generally we prefer to
      manage RAM at a higher level, by transparently killing and restarting
      processes.  But we noticed that zram is fast enough to be competitive
      with the latter, and it lets us make more efficient use of the
      available RAM.  " and he announced.
    http://www.spinics.net/lists/linux-mm/msg57717.html
    
    Other uses case is to use zram for block device.  Zram is block device
    so anyone can format the block device and mount on it so some guys on
    the internet start zram as /var/tmp.
    http://forums.gentoo.org/viewtopic-t-838198-start-0.html
    
    Let's promote zram and enhance/maintain it instead of removing.
    
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Acked-by: Nitin Gupta <ngupta@vflare.org>
    Acked-by: Pekka Enberg <penberg@kernel.org>
    Cc: Bob Liu <bob.liu@oracle.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Luigi Semenzato <semenzato@google.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Seth Jennings <sjenning@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/block/zram/zram_drv.h b/drivers/block/zram/zram_drv.h
new file mode 100644
index 000000000000..d8f6596513c3
--- /dev/null
+++ b/drivers/block/zram/zram_drv.h
@@ -0,0 +1,124 @@
+/*
+ * Compressed RAM block device
+ *
+ * Copyright (C) 2008, 2009, 2010  Nitin Gupta
+ *
+ * This code is released using a dual license strategy: BSD/GPL
+ * You can choose the licence that better fits your requirements.
+ *
+ * Released under the terms of 3-clause BSD License
+ * Released under the terms of GNU General Public License Version 2.0
+ *
+ * Project home: http://compcache.googlecode.com
+ */
+
+#ifndef _ZRAM_DRV_H_
+#define _ZRAM_DRV_H_
+
+#include <linux/spinlock.h>
+#include <linux/mutex.h>
+#include <linux/zsmalloc.h>
+
+/*
+ * Some arbitrary value. This is just to catch
+ * invalid value for num_devices module parameter.
+ */
+static const unsigned max_num_devices = 32;
+
+/*-- Configurable parameters */
+
+/*
+ * Pages that compress to size greater than this are stored
+ * uncompressed in memory.
+ */
+static const size_t max_zpage_size = PAGE_SIZE / 4 * 3;
+
+/*
+ * NOTE: max_zpage_size must be less than or equal to:
+ *   ZS_MAX_ALLOC_SIZE. Otherwise, zs_malloc() would
+ * always return failure.
+ */
+
+/*-- End of configurable params */
+
+#define SECTOR_SHIFT		9
+#define SECTOR_SIZE		(1 << SECTOR_SHIFT)
+#define SECTORS_PER_PAGE_SHIFT	(PAGE_SHIFT - SECTOR_SHIFT)
+#define SECTORS_PER_PAGE	(1 << SECTORS_PER_PAGE_SHIFT)
+#define ZRAM_LOGICAL_BLOCK_SHIFT 12
+#define ZRAM_LOGICAL_BLOCK_SIZE	(1 << ZRAM_LOGICAL_BLOCK_SHIFT)
+#define ZRAM_SECTOR_PER_LOGICAL_BLOCK	\
+	(1 << (ZRAM_LOGICAL_BLOCK_SHIFT - SECTOR_SHIFT))
+
+/* Flags for zram pages (table[page_no].flags) */
+enum zram_pageflags {
+	/* Page consists entirely of zeros */
+	ZRAM_ZERO,
+
+	__NR_ZRAM_PAGEFLAGS,
+};
+
+/*-- Data structures */
+
+/* Allocated for each disk page */
+struct table {
+	unsigned long handle;
+	u16 size;	/* object size (excluding header) */
+	u8 count;	/* object ref count (not yet used) */
+	u8 flags;
+} __aligned(4);
+
+/*
+ * All 64bit fields should only be manipulated by 64bit atomic accessors.
+ * All modifications to 32bit counter should be protected by zram->lock.
+ */
+struct zram_stats {
+	atomic64_t compr_size;	/* compressed size of pages stored */
+	atomic64_t num_reads;	/* failed + successful */
+	atomic64_t num_writes;	/* --do-- */
+	atomic64_t failed_reads;	/* should NEVER! happen */
+	atomic64_t failed_writes;	/* can happen when memory is too low */
+	atomic64_t invalid_io;	/* non-page-aligned I/O requests */
+	atomic64_t notify_free;	/* no. of swap slot free notifications */
+	u32 pages_zero;		/* no. of zero filled pages */
+	u32 pages_stored;	/* no. of pages currently stored */
+	u32 good_compress;	/* % of pages with compression ratio<=50% */
+	u32 bad_compress;	/* % of pages with compression ratio>=75% */
+};
+
+struct zram_meta {
+	void *compress_workmem;
+	void *compress_buffer;
+	struct table *table;
+	struct zs_pool *mem_pool;
+};
+
+struct zram_slot_free {
+	unsigned long index;
+	struct zram_slot_free *next;
+};
+
+struct zram {
+	struct zram_meta *meta;
+	struct rw_semaphore lock; /* protect compression buffers, table,
+				   * 32bit stat counters against concurrent
+				   * notifications, reads and writes */
+
+	struct work_struct free_work;  /* handle pending free request */
+	struct zram_slot_free *slot_free_rq; /* list head of free request */
+
+	struct request_queue *queue;
+	struct gendisk *disk;
+	int init_done;
+	/* Prevent concurrent execution of device init, reset and R/W request */
+	struct rw_semaphore init_lock;
+	/*
+	 * This is the limit on amount of *uncompressed* worth of data
+	 * we can store in a disk.
+	 */
+	u64 disksize;	/* bytes */
+	spinlock_t slot_free_lock;
+
+	struct zram_stats stats;
+};
+#endif
