commit 3b4f0b66c2b3dceea01bd26efa8c4c6f01b4961f
Author: Björn Töpel <bjorn.topel@intel.com>
Date:   Wed May 20 21:20:56 2020 +0200

    i40e, xsk: Migrate to new MEM_TYPE_XSK_BUFF_POOL
    
    Remove MEM_TYPE_ZERO_COPY in favor of the new MEM_TYPE_XSK_BUFF_POOL
    APIs. The AF_XDP zero-copy rx_bi ring is now simply a struct xdp_buff
    pointer.
    
    v4->v5: Fixed "warning: Excess function parameter 'bi' description in
            'i40e_construct_skb_zc'". (Jakub)
    
    Signed-off-by: Björn Töpel <bjorn.topel@intel.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Cc: intel-wired-lan@lists.osuosl.org
    Link: https://lore.kernel.org/bpf/20200520192103.355233-9-bjorn.topel@gmail.com

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index d343498e8de5..5c255977fd58 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -301,12 +301,6 @@ struct i40e_rx_buffer {
 	__u16 pagecnt_bias;
 };
 
-struct i40e_rx_buffer_zc {
-	dma_addr_t dma;
-	void *addr;
-	u64 handle;
-};
-
 struct i40e_queue_stats {
 	u64 packets;
 	u64 bytes;
@@ -356,7 +350,7 @@ struct i40e_ring {
 	union {
 		struct i40e_tx_buffer *tx_bi;
 		struct i40e_rx_buffer *rx_bi;
-		struct i40e_rx_buffer_zc *rx_bi_zc;
+		struct xdp_buff **rx_bi_zc;
 	};
 	DECLARE_BITMAP(state, __I40E_RING_STATE_NBITS);
 	u16 queue_index;		/* Queue number of ring */
@@ -418,7 +412,6 @@ struct i40e_ring {
 	struct i40e_channel *ch;
 	struct xdp_rxq_info xdp_rxq;
 	struct xdp_umem *xsk_umem;
-	struct zero_copy_allocator zca; /* ZC allocator anchor */
 } ____cacheline_internodealigned_in_smp;
 
 static inline bool ring_uses_build_skb(struct i40e_ring *ring)

commit be1222b585fdc410b8c1dbcc57dd03a00f04eff5
Author: Björn Töpel <bjorn.topel@intel.com>
Date:   Wed May 20 21:20:55 2020 +0200

    i40e: Separate kernel allocated rx_bi rings from AF_XDP rings
    
    Continuing the path to support MEM_TYPE_XSK_BUFF_POOL, the AF_XDP
    zero-copy/sk_buff rx_bi rings are now separate. Functions to properly
    allocate the different rings are added as well.
    
    v3->v4: Made i40e_fd_handle_status() static. (kbuild test robot)
    v4->v5: Fix kdoc for i40e_clean_programming_status(). (Jakub)
    
    Signed-off-by: Björn Töpel <bjorn.topel@intel.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Cc: intel-wired-lan@lists.osuosl.org
    Link: https://lore.kernel.org/bpf/20200520192103.355233-8-bjorn.topel@gmail.com

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 36d37f31a287..d343498e8de5 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -296,17 +296,15 @@ struct i40e_tx_buffer {
 
 struct i40e_rx_buffer {
 	dma_addr_t dma;
-	union {
-		struct {
-			struct page *page;
-			__u32 page_offset;
-			__u16 pagecnt_bias;
-		};
-		struct {
-			void *addr;
-			u64 handle;
-		};
-	};
+	struct page *page;
+	__u32 page_offset;
+	__u16 pagecnt_bias;
+};
+
+struct i40e_rx_buffer_zc {
+	dma_addr_t dma;
+	void *addr;
+	u64 handle;
 };
 
 struct i40e_queue_stats {
@@ -358,6 +356,7 @@ struct i40e_ring {
 	union {
 		struct i40e_tx_buffer *tx_bi;
 		struct i40e_rx_buffer *rx_bi;
+		struct i40e_rx_buffer_zc *rx_bi_zc;
 	};
 	DECLARE_BITMAP(state, __I40E_RING_STATE_NBITS);
 	u16 queue_index;		/* Queue number of ring */
@@ -495,6 +494,7 @@ int __i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size);
 bool __i40e_chk_linearize(struct sk_buff *skb);
 int i40e_xdp_xmit(struct net_device *dev, int n, struct xdp_frame **frames,
 		  u32 flags);
+int i40e_alloc_rx_bi(struct i40e_ring *rx_ring);
 
 /**
  * i40e_get_head - Retrieve head from head writeback

commit d7840976e3915669382c62ddd1700960f348328e
Author: Matthew Wilcox (Oracle) <willy@infradead.org>
Date:   Mon Jul 22 20:08:25 2019 -0700

    net: Use skb accessors in network drivers
    
    In preparation for unifying the skb_frag and bio_vec, use the fine
    accessors which already exist and use skb_frag_t instead of
    struct skb_frag_struct.
    
    Signed-off-by: Matthew Wilcox (Oracle) <willy@infradead.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 100e92d2982f..36d37f31a287 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -521,7 +521,7 @@ static inline u32 i40e_get_head(struct i40e_ring *tx_ring)
  **/
 static inline int i40e_xmit_descriptor_count(struct sk_buff *skb)
 {
-	const struct skb_frag_struct *frag = &skb_shinfo(skb)->frags[0];
+	const skb_frag_t *frag = &skb_shinfo(skb)->frags[0];
 	unsigned int nr_frags = skb_shinfo(skb)->nr_frags;
 	int count = 0, size = skb_headlen(skb);
 

commit 0a714186d3c0f7c563a03537f98716457c1f5ae0
Author: Björn Töpel <bjorn.topel@intel.com>
Date:   Tue Aug 28 14:44:32 2018 +0200

    i40e: add AF_XDP zero-copy Rx support
    
    This patch adds zero-copy Rx support for AF_XDP sockets. Instead of
    allocating buffers of type MEM_TYPE_PAGE_SHARED, the Rx frames are
    allocated as MEM_TYPE_ZERO_COPY when AF_XDP is enabled for a certain
    queue.
    
    All AF_XDP specific functions are added to a new file, i40e_xsk.c.
    
    Note that when AF_XDP zero-copy is enabled, the XDP action XDP_PASS
    will allocate a new buffer and copy the zero-copy frame prior passing
    it to the kernel stack.
    
    Signed-off-by: Björn Töpel <bjorn.topel@intel.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index bb04f6a731fe..100e92d2982f 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -296,13 +296,17 @@ struct i40e_tx_buffer {
 
 struct i40e_rx_buffer {
 	dma_addr_t dma;
-	struct page *page;
-#if (BITS_PER_LONG > 32) || (PAGE_SIZE >= 65536)
-	__u32 page_offset;
-#else
-	__u16 page_offset;
-#endif
-	__u16 pagecnt_bias;
+	union {
+		struct {
+			struct page *page;
+			__u32 page_offset;
+			__u16 pagecnt_bias;
+		};
+		struct {
+			void *addr;
+			u64 handle;
+		};
+	};
 };
 
 struct i40e_queue_stats {
@@ -414,6 +418,8 @@ struct i40e_ring {
 
 	struct i40e_channel *ch;
 	struct xdp_rxq_info xdp_rxq;
+	struct xdp_umem *xsk_umem;
+	struct zero_copy_allocator zca; /* ZC allocator anchor */
 } ____cacheline_internodealigned_in_smp;
 
 static inline bool ring_uses_build_skb(struct i40e_ring *ring)

commit 763ea096f3cf312608317fb1027d509cfd1efc16
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Tue Jun 5 13:55:30 2018 +0200

    i40e: remove ndo_xdp_flush call i40e_xdp_flush
    
    Remove the ndo_xdp_flush call implementation i40e_xdp_flush
    as no callers of ndo_xdp_flush are left.
    
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 820f76db251b..bb04f6a731fe 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -489,7 +489,6 @@ int __i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size);
 bool __i40e_chk_linearize(struct sk_buff *skb);
 int i40e_xdp_xmit(struct net_device *dev, int n, struct xdp_frame **frames,
 		  u32 flags);
-void i40e_xdp_flush(struct net_device *dev);
 
 /**
  * i40e_get_head - Retrieve head from head writeback

commit 42b33468987bac0dd95c30f14820c7abac04a153
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Thu May 31 10:59:47 2018 +0200

    xdp: add flags argument to ndo_xdp_xmit API
    
    This patch only change the API and reject any use of flags. This is an
    intermediate step that allows us to implement the flush flag operation
    later, for each individual driver in a separate patch.
    
    The plan is to implement flush operation via XDP_XMIT_FLUSH flag
    and then remove XDP_XMIT_FLAGS_NONE when done.
    
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Acked-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index eb8804b3d7b6..820f76db251b 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -487,7 +487,8 @@ u32 i40e_get_tx_pending(struct i40e_ring *ring, bool in_sw);
 void i40e_detect_recover_hung(struct i40e_vsi *vsi);
 int __i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size);
 bool __i40e_chk_linearize(struct sk_buff *skb);
-int i40e_xdp_xmit(struct net_device *dev, int n, struct xdp_frame **frames);
+int i40e_xdp_xmit(struct net_device *dev, int n, struct xdp_frame **frames,
+		  u32 flags);
 void i40e_xdp_flush(struct net_device *dev);
 
 /**

commit 735fc4054b3a25034445c6713d259da0f96f8131
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Thu May 24 16:46:12 2018 +0200

    xdp: change ndo_xdp_xmit API to support bulking
    
    This patch change the API for ndo_xdp_xmit to support bulking
    xdp_frames.
    
    When kernel is compiled with CONFIG_RETPOLINE, XDP sees a huge slowdown.
    Most of the slowdown is caused by DMA API indirect function calls, but
    also the net_device->ndo_xdp_xmit() call.
    
    Benchmarked patch with CONFIG_RETPOLINE, using xdp_redirect_map with
    single flow/core test (CPU E5-1650 v4 @ 3.60GHz), showed
    performance improved:
     for driver ixgbe: 6,042,682 pps -> 6,853,768 pps = +811,086 pps
     for driver i40e : 6,187,169 pps -> 6,724,519 pps = +537,350 pps
    
    With frames avail as a bulk inside the driver ndo_xdp_xmit call,
    further optimizations are possible, like bulk DMA-mapping for TX.
    
    Testing without CONFIG_RETPOLINE show the same performance for
    physical NIC drivers.
    
    The virtual NIC driver tun sees a huge performance boost, as it can
    avoid doing per frame producer locking, but instead amortize the
    locking cost over the bulk.
    
    V2: Fix compile errors reported by kbuild test robot <lkp@intel.com>
    V4: Isolated ndo, driver changes and callers.
    
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index fdd2c55f03a6..eb8804b3d7b6 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -487,7 +487,7 @@ u32 i40e_get_tx_pending(struct i40e_ring *ring, bool in_sw);
 void i40e_detect_recover_hung(struct i40e_vsi *vsi);
 int __i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size);
 bool __i40e_chk_linearize(struct sk_buff *skb);
-int i40e_xdp_xmit(struct net_device *dev, struct xdp_frame *xdpf);
+int i40e_xdp_xmit(struct net_device *dev, int n, struct xdp_frame **frames);
 void i40e_xdp_flush(struct net_device *dev);
 
 /**

commit 51dce24bcdbdc493a87a17bcaf898b1f1d2fa600
Author: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
Date:   Thu Apr 26 08:08:09 2018 -0700

    net: intel: Cleanup the copyright/license headers
    
    After many years of having a ~30 line copyright and license header to our
    source files, we are finally able to reduce that to one line with the
    advent of the SPDX identifier.
    
    Also caught a few files missing the SPDX license identifier, so fixed
    them up.
    
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
    Acked-by: Shannon Nelson <shannon.nelson@oracle.com>
    Acked-by: Richard Cochran <richardcochran@gmail.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 4bf318b8be85..fdd2c55f03a6 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -1,29 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/*******************************************************************************
- *
- * Intel Ethernet Controller XL710 Family Linux Driver
- * Copyright(c) 2013 - 2016 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify it
- * under the terms and conditions of the GNU General Public License,
- * version 2, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
- * more details.
- *
- * You should have received a copy of the GNU General Public License along
- * with this program.  If not, see <http://www.gnu.org/licenses/>.
- *
- * The full GNU General Public License is included in this distribution in
- * the file called "COPYING".
- *
- * Contact Information:
- * e1000-devel Mailing List <e1000-devel@lists.sourceforge.net>
- * Intel Corporation, 5200 N.E. Elam Young Parkway, Hillsboro, OR 97124-6497
- *
- ******************************************************************************/
+/* Copyright(c) 2013 - 2018 Intel Corporation. */
 
 #ifndef _I40E_TXRX_H_
 #define _I40E_TXRX_H_

commit 44fa2dbd475996ddc8f3a0e6113dee983e0ee3aa
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Tue Apr 17 16:46:37 2018 +0200

    xdp: transition into using xdp_frame for ndo_xdp_xmit
    
    Changing API ndo_xdp_xmit to take a struct xdp_frame instead of struct
    xdp_buff.  This brings xdp_return_frame and ndp_xdp_xmit in sync.
    
    This builds towards changing the API further to become a bulk API,
    because xdp_buff is not a queue-able object while xdp_frame is.
    
    V4: Adjust for commit 59655a5b6c83 ("tuntap: XDP_TX can use native XDP")
    V7: Adjust for commit d9314c474d4f ("i40e: add support for XDP_REDIRECT")
    
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 857b1d743c8d..4bf318b8be85 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -511,7 +511,7 @@ u32 i40e_get_tx_pending(struct i40e_ring *ring, bool in_sw);
 void i40e_detect_recover_hung(struct i40e_vsi *vsi);
 int __i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size);
 bool __i40e_chk_linearize(struct sk_buff *skb);
-int i40e_xdp_xmit(struct net_device *dev, struct xdp_buff *xdp);
+int i40e_xdp_xmit(struct net_device *dev, struct xdp_frame *xdpf);
 void i40e_xdp_flush(struct net_device *dev);
 
 /**

commit b411ef11020d012790839a5414040283d9335386
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Tue Apr 17 16:46:02 2018 +0200

    i40e: convert to use generic xdp_frame and xdp_return_frame API
    
    Also convert driver i40e, which very recently got XDP_REDIRECT support
    in commit d9314c474d4f ("i40e: add support for XDP_REDIRECT").
    
    V7: This patch got added in V7 of this patchset.
    
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 3043483ec426..857b1d743c8d 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -306,6 +306,7 @@ static inline unsigned int i40e_txd_use_count(unsigned int size)
 struct i40e_tx_buffer {
 	struct i40e_tx_desc *next_to_watch;
 	union {
+		struct xdp_frame *xdpf;
 		struct sk_buff *skb;
 		void *raw_buf;
 	};

commit d9314c474d4fc1985e836b92fba4c40dd84885a7
Author: Björn Töpel <bjorn.topel@intel.com>
Date:   Thu Mar 22 16:14:34 2018 +0100

    i40e: add support for XDP_REDIRECT
    
    The driver now acts upon the XDP_REDIRECT return action. Two new ndos
    are implemented, ndo_xdp_xmit and ndo_xdp_flush.
    
    XDP_REDIRECT action enables XDP program to redirect frames to other
    netdevs.
    
    Signed-off-by: Björn Töpel <bjorn.topel@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 7f8220e65374..3043483ec426 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -510,6 +510,8 @@ u32 i40e_get_tx_pending(struct i40e_ring *ring, bool in_sw);
 void i40e_detect_recover_hung(struct i40e_vsi *vsi);
 int __i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size);
 bool __i40e_chk_linearize(struct sk_buff *skb);
+int i40e_xdp_xmit(struct net_device *dev, struct xdp_buff *xdp);
+void i40e_xdp_flush(struct net_device *dev);
 
 /**
  * i40e_get_head - Retrieve head from head writeback

commit ae06c70b135886d7d6252f3090146f01a3f3b80c
Author: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
Date:   Thu Mar 22 10:08:48 2018 -0700

    intel: add SPDX identifiers to all the Intel drivers
    
    Add the SPDX identifiers to all the Intel wired LAN driver files, as
    outlined in Documentation/process/license-rules.rst.
    
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
    Tested-by: Aaron Brown <aaron.f.brown@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 3c80ea784389..7f8220e65374 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*******************************************************************************
  *
  * Intel Ethernet Controller XL710 Family Linux Driver

commit 04d4105174349dceccf9545a3e5e421c18f2cc56
Author: Alan Brady <alan.brady@intel.com>
Date:   Mon Feb 12 09:16:59 2018 -0500

    i40e/i40evf: use SW variables for hang detection
    
    The i40e_detect_recover_hung function uses the i40e_get_tx_pending
    function to determine if there are packets stalled on the ring.
    i40e_get_tx_pending calculates the pending packets using the head
    writeback value and HW tail.  If the queue is stopped and we lose the
    interrupt to update our next_to_clean then we a) won't get another
    interrupt to clean because queue is stopped b) we won't catch the
    problem with i40e_detect_recover_hung because the HW values look like
    there's no packets waiting to be transmitted.  Using the SW values we
    can catch the issue because next_to_clean will be out of sync with head
    writeback.
    
    This has the added benefit being less CPU intensive because we don't
    need to reach into the hardware to get the values.
    
    Signed-off-by: Alan Brady <alan.brady@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index f75a8fe68fcf..3c80ea784389 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -505,7 +505,7 @@ void i40e_free_tx_resources(struct i40e_ring *tx_ring);
 void i40e_free_rx_resources(struct i40e_ring *rx_ring);
 int i40e_napi_poll(struct napi_struct *napi, int budget);
 void i40e_force_wb(struct i40e_vsi *vsi, struct i40e_q_vector *q_vector);
-u32 i40e_get_tx_pending(struct i40e_ring *ring);
+u32 i40e_get_tx_pending(struct i40e_ring *ring, bool in_sw);
 void i40e_detect_recover_hung(struct i40e_vsi *vsi);
 int __i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size);
 bool __i40e_chk_linearize(struct sk_buff *skb);

commit a0073a4b8b5906b2a7eab5e9d4a91759b56bc96f
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Fri Dec 29 08:52:19 2017 -0500

    i40e/i40evf: Add support for new mechanism of updating adaptive ITR
    
    This patch replaces the existing mechanism for determining the correct
    value to program for adaptive ITR with yet another new and more
    complicated approach.
    
    The basic idea from a 30K foot view is that this new approach will push the
    Rx interrupt moderation up so that by default it starts in low latency and
    is gradually pushed up into a higher latency setup as long as doing so
    increases the number of packets processed, if the number of packets drops
    to 4 to 1 per packet we will reset and just base our ITR on the size of the
    packets being received. For Tx we leave it floating at a high interrupt
    delay and do not pull it down unless we start processing more than 112
    packets per interrupt. If we start exceeding that we will cut our interrupt
    rates in half until we are back below 112.
    
    The side effect of these patches are that we will be processing more
    packets per interrupt. This is both a good and a bad thing as it means we
    will not be blocking processing in the case of things like pktgen and XDP,
    but we will also be consuming a bit more CPU in the cases of things such as
    network throughput tests using netperf.
    
    One delta from this versus the ixgbe version of the changes is that I have
    made the interrupt moderation a bit more aggressive when we are in bulk
    mode by moving our "goldilocks zone" up from 48 to 96 to 56 to 112. The
    main motivation behind moving this is to address the fact that we need to
    update less frequently, and have more fine grained control due to the
    separate Tx and Rx ITR times.
    
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 8ad8ffc63579..f75a8fe68fcf 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -463,20 +463,19 @@ static inline void set_ring_xdp(struct i40e_ring *ring)
 	ring->flags |= I40E_TXR_FLAGS_XDP;
 }
 
-enum i40e_latency_range {
-	I40E_LOWEST_LATENCY = 0,
-	I40E_LOW_LATENCY = 1,
-	I40E_BULK_LATENCY = 2,
-};
+#define I40E_ITR_ADAPTIVE_MIN_INC	0x0002
+#define I40E_ITR_ADAPTIVE_MIN_USECS	0x0002
+#define I40E_ITR_ADAPTIVE_MAX_USECS	0x007e
+#define I40E_ITR_ADAPTIVE_LATENCY	0x8000
+#define I40E_ITR_ADAPTIVE_BULK		0x0000
+#define ITR_IS_BULK(x) (!((x) & I40E_ITR_ADAPTIVE_LATENCY))
 
 struct i40e_ring_container {
-	/* array of pointers to rings */
-	struct i40e_ring *ring;
+	struct i40e_ring *ring;		/* pointer to linked list of ring(s) */
+	unsigned long next_update;	/* jiffies value of next update */
 	unsigned int total_bytes;	/* total bytes processed this int */
 	unsigned int total_packets;	/* total packets processed this int */
-	unsigned long last_itr_update;	/* jiffies of last ITR update */
 	u16 count;
-	enum i40e_latency_range latency_range;
 	u16 target_itr;			/* target ITR setting for ring(s) */
 	u16 current_itr;		/* current ITR setting for ring(s) */
 };

commit 556fdfd6e6ffcab9d03c942df06a5591c84ca637
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Fri Dec 29 08:51:25 2017 -0500

    i40e/i40evf: Split container ITR into current_itr and target_itr
    
    This patch is mostly prep-work for replacing the current approach to
    programming the dynamic aka adaptive ITR. Specifically here what we are
    doing is splitting the Tx and Rx ITR each into two separate values.
    
    The first value current_itr represents the current value of the register.
    
    The second value target_itr represents the desired value of the register.
    
    The general plan by doing this is to allow for deferring the update of the
    ITR value under certain circumstances. For now we will work with what we
    have, but in the future I hope to change the behavior so that we always
    only update one ITR at a time using some simple logic to determine which
    ITR requires an update.
    
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 0f8751c2e595..8ad8ffc63579 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -477,7 +477,8 @@ struct i40e_ring_container {
 	unsigned long last_itr_update;	/* jiffies of last ITR update */
 	u16 count;
 	enum i40e_latency_range latency_range;
-	u16 itr;
+	u16 target_itr;			/* target ITR setting for ring(s) */
+	u16 current_itr;		/* current ITR setting for ring(s) */
 };
 
 /* iterator for handling rings in ring container */

commit 92418fb14750c2baeebddf5903e3105cd11da90c
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Fri Dec 29 08:51:08 2017 -0500

    i40e/i40evf: Use usec value instead of reg value for ITR defines
    
    Instead of using the register value for the defines when setting up the
    ring ITR we can just use the actual values and avoid the use of shifts and
    macros to translate between the values we have and the values we want.
    
    This helps to make the code more readable as we can quickly translate from
    one value to the other.
    
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 1758dd3bf91b..0f8751c2e595 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -30,32 +30,37 @@
 #include <net/xdp.h>
 
 /* Interrupt Throttling and Rate Limiting Goodies */
-
-#define I40E_MAX_ITR               0x0FF0  /* reg uses 2 usec resolution */
-#define I40E_MIN_ITR               0x0001  /* reg uses 2 usec resolution */
-#define I40E_ITR_100K              0x0005
-#define I40E_ITR_50K               0x000A
-#define I40E_ITR_20K               0x0019
-#define I40E_ITR_18K               0x001B
-#define I40E_ITR_8K                0x003E
-#define I40E_ITR_4K                0x007A
-#define I40E_MAX_INTRL             0x3B    /* reg uses 4 usec resolution */
-#define I40E_ITR_RX_DEF            (ITR_REG_TO_USEC(I40E_ITR_20K) | \
-				    I40E_ITR_DYNAMIC)
-#define I40E_ITR_TX_DEF            (ITR_REG_TO_USEC(I40E_ITR_20K) | \
-				    I40E_ITR_DYNAMIC)
-#define I40E_ITR_DYNAMIC           0x8000  /* use top bit as a flag */
-#define I40E_MIN_INT_RATE          250     /* ~= 1000000 / (I40E_MAX_ITR * 2) */
-#define I40E_MAX_INT_RATE          500000  /* == 1000000 / (I40E_MIN_ITR * 2) */
 #define I40E_DEFAULT_IRQ_WORK      256
-#define ITR_TO_REG(setting) ((setting & ~I40E_ITR_DYNAMIC) >> 1)
-#define ITR_IS_DYNAMIC(setting) (!!(setting & I40E_ITR_DYNAMIC))
-#define ITR_REG_TO_USEC(itr_reg) (itr_reg << 1)
+
+/* The datasheet for the X710 and XL710 indicate that the maximum value for
+ * the ITR is 8160usec which is then called out as 0xFF0 with a 2usec
+ * resolution. 8160 is 0x1FE0 when written out in hex. So instead of storing
+ * the register value which is divided by 2 lets use the actual values and
+ * avoid an excessive amount of translation.
+ */
+#define I40E_ITR_DYNAMIC	0x8000	/* use top bit as a flag */
+#define I40E_ITR_MASK		0x1FFE	/* mask for ITR register value */
+#define I40E_MIN_ITR		     2	/* reg uses 2 usec resolution */
+#define I40E_ITR_100K		    10	/* all values below must be even */
+#define I40E_ITR_50K		    20
+#define I40E_ITR_20K		    50
+#define I40E_ITR_18K		    60
+#define I40E_ITR_8K		   122
+#define I40E_MAX_ITR		  8160	/* maximum value as per datasheet */
+#define ITR_TO_REG(setting) ((setting) & ~I40E_ITR_DYNAMIC)
+#define ITR_REG_ALIGN(setting) __ALIGN_MASK(setting, ~I40E_ITR_MASK)
+#define ITR_IS_DYNAMIC(setting) (!!((setting) & I40E_ITR_DYNAMIC))
+
+#define I40E_ITR_RX_DEF		(I40E_ITR_20K | I40E_ITR_DYNAMIC)
+#define I40E_ITR_TX_DEF		(I40E_ITR_20K | I40E_ITR_DYNAMIC)
+
 /* 0x40 is the enable bit for interrupt rate limiting, and must be set if
  * the value of the rate limit is non-zero
  */
 #define INTRL_ENA                  BIT(6)
+#define I40E_MAX_INTRL             0x3B    /* reg uses 4 usec resolution */
 #define INTRL_REG_TO_USEC(intrl) ((intrl & ~INTRL_ENA) << 2)
+
 /**
  * i40e_intrl_usec_to_reg - convert interrupt rate limit to register
  * @intrl: interrupt rate limit to convert

commit 40588ca6513729e4de60e49896aab0a7ee09df19
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Fri Dec 29 08:49:28 2017 -0500

    i40e/i40evf: Only track one ITR setting per ring instead of Tx/Rx
    
    The rings are already split out into Tx and Rx rings so it doesn't make
    sense to have any single ring store both a Tx and Rx itr_setting value.
    Since that is the case drop the pair in favor of storing just a single ITR
    value.
    
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 701b708628b0..1758dd3bf91b 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -382,8 +382,7 @@ struct i40e_ring {
 	 * these values always store the USER setting, and must be converted
 	 * before programming to a register.
 	 */
-	u16 rx_itr_setting;
-	u16 tx_itr_setting;
+	u16 itr_setting;
 
 	u16 count;			/* Number of descriptors */
 	u16 reg_idx;			/* HW register index of the ring */

commit 0a797db323a6f74da3f43d5460792989da6617f4
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Fri Jan 26 08:54:45 2018 -0800

    i40e/i40evf: Update DESC_NEEDED value to reflect larger value
    
    When compared to ixgbe and other previous Intel drivers the i40e and i40evf
    drivers actually reserve 2 additional descriptors in maybe_stop_tx for
    cache line alignment. We need to update DESC_NEEDED to reflect this as
    otherwise we are more likely to return TX_BUSY which will cause issues with
    things like xmit_more.
    
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index d4799b41e98a..701b708628b0 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -279,7 +279,7 @@ static inline unsigned int i40e_txd_use_count(unsigned int size)
 }
 
 /* Tx Descriptors needed, worst case */
-#define DESC_NEEDED (MAX_SKB_FRAGS + 4)
+#define DESC_NEEDED (MAX_SKB_FRAGS + 6)
 #define I40E_MIN_DESC_PENDING	4
 
 #define I40E_TX_FLAGS_HW_VLAN		BIT(1)

commit 07d44190a38939adfec6177a6e1b683417da291f
Author: Sudheer Mogilappagari <sudheer.mogilappagari@intel.com>
Date:   Mon Dec 18 05:17:25 2017 -0500

    i40e/i40evf: Detect and recover hung queue scenario
    
    In VFs, there is a known issue which can cause writebacks
    to not occur when interrupts are disabled and there are
    less than 4 descriptors resulting in TX timeout. Timeout
    can also occur due to lost interrupt.
    
    The current implementation for detecting and recovering
    from hung queues in the PF is problematic because it actually
    actively encourages lost interrupts.  By triggering a SW
    interrupt, interrupts are forced on.  If we are already in
    napi_poll and an interrupt fires, napi_poll will not be
    rescheduled and the interrupt is effectively lost; thereby
    potentially *causing* hung queues.
    
    This patch checks whether packets are being processed between
    every watchdog cycle and determine potential hung queue and
    fires triggers SW interrupt only for that particular queue.
    
    Signed-off-by: Sudheer Mogilappagari <sudheer.mogilappagari@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 2d08760fc4ce..d4799b41e98a 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -333,6 +333,7 @@ struct i40e_tx_queue_stats {
 	u64 tx_done_old;
 	u64 tx_linearize;
 	u64 tx_force_wb;
+	int prev_pkt_ctr;
 };
 
 struct i40e_rx_queue_stats {
@@ -501,6 +502,7 @@ void i40e_free_rx_resources(struct i40e_ring *rx_ring);
 int i40e_napi_poll(struct napi_struct *napi, int budget);
 void i40e_force_wb(struct i40e_vsi *vsi, struct i40e_q_vector *q_vector);
 u32 i40e_get_tx_pending(struct i40e_ring *ring);
+void i40e_detect_recover_hung(struct i40e_vsi *vsi);
 int __i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size);
 bool __i40e_chk_linearize(struct sk_buff *skb);
 

commit 871288248de23d5c87433dcd94910ff813495588
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Wed Jan 3 11:25:23 2018 +0100

    i40e: setup xdp_rxq_info
    
    The i40e driver has a special "FDIR" RX-ring (I40E_VSI_FDIR) which is
    a sideband channel for configuring/updating the flow director tables.
    This (i40e_vsi_)type does not invoke XDP-ebpf code.
    
    As suggested by Björn (V2): Instead of marking this I40E_VSI_FDIR RX-ring
    a special case, reverse the logic and only select RX-rings of type
    I40E_VSI_MAIN to register xdp_rxq_info's for.
    
    Driver hook points for xdp_rxq_info:
     * reg  : i40e_setup_rx_descriptors (via i40e_vsi_setup_rx_resources)
     * unreg: i40e_free_rx_resources    (via i40e_vsi_free_rx_resources)
    
    Tested on actual hardware with samples/bpf program.
    
    V2: Fixed bug in i40e_set_ringparam (memset zero) + match on I40E_VSI_MAIN.
    V4: Update patch desc that got out-of-sync with code.
    
    Cc: intel-wired-lan@lists.osuosl.org
    Cc: Björn Töpel <bjorn.topel@intel.com>
    Cc: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
    Cc: Paul Menzel <pmenzel@molgen.mpg.de>
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Reviewed-by: Paul Menzel <pmenzel@molgen.mpg.de>
    Acked-by: John Fastabend <john.fastabend@gmail.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index fbae1182e2ea..2d08760fc4ce 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -27,6 +27,8 @@
 #ifndef _I40E_TXRX_H_
 #define _I40E_TXRX_H_
 
+#include <net/xdp.h>
+
 /* Interrupt Throttling and Rate Limiting Goodies */
 
 #define I40E_MAX_ITR               0x0FF0  /* reg uses 2 usec resolution */
@@ -428,6 +430,7 @@ struct i40e_ring {
 					 */
 
 	struct i40e_channel *ch;
+	struct xdp_rxq_info xdp_rxq;
 } ____cacheline_internodealigned_in_smp;
 
 static inline bool ring_uses_build_skb(struct i40e_ring *ring)

commit 8f88b3034db3be2eb600b9f57012bc63f1ea197f
Author: Amritha Nambiar <amritha.nambiar@intel.com>
Date:   Thu Sep 7 04:00:17 2017 -0700

    i40e: Add infrastructure for queue channel support
    
    This patch sets up the infrastructure for offloading TCs and
    queue configurations to the hardware by creating HW channels(VSI).
    A new channel is created for each of the traffic class
    configuration offloaded via mqprio framework except for the first TC
    (TC0). TC0 for the main VSI is also reconfigured as per user provided
    queue parameters. Queue counts that are not power-of-2 are handled by
    reconfiguring RSS by reprogramming LUTs using the queue count value.
    This patch also handles configuring the TX rings for the channels,
    setting up the RX queue map for channel.
    
    Also, the channels so created are removed and all the queue
    configuration is set to default when the qdisc is detached from the
    root of the device.
    
    Signed-off-by: Amritha Nambiar <amritha.nambiar@intel.com>
    Signed-off-by: Kiran Patil <kiran.patil@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index ff57ae451524..fbae1182e2ea 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -426,6 +426,8 @@ struct i40e_ring {
 					 * i40e_clean_rx_ring_irq() is called
 					 * for this ring.
 					 */
+
+	struct i40e_channel *ch;
 } ____cacheline_internodealigned_in_smp;
 
 static inline bool ring_uses_build_skb(struct i40e_ring *ring)

commit 95bc2fb4c6c7d23db6dc54a3d49bdbadb13c392b
Author: Jacob Keller <jacob.e.keller@intel.com>
Date:   Thu Sep 7 08:05:52 2017 -0400

    i40e/i40evf: bundle more descriptors when allocating buffers
    
    Double the number of descriptors we'll bundle into one tail bump when
    receiving. Empirical testing has shown that we reduce CPU utilization
    and don't appear to reduce throughput or packet rate. 32 seems to be the
    sweet spot, as it's half the default polling budget, so we'd essentially
    reduce from 4 tail writes when polling down to 2. Increasing this up to
    64 appears to have negative impacts as it may become possible that we
    don't bump the tail each time we get polled, which could cause a long
    delay between returning descriptors to the hardware.
    
    Signed-off-by: Jacob Keller <jacob.e.keller@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index c3156aa3f709..ff57ae451524 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -208,7 +208,7 @@ static inline bool i40e_test_staterr(union i40e_rx_desc *rx_desc,
 }
 
 /* How many Rx Buffers do we bundle into one write to the hardware ? */
-#define I40E_RX_BUFFER_WRITE	16	/* Must be power of 2 */
+#define I40E_RX_BUFFER_WRITE	32	/* Must be power of 2 */
 #define I40E_RX_INCREMENT(r, i) \
 	do {					\
 		(i)++;				\

commit 427025592955d245997b12923111e85f07850d5f
Author: Jacob Keller <jacob.e.keller@intel.com>
Date:   Thu Sep 7 08:05:48 2017 -0400

    i40e/i40evf: fix incorrect default ITR values on driver load
    
    The ITR register expects to be programmed in units of 2 microseconds.
    Because of this, all of the drivers I40E_ITR_* constants are in terms of
    this 2 microsecond register.
    
    Unfortunately, the rx_itr_default value is expected to be programmed in
    microseconds.
    
    Effectively the driver defaults to an ITR value of half the expected
    value (in terms of minimum microseconds between interrupts).
    
    Fix this by changing the default values to be calculated using
    ITR_REG_TO_USEC macro which indicates that we're converting from the
    register units into microseconds.
    
    Signed-off-by: Jacob Keller <jacob.e.keller@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index a4e3e665a1a1..c3156aa3f709 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -38,8 +38,10 @@
 #define I40E_ITR_8K                0x003E
 #define I40E_ITR_4K                0x007A
 #define I40E_MAX_INTRL             0x3B    /* reg uses 4 usec resolution */
-#define I40E_ITR_RX_DEF            I40E_ITR_20K
-#define I40E_ITR_TX_DEF            I40E_ITR_20K
+#define I40E_ITR_RX_DEF            (ITR_REG_TO_USEC(I40E_ITR_20K) | \
+				    I40E_ITR_DYNAMIC)
+#define I40E_ITR_TX_DEF            (ITR_REG_TO_USEC(I40E_ITR_20K) | \
+				    I40E_ITR_DYNAMIC)
 #define I40E_ITR_DYNAMIC           0x8000  /* use top bit as a flag */
 #define I40E_MIN_INT_RATE          250     /* ~= 1000000 / (I40E_MAX_ITR * 2) */
 #define I40E_MAX_INT_RATE          500000  /* == 1000000 / (I40E_MIN_ITR * 2) */

commit bd6cd4e6dd38a35215d3f28f12db51213c9aead6
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Tue Aug 29 05:32:35 2017 -0400

    i40e/i40evf: use DECLARE_BITMAP for state
    
    When using set_bit and friends, we should be using actual
    bitmaps, and fix all the locations where we might access
    it.
    
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 2f848bc5e391..a4e3e665a1a1 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -342,6 +342,7 @@ struct i40e_rx_queue_stats {
 enum i40e_ring_state_t {
 	__I40E_TX_FDIR_INIT_DONE,
 	__I40E_TX_XPS_INIT_DONE,
+	__I40E_RING_STATE_NBITS /* must be last */
 };
 
 /* some useful defines for virtchannel interface, which
@@ -366,7 +367,7 @@ struct i40e_ring {
 		struct i40e_tx_buffer *tx_bi;
 		struct i40e_rx_buffer *rx_bi;
 	};
-	unsigned long state;
+	DECLARE_BITMAP(state, __I40E_RING_STATE_NBITS);
 	u16 queue_index;		/* Queue number of ring */
 	u8 dcb_tc;			/* Traffic class of ring */
 	u8 __iomem *tail;

commit 742c9875759c1858c3312442a78a80f3e93d82c4
Author: Jacob Keller <jacob.e.keller@intel.com>
Date:   Fri Jul 14 09:10:13 2017 -0400

    i40e/i40evf: avoid dynamic ITR updates when polling or low packet rate
    
    The dynamic ITR algorithm depends on a calculation of usecs which
    assumes that the interrupts have been firing constantly at the interrupt
    throttle rate. This is not guaranteed because we could have a low packet
    rate, or have been polling in software.
    
    We'll estimate whether this is the case by using jiffies to determine if
    we've been too long. If the time difference of jiffies is larger we are
    guaranteed to have an incorrect calculation. If the time difference of
    jiffies is smaller we might have been polling some but the difference
    shouldn't affect the calculation too much.
    
    This ensures that we don't get stuck in BULK latency during certain rare
    situations where we receive bursts of packets that force us into NAPI
    polling.
    
    Signed-off-by: Jacob Keller <jacob.e.keller@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index e6456e8a899c..2f848bc5e391 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -461,6 +461,7 @@ struct i40e_ring_container {
 	struct i40e_ring *ring;
 	unsigned int total_bytes;	/* total bytes processed this int */
 	unsigned int total_packets;	/* total packets processed this int */
+	unsigned long last_itr_update;	/* jiffies of last ITR update */
 	u16 count;
 	enum i40e_latency_range latency_range;
 	u16 itr;

commit 0a2c7722be1705edca34458bd9de2f97188f9636
Author: Jacob Keller <jacob.e.keller@intel.com>
Date:   Fri Jul 14 09:10:12 2017 -0400

    i40e/i40evf: remove ULTRA latency mode
    
    Since commit c56625d59726 ("i40e/i40evf: change dynamic interrupt
    thresholds") a new higher latency ITR setting called I40E_ULTRA_LATENCY
    was added with a cryptic comment about how it was meant for adjusting Rx
    more aggressively when streaming small packets.
    
    This mode was attempting to calculate packets per second and then kick
    in when we have a huge number of small packets.
    
    Unfortunately, the ULTRA setting was kicking in for workloads it wasn't
    intended for including single-thread UDP_STREAM workloads.
    
    This wasn't caught for a variety of reasons. First, the ip_defrag
    routines were improved somewhat which makes the UDP_STREAM test still
    reasonable at 10GbE, even when dropped down to 8k interrupts a second.
    Additionally, some other obvious workloads appear to work fine, such
    as TCP_STREAM.
    
    The number 40k doesn't make sense for a number of reasons. First, we
    absolutely can do more than 40k packets per second. Second, we calculate
    the value inline in an integer, which sometimes can overflow resulting
    in using incorrect values.
    
    If we fix this overflow it makes it even more likely that we'll enter
    ULTRA mode which is the opposite of what we want.
    
    The ULTRA mode was added originally as a way to reduce CPU utilization
    during a small packet workload where we weren't keeping up anyways. It
    should never have been kicking in during these other workloads.
    
    Given the issues outlined above, let's remove the ULTRA latency mode. If
    necessary, a better solution to the CPU utilization issue for small
    packet workloads will be added in a future patch.
    
    Signed-off-by: Jacob Keller <jacob.e.keller@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index f0a0eabc2666..e6456e8a899c 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -454,7 +454,6 @@ enum i40e_latency_range {
 	I40E_LOWEST_LATENCY = 0,
 	I40E_LOW_LATENCY = 1,
 	I40E_BULK_LATENCY = 2,
-	I40E_ULTRA_LATENCY = 3,
 };
 
 struct i40e_ring_container {

commit d36e41dc78d31322f61952a558b817e15e60a855
Author: Jacob Keller <jacob.e.keller@intel.com>
Date:   Fri Jun 23 04:24:46 2017 -0400

    i40e: separate hw_features from runtime changing flags
    
    The number of flags found in pf->flags has grown quite large, and there
    are a lot of different types of flags. Most of the flags are simply
    hardware features which are enabled on some firmware or some MAC types.
    Other flags are dynamic run-time flags which enable or disable certain
    features of the driver.
    
    Separate these two types of flags into pf->hw_features and pf->flags.
    The hw_features list will contain a set of features which are enabled at
    init time. This will not contain toggles or otherwise dynamically
    changing features. These flags should not need atomic protections, as
    they will be set once during init and then be essentially read only.
    
    Everything else will remain in the flags variable. These flags may be
    modified at any time during run time. A future patch may wish to convert
    these flags into set_bit/clear_bit/test_bit or similar approach to
    ensure atomic correctness.
    
    The I40E_FLAG_MFP_ENABLED flag may be a good fit for hw_features but
    currently is used by ethtool in the private flags settings, and thus has
    been left as part of flags.
    
    Additionally, I40E_FLAG_DCB_CAPABLE may be a good fit for the
    hw_features but this patch has not tried to untangle it yet.
    
    Signed-off-by: Jacob Keller <jacob.e.keller@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index a39892d2453d..f0a0eabc2666 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -112,7 +112,7 @@ enum i40e_dyn_idx_t {
 	BIT_ULL(I40E_FILTER_PCTYPE_NONF_MULTICAST_IPV6_UDP))
 
 #define i40e_pf_get_default_rss_hena(pf) \
-	(((pf)->flags & I40E_FLAG_MULTIPLE_TCP_UDP_RSS_PCTYPE) ? \
+	(((pf)->hw_features & I40E_HW_MULTIPLE_TCP_UDP_RSS_PCTYPE) ? \
 	  I40E_DEFAULT_RSS_HENA_EXPANDED : I40E_DEFAULT_RSS_HENA)
 
 /* Supported Rx Buffer Sizes (a multiple of 128) */

commit 1e3a5fd5c0492d2cd37d86dce82ac7899136123f
Author: Mitch Williams <mitch.a.williams@intel.com>
Date:   Fri Jun 23 04:24:43 2017 -0400

    i40e/i40evf: adjust packet size to account for double VLANs
    
    Now that the kernel supports double VLAN tags, we should at least play
    nice. Adjust the max packet size to account for two VLAN tags, not just
    one.
    
    Signed-off-by: Mitch Williams <mitch.a.williams@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index b288d58313a6..a39892d2453d 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -130,6 +130,7 @@ enum i40e_dyn_idx_t {
  * i.e. RXBUFFER_512 --> 1216 byte skb (size-2048 slab)
  */
 #define I40E_RX_HDR_SIZE I40E_RXBUFFER_256
+#define I40E_PACKET_HDR_PAD (ETH_HLEN + ETH_FCS_LEN + (VLAN_HLEN * 2))
 #define i40e_rx_desc i40e_32byte_rx_desc
 
 #define I40E_RX_DMA_ATTR \

commit 74608d17fe29b2cddceea609033019b32e8a0650
Author: Björn Töpel <bjorn.topel@intel.com>
Date:   Wed May 24 07:55:35 2017 +0200

    i40e: add support for XDP_TX action
    
    This patch adds proper XDP_TX action support. For each Tx ring, an
    additional XDP Tx ring is allocated and setup. This version does the
    DMA mapping in the fast-path, which will penalize performance for
    IOMMU enabled systems. Further, debugfs support is not wired up for
    the XDP Tx rings.
    
    Signed-off-by: Björn Töpel <bjorn.topel@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 31f0b162996f..b288d58313a6 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -396,6 +396,7 @@ struct i40e_ring {
 	u16 flags;
 #define I40E_TXR_FLAGS_WB_ON_ITR		BIT(0)
 #define I40E_RXR_FLAGS_BUILD_SKB_ENABLED	BIT(1)
+#define I40E_TXR_FLAGS_XDP			BIT(2)
 
 	/* stats structs */
 	struct i40e_queue_stats	stats;
@@ -438,6 +439,16 @@ static inline void clear_ring_build_skb_enabled(struct i40e_ring *ring)
 	ring->flags &= ~I40E_RXR_FLAGS_BUILD_SKB_ENABLED;
 }
 
+static inline bool ring_is_xdp(struct i40e_ring *ring)
+{
+	return !!(ring->flags & I40E_TXR_FLAGS_XDP);
+}
+
+static inline void set_ring_xdp(struct i40e_ring *ring)
+{
+	ring->flags |= I40E_TXR_FLAGS_XDP;
+}
+
 enum i40e_latency_range {
 	I40E_LOWEST_LATENCY = 0,
 	I40E_LOW_LATENCY = 1,

commit 0c8493d90b6bb0f5c4fe9217db8f7203f24c0f28
Author: Björn Töpel <bjorn.topel@intel.com>
Date:   Wed May 24 07:55:34 2017 +0200

    i40e: add XDP support for pass and drop actions
    
    This commit adds basic XDP support for i40e derived NICs. All XDP
    actions will end up in XDP_DROP.
    
    Signed-off-by: Björn Töpel <bjorn.topel@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index f5de51124cae..31f0b162996f 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -360,6 +360,7 @@ struct i40e_ring {
 	void *desc;			/* Descriptor ring memory */
 	struct device *dev;		/* Used for DMA mapping */
 	struct net_device *netdev;	/* netdev ring maps to */
+	struct bpf_prog *xdp_prog;
 	union {
 		struct i40e_tx_buffer *tx_bi;
 		struct i40e_rx_buffer *rx_bi;

commit ca9ec0888d631c446040a7fab9985afdeb4f73f3
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Wed Apr 5 07:51:02 2017 -0400

    i40e/i40evf: Add support for padding start of frames
    
    This patch adds padding to the start of frames to make room for headroom
    for us to eventually start using build_skb.  Right now we guarantee at
    least NET_SKB_PAD + NET_IP_ALIGN, however we allocate more space if more is
    available.  For example on x86 the headroom should be 192 bytes.
    
    On systems that have too large of a cache line size to support storing 1.5K
    padding and shared info we default to using 3K buffers and reserve
    everything that isn't used for skb_shared_info or the data buffer for
    headroom.
    
    Change-ID: I33c641c9a1ea10cf7cc484c2d20985368d2d709a
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 2f618539a436..f5de51124cae 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -135,6 +135,58 @@ enum i40e_dyn_idx_t {
 #define I40E_RX_DMA_ATTR \
 	(DMA_ATTR_SKIP_CPU_SYNC | DMA_ATTR_WEAK_ORDERING)
 
+/* Attempt to maximize the headroom available for incoming frames.  We
+ * use a 2K buffer for receives and need 1536/1534 to store the data for
+ * the frame.  This leaves us with 512 bytes of room.  From that we need
+ * to deduct the space needed for the shared info and the padding needed
+ * to IP align the frame.
+ *
+ * Note: For cache line sizes 256 or larger this value is going to end
+ *	 up negative.  In these cases we should fall back to the legacy
+ *	 receive path.
+ */
+#if (PAGE_SIZE < 8192)
+#define I40E_2K_TOO_SMALL_WITH_PADDING \
+((NET_SKB_PAD + I40E_RXBUFFER_1536) > SKB_WITH_OVERHEAD(I40E_RXBUFFER_2048))
+
+static inline int i40e_compute_pad(int rx_buf_len)
+{
+	int page_size, pad_size;
+
+	page_size = ALIGN(rx_buf_len, PAGE_SIZE / 2);
+	pad_size = SKB_WITH_OVERHEAD(page_size) - rx_buf_len;
+
+	return pad_size;
+}
+
+static inline int i40e_skb_pad(void)
+{
+	int rx_buf_len;
+
+	/* If a 2K buffer cannot handle a standard Ethernet frame then
+	 * optimize padding for a 3K buffer instead of a 1.5K buffer.
+	 *
+	 * For a 3K buffer we need to add enough padding to allow for
+	 * tailroom due to NET_IP_ALIGN possibly shifting us out of
+	 * cache-line alignment.
+	 */
+	if (I40E_2K_TOO_SMALL_WITH_PADDING)
+		rx_buf_len = I40E_RXBUFFER_3072 + SKB_DATA_ALIGN(NET_IP_ALIGN);
+	else
+		rx_buf_len = I40E_RXBUFFER_1536;
+
+	/* if needed make room for NET_IP_ALIGN */
+	rx_buf_len -= NET_IP_ALIGN;
+
+	return i40e_compute_pad(rx_buf_len);
+}
+
+#define I40E_SKB_PAD i40e_skb_pad()
+#else
+#define I40E_2K_TOO_SMALL_WITH_PADDING false
+#define I40E_SKB_PAD (NET_SKB_PAD + NET_IP_ALIGN)
+#endif
+
 /**
  * i40e_test_staterr - tests bits in Rx descriptor status and error fields
  * @rx_desc: pointer to receive descriptor (in le64 format)
@@ -341,7 +393,8 @@ struct i40e_ring {
 	u8 packet_stride;
 
 	u16 flags;
-#define I40E_TXR_FLAGS_WB_ON_ITR	BIT(0)
+#define I40E_TXR_FLAGS_WB_ON_ITR		BIT(0)
+#define I40E_RXR_FLAGS_BUILD_SKB_ENABLED	BIT(1)
 
 	/* stats structs */
 	struct i40e_queue_stats	stats;
@@ -369,6 +422,21 @@ struct i40e_ring {
 					 */
 } ____cacheline_internodealigned_in_smp;
 
+static inline bool ring_uses_build_skb(struct i40e_ring *ring)
+{
+	return !!(ring->flags & I40E_RXR_FLAGS_BUILD_SKB_ENABLED);
+}
+
+static inline void set_ring_build_skb_enabled(struct i40e_ring *ring)
+{
+	ring->flags |= I40E_RXR_FLAGS_BUILD_SKB_ENABLED;
+}
+
+static inline void clear_ring_build_skb_enabled(struct i40e_ring *ring)
+{
+	ring->flags &= ~I40E_RXR_FLAGS_BUILD_SKB_ENABLED;
+}
+
 enum i40e_latency_range {
 	I40E_LOWEST_LATENCY = 0,
 	I40E_LOW_LATENCY = 1,

commit 98efd69493b9d4b02353a552af8ffaaf30de8af4
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Wed Apr 5 07:51:01 2017 -0400

    i40e/i40evf: Add support for using order 1 pages with a 3K buffer
    
    There are situations where adding padding to the front and back of an Rx
    buffer will require that we add additional padding.  Specifically if
    NET_IP_ALIGN is non-zero, or the MTU size is larger than 7.5K we would need
    to use 2K buffers which leaves us with no room for the padding.
    
    To preemptively address these cases I am adding support for 3K buffers to
    the Rx path so that we can provide the additional padding needed in the
    event of NET_IP_ALIGN being non-zero or a cache line being greater than 64.
    
    Change-ID: I938bc1ba611285428df39a613cd66f98e60b55c7
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index bc66ec4954d9..2f618539a436 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -119,6 +119,7 @@ enum i40e_dyn_idx_t {
 #define I40E_RXBUFFER_256   256
 #define I40E_RXBUFFER_1536  1536  /* 128B aligned standard Ethernet frame */
 #define I40E_RXBUFFER_2048  2048
+#define I40E_RXBUFFER_3072  3072  /* Used for large frames w/ padding */
 #define I40E_MAX_RXBUFFER   9728  /* largest size for single descriptor */
 
 /* NOTE: netdev_alloc_skb reserves up to 64 bytes, NET_IP_ALIGN means we
@@ -389,6 +390,17 @@ struct i40e_ring_container {
 #define i40e_for_each_ring(pos, head) \
 	for (pos = (head).ring; pos != NULL; pos = pos->next)
 
+static inline unsigned int i40e_rx_pg_order(struct i40e_ring *ring)
+{
+#if (PAGE_SIZE < 8192)
+	if (ring->rx_buf_len > (PAGE_SIZE / 2))
+		return 1;
+#endif
+	return 0;
+}
+
+#define i40e_rx_pg_size(_ring) (PAGE_SIZE << i40e_rx_pg_order(_ring))
+
 bool i40e_alloc_rx_buffers(struct i40e_ring *rxr, u16 cleaned_count);
 netdev_tx_t i40e_lan_xmit_frame(struct sk_buff *skb, struct net_device *netdev);
 void i40e_clean_tx_ring(struct i40e_ring *tx_ring);

commit 17daabb5e8db2b7de742f59dd73aa12550143e0d
Author: Alan Brady <alan.brady@intel.com>
Date:   Wed Apr 5 07:50:56 2017 -0400

    i40e: Simplify i40e_detect_recover_hung_queue logic
    
    This patch greatly reduces the unneeded complexity in the
    i40e_detect_recover_hung_queue code path.  The previous implementation
    set a 'hung bit' which would then get cleared while polling.  If the
    detection routine was called a second time with the bit already set, we
    would issue a software interrupt.  This patch makes it such that if
    interrupts are disabled and we have pending TX descriptors, we trigger a
    software interrupt since in, the worst case, queues are already clean
    and we have an extra interrupt.
    
    Additionally this patch removes the workaround for lost interrupts as
    calling napi_reschedule in this context can cause software interrupts to
    fire on the wrong CPU.
    
    Change-ID: Iae108582a3ceb6229ed1d22e4ed6e69cf97aad8d
    Signed-off-by: Alan Brady <alan.brady@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index d6609deace57..bc66ec4954d9 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -275,7 +275,6 @@ struct i40e_tx_queue_stats {
 	u64 tx_done_old;
 	u64 tx_linearize;
 	u64 tx_force_wb;
-	u64 tx_lost_interrupt;
 };
 
 struct i40e_rx_queue_stats {
@@ -400,7 +399,7 @@ void i40e_free_tx_resources(struct i40e_ring *tx_ring);
 void i40e_free_rx_resources(struct i40e_ring *rx_ring);
 int i40e_napi_poll(struct napi_struct *napi, int budget);
 void i40e_force_wb(struct i40e_vsi *vsi, struct i40e_q_vector *q_vector);
-u32 i40e_get_tx_pending(struct i40e_ring *ring, bool in_sw);
+u32 i40e_get_tx_pending(struct i40e_ring *ring);
 int __i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size);
 bool __i40e_chk_linearize(struct sk_buff *skb);
 

commit dab86afdbbd1bc5d5a89b67ed141d2f46c3b4191
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Tue Mar 14 10:15:27 2017 -0700

    i40e/i40evf: Change the way we limit the maximum frame size for Rx
    
    This patch changes the way we handle the maximum frame size for the Rx
    path.  Previously we were rounding up to 2K for a 1500 MTU and then brining
    the max frame size down to MTU plus a fixed amount.  With this patch
    applied what we now do is limit the maximum frame to 1.5K minus the value
    for NET_IP_ALIGN for standard MTU, and for any MTU greater than 1500 we
    allow up to the maximum frame size.  This makes the behavior more
    consistent with the other drivers such as igb which had similar logic.  In
    addition it reduces the test matrix for MTU since we only have two max
    frame sizes that are handled for Rx now.
    
    Change-ID: I23a9d3c857e7df04b0ef28c64df63e659c013f3f
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index eb733726637f..d6609deace57 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -117,10 +117,8 @@ enum i40e_dyn_idx_t {
 
 /* Supported Rx Buffer Sizes (a multiple of 128) */
 #define I40E_RXBUFFER_256   256
+#define I40E_RXBUFFER_1536  1536  /* 128B aligned standard Ethernet frame */
 #define I40E_RXBUFFER_2048  2048
-#define I40E_RXBUFFER_3072  3072   /* For FCoE MTU of 2158 */
-#define I40E_RXBUFFER_4096  4096
-#define I40E_RXBUFFER_8192  8192
 #define I40E_MAX_RXBUFFER   9728  /* largest size for single descriptor */
 
 /* NOTE: netdev_alloc_skb reserves up to 64 bytes, NET_IP_ALIGN means we

commit 9eed69a9147c27aeb016c55b30d810b39bf38662
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Tue Feb 21 15:55:47 2017 -0800

    i40e: Drop FCoE code from core driver files
    
    Looking over the code for FCoE it looks like the Rx path has been broken at
    least since the last major Rx refactor almost a year ago.  It seems like
    FCoE isn't supported for any of the Fortville/Fortpark hardware so there
    isn't much point in carrying the code around, especially if it is broken
    and untested.
    
    Change-ID: I892de8fa551cb129ce2361e738ff82ce55fa229e
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 77c3e96f5172..eb733726637f 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -401,13 +401,6 @@ int i40e_setup_rx_descriptors(struct i40e_ring *rx_ring);
 void i40e_free_tx_resources(struct i40e_ring *tx_ring);
 void i40e_free_rx_resources(struct i40e_ring *rx_ring);
 int i40e_napi_poll(struct napi_struct *napi, int budget);
-#ifdef I40E_FCOE
-void i40e_tx_map(struct i40e_ring *tx_ring, struct sk_buff *skb,
-		 struct i40e_tx_buffer *first, u32 tx_flags,
-		 const u8 hdr_len, u32 td_cmd, u32 td_offset);
-int i40e_tx_prepare_vlan_flags(struct sk_buff *skb,
-			       struct i40e_ring *tx_ring, u32 *flags);
-#endif
 void i40e_force_wb(struct i40e_vsi *vsi, struct i40e_q_vector *q_vector);
 u32 i40e_get_tx_pending(struct i40e_ring *ring, bool in_sw);
 int __i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size);
@@ -490,16 +483,6 @@ static inline bool i40e_chk_linearize(struct sk_buff *skb, int count)
 	return count != I40E_MAX_BUFFER_TXD;
 }
 
-/**
- * i40e_rx_is_fcoe - returns true if the Rx packet type is FCoE
- * @ptype: the packet type field from Rx descriptor write-back
- **/
-static inline bool i40e_rx_is_fcoe(u16 ptype)
-{
-	return (ptype >= I40E_RX_PTYPE_L2_FCOE_PAY3) &&
-	       (ptype <= I40E_RX_PTYPE_L2_FCOE_VFT_FCOTHER);
-}
-
 /**
  * txring_txq - Find the netdev Tx ring based on the i40e Tx ring
  * @ring: Tx ring to find the netdev equivalent of

commit 1793668c3b8c18ede309dfec30f7c486cca00d28
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Tue Feb 21 15:55:39 2017 -0800

    i40e/i40evf: Update code to better handle incrementing page count
    
    Update the driver code so that we do bulk updates of the page reference
    count instead of just incrementing it by one reference at a time.  The
    advantage to doing this is that we cut down on atomic operations and
    this in turn should give us a slight improvement in cycles per packet.
    In addition if we eventually move this over to using build_skb the gains
    will be more noticeable.
    
    I also found and fixed a store forwarding stall from where we were
    assigning "*new_buff = *old_buff".  By breaking it up into individual
    copies we can avoid this and as a result the performance is slightly
    improved.
    
    Change-ID: I1d3880dece4133eca3c32423b04a5467321ccc52
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 49c7b2089d8e..77c3e96f5172 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -258,7 +258,12 @@ struct i40e_tx_buffer {
 struct i40e_rx_buffer {
 	dma_addr_t dma;
 	struct page *page;
-	unsigned int page_offset;
+#if (BITS_PER_LONG > 32) || (PAGE_SIZE >= 65536)
+	__u32 page_offset;
+#else
+	__u16 page_offset;
+#endif
+	__u16 pagecnt_bias;
 };
 
 struct i40e_queue_stats {

commit 59605bc09630c2b577858c371edf89c099b5f925
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Mon Jan 30 12:29:35 2017 -0800

    i40e/i40evf: Add support for mapping pages with DMA attributes
    
    This patch adds support for DMA_ATTR_SKIP_CPU_SYNC and
    DMA_ATTR_WEAK_ORDERING. By enabling both of these for the Rx path we
    are able to see performance improvements on architectures that implement
    either one due to the fact that page mapping and unmapping only has to
    sync what is actually being used instead of the entire buffer. In addition
    by enabling the weak ordering attribute enables a performance improvement
    for architectures that can associate a memory ordering with a DMA buffer
    such as Sparc.
    
    Change-ID: If176824e8231c5b24b8a5d55b339a6026738fc75
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index f80979025c01..49c7b2089d8e 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -133,6 +133,9 @@ enum i40e_dyn_idx_t {
 #define I40E_RX_HDR_SIZE I40E_RXBUFFER_256
 #define i40e_rx_desc i40e_32byte_rx_desc
 
+#define I40E_RX_DMA_ATTR \
+	(DMA_ATTR_SKIP_CPU_SYNC | DMA_ATTR_WEAK_ORDERING)
+
 /**
  * i40e_test_staterr - tests bits in Rx descriptor status and error fields
  * @rx_desc: pointer to receive descriptor (in le64 format)

commit e72e56597ba15ce70f4fc1eb2ceeaa8da0d4ab5e
Author: Scott Peterson <scott.d.peterson@intel.com>
Date:   Thu Feb 9 23:40:25 2017 -0800

    i40e/i40evf: Moves skb from i40e_rx_buffer to i40e_ring
    
    This patch reduces the size of struct i40e_rx_buffer by one pointer,
    and makes the i40e driver a little more consistent with the igb driver
    in terms of packets that span buffers.
    
    We do this by moving the skb field from struct i40e_rx_buffer to
    struct i40e_ring. We pass the skb we already have (or NULL if we
    don't) to i40e_fetch_rx_buffer(), which skips the skb allocation if we
    already have one for this packet.
    
    Change-ID: I4ad48a531844494ba0c5d8e1a62209a057f661b0
    Signed-off-by: Scott Peterson <scott.d.peterson@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 1ea820e9debe..f80979025c01 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -253,7 +253,6 @@ struct i40e_tx_buffer {
 };
 
 struct i40e_rx_buffer {
-	struct sk_buff *skb;
 	dma_addr_t dma;
 	struct page *page;
 	unsigned int page_offset;
@@ -354,6 +353,14 @@ struct i40e_ring {
 
 	struct rcu_head rcu;		/* to avoid race on free */
 	u16 next_to_alloc;
+	struct sk_buff *skb;		/* When i40e_clean_rx_ring_irq() must
+					 * return before it sees the EOP for
+					 * the current packet, we save that skb
+					 * here and resume receiving this
+					 * packet the next time
+					 * i40e_clean_rx_ring_irq() is called
+					 * for this ring.
+					 */
 } ____cacheline_internodealigned_in_smp;
 
 enum i40e_latency_range {

commit 1c0e6a3613d3f0bb088a3160095c8da4c1214d02
Author: Alan Brady <alan.brady@intel.com>
Date:   Mon Nov 28 16:06:02 2016 -0800

    i40e: refactor macro INTRL_USEC_TO_REG
    
    This patch refactors the macro INTRL_USEC_TO_REG into a static inline
    function and fixes a couple subtle bugs caused by the macro.
    
    This patch fixes a bug which was caused by passing a bad register value
    to the firmware.  If enabling interrupt rate limiting, a non-zero value
    for the rate limit must be used.  Otherwise the firmware sets the
    interrupt rate limit to the maximum value.  Due to the limited
    resolution of the register, attempting to set a value of 1, 2, or 3
    would be rounded down to 0 and limiting was left enabled, causing
    unexpected behavior.
    
    This patch also fixes a possible bug in which using the macro itself can
    introduce unintended side-affects because the macro argument is used
    more than once in the macro definition (e.g. a variable post-increment
    argument would perform a double increment on the variable).
    
    Without this patch, attempting to set interrupt rate limits of 1, 2, or
    3 results in unexpected behavior and future use of this macro could
    cause subtle bugs.
    
    Change-Id: I83ac842de0ca9c86761923d6e3a4d7b1b95f2b3f
    Signed-off-by: Alan Brady <alan.brady@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index e065321ce8ed..1ea820e9debe 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -52,7 +52,20 @@
  */
 #define INTRL_ENA                  BIT(6)
 #define INTRL_REG_TO_USEC(intrl) ((intrl & ~INTRL_ENA) << 2)
-#define INTRL_USEC_TO_REG(set) ((set) ? ((set) >> 2) | INTRL_ENA : 0)
+/**
+ * i40e_intrl_usec_to_reg - convert interrupt rate limit to register
+ * @intrl: interrupt rate limit to convert
+ *
+ * This function converts a decimal interrupt rate limit to the appropriate
+ * register format expected by the firmware when setting interrupt rate limit.
+ */
+static inline u16 i40e_intrl_usec_to_reg(int intrl)
+{
+	if (intrl >> 2)
+		return ((intrl >> 2) | INTRL_ENA);
+	else
+		return 0;
+}
 #define I40E_INTRL_8K              125     /* 8000 ints/sec */
 #define I40E_INTRL_62K             16      /* 62500 ints/sec */
 #define I40E_INTRL_83K             12      /* 83333 ints/sec */

commit 4293d5f528b5a0a1b0c1b0c6eb522366822a965a
Author: Mitch Williams <mitch.a.williams@intel.com>
Date:   Tue Nov 8 13:05:14 2016 -0800

    i40e: simplify txd use count calculation
    
    The i40e_txd_use_count function was fast but confusing. In the comments,
    it even admits that it's ugly. So replace it with a new function that is
    (very) slightly faster and has extensive commenting to help the thicker
    among us (including the author, who will forget in a week) understand
    how it works.
    
    Change-ID: Ifb533f13786a0bf39cb29f77969a5be2c83d9a87
    Signed-off-by: Mitch Williams <mitch.a.williams@intel.com>
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index de8550f4e3a4..e065321ce8ed 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -173,26 +173,37 @@ static inline bool i40e_test_staterr(union i40e_rx_desc *rx_desc,
 #define I40E_MAX_DATA_PER_TXD_ALIGNED \
 	(I40E_MAX_DATA_PER_TXD & ~(I40E_MAX_READ_REQ_SIZE - 1))
 
-/* This ugly bit of math is equivalent to DIV_ROUNDUP(size, X) where X is
- * the value I40E_MAX_DATA_PER_TXD_ALIGNED.  It is needed due to the fact
- * that 12K is not a power of 2 and division is expensive.  It is used to
- * approximate the number of descriptors used per linear buffer.  Note
- * that this will overestimate in some cases as it doesn't account for the
- * fact that we will add up to 4K - 1 in aligning the 12K buffer, however
- * the error should not impact things much as large buffers usually mean
- * we will use fewer descriptors then there are frags in an skb.
+/**
+ * i40e_txd_use_count  - estimate the number of descriptors needed for Tx
+ * @size: transmit request size in bytes
+ *
+ * Due to hardware alignment restrictions (4K alignment), we need to
+ * assume that we can have no more than 12K of data per descriptor, even
+ * though each descriptor can take up to 16K - 1 bytes of aligned memory.
+ * Thus, we need to divide by 12K. But division is slow! Instead,
+ * we decompose the operation into shifts and one relatively cheap
+ * multiply operation.
+ *
+ * To divide by 12K, we first divide by 4K, then divide by 3:
+ *     To divide by 4K, shift right by 12 bits
+ *     To divide by 3, multiply by 85, then divide by 256
+ *     (Divide by 256 is done by shifting right by 8 bits)
+ * Finally, we add one to round up. Because 256 isn't an exact multiple of
+ * 3, we'll underestimate near each multiple of 12K. This is actually more
+ * accurate as we have 4K - 1 of wiggle room that we can fit into the last
+ * segment.  For our purposes this is accurate out to 1M which is orders of
+ * magnitude greater than our largest possible GSO size.
+ *
+ * This would then be implemented as:
+ *     return (((size >> 12) * 85) >> 8) + 1;
+ *
+ * Since multiplication and division are commutative, we can reorder
+ * operations into:
+ *     return ((size * 85) >> 20) + 1;
  */
 static inline unsigned int i40e_txd_use_count(unsigned int size)
 {
-	const unsigned int max = I40E_MAX_DATA_PER_TXD_ALIGNED;
-	const unsigned int reciprocal = ((1ull << 32) - 1 + (max / 2)) / max;
-	unsigned int adjust = ~(u32)0;
-
-	/* if we rounded up on the reciprocal pull down the adjustment */
-	if ((max * reciprocal) > adjust)
-		adjust = ~(u32)(reciprocal - 1);
-
-	return (u32)((((u64)size * reciprocal) + adjust) >> 32);
+	return ((size * 85) >> 20) + 1;
 }
 
 /* Tx Descriptors needed, worst case */

commit 1dc8b538795fcf92161cc056ceebb852cf375b17
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Tue Oct 11 15:26:54 2016 -0700

    i40e: Reorder logic for coalescing RS bits
    
    This patch reorders the logic at the end of i40e_tx_map to address the
    fact that the logic was rather convoluted and much larger than it needed
    to be.
    
    In order to try and coalesce the code paths I have updated some of the
    comments and repurposed some of the variables in order to reduce
    unnecessary overhead.
    
    This patch does the following:
    1.  Quit tracking skb->xmit_more with a flag, just max out packet_stride
    2.  Drop tail_bump and do_rs and instead just use desc_count and td_cmd
    3.  Pull comments from ixgbe that make need for wmb() more explicit.
    
    Change-ID: Ic7da85ec75043c634e87fef958109789bcc6317c
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 42f04d69c4d1..de8550f4e3a4 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -313,7 +313,6 @@ struct i40e_ring {
 
 	u16 flags;
 #define I40E_TXR_FLAGS_WB_ON_ITR	BIT(0)
-#define I40E_TXR_FLAGS_LAST_XMIT_MORE_SET BIT(2)
 
 	/* stats structs */
 	struct i40e_queue_stats	stats;

commit 124905012db8bdeebf5a7d1ddc841eaadda84a75
Author: Jacob Keller <jacob.e.keller@intel.com>
Date:   Wed Oct 5 09:30:44 2016 -0700

    i40e: replace PTP Rx timestamp hang logic
    
    The current Rx timestamp hang logic is not very robust because it does
    not notice a register is hung until all four timestamps have been
    latched and we wait a full 5 seconds. Replace this logic with a newer Rx
    hang detection based on storing the jiffies when we first notice
    a receive timestamp event. We store each register's time separately,
    along with a flag indicating if it is currently latched. Upon first
    transitioning to latch, we will update the latch_events[i] jiffies
    value. This indicates the time we first noticed this event. The watchdog
    routine will simply check that the either the flag has been cleared, or
    we have passed at least one second. In this case, it is able to clear
    the Rx timestamp register under the assumption that it was for a dropped
    frame. The benefit if this strategy is that we should be able to
    detect and clear out stalled RXTIME_H registers before we exhaust the
    supply of 4, and avoid complete stall of Rx timestamp events.
    
    Change-ID: Id55458c0cd7a5dd0c951ff2b8ac0b2509364131f
    Signed-off-by: Jacob Keller <jacob.e.keller@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 508840585645..42f04d69c4d1 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -307,8 +307,6 @@ struct i40e_ring {
 	u8 atr_sample_rate;
 	u8 atr_count;
 
-	unsigned long last_rx_timestamp;
-
 	bool ring_active;		/* is ring online or not */
 	bool arm_wb;		/* do something to arm write back */
 	u8 packet_stride;

commit e486bdfd7c491e997f29fcdf6a4216861ab1d06a
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Mon Sep 12 14:18:40 2016 -0700

    i40e/i40evf: Add txring_txq function to match fm10k and ixgbe
    
    This patch adds a txring_txq function which allows us to convert a
    i40e_ring/i40evf_ring to a netdev_tx_queue structure.  This way we
    can avoid having to make a multi-line function call for all the spots
    that need access to this.
    
    Change-ID: Ic063b71d8b92ea406d2c32e798c8e2b02809d65b
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index b78c810d1835..508840585645 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -463,4 +463,13 @@ static inline bool i40e_rx_is_fcoe(u16 ptype)
 	return (ptype >= I40E_RX_PTYPE_L2_FCOE_PAY3) &&
 	       (ptype <= I40E_RX_PTYPE_L2_FCOE_VFT_FCOTHER);
 }
+
+/**
+ * txring_txq - Find the netdev Tx ring based on the i40e Tx ring
+ * @ring: Tx ring to find the netdev equivalent of
+ **/
+static inline struct netdev_queue *txring_txq(const struct i40e_ring *ring)
+{
+	return netdev_get_tx_queue(ring->netdev, ring->queue_index);
+}
 #endif /* _I40E_TXRX_H_ */

commit bec60fc42b285344b027c87444c7fd6caade0ceb
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Mon Apr 18 11:33:47 2016 -0700

    i40e/i40evf: Remove unused hardware receive descriptor code
    
    The hardware supports a 16 byte descriptor for receive, but the
    driver was never using it in production.  There was no performance
    benefit to the real driver of 16 byte descriptors, so drop a whole
    lot of complexity while getting rid of the code.
    
    Also since the previous patch made us use no-split mode all the
    time, drop any support in the driver for any other value in dtype
    and assume it is always zero (aka no-split).
    
    Hooray for code removal!
    
    Change-ID: I2257e902e4dad84a07b94db6d2e6f4ce69b27bc0
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 37643e6b3afd..b78c810d1835 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -260,15 +260,18 @@ struct i40e_rx_queue_stats {
 enum i40e_ring_state_t {
 	__I40E_TX_FDIR_INIT_DONE,
 	__I40E_TX_XPS_INIT_DONE,
-	__I40E_RX_16BYTE_DESC_ENABLED,
 };
 
-#define ring_is_16byte_desc_enabled(ring) \
-	test_bit(__I40E_RX_16BYTE_DESC_ENABLED, &(ring)->state)
-#define set_ring_16byte_desc_enabled(ring) \
-	set_bit(__I40E_RX_16BYTE_DESC_ENABLED, &(ring)->state)
-#define clear_ring_16byte_desc_enabled(ring) \
-	clear_bit(__I40E_RX_16BYTE_DESC_ENABLED, &(ring)->state)
+/* some useful defines for virtchannel interface, which
+ * is the only remaining user of header split
+ */
+#define I40E_RX_DTYPE_NO_SPLIT      0
+#define I40E_RX_DTYPE_HEADER_SPLIT  1
+#define I40E_RX_DTYPE_SPLIT_ALWAYS  2
+#define I40E_RX_SPLIT_L2      0x1
+#define I40E_RX_SPLIT_IP      0x2
+#define I40E_RX_SPLIT_TCP_UDP 0x4
+#define I40E_RX_SPLIT_SCTP    0x8
 
 /* struct that defines a descriptor ring, associated with a VSI */
 struct i40e_ring {
@@ -296,13 +299,6 @@ struct i40e_ring {
 	u16 count;			/* Number of descriptors */
 	u16 reg_idx;			/* HW register index of the ring */
 	u16 rx_buf_len;
-#define I40E_RX_DTYPE_NO_SPLIT      0
-#define I40E_RX_DTYPE_HEADER_SPLIT  1
-#define I40E_RX_DTYPE_SPLIT_ALWAYS  2
-#define I40E_RX_SPLIT_L2      0x1
-#define I40E_RX_SPLIT_IP      0x2
-#define I40E_RX_SPLIT_TCP_UDP 0x4
-#define I40E_RX_SPLIT_SCTP    0x8
 
 	/* used in interrupt processing */
 	u16 next_to_use;

commit 1a557afc4dd59b85a5cae2be6d351eaeb31d2664
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Wed Apr 20 19:43:37 2016 -0700

    i40e: Refactor receive routine
    
    This is part 1 of the Rx refactor series, just including
    changes to i40e.
    
    This refactor aligns the receive routine with the one in
    ixgbe which was highly optimized.  This reduces the code
    we have to maintain and allows for (hopefully) more readable
    and maintainable RX hot path.
    
    In order to do this:
    - consolidate the receive path into a single function that doesn't
      use packet split but *does* use pages for Rx buffers.
    - remove the old _1buf routine
    - consolidate several routines into helper functions
    - remove ethtool control over packet split
    
    Change-ID: I5ca100721de65992aa0114f8b4bac844b84758e0
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 03e21d95c4f1..37643e6b3afd 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -102,8 +102,8 @@ enum i40e_dyn_idx_t {
 	(((pf)->flags & I40E_FLAG_MULTIPLE_TCP_UDP_RSS_PCTYPE) ? \
 	  I40E_DEFAULT_RSS_HENA_EXPANDED : I40E_DEFAULT_RSS_HENA)
 
-/* Supported Rx Buffer Sizes */
-#define I40E_RXBUFFER_512   512    /* Used for packet split */
+/* Supported Rx Buffer Sizes (a multiple of 128) */
+#define I40E_RXBUFFER_256   256
 #define I40E_RXBUFFER_2048  2048
 #define I40E_RXBUFFER_3072  3072   /* For FCoE MTU of 2158 */
 #define I40E_RXBUFFER_4096  4096
@@ -114,9 +114,28 @@ enum i40e_dyn_idx_t {
  * reserve 2 more, and skb_shared_info adds an additional 384 bytes more,
  * this adds up to 512 bytes of extra data meaning the smallest allocation
  * we could have is 1K.
- * i.e. RXBUFFER_512 --> size-1024 slab
+ * i.e. RXBUFFER_256 --> 960 byte skb (size-1024 slab)
+ * i.e. RXBUFFER_512 --> 1216 byte skb (size-2048 slab)
  */
-#define I40E_RX_HDR_SIZE  I40E_RXBUFFER_512
+#define I40E_RX_HDR_SIZE I40E_RXBUFFER_256
+#define i40e_rx_desc i40e_32byte_rx_desc
+
+/**
+ * i40e_test_staterr - tests bits in Rx descriptor status and error fields
+ * @rx_desc: pointer to receive descriptor (in le64 format)
+ * @stat_err_bits: value to mask
+ *
+ * This function does some fast chicanery in order to return the
+ * value of the mask which is really only used for boolean tests.
+ * The status_error_len doesn't need to be shifted because it begins
+ * at offset zero.
+ */
+static inline bool i40e_test_staterr(union i40e_rx_desc *rx_desc,
+				     const u64 stat_err_bits)
+{
+	return !!(rx_desc->wb.qword1.status_error_len &
+		  cpu_to_le64(stat_err_bits));
+}
 
 /* How many Rx Buffers do we bundle into one write to the hardware ? */
 #define I40E_RX_BUFFER_WRITE	16	/* Must be power of 2 */
@@ -142,8 +161,6 @@ enum i40e_dyn_idx_t {
 		prefetch((n));				\
 	} while (0)
 
-#define i40e_rx_desc i40e_32byte_rx_desc
-
 #define I40E_MAX_BUFFER_TXD	8
 #define I40E_MIN_TX_LEN		17
 
@@ -213,10 +230,8 @@ struct i40e_tx_buffer {
 
 struct i40e_rx_buffer {
 	struct sk_buff *skb;
-	void *hdr_buf;
 	dma_addr_t dma;
 	struct page *page;
-	dma_addr_t page_dma;
 	unsigned int page_offset;
 };
 
@@ -280,7 +295,6 @@ struct i40e_ring {
 
 	u16 count;			/* Number of descriptors */
 	u16 reg_idx;			/* HW register index of the ring */
-	u16 rx_hdr_len;
 	u16 rx_buf_len;
 #define I40E_RX_DTYPE_NO_SPLIT      0
 #define I40E_RX_DTYPE_HEADER_SPLIT  1
@@ -322,6 +336,7 @@ struct i40e_ring {
 	struct i40e_q_vector *q_vector;	/* Backreference to associated vector */
 
 	struct rcu_head rcu;		/* to avoid race on free */
+	u16 next_to_alloc;
 } ____cacheline_internodealigned_in_smp;
 
 enum i40e_latency_range {
@@ -345,9 +360,7 @@ struct i40e_ring_container {
 #define i40e_for_each_ring(pos, head) \
 	for (pos = (head).ring; pos != NULL; pos = pos->next)
 
-bool i40e_alloc_rx_buffers_ps(struct i40e_ring *rxr, u16 cleaned_count);
-bool i40e_alloc_rx_buffers_1buf(struct i40e_ring *rxr, u16 cleaned_count);
-void i40e_alloc_rx_headers(struct i40e_ring *rxr);
+bool i40e_alloc_rx_buffers(struct i40e_ring *rxr, u16 cleaned_count);
 netdev_tx_t i40e_lan_xmit_frame(struct sk_buff *skb, struct net_device *netdev);
 void i40e_clean_tx_ring(struct i40e_ring *tx_ring);
 void i40e_clean_rx_ring(struct i40e_ring *rx_ring);

commit 04b3b779816502549e5f4bfaf5df90204ce2fe0e
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Mon Apr 18 11:33:43 2016 -0700

    i40e/i40evf: Remove reference to ring->dtype
    
    As part of the rx-refactor, the dtype variable in the i40e_ring
    struct is no longer used, so remove it.
    
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 5a2d0fef4d37..03e21d95c4f1 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -282,7 +282,6 @@ struct i40e_ring {
 	u16 reg_idx;			/* HW register index of the ring */
 	u16 rx_hdr_len;
 	u16 rx_buf_len;
-	u8  dtype;
 #define I40E_RX_DTYPE_NO_SPLIT      0
 #define I40E_RX_DTYPE_HEADER_SPLIT  1
 #define I40E_RX_DTYPE_SPLIT_ALWAYS  2

commit b32bfa17246d836125958e39996a674653e899a5
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Mon Apr 18 11:33:42 2016 -0700

    i40e: Drop packet split receive routine
    
    As part of preparation for the rx-refactor, remove the
    packet split receive routine and ancillary code.
    
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 6b2b1913527d..5a2d0fef4d37 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -245,16 +245,9 @@ struct i40e_rx_queue_stats {
 enum i40e_ring_state_t {
 	__I40E_TX_FDIR_INIT_DONE,
 	__I40E_TX_XPS_INIT_DONE,
-	__I40E_RX_PS_ENABLED,
 	__I40E_RX_16BYTE_DESC_ENABLED,
 };
 
-#define ring_is_ps_enabled(ring) \
-	test_bit(__I40E_RX_PS_ENABLED, &(ring)->state)
-#define set_ring_ps_enabled(ring) \
-	set_bit(__I40E_RX_PS_ENABLED, &(ring)->state)
-#define clear_ring_ps_enabled(ring) \
-	clear_bit(__I40E_RX_PS_ENABLED, &(ring)->state)
 #define ring_is_16byte_desc_enabled(ring) \
 	test_bit(__I40E_RX_16BYTE_DESC_ENABLED, &(ring)->state)
 #define set_ring_16byte_desc_enabled(ring) \

commit 1602f49b58abcb0d34a5f0a29d68e7c1769547aa
Merge: 22d37b6b0058 5f44abd041c5
Author: David S. Miller <davem@davemloft.net>
Date:   Sat Apr 23 18:26:24 2016 -0400

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Conflicts were two cases of simple overlapping changes,
    nothing serious.
    
    In the UDP case, we need to add a hlist_add_tail_rcu()
    to linux/rculist.h, because we've moved UDP socket handling
    away from using nulls lists.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 3f3f7cb875c0f621485644d4fd7453b0d37f00e4
Author: Alexander Duyck <aduyck@mirantis.com>
Date:   Wed Mar 30 16:15:37 2016 -0700

    i40e/i40evf: Limit TSO to 7 descriptors for payload instead of 8 per packet
    
    This patch addresses a bug introduced based on my interpretation of the
    XL710 datasheet.  Specifically section 8.4.1 states that "A single transmit
    packet may span up to 8 buffers (up to 8 data descriptors per packet
    including both the header and payload buffers)."  It then later goes on to
    say that each segment for a TSO obeys the previous rule, however it then
    refers to TSO header and the segment payload buffers.
    
    I believe the actual limit for fragments with TSO and a skbuff that has
    payload data in the header portion of the buffer is actually only 7
    fragments as the skb->data portion counts as 2 buffers, one for the TSO
    header, and one for a segment payload buffer.
    
    Fixes: 2d37490b82af ("i40e/i40evf: Rewrite logic for 8 descriptor per packet check")
    Reported-by: Sowmini Varadhan <sowmini.varadhan@oracle.com>
    Signed-off-by: Alexander Duyck <aduyck@mirantis.com>
    Acked-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Sowmini Varadhan <sowmini.varadhan@oracle.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index cdd5dc00aec5..a9bd70537d65 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -413,10 +413,14 @@ static inline int i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size)
  **/
 static inline bool i40e_chk_linearize(struct sk_buff *skb, int count)
 {
-	/* we can only support up to 8 data buffers for a single send */
-	if (likely(count <= I40E_MAX_BUFFER_TXD))
+	/* Both TSO and single send will work if count is less than 8 */
+	if (likely(count < I40E_MAX_BUFFER_TXD))
 		return false;
 
-	return __i40e_chk_linearize(skb);
+	if (skb_is_gso(skb))
+		return __i40e_chk_linearize(skb);
+
+	/* we can support up to 8 data buffers for a single send */
+	return count != I40E_MAX_BUFFER_TXD;
 }
 #endif /* _I40E_TXRX_H_ */

commit 1f15d66712bb64e39fe2c23b1b32f68f9e1d4ee7
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Fri Apr 1 03:56:06 2016 -0700

    i40e/i40evf: Faster RX via avoiding FCoE
    
    As it turns out, calling into other files from hot path hurts
    performance a lot.  In this case the majority of the time we
    call "check FCoE" and the packet is *not* FCoE, but this call
    was taking 5% of our total cycles spent on receive.
    
    Change-ID: I080552c26e7060bc7b78504dc2763f6f0b3d8c76
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 9e654e611642..77ccdde56c0c 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -448,4 +448,14 @@ static inline bool i40e_chk_linearize(struct sk_buff *skb, int count)
 
 	return __i40e_chk_linearize(skb);
 }
+
+/**
+ * i40e_rx_is_fcoe - returns true if the Rx packet type is FCoE
+ * @ptype: the packet type field from Rx descriptor write-back
+ **/
+static inline bool i40e_rx_is_fcoe(u16 ptype)
+{
+	return (ptype >= I40E_RX_PTYPE_L2_FCOE_PAY3) &&
+	       (ptype <= I40E_RX_PTYPE_L2_FCOE_VFT_FCOTHER);
+}
 #endif /* _I40E_TXRX_H_ */

commit 5c4654daf2e2f25dfbd7fa572c59937ea6d4198b
Author: Alexander Duyck <aduyck@mirantis.com>
Date:   Fri Feb 19 12:17:08 2016 -0800

    i40e/i40evf: Allow up to 12K bytes of data per Tx descriptor instead of 8K
    
    From what I can tell the practical limitation on the size of the Tx data
    buffer is the fact that the Tx descriptor is limited to 14 bits.  As such
    we cannot use 16K as is typically used on the other Intel drivers.  However
    artificially limiting ourselves to 8K can be expensive as this means that
    we will consume up to 10 descriptors (1 context, 1 for header, and 9 for
    payload, non-8K aligned) in a single send.
    
    I propose that we can reduce this by increasing the maximum data for a 4K
    aligned block to 12K.  We can reduce the descriptors used for a 32K aligned
    block by 1 by increasing the size like this.  In addition we still have the
    4K - 1 of space that is still unused.  We can use this as a bit of extra
    padding when dealing with data that is not aligned to 4K.
    
    By aligning the descriptors after the first to 4K we can improve the
    efficiency of PCIe accesses as we can avoid using byte enables and can fetch
    full TLP transactions after the first fetch of the buffer.  This helps to
    improve PCIe efficiency.  Below is the results of testing before and after
    with this patch:
    
    Recv   Send   Send                         Utilization      Service Demand
    Socket Socket Message  Elapsed             Send     Recv    Send    Recv
    Size   Size   Size     Time    Throughput  local    remote  local   remote
    bytes  bytes  bytes    secs.   10^6bits/s  % S      % U     us/KB   us/KB
    Before:
    87380  16384  16384    10.00     33682.24  20.27    -1.00   0.592   -1.00
    After:
    87380  16384  16384    10.00     34204.08  20.54    -1.00   0.590   -1.00
    
    So the net result of this patch is that we have a small gain in throughput
    due to a reduction in overhead for putting together the frame.
    
    Signed-off-by: Alexander Duyck <aduyck@mirantis.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index cdd5dc00aec5..9e654e611642 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -146,10 +146,39 @@ enum i40e_dyn_idx_t {
 
 #define I40E_MAX_BUFFER_TXD	8
 #define I40E_MIN_TX_LEN		17
-#define I40E_MAX_DATA_PER_TXD	8192
+
+/* The size limit for a transmit buffer in a descriptor is (16K - 1).
+ * In order to align with the read requests we will align the value to
+ * the nearest 4K which represents our maximum read request size.
+ */
+#define I40E_MAX_READ_REQ_SIZE		4096
+#define I40E_MAX_DATA_PER_TXD		(16 * 1024 - 1)
+#define I40E_MAX_DATA_PER_TXD_ALIGNED \
+	(I40E_MAX_DATA_PER_TXD & ~(I40E_MAX_READ_REQ_SIZE - 1))
+
+/* This ugly bit of math is equivalent to DIV_ROUNDUP(size, X) where X is
+ * the value I40E_MAX_DATA_PER_TXD_ALIGNED.  It is needed due to the fact
+ * that 12K is not a power of 2 and division is expensive.  It is used to
+ * approximate the number of descriptors used per linear buffer.  Note
+ * that this will overestimate in some cases as it doesn't account for the
+ * fact that we will add up to 4K - 1 in aligning the 12K buffer, however
+ * the error should not impact things much as large buffers usually mean
+ * we will use fewer descriptors then there are frags in an skb.
+ */
+static inline unsigned int i40e_txd_use_count(unsigned int size)
+{
+	const unsigned int max = I40E_MAX_DATA_PER_TXD_ALIGNED;
+	const unsigned int reciprocal = ((1ull << 32) - 1 + (max / 2)) / max;
+	unsigned int adjust = ~(u32)0;
+
+	/* if we rounded up on the reciprocal pull down the adjustment */
+	if ((max * reciprocal) > adjust)
+		adjust = ~(u32)(reciprocal - 1);
+
+	return (u32)((((u64)size * reciprocal) + adjust) >> 32);
+}
 
 /* Tx Descriptors needed, worst case */
-#define TXD_USE_COUNT(S) DIV_ROUND_UP((S), I40E_MAX_DATA_PER_TXD)
 #define DESC_NEEDED (MAX_SKB_FRAGS + 4)
 #define I40E_MIN_DESC_PENDING	4
 
@@ -377,7 +406,7 @@ static inline int i40e_xmit_descriptor_count(struct sk_buff *skb)
 	int count = 0, size = skb_headlen(skb);
 
 	for (;;) {
-		count += TXD_USE_COUNT(size);
+		count += i40e_txd_use_count(size);
 
 		if (!nr_frags--)
 			break;

commit a75e8005d506f374554b17383c39aa82db0ea860
Author: Kan Liang <kan.liang@intel.com>
Date:   Fri Feb 19 09:24:04 2016 -0500

    i40e: queue-specific settings for interrupt moderation
    
    For i40e driver, each vector has its own ITR register. However, there
    are no concept of queue-specific settings in the driver proper. Only
    global variable is used to store ITR values. That will cause problems
    especially when resetting the vector. The specific ITR values could be
    lost.
    This patch move rx_itr_setting and tx_itr_setting to i40e_ring to store
    specific ITR register for each queue.
    i40e_get_coalesce and i40e_set_coalesce are also modified accordingly to
    support queue-specific settings. To make it compatible with old ethtool,
    if user doesn't specify the queue number, i40e_get_coalesce will return
    queue 0's value. While i40e_set_coalesce will apply value to all queues.
    
    Signed-off-by: Kan Liang <kan.liang@intel.com>
    Acked-by: Shannon Nelson <shannon.nelson@intel.com>
    Acked-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 56009709528a..cdd5dc00aec5 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -248,6 +248,14 @@ struct i40e_ring {
 	u8 dcb_tc;			/* Traffic class of ring */
 	u8 __iomem *tail;
 
+	/* high bit set means dynamic, use accessor routines to read/write.
+	 * hardware only supports 2us resolution for the ITR registers.
+	 * these values always store the USER setting, and must be converted
+	 * before programming to a register.
+	 */
+	u16 rx_itr_setting;
+	u16 tx_itr_setting;
+
 	u16 count;			/* Number of descriptors */
 	u16 reg_idx;			/* HW register index of the ring */
 	u16 rx_hdr_len;

commit 2d37490b82afe1d1b745811e6ce0a4d16bc5e996
Author: Alexander Duyck <aduyck@mirantis.com>
Date:   Wed Feb 17 11:02:50 2016 -0800

    i40e/i40evf: Rewrite logic for 8 descriptor per packet check
    
    This patch is meant to rewrite the logic for how we determine if we can
    transmit the frame or if it needs to be linearized.
    
    The previous code for this function was using a mix of division and modulus
    division as a part of computing if we need to take the slow path.  Instead
    I have replaced this by simply working with a sliding window which will
    tell us if the frame would be capable of causing a single packet to span
    several descriptors.
    
    The logic for the scan is fairly simple.  If any given group of 6 fragments
    is less than gso_size - 1 then it is possible for us to have one byte
    coming out of the first fragment, 6 fragments, and one or more bytes coming
    out of the last fragment.  This gives us a total of 8 fragments
    which exceeds what we can allow so we send such frames to be linearized.
    
    Arguably the use of modulus might be more exact as the approach I propose
    may generate some false positives.  However the likelihood of us taking much
    of a hit for those false positives is fairly low, and I would rather not
    add more overhead in the case where we are receiving a frame composed of 4K
    pages.
    
    Signed-off-by: Alexander Duyck <aduyck@mirantis.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 5dbc958293f7..56009709528a 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -337,6 +337,7 @@ int i40e_tx_prepare_vlan_flags(struct sk_buff *skb,
 void i40e_force_wb(struct i40e_vsi *vsi, struct i40e_q_vector *q_vector);
 u32 i40e_get_tx_pending(struct i40e_ring *ring, bool in_sw);
 int __i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size);
+bool __i40e_chk_linearize(struct sk_buff *skb);
 
 /**
  * i40e_get_head - Retrieve head from head writeback
@@ -392,4 +393,22 @@ static inline int i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size)
 		return 0;
 	return __i40e_maybe_stop_tx(tx_ring, size);
 }
+
+/**
+ * i40e_chk_linearize - Check if there are more than 8 fragments per packet
+ * @skb:      send buffer
+ * @count:    number of buffers used
+ *
+ * Note: Our HW can't scatter-gather more than 8 fragments to build
+ * a packet on the wire and so we need to figure out the cases where we
+ * need to linearize the skb.
+ **/
+static inline bool i40e_chk_linearize(struct sk_buff *skb, int count)
+{
+	/* we can only support up to 8 data buffers for a single send */
+	if (likely(count <= I40E_MAX_BUFFER_TXD))
+		return false;
+
+	return __i40e_chk_linearize(skb);
+}
 #endif /* _I40E_TXRX_H_ */

commit 4ec441df25a686518fb369086e2b34a1cedaa6c9
Author: Alexander Duyck <aduyck@mirantis.com>
Date:   Wed Feb 17 11:02:43 2016 -0800

    i40e/i40evf: Break up xmit_descriptor_count from maybe_stop_tx
    
    In an upcoming patch I would like to have access to the descriptor count
    used for the data portion of the frame.  For this reason I am splitting up
    the descriptor count function from the function that stops the ring.
    
    Also in order to try and reduce unnecessary duplication of code I am moving
    the slow-path portions of the code out of being inline calls so that we can
    just jump to them and process them instead of having to build them into
    each function that calls them.
    
    Signed-off-by: Alexander Duyck <aduyck@mirantis.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index fde5f42524fb..5dbc958293f7 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -331,13 +331,12 @@ int i40e_napi_poll(struct napi_struct *napi, int budget);
 void i40e_tx_map(struct i40e_ring *tx_ring, struct sk_buff *skb,
 		 struct i40e_tx_buffer *first, u32 tx_flags,
 		 const u8 hdr_len, u32 td_cmd, u32 td_offset);
-int i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size);
-int i40e_xmit_descriptor_count(struct sk_buff *skb, struct i40e_ring *tx_ring);
 int i40e_tx_prepare_vlan_flags(struct sk_buff *skb,
 			       struct i40e_ring *tx_ring, u32 *flags);
 #endif
 void i40e_force_wb(struct i40e_vsi *vsi, struct i40e_q_vector *q_vector);
 u32 i40e_get_tx_pending(struct i40e_ring *ring, bool in_sw);
+int __i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size);
 
 /**
  * i40e_get_head - Retrieve head from head writeback
@@ -352,4 +351,45 @@ static inline u32 i40e_get_head(struct i40e_ring *tx_ring)
 
 	return le32_to_cpu(*(volatile __le32 *)head);
 }
+
+/**
+ * i40e_xmit_descriptor_count - calculate number of Tx descriptors needed
+ * @skb:     send buffer
+ * @tx_ring: ring to send buffer on
+ *
+ * Returns number of data descriptors needed for this skb. Returns 0 to indicate
+ * there is not enough descriptors available in this ring since we need at least
+ * one descriptor.
+ **/
+static inline int i40e_xmit_descriptor_count(struct sk_buff *skb)
+{
+	const struct skb_frag_struct *frag = &skb_shinfo(skb)->frags[0];
+	unsigned int nr_frags = skb_shinfo(skb)->nr_frags;
+	int count = 0, size = skb_headlen(skb);
+
+	for (;;) {
+		count += TXD_USE_COUNT(size);
+
+		if (!nr_frags--)
+			break;
+
+		size = skb_frag_size(frag++);
+	}
+
+	return count;
+}
+
+/**
+ * i40e_maybe_stop_tx - 1st level check for Tx stop conditions
+ * @tx_ring: the ring to be checked
+ * @size:    the size buffer we want to assure is available
+ *
+ * Returns 0 if stop is not needed
+ **/
+static inline int i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size)
+{
+	if (likely(I40E_DESC_UNUSED(tx_ring) >= size))
+		return 0;
+	return __i40e_maybe_stop_tx(tx_ring, size);
+}
 #endif /* _I40E_TXRX_H_ */

commit 529f1f652e3c3c6db6ab5a6e3a35469ddfd9575d
Author: Alexander Duyck <aduyck@mirantis.com>
Date:   Sun Jan 24 21:17:10 2016 -0800

    i40e/i40evf: Add exception handling for Tx checksum
    
    Add exception handling to the Tx checksum path so that we can handle cases
    of TSO where the frame is bad, or Tx checksum where we didn't recognize a
    protocol
    
    Drop I40E_TX_FLAGS_CSUM as it is unused, move the CHECKSUM_PARTIAL check
    into the function itself so that we can decrease indent.
    
    Signed-off-by: Alexander Duyck <aduyck@mirantis.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index fb065d4fe15c..fde5f42524fb 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -153,7 +153,6 @@ enum i40e_dyn_idx_t {
 #define DESC_NEEDED (MAX_SKB_FRAGS + 4)
 #define I40E_MIN_DESC_PENDING	4
 
-#define I40E_TX_FLAGS_CSUM		BIT(0)
 #define I40E_TX_FLAGS_HW_VLAN		BIT(1)
 #define I40E_TX_FLAGS_SW_VLAN		BIT(2)
 #define I40E_TX_FLAGS_TSO		BIT(3)

commit a9c9a81f5892eb984234223399ee624f7dbd15e8
Author: Alexander Duyck <aduyck@mirantis.com>
Date:   Sun Jan 24 21:16:13 2016 -0800

    i40e/i40evf: Drop outer checksum offload that was not requested
    
    The i40e and i40evf drivers contained code for inserting an outer checksum
    on UDP tunnels.  The issue however is that the upper levels of the stack
    never requested such an offload and it results in possible errors.
    
    In addition the same logic was being applied to the Rx side where it was
    attempting to validate the outer checksum, but the logic there was
    incorrect in that it was testing for the resultant sum to be equal to the
    header checksum instead of being equal to 0.
    
    Since this code is so massively flawed, and doing things that we didn't ask
    for it to do I am just dropping it, and will bring it back later to use as
    an offload for SKB_GSO_UDP_TUNNEL_CSUM which can make use of such a
    feature.
    
    As far as the Rx feature I am dropping it completely since it would need to
    be massively expanded and applied to IPv4 and IPv6 checksums for all parts,
    not just the one that supports Tx checksum offload for the outer.
    
    Signed-off-by: Alexander Duyck <aduyck@mirantis.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 3acc9244134d..fb065d4fe15c 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -277,7 +277,6 @@ struct i40e_ring {
 
 	u16 flags;
 #define I40E_TXR_FLAGS_WB_ON_ITR	BIT(0)
-#define I40E_TXR_FLAGS_OUTER_UDP_CSUM	BIT(1)
 #define I40E_TXR_FLAGS_LAST_XMIT_MORE_SET BIT(2)
 
 	/* stats structs */

commit dd353109e41c1e92e0cea9954404a6f5a7d46218
Author: Anjali Singhai Jain <anjali.singhai@intel.com>
Date:   Fri Jan 15 14:33:12 2016 -0800

    i40e: Add a SW workaround for lost interrupts
    
    This patch adds a workaround for cases where we might have
    interrupts that got lost but WB happened.
    If that happens without this patch we will see a tx_timeout.
    To work around it, this patch goes ahead and reschedules NAPI
    in that situation, if NAPI is not already scheduled.
    We also add a counter in ethtool to keep track of when
    we detect a case of tx_lost_interrupt.
    
    Note: napi_reschedule() can be safely called from process/service_task
    context and is done in other drivers as well without an issue.
    
    Change-ID: I00f98f1ce3774524d9421227652bef20fcbd0d20
    Signed-off-by: Anjali Singhai Jain <anjali.singhai@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index ae22c4e9162f..3acc9244134d 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -203,6 +203,7 @@ struct i40e_tx_queue_stats {
 	u64 tx_done_old;
 	u64 tx_linearize;
 	u64 tx_force_wb;
+	u64 tx_lost_interrupt;
 };
 
 struct i40e_rx_queue_stats {
@@ -338,7 +339,7 @@ int i40e_tx_prepare_vlan_flags(struct sk_buff *skb,
 			       struct i40e_ring *tx_ring, u32 *flags);
 #endif
 void i40e_force_wb(struct i40e_vsi *vsi, struct i40e_q_vector *q_vector);
-u32 i40e_get_tx_pending(struct i40e_ring *ring);
+u32 i40e_get_tx_pending(struct i40e_ring *ring, bool in_sw);
 
 /**
  * i40e_get_head - Retrieve head from head writeback

commit 4668607aa30b3879312823a0ddbcd15077644f4e
Author: Mitch Williams <mitch.a.williams@intel.com>
Date:   Wed Jan 13 16:51:51 2016 -0800

    i40e: properly show packet split status in debugfs
    
    Get rid of the unused hsplit field in the ring struct and use the
    existing macro to detect packet split enablement. This allows debugfs
    dumps of the VSI to properly show which Rx routine is in use.
    
    Change-ID: Ic4e9589e6a788ab196ed0850703f704e30c03781
    Signed-off-by: Mitch Williams <mitch.a.williams@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 3b8d14701613..ae22c4e9162f 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -256,7 +256,6 @@ struct i40e_ring {
 #define I40E_RX_DTYPE_NO_SPLIT      0
 #define I40E_RX_DTYPE_HEADER_SPLIT  1
 #define I40E_RX_DTYPE_SPLIT_ALWAYS  2
-	u8  hsplit;
 #define I40E_RX_SPLIT_L2      0x1
 #define I40E_RX_SPLIT_IP      0x2
 #define I40E_RX_SPLIT_TCP_UDP 0x4

commit f16704e5e8aed1dfed4084c56dde17006c2e81f1
Author: Mitch Williams <mitch.a.williams@intel.com>
Date:   Wed Jan 13 16:51:49 2016 -0800

    i40e/i40evf: use pages correctly in Rx
    
    Refactor the packet split Rx code to properly use half-pages for
    receives. The previous code was doing way more mapping and unmapping
    than it needed to, and wasn't properly using half-pages.
    
    Increment the page use count each time we give a half-page to an skb,
    knowing that the stack will probably process and release the page before
    we need it again. Only free and reallocate pages if the count shows that
    both half-pages are in use. Add counters to track reallocations and page
    reuse.
    
    Change-ID: I534b299196036b64be82b4861a0a4036310a8f22
    Signed-off-by: Mitch Williams <mitch.a.williams@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 5c73f3d294b2..3b8d14701613 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -209,6 +209,8 @@ struct i40e_rx_queue_stats {
 	u64 non_eop_descs;
 	u64 alloc_page_failed;
 	u64 alloc_buff_failed;
+	u64 page_reuse_count;
+	u64 realloc_count;
 };
 
 enum i40e_ring_state_t {

commit c2e245ab1e9a61e66217aafea66c7dc6481f12f0
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Wed Jan 13 16:51:46 2016 -0800

    i40e/i40evf: try again after failure
    
    This is the "Don't Give Up" patch.  Previously the
    driver could fail an allocation, and then possibly stall
    a queue forever, by never coming back to continue receiving
    or allocating buffers.
    
    With this patch, the driver will keep polling trying to allocate
    receive buffers until it succeeds.  This should keep all receive
    queues running even in the face of memory pressure.
    
    Also update copyright year in file header.
    
    Change-ID: I2b103d1ce95b9831288a7222c3343ffa1988b81b
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 3f081e25e097..5c73f3d294b2 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -1,7 +1,7 @@
 /*******************************************************************************
  *
  * Intel Ethernet Controller XL710 Family Linux Driver
- * Copyright(c) 2013 - 2014 Intel Corporation.
+ * Copyright(c) 2013 - 2016 Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
@@ -316,8 +316,8 @@ struct i40e_ring_container {
 #define i40e_for_each_ring(pos, head) \
 	for (pos = (head).ring; pos != NULL; pos = pos->next)
 
-void i40e_alloc_rx_buffers_ps(struct i40e_ring *rxr, u16 cleaned_count);
-void i40e_alloc_rx_buffers_1buf(struct i40e_ring *rxr, u16 cleaned_count);
+bool i40e_alloc_rx_buffers_ps(struct i40e_ring *rxr, u16 cleaned_count);
+bool i40e_alloc_rx_buffers_1buf(struct i40e_ring *rxr, u16 cleaned_count);
 void i40e_alloc_rx_headers(struct i40e_ring *rxr);
 netdev_tx_t i40e_lan_xmit_frame(struct sk_buff *skb, struct net_device *netdev);
 void i40e_clean_tx_ring(struct i40e_ring *tx_ring);

commit 6a899024058d35dbcac33fbd3c7d70f2a54828e1
Author: Singhai, Anjali <anjali.singhai@intel.com>
Date:   Mon Dec 14 12:21:18 2015 -0800

    i40e: geneve tunnel offload support
    
    This patch adds driver hooks to implement ndo_ops to add/del
    udp port in the HW to identify GENEVE tunnels.
    
    Signed-off-by: Anjali Singhai Jain <anjali.singhai@intel.com>
    Signed-off-by: Kiran Patil <kiran.patil@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index dccc1eb576f2..3f081e25e097 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -163,7 +163,7 @@ enum i40e_dyn_idx_t {
 #define I40E_TX_FLAGS_FSO		BIT(7)
 #define I40E_TX_FLAGS_TSYN		BIT(8)
 #define I40E_TX_FLAGS_FD_SB		BIT(9)
-#define I40E_TX_FLAGS_VXLAN_TUNNEL	BIT(10)
+#define I40E_TX_FLAGS_UDP_TUNNEL	BIT(10)
 #define I40E_TX_FLAGS_VLAN_MASK		0xffff0000
 #define I40E_TX_FLAGS_VLAN_PRIO_MASK	0xe0000000
 #define I40E_TX_FLAGS_VLAN_PRIO_SHIFT	29

commit 164c9f54631beca4d174f306acdcaec2bdeef52e
Author: Anjali Singhai Jain <anjali.singhai@intel.com>
Date:   Wed Oct 21 19:47:08 2015 -0400

    i40e/i40evf: Add a stat to track how many times we have to do a force WB
    
    When in NAPI with interrupts disabled, the HW needs to be forced to do a
    write back on TX if the number of descriptors pending are less than a
    cache line.
    
    This stat helps keep track of how many times we get into this situation.
    
    Change-ID: I76c1bcc7ebccd6bffcc5aa33bfe05f2fa1c9a984
    Signed-off-by: Anjali Singhai Jain <anjali.singhai@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 6779fb771d6a..dccc1eb576f2 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -202,6 +202,7 @@ struct i40e_tx_queue_stats {
 	u64 tx_busy;
 	u64 tx_done_old;
 	u64 tx_linearize;
+	u64 tx_force_wb;
 };
 
 struct i40e_rx_queue_stats {

commit ee2319cf17ee64bbd0096f2f8f3f8390c93b1e39
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Mon Sep 28 14:16:54 2015 -0400

    i40e/i40evf: adjust interrupt throttle less frequently
    
    The adaptive ITR (interrupt throttle rate) algorithm was adjusting
    the hardware's interrupt rate too frequently.  This caused a lot
    of variation in the interrupt rate for fairly constant workloads.
    
    Change the code to have a counter and adjust only once every N
    number of interrupts.
    
    Change-ID: I0460f1f86571037484eca5aca36ac4d889cb8389
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 0fe7eb77cae5..6779fb771d6a 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -38,8 +38,8 @@
 #define I40E_ITR_8K                0x003E
 #define I40E_ITR_4K                0x007A
 #define I40E_MAX_INTRL             0x3B    /* reg uses 4 usec resolution */
-#define I40E_ITR_RX_DEF            I40E_ITR_8K
-#define I40E_ITR_TX_DEF            I40E_ITR_4K
+#define I40E_ITR_RX_DEF            I40E_ITR_20K
+#define I40E_ITR_TX_DEF            I40E_ITR_20K
 #define I40E_ITR_DYNAMIC           0x8000  /* use top bit as a flag */
 #define I40E_MIN_INT_RATE          250     /* ~= 1000000 / (I40E_MAX_ITR * 2) */
 #define I40E_MAX_INT_RATE          500000  /* == 1000000 / (I40E_MIN_ITR * 2) */

commit c56625d59726ee2dc4dfd91c8b6c22098abe1ac4
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Mon Sep 28 14:16:53 2015 -0400

    i40e/i40evf: change dynamic interrupt thresholds
    
    The dynamic algorithm, while now working, doesn't have good
    performance in 40G mode.
    
    One part of this patch addresses the high CPU utilization of some small
    streaming workloads that the driver should reduce CPU in.
    
    It also changes the minimum ITR that the dynamic algorithm
    will settle on, causing our minimum latency to go from 12us
    to about 14us, when using adaptive mode.
    
    It also changes the BULK interrupt rate to allow maximum throughput
    on a 40Gb connection with a single thread of transmit, clamping
    interrupt rate to 8000 for TX makes single thread traffic go too
    slow.
    
    The new ULTRA bulk setting is introduced and is used
    when the Rx packet rate on this queue exceeds 40000 packets per
    second.  This value of 40000 was chosen because the automatic tuning
    of minimum ITR=20us means that a single queue can't quite achieve
    that many packets per second from a round-robin test.
    
    Change-ID: Icce8faa128688ca5fd2c4229bdd9726877a92ea2
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 7c0ed84b296d..0fe7eb77cae5 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -32,7 +32,9 @@
 #define I40E_MAX_ITR               0x0FF0  /* reg uses 2 usec resolution */
 #define I40E_MIN_ITR               0x0001  /* reg uses 2 usec resolution */
 #define I40E_ITR_100K              0x0005
+#define I40E_ITR_50K               0x000A
 #define I40E_ITR_20K               0x0019
+#define I40E_ITR_18K               0x001B
 #define I40E_ITR_8K                0x003E
 #define I40E_ITR_4K                0x007A
 #define I40E_MAX_INTRL             0x3B    /* reg uses 4 usec resolution */
@@ -296,6 +298,7 @@ enum i40e_latency_range {
 	I40E_LOWEST_LATENCY = 0,
 	I40E_LOW_LATENCY = 1,
 	I40E_BULK_LATENCY = 2,
+	I40E_ULTRA_LATENCY = 3,
 };
 
 struct i40e_ring_container {

commit ac26fc136c24edee53f1719e490d896fb07cd79b
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Mon Sep 28 14:12:37 2015 -0400

    i40e/i40evf: moderate interrupts differently
    
    The XL710 hardware has a different interrupt moderation design
    that can support a limit of total interrupts per second per
    vector, in addition to the "number of interrupts per second"
    controls already established in the driver.  This combination
    of hardware features allows us to set very low default latency
    settings but minimize the total CPU utilization by not
    making too many interrupts, should the user desire.
    
    The current driver implementation is still enabling the dynamic
    moderation in the driver, and only using the rx/tx-usecs
    limit in ethtool to limit the interrupt rate per second, by default.
    
    The new code implemented in this patch
    2) adds init/use of the new "Interrupt Limit" register
    3) adds ethtool knob to control/report the limits above
    
    Usage is ethtool -C ethx rx-usecs-high <value> Where <value> is number
    of microseconds to create a rate of 1/N interrupts per second,
    regardless of rx-usecs or tx-usecs values. Since there is a credit based
    scheme in the hardware, the rx-usecs and tx-usecs can be configured for
    very low latency for short bursts, but once the credit runs out the
    refill rate on the credits is limited by rx-usecs-high.
    
    Change-ID: I3a1075d3296123b0f4f50623c779b027af5b188d
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 75cecfa6e338..7c0ed84b296d 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -35,6 +35,7 @@
 #define I40E_ITR_20K               0x0019
 #define I40E_ITR_8K                0x003E
 #define I40E_ITR_4K                0x007A
+#define I40E_MAX_INTRL             0x3B    /* reg uses 4 usec resolution */
 #define I40E_ITR_RX_DEF            I40E_ITR_8K
 #define I40E_ITR_TX_DEF            I40E_ITR_4K
 #define I40E_ITR_DYNAMIC           0x8000  /* use top bit as a flag */
@@ -44,6 +45,15 @@
 #define ITR_TO_REG(setting) ((setting & ~I40E_ITR_DYNAMIC) >> 1)
 #define ITR_IS_DYNAMIC(setting) (!!(setting & I40E_ITR_DYNAMIC))
 #define ITR_REG_TO_USEC(itr_reg) (itr_reg << 1)
+/* 0x40 is the enable bit for interrupt rate limiting, and must be set if
+ * the value of the rate limit is non-zero
+ */
+#define INTRL_ENA                  BIT(6)
+#define INTRL_REG_TO_USEC(intrl) ((intrl & ~INTRL_ENA) << 2)
+#define INTRL_USEC_TO_REG(set) ((set) ? ((set) >> 2) | INTRL_ENA : 0)
+#define I40E_INTRL_8K              125     /* 8000 ints/sec */
+#define I40E_INTRL_62K             16      /* 62500 ints/sec */
+#define I40E_INTRL_83K             12      /* 83333 ints/sec */
 
 #define I40E_QUEUE_END_OF_LIST 0x7FF
 

commit 6995b36c0fc3dd97c1d641f9630d19db2cadf44f
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Fri Aug 28 17:55:54 2015 -0400

    i40e/i40evf: clean up some code
    
    Add missings spaces after declarations, remove another __func__ use,
    remove uncessary braces, remove unneeded breaks, and useless returns,
    and generally fix up some code.
    
    Change-ID: Ie715d6b64976c50e1c21531685fe0a2bd38c4244
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Signed-off-by: Shannon Nelson <shannon.nelson@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index ac3fb3a6f42d..75cecfa6e338 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -165,6 +165,7 @@ struct i40e_tx_buffer {
 	};
 	unsigned int bytecount;
 	unsigned short gso_segs;
+
 	DEFINE_DMA_UNMAP_ADDR(dma);
 	DEFINE_DMA_UNMAP_LEN(len);
 	u32 tx_flags;

commit 2fc3d7152ae9562c15c30ed4a766ba05a3db8200
Author: Anjali Singhai Jain <anjali.singhai@intel.com>
Date:   Thu Aug 27 11:42:29 2015 -0400

    i40e/i40evf: Add a stat to keep track of linearization count
    
    Keep track of how many times we ask the stack to linearize the
    skb because the HW cannot handle skbs with more than 8 frags per
    segment/single packet.
    
    Change-ID: If455452060963a769bbe6112cba952e79e944b52
    Signed-off-by: Anjali Singhai Jain <anjali.singhai@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 7c9975c983d9..ac3fb3a6f42d 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -188,6 +188,7 @@ struct i40e_tx_queue_stats {
 	u64 restart_queue;
 	u64 tx_busy;
 	u64 tx_done_old;
+	u64 tx_linearize;
 };
 
 struct i40e_rx_queue_stats {

commit 9c70d7cebfec558e07a2ab0f2d5f5a80a821ecf5
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Thu Aug 13 18:54:31 2015 -0700

    i40e: fix 32 bit build warnings
    
    Sparse found some issues with 32 bit compilation, which probably should
    at least work without warning.  Not only that, but the code was wrong.
    Thanks sparse!!
    
    And thanks to the kbuild robot zero day testing for finding this issue.
    
    $ make ARCH=i386 M=drivers/net/ethernet/intel/i40e C=2 CF="-D__CHECK_ENDIAN__"
      CHECK   drivers/net/ethernet/intel/i40e/i40e_main.c
      include/linux/etherdevice.h:79:32: warning: restricted __be16 degrades to integer
      drivers/net/ethernet/intel/i40e/i40e_main.c:7565:17: warning: shift too big (32) for type unsigned long
      drivers/net/ethernet/intel/i40e/i40e_main.c:7565:17: warning: shift too big (42) for type unsigned long
      drivers/net/ethernet/intel/i40e/i40e_main.c:7565:17: warning: shift too big (39) for type unsigned long
      drivers/net/ethernet/intel/i40e/i40e_main.c:7565:17: warning: shift too big (40) for type unsigned long
    
    CC: kbuild-all@01.org
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Reported-by: kbuild test robot <fengguang.wu@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index a3978c2b5fc9..7c9975c983d9 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -79,12 +79,12 @@ enum i40e_dyn_idx_t {
 	BIT_ULL(I40E_FILTER_PCTYPE_L2_PAYLOAD))
 
 #define I40E_DEFAULT_RSS_HENA_EXPANDED (I40E_DEFAULT_RSS_HENA | \
-	BIT(I40E_FILTER_PCTYPE_NONF_IPV4_TCP_SYN_NO_ACK) | \
-	BIT(I40E_FILTER_PCTYPE_NONF_UNICAST_IPV4_UDP) | \
-	BIT(I40E_FILTER_PCTYPE_NONF_MULTICAST_IPV4_UDP) | \
-	BIT(I40E_FILTER_PCTYPE_NONF_IPV6_TCP_SYN_NO_ACK) | \
-	BIT(I40E_FILTER_PCTYPE_NONF_UNICAST_IPV6_UDP) | \
-	BIT(I40E_FILTER_PCTYPE_NONF_MULTICAST_IPV6_UDP))
+	BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV4_TCP_SYN_NO_ACK) | \
+	BIT_ULL(I40E_FILTER_PCTYPE_NONF_UNICAST_IPV4_UDP) | \
+	BIT_ULL(I40E_FILTER_PCTYPE_NONF_MULTICAST_IPV4_UDP) | \
+	BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV6_TCP_SYN_NO_ACK) | \
+	BIT_ULL(I40E_FILTER_PCTYPE_NONF_UNICAST_IPV6_UDP) | \
+	BIT_ULL(I40E_FILTER_PCTYPE_NONF_MULTICAST_IPV6_UDP))
 
 #define i40e_pf_get_default_rss_hena(pf) \
 	(((pf)->flags & I40E_FLAG_MULTIPLE_TCP_UDP_RSS_PCTYPE) ? \

commit 5804474311912c1b80601a1afee052e8df962cd4
Author: Anjali Singhai <anjali.singhai@intel.com>
Date:   Fri Sep 25 18:26:13 2015 -0700

    i40e: Fix RS bit update in Tx path and disable force WB workaround
    
    This patch fixes the issue of forcing WB too often causing us to not
    benefit from NAPI.
    
    Without this patch we were forcing WB/arming interrupt too often taking
    away the benefits of NAPI and causing a performance impact.
    
    With this patch we disable force WB in the clean routine for X710
    and XL710 adapters. X722 adapters do not enable interrupt to force
    a WB and benefit from WB_ON_ITR and hence force WB is left enabled
    for those adapters.
    For XL710 and X710 adapters if we have less than 4 packets pending
    a software Interrupt triggered from service task will force a WB.
    
    This patch also changes the conditions for setting RS bit as described
    in code comments. This optimizes when the HW does a tail bump and when
    it does a WB. It also optimizes when we do a wmb.
    
    Signed-off-by: Anjali Singhai Jain <anjali.singhai@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 977cb5b46115..a3978c2b5fc9 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -256,10 +256,12 @@ struct i40e_ring {
 
 	bool ring_active;		/* is ring online or not */
 	bool arm_wb;		/* do something to arm write back */
+	u8 packet_stride;
 
 	u16 flags;
 #define I40E_TXR_FLAGS_WB_ON_ITR	BIT(0)
 #define I40E_TXR_FLAGS_OUTER_UDP_CSUM	BIT(1)
+#define I40E_TXR_FLAGS_LAST_XMIT_MORE_SET BIT(2)
 
 	/* stats structs */
 	struct i40e_queue_stats	stats;

commit b03a8c1f4c0c6f95f5addaf4a13dd3aa118c3c1a
Author: Kiran Patil <kiran.patil@intel.com>
Date:   Thu Sep 24 18:13:15 2015 -0400

    i40e/i40evf: refactor tx timeout logic
    
    This patch modifies the driver timeout logic by issuing a writeback
    request via a software interrupt to the hardware the first time the
    driver detects a hang. The driver was too aggressive in resetting a hung
    queue, so back that off by removing logic to down the netdevice after
    too many hangs, and move the function to the service task.
    
    Change-ID: Ife100b9d124cd08cbdb81ab659008c1b9abbedea
    Signed-off-by: Kiran Patil <kiran.patil@intel.com>
    Signed-off-by: Shannon Nelson <shannon.nelson@intel.com>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 51487ef9eda3..977cb5b46115 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -199,8 +199,6 @@ struct i40e_rx_queue_stats {
 enum i40e_ring_state_t {
 	__I40E_TX_FDIR_INIT_DONE,
 	__I40E_TX_XPS_INIT_DONE,
-	__I40E_TX_DETECT_HANG,
-	__I40E_HANG_CHECK_ARMED,
 	__I40E_RX_PS_ENABLED,
 	__I40E_RX_16BYTE_DESC_ENABLED,
 };
@@ -211,12 +209,6 @@ enum i40e_ring_state_t {
 	set_bit(__I40E_RX_PS_ENABLED, &(ring)->state)
 #define clear_ring_ps_enabled(ring) \
 	clear_bit(__I40E_RX_PS_ENABLED, &(ring)->state)
-#define check_for_tx_hang(ring) \
-	test_bit(__I40E_TX_DETECT_HANG, &(ring)->state)
-#define set_check_for_tx_hang(ring) \
-	set_bit(__I40E_TX_DETECT_HANG, &(ring)->state)
-#define clear_check_for_tx_hang(ring) \
-	clear_bit(__I40E_TX_DETECT_HANG, &(ring)->state)
 #define ring_is_16byte_desc_enabled(ring) \
 	test_bit(__I40E_RX_16BYTE_DESC_ENABLED, &(ring)->state)
 #define set_ring_16byte_desc_enabled(ring) \
@@ -326,6 +318,8 @@ int i40e_xmit_descriptor_count(struct sk_buff *skb, struct i40e_ring *tx_ring);
 int i40e_tx_prepare_vlan_flags(struct sk_buff *skb,
 			       struct i40e_ring *tx_ring, u32 *flags);
 #endif
+void i40e_force_wb(struct i40e_vsi *vsi, struct i40e_q_vector *q_vector);
+u32 i40e_get_tx_pending(struct i40e_ring *ring);
 
 /**
  * i40e_get_head - Retrieve head from head writeback

commit 1e6d6f8c1b07a5874444c3a403eb24427e8b39d3
Author: Kiran Patil <kiran.patil@intel.com>
Date:   Thu Sep 24 15:43:02 2015 -0400

    i40e: Move i40e_get_head into header file
    
    i40e_get_head needs to be called in multiple files in a further patch,
    prepare by moving the function into a header file.
    
    Signed-off-by: Kiran Patil <kiran.patil@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index f1385a1989fa..51487ef9eda3 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -326,4 +326,18 @@ int i40e_xmit_descriptor_count(struct sk_buff *skb, struct i40e_ring *tx_ring);
 int i40e_tx_prepare_vlan_flags(struct sk_buff *skb,
 			       struct i40e_ring *tx_ring, u32 *flags);
 #endif
+
+/**
+ * i40e_get_head - Retrieve head from head writeback
+ * @tx_ring:  tx ring to fetch head of
+ *
+ * Returns value of Tx ring head based on value stored
+ * in head write-back location
+ **/
+static inline u32 i40e_get_head(struct i40e_ring *tx_ring)
+{
+	void *head = (struct i40e_tx_desc *)tx_ring->desc + tx_ring->count;
+
+	return le32_to_cpu(*(volatile __le32 *)head);
+}
 #endif /* _I40E_TXRX_H_ */

commit 527274c78ea7e0cad8b44ea25509c42aa605634e
Author: Anjali Singhai Jain <anjali.singhai@intel.com>
Date:   Fri Jun 5 12:20:31 2015 -0400

    i40e/i40evf: Add TX/RX outer UDP checksum support for X722
    
    X722 supports offloading of outer UDP TX and RX checksum for tunneled
    packets. This patch exposes the support and leaves it enabled by
    default.
    
    Signed-off-by: Anjali Singhai Jain <anjali.singhai@intel.com>
    Signed-off-by: Catherine Sullivan <catherine.sullivan@intel.com>
    Tested-by: Jim Young <james.m.young@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 0e40994500c1..f1385a1989fa 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -267,6 +267,8 @@ struct i40e_ring {
 
 	u16 flags;
 #define I40E_TXR_FLAGS_WB_ON_ITR	BIT(0)
+#define I40E_TXR_FLAGS_OUTER_UDP_CSUM	BIT(1)
+
 	/* stats structs */
 	struct i40e_queue_stats	stats;
 	struct u64_stats_sync syncp;

commit 8e0764b4d6be42459b6f517e199b8c7df43cc15c
Author: Anjali Singhai Jain <anjali.singhai@intel.com>
Date:   Fri Jun 5 12:20:30 2015 -0400

    i40e/i40evf: Add support for writeback on ITR feature for X722
    
    X722 fixes an issue from X710 where TX descriptor WB would not happen if
    the interrupts were disabled. In order for the write backs to happen a
    bit needs to be set in the dynamic interrupt control register called
    WB_ON_ITR. With this feature, the SW driver need not arm SW interrupts to
    work around the issue in X710.
    
    Signed-off-by: Anjali Singhai Jain <anjali.singhai@intel.com>
    Signed-off-by: Catherine Sullivan <catherine.sullivan@intel.com>
    Tested-by: Jim Young <james.m.young@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 8b618d0151cd..0e40994500c1 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -265,6 +265,8 @@ struct i40e_ring {
 	bool ring_active;		/* is ring online or not */
 	bool arm_wb;		/* do something to arm write back */
 
+	u16 flags;
+#define I40E_TXR_FLAGS_WB_ON_ITR	BIT(0)
 	/* stats structs */
 	struct i40e_queue_stats	stats;
 	struct u64_stats_sync syncp;

commit e25d00b87b26f96f91434e6608dc4b05f5ef5498
Author: Anjali Singhai Jain <anjali.singhai@intel.com>
Date:   Tue Jun 23 19:00:04 2015 -0400

    i40e/i40evf: RSS changes for X722
    
    X722 uses the admin queue to configure RSS. This patch adds the necessary
    flow changes to configure RSS through AQ. It also adds the separate VMDQ2
    lookup tables and hash key programming for X722.
    
    X722 also exposes a different set of PCTYPES for RSS, this patch
    accommodates those changes.
    
    Signed-off-by: Anjali Singhai Jain <anjali.singhai@intel.com>
    Signed-off-by: Catherine Sullivan <catherine.sullivan@intel.com>
    Signed-off-by: Mitch Williams <mitch.a.williams@intel.com>
    Tested-by: Jim Young <james.m.young@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 429833c47245..8b618d0151cd 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -78,6 +78,18 @@ enum i40e_dyn_idx_t {
 	BIT_ULL(I40E_FILTER_PCTYPE_FRAG_IPV6) | \
 	BIT_ULL(I40E_FILTER_PCTYPE_L2_PAYLOAD))
 
+#define I40E_DEFAULT_RSS_HENA_EXPANDED (I40E_DEFAULT_RSS_HENA | \
+	BIT(I40E_FILTER_PCTYPE_NONF_IPV4_TCP_SYN_NO_ACK) | \
+	BIT(I40E_FILTER_PCTYPE_NONF_UNICAST_IPV4_UDP) | \
+	BIT(I40E_FILTER_PCTYPE_NONF_MULTICAST_IPV4_UDP) | \
+	BIT(I40E_FILTER_PCTYPE_NONF_IPV6_TCP_SYN_NO_ACK) | \
+	BIT(I40E_FILTER_PCTYPE_NONF_UNICAST_IPV6_UDP) | \
+	BIT(I40E_FILTER_PCTYPE_NONF_MULTICAST_IPV6_UDP))
+
+#define i40e_pf_get_default_rss_hena(pf) \
+	(((pf)->flags & I40E_FLAG_MULTIPLE_TCP_UDP_RSS_PCTYPE) ? \
+	  I40E_DEFAULT_RSS_HENA_EXPANDED : I40E_DEFAULT_RSS_HENA)
+
 /* Supported Rx Buffer Sizes */
 #define I40E_RXBUFFER_512   512    /* Used for packet split */
 #define I40E_RXBUFFER_2048  2048

commit 41a1d04b9d2006fdac5cab7680cff89915610944
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Thu Jun 4 16:24:02 2015 -0400

    i40e: use BIT and BIT_ULL macros
    
    Use macros for abstracting (1 << foo) to BIT(foo)
    and (1ULL << foo64) to BIT_ULL(foo64) in order to match
    better with kernel requirements.
    
    NOTE: the adminq_cmd.h file was not modified on purpose because
    of the dependency upon firmware for that file.
    
    Change-ID: I73ee2e48c880d671948aad19bd53ca6b2ac558fc
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Signed-off-by: Catherine Sullivan <catherine.sullivan@intel.com>
    Tested-by: Jim Young <james.m.young@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 0dc48dc9ca61..429833c47245 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -66,17 +66,17 @@ enum i40e_dyn_idx_t {
 
 /* Supported RSS offloads */
 #define I40E_DEFAULT_RSS_HENA ( \
-	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV4_UDP) | \
-	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV4_SCTP) | \
-	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV4_TCP) | \
-	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV4_OTHER) | \
-	((u64)1 << I40E_FILTER_PCTYPE_FRAG_IPV4) | \
-	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_UDP) | \
-	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_TCP) | \
-	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_SCTP) | \
-	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_OTHER) | \
-	((u64)1 << I40E_FILTER_PCTYPE_FRAG_IPV6) | \
-	((u64)1 << I40E_FILTER_PCTYPE_L2_PAYLOAD))
+	BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV4_UDP) | \
+	BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV4_SCTP) | \
+	BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV4_TCP) | \
+	BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV4_OTHER) | \
+	BIT_ULL(I40E_FILTER_PCTYPE_FRAG_IPV4) | \
+	BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV6_UDP) | \
+	BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV6_TCP) | \
+	BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV6_SCTP) | \
+	BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV6_OTHER) | \
+	BIT_ULL(I40E_FILTER_PCTYPE_FRAG_IPV6) | \
+	BIT_ULL(I40E_FILTER_PCTYPE_L2_PAYLOAD))
 
 /* Supported Rx Buffer Sizes */
 #define I40E_RXBUFFER_512   512    /* Used for packet split */
@@ -129,17 +129,17 @@ enum i40e_dyn_idx_t {
 #define DESC_NEEDED (MAX_SKB_FRAGS + 4)
 #define I40E_MIN_DESC_PENDING	4
 
-#define I40E_TX_FLAGS_CSUM		(u32)(1)
-#define I40E_TX_FLAGS_HW_VLAN		(u32)(1 << 1)
-#define I40E_TX_FLAGS_SW_VLAN		(u32)(1 << 2)
-#define I40E_TX_FLAGS_TSO		(u32)(1 << 3)
-#define I40E_TX_FLAGS_IPV4		(u32)(1 << 4)
-#define I40E_TX_FLAGS_IPV6		(u32)(1 << 5)
-#define I40E_TX_FLAGS_FCCRC		(u32)(1 << 6)
-#define I40E_TX_FLAGS_FSO		(u32)(1 << 7)
-#define I40E_TX_FLAGS_TSYN		(u32)(1 << 8)
-#define I40E_TX_FLAGS_FD_SB		(u32)(1 << 9)
-#define I40E_TX_FLAGS_VXLAN_TUNNEL	(u32)(1 << 10)
+#define I40E_TX_FLAGS_CSUM		BIT(0)
+#define I40E_TX_FLAGS_HW_VLAN		BIT(1)
+#define I40E_TX_FLAGS_SW_VLAN		BIT(2)
+#define I40E_TX_FLAGS_TSO		BIT(3)
+#define I40E_TX_FLAGS_IPV4		BIT(4)
+#define I40E_TX_FLAGS_IPV6		BIT(5)
+#define I40E_TX_FLAGS_FCCRC		BIT(6)
+#define I40E_TX_FLAGS_FSO		BIT(7)
+#define I40E_TX_FLAGS_TSYN		BIT(8)
+#define I40E_TX_FLAGS_FD_SB		BIT(9)
+#define I40E_TX_FLAGS_VXLAN_TUNNEL	BIT(10)
 #define I40E_TX_FLAGS_VLAN_MASK		0xffff0000
 #define I40E_TX_FLAGS_VLAN_PRIO_MASK	0xe0000000
 #define I40E_TX_FLAGS_VLAN_PRIO_SHIFT	29

commit 335075989fbb3c3fffc3ba238b893fa92508a6f1
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Thu Apr 16 20:06:11 2015 -0400

    i40e/i40evf: remove time_stamp member
    
    The driver doesn't use the time_stamp member to determine if there is a
    tx_hang any more. There really isn't any point to the variable at all
    so just remove it. It was left over from a previous tx_hang design.
    
    Change-ID: I4c814827e1bcb46e45118fe37acdcfa814fb62a0
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Jim Young <james.m.young@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index ea1df3b48747..0dc48dc9ca61 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -147,7 +147,6 @@ enum i40e_dyn_idx_t {
 
 struct i40e_tx_buffer {
 	struct i40e_tx_desc *next_to_watch;
-	unsigned long time_stamp;
 	union {
 		struct sk_buff *skb;
 		void *raw_buf;

commit 89232c3bf78b3799699e48201f60892283564b78
Author: Anjali Singhai Jain <anjali.singhai@intel.com>
Date:   Thu Apr 16 20:06:00 2015 -0400

    i40e/i40evf: Add ATR support for tunneled TCP/IPv4/IPv6 packets.
    
    Without this, RSS would have done inner header load balancing. Now we can
    get the benefits of ATR for tunneled packets to better align TX and RX
    queues with the right core/interrupt.
    
    Change-ID: I07d0e0a192faf28fdd33b2f04c32b2a82ff97ddd
    Signed-off-by: Anjali Singhai Jain <anjali.singhai@intel.com>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 4b0b8102cdc3..ea1df3b48747 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -139,6 +139,7 @@ enum i40e_dyn_idx_t {
 #define I40E_TX_FLAGS_FSO		(u32)(1 << 7)
 #define I40E_TX_FLAGS_TSYN		(u32)(1 << 8)
 #define I40E_TX_FLAGS_FD_SB		(u32)(1 << 9)
+#define I40E_TX_FLAGS_VXLAN_TUNNEL	(u32)(1 << 10)
 #define I40E_TX_FLAGS_VLAN_MASK		0xffff0000
 #define I40E_TX_FLAGS_VLAN_PRIO_MASK	0xe0000000
 #define I40E_TX_FLAGS_VLAN_PRIO_SHIFT	29

commit 71a83a6db6138b9d41d8a0b6b91cb59f6dc4742c
Merge: b97526f3ff95 a6c5170d1ede
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Mar 3 21:16:48 2015 -0500

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Conflicts:
            drivers/net/ethernet/rocker/rocker.c
    
    The rocker commit was two overlapping changes, one to rename
    the ->vport member to ->pport, and another making the bitmask
    expression use '1ULL' instead of plain '1'.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 71da61976ec18fb57b3ba9a1dd846b747cc7c884
Author: Anjali Singhai <anjali.singhai@intel.com>
Date:   Sat Feb 21 06:42:35 2015 +0000

    i40e: Fix TSO with more than 8 frags per segment issue
    
    The hardware has some limitations the driver needs to adhere to,
    that we found in extended testing.
      1) no more than 8 descriptors per packet on the wire
      2) no header can span more than 3 descriptors
    
    If one of these events occurs, the hardware will generate an internal
    error and freeze the Tx queue.
    
    This patch linearizes the skb to avoid these situations.
    
    Change-ID: I37dab7d3966e14895a9663ec4d0aaa8eb0d9e115
    Signed-off-by: Anjali Singhai Jain <anjali.singhai@intel.com>
    Tested-by: Jim Young <james.m.young@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 18b00231d2f1..dff0baeb1ecc 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -112,6 +112,7 @@ enum i40e_dyn_idx_t {
 
 #define i40e_rx_desc i40e_32byte_rx_desc
 
+#define I40E_MAX_BUFFER_TXD	8
 #define I40E_MIN_TX_LEN		17
 #define I40E_MAX_DATA_PER_TXD	8192
 

commit a132af24e8d45edadcc0d5ce62ac02a54efb944a
Author: Mitch Williams <mitch.a.williams@intel.com>
Date:   Sat Jan 24 09:58:35 2015 +0000

    i40e/i40evf: Refactor the receive routines
    
    Split the receive hot path code into two, one for packet split and one
    for single buffer. This improves receive performance since we only need
    to check if the ring is in packet split mode once per NAPI poll time,
    not several times per packet. The single buffer code is further improved
    by the removal of a bunch of code and several variables that are not
    needed. On a receive-oriented test this can improve single-threaded
    throughput.
    
    Also refactor the packet split receive path to use a fixed buffer for
    headers, like ixgbe does. This vastly reduces the number of DMA mappings
    and unmappings we need to do, allowing for much better performance in
    the presence of an IOMMU.
    
    Lastly, correct packet split descriptor types now that we are actually
    using them.
    
    Change-ID: I3a194a93af3d2c31e77ff17644ac7376da6f3e4b
    Signed-off-by: Mitch Williams <mitch.a.williams@intel.com>
    Tested-by:  Jim Young <james.m.young@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 18b00231d2f1..38449b230d60 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -96,6 +96,14 @@ enum i40e_dyn_idx_t {
 
 /* How many Rx Buffers do we bundle into one write to the hardware ? */
 #define I40E_RX_BUFFER_WRITE	16	/* Must be power of 2 */
+#define I40E_RX_INCREMENT(r, i) \
+	do {					\
+		(i)++;				\
+		if ((i) == (r)->count)		\
+			i = 0;			\
+		r->next_to_clean = i;		\
+	} while (0)
+
 #define I40E_RX_NEXT_DESC(r, i, n)		\
 	do {					\
 		(i)++;				\
@@ -151,6 +159,7 @@ struct i40e_tx_buffer {
 
 struct i40e_rx_buffer {
 	struct sk_buff *skb;
+	void *hdr_buf;
 	dma_addr_t dma;
 	struct page *page;
 	dma_addr_t page_dma;
@@ -223,8 +232,8 @@ struct i40e_ring {
 	u16 rx_buf_len;
 	u8  dtype;
 #define I40E_RX_DTYPE_NO_SPLIT      0
-#define I40E_RX_DTYPE_SPLIT_ALWAYS  1
-#define I40E_RX_DTYPE_HEADER_SPLIT  2
+#define I40E_RX_DTYPE_HEADER_SPLIT  1
+#define I40E_RX_DTYPE_SPLIT_ALWAYS  2
 	u8  hsplit;
 #define I40E_RX_SPLIT_L2      0x1
 #define I40E_RX_SPLIT_IP      0x2
@@ -280,7 +289,9 @@ struct i40e_ring_container {
 #define i40e_for_each_ring(pos, head) \
 	for (pos = (head).ring; pos != NULL; pos = pos->next)
 
-void i40e_alloc_rx_buffers(struct i40e_ring *rxr, u16 cleaned_count);
+void i40e_alloc_rx_buffers_ps(struct i40e_ring *rxr, u16 cleaned_count);
+void i40e_alloc_rx_buffers_1buf(struct i40e_ring *rxr, u16 cleaned_count);
+void i40e_alloc_rx_headers(struct i40e_ring *rxr);
 netdev_tx_t i40e_lan_xmit_frame(struct sk_buff *skb, struct net_device *netdev);
 void i40e_clean_tx_ring(struct i40e_ring *tx_ring);
 void i40e_clean_rx_ring(struct i40e_ring *rx_ring);

commit d91649f5b719cd9d69206af7b3c4b4f6645e3b1e
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Wed Jan 7 02:55:01 2015 +0000

    i40e: fix un-necessary Tx hangs
    
    When the driver was polling with interrupts disabled the hardware
    will occasionally not write back descriptors.  This patch causes
    the driver to detect this situation and force an interrupt to
    fire which will flush the stuck descriptor.  Does not conflict
    with napi because if we are already polling the napi_schedule is
    ignored.  Additionally the extra interrupts are rate limited, so
    don't cause a burden to the CPU.
    
    Change-ID: Iba4616d2a71288672a5f08e4512e2704b97335e8
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index e60d3accb2e2..18b00231d2f1 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -241,6 +241,7 @@ struct i40e_ring {
 	unsigned long last_rx_timestamp;
 
 	bool ring_active;		/* is ring online or not */
+	bool arm_wb;		/* do something to arm write back */
 
 	/* stats structs */
 	struct i40e_queue_stats	stats;

commit 79442d38b370ed7317cd82fb2b6d1dafccaf44e5
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Sat Oct 25 03:24:32 2014 +0000

    i40e: clean up throttle rate code
    
    The interrupt throttle rate minimum is actually 2us, so
    fix that define and while we are there, remove some unused defines.
    
    Change some strings in the function to be a bit less wrappy, and
    express the correct limits.
    
    Change-ID: I96829bbc77935e0b57c6f0fc1439fb4152b2960a
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Signed-off-by: Patrick Lu <patrick.lu@intel.com>
    Tested-by: Jim Young <jamesx.m.young@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index d7a625a6a14f..e60d3accb2e2 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -30,10 +30,7 @@
 /* Interrupt Throttling and Rate Limiting Goodies */
 
 #define I40E_MAX_ITR               0x0FF0  /* reg uses 2 usec resolution */
-#define I40E_MIN_ITR               0x0004  /* reg uses 2 usec resolution */
-#define I40E_MAX_IRATE             0x03F
-#define I40E_MIN_IRATE             0x001
-#define I40E_IRATE_USEC_RESOLUTION 4
+#define I40E_MIN_ITR               0x0001  /* reg uses 2 usec resolution */
 #define I40E_ITR_100K              0x0005
 #define I40E_ITR_20K               0x0019
 #define I40E_ITR_8K                0x003E

commit 810b3ae42f5a6d1ddb17bb20eb69046de08ab1ef
Author: Anjali Singhai Jain <anjali.singhai@intel.com>
Date:   Thu Jul 10 07:58:25 2014 +0000

    i40e/i40evf: Ignore a driver perceived Tx hang if the number of desc pending < 4
    
    We are seeing situations where the driver sees a hang with less than 4
    desc pending, if the driver chooses to ignore it the queue progresses
    forward and the stack never experiences a real hang.
    With this patch we will log a stat when this situation happens
    "tx_sluggish" will increment and we can see some more details
    at a higher debug level. Other than that we will ignore this
    particular case of Tx hang.
    
    Change-ID: I7d1d1666d990e2b12f4f6bed0d17d22e1b6410d5
    Signed-off-by: Anjali Singhai Jain <anjali.singhai@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 73f4fa425697..d7a625a6a14f 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -121,6 +121,7 @@ enum i40e_dyn_idx_t {
 /* Tx Descriptors needed, worst case */
 #define TXD_USE_COUNT(S) DIV_ROUND_UP((S), I40E_MAX_DATA_PER_TXD)
 #define DESC_NEEDED (MAX_SKB_FRAGS + 4)
+#define I40E_MIN_DESC_PENDING	4
 
 #define I40E_TX_FLAGS_CSUM		(u32)(1)
 #define I40E_TX_FLAGS_HW_VLAN		(u32)(1 << 1)

commit 38e004388692f049908636a7944f6cd57d28bd77
Author: Vasu Dev <vasu.dev@intel.com>
Date:   Fri Aug 1 13:27:03 2014 -0700

    i40e: Adds FCoE related code to i40e core driver
    
    Adds FCoE specific code to existing i40e core driver to:-
    
    1. have separate FCoE VSI with additional FCoE queues pairs.
    2. have FCoE related hash defines.
    3. have additional FCoE related stats code.
    4. export and then re-use existing functions required by FCoE build.
    
    Signed-off-by: Vasu Dev <vasu.dev@intel.com>
    Tested-by: Jack Morgan<jack.morgan@intel.com>
    Signed-off-by: Aaron Brown <aaron.f.brown@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index c1c356984b17..73f4fa425697 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -290,4 +290,13 @@ int i40e_setup_rx_descriptors(struct i40e_ring *rx_ring);
 void i40e_free_tx_resources(struct i40e_ring *tx_ring);
 void i40e_free_rx_resources(struct i40e_ring *rx_ring);
 int i40e_napi_poll(struct napi_struct *napi, int budget);
+#ifdef I40E_FCOE
+void i40e_tx_map(struct i40e_ring *tx_ring, struct sk_buff *skb,
+		 struct i40e_tx_buffer *first, u32 tx_flags,
+		 const u8 hdr_len, u32 td_cmd, u32 td_offset);
+int i40e_maybe_stop_tx(struct i40e_ring *tx_ring, int size);
+int i40e_xmit_descriptor_count(struct sk_buff *skb, struct i40e_ring *tx_ring);
+int i40e_tx_prepare_vlan_flags(struct sk_buff *skb,
+			       struct i40e_ring *tx_ring, u32 *flags);
+#endif
 #endif /* _I40E_TXRX_H_ */

commit 49d7d933316375665cea49473d563cb8447d8a06
Author: Anjali Singhai Jain <anjali.singhai@intel.com>
Date:   Wed Jun 4 08:45:15 2014 +0000

    i40e/i40evf: Do not free the dummy packet buffer synchronously
    
    The HW still needs to consume it and freeing it in the function
    that created it would mean we will be racing with the HW. The
    i40e_clean_tx_ring() routine will free up the buffer attached once
    the HW has consumed it.  The clean_fdir_tx_irq function had to be fixed
    to handle the freeing correctly.
    
    Cases where we program more than one filter per flow (Ipv4), the
    code had to be changed to allocate dummy buffer multiple times
    since it will be freed by the clean routine.  This also fixes an issue
    where the filter program routine was not checking if there were
    descriptors available for programming a filter.
    
    Change-ID: Idf72028fd873221934e319d021ef65a1e51acaf7
    Signed-off-by: Anjali Singhai Jain <anjali.singhai@intel.com>
    Tested-by: Jim Young <jamesx.m.young@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index f09fb3ef691d..c1c356984b17 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -131,6 +131,7 @@ enum i40e_dyn_idx_t {
 #define I40E_TX_FLAGS_FCCRC		(u32)(1 << 6)
 #define I40E_TX_FLAGS_FSO		(u32)(1 << 7)
 #define I40E_TX_FLAGS_TSYN		(u32)(1 << 8)
+#define I40E_TX_FLAGS_FD_SB		(u32)(1 << 9)
 #define I40E_TX_FLAGS_VLAN_MASK		0xffff0000
 #define I40E_TX_FLAGS_VLAN_PRIO_MASK	0xe0000000
 #define I40E_TX_FLAGS_VLAN_PRIO_SHIFT	29
@@ -139,7 +140,10 @@ enum i40e_dyn_idx_t {
 struct i40e_tx_buffer {
 	struct i40e_tx_desc *next_to_watch;
 	unsigned long time_stamp;
-	struct sk_buff *skb;
+	union {
+		struct sk_buff *skb;
+		void *raw_buf;
+	};
 	unsigned int bytecount;
 	unsigned short gso_segs;
 	DEFINE_DMA_UNMAP_ADDR(dma);

commit c571ea05a03da856b1e9f8c0355128a7044d6a91
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Wed Jun 4 01:23:19 2014 +0000

    i40e/i40evf: remove reserved type
    
    One of the PCTYPES that was moved to a reserved value
    wasn't removed from the code.
    
    Change-ID: I31fafe6d79c5f5128179979af5eaafa8c0cd62fe
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 0277894fe1c4..f09fb3ef691d 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -75,7 +75,6 @@ enum i40e_dyn_idx_t {
 	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV4_OTHER) | \
 	((u64)1 << I40E_FILTER_PCTYPE_FRAG_IPV4) | \
 	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_UDP) | \
-	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_TCP_SYN) | \
 	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_TCP) | \
 	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_SCTP) | \
 	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_OTHER) | \

commit 980093ebf777f95459eabcf0ca7a29db7e9a10f7
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Sat May 10 04:49:12 2014 +0000

    i40e/i40evf: fix TSO accounting
    
    The TSO logic in the transmit path had some assumptions that
    have been broken now that the kernel can send as much as 32kB
    in a single skb->frag[.] entry, even on a system with 4kB pages.
    
    This fixes the assumptions and allows the kernel to operate
    as efficiently as possible with both SENDFILE and SEND.
    
    In addition, the hardware limit of data contained in a descriptor is
    changed to the next power of two below where it currently is in
    order to align to a power of two value, preventing a single byte
    of data in a descriptor.
    
    Change-ID: I6af1f0b87c1458e10644dbd47541591075a52651
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 30e5fe35fa3d..0277894fe1c4 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -117,11 +117,11 @@ enum i40e_dyn_idx_t {
 #define i40e_rx_desc i40e_32byte_rx_desc
 
 #define I40E_MIN_TX_LEN		17
-#define I40E_MAX_DATA_PER_TXD	16383	/* aka 16kB - 1 */
+#define I40E_MAX_DATA_PER_TXD	8192
 
 /* Tx Descriptors needed, worst case */
 #define TXD_USE_COUNT(S) DIV_ROUND_UP((S), I40E_MAX_DATA_PER_TXD)
-#define DESC_NEEDED ((MAX_SKB_FRAGS * TXD_USE_COUNT(PAGE_SIZE)) + 4)
+#define DESC_NEEDED (MAX_SKB_FRAGS + 4)
 
 #define I40E_TX_FLAGS_CSUM		(u32)(1)
 #define I40E_TX_FLAGS_HW_VLAN		(u32)(1 << 1)

commit d0277054ac9f0ddc420ad2f170a4f35baa909e48
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Wed Apr 23 04:50:04 2014 +0000

    i40e/i40evf: remove unused RX_LRO define
    
    Remove unused defines and macros for RX_LRO.
    
    Change-ID: I8ca6715edfa62b56837417a1c4ff68c2345dab6e
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Jim Young <jamesx.m.young@intel.com>
    Tested-by: Sibai Li <sibai.li@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index d5e3f5430284..30e5fe35fa3d 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -179,7 +179,6 @@ enum i40e_ring_state_t {
 	__I40E_TX_DETECT_HANG,
 	__I40E_HANG_CHECK_ARMED,
 	__I40E_RX_PS_ENABLED,
-	__I40E_RX_LRO_ENABLED,
 	__I40E_RX_16BYTE_DESC_ENABLED,
 };
 
@@ -195,12 +194,6 @@ enum i40e_ring_state_t {
 	set_bit(__I40E_TX_DETECT_HANG, &(ring)->state)
 #define clear_check_for_tx_hang(ring) \
 	clear_bit(__I40E_TX_DETECT_HANG, &(ring)->state)
-#define ring_is_lro_enabled(ring) \
-	test_bit(__I40E_RX_LRO_ENABLED, &(ring)->state)
-#define set_ring_lro_enabled(ring) \
-	set_bit(__I40E_RX_LRO_ENABLED, &(ring)->state)
-#define clear_ring_lro_enabled(ring) \
-	clear_bit(__I40E_RX_LRO_ENABLED, &(ring)->state)
 #define ring_is_16byte_desc_enabled(ring) \
 	test_bit(__I40E_RX_16BYTE_DESC_ENABLED, &(ring)->state)
 #define set_ring_16byte_desc_enabled(ring) \

commit aee8087f6b8a5021db50b134974538cfec373e88
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Wed Apr 9 05:59:02 2014 +0000

    i40e/i40evf: remove storm control
    
    The storm control features are not part of the hardware
    and mistakenly were left in the code.  Remove them as
    they are not needed any more.
    
    Change-ID: I6e9277c8da2c52e69348a657bae25271449c2099
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Kavindya Deegala <kavindya.s.deegala@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 71fbba9431eb..d5e3f5430284 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -27,7 +27,7 @@
 #ifndef _I40E_TXRX_H_
 #define _I40E_TXRX_H_
 
-/* Interrupt Throttling and Rate Limiting (storm control) Goodies */
+/* Interrupt Throttling and Rate Limiting Goodies */
 
 #define I40E_MAX_ITR               0x0FF0  /* reg uses 2 usec resolution */
 #define I40E_MIN_ITR               0x0004  /* reg uses 2 usec resolution */

commit b2d36c03ef0ad2d373fa5db2dcc54f8ee5d65545
Author: Kevin Scott <kevin.c.scott@intel.com>
Date:   Wed Apr 9 05:58:59 2014 +0000

    i40e/i40evf: Remove reserved PCTYPE defines
    
    Patch to remove PCTYPE definitions which are now reserved.
    
    Change-ID: I66c1c16a45a16f4894b2983101ab2a48ce03f1f4
    Signed-off-by: Kevin Scott <kevin.c.scott@intel.com>
    Signed-off-by: Shannon Nelson <shannon.nelson@intel.com>
    Tested-by: Jim Young <jamesx.m.young@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index d5349698e513..71fbba9431eb 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -69,16 +69,11 @@ enum i40e_dyn_idx_t {
 
 /* Supported RSS offloads */
 #define I40E_DEFAULT_RSS_HENA ( \
-	((u64)1 << I40E_FILTER_PCTYPE_NONF_UNICAST_IPV4_UDP) | \
-	((u64)1 << I40E_FILTER_PCTYPE_NONF_MULTICAST_IPV4_UDP) | \
 	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV4_UDP) | \
 	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV4_SCTP) | \
-	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV4_TCP_SYN) | \
 	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV4_TCP) | \
 	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV4_OTHER) | \
 	((u64)1 << I40E_FILTER_PCTYPE_FRAG_IPV4) | \
-	((u64)1 << I40E_FILTER_PCTYPE_NONF_UNICAST_IPV6_UDP) | \
-	((u64)1 << I40E_FILTER_PCTYPE_NONF_MULTICAST_IPV6_UDP) | \
 	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_UDP) | \
 	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_TCP_SYN) | \
 	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_TCP) | \

commit beb0dff1251db5214889ea8a122049ec3ae25e41
Author: Jacob Keller <jacob.e.keller@intel.com>
Date:   Sat Jan 11 05:43:19 2014 +0000

    i40e: enable PTP
    
    New feature: Enable PTP support in the i40e driver.
    
    Change-ID: I6a8e799f582705191f9583afb1b9231a8db96cc8
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Ben Hutchings <bhutchings@solarflare.com>
    Signed-off-by: Matthew Vick <matthew.vick@intel.com>
    Signed-off-by: Jacob Keller <jacob.e.keller@intel.com>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 93b8642d77cd..d5349698e513 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -136,6 +136,7 @@ enum i40e_dyn_idx_t {
 #define I40E_TX_FLAGS_IPV6		(u32)(1 << 5)
 #define I40E_TX_FLAGS_FCCRC		(u32)(1 << 6)
 #define I40E_TX_FLAGS_FSO		(u32)(1 << 7)
+#define I40E_TX_FLAGS_TSYN		(u32)(1 << 8)
 #define I40E_TX_FLAGS_VLAN_MASK		0xffff0000
 #define I40E_TX_FLAGS_VLAN_PRIO_MASK	0xe0000000
 #define I40E_TX_FLAGS_VLAN_PRIO_SHIFT	29
@@ -248,6 +249,8 @@ struct i40e_ring {
 	u8 atr_sample_rate;
 	u8 atr_count;
 
+	unsigned long last_rx_timestamp;
+
 	bool ring_active;		/* is ring online or not */
 
 	/* stats structs */

commit 3126dcb7368c152d74cda11a025328853948f9b9
Author: Shannon Nelson <shannon.nelson@intel.com>
Date:   Sat Dec 21 05:44:47 2013 +0000

    i40e: adjust ITR max and min values
    
    Set the ITR max and min values to match the hardware max value
    and the recommended min value.  These values are shifted right
    one bit because the register counts in 2 usec units, so leave
    a comment to explain.
    
    Change-ID: I289c27955cf6c566a6d21b95c3110b88cbb15dad
    Signed-off-by: Shannon Nelson <shannon.nelson@intel.com>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Kavindya Deegala <kavindya.s.deegala@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 6f8506c181d9..93b8642d77cd 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -29,9 +29,8 @@
 
 /* Interrupt Throttling and Rate Limiting (storm control) Goodies */
 
-#define I40E_MAX_ITR               0x07FF
-#define I40E_MIN_ITR               0x0001
-#define I40E_ITR_USEC_RESOLUTION   2
+#define I40E_MAX_ITR               0x0FF0  /* reg uses 2 usec resolution */
+#define I40E_MIN_ITR               0x0004  /* reg uses 2 usec resolution */
 #define I40E_MAX_IRATE             0x03F
 #define I40E_MIN_IRATE             0x001
 #define I40E_IRATE_USEC_RESOLUTION 4

commit 420136cccb3b042c46cb796d0d5e33ed4e8eebd7
Author: Mitch Williams <mitch.a.williams@intel.com>
Date:   Wed Dec 18 13:45:59 2013 +0000

    i40e: shorten wordy fields
    
    The alloc_rx_buff_failed and alloc_rx_page_failed variables
    are both part of an rx specific structure so just remove
    the _rx part of the name.  No functional changes.
    
    Change-ID: Icffa2f5d13c6f2b1e09cf45b9472b83c9dae8fc6
    Signed-off-by: Mitch Williams <mitch.a.williams@intel.com>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Kavindya Deegala <kavindya.s.deegala@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 7ec744b85d6a..6f8506c181d9 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -174,8 +174,8 @@ struct i40e_tx_queue_stats {
 
 struct i40e_rx_queue_stats {
 	u64 non_eop_descs;
-	u64 alloc_rx_page_failed;
-	u64 alloc_rx_buff_failed;
+	u64 alloc_page_failed;
+	u64 alloc_buff_failed;
 };
 
 enum i40e_ring_state_t {

commit dc641b7319f19a17639ed7d36aaddbf090206644
Author: Greg Rose <gregory.v.rose@intel.com>
Date:   Wed Dec 18 13:45:51 2013 +0000

    i40e: Fix GPL header
    
    The GPL header included in each file in the i40e driver doesn't
    need to include the "this program" text since this driver
    is already part of the larger kernel.
    
    Signed-off-by: Greg Rose <gregory.v.rose@intel.com>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Kavindya Deegala <kavindya.s.deegala@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 92f5cf5079e1..7ec744b85d6a 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -1,7 +1,7 @@
 /*******************************************************************************
  *
  * Intel Ethernet Controller XL710 Family Linux Driver
- * Copyright(c) 2013 Intel Corporation.
+ * Copyright(c) 2013 - 2014 Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
@@ -12,9 +12,8 @@
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
- * You should have received a copy of the GNU General Public License along with
- * this program; if not, write to the Free Software Foundation, Inc.,
- * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ * You should have received a copy of the GNU General Public License along
+ * with this program.  If not, see <http://www.gnu.org/licenses/>.
  *
  * The full GNU General Public License is included in this distribution in
  * the file called "COPYING".

commit 36fac58180937f0d76ebb0800a80bd6cfa466f86
Author: Vasu Dev <vasu.dev@intel.com>
Date:   Thu Nov 28 06:39:31 2013 +0000

    i40e: add header file flag _I40E_TXRX_H_
    
    Add an include header guard to guard against multiple includes
    
    Change-Id: I73efa03efc912d2047edab903c7caed05b444da2
    Signed-off-by: Vasu Dev <vasu.dev@intel.com>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Kavindya Deegala <kavindya.s.deegala@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 2992830d9333..92f5cf5079e1 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -25,6 +25,9 @@
  *
  ******************************************************************************/
 
+#ifndef _I40E_TXRX_H_
+#define _I40E_TXRX_H_
+
 /* Interrupt Throttling and Rate Limiting (storm control) Goodies */
 
 #define I40E_MAX_ITR               0x07FF
@@ -295,3 +298,4 @@ int i40e_setup_rx_descriptors(struct i40e_ring *rx_ring);
 void i40e_free_tx_resources(struct i40e_ring *tx_ring);
 void i40e_free_rx_resources(struct i40e_ring *rx_ring);
 int i40e_napi_poll(struct napi_struct *napi, int budget);
+#endif /* _I40E_TXRX_H_ */

commit 12dc4fe3981e94f43088b863a7ecccf86d641953
Author: Mitch Williams <mitch.a.williams@intel.com>
Date:   Thu Nov 28 06:39:32 2013 +0000

    i40e: make a define from a large constant
    
    Make a define used in the header file by both VF and PF drivers.
    
    Change-Id: Ie9e35adcc021cd6a8f7513934984eb4ed55774f5
    Signed-off-by: Mitch Williams <mitch.a.williams@intel.com>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Kavindya Deegala <kavindya.s.deegala@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index faabf22fbd20..2992830d9333 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -66,6 +66,26 @@ enum i40e_dyn_idx_t {
 #define I40E_TX_ITR    I40E_IDX_ITR1
 #define I40E_PE_ITR    I40E_IDX_ITR2
 
+/* Supported RSS offloads */
+#define I40E_DEFAULT_RSS_HENA ( \
+	((u64)1 << I40E_FILTER_PCTYPE_NONF_UNICAST_IPV4_UDP) | \
+	((u64)1 << I40E_FILTER_PCTYPE_NONF_MULTICAST_IPV4_UDP) | \
+	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV4_UDP) | \
+	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV4_SCTP) | \
+	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV4_TCP_SYN) | \
+	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV4_TCP) | \
+	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV4_OTHER) | \
+	((u64)1 << I40E_FILTER_PCTYPE_FRAG_IPV4) | \
+	((u64)1 << I40E_FILTER_PCTYPE_NONF_UNICAST_IPV6_UDP) | \
+	((u64)1 << I40E_FILTER_PCTYPE_NONF_MULTICAST_IPV6_UDP) | \
+	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_UDP) | \
+	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_TCP_SYN) | \
+	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_TCP) | \
+	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_SCTP) | \
+	((u64)1 << I40E_FILTER_PCTYPE_NONF_IPV6_OTHER) | \
+	((u64)1 << I40E_FILTER_PCTYPE_FRAG_IPV6) | \
+	((u64)1 << I40E_FILTER_PCTYPE_L2_PAYLOAD))
+
 /* Supported Rx Buffer Sizes */
 #define I40E_RXBUFFER_512   512    /* Used for packet split */
 #define I40E_RXBUFFER_2048  2048

commit 0319577f8902cd420d3159ac6dd134f1de10b52e
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Wed Nov 20 10:03:09 2013 +0000

    i40e: remove and fix confusing define name
    
    I40E_ITR_NONE was being used as an ITRN register index by
    accident because it was easily associated with the I40E_RX_ITR
    and friends defines.
    
    Change the name slightly in order to make it clear that
    I40E_ITR_NONE is really associated with the DYN_CTL register
    sets.
    
    Change-Id: I04702c027c7495b90a8bf2db85d3e085a2c7d02a
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Kavindya Deegala <kavindya.s.deegala@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index db55d9947f15..faabf22fbd20 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -49,10 +49,23 @@
 
 #define I40E_QUEUE_END_OF_LIST 0x7FF
 
-#define I40E_ITR_NONE  3
-#define I40E_RX_ITR    0
-#define I40E_TX_ITR    1
-#define I40E_PE_ITR    2
+/* this enum matches hardware bits and is meant to be used by DYN_CTLN
+ * registers and QINT registers or more generally anywhere in the manual
+ * mentioning ITR_INDX, ITR_NONE cannot be used as an index 'n' into any
+ * register but instead is a special value meaning "don't update" ITR0/1/2.
+ */
+enum i40e_dyn_idx_t {
+	I40E_IDX_ITR0 = 0,
+	I40E_IDX_ITR1 = 1,
+	I40E_IDX_ITR2 = 2,
+	I40E_ITR_NONE = 3	/* ITR_NONE must not be used as an index */
+};
+
+/* these are indexes into ITRN registers */
+#define I40E_RX_ITR    I40E_IDX_ITR0
+#define I40E_TX_ITR    I40E_IDX_ITR1
+#define I40E_PE_ITR    I40E_IDX_ITR2
+
 /* Supported Rx Buffer Sizes */
 #define I40E_RXBUFFER_512   512    /* Used for packet split */
 #define I40E_RXBUFFER_2048  2048

commit 980e9b1186424fa3eb766d59fc91003d0ed1ed6a
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Sat Sep 28 06:01:03 2013 +0000

    i40e: Add support for 64 bit netstats
    
    This change brings support for 64 bit netstats to the driver. Previously
    the stats were 64 bit but highly racy due to the fact that 64 bit
    transactions are not atomic on 32 bit systems.  This change makes is so
    that the 64 bit byte and packet stats are reliable on all architectures.
    
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Kavindya Deegala <kavindya.s.deegala@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 5db36c38573e..db55d9947f15 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -218,6 +218,7 @@ struct i40e_ring {
 
 	/* stats structs */
 	struct i40e_queue_stats	stats;
+	struct u64_stats_sync syncp;
 	union {
 		struct i40e_tx_queue_stats tx_stats;
 		struct i40e_rx_queue_stats rx_stats;

commit 9f65e15b4f982391eef795a74adcc6580f0d7c53
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Sat Sep 28 06:00:58 2013 +0000

    i40e: Move rings from pointer to array to array of pointers
    
    Allocate the queue pairs individually instead of as a group.  This
    allows for much easier queue management as it is possible to dynamically
    resize the queues without having to free and allocate the entire block.
    
    Ease statistic collection by treating Tx/Rx queue pairs as a single
    unit.  Each pair is allocated together and starts with a Tx queue and
    ends with an Rx queue.  By ordering them this way it is possible to know
    the Rx offset based on a pointer to the Tx queue.
    
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Kavindya Deegala <kavindya.s.deegala@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index c2a6746a5ec9..5db36c38573e 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -228,6 +228,8 @@ struct i40e_ring {
 
 	struct i40e_vsi *vsi;		/* Backreference to associated VSI */
 	struct i40e_q_vector *q_vector;	/* Backreference to associated vector */
+
+	struct rcu_head rcu;		/* to avoid race on free */
 } ____cacheline_internodealigned_in_smp;
 
 enum i40e_latency_range {

commit cd0b6fa65692a2bc150c3228008b812b1f45aed0
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Sat Sep 28 06:00:53 2013 +0000

    i40e: Replace ring container array with linked list
    
    This replaces the ring container array with a linked list.  The idea is
    to make the logic much easier to deal with since this will allow us to
    call a simple helper function from the q_vectors to go through the
    entire list.
    
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Kavindya Deegala <kavindya.s.deegala@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 7f3f7e3e4238..c2a6746a5ec9 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -180,6 +180,7 @@ enum i40e_ring_state_t {
 
 /* struct that defines a descriptor ring, associated with a VSI */
 struct i40e_ring {
+	struct i40e_ring *next;		/* pointer to next ring in q_vector */
 	void *desc;			/* Descriptor ring memory */
 	struct device *dev;		/* Used for DMA mapping */
 	struct net_device *netdev;	/* netdev ring maps to */
@@ -236,9 +237,8 @@ enum i40e_latency_range {
 };
 
 struct i40e_ring_container {
-#define I40E_MAX_RINGPAIR_PER_VECTOR 8
 	/* array of pointers to rings */
-	struct i40e_ring *ring[I40E_MAX_RINGPAIR_PER_VECTOR];
+	struct i40e_ring *ring;
 	unsigned int total_bytes;	/* total bytes processed this int */
 	unsigned int total_packets;	/* total packets processed this int */
 	u16 count;
@@ -246,6 +246,10 @@ struct i40e_ring_container {
 	u16 itr;
 };
 
+/* iterator for handling rings in ring container */
+#define i40e_for_each_ring(pos, head) \
+	for (pos = (head).ring; pos != NULL; pos = pos->next)
+
 void i40e_alloc_rx_buffers(struct i40e_ring *rxr, u16 cleaned_count);
 netdev_tx_t i40e_lan_xmit_frame(struct sk_buff *skb, struct net_device *netdev);
 void i40e_clean_tx_ring(struct i40e_ring *tx_ring);

commit a114d0a6aca7f96f46be93539665dbb28bdf1a73
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Sat Sep 28 06:00:43 2013 +0000

    i40e: Split bytes and packets from Rx/Tx stats
    
    This makes it so that the Tx and Rx byte and packet counts are
    separated from the rest of the statistics.  This allows for better
    isolation of these stats when we move them into the 64 bit statistics.
    
    Simplify things by re-ordering how the stats display in ethtool.
    Instead of displaying all of the Tx queues as a block, followed by all
    the Rx queues, the new order is Tx[0], Rx[0], Tx[1], Rx[1], ..., Tx[n],
    Rx[n].  This reduces the loops and cleans up the display for testing
    purposes since it is very easy to verify if flow director is doing the
    right thing as the Tx and Rx queue pair are shown in pairs.
    
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Kavindya Deegala <kavindya.s.deegala@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index e5142476a7f0..7f3f7e3e4238 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -126,17 +126,18 @@ struct i40e_rx_buffer {
 	unsigned int page_offset;
 };
 
-struct i40e_tx_queue_stats {
+struct i40e_queue_stats {
 	u64 packets;
 	u64 bytes;
+};
+
+struct i40e_tx_queue_stats {
 	u64 restart_queue;
 	u64 tx_busy;
 	u64 tx_done_old;
 };
 
 struct i40e_rx_queue_stats {
-	u64 packets;
-	u64 bytes;
 	u64 non_eop_descs;
 	u64 alloc_rx_page_failed;
 	u64 alloc_rx_buff_failed;
@@ -215,6 +216,7 @@ struct i40e_ring {
 	bool ring_active;		/* is ring online or not */
 
 	/* stats structs */
+	struct i40e_queue_stats	stats;
 	union {
 		struct i40e_tx_queue_stats tx_stats;
 		struct i40e_rx_queue_stats rx_stats;

commit b194130627580519e63665660db055bfe82b6949
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Sat Sep 28 06:00:32 2013 +0000

    i40e: Drop dead code and flags from Tx hotpath
    
    Drop Tx flag and TXSW which is tested but never set.
    
    As a result of this change we can drop a complicated check that always
    resulted in the final result of i40e_tx_csum being equal to the
    CHECKSUM_PARTIAL value.  As such we can replace the entire function call
    with just a check for skb->summed == CHECKSUM_PARTIAL.
    
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Kavindya Deegala <kavindya.s.deegala@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 2cb1338fb794..e5142476a7f0 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -102,7 +102,6 @@
 #define I40E_TX_FLAGS_IPV6		(u32)(1 << 5)
 #define I40E_TX_FLAGS_FCCRC		(u32)(1 << 6)
 #define I40E_TX_FLAGS_FSO		(u32)(1 << 7)
-#define I40E_TX_FLAGS_TXSW		(u32)(1 << 8)
 #define I40E_TX_FLAGS_VLAN_MASK		0xffff0000
 #define I40E_TX_FLAGS_VLAN_PRIO_MASK	0xe0000000
 #define I40E_TX_FLAGS_VLAN_PRIO_SHIFT	29

commit a5e9c5726424b05a3643450d45c134cea103181e
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Sat Sep 28 06:00:27 2013 +0000

    i40e: clean up Tx fast path
    
    Sync the fast path for i40e_tx_map and i40e_clean_tx_irq so that they
    are similar to igb and ixgbe.
    
    - Only update the Tx descriptor ring in tx_map
    - Make skb mapping always on the first buffer in the chain
    - Drop the use of MAPPED_AS_PAGE Tx flag
    - Only store flags on the first buffer_info structure
    
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Kavindya Deegala <kavindya.s.deegala@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 711f54938489..2cb1338fb794 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -103,7 +103,6 @@
 #define I40E_TX_FLAGS_FCCRC		(u32)(1 << 6)
 #define I40E_TX_FLAGS_FSO		(u32)(1 << 7)
 #define I40E_TX_FLAGS_TXSW		(u32)(1 << 8)
-#define I40E_TX_FLAGS_MAPPED_AS_PAGE	(u32)(1 << 9)
 #define I40E_TX_FLAGS_VLAN_MASK		0xffff0000
 #define I40E_TX_FLAGS_VLAN_PRIO_MASK	0xe0000000
 #define I40E_TX_FLAGS_VLAN_PRIO_SHIFT	29

commit 35a1e2ad1716fe3d956eea6e356ca2758f6392a7
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Sat Sep 28 06:00:17 2013 +0000

    i40e: Cleanup Tx buffer info layout
    
    - drop the mapped_as_page u8 from the Tx buffer info as it was unused
    - use the DMA unmap accessors for Tx DMA
    - replace checks of DMA with checks of the unmap length to verify if an
      unmap is needed
    - update the Tx buffer layout to make it consistent with igb, ixgbe
    
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Kavindya Deegala <kavindya.s.deegala@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index 2fbacaff0445..711f54938489 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -110,15 +110,14 @@
 #define I40E_TX_FLAGS_VLAN_SHIFT	16
 
 struct i40e_tx_buffer {
-	struct sk_buff *skb;
-	dma_addr_t dma;
-	unsigned long time_stamp;
-	u16 length;
-	u32 tx_flags;
 	struct i40e_tx_desc *next_to_watch;
+	unsigned long time_stamp;
+	struct sk_buff *skb;
 	unsigned int bytecount;
-	u16 gso_segs;
-	u8 mapped_as_page;
+	unsigned short gso_segs;
+	DEFINE_DMA_UNMAP_ADDR(dma);
+	DEFINE_DMA_UNMAP_LEN(len);
+	u32 tx_flags;
 };
 
 struct i40e_rx_buffer {

commit c304fdac6cc0aab1f01e0f2b32c881d908a57a84
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Sat Sep 28 06:00:12 2013 +0000

    i40e: Drop unused completed stat
    
    The Tx "completed" stat was part of the original rewrite for detecting
    Tx hangs.  However some time ago in ixgbe I determined that we could
    just use the packets stat instead.  Since then this stat was
    removed from ixgbe and it serves no purpose in i40e so it can be
    dropped.
    
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Tested-by: Kavindya Deegala <kavindya.s.deegala@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
index b1d7722d98a7..2fbacaff0445 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.h
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -134,7 +134,6 @@ struct i40e_tx_queue_stats {
 	u64 bytes;
 	u64 restart_queue;
 	u64 tx_busy;
-	u64 completed;
 	u64 tx_done_old;
 };
 

commit 7daa6bf3294e518cf939830c1a8ec2a6a96204ac
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Wed Sep 11 08:40:01 2013 +0000

    i40e: driver core headers
    
    This patch contains the main driver header files, containing
    structures and data types specific to the linux driver.
    
    i40e_osdep.h contains some code that helps us adapt our OS agnostic code to
    Linux.
    
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Signed-off-by: Shannon Nelson <shannon.nelson@intel.com>
    CC: PJ Waskiewicz <peter.p.waskiewicz.jr@intel.com>
    CC: e1000-devel@lists.sourceforge.net
    Tested-by: Kavindya Deegala <kavindya.s.deegala@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.h b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
new file mode 100644
index 000000000000..b1d7722d98a7
--- /dev/null
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.h
@@ -0,0 +1,259 @@
+/*******************************************************************************
+ *
+ * Intel Ethernet Controller XL710 Family Linux Driver
+ * Copyright(c) 2013 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * The full GNU General Public License is included in this distribution in
+ * the file called "COPYING".
+ *
+ * Contact Information:
+ * e1000-devel Mailing List <e1000-devel@lists.sourceforge.net>
+ * Intel Corporation, 5200 N.E. Elam Young Parkway, Hillsboro, OR 97124-6497
+ *
+ ******************************************************************************/
+
+/* Interrupt Throttling and Rate Limiting (storm control) Goodies */
+
+#define I40E_MAX_ITR               0x07FF
+#define I40E_MIN_ITR               0x0001
+#define I40E_ITR_USEC_RESOLUTION   2
+#define I40E_MAX_IRATE             0x03F
+#define I40E_MIN_IRATE             0x001
+#define I40E_IRATE_USEC_RESOLUTION 4
+#define I40E_ITR_100K              0x0005
+#define I40E_ITR_20K               0x0019
+#define I40E_ITR_8K                0x003E
+#define I40E_ITR_4K                0x007A
+#define I40E_ITR_RX_DEF            I40E_ITR_8K
+#define I40E_ITR_TX_DEF            I40E_ITR_4K
+#define I40E_ITR_DYNAMIC           0x8000  /* use top bit as a flag */
+#define I40E_MIN_INT_RATE          250     /* ~= 1000000 / (I40E_MAX_ITR * 2) */
+#define I40E_MAX_INT_RATE          500000  /* == 1000000 / (I40E_MIN_ITR * 2) */
+#define I40E_DEFAULT_IRQ_WORK      256
+#define ITR_TO_REG(setting) ((setting & ~I40E_ITR_DYNAMIC) >> 1)
+#define ITR_IS_DYNAMIC(setting) (!!(setting & I40E_ITR_DYNAMIC))
+#define ITR_REG_TO_USEC(itr_reg) (itr_reg << 1)
+
+#define I40E_QUEUE_END_OF_LIST 0x7FF
+
+#define I40E_ITR_NONE  3
+#define I40E_RX_ITR    0
+#define I40E_TX_ITR    1
+#define I40E_PE_ITR    2
+/* Supported Rx Buffer Sizes */
+#define I40E_RXBUFFER_512   512    /* Used for packet split */
+#define I40E_RXBUFFER_2048  2048
+#define I40E_RXBUFFER_3072  3072   /* For FCoE MTU of 2158 */
+#define I40E_RXBUFFER_4096  4096
+#define I40E_RXBUFFER_8192  8192
+#define I40E_MAX_RXBUFFER   9728  /* largest size for single descriptor */
+
+/* NOTE: netdev_alloc_skb reserves up to 64 bytes, NET_IP_ALIGN means we
+ * reserve 2 more, and skb_shared_info adds an additional 384 bytes more,
+ * this adds up to 512 bytes of extra data meaning the smallest allocation
+ * we could have is 1K.
+ * i.e. RXBUFFER_512 --> size-1024 slab
+ */
+#define I40E_RX_HDR_SIZE  I40E_RXBUFFER_512
+
+/* How many Rx Buffers do we bundle into one write to the hardware ? */
+#define I40E_RX_BUFFER_WRITE	16	/* Must be power of 2 */
+#define I40E_RX_NEXT_DESC(r, i, n)		\
+	do {					\
+		(i)++;				\
+		if ((i) == (r)->count)		\
+			i = 0;			\
+		(n) = I40E_RX_DESC((r), (i));	\
+	} while (0)
+
+#define I40E_RX_NEXT_DESC_PREFETCH(r, i, n)		\
+	do {						\
+		I40E_RX_NEXT_DESC((r), (i), (n));	\
+		prefetch((n));				\
+	} while (0)
+
+#define i40e_rx_desc i40e_32byte_rx_desc
+
+#define I40E_MIN_TX_LEN		17
+#define I40E_MAX_DATA_PER_TXD	16383	/* aka 16kB - 1 */
+
+/* Tx Descriptors needed, worst case */
+#define TXD_USE_COUNT(S) DIV_ROUND_UP((S), I40E_MAX_DATA_PER_TXD)
+#define DESC_NEEDED ((MAX_SKB_FRAGS * TXD_USE_COUNT(PAGE_SIZE)) + 4)
+
+#define I40E_TX_FLAGS_CSUM		(u32)(1)
+#define I40E_TX_FLAGS_HW_VLAN		(u32)(1 << 1)
+#define I40E_TX_FLAGS_SW_VLAN		(u32)(1 << 2)
+#define I40E_TX_FLAGS_TSO		(u32)(1 << 3)
+#define I40E_TX_FLAGS_IPV4		(u32)(1 << 4)
+#define I40E_TX_FLAGS_IPV6		(u32)(1 << 5)
+#define I40E_TX_FLAGS_FCCRC		(u32)(1 << 6)
+#define I40E_TX_FLAGS_FSO		(u32)(1 << 7)
+#define I40E_TX_FLAGS_TXSW		(u32)(1 << 8)
+#define I40E_TX_FLAGS_MAPPED_AS_PAGE	(u32)(1 << 9)
+#define I40E_TX_FLAGS_VLAN_MASK		0xffff0000
+#define I40E_TX_FLAGS_VLAN_PRIO_MASK	0xe0000000
+#define I40E_TX_FLAGS_VLAN_PRIO_SHIFT	29
+#define I40E_TX_FLAGS_VLAN_SHIFT	16
+
+struct i40e_tx_buffer {
+	struct sk_buff *skb;
+	dma_addr_t dma;
+	unsigned long time_stamp;
+	u16 length;
+	u32 tx_flags;
+	struct i40e_tx_desc *next_to_watch;
+	unsigned int bytecount;
+	u16 gso_segs;
+	u8 mapped_as_page;
+};
+
+struct i40e_rx_buffer {
+	struct sk_buff *skb;
+	dma_addr_t dma;
+	struct page *page;
+	dma_addr_t page_dma;
+	unsigned int page_offset;
+};
+
+struct i40e_tx_queue_stats {
+	u64 packets;
+	u64 bytes;
+	u64 restart_queue;
+	u64 tx_busy;
+	u64 completed;
+	u64 tx_done_old;
+};
+
+struct i40e_rx_queue_stats {
+	u64 packets;
+	u64 bytes;
+	u64 non_eop_descs;
+	u64 alloc_rx_page_failed;
+	u64 alloc_rx_buff_failed;
+};
+
+enum i40e_ring_state_t {
+	__I40E_TX_FDIR_INIT_DONE,
+	__I40E_TX_XPS_INIT_DONE,
+	__I40E_TX_DETECT_HANG,
+	__I40E_HANG_CHECK_ARMED,
+	__I40E_RX_PS_ENABLED,
+	__I40E_RX_LRO_ENABLED,
+	__I40E_RX_16BYTE_DESC_ENABLED,
+};
+
+#define ring_is_ps_enabled(ring) \
+	test_bit(__I40E_RX_PS_ENABLED, &(ring)->state)
+#define set_ring_ps_enabled(ring) \
+	set_bit(__I40E_RX_PS_ENABLED, &(ring)->state)
+#define clear_ring_ps_enabled(ring) \
+	clear_bit(__I40E_RX_PS_ENABLED, &(ring)->state)
+#define check_for_tx_hang(ring) \
+	test_bit(__I40E_TX_DETECT_HANG, &(ring)->state)
+#define set_check_for_tx_hang(ring) \
+	set_bit(__I40E_TX_DETECT_HANG, &(ring)->state)
+#define clear_check_for_tx_hang(ring) \
+	clear_bit(__I40E_TX_DETECT_HANG, &(ring)->state)
+#define ring_is_lro_enabled(ring) \
+	test_bit(__I40E_RX_LRO_ENABLED, &(ring)->state)
+#define set_ring_lro_enabled(ring) \
+	set_bit(__I40E_RX_LRO_ENABLED, &(ring)->state)
+#define clear_ring_lro_enabled(ring) \
+	clear_bit(__I40E_RX_LRO_ENABLED, &(ring)->state)
+#define ring_is_16byte_desc_enabled(ring) \
+	test_bit(__I40E_RX_16BYTE_DESC_ENABLED, &(ring)->state)
+#define set_ring_16byte_desc_enabled(ring) \
+	set_bit(__I40E_RX_16BYTE_DESC_ENABLED, &(ring)->state)
+#define clear_ring_16byte_desc_enabled(ring) \
+	clear_bit(__I40E_RX_16BYTE_DESC_ENABLED, &(ring)->state)
+
+/* struct that defines a descriptor ring, associated with a VSI */
+struct i40e_ring {
+	void *desc;			/* Descriptor ring memory */
+	struct device *dev;		/* Used for DMA mapping */
+	struct net_device *netdev;	/* netdev ring maps to */
+	union {
+		struct i40e_tx_buffer *tx_bi;
+		struct i40e_rx_buffer *rx_bi;
+	};
+	unsigned long state;
+	u16 queue_index;		/* Queue number of ring */
+	u8 dcb_tc;			/* Traffic class of ring */
+	u8 __iomem *tail;
+
+	u16 count;			/* Number of descriptors */
+	u16 reg_idx;			/* HW register index of the ring */
+	u16 rx_hdr_len;
+	u16 rx_buf_len;
+	u8  dtype;
+#define I40E_RX_DTYPE_NO_SPLIT      0
+#define I40E_RX_DTYPE_SPLIT_ALWAYS  1
+#define I40E_RX_DTYPE_HEADER_SPLIT  2
+	u8  hsplit;
+#define I40E_RX_SPLIT_L2      0x1
+#define I40E_RX_SPLIT_IP      0x2
+#define I40E_RX_SPLIT_TCP_UDP 0x4
+#define I40E_RX_SPLIT_SCTP    0x8
+
+	/* used in interrupt processing */
+	u16 next_to_use;
+	u16 next_to_clean;
+
+	u8 atr_sample_rate;
+	u8 atr_count;
+
+	bool ring_active;		/* is ring online or not */
+
+	/* stats structs */
+	union {
+		struct i40e_tx_queue_stats tx_stats;
+		struct i40e_rx_queue_stats rx_stats;
+	};
+
+	unsigned int size;		/* length of descriptor ring in bytes */
+	dma_addr_t dma;			/* physical address of ring */
+
+	struct i40e_vsi *vsi;		/* Backreference to associated VSI */
+	struct i40e_q_vector *q_vector;	/* Backreference to associated vector */
+} ____cacheline_internodealigned_in_smp;
+
+enum i40e_latency_range {
+	I40E_LOWEST_LATENCY = 0,
+	I40E_LOW_LATENCY = 1,
+	I40E_BULK_LATENCY = 2,
+};
+
+struct i40e_ring_container {
+#define I40E_MAX_RINGPAIR_PER_VECTOR 8
+	/* array of pointers to rings */
+	struct i40e_ring *ring[I40E_MAX_RINGPAIR_PER_VECTOR];
+	unsigned int total_bytes;	/* total bytes processed this int */
+	unsigned int total_packets;	/* total packets processed this int */
+	u16 count;
+	enum i40e_latency_range latency_range;
+	u16 itr;
+};
+
+void i40e_alloc_rx_buffers(struct i40e_ring *rxr, u16 cleaned_count);
+netdev_tx_t i40e_lan_xmit_frame(struct sk_buff *skb, struct net_device *netdev);
+void i40e_clean_tx_ring(struct i40e_ring *tx_ring);
+void i40e_clean_rx_ring(struct i40e_ring *rx_ring);
+int i40e_setup_tx_descriptors(struct i40e_ring *tx_ring);
+int i40e_setup_rx_descriptors(struct i40e_ring *rx_ring);
+void i40e_free_tx_resources(struct i40e_ring *tx_ring);
+void i40e_free_rx_resources(struct i40e_ring *rx_ring);
+int i40e_napi_poll(struct napi_struct *napi, int budget);
