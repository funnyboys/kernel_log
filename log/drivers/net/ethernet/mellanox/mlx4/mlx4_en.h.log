commit cf4058dbaa18bf8e55b7cb8c04e1c313298cd5b1
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Apr 22 09:13:29 2020 -0700

    net/mlx4_en: use napi_complete_done() in TX completion
    
    In order to benefit from the new napi_defer_hard_irqs feature,
    we need to use napi_complete_done() variant in this driver.
    
    RX path is already using it, this patch implements TX completion side.
    
    mlx4_en_process_tx_cq() now returns the amount of retired packets,
    instead of a boolean, so that mlx4_en_poll_tx_cq() can pass
    this value to napi_complete_done().
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 630f15977f09..9f5603612960 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -737,8 +737,8 @@ int mlx4_en_process_rx_cq(struct net_device *dev,
 			  int budget);
 int mlx4_en_poll_rx_cq(struct napi_struct *napi, int budget);
 int mlx4_en_poll_tx_cq(struct napi_struct *napi, int budget);
-bool mlx4_en_process_tx_cq(struct net_device *dev,
-			   struct mlx4_en_cq *cq, int napi_budget);
+int mlx4_en_process_tx_cq(struct net_device *dev,
+			  struct mlx4_en_cq *cq, int napi_budget);
 u32 mlx4_en_free_tx_desc(struct mlx4_en_priv *priv,
 			 struct mlx4_en_tx_ring *ring,
 			 int index, u64 timestamp,

commit a350eccee5830d9a1f29e393a88dc05a15326d44
Author: Paolo Abeni <pabeni@redhat.com>
Date:   Wed Mar 20 11:02:06 2019 +0100

    net: remove 'fallback' argument from dev->ndo_select_queue()
    
    After the previous patch, all the callers of ndo_select_queue()
    provide as a 'fallback' argument netdev_pick_tx.
    The only exceptions are nested calls to ndo_select_queue(),
    which pass down the 'fallback' available in the current scope
    - still netdev_pick_tx.
    
    We can drop such argument and replace fallback() invocation with
    netdev_pick_tx(). This avoids an indirect call per xmit packet
    in some scenarios (TCP syn, UDP unconnected, XDP generic, pktgen)
    with device drivers implementing such ndo. It also clean the code
    a bit.
    
    Tested with ixgbe and CONFIG_FCOE=m
    
    With pktgen using queue xmit:
    threads         vanilla         patched
                    (kpps)          (kpps)
    1               2334            2428
    2               4166            4278
    4               7895            8100
    
     v1 -> v2:
     - rebased after helper's name change
    
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 8137454e2534..630f15977f09 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -698,8 +698,7 @@ void mlx4_en_arm_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
 
 void mlx4_en_tx_irq(struct mlx4_cq *mcq);
 u16 mlx4_en_select_queue(struct net_device *dev, struct sk_buff *skb,
-			 struct net_device *sb_dev,
-			 select_queue_fallback_t fallback);
+			 struct net_device *sb_dev);
 netdev_tx_t mlx4_en_xmit(struct sk_buff *skb, struct net_device *dev);
 netdev_tx_t mlx4_en_xmit_frame(struct mlx4_en_rx_ring *rx_ring,
 			       struct mlx4_en_rx_alloc *frame,

commit 24be19e47779d604d1492c114459dca9a92acf78
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Sun Dec 2 14:34:36 2018 +0200

    net/mlx4_en: Change min MTU size to ETH_MIN_MTU
    
    NIC driver minimal MTU size shall be set to ETH_MIN_MTU, as defined in
    the RFC791 and in the network stack. Remove old mlx4_en only define for
    it, which was set to wrong value.
    
    Fixes: b80f71f5816f ("ethernet/mellanox: use core min/max MTU checking")
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 485d856546c6..8137454e2534 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -161,7 +161,6 @@
 #define MLX4_SELFTEST_LB_MIN_MTU (MLX4_LOOPBACK_TEST_PAYLOAD + NET_IP_ALIGN + \
 				  ETH_HLEN + PREAMBLE_LEN)
 
-#define MLX4_EN_MIN_MTU		46
 /* VLAN_HLEN is added twice,to support skb vlan tagged with multiple
  * headers. (For example: ETH_P_8021Q and ETH_P_8021AD).
  */

commit 27055454b43009b6775a7ce70907bb298f4fab1e
Author: Alaa Hleihel <alaa@mellanox.com>
Date:   Tue Oct 9 12:06:52 2018 +0300

    net/mlx4_en: Use minimal rx and tx ring sizes on kdump kernel
    
    When memory is limited (on kdump kernel), reduce size of rx and tx rings.
    Also reduce the number of rx rings.
    
    Signed-off-by: Alaa Hleihel <alaa@mellanox.com>
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index c3228b89df46..485d856546c6 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -72,7 +72,7 @@
 #define MLX4_EN_PAGE_SIZE	(1 << MLX4_EN_PAGE_SHIFT)
 #define DEF_RX_RINGS		16
 #define MAX_RX_RINGS		128
-#define MIN_RX_RINGS		4
+#define MIN_RX_RINGS		1
 #define LOG_TXBB_SIZE		6
 #define TXBB_SIZE		BIT(LOG_TXBB_SIZE)
 #define HEADROOM		(2048 / TXBB_SIZE + 1)

commit 4f49dec9075aa0277b8c9c657ec31e6361f88724
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Mon Jul 9 12:19:59 2018 -0400

    net: allow ndo_select_queue to pass netdev
    
    This patch makes it so that instead of passing a void pointer as the
    accel_priv we instead pass a net_device pointer as sb_dev. Making this
    change allows us to pass the subordinate device through to the fallback
    function eventually so that we can keep the actual code in the
    ndo_select_queue call as focused on possible on the exception cases.
    
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index ace6545f82e6..c3228b89df46 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -699,7 +699,8 @@ void mlx4_en_arm_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
 
 void mlx4_en_tx_irq(struct mlx4_cq *mcq);
 u16 mlx4_en_select_queue(struct net_device *dev, struct sk_buff *skb,
-			 void *accel_priv, select_queue_fallback_t fallback);
+			 struct net_device *sb_dev,
+			 select_queue_fallback_t fallback);
 netdev_tx_t mlx4_en_xmit(struct sk_buff *skb, struct net_device *dev);
 netdev_tx_t mlx4_en_xmit_frame(struct mlx4_en_rx_ring *rx_ring,
 			       struct mlx4_en_rx_alloc *frame,

commit 6ad4e91c6d796b38a7f0e724db1de28eeb122bad
Author: Moshe Shemesh <moshe@mellanox.com>
Date:   Wed May 9 18:35:13 2018 +0300

    net/mlx4_en: Verify coalescing parameters are in range
    
    Add check of coalescing parameters received through ethtool are within
    range of values supported by the HW.
    Driver gets the coalescing rx/tx-usecs and rx/tx-frames as set by the
    users through ethtool. The ethtool support up to 32 bit value for each.
    However, mlx4 modify cq limits the coalescing time parameter and
    coalescing frames parameters to 16 bits.
    Return out of range error if user tries to set these parameters to
    higher values.
    Change type of sample-interval and adaptive_rx_coal parameters in mlx4
    driver to u32 as the ethtool holds them as u32 and these parameters are
    not limited due to mlx4 HW.
    
    Fixes: c27a02cd94d6 ('mlx4_en: Add driver for Mellanox ConnectX 10GbE NIC')
    Signed-off-by: Moshe Shemesh <moshe@mellanox.com>
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index f7c81133594f..ace6545f82e6 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -132,6 +132,9 @@
 #define MLX4_EN_TX_COAL_PKTS	16
 #define MLX4_EN_TX_COAL_TIME	0x10
 
+#define MLX4_EN_MAX_COAL_PKTS	U16_MAX
+#define MLX4_EN_MAX_COAL_TIME	U16_MAX
+
 #define MLX4_EN_RX_RATE_LOW		400000
 #define MLX4_EN_RX_COAL_TIME_LOW	0
 #define MLX4_EN_RX_RATE_HIGH		450000
@@ -552,8 +555,8 @@ struct mlx4_en_priv {
 	u16 rx_usecs_low;
 	u32 pkt_rate_high;
 	u16 rx_usecs_high;
-	u16 sample_interval;
-	u16 adaptive_rx_coal;
+	u32 sample_interval;
+	u32 adaptive_rx_coal;
 	u32 msg_enable;
 	u32 loopback_ok;
 	u32 validate_loopback;

commit f26d0d2543cb34680393d9993eea4150a153c3fa
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Tue Feb 27 16:17:19 2018 +0200

    net/mlx4_en: Add physical RX/TX bytes/packets counters
    
    Add physical RX/TX packets/bytes counters into ethtool output to monitor
    all traffic that was received and transmitted on the port. These
    counters are available only for none Virtual Function.
    
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index f470ae37d937..f7c81133594f 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -608,6 +608,7 @@ struct mlx4_en_priv {
 	struct mlx4_en_flow_stats_tx tx_flowstats;
 	struct mlx4_en_port_stats port_stats;
 	struct mlx4_en_xdp_stats xdp_stats;
+	struct mlx4_en_phy_stats phy_stats;
 	struct mlx4_en_stats_bitmap stats_bitmap;
 	struct list_head mc_list;
 	struct list_head curr_list;

commit ae75415de1110613aa437ddf1196af6d33f1c90a
Author: Jesper Dangaard Brouer <brouer@redhat.com>
Date:   Wed Jan 3 11:25:39 2018 +0100

    mlx4: setup xdp_rxq_info
    
    Driver hook points for xdp_rxq_info:
     * reg  : mlx4_en_create_rx_ring
     * unreg: mlx4_en_destroy_rx_ring
    
    Tested on actual hardware.
    
    Cc: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 7db3d0d9bfce..f470ae37d937 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -46,6 +46,7 @@
 #endif
 #include <linux/cpu_rmap.h>
 #include <linux/ptp_clock_kernel.h>
+#include <net/xdp.h>
 
 #include <linux/mlx4/device.h>
 #include <linux/mlx4/qp.h>
@@ -356,6 +357,7 @@ struct mlx4_en_rx_ring {
 	unsigned long dropped;
 	int hwtstamp_rx_filter;
 	cpumask_var_t affinity_mask;
+	struct xdp_rxq_info xdp_rxq;
 };
 
 struct mlx4_en_cq {
@@ -720,7 +722,7 @@ void mlx4_en_set_num_rx_rings(struct mlx4_en_dev *mdev);
 void mlx4_en_recover_from_oom(struct mlx4_en_priv *priv);
 int mlx4_en_create_rx_ring(struct mlx4_en_priv *priv,
 			   struct mlx4_en_rx_ring **pring,
-			   u32 size, u16 stride, int node);
+			   u32 size, u16 stride, int node, int queue_index);
 void mlx4_en_destroy_rx_ring(struct mlx4_en_priv *priv,
 			     struct mlx4_en_rx_ring **pring,
 			     u32 size, u16 stride);

commit a42b63c1ac1986f17f71bc91a6b0aaa14d4dae71
Author: Moni Shoua <monis@mellanox.com>
Date:   Thu Dec 28 16:26:11 2017 +0200

    net/mlx4_en: Change default QoS settings
    
    Change the default mapping between TC and TCG as follows:
    
    Prio     |             TC/TCG
             |      from             to
             |    (set by FW)      (set by SW)
    ---------+-----------------------------------
    0        |      0/0              0/7
    1        |      1/0              0/6
    2        |      2/0              0/5
    3        |      3/0              0/4
    4        |      4/0              0/3
    5        |      5/0              0/2
    6        |      6/0              0/1
    7        |      7/0              0/0
    
    These new settings cause that a pause frame for any prio stops
    traffic for all prios.
    
    Fixes: 564c274c3df0 ("net/mlx4_en: DCB QoS support")
    Signed-off-by: Moni Shoua <monis@mellanox.com>
    Signed-off-by: Maor Gottlieb <maorg@mellanox.com>
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 2b72677eccd4..7db3d0d9bfce 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -479,6 +479,7 @@ struct mlx4_en_frag_info {
 #define MLX4_EN_BW_MIN 1
 #define MLX4_EN_BW_MAX 100 /* Utilize 100% of the line */
 
+#define MLX4_EN_TC_VENDOR 0
 #define MLX4_EN_TC_ETS 7
 
 enum dcb_pfc_type {

commit 78034f5fdd622520eb843301cf35ce6c626543a7
Author: Eugenia Emantayev <eugenia@mellanox.com>
Date:   Wed Dec 13 18:12:09 2017 +0200

    net/mlx4_en: Fix selftest for small MTUs
    
    Set the minimal MTU threshold for running loopback selftest.
    MTU should be big enough to include packet payload, NET_IP_ALIGN,
    Ethernet headers and preamble length.
    
    Fixes: e7c1c2c46201 ("mlx4_en: Added self diagnostics test implementation")
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.com>
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 1856e279a7e0..2b72677eccd4 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -153,6 +153,9 @@
 #define SMALL_PACKET_SIZE      (256 - NET_IP_ALIGN)
 #define HEADER_COPY_SIZE       (128 - NET_IP_ALIGN)
 #define MLX4_LOOPBACK_TEST_PAYLOAD (HEADER_COPY_SIZE - ETH_HLEN)
+#define PREAMBLE_LEN           8
+#define MLX4_SELFTEST_LB_MIN_MTU (MLX4_LOOPBACK_TEST_PAYLOAD + NET_IP_ALIGN + \
+				  ETH_HLEN + PREAMBLE_LEN)
 
 #define MLX4_EN_MIN_MTU		46
 /* VLAN_HLEN is added twice,to support skb vlan tagged with multiple

commit f025fd6061e120713d6c11c92983804c6805d6cb
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Wed Oct 11 13:17:27 2017 +0300

    net/mlx4_en: XDP_TX, assign constant values of TX descs on ring creaion
    
    In XDP_TX, some fields in tx_info and tx_desc are constants across
    all entries of the different XDP_TX rings.
    Assign values to these fields on ring creation time, rather than in
    data-path.
    
    Patchset performance tests:
    Tested on ConnectX3Pro, Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    Single queue no-RSS optimization ON.
    
    XDP_TX packet rate:
    ------------------------------
    Before    | After     | Gain |
    13.7 Mpps | 14.0 Mpps | %2.2 |
    ------------------------------
    
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 8cad9b4f1936..1856e279a7e0 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -705,6 +705,8 @@ int mlx4_en_create_tx_ring(struct mlx4_en_priv *priv,
 			   int node, int queue_index);
 void mlx4_en_destroy_tx_ring(struct mlx4_en_priv *priv,
 			     struct mlx4_en_tx_ring **pring);
+void mlx4_en_init_tx_xdp_ring_descs(struct mlx4_en_priv *priv,
+				    struct mlx4_en_tx_ring *ring);
 int mlx4_en_activate_tx_ring(struct mlx4_en_priv *priv,
 			     struct mlx4_en_tx_ring *ring,
 			     int cq, int user_prio);

commit 5dad61b83840d7eceaba5bf316419be11bbb993a
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Wed Oct 11 13:17:25 2017 +0300

    net/mlx4_en: Replace netdev parameter with priv in XDP xmit function
    
    The struct net_device parameter was passed only to extract
    struct mlx4_en_priv out of it.
    Here we pass the priv parameter directly.
    
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 245e9ea09ab2..8cad9b4f1936 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -693,7 +693,7 @@ u16 mlx4_en_select_queue(struct net_device *dev, struct sk_buff *skb,
 netdev_tx_t mlx4_en_xmit(struct sk_buff *skb, struct net_device *dev);
 netdev_tx_t mlx4_en_xmit_frame(struct mlx4_en_rx_ring *rx_ring,
 			       struct mlx4_en_rx_alloc *frame,
-			       struct net_device *dev, unsigned int length,
+			       struct mlx4_en_priv *priv, unsigned int length,
 			       int tx_ind, bool *doorbell_pending);
 void mlx4_en_xmit_doorbell(struct mlx4_en_tx_ring *ring);
 bool mlx4_en_rx_recycle(struct mlx4_en_rx_ring *ring,

commit 7e1dc5e926d57a5bc4ac97d6e061e2fe29c266c0
Author: Inbar Karmy <inbark@mellanox.com>
Date:   Tue Oct 10 12:28:33 2017 +0300

    net/mlx4_en: Limit the number of TX rings
    
    Limit the number of TX rings per UP by the number of cores
    in the system.
    
    Signed-off-by: Inbar Karmy <inbark@mellanox.com>
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index fdb3ad0cbe54..245e9ea09ab2 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -399,7 +399,7 @@ struct mlx4_en_profile {
 	u32 active_ports;
 	u32 small_pkt_int;
 	u8 no_reset;
-	u8 num_tx_rings_p_up;
+	u8 max_num_tx_rings_p_up;
 	struct mlx4_en_port_profile prof[MLX4_MAX_PORTS + 1];
 };
 

commit f3eebe88195478b1bfbe8510d58a8c226ea759a8
Author: Zhu Yanjun <yanjun.zhu@oracle.com>
Date:   Sun Jul 23 23:02:53 2017 -0400

    mlx4_en: remove unnecessary returned value
    
    The function mlx4_en_arm_cq always returns zero. So change the
    return type of the function mlx4_en_arm_cq to void.
    
    CC: Joe Jin <joe.jin@oracle.com>
    CC: Junxiao Bi <junxiao.bi@oracle.com>
    Signed-off-by: Zhu Yanjun <yanjun.zhu@oracle.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index d350b2158104..fdb3ad0cbe54 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -685,7 +685,7 @@ int mlx4_en_activate_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq,
 			int cq_idx);
 void mlx4_en_deactivate_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
 int mlx4_en_set_cq_moder(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
-int mlx4_en_arm_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
+void mlx4_en_arm_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
 
 void mlx4_en_tx_irq(struct mlx4_cq *mcq);
 u16 mlx4_en_select_queue(struct net_device *dev, struct sk_buff *skb,

commit ec327f7a4340b635d89ca9667935adefa3905be1
Author: Inbar Karmy <inbark@mellanox.com>
Date:   Thu Jun 29 14:07:57 2017 +0300

    net/mlx4_en: Do not allocate redundant TX queues when TC is disabled
    
    Currently the number of TX queues that are allocated doesn't depend
    on the number of TCs, the module always loads with max num of UP
    per channel.
    In order to prevent the allocation of unnecessary memory, the
    module will load with minimum number of UPs per channel, and the
    user will be able to control the number of TX queues per channel
    by changing the number of TC to 8 using the tc command.
    The variable num_up will hold the information about the current
    number of UPs.
    Due to the change, needed to remove the lines that set the value of
    UP to be different than zero in the func "mlx4_en_select_queue",
    since now the num of TX queues that are allocated is only one per channel
    in default.
    In order not to force the UP to be zero in case of only one TC, added
    a condition before forcing it in the func "mlx4_en_fill_qp_context".
    
    Tested:
    After the module is loaded with minimum number of UP per channel, to
    increase num of TCs to 8, use:
    tc qdisc add dev ens8 root mqprio num_tc 8
    In order to decrease the number of TCs to minimum number of UP per channel,
    use:
    tc qdisc del dev ens8 root
    
    Signed-off-by: Inbar Karmy <inbark@mellanox.com>
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Cc: Tarick Bedeir <tarick@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 89885281d489..d350b2158104 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -115,6 +115,7 @@
 #define MLX4_EN_SMALL_PKT_SIZE		64
 #define MLX4_EN_MIN_TX_RING_P_UP	1
 #define MLX4_EN_MAX_TX_RING_P_UP	32
+#define MLX4_EN_NUM_UP_LOW		1
 #define MLX4_EN_NUM_UP_HIGH		8
 #define MLX4_EN_DEF_RX_RING_SIZE  	1024
 #define MLX4_EN_DEF_TX_RING_SIZE	MLX4_EN_DEF_RX_RING_SIZE
@@ -762,6 +763,7 @@ extern const struct dcbnl_rtnl_ops mlx4_en_dcbnl_pfc_ops;
 #endif
 
 int mlx4_en_setup_tc(struct net_device *dev, u8 up);
+int mlx4_en_alloc_tx_queue_per_tc(struct net_device *dev, u8 tc);
 
 #ifdef CONFIG_RFS_ACCEL
 void mlx4_en_cleanup_filters(struct mlx4_en_priv *priv);

commit f21ad61424f7c623eddbcf54425a86afb68ca55f
Author: Inbar Karmy <inbark@mellanox.com>
Date:   Thu Jun 29 14:07:56 2017 +0300

    net/mlx4_en: Add dynamic variable to hold the number of user priorities (UP)
    
    Until this patch, the number of UPs was hard coded for eight.
    Replace this with a variable in struct "mlx4_en_port_profile".
    Currently, the variable will hold the maximum number of UP,
    as before.
    The patch creates an infrastructure to add an option for dynamic
    change of the actual number of TCs.
    
    Signed-off-by: Inbar Karmy <inbark@mellanox.com>
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Cc: Tarick Bedeir <tarick@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 963b77d51b48..89885281d489 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -115,11 +115,11 @@
 #define MLX4_EN_SMALL_PKT_SIZE		64
 #define MLX4_EN_MIN_TX_RING_P_UP	1
 #define MLX4_EN_MAX_TX_RING_P_UP	32
-#define MLX4_EN_NUM_UP			8
+#define MLX4_EN_NUM_UP_HIGH		8
 #define MLX4_EN_DEF_RX_RING_SIZE  	1024
 #define MLX4_EN_DEF_TX_RING_SIZE	MLX4_EN_DEF_RX_RING_SIZE
 #define MAX_TX_RINGS			(MLX4_EN_MAX_TX_RING_P_UP * \
-					 MLX4_EN_NUM_UP)
+					 MLX4_EN_NUM_UP_HIGH)
 
 #define MLX4_EN_DEFAULT_TX_WORK		256
 
@@ -386,6 +386,7 @@ struct mlx4_en_port_profile {
 	u8 rx_ppp;
 	u8 tx_pause;
 	u8 tx_ppp;
+	u8 num_up;
 	int rss_rings;
 	int inline_thold;
 	struct hwtstamp_config hwtstamp_config;
@@ -485,7 +486,7 @@ enum dcb_pfc_type {
 
 struct mlx4_en_cee_config {
 	bool	pfc_state;
-	enum	dcb_pfc_type dcb_pfc[MLX4_EN_NUM_UP];
+	enum	dcb_pfc_type dcb_pfc[MLX4_EN_NUM_UP_HIGH];
 };
 #endif
 

commit 9573e0d39ff8d7d1e0bcc10e23d18b9cbc4ca14e
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Thu Jun 15 14:35:39 2017 +0300

    net/mlx4_en: Replace TXBB_SIZE multiplications with shift operations
    
    Define LOG_TXBB_SIZE, log of TXBB_SIZE, and use it with a shift
    operation instead of a multiplication with TXBB_SIZE.
    Operations are equivalent as TXBB_SIZE is a power of two.
    
    Performance tests:
    Tested on ConnectX3Pro, Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    
    Gain is too small to be measurable, no degradation sensed.
    Results are similar for IPv4 and IPv6.
    
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Reviewed-by: Saeed Mahameed <saeedm@mellanox.com>
    Cc: kernel-team@fb.com
    Cc: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 7f61b5829709..963b77d51b48 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -72,7 +72,8 @@
 #define DEF_RX_RINGS		16
 #define MAX_RX_RINGS		128
 #define MIN_RX_RINGS		4
-#define TXBB_SIZE		64
+#define LOG_TXBB_SIZE		6
+#define TXBB_SIZE		BIT(LOG_TXBB_SIZE)
 #define HEADROOM		(2048 / TXBB_SIZE + 1)
 #define STAMP_STRIDE		64
 #define STAMP_DWORDS		(STAMP_STRIDE / 4)

commit 77788b5bf6becc5ada0da9f99e90c20ea6e77a58
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Thu Jun 15 14:35:38 2017 +0300

    net/mlx4_en: Increase default TX ring size
    
    Increase the default TX ring size (from 512 to 1024) to match
    the RX ring size.
    This gives the XDP TX ring a better chance to keep up with the
    rate of its RX ring in case of a high load of XDP_TX actions.
    
    Tested:
    Ethtool counter rx_xdp_tx_full used to increase, after applying this
    patch it stopped.
    
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Reviewed-by: Saeed Mahameed <saeedm@mellanox.com>
    Cc: kernel-team@fb.com
    Cc: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index bde3bc869b70..7f61b5829709 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -115,8 +115,8 @@
 #define MLX4_EN_MIN_TX_RING_P_UP	1
 #define MLX4_EN_MAX_TX_RING_P_UP	32
 #define MLX4_EN_NUM_UP			8
-#define MLX4_EN_DEF_TX_RING_SIZE	512
 #define MLX4_EN_DEF_RX_RING_SIZE  	1024
+#define MLX4_EN_DEF_TX_RING_SIZE	MLX4_EN_DEF_RX_RING_SIZE
 #define MAX_TX_RINGS			(MLX4_EN_MAX_TX_RING_P_UP * \
 					 MLX4_EN_NUM_UP)
 

commit 6c78511b0503c9b53fd0f5ccc8b28d5e94a3dfcb
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Thu Jun 15 14:35:37 2017 +0300

    net/mlx4_en: Poll XDP TX completion queue in RX NAPI
    
    Instead of having their own NAPIs, XDP TX completion queues get
    polled within the corresponding RX NAPI.
    This prevents any possible race on TX ring prod/cons indices,
    between the context that issues the transmits (RX NAPI) and the
    context that handles the completions (was previously done in
    a separate NAPI).
    
    This also improves performance, as it decreases the number
    of NAPIs running on a CPU, saving the overhead of syncing
    and switching between the contexts.
    
    Performance tests:
    Tested on ConnectX3Pro, Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    Single queue no-RSS optimization ON.
    
    XDP_TX packet rate:
    -------------------------------------
         | Before    | After     | Gain |
    IPv4 | 12.0 Mpps | 13.8 Mpps |  15% |
    IPv6 | 12.0 Mpps | 13.8 Mpps |  15% |
    -------------------------------------
    
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Reviewed-by: Saeed Mahameed <saeedm@mellanox.com>
    Cc: kernel-team@fb.com
    Cc: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index c52edb717add..bde3bc869b70 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -358,7 +358,10 @@ struct mlx4_en_cq {
 	struct mlx4_hwq_resources wqres;
 	int                     ring;
 	struct net_device      *dev;
-	struct napi_struct	napi;
+	union {
+		struct napi_struct napi;
+		bool               xdp_busy;
+	};
 	int size;
 	int buf_size;
 	int vector;
@@ -720,6 +723,8 @@ int mlx4_en_process_rx_cq(struct net_device *dev,
 			  int budget);
 int mlx4_en_poll_rx_cq(struct napi_struct *napi, int budget);
 int mlx4_en_poll_tx_cq(struct napi_struct *napi, int budget);
+bool mlx4_en_process_tx_cq(struct net_device *dev,
+			   struct mlx4_en_cq *cq, int napi_budget);
 u32 mlx4_en_free_tx_desc(struct mlx4_en_priv *priv,
 			 struct mlx4_en_tx_ring *ring,
 			 int index, u64 timestamp,

commit 36ea7964982f54370e051386b74df914c53e2219
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Thu Jun 15 14:35:36 2017 +0300

    net/mlx4_en: Improve XDP xmit function
    
    Several performance improvements in XDP TX datapath,
    including:
    - Ring a single doorbell for XDP TX ring per NAPI budget,
      instead of doing it per a lower threshold (was 8).
      This includes removing the flow of immediate doorbell ringing
      in case of a full TX ring.
    - Compiler branch predictor hints.
    - Calculate values in compile time rather than in runtime.
    
    Performance tests:
    Tested on ConnectX3Pro, Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    Single queue no-RSS optimization ON.
    
    XDP_TX packet rate:
    -------------------------------------
         | Before    | After     | Gain |
    IPv4 | 10.3 Mpps | 12.0 Mpps |  17% |
    IPv6 | 10.3 Mpps | 12.0 Mpps |  17% |
    -------------------------------------
    
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Reviewed-by: Saeed Mahameed <saeedm@mellanox.com>
    Cc: kernel-team@fb.com
    Cc: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 41f4f8f9f300..c52edb717add 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -121,7 +121,6 @@
 					 MLX4_EN_NUM_UP)
 
 #define MLX4_EN_DEFAULT_TX_WORK		256
-#define MLX4_EN_DOORBELL_BUDGET		8
 
 /* Target number of packets to coalesce with interrupt moderation */
 #define MLX4_EN_RX_COAL_TARGET	44
@@ -689,7 +688,7 @@ netdev_tx_t mlx4_en_xmit(struct sk_buff *skb, struct net_device *dev);
 netdev_tx_t mlx4_en_xmit_frame(struct mlx4_en_rx_ring *rx_ring,
 			       struct mlx4_en_rx_alloc *frame,
 			       struct net_device *dev, unsigned int length,
-			       int tx_ind, int *doorbell_pending);
+			       int tx_ind, bool *doorbell_pending);
 void mlx4_en_xmit_doorbell(struct mlx4_en_tx_ring *ring);
 bool mlx4_en_rx_recycle(struct mlx4_en_rx_ring *ring,
 			struct mlx4_en_rx_alloc *frame);

commit 4931c6ef04b4eb6f726def76f845c10d1bb7057d
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Thu Jun 15 14:35:32 2017 +0300

    net/mlx4_en: Optimized single ring steering
    
    Avoid touching RX QP RSS context when loading with only
    one RX ring, to allow optimized A0 RX steering.
    
    Enable by:
    - loading mlx4_core with module param: log_num_mgm_entry_size = -6.
    - then: ethtool -L <interface> rx 1
    
    Performance tests:
    Tested on ConnectX3Pro, Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    
    XDP_DROP packet rate:
    -------------------------------------
         | Before    | After     | Gain |
    IPv4 | 20.5 Mpps | 28.1 Mpps |  37% |
    IPv6 | 18.4 Mpps | 28.1 Mpps |  53% |
    -------------------------------------
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Cc: kernel-team@fb.com
    Cc: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 08b2906a98af..41f4f8f9f300 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -431,7 +431,7 @@ struct mlx4_en_rss_map {
 	int base_qpn;
 	struct mlx4_qp qps[MAX_RX_RINGS];
 	enum mlx4_qp_state state[MAX_RX_RINGS];
-	struct mlx4_qp indir_qp;
+	struct mlx4_qp *indir_qp;
 	enum mlx4_qp_state indir_state;
 };
 

commit cf97050d547281edc5b813b501d5888c60f23bb2
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Thu Jun 15 14:35:31 2017 +0300

    net/mlx4_en: Remove unused argument in TX datapath function
    
    Remove owner argument, as it is obsolete and unused.
    This also saves the overhead of calculating its value in data-path.
    
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Reviewed-by: Saeed Mahameed <saeedm@mellanox.com>
    Cc: kernel-team@fb.com
    Cc: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 8c4f63946b14..08b2906a98af 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -276,7 +276,7 @@ struct mlx4_en_tx_ring {
 	struct netdev_queue	*tx_queue;
 	u32			(*free_tx_desc)(struct mlx4_en_priv *priv,
 						struct mlx4_en_tx_ring *ring,
-						int index, u8 owner,
+						int index,
 						u64 timestamp, int napi_mode);
 	struct mlx4_en_rx_ring	*recycle_ring;
 
@@ -723,11 +723,11 @@ int mlx4_en_poll_rx_cq(struct napi_struct *napi, int budget);
 int mlx4_en_poll_tx_cq(struct napi_struct *napi, int budget);
 u32 mlx4_en_free_tx_desc(struct mlx4_en_priv *priv,
 			 struct mlx4_en_tx_ring *ring,
-			 int index, u8 owner, u64 timestamp,
+			 int index, u64 timestamp,
 			 int napi_mode);
 u32 mlx4_en_recycle_tx_desc(struct mlx4_en_priv *priv,
 			    struct mlx4_en_tx_ring *ring,
-			    int index, u8 owner, u64 timestamp,
+			    int index, u64 timestamp,
 			    int napi_mode);
 void mlx4_en_fill_qp_context(struct mlx4_en_priv *priv, int size, int stride,
 		int is_tx, int rss, int qpn, int cqn, int user_prio,

commit 808df6a209ab21af158de38031f52dd3e9fb409c
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Wed Jun 7 16:26:14 2017 +0300

    net/mlx4_en: Bump driver version
    
    Remove date and bump version for mlx4_en driver.
    
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 39f401aa3047..8c4f63946b14 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -58,8 +58,7 @@
 #include "mlx4_stats.h"
 
 #define DRV_NAME	"mlx4_en"
-#define DRV_VERSION	"2.2-1"
-#define DRV_RELDATE	"Feb 2014"
+#define DRV_VERSION	"4.0-0"
 
 #define MLX4_EN_MSG_LEVEL	(NETIF_MSG_LINK | NETIF_MSG_IFDOWN)
 

commit 7d7bfc6a3f69d2debe104656fadd8d568fda0e5b
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Mar 8 08:17:14 2017 -0800

    mlx4: add rx_alloc_pages counter in ethtool -S
    
    This new counter tracks number of pages that we allocated for one port.
    
    lpaa24:~# ethtool -S eth0 | egrep 'rx_alloc_pages|rx_packets'
         rx_packets: 306755183
         rx_alloc_pages: 932897
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 5f6080266981..39f401aa3047 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -346,6 +346,7 @@ struct mlx4_en_rx_ring {
 	unsigned long csum_ok;
 	unsigned long csum_none;
 	unsigned long csum_complete;
+	unsigned long rx_alloc_pages;
 	unsigned long xdp_drop;
 	unsigned long xdp_tx;
 	unsigned long xdp_tx_full;

commit 34db548bfb9580f33d9a7faecafe4da61a4428a3
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Mar 8 08:17:13 2017 -0800

    mlx4: add page recycling in receive path
    
    Same technique than some Intel drivers, for arches where PAGE_SIZE = 4096
    
    In most cases, pages are reused because they were consumed
    before we could loop around the RX ring.
    
    This brings back performance, and is even better,
    a single TCP flow reaches 30Gbit on my hosts.
    
    v2: added full memset() in mlx4_en_free_frag(), as Tariq found it was needed
    if we switch to large MTU, as priv->log_rx_info can dynamically be changed.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 6c80117006ed..5f6080266981 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -327,7 +327,6 @@ struct mlx4_en_rx_desc {
 
 struct mlx4_en_rx_ring {
 	struct mlx4_hwq_resources wqres;
-	struct mlx4_en_rx_alloc page_alloc[MLX4_EN_MAX_RX_FRAGS];
 	u32 size ;	/* number of Rx descs*/
 	u32 actual_size;
 	u32 size_mask;

commit b5a54d9a313645ec9607dc557b67d9325c28884c
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Mar 8 08:17:12 2017 -0800

    mlx4: use order-0 pages for RX
    
    Use of order-3 pages is problematic in some cases.
    
    This patch might add three kinds of regression :
    
    1) a CPU performance regression, but we will add later page
    recycling and performance should be back.
    
    2) TCP receiver could grow its receive window slightly slower,
       because skb->len/skb->truesize ratio will decrease.
       This is mostly ok, we prefer being conservative to not risk OOM,
       and eventually tune TCP better in the future.
       This is consistent with other drivers using 2048 per ethernet frame.
    
    3) Because we allocate one page per RX slot, we consume more
       memory for the ring buffers. XDP already had this constraint anyway.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 608396dc6d95..6c80117006ed 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -102,9 +102,6 @@
 /* Use the maximum between 16384 and a single page */
 #define MLX4_EN_ALLOC_SIZE	PAGE_ALIGN(16384)
 
-#define MLX4_EN_ALLOC_PREFER_ORDER min_t(int, get_order(32768),		\
-					 PAGE_ALLOC_COSTLY_ORDER)
-
 #define MLX4_EN_MAX_RX_FRAGS	4
 
 /* Maximum ring sizes */
@@ -256,7 +253,6 @@ struct mlx4_en_rx_alloc {
 	struct page	*page;
 	dma_addr_t	dma;
 	u32		page_offset;
-	u32		page_size;
 };
 
 #define MLX4_EN_CACHE_SIZE (2 * NAPI_POLL_WEIGHT)
@@ -579,7 +575,6 @@ struct mlx4_en_priv {
 	u8 num_frags;
 	u8 log_rx_info;
 	u8 dma_dir;
-	u8 rx_page_order;
 	u16 rx_headroom;
 
 	struct mlx4_en_tx_ring **tx_ring[MLX4_EN_NUM_TX_TYPES];

commit 60c7f5ae5416a8491216bcccf6b3b3d842d69fa4
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Mar 8 08:17:11 2017 -0800

    mlx4: removal of frag_sizes[]
    
    We will soon use order-0 pages, and frag truesize will more precisely
    match real sizes.
    
    In the new model, we prefer to use <= 2048 bytes fragments, so that
    we can use page-recycle technique on PAGE_SIZE=4096 arches.
    
    We will still pack as much frames as possible on arches with big
    pages, like PowerPC.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index c98940c6acd0..608396dc6d95 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -105,14 +105,6 @@
 #define MLX4_EN_ALLOC_PREFER_ORDER min_t(int, get_order(32768),		\
 					 PAGE_ALLOC_COSTLY_ORDER)
 
-/* Receive fragment sizes; we use at most 3 fragments (for 9600 byte MTU
- * and 4K allocations) */
-enum {
-	FRAG_SZ0 = 1536 - NET_IP_ALIGN,
-	FRAG_SZ1 = 4096,
-	FRAG_SZ2 = 4096,
-	FRAG_SZ3 = MLX4_EN_ALLOC_SIZE
-};
 #define MLX4_EN_MAX_RX_FRAGS	4
 
 /* Maximum ring sizes */

commit acd7628de05c73118aab7ae4847a5b5b2c6999c9
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Mar 8 08:17:10 2017 -0800

    mlx4: reduce rx ring page_cache size
    
    We only need to store the page and dma address.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index fc7b4da5d8c3..c98940c6acd0 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -268,9 +268,13 @@ struct mlx4_en_rx_alloc {
 };
 
 #define MLX4_EN_CACHE_SIZE (2 * NAPI_POLL_WEIGHT)
+
 struct mlx4_en_page_cache {
 	u32 index;
-	struct mlx4_en_rx_alloc buf[MLX4_EN_CACHE_SIZE];
+	struct {
+		struct page	*page;
+		dma_addr_t	dma;
+	} buf[MLX4_EN_CACHE_SIZE];
 };
 
 struct mlx4_en_priv;

commit d85f6c14e967b0bddfa9712daa17d79e297d18b8
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Mar 8 08:17:09 2017 -0800

    mlx4: rx_headroom is a per port attribute
    
    No need to duplicate it per RX queue / frags.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 849aa8af4dd7..fc7b4da5d8c3 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -472,7 +472,6 @@ struct mlx4_en_mc_list {
 
 struct mlx4_en_frag_info {
 	u16 frag_size;
-	u16 rx_headroom;
 	u32 frag_stride;
 };
 
@@ -585,6 +584,7 @@ struct mlx4_en_priv {
 	u8 log_rx_info;
 	u8 dma_dir;
 	u8 rx_page_order;
+	u16 rx_headroom;
 
 	struct mlx4_en_tx_ring **tx_ring[MLX4_EN_NUM_TX_TYPES];
 	struct mlx4_en_rx_ring *rx_ring[MAX_RX_RINGS];

commit aaca121dd6cfedc9afb9d0ee23ded9d84e217e20
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Mar 8 08:17:08 2017 -0800

    mlx4: get rid of frag_prefix_size
    
    Using per frag storage for frag_prefix_size is really silly.
    
    mlx4_en_complete_rx_desc() has all needed info already.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 9d2c53ddb15c..849aa8af4dd7 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -472,9 +472,8 @@ struct mlx4_en_mc_list {
 
 struct mlx4_en_frag_info {
 	u16 frag_size;
-	u16 frag_prefix_size;
-	u32 frag_stride;
 	u16 rx_headroom;
+	u32 frag_stride;
 };
 
 #ifdef CONFIG_MLX4_EN_DCB

commit 159ddfd2ca30a2361324111ef64fdedf43e7dc32
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Mar 8 08:17:07 2017 -0800

    mlx4: remove order field from mlx4_en_frag_info
    
    This is really a port attribute, no need to duplicate it per
    RX queue and per frag.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index a4c7d94d52c6..9d2c53ddb15c 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -474,7 +474,6 @@ struct mlx4_en_frag_info {
 	u16 frag_size;
 	u16 frag_prefix_size;
 	u32 frag_stride;
-	u16 order;
 	u16 rx_headroom;
 };
 
@@ -586,6 +585,7 @@ struct mlx4_en_priv {
 	u8 num_frags;
 	u8 log_rx_info;
 	u8 dma_dir;
+	u8 rx_page_order;
 
 	struct mlx4_en_tx_ring **tx_ring[MLX4_EN_NUM_TX_TYPES];
 	struct mlx4_en_rx_ring *rx_ring[MAX_RX_RINGS];

commit 69ba943151b2e40e201700cf5b3a94e433c6fd83
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Mar 8 08:17:06 2017 -0800

    mlx4: dma_dir is a mlx4_en_priv attribute
    
    No need to duplicate it for all queues and frags.
    
    num_frags & log_rx_info become u8 to save space.
    u8 accesses are a bit faster than u16 anyway.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 3629ce11a68b..a4c7d94d52c6 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -474,7 +474,6 @@ struct mlx4_en_frag_info {
 	u16 frag_size;
 	u16 frag_prefix_size;
 	u32 frag_stride;
-	enum dma_data_direction dma_dir;
 	u16 order;
 	u16 rx_headroom;
 };
@@ -584,8 +583,9 @@ struct mlx4_en_priv {
 	u32 rx_ring_num;
 	u32 rx_skb_size;
 	struct mlx4_en_frag_info frag_info[MLX4_EN_MAX_RX_FRAGS];
-	u16 num_frags;
-	u16 log_rx_info;
+	u8 num_frags;
+	u8 log_rx_info;
+	u8 dma_dir;
 
 	struct mlx4_en_tx_ring **tx_ring[MLX4_EN_NUM_TX_TYPES];
 	struct mlx4_en_rx_ring *rx_ring[MAX_RX_RINGS];

commit 47d3a07528ecbbccf53bc4390d70b4e3d1c04fcf
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Feb 23 15:22:43 2017 -0800

    net/mlx4_en: fix overflow in mlx4_en_init_timestamp()
    
    The cited commit makes a great job of finding optimal shift/multiplier
    values assuming a 10 seconds wrap around, but forgot to change the
    overflow_period computation.
    
    It overflows in cyclecounter_cyc2ns(), and the final result is 804 ms,
    which is silly.
    
    Lets simply use 5 seconds, no need to recompute this, given how it is
    supposed to work.
    
    Later, we will use a timer instead of a work queue, since the new RX
    allocation schem will no longer need mlx4_en_recover_from_oom() and the
    service_task firing every 250 ms.
    
    Fixes: 31c128b66e5b ("net/mlx4_en: Choose time-stamping shift value according to HW frequency")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Tariq Toukan <tariqt@mellanox.com>
    Cc: Eugenia Emantayev <eugenia@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 4941b692e947..3629ce11a68b 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -430,7 +430,6 @@ struct mlx4_en_dev {
 	seqlock_t		clock_lock;
 	struct timecounter	clock;
 	unsigned long		last_overflow_check;
-	unsigned long		overflow_period;
 	struct ptp_clock	*ptp_clock;
 	struct ptp_clock_info	ptp_clock_info;
 	struct notifier_block	nb;

commit 3608b13ccc51d06e499dfe12b27f134de1286e28
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Feb 18 10:34:18 2017 -0800

    mlx4: reduce OOM risk on arches with large pages
    
    Since mlx4 NIC are used on PowerPC with 64K pages, we need to adapt
    MLX4_EN_ALLOC_PREFER_ORDER definition.
    
    Otherwise, a fragment sitting in an out of order TCP queue can hold
    0.5 Mbytes and it is a serious OOM risk.
    
    Fixes: 51151a16a60f ("mlx4: allow order-0 memory allocations in RX path")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index d8ca6d1794ef..4941b692e947 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -102,7 +102,8 @@
 /* Use the maximum between 16384 and a single page */
 #define MLX4_EN_ALLOC_SIZE	PAGE_ALIGN(16384)
 
-#define MLX4_EN_ALLOC_PREFER_ORDER	PAGE_ALLOC_COSTLY_ORDER
+#define MLX4_EN_ALLOC_PREFER_ORDER min_t(int, get_order(32768),		\
+					 PAGE_ALLOC_COSTLY_ORDER)
 
 /* Receive fragment sizes; we use at most 3 fragments (for 9600 byte MTU
  * and 4K allocations) */

commit 99f5711e7c15e997c4eb34b378502ef6f3982233
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Feb 9 09:10:04 2017 -0800

    mlx4: do not use rwlock in fast path
    
    Using a reader-writer lock in fast path is silly, when we can
    instead use RCU or a seqlock.
    
    For mlx4 hwstamp clock, a seqlock is the way to go, removing
    two atomic operations and false sharing.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Tariq Toukan <tariqt@mellanox.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index cec59bc264c9..d8ca6d1794ef 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -424,9 +424,9 @@ struct mlx4_en_dev {
 	u32                     priv_pdn;
 	spinlock_t              uar_lock;
 	u8			mac_removed[MLX4_MAX_PORTS + 1];
-	rwlock_t		clock_lock;
 	u32			nominal_c_mult;
 	struct cyclecounter	cycles;
+	seqlock_t		clock_lock;
 	struct timecounter	clock;
 	unsigned long		last_overflow_check;
 	unsigned long		overflow_period;

commit 770f82253dbd7e6892a88018f2f6cd395f48d214
Author: Martin KaFai Lau <kafai@fb.com>
Date:   Tue Jan 31 22:35:33 2017 -0800

    mlx4: xdp_prog becomes inactive after ethtool '-L' or '-G'
    
    After calling mlx4_en_try_alloc_resources (e.g. by changing the
    number of rx-queues with ethtool -L), the existing xdp_prog becomes
    inactive.
    
    The bug is that the xdp_prog ptr has not been carried over from
    the old rx-queues to the new rx-queues
    
    Fixes: 47a38e155037 ("net/mlx4_en: add support for fast rx drop bpf program")
    Cc: Brenden Blanco <bblanco@plumgrid.com>
    Cc: Saeed Mahameed <saeedm@mellanox.com>
    Cc: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: Martin KaFai Lau <kafai@fb.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index ba1c6cd0cc79..cec59bc264c9 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -679,7 +679,8 @@ void mlx4_en_set_stats_bitmap(struct mlx4_dev *dev,
 
 int mlx4_en_try_alloc_resources(struct mlx4_en_priv *priv,
 				struct mlx4_en_priv *tmp,
-				struct mlx4_en_port_profile *prof);
+				struct mlx4_en_port_profile *prof,
+				bool carry_xdp_prog);
 void mlx4_en_safe_replace_resources(struct mlx4_en_priv *priv,
 				    struct mlx4_en_priv *tmp);
 

commit ea3349a03519dcd4f32d949cd80ab995623dc5ac
Author: Martin KaFai Lau <kafai@fb.com>
Date:   Wed Dec 7 15:53:13 2016 -0800

    mlx4: xdp: Reserve headroom for receiving packet when XDP prog is active
    
    Reserve XDP_PACKET_HEADROOM for packet and enable bpf_xdp_adjust_head()
    support.  This patch only affects the code path when XDP is active.
    
    After testing, the tx_dropped counter is incremented if the xdp_prog sends
    more than wire MTU.
    
    Signed-off-by: Martin KaFai Lau <kafai@fb.com>
    Acked-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 20a936428f4a..ba1c6cd0cc79 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -475,7 +475,8 @@ struct mlx4_en_frag_info {
 	u16 frag_prefix_size;
 	u32 frag_stride;
 	enum dma_data_direction dma_dir;
-	int order;
+	u16 order;
+	u16 rx_headroom;
 };
 
 #ifdef CONFIG_MLX4_EN_DCB

commit 40931b85113dad7881d49e8759e5ad41d30a5e6c
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Nov 25 07:46:20 2016 -0800

    mlx4: give precise rx/tx bytes/packets counters
    
    mlx4 stats are chaotic because a deferred work queue is responsible
    to update them every 250 ms.
    
    Even sampling stats every one second with "sar -n DEV 1" gives
    variations like the following :
    
    lpaa23:~# sar -n DEV 1 10 | grep eth0 | cut -c1-65
    07:39:22         eth0 146877.00 3265554.00   9467.15 4828168.50
    07:39:23         eth0 146587.00 3260329.00   9448.15 4820445.98
    07:39:24         eth0 146894.00 3259989.00   9468.55 4819943.26
    07:39:25         eth0 110368.00 2454497.00   7113.95 3629012.17  <<>>
    07:39:26         eth0 146563.00 3257502.00   9447.25 4816266.23
    07:39:27         eth0 145678.00 3258292.00   9389.79 4817414.39
    07:39:28         eth0 145268.00 3253171.00   9363.85 4809852.46
    07:39:29         eth0 146439.00 3262185.00   9438.97 4823172.48
    07:39:30         eth0 146758.00 3264175.00   9459.94 4826124.13
    07:39:31         eth0 146843.00 3256903.00   9465.44 4815381.97
    Average:         eth0 142827.50 3179259.70   9206.30 4700578.16
    
    This patch allows rx/tx bytes/packets counters being folded at the
    time we need stats.
    
    We now can fetch stats every 1 ms if we want to check NIC behavior
    on a small time window. It is also easier to detect anomalies.
    
    lpaa23:~# sar -n DEV 1 10 | grep eth0 | cut -c1-65
    07:42:50         eth0 142915.00 3177696.00   9212.06 4698270.42
    07:42:51         eth0 143741.00 3200232.00   9265.15 4731593.02
    07:42:52         eth0 142781.00 3171600.00   9202.92 4689260.16
    07:42:53         eth0 143835.00 3192932.00   9271.80 4720761.39
    07:42:54         eth0 141922.00 3165174.00   9147.64 4679759.21
    07:42:55         eth0 142993.00 3207038.00   9216.78 4741653.05
    07:42:56         eth0 141394.06 3154335.64   9113.85 4663731.73
    07:42:57         eth0 141850.00 3161202.00   9144.48 4673866.07
    07:42:58         eth0 143439.00 3180736.00   9246.05 4702755.35
    07:42:59         eth0 143501.00 3210992.00   9249.99 4747501.84
    Average:         eth0 142835.66 3182165.93   9206.98 4704874.08
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 574bcbb1b38f..20a936428f4a 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -755,6 +755,7 @@ void mlx4_en_rx_irq(struct mlx4_cq *mcq);
 int mlx4_SET_MCAST_FLTR(struct mlx4_dev *dev, u8 port, u64 mac, u64 clear, u8 mode);
 int mlx4_SET_VLAN_FLTR(struct mlx4_dev *dev, struct mlx4_en_priv *priv);
 
+void mlx4_en_fold_software_stats(struct net_device *dev);
 int mlx4_en_DUMP_ETH_STATS(struct mlx4_en_dev *mdev, u8 port, u8 reset);
 int mlx4_en_QUERY_PORT(struct mlx4_en_dev *mdev, u8 port);
 

commit e3f42f8453902d1520dcdc9909731f274c6d52c1
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Nov 22 15:56:10 2016 -0800

    mlx4: reorganize struct mlx4_en_tx_ring
    
    Goal is to reorganize this critical structure to increase performance.
    
    ndo_start_xmit() should only dirty one cache line, and access as few
    cache lines as possible.
    
    Add sp_ (Slow Path) prefix to fields that are not used in fast path,
    to make clear what is going on.
    
    After this patch pahole reports something much better, as all
    ndo_start_xmit() needed fields are packed into two cache lines instead
    of seven or eight
    
    struct mlx4_en_tx_ring {
            u32                        last_nr_txbb;         /*     0   0x4 */
            u32                        cons;                 /*   0x4   0x4 */
            long unsigned int          wake_queue;           /*   0x8   0x8 */
            struct netdev_queue *      tx_queue;             /*  0x10   0x8 */
            u32                        (*free_tx_desc)(struct mlx4_en_priv *, struct mlx4_en_tx_ring *, int, u8, u64, int); /*  0x18   0x8 */
            struct mlx4_en_rx_ring *   recycle_ring;         /*  0x20   0x8 */
    
            /* XXX 24 bytes hole, try to pack */
    
            /* --- cacheline 1 boundary (64 bytes) --- */
            u32                        prod;                 /*  0x40   0x4 */
            unsigned int               tx_dropped;           /*  0x44   0x4 */
            long unsigned int          bytes;                /*  0x48   0x8 */
            long unsigned int          packets;              /*  0x50   0x8 */
            long unsigned int          tx_csum;              /*  0x58   0x8 */
            long unsigned int          tso_packets;          /*  0x60   0x8 */
            long unsigned int          xmit_more;            /*  0x68   0x8 */
            struct mlx4_bf             bf;                   /*  0x70  0x18 */
            /* --- cacheline 2 boundary (128 bytes) was 8 bytes ago --- */
            __be32                     doorbell_qpn;         /*  0x88   0x4 */
            __be32                     mr_key;               /*  0x8c   0x4 */
            u32                        size;                 /*  0x90   0x4 */
            u32                        size_mask;            /*  0x94   0x4 */
            u32                        full_size;            /*  0x98   0x4 */
            u32                        buf_size;             /*  0x9c   0x4 */
            void *                     buf;                  /*  0xa0   0x8 */
            struct mlx4_en_tx_info *   tx_info;              /*  0xa8   0x8 */
            int                        qpn;                  /*  0xb0   0x4 */
            u8                         queue_index;          /*  0xb4   0x1 */
            bool                       bf_enabled;           /*  0xb5   0x1 */
            bool                       bf_alloced;           /*  0xb6   0x1 */
            u8                         hwtstamp_tx_type;     /*  0xb7   0x1 */
            u8 *                       bounce_buf;           /*  0xb8   0x8 */
            /* --- cacheline 3 boundary (192 bytes) --- */
            long unsigned int          queue_stopped;        /*  0xc0   0x8 */
            struct mlx4_hwq_resources  sp_wqres;             /*  0xc8  0x58 */
            /* --- cacheline 4 boundary (256 bytes) was 32 bytes ago --- */
            struct mlx4_qp             sp_qp;                /* 0x120  0x30 */
            /* --- cacheline 5 boundary (320 bytes) was 16 bytes ago --- */
            struct mlx4_qp_context     sp_context;           /* 0x150  0xf8 */
            /* --- cacheline 9 boundary (576 bytes) was 8 bytes ago --- */
            cpumask_t                  sp_affinity_mask;     /* 0x248  0x20 */
            enum mlx4_qp_state         sp_qp_state;          /* 0x268   0x4 */
            u16                        sp_stride;            /* 0x26c   0x2 */
            u16                        sp_cqn;               /* 0x26e   0x2 */
    
            /* size: 640, cachelines: 10, members: 36 */
            /* sum members: 600, holes: 1, sum holes: 24 */
            /* padding: 16 */
    };
    
    Instead of this silly placement :
    
    struct mlx4_en_tx_ring {
            u32                        last_nr_txbb;         /*     0   0x4 */
            u32                        cons;                 /*   0x4   0x4 */
            long unsigned int          wake_queue;           /*   0x8   0x8 */
    
            /* XXX 48 bytes hole, try to pack */
    
            /* --- cacheline 1 boundary (64 bytes) --- */
            u32                        prod;                 /*  0x40   0x4 */
    
            /* XXX 4 bytes hole, try to pack */
    
            long unsigned int          bytes;                /*  0x48   0x8 */
            long unsigned int          packets;              /*  0x50   0x8 */
            long unsigned int          tx_csum;              /*  0x58   0x8 */
            long unsigned int          tso_packets;          /*  0x60   0x8 */
            long unsigned int          xmit_more;            /*  0x68   0x8 */
            unsigned int               tx_dropped;           /*  0x70   0x4 */
    
            /* XXX 4 bytes hole, try to pack */
    
            struct mlx4_bf             bf;                   /*  0x78  0x18 */
            /* --- cacheline 2 boundary (128 bytes) was 16 bytes ago --- */
            long unsigned int          queue_stopped;        /*  0x90   0x8 */
            cpumask_t                  affinity_mask;        /*  0x98  0x10 */
            struct mlx4_qp             qp;                   /*  0xa8  0x30 */
            /* --- cacheline 3 boundary (192 bytes) was 24 bytes ago --- */
            struct mlx4_hwq_resources  wqres;                /*  0xd8  0x58 */
            /* --- cacheline 4 boundary (256 bytes) was 48 bytes ago --- */
            u32                        size;                 /* 0x130   0x4 */
            u32                        size_mask;            /* 0x134   0x4 */
            u16                        stride;               /* 0x138   0x2 */
    
            /* XXX 2 bytes hole, try to pack */
    
            u32                        full_size;            /* 0x13c   0x4 */
            /* --- cacheline 5 boundary (320 bytes) --- */
            u16                        cqn;                  /* 0x140   0x2 */
    
            /* XXX 2 bytes hole, try to pack */
    
            u32                        buf_size;             /* 0x144   0x4 */
            __be32                     doorbell_qpn;         /* 0x148   0x4 */
            __be32                     mr_key;               /* 0x14c   0x4 */
            void *                     buf;                  /* 0x150   0x8 */
            struct mlx4_en_tx_info *   tx_info;              /* 0x158   0x8 */
            struct mlx4_en_rx_ring *   recycle_ring;         /* 0x160   0x8 */
            u32                        (*free_tx_desc)(struct mlx4_en_priv *, struct mlx4_en_tx_ring *, int, u8, u64, int); /* 0x168   0x8 */
            u8 *                       bounce_buf;           /* 0x170   0x8 */
            struct mlx4_qp_context     context;              /* 0x178  0xf8 */
            /* --- cacheline 9 boundary (576 bytes) was 48 bytes ago --- */
            int                        qpn;                  /* 0x270   0x4 */
            enum mlx4_qp_state         qp_state;             /* 0x274   0x4 */
            u8                         queue_index;          /* 0x278   0x1 */
            bool                       bf_enabled;           /* 0x279   0x1 */
            bool                       bf_alloced;           /* 0x27a   0x1 */
    
            /* XXX 5 bytes hole, try to pack */
    
            /* --- cacheline 10 boundary (640 bytes) --- */
            struct netdev_queue *      tx_queue;             /* 0x280   0x8 */
            int                        hwtstamp_tx_type;     /* 0x288   0x4 */
    
            /* size: 704, cachelines: 11, members: 36 */
            /* sum members: 587, holes: 6, sum holes: 65 */
            /* padding: 52 */
    };
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index eff21651b673..574bcbb1b38f 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -281,46 +281,50 @@ struct mlx4_en_tx_ring {
 	u32			last_nr_txbb;
 	u32			cons;
 	unsigned long		wake_queue;
+	struct netdev_queue	*tx_queue;
+	u32			(*free_tx_desc)(struct mlx4_en_priv *priv,
+						struct mlx4_en_tx_ring *ring,
+						int index, u8 owner,
+						u64 timestamp, int napi_mode);
+	struct mlx4_en_rx_ring	*recycle_ring;
 
 	/* cache line used and dirtied in mlx4_en_xmit() */
 	u32			prod ____cacheline_aligned_in_smp;
+	unsigned int		tx_dropped;
 	unsigned long		bytes;
 	unsigned long		packets;
 	unsigned long		tx_csum;
 	unsigned long		tso_packets;
 	unsigned long		xmit_more;
-	unsigned int		tx_dropped;
 	struct mlx4_bf		bf;
-	unsigned long		queue_stopped;
 
 	/* Following part should be mostly read */
-	cpumask_t		affinity_mask;
-	struct mlx4_qp		qp;
-	struct mlx4_hwq_resources wqres;
+	__be32			doorbell_qpn;
+	__be32			mr_key;
 	u32			size; /* number of TXBBs */
 	u32			size_mask;
-	u16			stride;
 	u32			full_size;
-	u16			cqn;	/* index of port CQ associated with this ring */
 	u32			buf_size;
-	__be32			doorbell_qpn;
-	__be32			mr_key;
 	void			*buf;
 	struct mlx4_en_tx_info	*tx_info;
-	struct mlx4_en_rx_ring	*recycle_ring;
-	u32			(*free_tx_desc)(struct mlx4_en_priv *priv,
-						struct mlx4_en_tx_ring *ring,
-						int index, u8 owner,
-						u64 timestamp, int napi_mode);
-	u8			*bounce_buf;
-	struct mlx4_qp_context	context;
 	int			qpn;
-	enum mlx4_qp_state	qp_state;
 	u8			queue_index;
 	bool			bf_enabled;
 	bool			bf_alloced;
-	struct netdev_queue	*tx_queue;
-	int			hwtstamp_tx_type;
+	u8			hwtstamp_tx_type;
+	u8			*bounce_buf;
+
+	/* Not used in fast path
+	 * Only queue_stopped might be used if BQL is not properly working.
+	 */
+	unsigned long		queue_stopped;
+	struct mlx4_hwq_resources sp_wqres;
+	struct mlx4_qp		sp_qp;
+	struct mlx4_qp_context	sp_context;
+	cpumask_t		sp_affinity_mask;
+	enum mlx4_qp_state	sp_qp_state;
+	u16			sp_stride;
+	u16			sp_cqn;	/* index of port CQ associated with this ring */
 } ____cacheline_aligned_in_smp;
 
 struct mlx4_en_rx_desc {

commit 15fca2c8eb4166123a3edbd151765b00af190b75
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Wed Nov 2 17:12:25 2016 +0200

    net/mlx4_en: Add ethtool statistics for XDP cases
    
    XDP statistics are reported in ethtool, in total and per ring,
    as follows:
    - xdp_drop: the number of packets dropped by xdp.
    - xdp_tx: the number of packets forwarded by xdp.
    - xdp_tx_full: the number of times an xdp forward failed
            due to a full tx xdp ring.
    
    In addition, all packets that are dropped/forwarded by XDP
    are no longer accounted in rx_packets/rx_bytes of the ring,
    so that they count traffic that is passed to the stack.
    
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 6e0693659f85..eff21651b673 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -350,6 +350,9 @@ struct mlx4_en_rx_ring {
 	unsigned long csum_ok;
 	unsigned long csum_none;
 	unsigned long csum_complete;
+	unsigned long xdp_drop;
+	unsigned long xdp_tx;
+	unsigned long xdp_tx_full;
 	unsigned long dropped;
 	int hwtstamp_rx_filter;
 	cpumask_var_t affinity_mask;
@@ -599,6 +602,7 @@ struct mlx4_en_priv {
 	struct mlx4_en_flow_stats_rx rx_flowstats;
 	struct mlx4_en_flow_stats_tx tx_flowstats;
 	struct mlx4_en_port_stats port_stats;
+	struct mlx4_en_xdp_stats xdp_stats;
 	struct mlx4_en_stats_bitmap stats_bitmap;
 	struct list_head mc_list;
 	struct list_head curr_list;
@@ -687,7 +691,8 @@ void mlx4_en_tx_irq(struct mlx4_cq *mcq);
 u16 mlx4_en_select_queue(struct net_device *dev, struct sk_buff *skb,
 			 void *accel_priv, select_queue_fallback_t fallback);
 netdev_tx_t mlx4_en_xmit(struct sk_buff *skb, struct net_device *dev);
-netdev_tx_t mlx4_en_xmit_frame(struct mlx4_en_rx_alloc *frame,
+netdev_tx_t mlx4_en_xmit_frame(struct mlx4_en_rx_ring *rx_ring,
+			       struct mlx4_en_rx_alloc *frame,
 			       struct net_device *dev, unsigned int length,
 			       int tx_ind, int *doorbell_pending);
 void mlx4_en_xmit_doorbell(struct mlx4_en_tx_ring *ring);

commit 67f8b1dcb9ee7f1e165da4eb2ec53483a6b141ea
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Wed Nov 2 17:12:24 2016 +0200

    net/mlx4_en: Refactor the XDP forwarding rings scheme
    
    Separately manage the two types of TX rings: regular ones, and XDP.
    Upon an XDP set, do not borrow regular TX rings and convert them
    into XDP ones, but allocate new ones, unless we hit the max number
    of rings.
    Which means that in systems with smaller #cores we will not consume
    the current TX rings for XDP, while we are still in the num TX limit.
    
    XDP TX rings counters are not shown in ethtool statistics.
    Instead, XDP counters will be added to the respective RX rings
    in a downstream patch.
    
    This has no performance implications.
    
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 83c914a79f14..6e0693659f85 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -207,8 +207,10 @@ enum {
  */
 
 enum cq_type {
+	/* keep tx types first */
 	TX,
 	TX_XDP,
+#define MLX4_EN_NUM_TX_TYPES (TX_XDP + 1)
 	RX,
 };
 
@@ -373,7 +375,7 @@ struct mlx4_en_cq {
 
 struct mlx4_en_port_profile {
 	u32 flags;
-	u32 tx_ring_num;
+	u32 tx_ring_num[MLX4_EN_NUM_TX_TYPES];
 	u32 rx_ring_num;
 	u32 tx_ring_size;
 	u32 rx_ring_size;
@@ -570,17 +572,16 @@ struct mlx4_en_priv {
 	u32 flags;
 	u8 num_tx_rings_p_up;
 	u32 tx_work_limit;
-	u32 tx_ring_num;
+	u32 tx_ring_num[MLX4_EN_NUM_TX_TYPES];
 	u32 rx_ring_num;
 	u32 rx_skb_size;
 	struct mlx4_en_frag_info frag_info[MLX4_EN_MAX_RX_FRAGS];
 	u16 num_frags;
 	u16 log_rx_info;
-	int xdp_ring_num;
 
-	struct mlx4_en_tx_ring **tx_ring;
+	struct mlx4_en_tx_ring **tx_ring[MLX4_EN_NUM_TX_TYPES];
 	struct mlx4_en_rx_ring *rx_ring[MAX_RX_RINGS];
-	struct mlx4_en_cq **tx_cq;
+	struct mlx4_en_cq **tx_cq[MLX4_EN_NUM_TX_TYPES];
 	struct mlx4_en_cq *rx_cq[MAX_RX_RINGS];
 	struct mlx4_qp drop_qp;
 	struct work_struct rx_mode_task;

commit ccc109b8ed24c6a84cc46a78ec3df9a57a6c674a
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Wed Nov 2 17:12:23 2016 +0200

    net/mlx4_en: Add TX_XDP for CQ types
    
    Support XDP CQ type, and refactor the CQ type enum.
    Rename the is_tx field to match the change.
    
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index a3528dd1e72e..83c914a79f14 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -207,8 +207,9 @@ enum {
  */
 
 enum cq_type {
-	RX = 0,
-	TX = 1,
+	TX,
+	TX_XDP,
+	RX,
 };
 
 
@@ -361,7 +362,7 @@ struct mlx4_en_cq {
 	int size;
 	int buf_size;
 	int vector;
-	enum cq_type is_tx;
+	enum cq_type type;
 	u16 moder_time;
 	u16 moder_cnt;
 	struct mlx4_cqe *buf;

commit b20b378d49926b82c0a131492fa8842156e0e8a9
Merge: 02154927c115 da499f8f5385
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Sep 12 15:52:44 2016 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Conflicts:
            drivers/net/ethernet/mediatek/mtk_eth_soc.c
            drivers/net/ethernet/qlogic/qed/qed_dcbx.c
            drivers/net/phy/Kconfig
    
    All conflicts were cases of overlapping commits.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 564ed9b187082da79726a2f25bb88a58ebeec7e8
Author: Tariq Toukan <tariqt@mellanox.com>
Date:   Sun Sep 11 10:56:19 2016 +0300

    net/mlx4_en: Fixes for DCBX
    
    This patch adds a capability check before enabling DCBX.
    In addition, it re-organizes the relevant data structures,
    and fixes a typo in a define.
    
    Fixes: af7d51852631 ("net/mlx4_en: Add DCB PFC support through CEE netlink commands")
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 2c2913dcae98..9099dbd04951 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -482,20 +482,10 @@ enum dcb_pfc_type {
 	pfc_enabled_rx
 };
 
-struct tc_configuration {
-	enum dcb_pfc_type  dcb_pfc;
-};
-
 struct mlx4_en_cee_config {
 	bool	pfc_state;
-	struct	tc_configuration tc_config[MLX4_EN_NUM_UP];
+	enum	dcb_pfc_type dcb_pfc[MLX4_EN_NUM_UP];
 };
-
-struct mlx4_en_cee_params {
-	u8 dcbx_cap;
-	struct mlx4_en_cee_config dcb_cfg;
-};
-
 #endif
 
 struct ethtool_flow_id {
@@ -624,7 +614,8 @@ struct mlx4_en_priv {
 	struct ieee_ets ets;
 	u16 maxrate[IEEE_8021QAZ_MAX_TCS];
 	enum dcbnl_cndd_states cndd_state[IEEE_8021QAZ_MAX_TCS];
-	struct mlx4_en_cee_params cee_params;
+	struct mlx4_en_cee_config cee_config;
+	u8 dcbx_cap;
 #endif
 #ifdef CONFIG_RFS_ACCEL
 	spinlock_t filters_lock;

commit 326fe02d1ed61a63c30fa1f144758f34f0ef11cb
Author: Brenden Blanco <bblanco@plumgrid.com>
Date:   Sat Sep 3 21:29:58 2016 -0700

    net/mlx4_en: protect ring->xdp_prog with rcu_read_lock
    
    Depending on the preempt mode, the bpf_prog stored in xdp_prog may be
    freed despite the use of call_rcu inside bpf_prog_put. The situation is
    possible when running in PREEMPT_RCU=y mode, for instance, since the rcu
    callback for destroying the bpf prog can run even during the bh handling
    in the mlx4 rx path.
    
    Several options were considered before this patch was settled on:
    
    Add a napi_synchronize loop in mlx4_xdp_set, which would occur after all
    of the rings are updated with the new program.
    This approach has the disadvantage that as the number of rings
    increases, the speed of update will slow down significantly due to
    napi_synchronize's msleep(1).
    
    Add a new rcu_head in bpf_prog_aux, to be used by a new bpf_prog_put_bh.
    The action of the bpf_prog_put_bh would be to then call bpf_prog_put
    later. Those drivers that consume a bpf prog in a bh context (like mlx4)
    would then use the bpf_prog_put_bh instead when the ring is up. This has
    the problem of complexity, in maintaining proper refcnts and rcu lists,
    and would likely be harder to review. In addition, this approach to
    freeing must be exclusive with other frees of the bpf prog, for instance
    a _bh prog must not be referenced from a prog array that is consumed by
    a non-_bh prog.
    
    The placement of rcu_read_lock in this patch is functionally the same as
    putting an rcu_read_lock in napi_poll. Actually doing so could be a
    potentially controversial change, but would bring the implementation in
    line with sk_busy_loop (though of course the nature of those two paths
    is substantially different), and would also avoid future copy/paste
    problems with future supporters of XDP. Still, this patch does not take
    that opinionated option.
    
    Testing was done with kernels in either PREEMPT_RCU=y or
    CONFIG_PREEMPT_VOLUNTARY=y+PREEMPT_RCU=n modes, with neither exhibiting
    any drawback. With PREEMPT_RCU=n, the extra call to rcu_read_lock did
    not show up in the perf report whatsoever, and with PREEMPT_RCU=y the
    overhead of rcu_read_lock (according to perf) was the same before/after.
    In the rx path, rcu_read_lock is eventually called for every packet
    from netif_receive_skb_internal, so the napi poll call's rcu_read_lock
    is easily amortized.
    
    v2:
    Remove extra rcu_read_lock in mlx4_en_process_rx_cq body
    Annotate xdp_prog with __rcu, and convert all usages to rcu_assign or
    rcu_dereference[_protected] as appropriate.
    Add explicit mutex lock around rcu_assign instead of xchg loop.
    
    Fixes: d576acf0a22 ("net/mlx4_en: add page recycle to prepare rx ring for tx support")
    Acked-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Alexei Starovoitov <alexei.starovoitov@gmail.com>
    Signed-off-by: Brenden Blanco <bblanco@plumgrid.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 2c2913dcae98..47867c49f91c 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -340,7 +340,7 @@ struct mlx4_en_rx_ring {
 	u8  fcs_del;
 	void *buf;
 	void *rx_info;
-	struct bpf_prog *xdp_prog;
+	struct bpf_prog __rcu *xdp_prog;
 	struct mlx4_en_page_cache page_cache;
 	unsigned long bytes;
 	unsigned long packets;

commit de0ba9a0d8909996f9e293d311c2cc459fa77d67
Merge: d95a93a9b716 107df03203bb
Author: David S. Miller <davem@davemloft.net>
Date:   Sat Jul 23 19:31:37 2016 -0400

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Just several instances of overlapping changes.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 9ecc2d86171adf23796133c89610987a14624875
Author: Brenden Blanco <bblanco@plumgrid.com>
Date:   Tue Jul 19 12:16:55 2016 -0700

    net/mlx4_en: add xdp forwarding and data write support
    
    A user will now be able to loop packets back out of the same port using
    a bpf program attached to xdp hook. Updates to the packet contents from
    the bpf program is also supported.
    
    For the packet write feature to work, the rx buffers are now mapped as
    bidirectional when the page is allocated. This occurs only when the xdp
    hook is active.
    
    When the program returns a TX action, enqueue the packet directly to a
    dedicated tx ring, so as to avoid completely any locking. This requires
    the tx ring to be allocated 1:1 for each rx ring, as well as the tx
    completion running in the same softirq.
    
    Upon tx completion, this dedicated tx ring recycles pages without
    unmapping directly back to the original rx ring. In steady state tx/drop
    workload, effectively 0 page allocs/frees will occur.
    
    In order to separate out the paths between free and recycle, a
    free_tx_desc func pointer is introduced that is optionally updated
    whenever recycle_ring is activated. By default the original free
    function is always initialized.
    
    Signed-off-by: Brenden Blanco <bblanco@plumgrid.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index eff4be0279e6..29c81d26f9f5 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -132,6 +132,7 @@ enum {
 					 MLX4_EN_NUM_UP)
 
 #define MLX4_EN_DEFAULT_TX_WORK		256
+#define MLX4_EN_DOORBELL_BUDGET		8
 
 /* Target number of packets to coalesce with interrupt moderation */
 #define MLX4_EN_RX_COAL_TARGET	44
@@ -219,7 +220,10 @@ enum cq_type {
 
 
 struct mlx4_en_tx_info {
-	struct sk_buff *skb;
+	union {
+		struct sk_buff *skb;
+		struct page *page;
+	};
 	dma_addr_t	map0_dma;
 	u32		map0_byte_count;
 	u32		nr_txbb;
@@ -265,6 +269,8 @@ struct mlx4_en_page_cache {
 	struct mlx4_en_rx_alloc buf[MLX4_EN_CACHE_SIZE];
 };
 
+struct mlx4_en_priv;
+
 struct mlx4_en_tx_ring {
 	/* cache line used and dirtied in tx completion
 	 * (mlx4_en_free_tx_buf())
@@ -298,6 +304,11 @@ struct mlx4_en_tx_ring {
 	__be32			mr_key;
 	void			*buf;
 	struct mlx4_en_tx_info	*tx_info;
+	struct mlx4_en_rx_ring	*recycle_ring;
+	u32			(*free_tx_desc)(struct mlx4_en_priv *priv,
+						struct mlx4_en_tx_ring *ring,
+						int index, u8 owner,
+						u64 timestamp, int napi_mode);
 	u8			*bounce_buf;
 	struct mlx4_qp_context	context;
 	int			qpn;
@@ -678,6 +689,12 @@ void mlx4_en_tx_irq(struct mlx4_cq *mcq);
 u16 mlx4_en_select_queue(struct net_device *dev, struct sk_buff *skb,
 			 void *accel_priv, select_queue_fallback_t fallback);
 netdev_tx_t mlx4_en_xmit(struct sk_buff *skb, struct net_device *dev);
+netdev_tx_t mlx4_en_xmit_frame(struct mlx4_en_rx_alloc *frame,
+			       struct net_device *dev, unsigned int length,
+			       int tx_ind, int *doorbell_pending);
+void mlx4_en_xmit_doorbell(struct mlx4_en_tx_ring *ring);
+bool mlx4_en_rx_recycle(struct mlx4_en_rx_ring *ring,
+			struct mlx4_en_rx_alloc *frame);
 
 int mlx4_en_create_tx_ring(struct mlx4_en_priv *priv,
 			   struct mlx4_en_tx_ring **pring,
@@ -706,6 +723,14 @@ int mlx4_en_process_rx_cq(struct net_device *dev,
 			  int budget);
 int mlx4_en_poll_rx_cq(struct napi_struct *napi, int budget);
 int mlx4_en_poll_tx_cq(struct napi_struct *napi, int budget);
+u32 mlx4_en_free_tx_desc(struct mlx4_en_priv *priv,
+			 struct mlx4_en_tx_ring *ring,
+			 int index, u8 owner, u64 timestamp,
+			 int napi_mode);
+u32 mlx4_en_recycle_tx_desc(struct mlx4_en_priv *priv,
+			    struct mlx4_en_tx_ring *ring,
+			    int index, u8 owner, u64 timestamp,
+			    int napi_mode);
 void mlx4_en_fill_qp_context(struct mlx4_en_priv *priv, int size, int stride,
 		int is_tx, int rss, int qpn, int cqn, int user_prio,
 		struct mlx4_qp_context *context);

commit d576acf0a22890cf3f8f7a9b035f1558077f6770
Author: Brenden Blanco <bblanco@plumgrid.com>
Date:   Tue Jul 19 12:16:52 2016 -0700

    net/mlx4_en: add page recycle to prepare rx ring for tx support
    
    The mlx4 driver by default allocates order-3 pages for the ring to
    consume in multiple fragments. When the device has an xdp program, this
    behavior will prevent tx actions since the page must be re-mapped in
    TODEVICE mode, which cannot be done if the page is still shared.
    
    Start by making the allocator configurable based on whether xdp is
    running, such that order-0 pages are always used and never shared.
    
    Since this will stress the page allocator, add a simple page cache to
    each rx ring. Pages in the cache are left dma-mapped, and in drop-only
    stress tests the page allocator is eliminated from the perf report.
    
    Note that setting an xdp program will now require the rings to be
    reconfigured.
    
    Before:
     26.91%  ksoftirqd/0  [mlx4_en]         [k] mlx4_en_process_rx_cq
     17.88%  ksoftirqd/0  [mlx4_en]         [k] mlx4_en_alloc_frags
      6.00%  ksoftirqd/0  [mlx4_en]         [k] mlx4_en_free_frag
      4.49%  ksoftirqd/0  [kernel.vmlinux]  [k] get_page_from_freelist
      3.21%  swapper      [kernel.vmlinux]  [k] intel_idle
      2.73%  ksoftirqd/0  [kernel.vmlinux]  [k] bpf_map_lookup_elem
      2.57%  swapper      [mlx4_en]         [k] mlx4_en_process_rx_cq
    
    After:
     31.72%  swapper      [kernel.vmlinux]       [k] intel_idle
      8.79%  swapper      [mlx4_en]              [k] mlx4_en_process_rx_cq
      7.54%  swapper      [kernel.vmlinux]       [k] poll_idle
      6.36%  swapper      [mlx4_core]            [k] mlx4_eq_int
      4.21%  swapper      [kernel.vmlinux]       [k] tasklet_action
      4.03%  swapper      [kernel.vmlinux]       [k] cpuidle_enter_state
      3.43%  swapper      [mlx4_en]              [k] mlx4_en_prepare_rx_desc
      2.18%  swapper      [kernel.vmlinux]       [k] native_irq_return_iret
      1.37%  swapper      [kernel.vmlinux]       [k] menu_select
      1.09%  swapper      [kernel.vmlinux]       [k] bpf_map_lookup_elem
    
    Signed-off-by: Brenden Blanco <bblanco@plumgrid.com>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index eb1238d05ca8..eff4be0279e6 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -259,6 +259,12 @@ struct mlx4_en_rx_alloc {
 	u32		page_size;
 };
 
+#define MLX4_EN_CACHE_SIZE (2 * NAPI_POLL_WEIGHT)
+struct mlx4_en_page_cache {
+	u32 index;
+	struct mlx4_en_rx_alloc buf[MLX4_EN_CACHE_SIZE];
+};
+
 struct mlx4_en_tx_ring {
 	/* cache line used and dirtied in tx completion
 	 * (mlx4_en_free_tx_buf())
@@ -324,6 +330,7 @@ struct mlx4_en_rx_ring {
 	void *buf;
 	void *rx_info;
 	struct bpf_prog *xdp_prog;
+	struct mlx4_en_page_cache page_cache;
 	unsigned long bytes;
 	unsigned long packets;
 	unsigned long csum_ok;
@@ -443,7 +450,9 @@ struct mlx4_en_mc_list {
 struct mlx4_en_frag_info {
 	u16 frag_size;
 	u16 frag_prefix_size;
-	u16 frag_stride;
+	u32 frag_stride;
+	enum dma_data_direction dma_dir;
+	int order;
 };
 
 #ifdef CONFIG_MLX4_EN_DCB

commit 47a38e155037f417c5740e24ccae6482aedf4b68
Author: Brenden Blanco <bblanco@plumgrid.com>
Date:   Tue Jul 19 12:16:50 2016 -0700

    net/mlx4_en: add support for fast rx drop bpf program
    
    Add support for the BPF_PROG_TYPE_XDP hook in mlx4 driver.
    
    In tc/socket bpf programs, helpers linearize skb fragments as needed
    when the program touches the packet data. However, in the pursuit of
    speed, XDP programs will not be allowed to use these slower functions,
    especially if it involves allocating an skb.
    
    Therefore, disallow MTU settings that would produce a multi-fragment
    packet that XDP programs would fail to access. Future enhancements could
    be done to increase the allowable MTU.
    
    The xdp program is present as a per-ring data structure, but as of yet
    it is not possible to set at that granularity through any ndo.
    
    Signed-off-by: Brenden Blanco <bblanco@plumgrid.com>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index d39bf594abe4..eb1238d05ca8 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -164,6 +164,10 @@ enum {
 #define MLX4_LOOPBACK_TEST_PAYLOAD (HEADER_COPY_SIZE - ETH_HLEN)
 
 #define MLX4_EN_MIN_MTU		46
+/* VLAN_HLEN is added twice,to support skb vlan tagged with multiple
+ * headers. (For example: ETH_P_8021Q and ETH_P_8021AD).
+ */
+#define MLX4_EN_EFF_MTU(mtu)	((mtu) + ETH_HLEN + (2 * VLAN_HLEN))
 #define ETH_BCAST		0xffffffffffffULL
 
 #define MLX4_EN_LOOPBACK_RETRIES	5
@@ -319,6 +323,7 @@ struct mlx4_en_rx_ring {
 	u8  fcs_del;
 	void *buf;
 	void *rx_info;
+	struct bpf_prog *xdp_prog;
 	unsigned long bytes;
 	unsigned long packets;
 	unsigned long csum_ok;
@@ -558,6 +563,7 @@ struct mlx4_en_priv {
 	struct mlx4_en_frag_info frag_info[MLX4_EN_MAX_RX_FRAGS];
 	u16 num_frags;
 	u16 log_rx_info;
+	int xdp_ring_num;
 
 	struct mlx4_en_tx_ring **tx_ring;
 	struct mlx4_en_rx_ring *rx_ring[MAX_RX_RINGS];

commit ec25bc04ed8e12947738468cbe2191f1529f9e39
Author: Eugenia Emantayev <eugenia@mellanox.com>
Date:   Mon Jul 18 18:35:12 2016 +0300

    net/mlx4_en: Add resilience in low memory systems
    
    This patch fixes the lost of Ethernet port on low memory system,
    when driver frees its resources and fails to allocate new resources.
    Issue could happen while changing number of channels, rings size or
    changing the timestamp configuration.
    This fix is necessary because of removing vmap use in the code.
    When vmap was in use driver could allocate non-contiguous memory
    and make it contiguous with vmap. Now it could fail to allocate
    a large chunk of contiguous memory and lose the port.
    Current code tries to allocate new resources and then upon success
    frees the old resources.
    
    Fixes: 73898db04301 ('net/mlx4: Avoid wrong virtual mappings')
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.com>
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 467d47ed2c39..13d297ee34bb 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -353,12 +353,14 @@ struct mlx4_en_port_profile {
 	u32 rx_ring_num;
 	u32 tx_ring_size;
 	u32 rx_ring_size;
+	u8 num_tx_rings_p_up;
 	u8 rx_pause;
 	u8 rx_ppp;
 	u8 tx_pause;
 	u8 tx_ppp;
 	int rss_rings;
 	int inline_thold;
+	struct hwtstamp_config hwtstamp_config;
 };
 
 struct mlx4_en_profile {
@@ -623,8 +625,11 @@ void mlx4_en_set_stats_bitmap(struct mlx4_dev *dev,
 			      u8 rx_ppp, u8 rx_pause,
 			      u8 tx_ppp, u8 tx_pause);
 
-void mlx4_en_free_resources(struct mlx4_en_priv *priv);
-int mlx4_en_alloc_resources(struct mlx4_en_priv *priv);
+int mlx4_en_try_alloc_resources(struct mlx4_en_priv *priv,
+				struct mlx4_en_priv *tmp,
+				struct mlx4_en_port_profile *prof);
+void mlx4_en_safe_replace_resources(struct mlx4_en_priv *priv,
+				    struct mlx4_en_priv *tmp);
 
 int mlx4_en_create_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq **pcq,
 		      int entries, int ring, enum cq_type mode, int node);

commit af7d5185263133f859dd4f35d45594deef9db854
Author: Rana Shahout <ranas@mellanox.com>
Date:   Tue Jun 21 12:43:59 2016 +0300

    net/mlx4_en: Add DCB PFC support through CEE netlink commands
    
    This patch adds support for reading and updating priority flow
    control (PFC) attributes in the driver via netlink.
    
    Signed-off-by: Rana Shahout <ranas@mellanox.com>
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.com>
    Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 6b3b0fefabad..d39bf594abe4 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -448,6 +448,27 @@ struct mlx4_en_frag_info {
 
 #define MLX4_EN_TC_ETS 7
 
+enum dcb_pfc_type {
+	pfc_disabled = 0,
+	pfc_enabled_full,
+	pfc_enabled_tx,
+	pfc_enabled_rx
+};
+
+struct tc_configuration {
+	enum dcb_pfc_type  dcb_pfc;
+};
+
+struct mlx4_en_cee_config {
+	bool	pfc_state;
+	struct	tc_configuration tc_config[MLX4_EN_NUM_UP];
+};
+
+struct mlx4_en_cee_params {
+	u8 dcbx_cap;
+	struct mlx4_en_cee_config dcb_cfg;
+};
+
 #endif
 
 struct ethtool_flow_id {
@@ -467,6 +488,9 @@ enum {
 	MLX4_EN_FLAG_RX_FILTER_NEEDED	= (1 << 3),
 	MLX4_EN_FLAG_FORCE_PROMISC	= (1 << 4),
 	MLX4_EN_FLAG_RX_CSUM_NON_TCP_UDP	= (1 << 5),
+#ifdef CONFIG_MLX4_EN_DCB
+	MLX4_EN_FLAG_DCB_ENABLED        = (1 << 6),
+#endif
 };
 
 #define PORT_BEACON_MAX_LIMIT (65535)
@@ -568,9 +592,11 @@ struct mlx4_en_priv {
 	u32 counter_index;
 
 #ifdef CONFIG_MLX4_EN_DCB
+#define MLX4_EN_DCB_ENABLED	0x3
 	struct ieee_ets ets;
 	u16 maxrate[IEEE_8021QAZ_MAX_TCS];
 	enum dcbnl_cndd_states cndd_state[IEEE_8021QAZ_MAX_TCS];
+	struct mlx4_en_cee_params cee_params;
 #endif
 #ifdef CONFIG_RFS_ACCEL
 	spinlock_t filters_lock;

commit a831274a1346913c145797ddee6f39e30e061318
Author: Alexander Duyck <aduyck@mirantis.com>
Date:   Thu Jun 16 12:22:30 2016 -0700

    mlx4_en: Replace ndo_add/del_vxlan_port with ndo_add/del_udp_enc_port
    
    This change replaces the network device operations for adding or removing a
    VXLAN port with operations that are more generically defined to be used for
    any UDP offload port but provide a type.  As such by just adding a line to
    verify that the offload type is VXLAN we can maintain the same
    functionality.
    
    In addition I updated the socket address family check so that instead of
    excluding IPv6 we instead abort of type is not IPv4.  This makes much more
    sense as we should only be supporting IPv4 outer addresses on this
    hardware.
    
    Signed-off-by: Alexander Duyck <aduyck@mirantis.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 467d47ed2c39..6b3b0fefabad 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -545,10 +545,8 @@ struct mlx4_en_priv {
 	struct work_struct linkstate_task;
 	struct delayed_work stats_task;
 	struct delayed_work service_task;
-#ifdef CONFIG_MLX4_EN_VXLAN
 	struct work_struct vxlan_add_task;
 	struct work_struct vxlan_del_task;
-#endif
 	struct mlx4_en_perf_stats pstats;
 	struct mlx4_en_pkt_stats pkstats;
 	struct mlx4_en_counter_stats pf_stats;

commit f73a6f439fca0e14f228726e5647d5afe141bc32
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed May 25 09:50:39 2016 -0700

    net/mlx4_en: get rid of private net_device_stats
    
    We simply can use the standard net_device stats.
    
    We do not need to clear fields that are already 0.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Willem de Bruijn <willemb@google.com>
    Cc: Eugenia Emantayev <eugenia@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index bfda84df8aae..467d47ed2c39 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -483,7 +483,6 @@ struct mlx4_en_priv {
 	struct mlx4_en_port_profile *prof;
 	struct net_device *dev;
 	unsigned long active_vlans[BITS_TO_LONGS(VLAN_N_VID)];
-	struct net_device_stats stats;
 	struct mlx4_en_port_state port_state;
 	spinlock_t stats_lock;
 	struct ethtool_flow_id ethtool_rules[MAX_NUM_OF_FS_RULES];

commit 9ed17db17fb01a7be5b84558b768c091bdf8bb41
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed May 25 09:50:38 2016 -0700

    net/mlx4_en: get rid of ret_stats
    
    mlx4 uses a private struct net_device_stats in a vain attempt
    to avoid races.
    
    This is buggy because multiple cpus could call mlx4_en_get_stats()
    at the same time, so ret_stats can not guarantee stable results.
    
    To fix this, we need to switch to ndo_get_stats64() as this
    method provides per-thread storage.
    
    This allows to reduce mlx4_en_priv bloat.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Willem de Bruijn <willemb@google.com>
    Cc: Eugenia Emantayev <eugenia@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 9a9124031fc7..bfda84df8aae 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -484,7 +484,6 @@ struct mlx4_en_priv {
 	struct net_device *dev;
 	unsigned long active_vlans[BITS_TO_LONGS(VLAN_N_VID)];
 	struct net_device_stats stats;
-	struct net_device_stats ret_stats;
 	struct mlx4_en_port_state port_state;
 	spinlock_t stats_lock;
 	struct ethtool_flow_id ethtool_rules[MAX_NUM_OF_FS_RULES];

commit 63a664b7e92b14aaa1e1c3e9ae362aa70cf4cefb
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed May 25 09:50:36 2016 -0700

    net/mlx4_en: fix tx_dropped bug
    
    1) mlx4_en_xmit() can increment priv->stats.tx_dropped, but this variable
    is overwritten in mlx4_en_DUMP_ETH_STATS().
    
    2) This increment was not SMP safe, as a port might have many TX queues.
    
    Add a per TX ring tx_dropped to fix these issues.
    
    This is u32 as mlx4_en_DUMP_ETH_STATS() will add a 32bit field.
    
    So lets avoid bugs with SNMP agents having to cope with partial
    overwraps. (One of these agents being bond_fold_stats())
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Willem de Bruijn <willemb@google.com>
    Cc: Eugenia Emantayev <eugenia@mellanox.com>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index cc84e09f324a..9a9124031fc7 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -270,6 +270,7 @@ struct mlx4_en_tx_ring {
 	unsigned long		tx_csum;
 	unsigned long		tso_packets;
 	unsigned long		xmit_more;
+	unsigned int		tx_dropped;
 	struct mlx4_bf		bf;
 	unsigned long		queue_stopped;
 

commit 73898db0430125606c86c798c0627aefef9af9ed
Author: Haggai Abramovsky <hagaya@mellanox.com>
Date:   Wed May 4 14:50:15 2016 +0300

    net/mlx4: Avoid wrong virtual mappings
    
    The dma_alloc_coherent() function returns a virtual address which can
    be used for coherent access to the underlying memory.  On some
    architectures, like arm64, undefined behavior results if this memory is
    also accessed via virtual mappings that are not coherent.  Because of
    their undefined nature, operations like virt_to_page() return garbage
    when passed virtual addresses obtained from dma_alloc_coherent().  Any
    subsequent mappings via vmap() of the garbage page values are unusable
    and result in bad things like bus errors (synchronous aborts in ARM64
    speak).
    
    The mlx4 driver contains code that does the equivalent of:
    vmap(virt_to_page(dma_alloc_coherent)), this results in an OOPs when the
    device is opened.
    
    Prevent Ethernet driver to run this problematic code by forcing it to
    allocate contiguous memory. As for the Infiniband driver, at first we
    are trying to allocate contiguous memory, but in case of failure roll
    back to work with fragmented memory.
    
    Signed-off-by: Haggai Abramovsky <hagaya@mellanox.com>
    Signed-off-by: Yishai Hadas <yishaih@mellanox.com>
    Reported-by: David Daney <david.daney@cavium.com>
    Tested-by: Sinan Kaya <okaya@codeaurora.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 63b1aeae2c03..cc84e09f324a 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -672,8 +672,6 @@ void mlx4_en_fill_qp_context(struct mlx4_en_priv *priv, int size, int stride,
 		int is_tx, int rss, int qpn, int cqn, int user_prio,
 		struct mlx4_qp_context *context);
 void mlx4_en_sqp_event(struct mlx4_qp *qp, enum mlx4_event event);
-int mlx4_en_map_buffer(struct mlx4_buf *buf);
-void mlx4_en_unmap_buffer(struct mlx4_buf *buf);
 int mlx4_en_change_mcast_lb(struct mlx4_en_priv *priv, struct mlx4_qp *qp,
 			    int loopback);
 void mlx4_en_calc_rx_buf(struct net_device *dev);

commit d21ed3a311a1031dddc78e9270d1aa9adc8f8a93
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Wed Apr 20 16:01:18 2016 +0300

    net/mlx4_en: Split SW RX dropped counter per RX ring
    
    Count SW packet drops per RX ring instead of a global counter. This
    will allow monitoring the number of rx drops per ring.
    
    In addition, SW rx_dropped counter was overwritten by HW rx_dropped
    counter, sum both of them instead to show the accurate value.
    
    Fixes: a3333b35da16 ('net/mlx4_en: Moderate ethtool callback to [...] ')
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Reported-by: Brenden Blanco <bblanco@plumgrid.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Reported-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index d12ab6a73344..63b1aeae2c03 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -323,6 +323,7 @@ struct mlx4_en_rx_ring {
 	unsigned long csum_ok;
 	unsigned long csum_none;
 	unsigned long csum_complete;
+	unsigned long dropped;
 	int hwtstamp_rx_filter;
 	cpumask_var_t affinity_mask;
 };

commit 3d8f7cc78d0eb07641fdcfb3961e8794778a6678
Author: David Decotigny <decot@googlers.com>
Date:   Wed Feb 24 10:58:12 2016 -0800

    net: mlx4: use new ETHTOOL_G/SSETTINGS API
    
    Signed-off-by: David Decotigny <decot@googlers.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 35de7d2e6b34..d12ab6a73344 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -607,6 +607,7 @@ static inline struct mlx4_cqe *mlx4_en_get_cqe(void *buf, int idx, int cqe_sz)
 
 #define MLX4_EN_WOL_DO_MODIFY (1ULL << 63)
 
+void mlx4_en_init_ptys2ethtool_map(void);
 void mlx4_en_update_loopback_state(struct net_device *dev,
 				   netdev_features_t features);
 

commit 868fdb06063d92f4373be4974d1b651a32bb9442
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Nov 18 06:30:58 2015 -0800

    mlx4: remove mlx4_en_low_latency_recv()
    
    Busy polling can now be handled in generic NAPI poll infrastructure.
    This removes complexity and fast path overhead :
    
    mlx4 used two spin_lock()/spin_unlock() pair per napi->poll() call
    in mlx4_en_cq_lock_napi()/mlx4_en_cq_unlock_napi()
    
    Tested:
    
    Without busy polling :
    
    lpaa23:~# echo 0 >/proc/sys/net/core/busy_read
    lpaa24:~# echo 0 >/proc/sys/net/core/busy_read
    lpaa23:~# ./netperf -H lpaa24 -t TCP_RR
    MIGRATED TCP REQUEST/RESPONSE TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to lpaa24.prod.google.com () port 0 AF_INET : first burst 0
    Local /Remote
    Socket Size   Request  Resp.   Elapsed  Trans.
    Send   Recv   Size     Size    Time     Rate
    bytes  Bytes  bytes    bytes   secs.    per sec
    
    16384  87380  1        1       10.00    47330.78
    
    With busy polling :
    
    lpaa23:~# echo 70 >/proc/sys/net/core/busy_read
    lpaa24:~# echo 70 >/proc/sys/net/core/busy_read
    lpaa23:~# ./netperf -H lpaa24 -t TCP_RR
    MIGRATED TCP REQUEST/RESPONSE TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to lpaa24.prod.google.com () port 0 AF_INET : first burst 0
    Local /Remote
    Socket Size   Request  Resp.   Elapsed  Trans.
    Send   Recv   Size     Size    Time     Rate
    bytes  Bytes  bytes    bytes   secs.    per sec
    
    16384  87380  1        1       10.00    97643.55
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 965c8f016ac4..35de7d2e6b34 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -320,11 +320,6 @@ struct mlx4_en_rx_ring {
 	void *rx_info;
 	unsigned long bytes;
 	unsigned long packets;
-#ifdef CONFIG_NET_RX_BUSY_POLL
-	unsigned long yields;
-	unsigned long misses;
-	unsigned long cleaned;
-#endif
 	unsigned long csum_ok;
 	unsigned long csum_none;
 	unsigned long csum_complete;
@@ -347,18 +342,6 @@ struct mlx4_en_cq {
 	struct mlx4_cqe *buf;
 #define MLX4_EN_OPCODE_ERROR	0x1e
 
-#ifdef CONFIG_NET_RX_BUSY_POLL
-	unsigned int state;
-#define MLX4_EN_CQ_STATE_IDLE        0
-#define MLX4_EN_CQ_STATE_NAPI     1    /* NAPI owns this CQ */
-#define MLX4_EN_CQ_STATE_POLL     2    /* poll owns this CQ */
-#define MLX4_CQ_LOCKED (MLX4_EN_CQ_STATE_NAPI | MLX4_EN_CQ_STATE_POLL)
-#define MLX4_EN_CQ_STATE_NAPI_YIELD  4    /* NAPI yielded this CQ */
-#define MLX4_EN_CQ_STATE_POLL_YIELD  8    /* poll yielded this CQ */
-#define CQ_YIELD (MLX4_EN_CQ_STATE_NAPI_YIELD | MLX4_EN_CQ_STATE_POLL_YIELD)
-#define CQ_USER_PEND (MLX4_EN_CQ_STATE_POLL | MLX4_EN_CQ_STATE_POLL_YIELD)
-	spinlock_t poll_lock; /* protects from LLS/napi conflicts */
-#endif  /* CONFIG_NET_RX_BUSY_POLL */
 	struct irq_desc *irq_desc;
 };
 
@@ -622,117 +605,6 @@ static inline struct mlx4_cqe *mlx4_en_get_cqe(void *buf, int idx, int cqe_sz)
 	return buf + idx * cqe_sz;
 }
 
-#ifdef CONFIG_NET_RX_BUSY_POLL
-static inline void mlx4_en_cq_init_lock(struct mlx4_en_cq *cq)
-{
-	spin_lock_init(&cq->poll_lock);
-	cq->state = MLX4_EN_CQ_STATE_IDLE;
-}
-
-/* called from the device poll rutine to get ownership of a cq */
-static inline bool mlx4_en_cq_lock_napi(struct mlx4_en_cq *cq)
-{
-	int rc = true;
-	spin_lock(&cq->poll_lock);
-	if (cq->state & MLX4_CQ_LOCKED) {
-		WARN_ON(cq->state & MLX4_EN_CQ_STATE_NAPI);
-		cq->state |= MLX4_EN_CQ_STATE_NAPI_YIELD;
-		rc = false;
-	} else
-		/* we don't care if someone yielded */
-		cq->state = MLX4_EN_CQ_STATE_NAPI;
-	spin_unlock(&cq->poll_lock);
-	return rc;
-}
-
-/* returns true is someone tried to get the cq while napi had it */
-static inline bool mlx4_en_cq_unlock_napi(struct mlx4_en_cq *cq)
-{
-	int rc = false;
-	spin_lock(&cq->poll_lock);
-	WARN_ON(cq->state & (MLX4_EN_CQ_STATE_POLL |
-			       MLX4_EN_CQ_STATE_NAPI_YIELD));
-
-	if (cq->state & MLX4_EN_CQ_STATE_POLL_YIELD)
-		rc = true;
-	cq->state = MLX4_EN_CQ_STATE_IDLE;
-	spin_unlock(&cq->poll_lock);
-	return rc;
-}
-
-/* called from mlx4_en_low_latency_recv(), BH are disabled */
-static inline bool mlx4_en_cq_lock_poll(struct mlx4_en_cq *cq)
-{
-	int rc = true;
-
-	spin_lock(&cq->poll_lock);
-	if ((cq->state & MLX4_CQ_LOCKED)) {
-		struct net_device *dev = cq->dev;
-		struct mlx4_en_priv *priv = netdev_priv(dev);
-		struct mlx4_en_rx_ring *rx_ring = priv->rx_ring[cq->ring];
-
-		cq->state |= MLX4_EN_CQ_STATE_POLL_YIELD;
-		rc = false;
-		rx_ring->yields++;
-	} else
-		/* preserve yield marks */
-		cq->state |= MLX4_EN_CQ_STATE_POLL;
-	spin_unlock(&cq->poll_lock);
-	return rc;
-}
-
-/* returns true if someone tried to get the cq while it was locked */
-static inline bool mlx4_en_cq_unlock_poll(struct mlx4_en_cq *cq)
-{
-	int rc = false;
-
-	spin_lock(&cq->poll_lock);
-	WARN_ON(cq->state & (MLX4_EN_CQ_STATE_NAPI));
-
-	if (cq->state & MLX4_EN_CQ_STATE_POLL_YIELD)
-		rc = true;
-	cq->state = MLX4_EN_CQ_STATE_IDLE;
-	spin_unlock(&cq->poll_lock);
-	return rc;
-}
-
-/* true if a socket is polling, even if it did not get the lock */
-static inline bool mlx4_en_cq_busy_polling(struct mlx4_en_cq *cq)
-{
-	WARN_ON(!(cq->state & MLX4_CQ_LOCKED));
-	return cq->state & CQ_USER_PEND;
-}
-#else
-static inline void mlx4_en_cq_init_lock(struct mlx4_en_cq *cq)
-{
-}
-
-static inline bool mlx4_en_cq_lock_napi(struct mlx4_en_cq *cq)
-{
-	return true;
-}
-
-static inline bool mlx4_en_cq_unlock_napi(struct mlx4_en_cq *cq)
-{
-	return false;
-}
-
-static inline bool mlx4_en_cq_lock_poll(struct mlx4_en_cq *cq)
-{
-	return false;
-}
-
-static inline bool mlx4_en_cq_unlock_poll(struct mlx4_en_cq *cq)
-{
-	return false;
-}
-
-static inline bool mlx4_en_cq_busy_polling(struct mlx4_en_cq *cq)
-{
-	return false;
-}
-#endif /* CONFIG_NET_RX_BUSY_POLL */
-
 #define MLX4_EN_WOL_DO_MODIFY (1ULL << 63)
 
 void mlx4_en_update_loopback_state(struct net_device *dev,

commit 5865316c9db31e863d4baef04dc86957d7fdae7f
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Nov 18 06:30:51 2015 -0800

    mlx4: mlx4_en_low_latency_recv() called with BH disabled
    
    mlx4_en_low_latency_recv() is called with BH disabled,
    as other ndo_busy_poll() methods.
    
    No need for spin_lock_bh()/spin_unlock_bh()
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index c41f15102ae0..965c8f016ac4 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -660,11 +660,12 @@ static inline bool mlx4_en_cq_unlock_napi(struct mlx4_en_cq *cq)
 	return rc;
 }
 
-/* called from mlx4_en_low_latency_poll() */
+/* called from mlx4_en_low_latency_recv(), BH are disabled */
 static inline bool mlx4_en_cq_lock_poll(struct mlx4_en_cq *cq)
 {
 	int rc = true;
-	spin_lock_bh(&cq->poll_lock);
+
+	spin_lock(&cq->poll_lock);
 	if ((cq->state & MLX4_CQ_LOCKED)) {
 		struct net_device *dev = cq->dev;
 		struct mlx4_en_priv *priv = netdev_priv(dev);
@@ -676,7 +677,7 @@ static inline bool mlx4_en_cq_lock_poll(struct mlx4_en_cq *cq)
 	} else
 		/* preserve yield marks */
 		cq->state |= MLX4_EN_CQ_STATE_POLL;
-	spin_unlock_bh(&cq->poll_lock);
+	spin_unlock(&cq->poll_lock);
 	return rc;
 }
 
@@ -684,13 +685,14 @@ static inline bool mlx4_en_cq_lock_poll(struct mlx4_en_cq *cq)
 static inline bool mlx4_en_cq_unlock_poll(struct mlx4_en_cq *cq)
 {
 	int rc = false;
-	spin_lock_bh(&cq->poll_lock);
+
+	spin_lock(&cq->poll_lock);
 	WARN_ON(cq->state & (MLX4_EN_CQ_STATE_NAPI));
 
 	if (cq->state & MLX4_EN_CQ_STATE_POLL_YIELD)
 		rc = true;
 	cq->state = MLX4_EN_CQ_STATE_IDLE;
-	spin_unlock_bh(&cq->poll_lock);
+	spin_unlock(&cq->poll_lock);
 	return rc;
 }
 

commit 74194fb9c80cedb3130d26802c52deec3caebc75
Author: Maor Gottlieb <maorg@mellanox.com>
Date:   Thu Oct 15 14:44:39 2015 +0300

    net/mlx4_en: Implement mcast loopback prevention for ETH qps
    
    Set the mcast loopback prevention bit in the QPC for ETH MLX QPs (not
    RSS QPs), when the firmware supports this feature. In addition, all rx
    ring QPs need to be updated in order not to enforce loopback checks.
    This prevents getting packets we sent both from the network stack and
    the HCA. Loopback prevention is done by comparing the counter indices of
    the sent and receiving QPs. If they're equal, packets aren't
    loopback-ed.
    
    Signed-off-by: Maor Gottlieb <maorg@mellanox.com>
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index defcf8c395bf..c41f15102ae0 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -798,7 +798,8 @@ void mlx4_en_fill_qp_context(struct mlx4_en_priv *priv, int size, int stride,
 void mlx4_en_sqp_event(struct mlx4_qp *qp, enum mlx4_event event);
 int mlx4_en_map_buffer(struct mlx4_buf *buf);
 void mlx4_en_unmap_buffer(struct mlx4_buf *buf);
-
+int mlx4_en_change_mcast_lb(struct mlx4_en_priv *priv, struct mlx4_qp *qp,
+			    int loopback);
 void mlx4_en_calc_rx_buf(struct net_device *dev);
 int mlx4_en_config_rss_steer(struct mlx4_en_priv *priv);
 void mlx4_en_release_rss_steer(struct mlx4_en_priv *priv);

commit e38af4faf01d0b35df6995fb395e5fa4a4898289
Author: Hadar Hen Zion <hadarh@mellanox.com>
Date:   Mon Jul 27 14:46:34 2015 +0300

    net/mlx4_en: Add support for hardware accelerated 802.1ad vlan
    
    To enable device support in accelerated 802.1ad vlan, the port
    capability "packet has vlan enable" (phv_en) should be set.
    Firmware won't work properly, in case phv_en is not set.
    
    The user can enable "phv_en" port capability with the new ethtool
    private flag phv-bit. The phv-bit private flag default value is OFF,
    users who are interested in 802.1ad hardware acceleration should turn ON
    the phv-bit private flag:
    $ ethtool --set-priv-flags eth1 phv-bit on
    
    Once the private flag is set, the device is ready for 802.1ad vlan
    acceleration.
    
    The user should also change the interface device features and turn on
    "tx-vlan-stag-hw-insert" which is off by default:
    $ ethtool -K eth1  tx-vlan-stag-hw-insert on
    
    "phv-bit" private flag setting is available only for Physical
    Functions(PF), the Virtual Function (VF) will be able to use the feature
    by setting "tx-vlan-stag-hw-insert" ethtool device feature only if the
    feature was enabled by the Hypervisor.
    
    Signed-off-by: Hadar Hen Zion <hadarh@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 666d1669eb52..defcf8c395bf 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -95,6 +95,7 @@
  */
 
 #define MLX4_EN_PRIV_FLAGS_BLUEFLAME 1
+#define MLX4_EN_PRIV_FLAGS_PHV	     2
 
 #define MLX4_EN_WATCHDOG_TIMEOUT	(15 * HZ)
 

commit 488a9b48e398b157703766e2cd91ea45ac6997c5
Author: Ido Shamay <idos@mellanox.com>
Date:   Thu Jun 25 11:29:42 2015 +0300

    net/mlx4_en: Wake TX queues only when there's enough room
    
    Indication of a single completed packet, marked by txbbs_skipped
    being bigger then zero, in not enough in order to wake up a
    stopped TX queue. The completed packet may contain a single TXBB,
    while next packet to be sent (after the wake up) may have multiple
    TXBBs (LSO/TSO packets for example), causing overflow in queue followed
    by WQE corruption and TX queue timeout.
    Instead, wake the stopped queue only when there's enough room for the
    worst case (maximum sized WQE) packet that we should need to handle after
    the queue is opened again.
    
    Also created an helper routine - mlx4_en_is_tx_ring_full, which checks
    if the current TX ring is full or not. It provides better code readability
    and removes code duplication.
    
    Signed-off-by: Ido Shamay <idos@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 32134bd98fe0..666d1669eb52 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -279,6 +279,7 @@ struct mlx4_en_tx_ring {
 	u32			size; /* number of TXBBs */
 	u32			size_mask;
 	u16			stride;
+	u32			full_size;
 	u16			cqn;	/* index of port CQ associated with this ring */
 	u32			buf_size;
 	__be32			doorbell_qpn;

commit 0eb08514fdbdcd16fd6870680cd638f203662e9d
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Thu Jun 25 11:29:41 2015 +0300

    net/mlx4_en: Release TX QP when destroying TX ring
    
    TX ring QP wasn't released at mlx4_en_destroy_tx_ring. Instead, the code
    used the deprecated base_tx_qpn field. Move TX QP release to
    mlx4_en_destroy_tx_ring and remove the base_tx_qpn field.
    
    Fixes: ddae0349fdb7 ('net/mlx4: Change QP allocation scheme')
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index d5f9adb6a784..32134bd98fe0 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -580,7 +580,6 @@ struct mlx4_en_priv {
 	int vids[128];
 	bool wol;
 	struct device *ddev;
-	int base_tx_qpn;
 	struct hlist_head mac_hash[MLX4_EN_MAC_HASH_SIZE];
 	struct hwtstamp_config hwtstamp_config;
 	u32 counter_index;

commit b42de4d01264fa84d8c9e04a18753a6c255567b5
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Mon Jun 15 17:59:06 2015 +0300

    net/mlx4_en: Show PF own statistics via ethtool
    
    Allow the user to observe the PF own statistics using ethtool with pf_
    prefixed counter names.
    
    Those counters are the PF statistics out of the overall port statistics.
    Every PF QP is attached to a counter and the summary of those counters
    is the PF statistics.
    
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Hadar Hen Zion <hadarh@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index f6c3e128cc0c..d5f9adb6a784 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -566,6 +566,7 @@ struct mlx4_en_priv {
 #endif
 	struct mlx4_en_perf_stats pstats;
 	struct mlx4_en_pkt_stats pkstats;
+	struct mlx4_en_counter_stats pf_stats;
 	struct mlx4_en_flow_stats_rx rx_priority_flowstats[MLX4_NUM_PRIORITIES];
 	struct mlx4_en_flow_stats_tx tx_priority_flowstats[MLX4_NUM_PRIORITIES];
 	struct mlx4_en_flow_stats_rx rx_flowstats;

commit 6de5f7f6a1fa2288552d46b3effbb6d5571413e5
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Mon Jun 15 17:59:02 2015 +0300

    net/mlx4_core: Allocate default counter per port
    
    Default counter per port will be allocated at the mlx4 core driver load.
    
    Every QP opened by the Ethernet driver will be attached to the port's default
    counter.  This is an infrastructure step to collect VF statistics from the PF.
    
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Hadar Hen Zion <hadarh@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index edd8fd69ec9a..f6c3e128cc0c 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -582,6 +582,7 @@ struct mlx4_en_priv {
 	int base_tx_qpn;
 	struct hlist_head mac_hash[MLX4_EN_MAC_HASH_SIZE];
 	struct hwtstamp_config hwtstamp_config;
+	u32 counter_index;
 
 #ifdef CONFIG_MLX4_EN_DCB
 	struct ieee_ets ets;

commit c66fa19c405a36673d4aab13658c8246413d5c0f
Author: Matan Barak <matanb@mellanox.com>
Date:   Sun May 31 09:30:16 2015 +0300

    net/mlx4: Add EQ pool
    
    Previously, mlx4_en allocated EQs and used them exclusively.
    This affected RoCE performance, as applications which are
    events sensitive were limited to use only the legacy EQs.
    
    Change that by introducing an EQ pool. This pool is managed
    by mlx4_core. EQs are assigned to ports (when there are limited
    number of EQs, multiple ports could be assigned to the same EQs).
    
    An exception to this rule is the ASYNC EQ which handles various events.
    
    Legacy EQs are completely removed as all EQs could be shared.
    
    When a consumer (mlx4_ib/mlx4_en) requests an EQ, it asks for
    EQ serving on a specific port. The core driver calculates which
    EQ should be assigned to that request.
    
    Because IRQs are shared between IB and Ethernet modules, their
    names only include the PCI device BDF address.
    
    Signed-off-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Ido Shamay <idos@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index d021f079f181..edd8fd69ec9a 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -338,7 +338,7 @@ struct mlx4_en_cq {
 	struct napi_struct	napi;
 	int size;
 	int buf_size;
-	unsigned vector;
+	int vector;
 	enum cq_type is_tx;
 	u16 moder_time;
 	u16 moder_cnt;

commit 07841f9d94c11afe00c0498cf242edf4075729f4
Author: Ido Shamay <idos@mellanox.com>
Date:   Thu Apr 30 17:32:46 2015 +0300

    net/mlx4_en: Schedule napi when RX buffers allocation fails
    
    When system is out of memory, refilling of RX buffers fails while
    the driver continue to pass the received packets to the kernel stack.
    At some point, when all RX buffers deplete, driver may fall into a
    sleep, and not recover when memory for new RX buffers is once again
    availible. This is because hardware does not have valid descriptors,
    so no interrupt will be generated for the driver to return to work
    in napi context. Fix it by schedule the napi poll function from
    stats_task delayed workqueue, as long as the allocations fail.
    
    Signed-off-by: Ido Shamay <idos@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 9de30216b146..d021f079f181 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -774,6 +774,7 @@ int mlx4_en_activate_tx_ring(struct mlx4_en_priv *priv,
 void mlx4_en_deactivate_tx_ring(struct mlx4_en_priv *priv,
 				struct mlx4_en_tx_ring *ring);
 void mlx4_en_set_num_rx_rings(struct mlx4_en_dev *mdev);
+void mlx4_en_recover_from_oom(struct mlx4_en_priv *priv);
 int mlx4_en_create_rx_ring(struct mlx4_en_priv *priv,
 			   struct mlx4_en_rx_ring **pring,
 			   u32 size, u16 stride, int node);

commit 51af33cfed248dc8f36fa82df06b85e10038a01e
Author: Ido Shamay <idos@mellanox.com>
Date:   Thu Apr 2 16:31:20 2015 +0300

    net/mlx4_en: Add interface identify support
    
    Add support for the interface ethtool identify feature.
    
    Make the physical port LED to blink with green and yellow colors.
    
    The device handles the LED blink by itself (synchrous use of
    set_phys_id), by returning 0 to ETHTOOL_ID_ACTIVE command.
    
    Signed-off-by: Eyal Grossman <eyalgr@mellanox.com>
    Signed-off-by: Ido Shamay <idos@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 67eeea244eff..9de30216b146 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -482,6 +482,7 @@ enum {
 	MLX4_EN_FLAG_RX_CSUM_NON_TCP_UDP	= (1 << 5),
 };
 
+#define PORT_BEACON_MAX_LIMIT (65535)
 #define MLX4_EN_MAC_HASH_SIZE (1 << BITS_PER_BYTE)
 #define MLX4_EN_MAC_HASH_IDX 5
 

commit 0b131561a7d639abb0a194d2d8fae839ce3b99e9
Author: Matan Barak <matanb@mellanox.com>
Date:   Mon Mar 30 17:45:25 2015 +0300

    net/mlx4_en: Add Flow control statistics display via ethtool
    
    Flow control per priority and Global pause counters are now visible via
    ethtool.  The counters shows statistics regarding pauses in the device.
    
    Signed-off-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Shani Michaeli <shanim@mellanox.com>
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Hadar Hen Zion <hadarh@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index d5d971a408f2..67eeea244eff 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -565,6 +565,10 @@ struct mlx4_en_priv {
 #endif
 	struct mlx4_en_perf_stats pstats;
 	struct mlx4_en_pkt_stats pkstats;
+	struct mlx4_en_flow_stats_rx rx_priority_flowstats[MLX4_NUM_PRIORITIES];
+	struct mlx4_en_flow_stats_tx tx_priority_flowstats[MLX4_NUM_PRIORITIES];
+	struct mlx4_en_flow_stats_rx rx_flowstats;
+	struct mlx4_en_flow_stats_tx tx_flowstats;
 	struct mlx4_en_port_stats port_stats;
 	struct mlx4_en_stats_bitmap stats_bitmap;
 	struct list_head mc_list;
@@ -736,7 +740,9 @@ int mlx4_en_start_port(struct net_device *dev);
 void mlx4_en_stop_port(struct net_device *dev, int detach);
 
 void mlx4_en_set_stats_bitmap(struct mlx4_dev *dev,
-			      struct mlx4_en_stats_bitmap *stats_bitmap);
+			      struct mlx4_en_stats_bitmap *stats_bitmap,
+			      u8 rx_ppp, u8 rx_pause,
+			      u8 tx_ppp, u8 tx_pause);
 
 void mlx4_en_free_resources(struct mlx4_en_priv *priv);
 int mlx4_en_alloc_resources(struct mlx4_en_priv *priv);
@@ -823,7 +829,10 @@ void mlx4_en_ptp_overflow_check(struct mlx4_en_dev *mdev);
 int mlx4_en_reset_config(struct net_device *dev,
 			 struct hwtstamp_config ts_config,
 			 netdev_features_t new_features);
-
+void mlx4_en_update_pfc_stats_bitmap(struct mlx4_dev *dev,
+				     struct mlx4_en_stats_bitmap *stats_bitmap,
+				     u8 rx_ppp, u8 rx_pause,
+				     u8 tx_ppp, u8 tx_pause);
 int mlx4_en_netdev_event(struct notifier_block *this,
 			 unsigned long event, void *ptr);
 

commit 3da8a36cc5c2a172bb42f8dc89638f5b41d7d7a6
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Mon Mar 30 17:45:24 2015 +0300

    net/mlx4_en: Protect access to the statistics bitmap
    
    This will allow parallel access to the statistics bitmap.
    A pre-step for adding PFC counters, where the statistics bitmap
    can be dynamically changed when modifying the PFC setting.
    
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Hadar Hen Zion <hadarh@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index a612bfd921f7..d5d971a408f2 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -485,6 +485,11 @@ enum {
 #define MLX4_EN_MAC_HASH_SIZE (1 << BITS_PER_BYTE)
 #define MLX4_EN_MAC_HASH_IDX 5
 
+struct mlx4_en_stats_bitmap {
+	DECLARE_BITMAP(bitmap, NUM_ALL_STATS);
+	struct mutex mutex; /* for mutual access to stats bitmap */
+};
+
 struct mlx4_en_priv {
 	struct mlx4_en_dev *mdev;
 	struct mlx4_en_port_profile *prof;
@@ -561,7 +566,7 @@ struct mlx4_en_priv {
 	struct mlx4_en_perf_stats pstats;
 	struct mlx4_en_pkt_stats pkstats;
 	struct mlx4_en_port_stats port_stats;
-	DECLARE_BITMAP(stats_bitmap, NUM_ALL_STATS);
+	struct mlx4_en_stats_bitmap stats_bitmap;
 	struct list_head mc_list;
 	struct list_head curr_list;
 	u64 broadcast_id;
@@ -731,7 +736,7 @@ int mlx4_en_start_port(struct net_device *dev);
 void mlx4_en_stop_port(struct net_device *dev, int detach);
 
 void mlx4_en_set_stats_bitmap(struct mlx4_dev *dev,
-			      unsigned long *stats_bitmap);
+			      struct mlx4_en_stats_bitmap *stats_bitmap);
 
 void mlx4_en_free_resources(struct mlx4_en_priv *priv);
 int mlx4_en_alloc_resources(struct mlx4_en_priv *priv);

commit 6fcd27354b36fb9234aabeecde337b40d5a16842
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Mon Mar 30 17:45:23 2015 +0300

    net/mlx4_en: Support general selective view of ethtool statistics
    
    The driver uses a bitmask to indicate which statistics should be
    displayed to the user in ethtool. The bitmask is u64, therefore we are
    limited for a selective view of up to 64 statistics. Extend the bitmap
    in order to show more than 64 statistics.
    
    In addition, add packet statistics to the ethtool display for PF.
    
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Hadar Hen Zion <hadarh@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index af3d9b79277c..a612bfd921f7 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -561,7 +561,7 @@ struct mlx4_en_priv {
 	struct mlx4_en_perf_stats pstats;
 	struct mlx4_en_pkt_stats pkstats;
 	struct mlx4_en_port_stats port_stats;
-	u64 stats_bitmap;
+	DECLARE_BITMAP(stats_bitmap, NUM_ALL_STATS);
 	struct list_head mc_list;
 	struct list_head curr_list;
 	u64 broadcast_id;
@@ -730,7 +730,8 @@ int mlx4_en_init_netdev(struct mlx4_en_dev *mdev, int port,
 int mlx4_en_start_port(struct net_device *dev);
 void mlx4_en_stop_port(struct net_device *dev, int detach);
 
-void mlx4_en_set_stats_bitmap(struct mlx4_dev *dev, u64 *stats_bitmap);
+void mlx4_en_set_stats_bitmap(struct mlx4_dev *dev,
+			      unsigned long *stats_bitmap);
 
 void mlx4_en_free_resources(struct mlx4_en_priv *priv);
 int mlx4_en_alloc_resources(struct mlx4_en_priv *priv);

commit ffa88f37ffeaac398be68f9678b0e6046a5ba7f6
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Mon Mar 30 17:45:22 2015 +0300

    net/mlx4_en: Move statistics bitmap setting to the Ethernet driver
    
    The statistics bitmap belongs to the Ethernet driver, move it there.
    
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Hadar Hen Zion <hadarh@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 6b379a2df4a0..af3d9b79277c 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -730,6 +730,8 @@ int mlx4_en_init_netdev(struct mlx4_en_dev *mdev, int port,
 int mlx4_en_start_port(struct net_device *dev);
 void mlx4_en_stop_port(struct net_device *dev, int detach);
 
+void mlx4_en_set_stats_bitmap(struct mlx4_dev *dev, u64 *stats_bitmap);
+
 void mlx4_en_free_resources(struct mlx4_en_priv *priv);
 int mlx4_en_alloc_resources(struct mlx4_en_priv *priv);
 

commit b4b6e842fc590de809a2f5af472a4ba64999e6b1
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Mon Mar 30 17:45:21 2015 +0300

    net/mlx4_en: Create new header file for all statistics info
    
    Add mlx4_stats.h file and move there all statistics structs and marcos.
    
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Hadar Hen Zion <hadarh@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 8ad241bbcf25..6b379a2df4a0 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -55,6 +55,7 @@
 #include <linux/mlx4/cmd.h>
 
 #include "en_port.h"
+#include "mlx4_stats.h"
 
 #define DRV_NAME	"mlx4_en"
 #define DRV_VERSION	"2.2-1"
@@ -171,7 +172,6 @@ enum {
 /* Number of samples to 'average' */
 #define AVG_SIZE			128
 #define AVG_FACTOR			1024
-#define NUM_PERF_STATS			NUM_PERF_COUNTERS
 
 #define INC_PERF_COUNTER(cnt)		(++(cnt))
 #define ADD_PERF_COUNTER(cnt, add)	((cnt) += (add))
@@ -182,7 +182,6 @@ enum {
 
 #else
 
-#define NUM_PERF_STATS			0
 #define INC_PERF_COUNTER(cnt)		do {} while (0)
 #define ADD_PERF_COUNTER(cnt, add)	do {} while (0)
 #define AVG_PERF_COUNTER(cnt, sample)	do {} while (0)
@@ -435,37 +434,6 @@ struct mlx4_en_port_state {
 	u32 flags;
 };
 
-struct mlx4_en_pkt_stats {
-	unsigned long broadcast;
-	unsigned long rx_prio[8];
-	unsigned long tx_prio[8];
-#define NUM_PKT_STATS		17
-};
-
-struct mlx4_en_port_stats {
-	unsigned long tso_packets;
-	unsigned long xmit_more;
-	unsigned long queue_stopped;
-	unsigned long wake_queue;
-	unsigned long tx_timeout;
-	unsigned long rx_alloc_failed;
-	unsigned long rx_chksum_good;
-	unsigned long rx_chksum_none;
-	unsigned long rx_chksum_complete;
-	unsigned long tx_chksum_offload;
-#define NUM_PORT_STATS		10
-};
-
-struct mlx4_en_perf_stats {
-	u32 tx_poll;
-	u64 tx_pktsz_avg;
-	u32 inflight_avg;
-	u16 tx_coal_avg;
-	u16 rx_coal_avg;
-	u32 napi_quota;
-#define NUM_PERF_COUNTERS		6
-};
-
 enum mlx4_en_mclist_act {
 	MCLIST_NONE,
 	MCLIST_REM,

commit 0fa74a4be48e0f810d3dc6ddbc9d6ac7e86cbee8
Merge: 6626af692692 4de930efc23b
Author: David S. Miller <davem@davemloft.net>
Date:   Fri Mar 20 18:51:09 2015 -0400

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Conflicts:
            drivers/net/ethernet/emulex/benet/be_main.c
            net/core/sysctl_net_core.c
            net/ipv4/inet_diag.c
    
    The be_main.c conflict resolution was really tricky.  The conflict
    hunks generated by GIT were very unhelpful, to say the least.  It
    split functions in half and moved them around, when the real actual
    conflict only existed solely inside of one function, that being
    be_map_pci_bars().
    
    So instead, to resolve this, I checked out be_main.c from the top
    of net-next, then I applied the be_main.c changes from 'net' since
    the last time I merged.  And this worked beautifully.
    
    The inet_diag.c and sysctl_net_core.c conflicts were simple
    overlapping changes, and were easily to resolve.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit a16f3565703cfc3094938fb3c979cbb90f6d9eb4
Author: Eran Ben Elisha <eranbe@mellanox.com>
Date:   Wed Mar 18 16:51:36 2015 +0200

    net/mlx4_en: Fix off-by-one in ethtool statistics display
    
    NUM_PORT_STATS was 9 instead of 10, which caused off-by-one bug when
    displaying the statistics starting from tx_chksum_offload in ethtool.
    
    Fixes: f8c6455bb04b ('net/mlx4_en: Extend checksum offloading by CHECKSUM COMPLETE')
    Signed-off-by: Eran Ben Elisha <eranbe@mellanox.com>
    Signed-off-by: Hadar Hen Zion <hadarh@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 2a8268e6be15..ebbe244e80dd 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -453,7 +453,7 @@ struct mlx4_en_port_stats {
 	unsigned long rx_chksum_none;
 	unsigned long rx_chksum_complete;
 	unsigned long tx_chksum_offload;
-#define NUM_PORT_STATS		9
+#define NUM_PORT_STATS		10
 };
 
 struct mlx4_en_perf_stats {

commit 708b869bf56e58b0c41460ba7bf363bf50f330c2
Author: Shani Michaeli <shanim@mellanox.com>
Date:   Thu Mar 5 20:16:13 2015 +0200

    net/mlx4_en: Add QCN parameters and statistics handling
    
    Implement the IEEE DCB handlers for set/get QCN parameters and
    statistics reading per TC.
    
    Signed-off-by: Shani Michaeli <shanim@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 2a8268e6be15..94553b501c76 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -608,6 +608,7 @@ struct mlx4_en_priv {
 #ifdef CONFIG_MLX4_EN_DCB
 	struct ieee_ets ets;
 	u16 maxrate[IEEE_8021QAZ_MAX_TCS];
+	enum dcbnl_cndd_states cndd_state[IEEE_8021QAZ_MAX_TCS];
 #endif
 #ifdef CONFIG_RFS_ACCEL
 	spinlock_t filters_lock;

commit 5da0354726e4a6ae2e25c1fa2feb77585d997b05
Author: Moni Shoua <monis@mellanox.com>
Date:   Tue Feb 3 16:48:34 2015 +0200

    net/mlx4_en: Port aggregation configuration
    
    Capture NETDEV events generated by the bonding driver and based on that
    make decisions of how to configure port aggregation in the mlx4 core driver.
    
    This includes setting the V2P port table and re-creating the interested
    interfaces in bonded/non-bonded mode.
    
    Signed-off-by: Moni Shoua <monis@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 944a112dff37..2a8268e6be15 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -390,6 +390,7 @@ struct mlx4_en_dev {
 	struct pci_dev		*pdev;
 	struct mutex		state_lock;
 	struct net_device       *pndev[MLX4_MAX_PORTS + 1];
+	struct net_device       *upper[MLX4_MAX_PORTS + 1];
 	u32                     port_cnt;
 	bool			device_up;
 	struct mlx4_en_profile  profile;
@@ -410,6 +411,7 @@ struct mlx4_en_dev {
 	unsigned long		overflow_period;
 	struct ptp_clock	*ptp_clock;
 	struct ptp_clock_info	ptp_clock_info;
+	struct notifier_block	nb;
 };
 
 
@@ -845,6 +847,9 @@ int mlx4_en_reset_config(struct net_device *dev,
 			 struct hwtstamp_config ts_config,
 			 netdev_features_t new_features);
 
+int mlx4_en_netdev_event(struct notifier_block *this,
+			 unsigned long event, void *ptr);
+
 /*
  * Functions for time stamping
  */

commit ddae0349fdb78bcc5e7219061847012aa1a29069
Author: Eugenia Emantayev <eugenia@mellanox.co.il>
Date:   Thu Dec 11 10:57:54 2014 +0200

    net/mlx4: Change QP allocation scheme
    
    When using BF (Blue-Flame), the QPN overrides the VLAN, CV, and SV fields
    in the WQE. Thus, BF may only be used for QPNs with bits 6,7 unset.
    
    The current Ethernet driver code reserves a Tx QP range with 256b alignment.
    
    This is wrong because if there are more than 64 Tx QPs in use,
    QPNs >= base + 65 will have bits 6/7 set.
    
    This problem is not specific for the Ethernet driver, any entity that
    tries to reserve more than 64 BF-enabled QPs should fail. Also, using
    ranges is not necessary here and is wasteful.
    
    The new mechanism introduced here will support reservation for
    "Eth QPs eligible for BF" for all drivers: bare-metal, multi-PF, and VFs
    (when hypervisors support WC in VMs). The flow we use is:
    
    1. In mlx4_en, allocate Tx QPs one by one instead of a range allocation,
       and request "BF enabled QPs" if BF is supported for the function
    
    2. In the ALLOC_RES FW command, change param1 to:
    a. param1[23:0]  - number of QPs
    b. param1[31-24] - flags controlling QPs reservation
    
    Bit 31 refers to Eth blueflame supported QPs. Those QPs must have
    bits 6 and 7 unset in order to be used in Ethernet.
    
    Bits 24-30 of the flags are currently reserved.
    
    When a function tries to allocate a QP, it states the required attributes
    for this QP. Those attributes are considered "best-effort". If an attribute,
    such as Ethernet BF enabled QP, is a must-have attribute, the function has
    to check that attribute is supported before trying to do the allocation.
    
    In a lower layer of the code, mlx4_qp_reserve_range masks out the bits
    which are unsupported. If SRIOV is used, the PF validates those attributes
    and masks out unsupported attributes as well. In order to notify VFs which
    attributes are supported, the VF uses QUERY_FUNC_CAP command. This command's
    mailbox is filled by the PF, which notifies which QP allocation attributes
    it supports.
    
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.co.il>
    Signed-off-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index ac48a8d91501..944a112dff37 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -778,7 +778,7 @@ netdev_tx_t mlx4_en_xmit(struct sk_buff *skb, struct net_device *dev);
 
 int mlx4_en_create_tx_ring(struct mlx4_en_priv *priv,
 			   struct mlx4_en_tx_ring **pring,
-			   int qpn, u32 size, u16 stride,
+			   u32 size, u16 stride,
 			   int node, int queue_index);
 void mlx4_en_destroy_tx_ring(struct mlx4_en_priv *priv,
 			     struct mlx4_en_tx_ring **pring);

commit 947cbb0ac242096d60380952ec1a1761372cba66
Author: Eyal Perry <eyalpe@mellanox.com>
Date:   Tue Dec 2 18:12:11 2014 +0200

    net/mlx4_en: Support for configurable RSS hash function
    
    The ConnectX HW is capable of using one of the following hash functions:
    Toeplitz and an XOR hash function. This patch extends the implementation
    of the mlx4_en driver set/get_rxfh callbacks to support getting and
    setting the RSS hash function used by the device.
    
    Signed-off-by: Eyal Perry <eyalpe@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index aaa7efbb9664..ac48a8d91501 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -376,7 +376,6 @@ struct mlx4_en_port_profile {
 };
 
 struct mlx4_en_profile {
-	int rss_xor;
 	int udp_rss;
 	u8 rss_mask;
 	u32 active_ports;
@@ -619,6 +618,7 @@ struct mlx4_en_priv {
 
 	u32 pflags;
 	u8 rss_key[MLX4_EN_RSS_KEY_SIZE];
+	u8 rss_hash_fn;
 };
 
 enum mlx4_en_wol {

commit bd635c354de407b3cdca9d0948c7bfdc3c0c63cf
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Nov 22 17:24:19 2014 -0800

    mlx4: fix mlx4_en_set_rxfh()
    
    mlx4_en_set_rxfh() can crash if no RSS indir table is provided.
    
    While we are at it, allow RSS key to be changed with ethtool -X
    
    Tested:
    
    myhost:~# cat /proc/sys/net/core/netdev_rss_key
    b6:89:91:f3:b2:c3:c2:90:11:e8:ce:45:e8:a9:9d:1c:f2:f6:d4:53:61:8b:26:3a:b3:9a:57:97:c3:b6:79:4d:2e:d9:66:5c:72:ed:b6:8e:c5:5d:4d:8c:22:67:30:ab:8a:6e:c3:6a
    
    myhost:~# ethtool -x eth0
    RX flow hash indirection table for eth0 with 8 RX ring(s):
        0:      0     1     2     3     4     5     6     7
    RSS hash key:
    b6:89:91:f3:b2:c3:c2:90:11:e8:ce:45:e8:a9:9d:1c:f2:f6:d4:53:61:8b:26:3a:b3:9a:57:97:c3:b6:79:4d:2e:d9:66:5c:72:ed:b6:8e
    
    myhost:~# ethtool -X eth0 hkey \
    03:0e:e2:43:fa:82:0e:73:14:2d:c0:68:21:9e:82:99:b9:84:d0:22:e2:b3:64:9f:4a:af:00:fa:cc:05:b4:4a:17:05:14:73:76:58:bd:2f
    
    myhost:~# ethtool -x eth0
    RX flow hash indirection table for eth0 with 8 RX ring(s):
        0:      0     1     2     3     4     5     6     7
    RSS hash key:
    03:0e:e2:43:fa:82:0e:73:14:2d:c0:68:21:9e:82:99:b9:84:d0:22:e2:b3:64:9f:4a:af:00:fa:cc:05:b4:4a:17:05:14:73:76:58:bd:2f
    
    Reported-by: Ben Hutchings <ben@decadent.org.uk>
    Fixes: b9d1ab7eb42e ("mlx4: use netdev_rss_key_fill() helper")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index de456749ffae..aaa7efbb9664 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -618,6 +618,7 @@ struct mlx4_en_priv {
 	__be16 vxlan_port;
 
 	u32 pflags;
+	u8 rss_key[MLX4_EN_RSS_KEY_SIZE];
 };
 
 enum mlx4_en_wol {

commit f8c6455bb04b944edb69e9b074e28efee2c56bdd
Author: Shani Michaeli <shanim@mellanox.com>
Date:   Sun Nov 9 13:51:53 2014 +0200

    net/mlx4_en: Extend checksum offloading by CHECKSUM COMPLETE
    
    When processing received traffic, pass CHECKSUM_COMPLETE status to the
    stack, with calculated checksum for non TCP/UDP packets (such
    as GRE or ICMP).
    
    Although the stack expects checksum which doesn't include the pseudo
    header, the HW adds it. To address that, we are subtracting the pseudo
    header checksum from the checksum value provided by the HW.
    
    In the IPv6 case, we also compute/add the IP header checksum which
    is not added by the HW for such packets.
    
    Cc: Jerry Chu <hkchu@google.com>
    Signed-off-by: Shani Michaeli <shanim@mellanox.com>
    Signed-off-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index ef83d127f406..de456749ffae 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -326,6 +326,7 @@ struct mlx4_en_rx_ring {
 #endif
 	unsigned long csum_ok;
 	unsigned long csum_none;
+	unsigned long csum_complete;
 	int hwtstamp_rx_filter;
 	cpumask_var_t affinity_mask;
 };
@@ -449,6 +450,7 @@ struct mlx4_en_port_stats {
 	unsigned long rx_alloc_failed;
 	unsigned long rx_chksum_good;
 	unsigned long rx_chksum_none;
+	unsigned long rx_chksum_complete;
 	unsigned long tx_chksum_offload;
 #define NUM_PORT_STATS		9
 };
@@ -507,7 +509,8 @@ enum {
 	MLX4_EN_FLAG_ENABLE_HW_LOOPBACK	= (1 << 2),
 	/* whether we need to drop packets that hardware loopback-ed */
 	MLX4_EN_FLAG_RX_FILTER_NEEDED	= (1 << 3),
-	MLX4_EN_FLAG_FORCE_PROMISC	= (1 << 4)
+	MLX4_EN_FLAG_FORCE_PROMISC	= (1 << 4),
+	MLX4_EN_FLAG_RX_CSUM_NON_TCP_UDP	= (1 << 5),
 };
 
 #define MLX4_EN_MAC_HASH_SIZE (1 << BITS_PER_BYTE)

commit 5f6e9800804758de367132a0fe9b85865d24f89b
Author: Ido Shamay <idos@mellanox.com>
Date:   Sun Nov 2 16:26:15 2014 +0200

    net/mlx4_en: Remove RX buffers alignment to IP_ALIGN
    
    When IP_ALIGN has a non zero value, hardware will write to a non aligned
    address. The only reader from this address is when copying the header
    from the first frag into the linear buffer (further access to the IP
    address will be from the linear buffer, in which the headers are
    aligned). Since the penalty of non align access by the hardware is
    greater than the software memcpy, changing the frag_align to always be 0.
    
    Signed-off-by: Ido Shamay <idos@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 6beb4d34dce0..ef83d127f406 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -481,7 +481,6 @@ struct mlx4_en_frag_info {
 	u16 frag_size;
 	u16 frag_prefix_size;
 	u16 frag_stride;
-	u16 frag_align;
 };
 
 #ifdef CONFIG_MLX4_EN_DCB

commit 7787fa661b8b9acba95ba35974b7092675baee8a
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Oct 27 11:37:42 2014 +0200

    net/mlx4_en: Add support for setting rxvlan offload OFF/ON
    
    Rename mlx4_en_timestamp_config to mlx4_en_reset_config and extend it to support
    choosing RX vlan offload configuration.
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 946754ed393f..6beb4d34dce0 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -835,6 +835,13 @@ void mlx4_en_cleanup_filters(struct mlx4_en_priv *priv);
 void mlx4_en_ex_selftest(struct net_device *dev, u32 *flags, u64 *buf);
 void mlx4_en_ptp_overflow_check(struct mlx4_en_dev *mdev);
 
+#define DEV_FEATURE_CHANGED(dev, new_features, feature) \
+	((dev->features & feature) ^ (new_features & feature))
+
+int mlx4_en_reset_config(struct net_device *dev,
+			 struct hwtstamp_config ts_config,
+			 netdev_features_t new_features);
+
 /*
  * Functions for time stamping
  */
@@ -844,9 +851,6 @@ void mlx4_en_fill_hwtstamps(struct mlx4_en_dev *mdev,
 			    u64 timestamp);
 void mlx4_en_init_timestamp(struct mlx4_en_dev *mdev);
 void mlx4_en_remove_timestamp(struct mlx4_en_dev *mdev);
-int mlx4_en_timestamp_config(struct net_device *dev,
-			     int tx_type,
-			     int rx_filter);
 
 /* Globals
  */

commit 2c762679435dc812b7031ef9a839b901827294a9
Author: Saeed Mahameed <saeedm@mellanox.com>
Date:   Mon Oct 27 11:37:40 2014 +0200

    net/mlx4_en: Use PTYS register to query ethtool settings
    
    - If dev cap MLX4_DEV_CAP_FLAG2_ETH_PROT_CTRL is ON, query PTYS register to fill ethtool settings.
    else use default values.
    - Use autoneg port cap and dev backplane autoneg cap to reprort autoneg interface capbilities.
    - Fix typo in mlx4_en_port_state struct field (transciver to transceiver).
    
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 8fef65840b3b..946754ed393f 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -421,10 +421,16 @@ struct mlx4_en_rss_map {
 	enum mlx4_qp_state indir_state;
 };
 
+enum mlx4_en_port_flag {
+	MLX4_EN_PORT_ANC = 1<<0, /* Auto-negotiation complete */
+	MLX4_EN_PORT_ANE = 1<<1, /* Auto-negotiation enabled */
+};
+
 struct mlx4_en_port_state {
 	int link_state;
 	int link_speed;
-	int transciver;
+	int transceiver;
+	u32 flags;
 };
 
 struct mlx4_en_pkt_stats {

commit 1556b8746e52501fdfaadd65837baaa63a9fa937
Author: Eric Dumazet <edumazet@google.com>
Date:   Sun Oct 5 12:35:22 2014 +0300

    net/mlx4_en: Use the new tx_copybreak to set inline threshold
    
    Instead of setting inline threshold using module parameter only on
    driver load, use set_tunable() to set it dynamically.
    No need to store the threshold per ring, using instead the netdev global
    priv->prof->inline_thold
    Initial value still is set using the module parameter, therefore
    backward compatability is kept.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index a90403000577..8fef65840b3b 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -295,7 +295,6 @@ struct mlx4_en_tx_ring {
 	bool			bf_alloced;
 	struct netdev_queue	*tx_queue;
 	int			hwtstamp_tx_type;
-	int			inline_thold;
 } ____cacheline_aligned_in_smp;
 
 struct mlx4_en_rx_desc {

commit 3d03641cb4ea050f969dd3ab34113adb95287f36
Author: Eric Dumazet <edumazet@google.com>
Date:   Sun Oct 5 12:35:13 2014 +0300

    net/mlx4_en: Avoid a cache line miss in TX completion for single frag skb's
    
    Add frag0_dma/frag0_byte_count into mlx4_en_tx_info to avoid a cache
    line miss in TX completion for frames having one dma element.  (We avoid
    reading back the tx descriptor)
    
    Note this could be extended to 2/3 dma elements later, as we have free
    room in mlx4_en_tx_info
    
    Also, mlx4_en_free_tx_desc() no longer accesses skb_shinfo(). We use a
    new nr_maps fields in mlx4_en_tx_info to avoid 2 or 3 cache misses.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index ab34461e628c..a90403000577 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -216,12 +216,15 @@ enum cq_type {
 
 struct mlx4_en_tx_info {
 	struct sk_buff *skb;
+	dma_addr_t	map0_dma;
+	u32		map0_byte_count;
 	u32		nr_txbb;
 	u32		nr_bytes;
 	u8		linear;
 	u8		data_offset;
 	u8		inl;
 	u8		ts_requested;
+	u8		nr_maps;
 } ____cacheline_aligned_in_smp;
 
 

commit 6a4e81211f475561ed87c613216f981fbef8b7fc
Author: Eric Dumazet <edumazet@google.com>
Date:   Sun Oct 5 12:35:11 2014 +0300

    net/mlx4_en: Avoid calling bswap in tx fast path
    
    - doorbell_qpn is stored in the cpu_to_be32() way to avoid bswap() in fast
      path.
    - mdev->mr.key stored in ring->mr_key to also avoid bswap() and access to
      cold cache line.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index b7bde95e05fe..ab34461e628c 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -279,7 +279,8 @@ struct mlx4_en_tx_ring {
 	u16			stride;
 	u16			cqn;	/* index of port CQ associated with this ring */
 	u32			buf_size;
-	u32			doorbell_qpn;
+	__be32			doorbell_qpn;
+	__be32			mr_key;
 	void			*buf;
 	struct mlx4_en_tx_info	*tx_info;
 	u8			*bounce_buf;

commit 98b1634941e3efb0334f794efc79702839993d86
Author: Eric Dumazet <edumazet@google.com>
Date:   Sun Oct 5 12:35:10 2014 +0300

    net/mlx4_en: Align tx path structures to cache lines
    
    Reorganize struct mlx4_en_tx_ring to have:
    - One cache line containing last_nr_txbb & cons & wake_queue, used by tx
      completion.
    - One cache line containing fields dirtied by mlx4_en_xmit()
    - Following part is read mostly and shared by cpus.
    
    Align struct mlx4_en_tx_info to a cache line
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index e54b653de3d4..b7bde95e05fe 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -216,13 +216,13 @@ enum cq_type {
 
 struct mlx4_en_tx_info {
 	struct sk_buff *skb;
-	u32 nr_txbb;
-	u32 nr_bytes;
-	u8 linear;
-	u8 data_offset;
-	u8 inl;
-	u8 ts_requested;
-};
+	u32		nr_txbb;
+	u32		nr_bytes;
+	u8		linear;
+	u8		data_offset;
+	u8		inl;
+	u8		ts_requested;
+} ____cacheline_aligned_in_smp;
 
 
 #define MLX4_EN_BIT_DESC_OWN	0x80000000
@@ -253,40 +253,46 @@ struct mlx4_en_rx_alloc {
 };
 
 struct mlx4_en_tx_ring {
+	/* cache line used and dirtied in tx completion
+	 * (mlx4_en_free_tx_buf())
+	 */
+	u32			last_nr_txbb;
+	u32			cons;
+	unsigned long		wake_queue;
+
+	/* cache line used and dirtied in mlx4_en_xmit() */
+	u32			prod ____cacheline_aligned_in_smp;
+	unsigned long		bytes;
+	unsigned long		packets;
+	unsigned long		tx_csum;
+	unsigned long		tso_packets;
+	unsigned long		xmit_more;
+	struct mlx4_bf		bf;
+	unsigned long		queue_stopped;
+
+	/* Following part should be mostly read */
+	cpumask_t		affinity_mask;
+	struct mlx4_qp		qp;
 	struct mlx4_hwq_resources wqres;
-	u32 size ; /* number of TXBBs */
-	u32 size_mask;
-	u16 stride;
-	u16 cqn;	/* index of port CQ associated with this ring */
-	u32 prod;
-	u32 cons;
-	u32 buf_size;
-	u32 doorbell_qpn;
-	void *buf;
-	struct mlx4_en_tx_info *tx_info;
-	u8 *bounce_buf;
-	u8 queue_index;
-	cpumask_t affinity_mask;
-	u32 last_nr_txbb;
-	struct mlx4_qp qp;
-	struct mlx4_qp_context context;
-	int qpn;
-	enum mlx4_qp_state qp_state;
-	struct mlx4_srq dummy;
-	unsigned long bytes;
-	unsigned long packets;
-	unsigned long tx_csum;
-	unsigned long queue_stopped;
-	unsigned long wake_queue;
-	unsigned long tso_packets;
-	unsigned long xmit_more;
-	struct mlx4_bf bf;
-	bool bf_enabled;
-	bool bf_alloced;
-	struct netdev_queue *tx_queue;
-	int hwtstamp_tx_type;
-	int inline_thold;
-};
+	u32			size; /* number of TXBBs */
+	u32			size_mask;
+	u16			stride;
+	u16			cqn;	/* index of port CQ associated with this ring */
+	u32			buf_size;
+	u32			doorbell_qpn;
+	void			*buf;
+	struct mlx4_en_tx_info	*tx_info;
+	u8			*bounce_buf;
+	struct mlx4_qp_context	context;
+	int			qpn;
+	enum mlx4_qp_state	qp_state;
+	u8			queue_index;
+	bool			bf_enabled;
+	bool			bf_alloced;
+	struct netdev_queue	*tx_queue;
+	int			hwtstamp_tx_type;
+	int			inline_thold;
+} ____cacheline_aligned_in_smp;
 
 struct mlx4_en_rx_desc {
 	/* actual number of entries depends on rx ring stride */

commit 7dfa4b414d4eec8da56e44fb2b4aea3e549b092f
Author: Eric Dumazet <edumazet@google.com>
Date:   Sun Oct 5 12:35:09 2014 +0300

    net/mlx4_en: Code cleanups in tx path
    
    - Remove unused variable ring->poll_cnt
    - No need to set some fields if using blueflame
    - Add missing const's
    - Use unlikely
    - Remove unneeded new line
    - Make some comments more precise
    - struct mlx4_bf @offset field reduced to unsigned int to save space
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 84c9d5dbfa4f..e54b653de3d4 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -263,7 +263,6 @@ struct mlx4_en_tx_ring {
 	u32 buf_size;
 	u32 doorbell_qpn;
 	void *buf;
-	u16 poll_cnt;
 	struct mlx4_en_tx_info *tx_info;
 	u8 *bounce_buf;
 	u8 queue_index;

commit 9fab426de78140dc5cb0b85bbee6042c9c3d5ca5
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Oct 2 08:24:21 2014 -0700

    mlx4: add a new xmit_more counter
    
    ethtool -S reports a new counter, tracking number of time doorbell
    was not triggered, because skb->xmit_more was set.
    
    $ ethtool -S eth0 | egrep "tx_packet|xmit_more"
         tx_packets: 2413288400
         xmit_more: 666121277
    
    I merged the tso_packet false sharing avoidance in this patch as well.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 6a4fc2394cf2..84c9d5dbfa4f 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -279,6 +279,8 @@ struct mlx4_en_tx_ring {
 	unsigned long tx_csum;
 	unsigned long queue_stopped;
 	unsigned long wake_queue;
+	unsigned long tso_packets;
+	unsigned long xmit_more;
 	struct mlx4_bf bf;
 	bool bf_enabled;
 	bool bf_alloced;
@@ -426,6 +428,7 @@ struct mlx4_en_pkt_stats {
 
 struct mlx4_en_port_stats {
 	unsigned long tso_packets;
+	unsigned long xmit_more;
 	unsigned long queue_stopped;
 	unsigned long wake_queue;
 	unsigned long tx_timeout;
@@ -433,7 +436,7 @@ struct mlx4_en_port_stats {
 	unsigned long rx_chksum_good;
 	unsigned long rx_chksum_none;
 	unsigned long tx_chksum_offload;
-#define NUM_PORT_STATS		8
+#define NUM_PORT_STATS		9
 };
 
 struct mlx4_en_perf_stats {

commit 0c87b29c3167a2cf9870e721b522651de2c72ce2
Author: Joe Perches <joe@perches.com>
Date:   Mon Sep 22 10:40:22 2014 -0700

    mellanox: Change en_print to return void
    
    No caller or macro uses the return value so make it void.
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Acked-By: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index e3d71c386da7..6a4fc2394cf2 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -842,8 +842,8 @@ extern const struct ethtool_ops mlx4_en_ethtool_ops;
  */
 
 __printf(3, 4)
-int en_print(const char *level, const struct mlx4_en_priv *priv,
-	     const char *format, ...);
+void en_print(const char *level, const struct mlx4_en_priv *priv,
+	      const char *format, ...);
 
 #define en_dbg(mlevel, priv, format, ...)				\
 do {									\

commit b1b6b4da7867d220f0da5f6686b869b304c5459b
Author: Ido Shamay <idos@mellanox.com>
Date:   Thu Sep 18 11:51:01 2014 +0300

    net/mlx4_en: Add mlx4_en_get_cqe helper
    
    This function derives the base address of the CQE from the CQE size,
    and calculates the real CQE context segment in it from the factor
    (this is like before). Before this change the code used the factor to
    calculate the base address of the CQE as well.
    
    The factor indicates in which segment of the cqe stride the cqe information
    is located. For 32-byte strides, the segment is 0, and for 64 byte strides,
    the segment is 1 (bytes 32..63). Using the factor was ok as long as we had
    only 32 and 64 byte strides. However, with larger strides, the factor is zero,
    and so cannot be used to calculate the base of the CQE.
    
    The helper uses the same method of CQE buffer pulling made by all other
    components that reads the CQE buffer (mlx4_ib driver and libmlx4).
    
    Signed-off-by: Ido Shamay <idos@mellanox.com>
    Signed-off-by: Jack Morgenstein <jackm@dev.mellanox.co.il>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 3de41be49425..e3d71c386da7 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -542,6 +542,7 @@ struct mlx4_en_priv {
 	unsigned max_mtu;
 	int base_qpn;
 	int cqe_factor;
+	int cqe_size;
 
 	struct mlx4_en_rss_map rss_map;
 	__be32 ctrl_flags;
@@ -612,6 +613,11 @@ struct mlx4_mac_entry {
 	struct rcu_head rcu;
 };
 
+static inline struct mlx4_cqe *mlx4_en_get_cqe(void *buf, int idx, int cqe_sz)
+{
+	return buf + idx * cqe_sz;
+}
+
 #ifdef CONFIG_NET_RX_BUSY_POLL
 static inline void mlx4_en_cq_init_lock(struct mlx4_en_cq *cq)
 {

commit ea1c1af1396cac9f8a1160acdac17f80e4b4f2c4
Author: Amir Vadai <amirv@mellanox.com>
Date:   Tue Jul 22 15:44:12 2014 +0300

    net/mlx4_en: Reduce memory consumption on kdump kernel
    
    When memory is limited, reduce number of rx and tx rings.
    
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 54c277412e42..3de41be49425 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -121,6 +121,7 @@ enum {
 #define MLX4_EN_MIN_TX_SIZE	(4096 / TXBB_SIZE)
 
 #define MLX4_EN_SMALL_PKT_SIZE		64
+#define MLX4_EN_MIN_TX_RING_P_UP	1
 #define MLX4_EN_MAX_TX_RING_P_UP	32
 #define MLX4_EN_NUM_UP			8
 #define MLX4_EN_DEF_TX_RING_SIZE	512

commit 0fef9d0308d4c524da716b4b669d8754594450b2
Author: Amir Vadai <amirv@mellanox.com>
Date:   Tue Jul 22 15:44:10 2014 +0300

    net/mlx4_en: Disable blueflame using ethtool private flags
    
    Enable the user to turn off the hardware feature called BlueFlame.
    Since it is something specific to mlx4_en hardware, we control
    the feature via ethtool private flags.
    
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 2b19dd1f2c5d..54c277412e42 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -93,6 +93,8 @@
  * OS related constants and tunables
  */
 
+#define MLX4_EN_PRIV_FLAGS_BLUEFLAME 1
+
 #define MLX4_EN_WATCHDOG_TIMEOUT	(15 * HZ)
 
 /* Use the maximum between 16384 and a single page */
@@ -278,6 +280,7 @@ struct mlx4_en_tx_ring {
 	unsigned long wake_queue;
 	struct mlx4_bf bf;
 	bool bf_enabled;
+	bool bf_alloced;
 	struct netdev_queue *tx_queue;
 	int hwtstamp_tx_type;
 	int inline_thold;
@@ -592,6 +595,8 @@ struct mlx4_en_priv {
 #endif
 	u64 tunnel_reg_id;
 	__be16 vxlan_port;
+
+	u32 pflags;
 };
 
 enum mlx4_en_wol {

commit 1a98c69af1ecd97bfd1f4e4539924a9192434e36
Merge: 7a575f6b907e b6603fe574af
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Jul 16 14:09:34 2014 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit fbc6daf19745b372c0d909e5d74ab02e42b70e51
Author: Amir Vadai <amirv@mellanox.com>
Date:   Tue Jul 8 11:28:12 2014 +0300

    net/mlx4_en: Ignore budget on TX napi polling
    
    It is recommended that TX work not count against the quota.
    The cost of TX packet liberation is a minute percentage of what it costs to
    process an RX frame. Furthermore, that SKB freeing makes memory available for
    other paths in the stack.
    
    Give the TX a larger budget and be more aggressive about cleaning up the Tx
    descriptors this budget could be changed using ethtool:
    $ ethtool -C eth1 tx-frames-irq <budget>
    
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 624e1939e9ee..d72a5a894fc6 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -126,6 +126,8 @@ enum {
 #define MAX_TX_RINGS			(MLX4_EN_MAX_TX_RING_P_UP * \
 					 MLX4_EN_NUM_UP)
 
+#define MLX4_EN_DEFAULT_TX_WORK		256
+
 /* Target number of packets to coalesce with interrupt moderation */
 #define MLX4_EN_RX_COAL_TARGET	44
 #define MLX4_EN_RX_COAL_TIME	0x10
@@ -543,6 +545,7 @@ struct mlx4_en_priv {
 	__be32 ctrl_flags;
 	u32 flags;
 	u8 num_tx_rings_p_up;
+	u32 tx_work_limit;
 	u32 tx_ring_num;
 	u32 rx_ring_num;
 	u32 rx_skb_size;

commit 2695bab2a6a18f31839c4e862eba3b450c0d2868
Author: Noa Osherovich <noaos@mellanox.com>
Date:   Tue Jul 8 11:25:24 2014 +0300

    net/mlx4_en: Fix mac_hash database inconsistency
    
    Using a local copy of dev_addr in mlx4_en_set_mac() to prevent dev_addr
    from being modified during error flow or when dev_addr is modified in
    another context (which is another problem that is being discussed over
    the mailing list [1]).
    Also fixing bad naming of priv->prev_mac into priv->current_mac.
    
    [1] - http://patchwork.ozlabs.org/patch/351489/
    
    Reviewed-by: Eyal Perry <eyalpe@mellanox.com>
    Signed-off-by: Noa Osherovich <noaos@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 01011d4a7cbb..7c1b5ec5378f 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -530,7 +530,7 @@ struct mlx4_en_priv {
 	int registered;
 	int allocated;
 	int stride;
-	unsigned char prev_mac[ETH_ALEN + 2];
+	unsigned char current_mac[ETH_ALEN + 2];
 	int mac_index;
 	unsigned max_mtu;
 	int base_qpn;

commit d5b8dff0073d782f3169e510fd9445f1f56994e2
Author: Yishai Hadas <yishaih@mellanox.com>
Date:   Tue Jul 8 11:25:23 2014 +0300

    net/mlx4_en: Do not count LLC/SNAP in MTU calculation
    
    LLC/SNAP 8 bytes should not be added as part of header calculation.
    If used, payload will be decreased accordingly. For MTU of 1500
    we'll set 1522 instead of 1523.
    
    Signed-off-by: Yishai Hadas <yishaih@mellanox.com>
    Reviewed-by: Liran Liss <liranl@mellanox.com>
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.com>
    
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 0e15295bedd6..01011d4a7cbb 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -152,8 +152,6 @@ enum {
 #define MLX4_EN_TX_POLL_MODER	16
 #define MLX4_EN_TX_POLL_TIMEOUT	(HZ / 4)
 
-#define ETH_LLC_SNAP_SIZE	8
-
 #define SMALL_PACKET_SIZE      (256 - NET_IP_ALIGN)
 #define HEADER_COPY_SIZE       (128 - NET_IP_ALIGN)
 #define MLX4_LOOPBACK_TEST_PAYLOAD (HEADER_COPY_SIZE - ETH_HLEN)

commit 35f6f45368632f21bd27559c44dbb1cab51d8947
Author: Amir Vadai <amirv@mellanox.com>
Date:   Sun Jun 29 11:54:55 2014 +0300

    net/mlx4_en: Don't use irq_affinity_notifier to track changes in IRQ affinity map
    
    IRQ affinity notifier can only have a single notifier - cpu_rmap
    notifier. Can't use it to track changes in IRQ affinity map.
    Detect IRQ affinity changes by comparing CPU to current IRQ affinity map
    during NAPI poll thread.
    
    CC: Thomas Gleixner <tglx@linutronix.de>
    CC: Ben Hutchings <ben@decadent.org.uk>
    Fixes: 2eacc23 ("net/mlx4_core: Enforce irq affinity changes immediatly")
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 0e15295bedd6..624e1939e9ee 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -343,6 +343,7 @@ struct mlx4_en_cq {
 #define CQ_USER_PEND (MLX4_EN_CQ_STATE_POLL | MLX4_EN_CQ_STATE_POLL_YIELD)
 	spinlock_t poll_lock; /* protects from LLS/napi conflicts */
 #endif  /* CONFIG_NET_RX_BUSY_POLL */
+	struct irq_desc *irq_desc;
 };
 
 struct mlx4_en_port_profile {

commit 9e311e77a85e37b5caec3d64c3593cd52b2cdb71
Author: Yuval Atias <yuvala@mellanox.com>
Date:   Mon Jun 9 10:24:39 2014 +0300

    net/mlx4_en: Use affinity hint
    
    The affinity hint mechanism is used by the user space
    daemon, irqbalancer, to indicate a preferred CPU mask for irqs.
    Irqbalancer can use this hint to balance the irqs between the
    cpus indicated by the mask.
    
    We wish the HCA to preferentially map the IRQs it uses to numa cores
    close to it.  To accomplish this, we use cpumask_set_cpu_local_first(), that
    sets the affinity hint according the following policy:
    First it maps IRQs to close numa cores.  If these are exhausted, the
    remaining IRQs are mapped to far numa cores.
    
    Signed-off-by: Yuval Atias <yuvala@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index b5db1bf361dc..0e15295bedd6 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -313,6 +313,7 @@ struct mlx4_en_rx_ring {
 	unsigned long csum_ok;
 	unsigned long csum_none;
 	int hwtstamp_rx_filter;
+	cpumask_var_t affinity_mask;
 };
 
 struct mlx4_en_cq {

commit 96b2e73c5471542cb9c622c4360716684f8797ed
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Jun 2 00:18:48 2014 -0700

    Revert "net/mlx4_en: Use affinity hint"
    
    This reverts commit 70a640d0dae3a9b1b222ce673eb5d92c263ddd61.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 0e15295bedd6..b5db1bf361dc 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -313,7 +313,6 @@ struct mlx4_en_rx_ring {
 	unsigned long csum_ok;
 	unsigned long csum_none;
 	int hwtstamp_rx_filter;
-	cpumask_var_t affinity_mask;
 };
 
 struct mlx4_en_cq {

commit 70a640d0dae3a9b1b222ce673eb5d92c263ddd61
Author: Yuval Atias <yuvala@mellanox.com>
Date:   Sun May 25 17:47:27 2014 +0300

    net/mlx4_en: Use affinity hint
    
    The affinity hint mechanism is used by the user space
    daemon, irqbalancer, to indicate a preferred CPU mask for irqs.
    Irqbalancer can use this hint to balance the irqs between the
    cpus indicated by the mask.
    
    We wish the HCA to preferentially map the IRQs it uses to numa cores
    close to it.  To accomplish this, we use cpumask_set_cpu_local_first(), that
    sets the affinity hint according the following policy:
    First it maps IRQs to close numa cores.  If these are exhausted, the
    remaining IRQs are mapped to far numa cores.
    
    Signed-off-by: Yuval Atias <yuvala@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index b5db1bf361dc..0e15295bedd6 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -313,6 +313,7 @@ struct mlx4_en_rx_ring {
 	unsigned long csum_ok;
 	unsigned long csum_none;
 	int hwtstamp_rx_filter;
+	cpumask_var_t affinity_mask;
 };
 
 struct mlx4_en_cq {

commit 1a91de28831a1bd913e14dacf25763f3672e24a9
Author: Joe Perches <joe@perches.com>
Date:   Wed May 7 12:52:57 2014 -0700

    mellanox: Logging message cleanups
    
    Use a more current logging style.
    
    o Coalesce formats
    o Add missing spaces for coalesced formats
    o Align arguments for modified formats
    o Add missing newlines for some logging messages
    o Use DRV_NAME as part of format instead of %s, DRV_NAME to
      reduce overall text.
    o Use ..., ##__VA_ARGS__ instead of args... in macros
    o Correct a few format typos
    o Use a single line message where appropriate
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Acked-By: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 04d9b6fe3e80..b5db1bf361dc 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -830,26 +830,26 @@ __printf(3, 4)
 int en_print(const char *level, const struct mlx4_en_priv *priv,
 	     const char *format, ...);
 
-#define en_dbg(mlevel, priv, format, arg...)			\
-do {								\
-	if (NETIF_MSG_##mlevel & priv->msg_enable)		\
-		en_print(KERN_DEBUG, priv, format, ##arg);	\
+#define en_dbg(mlevel, priv, format, ...)				\
+do {									\
+	if (NETIF_MSG_##mlevel & (priv)->msg_enable)			\
+		en_print(KERN_DEBUG, priv, format, ##__VA_ARGS__);	\
 } while (0)
-#define en_warn(priv, format, arg...)			\
-	en_print(KERN_WARNING, priv, format, ##arg)
-#define en_err(priv, format, arg...)			\
-	en_print(KERN_ERR, priv, format, ##arg)
-#define en_info(priv, format, arg...)			\
-	en_print(KERN_INFO, priv, format, ## arg)
-
-#define mlx4_err(mdev, format, arg...)			\
-	pr_err("%s %s: " format, DRV_NAME,		\
-	       dev_name(&mdev->pdev->dev), ##arg)
-#define mlx4_info(mdev, format, arg...)			\
-	pr_info("%s %s: " format, DRV_NAME,		\
-		dev_name(&mdev->pdev->dev), ##arg)
-#define mlx4_warn(mdev, format, arg...)			\
-	pr_warning("%s %s: " format, DRV_NAME,		\
-		   dev_name(&mdev->pdev->dev), ##arg)
+#define en_warn(priv, format, ...)					\
+	en_print(KERN_WARNING, priv, format, ##__VA_ARGS__)
+#define en_err(priv, format, ...)					\
+	en_print(KERN_ERR, priv, format, ##__VA_ARGS__)
+#define en_info(priv, format, ...)					\
+	en_print(KERN_INFO, priv, format, ##__VA_ARGS__)
+
+#define mlx4_err(mdev, format, ...)					\
+	pr_err(DRV_NAME " %s: " format,					\
+	       dev_name(&(mdev)->pdev->dev), ##__VA_ARGS__)
+#define mlx4_info(mdev, format, ...)					\
+	pr_info(DRV_NAME " %s: " format,				\
+		dev_name(&(mdev)->pdev->dev), ##__VA_ARGS__)
+#define mlx4_warn(mdev, format, ...)					\
+	pr_warn(DRV_NAME " %s: " format,				\
+		dev_name(&(mdev)->pdev->dev), ##__VA_ARGS__)
 
 #endif

commit c98235cb8584a72e95786e17d695a8e5fafcd766
Author: Chris Mason <clm@fb.com>
Date:   Tue Apr 15 18:09:24 2014 -0400

    mlx4_en: don't use napi_synchronize inside mlx4_en_netpoll
    
    The mlx4 driver is triggering schedules while atomic inside
    mlx4_en_netpoll:
    
            spin_lock_irqsave(&cq->lock, flags);
            napi_synchronize(&cq->napi);
                    ^^^^^ msleep here
            mlx4_en_process_rx_cq(dev, cq, 0);
            spin_unlock_irqrestore(&cq->lock, flags);
    
    This was part of a patch by Alexander Guller from Mellanox in 2011,
    but it still isn't upstream.
    
    Signed-off-by: Chris Mason <clm@fb.com>
    cc: stable@vger.kernel.org
    Acked-By: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 7a733c287744..04d9b6fe3e80 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -319,7 +319,6 @@ struct mlx4_en_cq {
 	struct mlx4_cq          mcq;
 	struct mlx4_hwq_resources wqres;
 	int                     ring;
-	spinlock_t              lock;
 	struct net_device      *dev;
 	struct napi_struct	napi;
 	int size;

commit a66132f3eb514f42c49a3e8f57aab2ccd0360f06
Author: Or Gerlitz <ogerlitz@mellanox.com>
Date:   Tue Apr 1 11:27:13 2014 +0300

    net/mlx4: Set proper build dependancy with vxlan
    
    Make sure that vxlan_get_rx_port() is present in the kernel build in a manner
    consistent with mlx4, else mlx4 can be made built-in where vxlan a module and
    the phase of the build linking fails. Add CONFIG_MLX4_EN_VXLAN for that.
    
    Also, #ifdef the advertizement and implementation of the mlx4 vxlan ndo
    calls and related code under this config directive.
    
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 36fc2a2b24c3..7a733c287744 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -559,8 +559,10 @@ struct mlx4_en_priv {
 	struct work_struct linkstate_task;
 	struct delayed_work stats_task;
 	struct delayed_work service_task;
+#ifdef CONFIG_MLX4_EN_VXLAN
 	struct work_struct vxlan_add_task;
 	struct work_struct vxlan_del_task;
+#endif
 	struct mlx4_en_perf_stats pstats;
 	struct mlx4_en_pkt_stats pkstats;
 	struct mlx4_en_port_stats port_stats;

commit 1b136de120dda625109f2afe1e3d04e256be9ec1
Author: Or Gerlitz <ogerlitz@mellanox.com>
Date:   Thu Mar 27 14:02:04 2014 +0200

    net/mlx4: Implement vxlan ndo calls
    
    Add implementation for the add/del vxlan port ndo calls, using the
    CONFIG_DEV firmware command.
    
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 69e1f36858e0..36fc2a2b24c3 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -559,6 +559,8 @@ struct mlx4_en_priv {
 	struct work_struct linkstate_task;
 	struct delayed_work stats_task;
 	struct delayed_work service_task;
+	struct work_struct vxlan_add_task;
+	struct work_struct vxlan_del_task;
 	struct mlx4_en_perf_stats pstats;
 	struct mlx4_en_pkt_stats pkstats;
 	struct mlx4_en_port_stats port_stats;
@@ -585,6 +587,7 @@ struct mlx4_en_priv {
 	struct hlist_head filter_hash[1 << MLX4_EN_FILTER_HASH_SHIFT];
 #endif
 	u64 tunnel_reg_id;
+	__be16 vxlan_port;
 };
 
 enum mlx4_en_wol {

commit 67ddc87f162e2d0e29db2b6b21c5a3fbcb8be206
Merge: 6092c79fd00c c3bebc71c4bc
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Mar 5 20:32:02 2014 -0500

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Conflicts:
            drivers/net/wireless/ath/ath9k/recv.c
            drivers/net/wireless/mwifiex/pcie.c
            net/ipv6/sit.c
    
    The SIT driver conflict consists of a bug fix being done by hand
    in 'net' (missing u64_stats_init()) whilst in 'net-next' a helper
    was created (netdev_alloc_pcpu_stats()) which takes care of this.
    
    The two wireless conflicts were overlapping changes.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 9813337a4b16ea5b1701b1d00f7e410f5decdfa5
Author: Eugenia Emantayev <eugenia@mellanox.com>
Date:   Sun Mar 2 10:25:01 2014 +0200

    net/mlx4: Replace mlx4_en_mac_to_u64() with mlx4_mac_to_u64()
    
    Currently, the EN driver uses a private static function
    mlx4_en_mac_to_u64(). Move it to a common include file (driver.h)
    for mlx4_en and mlx4_ib for further use.
    
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index c59011d4e830..4ff7da83c4b3 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -797,7 +797,6 @@ void mlx4_en_cleanup_filters(struct mlx4_en_priv *priv);
 
 #define MLX4_EN_NUM_SELF_TEST	5
 void mlx4_en_ex_selftest(struct net_device *dev, u32 *flags, u64 *buf);
-u64 mlx4_en_mac_to_u64(u8 *addr);
 void mlx4_en_ptp_overflow_check(struct mlx4_en_dev *mdev);
 
 /*

commit 15bffdffccb3204eb1e993f60eee65c439a03136
Author: Eugenia Emantayev <eugenia@mellanox.com>
Date:   Sun Mar 2 10:25:00 2014 +0200

    net/mlx4_en: Move queue stopped/waked counters to be per ring
    
    Give accurate counters and avoids cache misses when several rings
    update the counters of stop/wake queue.
    
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 2610cc53fb4a..c59011d4e830 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -274,6 +274,8 @@ struct mlx4_en_tx_ring {
 	unsigned long bytes;
 	unsigned long packets;
 	unsigned long tx_csum;
+	unsigned long queue_stopped;
+	unsigned long wake_queue;
 	struct mlx4_bf bf;
 	bool bf_enabled;
 	struct netdev_queue *tx_queue;

commit b97b33a3df0439401f80f041eda507d4fffa0dbf
Author: Eugenia Emantayev <eugenia@mellanox.com>
Date:   Sun Mar 2 10:24:58 2014 +0200

    net/mlx4_en: Verify mlx4_en module parameters
    
    Verify mlx4_en module parameters.
    In case they are out of range - reset to default values.
    
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 3c25c7bf3dba..2610cc53fb4a 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -187,6 +187,13 @@ enum {
 #define GET_AVG_PERF_COUNTER(cnt)	(0)
 #endif /* MLX4_EN_PERF_STAT */
 
+/* Constants for TX flow */
+enum {
+	MAX_INLINE = 104, /* 128 - 16 - 4 - 4 */
+	MAX_BF = 256,
+	MIN_PKT_LEN = 17,
+};
+
 /*
  * Configurables
  */
@@ -271,6 +278,7 @@ struct mlx4_en_tx_ring {
 	bool bf_enabled;
 	struct netdev_queue *tx_queue;
 	int hwtstamp_tx_type;
+	int inline_thold;
 };
 
 struct mlx4_en_rx_desc {
@@ -346,6 +354,7 @@ struct mlx4_en_port_profile {
 	u8 tx_pause;
 	u8 tx_ppp;
 	int rss_rings;
+	int inline_thold;
 };
 
 struct mlx4_en_profile {

commit 169a1d85d084edeb0736ad80fe439639ac938dcd
Author: Amir Vadai <amirv@mellanox.com>
Date:   Wed Feb 19 17:47:31 2014 +0200

    net,IB/mlx: Bump all Mellanox driver versions
    
    Bump all Mellanox driver versions.
    
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 9ca223bc90fc..b57e8c87a34e 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -57,8 +57,8 @@
 #include "en_port.h"
 
 #define DRV_NAME	"mlx4_en"
-#define DRV_VERSION	"2.0"
-#define DRV_RELDATE	"Dec 2011"
+#define DRV_VERSION	"2.2-1"
+#define DRV_RELDATE	"Feb 2014"
 
 #define MLX4_EN_MSG_LEVEL	(NETIF_MSG_LINK | NETIF_MSG_IFDOWN)
 

commit 02512482321c531df4abf73943529f8b44d869e2
Author: Ido Shamay <idos@mellanox.com>
Date:   Fri Feb 21 12:39:17 2014 +0200

    net/mlx4: Set number of RX rings in a utility function
    
    mlx4_en_add() is too long.
    Moving set number of RX rings to a utiltity function to improve
    readability and modulization of the code.
    
    Signed-off-by: Ido Shamay <idos@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 9ca223bc90fc..3c25c7bf3dba 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -737,7 +737,7 @@ int mlx4_en_activate_tx_ring(struct mlx4_en_priv *priv,
 			     int cq, int user_prio);
 void mlx4_en_deactivate_tx_ring(struct mlx4_en_priv *priv,
 				struct mlx4_en_tx_ring *ring);
-
+void mlx4_en_set_num_rx_rings(struct mlx4_en_dev *mdev);
 int mlx4_en_create_rx_ring(struct mlx4_en_priv *priv,
 			   struct mlx4_en_rx_ring **pring,
 			   u32 size, u16 stride, int node);

commit 99932d4fc03a13bb3e94938fe25458fabc8f2fc3
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Sun Feb 16 15:55:20 2014 +0100

    netdevice: add queue selection fallback handler for ndo_select_queue
    
    Add a new argument for ndo_select_queue() callback that passes a
    fallback handler. This gets invoked through netdev_pick_tx();
    fallback handler is currently __netdev_pick_tx() as most drivers
    invoke this function within their customized implementation in
    case for skbs that don't need any special handling. This fallback
    handler can then be replaced on other call-sites with different
    queue selection methods (e.g. in packet sockets, pktgen etc).
    
    This also has the nice side-effect that __netdev_pick_tx() is
    then only invoked from netdev_pick_tx() and export of that
    function to modules can be undone.
    
    Suggested-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 3af04c3f42ea..9ca223bc90fc 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -723,7 +723,7 @@ int mlx4_en_arm_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
 
 void mlx4_en_tx_irq(struct mlx4_cq *mcq);
 u16 mlx4_en_select_queue(struct net_device *dev, struct sk_buff *skb,
-			 void *accel_priv);
+			 void *accel_priv, select_queue_fallback_t fallback);
 netdev_tx_t mlx4_en_xmit(struct sk_buff *skb, struct net_device *dev);
 
 int mlx4_en_create_tx_ring(struct mlx4_en_priv *priv,

commit 0a379e21c503b2ff66b44d588df9f231e9b0b9ca
Merge: a49da8811e71 fdc3452cd2c7
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Jan 14 14:37:09 2014 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net

commit e6a767582942d6fd9da0ddea673f5a7017a365c7
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Jan 9 10:30:13 2014 -0800

    net/mlx4_en: call gro handler for encapsulated frames
    
    In order to use the native GRO handling of encapsulated protocols on
    mlx4, we need to call napi_gro_receive() instead of netif_receive_skb()
    unless busy polling is in action.
    
    While we are at it, rename mlx4_en_cq_ll_polling() to
    mlx4_en_cq_busy_polling()
    
    Tested with GRE tunnel : GRO aggregation is now performed on the
    ethernet device instead of being done later on gre device.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Amir Vadai <amirv@mellanox.com>
    Cc: Jerry Chu <hkchu@google.com>
    Cc: Or Gerlitz <ogerlitz@mellanox.com>
    Acked-By: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 2f1e200f2e4c..fe7bdfebf353 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -661,7 +661,7 @@ static inline bool mlx4_en_cq_unlock_poll(struct mlx4_en_cq *cq)
 }
 
 /* true if a socket is polling, even if it did not get the lock */
-static inline bool mlx4_en_cq_ll_polling(struct mlx4_en_cq *cq)
+static inline bool mlx4_en_cq_busy_polling(struct mlx4_en_cq *cq)
 {
 	WARN_ON(!(cq->state & MLX4_CQ_LOCKED));
 	return cq->state & CQ_USER_PEND;
@@ -691,7 +691,7 @@ static inline bool mlx4_en_cq_unlock_poll(struct mlx4_en_cq *cq)
 	return false;
 }
 
-static inline bool mlx4_en_cq_ll_polling(struct mlx4_en_cq *cq)
+static inline bool mlx4_en_cq_busy_polling(struct mlx4_en_cq *cq)
 {
 	return false;
 }

commit f663dd9aaf9ed124f25f0f8452edf238f087ad50
Author: Jason Wang <jasowang@redhat.com>
Date:   Fri Jan 10 16:18:26 2014 +0800

    net: core: explicitly select a txq before doing l2 forwarding
    
    Currently, the tx queue were selected implicitly in ndo_dfwd_start_xmit(). The
    will cause several issues:
    
    - NETIF_F_LLTX were removed for macvlan, so txq lock were done for macvlan
      instead of lower device which misses the necessary txq synchronization for
      lower device such as txq stopping or frozen required by dev watchdog or
      control path.
    - dev_hard_start_xmit() was called with NULL txq which bypasses the net device
      watchdog.
    - dev_hard_start_xmit() does not check txq everywhere which will lead a crash
      when tso is disabled for lower device.
    
    Fix this by explicitly introducing a new param for .ndo_select_queue() for just
    selecting queues in the case of l2 forwarding offload. netdev_pick_tx() was also
    extended to accept this parameter and dev_queue_xmit_accel() was used to do l2
    forwarding transmission.
    
    With this fixes, NETIF_F_LLTX could be preserved for macvlan and there's no need
    to check txq against NULL in dev_hard_start_xmit(). Also there's no need to keep
    a dedicated ndo_dfwd_start_xmit() and we can just reuse the code of
    dev_queue_xmit() to do the transmission.
    
    In the future, it was also required for macvtap l2 forwarding support since it
    provides a necessary synchronization method.
    
    Cc: John Fastabend <john.r.fastabend@intel.com>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Cc: e1000-devel@lists.sourceforge.net
    Signed-off-by: Jason Wang <jasowang@redhat.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Acked-by: John Fastabend <john.r.fastabend@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index f3758de59c05..d5758adceaa2 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -714,7 +714,8 @@ int mlx4_en_set_cq_moder(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
 int mlx4_en_arm_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
 
 void mlx4_en_tx_irq(struct mlx4_cq *mcq);
-u16 mlx4_en_select_queue(struct net_device *dev, struct sk_buff *skb);
+u16 mlx4_en_select_queue(struct net_device *dev, struct sk_buff *skb,
+			 void *accel_priv);
 netdev_tx_t mlx4_en_xmit(struct sk_buff *skb, struct net_device *dev);
 
 int mlx4_en_create_tx_ring(struct mlx4_en_priv *priv,

commit ad7d4eaed995d76fb24a18e202fdf5072197ff0a
Author: Shawn Bohrer <sbohrer@rgmadvisors.com>
Date:   Tue Dec 31 11:39:39 2013 -0600

    mlx4_en: Add PTP hardware clock
    
    This adds a PHC to the mlx4_en driver. We use reader/writer spinlocks to
    protect the timecounter since every packet received needs to call
    timecounter_cycle2time() when timestamping is enabled.  This can become
    a performance bottleneck with RSS and multiple receive queues if normal
    spinlocks are used.
    
    This driver has been tested with both Documentation/ptp/testptp and the
    linuxptp project (http://linuxptp.sourceforge.net/) on a Mellanox
    ConnectX-3 card.
    
    Signed-off-by: Shawn Bohrer <sbohrer@rgmadvisors.com>
    Acked-By: Hadar Hen Zion <hadarh@mellanox.com>
    Acked-by: Richard Cochran <richardcochran@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 766691c66111..2f1e200f2e4c 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -45,6 +45,7 @@
 #include <linux/dcbnl.h>
 #endif
 #include <linux/cpu_rmap.h>
+#include <linux/ptp_clock_kernel.h>
 
 #include <linux/mlx4/device.h>
 #include <linux/mlx4/qp.h>
@@ -375,10 +376,14 @@ struct mlx4_en_dev {
 	u32                     priv_pdn;
 	spinlock_t              uar_lock;
 	u8			mac_removed[MLX4_MAX_PORTS + 1];
+	rwlock_t		clock_lock;
+	u32			nominal_c_mult;
 	struct cyclecounter	cycles;
 	struct timecounter	clock;
 	unsigned long		last_overflow_check;
 	unsigned long		overflow_period;
+	struct ptp_clock	*ptp_clock;
+	struct ptp_clock_info	ptp_clock_info;
 };
 
 
@@ -791,6 +796,7 @@ void mlx4_en_fill_hwtstamps(struct mlx4_en_dev *mdev,
 			    struct skb_shared_hwtstamps *hwts,
 			    u64 timestamp);
 void mlx4_en_init_timestamp(struct mlx4_en_dev *mdev);
+void mlx4_en_remove_timestamp(struct mlx4_en_dev *mdev);
 int mlx4_en_timestamp_config(struct net_device *dev,
 			     int tx_type,
 			     int rx_filter);

commit 837052d0ccc5a789a578f8b628ba154b63bd51ea
Author: Or Gerlitz <ogerlitz@mellanox.com>
Date:   Mon Dec 23 16:09:44 2013 +0200

    net/mlx4_en: Add netdev support for TCP/IP offloads of vxlan tunneling
    
    When the device tunneling offloads mode is vxlan do the following
    
     - call SET_PORT with the relevant setting
    
     - add DMFS steering vxlan rule for the device self and multicast mac addresses
       of the form: {<ETH, outer-mac> <VXLAN, ANY vnid> <ETH, ANY mac>} --> RSS QP
    
     - set relevant QPC fields in RSS context and RX ring QPs
    
     - in TX flow, set WQE fields to generate HW checksum, and handle gso skbs
       which are marked for encapsulation such that the HW will segment them properly.
    
     - in RX flow, read HW offloaded checksum for encapsulated packets from the CQE
    
     - advertize hw_enc_features and NETIF_F_GSO_UDP_TUNNEL to the networking stack
    
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 123714cbd35f..766691c66111 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -436,6 +436,7 @@ struct mlx4_en_mc_list {
 	enum mlx4_en_mclist_act	action;
 	u8			addr[ETH_ALEN];
 	u64			reg_id;
+	u64			tunnel_reg_id;
 };
 
 struct mlx4_en_frag_info {
@@ -567,7 +568,7 @@ struct mlx4_en_priv {
 	struct list_head filters;
 	struct hlist_head filter_hash[1 << MLX4_EN_FILTER_HASH_SHIFT];
 #endif
-
+	u64 tunnel_reg_id;
 };
 
 enum mlx4_en_wol {

commit 0276a330617a0cf380f09e5065299078d3d45886
Author: Eugenia Emantayev <eugenia@mellanox.com>
Date:   Thu Dec 19 21:20:17 2013 +0200

    net/mlx4_en: Add NAPI support for transmit side
    
    Add NAPI for TX side,
    implement its support and provide NAPI callback.
    
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.com>
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 202d8e5eb41f..123714cbd35f 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -744,6 +744,7 @@ int mlx4_en_process_rx_cq(struct net_device *dev,
 			  struct mlx4_en_cq *cq,
 			  int budget);
 int mlx4_en_poll_rx_cq(struct napi_struct *napi, int budget);
+int mlx4_en_poll_tx_cq(struct napi_struct *napi, int budget);
 void mlx4_en_fill_qp_context(struct mlx4_en_priv *priv, int size, int stride,
 		int is_tx, int rss, int qpn, int cqn, int user_prio,
 		struct mlx4_qp_context *context);

commit d03a68f8217ea03492e4f7928db222dc6544792a
Author: Ido Shamay <idos@mellanox.com>
Date:   Thu Dec 19 21:20:14 2013 +0200

    net/mlx4_en: Configure the XPS queue mapping on driver load
    
    Only TX rings of User Piority 0 are mapped.
    TX rings of other UP's are using UP 0 mapping.
    XPS is not in use when num_tc is set.
    
    Signed-off-by: Ido Shamay <idos@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index f3758de59c05..202d8e5eb41f 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -255,6 +255,8 @@ struct mlx4_en_tx_ring {
 	u16 poll_cnt;
 	struct mlx4_en_tx_info *tx_info;
 	u8 *bounce_buf;
+	u8 queue_index;
+	cpumask_t affinity_mask;
 	u32 last_nr_txbb;
 	struct mlx4_qp qp;
 	struct mlx4_qp_context context;
@@ -719,7 +721,8 @@ netdev_tx_t mlx4_en_xmit(struct sk_buff *skb, struct net_device *dev);
 
 int mlx4_en_create_tx_ring(struct mlx4_en_priv *priv,
 			   struct mlx4_en_tx_ring **pring,
-			   int qpn, u32 size, u16 stride, int node);
+			   int qpn, u32 size, u16 stride,
+			   int node, int queue_index);
 void mlx4_en_destroy_tx_ring(struct mlx4_en_priv *priv,
 			     struct mlx4_en_tx_ring **pring);
 int mlx4_en_activate_tx_ring(struct mlx4_en_priv *priv,

commit 163561a4e2f8af44e96453bc10c7a4f9bcc736e1
Author: Eugenia Emantayev <eugenia@mellanox.com>
Date:   Thu Nov 7 12:19:54 2013 +0200

    net/mlx4_en: Datapath structures are allocated per NUMA node
    
    For each RX/TX ring and its CQ, allocation is done on a NUMA node that
    corresponds to the core that the data structure should operate on.
    The assumption is that the core number is reflected by the ring index.
    The affected allocations are the ring/CQ data structures,
    the TX/RX info and the shared HW/SW buffer.
    For TX rings, each core has rings of all UPs.
    
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.com>
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.com>
    Reviewed-by: Hadar Hen Zion <hadarh@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index b2547ae07dfa..f3758de59c05 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -705,7 +705,7 @@ void mlx4_en_free_resources(struct mlx4_en_priv *priv);
 int mlx4_en_alloc_resources(struct mlx4_en_priv *priv);
 
 int mlx4_en_create_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq **pcq,
-		      int entries, int ring, enum cq_type mode);
+		      int entries, int ring, enum cq_type mode, int node);
 void mlx4_en_destroy_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq **pcq);
 int mlx4_en_activate_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq,
 			int cq_idx);
@@ -719,7 +719,7 @@ netdev_tx_t mlx4_en_xmit(struct sk_buff *skb, struct net_device *dev);
 
 int mlx4_en_create_tx_ring(struct mlx4_en_priv *priv,
 			   struct mlx4_en_tx_ring **pring,
-			   int qpn, u32 size, u16 stride);
+			   int qpn, u32 size, u16 stride, int node);
 void mlx4_en_destroy_tx_ring(struct mlx4_en_priv *priv,
 			     struct mlx4_en_tx_ring **pring);
 int mlx4_en_activate_tx_ring(struct mlx4_en_priv *priv,
@@ -730,7 +730,7 @@ void mlx4_en_deactivate_tx_ring(struct mlx4_en_priv *priv,
 
 int mlx4_en_create_rx_ring(struct mlx4_en_priv *priv,
 			   struct mlx4_en_rx_ring **pring,
-			   u32 size, u16 stride);
+			   u32 size, u16 stride, int node);
 void mlx4_en_destroy_rx_ring(struct mlx4_en_priv *priv,
 			     struct mlx4_en_rx_ring **pring,
 			     u32 size, u16 stride);

commit 41d942d56cfd21058fba465804e14ba349541442
Author: Eugenia Emantayev <eugenia@mellanox.com>
Date:   Thu Nov 7 12:19:52 2013 +0200

    net/mlx4_en: Datapath resources allocated dynamically
    
    Currently all TX/RX rings and completion queues are part of the
    netdev priv structure and are allocated statically. This patch
    will change the priv to hold only arrays of pointers and therefore
    all TX/RX rings and completetion queues will be allocated
    dynamically. This is in preparation for NUMA aware allocations.
    
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.com>
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.com>
    Reviewed-by: Hadar Hen Zion <hadarh@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index bf06e3610d27..b2547ae07dfa 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -530,10 +530,10 @@ struct mlx4_en_priv {
 	u16 num_frags;
 	u16 log_rx_info;
 
-	struct mlx4_en_tx_ring *tx_ring;
-	struct mlx4_en_rx_ring rx_ring[MAX_RX_RINGS];
-	struct mlx4_en_cq *tx_cq;
-	struct mlx4_en_cq rx_cq[MAX_RX_RINGS];
+	struct mlx4_en_tx_ring **tx_ring;
+	struct mlx4_en_rx_ring *rx_ring[MAX_RX_RINGS];
+	struct mlx4_en_cq **tx_cq;
+	struct mlx4_en_cq *rx_cq[MAX_RX_RINGS];
 	struct mlx4_qp drop_qp;
 	struct work_struct rx_mode_task;
 	struct work_struct watchdog_task;
@@ -626,7 +626,7 @@ static inline bool mlx4_en_cq_lock_poll(struct mlx4_en_cq *cq)
 	if ((cq->state & MLX4_CQ_LOCKED)) {
 		struct net_device *dev = cq->dev;
 		struct mlx4_en_priv *priv = netdev_priv(dev);
-		struct mlx4_en_rx_ring *rx_ring = &priv->rx_ring[cq->ring];
+		struct mlx4_en_rx_ring *rx_ring = priv->rx_ring[cq->ring];
 
 		cq->state |= MLX4_EN_CQ_STATE_POLL_YIELD;
 		rc = false;
@@ -704,9 +704,9 @@ void mlx4_en_stop_port(struct net_device *dev, int detach);
 void mlx4_en_free_resources(struct mlx4_en_priv *priv);
 int mlx4_en_alloc_resources(struct mlx4_en_priv *priv);
 
-int mlx4_en_create_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq,
+int mlx4_en_create_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq **pcq,
 		      int entries, int ring, enum cq_type mode);
-void mlx4_en_destroy_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
+void mlx4_en_destroy_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq **pcq);
 int mlx4_en_activate_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq,
 			int cq_idx);
 void mlx4_en_deactivate_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
@@ -717,9 +717,11 @@ void mlx4_en_tx_irq(struct mlx4_cq *mcq);
 u16 mlx4_en_select_queue(struct net_device *dev, struct sk_buff *skb);
 netdev_tx_t mlx4_en_xmit(struct sk_buff *skb, struct net_device *dev);
 
-int mlx4_en_create_tx_ring(struct mlx4_en_priv *priv, struct mlx4_en_tx_ring *ring,
+int mlx4_en_create_tx_ring(struct mlx4_en_priv *priv,
+			   struct mlx4_en_tx_ring **pring,
 			   int qpn, u32 size, u16 stride);
-void mlx4_en_destroy_tx_ring(struct mlx4_en_priv *priv, struct mlx4_en_tx_ring *ring);
+void mlx4_en_destroy_tx_ring(struct mlx4_en_priv *priv,
+			     struct mlx4_en_tx_ring **pring);
 int mlx4_en_activate_tx_ring(struct mlx4_en_priv *priv,
 			     struct mlx4_en_tx_ring *ring,
 			     int cq, int user_prio);
@@ -727,10 +729,10 @@ void mlx4_en_deactivate_tx_ring(struct mlx4_en_priv *priv,
 				struct mlx4_en_tx_ring *ring);
 
 int mlx4_en_create_rx_ring(struct mlx4_en_priv *priv,
-			   struct mlx4_en_rx_ring *ring,
+			   struct mlx4_en_rx_ring **pring,
 			   u32 size, u16 stride);
 void mlx4_en_destroy_rx_ring(struct mlx4_en_priv *priv,
-			     struct mlx4_en_rx_ring *ring,
+			     struct mlx4_en_rx_ring **pring,
 			     u32 size, u16 stride);
 int mlx4_en_activate_rx_rings(struct mlx4_en_priv *priv);
 void mlx4_en_deactivate_rx_ring(struct mlx4_en_priv *priv,
@@ -768,8 +770,7 @@ extern const struct dcbnl_rtnl_ops mlx4_en_dcbnl_pfc_ops;
 int mlx4_en_setup_tc(struct net_device *dev, u8 up);
 
 #ifdef CONFIG_RFS_ACCEL
-void mlx4_en_cleanup_filters(struct mlx4_en_priv *priv,
-			     struct mlx4_en_rx_ring *rx_ring);
+void mlx4_en_cleanup_filters(struct mlx4_en_priv *priv);
 #endif
 
 #define MLX4_EN_NUM_SELF_TEST	5

commit 70fbe0794393829d9acd686428d87c27b6f6984b
Author: Amir Vadai <amirv@mellanox.com>
Date:   Mon Oct 7 13:38:12 2013 +0200

    net/mlx4_en: Rename name of mlx4_en_rx_alloc members
    
    Add page prefix to page related members: @size and @offset into
    @page_size and @page_offset
    
    CC: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 5e0aa569306a..bf06e3610d27 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -237,8 +237,8 @@ struct mlx4_en_tx_desc {
 struct mlx4_en_rx_alloc {
 	struct page	*page;
 	dma_addr_t	dma;
-	u32		offset;
-	u32		size;
+	u32		page_offset;
+	u32		page_size;
 };
 
 struct mlx4_en_tx_ring {

commit e0d1095ae3405404d247afb00233ef837d58da83
Author: Cong Wang <amwang@redhat.com>
Date:   Thu Aug 1 11:10:25 2013 +0800

    net: rename CONFIG_NET_LL_RX_POLL to CONFIG_NET_RX_BUSY_POLL
    
    Eliezer renames several *ll_poll to *busy_poll, but forgets
    CONFIG_NET_LL_RX_POLL, so in case of confusion, rename it too.
    
    Cc: Eliezer Tamir <eliezer.tamir@linux.intel.com>
    Cc: David S. Miller <davem@davemloft.net>
    Signed-off-by: Cong Wang <amwang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 35fb60e2320c..5e0aa569306a 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -292,7 +292,7 @@ struct mlx4_en_rx_ring {
 	void *rx_info;
 	unsigned long bytes;
 	unsigned long packets;
-#ifdef CONFIG_NET_LL_RX_POLL
+#ifdef CONFIG_NET_RX_BUSY_POLL
 	unsigned long yields;
 	unsigned long misses;
 	unsigned long cleaned;
@@ -318,7 +318,7 @@ struct mlx4_en_cq {
 	struct mlx4_cqe *buf;
 #define MLX4_EN_OPCODE_ERROR	0x1e
 
-#ifdef CONFIG_NET_LL_RX_POLL
+#ifdef CONFIG_NET_RX_BUSY_POLL
 	unsigned int state;
 #define MLX4_EN_CQ_STATE_IDLE        0
 #define MLX4_EN_CQ_STATE_NAPI     1    /* NAPI owns this CQ */
@@ -329,7 +329,7 @@ struct mlx4_en_cq {
 #define CQ_YIELD (MLX4_EN_CQ_STATE_NAPI_YIELD | MLX4_EN_CQ_STATE_POLL_YIELD)
 #define CQ_USER_PEND (MLX4_EN_CQ_STATE_POLL | MLX4_EN_CQ_STATE_POLL_YIELD)
 	spinlock_t poll_lock; /* protects from LLS/napi conflicts */
-#endif  /* CONFIG_NET_LL_RX_POLL */
+#endif  /* CONFIG_NET_RX_BUSY_POLL */
 };
 
 struct mlx4_en_port_profile {
@@ -580,7 +580,7 @@ struct mlx4_mac_entry {
 	struct rcu_head rcu;
 };
 
-#ifdef CONFIG_NET_LL_RX_POLL
+#ifdef CONFIG_NET_RX_BUSY_POLL
 static inline void mlx4_en_cq_init_lock(struct mlx4_en_cq *cq)
 {
 	spin_lock_init(&cq->poll_lock);
@@ -687,7 +687,7 @@ static inline bool mlx4_en_cq_ll_polling(struct mlx4_en_cq *cq)
 {
 	return false;
 }
-#endif /* CONFIG_NET_LL_RX_POLL */
+#endif /* CONFIG_NET_RX_BUSY_POLL */
 
 #define MLX4_EN_WOL_DO_MODIFY (1ULL << 63)
 

commit 51151a16a60f0a886a0b1e4a0697001198af50c4
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Sun Jun 23 08:17:56 2013 -0700

    mlx4: allow order-0 memory allocations in RX path
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    
    mlx4 exclusively uses order-2 allocations in RX path, which are
    likely to fail under memory pressure.
    
    We therefore drop frames more than needed.
    
    This patch tries order-3, order-2, order-1 and finally order-0
    allocations to keep good performance, yet allow allocations if/when
    memory gets fragmented.
    
    By using larger pages, and avoiding unnecessary get_page()/put_page()
    on compound pages, this patch improves performance as well, lowering
    false sharing on struct page.
    
    Also use GFP_KERNEL allocations in initialization path, as allocating 12
    MB (390 order-3 pages) can easily fail with GFP_ATOMIC.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Amir Vadai <amirv@mellanox.com>
    Acked-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 57192a8f1d5e..35fb60e2320c 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -96,7 +96,8 @@
 
 /* Use the maximum between 16384 and a single page */
 #define MLX4_EN_ALLOC_SIZE	PAGE_ALIGN(16384)
-#define MLX4_EN_ALLOC_ORDER	get_order(MLX4_EN_ALLOC_SIZE)
+
+#define MLX4_EN_ALLOC_PREFER_ORDER	PAGE_ALLOC_COSTLY_ORDER
 
 /* Receive fragment sizes; we use at most 3 fragments (for 9600 byte MTU
  * and 4K allocations) */
@@ -234,9 +235,10 @@ struct mlx4_en_tx_desc {
 #define MLX4_EN_CX3_HIGH_ID	0x1005
 
 struct mlx4_en_rx_alloc {
-	struct page *page;
-	dma_addr_t dma;
-	u16 offset;
+	struct page	*page;
+	dma_addr_t	dma;
+	u32		offset;
+	u32		size;
 };
 
 struct mlx4_en_tx_ring {
@@ -439,8 +441,6 @@ struct mlx4_en_frag_info {
 	u16 frag_prefix_size;
 	u16 frag_stride;
 	u16 frag_align;
-	u16 last_offset;
-
 };
 
 #ifdef CONFIG_MLX4_EN_DCB

commit 8501841a4483e678ebd1b7872019621244d0098a
Author: Amir Vadai <amirv@mellanox.com>
Date:   Tue Jun 18 16:18:28 2013 +0300

    net/mlx4_en: Low Latency recv statistics
    
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 11c862e4e69d..57192a8f1d5e 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -290,6 +290,11 @@ struct mlx4_en_rx_ring {
 	void *rx_info;
 	unsigned long bytes;
 	unsigned long packets;
+#ifdef CONFIG_NET_LL_RX_POLL
+	unsigned long yields;
+	unsigned long misses;
+	unsigned long cleaned;
+#endif
 	unsigned long csum_ok;
 	unsigned long csum_none;
 	int hwtstamp_rx_filter;
@@ -625,6 +630,7 @@ static inline bool mlx4_en_cq_lock_poll(struct mlx4_en_cq *cq)
 
 		cq->state |= MLX4_EN_CQ_STATE_POLL_YIELD;
 		rc = false;
+		rx_ring->yields++;
 	} else
 		/* preserve yield marks */
 		cq->state |= MLX4_EN_CQ_STATE_POLL;

commit 9e77a2b837bbd7197da966f0915e8f1ddb2ca850
Author: Amir Vadai <amirv@mellanox.com>
Date:   Tue Jun 18 16:18:27 2013 +0300

    net/mlx4_en: Add Low Latency Socket (LLS) support
    
    Add basic support for LLS.
    
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Reviewed-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index b1f51c1f635c..11c862e4e69d 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -310,6 +310,19 @@ struct mlx4_en_cq {
 	u16 moder_cnt;
 	struct mlx4_cqe *buf;
 #define MLX4_EN_OPCODE_ERROR	0x1e
+
+#ifdef CONFIG_NET_LL_RX_POLL
+	unsigned int state;
+#define MLX4_EN_CQ_STATE_IDLE        0
+#define MLX4_EN_CQ_STATE_NAPI     1    /* NAPI owns this CQ */
+#define MLX4_EN_CQ_STATE_POLL     2    /* poll owns this CQ */
+#define MLX4_CQ_LOCKED (MLX4_EN_CQ_STATE_NAPI | MLX4_EN_CQ_STATE_POLL)
+#define MLX4_EN_CQ_STATE_NAPI_YIELD  4    /* NAPI yielded this CQ */
+#define MLX4_EN_CQ_STATE_POLL_YIELD  8    /* poll yielded this CQ */
+#define CQ_YIELD (MLX4_EN_CQ_STATE_NAPI_YIELD | MLX4_EN_CQ_STATE_POLL_YIELD)
+#define CQ_USER_PEND (MLX4_EN_CQ_STATE_POLL | MLX4_EN_CQ_STATE_POLL_YIELD)
+	spinlock_t poll_lock; /* protects from LLS/napi conflicts */
+#endif  /* CONFIG_NET_LL_RX_POLL */
 };
 
 struct mlx4_en_port_profile {
@@ -562,6 +575,114 @@ struct mlx4_mac_entry {
 	struct rcu_head rcu;
 };
 
+#ifdef CONFIG_NET_LL_RX_POLL
+static inline void mlx4_en_cq_init_lock(struct mlx4_en_cq *cq)
+{
+	spin_lock_init(&cq->poll_lock);
+	cq->state = MLX4_EN_CQ_STATE_IDLE;
+}
+
+/* called from the device poll rutine to get ownership of a cq */
+static inline bool mlx4_en_cq_lock_napi(struct mlx4_en_cq *cq)
+{
+	int rc = true;
+	spin_lock(&cq->poll_lock);
+	if (cq->state & MLX4_CQ_LOCKED) {
+		WARN_ON(cq->state & MLX4_EN_CQ_STATE_NAPI);
+		cq->state |= MLX4_EN_CQ_STATE_NAPI_YIELD;
+		rc = false;
+	} else
+		/* we don't care if someone yielded */
+		cq->state = MLX4_EN_CQ_STATE_NAPI;
+	spin_unlock(&cq->poll_lock);
+	return rc;
+}
+
+/* returns true is someone tried to get the cq while napi had it */
+static inline bool mlx4_en_cq_unlock_napi(struct mlx4_en_cq *cq)
+{
+	int rc = false;
+	spin_lock(&cq->poll_lock);
+	WARN_ON(cq->state & (MLX4_EN_CQ_STATE_POLL |
+			       MLX4_EN_CQ_STATE_NAPI_YIELD));
+
+	if (cq->state & MLX4_EN_CQ_STATE_POLL_YIELD)
+		rc = true;
+	cq->state = MLX4_EN_CQ_STATE_IDLE;
+	spin_unlock(&cq->poll_lock);
+	return rc;
+}
+
+/* called from mlx4_en_low_latency_poll() */
+static inline bool mlx4_en_cq_lock_poll(struct mlx4_en_cq *cq)
+{
+	int rc = true;
+	spin_lock_bh(&cq->poll_lock);
+	if ((cq->state & MLX4_CQ_LOCKED)) {
+		struct net_device *dev = cq->dev;
+		struct mlx4_en_priv *priv = netdev_priv(dev);
+		struct mlx4_en_rx_ring *rx_ring = &priv->rx_ring[cq->ring];
+
+		cq->state |= MLX4_EN_CQ_STATE_POLL_YIELD;
+		rc = false;
+	} else
+		/* preserve yield marks */
+		cq->state |= MLX4_EN_CQ_STATE_POLL;
+	spin_unlock_bh(&cq->poll_lock);
+	return rc;
+}
+
+/* returns true if someone tried to get the cq while it was locked */
+static inline bool mlx4_en_cq_unlock_poll(struct mlx4_en_cq *cq)
+{
+	int rc = false;
+	spin_lock_bh(&cq->poll_lock);
+	WARN_ON(cq->state & (MLX4_EN_CQ_STATE_NAPI));
+
+	if (cq->state & MLX4_EN_CQ_STATE_POLL_YIELD)
+		rc = true;
+	cq->state = MLX4_EN_CQ_STATE_IDLE;
+	spin_unlock_bh(&cq->poll_lock);
+	return rc;
+}
+
+/* true if a socket is polling, even if it did not get the lock */
+static inline bool mlx4_en_cq_ll_polling(struct mlx4_en_cq *cq)
+{
+	WARN_ON(!(cq->state & MLX4_CQ_LOCKED));
+	return cq->state & CQ_USER_PEND;
+}
+#else
+static inline void mlx4_en_cq_init_lock(struct mlx4_en_cq *cq)
+{
+}
+
+static inline bool mlx4_en_cq_lock_napi(struct mlx4_en_cq *cq)
+{
+	return true;
+}
+
+static inline bool mlx4_en_cq_unlock_napi(struct mlx4_en_cq *cq)
+{
+	return false;
+}
+
+static inline bool mlx4_en_cq_lock_poll(struct mlx4_en_cq *cq)
+{
+	return false;
+}
+
+static inline bool mlx4_en_cq_unlock_poll(struct mlx4_en_cq *cq)
+{
+	return false;
+}
+
+static inline bool mlx4_en_cq_ll_polling(struct mlx4_en_cq *cq)
+{
+	return false;
+}
+#endif /* CONFIG_NET_LL_RX_POLL */
+
 #define MLX4_EN_WOL_DO_MODIFY (1ULL << 63)
 
 void mlx4_en_update_loopback_state(struct net_device *dev,

commit e6309cff76a6adc0010609d45d34173e524a546d
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Jun 3 07:54:55 2013 +0000

    net/mlx4: use one page fragment per incoming frame
    
    mlx4 driver has a suboptimal memory allocation strategy for regular
    MTU=1500 frames, as it uses two page fragments :
    
    One of 512 bytes and one of 1024 bytes.
    
    This makes GRO less effective, as each GSO packet contains 8 MSS instead
    of 16 MSS.
    
    Performance of a single TCP flow gains 25 % increase with the following
    patch.
    
    Before patch :
    
    A:~# netperf -H 192.168.0.2 -Cc
    MIGRATED TCP STREAM TEST ...
    Recv   Send    Send                          Utilization       Service Demand
    Socket Socket  Message  Elapsed              Send     Recv     Send    Recv
    Size   Size    Size     Time     Throughput  local    remote   local   remote
    bytes  bytes   bytes    secs.    10^6bits/s  % S      % S      us/KB   us/KB
    
     87380  16384  16384    10.00      13798.47   3.06     4.20     0.436   0.598
    
    After patch :
    
    A:~# netperf -H 192.68.0.2 -Cc
    MIGRATED TCP STREAM TEST ...
    Recv   Send    Send                          Utilization       Service Demand
    Socket Socket  Message  Elapsed              Send     Recv     Send    Recv
    Size   Size    Size     Time     Throughput  local    remote   local   remote
    bytes  bytes   bytes    secs.    10^6bits/s  % S      % S      us/KB   us/KB
    
     87380  16384  16384    10.00      17273.80   3.44     4.19     0.391   0.477
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Amir Vadai <amirv@mellanox.com>
    Acked-By: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index b1d7657b2bf5..b1f51c1f635c 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -98,11 +98,11 @@
 #define MLX4_EN_ALLOC_SIZE	PAGE_ALIGN(16384)
 #define MLX4_EN_ALLOC_ORDER	get_order(MLX4_EN_ALLOC_SIZE)
 
-/* Receive fragment sizes; we use at most 4 fragments (for 9600 byte MTU
+/* Receive fragment sizes; we use at most 3 fragments (for 9600 byte MTU
  * and 4K allocations) */
 enum {
-	FRAG_SZ0 = 512 - NET_IP_ALIGN,
-	FRAG_SZ1 = 1024,
+	FRAG_SZ0 = 1536 - NET_IP_ALIGN,
+	FRAG_SZ1 = 4096,
 	FRAG_SZ2 = 4096,
 	FRAG_SZ3 = MLX4_EN_ALLOC_SIZE
 };

commit b6c39bfcf1d7d6368b8c00081cc8e941041ff478
Author: Amir Vadai <amirv@mellanox.com>
Date:   Tue Apr 23 06:06:51 2013 +0000

    net/mlx4_en: Add a service task
    
    Add a service task to run tasks that needed to be executed periodically.
    Currently the only task is a watchdog to catch NIC clock overflow, to make
    timestamping accurate.
    Will move the statistics task into this framework in a later patch.
    
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 85b0754ec8ac..b1d7657b2bf5 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -78,6 +78,7 @@
 #define STAMP_SHIFT		31
 #define STAMP_VAL		0x7fffffff
 #define STATS_DELAY		(HZ / 4)
+#define SERVICE_TASK_DELAY	(HZ / 4)
 #define MAX_NUM_OF_FS_RULES	256
 
 #define MLX4_EN_FILTER_HASH_SHIFT 4
@@ -355,6 +356,7 @@ struct mlx4_en_dev {
 	struct cyclecounter	cycles;
 	struct timecounter	clock;
 	unsigned long		last_overflow_check;
+	unsigned long		overflow_period;
 };
 
 
@@ -519,6 +521,7 @@ struct mlx4_en_priv {
 	struct work_struct watchdog_task;
 	struct work_struct linkstate_task;
 	struct delayed_work stats_task;
+	struct delayed_work service_task;
 	struct mlx4_en_perf_stats pstats;
 	struct mlx4_en_pkt_stats pkstats;
 	struct mlx4_en_port_stats port_stats;
@@ -645,6 +648,7 @@ void mlx4_en_cleanup_filters(struct mlx4_en_priv *priv,
 #define MLX4_EN_NUM_SELF_TEST	5
 void mlx4_en_ex_selftest(struct net_device *dev, u32 *flags, u64 *buf);
 u64 mlx4_en_mac_to_u64(u8 *addr);
+void mlx4_en_ptp_overflow_check(struct mlx4_en_dev *mdev);
 
 /*
  * Functions for time stamping

commit ec693d47010e8302e61e0bdf3f47496c5610641a
Author: Amir Vadai <amirv@mellanox.com>
Date:   Tue Apr 23 06:06:49 2013 +0000

    net/mlx4_en: Add HW timestamping (TS) support
    
    The patch allows to enable/disable HW timestamping for incoming and/or
    outgoing packets. It adds and initializes all structs and callbacks
    needed by kernel TS API.
    To enable/disable HW timestamping appropriate ioctl should be used.
    Currently HWTSTAMP_FILTER_ALL/NONE and HWTSAMP_TX_ON/OFF only are
    supported.
    When enabling TS on receive flow - VLAN stripping will be disabled.
    Also were made all relevant changes in RX/TX flows to consider TS request
    and plant HW timestamps into relevant structures.
    mlx4_ib was fixed to compile with new mlx4_cq_alloc() signature.
    
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index d4cb5d3b28a2..85b0754ec8ac 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -40,6 +40,7 @@
 #include <linux/mutex.h>
 #include <linux/netdevice.h>
 #include <linux/if_vlan.h>
+#include <linux/net_tstamp.h>
 #ifdef CONFIG_MLX4_EN_DCB
 #include <linux/dcbnl.h>
 #endif
@@ -207,6 +208,7 @@ struct mlx4_en_tx_info {
 	u8 linear;
 	u8 data_offset;
 	u8 inl;
+	u8 ts_requested;
 };
 
 
@@ -262,6 +264,7 @@ struct mlx4_en_tx_ring {
 	struct mlx4_bf bf;
 	bool bf_enabled;
 	struct netdev_queue *tx_queue;
+	int hwtstamp_tx_type;
 };
 
 struct mlx4_en_rx_desc {
@@ -288,6 +291,7 @@ struct mlx4_en_rx_ring {
 	unsigned long packets;
 	unsigned long csum_ok;
 	unsigned long csum_none;
+	int hwtstamp_rx_filter;
 };
 
 struct mlx4_en_cq {
@@ -348,6 +352,9 @@ struct mlx4_en_dev {
 	u32                     priv_pdn;
 	spinlock_t              uar_lock;
 	u8			mac_removed[MLX4_MAX_PORTS + 1];
+	struct cyclecounter	cycles;
+	struct timecounter	clock;
+	unsigned long		last_overflow_check;
 };
 
 
@@ -525,6 +532,7 @@ struct mlx4_en_priv {
 	struct device *ddev;
 	int base_tx_qpn;
 	struct hlist_head mac_hash[MLX4_EN_MAC_HASH_SIZE];
+	struct hwtstamp_config hwtstamp_config;
 
 #ifdef CONFIG_MLX4_EN_DCB
 	struct ieee_ets ets;
@@ -639,7 +647,18 @@ void mlx4_en_ex_selftest(struct net_device *dev, u32 *flags, u64 *buf);
 u64 mlx4_en_mac_to_u64(u8 *addr);
 
 /*
- * Globals
+ * Functions for time stamping
+ */
+u64 mlx4_en_get_cqe_ts(struct mlx4_cqe *cqe);
+void mlx4_en_fill_hwtstamps(struct mlx4_en_dev *mdev,
+			    struct skb_shared_hwtstamps *hwts,
+			    u64 timestamp);
+void mlx4_en_init_timestamp(struct mlx4_en_dev *mdev);
+int mlx4_en_timestamp_config(struct net_device *dev,
+			     int tx_type,
+			     int rx_filter);
+
+/* Globals
  */
 extern const struct ethtool_ops mlx4_en_ethtool_ops;
 

commit 540b3a39eea0056d305f17dda47eb185c4d56ddc
Author: Or Gerlitz <ogerlitz@mellanox.com>
Date:   Sun Apr 7 03:44:07 2013 +0000

    net/mlx4_en: Enable DCB ETS ops only when supported by the firmware
    
    Enable the DCB ETS ops only when supported by the firmware. For older firmware/cards
    which don't support ETS, advertize only PFC DCB ops.
    
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.co.il>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index f710b7ce0dcb..d4cb5d3b28a2 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -624,6 +624,7 @@ int mlx4_en_QUERY_PORT(struct mlx4_en_dev *mdev, u8 port);
 
 #ifdef CONFIG_MLX4_EN_DCB
 extern const struct dcbnl_rtnl_ops mlx4_en_dcbnl_ops;
+extern const struct dcbnl_rtnl_ops mlx4_en_dcbnl_pfc_ops;
 #endif
 
 int mlx4_en_setup_tc(struct net_device *dev, u8 up);

commit bfa8ab47415a87c6c93a9e54e16f2f8cc6de79af
Author: Yan Burman <yanb@mellanox.com>
Date:   Thu Mar 7 03:46:55 2013 +0000

    net/mlx4_en: Fix race when setting the device MAC address
    
    Remove unnecessary use of workqueue for the device MAC address setting
    flow, and fix a race when setting MAC address which was introduced by
    commit c07cb4b0a "net/mlx4_en: Manage hash of MAC addresses per port"
    
    The race happened when mlx4_en_replace_mac was being executed in parallel
    with a successive call to ndo_set_mac_address, e.g witn an A/B/A MAC
    setting configuration test, the third set fails.
    
    With this change we also properly report an error if set MAC fails.
    
    Signed-off-by: Yan Burman <yanb@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index c313d7e943a9..f710b7ce0dcb 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -509,7 +509,6 @@ struct mlx4_en_priv {
 	struct mlx4_en_cq rx_cq[MAX_RX_RINGS];
 	struct mlx4_qp drop_qp;
 	struct work_struct rx_mode_task;
-	struct work_struct mac_task;
 	struct work_struct watchdog_task;
 	struct work_struct linkstate_task;
 	struct delayed_work stats_task;

commit cc5387f7346a9f35aaf7f35133666fa8acbcbde3
Author: Yan Burman <yanb@mellanox.com>
Date:   Thu Feb 7 02:25:26 2013 +0000

    net/mlx4_en: Add unicast MAC filtering
    
    Implement and advertise unicast MAC filtering, such that setting macvlan
    instance over mlx4_en interfaces will not require the networking core
    to put mlx4_en devices in promiscuous mode.
    
    If for some reason adding a unicast address filter fails e.g as of missing space in
    the HW mac table, the device forces itself into promiscuous mode (and out of this
    forced state when enough space is available).
    
    Signed-off-by: Yan Burman <yanb@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 0ff99e0b2ea3..c313d7e943a9 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -439,7 +439,8 @@ enum {
 	 */
 	MLX4_EN_FLAG_ENABLE_HW_LOOPBACK	= (1 << 2),
 	/* whether we need to drop packets that hardware loopback-ed */
-	MLX4_EN_FLAG_RX_FILTER_NEEDED	= (1 << 3)
+	MLX4_EN_FLAG_RX_FILTER_NEEDED	= (1 << 3),
+	MLX4_EN_FLAG_FORCE_PROMISC	= (1 << 4)
 };
 
 #define MLX4_EN_MAC_HASH_SIZE (1 << BITS_PER_BYTE)

commit c07cb4b0ab78f279ea94c3b4661cad86eb02a5d9
Author: Yan Burman <yanb@mellanox.com>
Date:   Thu Feb 7 02:25:25 2013 +0000

    net/mlx4_en: Manage hash of MAC addresses per port
    
    As a preparation step for supporting multiple unicast addresses, store MAC addresses in hash table.
    Remove the radix tree for MAC addresses per QP, as it's not in use.
    
    Signed-off-by: Yan Burman <yanb@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 47c9876a2449..0ff99e0b2ea3 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -442,6 +442,9 @@ enum {
 	MLX4_EN_FLAG_RX_FILTER_NEEDED	= (1 << 3)
 };
 
+#define MLX4_EN_MAC_HASH_SIZE (1 << BITS_PER_BYTE)
+#define MLX4_EN_MAC_HASH_IDX 5
+
 struct mlx4_en_priv {
 	struct mlx4_en_dev *mdev;
 	struct mlx4_en_port_profile *prof;
@@ -521,7 +524,7 @@ struct mlx4_en_priv {
 	bool wol;
 	struct device *ddev;
 	int base_tx_qpn;
-	struct radix_tree_root mac_tree;
+	struct hlist_head mac_hash[MLX4_EN_MAC_HASH_SIZE];
 
 #ifdef CONFIG_MLX4_EN_DCB
 	struct ieee_ets ets;
@@ -542,8 +545,10 @@ enum mlx4_en_wol {
 };
 
 struct mlx4_mac_entry {
+	struct hlist_node hlist;
 	unsigned char mac[ETH_ALEN + 2];
 	u64 reg_id;
+	struct rcu_head rcu;
 };
 
 #define MLX4_EN_WOL_DO_MODIFY (1ULL << 63)

commit 0eb74fdda4ff72535849f9d99a8eabe69dceaddf
Author: Yan Burman <yanb@mellanox.com>
Date:   Thu Feb 7 02:25:23 2013 +0000

    net/mlx4_en: Re-arrange ndo_set_rx_mode related code
    
    Currently, mlx4_en_do_set_multicast serves as the ndo_set_rx_mode entry for mlx4_en,
    doing all related work. Split it to few calls, one per required functionality
    (e.g multicast, promiscuous, etc) and rename some structures and calls
    to use rx_mode notation instead of multicast.
    
    Signed-off-by: Yan Burman <yanb@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 84ed328582ac..47c9876a2449 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -504,7 +504,7 @@ struct mlx4_en_priv {
 	struct mlx4_en_cq *tx_cq;
 	struct mlx4_en_cq rx_cq[MAX_RX_RINGS];
 	struct mlx4_qp drop_qp;
-	struct work_struct mcast_task;
+	struct work_struct rx_mode_task;
 	struct work_struct mac_task;
 	struct work_struct watchdog_task;
 	struct work_struct linkstate_task;

commit 16a10ffd20a13215243bdba64c8e57ef277a55b9
Author: Yan Burman <yanb@mellanox.com>
Date:   Thu Feb 7 02:25:22 2013 +0000

    net/mlx4: Move Ethernet related functionality from mlx4_core to mlx4_en
    
    Move low level code that deals with management of Ethernet MACs and QPs from mlx4_core to mlx4_en.
    Also convert the new functions to deal with MACs in form of char array instead of u64.
    
    Actual functions moved:
    mlx4_replace_mac
    mlx4_get_eth_qp
    mlx4_put_eth_qp
    
    To conduct this change, some functionality had to be exported from the core,
    the following functions were added:
    mlx4_get_base_qp
    __mlx4_replace_mac (low level function for CX1/A0 compatibility)
    
    Signed-off-by: Yan Burman <yanb@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 9d0105d3eaf3..84ed328582ac 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -521,6 +521,7 @@ struct mlx4_en_priv {
 	bool wol;
 	struct device *ddev;
 	int base_tx_qpn;
+	struct radix_tree_root mac_tree;
 
 #ifdef CONFIG_MLX4_EN_DCB
 	struct ieee_ets ets;
@@ -540,6 +541,11 @@ enum mlx4_en_wol {
 	MLX4_EN_WOL_ENABLED = (1ULL << 62),
 };
 
+struct mlx4_mac_entry {
+	unsigned char mac[ETH_ALEN + 2];
+	u64 reg_id;
+};
+
 #define MLX4_EN_WOL_DO_MODIFY (1ULL << 63)
 
 void mlx4_en_update_loopback_state(struct net_device *dev,

commit 6bbb6d99f3d2653e634657ea0d85ef4c0fc49463
Author: Yan Burman <yanb@mellanox.com>
Date:   Thu Feb 7 02:25:20 2013 +0000

    net/mlx4_en: Optimize Rx fast path filter checks
    
    Currently, RX path code that does RX filtering is not optimized
    and does an expensive conversion. In order to use ether_addr_equal_64bits
    which is optimized for such cases, we need the MAC address kept by the device
    to be in the form of unsigned char array instead of u64. Store the MAC address
    as unsigned char array and convert to/from u64 out of the fast path when needed.
    Side effect of this is that we no longer need priv->mac, since it's the same
    as dev->dev_addr.
    
    This optimization was suggested by Eric Dumazet <eric.dumazet@gmail.com>
    
    Signed-off-by: Yan Burman <yanb@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 696dcf33619f..9d0105d3eaf3 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -198,7 +198,6 @@ enum cq_type {
  */
 #define ROUNDUP_LOG2(x)		ilog2(roundup_pow_of_two(x))
 #define XNOR(x, y)		(!(x) == !(y))
-#define ILLEGAL_MAC(addr)	(addr == 0xffffffffffffULL || addr == 0x0)
 
 
 struct mlx4_en_tx_info {
@@ -483,7 +482,7 @@ struct mlx4_en_priv {
 	int registered;
 	int allocated;
 	int stride;
-	u64 mac;
+	unsigned char prev_mac[ETH_ALEN + 2];
 	int mac_index;
 	unsigned max_mtu;
 	int base_qpn;

commit 79aeaccd915c527a75f2cb01682eab160bed4f48
Author: Yan Burman <yanb@mellanox.com>
Date:   Thu Feb 7 02:25:19 2013 +0000

    net/mlx4_en: Optimize loopback related checks in data path
    
    Currently there are relatively complex conditional checks in the fast path,
    for TX loopback enabling and resulting RX filter logic.
    Move elaborate if's out of data path, replace them with a single flag
    for each state and update that state from appropriate places.
    Also, in native (non SRIOV) mode and not in loopback or in selftest,
    there is no need to try and filter out packets that HW loopback-ed,
    as in native mode we do not loopback packets anymore.
    
    Signed-off-by: Yan Burman <yanb@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 43f01650e585..696dcf33619f 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -432,6 +432,17 @@ struct ethtool_flow_id {
 	u64 id;
 };
 
+enum {
+	MLX4_EN_FLAG_PROMISC		= (1 << 0),
+	MLX4_EN_FLAG_MC_PROMISC		= (1 << 1),
+	/* whether we need to enable hardware loopback by putting dmac
+	 * in Tx WQE
+	 */
+	MLX4_EN_FLAG_ENABLE_HW_LOOPBACK	= (1 << 2),
+	/* whether we need to drop packets that hardware loopback-ed */
+	MLX4_EN_FLAG_RX_FILTER_NEEDED	= (1 << 3)
+};
+
 struct mlx4_en_priv {
 	struct mlx4_en_dev *mdev;
 	struct mlx4_en_port_profile *prof;
@@ -481,8 +492,6 @@ struct mlx4_en_priv {
 	struct mlx4_en_rss_map rss_map;
 	__be32 ctrl_flags;
 	u32 flags;
-#define MLX4_EN_FLAG_PROMISC	0x1
-#define MLX4_EN_FLAG_MC_PROMISC	0x2
 	u8 num_tx_rings_p_up;
 	u32 tx_ring_num;
 	u32 rx_ring_num;
@@ -534,6 +543,9 @@ enum mlx4_en_wol {
 
 #define MLX4_EN_WOL_DO_MODIFY (1ULL << 63)
 
+void mlx4_en_update_loopback_state(struct net_device *dev,
+				   netdev_features_t features);
+
 void mlx4_en_destroy_netdev(struct net_device *dev);
 int mlx4_en_init_netdev(struct mlx4_en_dev *mdev, int port,
 			struct mlx4_en_port_profile *prof);

commit 3484aac16149636f0ba5b5b0789a2918c682db7e
Author: Amir Vadai <amirv@mellanox.com>
Date:   Wed Jan 30 23:07:11 2013 +0000

    net/mlx4_en: Fix transmit timeout when driver restarts port
    
    Under heavy CPU load, changing, ring size/mtu/etc. could result in transmit
    timeout, since stop-start port might take more than 10 seconds.
    Calling netif_detach_device to prevent tx queue transmit timeout.
    
    netif_detach_device() is not called under ndo_stop, because netif_carrier_off
    will prevent the timeout, and device should not be marked as not present, or
    else user won't be able to start it later on.
    
    CC: Ben Hutchings <bhutchings@solarflare.com>
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 4fb4a3e3ae8b..43f01650e585 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -539,7 +539,7 @@ int mlx4_en_init_netdev(struct mlx4_en_dev *mdev, int port,
 			struct mlx4_en_port_profile *prof);
 
 int mlx4_en_start_port(struct net_device *dev);
-void mlx4_en_stop_port(struct net_device *dev);
+void mlx4_en_stop_port(struct net_device *dev, int detach);
 
 void mlx4_en_free_resources(struct mlx4_en_priv *priv);
 int mlx4_en_alloc_resources(struct mlx4_en_priv *priv);

commit 0d256c0e93916f416f46d2ec235ea05fca202ede
Author: Hadar Hen Zion <hadarh@mellanox.com>
Date:   Wed Jan 30 23:07:08 2013 +0000

    net/mlx4_en: Fix ethtool rules leftovers after module unloaded
    
    As part of the driver unload flow, all steering rules must be deleted,
    make sure to remove the rules that were set through ethtool.
    
    Signed-off-by: Hadar Hen Zion <hadarh@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 8d54412ada63..4fb4a3e3ae8b 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -427,6 +427,7 @@ struct mlx4_en_frag_info {
 #endif
 
 struct ethtool_flow_id {
+	struct list_head list;
 	struct ethtool_rx_flow_spec flow_spec;
 	u64 id;
 };
@@ -441,6 +442,8 @@ struct mlx4_en_priv {
 	struct mlx4_en_port_state port_state;
 	spinlock_t stats_lock;
 	struct ethtool_flow_id ethtool_rules[MAX_NUM_OF_FS_RULES];
+	/* To allow rules removal while port is going down */
+	struct list_head ethtool_list;
 
 	unsigned long last_moder_packets[MAX_RX_RINGS];
 	unsigned long last_moder_tx_packets;

commit f132c54e3ab25b305a1e368ad413a417052c966e
Merge: d3b43e12b2c8 01e03365981e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Dec 13 19:19:09 2012 -0800

    Merge tag 'rdma-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/roland/infiniband
    
    Pull infiniband upate from Roland Dreier:
     "First batch of InfiniBand/RDMA changes for the 3.8 merge window:
       - A good chunk of Bart Van Assche's SRP fixes
       - UAPI disintegration from David Howells
       - mlx4 support for "64-byte CQE" hardware feature from Or Gerlitz
       - Other miscellaneous fixes"
    
    Fix up trivial conflict in mellanox/mlx4 driver.
    
    * tag 'rdma-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/roland/infiniband: (33 commits)
      RDMA/nes: Fix for crash when registering zero length MR for CQ
      RDMA/nes: Fix for terminate timer crash
      RDMA/nes: Fix for BUG_ON due to adding already-pending timer
      IB/srp: Allow SRP disconnect through sysfs
      srp_transport: Document sysfs attributes
      srp_transport: Simplify attribute initialization code
      srp_transport: Fix attribute registration
      IB/srp: Document sysfs attributes
      IB/srp: send disconnect request without waiting for CM timewait exit
      IB/srp: destroy and recreate QP and CQs when reconnecting
      IB/srp: Eliminate state SRP_TARGET_DEAD
      IB/srp: Introduce the helper function srp_remove_target()
      IB/srp: Suppress superfluous error messages
      IB/srp: Process all error completions
      IB/srp: Introduce srp_handle_qp_err()
      IB/srp: Simplify SCSI error handling
      IB/srp: Keep processing commands during host removal
      IB/srp: Eliminate state SRP_TARGET_CONNECTING
      IB/srp: Increase block layer timeout
      RDMA/cm: Change return value from find_gid_port()
      ...

commit d317966bd3249ee7cd912931ab013c49cb77b9a4
Author: Amir Vadai <amirv@mellanox.com>
Date:   Sun Dec 2 03:49:23 2012 +0000

    net/mlx4_en: Set number of rx/tx channels using ethtool
    
    Add support to changing number of rx/tx channels using
    ethtool ('ethtool -[lL]'). Where the number of tx channels specified in ethtool
    is the number of rings per user priority - not total number of tx rings.
    
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index d3eba8bcce13..334ec483480b 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -67,7 +67,8 @@
 
 #define MLX4_EN_PAGE_SHIFT	12
 #define MLX4_EN_PAGE_SIZE	(1 << MLX4_EN_PAGE_SHIFT)
-#define MAX_RX_RINGS		16
+#define DEF_RX_RINGS		16
+#define MAX_RX_RINGS		128
 #define MIN_RX_RINGS		4
 #define TXBB_SIZE		64
 #define HEADROOM		(2048 / TXBB_SIZE + 1)
@@ -118,6 +119,8 @@ enum {
 #define MLX4_EN_NUM_UP			8
 #define MLX4_EN_DEF_TX_RING_SIZE	512
 #define MLX4_EN_DEF_RX_RING_SIZE  	1024
+#define MAX_TX_RINGS			(MLX4_EN_MAX_TX_RING_P_UP * \
+					 MLX4_EN_NUM_UP)
 
 /* Target number of packets to coalesce with interrupt moderation */
 #define MLX4_EN_RX_COAL_TARGET	44
@@ -476,6 +479,7 @@ struct mlx4_en_priv {
 	u32 flags;
 #define MLX4_EN_FLAG_PROMISC	0x1
 #define MLX4_EN_FLAG_MC_PROMISC	0x2
+	u8 num_tx_rings_p_up;
 	u32 tx_ring_num;
 	u32 rx_ring_num;
 	u32 rx_skb_size;
@@ -596,6 +600,8 @@ int mlx4_en_QUERY_PORT(struct mlx4_en_dev *mdev, u8 port);
 extern const struct dcbnl_rtnl_ops mlx4_en_dcbnl_ops;
 #endif
 
+int mlx4_en_setup_tc(struct net_device *dev, u8 up);
+
 #ifdef CONFIG_RFS_ACCEL
 void mlx4_en_cleanup_filters(struct mlx4_en_priv *priv,
 			     struct mlx4_en_rx_ring *rx_ring);

commit 08ff32352d6ff7083533dc1c25618d42f92ec28e
Author: Or Gerlitz <ogerlitz@mellanox.com>
Date:   Sun Oct 21 14:59:24 2012 +0000

    mlx4: 64-byte CQE/EQE support
    
    ConnectX-3 devices can use either 64- or 32-byte completion queue
    entries (CQEs) and event queue entries (EQEs).  Using 64-byte
    EQEs/CQEs performs better because each entry is aligned to a complete
    cacheline.  This patch queries the HCA's capabilities, and if it
    supports 64-byte CQEs and EQES the driver will configure the HW to
    work in 64-byte mode.
    
    The 32-byte vs 64-byte mode is global per HCA and not per CQ or EQ.
    
    Since this mode is global, userspace (libmlx4) must be updated to work
    with the configured CQE size, and guests using SR-IOV virtual
    functions need to know both EQE and CQE size.
    
    In case one of the 64-byte CQE/EQE capabilities is activated, the
    patch makes sure that older guest drivers that use the QUERY_DEV_FUNC
    command (e.g as done in mlx4_core of Linux 3.3..3.6) will notice that
    they need an update to be able to work with the PPF. This is done by
    changing the returned pf_context_behaviour not to be zero any more. In
    case none of these capabilities is activated that value remains zero
    and older guest drivers can run OK.
    
    The SRIOV related flow is as follows
    
    1. the PPF does the detection of the new capabilities using
       QUERY_DEV_CAP command.
    
    2. the PPF activates the new capabilities using INIT_HCA.
    
    3. the VF detects if the PPF activated the capabilities using
       QUERY_HCA, and if this is the case activates them for itself too.
    
    Note that the VF detects that it must be aware to the new PF behaviour
    using QUERY_FUNC_CAP.  Steps 1 and 2 apply also for native mode.
    
    User space notification is done through a new field introduced in
    struct mlx4_ib_ucontext which holds device capabilities for which user
    space must take action. This changes the binary interface so the ABI
    towards libmlx4 exposed through uverbs is bumped from 3 to 4 but only
    when **needed** i.e. only when the driver does use 64-byte CQEs or
    future device capabilities which must be in sync by user space. This
    practice allows to work with unmodified libmlx4 on older devices (e.g
    A0, B0) which don't support 64-byte CQEs.
    
    In order to keep existing systems functional when they update to a
    newer kernel that contains these changes in VF and userspace ABI, a
    module parameter enable_64b_cqe_eqe must be set to enable 64-byte
    mode; the default is currently false.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 9d27e42264e2..73b5c2ac5bd5 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -487,6 +487,7 @@ struct mlx4_en_priv {
 	int mac_index;
 	unsigned max_mtu;
 	int base_qpn;
+	int cqe_factor;
 
 	struct mlx4_en_rss_map rss_map;
 	__be32 ctrl_flags;

commit f1d29a3fa68ba7c0b78b659a0e427ab834a26b44
Author: Ben Hutchings <bhutchings@solarflare.com>
Date:   Fri Nov 16 12:44:56 2012 +0000

    mlx4_en: Remove remnants of LRO support
    
    Commit fa37a9586f92051de03a13e55e5ec3880bb6783e ('mlx4_en: Moving to
    work with GRO') left behind the Kconfig depends/select, some dead
    code and comments referring to LRO.
    
    Signed-off-by: Ben Hutchings <bhutchings@solarflare.com>
    Acked-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 8a5e70d68894..d3eba8bcce13 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -95,8 +95,6 @@
 #define MLX4_EN_ALLOC_SIZE	PAGE_ALIGN(16384)
 #define MLX4_EN_ALLOC_ORDER	get_order(MLX4_EN_ALLOC_SIZE)
 
-#define MLX4_EN_MAX_LRO_DESCRIPTORS	32
-
 /* Receive fragment sizes; we use at most 4 fragments (for 9600 byte MTU
  * and 4K allocations) */
 enum {
@@ -290,21 +288,6 @@ struct mlx4_en_rx_ring {
 	unsigned long csum_none;
 };
 
-
-static inline int mlx4_en_can_lro(__be16 status)
-{
-	return (status & cpu_to_be16(MLX4_CQE_STATUS_IPV4	|
-				     MLX4_CQE_STATUS_IPV4F	|
-				     MLX4_CQE_STATUS_IPV6	|
-				     MLX4_CQE_STATUS_IPV4OPT	|
-				     MLX4_CQE_STATUS_TCP	|
-				     MLX4_CQE_STATUS_UDP	|
-				     MLX4_CQE_STATUS_IPOK)) ==
-		cpu_to_be16(MLX4_CQE_STATUS_IPV4 |
-			    MLX4_CQE_STATUS_IPOK |
-			    MLX4_CQE_STATUS_TCP);
-}
-
 struct mlx4_en_cq {
 	struct mlx4_cq          mcq;
 	struct mlx4_hwq_resources wqres;

commit ecfd2ce1a9d5e6376ff5c00b366345160abdbbb7
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Nov 5 16:20:42 2012 +0000

    mlx4: change TX coalescing defaults
    
    mlx4 currently uses a too high tx coalescing setting, deferring
    TX completion interrupts by up to 128 us.
    
    With the recent skb_orphan() removal in commit 8112ec3b872,
    performance of a single TCP flow is capped to ~4 Gbps, unless
    we increase tcp_limit_output_bytes.
    
    I suggest using 16 us instead of 128 us, allowing a finer control.
    
    Performance of a single TCP flow is restored to previous levels,
    while keeping TCP small queues fully enabled with default sysctl.
    
    This patch is also a BQL prereq.
    
    Reported-by: Vimalkumar <j.vimal@gmail.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Yevgeny Petrilin <yevgenyp@mellanox.com>
    Cc: Or Gerlitz <ogerlitz@mellanox.com>
    Acked-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 9d27e42264e2..8a5e70d68894 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -126,7 +126,7 @@ enum {
 #define MLX4_EN_RX_COAL_TIME	0x10
 
 #define MLX4_EN_TX_COAL_PKTS	16
-#define MLX4_EN_TX_COAL_TIME	0x80
+#define MLX4_EN_TX_COAL_TIME	0x10
 
 #define MLX4_EN_RX_RATE_LOW		400000
 #define MLX4_EN_RX_COAL_TIME_LOW	0

commit c18520bd1b244fe8e3ac5358137321780a70d6e7
Author: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
Date:   Fri Aug 3 00:38:37 2012 +0000

    net/mlx4_en: Fixing TX queue stop/wake flow
    
    Removing the ring->blocked flag, it is redundant and leads to a race:
    
    We close the TX queue and then set the "blocked" flag.
    Between those 2 operations the completion function can check the "blocked"
    flag, sees that it is 0, and wouldn't open the TX queue.
    
    Using netif_tx_queue_stopped to check the state of the queue to avoid this race.
    
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 5f1ab105debc..9d27e42264e2 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -248,7 +248,6 @@ struct mlx4_en_tx_ring {
 	u32 doorbell_qpn;
 	void *buf;
 	u16 poll_cnt;
-	int blocked;
 	struct mlx4_en_tx_info *tx_info;
 	u8 *bounce_buf;
 	u32 last_nr_txbb;

commit 4cce66cdd14aa5006a011505865d932adb49f600
Author: Thadeu Lima de Souza Cascardo <cascardo@linux.vnet.ibm.com>
Date:   Mon Jul 16 07:01:53 2012 +0000

    mlx4_en: map entire pages to increase throughput
    
    In its receive path, mlx4_en driver maps each page chunk that it pushes
    to the hardware and unmaps it when pushing it up the stack. This limits
    throughput to about 3Gbps on a Power7 8-core machine.
    
    One solution is to map the entire allocated page at once. However, this
    requires that we keep track of every page fragment we give to a
    descriptor. We also need to work with the discipline that all fragments will
    be released (in the sense that it will not be reused by the driver
    anymore) in the order they are allocated to the driver.
    
    This requires that we don't reuse any fragments, every single one of
    them must be reallocated. We do that by releasing all the fragments that
    are processed and only after finished processing the descriptors, we
    start the refill.
    
    We also must somehow guarantee that we either refill all fragments in a
    descriptor or none at all, without resorting to giving up a page
    fragment that we would have already given. Otherwise, we would break the
    discipline of only releasing the fragments in the order they were
    allocated.
    
    This has passed page allocation fault injections (restricted to the
    driver by using required-start and required-end) and device hotplug
    while 16 TCP streams were able to deliver more than 9Gbps.
    
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@linux.vnet.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index af34c98d43e5..5f1ab105debc 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -111,7 +111,7 @@ enum {
 #define MLX4_EN_MAX_TX_SIZE	8192
 #define MLX4_EN_MAX_RX_SIZE	8192
 
-/* Minimum ring size for our page-allocation sceme to work */
+/* Minimum ring size for our page-allocation scheme to work */
 #define MLX4_EN_MIN_RX_SIZE	(MLX4_EN_ALLOC_SIZE / SMP_CACHE_BYTES)
 #define MLX4_EN_MIN_TX_SIZE	(4096 / TXBB_SIZE)
 
@@ -232,6 +232,7 @@ struct mlx4_en_tx_desc {
 
 struct mlx4_en_rx_alloc {
 	struct page *page;
+	dma_addr_t dma;
 	u16 offset;
 };
 

commit 1eb8c695bda92ccaec30e9a3351e37a1896da54f
Author: Amir Vadai <amirv@mellanox.com>
Date:   Wed Jul 18 22:33:52 2012 +0000

    net/mlx4_en: Add accelerated RFS support
    
    Use RFS infrastructure and flow steering in HW to keep CPU
    affinity of rx interrupts and application per TCP stream.
    
    A flow steering filter is added to the HW whenever the RFS
    ndo callback is invoked by core networking code.
    
    Because the invocation takes place in interrupt context, the
    actual setup of HW is done using workqueue. Whenever new filter
    is added, the driver checks for expiry of existing filters.
    
    Since there's window in time between the point where the core
    RFS code invoked the ndo callback, to the point where the HW
    is configured from the workqueue context, the 2nd, 3rd etc
    packets from that stream will cause the net core to invoke
    the callback again and again.
    
    To prevent inefficient/double configuration of the HW, the filters
    are kept in a database which is indexed using hash function to enable
    fast access.
    
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index a12632150b34..af34c98d43e5 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -43,6 +43,7 @@
 #ifdef CONFIG_MLX4_EN_DCB
 #include <linux/dcbnl.h>
 #endif
+#include <linux/cpu_rmap.h>
 
 #include <linux/mlx4/device.h>
 #include <linux/mlx4/qp.h>
@@ -77,6 +78,9 @@
 #define STATS_DELAY		(HZ / 4)
 #define MAX_NUM_OF_FS_RULES	256
 
+#define MLX4_EN_FILTER_HASH_SHIFT 4
+#define MLX4_EN_FILTER_EXPIRY_QUOTA 60
+
 /* Typical TSO descriptor with 16 gather entries is 352 bytes... */
 #define MAX_DESC_SIZE		512
 #define MAX_DESC_TXBBS		(MAX_DESC_SIZE / TXBB_SIZE)
@@ -523,6 +527,13 @@ struct mlx4_en_priv {
 	struct ieee_ets ets;
 	u16 maxrate[IEEE_8021QAZ_MAX_TCS];
 #endif
+#ifdef CONFIG_RFS_ACCEL
+	spinlock_t filters_lock;
+	int last_filter_id;
+	struct list_head filters;
+	struct hlist_head filter_hash[1 << MLX4_EN_FILTER_HASH_SHIFT];
+#endif
+
 };
 
 enum mlx4_en_wol {
@@ -602,6 +613,11 @@ int mlx4_en_QUERY_PORT(struct mlx4_en_dev *mdev, u8 port);
 extern const struct dcbnl_rtnl_ops mlx4_en_dcbnl_ops;
 #endif
 
+#ifdef CONFIG_RFS_ACCEL
+void mlx4_en_cleanup_filters(struct mlx4_en_priv *priv,
+			     struct mlx4_en_rx_ring *rx_ring);
+#endif
+
 #define MLX4_EN_NUM_SELF_TEST	5
 void mlx4_en_ex_selftest(struct net_device *dev, u32 *flags, u64 *buf);
 u64 mlx4_en_mac_to_u64(u8 *addr);

commit cabdc8ee3768ceb6367e88c6fe84a66dd667bdf9
Author: Hadar Hen Zion <hadarh@mellanox.co.il>
Date:   Thu Jul 5 04:03:50 2012 +0000

    net/mlx4_en: Add support for drop action through ethtool
    
    The drop action is implemented by allocating a QP and keeping it in a reset state
    such that the HW drops any packets which are steered to that QP. When a drop action
    is requested, we attach the relevant flow to that QP.
    
    Sign-off-by: Hadar Hen Zion <hadarh@mellanox.co.il>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 8882e70493fe..a12632150b34 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -500,6 +500,7 @@ struct mlx4_en_priv {
 	struct mlx4_en_rx_ring rx_ring[MAX_RX_RINGS];
 	struct mlx4_en_cq *tx_cq;
 	struct mlx4_en_cq rx_cq[MAX_RX_RINGS];
+	struct mlx4_qp drop_qp;
 	struct work_struct mcast_task;
 	struct work_struct mac_task;
 	struct work_struct watchdog_task;
@@ -586,6 +587,8 @@ void mlx4_en_unmap_buffer(struct mlx4_buf *buf);
 void mlx4_en_calc_rx_buf(struct net_device *dev);
 int mlx4_en_config_rss_steer(struct mlx4_en_priv *priv);
 void mlx4_en_release_rss_steer(struct mlx4_en_priv *priv);
+int mlx4_en_create_drop_qp(struct mlx4_en_priv *priv);
+void mlx4_en_destroy_drop_qp(struct mlx4_en_priv *priv);
 int mlx4_en_free_tx_buf(struct net_device *dev, struct mlx4_en_tx_ring *ring);
 void mlx4_en_rx_irq(struct mlx4_cq *mcq);
 

commit 820672812f8284143f933da8ccc60e296230d25d
Author: Hadar Hen Zion <hadarh@mellanox.co.il>
Date:   Thu Jul 5 04:03:49 2012 +0000

    net/mlx4_en: Manage flow steering rules with ethtool
    
    Implement the ethtool APIs for attaching L2/L3/L4 based flow steering
    rules to the netdevice RX rings. Added set_rxnfc callback and enhanced
    the existing get_rxnfc callback.
    
    Signed-off-by: Hadar Hen Zion <hadarh@mellanox.co.il>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 2d6dabe7f55d..8882e70493fe 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -75,6 +75,7 @@
 #define STAMP_SHIFT		31
 #define STAMP_VAL		0x7fffffff
 #define STATS_DELAY		(HZ / 4)
+#define MAX_NUM_OF_FS_RULES	256
 
 /* Typical TSO descriptor with 16 gather entries is 352 bytes... */
 #define MAX_DESC_SIZE		512
@@ -435,6 +436,11 @@ struct mlx4_en_frag_info {
 
 #endif
 
+struct ethtool_flow_id {
+	struct ethtool_rx_flow_spec flow_spec;
+	u64 id;
+};
+
 struct mlx4_en_priv {
 	struct mlx4_en_dev *mdev;
 	struct mlx4_en_port_profile *prof;
@@ -444,6 +450,7 @@ struct mlx4_en_priv {
 	struct net_device_stats ret_stats;
 	struct mlx4_en_port_state port_state;
 	spinlock_t stats_lock;
+	struct ethtool_flow_id ethtool_rules[MAX_NUM_OF_FS_RULES];
 
 	unsigned long last_moder_packets[MAX_RX_RINGS];
 	unsigned long last_moder_tx_packets;

commit 0ff1fb654bec0cff62ddf81a8a8edec4263604a0
Author: Hadar Hen Zion <hadarh@mellanox.co.il>
Date:   Thu Jul 5 04:03:46 2012 +0000

    {NET, IB}/mlx4: Add device managed flow steering firmware API
    
    The driver is modified to support three operation modes.
    
    If supported by firmware use the device managed flow steering
    API, that which we call device managed steering mode. Else, if
    the firmware supports the B0 steering mode use it, and finally,
    if none of the above, use the A0 steering mode.
    
    When the steering mode is device managed, the code is modified
    such that L2 based rules set by the mlx4_en driver for Ethernet
    unicast and multicast, and the IB stack multicast attach calls
    done through the mlx4_ib driver are all routed to use the device
    managed API.
    
    When attaching rule using device managed flow steering API,
    the firmware returns a 64 bit registration id, which is to be
    provided during detach.
    
    Currently the firmware is always programmed during HCA initialization
    to use standard L2 hashing. Future work should be done to allow
    configuring the flow-steering hash function with common, non
    proprietary means.
    
    Signed-off-by: Hadar Hen Zion <hadarh@mellanox.co.il>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 1bb00cd22d42..2d6dabe7f55d 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -414,6 +414,7 @@ struct mlx4_en_mc_list {
 	struct list_head	list;
 	enum mlx4_en_mclist_act	action;
 	u8			addr[ETH_ALEN];
+	u64			reg_id;
 };
 
 struct mlx4_en_frag_info {
@@ -503,6 +504,7 @@ struct mlx4_en_priv {
 	u64 stats_bitmap;
 	struct list_head mc_list;
 	struct list_head curr_list;
+	u64 broadcast_id;
 	struct mlx4_en_stat_out_mbox hw_stats;
 	int vids[128];
 	bool wol;

commit 6d19993788e080edb557178cc6aba2d963edce4e
Author: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
Date:   Thu Jul 5 04:03:43 2012 +0000

    net/mlx4_en: Re-design multicast attachments flow
    
    Currently, for every change in the net device multicast list, the driver
    detaches all the addresses from the HW device, and then attaches the
    updated list. This behavior is wrong from two aspects: first, it causes
    a load of firmware commands and second, there is period of time where
    the correct addresses are not attached, which turned into packet loss.
    
    To improve - a copy of the multicast list is saved by the driver. For
    every change in the multicast list, the multicast list copy is used
    to find the delta between those two lists and add or remove multicast
    addresses as needed.
    
    Reported-by: Shawn Bohrer <sbohrer@rgmadvisors.com>
    Cc: Shawn Bohrer <sbohrer@rgmadvisors.com>
    Signed-off-by: Hadar Hen Zion <hadarh@mellanox.co.il>
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 225c20d47900..1bb00cd22d42 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -404,6 +404,18 @@ struct mlx4_en_perf_stats {
 #define NUM_PERF_COUNTERS		6
 };
 
+enum mlx4_en_mclist_act {
+	MCLIST_NONE,
+	MCLIST_REM,
+	MCLIST_ADD,
+};
+
+struct mlx4_en_mc_list {
+	struct list_head	list;
+	enum mlx4_en_mclist_act	action;
+	u8			addr[ETH_ALEN];
+};
+
 struct mlx4_en_frag_info {
 	u16 frag_size;
 	u16 frag_prefix_size;
@@ -489,8 +501,8 @@ struct mlx4_en_priv {
 	struct mlx4_en_pkt_stats pkstats;
 	struct mlx4_en_port_stats port_stats;
 	u64 stats_bitmap;
-	char *mc_addrs;
-	int mc_addrs_cnt;
+	struct list_head mc_list;
+	struct list_head curr_list;
 	struct mlx4_en_stat_out_mbox hw_stats;
 	int vids[128];
 	bool wol;

commit 044ca2a5f2f781c7e4b49c7c0a256913648297ea
Author: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
Date:   Mon Jun 25 00:24:13 2012 +0000

    net/mlx4_en: Release QP range in free_resources
    
    Add a missing resource release in ring cleanup.
    Not doing this leaves a range of QPs that are being reserved,
    and no one can use them.
    
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 6ae350921b1a..225c20d47900 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -495,6 +495,7 @@ struct mlx4_en_priv {
 	int vids[128];
 	bool wol;
 	struct device *ddev;
+	int base_tx_qpn;
 
 #ifdef CONFIG_MLX4_EN_DCB
 	struct ieee_ets ets;

commit bc6a4744b827c5a78ca591acca81809bddb8b2db
Author: Amir Vadai <amirv@mellanox.com>
Date:   Thu May 17 00:58:10 2012 +0000

    net/mlx4_en: num cores tx rings for every UP
    
    Change the TX ring scheme such that the number of rings for untagged packets
    and for tagged packets (per each of the vlan priorities) is the same, unlike
    the current situation where for tagged traffic there's one ring per priority
    and for untagged rings as the number of core.
    
    Queue selection is done as follows:
    
    If the mqprio qdisc is operates on the interface, such that the core networking
    code invoked the device setup_tc ndo callback, a mapping of skb->priority =>
    queue set is forced - for both, tagged and untagged traffic.
    
    Else, the egress map skb->priority =>  User priority is used for tagged traffic, and
    all untagged traffic is sent through tx rings of UP 0.
    
    The patch follows the convergence of discussing that issue with John Fastabend
    over this thread http://comments.gmane.org/gmane.linux.network/229877
    
    Cc: John Fastabend <john.r.fastabend@intel.com>
    Cc: Liran Liss <liranl@mellanox.com>
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 5d876375a132..6ae350921b1a 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -111,9 +111,7 @@ enum {
 #define MLX4_EN_MIN_TX_SIZE	(4096 / TXBB_SIZE)
 
 #define MLX4_EN_SMALL_PKT_SIZE		64
-#define MLX4_EN_NUM_TX_RINGS		8
-#define MLX4_EN_NUM_PPP_RINGS		8
-#define MAX_TX_RINGS			(MLX4_EN_NUM_TX_RINGS + MLX4_EN_NUM_PPP_RINGS)
+#define MLX4_EN_MAX_TX_RING_P_UP	32
 #define MLX4_EN_NUM_UP			8
 #define MLX4_EN_DEF_TX_RING_SIZE	512
 #define MLX4_EN_DEF_RX_RING_SIZE  	1024
@@ -339,6 +337,7 @@ struct mlx4_en_profile {
 	u32 active_ports;
 	u32 small_pkt_int;
 	u8 no_reset;
+	u8 num_tx_rings_p_up;
 	struct mlx4_en_port_profile prof[MLX4_MAX_PORTS + 1];
 };
 
@@ -477,9 +476,9 @@ struct mlx4_en_priv {
 	u16 num_frags;
 	u16 log_rx_info;
 
-	struct mlx4_en_tx_ring tx_ring[MAX_TX_RINGS];
+	struct mlx4_en_tx_ring *tx_ring;
 	struct mlx4_en_rx_ring rx_ring[MAX_RX_RINGS];
-	struct mlx4_en_cq tx_cq[MAX_TX_RINGS];
+	struct mlx4_en_cq *tx_cq;
 	struct mlx4_en_cq rx_cq[MAX_RX_RINGS];
 	struct work_struct mcast_task;
 	struct work_struct mac_task;

commit 5b263f5374ea70daa61ed9f5cc5d8f4ac236efbd
Author: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
Date:   Mon Apr 23 02:18:50 2012 +0000

    mlx4_en: Byte Queue Limit support
    
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 0feafc5344b3..5d876375a132 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -200,6 +200,7 @@ enum cq_type {
 struct mlx4_en_tx_info {
 	struct sk_buff *skb;
 	u32 nr_txbb;
+	u32 nr_bytes;
 	u8 linear;
 	u8 data_offset;
 	u8 inl;
@@ -257,6 +258,7 @@ struct mlx4_en_tx_ring {
 	unsigned long tx_csum;
 	struct mlx4_bf bf;
 	bool bf_enabled;
+	struct netdev_queue *tx_queue;
 };
 
 struct mlx4_en_rx_desc {

commit e22979d96a55d24bc43247341a052ec1b3a7fda6
Author: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
Date:   Mon Apr 23 02:18:39 2012 +0000

    mlx4_en: Moving to Interrupts for TX completions
    
    Moving to interrupts instead of polling fpr TX completions
    Avoiding situations where skb can be held in by the driver for
    a long time (till timer expires).
    The change is also necessary for supporting BQL.
    
    Removing comp_lock that was required because we could handle TX
    completions from several contexts: Interrupts, timer, polling.
    Now there is only interrupts
    
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 47e1c0ff1775..0feafc5344b3 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -122,7 +122,7 @@ enum {
 #define MLX4_EN_RX_COAL_TARGET	44
 #define MLX4_EN_RX_COAL_TIME	0x10
 
-#define MLX4_EN_TX_COAL_PKTS	5
+#define MLX4_EN_TX_COAL_PKTS	16
 #define MLX4_EN_TX_COAL_TIME	0x80
 
 #define MLX4_EN_RX_RATE_LOW		400000
@@ -255,7 +255,6 @@ struct mlx4_en_tx_ring {
 	unsigned long bytes;
 	unsigned long packets;
 	unsigned long tx_csum;
-	spinlock_t comp_lock;
 	struct mlx4_bf bf;
 	bool bf_enabled;
 };
@@ -308,8 +307,6 @@ struct mlx4_en_cq {
 	spinlock_t              lock;
 	struct net_device      *dev;
 	struct napi_struct	napi;
-	/* Per-core Tx cq processing support */
-	struct timer_list timer;
 	int size;
 	int buf_size;
 	unsigned vector;
@@ -530,7 +527,6 @@ void mlx4_en_deactivate_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
 int mlx4_en_set_cq_moder(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
 int mlx4_en_arm_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
 
-void mlx4_en_poll_tx_cq(unsigned long data);
 void mlx4_en_tx_irq(struct mlx4_cq *mcq);
 u16 mlx4_en_select_queue(struct net_device *dev, struct sk_buff *skb);
 netdev_tx_t mlx4_en_xmit(struct sk_buff *skb, struct net_device *dev);

commit 06eb4eafbdc0796d741d139a44f1253278da8611
Merge: 32ed53b83ea5 f68e556e23d1
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Apr 10 14:30:45 2012 -0400

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net

commit 109d2446052a484c58f07f71f9457bf7b71017f8
Author: Amir Vadai <amirv@mellanox.com>
Date:   Wed Apr 4 21:33:31 2012 +0000

    net/mlx4_en: Set max rate-limit for a TC
    
    This patch is using the DCB netlink to set rate limit per ETS TC
    Values are accepted in Kbps and rounded up to the nearest multiply of 100Mbps.
    
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 97d4f3540f6e..3879c5eee62b 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -499,6 +499,7 @@ struct mlx4_en_priv {
 
 #ifdef CONFIG_MLX4_EN_DCB
 	struct ieee_ets ets;
+	u16 maxrate[IEEE_8021QAZ_MAX_TCS];
 #endif
 };
 

commit 564c274c3df07d727fbe23684dc3077a9dd30607
Author: Amir Vadai <amirv@mellanox.com>
Date:   Wed Apr 4 21:33:26 2012 +0000

    net/mlx4_en: DCB QoS support
    
    Set TSA, promised BW and PFC using IEEE 802.1qaz netlink commands.
    
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 5bd7c2a3823e..97d4f3540f6e 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -40,6 +40,9 @@
 #include <linux/mutex.h>
 #include <linux/netdevice.h>
 #include <linux/if_vlan.h>
+#ifdef CONFIG_MLX4_EN_DCB
+#include <linux/dcbnl.h>
+#endif
 
 #include <linux/mlx4/device.h>
 #include <linux/mlx4/qp.h>
@@ -110,6 +113,7 @@ enum {
 #define MLX4_EN_NUM_TX_RINGS		8
 #define MLX4_EN_NUM_PPP_RINGS		8
 #define MAX_TX_RINGS			(MLX4_EN_NUM_TX_RINGS + MLX4_EN_NUM_PPP_RINGS)
+#define MLX4_EN_NUM_UP			8
 #define MLX4_EN_DEF_TX_RING_SIZE	512
 #define MLX4_EN_DEF_RX_RING_SIZE  	1024
 
@@ -410,6 +414,15 @@ struct mlx4_en_frag_info {
 
 };
 
+#ifdef CONFIG_MLX4_EN_DCB
+/* Minimal TC BW - setting to 0 will block traffic */
+#define MLX4_EN_BW_MIN 1
+#define MLX4_EN_BW_MAX 100 /* Utilize 100% of the line */
+
+#define MLX4_EN_TC_ETS 7
+
+#endif
+
 struct mlx4_en_priv {
 	struct mlx4_en_dev *mdev;
 	struct mlx4_en_port_profile *prof;
@@ -483,6 +496,10 @@ struct mlx4_en_priv {
 	int vids[128];
 	bool wol;
 	struct device *ddev;
+
+#ifdef CONFIG_MLX4_EN_DCB
+	struct ieee_ets ets;
+#endif
 };
 
 enum mlx4_en_wol {
@@ -557,6 +574,10 @@ int mlx4_SET_VLAN_FLTR(struct mlx4_dev *dev, struct mlx4_en_priv *priv);
 int mlx4_en_DUMP_ETH_STATS(struct mlx4_en_dev *mdev, u8 port, u8 reset);
 int mlx4_en_QUERY_PORT(struct mlx4_en_dev *mdev, u8 port);
 
+#ifdef CONFIG_MLX4_EN_DCB
+extern const struct dcbnl_rtnl_ops mlx4_en_dcbnl_ops;
+#endif
+
 #define MLX4_EN_NUM_SELF_TEST	5
 void mlx4_en_ex_selftest(struct net_device *dev, u32 *flags, u64 *buf);
 u64 mlx4_en_mac_to_u64(u8 *addr);

commit 0e98b523c4a4119cbd17e58dff385cc329064694
Author: Amir Vadai <amirv@mellanox.com>
Date:   Wed Apr 4 21:33:24 2012 +0000

    net/mlx4_en: Force user priority by QP attribute
    
    Instead of relying on HW to change schedule queue by UP, schedule
    queue is fixed for a tx_ring, and UP in WQE is ignored in this aspect.  This
    resolves two issues with untagged traffic:
    1. untagged traffic has no UP in packet which is needed for QoS. The change
       above allows setting the schedule queue (and by that the UP) of such a stream.
    2. BlueFlame uses the same field used by vlan tag. So forcing UP from QPC
       allows using BF for untagged but prioritized traffic.
    
    In old firmware that force UP is not supported, untagged traffic will not subject to
    QoS.
    
    Because UP is set by QP, need to always have a tx ring per UP, even if pfcrx
    module paramter is false.
    
    Signed-off-by: Amir Vadai <amirv@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 9e2b911a1230..5bd7c2a3823e 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -521,7 +521,7 @@ int mlx4_en_create_tx_ring(struct mlx4_en_priv *priv, struct mlx4_en_tx_ring *ri
 void mlx4_en_destroy_tx_ring(struct mlx4_en_priv *priv, struct mlx4_en_tx_ring *ring);
 int mlx4_en_activate_tx_ring(struct mlx4_en_priv *priv,
 			     struct mlx4_en_tx_ring *ring,
-			     int cq);
+			     int cq, int user_prio);
 void mlx4_en_deactivate_tx_ring(struct mlx4_en_priv *priv,
 				struct mlx4_en_tx_ring *ring);
 
@@ -539,8 +539,8 @@ int mlx4_en_process_rx_cq(struct net_device *dev,
 			  int budget);
 int mlx4_en_poll_rx_cq(struct napi_struct *napi, int budget);
 void mlx4_en_fill_qp_context(struct mlx4_en_priv *priv, int size, int stride,
-			     int is_tx, int rss, int qpn, int cqn,
-			     struct mlx4_qp_context *context);
+		int is_tx, int rss, int qpn, int cqn, int user_prio,
+		struct mlx4_qp_context *context);
 void mlx4_en_sqp_event(struct mlx4_qp *qp, enum mlx4_event event);
 int mlx4_en_map_buffer(struct mlx4_buf *buf);
 void mlx4_en_unmap_buffer(struct mlx4_buf *buf);

commit 117980c4c994b6fe58e873fe803c9bcdcb4337a3
Author: Thadeu Lima de Souza Cascardo <cascardo@linux.vnet.ibm.com>
Date:   Wed Apr 4 09:40:40 2012 +0000

    mlx4: allocate just enough pages instead of always 4 pages
    
    The driver uses a 2-order allocation, which is too much on architectures
    like ppc64, which has a 64KiB page. This particular allocation is used
    for large packet fragments that may have a size of 512, 1024, 4096 or
    fill the whole allocation. So, a minimum size of 16384 is good enough
    and will be the same size that is used in architectures of 4KiB sized
    pages.
    
    This will avoid allocation failures that we see when the system is under
    stress, but still has plenty of memory, like the one below.
    
    This will also allow us to set the interface MTU to higher values like
    9000, which was not possible on ppc64 without this patch.
    
    Node 1 DMA: 737*64kB 37*128kB 0*256kB 0*512kB 0*1024kB 0*2048kB 0*4096kB 0*8192kB 0*16384kB = 51904kB
    83137 total pagecache pages
    0 pages in swap cache
    Swap cache stats: add 0, delete 0, find 0/0
    Free swap  = 10420096kB
    Total swap = 10420096kB
    107776 pages RAM
    1184 pages reserved
    147343 pages shared
    28152 pages non-shared
    netstat: page allocation failure. order:2, mode:0x4020
    Call Trace:
    [c0000001a4fa3770] [c000000000012f04] .show_stack+0x74/0x1c0 (unreliable)
    [c0000001a4fa3820] [c00000000016af38] .__alloc_pages_nodemask+0x618/0x930
    [c0000001a4fa39a0] [c0000000001a71a0] .alloc_pages_current+0xb0/0x170
    [c0000001a4fa3a40] [d00000000dcc3e00] .mlx4_en_alloc_frag+0x200/0x240 [mlx4_en]
    [c0000001a4fa3b10] [d00000000dcc3f8c] .mlx4_en_complete_rx_desc+0x14c/0x250 [mlx4_en]
    [c0000001a4fa3be0] [d00000000dcc4eec] .mlx4_en_process_rx_cq+0x62c/0x850 [mlx4_en]
    [c0000001a4fa3d20] [d00000000dcc5150] .mlx4_en_poll_rx_cq+0x40/0x90 [mlx4_en]
    [c0000001a4fa3dc0] [c0000000004e2bb8] .net_rx_action+0x178/0x450
    [c0000001a4fa3eb0] [c00000000009c9b8] .__do_softirq+0x118/0x290
    [c0000001a4fa3f90] [c000000000031df8] .call_do_softirq+0x14/0x24
    [c000000184c3b520] [c00000000000e700] .do_softirq+0xf0/0x110
    [c000000184c3b5c0] [c00000000009c6d4] .irq_exit+0xb4/0xc0
    [c000000184c3b640] [c00000000000e964] .do_IRQ+0x144/0x230
    
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@linux.vnet.ibm.com>
    Signed-off-by: Kleber Sacilotto de Souza <klebers@linux.vnet.ibm.com>
    Tested-by: Kleber Sacilotto de Souza <klebers@linux.vnet.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 9e2b911a1230..d69fee41f24a 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -83,8 +83,9 @@
 
 #define MLX4_EN_WATCHDOG_TIMEOUT	(15 * HZ)
 
-#define MLX4_EN_ALLOC_ORDER	2
-#define MLX4_EN_ALLOC_SIZE	(PAGE_SIZE << MLX4_EN_ALLOC_ORDER)
+/* Use the maximum between 16384 and a single page */
+#define MLX4_EN_ALLOC_SIZE	PAGE_ALIGN(16384)
+#define MLX4_EN_ALLOC_ORDER	get_order(MLX4_EN_ALLOC_SIZE)
 
 #define MLX4_EN_MAX_LRO_DESCRIPTORS	32
 

commit 9a9a232a9295deb3b6b5f4ce4290a7d05ff061fa
Author: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
Date:   Tue Mar 6 04:04:47 2012 +0000

    net/mlx4: fixing sparse warnings for not declared, functions
    
    The SET_PORT functions are implemented in port.c, which is part
    of mlx4_core, these functions are exported. The functions are in use by
    the mlx4_en module (were originally part of mlx4_en).
    Their declaration remained in mlx4_en module, moving the declaration to the right location.
    
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 8f4e655bd57b..9e2b911a1230 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -553,10 +553,6 @@ void mlx4_en_rx_irq(struct mlx4_cq *mcq);
 
 int mlx4_SET_MCAST_FLTR(struct mlx4_dev *dev, u8 port, u64 mac, u64 clear, u8 mode);
 int mlx4_SET_VLAN_FLTR(struct mlx4_dev *dev, struct mlx4_en_priv *priv);
-int mlx4_SET_PORT_general(struct mlx4_dev *dev, u8 port, int mtu,
-			  u8 pptx, u8 pfctx, u8 pprx, u8 pfcrx);
-int mlx4_SET_PORT_qpn_calc(struct mlx4_dev *dev, u8 port, u32 base_qpn,
-			   u8 promisc);
 
 int mlx4_en_DUMP_ETH_STATS(struct mlx4_en_dev *mdev, u8 port, u8 reset);
 int mlx4_en_QUERY_PORT(struct mlx4_en_dev *mdev, u8 port);

commit 4ef2a435bea24330781cbfe910a05810f17079d2
Author: Or Gerlitz <ogerlitz@mellanox.com>
Date:   Tue Mar 6 04:03:41 2012 +0000

    net/mlx4: fix sparse warnings on TX control flags, endianess
    
    Fix sparse warnings on incompatibility between the endianess of the ctrl_flags
    field of struct mlx4_en_priv to the srcrb_flags field of struct
    mlx4_wqe_ctrl_seg by changing the former to be __be32 instead of u32.
    
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index a5bb0b7d339a..8f4e655bd57b 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -453,7 +453,7 @@ struct mlx4_en_priv {
 	int base_qpn;
 
 	struct mlx4_en_rss_map rss_map;
-	u32 ctrl_flags;
+	__be32 ctrl_flags;
 	u32 flags;
 #define MLX4_EN_FLAG_PROMISC	0x1
 #define MLX4_EN_FLAG_MC_PROMISC	0x2

commit ebf8c9aa032f03343b91c91951b0705021b02eb0
Author: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
Date:   Tue Mar 6 04:03:34 2012 +0000

    net/mlx4_en: Saving mem access on data path
    
    Localized the pdev->dev, and using dma_map instead of pci_map
    There are multiple map/unmap operations on data path,
    optimizing those by saving redundant pointer access.
    Those places were identified as hot-spots when running kernel profiling
    during some benchmarks.
    The fixes had most impact when testing packet rate with small packets,
    reducing several % from CPU load, and in some case being the difference
    between reaching wire speed or being CPU bound.
    
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index d60335f3c473..a5bb0b7d339a 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -482,6 +482,7 @@ struct mlx4_en_priv {
 	struct mlx4_en_stat_out_mbox hw_stats;
 	int vids[128];
 	bool wol;
+	struct device *ddev;
 };
 
 enum mlx4_en_wol {

commit 68355f71132bec25e0d89b2d8d3ed01286307d31
Author: Thadeu Lima de Souza Cascardo <cascardo@linux.vnet.ibm.com>
Date:   Mon Feb 6 08:39:49 2012 +0000

    mlx4: allow device removal by fixing dma unmap size
    
    After opening the network interface, Mellanox ConnectX device cannot be
    removed by hotplug because it has not properly unmapped all DMA memory.
    
    It happens that mlx4_en_activate_rx_rings overrides the variable that
    keeps the size of the memory mapped.
    
    This is fixed by passing to mlx4_en_destroy_rx_ring the same size that is
    given to mlx4_en_create_rx_ring.
    
    After applying this patch, hot unplugging the device works after opening
    the interface.
    
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@linux.vnet.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 35f08840813c..d60335f3c473 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -528,7 +528,8 @@ int mlx4_en_create_rx_ring(struct mlx4_en_priv *priv,
 			   struct mlx4_en_rx_ring *ring,
 			   u32 size, u16 stride);
 void mlx4_en_destroy_rx_ring(struct mlx4_en_priv *priv,
-			     struct mlx4_en_rx_ring *ring);
+			     struct mlx4_en_rx_ring *ring,
+			     u32 size, u16 stride);
 int mlx4_en_activate_rx_rings(struct mlx4_en_priv *priv);
 void mlx4_en_deactivate_rx_ring(struct mlx4_en_priv *priv,
 				struct mlx4_en_rx_ring *ring);

commit 93ece0c1a7ace88f10411dbb5643d2aa2fe00ebf
Author: Eugenia Emantayev <eugenia@mellanox.co.il>
Date:   Thu Jan 19 09:45:05 2012 +0000

    mlx4_en: eth statistics modification
    
    In native mode display all available staticstics.
    In SRIOV mode on VF display only SW counters statistics,
    in SRIOV mode on hypervisor display SW counters and errors (got from FW)
    statistics.
    
    Signed-off-by: Eugenia Emantayev <eugenia@mellanox.co.il>
    Reviewed-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index f4d189a1290e..35f08840813c 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -476,6 +476,7 @@ struct mlx4_en_priv {
 	struct mlx4_en_perf_stats pstats;
 	struct mlx4_en_pkt_stats pkstats;
 	struct mlx4_en_port_stats port_stats;
+	u64 stats_bitmap;
 	char *mc_addrs;
 	int mc_addrs_cnt;
 	struct mlx4_en_stat_out_mbox hw_stats;

commit 93d3e3678f23109363cd6f99f2944d2cda616b23
Author: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
Date:   Tue Jan 17 22:54:55 2012 +0000

    mlx4_en: set number of rx rings used by RSS using ethtool
    
    Value must be a power of 2 due to HW limitation.
    Driver supports only 'equal' mode in ethtool and can't be set by using weights.
    
    Signed-off-by: Amir Vadai <amirv@mellanox.co.il>
    Reviewed-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index f2a8e65f5f88..f4d189a1290e 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -325,11 +325,11 @@ struct mlx4_en_port_profile {
 	u8 rx_ppp;
 	u8 tx_pause;
 	u8 tx_ppp;
+	int rss_rings;
 };
 
 struct mlx4_en_profile {
 	int rss_xor;
-	int tcp_rss;
 	int udp_rss;
 	u8 rss_mask;
 	u32 active_ports;

commit 6edf91da43017b15b45604fcd332c19e3000c535
Author: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
Date:   Tue Dec 13 04:19:34 2011 +0000

    mlx4_en: updated driver version to 2.0
    
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index ea2ba6899e9a..f2a8e65f5f88 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -51,8 +51,8 @@
 #include "en_port.h"
 
 #define DRV_NAME	"mlx4_en"
-#define DRV_VERSION	"1.5.4.2"
-#define DRV_RELDATE	"October 2011"
+#define DRV_VERSION	"2.0"
+#define DRV_RELDATE	"Dec 2011"
 
 #define MLX4_EN_MSG_LEVEL	(NETIF_MSG_LINK | NETIF_MSG_IFDOWN)
 

commit 60d6fe99e4a507f77b63c090eb8aacb67e21687a
Author: Amir Vadai <amirv@mellanox.co.il>
Date:   Sat Nov 26 19:55:19 2011 +0000

    net/mlx4_en: adding loopback support
    
    Device must be in promiscuous mode or DMAC must be same as the host MAC, or
    else packet will be dropped by the HW rx filtering.
    
    Signed-off-by: Amir Vadai <amirv@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index d2dd97fa091f..ea2ba6899e9a 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -453,6 +453,7 @@ struct mlx4_en_priv {
 	int base_qpn;
 
 	struct mlx4_en_rss_map rss_map;
+	u32 ctrl_flags;
 	u32 flags;
 #define MLX4_EN_FLAG_PROMISC	0x1
 #define MLX4_EN_FLAG_MC_PROMISC	0x2

commit 0d9fdaa9f53cf65a2470e8a7506b59fd88d409e2
Author: Or Gerlitz <ogerlitz@mellanox.com>
Date:   Sat Nov 26 19:55:06 2011 +0000

    net/mlx4_en: fix sparse warning on a cast which truncates bits from constant value
    
    the MLX4_EN_WOL_DO_MODIFY flag which is defined through enum targets
    bit 63, this triggers a "cast truncate bits from constant value
    (8000000000000000 becomes 0)" warning from sparse, fix that by using
    define instead of enum.
    
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index ef7dfcff588d..d2dd97fa091f 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -485,9 +485,9 @@ struct mlx4_en_priv {
 enum mlx4_en_wol {
 	MLX4_EN_WOL_MAGIC = (1ULL << 61),
 	MLX4_EN_WOL_ENABLED = (1ULL << 62),
-	MLX4_EN_WOL_DO_MODIFY = (1ULL << 63),
 };
 
+#define MLX4_EN_WOL_DO_MODIFY (1ULL << 63)
 
 void mlx4_en_destroy_netdev(struct net_device *dev);
 int mlx4_en_init_netdev(struct mlx4_en_dev *mdev, int port,

commit 876f6e67d1c617c098c67934a8d00b065bb9688b
Author: Or Gerlitz <ogerlitz@mellanox.com>
Date:   Sat Nov 26 19:54:58 2011 +0000

    net/mlx4: move RSS related definitions to be global
    
    Towards adding RSS support for IB drivers/application who use
    the mlx4 HW, make the RSS related definitions global and change
    the mlx4_en driver to use them.
    
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Shlomo Pongratz <shlomop@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 207b5add3ca8..ef7dfcff588d 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -366,16 +366,6 @@ struct mlx4_en_rss_map {
 	enum mlx4_qp_state indir_state;
 };
 
-struct mlx4_en_rss_context {
-	__be32 base_qpn;
-	__be32 default_qpn;
-	u16 reserved;
-	u8 hash_fn;
-	u8 flags;
-	__be32 rss_key[10];
-	__be32 base_qpn_udp;
-};
-
 struct mlx4_en_port_state {
 	int link_state;
 	int link_speed;

commit 4a5f4dd8595a3d3cdf75db7247b644ae37f5d460
Author: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
Date:   Mon Nov 14 14:25:36 2011 -0500

    mlx4_en: Remove FCS bytes from packet length.
    
    When HW doesn't remove FCS bytes they are reported in the completion
    byte count, we don't need to take them to skb.
    
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 8fda331c65df..207b5add3ca8 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -272,6 +272,7 @@ struct mlx4_en_rx_ring {
 	u32 prod;
 	u32 cons;
 	u32 buf_size;
+	u8  fcs_del;
 	void *buf;
 	void *rx_info;
 	unsigned long bytes;

commit b9075fa968a0a4347aef35e235e2995c0e57dddd
Author: Joe Perches <joe@perches.com>
Date:   Mon Oct 31 17:11:33 2011 -0700

    treewide: use __printf not __attribute__((format(printf,...)))
    
    Standardize the style for compiler based printf format verification.
    Standardized the location of __printf too.
    
    Done via script and a little typing.
    
    $ grep -rPl --include=*.[ch] -w "__attribute__" * | \
      grep -vP "^(tools|scripts|include/linux/compiler-gcc.h)" | \
      xargs perl -n -i -e 'local $/; while (<>) { s/\b__attribute__\s*\(\s*\(\s*format\s*\(\s*printf\s*,\s*(.+)\s*,\s*(.+)\s*\)\s*\)\s*\)/__printf($1, $2)/g ; print; }'
    
    [akpm@linux-foundation.org: revert arch bits]
    Signed-off-by: Joe Perches <joe@perches.com>
    Cc: "Kirill A. Shutemov" <kirill@shutemov.name>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index fca66165110e..8fda331c65df 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -581,8 +581,9 @@ extern const struct ethtool_ops mlx4_en_ethtool_ops;
  * printk / logging functions
  */
 
+__printf(3, 4)
 int en_print(const char *level, const struct mlx4_en_priv *priv,
-	     const char *format, ...) __attribute__ ((format (printf, 3, 4)));
+	     const char *format, ...);
 
 #define en_dbg(mlevel, priv, format, arg...)			\
 do {								\

commit 1e5c22cde3b85737921d3ec6ecf2c356e5b64ea7
Author: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
Date:   Tue Oct 18 01:51:36 2011 +0000

    mlx4_en: Updating driver version
    
    Driver version updated to 1.5.4.2
    
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index a6b5cf6193d2..fca66165110e 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -51,8 +51,8 @@
 #include "en_port.h"
 
 #define DRV_NAME	"mlx4_en"
-#define DRV_VERSION	"1.5.4.1"
-#define DRV_RELDATE	"March 2011"
+#define DRV_VERSION	"1.5.4.2"
+#define DRV_RELDATE	"October 2011"
 
 #define MLX4_EN_MSG_LEVEL	(NETIF_MSG_LINK | NETIF_MSG_IFDOWN)
 

commit ad04378cecca9c33b5ea3e46aa4ed71b15e0be0c
Author: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
Date:   Tue Oct 18 01:50:56 2011 +0000

    mlx4_en: Checksum counters per ring
    
    Not updating common counters from data path.
    The checksum counters are per ring, summarizing them when collecting statistics.
    
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 3b753f7b866a..a6b5cf6193d2 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -249,6 +249,7 @@ struct mlx4_en_tx_ring {
 	struct mlx4_srq dummy;
 	unsigned long bytes;
 	unsigned long packets;
+	unsigned long tx_csum;
 	spinlock_t comp_lock;
 	struct mlx4_bf bf;
 	bool bf_enabled;
@@ -275,6 +276,8 @@ struct mlx4_en_rx_ring {
 	void *rx_info;
 	unsigned long bytes;
 	unsigned long packets;
+	unsigned long csum_ok;
+	unsigned long csum_none;
 };
 
 

commit 6b4d8d9fd1acb9ff230810793b363dbdb267b892
Author: Alexander Guller <alexg@mellanox.com>
Date:   Sun Oct 9 05:38:23 2011 +0000

    mlx4_en: Adjusting moderation per each ring
    
    Moderation is now done per ring and coalescing is enabled
    by set_ring_param in ethtool.
    
    Signed-off-by: Alexander Guller <alexg@mellanox.co.il>
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index fe8146d68b0a..3b753f7b866a 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -426,11 +426,11 @@ struct mlx4_en_priv {
 	struct mlx4_en_port_state port_state;
 	spinlock_t stats_lock;
 
-	unsigned long last_moder_packets;
+	unsigned long last_moder_packets[MAX_RX_RINGS];
 	unsigned long last_moder_tx_packets;
-	unsigned long last_moder_bytes;
+	unsigned long last_moder_bytes[MAX_RX_RINGS];
 	unsigned long last_moder_jiffies;
-	int last_moder_time;
+	int last_moder_time[MAX_RX_RINGS];
 	u16 rx_usecs;
 	u16 rx_frames;
 	u16 tx_usecs;

commit fe0af03c69abc2178fc4667664726ec1f688539b
Author: Alexander Guller <alexg@mellanox.com>
Date:   Sun Oct 9 05:26:46 2011 +0000

    mlx4_en: Removing reserve vectors
    
    Fixed a bug where ring size change caused insufficient memory
    upon driver restart due to unreleased EQs.
    
    Signed-off-by: Alexander Guller <alexg@mellanox.co.il>
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 115784da8efa..fe8146d68b0a 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -502,13 +502,12 @@ int mlx4_en_init_netdev(struct mlx4_en_dev *mdev, int port,
 int mlx4_en_start_port(struct net_device *dev);
 void mlx4_en_stop_port(struct net_device *dev);
 
-void mlx4_en_free_resources(struct mlx4_en_priv *priv, bool reserve_vectors);
+void mlx4_en_free_resources(struct mlx4_en_priv *priv);
 int mlx4_en_alloc_resources(struct mlx4_en_priv *priv);
 
 int mlx4_en_create_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq,
 		      int entries, int ring, enum cq_type mode);
-void mlx4_en_destroy_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq,
-			bool reserve_vectors);
+void mlx4_en_destroy_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
 int mlx4_en_activate_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq,
 			int cq_idx);
 void mlx4_en_deactivate_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);

commit 76532d0c7e7424914ab6f24683c63e50f0a08f1c
Author: Alexander Guller <alexg@mellanox.com>
Date:   Sun Oct 9 05:26:31 2011 +0000

    mlx4_en: Assigning TX irq per ring
    
    Until now only RX rings used irq per ring
    and TX used only one per port.
    >From now on, both of them will use the
    irq per ring while RX & TX ring[i] will
    use the same irq.
    
    Signed-off-by: Alexander Guller <alexg@mellanox.co.il>
    Signed-off-by: Sharon Cohen <sharonc@mellanox.co.il>
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index ed84811766e6..115784da8efa 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -470,7 +470,6 @@ struct mlx4_en_priv {
 	u16 log_rx_info;
 
 	struct mlx4_en_tx_ring tx_ring[MAX_TX_RINGS];
-	int tx_vector;
 	struct mlx4_en_rx_ring rx_ring[MAX_RX_RINGS];
 	struct mlx4_en_cq tx_cq[MAX_TX_RINGS];
 	struct mlx4_en_cq rx_cq[MAX_RX_RINGS];
@@ -510,7 +509,8 @@ int mlx4_en_create_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq,
 		      int entries, int ring, enum cq_type mode);
 void mlx4_en_destroy_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq,
 			bool reserve_vectors);
-int mlx4_en_activate_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
+int mlx4_en_activate_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq,
+			int cq_idx);
 void mlx4_en_deactivate_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
 int mlx4_en_set_cq_moder(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
 int mlx4_en_arm_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);

commit 5a2cc190eb3fe58fe519795c509b01b25795992e
Author: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
Date:   Fri May 13 01:32:22 2011 -0700

    mlx4: Move the Mellanox driver
    
    Moves the Mellanox driver into drivers/net/ethernet/mellanox/ and
    make the necessary Kconfig and Makefile changes.
    
    CC: Roland Dreier <roland@kernel.org>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
new file mode 100644
index 000000000000..ed84811766e6
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -0,0 +1,607 @@
+/*
+ * Copyright (c) 2007 Mellanox Technologies. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ */
+
+#ifndef _MLX4_EN_H_
+#define _MLX4_EN_H_
+
+#include <linux/bitops.h>
+#include <linux/compiler.h>
+#include <linux/list.h>
+#include <linux/mutex.h>
+#include <linux/netdevice.h>
+#include <linux/if_vlan.h>
+
+#include <linux/mlx4/device.h>
+#include <linux/mlx4/qp.h>
+#include <linux/mlx4/cq.h>
+#include <linux/mlx4/srq.h>
+#include <linux/mlx4/doorbell.h>
+#include <linux/mlx4/cmd.h>
+
+#include "en_port.h"
+
+#define DRV_NAME	"mlx4_en"
+#define DRV_VERSION	"1.5.4.1"
+#define DRV_RELDATE	"March 2011"
+
+#define MLX4_EN_MSG_LEVEL	(NETIF_MSG_LINK | NETIF_MSG_IFDOWN)
+
+/*
+ * Device constants
+ */
+
+
+#define MLX4_EN_PAGE_SHIFT	12
+#define MLX4_EN_PAGE_SIZE	(1 << MLX4_EN_PAGE_SHIFT)
+#define MAX_RX_RINGS		16
+#define MIN_RX_RINGS		4
+#define TXBB_SIZE		64
+#define HEADROOM		(2048 / TXBB_SIZE + 1)
+#define STAMP_STRIDE		64
+#define STAMP_DWORDS		(STAMP_STRIDE / 4)
+#define STAMP_SHIFT		31
+#define STAMP_VAL		0x7fffffff
+#define STATS_DELAY		(HZ / 4)
+
+/* Typical TSO descriptor with 16 gather entries is 352 bytes... */
+#define MAX_DESC_SIZE		512
+#define MAX_DESC_TXBBS		(MAX_DESC_SIZE / TXBB_SIZE)
+
+/*
+ * OS related constants and tunables
+ */
+
+#define MLX4_EN_WATCHDOG_TIMEOUT	(15 * HZ)
+
+#define MLX4_EN_ALLOC_ORDER	2
+#define MLX4_EN_ALLOC_SIZE	(PAGE_SIZE << MLX4_EN_ALLOC_ORDER)
+
+#define MLX4_EN_MAX_LRO_DESCRIPTORS	32
+
+/* Receive fragment sizes; we use at most 4 fragments (for 9600 byte MTU
+ * and 4K allocations) */
+enum {
+	FRAG_SZ0 = 512 - NET_IP_ALIGN,
+	FRAG_SZ1 = 1024,
+	FRAG_SZ2 = 4096,
+	FRAG_SZ3 = MLX4_EN_ALLOC_SIZE
+};
+#define MLX4_EN_MAX_RX_FRAGS	4
+
+/* Maximum ring sizes */
+#define MLX4_EN_MAX_TX_SIZE	8192
+#define MLX4_EN_MAX_RX_SIZE	8192
+
+/* Minimum ring size for our page-allocation sceme to work */
+#define MLX4_EN_MIN_RX_SIZE	(MLX4_EN_ALLOC_SIZE / SMP_CACHE_BYTES)
+#define MLX4_EN_MIN_TX_SIZE	(4096 / TXBB_SIZE)
+
+#define MLX4_EN_SMALL_PKT_SIZE		64
+#define MLX4_EN_NUM_TX_RINGS		8
+#define MLX4_EN_NUM_PPP_RINGS		8
+#define MAX_TX_RINGS			(MLX4_EN_NUM_TX_RINGS + MLX4_EN_NUM_PPP_RINGS)
+#define MLX4_EN_DEF_TX_RING_SIZE	512
+#define MLX4_EN_DEF_RX_RING_SIZE  	1024
+
+/* Target number of packets to coalesce with interrupt moderation */
+#define MLX4_EN_RX_COAL_TARGET	44
+#define MLX4_EN_RX_COAL_TIME	0x10
+
+#define MLX4_EN_TX_COAL_PKTS	5
+#define MLX4_EN_TX_COAL_TIME	0x80
+
+#define MLX4_EN_RX_RATE_LOW		400000
+#define MLX4_EN_RX_COAL_TIME_LOW	0
+#define MLX4_EN_RX_RATE_HIGH		450000
+#define MLX4_EN_RX_COAL_TIME_HIGH	128
+#define MLX4_EN_RX_SIZE_THRESH		1024
+#define MLX4_EN_RX_RATE_THRESH		(1000000 / MLX4_EN_RX_COAL_TIME_HIGH)
+#define MLX4_EN_SAMPLE_INTERVAL		0
+#define MLX4_EN_AVG_PKT_SMALL		256
+
+#define MLX4_EN_AUTO_CONF	0xffff
+
+#define MLX4_EN_DEF_RX_PAUSE	1
+#define MLX4_EN_DEF_TX_PAUSE	1
+
+/* Interval between successive polls in the Tx routine when polling is used
+   instead of interrupts (in per-core Tx rings) - should be power of 2 */
+#define MLX4_EN_TX_POLL_MODER	16
+#define MLX4_EN_TX_POLL_TIMEOUT	(HZ / 4)
+
+#define ETH_LLC_SNAP_SIZE	8
+
+#define SMALL_PACKET_SIZE      (256 - NET_IP_ALIGN)
+#define HEADER_COPY_SIZE       (128 - NET_IP_ALIGN)
+#define MLX4_LOOPBACK_TEST_PAYLOAD (HEADER_COPY_SIZE - ETH_HLEN)
+
+#define MLX4_EN_MIN_MTU		46
+#define ETH_BCAST		0xffffffffffffULL
+
+#define MLX4_EN_LOOPBACK_RETRIES	5
+#define MLX4_EN_LOOPBACK_TIMEOUT	100
+
+#ifdef MLX4_EN_PERF_STAT
+/* Number of samples to 'average' */
+#define AVG_SIZE			128
+#define AVG_FACTOR			1024
+#define NUM_PERF_STATS			NUM_PERF_COUNTERS
+
+#define INC_PERF_COUNTER(cnt)		(++(cnt))
+#define ADD_PERF_COUNTER(cnt, add)	((cnt) += (add))
+#define AVG_PERF_COUNTER(cnt, sample) \
+	((cnt) = ((cnt) * (AVG_SIZE - 1) + (sample) * AVG_FACTOR) / AVG_SIZE)
+#define GET_PERF_COUNTER(cnt)		(cnt)
+#define GET_AVG_PERF_COUNTER(cnt)	((cnt) / AVG_FACTOR)
+
+#else
+
+#define NUM_PERF_STATS			0
+#define INC_PERF_COUNTER(cnt)		do {} while (0)
+#define ADD_PERF_COUNTER(cnt, add)	do {} while (0)
+#define AVG_PERF_COUNTER(cnt, sample)	do {} while (0)
+#define GET_PERF_COUNTER(cnt)		(0)
+#define GET_AVG_PERF_COUNTER(cnt)	(0)
+#endif /* MLX4_EN_PERF_STAT */
+
+/*
+ * Configurables
+ */
+
+enum cq_type {
+	RX = 0,
+	TX = 1,
+};
+
+
+/*
+ * Useful macros
+ */
+#define ROUNDUP_LOG2(x)		ilog2(roundup_pow_of_two(x))
+#define XNOR(x, y)		(!(x) == !(y))
+#define ILLEGAL_MAC(addr)	(addr == 0xffffffffffffULL || addr == 0x0)
+
+
+struct mlx4_en_tx_info {
+	struct sk_buff *skb;
+	u32 nr_txbb;
+	u8 linear;
+	u8 data_offset;
+	u8 inl;
+};
+
+
+#define MLX4_EN_BIT_DESC_OWN	0x80000000
+#define CTRL_SIZE	sizeof(struct mlx4_wqe_ctrl_seg)
+#define MLX4_EN_MEMTYPE_PAD	0x100
+#define DS_SIZE		sizeof(struct mlx4_wqe_data_seg)
+
+
+struct mlx4_en_tx_desc {
+	struct mlx4_wqe_ctrl_seg ctrl;
+	union {
+		struct mlx4_wqe_data_seg data; /* at least one data segment */
+		struct mlx4_wqe_lso_seg lso;
+		struct mlx4_wqe_inline_seg inl;
+	};
+};
+
+#define MLX4_EN_USE_SRQ		0x01000000
+
+#define MLX4_EN_CX3_LOW_ID	0x1000
+#define MLX4_EN_CX3_HIGH_ID	0x1005
+
+struct mlx4_en_rx_alloc {
+	struct page *page;
+	u16 offset;
+};
+
+struct mlx4_en_tx_ring {
+	struct mlx4_hwq_resources wqres;
+	u32 size ; /* number of TXBBs */
+	u32 size_mask;
+	u16 stride;
+	u16 cqn;	/* index of port CQ associated with this ring */
+	u32 prod;
+	u32 cons;
+	u32 buf_size;
+	u32 doorbell_qpn;
+	void *buf;
+	u16 poll_cnt;
+	int blocked;
+	struct mlx4_en_tx_info *tx_info;
+	u8 *bounce_buf;
+	u32 last_nr_txbb;
+	struct mlx4_qp qp;
+	struct mlx4_qp_context context;
+	int qpn;
+	enum mlx4_qp_state qp_state;
+	struct mlx4_srq dummy;
+	unsigned long bytes;
+	unsigned long packets;
+	spinlock_t comp_lock;
+	struct mlx4_bf bf;
+	bool bf_enabled;
+};
+
+struct mlx4_en_rx_desc {
+	/* actual number of entries depends on rx ring stride */
+	struct mlx4_wqe_data_seg data[0];
+};
+
+struct mlx4_en_rx_ring {
+	struct mlx4_hwq_resources wqres;
+	struct mlx4_en_rx_alloc page_alloc[MLX4_EN_MAX_RX_FRAGS];
+	u32 size ;	/* number of Rx descs*/
+	u32 actual_size;
+	u32 size_mask;
+	u16 stride;
+	u16 log_stride;
+	u16 cqn;	/* index of port CQ associated with this ring */
+	u32 prod;
+	u32 cons;
+	u32 buf_size;
+	void *buf;
+	void *rx_info;
+	unsigned long bytes;
+	unsigned long packets;
+};
+
+
+static inline int mlx4_en_can_lro(__be16 status)
+{
+	return (status & cpu_to_be16(MLX4_CQE_STATUS_IPV4	|
+				     MLX4_CQE_STATUS_IPV4F	|
+				     MLX4_CQE_STATUS_IPV6	|
+				     MLX4_CQE_STATUS_IPV4OPT	|
+				     MLX4_CQE_STATUS_TCP	|
+				     MLX4_CQE_STATUS_UDP	|
+				     MLX4_CQE_STATUS_IPOK)) ==
+		cpu_to_be16(MLX4_CQE_STATUS_IPV4 |
+			    MLX4_CQE_STATUS_IPOK |
+			    MLX4_CQE_STATUS_TCP);
+}
+
+struct mlx4_en_cq {
+	struct mlx4_cq          mcq;
+	struct mlx4_hwq_resources wqres;
+	int                     ring;
+	spinlock_t              lock;
+	struct net_device      *dev;
+	struct napi_struct	napi;
+	/* Per-core Tx cq processing support */
+	struct timer_list timer;
+	int size;
+	int buf_size;
+	unsigned vector;
+	enum cq_type is_tx;
+	u16 moder_time;
+	u16 moder_cnt;
+	struct mlx4_cqe *buf;
+#define MLX4_EN_OPCODE_ERROR	0x1e
+};
+
+struct mlx4_en_port_profile {
+	u32 flags;
+	u32 tx_ring_num;
+	u32 rx_ring_num;
+	u32 tx_ring_size;
+	u32 rx_ring_size;
+	u8 rx_pause;
+	u8 rx_ppp;
+	u8 tx_pause;
+	u8 tx_ppp;
+};
+
+struct mlx4_en_profile {
+	int rss_xor;
+	int tcp_rss;
+	int udp_rss;
+	u8 rss_mask;
+	u32 active_ports;
+	u32 small_pkt_int;
+	u8 no_reset;
+	struct mlx4_en_port_profile prof[MLX4_MAX_PORTS + 1];
+};
+
+struct mlx4_en_dev {
+	struct mlx4_dev         *dev;
+	struct pci_dev		*pdev;
+	struct mutex		state_lock;
+	struct net_device       *pndev[MLX4_MAX_PORTS + 1];
+	u32                     port_cnt;
+	bool			device_up;
+	struct mlx4_en_profile  profile;
+	u32			LSO_support;
+	struct workqueue_struct *workqueue;
+	struct device           *dma_device;
+	void __iomem            *uar_map;
+	struct mlx4_uar         priv_uar;
+	struct mlx4_mr		mr;
+	u32                     priv_pdn;
+	spinlock_t              uar_lock;
+	u8			mac_removed[MLX4_MAX_PORTS + 1];
+};
+
+
+struct mlx4_en_rss_map {
+	int base_qpn;
+	struct mlx4_qp qps[MAX_RX_RINGS];
+	enum mlx4_qp_state state[MAX_RX_RINGS];
+	struct mlx4_qp indir_qp;
+	enum mlx4_qp_state indir_state;
+};
+
+struct mlx4_en_rss_context {
+	__be32 base_qpn;
+	__be32 default_qpn;
+	u16 reserved;
+	u8 hash_fn;
+	u8 flags;
+	__be32 rss_key[10];
+	__be32 base_qpn_udp;
+};
+
+struct mlx4_en_port_state {
+	int link_state;
+	int link_speed;
+	int transciver;
+};
+
+struct mlx4_en_pkt_stats {
+	unsigned long broadcast;
+	unsigned long rx_prio[8];
+	unsigned long tx_prio[8];
+#define NUM_PKT_STATS		17
+};
+
+struct mlx4_en_port_stats {
+	unsigned long tso_packets;
+	unsigned long queue_stopped;
+	unsigned long wake_queue;
+	unsigned long tx_timeout;
+	unsigned long rx_alloc_failed;
+	unsigned long rx_chksum_good;
+	unsigned long rx_chksum_none;
+	unsigned long tx_chksum_offload;
+#define NUM_PORT_STATS		8
+};
+
+struct mlx4_en_perf_stats {
+	u32 tx_poll;
+	u64 tx_pktsz_avg;
+	u32 inflight_avg;
+	u16 tx_coal_avg;
+	u16 rx_coal_avg;
+	u32 napi_quota;
+#define NUM_PERF_COUNTERS		6
+};
+
+struct mlx4_en_frag_info {
+	u16 frag_size;
+	u16 frag_prefix_size;
+	u16 frag_stride;
+	u16 frag_align;
+	u16 last_offset;
+
+};
+
+struct mlx4_en_priv {
+	struct mlx4_en_dev *mdev;
+	struct mlx4_en_port_profile *prof;
+	struct net_device *dev;
+	unsigned long active_vlans[BITS_TO_LONGS(VLAN_N_VID)];
+	struct net_device_stats stats;
+	struct net_device_stats ret_stats;
+	struct mlx4_en_port_state port_state;
+	spinlock_t stats_lock;
+
+	unsigned long last_moder_packets;
+	unsigned long last_moder_tx_packets;
+	unsigned long last_moder_bytes;
+	unsigned long last_moder_jiffies;
+	int last_moder_time;
+	u16 rx_usecs;
+	u16 rx_frames;
+	u16 tx_usecs;
+	u16 tx_frames;
+	u32 pkt_rate_low;
+	u16 rx_usecs_low;
+	u32 pkt_rate_high;
+	u16 rx_usecs_high;
+	u16 sample_interval;
+	u16 adaptive_rx_coal;
+	u32 msg_enable;
+	u32 loopback_ok;
+	u32 validate_loopback;
+
+	struct mlx4_hwq_resources res;
+	int link_state;
+	int last_link_state;
+	bool port_up;
+	int port;
+	int registered;
+	int allocated;
+	int stride;
+	u64 mac;
+	int mac_index;
+	unsigned max_mtu;
+	int base_qpn;
+
+	struct mlx4_en_rss_map rss_map;
+	u32 flags;
+#define MLX4_EN_FLAG_PROMISC	0x1
+#define MLX4_EN_FLAG_MC_PROMISC	0x2
+	u32 tx_ring_num;
+	u32 rx_ring_num;
+	u32 rx_skb_size;
+	struct mlx4_en_frag_info frag_info[MLX4_EN_MAX_RX_FRAGS];
+	u16 num_frags;
+	u16 log_rx_info;
+
+	struct mlx4_en_tx_ring tx_ring[MAX_TX_RINGS];
+	int tx_vector;
+	struct mlx4_en_rx_ring rx_ring[MAX_RX_RINGS];
+	struct mlx4_en_cq tx_cq[MAX_TX_RINGS];
+	struct mlx4_en_cq rx_cq[MAX_RX_RINGS];
+	struct work_struct mcast_task;
+	struct work_struct mac_task;
+	struct work_struct watchdog_task;
+	struct work_struct linkstate_task;
+	struct delayed_work stats_task;
+	struct mlx4_en_perf_stats pstats;
+	struct mlx4_en_pkt_stats pkstats;
+	struct mlx4_en_port_stats port_stats;
+	char *mc_addrs;
+	int mc_addrs_cnt;
+	struct mlx4_en_stat_out_mbox hw_stats;
+	int vids[128];
+	bool wol;
+};
+
+enum mlx4_en_wol {
+	MLX4_EN_WOL_MAGIC = (1ULL << 61),
+	MLX4_EN_WOL_ENABLED = (1ULL << 62),
+	MLX4_EN_WOL_DO_MODIFY = (1ULL << 63),
+};
+
+
+void mlx4_en_destroy_netdev(struct net_device *dev);
+int mlx4_en_init_netdev(struct mlx4_en_dev *mdev, int port,
+			struct mlx4_en_port_profile *prof);
+
+int mlx4_en_start_port(struct net_device *dev);
+void mlx4_en_stop_port(struct net_device *dev);
+
+void mlx4_en_free_resources(struct mlx4_en_priv *priv, bool reserve_vectors);
+int mlx4_en_alloc_resources(struct mlx4_en_priv *priv);
+
+int mlx4_en_create_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq,
+		      int entries, int ring, enum cq_type mode);
+void mlx4_en_destroy_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq,
+			bool reserve_vectors);
+int mlx4_en_activate_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
+void mlx4_en_deactivate_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
+int mlx4_en_set_cq_moder(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
+int mlx4_en_arm_cq(struct mlx4_en_priv *priv, struct mlx4_en_cq *cq);
+
+void mlx4_en_poll_tx_cq(unsigned long data);
+void mlx4_en_tx_irq(struct mlx4_cq *mcq);
+u16 mlx4_en_select_queue(struct net_device *dev, struct sk_buff *skb);
+netdev_tx_t mlx4_en_xmit(struct sk_buff *skb, struct net_device *dev);
+
+int mlx4_en_create_tx_ring(struct mlx4_en_priv *priv, struct mlx4_en_tx_ring *ring,
+			   int qpn, u32 size, u16 stride);
+void mlx4_en_destroy_tx_ring(struct mlx4_en_priv *priv, struct mlx4_en_tx_ring *ring);
+int mlx4_en_activate_tx_ring(struct mlx4_en_priv *priv,
+			     struct mlx4_en_tx_ring *ring,
+			     int cq);
+void mlx4_en_deactivate_tx_ring(struct mlx4_en_priv *priv,
+				struct mlx4_en_tx_ring *ring);
+
+int mlx4_en_create_rx_ring(struct mlx4_en_priv *priv,
+			   struct mlx4_en_rx_ring *ring,
+			   u32 size, u16 stride);
+void mlx4_en_destroy_rx_ring(struct mlx4_en_priv *priv,
+			     struct mlx4_en_rx_ring *ring);
+int mlx4_en_activate_rx_rings(struct mlx4_en_priv *priv);
+void mlx4_en_deactivate_rx_ring(struct mlx4_en_priv *priv,
+				struct mlx4_en_rx_ring *ring);
+int mlx4_en_process_rx_cq(struct net_device *dev,
+			  struct mlx4_en_cq *cq,
+			  int budget);
+int mlx4_en_poll_rx_cq(struct napi_struct *napi, int budget);
+void mlx4_en_fill_qp_context(struct mlx4_en_priv *priv, int size, int stride,
+			     int is_tx, int rss, int qpn, int cqn,
+			     struct mlx4_qp_context *context);
+void mlx4_en_sqp_event(struct mlx4_qp *qp, enum mlx4_event event);
+int mlx4_en_map_buffer(struct mlx4_buf *buf);
+void mlx4_en_unmap_buffer(struct mlx4_buf *buf);
+
+void mlx4_en_calc_rx_buf(struct net_device *dev);
+int mlx4_en_config_rss_steer(struct mlx4_en_priv *priv);
+void mlx4_en_release_rss_steer(struct mlx4_en_priv *priv);
+int mlx4_en_free_tx_buf(struct net_device *dev, struct mlx4_en_tx_ring *ring);
+void mlx4_en_rx_irq(struct mlx4_cq *mcq);
+
+int mlx4_SET_MCAST_FLTR(struct mlx4_dev *dev, u8 port, u64 mac, u64 clear, u8 mode);
+int mlx4_SET_VLAN_FLTR(struct mlx4_dev *dev, struct mlx4_en_priv *priv);
+int mlx4_SET_PORT_general(struct mlx4_dev *dev, u8 port, int mtu,
+			  u8 pptx, u8 pfctx, u8 pprx, u8 pfcrx);
+int mlx4_SET_PORT_qpn_calc(struct mlx4_dev *dev, u8 port, u32 base_qpn,
+			   u8 promisc);
+
+int mlx4_en_DUMP_ETH_STATS(struct mlx4_en_dev *mdev, u8 port, u8 reset);
+int mlx4_en_QUERY_PORT(struct mlx4_en_dev *mdev, u8 port);
+
+#define MLX4_EN_NUM_SELF_TEST	5
+void mlx4_en_ex_selftest(struct net_device *dev, u32 *flags, u64 *buf);
+u64 mlx4_en_mac_to_u64(u8 *addr);
+
+/*
+ * Globals
+ */
+extern const struct ethtool_ops mlx4_en_ethtool_ops;
+
+
+
+/*
+ * printk / logging functions
+ */
+
+int en_print(const char *level, const struct mlx4_en_priv *priv,
+	     const char *format, ...) __attribute__ ((format (printf, 3, 4)));
+
+#define en_dbg(mlevel, priv, format, arg...)			\
+do {								\
+	if (NETIF_MSG_##mlevel & priv->msg_enable)		\
+		en_print(KERN_DEBUG, priv, format, ##arg);	\
+} while (0)
+#define en_warn(priv, format, arg...)			\
+	en_print(KERN_WARNING, priv, format, ##arg)
+#define en_err(priv, format, arg...)			\
+	en_print(KERN_ERR, priv, format, ##arg)
+#define en_info(priv, format, arg...)			\
+	en_print(KERN_INFO, priv, format, ## arg)
+
+#define mlx4_err(mdev, format, arg...)			\
+	pr_err("%s %s: " format, DRV_NAME,		\
+	       dev_name(&mdev->pdev->dev), ##arg)
+#define mlx4_info(mdev, format, arg...)			\
+	pr_info("%s %s: " format, DRV_NAME,		\
+		dev_name(&mdev->pdev->dev), ##arg)
+#define mlx4_warn(mdev, format, arg...)			\
+	pr_warning("%s %s: " format, DRV_NAME,		\
+		   dev_name(&mdev->pdev->dev), ##arg)
+
+#endif
