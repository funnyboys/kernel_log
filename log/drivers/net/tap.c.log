commit 5643a552d31242e5adf3dbefba26c90b1bce2826
Author: Jason A. Donenfeld <Jason@zx2c4.com>
Date:   Wed Jan 8 16:59:03 2020 -0500

    net: tap: use skb_list_walk_safe helper for gso segments
    
    This is a straight-forward conversion case for the new function, and
    while we're at it, we can remove a null write to skb->next by replacing
    it with skb_mark_not_on_list.
    
    Signed-off-by: Jason A. Donenfeld <Jason@zx2c4.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index a6d63665ad03..1f4bdd94407a 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -341,6 +341,7 @@ rx_handler_result_t tap_handle_frame(struct sk_buff **pskb)
 		features |= tap->tap_features;
 	if (netif_needs_gso(skb, features)) {
 		struct sk_buff *segs = __skb_gso_segment(skb, features, false);
+		struct sk_buff *next;
 
 		if (IS_ERR(segs))
 			goto drop;
@@ -352,16 +353,13 @@ rx_handler_result_t tap_handle_frame(struct sk_buff **pskb)
 		}
 
 		consume_skb(skb);
-		while (segs) {
-			struct sk_buff *nskb = segs->next;
-
-			segs->next = NULL;
-			if (ptr_ring_produce(&q->ring, segs)) {
-				kfree_skb(segs);
-				kfree_skb_list(nskb);
+		skb_list_walk_safe(segs, skb, next) {
+			skb_mark_not_on_list(skb);
+			if (ptr_ring_produce(&q->ring, skb)) {
+				kfree_skb(skb);
+				kfree_skb_list(next);
 				break;
 			}
-			segs = nskb;
 		}
 	} else {
 		/* If we receive a partial checksum and the tap side

commit 407e9ef72476e64937ebec44cc835e03a25fb408
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Tue Sep 11 17:23:00 2018 +0200

    compat_ioctl: move drivers to compat_ptr_ioctl
    
    Each of these drivers has a copy of the same trivial helper function to
    convert the pointer argument and then call the native ioctl handler.
    
    We now have a generic implementation of that, so use it.
    
    Acked-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Acked-by: Michael S. Tsirkin <mst@redhat.com>
    Acked-by: David S. Miller <davem@davemloft.net>
    Acked-by: Jarkko Sakkinen <jarkko.sakkinen@linux.intel.com>
    Reviewed-by: Jarkko Sakkinen <jarkko.sakkinen@linux.intel.com>
    Reviewed-by: Jason Gunthorpe <jgg@mellanox.com>
    Reviewed-by: Jiri Kosina <jkosina@suse.cz>
    Reviewed-by: Stefan Hajnoczi <stefanha@redhat.com>
    Reviewed-by: Cornelia Huck <cohuck@redhat.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 3ae70c7e6860..a6d63665ad03 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -1123,14 +1123,6 @@ static long tap_ioctl(struct file *file, unsigned int cmd,
 	}
 }
 
-#ifdef CONFIG_COMPAT
-static long tap_compat_ioctl(struct file *file, unsigned int cmd,
-			     unsigned long arg)
-{
-	return tap_ioctl(file, cmd, (unsigned long)compat_ptr(arg));
-}
-#endif
-
 static const struct file_operations tap_fops = {
 	.owner		= THIS_MODULE,
 	.open		= tap_open,
@@ -1140,9 +1132,7 @@ static const struct file_operations tap_fops = {
 	.poll		= tap_poll,
 	.llseek		= no_llseek,
 	.unlocked_ioctl	= tap_ioctl,
-#ifdef CONFIG_COMPAT
-	.compat_ioctl	= tap_compat_ioctl,
-#endif
+	.compat_ioctl	= compat_ptr_ioctl,
 };
 
 static int tap_get_user_xdp(struct tap_queue *q, struct xdp_buff *xdp)

commit faeacb6ddb13b7a020b50b9246fe098653cfbd6e
Author: Colin Ian King <colin.king@canonical.com>
Date:   Fri Sep 27 10:40:39 2019 +0100

    net: tap: clean up an indentation issue
    
    There is a statement that is indented too deeply, remove
    the extraneous tab.
    
    Signed-off-by: Colin Ian King <colin.king@canonical.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index dd614c2cd994..3ae70c7e6860 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -1200,7 +1200,7 @@ static int tap_get_user_xdp(struct tap_queue *q, struct xdp_buff *xdp)
 	kfree_skb(skb);
 err:
 	rcu_read_lock();
-		tap = rcu_dereference(q->tap);
+	tap = rcu_dereference(q->tap);
 	if (tap && tap->count_tx_dropped)
 		tap->count_tx_dropped(tap);
 	rcu_read_unlock();

commit 333f7909a8573145811c4ab7d8c9092301707721
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Jul 5 20:14:16 2019 +0100

    coallocate socket_wq with socket itself
    
    socket->wq is assign-once, set when we are initializing both
    struct socket it's in and struct socket_wq it points to.  As the
    matter of fact, the only reason for separate allocation was the
    ability to RCU-delay freeing of socket_wq.  RCU-delaying the
    freeing of socket itself gets rid of that need, so we can just
    fold struct socket_wq into the end of struct socket and simplify
    the life both for sock_alloc_inode() (one allocation instead of
    two) and for tun/tap oddballs, where we used to embed struct socket
    and struct socket_wq into the same structure (now - embedding just
    the struct socket).
    
    Note that reference to struct socket_wq in struct sock does remain
    a reference - that's unchanged.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 8e01390c738e..dd614c2cd994 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -520,8 +520,7 @@ static int tap_open(struct inode *inode, struct file *file)
 		goto err;
 	}
 
-	RCU_INIT_POINTER(q->sock.wq, &q->wq);
-	init_waitqueue_head(&q->wq.wait);
+	init_waitqueue_head(&q->sock.wq.wait);
 	q->sock.type = SOCK_RAW;
 	q->sock.state = SS_CONNECTED;
 	q->sock.file = file;
@@ -579,7 +578,7 @@ static __poll_t tap_poll(struct file *file, poll_table *wait)
 		goto out;
 
 	mask = 0;
-	poll_wait(file, &q->wq.wait, wait);
+	poll_wait(file, &q->sock.wq.wait, wait);
 
 	if (!ptr_ring_empty(&q->ring))
 		mask |= EPOLLIN | EPOLLRDNORM;

commit 09c434b8a0047c69e48499de0107de312901e798
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun May 19 13:08:20 2019 +0100

    treewide: Add SPDX license identifier for more missed files
    
    Add SPDX license identifiers to all files which:
    
     - Have no license information of any form
    
     - Have MODULE_LICENCE("GPL*") inside which was used in the initial
       scan/conversion to ignore the file
    
    These files fall under the project license, GPL v2 only. The resulting SPDX
    license identifier is:
    
      GPL-2.0-only
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 2ea9b4976f4a..8e01390c738e 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 #include <linux/etherdevice.h>
 #include <linux/if_tap.h>
 #include <linux/if_vlan.h>

commit d2aa125d629080c4f3e31f23b7f612ef6b8492ac
Author: Maxim Mikityanskiy <maximmi@mellanox.com>
Date:   Thu Feb 21 12:39:57 2019 +0000

    net: Don't set transport offset to invalid value
    
    If the socket was created with socket(AF_PACKET, SOCK_RAW, 0),
    skb->protocol will be unset, __skb_flow_dissect() will fail, and
    skb_probe_transport_header() will fall back to the offset_hint, making
    the resulting skb_transport_offset incorrect.
    
    If, however, there is no transport header in the packet,
    transport_header shouldn't be set to an arbitrary value.
    
    Fix it by leaving the transport offset unset if it couldn't be found, to
    be explicit rather than to fill it with some wrong value. It changes the
    behavior, but if some code relied on the old behavior, it would be
    broken anyway, as the old one is incorrect.
    
    Signed-off-by: Maxim Mikityanskiy <maximmi@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index c0b52e48f0e6..2ea9b4976f4a 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -712,7 +712,7 @@ static ssize_t tap_get_user(struct tap_queue *q, void *msg_control,
 			goto err_kfree;
 	}
 
-	skb_probe_transport_header(skb, ETH_HLEN);
+	skb_probe_transport_header(skb);
 
 	/* Move network header to the right position for VLAN tagged packets */
 	if ((skb->protocol == htons(ETH_P_8021Q) ||
@@ -1187,7 +1187,7 @@ static int tap_get_user_xdp(struct tap_queue *q, struct xdp_buff *xdp)
 	tap = rcu_dereference(q->tap);
 	if (tap) {
 		skb->dev = tap->dev;
-		skb_probe_transport_header(skb, ETH_HLEN);
+		skb_probe_transport_header(skb);
 		dev_queue_xmit(skb);
 	} else {
 		kfree_skb(skb);

commit 8c76e77f9069f10505c08e02646c3ee11ad79038
Author: Willem de Bruijn <willemb@google.com>
Date:   Sun Dec 30 17:21:05 2018 -0500

    tap: call skb_probe_transport_header after setting skb->dev
    
    The BPF flow dissector expects either skb->sk or skb->dev set on
    all skbs. Delay flow dissection until after skb->dev is set.
    
    This requires calling from within an rcu read-side critical section.
    That is fine, see also the call from tun_xdp_one.
    
    Fixes: d0e13a1488ad ("flow_dissector: lookup netns by skb->sk if skb->dev is NULL")
    Reported-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Signed-off-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 443b2694130c..c0b52e48f0e6 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -1177,8 +1177,6 @@ static int tap_get_user_xdp(struct tap_queue *q, struct xdp_buff *xdp)
 			goto err_kfree;
 	}
 
-	skb_probe_transport_header(skb, ETH_HLEN);
-
 	/* Move network header to the right position for VLAN tagged packets */
 	if ((skb->protocol == htons(ETH_P_8021Q) ||
 	     skb->protocol == htons(ETH_P_8021AD)) &&
@@ -1189,6 +1187,7 @@ static int tap_get_user_xdp(struct tap_queue *q, struct xdp_buff *xdp)
 	tap = rcu_dereference(q->tap);
 	if (tap) {
 		skb->dev = tap->dev;
+		skb_probe_transport_header(skb, ETH_HLEN);
 		dev_queue_xmit(skb);
 	} else {
 		kfree_skb(skb);

commit 3a37a9636cf3a1af2621a33f7eef8a2a3da81030
Author: Petr Machata <petrm@mellanox.com>
Date:   Thu Dec 13 11:54:30 2018 +0000

    net: dev: Add extack argument to dev_set_mac_address()
    
    A follow-up patch will add a notifier type NETDEV_PRE_CHANGEADDR, which
    allows vetoing of MAC address changes. One prominent path to that
    notification is through dev_set_mac_address(). Therefore give this
    function an extack argument, so that it can be packed together with the
    notification. Thus a textual reason for rejection (or a warning) can be
    communicated back to the user.
    
    Signed-off-by: Petr Machata <petrm@mellanox.com>
    Acked-by: Jiri Pirko <jiri@mellanox.com>
    Reviewed-by: Ido Schimmel <idosch@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index f03004f37eca..443b2694130c 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -1113,7 +1113,7 @@ static long tap_ioctl(struct file *file, unsigned int cmd,
 			rtnl_unlock();
 			return -ENOLINK;
 		}
-		ret = dev_set_mac_address(tap->dev, &sa);
+		ret = dev_set_mac_address(tap->dev, &sa, NULL);
 		tap_put_tap_dev(tap);
 		rtnl_unlock();
 		return ret;

commit 144a6adfa1435e6235fd55b700d2c9f93345bb7f
Author: zhong jiang <zhongjiang@huawei.com>
Date:   Thu Sep 20 17:37:41 2018 +0800

    net: tap: remove redundant null pointer check before kfree_skb
    
    kfree_skb has taken the null pointer into account. hence it is safe
    to remove the redundant null pointer check before kfree_skb.
    
    Signed-off-by: zhong jiang <zhongjiang@huawei.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index a4ab4a791fe7..f03004f37eca 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -830,8 +830,7 @@ static ssize_t tap_do_read(struct tap_queue *q,
 	ssize_t ret = 0;
 
 	if (!iov_iter_count(to)) {
-		if (skb)
-			kfree_skb(skb);
+		kfree_skb(skb);
 		return 0;
 	}
 
@@ -1236,8 +1235,7 @@ static int tap_recvmsg(struct socket *sock, struct msghdr *m,
 	struct sk_buff *skb = m->msg_control;
 	int ret;
 	if (flags & ~(MSG_DONTWAIT|MSG_TRUNC)) {
-		if (skb)
-			kfree_skb(skb);
+		kfree_skb(skb);
 		return -EINVAL;
 	}
 	ret = tap_do_read(q, &m->msg_iter, flags & MSG_DONTWAIT, skb);

commit 0efac27791ee068075d80f07c55a229b1335ce12
Author: Jason Wang <jasowang@redhat.com>
Date:   Wed Sep 12 11:17:08 2018 +0800

    tap: accept an array of XDP buffs through sendmsg()
    
    This patch implement TUN_MSG_PTR msg_control type. This type allows
    the caller to pass an array of XDP buffs to tuntap through ptr field
    of the tun_msg_control. Tap will build skb through those XDP buffers.
    
    This will avoid lots of indirect calls thus improves the icache
    utilization and allows to do XDP batched flushing when doing XDP
    redirection.
    
    Signed-off-by: Jason Wang <jasowang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 7996ed7cbf18..a4ab4a791fe7 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -1146,14 +1146,84 @@ static const struct file_operations tap_fops = {
 #endif
 };
 
+static int tap_get_user_xdp(struct tap_queue *q, struct xdp_buff *xdp)
+{
+	struct tun_xdp_hdr *hdr = xdp->data_hard_start;
+	struct virtio_net_hdr *gso = &hdr->gso;
+	int buflen = hdr->buflen;
+	int vnet_hdr_len = 0;
+	struct tap_dev *tap;
+	struct sk_buff *skb;
+	int err, depth;
+
+	if (q->flags & IFF_VNET_HDR)
+		vnet_hdr_len = READ_ONCE(q->vnet_hdr_sz);
+
+	skb = build_skb(xdp->data_hard_start, buflen);
+	if (!skb) {
+		err = -ENOMEM;
+		goto err;
+	}
+
+	skb_reserve(skb, xdp->data - xdp->data_hard_start);
+	skb_put(skb, xdp->data_end - xdp->data);
+
+	skb_set_network_header(skb, ETH_HLEN);
+	skb_reset_mac_header(skb);
+	skb->protocol = eth_hdr(skb)->h_proto;
+
+	if (vnet_hdr_len) {
+		err = virtio_net_hdr_to_skb(skb, gso, tap_is_little_endian(q));
+		if (err)
+			goto err_kfree;
+	}
+
+	skb_probe_transport_header(skb, ETH_HLEN);
+
+	/* Move network header to the right position for VLAN tagged packets */
+	if ((skb->protocol == htons(ETH_P_8021Q) ||
+	     skb->protocol == htons(ETH_P_8021AD)) &&
+	    __vlan_get_protocol(skb, skb->protocol, &depth) != 0)
+		skb_set_network_header(skb, depth);
+
+	rcu_read_lock();
+	tap = rcu_dereference(q->tap);
+	if (tap) {
+		skb->dev = tap->dev;
+		dev_queue_xmit(skb);
+	} else {
+		kfree_skb(skb);
+	}
+	rcu_read_unlock();
+
+	return 0;
+
+err_kfree:
+	kfree_skb(skb);
+err:
+	rcu_read_lock();
+		tap = rcu_dereference(q->tap);
+	if (tap && tap->count_tx_dropped)
+		tap->count_tx_dropped(tap);
+	rcu_read_unlock();
+	return err;
+}
+
 static int tap_sendmsg(struct socket *sock, struct msghdr *m,
 		       size_t total_len)
 {
 	struct tap_queue *q = container_of(sock, struct tap_queue, sock);
 	struct tun_msg_ctl *ctl = m->msg_control;
+	struct xdp_buff *xdp;
+	int i;
 
-	if (ctl && ctl->type != TUN_MSG_UBUF)
-		return -EINVAL;
+	if (ctl && (ctl->type == TUN_MSG_PTR)) {
+		for (i = 0; i < ctl->num; i++) {
+			xdp = &((struct xdp_buff *)ctl->ptr)[i];
+			tap_get_user_xdp(q, xdp);
+		}
+		return 0;
+	}
 
 	return tap_get_user(q, ctl ? ctl->ptr : NULL, &m->msg_iter,
 			    m->msg_flags & MSG_DONTWAIT);

commit fe8dd45bb7556246c6b76277b1ba4296c91c2505
Author: Jason Wang <jasowang@redhat.com>
Date:   Wed Sep 12 11:17:06 2018 +0800

    tun: switch to new type of msg_control
    
    This patch introduces to a new tun/tap specific msg_control:
    
    #define TUN_MSG_UBUF 1
    #define TUN_MSG_PTR  2
    struct tun_msg_ctl {
           int type;
           void *ptr;
    };
    
    This allows us to pass different kinds of msg_control through
    sendmsg(). The first supported type is ubuf (TUN_MSG_UBUF) which will
    be used by the existed vhost_net zerocopy code. The second is XDP
    buff, which allows vhost_net to pass XDP buff to TUN. This could be
    used to implement accepting an array of XDP buffs from vhost_net in
    the following patches.
    
    Signed-off-by: Jason Wang <jasowang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index f0f7cd977667..7996ed7cbf18 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -619,7 +619,7 @@ static inline struct sk_buff *tap_alloc_skb(struct sock *sk, size_t prepad,
 #define TAP_RESERVE HH_DATA_OFF(ETH_HLEN)
 
 /* Get packet from user space buffer */
-static ssize_t tap_get_user(struct tap_queue *q, struct msghdr *m,
+static ssize_t tap_get_user(struct tap_queue *q, void *msg_control,
 			    struct iov_iter *from, int noblock)
 {
 	int good_linear = SKB_MAX_HEAD(TAP_RESERVE);
@@ -663,7 +663,7 @@ static ssize_t tap_get_user(struct tap_queue *q, struct msghdr *m,
 	if (unlikely(len < ETH_HLEN))
 		goto err;
 
-	if (m && m->msg_control && sock_flag(&q->sk, SOCK_ZEROCOPY)) {
+	if (msg_control && sock_flag(&q->sk, SOCK_ZEROCOPY)) {
 		struct iov_iter i;
 
 		copylen = vnet_hdr.hdr_len ?
@@ -724,11 +724,11 @@ static ssize_t tap_get_user(struct tap_queue *q, struct msghdr *m,
 	tap = rcu_dereference(q->tap);
 	/* copy skb_ubuf_info for callback when skb has no error */
 	if (zerocopy) {
-		skb_shinfo(skb)->destructor_arg = m->msg_control;
+		skb_shinfo(skb)->destructor_arg = msg_control;
 		skb_shinfo(skb)->tx_flags |= SKBTX_DEV_ZEROCOPY;
 		skb_shinfo(skb)->tx_flags |= SKBTX_SHARED_FRAG;
-	} else if (m && m->msg_control) {
-		struct ubuf_info *uarg = m->msg_control;
+	} else if (msg_control) {
+		struct ubuf_info *uarg = msg_control;
 		uarg->callback(uarg, false);
 	}
 
@@ -1150,7 +1150,13 @@ static int tap_sendmsg(struct socket *sock, struct msghdr *m,
 		       size_t total_len)
 {
 	struct tap_queue *q = container_of(sock, struct tap_queue, sock);
-	return tap_get_user(q, m, &m->msg_iter, m->msg_flags & MSG_DONTWAIT);
+	struct tun_msg_ctl *ctl = m->msg_control;
+
+	if (ctl && ctl->type != TUN_MSG_UBUF)
+		return -EINVAL;
+
+	return tap_get_user(q, ctl ? ctl->ptr : NULL, &m->msg_iter,
+			    m->msg_flags & MSG_DONTWAIT);
 }
 
 static int tap_recvmsg(struct socket *sock, struct msghdr *m,

commit fd3a88625844907151737fc3b4201676effa6d27
Author: Willem de Bruijn <willemb@google.com>
Date:   Wed Jun 6 11:23:01 2018 -0400

    net: in virtio_net_hdr only add VLAN_HLEN to csum_start if payload holds vlan
    
    Tun, tap, virtio, packet and uml vector all use struct virtio_net_hdr
    to communicate packet metadata to userspace.
    
    For skbuffs with vlan, the first two return the packet as it may have
    existed on the wire, inserting the VLAN tag in the user buffer.  Then
    virtio_net_hdr.csum_start needs to be adjusted by VLAN_HLEN bytes.
    
    Commit f09e2249c4f5 ("macvtap: restore vlan header on user read")
    added this feature to macvtap. Commit 3ce9b20f1971 ("macvtap: Fix
    csum_start when VLAN tags are present") then fixed up csum_start.
    
    Virtio, packet and uml do not insert the vlan header in the user
    buffer.
    
    When introducing virtio_net_hdr_from_skb to deduplicate filling in
    the virtio_net_hdr, the variant from macvtap which adds VLAN_HLEN was
    applied uniformly, breaking csum offset for packets with vlan on
    virtio and packet.
    
    Make insertion of VLAN_HLEN optional. Convert the callers to pass it
    when needed.
    
    Fixes: e858fae2b0b8f4 ("virtio_net: use common code for virtio_net_hdr and skb GSO conversion")
    Fixes: 1276f24eeef2 ("packet: use common code for virtio_net_hdr and skb GSO conversion")
    Signed-off-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 9b6cb780affe..f0f7cd977667 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -774,13 +774,16 @@ static ssize_t tap_put_user(struct tap_queue *q,
 	int total;
 
 	if (q->flags & IFF_VNET_HDR) {
+		int vlan_hlen = skb_vlan_tag_present(skb) ? VLAN_HLEN : 0;
 		struct virtio_net_hdr vnet_hdr;
+
 		vnet_hdr_len = READ_ONCE(q->vnet_hdr_sz);
 		if (iov_iter_count(iter) < vnet_hdr_len)
 			return -EINVAL;
 
 		if (virtio_net_hdr_from_skb(skb, &vnet_hdr,
-					    tap_is_little_endian(q), true))
+					    tap_is_little_endian(q), true,
+					    vlan_hlen))
 			BUG();
 
 		if (copy_to_iter(&vnet_hdr, sizeof(vnet_hdr), iter) !=

commit a9a08845e9acbd224e4ee466f5c1275ed50054e8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Feb 11 14:34:03 2018 -0800

    vfs: do bulk POLL* -> EPOLL* replacement
    
    This is the mindless scripted replacement of kernel use of POLL*
    variables as described by Al, done by this script:
    
        for V in IN OUT PRI ERR RDNORM RDBAND WRNORM WRBAND HUP RDHUP NVAL MSG; do
            L=`git grep -l -w POLL$V | grep -v '^t' | grep -v /um/ | grep -v '^sa' | grep -v '/poll.h$'|grep -v '^D'`
            for f in $L; do sed -i "-es/^\([^\"]*\)\(\<POLL$V\>\)/\\1E\\2/" $f; done
        done
    
    with de-mangling cleanups yet to come.
    
    NOTE! On almost all architectures, the EPOLL* constants have the same
    values as the POLL* constants do.  But they keyword here is "almost".
    For various bad reasons they aren't the same, and epoll() doesn't
    actually work quite correctly in some cases due to this on Sparc et al.
    
    The next patch from Al will sort out the final differences, and we
    should be all done.
    
    Scripted-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 0a5ed004781c..9b6cb780affe 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -377,7 +377,7 @@ rx_handler_result_t tap_handle_frame(struct sk_buff **pskb)
 	}
 
 wake_up:
-	wake_up_interruptible_poll(sk_sleep(&q->sk), POLLIN | POLLRDNORM | POLLRDBAND);
+	wake_up_interruptible_poll(sk_sleep(&q->sk), EPOLLIN | EPOLLRDNORM | EPOLLRDBAND);
 	return RX_HANDLER_CONSUMED;
 
 drop:
@@ -487,7 +487,7 @@ static void tap_sock_write_space(struct sock *sk)
 
 	wqueue = sk_sleep(sk);
 	if (wqueue && waitqueue_active(wqueue))
-		wake_up_interruptible_poll(wqueue, POLLOUT | POLLWRNORM | POLLWRBAND);
+		wake_up_interruptible_poll(wqueue, EPOLLOUT | EPOLLWRNORM | EPOLLWRBAND);
 }
 
 static void tap_sock_destruct(struct sock *sk)
@@ -572,7 +572,7 @@ static int tap_release(struct inode *inode, struct file *file)
 static __poll_t tap_poll(struct file *file, poll_table *wait)
 {
 	struct tap_queue *q = file->private_data;
-	__poll_t mask = POLLERR;
+	__poll_t mask = EPOLLERR;
 
 	if (!q)
 		goto out;
@@ -581,12 +581,12 @@ static __poll_t tap_poll(struct file *file, poll_table *wait)
 	poll_wait(file, &q->wq.wait, wait);
 
 	if (!ptr_ring_empty(&q->ring))
-		mask |= POLLIN | POLLRDNORM;
+		mask |= EPOLLIN | EPOLLRDNORM;
 
 	if (sock_writeable(&q->sk) ||
 	    (!test_and_set_bit(SOCKWQ_ASYNC_NOSPACE, &q->sock.flags) &&
 	     sock_writeable(&q->sk)))
-		mask |= POLLOUT | POLLWRNORM;
+		mask |= EPOLLOUT | EPOLLWRNORM;
 
 out:
 	return mask;

commit b2fe5fa68642860e7de76167c3111623aa0d5de1
Merge: a103950e0dd2 a54667f6728c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 31 14:31:10 2018 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Miller:
    
     1) Significantly shrink the core networking routing structures. Result
        of http://vger.kernel.org/~davem/seoul2017_netdev_keynote.pdf
    
     2) Add netdevsim driver for testing various offloads, from Jakub
        Kicinski.
    
     3) Support cross-chip FDB operations in DSA, from Vivien Didelot.
    
     4) Add a 2nd listener hash table for TCP, similar to what was done for
        UDP. From Martin KaFai Lau.
    
     5) Add eBPF based queue selection to tun, from Jason Wang.
    
     6) Lockless qdisc support, from John Fastabend.
    
     7) SCTP stream interleave support, from Xin Long.
    
     8) Smoother TCP receive autotuning, from Eric Dumazet.
    
     9) Lots of erspan tunneling enhancements, from William Tu.
    
    10) Add true function call support to BPF, from Alexei Starovoitov.
    
    11) Add explicit support for GRO HW offloading, from Michael Chan.
    
    12) Support extack generation in more netlink subsystems. From Alexander
        Aring, Quentin Monnet, and Jakub Kicinski.
    
    13) Add 1000BaseX, flow control, and EEE support to mvneta driver. From
        Russell King.
    
    14) Add flow table abstraction to netfilter, from Pablo Neira Ayuso.
    
    15) Many improvements and simplifications to the NFP driver bpf JIT,
        from Jakub Kicinski.
    
    16) Support for ipv6 non-equal cost multipath routing, from Ido
        Schimmel.
    
    17) Add resource abstration to devlink, from Arkadi Sharshevsky.
    
    18) Packet scheduler classifier shared filter block support, from Jiri
        Pirko.
    
    19) Avoid locking in act_csum, from Davide Caratti.
    
    20) devinet_ioctl() simplifications from Al viro.
    
    21) More TCP bpf improvements from Lawrence Brakmo.
    
    22) Add support for onlink ipv6 route flag, similar to ipv4, from David
        Ahern.
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (1925 commits)
      tls: Add support for encryption using async offload accelerator
      ip6mr: fix stale iterator
      net/sched: kconfig: Remove blank help texts
      openvswitch: meter: Use 64-bit arithmetic instead of 32-bit
      tcp_nv: fix potential integer overflow in tcpnv_acked
      r8169: fix RTL8168EP take too long to complete driver initialization.
      qmi_wwan: Add support for Quectel EP06
      rtnetlink: enable IFLA_IF_NETNSID for RTM_NEWLINK
      ipmr: Fix ptrdiff_t print formatting
      ibmvnic: Wait for device response when changing MAC
      qlcnic: fix deadlock bug
      tcp: release sk_frag.page in tcp_disconnect
      ipv4: Get the address of interface correctly.
      net_sched: gen_estimator: fix lockdep splat
      net: macb: Handle HRESP error
      net/mlx5e: IPoIB, Fix copy-paste bug in flow steering refactoring
      ipv6: addrconf: break critical section in addrconf_verify_rtnl()
      ipv6: change route cache aging logic
      i40e/i40evf: Update DESC_NEEDED value to reflect larger value
      bnxt_en: cleanup DIM work on device shutdown
      ...

commit 168fe32a072a4b8dc81a3aebf0e5e588d38e2955
Merge: 13ddd1667e7f c71d227fc413
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jan 30 17:58:07 2018 -0800

    Merge branch 'misc.poll' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull poll annotations from Al Viro:
     "This introduces a __bitwise type for POLL### bitmap, and propagates
      the annotations through the tree. Most of that stuff is as simple as
      'make ->poll() instances return __poll_t and do the same to local
      variables used to hold the future return value'.
    
      Some of the obvious brainos found in process are fixed (e.g. POLLIN
      misspelled as POLL_IN). At that point the amount of sparse warnings is
      low and most of them are for genuine bugs - e.g. ->poll() instance
      deciding to return -EINVAL instead of a bitmap. I hadn't touched those
      in this series - it's large enough as it is.
    
      Another problem it has caught was eventpoll() ABI mess; select.c and
      eventpoll.c assumed that corresponding POLL### and EPOLL### were
      equal. That's true for some, but not all of them - EPOLL### are
      arch-independent, but POLL### are not.
    
      The last commit in this series separates userland POLL### values from
      the (now arch-independent) kernel-side ones, converting between them
      in the few places where they are copied to/from userland. AFAICS, this
      is the least disruptive fix preserving poll(2) ABI and making epoll()
      work on all architectures.
    
      As it is, it's simply broken on sparc - try to give it EPOLLWRNORM and
      it will trigger only on what would've triggered EPOLLWRBAND on other
      architectures. EPOLLWRBAND and EPOLLRDHUP, OTOH, are never triggered
      at all on sparc. With this patch they should work consistently on all
      architectures"
    
    * 'misc.poll' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (37 commits)
      make kernel-side POLL... arch-independent
      eventpoll: no need to mask the result of epi_item_poll() again
      eventpoll: constify struct epoll_event pointers
      debugging printk in sg_poll() uses %x to print POLL... bitmap
      annotate poll(2) guts
      9p: untangle ->poll() mess
      ->si_band gets POLL... bitmap stored into a user-visible long field
      ring_buffer_poll_wait() return value used as return value of ->poll()
      the rest of drivers/*: annotate ->poll() instances
      media: annotate ->poll() instances
      fs: annotate ->poll() instances
      ipc, kernel, mm: annotate ->poll() instances
      net: annotate ->poll() instances
      apparmor: annotate ->poll() instances
      tomoyo: annotate ->poll() instances
      sound: annotate ->poll() instances
      acpi: annotate ->poll() instances
      crypto: annotate ->poll() instances
      block: annotate ->poll() instances
      x86: annotate ->poll() instances
      ...

commit 88fae87327a2261cf8db078f6ce4e5a3e55b30b1
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Fri Jan 26 01:36:31 2018 +0200

    tap: fix use-after-free
    
    Lockless access to __ptr_ring_full is only legal if ring is
    never resized, otherwise it might cause use-after free errors.
    Simply drop the lockless test, we'll drop the packet
    a bit later when produce fails.
    
    Fixes: 362899b8 ("macvtap: switch to use skb array")
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 7c38659b2a76..77872699c45d 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -330,9 +330,6 @@ rx_handler_result_t tap_handle_frame(struct sk_buff **pskb)
 	if (!q)
 		return RX_HANDLER_PASS;
 
-	if (__ptr_ring_full(&q->ring))
-		goto drop;
-
 	skb_push(skb, ETH_HLEN);
 
 	/* Apply the forward feature mask so that we perform segmentation

commit 5990a30510ed1c37a769d3a035ad2d030b843528
Author: Jason Wang <jasowang@redhat.com>
Date:   Thu Jan 4 11:14:27 2018 +0800

    tun/tap: use ptr_ring instead of skb_array
    
    This patch switches to use ptr_ring instead of skb_array. This will be
    used to enqueue different types of pointers by encoding type into
    lower bits.
    
    Signed-off-by: Jason Wang <jasowang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 0a886fda0129..7c38659b2a76 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -330,7 +330,7 @@ rx_handler_result_t tap_handle_frame(struct sk_buff **pskb)
 	if (!q)
 		return RX_HANDLER_PASS;
 
-	if (__skb_array_full(&q->skb_array))
+	if (__ptr_ring_full(&q->ring))
 		goto drop;
 
 	skb_push(skb, ETH_HLEN);
@@ -348,7 +348,7 @@ rx_handler_result_t tap_handle_frame(struct sk_buff **pskb)
 			goto drop;
 
 		if (!segs) {
-			if (skb_array_produce(&q->skb_array, skb))
+			if (ptr_ring_produce(&q->ring, skb))
 				goto drop;
 			goto wake_up;
 		}
@@ -358,7 +358,7 @@ rx_handler_result_t tap_handle_frame(struct sk_buff **pskb)
 			struct sk_buff *nskb = segs->next;
 
 			segs->next = NULL;
-			if (skb_array_produce(&q->skb_array, segs)) {
+			if (ptr_ring_produce(&q->ring, segs)) {
 				kfree_skb(segs);
 				kfree_skb_list(nskb);
 				break;
@@ -375,7 +375,7 @@ rx_handler_result_t tap_handle_frame(struct sk_buff **pskb)
 		    !(features & NETIF_F_CSUM_MASK) &&
 		    skb_checksum_help(skb))
 			goto drop;
-		if (skb_array_produce(&q->skb_array, skb))
+		if (ptr_ring_produce(&q->ring, skb))
 			goto drop;
 	}
 
@@ -497,7 +497,7 @@ static void tap_sock_destruct(struct sock *sk)
 {
 	struct tap_queue *q = container_of(sk, struct tap_queue, sk);
 
-	skb_array_cleanup(&q->skb_array);
+	ptr_ring_cleanup(&q->ring, __skb_array_destroy_skb);
 }
 
 static int tap_open(struct inode *inode, struct file *file)
@@ -517,7 +517,7 @@ static int tap_open(struct inode *inode, struct file *file)
 					     &tap_proto, 0);
 	if (!q)
 		goto err;
-	if (skb_array_init(&q->skb_array, tap->dev->tx_queue_len, GFP_KERNEL)) {
+	if (ptr_ring_init(&q->ring, tap->dev->tx_queue_len, GFP_KERNEL)) {
 		sk_free(&q->sk);
 		goto err;
 	}
@@ -546,7 +546,7 @@ static int tap_open(struct inode *inode, struct file *file)
 
 	err = tap_set_queue(tap, file, q);
 	if (err) {
-		/* tap_sock_destruct() will take care of freeing skb_array */
+		/* tap_sock_destruct() will take care of freeing ptr_ring */
 		goto err_put;
 	}
 
@@ -583,7 +583,7 @@ static unsigned int tap_poll(struct file *file, poll_table *wait)
 	mask = 0;
 	poll_wait(file, &q->wq.wait, wait);
 
-	if (!skb_array_empty(&q->skb_array))
+	if (!ptr_ring_empty(&q->ring))
 		mask |= POLLIN | POLLRDNORM;
 
 	if (sock_writeable(&q->sk) ||
@@ -844,7 +844,7 @@ static ssize_t tap_do_read(struct tap_queue *q,
 					TASK_INTERRUPTIBLE);
 
 		/* Read frames from the queue */
-		skb = skb_array_consume(&q->skb_array);
+		skb = ptr_ring_consume(&q->ring);
 		if (skb)
 			break;
 		if (noblock) {
@@ -1176,7 +1176,7 @@ static int tap_peek_len(struct socket *sock)
 {
 	struct tap_queue *q = container_of(sock, struct tap_queue,
 					       sock);
-	return skb_array_peek_len(&q->skb_array);
+	return PTR_RING_PEEK_CALL(&q->ring, __skb_array_len_with_tag);
 }
 
 /* Ops structure to mimic raw sockets with tun */
@@ -1202,7 +1202,7 @@ struct socket *tap_get_socket(struct file *file)
 }
 EXPORT_SYMBOL_GPL(tap_get_socket);
 
-struct skb_array *tap_get_skb_array(struct file *file)
+struct ptr_ring *tap_get_ptr_ring(struct file *file)
 {
 	struct tap_queue *q;
 
@@ -1211,29 +1211,30 @@ struct skb_array *tap_get_skb_array(struct file *file)
 	q = file->private_data;
 	if (!q)
 		return ERR_PTR(-EBADFD);
-	return &q->skb_array;
+	return &q->ring;
 }
-EXPORT_SYMBOL_GPL(tap_get_skb_array);
+EXPORT_SYMBOL_GPL(tap_get_ptr_ring);
 
 int tap_queue_resize(struct tap_dev *tap)
 {
 	struct net_device *dev = tap->dev;
 	struct tap_queue *q;
-	struct skb_array **arrays;
+	struct ptr_ring **rings;
 	int n = tap->numqueues;
 	int ret, i = 0;
 
-	arrays = kmalloc_array(n, sizeof(*arrays), GFP_KERNEL);
-	if (!arrays)
+	rings = kmalloc_array(n, sizeof(*rings), GFP_KERNEL);
+	if (!rings)
 		return -ENOMEM;
 
 	list_for_each_entry(q, &tap->queue_list, next)
-		arrays[i++] = &q->skb_array;
+		rings[i++] = &q->ring;
 
-	ret = skb_array_resize_multiple(arrays, n,
-					dev->tx_queue_len, GFP_KERNEL);
+	ret = ptr_ring_resize_multiple(rings, n,
+				       dev->tx_queue_len, GFP_KERNEL,
+				       __skb_array_destroy_skb);
 
-	kfree(arrays);
+	kfree(rings);
 	return ret;
 }
 EXPORT_SYMBOL_GPL(tap_queue_resize);

commit 61d78537843e676e7f56ac6db333db0c0529b892
Author: Wei Xu <wexu@redhat.com>
Date:   Fri Dec 1 05:10:38 2017 -0500

    tap: free skb if flags error
    
    tap_recvmsg() supports accepting skb by msg_control after
    commit 3b4ba04acca8 ("tap: support receiving skb from msg_control"),
    the skb if presented should be freed within the function, otherwise
    it would be leaked.
    
    Signed-off-by: Wei Xu <wexu@redhat.com>
    Reported-by: Matthew Rosato <mjrosato@linux.vnet.ibm.com>
    Acked-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index e9489b88407c..0a886fda0129 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -829,8 +829,11 @@ static ssize_t tap_do_read(struct tap_queue *q,
 	DEFINE_WAIT(wait);
 	ssize_t ret = 0;
 
-	if (!iov_iter_count(to))
+	if (!iov_iter_count(to)) {
+		if (skb)
+			kfree_skb(skb);
 		return 0;
+	}
 
 	if (skb)
 		goto put;
@@ -1154,11 +1157,14 @@ static int tap_recvmsg(struct socket *sock, struct msghdr *m,
 		       size_t total_len, int flags)
 {
 	struct tap_queue *q = container_of(sock, struct tap_queue, sock);
+	struct sk_buff *skb = m->msg_control;
 	int ret;
-	if (flags & ~(MSG_DONTWAIT|MSG_TRUNC))
+	if (flags & ~(MSG_DONTWAIT|MSG_TRUNC)) {
+		if (skb)
+			kfree_skb(skb);
 		return -EINVAL;
-	ret = tap_do_read(q, &m->msg_iter, flags & MSG_DONTWAIT,
-			  m->msg_control);
+	}
+	ret = tap_do_read(q, &m->msg_iter, flags & MSG_DONTWAIT, skb);
 	if (ret > total_len) {
 		m->msg_flags |= MSG_TRUNC;
 		ret = flags & MSG_TRUNC ? ret : total_len;

commit afc9a42b7464f76e1388cad87d8543c69f6f74ed
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jul 3 06:39:46 2017 -0400

    the rest of drivers/*: annotate ->poll() instances
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index e9489b88407c..c4e91c73568e 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -572,10 +572,10 @@ static int tap_release(struct inode *inode, struct file *file)
 	return 0;
 }
 
-static unsigned int tap_poll(struct file *file, poll_table *wait)
+static __poll_t tap_poll(struct file *file, poll_table *wait)
 {
 	struct tap_queue *q = file->private_data;
-	unsigned int mask = POLLERR;
+	__poll_t mask = POLLERR;
 
 	if (!q)
 		goto out;

commit 0c19f846d582af919db66a5914a0189f9f92c936
Author: Willem de Bruijn <willemb@google.com>
Date:   Tue Nov 21 10:22:25 2017 -0500

    net: accept UFO datagrams from tuntap and packet
    
    Tuntap and similar devices can inject GSO packets. Accept type
    VIRTIO_NET_HDR_GSO_UDP, even though not generating UFO natively.
    
    Processes are expected to use feature negotiation such as TUNSETOFFLOAD
    to detect supported offload types and refrain from injecting other
    packets. This process breaks down with live migration: guest kernels
    do not renegotiate flags, so destination hosts need to expose all
    features that the source host does.
    
    Partially revert the UFO removal from 182e0b6b5846~1..d9d30adf5677.
    This patch introduces nearly(*) no new code to simplify verification.
    It brings back verbatim tuntap UFO negotiation, VIRTIO_NET_HDR_GSO_UDP
    insertion and software UFO segmentation.
    
    It does not reinstate protocol stack support, hardware offload
    (NETIF_F_UFO), SKB_GSO_UDP tunneling in SKB_GSO_SOFTWARE or reception
    of VIRTIO_NET_HDR_GSO_UDP packets in tuntap.
    
    To support SKB_GSO_UDP reappearing in the stack, also reinstate
    logic in act_csum and openvswitch. Achieve equivalence with v4.13 HEAD
    by squashing in commit 939912216fa8 ("net: skb_needs_check() removes
    CHECKSUM_UNNECESSARY check for tx.") and reverting commit 8d63bee643f1
    ("net: avoid skb_warn_bad_offload false positives on UFO").
    
    (*) To avoid having to bring back skb_shinfo(skb)->ip6_frag_id,
    ipv6_proxy_select_ident is changed to return a __be32 and this is
    assigned directly to the frag_hdr. Also, SKB_GSO_UDP is inserted
    at the end of the enum to minimize code churn.
    
    Tested
      Booted a v4.13 guest kernel with QEMU. On a host kernel before this
      patch `ethtool -k eth0` shows UFO disabled. After the patch, it is
      enabled, same as on a v4.13 host kernel.
    
      A UFO packet sent from the guest appears on the tap device:
        host:
          nc -l -p -u 8000 &
          tcpdump -n -i tap0
    
        guest:
          dd if=/dev/zero of=payload.txt bs=1 count=2000
          nc -u 192.16.1.1 8000 < payload.txt
    
      Direct tap to tap transmission of VIRTIO_NET_HDR_GSO_UDP succeeds,
      packets arriving fragmented:
    
        ./with_tap_pair.sh ./tap_send_ufo tap0 tap1
        (from https://github.com/wdebruij/kerneltools/tree/master/tests)
    
    Changes
      v1 -> v2
        - simplified set_offload change (review comment)
        - documented test procedure
    
    Link: http://lkml.kernel.org/r/<CAF=yD-LuUeDuL9YWPJD9ykOZ0QCjNeznPDr6whqZ9NGMNF12Mw@mail.gmail.com>
    Fixes: fb652fdfe837 ("macvlan/macvtap: Remove NETIF_F_UFO advertisement.")
    Reported-by: Michal Kubecek <mkubecek@suse.cz>
    Signed-off-by: Willem de Bruijn <willemb@google.com>
    Acked-by: Jason Wang <jasowang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index b13890953ebb..e9489b88407c 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -1077,7 +1077,7 @@ static long tap_ioctl(struct file *file, unsigned int cmd,
 	case TUNSETOFFLOAD:
 		/* let the user check for future flags */
 		if (arg & ~(TUN_F_CSUM | TUN_F_TSO4 | TUN_F_TSO6 |
-			    TUN_F_TSO_ECN))
+			    TUN_F_TSO_ECN | TUN_F_UFO))
 			return -EINVAL;
 
 		rtnl_lock();

commit 8c5db92a705d9e2c986adec475980d1120fa07b4
Merge: ca5d376e1707 e4880bc5dfb1
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Nov 7 10:32:44 2017 +0100

    Merge branch 'linus' into locking/core, to resolve conflicts
    
    Conflicts:
            include/linux/compiler-clang.h
            include/linux/compiler-gcc.h
            include/linux/compiler-intel.h
            include/uapi/linux/stddef.h
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 93161922c658c714715686cd0cf69b090cb9bf1d
Author: Craig Gallek <kraig@google.com>
Date:   Mon Oct 30 18:50:11 2017 -0400

    tun/tap: sanitize TUNSETSNDBUF input
    
    Syzkaller found several variants of the lockup below by setting negative
    values with the TUNSETSNDBUF ioctl.  This patch adds a sanity check
    to both the tun and tap versions of this ioctl.
    
      watchdog: BUG: soft lockup - CPU#0 stuck for 22s! [repro:2389]
      Modules linked in:
      irq event stamp: 329692056
      hardirqs last  enabled at (329692055): [<ffffffff824b8381>] _raw_spin_unlock_irqrestore+0x31/0x75
      hardirqs last disabled at (329692056): [<ffffffff824b9e58>] apic_timer_interrupt+0x98/0xb0
      softirqs last  enabled at (35659740): [<ffffffff824bc958>] __do_softirq+0x328/0x48c
      softirqs last disabled at (35659731): [<ffffffff811c796c>] irq_exit+0xbc/0xd0
      CPU: 0 PID: 2389 Comm: repro Not tainted 4.14.0-rc7 #23
      Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011
      task: ffff880009452140 task.stack: ffff880006a20000
      RIP: 0010:_raw_spin_lock_irqsave+0x11/0x80
      RSP: 0018:ffff880006a27c50 EFLAGS: 00000282 ORIG_RAX: ffffffffffffff10
      RAX: ffff880009ac68d0 RBX: ffff880006a27ce0 RCX: 0000000000000000
      RDX: 0000000000000001 RSI: ffff880006a27ce0 RDI: ffff880009ac6900
      RBP: ffff880006a27c60 R08: 0000000000000000 R09: 0000000000000000
      R10: 0000000000000001 R11: 000000000063ff00 R12: ffff880009ac6900
      R13: ffff880006a27cf8 R14: 0000000000000001 R15: ffff880006a27cf8
      FS:  00007f4be4838700(0000) GS:ffff88000cc00000(0000) knlGS:0000000000000000
      CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      CR2: 0000000020101000 CR3: 0000000009616000 CR4: 00000000000006f0
      Call Trace:
       prepare_to_wait+0x26/0xc0
       sock_alloc_send_pskb+0x14e/0x270
       ? remove_wait_queue+0x60/0x60
       tun_get_user+0x2cc/0x19d0
       ? __tun_get+0x60/0x1b0
       tun_chr_write_iter+0x57/0x86
       __vfs_write+0x156/0x1e0
       vfs_write+0xf7/0x230
       SyS_write+0x57/0xd0
       entry_SYSCALL_64_fastpath+0x1f/0xbe
      RIP: 0033:0x7f4be4356df9
      RSP: 002b:00007ffc18101c08 EFLAGS: 00000293 ORIG_RAX: 0000000000000001
      RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007f4be4356df9
      RDX: 0000000000000046 RSI: 0000000020101000 RDI: 0000000000000005
      RBP: 00007ffc18101c40 R08: 0000000000000001 R09: 0000000000000001
      R10: 0000000000000001 R11: 0000000000000293 R12: 0000559c75f64780
      R13: 00007ffc18101d30 R14: 0000000000000000 R15: 0000000000000000
    
    Fixes: 33dccbb050bb ("tun: Limit amount of queued packets per device")
    Fixes: 20d29d7a916a ("net: macvtap driver")
    Signed-off-by: Craig Gallek <kraig@google.com>
    Reviewed-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 1b10fcc6a58d..6c0c84c33e1f 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -1032,6 +1032,8 @@ static long tap_ioctl(struct file *file, unsigned int cmd,
 	case TUNSETSNDBUF:
 		if (get_user(s, sp))
 			return -EFAULT;
+		if (s <= 0)
+			return -EINVAL;
 
 		q->sk.sk_sndbuf = s;
 		return 0;

commit dea6e19f4ef746aa18b4c33d1a7fed54356796ed
Author: Girish Moodalbail <girish.moodalbail@oracle.com>
Date:   Fri Oct 27 00:00:16 2017 -0700

    tap: reference to KVA of an unloaded module causes kernel panic
    
    The commit 9a393b5d5988 ("tap: tap as an independent module") created a
    separate tap module that implements tap functionality and exports
    interfaces that will be used by macvtap and ipvtap modules to create
    create respective tap devices.
    
    However, that patch introduced a regression wherein the modules macvtap
    and ipvtap can be removed (through modprobe -r) while there are
    applications using the respective /dev/tapX devices. These applications
    cause kernel to hold reference to /dev/tapX through 'struct cdev
    macvtap_cdev' and 'struct cdev ipvtap_dev' defined in macvtap and ipvtap
    modules respectively. So,  when the application is later closed the
    kernel panics because we are referencing KVA that is present in the
    unloaded modules.
    
    ----------8<------- Example ----------8<----------
    $ sudo ip li add name mv0 link enp7s0 type macvtap
    $ sudo ip li show mv0 |grep mv0| awk -e '{print $1 $2}'
      14:mv0@enp7s0:
    $ cat /dev/tap14 &
    $ lsmod |egrep -i 'tap|vlan'
    macvtap                16384  0
    macvlan                24576  1 macvtap
    tap                    24576  3 macvtap
    $ sudo modprobe -r macvtap
    $ fg
    cat /dev/tap14
    ^C
    
    <...system panics...>
    BUG: unable to handle kernel paging request at ffffffffa038c500
    IP: cdev_put+0xf/0x30
    ----------8<-----------------8<----------
    
    The fix is to set cdev.owner to the module that creates the tap device
    (either macvtap or ipvtap). With this set, the operations (in
    fs/char_dev.c) on char device holds and releases the module through
    cdev_get() and cdev_put() and will not allow the module to unload
    prematurely.
    
    Fixes: 9a393b5d5988ea4e (tap: tap as an independent module)
    Signed-off-by: Girish Moodalbail <girish.moodalbail@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 98ee6cc2875d..1b10fcc6a58d 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -1249,8 +1249,8 @@ static int tap_list_add(dev_t major, const char *device_name)
 	return 0;
 }
 
-int tap_create_cdev(struct cdev *tap_cdev,
-		    dev_t *tap_major, const char *device_name)
+int tap_create_cdev(struct cdev *tap_cdev, dev_t *tap_major,
+		    const char *device_name, struct module *module)
 {
 	int err;
 
@@ -1259,6 +1259,7 @@ int tap_create_cdev(struct cdev *tap_cdev,
 		goto out1;
 
 	cdev_init(tap_cdev, &tap_fops);
+	tap_cdev->owner = module;
 	err = cdev_add(tap_cdev, *tap_major, TAP_NUM_DEVS);
 	if (err)
 		goto out2;

commit 78e0ea6791d7baafb8a0ca82b1bd0c7b3453c919
Author: Girish Moodalbail <girish.moodalbail@oracle.com>
Date:   Wed Oct 25 00:23:04 2017 -0700

    tap: double-free in error path in tap_open()
    
    Double free of skb_array in tap module is causing kernel panic. When
    tap_set_queue() fails we free skb_array right away by calling
    skb_array_cleanup(). However, later on skb_array_cleanup() is called
    again by tap_sock_destruct through sock_put(). This patch fixes that
    issue.
    
    Fixes: 362899b8725b35e3 (macvtap: switch to use skb array)
    Signed-off-by: Girish Moodalbail <girish.moodalbail@oracle.com>
    Acked-by: Jason Wang <jasowang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 21b71ae947fd..98ee6cc2875d 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -517,6 +517,10 @@ static int tap_open(struct inode *inode, struct file *file)
 					     &tap_proto, 0);
 	if (!q)
 		goto err;
+	if (skb_array_init(&q->skb_array, tap->dev->tx_queue_len, GFP_KERNEL)) {
+		sk_free(&q->sk);
+		goto err;
+	}
 
 	RCU_INIT_POINTER(q->sock.wq, &q->wq);
 	init_waitqueue_head(&q->wq.wait);
@@ -540,22 +544,18 @@ static int tap_open(struct inode *inode, struct file *file)
 	if ((tap->dev->features & NETIF_F_HIGHDMA) && (tap->dev->features & NETIF_F_SG))
 		sock_set_flag(&q->sk, SOCK_ZEROCOPY);
 
-	err = -ENOMEM;
-	if (skb_array_init(&q->skb_array, tap->dev->tx_queue_len, GFP_KERNEL))
-		goto err_array;
-
 	err = tap_set_queue(tap, file, q);
-	if (err)
-		goto err_queue;
+	if (err) {
+		/* tap_sock_destruct() will take care of freeing skb_array */
+		goto err_put;
+	}
 
 	dev_put(tap->dev);
 
 	rtnl_unlock();
 	return err;
 
-err_queue:
-	skb_array_cleanup(&q->skb_array);
-err_array:
+err_put:
 	sock_put(&q->sk);
 err:
 	if (tap)

commit 6aa7de059173a986114ac43b8f50b297a86f09a8
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Mon Oct 23 14:07:29 2017 -0700

    locking/atomics: COCCINELLE/treewide: Convert trivial ACCESS_ONCE() patterns to READ_ONCE()/WRITE_ONCE()
    
    Please do not apply this to mainline directly, instead please re-run the
    coccinelle script shown below and apply its output.
    
    For several reasons, it is desirable to use {READ,WRITE}_ONCE() in
    preference to ACCESS_ONCE(), and new code is expected to use one of the
    former. So far, there's been no reason to change most existing uses of
    ACCESS_ONCE(), as these aren't harmful, and changing them results in
    churn.
    
    However, for some features, the read/write distinction is critical to
    correct operation. To distinguish these cases, separate read/write
    accessors must be used. This patch migrates (most) remaining
    ACCESS_ONCE() instances to {READ,WRITE}_ONCE(), using the following
    coccinelle script:
    
    ----
    // Convert trivial ACCESS_ONCE() uses to equivalent READ_ONCE() and
    // WRITE_ONCE()
    
    // $ make coccicheck COCCI=/home/mark/once.cocci SPFLAGS="--include-headers" MODE=patch
    
    virtual patch
    
    @ depends on patch @
    expression E1, E2;
    @@
    
    - ACCESS_ONCE(E1) = E2
    + WRITE_ONCE(E1, E2)
    
    @ depends on patch @
    expression E;
    @@
    
    - ACCESS_ONCE(E)
    + READ_ONCE(E)
    ----
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: davem@davemloft.net
    Cc: linux-arch@vger.kernel.org
    Cc: mpe@ellerman.id.au
    Cc: shuah@kernel.org
    Cc: snitzer@redhat.com
    Cc: thor.thayer@linux.intel.com
    Cc: tj@kernel.org
    Cc: viro@zeniv.linux.org.uk
    Cc: will.deacon@arm.com
    Link: http://lkml.kernel.org/r/1508792849-3115-19-git-send-email-paulmck@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 21b71ae947fd..b55b29b90b88 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -257,7 +257,7 @@ static struct tap_queue *tap_get_queue(struct tap_dev *tap,
 	 * and validate that the result isn't NULL - in case we are
 	 * racing against queue removal.
 	 */
-	int numvtaps = ACCESS_ONCE(tap->numvtaps);
+	int numvtaps = READ_ONCE(tap->numvtaps);
 	__u32 rxq;
 
 	if (!numvtaps)

commit 120390468b38f04373e67dbc9f361e2bb2996691
Author: stephen hemminger <stephen@networkplumber.org>
Date:   Tue Aug 15 10:29:16 2017 -0700

    tun/tap: use paren's with sizeof
    
    Although sizeof is an operator in C. The kernel coding style convention
    is to always use it like a function and add parenthesis.
    
    Signed-off-by: Stephen Hemminger <stephen@networkplumber.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 0d039411e64c..21b71ae947fd 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -1215,7 +1215,7 @@ int tap_queue_resize(struct tap_dev *tap)
 	int n = tap->numqueues;
 	int ret, i = 0;
 
-	arrays = kmalloc(sizeof *arrays * n, GFP_KERNEL);
+	arrays = kmalloc_array(n, sizeof(*arrays), GFP_KERNEL);
 	if (!arrays)
 		return -ENOMEM;
 

commit d17eb73bb713dc8dd389aa87606b90edb0d258b2
Author: Colin Ian King <colin.king@canonical.com>
Date:   Sat Aug 12 22:52:31 2017 +0100

    tap: make struct tap_fops static
    
    The structure tap_fops is local to the source and does not need to
    be in global scope, so make it static.
    
    Cleans up sparse warning:
    symbol 'tap_fops' was not declared. Should it be static?
    
    Signed-off-by: Colin Ian King <colin.king@canonical.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index ca267fd28ab8..0d039411e64c 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -1127,7 +1127,7 @@ static long tap_compat_ioctl(struct file *file, unsigned int cmd,
 }
 #endif
 
-const struct file_operations tap_fops = {
+static const struct file_operations tap_fops = {
 	.owner		= THIS_MODULE,
 	.open		= tap_open,
 	.release	= tap_release,

commit d591a1f3aad92ade4642e4173f4c368006c27f0f
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Jul 3 06:35:32 2017 -0700

    tun/tap: Remove references to NETIF_F_UFO.
    
    It is going away.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 3570c7576993..ca267fd28ab8 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -943,9 +943,6 @@ static int set_offload(struct tap_queue *q, unsigned long arg)
 			if (arg & TUN_F_TSO6)
 				feature_mask |= NETIF_F_TSO6;
 		}
-
-		if (arg & TUN_F_UFO)
-			feature_mask |= NETIF_F_UFO;
 	}
 
 	/* tun/tap driver inverts the usage for TSO offloads, where
@@ -956,7 +953,7 @@ static int set_offload(struct tap_queue *q, unsigned long arg)
 	 * When user space turns off TSO, we turn off GSO/LRO so that
 	 * user-space will not receive TSO frames.
 	 */
-	if (feature_mask & (NETIF_F_TSO | NETIF_F_TSO6 | NETIF_F_UFO))
+	if (feature_mask & (NETIF_F_TSO | NETIF_F_TSO6))
 		features |= RX_OFFLOADS;
 	else
 		features &= ~RX_OFFLOADS;
@@ -1078,7 +1075,7 @@ static long tap_ioctl(struct file *file, unsigned int cmd,
 	case TUNSETOFFLOAD:
 		/* let the user check for future flags */
 		if (arg & ~(TUN_F_CSUM | TUN_F_TSO4 | TUN_F_TSO6 |
-			    TUN_F_TSO_ECN | TUN_F_UFO))
+			    TUN_F_TSO_ECN))
 			return -EINVAL;
 
 		rtnl_lock();

commit ffa423fb3251f8737303ffc3b0659e86e501808e
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Mon Jul 10 10:05:50 2017 -0700

    tap: convert a mutex to a spinlock
    
    We are not allowed to block on the RCU reader side, so can't
    just hold the mutex as before. As a quick fix, convert it to
    a spinlock.
    
    Fixes: d9f1f61c0801 ("tap: Extending tap device create/destroy APIs")
    Reported-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Tested-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Sainath Grandhi <sainath.grandhi@intel.com>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 9af3239d6ad5..3570c7576993 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -106,7 +106,7 @@ struct major_info {
 	struct rcu_head rcu;
 	dev_t major;
 	struct idr minor_idr;
-	struct mutex minor_lock;
+	spinlock_t minor_lock;
 	const char *device_name;
 	struct list_head next;
 };
@@ -416,15 +416,15 @@ int tap_get_minor(dev_t major, struct tap_dev *tap)
 		goto unlock;
 	}
 
-	mutex_lock(&tap_major->minor_lock);
-	retval = idr_alloc(&tap_major->minor_idr, tap, 1, TAP_NUM_DEVS, GFP_KERNEL);
+	spin_lock(&tap_major->minor_lock);
+	retval = idr_alloc(&tap_major->minor_idr, tap, 1, TAP_NUM_DEVS, GFP_ATOMIC);
 	if (retval >= 0) {
 		tap->minor = retval;
 	} else if (retval == -ENOSPC) {
 		netdev_err(tap->dev, "Too many tap devices\n");
 		retval = -EINVAL;
 	}
-	mutex_unlock(&tap_major->minor_lock);
+	spin_unlock(&tap_major->minor_lock);
 
 unlock:
 	rcu_read_unlock();
@@ -442,12 +442,12 @@ void tap_free_minor(dev_t major, struct tap_dev *tap)
 		goto unlock;
 	}
 
-	mutex_lock(&tap_major->minor_lock);
+	spin_lock(&tap_major->minor_lock);
 	if (tap->minor) {
 		idr_remove(&tap_major->minor_idr, tap->minor);
 		tap->minor = 0;
 	}
-	mutex_unlock(&tap_major->minor_lock);
+	spin_unlock(&tap_major->minor_lock);
 
 unlock:
 	rcu_read_unlock();
@@ -467,13 +467,13 @@ static struct tap_dev *dev_get_by_tap_file(int major, int minor)
 		goto unlock;
 	}
 
-	mutex_lock(&tap_major->minor_lock);
+	spin_lock(&tap_major->minor_lock);
 	tap = idr_find(&tap_major->minor_idr, minor);
 	if (tap) {
 		dev = tap->dev;
 		dev_hold(dev);
 	}
-	mutex_unlock(&tap_major->minor_lock);
+	spin_unlock(&tap_major->minor_lock);
 
 unlock:
 	rcu_read_unlock();
@@ -1244,7 +1244,7 @@ static int tap_list_add(dev_t major, const char *device_name)
 	tap_major->major = MAJOR(major);
 
 	idr_init(&tap_major->minor_idr);
-	mutex_init(&tap_major->minor_lock);
+	spin_lock_init(&tap_major->minor_lock);
 
 	tap_major->device_name = device_name;
 

commit 3b4ba04acca8f98a62fd014a0826ea10bc93cde3
Author: Jason Wang <jasowang@redhat.com>
Date:   Wed May 17 12:14:44 2017 +0800

    tap: support receiving skb from msg_control
    
    This patch makes tap_recvmsg() can receive from skb from its caller
    through msg_control. Vhost_net will be the first user.
    
    Signed-off-by: Jason Wang <jasowang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index abdaf867774d..9af3239d6ad5 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -824,15 +824,17 @@ static ssize_t tap_put_user(struct tap_queue *q,
 
 static ssize_t tap_do_read(struct tap_queue *q,
 			   struct iov_iter *to,
-			   int noblock)
+			   int noblock, struct sk_buff *skb)
 {
 	DEFINE_WAIT(wait);
-	struct sk_buff *skb;
 	ssize_t ret = 0;
 
 	if (!iov_iter_count(to))
 		return 0;
 
+	if (skb)
+		goto put;
+
 	while (1) {
 		if (!noblock)
 			prepare_to_wait(sk_sleep(&q->sk), &wait,
@@ -856,6 +858,7 @@ static ssize_t tap_do_read(struct tap_queue *q,
 	if (!noblock)
 		finish_wait(sk_sleep(&q->sk), &wait);
 
+put:
 	if (skb) {
 		ret = tap_put_user(q, skb, to);
 		if (unlikely(ret < 0))
@@ -872,7 +875,7 @@ static ssize_t tap_read_iter(struct kiocb *iocb, struct iov_iter *to)
 	struct tap_queue *q = file->private_data;
 	ssize_t len = iov_iter_count(to), ret;
 
-	ret = tap_do_read(q, to, file->f_flags & O_NONBLOCK);
+	ret = tap_do_read(q, to, file->f_flags & O_NONBLOCK, NULL);
 	ret = min_t(ssize_t, ret, len);
 	if (ret > 0)
 		iocb->ki_pos = ret;
@@ -1155,7 +1158,8 @@ static int tap_recvmsg(struct socket *sock, struct msghdr *m,
 	int ret;
 	if (flags & ~(MSG_DONTWAIT|MSG_TRUNC))
 		return -EINVAL;
-	ret = tap_do_read(q, &m->msg_iter, flags & MSG_DONTWAIT);
+	ret = tap_do_read(q, &m->msg_iter, flags & MSG_DONTWAIT,
+			  m->msg_control);
 	if (ret > total_len) {
 		m->msg_flags |= MSG_TRUNC;
 		ret = flags & MSG_TRUNC ? ret : total_len;

commit 49f96fd0cb3808e5ff96573f28b3dceb16eb6998
Author: Jason Wang <jasowang@redhat.com>
Date:   Wed May 17 12:14:42 2017 +0800

    tap: export skb_array
    
    This patch exports skb_array through tap_get_skb_array(). Caller can
    then manipulate skb array directly.
    
    Signed-off-by: Jason Wang <jasowang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 4d4173d25dd0..abdaf867774d 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -1193,6 +1193,19 @@ struct socket *tap_get_socket(struct file *file)
 }
 EXPORT_SYMBOL_GPL(tap_get_socket);
 
+struct skb_array *tap_get_skb_array(struct file *file)
+{
+	struct tap_queue *q;
+
+	if (file->f_op != &tap_fops)
+		return ERR_PTR(-EINVAL);
+	q = file->private_data;
+	if (!q)
+		return ERR_PTR(-EBADFD);
+	return &q->skb_array;
+}
+EXPORT_SYMBOL_GPL(tap_get_skb_array);
+
 int tap_queue_resize(struct tap_dev *tap)
 {
 	struct net_device *dev = tap->dev;

commit c3edc4010e9d102eb7b8f17d15c2ebc425fed63c
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Feb 2 08:35:14 2017 +0100

    sched/headers: Move task_struct::signal and task_struct::sighand types and accessors into <linux/sched/signal.h>
    
    task_struct::signal and task_struct::sighand are pointers, which would normally make it
    straightforward to not define those types in sched.h.
    
    That is not so, because the types are accompanied by a myriad of APIs (macros and inline
    functions) that dereference them.
    
    Split the types and the APIs out of sched.h and move them into a new header, <linux/sched/signal.h>.
    
    With this change sched.h does not know about 'struct signal' and 'struct sighand' anymore,
    trying to put accessors into sched.h as a test fails the following way:
    
      ./include/linux/sched.h: In function test_signal_types:
      ./include/linux/sched.h:2461:18: error: dereferencing pointer to incomplete type struct signal_struct
                        ^
    
    This reduces the size and complexity of sched.h significantly.
    
    Update all headers and .c code that relied on getting the signal handling
    functionality from <linux/sched.h> to include <linux/sched/signal.h>.
    
    The list of affected files in the preparatory patch was partly generated by
    grepping for the APIs, and partly by doing coverage build testing, both
    all[yes|mod|def|no]config builds on 64-bit and 32-bit x86, and an array of
    cross-architecture builds.
    
    Nevertheless some (trivial) build breakage is still expected related to rare
    Kconfig combinations and in-flight patches to various kernel code, but most
    of it should be handled by this patch.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 35b55a2fa1a1..4d4173d25dd0 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -8,7 +8,7 @@
 #include <linux/module.h>
 #include <linux/skbuff.h>
 #include <linux/cache.h>
-#include <linux/sched.h>
+#include <linux/sched/signal.h>
 #include <linux/types.h>
 #include <linux/slab.h>
 #include <linux/wait.h>

commit 9a393b5d5988ea4eaa3e0da138321abe0dc03a68
Author: Sainath Grandhi <sainath.grandhi@intel.com>
Date:   Fri Feb 10 16:03:51 2017 -0800

    tap: tap as an independent module
    
    This patch makes tap a separate module for other types of virtual interfaces, for example,
    ipvlan to use.
    
    Signed-off-by: Sainath Grandhi <sainath.grandhi@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 71bbf0b6327d..35b55a2fa1a1 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -312,6 +312,7 @@ void tap_del_queues(struct tap_dev *tap)
 	/* guarantee that any future tap_set_queue will fail */
 	tap->numvtaps = MAX_TAP_QUEUES;
 }
+EXPORT_SYMBOL_GPL(tap_del_queues);
 
 rx_handler_result_t tap_handle_frame(struct sk_buff **pskb)
 {
@@ -389,6 +390,7 @@ rx_handler_result_t tap_handle_frame(struct sk_buff **pskb)
 	kfree_skb(skb);
 	return RX_HANDLER_CONSUMED;
 }
+EXPORT_SYMBOL_GPL(tap_handle_frame);
 
 static struct major_info *tap_get_major(int major)
 {
@@ -428,6 +430,7 @@ int tap_get_minor(dev_t major, struct tap_dev *tap)
 	rcu_read_unlock();
 	return retval < 0 ? retval : 0;
 }
+EXPORT_SYMBOL_GPL(tap_get_minor);
 
 void tap_free_minor(dev_t major, struct tap_dev *tap)
 {
@@ -449,6 +452,7 @@ void tap_free_minor(dev_t major, struct tap_dev *tap)
 unlock:
 	rcu_read_unlock();
 }
+EXPORT_SYMBOL_GPL(tap_free_minor);
 
 static struct tap_dev *dev_get_by_tap_file(int major, int minor)
 {
@@ -1210,6 +1214,7 @@ int tap_queue_resize(struct tap_dev *tap)
 	kfree(arrays);
 	return ret;
 }
+EXPORT_SYMBOL_GPL(tap_queue_resize);
 
 static int tap_list_add(dev_t major, const char *device_name)
 {
@@ -1257,6 +1262,7 @@ int tap_create_cdev(struct cdev *tap_cdev,
 out1:
 	return err;
 }
+EXPORT_SYMBOL_GPL(tap_create_cdev);
 
 void tap_destroy_cdev(dev_t major, struct cdev *tap_cdev)
 {
@@ -1272,3 +1278,8 @@ void tap_destroy_cdev(dev_t major, struct cdev *tap_cdev)
 		}
 	}
 }
+EXPORT_SYMBOL_GPL(tap_destroy_cdev);
+
+MODULE_AUTHOR("Arnd Bergmann <arnd@arndb.de>");
+MODULE_AUTHOR("Sainath Grandhi <sainath.grandhi@intel.com>");
+MODULE_LICENSE("GPL");

commit d9f1f61c0801a73ff36d416a7ede54229b231e1d
Author: Sainath Grandhi <sainath.grandhi@intel.com>
Date:   Fri Feb 10 16:03:50 2017 -0800

    tap: Extending tap device create/destroy APIs
    
    Extending tap APIs get/free_minor and create/destroy_cdev to handle more than one
    type of virtual interface.
    
    Signed-off-by: Sainath Grandhi <sainath.grandhi@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 7d3e8b18f5e6..71bbf0b6327d 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -99,12 +99,17 @@ static struct proto tap_proto = {
 };
 
 #define TAP_NUM_DEVS (1U << MINORBITS)
+
+static LIST_HEAD(major_list);
+
 struct major_info {
+	struct rcu_head rcu;
 	dev_t major;
 	struct idr minor_idr;
 	struct mutex minor_lock;
 	const char *device_name;
-} macvtap_major;
+	struct list_head next;
+};
 
 #define GOODCOPY_LEN 128
 
@@ -385,44 +390,89 @@ rx_handler_result_t tap_handle_frame(struct sk_buff **pskb)
 	return RX_HANDLER_CONSUMED;
 }
 
-int tap_get_minor(struct tap_dev *tap)
+static struct major_info *tap_get_major(int major)
+{
+	struct major_info *tap_major;
+
+	list_for_each_entry_rcu(tap_major, &major_list, next) {
+		if (tap_major->major == major)
+			return tap_major;
+	}
+
+	return NULL;
+}
+
+int tap_get_minor(dev_t major, struct tap_dev *tap)
 {
 	int retval = -ENOMEM;
+	struct major_info *tap_major;
+
+	rcu_read_lock();
+	tap_major = tap_get_major(MAJOR(major));
+	if (!tap_major) {
+		retval = -EINVAL;
+		goto unlock;
+	}
 
-	mutex_lock(&macvtap_major.minor_lock);
-	retval = idr_alloc(&macvtap_major.minor_idr, tap, 1, TAP_NUM_DEVS, GFP_KERNEL);
+	mutex_lock(&tap_major->minor_lock);
+	retval = idr_alloc(&tap_major->minor_idr, tap, 1, TAP_NUM_DEVS, GFP_KERNEL);
 	if (retval >= 0) {
 		tap->minor = retval;
 	} else if (retval == -ENOSPC) {
 		netdev_err(tap->dev, "Too many tap devices\n");
 		retval = -EINVAL;
 	}
-	mutex_unlock(&macvtap_major.minor_lock);
+	mutex_unlock(&tap_major->minor_lock);
+
+unlock:
+	rcu_read_unlock();
 	return retval < 0 ? retval : 0;
 }
 
-void tap_free_minor(struct tap_dev *tap)
+void tap_free_minor(dev_t major, struct tap_dev *tap)
 {
-	mutex_lock(&macvtap_major.minor_lock);
+	struct major_info *tap_major;
+
+	rcu_read_lock();
+	tap_major = tap_get_major(MAJOR(major));
+	if (!tap_major) {
+		goto unlock;
+	}
+
+	mutex_lock(&tap_major->minor_lock);
 	if (tap->minor) {
-		idr_remove(&macvtap_major.minor_idr, tap->minor);
+		idr_remove(&tap_major->minor_idr, tap->minor);
 		tap->minor = 0;
 	}
-	mutex_unlock(&macvtap_major.minor_lock);
+	mutex_unlock(&tap_major->minor_lock);
+
+unlock:
+	rcu_read_unlock();
 }
 
-static struct tap_dev *dev_get_by_tap_minor(int minor)
+static struct tap_dev *dev_get_by_tap_file(int major, int minor)
 {
 	struct net_device *dev = NULL;
 	struct tap_dev *tap;
+	struct major_info *tap_major;
 
-	mutex_lock(&macvtap_major.minor_lock);
-	tap = idr_find(&macvtap_major.minor_idr, minor);
+	rcu_read_lock();
+	tap_major = tap_get_major(major);
+	if (!tap_major) {
+		tap = NULL;
+		goto unlock;
+	}
+
+	mutex_lock(&tap_major->minor_lock);
+	tap = idr_find(&tap_major->minor_idr, minor);
 	if (tap) {
 		dev = tap->dev;
 		dev_hold(dev);
 	}
-	mutex_unlock(&macvtap_major.minor_lock);
+	mutex_unlock(&tap_major->minor_lock);
+
+unlock:
+	rcu_read_unlock();
 	return tap;
 }
 
@@ -454,7 +504,7 @@ static int tap_open(struct inode *inode, struct file *file)
 	int err = -ENODEV;
 
 	rtnl_lock();
-	tap = dev_get_by_tap_minor(iminor(inode));
+	tap = dev_get_by_tap_file(imajor(inode), iminor(inode));
 	if (!tap)
 		goto err;
 
@@ -1161,6 +1211,25 @@ int tap_queue_resize(struct tap_dev *tap)
 	return ret;
 }
 
+static int tap_list_add(dev_t major, const char *device_name)
+{
+	struct major_info *tap_major;
+
+	tap_major = kzalloc(sizeof(*tap_major), GFP_ATOMIC);
+	if (!tap_major)
+		return -ENOMEM;
+
+	tap_major->major = MAJOR(major);
+
+	idr_init(&tap_major->minor_idr);
+	mutex_init(&tap_major->minor_lock);
+
+	tap_major->device_name = device_name;
+
+	list_add_tail_rcu(&tap_major->next, &major_list);
+	return 0;
+}
+
 int tap_create_cdev(struct cdev *tap_cdev,
 		    dev_t *tap_major, const char *device_name)
 {
@@ -1175,15 +1244,14 @@ int tap_create_cdev(struct cdev *tap_cdev,
 	if (err)
 		goto out2;
 
-	macvtap_major.major = MAJOR(*tap_major);
-
-	idr_init(&macvtap_major.minor_idr);
-	mutex_init(&macvtap_major.minor_lock);
-
-	macvtap_major.device_name = device_name;
+	err =  tap_list_add(*tap_major, device_name);
+	if (err)
+		goto out3;
 
 	return 0;
 
+out3:
+	cdev_del(tap_cdev);
 out2:
 	unregister_chrdev_region(*tap_major, TAP_NUM_DEVS);
 out1:
@@ -1192,7 +1260,15 @@ int tap_create_cdev(struct cdev *tap_cdev,
 
 void tap_destroy_cdev(dev_t major, struct cdev *tap_cdev)
 {
+	struct major_info *tap_major, *tmp;
+
 	cdev_del(tap_cdev);
 	unregister_chrdev_region(major, TAP_NUM_DEVS);
-	idr_destroy(&macvtap_major.minor_idr);
+	list_for_each_entry_safe(tap_major, tmp, &major_list, next) {
+		if (tap_major->major == MAJOR(major)) {
+			idr_destroy(&tap_major->minor_idr);
+			list_del_rcu(&tap_major->next);
+			kfree_rcu(tap_major, rcu);
+		}
+	}
 }

commit 6fe3faf86757eb7f078ff06b23b206f17dc4fb36
Author: Sainath Grandhi <sainath.grandhi@intel.com>
Date:   Fri Feb 10 16:03:49 2017 -0800

    tap: Abstract type of virtual interface from tap implementation
    
    macvlan object is re-structured to hold tap related elements in a separate
    entity, tap_dev. Upon NETDEV_REGISTER device_event, tap_dev is registered with
    idr and fetched again on tap_open. Few of the tap functions are modified to
    accepted tap_dev as argument. tap_dev object includes callbacks to be used by
    underlying virtual interface to take care of tx and rx accounting.
    
    Signed-off-by: Sainath Grandhi <sainath.grandhi@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 04ba9782c2f3..7d3e8b18f5e6 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -1,5 +1,5 @@
 #include <linux/etherdevice.h>
-#include <linux/if_macvlan.h>
+#include <linux/if_tap.h>
 #include <linux/if_vlan.h>
 #include <linux/interrupt.h>
 #include <linux/nsproxy.h>
@@ -23,30 +23,6 @@
 #include <linux/virtio_net.h>
 #include <linux/skb_array.h>
 
-/*
- * A tap queue is the central object of this driver, it connects
- * an open character device to a macvlan interface. There can be
- * multiple queues on one interface, which map back to queues
- * implemented in hardware on the underlying device.
- *
- * tap_proto is used to allocate queues through the sock allocation
- * mechanism.
- *
- */
-struct tap_queue {
-	struct sock sk;
-	struct socket sock;
-	struct socket_wq wq;
-	int vnet_hdr_sz;
-	struct macvlan_dev __rcu *vlan;
-	struct file *file;
-	unsigned int flags;
-	u16 queue_index;
-	bool enabled;
-	struct list_head next;
-	struct skb_array skb_array;
-};
-
 #define TAP_IFFEATURES (IFF_VNET_HDR | IFF_MULTI_QUEUE)
 
 #define TAP_VNET_LE 0x80000000
@@ -137,7 +113,7 @@ static const struct proto_ops tap_socket_ops;
 #define RX_OFFLOADS (NETIF_F_GRO | NETIF_F_LRO)
 #define TAP_FEATURES (NETIF_F_GSO | NETIF_F_SG | NETIF_F_FRAGLIST)
 
-static struct macvlan_dev *tap_get_vlan_rcu(const struct net_device *dev)
+static struct tap_dev *tap_dev_get_rcu(const struct net_device *dev)
 {
 	return rcu_dereference(dev->rx_handler_data);
 }
@@ -159,10 +135,9 @@ static struct macvlan_dev *tap_get_vlan_rcu(const struct net_device *dev)
  * when both our references and any pending SKBs are gone.
  */
 
-static int tap_enable_queue(struct net_device *dev, struct file *file,
+static int tap_enable_queue(struct tap_dev *tap, struct file *file,
 			    struct tap_queue *q)
 {
-	struct macvlan_dev *vlan = netdev_priv(dev);
 	int err = -EINVAL;
 
 	ASSERT_RTNL();
@@ -171,62 +146,60 @@ static int tap_enable_queue(struct net_device *dev, struct file *file,
 		goto out;
 
 	err = 0;
-	rcu_assign_pointer(vlan->taps[vlan->numvtaps], q);
-	q->queue_index = vlan->numvtaps;
+	rcu_assign_pointer(tap->taps[tap->numvtaps], q);
+	q->queue_index = tap->numvtaps;
 	q->enabled = true;
 
-	vlan->numvtaps++;
+	tap->numvtaps++;
 out:
 	return err;
 }
 
 /* Requires RTNL */
-static int tap_set_queue(struct net_device *dev, struct file *file,
+static int tap_set_queue(struct tap_dev *tap, struct file *file,
 			 struct tap_queue *q)
 {
-	struct macvlan_dev *vlan = netdev_priv(dev);
-
-	if (vlan->numqueues == MAX_TAP_QUEUES)
+	if (tap->numqueues == MAX_TAP_QUEUES)
 		return -EBUSY;
 
-	rcu_assign_pointer(q->vlan, vlan);
-	rcu_assign_pointer(vlan->taps[vlan->numvtaps], q);
+	rcu_assign_pointer(q->tap, tap);
+	rcu_assign_pointer(tap->taps[tap->numvtaps], q);
 	sock_hold(&q->sk);
 
 	q->file = file;
-	q->queue_index = vlan->numvtaps;
+	q->queue_index = tap->numvtaps;
 	q->enabled = true;
 	file->private_data = q;
-	list_add_tail(&q->next, &vlan->queue_list);
+	list_add_tail(&q->next, &tap->queue_list);
 
-	vlan->numvtaps++;
-	vlan->numqueues++;
+	tap->numvtaps++;
+	tap->numqueues++;
 
 	return 0;
 }
 
 static int tap_disable_queue(struct tap_queue *q)
 {
-	struct macvlan_dev *vlan;
+	struct tap_dev *tap;
 	struct tap_queue *nq;
 
 	ASSERT_RTNL();
 	if (!q->enabled)
 		return -EINVAL;
 
-	vlan = rtnl_dereference(q->vlan);
+	tap = rtnl_dereference(q->tap);
 
-	if (vlan) {
+	if (tap) {
 		int index = q->queue_index;
-		BUG_ON(index >= vlan->numvtaps);
-		nq = rtnl_dereference(vlan->taps[vlan->numvtaps - 1]);
+		BUG_ON(index >= tap->numvtaps);
+		nq = rtnl_dereference(tap->taps[tap->numvtaps - 1]);
 		nq->queue_index = index;
 
-		rcu_assign_pointer(vlan->taps[index], nq);
-		RCU_INIT_POINTER(vlan->taps[vlan->numvtaps - 1], NULL);
+		rcu_assign_pointer(tap->taps[index], nq);
+		RCU_INIT_POINTER(tap->taps[tap->numvtaps - 1], NULL);
 		q->enabled = false;
 
-		vlan->numvtaps--;
+		tap->numvtaps--;
 	}
 
 	return 0;
@@ -242,17 +215,17 @@ static int tap_disable_queue(struct tap_queue *q)
  */
 static void tap_put_queue(struct tap_queue *q)
 {
-	struct macvlan_dev *vlan;
+	struct tap_dev *tap;
 
 	rtnl_lock();
-	vlan = rtnl_dereference(q->vlan);
+	tap = rtnl_dereference(q->tap);
 
-	if (vlan) {
+	if (tap) {
 		if (q->enabled)
 			BUG_ON(tap_disable_queue(q));
 
-		vlan->numqueues--;
-		RCU_INIT_POINTER(q->vlan, NULL);
+		tap->numqueues--;
+		RCU_INIT_POINTER(q->tap, NULL);
 		sock_put(&q->sk);
 		list_del_init(&q->next);
 	}
@@ -270,17 +243,16 @@ static void tap_put_queue(struct tap_queue *q)
  * Cache vlan->numvtaps since it can become zero during the execution
  * of this function.
  */
-static struct tap_queue *tap_get_queue(struct net_device *dev,
+static struct tap_queue *tap_get_queue(struct tap_dev *tap,
 				       struct sk_buff *skb)
 {
-	struct macvlan_dev *vlan = netdev_priv(dev);
-	struct tap_queue *tap = NULL;
+	struct tap_queue *queue = NULL;
 	/* Access to taps array is protected by rcu, but access to numvtaps
 	 * isn't. Below we use it to lookup a queue, but treat it as a hint
 	 * and validate that the result isn't NULL - in case we are
 	 * racing against queue removal.
 	 */
-	int numvtaps = ACCESS_ONCE(vlan->numvtaps);
+	int numvtaps = ACCESS_ONCE(tap->numvtaps);
 	__u32 rxq;
 
 	if (!numvtaps)
@@ -292,7 +264,7 @@ static struct tap_queue *tap_get_queue(struct net_device *dev,
 	/* Check if we can use flow to select a queue */
 	rxq = skb_get_hash(skb);
 	if (rxq) {
-		tap = rcu_dereference(vlan->taps[rxq % numvtaps]);
+		queue = rcu_dereference(tap->taps[rxq % numvtaps]);
 		goto out;
 	}
 
@@ -302,14 +274,14 @@ static struct tap_queue *tap_get_queue(struct net_device *dev,
 		while (unlikely(rxq >= numvtaps))
 			rxq -= numvtaps;
 
-		tap = rcu_dereference(vlan->taps[rxq]);
+		queue = rcu_dereference(tap->taps[rxq]);
 		goto out;
 	}
 
 single:
-	tap = rcu_dereference(vlan->taps[0]);
+	queue = rcu_dereference(tap->taps[0]);
 out:
-	return tap;
+	return queue;
 }
 
 /*
@@ -317,39 +289,38 @@ static struct tap_queue *tap_get_queue(struct net_device *dev,
  * that it holds on all queues and safely set the pointer
  * from the queues to NULL.
  */
-void tap_del_queues(struct net_device *dev)
+void tap_del_queues(struct tap_dev *tap)
 {
-	struct macvlan_dev *vlan = netdev_priv(dev);
 	struct tap_queue *q, *tmp;
 
 	ASSERT_RTNL();
-	list_for_each_entry_safe(q, tmp, &vlan->queue_list, next) {
+	list_for_each_entry_safe(q, tmp, &tap->queue_list, next) {
 		list_del_init(&q->next);
-		RCU_INIT_POINTER(q->vlan, NULL);
+		RCU_INIT_POINTER(q->tap, NULL);
 		if (q->enabled)
-			vlan->numvtaps--;
-		vlan->numqueues--;
+			tap->numvtaps--;
+		tap->numqueues--;
 		sock_put(&q->sk);
 	}
-	BUG_ON(vlan->numvtaps);
-	BUG_ON(vlan->numqueues);
+	BUG_ON(tap->numvtaps);
+	BUG_ON(tap->numqueues);
 	/* guarantee that any future tap_set_queue will fail */
-	vlan->numvtaps = MAX_TAP_QUEUES;
+	tap->numvtaps = MAX_TAP_QUEUES;
 }
 
 rx_handler_result_t tap_handle_frame(struct sk_buff **pskb)
 {
 	struct sk_buff *skb = *pskb;
 	struct net_device *dev = skb->dev;
-	struct macvlan_dev *vlan;
+	struct tap_dev *tap;
 	struct tap_queue *q;
 	netdev_features_t features = TAP_FEATURES;
 
-	vlan = tap_get_vlan_rcu(dev);
-	if (!vlan)
+	tap = tap_dev_get_rcu(dev);
+	if (!tap)
 		return RX_HANDLER_PASS;
 
-	q = tap_get_queue(dev, skb);
+	q = tap_get_queue(tap, skb);
 	if (!q)
 		return RX_HANDLER_PASS;
 
@@ -363,7 +334,7 @@ rx_handler_result_t tap_handle_frame(struct sk_buff **pskb)
 	 * enabled.
 	 */
 	if (q->flags & IFF_VNET_HDR)
-		features |= vlan->tap_features;
+		features |= tap->tap_features;
 	if (netif_needs_gso(skb, features)) {
 		struct sk_buff *segs = __skb_gso_segment(skb, features, false);
 
@@ -408,50 +379,51 @@ rx_handler_result_t tap_handle_frame(struct sk_buff **pskb)
 
 drop:
 	/* Count errors/drops only here, thus don't care about args. */
-	macvlan_count_rx(vlan, 0, 0, 0);
+	if (tap->count_rx_dropped)
+		tap->count_rx_dropped(tap);
 	kfree_skb(skb);
 	return RX_HANDLER_CONSUMED;
 }
 
-int tap_get_minor(struct macvlan_dev *vlan)
+int tap_get_minor(struct tap_dev *tap)
 {
 	int retval = -ENOMEM;
 
 	mutex_lock(&macvtap_major.minor_lock);
-	retval = idr_alloc(&macvtap_major.minor_idr, vlan, 1, TAP_NUM_DEVS, GFP_KERNEL);
+	retval = idr_alloc(&macvtap_major.minor_idr, tap, 1, TAP_NUM_DEVS, GFP_KERNEL);
 	if (retval >= 0) {
-		vlan->minor = retval;
+		tap->minor = retval;
 	} else if (retval == -ENOSPC) {
-		netdev_err(vlan->dev, "Too many tap devices\n");
+		netdev_err(tap->dev, "Too many tap devices\n");
 		retval = -EINVAL;
 	}
 	mutex_unlock(&macvtap_major.minor_lock);
 	return retval < 0 ? retval : 0;
 }
 
-void tap_free_minor(struct macvlan_dev *vlan)
+void tap_free_minor(struct tap_dev *tap)
 {
 	mutex_lock(&macvtap_major.minor_lock);
-	if (vlan->minor) {
-		idr_remove(&macvtap_major.minor_idr, vlan->minor);
-		vlan->minor = 0;
+	if (tap->minor) {
+		idr_remove(&macvtap_major.minor_idr, tap->minor);
+		tap->minor = 0;
 	}
 	mutex_unlock(&macvtap_major.minor_lock);
 }
 
-static struct net_device *dev_get_by_tap_minor(int minor)
+static struct tap_dev *dev_get_by_tap_minor(int minor)
 {
 	struct net_device *dev = NULL;
-	struct macvlan_dev *vlan;
+	struct tap_dev *tap;
 
 	mutex_lock(&macvtap_major.minor_lock);
-	vlan = idr_find(&macvtap_major.minor_idr, minor);
-	if (vlan) {
-		dev = vlan->dev;
+	tap = idr_find(&macvtap_major.minor_idr, minor);
+	if (tap) {
+		dev = tap->dev;
 		dev_hold(dev);
 	}
 	mutex_unlock(&macvtap_major.minor_lock);
-	return dev;
+	return tap;
 }
 
 static void tap_sock_write_space(struct sock *sk)
@@ -477,13 +449,13 @@ static void tap_sock_destruct(struct sock *sk)
 static int tap_open(struct inode *inode, struct file *file)
 {
 	struct net *net = current->nsproxy->net_ns;
-	struct net_device *dev;
+	struct tap_dev *tap;
 	struct tap_queue *q;
 	int err = -ENODEV;
 
 	rtnl_lock();
-	dev = dev_get_by_tap_minor(iminor(inode));
-	if (!dev)
+	tap = dev_get_by_tap_minor(iminor(inode));
+	if (!tap)
 		goto err;
 
 	err = -ENOMEM;
@@ -511,18 +483,18 @@ static int tap_open(struct inode *inode, struct file *file)
 	 * The macvlan supports zerocopy iff the lower device supports zero
 	 * copy so we don't have to look at the lower device directly.
 	 */
-	if ((dev->features & NETIF_F_HIGHDMA) && (dev->features & NETIF_F_SG))
+	if ((tap->dev->features & NETIF_F_HIGHDMA) && (tap->dev->features & NETIF_F_SG))
 		sock_set_flag(&q->sk, SOCK_ZEROCOPY);
 
 	err = -ENOMEM;
-	if (skb_array_init(&q->skb_array, dev->tx_queue_len, GFP_KERNEL))
+	if (skb_array_init(&q->skb_array, tap->dev->tx_queue_len, GFP_KERNEL))
 		goto err_array;
 
-	err = tap_set_queue(dev, file, q);
+	err = tap_set_queue(tap, file, q);
 	if (err)
 		goto err_queue;
 
-	dev_put(dev);
+	dev_put(tap->dev);
 
 	rtnl_unlock();
 	return err;
@@ -532,8 +504,8 @@ static int tap_open(struct inode *inode, struct file *file)
 err_array:
 	sock_put(&q->sk);
 err:
-	if (dev)
-		dev_put(dev);
+	if (tap)
+		dev_put(tap->dev);
 
 	rtnl_unlock();
 	return err;
@@ -601,7 +573,7 @@ static ssize_t tap_get_user(struct tap_queue *q, struct msghdr *m,
 {
 	int good_linear = SKB_MAX_HEAD(TAP_RESERVE);
 	struct sk_buff *skb;
-	struct macvlan_dev *vlan;
+	struct tap_dev *tap;
 	unsigned long total_len = iov_iter_count(from);
 	unsigned long len = total_len;
 	int err;
@@ -698,7 +670,7 @@ static ssize_t tap_get_user(struct tap_queue *q, struct msghdr *m,
 		skb_set_network_header(skb, depth);
 
 	rcu_read_lock();
-	vlan = rcu_dereference(q->vlan);
+	tap = rcu_dereference(q->tap);
 	/* copy skb_ubuf_info for callback when skb has no error */
 	if (zerocopy) {
 		skb_shinfo(skb)->destructor_arg = m->msg_control;
@@ -709,8 +681,8 @@ static ssize_t tap_get_user(struct tap_queue *q, struct msghdr *m,
 		uarg->callback(uarg, false);
 	}
 
-	if (vlan) {
-		skb->dev = vlan->dev;
+	if (tap) {
+		skb->dev = tap->dev;
 		dev_queue_xmit(skb);
 	} else {
 		kfree_skb(skb);
@@ -724,9 +696,9 @@ static ssize_t tap_get_user(struct tap_queue *q, struct msghdr *m,
 
 err:
 	rcu_read_lock();
-	vlan = rcu_dereference(q->vlan);
-	if (vlan)
-		this_cpu_inc(vlan->pcpu_stats->tx_dropped);
+	tap = rcu_dereference(q->tap);
+	if (tap && tap->count_tx_dropped)
+		tap->count_tx_dropped(tap);
 	rcu_read_unlock();
 
 	return err;
@@ -853,55 +825,55 @@ static ssize_t tap_read_iter(struct kiocb *iocb, struct iov_iter *to)
 	return ret;
 }
 
-static struct macvlan_dev *tap_get_vlan(struct tap_queue *q)
+static struct tap_dev *tap_get_tap_dev(struct tap_queue *q)
 {
-	struct macvlan_dev *vlan;
+	struct tap_dev *tap;
 
 	ASSERT_RTNL();
-	vlan = rtnl_dereference(q->vlan);
-	if (vlan)
-		dev_hold(vlan->dev);
+	tap = rtnl_dereference(q->tap);
+	if (tap)
+		dev_hold(tap->dev);
 
-	return vlan;
+	return tap;
 }
 
-static void tap_put_vlan(struct macvlan_dev *vlan)
+static void tap_put_tap_dev(struct tap_dev *tap)
 {
-	dev_put(vlan->dev);
+	dev_put(tap->dev);
 }
 
 static int tap_ioctl_set_queue(struct file *file, unsigned int flags)
 {
 	struct tap_queue *q = file->private_data;
-	struct macvlan_dev *vlan;
+	struct tap_dev *tap;
 	int ret;
 
-	vlan = tap_get_vlan(q);
-	if (!vlan)
+	tap = tap_get_tap_dev(q);
+	if (!tap)
 		return -EINVAL;
 
 	if (flags & IFF_ATTACH_QUEUE)
-		ret = tap_enable_queue(vlan->dev, file, q);
+		ret = tap_enable_queue(tap, file, q);
 	else if (flags & IFF_DETACH_QUEUE)
 		ret = tap_disable_queue(q);
 	else
 		ret = -EINVAL;
 
-	tap_put_vlan(vlan);
+	tap_put_tap_dev(tap);
 	return ret;
 }
 
 static int set_offload(struct tap_queue *q, unsigned long arg)
 {
-	struct macvlan_dev *vlan;
+	struct tap_dev *tap;
 	netdev_features_t features;
 	netdev_features_t feature_mask = 0;
 
-	vlan = rtnl_dereference(q->vlan);
-	if (!vlan)
+	tap = rtnl_dereference(q->tap);
+	if (!tap)
 		return -ENOLINK;
 
-	features = vlan->dev->features;
+	features = tap->dev->features;
 
 	if (arg & TUN_F_CSUM) {
 		feature_mask = NETIF_F_HW_CSUM;
@@ -935,9 +907,9 @@ static int set_offload(struct tap_queue *q, unsigned long arg)
 	/* tap_features are the same as features on tun/tap and
 	 * reflect user expectations.
 	 */
-	vlan->tap_features = feature_mask;
-	vlan->set_features = features;
-	netdev_update_features(vlan->dev);
+	tap->tap_features = feature_mask;
+	if (tap->update_features)
+		tap->update_features(tap, features);
 
 	return 0;
 }
@@ -949,7 +921,7 @@ static long tap_ioctl(struct file *file, unsigned int cmd,
 		      unsigned long arg)
 {
 	struct tap_queue *q = file->private_data;
-	struct macvlan_dev *vlan;
+	struct tap_dev *tap;
 	void __user *argp = (void __user *)arg;
 	struct ifreq __user *ifr = argp;
 	unsigned int __user *up = argp;
@@ -975,18 +947,18 @@ static long tap_ioctl(struct file *file, unsigned int cmd,
 
 	case TUNGETIFF:
 		rtnl_lock();
-		vlan = tap_get_vlan(q);
-		if (!vlan) {
+		tap = tap_get_tap_dev(q);
+		if (!tap) {
 			rtnl_unlock();
 			return -ENOLINK;
 		}
 
 		ret = 0;
 		u = q->flags;
-		if (copy_to_user(&ifr->ifr_name, vlan->dev->name, IFNAMSIZ) ||
+		if (copy_to_user(&ifr->ifr_name, tap->dev->name, IFNAMSIZ) ||
 		    put_user(u, &ifr->ifr_flags))
 			ret = -EFAULT;
-		tap_put_vlan(vlan);
+		tap_put_tap_dev(tap);
 		rtnl_unlock();
 		return ret;
 
@@ -1059,18 +1031,18 @@ static long tap_ioctl(struct file *file, unsigned int cmd,
 
 	case SIOCGIFHWADDR:
 		rtnl_lock();
-		vlan = tap_get_vlan(q);
-		if (!vlan) {
+		tap = tap_get_tap_dev(q);
+		if (!tap) {
 			rtnl_unlock();
 			return -ENOLINK;
 		}
 		ret = 0;
-		u = vlan->dev->type;
-		if (copy_to_user(&ifr->ifr_name, vlan->dev->name, IFNAMSIZ) ||
-		    copy_to_user(&ifr->ifr_hwaddr.sa_data, vlan->dev->dev_addr, ETH_ALEN) ||
+		u = tap->dev->type;
+		if (copy_to_user(&ifr->ifr_name, tap->dev->name, IFNAMSIZ) ||
+		    copy_to_user(&ifr->ifr_hwaddr.sa_data, tap->dev->dev_addr, ETH_ALEN) ||
 		    put_user(u, &ifr->ifr_hwaddr.sa_family))
 			ret = -EFAULT;
-		tap_put_vlan(vlan);
+		tap_put_tap_dev(tap);
 		rtnl_unlock();
 		return ret;
 
@@ -1078,13 +1050,13 @@ static long tap_ioctl(struct file *file, unsigned int cmd,
 		if (copy_from_user(&sa, &ifr->ifr_hwaddr, sizeof(sa)))
 			return -EFAULT;
 		rtnl_lock();
-		vlan = tap_get_vlan(q);
-		if (!vlan) {
+		tap = tap_get_tap_dev(q);
+		if (!tap) {
 			rtnl_unlock();
 			return -ENOLINK;
 		}
-		ret = dev_set_mac_address(vlan->dev, &sa);
-		tap_put_vlan(vlan);
+		ret = dev_set_mac_address(tap->dev, &sa);
+		tap_put_tap_dev(tap);
 		rtnl_unlock();
 		return ret;
 
@@ -1167,19 +1139,19 @@ struct socket *tap_get_socket(struct file *file)
 }
 EXPORT_SYMBOL_GPL(tap_get_socket);
 
-int tap_queue_resize(struct macvlan_dev *vlan)
+int tap_queue_resize(struct tap_dev *tap)
 {
-	struct net_device *dev = vlan->dev;
+	struct net_device *dev = tap->dev;
 	struct tap_queue *q;
 	struct skb_array **arrays;
-	int n = vlan->numqueues;
+	int n = tap->numqueues;
 	int ret, i = 0;
 
 	arrays = kmalloc(sizeof *arrays * n, GFP_KERNEL);
 	if (!arrays)
 		return -ENOMEM;
 
-	list_for_each_entry(q, &vlan->queue_list, next)
+	list_for_each_entry(q, &tap->queue_list, next)
 		arrays[i++] = &q->skb_array;
 
 	ret = skb_array_resize_multiple(arrays, n,

commit ebc05ba7e8600b52a2a0c87a43105143368aca2a
Author: Sainath Grandhi <sainath.grandhi@intel.com>
Date:   Fri Feb 10 16:03:48 2017 -0800

    tap: Tap character device creation/destroy API
    
    This patch provides tap device create/destroy APIs in tap.c.
    
    Signed-off-by: Sainath Grandhi <sainath.grandhi@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 15ca2d531d05..04ba9782c2f3 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -123,8 +123,12 @@ static struct proto tap_proto = {
 };
 
 #define TAP_NUM_DEVS (1U << MINORBITS)
-static DEFINE_MUTEX(minor_lock);
-DEFINE_IDR(minor_idr);
+struct major_info {
+	dev_t major;
+	struct idr minor_idr;
+	struct mutex minor_lock;
+	const char *device_name;
+} macvtap_major;
 
 #define GOODCOPY_LEN 128
 
@@ -413,26 +417,26 @@ int tap_get_minor(struct macvlan_dev *vlan)
 {
 	int retval = -ENOMEM;
 
-	mutex_lock(&minor_lock);
-	retval = idr_alloc(&minor_idr, vlan, 1, TAP_NUM_DEVS, GFP_KERNEL);
+	mutex_lock(&macvtap_major.minor_lock);
+	retval = idr_alloc(&macvtap_major.minor_idr, vlan, 1, TAP_NUM_DEVS, GFP_KERNEL);
 	if (retval >= 0) {
 		vlan->minor = retval;
 	} else if (retval == -ENOSPC) {
 		netdev_err(vlan->dev, "Too many tap devices\n");
 		retval = -EINVAL;
 	}
-	mutex_unlock(&minor_lock);
+	mutex_unlock(&macvtap_major.minor_lock);
 	return retval < 0 ? retval : 0;
 }
 
 void tap_free_minor(struct macvlan_dev *vlan)
 {
-	mutex_lock(&minor_lock);
+	mutex_lock(&macvtap_major.minor_lock);
 	if (vlan->minor) {
-		idr_remove(&minor_idr, vlan->minor);
+		idr_remove(&macvtap_major.minor_idr, vlan->minor);
 		vlan->minor = 0;
 	}
-	mutex_unlock(&minor_lock);
+	mutex_unlock(&macvtap_major.minor_lock);
 }
 
 static struct net_device *dev_get_by_tap_minor(int minor)
@@ -440,13 +444,13 @@ static struct net_device *dev_get_by_tap_minor(int minor)
 	struct net_device *dev = NULL;
 	struct macvlan_dev *vlan;
 
-	mutex_lock(&minor_lock);
-	vlan = idr_find(&minor_idr, minor);
+	mutex_lock(&macvtap_major.minor_lock);
+	vlan = idr_find(&macvtap_major.minor_idr, minor);
 	if (vlan) {
 		dev = vlan->dev;
 		dev_hold(dev);
 	}
-	mutex_unlock(&minor_lock);
+	mutex_unlock(&macvtap_major.minor_lock);
 	return dev;
 }
 
@@ -1184,3 +1188,39 @@ int tap_queue_resize(struct macvlan_dev *vlan)
 	kfree(arrays);
 	return ret;
 }
+
+int tap_create_cdev(struct cdev *tap_cdev,
+		    dev_t *tap_major, const char *device_name)
+{
+	int err;
+
+	err = alloc_chrdev_region(tap_major, 0, TAP_NUM_DEVS, device_name);
+	if (err)
+		goto out1;
+
+	cdev_init(tap_cdev, &tap_fops);
+	err = cdev_add(tap_cdev, *tap_major, TAP_NUM_DEVS);
+	if (err)
+		goto out2;
+
+	macvtap_major.major = MAJOR(*tap_major);
+
+	idr_init(&macvtap_major.minor_idr);
+	mutex_init(&macvtap_major.minor_lock);
+
+	macvtap_major.device_name = device_name;
+
+	return 0;
+
+out2:
+	unregister_chrdev_region(*tap_major, TAP_NUM_DEVS);
+out1:
+	return err;
+}
+
+void tap_destroy_cdev(dev_t major, struct cdev *tap_cdev)
+{
+	cdev_del(tap_cdev);
+	unregister_chrdev_region(major, TAP_NUM_DEVS);
+	idr_destroy(&macvtap_major.minor_idr);
+}

commit 635b8c8ecdd27142d7fdab0df334b2e9201481cf
Author: Sainath Grandhi <sainath.grandhi@intel.com>
Date:   Fri Feb 10 16:03:47 2017 -0800

    tap: Renaming tap related APIs, data structures, macros
    
    Renaming tap related APIs, data structures and macros in tap.c from macvtap_.* to tap_.*
    
    Signed-off-by: Sainath Grandhi <sainath.grandhi@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index 6f6228e4fd3f..15ca2d531d05 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -24,16 +24,16 @@
 #include <linux/skb_array.h>
 
 /*
- * A macvtap queue is the central object of this driver, it connects
+ * A tap queue is the central object of this driver, it connects
  * an open character device to a macvlan interface. There can be
  * multiple queues on one interface, which map back to queues
  * implemented in hardware on the underlying device.
  *
- * macvtap_proto is used to allocate queues through the sock allocation
+ * tap_proto is used to allocate queues through the sock allocation
  * mechanism.
  *
  */
-struct macvtap_queue {
+struct tap_queue {
 	struct sock sk;
 	struct socket sock;
 	struct socket_wq wq;
@@ -47,21 +47,21 @@ struct macvtap_queue {
 	struct skb_array skb_array;
 };
 
-#define MACVTAP_FEATURES (IFF_VNET_HDR | IFF_MULTI_QUEUE)
+#define TAP_IFFEATURES (IFF_VNET_HDR | IFF_MULTI_QUEUE)
 
-#define MACVTAP_VNET_LE 0x80000000
-#define MACVTAP_VNET_BE 0x40000000
+#define TAP_VNET_LE 0x80000000
+#define TAP_VNET_BE 0x40000000
 
 #ifdef CONFIG_TUN_VNET_CROSS_LE
-static inline bool macvtap_legacy_is_little_endian(struct macvtap_queue *q)
+static inline bool tap_legacy_is_little_endian(struct tap_queue *q)
 {
-	return q->flags & MACVTAP_VNET_BE ? false :
+	return q->flags & TAP_VNET_BE ? false :
 		virtio_legacy_is_little_endian();
 }
 
-static long macvtap_get_vnet_be(struct macvtap_queue *q, int __user *sp)
+static long tap_get_vnet_be(struct tap_queue *q, int __user *sp)
 {
-	int s = !!(q->flags & MACVTAP_VNET_BE);
+	int s = !!(q->flags & TAP_VNET_BE);
 
 	if (put_user(s, sp))
 		return -EFAULT;
@@ -69,7 +69,7 @@ static long macvtap_get_vnet_be(struct macvtap_queue *q, int __user *sp)
 	return 0;
 }
 
-static long macvtap_set_vnet_be(struct macvtap_queue *q, int __user *sp)
+static long tap_set_vnet_be(struct tap_queue *q, int __user *sp)
 {
 	int s;
 
@@ -77,77 +77,77 @@ static long macvtap_set_vnet_be(struct macvtap_queue *q, int __user *sp)
 		return -EFAULT;
 
 	if (s)
-		q->flags |= MACVTAP_VNET_BE;
+		q->flags |= TAP_VNET_BE;
 	else
-		q->flags &= ~MACVTAP_VNET_BE;
+		q->flags &= ~TAP_VNET_BE;
 
 	return 0;
 }
 #else
-static inline bool macvtap_legacy_is_little_endian(struct macvtap_queue *q)
+static inline bool tap_legacy_is_little_endian(struct tap_queue *q)
 {
 	return virtio_legacy_is_little_endian();
 }
 
-static long macvtap_get_vnet_be(struct macvtap_queue *q, int __user *argp)
+static long tap_get_vnet_be(struct tap_queue *q, int __user *argp)
 {
 	return -EINVAL;
 }
 
-static long macvtap_set_vnet_be(struct macvtap_queue *q, int __user *argp)
+static long tap_set_vnet_be(struct tap_queue *q, int __user *argp)
 {
 	return -EINVAL;
 }
 #endif /* CONFIG_TUN_VNET_CROSS_LE */
 
-static inline bool macvtap_is_little_endian(struct macvtap_queue *q)
+static inline bool tap_is_little_endian(struct tap_queue *q)
 {
-	return q->flags & MACVTAP_VNET_LE ||
-		macvtap_legacy_is_little_endian(q);
+	return q->flags & TAP_VNET_LE ||
+		tap_legacy_is_little_endian(q);
 }
 
-static inline u16 macvtap16_to_cpu(struct macvtap_queue *q, __virtio16 val)
+static inline u16 tap16_to_cpu(struct tap_queue *q, __virtio16 val)
 {
-	return __virtio16_to_cpu(macvtap_is_little_endian(q), val);
+	return __virtio16_to_cpu(tap_is_little_endian(q), val);
 }
 
-static inline __virtio16 cpu_to_macvtap16(struct macvtap_queue *q, u16 val)
+static inline __virtio16 cpu_to_tap16(struct tap_queue *q, u16 val)
 {
-	return __cpu_to_virtio16(macvtap_is_little_endian(q), val);
+	return __cpu_to_virtio16(tap_is_little_endian(q), val);
 }
 
-static struct proto macvtap_proto = {
-	.name = "macvtap",
+static struct proto tap_proto = {
+	.name = "tap",
 	.owner = THIS_MODULE,
-	.obj_size = sizeof (struct macvtap_queue),
+	.obj_size = sizeof(struct tap_queue),
 };
 
-#define MACVTAP_NUM_DEVS (1U << MINORBITS)
+#define TAP_NUM_DEVS (1U << MINORBITS)
 static DEFINE_MUTEX(minor_lock);
 DEFINE_IDR(minor_idr);
 
 #define GOODCOPY_LEN 128
 
-static const struct proto_ops macvtap_socket_ops;
+static const struct proto_ops tap_socket_ops;
 
 #define RX_OFFLOADS (NETIF_F_GRO | NETIF_F_LRO)
 #define TAP_FEATURES (NETIF_F_GSO | NETIF_F_SG | NETIF_F_FRAGLIST)
 
-static struct macvlan_dev *macvtap_get_vlan_rcu(const struct net_device *dev)
+static struct macvlan_dev *tap_get_vlan_rcu(const struct net_device *dev)
 {
 	return rcu_dereference(dev->rx_handler_data);
 }
 
 /*
  * RCU usage:
- * The macvtap_queue and the macvlan_dev are loosely coupled, the
+ * The tap_queue and the macvlan_dev are loosely coupled, the
  * pointers from one to the other can only be read while rcu_read_lock
  * or rtnl is held.
  *
- * Both the file and the macvlan_dev hold a reference on the macvtap_queue
+ * Both the file and the macvlan_dev hold a reference on the tap_queue
  * through sock_hold(&q->sk). When the macvlan_dev goes away first,
  * q->vlan becomes inaccessible. When the files gets closed,
- * macvtap_get_queue() fails.
+ * tap_get_queue() fails.
  *
  * There may still be references to the struct sock inside of the
  * queue from outbound SKBs, but these never reference back to the
@@ -155,8 +155,8 @@ static struct macvlan_dev *macvtap_get_vlan_rcu(const struct net_device *dev)
  * when both our references and any pending SKBs are gone.
  */
 
-static int macvtap_enable_queue(struct net_device *dev, struct file *file,
-				struct macvtap_queue *q)
+static int tap_enable_queue(struct net_device *dev, struct file *file,
+			    struct tap_queue *q)
 {
 	struct macvlan_dev *vlan = netdev_priv(dev);
 	int err = -EINVAL;
@@ -177,12 +177,12 @@ static int macvtap_enable_queue(struct net_device *dev, struct file *file,
 }
 
 /* Requires RTNL */
-static int macvtap_set_queue(struct net_device *dev, struct file *file,
-			     struct macvtap_queue *q)
+static int tap_set_queue(struct net_device *dev, struct file *file,
+			 struct tap_queue *q)
 {
 	struct macvlan_dev *vlan = netdev_priv(dev);
 
-	if (vlan->numqueues == MAX_MACVTAP_QUEUES)
+	if (vlan->numqueues == MAX_TAP_QUEUES)
 		return -EBUSY;
 
 	rcu_assign_pointer(q->vlan, vlan);
@@ -201,10 +201,10 @@ static int macvtap_set_queue(struct net_device *dev, struct file *file,
 	return 0;
 }
 
-static int macvtap_disable_queue(struct macvtap_queue *q)
+static int tap_disable_queue(struct tap_queue *q)
 {
 	struct macvlan_dev *vlan;
-	struct macvtap_queue *nq;
+	struct tap_queue *nq;
 
 	ASSERT_RTNL();
 	if (!q->enabled)
@@ -236,7 +236,7 @@ static int macvtap_disable_queue(struct macvtap_queue *q)
  * Using the spinlock makes sure that we don't get
  * to the queue again after destroying it.
  */
-static void macvtap_put_queue(struct macvtap_queue *q)
+static void tap_put_queue(struct tap_queue *q)
 {
 	struct macvlan_dev *vlan;
 
@@ -245,7 +245,7 @@ static void macvtap_put_queue(struct macvtap_queue *q)
 
 	if (vlan) {
 		if (q->enabled)
-			BUG_ON(macvtap_disable_queue(q));
+			BUG_ON(tap_disable_queue(q));
 
 		vlan->numqueues--;
 		RCU_INIT_POINTER(q->vlan, NULL);
@@ -266,11 +266,11 @@ static void macvtap_put_queue(struct macvtap_queue *q)
  * Cache vlan->numvtaps since it can become zero during the execution
  * of this function.
  */
-static struct macvtap_queue *macvtap_get_queue(struct net_device *dev,
-					       struct sk_buff *skb)
+static struct tap_queue *tap_get_queue(struct net_device *dev,
+				       struct sk_buff *skb)
 {
 	struct macvlan_dev *vlan = netdev_priv(dev);
-	struct macvtap_queue *tap = NULL;
+	struct tap_queue *tap = NULL;
 	/* Access to taps array is protected by rcu, but access to numvtaps
 	 * isn't. Below we use it to lookup a queue, but treat it as a hint
 	 * and validate that the result isn't NULL - in case we are
@@ -313,10 +313,10 @@ static struct macvtap_queue *macvtap_get_queue(struct net_device *dev,
  * that it holds on all queues and safely set the pointer
  * from the queues to NULL.
  */
-void macvtap_del_queues(struct net_device *dev)
+void tap_del_queues(struct net_device *dev)
 {
 	struct macvlan_dev *vlan = netdev_priv(dev);
-	struct macvtap_queue *q, *tmp;
+	struct tap_queue *q, *tmp;
 
 	ASSERT_RTNL();
 	list_for_each_entry_safe(q, tmp, &vlan->queue_list, next) {
@@ -329,23 +329,23 @@ void macvtap_del_queues(struct net_device *dev)
 	}
 	BUG_ON(vlan->numvtaps);
 	BUG_ON(vlan->numqueues);
-	/* guarantee that any future macvtap_set_queue will fail */
-	vlan->numvtaps = MAX_MACVTAP_QUEUES;
+	/* guarantee that any future tap_set_queue will fail */
+	vlan->numvtaps = MAX_TAP_QUEUES;
 }
 
-rx_handler_result_t macvtap_handle_frame(struct sk_buff **pskb)
+rx_handler_result_t tap_handle_frame(struct sk_buff **pskb)
 {
 	struct sk_buff *skb = *pskb;
 	struct net_device *dev = skb->dev;
 	struct macvlan_dev *vlan;
-	struct macvtap_queue *q;
+	struct tap_queue *q;
 	netdev_features_t features = TAP_FEATURES;
 
-	vlan = macvtap_get_vlan_rcu(dev);
+	vlan = tap_get_vlan_rcu(dev);
 	if (!vlan)
 		return RX_HANDLER_PASS;
 
-	q = macvtap_get_queue(dev, skb);
+	q = tap_get_queue(dev, skb);
 	if (!q)
 		return RX_HANDLER_PASS;
 
@@ -409,23 +409,23 @@ rx_handler_result_t macvtap_handle_frame(struct sk_buff **pskb)
 	return RX_HANDLER_CONSUMED;
 }
 
-int macvtap_get_minor(struct macvlan_dev *vlan)
+int tap_get_minor(struct macvlan_dev *vlan)
 {
 	int retval = -ENOMEM;
 
 	mutex_lock(&minor_lock);
-	retval = idr_alloc(&minor_idr, vlan, 1, MACVTAP_NUM_DEVS, GFP_KERNEL);
+	retval = idr_alloc(&minor_idr, vlan, 1, TAP_NUM_DEVS, GFP_KERNEL);
 	if (retval >= 0) {
 		vlan->minor = retval;
 	} else if (retval == -ENOSPC) {
-		netdev_err(vlan->dev, "Too many macvtap devices\n");
+		netdev_err(vlan->dev, "Too many tap devices\n");
 		retval = -EINVAL;
 	}
 	mutex_unlock(&minor_lock);
 	return retval < 0 ? retval : 0;
 }
 
-void macvtap_free_minor(struct macvlan_dev *vlan)
+void tap_free_minor(struct macvlan_dev *vlan)
 {
 	mutex_lock(&minor_lock);
 	if (vlan->minor) {
@@ -435,7 +435,7 @@ void macvtap_free_minor(struct macvlan_dev *vlan)
 	mutex_unlock(&minor_lock);
 }
 
-static struct net_device *dev_get_by_macvtap_minor(int minor)
+static struct net_device *dev_get_by_tap_minor(int minor)
 {
 	struct net_device *dev = NULL;
 	struct macvlan_dev *vlan;
@@ -450,7 +450,7 @@ static struct net_device *dev_get_by_macvtap_minor(int minor)
 	return dev;
 }
 
-static void macvtap_sock_write_space(struct sock *sk)
+static void tap_sock_write_space(struct sock *sk)
 {
 	wait_queue_head_t *wqueue;
 
@@ -463,28 +463,28 @@ static void macvtap_sock_write_space(struct sock *sk)
 		wake_up_interruptible_poll(wqueue, POLLOUT | POLLWRNORM | POLLWRBAND);
 }
 
-static void macvtap_sock_destruct(struct sock *sk)
+static void tap_sock_destruct(struct sock *sk)
 {
-	struct macvtap_queue *q = container_of(sk, struct macvtap_queue, sk);
+	struct tap_queue *q = container_of(sk, struct tap_queue, sk);
 
 	skb_array_cleanup(&q->skb_array);
 }
 
-static int macvtap_open(struct inode *inode, struct file *file)
+static int tap_open(struct inode *inode, struct file *file)
 {
 	struct net *net = current->nsproxy->net_ns;
 	struct net_device *dev;
-	struct macvtap_queue *q;
+	struct tap_queue *q;
 	int err = -ENODEV;
 
 	rtnl_lock();
-	dev = dev_get_by_macvtap_minor(iminor(inode));
+	dev = dev_get_by_tap_minor(iminor(inode));
 	if (!dev)
 		goto err;
 
 	err = -ENOMEM;
-	q = (struct macvtap_queue *)sk_alloc(net, AF_UNSPEC, GFP_KERNEL,
-					     &macvtap_proto, 0);
+	q = (struct tap_queue *)sk_alloc(net, AF_UNSPEC, GFP_KERNEL,
+					     &tap_proto, 0);
 	if (!q)
 		goto err;
 
@@ -493,15 +493,15 @@ static int macvtap_open(struct inode *inode, struct file *file)
 	q->sock.type = SOCK_RAW;
 	q->sock.state = SS_CONNECTED;
 	q->sock.file = file;
-	q->sock.ops = &macvtap_socket_ops;
+	q->sock.ops = &tap_socket_ops;
 	sock_init_data(&q->sock, &q->sk);
-	q->sk.sk_write_space = macvtap_sock_write_space;
-	q->sk.sk_destruct = macvtap_sock_destruct;
+	q->sk.sk_write_space = tap_sock_write_space;
+	q->sk.sk_destruct = tap_sock_destruct;
 	q->flags = IFF_VNET_HDR | IFF_NO_PI | IFF_TAP;
 	q->vnet_hdr_sz = sizeof(struct virtio_net_hdr);
 
 	/*
-	 * so far only KVM virtio_net uses macvtap, enable zero copy between
+	 * so far only KVM virtio_net uses tap, enable zero copy between
 	 * guest kernel and host kernel when lower device supports zerocopy
 	 *
 	 * The macvlan supports zerocopy iff the lower device supports zero
@@ -514,7 +514,7 @@ static int macvtap_open(struct inode *inode, struct file *file)
 	if (skb_array_init(&q->skb_array, dev->tx_queue_len, GFP_KERNEL))
 		goto err_array;
 
-	err = macvtap_set_queue(dev, file, q);
+	err = tap_set_queue(dev, file, q);
 	if (err)
 		goto err_queue;
 
@@ -535,16 +535,16 @@ static int macvtap_open(struct inode *inode, struct file *file)
 	return err;
 }
 
-static int macvtap_release(struct inode *inode, struct file *file)
+static int tap_release(struct inode *inode, struct file *file)
 {
-	struct macvtap_queue *q = file->private_data;
-	macvtap_put_queue(q);
+	struct tap_queue *q = file->private_data;
+	tap_put_queue(q);
 	return 0;
 }
 
-static unsigned int macvtap_poll(struct file *file, poll_table * wait)
+static unsigned int tap_poll(struct file *file, poll_table *wait)
 {
-	struct macvtap_queue *q = file->private_data;
+	struct tap_queue *q = file->private_data;
 	unsigned int mask = POLLERR;
 
 	if (!q)
@@ -565,8 +565,8 @@ static unsigned int macvtap_poll(struct file *file, poll_table * wait)
 	return mask;
 }
 
-static inline struct sk_buff *macvtap_alloc_skb(struct sock *sk, size_t prepad,
-						size_t len, size_t linear,
+static inline struct sk_buff *tap_alloc_skb(struct sock *sk, size_t prepad,
+					    size_t len, size_t linear,
 						int noblock, int *err)
 {
 	struct sk_buff *skb;
@@ -589,13 +589,13 @@ static inline struct sk_buff *macvtap_alloc_skb(struct sock *sk, size_t prepad,
 }
 
 /* Neighbour code has some assumptions on HH_DATA_MOD alignment */
-#define MACVTAP_RESERVE HH_DATA_OFF(ETH_HLEN)
+#define TAP_RESERVE HH_DATA_OFF(ETH_HLEN)
 
 /* Get packet from user space buffer */
-static ssize_t macvtap_get_user(struct macvtap_queue *q, struct msghdr *m,
-				struct iov_iter *from, int noblock)
+static ssize_t tap_get_user(struct tap_queue *q, struct msghdr *m,
+			    struct iov_iter *from, int noblock)
 {
-	int good_linear = SKB_MAX_HEAD(MACVTAP_RESERVE);
+	int good_linear = SKB_MAX_HEAD(TAP_RESERVE);
 	struct sk_buff *skb;
 	struct macvlan_dev *vlan;
 	unsigned long total_len = iov_iter_count(from);
@@ -621,14 +621,14 @@ static ssize_t macvtap_get_user(struct macvtap_queue *q, struct msghdr *m,
 			goto err;
 		iov_iter_advance(from, vnet_hdr_len - sizeof(vnet_hdr));
 		if ((vnet_hdr.flags & VIRTIO_NET_HDR_F_NEEDS_CSUM) &&
-		     macvtap16_to_cpu(q, vnet_hdr.csum_start) +
-		     macvtap16_to_cpu(q, vnet_hdr.csum_offset) + 2 >
-			     macvtap16_to_cpu(q, vnet_hdr.hdr_len))
-			vnet_hdr.hdr_len = cpu_to_macvtap16(q,
-				 macvtap16_to_cpu(q, vnet_hdr.csum_start) +
-				 macvtap16_to_cpu(q, vnet_hdr.csum_offset) + 2);
+		     tap16_to_cpu(q, vnet_hdr.csum_start) +
+		     tap16_to_cpu(q, vnet_hdr.csum_offset) + 2 >
+			     tap16_to_cpu(q, vnet_hdr.hdr_len))
+			vnet_hdr.hdr_len = cpu_to_tap16(q,
+				 tap16_to_cpu(q, vnet_hdr.csum_start) +
+				 tap16_to_cpu(q, vnet_hdr.csum_offset) + 2);
 		err = -EINVAL;
-		if (macvtap16_to_cpu(q, vnet_hdr.hdr_len) > len)
+		if (tap16_to_cpu(q, vnet_hdr.hdr_len) > len)
 			goto err;
 	}
 
@@ -640,7 +640,7 @@ static ssize_t macvtap_get_user(struct macvtap_queue *q, struct msghdr *m,
 		struct iov_iter i;
 
 		copylen = vnet_hdr.hdr_len ?
-			macvtap16_to_cpu(q, vnet_hdr.hdr_len) : GOODCOPY_LEN;
+			tap16_to_cpu(q, vnet_hdr.hdr_len) : GOODCOPY_LEN;
 		if (copylen > good_linear)
 			copylen = good_linear;
 		else if (copylen < ETH_HLEN)
@@ -654,15 +654,15 @@ static ssize_t macvtap_get_user(struct macvtap_queue *q, struct msghdr *m,
 
 	if (!zerocopy) {
 		copylen = len;
-		linear = macvtap16_to_cpu(q, vnet_hdr.hdr_len);
+		linear = tap16_to_cpu(q, vnet_hdr.hdr_len);
 		if (linear > good_linear)
 			linear = good_linear;
 		else if (linear < ETH_HLEN)
 			linear = ETH_HLEN;
 	}
 
-	skb = macvtap_alloc_skb(&q->sk, MACVTAP_RESERVE, copylen,
-				linear, noblock, &err);
+	skb = tap_alloc_skb(&q->sk, TAP_RESERVE, copylen,
+			    linear, noblock, &err);
 	if (!skb)
 		goto err;
 
@@ -680,7 +680,7 @@ static ssize_t macvtap_get_user(struct macvtap_queue *q, struct msghdr *m,
 
 	if (vnet_hdr_len) {
 		err = virtio_net_hdr_to_skb(skb, &vnet_hdr,
-					    macvtap_is_little_endian(q));
+					    tap_is_little_endian(q));
 		if (err)
 			goto err_kfree;
 	}
@@ -728,18 +728,18 @@ static ssize_t macvtap_get_user(struct macvtap_queue *q, struct msghdr *m,
 	return err;
 }
 
-static ssize_t macvtap_write_iter(struct kiocb *iocb, struct iov_iter *from)
+static ssize_t tap_write_iter(struct kiocb *iocb, struct iov_iter *from)
 {
 	struct file *file = iocb->ki_filp;
-	struct macvtap_queue *q = file->private_data;
+	struct tap_queue *q = file->private_data;
 
-	return macvtap_get_user(q, NULL, from, file->f_flags & O_NONBLOCK);
+	return tap_get_user(q, NULL, from, file->f_flags & O_NONBLOCK);
 }
 
 /* Put packet to the user space buffer */
-static ssize_t macvtap_put_user(struct macvtap_queue *q,
-				const struct sk_buff *skb,
-				struct iov_iter *iter)
+static ssize_t tap_put_user(struct tap_queue *q,
+			    const struct sk_buff *skb,
+			    struct iov_iter *iter)
 {
 	int ret;
 	int vnet_hdr_len = 0;
@@ -753,7 +753,7 @@ static ssize_t macvtap_put_user(struct macvtap_queue *q,
 			return -EINVAL;
 
 		if (virtio_net_hdr_from_skb(skb, &vnet_hdr,
-					    macvtap_is_little_endian(q), true))
+					    tap_is_little_endian(q), true))
 			BUG();
 
 		if (copy_to_iter(&vnet_hdr, sizeof(vnet_hdr), iter) !=
@@ -792,9 +792,9 @@ static ssize_t macvtap_put_user(struct macvtap_queue *q,
 	return ret ? ret : total;
 }
 
-static ssize_t macvtap_do_read(struct macvtap_queue *q,
-			       struct iov_iter *to,
-			       int noblock)
+static ssize_t tap_do_read(struct tap_queue *q,
+			   struct iov_iter *to,
+			   int noblock)
 {
 	DEFINE_WAIT(wait);
 	struct sk_buff *skb;
@@ -827,7 +827,7 @@ static ssize_t macvtap_do_read(struct macvtap_queue *q,
 		finish_wait(sk_sleep(&q->sk), &wait);
 
 	if (skb) {
-		ret = macvtap_put_user(q, skb, to);
+		ret = tap_put_user(q, skb, to);
 		if (unlikely(ret < 0))
 			kfree_skb(skb);
 		else
@@ -836,20 +836,20 @@ static ssize_t macvtap_do_read(struct macvtap_queue *q,
 	return ret;
 }
 
-static ssize_t macvtap_read_iter(struct kiocb *iocb, struct iov_iter *to)
+static ssize_t tap_read_iter(struct kiocb *iocb, struct iov_iter *to)
 {
 	struct file *file = iocb->ki_filp;
-	struct macvtap_queue *q = file->private_data;
+	struct tap_queue *q = file->private_data;
 	ssize_t len = iov_iter_count(to), ret;
 
-	ret = macvtap_do_read(q, to, file->f_flags & O_NONBLOCK);
+	ret = tap_do_read(q, to, file->f_flags & O_NONBLOCK);
 	ret = min_t(ssize_t, ret, len);
 	if (ret > 0)
 		iocb->ki_pos = ret;
 	return ret;
 }
 
-static struct macvlan_dev *macvtap_get_vlan(struct macvtap_queue *q)
+static struct macvlan_dev *tap_get_vlan(struct tap_queue *q)
 {
 	struct macvlan_dev *vlan;
 
@@ -861,33 +861,33 @@ static struct macvlan_dev *macvtap_get_vlan(struct macvtap_queue *q)
 	return vlan;
 }
 
-static void macvtap_put_vlan(struct macvlan_dev *vlan)
+static void tap_put_vlan(struct macvlan_dev *vlan)
 {
 	dev_put(vlan->dev);
 }
 
-static int macvtap_ioctl_set_queue(struct file *file, unsigned int flags)
+static int tap_ioctl_set_queue(struct file *file, unsigned int flags)
 {
-	struct macvtap_queue *q = file->private_data;
+	struct tap_queue *q = file->private_data;
 	struct macvlan_dev *vlan;
 	int ret;
 
-	vlan = macvtap_get_vlan(q);
+	vlan = tap_get_vlan(q);
 	if (!vlan)
 		return -EINVAL;
 
 	if (flags & IFF_ATTACH_QUEUE)
-		ret = macvtap_enable_queue(vlan->dev, file, q);
+		ret = tap_enable_queue(vlan->dev, file, q);
 	else if (flags & IFF_DETACH_QUEUE)
-		ret = macvtap_disable_queue(q);
+		ret = tap_disable_queue(q);
 	else
 		ret = -EINVAL;
 
-	macvtap_put_vlan(vlan);
+	tap_put_vlan(vlan);
 	return ret;
 }
 
-static int set_offload(struct macvtap_queue *q, unsigned long arg)
+static int set_offload(struct tap_queue *q, unsigned long arg)
 {
 	struct macvlan_dev *vlan;
 	netdev_features_t features;
@@ -919,7 +919,7 @@ static int set_offload(struct macvtap_queue *q, unsigned long arg)
 	 * setting the TSO bit means that the userspace wants to
 	 * accept TSO frames and turning it off means that user space
 	 * does not support TSO.
-	 * For macvtap, we have to invert it to mean the same thing.
+	 * For tap, we have to invert it to mean the same thing.
 	 * When user space turns off TSO, we turn off GSO/LRO so that
 	 * user-space will not receive TSO frames.
 	 */
@@ -941,10 +941,10 @@ static int set_offload(struct macvtap_queue *q, unsigned long arg)
 /*
  * provide compatibility with generic tun/tap interface
  */
-static long macvtap_ioctl(struct file *file, unsigned int cmd,
-			  unsigned long arg)
+static long tap_ioctl(struct file *file, unsigned int cmd,
+		      unsigned long arg)
 {
-	struct macvtap_queue *q = file->private_data;
+	struct tap_queue *q = file->private_data;
 	struct macvlan_dev *vlan;
 	void __user *argp = (void __user *)arg;
 	struct ifreq __user *ifr = argp;
@@ -962,16 +962,16 @@ static long macvtap_ioctl(struct file *file, unsigned int cmd,
 			return -EFAULT;
 
 		ret = 0;
-		if ((u & ~MACVTAP_FEATURES) != (IFF_NO_PI | IFF_TAP))
+		if ((u & ~TAP_IFFEATURES) != (IFF_NO_PI | IFF_TAP))
 			ret = -EINVAL;
 		else
-			q->flags = (q->flags & ~MACVTAP_FEATURES) | u;
+			q->flags = (q->flags & ~TAP_IFFEATURES) | u;
 
 		return ret;
 
 	case TUNGETIFF:
 		rtnl_lock();
-		vlan = macvtap_get_vlan(q);
+		vlan = tap_get_vlan(q);
 		if (!vlan) {
 			rtnl_unlock();
 			return -ENOLINK;
@@ -982,7 +982,7 @@ static long macvtap_ioctl(struct file *file, unsigned int cmd,
 		if (copy_to_user(&ifr->ifr_name, vlan->dev->name, IFNAMSIZ) ||
 		    put_user(u, &ifr->ifr_flags))
 			ret = -EFAULT;
-		macvtap_put_vlan(vlan);
+		tap_put_vlan(vlan);
 		rtnl_unlock();
 		return ret;
 
@@ -990,12 +990,12 @@ static long macvtap_ioctl(struct file *file, unsigned int cmd,
 		if (get_user(u, &ifr->ifr_flags))
 			return -EFAULT;
 		rtnl_lock();
-		ret = macvtap_ioctl_set_queue(file, u);
+		ret = tap_ioctl_set_queue(file, u);
 		rtnl_unlock();
 		return ret;
 
 	case TUNGETFEATURES:
-		if (put_user(IFF_TAP | IFF_NO_PI | MACVTAP_FEATURES, up))
+		if (put_user(IFF_TAP | IFF_NO_PI | TAP_IFFEATURES, up))
 			return -EFAULT;
 		return 0;
 
@@ -1022,7 +1022,7 @@ static long macvtap_ioctl(struct file *file, unsigned int cmd,
 		return 0;
 
 	case TUNGETVNETLE:
-		s = !!(q->flags & MACVTAP_VNET_LE);
+		s = !!(q->flags & TAP_VNET_LE);
 		if (put_user(s, sp))
 			return -EFAULT;
 		return 0;
@@ -1031,16 +1031,16 @@ static long macvtap_ioctl(struct file *file, unsigned int cmd,
 		if (get_user(s, sp))
 			return -EFAULT;
 		if (s)
-			q->flags |= MACVTAP_VNET_LE;
+			q->flags |= TAP_VNET_LE;
 		else
-			q->flags &= ~MACVTAP_VNET_LE;
+			q->flags &= ~TAP_VNET_LE;
 		return 0;
 
 	case TUNGETVNETBE:
-		return macvtap_get_vnet_be(q, sp);
+		return tap_get_vnet_be(q, sp);
 
 	case TUNSETVNETBE:
-		return macvtap_set_vnet_be(q, sp);
+		return tap_set_vnet_be(q, sp);
 
 	case TUNSETOFFLOAD:
 		/* let the user check for future flags */
@@ -1055,7 +1055,7 @@ static long macvtap_ioctl(struct file *file, unsigned int cmd,
 
 	case SIOCGIFHWADDR:
 		rtnl_lock();
-		vlan = macvtap_get_vlan(q);
+		vlan = tap_get_vlan(q);
 		if (!vlan) {
 			rtnl_unlock();
 			return -ENOLINK;
@@ -1066,7 +1066,7 @@ static long macvtap_ioctl(struct file *file, unsigned int cmd,
 		    copy_to_user(&ifr->ifr_hwaddr.sa_data, vlan->dev->dev_addr, ETH_ALEN) ||
 		    put_user(u, &ifr->ifr_hwaddr.sa_family))
 			ret = -EFAULT;
-		macvtap_put_vlan(vlan);
+		tap_put_vlan(vlan);
 		rtnl_unlock();
 		return ret;
 
@@ -1074,13 +1074,13 @@ static long macvtap_ioctl(struct file *file, unsigned int cmd,
 		if (copy_from_user(&sa, &ifr->ifr_hwaddr, sizeof(sa)))
 			return -EFAULT;
 		rtnl_lock();
-		vlan = macvtap_get_vlan(q);
+		vlan = tap_get_vlan(q);
 		if (!vlan) {
 			rtnl_unlock();
 			return -ENOLINK;
 		}
 		ret = dev_set_mac_address(vlan->dev, &sa);
-		macvtap_put_vlan(vlan);
+		tap_put_vlan(vlan);
 		rtnl_unlock();
 		return ret;
 
@@ -1090,42 +1090,42 @@ static long macvtap_ioctl(struct file *file, unsigned int cmd,
 }
 
 #ifdef CONFIG_COMPAT
-static long macvtap_compat_ioctl(struct file *file, unsigned int cmd,
-				 unsigned long arg)
+static long tap_compat_ioctl(struct file *file, unsigned int cmd,
+			     unsigned long arg)
 {
-	return macvtap_ioctl(file, cmd, (unsigned long)compat_ptr(arg));
+	return tap_ioctl(file, cmd, (unsigned long)compat_ptr(arg));
 }
 #endif
 
-const struct file_operations macvtap_fops = {
+const struct file_operations tap_fops = {
 	.owner		= THIS_MODULE,
-	.open		= macvtap_open,
-	.release	= macvtap_release,
-	.read_iter	= macvtap_read_iter,
-	.write_iter	= macvtap_write_iter,
-	.poll		= macvtap_poll,
+	.open		= tap_open,
+	.release	= tap_release,
+	.read_iter	= tap_read_iter,
+	.write_iter	= tap_write_iter,
+	.poll		= tap_poll,
 	.llseek		= no_llseek,
-	.unlocked_ioctl	= macvtap_ioctl,
+	.unlocked_ioctl	= tap_ioctl,
 #ifdef CONFIG_COMPAT
-	.compat_ioctl	= macvtap_compat_ioctl,
+	.compat_ioctl	= tap_compat_ioctl,
 #endif
 };
 
-static int macvtap_sendmsg(struct socket *sock, struct msghdr *m,
-			   size_t total_len)
+static int tap_sendmsg(struct socket *sock, struct msghdr *m,
+		       size_t total_len)
 {
-	struct macvtap_queue *q = container_of(sock, struct macvtap_queue, sock);
-	return macvtap_get_user(q, m, &m->msg_iter, m->msg_flags & MSG_DONTWAIT);
+	struct tap_queue *q = container_of(sock, struct tap_queue, sock);
+	return tap_get_user(q, m, &m->msg_iter, m->msg_flags & MSG_DONTWAIT);
 }
 
-static int macvtap_recvmsg(struct socket *sock, struct msghdr *m,
-			   size_t total_len, int flags)
+static int tap_recvmsg(struct socket *sock, struct msghdr *m,
+		       size_t total_len, int flags)
 {
-	struct macvtap_queue *q = container_of(sock, struct macvtap_queue, sock);
+	struct tap_queue *q = container_of(sock, struct tap_queue, sock);
 	int ret;
 	if (flags & ~(MSG_DONTWAIT|MSG_TRUNC))
 		return -EINVAL;
-	ret = macvtap_do_read(q, &m->msg_iter, flags & MSG_DONTWAIT);
+	ret = tap_do_read(q, &m->msg_iter, flags & MSG_DONTWAIT);
 	if (ret > total_len) {
 		m->msg_flags |= MSG_TRUNC;
 		ret = flags & MSG_TRUNC ? ret : total_len;
@@ -1133,40 +1133,40 @@ static int macvtap_recvmsg(struct socket *sock, struct msghdr *m,
 	return ret;
 }
 
-static int macvtap_peek_len(struct socket *sock)
+static int tap_peek_len(struct socket *sock)
 {
-	struct macvtap_queue *q = container_of(sock, struct macvtap_queue,
+	struct tap_queue *q = container_of(sock, struct tap_queue,
 					       sock);
 	return skb_array_peek_len(&q->skb_array);
 }
 
 /* Ops structure to mimic raw sockets with tun */
-static const struct proto_ops macvtap_socket_ops = {
-	.sendmsg = macvtap_sendmsg,
-	.recvmsg = macvtap_recvmsg,
-	.peek_len = macvtap_peek_len,
+static const struct proto_ops tap_socket_ops = {
+	.sendmsg = tap_sendmsg,
+	.recvmsg = tap_recvmsg,
+	.peek_len = tap_peek_len,
 };
 
 /* Get an underlying socket object from tun file.  Returns error unless file is
  * attached to a device.  The returned object works like a packet socket, it
  * can be used for sock_sendmsg/sock_recvmsg.  The caller is responsible for
  * holding a reference to the file for as long as the socket is in use. */
-struct socket *macvtap_get_socket(struct file *file)
+struct socket *tap_get_socket(struct file *file)
 {
-	struct macvtap_queue *q;
-	if (file->f_op != &macvtap_fops)
+	struct tap_queue *q;
+	if (file->f_op != &tap_fops)
 		return ERR_PTR(-EINVAL);
 	q = file->private_data;
 	if (!q)
 		return ERR_PTR(-EBADFD);
 	return &q->sock;
 }
-EXPORT_SYMBOL_GPL(macvtap_get_socket);
+EXPORT_SYMBOL_GPL(tap_get_socket);
 
-int macvtap_queue_resize(struct macvlan_dev *vlan)
+int tap_queue_resize(struct macvlan_dev *vlan)
 {
 	struct net_device *dev = vlan->dev;
-	struct macvtap_queue *q;
+	struct tap_queue *q;
 	struct skb_array **arrays;
 	int n = vlan->numqueues;
 	int ret, i = 0;

commit a8e04698732736f59fefe72c675791a006b76e1d
Author: Sainath Grandhi <sainath.grandhi@intel.com>
Date:   Fri Feb 10 16:03:46 2017 -0800

    tap: Refactoring macvtap.c
    
    macvtap module has code for tap/queue management and link management. This patch splits
    the code into macvtap_main.c for link management and tap.c for tap/queue management.
    Functionality in tap.c can be re-used for implementing tap on other virtual interfaces.
    
    Signed-off-by: Sainath Grandhi <sainath.grandhi@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/net/tap.c b/drivers/net/tap.c
new file mode 100644
index 000000000000..6f6228e4fd3f
--- /dev/null
+++ b/drivers/net/tap.c
@@ -0,0 +1,1186 @@
+#include <linux/etherdevice.h>
+#include <linux/if_macvlan.h>
+#include <linux/if_vlan.h>
+#include <linux/interrupt.h>
+#include <linux/nsproxy.h>
+#include <linux/compat.h>
+#include <linux/if_tun.h>
+#include <linux/module.h>
+#include <linux/skbuff.h>
+#include <linux/cache.h>
+#include <linux/sched.h>
+#include <linux/types.h>
+#include <linux/slab.h>
+#include <linux/wait.h>
+#include <linux/cdev.h>
+#include <linux/idr.h>
+#include <linux/fs.h>
+#include <linux/uio.h>
+
+#include <net/net_namespace.h>
+#include <net/rtnetlink.h>
+#include <net/sock.h>
+#include <linux/virtio_net.h>
+#include <linux/skb_array.h>
+
+/*
+ * A macvtap queue is the central object of this driver, it connects
+ * an open character device to a macvlan interface. There can be
+ * multiple queues on one interface, which map back to queues
+ * implemented in hardware on the underlying device.
+ *
+ * macvtap_proto is used to allocate queues through the sock allocation
+ * mechanism.
+ *
+ */
+struct macvtap_queue {
+	struct sock sk;
+	struct socket sock;
+	struct socket_wq wq;
+	int vnet_hdr_sz;
+	struct macvlan_dev __rcu *vlan;
+	struct file *file;
+	unsigned int flags;
+	u16 queue_index;
+	bool enabled;
+	struct list_head next;
+	struct skb_array skb_array;
+};
+
+#define MACVTAP_FEATURES (IFF_VNET_HDR | IFF_MULTI_QUEUE)
+
+#define MACVTAP_VNET_LE 0x80000000
+#define MACVTAP_VNET_BE 0x40000000
+
+#ifdef CONFIG_TUN_VNET_CROSS_LE
+static inline bool macvtap_legacy_is_little_endian(struct macvtap_queue *q)
+{
+	return q->flags & MACVTAP_VNET_BE ? false :
+		virtio_legacy_is_little_endian();
+}
+
+static long macvtap_get_vnet_be(struct macvtap_queue *q, int __user *sp)
+{
+	int s = !!(q->flags & MACVTAP_VNET_BE);
+
+	if (put_user(s, sp))
+		return -EFAULT;
+
+	return 0;
+}
+
+static long macvtap_set_vnet_be(struct macvtap_queue *q, int __user *sp)
+{
+	int s;
+
+	if (get_user(s, sp))
+		return -EFAULT;
+
+	if (s)
+		q->flags |= MACVTAP_VNET_BE;
+	else
+		q->flags &= ~MACVTAP_VNET_BE;
+
+	return 0;
+}
+#else
+static inline bool macvtap_legacy_is_little_endian(struct macvtap_queue *q)
+{
+	return virtio_legacy_is_little_endian();
+}
+
+static long macvtap_get_vnet_be(struct macvtap_queue *q, int __user *argp)
+{
+	return -EINVAL;
+}
+
+static long macvtap_set_vnet_be(struct macvtap_queue *q, int __user *argp)
+{
+	return -EINVAL;
+}
+#endif /* CONFIG_TUN_VNET_CROSS_LE */
+
+static inline bool macvtap_is_little_endian(struct macvtap_queue *q)
+{
+	return q->flags & MACVTAP_VNET_LE ||
+		macvtap_legacy_is_little_endian(q);
+}
+
+static inline u16 macvtap16_to_cpu(struct macvtap_queue *q, __virtio16 val)
+{
+	return __virtio16_to_cpu(macvtap_is_little_endian(q), val);
+}
+
+static inline __virtio16 cpu_to_macvtap16(struct macvtap_queue *q, u16 val)
+{
+	return __cpu_to_virtio16(macvtap_is_little_endian(q), val);
+}
+
+static struct proto macvtap_proto = {
+	.name = "macvtap",
+	.owner = THIS_MODULE,
+	.obj_size = sizeof (struct macvtap_queue),
+};
+
+#define MACVTAP_NUM_DEVS (1U << MINORBITS)
+static DEFINE_MUTEX(minor_lock);
+DEFINE_IDR(minor_idr);
+
+#define GOODCOPY_LEN 128
+
+static const struct proto_ops macvtap_socket_ops;
+
+#define RX_OFFLOADS (NETIF_F_GRO | NETIF_F_LRO)
+#define TAP_FEATURES (NETIF_F_GSO | NETIF_F_SG | NETIF_F_FRAGLIST)
+
+static struct macvlan_dev *macvtap_get_vlan_rcu(const struct net_device *dev)
+{
+	return rcu_dereference(dev->rx_handler_data);
+}
+
+/*
+ * RCU usage:
+ * The macvtap_queue and the macvlan_dev are loosely coupled, the
+ * pointers from one to the other can only be read while rcu_read_lock
+ * or rtnl is held.
+ *
+ * Both the file and the macvlan_dev hold a reference on the macvtap_queue
+ * through sock_hold(&q->sk). When the macvlan_dev goes away first,
+ * q->vlan becomes inaccessible. When the files gets closed,
+ * macvtap_get_queue() fails.
+ *
+ * There may still be references to the struct sock inside of the
+ * queue from outbound SKBs, but these never reference back to the
+ * file or the dev. The data structure is freed through __sk_free
+ * when both our references and any pending SKBs are gone.
+ */
+
+static int macvtap_enable_queue(struct net_device *dev, struct file *file,
+				struct macvtap_queue *q)
+{
+	struct macvlan_dev *vlan = netdev_priv(dev);
+	int err = -EINVAL;
+
+	ASSERT_RTNL();
+
+	if (q->enabled)
+		goto out;
+
+	err = 0;
+	rcu_assign_pointer(vlan->taps[vlan->numvtaps], q);
+	q->queue_index = vlan->numvtaps;
+	q->enabled = true;
+
+	vlan->numvtaps++;
+out:
+	return err;
+}
+
+/* Requires RTNL */
+static int macvtap_set_queue(struct net_device *dev, struct file *file,
+			     struct macvtap_queue *q)
+{
+	struct macvlan_dev *vlan = netdev_priv(dev);
+
+	if (vlan->numqueues == MAX_MACVTAP_QUEUES)
+		return -EBUSY;
+
+	rcu_assign_pointer(q->vlan, vlan);
+	rcu_assign_pointer(vlan->taps[vlan->numvtaps], q);
+	sock_hold(&q->sk);
+
+	q->file = file;
+	q->queue_index = vlan->numvtaps;
+	q->enabled = true;
+	file->private_data = q;
+	list_add_tail(&q->next, &vlan->queue_list);
+
+	vlan->numvtaps++;
+	vlan->numqueues++;
+
+	return 0;
+}
+
+static int macvtap_disable_queue(struct macvtap_queue *q)
+{
+	struct macvlan_dev *vlan;
+	struct macvtap_queue *nq;
+
+	ASSERT_RTNL();
+	if (!q->enabled)
+		return -EINVAL;
+
+	vlan = rtnl_dereference(q->vlan);
+
+	if (vlan) {
+		int index = q->queue_index;
+		BUG_ON(index >= vlan->numvtaps);
+		nq = rtnl_dereference(vlan->taps[vlan->numvtaps - 1]);
+		nq->queue_index = index;
+
+		rcu_assign_pointer(vlan->taps[index], nq);
+		RCU_INIT_POINTER(vlan->taps[vlan->numvtaps - 1], NULL);
+		q->enabled = false;
+
+		vlan->numvtaps--;
+	}
+
+	return 0;
+}
+
+/*
+ * The file owning the queue got closed, give up both
+ * the reference that the files holds as well as the
+ * one from the macvlan_dev if that still exists.
+ *
+ * Using the spinlock makes sure that we don't get
+ * to the queue again after destroying it.
+ */
+static void macvtap_put_queue(struct macvtap_queue *q)
+{
+	struct macvlan_dev *vlan;
+
+	rtnl_lock();
+	vlan = rtnl_dereference(q->vlan);
+
+	if (vlan) {
+		if (q->enabled)
+			BUG_ON(macvtap_disable_queue(q));
+
+		vlan->numqueues--;
+		RCU_INIT_POINTER(q->vlan, NULL);
+		sock_put(&q->sk);
+		list_del_init(&q->next);
+	}
+
+	rtnl_unlock();
+
+	synchronize_rcu();
+	sock_put(&q->sk);
+}
+
+/*
+ * Select a queue based on the rxq of the device on which this packet
+ * arrived. If the incoming device is not mq, calculate a flow hash
+ * to select a queue. If all fails, find the first available queue.
+ * Cache vlan->numvtaps since it can become zero during the execution
+ * of this function.
+ */
+static struct macvtap_queue *macvtap_get_queue(struct net_device *dev,
+					       struct sk_buff *skb)
+{
+	struct macvlan_dev *vlan = netdev_priv(dev);
+	struct macvtap_queue *tap = NULL;
+	/* Access to taps array is protected by rcu, but access to numvtaps
+	 * isn't. Below we use it to lookup a queue, but treat it as a hint
+	 * and validate that the result isn't NULL - in case we are
+	 * racing against queue removal.
+	 */
+	int numvtaps = ACCESS_ONCE(vlan->numvtaps);
+	__u32 rxq;
+
+	if (!numvtaps)
+		goto out;
+
+	if (numvtaps == 1)
+		goto single;
+
+	/* Check if we can use flow to select a queue */
+	rxq = skb_get_hash(skb);
+	if (rxq) {
+		tap = rcu_dereference(vlan->taps[rxq % numvtaps]);
+		goto out;
+	}
+
+	if (likely(skb_rx_queue_recorded(skb))) {
+		rxq = skb_get_rx_queue(skb);
+
+		while (unlikely(rxq >= numvtaps))
+			rxq -= numvtaps;
+
+		tap = rcu_dereference(vlan->taps[rxq]);
+		goto out;
+	}
+
+single:
+	tap = rcu_dereference(vlan->taps[0]);
+out:
+	return tap;
+}
+
+/*
+ * The net_device is going away, give up the reference
+ * that it holds on all queues and safely set the pointer
+ * from the queues to NULL.
+ */
+void macvtap_del_queues(struct net_device *dev)
+{
+	struct macvlan_dev *vlan = netdev_priv(dev);
+	struct macvtap_queue *q, *tmp;
+
+	ASSERT_RTNL();
+	list_for_each_entry_safe(q, tmp, &vlan->queue_list, next) {
+		list_del_init(&q->next);
+		RCU_INIT_POINTER(q->vlan, NULL);
+		if (q->enabled)
+			vlan->numvtaps--;
+		vlan->numqueues--;
+		sock_put(&q->sk);
+	}
+	BUG_ON(vlan->numvtaps);
+	BUG_ON(vlan->numqueues);
+	/* guarantee that any future macvtap_set_queue will fail */
+	vlan->numvtaps = MAX_MACVTAP_QUEUES;
+}
+
+rx_handler_result_t macvtap_handle_frame(struct sk_buff **pskb)
+{
+	struct sk_buff *skb = *pskb;
+	struct net_device *dev = skb->dev;
+	struct macvlan_dev *vlan;
+	struct macvtap_queue *q;
+	netdev_features_t features = TAP_FEATURES;
+
+	vlan = macvtap_get_vlan_rcu(dev);
+	if (!vlan)
+		return RX_HANDLER_PASS;
+
+	q = macvtap_get_queue(dev, skb);
+	if (!q)
+		return RX_HANDLER_PASS;
+
+	if (__skb_array_full(&q->skb_array))
+		goto drop;
+
+	skb_push(skb, ETH_HLEN);
+
+	/* Apply the forward feature mask so that we perform segmentation
+	 * according to users wishes.  This only works if VNET_HDR is
+	 * enabled.
+	 */
+	if (q->flags & IFF_VNET_HDR)
+		features |= vlan->tap_features;
+	if (netif_needs_gso(skb, features)) {
+		struct sk_buff *segs = __skb_gso_segment(skb, features, false);
+
+		if (IS_ERR(segs))
+			goto drop;
+
+		if (!segs) {
+			if (skb_array_produce(&q->skb_array, skb))
+				goto drop;
+			goto wake_up;
+		}
+
+		consume_skb(skb);
+		while (segs) {
+			struct sk_buff *nskb = segs->next;
+
+			segs->next = NULL;
+			if (skb_array_produce(&q->skb_array, segs)) {
+				kfree_skb(segs);
+				kfree_skb_list(nskb);
+				break;
+			}
+			segs = nskb;
+		}
+	} else {
+		/* If we receive a partial checksum and the tap side
+		 * doesn't support checksum offload, compute the checksum.
+		 * Note: it doesn't matter which checksum feature to
+		 *	  check, we either support them all or none.
+		 */
+		if (skb->ip_summed == CHECKSUM_PARTIAL &&
+		    !(features & NETIF_F_CSUM_MASK) &&
+		    skb_checksum_help(skb))
+			goto drop;
+		if (skb_array_produce(&q->skb_array, skb))
+			goto drop;
+	}
+
+wake_up:
+	wake_up_interruptible_poll(sk_sleep(&q->sk), POLLIN | POLLRDNORM | POLLRDBAND);
+	return RX_HANDLER_CONSUMED;
+
+drop:
+	/* Count errors/drops only here, thus don't care about args. */
+	macvlan_count_rx(vlan, 0, 0, 0);
+	kfree_skb(skb);
+	return RX_HANDLER_CONSUMED;
+}
+
+int macvtap_get_minor(struct macvlan_dev *vlan)
+{
+	int retval = -ENOMEM;
+
+	mutex_lock(&minor_lock);
+	retval = idr_alloc(&minor_idr, vlan, 1, MACVTAP_NUM_DEVS, GFP_KERNEL);
+	if (retval >= 0) {
+		vlan->minor = retval;
+	} else if (retval == -ENOSPC) {
+		netdev_err(vlan->dev, "Too many macvtap devices\n");
+		retval = -EINVAL;
+	}
+	mutex_unlock(&minor_lock);
+	return retval < 0 ? retval : 0;
+}
+
+void macvtap_free_minor(struct macvlan_dev *vlan)
+{
+	mutex_lock(&minor_lock);
+	if (vlan->minor) {
+		idr_remove(&minor_idr, vlan->minor);
+		vlan->minor = 0;
+	}
+	mutex_unlock(&minor_lock);
+}
+
+static struct net_device *dev_get_by_macvtap_minor(int minor)
+{
+	struct net_device *dev = NULL;
+	struct macvlan_dev *vlan;
+
+	mutex_lock(&minor_lock);
+	vlan = idr_find(&minor_idr, minor);
+	if (vlan) {
+		dev = vlan->dev;
+		dev_hold(dev);
+	}
+	mutex_unlock(&minor_lock);
+	return dev;
+}
+
+static void macvtap_sock_write_space(struct sock *sk)
+{
+	wait_queue_head_t *wqueue;
+
+	if (!sock_writeable(sk) ||
+	    !test_and_clear_bit(SOCKWQ_ASYNC_NOSPACE, &sk->sk_socket->flags))
+		return;
+
+	wqueue = sk_sleep(sk);
+	if (wqueue && waitqueue_active(wqueue))
+		wake_up_interruptible_poll(wqueue, POLLOUT | POLLWRNORM | POLLWRBAND);
+}
+
+static void macvtap_sock_destruct(struct sock *sk)
+{
+	struct macvtap_queue *q = container_of(sk, struct macvtap_queue, sk);
+
+	skb_array_cleanup(&q->skb_array);
+}
+
+static int macvtap_open(struct inode *inode, struct file *file)
+{
+	struct net *net = current->nsproxy->net_ns;
+	struct net_device *dev;
+	struct macvtap_queue *q;
+	int err = -ENODEV;
+
+	rtnl_lock();
+	dev = dev_get_by_macvtap_minor(iminor(inode));
+	if (!dev)
+		goto err;
+
+	err = -ENOMEM;
+	q = (struct macvtap_queue *)sk_alloc(net, AF_UNSPEC, GFP_KERNEL,
+					     &macvtap_proto, 0);
+	if (!q)
+		goto err;
+
+	RCU_INIT_POINTER(q->sock.wq, &q->wq);
+	init_waitqueue_head(&q->wq.wait);
+	q->sock.type = SOCK_RAW;
+	q->sock.state = SS_CONNECTED;
+	q->sock.file = file;
+	q->sock.ops = &macvtap_socket_ops;
+	sock_init_data(&q->sock, &q->sk);
+	q->sk.sk_write_space = macvtap_sock_write_space;
+	q->sk.sk_destruct = macvtap_sock_destruct;
+	q->flags = IFF_VNET_HDR | IFF_NO_PI | IFF_TAP;
+	q->vnet_hdr_sz = sizeof(struct virtio_net_hdr);
+
+	/*
+	 * so far only KVM virtio_net uses macvtap, enable zero copy between
+	 * guest kernel and host kernel when lower device supports zerocopy
+	 *
+	 * The macvlan supports zerocopy iff the lower device supports zero
+	 * copy so we don't have to look at the lower device directly.
+	 */
+	if ((dev->features & NETIF_F_HIGHDMA) && (dev->features & NETIF_F_SG))
+		sock_set_flag(&q->sk, SOCK_ZEROCOPY);
+
+	err = -ENOMEM;
+	if (skb_array_init(&q->skb_array, dev->tx_queue_len, GFP_KERNEL))
+		goto err_array;
+
+	err = macvtap_set_queue(dev, file, q);
+	if (err)
+		goto err_queue;
+
+	dev_put(dev);
+
+	rtnl_unlock();
+	return err;
+
+err_queue:
+	skb_array_cleanup(&q->skb_array);
+err_array:
+	sock_put(&q->sk);
+err:
+	if (dev)
+		dev_put(dev);
+
+	rtnl_unlock();
+	return err;
+}
+
+static int macvtap_release(struct inode *inode, struct file *file)
+{
+	struct macvtap_queue *q = file->private_data;
+	macvtap_put_queue(q);
+	return 0;
+}
+
+static unsigned int macvtap_poll(struct file *file, poll_table * wait)
+{
+	struct macvtap_queue *q = file->private_data;
+	unsigned int mask = POLLERR;
+
+	if (!q)
+		goto out;
+
+	mask = 0;
+	poll_wait(file, &q->wq.wait, wait);
+
+	if (!skb_array_empty(&q->skb_array))
+		mask |= POLLIN | POLLRDNORM;
+
+	if (sock_writeable(&q->sk) ||
+	    (!test_and_set_bit(SOCKWQ_ASYNC_NOSPACE, &q->sock.flags) &&
+	     sock_writeable(&q->sk)))
+		mask |= POLLOUT | POLLWRNORM;
+
+out:
+	return mask;
+}
+
+static inline struct sk_buff *macvtap_alloc_skb(struct sock *sk, size_t prepad,
+						size_t len, size_t linear,
+						int noblock, int *err)
+{
+	struct sk_buff *skb;
+
+	/* Under a page?  Don't bother with paged skb. */
+	if (prepad + len < PAGE_SIZE || !linear)
+		linear = len;
+
+	skb = sock_alloc_send_pskb(sk, prepad + linear, len - linear, noblock,
+				   err, 0);
+	if (!skb)
+		return NULL;
+
+	skb_reserve(skb, prepad);
+	skb_put(skb, linear);
+	skb->data_len = len - linear;
+	skb->len += len - linear;
+
+	return skb;
+}
+
+/* Neighbour code has some assumptions on HH_DATA_MOD alignment */
+#define MACVTAP_RESERVE HH_DATA_OFF(ETH_HLEN)
+
+/* Get packet from user space buffer */
+static ssize_t macvtap_get_user(struct macvtap_queue *q, struct msghdr *m,
+				struct iov_iter *from, int noblock)
+{
+	int good_linear = SKB_MAX_HEAD(MACVTAP_RESERVE);
+	struct sk_buff *skb;
+	struct macvlan_dev *vlan;
+	unsigned long total_len = iov_iter_count(from);
+	unsigned long len = total_len;
+	int err;
+	struct virtio_net_hdr vnet_hdr = { 0 };
+	int vnet_hdr_len = 0;
+	int copylen = 0;
+	int depth;
+	bool zerocopy = false;
+	size_t linear;
+
+	if (q->flags & IFF_VNET_HDR) {
+		vnet_hdr_len = READ_ONCE(q->vnet_hdr_sz);
+
+		err = -EINVAL;
+		if (len < vnet_hdr_len)
+			goto err;
+		len -= vnet_hdr_len;
+
+		err = -EFAULT;
+		if (!copy_from_iter_full(&vnet_hdr, sizeof(vnet_hdr), from))
+			goto err;
+		iov_iter_advance(from, vnet_hdr_len - sizeof(vnet_hdr));
+		if ((vnet_hdr.flags & VIRTIO_NET_HDR_F_NEEDS_CSUM) &&
+		     macvtap16_to_cpu(q, vnet_hdr.csum_start) +
+		     macvtap16_to_cpu(q, vnet_hdr.csum_offset) + 2 >
+			     macvtap16_to_cpu(q, vnet_hdr.hdr_len))
+			vnet_hdr.hdr_len = cpu_to_macvtap16(q,
+				 macvtap16_to_cpu(q, vnet_hdr.csum_start) +
+				 macvtap16_to_cpu(q, vnet_hdr.csum_offset) + 2);
+		err = -EINVAL;
+		if (macvtap16_to_cpu(q, vnet_hdr.hdr_len) > len)
+			goto err;
+	}
+
+	err = -EINVAL;
+	if (unlikely(len < ETH_HLEN))
+		goto err;
+
+	if (m && m->msg_control && sock_flag(&q->sk, SOCK_ZEROCOPY)) {
+		struct iov_iter i;
+
+		copylen = vnet_hdr.hdr_len ?
+			macvtap16_to_cpu(q, vnet_hdr.hdr_len) : GOODCOPY_LEN;
+		if (copylen > good_linear)
+			copylen = good_linear;
+		else if (copylen < ETH_HLEN)
+			copylen = ETH_HLEN;
+		linear = copylen;
+		i = *from;
+		iov_iter_advance(&i, copylen);
+		if (iov_iter_npages(&i, INT_MAX) <= MAX_SKB_FRAGS)
+			zerocopy = true;
+	}
+
+	if (!zerocopy) {
+		copylen = len;
+		linear = macvtap16_to_cpu(q, vnet_hdr.hdr_len);
+		if (linear > good_linear)
+			linear = good_linear;
+		else if (linear < ETH_HLEN)
+			linear = ETH_HLEN;
+	}
+
+	skb = macvtap_alloc_skb(&q->sk, MACVTAP_RESERVE, copylen,
+				linear, noblock, &err);
+	if (!skb)
+		goto err;
+
+	if (zerocopy)
+		err = zerocopy_sg_from_iter(skb, from);
+	else
+		err = skb_copy_datagram_from_iter(skb, 0, from, len);
+
+	if (err)
+		goto err_kfree;
+
+	skb_set_network_header(skb, ETH_HLEN);
+	skb_reset_mac_header(skb);
+	skb->protocol = eth_hdr(skb)->h_proto;
+
+	if (vnet_hdr_len) {
+		err = virtio_net_hdr_to_skb(skb, &vnet_hdr,
+					    macvtap_is_little_endian(q));
+		if (err)
+			goto err_kfree;
+	}
+
+	skb_probe_transport_header(skb, ETH_HLEN);
+
+	/* Move network header to the right position for VLAN tagged packets */
+	if ((skb->protocol == htons(ETH_P_8021Q) ||
+	     skb->protocol == htons(ETH_P_8021AD)) &&
+	    __vlan_get_protocol(skb, skb->protocol, &depth) != 0)
+		skb_set_network_header(skb, depth);
+
+	rcu_read_lock();
+	vlan = rcu_dereference(q->vlan);
+	/* copy skb_ubuf_info for callback when skb has no error */
+	if (zerocopy) {
+		skb_shinfo(skb)->destructor_arg = m->msg_control;
+		skb_shinfo(skb)->tx_flags |= SKBTX_DEV_ZEROCOPY;
+		skb_shinfo(skb)->tx_flags |= SKBTX_SHARED_FRAG;
+	} else if (m && m->msg_control) {
+		struct ubuf_info *uarg = m->msg_control;
+		uarg->callback(uarg, false);
+	}
+
+	if (vlan) {
+		skb->dev = vlan->dev;
+		dev_queue_xmit(skb);
+	} else {
+		kfree_skb(skb);
+	}
+	rcu_read_unlock();
+
+	return total_len;
+
+err_kfree:
+	kfree_skb(skb);
+
+err:
+	rcu_read_lock();
+	vlan = rcu_dereference(q->vlan);
+	if (vlan)
+		this_cpu_inc(vlan->pcpu_stats->tx_dropped);
+	rcu_read_unlock();
+
+	return err;
+}
+
+static ssize_t macvtap_write_iter(struct kiocb *iocb, struct iov_iter *from)
+{
+	struct file *file = iocb->ki_filp;
+	struct macvtap_queue *q = file->private_data;
+
+	return macvtap_get_user(q, NULL, from, file->f_flags & O_NONBLOCK);
+}
+
+/* Put packet to the user space buffer */
+static ssize_t macvtap_put_user(struct macvtap_queue *q,
+				const struct sk_buff *skb,
+				struct iov_iter *iter)
+{
+	int ret;
+	int vnet_hdr_len = 0;
+	int vlan_offset = 0;
+	int total;
+
+	if (q->flags & IFF_VNET_HDR) {
+		struct virtio_net_hdr vnet_hdr;
+		vnet_hdr_len = READ_ONCE(q->vnet_hdr_sz);
+		if (iov_iter_count(iter) < vnet_hdr_len)
+			return -EINVAL;
+
+		if (virtio_net_hdr_from_skb(skb, &vnet_hdr,
+					    macvtap_is_little_endian(q), true))
+			BUG();
+
+		if (copy_to_iter(&vnet_hdr, sizeof(vnet_hdr), iter) !=
+		    sizeof(vnet_hdr))
+			return -EFAULT;
+
+		iov_iter_advance(iter, vnet_hdr_len - sizeof(vnet_hdr));
+	}
+	total = vnet_hdr_len;
+	total += skb->len;
+
+	if (skb_vlan_tag_present(skb)) {
+		struct {
+			__be16 h_vlan_proto;
+			__be16 h_vlan_TCI;
+		} veth;
+		veth.h_vlan_proto = skb->vlan_proto;
+		veth.h_vlan_TCI = htons(skb_vlan_tag_get(skb));
+
+		vlan_offset = offsetof(struct vlan_ethhdr, h_vlan_proto);
+		total += VLAN_HLEN;
+
+		ret = skb_copy_datagram_iter(skb, 0, iter, vlan_offset);
+		if (ret || !iov_iter_count(iter))
+			goto done;
+
+		ret = copy_to_iter(&veth, sizeof(veth), iter);
+		if (ret != sizeof(veth) || !iov_iter_count(iter))
+			goto done;
+	}
+
+	ret = skb_copy_datagram_iter(skb, vlan_offset, iter,
+				     skb->len - vlan_offset);
+
+done:
+	return ret ? ret : total;
+}
+
+static ssize_t macvtap_do_read(struct macvtap_queue *q,
+			       struct iov_iter *to,
+			       int noblock)
+{
+	DEFINE_WAIT(wait);
+	struct sk_buff *skb;
+	ssize_t ret = 0;
+
+	if (!iov_iter_count(to))
+		return 0;
+
+	while (1) {
+		if (!noblock)
+			prepare_to_wait(sk_sleep(&q->sk), &wait,
+					TASK_INTERRUPTIBLE);
+
+		/* Read frames from the queue */
+		skb = skb_array_consume(&q->skb_array);
+		if (skb)
+			break;
+		if (noblock) {
+			ret = -EAGAIN;
+			break;
+		}
+		if (signal_pending(current)) {
+			ret = -ERESTARTSYS;
+			break;
+		}
+		/* Nothing to read, let's sleep */
+		schedule();
+	}
+	if (!noblock)
+		finish_wait(sk_sleep(&q->sk), &wait);
+
+	if (skb) {
+		ret = macvtap_put_user(q, skb, to);
+		if (unlikely(ret < 0))
+			kfree_skb(skb);
+		else
+			consume_skb(skb);
+	}
+	return ret;
+}
+
+static ssize_t macvtap_read_iter(struct kiocb *iocb, struct iov_iter *to)
+{
+	struct file *file = iocb->ki_filp;
+	struct macvtap_queue *q = file->private_data;
+	ssize_t len = iov_iter_count(to), ret;
+
+	ret = macvtap_do_read(q, to, file->f_flags & O_NONBLOCK);
+	ret = min_t(ssize_t, ret, len);
+	if (ret > 0)
+		iocb->ki_pos = ret;
+	return ret;
+}
+
+static struct macvlan_dev *macvtap_get_vlan(struct macvtap_queue *q)
+{
+	struct macvlan_dev *vlan;
+
+	ASSERT_RTNL();
+	vlan = rtnl_dereference(q->vlan);
+	if (vlan)
+		dev_hold(vlan->dev);
+
+	return vlan;
+}
+
+static void macvtap_put_vlan(struct macvlan_dev *vlan)
+{
+	dev_put(vlan->dev);
+}
+
+static int macvtap_ioctl_set_queue(struct file *file, unsigned int flags)
+{
+	struct macvtap_queue *q = file->private_data;
+	struct macvlan_dev *vlan;
+	int ret;
+
+	vlan = macvtap_get_vlan(q);
+	if (!vlan)
+		return -EINVAL;
+
+	if (flags & IFF_ATTACH_QUEUE)
+		ret = macvtap_enable_queue(vlan->dev, file, q);
+	else if (flags & IFF_DETACH_QUEUE)
+		ret = macvtap_disable_queue(q);
+	else
+		ret = -EINVAL;
+
+	macvtap_put_vlan(vlan);
+	return ret;
+}
+
+static int set_offload(struct macvtap_queue *q, unsigned long arg)
+{
+	struct macvlan_dev *vlan;
+	netdev_features_t features;
+	netdev_features_t feature_mask = 0;
+
+	vlan = rtnl_dereference(q->vlan);
+	if (!vlan)
+		return -ENOLINK;
+
+	features = vlan->dev->features;
+
+	if (arg & TUN_F_CSUM) {
+		feature_mask = NETIF_F_HW_CSUM;
+
+		if (arg & (TUN_F_TSO4 | TUN_F_TSO6)) {
+			if (arg & TUN_F_TSO_ECN)
+				feature_mask |= NETIF_F_TSO_ECN;
+			if (arg & TUN_F_TSO4)
+				feature_mask |= NETIF_F_TSO;
+			if (arg & TUN_F_TSO6)
+				feature_mask |= NETIF_F_TSO6;
+		}
+
+		if (arg & TUN_F_UFO)
+			feature_mask |= NETIF_F_UFO;
+	}
+
+	/* tun/tap driver inverts the usage for TSO offloads, where
+	 * setting the TSO bit means that the userspace wants to
+	 * accept TSO frames and turning it off means that user space
+	 * does not support TSO.
+	 * For macvtap, we have to invert it to mean the same thing.
+	 * When user space turns off TSO, we turn off GSO/LRO so that
+	 * user-space will not receive TSO frames.
+	 */
+	if (feature_mask & (NETIF_F_TSO | NETIF_F_TSO6 | NETIF_F_UFO))
+		features |= RX_OFFLOADS;
+	else
+		features &= ~RX_OFFLOADS;
+
+	/* tap_features are the same as features on tun/tap and
+	 * reflect user expectations.
+	 */
+	vlan->tap_features = feature_mask;
+	vlan->set_features = features;
+	netdev_update_features(vlan->dev);
+
+	return 0;
+}
+
+/*
+ * provide compatibility with generic tun/tap interface
+ */
+static long macvtap_ioctl(struct file *file, unsigned int cmd,
+			  unsigned long arg)
+{
+	struct macvtap_queue *q = file->private_data;
+	struct macvlan_dev *vlan;
+	void __user *argp = (void __user *)arg;
+	struct ifreq __user *ifr = argp;
+	unsigned int __user *up = argp;
+	unsigned short u;
+	int __user *sp = argp;
+	struct sockaddr sa;
+	int s;
+	int ret;
+
+	switch (cmd) {
+	case TUNSETIFF:
+		/* ignore the name, just look at flags */
+		if (get_user(u, &ifr->ifr_flags))
+			return -EFAULT;
+
+		ret = 0;
+		if ((u & ~MACVTAP_FEATURES) != (IFF_NO_PI | IFF_TAP))
+			ret = -EINVAL;
+		else
+			q->flags = (q->flags & ~MACVTAP_FEATURES) | u;
+
+		return ret;
+
+	case TUNGETIFF:
+		rtnl_lock();
+		vlan = macvtap_get_vlan(q);
+		if (!vlan) {
+			rtnl_unlock();
+			return -ENOLINK;
+		}
+
+		ret = 0;
+		u = q->flags;
+		if (copy_to_user(&ifr->ifr_name, vlan->dev->name, IFNAMSIZ) ||
+		    put_user(u, &ifr->ifr_flags))
+			ret = -EFAULT;
+		macvtap_put_vlan(vlan);
+		rtnl_unlock();
+		return ret;
+
+	case TUNSETQUEUE:
+		if (get_user(u, &ifr->ifr_flags))
+			return -EFAULT;
+		rtnl_lock();
+		ret = macvtap_ioctl_set_queue(file, u);
+		rtnl_unlock();
+		return ret;
+
+	case TUNGETFEATURES:
+		if (put_user(IFF_TAP | IFF_NO_PI | MACVTAP_FEATURES, up))
+			return -EFAULT;
+		return 0;
+
+	case TUNSETSNDBUF:
+		if (get_user(s, sp))
+			return -EFAULT;
+
+		q->sk.sk_sndbuf = s;
+		return 0;
+
+	case TUNGETVNETHDRSZ:
+		s = q->vnet_hdr_sz;
+		if (put_user(s, sp))
+			return -EFAULT;
+		return 0;
+
+	case TUNSETVNETHDRSZ:
+		if (get_user(s, sp))
+			return -EFAULT;
+		if (s < (int)sizeof(struct virtio_net_hdr))
+			return -EINVAL;
+
+		q->vnet_hdr_sz = s;
+		return 0;
+
+	case TUNGETVNETLE:
+		s = !!(q->flags & MACVTAP_VNET_LE);
+		if (put_user(s, sp))
+			return -EFAULT;
+		return 0;
+
+	case TUNSETVNETLE:
+		if (get_user(s, sp))
+			return -EFAULT;
+		if (s)
+			q->flags |= MACVTAP_VNET_LE;
+		else
+			q->flags &= ~MACVTAP_VNET_LE;
+		return 0;
+
+	case TUNGETVNETBE:
+		return macvtap_get_vnet_be(q, sp);
+
+	case TUNSETVNETBE:
+		return macvtap_set_vnet_be(q, sp);
+
+	case TUNSETOFFLOAD:
+		/* let the user check for future flags */
+		if (arg & ~(TUN_F_CSUM | TUN_F_TSO4 | TUN_F_TSO6 |
+			    TUN_F_TSO_ECN | TUN_F_UFO))
+			return -EINVAL;
+
+		rtnl_lock();
+		ret = set_offload(q, arg);
+		rtnl_unlock();
+		return ret;
+
+	case SIOCGIFHWADDR:
+		rtnl_lock();
+		vlan = macvtap_get_vlan(q);
+		if (!vlan) {
+			rtnl_unlock();
+			return -ENOLINK;
+		}
+		ret = 0;
+		u = vlan->dev->type;
+		if (copy_to_user(&ifr->ifr_name, vlan->dev->name, IFNAMSIZ) ||
+		    copy_to_user(&ifr->ifr_hwaddr.sa_data, vlan->dev->dev_addr, ETH_ALEN) ||
+		    put_user(u, &ifr->ifr_hwaddr.sa_family))
+			ret = -EFAULT;
+		macvtap_put_vlan(vlan);
+		rtnl_unlock();
+		return ret;
+
+	case SIOCSIFHWADDR:
+		if (copy_from_user(&sa, &ifr->ifr_hwaddr, sizeof(sa)))
+			return -EFAULT;
+		rtnl_lock();
+		vlan = macvtap_get_vlan(q);
+		if (!vlan) {
+			rtnl_unlock();
+			return -ENOLINK;
+		}
+		ret = dev_set_mac_address(vlan->dev, &sa);
+		macvtap_put_vlan(vlan);
+		rtnl_unlock();
+		return ret;
+
+	default:
+		return -EINVAL;
+	}
+}
+
+#ifdef CONFIG_COMPAT
+static long macvtap_compat_ioctl(struct file *file, unsigned int cmd,
+				 unsigned long arg)
+{
+	return macvtap_ioctl(file, cmd, (unsigned long)compat_ptr(arg));
+}
+#endif
+
+const struct file_operations macvtap_fops = {
+	.owner		= THIS_MODULE,
+	.open		= macvtap_open,
+	.release	= macvtap_release,
+	.read_iter	= macvtap_read_iter,
+	.write_iter	= macvtap_write_iter,
+	.poll		= macvtap_poll,
+	.llseek		= no_llseek,
+	.unlocked_ioctl	= macvtap_ioctl,
+#ifdef CONFIG_COMPAT
+	.compat_ioctl	= macvtap_compat_ioctl,
+#endif
+};
+
+static int macvtap_sendmsg(struct socket *sock, struct msghdr *m,
+			   size_t total_len)
+{
+	struct macvtap_queue *q = container_of(sock, struct macvtap_queue, sock);
+	return macvtap_get_user(q, m, &m->msg_iter, m->msg_flags & MSG_DONTWAIT);
+}
+
+static int macvtap_recvmsg(struct socket *sock, struct msghdr *m,
+			   size_t total_len, int flags)
+{
+	struct macvtap_queue *q = container_of(sock, struct macvtap_queue, sock);
+	int ret;
+	if (flags & ~(MSG_DONTWAIT|MSG_TRUNC))
+		return -EINVAL;
+	ret = macvtap_do_read(q, &m->msg_iter, flags & MSG_DONTWAIT);
+	if (ret > total_len) {
+		m->msg_flags |= MSG_TRUNC;
+		ret = flags & MSG_TRUNC ? ret : total_len;
+	}
+	return ret;
+}
+
+static int macvtap_peek_len(struct socket *sock)
+{
+	struct macvtap_queue *q = container_of(sock, struct macvtap_queue,
+					       sock);
+	return skb_array_peek_len(&q->skb_array);
+}
+
+/* Ops structure to mimic raw sockets with tun */
+static const struct proto_ops macvtap_socket_ops = {
+	.sendmsg = macvtap_sendmsg,
+	.recvmsg = macvtap_recvmsg,
+	.peek_len = macvtap_peek_len,
+};
+
+/* Get an underlying socket object from tun file.  Returns error unless file is
+ * attached to a device.  The returned object works like a packet socket, it
+ * can be used for sock_sendmsg/sock_recvmsg.  The caller is responsible for
+ * holding a reference to the file for as long as the socket is in use. */
+struct socket *macvtap_get_socket(struct file *file)
+{
+	struct macvtap_queue *q;
+	if (file->f_op != &macvtap_fops)
+		return ERR_PTR(-EINVAL);
+	q = file->private_data;
+	if (!q)
+		return ERR_PTR(-EBADFD);
+	return &q->sock;
+}
+EXPORT_SYMBOL_GPL(macvtap_get_socket);
+
+int macvtap_queue_resize(struct macvlan_dev *vlan)
+{
+	struct net_device *dev = vlan->dev;
+	struct macvtap_queue *q;
+	struct skb_array **arrays;
+	int n = vlan->numqueues;
+	int ret, i = 0;
+
+	arrays = kmalloc(sizeof *arrays * n, GFP_KERNEL);
+	if (!arrays)
+		return -ENOMEM;
+
+	list_for_each_entry(q, &vlan->queue_list, next)
+		arrays[i++] = &q->skb_array;
+
+	ret = skb_array_resize_multiple(arrays, n,
+					dev->tx_queue_len, GFP_KERNEL);
+
+	kfree(arrays);
+	return ret;
+}
