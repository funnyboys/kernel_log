commit 0fd92f89a44d3ba32c1056f3ceaba8f8bdc08712
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 27 07:24:10 2020 +0200

    nvdimm: use bio_{start,end}_io_acct
    
    Switch dm to use the nicer bio accounting helpers.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 85dbb2a322b9..85c1ae813ea3 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -396,25 +396,6 @@ static inline int nvdimm_setup_pfn(struct nd_pfn *nd_pfn,
 #endif
 int nd_blk_region_init(struct nd_region *nd_region);
 int nd_region_activate(struct nd_region *nd_region);
-void __nd_iostat_start(struct bio *bio, unsigned long *start);
-static inline bool nd_iostat_start(struct bio *bio, unsigned long *start)
-{
-	struct gendisk *disk = bio->bi_disk;
-
-	if (!blk_queue_io_stat(disk->queue))
-		return false;
-
-	*start = jiffies;
-	generic_start_io_acct(disk->queue, bio_op(bio), bio_sectors(bio),
-			      &disk->part0);
-	return true;
-}
-static inline void nd_iostat_end(struct bio *bio, unsigned long start)
-{
-	struct gendisk *disk = bio->bi_disk;
-
-	generic_end_io_acct(disk->queue, bio_op(bio), &disk->part0, start);
-}
 static inline bool is_bad_pmem(struct badblocks *bb, sector_t sector,
 		unsigned int len)
 {

commit f6d2b802f80d0ca89ee1f51c1781b3f79cdb25d5
Merge: d3b88655c0a1 4e4ced93794a
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Apr 2 19:55:17 2020 -0700

    Merge branch 'for-5.7/libnvdimm' into libnvdimm-for-next
    
    - Introduce 'zero_page_range' as a dax operation. This facilitates
      filesystem-dax operation without a block-device.
    
    - Advertise a persistence-domain for of_pmem and papr_scm. The
      persistence domain indicates where cpu-store cycles need to reach in
      the platform-memory subsystem before the platform will consider them
      power-fail protected.
    
    - Fixup some flexible-array declarations.

commit 9106137c6f0d0d959a855ad6885c6b3cb010ff98
Author: Gustavo A. R. Silva <gustavo@embeddedor.com>
Date:   Thu Mar 19 18:09:37 2020 -0500

    libnvdimm/region: Replace zero-length array with flexible-array member
    
    The current codebase makes use of the zero-length array language
    extension to the C90 standard, but the preferred mechanism to declare
    variable-length types such as these ones is a flexible array member[1][2],
    introduced in C99:
    
    struct foo {
            int stuff;
            struct boo array[];
    };
    
    By making use of the mechanism above, we will get a compiler warning
    in case the flexible array does not occur last in the structure, which
    will help us prevent some kind of undefined behavior bugs from being
    inadvertently introduced[3] to the codebase from now on.
    
    Also, notice that, dynamic memory allocations won't be affected by
    this change:
    
    "Flexible array members have incomplete type, and so the sizeof operator
    may not be applied. As a quirk of the original implementation of
    zero-length arrays, sizeof evaluates to zero."[1]
    
    This issue was found with the help of Coccinelle.
    
    [1] https://gcc.gnu.org/onlinedocs/gcc/Zero-Length.html
    [2] https://github.com/KSPP/linux/issues/21
    [3] commit 76497732932f ("cxgb3/l2t: Fix undefined behaviour")
    
    Signed-off-by: Gustavo A. R. Silva <gustavo@embeddedor.com>
    Link: https://lore.kernel.org/r/20200319230937.GA16648@embeddedor.com
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index c9f6a5b5253a..2cf77bc859c1 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -39,7 +39,7 @@ struct nd_region_data {
 	int ns_count;
 	int ns_active;
 	unsigned int hints_shift;
-	void __iomem *flush_wpq[0];
+	void __iomem *flush_wpq[];
 };
 
 static inline void __iomem *ndrd_get_flush_wpq(struct nd_region_data *ndrd,
@@ -156,7 +156,7 @@ struct nd_region {
 	struct nd_interleave_set *nd_set;
 	struct nd_percpu_lane __percpu *lane;
 	int (*flush)(struct nd_region *nd_region, struct bio *bio);
-	struct nd_mapping mapping[0];
+	struct nd_mapping mapping[];
 };
 
 struct nd_blk_region {

commit 2522afb86a8cceba0f67dbf05772d21b76d79f06
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Jan 30 12:06:23 2020 -0800

    libnvdimm/region: Introduce an 'align' attribute
    
    The align attribute applies an alignment constraint for namespace
    creation in a region. Whereas the 'align' attribute of a namespace
    applied alignment padding via an info block, the 'align' attribute
    applies alignment constraints to the free space allocation.
    
    The default for 'align' is the maximum known memremap_compat_align()
    across all archs (16MiB from PowerPC at time of writing) multiplied by
    the number of interleave ways if there is blk-aliasing. The minimum is
    PAGE_SIZE and allows for the creation of cross-arch incompatible
    namespaces, just as previous kernels allowed, but the expectation is
    cross-arch and mode-independent compatibility by default.
    
    The regression risk with this change is limited to cases that were
    dependent on the ability to create unaligned namespaces, *and* for some
    reason are unable to opt-out of aligned namespaces by writing to
    'regionX/align'. If such a scenario arises the default can be flipped
    from opt-out to opt-in of compat-aligned namespace creation, but that is
    a last resort. The kernel will otherwise continue to support existing
    defined misaligned namespaces.
    
    Unfortunately this change needs to touch several parts of the
    implementation at once:
    
    - region/available_size: expand busy extents to current align
    - region/max_available_extent: expand busy extents to current align
    - namespace/size: trim free space to current align
    
    ...to keep the free space accounting conforming to the dynamic align
    setting.
    
    Reported-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Reported-by: Jeff Moyer <jmoyer@redhat.com>
    Reviewed-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Reviewed-by: Jeff Moyer <jmoyer@redhat.com>
    Link: https://lore.kernel.org/r/158041478371.3889308.14542630147672668068.stgit@dwillia2-desk3.amr.corp.intel.com
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index ca39abe29c7c..c4d69c1cce55 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -146,6 +146,7 @@ struct nd_region {
 	struct device *btt_seed;
 	struct device *pfn_seed;
 	struct device *dax_seed;
+	unsigned long align;
 	u16 ndr_mappings;
 	u64 ndr_size;
 	u64 ndr_start;

commit a0e374525def2ef18a078523e1faefb5ce2b05e5
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Jan 30 12:06:18 2020 -0800

    libnvdimm/region: Introduce NDD_LABELING
    
    The NDD_ALIASING flag is used to indicate where pmem capacity might
    alias with blk capacity and require labeling. It is also used to
    indicate whether the DIMM supports labeling. Separate this latter
    capability into its own flag so that the NDD_ALIASING flag is scoped to
    true aliased configurations.
    
    To my knowledge aliased configurations only exist in the ACPI spec,
    there are no known platforms that ship this support in production.
    
    This clarity allows namespace-capacity alignment constraints around
    interleave-ways to be relaxed.
    
    Cc: Vishal Verma <vishal.l.verma@intel.com>
    Cc: Oliver O'Halloran <oohall@gmail.com>
    Reviewed-by: Jeff Moyer <jmoyer@redhat.com>
    Reviewed-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Link: https://lore.kernel.org/r/158041477856.3889308.4212605617834097674.stgit@dwillia2-desk3.amr.corp.intel.com
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index c9f6a5b5253a..ca39abe29c7c 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -252,7 +252,7 @@ int nvdimm_set_config_data(struct nvdimm_drvdata *ndd, size_t offset,
 		void *buf, size_t len);
 long nvdimm_clear_poison(struct device *dev, phys_addr_t phys,
 		unsigned int len);
-void nvdimm_set_aliasing(struct device *dev);
+void nvdimm_set_labeling(struct device *dev);
 void nvdimm_set_locked(struct device *dev);
 void nvdimm_clear_locked(struct device *dev);
 int nvdimm_security_setup_events(struct device *dev);

commit e755799aefa9385469bec49b2c2ccf1aaa33829a
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Nov 12 17:08:56 2019 -0800

    libnvdimm: Move nvdimm_bus_attribute_group to device_type
    
    A 'struct device_type' instance can carry default attributes for the
    device. Use this facility to remove the export of
    nvdimm_bus_attribute_group and put the responsibility on the core rather
    than leaf implementations to define this attribute.
    
    Cc: Ira Weiny <ira.weiny@intel.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: "Oliver O'Halloran" <oohall@gmail.com>
    Cc: Vishal Verma <vishal.l.verma@intel.com>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Reviewed-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Link: https://lore.kernel.org/r/157309903815.1582359.6418211876315050283.stgit@dwillia2-desk3.amr.corp.intel.com

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index ec3d5f619957..c9f6a5b5253a 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -241,6 +241,7 @@ void nd_region_exit(void);
 struct nvdimm;
 extern const struct attribute_group nd_device_attribute_group;
 extern const struct attribute_group nd_numa_attribute_group;
+extern const struct attribute_group *nvdimm_bus_attribute_groups[];
 struct nvdimm_drvdata *to_ndd(struct nd_mapping *nd_mapping);
 int nvdimm_check_config_data(struct device *dev);
 int nvdimm_init_nsarea(struct nvdimm_drvdata *ndd);

commit e2f6a0e34870ff1bdb1411e250dd2f03908cfa9f
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Nov 19 09:51:54 2019 -0800

    libnvdimm: Move nd_numa_attribute_group to device_type
    
    A 'struct device_type' instance can carry default attributes for the
    device. Use this facility to remove the export of
    nd_numa_attribute_group and put the responsibility on the core rather
    than leaf implementations to define this attribute.
    
    Cc: Ira Weiny <ira.weiny@intel.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: "Oliver O'Halloran" <oohall@gmail.com>
    Cc: Vishal Verma <vishal.l.verma@intel.com>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Reviewed-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Link: https://lore.kernel.org/r/157401269537.43284.14411189404186877352.stgit@dwillia2-desk3.amr.corp.intel.com
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 21e018bfa188..ec3d5f619957 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -240,6 +240,7 @@ void nvdimm_exit(void);
 void nd_region_exit(void);
 struct nvdimm;
 extern const struct attribute_group nd_device_attribute_group;
+extern const struct attribute_group nd_numa_attribute_group;
 struct nvdimm_drvdata *to_ndd(struct nd_mapping *nd_mapping);
 int nvdimm_check_config_data(struct device *dev);
 int nvdimm_init_nsarea(struct nvdimm_drvdata *ndd);

commit adbb68293fc5950a46e3e22f9dc9c619661194ae
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Nov 12 17:00:24 2019 -0800

    libnvdimm: Move nd_device_attribute_group to device_type
    
    A 'struct device_type' instance can carry default attributes for the
    device. Use this facility to remove the export of
    nd_device_attribute_group and put the responsibility on the core rather
    than leaf implementations to define this attribute.
    
    For regions this creates a new nd_region_attribute_groups[] added to the
    per-region device-type instances.
    
    Cc: Ira Weiny <ira.weiny@intel.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: "Oliver O'Halloran" <oohall@gmail.com>
    Cc: Vishal Verma <vishal.l.verma@intel.com>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Reviewed-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Link: https://lore.kernel.org/r/157309901138.1582359.12909354140826530394.stgit@dwillia2-desk3.amr.corp.intel.com
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index d83dd34cd169..21e018bfa188 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -239,6 +239,7 @@ int __init nd_label_init(void);
 void nvdimm_exit(void);
 void nd_region_exit(void);
 struct nvdimm;
+extern const struct attribute_group nd_device_attribute_group;
 struct nvdimm_drvdata *to_ndd(struct nd_mapping *nd_mapping);
 int nvdimm_check_config_data(struct device *dev);
 int nvdimm_init_nsarea(struct nvdimm_drvdata *ndd);

commit 78c81cc89a40114d09a5ec0693cfd97831ffbe79
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed Nov 6 19:56:41 2019 -0800

    libnvdimm: Move attribute groups to device type
    
    Statically initialize the attribute groups for each libnvdimm
    device_type. This is a preparation step for removing unnecessary exports
    of attributes that can be included in the device_type by default.
    
    Also take the opportunity to mark 'struct device_type' instances const.
    
    Cc: Ira Weiny <ira.weiny@intel.com>
    Cc: Vishal Verma <vishal.l.verma@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Reviewed-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Link: https://lore.kernel.org/r/157309900111.1582359.2445687530383470348.stgit@dwillia2-desk3.amr.corp.intel.com

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index a9f338d01a55..d83dd34cd169 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -302,7 +302,7 @@ struct device *nd_pfn_create(struct nd_region *nd_region);
 struct device *nd_pfn_devinit(struct nd_pfn *nd_pfn,
 		struct nd_namespace_common *ndns);
 int nd_pfn_validate(struct nd_pfn *nd_pfn, const char *sig);
-extern struct attribute_group nd_pfn_attribute_group;
+extern const struct attribute_group *nd_pfn_attribute_groups[];
 #else
 static inline int nd_pfn_probe(struct device *dev,
 		struct nd_namespace_common *ndns)

commit 8f4b01fcded2dc821349cc0edfa5311c05abe293
Author: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
Date:   Thu Oct 31 16:27:41 2019 +0530

    libnvdimm/namespace: Differentiate between probe mapping and runtime mapping
    
    The nvdimm core currently maps the full namespace to an ioremap range
    while probing the namespace mode. This can result in probe failures on
    architectures that have limited ioremap space.
    
    For example, with a large btt namespace that consumes most of I/O remap
    range, depending on the sequence of namespace initialization, the user
    can find a pfn namespace initialization failure due to unavailable I/O
    remap space which nvdimm core uses for temporary mapping.
    
    nvdimm core can avoid this failure by only mapping the reserved info
    block area to check for pfn superblock type and map the full namespace
    resource only before using the namespace.
    
    Given that personalities like BTT can be layered on top of any namespace
    type create a generic form of devm_nsio_enable (devm_namespace_enable)
    and use it inside the per-personality attach routines. Now
    devm_namespace_enable() is always paired with disable unless the mapping
    is going to be used for long term runtime access.
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Link: https://lore.kernel.org/r/20191017073308.32645-1-aneesh.kumar@linux.ibm.com
    [djbw: reworks to move devm_namespace_{en,dis}able into *attach helpers]
    Reported-by: kbuild test robot <lkp@intel.com>
    Link: https://lore.kernel.org/r/20191031105741.102793-2-aneesh.kumar@linux.ibm.com
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index ee5c04070ef9..a9f338d01a55 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -212,6 +212,11 @@ struct nd_dax {
 	struct nd_pfn nd_pfn;
 };
 
+static inline u32 nd_info_block_reserve(void)
+{
+	return ALIGN(SZ_8K, PAGE_SIZE);
+}
+
 enum nd_async_mode {
 	ND_SYNC,
 	ND_ASYNC,
@@ -370,29 +375,20 @@ const char *nvdimm_namespace_disk_name(struct nd_namespace_common *ndns,
 unsigned int pmem_sector_size(struct nd_namespace_common *ndns);
 void nvdimm_badblocks_populate(struct nd_region *nd_region,
 		struct badblocks *bb, const struct resource *res);
+int devm_namespace_enable(struct device *dev, struct nd_namespace_common *ndns,
+		resource_size_t size);
+void devm_namespace_disable(struct device *dev,
+		struct nd_namespace_common *ndns);
 #if IS_ENABLED(CONFIG_ND_CLAIM)
-
 /* max struct page size independent of kernel config */
 #define MAX_STRUCT_PAGE_SIZE 64
-
 int nvdimm_setup_pfn(struct nd_pfn *nd_pfn, struct dev_pagemap *pgmap);
-int devm_nsio_enable(struct device *dev, struct nd_namespace_io *nsio);
-void devm_nsio_disable(struct device *dev, struct nd_namespace_io *nsio);
 #else
 static inline int nvdimm_setup_pfn(struct nd_pfn *nd_pfn,
 				   struct dev_pagemap *pgmap)
 {
 	return -ENXIO;
 }
-static inline int devm_nsio_enable(struct device *dev,
-		struct nd_namespace_io *nsio)
-{
-	return -ENXIO;
-}
-static inline void devm_nsio_disable(struct device *dev,
-		struct nd_namespace_io *nsio)
-{
-}
 #endif
 int nd_blk_region_init(struct nd_region *nd_region);
 int nd_region_activate(struct nd_region *nd_region);

commit f537669978a7abae29c1d3b489f300e4d8f47005
Author: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
Date:   Thu Sep 5 21:16:03 2019 +0530

    libnvdimm/dax: Pick the right alignment default when creating dax devices
    
    Allow arch to provide the supported alignments and use hugepage alignment only
    if we support hugepage. Right now we depend on compile time configs whereas this
    patch switch this to runtime discovery.
    
    Architectures like ppc64 can have THP enabled in code, but then can have
    hugepage size disabled by the hypervisor. This allows us to create dax devices
    with PAGE_SIZE alignment in this case.
    
    Existing dax namespace with alignment larger than PAGE_SIZE will fail to
    initialize in this specific case. We still allow fsdax namespace initialization.
    
    With respect to identifying whether to enable hugepage fault for a dax device,
    if THP is enabled during compile, we default to taking hugepage fault and in dax
    fault handler if we find the fault size > alignment we retry with PAGE_SIZE
    fault size.
    
    This also addresses the below failure scenario on ppc64
    
    ndctl create-namespace --mode=devdax  | grep align
     "align":16777216,
     "align":16777216
    
    cat /sys/devices/ndbus0/region0/dax0.0/supported_alignments
     65536 16777216
    
    daxio.static-debug  -z -o /dev/dax0.0
      Bus error (core dumped)
    
      $ dmesg | tail
       lpar: Failed hash pte insert with error -4
       hash-mmu: mm: Hashing failure ! EA=0x7fff17000000 access=0x8000000000000006 current=daxio
       hash-mmu:     trap=0x300 vsid=0x22cb7a3 ssize=1 base psize=2 psize 10 pte=0xc000000501002b86
       daxio[3860]: bus error (7) at 7fff17000000 nip 7fff973c007c lr 7fff973bff34 code 2 in libpmem.so.1.0.0[7fff973b0000+20000]
       daxio[3860]: code: 792945e4 7d494b78 e95f0098 7d494b78 f93f00a0 4800012c e93f0088 f93f0120
       daxio[3860]: code: e93f00a0 f93f0128 e93f0120 e95f0128 <f9490000> e93f0088 39290008 f93f0110
    
    The failure was due to guest kernel using wrong page size.
    
    The namespaces created with 16M alignment will appear as below on a config with
    16M page size disabled.
    
    $ ndctl list -Ni
    [
      {
        "dev":"namespace0.1",
        "mode":"fsdax",
        "map":"dev",
        "size":5351931904,
        "uuid":"fc6e9667-461a-4718-82b4-69b24570bddb",
        "align":16777216,
        "blockdev":"pmem0.1",
        "supported_alignments":[
          65536
        ]
      },
      {
        "dev":"namespace0.0",
        "mode":"fsdax",    <==== devdax 16M alignment marked disabled.
        "map":"mem",
        "size":5368709120,
        "uuid":"a4bdf81a-f2ee-4bc6-91db-7b87eddd0484",
        "state":"disabled"
      }
    ]
    
    Cc: linux-mm@kvack.org
    Cc: "Kirill A. Shutemov" <kirill@shutemov.name>
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Link: https://lore.kernel.org/r/20190905154603.10349-8-aneesh.kumar@linux.ibm.com
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index e89af4b2d8e9..ee5c04070ef9 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -289,11 +289,7 @@ static inline struct device *nd_btt_create(struct nd_region *nd_region)
 struct nd_pfn *to_nd_pfn(struct device *dev);
 #if IS_ENABLED(CONFIG_NVDIMM_PFN)
 
-#ifdef CONFIG_TRANSPARENT_HUGEPAGE
-#define PFN_DEFAULT_ALIGNMENT HPAGE_PMD_SIZE
-#else
-#define PFN_DEFAULT_ALIGNMENT PAGE_SIZE
-#endif
+#define MAX_NVDIMM_ALIGN	4
 
 int nd_pfn_probe(struct device *dev, struct nd_namespace_common *ndns);
 bool is_nd_pfn(struct device *dev);

commit e96f0bf2ec92da2bc9c11b0d69e9086f076e7f0b
Author: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
Date:   Thu Sep 5 21:15:59 2019 +0530

    libnvdimm/pfn_dev: Add a build check to make sure we notice when struct page size change
    
    Namespaces created with PFN_MODE_PMEM mode stores struct page in the reserve
    block area. We need to make sure we account for the right struct page
    size while doing this. Instead of directly depending on sizeof(struct page)
    which can change based on different kernel config option, use the max struct
    page size (64) while calculating the reserve block area. This makes sure pmem
    device can be used across kernels built with different configs.
    
    If the above assumption of max struct page size change, we need to update the
    reserve block allocation space for new namespaces created.
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Link: https://lore.kernel.org/r/20190905154603.10349-4-aneesh.kumar@linux.ibm.com
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 1b9955651379..e89af4b2d8e9 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -375,6 +375,10 @@ unsigned int pmem_sector_size(struct nd_namespace_common *ndns);
 void nvdimm_badblocks_populate(struct nd_region *nd_region,
 		struct badblocks *bb, const struct resource *res);
 #if IS_ENABLED(CONFIG_ND_CLAIM)
+
+/* max struct page size independent of kernel config */
+#define MAX_STRUCT_PAGE_SIZE 64
+
 int nvdimm_setup_pfn(struct nd_pfn *nd_pfn, struct dev_pagemap *pgmap);
 int devm_nsio_enable(struct device *dev, struct nd_namespace_io *nsio);
 void devm_nsio_disable(struct device *dev, struct nd_namespace_io *nsio);

commit c5d4355d10d414a96ca870b731756b89d068d57a
Author: Pankaj Gupta <pagupta@redhat.com>
Date:   Fri Jul 5 19:33:22 2019 +0530

    libnvdimm: nd_region flush callback support
    
    This patch adds functionality to perform flush from guest
    to host over VIRTIO. We are registering a callback based
    on 'nd_region' type. virtio_pmem driver requires this special
    flush function. For rest of the region types we are registering
    existing flush function. Report error returned by host fsync
    failure to userspace.
    
    Signed-off-by: Pankaj Gupta <pagupta@redhat.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index d24304c0e6d7..1b9955651379 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -155,6 +155,7 @@ struct nd_region {
 	struct badblocks bb;
 	struct nd_interleave_set *nd_set;
 	struct nd_percpu_lane __percpu *lane;
+	int (*flush)(struct nd_region *nd_region, struct bio *bio);
 	struct nd_mapping mapping[0];
 };
 

commit 5b497af42fab12cadc0e29bcb7052cf9963603f5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed May 29 07:18:09 2019 -0700

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 295
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of version 2 of the gnu general public license as
      published by the free software foundation this program is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 64 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190529141901.894819585@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 191d62af0e51..d24304c0e6d7 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -1,14 +1,6 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
 /*
  * Copyright(c) 2013-2015 Intel Corporation. All rights reserved.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
  */
 #ifndef __ND_H__
 #define __ND_H__

commit c4703ce11c23423d4b46e3d59aef7979814fd608
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Apr 30 21:51:21 2019 -0700

    libnvdimm/namespace: Fix label tracking error
    
    Users have reported intermittent occurrences of DIMM initialization
    failures due to duplicate allocations of address capacity detected in
    the labels, or errors of the form below, both have the same root cause.
    
        nd namespace1.4: failed to track label: 0
        WARNING: CPU: 17 PID: 1381 at drivers/nvdimm/label.c:863
    
        RIP: 0010:__pmem_label_update+0x56c/0x590 [libnvdimm]
        Call Trace:
         ? nd_pmem_namespace_label_update+0xd6/0x160 [libnvdimm]
         nd_pmem_namespace_label_update+0xd6/0x160 [libnvdimm]
         uuid_store+0x17e/0x190 [libnvdimm]
         kernfs_fop_write+0xf0/0x1a0
         vfs_write+0xb7/0x1b0
         ksys_write+0x57/0xd0
         do_syscall_64+0x60/0x210
    
    Unfortunately those reports were typically with a busy parallel
    namespace creation / destruction loop making it difficult to see the
    components of the bug. However, Jane provided a simple reproducer using
    the work-in-progress sub-section implementation.
    
    When ndctl is reconfiguring a namespace it may take an existing defunct
    / disabled namespace and reconfigure it with a new uuid and other
    parameters. Critically namespace_update_uuid() takes existing address
    resources and renames them for the new namespace to use / reconfigure as
    it sees fit. The bug is that this rename only happens in the resource
    tracking tree. Existing labels with the old uuid are not reaped leading
    to a scenario where multiple active labels reference the same span of
    address range.
    
    Teach namespace_update_uuid() to flag any references to the old uuid for
    reaping at the next label update attempt.
    
    Cc: <stable@vger.kernel.org>
    Fixes: bf9bccc14c05 ("libnvdimm: pmem label sets and namespace instantiation")
    Link: https://github.com/pmem/ndctl/issues/91
    Reported-by: Jane Chu <jane.chu@oracle.com>
    Reported-by: Jeff Moyer <jmoyer@redhat.com>
    Reported-by: Erwin Tsaur <erwin.tsaur@oracle.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index a5ac3b240293..191d62af0e51 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -113,8 +113,12 @@ struct nd_percpu_lane {
 	spinlock_t lock;
 };
 
+enum nd_label_flags {
+	ND_LABEL_REAP,
+};
 struct nd_label_ent {
 	struct list_head list;
+	unsigned long flags;
 	struct nd_namespace_label *label;
 };
 

commit f67e3fb4891287b8248ebb3320f794b9f5e782d4
Merge: 477558d7e8d8 c221c0b0308f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Mar 16 13:05:32 2019 -0700

    Merge tag 'devdax-for-5.1' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm
    
    Pull device-dax updates from Dan Williams:
     "New device-dax infrastructure to allow persistent memory and other
      "reserved" / performance differentiated memories, to be assigned to
      the core-mm as "System RAM".
    
      Some users want to use persistent memory as additional volatile
      memory. They are willing to cope with potential performance
      differences, for example between DRAM and 3D Xpoint, and want to use
      typical Linux memory management apis rather than a userspace memory
      allocator layered over an mmap() of a dax file. The administration
      model is to decide how much Persistent Memory (pmem) to use as System
      RAM, create a device-dax-mode namespace of that size, and then assign
      it to the core-mm. The rationale for device-dax is that it is a
      generic memory-mapping driver that can be layered over any "special
      purpose" memory, not just pmem. On subsequent boots udev rules can be
      used to restore the memory assignment.
    
      One implication of using pmem as RAM is that mlock() no longer keeps
      data off persistent media. For this reason it is recommended to enable
      NVDIMM Security (previously merged for 5.0) to encrypt pmem contents
      at rest. We considered making this recommendation an actively enforced
      requirement, but in the end decided to leave it as a distribution /
      administrator policy to allow for emulation and test environments that
      lack security capable NVDIMMs.
    
      Summary:
    
       - Replace the /sys/class/dax device model with /sys/bus/dax, and
         include a compat driver so distributions can opt-in to the new ABI.
    
       - Allow for an alternative driver for the device-dax address-range
    
       - Introduce the 'kmem' driver to hotplug / assign a device-dax
         address-range to the core-mm.
    
       - Arrange for the device-dax target-node to be onlined so that the
         newly added memory range can be uniquely referenced by numa apis"
    
    NOTE! I'm not entirely happy with the whole "PMEM as RAM" model because
    we currently have special - and very annoying rules in the kernel about
    accessing PMEM only with the "MC safe" accessors, because machine checks
    inside the regular repeat string copy functions can be fatal in some
    (not described) circumstances.
    
    And apparently the PMEM modules can cause that a lot more than regular
    RAM.  The argument is that this happens because PMEM doesn't necessarily
    get scrubbed at boot like RAM does, but that is planned to be added for
    the user space tooling.
    
    Quoting Dan from another email:
     "The exposure can be reduced in the volatile-RAM case by scanning for
      and clearing errors before it is onlined as RAM. The userspace tooling
      for that can be in place before v5.1-final. There's also runtime
      notifications of errors via acpi_nfit_uc_error_notify() from
      background scrubbers on the DIMM devices. With that mechanism the
      kernel could proactively clear newly discovered poison in the volatile
      case, but that would be additional development more suitable for v5.2.
    
      I understand the concern, and the need to highlight this issue by
      tapping the brakes on feature development, but I don't see PMEM as RAM
      making the situation worse when the exposure is also there via DAX in
      the PMEM case. Volatile-RAM is arguably a safer use case since it's
      possible to repair pages where the persistent case needs active
      application coordination"
    
    * tag 'devdax-for-5.1' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm:
      device-dax: "Hotplug" persistent memory for use like normal RAM
      mm/resource: Let walk_system_ram_range() search child resources
      mm/memory-hotplug: Allow memory resources to be children
      mm/resource: Move HMM pr_debug() deeper into resource code
      mm/resource: Return real error codes from walk failures
      device-dax: Add a 'modalias' attribute to DAX 'bus' devices
      device-dax: Add a 'target_node' attribute
      device-dax: Auto-bind device after successful new_id
      acpi/nfit, device-dax: Identify differentiated memory with a unique numa-node
      device-dax: Add /sys/class/dax backwards compatibility
      device-dax: Add support for a dax override driver
      device-dax: Move resource pinning+mapping into the common driver
      device-dax: Introduce bus + driver model
      device-dax: Start defining a dax bus model
      device-dax: Remove multi-resource infrastructure
      device-dax: Kill dax_region base
      device-dax: Kill dax_region ida

commit 1cd7386549f9b6f2f230da54aa9e7fe2d6c216d2
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sat Jan 19 08:45:56 2019 -0800

    libnvdimm/security: Require nvdimm_security_setup_events() to succeed
    
    The following warning:
    
        ACPI0012:00: security event setup failed: -19
    
    ...is meant to capture exceptional failures of sysfs_get_dirent(),
    however it will also fail in the common case when security support is
    disabled. A few issues:
    
    1/ A dev_warn() report for a common case is too chatty
    2/ The setup of this notifier is generic, no need for it to be driven
       from the nfit driver, it can exist completely in the core.
    3/ If it fails for any reason besides security support being disabled,
       that's fatal and should abort DIMM activation. Userspace may hang if
       it never gets overwrite notifications.
    4/ The dirent needs to be released.
    
    Move the call to the core 'dimm' driver, make it conditional on security
    support being active, make it fatal for the exceptional case, add the
    missing sysfs_put() at device disable time.
    
    Fixes: 7d988097c546 ("...Add security DSM overwrite support")
    Reviewed-by: Dave Jiang <dave.jiang@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index cfde992684e7..379bf4305e61 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -250,6 +250,7 @@ long nvdimm_clear_poison(struct device *dev, phys_addr_t phys,
 void nvdimm_set_aliasing(struct device *dev);
 void nvdimm_set_locked(struct device *dev);
 void nvdimm_clear_locked(struct device *dev);
+int nvdimm_security_setup_events(struct device *dev);
 #if IS_ENABLED(CONFIG_NVDIMM_KEYS)
 int nvdimm_security_unlock(struct device *dev);
 #else

commit 8fc5c73554db0ac18c0c6ac5b2099ab917f83bdf
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Nov 9 12:43:07 2018 -0800

    acpi/nfit, device-dax: Identify differentiated memory with a unique numa-node
    
    Persistent memory, as described by the ACPI NFIT (NVDIMM Firmware
    Interface Table), is the first known instance of a memory range
    described by a unique "target" proximity domain. Where "initiator" and
    "target" proximity domains is an approach that the ACPI HMAT
    (Heterogeneous Memory Attributes Table) uses to described the unique
    performance properties of a memory range relative to a given initiator
    (e.g. CPU or DMA device).
    
    Currently the numa-node for a /dev/pmemX block-device or /dev/daxX.Y
    char-device follows the traditional notion of 'numa-node' where the
    attribute conveys the closest online numa-node. That numa-node attribute
    is useful for cpu-binding and memory-binding processes *near* the
    device. However, when the memory range backing a 'pmem', or 'dax' device
    is onlined (memory hot-add) the memory-only-numa-node representing that
    address needs to be differentiated from the set of online nodes. In
    other words, the numa-node association of the device depends on whether
    you can bind processes *near* the cpu-numa-node in the offline
    device-case, or bind process *on* the memory-range directly after the
    backing address range is onlined.
    
    Allow for the case that platform firmware describes persistent memory
    with a unique proximity domain, i.e. when it is distinct from the
    proximity of DRAM and CPUs that are on the same socket. Plumb the Linux
    numa-node translation of that proximity through the libnvdimm region
    device to namespaces that are in device-dax mode. With this in place the
    proposed kmem driver [1] can optionally discover a unique numa-node
    number for the address range as it transitions the memory from an
    offline state managed by a device-driver to an online memory range
    managed by the core-mm.
    
    [1]: https://lore.kernel.org/lkml/20181022201317.8558C1D8@viggo.jf.intel.com
    
    Reported-by: Fan Du <fan.du@intel.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: "Oliver O'Halloran" <oohall@gmail.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Jérôme Glisse <jglisse@redhat.com>
    Reviewed-by: Yang Shi <yang.shi@linux.alibaba.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index cfde992684e7..0b3d7595b3cb 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -153,7 +153,7 @@ struct nd_region {
 	u16 ndr_mappings;
 	u64 ndr_size;
 	u64 ndr_start;
-	int id, num_lanes, ro, numa_node;
+	int id, num_lanes, ro, numa_node, target_node;
 	void *provider_data;
 	struct kernfs_node *bb_state;
 	struct badblocks bb;

commit 4c6926a23b76ea23403976290cd45a7a143f6500
Author: Dave Jiang <dave.jiang@intel.com>
Date:   Thu Dec 6 12:40:01 2018 -0800

    acpi/nfit, libnvdimm: Add unlock of nvdimm support for Intel DIMMs
    
    Add support to unlock the dimm via the kernel key management APIs. The
    passphrase is expected to be pulled from userspace through keyutils.
    The key management and sysfs attributes are libnvdimm generic.
    
    Encrypted keys are used to protect the nvdimm passphrase at rest. The
    master key can be a trusted-key sealed in a TPM, preferred, or an
    encrypted-key, more flexible, but more exposure to a potential attacker.
    
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    Co-developed-by: Dan Williams <dan.j.williams@intel.com>
    Reported-by: Randy Dunlap <rdunlap@infradead.org>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index e79cc8e5c114..cfde992684e7 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -250,6 +250,14 @@ long nvdimm_clear_poison(struct device *dev, phys_addr_t phys,
 void nvdimm_set_aliasing(struct device *dev);
 void nvdimm_set_locked(struct device *dev);
 void nvdimm_clear_locked(struct device *dev);
+#if IS_ENABLED(CONFIG_NVDIMM_KEYS)
+int nvdimm_security_unlock(struct device *dev);
+#else
+static inline int nvdimm_security_unlock(struct device *dev)
+{
+	return 0;
+}
+#endif
 struct nd_btt *to_nd_btt(struct device *dev);
 
 struct nd_gen_sb {

commit 2d657d17f72d2ae70c02f0d0ea6a04ad0f016b57
Author: Alexander Duyck <alexander.h.duyck@linux.intel.com>
Date:   Wed Oct 10 16:39:20 2018 -0700

    nvdimm: Split label init out from the logic for getting config data
    
    This patch splits the initialization of the label data into two functions.
    One for doing the init, and another for reading the actual configuration
    data. The idea behind this is that by doing this we create a symmetry
    between the getting and setting of config data in that we have a function
    for both. In addition it will make it easier for us to identify the bits
    that are related to init versus the pieces that are a wrapper for reading
    data from the ACPI interface.
    
    So for example by splitting things out like this it becomes much more
    obvious that we were performing checks that weren't necessarily related to
    the set/get operations such as relying on ndd->data being present when the
    set and get ops should not care about a locally cached copy of the label
    area.
    
    Reviewed-by: Toshi Kani <toshi.kani@hpe.com>
    Signed-off-by: Alexander Duyck <alexander.h.duyck@linux.intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 98317e7ce5b5..e79cc8e5c114 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -241,6 +241,8 @@ struct nvdimm_drvdata *to_ndd(struct nd_mapping *nd_mapping);
 int nvdimm_check_config_data(struct device *dev);
 int nvdimm_init_nsarea(struct nvdimm_drvdata *ndd);
 int nvdimm_init_config_data(struct nvdimm_drvdata *ndd);
+int nvdimm_get_config_data(struct nvdimm_drvdata *ndd, void *buf,
+			   size_t offset, size_t len);
 int nvdimm_set_config_data(struct nvdimm_drvdata *ndd, size_t offset,
 		void *buf, size_t len);
 long nvdimm_clear_poison(struct device *dev, phys_addr_t phys,

commit 828bf6e904eb8fc8969333568802689fbbf07a40
Merge: b326272010b6 286e87718103
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Aug 25 18:13:10 2018 -0700

    Merge tag 'libnvdimm-for-4.19_misc' of gitolite.kernel.org:pub/scm/linux/kernel/git/nvdimm/nvdimm
    
    Pull libnvdimm updates from Dave Jiang:
     "Collection of misc libnvdimm patches for 4.19 submission:
    
       - Adding support to read locked nvdimm capacity.
    
       - Change test code to make DSM failure code injection an override.
    
       - Add support for calculate maximum contiguous area for namespace.
    
       - Add support for queueing a short ARS when there is on going ARS for
         nvdimm.
    
       - Allow NULL to be passed in to ->direct_access() for kaddr and pfn
         params.
    
       - Improve smart injection support for nvdimm emulation testing.
    
       - Fix test code that supports for emulating controller temperature.
    
       - Fix hang on error before devm_memremap_pages()
    
       - Fix a bug that causes user memory corruption when data returned to
         user for ars_status.
    
       - Maintainer updates for Ross Zwisler emails and adding Jan Kara to
         fsdax"
    
    * tag 'libnvdimm-for-4.19_misc' of gitolite.kernel.org:pub/scm/linux/kernel/git/nvdimm/nvdimm:
      libnvdimm: fix ars_status output length calculation
      device-dax: avoid hang on error before devm_memremap_pages()
      tools/testing/nvdimm: improve emulation of smart injection
      filesystem-dax: Do not request kaddr and pfn when not required
      md/dm-writecache: Don't request pointer dummy_addr when not required
      dax/super: Do not request a pointer kaddr when not required
      tools/testing/nvdimm: kaddr and pfn can be NULL to ->direct_access()
      s390, dcssblk: kaddr and pfn can be NULL to ->direct_access()
      libnvdimm, pmem: kaddr and pfn can be NULL to ->direct_access()
      acpi/nfit: queue issuing of ars when an uc error notification comes in
      libnvdimm: Export max available extent
      libnvdimm: Use max contiguous area for namespace size
      MAINTAINERS: Add Jan Kara for filesystem DAX
      MAINTAINERS: update Ross Zwisler's email address
      tools/testing/nvdimm: Fix support for emulating controller temperature
      tools/testing/nvdimm: Make DSM failure code injection an override
      acpi, nfit: Prefer _DSM over _LSR for namespace label reads
      libnvdimm: Introduce locked DIMM capacity support

commit ddcf35d397976421a4ec1d0d00fbcc027a8cb034
Author: Michael Callahan <michaelcallahan@fb.com>
Date:   Wed Jul 18 04:47:39 2018 -0700

    block: Add and use op_stat_group() for indexing disk_stat fields.
    
    Add and use a new op_stat_group() function for indexing partition stat
    fields rather than indexing them by rq_data_dir() or bio_data_dir().
    This function works similarly to op_is_sync() in that it takes the
    request::cmd_flags or bio::bi_opf flags and determines which stats
    should et updated.
    
    In addition, the second parameter to generic_start_io_acct() and
    generic_end_io_acct() is now a REQ_OP rather than simply a read or
    write bit and it uses op_stat_group() on the parameter to determine
    the stat group.
    
    Note that the partition in_flight counts are not part of the per-cpu
    statistics and as such are not indexed via this function.  It's now
    indexed by op_is_write().
    
    tj: Refreshed on top of v4.17.  Updated to pass around REQ_OP.
    
    Signed-off-by: Michael Callahan <michaelcallahan@fb.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Joshua Morris <josh.h.morris@us.ibm.com>
    Cc: Philipp Reisner <philipp.reisner@linbit.com>
    Cc: Matias Bjorling <mb@lightnvm.io>
    Cc: Kent Overstreet <kent.overstreet@gmail.com>
    Cc: Alasdair Kergon <agk@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 32e0364b48b9..6ee7fd7e4bbd 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -396,16 +396,15 @@ static inline bool nd_iostat_start(struct bio *bio, unsigned long *start)
 		return false;
 
 	*start = jiffies;
-	generic_start_io_acct(disk->queue, bio_data_dir(bio),
-			      bio_sectors(bio), &disk->part0);
+	generic_start_io_acct(disk->queue, bio_op(bio), bio_sectors(bio),
+			      &disk->part0);
 	return true;
 }
 static inline void nd_iostat_end(struct bio *bio, unsigned long start)
 {
 	struct gendisk *disk = bio->bi_disk;
 
-	generic_end_io_acct(disk->queue, bio_data_dir(bio), &disk->part0,
-				start);
+	generic_end_io_acct(disk->queue, bio_op(bio), &disk->part0, start);
 }
 static inline bool is_bad_pmem(struct badblocks *bb, sector_t sector,
 		unsigned int len)

commit 08e6b3c6e3a054f566367740c94b8c1d18e52056
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed Jun 13 09:08:36 2018 -0700

    libnvdimm: Introduce locked DIMM capacity support
    
    When a DIMM is locked its namespace label area may not be. Introduce the
    distinction of locked namespaces to allow namespace enumeration while
    the capacity is locked.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 32e0364b48b9..9d17abd9f8d0 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -357,6 +357,7 @@ struct resource *nvdimm_allocate_dpa(struct nvdimm_drvdata *ndd,
 		struct nd_label_id *label_id, resource_size_t start,
 		resource_size_t n);
 resource_size_t nvdimm_namespace_capacity(struct nd_namespace_common *ndns);
+bool nvdimm_namespace_locked(struct nd_namespace_common *ndns);
 struct nd_namespace_common *nvdimm_namespace_common_probe(struct device *dev);
 int nvdimm_namespace_attach_btt(struct nd_namespace_common *ndns);
 int nvdimm_namespace_detach_btt(struct nd_btt *nd_btt);

commit 9f3a0941fb5efaa4d27911e251dc595034d58baa
Merge: fbe173e3ffbd e13e75b86ef2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 10 10:25:57 2018 -0700

    Merge tag 'libnvdimm-for-4.17' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm
    
    Pull libnvdimm updates from Dan Williams:
     "This cycle was was not something I ever want to repeat as there were
      several late changes that have only now just settled.
    
      Half of the branch up to commit d2c997c0f145 ("fs, dax: use
      page->mapping to warn...") have been in -next for several releases.
      The of_pmem driver and the address range scrub rework were late
      arrivals, and the dax work was scaled back at the last moment.
    
      The of_pmem driver missed a previous merge window due to an oversight.
      A sense of obligation to rectify that miss is why it is included for
      4.17. It has acks from PowerPC folks. Stephen reported a build failure
      that only occurs when merging it with your latest tree, for now I have
      fixed that up by disabling modular builds of of_pmem. A test merge
      with your tree has received a build success report from the 0day robot
      over 156 configs.
    
      An initial version of the ARS rework was submitted before the merge
      window. It is self contained to libnvdimm, a net code reduction, and
      passing all unit tests.
    
      The filesystem-dax changes are based on the wait_var_event()
      functionality from tip/sched/core. However, late review feedback
      showed that those changes regressed truncate performance to a large
      degree. The branch was rewound to drop the truncate behavior change
      and now only includes preparation patches and cleanups (with full acks
      and reviews). The finalization of this dax-dma-vs-trnucate work will
      need to wait for 4.18.
    
      Summary:
    
       - A rework of the filesytem-dax implementation provides for detection
         of unmap operations (truncate / hole punch) colliding with
         in-progress device-DMA. A fix for these collisions remains a
         work-in-progress pending resolution of truncate latency and
         starvation regressions.
    
       - The of_pmem driver expands the users of libnvdimm outside of x86
         and ACPI to describe an implementation of persistent memory on
         PowerPC with Open Firmware / Device tree.
    
       - Address Range Scrub (ARS) handling is completely rewritten to
         account for the fact that ARS may run for 100s of seconds and there
         is no platform defined way to cancel it. ARS will now no longer
         block namespace initialization.
    
       - The NVDIMM Namespace Label implementation is updated to handle
         label areas as small as 1K, down from 128K.
    
       - Miscellaneous cleanups and updates to unit test infrastructure"
    
    * tag 'libnvdimm-for-4.17' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm: (39 commits)
      libnvdimm, of_pmem: workaround OF_NUMA=n build error
      nfit, address-range-scrub: add module option to skip initial ars
      nfit, address-range-scrub: rework and simplify ARS state machine
      nfit, address-range-scrub: determine one platform max_ars value
      powerpc/powernv: Create platform devs for nvdimm buses
      doc/devicetree: Persistent memory region bindings
      libnvdimm: Add device-tree based driver
      libnvdimm: Add of_node to region and bus descriptors
      libnvdimm, region: quiet region probe
      libnvdimm, namespace: use a safe lookup for dimm device name
      libnvdimm, dimm: fix dpa reservation vs uninitialized label area
      libnvdimm, testing: update the default smart ctrl_temperature
      libnvdimm, testing: Add emulation for smart injection commands
      nfit, address-range-scrub: introduce nfit_spa->ars_state
      libnvdimm: add an api to cast a 'struct nd_region' to its 'struct device'
      nfit, address-range-scrub: fix scrub in-progress reporting
      dax, dm: allow device-mapper to operate without dax support
      dax: introduce CONFIG_DAX_DRIVER
      fs, dax: use page->mapping to warn if truncate collides with a busy page
      ext2, dax: introduce ext2_dax_aops
      ...

commit 243f29fe449bbead69076ad861dbe8f51b42c4d7
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Apr 2 13:14:25 2018 -0700

    libnvdimm: add an api to cast a 'struct nd_region' to its 'struct device'
    
    For debug, it is useful for bus providers to be able to retrieve the
    'struct device' associated with an nd_region instance that it
    registered. We already have to_nd_region() to perform the reverse cast
    operation, in fact its duplicate declaration can be removed from the
    private drivers/nvdimm/nd.h header.
    
    Reviewed-by: Dave Jiang <dave.jiang@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 8d6375ee0fda..9dad5d737309 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -341,7 +341,6 @@ static inline struct device *nd_dax_create(struct nd_region *nd_region)
 }
 #endif
 
-struct nd_region *to_nd_region(struct device *dev);
 int nd_region_to_nstype(struct nd_region *nd_region);
 int nd_region_register_namespaces(struct nd_region *nd_region, int *err);
 u64 nd_region_interleave_set_cookie(struct nd_region *nd_region,

commit 233bde21aa43516baa013ef7ac33f3427056db3e
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Wed Mar 14 15:48:06 2018 -0700

    block: Move SECTOR_SIZE and SECTOR_SHIFT definitions into <linux/blkdev.h>
    
    It happens often while I'm preparing a patch for a block driver that
    I'm wondering: is a definition of SECTOR_SIZE and/or SECTOR_SHIFT
    available for this driver? Do I have to introduce definitions of these
    constants before I can use these constants? To avoid this confusion,
    move the existing definitions of SECTOR_SIZE and SECTOR_SHIFT into the
    <linux/blkdev.h> header file such that these become available for all
    block drivers. Make the SECTOR_SIZE definition in the uapi msdos_fs.h
    header file conditional to avoid that including that header file after
    <linux/blkdev.h> causes the compiler to complain about a SECTOR_SIZE
    redefinition.
    
    Note: the SECTOR_SIZE / SECTOR_SHIFT / SECTOR_BITS definitions have
    not been removed from uapi header files nor from NAND drivers in
    which these constants are used for another purpose than converting
    block layer offsets and sizes into a number of sectors.
    
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Reviewed-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 8d6375ee0fda..184e070d50a2 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -29,7 +29,6 @@ enum {
 	 * BTT instance
 	 */
 	ND_MAX_LANES = 256,
-	SECTOR_SHIFT = 9,
 	INT_LBASIZE_ALIGNMENT = 64,
 	NVDIMM_IO_ATOMIC = 1,
 };

commit e8d5134833006a46fcbefc5f4a84d0b62bd520e7
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Dec 29 08:54:05 2017 +0100

    memremap: change devm_memremap_pages interface to use struct dev_pagemap
    
    This new interface is similar to how struct device (and many others)
    work. The caller initializes a 'struct dev_pagemap' as required
    and calls 'devm_memremap_pages'. This allows the pagemap structure to
    be embedded in another structure and thus container_of can be used. In
    this way application specific members can be stored in a containing
    struct.
    
    This will be used by the P2P infrastructure and HMM could probably
    be cleaned up to use it as well (instead of having it's own, similar
    'hmm_devmem_pages_create' function).
    
    Signed-off-by: Logan Gunthorpe <logang@deltatee.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index e958f3724c41..8d6375ee0fda 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -368,15 +368,14 @@ unsigned int pmem_sector_size(struct nd_namespace_common *ndns);
 void nvdimm_badblocks_populate(struct nd_region *nd_region,
 		struct badblocks *bb, const struct resource *res);
 #if IS_ENABLED(CONFIG_ND_CLAIM)
-struct vmem_altmap *nvdimm_setup_pfn(struct nd_pfn *nd_pfn,
-		struct resource *res, struct vmem_altmap *altmap);
+int nvdimm_setup_pfn(struct nd_pfn *nd_pfn, struct dev_pagemap *pgmap);
 int devm_nsio_enable(struct device *dev, struct nd_namespace_io *nsio);
 void devm_nsio_disable(struct device *dev, struct nd_namespace_io *nsio);
 #else
-static inline struct vmem_altmap *nvdimm_setup_pfn(struct nd_pfn *nd_pfn,
-		struct resource *res, struct vmem_altmap *altmap)
+static inline int nvdimm_setup_pfn(struct nd_pfn *nd_pfn,
+				   struct dev_pagemap *pgmap)
 {
-	return ERR_PTR(-ENXIO);
+	return -ENXIO;
 }
 static inline int devm_nsio_enable(struct device *dev,
 		struct nd_namespace_io *nsio)

commit aa9ad44a42b4cf4387f8ecddaf8e51707fdcda5a
Author: Dave Jiang <dave.jiang@intel.com>
Date:   Wed Aug 23 12:48:26 2017 -0700

    libnvdimm: move poison list functions to a new 'badrange' file
    
    nfit_test needs to use the poison list manipulation code as well. Make
    it more generic and in the process rename poison to badrange, and move
    all the related helpers to a new file.
    
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    [vishal: Add badrange.o to nfit_test's Kbuild]
    [vishal: add a missed include in bus.c for the new badrange functions]
    [vishal: rename all instances of 'be' to 'bre']
    Signed-off-by: Vishal Verma <vishal.l.verma@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 156be00e1f76..e958f3724c41 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -34,12 +34,6 @@ enum {
 	NVDIMM_IO_ATOMIC = 1,
 };
 
-struct nd_poison {
-	u64 start;
-	u64 length;
-	struct list_head list;
-};
-
 struct nvdimm_drvdata {
 	struct device *dev;
 	int nslabel_size;

commit d34cb808402898e53b9a9bcbbedd01667a78723b
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Sep 25 11:01:31 2017 -0700

    libnvdimm, dimm: clear 'locked' status on successful DIMM enable
    
    If we successfully enable a DIMM then it must not be locked and we can
    clear the label-read failure condition. Otherwise, we need to reload the
    entire bus provider driver to achieve the same effect, and that can
    disrupt unrelated DIMMs and namespaces.
    
    Fixes: 9d62ed965118 ("libnvdimm: handle locked label storage areas")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 9c758a91372b..156be00e1f76 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -254,6 +254,7 @@ long nvdimm_clear_poison(struct device *dev, phys_addr_t phys,
 		unsigned int len);
 void nvdimm_set_aliasing(struct device *dev);
 void nvdimm_set_locked(struct device *dev);
+void nvdimm_clear_locked(struct device *dev);
 struct nd_btt *to_nd_btt(struct device *dev);
 
 struct nd_gen_sb {

commit 89fd915c402113528750353ad6de9ea68a787e5c
Merge: 66c9457df392 04c3c982fcc0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Sep 11 13:10:57 2017 -0700

    Merge tag 'libnvdimm-for-4.14' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm
    
    Pull libnvdimm from Dan Williams:
     "A rework of media error handling in the BTT driver and other updates.
      It has appeared in a few -next releases and collected some late-
      breaking build-error and warning fixups as a result.
    
      Summary:
    
       - Media error handling support in the Block Translation Table (BTT)
         driver is reworked to address sleeping-while-atomic locking and
         memory-allocation-context conflicts.
    
       - The dax_device lookup overhead for xfs and ext4 is moved out of the
         iomap hot-path to a mount-time lookup.
    
       - A new 'ecc_unit_size' sysfs attribute is added to advertise the
         read-modify-write boundary property of a persistent memory range.
    
       - Preparatory fix-ups for arm and powerpc pmem support are included
         along with other miscellaneous fixes"
    
    * tag 'libnvdimm-for-4.14' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm: (26 commits)
      libnvdimm, btt: fix format string warnings
      libnvdimm, btt: clean up warning and error messages
      ext4: fix null pointer dereference on sbi
      libnvdimm, nfit: move the check on nd_reserved2 to the endpoint
      dax: fix FS_DAX=n BLOCK=y compilation
      libnvdimm: fix integer overflow static analysis warning
      libnvdimm, nd_blk: remove mmio_flush_range()
      libnvdimm, btt: rework error clearing
      libnvdimm: fix potential deadlock while clearing errors
      libnvdimm, btt: cache sector_size in arena_info
      libnvdimm, btt: ensure that flags were also unchanged during a map_read
      libnvdimm, btt: refactor map entry operations with macros
      libnvdimm, btt: fix a missed NVDIMM_IO_ATOMIC case in the write path
      libnvdimm, nfit: export an 'ecc_unit_size' sysfs attribute
      ext4: perform dax_device lookup at mount
      ext2: perform dax_device lookup at mount
      xfs: perform dax_device lookup at mount
      dax: introduce a fs_dax_get_by_bdev() helper
      libnvdimm, btt: check memory allocation failure
      libnvdimm, label: fix index block size calculation
      ...

commit 02881768695da29772f6f9e0d857a8637c6b0e90
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Aug 29 18:28:18 2017 -0700

    libnvdimm, label: fix index block size calculation
    
    The old calculation assumed that the label space was 128k and the label
    size is 128. With v1.2 labels where the label size is 256 this
    calculation will return zero. We are saved by the fact that the
    nsindex_size is always pre-initialized from a previous 128 byte
    assumption and we are lucky that the index sizes turn out the same.
    
    Fix this going forward in case we start encountering different
    geometries of label areas besides 128k.
    
    Since the label size can change from one call to the next, drop the
    caching of nsindex_size.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 251c7e6d2588..023fc93e21a5 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -42,7 +42,7 @@ struct nd_poison {
 
 struct nvdimm_drvdata {
 	struct device *dev;
-	int nsindex_size, nslabel_size;
+	int nslabel_size;
 	struct nd_cmd_get_config_size nsarea;
 	void *data;
 	int ns_current, ns_next;

commit 74d46992e0d9dee7f1f376de0d56d31614c8a17a
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Aug 23 19:10:32 2017 +0200

    block: replace bi_bdev with a gendisk pointer and partitions index
    
    This way we don't need a block_device structure to submit I/O.  The
    block_device has different life time rules from the gendisk and
    request_queue and is usually only available when the block device node
    is open.  Other callers need to explicitly create one (e.g. the lightnvm
    passthrough code, or the new nvme multipathing code).
    
    For the actual I/O path all that we need is the gendisk, which exists
    once per block device.  But given that the block layer also does
    partition remapping we additionally need a partition index, which is
    used for said remapping in generic_make_request.
    
    Note that all the block drivers generally want request_queue or
    sometimes the gendisk, so this removes a layer of indirection all
    over the stack.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 73062da3177f..a87f793f2945 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -390,7 +390,7 @@ int nd_region_activate(struct nd_region *nd_region);
 void __nd_iostat_start(struct bio *bio, unsigned long *start);
 static inline bool nd_iostat_start(struct bio *bio, unsigned long *start)
 {
-	struct gendisk *disk = bio->bi_bdev->bd_disk;
+	struct gendisk *disk = bio->bi_disk;
 
 	if (!blk_queue_io_stat(disk->queue))
 		return false;
@@ -402,7 +402,7 @@ static inline bool nd_iostat_start(struct bio *bio, unsigned long *start)
 }
 static inline void nd_iostat_end(struct bio *bio, unsigned long start)
 {
-	struct gendisk *disk = bio->bi_bdev->bd_disk;
+	struct gendisk *disk = bio->bi_disk;
 
 	generic_end_io_acct(disk->queue, bio_data_dir(bio), &disk->part0,
 				start);

commit b2c48f9f95cba395e16020bef1fdfc248f53030c
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Aug 11 17:36:54 2017 -0700

    libnvdimm: rename nd_sector_size_{show,store} to nd_size_select_{show,store}
    
    Prepare for other another consumer of this size selection scheme that is
    not a 'sector size'.
    
    Cc: Oliver O'Halloran <oohall@gmail.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index a08fc2e24fb3..251c7e6d2588 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -234,10 +234,10 @@ void nd_device_unregister(struct device *dev, enum nd_async_mode mode);
 void nd_device_notify(struct device *dev, enum nvdimm_event event);
 int nd_uuid_store(struct device *dev, u8 **uuid_out, const char *buf,
 		size_t len);
-ssize_t nd_sector_size_show(unsigned long current_lbasize,
+ssize_t nd_size_select_show(unsigned long current_size,
 		const unsigned long *supported, char *buf);
-ssize_t nd_sector_size_store(struct device *dev, const char *buf,
-		unsigned long *current_lbasize, const unsigned long *supported);
+ssize_t nd_size_select_store(struct device *dev, const char *buf,
+		unsigned long *current_size, const unsigned long *supported);
 int __init nvdimm_init(void);
 int __init nd_region_init(void);
 int __init nd_label_init(void);

commit d62e26b3ffd28f16ddae85a1babd0303a1a6dfb6
Author: Jens Axboe <axboe@kernel.dk>
Date:   Fri Jun 30 21:55:08 2017 -0600

    block: pass in queue to inflight accounting
    
    No functional change in this patch, just in preparation for
    basing the inflight mechanism on the queue in question.
    
    Reviewed-by: Bart Van Assche <bart.vanassche@wdc.com>
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index e1b5715bd91f..73062da3177f 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -396,7 +396,7 @@ static inline bool nd_iostat_start(struct bio *bio, unsigned long *start)
 		return false;
 
 	*start = jiffies;
-	generic_start_io_acct(bio_data_dir(bio),
+	generic_start_io_acct(disk->queue, bio_data_dir(bio),
 			      bio_sectors(bio), &disk->part0);
 	return true;
 }
@@ -404,7 +404,8 @@ static inline void nd_iostat_end(struct bio *bio, unsigned long start)
 {
 	struct gendisk *disk = bio->bi_bdev->bd_disk;
 
-	generic_end_io_acct(bio_data_dir(bio), &disk->part0, start);
+	generic_end_io_acct(disk->queue, bio_data_dir(bio), &disk->part0,
+				start);
 }
 static inline bool is_bad_pmem(struct badblocks *bb, sector_t sector,
 		unsigned int len)

commit 401c0a19c6c22efcaff85d5a64a396f9130da2ca
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Aug 4 17:20:16 2017 -0700

    nfit, libnvdimm, region: export 'position' in mapping info
    
    It is useful to be able to know the position of a DIMM in an
    interleave-set. Consider the case where the order of the DIMMs changes
    causing a namespace to be invalidated because the interleave-set cookie no
    longer matches. If the before and after state of each DIMM position is
    known this state debugged by the system owner.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index e9fa9e84b364..a08fc2e24fb3 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -134,6 +134,7 @@ struct nd_mapping {
 	struct nvdimm *nvdimm;
 	u64 start;
 	u64 size;
+	int position;
 	struct list_head labels;
 	struct mutex lock;
 	/*

commit 0dd69643061d78f3f9047c2382d8d77cca1ac943
Author: Oliver O'Halloran <oohall@gmail.com>
Date:   Tue Jun 27 19:56:33 2017 +1000

    libnvdimm: Stop using HPAGE_SIZE
    
    Currently libnvdimm uses HPAGE_SIZE as the default alignment for DAX and
    PFN devices. HPAGE_SIZE is the default hugetlbfs page size and when
    hugetlbfs is disabled it defaults to PAGE_SIZE. Given DAX has more
    in common with THP than hugetlbfs we should proably be using
    HPAGE_PMD_SIZE, but this is undefined when THP is disabled so lets just
    give it a new name.
    
    The other usage of HPAGE_SIZE in libnvdimm is when determining how large
    the altmap should be. For the reasons mentioned above it doesn't really
    make sense to use HPAGE_SIZE here either. PMD_SIZE seems to be safe to
    use in generic code and it happens to match the vmemmap allocation block
    on x86 and Power. It's still a hack, but it's a slightly nicer hack.
    
    Signed-off-by: Oliver O'Halloran <oohall@gmail.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index e1b5715bd91f..e9fa9e84b364 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -285,6 +285,13 @@ static inline struct device *nd_btt_create(struct nd_region *nd_region)
 
 struct nd_pfn *to_nd_pfn(struct device *dev);
 #if IS_ENABLED(CONFIG_NVDIMM_PFN)
+
+#ifdef CONFIG_TRANSPARENT_HUGEPAGE
+#define PFN_DEFAULT_ALIGNMENT HPAGE_PMD_SIZE
+#else
+#define PFN_DEFAULT_ALIGNMENT PAGE_SIZE
+#endif
+
 int nd_pfn_probe(struct device *dev, struct nd_namespace_common *ndns);
 bool is_nd_pfn(struct device *dev);
 struct device *nd_pfn_create(struct nd_region *nd_region);

commit 14e494542636b7a685c5bf27e695e3bb9ec3fe7d
Author: Vishal Verma <vishal.l.verma@intel.com>
Date:   Wed Jun 28 14:25:00 2017 -0600

    libnvdimm, btt: BTT updates for UEFI 2.7 format
    
    The UEFI 2.7 specification defines an updated BTT metadata format,
    bumping the revision to 2.0. Add support for the new format, while
    retaining compatibility for the old 1.1 format.
    
    Cc: Toshi Kani <toshi.kani@hpe.com>
    Cc: Linda Knippers <linda.knippers@hpe.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Vishal Verma <vishal.l.verma@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index e802c877d783..e1b5715bd91f 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -195,6 +195,9 @@ struct nd_btt {
 	u64 size;
 	u8 *uuid;
 	int id;
+	int initial_offset;
+	u16 version_major;
+	u16 version_minor;
 };
 
 enum nd_pfn_mode {

commit 975750a98c26769fe54785579f4b26c961a7a6f4
Author: Toshi Kani <toshi.kani@hpe.com>
Date:   Mon Jun 12 16:25:11 2017 -0600

    libnvdimm, pmem: Add sysfs notifications to badblocks
    
    Sysfs "badblocks" information may be updated during run-time that:
     - MCE, SCI, and sysfs "scrub" may add new bad blocks
     - Writes and ioctl() may clear bad blocks
    
    Add support to send sysfs notifications to sysfs "badblocks" file
    under region and pmem directories when their badblocks information
    is re-evaluated (but is not necessarily changed) during run-time.
    
    Signed-off-by: Toshi Kani <toshi.kani@hpe.com>
    Cc: Vishal Verma <vishal.l.verma@intel.com>
    Cc: Linda Knippers <linda.knippers@hpe.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 8cabd836df0e..e802c877d783 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -161,6 +161,7 @@ struct nd_region {
 	u64 ndr_start;
 	int id, num_lanes, ro, numa_node;
 	void *provider_data;
+	struct kernfs_node *bb_state;
 	struct badblocks bb;
 	struct nd_interleave_set *nd_set;
 	struct nd_percpu_lane __percpu *lane;

commit b3fde74ea195d2f9f49830a29f971a0aab4cd67a
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sun Jun 4 10:18:39 2017 +0900

    libnvdimm, label: add address abstraction identifiers
    
    Starting with v1.2 labels, 'address abstractions' can be hinted via an
    address abstraction id that implies an info-block format. The standard
    address abstraction in the specification is the v2 format of the
    Block-Translation-Table (BTT). Support for that is saved for a later
    patch, for now we add support for the Linux supported address
    abstractions BTT (v1), PFN, and DAX.
    
    The new 'holder_class' attribute for namespace devices is added for
    tooling to specify the 'abstraction_guid' to store in the namespace label.
    For v1.1 labels this field is undefined and any setting of
    'holder_class' away from the default 'none' value will only have effect
    until the driver is unloaded. Setting 'holder_class' requires that
    whatever device tries to claim the namespace must be of the specified
    class.
    
    Cc: Vishal Verma <vishal.l.verma@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 17cecb38dfc9..8cabd836df0e 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -235,6 +235,7 @@ ssize_t nd_sector_size_store(struct device *dev, const char *buf,
 		unsigned long *current_lbasize, const unsigned long *supported);
 int __init nvdimm_init(void);
 int __init nd_region_init(void);
+int __init nd_label_init(void);
 void nvdimm_exit(void);
 void nd_region_exit(void);
 struct nvdimm;

commit f979b13c3cc51584882bffa32965f34e5afa3b9b
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sun Jun 4 12:12:07 2017 +0900

    libnvdimm, label: honor the lba size specified in v1.2 labels
    
    Previously we only honored the lba size for blk-aperture mode
    namespaces. For pmem namespaces the lba size was just assumed to be 512.
    With the new v1.2 label definition and compatibility with other
    operating environments, the ->lbasize property is now respected for pmem
    namespaces.
    
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index ad4e518940c9..17cecb38dfc9 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -356,6 +356,7 @@ int nvdimm_namespace_attach_btt(struct nd_namespace_common *ndns);
 int nvdimm_namespace_detach_btt(struct nd_btt *nd_btt);
 const char *nvdimm_namespace_disk_name(struct nd_namespace_common *ndns,
 		char *name);
+unsigned int pmem_sector_size(struct nd_namespace_common *ndns);
 void nvdimm_badblocks_populate(struct nd_region *nd_region,
 		struct badblocks *bb, const struct resource *res);
 #if IS_ENABLED(CONFIG_ND_CLAIM)

commit c12c48ce869d72029d70666f615cbd8f67fc14e9
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sun Jun 4 10:59:15 2017 +0900

    libnvdimm, label: add v1.2 interleave-set-cookie algorithm
    
    The interleave-set-cookie algorithm is extended to incorporate all the
    same components that are used to generate an nvdimm unique-id. For
    backwards compatibility we still maintain the old v1.1 definition.
    
    Reported-by: Nicholas Moulin <nicholas.w.moulin@intel.com>
    Reported-by: Kaushik Kanetkar <kaushik.a.kanetkar@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 28d9f4481547..ad4e518940c9 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -336,7 +336,8 @@ static inline struct device *nd_dax_create(struct nd_region *nd_region)
 struct nd_region *to_nd_region(struct device *dev);
 int nd_region_to_nstype(struct nd_region *nd_region);
 int nd_region_register_namespaces(struct nd_region *nd_region, int *err);
-u64 nd_region_interleave_set_cookie(struct nd_region *nd_region);
+u64 nd_region_interleave_set_cookie(struct nd_region *nd_region,
+		struct nd_namespace_index *nsindex);
 u64 nd_region_interleave_set_altcookie(struct nd_region *nd_region);
 void nvdimm_bus_lock(struct device *dev);
 void nvdimm_bus_unlock(struct device *dev);

commit 564e871aa66f548a947b23808d3140f326381f0c
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sat Jun 3 18:30:43 2017 +0900

    libnvdimm, label: add v1.2 nvdimm label definitions
    
    In support of improved interoperability between operating systems and pre-boot
    environments the Intel proposed NVDIMM Namespace Specification [1], has been
    adopted and modified to the the UEFI 2.7 NVDIMM Label Protocol [2].
    
    Update the definitions of the namespace label data structures so that the new
    format can be supported alongside the existing label format.
    
    The new specification changes the default label size to 256 bytes, so
    everywhere that relied on sizeof(struct nd_namespace_label) must now use the
    sizeof_namespace_label() helper.
    
    There should be no functional differences from these changes as the
    default is still the v1.1 128-byte format. Future patches will move the
    default to the v1.2 definition.
    
    [1]: http://pmem.io/documents/NVDIMM_Namespace_Spec.pdf
    [2]: http://www.uefi.org/sites/default/files/resources/UEFI_Spec_2_7.pdf
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 03852d738eec..28d9f4481547 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -42,7 +42,7 @@ struct nd_poison {
 
 struct nvdimm_drvdata {
 	struct device *dev;
-	int nsindex_size;
+	int nsindex_size, nslabel_size;
 	struct nd_cmd_get_config_size nsarea;
 	void *data;
 	int ns_current, ns_next;
@@ -96,6 +96,12 @@ static inline struct nd_namespace_index *to_next_namespace_index(
 	return to_namespace_index(ndd, ndd->ns_next);
 }
 
+unsigned sizeof_namespace_label(struct nvdimm_drvdata *ndd);
+
+#define namespace_label_has(ndd, field) \
+	(offsetof(struct nd_namespace_label, field) \
+		< sizeof_namespace_label(ndd))
+
 #define nd_dbg_dpa(r, d, res, fmt, arg...) \
 	dev_dbg((r) ? &(r)->dev : (d)->dev, "%s: %.13s: %#llx @ %#llx " fmt, \
 		(r) ? dev_name((d)->dev) : "", res ? res->name : "null", \

commit 3ae3d67ba705c754a3c91ac009f9ce73a0e7286a
Author: Vishal Verma <vishal.l.verma@intel.com>
Date:   Wed May 10 15:01:30 2017 -0600

    libnvdimm: add an atomic vs process context flag to rw_bytes
    
    nsio_rw_bytes can clear media errors, but this cannot be done while we
    are in an atomic context due to locking within ACPI. From the BTT,
    ->rw_bytes may be called either from atomic or process context depending
    on whether the calls happen during initialization or during IO.
    
    During init, we want to ensure error clearing happens, and the flag
    marking process context allows nsio_rw_bytes to do that. When called
    during IO, we're in atomic context, and error clearing can be skipped.
    
    Cc: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Vishal Verma <vishal.l.verma@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 77d032192bf7..03852d738eec 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -31,6 +31,7 @@ enum {
 	ND_MAX_LANES = 256,
 	SECTOR_SHIFT = 9,
 	INT_LBASIZE_ALIGNMENT = 64,
+	NVDIMM_IO_ATOMIC = 1,
 };
 
 struct nd_poison {

commit 8f078b38dd382710884ce7abd31a1935c440e6f8
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu May 4 14:01:24 2017 -0700

    libnvdimm: convert NDD_ flags to use bitops, introduce NDD_LOCKED
    
    This is a preparation patch for handling locked nvdimm label regions, a
    new concept as introduced by the latest DSM document on pmem.io [1]. A
    future patch will leverage nvdimm_set_locked() at DIMM probe time to
    flag regions that can not be enabled. There should be no functional
    difference resulting from this change.
    
    [1]: http://pmem.io/documents/NVDIMM_DSM_Interface_Example-V1.3.pdf
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index c3b33cf655fb..77d032192bf7 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -240,6 +240,7 @@ int nvdimm_set_config_data(struct nvdimm_drvdata *ndd, size_t offset,
 long nvdimm_clear_poison(struct device *dev, phys_addr_t phys,
 		unsigned int len);
 void nvdimm_set_aliasing(struct device *dev);
+void nvdimm_set_locked(struct device *dev);
 struct nd_btt *to_nd_btt(struct device *dev);
 
 struct nd_gen_sb {

commit 6a6bef90425e8cba7c53919d923240559b7f247c
Author: Dave Jiang <dave.jiang@intel.com>
Date:   Fri Apr 7 15:33:20 2017 -0700

    libnvdimm: add mechanism to publish badblocks at the region level
    
    badblocks sysfs file will be export at region level. When nvdimm event
    notifier happens for NVDIMM_REVALIATE_POISON, the badblocks in the
    region will be updated.
    
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 2a99c83aa19f..c3b33cf655fb 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -154,6 +154,7 @@ struct nd_region {
 	u64 ndr_start;
 	int id, num_lanes, ro, numa_node;
 	void *provider_data;
+	struct badblocks bb;
 	struct nd_interleave_set *nd_set;
 	struct nd_percpu_lane __percpu *lane;
 	struct nd_mapping mapping[0];

commit 86ef58a4e35e8fa66afb5898cf6dec6a3bb29f67
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Feb 28 18:32:48 2017 -0800

    nfit, libnvdimm: fix interleave set cookie calculation
    
    The interleave-set cookie is a sum that sanity checks the composition of
    an interleave set has not changed from when the namespace was initially
    created.  The checksum is calculated by sorting the DIMMs by their
    location in the interleave-set. The comparison for the sort must be
    64-bit wide, not byte-by-byte as performed by memcmp() in the broken
    case.
    
    Fix the implementation to accept correct cookie values in addition to
    the Linux "memcmp" order cookies, but only allow correct cookies to be
    generated going forward. It does mean that namespaces created by
    third-party-tooling, or created by newer kernels with this fix, will not
    validate on older kernels. However, there are a couple mitigating
    conditions:
    
        1/ platforms with namespace-label capable NVDIMMs are not widely
           available.
    
        2/ interleave-sets with a single-dimm are by definition not affected
           (nothing to sort). This covers the QEMU-KVM NVDIMM emulation case.
    
    The cookie stored in the namespace label will be fixed by any write the
    namespace label, the most straightforward way to achieve this is to
    write to the "alt_name" attribute of a namespace in sysfs.
    
    Cc: <stable@vger.kernel.org>
    Fixes: eaf961536e16 ("libnvdimm, nfit: add interleave-set state-tracking infrastructure")
    Reported-by: Nicholas Moulin <nicholas.w.moulin@linux.intel.com>
    Tested-by: Nicholas Moulin <nicholas.w.moulin@linux.intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 35dd75057e16..2a99c83aa19f 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -328,6 +328,7 @@ struct nd_region *to_nd_region(struct device *dev);
 int nd_region_to_nstype(struct nd_region *nd_region);
 int nd_region_register_namespaces(struct nd_region *nd_region, int *err);
 u64 nd_region_interleave_set_cookie(struct nd_region *nd_region);
+u64 nd_region_interleave_set_altcookie(struct nd_region *nd_region);
 void nvdimm_bus_lock(struct device *dev);
 void nvdimm_bus_unlock(struct device *dev);
 bool is_nvdimm_bus_locked(struct device *dev);

commit 42237e393f64d619ed56e17fbf8fd27526485695
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sat Oct 15 15:33:52 2016 -0700

    libnvdimm: allow a platform to force enable label support
    
    Platforms like QEMU-KVM implement an NFIT table and label DSMs.
    However, since that environment does not define an aliased
    configuration, the labels are currently ignored and the kernel registers
    a single full-sized pmem-namespace per region. Now that the kernel
    supports sub-divisions of pmem regions the labels have a purpose.
    Arrange for the labels to be honored when we find an existing / valid
    namespace index block.
    
    Cc: <qemu-devel@nongnu.org>
    Cc: Haozhong Zhang <haozhong.zhang@intel.com>
    Cc: Xiao Guangrong <guangrong.xiao@linux.intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 065abf1b8f32..35dd75057e16 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -238,6 +238,7 @@ int nvdimm_set_config_data(struct nvdimm_drvdata *ndd, size_t offset,
 		void *buf, size_t len);
 long nvdimm_clear_poison(struct device *dev, phys_addr_t phys,
 		unsigned int len);
+void nvdimm_set_aliasing(struct device *dev);
 struct nd_btt *to_nd_btt(struct device *dev);
 
 struct nd_gen_sb {

commit 8d7c22ac0c036978a072b7e13c607b5402c474e0
Author: Toshi Kani <toshi.kani@hpe.com>
Date:   Wed Oct 19 08:19:44 2016 -0600

    libnvdimm: use generic iostat interfaces
    
    nd_iostat_start() and nd_iostat_end() implement the same functionality
    that generic_start_io_acct() and generic_end_io_acct() already provide.
    
    Change nd_iostat_start() and nd_iostat_end() to call the generic iostat
    interfaces.  There is no change in the nd interfaces.
    
    Signed-off-by: Toshi Kani <toshi.kani@hpe.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index d3b2fca8deec..065abf1b8f32 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -377,10 +377,17 @@ static inline bool nd_iostat_start(struct bio *bio, unsigned long *start)
 	if (!blk_queue_io_stat(disk->queue))
 		return false;
 
-	__nd_iostat_start(bio, start);
+	*start = jiffies;
+	generic_start_io_acct(bio_data_dir(bio),
+			      bio_sectors(bio), &disk->part0);
 	return true;
 }
-void nd_iostat_end(struct bio *bio, unsigned long start);
+static inline void nd_iostat_end(struct bio *bio, unsigned long start)
+{
+	struct gendisk *disk = bio->bi_bdev->bd_disk;
+
+	generic_end_io_acct(bio_data_dir(bio), &disk->part0, start);
+}
 static inline bool is_bad_pmem(struct badblocks *bb, sector_t sector,
 		unsigned int len)
 {

commit 178d6f4be8bf42b298bedf8ea2a00754100e0c4e
Merge: db58028ee4e3 98a29c39dc68
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Oct 7 16:46:24 2016 -0700

    Merge branch 'for-4.9/libnvdimm' into libnvdimm-for-next

commit ae8219f186d8e98a3239afc6ea49bb46f2871d2f
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Sep 19 16:04:21 2016 -0700

    libnvdimm, label: convert label tracking to a linked list
    
    In preparation for enabling multiple namespaces per pmem region, convert
    the label tracking to use a linked list.  In particular this will allow
    select_pmem_id() to move labels from the unvalidated state to the
    validated state.  Currently we only track one validated set per-region.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index e58c40824e1f..f67c61f1a8a4 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -83,9 +83,6 @@ static inline struct nd_namespace_index *to_next_namespace_index(
 		(unsigned long long) (res ? resource_size(res) : 0), \
 		(unsigned long long) (res ? res->start : 0), ##arg)
 
-#define for_each_label(l, label, labels) \
-	for (l = 0; (label = labels ? labels[l] : NULL); l++)
-
 #define for_each_dpa_resource(ndd, res) \
 	for (res = (ndd)->dpa.child; res; res = res->sibling)
 
@@ -98,11 +95,22 @@ struct nd_percpu_lane {
 	spinlock_t lock;
 };
 
+struct nd_label_ent {
+	struct list_head list;
+	struct nd_namespace_label *label;
+};
+
+enum nd_mapping_lock_class {
+	ND_MAPPING_CLASS0,
+	ND_MAPPING_UUID_SCAN,
+};
+
 struct nd_mapping {
 	struct nvdimm *nvdimm;
-	struct nd_namespace_label **labels;
 	u64 start;
 	u64 size;
+	struct list_head labels;
+	struct mutex lock;
 	/*
 	 * @ndd is for private use at region enable / disable time for
 	 * get_ndd() + put_ndd(), all other nd_mapping to ndd

commit 44c462eb9e19dfa089b454271dd2dff5eaf1ad6d
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Sep 19 16:38:50 2016 -0700

    libnvdimm, region: move region-mapping input-paramters to nd_mapping_desc
    
    Before we add more libnvdimm-private fields to nd_mapping make it clear
    which parameters are input vs libnvdimm internals. Use struct
    nd_mapping_desc instead of struct nd_mapping in nd_region_desc and make
    struct nd_mapping private to libnvdimm.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 38d6f039234e..e58c40824e1f 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -98,6 +98,20 @@ struct nd_percpu_lane {
 	spinlock_t lock;
 };
 
+struct nd_mapping {
+	struct nvdimm *nvdimm;
+	struct nd_namespace_label **labels;
+	u64 start;
+	u64 size;
+	/*
+	 * @ndd is for private use at region enable / disable time for
+	 * get_ndd() + put_ndd(), all other nd_mapping to ndd
+	 * conversions use to_ndd() which respects enabled state of the
+	 * nvdimm.
+	 */
+	struct nvdimm_drvdata *ndd;
+};
+
 struct nd_region {
 	struct device dev;
 	struct ida ns_ida;

commit 595c73071e6641e59b83911fbb4026e767471000
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Sep 23 17:53:52 2016 -0700

    libnvdimm, region: fix flush hint table thinko
    
    The definition of the flush hint table as:
    
            void __iomem *flush_wpq[0][0];
    
    ...passed the unit test, but is broken as flush_wpq[0][1] and
    flush_wpq[1][0] refer to the same entry.  Fix this to use a helper that
    calculates a slot in the table based on the geometry of flush hints in
    the region.  This is important to get right since virtualization
    solutions use this mechanism to trigger hypervisor flushes to platform
    persistence.
    
    Reported-by: Dave Jiang <dave.jiang@intel.com>
    Tested-by: Dave Jiang <dave.jiang@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 8024a0ef86d3..0b78a8211f4a 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -52,10 +52,28 @@ struct nvdimm_drvdata {
 struct nd_region_data {
 	int ns_count;
 	int ns_active;
-	unsigned int flush_mask;
-	void __iomem *flush_wpq[0][0];
+	unsigned int hints_shift;
+	void __iomem *flush_wpq[0];
 };
 
+static inline void __iomem *ndrd_get_flush_wpq(struct nd_region_data *ndrd,
+		int dimm, int hint)
+{
+	unsigned int num = 1 << ndrd->hints_shift;
+	unsigned int mask = num - 1;
+
+	return ndrd->flush_wpq[dimm * num + (hint & mask)];
+}
+
+static inline void ndrd_set_flush_wpq(struct nd_region_data *ndrd, int dimm,
+		int hint, void __iomem *flush)
+{
+	unsigned int num = 1 << ndrd->hints_shift;
+	unsigned int mask = num - 1;
+
+	ndrd->flush_wpq[dimm * num + (hint & mask)] = flush;
+}
+
 static inline struct nd_namespace_index *to_namespace_index(
 		struct nvdimm_drvdata *ndd, int i)
 {

commit aee6598748335794dc25d7c4f16f0d4801f6b584
Author: Toshi Kani <toshi.kani@hpe.com>
Date:   Tue Aug 16 13:08:40 2016 -0600

    libnvdimm: Fix nvdimm_probe error on NVDIMM-N
    
    'ndctl list --buses --dimms' does not list any NVDIMM-Ns since
    they are considered as idle.  ndctl checks if any driver is
    attached to nmem device.  nvdimm_probe() always fails in
    nvdimm_init_nsarea() since NVDIMM-Ns do not implement optinal
    ND_CMD_GET_CONFIG_DATA command.
    
    Change nvdimm_probe() to accept the case that the CONFIG_DATA
    command is not implemented for NVDIMM-Ns.  The driver attaches
    without ndd, which keeps it no-op to the device.
    
    Reported-by: Brian Boylston <brian.boylston@hpe.com>
    Signed-off-by: Toshi Kani <toshi.kani@hpe.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Tested-by: Johannes Thumshirn <jthumshirn@suse.de>
    Acked-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 8024a0ef86d3..38d6f039234e 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -191,6 +191,7 @@ void nvdimm_exit(void);
 void nd_region_exit(void);
 struct nvdimm;
 struct nvdimm_drvdata *to_ndd(struct nd_mapping *nd_mapping);
+int nvdimm_check_config_data(struct device *dev);
 int nvdimm_init_nsarea(struct nvdimm_drvdata *ndd);
 int nvdimm_init_config_data(struct nvdimm_drvdata *ndd);
 int nvdimm_set_config_data(struct nvdimm_drvdata *ndd, size_t offset,

commit abe8b4e3cef88b8202641d63f5ad58141b970b0f
Author: Vishal Verma <vishal.l.verma@intel.com>
Date:   Wed Jul 27 16:38:59 2016 -0600

    nvdimm, btt: add a size attribute for BTTs
    
    To be consistent with other namespaces, expose a 'size' attribute for
    BTT devices also.
    
    Cc: Dan Williams <dan.j.williams@intel.com>
    Reported-by: Linda Knippers <linda.knippers@hpe.com>
    Signed-off-by: Vishal Verma <vishal.l.verma@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 40476399d227..8024a0ef86d3 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -143,6 +143,7 @@ struct nd_btt {
 	struct nd_namespace_common *ndns;
 	struct btt *btt;
 	unsigned long lbasize;
+	u64 size;
 	u8 *uuid;
 	int id;
 };

commit 0c27af60d1bbd33c7d3dffb46a4c9f6aa103d754
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri May 27 09:23:01 2016 -0700

    libnvdimm: cycle flush hints
    
    When the NFIT provides multiple flush hint addresses per-dimm it is
    expressing that the platform is capable of processing multiple flush
    requests in parallel.  There is some fixed cost per flush request, let
    the cost be shared in parallel on multiple cpus.
    
    Since there may not be enough flush hint addresses for each cpu to have
    one, keep a per-cpu index of the last used hint, hash it with current
    pid, and assume that access pattern and scheduler randomness will keep
    the flush-hint usage somewhat staggered across cpus.
    
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 5912bd6b4234..40476399d227 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -52,6 +52,7 @@ struct nvdimm_drvdata {
 struct nd_region_data {
 	int ns_count;
 	int ns_active;
+	unsigned int flush_mask;
 	void __iomem *flush_wpq[0][0];
 };
 

commit e5ae3b252c6732f838f5695170bbf2ea9fb5b9ff
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Jun 7 17:00:04 2016 -0700

    libnvdimm, nfit: move flush hint mapping to region-device driver-data
    
    In preparation for triggering flushes of a DIMM's writes-posted-queue
    (WPQ) via the pmem driver move mapping of flush hint addresses to the
    region driver.  Since this uses devm_nvdimm_memremap() the flush
    addresses will remain mapped while any region to which the dimm belongs
    is active.
    
    We need to communicate more information to the nvdimm core to facilitate
    this mapping, namely each dimm object now carries an array of flush hint
    address resources.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 2819e886dfd2..5912bd6b4234 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -49,9 +49,10 @@ struct nvdimm_drvdata {
 	struct kref kref;
 };
 
-struct nd_region_namespaces {
-	int count;
-	int active;
+struct nd_region_data {
+	int ns_count;
+	int ns_active;
+	void __iomem *flush_wpq[0][0];
 };
 
 static inline struct nd_namespace_index *to_namespace_index(
@@ -324,6 +325,7 @@ static inline void devm_nsio_disable(struct device *dev,
 }
 #endif
 int nd_blk_region_init(struct nd_region *nd_region);
+int nd_region_activate(struct nd_region *nd_region);
 void __nd_iostat_start(struct bio *bio, unsigned long *start);
 static inline bool nd_iostat_start(struct bio *bio, unsigned long *start)
 {

commit a8a6d2e04c4ffda055db70814c50bd106e44730f
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Jun 7 16:38:04 2016 -0700

    libnvdimm, nfit: remove nfit_spa_map() infrastructure
    
    Now that all shared mappings are handled by devm_nvdimm_memremap() we no
    longer need nfit_spa_map() nor do we need to trigger a callback to the
    bus provider at region disable time.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index d0ac93c31dda..2819e886dfd2 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -119,7 +119,6 @@ struct nd_region {
 
 struct nd_blk_region {
 	int (*enable)(struct nvdimm_bus *nvdimm_bus, struct device *dev);
-	void (*disable)(struct nvdimm_bus *nvdimm_bus, struct device *dev);
 	int (*do_io)(struct nd_blk_region *ndbr, resource_size_t dpa,
 			void *iobuf, u64 len, int rw);
 	void *blk_provider_data;

commit c5ed9268643c7c4c9f2aaa0fd4c936095e6480ef
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed May 18 14:50:12 2016 -0700

    libnvdimm, dax: autodetect support
    
    For autodetecting a previously established dax configuration we need the
    info block to indicate block-device vs device-dax mode, and we need to
    have the default namespace probe hand-off the configuration to the
    dax_pmem driver.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 46910b8f32b1..d0ac93c31dda 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -232,7 +232,7 @@ bool is_nd_pfn(struct device *dev);
 struct device *nd_pfn_create(struct nd_region *nd_region);
 struct device *nd_pfn_devinit(struct nd_pfn *nd_pfn,
 		struct nd_namespace_common *ndns);
-int nd_pfn_validate(struct nd_pfn *nd_pfn);
+int nd_pfn_validate(struct nd_pfn *nd_pfn, const char *sig);
 extern struct attribute_group nd_pfn_attribute_group;
 #else
 static inline int nd_pfn_probe(struct device *dev,
@@ -251,7 +251,7 @@ static inline struct device *nd_pfn_create(struct nd_region *nd_region)
 	return NULL;
 }
 
-static inline int nd_pfn_validate(struct nd_pfn *nd_pfn)
+static inline int nd_pfn_validate(struct nd_pfn *nd_pfn, const char *sig)
 {
 	return -ENODEV;
 }
@@ -259,9 +259,16 @@ static inline int nd_pfn_validate(struct nd_pfn *nd_pfn)
 
 struct nd_dax *to_nd_dax(struct device *dev);
 #if IS_ENABLED(CONFIG_NVDIMM_DAX)
+int nd_dax_probe(struct device *dev, struct nd_namespace_common *ndns);
 bool is_nd_dax(struct device *dev);
 struct device *nd_dax_create(struct nd_region *nd_region);
 #else
+static inline int nd_dax_probe(struct device *dev,
+		struct nd_namespace_common *ndns)
+{
+	return -ENODEV;
+}
+
 static inline bool is_nd_dax(struct device *dev)
 {
 	return false;

commit cd03412a51ac4cb3001a8cdfae4560c9602f3387
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Mar 11 10:15:36 2016 -0800

    libnvdimm, dax: introduce device-dax infrastructure
    
    Device DAX is the device-centric analogue of Filesystem DAX
    (CONFIG_FS_DAX).  It allows persistent memory ranges to be allocated and
    mapped without need of an intervening file system.  This initial
    infrastructure arranges for a libnvdimm pfn-device to be represented as
    a different device-type so that it can be attached to a driver other
    than the pmem driver.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 6c36509662e4..46910b8f32b1 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -101,10 +101,12 @@ struct nd_region {
 	struct ida ns_ida;
 	struct ida btt_ida;
 	struct ida pfn_ida;
+	struct ida dax_ida;
 	unsigned long flags;
 	struct device *ns_seed;
 	struct device *btt_seed;
 	struct device *pfn_seed;
+	struct device *dax_seed;
 	u16 ndr_mappings;
 	u64 ndr_size;
 	u64 ndr_start;
@@ -161,6 +163,10 @@ struct nd_pfn {
 	struct nd_namespace_common *ndns;
 };
 
+struct nd_dax {
+	struct nd_pfn nd_pfn;
+};
+
 enum nd_async_mode {
 	ND_SYNC,
 	ND_ASYNC,
@@ -224,7 +230,10 @@ struct nd_pfn *to_nd_pfn(struct device *dev);
 int nd_pfn_probe(struct device *dev, struct nd_namespace_common *ndns);
 bool is_nd_pfn(struct device *dev);
 struct device *nd_pfn_create(struct nd_region *nd_region);
+struct device *nd_pfn_devinit(struct nd_pfn *nd_pfn,
+		struct nd_namespace_common *ndns);
 int nd_pfn_validate(struct nd_pfn *nd_pfn);
+extern struct attribute_group nd_pfn_attribute_group;
 #else
 static inline int nd_pfn_probe(struct device *dev,
 		struct nd_namespace_common *ndns)
@@ -248,6 +257,22 @@ static inline int nd_pfn_validate(struct nd_pfn *nd_pfn)
 }
 #endif
 
+struct nd_dax *to_nd_dax(struct device *dev);
+#if IS_ENABLED(CONFIG_NVDIMM_DAX)
+bool is_nd_dax(struct device *dev);
+struct device *nd_dax_create(struct nd_region *nd_region);
+#else
+static inline bool is_nd_dax(struct device *dev)
+{
+	return false;
+}
+
+static inline struct device *nd_dax_create(struct nd_region *nd_region)
+{
+	return NULL;
+}
+#endif
+
 struct nd_region *to_nd_region(struct device *dev);
 int nd_region_to_nstype(struct nd_region *nd_region);
 int nd_region_register_namespaces(struct nd_region *nd_region, int *err);

commit ac515c084be9b3995f7aef0ae87797e75e0260f0
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Mar 22 00:29:43 2016 -0700

    libnvdimm, pmem, pfn: move pfn setup to the core
    
    Now that pmem internals have been disentangled from pfn setup, that code
    can move to the core.  This is in preparation for adding another user of
    the pfn-device capabilities.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 10e23fe49012..6c36509662e4 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -272,9 +272,16 @@ const char *nvdimm_namespace_disk_name(struct nd_namespace_common *ndns,
 void nvdimm_badblocks_populate(struct nd_region *nd_region,
 		struct badblocks *bb, const struct resource *res);
 #if IS_ENABLED(CONFIG_ND_CLAIM)
+struct vmem_altmap *nvdimm_setup_pfn(struct nd_pfn *nd_pfn,
+		struct resource *res, struct vmem_altmap *altmap);
 int devm_nsio_enable(struct device *dev, struct nd_namespace_io *nsio);
 void devm_nsio_disable(struct device *dev, struct nd_namespace_io *nsio);
 #else
+static inline struct vmem_altmap *nvdimm_setup_pfn(struct nd_pfn *nd_pfn,
+		struct resource *res, struct vmem_altmap *altmap)
+{
+	return ERR_PTR(-ENXIO);
+}
 static inline int devm_nsio_enable(struct device *dev,
 		struct nd_namespace_io *nsio)
 {

commit 200c79da824c978fcf6eec1dc9c0a1e521133267
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Mar 22 00:22:16 2016 -0700

    libnvdimm, pmem, pfn: make pmem_rw_bytes generic and refactor pfn setup
    
    In preparation for providing an alternative (to block device) access
    mechanism to persistent memory, convert pmem_rw_bytes() to
    nsio_rw_bytes().  This allows ->rw_bytes() functionality without
    requiring a 'struct pmem_device' to be instantiated.
    
    In other words, when ->rw_bytes() is in use i/o is driven through
    'struct nd_namespace_io', otherwise it is driven through 'struct
    pmem_device' and the block layer.  This consolidates the disjoint calls
    to devm_exit_badblocks() and devm_memunmap() into a common
    devm_nsio_disable() and cleans up the init path to use a unified
    pmem_attach_disk() implementation.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 0fb14890ba26..10e23fe49012 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -13,6 +13,7 @@
 #ifndef __ND_H__
 #define __ND_H__
 #include <linux/libnvdimm.h>
+#include <linux/badblocks.h>
 #include <linux/blkdev.h>
 #include <linux/device.h>
 #include <linux/mutex.h>
@@ -197,13 +198,12 @@ struct nd_gen_sb {
 
 u64 nd_sb_checksum(struct nd_gen_sb *sb);
 #if IS_ENABLED(CONFIG_BTT)
-int nd_btt_probe(struct device *dev, struct nd_namespace_common *ndns,
-		void *drvdata);
+int nd_btt_probe(struct device *dev, struct nd_namespace_common *ndns);
 bool is_nd_btt(struct device *dev);
 struct device *nd_btt_create(struct nd_region *nd_region);
 #else
 static inline int nd_btt_probe(struct device *dev,
-		struct nd_namespace_common *ndns, void *drvdata)
+		struct nd_namespace_common *ndns)
 {
 	return -ENODEV;
 }
@@ -221,14 +221,13 @@ static inline struct device *nd_btt_create(struct nd_region *nd_region)
 
 struct nd_pfn *to_nd_pfn(struct device *dev);
 #if IS_ENABLED(CONFIG_NVDIMM_PFN)
-int nd_pfn_probe(struct device *dev, struct nd_namespace_common *ndns,
-		void *drvdata);
+int nd_pfn_probe(struct device *dev, struct nd_namespace_common *ndns);
 bool is_nd_pfn(struct device *dev);
 struct device *nd_pfn_create(struct nd_region *nd_region);
 int nd_pfn_validate(struct nd_pfn *nd_pfn);
 #else
-static inline int nd_pfn_probe(struct device *dev, struct nd_namespace_common *ndns,
-		void *drvdata)
+static inline int nd_pfn_probe(struct device *dev,
+		struct nd_namespace_common *ndns)
 {
 	return -ENODEV;
 }
@@ -272,6 +271,20 @@ const char *nvdimm_namespace_disk_name(struct nd_namespace_common *ndns,
 		char *name);
 void nvdimm_badblocks_populate(struct nd_region *nd_region,
 		struct badblocks *bb, const struct resource *res);
+#if IS_ENABLED(CONFIG_ND_CLAIM)
+int devm_nsio_enable(struct device *dev, struct nd_namespace_io *nsio);
+void devm_nsio_disable(struct device *dev, struct nd_namespace_io *nsio);
+#else
+static inline int devm_nsio_enable(struct device *dev,
+		struct nd_namespace_io *nsio)
+{
+	return -ENXIO;
+}
+static inline void devm_nsio_disable(struct device *dev,
+		struct nd_namespace_io *nsio)
+{
+}
+#endif
 int nd_blk_region_init(struct nd_region *nd_region);
 void __nd_iostat_start(struct bio *bio, unsigned long *start);
 static inline bool nd_iostat_start(struct bio *bio, unsigned long *start)
@@ -285,6 +298,19 @@ static inline bool nd_iostat_start(struct bio *bio, unsigned long *start)
 	return true;
 }
 void nd_iostat_end(struct bio *bio, unsigned long start);
+static inline bool is_bad_pmem(struct badblocks *bb, sector_t sector,
+		unsigned int len)
+{
+	if (bb->count) {
+		sector_t first_bad;
+		int num_bad;
+
+		return !!badblocks_check(bb, sector, len / 512, &first_bad,
+				&num_bad);
+	}
+
+	return false;
+}
 resource_size_t nd_namespace_blk_validate(struct nd_namespace_blk *nsblk);
 const u8 *nd_dev_to_uuid(struct device *dev);
 bool pmem_should_map_pages(struct device *dev);

commit e32bc729a3a486e20443db3379ecf67240b20616
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Mar 17 18:23:09 2016 -0700

    libnvdimm, btt, convert nd_btt_probe() to devm
    
    Pass the device performing the probe so we can use a devm allocation for
    the btt superblock.
    
    Cc: Vishal Verma <vishal.l.verma@intel.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index c831caa3d60a..0fb14890ba26 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -197,11 +197,13 @@ struct nd_gen_sb {
 
 u64 nd_sb_checksum(struct nd_gen_sb *sb);
 #if IS_ENABLED(CONFIG_BTT)
-int nd_btt_probe(struct nd_namespace_common *ndns, void *drvdata);
+int nd_btt_probe(struct device *dev, struct nd_namespace_common *ndns,
+		void *drvdata);
 bool is_nd_btt(struct device *dev);
 struct device *nd_btt_create(struct nd_region *nd_region);
 #else
-static inline int nd_btt_probe(struct nd_namespace_common *ndns, void *drvdata)
+static inline int nd_btt_probe(struct device *dev,
+		struct nd_namespace_common *ndns, void *drvdata)
 {
 	return -ENODEV;
 }

commit bd032943b5b2b336994171dcebc11531a38b45ba
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Mar 17 18:16:15 2016 -0700

    libnvdimm, pfn, convert nd_pfn_probe() to devm
    
    Pass the device performing the probe so we can use a devm allocation for
    the pfn superblock.
    
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index b0a4ab91307b..c831caa3d60a 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -219,12 +219,14 @@ static inline struct device *nd_btt_create(struct nd_region *nd_region)
 
 struct nd_pfn *to_nd_pfn(struct device *dev);
 #if IS_ENABLED(CONFIG_NVDIMM_PFN)
-int nd_pfn_probe(struct nd_namespace_common *ndns, void *drvdata);
+int nd_pfn_probe(struct device *dev, struct nd_namespace_common *ndns,
+		void *drvdata);
 bool is_nd_pfn(struct device *dev);
 struct device *nd_pfn_create(struct nd_region *nd_region);
 int nd_pfn_validate(struct nd_pfn *nd_pfn);
 #else
-static inline int nd_pfn_probe(struct nd_namespace_common *ndns, void *drvdata)
+static inline int nd_pfn_probe(struct device *dev, struct nd_namespace_common *ndns,
+		void *drvdata)
 {
 	return -ENODEV;
 }

commit 298f2bc5db3851cf2e839a0025425256ef852139
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Mar 15 16:41:04 2016 -0700

    libnvdimm, pmem: kill pmem->ndns
    
    We can derive the common namespace from other information.  We also do
    not need to cache it because all the usages are in slow paths.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 875c524fafb0..b0a4ab91307b 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -263,7 +263,7 @@ struct resource *nvdimm_allocate_dpa(struct nvdimm_drvdata *ndd,
 resource_size_t nvdimm_namespace_capacity(struct nd_namespace_common *ndns);
 struct nd_namespace_common *nvdimm_namespace_common_probe(struct device *dev);
 int nvdimm_namespace_attach_btt(struct nd_namespace_common *ndns);
-int nvdimm_namespace_detach_btt(struct nd_namespace_common *ndns);
+int nvdimm_namespace_detach_btt(struct nd_btt *nd_btt);
 const char *nvdimm_namespace_disk_name(struct nd_namespace_common *ndns,
 		char *name);
 void nvdimm_badblocks_populate(struct nd_region *nd_region,

commit a390180291dd9a2392bbab4242cde712c326efc6
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Apr 7 20:02:06 2016 -0700

    libnvdimm, pfn: fix nvdimm_namespace_add_poison() vs section alignment
    
    When section alignment padding is in effect we need to shift / truncate
    the range that is queried for poison by the 'start_pad' or 'end_trunc'
    reservations.
    
    It's easiest if we just pass in an adjusted resource range rather than
    deriving it from the passed in namespace.  With the resource range
    resolution pushed out to the caller we can also push the
    namespace-to-region lookup to the caller and drop the implicit pmem-type
    assumption about the passed in namespace object.
    
    Cc: Vishal Verma <vishal.l.verma@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 1799bd97a9ce..875c524fafb0 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -266,8 +266,8 @@ int nvdimm_namespace_attach_btt(struct nd_namespace_common *ndns);
 int nvdimm_namespace_detach_btt(struct nd_namespace_common *ndns);
 const char *nvdimm_namespace_disk_name(struct nd_namespace_common *ndns,
 		char *name);
-void nvdimm_namespace_add_poison(struct nd_namespace_common *ndns,
-		struct badblocks *bb, resource_size_t offset);
+void nvdimm_badblocks_populate(struct nd_region *nd_region,
+		struct badblocks *bb, const struct resource *res);
 int nd_blk_region_init(struct nd_region *nd_region);
 void __nd_iostat_start(struct bio *bio, unsigned long *start);
 static inline bool nd_iostat_start(struct bio *bio, unsigned long *start)

commit 59e6473980f321c16299e12db69d1fabc2644a6f
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Mar 8 07:16:07 2016 -0800

    libnvdimm, pmem: clear poison on write
    
    If a write is directed at a known bad block perform the following:
    
    1/ write the data
    
    2/ send a clear poison command
    
    3/ invalidate the poison out of the cache hierarchy
    
    Cc: <x86@kernel.org>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reviewed-by: Vishal Verma <vishal.l.verma@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 78b82f6dd191..1799bd97a9ce 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -186,6 +186,8 @@ int nvdimm_init_nsarea(struct nvdimm_drvdata *ndd);
 int nvdimm_init_config_data(struct nvdimm_drvdata *ndd);
 int nvdimm_set_config_data(struct nvdimm_drvdata *ndd, size_t offset,
 		void *buf, size_t len);
+long nvdimm_clear_poison(struct device *dev, phys_addr_t phys,
+		unsigned int len);
 struct nd_btt *to_nd_btt(struct device *dev);
 
 struct nd_gen_sb {

commit 719994660c249a086a7493205c7f1562e30c38cb
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Feb 18 10:29:49 2016 -0800

    libnvdimm: async notification support
    
    In preparation for asynchronous address range scrub support add an
    ability for the pmem driver to dynamically consume address range scrub
    results.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index ba1633b9da31..78b82f6dd191 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -18,6 +18,7 @@
 #include <linux/mutex.h>
 #include <linux/ndctl.h>
 #include <linux/types.h>
+#include <linux/nd.h>
 #include "label.h"
 
 enum {
@@ -168,6 +169,7 @@ int nd_integrity_init(struct gendisk *disk, unsigned long meta_size);
 void wait_nvdimm_bus_probe_idle(struct device *dev);
 void nd_device_register(struct device *dev);
 void nd_device_unregister(struct device *dev, enum nd_async_mode mode);
+void nd_device_notify(struct device *dev, enum nvdimm_event event);
 int nd_uuid_store(struct device *dev, u8 **uuid_out, const char *buf,
 		size_t len);
 ssize_t nd_sector_size_show(unsigned long current_lbasize,

commit 8b63b6bfc1a551acf154061699028c7032d7890c
Merge: e07ecd76d4db 55f5560d8c18
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sun Jan 10 07:53:55 2016 -0800

    Merge branch 'for-4.5/block-dax' into for-4.5/libnvdimm

commit b95f5f4391fad65f1819c2404080b05ca95bdd92
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Jan 4 23:50:23 2016 -0800

    libnvdimm: convert to statically allocated badblocks
    
    If a device will ever have badblocks it should always have a badblocks
    instance available.  So, similar to md, embed a badblocks instance in
    pmem_device.  This reduces pointer chasing in the i/o fast path, and
    simplifies the init path.
    
    Reported-by: Vishal Verma <vishal.l.verma@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 198933da83e5..288d96ec7233 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -268,8 +268,8 @@ int nvdimm_namespace_attach_btt(struct nd_namespace_common *ndns);
 int nvdimm_namespace_detach_btt(struct nd_namespace_common *ndns);
 const char *nvdimm_namespace_disk_name(struct nd_namespace_common *ndns,
 		char *name);
-int nvdimm_namespace_add_poison(struct gendisk *disk, resource_size_t offset,
-		struct nd_namespace_common *ndns);
+void nvdimm_namespace_add_poison(struct nd_namespace_common *ndns,
+		struct badblocks *bb, resource_size_t offset);
 int nd_blk_region_init(struct nd_region *nd_region);
 void __nd_iostat_start(struct bio *bio, unsigned long *start);
 static inline bool nd_iostat_start(struct bio *bio, unsigned long *start)

commit ad9a8bde2cb19f6876f964fc48acc8b6a2f325ff
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed Jan 6 12:03:41 2016 -0800

    libnvdimm, pmem: move definition of nvdimm_namespace_add_poison to nd.h
    
    nd-core.h is private to the libnvdimm core internals and should not be
    used by drivers.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index ba91fcd5818d..198933da83e5 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -268,6 +268,8 @@ int nvdimm_namespace_attach_btt(struct nd_namespace_common *ndns);
 int nvdimm_namespace_detach_btt(struct nd_namespace_common *ndns);
 const char *nvdimm_namespace_disk_name(struct nd_namespace_common *ndns,
 		char *name);
+int nvdimm_namespace_add_poison(struct gendisk *disk, resource_size_t offset,
+		struct nd_namespace_common *ndns);
 int nd_blk_region_init(struct nd_region *nd_region);
 void __nd_iostat_start(struct bio *bio, unsigned long *start);
 static inline bool nd_iostat_start(struct bio *bio, unsigned long *start)

commit 0caeef63e6d2f866d85bb507bf63e0ce8ec91cef
Author: Vishal Verma <vishal.l.verma@intel.com>
Date:   Thu Dec 24 19:21:43 2015 -0700

    libnvdimm: Add a poison list and export badblocks
    
    During region creation, perform Address Range Scrubs (ARS) for the SPA
    (System Physical Address) ranges to retrieve known poison locations from
    firmware. Add a new data structure 'nd_poison' which is used as a list
    in nvdimm_bus to store these poison locations.
    
    When creating a pmem namespace, if there is any known poison associated
    with its physical address space, convert the poison ranges to bad sectors
    that are exposed using the badblocks interface.
    
    Signed-off-by: Vishal Verma <vishal.l.verma@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 417e521d299c..ba91fcd5818d 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -38,6 +38,12 @@ enum {
 #endif
 };
 
+struct nd_poison {
+	u64 start;
+	u64 length;
+	struct list_head list;
+};
+
 struct nvdimm_drvdata {
 	struct device *dev;
 	int nsindex_size;

commit 315c562536c42aa4da9b6c5a2135dd6715a5e0b5
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Dec 10 14:45:23 2015 -0800

    libnvdimm, pfn: add 'align' attribute, default to HPAGE_SIZE
    
    When setting aside capacity for struct page it must be aligned to the
    largest mapping size that is to be made available via DAX.  Make the
    alignment configurable to enable support for 1GiB page-size mappings.
    
    The offset for PFN_MODE_RAM may now be larger than SZ_8K, so fixup the
    offset check in nvdimm_namespace_attach_pfn().
    
    Reported-by: Toshi Kani <toshi.kani@hpe.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 2ce428e9b584..e4e9f9ae0cc8 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -146,6 +146,7 @@ struct nd_pfn {
 	int id;
 	u8 *uuid;
 	struct device dev;
+	unsigned long align;
 	unsigned long npfns;
 	enum nd_pfn_mode mode;
 	struct nd_pfn_sb *pfn_sb;

commit 9f1e8cee7742cadbe6b97f2c80b787b4ee067bae
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Dec 10 15:14:20 2015 -0800

    libnvdimm, pfn: kill ND_PFN_ALIGN
    
    The alignment constraint isn't necessary now that devm_memremap_pages()
    allows for unaligned mappings.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 417e521d299c..2ce428e9b584 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -29,13 +29,6 @@ enum {
 	ND_MAX_LANES = 256,
 	SECTOR_SHIFT = 9,
 	INT_LBASIZE_ALIGNMENT = 64,
-#if IS_ENABLED(CONFIG_NVDIMM_PFN)
-	ND_PFN_ALIGN = PAGES_PER_SECTION * PAGE_SIZE,
-	ND_PFN_MASK = ND_PFN_ALIGN - 1,
-#else
-	ND_PFN_ALIGN = 0,
-	ND_PFN_MASK = 0,
-#endif
 };
 
 struct nvdimm_drvdata {

commit 004f1afbe199e6ab20805b95aefd83ccd24bc5c7
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Aug 24 19:20:23 2015 -0400

    libnvdimm, pmem: direct map legacy pmem by default
    
    The expectation is that the legacy / non-standard pmem discovery method
    (e820 type-12) will only ever be used to describe small quantities of
    persistent memory.  Larger capacities will be described via the ACPI
    NFIT.  When "allocate struct page from pmem" support is added this default
    policy can be overridden by assigning a legacy pmem namespace to a pfn
    device, however this would be only be necessary if a platform used the
    legacy mechanism to define a very large range.
    
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 83e5d0935012..417e521d299c 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -100,6 +100,7 @@ struct nd_region {
 	struct ida ns_ida;
 	struct ida btt_ida;
 	struct ida pfn_ida;
+	unsigned long flags;
 	struct device *ns_seed;
 	struct device *btt_seed;
 	struct device *pfn_seed;
@@ -276,4 +277,5 @@ static inline bool nd_iostat_start(struct bio *bio, unsigned long *start)
 void nd_iostat_end(struct bio *bio, unsigned long start);
 resource_size_t nd_namespace_blk_validate(struct nd_namespace_blk *nsblk);
 const u8 *nd_dev_to_uuid(struct device *dev);
+bool pmem_should_map_pages(struct device *dev);
 #endif /* __ND_H__ */

commit 32ab0a3f51701cb37ab960635254d5f84ec3de0a
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sat Aug 1 02:16:37 2015 -0400

    libnvdimm, pmem: 'struct page' for pmem
    
    Enable the pmem driver to handle PFN device instances.  Attaching a pmem
    namespace to a pfn device triggers the driver to allocate and initialize
    struct page entries for pmem.  Memory capacity for this allocation comes
    exclusively from RAM for now which is suitable for low PMEM to RAM
    ratios.  This mechanism will be expanded later for setting an "allocate
    from PMEM" policy.
    
    Cc: Boaz Harrosh <boaz@plexistor.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 8da2be1cecb8..83e5d0935012 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -217,6 +217,7 @@ struct nd_pfn *to_nd_pfn(struct device *dev);
 int nd_pfn_probe(struct nd_namespace_common *ndns, void *drvdata);
 bool is_nd_pfn(struct device *dev);
 struct device *nd_pfn_create(struct nd_region *nd_region);
+int nd_pfn_validate(struct nd_pfn *nd_pfn);
 #else
 static inline int nd_pfn_probe(struct nd_namespace_common *ndns, void *drvdata)
 {
@@ -232,6 +233,11 @@ static inline struct device *nd_pfn_create(struct nd_region *nd_region)
 {
 	return NULL;
 }
+
+static inline int nd_pfn_validate(struct nd_pfn *nd_pfn)
+{
+	return -ENODEV;
+}
 #endif
 
 struct nd_region *to_nd_region(struct device *dev);

commit e1455744b27c9e6115c3508a7b2902157c2c4347
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Jul 30 17:57:47 2015 -0400

    libnvdimm, pfn: 'struct page' provider infrastructure
    
    Implement the base infrastructure for libnvdimm PFN devices. Similar to
    BTT devices they take a namespace as a backing device and layer
    functionality on top. In this case the functionality is reserving space
    for an array of 'struct page' entries to be handed out through
    pfn_to_page(). For now this is just the basic libnvdimm-device-model for
    configuring the base PFN device.
    
    As the namespace claiming mechanism for PFN devices is mostly identical
    to BTT devices drivers/nvdimm/claim.c is created to house the common
    bits.
    
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index f9615824947b..8da2be1cecb8 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -29,6 +29,13 @@ enum {
 	ND_MAX_LANES = 256,
 	SECTOR_SHIFT = 9,
 	INT_LBASIZE_ALIGNMENT = 64,
+#if IS_ENABLED(CONFIG_NVDIMM_PFN)
+	ND_PFN_ALIGN = PAGES_PER_SECTION * PAGE_SIZE,
+	ND_PFN_MASK = ND_PFN_ALIGN - 1,
+#else
+	ND_PFN_ALIGN = 0,
+	ND_PFN_MASK = 0,
+#endif
 };
 
 struct nvdimm_drvdata {
@@ -92,8 +99,10 @@ struct nd_region {
 	struct device dev;
 	struct ida ns_ida;
 	struct ida btt_ida;
+	struct ida pfn_ida;
 	struct device *ns_seed;
 	struct device *btt_seed;
+	struct device *pfn_seed;
 	u16 ndr_mappings;
 	u64 ndr_size;
 	u64 ndr_start;
@@ -133,6 +142,22 @@ struct nd_btt {
 	int id;
 };
 
+enum nd_pfn_mode {
+	PFN_MODE_NONE,
+	PFN_MODE_RAM,
+	PFN_MODE_PMEM,
+};
+
+struct nd_pfn {
+	int id;
+	u8 *uuid;
+	struct device dev;
+	unsigned long npfns;
+	enum nd_pfn_mode mode;
+	struct nd_pfn_sb *pfn_sb;
+	struct nd_namespace_common *ndns;
+};
+
 enum nd_async_mode {
 	ND_SYNC,
 	ND_ASYNC,
@@ -159,8 +184,13 @@ int nvdimm_init_config_data(struct nvdimm_drvdata *ndd);
 int nvdimm_set_config_data(struct nvdimm_drvdata *ndd, size_t offset,
 		void *buf, size_t len);
 struct nd_btt *to_nd_btt(struct device *dev);
-struct btt_sb;
-u64 nd_btt_sb_checksum(struct btt_sb *btt_sb);
+
+struct nd_gen_sb {
+	char reserved[SZ_4K - 8];
+	__le64 checksum;
+};
+
+u64 nd_sb_checksum(struct nd_gen_sb *sb);
 #if IS_ENABLED(CONFIG_BTT)
 int nd_btt_probe(struct nd_namespace_common *ndns, void *drvdata);
 bool is_nd_btt(struct device *dev);
@@ -180,8 +210,30 @@ static inline struct device *nd_btt_create(struct nd_region *nd_region)
 {
 	return NULL;
 }
+#endif
 
+struct nd_pfn *to_nd_pfn(struct device *dev);
+#if IS_ENABLED(CONFIG_NVDIMM_PFN)
+int nd_pfn_probe(struct nd_namespace_common *ndns, void *drvdata);
+bool is_nd_pfn(struct device *dev);
+struct device *nd_pfn_create(struct nd_region *nd_region);
+#else
+static inline int nd_pfn_probe(struct nd_namespace_common *ndns, void *drvdata)
+{
+	return -ENODEV;
+}
+
+static inline bool is_nd_pfn(struct device *dev)
+{
+	return false;
+}
+
+static inline struct device *nd_pfn_create(struct nd_region *nd_region)
+{
+	return NULL;
+}
 #endif
+
 struct nd_region *to_nd_region(struct device *dev);
 int nd_region_to_nstype(struct nd_region *nd_region);
 int nd_region_register_namespaces(struct nd_region *nd_region, int *err);

commit 6ec689542b5bc516187917d49b112847dfb75b0b
Author: Vishal Verma <vishal.l.verma@intel.com>
Date:   Wed Jul 29 14:58:09 2015 -0600

    libnvdimm, btt: write and validate parent_uuid
    
    When a BTT is instantiated on a namespace it must validate the namespace
    uuid matches the 'parent_uuid' stored in the btt superblock. This
    property enforces that changing the namespace UUID invalidates all
    former BTT instances on that storage. For "IO namespaces" that don't
    have a label or UUID, the parent_uuid is set to zero, and this
    validation is skipped. For such cases, old BTTs have to be invalidated
    by forcing the namespace to raw mode, and overwriting the BTT info
    blocks.
    
    Based on a patch by Dan Williams <dan.j.williams@intel.com>
    
    Signed-off-by: Vishal Verma <vishal.l.verma@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 835263e47bb8..f9615824947b 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -217,4 +217,5 @@ static inline bool nd_iostat_start(struct bio *bio, unsigned long *start)
 }
 void nd_iostat_end(struct bio *bio, unsigned long start);
 resource_size_t nd_namespace_blk_validate(struct nd_namespace_blk *nsblk);
+const u8 *nd_dev_to_uuid(struct device *dev);
 #endif /* __ND_H__ */

commit f6ef5a2a50816b58e3126206de13d0b9fdf89df5
Author: Randy Dunlap <rdunlap@infradead.org>
Date:   Tue Jul 28 12:27:01 2015 -0700

    nvdimm: fix inline function return type warning
    
    Fix multiple build warnings when CONFIG_BTT is not enabled:
    
    In file included from ../drivers/nvdimm/bus.c:29:0:
    ../drivers/nvdimm/nd.h:169:15: warning: return type defaults to 'int' [-Wreturn-type]
     static inline nd_btt_probe(struct nd_namespace_common *ndns, void *drvdata)
                   ^
    
    Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: linux-nvdimm@lists.01.org
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index c41f53e74277..835263e47bb8 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -166,7 +166,7 @@ int nd_btt_probe(struct nd_namespace_common *ndns, void *drvdata);
 bool is_nd_btt(struct device *dev);
 struct device *nd_btt_create(struct nd_region *nd_region);
 #else
-static inline nd_btt_probe(struct nd_namespace_common *ndns, void *drvdata)
+static inline int nd_btt_probe(struct nd_namespace_common *ndns, void *drvdata)
 {
 	return -ENODEV;
 }

commit 41d7a6d637e1440f5410cb43c25a3c41255540c5
Author: Toshi Kani <toshi.kani@hp.com>
Date:   Fri Jun 19 12:18:33 2015 -0600

    libnvdimm: Set numa_node to NVDIMM devices
    
    ACPI NFIT table has System Physical Address Range Structure entries that
    describe a proximity ID of each range when ACPI_NFIT_PROXIMITY_VALID is
    set in the flags.
    
    Change acpi_nfit_register_region() to map a proximity ID to its node ID,
    and set it to a new numa_node field of nd_region_desc, which is then
    conveyed to the nd_region device.
    
    The device core arranges for btt and namespace devices to inherit their
    node from their parent region.
    
    Signed-off-by: Toshi Kani <toshi.kani@hp.com>
    [djbw: move set_dev_node() from region.c to bus.c]
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 48b09a210689..c41f53e74277 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -97,7 +97,7 @@ struct nd_region {
 	u16 ndr_mappings;
 	u64 ndr_size;
 	u64 ndr_start;
-	int id, num_lanes, ro;
+	int id, num_lanes, ro, numa_node;
 	void *provider_data;
 	struct nd_interleave_set *nd_set;
 	struct nd_percpu_lane __percpu *lane;

commit 581388209405902b56d055f644b4dd124a206112
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Jun 23 20:08:34 2015 -0400

    libnvdimm, nfit: handle unarmed dimms, mark namespaces read-only
    
    Upon detection of an unarmed dimm in a region, arrange for descendant
    BTT, PMEM, or BLK instances to be read-only.  A dimm is primarily marked
    "unarmed" via flags passed by platform firmware (NFIT).
    
    The flags in the NFIT memory device sub-structure indicate the state of
    the data on the nvdimm relative to its energy source or last "flush to
    persistence".  For the most part there is nothing the driver can do but
    advertise the state of these flags in sysfs and emit a message if
    firmware indicates that the contents of the device may be corrupted.
    However, for the case of ACPI_NFIT_MEM_ARMED, the driver can arrange for
    the block devices incorporating that nvdimm to be marked read-only.
    This is a safe default as the data is still available and new writes are
    held off until the administrator either forces read-write mode, or the
    energy source becomes armed.
    
    A 'read_only' attribute is added to REGION devices to allow for
    overriding the default read-only policy of all descendant block devices.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 4614b00542d1..48b09a210689 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -97,7 +97,7 @@ struct nd_region {
 	u16 ndr_mappings;
 	u64 ndr_size;
 	u64 ndr_start;
-	int id, num_lanes;
+	int id, num_lanes, ro;
 	void *provider_data;
 	struct nd_interleave_set *nd_set;
 	struct nd_percpu_lane __percpu *lane;
@@ -189,6 +189,7 @@ u64 nd_region_interleave_set_cookie(struct nd_region *nd_region);
 void nvdimm_bus_lock(struct device *dev);
 void nvdimm_bus_unlock(struct device *dev);
 bool is_nvdimm_bus_locked(struct device *dev);
+int nvdimm_revalidate_disk(struct gendisk *disk);
 void nvdimm_drvdata_release(struct kref *kref);
 void put_ndd(struct nvdimm_drvdata *ndd);
 int nd_label_reserve_dpa(struct nvdimm_drvdata *ndd);

commit f0dc089ce217e7b98e0d2077c548ff08129e7911
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sat May 16 12:28:53 2015 -0400

    libnvdimm: enable iostat
    
    This is disabled by default as the overhead is prohibitive, but if the
    user takes the action to turn it on we'll oblige.
    
    Reviewed-by: Vishal Verma <vishal.l.verma@linux.intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 6f916b65b7d6..4614b00542d1 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -13,6 +13,7 @@
 #ifndef __ND_H__
 #define __ND_H__
 #include <linux/libnvdimm.h>
+#include <linux/blkdev.h>
 #include <linux/device.h>
 #include <linux/mutex.h>
 #include <linux/ndctl.h>
@@ -202,5 +203,17 @@ int nvdimm_namespace_detach_btt(struct nd_namespace_common *ndns);
 const char *nvdimm_namespace_disk_name(struct nd_namespace_common *ndns,
 		char *name);
 int nd_blk_region_init(struct nd_region *nd_region);
+void __nd_iostat_start(struct bio *bio, unsigned long *start);
+static inline bool nd_iostat_start(struct bio *bio, unsigned long *start)
+{
+	struct gendisk *disk = bio->bi_bdev->bd_disk;
+
+	if (!blk_queue_io_stat(disk->queue))
+		return false;
+
+	__nd_iostat_start(bio, start);
+	return true;
+}
+void nd_iostat_end(struct bio *bio, unsigned long start);
 resource_size_t nd_namespace_blk_validate(struct nd_namespace_blk *nsblk);
 #endif /* __ND_H__ */

commit fcae695737fca0849c18db814d9d8de05c0fd2a2
Author: Vishal Verma <vishal.l.verma@intel.com>
Date:   Thu Jun 25 04:22:39 2015 -0400

    libnvdimm, blk: add support for blk integrity
    
    Support multiple block sizes (sector + metadata) for nd_blk in the
    same way as done for the BTT. Add the idea of an 'internal' lbasize,
    which is properly aligned and padded, and store metadata in this space.
    
    Signed-off-by: Vishal Verma <vishal.l.verma@linux.intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index f4459faa456c..6f916b65b7d6 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -27,6 +27,7 @@ enum {
 	 */
 	ND_MAX_LANES = 256,
 	SECTOR_SHIFT = 9,
+	INT_LBASIZE_ALIGNMENT = 64,
 };
 
 struct nvdimm_drvdata {

commit 41cd8b70c37ace40077c8d6ec0b74b983178c192
Author: Vishal Verma <vishal.l.verma@intel.com>
Date:   Thu Jun 25 04:21:52 2015 -0400

    libnvdimm, btt: add support for blk integrity
    
    Support multiple block sizes (sector + metadata) using the blk integrity
    framework. This registers a new integrity template that defines the
    protection information tuple size based on the configured metadata size,
    and simply acts as a passthrough for protection information generated by
    another layer. The metadata is written to the storage as-is, and read back
    with each sector.
    
    Signed-off-by: Vishal Verma <vishal.l.verma@linux.intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index f153f43ca3d6..f4459faa456c 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -136,6 +136,7 @@ enum nd_async_mode {
 	ND_ASYNC,
 };
 
+int nd_integrity_init(struct gendisk *disk, unsigned long meta_size);
 void wait_nvdimm_bus_probe_idle(struct device *dev);
 void nd_device_register(struct device *dev);
 void nd_device_unregister(struct device *dev, enum nd_async_mode mode);

commit 047fc8a1f9a6330eacc80374dff087e20dc2304b
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Thu Jun 25 04:21:02 2015 -0400

    libnvdimm, nfit, nd_blk: driver for BLK-mode access persistent memory
    
    The libnvdimm implementation handles allocating dimm address space (DPA)
    between PMEM and BLK mode interfaces.  After DPA has been allocated from
    a BLK-region to a BLK-namespace the nd_blk driver attaches to handle I/O
    as a struct bio based block device. Unlike PMEM, BLK is required to
    handle platform specific details like mmio register formats and memory
    controller interleave.  For this reason the libnvdimm generic nd_blk
    driver calls back into the bus provider to carry out the I/O.
    
    This initial implementation handles the BLK interface defined by the
    ACPI 6 NFIT [1] and the NVDIMM DSM Interface Example [2] composed from
    DCR (dimm control region), BDW (block data window), IDT (interleave
    descriptor) NFIT structures and the hardware register format.
    [1]: http://www.uefi.org/sites/default/files/resources/ACPI_6.0.pdf
    [2]: http://pmem.io/documents/NVDIMM_DSM_Interface_Example.pdf
    
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Boaz Harrosh <boaz@plexistor.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Acked-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 1b937c235913..f153f43ca3d6 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -102,6 +102,15 @@ struct nd_region {
 	struct nd_mapping mapping[0];
 };
 
+struct nd_blk_region {
+	int (*enable)(struct nvdimm_bus *nvdimm_bus, struct device *dev);
+	void (*disable)(struct nvdimm_bus *nvdimm_bus, struct device *dev);
+	int (*do_io)(struct nd_blk_region *ndbr, resource_size_t dpa,
+			void *iobuf, u64 len, int rw);
+	void *blk_provider_data;
+	struct nd_region nd_region;
+};
+
 /*
  * Lookup next in the repeating sequence of 01, 10, and 11.
  */
@@ -171,8 +180,6 @@ static inline struct device *nd_btt_create(struct nd_region *nd_region)
 
 #endif
 struct nd_region *to_nd_region(struct device *dev);
-unsigned int nd_region_acquire_lane(struct nd_region *nd_region);
-void nd_region_release_lane(struct nd_region *nd_region, unsigned int lane);
 int nd_region_to_nstype(struct nd_region *nd_region);
 int nd_region_register_namespaces(struct nd_region *nd_region, int *err);
 u64 nd_region_interleave_set_cookie(struct nd_region *nd_region);
@@ -192,4 +199,6 @@ int nvdimm_namespace_attach_btt(struct nd_namespace_common *ndns);
 int nvdimm_namespace_detach_btt(struct nd_namespace_common *ndns);
 const char *nvdimm_namespace_disk_name(struct nd_namespace_common *ndns,
 		char *name);
+int nd_blk_region_init(struct nd_region *nd_region);
+resource_size_t nd_namespace_blk_validate(struct nd_namespace_blk *nsblk);
 #endif /* __ND_H__ */

commit 5212e11fde4d40fa627668b4f2222d20db488f71
Author: Vishal Verma <vishal.l.verma@intel.com>
Date:   Thu Jun 25 04:20:32 2015 -0400

    nd_btt: atomic sector updates
    
    BTT stands for Block Translation Table, and is a way to provide power
    fail sector atomicity semantics for block devices that have the ability
    to perform byte granularity IO. It relies on the capability of libnvdimm
    namespace devices to do byte aligned IO.
    
    The BTT works as a stacked blocked device, and reserves a chunk of space
    from the backing device for its accounting metadata. It is a bio-based
    driver because all IO is done synchronously, and there is no queuing or
    asynchronous completions at either the device or the driver level.
    
    The BTT uses 'lanes' to index into various 'on-disk' data structures,
    and lanes also act as a synchronization mechanism in case there are more
    CPUs than available lanes. We did a comparison between two lane lock
    strategies - first where we kept an atomic counter around that tracked
    which was the last lane that was used, and 'our' lane was determined by
    atomically incrementing that. That way, for the nr_cpus > nr_lanes case,
    theoretically, no CPU would be blocked waiting for a lane. The other
    strategy was to use the cpu number we're scheduled on to and hash it to
    a lane number. Theoretically, this could block an IO that could've
    otherwise run using a different, free lane. But some fio workloads
    showed that the direct cpu -> lane hash performed faster than tracking
    'last lane' - my reasoning is the cache thrash caused by moving the
    atomic variable made that approach slower than simply waiting out the
    in-progress IO. This supports the conclusion that the driver can be a
    very simple bio-based one that does synchronous IOs instead of queuing.
    
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Boaz Harrosh <boaz@plexistor.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Jeff Moyer <jmoyer@redhat.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    [jmoyer: fix nmi watchdog timeout in btt_map_init]
    [jmoyer: move btt initialization to module load path]
    [jmoyer: fix memory leak in the btt initialization path]
    [jmoyer: Don't overwrite corrupted arenas]
    Signed-off-by: Vishal Verma <vishal.l.verma@linux.intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index d13eccbb67e9..1b937c235913 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -20,6 +20,12 @@
 #include "label.h"
 
 enum {
+	/*
+	 * Limits the maximum number of block apertures a dimm can
+	 * support and is an input to the geometry/on-disk-format of a
+	 * BTT instance
+	 */
+	ND_MAX_LANES = 256,
 	SECTOR_SHIFT = 9,
 };
 
@@ -75,6 +81,11 @@ static inline struct nd_namespace_index *to_next_namespace_index(
 	for (res = (ndd)->dpa.child, next = res ? res->sibling : NULL; \
 			res; res = next, next = next ? next->sibling : NULL)
 
+struct nd_percpu_lane {
+	int count;
+	spinlock_t lock;
+};
+
 struct nd_region {
 	struct device dev;
 	struct ida ns_ida;
@@ -84,9 +95,10 @@ struct nd_region {
 	u16 ndr_mappings;
 	u64 ndr_size;
 	u64 ndr_start;
-	int id;
+	int id, num_lanes;
 	void *provider_data;
 	struct nd_interleave_set *nd_set;
+	struct nd_percpu_lane __percpu *lane;
 	struct nd_mapping mapping[0];
 };
 
@@ -100,9 +112,11 @@ static inline unsigned nd_inc_seq(unsigned seq)
 	return next[seq & 3];
 }
 
+struct btt;
 struct nd_btt {
 	struct device dev;
 	struct nd_namespace_common *ndns;
+	struct btt *btt;
 	unsigned long lbasize;
 	u8 *uuid;
 	int id;
@@ -157,6 +171,8 @@ static inline struct device *nd_btt_create(struct nd_region *nd_region)
 
 #endif
 struct nd_region *to_nd_region(struct device *dev);
+unsigned int nd_region_acquire_lane(struct nd_region *nd_region);
+void nd_region_release_lane(struct nd_region *nd_region, unsigned int lane);
 int nd_region_to_nstype(struct nd_region *nd_region);
 int nd_region_register_namespaces(struct nd_region *nd_region, int *err);
 u64 nd_region_interleave_set_cookie(struct nd_region *nd_region);
@@ -172,4 +188,8 @@ struct resource *nvdimm_allocate_dpa(struct nvdimm_drvdata *ndd,
 		resource_size_t n);
 resource_size_t nvdimm_namespace_capacity(struct nd_namespace_common *ndns);
 struct nd_namespace_common *nvdimm_namespace_common_probe(struct device *dev);
+int nvdimm_namespace_attach_btt(struct nd_namespace_common *ndns);
+int nvdimm_namespace_detach_btt(struct nd_namespace_common *ndns);
+const char *nvdimm_namespace_disk_name(struct nd_namespace_common *ndns,
+		char *name);
 #endif /* __ND_H__ */

commit 8c2f7e8658df1d3b7cbfa62706941d14c715823a
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Jun 25 04:20:04 2015 -0400

    libnvdimm: infrastructure for btt devices
    
    NVDIMM namespaces, in addition to accepting "struct bio" based requests,
    also have the capability to perform byte-aligned accesses.  By default
    only the bio/block interface is used.  However, if another driver can
    make effective use of the byte-aligned capability it can claim namespace
    interface and use the byte-aligned ->rw_bytes() interface.
    
    The BTT driver is the initial first consumer of this mechanism to allow
    adding atomic sector update semantics to a pmem or blk namespace.  This
    patch is the sysfs infrastructure to allow configuring a BTT instance
    for a namespace.  Enabling that BTT and performing i/o is in a
    subsequent patch.
    
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: Neil Brown <neilb@suse.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index bfa849617358..d13eccbb67e9 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -19,6 +19,10 @@
 #include <linux/types.h>
 #include "label.h"
 
+enum {
+	SECTOR_SHIFT = 9,
+};
+
 struct nvdimm_drvdata {
 	struct device *dev;
 	int nsindex_size;
@@ -74,7 +78,9 @@ static inline struct nd_namespace_index *to_next_namespace_index(
 struct nd_region {
 	struct device dev;
 	struct ida ns_ida;
+	struct ida btt_ida;
 	struct device *ns_seed;
+	struct device *btt_seed;
 	u16 ndr_mappings;
 	u64 ndr_size;
 	u64 ndr_start;
@@ -94,6 +100,14 @@ static inline unsigned nd_inc_seq(unsigned seq)
 	return next[seq & 3];
 }
 
+struct nd_btt {
+	struct device dev;
+	struct nd_namespace_common *ndns;
+	unsigned long lbasize;
+	u8 *uuid;
+	int id;
+};
+
 enum nd_async_mode {
 	ND_SYNC,
 	ND_ASYNC,
@@ -118,6 +132,30 @@ int nvdimm_init_nsarea(struct nvdimm_drvdata *ndd);
 int nvdimm_init_config_data(struct nvdimm_drvdata *ndd);
 int nvdimm_set_config_data(struct nvdimm_drvdata *ndd, size_t offset,
 		void *buf, size_t len);
+struct nd_btt *to_nd_btt(struct device *dev);
+struct btt_sb;
+u64 nd_btt_sb_checksum(struct btt_sb *btt_sb);
+#if IS_ENABLED(CONFIG_BTT)
+int nd_btt_probe(struct nd_namespace_common *ndns, void *drvdata);
+bool is_nd_btt(struct device *dev);
+struct device *nd_btt_create(struct nd_region *nd_region);
+#else
+static inline nd_btt_probe(struct nd_namespace_common *ndns, void *drvdata)
+{
+	return -ENODEV;
+}
+
+static inline bool is_nd_btt(struct device *dev)
+{
+	return false;
+}
+
+static inline struct device *nd_btt_create(struct nd_region *nd_region)
+{
+	return NULL;
+}
+
+#endif
 struct nd_region *to_nd_region(struct device *dev);
 int nd_region_to_nstype(struct nd_region *nd_region);
 int nd_region_register_namespaces(struct nd_region *nd_region, int *err);
@@ -132,4 +170,6 @@ void nvdimm_free_dpa(struct nvdimm_drvdata *ndd, struct resource *res);
 struct resource *nvdimm_allocate_dpa(struct nvdimm_drvdata *ndd,
 		struct nd_label_id *label_id, resource_size_t start,
 		resource_size_t n);
+resource_size_t nvdimm_namespace_capacity(struct nd_namespace_common *ndns);
+struct nd_namespace_common *nvdimm_namespace_common_probe(struct device *dev);
 #endif /* __ND_H__ */

commit f524bf271a5cf12a44253194abcf8b6688ff5b9d
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sat May 30 12:36:02 2015 -0400

    libnvdimm: write pmem label set
    
    After 'uuid', 'size', and optionally 'alt_name' have been set to valid
    values the labels on the dimms can be updated.
    
    Write procedure is:
    1/ Allocate and write new labels in the "next" index
    2/ Free the old labels in the working copy
    3/ Write the bitmap and the label space on the dimm
    4/ Write the index to make the update valid
    
    Label ranges directly mirror the dpa resource values for the given
    label_id of the namespace.
    
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: Neil Brown <neilb@suse.de>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 9b021b626202..bfa849617358 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -93,6 +93,7 @@ static inline unsigned nd_inc_seq(unsigned seq)
 
 	return next[seq & 3];
 }
+
 enum nd_async_mode {
 	ND_SYNC,
 	ND_ASYNC,
@@ -115,6 +116,8 @@ struct nvdimm;
 struct nvdimm_drvdata *to_ndd(struct nd_mapping *nd_mapping);
 int nvdimm_init_nsarea(struct nvdimm_drvdata *ndd);
 int nvdimm_init_config_data(struct nvdimm_drvdata *ndd);
+int nvdimm_set_config_data(struct nvdimm_drvdata *ndd, size_t offset,
+		void *buf, size_t len);
 struct nd_region *to_nd_region(struct device *dev);
 int nd_region_to_nstype(struct nd_region *nd_region);
 int nd_region_register_namespaces(struct nd_region *nd_region, int *err);

commit 1b40e09a1232de537b193fa1b6b3ef16d3a1e397
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri May 1 13:34:01 2015 -0400

    libnvdimm: blk labels and namespace instantiation
    
    A blk label set describes a namespace comprised of one or more
    discontiguous dpa ranges on a single dimm.  They may alias with one or
    more pmem interleave sets that include the given dimm.
    
    This is the runtime/volatile configuration infrastructure for sysfs
    manipulation of 'alt_name', 'uuid', 'size', and 'sector_size'.  A later
    patch will make these settings persistent by writing back the label(s).
    
    Unlike pmem namespaces, multiple blk namespaces can be created per
    region.  Once a blk namespace has been created a new seed device
    (unconfigured child of a parent blk region) is instantiated.  As long as
    a region has 'available_size' != 0 new child namespaces may be created.
    
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: Neil Brown <neilb@suse.de>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 03e610cd9f43..9b021b626202 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -73,6 +73,7 @@ static inline struct nd_namespace_index *to_next_namespace_index(
 
 struct nd_region {
 	struct device dev;
+	struct ida ns_ida;
 	struct device *ns_seed;
 	u16 ndr_mappings;
 	u64 ndr_size;
@@ -102,6 +103,10 @@ void nd_device_register(struct device *dev);
 void nd_device_unregister(struct device *dev, enum nd_async_mode mode);
 int nd_uuid_store(struct device *dev, u8 **uuid_out, const char *buf,
 		size_t len);
+ssize_t nd_sector_size_show(unsigned long current_lbasize,
+		const unsigned long *supported, char *buf);
+ssize_t nd_sector_size_store(struct device *dev, const char *buf,
+		unsigned long *current_lbasize, const unsigned long *supported);
 int __init nvdimm_init(void);
 int __init nd_region_init(void);
 void nvdimm_exit(void);

commit bf9bccc14c05dae8caba29df6187c731710f5380
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed Jun 17 17:14:46 2015 -0400

    libnvdimm: pmem label sets and namespace instantiation.
    
    A complete label set is a PMEM-label per-dimm per-interleave-set where
    all the UUIDs match and the interleave set cookie matches the hosting
    interleave set.
    
    Present sysfs attributes for manipulation of a PMEM-namespace's
    'alt_name', 'uuid', and 'size' attributes.  A later patch will make
    these settings persistent by writing back the label.
    
    Note that PMEM allocations grow forwards from the start of an interleave
    set (lowest dimm-physical-address (DPA)).  BLK-namespaces that alias
    with a PMEM interleave set will grow allocations backward from the
    highest DPA.
    
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: Neil Brown <neilb@suse.de>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 401fa0d5b6ea..03e610cd9f43 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -16,6 +16,7 @@
 #include <linux/device.h>
 #include <linux/mutex.h>
 #include <linux/ndctl.h>
+#include <linux/types.h>
 #include "label.h"
 
 struct nvdimm_drvdata {
@@ -25,6 +26,7 @@ struct nvdimm_drvdata {
 	void *data;
 	int ns_current, ns_next;
 	struct resource dpa;
+	struct kref kref;
 };
 
 struct nd_region_namespaces {
@@ -59,12 +61,19 @@ static inline struct nd_namespace_index *to_next_namespace_index(
 		(unsigned long long) (res ? resource_size(res) : 0), \
 		(unsigned long long) (res ? res->start : 0), ##arg)
 
+#define for_each_label(l, label, labels) \
+	for (l = 0; (label = labels ? labels[l] : NULL); l++)
+
+#define for_each_dpa_resource(ndd, res) \
+	for (res = (ndd)->dpa.child; res; res = res->sibling)
+
 #define for_each_dpa_resource_safe(ndd, res, next) \
 	for (res = (ndd)->dpa.child, next = res ? res->sibling : NULL; \
 			res; res = next, next = next ? next->sibling : NULL)
 
 struct nd_region {
 	struct device dev;
+	struct device *ns_seed;
 	u16 ndr_mappings;
 	u64 ndr_size;
 	u64 ndr_start;
@@ -88,20 +97,28 @@ enum nd_async_mode {
 	ND_ASYNC,
 };
 
+void wait_nvdimm_bus_probe_idle(struct device *dev);
 void nd_device_register(struct device *dev);
 void nd_device_unregister(struct device *dev, enum nd_async_mode mode);
+int nd_uuid_store(struct device *dev, u8 **uuid_out, const char *buf,
+		size_t len);
 int __init nvdimm_init(void);
 int __init nd_region_init(void);
 void nvdimm_exit(void);
 void nd_region_exit(void);
+struct nvdimm;
+struct nvdimm_drvdata *to_ndd(struct nd_mapping *nd_mapping);
 int nvdimm_init_nsarea(struct nvdimm_drvdata *ndd);
 int nvdimm_init_config_data(struct nvdimm_drvdata *ndd);
 struct nd_region *to_nd_region(struct device *dev);
 int nd_region_to_nstype(struct nd_region *nd_region);
 int nd_region_register_namespaces(struct nd_region *nd_region, int *err);
+u64 nd_region_interleave_set_cookie(struct nd_region *nd_region);
 void nvdimm_bus_lock(struct device *dev);
 void nvdimm_bus_unlock(struct device *dev);
 bool is_nvdimm_bus_locked(struct device *dev);
+void nvdimm_drvdata_release(struct kref *kref);
+void put_ndd(struct nvdimm_drvdata *ndd);
 int nd_label_reserve_dpa(struct nvdimm_drvdata *ndd);
 void nvdimm_free_dpa(struct nvdimm_drvdata *ndd, struct resource *res);
 struct resource *nvdimm_allocate_dpa(struct nvdimm_drvdata *ndd,

commit 4a826c83db4edc040da3a66dbefd53f0cfcf457d
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Jun 9 16:09:36 2015 -0400

    libnvdimm: namespace indices: read and validate
    
    This on media label format [1] consists of two index blocks followed by
    an array of labels.  None of these structures are ever updated in place.
    A sequence number tracks the current active index and the next one to
    write, while labels are written to free slots.
    
        +------------+
        |            |
        |  nsindex0  |
        |            |
        +------------+
        |            |
        |  nsindex1  |
        |            |
        +------------+
        |   label0   |
        +------------+
        |   label1   |
        +------------+
        |            |
         ....nslot...
        |            |
        +------------+
        |   labelN   |
        +------------+
    
    After reading valid labels, store the dpa ranges they claim into
    per-dimm resource trees.
    
    [1]: http://pmem.io/documents/NVDIMM_Namespace_Spec.pdf
    
    Cc: Neil Brown <neilb@suse.de>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 0285e4588b03..401fa0d5b6ea 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -16,11 +16,15 @@
 #include <linux/device.h>
 #include <linux/mutex.h>
 #include <linux/ndctl.h>
+#include "label.h"
 
 struct nvdimm_drvdata {
 	struct device *dev;
+	int nsindex_size;
 	struct nd_cmd_get_config_size nsarea;
 	void *data;
+	int ns_current, ns_next;
+	struct resource dpa;
 };
 
 struct nd_region_namespaces {
@@ -28,6 +32,37 @@ struct nd_region_namespaces {
 	int active;
 };
 
+static inline struct nd_namespace_index *to_namespace_index(
+		struct nvdimm_drvdata *ndd, int i)
+{
+	if (i < 0)
+		return NULL;
+
+	return ndd->data + sizeof_namespace_index(ndd) * i;
+}
+
+static inline struct nd_namespace_index *to_current_namespace_index(
+		struct nvdimm_drvdata *ndd)
+{
+	return to_namespace_index(ndd, ndd->ns_current);
+}
+
+static inline struct nd_namespace_index *to_next_namespace_index(
+		struct nvdimm_drvdata *ndd)
+{
+	return to_namespace_index(ndd, ndd->ns_next);
+}
+
+#define nd_dbg_dpa(r, d, res, fmt, arg...) \
+	dev_dbg((r) ? &(r)->dev : (d)->dev, "%s: %.13s: %#llx @ %#llx " fmt, \
+		(r) ? dev_name((d)->dev) : "", res ? res->name : "null", \
+		(unsigned long long) (res ? resource_size(res) : 0), \
+		(unsigned long long) (res ? res->start : 0), ##arg)
+
+#define for_each_dpa_resource_safe(ndd, res, next) \
+	for (res = (ndd)->dpa.child, next = res ? res->sibling : NULL; \
+			res; res = next, next = next ? next->sibling : NULL)
+
 struct nd_region {
 	struct device dev;
 	u16 ndr_mappings;
@@ -39,6 +74,15 @@ struct nd_region {
 	struct nd_mapping mapping[0];
 };
 
+/*
+ * Lookup next in the repeating sequence of 01, 10, and 11.
+ */
+static inline unsigned nd_inc_seq(unsigned seq)
+{
+	static const unsigned next[] = { 0, 2, 3, 1 };
+
+	return next[seq & 3];
+}
 enum nd_async_mode {
 	ND_SYNC,
 	ND_ASYNC,
@@ -58,4 +102,9 @@ int nd_region_register_namespaces(struct nd_region *nd_region, int *err);
 void nvdimm_bus_lock(struct device *dev);
 void nvdimm_bus_unlock(struct device *dev);
 bool is_nvdimm_bus_locked(struct device *dev);
+int nd_label_reserve_dpa(struct nvdimm_drvdata *ndd);
+void nvdimm_free_dpa(struct nvdimm_drvdata *ndd, struct resource *res);
+struct resource *nvdimm_allocate_dpa(struct nvdimm_drvdata *ndd,
+		struct nd_label_id *label_id, resource_size_t start,
+		resource_size_t n);
 #endif /* __ND_H__ */

commit eaf961536e1622ad21247ac8d44acd48ba65566e
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri May 1 13:11:27 2015 -0400

    libnvdimm, nfit: add interleave-set state-tracking infrastructure
    
    On platforms that have firmware support for reading/writing per-dimm
    label space, a portion of the dimm may be accessible via an interleave
    set PMEM mapping in addition to the dimm's BLK (block-data-window
    aperture(s)) interface.  A label, stored in a "configuration data
    region" on the dimm, disambiguates which dimm addresses are accessed
    through which exclusive interface.
    
    Add infrastructure that allows the kernel to block modifications to a
    label in the set while any member dimm is active.  Note that this is
    meant only for enforcing "no modifications of active labels" via the
    coarse ioctl command.  Adding/deleting namespaces from an active
    interleave set is always possible via sysfs.
    
    Another aspect of tracking interleave sets is tracking their integrity
    when DIMMs in a set are physically re-ordered.  For this purpose we
    generate an "interleave-set cookie" that can be recorded in a label and
    validated against the current configuration.  It is the bus provider
    implementation's responsibility to calculate the interleave set cookie
    and attach it to a given region.
    
    Cc: Neil Brown <neilb@suse.de>
    Cc: <linux-acpi@vger.kernel.org>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: Robert Moore <robert.moore@intel.com>
    Cc: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index bc5a08e36a25..0285e4588b03 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -35,6 +35,7 @@ struct nd_region {
 	u64 ndr_start;
 	int id;
 	void *provider_data;
+	struct nd_interleave_set *nd_set;
 	struct nd_mapping mapping[0];
 };
 

commit 3d88002e4a7bd40f355550284c6cd140e6fe29dc
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sun May 31 15:02:11 2015 -0400

    libnvdimm: support for legacy (non-aliasing) nvdimms
    
    The libnvdimm region driver is an intermediary driver that translates
    non-volatile "region"s into "namespace" sub-devices that are surfaced by
    persistent memory block-device drivers (PMEM and BLK).
    
    ACPI 6 introduces the concept that a given nvdimm may simultaneously
    offer multiple access modes to its media through direct PMEM load/store
    access, or windowed BLK mode.  Existing nvdimms mostly implement a PMEM
    interface, some offer a BLK-like mode, but never both as ACPI 6 defines.
    If an nvdimm is single interfaced, then there is no need for dimm
    metadata labels.  For these devices we can take the region boundaries
    directly to create a child namespace device (nd_namespace_io).
    
    Acked-by: Christoph Hellwig <hch@lst.de>
    Tested-by: Toshi Kani <toshi.kani@hp.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index ea0cca337aa6..bc5a08e36a25 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -23,6 +23,11 @@ struct nvdimm_drvdata {
 	void *data;
 };
 
+struct nd_region_namespaces {
+	int count;
+	int active;
+};
+
 struct nd_region {
 	struct device dev;
 	u16 ndr_mappings;
@@ -41,7 +46,15 @@ enum nd_async_mode {
 void nd_device_register(struct device *dev);
 void nd_device_unregister(struct device *dev, enum nd_async_mode mode);
 int __init nvdimm_init(void);
+int __init nd_region_init(void);
 void nvdimm_exit(void);
+void nd_region_exit(void);
 int nvdimm_init_nsarea(struct nvdimm_drvdata *ndd);
 int nvdimm_init_config_data(struct nvdimm_drvdata *ndd);
+struct nd_region *to_nd_region(struct device *dev);
+int nd_region_to_nstype(struct nd_region *nd_region);
+int nd_region_register_namespaces(struct nd_region *nd_region, int *err);
+void nvdimm_bus_lock(struct device *dev);
+void nvdimm_bus_unlock(struct device *dev);
+bool is_nvdimm_bus_locked(struct device *dev);
 #endif /* __ND_H__ */

commit 1f7df6f88b9245a7f2d0f8ecbc97dc88c8d0d8e1
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Jun 9 20:13:14 2015 -0400

    libnvdimm, nfit: regions (block-data-window, persistent memory, volatile memory)
    
    A "region" device represents the maximum capacity of a BLK range (mmio
    block-data-window(s)), or a PMEM range (DAX-capable persistent memory or
    volatile memory), without regard for aliasing.  Aliasing, in the
    dimm-local address space (DPA), is resolved by metadata on a dimm to
    designate which exclusive interface will access the aliased DPA ranges.
    Support for the per-dimm metadata/label arrvies is in a subsequent
    patch.
    
    The name format of "region" devices is "regionN" where, like dimms, N is
    a global ida index assigned at discovery time.  This id is not reliable
    across reboots nor in the presence of hotplug.  Look to attributes of
    the region or static id-data of the sub-namespace to generate a
    persistent name.  However, if the platform configuration does not change
    it is reasonable to expect the same region id to be assigned at the next
    boot.
    
    "region"s have 2 generic attributes "size", and "mapping"s where:
    - size: the BLK accessible capacity or the span of the
      system physical address range in the case of PMEM.
    
    - mappingN: a tuple describing a dimm's contribution to the region's
      capacity in the format (<nmemX>,<dpa>,<size>).  For a PMEM-region
      there will be at least one mapping per dimm in the interleave set.  For
      a BLK-region there is only "mapping0" listing the starting DPA of the
      BLK-region and the available DPA capacity of that space (matches "size"
      above).
    
    The max number of mappings per "region" is hard coded per the
    constraints of sysfs attribute groups.  That said the number of mappings
    per region should never exceed the maximum number of possible dimms in
    the system.  If the current number turns out to not be enough then the
    "mappings" attribute clarifies how many there are supposed to be. "32
    should be enough for anybody...".
    
    Cc: Neil Brown <neilb@suse.de>
    Cc: <linux-acpi@vger.kernel.org>
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: Robert Moore <robert.moore@intel.com>
    Cc: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Tested-by: Toshi Kani <toshi.kani@hp.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
index 1f7f6ecab0fc..ea0cca337aa6 100644
--- a/drivers/nvdimm/nd.h
+++ b/drivers/nvdimm/nd.h
@@ -12,6 +12,7 @@
  */
 #ifndef __ND_H__
 #define __ND_H__
+#include <linux/libnvdimm.h>
 #include <linux/device.h>
 #include <linux/mutex.h>
 #include <linux/ndctl.h>
@@ -22,6 +23,16 @@ struct nvdimm_drvdata {
 	void *data;
 };
 
+struct nd_region {
+	struct device dev;
+	u16 ndr_mappings;
+	u64 ndr_size;
+	u64 ndr_start;
+	int id;
+	void *provider_data;
+	struct nd_mapping mapping[0];
+};
+
 enum nd_async_mode {
 	ND_SYNC,
 	ND_ASYNC,

commit 4d88a97aa9e8cfa6460aab119c5da60ad2267423
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sun May 31 14:41:48 2015 -0400

    libnvdimm, nvdimm: dimm driver and base libnvdimm device-driver infrastructure
    
    * Implement the device-model infrastructure for loading modules and
      attaching drivers to nvdimm devices.  This is a simple association of a
      nd-device-type number with a driver that has a bitmask of supported
      device types.  To facilitate userspace bind/unbind operations 'modalias'
      and 'devtype', that also appear in the uevent, are added as generic
      sysfs attributes for all nvdimm devices.  The reason for the device-type
      number is to support sub-types within a given parent devtype, be it a
      vendor-specific sub-type or otherwise.
    
    * The first consumer of this infrastructure is the driver
      for dimm devices.  It simply uses control messages to retrieve and
      store the configuration-data image (label set) from each dimm.
    
    Note: nd_device_register() arranges for asynchronous registration of
          nvdimm bus devices by default.
    
    Cc: Greg KH <gregkh@linuxfoundation.org>
    Cc: Neil Brown <neilb@suse.de>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Tested-by: Toshi Kani <toshi.kani@hp.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h
new file mode 100644
index 000000000000..1f7f6ecab0fc
--- /dev/null
+++ b/drivers/nvdimm/nd.h
@@ -0,0 +1,36 @@
+/*
+ * Copyright(c) 2013-2015 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ */
+#ifndef __ND_H__
+#define __ND_H__
+#include <linux/device.h>
+#include <linux/mutex.h>
+#include <linux/ndctl.h>
+
+struct nvdimm_drvdata {
+	struct device *dev;
+	struct nd_cmd_get_config_size nsarea;
+	void *data;
+};
+
+enum nd_async_mode {
+	ND_SYNC,
+	ND_ASYNC,
+};
+
+void nd_device_register(struct device *dev);
+void nd_device_unregister(struct device *dev, enum nd_async_mode mode);
+int __init nvdimm_init(void);
+void nvdimm_exit(void);
+int nvdimm_init_nsarea(struct nvdimm_drvdata *ndd);
+int nvdimm_init_config_data(struct nvdimm_drvdata *ndd);
+#endif /* __ND_H__ */
