commit 9ac8545199a1b711f5643f535b82981faa0b4bf1
Author: Qian Cai <cai@lca.pw>
Date:   Fri Jul 3 20:10:03 2020 -0400

    iommu: Fix use-after-free in iommu_release_device
    
    In pci_disable_sriov(), i.e.,
    
     # echo 0 > /sys/class/net/enp11s0f1np1/device/sriov_numvfs
    
    iommu_release_device
      iommu_group_remove_device
        arm_smmu_domain_free
          kfree(smmu_domain)
    
    Later,
    
    iommu_release_device
      arm_smmu_release_device
        arm_smmu_detach_dev
          spin_lock_irqsave(&smmu_domain->devices_lock,
    
    would trigger an use-after-free. Fixed it by call
    arm_smmu_release_device() first before iommu_group_remove_device().
    
     BUG: KASAN: use-after-free in __lock_acquire+0x3458/0x4440
      __lock_acquire at kernel/locking/lockdep.c:4250
     Read of size 8 at addr ffff0089df1a6f68 by task bash/3356
    
     CPU: 5 PID: 3356 Comm: bash Not tainted 5.8.0-rc3-next-20200630 #2
     Hardware name: HPE Apollo 70             /C01_APACHE_MB         , BIOS L50_5.13_1.11 06/18/2019
     Call trace:
      dump_backtrace+0x0/0x398
      show_stack+0x14/0x20
      dump_stack+0x140/0x1b8
      print_address_description.isra.12+0x54/0x4a8
      kasan_report+0x134/0x1b8
      __asan_report_load8_noabort+0x2c/0x50
      __lock_acquire+0x3458/0x4440
      lock_acquire+0x204/0xf10
      _raw_spin_lock_irqsave+0xf8/0x180
      arm_smmu_detach_dev+0xd8/0x4a0
      arm_smmu_detach_dev at drivers/iommu/arm-smmu-v3.c:2776
      arm_smmu_release_device+0xb4/0x1c8
      arm_smmu_disable_pasid at drivers/iommu/arm-smmu-v3.c:2754
      (inlined by) arm_smmu_release_device at drivers/iommu/arm-smmu-v3.c:3000
      iommu_release_device+0xc0/0x178
      iommu_release_device at drivers/iommu/iommu.c:302
      iommu_bus_notifier+0x118/0x160
      notifier_call_chain+0xa4/0x128
      __blocking_notifier_call_chain+0x70/0xa8
      blocking_notifier_call_chain+0x14/0x20
      device_del+0x618/0xa00
      pci_remove_bus_device+0x108/0x2d8
      pci_stop_and_remove_bus_device+0x1c/0x28
      pci_iov_remove_virtfn+0x228/0x368
      sriov_disable+0x8c/0x348
      pci_disable_sriov+0x5c/0x70
      mlx5_core_sriov_configure+0xd8/0x260 [mlx5_core]
      sriov_numvfs_store+0x240/0x318
      dev_attr_store+0x38/0x68
      sysfs_kf_write+0xdc/0x128
      kernfs_fop_write+0x23c/0x448
      __vfs_write+0x54/0xe8
      vfs_write+0x124/0x3f0
      ksys_write+0xe8/0x1b8
      __arm64_sys_write+0x68/0x98
      do_el0_svc+0x124/0x220
      el0_sync_handler+0x260/0x408
      el0_sync+0x140/0x180
    
     Allocated by task 3356:
      save_stack+0x24/0x50
      __kasan_kmalloc.isra.13+0xc4/0xe0
      kasan_kmalloc+0xc/0x18
      kmem_cache_alloc_trace+0x1ec/0x318
      arm_smmu_domain_alloc+0x54/0x148
      iommu_group_alloc_default_domain+0xc0/0x440
      iommu_probe_device+0x1c0/0x308
      iort_iommu_configure+0x434/0x518
      acpi_dma_configure+0xf0/0x128
      pci_dma_configure+0x114/0x160
      really_probe+0x124/0x6d8
      driver_probe_device+0xc4/0x180
      __device_attach_driver+0x184/0x1e8
      bus_for_each_drv+0x114/0x1a0
      __device_attach+0x19c/0x2a8
      device_attach+0x10/0x18
      pci_bus_add_device+0x70/0xf8
      pci_iov_add_virtfn+0x7b4/0xb40
      sriov_enable+0x5c8/0xc30
      pci_enable_sriov+0x64/0x80
      mlx5_core_sriov_configure+0x58/0x260 [mlx5_core]
      sriov_numvfs_store+0x1c0/0x318
      dev_attr_store+0x38/0x68
      sysfs_kf_write+0xdc/0x128
      kernfs_fop_write+0x23c/0x448
      __vfs_write+0x54/0xe8
      vfs_write+0x124/0x3f0
      ksys_write+0xe8/0x1b8
      __arm64_sys_write+0x68/0x98
      do_el0_svc+0x124/0x220
      el0_sync_handler+0x260/0x408
      el0_sync+0x140/0x180
    
     Freed by task 3356:
      save_stack+0x24/0x50
      __kasan_slab_free+0x124/0x198
      kasan_slab_free+0x10/0x18
      slab_free_freelist_hook+0x110/0x298
      kfree+0x128/0x668
      arm_smmu_domain_free+0xf4/0x1a0
      iommu_group_release+0xec/0x160
      kobject_put+0xf4/0x238
      kobject_del+0x110/0x190
      kobject_put+0x1e4/0x238
      iommu_group_remove_device+0x394/0x938
      iommu_release_device+0x9c/0x178
      iommu_release_device at drivers/iommu/iommu.c:300
      iommu_bus_notifier+0x118/0x160
      notifier_call_chain+0xa4/0x128
      __blocking_notifier_call_chain+0x70/0xa8
      blocking_notifier_call_chain+0x14/0x20
      device_del+0x618/0xa00
      pci_remove_bus_device+0x108/0x2d8
      pci_stop_and_remove_bus_device+0x1c/0x28
      pci_iov_remove_virtfn+0x228/0x368
      sriov_disable+0x8c/0x348
      pci_disable_sriov+0x5c/0x70
      mlx5_core_sriov_configure+0xd8/0x260 [mlx5_core]
      sriov_numvfs_store+0x240/0x318
      dev_attr_store+0x38/0x68
      sysfs_kf_write+0xdc/0x128
      kernfs_fop_write+0x23c/0x448
      __vfs_write+0x54/0xe8
      vfs_write+0x124/0x3f0
      ksys_write+0xe8/0x1b8
      __arm64_sys_write+0x68/0x98
      do_el0_svc+0x124/0x220
      el0_sync_handler+0x260/0x408
      el0_sync+0x140/0x180
    
     The buggy address belongs to the object at ffff0089df1a6e00
      which belongs to the cache kmalloc-512 of size 512
     The buggy address is located 360 bytes inside of
      512-byte region [ffff0089df1a6e00, ffff0089df1a7000)
     The buggy address belongs to the page:
     page:ffffffe02257c680 refcount:1 mapcount:0 mapping:0000000000000000 index:0xffff0089df1a1400
     flags: 0x7ffff800000200(slab)
     raw: 007ffff800000200 ffffffe02246b8c8 ffffffe02257ff88 ffff000000320680
     raw: ffff0089df1a1400 00000000002a000e 00000001ffffffff ffff0089df1a5001
     page dumped because: kasan: bad access detected
     page->mem_cgroup:ffff0089df1a5001
    
     Memory state around the buggy address:
      ffff0089df1a6e00: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
      ffff0089df1a6e80: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
     >ffff0089df1a6f00: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
                                                               ^
      ffff0089df1a6f80: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
      ffff0089df1a7000: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    
    Fixes: a6a4c7e2c5b8 ("iommu: Add probe_device() and release_device() call-backs")
    Signed-off-by: Qian Cai <cai@lca.pw>
    Link: https://lore.kernel.org/r/20200704001003.2303-1-cai@lca.pw
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index d43120eb1dc5..b6858adc4f17 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -295,10 +295,10 @@ void iommu_release_device(struct device *dev)
 		return;
 
 	iommu_device_unlink(dev->iommu->iommu_dev, dev);
-	iommu_group_remove_device(dev);
 
 	ops->release_device(dev);
 
+	iommu_group_remove_device(dev);
 	module_put(ops->owner);
 	dev_iommu_free(dev);
 }

commit 431275afdc7155415254aef4bd3816a1b8a2ead0
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu Jun 4 11:19:44 2020 +0200

    iommu: Check for deferred attach in iommu_group_do_dma_attach()
    
    The iommu_group_do_dma_attach() must not attach devices which have
    deferred_attach set. Otherwise devices could cause IOMMU faults when
    re-initialized in a kdump kernel.
    
    Fixes: deac0b3bed26 ("iommu: Split off default domain allocation from group assignment")
    Reported-by: Jerry Snitselaar <jsnitsel@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Jerry Snitselaar <jsnitsel@redhat.com>
    Reviewed-by: Jerry Snitselaar <jsnitsel@redhat.com>
    Link: https://lore.kernel.org/r/20200604091944.26402-1-joro@8bytes.org

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index b5ea203f6c68..d43120eb1dc5 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1680,8 +1680,12 @@ static void probe_alloc_default_domain(struct bus_type *bus,
 static int iommu_group_do_dma_attach(struct device *dev, void *data)
 {
 	struct iommu_domain *domain = data;
+	int ret = 0;
 
-	return __iommu_attach_device(domain, dev);
+	if (!iommu_is_attach_deferred(domain, dev))
+		ret = __iommu_attach_device(domain, dev);
+
+	return ret;
 }
 
 static int __iommu_group_dma_attach(struct iommu_group *group)

commit cc69fc4861705c27c0506d39189015d7404129ed
Merge: 3d77e6a8804a c4e0f3b24004 79074f61c022 0299a1a81ca0 71974cfb6737 9f510d1e4299 edcc40d2ab5f 736c3333e397
Author: Joerg Roedel <jroedel@suse.de>
Date:   Tue Jun 2 10:32:04 2020 +0200

    Merge branches 'arm/msm', 'arm/allwinner', 'arm/smmu', 'x86/vt-d', 'hyper-v', 'core' and 'x86/amd' into next

commit 4c201d58cfee8631350888bad9e8bae33e628605
Merge: 555fb5ae0f39 9cb1fd0efd19
Author: Joerg Roedel <jroedel@suse.de>
Date:   Fri May 29 17:10:09 2020 +0200

    Merge tag 'v5.7-rc7' into x86/amd
    
    Linux 5.7-rc7

commit 7cc31613734c4870ae32f5265d576ef296621343
Author: Qiushi Wu <wu000273@umn.edu>
Date:   Wed May 27 16:00:19 2020 -0500

    iommu: Fix reference count leak in iommu_group_alloc.
    
    kobject_init_and_add() takes reference even when it fails.
    Thus, when kobject_init_and_add() returns an error,
    kobject_put() must be called to properly clean up the kobject.
    
    Fixes: d72e31c93746 ("iommu: IOMMU Groups")
    Signed-off-by: Qiushi Wu <wu000273@umn.edu>
    Link: https://lore.kernel.org/r/20200527210020.6522-1-wu000273@umn.edu
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 1faa08c8bbb4..03d6a26687bc 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -510,7 +510,7 @@ struct iommu_group *iommu_group_alloc(void)
 				   NULL, "%d", group->id);
 	if (ret) {
 		ida_simple_remove(&iommu_group_ida, group->id);
-		kfree(group);
+		kobject_put(&group->kobj);
 		return ERR_PTR(ret);
 	}
 

commit edcc40d2ab5f47f205c2dd2a9aeedd8c77de050a
Author: Jean-Philippe Brucker <jean-philippe@linaro.org>
Date:   Thu Apr 23 14:53:30 2020 +0200

    iommu: Remove iommu_sva_ops::mm_exit()
    
    After binding a device to an mm, device drivers currently need to
    register a mm_exit handler. This function is called when the mm exits,
    to gracefully stop DMA targeting the address space and flush page faults
    to the IOMMU.
    
    This is deemed too complex for the MMU release() notifier, which may be
    triggered by any mmput() invocation, from about 120 callsites [1]. The
    upcoming SVA module has an example of such complexity: the I/O Page
    Fault handler would need to call mmput_async() instead of mmput() after
    handling an IOPF, to avoid triggering the release() notifier which would
    in turn drain the IOPF queue and lock up.
    
    Another concern is the DMA stop function taking too long, up to several
    minutes [2]. For some mmput() callers this may disturb other users. For
    example, if the OOM killer picks the mm bound to a device as the victim
    and that mm's memory is locked, if the release() takes too long, it
    might choose additional innocent victims to kill.
    
    To simplify the MMU release notifier, don't forward the notification to
    device drivers. Since they don't stop DMA on mm exit anymore, the PASID
    lifetime is extended:
    
    (1) The device driver calls bind(). A PASID is allocated.
    
      Here any DMA fault is handled by mm, and on error we don't print
      anything to dmesg. Userspace can easily trigger errors by issuing DMA
      on unmapped buffers.
    
    (2) exit_mmap(), for example the process took a SIGKILL. This step
        doesn't happen during normal operations. Remove the pgd from the
        PASID table, since the page tables are about to be freed. Invalidate
        the IOTLBs.
    
      Here the device may still perform DMA on the address space. Incoming
      transactions are aborted but faults aren't printed out. ATS
      Translation Requests return Successful Translation Completions with
      R=W=0. PRI Page Requests return with Invalid Request.
    
    (3) The device driver stops DMA, possibly following release of a fd, and
        calls unbind(). PASID table is cleared, IOTLB invalidated if
        necessary. The page fault queues are drained, and the PASID is
        freed.
    
      If DMA for that PASID is still running here, something went seriously
      wrong and errors should be reported.
    
    For now remove iommu_sva_ops entirely. We might need to re-introduce
    them at some point, for example to notify device drivers of unhandled
    IOPF.
    
    [1] https://lore.kernel.org/linux-iommu/20200306174239.GM31668@ziepe.ca/
    [2] https://lore.kernel.org/linux-iommu/4d68da96-0ad5-b412-5987-2f7a6aa796c3@amd.com/
    
    Signed-off-by: Jean-Philippe Brucker <jean-philippe@linaro.org>
    Acked-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Acked-by: Lu Baolu <baolu.lu@linux.intel.com>
    Link: https://lore.kernel.org/r/20200423125329.782066-3-jean-philippe@linaro.org
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 298397721144..abcd19118169 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -2883,17 +2883,6 @@ void iommu_sva_unbind_device(struct iommu_sva *handle)
 }
 EXPORT_SYMBOL_GPL(iommu_sva_unbind_device);
 
-int iommu_sva_set_ops(struct iommu_sva *handle,
-		      const struct iommu_sva_ops *sva_ops)
-{
-	if (handle->ops && handle->ops != sva_ops)
-		return -EEXIST;
-
-	handle->ops = sva_ops;
-	return 0;
-}
-EXPORT_SYMBOL_GPL(iommu_sva_set_ops);
-
 int iommu_sva_get_pasid(struct iommu_sva *handle)
 {
 	const struct iommu_ops *ops = handle->dev->bus->iommu_ops;

commit 79659190ee972c05498c338e48d80cb45490c533
Author: Joerg Roedel <jroedel@suse.de>
Date:   Mon May 25 15:01:22 2020 +0200

    iommu: Don't take group reference in iommu_alloc_default_domain()
    
    The iommu_alloc_default_domain() function takes a reference to an IOMMU
    group without releasing it. This causes the group to never be released,
    with undefined side effects.
    
    The function has only one call-site, which takes a group reference on
    its own, so to fix this leak, do not take another reference in
    iommu_alloc_default_domain() and pass the group as a function parameter
    instead.
    
    Fixes: 6e1aa2049154 ("iommu: Move default domain allocation to iommu_probe_device()")
    Reported-by: Sai Prakash Ranjan <saiprakash.ranjan@codeaurora.org>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Sai Prakash Ranjan <saiprakash.ranjan@codeaurora.org>
    Cc: Sai Prakash Ranjan <saiprakash.ranjan@codeaurora.org>
    Link: https://lore.kernel.org/r/20200525130122.380-1-joro@8bytes.org
    Reference: https://lore.kernel.org/lkml/20200522130145.30067-1-saiprakash.ranjan@codeaurora.org/

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index b5ae598af2f4..298397721144 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -80,7 +80,8 @@ static bool iommu_cmd_line_dma_api(void)
 	return !!(iommu_cmd_line & IOMMU_CMD_LINE_DMA_API);
 }
 
-static int iommu_alloc_default_domain(struct device *dev);
+static int iommu_alloc_default_domain(struct iommu_group *group,
+				      struct device *dev);
 static struct iommu_domain *__iommu_domain_alloc(struct bus_type *bus,
 						 unsigned type);
 static int __iommu_attach_device(struct iommu_domain *domain,
@@ -251,17 +252,17 @@ int iommu_probe_device(struct device *dev)
 	if (ret)
 		goto err_out;
 
+	group = iommu_group_get(dev);
+	if (!group)
+		goto err_release;
+
 	/*
 	 * Try to allocate a default domain - needs support from the
 	 * IOMMU driver. There are still some drivers which don't
 	 * support default domains, so the return value is not yet
 	 * checked.
 	 */
-	iommu_alloc_default_domain(dev);
-
-	group = iommu_group_get(dev);
-	if (!group)
-		goto err_release;
+	iommu_alloc_default_domain(group, dev);
 
 	if (group->default_domain)
 		ret = __iommu_attach_device(group->default_domain, dev);
@@ -1478,15 +1479,11 @@ static int iommu_group_alloc_default_domain(struct bus_type *bus,
 	return 0;
 }
 
-static int iommu_alloc_default_domain(struct device *dev)
+static int iommu_alloc_default_domain(struct iommu_group *group,
+				      struct device *dev)
 {
-	struct iommu_group *group;
 	unsigned int type;
 
-	group = iommu_group_get(dev);
-	if (!group)
-		return -ENODEV;
-
 	if (group->default_domain)
 		return 0;
 

commit 70b8170e55d3ca9503a53211967faee6b5f18b19
Author: Joerg Roedel <jroedel@suse.de>
Date:   Tue May 19 15:28:24 2020 +0200

    iommu: Don't call .probe_finalize() under group->mutex
    
    The .probe_finalize() call-back of some IOMMU drivers calls into
    arm_iommu_attach_device(). This function will call back into the
    IOMMU core code, where it tries to take group->mutex again, resulting
    in a deadlock.
    
    As there is no reason why .probe_finalize() needs to be called under
    that mutex, move it after the lock has been released to fix the
    deadlock.
    
    Fixes: deac0b3bed26 ("iommu: Split off default domain allocation from group assignment")
    Reported-by: Yong Wu <yong.wu@mediatek.com>
    Tested-by: Yong Wu <yong.wu@mediatek.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Cc: Yong Wu <yong.wu@mediatek.com>
    Link: https://lore.kernel.org/r/20200519132824.15163-1-joro@8bytes.org

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 4050569188be..b5ae598af2f4 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1674,17 +1674,8 @@ static void probe_alloc_default_domain(struct bus_type *bus,
 static int iommu_group_do_dma_attach(struct device *dev, void *data)
 {
 	struct iommu_domain *domain = data;
-	const struct iommu_ops *ops;
-	int ret;
-
-	ret = __iommu_attach_device(domain, dev);
-
-	ops = domain->ops;
-
-	if (ret == 0 && ops->probe_finalize)
-		ops->probe_finalize(dev);
 
-	return ret;
+	return __iommu_attach_device(domain, dev);
 }
 
 static int __iommu_group_dma_attach(struct iommu_group *group)
@@ -1693,6 +1684,21 @@ static int __iommu_group_dma_attach(struct iommu_group *group)
 					  iommu_group_do_dma_attach);
 }
 
+static int iommu_group_do_probe_finalize(struct device *dev, void *data)
+{
+	struct iommu_domain *domain = data;
+
+	if (domain->ops->probe_finalize)
+		domain->ops->probe_finalize(dev);
+
+	return 0;
+}
+
+static void __iommu_group_dma_finalize(struct iommu_group *group)
+{
+	__iommu_group_for_each_dev(group, group->default_domain,
+				   iommu_group_do_probe_finalize);
+}
 static int iommu_do_create_direct_mappings(struct device *dev, void *data)
 {
 	struct iommu_group *group = data;
@@ -1745,6 +1751,8 @@ int bus_iommu_probe(struct bus_type *bus)
 
 		if (ret)
 			break;
+
+		__iommu_group_dma_finalize(group);
 	}
 
 	return ret;

commit bd421264ed307dd296eab036851221b225071a32
Author: Joerg Roedel <jroedel@suse.de>
Date:   Tue May 19 15:03:40 2020 +0200

    iommu: Fix deferred domain attachment
    
    The IOMMU core code has support for deferring the attachment of a domain
    to a device. This is needed in kdump kernels where the new domain must
    not be attached to a device before the device driver takes it over.
    
    When the AMD IOMMU driver got converted to use the dma-iommu
    implementation, the deferred attaching got lost. The code in
    dma-iommu.c has support for deferred attaching, but it calls into
    iommu_attach_device() to actually do it. But iommu_attach_device()
    will check if the device should be deferred in it code-path and do
    nothing, breaking deferred attachment.
    
    Move the is_deferred_attach() check out of the attach_device path and
    into iommu_group_add_device() to make deferred attaching work from the
    dma-iommu code.
    
    Fixes: 795bbbb9b6f8 ("iommu/dma-iommu: Handle deferred devices")
    Reported-by: Jerry Snitselaar <jsnitsel@redhat.com>
    Suggested-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Jerry Snitselaar <jsnitsel@redhat.com>
    Cc: Jerry Snitselaar <jsnitsel@redhat.com>
    Cc: Tom Murphy <murphyt7@tcd.ie>
    Cc: Robin Murphy <robin.murphy@arm.com>
    Link: https://lore.kernel.org/r/20200519130340.14564-1-joro@8bytes.org

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 7b375421afba..1faa08c8bbb4 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -693,6 +693,15 @@ static int iommu_group_create_direct_mappings(struct iommu_group *group,
 	return ret;
 }
 
+static bool iommu_is_attach_deferred(struct iommu_domain *domain,
+				     struct device *dev)
+{
+	if (domain->ops->is_attach_deferred)
+		return domain->ops->is_attach_deferred(domain, dev);
+
+	return false;
+}
+
 /**
  * iommu_group_add_device - add a device to an iommu group
  * @group: the group into which to add the device (reference should be held)
@@ -747,7 +756,7 @@ int iommu_group_add_device(struct iommu_group *group, struct device *dev)
 
 	mutex_lock(&group->mutex);
 	list_add_tail(&device->list, &group->devices);
-	if (group->domain)
+	if (group->domain  && !iommu_is_attach_deferred(group->domain, dev))
 		ret = __iommu_attach_device(group->domain, dev);
 	mutex_unlock(&group->mutex);
 	if (ret)
@@ -1653,9 +1662,6 @@ static int __iommu_attach_device(struct iommu_domain *domain,
 				 struct device *dev)
 {
 	int ret;
-	if ((domain->ops->is_attach_deferred != NULL) &&
-	    domain->ops->is_attach_deferred(domain, dev))
-		return 0;
 
 	if (unlikely(domain->ops->attach_dev == NULL))
 		return -ENODEV;
@@ -1727,8 +1733,7 @@ EXPORT_SYMBOL_GPL(iommu_sva_unbind_gpasid);
 static void __iommu_detach_device(struct iommu_domain *domain,
 				  struct device *dev)
 {
-	if ((domain->ops->is_attach_deferred != NULL) &&
-	    domain->ops->is_attach_deferred(domain, dev))
+	if (iommu_is_attach_deferred(domain, dev))
 		return;
 
 	if (unlikely(domain->ops->detach_dev == NULL))

commit 69cf449166987d9a041020be6422ee7bf94a7228
Author: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
Date:   Wed May 13 15:47:21 2020 -0700

    iommu: Remove functions that support private domain
    
    After moving iommu_group setup to iommu core code [1][2] and removing
    private domain support in vt-d [3], there are no users for functions such
    as iommu_request_dm_for_dev(), iommu_request_dma_domain_for_dev() and
    request_default_domain_for_dev(). So, remove these functions.
    
    [1] commit dce8d6964ebd ("iommu/amd: Convert to probe/release_device()
        call-backs")
    [2] commit e5d1841f18b2 ("iommu/vt-d: Convert to probe/release_device()
        call-backs")
    [3] commit 327d5b2fee91 ("iommu/vt-d: Allow 32bit devices to uses DMA
        domain")
    
    Signed-off-by: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Lu Baolu <baolu.lu@linux.intel.com>
    Link: https://lore.kernel.org/r/20200513224721.20504-1-sai.praneeth.prakhya@intel.com
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 4050569188be..374b34fd6fac 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -2536,71 +2536,6 @@ struct iommu_resv_region *iommu_alloc_resv_region(phys_addr_t start,
 }
 EXPORT_SYMBOL_GPL(iommu_alloc_resv_region);
 
-static int
-request_default_domain_for_dev(struct device *dev, unsigned long type)
-{
-	struct iommu_domain *domain;
-	struct iommu_group *group;
-	int ret;
-
-	/* Device must already be in a group before calling this function */
-	group = iommu_group_get(dev);
-	if (!group)
-		return -EINVAL;
-
-	mutex_lock(&group->mutex);
-
-	ret = 0;
-	if (group->default_domain && group->default_domain->type == type)
-		goto out;
-
-	/* Don't change mappings of existing devices */
-	ret = -EBUSY;
-	if (iommu_group_device_count(group) != 1)
-		goto out;
-
-	ret = -ENOMEM;
-	domain = __iommu_domain_alloc(dev->bus, type);
-	if (!domain)
-		goto out;
-
-	/* Attach the device to the domain */
-	ret = __iommu_attach_group(domain, group);
-	if (ret) {
-		iommu_domain_free(domain);
-		goto out;
-	}
-
-	/* Make the domain the default for this group */
-	if (group->default_domain)
-		iommu_domain_free(group->default_domain);
-	group->default_domain = domain;
-
-	iommu_create_device_direct_mappings(group, dev);
-
-	dev_info(dev, "Using iommu %s mapping\n",
-		 type == IOMMU_DOMAIN_DMA ? "dma" : "direct");
-
-	ret = 0;
-out:
-	mutex_unlock(&group->mutex);
-	iommu_group_put(group);
-
-	return ret;
-}
-
-/* Request that a device is direct mapped by the IOMMU */
-int iommu_request_dm_for_dev(struct device *dev)
-{
-	return request_default_domain_for_dev(dev, IOMMU_DOMAIN_IDENTITY);
-}
-
-/* Request that a device can't be direct mapped by the IOMMU */
-int iommu_request_dma_domain_for_dev(struct device *dev)
-{
-	return request_default_domain_for_dev(dev, IOMMU_DOMAIN_DMA);
-}
-
 void iommu_set_default_passthrough(bool cmd_line)
 {
 	if (cmd_line)

commit ec9b40cffdb68c4ea1ebdcd1648ed6ce15c4449e
Merge: 3a0ce12e3b8e 0e698dfa2822
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed May 13 12:01:33 2020 +0200

    Merge tag 'v5.7-rc4' into core
    
    Linux 5.7-rc4

commit f38338cf0691b5fae5f9a46d188eef92ab9e6296
Author: Thierry Reding <treding@nvidia.com>
Date:   Mon May 11 18:10:00 2020 +0200

    iommu: Do not probe devices on IOMMU-less busses
    
    The host1x bus implemented on Tegra SoCs is primarily an abstraction to
    create logical device from multiple platform devices. Since the devices
    in such a setup are typically hierarchical, DMA setup still needs to be
    done so that DMA masks can be properly inherited, but we don't actually
    want to attach the host1x logical devices to any IOMMU. The platform
    devices that make up the logical device are responsible for memory bus
    transactions, so it is them that will need to be attached to the IOMMU.
    
    Add a check to __iommu_probe_device() that aborts IOMMU setup early for
    busses that don't have the IOMMU operations pointer set since they will
    cause a crash otherwise.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>
    Link: https://lore.kernel.org/r/20200511161000.3853342-1-thierry.reding@gmail.com
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index a9e5618cde80..9d1d917e1050 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -195,6 +195,9 @@ static int __iommu_probe_device(struct device *dev, struct list_head *group_list
 	struct iommu_group *group;
 	int ret;
 
+	if (!ops)
+		return -ENODEV;
+
 	if (!dev_iommu_get(dev))
 		return -ENOMEM;
 

commit 1b032ec1ecbce6047af7d11c9db432e237cb17d8
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Apr 29 15:37:12 2020 +0200

    iommu: Unexport iommu_group_get_for_dev()
    
    The function is now only used in IOMMU core code and shouldn't be used
    outside of it anyway, so remove the export for it.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Acked-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Link: https://lore.kernel.org/r/20200429133712.31431-35-joro@8bytes.org
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 48a95f7d7999..a9e5618cde80 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -91,6 +91,7 @@ static void __iommu_detach_group(struct iommu_domain *domain,
 				 struct iommu_group *group);
 static int iommu_create_device_direct_mappings(struct iommu_group *group,
 					       struct device *dev);
+static struct iommu_group *iommu_group_get_for_dev(struct device *dev);
 
 #define IOMMU_GROUP_ATTR(_name, _mode, _show, _store)		\
 struct iommu_group_attribute iommu_group_attr_##_name =		\
@@ -1500,7 +1501,7 @@ static int iommu_alloc_default_domain(struct device *dev)
  * to the returned IOMMU group, which will already include the provided
  * device.  The reference should be released with iommu_group_put().
  */
-struct iommu_group *iommu_group_get_for_dev(struct device *dev)
+static struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 {
 	const struct iommu_ops *ops = dev->bus->iommu_ops;
 	struct iommu_group *group;
@@ -1531,7 +1532,6 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 
 	return ERR_PTR(ret);
 }
-EXPORT_SYMBOL(iommu_group_get_for_dev);
 
 struct iommu_domain *iommu_group_default_domain(struct iommu_group *group)
 {

commit 4e8906f0d84d1a7d3cf82a30a701b0fb5d48977c
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Apr 29 15:37:11 2020 +0200

    iommu: Move more initialization to __iommu_probe_device()
    
    Move the calls to dev_iommu_get() and try_module_get() into
    __iommu_probe_device(), so that the callers don't have to do it on
    their own.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Acked-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Link: https://lore.kernel.org/r/20200429133712.31431-34-joro@8bytes.org
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 7f99e5ae432c..48a95f7d7999 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -194,9 +194,19 @@ static int __iommu_probe_device(struct device *dev, struct list_head *group_list
 	struct iommu_group *group;
 	int ret;
 
+	if (!dev_iommu_get(dev))
+		return -ENOMEM;
+
+	if (!try_module_get(ops->owner)) {
+		ret = -EINVAL;
+		goto err_free;
+	}
+
 	iommu_dev = ops->probe_device(dev);
-	if (IS_ERR(iommu_dev))
-		return PTR_ERR(iommu_dev);
+	if (IS_ERR(iommu_dev)) {
+		ret = PTR_ERR(iommu_dev);
+		goto out_module_put;
+	}
 
 	dev->iommu->iommu_dev = iommu_dev;
 
@@ -217,6 +227,12 @@ static int __iommu_probe_device(struct device *dev, struct list_head *group_list
 out_release:
 	ops->release_device(dev);
 
+out_module_put:
+	module_put(ops->owner);
+
+err_free:
+	dev_iommu_free(dev);
+
 	return ret;
 }
 
@@ -226,14 +242,6 @@ int iommu_probe_device(struct device *dev)
 	struct iommu_group *group;
 	int ret;
 
-	if (!dev_iommu_get(dev))
-		return -ENOMEM;
-
-	if (!try_module_get(ops->owner)) {
-		ret = -EINVAL;
-		goto err_out;
-	}
-
 	ret = __iommu_probe_device(dev, NULL);
 	if (ret)
 		goto err_out;
@@ -1532,14 +1540,10 @@ struct iommu_domain *iommu_group_default_domain(struct iommu_group *group)
 
 static int probe_iommu_group(struct device *dev, void *data)
 {
-	const struct iommu_ops *ops = dev->bus->iommu_ops;
 	struct list_head *group_list = data;
 	struct iommu_group *group;
 	int ret;
 
-	if (!dev_iommu_get(dev))
-		return -ENOMEM;
-
 	/* Device is probed already if in a group */
 	group = iommu_group_get(dev);
 	if (group) {
@@ -1547,22 +1551,7 @@ static int probe_iommu_group(struct device *dev, void *data)
 		return 0;
 	}
 
-	if (!try_module_get(ops->owner)) {
-		ret = -EINVAL;
-		goto err_free_dev_iommu;
-	}
-
 	ret = __iommu_probe_device(dev, group_list);
-	if (ret)
-		goto err_module_put;
-
-	return 0;
-
-err_module_put:
-	module_put(ops->owner);
-err_free_dev_iommu:
-	dev_iommu_free(dev);
-
 	if (ret == -ENODEV)
 		ret = 0;
 

commit 3eeeb45c6d0444b368cdeba9bdafa8bbcf5370d1
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Apr 29 15:37:10 2020 +0200

    iommu: Remove add_device()/remove_device() code-paths
    
    All drivers are converted to use the probe/release_device()
    call-backs, so the add_device/remove_device() pointers are unused and
    the code using them can be removed.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Acked-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Link: https://lore.kernel.org/r/20200429133712.31431-33-joro@8bytes.org
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 397fd4fd0c32..7f99e5ae432c 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -220,12 +220,20 @@ static int __iommu_probe_device(struct device *dev, struct list_head *group_list
 	return ret;
 }
 
-static int __iommu_probe_device_helper(struct device *dev)
+int iommu_probe_device(struct device *dev)
 {
 	const struct iommu_ops *ops = dev->bus->iommu_ops;
 	struct iommu_group *group;
 	int ret;
 
+	if (!dev_iommu_get(dev))
+		return -ENOMEM;
+
+	if (!try_module_get(ops->owner)) {
+		ret = -EINVAL;
+		goto err_out;
+	}
+
 	ret = __iommu_probe_device(dev, NULL);
 	if (ret)
 		goto err_out;
@@ -259,75 +267,23 @@ static int __iommu_probe_device_helper(struct device *dev)
 
 err_release:
 	iommu_release_device(dev);
+
 err_out:
 	return ret;
 
 }
 
-int iommu_probe_device(struct device *dev)
+void iommu_release_device(struct device *dev)
 {
 	const struct iommu_ops *ops = dev->bus->iommu_ops;
-	struct iommu_group *group;
-	int ret;
-
-	WARN_ON(dev->iommu_group);
-
-	if (!ops)
-		return -EINVAL;
-
-	if (!dev_iommu_get(dev))
-		return -ENOMEM;
-
-	if (!try_module_get(ops->owner)) {
-		ret = -EINVAL;
-		goto err_free_dev_param;
-	}
-
-	if (ops->probe_device)
-		return __iommu_probe_device_helper(dev);
-
-	ret = ops->add_device(dev);
-	if (ret)
-		goto err_module_put;
 
-	group = iommu_group_get(dev);
-	iommu_create_device_direct_mappings(group, dev);
-	iommu_group_put(group);
-
-	if (ops->probe_finalize)
-		ops->probe_finalize(dev);
-
-	return 0;
-
-err_module_put:
-	module_put(ops->owner);
-err_free_dev_param:
-	dev_iommu_free(dev);
-	return ret;
-}
-
-static void __iommu_release_device(struct device *dev)
-{
-	const struct iommu_ops *ops = dev->bus->iommu_ops;
+	if (!dev->iommu)
+		return;
 
 	iommu_device_unlink(dev->iommu->iommu_dev, dev);
-
 	iommu_group_remove_device(dev);
 
 	ops->release_device(dev);
-}
-
-void iommu_release_device(struct device *dev)
-{
-	const struct iommu_ops *ops = dev->bus->iommu_ops;
-
-	if (!dev->iommu)
-		return;
-
-	if (ops->release_device)
-		__iommu_release_device(dev);
-	else if (dev->iommu_group)
-		ops->remove_device(dev);
 
 	module_put(ops->owner);
 	dev_iommu_free(dev);
@@ -1560,23 +1516,6 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 	if (ret)
 		goto out_put_group;
 
-	/*
-	 * Try to allocate a default domain - needs support from the
-	 * IOMMU driver. There are still some drivers which don't support
-	 * default domains, so the return value is not yet checked. Only
-	 * allocate the domain here when the driver still has the
-	 * add_device/remove_device call-backs implemented.
-	 */
-	if (!ops->probe_device) {
-		iommu_alloc_default_domain(dev);
-
-		if (group->default_domain)
-			ret = __iommu_attach_device(group->default_domain, dev);
-
-		if (ret)
-			goto out_put_group;
-	}
-
 	return group;
 
 out_put_group:
@@ -1591,21 +1530,6 @@ struct iommu_domain *iommu_group_default_domain(struct iommu_group *group)
 	return group->default_domain;
 }
 
-static int add_iommu_group(struct device *dev, void *data)
-{
-	int ret = iommu_probe_device(dev);
-
-	/*
-	 * We ignore -ENODEV errors for now, as they just mean that the
-	 * device is not translated by an IOMMU. We still care about
-	 * other errors and fail to initialize when they happen.
-	 */
-	if (ret == -ENODEV)
-		ret = 0;
-
-	return ret;
-}
-
 static int probe_iommu_group(struct device *dev, void *data)
 {
 	const struct iommu_ops *ops = dev->bus->iommu_ops;
@@ -1793,47 +1717,41 @@ static int iommu_group_create_direct_mappings(struct iommu_group *group)
 
 int bus_iommu_probe(struct bus_type *bus)
 {
-	const struct iommu_ops *ops = bus->iommu_ops;
+	struct iommu_group *group, *next;
+	LIST_HEAD(group_list);
 	int ret;
 
-	if (ops->probe_device) {
-		struct iommu_group *group, *next;
-		LIST_HEAD(group_list);
-
-		/*
-		 * This code-path does not allocate the default domain when
-		 * creating the iommu group, so do it after the groups are
-		 * created.
-		 */
-		ret = bus_for_each_dev(bus, NULL, &group_list, probe_iommu_group);
-		if (ret)
-			return ret;
+	/*
+	 * This code-path does not allocate the default domain when
+	 * creating the iommu group, so do it after the groups are
+	 * created.
+	 */
+	ret = bus_for_each_dev(bus, NULL, &group_list, probe_iommu_group);
+	if (ret)
+		return ret;
 
-		list_for_each_entry_safe(group, next, &group_list, entry) {
-			/* Remove item from the list */
-			list_del_init(&group->entry);
+	list_for_each_entry_safe(group, next, &group_list, entry) {
+		/* Remove item from the list */
+		list_del_init(&group->entry);
 
-			mutex_lock(&group->mutex);
+		mutex_lock(&group->mutex);
 
-			/* Try to allocate default domain */
-			probe_alloc_default_domain(bus, group);
+		/* Try to allocate default domain */
+		probe_alloc_default_domain(bus, group);
 
-			if (!group->default_domain) {
-				mutex_unlock(&group->mutex);
-				continue;
-			}
+		if (!group->default_domain) {
+			mutex_unlock(&group->mutex);
+			continue;
+		}
 
-			iommu_group_create_direct_mappings(group);
+		iommu_group_create_direct_mappings(group);
 
-			ret = __iommu_group_dma_attach(group);
+		ret = __iommu_group_dma_attach(group);
 
-			mutex_unlock(&group->mutex);
+		mutex_unlock(&group->mutex);
 
-			if (ret)
-				break;
-		}
-	} else {
-		ret = bus_for_each_dev(bus, NULL, NULL, add_iommu_group);
+		if (ret)
+			break;
 	}
 
 	return ret;

commit 5012c3968537e2ffecbdb2eba3479bf9fb9e5597
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Apr 29 15:36:51 2020 +0200

    iommu: Export bus_iommu_probe() and make is safe for re-probing
    
    Add a check to the bus_iommu_probe() call-path to make sure it ignores
    devices which have already been successfully probed. Then export the
    bus_iommu_probe() function so it can be used by IOMMU drivers.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Acked-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Link: https://lore.kernel.org/r/20200429133712.31431-14-joro@8bytes.org
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 834a45da0ed0..397fd4fd0c32 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1610,11 +1610,19 @@ static int probe_iommu_group(struct device *dev, void *data)
 {
 	const struct iommu_ops *ops = dev->bus->iommu_ops;
 	struct list_head *group_list = data;
+	struct iommu_group *group;
 	int ret;
 
 	if (!dev_iommu_get(dev))
 		return -ENOMEM;
 
+	/* Device is probed already if in a group */
+	group = iommu_group_get(dev);
+	if (group) {
+		iommu_group_put(group);
+		return 0;
+	}
+
 	if (!try_module_get(ops->owner)) {
 		ret = -EINVAL;
 		goto err_free_dev_iommu;
@@ -1783,7 +1791,7 @@ static int iommu_group_create_direct_mappings(struct iommu_group *group)
 					  iommu_do_create_direct_mappings);
 }
 
-static int bus_iommu_probe(struct bus_type *bus)
+int bus_iommu_probe(struct bus_type *bus)
 {
 	const struct iommu_ops *ops = bus->iommu_ops;
 	int ret;

commit ce574c27ae275bc51b6437883fc9cd1c46b498e5
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Apr 29 15:36:50 2020 +0200

    iommu: Move iommu_group_create_direct_mappings() out of iommu_group_add_device()
    
    After the previous changes the iommu group may not have a default
    domain when iommu_group_add_device() is called. With no default domain
    iommu_group_create_direct_mappings() will do nothing and no direct
    mappings will be created.
    
    Rename iommu_group_create_direct_mappings() to
    iommu_create_device_direct_mappings() to better reflect that the
    function creates direct mappings only for one device and not for all
    devices in the group. Then move the call to the places where a default
    domain actually exists.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Acked-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Link: https://lore.kernel.org/r/20200429133712.31431-13-joro@8bytes.org
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 7de0e29db333..834a45da0ed0 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -89,6 +89,8 @@ static int __iommu_attach_group(struct iommu_domain *domain,
 				struct iommu_group *group);
 static void __iommu_detach_group(struct iommu_domain *domain,
 				 struct iommu_group *group);
+static int iommu_create_device_direct_mappings(struct iommu_group *group,
+					       struct device *dev);
 
 #define IOMMU_GROUP_ATTR(_name, _mode, _show, _store)		\
 struct iommu_group_attribute iommu_group_attr_##_name =		\
@@ -243,6 +245,8 @@ static int __iommu_probe_device_helper(struct device *dev)
 	if (group->default_domain)
 		ret = __iommu_attach_device(group->default_domain, dev);
 
+	iommu_create_device_direct_mappings(group, dev);
+
 	iommu_group_put(group);
 
 	if (ret)
@@ -263,6 +267,7 @@ static int __iommu_probe_device_helper(struct device *dev)
 int iommu_probe_device(struct device *dev)
 {
 	const struct iommu_ops *ops = dev->bus->iommu_ops;
+	struct iommu_group *group;
 	int ret;
 
 	WARN_ON(dev->iommu_group);
@@ -285,6 +290,10 @@ int iommu_probe_device(struct device *dev)
 	if (ret)
 		goto err_module_put;
 
+	group = iommu_group_get(dev);
+	iommu_create_device_direct_mappings(group, dev);
+	iommu_group_put(group);
+
 	if (ops->probe_finalize)
 		ops->probe_finalize(dev);
 
@@ -736,8 +745,8 @@ int iommu_group_set_name(struct iommu_group *group, const char *name)
 }
 EXPORT_SYMBOL_GPL(iommu_group_set_name);
 
-static int iommu_group_create_direct_mappings(struct iommu_group *group,
-					      struct device *dev)
+static int iommu_create_device_direct_mappings(struct iommu_group *group,
+					       struct device *dev)
 {
 	struct iommu_domain *domain = group->default_domain;
 	struct iommu_resv_region *entry;
@@ -841,8 +850,6 @@ int iommu_group_add_device(struct iommu_group *group, struct device *dev)
 
 	dev->iommu_group = group;
 
-	iommu_group_create_direct_mappings(group, dev);
-
 	mutex_lock(&group->mutex);
 	list_add_tail(&device->list, &group->devices);
 	if (group->domain)
@@ -1736,6 +1743,7 @@ static void probe_alloc_default_domain(struct bus_type *bus,
 		gtype.type = iommu_def_domain_type;
 
 	iommu_group_alloc_default_domain(bus, group, gtype.type);
+
 }
 
 static int iommu_group_do_dma_attach(struct device *dev, void *data)
@@ -1760,6 +1768,21 @@ static int __iommu_group_dma_attach(struct iommu_group *group)
 					  iommu_group_do_dma_attach);
 }
 
+static int iommu_do_create_direct_mappings(struct device *dev, void *data)
+{
+	struct iommu_group *group = data;
+
+	iommu_create_device_direct_mappings(group, dev);
+
+	return 0;
+}
+
+static int iommu_group_create_direct_mappings(struct iommu_group *group)
+{
+	return __iommu_group_for_each_dev(group, group,
+					  iommu_do_create_direct_mappings);
+}
+
 static int bus_iommu_probe(struct bus_type *bus)
 {
 	const struct iommu_ops *ops = bus->iommu_ops;
@@ -1792,6 +1815,8 @@ static int bus_iommu_probe(struct bus_type *bus)
 				continue;
 			}
 
+			iommu_group_create_direct_mappings(group);
+
 			ret = __iommu_group_dma_attach(group);
 
 			mutex_unlock(&group->mutex);
@@ -2632,7 +2657,7 @@ request_default_domain_for_dev(struct device *dev, unsigned long type)
 		iommu_domain_free(group->default_domain);
 	group->default_domain = domain;
 
-	iommu_group_create_direct_mappings(group, dev);
+	iommu_create_device_direct_mappings(group, dev);
 
 	dev_info(dev, "Using iommu %s mapping\n",
 		 type == IOMMU_DOMAIN_DMA ? "dma" : "direct");

commit deac0b3bed26bb5d04486696b1071d8ec3851100
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Apr 29 15:36:49 2020 +0200

    iommu: Split off default domain allocation from group assignment
    
    When a bus is initialized with iommu-ops, all devices on the bus are
    scanned and iommu-groups are allocated for them, and each groups will
    also get a default domain allocated.
    
    Until now this happened as soon as the group was created and the first
    device added to it. When other devices with different default domain
    requirements were added to the group later on, the default domain was
    re-allocated, if possible.
    
    This resulted in some back and forth and unnecessary allocations, so
    change the flow to defer default domain allocation until all devices
    have been added to their respective IOMMU groups.
    
    The default domains are allocated for newly allocated groups after
    each device on the bus is handled and was probed by the IOMMU driver.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Acked-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Link: https://lore.kernel.org/r/20200429133712.31431-12-joro@8bytes.org
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 8be047a4808f..7de0e29db333 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -199,7 +199,7 @@ static int __iommu_probe_device(struct device *dev, struct list_head *group_list
 	dev->iommu->iommu_dev = iommu_dev;
 
 	group = iommu_group_get_for_dev(dev);
-	if (!IS_ERR(group)) {
+	if (IS_ERR(group)) {
 		ret = PTR_ERR(group);
 		goto out_release;
 	}
@@ -1599,6 +1599,37 @@ static int add_iommu_group(struct device *dev, void *data)
 	return ret;
 }
 
+static int probe_iommu_group(struct device *dev, void *data)
+{
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
+	struct list_head *group_list = data;
+	int ret;
+
+	if (!dev_iommu_get(dev))
+		return -ENOMEM;
+
+	if (!try_module_get(ops->owner)) {
+		ret = -EINVAL;
+		goto err_free_dev_iommu;
+	}
+
+	ret = __iommu_probe_device(dev, group_list);
+	if (ret)
+		goto err_module_put;
+
+	return 0;
+
+err_module_put:
+	module_put(ops->owner);
+err_free_dev_iommu:
+	dev_iommu_free(dev);
+
+	if (ret == -ENODEV)
+		ret = 0;
+
+	return ret;
+}
+
 static int remove_iommu_group(struct device *dev, void *data)
 {
 	iommu_release_device(dev);
@@ -1658,10 +1689,127 @@ static int iommu_bus_notifier(struct notifier_block *nb,
 	return 0;
 }
 
+struct __group_domain_type {
+	struct device *dev;
+	unsigned int type;
+};
+
+static int probe_get_default_domain_type(struct device *dev, void *data)
+{
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
+	struct __group_domain_type *gtype = data;
+	unsigned int type = 0;
+
+	if (ops->def_domain_type)
+		type = ops->def_domain_type(dev);
+
+	if (type) {
+		if (gtype->type && gtype->type != type) {
+			dev_warn(dev, "Device needs domain type %s, but device %s in the same iommu group requires type %s - using default\n",
+				 iommu_domain_type_str(type),
+				 dev_name(gtype->dev),
+				 iommu_domain_type_str(gtype->type));
+			gtype->type = 0;
+		}
+
+		if (!gtype->dev) {
+			gtype->dev  = dev;
+			gtype->type = type;
+		}
+	}
+
+	return 0;
+}
+
+static void probe_alloc_default_domain(struct bus_type *bus,
+				       struct iommu_group *group)
+{
+	struct __group_domain_type gtype;
+
+	memset(&gtype, 0, sizeof(gtype));
+
+	/* Ask for default domain requirements of all devices in the group */
+	__iommu_group_for_each_dev(group, &gtype,
+				   probe_get_default_domain_type);
+
+	if (!gtype.type)
+		gtype.type = iommu_def_domain_type;
+
+	iommu_group_alloc_default_domain(bus, group, gtype.type);
+}
+
+static int iommu_group_do_dma_attach(struct device *dev, void *data)
+{
+	struct iommu_domain *domain = data;
+	const struct iommu_ops *ops;
+	int ret;
+
+	ret = __iommu_attach_device(domain, dev);
+
+	ops = domain->ops;
+
+	if (ret == 0 && ops->probe_finalize)
+		ops->probe_finalize(dev);
+
+	return ret;
+}
+
+static int __iommu_group_dma_attach(struct iommu_group *group)
+{
+	return __iommu_group_for_each_dev(group, group->default_domain,
+					  iommu_group_do_dma_attach);
+}
+
+static int bus_iommu_probe(struct bus_type *bus)
+{
+	const struct iommu_ops *ops = bus->iommu_ops;
+	int ret;
+
+	if (ops->probe_device) {
+		struct iommu_group *group, *next;
+		LIST_HEAD(group_list);
+
+		/*
+		 * This code-path does not allocate the default domain when
+		 * creating the iommu group, so do it after the groups are
+		 * created.
+		 */
+		ret = bus_for_each_dev(bus, NULL, &group_list, probe_iommu_group);
+		if (ret)
+			return ret;
+
+		list_for_each_entry_safe(group, next, &group_list, entry) {
+			/* Remove item from the list */
+			list_del_init(&group->entry);
+
+			mutex_lock(&group->mutex);
+
+			/* Try to allocate default domain */
+			probe_alloc_default_domain(bus, group);
+
+			if (!group->default_domain) {
+				mutex_unlock(&group->mutex);
+				continue;
+			}
+
+			ret = __iommu_group_dma_attach(group);
+
+			mutex_unlock(&group->mutex);
+
+			if (ret)
+				break;
+		}
+	} else {
+		ret = bus_for_each_dev(bus, NULL, NULL, add_iommu_group);
+	}
+
+	return ret;
+}
+
 static int iommu_bus_init(struct bus_type *bus, const struct iommu_ops *ops)
 {
-	int err;
 	struct notifier_block *nb;
+	int err;
 
 	nb = kzalloc(sizeof(struct notifier_block), GFP_KERNEL);
 	if (!nb)
@@ -1673,7 +1821,7 @@ static int iommu_bus_init(struct bus_type *bus, const struct iommu_ops *ops)
 	if (err)
 		goto out_free;
 
-	err = bus_for_each_dev(bus, NULL, NULL, add_iommu_group);
+	err = bus_iommu_probe(bus);
 	if (err)
 		goto out_err;
 

commit cf193888bfbd3d57e03a511e49d26f7d9c6f76df
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Apr 29 15:36:48 2020 +0200

    iommu: Move new probe_device path to separate function
    
    This makes it easier to remove to old code-path when all drivers are
    converted. As a side effect that it also fixes the error cleanup
    path.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Acked-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Link: https://lore.kernel.org/r/20200429133712.31431-11-joro@8bytes.org
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 18eb3623bd00..8be047a4808f 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -218,12 +218,55 @@ static int __iommu_probe_device(struct device *dev, struct list_head *group_list
 	return ret;
 }
 
+static int __iommu_probe_device_helper(struct device *dev)
+{
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
+	struct iommu_group *group;
+	int ret;
+
+	ret = __iommu_probe_device(dev, NULL);
+	if (ret)
+		goto err_out;
+
+	/*
+	 * Try to allocate a default domain - needs support from the
+	 * IOMMU driver. There are still some drivers which don't
+	 * support default domains, so the return value is not yet
+	 * checked.
+	 */
+	iommu_alloc_default_domain(dev);
+
+	group = iommu_group_get(dev);
+	if (!group)
+		goto err_release;
+
+	if (group->default_domain)
+		ret = __iommu_attach_device(group->default_domain, dev);
+
+	iommu_group_put(group);
+
+	if (ret)
+		goto err_release;
+
+	if (ops->probe_finalize)
+		ops->probe_finalize(dev);
+
+	return 0;
+
+err_release:
+	iommu_release_device(dev);
+err_out:
+	return ret;
+
+}
+
 int iommu_probe_device(struct device *dev)
 {
 	const struct iommu_ops *ops = dev->bus->iommu_ops;
 	int ret;
 
 	WARN_ON(dev->iommu_group);
+
 	if (!ops)
 		return -EINVAL;
 
@@ -235,30 +278,10 @@ int iommu_probe_device(struct device *dev)
 		goto err_free_dev_param;
 	}
 
-	if (ops->probe_device) {
-		struct iommu_group *group;
-
-		ret = __iommu_probe_device(dev, NULL);
-
-		/*
-		 * Try to allocate a default domain - needs support from the
-		 * IOMMU driver. There are still some drivers which don't
-		 * support default domains, so the return value is not yet
-		 * checked.
-		 */
-		if (!ret)
-			iommu_alloc_default_domain(dev);
-
-		group = iommu_group_get(dev);
-		if (group && group->default_domain) {
-			ret = __iommu_attach_device(group->default_domain, dev);
-			iommu_group_put(group);
-		}
-
-	} else {
-		ret = ops->add_device(dev);
-	}
+	if (ops->probe_device)
+		return __iommu_probe_device_helper(dev);
 
+	ret = ops->add_device(dev);
 	if (ret)
 		goto err_module_put;
 

commit 41df6dcc0a3ff4fb654c3d969ab96ba9c4f0e796
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Apr 29 15:36:47 2020 +0200

    iommu: Keep a list of allocated groups in __iommu_probe_device()
    
    This is needed to defer default_domain allocation for new IOMMU groups
    until all devices have been added to the group.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Acked-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Link: https://lore.kernel.org/r/20200429133712.31431-10-joro@8bytes.org
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 7a385c18e1a5..18eb3623bd00 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -44,6 +44,7 @@ struct iommu_group {
 	int id;
 	struct iommu_domain *default_domain;
 	struct iommu_domain *domain;
+	struct list_head entry;
 };
 
 struct group_device {
@@ -184,7 +185,7 @@ static void dev_iommu_free(struct device *dev)
 	dev->iommu = NULL;
 }
 
-static int __iommu_probe_device(struct device *dev)
+static int __iommu_probe_device(struct device *dev, struct list_head *group_list)
 {
 	const struct iommu_ops *ops = dev->bus->iommu_ops;
 	struct iommu_device *iommu_dev;
@@ -204,6 +205,9 @@ static int __iommu_probe_device(struct device *dev)
 	}
 	iommu_group_put(group);
 
+	if (group_list && !group->default_domain && list_empty(&group->entry))
+		list_add_tail(&group->entry, group_list);
+
 	iommu_device_link(iommu_dev, dev);
 
 	return 0;
@@ -234,7 +238,7 @@ int iommu_probe_device(struct device *dev)
 	if (ops->probe_device) {
 		struct iommu_group *group;
 
-		ret = __iommu_probe_device(dev);
+		ret = __iommu_probe_device(dev, NULL);
 
 		/*
 		 * Try to allocate a default domain - needs support from the
@@ -567,6 +571,7 @@ struct iommu_group *iommu_group_alloc(void)
 	group->kobj.kset = iommu_group_kset;
 	mutex_init(&group->mutex);
 	INIT_LIST_HEAD(&group->devices);
+	INIT_LIST_HEAD(&group->entry);
 	BLOCKING_INIT_NOTIFIER_HEAD(&group->notifier);
 
 	ret = ida_simple_get(&iommu_group_ida, 0, 0, GFP_KERNEL);

commit 6e1aa2049154d7462968c968b20f985859308267
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Apr 29 15:36:46 2020 +0200

    iommu: Move default domain allocation to iommu_probe_device()
    
    Well, not really. The call to iommu_alloc_default_domain() in
    iommu_group_get_for_dev() has to stay around as long as there are
    IOMMU drivers using the add/remove_device() call-backs instead of
    probe/release_device().
    
    Those drivers expect that iommu_group_get_for_dev() returns the device
    attached to a group and the group set up with a default domain (and
    the device attached to the groups current domain).
    
    But when all drivers are converted this compatability mess can be
    removed.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Acked-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Link: https://lore.kernel.org/r/20200429133712.31431-9-joro@8bytes.org
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 6cfe7799dc8c..7a385c18e1a5 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -79,6 +79,16 @@ static bool iommu_cmd_line_dma_api(void)
 	return !!(iommu_cmd_line & IOMMU_CMD_LINE_DMA_API);
 }
 
+static int iommu_alloc_default_domain(struct device *dev);
+static struct iommu_domain *__iommu_domain_alloc(struct bus_type *bus,
+						 unsigned type);
+static int __iommu_attach_device(struct iommu_domain *domain,
+				 struct device *dev);
+static int __iommu_attach_group(struct iommu_domain *domain,
+				struct iommu_group *group);
+static void __iommu_detach_group(struct iommu_domain *domain,
+				 struct iommu_group *group);
+
 #define IOMMU_GROUP_ATTR(_name, _mode, _show, _store)		\
 struct iommu_group_attribute iommu_group_attr_##_name =		\
 	__ATTR(_name, _mode, _show, _store)
@@ -221,10 +231,29 @@ int iommu_probe_device(struct device *dev)
 		goto err_free_dev_param;
 	}
 
-	if (ops->probe_device)
+	if (ops->probe_device) {
+		struct iommu_group *group;
+
 		ret = __iommu_probe_device(dev);
-	else
+
+		/*
+		 * Try to allocate a default domain - needs support from the
+		 * IOMMU driver. There are still some drivers which don't
+		 * support default domains, so the return value is not yet
+		 * checked.
+		 */
+		if (!ret)
+			iommu_alloc_default_domain(dev);
+
+		group = iommu_group_get(dev);
+		if (group && group->default_domain) {
+			ret = __iommu_attach_device(group->default_domain, dev);
+			iommu_group_put(group);
+		}
+
+	} else {
 		ret = ops->add_device(dev);
+	}
 
 	if (ret)
 		goto err_module_put;
@@ -268,15 +297,6 @@ void iommu_release_device(struct device *dev)
 	dev_iommu_free(dev);
 }
 
-static struct iommu_domain *__iommu_domain_alloc(struct bus_type *bus,
-						 unsigned type);
-static int __iommu_attach_device(struct iommu_domain *domain,
-				 struct device *dev);
-static int __iommu_attach_group(struct iommu_domain *domain,
-				struct iommu_group *group);
-static void __iommu_detach_group(struct iommu_domain *domain,
-				 struct iommu_group *group);
-
 static int __init iommu_set_def_domain_type(char *str)
 {
 	bool pt;
@@ -1423,25 +1443,18 @@ static int iommu_get_def_domain_type(struct device *dev)
 	return (type == 0) ? iommu_def_domain_type : type;
 }
 
-static int iommu_alloc_default_domain(struct device *dev,
-				      struct iommu_group *group)
+static int iommu_group_alloc_default_domain(struct bus_type *bus,
+					    struct iommu_group *group,
+					    unsigned int type)
 {
 	struct iommu_domain *dom;
-	unsigned int type;
-
-	if (group->default_domain)
-		return 0;
 
-	type = iommu_get_def_domain_type(dev);
-
-	dom = __iommu_domain_alloc(dev->bus, type);
+	dom = __iommu_domain_alloc(bus, type);
 	if (!dom && type != IOMMU_DOMAIN_DMA) {
-		dom = __iommu_domain_alloc(dev->bus, IOMMU_DOMAIN_DMA);
-		if (dom) {
-			dev_warn(dev,
-				 "failed to allocate default IOMMU domain of type %u; falling back to IOMMU_DOMAIN_DMA",
-				 type);
-		}
+		dom = __iommu_domain_alloc(bus, IOMMU_DOMAIN_DMA);
+		if (dom)
+			pr_warn("Failed to allocate default IOMMU domain of type %u for group %s - Falling back to IOMMU_DOMAIN_DMA",
+				type, group->name);
 	}
 
 	if (!dom)
@@ -1461,6 +1474,23 @@ static int iommu_alloc_default_domain(struct device *dev,
 	return 0;
 }
 
+static int iommu_alloc_default_domain(struct device *dev)
+{
+	struct iommu_group *group;
+	unsigned int type;
+
+	group = iommu_group_get(dev);
+	if (!group)
+		return -ENODEV;
+
+	if (group->default_domain)
+		return 0;
+
+	type = iommu_get_def_domain_type(dev);
+
+	return iommu_group_alloc_default_domain(dev->bus, group, type);
+}
+
 /**
  * iommu_group_get_for_dev - Find or create the IOMMU group for a device
  * @dev: target device
@@ -1491,16 +1521,26 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 	if (IS_ERR(group))
 		return group;
 
+	ret = iommu_group_add_device(group, dev);
+	if (ret)
+		goto out_put_group;
+
 	/*
 	 * Try to allocate a default domain - needs support from the
 	 * IOMMU driver. There are still some drivers which don't support
-	 * default domains, so the return value is not yet checked.
+	 * default domains, so the return value is not yet checked. Only
+	 * allocate the domain here when the driver still has the
+	 * add_device/remove_device call-backs implemented.
 	 */
-	iommu_alloc_default_domain(dev, group);
+	if (!ops->probe_device) {
+		iommu_alloc_default_domain(dev);
 
-	ret = iommu_group_add_device(group, dev);
-	if (ret)
-		goto out_put_group;
+		if (group->default_domain)
+			ret = __iommu_attach_device(group->default_domain, dev);
+
+		if (ret)
+			goto out_put_group;
+	}
 
 	return group;
 

commit a6a4c7e2c5b8b981d1c546a393ff21f2112468c3
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Apr 29 15:36:45 2020 +0200

    iommu: Add probe_device() and release_device() call-backs
    
    Add call-backs to 'struct iommu_ops' as an alternative to the
    add_device() and remove_device() call-backs, which will be removed when
    all drivers are converted.
    
    The new call-backs will not setup IOMMU groups and domains anymore,
    so also add a probe_finalize() call-back where the IOMMU driver can do
    per-device setup work which require the device to be set up with a
    group and a domain.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Acked-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Link: https://lore.kernel.org/r/20200429133712.31431-8-joro@8bytes.org
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 5877abd9b693..6cfe7799dc8c 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -174,6 +174,36 @@ static void dev_iommu_free(struct device *dev)
 	dev->iommu = NULL;
 }
 
+static int __iommu_probe_device(struct device *dev)
+{
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
+	struct iommu_device *iommu_dev;
+	struct iommu_group *group;
+	int ret;
+
+	iommu_dev = ops->probe_device(dev);
+	if (IS_ERR(iommu_dev))
+		return PTR_ERR(iommu_dev);
+
+	dev->iommu->iommu_dev = iommu_dev;
+
+	group = iommu_group_get_for_dev(dev);
+	if (!IS_ERR(group)) {
+		ret = PTR_ERR(group);
+		goto out_release;
+	}
+	iommu_group_put(group);
+
+	iommu_device_link(iommu_dev, dev);
+
+	return 0;
+
+out_release:
+	ops->release_device(dev);
+
+	return ret;
+}
+
 int iommu_probe_device(struct device *dev)
 {
 	const struct iommu_ops *ops = dev->bus->iommu_ops;
@@ -191,10 +221,17 @@ int iommu_probe_device(struct device *dev)
 		goto err_free_dev_param;
 	}
 
-	ret = ops->add_device(dev);
+	if (ops->probe_device)
+		ret = __iommu_probe_device(dev);
+	else
+		ret = ops->add_device(dev);
+
 	if (ret)
 		goto err_module_put;
 
+	if (ops->probe_finalize)
+		ops->probe_finalize(dev);
+
 	return 0;
 
 err_module_put:
@@ -204,17 +241,31 @@ int iommu_probe_device(struct device *dev)
 	return ret;
 }
 
+static void __iommu_release_device(struct device *dev)
+{
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
+
+	iommu_device_unlink(dev->iommu->iommu_dev, dev);
+
+	iommu_group_remove_device(dev);
+
+	ops->release_device(dev);
+}
+
 void iommu_release_device(struct device *dev)
 {
 	const struct iommu_ops *ops = dev->bus->iommu_ops;
 
-	if (dev->iommu_group)
+	if (!dev->iommu)
+		return;
+
+	if (ops->release_device)
+		__iommu_release_device(dev);
+	else if (dev->iommu_group)
 		ops->remove_device(dev);
 
-	if (dev->iommu) {
-		module_put(ops->owner);
-		dev_iommu_free(dev);
-	}
+	module_put(ops->owner);
+	dev_iommu_free(dev);
 }
 
 static struct iommu_domain *__iommu_domain_alloc(struct bus_type *bus,

commit 4cbf38511a007867def958872203ae8adb8e2351
Author: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
Date:   Wed Apr 29 15:36:40 2020 +0200

    iommu: Add def_domain_type() callback in iommu_ops
    
    Some devices are reqired to use a specific type (identity or dma)
    of default domain when they are used with a vendor iommu. When the
    system level default domain type is different from it, the vendor
    iommu driver has to request a new default domain with
    iommu_request_dma_domain_for_dev() and iommu_request_dm_for_dev()
    in the add_dev() callback. Unfortunately, these two helpers only
    work when the group hasn't been assigned to any other devices,
    hence, some vendor iommu driver has to use a private domain if
    it fails to request a new default one.
    
    This adds def_domain_type() callback in the iommu_ops, so that
    any special requirement of default domain for a device could be
    aware by the iommu generic layer.
    
    Signed-off-by: Sai Praneeth Prakhya <sai.praneeth.prakhya@intel.com>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    [ jroedel@suse.de: Added iommu_get_def_domain_type() function and use
                       it to allocate the default domain ]
    Co-developed-by: Joerg Roedel <jroedel@suse.de>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Acked-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Link: https://lore.kernel.org/r/20200429133712.31431-3-joro@8bytes.org
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index bfe011760ed1..5877abd9b693 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1361,21 +1361,35 @@ struct iommu_group *fsl_mc_device_group(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(fsl_mc_device_group);
 
+static int iommu_get_def_domain_type(struct device *dev)
+{
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
+	unsigned int type = 0;
+
+	if (ops->def_domain_type)
+		type = ops->def_domain_type(dev);
+
+	return (type == 0) ? iommu_def_domain_type : type;
+}
+
 static int iommu_alloc_default_domain(struct device *dev,
 				      struct iommu_group *group)
 {
 	struct iommu_domain *dom;
+	unsigned int type;
 
 	if (group->default_domain)
 		return 0;
 
-	dom = __iommu_domain_alloc(dev->bus, iommu_def_domain_type);
-	if (!dom && iommu_def_domain_type != IOMMU_DOMAIN_DMA) {
+	type = iommu_get_def_domain_type(dev);
+
+	dom = __iommu_domain_alloc(dev->bus, type);
+	if (!dom && type != IOMMU_DOMAIN_DMA) {
 		dom = __iommu_domain_alloc(dev->bus, IOMMU_DOMAIN_DMA);
 		if (dom) {
 			dev_warn(dev,
 				 "failed to allocate default IOMMU domain of type %u; falling back to IOMMU_DOMAIN_DMA",
-				 iommu_def_domain_type);
+				 type);
 		}
 	}
 

commit ff2a08b39bcede1b08d84d8b5c8ee1336a39c5df
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Apr 29 15:36:39 2020 +0200

    iommu: Move default domain allocation to separate function
    
    Move the code out of iommu_group_get_for_dev() into a separate
    function.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Acked-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Link: https://lore.kernel.org/r/20200429133712.31431-2-joro@8bytes.org
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 2b471419e26c..bfe011760ed1 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1361,6 +1361,41 @@ struct iommu_group *fsl_mc_device_group(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(fsl_mc_device_group);
 
+static int iommu_alloc_default_domain(struct device *dev,
+				      struct iommu_group *group)
+{
+	struct iommu_domain *dom;
+
+	if (group->default_domain)
+		return 0;
+
+	dom = __iommu_domain_alloc(dev->bus, iommu_def_domain_type);
+	if (!dom && iommu_def_domain_type != IOMMU_DOMAIN_DMA) {
+		dom = __iommu_domain_alloc(dev->bus, IOMMU_DOMAIN_DMA);
+		if (dom) {
+			dev_warn(dev,
+				 "failed to allocate default IOMMU domain of type %u; falling back to IOMMU_DOMAIN_DMA",
+				 iommu_def_domain_type);
+		}
+	}
+
+	if (!dom)
+		return -ENOMEM;
+
+	group->default_domain = dom;
+	if (!group->domain)
+		group->domain = dom;
+
+	if (!iommu_dma_strict) {
+		int attr = 1;
+		iommu_domain_set_attr(dom,
+				      DOMAIN_ATTR_DMA_USE_FLUSH_QUEUE,
+				      &attr);
+	}
+
+	return 0;
+}
+
 /**
  * iommu_group_get_for_dev - Find or create the IOMMU group for a device
  * @dev: target device
@@ -1393,40 +1428,21 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 
 	/*
 	 * Try to allocate a default domain - needs support from the
-	 * IOMMU driver.
+	 * IOMMU driver. There are still some drivers which don't support
+	 * default domains, so the return value is not yet checked.
 	 */
-	if (!group->default_domain) {
-		struct iommu_domain *dom;
-
-		dom = __iommu_domain_alloc(dev->bus, iommu_def_domain_type);
-		if (!dom && iommu_def_domain_type != IOMMU_DOMAIN_DMA) {
-			dom = __iommu_domain_alloc(dev->bus, IOMMU_DOMAIN_DMA);
-			if (dom) {
-				dev_warn(dev,
-					 "failed to allocate default IOMMU domain of type %u; falling back to IOMMU_DOMAIN_DMA",
-					 iommu_def_domain_type);
-			}
-		}
-
-		group->default_domain = dom;
-		if (!group->domain)
-			group->domain = dom;
-
-		if (dom && !iommu_dma_strict) {
-			int attr = 1;
-			iommu_domain_set_attr(dom,
-					      DOMAIN_ATTR_DMA_USE_FLUSH_QUEUE,
-					      &attr);
-		}
-	}
+	iommu_alloc_default_domain(dev, group);
 
 	ret = iommu_group_add_device(group, dev);
-	if (ret) {
-		iommu_group_put(group);
-		return ERR_PTR(ret);
-	}
+	if (ret)
+		goto out_put_group;
 
 	return group;
+
+out_put_group:
+	iommu_group_put(group);
+
+	return ERR_PTR(ret);
 }
 EXPORT_SYMBOL(iommu_group_get_for_dev);
 

commit ae74c19faa7d7996e857e13165bd40fc4a285e0d
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Thu Apr 30 14:01:20 2020 +0200

    iommu: Properly export iommu_group_get_for_dev()
    
    In commit a7ba5c3d008d ("drivers/iommu: Export core IOMMU API symbols to
    permit modular drivers") a bunch of iommu symbols were exported, all
    with _GPL markings except iommu_group_get_for_dev().  That export should
    also be _GPL like the others.
    
    Fixes: a7ba5c3d008d ("drivers/iommu: Export core IOMMU API symbols to permit modular drivers")
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Acked-by: Will Deacon <will@kernel.org>
    Cc: Joerg Roedel <jroedel@suse.de>
    Cc: John Garry <john.garry@huawei.com>
    Cc: Will Deacon <will@kernel.org>
    Link: https://lore.kernel.org/r/20200430120120.2948448-1-gregkh@linuxfoundation.org
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 54757c404866..7b375421afba 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1429,7 +1429,7 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 
 	return group;
 }
-EXPORT_SYMBOL(iommu_group_get_for_dev);
+EXPORT_SYMBOL_GPL(iommu_group_get_for_dev);
 
 struct iommu_domain *iommu_group_default_domain(struct iommu_group *group)
 {

commit 5375e874c7634f0e1795ec4b37260b724d481e86
Author: Kevin Hao <haokexin@gmail.com>
Date:   Thu Apr 2 22:37:49 2020 +0800

    iommu: Fix the memory leak in dev_iommu_free()
    
    In iommu_probe_device(), we would invoke dev_iommu_free() to free the
    dev->iommu after the ->add_device() returns failure. But after commit
    72acd9df18f1 ("iommu: Move iommu_fwspec to struct dev_iommu"), we also
    need to free the iommu_fwspec before the dev->iommu is freed. This fixes
    the following memory leak reported by kmemleak:
      unreferenced object 0xffff000bc836c700 (size 128):
        comm "swapper/0", pid 1, jiffies 4294896304 (age 782.120s)
        hex dump (first 32 bytes):
          00 00 00 00 00 00 00 00 d8 cd 9b ff 0b 00 ff ff  ................
          00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
        backtrace:
          [<00000000df34077b>] kmem_cache_alloc_trace+0x244/0x4b0
          [<000000000e560ac0>] iommu_fwspec_init+0x7c/0xb0
          [<0000000075eda275>] of_iommu_xlate+0x80/0xe8
          [<00000000728d6bf9>] of_pci_iommu_init+0xb0/0xb8
          [<00000000d001fe6f>] pci_for_each_dma_alias+0x48/0x190
          [<000000006db6bbce>] of_iommu_configure+0x1ac/0x1d0
          [<00000000634745f8>] of_dma_configure+0xdc/0x220
          [<000000002cbc8ba0>] pci_dma_configure+0x50/0x78
          [<00000000cdf6e193>] really_probe+0x8c/0x340
          [<00000000fddddc46>] driver_probe_device+0x60/0xf8
          [<0000000061bcdb51>] __device_attach_driver+0x8c/0xd0
          [<000000009b9ff58e>] bus_for_each_drv+0x80/0xd0
          [<000000004b9c8aa3>] __device_attach+0xec/0x148
          [<00000000a5c13bf3>] device_attach+0x1c/0x28
          [<000000005071e151>] pci_bus_add_device+0x58/0xd0
          [<000000002d4f87d1>] pci_bus_add_devices+0x40/0x90
    
    Fixes: 72acd9df18f1 ("iommu: Move iommu_fwspec to struct dev_iommu")
    Signed-off-by: Kevin Hao <haokexin@gmail.com>
    Link: https://lore.kernel.org/r/20200402143749.40500-1-haokexin@gmail.com
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 2b471419e26c..54757c404866 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -170,6 +170,7 @@ static struct dev_iommu *dev_iommu_get(struct device *dev)
 
 static void dev_iommu_free(struct device *dev)
 {
+	iommu_fwspec_free(dev);
 	kfree(dev->iommu);
 	dev->iommu = NULL;
 }

commit 72acd9df18f12420001f901493c54b7364f34d60
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu Mar 26 16:08:31 2020 +0100

    iommu: Move iommu_fwspec to struct dev_iommu
    
    Move the iommu_fwspec pointer in struct device into struct dev_iommu.
    This is a step in the effort to reduce the iommu related pointers in
    struct device to one.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Will Deacon <will@kernel.org> # arm-smmu
    Reviewed-by: Jean-Philippe Brucker <jean-philippe@linaro.org>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Link: https://lore.kernel.org/r/20200326150841.10083-7-joro@8bytes.org

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 15d64a175d92..2b471419e26c 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -2405,6 +2405,9 @@ int iommu_fwspec_init(struct device *dev, struct fwnode_handle *iommu_fwnode,
 	if (fwspec)
 		return ops == fwspec->ops ? 0 : -EINVAL;
 
+	if (!dev_iommu_get(dev))
+		return -ENOMEM;
+
 	/* Preallocate for the overwhelmingly common case of 1 ID */
 	fwspec = kzalloc(struct_size(fwspec, ids, 1), GFP_KERNEL);
 	if (!fwspec)

commit 045a70426067d6a22e3e5745b55efc18fa75aabf
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu Mar 26 16:08:30 2020 +0100

    iommu: Rename struct iommu_param to dev_iommu
    
    The term dev_iommu aligns better with other existing structures and
    their accessor functions.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Tested-by: Will Deacon <will@kernel.org> # arm-smmu
    Reviewed-by: Jean-Philippe Brucker <jean-philippe@linaro.org>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Link: https://lore.kernel.org/r/20200326150841.10083-6-joro@8bytes.org

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 660eea8d1d2f..15d64a175d92 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -152,9 +152,9 @@ void iommu_device_unregister(struct iommu_device *iommu)
 }
 EXPORT_SYMBOL_GPL(iommu_device_unregister);
 
-static struct iommu_param *iommu_get_dev_param(struct device *dev)
+static struct dev_iommu *dev_iommu_get(struct device *dev)
 {
-	struct iommu_param *param = dev->iommu_param;
+	struct dev_iommu *param = dev->iommu;
 
 	if (param)
 		return param;
@@ -164,14 +164,14 @@ static struct iommu_param *iommu_get_dev_param(struct device *dev)
 		return NULL;
 
 	mutex_init(&param->lock);
-	dev->iommu_param = param;
+	dev->iommu = param;
 	return param;
 }
 
-static void iommu_free_dev_param(struct device *dev)
+static void dev_iommu_free(struct device *dev)
 {
-	kfree(dev->iommu_param);
-	dev->iommu_param = NULL;
+	kfree(dev->iommu);
+	dev->iommu = NULL;
 }
 
 int iommu_probe_device(struct device *dev)
@@ -183,7 +183,7 @@ int iommu_probe_device(struct device *dev)
 	if (!ops)
 		return -EINVAL;
 
-	if (!iommu_get_dev_param(dev))
+	if (!dev_iommu_get(dev))
 		return -ENOMEM;
 
 	if (!try_module_get(ops->owner)) {
@@ -200,7 +200,7 @@ int iommu_probe_device(struct device *dev)
 err_module_put:
 	module_put(ops->owner);
 err_free_dev_param:
-	iommu_free_dev_param(dev);
+	dev_iommu_free(dev);
 	return ret;
 }
 
@@ -211,9 +211,9 @@ void iommu_release_device(struct device *dev)
 	if (dev->iommu_group)
 		ops->remove_device(dev);
 
-	if (dev->iommu_param) {
+	if (dev->iommu) {
 		module_put(ops->owner);
-		iommu_free_dev_param(dev);
+		dev_iommu_free(dev);
 	}
 }
 
@@ -972,7 +972,7 @@ int iommu_register_device_fault_handler(struct device *dev,
 					iommu_dev_fault_handler_t handler,
 					void *data)
 {
-	struct iommu_param *param = dev->iommu_param;
+	struct dev_iommu *param = dev->iommu;
 	int ret = 0;
 
 	if (!param)
@@ -1015,7 +1015,7 @@ EXPORT_SYMBOL_GPL(iommu_register_device_fault_handler);
  */
 int iommu_unregister_device_fault_handler(struct device *dev)
 {
-	struct iommu_param *param = dev->iommu_param;
+	struct dev_iommu *param = dev->iommu;
 	int ret = 0;
 
 	if (!param)
@@ -1055,7 +1055,7 @@ EXPORT_SYMBOL_GPL(iommu_unregister_device_fault_handler);
  */
 int iommu_report_device_fault(struct device *dev, struct iommu_fault_event *evt)
 {
-	struct iommu_param *param = dev->iommu_param;
+	struct dev_iommu *param = dev->iommu;
 	struct iommu_fault_event *evt_pending = NULL;
 	struct iommu_fault_param *fparam;
 	int ret = 0;
@@ -1104,7 +1104,7 @@ int iommu_page_response(struct device *dev,
 	int ret = -EINVAL;
 	struct iommu_fault_event *evt;
 	struct iommu_fault_page_request *prm;
-	struct iommu_param *param = dev->iommu_param;
+	struct dev_iommu *param = dev->iommu;
 	struct iommu_domain *domain = iommu_get_domain_for_dev(dev);
 
 	if (!domain || !domain->ops->page_response)

commit 098accf2da940189f4d62d3514d17f8bb05dc6e1
Author: Robin Murphy <robin.murphy@arm.com>
Date:   Thu Feb 13 14:00:21 2020 +0000

    iommu: Use C99 flexible array in fwspec
    
    Although the 1-element array was a typical pre-C99 way to implement
    variable-length structures, and indeed is a fundamental construct in the
    APIs of certain other popular platforms, there's no good reason for it
    here (and in particular the sizeof() trick is far too "clever" for its
    own good). We can just as easily implement iommu_fwspec's preallocation
    behaviour using a standard flexible array member, so let's make it look
    the way most readers would expect.
    
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 3e3528436e0b..660eea8d1d2f 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -2405,7 +2405,8 @@ int iommu_fwspec_init(struct device *dev, struct fwnode_handle *iommu_fwnode,
 	if (fwspec)
 		return ops == fwspec->ops ? 0 : -EINVAL;
 
-	fwspec = kzalloc(sizeof(*fwspec), GFP_KERNEL);
+	/* Preallocate for the overwhelmingly common case of 1 ID */
+	fwspec = kzalloc(struct_size(fwspec, ids, 1), GFP_KERNEL);
 	if (!fwspec)
 		return -ENOMEM;
 
@@ -2432,15 +2433,15 @@ EXPORT_SYMBOL_GPL(iommu_fwspec_free);
 int iommu_fwspec_add_ids(struct device *dev, u32 *ids, int num_ids)
 {
 	struct iommu_fwspec *fwspec = dev_iommu_fwspec_get(dev);
-	size_t size;
-	int i;
+	int i, new_num;
 
 	if (!fwspec)
 		return -EINVAL;
 
-	size = offsetof(struct iommu_fwspec, ids[fwspec->num_ids + num_ids]);
-	if (size > sizeof(*fwspec)) {
-		fwspec = krealloc(fwspec, size, GFP_KERNEL);
+	new_num = fwspec->num_ids + num_ids;
+	if (new_num > 1) {
+		fwspec = krealloc(fwspec, struct_size(fwspec, ids, new_num),
+				  GFP_KERNEL);
 		if (!fwspec)
 			return -ENOMEM;
 
@@ -2450,7 +2451,7 @@ int iommu_fwspec_add_ids(struct device *dev, u32 *ids, int num_ids)
 	for (i = 0; i < num_ids; i++)
 		fwspec->ids[fwspec->num_ids + i] = ids[i];
 
-	fwspec->num_ids += num_ids;
+	fwspec->num_ids = new_num;
 	return 0;
 }
 EXPORT_SYMBOL_GPL(iommu_fwspec_add_ids);

commit e3b5ee0cfb65646f4a915643fe53e0a51829d891
Merge: 8c17bbf6c8f7 6855d1ba7537 154e3a65f404 857f081426e5 c11738cf9d29
Author: Joerg Roedel <jroedel@suse.de>
Date:   Fri Jan 24 15:39:39 2020 +0100

    Merge branches 'iommu/fixes', 'arm/smmu', 'x86/amd', 'x86/vt-d' and 'core' into next

commit 7d4e6ccd1fb09dbfbc49746ca82bd5c25ad4bfe4
Author: Jon Derrick <jonathan.derrick@intel.com>
Date:   Tue Dec 31 13:24:19 2019 -0700

    iommu: Remove device link to group on failure
    
    This adds the missing teardown step that removes the device link from
    the group when the device addition fails.
    
    Signed-off-by: Jon Derrick <jonathan.derrick@intel.com>
    Fixes: 797a8b4d768c5 ("iommu: Handle default domain attach failure")
    Reviewed-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index fdd40756dbc1..3ead597e1c57 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -751,6 +751,7 @@ int iommu_group_add_device(struct iommu_group *group, struct device *dev)
 	mutex_unlock(&group->mutex);
 	dev->iommu_group = NULL;
 	kobject_put(group->devices_kobj);
+	sysfs_remove_link(group->devices_kobj, device->name);
 err_free_name:
 	kfree(device->name);
 err_remove_link:

commit f9f6971ebb75f5bc302d77e3380dd6363cc1a0f6
Author: Thierry Reding <treding@nvidia.com>
Date:   Wed Dec 18 14:42:01 2019 +0100

    iommu: Implement generic_iommu_put_resv_regions()
    
    Implement a generic function for removing reserved regions. This can be
    used by drivers that don't do anything fancy with these regions other
    than allocating memory for them.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index fdd40756dbc1..101f2d68eb6e 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -2229,6 +2229,25 @@ void iommu_put_resv_regions(struct device *dev, struct list_head *list)
 		ops->put_resv_regions(dev, list);
 }
 
+/**
+ * generic_iommu_put_resv_regions - Reserved region driver helper
+ * @dev: device for which to free reserved regions
+ * @list: reserved region list for device
+ *
+ * IOMMU drivers can use this to implement their .put_resv_regions() callback
+ * for simple reservations. Memory allocated for each reserved region will be
+ * freed. If an IOMMU driver allocates additional resources per region, it is
+ * going to have to implement a custom callback.
+ */
+void generic_iommu_put_resv_regions(struct device *dev, struct list_head *list)
+{
+	struct iommu_resv_region *entry, *next;
+
+	list_for_each_entry_safe(entry, next, list, list)
+		kfree(entry);
+}
+EXPORT_SYMBOL(generic_iommu_put_resv_regions);
+
 struct iommu_resv_region *iommu_alloc_resv_region(phys_addr_t start,
 						  size_t length, int prot,
 						  enum iommu_resv_type type)

commit 4312cf7f16c8d43e154bf2a6eea6d1e9347c922c
Author: Will Deacon <will@kernel.org>
Date:   Thu Dec 19 12:03:43 2019 +0000

    drivers/iommu: Allow IOMMU bus ops to be unregistered
    
    'bus_set_iommu()' allows IOMMU drivers to register their ops for a given
    bus type. Unfortunately, it then doesn't allow them to be removed, which
    is necessary for modular drivers to shutdown cleanly so that they can be
    reloaded later on.
    
    Allow 'bus_set_iommu()' to take a NULL 'ops' argument, which clear the
    ops pointer for the selected bus_type.
    
    Signed-off-by: Will Deacon <will@kernel.org>
    Tested-by: John Garry <john.garry@huawei.com> # smmu v3
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 32ceda1d5031..ffe6f685ceae 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1558,6 +1558,11 @@ int bus_set_iommu(struct bus_type *bus, const struct iommu_ops *ops)
 {
 	int err;
 
+	if (ops == NULL) {
+		bus->iommu_ops = NULL;
+		return 0;
+	}
+
 	if (bus->iommu_ops != NULL)
 		return -EBUSY;
 

commit 25f003de987aed630db265ceae9cd978537a3f80
Author: Will Deacon <will@kernel.org>
Date:   Thu Dec 19 12:03:41 2019 +0000

    drivers/iommu: Take a ref to the IOMMU driver prior to ->add_device()
    
    To avoid accidental removal of an active IOMMU driver module, take a
    reference to the driver module in 'iommu_probe_device()' immediately
    prior to invoking the '->add_device()' callback and hold it until the
    after the device has been removed by '->remove_device()'.
    
    Suggested-by: Joerg Roedel <joro@8bytes.org>
    Signed-off-by: Will Deacon <will@kernel.org>
    Tested-by: John Garry <john.garry@huawei.com> # smmu v3
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 3abe19ecbcd1..32ceda1d5031 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -22,6 +22,7 @@
 #include <linux/bitops.h>
 #include <linux/property.h>
 #include <linux/fsl/mc.h>
+#include <linux/module.h>
 #include <trace/events/iommu.h>
 
 static struct kset *iommu_group_kset;
@@ -185,10 +186,21 @@ int iommu_probe_device(struct device *dev)
 	if (!iommu_get_dev_param(dev))
 		return -ENOMEM;
 
+	if (!try_module_get(ops->owner)) {
+		ret = -EINVAL;
+		goto err_free_dev_param;
+	}
+
 	ret = ops->add_device(dev);
 	if (ret)
-		iommu_free_dev_param(dev);
+		goto err_module_put;
+
+	return 0;
 
+err_module_put:
+	module_put(ops->owner);
+err_free_dev_param:
+	iommu_free_dev_param(dev);
 	return ret;
 }
 
@@ -199,7 +211,10 @@ void iommu_release_device(struct device *dev)
 	if (dev->iommu_group)
 		ops->remove_device(dev);
 
-	iommu_free_dev_param(dev);
+	if (dev->iommu_param) {
+		module_put(ops->owner);
+		iommu_free_dev_param(dev);
+	}
 }
 
 static struct iommu_domain *__iommu_domain_alloc(struct bus_type *bus,

commit a7ba5c3d008dd78d881a1658eae5a2275ebd5087
Author: Will Deacon <will@kernel.org>
Date:   Thu Dec 19 12:03:37 2019 +0000

    drivers/iommu: Export core IOMMU API symbols to permit modular drivers
    
    Building IOMMU drivers as modules requires that the core IOMMU API
    symbols are exported as GPL symbols.
    
    Signed-off-by: Will Deacon <will@kernel.org>
    Tested-by: John Garry <john.garry@huawei.com> # smmu v3
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index fdd40756dbc1..3abe19ecbcd1 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -141,6 +141,7 @@ int iommu_device_register(struct iommu_device *iommu)
 	spin_unlock(&iommu_device_lock);
 	return 0;
 }
+EXPORT_SYMBOL_GPL(iommu_device_register);
 
 void iommu_device_unregister(struct iommu_device *iommu)
 {
@@ -148,6 +149,7 @@ void iommu_device_unregister(struct iommu_device *iommu)
 	list_del(&iommu->list);
 	spin_unlock(&iommu_device_lock);
 }
+EXPORT_SYMBOL_GPL(iommu_device_unregister);
 
 static struct iommu_param *iommu_get_dev_param(struct device *dev)
 {
@@ -886,6 +888,7 @@ struct iommu_group *iommu_group_ref_get(struct iommu_group *group)
 	kobject_get(group->devices_kobj);
 	return group;
 }
+EXPORT_SYMBOL_GPL(iommu_group_ref_get);
 
 /**
  * iommu_group_put - Decrement group reference
@@ -1259,6 +1262,7 @@ struct iommu_group *generic_device_group(struct device *dev)
 {
 	return iommu_group_alloc();
 }
+EXPORT_SYMBOL_GPL(generic_device_group);
 
 /*
  * Use standard PCI bus topology, isolation features, and DMA alias quirks
@@ -1326,6 +1330,7 @@ struct iommu_group *pci_device_group(struct device *dev)
 	/* No shared group found, allocate new */
 	return iommu_group_alloc();
 }
+EXPORT_SYMBOL_GPL(pci_device_group);
 
 /* Get the IOMMU group for device on fsl-mc bus */
 struct iommu_group *fsl_mc_device_group(struct device *dev)
@@ -1338,6 +1343,7 @@ struct iommu_group *fsl_mc_device_group(struct device *dev)
 		group = iommu_group_alloc();
 	return group;
 }
+EXPORT_SYMBOL_GPL(fsl_mc_device_group);
 
 /**
  * iommu_group_get_for_dev - Find or create the IOMMU group for a device
@@ -1406,6 +1412,7 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 
 	return group;
 }
+EXPORT_SYMBOL(iommu_group_get_for_dev);
 
 struct iommu_domain *iommu_group_default_domain(struct iommu_group *group)
 {
@@ -2246,6 +2253,7 @@ struct iommu_resv_region *iommu_alloc_resv_region(phys_addr_t start,
 	region->type = type;
 	return region;
 }
+EXPORT_SYMBOL_GPL(iommu_alloc_resv_region);
 
 static int
 request_default_domain_for_dev(struct device *dev, unsigned long type)

commit b371ddb94fae82b6565020639b7db31934043c65
Merge: fce34dec76d9 c18647900ec8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Dec 20 10:42:25 2019 -0800

    Merge tag 'iommu-fixes-v5.5-rc2' of git://git.kernel.org/pub/scm/linux/kernel/git/joro/iommu
    
    Pull iommu fixes from Joerg Roedel:
    
     - Fix kmemleak warning in IOVA code
    
     - Fix compile warnings on ARM32/64 in dma-iommu code due to dma_mask
       type mismatches
    
     - Make ISA reserved regions relaxable, so that VFIO can assign devices
       which have such regions defined
    
     - Fix mapping errors resulting in IO page-faults in the VT-d driver
    
     - Make sure direct mappings for a domain are created after the default
       domain is updated
    
     - Map ISA reserved regions in the VT-d driver with correct permissions
    
     - Remove unneeded check for PSI capability in the IOTLB flush code of
       the VT-d driver
    
     - Lockdep fix iommu_dma_prepare_msi()
    
    * tag 'iommu-fixes-v5.5-rc2' of git://git.kernel.org/pub/scm/linux/kernel/git/joro/iommu:
      iommu/dma: Relax locking in iommu_dma_prepare_msi()
      iommu/vt-d: Remove incorrect PSI capability check
      iommu/vt-d: Allocate reserved region for ISA with correct permission
      iommu: set group default domain before creating direct mappings
      iommu/vt-d: Fix dmar pte read access not set error
      iommu/vt-d: Set ISA bridge reserved region as relaxable
      iommu/dma: Rationalise types for DMA masks
      iommu/iova: Init the struct iova to fix the possible memleak

commit d360211524bece6db9920f32c91808235290b51c
Author: Jerry Snitselaar <jsnitsel@redhat.com>
Date:   Tue Dec 10 11:56:06 2019 -0700

    iommu: set group default domain before creating direct mappings
    
    iommu_group_create_direct_mappings uses group->default_domain, but
    right after it is called, request_default_domain_for_dev calls
    iommu_domain_free for the default domain, and sets the group default
    domain to a different domain. Move the
    iommu_group_create_direct_mappings call to after the group default
    domain is set, so the direct mappings get associated with that domain.
    
    Cc: Joerg Roedel <jroedel@suse.de>
    Cc: Lu Baolu <baolu.lu@linux.intel.com>
    Cc: iommu@lists.linux-foundation.org
    Cc: stable@vger.kernel.org
    Fixes: 7423e01741dd ("iommu: Add API to request DMA domain for device")
    Signed-off-by: Jerry Snitselaar <jsnitsel@redhat.com>
    Reviewed-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index db7bfd4f2d20..fa908179b80b 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -2282,13 +2282,13 @@ request_default_domain_for_dev(struct device *dev, unsigned long type)
 		goto out;
 	}
 
-	iommu_group_create_direct_mappings(group, dev);
-
 	/* Make the domain the default for this group */
 	if (group->default_domain)
 		iommu_domain_free(group->default_domain);
 	group->default_domain = domain;
 
+	iommu_group_create_direct_mappings(group, dev);
+
 	dev_info(dev, "Using iommu %s mapping\n",
 		 type == IOMMU_DOMAIN_DMA ? "dma" : "direct");
 

commit 4c80ba392bf603d468ea827d902f8e7b2505fbf4
Author: Eric Auger <eric.auger@redhat.com>
Date:   Tue Nov 26 18:54:13 2019 +0100

    iommu: fix KASAN use-after-free in iommu_insert_resv_region
    
    In case the new region gets merged into another one, the nr list node is
    freed.  Checking its type while completing the merge algorithm leads to
    a use-after-free.  Use new->type instead.
    
    Fixes: 4dbd258ff63e ("iommu: Revisit iommu_insert_resv_region() implementation")
    Signed-off-by: Eric Auger <eric.auger@redhat.com>
    Reported-by: Qian Cai <cai@lca.pw>
    Reviewed-by: Jerry Snitselaar <jsnitsel@redhat.com>
    Cc: Stable <stable@vger.kernel.org> #v5.3+
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index db7bfd4f2d20..1c3f2a3035c1 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -312,8 +312,8 @@ int iommu_insert_resv_region(struct iommu_resv_region *new,
 	list_for_each_entry_safe(iter, tmp, regions, list) {
 		phys_addr_t top_end, iter_end = iter->start + iter->length - 1;
 
-		/* no merge needed on elements of different types than @nr */
-		if (iter->type != nr->type) {
+		/* no merge needed on elements of different types than @new */
+		if (iter->type != new->type) {
 			list_move_tail(&iter->list, &stack);
 			continue;
 		}

commit 9b3a713feef8db41d4bcccb3b97e86ee906690c8
Merge: 4e7120d79edb da6b05dce2a9 1289f7f15001 5b47748ecf2e c90ae4a63541 96d3ab802e49 34d1b0895dbd 3c124435e8dd 6c3a44ed3c55 c1c8058dfb98 808be0aae53a
Author: Joerg Roedel <jroedel@suse.de>
Date:   Tue Nov 12 17:11:25 2019 +0100

    Merge branches 'iommu/fixes', 'arm/qcom', 'arm/renesas', 'arm/rockchip', 'arm/mediatek', 'arm/tegra', 'arm/smmu', 'x86/amd', 'x86/vt-d', 'virtio' and 'core' into next

commit 808be0aae53a3675337fad9cde616e086bdc8287
Author: Jacob Pan <jacob.jun.pan@linux.intel.com>
Date:   Wed Oct 2 12:42:43 2019 -0700

    iommu: Introduce guest PASID bind function
    
    Guest shared virtual address (SVA) may require host to shadow guest
    PASID tables. Guest PASID can also be allocated from the host via
    enlightened interfaces. In this case, guest needs to bind the guest
    mm, i.e. cr3 in guest physical address to the actual PASID table in
    the host IOMMU. Nesting will be turned on such that guest virtual
    address can go through a two level translation:
    - 1st level translates GVA to GPA
    - 2nd level translates GPA to HPA
    This patch introduces APIs to bind guest PASID data to the assigned
    device entry in the physical IOMMU. See the diagram below for usage
    explanation.
    
        .-------------.  .---------------------------.
        |   vIOMMU    |  | Guest process mm, FL only |
        |             |  '---------------------------'
        .----------------/
        | PASID Entry |--- PASID cache flush -
        '-------------'                       |
        |             |                       V
        |             |                      GP
        '-------------'
    Guest
    ------| Shadow |----------------------- GP->HP* ---------
          v        v                          |
    Host                                      v
        .-------------.  .----------------------.
        |   pIOMMU    |  | Bind FL for GVA-GPA  |
        |             |  '----------------------'
        .----------------/  |
        | PASID Entry |     V (Nested xlate)
        '----------------\.---------------------.
        |             |   |Set SL to GPA-HPA    |
        |             |   '---------------------'
        '-------------'
    
    Where:
     - FL = First level/stage one page tables
     - SL = Second level/stage two page tables
     - GP = Guest PASID
     - HP = Host PASID
    * Conversion needed if non-identity GP-HP mapping option is chosen.
    
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Signed-off-by: Liu Yi L <yi.l.liu@intel.com>
    Reviewed-by: Jean-Philippe Brucker <jean-philippe@linaro.com>
    Reviewed-by: Jean-Philippe Brucker <jean-philippe@linaro.org>
    Reviewed-by: Eric Auger <eric.auger@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 6ca9d28c08bb..4486c4e6830a 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1675,6 +1675,26 @@ int iommu_cache_invalidate(struct iommu_domain *domain, struct device *dev,
 }
 EXPORT_SYMBOL_GPL(iommu_cache_invalidate);
 
+int iommu_sva_bind_gpasid(struct iommu_domain *domain,
+			   struct device *dev, struct iommu_gpasid_bind_data *data)
+{
+	if (unlikely(!domain->ops->sva_bind_gpasid))
+		return -ENODEV;
+
+	return domain->ops->sva_bind_gpasid(domain, dev, data);
+}
+EXPORT_SYMBOL_GPL(iommu_sva_bind_gpasid);
+
+int iommu_sva_unbind_gpasid(struct iommu_domain *domain, struct device *dev,
+			     ioasid_t pasid)
+{
+	if (unlikely(!domain->ops->sva_unbind_gpasid))
+		return -ENODEV;
+
+	return domain->ops->sva_unbind_gpasid(dev, pasid);
+}
+EXPORT_SYMBOL_GPL(iommu_sva_unbind_gpasid);
+
 static void __iommu_detach_device(struct iommu_domain *domain,
 				  struct device *dev)
 {

commit 4c7c171f85b261f91270d405b7c7390aa6ddfb60
Author: Yi L Liu <yi.l.liu@intel.com>
Date:   Wed Oct 2 12:42:40 2019 -0700

    iommu: Introduce cache_invalidate API
    
    In any virtualization use case, when the first translation stage
    is "owned" by the guest OS, the host IOMMU driver has no knowledge
    of caching structure updates unless the guest invalidation activities
    are trapped by the virtualizer and passed down to the host.
    
    Since the invalidation data can be obtained from user space and will be
    written into physical IOMMU, we must allow security check at various
    layers. Therefore, generic invalidation data format are proposed here,
    model specific IOMMU drivers need to convert them into their own format.
    
    Signed-off-by: Yi L Liu <yi.l.liu@intel.com>
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Signed-off-by: Ashok Raj <ashok.raj@intel.com>
    Signed-off-by: Eric Auger <eric.auger@redhat.com>
    Signed-off-by: Jean-Philippe Brucker <jean-philippe@linaro.com>
    Reviewed-by: Jean-Philippe Brucker <jean-philippe@linaro.org>
    Reviewed-by: Eric Auger <eric.auger@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index d658c7c6a2ab..6ca9d28c08bb 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1665,6 +1665,16 @@ int iommu_attach_device(struct iommu_domain *domain, struct device *dev)
 }
 EXPORT_SYMBOL_GPL(iommu_attach_device);
 
+int iommu_cache_invalidate(struct iommu_domain *domain, struct device *dev,
+			   struct iommu_cache_invalidate_info *inv_info)
+{
+	if (unlikely(!domain->ops->cache_invalidate))
+		return -ENODEV;
+
+	return domain->ops->cache_invalidate(domain, dev, inv_info);
+}
+EXPORT_SYMBOL_GPL(iommu_cache_invalidate);
+
 static void __iommu_detach_device(struct iommu_domain *domain,
 				  struct device *dev)
 {

commit 781ca2de89bae1b1d2c96df9ef33e9a324415995
Author: Tom Murphy <murphyt7@tcd.ie>
Date:   Sun Sep 8 09:56:38 2019 -0700

    iommu: Add gfp parameter to iommu_ops::map
    
    Add a gfp_t parameter to the iommu_ops::map function.
    Remove the needless locking in the AMD iommu driver.
    
    The iommu_ops::map function (or the iommu_map function which calls it)
    was always supposed to be sleepable (according to Joerg's comment in
    this thread: https://lore.kernel.org/patchwork/patch/977520/ ) and so
    should probably have had a "might_sleep()" since it was written. However
    currently the dma-iommu api can call iommu_map in an atomic context,
    which it shouldn't do. This doesn't cause any problems because any iommu
    driver which uses the dma-iommu api uses gfp_atomic in it's
    iommu_ops::map function. But doing this wastes the memory allocators
    atomic pools.
    
    Signed-off-by: Tom Murphy <murphyt7@tcd.ie>
    Reviewed-by: Robin Murphy <robin.murphy@arm.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index d658c7c6a2ab..f8853dbf1c4e 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1854,8 +1854,8 @@ static size_t iommu_pgsize(struct iommu_domain *domain,
 	return pgsize;
 }
 
-int iommu_map(struct iommu_domain *domain, unsigned long iova,
-	      phys_addr_t paddr, size_t size, int prot)
+int __iommu_map(struct iommu_domain *domain, unsigned long iova,
+	      phys_addr_t paddr, size_t size, int prot, gfp_t gfp)
 {
 	const struct iommu_ops *ops = domain->ops;
 	unsigned long orig_iova = iova;
@@ -1892,8 +1892,8 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 
 		pr_debug("mapping: iova 0x%lx pa %pa pgsize 0x%zx\n",
 			 iova, &paddr, pgsize);
+		ret = ops->map(domain, iova, paddr, pgsize, prot, gfp);
 
-		ret = ops->map(domain, iova, paddr, pgsize, prot);
 		if (ret)
 			break;
 
@@ -1913,8 +1913,22 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 
 	return ret;
 }
+
+int iommu_map(struct iommu_domain *domain, unsigned long iova,
+	      phys_addr_t paddr, size_t size, int prot)
+{
+	might_sleep();
+	return __iommu_map(domain, iova, paddr, size, prot, GFP_KERNEL);
+}
 EXPORT_SYMBOL_GPL(iommu_map);
 
+int iommu_map_atomic(struct iommu_domain *domain, unsigned long iova,
+	      phys_addr_t paddr, size_t size, int prot)
+{
+	return __iommu_map(domain, iova, paddr, size, prot, GFP_ATOMIC);
+}
+EXPORT_SYMBOL_GPL(iommu_map_atomic);
+
 static size_t __iommu_unmap(struct iommu_domain *domain,
 			    unsigned long iova, size_t size,
 			    struct iommu_iotlb_gather *iotlb_gather)
@@ -1991,8 +2005,9 @@ size_t iommu_unmap_fast(struct iommu_domain *domain,
 }
 EXPORT_SYMBOL_GPL(iommu_unmap_fast);
 
-size_t iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
-		    struct scatterlist *sg, unsigned int nents, int prot)
+size_t __iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
+		    struct scatterlist *sg, unsigned int nents, int prot,
+		    gfp_t gfp)
 {
 	size_t len = 0, mapped = 0;
 	phys_addr_t start;
@@ -2003,7 +2018,9 @@ size_t iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
 		phys_addr_t s_phys = sg_phys(sg);
 
 		if (len && s_phys != start + len) {
-			ret = iommu_map(domain, iova + mapped, start, len, prot);
+			ret = __iommu_map(domain, iova + mapped, start,
+					len, prot, gfp);
+
 			if (ret)
 				goto out_err;
 
@@ -2031,8 +2048,22 @@ size_t iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
 	return 0;
 
 }
+
+size_t iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
+		    struct scatterlist *sg, unsigned int nents, int prot)
+{
+	might_sleep();
+	return __iommu_map_sg(domain, iova, sg, nents, prot, GFP_KERNEL);
+}
 EXPORT_SYMBOL_GPL(iommu_map_sg);
 
+size_t iommu_map_sg_atomic(struct iommu_domain *domain, unsigned long iova,
+		    struct scatterlist *sg, unsigned int nents, int prot)
+{
+	return __iommu_map_sg(domain, iova, sg, nents, prot, GFP_ATOMIC);
+}
+EXPORT_SYMBOL_GPL(iommu_map_sg_atomic);
+
 int iommu_domain_window_enable(struct iommu_domain *domain, u32 wnd_nr,
 			       phys_addr_t paddr, u64 size, int prot)
 {

commit 2896ba40d0becdb72b45f096cad70633abc014f6
Author: Joerg Roedel <jroedel@suse.de>
Date:   Tue Sep 3 15:15:44 2019 +0200

    iommu: Don't use sme_active() in generic code
    
    Switch to the generic function mem_encrypt_active() because
    sme_active() is x86 specific and can't be called from
    generic code on other platforms than x86.
    
    Fixes: 2cc13bb4f59f ("iommu: Disable passthrough mode when SME is active")
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 66cfacaa483d..d658c7c6a2ab 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -120,8 +120,8 @@ static int __init iommu_subsys_init(void)
 		else
 			iommu_set_default_translated(false);
 
-		if (iommu_default_passthrough() && sme_active()) {
-			pr_info("SME detected - Disabling default IOMMU Passthrough\n");
+		if (iommu_default_passthrough() && mem_encrypt_active()) {
+			pr_info("Memory encryption detected - Disabling default IOMMU Passthrough\n");
 			iommu_set_default_translated(false);
 		}
 	}

commit d127bc9be856098cc2410c1266ed64e258bc5377
Author: Tom Murphy <murphyt7@tcd.ie>
Date:   Mon Aug 26 05:48:21 2019 +0100

    iommu: Remove wrong default domain comments
    
    These comments are wrong. request_default_domain_for_dev doesn't just
    handle direct mapped domains.
    
    Signed-off-by: Tom Murphy <murphyt7@tcd.ie>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index b6980938882e..66cfacaa483d 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -2200,7 +2200,6 @@ request_default_domain_for_dev(struct device *dev, unsigned long type)
 
 	mutex_lock(&group->mutex);
 
-	/* Check if the default domain is already direct mapped */
 	ret = 0;
 	if (group->default_domain && group->default_domain->type == type)
 		goto out;
@@ -2210,7 +2209,6 @@ request_default_domain_for_dev(struct device *dev, unsigned long type)
 	if (iommu_group_device_count(group) != 1)
 		goto out;
 
-	/* Allocate a direct mapped domain */
 	ret = -ENOMEM;
 	domain = __iommu_domain_alloc(dev->bus, type);
 	if (!domain)
@@ -2225,7 +2223,7 @@ request_default_domain_for_dev(struct device *dev, unsigned long type)
 
 	iommu_group_create_direct_mappings(group, dev);
 
-	/* Make the direct mapped domain the default for this group */
+	/* Make the domain the default for this group */
 	if (group->default_domain)
 		iommu_domain_free(group->default_domain);
 	group->default_domain = domain;

commit 4dbd258ff63e0597ee8fb44d277c6c701f5019d9
Author: Eric Auger <eric.auger@redhat.com>
Date:   Wed Aug 21 14:09:40 2019 +0200

    iommu: Revisit iommu_insert_resv_region() implementation
    
    Current implementation is recursive and in case of allocation
    failure the existing @regions list is altered. A non recursive
    version looks better for maintainability and simplifies the
    error handling. We use a separate stack for overlapping segment
    merging. The elements are sorted by start address and then by
    type, if their start address match.
    
    Note this new implementation may change the region order of
    appearance in /sys/kernel/iommu_groups/<n>/reserved_regions
    files but this order has never been documented, see
    commit bc7d12b91bd3 ("iommu: Implement reserved_regions
    iommu-group sysfs file").
    
    Signed-off-by: Eric Auger <eric.auger@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 0f585b614657..b6980938882e 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -286,60 +286,58 @@ static ssize_t iommu_group_show_name(struct iommu_group *group, char *buf)
  * @new: new region to insert
  * @regions: list of regions
  *
- * The new element is sorted by address with respect to the other
- * regions of the same type. In case it overlaps with another
- * region of the same type, regions are merged. In case it
- * overlaps with another region of different type, regions are
- * not merged.
+ * Elements are sorted by start address and overlapping segments
+ * of the same type are merged.
  */
-static int iommu_insert_resv_region(struct iommu_resv_region *new,
-				    struct list_head *regions)
+int iommu_insert_resv_region(struct iommu_resv_region *new,
+			     struct list_head *regions)
 {
-	struct iommu_resv_region *region;
-	phys_addr_t start = new->start;
-	phys_addr_t end = new->start + new->length - 1;
-	struct list_head *pos = regions->next;
-
-	while (pos != regions) {
-		struct iommu_resv_region *entry =
-			list_entry(pos, struct iommu_resv_region, list);
-		phys_addr_t a = entry->start;
-		phys_addr_t b = entry->start + entry->length - 1;
-		int type = entry->type;
-
-		if (end < a) {
-			goto insert;
-		} else if (start > b) {
-			pos = pos->next;
-		} else if ((start >= a) && (end <= b)) {
-			if (new->type == type)
-				return 0;
-			else
-				pos = pos->next;
+	struct iommu_resv_region *iter, *tmp, *nr, *top;
+	LIST_HEAD(stack);
+
+	nr = iommu_alloc_resv_region(new->start, new->length,
+				     new->prot, new->type);
+	if (!nr)
+		return -ENOMEM;
+
+	/* First add the new element based on start address sorting */
+	list_for_each_entry(iter, regions, list) {
+		if (nr->start < iter->start ||
+		    (nr->start == iter->start && nr->type <= iter->type))
+			break;
+	}
+	list_add_tail(&nr->list, &iter->list);
+
+	/* Merge overlapping segments of type nr->type in @regions, if any */
+	list_for_each_entry_safe(iter, tmp, regions, list) {
+		phys_addr_t top_end, iter_end = iter->start + iter->length - 1;
+
+		/* no merge needed on elements of different types than @nr */
+		if (iter->type != nr->type) {
+			list_move_tail(&iter->list, &stack);
+			continue;
+		}
+
+		/* look for the last stack element of same type as @iter */
+		list_for_each_entry_reverse(top, &stack, list)
+			if (top->type == iter->type)
+				goto check_overlap;
+
+		list_move_tail(&iter->list, &stack);
+		continue;
+
+check_overlap:
+		top_end = top->start + top->length - 1;
+
+		if (iter->start > top_end + 1) {
+			list_move_tail(&iter->list, &stack);
 		} else {
-			if (new->type == type) {
-				phys_addr_t new_start = min(a, start);
-				phys_addr_t new_end = max(b, end);
-				int ret;
-
-				list_del(&entry->list);
-				entry->start = new_start;
-				entry->length = new_end - new_start + 1;
-				ret = iommu_insert_resv_region(entry, regions);
-				kfree(entry);
-				return ret;
-			} else {
-				pos = pos->next;
-			}
+			top->length = max(top_end, iter_end) - top->start + 1;
+			list_del(&iter->list);
+			kfree(iter);
 		}
 	}
-insert:
-	region = iommu_alloc_resv_region(new->start, new->length,
-					 new->prot, new->type);
-	if (!region)
-		return -ENOMEM;
-
-	list_add_tail(&region->list, pos);
+	list_splice(&stack, regions);
 	return 0;
 }
 

commit 2cc13bb4f59fa7e66acf5b1b78bdf97d73d3416a
Author: Joerg Roedel <jroedel@suse.de>
Date:   Mon Aug 19 15:22:55 2019 +0200

    iommu: Disable passthrough mode when SME is active
    
    Using Passthrough mode when SME is active causes certain
    devices to use the SWIOTLB bounce buffer. The bounce buffer
    code has an upper limit of 256kb for the size of DMA
    allocations, which is too small for certain devices and
    causes them to fail.
    
    With this patch we enable IOMMU by default when SME is
    active in the system, making the default configuration work
    for more systems than it does now.
    
    Users that don't want IOMMUs to be enabled still can disable
    them with kernel parameters.
    
    Reviewed-by: Tom Lendacky <thomas.lendacky@amd.com>
    Tested-by: Tom Lendacky <thomas.lendacky@amd.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 9ad1b0af2306..0f585b614657 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -119,6 +119,11 @@ static int __init iommu_subsys_init(void)
 			iommu_set_default_passthrough(false);
 		else
 			iommu_set_default_translated(false);
+
+		if (iommu_default_passthrough() && sme_active()) {
+			pr_info("SME detected - Disabling default IOMMU Passthrough\n");
+			iommu_set_default_translated(false);
+		}
 	}
 
 	pr_info("Default domain type: %s %s\n",

commit 22bb182c839d8ef6c08cf548feb0451c429216d8
Author: Joerg Roedel <jroedel@suse.de>
Date:   Mon Aug 19 15:22:54 2019 +0200

    iommu: Set default domain type at runtime
    
    Set the default domain-type at runtime, not at compile-time.
    This keeps default domain type setting in one place when we
    have to change it at runtime.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 31a66c4600bc..9ad1b0af2306 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -26,11 +26,8 @@
 
 static struct kset *iommu_group_kset;
 static DEFINE_IDA(iommu_group_ida);
-#ifdef CONFIG_IOMMU_DEFAULT_PASSTHROUGH
-static unsigned int iommu_def_domain_type = IOMMU_DOMAIN_IDENTITY;
-#else
-static unsigned int iommu_def_domain_type = IOMMU_DOMAIN_DMA;
-#endif
+
+static unsigned int iommu_def_domain_type __read_mostly;
 static bool iommu_dma_strict __read_mostly = true;
 static u32 iommu_cmd_line __read_mostly;
 
@@ -76,7 +73,7 @@ static void iommu_set_cmd_line_dma_api(void)
 	iommu_cmd_line |= IOMMU_CMD_LINE_DMA_API;
 }
 
-static bool __maybe_unused iommu_cmd_line_dma_api(void)
+static bool iommu_cmd_line_dma_api(void)
 {
 	return !!(iommu_cmd_line & IOMMU_CMD_LINE_DMA_API);
 }
@@ -115,8 +112,18 @@ static const char *iommu_domain_type_str(unsigned int t)
 
 static int __init iommu_subsys_init(void)
 {
-	pr_info("Default domain type: %s\n",
-		iommu_domain_type_str(iommu_def_domain_type));
+	bool cmd_line = iommu_cmd_line_dma_api();
+
+	if (!cmd_line) {
+		if (IS_ENABLED(CONFIG_IOMMU_DEFAULT_PASSTHROUGH))
+			iommu_set_default_passthrough(false);
+		else
+			iommu_set_default_translated(false);
+	}
+
+	pr_info("Default domain type: %s %s\n",
+		iommu_domain_type_str(iommu_def_domain_type),
+		cmd_line ? "(set via kernel command line)" : "");
 
 	return 0;
 }

commit 5fa9e7c5fa50f27afd71f2f6373179739bfa4034
Author: Joerg Roedel <jroedel@suse.de>
Date:   Mon Aug 19 15:22:53 2019 +0200

    iommu: Print default domain type on boot
    
    Introduce a subsys_initcall for IOMMU code and use it to
    print the default domain type at boot.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 544f44fc08e4..31a66c4600bc 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -93,12 +93,40 @@ struct iommu_group_attribute iommu_group_attr_##_name =		\
 static LIST_HEAD(iommu_device_list);
 static DEFINE_SPINLOCK(iommu_device_lock);
 
+/*
+ * Use a function instead of an array here because the domain-type is a
+ * bit-field, so an array would waste memory.
+ */
+static const char *iommu_domain_type_str(unsigned int t)
+{
+	switch (t) {
+	case IOMMU_DOMAIN_BLOCKED:
+		return "Blocked";
+	case IOMMU_DOMAIN_IDENTITY:
+		return "Passthrough";
+	case IOMMU_DOMAIN_UNMANAGED:
+		return "Unmanaged";
+	case IOMMU_DOMAIN_DMA:
+		return "Translated";
+	default:
+		return "Unknown";
+	}
+}
+
+static int __init iommu_subsys_init(void)
+{
+	pr_info("Default domain type: %s\n",
+		iommu_domain_type_str(iommu_def_domain_type));
+
+	return 0;
+}
+subsys_initcall(iommu_subsys_init);
+
 int iommu_device_register(struct iommu_device *iommu)
 {
 	spin_lock(&iommu_device_lock);
 	list_add_tail(&iommu->list, &iommu_device_list);
 	spin_unlock(&iommu_device_lock);
-
 	return 0;
 }
 

commit adab0b07cbbc73f9fc338e4fc1749714dd093a7c
Author: Joerg Roedel <jroedel@suse.de>
Date:   Mon Aug 19 15:22:48 2019 +0200

    iommu: Use Functions to set default domain type in iommu_set_def_domain_type()
    
    There are functions now to set the default domain type which
    take care of updating other necessary state. Don't open-code
    it in iommu_set_def_domain_type() and use those functions
    instead.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index c5e0fc5ffe8b..544f44fc08e4 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -178,9 +178,11 @@ static int __init iommu_set_def_domain_type(char *str)
 	if (ret)
 		return ret;
 
-	iommu_set_cmd_line_dma_api();
+	if (pt)
+		iommu_set_default_passthrough(true);
+	else
+		iommu_set_default_translated(true);
 
-	iommu_def_domain_type = pt ? IOMMU_DOMAIN_IDENTITY : IOMMU_DOMAIN_DMA;
 	return 0;
 }
 early_param("iommu.passthrough", iommu_set_def_domain_type);

commit 8a69961c7f7583742ab9064feab5ea533a6b1b97
Author: Joerg Roedel <jroedel@suse.de>
Date:   Mon Aug 19 15:22:47 2019 +0200

    iommu: Add helpers to set/get default domain type
    
    Add a couple of functions to allow changing the default
    domain type from architecture code and a function for iommu
    drivers to request whether the default domain is
    passthrough.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 0ae34cca0d4a..c5e0fc5ffe8b 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -2213,6 +2213,28 @@ int iommu_request_dma_domain_for_dev(struct device *dev)
 	return request_default_domain_for_dev(dev, IOMMU_DOMAIN_DMA);
 }
 
+void iommu_set_default_passthrough(bool cmd_line)
+{
+	if (cmd_line)
+		iommu_set_cmd_line_dma_api();
+
+	iommu_def_domain_type = IOMMU_DOMAIN_IDENTITY;
+}
+
+void iommu_set_default_translated(bool cmd_line)
+{
+	if (cmd_line)
+		iommu_set_cmd_line_dma_api();
+
+	iommu_def_domain_type = IOMMU_DOMAIN_DMA;
+}
+
+bool iommu_default_passthrough(void)
+{
+	return iommu_def_domain_type == IOMMU_DOMAIN_IDENTITY;
+}
+EXPORT_SYMBOL_GPL(iommu_default_passthrough);
+
 const struct iommu_ops *iommu_ops_from_fwnode(struct fwnode_handle *fwnode)
 {
 	const struct iommu_ops *ops = NULL;

commit faf1498993cdf65fd3a624b7653bc91909135a55
Author: Joerg Roedel <jroedel@suse.de>
Date:   Mon Aug 19 15:22:46 2019 +0200

    iommu: Remember when default domain type was set on kernel command line
    
    Introduce an extensible concept to remember when certain
    configuration settings for the IOMMU code have been set on
    the kernel command line.
    
    This will be used later to prevent overwriting these
    settings with other defaults.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 70bfbcc09248..0ae34cca0d4a 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -32,6 +32,7 @@ static unsigned int iommu_def_domain_type = IOMMU_DOMAIN_IDENTITY;
 static unsigned int iommu_def_domain_type = IOMMU_DOMAIN_DMA;
 #endif
 static bool iommu_dma_strict __read_mostly = true;
+static u32 iommu_cmd_line __read_mostly;
 
 struct iommu_group {
 	struct kobject kobj;
@@ -68,6 +69,18 @@ static const char * const iommu_group_resv_type_string[] = {
 	[IOMMU_RESV_SW_MSI]			= "msi",
 };
 
+#define IOMMU_CMD_LINE_DMA_API		BIT(0)
+
+static void iommu_set_cmd_line_dma_api(void)
+{
+	iommu_cmd_line |= IOMMU_CMD_LINE_DMA_API;
+}
+
+static bool __maybe_unused iommu_cmd_line_dma_api(void)
+{
+	return !!(iommu_cmd_line & IOMMU_CMD_LINE_DMA_API);
+}
+
 #define IOMMU_GROUP_ATTR(_name, _mode, _show, _store)		\
 struct iommu_group_attribute iommu_group_attr_##_name =		\
 	__ATTR(_name, _mode, _show, _store)
@@ -165,6 +178,8 @@ static int __init iommu_set_def_domain_type(char *str)
 	if (ret)
 		return ret;
 
+	iommu_set_cmd_line_dma_api();
+
 	iommu_def_domain_type = pt ? IOMMU_DOMAIN_IDENTITY : IOMMU_DOMAIN_DMA;
 	return 0;
 }

commit 56f8af5e9d38f120cba2c2adb0786fa2dbc901a4
Author: Will Deacon <will@kernel.org>
Date:   Tue Jul 2 16:44:06 2019 +0100

    iommu: Pass struct iommu_iotlb_gather to ->unmap() and ->iotlb_sync()
    
    To allow IOMMU drivers to batch up TLB flushing operations and postpone
    them until ->iotlb_sync() is called, extend the prototypes for the
    ->unmap() and ->iotlb_sync() IOMMU ops callbacks to take a pointer to
    the current iommu_iotlb_gather structure.
    
    All affected IOMMU drivers are updated, but there should be no
    functional change since the extra parameter is ignored for now.
    
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index d67222fdfe44..70bfbcc09248 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1899,7 +1899,7 @@ static size_t __iommu_unmap(struct iommu_domain *domain,
 	while (unmapped < size) {
 		size_t pgsize = iommu_pgsize(domain, iova, size - unmapped);
 
-		unmapped_page = ops->unmap(domain, iova, pgsize);
+		unmapped_page = ops->unmap(domain, iova, pgsize, iotlb_gather);
 		if (!unmapped_page)
 			break;
 

commit a7d20dc19d9ea7012227be5144353012ffa3ddc4
Author: Will Deacon <will@kernel.org>
Date:   Tue Jul 2 16:43:48 2019 +0100

    iommu: Introduce struct iommu_iotlb_gather for batching TLB flushes
    
    To permit batching of TLB flushes across multiple calls to the IOMMU
    driver's ->unmap() implementation, introduce a new structure for
    tracking the address range to be flushed and the granularity at which
    the flushing is required.
    
    This is hooked into the IOMMU API and its caller are updated to make use
    of the new structure. Subsequent patches will plumb this into the IOMMU
    drivers as well, but for now the gathering information is ignored.
    
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 6d7b25fe2474..d67222fdfe44 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1862,7 +1862,7 @@ EXPORT_SYMBOL_GPL(iommu_map);
 
 static size_t __iommu_unmap(struct iommu_domain *domain,
 			    unsigned long iova, size_t size,
-			    bool sync)
+			    struct iommu_iotlb_gather *iotlb_gather)
 {
 	const struct iommu_ops *ops = domain->ops;
 	size_t unmapped_page, unmapped = 0;
@@ -1910,9 +1910,6 @@ static size_t __iommu_unmap(struct iommu_domain *domain,
 		unmapped += unmapped_page;
 	}
 
-	if (sync && ops->iotlb_sync)
-		ops->iotlb_sync(domain);
-
 	trace_unmap(orig_iova, size, unmapped);
 	return unmapped;
 }
@@ -1920,14 +1917,22 @@ static size_t __iommu_unmap(struct iommu_domain *domain,
 size_t iommu_unmap(struct iommu_domain *domain,
 		   unsigned long iova, size_t size)
 {
-	return __iommu_unmap(domain, iova, size, true);
+	struct iommu_iotlb_gather iotlb_gather;
+	size_t ret;
+
+	iommu_iotlb_gather_init(&iotlb_gather);
+	ret = __iommu_unmap(domain, iova, size, &iotlb_gather);
+	iommu_tlb_sync(domain, &iotlb_gather);
+
+	return ret;
 }
 EXPORT_SYMBOL_GPL(iommu_unmap);
 
 size_t iommu_unmap_fast(struct iommu_domain *domain,
-			unsigned long iova, size_t size)
+			unsigned long iova, size_t size,
+			struct iommu_iotlb_gather *iotlb_gather)
 {
-	return __iommu_unmap(domain, iova, size, false);
+	return __iommu_unmap(domain, iova, size, iotlb_gather);
 }
 EXPORT_SYMBOL_GPL(iommu_unmap_fast);
 

commit 6d1bcb957be2850e0776f24c289e1f87c256baeb
Author: Will Deacon <will@kernel.org>
Date:   Tue Jul 2 16:43:07 2019 +0100

    iommu: Remove empty iommu_tlb_range_add() callback from iommu_ops
    
    Commit add02cfdc9bc ("iommu: Introduce Interface for IOMMU TLB Flushing")
    added three new TLB flushing operations to the IOMMU API so that the
    underlying driver operations can be batched when unmapping large regions
    of IO virtual address space.
    
    However, the ->iotlb_range_add() callback has not been implemented by
    any IOMMU drivers (amd_iommu.c implements it as an empty function, which
    incurs the overhead of an indirect branch). Instead, drivers either flush
    the entire IOTLB in the ->iotlb_sync() callback or perform the necessary
    invalidation during ->unmap().
    
    Attempting to implement ->iotlb_range_add() for arm-smmu-v3.c revealed
    two major issues:
    
      1. The page size used to map the region in the page-table is not known,
         and so it is not generally possible to issue TLB flushes in the most
         efficient manner.
    
      2. The only mutable state passed to the callback is a pointer to the
         iommu_domain, which can be accessed concurrently and therefore
         requires expensive synchronisation to keep track of the outstanding
         flushes.
    
    Remove the callback entirely in preparation for extending ->unmap() and
    ->iotlb_sync() to update a token on the caller's stack.
    
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 0c674d80c37f..6d7b25fe2474 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1903,9 +1903,6 @@ static size_t __iommu_unmap(struct iommu_domain *domain,
 		if (!unmapped_page)
 			break;
 
-		if (sync && ops->iotlb_range_add)
-			ops->iotlb_range_add(domain, iova, pgsize);
-
 		pr_debug("unmapped: iova 0x%lx size 0x%zx\n",
 			 iova, unmapped_page);
 

commit d95c3885865b71e56d8d60c8617f2ce1f0fa079d
Merge: 0bcfa628f8a3 5cd3f2e98cca 8dd8f005bdd4 9378bfeaafcb ceedd5f74d8c 29fcea8ce7f3
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu Jul 4 17:26:48 2019 +0200

    Merge branches 'x86/vt-d', 'x86/amd', 'arm/smmu', 'arm/omap', 'generic-dma-ops' and 'core' into next

commit c78ad1be4b4d65eb214421b90a788abf3c85c3ea
Merge: 7617c9a087d2 4e4abae311e4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jun 14 05:49:35 2019 -1000

    Merge tag 'iommu-fixes-v5.2-rc4' of git://git.kernel.org/pub/scm/linux/kernel/git/joro/iommu
    
    Pull iommu fixes from Joerg Roedel:
    
     - three fixes for Intel VT-d to fix a potential dead-lock, a formatting
       fix and a bit setting fix
    
     - one fix for the ARM-SMMU to make it work on some platforms with
       sub-optimal SMMU emulation
    
    * tag 'iommu-fixes-v5.2-rc4' of git://git.kernel.org/pub/scm/linux/kernel/git/joro/iommu:
      iommu/arm-smmu: Avoid constant zero in TLBI writes
      iommu/vt-d: Set the right field for Page Walk Snoop
      iommu/vt-d: Fix lock inversion between iommu->lock and device_domain_lock
      iommu: Add missing new line for dma type

commit adfd373820906d376c8b643f1a279ac809605b6b
Author: Eric Auger <eric.auger@redhat.com>
Date:   Mon Jun 3 08:53:35 2019 +0200

    iommu: Introduce IOMMU_RESV_DIRECT_RELAXABLE reserved memory regions
    
    Introduce a new type for reserved region. This corresponds
    to directly mapped regions which are known to be relaxable
    in some specific conditions, such as device assignment use
    case. Well known examples are those used by USB controllers
    providing PS/2 keyboard emulation for pre-boot BIOS and
    early BOOT or RMRRs associated to IGD working in legacy mode.
    
    Since commit c875d2c1b808 ("iommu/vt-d: Exclude devices using RMRRs
    from IOMMU API domains") and commit 18436afdc11a ("iommu/vt-d: Allow
    RMRR on graphics devices too"), those regions are currently
    considered "safe" with respect to device assignment use case
    which requires a non direct mapping at IOMMU physical level
    (RAM GPA -> HPA mapping).
    
    Those RMRRs currently exist and sometimes the device is
    attempting to access it but this has not been considered
    an issue until now.
    
    However at the moment, iommu_get_group_resv_regions() is
    not able to make any difference between directly mapped
    regions: those which must be absolutely enforced and those
    like above ones which are known as relaxable.
    
    This is a blocker for reporting severe conflicts between
    non relaxable RMRRs (like MSI doorbells) and guest GPA space.
    
    With this new reserved region type we will be able to use
    iommu_get_group_resv_regions() to enumerate the IOVA space
    that is usable through the IOMMU API without introducing
    regressions with respect to existing device assignment
    use cases (USB and IGD).
    
    Signed-off-by: Eric Auger <eric.auger@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index ba0661744a3d..46a06ff46e47 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -73,10 +73,11 @@ struct iommu_group_attribute {
 };
 
 static const char * const iommu_group_resv_type_string[] = {
-	[IOMMU_RESV_DIRECT]	= "direct",
-	[IOMMU_RESV_RESERVED]	= "reserved",
-	[IOMMU_RESV_MSI]	= "msi",
-	[IOMMU_RESV_SW_MSI]	= "msi",
+	[IOMMU_RESV_DIRECT]			= "direct",
+	[IOMMU_RESV_DIRECT_RELAXABLE]		= "direct-relaxable",
+	[IOMMU_RESV_RESERVED]			= "reserved",
+	[IOMMU_RESV_MSI]			= "msi",
+	[IOMMU_RESV_SW_MSI]			= "msi",
 };
 
 #define IOMMU_GROUP_ATTR(_name, _mode, _show, _store)		\
@@ -575,7 +576,8 @@ static int iommu_group_create_direct_mappings(struct iommu_group *group,
 		start = ALIGN(entry->start, pg_size);
 		end   = ALIGN(entry->start + entry->length, pg_size);
 
-		if (entry->type != IOMMU_RESV_DIRECT)
+		if (entry->type != IOMMU_RESV_DIRECT &&
+		    entry->type != IOMMU_RESV_DIRECT_RELAXABLE)
 			continue;
 
 		for (addr = start; addr < end; addr += pg_size) {

commit ad0834dedaa15c3a176f783c0373f836e44b4700
Author: Eric Auger <eric.auger@redhat.com>
Date:   Mon Jun 3 08:53:30 2019 +0200

    iommu: Fix a leak in iommu_insert_resv_region
    
    In case we expand an existing region, we unlink
    this latter and insert the larger one. In
    that case we should free the original region after
    the insertion. Also we can immediately return.
    
    Fixes: 6c65fb318e8b ("iommu: iommu_get_group_resv_regions")
    
    Signed-off-by: Eric Auger <eric.auger@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 2fca04c3dbaf..ba0661744a3d 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -237,18 +237,21 @@ static int iommu_insert_resv_region(struct iommu_resv_region *new,
 			pos = pos->next;
 		} else if ((start >= a) && (end <= b)) {
 			if (new->type == type)
-				goto done;
+				return 0;
 			else
 				pos = pos->next;
 		} else {
 			if (new->type == type) {
 				phys_addr_t new_start = min(a, start);
 				phys_addr_t new_end = max(b, end);
+				int ret;
 
 				list_del(&entry->list);
 				entry->start = new_start;
 				entry->length = new_end - new_start + 1;
-				iommu_insert_resv_region(entry, regions);
+				ret = iommu_insert_resv_region(entry, regions);
+				kfree(entry);
+				return ret;
 			} else {
 				pos = pos->next;
 			}
@@ -261,7 +264,6 @@ static int iommu_insert_resv_region(struct iommu_resv_region *new,
 		return -ENOMEM;
 
 	list_add_tail(&region->list, pos);
-done:
 	return 0;
 }
 

commit bf3255b3cfe2d06280340dbac3f44b65d3ee6da3
Author: Jean-Philippe Brucker <jean-philippe.brucker@arm.com>
Date:   Mon Jun 3 15:57:49 2019 +0100

    iommu: Add recoverable fault reporting
    
    Some IOMMU hardware features, for example PCI PRI and Arm SMMU Stall,
    enable recoverable I/O page faults. Allow IOMMU drivers to report PRI Page
    Requests and Stall events through the new fault reporting API. The
    consumer of the fault can be either an I/O page fault handler in the host,
    or a guest OS.
    
    Once handled, the fault must be completed by sending a page response back
    to the IOMMU. Add an iommu_page_response() function to complete a page
    fault.
    
    There are two ways to extend the userspace API:
    * Add a field to iommu_page_response and a flag to
      iommu_page_response::flags describing the validity of this field.
    * Introduce a new iommu_page_response_X structure with a different version
      number. The kernel must then support both versions.
    
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Signed-off-by: Jean-Philippe Brucker <jean-philippe.brucker@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 293a6fa716e0..ac1f29c19e59 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -891,7 +891,14 @@ EXPORT_SYMBOL_GPL(iommu_group_unregister_notifier);
  * @data: private data passed as argument to the handler
  *
  * When an IOMMU fault event is received, this handler gets called with the
- * fault event and data as argument. The handler should return 0 on success.
+ * fault event and data as argument. The handler should return 0 on success. If
+ * the fault is recoverable (IOMMU_FAULT_PAGE_REQ), the consumer should also
+ * complete the fault by calling iommu_page_response() with one of the following
+ * response code:
+ * - IOMMU_PAGE_RESP_SUCCESS: retry the translation
+ * - IOMMU_PAGE_RESP_INVALID: terminate the fault
+ * - IOMMU_PAGE_RESP_FAILURE: terminate the fault and stop reporting
+ *   page faults if possible.
  *
  * Return 0 if the fault handler was installed successfully, or an error.
  */
@@ -921,6 +928,8 @@ int iommu_register_device_fault_handler(struct device *dev,
 	}
 	param->fault_param->handler = handler;
 	param->fault_param->data = data;
+	mutex_init(&param->fault_param->lock);
+	INIT_LIST_HEAD(&param->fault_param->faults);
 
 done_unlock:
 	mutex_unlock(&param->lock);
@@ -951,6 +960,12 @@ int iommu_unregister_device_fault_handler(struct device *dev)
 	if (!param->fault_param)
 		goto unlock;
 
+	/* we cannot unregister handler if there are pending faults */
+	if (!list_empty(&param->fault_param->faults)) {
+		ret = -EBUSY;
+		goto unlock;
+	}
+
 	kfree(param->fault_param);
 	param->fault_param = NULL;
 	put_device(dev);
@@ -967,13 +982,15 @@ EXPORT_SYMBOL_GPL(iommu_unregister_device_fault_handler);
  * @evt: fault event data
  *
  * Called by IOMMU drivers when a fault is detected, typically in a threaded IRQ
- * handler.
+ * handler. When this function fails and the fault is recoverable, it is the
+ * caller's responsibility to complete the fault.
  *
  * Return 0 on success, or an error.
  */
 int iommu_report_device_fault(struct device *dev, struct iommu_fault_event *evt)
 {
 	struct iommu_param *param = dev->iommu_param;
+	struct iommu_fault_event *evt_pending = NULL;
 	struct iommu_fault_param *fparam;
 	int ret = 0;
 
@@ -987,13 +1004,86 @@ int iommu_report_device_fault(struct device *dev, struct iommu_fault_event *evt)
 		ret = -EINVAL;
 		goto done_unlock;
 	}
+
+	if (evt->fault.type == IOMMU_FAULT_PAGE_REQ &&
+	    (evt->fault.prm.flags & IOMMU_FAULT_PAGE_REQUEST_LAST_PAGE)) {
+		evt_pending = kmemdup(evt, sizeof(struct iommu_fault_event),
+				      GFP_KERNEL);
+		if (!evt_pending) {
+			ret = -ENOMEM;
+			goto done_unlock;
+		}
+		mutex_lock(&fparam->lock);
+		list_add_tail(&evt_pending->list, &fparam->faults);
+		mutex_unlock(&fparam->lock);
+	}
+
 	ret = fparam->handler(&evt->fault, fparam->data);
+	if (ret && evt_pending) {
+		mutex_lock(&fparam->lock);
+		list_del(&evt_pending->list);
+		mutex_unlock(&fparam->lock);
+		kfree(evt_pending);
+	}
 done_unlock:
 	mutex_unlock(&param->lock);
 	return ret;
 }
 EXPORT_SYMBOL_GPL(iommu_report_device_fault);
 
+int iommu_page_response(struct device *dev,
+			struct iommu_page_response *msg)
+{
+	bool pasid_valid;
+	int ret = -EINVAL;
+	struct iommu_fault_event *evt;
+	struct iommu_fault_page_request *prm;
+	struct iommu_param *param = dev->iommu_param;
+	struct iommu_domain *domain = iommu_get_domain_for_dev(dev);
+
+	if (!domain || !domain->ops->page_response)
+		return -ENODEV;
+
+	if (!param || !param->fault_param)
+		return -EINVAL;
+
+	if (msg->version != IOMMU_PAGE_RESP_VERSION_1 ||
+	    msg->flags & ~IOMMU_PAGE_RESP_PASID_VALID)
+		return -EINVAL;
+
+	/* Only send response if there is a fault report pending */
+	mutex_lock(&param->fault_param->lock);
+	if (list_empty(&param->fault_param->faults)) {
+		dev_warn_ratelimited(dev, "no pending PRQ, drop response\n");
+		goto done_unlock;
+	}
+	/*
+	 * Check if we have a matching page request pending to respond,
+	 * otherwise return -EINVAL
+	 */
+	list_for_each_entry(evt, &param->fault_param->faults, list) {
+		prm = &evt->fault.prm;
+		pasid_valid = prm->flags & IOMMU_FAULT_PAGE_REQUEST_PASID_VALID;
+
+		if ((pasid_valid && prm->pasid != msg->pasid) ||
+		    prm->grpid != msg->grpid)
+			continue;
+
+		/* Sanitize the reply */
+		msg->flags = pasid_valid ? IOMMU_PAGE_RESP_PASID_VALID : 0;
+
+		ret = domain->ops->page_response(dev, evt, msg);
+		list_del(&evt->list);
+		kfree(evt);
+		break;
+	}
+
+done_unlock:
+	mutex_unlock(&param->fault_param->lock);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(iommu_page_response);
+
 /**
  * iommu_group_id - Return ID for a group
  * @group: the group to ID

commit 0c830e6b32826311fc2b9ea1f4679be0f4ef0933
Author: Jacob Pan <jacob.jun.pan@linux.intel.com>
Date:   Mon Jun 3 15:57:48 2019 +0100

    iommu: Introduce device fault report API
    
    Traditionally, device specific faults are detected and handled within
    their own device drivers. When IOMMU is enabled, faults such as DMA
    related transactions are detected by IOMMU. There is no generic
    reporting mechanism to report faults back to the in-kernel device
    driver or the guest OS in case of assigned devices.
    
    This patch introduces a registration API for device specific fault
    handlers. This differs from the existing iommu_set_fault_handler/
    report_iommu_fault infrastructures in several ways:
    - it allows to report more sophisticated fault events (both
      unrecoverable faults and page request faults) due to the nature
      of the iommu_fault struct
    - it is device specific and not domain specific.
    
    The current iommu_report_device_fault() implementation only handles
    the "shoot and forget" unrecoverable fault case. Handling of page
    request faults or stalled faults will come later.
    
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Signed-off-by: Ashok Raj <ashok.raj@intel.com>
    Signed-off-by: Jean-Philippe Brucker <jean-philippe.brucker@arm.com>
    Signed-off-by: Eric Auger <eric.auger@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 3fa025f849e9..293a6fa716e0 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -107,15 +107,43 @@ void iommu_device_unregister(struct iommu_device *iommu)
 	spin_unlock(&iommu_device_lock);
 }
 
+static struct iommu_param *iommu_get_dev_param(struct device *dev)
+{
+	struct iommu_param *param = dev->iommu_param;
+
+	if (param)
+		return param;
+
+	param = kzalloc(sizeof(*param), GFP_KERNEL);
+	if (!param)
+		return NULL;
+
+	mutex_init(&param->lock);
+	dev->iommu_param = param;
+	return param;
+}
+
+static void iommu_free_dev_param(struct device *dev)
+{
+	kfree(dev->iommu_param);
+	dev->iommu_param = NULL;
+}
+
 int iommu_probe_device(struct device *dev)
 {
 	const struct iommu_ops *ops = dev->bus->iommu_ops;
-	int ret = -EINVAL;
+	int ret;
 
 	WARN_ON(dev->iommu_group);
+	if (!ops)
+		return -EINVAL;
 
-	if (ops)
-		ret = ops->add_device(dev);
+	if (!iommu_get_dev_param(dev))
+		return -ENOMEM;
+
+	ret = ops->add_device(dev);
+	if (ret)
+		iommu_free_dev_param(dev);
 
 	return ret;
 }
@@ -126,6 +154,8 @@ void iommu_release_device(struct device *dev)
 
 	if (dev->iommu_group)
 		ops->remove_device(dev);
+
+	iommu_free_dev_param(dev);
 }
 
 static struct iommu_domain *__iommu_domain_alloc(struct bus_type *bus,
@@ -854,6 +884,116 @@ int iommu_group_unregister_notifier(struct iommu_group *group,
 }
 EXPORT_SYMBOL_GPL(iommu_group_unregister_notifier);
 
+/**
+ * iommu_register_device_fault_handler() - Register a device fault handler
+ * @dev: the device
+ * @handler: the fault handler
+ * @data: private data passed as argument to the handler
+ *
+ * When an IOMMU fault event is received, this handler gets called with the
+ * fault event and data as argument. The handler should return 0 on success.
+ *
+ * Return 0 if the fault handler was installed successfully, or an error.
+ */
+int iommu_register_device_fault_handler(struct device *dev,
+					iommu_dev_fault_handler_t handler,
+					void *data)
+{
+	struct iommu_param *param = dev->iommu_param;
+	int ret = 0;
+
+	if (!param)
+		return -EINVAL;
+
+	mutex_lock(&param->lock);
+	/* Only allow one fault handler registered for each device */
+	if (param->fault_param) {
+		ret = -EBUSY;
+		goto done_unlock;
+	}
+
+	get_device(dev);
+	param->fault_param = kzalloc(sizeof(*param->fault_param), GFP_KERNEL);
+	if (!param->fault_param) {
+		put_device(dev);
+		ret = -ENOMEM;
+		goto done_unlock;
+	}
+	param->fault_param->handler = handler;
+	param->fault_param->data = data;
+
+done_unlock:
+	mutex_unlock(&param->lock);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(iommu_register_device_fault_handler);
+
+/**
+ * iommu_unregister_device_fault_handler() - Unregister the device fault handler
+ * @dev: the device
+ *
+ * Remove the device fault handler installed with
+ * iommu_register_device_fault_handler().
+ *
+ * Return 0 on success, or an error.
+ */
+int iommu_unregister_device_fault_handler(struct device *dev)
+{
+	struct iommu_param *param = dev->iommu_param;
+	int ret = 0;
+
+	if (!param)
+		return -EINVAL;
+
+	mutex_lock(&param->lock);
+
+	if (!param->fault_param)
+		goto unlock;
+
+	kfree(param->fault_param);
+	param->fault_param = NULL;
+	put_device(dev);
+unlock:
+	mutex_unlock(&param->lock);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(iommu_unregister_device_fault_handler);
+
+/**
+ * iommu_report_device_fault() - Report fault event to device driver
+ * @dev: the device
+ * @evt: fault event data
+ *
+ * Called by IOMMU drivers when a fault is detected, typically in a threaded IRQ
+ * handler.
+ *
+ * Return 0 on success, or an error.
+ */
+int iommu_report_device_fault(struct device *dev, struct iommu_fault_event *evt)
+{
+	struct iommu_param *param = dev->iommu_param;
+	struct iommu_fault_param *fparam;
+	int ret = 0;
+
+	if (!param || !evt)
+		return -EINVAL;
+
+	/* we only report device fault if there is a handler registered */
+	mutex_lock(&param->lock);
+	fparam = param->fault_param;
+	if (!fparam || !fparam->handler) {
+		ret = -EINVAL;
+		goto done_unlock;
+	}
+	ret = fparam->handler(&evt->fault, fparam->data);
+done_unlock:
+	mutex_unlock(&param->lock);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(iommu_report_device_fault);
+
 /**
  * iommu_group_id - Return ID for a group
  * @group: the group to ID

commit 4505153954fdb1465d2b178288a9bf646f2a2166
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed May 29 16:57:47 2019 -0700

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 333
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation this program is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details you should have received a copy of the gnu general
      public license along with this program if not write to the free
      software foundation inc 59 temple place suite 330 boston ma 02111
      1307 usa
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 136 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190530000436.384967451@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 67ee6623f9b2..f9cacce909d3 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1,19 +1,7 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * Copyright (C) 2007-2008 Advanced Micro Devices, Inc.
  * Author: Joerg Roedel <jroedel@suse.de>
- *
- * This program is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 as published
- * by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
 
 #define pr_fmt(fmt)    "iommu: " fmt

commit 7423e01741dd6a5f1255f589145313f0fb1c8cbe
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Sat May 25 13:41:22 2019 +0800

    iommu: Add API to request DMA domain for device
    
    Normally during iommu probing a device, a default doamin will
    be allocated and attached to the device. The domain type of
    the default domain is statically defined, which results in a
    situation where the allocated default domain isn't suitable
    for the device due to some limitations. We already have API
    iommu_request_dm_for_dev() to replace a DMA domain with an
    identity one. This adds iommu_request_dma_domain_for_dev()
    to request a dma domain if an allocated identity domain isn't
    suitable for the device in question.
    
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 67ee6623f9b2..2fca04c3dbaf 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1907,10 +1907,10 @@ struct iommu_resv_region *iommu_alloc_resv_region(phys_addr_t start,
 	return region;
 }
 
-/* Request that a device is direct mapped by the IOMMU */
-int iommu_request_dm_for_dev(struct device *dev)
+static int
+request_default_domain_for_dev(struct device *dev, unsigned long type)
 {
-	struct iommu_domain *dm_domain;
+	struct iommu_domain *domain;
 	struct iommu_group *group;
 	int ret;
 
@@ -1923,8 +1923,7 @@ int iommu_request_dm_for_dev(struct device *dev)
 
 	/* Check if the default domain is already direct mapped */
 	ret = 0;
-	if (group->default_domain &&
-	    group->default_domain->type == IOMMU_DOMAIN_IDENTITY)
+	if (group->default_domain && group->default_domain->type == type)
 		goto out;
 
 	/* Don't change mappings of existing devices */
@@ -1934,23 +1933,26 @@ int iommu_request_dm_for_dev(struct device *dev)
 
 	/* Allocate a direct mapped domain */
 	ret = -ENOMEM;
-	dm_domain = __iommu_domain_alloc(dev->bus, IOMMU_DOMAIN_IDENTITY);
-	if (!dm_domain)
+	domain = __iommu_domain_alloc(dev->bus, type);
+	if (!domain)
 		goto out;
 
 	/* Attach the device to the domain */
-	ret = __iommu_attach_group(dm_domain, group);
+	ret = __iommu_attach_group(domain, group);
 	if (ret) {
-		iommu_domain_free(dm_domain);
+		iommu_domain_free(domain);
 		goto out;
 	}
 
+	iommu_group_create_direct_mappings(group, dev);
+
 	/* Make the direct mapped domain the default for this group */
 	if (group->default_domain)
 		iommu_domain_free(group->default_domain);
-	group->default_domain = dm_domain;
+	group->default_domain = domain;
 
-	dev_info(dev, "Using iommu direct mapping\n");
+	dev_info(dev, "Using iommu %s mapping\n",
+		 type == IOMMU_DOMAIN_DMA ? "dma" : "direct");
 
 	ret = 0;
 out:
@@ -1960,6 +1962,18 @@ int iommu_request_dm_for_dev(struct device *dev)
 	return ret;
 }
 
+/* Request that a device is direct mapped by the IOMMU */
+int iommu_request_dm_for_dev(struct device *dev)
+{
+	return request_default_domain_for_dev(dev, IOMMU_DOMAIN_IDENTITY);
+}
+
+/* Request that a device can't be direct mapped by the IOMMU */
+int iommu_request_dma_domain_for_dev(struct device *dev)
+{
+	return request_default_domain_for_dev(dev, IOMMU_DOMAIN_DMA);
+}
+
 const struct iommu_ops *iommu_ops_from_fwnode(struct fwnode_handle *fwnode)
 {
 	const struct iommu_ops *ops = NULL;

commit 57274ea25736496ee019a5c40479855b21888839
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Tue May 21 15:27:35 2019 +0800

    iommu: Use right function to get group for device
    
    The iommu_group_get_for_dev() will allocate a group for a
    device if it isn't in any group. This isn't the use case
    in iommu_request_dm_for_dev(). Let's use iommu_group_get()
    instead.
    
    Fixes: d290f1e70d85a ("iommu: Introduce iommu_request_dm_for_dev()")
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 67ee6623f9b2..3fa025f849e9 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1915,9 +1915,9 @@ int iommu_request_dm_for_dev(struct device *dev)
 	int ret;
 
 	/* Device must already be in a group before calling this function */
-	group = iommu_group_get_for_dev(dev);
-	if (IS_ERR(group))
-		return PTR_ERR(group);
+	group = iommu_group_get(dev);
+	if (!group)
+		return -EINVAL;
 
 	mutex_lock(&group->mutex);
 

commit 24f307d8abf79486dd3c1b645037df7d91602aaa
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Fri May 24 14:30:56 2019 +0800

    iommu: Add missing new line for dma type
    
    So that all types are printed in the same format.
    
    Fixes: c52c72d3dee81 ("iommu: Add sysfs attribyte for domain type")
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 67ee6623f9b2..c9cfd08673e1 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -341,7 +341,7 @@ static ssize_t iommu_group_show_type(struct iommu_group *group,
 			type = "unmanaged\n";
 			break;
 		case IOMMU_DOMAIN_DMA:
-			type = "DMA";
+			type = "DMA\n";
 			break;
 		}
 	}

commit b5531563e8a0b8fcc5344a38d1fad9217e08e09b
Merge: 37624b58542f 43d957b13346 1eb8e4e2b35b d53bff888f3b dca4d60f5f8c 97a18f548548 14bd9a607f90
Author: Joerg Roedel <jroedel@suse.de>
Date:   Tue May 7 09:40:12 2019 +0200

    Merge branches 'arm/tegra', 'arm/mediatek', 'arm/smmu', 'x86/vt-d', 'x86/amd' and 'core' into next

commit 26b25a2b98e45aeb40eedcedc586ad5034cbd984
Author: Jean-Philippe Brucker <jean-philippe.brucker@arm.com>
Date:   Wed Apr 10 16:15:16 2019 +0100

    iommu: Bind process address spaces to devices
    
    Add bind() and unbind() operations to the IOMMU API.
    iommu_sva_bind_device() binds a device to an mm, and returns a handle to
    the bond, which is released by calling iommu_sva_unbind_device().
    
    Each mm bound to devices gets a PASID (by convention, a 20-bit system-wide
    ID representing the address space), which can be retrieved with
    iommu_sva_get_pasid(). When programming DMA addresses, device drivers
    include this PASID in a device-specific manner, to let the device access
    the given address space. Since the process memory may be paged out, device
    and IOMMU must support I/O page faults (e.g. PCI PRI).
    
    Using iommu_sva_set_ops(), device drivers provide an mm_exit() callback
    that is called by the IOMMU driver if the process exits before the device
    driver called unbind(). In mm_exit(), device driver should disable DMA
    from the given context, so that the core IOMMU can reallocate the PASID.
    Whether the process exited or nor, the device driver should always release
    the handle with unbind().
    
    To use these functions, device driver must first enable the
    IOMMU_DEV_FEAT_SVA device feature with iommu_dev_enable_feature().
    
    Signed-off-by: Jean-Philippe Brucker <jean-philippe.brucker@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 344e27e8f188..f8fe112e507a 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -2135,3 +2135,107 @@ int iommu_aux_get_pasid(struct iommu_domain *domain, struct device *dev)
 	return ret;
 }
 EXPORT_SYMBOL_GPL(iommu_aux_get_pasid);
+
+/**
+ * iommu_sva_bind_device() - Bind a process address space to a device
+ * @dev: the device
+ * @mm: the mm to bind, caller must hold a reference to it
+ *
+ * Create a bond between device and address space, allowing the device to access
+ * the mm using the returned PASID. If a bond already exists between @device and
+ * @mm, it is returned and an additional reference is taken. Caller must call
+ * iommu_sva_unbind_device() to release each reference.
+ *
+ * iommu_dev_enable_feature(dev, IOMMU_DEV_FEAT_SVA) must be called first, to
+ * initialize the required SVA features.
+ *
+ * On error, returns an ERR_PTR value.
+ */
+struct iommu_sva *
+iommu_sva_bind_device(struct device *dev, struct mm_struct *mm, void *drvdata)
+{
+	struct iommu_group *group;
+	struct iommu_sva *handle = ERR_PTR(-EINVAL);
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
+
+	if (!ops || !ops->sva_bind)
+		return ERR_PTR(-ENODEV);
+
+	group = iommu_group_get(dev);
+	if (!group)
+		return ERR_PTR(-ENODEV);
+
+	/* Ensure device count and domain don't change while we're binding */
+	mutex_lock(&group->mutex);
+
+	/*
+	 * To keep things simple, SVA currently doesn't support IOMMU groups
+	 * with more than one device. Existing SVA-capable systems are not
+	 * affected by the problems that required IOMMU groups (lack of ACS
+	 * isolation, device ID aliasing and other hardware issues).
+	 */
+	if (iommu_group_device_count(group) != 1)
+		goto out_unlock;
+
+	handle = ops->sva_bind(dev, mm, drvdata);
+
+out_unlock:
+	mutex_unlock(&group->mutex);
+	iommu_group_put(group);
+
+	return handle;
+}
+EXPORT_SYMBOL_GPL(iommu_sva_bind_device);
+
+/**
+ * iommu_sva_unbind_device() - Remove a bond created with iommu_sva_bind_device
+ * @handle: the handle returned by iommu_sva_bind_device()
+ *
+ * Put reference to a bond between device and address space. The device should
+ * not be issuing any more transaction for this PASID. All outstanding page
+ * requests for this PASID must have been flushed to the IOMMU.
+ *
+ * Returns 0 on success, or an error value
+ */
+void iommu_sva_unbind_device(struct iommu_sva *handle)
+{
+	struct iommu_group *group;
+	struct device *dev = handle->dev;
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
+
+	if (!ops || !ops->sva_unbind)
+		return;
+
+	group = iommu_group_get(dev);
+	if (!group)
+		return;
+
+	mutex_lock(&group->mutex);
+	ops->sva_unbind(handle);
+	mutex_unlock(&group->mutex);
+
+	iommu_group_put(group);
+}
+EXPORT_SYMBOL_GPL(iommu_sva_unbind_device);
+
+int iommu_sva_set_ops(struct iommu_sva *handle,
+		      const struct iommu_sva_ops *sva_ops)
+{
+	if (handle->ops && handle->ops != sva_ops)
+		return -EEXIST;
+
+	handle->ops = sva_ops;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(iommu_sva_set_ops);
+
+int iommu_sva_get_pasid(struct iommu_sva *handle)
+{
+	const struct iommu_ops *ops = handle->dev->bus->iommu_ops;
+
+	if (!ops || !ops->sva_get_pasid)
+		return IOMMU_PASID_INVALID;
+
+	return ops->sva_get_pasid(handle);
+}
+EXPORT_SYMBOL_GPL(iommu_sva_get_pasid);

commit a3a195929d40b38833ffd0f82b2db2cc898641eb
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Mon Mar 25 09:30:28 2019 +0800

    iommu: Add APIs for multiple domains per device
    
    Sharing a physical PCI device in a finer-granularity way
    is becoming a consensus in the industry. IOMMU vendors
    are also engaging efforts to support such sharing as well
    as possible. Among the efforts, the capability of support
    finer-granularity DMA isolation is a common requirement
    due to the security consideration. With finer-granularity
    DMA isolation, subsets of a PCI function can be isolated
    from each others by the IOMMU. As a result, there is a
    request in software to attach multiple domains to a physical
    PCI device. One example of such use model is the Intel
    Scalable IOV [1] [2]. The Intel vt-d 3.0 spec [3] introduces
    the scalable mode which enables PASID granularity DMA
    isolation.
    
    This adds the APIs to support multiple domains per device.
    In order to ease the discussions, we call it 'a domain in
    auxiliary mode' or simply 'auxiliary domain' when multiple
    domains are attached to a physical device.
    
    The APIs include:
    
    * iommu_dev_has_feature(dev, IOMMU_DEV_FEAT_AUX)
      - Detect both IOMMU and PCI endpoint devices supporting
        the feature (aux-domain here) without the host driver
        dependency.
    
    * iommu_dev_feature_enabled(dev, IOMMU_DEV_FEAT_AUX)
      - Check the enabling status of the feature (aux-domain
        here). The aux-domain interfaces are available only
        if this returns true.
    
    * iommu_dev_enable/disable_feature(dev, IOMMU_DEV_FEAT_AUX)
      - Enable/disable device specific aux-domain feature.
    
    * iommu_aux_attach_device(domain, dev)
      - Attaches @domain to @dev in the auxiliary mode. Multiple
        domains could be attached to a single device in the
        auxiliary mode with each domain representing an isolated
        address space for an assignable subset of the device.
    
    * iommu_aux_detach_device(domain, dev)
      - Detach @domain which has been attached to @dev in the
        auxiliary mode.
    
    * iommu_aux_get_pasid(domain, dev)
      - Return ID used for finer-granularity DMA translation.
        For the Intel Scalable IOV usage model, this will be
        a PASID. The device which supports Scalable IOV needs
        to write this ID to the device register so that DMA
        requests could be tagged with a right PASID prefix.
    
    This has been updated with the latest proposal from Joerg
    posted here [5].
    
    Many people involved in discussions of this design.
    
    Kevin Tian <kevin.tian@intel.com>
    Liu Yi L <yi.l.liu@intel.com>
    Ashok Raj <ashok.raj@intel.com>
    Sanjay Kumar <sanjay.k.kumar@intel.com>
    Jacob Pan <jacob.jun.pan@linux.intel.com>
    Alex Williamson <alex.williamson@redhat.com>
    Jean-Philippe Brucker <jean-philippe.brucker@arm.com>
    Joerg Roedel <joro@8bytes.org>
    
    and some discussions can be found here [4] [5].
    
    [1] https://software.intel.com/en-us/download/intel-scalable-io-virtualization-technical-specification
    [2] https://schd.ws/hosted_files/lc32018/00/LC3-SIOV-final.pdf
    [3] https://software.intel.com/en-us/download/intel-virtualization-technology-for-directed-io-architecture-specification
    [4] https://lkml.org/lkml/2018/7/26/4
    [5] https://www.spinics.net/lists/iommu/msg31874.html
    
    Cc: Ashok Raj <ashok.raj@intel.com>
    Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
    Cc: Kevin Tian <kevin.tian@intel.com>
    Cc: Liu Yi L <yi.l.liu@intel.com>
    Suggested-by: Kevin Tian <kevin.tian@intel.com>
    Suggested-by: Jean-Philippe Brucker <jean-philippe.brucker@arm.com>
    Suggested-by: Joerg Roedel <jroedel@suse.de>
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Reviewed-by: Jean-Philippe Brucker <jean-philippe.brucker@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 109de67d5d72..344e27e8f188 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -2039,3 +2039,99 @@ int iommu_fwspec_add_ids(struct device *dev, u32 *ids, int num_ids)
 	return 0;
 }
 EXPORT_SYMBOL_GPL(iommu_fwspec_add_ids);
+
+/*
+ * Per device IOMMU features.
+ */
+bool iommu_dev_has_feature(struct device *dev, enum iommu_dev_features feat)
+{
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
+
+	if (ops && ops->dev_has_feat)
+		return ops->dev_has_feat(dev, feat);
+
+	return false;
+}
+EXPORT_SYMBOL_GPL(iommu_dev_has_feature);
+
+int iommu_dev_enable_feature(struct device *dev, enum iommu_dev_features feat)
+{
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
+
+	if (ops && ops->dev_enable_feat)
+		return ops->dev_enable_feat(dev, feat);
+
+	return -ENODEV;
+}
+EXPORT_SYMBOL_GPL(iommu_dev_enable_feature);
+
+/*
+ * The device drivers should do the necessary cleanups before calling this.
+ * For example, before disabling the aux-domain feature, the device driver
+ * should detach all aux-domains. Otherwise, this will return -EBUSY.
+ */
+int iommu_dev_disable_feature(struct device *dev, enum iommu_dev_features feat)
+{
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
+
+	if (ops && ops->dev_disable_feat)
+		return ops->dev_disable_feat(dev, feat);
+
+	return -EBUSY;
+}
+EXPORT_SYMBOL_GPL(iommu_dev_disable_feature);
+
+bool iommu_dev_feature_enabled(struct device *dev, enum iommu_dev_features feat)
+{
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
+
+	if (ops && ops->dev_feat_enabled)
+		return ops->dev_feat_enabled(dev, feat);
+
+	return false;
+}
+EXPORT_SYMBOL_GPL(iommu_dev_feature_enabled);
+
+/*
+ * Aux-domain specific attach/detach.
+ *
+ * Only works if iommu_dev_feature_enabled(dev, IOMMU_DEV_FEAT_AUX) returns
+ * true. Also, as long as domains are attached to a device through this
+ * interface, any tries to call iommu_attach_device() should fail
+ * (iommu_detach_device() can't fail, so we fail when trying to re-attach).
+ * This should make us safe against a device being attached to a guest as a
+ * whole while there are still pasid users on it (aux and sva).
+ */
+int iommu_aux_attach_device(struct iommu_domain *domain, struct device *dev)
+{
+	int ret = -ENODEV;
+
+	if (domain->ops->aux_attach_dev)
+		ret = domain->ops->aux_attach_dev(domain, dev);
+
+	if (!ret)
+		trace_attach_device_to_domain(dev);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(iommu_aux_attach_device);
+
+void iommu_aux_detach_device(struct iommu_domain *domain, struct device *dev)
+{
+	if (domain->ops->aux_detach_dev) {
+		domain->ops->aux_detach_dev(domain, dev);
+		trace_detach_device_from_domain(dev);
+	}
+}
+EXPORT_SYMBOL_GPL(iommu_aux_detach_device);
+
+int iommu_aux_get_pasid(struct iommu_domain *domain, struct device *dev)
+{
+	int ret = -ENODEV;
+
+	if (domain->ops->aux_get_pasid)
+		ret = domain->ops->aux_get_pasid(domain, dev);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(iommu_aux_get_pasid);

commit 8cec63e52966b6c1242f8323535532d791d440e8
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Wed Mar 20 09:40:24 2019 +0800

    iommu: Remove iommu_callback_data
    
    The iommu_callback_data is not used anywhere, remove it to make
    the code more concise.
    
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 33a982e33716..1164b9926a2b 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -45,10 +45,6 @@ static unsigned int iommu_def_domain_type = IOMMU_DOMAIN_DMA;
 #endif
 static bool iommu_dma_strict __read_mostly = true;
 
-struct iommu_callback_data {
-	const struct iommu_ops *ops;
-};
-
 struct iommu_group {
 	struct kobject kobj;
 	struct kobject *devices_kobj;
@@ -1215,9 +1211,6 @@ static int iommu_bus_init(struct bus_type *bus, const struct iommu_ops *ops)
 {
 	int err;
 	struct notifier_block *nb;
-	struct iommu_callback_data cb = {
-		.ops = ops,
-	};
 
 	nb = kzalloc(sizeof(struct notifier_block), GFP_KERNEL);
 	if (!nb)
@@ -1229,7 +1222,7 @@ static int iommu_bus_init(struct bus_type *bus, const struct iommu_ops *ops)
 	if (err)
 		goto out_free;
 
-	err = bus_for_each_dev(bus, NULL, &cb, add_iommu_group);
+	err = bus_for_each_dev(bus, NULL, NULL, add_iommu_group);
 	if (err)
 		goto out_err;
 
@@ -1238,7 +1231,7 @@ static int iommu_bus_init(struct bus_type *bus, const struct iommu_ops *ops)
 
 out_err:
 	/* Clean up */
-	bus_for_each_dev(bus, NULL, &cb, remove_iommu_group);
+	bus_for_each_dev(bus, NULL, NULL, remove_iommu_group);
 	bus_unregister_notifier(bus, nb);
 
 out_free:

commit 8bc32a285660e13fdcf92ddaf5b8653abe112040
Author: Joerg Roedel <jroedel@suse.de>
Date:   Fri Mar 22 16:52:17 2019 +0100

    iommu: Don't print warning when IOMMU driver only supports unmanaged domains
    
    Print the warning about the fall-back to IOMMU_DOMAIN_DMA in
    iommu_group_get_for_dev() only when such a domain was
    actually allocated.
    
    Otherwise the user will get misleading warnings in the
    kernel log when the iommu driver used doesn't support
    IOMMU_DOMAIN_DMA and IOMMU_DOMAIN_IDENTITY.
    
    Fixes: fccb4e3b8ab09 ('iommu: Allow default domain type to be set on the kernel command line')
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 33a982e33716..109de67d5d72 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1105,10 +1105,12 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 
 		dom = __iommu_domain_alloc(dev->bus, iommu_def_domain_type);
 		if (!dom && iommu_def_domain_type != IOMMU_DOMAIN_DMA) {
-			dev_warn(dev,
-				 "failed to allocate default IOMMU domain of type %u; falling back to IOMMU_DOMAIN_DMA",
-				 iommu_def_domain_type);
 			dom = __iommu_domain_alloc(dev->bus, IOMMU_DOMAIN_DMA);
+			if (dom) {
+				dev_warn(dev,
+					 "failed to allocate default IOMMU domain of type %u; falling back to IOMMU_DOMAIN_DMA",
+					 iommu_def_domain_type);
+			}
 		}
 
 		group->default_domain = dom;

commit d05e4c8600c36084ce9de6249bb972c9bdd75b7e
Merge: cffaaf0c8162 ba93c357229f 707223095ccf a947a45f0529 48739afaac2a 5f226da1b1d7 32d5860a9e3c 18b3af4492a0
Author: Joerg Roedel <jroedel@suse.de>
Date:   Fri Mar 1 11:24:51 2019 +0100

    Merge branches 'iommu/fixes', 'arm/msm', 'arm/tegra', 'arm/mediatek', 'x86/vt-d', 'x86/amd', 'hyper-v' and 'core' into next

commit 780da9e4f5bf35d348b290f0f97de9b55670cb5b
Author: Bjorn Helgaas <bhelgaas@google.com>
Date:   Fri Feb 8 16:05:45 2019 -0600

    iommu: Use dev_printk() when possible
    
    Use dev_printk() when possible so the IOMMU messages are more consistent
    with other messages related to the device.
    
    E.g., I think these messages related to surprise hotplug:
    
      pciehp 0000:80:10.0:pcie004: Slot(36): Link Down
      iommu: Removing device 0000:87:00.0 from group 12
      pciehp 0000:80:10.0:pcie004: Slot(36): Card present
      pcieport 0000:80:10.0: Data Link Layer Link Active not set in 1000 msec
    
    would be easier to read as these (also requires some PCI changes not
    included here):
    
      pci 0000:80:10.0: Slot(36): Link Down
      pci 0000:87:00.0: Removing from iommu group 12
      pci 0000:80:10.0: Slot(36): Card present
      pci 0000:80:10.0: Data Link Layer Link Active not set in 1000 msec
    
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 3ed4db334341..54c9d18fe31d 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -668,7 +668,7 @@ int iommu_group_add_device(struct iommu_group *group, struct device *dev)
 
 	trace_add_device_to_group(group->id, dev);
 
-	pr_info("Adding device %s to group %d\n", dev_name(dev), group->id);
+	dev_info(dev, "Adding to iommu group %d\n", group->id);
 
 	return 0;
 
@@ -684,7 +684,7 @@ int iommu_group_add_device(struct iommu_group *group, struct device *dev)
 	sysfs_remove_link(&dev->kobj, "iommu_group");
 err_free_device:
 	kfree(device);
-	pr_err("Failed to add device %s to group %d: %d\n", dev_name(dev), group->id, ret);
+	dev_err(dev, "Failed to add to iommu group %d: %d\n", group->id, ret);
 	return ret;
 }
 EXPORT_SYMBOL_GPL(iommu_group_add_device);
@@ -701,7 +701,7 @@ void iommu_group_remove_device(struct device *dev)
 	struct iommu_group *group = dev->iommu_group;
 	struct group_device *tmp_device, *device = NULL;
 
-	pr_info("Removing device %s from group %d\n", dev_name(dev), group->id);
+	dev_info(dev, "Removing from iommu group %d\n", group->id);
 
 	/* Pre-notify listeners that a device is being removed. */
 	blocking_notifier_call_chain(&group->notifier,
@@ -1951,7 +1951,7 @@ int iommu_request_dm_for_dev(struct device *dev)
 		iommu_domain_free(group->default_domain);
 	group->default_domain = dm_domain;
 
-	pr_info("Using direct mapping for device %s\n", dev_name(dev));
+	dev_info(dev, "Using iommu direct mapping\n");
 
 	ret = 0;
 out:

commit 1d7ae53b152dbc5ba0a4f6a83ecc42ac66f52d11
Author: Dmitry Osipenko <digetx@gmail.com>
Date:   Wed Dec 12 23:38:47 2018 +0300

    iommu: Introduce iotlb_sync_map callback
    
    Introduce iotlb_sync_map() callback that is invoked in the end of
    iommu_map(). This new callback allows IOMMU drivers to avoid syncing
    after mapping of each contiguous chunk and sync only when the whole
    mapping is completed, optimizing performance of the mapping operation.
    
    Signed-off-by: Dmitry Osipenko <digetx@gmail.com>
    Reviewed-by: Robin Murphy <robin.murphy@arm.com>
    Reviewed-by: Thierry Reding <treding@nvidia.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 3ed4db334341..ed0e63f2cd9b 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1585,13 +1585,14 @@ static size_t iommu_pgsize(struct iommu_domain *domain,
 int iommu_map(struct iommu_domain *domain, unsigned long iova,
 	      phys_addr_t paddr, size_t size, int prot)
 {
+	const struct iommu_ops *ops = domain->ops;
 	unsigned long orig_iova = iova;
 	unsigned int min_pagesz;
 	size_t orig_size = size;
 	phys_addr_t orig_paddr = paddr;
 	int ret = 0;
 
-	if (unlikely(domain->ops->map == NULL ||
+	if (unlikely(ops->map == NULL ||
 		     domain->pgsize_bitmap == 0UL))
 		return -ENODEV;
 
@@ -1620,7 +1621,7 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 		pr_debug("mapping: iova 0x%lx pa %pa pgsize 0x%zx\n",
 			 iova, &paddr, pgsize);
 
-		ret = domain->ops->map(domain, iova, paddr, pgsize, prot);
+		ret = ops->map(domain, iova, paddr, pgsize, prot);
 		if (ret)
 			break;
 
@@ -1629,6 +1630,9 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 		size -= pgsize;
 	}
 
+	if (ops->iotlb_sync_map)
+		ops->iotlb_sync_map(domain);
+
 	/* unroll mapping in case something went wrong */
 	if (ret)
 		iommu_unmap(domain, orig_iova, orig_size - size);

commit dc9de8a2b20f495696330d60a289935f36407995
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu Dec 20 10:02:20 2018 +0100

    iommu: Check for iommu_ops == NULL in iommu_probe_device()
    
    This check needs to be there and got lost at some point
    during development. Add it again.
    
    Fixes: 641fb0efbff0 ('iommu/of: Don't call iommu_ops->add_device directly')
    Reported-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Reported-by: kernelci.org bot <bot@kernelci.org>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index a2131751dcff..3ed4db334341 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -114,10 +114,14 @@ void iommu_device_unregister(struct iommu_device *iommu)
 int iommu_probe_device(struct device *dev)
 {
 	const struct iommu_ops *ops = dev->bus->iommu_ops;
+	int ret = -EINVAL;
 
 	WARN_ON(dev->iommu_group);
 
-	return ops->add_device(dev);
+	if (ops)
+		ret = ops->add_device(dev);
+
+	return ret;
 }
 
 void iommu_release_device(struct device *dev)

commit cc5aed44a3a8e4fca721636cf881a52f8d68a098
Author: Joerg Roedel <jroedel@suse.de>
Date:   Fri Nov 30 10:31:59 2018 +0100

    iommu: Consolitate ->add/remove_device() calls
    
    Put them into separate functions and call those where the
    plain ops have been called before.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 304c067a0f85..a2131751dcff 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -111,6 +111,23 @@ void iommu_device_unregister(struct iommu_device *iommu)
 	spin_unlock(&iommu_device_lock);
 }
 
+int iommu_probe_device(struct device *dev)
+{
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
+
+	WARN_ON(dev->iommu_group);
+
+	return ops->add_device(dev);
+}
+
+void iommu_release_device(struct device *dev)
+{
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
+
+	if (dev->iommu_group)
+		ops->remove_device(dev);
+}
+
 static struct iommu_domain *__iommu_domain_alloc(struct bus_type *bus,
 						 unsigned type);
 static int __iommu_attach_device(struct iommu_domain *domain,
@@ -1118,16 +1135,7 @@ struct iommu_domain *iommu_group_default_domain(struct iommu_group *group)
 
 static int add_iommu_group(struct device *dev, void *data)
 {
-	struct iommu_callback_data *cb = data;
-	const struct iommu_ops *ops = cb->ops;
-	int ret;
-
-	if (!ops->add_device)
-		return 0;
-
-	WARN_ON(dev->iommu_group);
-
-	ret = ops->add_device(dev);
+	int ret = iommu_probe_device(dev);
 
 	/*
 	 * We ignore -ENODEV errors for now, as they just mean that the
@@ -1142,11 +1150,7 @@ static int add_iommu_group(struct device *dev, void *data)
 
 static int remove_iommu_group(struct device *dev, void *data)
 {
-	struct iommu_callback_data *cb = data;
-	const struct iommu_ops *ops = cb->ops;
-
-	if (ops->remove_device && dev->iommu_group)
-		ops->remove_device(dev);
+	iommu_release_device(dev);
 
 	return 0;
 }
@@ -1154,27 +1158,22 @@ static int remove_iommu_group(struct device *dev, void *data)
 static int iommu_bus_notifier(struct notifier_block *nb,
 			      unsigned long action, void *data)
 {
+	unsigned long group_action = 0;
 	struct device *dev = data;
-	const struct iommu_ops *ops = dev->bus->iommu_ops;
 	struct iommu_group *group;
-	unsigned long group_action = 0;
 
 	/*
 	 * ADD/DEL call into iommu driver ops if provided, which may
 	 * result in ADD/DEL notifiers to group->notifier
 	 */
 	if (action == BUS_NOTIFY_ADD_DEVICE) {
-		if (ops->add_device) {
-			int ret;
+		int ret;
 
-			ret = ops->add_device(dev);
-			return (ret) ? NOTIFY_DONE : NOTIFY_OK;
-		}
+		ret = iommu_probe_device(dev);
+		return (ret) ? NOTIFY_DONE : NOTIFY_OK;
 	} else if (action == BUS_NOTIFY_REMOVED_DEVICE) {
-		if (ops->remove_device && dev->iommu_group) {
-			ops->remove_device(dev);
-			return 0;
-		}
+		iommu_release_device(dev);
+		return NOTIFY_OK;
 	}
 
 	/*

commit b4ef725eeba158f365da9de1f05149094643ddea
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Nov 28 13:35:24 2018 +0100

    iommu: Introduce wrappers around dev->iommu_fwspec
    
    These wrappers will be used to easily change the location of
    the field later when all users are converted.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index cc25ec6d4c06..304c067a0f85 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1976,7 +1976,7 @@ const struct iommu_ops *iommu_ops_from_fwnode(struct fwnode_handle *fwnode)
 int iommu_fwspec_init(struct device *dev, struct fwnode_handle *iommu_fwnode,
 		      const struct iommu_ops *ops)
 {
-	struct iommu_fwspec *fwspec = dev->iommu_fwspec;
+	struct iommu_fwspec *fwspec = dev_iommu_fwspec_get(dev);
 
 	if (fwspec)
 		return ops == fwspec->ops ? 0 : -EINVAL;
@@ -1988,26 +1988,26 @@ int iommu_fwspec_init(struct device *dev, struct fwnode_handle *iommu_fwnode,
 	of_node_get(to_of_node(iommu_fwnode));
 	fwspec->iommu_fwnode = iommu_fwnode;
 	fwspec->ops = ops;
-	dev->iommu_fwspec = fwspec;
+	dev_iommu_fwspec_set(dev, fwspec);
 	return 0;
 }
 EXPORT_SYMBOL_GPL(iommu_fwspec_init);
 
 void iommu_fwspec_free(struct device *dev)
 {
-	struct iommu_fwspec *fwspec = dev->iommu_fwspec;
+	struct iommu_fwspec *fwspec = dev_iommu_fwspec_get(dev);
 
 	if (fwspec) {
 		fwnode_handle_put(fwspec->iommu_fwnode);
 		kfree(fwspec);
-		dev->iommu_fwspec = NULL;
+		dev_iommu_fwspec_set(dev, NULL);
 	}
 }
 EXPORT_SYMBOL_GPL(iommu_fwspec_free);
 
 int iommu_fwspec_add_ids(struct device *dev, u32 *ids, int num_ids)
 {
-	struct iommu_fwspec *fwspec = dev->iommu_fwspec;
+	struct iommu_fwspec *fwspec = dev_iommu_fwspec_get(dev);
 	size_t size;
 	int i;
 
@@ -2016,11 +2016,11 @@ int iommu_fwspec_add_ids(struct device *dev, u32 *ids, int num_ids)
 
 	size = offsetof(struct iommu_fwspec, ids[fwspec->num_ids + num_ids]);
 	if (size > sizeof(*fwspec)) {
-		fwspec = krealloc(dev->iommu_fwspec, size, GFP_KERNEL);
+		fwspec = krealloc(fwspec, size, GFP_KERNEL);
 		if (!fwspec)
 			return -ENOMEM;
 
-		dev->iommu_fwspec = fwspec;
+		dev_iommu_fwspec_set(dev, fwspec);
 	}
 
 	for (i = 0; i < num_ids; i++)

commit c1af7b4013e86bcfd4e1e8f0eeb7ae914ca7e819
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Sat Dec 1 14:19:09 2018 -0500

    iommu: Audit and remove any unnecessary uses of module.h
    
    Historically a lot of these existed because we did not have
    a distinction between what was modular code and what was providing
    support to modules via EXPORT_SYMBOL and friends.  That changed
    when we forked out support for the latter into the export.h file.
    This means we should be able to reduce the usage of module.h
    in code that is obj-y Makefile or bool Kconfig.
    
    The advantage in removing such instances is that module.h itself
    sources about 15 other headers; adding significantly to what we feed
    cpp, and it can obscure what headers we are effectively using.
    
    Since module.h might have been the implicit source for init.h
    (for __init) and for export.h (for EXPORT_SYMBOL) we consider each
    instance for the presence of either and replace as needed.
    
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: iommu@lists.linux-foundation.org
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index f8ec49e0f6c6..cc25ec6d4c06 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -22,7 +22,8 @@
 #include <linux/kernel.h>
 #include <linux/bug.h>
 #include <linux/types.h>
-#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/export.h>
 #include <linux/slab.h>
 #include <linux/errno.h>
 #include <linux/iommu.h>

commit 5d95f40e62e4f2ed3053e9b178471669736cf636
Author: Robin Murphy <robin.murphy@arm.com>
Date:   Thu Oct 11 16:56:42 2018 +0100

    iommu: Do physical merging in iommu_map_sg()
    
    The original motivation for iommu_map_sg() was to give IOMMU drivers the
    chance to map an IOVA-contiguous scatterlist as efficiently as they
    could. It turns out that there isn't really much driver-specific
    business involved there, so now that the default implementation is
    mandatory let's just improve that - the main thing we're after is to use
    larger pages wherever possible, and as long as domain->pgsize_bitmap
    reflects reality, iommu_map() can already do that in a generic way. All
    we need to do is detect physically-contiguous segments and batch them
    into a single map operation, since whatever we do here is transparent to
    our caller and not bound by any segment-length restrictions on the list
    itself.
    
    Speaking of efficiency, there's really very little point in duplicating
    the checks that iommu_map() is going to do anyway, so those get cleared
    up in the process.
    
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index edbdf5d6962c..f8ec49e0f6c6 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1712,33 +1712,32 @@ EXPORT_SYMBOL_GPL(iommu_unmap_fast);
 size_t iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
 		    struct scatterlist *sg, unsigned int nents, int prot)
 {
-	struct scatterlist *s;
-	size_t mapped = 0;
-	unsigned int i, min_pagesz;
+	size_t len = 0, mapped = 0;
+	phys_addr_t start;
+	unsigned int i = 0;
 	int ret;
 
-	if (unlikely(domain->pgsize_bitmap == 0UL))
-		return 0;
-
-	min_pagesz = 1 << __ffs(domain->pgsize_bitmap);
+	while (i <= nents) {
+		phys_addr_t s_phys = sg_phys(sg);
 
-	for_each_sg(sg, s, nents, i) {
-		phys_addr_t phys = page_to_phys(sg_page(s)) + s->offset;
+		if (len && s_phys != start + len) {
+			ret = iommu_map(domain, iova + mapped, start, len, prot);
+			if (ret)
+				goto out_err;
 
-		/*
-		 * We are mapping on IOMMU page boundaries, so offset within
-		 * the page must be 0. However, the IOMMU may support pages
-		 * smaller than PAGE_SIZE, so s->offset may still represent
-		 * an offset of that boundary within the CPU page.
-		 */
-		if (!IS_ALIGNED(s->offset, min_pagesz))
-			goto out_err;
+			mapped += len;
+			len = 0;
+		}
 
-		ret = iommu_map(domain, iova + mapped, phys, s->length, prot);
-		if (ret)
-			goto out_err;
+		if (len) {
+			len += sg->length;
+		} else {
+			len = sg->length;
+			start = s_phys;
+		}
 
-		mapped += s->length;
+		if (++i < nents)
+			sg = sg_next(sg);
 	}
 
 	return mapped;

commit 2f2fbfb71ecc221352d84ae6430b42031ae5b654
Merge: 0238df646e62 a089845b3ed2 5e731073bc0a bc46c229b6af 18f99c9b9dec e84b7cc457f9 35449adce847
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Oct 10 18:09:37 2018 +0200

    Merge branches 'arm/renesas', 'arm/smmu', 'ppc/pamu', 'x86/vt-d', 'x86/amd' and 'core' into next

commit 68a6efe86f6a16e25556a2aff40efad41097b486
Author: Zhen Lei <thunder.leizhen@huawei.com>
Date:   Thu Sep 20 17:10:23 2018 +0100

    iommu: Add "iommu.strict" command line option
    
    Add a generic command line option to enable lazy unmapping via IOVA
    flush queues, which will initally be suuported by iommu-dma. This echoes
    the semantics of "intel_iommu=strict" (albeit with the opposite default
    value), but in the driver-agnostic fashion of "iommu.passthrough".
    
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    [rm: move handling out of SMMUv3 driver, clean up documentation]
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    [will: dropped broken printk when parsing command-line option]
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 8c15c5980299..2b6dad2aa9f1 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -41,6 +41,7 @@ static unsigned int iommu_def_domain_type = IOMMU_DOMAIN_IDENTITY;
 #else
 static unsigned int iommu_def_domain_type = IOMMU_DOMAIN_DMA;
 #endif
+static bool iommu_dma_strict __read_mostly = true;
 
 struct iommu_callback_data {
 	const struct iommu_ops *ops;
@@ -131,6 +132,12 @@ static int __init iommu_set_def_domain_type(char *str)
 }
 early_param("iommu.passthrough", iommu_set_def_domain_type);
 
+static int __init iommu_dma_setup(char *str)
+{
+	return kstrtobool(str, &iommu_dma_strict);
+}
+early_param("iommu.strict", iommu_dma_setup);
+
 static ssize_t iommu_group_attr_show(struct kobject *kobj,
 				     struct attribute *__attr, char *buf)
 {
@@ -1072,6 +1079,13 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 		group->default_domain = dom;
 		if (!group->domain)
 			group->domain = dom;
+
+		if (dom && !iommu_dma_strict) {
+			int attr = 1;
+			iommu_domain_set_attr(dom,
+					      DOMAIN_ATTR_DMA_USE_FLUSH_QUEUE,
+					      &attr);
+		}
 	}
 
 	ret = iommu_group_add_device(group, dev);

commit 35449adce847400ca8af25702be112fd67f42439
Author: Rami Rosen <ramirose@gmail.com>
Date:   Tue Sep 18 17:38:49 2018 +0300

    iommu: Fix a typo
    
    This patch fixes a typo in iommu.c.
    
    Signed-off-by: Rami Rosen <ramirose@gmail.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index e9b50abc02a4..8b024b1f60c9 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1425,7 +1425,7 @@ struct iommu_domain *iommu_get_dma_domain(struct device *dev)
 }
 
 /*
- * IOMMU groups are really the natrual working unit of the IOMMU, but
+ * IOMMU groups are really the natural working unit of the IOMMU, but
  * the IOMMU API works on domains and devices.  Bridge that gap by
  * iterating over the devices in a group.  Ideally we'd have a single
  * device which represents the requestor ID of the group, but we also

commit 701d8a624a2d5aa7d7efd38800c7c6ab4a4c453c
Author: Robin Murphy <robin.murphy@arm.com>
Date:   Wed Sep 19 11:12:57 2018 +0100

    iommu: Tidy up window attributes
    
    The external interface to get/set window attributes is already
    abstracted behind iommu_domain_{get,set}_attr(), so there's no real
    reason for the internal interface to be different. Since we only have
    one window-based driver anyway, clean up the core code by just moving
    the DOMAIN_ATTR_WINDOWS handling directly into the PAMU driver.
    
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 9d70344204fe..e9b50abc02a4 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1805,7 +1805,6 @@ int iommu_domain_get_attr(struct iommu_domain *domain,
 	struct iommu_domain_geometry *geometry;
 	bool *paging;
 	int ret = 0;
-	u32 *count;
 
 	switch (attr) {
 	case DOMAIN_ATTR_GEOMETRY:
@@ -1816,15 +1815,6 @@ int iommu_domain_get_attr(struct iommu_domain *domain,
 	case DOMAIN_ATTR_PAGING:
 		paging  = data;
 		*paging = (domain->pgsize_bitmap != 0UL);
-		break;
-	case DOMAIN_ATTR_WINDOWS:
-		count = data;
-
-		if (domain->ops->domain_get_windows != NULL)
-			*count = domain->ops->domain_get_windows(domain);
-		else
-			ret = -ENODEV;
-
 		break;
 	default:
 		if (!domain->ops->domain_get_attr)
@@ -1841,18 +1831,8 @@ int iommu_domain_set_attr(struct iommu_domain *domain,
 			  enum iommu_attr attr, void *data)
 {
 	int ret = 0;
-	u32 *count;
 
 	switch (attr) {
-	case DOMAIN_ATTR_WINDOWS:
-		count = data;
-
-		if (domain->ops->domain_set_windows != NULL)
-			ret = domain->ops->domain_set_windows(domain, *count);
-		else
-			ret = -ENODEV;
-
-		break;
 	default:
 		if (domain->ops->domain_set_attr == NULL)
 			return -EINVAL;

commit 6af588fed39178c8e118fcf9cb6664e58a1fbe88
Author: Robin Murphy <robin.murphy@arm.com>
Date:   Wed Sep 12 16:24:12 2018 +0100

    iommu: Add fast hook for getting DMA domains
    
    While iommu_get_domain_for_dev() is the robust way for arbitrary IOMMU
    API callers to retrieve the domain pointer, for DMA ops domains it
    doesn't scale well for large systems and multi-queue devices, since the
    momentary refcount adjustment will lead to exclusive cacheline contention
    when multiple CPUs are operating in parallel on different mappings for
    the same device.
    
    In the case of DMA ops domains, however, this refcounting is actually
    unnecessary, since they already imply that the group exists and is
    managed by platform code and IOMMU internals (by virtue of
    iommu_group_get_for_dev()) such that a reference will already be held
    for the lifetime of the device. Thus we can avoid the bottleneck by
    providing a fast lookup specifically for the DMA code to retrieve the
    default domain it already knows it has set up - a simple read-only
    dereference plays much nicer with cache-coherency protocols.
    
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Tested-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 8c15c5980299..9d70344204fe 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1415,6 +1415,15 @@ struct iommu_domain *iommu_get_domain_for_dev(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(iommu_get_domain_for_dev);
 
+/*
+ * For IOMMU_DOMAIN_DMA implementations which already provide their own
+ * guarantees that the group and its default domain are valid and correct.
+ */
+struct iommu_domain *iommu_get_dma_domain(struct device *dev)
+{
+	return dev->iommu_group->default_domain;
+}
+
 /*
  * IOMMU groups are really the natrual working unit of the IOMMU, but
  * the IOMMU API works on domains and devices.  Bridge that gap by

commit eab03e2a1a3d9d354943aff5ae5e4254ee1ec967
Author: Nipun Gupta <nipun.gupta@nxp.com>
Date:   Mon Sep 10 19:19:18 2018 +0530

    iommu/arm-smmu: Add support for the fsl-mc bus
    
    Implement bus specific support for the fsl-mc bus including
    registering arm_smmu_ops and bus specific device add operations.
    
    Signed-off-by: Nipun Gupta <nipun.gupta@nxp.com>
    Reviewed-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 8c15c5980299..7e5cb7cf2bbe 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -32,6 +32,7 @@
 #include <linux/pci.h>
 #include <linux/bitops.h>
 #include <linux/property.h>
+#include <linux/fsl/mc.h>
 #include <trace/events/iommu.h>
 
 static struct kset *iommu_group_kset;
@@ -1024,6 +1025,18 @@ struct iommu_group *pci_device_group(struct device *dev)
 	return iommu_group_alloc();
 }
 
+/* Get the IOMMU group for device on fsl-mc bus */
+struct iommu_group *fsl_mc_device_group(struct device *dev)
+{
+	struct device *cont_dev = fsl_mc_cont_dev(dev);
+	struct iommu_group *group;
+
+	group = iommu_group_get(cont_dev);
+	if (!group)
+		group = iommu_group_alloc();
+	return group;
+}
+
 /**
  * iommu_group_get_for_dev - Find or create the IOMMU group for a device
  * @dev: target device

commit d88e61faad526a5850e9330c846641b91cf971e7
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jul 30 09:36:26 2018 +0200

    iommu: Remove the ->map_sg indirection
    
    All iommu drivers use the default_iommu_map_sg implementation, and there
    is no good reason to ever override it.  Just expose it as iommu_map_sg
    directly and remove the indirection, specially in our post-spectre world
    where indirect calls are horribly expensive.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index f3698006cb53..8c15c5980299 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1673,8 +1673,8 @@ size_t iommu_unmap_fast(struct iommu_domain *domain,
 }
 EXPORT_SYMBOL_GPL(iommu_unmap_fast);
 
-size_t default_iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
-			 struct scatterlist *sg, unsigned int nents, int prot)
+size_t iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
+		    struct scatterlist *sg, unsigned int nents, int prot)
 {
 	struct scatterlist *s;
 	size_t mapped = 0;
@@ -1714,7 +1714,7 @@ size_t default_iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
 	return 0;
 
 }
-EXPORT_SYMBOL_GPL(default_iommu_map_sg);
+EXPORT_SYMBOL_GPL(iommu_map_sg);
 
 int iommu_domain_window_enable(struct iommu_domain *domain, u32 wnd_nr,
 			       phys_addr_t paddr, u64 size, int prot)

commit 58d1131777a4b7c228267b809bd88f7be66edcfb
Author: Olof Johansson <olof@lixom.net>
Date:   Fri Jul 20 11:02:23 2018 -0700

    iommu: Add config option to set passthrough as default
    
    This allows the default behavior to be controlled by a kernel config
    option instead of changing the commandline for the kernel to include
    "iommu.passthrough=on" or "iommu=pt" on machines where this is desired.
    
    Likewise, for machines where this config option is enabled, it can be
    disabled at boot time with "iommu.passthrough=off" or "iommu=nopt".
    
    Also corrected iommu=pt documentation for IA-64, since it has no code that
    parses iommu= at all.
    
    Signed-off-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 7f50013b0bcf..f3698006cb53 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -36,7 +36,11 @@
 
 static struct kset *iommu_group_kset;
 static DEFINE_IDA(iommu_group_ida);
+#ifdef CONFIG_IOMMU_DEFAULT_PASSTHROUGH
+static unsigned int iommu_def_domain_type = IOMMU_DOMAIN_IDENTITY;
+#else
 static unsigned int iommu_def_domain_type = IOMMU_DOMAIN_DMA;
+#endif
 
 struct iommu_callback_data {
 	const struct iommu_ops *ops;

commit c52c72d3dee81af893cee0414444818ed91e2e11
Author: Olof Johansson <olof@lixom.net>
Date:   Wed Jul 11 13:59:36 2018 -0700

    iommu: Add sysfs attribyte for domain type
    
    While we could print it at setup time, this is an easier way to match
    each device to their default IOMMU allocation type.
    
    Signed-off-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index d227b864a109..7f50013b0bcf 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -294,11 +294,39 @@ static ssize_t iommu_group_show_resv_regions(struct iommu_group *group,
 	return (str - buf);
 }
 
+static ssize_t iommu_group_show_type(struct iommu_group *group,
+				     char *buf)
+{
+	char *type = "unknown\n";
+
+	if (group->default_domain) {
+		switch (group->default_domain->type) {
+		case IOMMU_DOMAIN_BLOCKED:
+			type = "blocked\n";
+			break;
+		case IOMMU_DOMAIN_IDENTITY:
+			type = "identity\n";
+			break;
+		case IOMMU_DOMAIN_UNMANAGED:
+			type = "unmanaged\n";
+			break;
+		case IOMMU_DOMAIN_DMA:
+			type = "DMA";
+			break;
+		}
+	}
+	strcpy(buf, type);
+
+	return strlen(type);
+}
+
 static IOMMU_GROUP_ATTR(name, S_IRUGO, iommu_group_show_name, NULL);
 
 static IOMMU_GROUP_ATTR(reserved_regions, 0444,
 			iommu_group_show_resv_regions, NULL);
 
+static IOMMU_GROUP_ATTR(type, 0444, iommu_group_show_type, NULL);
+
 static void iommu_group_release(struct kobject *kobj)
 {
 	struct iommu_group *group = to_iommu_group(kobj);
@@ -380,6 +408,10 @@ struct iommu_group *iommu_group_alloc(void)
 	if (ret)
 		return ERR_PTR(ret);
 
+	ret = iommu_group_create_file(group, &iommu_group_attr_type);
+	if (ret)
+		return ERR_PTR(ret);
+
 	pr_debug("Allocated group %d\n", group->id);
 
 	return group;

commit bad614b24293ae463e74d2465685f0e4e229baca
Author: Gary R Hook <gary.hook@amd.com>
Date:   Tue Jun 12 16:41:21 2018 -0500

    iommu: Enable debugfs exposure of IOMMU driver internals
    
    Provide base enablement for using debugfs to expose internal data of an
    IOMMU driver. When called, create the /sys/kernel/debug/iommu directory.
    
    Emit a strong warning at boot time to indicate that this feature is
    enabled.
    
    This function is called from iommu_init, and creates the initial DebugFS
    directory. Drivers may then call iommu_debugfs_new_driver_dir() to
    instantiate a device-specific directory to expose internal data.
    It will return a pointer to the new dentry structure created in
    /sys/kernel/debug/iommu, or NULL in the event of a failure.
    
    Since the IOMMU driver can not be removed from the running system, there
    is no need for an "off" function.
    
    Signed-off-by: Gary R Hook <gary.hook@amd.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 63b37563db7e..d227b864a109 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1748,6 +1748,8 @@ static int __init iommu_init(void)
 					       NULL, kernel_kobj);
 	BUG_ON(!iommu_group_kset);
 
+	iommu_debugfs_setup();
+
 	return 0;
 }
 core_initcall(iommu_init);

commit 1eefe5a034e3b9104f129ae4e8632838b8702a41
Author: Lu Baolu <baolu.lu@linux.intel.com>
Date:   Fri May 4 13:08:16 2018 +0800

    iommu: Clean up the comments for iommu_group_alloc
    
    @name parameter has been removed.
    
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 7f61b142263e..63b37563db7e 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -324,7 +324,6 @@ static struct kobj_type iommu_group_ktype = {
 
 /**
  * iommu_group_alloc - Allocate a new group
- * @name: Optional name to associate with group, visible in sysfs
  *
  * This function is called by an iommu driver to allocate a new iommu
  * group.  The iommu group represents the minimum granularity of the iommu.

commit 7f9584df8495787393d8c18598c2b6eb03e647b0
Author: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Date:   Mon May 14 19:22:25 2018 +0300

    iommu: Remove extra NULL check when call strtobool()
    
    strtobool() does check for NULL parameter already. No need to repeat.
    
    While here, switch to kstrtobool() and unshadow actual error code
    (which is still -EINVAL).
    
    No functional change intended.
    
    Signed-off-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index d2aa23202bb9..7f61b142263e 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -116,9 +116,11 @@ static void __iommu_detach_group(struct iommu_domain *domain,
 static int __init iommu_set_def_domain_type(char *str)
 {
 	bool pt;
+	int ret;
 
-	if (!str || strtobool(str, &pt))
-		return -EINVAL;
+	ret = kstrtobool(str, &pt);
+	if (ret)
+		return ret;
 
 	iommu_def_domain_type = pt ? IOMMU_DOMAIN_IDENTITY : IOMMU_DOMAIN_DMA;
 	return 0;

commit c5611a8751e67595e4e7d3feaff3c900b92094b9
Author: Suravee Suthikulpanit <suravee.suthikulpanit@amd.com>
Date:   Mon Feb 5 05:45:53 2018 -0500

    iommu: Do not return error code for APIs with size_t return type
    
    Currently, iommu_unmap, iommu_unmap_fast and iommu_map_sg return
    size_t.  However, some of the return values are error codes (< 0),
    which can be misinterpreted as large size. Therefore, returning size 0
    instead to signify failure to map/unmap.
    
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Suravee Suthikulpanit <suravee.suthikulpanit@amd.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 69fef991c651..d2aa23202bb9 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1573,10 +1573,10 @@ static size_t __iommu_unmap(struct iommu_domain *domain,
 
 	if (unlikely(ops->unmap == NULL ||
 		     domain->pgsize_bitmap == 0UL))
-		return -ENODEV;
+		return 0;
 
 	if (unlikely(!(domain->type & __IOMMU_DOMAIN_PAGING)))
-		return -EINVAL;
+		return 0;
 
 	/* find out the minimum page size supported */
 	min_pagesz = 1 << __ffs(domain->pgsize_bitmap);
@@ -1589,7 +1589,7 @@ static size_t __iommu_unmap(struct iommu_domain *domain,
 	if (!IS_ALIGNED(iova | size, min_pagesz)) {
 		pr_err("unaligned: iova 0x%lx size 0x%zx min_pagesz 0x%x\n",
 		       iova, size, min_pagesz);
-		return -EINVAL;
+		return 0;
 	}
 
 	pr_debug("unmap this: iova 0x%lx size 0x%zx\n", iova, size);

commit 9ae9df035c274c89b7fe3dbc74cbe2fa63386668
Author: Jordan Crouse <jcrouse@codeaurora.org>
Date:   Wed Dec 20 09:48:36 2017 -0700

    iommu: Check the result of iommu_group_get() for NULL
    
    The result of iommu_group_get() was being blindly used in both
    attach and detach which results in a dereference when trying
    to work with an unknown device.
    
    Signed-off-by: Jordan Crouse <jcrouse@codeaurora.org>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 3de5c0bcb5cc..69fef991c651 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1303,6 +1303,9 @@ int iommu_attach_device(struct iommu_domain *domain, struct device *dev)
 	int ret;
 
 	group = iommu_group_get(dev);
+	if (!group)
+		return -ENODEV;
+
 	/*
 	 * Lock the group to make sure the device-count doesn't
 	 * change while we are attaching
@@ -1341,6 +1344,8 @@ void iommu_detach_device(struct iommu_domain *domain, struct device *dev)
 	struct iommu_group *group;
 
 	group = iommu_group_get(dev);
+	if (!group)
+		return;
 
 	mutex_lock(&group->mutex);
 	if (iommu_group_device_count(group) != 1) {

commit 47b59d8e40850a05370ee9198ea5e505d89489f1
Merge: cc4a41fe5541 0b9a36947c6b 8da4af95867e c3aa47424918 bfee0cf0ee1d 419399804382 96302d89a035 6ce5b0f22d60 af6ee6c1c4db 3ff2dcc05894 5082219b6a61 ec62b1ab0f4c cceb84519520 add02cfdc9bc
Author: Joerg Roedel <jroedel@suse.de>
Date:   Fri Sep 1 11:31:42 2017 +0200

    Merge branches 'arm/exynos', 'arm/renesas', 'arm/rockchip', 'arm/omap', 'arm/mediatek', 'arm/tegra', 'arm/qcom', 'arm/smmu', 'ppc/pamu', 'x86/vt-d', 'x86/amd', 's390' and 'core' into next

commit add02cfdc9bc2987b0121861d5bb0c7392865be9
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Aug 23 15:50:04 2017 +0200

    iommu: Introduce Interface for IOMMU TLB Flushing
    
    With the current IOMMU-API the hardware TLBs have to be
    flushed in every iommu_ops->unmap() call-back.
    
    For unmapping large amounts of address space, like it
    happens when a KVM domain with assigned devices is
    destroyed, this causes thousands of unnecessary TLB flushes
    in the IOMMU hardware because the unmap call-back runs for
    every unmapped physical page.
    
    With the TLB Flush Interface and the new iommu_unmap_fast()
    function introduced here the need to clean the hardware TLBs
    is removed from the unmapping code-path. Users of
    iommu_unmap_fast() have to explicitly call the TLB-Flush
    functions to sync the page-table changes to the hardware.
    
    Three functions for TLB-Flushes are introduced:
    
            * iommu_flush_tlb_all() - Flushes all TLB entries
                                      associated with that
                                      domain. TLBs entries are
                                      flushed when this function
                                      returns.
    
            * iommu_tlb_range_add() - This will add a given
                                      range to the flush queue
                                      for this domain.
    
            * iommu_tlb_sync() - Flushes all queued ranges from
                                 the hardware TLBs. Returns when
                                 the flush is finished.
    
    The semantic of this interface is intentionally similar to
    the iommu_gather_ops from the io-pgtable code.
    
    Cc: Alex Williamson <alex.williamson@redhat.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 5499a0387349..31c2b1dc8cfd 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -527,6 +527,8 @@ static int iommu_group_create_direct_mappings(struct iommu_group *group,
 
 	}
 
+	iommu_flush_tlb_all(domain);
+
 out:
 	iommu_put_resv_regions(dev, &mappings);
 
@@ -1547,13 +1549,16 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 }
 EXPORT_SYMBOL_GPL(iommu_map);
 
-size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
+static size_t __iommu_unmap(struct iommu_domain *domain,
+			    unsigned long iova, size_t size,
+			    bool sync)
 {
+	const struct iommu_ops *ops = domain->ops;
 	size_t unmapped_page, unmapped = 0;
-	unsigned int min_pagesz;
 	unsigned long orig_iova = iova;
+	unsigned int min_pagesz;
 
-	if (unlikely(domain->ops->unmap == NULL ||
+	if (unlikely(ops->unmap == NULL ||
 		     domain->pgsize_bitmap == 0UL))
 		return -ENODEV;
 
@@ -1583,10 +1588,13 @@ size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
 	while (unmapped < size) {
 		size_t pgsize = iommu_pgsize(domain, iova, size - unmapped);
 
-		unmapped_page = domain->ops->unmap(domain, iova, pgsize);
+		unmapped_page = ops->unmap(domain, iova, pgsize);
 		if (!unmapped_page)
 			break;
 
+		if (sync && ops->iotlb_range_add)
+			ops->iotlb_range_add(domain, iova, pgsize);
+
 		pr_debug("unmapped: iova 0x%lx size 0x%zx\n",
 			 iova, unmapped_page);
 
@@ -1594,11 +1602,27 @@ size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
 		unmapped += unmapped_page;
 	}
 
+	if (sync && ops->iotlb_sync)
+		ops->iotlb_sync(domain);
+
 	trace_unmap(orig_iova, size, unmapped);
 	return unmapped;
 }
+
+size_t iommu_unmap(struct iommu_domain *domain,
+		   unsigned long iova, size_t size)
+{
+	return __iommu_unmap(domain, iova, size, true);
+}
 EXPORT_SYMBOL_GPL(iommu_unmap);
 
+size_t iommu_unmap_fast(struct iommu_domain *domain,
+			unsigned long iova, size_t size)
+{
+	return __iommu_unmap(domain, iova, size, false);
+}
+EXPORT_SYMBOL_GPL(iommu_unmap_fast);
+
 size_t default_iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
 			 struct scatterlist *sg, unsigned int nents, int prot)
 {

commit 1464d0b1defe421aef8c8877e19c7ae011e32eb9
Author: Robin Murphy <robin.murphy@arm.com>
Date:   Thu Aug 17 11:40:08 2017 +0100

    iommu: Avoid NULL group dereference
    
    The recently-removed FIXME in iommu_get_domain_for_dev() turns out to
    have been a little misleading, since that check is still worthwhile even
    when groups *are* universal. We have a few IOMMU-aware drivers which
    only care whether their device is already attached to an existing domain
    or not, for which the previous behaviour of iommu_get_domain_for_dev()
    was ideal, and who now crash if their device does not have an IOMMU.
    
    With IOMMU groups now serving as a reliable indicator of whether a
    device has an IOMMU or not (barring false-positives from VFIO no-IOMMU
    mode), drivers could arguably do this:
    
            group = iommu_group_get(dev);
            if (group) {
                    domain = iommu_get_domain_for_dev(dev);
                    iommu_group_put(group);
            }
    
    However, rather than duplicate that code across multiple callsites,
    particularly when it's still only the domain they care about, let's skip
    straight to the next step and factor out the check into the common place
    it applies - in iommu_get_domain_for_dev() itself. Sure, it ends up
    looking rather familiar, but now it's backed by the reasoning of having
    a robust API able to do the expected thing for all devices regardless.
    
    Fixes: 05f80300dc8b ("iommu: Finish making iommu_group support mandatory")
    Reported-by: Shawn Lin <shawn.lin@rock-chips.com>
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index af69bf7e035a..5499a0387349 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1352,6 +1352,8 @@ struct iommu_domain *iommu_get_domain_for_dev(struct device *dev)
 	struct iommu_group *group;
 
 	group = iommu_group_get(dev);
+	if (!group)
+		return NULL;
 
 	domain = group->domain;
 

commit e01d1913b0d0817191418381a6fcebaa01abde2a
Author: Baoquan He <bhe@redhat.com>
Date:   Wed Aug 9 16:33:40 2017 +0800

    iommu: Add is_attach_deferred call-back to iommu-ops
    
    This new call-back will be used to check if the domain attach need be
    deferred for now. If yes, the domain attach/detach will return directly.
    
    Signed-off-by: Baoquan He <bhe@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 3f6ea160afed..86581b115b92 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1283,6 +1283,10 @@ static int __iommu_attach_device(struct iommu_domain *domain,
 				 struct device *dev)
 {
 	int ret;
+	if ((domain->ops->is_attach_deferred != NULL) &&
+	    domain->ops->is_attach_deferred(domain, dev))
+		return 0;
+
 	if (unlikely(domain->ops->attach_dev == NULL))
 		return -ENODEV;
 
@@ -1324,6 +1328,10 @@ EXPORT_SYMBOL_GPL(iommu_attach_device);
 static void __iommu_detach_device(struct iommu_domain *domain,
 				  struct device *dev)
 {
+	if ((domain->ops->is_attach_deferred != NULL) &&
+	    domain->ops->is_attach_deferred(domain, dev))
+		return;
+
 	if (unlikely(domain->ops->detach_dev == NULL))
 		return;
 

commit 05f80300dc8bcfe8566b36256d01482cae5afa02
Author: Robin Murphy <robin.murphy@arm.com>
Date:   Fri Jul 21 13:12:38 2017 +0100

    iommu: Finish making iommu_group support mandatory
    
    Now that all the drivers properly implementing the IOMMU API support
    groups (I'm ignoring the etnaviv GPU MMUs which seemingly only do just
    enough to convince the ARM DMA mapping ops), we can remove the FIXME
    workarounds from the core code. In the process, it also seems logical to
    make the .device_group callback non-optional for drivers calling
    iommu_group_get_for_dev() - the current callers all implement it anyway,
    and it doesn't make sense for any future callers not to either.
    
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 3f6ea160afed..af69bf7e035a 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1005,11 +1005,10 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 	if (group)
 		return group;
 
-	group = ERR_PTR(-EINVAL);
-
-	if (ops && ops->device_group)
-		group = ops->device_group(dev);
+	if (!ops)
+		return ERR_PTR(-EINVAL);
 
+	group = ops->device_group(dev);
 	if (WARN_ON_ONCE(group == NULL))
 		return ERR_PTR(-EINVAL);
 
@@ -1298,12 +1297,8 @@ int iommu_attach_device(struct iommu_domain *domain, struct device *dev)
 	int ret;
 
 	group = iommu_group_get(dev);
-	/* FIXME: Remove this when groups a mandatory for iommu drivers */
-	if (group == NULL)
-		return __iommu_attach_device(domain, dev);
-
 	/*
-	 * We have a group - lock it to make sure the device-count doesn't
+	 * Lock the group to make sure the device-count doesn't
 	 * change while we are attaching
 	 */
 	mutex_lock(&group->mutex);
@@ -1336,9 +1331,6 @@ void iommu_detach_device(struct iommu_domain *domain, struct device *dev)
 	struct iommu_group *group;
 
 	group = iommu_group_get(dev);
-	/* FIXME: Remove this when groups a mandatory for iommu drivers */
-	if (group == NULL)
-		return __iommu_detach_device(domain, dev);
 
 	mutex_lock(&group->mutex);
 	if (iommu_group_device_count(group) != 1) {
@@ -1360,9 +1352,6 @@ struct iommu_domain *iommu_get_domain_for_dev(struct device *dev)
 	struct iommu_group *group;
 
 	group = iommu_group_get(dev);
-	/* FIXME: Remove this when groups a mandatory for iommu drivers */
-	if (group == NULL)
-		return NULL;
 
 	domain = group->domain;
 

commit 72dcac633475a5b331cf21f3525467d0e123395a
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Jun 28 12:52:48 2017 +0200

    iommu: Warn once when device_group callback returns NULL
    
    This callback should never return NULL. Print a warning if
    that happens so that we notice and can fix it.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index de09e1e35830..3f6ea160afed 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1010,6 +1010,9 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 	if (ops && ops->device_group)
 		group = ops->device_group(dev);
 
+	if (WARN_ON_ONCE(group == NULL))
+		return ERR_PTR(-EINVAL);
+
 	if (IS_ERR(group))
 		return group;
 

commit 7f7a2304aabc4a8102bbbbeed2ec9eaee4a480c2
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Jun 28 12:45:31 2017 +0200

    iommu: Return ERR_PTR() values from device_group call-backs
    
    The generic device_group call-backs in iommu.c return NULL
    in case of error. Since they are getting ERR_PTR values from
    iommu_group_alloc(), just pass them up instead.
    
    Reported-by: Gerald Schaefer <gerald.schaefer@de.ibm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index cf7ca7e70777..de09e1e35830 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -915,13 +915,7 @@ static int get_pci_alias_or_group(struct pci_dev *pdev, u16 alias, void *opaque)
  */
 struct iommu_group *generic_device_group(struct device *dev)
 {
-	struct iommu_group *group;
-
-	group = iommu_group_alloc();
-	if (IS_ERR(group))
-		return NULL;
-
-	return group;
+	return iommu_group_alloc();
 }
 
 /*
@@ -988,11 +982,7 @@ struct iommu_group *pci_device_group(struct device *dev)
 		return group;
 
 	/* No shared group found, allocate new */
-	group = iommu_group_alloc();
-	if (IS_ERR(group))
-		return NULL;
-
-	return group;
+	return iommu_group_alloc();
 }
 
 /**

commit 2c0248d68880fc0e783af1048b3367ee5d4412f0
Merge: d5bf739dc762 fd8e2d4b3932 c9d9f2394c6a 6f66ea099fc2 bdf95923086f 26b37b946a5c 8e1218840066 73dbd4a42302 290d638e04e7
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu May 4 18:06:17 2017 +0200

    Merge branches 'arm/exynos', 'arm/omap', 'arm/rockchip', 'arm/mediatek', 'arm/smmu', 'arm/core', 'x86/vt-d', 'x86/amd' and 'core' into next

commit 207c6e36f122ebb1164d611c9f34f128313f47d5
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Apr 26 15:39:28 2017 +0200

    iommu: Move report_iommu_fault() to iommu.c
    
    The function is in no fast-path, there is no need for it to
    be static inline in a header file. This also removes the
    need to include iommu trace-points in iommu.h.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 9170fd498f46..4cb5792cbc21 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1655,6 +1655,48 @@ void iommu_domain_window_disable(struct iommu_domain *domain, u32 wnd_nr)
 }
 EXPORT_SYMBOL_GPL(iommu_domain_window_disable);
 
+/**
+ * report_iommu_fault() - report about an IOMMU fault to the IOMMU framework
+ * @domain: the iommu domain where the fault has happened
+ * @dev: the device where the fault has happened
+ * @iova: the faulting address
+ * @flags: mmu fault flags (e.g. IOMMU_FAULT_READ/IOMMU_FAULT_WRITE/...)
+ *
+ * This function should be called by the low-level IOMMU implementations
+ * whenever IOMMU faults happen, to allow high-level users, that are
+ * interested in such events, to know about them.
+ *
+ * This event may be useful for several possible use cases:
+ * - mere logging of the event
+ * - dynamic TLB/PTE loading
+ * - if restarting of the faulting device is required
+ *
+ * Returns 0 on success and an appropriate error code otherwise (if dynamic
+ * PTE/TLB loading will one day be supported, implementations will be able
+ * to tell whether it succeeded or not according to this return value).
+ *
+ * Specifically, -ENOSYS is returned if a fault handler isn't installed
+ * (though fault handlers can also return -ENOSYS, in case they want to
+ * elicit the default behavior of the IOMMU drivers).
+ */
+int report_iommu_fault(struct iommu_domain *domain, struct device *dev,
+		       unsigned long iova, int flags)
+{
+	int ret = -ENOSYS;
+
+	/*
+	 * if upper layers showed interest and installed a fault handler,
+	 * invoke it.
+	 */
+	if (domain->handler)
+		ret = domain->handler(domain, dev, iova, flags,
+						domain->handler_token);
+
+	trace_io_page_fault(dev, iova, flags);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(report_iommu_fault);
+
 static int __init iommu_init(void)
 {
 	iommu_group_kset = kset_create_and_add("iommu_groups",

commit 3ba8775f64484a2b56bf3c88d09a186d819fa348
Author: zhichang.yuan <yuanzhichang@hisilicon.com>
Date:   Tue Apr 18 20:51:48 2017 +0800

    iommu: Make iommu_bus_notifier return NOTIFY_DONE rather than error code
    
    In iommu_bus_notifier(), when action is
    BUS_NOTIFY_ADD_DEVICE, it will return 'ops->add_device(dev)'
    directly. But ops->add_device will return ERR_VAL, such as
    -ENODEV. These value will make notifier_call_chain() not to
    traverse the remain nodes in struct notifier_block list.
    
    This patch revises iommu_bus_notifier() to return
    NOTIFY_DONE when some errors happened in ops->add_device().
    
    Signed-off-by: zhichang.yuan <yuanzhichang@hisilicon.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 8ea14f41a979..9170fd498f46 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1082,8 +1082,12 @@ static int iommu_bus_notifier(struct notifier_block *nb,
 	 * result in ADD/DEL notifiers to group->notifier
 	 */
 	if (action == BUS_NOTIFY_ADD_DEVICE) {
-		if (ops->add_device)
-			return ops->add_device(dev);
+		if (ops->add_device) {
+			int ret;
+
+			ret = ops->add_device(dev);
+			return (ret) ? NOTIFY_DONE : NOTIFY_OK;
+		}
 	} else if (action == BUS_NOTIFY_REMOVED_DEVICE) {
 		if (ops->remove_device && dev->iommu_group) {
 			ops->remove_device(dev);

commit fccb4e3b8ab0957628abec82675691c72f67003e
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Jan 5 18:38:26 2017 +0000

    iommu: Allow default domain type to be set on the kernel command line
    
    The IOMMU core currently initialises the default domain for each group
    to IOMMU_DOMAIN_DMA, under the assumption that devices will use
    IOMMU-backed DMA ops by default. However, in some cases it is desirable
    for the DMA ops to bypass the IOMMU for performance reasons, reserving
    use of translation for subsystems such as VFIO that require it for
    enforcing device isolation.
    
    Rather than modify each IOMMU driver to provide different semantics for
    DMA domains, instead we introduce a command line parameter that can be
    used to change the type of the default domain. Passthrough can then be
    specified using "iommu.passthrough=1" on the kernel command line.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 3b67144dead2..770ba7e7ef4d 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -36,6 +36,7 @@
 
 static struct kset *iommu_group_kset;
 static DEFINE_IDA(iommu_group_ida);
+static unsigned int iommu_def_domain_type = IOMMU_DOMAIN_DMA;
 
 struct iommu_callback_data {
 	const struct iommu_ops *ops;
@@ -112,6 +113,18 @@ static int __iommu_attach_group(struct iommu_domain *domain,
 static void __iommu_detach_group(struct iommu_domain *domain,
 				 struct iommu_group *group);
 
+static int __init iommu_set_def_domain_type(char *str)
+{
+	bool pt;
+
+	if (!str || strtobool(str, &pt))
+		return -EINVAL;
+
+	iommu_def_domain_type = pt ? IOMMU_DOMAIN_IDENTITY : IOMMU_DOMAIN_DMA;
+	return 0;
+}
+early_param("iommu.passthrough", iommu_set_def_domain_type);
+
 static ssize_t iommu_group_attr_show(struct kobject *kobj,
 				     struct attribute *__attr, char *buf)
 {
@@ -1015,10 +1028,19 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 	 * IOMMU driver.
 	 */
 	if (!group->default_domain) {
-		group->default_domain = __iommu_domain_alloc(dev->bus,
-							     IOMMU_DOMAIN_DMA);
+		struct iommu_domain *dom;
+
+		dom = __iommu_domain_alloc(dev->bus, iommu_def_domain_type);
+		if (!dom && iommu_def_domain_type != IOMMU_DOMAIN_DMA) {
+			dev_warn(dev,
+				 "failed to allocate default IOMMU domain of type %u; falling back to IOMMU_DOMAIN_DMA",
+				 iommu_def_domain_type);
+			dom = __iommu_domain_alloc(dev->bus, IOMMU_DOMAIN_DMA);
+		}
+
+		group->default_domain = dom;
 		if (!group->domain)
-			group->domain = group->default_domain;
+			group->domain = dom;
 	}
 
 	ret = iommu_group_add_device(group, dev);

commit 9d3a4de4cb8db8e71730e36736272ef041836f68
Author: Robin Murphy <robin.murphy@arm.com>
Date:   Thu Mar 16 17:00:16 2017 +0000

    iommu: Disambiguate MSI region types
    
    The introduction of reserved regions has left a couple of rough edges
    which we could do with sorting out sooner rather than later. Since we
    are not yet addressing the potential dynamic aspect of software-managed
    reservations and presenting them at arbitrary fixed addresses, it is
    incongruous that we end up displaying hardware vs. software-managed MSI
    regions to userspace differently, especially since ARM-based systems may
    actually require one or the other, or even potentially both at once,
    (which iommu-dma currently has no hope of dealing with at all). Let's
    resolve the former user-visible inconsistency ASAP before the ABI has
    been baked into a kernel release, in a way that also lays the groundwork
    for the latter shortcoming to be addressed by follow-up patches.
    
    For clarity, rename the software-managed type to IOMMU_RESV_SW_MSI, use
    IOMMU_RESV_MSI to describe the hardware type, and document everything a
    little bit. Since the x86 MSI remapping hardware falls squarely under
    this meaning of IOMMU_RESV_MSI, apply that type to their regions as well,
    so that we tell the same story to userspace across all platforms.
    
    Secondly, as the various region types require quite different handling,
    and it really makes little sense to ever try combining them, convert the
    bitfield-esque #defines to a plain enum in the process before anyone
    gets the wrong impression.
    
    Fixes: d30ddcaa7b02 ("iommu: Add a new type field in iommu_resv_region")
    Reviewed-by: Eric Auger <eric.auger@redhat.com>
    CC: Alex Williamson <alex.williamson@redhat.com>
    CC: David Woodhouse <dwmw2@infradead.org>
    CC: kvm@vger.kernel.org
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 8ea14f41a979..3b67144dead2 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -72,6 +72,7 @@ static const char * const iommu_group_resv_type_string[] = {
 	[IOMMU_RESV_DIRECT]	= "direct",
 	[IOMMU_RESV_RESERVED]	= "reserved",
 	[IOMMU_RESV_MSI]	= "msi",
+	[IOMMU_RESV_SW_MSI]	= "msi",
 };
 
 #define IOMMU_GROUP_ATTR(_name, _mode, _show, _store)		\
@@ -1743,8 +1744,8 @@ void iommu_put_resv_regions(struct device *dev, struct list_head *list)
 }
 
 struct iommu_resv_region *iommu_alloc_resv_region(phys_addr_t start,
-						  size_t length,
-						  int prot, int type)
+						  size_t length, int prot,
+						  enum iommu_resv_type type)
 {
 	struct iommu_resv_region *region;
 

commit 8d2932dd0634ebeb0a42df896976772bdb569bfe
Merge: 99e8ccd3837a fff2fd1a9e4b 3b6bb5b705a4 aac7d39f200d 087a908f533f 2c9f1af528a4 f7116e115acd d0f6f5832603
Author: Joerg Roedel <jroedel@suse.de>
Date:   Fri Feb 10 15:13:10 2017 +0100

    Merge branches 'iommu/fixes', 'arm/exynos', 'arm/renesas', 'arm/smmu', 'arm/mediatek', 'arm/core', 'x86/vt-d' and 'core' into next

commit d0f6f5832603931b0a8da044fb9abe8289e201ee
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu Feb 2 12:19:12 2017 +0100

    iommu: Remove iommu_register_instance interface
    
    And also move its remaining functionality to
    iommu_device_register() and 'struct iommu_device'.
    
    Cc: Rob Herring <robh+dt@kernel.org>
    Cc: Frank Rowand <frowand.list@gmail.com>
    Cc: Matthias Brugger <matthias.bgg@gmail.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: devicetree@vger.kernel.org
    Cc: linux-arm-kernel@lists.infradead.org
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 1dfd70ea27e4..162d865e2e29 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1658,43 +1658,18 @@ int iommu_request_dm_for_dev(struct device *dev)
 	return ret;
 }
 
-struct iommu_instance {
-	struct list_head list;
-	struct fwnode_handle *fwnode;
-	const struct iommu_ops *ops;
-};
-static LIST_HEAD(iommu_instance_list);
-static DEFINE_SPINLOCK(iommu_instance_lock);
-
-void iommu_register_instance(struct fwnode_handle *fwnode,
-			     const struct iommu_ops *ops)
-{
-	struct iommu_instance *iommu = kzalloc(sizeof(*iommu), GFP_KERNEL);
-
-	if (WARN_ON(!iommu))
-		return;
-
-	of_node_get(to_of_node(fwnode));
-	INIT_LIST_HEAD(&iommu->list);
-	iommu->fwnode = fwnode;
-	iommu->ops = ops;
-	spin_lock(&iommu_instance_lock);
-	list_add_tail(&iommu->list, &iommu_instance_list);
-	spin_unlock(&iommu_instance_lock);
-}
-
 const struct iommu_ops *iommu_ops_from_fwnode(struct fwnode_handle *fwnode)
 {
-	struct iommu_instance *instance;
 	const struct iommu_ops *ops = NULL;
+	struct iommu_device *iommu;
 
-	spin_lock(&iommu_instance_lock);
-	list_for_each_entry(instance, &iommu_instance_list, list)
-		if (instance->fwnode == fwnode) {
-			ops = instance->ops;
+	spin_lock(&iommu_device_lock);
+	list_for_each_entry(iommu, &iommu_device_list, list)
+		if (iommu->fwnode == fwnode) {
+			ops = iommu->ops;
 			break;
 		}
-	spin_unlock(&iommu_instance_lock);
+	spin_unlock(&iommu_device_lock);
 	return ops;
 }
 

commit b0119e870837dcd15a207b4701542ebac5d19b45
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Feb 1 13:23:08 2017 +0100

    iommu: Introduce new 'struct iommu_device'
    
    This struct represents one hardware iommu in the iommu core
    code. For now it only has the iommu-ops associated with it,
    but that will be extended soon.
    
    The register/unregister interface is also added, as well as
    making use of it in the Intel and AMD IOMMU drivers.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index cc569b1b66a2..1dfd70ea27e4 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -77,6 +77,25 @@ struct iommu_group_attribute iommu_group_attr_##_name =		\
 #define to_iommu_group(_kobj)		\
 	container_of(_kobj, struct iommu_group, kobj)
 
+static LIST_HEAD(iommu_device_list);
+static DEFINE_SPINLOCK(iommu_device_lock);
+
+int iommu_device_register(struct iommu_device *iommu)
+{
+	spin_lock(&iommu_device_lock);
+	list_add_tail(&iommu->list, &iommu_device_list);
+	spin_unlock(&iommu_device_lock);
+
+	return 0;
+}
+
+void iommu_device_unregister(struct iommu_device *iommu)
+{
+	spin_lock(&iommu_device_lock);
+	list_del(&iommu->list);
+	spin_unlock(&iommu_device_lock);
+}
+
 static struct iommu_domain *__iommu_domain_alloc(struct bus_type *bus,
 						 unsigned type);
 static int __iommu_attach_device(struct iommu_domain *domain,

commit c09e22d5370739e16463c113525df51b5980b1d5
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Feb 1 12:19:46 2017 +0100

    iommu: Rename struct iommu_device
    
    The struct is used to link devices to iommu-groups, so
    'struct group_device' is a better name. Further this makes
    the name iommu_device available for a struct representing
    hardware iommus.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 2bb61e806a52..cc569b1b66a2 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -55,7 +55,7 @@ struct iommu_group {
 	struct iommu_domain *domain;
 };
 
-struct iommu_device {
+struct group_device {
 	struct list_head list;
 	struct device *dev;
 	char *name;
@@ -374,7 +374,7 @@ static int iommu_group_create_direct_mappings(struct iommu_group *group,
 int iommu_group_add_device(struct iommu_group *group, struct device *dev)
 {
 	int ret, i = 0;
-	struct iommu_device *device;
+	struct group_device *device;
 
 	device = kzalloc(sizeof(*device), GFP_KERNEL);
 	if (!device)
@@ -460,7 +460,7 @@ EXPORT_SYMBOL_GPL(iommu_group_add_device);
 void iommu_group_remove_device(struct device *dev)
 {
 	struct iommu_group *group = dev->iommu_group;
-	struct iommu_device *tmp_device, *device = NULL;
+	struct group_device *tmp_device, *device = NULL;
 
 	pr_info("Removing device %s from group %d\n", dev_name(dev), group->id);
 
@@ -495,7 +495,7 @@ EXPORT_SYMBOL_GPL(iommu_group_remove_device);
 
 static int iommu_group_device_count(struct iommu_group *group)
 {
-	struct iommu_device *entry;
+	struct group_device *entry;
 	int ret = 0;
 
 	list_for_each_entry(entry, &group->devices, list)
@@ -518,7 +518,7 @@ static int iommu_group_device_count(struct iommu_group *group)
 static int __iommu_group_for_each_dev(struct iommu_group *group, void *data,
 				      int (*fn)(struct device *, void *))
 {
-	struct iommu_device *device;
+	struct group_device *device;
 	int ret = 0;
 
 	list_for_each_entry(device, &group->devices, list) {

commit 534766dfef999f7e7349bbd91cd19c1673792af3
Author: Joerg Roedel <jroedel@suse.de>
Date:   Tue Jan 31 16:58:42 2017 +0100

    iommu: Rename iommu_get_instance()
    
    Rename the function to iommu_ops_from_fwnode(), because that
    is what the function actually does. The new name is much
    more descriptive about what the function does.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index aed906a3e3db..2bb61e806a52 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1664,7 +1664,7 @@ void iommu_register_instance(struct fwnode_handle *fwnode,
 	spin_unlock(&iommu_instance_lock);
 }
 
-const struct iommu_ops *iommu_get_instance(struct fwnode_handle *fwnode)
+const struct iommu_ops *iommu_ops_from_fwnode(struct fwnode_handle *fwnode)
 {
 	struct iommu_instance *instance;
 	const struct iommu_ops *ops = NULL;

commit a514a6e241f051dd8a4a00a456382dec0b1af21b
Author: Eric Auger <eric.auger@redhat.com>
Date:   Mon Feb 6 10:11:38 2017 +0100

    iommu: Fix static checker warning in iommu_insert_device_resv_regions
    
    In case the device reserved region list is void, the returned value
    of iommu_insert_device_resv_regions is uninitialized. Let's return 0
    in that case.
    
    This fixes commit 6c65fb318e8b ("iommu: iommu_get_group_resv_regions").
    
    Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Eric Auger <eric.auger@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 428455a21ee7..c37d701ddaa2 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -205,7 +205,7 @@ iommu_insert_device_resv_regions(struct list_head *dev_resv_regions,
 				 struct list_head *group_resv_regions)
 {
 	struct iommu_resv_region *entry;
-	int ret;
+	int ret = 0;
 
 	list_for_each_entry(entry, dev_resv_regions, list) {
 		ret = iommu_insert_resv_region(entry, group_resv_regions);

commit 909111ba0ba6aa228d9b6e9cf01dd68a46586cb4
Author: Zhen Lei <thunder.leizhen@huawei.com>
Date:   Fri Feb 3 17:35:02 2017 +0800

    iommu: Avoid unnecessary assignment of dev->iommu_fwspec
    
    Move the assignment statement into if branch above, where it only
    needs to be.
    
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Reviewed-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index f4a176e56e39..428455a21ee7 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1869,13 +1869,14 @@ int iommu_fwspec_add_ids(struct device *dev, u32 *ids, int num_ids)
 		fwspec = krealloc(dev->iommu_fwspec, size, GFP_KERNEL);
 		if (!fwspec)
 			return -ENOMEM;
+
+		dev->iommu_fwspec = fwspec;
 	}
 
 	for (i = 0; i < num_ids; i++)
 		fwspec->ids[fwspec->num_ids + i] = ids[i];
 
 	fwspec->num_ids += num_ids;
-	dev->iommu_fwspec = fwspec;
 	return 0;
 }
 EXPORT_SYMBOL_GPL(iommu_fwspec_add_ids);

commit bc7d12b91bd35477fd650c4d72b61239de9d9066
Author: Eric Auger <eric.auger@redhat.com>
Date:   Thu Jan 19 20:57:52 2017 +0000

    iommu: Implement reserved_regions iommu-group sysfs file
    
    A new iommu-group sysfs attribute file is introduced. It contains
    the list of reserved regions for the iommu-group. Each reserved
    region is described on a separate line:
    - first field is the start IOVA address,
    - second is the end IOVA address,
    - third is the type.
    
    Signed-off-by: Eric Auger <eric.auger@redhat.com>
    Tested-by: Tomasz Nowicki <tomasz.nowicki@caviumnetworks.com>
    Tested-by: Bharat Bhushan <bharat.bhushan@nxp.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 640056ba46c2..f4a176e56e39 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -68,6 +68,12 @@ struct iommu_group_attribute {
 			 const char *buf, size_t count);
 };
 
+static const char * const iommu_group_resv_type_string[] = {
+	[IOMMU_RESV_DIRECT]	= "direct",
+	[IOMMU_RESV_RESERVED]	= "reserved",
+	[IOMMU_RESV_MSI]	= "msi",
+};
+
 #define IOMMU_GROUP_ATTR(_name, _mode, _show, _store)		\
 struct iommu_group_attribute iommu_group_attr_##_name =		\
 	__ATTR(_name, _mode, _show, _store)
@@ -231,8 +237,33 @@ int iommu_get_group_resv_regions(struct iommu_group *group,
 }
 EXPORT_SYMBOL_GPL(iommu_get_group_resv_regions);
 
+static ssize_t iommu_group_show_resv_regions(struct iommu_group *group,
+					     char *buf)
+{
+	struct iommu_resv_region *region, *next;
+	struct list_head group_resv_regions;
+	char *str = buf;
+
+	INIT_LIST_HEAD(&group_resv_regions);
+	iommu_get_group_resv_regions(group, &group_resv_regions);
+
+	list_for_each_entry_safe(region, next, &group_resv_regions, list) {
+		str += sprintf(str, "0x%016llx 0x%016llx %s\n",
+			       (long long int)region->start,
+			       (long long int)(region->start +
+						region->length - 1),
+			       iommu_group_resv_type_string[region->type]);
+		kfree(region);
+	}
+
+	return (str - buf);
+}
+
 static IOMMU_GROUP_ATTR(name, S_IRUGO, iommu_group_show_name, NULL);
 
+static IOMMU_GROUP_ATTR(reserved_regions, 0444,
+			iommu_group_show_resv_regions, NULL);
+
 static void iommu_group_release(struct kobject *kobj)
 {
 	struct iommu_group *group = to_iommu_group(kobj);
@@ -310,6 +341,11 @@ struct iommu_group *iommu_group_alloc(void)
 	 */
 	kobject_put(&group->kobj);
 
+	ret = iommu_group_create_file(group,
+				      &iommu_group_attr_reserved_regions);
+	if (ret)
+		return ERR_PTR(ret);
+
 	pr_debug("Allocated group %d\n", group->id);
 
 	return group;

commit 6c65fb318e8bbf21e939e651028b955324f1d873
Author: Eric Auger <eric.auger@redhat.com>
Date:   Thu Jan 19 20:57:51 2017 +0000

    iommu: iommu_get_group_resv_regions
    
    Introduce iommu_get_group_resv_regions whose role consists in
    enumerating all devices from the group and collecting their
    reserved regions. The list is sorted and overlaps between
    regions of the same type are handled by merging the regions.
    
    Signed-off-by: Eric Auger <eric.auger@redhat.com>
    Reviewed-by: Tomasz Nowicki <tomasz.nowicki@caviumnetworks.com>
    Tested-by: Tomasz Nowicki <tomasz.nowicki@caviumnetworks.com>
    Tested-by: Bharat Bhushan <bharat.bhushan@nxp.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 41c190695749..640056ba46c2 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -133,6 +133,104 @@ static ssize_t iommu_group_show_name(struct iommu_group *group, char *buf)
 	return sprintf(buf, "%s\n", group->name);
 }
 
+/**
+ * iommu_insert_resv_region - Insert a new region in the
+ * list of reserved regions.
+ * @new: new region to insert
+ * @regions: list of regions
+ *
+ * The new element is sorted by address with respect to the other
+ * regions of the same type. In case it overlaps with another
+ * region of the same type, regions are merged. In case it
+ * overlaps with another region of different type, regions are
+ * not merged.
+ */
+static int iommu_insert_resv_region(struct iommu_resv_region *new,
+				    struct list_head *regions)
+{
+	struct iommu_resv_region *region;
+	phys_addr_t start = new->start;
+	phys_addr_t end = new->start + new->length - 1;
+	struct list_head *pos = regions->next;
+
+	while (pos != regions) {
+		struct iommu_resv_region *entry =
+			list_entry(pos, struct iommu_resv_region, list);
+		phys_addr_t a = entry->start;
+		phys_addr_t b = entry->start + entry->length - 1;
+		int type = entry->type;
+
+		if (end < a) {
+			goto insert;
+		} else if (start > b) {
+			pos = pos->next;
+		} else if ((start >= a) && (end <= b)) {
+			if (new->type == type)
+				goto done;
+			else
+				pos = pos->next;
+		} else {
+			if (new->type == type) {
+				phys_addr_t new_start = min(a, start);
+				phys_addr_t new_end = max(b, end);
+
+				list_del(&entry->list);
+				entry->start = new_start;
+				entry->length = new_end - new_start + 1;
+				iommu_insert_resv_region(entry, regions);
+			} else {
+				pos = pos->next;
+			}
+		}
+	}
+insert:
+	region = iommu_alloc_resv_region(new->start, new->length,
+					 new->prot, new->type);
+	if (!region)
+		return -ENOMEM;
+
+	list_add_tail(&region->list, pos);
+done:
+	return 0;
+}
+
+static int
+iommu_insert_device_resv_regions(struct list_head *dev_resv_regions,
+				 struct list_head *group_resv_regions)
+{
+	struct iommu_resv_region *entry;
+	int ret;
+
+	list_for_each_entry(entry, dev_resv_regions, list) {
+		ret = iommu_insert_resv_region(entry, group_resv_regions);
+		if (ret)
+			break;
+	}
+	return ret;
+}
+
+int iommu_get_group_resv_regions(struct iommu_group *group,
+				 struct list_head *head)
+{
+	struct iommu_device *device;
+	int ret = 0;
+
+	mutex_lock(&group->mutex);
+	list_for_each_entry(device, &group->devices, list) {
+		struct list_head dev_resv_regions;
+
+		INIT_LIST_HEAD(&dev_resv_regions);
+		iommu_get_resv_regions(device->dev, &dev_resv_regions);
+		ret = iommu_insert_device_resv_regions(&dev_resv_regions, head);
+		iommu_put_resv_regions(device->dev, &dev_resv_regions);
+		if (ret)
+			break;
+	}
+	mutex_unlock(&group->mutex);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(iommu_get_group_resv_regions);
+
 static IOMMU_GROUP_ATTR(name, S_IRUGO, iommu_group_show_name, NULL);
 
 static void iommu_group_release(struct kobject *kobj)

commit 544a25d904cab2ae68bd71b334603ec3a49b60dd
Author: Eric Auger <eric.auger@redhat.com>
Date:   Thu Jan 19 20:57:50 2017 +0000

    iommu: Only map direct mapped regions
    
    As we introduced new reserved region types which do not require
    mapping, let's make sure we only map direct mapped regions.
    
    Signed-off-by: Eric Auger <eric.auger@redhat.com>
    Reviewed-by: Tomasz Nowicki <tomasz.nowicki@caviumnetworks.com>
    Tested-by: Tomasz Nowicki <tomasz.nowicki@caviumnetworks.com>
    Tested-by: Bharat Bhushan <bharat.bhushan@nxp.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 927878d0a612..41c190695749 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -343,6 +343,9 @@ static int iommu_group_create_direct_mappings(struct iommu_group *group,
 		start = ALIGN(entry->start, pg_size);
 		end   = ALIGN(entry->start + entry->length, pg_size);
 
+		if (entry->type != IOMMU_RESV_DIRECT)
+			continue;
+
 		for (addr = start; addr < end; addr += pg_size) {
 			phys_addr_t phys_addr;
 

commit 2b20cbba3390a55c511acba2f0f517dd27a528b2
Author: Eric Auger <eric.auger@redhat.com>
Date:   Thu Jan 19 20:57:49 2017 +0000

    iommu: iommu_alloc_resv_region
    
    Introduce a new helper serving the purpose to allocate a reserved
    region. This will be used in iommu driver implementing reserved
    region callbacks.
    
    Signed-off-by: Eric Auger <eric.auger@redhat.com>
    Reviewed-by: Tomasz Nowicki <tomasz.nowicki@caviumnetworks.com>
    Tested-by: Tomasz Nowicki <tomasz.nowicki@caviumnetworks.com>
    Tested-by: Bharat Bhushan <bharat.bhushan@nxp.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 1cee5c361c21..927878d0a612 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1575,6 +1575,24 @@ void iommu_put_resv_regions(struct device *dev, struct list_head *list)
 		ops->put_resv_regions(dev, list);
 }
 
+struct iommu_resv_region *iommu_alloc_resv_region(phys_addr_t start,
+						  size_t length,
+						  int prot, int type)
+{
+	struct iommu_resv_region *region;
+
+	region = kzalloc(sizeof(*region), GFP_KERNEL);
+	if (!region)
+		return NULL;
+
+	INIT_LIST_HEAD(&region->list);
+	region->start = start;
+	region->length = length;
+	region->prot = prot;
+	region->type = type;
+	return region;
+}
+
 /* Request that a device is direct mapped by the IOMMU */
 int iommu_request_dm_for_dev(struct device *dev)
 {

commit e5b5234a36ca283158721d3d2e0cddfa324abdf9
Author: Eric Auger <eric.auger@redhat.com>
Date:   Thu Jan 19 20:57:47 2017 +0000

    iommu: Rename iommu_dm_regions into iommu_resv_regions
    
    We want to extend the callbacks used for dm regions and
    use them for reserved regions. Reserved regions can be
    - directly mapped regions
    - regions that cannot be iommu mapped (PCI host bridge windows, ...)
    - MSI regions (because they belong to another address space or because
      they are not translated by the IOMMU and need special handling)
    
    So let's rename the struct and also the callbacks.
    
    Signed-off-by: Eric Auger <eric.auger@redhat.com>
    Acked-by: Robin Murphy <robin.murphy@arm.com>
    Reviewed-by: Tomasz Nowicki <tomasz.nowicki@caviumnetworks.com>
    Tested-by: Tomasz Nowicki <tomasz.nowicki@caviumnetworks.com>
    Tested-by: Bharat Bhushan <bharat.bhushan@nxp.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index dbe7f653bb7c..1cee5c361c21 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -318,7 +318,7 @@ static int iommu_group_create_direct_mappings(struct iommu_group *group,
 					      struct device *dev)
 {
 	struct iommu_domain *domain = group->default_domain;
-	struct iommu_dm_region *entry;
+	struct iommu_resv_region *entry;
 	struct list_head mappings;
 	unsigned long pg_size;
 	int ret = 0;
@@ -331,14 +331,14 @@ static int iommu_group_create_direct_mappings(struct iommu_group *group,
 	pg_size = 1UL << __ffs(domain->pgsize_bitmap);
 	INIT_LIST_HEAD(&mappings);
 
-	iommu_get_dm_regions(dev, &mappings);
+	iommu_get_resv_regions(dev, &mappings);
 
 	/* We need to consider overlapping regions for different devices */
 	list_for_each_entry(entry, &mappings, list) {
 		dma_addr_t start, end, addr;
 
-		if (domain->ops->apply_dm_region)
-			domain->ops->apply_dm_region(dev, domain, entry);
+		if (domain->ops->apply_resv_region)
+			domain->ops->apply_resv_region(dev, domain, entry);
 
 		start = ALIGN(entry->start, pg_size);
 		end   = ALIGN(entry->start + entry->length, pg_size);
@@ -358,7 +358,7 @@ static int iommu_group_create_direct_mappings(struct iommu_group *group,
 	}
 
 out:
-	iommu_put_dm_regions(dev, &mappings);
+	iommu_put_resv_regions(dev, &mappings);
 
 	return ret;
 }
@@ -1559,20 +1559,20 @@ int iommu_domain_set_attr(struct iommu_domain *domain,
 }
 EXPORT_SYMBOL_GPL(iommu_domain_set_attr);
 
-void iommu_get_dm_regions(struct device *dev, struct list_head *list)
+void iommu_get_resv_regions(struct device *dev, struct list_head *list)
 {
 	const struct iommu_ops *ops = dev->bus->iommu_ops;
 
-	if (ops && ops->get_dm_regions)
-		ops->get_dm_regions(dev, list);
+	if (ops && ops->get_resv_regions)
+		ops->get_resv_regions(dev, list);
 }
 
-void iommu_put_dm_regions(struct device *dev, struct list_head *list)
+void iommu_put_resv_regions(struct device *dev, struct list_head *list)
 {
 	const struct iommu_ops *ops = dev->bus->iommu_ops;
 
-	if (ops && ops->put_dm_regions)
-		ops->put_dm_regions(dev, list);
+	if (ops && ops->put_resv_regions)
+		ops->put_resv_regions(dev, list);
 }
 
 /* Request that a device is direct mapped by the IOMMU */

commit 797a8b4d768c58caac58ee3e8cb36a164d1b7751
Author: Robin Murphy <robin.murphy@arm.com>
Date:   Mon Jan 16 12:58:07 2017 +0000

    iommu: Handle default domain attach failure
    
    We wouldn't normally expect ops->attach_dev() to fail, but on IOMMUs
    with limited hardware resources, or generally misconfigured systems,
    it is certainly possible. We report failure correctly from the external
    iommu_attach_device() interface, but do not do so in iommu_group_add()
    when attaching to the default domain. The result of failure there is
    that the device, group and domain all get left in a broken,
    part-configured state which leads to weird errors and misbehaviour down
    the line when IOMMU API calls sort-of-but-don't-quite work.
    
    Check the return value of __iommu_attach_device() on the default domain,
    and refactor the error handling paths to cope with its failure and clean
    up correctly in such cases.
    
    Fixes: e39cb8a3aa98 ("iommu: Make sure a device is always attached to a domain")
    Reported-by: Punit Agrawal <punit.agrawal@arm.com>
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index dbe7f653bb7c..aed906a3e3db 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -383,36 +383,30 @@ int iommu_group_add_device(struct iommu_group *group, struct device *dev)
 	device->dev = dev;
 
 	ret = sysfs_create_link(&dev->kobj, &group->kobj, "iommu_group");
-	if (ret) {
-		kfree(device);
-		return ret;
-	}
+	if (ret)
+		goto err_free_device;
 
 	device->name = kasprintf(GFP_KERNEL, "%s", kobject_name(&dev->kobj));
 rename:
 	if (!device->name) {
-		sysfs_remove_link(&dev->kobj, "iommu_group");
-		kfree(device);
-		return -ENOMEM;
+		ret = -ENOMEM;
+		goto err_remove_link;
 	}
 
 	ret = sysfs_create_link_nowarn(group->devices_kobj,
 				       &dev->kobj, device->name);
 	if (ret) {
-		kfree(device->name);
 		if (ret == -EEXIST && i >= 0) {
 			/*
 			 * Account for the slim chance of collision
 			 * and append an instance to the name.
 			 */
+			kfree(device->name);
 			device->name = kasprintf(GFP_KERNEL, "%s.%d",
 						 kobject_name(&dev->kobj), i++);
 			goto rename;
 		}
-
-		sysfs_remove_link(&dev->kobj, "iommu_group");
-		kfree(device);
-		return ret;
+		goto err_free_name;
 	}
 
 	kobject_get(group->devices_kobj);
@@ -424,8 +418,10 @@ int iommu_group_add_device(struct iommu_group *group, struct device *dev)
 	mutex_lock(&group->mutex);
 	list_add_tail(&device->list, &group->devices);
 	if (group->domain)
-		__iommu_attach_device(group->domain, dev);
+		ret = __iommu_attach_device(group->domain, dev);
 	mutex_unlock(&group->mutex);
+	if (ret)
+		goto err_put_group;
 
 	/* Notify any listeners about change to group. */
 	blocking_notifier_call_chain(&group->notifier,
@@ -436,6 +432,21 @@ int iommu_group_add_device(struct iommu_group *group, struct device *dev)
 	pr_info("Adding device %s to group %d\n", dev_name(dev), group->id);
 
 	return 0;
+
+err_put_group:
+	mutex_lock(&group->mutex);
+	list_del(&device->list);
+	mutex_unlock(&group->mutex);
+	dev->iommu_group = NULL;
+	kobject_put(group->devices_kobj);
+err_free_name:
+	kfree(device->name);
+err_remove_link:
+	sysfs_remove_link(&dev->kobj, "iommu_group");
+err_free_device:
+	kfree(device);
+	pr_err("Failed to add device %s to group %d: %d\n", dev_name(dev), group->id, ret);
+	return ret;
 }
 EXPORT_SYMBOL_GPL(iommu_group_add_device);
 

commit 1465f481460cbfc60dc119873099d89a58f9be4f
Merge: 3e5de27e940d 00c7c81f7b49 18b709beb503 ebcfa2843954 37bad55b784c 24c790fbf5d8 2f5f44f205cc
Author: Joerg Roedel <jroedel@suse.de>
Date:   Tue Dec 6 17:32:16 2016 +0100

    Merge branches 'arm/mediatek', 'arm/smmu', 'x86/amd', 's390', 'core' and 'arm/exynos' into next

commit e4f10ffe4c9b500e545b874b816ffea5e8659b05
Author: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
Date:   Mon Nov 21 10:01:36 2016 +0000

    iommu: Make of_iommu_set/get_ops() DT agnostic
    
    The of_iommu_{set/get}_ops() API is used to associate a device
    tree node with a specific set of IOMMU operations. The same
    kernel interface is required on systems booting with ACPI, where
    devices are not associated with a device tree node, therefore
    the interface requires generalization.
    
    The struct device fwnode member represents the fwnode token associated
    with the device and the struct it points at is firmware specific;
    regardless, it is initialized on both ACPI and DT systems and makes an
    ideal candidate to use it to associate a set of IOMMU operations to a
    given device, through its struct device.fwnode member pointer, paving
    the way for representing per-device iommu_ops (ie an iommu instance
    associated with a device).
    
    Convert the DT specific of_iommu_{set/get}_ops() interface to
    use struct device.fwnode as a look-up token, making the interface
    usable on ACPI systems and rename the data structures and the
    registration API so that they are made to represent their usage
    more clearly.
    
    Signed-off-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Reviewed-by: Robin Murphy <robin.murphy@arm.com>
    Reviewed-by: Tomasz Nowicki <tn@semihalf.com>
    Tested-by: Hanjun Guo <hanjun.guo@linaro.org>
    Tested-by: Tomasz Nowicki <tn@semihalf.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Hanjun Guo <hanjun.guo@linaro.org>
    Cc: Robin Murphy <robin.murphy@arm.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 9a2f1960873b..8d3e847d4845 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1615,6 +1615,46 @@ int iommu_request_dm_for_dev(struct device *dev)
 	return ret;
 }
 
+struct iommu_instance {
+	struct list_head list;
+	struct fwnode_handle *fwnode;
+	const struct iommu_ops *ops;
+};
+static LIST_HEAD(iommu_instance_list);
+static DEFINE_SPINLOCK(iommu_instance_lock);
+
+void iommu_register_instance(struct fwnode_handle *fwnode,
+			     const struct iommu_ops *ops)
+{
+	struct iommu_instance *iommu = kzalloc(sizeof(*iommu), GFP_KERNEL);
+
+	if (WARN_ON(!iommu))
+		return;
+
+	of_node_get(to_of_node(fwnode));
+	INIT_LIST_HEAD(&iommu->list);
+	iommu->fwnode = fwnode;
+	iommu->ops = ops;
+	spin_lock(&iommu_instance_lock);
+	list_add_tail(&iommu->list, &iommu_instance_list);
+	spin_unlock(&iommu_instance_lock);
+}
+
+const struct iommu_ops *iommu_get_instance(struct fwnode_handle *fwnode)
+{
+	struct iommu_instance *instance;
+	const struct iommu_ops *ops = NULL;
+
+	spin_lock(&iommu_instance_lock);
+	list_for_each_entry(instance, &iommu_instance_list, list)
+		if (instance->fwnode == fwnode) {
+			ops = instance->ops;
+			break;
+		}
+	spin_unlock(&iommu_instance_lock);
+	return ops;
+}
+
 int iommu_fwspec_init(struct device *dev, struct fwnode_handle *iommu_fwnode,
 		      const struct iommu_ops *ops)
 {

commit 13f59a78c6d69a9bf4c8989dd5f3396f54a2fe41
Author: Robin Murphy <robin.murphy@arm.com>
Date:   Fri Nov 11 17:59:21 2016 +0000

    iommu: Allow taking a reference on a group directly
    
    iommu_group_get_for_dev() expects that the IOMMU driver's device_group
    callback return a group with a reference held for the given device.
    Whilst allocating a new group is fine, and pci_device_group() correctly
    handles reusing an existing group, there is no general means for IOMMU
    drivers doing their own group lookup to take additional references on an
    existing group pointer without having to also store device pointers or
    resort to elaborate trickery.
    
    Add an IOMMU-driver-specific function to fill the hole.
    
    Acked-by: Sricharan R <sricharan@codeaurora.org>
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 9a2f1960873b..9408c3145483 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -551,6 +551,19 @@ struct iommu_group *iommu_group_get(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(iommu_group_get);
 
+/**
+ * iommu_group_ref_get - Increment reference on a group
+ * @group: the group to use, must not be NULL
+ *
+ * This function is called by iommu drivers to take additional references on an
+ * existing group.  Returns the given group for convenience.
+ */
+struct iommu_group *iommu_group_ref_get(struct iommu_group *group)
+{
+	kobject_get(group->devices_kobj);
+	return group;
+}
+
 /**
  * iommu_group_put - Decrement group reference
  * @group: the group to use

commit 57f98d2f61e191ef9d06863c9ce3f8621f3671ef
Author: Robin Murphy <robin.murphy@arm.com>
Date:   Tue Sep 13 10:54:14 2016 +0100

    iommu: Introduce iommu_fwspec
    
    Introduce a common structure to hold the per-device firmware data that
    most IOMMU drivers need to keep track of. This enables us to configure
    much of that data from common firmware code, and consolidate a lot of
    the equivalent implementations, device look-up tables, etc. which are
    currently strewn across IOMMU drivers.
    
    This will also be enable us to address the outstanding "multiple IOMMUs
    on the platform bus" problem by tweaking IOMMU API calls to prefer
    dev->fwspec->ops before falling back to dev->bus->iommu_ops, and thus
    gracefully handle those troublesome systems which we currently cannot.
    
    As the first user, hook up the OF IOMMU configuration mechanism. The
    driver-defined nature of DT cells means that we still need the drivers
    to translate and add the IDs themselves, but future users such as the
    much less free-form ACPI IORT will be much simpler and self-contained.
    
    CC: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Suggested-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index b06d93594436..9a2f1960873b 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -31,6 +31,7 @@
 #include <linux/err.h>
 #include <linux/pci.h>
 #include <linux/bitops.h>
+#include <linux/property.h>
 #include <trace/events/iommu.h>
 
 static struct kset *iommu_group_kset;
@@ -1613,3 +1614,60 @@ int iommu_request_dm_for_dev(struct device *dev)
 
 	return ret;
 }
+
+int iommu_fwspec_init(struct device *dev, struct fwnode_handle *iommu_fwnode,
+		      const struct iommu_ops *ops)
+{
+	struct iommu_fwspec *fwspec = dev->iommu_fwspec;
+
+	if (fwspec)
+		return ops == fwspec->ops ? 0 : -EINVAL;
+
+	fwspec = kzalloc(sizeof(*fwspec), GFP_KERNEL);
+	if (!fwspec)
+		return -ENOMEM;
+
+	of_node_get(to_of_node(iommu_fwnode));
+	fwspec->iommu_fwnode = iommu_fwnode;
+	fwspec->ops = ops;
+	dev->iommu_fwspec = fwspec;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(iommu_fwspec_init);
+
+void iommu_fwspec_free(struct device *dev)
+{
+	struct iommu_fwspec *fwspec = dev->iommu_fwspec;
+
+	if (fwspec) {
+		fwnode_handle_put(fwspec->iommu_fwnode);
+		kfree(fwspec);
+		dev->iommu_fwspec = NULL;
+	}
+}
+EXPORT_SYMBOL_GPL(iommu_fwspec_free);
+
+int iommu_fwspec_add_ids(struct device *dev, u32 *ids, int num_ids)
+{
+	struct iommu_fwspec *fwspec = dev->iommu_fwspec;
+	size_t size;
+	int i;
+
+	if (!fwspec)
+		return -EINVAL;
+
+	size = offsetof(struct iommu_fwspec, ids[fwspec->num_ids + num_ids]);
+	if (size > sizeof(*fwspec)) {
+		fwspec = krealloc(dev->iommu_fwspec, size, GFP_KERNEL);
+		if (!fwspec)
+			return -ENOMEM;
+	}
+
+	for (i = 0; i < num_ids; i++)
+		fwspec->ids[fwspec->num_ids + i] = ids[i];
+
+	fwspec->num_ids += num_ids;
+	dev->iommu_fwspec = fwspec;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(iommu_fwspec_add_ids);

commit f360d3241f5557f241d55b959e6e65070e77992e
Merge: 523d939ef98f ffec219770da 5c365d18a73d 6ae5343c26f9 131bc8ebb46a 1cb13f78329c a93db2f22b6b c3928e75158e feccf398db63
Author: Joerg Roedel <jroedel@suse.de>
Date:   Tue Jul 26 16:02:37 2016 +0200

    Merge branches 'x86/amd', 'x86/vt-d', 'arm/exynos', 'arm/mediatek', 'arm/msm', 'arm/rockchip', 'arm/smmu' and 'core' into next

commit 33b21a6b203f70e2012b02753134e59c3ab38779
Author: Joerg Roedel <jroedel@suse.de>
Date:   Tue Jul 5 13:07:53 2016 +0200

    iommu: Add apply_dm_region call-back to iommu-ops
    
    This new call-back will be used by the iommu driver to do
    reserve the given dm_region in its iova space before the
    mapping is created.
    
    The call-back is temporary until the dma-ops implementation
    is part of the common iommu code.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 3000051f48b4..e8d2fb02d88e 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -348,6 +348,9 @@ static int iommu_group_create_direct_mappings(struct iommu_group *group,
 	list_for_each_entry(entry, &mappings, list) {
 		dma_addr_t start, end, addr;
 
+		if (domain->ops->apply_dm_region)
+			domain->ops->apply_dm_region(dev, domain, entry);
+
 		start = ALIGN(entry->start, pg_size);
 		end   = ALIGN(entry->start + entry->length, pg_size);
 

commit feccf398db631f3b98c4c6572381517d90b5fd87
Author: Heiner Kallweit <hkallweit1@gmail.com>
Date:   Wed Jun 29 21:13:59 2016 +0200

    iommu: Simplify and fix ida handling
    
    Ida handling can be much simplified by using the ida_simple_.. functions.
    
    This change also fixes the bug that previously checking for errors
    returned by ida_get_new() was incomplete.
    ida_get_new() can return errors other than EAGAIN, e.g. ENOSPC.
    This case wasn't handled.
    
    Signed-off-by: Heiner Kallweit <hkallweit1@gmail.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index debce45b5b8c..4d3c4a82af03 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -35,7 +35,6 @@
 
 static struct kset *iommu_group_kset;
 static DEFINE_IDA(iommu_group_ida);
-static DEFINE_MUTEX(iommu_group_mutex);
 
 struct iommu_callback_data {
 	const struct iommu_ops *ops;
@@ -144,9 +143,7 @@ static void iommu_group_release(struct kobject *kobj)
 	if (group->iommu_data_release)
 		group->iommu_data_release(group->iommu_data);
 
-	mutex_lock(&iommu_group_mutex);
-	ida_remove(&iommu_group_ida, group->id);
-	mutex_unlock(&iommu_group_mutex);
+	ida_simple_remove(&iommu_group_ida, group->id);
 
 	if (group->default_domain)
 		iommu_domain_free(group->default_domain);
@@ -186,26 +183,17 @@ struct iommu_group *iommu_group_alloc(void)
 	INIT_LIST_HEAD(&group->devices);
 	BLOCKING_INIT_NOTIFIER_HEAD(&group->notifier);
 
-	mutex_lock(&iommu_group_mutex);
-
-again:
-	if (unlikely(0 == ida_pre_get(&iommu_group_ida, GFP_KERNEL))) {
+	ret = ida_simple_get(&iommu_group_ida, 0, 0, GFP_KERNEL);
+	if (ret < 0) {
 		kfree(group);
-		mutex_unlock(&iommu_group_mutex);
-		return ERR_PTR(-ENOMEM);
+		return ERR_PTR(ret);
 	}
-
-	if (-EAGAIN == ida_get_new(&iommu_group_ida, &group->id))
-		goto again;
-
-	mutex_unlock(&iommu_group_mutex);
+	group->id = ret;
 
 	ret = kobject_init_and_add(&group->kobj, &iommu_group_ktype,
 				   NULL, "%d", group->id);
 	if (ret) {
-		mutex_lock(&iommu_group_mutex);
-		ida_remove(&iommu_group_ida, group->id);
-		mutex_unlock(&iommu_group_mutex);
+		ida_simple_remove(&iommu_group_ida, group->id);
 		kfree(group);
 		return ERR_PTR(ret);
 	}

commit e38d1f1312e4e88d1dab1fdf591824e1f3b105a9
Author: Heiner Kallweit <hkallweit1@gmail.com>
Date:   Tue Jun 28 20:38:36 2016 +0200

    iommu: Simplify init function
    
    iommu_group_ida and iommu_group_mutex can be initialized statically.
    There's no need to do this dynamically in the init function.
    
    Signed-off-by: Heiner Kallweit <hkallweit1@gmail.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 3000051f48b4..debce45b5b8c 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -34,8 +34,8 @@
 #include <trace/events/iommu.h>
 
 static struct kset *iommu_group_kset;
-static struct ida iommu_group_ida;
-static struct mutex iommu_group_mutex;
+static DEFINE_IDA(iommu_group_ida);
+static DEFINE_MUTEX(iommu_group_mutex);
 
 struct iommu_callback_data {
 	const struct iommu_ops *ops;
@@ -1483,9 +1483,6 @@ static int __init iommu_init(void)
 {
 	iommu_group_kset = kset_create_and_add("iommu_groups",
 					       NULL, kernel_kobj);
-	ida_init(&iommu_group_ida);
-	mutex_init(&iommu_group_mutex);
-
 	BUG_ON(!iommu_group_kset);
 
 	return 0;

commit e0fb1b36398487475e0d2c50264e4ec1eaed3e11
Merge: f4c80d5a16eb 6c0b43df74f9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu May 19 17:07:04 2016 -0700

    Merge tag 'iommu-updates-v4.7' of git://git.kernel.org/pub/scm/linux/kernel/git/joro/iommu
    
    Pull IOMMU updates from Joerg Roedel:
     "The updates include:
    
       - rate limiting for the VT-d fault handler
    
       - remove statistics code from the AMD IOMMU driver.  It is unused and
         should be replaced by something more generic if needed
    
       - per-domain pagesize-bitmaps in IOMMU core code to support systems
         with different types of IOMMUs
    
       - support for ACPI devices in the AMD IOMMU driver
    
       - 4GB mode support for Mediatek IOMMU driver
    
       - ARM-SMMU updates from Will Deacon:
          - support for 64k pages with SMMUv1 implementations (e.g MMU-401)
          - remove open-coded 64-bit MMIO accessors
          - initial support for 16-bit VMIDs, as supported by some ThunderX
            SMMU implementations
          - a couple of errata workarounds for silicon in the field
    
       - various fixes here and there"
    
    * tag 'iommu-updates-v4.7' of git://git.kernel.org/pub/scm/linux/kernel/git/joro/iommu: (44 commits)
      iommu/arm-smmu: Use per-domain page sizes.
      iommu/amd: Remove statistics code
      iommu/dma: Finish optimising higher-order allocations
      iommu: Allow selecting page sizes per domain
      iommu: of: enforce const-ness of struct iommu_ops
      iommu: remove unused priv field from struct iommu_ops
      iommu/dma: Implement scatterlist segment merging
      iommu/arm-smmu: Clear cache lock bit of ACR
      iommu/arm-smmu: Support SMMUv1 64KB supplement
      iommu/arm-smmu: Decouple context format from kernel config
      iommu/arm-smmu: Tidy up 64-bit/atomic I/O accesses
      io-64-nonatomic: Add relaxed accessor variants
      iommu/arm-smmu: Work around MMU-500 prefetch errata
      iommu/arm-smmu: Convert ThunderX workaround to new method
      iommu/arm-smmu: Differentiate specific implementations
      iommu/arm-smmu: Workaround for ThunderX erratum #27704
      iommu/arm-smmu: Add support for 16 bit VMID
      iommu/amd: Move get_device_id() and friends to beginning of file
      iommu/amd: Don't use IS_ERR_VALUE to check integer values
      iommu/amd: Signedness bug in acpihid_device_group()
      ...

commit 7afd16f882887c9adc69cd1794f5e57777723217
Merge: a37571a29eca e257ef55ce51
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu May 19 13:10:54 2016 -0700

    Merge tag 'pci-v4.7-changes' of git://git.kernel.org/pub/scm/linux/kernel/git/helgaas/pci
    
    Pull PCI updates from Bjorn Helgaas:
     "Enumeration:
       - Refine PCI support check in pcibios_init() (Adrian-Ken Rueegsegger)
       - Provide common functions for ECAM mapping (Jayachandran C)
       - Allow all PCIe services on non-ACPI host bridges (Jon Derrick)
       - Remove return values from pcie_port_platform_notify() and relatives (Jon Derrick)
       - Widen portdrv service type from 4 bits to 8 bits (Keith Busch)
       - Add Downstream Port Containment portdrv service type (Keith Busch)
       - Add Downstream Port Containment driver (Keith Busch)
    
      Resource management:
       - Identify Enhanced Allocation (EA) BAR Equivalent resources in sysfs (Alex Williamson)
       - Supply CPU physical address (not bus address) to iomem_is_exclusive() (Bjorn Helgaas)
       - alpha: Call iomem_is_exclusive() for IORESOURCE_MEM, but not IORESOURCE_IO (Bjorn Helgaas)
       - Mark Broadwell-EP Home Agent 1 as having non-compliant BARs (Prarit Bhargava)
       - Disable all BAR sizing for devices with non-compliant BARs (Prarit Bhargava)
       - Move PCI I/O space management from OF to PCI core code (Tomasz Nowicki)
    
      PCI device hotplug:
       - acpiphp_ibm: Avoid uninitialized variable reference (Dan Carpenter)
       - Use cached copy of PCI_EXP_SLTCAP_HPC bit (Lukas Wunner)
    
      Virtualization:
       - Mark Intel i40e NIC INTx masking as broken (Alex Williamson)
       - Reverse standard ACS vs device-specific ACS enabling (Alex Williamson)
       - Work around Intel Sunrise Point PCH incorrect ACS capability (Alex Williamson)
    
      IOMMU:
       - Add pci_add_dma_alias() to abstract implementation (Bjorn Helgaas)
       - Move informational printk to pci_add_dma_alias() (Bjorn Helgaas)
       - Add support for multiple DMA aliases (Jacek Lawrynowicz)
       - Add DMA alias quirk for mic_x200_dma (Jacek Lawrynowicz)
    
      Thunderbolt:
       - Fix double free of drom buffer (Andreas Noever)
       - Add Intel Thunderbolt device IDs (Lukas Wunner)
       - Fix typos and magic number (Lukas Wunner)
       - Support 1st gen Light Ridge controller (Lukas Wunner)
    
      Generic host bridge driver:
       - Use generic ECAM API (Jayachandran C)
    
      Cavium ThunderX host bridge driver:
       - Don't clobber read-only bits in bridge config registers (David Daney)
       - Use generic ECAM API (Jayachandran C)
    
      Freescale i.MX6 host bridge driver:
       - Use enum instead of bool for variant indicator (Andrey Smirnov)
       - Implement reset sequence for i.MX6+ (Andrey Smirnov)
       - Factor out ref clock enable (Bjorn Helgaas)
       - Add initial imx6sx support (Christoph Fritz)
       - Add reset-gpio-active-high boolean property to DT (Petr Štetiar)
       - Add DT property for link gen, default to Gen1 (Tim Harvey)
       - dts: Specify imx6qp version of PCIe core (Andrey Smirnov)
       - dts: Fix PCIe reset GPIO polarity on Toradex Apalis Ixora (Petr Štetiar)
    
      Marvell Armada host bridge driver:
       - add DT binding for Marvell Armada 7K/8K PCIe controller (Thomas Petazzoni)
       - Add driver for Marvell Armada 7K/8K PCIe controller (Thomas Petazzoni)
    
      Marvell MVEBU host bridge driver:
       - Constify mvebu_pcie_pm_ops structure (Jisheng Zhang)
       - Use SET_NOIRQ_SYSTEM_SLEEP_PM_OPS for mvebu_pcie_pm_ops (Jisheng Zhang)
    
      Microsoft Hyper-V host bridge driver:
       - Report resources release after stopping the bus (Vitaly Kuznetsov)
       - Add explicit barriers to config space access (Vitaly Kuznetsov)
    
      Renesas R-Car host bridge driver:
       - Select PCI_MSI_IRQ_DOMAIN (Arnd Bergmann)
    
      Synopsys DesignWare host bridge driver:
       - Remove incorrect RC memory base/limit configuration (Gabriele Paoloni)
       - Move Root Complex setup code to dw_pcie_setup_rc() (Jisheng Zhang)
    
      TI Keystone host bridge driver:
       - Add error IRQ handler (Murali Karicheri)
       - Remove unnecessary goto statement (Murali Karicheri)
    
      Miscellaneous:
       - Fix spelling errors (Colin Ian King)"
    
    * tag 'pci-v4.7-changes' of git://git.kernel.org/pub/scm/linux/kernel/git/helgaas/pci: (48 commits)
      PCI: Disable all BAR sizing for devices with non-compliant BARs
      x86/PCI: Mark Broadwell-EP Home Agent 1 as having non-compliant BARs
      PCI: Identify Enhanced Allocation (EA) BAR Equivalent resources in sysfs
      PCI, of: Move PCI I/O space management to PCI core code
      PCI: generic, thunder: Use generic ECAM API
      PCI: Provide common functions for ECAM mapping
      PCI: hv: Add explicit barriers to config space access
      PCI: Use cached copy of PCI_EXP_SLTCAP_HPC bit
      PCI: Add Downstream Port Containment driver
      PCI: Add Downstream Port Containment portdrv service type
      PCI: Widen portdrv service type from 4 bits to 8 bits
      PCI: designware: Remove incorrect RC memory base/limit configuration
      PCI: hv: Report resources release after stopping the bus
      ARM: dts: imx6qp: Specify imx6qp version of PCIe core
      PCI: imx6: Implement reset sequence for i.MX6+
      PCI: imx6: Use enum instead of bool for variant indicator
      PCI: thunder: Don't clobber read-only bits in bridge config registers
      thunderbolt: Fix double free of drom buffer
      PCI: rcar: Select PCI_MSI_IRQ_DOMAIN
      PCI: armada: Add driver for Marvell Armada 7K/8K PCIe controller
      ...

commit d16e0faab911cc0e100a1e8e93635b432566608e
Author: Robin Murphy <robin.murphy@arm.com>
Date:   Thu Apr 7 18:42:06 2016 +0100

    iommu: Allow selecting page sizes per domain
    
    Many IOMMUs support multiple page table formats, meaning that any given
    domain may only support a subset of the hardware page sizes presented in
    iommu_ops->pgsize_bitmap. There are also certain use-cases where the
    creator of a domain may want to control which page sizes are used, for
    example to force the use of hugepage mappings to reduce pagetable walk
    depth.
    
    To this end, add a per-domain pgsize_bitmap to represent the subset of
    page sizes actually in use, to make it possible for domains with
    different requirements to coexist.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    [rm: hijacked and rebased original patch with new commit message]
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index b9df1411c894..ab4d014e3687 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -337,9 +337,9 @@ static int iommu_group_create_direct_mappings(struct iommu_group *group,
 	if (!domain || domain->type != IOMMU_DOMAIN_DMA)
 		return 0;
 
-	BUG_ON(!domain->ops->pgsize_bitmap);
+	BUG_ON(!domain->pgsize_bitmap);
 
-	pg_size = 1UL << __ffs(domain->ops->pgsize_bitmap);
+	pg_size = 1UL << __ffs(domain->pgsize_bitmap);
 	INIT_LIST_HEAD(&mappings);
 
 	iommu_get_dm_regions(dev, &mappings);
@@ -1073,6 +1073,8 @@ static struct iommu_domain *__iommu_domain_alloc(struct bus_type *bus,
 
 	domain->ops  = bus->iommu_ops;
 	domain->type = type;
+	/* Assume all sizes by default; the driver may override this later */
+	domain->pgsize_bitmap  = bus->iommu_ops->pgsize_bitmap;
 
 	return domain;
 }
@@ -1297,7 +1299,7 @@ static size_t iommu_pgsize(struct iommu_domain *domain,
 	pgsize = (1UL << (pgsize_idx + 1)) - 1;
 
 	/* throw away page sizes not supported by the hardware */
-	pgsize &= domain->ops->pgsize_bitmap;
+	pgsize &= domain->pgsize_bitmap;
 
 	/* make sure we're still sane */
 	BUG_ON(!pgsize);
@@ -1319,14 +1321,14 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 	int ret = 0;
 
 	if (unlikely(domain->ops->map == NULL ||
-		     domain->ops->pgsize_bitmap == 0UL))
+		     domain->pgsize_bitmap == 0UL))
 		return -ENODEV;
 
 	if (unlikely(!(domain->type & __IOMMU_DOMAIN_PAGING)))
 		return -EINVAL;
 
 	/* find out the minimum page size supported */
-	min_pagesz = 1 << __ffs(domain->ops->pgsize_bitmap);
+	min_pagesz = 1 << __ffs(domain->pgsize_bitmap);
 
 	/*
 	 * both the virtual address and the physical one, as well as
@@ -1373,14 +1375,14 @@ size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
 	unsigned long orig_iova = iova;
 
 	if (unlikely(domain->ops->unmap == NULL ||
-		     domain->ops->pgsize_bitmap == 0UL))
+		     domain->pgsize_bitmap == 0UL))
 		return -ENODEV;
 
 	if (unlikely(!(domain->type & __IOMMU_DOMAIN_PAGING)))
 		return -EINVAL;
 
 	/* find out the minimum page size supported */
-	min_pagesz = 1 << __ffs(domain->ops->pgsize_bitmap);
+	min_pagesz = 1 << __ffs(domain->pgsize_bitmap);
 
 	/*
 	 * The virtual address, as well as the size of the mapping, must be
@@ -1426,10 +1428,10 @@ size_t default_iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
 	unsigned int i, min_pagesz;
 	int ret;
 
-	if (unlikely(domain->ops->pgsize_bitmap == 0UL))
+	if (unlikely(domain->pgsize_bitmap == 0UL))
 		return 0;
 
-	min_pagesz = 1 << __ffs(domain->ops->pgsize_bitmap);
+	min_pagesz = 1 << __ffs(domain->pgsize_bitmap);
 
 	for_each_sg(sg, s, nents, i) {
 		phys_addr_t phys = page_to_phys(sg_page(s)) + s->offset;
@@ -1510,7 +1512,7 @@ int iommu_domain_get_attr(struct iommu_domain *domain,
 		break;
 	case DOMAIN_ATTR_PAGING:
 		paging  = data;
-		*paging = (domain->ops->pgsize_bitmap != 0UL);
+		*paging = (domain->pgsize_bitmap != 0UL);
 		break;
 	case DOMAIN_ATTR_WINDOWS:
 		count = data;

commit 338c3149a221527e202ee26b1e35f76c965bb6c0
Author: Jacek Lawrynowicz <jacek.lawrynowicz@intel.com>
Date:   Thu Mar 3 15:38:02 2016 +0100

    PCI: Add support for multiple DMA aliases
    
    Solve IOMMU support issues with PCIe non-transparent bridges that use
    Requester ID look-up tables (RID-LUT), e.g., the PEX8733.
    
    The NTB connects devices in two independent PCI domains.  Devices separated
    by the NTB are not able to discover each other.  A PCI packet being
    forwared from one domain to another has to have its RID modified so it
    appears on correct bus and completions are forwarded back to the original
    domain through the NTB.  The RID is translated using a preprogrammed table
    (LUT) and the PCI packet propagates upstream away from the NTB.  If the
    destination system has IOMMU enabled, the packet will be discarded because
    the new RID is unknown to the IOMMU.  Adding a DMA alias for the new RID
    allows IOMMU to properly recognize the packet.
    
    Each device behind the NTB has a unique RID assigned in the RID-LUT.  The
    current DMA alias implementation supports only a single alias, so it's not
    possible to support mutiple devices behind the NTB when IOMMU is enabled.
    
    Enable all possible aliases on a given bus (256) that are stored in a
    bitset.  Alias devfn is directly translated to a bit number.  The bitset is
    not allocated for devices that have no need for DMA aliases.
    
    More details can be found in the following article:
    http://www.plxtech.com/files/pdf/technical/expresslane/RTC_Enabling%20MulitHostSystemDesigns.pdf
    
    Signed-off-by: Jacek Lawrynowicz <jacek.lawrynowicz@intel.com>
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
    Reviewed-by: Alex Williamson <alex.williamson@redhat.com>
    Acked-by: David Woodhouse <David.Woodhouse@intel.com>
    Acked-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index bfd4f7c3b1d8..1b49e940a318 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -660,8 +660,8 @@ static struct iommu_group *get_pci_function_alias_group(struct pci_dev *pdev,
 }
 
 /*
- * Look for aliases to or from the given device for exisiting groups.  The
- * dma_alias_devfn only supports aliases on the same bus, therefore the search
+ * Look for aliases to or from the given device for existing groups. DMA
+ * aliases are only supported on the same bus, therefore the search
  * space is quite small (especially since we're really only looking at pcie
  * device, and therefore only expect multiple slots on the root complex or
  * downstream switch ports).  It's conceivable though that a pair of
@@ -686,11 +686,7 @@ static struct iommu_group *get_pci_alias_group(struct pci_dev *pdev,
 			continue;
 
 		/* We alias them or they alias us */
-		if (((pdev->dev_flags & PCI_DEV_FLAGS_DMA_ALIAS_DEVFN) &&
-		     pdev->dma_alias_devfn == tmp->devfn) ||
-		    ((tmp->dev_flags & PCI_DEV_FLAGS_DMA_ALIAS_DEVFN) &&
-		     tmp->dma_alias_devfn == pdev->devfn)) {
-
+		if (pci_devs_are_dma_aliases(pdev, tmp)) {
 			group = get_pci_alias_group(tmp, devfns);
 			if (group) {
 				pci_dev_put(tmp);

commit eebb8034a5be8c2177cbf07ca2ecd2ff8a058958
Author: Joerg Roedel <jroedel@suse.de>
Date:   Mon Apr 4 15:47:48 2016 +0200

    iommu: Don't overwrite domain pointer when there is no default_domain
    
    IOMMU drivers that do not support default domains, but make
    use of the the group->domain pointer can get that pointer
    overwritten with NULL on device add/remove.
    
    Make sure this can't happen by only overwriting the domain
    pointer when it is NULL.
    
    Cc: stable@vger.kernel.org # v4.4+
    Fixes: 1228236de5f9 ('iommu: Move default domain allocation to iommu_group_get_for_dev()')
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index bfd4f7c3b1d8..b9df1411c894 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -848,7 +848,8 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 	if (!group->default_domain) {
 		group->default_domain = __iommu_domain_alloc(dev->bus,
 							     IOMMU_DOMAIN_DMA);
-		group->domain = group->default_domain;
+		if (!group->domain)
+			group->domain = group->default_domain;
 	}
 
 	ret = iommu_group_add_device(group, dev);

commit 06bfcaa91f0eff1aeab37c74056afa79fb450aea
Author: Yoshihiro Shimoda <yoshihiro.shimoda.uh@renesas.com>
Date:   Wed Feb 10 10:18:04 2016 +0900

    iommu: Fix second argument of trace_map() to report correct paddr
    
    Since iommu_map() code added pgsize value to the paddr, trace_map()
    used wrong paddr. So, this patch adds "orig_paddr" value in the
    iommu_map() to use for the trace_map().
    
    Signed-off-by: Yoshihiro Shimoda <yoshihiro.shimoda.uh@renesas.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 0e3b0092ec92..bfd4f7c3b1d8 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1314,6 +1314,7 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 	unsigned long orig_iova = iova;
 	unsigned int min_pagesz;
 	size_t orig_size = size;
+	phys_addr_t orig_paddr = paddr;
 	int ret = 0;
 
 	if (unlikely(domain->ops->map == NULL ||
@@ -1358,7 +1359,7 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 	if (ret)
 		iommu_unmap(domain, orig_iova, orig_size - size);
 	else
-		trace_map(orig_iova, paddr, orig_size);
+		trace_map(orig_iova, orig_paddr, orig_size);
 
 	return ret;
 }

commit 3e6110fd5480f5f86ff31381f4dea14218284bff
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Dec 15 12:54:06 2015 -0800

    Revert "scatterlist: use sg_phys()"
    
    commit db0fa0cb0157 "scatterlist: use sg_phys()" did replacements of
    the form:
    
        phys_addr_t phys = page_to_phys(sg_page(s));
        phys_addr_t phys = sg_phys(s) & PAGE_MASK;
    
    However, this breaks platforms where sizeof(phys_addr_t) >
    sizeof(unsigned long).  Revert for 4.3 and 4.4 to make room for a
    combined helper in 4.5.
    
    Cc: <stable@vger.kernel.org>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Fixes: db0fa0cb0157 ("scatterlist: use sg_phys()")
    Suggested-by: Joerg Roedel <joro@8bytes.org>
    Reported-by: Vitaly Lavrov <vel21ripn@gmail.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index abae363c7b9b..0e3b0092ec92 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1430,7 +1430,7 @@ size_t default_iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
 	min_pagesz = 1 << __ffs(domain->ops->pgsize_bitmap);
 
 	for_each_sg(sg, s, nents, i) {
-		phys_addr_t phys = sg_phys(s);
+		phys_addr_t phys = page_to_phys(sg_page(s)) + s->offset;
 
 		/*
 		 * We are mapping on IOMMU page boundaries, so offset within

commit 1228236de5f978970fb814cc27138cdb00cbb48d
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Oct 21 23:51:43 2015 +0200

    iommu: Move default domain allocation to iommu_group_get_for_dev()
    
    Now that the iommu core support for iommu groups is not
    pci-centric anymore, we can move default domain allocation
    to the bus independent iommu_group_get_for_dev() function.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index e2b5526506fd..abae363c7b9b 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -810,14 +810,6 @@ struct iommu_group *pci_device_group(struct device *dev)
 	if (IS_ERR(group))
 		return NULL;
 
-	/*
-	 * Try to allocate a default domain - needs support from the
-	 * IOMMU driver.
-	 */
-	group->default_domain = __iommu_domain_alloc(pdev->dev.bus,
-						     IOMMU_DOMAIN_DMA);
-	group->domain = group->default_domain;
-
 	return group;
 }
 
@@ -849,6 +841,16 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 	if (IS_ERR(group))
 		return group;
 
+	/*
+	 * Try to allocate a default domain - needs support from the
+	 * IOMMU driver.
+	 */
+	if (!group->default_domain) {
+		group->default_domain = __iommu_domain_alloc(dev->bus,
+							     IOMMU_DOMAIN_DMA);
+		group->domain = group->default_domain;
+	}
+
 	ret = iommu_group_add_device(group, dev);
 	if (ret) {
 		iommu_group_put(group);

commit 391811e185408671180745dfd30914bb64f6368e
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Oct 21 23:51:42 2015 +0200

    iommu: Remove is_pci_dev() fall-back from iommu_group_get_for_dev
    
    All callers of iommu_group_get_for_dev() provide a
    device_group call-back now, so this fall-back is no longer
    needed.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index a80c9c5c2650..e2b5526506fd 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -845,8 +845,6 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 
 	if (ops && ops->device_group)
 		group = ops->device_group(dev);
-	else if (dev_is_pci(dev))
-		group = pci_device_group(dev);
 
 	if (IS_ERR(group))
 		return group;

commit 6eab556a40384de94c2d03c8d9d632e5154367f5
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Oct 21 23:51:38 2015 +0200

    iommu: Add generic_device_group() function
    
    This function can be used as a device_group call-back and
    just allocates one iommu-group per device.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index fdea700ca12c..a80c9c5c2650 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -727,6 +727,21 @@ static int get_pci_alias_or_group(struct pci_dev *pdev, u16 alias, void *opaque)
 	return data->group != NULL;
 }
 
+/*
+ * Generic device_group call-back function. It just allocates one
+ * iommu-group per device.
+ */
+struct iommu_group *generic_device_group(struct device *dev)
+{
+	struct iommu_group *group;
+
+	group = iommu_group_alloc();
+	if (IS_ERR(group))
+		return NULL;
+
+	return group;
+}
+
 /*
  * Use standard PCI bus topology, isolation features, and DMA alias quirks
  * to find or create an IOMMU group for a device.

commit 5e62292bad10cff25ff75d136c54e62b43bfb0fa
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Oct 21 23:51:37 2015 +0200

    iommu: Export and rename iommu_group_get_for_pci_dev()
    
    Rename that function to pci_device_group() and export it, so
    that IOMMU drivers can use it as their device_group
    call-back.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 563746383973..fdea700ca12c 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -731,13 +731,17 @@ static int get_pci_alias_or_group(struct pci_dev *pdev, u16 alias, void *opaque)
  * Use standard PCI bus topology, isolation features, and DMA alias quirks
  * to find or create an IOMMU group for a device.
  */
-static struct iommu_group *iommu_group_get_for_pci_dev(struct pci_dev *pdev)
+struct iommu_group *pci_device_group(struct device *dev)
 {
+	struct pci_dev *pdev = to_pci_dev(dev);
 	struct group_for_pci_data data;
 	struct pci_bus *bus;
 	struct iommu_group *group = NULL;
 	u64 devfns[4] = { 0 };
 
+	if (WARN_ON(!dev_is_pci(dev)))
+		return ERR_PTR(-EINVAL);
+
 	/*
 	 * Find the upstream DMA alias for the device.  A device must not
 	 * be aliased due to topology in order to have its own IOMMU group.
@@ -827,7 +831,7 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 	if (ops && ops->device_group)
 		group = ops->device_group(dev);
 	else if (dev_is_pci(dev))
-		group = iommu_group_get_for_pci_dev(to_pci_dev(dev));
+		group = pci_device_group(dev);
 
 	if (IS_ERR(group))
 		return group;

commit 46c6b2bc88a729366605d0dedb6a35b8cf7cc4f0
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Oct 21 23:51:36 2015 +0200

    iommu: Revive device_group iommu-ops call-back
    
    That call-back is currently unused, change it into a
    call-back function for finding the right IOMMU group for a
    device.
    This is a first step to remove the hard-coded PCI dependency
    in the iommu-group code.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 049df495c274..563746383973 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -814,6 +814,7 @@ static struct iommu_group *iommu_group_get_for_pci_dev(struct pci_dev *pdev)
  */
 struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 {
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
 	struct iommu_group *group;
 	int ret;
 
@@ -821,10 +822,12 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 	if (group)
 		return group;
 
-	if (!dev_is_pci(dev))
-		return ERR_PTR(-EINVAL);
+	group = ERR_PTR(-EINVAL);
 
-	group = iommu_group_get_for_pci_dev(to_pci_dev(dev));
+	if (ops && ops->device_group)
+		group = ops->device_group(dev);
+	else if (dev_is_pci(dev))
+		group = iommu_group_get_for_pci_dev(to_pci_dev(dev));
 
 	if (IS_ERR(group))
 		return group;

commit db0fa0cb015794dd19f664933d49c6ce902ec1e1
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Aug 17 08:13:26 2015 -0600

    scatterlist: use sg_phys()
    
    Coccinelle cleanup to replace open coded sg to physical address
    translations.  This is in preparation for introducing scatterlists that
    reference __pfn_t.
    
    // sg_phys.cocci: convert usage page_to_phys(sg_page(sg)) to sg_phys(sg)
    // usage: make coccicheck COCCI=sg_phys.cocci MODE=patch
    
    virtual patch
    
    @@
    struct scatterlist *sg;
    @@
    
    - page_to_phys(sg_page(sg)) + sg->offset
    + sg_phys(sg)
    
    @@
    struct scatterlist *sg;
    @@
    
    - page_to_phys(sg_page(sg))
    + sg_phys(sg) & PAGE_MASK
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index f286090931cc..049df495c274 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1408,7 +1408,7 @@ size_t default_iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
 	min_pagesz = 1 << __ffs(domain->ops->pgsize_bitmap);
 
 	for_each_sg(sg, s, nents, i) {
-		phys_addr_t phys = page_to_phys(sg_page(s)) + s->offset;
+		phys_addr_t phys = sg_phys(s);
 
 		/*
 		 * We are mapping on IOMMU page boundaries, so offset within

commit 38667f18900afe172a4fe44279b132b4140f920f
Author: Joerg Roedel <jroedel@suse.de>
Date:   Mon Jun 29 10:16:08 2015 +0200

    iommu: Ignore -ENODEV errors from add_device call-back
    
    The -ENODEV error just means that the device is not
    translated by an IOMMU. We shouldn't bail out of iommu
    driver initialization when that happens, as this is a common
    scenario on ARM.
    
    Not returning -ENODEV in the drivers would be a bad idea, as
    the IOMMU core would have no indication whether a device is
    translated or not. This indication is not used at the
    moment, but will probably be in the future.
    
    Fixes: 19762d7 ("iommu: Propagate error in add_iommu_group")
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Tested-by: Eric Auger <eric.auger@linaro.org>
    Tested-by: Heiko Stuebner <heiko@sntech.de>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 49e7542510d1..f286090931cc 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -847,13 +847,24 @@ static int add_iommu_group(struct device *dev, void *data)
 {
 	struct iommu_callback_data *cb = data;
 	const struct iommu_ops *ops = cb->ops;
+	int ret;
 
 	if (!ops->add_device)
 		return 0;
 
 	WARN_ON(dev->iommu_group);
 
-	return ops->add_device(dev);
+	ret = ops->add_device(dev);
+
+	/*
+	 * We ignore -ENODEV errors for now, as they just mean that the
+	 * device is not translated by an IOMMU. We still care about
+	 * other errors and fail to initialize when they happen.
+	 */
+	if (ret == -ENODEV)
+		ret = 0;
+
+	return ret;
 }
 
 static int remove_iommu_group(struct device *dev, void *data)

commit 5ffde2f67181195d457b95df44b8f88e8d969d89
Merge: ec4292defd42 aa759fd376fb 8a0a01bff855 571dbbd4d044 0b3fff54bc01 4d58b8a6de6b 733cac2ade2f
Author: Joerg Roedel <jroedel@suse.de>
Date:   Fri Jun 19 17:17:47 2015 +0200

    Merge branches 'arm/rockchip', 'arm/exynos', 'arm/smmu', 'x86/vt-d', 'x86/amd', 'default-domains' and 'core' into next

commit 409e553deeeb08d644ed1110e0f1c97b71cb6409
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Wed Jun 10 13:59:27 2015 +0300

    iommu: Checking for NULL instead of IS_ERR
    
    The iommu_group_alloc() and iommu_group_get_for_dev()
    functions return error pointers, they never return NULL.
    
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 3b1a2551a747..89dc50b9acdc 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -788,15 +788,16 @@ static struct iommu_group *iommu_group_get_for_pci_dev(struct pci_dev *pdev)
 
 	/* No shared group found, allocate new */
 	group = iommu_group_alloc();
-	if (group) {
-		/*
-		 * Try to allocate a default domain - needs support from the
-		 * IOMMU driver.
-		 */
-		group->default_domain = __iommu_domain_alloc(pdev->dev.bus,
-							     IOMMU_DOMAIN_DMA);
-		group->domain = group->default_domain;
-	}
+	if (IS_ERR(group))
+		return NULL;
+
+	/*
+	 * Try to allocate a default domain - needs support from the
+	 * IOMMU driver.
+	 */
+	group->default_domain = __iommu_domain_alloc(pdev->dev.bus,
+						     IOMMU_DOMAIN_DMA);
+	group->domain = group->default_domain;
 
 	return group;
 }
@@ -1548,8 +1549,8 @@ int iommu_request_dm_for_dev(struct device *dev)
 
 	/* Device must already be in a group before calling this function */
 	group = iommu_group_get_for_dev(dev);
-	if (!group)
-		return -EINVAL;
+	if (IS_ERR(group))
+		return PTR_ERR(group);
 
 	mutex_lock(&group->mutex);
 

commit d290f1e70d85a9a4d124594c6a3d769329960bdc
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu May 28 18:41:36 2015 +0200

    iommu: Introduce iommu_request_dm_for_dev()
    
    This function can be called by an IOMMU driver to request
    that a device's default domain is direct mapped.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 224c6dd2d249..3b1a2551a747 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1538,3 +1538,56 @@ void iommu_put_dm_regions(struct device *dev, struct list_head *list)
 	if (ops && ops->put_dm_regions)
 		ops->put_dm_regions(dev, list);
 }
+
+/* Request that a device is direct mapped by the IOMMU */
+int iommu_request_dm_for_dev(struct device *dev)
+{
+	struct iommu_domain *dm_domain;
+	struct iommu_group *group;
+	int ret;
+
+	/* Device must already be in a group before calling this function */
+	group = iommu_group_get_for_dev(dev);
+	if (!group)
+		return -EINVAL;
+
+	mutex_lock(&group->mutex);
+
+	/* Check if the default domain is already direct mapped */
+	ret = 0;
+	if (group->default_domain &&
+	    group->default_domain->type == IOMMU_DOMAIN_IDENTITY)
+		goto out;
+
+	/* Don't change mappings of existing devices */
+	ret = -EBUSY;
+	if (iommu_group_device_count(group) != 1)
+		goto out;
+
+	/* Allocate a direct mapped domain */
+	ret = -ENOMEM;
+	dm_domain = __iommu_domain_alloc(dev->bus, IOMMU_DOMAIN_IDENTITY);
+	if (!dm_domain)
+		goto out;
+
+	/* Attach the device to the domain */
+	ret = __iommu_attach_group(dm_domain, group);
+	if (ret) {
+		iommu_domain_free(dm_domain);
+		goto out;
+	}
+
+	/* Make the direct mapped domain the default for this group */
+	if (group->default_domain)
+		iommu_domain_free(group->default_domain);
+	group->default_domain = dm_domain;
+
+	pr_info("Using direct mapping for device %s\n", dev_name(dev));
+
+	ret = 0;
+out:
+	mutex_unlock(&group->mutex);
+	iommu_group_put(group);
+
+	return ret;
+}

commit 6827ca83695d5e41ad31b0719788ee65f00ca4b3
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu May 28 18:41:35 2015 +0200

    iommu: Add function to query the default domain of a group
    
    This will be used to handle unity mappings in the iommu
    drivers.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index ffad1eaf450d..224c6dd2d249 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -837,6 +837,11 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 	return group;
 }
 
+struct iommu_domain *iommu_group_default_domain(struct iommu_group *group)
+{
+	return group->default_domain;
+}
+
 static int add_iommu_group(struct device *dev, void *data)
 {
 	struct iommu_callback_data *cb = data;

commit beed2821b4f42c268222c4c1f1795e53340acf64
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu May 28 18:41:34 2015 +0200

    iommu: Create direct mappings in default domains
    
    Use the information exported by the IOMMU drivers to create
    direct mapped regions in the default domains.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 6b8d6e7771e1..ffad1eaf450d 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -325,6 +325,52 @@ int iommu_group_set_name(struct iommu_group *group, const char *name)
 }
 EXPORT_SYMBOL_GPL(iommu_group_set_name);
 
+static int iommu_group_create_direct_mappings(struct iommu_group *group,
+					      struct device *dev)
+{
+	struct iommu_domain *domain = group->default_domain;
+	struct iommu_dm_region *entry;
+	struct list_head mappings;
+	unsigned long pg_size;
+	int ret = 0;
+
+	if (!domain || domain->type != IOMMU_DOMAIN_DMA)
+		return 0;
+
+	BUG_ON(!domain->ops->pgsize_bitmap);
+
+	pg_size = 1UL << __ffs(domain->ops->pgsize_bitmap);
+	INIT_LIST_HEAD(&mappings);
+
+	iommu_get_dm_regions(dev, &mappings);
+
+	/* We need to consider overlapping regions for different devices */
+	list_for_each_entry(entry, &mappings, list) {
+		dma_addr_t start, end, addr;
+
+		start = ALIGN(entry->start, pg_size);
+		end   = ALIGN(entry->start + entry->length, pg_size);
+
+		for (addr = start; addr < end; addr += pg_size) {
+			phys_addr_t phys_addr;
+
+			phys_addr = iommu_iova_to_phys(domain, addr);
+			if (phys_addr)
+				continue;
+
+			ret = iommu_map(domain, addr, addr, pg_size, entry->prot);
+			if (ret)
+				goto out;
+		}
+
+	}
+
+out:
+	iommu_put_dm_regions(dev, &mappings);
+
+	return ret;
+}
+
 /**
  * iommu_group_add_device - add a device to an iommu group
  * @group: the group into which to add the device (reference should be held)
@@ -381,6 +427,8 @@ int iommu_group_add_device(struct iommu_group *group, struct device *dev)
 
 	dev->iommu_group = group;
 
+	iommu_group_create_direct_mappings(group, dev);
+
 	mutex_lock(&group->mutex);
 	list_add_tail(&device->list, &group->devices);
 	if (group->domain)

commit a1015c2b99b94cf521603b41debf167114031456
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu May 28 18:41:33 2015 +0200

    iommu: Introduce direct mapped region handling
    
    Add two new functions to the IOMMU-API to allow the IOMMU
    drivers to export the requirements for direct mapped regions
    per device.
    This is useful for exporting the information in Intel VT-d's
    RMRR entries or AMD-Vi's unity mappings.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index a0a38bd2668b..6b8d6e7771e1 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1469,3 +1469,19 @@ int iommu_domain_set_attr(struct iommu_domain *domain,
 	return ret;
 }
 EXPORT_SYMBOL_GPL(iommu_domain_set_attr);
+
+void iommu_get_dm_regions(struct device *dev, struct list_head *list)
+{
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
+
+	if (ops && ops->get_dm_regions)
+		ops->get_dm_regions(dev, list);
+}
+
+void iommu_put_dm_regions(struct device *dev, struct list_head *list)
+{
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
+
+	if (ops && ops->put_dm_regions)
+		ops->put_dm_regions(dev, list);
+}

commit 2c1296d92ac0367364bcb73a43c12a0bdfbfee75
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu May 28 18:41:32 2015 +0200

    iommu: Add iommu_get_domain_for_dev function
    
    This function can be used to request the current domain a
    device is attached to.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 7bce522c2367..a0a38bd2668b 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1076,6 +1076,24 @@ void iommu_detach_device(struct iommu_domain *domain, struct device *dev)
 }
 EXPORT_SYMBOL_GPL(iommu_detach_device);
 
+struct iommu_domain *iommu_get_domain_for_dev(struct device *dev)
+{
+	struct iommu_domain *domain;
+	struct iommu_group *group;
+
+	group = iommu_group_get(dev);
+	/* FIXME: Remove this when groups a mandatory for iommu drivers */
+	if (group == NULL)
+		return NULL;
+
+	domain = group->domain;
+
+	iommu_group_put(group);
+
+	return domain;
+}
+EXPORT_SYMBOL_GPL(iommu_get_domain_for_dev);
+
 /*
  * IOMMU groups are really the natrual working unit of the IOMMU, but
  * the IOMMU API works on domains and devices.  Bridge that gap by

commit e39cb8a3aa988a74433a3f26443b454cca033651
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu May 28 18:41:31 2015 +0200

    iommu: Make sure a device is always attached to a domain
    
    Make use of the default domain and re-attach a device to it
    when it is detached from another domain. Also enforce that a
    device has to be in the default domain before it can be
    attached to a different domain.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index ef73923db2f1..7bce522c2367 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -52,6 +52,7 @@ struct iommu_group {
 	char *name;
 	int id;
 	struct iommu_domain *default_domain;
+	struct iommu_domain *domain;
 };
 
 struct iommu_device {
@@ -78,6 +79,12 @@ struct iommu_group_attribute iommu_group_attr_##_name =		\
 
 static struct iommu_domain *__iommu_domain_alloc(struct bus_type *bus,
 						 unsigned type);
+static int __iommu_attach_device(struct iommu_domain *domain,
+				 struct device *dev);
+static int __iommu_attach_group(struct iommu_domain *domain,
+				struct iommu_group *group);
+static void __iommu_detach_group(struct iommu_domain *domain,
+				 struct iommu_group *group);
 
 static ssize_t iommu_group_attr_show(struct kobject *kobj,
 				     struct attribute *__attr, char *buf)
@@ -376,6 +383,8 @@ int iommu_group_add_device(struct iommu_group *group, struct device *dev)
 
 	mutex_lock(&group->mutex);
 	list_add_tail(&device->list, &group->devices);
+	if (group->domain)
+		__iommu_attach_device(group->domain, dev);
 	mutex_unlock(&group->mutex);
 
 	/* Notify any listeners about change to group. */
@@ -455,19 +464,30 @@ static int iommu_group_device_count(struct iommu_group *group)
  * The group->mutex is held across callbacks, which will block calls to
  * iommu_group_add/remove_device.
  */
-int iommu_group_for_each_dev(struct iommu_group *group, void *data,
-			     int (*fn)(struct device *, void *))
+static int __iommu_group_for_each_dev(struct iommu_group *group, void *data,
+				      int (*fn)(struct device *, void *))
 {
 	struct iommu_device *device;
 	int ret = 0;
 
-	mutex_lock(&group->mutex);
 	list_for_each_entry(device, &group->devices, list) {
 		ret = fn(device->dev, data);
 		if (ret)
 			break;
 	}
+	return ret;
+}
+
+
+int iommu_group_for_each_dev(struct iommu_group *group, void *data,
+			     int (*fn)(struct device *, void *))
+{
+	int ret;
+
+	mutex_lock(&group->mutex);
+	ret = __iommu_group_for_each_dev(group, data, fn);
 	mutex_unlock(&group->mutex);
+
 	return ret;
 }
 EXPORT_SYMBOL_GPL(iommu_group_for_each_dev);
@@ -727,6 +747,7 @@ static struct iommu_group *iommu_group_get_for_pci_dev(struct pci_dev *pdev)
 		 */
 		group->default_domain = __iommu_domain_alloc(pdev->dev.bus,
 							     IOMMU_DOMAIN_DMA);
+		group->domain = group->default_domain;
 	}
 
 	return group;
@@ -1012,7 +1033,7 @@ int iommu_attach_device(struct iommu_domain *domain, struct device *dev)
 	if (iommu_group_device_count(group) != 1)
 		goto out_unlock;
 
-	ret = __iommu_attach_device(domain, dev);
+	ret = __iommu_attach_group(domain, group);
 
 out_unlock:
 	mutex_unlock(&group->mutex);
@@ -1047,7 +1068,7 @@ void iommu_detach_device(struct iommu_domain *domain, struct device *dev)
 		goto out_unlock;
 	}
 
-	__iommu_detach_device(domain, dev);
+	__iommu_detach_group(domain, group);
 
 out_unlock:
 	mutex_unlock(&group->mutex);
@@ -1072,10 +1093,31 @@ static int iommu_group_do_attach_device(struct device *dev, void *data)
 	return __iommu_attach_device(domain, dev);
 }
 
+static int __iommu_attach_group(struct iommu_domain *domain,
+				struct iommu_group *group)
+{
+	int ret;
+
+	if (group->default_domain && group->domain != group->default_domain)
+		return -EBUSY;
+
+	ret = __iommu_group_for_each_dev(group, domain,
+					 iommu_group_do_attach_device);
+	if (ret == 0)
+		group->domain = domain;
+
+	return ret;
+}
+
 int iommu_attach_group(struct iommu_domain *domain, struct iommu_group *group)
 {
-	return iommu_group_for_each_dev(group, domain,
-					iommu_group_do_attach_device);
+	int ret;
+
+	mutex_lock(&group->mutex);
+	ret = __iommu_attach_group(domain, group);
+	mutex_unlock(&group->mutex);
+
+	return ret;
 }
 EXPORT_SYMBOL_GPL(iommu_attach_group);
 
@@ -1088,9 +1130,35 @@ static int iommu_group_do_detach_device(struct device *dev, void *data)
 	return 0;
 }
 
+static void __iommu_detach_group(struct iommu_domain *domain,
+				 struct iommu_group *group)
+{
+	int ret;
+
+	if (!group->default_domain) {
+		__iommu_group_for_each_dev(group, domain,
+					   iommu_group_do_detach_device);
+		group->domain = NULL;
+		return;
+	}
+
+	if (group->domain == group->default_domain)
+		return;
+
+	/* Detach by re-attaching to the default domain */
+	ret = __iommu_group_for_each_dev(group, group->default_domain,
+					 iommu_group_do_attach_device);
+	if (ret != 0)
+		WARN_ON(1);
+	else
+		group->domain = group->default_domain;
+}
+
 void iommu_detach_group(struct iommu_domain *domain, struct iommu_group *group)
 {
-	iommu_group_for_each_dev(group, domain, iommu_group_do_detach_device);
+	mutex_lock(&group->mutex);
+	__iommu_detach_group(domain, group);
+	mutex_unlock(&group->mutex);
 }
 EXPORT_SYMBOL_GPL(iommu_detach_group);
 

commit 426a273834eae65abcfc7132a21a85b3151e0bce
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu May 28 18:41:30 2015 +0200

    iommu: Limit iommu_attach/detach_device to devices with their own group
    
    This patch changes the behavior of the iommu_attach_device
    and iommu_detach_device functions. With this change these
    functions only work on devices that have their own group.
    For all other devices the iommu_group_attach/detach
    functions must be used.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 49eb9bfe518e..ef73923db2f1 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -433,6 +433,17 @@ void iommu_group_remove_device(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(iommu_group_remove_device);
 
+static int iommu_group_device_count(struct iommu_group *group)
+{
+	struct iommu_device *entry;
+	int ret = 0;
+
+	list_for_each_entry(entry, &group->devices, list)
+		ret++;
+
+	return ret;
+}
+
 /**
  * iommu_group_for_each_dev - iterate over each device in the group
  * @group: the group
@@ -969,7 +980,8 @@ void iommu_domain_free(struct iommu_domain *domain)
 }
 EXPORT_SYMBOL_GPL(iommu_domain_free);
 
-int iommu_attach_device(struct iommu_domain *domain, struct device *dev)
+static int __iommu_attach_device(struct iommu_domain *domain,
+				 struct device *dev)
 {
 	int ret;
 	if (unlikely(domain->ops->attach_dev == NULL))
@@ -980,9 +992,38 @@ int iommu_attach_device(struct iommu_domain *domain, struct device *dev)
 		trace_attach_device_to_domain(dev);
 	return ret;
 }
+
+int iommu_attach_device(struct iommu_domain *domain, struct device *dev)
+{
+	struct iommu_group *group;
+	int ret;
+
+	group = iommu_group_get(dev);
+	/* FIXME: Remove this when groups a mandatory for iommu drivers */
+	if (group == NULL)
+		return __iommu_attach_device(domain, dev);
+
+	/*
+	 * We have a group - lock it to make sure the device-count doesn't
+	 * change while we are attaching
+	 */
+	mutex_lock(&group->mutex);
+	ret = -EINVAL;
+	if (iommu_group_device_count(group) != 1)
+		goto out_unlock;
+
+	ret = __iommu_attach_device(domain, dev);
+
+out_unlock:
+	mutex_unlock(&group->mutex);
+	iommu_group_put(group);
+
+	return ret;
+}
 EXPORT_SYMBOL_GPL(iommu_attach_device);
 
-void iommu_detach_device(struct iommu_domain *domain, struct device *dev)
+static void __iommu_detach_device(struct iommu_domain *domain,
+				  struct device *dev)
 {
 	if (unlikely(domain->ops->detach_dev == NULL))
 		return;
@@ -990,6 +1031,28 @@ void iommu_detach_device(struct iommu_domain *domain, struct device *dev)
 	domain->ops->detach_dev(domain, dev);
 	trace_detach_device_from_domain(dev);
 }
+
+void iommu_detach_device(struct iommu_domain *domain, struct device *dev)
+{
+	struct iommu_group *group;
+
+	group = iommu_group_get(dev);
+	/* FIXME: Remove this when groups a mandatory for iommu drivers */
+	if (group == NULL)
+		return __iommu_detach_device(domain, dev);
+
+	mutex_lock(&group->mutex);
+	if (iommu_group_device_count(group) != 1) {
+		WARN_ON(1);
+		goto out_unlock;
+	}
+
+	__iommu_detach_device(domain, dev);
+
+out_unlock:
+	mutex_unlock(&group->mutex);
+	iommu_group_put(group);
+}
 EXPORT_SYMBOL_GPL(iommu_detach_device);
 
 /*
@@ -1006,7 +1069,7 @@ static int iommu_group_do_attach_device(struct device *dev, void *data)
 {
 	struct iommu_domain *domain = data;
 
-	return iommu_attach_device(domain, dev);
+	return __iommu_attach_device(domain, dev);
 }
 
 int iommu_attach_group(struct iommu_domain *domain, struct iommu_group *group)
@@ -1020,7 +1083,7 @@ static int iommu_group_do_detach_device(struct device *dev, void *data)
 {
 	struct iommu_domain *domain = data;
 
-	iommu_detach_device(domain, dev);
+	__iommu_detach_device(domain, dev);
 
 	return 0;
 }

commit 53723dc59ff3ab504c739000b287ded49aeb2019
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu May 28 18:41:29 2015 +0200

    iommu: Allocate a default domain for iommu groups
    
    The default domain will be used (if supported by the iommu
    driver) when the devices in the iommu group are not attached
    to any other domain.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index d69e0ca77f82..49eb9bfe518e 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -51,6 +51,7 @@ struct iommu_group {
 	void (*iommu_data_release)(void *iommu_data);
 	char *name;
 	int id;
+	struct iommu_domain *default_domain;
 };
 
 struct iommu_device {
@@ -75,6 +76,9 @@ struct iommu_group_attribute iommu_group_attr_##_name =		\
 #define to_iommu_group(_kobj)		\
 	container_of(_kobj, struct iommu_group, kobj)
 
+static struct iommu_domain *__iommu_domain_alloc(struct bus_type *bus,
+						 unsigned type);
+
 static ssize_t iommu_group_attr_show(struct kobject *kobj,
 				     struct attribute *__attr, char *buf)
 {
@@ -137,6 +141,9 @@ static void iommu_group_release(struct kobject *kobj)
 	ida_remove(&iommu_group_ida, group->id);
 	mutex_unlock(&iommu_group_mutex);
 
+	if (group->default_domain)
+		iommu_domain_free(group->default_domain);
+
 	kfree(group->name);
 	kfree(group);
 }
@@ -701,7 +708,17 @@ static struct iommu_group *iommu_group_get_for_pci_dev(struct pci_dev *pdev)
 		return group;
 
 	/* No shared group found, allocate new */
-	return iommu_group_alloc();
+	group = iommu_group_alloc();
+	if (group) {
+		/*
+		 * Try to allocate a default domain - needs support from the
+		 * IOMMU driver.
+		 */
+		group->default_domain = __iommu_domain_alloc(pdev->dev.bus,
+							     IOMMU_DOMAIN_DMA);
+	}
+
+	return group;
 }
 
 /**
@@ -922,22 +939,28 @@ void iommu_set_fault_handler(struct iommu_domain *domain,
 }
 EXPORT_SYMBOL_GPL(iommu_set_fault_handler);
 
-struct iommu_domain *iommu_domain_alloc(struct bus_type *bus)
+static struct iommu_domain *__iommu_domain_alloc(struct bus_type *bus,
+						 unsigned type)
 {
 	struct iommu_domain *domain;
 
 	if (bus == NULL || bus->iommu_ops == NULL)
 		return NULL;
 
-	domain = bus->iommu_ops->domain_alloc(IOMMU_DOMAIN_UNMANAGED);
+	domain = bus->iommu_ops->domain_alloc(type);
 	if (!domain)
 		return NULL;
 
 	domain->ops  = bus->iommu_ops;
-	domain->type = IOMMU_DOMAIN_UNMANAGED;
+	domain->type = type;
 
 	return domain;
 }
+
+struct iommu_domain *iommu_domain_alloc(struct bus_type *bus)
+{
+	return __iommu_domain_alloc(bus, IOMMU_DOMAIN_UNMANAGED);
+}
 EXPORT_SYMBOL_GPL(iommu_domain_alloc);
 
 void iommu_domain_free(struct iommu_domain *domain)

commit 843cb6dc7749a25849797cc9aeeb86f87a8acb84
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu May 28 18:41:28 2015 +0200

    iommu: Call remove_device call-back after driver release
    
    Do not remove the device from the IOMMU while the driver is
    still attached.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index f0e0a233c902..d69e0ca77f82 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -779,7 +779,7 @@ static int iommu_bus_notifier(struct notifier_block *nb,
 	if (action == BUS_NOTIFY_ADD_DEVICE) {
 		if (ops->add_device)
 			return ops->add_device(dev);
-	} else if (action == BUS_NOTIFY_DEL_DEVICE) {
+	} else if (action == BUS_NOTIFY_REMOVED_DEVICE) {
 		if (ops->remove_device && dev->iommu_group) {
 			ops->remove_device(dev);
 			return 0;

commit 8da30142a21e2d7595510892a4c99cf294f7e6f1
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu May 28 18:41:27 2015 +0200

    iommu: Clean up after a failed bus initialization
    
    Make sure we call the ->remove_device call-back on all
    devices already initialized with ->add_device when the bus
    initialization fails.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 9c9336a923cd..f0e0a233c902 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -753,6 +753,17 @@ static int add_iommu_group(struct device *dev, void *data)
 	return ops->add_device(dev);
 }
 
+static int remove_iommu_group(struct device *dev, void *data)
+{
+	struct iommu_callback_data *cb = data;
+	const struct iommu_ops *ops = cb->ops;
+
+	if (ops->remove_device && dev->iommu_group)
+		ops->remove_device(dev);
+
+	return 0;
+}
+
 static int iommu_bus_notifier(struct notifier_block *nb,
 			      unsigned long action, void *data)
 {
@@ -821,19 +832,25 @@ static int iommu_bus_init(struct bus_type *bus, const struct iommu_ops *ops)
 	nb->notifier_call = iommu_bus_notifier;
 
 	err = bus_register_notifier(bus, nb);
-	if (err) {
-		kfree(nb);
-		return err;
-	}
+	if (err)
+		goto out_free;
 
 	err = bus_for_each_dev(bus, NULL, &cb, add_iommu_group);
-	if (err) {
-		bus_unregister_notifier(bus, nb);
-		kfree(nb);
-		return err;
-	}
+	if (err)
+		goto out_err;
+
 
 	return 0;
+
+out_err:
+	/* Clean up */
+	bus_for_each_dev(bus, NULL, &cb, remove_iommu_group);
+	bus_unregister_notifier(bus, nb);
+
+out_free:
+	kfree(nb);
+
+	return err;
 }
 
 /**

commit 19762d7095e6392b6ec56c363a6f29b2119488c2
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu May 28 18:41:26 2015 +0200

    iommu: Propagate error in add_iommu_group
    
    Make sure any errors reported from the IOMMU drivers get
    progapated back to the IOMMU core.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 755e4889046a..9c9336a923cd 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -750,9 +750,7 @@ static int add_iommu_group(struct device *dev, void *data)
 
 	WARN_ON(dev->iommu_group);
 
-	ops->add_device(dev);
-
-	return 0;
+	return ops->add_device(dev);
 }
 
 static int iommu_bus_notifier(struct notifier_block *nb,

commit 269aa808a990b3fdd0e7ec9e04322284c40748c4
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu May 28 18:41:25 2015 +0200

    iommu: Add a few printk messages to group handling code
    
    Write a message to the kernel log when a device is added or
    removed from a group and add debug messages to group
    allocation and release routines.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index c31bfd027979..755e4889046a 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -128,6 +128,8 @@ static void iommu_group_release(struct kobject *kobj)
 {
 	struct iommu_group *group = to_iommu_group(kobj);
 
+	pr_debug("Releasing group %d\n", group->id);
+
 	if (group->iommu_data_release)
 		group->iommu_data_release(group->iommu_data);
 
@@ -207,6 +209,8 @@ struct iommu_group *iommu_group_alloc(void)
 	 */
 	kobject_put(&group->kobj);
 
+	pr_debug("Allocated group %d\n", group->id);
+
 	return group;
 }
 EXPORT_SYMBOL_GPL(iommu_group_alloc);
@@ -372,6 +376,9 @@ int iommu_group_add_device(struct iommu_group *group, struct device *dev)
 				     IOMMU_GROUP_NOTIFY_ADD_DEVICE, dev);
 
 	trace_add_device_to_group(group->id, dev);
+
+	pr_info("Adding device %s to group %d\n", dev_name(dev), group->id);
+
 	return 0;
 }
 EXPORT_SYMBOL_GPL(iommu_group_add_device);
@@ -388,6 +395,8 @@ void iommu_group_remove_device(struct device *dev)
 	struct iommu_group *group = dev->iommu_group;
 	struct iommu_device *tmp_device, *device = NULL;
 
+	pr_info("Removing device %s from group %d\n", dev_name(dev), group->id);
+
 	/* Pre-notify listeners that a device is being removed. */
 	blocking_notifier_call_chain(&group->notifier,
 				     IOMMU_GROUP_NOTIFY_DEL_DEVICE, dev);

commit 92e7066fde31d5ac48a9bccc12d3063d251dd079
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu May 28 18:41:24 2015 +0200

    iommu: Remove function name from pr_fmt()
    
    Including the function name is only useful for debugging
    messages. They don't belong into other messages from the
    iommu core.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index d4f527e56679..c31bfd027979 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -16,7 +16,7 @@
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
 
-#define pr_fmt(fmt)    "%s: " fmt, __func__
+#define pr_fmt(fmt)    "iommu: " fmt
 
 #include <linux/device.h>
 #include <linux/kernel.h>

commit d7ef9995f1d9e394f994b9a1755cccb21ba3e421
Author: Marek Szyprowski <m.szyprowski@samsung.com>
Date:   Tue May 19 15:20:23 2015 +0200

    iommu: Init iommu-groups support earlier, in core_initcall
    
    iommu_group_alloc might be called very early in case of iommu controllers
    activated from of_iommu, so ensure that this part of subsystem is ready
    when devices are being populated from device-tree (core_initcall seems to
    be okay for this case).
    
    Signed-off-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Tested-by: Javier Martinez Canillas <javier.martinez@collabora.co.uk>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index d4f527e56679..37a6aa8f318b 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1207,7 +1207,7 @@ static int __init iommu_init(void)
 
 	return 0;
 }
-arch_initcall(iommu_init);
+core_initcall(iommu_init);
 
 int iommu_domain_get_attr(struct iommu_domain *domain,
 			  enum iommu_attr attr, void *data)

commit 89be34a1ced886880a3219f9d2ba2192dc738ef2
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu Mar 26 13:43:19 2015 +0100

    iommu: Remove domain_init and domain_free iommu_ops
    
    All drivers have been converted to the new domain_alloc and
    domain_free iommu-ops. So remove the old ones and get rid of
    iommu_domain->priv too, as this is no longer needed when the
    struct iommu_domain is embedded in the private structures of
    the iommu drivers.
    
    Tested-by: Thierry Reding <treding@nvidia.com>
    Tested-by: Heiko Stuebner <heiko@sntech.de>
    Reviewed-by: Alex Williamson <alex.williamson@redhat.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 656b9499e748..d4f527e56679 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -900,51 +900,25 @@ EXPORT_SYMBOL_GPL(iommu_set_fault_handler);
 
 struct iommu_domain *iommu_domain_alloc(struct bus_type *bus)
 {
-	const struct iommu_ops *ops;
 	struct iommu_domain *domain;
 
 	if (bus == NULL || bus->iommu_ops == NULL)
 		return NULL;
 
-	ops = bus->iommu_ops;
-
-	if (ops->domain_alloc)
-		domain = ops->domain_alloc(IOMMU_DOMAIN_UNMANAGED);
-	else
-		domain = kzalloc(sizeof(*domain), GFP_KERNEL);
-
+	domain = bus->iommu_ops->domain_alloc(IOMMU_DOMAIN_UNMANAGED);
 	if (!domain)
 		return NULL;
 
 	domain->ops  = bus->iommu_ops;
 	domain->type = IOMMU_DOMAIN_UNMANAGED;
 
-	if (ops->domain_init && domain->ops->domain_init(domain))
-		goto out_free;
-
 	return domain;
-
-out_free:
-	if (ops->domain_free)
-		ops->domain_free(domain);
-	else
-		kfree(domain);
-
-	return NULL;
 }
 EXPORT_SYMBOL_GPL(iommu_domain_alloc);
 
 void iommu_domain_free(struct iommu_domain *domain)
 {
-	const struct iommu_ops *ops = domain->ops;
-
-	if (likely(ops->domain_destroy != NULL))
-		ops->domain_destroy(domain);
-
-	if (ops->domain_free)
-		ops->domain_free(domain);
-	else
-		kfree(domain);
+	domain->ops->domain_free(domain);
 }
 EXPORT_SYMBOL_GPL(iommu_domain_free);
 

commit a10315e5efb86c689142a7e7927125889f3682e6
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu Mar 26 13:43:06 2015 +0100

    iommu: Only allow iommu_map/unmap for paging domains
    
    Check for the new __IOMMU_DOMAIN_PAGING flag before calling
    into the iommu drivers ->map and ->unmap call-backs.
    
    Tested-by: Thierry Reding <treding@nvidia.com>
    Tested-by: Heiko Stuebner <heiko@sntech.de>
    Reviewed-by: Alex Williamson <alex.williamson@redhat.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 4920605892a3..656b9499e748 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1063,6 +1063,9 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 		     domain->ops->pgsize_bitmap == 0UL))
 		return -ENODEV;
 
+	if (unlikely(!(domain->type & __IOMMU_DOMAIN_PAGING)))
+		return -EINVAL;
+
 	/* find out the minimum page size supported */
 	min_pagesz = 1 << __ffs(domain->ops->pgsize_bitmap);
 
@@ -1114,6 +1117,9 @@ size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
 		     domain->ops->pgsize_bitmap == 0UL))
 		return -ENODEV;
 
+	if (unlikely(!(domain->type & __IOMMU_DOMAIN_PAGING)))
+		return -EINVAL;
+
 	/* find out the minimum page size supported */
 	min_pagesz = 1 << __ffs(domain->ops->pgsize_bitmap);
 

commit 8539c7c16b970258e14761d8a1f7d10fe798031a
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu Mar 26 13:43:05 2015 +0100

    iommu: Introduce iommu domain types
    
    This allows to handle domains differently based on their
    type in the future. An IOMMU driver can implement certain
    optimizations for DMA-API domains for example.
    
    The domain types can be extended later and some of the
    existing domain attributes can be migrated to become domain
    flags.
    
    Tested-by: Thierry Reding <treding@nvidia.com>
    Tested-by: Heiko Stuebner <heiko@sntech.de>
    Reviewed-by: Alex Williamson <alex.williamson@redhat.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 11de2620bbf4..4920605892a3 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -909,14 +909,15 @@ struct iommu_domain *iommu_domain_alloc(struct bus_type *bus)
 	ops = bus->iommu_ops;
 
 	if (ops->domain_alloc)
-		domain = ops->domain_alloc();
+		domain = ops->domain_alloc(IOMMU_DOMAIN_UNMANAGED);
 	else
 		domain = kzalloc(sizeof(*domain), GFP_KERNEL);
 
 	if (!domain)
 		return NULL;
 
-	domain->ops = bus->iommu_ops;
+	domain->ops  = bus->iommu_ops;
+	domain->type = IOMMU_DOMAIN_UNMANAGED;
 
 	if (ops->domain_init && domain->ops->domain_init(domain))
 		goto out_free;

commit 938c470976192590b4adc921b2e10fa31237eddc
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu Mar 26 13:43:04 2015 +0100

    iommu: Introduce domain_alloc and domain_free iommu_ops
    
    These new call-backs defer the allocation and destruction of
    'struct iommu_domain' to the iommu driver. This allows
    drivers to embed this struct into their private domain
    structures and to get rid of the domain_init and
    domain_destroy call-backs when all drivers have been
    converted.
    
    Tested-by: Thierry Reding <treding@nvidia.com>
    Tested-by: Heiko Stuebner <heiko@sntech.de>
    Reviewed-by: Alex Williamson <alex.williamson@redhat.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 72e683df0731..11de2620bbf4 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -900,26 +900,34 @@ EXPORT_SYMBOL_GPL(iommu_set_fault_handler);
 
 struct iommu_domain *iommu_domain_alloc(struct bus_type *bus)
 {
+	const struct iommu_ops *ops;
 	struct iommu_domain *domain;
-	int ret;
 
 	if (bus == NULL || bus->iommu_ops == NULL)
 		return NULL;
 
-	domain = kzalloc(sizeof(*domain), GFP_KERNEL);
+	ops = bus->iommu_ops;
+
+	if (ops->domain_alloc)
+		domain = ops->domain_alloc();
+	else
+		domain = kzalloc(sizeof(*domain), GFP_KERNEL);
+
 	if (!domain)
 		return NULL;
 
 	domain->ops = bus->iommu_ops;
 
-	ret = domain->ops->domain_init(domain);
-	if (ret)
+	if (ops->domain_init && domain->ops->domain_init(domain))
 		goto out_free;
 
 	return domain;
 
 out_free:
-	kfree(domain);
+	if (ops->domain_free)
+		ops->domain_free(domain);
+	else
+		kfree(domain);
 
 	return NULL;
 }
@@ -927,10 +935,15 @@ EXPORT_SYMBOL_GPL(iommu_domain_alloc);
 
 void iommu_domain_free(struct iommu_domain *domain)
 {
-	if (likely(domain->ops->domain_destroy != NULL))
-		domain->ops->domain_destroy(domain);
+	const struct iommu_ops *ops = domain->ops;
 
-	kfree(domain);
+	if (likely(ops->domain_destroy != NULL))
+		ops->domain_destroy(domain);
+
+	if (ops->domain_free)
+		ops->domain_free(domain);
+	else
+		kfree(domain);
 }
 EXPORT_SYMBOL_GPL(iommu_domain_free);
 

commit 63ce3ae889db917cff0cf0c65c837ca7160c8a83
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Feb 4 16:12:55 2015 +0100

    iommu: Update my email address
    
    The AMD address is dead for a long time already, replace it
    with a working one.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 9e0dcdbf4110..72e683df0731 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1,6 +1,6 @@
 /*
  * Copyright (C) 2007-2008 Advanced Micro Devices, Inc.
- * Author: Joerg Roedel <joerg.roedel@amd.com>
+ * Author: Joerg Roedel <jroedel@suse.de>
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 as published

commit 860cd64d102d9b6c97830e09c447a9a850ea7641
Author: Shuah Khan <shuahkh@osg.samsung.com>
Date:   Thu Jan 15 19:29:43 2015 -0700

    iommu: Fix trace_map() to report original iova and original size
    
    iommu_map() calls trace_map() with iova and size. trace_map()
    should report original iova and original size as opposed to
    iova and size after they get changed during mapping. size is
    always zero at the end of mapping which is useless to report
    and iova as it gets incremented, it is not as useful as the
    original iova. Change iommu_map() to call trace_map() to
    report original iova and original size.
    
    Signed-off-by: Shuah Khan <shuahkh@osg.samsung.com>
    Reported-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 3a4fb6274c99..9e0dcdbf4110 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1084,7 +1084,7 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 	if (ret)
 		iommu_unmap(domain, orig_iova, orig_size - size);
 	else
-		trace_map(iova, paddr, size);
+		trace_map(orig_iova, paddr, orig_size);
 
 	return ret;
 }

commit db8614d35bb8fc6d032792c801bd5b38ce860f19
Author: Shuah Khan <shuahkh@osg.samsung.com>
Date:   Fri Jan 16 20:53:17 2015 -0700

    iommu: Change trace unmap api to report unmapped size
    
    Currently map and unmap are implemented as events under a
    common trace class declaration. The common class forces
    trace_unmap() to require a bogus physical address argument
    that it doesn't use. Changing unmap to report unmapped size
    will provide useful information for debugging. Remove common
    map_unmap trace class and change map and unmap into separate
    events as opposed to events under the same class to allow for
    differences in the reporting information. In addition, map and
    unmap are changed to handle size value as size_t instead of int
    to match the passed size value and avoid overflow.
    
    Signed-off-by: Shuah Khan <shuahkh@osg.samsung.com>
    Suggested-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index d4c3db5abf25..3a4fb6274c99 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1134,7 +1134,7 @@ size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
 		unmapped += unmapped_page;
 	}
 
-	trace_unmap(orig_iova, 0, size);
+	trace_unmap(orig_iova, size, unmapped);
 	return unmapped;
 }
 EXPORT_SYMBOL_GPL(iommu_unmap);

commit 6fd492fd746d9858a41dc85eef44bd627b809109
Author: Shuah Khan <shuahkh@osg.samsung.com>
Date:   Fri Jan 16 16:47:19 2015 -0700

    iommu: Fix trace_unmap() to report original iova
    
    iommu_unmap() calls trace_unmap() with changed iova and original
    size. trace_unmap() should report original iova instead. Change
    iommu_unmap() to call trace_unmap() with original iova.
    
    Signed-off-by: Shuah Khan <shuahkh@osg.samsung.com>
    Reported-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index f7718d73e984..d4c3db5abf25 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1094,6 +1094,7 @@ size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
 {
 	size_t unmapped_page, unmapped = 0;
 	unsigned int min_pagesz;
+	unsigned long orig_iova = iova;
 
 	if (unlikely(domain->ops->unmap == NULL ||
 		     domain->ops->pgsize_bitmap == 0UL))
@@ -1133,7 +1134,7 @@ size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
 		unmapped += unmapped_page;
 	}
 
-	trace_unmap(iova, 0, size);
+	trace_unmap(orig_iova, 0, size);
 	return unmapped;
 }
 EXPORT_SYMBOL_GPL(iommu_unmap);

commit 6f51ee709e4c6b56f2c2a071da2d056a109b9d26
Merge: 205dc205ed3b fd522d279235
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 16 14:53:01 2014 -0800

    Merge tag 'iommu-config-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/arm/arm-soc
    
    Pull ARM SoC/iommu configuration update from Arnd Bergmann:
     "The iomm-config branch contains work from Will Deacon, quoting his
      description:
    
        This series adds automatic IOMMU and DMA-mapping configuration for
        OF-based DMA masters described using the generic IOMMU devicetree
        bindings. Although there is plenty of future work around splitting up
        iommu_ops, adding default IOMMU domains and sorting out automatic IOMMU
        group creation for the platform_bus, this is already useful enough for
        people to port over their IOMMU drivers and start using the new probing
        infrastructure (indeed, Marek has patches queued for the Exynos IOMMU).
    
      The branch touches core ARM and IOMMU driver files, and the respective
      maintainers (Russell King and Joerg Roedel) agreed to have the
      contents merged through the arm-soc tree.
    
      The final version was ready just before the merge window, so we ended
      up delaying it a bit longer than the rest, but we don't expect to see
      regressions because this is just additional infrastructure that will
      get used in drivers starting in 3.20 but is unused so far"
    
    * tag 'iommu-config-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/arm/arm-soc:
      iommu: store DT-probed IOMMU data privately
      arm: dma-mapping: plumb our iommu mapping ops into arch_setup_dma_ops
      arm: call iommu_init before of_platform_populate
      dma-mapping: detect and configure IOMMU in of_dma_configure
      iommu: fix initialization without 'add_device' callback
      iommu: provide helper function to configure an IOMMU for an of master
      iommu: add new iommu_ops callback for adding an OF device
      dma-mapping: replace set_arch_dma_coherent_ops with arch_setup_dma_ops
      iommu: provide early initialisation hook for IOMMU drivers

commit 18f23409909a9547ac7c149013286f36fcffa433
Author: Robin Murphy <robin.murphy@arm.com>
Date:   Tue Nov 25 17:50:55 2014 +0000

    iommu: Decouple iommu_map_sg from CPU page size
    
    If the IOMMU supports pages smaller than the CPU page size, segments
    which lie at offsets within the CPU page may be mapped based on the
    finer-grained IOMMU page boundaries. This minimises the amount of
    non-buffer memory between the CPU page boundary and the start of the
    segment which must be mapped and therefore exposed to the device, and
    brings the default iommu_map_sg implementation in line with
    iommu_map/unmap with respect to alignment.
    
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 02e4313e937c..1bd63352ab17 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1143,14 +1143,24 @@ size_t default_iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
 {
 	struct scatterlist *s;
 	size_t mapped = 0;
-	unsigned int i;
+	unsigned int i, min_pagesz;
 	int ret;
 
-	for_each_sg(sg, s, nents, i) {
-		phys_addr_t phys = page_to_phys(sg_page(s));
+	if (unlikely(domain->ops->pgsize_bitmap == 0UL))
+		return 0;
 
-		/* We are mapping on page boundarys, so offset must be 0 */
-		if (s->offset)
+	min_pagesz = 1 << __ffs(domain->ops->pgsize_bitmap);
+
+	for_each_sg(sg, s, nents, i) {
+		phys_addr_t phys = page_to_phys(sg_page(s)) + s->offset;
+
+		/*
+		 * We are mapping on IOMMU page boundaries, so offset within
+		 * the page must be 0. However, the IOMMU may support pages
+		 * smaller than PAGE_SIZE, so s->offset may still represent
+		 * an offset of that boundary within the CPU page.
+		 */
+		if (!IS_ALIGNED(s->offset, min_pagesz))
 			goto out_err;
 
 		ret = iommu_map(domain, iova + mapped, phys, s->length, prot);

commit 461bfb3fe7d0cf64d9ee2190ad8507e460fab198
Author: Marek Szyprowski <m.szyprowski@samsung.com>
Date:   Wed Nov 19 11:15:31 2014 +0000

    iommu: fix initialization without 'add_device' callback
    
    IOMMU drivers can be initialized from of_iommu helpers. Such drivers don't
    need to provide device_add callbacks to operate properly, so there is no
    need to fail initialization if the callback is missing.
    
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index ed8b04867b1f..02f798b7e295 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -737,7 +737,7 @@ static int add_iommu_group(struct device *dev, void *data)
 	const struct iommu_ops *ops = cb->ops;
 
 	if (!ops->add_device)
-		return -ENODEV;
+		return 0;
 
 	WARN_ON(dev->iommu_group);
 

commit d7da6bdc322bb79c4326dff7c2727236a48c4be9
Author: Heiko Stübner <heiko@sntech.de>
Date:   Wed Oct 29 01:22:56 2014 +0100

    iommu: Improve error handling when setting bus iommu
    
    When some part of bus_set_iommu fails it should undo any made changes
    and not simply leave everything as is.
    
    This includes unregistering the bus notifier in iommu_bus_init when
    add_iommu_group fails and also setting the bus->iommu_ops back to NULL.
    
    Signed-off-by: Heiko Stuebner <heiko@sntech.de>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 08c53c5a046f..02e4313e937c 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -818,7 +818,15 @@ static int iommu_bus_init(struct bus_type *bus, const struct iommu_ops *ops)
 		kfree(nb);
 		return err;
 	}
-	return bus_for_each_dev(bus, NULL, &cb, add_iommu_group);
+
+	err = bus_for_each_dev(bus, NULL, &cb, add_iommu_group);
+	if (err) {
+		bus_unregister_notifier(bus, nb);
+		kfree(nb);
+		return err;
+	}
+
+	return 0;
 }
 
 /**
@@ -836,13 +844,19 @@ static int iommu_bus_init(struct bus_type *bus, const struct iommu_ops *ops)
  */
 int bus_set_iommu(struct bus_type *bus, const struct iommu_ops *ops)
 {
+	int err;
+
 	if (bus->iommu_ops != NULL)
 		return -EBUSY;
 
 	bus->iommu_ops = ops;
 
 	/* Do IOMMU specific setup for this bus-type */
-	return iommu_bus_init(bus, ops);
+	err = iommu_bus_init(bus, ops);
+	if (err)
+		bus->iommu_ops = NULL;
+
+	return err;
 }
 EXPORT_SYMBOL_GPL(bus_set_iommu);
 

commit 38ec010d9b04ed94845f8ff6f10d33eb6bbfe180
Author: Joerg Roedel <jroedel@suse.de>
Date:   Tue Nov 4 14:53:51 2014 +0100

    iommu: Do more input validation in iommu_map_sg()
    
    The IOMMU-API works on page boundarys, unlike the DMA-API
    which can work with sub-page buffers. The sg->offset
    field does not make sense on the IOMMU level, so force it to
    be 0. Do some error-path consolidation while at it.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 46727ce9280d..08c53c5a046f 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1127,26 +1127,33 @@ EXPORT_SYMBOL_GPL(iommu_unmap);
 size_t default_iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
 			 struct scatterlist *sg, unsigned int nents, int prot)
 {
-	int ret;
+	struct scatterlist *s;
 	size_t mapped = 0;
 	unsigned int i;
-	struct scatterlist *s;
+	int ret;
 
 	for_each_sg(sg, s, nents, i) {
 		phys_addr_t phys = page_to_phys(sg_page(s));
-		size_t page_len = s->offset + s->length;
 
-		ret = iommu_map(domain, iova + mapped, phys, page_len, prot);
-		if (ret) {
-			/* undo mappings already done */
-			iommu_unmap(domain, iova, mapped);
-			mapped = 0;
-			break;
-		}
-		mapped += page_len;
+		/* We are mapping on page boundarys, so offset must be 0 */
+		if (s->offset)
+			goto out_err;
+
+		ret = iommu_map(domain, iova + mapped, phys, s->length, prot);
+		if (ret)
+			goto out_err;
+
+		mapped += s->length;
 	}
 
 	return mapped;
+
+out_err:
+	/* undo mappings already done */
+	iommu_unmap(domain, iova, mapped);
+
+	return 0;
+
 }
 EXPORT_SYMBOL_GPL(default_iommu_map_sg);
 

commit 315786ebbf4ad6552b6fd8e0e7b2ea220fcbfdbd
Author: Olav Haugan <ohaugan@codeaurora.org>
Date:   Sat Oct 25 09:55:16 2014 -0700

    iommu: Add iommu_map_sg() function
    
    Mapping and unmapping are more often than not in the critical path.
    map_sg allows IOMMU driver implementations to optimize the process
    of mapping buffers into the IOMMU page tables.
    
    Instead of mapping a buffer one page at a time and requiring potentially
    expensive TLB operations for each page, this function allows the driver
    to map all pages in one go and defer TLB maintenance until after all
    pages have been mapped.
    
    Additionally, the mapping operation would be faster in general since
    clients does not have to keep calling map API over and over again for
    each physically contiguous chunk of memory that needs to be mapped to a
    virtually contiguous region.
    
    Signed-off-by: Olav Haugan <ohaugan@codeaurora.org>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index ed8b04867b1f..46727ce9280d 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -1124,6 +1124,31 @@ size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
 }
 EXPORT_SYMBOL_GPL(iommu_unmap);
 
+size_t default_iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
+			 struct scatterlist *sg, unsigned int nents, int prot)
+{
+	int ret;
+	size_t mapped = 0;
+	unsigned int i;
+	struct scatterlist *s;
+
+	for_each_sg(sg, s, nents, i) {
+		phys_addr_t phys = page_to_phys(sg_page(s));
+		size_t page_len = s->offset + s->length;
+
+		ret = iommu_map(domain, iova + mapped, phys, page_len, prot);
+		if (ret) {
+			/* undo mappings already done */
+			iommu_unmap(domain, iova, mapped);
+			mapped = 0;
+			break;
+		}
+		mapped += page_len;
+	}
+
+	return mapped;
+}
+EXPORT_SYMBOL_GPL(default_iommu_map_sg);
 
 int iommu_domain_window_enable(struct iommu_domain *domain, u32 wnd_nr,
 			       phys_addr_t paddr, u64 size, int prot)

commit fb3e306515ba6a012364b698b8ca71c337424ed3
Author: Mark Salter <msalter@redhat.com>
Date:   Sun Sep 21 13:58:24 2014 -0400

    iommu: Fix bus notifier breakage
    
    iommu_bus_init() registers a bus notifier on the given bus by using
    a statically defined notifier block:
    
      static struct notifier_block iommu_bus_nb = {
              .notifier_call = iommu_bus_notifier,
      };
    
    This same notifier block is used for all busses. This causes a
    problem for notifiers registered after iommu has registered this
    callback on multiple busses. The problem is that a subsequent
    notifier being registered on a bus which has this iommu notifier
    will also get linked in to the notifier list of all other busses
    which have this iommu notifier.
    
    This patch fixes this by allocating the notifier_block at runtime.
    Some error checking is also added to catch any allocation failure
    or notifier registration error.
    
    Signed-off-by: Mark Salter <msalter@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index b59826aa5531..ed8b04867b1f 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -799,18 +799,26 @@ static int iommu_bus_notifier(struct notifier_block *nb,
 	return 0;
 }
 
-static struct notifier_block iommu_bus_nb = {
-	.notifier_call = iommu_bus_notifier,
-};
-
-static void iommu_bus_init(struct bus_type *bus, const struct iommu_ops *ops)
+static int iommu_bus_init(struct bus_type *bus, const struct iommu_ops *ops)
 {
+	int err;
+	struct notifier_block *nb;
 	struct iommu_callback_data cb = {
 		.ops = ops,
 	};
 
-	bus_register_notifier(bus, &iommu_bus_nb);
-	bus_for_each_dev(bus, NULL, &cb, add_iommu_group);
+	nb = kzalloc(sizeof(struct notifier_block), GFP_KERNEL);
+	if (!nb)
+		return -ENOMEM;
+
+	nb->notifier_call = iommu_bus_notifier;
+
+	err = bus_register_notifier(bus, nb);
+	if (err) {
+		kfree(nb);
+		return err;
+	}
+	return bus_for_each_dev(bus, NULL, &cb, add_iommu_group);
 }
 
 /**
@@ -834,9 +842,7 @@ int bus_set_iommu(struct bus_type *bus, const struct iommu_ops *ops)
 	bus->iommu_ops = ops;
 
 	/* Do IOMMU specific setup for this bus-type */
-	iommu_bus_init(bus, ops);
-
-	return 0;
+	return iommu_bus_init(bus, ops);
 }
 EXPORT_SYMBOL_GPL(bus_set_iommu);
 

commit f096c061f5525d1b35a65b793057b52061dcb486
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Fri Sep 19 10:03:06 2014 -0600

    iommu: Rework iommu_group_get_for_pci_dev()
    
    It turns out that our assumption that aliases are always to the same
    slot isn't true.  One particular platform reports an IVRS alias of the
    SATA controller (00:11.0) for the legacy IDE controller (00:14.1).
    When we hit this, we attempt to use a single IOMMU group for
    everything on the same bus, which in this case is the root complex.
    We already have multiple groups defined for the root complex by this
    point, resulting in multiple WARN_ON hits.
    
    This patch makes these sorts of aliases work again with IOMMU groups
    by reworking how we search through the PCI address space to find
    existing groups.  This should also now handle looped dependencies and
    all sorts of crazy inter-dependencies that we'll likely never see.
    
    The recursion used here should never be very deep.  It's unlikely to
    have individual aliases and only theoretical that we'd ever see a
    chain where one alias causes us to search through to yet another
    alias.  We're also only dealing with PCIe device on a single bus,
    which means we'll typically only see multiple slots in use on the root
    complex.  Loops are also a theoretically possibility, which I've
    tested using fake DMA alias quirks and prevent from causing problems
    using a bitmap of the devfn space that's been visited.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Cc: stable@vger.kernel.org # 3.17
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index d2d242fcaa3d..b59826aa5531 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -30,6 +30,7 @@
 #include <linux/notifier.h>
 #include <linux/err.h>
 #include <linux/pci.h>
+#include <linux/bitops.h>
 #include <trace/events/iommu.h>
 
 static struct kset *iommu_group_kset;
@@ -519,6 +520,9 @@ int iommu_group_id(struct iommu_group *group)
 }
 EXPORT_SYMBOL_GPL(iommu_group_id);
 
+static struct iommu_group *get_pci_alias_group(struct pci_dev *pdev,
+					       unsigned long *devfns);
+
 /*
  * To consider a PCI device isolated, we require ACS to support Source
  * Validation, Request Redirection, Completer Redirection, and Upstream
@@ -529,6 +533,86 @@ EXPORT_SYMBOL_GPL(iommu_group_id);
  */
 #define REQ_ACS_FLAGS   (PCI_ACS_SV | PCI_ACS_RR | PCI_ACS_CR | PCI_ACS_UF)
 
+/*
+ * For multifunction devices which are not isolated from each other, find
+ * all the other non-isolated functions and look for existing groups.  For
+ * each function, we also need to look for aliases to or from other devices
+ * that may already have a group.
+ */
+static struct iommu_group *get_pci_function_alias_group(struct pci_dev *pdev,
+							unsigned long *devfns)
+{
+	struct pci_dev *tmp = NULL;
+	struct iommu_group *group;
+
+	if (!pdev->multifunction || pci_acs_enabled(pdev, REQ_ACS_FLAGS))
+		return NULL;
+
+	for_each_pci_dev(tmp) {
+		if (tmp == pdev || tmp->bus != pdev->bus ||
+		    PCI_SLOT(tmp->devfn) != PCI_SLOT(pdev->devfn) ||
+		    pci_acs_enabled(tmp, REQ_ACS_FLAGS))
+			continue;
+
+		group = get_pci_alias_group(tmp, devfns);
+		if (group) {
+			pci_dev_put(tmp);
+			return group;
+		}
+	}
+
+	return NULL;
+}
+
+/*
+ * Look for aliases to or from the given device for exisiting groups.  The
+ * dma_alias_devfn only supports aliases on the same bus, therefore the search
+ * space is quite small (especially since we're really only looking at pcie
+ * device, and therefore only expect multiple slots on the root complex or
+ * downstream switch ports).  It's conceivable though that a pair of
+ * multifunction devices could have aliases between them that would cause a
+ * loop.  To prevent this, we use a bitmap to track where we've been.
+ */
+static struct iommu_group *get_pci_alias_group(struct pci_dev *pdev,
+					       unsigned long *devfns)
+{
+	struct pci_dev *tmp = NULL;
+	struct iommu_group *group;
+
+	if (test_and_set_bit(pdev->devfn & 0xff, devfns))
+		return NULL;
+
+	group = iommu_group_get(&pdev->dev);
+	if (group)
+		return group;
+
+	for_each_pci_dev(tmp) {
+		if (tmp == pdev || tmp->bus != pdev->bus)
+			continue;
+
+		/* We alias them or they alias us */
+		if (((pdev->dev_flags & PCI_DEV_FLAGS_DMA_ALIAS_DEVFN) &&
+		     pdev->dma_alias_devfn == tmp->devfn) ||
+		    ((tmp->dev_flags & PCI_DEV_FLAGS_DMA_ALIAS_DEVFN) &&
+		     tmp->dma_alias_devfn == pdev->devfn)) {
+
+			group = get_pci_alias_group(tmp, devfns);
+			if (group) {
+				pci_dev_put(tmp);
+				return group;
+			}
+
+			group = get_pci_function_alias_group(tmp, devfns);
+			if (group) {
+				pci_dev_put(tmp);
+				return group;
+			}
+		}
+	}
+
+	return NULL;
+}
+
 struct group_for_pci_data {
 	struct pci_dev *pdev;
 	struct iommu_group *group;
@@ -557,7 +641,7 @@ static struct iommu_group *iommu_group_get_for_pci_dev(struct pci_dev *pdev)
 	struct group_for_pci_data data;
 	struct pci_bus *bus;
 	struct iommu_group *group = NULL;
-	struct pci_dev *tmp;
+	u64 devfns[4] = { 0 };
 
 	/*
 	 * Find the upstream DMA alias for the device.  A device must not
@@ -591,76 +675,21 @@ static struct iommu_group *iommu_group_get_for_pci_dev(struct pci_dev *pdev)
 	}
 
 	/*
-	 * Next we need to consider DMA alias quirks.  If one device aliases
-	 * to another, they should be grouped together.  It's theoretically
-	 * possible that aliases could create chains of devices where each
-	 * device aliases another device.  If we then factor in multifunction
-	 * ACS grouping requirements, each alias could incorporate a new slot
-	 * with multiple functions, each with aliases.  This is all extremely
-	 * unlikely as DMA alias quirks are typically only used for PCIe
-	 * devices where we usually have a single slot per bus.  Furthermore,
-	 * the alias quirk is usually to another function within the slot
-	 * (and ACS multifunction is not supported) or to a different slot
-	 * that doesn't physically exist.  The likely scenario is therefore
-	 * that everything on the bus gets grouped together.  To reduce the
-	 * problem space, share the IOMMU group for all devices on the bus
-	 * if a DMA alias quirk is present on the bus.
-	 */
-	tmp = NULL;
-	for_each_pci_dev(tmp) {
-		if (tmp->bus != pdev->bus ||
-		    !(tmp->dev_flags & PCI_DEV_FLAGS_DMA_ALIAS_DEVFN))
-			continue;
-
-		pci_dev_put(tmp);
-		tmp = NULL;
-
-		/* We have an alias quirk, search for an existing group */
-		for_each_pci_dev(tmp) {
-			struct iommu_group *group_tmp;
-
-			if (tmp->bus != pdev->bus)
-				continue;
-
-			group_tmp = iommu_group_get(&tmp->dev);
-			if (!group) {
-				group = group_tmp;
-				continue;
-			}
-
-			if (group_tmp) {
-				WARN_ON(group != group_tmp);
-				iommu_group_put(group_tmp);
-			}
-		}
-
-		return group ? group : iommu_group_alloc();
-	}
-
-	/*
-	 * Non-multifunction devices or multifunction devices supporting
-	 * ACS get their own group.
+	 * Look for existing groups on device aliases.  If we alias another
+	 * device or another device aliases us, use the same group.
 	 */
-	if (!pdev->multifunction || pci_acs_enabled(pdev, REQ_ACS_FLAGS))
-		return iommu_group_alloc();
+	group = get_pci_alias_group(pdev, (unsigned long *)devfns);
+	if (group)
+		return group;
 
 	/*
-	 * Multifunction devices not supporting ACS share a group with other
-	 * similar devices in the same slot.
+	 * Look for existing groups on non-isolated functions on the same
+	 * slot and aliases of those funcions, if any.  No need to clear
+	 * the search bitmap, the tested devfns are still valid.
 	 */
-	tmp = NULL;
-	for_each_pci_dev(tmp) {
-		if (tmp == pdev || tmp->bus != pdev->bus ||
-		    PCI_SLOT(tmp->devfn) !=  PCI_SLOT(pdev->devfn) ||
-		    pci_acs_enabled(tmp, REQ_ACS_FLAGS))
-			continue;
-
-		group = iommu_group_get(&tmp->dev);
-		if (group) {
-			pci_dev_put(tmp);
-			return group;
-		}
-	}
+	group = get_pci_function_alias_group(pdev, (unsigned long *)devfns);
+	if (group)
+		return group;
 
 	/* No shared group found, allocate new */
 	return iommu_group_alloc();

commit 24278a24d88ae730229417e5d3bd452d7545fbcc
Author: Joerg Roedel <jroedel@suse.de>
Date:   Fri Sep 5 10:57:11 2014 +0200

    iommu: Remove iommu_domain_has_cap() API function
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index aeb243f46332..d2d242fcaa3d 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -956,19 +956,6 @@ phys_addr_t iommu_iova_to_phys(struct iommu_domain *domain, dma_addr_t iova)
 }
 EXPORT_SYMBOL_GPL(iommu_iova_to_phys);
 
-int iommu_domain_has_cap(struct iommu_domain *domain,
-			 enum iommu_cap cap)
-{
-	if (domain->ops->domain_has_cap != NULL)
-		return domain->ops->domain_has_cap(domain, cap);
-
-	if (domain->ops->capable != NULL)
-		return domain->ops->capable(cap);
-
-	return 0;
-}
-EXPORT_SYMBOL_GPL(iommu_domain_has_cap);
-
 static size_t iommu_pgsize(struct iommu_domain *domain,
 			   unsigned long addr_merge, size_t size)
 {

commit 3c0e0ca0a4e757159d868c4870556515d66b6c97
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Sep 3 18:47:25 2014 +0200

    iommu: Introduce iommu_capable API function
    
    This function will replace the current iommu_domain_has_cap
    function and clean up the interface while at it.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index bc45478e26db..aeb243f46332 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -817,6 +817,15 @@ bool iommu_present(struct bus_type *bus)
 }
 EXPORT_SYMBOL_GPL(iommu_present);
 
+bool iommu_capable(struct bus_type *bus, enum iommu_cap cap)
+{
+	if (!bus->iommu_ops || !bus->iommu_ops->capable)
+		return false;
+
+	return bus->iommu_ops->capable(cap);
+}
+EXPORT_SYMBOL_GPL(iommu_capable);
+
 /**
  * iommu_set_fault_handler() - set a fault handler for an iommu domain
  * @domain: iommu domain
@@ -950,10 +959,13 @@ EXPORT_SYMBOL_GPL(iommu_iova_to_phys);
 int iommu_domain_has_cap(struct iommu_domain *domain,
 			 enum iommu_cap cap)
 {
-	if (unlikely(domain->ops->domain_has_cap == NULL))
-		return 0;
+	if (domain->ops->domain_has_cap != NULL)
+		return domain->ops->domain_has_cap(domain, cap);
+
+	if (domain->ops->capable != NULL)
+		return domain->ops->capable(cap);
 
-	return domain->ops->domain_has_cap(domain, cap);
+	return 0;
 }
 EXPORT_SYMBOL_GPL(iommu_domain_has_cap);
 

commit 1aed074869a9cbe0a846ea7b254d8fd9a4a4d31f
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Sep 3 18:34:04 2014 +0200

    iommu: Convert iommu-caps from define to enum
    
    Allow compile-time type-checking.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 0639b9274b11..bc45478e26db 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -948,7 +948,7 @@ phys_addr_t iommu_iova_to_phys(struct iommu_domain *domain, dma_addr_t iova)
 EXPORT_SYMBOL_GPL(iommu_iova_to_phys);
 
 int iommu_domain_has_cap(struct iommu_domain *domain,
-			 unsigned long cap)
+			 enum iommu_cap cap)
 {
 	if (unlikely(domain->ops->domain_has_cap == NULL))
 		return 0;

commit c4a783b89ee3fc1201510ecf204278da4ccb0993
Author: Joerg Roedel <jroedel@suse.de>
Date:   Thu Aug 21 22:32:08 2014 +0200

    iommu/core: Make iommu_group_get_for_dev() more robust
    
    When a non-PCI device is passed to that function it might
    pass group == NULL to iommu_group_add_device() which then
    dereferences it and cause a crash this way. Fix it by
    just returning an error for non-PCI devices.
    
    Fixes: 104a1c13ac66e40cf8c6ae74d76ff14ff24b9b01
    Cc: Alex Williamson <alex.williamson@redhat.com>
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index ac4adb337038..0639b9274b11 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -678,15 +678,17 @@ static struct iommu_group *iommu_group_get_for_pci_dev(struct pci_dev *pdev)
  */
 struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 {
-	struct iommu_group *group = ERR_PTR(-EIO);
+	struct iommu_group *group;
 	int ret;
 
 	group = iommu_group_get(dev);
 	if (group)
 		return group;
 
-	if (dev_is_pci(dev))
-		group = iommu_group_get_for_pci_dev(to_pci_dev(dev));
+	if (!dev_is_pci(dev))
+		return ERR_PTR(-EINVAL);
+
+	group = iommu_group_get_for_pci_dev(to_pci_dev(dev));
 
 	if (IS_ERR(group))
 		return group;

commit 9db4ad9183aad0e9567f6afb23db1bdc9aa6c2a9
Author: Joerg Roedel <jroedel@suse.de>
Date:   Tue Aug 19 00:19:26 2014 +0200

    iommu/core: Check for the right function pointer in iommu_map()
    
    Check for the ->map and not the ->unmap pointer.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 169836020208..ac4adb337038 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -995,7 +995,7 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 	size_t orig_size = size;
 	int ret = 0;
 
-	if (unlikely(domain->ops->unmap == NULL ||
+	if (unlikely(domain->ops->map == NULL ||
 		     domain->ops->pgsize_bitmap == 0UL))
 		return -ENODEV;
 

commit b22f6434cf48af001330e370e9d781aeb668f98c
Author: Thierry Reding <treding@nvidia.com>
Date:   Fri Jun 27 09:03:12 2014 +0200

    iommu: Constify struct iommu_ops
    
    This structure is read-only data and should never be modified.
    
    Signed-off-by: Thierry Reding <treding@nvidia.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index d061c8677a81..169836020208 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -36,6 +36,10 @@ static struct kset *iommu_group_kset;
 static struct ida iommu_group_ida;
 static struct mutex iommu_group_mutex;
 
+struct iommu_callback_data {
+	const struct iommu_ops *ops;
+};
+
 struct iommu_group {
 	struct kobject kobj;
 	struct kobject *devices_kobj;
@@ -698,7 +702,8 @@ struct iommu_group *iommu_group_get_for_dev(struct device *dev)
 
 static int add_iommu_group(struct device *dev, void *data)
 {
-	struct iommu_ops *ops = data;
+	struct iommu_callback_data *cb = data;
+	const struct iommu_ops *ops = cb->ops;
 
 	if (!ops->add_device)
 		return -ENODEV;
@@ -714,7 +719,7 @@ static int iommu_bus_notifier(struct notifier_block *nb,
 			      unsigned long action, void *data)
 {
 	struct device *dev = data;
-	struct iommu_ops *ops = dev->bus->iommu_ops;
+	const struct iommu_ops *ops = dev->bus->iommu_ops;
 	struct iommu_group *group;
 	unsigned long group_action = 0;
 
@@ -767,10 +772,14 @@ static struct notifier_block iommu_bus_nb = {
 	.notifier_call = iommu_bus_notifier,
 };
 
-static void iommu_bus_init(struct bus_type *bus, struct iommu_ops *ops)
+static void iommu_bus_init(struct bus_type *bus, const struct iommu_ops *ops)
 {
+	struct iommu_callback_data cb = {
+		.ops = ops,
+	};
+
 	bus_register_notifier(bus, &iommu_bus_nb);
-	bus_for_each_dev(bus, NULL, ops, add_iommu_group);
+	bus_for_each_dev(bus, NULL, &cb, add_iommu_group);
 }
 
 /**
@@ -786,7 +795,7 @@ static void iommu_bus_init(struct bus_type *bus, struct iommu_ops *ops)
  * is set up. With this function the iommu-driver can set the iommu-ops
  * afterwards.
  */
-int bus_set_iommu(struct bus_type *bus, struct iommu_ops *ops)
+int bus_set_iommu(struct bus_type *bus, const struct iommu_ops *ops)
 {
 	if (bus->iommu_ops != NULL)
 		return -EBUSY;

commit 104a1c13ac66e40cf8c6ae74d76ff14ff24b9b01
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Thu Jul 3 09:51:18 2014 -0600

    iommu/core: Create central IOMMU group lookup/creation interface
    
    Currently each IOMMU driver that supports IOMMU groups has its own
    code for discovering the base device used in grouping.  This code
    is generally not specific to the IOMMU hardware, but to the bus of
    the devices managed by the IOMMU.  We can therefore create a common
    interface for supporting devices on different buses.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index e5555fcfe703..d061c8677a81 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -29,6 +29,7 @@
 #include <linux/idr.h>
 #include <linux/notifier.h>
 #include <linux/err.h>
+#include <linux/pci.h>
 #include <trace/events/iommu.h>
 
 static struct kset *iommu_group_kset;
@@ -514,6 +515,187 @@ int iommu_group_id(struct iommu_group *group)
 }
 EXPORT_SYMBOL_GPL(iommu_group_id);
 
+/*
+ * To consider a PCI device isolated, we require ACS to support Source
+ * Validation, Request Redirection, Completer Redirection, and Upstream
+ * Forwarding.  This effectively means that devices cannot spoof their
+ * requester ID, requests and completions cannot be redirected, and all
+ * transactions are forwarded upstream, even as it passes through a
+ * bridge where the target device is downstream.
+ */
+#define REQ_ACS_FLAGS   (PCI_ACS_SV | PCI_ACS_RR | PCI_ACS_CR | PCI_ACS_UF)
+
+struct group_for_pci_data {
+	struct pci_dev *pdev;
+	struct iommu_group *group;
+};
+
+/*
+ * DMA alias iterator callback, return the last seen device.  Stop and return
+ * the IOMMU group if we find one along the way.
+ */
+static int get_pci_alias_or_group(struct pci_dev *pdev, u16 alias, void *opaque)
+{
+	struct group_for_pci_data *data = opaque;
+
+	data->pdev = pdev;
+	data->group = iommu_group_get(&pdev->dev);
+
+	return data->group != NULL;
+}
+
+/*
+ * Use standard PCI bus topology, isolation features, and DMA alias quirks
+ * to find or create an IOMMU group for a device.
+ */
+static struct iommu_group *iommu_group_get_for_pci_dev(struct pci_dev *pdev)
+{
+	struct group_for_pci_data data;
+	struct pci_bus *bus;
+	struct iommu_group *group = NULL;
+	struct pci_dev *tmp;
+
+	/*
+	 * Find the upstream DMA alias for the device.  A device must not
+	 * be aliased due to topology in order to have its own IOMMU group.
+	 * If we find an alias along the way that already belongs to a
+	 * group, use it.
+	 */
+	if (pci_for_each_dma_alias(pdev, get_pci_alias_or_group, &data))
+		return data.group;
+
+	pdev = data.pdev;
+
+	/*
+	 * Continue upstream from the point of minimum IOMMU granularity
+	 * due to aliases to the point where devices are protected from
+	 * peer-to-peer DMA by PCI ACS.  Again, if we find an existing
+	 * group, use it.
+	 */
+	for (bus = pdev->bus; !pci_is_root_bus(bus); bus = bus->parent) {
+		if (!bus->self)
+			continue;
+
+		if (pci_acs_path_enabled(bus->self, NULL, REQ_ACS_FLAGS))
+			break;
+
+		pdev = bus->self;
+
+		group = iommu_group_get(&pdev->dev);
+		if (group)
+			return group;
+	}
+
+	/*
+	 * Next we need to consider DMA alias quirks.  If one device aliases
+	 * to another, they should be grouped together.  It's theoretically
+	 * possible that aliases could create chains of devices where each
+	 * device aliases another device.  If we then factor in multifunction
+	 * ACS grouping requirements, each alias could incorporate a new slot
+	 * with multiple functions, each with aliases.  This is all extremely
+	 * unlikely as DMA alias quirks are typically only used for PCIe
+	 * devices where we usually have a single slot per bus.  Furthermore,
+	 * the alias quirk is usually to another function within the slot
+	 * (and ACS multifunction is not supported) or to a different slot
+	 * that doesn't physically exist.  The likely scenario is therefore
+	 * that everything on the bus gets grouped together.  To reduce the
+	 * problem space, share the IOMMU group for all devices on the bus
+	 * if a DMA alias quirk is present on the bus.
+	 */
+	tmp = NULL;
+	for_each_pci_dev(tmp) {
+		if (tmp->bus != pdev->bus ||
+		    !(tmp->dev_flags & PCI_DEV_FLAGS_DMA_ALIAS_DEVFN))
+			continue;
+
+		pci_dev_put(tmp);
+		tmp = NULL;
+
+		/* We have an alias quirk, search for an existing group */
+		for_each_pci_dev(tmp) {
+			struct iommu_group *group_tmp;
+
+			if (tmp->bus != pdev->bus)
+				continue;
+
+			group_tmp = iommu_group_get(&tmp->dev);
+			if (!group) {
+				group = group_tmp;
+				continue;
+			}
+
+			if (group_tmp) {
+				WARN_ON(group != group_tmp);
+				iommu_group_put(group_tmp);
+			}
+		}
+
+		return group ? group : iommu_group_alloc();
+	}
+
+	/*
+	 * Non-multifunction devices or multifunction devices supporting
+	 * ACS get their own group.
+	 */
+	if (!pdev->multifunction || pci_acs_enabled(pdev, REQ_ACS_FLAGS))
+		return iommu_group_alloc();
+
+	/*
+	 * Multifunction devices not supporting ACS share a group with other
+	 * similar devices in the same slot.
+	 */
+	tmp = NULL;
+	for_each_pci_dev(tmp) {
+		if (tmp == pdev || tmp->bus != pdev->bus ||
+		    PCI_SLOT(tmp->devfn) !=  PCI_SLOT(pdev->devfn) ||
+		    pci_acs_enabled(tmp, REQ_ACS_FLAGS))
+			continue;
+
+		group = iommu_group_get(&tmp->dev);
+		if (group) {
+			pci_dev_put(tmp);
+			return group;
+		}
+	}
+
+	/* No shared group found, allocate new */
+	return iommu_group_alloc();
+}
+
+/**
+ * iommu_group_get_for_dev - Find or create the IOMMU group for a device
+ * @dev: target device
+ *
+ * This function is intended to be called by IOMMU drivers and extended to
+ * support common, bus-defined algorithms when determining or creating the
+ * IOMMU group for a device.  On success, the caller will hold a reference
+ * to the returned IOMMU group, which will already include the provided
+ * device.  The reference should be released with iommu_group_put().
+ */
+struct iommu_group *iommu_group_get_for_dev(struct device *dev)
+{
+	struct iommu_group *group = ERR_PTR(-EIO);
+	int ret;
+
+	group = iommu_group_get(dev);
+	if (group)
+		return group;
+
+	if (dev_is_pci(dev))
+		group = iommu_group_get_for_pci_dev(to_pci_dev(dev));
+
+	if (IS_ERR(group))
+		return group;
+
+	ret = iommu_group_add_device(group, dev);
+	if (ret) {
+		iommu_group_put(group);
+		return ERR_PTR(ret);
+	}
+
+	return group;
+}
+
 static int add_iommu_group(struct device *dev, void *data)
 {
 	struct iommu_ops *ops = data;

commit bb51eeee5a947f61eeefaa55221c26460542654d
Merge: 56fa484969c3 abedb049c52e a33a97c5c72c bca2b916f3d5 659db6f6beac 7d02c4d64dbb
Author: Joerg Roedel <joro@8bytes.org>
Date:   Fri Nov 1 14:44:25 2013 +0100

    Merge branches 'iommu/fixes', 'tracing', 'core', 'arm/tegra', 'x86/vt-d', 'arm/smmu' and 'arm/shmobile' into next

commit abedb049c52ef77ce7b11b915a4e7e6abd3985cb
Author: Fabio Estevam <fabio.estevam@freescale.com>
Date:   Thu Aug 22 10:25:42 2013 -0300

    iommu: No need to pass '0x' when '%pa' is used
    
    Commit 6197ca82 (iommu: Use %pa and %zx instead of casting) introduced the
    usage of '%pa', but still kept the '0x', which leads to printing '0x0x'.
    
    Remove the '0x' when '%pa' is used.
    
    Signed-off-by: Fabio Estevam <fabio.estevam@freescale.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index fbe9ca734f8f..06d36a0b1001 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -807,17 +807,17 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 	 * size of the smallest page supported by the hardware
 	 */
 	if (!IS_ALIGNED(iova | paddr | size, min_pagesz)) {
-		pr_err("unaligned: iova 0x%lx pa 0x%pa size 0x%zx min_pagesz 0x%x\n",
+		pr_err("unaligned: iova 0x%lx pa %pa size 0x%zx min_pagesz 0x%x\n",
 		       iova, &paddr, size, min_pagesz);
 		return -EINVAL;
 	}
 
-	pr_debug("map: iova 0x%lx pa 0x%pa size 0x%zx\n", iova, &paddr, size);
+	pr_debug("map: iova 0x%lx pa %pa size 0x%zx\n", iova, &paddr, size);
 
 	while (size) {
 		size_t pgsize = iommu_pgsize(domain, iova | paddr, size);
 
-		pr_debug("mapping: iova 0x%lx pa 0x%pa pgsize 0x%zx\n",
+		pr_debug("mapping: iova 0x%lx pa %pa pgsize 0x%zx\n",
 			 iova, &paddr, pgsize);
 
 		ret = domain->ops->map(domain, iova, paddr, pgsize, prot);

commit 3a50639ca4684476a69314811d89622d78c09448
Author: Shuah Khan <shuah.kh@samsung.com>
Date:   Thu Aug 15 11:59:29 2013 -0600

    iommu: Change iommu driver to call unmap trace event
    
    Change iommu driver to call unmap trace event. This iommu_map_unmap class
    event can be enabled to trigger when iommu unmap iommu ops is called. Trace
    information includes iova, physical address (map event only), and size.
    
    Testing:
    Added trace calls to iommu_prepare_identity_map() for testing some of the
    conditions that are hard to trigger. Here is the trace from the testing:
    
           swapper/0-1     [003] ....     1.854102: unmap: IOMMU: iova=0x00000000cb800000 size=0x400
    
    Signed-off-by: Shuah Khan <shuah.kh@samsung.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index ea49fe814026..d8c53c7a7ec1 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -892,6 +892,7 @@ size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
 		unmapped += unmapped_page;
 	}
 
+	trace_unmap(iova, 0, size);
 	return unmapped;
 }
 EXPORT_SYMBOL_GPL(iommu_unmap);

commit e0be7c867882320b65714a4386760382196dc7e8
Author: Shuah Khan <shuah.kh@samsung.com>
Date:   Thu Aug 15 11:59:28 2013 -0600

    iommu: Change iommu driver to call map trace event
    
    Change iommu driver to call map trace event. This iommu_map_unmap class event
    can be enabled to trigger when iommu map iommu ops is called. Trace information
    includes iova, physical address (map event only), and size.
    
    Testing:
    Added trace calls to iommu_prepare_identity_map() for testing some of the
    conditions that are hard to trigger. Here is the trace from the testing:
    
           swapper/0-1     [003] ....     1.854102: map: IOMMU: iova=0x00000000cb800000 paddr=0x00000000cf9fffff size=0x400
    
    Signed-off-by: Shuah Khan <shuah.kh@samsung.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index b6307545124c..ea49fe814026 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -842,6 +842,8 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 	/* unroll mapping in case something went wrong */
 	if (ret)
 		iommu_unmap(domain, orig_iova, orig_size - size);
+	else
+		trace_map(iova, paddr, size);
 
 	return ret;
 }

commit 699806302d8ac7dfb7d46e20da0ecd4317418d1d
Author: Shuah Khan <shuah.kh@samsung.com>
Date:   Thu Aug 15 11:59:27 2013 -0600

    iommu: Change iommu driver to call detach_device_to_domain trace event
    
    Change iommu driver to call detach_device_to_domain trace event. This
    iommu_device class event can be enabled to trigger when devices are detached
    from a domain. Trace information includes device name.
    
    Testing:
    Added trace calls to iommu_prepare_identity_map() for testing some of the
    conditions that are hard to trigger. Here is the trace from the testing:
    
           swapper/0-1     [003] ....     1.854102: detach_device_from_domain: IOMMU: device=0000:00:02.0
    
    Signed-off-by: Shuah Khan <shuah.kh@samsung.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 74c371c53ee4..b6307545124c 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -702,6 +702,7 @@ void iommu_detach_device(struct iommu_domain *domain, struct device *dev)
 		return;
 
 	domain->ops->detach_dev(domain, dev);
+	trace_detach_device_from_domain(dev);
 }
 EXPORT_SYMBOL_GPL(iommu_detach_device);
 

commit b54db778858bc83f9231e5b358cb978f559f7016
Author: Shuah Khan <shuah.kh@samsung.com>
Date:   Thu Aug 15 11:59:26 2013 -0600

    iommu: Change iommu driver to call attach_device_to_domain trace event
    
    Change iommu driver to call attach_device_to_domain trace event. This
    iommu_device class event can be enabled to trigger when devices are attached
    to a domain. Trace information includes device name.
    
    Testing:
    Added trace calls to iommu_prepare_identity_map() for testing some of the
    conditions that are hard to trigger. Here is the trace from the testing:
    
          swapper/0-1     [003] ....     1.854102: attach_device_to_domain: IOMMU: device=0000:00:02.0
    
    Signed-off-by: Shuah Khan <shuah.kh@samsung.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 278055bd0715..74c371c53ee4 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -685,10 +685,14 @@ EXPORT_SYMBOL_GPL(iommu_domain_free);
 
 int iommu_attach_device(struct iommu_domain *domain, struct device *dev)
 {
+	int ret;
 	if (unlikely(domain->ops->attach_dev == NULL))
 		return -ENODEV;
 
-	return domain->ops->attach_dev(domain, dev);
+	ret = domain->ops->attach_dev(domain, dev);
+	if (!ret)
+		trace_attach_device_to_domain(dev);
+	return ret;
 }
 EXPORT_SYMBOL_GPL(iommu_attach_device);
 

commit 2e757086bdfdc9450dc2e4a5d2ec5431520a02c8
Author: Shuah Khan <shuah.kh@samsung.com>
Date:   Thu Aug 15 11:59:25 2013 -0600

    iommu: Change iommu driver to call remove_device_to_group trace event
    
    Change iommu driver to call remove_device_to_group trace event. This
    iommu_group class event can be enabled to trigger when devices get
    removed from an iommu group. Trace information includes iommu group id and
    device name.
    
    Testing:
    Added trace calls to iommu_prepare_identity_map() for testing some of the
    conditions that are hard to trigger. Here is the trace from the testing:
    
           swapper/0-1     [003] ....     1.854101: remove_device_from_group: IOMMU: groupID=0 device=0000:00:02.0
    
    Signed-off-by: Shuah Khan <shuah.kh@samsung.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 349c92dfce05..278055bd0715 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -402,6 +402,8 @@ void iommu_group_remove_device(struct device *dev)
 	sysfs_remove_link(group->devices_kobj, device->name);
 	sysfs_remove_link(&dev->kobj, "iommu_group");
 
+	trace_remove_device_from_group(group->id, dev);
+
 	kfree(device->name);
 	kfree(device);
 	dev->iommu_group = NULL;

commit d1cf7e822746b5e755f5a893ffeced1f6311c0cf
Author: Shuah Khan <shuah.kh@samsung.com>
Date:   Thu Aug 15 11:59:24 2013 -0600

    iommu: Change iommu driver to call add_device_to_group trace event
    
    Change iommu driver to call add_device_to_group trace event. This iommu_group
    class event can be enabled to trigger when devices get added to an iommu group.
    Trace information includes iommu group id and device name.
    
    Testing:
    The following is trace is generated when intel-iommu driver adds devices to
    to iommu groups during boot-time during its initialization:
    
           swapper/0-1     [003] ....     1.854793: add_device_to_group: IOMMU: groupID=0 device=0000:00:00.0
           swapper/0-1     [003] ....     1.854797: add_device_to_group: IOMMU: groupID=1 device=0000:00:02.0
    
    Signed-off-by: Shuah Khan <shuah.kh@samsung.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 58f6a16b2e1a..349c92dfce05 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -364,6 +364,8 @@ int iommu_group_add_device(struct iommu_group *group, struct device *dev)
 	/* Notify any listeners about change to group. */
 	blocking_notifier_call_chain(&group->notifier,
 				     IOMMU_GROUP_NOTIFY_ADD_DEVICE, dev);
+
+	trace_add_device_to_group(group->id, dev);
 	return 0;
 }
 EXPORT_SYMBOL_GPL(iommu_group_add_device);

commit 7f6db1717235bd45d265766dad53c10d30899d41
Author: Shuah Khan <shuah.kh@samsung.com>
Date:   Thu Aug 15 11:59:23 2013 -0600

    iommu: Add event tracing feature to iommu
    
    Add tracing feature to iommu to report various iommu events. Classes
    iommu_group, iommu_device, and iommu_map_unmap are defined.
    
    iommu_group class events can be enabled to trigger when devices get added
    to and removed from an iommu group. Trace information includes iommu group
    id and device name.
    
    iommu:add_device_to_group
    iommu:remove_device_from_group
    
    iommu_device class events can be enabled to trigger when devices are attached
    to and detached from a domain. Trace information includes device name.
    
    iommu:attach_device_to_domain
    iommu:detach_device_from_domain
    
    iommu_map_unmap class events can be enabled to trigger when iommu map and
    unmap iommu ops. Trace information includes iova, physical address (map event
    only), and size.
    
    iommu:map
    iommu:unmap
    
    Signed-off-by: Shuah Khan <shuah.kh@samsung.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index fbe9ca734f8f..58f6a16b2e1a 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -29,6 +29,7 @@
 #include <linux/idr.h>
 #include <linux/notifier.h>
 #include <linux/err.h>
+#include <trace/events/iommu.h>
 
 static struct kset *iommu_group_kset;
 static struct ida iommu_group_ida;

commit 6197ca8272d16b0c7f95764a2c88eb976347e38b
Author: Joe Perches <joe@perches.com>
Date:   Sun Jun 23 12:29:04 2013 -0700

    iommu: Use %pa and %zx instead of casting
    
    printk supports using %pa for phys_addr_t and
    %zx for size_t so use those instead of %lx and
    casts to unsigned long.
    
    Other miscellaneous changes around this:
    
    Always use 0x%zx for size instead of one use of decimal.
    Coalesce format and align arguments.
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index ab1fa19ddddb..fbe9ca734f8f 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -807,20 +807,18 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 	 * size of the smallest page supported by the hardware
 	 */
 	if (!IS_ALIGNED(iova | paddr | size, min_pagesz)) {
-		pr_err("unaligned: iova 0x%lx pa 0x%lx size 0x%lx min_pagesz "
-			"0x%x\n", iova, (unsigned long)paddr,
-			(unsigned long)size, min_pagesz);
+		pr_err("unaligned: iova 0x%lx pa 0x%pa size 0x%zx min_pagesz 0x%x\n",
+		       iova, &paddr, size, min_pagesz);
 		return -EINVAL;
 	}
 
-	pr_debug("map: iova 0x%lx pa 0x%lx size 0x%lx\n", iova,
-				(unsigned long)paddr, (unsigned long)size);
+	pr_debug("map: iova 0x%lx pa 0x%pa size 0x%zx\n", iova, &paddr, size);
 
 	while (size) {
 		size_t pgsize = iommu_pgsize(domain, iova | paddr, size);
 
-		pr_debug("mapping: iova 0x%lx pa 0x%lx pgsize %lu\n", iova,
-			 (unsigned long)paddr, (unsigned long)pgsize);
+		pr_debug("mapping: iova 0x%lx pa 0x%pa pgsize 0x%zx\n",
+			 iova, &paddr, pgsize);
 
 		ret = domain->ops->map(domain, iova, paddr, pgsize, prot);
 		if (ret)
@@ -857,13 +855,12 @@ size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
 	 * by the hardware
 	 */
 	if (!IS_ALIGNED(iova | size, min_pagesz)) {
-		pr_err("unaligned: iova 0x%lx size 0x%lx min_pagesz 0x%x\n",
-					iova, (unsigned long)size, min_pagesz);
+		pr_err("unaligned: iova 0x%lx size 0x%zx min_pagesz 0x%x\n",
+		       iova, size, min_pagesz);
 		return -EINVAL;
 	}
 
-	pr_debug("unmap this: iova 0x%lx size 0x%lx\n", iova,
-							(unsigned long)size);
+	pr_debug("unmap this: iova 0x%lx size 0x%zx\n", iova, size);
 
 	/*
 	 * Keep iterating until we either unmap 'size' bytes (or more)
@@ -876,8 +873,8 @@ size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
 		if (!unmapped_page)
 			break;
 
-		pr_debug("unmapped: iova 0x%lx size %lx\n", iova,
-					(unsigned long)unmapped_page);
+		pr_debug("unmapped: iova 0x%lx size 0x%zx\n",
+			 iova, unmapped_page);
 
 		iova += unmapped_page;
 		unmapped += unmapped_page;

commit c6a8af50b89e78f7f429f6189d9db82215cc8873
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Fri Jun 21 09:33:50 2013 -0600

    iommu: Fix compiler warning on pr_debug
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 4b0b56b0501d..ab1fa19ddddb 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -820,7 +820,7 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 		size_t pgsize = iommu_pgsize(domain, iova | paddr, size);
 
 		pr_debug("mapping: iova 0x%lx pa 0x%lx pgsize %lu\n", iova,
-					(unsigned long)paddr, pgsize);
+			 (unsigned long)paddr, (unsigned long)pgsize);
 
 		ret = domain->ops->map(domain, iova, paddr, pgsize, prot);
 		if (ret)

commit bd13969b952491149e641d3dab24fa59b98f82e9
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Mon Jun 17 19:57:34 2013 -0600

    iommu: Split iommu_unmaps
    
    iommu_map splits requests into pages that the iommu driver reports
    that it can handle.  The iommu_unmap path does not do the same.  This
    can cause problems not only from callers that might expect the same
    behavior as the map path, but even from the failure path of iommu_map,
    should it fail at a point where it has mapped and needs to unwind a
    set of pages that the iommu driver cannot handle directly.  amd_iommu,
    for example, will BUG_ON if asked to unmap a non power of 2 size.
    
    Fix this by extracting and generalizing the sizing code from the
    iommu_map path and use it for both map and unmap.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index d8f98b14e2fe..4b0b56b0501d 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -754,6 +754,38 @@ int iommu_domain_has_cap(struct iommu_domain *domain,
 }
 EXPORT_SYMBOL_GPL(iommu_domain_has_cap);
 
+static size_t iommu_pgsize(struct iommu_domain *domain,
+			   unsigned long addr_merge, size_t size)
+{
+	unsigned int pgsize_idx;
+	size_t pgsize;
+
+	/* Max page size that still fits into 'size' */
+	pgsize_idx = __fls(size);
+
+	/* need to consider alignment requirements ? */
+	if (likely(addr_merge)) {
+		/* Max page size allowed by address */
+		unsigned int align_pgsize_idx = __ffs(addr_merge);
+		pgsize_idx = min(pgsize_idx, align_pgsize_idx);
+	}
+
+	/* build a mask of acceptable page sizes */
+	pgsize = (1UL << (pgsize_idx + 1)) - 1;
+
+	/* throw away page sizes not supported by the hardware */
+	pgsize &= domain->ops->pgsize_bitmap;
+
+	/* make sure we're still sane */
+	BUG_ON(!pgsize);
+
+	/* pick the biggest page */
+	pgsize_idx = __fls(pgsize);
+	pgsize = 1UL << pgsize_idx;
+
+	return pgsize;
+}
+
 int iommu_map(struct iommu_domain *domain, unsigned long iova,
 	      phys_addr_t paddr, size_t size, int prot)
 {
@@ -785,32 +817,7 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 				(unsigned long)paddr, (unsigned long)size);
 
 	while (size) {
-		unsigned long pgsize, addr_merge = iova | paddr;
-		unsigned int pgsize_idx;
-
-		/* Max page size that still fits into 'size' */
-		pgsize_idx = __fls(size);
-
-		/* need to consider alignment requirements ? */
-		if (likely(addr_merge)) {
-			/* Max page size allowed by both iova and paddr */
-			unsigned int align_pgsize_idx = __ffs(addr_merge);
-
-			pgsize_idx = min(pgsize_idx, align_pgsize_idx);
-		}
-
-		/* build a mask of acceptable page sizes */
-		pgsize = (1UL << (pgsize_idx + 1)) - 1;
-
-		/* throw away page sizes not supported by the hardware */
-		pgsize &= domain->ops->pgsize_bitmap;
-
-		/* make sure we're still sane */
-		BUG_ON(!pgsize);
-
-		/* pick the biggest page */
-		pgsize_idx = __fls(pgsize);
-		pgsize = 1UL << pgsize_idx;
+		size_t pgsize = iommu_pgsize(domain, iova | paddr, size);
 
 		pr_debug("mapping: iova 0x%lx pa 0x%lx pgsize %lu\n", iova,
 					(unsigned long)paddr, pgsize);
@@ -863,9 +870,9 @@ size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
 	 * or we hit an area that isn't mapped.
 	 */
 	while (unmapped < size) {
-		size_t left = size - unmapped;
+		size_t pgsize = iommu_pgsize(domain, iova, size - unmapped);
 
-		unmapped_page = domain->ops->unmap(domain, iova, left);
+		unmapped_page = domain->ops->unmap(domain, iova, pgsize);
 		if (!unmapped_page)
 			break;
 

commit 0c4513be3d01a854867446ee793748409cc0ebdf
Merge: ae3e7f3aba44 83ed9c13e37e 80f97f0f73b8 aa16bea929ae 72ca55dbae81
Author: Joerg Roedel <joro@8bytes.org>
Date:   Thu May 2 12:10:19 2013 +0200

    Merge branches 'iommu/fixes', 'x86/vt-d', 'x86/amd', 'ppc/pamu', 'core' and 'arm/tegra' into next

commit aa16bea929aed6ea854b55d2be8306a9fb40e694
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Mon Mar 25 10:23:49 2013 +1100

    iommu: Add a function to find an iommu group by id
    
    As IOMMU groups are exposed to the user space by their numbers,
    the user space can use them in various kernel APIs so the kernel
    might need an API to find a group by its ID.
    
    As an example, QEMU VFIO on PPC64 platform needs it to associate
    a logical bus number (LIOBN) with a specific IOMMU group in order
    to support in-kernel handling of DMA map/unmap requests.
    
    The patch adds the iommu_group_get_by_id(id) function which performs
    such search.
    
    v2: fixed reference counting.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index b972d430d92b..db01af01ce0a 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -204,6 +204,35 @@ struct iommu_group *iommu_group_alloc(void)
 }
 EXPORT_SYMBOL_GPL(iommu_group_alloc);
 
+struct iommu_group *iommu_group_get_by_id(int id)
+{
+	struct kobject *group_kobj;
+	struct iommu_group *group;
+	const char *name;
+
+	if (!iommu_group_kset)
+		return NULL;
+
+	name = kasprintf(GFP_KERNEL, "%d", id);
+	if (!name)
+		return NULL;
+
+	group_kobj = kset_find_obj(iommu_group_kset, name);
+	kfree(name);
+
+	if (!group_kobj)
+		return NULL;
+
+	group = container_of(group_kobj, struct iommu_group, kobj);
+	BUG_ON(group->id != id);
+
+	kobject_get(group->devices_kobj);
+	kobject_put(&group->kobj);
+
+	return group;
+}
+EXPORT_SYMBOL_GPL(iommu_group_get_by_id);
+
 /**
  * iommu_group_get_iommudata - retrieve iommu_data registered for a group
  * @group: the group

commit 80f97f0f73b82444f714651ea053838d27779dca
Author: Varun Sethi <Varun.Sethi@freescale.com>
Date:   Fri Mar 29 01:24:00 2013 +0530

    iommu/fsl: Add the window permission flag as a parameter to iommu_window_enable API.
    
    Each iommu window can have access permissions associated with it. Extended the
    window_enable API to incorporate window access permissions.
    
    In case of PAMU each window can have its specific set of permissions.
    
    Signed-off-by: Varun Sethi <Varun.Sethi@freescale.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index f730ed9d8af9..1d72b4f5b006 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -853,12 +853,13 @@ EXPORT_SYMBOL_GPL(iommu_unmap);
 
 
 int iommu_domain_window_enable(struct iommu_domain *domain, u32 wnd_nr,
-			       phys_addr_t paddr, u64 size)
+			       phys_addr_t paddr, u64 size, int prot)
 {
 	if (unlikely(domain->ops->domain_window_enable == NULL))
 		return -ENODEV;
 
-	return domain->ops->domain_window_enable(domain, wnd_nr, paddr, size);
+	return domain->ops->domain_window_enable(domain, wnd_nr, paddr, size,
+						 prot);
 }
 EXPORT_SYMBOL_GPL(iommu_domain_window_enable);
 

commit bb5547acfcd842950b8a22aa83f84af93388b9f2
Author: Varun Sethi <Varun.Sethi@freescale.com>
Date:   Fri Mar 29 01:23:58 2013 +0530

    iommu/fsl: Make iova dma_addr_t in the iommu_iova_to_phys API.
    
    This is required in case of PAMU, as it can support a window size of up
    to 64G (even on 32bit).
    
    Signed-off-by: Varun Sethi <Varun.Sethi@freescale.com>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index b972d430d92b..f730ed9d8af9 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -706,8 +706,7 @@ void iommu_detach_group(struct iommu_domain *domain, struct iommu_group *group)
 }
 EXPORT_SYMBOL_GPL(iommu_detach_group);
 
-phys_addr_t iommu_iova_to_phys(struct iommu_domain *domain,
-			       unsigned long iova)
+phys_addr_t iommu_iova_to_phys(struct iommu_domain *domain, dma_addr_t iova)
 {
 	if (unlikely(domain->ops->iova_to_phys == NULL))
 		return 0;

commit 693567125bde1966a095267a9d8ca1b8d40f59ee
Author: Joerg Roedel <joro@8bytes.org>
Date:   Mon Feb 4 14:00:01 2013 +0100

    iommu: Add DOMAIN_ATTR_WINDOWS domain attribute
    
    This attribute can be used to set and get the number of
    subwindows on IOMMUs that are window-based.
    
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index b3aced7356cc..b972d430d92b 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -891,6 +891,7 @@ int iommu_domain_get_attr(struct iommu_domain *domain,
 	struct iommu_domain_geometry *geometry;
 	bool *paging;
 	int ret = 0;
+	u32 *count;
 
 	switch (attr) {
 	case DOMAIN_ATTR_GEOMETRY:
@@ -901,6 +902,15 @@ int iommu_domain_get_attr(struct iommu_domain *domain,
 	case DOMAIN_ATTR_PAGING:
 		paging  = data;
 		*paging = (domain->ops->pgsize_bitmap != 0UL);
+		break;
+	case DOMAIN_ATTR_WINDOWS:
+		count = data;
+
+		if (domain->ops->domain_get_windows != NULL)
+			*count = domain->ops->domain_get_windows(domain);
+		else
+			ret = -ENODEV;
+
 		break;
 	default:
 		if (!domain->ops->domain_get_attr)
@@ -916,9 +926,26 @@ EXPORT_SYMBOL_GPL(iommu_domain_get_attr);
 int iommu_domain_set_attr(struct iommu_domain *domain,
 			  enum iommu_attr attr, void *data)
 {
-	if (!domain->ops->domain_set_attr)
-		return -EINVAL;
+	int ret = 0;
+	u32 *count;
+
+	switch (attr) {
+	case DOMAIN_ATTR_WINDOWS:
+		count = data;
+
+		if (domain->ops->domain_set_windows != NULL)
+			ret = domain->ops->domain_set_windows(domain, *count);
+		else
+			ret = -ENODEV;
 
-	return domain->ops->domain_set_attr(domain, attr, data);
+		break;
+	default:
+		if (domain->ops->domain_set_attr == NULL)
+			return -EINVAL;
+
+		ret = domain->ops->domain_set_attr(domain, attr, data);
+	}
+
+	return ret;
 }
 EXPORT_SYMBOL_GPL(iommu_domain_set_attr);

commit d7787d579cbef9f8079104759a2259fc916c688c
Author: Joerg Roedel <joro@8bytes.org>
Date:   Tue Jan 29 14:26:20 2013 +0100

    iommu: Add domain window handling functions
    
    Add the iommu_domain_window_enable() and iommu_domain_window_disable()
    functions to the IOMMU-API. These functions will be used to setup
    domains that are based on subwindows and not on paging.
    
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 0e0e5f2e0ccc..b3aced7356cc 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -852,6 +852,26 @@ size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
 }
 EXPORT_SYMBOL_GPL(iommu_unmap);
 
+
+int iommu_domain_window_enable(struct iommu_domain *domain, u32 wnd_nr,
+			       phys_addr_t paddr, u64 size)
+{
+	if (unlikely(domain->ops->domain_window_enable == NULL))
+		return -ENODEV;
+
+	return domain->ops->domain_window_enable(domain, wnd_nr, paddr, size);
+}
+EXPORT_SYMBOL_GPL(iommu_domain_window_enable);
+
+void iommu_domain_window_disable(struct iommu_domain *domain, u32 wnd_nr)
+{
+	if (unlikely(domain->ops->domain_window_disable == NULL))
+		return;
+
+	return domain->ops->domain_window_disable(domain, wnd_nr);
+}
+EXPORT_SYMBOL_GPL(iommu_domain_window_disable);
+
 static int __init iommu_init(void)
 {
 	iommu_group_kset = kset_create_and_add("iommu_groups",

commit d2e121601619631517409cba34e50db3cbff5852
Author: Joerg Roedel <joro@8bytes.org>
Date:   Tue Jan 29 13:49:04 2013 +0100

    iommu: Implement DOMAIN_ATTR_PAGING attribute
    
    This attribute of a domain can be queried to find out if the
    domain supports setting up page-tables using the iommu_map()
    and iommu_unmap() functions.
    
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 4e6d6f857e6f..0e0e5f2e0ccc 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -869,6 +869,7 @@ int iommu_domain_get_attr(struct iommu_domain *domain,
 			  enum iommu_attr attr, void *data)
 {
 	struct iommu_domain_geometry *geometry;
+	bool *paging;
 	int ret = 0;
 
 	switch (attr) {
@@ -876,6 +877,10 @@ int iommu_domain_get_attr(struct iommu_domain *domain,
 		geometry  = data;
 		*geometry = domain->geometry;
 
+		break;
+	case DOMAIN_ATTR_PAGING:
+		paging  = data;
+		*paging = (domain->ops->pgsize_bitmap != 0UL);
 		break;
 	default:
 		if (!domain->ops->domain_get_attr)

commit 57886518a8cdd319a04f5ea06a5f7ffcb8a93120
Author: Joerg Roedel <joro@8bytes.org>
Date:   Tue Jan 29 13:41:09 2013 +0100

    iommu: Check for valid pgsize_bitmap in iommu_map/unmap
    
    In case the page-size bitmap is zero the code path in
    iommu_map and iommu_unmap is undefined. Make it defined and
    return -ENODEV in this case.
    
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 1065a1a19478..4e6d6f857e6f 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -734,7 +734,8 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 	size_t orig_size = size;
 	int ret = 0;
 
-	if (unlikely(domain->ops->map == NULL))
+	if (unlikely(domain->ops->unmap == NULL ||
+		     domain->ops->pgsize_bitmap == 0UL))
 		return -ENODEV;
 
 	/* find out the minimum page size supported */
@@ -808,7 +809,8 @@ size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
 	size_t unmapped_page, unmapped = 0;
 	unsigned int min_pagesz;
 
-	if (unlikely(domain->ops->unmap == NULL))
+	if (unlikely(domain->ops->unmap == NULL ||
+		     domain->ops->pgsize_bitmap == 0UL))
 		return -ENODEV;
 
 	/* find out the minimum page size supported */

commit 097e3635dc35d1cfc14057f8006f1b1f0eaf1987
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Mon Jan 7 18:51:52 2013 +1100

    iommu: moving initialization earlier
    
    The iommu_init() initializes IOMMU internal structures and data
    required for the IOMMU API as iommu_group_alloc().
    It is registered as a subsys_initcall now.
    
    One of the IOMMU users is going to be a PCI subsystem on POWER.
    It discovers new IOMMU tables during the PCI scan so the logical
    place to call iommu_group_alloc() is the moment when a new group
    is discovered. However PCI scan is done from subsys_initcall hook
    as IOMMU does so PCI hook can be (and is) called before the IOMMU one.
    
    The patch moves IOMMU subsystem initialization one step earlier
    to make sure that IOMMU is initialized before PCI scan begins.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Signed-off-by: Joerg Roedel <joro@8bytes.org>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index ddbdacad7768..1065a1a19478 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -861,7 +861,7 @@ static int __init iommu_init(void)
 
 	return 0;
 }
-subsys_initcall(iommu_init);
+arch_initcall(iommu_init);
 
 int iommu_domain_get_attr(struct iommu_domain *domain,
 			  enum iommu_attr attr, void *data)

commit 395e51f18d3b26619c1c462b7a1c0226846ac0a9
Merge: 28a33cbc24e4 2c9195e99029 2c0ae1720c09 7d43c2e42cb1 8ce44a2174c3 3177bb76a8c5
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Mon Jul 23 12:17:00 2012 +0200

    Merge branches 'iommu/fixes', 'x86/amd', 'groups', 'arm/tegra' and 'api/domain-attr' into next
    
    Conflicts:
            drivers/iommu/iommu.c
            include/linux/iommu.h

commit 0ff64f80e075ae036a4c80c7d7752b1e07fed792
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Thu Jan 26 19:40:53 2012 +0100

    iommu/amd: Implement DOMAIN_ATTR_GEOMETRY attribute
    
    Implement the attribute itself and add the code for the
    AMD IOMMU driver.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index c39972d8ded3..ed5e0a553ca7 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -348,10 +348,23 @@ EXPORT_SYMBOL_GPL(iommu_device_group);
 int iommu_domain_get_attr(struct iommu_domain *domain,
 			  enum iommu_attr attr, void *data)
 {
-	if (!domain->ops->domain_get_attr)
-		return -EINVAL;
+	struct iommu_domain_geometry *geometry;
+	int ret = 0;
+
+	switch (attr) {
+	case DOMAIN_ATTR_GEOMETRY:
+		geometry  = data;
+		*geometry = domain->geometry;
+
+		break;
+	default:
+		if (!domain->ops->domain_get_attr)
+			return -EINVAL;
 
-	return domain->ops->domain_get_attr(domain, attr, data);
+		ret = domain->ops->domain_get_attr(domain, attr, data);
+	}
+
+	return ret;
 }
 EXPORT_SYMBOL_GPL(iommu_domain_get_attr);
 

commit 0cd76dd13bdd2f7f02a2dc931e808e92b191082f
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Thu Jan 26 19:40:52 2012 +0100

    iommu: Add domain-attribute handlers
    
    This patch introduces an extension to the iommu-api to get
    and set attributes for an iommu_domain. Two functions are
    introduced for this:
    
            * iommu_domain_get_attr()
            * iommu_domain_set_attr()
    
    These functions will be used to make the iommu-api suitable
    for GART-like IOMMUs and to implement hardware-specifc
    api-extensions.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 8b9ded88e6f5..c39972d8ded3 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -344,3 +344,23 @@ int iommu_device_group(struct device *dev, unsigned int *groupid)
 	return -ENODEV;
 }
 EXPORT_SYMBOL_GPL(iommu_device_group);
+
+int iommu_domain_get_attr(struct iommu_domain *domain,
+			  enum iommu_attr attr, void *data)
+{
+	if (!domain->ops->domain_get_attr)
+		return -EINVAL;
+
+	return domain->ops->domain_get_attr(domain, attr, data);
+}
+EXPORT_SYMBOL_GPL(iommu_domain_get_attr);
+
+int iommu_domain_set_attr(struct iommu_domain *domain,
+			  enum iommu_attr attr, void *data)
+{
+	if (!domain->ops->domain_set_attr)
+		return -EINVAL;
+
+	return domain->ops->domain_set_attr(domain, attr, data);
+}
+EXPORT_SYMBOL_GPL(iommu_domain_set_attr);

commit d72e31c9374627068df29da8085ca18c92ae35d3
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Wed May 30 14:18:53 2012 -0600

    iommu: IOMMU Groups
    
    IOMMU device groups are currently a rather vague associative notion
    with assembly required by the user or user level driver provider to
    do anything useful.  This patch intends to grow the IOMMU group concept
    into something a bit more consumable.
    
    To do this, we first create an object representing the group, struct
    iommu_group.  This structure is allocated (iommu_group_alloc) and
    filled (iommu_group_add_device) by the iommu driver.  The iommu driver
    is free to add devices to the group using it's own set of policies.
    This allows inclusion of devices based on physical hardware or topology
    limitations of the platform, as well as soft requirements, such as
    multi-function trust levels or peer-to-peer protection of the
    interconnects.  Each device may only belong to a single iommu group,
    which is linked from struct device.iommu_group.  IOMMU groups are
    maintained using kobject reference counting, allowing for automatic
    removal of empty, unreferenced groups.  It is the responsibility of
    the iommu driver to remove devices from the group
    (iommu_group_remove_device).
    
    IOMMU groups also include a userspace representation in sysfs under
    /sys/kernel/iommu_groups.  When allocated, each group is given a
    dynamically assign ID (int).  The ID is managed by the core IOMMU group
    code to support multiple heterogeneous iommu drivers, which could
    potentially collide in group naming/numbering.  This also keeps group
    IDs to small, easily managed values.  A directory is created under
    /sys/kernel/iommu_groups for each group.  A further subdirectory named
    "devices" contains links to each device within the group.  The iommu_group
    file in the device's sysfs directory, which formerly contained a group
    number when read, is now a link to the iommu group.  Example:
    
    $ ls -l /sys/kernel/iommu_groups/26/devices/
    total 0
    lrwxrwxrwx. 1 root root 0 Apr 17 12:57 0000:00:1e.0 ->
                    ../../../../devices/pci0000:00/0000:00:1e.0
    lrwxrwxrwx. 1 root root 0 Apr 17 12:57 0000:06:0d.0 ->
                    ../../../../devices/pci0000:00/0000:00:1e.0/0000:06:0d.0
    lrwxrwxrwx. 1 root root 0 Apr 17 12:57 0000:06:0d.1 ->
                    ../../../../devices/pci0000:00/0000:00:1e.0/0000:06:0d.1
    
    $ ls -l  /sys/kernel/iommu_groups/26/devices/*/iommu_group
    [truncating perms/owner/timestamp]
    /sys/kernel/iommu_groups/26/devices/0000:00:1e.0/iommu_group ->
                                            ../../../kernel/iommu_groups/26
    /sys/kernel/iommu_groups/26/devices/0000:06:0d.0/iommu_group ->
                                            ../../../../kernel/iommu_groups/26
    /sys/kernel/iommu_groups/26/devices/0000:06:0d.1/iommu_group ->
                                            ../../../../kernel/iommu_groups/26
    
    Groups also include several exported functions for use by user level
    driver providers, for example VFIO.  These include:
    
    iommu_group_get(): Acquires a reference to a group from a device
    iommu_group_put(): Releases reference
    iommu_group_for_each_dev(): Iterates over group devices using callback
    iommu_group_[un]register_notifier(): Allows notification of device add
            and remove operations relevant to the group
    iommu_group_id(): Return the group number
    
    This patch also extends the IOMMU API to allow attaching groups to
    domains.  This is currently a simple wrapper for iterating through
    devices within a group, but it's expected that the IOMMU API may
    eventually make groups a more integral part of domains.
    
    Groups intentionally do not try to manage group ownership.  A user
    level driver provider must independently acquire ownership for each
    device within a group before making use of the group as a whole.
    This may change in the future if group usage becomes more pervasive
    across both DMA and IOMMU ops.
    
    Groups intentionally do not provide a mechanism for driver locking
    or otherwise manipulating driver matching/probing of devices within
    the group.  Such interfaces are generic to devices and beyond the
    scope of IOMMU groups.  If implemented, user level providers have
    ready access via iommu_group_for_each_dev and group notifiers.
    
    iommu_device_group() is removed here as it has no users.  The
    replacement is:
    
            group = iommu_group_get(dev);
            id = iommu_group_id(group);
            iommu_group_put(group);
    
    AMD-Vi & Intel VT-d support re-added in following patches.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 8b9ded88e6f5..0e928acd7dcf 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -26,60 +26,535 @@
 #include <linux/slab.h>
 #include <linux/errno.h>
 #include <linux/iommu.h>
+#include <linux/idr.h>
+#include <linux/notifier.h>
+#include <linux/err.h>
+
+static struct kset *iommu_group_kset;
+static struct ida iommu_group_ida;
+static struct mutex iommu_group_mutex;
+
+struct iommu_group {
+	struct kobject kobj;
+	struct kobject *devices_kobj;
+	struct list_head devices;
+	struct mutex mutex;
+	struct blocking_notifier_head notifier;
+	void *iommu_data;
+	void (*iommu_data_release)(void *iommu_data);
+	char *name;
+	int id;
+};
+
+struct iommu_device {
+	struct list_head list;
+	struct device *dev;
+	char *name;
+};
+
+struct iommu_group_attribute {
+	struct attribute attr;
+	ssize_t (*show)(struct iommu_group *group, char *buf);
+	ssize_t (*store)(struct iommu_group *group,
+			 const char *buf, size_t count);
+};
+
+#define IOMMU_GROUP_ATTR(_name, _mode, _show, _store)		\
+struct iommu_group_attribute iommu_group_attr_##_name =		\
+	__ATTR(_name, _mode, _show, _store)
 
-static ssize_t show_iommu_group(struct device *dev,
-				struct device_attribute *attr, char *buf)
+#define to_iommu_group_attr(_attr)	\
+	container_of(_attr, struct iommu_group_attribute, attr)
+#define to_iommu_group(_kobj)		\
+	container_of(_kobj, struct iommu_group, kobj)
+
+static ssize_t iommu_group_attr_show(struct kobject *kobj,
+				     struct attribute *__attr, char *buf)
 {
-	unsigned int groupid;
+	struct iommu_group_attribute *attr = to_iommu_group_attr(__attr);
+	struct iommu_group *group = to_iommu_group(kobj);
+	ssize_t ret = -EIO;
 
-	if (iommu_device_group(dev, &groupid))
-		return 0;
+	if (attr->show)
+		ret = attr->show(group, buf);
+	return ret;
+}
+
+static ssize_t iommu_group_attr_store(struct kobject *kobj,
+				      struct attribute *__attr,
+				      const char *buf, size_t count)
+{
+	struct iommu_group_attribute *attr = to_iommu_group_attr(__attr);
+	struct iommu_group *group = to_iommu_group(kobj);
+	ssize_t ret = -EIO;
 
-	return sprintf(buf, "%u", groupid);
+	if (attr->store)
+		ret = attr->store(group, buf, count);
+	return ret;
 }
-static DEVICE_ATTR(iommu_group, S_IRUGO, show_iommu_group, NULL);
 
-static int add_iommu_group(struct device *dev, void *data)
+static const struct sysfs_ops iommu_group_sysfs_ops = {
+	.show = iommu_group_attr_show,
+	.store = iommu_group_attr_store,
+};
+
+static int iommu_group_create_file(struct iommu_group *group,
+				   struct iommu_group_attribute *attr)
+{
+	return sysfs_create_file(&group->kobj, &attr->attr);
+}
+
+static void iommu_group_remove_file(struct iommu_group *group,
+				    struct iommu_group_attribute *attr)
+{
+	sysfs_remove_file(&group->kobj, &attr->attr);
+}
+
+static ssize_t iommu_group_show_name(struct iommu_group *group, char *buf)
+{
+	return sprintf(buf, "%s\n", group->name);
+}
+
+static IOMMU_GROUP_ATTR(name, S_IRUGO, iommu_group_show_name, NULL);
+
+static void iommu_group_release(struct kobject *kobj)
+{
+	struct iommu_group *group = to_iommu_group(kobj);
+
+	if (group->iommu_data_release)
+		group->iommu_data_release(group->iommu_data);
+
+	mutex_lock(&iommu_group_mutex);
+	ida_remove(&iommu_group_ida, group->id);
+	mutex_unlock(&iommu_group_mutex);
+
+	kfree(group->name);
+	kfree(group);
+}
+
+static struct kobj_type iommu_group_ktype = {
+	.sysfs_ops = &iommu_group_sysfs_ops,
+	.release = iommu_group_release,
+};
+
+/**
+ * iommu_group_alloc - Allocate a new group
+ * @name: Optional name to associate with group, visible in sysfs
+ *
+ * This function is called by an iommu driver to allocate a new iommu
+ * group.  The iommu group represents the minimum granularity of the iommu.
+ * Upon successful return, the caller holds a reference to the supplied
+ * group in order to hold the group until devices are added.  Use
+ * iommu_group_put() to release this extra reference count, allowing the
+ * group to be automatically reclaimed once it has no devices or external
+ * references.
+ */
+struct iommu_group *iommu_group_alloc(void)
 {
-	unsigned int groupid;
+	struct iommu_group *group;
+	int ret;
+
+	group = kzalloc(sizeof(*group), GFP_KERNEL);
+	if (!group)
+		return ERR_PTR(-ENOMEM);
+
+	group->kobj.kset = iommu_group_kset;
+	mutex_init(&group->mutex);
+	INIT_LIST_HEAD(&group->devices);
+	BLOCKING_INIT_NOTIFIER_HEAD(&group->notifier);
+
+	mutex_lock(&iommu_group_mutex);
+
+again:
+	if (unlikely(0 == ida_pre_get(&iommu_group_ida, GFP_KERNEL))) {
+		kfree(group);
+		mutex_unlock(&iommu_group_mutex);
+		return ERR_PTR(-ENOMEM);
+	}
+
+	if (-EAGAIN == ida_get_new(&iommu_group_ida, &group->id))
+		goto again;
+
+	mutex_unlock(&iommu_group_mutex);
 
-	if (iommu_device_group(dev, &groupid) == 0)
-		return device_create_file(dev, &dev_attr_iommu_group);
+	ret = kobject_init_and_add(&group->kobj, &iommu_group_ktype,
+				   NULL, "%d", group->id);
+	if (ret) {
+		mutex_lock(&iommu_group_mutex);
+		ida_remove(&iommu_group_ida, group->id);
+		mutex_unlock(&iommu_group_mutex);
+		kfree(group);
+		return ERR_PTR(ret);
+	}
+
+	group->devices_kobj = kobject_create_and_add("devices", &group->kobj);
+	if (!group->devices_kobj) {
+		kobject_put(&group->kobj); /* triggers .release & free */
+		return ERR_PTR(-ENOMEM);
+	}
+
+	/*
+	 * The devices_kobj holds a reference on the group kobject, so
+	 * as long as that exists so will the group.  We can therefore
+	 * use the devices_kobj for reference counting.
+	 */
+	kobject_put(&group->kobj);
+
+	return group;
+}
+EXPORT_SYMBOL_GPL(iommu_group_alloc);
+
+/**
+ * iommu_group_get_iommudata - retrieve iommu_data registered for a group
+ * @group: the group
+ *
+ * iommu drivers can store data in the group for use when doing iommu
+ * operations.  This function provides a way to retrieve it.  Caller
+ * should hold a group reference.
+ */
+void *iommu_group_get_iommudata(struct iommu_group *group)
+{
+	return group->iommu_data;
+}
+EXPORT_SYMBOL_GPL(iommu_group_get_iommudata);
+
+/**
+ * iommu_group_set_iommudata - set iommu_data for a group
+ * @group: the group
+ * @iommu_data: new data
+ * @release: release function for iommu_data
+ *
+ * iommu drivers can store data in the group for use when doing iommu
+ * operations.  This function provides a way to set the data after
+ * the group has been allocated.  Caller should hold a group reference.
+ */
+void iommu_group_set_iommudata(struct iommu_group *group, void *iommu_data,
+			       void (*release)(void *iommu_data))
+{
+	group->iommu_data = iommu_data;
+	group->iommu_data_release = release;
+}
+EXPORT_SYMBOL_GPL(iommu_group_set_iommudata);
+
+/**
+ * iommu_group_set_name - set name for a group
+ * @group: the group
+ * @name: name
+ *
+ * Allow iommu driver to set a name for a group.  When set it will
+ * appear in a name attribute file under the group in sysfs.
+ */
+int iommu_group_set_name(struct iommu_group *group, const char *name)
+{
+	int ret;
+
+	if (group->name) {
+		iommu_group_remove_file(group, &iommu_group_attr_name);
+		kfree(group->name);
+		group->name = NULL;
+		if (!name)
+			return 0;
+	}
+
+	group->name = kstrdup(name, GFP_KERNEL);
+	if (!group->name)
+		return -ENOMEM;
+
+	ret = iommu_group_create_file(group, &iommu_group_attr_name);
+	if (ret) {
+		kfree(group->name);
+		group->name = NULL;
+		return ret;
+	}
 
 	return 0;
 }
+EXPORT_SYMBOL_GPL(iommu_group_set_name);
 
-static int remove_iommu_group(struct device *dev)
+/**
+ * iommu_group_add_device - add a device to an iommu group
+ * @group: the group into which to add the device (reference should be held)
+ * @dev: the device
+ *
+ * This function is called by an iommu driver to add a device into a
+ * group.  Adding a device increments the group reference count.
+ */
+int iommu_group_add_device(struct iommu_group *group, struct device *dev)
 {
-	unsigned int groupid;
+	int ret, i = 0;
+	struct iommu_device *device;
+
+	device = kzalloc(sizeof(*device), GFP_KERNEL);
+	if (!device)
+		return -ENOMEM;
+
+	device->dev = dev;
 
-	if (iommu_device_group(dev, &groupid) == 0)
-		device_remove_file(dev, &dev_attr_iommu_group);
+	ret = sysfs_create_link(&dev->kobj, &group->kobj, "iommu_group");
+	if (ret) {
+		kfree(device);
+		return ret;
+	}
+
+	device->name = kasprintf(GFP_KERNEL, "%s", kobject_name(&dev->kobj));
+rename:
+	if (!device->name) {
+		sysfs_remove_link(&dev->kobj, "iommu_group");
+		kfree(device);
+		return -ENOMEM;
+	}
 
+	ret = sysfs_create_link_nowarn(group->devices_kobj,
+				       &dev->kobj, device->name);
+	if (ret) {
+		kfree(device->name);
+		if (ret == -EEXIST && i >= 0) {
+			/*
+			 * Account for the slim chance of collision
+			 * and append an instance to the name.
+			 */
+			device->name = kasprintf(GFP_KERNEL, "%s.%d",
+						 kobject_name(&dev->kobj), i++);
+			goto rename;
+		}
+
+		sysfs_remove_link(&dev->kobj, "iommu_group");
+		kfree(device);
+		return ret;
+	}
+
+	kobject_get(group->devices_kobj);
+
+	dev->iommu_group = group;
+
+	mutex_lock(&group->mutex);
+	list_add_tail(&device->list, &group->devices);
+	mutex_unlock(&group->mutex);
+
+	/* Notify any listeners about change to group. */
+	blocking_notifier_call_chain(&group->notifier,
+				     IOMMU_GROUP_NOTIFY_ADD_DEVICE, dev);
 	return 0;
 }
+EXPORT_SYMBOL_GPL(iommu_group_add_device);
 
-static int iommu_device_notifier(struct notifier_block *nb,
-				 unsigned long action, void *data)
+/**
+ * iommu_group_remove_device - remove a device from it's current group
+ * @dev: device to be removed
+ *
+ * This function is called by an iommu driver to remove the device from
+ * it's current group.  This decrements the iommu group reference count.
+ */
+void iommu_group_remove_device(struct device *dev)
+{
+	struct iommu_group *group = dev->iommu_group;
+	struct iommu_device *tmp_device, *device = NULL;
+
+	/* Pre-notify listeners that a device is being removed. */
+	blocking_notifier_call_chain(&group->notifier,
+				     IOMMU_GROUP_NOTIFY_DEL_DEVICE, dev);
+
+	mutex_lock(&group->mutex);
+	list_for_each_entry(tmp_device, &group->devices, list) {
+		if (tmp_device->dev == dev) {
+			device = tmp_device;
+			list_del(&device->list);
+			break;
+		}
+	}
+	mutex_unlock(&group->mutex);
+
+	if (!device)
+		return;
+
+	sysfs_remove_link(group->devices_kobj, device->name);
+	sysfs_remove_link(&dev->kobj, "iommu_group");
+
+	kfree(device->name);
+	kfree(device);
+	dev->iommu_group = NULL;
+	kobject_put(group->devices_kobj);
+}
+EXPORT_SYMBOL_GPL(iommu_group_remove_device);
+
+/**
+ * iommu_group_for_each_dev - iterate over each device in the group
+ * @group: the group
+ * @data: caller opaque data to be passed to callback function
+ * @fn: caller supplied callback function
+ *
+ * This function is called by group users to iterate over group devices.
+ * Callers should hold a reference count to the group during callback.
+ * The group->mutex is held across callbacks, which will block calls to
+ * iommu_group_add/remove_device.
+ */
+int iommu_group_for_each_dev(struct iommu_group *group, void *data,
+			     int (*fn)(struct device *, void *))
+{
+	struct iommu_device *device;
+	int ret = 0;
+
+	mutex_lock(&group->mutex);
+	list_for_each_entry(device, &group->devices, list) {
+		ret = fn(device->dev, data);
+		if (ret)
+			break;
+	}
+	mutex_unlock(&group->mutex);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(iommu_group_for_each_dev);
+
+/**
+ * iommu_group_get - Return the group for a device and increment reference
+ * @dev: get the group that this device belongs to
+ *
+ * This function is called by iommu drivers and users to get the group
+ * for the specified device.  If found, the group is returned and the group
+ * reference in incremented, else NULL.
+ */
+struct iommu_group *iommu_group_get(struct device *dev)
+{
+	struct iommu_group *group = dev->iommu_group;
+
+	if (group)
+		kobject_get(group->devices_kobj);
+
+	return group;
+}
+EXPORT_SYMBOL_GPL(iommu_group_get);
+
+/**
+ * iommu_group_put - Decrement group reference
+ * @group: the group to use
+ *
+ * This function is called by iommu drivers and users to release the
+ * iommu group.  Once the reference count is zero, the group is released.
+ */
+void iommu_group_put(struct iommu_group *group)
+{
+	if (group)
+		kobject_put(group->devices_kobj);
+}
+EXPORT_SYMBOL_GPL(iommu_group_put);
+
+/**
+ * iommu_group_register_notifier - Register a notifier for group changes
+ * @group: the group to watch
+ * @nb: notifier block to signal
+ *
+ * This function allows iommu group users to track changes in a group.
+ * See include/linux/iommu.h for actions sent via this notifier.  Caller
+ * should hold a reference to the group throughout notifier registration.
+ */
+int iommu_group_register_notifier(struct iommu_group *group,
+				  struct notifier_block *nb)
+{
+	return blocking_notifier_chain_register(&group->notifier, nb);
+}
+EXPORT_SYMBOL_GPL(iommu_group_register_notifier);
+
+/**
+ * iommu_group_unregister_notifier - Unregister a notifier
+ * @group: the group to watch
+ * @nb: notifier block to signal
+ *
+ * Unregister a previously registered group notifier block.
+ */
+int iommu_group_unregister_notifier(struct iommu_group *group,
+				    struct notifier_block *nb)
+{
+	return blocking_notifier_chain_unregister(&group->notifier, nb);
+}
+EXPORT_SYMBOL_GPL(iommu_group_unregister_notifier);
+
+/**
+ * iommu_group_id - Return ID for a group
+ * @group: the group to ID
+ *
+ * Return the unique ID for the group matching the sysfs group number.
+ */
+int iommu_group_id(struct iommu_group *group)
+{
+	return group->id;
+}
+EXPORT_SYMBOL_GPL(iommu_group_id);
+
+static int add_iommu_group(struct device *dev, void *data)
+{
+	struct iommu_ops *ops = data;
+
+	if (!ops->add_device)
+		return -ENODEV;
+
+	WARN_ON(dev->iommu_group);
+
+	ops->add_device(dev);
+
+	return 0;
+}
+
+static int iommu_bus_notifier(struct notifier_block *nb,
+			      unsigned long action, void *data)
 {
 	struct device *dev = data;
+	struct iommu_ops *ops = dev->bus->iommu_ops;
+	struct iommu_group *group;
+	unsigned long group_action = 0;
+
+	/*
+	 * ADD/DEL call into iommu driver ops if provided, which may
+	 * result in ADD/DEL notifiers to group->notifier
+	 */
+	if (action == BUS_NOTIFY_ADD_DEVICE) {
+		if (ops->add_device)
+			return ops->add_device(dev);
+	} else if (action == BUS_NOTIFY_DEL_DEVICE) {
+		if (ops->remove_device && dev->iommu_group) {
+			ops->remove_device(dev);
+			return 0;
+		}
+	}
 
-	if (action == BUS_NOTIFY_ADD_DEVICE)
-		return add_iommu_group(dev, NULL);
-	else if (action == BUS_NOTIFY_DEL_DEVICE)
-		return remove_iommu_group(dev);
+	/*
+	 * Remaining BUS_NOTIFYs get filtered and republished to the
+	 * group, if anyone is listening
+	 */
+	group = iommu_group_get(dev);
+	if (!group)
+		return 0;
 
+	switch (action) {
+	case BUS_NOTIFY_BIND_DRIVER:
+		group_action = IOMMU_GROUP_NOTIFY_BIND_DRIVER;
+		break;
+	case BUS_NOTIFY_BOUND_DRIVER:
+		group_action = IOMMU_GROUP_NOTIFY_BOUND_DRIVER;
+		break;
+	case BUS_NOTIFY_UNBIND_DRIVER:
+		group_action = IOMMU_GROUP_NOTIFY_UNBIND_DRIVER;
+		break;
+	case BUS_NOTIFY_UNBOUND_DRIVER:
+		group_action = IOMMU_GROUP_NOTIFY_UNBOUND_DRIVER;
+		break;
+	}
+
+	if (group_action)
+		blocking_notifier_call_chain(&group->notifier,
+					     group_action, dev);
+
+	iommu_group_put(group);
 	return 0;
 }
 
-static struct notifier_block iommu_device_nb = {
-	.notifier_call = iommu_device_notifier,
+static struct notifier_block iommu_bus_nb = {
+	.notifier_call = iommu_bus_notifier,
 };
 
 static void iommu_bus_init(struct bus_type *bus, struct iommu_ops *ops)
 {
-	bus_register_notifier(bus, &iommu_device_nb);
-	bus_for_each_dev(bus, NULL, NULL, add_iommu_group);
+	bus_register_notifier(bus, &iommu_bus_nb);
+	bus_for_each_dev(bus, NULL, ops, add_iommu_group);
 }
 
 /**
@@ -192,6 +667,45 @@ void iommu_detach_device(struct iommu_domain *domain, struct device *dev)
 }
 EXPORT_SYMBOL_GPL(iommu_detach_device);
 
+/*
+ * IOMMU groups are really the natrual working unit of the IOMMU, but
+ * the IOMMU API works on domains and devices.  Bridge that gap by
+ * iterating over the devices in a group.  Ideally we'd have a single
+ * device which represents the requestor ID of the group, but we also
+ * allow IOMMU drivers to create policy defined minimum sets, where
+ * the physical hardware may be able to distiguish members, but we
+ * wish to group them at a higher level (ex. untrusted multi-function
+ * PCI devices).  Thus we attach each device.
+ */
+static int iommu_group_do_attach_device(struct device *dev, void *data)
+{
+	struct iommu_domain *domain = data;
+
+	return iommu_attach_device(domain, dev);
+}
+
+int iommu_attach_group(struct iommu_domain *domain, struct iommu_group *group)
+{
+	return iommu_group_for_each_dev(group, domain,
+					iommu_group_do_attach_device);
+}
+EXPORT_SYMBOL_GPL(iommu_attach_group);
+
+static int iommu_group_do_detach_device(struct device *dev, void *data)
+{
+	struct iommu_domain *domain = data;
+
+	iommu_detach_device(domain, dev);
+
+	return 0;
+}
+
+void iommu_detach_group(struct iommu_domain *domain, struct iommu_group *group)
+{
+	iommu_group_for_each_dev(group, domain, iommu_group_do_detach_device);
+}
+EXPORT_SYMBOL_GPL(iommu_detach_group);
+
 phys_addr_t iommu_iova_to_phys(struct iommu_domain *domain,
 			       unsigned long iova)
 {
@@ -336,11 +850,15 @@ size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
 }
 EXPORT_SYMBOL_GPL(iommu_unmap);
 
-int iommu_device_group(struct device *dev, unsigned int *groupid)
+static int __init iommu_init(void)
 {
-	if (iommu_present(dev->bus) && dev->bus->iommu_ops->device_group)
-		return dev->bus->iommu_ops->device_group(dev, groupid);
+	iommu_group_kset = kset_create_and_add("iommu_groups",
+					       NULL, kernel_kobj);
+	ida_init(&iommu_group_ida);
+	mutex_init(&iommu_group_mutex);
 
-	return -ENODEV;
+	BUG_ON(!iommu_group_kset);
+
+	return 0;
 }
-EXPORT_SYMBOL_GPL(iommu_device_group);
+subsys_initcall(iommu_init);

commit 77ca23323594589ac8cba1c8d59bfe7e85d3cb8b
Author: Ohad Ben-Cohen <ohad@wizery.com>
Date:   Mon May 21 20:20:05 2012 +0300

    iommu/core: pass a user-provided token to fault handlers
    
    Sometimes a single IOMMU user may have to deal with several
    different IOMMU devices (e.g. remoteproc).
    
    When an IOMMU fault happens, such users have to regain their
    context in order to deal with the fault.
    
    Users can't use the private fields of neither the iommu_domain nor
    the IOMMU device, because those are already used by the IOMMU core
    and low level driver (respectively).
    
    This patch just simply allows users to pass a private token (most
    notably their own context pointer) to iommu_set_fault_handler(),
    and then makes sure it is provided back to the users whenever
    an IOMMU fault happens.
    
    The patch also adopts remoteproc to the new fault handling
    interface, but the real functionality using this (recovery of
    remote processors) will only be added later in a subsequent patch
    set.
    
    Cc: Fernando Guzman Lugo <fernando.lugo@ti.com>
    Signed-off-by: Ohad Ben-Cohen <ohad@wizery.com>
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 2198b2dbbcd3..8b9ded88e6f5 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -119,6 +119,7 @@ EXPORT_SYMBOL_GPL(iommu_present);
  * iommu_set_fault_handler() - set a fault handler for an iommu domain
  * @domain: iommu domain
  * @handler: fault handler
+ * @token: user data, will be passed back to the fault handler
  *
  * This function should be used by IOMMU users which want to be notified
  * whenever an IOMMU fault happens.
@@ -127,11 +128,13 @@ EXPORT_SYMBOL_GPL(iommu_present);
  * error code otherwise.
  */
 void iommu_set_fault_handler(struct iommu_domain *domain,
-					iommu_fault_handler_t handler)
+					iommu_fault_handler_t handler,
+					void *token)
 {
 	BUG_ON(!domain);
 
 	domain->handler = handler;
+	domain->handler_token = token;
 }
 EXPORT_SYMBOL_GPL(iommu_set_fault_handler);
 

commit f93ea733878733f3e98475bc3e2ccf789bebcfb8
Merge: 00fb5430f547 95bdaf71ccf2
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Mon Jan 9 13:06:28 2012 +0100

    Merge branches 'iommu/page-sizes' and 'iommu/group-id' into next
    
    Conflicts:
            drivers/iommu/amd_iommu.c
            drivers/iommu/intel-iommu.c
            include/linux/iommu.h

commit 00fb5430f547e411ab03385cfa548776aaac1c92
Merge: 805a6af8dba5 1a36ea815a35 1456e9d2c466
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Mon Jan 9 13:04:05 2012 +0100

    Merge branches 'iommu/fixes', 'arm/omap' and 'x86/amd' into next
    
    Conflicts:
            drivers/pci/hotplug/acpiphp_glue.c

commit 8bd6960c6ae65d7f92bfb708154ee813417d7b26
Author: KyongHo Cho <pullip.cho@samsung.com>
Date:   Fri Dec 16 21:38:25 2011 +0900

    iommu: Initialize domain->handler in iommu_domain_alloc()
    
    Since it is not guaranteed that an iommu driver initializes in its
    domain_init() function, it must be initialized with NULL to prevent
    calling a function in an arbitrary location when iommu fault occurred.
    
    Signed-off-by: KyongHo Cho <pullip.cho@samsung.com>
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 2fb2963df553..5b5fa5cdaa31 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -90,7 +90,7 @@ struct iommu_domain *iommu_domain_alloc(struct bus_type *bus)
 	if (bus == NULL || bus->iommu_ops == NULL)
 		return NULL;
 
-	domain = kmalloc(sizeof(*domain), GFP_KERNEL);
+	domain = kzalloc(sizeof(*domain), GFP_KERNEL);
 	if (!domain)
 		return NULL;
 

commit 1460432cb513f0c16136ed132c20ecfbf8ccf942
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Fri Oct 21 15:56:05 2011 -0400

    iommu: Add iommu_device_group callback and iommu_group sysfs entry
    
    An IOMMU group is a set of devices for which the IOMMU cannot
    distinguish transactions.  For PCI devices, a group often occurs
    when a PCI bridge is involved.  Transactions from any device
    behind the bridge appear to be sourced from the bridge itself.
    We leave it to the IOMMU driver to define the grouping restraints
    for their platform.
    
    Using this new interface, the group for a device can be retrieved
    using the iommu_device_group() callback.  Users will compare the
    value returned against the value returned for other devices to
    determine whether they are part of the same group.  Devices with
    no group are not translated by the IOMMU.  There should be no
    expectations about the group numbers as they may be arbitrarily
    assigned by the IOMMU driver and may not be persistent across boots.
    
    We also provide a sysfs interface to the group numbers here so
    that userspace can understand IOMMU dependencies between devices
    for managing safe, userspace drivers.
    
    [Some code changes by Joerg Roedel <joerg.roedel@amd.com>]
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 2fb2963df553..9c35be4b333f 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -25,8 +25,59 @@
 #include <linux/errno.h>
 #include <linux/iommu.h>
 
+static ssize_t show_iommu_group(struct device *dev,
+				struct device_attribute *attr, char *buf)
+{
+	unsigned int groupid;
+
+	if (iommu_device_group(dev, &groupid))
+		return 0;
+
+	return sprintf(buf, "%u", groupid);
+}
+static DEVICE_ATTR(iommu_group, S_IRUGO, show_iommu_group, NULL);
+
+static int add_iommu_group(struct device *dev, void *data)
+{
+	unsigned int groupid;
+
+	if (iommu_device_group(dev, &groupid) == 0)
+		return device_create_file(dev, &dev_attr_iommu_group);
+
+	return 0;
+}
+
+static int remove_iommu_group(struct device *dev)
+{
+	unsigned int groupid;
+
+	if (iommu_device_group(dev, &groupid) == 0)
+		device_remove_file(dev, &dev_attr_iommu_group);
+
+	return 0;
+}
+
+static int iommu_device_notifier(struct notifier_block *nb,
+				 unsigned long action, void *data)
+{
+	struct device *dev = data;
+
+	if (action == BUS_NOTIFY_ADD_DEVICE)
+		return add_iommu_group(dev, NULL);
+	else if (action == BUS_NOTIFY_DEL_DEVICE)
+		return remove_iommu_group(dev);
+
+	return 0;
+}
+
+static struct notifier_block iommu_device_nb = {
+	.notifier_call = iommu_device_notifier,
+};
+
 static void iommu_bus_init(struct bus_type *bus, struct iommu_ops *ops)
 {
+	bus_register_notifier(bus, &iommu_device_nb);
+	bus_for_each_dev(bus, NULL, NULL, add_iommu_group);
 }
 
 /**
@@ -186,3 +237,12 @@ int iommu_unmap(struct iommu_domain *domain, unsigned long iova, int gfp_order)
 	return domain->ops->unmap(domain, iova, gfp_order);
 }
 EXPORT_SYMBOL_GPL(iommu_unmap);
+
+int iommu_device_group(struct device *dev, unsigned int *groupid)
+{
+	if (iommu_present(dev->bus) && dev->bus->iommu_ops->device_group)
+		return dev->bus->iommu_ops->device_group(dev, groupid);
+
+	return -ENODEV;
+}
+EXPORT_SYMBOL_GPL(iommu_device_group);

commit 6c274d1cd5b3aa0834e9f0c3f58038f42278ff8c
Author: Ohad Ben-Cohen <ohad@wizery.com>
Date:   Thu Nov 10 11:32:31 2011 +0200

    iommu/core: remove the temporary pgsize settings
    
    Now that all IOMMU drivers are exporting their supported pgsizes,
    we can remove the default pgsize settings in register_iommu().
    
    Signed-off-by: Ohad Ben-Cohen <ohad@wizery.com>
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index b278458d5816..84cdd8ac81f1 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -49,16 +49,6 @@ int bus_set_iommu(struct bus_type *bus, struct iommu_ops *ops)
 	if (bus->iommu_ops != NULL)
 		return -EBUSY;
 
-	/*
-	 * Set the default pgsize values, which retain the existing
-	 * IOMMU API behavior: drivers will be called to map
-	 * regions that are sized/aligned to order of 4KiB pages.
-	 *
-	 * This will be removed once all drivers are migrated.
-	 */
-	if (!ops->pgsize_bitmap)
-		ops->pgsize_bitmap = ~0xFFFUL;
-
 	bus->iommu_ops = ops;
 
 	/* Do IOMMU specific setup for this bus-type */

commit 7d3002cc8c160dbda0e6ab9cd66dc6eb401b8b70
Author: Ohad Ben-Cohen <ohad@wizery.com>
Date:   Thu Nov 10 11:32:26 2011 +0200

    iommu/core: split mapping to page sizes as supported by the hardware
    
    When mapping a memory region, split it to page sizes as supported
    by the iommu hardware. Always prefer bigger pages, when possible,
    in order to reduce the TLB pressure.
    
    The logic to do that is now added to the IOMMU core, so neither the iommu
    drivers themselves nor users of the IOMMU API have to duplicate it.
    
    This allows a more lenient granularity of mappings; traditionally the
    IOMMU API took 'order' (of a page) as a mapping size, and directly let
    the low level iommu drivers handle the mapping, but now that the IOMMU
    core can split arbitrary memory regions into pages, we can remove this
    limitation, so users don't have to split those regions by themselves.
    
    Currently the supported page sizes are advertised once and they then
    remain static. That works well for OMAP and MSM but it would probably
    not fly well with intel's hardware, where the page size capabilities
    seem to have the potential to be different between several DMA
    remapping devices.
    
    register_iommu() currently sets a default pgsize behavior, so we can convert
    the IOMMU drivers in subsequent patches. After all the drivers
    are converted, the temporary default settings will be removed.
    
    Mainline users of the IOMMU API (kvm and omap-iovmm) are adopted
    to deal with bytes instead of page order.
    
    Many thanks to Joerg Roedel <Joerg.Roedel@amd.com> for significant review!
    
    Signed-off-by: Ohad Ben-Cohen <ohad@wizery.com>
    Cc: David Brown <davidb@codeaurora.org>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Joerg Roedel <Joerg.Roedel@amd.com>
    Cc: Stepan Moskovchenko <stepanm@codeaurora.org>
    Cc: KyongHo Cho <pullip.cho@samsung.com>
    Cc: Hiroshi DOYU <hdoyu@nvidia.com>
    Cc: Laurent Pinchart <laurent.pinchart@ideasonboard.com>
    Cc: kvm@vger.kernel.org
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 7a2953d8f12e..b278458d5816 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -16,6 +16,8 @@
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
 
+#define pr_fmt(fmt)    "%s: " fmt, __func__
+
 #include <linux/device.h>
 #include <linux/kernel.h>
 #include <linux/bug.h>
@@ -47,6 +49,16 @@ int bus_set_iommu(struct bus_type *bus, struct iommu_ops *ops)
 	if (bus->iommu_ops != NULL)
 		return -EBUSY;
 
+	/*
+	 * Set the default pgsize values, which retain the existing
+	 * IOMMU API behavior: drivers will be called to map
+	 * regions that are sized/aligned to order of 4KiB pages.
+	 *
+	 * This will be removed once all drivers are migrated.
+	 */
+	if (!ops->pgsize_bitmap)
+		ops->pgsize_bitmap = ~0xFFFUL;
+
 	bus->iommu_ops = ops;
 
 	/* Do IOMMU specific setup for this bus-type */
@@ -157,34 +169,125 @@ int iommu_domain_has_cap(struct iommu_domain *domain,
 EXPORT_SYMBOL_GPL(iommu_domain_has_cap);
 
 int iommu_map(struct iommu_domain *domain, unsigned long iova,
-	      phys_addr_t paddr, int gfp_order, int prot)
+	      phys_addr_t paddr, size_t size, int prot)
 {
-	size_t size;
+	unsigned long orig_iova = iova;
+	unsigned int min_pagesz;
+	size_t orig_size = size;
+	int ret = 0;
 
 	if (unlikely(domain->ops->map == NULL))
 		return -ENODEV;
 
-	size         = PAGE_SIZE << gfp_order;
+	/* find out the minimum page size supported */
+	min_pagesz = 1 << __ffs(domain->ops->pgsize_bitmap);
+
+	/*
+	 * both the virtual address and the physical one, as well as
+	 * the size of the mapping, must be aligned (at least) to the
+	 * size of the smallest page supported by the hardware
+	 */
+	if (!IS_ALIGNED(iova | paddr | size, min_pagesz)) {
+		pr_err("unaligned: iova 0x%lx pa 0x%lx size 0x%lx min_pagesz "
+			"0x%x\n", iova, (unsigned long)paddr,
+			(unsigned long)size, min_pagesz);
+		return -EINVAL;
+	}
+
+	pr_debug("map: iova 0x%lx pa 0x%lx size 0x%lx\n", iova,
+				(unsigned long)paddr, (unsigned long)size);
+
+	while (size) {
+		unsigned long pgsize, addr_merge = iova | paddr;
+		unsigned int pgsize_idx;
+
+		/* Max page size that still fits into 'size' */
+		pgsize_idx = __fls(size);
+
+		/* need to consider alignment requirements ? */
+		if (likely(addr_merge)) {
+			/* Max page size allowed by both iova and paddr */
+			unsigned int align_pgsize_idx = __ffs(addr_merge);
+
+			pgsize_idx = min(pgsize_idx, align_pgsize_idx);
+		}
+
+		/* build a mask of acceptable page sizes */
+		pgsize = (1UL << (pgsize_idx + 1)) - 1;
+
+		/* throw away page sizes not supported by the hardware */
+		pgsize &= domain->ops->pgsize_bitmap;
 
-	BUG_ON(!IS_ALIGNED(iova | paddr, size));
+		/* make sure we're still sane */
+		BUG_ON(!pgsize);
 
-	return domain->ops->map(domain, iova, paddr, size, prot);
+		/* pick the biggest page */
+		pgsize_idx = __fls(pgsize);
+		pgsize = 1UL << pgsize_idx;
+
+		pr_debug("mapping: iova 0x%lx pa 0x%lx pgsize %lu\n", iova,
+					(unsigned long)paddr, pgsize);
+
+		ret = domain->ops->map(domain, iova, paddr, pgsize, prot);
+		if (ret)
+			break;
+
+		iova += pgsize;
+		paddr += pgsize;
+		size -= pgsize;
+	}
+
+	/* unroll mapping in case something went wrong */
+	if (ret)
+		iommu_unmap(domain, orig_iova, orig_size - size);
+
+	return ret;
 }
 EXPORT_SYMBOL_GPL(iommu_map);
 
-int iommu_unmap(struct iommu_domain *domain, unsigned long iova, int gfp_order)
+size_t iommu_unmap(struct iommu_domain *domain, unsigned long iova, size_t size)
 {
-	size_t size, unmapped;
+	size_t unmapped_page, unmapped = 0;
+	unsigned int min_pagesz;
 
 	if (unlikely(domain->ops->unmap == NULL))
 		return -ENODEV;
 
-	size         = PAGE_SIZE << gfp_order;
-
-	BUG_ON(!IS_ALIGNED(iova, size));
-
-	unmapped = domain->ops->unmap(domain, iova, size);
-
-	return get_order(unmapped);
+	/* find out the minimum page size supported */
+	min_pagesz = 1 << __ffs(domain->ops->pgsize_bitmap);
+
+	/*
+	 * The virtual address, as well as the size of the mapping, must be
+	 * aligned (at least) to the size of the smallest page supported
+	 * by the hardware
+	 */
+	if (!IS_ALIGNED(iova | size, min_pagesz)) {
+		pr_err("unaligned: iova 0x%lx size 0x%lx min_pagesz 0x%x\n",
+					iova, (unsigned long)size, min_pagesz);
+		return -EINVAL;
+	}
+
+	pr_debug("unmap this: iova 0x%lx size 0x%lx\n", iova,
+							(unsigned long)size);
+
+	/*
+	 * Keep iterating until we either unmap 'size' bytes (or more)
+	 * or we hit an area that isn't mapped.
+	 */
+	while (unmapped < size) {
+		size_t left = size - unmapped;
+
+		unmapped_page = domain->ops->unmap(domain, iova, left);
+		if (!unmapped_page)
+			break;
+
+		pr_debug("unmapped: iova 0x%lx size %lx\n", iova,
+					(unsigned long)unmapped_page);
+
+		iova += unmapped_page;
+		unmapped += unmapped_page;
+	}
+
+	return unmapped;
 }
 EXPORT_SYMBOL_GPL(iommu_unmap);

commit 5009065d38c95455bd2d27c2838313e3dd0c5bc7
Author: Ohad Ben-Cohen <ohad@wizery.com>
Date:   Thu Nov 10 11:32:25 2011 +0200

    iommu/core: stop converting bytes to page order back and forth
    
    Express sizes in bytes rather than in page order, to eliminate the
    size->order->size conversions we have whenever the IOMMU API is calling
    the low level drivers' map/unmap methods.
    
    Adopt all existing drivers.
    
    Signed-off-by: Ohad Ben-Cohen <ohad@wizery.com>
    Cc: David Brown <davidb@codeaurora.org>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Joerg Roedel <Joerg.Roedel@amd.com>
    Cc: Stepan Moskovchenko <stepanm@codeaurora.org>
    Cc: KyongHo Cho <pullip.cho@samsung.com>
    Cc: Hiroshi DOYU <hdoyu@nvidia.com>
    Cc: Laurent Pinchart <laurent.pinchart@ideasonboard.com>
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 2fb2963df553..7a2953d8f12e 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -168,13 +168,13 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 
 	BUG_ON(!IS_ALIGNED(iova | paddr, size));
 
-	return domain->ops->map(domain, iova, paddr, gfp_order, prot);
+	return domain->ops->map(domain, iova, paddr, size, prot);
 }
 EXPORT_SYMBOL_GPL(iommu_map);
 
 int iommu_unmap(struct iommu_domain *domain, unsigned long iova, int gfp_order)
 {
-	size_t size;
+	size_t size, unmapped;
 
 	if (unlikely(domain->ops->unmap == NULL))
 		return -ENODEV;
@@ -183,6 +183,8 @@ int iommu_unmap(struct iommu_domain *domain, unsigned long iova, int gfp_order)
 
 	BUG_ON(!IS_ALIGNED(iova, size));
 
-	return domain->ops->unmap(domain, iova, gfp_order);
+	unmapped = domain->ops->unmap(domain, iova, size);
+
+	return get_order(unmapped);
 }
 EXPORT_SYMBOL_GPL(iommu_unmap);

commit 1abb4ba596a91a839f82e0c9c837b777d574e83d
Merge: 899e3ee40496 fcd0861db1cf e4efd94bde1a 0ed6d2d27bcc 94441c3bd992
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Fri Oct 21 14:38:55 2011 +0200

    Merge branches 'amd/fixes', 'debug/dma-api', 'arm/omap', 'arm/msm', 'core', 'iommu/fault-reporting' and 'api/iommu-ops-per-bus' into next
    
    Conflicts:
            drivers/iommu/amd_iommu.c
            drivers/iommu/iommu.c

commit 94441c3bd99287b9d84f148a08cc9a44675ec749
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Tue Sep 6 18:58:54 2011 +0200

    iommu/core: Remove global iommu_ops and register_iommu
    
    With all IOMMU drivers being converted to bus_set_iommu the
    global iommu_ops are no longer required. The same is true
    for the deprecated register_iommu function.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 1575aaa36c94..64419c88727e 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -25,16 +25,6 @@
 #include <linux/errno.h>
 #include <linux/iommu.h>
 
-static struct iommu_ops *iommu_ops;
-
-void register_iommu(struct iommu_ops *ops)
-{
-	if (iommu_ops)
-		BUG();
-
-	iommu_ops = ops;
-}
-
 static void iommu_bus_init(struct bus_type *bus, struct iommu_ops *ops)
 {
 }
@@ -68,34 +58,25 @@ EXPORT_SYMBOL_GPL(bus_set_iommu);
 
 bool iommu_present(struct bus_type *bus)
 {
-	if (bus->iommu_ops != NULL)
-		return true;
-	else
-		return iommu_ops != NULL;
+	return bus->iommu_ops != NULL;
 }
 EXPORT_SYMBOL_GPL(iommu_present);
 
 struct iommu_domain *iommu_domain_alloc(struct bus_type *bus)
 {
 	struct iommu_domain *domain;
-	struct iommu_ops *ops;
 	int ret;
 
-	if (bus->iommu_ops)
-		ops = bus->iommu_ops;
-	else
-		ops = iommu_ops;
-
-	if (ops == NULL)
+	if (bus == NULL || bus->iommu_ops == NULL)
 		return NULL;
 
 	domain = kmalloc(sizeof(*domain), GFP_KERNEL);
 	if (!domain)
 		return NULL;
 
-	domain->ops = ops;
+	domain->ops = bus->iommu_ops;
 
-	ret = iommu_ops->domain_init(domain);
+	ret = domain->ops->domain_init(domain);
 	if (ret)
 		goto out_free;
 

commit e5aa7f00776f2d73f410ede5c1f68246cdc83de1
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Tue Sep 6 16:44:29 2011 +0200

    iommu/core: Use bus->iommu_ops in the iommu-api
    
    Use the per-bus iommu-ops in the functions of the iommu-api
    instead of the global iommu_ops.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index ad8ce1addb4d..1575aaa36c94 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -110,34 +110,48 @@ EXPORT_SYMBOL_GPL(iommu_domain_alloc);
 
 void iommu_domain_free(struct iommu_domain *domain)
 {
-	iommu_ops->domain_destroy(domain);
+	if (likely(domain->ops->domain_destroy != NULL))
+		domain->ops->domain_destroy(domain);
+
 	kfree(domain);
 }
 EXPORT_SYMBOL_GPL(iommu_domain_free);
 
 int iommu_attach_device(struct iommu_domain *domain, struct device *dev)
 {
-	return iommu_ops->attach_dev(domain, dev);
+	if (unlikely(domain->ops->attach_dev == NULL))
+		return -ENODEV;
+
+	return domain->ops->attach_dev(domain, dev);
 }
 EXPORT_SYMBOL_GPL(iommu_attach_device);
 
 void iommu_detach_device(struct iommu_domain *domain, struct device *dev)
 {
-	iommu_ops->detach_dev(domain, dev);
+	if (unlikely(domain->ops->detach_dev == NULL))
+		return;
+
+	domain->ops->detach_dev(domain, dev);
 }
 EXPORT_SYMBOL_GPL(iommu_detach_device);
 
 phys_addr_t iommu_iova_to_phys(struct iommu_domain *domain,
 			       unsigned long iova)
 {
-	return iommu_ops->iova_to_phys(domain, iova);
+	if (unlikely(domain->ops->iova_to_phys == NULL))
+		return 0;
+
+	return domain->ops->iova_to_phys(domain, iova);
 }
 EXPORT_SYMBOL_GPL(iommu_iova_to_phys);
 
 int iommu_domain_has_cap(struct iommu_domain *domain,
 			 unsigned long cap)
 {
-	return iommu_ops->domain_has_cap(domain, cap);
+	if (unlikely(domain->ops->domain_has_cap == NULL))
+		return 0;
+
+	return domain->ops->domain_has_cap(domain, cap);
 }
 EXPORT_SYMBOL_GPL(iommu_domain_has_cap);
 
@@ -146,11 +160,14 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 {
 	size_t size;
 
+	if (unlikely(domain->ops->map == NULL))
+		return -ENODEV;
+
 	size         = PAGE_SIZE << gfp_order;
 
 	BUG_ON(!IS_ALIGNED(iova | paddr, size));
 
-	return iommu_ops->map(domain, iova, paddr, gfp_order, prot);
+	return domain->ops->map(domain, iova, paddr, gfp_order, prot);
 }
 EXPORT_SYMBOL_GPL(iommu_map);
 
@@ -158,10 +175,13 @@ int iommu_unmap(struct iommu_domain *domain, unsigned long iova, int gfp_order)
 {
 	size_t size;
 
+	if (unlikely(domain->ops->unmap == NULL))
+		return -ENODEV;
+
 	size         = PAGE_SIZE << gfp_order;
 
 	BUG_ON(!IS_ALIGNED(iova, size));
 
-	return iommu_ops->unmap(domain, iova, gfp_order);
+	return domain->ops->unmap(domain, iova, gfp_order);
 }
 EXPORT_SYMBOL_GPL(iommu_unmap);

commit a1b60c1cd913c5ccfb38c717ba0bd22622425fa7
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Tue Sep 6 18:46:34 2011 +0200

    iommu/core: Convert iommu_found to iommu_present
    
    With per-bus iommu_ops the iommu_found function needs to
    work on a bus_type too. This patch adds a bus_type parameter
    to that function and converts all call-places.
    The function is also renamed to iommu_present because the
    function now checks if an iommu is present for a given bus
    and does not check for a global iommu anymore.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 46e1c24f2f43..ad8ce1addb4d 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -66,11 +66,14 @@ int bus_set_iommu(struct bus_type *bus, struct iommu_ops *ops)
 }
 EXPORT_SYMBOL_GPL(bus_set_iommu);
 
-bool iommu_found(void)
+bool iommu_present(struct bus_type *bus)
 {
-	return iommu_ops != NULL;
+	if (bus->iommu_ops != NULL)
+		return true;
+	else
+		return iommu_ops != NULL;
 }
-EXPORT_SYMBOL_GPL(iommu_found);
+EXPORT_SYMBOL_GPL(iommu_present);
 
 struct iommu_domain *iommu_domain_alloc(struct bus_type *bus)
 {

commit 905d66c1e5dc8149e111f04a32bb193f25da1d53
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Tue Sep 6 16:03:26 2011 +0200

    iommu/core: Add bus_type parameter to iommu_domain_alloc
    
    This is necessary to store a pointer to the bus-specific
    iommu_ops in the iommu-domain structure. It will be used
    later to call into bus-specific iommu-ops.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 3343264f5105..46e1c24f2f43 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -16,6 +16,7 @@
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
 
+#include <linux/device.h>
 #include <linux/kernel.h>
 #include <linux/bug.h>
 #include <linux/types.h>
@@ -71,15 +72,26 @@ bool iommu_found(void)
 }
 EXPORT_SYMBOL_GPL(iommu_found);
 
-struct iommu_domain *iommu_domain_alloc(void)
+struct iommu_domain *iommu_domain_alloc(struct bus_type *bus)
 {
 	struct iommu_domain *domain;
+	struct iommu_ops *ops;
 	int ret;
 
+	if (bus->iommu_ops)
+		ops = bus->iommu_ops;
+	else
+		ops = iommu_ops;
+
+	if (ops == NULL)
+		return NULL;
+
 	domain = kmalloc(sizeof(*domain), GFP_KERNEL);
 	if (!domain)
 		return NULL;
 
+	domain->ops = ops;
+
 	ret = iommu_ops->domain_init(domain);
 	if (ret)
 		goto out_free;

commit ff21776d12ff7993a6b236b8273ef62777d25dfb
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Fri Aug 26 16:48:26 2011 +0200

    Driver core: Add iommu_ops to bus_type
    
    This is the starting point to make the iommu_ops used for
    the iommu-api a per-bus-type structure. It is required to
    easily implement bus-specific setup in the iommu-layer.
    The first user will be the iommu-group attribute in sysfs.
    
    Acked-by: Greg Kroah-Hartman <gregkh@suse.de>
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 30b064497486..3343264f5105 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -34,6 +34,37 @@ void register_iommu(struct iommu_ops *ops)
 	iommu_ops = ops;
 }
 
+static void iommu_bus_init(struct bus_type *bus, struct iommu_ops *ops)
+{
+}
+
+/**
+ * bus_set_iommu - set iommu-callbacks for the bus
+ * @bus: bus.
+ * @ops: the callbacks provided by the iommu-driver
+ *
+ * This function is called by an iommu driver to set the iommu methods
+ * used for a particular bus. Drivers for devices on that bus can use
+ * the iommu-api after these ops are registered.
+ * This special function is needed because IOMMUs are usually devices on
+ * the bus itself, so the iommu drivers are not initialized when the bus
+ * is set up. With this function the iommu-driver can set the iommu-ops
+ * afterwards.
+ */
+int bus_set_iommu(struct bus_type *bus, struct iommu_ops *ops)
+{
+	if (bus->iommu_ops != NULL)
+		return -EBUSY;
+
+	bus->iommu_ops = ops;
+
+	/* Do IOMMU specific setup for this bus-type */
+	iommu_bus_init(bus, ops);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(bus_set_iommu);
+
 bool iommu_found(void)
 {
 	return iommu_ops != NULL;

commit 0ed6d2d27bcc2ace454a8c55446e1bc3efd2d529
Author: Ohad Ben-Cohen <ohad@wizery.com>
Date:   Tue Sep 27 07:36:40 2011 -0400

    iommu/core: let drivers know if an iommu fault handler isn't installed
    
    Make report_iommu_fault() return -ENOSYS whenever an iommu fault
    handler isn't installed, so IOMMU drivers can then do their own
    platform-specific default behavior if they wanted.
    
    Fault handlers can still return -ENOSYS in case they want to elicit the
    default behavior of the IOMMU drivers.
    
    Signed-off-by: Ohad Ben-Cohen <ohad@wizery.com>
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 3a072596b1b2..bd2d4d2764dd 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -43,6 +43,12 @@ EXPORT_SYMBOL_GPL(iommu_found);
  * iommu_set_fault_handler() - set a fault handler for an iommu domain
  * @domain: iommu domain
  * @handler: fault handler
+ *
+ * This function should be used by IOMMU users which want to be notified
+ * whenever an IOMMU fault happens.
+ *
+ * The fault handler itself should return 0 on success, and an appropriate
+ * error code otherwise.
  */
 void iommu_set_fault_handler(struct iommu_domain *domain,
 					iommu_fault_handler_t handler)

commit 30bd918c7132adddd370c79fd5619bf108efd702
Author: Ohad Ben-Cohen <ohad@wizery.com>
Date:   Mon Sep 26 09:11:46 2011 -0400

    iommu/core: export iommu_set_fault_handler()
    
    commit 4f3f8d9 "iommu/core: Add fault reporting mechanism" added
    the public iommu_set_fault_handler() symbol but forgot to export it.
    
    Fix that.
    
    Signed-off-by: Ohad Ben-Cohen <ohad@wizery.com>
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index b75d9fb2fa91..3a072596b1b2 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -51,6 +51,7 @@ void iommu_set_fault_handler(struct iommu_domain *domain,
 
 	domain->handler = handler;
 }
+EXPORT_SYMBOL_GPL(iommu_set_fault_handler);
 
 struct iommu_domain *iommu_domain_alloc(void)
 {

commit 4f3f8d9db359bbc780d482849f2a9c8b12f910b6
Author: Ohad Ben-Cohen <ohad@wizery.com>
Date:   Tue Sep 13 15:25:23 2011 -0400

    iommu/core: Add fault reporting mechanism
    
    Add iommu fault report mechanism to the IOMMU API, so implementations
    could report about mmu faults (translation errors, hardware errors,
    etc..).
    
    Fault reports can be used in several ways:
    - mere logging
    - reset the device that accessed the faulting address (may be necessary
      in case the device is a remote processor for example)
    - implement dynamic PTE/TLB loading
    
    A dedicated iommu_set_fault_handler() API has been added to allow
    users, who are interested to receive such reports, to provide
    their handler.
    
    Signed-off-by: Ohad Ben-Cohen <ohad@wizery.com>
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 6e6b6a11b3ce..b75d9fb2fa91 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -39,6 +39,19 @@ bool iommu_found(void)
 }
 EXPORT_SYMBOL_GPL(iommu_found);
 
+/**
+ * iommu_set_fault_handler() - set a fault handler for an iommu domain
+ * @domain: iommu domain
+ * @handler: fault handler
+ */
+void iommu_set_fault_handler(struct iommu_domain *domain,
+					iommu_fault_handler_t handler)
+{
+	BUG_ON(!domain);
+
+	domain->handler = handler;
+}
+
 struct iommu_domain *iommu_domain_alloc(void)
 {
 	struct iommu_domain *domain;

commit 85410340e0d0224c78c7d40a3ac7e1b3e9670cf1
Author: Joerg Roedel <joerg.roedel@amd.com>
Date:   Tue Sep 6 14:36:17 2011 +0200

    iommu/core: Use PAGE_SIZE instead of hard-coded value
    
    Replace the hard-coded 4kb by PAGE_SIZE to make iommu-api
    implementations possible on architectures where
    PAGE_SIZE != 4kb.
    
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index e61a9bad6df3..30b064497486 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -100,7 +100,7 @@ int iommu_map(struct iommu_domain *domain, unsigned long iova,
 {
 	size_t size;
 
-	size         = 0x1000UL << gfp_order;
+	size         = PAGE_SIZE << gfp_order;
 
 	BUG_ON(!IS_ALIGNED(iova | paddr, size));
 
@@ -112,7 +112,7 @@ int iommu_unmap(struct iommu_domain *domain, unsigned long iova, int gfp_order)
 {
 	size_t size;
 
-	size         = 0x1000UL << gfp_order;
+	size         = PAGE_SIZE << gfp_order;
 
 	BUG_ON(!IS_ALIGNED(iova, size));
 

commit 4099818842abd98ef2b18a8ac7a2e2ad3bc3d7c2
Author: Ohad Ben-Cohen <ohad@wizery.com>
Date:   Fri Sep 2 13:32:32 2011 -0400

    iommu/core: use the existing IS_ALIGNED macro
    
    Replace iommu's alignment checks with the existing IS_ALIGNED macro,
    to drop a few lines of code and utilize IS_ALIGNED's type safety.
    
    Signed-off-by: Ohad Ben-Cohen <ohad@wizery.com>
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
index 6e6b6a11b3ce..e61a9bad6df3 100644
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@ -16,6 +16,7 @@
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
 
+#include <linux/kernel.h>
 #include <linux/bug.h>
 #include <linux/types.h>
 #include <linux/module.h>
@@ -97,13 +98,11 @@ EXPORT_SYMBOL_GPL(iommu_domain_has_cap);
 int iommu_map(struct iommu_domain *domain, unsigned long iova,
 	      phys_addr_t paddr, int gfp_order, int prot)
 {
-	unsigned long invalid_mask;
 	size_t size;
 
 	size         = 0x1000UL << gfp_order;
-	invalid_mask = size - 1;
 
-	BUG_ON((iova | paddr) & invalid_mask);
+	BUG_ON(!IS_ALIGNED(iova | paddr, size));
 
 	return iommu_ops->map(domain, iova, paddr, gfp_order, prot);
 }
@@ -111,13 +110,11 @@ EXPORT_SYMBOL_GPL(iommu_map);
 
 int iommu_unmap(struct iommu_domain *domain, unsigned long iova, int gfp_order)
 {
-	unsigned long invalid_mask;
 	size_t size;
 
 	size         = 0x1000UL << gfp_order;
-	invalid_mask = size - 1;
 
-	BUG_ON(iova & invalid_mask);
+	BUG_ON(!IS_ALIGNED(iova, size));
 
 	return iommu_ops->unmap(domain, iova, gfp_order);
 }

commit ab493a0f0f55d28636ac860ea682d57b84257f10
Author: Ohad Ben-Cohen <ohad@wizery.com>
Date:   Thu Jun 2 02:48:05 2011 +0300

    drivers: iommu: move to a dedicated folder
    
    Create a dedicated folder for iommu drivers, and move the base
    iommu implementation over there.
    
    Grouping the various iommu drivers in a single location will help
    finding similar problems shared by different platforms, so they
    could be solved once, in the iommu framework, instead of solved
    differently (or duplicated) in each driver.
    
    Signed-off-by: Ohad Ben-Cohen <ohad@wizery.com>
    Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>

diff --git a/drivers/iommu/iommu.c b/drivers/iommu/iommu.c
new file mode 100644
index 000000000000..6e6b6a11b3ce
--- /dev/null
+++ b/drivers/iommu/iommu.c
@@ -0,0 +1,124 @@
+/*
+ * Copyright (C) 2007-2008 Advanced Micro Devices, Inc.
+ * Author: Joerg Roedel <joerg.roedel@amd.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
+ */
+
+#include <linux/bug.h>
+#include <linux/types.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/errno.h>
+#include <linux/iommu.h>
+
+static struct iommu_ops *iommu_ops;
+
+void register_iommu(struct iommu_ops *ops)
+{
+	if (iommu_ops)
+		BUG();
+
+	iommu_ops = ops;
+}
+
+bool iommu_found(void)
+{
+	return iommu_ops != NULL;
+}
+EXPORT_SYMBOL_GPL(iommu_found);
+
+struct iommu_domain *iommu_domain_alloc(void)
+{
+	struct iommu_domain *domain;
+	int ret;
+
+	domain = kmalloc(sizeof(*domain), GFP_KERNEL);
+	if (!domain)
+		return NULL;
+
+	ret = iommu_ops->domain_init(domain);
+	if (ret)
+		goto out_free;
+
+	return domain;
+
+out_free:
+	kfree(domain);
+
+	return NULL;
+}
+EXPORT_SYMBOL_GPL(iommu_domain_alloc);
+
+void iommu_domain_free(struct iommu_domain *domain)
+{
+	iommu_ops->domain_destroy(domain);
+	kfree(domain);
+}
+EXPORT_SYMBOL_GPL(iommu_domain_free);
+
+int iommu_attach_device(struct iommu_domain *domain, struct device *dev)
+{
+	return iommu_ops->attach_dev(domain, dev);
+}
+EXPORT_SYMBOL_GPL(iommu_attach_device);
+
+void iommu_detach_device(struct iommu_domain *domain, struct device *dev)
+{
+	iommu_ops->detach_dev(domain, dev);
+}
+EXPORT_SYMBOL_GPL(iommu_detach_device);
+
+phys_addr_t iommu_iova_to_phys(struct iommu_domain *domain,
+			       unsigned long iova)
+{
+	return iommu_ops->iova_to_phys(domain, iova);
+}
+EXPORT_SYMBOL_GPL(iommu_iova_to_phys);
+
+int iommu_domain_has_cap(struct iommu_domain *domain,
+			 unsigned long cap)
+{
+	return iommu_ops->domain_has_cap(domain, cap);
+}
+EXPORT_SYMBOL_GPL(iommu_domain_has_cap);
+
+int iommu_map(struct iommu_domain *domain, unsigned long iova,
+	      phys_addr_t paddr, int gfp_order, int prot)
+{
+	unsigned long invalid_mask;
+	size_t size;
+
+	size         = 0x1000UL << gfp_order;
+	invalid_mask = size - 1;
+
+	BUG_ON((iova | paddr) & invalid_mask);
+
+	return iommu_ops->map(domain, iova, paddr, gfp_order, prot);
+}
+EXPORT_SYMBOL_GPL(iommu_map);
+
+int iommu_unmap(struct iommu_domain *domain, unsigned long iova, int gfp_order)
+{
+	unsigned long invalid_mask;
+	size_t size;
+
+	size         = 0x1000UL << gfp_order;
+	invalid_mask = size - 1;
+
+	BUG_ON(iova & invalid_mask);
+
+	return iommu_ops->unmap(domain, iova, gfp_order);
+}
+EXPORT_SYMBOL_GPL(iommu_unmap);
