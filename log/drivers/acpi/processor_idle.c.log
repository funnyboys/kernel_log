commit 496121c02127e9c460b436244c38260b044cc45a
Author: Zhang Rui <rui.zhang@intel.com>
Date:   Wed Apr 22 15:26:07 2020 +0800

    ACPI: processor: idle: Allow probing on platforms with one ACPI C-state
    
    It is possible for ACPI _CST to return only one ACPI C-state, for
    example, when deep cstate disabled in the BIOS.
    
    And it is better for the acpi_idle driver to probe succesfully in
    this case as well for consistency.
    
    Signed-off-by: Zhang Rui <rui.zhang@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index dcc289e30166..75534c5b5433 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -308,11 +308,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 	if (ret)
 		return ret;
 
-	/*
-	 * It is expected that there will be at least 2 states, C1 and
-	 * something else (C2 or C3), so fail if that is not the case.
-	 */
-	if (pr->power.count < 2)
+	if (!pr->power.count)
 		return -EFAULT;
 
 	pr->flags.has_cst = 1;
@@ -468,8 +464,7 @@ static int acpi_processor_get_cstate_info(struct acpi_processor *pr)
 	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
 		if (pr->power.states[i].valid) {
 			pr->power.count = i;
-			if (pr->power.states[i].type >= ACPI_STATE_C2)
-				pr->flags.power = 1;
+			pr->flags.power = 1;
 		}
 	}
 

commit 77fb4e0a559a960eb36d0b2c50c781c5492577eb
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Dec 13 09:55:42 2019 +0100

    ACPI: processor: Export acpi_processor_evaluate_cst()
    
    The intel_idle driver will be modified to use ACPI _CST subsequently
    and it will need to call acpi_processor_evaluate_cst(), so move that
    function to acpi_processor.c so that it is always present (which is
    required by intel_idle) and export it to modules to allow the ACPI
    processor driver (which is modular) to call it.
    
    No intentional functional impact.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 7c2fe3b2ec31..dcc289e30166 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -297,148 +297,6 @@ static int acpi_processor_get_power_info_default(struct acpi_processor *pr)
 	return 0;
 }
 
-static int acpi_processor_evaluate_cst(acpi_handle handle, u32 cpu,
-				       struct acpi_processor_power *info)
-{
-	struct acpi_buffer buffer = { ACPI_ALLOCATE_BUFFER, NULL };
-	union acpi_object *cst;
-	acpi_status status;
-	u64 count;
-	int last_index = 0;
-	int i, ret = 0;
-
-	status = acpi_evaluate_object(handle, "_CST", NULL, &buffer);
-	if (ACPI_FAILURE(status)) {
-		acpi_handle_debug(handle, "No _CST\n");
-		return -ENODEV;
-	}
-
-	cst = buffer.pointer;
-
-	/* There must be at least 2 elements. */
-	if (!cst || cst->type != ACPI_TYPE_PACKAGE || cst->package.count < 2) {
-		acpi_handle_warn(handle, "Invalid _CST output\n");
-		ret = -EFAULT;
-		goto end;
-	}
-
-	count = cst->package.elements[0].integer.value;
-
-	/* Validate the number of C-states. */
-	if (count < 1 || count != cst->package.count - 1) {
-		acpi_handle_warn(handle, "Inconsistent _CST data\n");
-		ret = -EFAULT;
-		goto end;
-	}
-
-	for (i = 1; i <= count; i++) {
-		union acpi_object *element;
-		union acpi_object *obj;
-		struct acpi_power_register *reg;
-		struct acpi_processor_cx cx;
-
-		/*
-		 * If there is not enough space for all C-states, skip the
-		 * excess ones and log a warning.
-		 */
-		if (last_index >= ACPI_PROCESSOR_MAX_POWER - 1) {
-			acpi_handle_warn(handle,
-					 "No room for more idle states (limit: %d)\n",
-					 ACPI_PROCESSOR_MAX_POWER - 1);
-			break;
-		}
-
-		memset(&cx, 0, sizeof(cx));
-
-		element = &cst->package.elements[i];
-		if (element->type != ACPI_TYPE_PACKAGE)
-			continue;
-
-		if (element->package.count != 4)
-			continue;
-
-		obj = &element->package.elements[0];
-
-		if (obj->type != ACPI_TYPE_BUFFER)
-			continue;
-
-		reg = (struct acpi_power_register *)obj->buffer.pointer;
-
-		obj = &element->package.elements[1];
-		if (obj->type != ACPI_TYPE_INTEGER)
-			continue;
-
-		cx.type = obj->integer.value;
-		/*
-		 * There are known cases in which the _CST output does not
-		 * contain C1, so if the type of the first state found is not
-		 * C1, leave an empty slot for C1 to be filled in later.
-		 */
-		if (i == 1 && cx.type != ACPI_STATE_C1)
-			last_index = 1;
-
-		cx.address = reg->address;
-		cx.index = last_index + 1;
-
-		if (reg->space_id == ACPI_ADR_SPACE_FIXED_HARDWARE) {
-			if (!acpi_processor_ffh_cstate_probe(cpu, &cx, reg)) {
-				/*
-				 * In the majority of cases _CST describes C1 as
-				 * a FIXED_HARDWARE C-state, but if the command
-				 * line forbids using MWAIT, use CSTATE_HALT for
-				 * C1 regardless.
-				 */
-				if (cx.type == ACPI_STATE_C1 &&
-				    boot_option_idle_override == IDLE_NOMWAIT) {
-					cx.entry_method = ACPI_CSTATE_HALT;
-					snprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI HLT");
-				} else {
-					cx.entry_method = ACPI_CSTATE_FFH;
-				}
-			} else if (cx.type == ACPI_STATE_C1) {
-				/*
-				 * In the special case of C1, FIXED_HARDWARE can
-				 * be handled by executing the HLT instruction.
-				 */
-				cx.entry_method = ACPI_CSTATE_HALT;
-				snprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI HLT");
-			} else {
-				continue;
-			}
-		} else if (reg->space_id == ACPI_ADR_SPACE_SYSTEM_IO) {
-			cx.entry_method = ACPI_CSTATE_SYSTEMIO;
-			snprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI IOPORT 0x%x",
-				 cx.address);
-		} else {
-			continue;
-		}
-
-		if (cx.type == ACPI_STATE_C1)
-			cx.valid = 1;
-
-		obj = &element->package.elements[2];
-		if (obj->type != ACPI_TYPE_INTEGER)
-			continue;
-
-		cx.latency = obj->integer.value;
-
-		obj = &element->package.elements[3];
-		if (obj->type != ACPI_TYPE_INTEGER)
-			continue;
-
-		memcpy(&info->states[++last_index], &cx, sizeof(cx));
-	}
-
-	acpi_handle_info(handle, "Found %d idle states\n", last_index);
-
-	info->count = last_index;
-
-      end:
-	kfree(buffer.pointer);
-
-	return ret;
-}
-
 static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 {
 	int ret;

commit aa659a3fca79abd9a3ca3ddc535db631b01c9a02
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Dec 13 09:55:33 2019 +0100

    ACPI: processor: Clean up acpi_processor_evaluate_cst()
    
    Clean up acpi_processor_evaluate_cst() in multiple ways:
    
     * Rename current_count to last_index which matches the purpose of
       the variable better.
    
     * Consistently use acpi_handle_*() for printing messages and make
       the messages cleaner.
    
     * Drop redundant parens and braces.
    
     * Rewrite and clarify comments.
    
     * Rearrange checks and drop the redundant ones.
    
    No intentional functional impact.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index e92d0e6d4cd1..7c2fe3b2ec31 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -304,29 +304,29 @@ static int acpi_processor_evaluate_cst(acpi_handle handle, u32 cpu,
 	union acpi_object *cst;
 	acpi_status status;
 	u64 count;
-	int current_count = 0;
+	int last_index = 0;
 	int i, ret = 0;
 
 	status = acpi_evaluate_object(handle, "_CST", NULL, &buffer);
 	if (ACPI_FAILURE(status)) {
-		ACPI_DEBUG_PRINT((ACPI_DB_INFO, "No _CST, giving up\n"));
+		acpi_handle_debug(handle, "No _CST\n");
 		return -ENODEV;
 	}
 
 	cst = buffer.pointer;
 
-	/* There must be at least 2 elements */
-	if (!cst || (cst->type != ACPI_TYPE_PACKAGE) || cst->package.count < 2) {
-		pr_err("not enough elements in _CST\n");
+	/* There must be at least 2 elements. */
+	if (!cst || cst->type != ACPI_TYPE_PACKAGE || cst->package.count < 2) {
+		acpi_handle_warn(handle, "Invalid _CST output\n");
 		ret = -EFAULT;
 		goto end;
 	}
 
 	count = cst->package.elements[0].integer.value;
 
-	/* Validate number of power states. */
+	/* Validate the number of C-states. */
 	if (count < 1 || count != cst->package.count - 1) {
-		pr_err("count given by _CST is not valid\n");
+		acpi_handle_warn(handle, "Inconsistent _CST data\n");
 		ret = -EFAULT;
 		goto end;
 	}
@@ -337,111 +337,101 @@ static int acpi_processor_evaluate_cst(acpi_handle handle, u32 cpu,
 		struct acpi_power_register *reg;
 		struct acpi_processor_cx cx;
 
+		/*
+		 * If there is not enough space for all C-states, skip the
+		 * excess ones and log a warning.
+		 */
+		if (last_index >= ACPI_PROCESSOR_MAX_POWER - 1) {
+			acpi_handle_warn(handle,
+					 "No room for more idle states (limit: %d)\n",
+					 ACPI_PROCESSOR_MAX_POWER - 1);
+			break;
+		}
+
 		memset(&cx, 0, sizeof(cx));
 
-		element = &(cst->package.elements[i]);
+		element = &cst->package.elements[i];
 		if (element->type != ACPI_TYPE_PACKAGE)
 			continue;
 
 		if (element->package.count != 4)
 			continue;
 
-		obj = &(element->package.elements[0]);
+		obj = &element->package.elements[0];
 
 		if (obj->type != ACPI_TYPE_BUFFER)
 			continue;
 
 		reg = (struct acpi_power_register *)obj->buffer.pointer;
 
-		if (reg->space_id != ACPI_ADR_SPACE_SYSTEM_IO &&
-		    (reg->space_id != ACPI_ADR_SPACE_FIXED_HARDWARE))
-			continue;
-
-		/* There should be an easy way to extract an integer... */
-		obj = &(element->package.elements[1]);
+		obj = &element->package.elements[1];
 		if (obj->type != ACPI_TYPE_INTEGER)
 			continue;
 
 		cx.type = obj->integer.value;
 		/*
-		 * Some buggy BIOSes won't list C1 in _CST -
-		 * Let acpi_processor_get_power_info_default() handle them later
+		 * There are known cases in which the _CST output does not
+		 * contain C1, so if the type of the first state found is not
+		 * C1, leave an empty slot for C1 to be filled in later.
 		 */
 		if (i == 1 && cx.type != ACPI_STATE_C1)
-			current_count++;
+			last_index = 1;
 
 		cx.address = reg->address;
-		cx.index = current_count + 1;
+		cx.index = last_index + 1;
 
-		cx.entry_method = ACPI_CSTATE_SYSTEMIO;
 		if (reg->space_id == ACPI_ADR_SPACE_FIXED_HARDWARE) {
-			if (acpi_processor_ffh_cstate_probe
-					(cpu, &cx, reg) == 0) {
-				cx.entry_method = ACPI_CSTATE_FFH;
+			if (!acpi_processor_ffh_cstate_probe(cpu, &cx, reg)) {
+				/*
+				 * In the majority of cases _CST describes C1 as
+				 * a FIXED_HARDWARE C-state, but if the command
+				 * line forbids using MWAIT, use CSTATE_HALT for
+				 * C1 regardless.
+				 */
+				if (cx.type == ACPI_STATE_C1 &&
+				    boot_option_idle_override == IDLE_NOMWAIT) {
+					cx.entry_method = ACPI_CSTATE_HALT;
+					snprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI HLT");
+				} else {
+					cx.entry_method = ACPI_CSTATE_FFH;
+				}
 			} else if (cx.type == ACPI_STATE_C1) {
 				/*
-				 * C1 is a special case where FIXED_HARDWARE
-				 * can be handled in non-MWAIT way as well.
-				 * In that case, save this _CST entry info.
-				 * Otherwise, ignore this info and continue.
+				 * In the special case of C1, FIXED_HARDWARE can
+				 * be handled by executing the HLT instruction.
 				 */
 				cx.entry_method = ACPI_CSTATE_HALT;
 				snprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI HLT");
 			} else {
 				continue;
 			}
-			if (cx.type == ACPI_STATE_C1 &&
-			    (boot_option_idle_override == IDLE_NOMWAIT)) {
-				/*
-				 * In most cases the C1 space_id obtained from
-				 * _CST object is FIXED_HARDWARE access mode.
-				 * But when the option of idle=halt is added,
-				 * the entry_method type should be changed from
-				 * CSTATE_FFH to CSTATE_HALT.
-				 * When the option of idle=nomwait is added,
-				 * the C1 entry_method type should be
-				 * CSTATE_HALT.
-				 */
-				cx.entry_method = ACPI_CSTATE_HALT;
-				snprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI HLT");
-			}
-		} else {
+		} else if (reg->space_id == ACPI_ADR_SPACE_SYSTEM_IO) {
+			cx.entry_method = ACPI_CSTATE_SYSTEMIO;
 			snprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI IOPORT 0x%x",
 				 cx.address);
+		} else {
+			continue;
 		}
 
-		if (cx.type == ACPI_STATE_C1) {
+		if (cx.type == ACPI_STATE_C1)
 			cx.valid = 1;
-		}
 
-		obj = &(element->package.elements[2]);
+		obj = &element->package.elements[2];
 		if (obj->type != ACPI_TYPE_INTEGER)
 			continue;
 
 		cx.latency = obj->integer.value;
 
-		obj = &(element->package.elements[3]);
+		obj = &element->package.elements[3];
 		if (obj->type != ACPI_TYPE_INTEGER)
 			continue;
 
-		current_count++;
-		memcpy(&info->states[current_count], &cx, sizeof(cx));
-
-		/*
-		 * We support total ACPI_PROCESSOR_MAX_POWER - 1
-		 * (From 1 through ACPI_PROCESSOR_MAX_POWER - 1)
-		 */
-		if (current_count >= (ACPI_PROCESSOR_MAX_POWER - 1)) {
-			pr_warn("Limiting number of power states to max (%d)\n",
-				ACPI_PROCESSOR_MAX_POWER);
-			pr_warn("Please increase ACPI_PROCESSOR_MAX_POWER if needed.\n");
-			break;
-		}
+		memcpy(&info->states[++last_index], &cx, sizeof(cx));
 	}
 
-	acpi_handle_info(handle, "Found %d idle states\n", current_count);
+	acpi_handle_info(handle, "Found %d idle states\n", last_index);
 
-	info->count = current_count;
+	info->count = last_index;
 
       end:
 	kfree(buffer.pointer);

commit 987c785319b99e32602f7f86cfae3cf9b81e402b
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Dec 13 09:55:24 2019 +0100

    ACPI: processor: Introduce acpi_processor_evaluate_cst()
    
    In order to separate the ACPI _CST evaluation from checks
    specific to the ACPI processor driver, move the majority of
    the acpi_processor_get_power_info_cst() function body to a new
    function, acpi_processor_evaluate_cst(), that will extract
    the C-states information from _CST output, and redefine
    acpi_processor_get_power_info_cst() as a wrapper around it.
    
    No intentional functional impact.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index dd737d836c03..e92d0e6d4cd1 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -297,21 +297,17 @@ static int acpi_processor_get_power_info_default(struct acpi_processor *pr)
 	return 0;
 }
 
-static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
+static int acpi_processor_evaluate_cst(acpi_handle handle, u32 cpu,
+				       struct acpi_processor_power *info)
 {
+	struct acpi_buffer buffer = { ACPI_ALLOCATE_BUFFER, NULL };
+	union acpi_object *cst;
 	acpi_status status;
 	u64 count;
-	int current_count;
+	int current_count = 0;
 	int i, ret = 0;
-	struct acpi_buffer buffer = { ACPI_ALLOCATE_BUFFER, NULL };
-	union acpi_object *cst;
-
-	if (nocst)
-		return -ENODEV;
 
-	current_count = 0;
-
-	status = acpi_evaluate_object(pr->handle, "_CST", NULL, &buffer);
+	status = acpi_evaluate_object(handle, "_CST", NULL, &buffer);
 	if (ACPI_FAILURE(status)) {
 		ACPI_DEBUG_PRINT((ACPI_DB_INFO, "No _CST, giving up\n"));
 		return -ENODEV;
@@ -335,9 +331,6 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 		goto end;
 	}
 
-	/* Tell driver that at least _CST is supported. */
-	pr->flags.has_cst = 1;
-
 	for (i = 1; i <= count; i++) {
 		union acpi_object *element;
 		union acpi_object *obj;
@@ -383,7 +376,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 		cx.entry_method = ACPI_CSTATE_SYSTEMIO;
 		if (reg->space_id == ACPI_ADR_SPACE_FIXED_HARDWARE) {
 			if (acpi_processor_ffh_cstate_probe
-					(pr->id, &cx, reg) == 0) {
+					(cpu, &cx, reg) == 0) {
 				cx.entry_method = ACPI_CSTATE_FFH;
 			} else if (cx.type == ACPI_STATE_C1) {
 				/*
@@ -432,7 +425,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 			continue;
 
 		current_count++;
-		memcpy(&(pr->power.states[current_count]), &cx, sizeof(cx));
+		memcpy(&info->states[current_count], &cx, sizeof(cx));
 
 		/*
 		 * We support total ACPI_PROCESSOR_MAX_POWER - 1
@@ -446,12 +439,9 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 		}
 	}
 
-	ACPI_DEBUG_PRINT((ACPI_DB_INFO, "Found %d power states\n",
-			  current_count));
+	acpi_handle_info(handle, "Found %d idle states\n", current_count);
 
-	/* Validate number of power states discovered */
-	if (current_count < 2)
-		ret = -EFAULT;
+	info->count = current_count;
 
       end:
 	kfree(buffer.pointer);
@@ -459,6 +449,28 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 	return ret;
 }
 
+static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
+{
+	int ret;
+
+	if (nocst)
+		return -ENODEV;
+
+	ret = acpi_processor_evaluate_cst(pr->handle, pr->id, &pr->power);
+	if (ret)
+		return ret;
+
+	/*
+	 * It is expected that there will be at least 2 states, C1 and
+	 * something else (C2 or C3), so fail if that is not the case.
+	 */
+	if (pr->power.count < 2)
+		return -EFAULT;
+
+	pr->flags.has_cst = 1;
+	return 0;
+}
+
 static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 					   struct acpi_processor_cx *cx)
 {

commit bc94638886ab21f8247d3f7f39573d3feb7d8284
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Dec 13 09:55:14 2019 +0100

    ACPI: processor: Export function to claim _CST control
    
    The intel_idle driver will be modified to use ACPI _CST subsequently
    and it will need to notify the platform firmware of that if
    acpi_gbl_FADT.cst_control is set, so add a routine for this purpose,
    acpi_processor_claim_cst_control(), to acpi_processor.c (so that it
    is always present which is required by intel_idle) and export it
    to allow the ACPI processor driver (which is modular) to call it.
    
    No intentional functional impact.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 2ae95df2e74f..dd737d836c03 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -909,7 +909,6 @@ static int acpi_processor_setup_cstates(struct acpi_processor *pr)
 
 static inline void acpi_processor_cstate_first_run_checks(void)
 {
-	acpi_status status;
 	static int first_run;
 
 	if (first_run)
@@ -921,13 +920,10 @@ static inline void acpi_processor_cstate_first_run_checks(void)
 			  max_cstate);
 	first_run++;
 
-	if (acpi_gbl_FADT.cst_control && !nocst) {
-		status = acpi_os_write_port(acpi_gbl_FADT.smi_command,
-					    acpi_gbl_FADT.cst_control, 8);
-		if (ACPI_FAILURE(status))
-			ACPI_EXCEPTION((AE_INFO, status,
-					"Notifying BIOS of _CST ability failed"));
-	}
+	if (nocst)
+		return;
+
+	acpi_processor_claim_cst_control();
 }
 #else
 

commit fa583f71a99c85e52781ed877c82c8757437b680
Author: Yin Fengwei <fengwei.yin@intel.com>
Date:   Thu Oct 24 15:04:20 2019 +0800

    ACPI: processor_idle: Skip dummy wait if kernel is in guest
    
    In function acpi_idle_do_entry(), an ioport access is used for
    dummy wait to guarantee hardware behavior. But it could trigger
    unnecessary VMexit if kernel is running as guest in virtualization
    environment.
    
    If it's in virtualization environment, the deeper C state enter
    operation (inb()) will trap to hypervisor. It's not needed to do
    dummy wait after the inb() call. So we could just remove the
    dummy io port access to avoid unnecessary VMexit.
    
    And keep dummy io port access to maintain timing for native
    environment.
    
    Signed-off-by: Yin Fengwei <fengwei.yin@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index ed56c6d20b08..2ae95df2e74f 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -642,6 +642,19 @@ static int acpi_idle_bm_check(void)
 	return bm_status;
 }
 
+static void wait_for_freeze(void)
+{
+#ifdef	CONFIG_X86
+	/* No delay is needed if we are in guest */
+	if (boot_cpu_has(X86_FEATURE_HYPERVISOR))
+		return;
+#endif
+	/* Dummy wait op - must do something useless after P_LVL2 read
+	   because chipsets cannot guarantee that STPCLK# signal
+	   gets asserted in time to freeze execution properly. */
+	inl(acpi_gbl_FADT.xpm_timer_block.address);
+}
+
 /**
  * acpi_idle_do_entry - enter idle state using the appropriate method
  * @cx: cstate data
@@ -658,10 +671,7 @@ static void __cpuidle acpi_idle_do_entry(struct acpi_processor_cx *cx)
 	} else {
 		/* IO port based C-state */
 		inb(cx->address);
-		/* Dummy wait op - must do something useless after P_LVL2 read
-		   because chipsets cannot guarantee that STPCLK# signal
-		   gets asserted in time to freeze execution properly. */
-		inl(acpi_gbl_FADT.xpm_timer_block.address);
+		wait_for_freeze();
 	}
 }
 
@@ -682,8 +692,7 @@ static int acpi_idle_play_dead(struct cpuidle_device *dev, int index)
 			safe_halt();
 		else if (cx->entry_method == ACPI_CSTATE_SYSTEMIO) {
 			inb(cx->address);
-			/* See comment in acpi_idle_do_entry() */
-			inl(acpi_gbl_FADT.xpm_timer_block.address);
+			wait_for_freeze();
 		} else
 			return -ENODEV;
 	}

commit 773b2f30a3fc026f3ed121a8b945b0ae19b64ec5
Author: Tony W Wang-oc <TonyWWang-oc@zhaoxin.com>
Date:   Tue Jun 18 08:37:14 2019 +0000

    ACPI, x86: Add Zhaoxin processors support for NONSTOP TSC
    
    Zhaoxin CPUs have NONSTOP TSC feature, so enable the ACPI
    driver support for it.
    
    Signed-off-by: Tony W Wang-oc <TonyWWang-oc@zhaoxin.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: "hpa@zytor.com" <hpa@zytor.com>
    Cc: "gregkh@linuxfoundation.org" <gregkh@linuxfoundation.org>
    Cc: "rjw@rjwysocki.net" <rjw@rjwysocki.net>
    Cc: "lenb@kernel.org" <lenb@kernel.org>
    Cc: David Wang <DavidWang@zhaoxin.com>
    Cc: "Cooper Yan(BJ-RD)" <CooperYan@zhaoxin.com>
    Cc: "Qiyuan Wang(BJ-RD)" <QiyuanWang@zhaoxin.com>
    Cc: "Herry Yang(BJ-RD)" <HerryYang@zhaoxin.com>
    Link: https://lkml.kernel.org/r/d1cfd937dabc44518d42038b55522c53@zhaoxin.com

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index e387a258d649..ed56c6d20b08 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -196,6 +196,7 @@ static void tsc_check_state(int state)
 	case X86_VENDOR_AMD:
 	case X86_VENDOR_INTEL:
 	case X86_VENDOR_CENTAUR:
+	case X86_VENDOR_ZHAOXIN:
 		/*
 		 * AMD Fam10h TSC will tick in all
 		 * C/P/S0/S1 states when this bit is set.

commit c942fddf8793b2013be8c901b47d0a8dc02bf99f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:06 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 157
    
    Based on 3 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version this program is distributed in the
      hope that it will be useful but without any warranty without even
      the implied warranty of merchantability or fitness for a particular
      purpose see the gnu general public license for more details
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version [author] [kishon] [vijay] [abraham]
      [i] [kishon]@[ti] [com] this program is distributed in the hope that
      it will be useful but without any warranty without even the implied
      warranty of merchantability or fitness for a particular purpose see
      the gnu general public license for more details
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version [author] [graeme] [gregory]
      [gg]@[slimlogic] [co] [uk] [author] [kishon] [vijay] [abraham] [i]
      [kishon]@[ti] [com] [based] [on] [twl6030]_[usb] [c] [author] [hema]
      [hk] [hemahk]@[ti] [com] this program is distributed in the hope
      that it will be useful but without any warranty without even the
      implied warranty of merchantability or fitness for a particular
      purpose see the gnu general public license for more details
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 1105 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Richard Fontana <rfontana@redhat.com>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070033.202006027@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 98d4ec5bf450..e387a258d649 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  * processor_idle - idle state submodule to the ACPI processor driver
  *
@@ -8,20 +9,6 @@
  *  			- Added processor hotplug support
  *  Copyright (C) 2005  Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
  *  			- Added support for C3 on SMP
- *
- * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
- *
- *  This program is free software; you can redistribute it and/or modify
- *  it under the terms of the GNU General Public License as published by
- *  the Free Software Foundation; either version 2 of the License, or (at
- *  your option) any later version.
- *
- *  This program is distributed in the hope that it will be useful, but
- *  WITHOUT ANY WARRANTY; without even the implied warranty of
- *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- *  General Public License for more details.
- *
- * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  */
 #define pr_fmt(fmt) "ACPI: " fmt
 

commit 34a62cd0df89dd7034165048c0921d1314191b66
Author: Yazen Ghannam <yazen.ghannam@amd.com>
Date:   Mon Feb 18 01:33:49 2019 +0000

    ACPI / processor: Set P_LVL{2,3} idle state descriptions
    
    The ACPI idle driver will fallback to using the legacy P_LVL* SystemIO
    method of entering C-states if the _CST method is disabled and P_BLK is
    defined. However, in this case the C2 and C3 states won't have a
    description set, so the user will see "<null>" when reading the
    description from sysfs.
    
    Give each of these states a description.
    
    Signed-off-by: Yazen Ghannam <yazen.ghannam@amd.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index b2131c4ea124..98d4ec5bf450 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -282,6 +282,13 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 			  pr->power.states[ACPI_STATE_C2].address,
 			  pr->power.states[ACPI_STATE_C3].address));
 
+	snprintf(pr->power.states[ACPI_STATE_C2].desc,
+			 ACPI_CX_DESC_LEN, "ACPI P_LVL2 IOPORT 0x%x",
+			 pr->power.states[ACPI_STATE_C2].address);
+	snprintf(pr->power.states[ACPI_STATE_C3].desc,
+			 ACPI_CX_DESC_LEN, "ACPI P_LVL3 IOPORT 0x%x",
+			 pr->power.states[ACPI_STATE_C3].address);
+
 	return 0;
 }
 

commit 7377ed4bd56e6cc1ddbb63f03626fc5b92d3d6fe
Author: Pu Wen <puwen@hygon.cn>
Date:   Sun Sep 23 17:37:05 2018 +0800

    ACPI: Add Hygon Dhyana support
    
    The Hygon Dhyana CPU has NONSTOP TSC feature, so enable the ACPI driver
    support to it.
    
    Signed-off-by: Pu Wen <puwen@hygon.cn>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: rjw@rjwysocki.net
    Cc: tglx@linutronix.de
    Cc: mingo@redhat.com
    Cc: hpa@zytor.com
    Cc: x86@kernel.org
    Cc: thomas.lendacky@amd.com
    Cc: lenb@kernel.org
    Cc: rafael@kernel.org
    Cc: linux-acpi@vger.kernel.org
    Link: https://lkml.kernel.org/r/cce6ee26f4e2ebbab493433264d89d7cea661284.1537533369.git.puwen@hygon.cn

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index abb559cd28d7..b2131c4ea124 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -205,6 +205,7 @@ static void lapic_timer_state_broadcast(struct acpi_processor *pr,
 static void tsc_check_state(int state)
 {
 	switch (boot_cpu_data.x86_vendor) {
+	case X86_VENDOR_HYGON:
 	case X86_VENDOR_AMD:
 	case X86_VENDOR_INTEL:
 	case X86_VENDOR_CENTAUR:

commit 54ce685cae30c106f062d714c11e644ab1b93b51
Merge: a051c14b8db3 d4abd46b7e72
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Feb 9 09:44:25 2018 -0800

    Merge tag 'acpi-part2-4.16-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull more ACPI updates from Rafael Wysocki:
     "These are mostly fixes and cleanups, a few new quirks, a couple of
      updates related to the handling of ACPI tables and ACPICA copyrights
      refreshment.
    
      Specifics:
    
       - Update the ACPICA kernel code to upstream revision 20180105
         including:
           * Assorted fixes (Jung-uk Kim)
           * Support for X32 ABI compilation (Anuj Mittal)
           * Update of ACPICA copyrights to 2018 (Bob Moore)
    
       - Prepare for future modifications to avoid executing the _STA
         control method too early (Hans de Goede)
    
       - Make the processor performance control library code ignore _PPC
         notifications if they cannot be handled and fix up the C1 idle
         state definition when it is used as a fallback state (Chen Yu,
         Yazen Ghannam)
    
       - Make it possible to use the SPCR table on x86 and to replace the
         original IORT table with a new one from initrd (Prarit Bhargava,
         Shunyong Yang)
    
       - Add battery-related quirks for Asus UX360UA and UX410UAK and add
         quirks for table parsing on Dell XPS 9570 and Precision M5530 (Kai
         Heng Feng)
    
       - Address static checker warnings in the CPPC code (Gustavo Silva)
    
       - Avoid printing a raw pointer to the kernel log in the smart battery
         driver (Greg Kroah-Hartman)"
    
    * tag 'acpi-part2-4.16-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm:
      ACPI: sbshc: remove raw pointer from printk() message
      ACPI: SPCR: Make SPCR available to x86
      ACPI / CPPC: Use 64-bit arithmetic instead of 32-bit
      ACPI / tables: Add IORT to injectable table list
      ACPI / bus: Parse tables as term_list for Dell XPS 9570 and Precision M5530
      ACPICA: Update version to 20180105
      ACPICA: All acpica: Update copyrights to 2018
      ACPI / processor: Set default C1 idle state description
      ACPI / battery: Add quirk for Asus UX360UA and UX410UAK
      ACPI: processor_perflib: Do not send _PPC change notification if not ready
      ACPI / scan: Use acpi_bus_get_status() to initialize ACPI_TYPE_DEVICE devs
      ACPI / bus: Do not call _STA on battery devices with unmet dependencies
      PCI: acpiphp_ibm: prepare for acpi_get_object_info() no longer returning status
      ACPI: export acpi_bus_get_status_handle()
      ACPICA: Add a missing pair of parentheses
      ACPICA: Prefer ACPI_TO_POINTER() over ACPI_ADD_PTR()
      ACPICA: Avoid NULL pointer arithmetic
      ACPICA: Linux: add support for X32 ABI compilation
      ACPI / video: Use true for boolean value

commit 248e8841b4fbb07048f1eb4f63b74bd3c4cf91f2
Author: Yazen Ghannam <yazen.ghannam@amd.com>
Date:   Mon Jan 29 14:22:49 2018 -0600

    ACPI / processor: Set default C1 idle state description
    
    The ACPI idle driver will default to ACPI_CSTATE_HALT for C1 if a _CST
    object for C1 is not defined. However, the description will not be set,
    so users will see "<null>" when reading the description from sysfs.
    
    Set the C1 state description when defaulting to ACPI_CSTATE_HALT.
    
    Signed-off-by: Yazen Ghannam <yazen.ghannam@amd.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index d50a7b6ccddd..226dc5665d81 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -291,6 +291,9 @@ static int acpi_processor_get_power_info_default(struct acpi_processor *pr)
 		pr->power.states[ACPI_STATE_C1].type = ACPI_STATE_C1;
 		pr->power.states[ACPI_STATE_C1].valid = 1;
 		pr->power.states[ACPI_STATE_C1].entry_method = ACPI_CSTATE_HALT;
+
+		snprintf(pr->power.states[ACPI_STATE_C1].desc,
+			 ACPI_CX_DESC_LEN, "ACPI HLT");
 	}
 	/* the C0 state only exists as a filler in our array */
 	pr->power.states[ACPI_STATE_C0].valid = 1;

commit fe6daab1ee9dfe7f89974ee6c486cccb0f18a61d
Author: davidwang <davidwang@zhaoxin.com>
Date:   Mon Jan 22 18:14:17 2018 +0800

    x86/centaur: Mark TSC invariant
    
    Centaur CPU has a constant frequency TSC and that TSC does not stop in
    C-States. But because the corresponding TSC feature flags are not set for
    that CPU, the TSC is treated as not constant frequency and assumed to stop
    in C-States, which makes it an unreliable and unusable clock source.
    
    Setting those flags tells the kernel that the TSC is usable, so it will
    select it over HPET.  The effect of this is that reading time stamps (from
    kernel or user space) will be faster and more efficent.
    
    Signed-off-by: davidwang <davidwang@zhaoxin.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: qiyuanwang@zhaoxin.com
    Cc: linux-pm@vger.kernel.org
    Cc: brucechang@via-alliance.com
    Cc: cooperyan@zhaoxin.com
    Cc: benjaminpan@viatech.com
    Link: https://lkml.kernel.org/r/1516616057-5158-1-git-send-email-davidwang@zhaoxin.com

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index d50a7b6ccddd..5f0071c7e2e1 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -207,6 +207,7 @@ static void tsc_check_state(int state)
 	switch (boot_cpu_data.x86_vendor) {
 	case X86_VENDOR_AMD:
 	case X86_VENDOR_INTEL:
+	case X86_VENDOR_CENTAUR:
 		/*
 		 * AMD Fam10h TSC will tick in all
 		 * C/P/S0/S1 states when this bit is set.

commit 675357362aeba19688440eb1aaa7991067f73b12
Author: Andy Lutomirski <luto@kernel.org>
Date:   Sat Nov 4 04:16:12 2017 -0700

    Revert "x86/mm: Stop calling leave_mm() in idle code"
    
    This reverts commit 43858b4f25cf0adc5c2ca9cf5ce5fdf2532941e5.
    
    The reason I removed the leave_mm() calls in question is because the
    heuristic wasn't needed after that patch.  With the original version
    of my PCID series, we never flushed a "lazy cpu" (i.e. a CPU running
    kernel thread) due a flush on the loaded mm.
    
    Unfortunately, that caused architectural issues, so now I've
    reinstated these flushes on non-PCID systems in:
    
        commit b956575bed91 ("x86/mm: Flush more aggressively in lazy TLB mode").
    
    That, in turn, gives us a power management and occasionally
    performance regression as compared to old kernels: a process that
    goes into a deep idle state on a given CPU and gets its mm flushed
    due to activity on a different CPU will wake the idle CPU.
    
    Reinstate the old ugly heuristic: if a CPU goes into ACPI C3 or an
    intel_idle state that is likely to cause a TLB flush gets its mm
    switched to init_mm before going idle.
    
    FWIW, this heuristic is lousy.  Whether we should change CR3 before
    idle isn't a good hint except insofar as the performance hit is a bit
    lower if the TLB is getting flushed by the idle code anyway.  What we
    really want to know is whether we anticipate being idle long enough
    that the mm is likely to be flushed before we wake up.  This is more a
    matter of the expected latency than the idle state that gets chosen.
    This heuristic also completely fails on systems that don't know
    whether the TLB will be flushed (e.g. AMD systems?).  OTOH it may be a
    bit obsolete anyway -- PCID systems don't presently benefit from this
    heuristic at all.
    
    We also shouldn't do this callback from innermost bit of the idle code
    due to the RCU nastiness it causes.  All the information need is
    available before rcu_idle_enter() needs to happen.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Borislav Petkov <bpetkov@suse.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Fixes: 43858b4f25cf "x86/mm: Stop calling leave_mm() in idle code"
    Link: http://lkml.kernel.org/r/c513bbd4e653747213e05bc7062de000bf0202a5.1509793738.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 2736e25e9dc6..d50a7b6ccddd 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -710,6 +710,8 @@ static DEFINE_RAW_SPINLOCK(c3_lock);
 static void acpi_idle_enter_bm(struct acpi_processor *pr,
 			       struct acpi_processor_cx *cx, bool timer_bc)
 {
+	acpi_unlazy_tlb(smp_processor_id());
+
 	/*
 	 * Must be done before busmaster disable as we might need to
 	 * access HPET !

commit 439644096c1a6afb9bd9953130f4444a856f76c5
Merge: b42a362e6d10 d97561f461e4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 5 12:19:08 2017 -0700

    Merge tag 'pm-4.14-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull power management updates from Rafael Wysocki:
     "This time (again) cpufreq gets the majority of changes which mostly
      are driver updates (including a major consolidation of intel_pstate),
      some schedutil governor modifications and core cleanups.
    
      There also are some changes in the system suspend area, mostly related
      to diagnostics and debug messages plus some renames of things related
      to suspend-to-idle. One major change here is that suspend-to-idle is
      now going to be preferred over S3 on systems where the ACPI tables
      indicate to do so and provide requsite support (the Low Power Idle S0
      _DSM in particular). The system sleep documentation and the tools
      related to it are updated too.
    
      The rest is a few cpuidle changes (nothing major), devfreq updates,
      generic power domains (genpd) framework updates and a few assorted
      modifications elsewhere.
    
      Specifics:
    
       - Drop the P-state selection algorithm based on a PID controller from
         intel_pstate and make it use the same P-state selection method
         (based on the CPU load) for all types of systems in the active mode
         (Rafael Wysocki, Srinivas Pandruvada).
    
       - Rework the cpufreq core and governors to make it possible to take
         cross-CPU utilization updates into account and modify the schedutil
         governor to actually do so (Viresh Kumar).
    
       - Clean up the handling of transition latency information in the
         cpufreq core and untangle it from the information on which drivers
         cannot do dynamic frequency switching (Viresh Kumar).
    
       - Add support for new SoCs (MT2701/MT7623 and MT7622) to the mediatek
         cpufreq driver and update its DT bindings (Sean Wang).
    
       - Modify the cpufreq dt-platdev driver to autimatically create
         cpufreq devices for the new (v2) Operating Performance Points (OPP)
         DT bindings and update its whitelist of supported systems (Viresh
         Kumar, Shubhrajyoti Datta, Marc Gonzalez, Khiem Nguyen, Finley
         Xiao).
    
       - Add support for Ux500 to the cpufreq-dt driver and drop the
         obsolete dbx500 cpufreq driver (Linus Walleij, Arnd Bergmann).
    
       - Add new SoC (R8A7795) support to the cpufreq rcar driver (Khiem
         Nguyen).
    
       - Fix and clean up assorted issues in the cpufreq drivers and core
         (Arvind Yadav, Christophe Jaillet, Colin Ian King, Gustavo Silva,
         Julia Lawall, Leonard Crestez, Rob Herring, Sudeep Holla).
    
       - Update the IO-wait boost handling in the schedutil governor to make
         it less aggressive (Joel Fernandes).
    
       - Rework system suspend diagnostics to make it print fewer messages
         to the kernel log by default, add a sysfs knob to allow more
         suspend-related messages to be printed and add Low Power S0 Idle
         constraints checks to the ACPI suspend-to-idle code (Rafael
         Wysocki, Srinivas Pandruvada).
    
       - Prefer suspend-to-idle over S3 on ACPI-based systems with the
         ACPI_FADT_LOW_POWER_S0 flag set and the Low Power Idle S0 _DSM
         interface present in the ACPI tables (Rafael Wysocki).
    
       - Update documentation related to system sleep and rename a number of
         items in the code to make it cleare that they are related to
         suspend-to-idle (Rafael Wysocki).
    
       - Export a variable allowing device drivers to check the target
         system sleep state from the core system suspend code (Florian
         Fainelli).
    
       - Clean up the cpuidle subsystem to handle the polling state on x86
         in a more straightforward way and to use %pOF instead of full_name
         (Rafael Wysocki, Rob Herring).
    
       - Update the devfreq framework to fix and clean up a few minor issues
         (Chanwoo Choi, Rob Herring).
    
       - Extend diagnostics in the generic power domains (genpd) framework
         and clean it up slightly (Thara Gopinath, Rob Herring).
    
       - Fix and clean up a couple of issues in the operating performance
         points (OPP) framework (Viresh Kumar, Waldemar Rymarkiewicz).
    
       - Add support for RV1108 to the rockchip-io Adaptive Voltage Scaling
         (AVS) driver (David Wu).
    
       - Fix the usage of notifiers in CPU power management on some
         platforms (Alex Shi).
    
       - Update the pm-graph system suspend/hibernation and boot profiling
         utility (Todd Brandt).
    
       - Make it possible to run the cpupower utility without CPU0 (Prarit
         Bhargava)"
    
    * tag 'pm-4.14-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (87 commits)
      cpuidle: Make drivers initialize polling state
      cpuidle: Move polling state initialization code to separate file
      cpuidle: Eliminate the CPUIDLE_DRIVER_STATE_START symbol
      cpufreq: imx6q: Fix imx6sx low frequency support
      cpufreq: speedstep-lib: make several arrays static, makes code smaller
      PM: docs: Delete the obsolete states.txt document
      PM: docs: Describe high-level PM strategies and sleep states
      PM / devfreq: Fix memory leak when fail to register device
      PM / devfreq: Add dependency on PM_OPP
      PM / devfreq: Move private devfreq_update_stats() into devfreq
      PM / devfreq: Convert to using %pOF instead of full_name
      PM / AVS: rockchip-io: add io selectors and supplies for RV1108
      cpufreq: ti: Fix 'of_node_put' being called twice in error handling path
      cpufreq: dt-platdev: Drop few entries from whitelist
      cpufreq: dt-platdev: Automatically create cpufreq device with OPP v2
      ARM: ux500: don't select CPUFREQ_DT
      cpuidle: Convert to using %pOF instead of full_name
      cpufreq: Convert to using %pOF instead of full_name
      PM / Domains: Convert to using %pOF instead of full_name
      cpufreq: Cap the default transition delay value to 10 ms
      ...

commit 7b01463e51f6849d0787b24d06a62efcb243dd44
Merge: a1b5fd8fa29f 726fb6b4f2a8
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Sep 4 00:06:02 2017 +0200

    Merge branch 'pm-sleep'
    
    * pm-sleep:
      ACPI / PM: Check low power idle constraints for debug only
      PM / s2idle: Rename platform operations structure
      PM / s2idle: Rename ->enter_freeze to ->enter_s2idle
      PM / s2idle: Rename freeze_state enum and related items
      PM / s2idle: Rename PM_SUSPEND_FREEZE to PM_SUSPEND_TO_IDLE
      ACPI / PM: Prefer suspend-to-idle over S3 on some systems
      platform/x86: intel-hid: Wake up Dell Latitude 7275 from suspend-to-idle
      PM / suspend: Define pr_fmt() in suspend.c
      PM / suspend: Use mem_sleep_labels[] strings in messages
      PM / sleep: Put pm_test under CONFIG_PM_SLEEP_DEBUG
      PM / sleep: Check pm_wakeup_pending() in __device_suspend_noirq()
      PM / core: Add error argument to dpm_show_time()
      PM / core: Split dpm_suspend_noirq() and dpm_resume_noirq()
      PM / s2idle: Rearrange the main suspend-to-idle loop
      PM / timekeeping: Print debug messages when requested
      PM / sleep: Mark suspend/hibernation start and finish
      PM / sleep: Do not print debug messages by default
      PM / suspend: Export pm_suspend_target_state

commit 1b39e3f813b4685c7a30ae964d5529a1b0e3a286
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Tue Aug 29 03:14:37 2017 +0200

    cpuidle: Make drivers initialize polling state
    
    Make the drivers that want to include the polling state into their
    states table initialize it explicitly and drop the initialization of
    it (which in fact is conditional, but that is not obvious from the
    code) from the core.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Tested-by: Sudeep Holla <sudeep.holla@arm.com>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 39a01ea7a46d..df38e81cc672 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -842,7 +842,7 @@ static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,
 
 static int acpi_processor_setup_cstates(struct acpi_processor *pr)
 {
-	int i, count = ACPI_IDLE_STATE_START;
+	int i, count;
 	struct acpi_processor_cx *cx;
 	struct cpuidle_state *state;
 	struct cpuidle_driver *drv = &acpi_idle_driver;
@@ -850,6 +850,13 @@ static int acpi_processor_setup_cstates(struct acpi_processor *pr)
 	if (max_cstate == 0)
 		max_cstate = 1;
 
+	if (IS_ENABLED(CONFIG_ARCH_HAS_CPU_RELAX)) {
+		cpuidle_poll_state_init(drv);
+		count = 1;
+	} else {
+		count = 0;
+	}
+
 	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {
 		cx = &pr->power.states[i];
 

commit dc2251bf98c66db3f4e055b751968f0871037ae4
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Wed Aug 23 23:19:57 2017 +0200

    cpuidle: Eliminate the CPUIDLE_DRIVER_STATE_START symbol
    
    On some architectures the first (index 0) idle state is a polling
    one and it doesn't really save energy, so there is the
    CPUIDLE_DRIVER_STATE_START symbol allowing some pieces of
    cpuidle code to avoid using that state.
    
    However, this makes the code rather hard to follow.  It is better
    to explicitly avoid the polling state, so add a new cpuidle state
    flag CPUIDLE_FLAG_POLLING to mark it and make the relevant code
    check that flag for the first state instead of using the
    CPUIDLE_DRIVER_STATE_START symbol.
    
    In the ACPI processor driver that cannot always rely on the state
    flags (like before the states table has been set up) define
    a new internal symbol ACPI_IDLE_STATE_START equivalent to the
    CPUIDLE_DRIVER_STATE_START one and drop the latter.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Tested-by: Sudeep Holla <sudeep.holla@arm.com>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 5c8aa9cf62d7..39a01ea7a46d 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -48,6 +48,8 @@
 #define _COMPONENT              ACPI_PROCESSOR_COMPONENT
 ACPI_MODULE_NAME("processor_idle");
 
+#define ACPI_IDLE_STATE_START	(IS_ENABLED(CONFIG_ARCH_HAS_CPU_RELAX) ? 1 : 0)
+
 static unsigned int max_cstate __read_mostly = ACPI_PROCESSOR_MAX_POWER;
 module_param(max_cstate, uint, 0000);
 static unsigned int nocst __read_mostly;
@@ -761,7 +763,7 @@ static int acpi_idle_enter(struct cpuidle_device *dev,
 
 	if (cx->type != ACPI_STATE_C1) {
 		if (acpi_idle_fallback_to_c1(pr) && num_online_cpus() > 1) {
-			index = CPUIDLE_DRIVER_STATE_START;
+			index = ACPI_IDLE_STATE_START;
 			cx = per_cpu(acpi_cstate[index], dev->cpu);
 		} else if (cx->type == ACPI_STATE_C3 && pr->flags.bm_check) {
 			if (cx->bm_sts_skip || !acpi_idle_bm_check()) {
@@ -813,7 +815,7 @@ static void acpi_idle_enter_freeze(struct cpuidle_device *dev,
 static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,
 					   struct cpuidle_device *dev)
 {
-	int i, count = CPUIDLE_DRIVER_STATE_START;
+	int i, count = ACPI_IDLE_STATE_START;
 	struct acpi_processor_cx *cx;
 
 	if (max_cstate == 0)
@@ -840,7 +842,7 @@ static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,
 
 static int acpi_processor_setup_cstates(struct acpi_processor *pr)
 {
-	int i, count = CPUIDLE_DRIVER_STATE_START;
+	int i, count = ACPI_IDLE_STATE_START;
 	struct acpi_processor_cx *cx;
 	struct cpuidle_state *state;
 	struct cpuidle_driver *drv = &acpi_idle_driver;
@@ -1291,7 +1293,7 @@ static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
 		return -EINVAL;
 
 	drv->safe_state_index = -1;
-	for (i = CPUIDLE_DRIVER_STATE_START; i < CPUIDLE_STATE_MAX; i++) {
+	for (i = ACPI_IDLE_STATE_START; i < CPUIDLE_STATE_MAX; i++) {
 		drv->states[i].name[0] = '\0';
 		drv->states[i].desc[0] = '\0';
 	}

commit 28ba086ed30fb3fb714598aa029b894c3754fa7b
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu Aug 10 00:14:45 2017 +0200

    PM / s2idle: Rename ->enter_freeze to ->enter_s2idle
    
    Rename the ->enter_freeze cpuidle driver callback to ->enter_s2idle
    to make it clear that it is used for entering suspend-to-idle and
    rename the related functions, variables and so on accordingly.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 5c8aa9cf62d7..a9eb9d654b7a 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -789,7 +789,7 @@ static int acpi_idle_enter(struct cpuidle_device *dev,
 	return index;
 }
 
-static void acpi_idle_enter_freeze(struct cpuidle_device *dev,
+static void acpi_idle_enter_s2idle(struct cpuidle_device *dev,
 				   struct cpuidle_driver *drv, int index)
 {
 	struct acpi_processor_cx *cx = per_cpu(acpi_cstate[index], dev->cpu);
@@ -867,14 +867,14 @@ static int acpi_processor_setup_cstates(struct acpi_processor *pr)
 			drv->safe_state_index = count;
 		}
 		/*
-		 * Halt-induced C1 is not good for ->enter_freeze, because it
+		 * Halt-induced C1 is not good for ->enter_s2idle, because it
 		 * re-enables interrupts on exit.  Moreover, C1 is generally not
 		 * particularly interesting from the suspend-to-idle angle, so
 		 * avoid C1 and the situations in which we may need to fall back
 		 * to it altogether.
 		 */
 		if (cx->type != ACPI_STATE_C1 && !acpi_idle_fallback_to_c1(pr))
-			state->enter_freeze = acpi_idle_enter_freeze;
+			state->enter_s2idle = acpi_idle_enter_s2idle;
 
 		count++;
 		if (count == CPUIDLE_STATE_MAX)

commit 43858b4f25cf0adc5c2ca9cf5ce5fdf2532941e5
Author: Andy Lutomirski <luto@kernel.org>
Date:   Thu Jun 29 08:53:18 2017 -0700

    x86/mm: Stop calling leave_mm() in idle code
    
    Now that lazy TLB suppresses all flush IPIs (as opposed to all but
    the first), there's no need to leave_mm() when going idle.
    
    This means we can get rid of the rcuidle hack in
    switch_mm_irqs_off() and we can unexport leave_mm().
    
    This also removes acpi_unlazy_tlb() from the x86 and ia64 headers,
    since it has no callers any more.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Reviewed-by: Nadav Amit <nadav.amit@gmail.com>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/03c699cfd6021e467be650d6b73deaccfe4b4bd7.1498751203.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 5c8aa9cf62d7..fe3d2a40f311 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -708,8 +708,6 @@ static DEFINE_RAW_SPINLOCK(c3_lock);
 static void acpi_idle_enter_bm(struct acpi_processor *pr,
 			       struct acpi_processor_cx *cx, bool timer_bc)
 {
-	acpi_unlazy_tlb(smp_processor_id());
-
 	/*
 	 * Must be done before busmaster disable as we might need to
 	 * access HPET !

commit 07c94a38125376d70d156bd8bff98ddfe4c8ea95
Author: Borislav Petkov <bp@alien8.de>
Date:   Fri Dec 9 19:29:11 2016 +0100

    x86/amd: Simplify AMD E400 aware idle routine
    
    Reorganize the E400 detection now that we have everything in place:
    switch the CPUs to broadcast mode after the LAPIC has been initialized
    and remove the facilities that were used previously on the idle path.
    
    Unfortunately static_cpu_has_bug() cannpt be used in the E400 idle routine
    because alternatives have been applied when the actual detection happens,
    so the static switching does not take effect and the test will stay
    false. Use boot_cpu_has_bug() instead which is definitely an improvement
    over the RDMSR and the cpumask handling.
    
    Suggested-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Link: http://lkml.kernel.org/r/20161209182912.2726-5-bp@alien8.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 2237d3f24f0e..5c8aa9cf62d7 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -141,7 +141,7 @@ static void lapic_timer_check_state(int state, struct acpi_processor *pr,
 	if (cpu_has(&cpu_data(pr->id), X86_FEATURE_ARAT))
 		return;
 
-	if (amd_e400_c1e_detected)
+	if (boot_cpu_has_bug(X86_BUG_AMD_APIC_C1E))
 		type = ACPI_STATE_C1;
 
 	/*

commit 6727ad9e206cc08b80d8000a4d67f8417e53539d
Author: Chris Metcalf <cmetcalf@mellanox.com>
Date:   Fri Oct 7 17:02:55 2016 -0700

    nmi_backtrace: generate one-line reports for idle cpus
    
    When doing an nmi backtrace of many cores, most of which are idle, the
    output is a little overwhelming and very uninformative.  Suppress
    messages for cpus that are idling when they are interrupted and just
    emit one line, "NMI backtrace for N skipped: idling at pc 0xNNN".
    
    We do this by grouping all the cpuidle code together into a new
    .cpuidle.text section, and then checking the address of the interrupted
    PC to see if it lies within that section.
    
    This commit suitably tags x86 and tile idle routines, and only adds in
    the minimal framework for other architectures.
    
    Link: http://lkml.kernel.org/r/1472487169-14923-5-git-send-email-cmetcalf@mellanox.com
    Signed-off-by: Chris Metcalf <cmetcalf@mellanox.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Tested-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Tested-by: Daniel Thompson <daniel.thompson@linaro.org> [arm]
    Tested-by: Petr Mladek <pmladek@suse.com>
    Cc: Aaron Tomlin <atomlin@redhat.com>
    Cc: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index cea52528aa18..2237d3f24f0e 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -31,6 +31,7 @@
 #include <linux/sched.h>       /* need_resched() */
 #include <linux/tick.h>
 #include <linux/cpuidle.h>
+#include <linux/cpu.h>
 #include <acpi/processor.h>
 
 /*
@@ -115,7 +116,7 @@ static const struct dmi_system_id processor_power_dmi_table[] = {
  * Callers should disable interrupts before the call and enable
  * interrupts after return.
  */
-static void acpi_safe_halt(void)
+static void __cpuidle acpi_safe_halt(void)
 {
 	if (!tif_need_resched()) {
 		safe_halt();
@@ -645,7 +646,7 @@ static int acpi_idle_bm_check(void)
  *
  * Caller disables interrupt before call and enables interrupt after return.
  */
-static void acpi_idle_do_entry(struct acpi_processor_cx *cx)
+static void __cpuidle acpi_idle_do_entry(struct acpi_processor_cx *cx)
 {
 	if (cx->entry_method == ACPI_CSTATE_FFH) {
 		/* Call into architectural FFH based C-state */

commit a36a7fecfe6071732075ad5aa31196adce13181b
Author: Sudeep Holla <Sudeep.Holla@arm.com>
Date:   Thu Jul 21 17:18:07 2016 +0100

    ACPI / processor_idle: Add support for Low Power Idle(LPI) states
    
    ACPI 6.0 introduced an optional object _LPI that provides an alternate
    method to describe Low Power Idle states. It defines the local power
    states for each node in a hierarchical processor topology. The OSPM can
    use _LPI object to select a local power state for each level of processor
    hierarchy in the system. They used to produce a composite power state
    request that is presented to the platform by the OSPM.
    
    Since multiple processors affect the idle state for any non-leaf hierarchy
    node, coordination of idle state requests between the processors is
    required. ACPI supports two different coordination schemes: Platform
    coordinated and  OS initiated.
    
    This patch adds initial support for Platform coordination scheme of LPI.
    
    Signed-off-by: Sudeep Holla <sudeep.holla@arm.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index ca0de35d1c3a..cea52528aa18 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -303,7 +303,6 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 	struct acpi_buffer buffer = { ACPI_ALLOCATE_BUFFER, NULL };
 	union acpi_object *cst;
 
-
 	if (nocst)
 		return -ENODEV;
 
@@ -576,7 +575,7 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 	return (working);
 }
 
-static int acpi_processor_get_power_info(struct acpi_processor *pr)
+static int acpi_processor_get_cstate_info(struct acpi_processor *pr)
 {
 	unsigned int i;
 	int result;
@@ -810,31 +809,12 @@ static void acpi_idle_enter_freeze(struct cpuidle_device *dev,
 	acpi_idle_do_entry(cx);
 }
 
-/**
- * acpi_processor_setup_cpuidle_cx - prepares and configures CPUIDLE
- * device i.e. per-cpu data
- *
- * @pr: the ACPI processor
- * @dev : the cpuidle device
- */
 static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,
 					   struct cpuidle_device *dev)
 {
 	int i, count = CPUIDLE_DRIVER_STATE_START;
 	struct acpi_processor_cx *cx;
 
-	if (!pr->flags.power_setup_done)
-		return -EINVAL;
-
-	if (pr->flags.power == 0) {
-		return -EINVAL;
-	}
-
-	if (!dev)
-		return -EINVAL;
-
-	dev->cpu = pr->id;
-
 	if (max_cstate == 0)
 		max_cstate = 1;
 
@@ -857,31 +837,13 @@ static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,
 	return 0;
 }
 
-/**
- * acpi_processor_setup_cpuidle states- prepares and configures cpuidle
- * global state data i.e. idle routines
- *
- * @pr: the ACPI processor
- */
-static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
+static int acpi_processor_setup_cstates(struct acpi_processor *pr)
 {
 	int i, count = CPUIDLE_DRIVER_STATE_START;
 	struct acpi_processor_cx *cx;
 	struct cpuidle_state *state;
 	struct cpuidle_driver *drv = &acpi_idle_driver;
 
-	if (!pr->flags.power_setup_done)
-		return -EINVAL;
-
-	if (pr->flags.power == 0)
-		return -EINVAL;
-
-	drv->safe_state_index = -1;
-	for (i = CPUIDLE_DRIVER_STATE_START; i < CPUIDLE_STATE_MAX; i++) {
-		drv->states[i].name[0] = '\0';
-		drv->states[i].desc[0] = '\0';
-	}
-
 	if (max_cstate == 0)
 		max_cstate = 1;
 
@@ -893,7 +855,7 @@ static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
 
 		state = &drv->states[count];
 		snprintf(state->name, CPUIDLE_NAME_LEN, "C%d", i);
-		strncpy(state->desc, cx->desc, CPUIDLE_DESC_LEN);
+		strlcpy(state->desc, cx->desc, CPUIDLE_DESC_LEN);
 		state->exit_latency = cx->latency;
 		state->target_residency = cx->latency * latency_factor;
 		state->enter = acpi_idle_enter;
@@ -952,7 +914,7 @@ static inline void acpi_processor_cstate_first_run_checks(void)
 
 static inline int disabled_by_idle_boot_param(void) { return 0; }
 static inline void acpi_processor_cstate_first_run_checks(void) { }
-static int acpi_processor_get_power_info(struct acpi_processor *pr)
+static int acpi_processor_get_cstate_info(struct acpi_processor *pr)
 {
 	return -ENODEV;
 }
@@ -963,13 +925,413 @@ static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,
 	return -EINVAL;
 }
 
-static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
+static int acpi_processor_setup_cstates(struct acpi_processor *pr)
 {
 	return -EINVAL;
 }
 
 #endif /* CONFIG_ACPI_PROCESSOR_CSTATE */
 
+struct acpi_lpi_states_array {
+	unsigned int size;
+	unsigned int composite_states_size;
+	struct acpi_lpi_state *entries;
+	struct acpi_lpi_state *composite_states[ACPI_PROCESSOR_MAX_POWER];
+};
+
+static int obj_get_integer(union acpi_object *obj, u32 *value)
+{
+	if (obj->type != ACPI_TYPE_INTEGER)
+		return -EINVAL;
+
+	*value = obj->integer.value;
+	return 0;
+}
+
+static int acpi_processor_evaluate_lpi(acpi_handle handle,
+				       struct acpi_lpi_states_array *info)
+{
+	acpi_status status;
+	int ret = 0;
+	int pkg_count, state_idx = 1, loop;
+	struct acpi_buffer buffer = { ACPI_ALLOCATE_BUFFER, NULL };
+	union acpi_object *lpi_data;
+	struct acpi_lpi_state *lpi_state;
+
+	status = acpi_evaluate_object(handle, "_LPI", NULL, &buffer);
+	if (ACPI_FAILURE(status)) {
+		ACPI_DEBUG_PRINT((ACPI_DB_INFO, "No _LPI, giving up\n"));
+		return -ENODEV;
+	}
+
+	lpi_data = buffer.pointer;
+
+	/* There must be at least 4 elements = 3 elements + 1 package */
+	if (!lpi_data || lpi_data->type != ACPI_TYPE_PACKAGE ||
+	    lpi_data->package.count < 4) {
+		pr_debug("not enough elements in _LPI\n");
+		ret = -ENODATA;
+		goto end;
+	}
+
+	pkg_count = lpi_data->package.elements[2].integer.value;
+
+	/* Validate number of power states. */
+	if (pkg_count < 1 || pkg_count != lpi_data->package.count - 3) {
+		pr_debug("count given by _LPI is not valid\n");
+		ret = -ENODATA;
+		goto end;
+	}
+
+	lpi_state = kcalloc(pkg_count, sizeof(*lpi_state), GFP_KERNEL);
+	if (!lpi_state) {
+		ret = -ENOMEM;
+		goto end;
+	}
+
+	info->size = pkg_count;
+	info->entries = lpi_state;
+
+	/* LPI States start at index 3 */
+	for (loop = 3; state_idx <= pkg_count; loop++, state_idx++, lpi_state++) {
+		union acpi_object *element, *pkg_elem, *obj;
+
+		element = &lpi_data->package.elements[loop];
+		if (element->type != ACPI_TYPE_PACKAGE || element->package.count < 7)
+			continue;
+
+		pkg_elem = element->package.elements;
+
+		obj = pkg_elem + 6;
+		if (obj->type == ACPI_TYPE_BUFFER) {
+			struct acpi_power_register *reg;
+
+			reg = (struct acpi_power_register *)obj->buffer.pointer;
+			if (reg->space_id != ACPI_ADR_SPACE_SYSTEM_IO &&
+			    reg->space_id != ACPI_ADR_SPACE_FIXED_HARDWARE)
+				continue;
+
+			lpi_state->address = reg->address;
+			lpi_state->entry_method =
+				reg->space_id == ACPI_ADR_SPACE_FIXED_HARDWARE ?
+				ACPI_CSTATE_FFH : ACPI_CSTATE_SYSTEMIO;
+		} else if (obj->type == ACPI_TYPE_INTEGER) {
+			lpi_state->entry_method = ACPI_CSTATE_INTEGER;
+			lpi_state->address = obj->integer.value;
+		} else {
+			continue;
+		}
+
+		/* elements[7,8] skipped for now i.e. Residency/Usage counter*/
+
+		obj = pkg_elem + 9;
+		if (obj->type == ACPI_TYPE_STRING)
+			strlcpy(lpi_state->desc, obj->string.pointer,
+				ACPI_CX_DESC_LEN);
+
+		lpi_state->index = state_idx;
+		if (obj_get_integer(pkg_elem + 0, &lpi_state->min_residency)) {
+			pr_debug("No min. residency found, assuming 10 us\n");
+			lpi_state->min_residency = 10;
+		}
+
+		if (obj_get_integer(pkg_elem + 1, &lpi_state->wake_latency)) {
+			pr_debug("No wakeup residency found, assuming 10 us\n");
+			lpi_state->wake_latency = 10;
+		}
+
+		if (obj_get_integer(pkg_elem + 2, &lpi_state->flags))
+			lpi_state->flags = 0;
+
+		if (obj_get_integer(pkg_elem + 3, &lpi_state->arch_flags))
+			lpi_state->arch_flags = 0;
+
+		if (obj_get_integer(pkg_elem + 4, &lpi_state->res_cnt_freq))
+			lpi_state->res_cnt_freq = 1;
+
+		if (obj_get_integer(pkg_elem + 5, &lpi_state->enable_parent_state))
+			lpi_state->enable_parent_state = 0;
+	}
+
+	acpi_handle_debug(handle, "Found %d power states\n", state_idx);
+end:
+	kfree(buffer.pointer);
+	return ret;
+}
+
+/*
+ * flat_state_cnt - the number of composite LPI states after the process of flattening
+ */
+static int flat_state_cnt;
+
+/**
+ * combine_lpi_states - combine local and parent LPI states to form a composite LPI state
+ *
+ * @local: local LPI state
+ * @parent: parent LPI state
+ * @result: composite LPI state
+ */
+static bool combine_lpi_states(struct acpi_lpi_state *local,
+			       struct acpi_lpi_state *parent,
+			       struct acpi_lpi_state *result)
+{
+	if (parent->entry_method == ACPI_CSTATE_INTEGER) {
+		if (!parent->address) /* 0 means autopromotable */
+			return false;
+		result->address = local->address + parent->address;
+	} else {
+		result->address = parent->address;
+	}
+
+	result->min_residency = max(local->min_residency, parent->min_residency);
+	result->wake_latency = local->wake_latency + parent->wake_latency;
+	result->enable_parent_state = parent->enable_parent_state;
+	result->entry_method = local->entry_method;
+
+	result->flags = parent->flags;
+	result->arch_flags = parent->arch_flags;
+	result->index = parent->index;
+
+	strlcpy(result->desc, local->desc, ACPI_CX_DESC_LEN);
+	strlcat(result->desc, "+", ACPI_CX_DESC_LEN);
+	strlcat(result->desc, parent->desc, ACPI_CX_DESC_LEN);
+	return true;
+}
+
+#define ACPI_LPI_STATE_FLAGS_ENABLED			BIT(0)
+
+static void stash_composite_state(struct acpi_lpi_states_array *curr_level,
+				  struct acpi_lpi_state *t)
+{
+	curr_level->composite_states[curr_level->composite_states_size++] = t;
+}
+
+static int flatten_lpi_states(struct acpi_processor *pr,
+			      struct acpi_lpi_states_array *curr_level,
+			      struct acpi_lpi_states_array *prev_level)
+{
+	int i, j, state_count = curr_level->size;
+	struct acpi_lpi_state *p, *t = curr_level->entries;
+
+	curr_level->composite_states_size = 0;
+	for (j = 0; j < state_count; j++, t++) {
+		struct acpi_lpi_state *flpi;
+
+		if (!(t->flags & ACPI_LPI_STATE_FLAGS_ENABLED))
+			continue;
+
+		if (flat_state_cnt >= ACPI_PROCESSOR_MAX_POWER) {
+			pr_warn("Limiting number of LPI states to max (%d)\n",
+				ACPI_PROCESSOR_MAX_POWER);
+			pr_warn("Please increase ACPI_PROCESSOR_MAX_POWER if needed.\n");
+			break;
+		}
+
+		flpi = &pr->power.lpi_states[flat_state_cnt];
+
+		if (!prev_level) { /* leaf/processor node */
+			memcpy(flpi, t, sizeof(*t));
+			stash_composite_state(curr_level, flpi);
+			flat_state_cnt++;
+			continue;
+		}
+
+		for (i = 0; i < prev_level->composite_states_size; i++) {
+			p = prev_level->composite_states[i];
+			if (t->index <= p->enable_parent_state &&
+			    combine_lpi_states(p, t, flpi)) {
+				stash_composite_state(curr_level, flpi);
+				flat_state_cnt++;
+				flpi++;
+			}
+		}
+	}
+
+	kfree(curr_level->entries);
+	return 0;
+}
+
+static int acpi_processor_get_lpi_info(struct acpi_processor *pr)
+{
+	int ret, i;
+	acpi_status status;
+	acpi_handle handle = pr->handle, pr_ahandle;
+	struct acpi_device *d = NULL;
+	struct acpi_lpi_states_array info[2], *tmp, *prev, *curr;
+
+	if (!osc_pc_lpi_support_confirmed)
+		return -EOPNOTSUPP;
+
+	if (!acpi_has_method(handle, "_LPI"))
+		return -EINVAL;
+
+	flat_state_cnt = 0;
+	prev = &info[0];
+	curr = &info[1];
+	handle = pr->handle;
+	ret = acpi_processor_evaluate_lpi(handle, prev);
+	if (ret)
+		return ret;
+	flatten_lpi_states(pr, prev, NULL);
+
+	status = acpi_get_parent(handle, &pr_ahandle);
+	while (ACPI_SUCCESS(status)) {
+		acpi_bus_get_device(pr_ahandle, &d);
+		handle = pr_ahandle;
+
+		if (strcmp(acpi_device_hid(d), ACPI_PROCESSOR_CONTAINER_HID))
+			break;
+
+		/* can be optional ? */
+		if (!acpi_has_method(handle, "_LPI"))
+			break;
+
+		ret = acpi_processor_evaluate_lpi(handle, curr);
+		if (ret)
+			break;
+
+		/* flatten all the LPI states in this level of hierarchy */
+		flatten_lpi_states(pr, curr, prev);
+
+		tmp = prev, prev = curr, curr = tmp;
+
+		status = acpi_get_parent(handle, &pr_ahandle);
+	}
+
+	pr->power.count = flat_state_cnt;
+	/* reset the index after flattening */
+	for (i = 0; i < pr->power.count; i++)
+		pr->power.lpi_states[i].index = i;
+
+	/* Tell driver that _LPI is supported. */
+	pr->flags.has_lpi = 1;
+	pr->flags.power = 1;
+
+	return 0;
+}
+
+int __weak acpi_processor_ffh_lpi_probe(unsigned int cpu)
+{
+	return -ENODEV;
+}
+
+int __weak acpi_processor_ffh_lpi_enter(struct acpi_lpi_state *lpi)
+{
+	return -ENODEV;
+}
+
+/**
+ * acpi_idle_lpi_enter - enters an ACPI any LPI state
+ * @dev: the target CPU
+ * @drv: cpuidle driver containing cpuidle state info
+ * @index: index of target state
+ *
+ * Return: 0 for success or negative value for error
+ */
+static int acpi_idle_lpi_enter(struct cpuidle_device *dev,
+			       struct cpuidle_driver *drv, int index)
+{
+	struct acpi_processor *pr;
+	struct acpi_lpi_state *lpi;
+
+	pr = __this_cpu_read(processors);
+
+	if (unlikely(!pr))
+		return -EINVAL;
+
+	lpi = &pr->power.lpi_states[index];
+	if (lpi->entry_method == ACPI_CSTATE_FFH)
+		return acpi_processor_ffh_lpi_enter(lpi);
+
+	return -EINVAL;
+}
+
+static int acpi_processor_setup_lpi_states(struct acpi_processor *pr)
+{
+	int i;
+	struct acpi_lpi_state *lpi;
+	struct cpuidle_state *state;
+	struct cpuidle_driver *drv = &acpi_idle_driver;
+
+	if (!pr->flags.has_lpi)
+		return -EOPNOTSUPP;
+
+	for (i = 0; i < pr->power.count && i < CPUIDLE_STATE_MAX; i++) {
+		lpi = &pr->power.lpi_states[i];
+
+		state = &drv->states[i];
+		snprintf(state->name, CPUIDLE_NAME_LEN, "LPI-%d", i);
+		strlcpy(state->desc, lpi->desc, CPUIDLE_DESC_LEN);
+		state->exit_latency = lpi->wake_latency;
+		state->target_residency = lpi->min_residency;
+		if (lpi->arch_flags)
+			state->flags |= CPUIDLE_FLAG_TIMER_STOP;
+		state->enter = acpi_idle_lpi_enter;
+		drv->safe_state_index = i;
+	}
+
+	drv->state_count = i;
+
+	return 0;
+}
+
+/**
+ * acpi_processor_setup_cpuidle_states- prepares and configures cpuidle
+ * global state data i.e. idle routines
+ *
+ * @pr: the ACPI processor
+ */
+static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
+{
+	int i;
+	struct cpuidle_driver *drv = &acpi_idle_driver;
+
+	if (!pr->flags.power_setup_done || !pr->flags.power)
+		return -EINVAL;
+
+	drv->safe_state_index = -1;
+	for (i = CPUIDLE_DRIVER_STATE_START; i < CPUIDLE_STATE_MAX; i++) {
+		drv->states[i].name[0] = '\0';
+		drv->states[i].desc[0] = '\0';
+	}
+
+	if (pr->flags.has_lpi)
+		return acpi_processor_setup_lpi_states(pr);
+
+	return acpi_processor_setup_cstates(pr);
+}
+
+/**
+ * acpi_processor_setup_cpuidle_dev - prepares and configures CPUIDLE
+ * device i.e. per-cpu data
+ *
+ * @pr: the ACPI processor
+ * @dev : the cpuidle device
+ */
+static int acpi_processor_setup_cpuidle_dev(struct acpi_processor *pr,
+					    struct cpuidle_device *dev)
+{
+	if (!pr->flags.power_setup_done || !pr->flags.power || !dev)
+		return -EINVAL;
+
+	dev->cpu = pr->id;
+	if (pr->flags.has_lpi)
+		return acpi_processor_ffh_lpi_probe(pr->id);
+
+	return acpi_processor_setup_cpuidle_cx(pr, dev);
+}
+
+static int acpi_processor_get_power_info(struct acpi_processor *pr)
+{
+	int ret;
+
+	ret = acpi_processor_get_lpi_info(pr);
+	if (ret)
+		ret = acpi_processor_get_cstate_info(pr);
+
+	return ret;
+}
+
 int acpi_processor_hotplug(struct acpi_processor *pr)
 {
 	int ret = 0;
@@ -978,18 +1340,15 @@ int acpi_processor_hotplug(struct acpi_processor *pr)
 	if (disabled_by_idle_boot_param())
 		return 0;
 
-	if (nocst)
-		return -ENODEV;
-
 	if (!pr->flags.power_setup_done)
 		return -ENODEV;
 
 	dev = per_cpu(acpi_cpuidle_device, pr->id);
 	cpuidle_pause_and_lock();
 	cpuidle_disable_device(dev);
-	acpi_processor_get_power_info(pr);
-	if (pr->flags.power) {
-		acpi_processor_setup_cpuidle_cx(pr, dev);
+	ret = acpi_processor_get_power_info(pr);
+	if (!ret && pr->flags.power) {
+		acpi_processor_setup_cpuidle_dev(pr, dev);
 		ret = cpuidle_enable_device(dev);
 	}
 	cpuidle_resume_and_unlock();
@@ -997,7 +1356,7 @@ int acpi_processor_hotplug(struct acpi_processor *pr)
 	return ret;
 }
 
-int acpi_processor_cst_has_changed(struct acpi_processor *pr)
+int acpi_processor_power_state_has_changed(struct acpi_processor *pr)
 {
 	int cpu;
 	struct acpi_processor *_pr;
@@ -1006,9 +1365,6 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 	if (disabled_by_idle_boot_param())
 		return 0;
 
-	if (nocst)
-		return -ENODEV;
-
 	if (!pr->flags.power_setup_done)
 		return -ENODEV;
 
@@ -1045,7 +1401,7 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 			acpi_processor_get_power_info(_pr);
 			if (_pr->flags.power) {
 				dev = per_cpu(acpi_cpuidle_device, cpu);
-				acpi_processor_setup_cpuidle_cx(_pr, dev);
+				acpi_processor_setup_cpuidle_dev(_pr, dev);
 				cpuidle_enable_device(dev);
 			}
 		}
@@ -1092,7 +1448,7 @@ int acpi_processor_power_init(struct acpi_processor *pr)
 			return -ENOMEM;
 		per_cpu(acpi_cpuidle_device, pr->id) = dev;
 
-		acpi_processor_setup_cpuidle_cx(pr, dev);
+		acpi_processor_setup_cpuidle_dev(pr, dev);
 
 		/* Register per-cpu cpuidle_device. Cpuidle driver
 		 * must already be registered before registering device

commit 35ae713355868aa493edbfbabf615473473215cc
Author: Sudeep Holla <Sudeep.Holla@arm.com>
Date:   Tue Jul 19 18:52:53 2016 +0100

    ACPI / processor_idle: introduce ACPI_PROCESSOR_CSTATE
    
    ACPI 6.0 adds a new method to specify the CPU idle states(C-states)
    called Low Power Idle(LPI) states. Since new architectures like ARM64
    use only LPIs, introduce ACPI_PROCESSOR_CSTATE to encapsulate all the
    code supporting the old style C-states(_CST).
    
    This patch will help to extend the processor_idle module to support
    LPI.
    
    Signed-off-by: Sudeep Holla <sudeep.holla@arm.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 444e3745c8b3..ca0de35d1c3a 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -59,6 +59,12 @@ module_param(latency_factor, uint, 0644);
 
 static DEFINE_PER_CPU(struct cpuidle_device *, acpi_cpuidle_device);
 
+struct cpuidle_driver acpi_idle_driver = {
+	.name =		"acpi_idle",
+	.owner =	THIS_MODULE,
+};
+
+#ifdef CONFIG_ACPI_PROCESSOR_CSTATE
 static
 DEFINE_PER_CPU(struct acpi_processor_cx * [CPUIDLE_STATE_MAX], acpi_cstate);
 
@@ -804,11 +810,6 @@ static void acpi_idle_enter_freeze(struct cpuidle_device *dev,
 	acpi_idle_do_entry(cx);
 }
 
-struct cpuidle_driver acpi_idle_driver = {
-	.name =		"acpi_idle",
-	.owner =	THIS_MODULE,
-};
-
 /**
  * acpi_processor_setup_cpuidle_cx - prepares and configures CPUIDLE
  * device i.e. per-cpu data
@@ -925,6 +926,50 @@ static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
 	return 0;
 }
 
+static inline void acpi_processor_cstate_first_run_checks(void)
+{
+	acpi_status status;
+	static int first_run;
+
+	if (first_run)
+		return;
+	dmi_check_system(processor_power_dmi_table);
+	max_cstate = acpi_processor_cstate_check(max_cstate);
+	if (max_cstate < ACPI_C_STATES_MAX)
+		pr_notice("ACPI: processor limited to max C-state %d\n",
+			  max_cstate);
+	first_run++;
+
+	if (acpi_gbl_FADT.cst_control && !nocst) {
+		status = acpi_os_write_port(acpi_gbl_FADT.smi_command,
+					    acpi_gbl_FADT.cst_control, 8);
+		if (ACPI_FAILURE(status))
+			ACPI_EXCEPTION((AE_INFO, status,
+					"Notifying BIOS of _CST ability failed"));
+	}
+}
+#else
+
+static inline int disabled_by_idle_boot_param(void) { return 0; }
+static inline void acpi_processor_cstate_first_run_checks(void) { }
+static int acpi_processor_get_power_info(struct acpi_processor *pr)
+{
+	return -ENODEV;
+}
+
+static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,
+					   struct cpuidle_device *dev)
+{
+	return -EINVAL;
+}
+
+static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
+{
+	return -EINVAL;
+}
+
+#endif /* CONFIG_ACPI_PROCESSOR_CSTATE */
+
 int acpi_processor_hotplug(struct acpi_processor *pr)
 {
 	int ret = 0;
@@ -1015,35 +1060,16 @@ static int acpi_processor_registered;
 
 int acpi_processor_power_init(struct acpi_processor *pr)
 {
-	acpi_status status;
 	int retval;
 	struct cpuidle_device *dev;
-	static int first_run;
 
 	if (disabled_by_idle_boot_param())
 		return 0;
 
-	if (!first_run) {
-		dmi_check_system(processor_power_dmi_table);
-		max_cstate = acpi_processor_cstate_check(max_cstate);
-		if (max_cstate < ACPI_C_STATES_MAX)
-			printk(KERN_NOTICE
-			       "ACPI: processor limited to max C-state %d\n",
-			       max_cstate);
-		first_run++;
-	}
+	acpi_processor_cstate_first_run_checks();
 
-	if (acpi_gbl_FADT.cst_control && !nocst) {
-		status =
-		    acpi_os_write_port(acpi_gbl_FADT.smi_command, acpi_gbl_FADT.cst_control, 8);
-		if (ACPI_FAILURE(status)) {
-			ACPI_EXCEPTION((AE_INFO, status,
-					"Notifying BIOS of _CST ability failed"));
-		}
-	}
-
-	acpi_processor_get_power_info(pr);
-	pr->flags.power_setup_done = 1;
+	if (!acpi_processor_get_power_info(pr))
+		pr->flags.power_setup_done = 1;
 
 	/*
 	 * Install the idle handler if processor power management is supported.

commit 277edbabf6fece057b14fb6db5e3a34e00f42f42
Merge: 271ecc5253e2 0d571b62dd8e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 16 14:10:53 2016 -0700

    Merge tag 'pm+acpi-4.6-rc1-1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull power management and ACPI updates from Rafael Wysocki:
     "This time the majority of changes go into cpufreq and they are
      significant.
    
      First off, the way CPU frequency updates are triggered is different
      now.  Instead of having to set up and manage a deferrable timer for
      each CPU in the system to evaluate and possibly change its frequency
      periodically, cpufreq governors set up callbacks to be invoked by the
      scheduler on a regular basis (basically on utilization updates).  The
      "old" governors, "ondemand" and "conservative", still do all of their
      work in process context (although that is triggered by the scheduler
      now), but intel_pstate does it all in the callback invoked by the
      scheduler with no need for any additional asynchronous processing.
    
      Of course, this eliminates the overhead related to the management of
      all those timers, but also it allows the cpufreq governor code to be
      simplified quite a bit.  On top of that, the common code and data
      structures used by the "ondemand" and "conservative" governors are
      cleaned up and made more straightforward and some long-standing and
      quite annoying problems are addressed.  In particular, the handling of
      governor sysfs attributes is modified and the related locking becomes
      more fine grained which allows some concurrency problems to be avoided
      (particularly deadlocks with the core cpufreq code).
    
      In principle, the new mechanism for triggering frequency updates
      allows utilization information to be passed from the scheduler to
      cpufreq.  Although the current code doesn't make use of it, in the
      works is a new cpufreq governor that will make decisions based on the
      scheduler's utilization data.  That should allow the scheduler and
      cpufreq to work more closely together in the long run.
    
      In addition to the core and governor changes, cpufreq drivers are
      updated too.  Fixes and optimizations go into intel_pstate, the
      cpufreq-dt driver is updated on top of some modification in the
      Operating Performance Points (OPP) framework and there are fixes and
      other updates in the powernv cpufreq driver.
    
      Apart from the cpufreq updates there is some new ACPICA material,
      including a fix for a problem introduced by previous ACPICA updates,
      and some less significant changes in the ACPI code, like CPPC code
      optimizations, ACPI processor driver cleanups and support for loading
      ACPI tables from initrd.
    
      Also updated are the generic power domains framework, the Intel RAPL
      power capping driver and the turbostat utility and we have a bunch of
      traditional assorted fixes and cleanups.
    
      Specifics:
    
       - Redesign of cpufreq governors and the intel_pstate driver to make
         them use callbacks invoked by the scheduler to trigger CPU
         frequency evaluation instead of using per-CPU deferrable timers for
         that purpose (Rafael Wysocki).
    
       - Reorganization and cleanup of cpufreq governor code to make it more
         straightforward and fix some concurrency problems in it (Rafael
         Wysocki, Viresh Kumar).
    
       - Cleanup and improvements of locking in the cpufreq core (Viresh
         Kumar).
    
       - Assorted cleanups in the cpufreq core (Rafael Wysocki, Viresh
         Kumar, Eric Biggers).
    
       - intel_pstate driver updates including fixes, optimizations and a
         modification to make it enable enable hardware-coordinated P-state
         selection (HWP) by default if supported by the processor (Philippe
         Longepe, Srinivas Pandruvada, Rafael Wysocki, Viresh Kumar, Felipe
         Franciosi).
    
       - Operating Performance Points (OPP) framework updates to improve its
         handling of voltage regulators and device clocks and updates of the
         cpufreq-dt driver on top of that (Viresh Kumar, Jon Hunter).
    
       - Updates of the powernv cpufreq driver to fix initialization and
         cleanup problems in it and correct its worker thread handling with
         respect to CPU offline, new powernv_throttle tracepoint (Shilpasri
         Bhat).
    
       - ACPI cpufreq driver optimization and cleanup (Rafael Wysocki).
    
       - ACPICA updates including one fix for a regression introduced by
         previos changes in the ACPICA code (Bob Moore, Lv Zheng, David Box,
         Colin Ian King).
    
       - Support for installing ACPI tables from initrd (Lv Zheng).
    
       - Optimizations of the ACPI CPPC code (Prashanth Prakash, Ashwin
         Chaugule).
    
       - Support for _HID(ACPI0010) devices (ACPI processor containers) and
         ACPI processor driver cleanups (Sudeep Holla).
    
       - Support for ACPI-based enumeration of the AMBA bus (Graeme Gregory,
         Aleksey Makarov).
    
       - Modification of the ACPI PCI IRQ management code to make it treat
         255 in the Interrupt Line register as "not connected" on x86 (as
         per the specification) and avoid attempts to use that value as a
         valid interrupt vector (Chen Fan).
    
       - ACPI APEI fixes related to resource leaks (Josh Hunt).
    
       - Removal of modularity from a few ACPI drivers (BGRT, GHES,
         intel_pmic_crc) that cannot be built as modules in practice (Paul
         Gortmaker).
    
       - PNP framework update to make it treat ACPI_RESOURCE_TYPE_SERIAL_BUS
         as a valid resource type (Harb Abdulhamid).
    
       - New device ID (future AMD I2C controller) in the ACPI driver for
         AMD SoCs (APD) and in the designware I2C driver (Xiangliang Yu).
    
       - Assorted ACPI cleanups (Colin Ian King, Kaiyen Chang, Oleg Drokin).
    
       - cpuidle menu governor optimization to avoid a square root
         computation in it (Rasmus Villemoes).
    
       - Fix for potential use-after-free in the generic device properties
         framework (Heikki Krogerus).
    
       - Updates of the generic power domains (genpd) framework including
         support for multiple power states of a domain, fixes and debugfs
         output improvements (Axel Haslam, Jon Hunter, Laurent Pinchart,
         Geert Uytterhoeven).
    
       - Intel RAPL power capping driver updates to reduce IPI overhead in
         it (Jacob Pan).
    
       - System suspend/hibernation code cleanups (Eric Biggers, Saurabh
         Sengar).
    
       - Year 2038 fix for the process freezer (Abhilash Jindal).
    
       - turbostat utility updates including new features (decoding of more
         registers and CPUID fields, sub-second intervals support, GFX MHz
         and RC6 printout, --out command line option), fixes (syscall jitter
         detection and workaround, reductioin of the number of syscalls
         made, fixes related to Xeon x200 processors, compiler warning
         fixes) and cleanups (Len Brown, Hubert Chrzaniuk, Chen Yu)"
    
    * tag 'pm+acpi-4.6-rc1-1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (182 commits)
      tools/power turbostat: bugfix: TDP MSRs print bits fixing
      tools/power turbostat: correct output for MSR_NHM_SNB_PKG_CST_CFG_CTL dump
      tools/power turbostat: call __cpuid() instead of __get_cpuid()
      tools/power turbostat: indicate SMX and SGX support
      tools/power turbostat: detect and work around syscall jitter
      tools/power turbostat: show GFX%rc6
      tools/power turbostat: show GFXMHz
      tools/power turbostat: show IRQs per CPU
      tools/power turbostat: make fewer systems calls
      tools/power turbostat: fix compiler warnings
      tools/power turbostat: add --out option for saving output in a file
      tools/power turbostat: re-name "%Busy" field to "Busy%"
      tools/power turbostat: Intel Xeon x200: fix turbo-ratio decoding
      tools/power turbostat: Intel Xeon x200: fix erroneous bclk value
      tools/power turbostat: allow sub-sec intervals
      ACPI / APEI: ERST: Fixed leaked resources in erst_init
      ACPI / APEI: Fix leaked resources
      intel_pstate: Do not skip samples partially
      intel_pstate: Remove freq calculation from intel_pstate_calc_busy()
      intel_pstate: Move intel_pstate_calc_busy() into get_target_pstate_use_performance()
      ...

commit 25528213fe9f75f4e286f08d35a73ca2bb634a50
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Mar 15 14:52:49 2016 -0700

    tags: Fix DEFINE_PER_CPU expansions
    
    $ make tags
      GEN     tags
    ctags: Warning: drivers/acpi/processor_idle.c:64: null expansion of name pattern "\1"
    ctags: Warning: drivers/xen/events/events_2l.c:41: null expansion of name pattern "\1"
    ctags: Warning: kernel/locking/lockdep.c:151: null expansion of name pattern "\1"
    ctags: Warning: kernel/rcu/rcutorture.c:133: null expansion of name pattern "\1"
    ctags: Warning: kernel/rcu/rcutorture.c:135: null expansion of name pattern "\1"
    ctags: Warning: kernel/workqueue.c:323: null expansion of name pattern "\1"
    ctags: Warning: net/ipv4/syncookies.c:53: null expansion of name pattern "\1"
    ctags: Warning: net/ipv6/syncookies.c:44: null expansion of name pattern "\1"
    ctags: Warning: net/rds/page.c:45: null expansion of name pattern "\1"
    
    Which are all the result of the DEFINE_PER_CPU pattern:
    
      scripts/tags.sh:200:  '/\<DEFINE_PER_CPU([^,]*, *\([[:alnum:]_]*\)/\1/v/'
      scripts/tags.sh:201:  '/\<DEFINE_PER_CPU_SHARED_ALIGNED([^,]*, *\([[:alnum:]_]*\)/\1/v/'
    
    The below cures them. All except the workqueue one are within reasonable
    distance of the 80 char limit. TJ do you have any preference on how to
    fix the wq one, or shall we just not care its too long?
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: David S. Miller <davem@davemloft.net>
    Acked-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 175c86bee3a9..9ca2b2fefd76 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -61,8 +61,8 @@ module_param(latency_factor, uint, 0644);
 
 static DEFINE_PER_CPU(struct cpuidle_device *, acpi_cpuidle_device);
 
-static DEFINE_PER_CPU(struct acpi_processor_cx * [CPUIDLE_STATE_MAX],
-								acpi_cstate);
+static
+DEFINE_PER_CPU(struct acpi_processor_cx * [CPUIDLE_STATE_MAX], acpi_cstate);
 
 static int disabled_by_idle_boot_param(void)
 {

commit 504997cf96fabf67b4768b7a8ca1a1b622abd839
Author: Sudeep Holla <Sudeep.Holla@arm.com>
Date:   Wed Feb 17 12:03:23 2016 +0000

    ACPI / sleep: move acpi_processor_sleep to sleep.c
    
    acpi_processor_sleep is neither related nor used by CPUIdle framework.
    It's used in system suspend/resume path as a syscore operation. It makes
    more sense to move it to acpi/sleep.c where all the S-state transition
    (a.k.a. Linux system suspend/hiberate) related code are present.
    
    Also make it depend on CONFIG_ACPI_SYSTEM_POWER_STATES_SUPPORT so that
    it's not compiled on architecture like ARM64 where S-states are not
    yet defined in ACPI.
    
    Signed-off-by: Sudeep Holla <sudeep.holla@arm.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index e057aa8fafb0..fadce354d2b7 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -31,7 +31,6 @@
 #include <linux/sched.h>       /* need_resched() */
 #include <linux/tick.h>
 #include <linux/cpuidle.h>
-#include <linux/syscore_ops.h>
 #include <acpi/processor.h>
 
 /*
@@ -193,42 +192,6 @@ static void lapic_timer_state_broadcast(struct acpi_processor *pr,
 
 #endif
 
-#ifdef CONFIG_PM_SLEEP
-static u32 saved_bm_rld;
-
-static int acpi_processor_suspend(void)
-{
-	acpi_read_bit_register(ACPI_BITREG_BUS_MASTER_RLD, &saved_bm_rld);
-	return 0;
-}
-
-static void acpi_processor_resume(void)
-{
-	u32 resumed_bm_rld = 0;
-
-	acpi_read_bit_register(ACPI_BITREG_BUS_MASTER_RLD, &resumed_bm_rld);
-	if (resumed_bm_rld == saved_bm_rld)
-		return;
-
-	acpi_write_bit_register(ACPI_BITREG_BUS_MASTER_RLD, saved_bm_rld);
-}
-
-static struct syscore_ops acpi_processor_syscore_ops = {
-	.suspend = acpi_processor_suspend,
-	.resume = acpi_processor_resume,
-};
-
-void acpi_processor_syscore_init(void)
-{
-	register_syscore_ops(&acpi_processor_syscore_ops);
-}
-
-void acpi_processor_syscore_exit(void)
-{
-	unregister_syscore_ops(&acpi_processor_syscore_ops);
-}
-#endif /* CONFIG_PM_SLEEP */
-
 #if defined(CONFIG_X86)
 static void tsc_check_state(int state)
 {

commit b6ec26fb963133d16acb473bf4fcda09630b2298
Author: Sudeep Holla <Sudeep.Holla@arm.com>
Date:   Wed Dec 2 14:10:44 2015 +0000

    ACPI / processor_idle: replace PREFIX with pr_fmt
    
    Like few of the other ACPI modules, replace PREFIX with pr_fmt and
    change all the printk call sites to use pr_* companion functions
    in processor_idle.
    
    Signed-off-by: Sudeep Holla <sudeep.holla@arm.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 175c86bee3a9..e057aa8fafb0 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -23,6 +23,7 @@
  *
  * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  */
+#define pr_fmt(fmt) "ACPI: " fmt
 
 #include <linux/module.h>
 #include <linux/acpi.h>
@@ -43,8 +44,6 @@
 #include <asm/apic.h>
 #endif
 
-#define PREFIX "ACPI: "
-
 #define ACPI_PROCESSOR_CLASS            "processor"
 #define _COMPONENT              ACPI_PROCESSOR_COMPONENT
 ACPI_MODULE_NAME("processor_idle");
@@ -81,9 +80,9 @@ static int set_max_cstate(const struct dmi_system_id *id)
 	if (max_cstate > ACPI_PROCESSOR_MAX_POWER)
 		return 0;
 
-	printk(KERN_NOTICE PREFIX "%s detected - limiting to C%ld max_cstate."
-	       " Override with \"processor.max_cstate=%d\"\n", id->ident,
-	       (long)id->driver_data, ACPI_PROCESSOR_MAX_POWER + 1);
+	pr_notice("%s detected - limiting to C%ld max_cstate."
+		  " Override with \"processor.max_cstate=%d\"\n", id->ident,
+		  (long)id->driver_data, ACPI_PROCESSOR_MAX_POWER + 1);
 
 	max_cstate = (long)id->driver_data;
 
@@ -351,7 +350,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 
 	/* There must be at least 2 elements */
 	if (!cst || (cst->type != ACPI_TYPE_PACKAGE) || cst->package.count < 2) {
-		printk(KERN_ERR PREFIX "not enough elements in _CST\n");
+		pr_err("not enough elements in _CST\n");
 		ret = -EFAULT;
 		goto end;
 	}
@@ -360,7 +359,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 
 	/* Validate number of power states. */
 	if (count < 1 || count != cst->package.count - 1) {
-		printk(KERN_ERR PREFIX "count given by _CST is not valid\n");
+		pr_err("count given by _CST is not valid\n");
 		ret = -EFAULT;
 		goto end;
 	}
@@ -469,11 +468,9 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 		 * (From 1 through ACPI_PROCESSOR_MAX_POWER - 1)
 		 */
 		if (current_count >= (ACPI_PROCESSOR_MAX_POWER - 1)) {
-			printk(KERN_WARNING
-			       "Limiting number of power states to max (%d)\n",
-			       ACPI_PROCESSOR_MAX_POWER);
-			printk(KERN_WARNING
-			       "Please increase ACPI_PROCESSOR_MAX_POWER if needed.\n");
+			pr_warn("Limiting number of power states to max (%d)\n",
+				ACPI_PROCESSOR_MAX_POWER);
+			pr_warn("Please increase ACPI_PROCESSOR_MAX_POWER if needed.\n");
 			break;
 		}
 	}
@@ -1097,8 +1094,8 @@ int acpi_processor_power_init(struct acpi_processor *pr)
 			retval = cpuidle_register_driver(&acpi_idle_driver);
 			if (retval)
 				return retval;
-			printk(KERN_DEBUG "ACPI: %s registered with cpuidle\n",
-					acpi_idle_driver.name);
+			pr_debug("%s registered with cpuidle\n",
+				 acpi_idle_driver.name);
 		}
 
 		dev = kzalloc(sizeof(*dev), GFP_KERNEL);

commit 4c62dbbce902cf2afa88cac89ec67c828160f431
Author: Jarkko Nikula <jarkko.nikula@linux.intel.com>
Date:   Fri Jun 26 11:27:41 2015 +0300

    ACPI: Remove FSF mailing addresses
    
    There is no need to carry potentially outdated Free Software Foundation
    mailing address in file headers since the COPYING file includes it.
    
    Signed-off-by: Jarkko Nikula <jarkko.nikula@linux.intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index d540f42c9232..175c86bee3a9 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -21,10 +21,6 @@
  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
  *  General Public License for more details.
  *
- *  You should have received a copy of the GNU General Public License along
- *  with this program; if not, write to the Free Software Foundation, Inc.,
- *  59 Temple Place, Suite 330, Boston, MA 02111-1307 USA.
- *
  * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  */
 

commit b03466883edb192b3e3877ea3f71036a3899ae51
Author: Mathias Krause <minipli@googlemail.com>
Date:   Sat Jun 13 14:26:57 2015 +0200

    ACPI / processor: constify DMI system id table
    
    There is no need to have processor_power_dmi_table[] writeable, constify
    it.
    
    Signed-off-by: Mathias Krause <minipli@googlemail.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 39e0c8e36244..d540f42c9232 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -94,7 +94,7 @@ static int set_max_cstate(const struct dmi_system_id *id)
 	return 0;
 }
 
-static struct dmi_system_id processor_power_dmi_table[] = {
+static const struct dmi_system_id processor_power_dmi_table[] = {
 	{ set_max_cstate, "Clevo 5600D", {
 	  DMI_MATCH(DMI_BIOS_VENDOR,"Phoenix Technologies LTD"),
 	  DMI_MATCH(DMI_BIOS_VERSION,"SHE845M0.86C.0013.D.0302131307")},

commit 7fd56474db326f7a6df0e2a4e3a9600cc083ab9b
Merge: 49d2953c72c6 def747087e83
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Apr 13 11:08:28 2015 -0700

    Merge branch 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timer updates from Ingo Molnar:
     "The main changes in this cycle were:
    
       - clockevents state machine cleanups and enhancements (Viresh Kumar)
    
       - clockevents broadcast notifier horror to state machine conversion
         and related cleanups (Thomas Gleixner, Rafael J Wysocki)
    
       - clocksource and timekeeping core updates (John Stultz)
    
       - clocksource driver updates and fixes (Ben Dooks, Dmitry Osipenko,
         Hans de Goede, Laurent Pinchart, Maxime Ripard, Xunlei Pang)
    
       - y2038 fixes (Xunlei Pang, John Stultz)
    
       - NMI-safe ktime_get_raw_fast() and general refactoring of the clock
         code, in preparation to perf's per event clock ID support (Peter
         Zijlstra)
    
       - generic sched/clock fixes, optimizations and cleanups (Daniel
         Thompson)
    
       - clockevents cpu_down() race fix (Preeti U Murthy)"
    
    * 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (94 commits)
      timers/PM: Drop unnecessary braces from tick_freeze()
      timers/PM: Fix up tick_unfreeze()
      timekeeping: Get rid of stale comment
      clockevents: Cleanup dead cpu explicitely
      clockevents: Make tick handover explicit
      clockevents: Remove broadcast oneshot control leftovers
      sched/idle: Use explicit broadcast oneshot control function
      ARM: Tegra: Use explicit broadcast oneshot control function
      ARM: OMAP: Use explicit broadcast oneshot control function
      intel_idle: Use explicit broadcast oneshot control function
      ACPI/idle: Use explicit broadcast control function
      ACPI/PAD: Use explicit broadcast oneshot control function
      x86/amd/idle, clockevents: Use explicit broadcast oneshot control functions
      clockevents: Provide explicit broadcast oneshot control functions
      clockevents: Remove the broadcast control leftovers
      ARM: OMAP: Use explicit broadcast control function
      intel_idle: Use explicit broadcast control function
      cpuidle: Use explicit broadcast control function
      ACPI/processor: Use explicit broadcast control function
      ACPI/PAD: Use explicit broadcast control function
      ...

commit c7e8bdf5872c5a8f5a6494e16fe839c38a0d3d3d
Author: Thomas Schlichter <thomas.schlichter@web.de>
Date:   Tue Mar 31 20:24:39 2015 +0200

    cpuidle: ACPI: do not overwrite name and description of C0
    
    Fix a bug that leads to showing the name and description of C-state C0
    as "<null>" in sysfs after the ACPI C-states changed (e.g. after AC->DC
    or DC->AC
    transition).
    
    The function poll_idle_init() in drivers/cpuidle/driver.c initializes the
    state 0 during cpuidle_register_driver(), so we better do not overwrite it
    again with '\0' during acpi_processor_cst_has_changed().
    
    Signed-off-by: Thomas Schlichter <thomas.schlichter@web.de>
    Reviewed-by: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
    Cc: 3.13+ <stable@vger.kernel.org> # 3.13+
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index c6bb9f1257c9..f98db0b50551 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -922,7 +922,7 @@ static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
 		return -EINVAL;
 
 	drv->safe_state_index = -1;
-	for (i = 0; i < CPUIDLE_STATE_MAX; i++) {
+	for (i = CPUIDLE_DRIVER_STATE_START; i < CPUIDLE_STATE_MAX; i++) {
 		drv->states[i].name[0] = '\0';
 		drv->states[i].desc[0] = '\0';
 	}

commit 7815701c5cd7276b712d898b3cf49c55e587dbb1
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Apr 3 02:12:03 2015 +0200

    ACPI/idle: Use explicit broadcast control function
    
    Replace the clockevents_notify() call with an explicit function call.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/2653377.MSAlfA939I@vostro.rjw.lan
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index be5479739287..53355196c5c6 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -178,11 +178,10 @@ static void lapic_timer_state_broadcast(struct acpi_processor *pr,
 	int state = cx - pr->power.states;
 
 	if (state >= pr->power.timer_broadcast_on_state) {
-		unsigned long reason;
-
-		reason = broadcast ?  CLOCK_EVT_NOTIFY_BROADCAST_ENTER :
-			CLOCK_EVT_NOTIFY_BROADCAST_EXIT;
-		clockevents_notify(reason, &pr->id);
+		if (broadcast)
+			tick_broadcast_enter();
+		else
+			tick_broadcast_exit();
 	}
 }
 

commit ee41eebf9cef624b2e766a4b8688eeeedb65114c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Apr 3 02:02:00 2015 +0200

    ACPI/processor: Use explicit broadcast control function
    
    Replace the clockevents_notify() call with an explicit function call.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/25071624.dkenaL3SGT@vostro.rjw.lan
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index c6bb9f1257c9..be5479739287 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -32,7 +32,7 @@
 #include <linux/acpi.h>
 #include <linux/dmi.h>
 #include <linux/sched.h>       /* need_resched() */
-#include <linux/clockchips.h>
+#include <linux/tick.h>
 #include <linux/cpuidle.h>
 #include <linux/syscore_ops.h>
 #include <acpi/processor.h>
@@ -157,12 +157,11 @@ static void lapic_timer_check_state(int state, struct acpi_processor *pr,
 static void __lapic_timer_propagate_broadcast(void *arg)
 {
 	struct acpi_processor *pr = (struct acpi_processor *) arg;
-	unsigned long reason;
 
-	reason = pr->power.timer_broadcast_on_state < INT_MAX ?
-		CLOCK_EVT_NOTIFY_BROADCAST_ON : CLOCK_EVT_NOTIFY_BROADCAST_OFF;
-
-	clockevents_notify(reason, &pr->id);
+	if (pr->power.timer_broadcast_on_state < INT_MAX)
+		tick_broadcast_enable();
+	else
+		tick_broadcast_disable();
 }
 
 static void lapic_timer_propagate_broadcast(struct acpi_processor *pr)

commit 5f5081852038d9a7b309190730bfb724b413235e
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Wed Feb 11 05:04:57 2015 +0100

    ACPI / idle: Implement ->enter_freeze callback routine
    
    Add an ->enter_freeze callback routine, acpi_idle_enter_freeze(), to
    the ACPI cpuidle driver and point ->enter_freeze to it for all the
    C2-type and C3-type states that don't need to fall back to C1
    (which may be halt-induced and that will re-enable interrupts on
    exit from idle, which ->enter_freeze cannot do).
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index c256bd7fbd78..c6bb9f1257c9 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -732,9 +732,8 @@ static int acpi_idle_play_dead(struct cpuidle_device *dev, int index)
 
 static bool acpi_idle_fallback_to_c1(struct acpi_processor *pr)
 {
-	return IS_ENABLED(CONFIG_HOTPLUG_CPU) && num_online_cpus() > 1 &&
-		!(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED) &&
-		!pr->flags.has_cst;
+	return IS_ENABLED(CONFIG_HOTPLUG_CPU) && !pr->flags.has_cst &&
+		!(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED);
 }
 
 static int c3_cpu_count;
@@ -744,9 +743,10 @@ static DEFINE_RAW_SPINLOCK(c3_lock);
  * acpi_idle_enter_bm - enters C3 with proper BM handling
  * @pr: Target processor
  * @cx: Target state context
+ * @timer_bc: Whether or not to change timer mode to broadcast
  */
 static void acpi_idle_enter_bm(struct acpi_processor *pr,
-			       struct acpi_processor_cx *cx)
+			       struct acpi_processor_cx *cx, bool timer_bc)
 {
 	acpi_unlazy_tlb(smp_processor_id());
 
@@ -754,7 +754,8 @@ static void acpi_idle_enter_bm(struct acpi_processor *pr,
 	 * Must be done before busmaster disable as we might need to
 	 * access HPET !
 	 */
-	lapic_timer_state_broadcast(pr, cx, 1);
+	if (timer_bc)
+		lapic_timer_state_broadcast(pr, cx, 1);
 
 	/*
 	 * disable bus master
@@ -784,7 +785,8 @@ static void acpi_idle_enter_bm(struct acpi_processor *pr,
 		raw_spin_unlock(&c3_lock);
 	}
 
-	lapic_timer_state_broadcast(pr, cx, 0);
+	if (timer_bc)
+		lapic_timer_state_broadcast(pr, cx, 0);
 }
 
 static int acpi_idle_enter(struct cpuidle_device *dev,
@@ -798,12 +800,12 @@ static int acpi_idle_enter(struct cpuidle_device *dev,
 		return -EINVAL;
 
 	if (cx->type != ACPI_STATE_C1) {
-		if (acpi_idle_fallback_to_c1(pr)) {
+		if (acpi_idle_fallback_to_c1(pr) && num_online_cpus() > 1) {
 			index = CPUIDLE_DRIVER_STATE_START;
 			cx = per_cpu(acpi_cstate[index], dev->cpu);
 		} else if (cx->type == ACPI_STATE_C3 && pr->flags.bm_check) {
 			if (cx->bm_sts_skip || !acpi_idle_bm_check()) {
-				acpi_idle_enter_bm(pr, cx);
+				acpi_idle_enter_bm(pr, cx, true);
 				return index;
 			} else if (drv->safe_state_index >= 0) {
 				index = drv->safe_state_index;
@@ -827,6 +829,27 @@ static int acpi_idle_enter(struct cpuidle_device *dev,
 	return index;
 }
 
+static void acpi_idle_enter_freeze(struct cpuidle_device *dev,
+				   struct cpuidle_driver *drv, int index)
+{
+	struct acpi_processor_cx *cx = per_cpu(acpi_cstate[index], dev->cpu);
+
+	if (cx->type == ACPI_STATE_C3) {
+		struct acpi_processor *pr = __this_cpu_read(processors);
+
+		if (unlikely(!pr))
+			return;
+
+		if (pr->flags.bm_check) {
+			acpi_idle_enter_bm(pr, cx, false);
+			return;
+		} else {
+			ACPI_FLUSH_CPU_CACHE();
+		}
+	}
+	acpi_idle_do_entry(cx);
+}
+
 struct cpuidle_driver acpi_idle_driver = {
 	.name =		"acpi_idle",
 	.owner =	THIS_MODULE,
@@ -925,6 +948,15 @@ static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
 			state->enter_dead = acpi_idle_play_dead;
 			drv->safe_state_index = count;
 		}
+		/*
+		 * Halt-induced C1 is not good for ->enter_freeze, because it
+		 * re-enables interrupts on exit.  Moreover, C1 is generally not
+		 * particularly interesting from the suspend-to-idle angle, so
+		 * avoid C1 and the situations in which we may need to fall back
+		 * to it altogether.
+		 */
+		if (cx->type != ACPI_STATE_C1 && !acpi_idle_fallback_to_c1(pr))
+			state->enter_freeze = acpi_idle_enter_freeze;
 
 		count++;
 		if (count == CPUIDLE_STATE_MAX)

commit 6491bc0c616969f7ae1fcb30a8823c333e2944c7
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Tue Feb 3 21:55:11 2015 +0100

    ACPI / cpuidle: Common callback routine for entering states
    
    Introduce a common ->enter callback routine for the ACPI cpuidle
    driver, acpi_idle_enter(), which helps to reduce code complexity,
    size and duplication and prevents theoretically possible failues that
    an incorrect routine may be run to enter the given idle state due to
    a firmware bug (eg. when _CST returns a different set of states for
    each processor).
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 58113a6fa1d3..c256bd7fbd78 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -737,74 +737,17 @@ static bool acpi_idle_fallback_to_c1(struct acpi_processor *pr)
 		!pr->flags.has_cst;
 }
 
-/**
- * acpi_idle_enter_simple - enters a CPU idle state without BM handling
- * @dev: the target CPU
- * @drv: cpuidle driver with cpuidle state information
- * @index: the index of suggested state
- */
-static int acpi_idle_enter_simple(struct cpuidle_device *dev,
-		struct cpuidle_driver *drv, int index)
-{
-	struct acpi_processor *pr;
-	struct acpi_processor_cx *cx = per_cpu(acpi_cstate[index], dev->cpu);
-
-	pr = __this_cpu_read(processors);
-
-	if (unlikely(!pr))
-		return -EINVAL;
-
-	if (cx->type != ACPI_STATE_C1 && acpi_idle_fallback_to_c1(pr)) {
-		index = CPUIDLE_DRIVER_STATE_START;
-		cx = per_cpu(acpi_cstate[index], dev->cpu);
-	}
-
-	lapic_timer_state_broadcast(pr, cx, 1);
-
-	if (cx->type == ACPI_STATE_C3)
-		ACPI_FLUSH_CPU_CACHE();
-
-	acpi_idle_do_entry(cx);
-
-	lapic_timer_state_broadcast(pr, cx, 0);
-	return index;
-}
-
 static int c3_cpu_count;
 static DEFINE_RAW_SPINLOCK(c3_lock);
 
 /**
  * acpi_idle_enter_bm - enters C3 with proper BM handling
- * @dev: the target CPU
- * @drv: cpuidle driver containing state data
- * @index: the index of suggested state
- *
- * If BM is detected, the deepest non-C3 idle state is entered instead.
+ * @pr: Target processor
+ * @cx: Target state context
  */
-static int acpi_idle_enter_bm(struct cpuidle_device *dev,
-		struct cpuidle_driver *drv, int index)
+static void acpi_idle_enter_bm(struct acpi_processor *pr,
+			       struct acpi_processor_cx *cx)
 {
-	struct acpi_processor *pr;
-	struct acpi_processor_cx *cx = per_cpu(acpi_cstate[index], dev->cpu);
-
-	pr = __this_cpu_read(processors);
-
-	if (unlikely(!pr))
-		return -EINVAL;
-
-	if (acpi_idle_fallback_to_c1(pr))
-		return acpi_idle_enter_simple(dev, drv, CPUIDLE_DRIVER_STATE_START);
-
-	if (!cx->bm_sts_skip && acpi_idle_bm_check()) {
-		if (drv->safe_state_index >= 0) {
-			return drv->states[drv->safe_state_index].enter(dev,
-						drv, drv->safe_state_index);
-		} else {
-			acpi_safe_halt();
-			return -EBUSY;
-		}
-	}
-
 	acpi_unlazy_tlb(smp_processor_id());
 
 	/*
@@ -842,6 +785,45 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	}
 
 	lapic_timer_state_broadcast(pr, cx, 0);
+}
+
+static int acpi_idle_enter(struct cpuidle_device *dev,
+			   struct cpuidle_driver *drv, int index)
+{
+	struct acpi_processor_cx *cx = per_cpu(acpi_cstate[index], dev->cpu);
+	struct acpi_processor *pr;
+
+	pr = __this_cpu_read(processors);
+	if (unlikely(!pr))
+		return -EINVAL;
+
+	if (cx->type != ACPI_STATE_C1) {
+		if (acpi_idle_fallback_to_c1(pr)) {
+			index = CPUIDLE_DRIVER_STATE_START;
+			cx = per_cpu(acpi_cstate[index], dev->cpu);
+		} else if (cx->type == ACPI_STATE_C3 && pr->flags.bm_check) {
+			if (cx->bm_sts_skip || !acpi_idle_bm_check()) {
+				acpi_idle_enter_bm(pr, cx);
+				return index;
+			} else if (drv->safe_state_index >= 0) {
+				index = drv->safe_state_index;
+				cx = per_cpu(acpi_cstate[index], dev->cpu);
+			} else {
+				acpi_safe_halt();
+				return -EBUSY;
+			}
+		}
+	}
+
+	lapic_timer_state_broadcast(pr, cx, 1);
+
+	if (cx->type == ACPI_STATE_C3)
+		ACPI_FLUSH_CPU_CACHE();
+
+	acpi_idle_do_entry(cx);
+
+	lapic_timer_state_broadcast(pr, cx, 0);
+
 	return index;
 }
 
@@ -936,22 +918,12 @@ static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
 		strncpy(state->desc, cx->desc, CPUIDLE_DESC_LEN);
 		state->exit_latency = cx->latency;
 		state->target_residency = cx->latency * latency_factor;
+		state->enter = acpi_idle_enter;
 
 		state->flags = 0;
-		switch (cx->type) {
-
-		case ACPI_STATE_C1:
-		case ACPI_STATE_C2:
-			state->enter = acpi_idle_enter_simple;
+		if (cx->type == ACPI_STATE_C1 || cx->type == ACPI_STATE_C2) {
 			state->enter_dead = acpi_idle_play_dead;
 			drv->safe_state_index = count;
-			break;
-
-		case ACPI_STATE_C3:
-			state->enter = pr->flags.bm_check ?
-					acpi_idle_enter_bm :
-					acpi_idle_enter_simple;
-			break;
 		}
 
 		count++;

commit d2cecb3d66e39765f3dec8adfb88c322e709b06d
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Tue Feb 3 21:54:48 2015 +0100

    ACPI / cpuidle: Merge acpi_idle_enter_c1() and acpi_idle_enter_simple()
    
    acpi_idle_enter_c1() and acpi_idle_enter_simple() are close enough to
    each other that they can be merged into one function which reduces
    duplication of code quite a bit.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index eaa32586f89c..58113a6fa1d3 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -703,34 +703,6 @@ static void acpi_idle_do_entry(struct acpi_processor_cx *cx)
 	}
 }
 
-/**
- * acpi_idle_enter_c1 - enters an ACPI C1 state-type
- * @dev: the target CPU
- * @drv: cpuidle driver containing cpuidle state info
- * @index: index of target state
- *
- * This is equivalent to the HALT instruction.
- */
-static int acpi_idle_enter_c1(struct cpuidle_device *dev,
-		struct cpuidle_driver *drv, int index)
-{
-	struct acpi_processor *pr;
-	struct acpi_processor_cx *cx = per_cpu(acpi_cstate[index], dev->cpu);
-
-	pr = __this_cpu_read(processors);
-
-	if (unlikely(!pr))
-		return -EINVAL;
-
-	lapic_timer_state_broadcast(pr, cx, 1);
-	acpi_idle_do_entry(cx);
-
-	lapic_timer_state_broadcast(pr, cx, 0);
-
-	return index;
-}
-
-
 /**
  * acpi_idle_play_dead - enters an ACPI state for long-term idle (i.e. off-lining)
  * @dev: the target CPU
@@ -766,7 +738,7 @@ static bool acpi_idle_fallback_to_c1(struct acpi_processor *pr)
 }
 
 /**
- * acpi_idle_enter_simple - enters an ACPI state without BM handling
+ * acpi_idle_enter_simple - enters a CPU idle state without BM handling
  * @dev: the target CPU
  * @drv: cpuidle driver with cpuidle state information
  * @index: the index of suggested state
@@ -782,8 +754,10 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	if (unlikely(!pr))
 		return -EINVAL;
 
-	if (acpi_idle_fallback_to_c1(pr))
-		return acpi_idle_enter_c1(dev, drv, CPUIDLE_DRIVER_STATE_START);
+	if (cx->type != ACPI_STATE_C1 && acpi_idle_fallback_to_c1(pr)) {
+		index = CPUIDLE_DRIVER_STATE_START;
+		cx = per_cpu(acpi_cstate[index], dev->cpu);
+	}
 
 	lapic_timer_state_broadcast(pr, cx, 1);
 
@@ -819,7 +793,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		return -EINVAL;
 
 	if (acpi_idle_fallback_to_c1(pr))
-		return acpi_idle_enter_c1(dev, drv, CPUIDLE_DRIVER_STATE_START);
+		return acpi_idle_enter_simple(dev, drv, CPUIDLE_DRIVER_STATE_START);
 
 	if (!cx->bm_sts_skip && acpi_idle_bm_check()) {
 		if (drv->safe_state_index >= 0) {
@@ -967,11 +941,6 @@ static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
 		switch (cx->type) {
 
 		case ACPI_STATE_C1:
-			state->enter = acpi_idle_enter_c1;
-			state->enter_dead = acpi_idle_play_dead;
-			drv->safe_state_index = count;
-			break;
-
 		case ACPI_STATE_C2:
 			state->enter = acpi_idle_enter_simple;
 			state->enter_dead = acpi_idle_play_dead;

commit 2a7383529109252a7f9d81639784e5fddb4f3df4
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Feb 2 23:56:03 2015 +0100

    ACPI / cpuidle: Drop flags.bm_check tests from acpi_idle_enter_bm()
    
    Since acpi_idle_enter_bm() is only used if flags.bm_check is set for
    the given acpi_processor object, it doesn't make sense to check that
    flag in there.
    
    For this reason, drop flags.bm_check tests (and some code depending
    on them) from acpi_idle_enter_bm().
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index c05d5ec9882a..eaa32586f89c 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -842,28 +842,25 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	/*
 	 * disable bus master
 	 * bm_check implies we need ARB_DIS
-	 * !bm_check implies we need cache flush
 	 * bm_control implies whether we can do ARB_DIS
 	 *
 	 * That leaves a case where bm_check is set and bm_control is
 	 * not set. In that case we cannot do much, we enter C3
 	 * without doing anything.
 	 */
-	if (pr->flags.bm_check && pr->flags.bm_control) {
+	if (pr->flags.bm_control) {
 		raw_spin_lock(&c3_lock);
 		c3_cpu_count++;
 		/* Disable bus master arbitration when all CPUs are in C3 */
 		if (c3_cpu_count == num_online_cpus())
 			acpi_write_bit_register(ACPI_BITREG_ARB_DISABLE, 1);
 		raw_spin_unlock(&c3_lock);
-	} else if (!pr->flags.bm_check) {
-		ACPI_FLUSH_CPU_CACHE();
 	}
 
 	acpi_idle_do_entry(cx);
 
 	/* Re-enable bus master arbitration */
-	if (pr->flags.bm_check && pr->flags.bm_control) {
+	if (pr->flags.bm_control) {
 		raw_spin_lock(&c3_lock);
 		acpi_write_bit_register(ACPI_BITREG_ARB_DISABLE, 0);
 		c3_cpu_count--;

commit 5f97d6628640842229824c9f4fd433621c5a7b72
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Feb 2 23:55:55 2015 +0100

    ACPI / cpuidle: Clean up white space in a switch statement
    
    White space in the switch statement in acpi_processor_setup_cpuidle_states()
    does not adhere to the kernel coding style and that makes the code
    difficult to read.  Clean that up.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 1798bbeff96b..c05d5ec9882a 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -968,20 +968,20 @@ static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
 
 		state->flags = 0;
 		switch (cx->type) {
-			case ACPI_STATE_C1:
 
+		case ACPI_STATE_C1:
 			state->enter = acpi_idle_enter_c1;
 			state->enter_dead = acpi_idle_play_dead;
 			drv->safe_state_index = count;
 			break;
 
-			case ACPI_STATE_C2:
+		case ACPI_STATE_C2:
 			state->enter = acpi_idle_enter_simple;
 			state->enter_dead = acpi_idle_play_dead;
 			drv->safe_state_index = count;
 			break;
 
-			case ACPI_STATE_C3:
+		case ACPI_STATE_C3:
 			state->enter = pr->flags.bm_check ?
 					acpi_idle_enter_bm :
 					acpi_idle_enter_simple;

commit de6cc4ec6ea05de1933dc3b832013960af49c852
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Feb 2 23:55:47 2015 +0100

    ACPI / cpuidle: Drop irrelevant comment from acpi_idle_enter_simple()
    
    The comment about bus master disable in acpi_idle_enter_simple() is
    irrelevant, because the function doesn't disable bus mastering, so
    drop it.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 94c85ff2d123..1798bbeff96b 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -785,10 +785,6 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	if (acpi_idle_fallback_to_c1(pr))
 		return acpi_idle_enter_c1(dev, drv, CPUIDLE_DRIVER_STATE_START);
 
-	/*
-	 * Must be done before busmaster disable as we might need to
-	 * access HPET !
-	 */
 	lapic_timer_state_broadcast(pr, cx, 1);
 
 	if (cx->type == ACPI_STATE_C3)

commit adcb2623f149abd4d4783ecada543a01e25d1c04
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Feb 2 23:55:42 2015 +0100

    ACPI / cpuidle: Clean up fallback to C1 checks
    
    acpi_idle_enter_simple() and acpi_idle_enter_bm() both check
    if C2/C3 type entry is supported on MP in the same way, so move
    those checks to a separate function and call it from both
    places (and it doesn't need to check if the state type is not
    C1, because the functions in question won't be called otherwise).
    
    While at it, use IS_ENABLED() for the CONFIG_HOTPLUG_CPU check.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index ceeff3d473f1..94c85ff2d123 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -758,6 +758,13 @@ static int acpi_idle_play_dead(struct cpuidle_device *dev, int index)
 	return 0;
 }
 
+static bool acpi_idle_fallback_to_c1(struct acpi_processor *pr)
+{
+	return IS_ENABLED(CONFIG_HOTPLUG_CPU) && num_online_cpus() > 1 &&
+		!(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED) &&
+		!pr->flags.has_cst;
+}
+
 /**
  * acpi_idle_enter_simple - enters an ACPI state without BM handling
  * @dev: the target CPU
@@ -775,12 +782,8 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	if (unlikely(!pr))
 		return -EINVAL;
 
-#ifdef CONFIG_HOTPLUG_CPU
-	if ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) &&
-	    !pr->flags.has_cst &&
-	    !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
+	if (acpi_idle_fallback_to_c1(pr))
 		return acpi_idle_enter_c1(dev, drv, CPUIDLE_DRIVER_STATE_START);
-#endif
 
 	/*
 	 * Must be done before busmaster disable as we might need to
@@ -819,12 +822,8 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	if (unlikely(!pr))
 		return -EINVAL;
 
-#ifdef CONFIG_HOTPLUG_CPU
-	if ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) &&
-	    !pr->flags.has_cst &&
-	    !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
+	if (acpi_idle_fallback_to_c1(pr))
 		return acpi_idle_enter_c1(dev, drv, CPUIDLE_DRIVER_STATE_START);
-#endif
 
 	if (!cx->bm_sts_skip && acpi_idle_bm_check()) {
 		if (drv->safe_state_index >= 0) {

commit 67f592c8f681061d69c621b97a868e679c8a77be
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Feb 2 23:55:17 2015 +0100

    ACPI / cpuidle: Drop unnecessary calls from ->enter callback routines
    
    acpi_idle_enter_simple() and acpi_idle_enter_bm() don't need to
    call sched_clock_idle_sleep/wakeup_event(), because that's taken
    care of by the core already.  Namely, sched_clock_idle_sleep_event()
    is called by tick_nohz_start_idle() called by __tick_nohz_idle_enter()
    which in turn is called by tick_nohz_idle_enter() and that is called
    by cpu_idle_loop().  Analogously for sched_clock_idle_wakeup_event().
    
    For this reason, drop those calls from the ACPI cpuidle driver's
    ->enter callback routines.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index f36517164553..ceeff3d473f1 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -791,12 +791,8 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	if (cx->type == ACPI_STATE_C3)
 		ACPI_FLUSH_CPU_CACHE();
 
-	/* Tell the scheduler that we are going deep-idle: */
-	sched_clock_idle_sleep_event();
 	acpi_idle_do_entry(cx);
 
-	sched_clock_idle_wakeup_event(0);
-
 	lapic_timer_state_broadcast(pr, cx, 0);
 	return index;
 }
@@ -842,8 +838,6 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 
 	acpi_unlazy_tlb(smp_processor_id());
 
-	/* Tell the scheduler that we are going deep-idle: */
-	sched_clock_idle_sleep_event();
 	/*
 	 * Must be done before busmaster disable as we might need to
 	 * access HPET !
@@ -881,8 +875,6 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		raw_spin_unlock(&c3_lock);
 	}
 
-	sched_clock_idle_wakeup_event(0);
-
 	lapic_timer_state_broadcast(pr, cx, 0);
 	return index;
 }

commit b00783fd90388d221dabd4df2affeea7da2363cd
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Feb 2 23:55:08 2015 +0100

    ACPI / cpuidle: Drop unnecessary calls from acpi_idle_do_entry()
    
    Since the cpuidle core calls stop_critical_timings() and
    start_critical_timings() around the execution of ->enter callbacks,
    acpi_idle_do_entry() doesn't need to do that (and really shouldn't).
    
    Also using "inline" on it is pointless and the kerneldoc entry does
    not reflect the actual situation any more.
    
    Fix all of the above.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 87b704e41877..f36517164553 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -681,15 +681,13 @@ static int acpi_idle_bm_check(void)
 }
 
 /**
- * acpi_idle_do_entry - a helper function that does C2 and C3 type entry
+ * acpi_idle_do_entry - enter idle state using the appropriate method
  * @cx: cstate data
  *
  * Caller disables interrupt before call and enables interrupt after return.
  */
-static inline void acpi_idle_do_entry(struct acpi_processor_cx *cx)
+static void acpi_idle_do_entry(struct acpi_processor_cx *cx)
 {
-	/* Don't trace irqs off for idle */
-	stop_critical_timings();
 	if (cx->entry_method == ACPI_CSTATE_FFH) {
 		/* Call into architectural FFH based C-state */
 		acpi_processor_ffh_cstate_enter(cx);
@@ -703,7 +701,6 @@ static inline void acpi_idle_do_entry(struct acpi_processor_cx *cx)
 		   gets asserted in time to freeze execution properly. */
 		inl(acpi_gbl_FADT.xpm_timer_block.address);
 	}
-	start_critical_timings();
 }
 
 /**

commit ff23ab2441e7ba5089e8631bad3a6569e7b6d5b8
Merge: e0288b0e9e2a cb57720bf796 62c4cf97e82c
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Dec 29 21:23:41 2014 +0100

    Merge branches 'pm-cpufreq' and 'pm-cpuidle'
    
    * pm-cpufreq:
      cpufreq: fix a NULL pointer dereference in __cpufreq_governor()
      cpufreq-dt: defer probing if OPP table is not ready
    
    * pm-cpuidle:
      cpuidle / ACPI: remove unused CPUIDLE_FLAG_TIME_INVALID
      cpuidle: ladder: Better idle duration measurement without using CPUIDLE_FLAG_TIME_INVALID
      cpuidle: menu: Better idle duration measurement without using CPUIDLE_FLAG_TIME_INVALID

commit 62c4cf97e82cf79446642e599d155884f600cf17
Author: Len Brown <len.brown@intel.com>
Date:   Tue Dec 16 01:52:08 2014 -0500

    cpuidle / ACPI: remove unused CPUIDLE_FLAG_TIME_INVALID
    
    CPUIDLE_FLAG_TIME_INVALID is no longer checked
    by menu or ladder cpuidle governors, so don't
    bother setting or defining it.
    
    It was originally invented to account for the fact that
    acpi_safe_halt() enables interrupts to invoke HLT.
    That would allow interrupt service routines to be included
    in the last_idle duration measurements made in cpuidle_enter_state(),
    potentially returning a duration much larger than reality.
    
    But menu and ladder can gracefully handle erroneously large duration
    intervals without checking for CPUIDLE_FLAG_TIME_INVALID.
    Further, if they don't check CPUIDLE_FLAG_TIME_INVALID, they
    can also benefit from the instances when the duration interval
    is not erroneously large.
    
    Signed-off-by: Len Brown <len.brown@intel.com>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 380b4b43f361..7afba40e350e 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -985,8 +985,6 @@ static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
 		state->flags = 0;
 		switch (cx->type) {
 			case ACPI_STATE_C1:
-			if (cx->entry_method != ACPI_CSTATE_FFH)
-				state->flags |= CPUIDLE_FLAG_TIME_INVALID;
 
 			state->enter = acpi_idle_enter_c1;
 			state->enter_dead = acpi_idle_play_dead;

commit 648fcab2b060f82dc0138529af380171a2566d94
Merge: 389cbf36e50a 0c570c183ace
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Dec 8 20:00:09 2014 +0100

    Merge branch 'pm-cpuidle'
    
    * pm-cpuidle:
      cpuidle: add MAINTAINERS entry for ARM Exynos cpuidle driver
      drivers: cpuidle: Remove cpuidle-arm64 duplicate error messages
      drivers: cpuidle: Add idle-state-name description to ARM idle states
      drivers: cpuidle: Add status property to ARM idle states
      cpuidle: Invert CPUIDLE_FLAG_TIME_VALID logic

commit 6fd8050a35475259c444afc6856d57f4bbd74231
Author: Sudeep Holla <Sudeep.Holla@arm.com>
Date:   Tue Nov 25 14:48:50 2014 +0000

    ACPI / cpuidle: avoid assigning signed errno to acpi_status
    
    It's incorrect to assign a signed value to an unsigned acpi_status
    variable. This patch fixes it by using a signed integer to return
    error values.
    
    Signed-off-by: Sudeep Holla <sudeep.holla@arm.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 17f9ec501972..38472fd5d104 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -334,10 +334,10 @@ static int acpi_processor_get_power_info_default(struct acpi_processor *pr)
 
 static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 {
-	acpi_status status = 0;
+	acpi_status status;
 	u64 count;
 	int current_count;
-	int i;
+	int i, ret = 0;
 	struct acpi_buffer buffer = { ACPI_ALLOCATE_BUFFER, NULL };
 	union acpi_object *cst;
 
@@ -358,7 +358,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 	/* There must be at least 2 elements */
 	if (!cst || (cst->type != ACPI_TYPE_PACKAGE) || cst->package.count < 2) {
 		printk(KERN_ERR PREFIX "not enough elements in _CST\n");
-		status = -EFAULT;
+		ret = -EFAULT;
 		goto end;
 	}
 
@@ -367,7 +367,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 	/* Validate number of power states. */
 	if (count < 1 || count != cst->package.count - 1) {
 		printk(KERN_ERR PREFIX "count given by _CST is not valid\n");
-		status = -EFAULT;
+		ret = -EFAULT;
 		goto end;
 	}
 
@@ -489,12 +489,12 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 
 	/* Validate number of power states discovered */
 	if (current_count < 2)
-		status = -EFAULT;
+		ret = -EFAULT;
 
       end:
 	kfree(buffer.pointer);
 
-	return status;
+	return ret;
 }
 
 static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
@@ -1111,7 +1111,7 @@ static int acpi_processor_registered;
 
 int acpi_processor_power_init(struct acpi_processor *pr)
 {
-	acpi_status status = 0;
+	acpi_status status;
 	int retval;
 	struct cpuidle_device *dev;
 	static int first_run;

commit b82b6cca488074da3852e8a54fde1d9f74bf1557
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Wed Nov 12 16:03:50 2014 +0100

    cpuidle: Invert CPUIDLE_FLAG_TIME_VALID logic
    
    The only place where the time is invalid is when the ACPI_CSTATE_FFH entry
    method is not set. Otherwise for all the drivers, the time can be correctly
    measured.
    
    Instead of duplicating the CPUIDLE_FLAG_TIME_VALID flag in all the drivers
    for all the states, just invert the logic by replacing it by the flag
    CPUIDLE_FLAG_TIME_INVALID, hence we can set this flag only for the acpi idle
    driver, remove the former flag from all the drivers and invert the logic with
    this flag in the different governor.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 17f9ec501972..380b4b43f361 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -985,8 +985,8 @@ static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
 		state->flags = 0;
 		switch (cx->type) {
 			case ACPI_STATE_C1:
-			if (cx->entry_method == ACPI_CSTATE_FFH)
-				state->flags |= CPUIDLE_FLAG_TIME_VALID;
+			if (cx->entry_method != ACPI_CSTATE_FFH)
+				state->flags |= CPUIDLE_FLAG_TIME_INVALID;
 
 			state->enter = acpi_idle_enter_c1;
 			state->enter_dead = acpi_idle_play_dead;
@@ -994,14 +994,12 @@ static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
 			break;
 
 			case ACPI_STATE_C2:
-			state->flags |= CPUIDLE_FLAG_TIME_VALID;
 			state->enter = acpi_idle_enter_simple;
 			state->enter_dead = acpi_idle_play_dead;
 			drv->safe_state_index = count;
 			break;
 
 			case ACPI_STATE_C3:
-			state->flags |= CPUIDLE_FLAG_TIME_VALID;
 			state->enter = pr->flags.bm_check ?
 					acpi_idle_enter_bm :
 					acpi_idle_enter_simple;

commit 6726655dfdd2dc60c035c690d9f10cb69d7ea075
Author: Jiri Kosina <jkosina@suse.cz>
Date:   Wed Sep 3 15:04:28 2014 +0200

    ACPI / cpuidle: fix deadlock between cpuidle_lock and cpu_hotplug.lock
    
    There is a following AB-BA dependency between cpu_hotplug.lock and
    cpuidle_lock:
    
    1) cpu_hotplug.lock -> cpuidle_lock
    enable_nonboot_cpus()
     _cpu_up()
      cpu_hotplug_begin()
       LOCK(cpu_hotplug.lock)
     cpu_notify()
      ...
      acpi_processor_hotplug()
       cpuidle_pause_and_lock()
        LOCK(cpuidle_lock)
    
    2) cpuidle_lock -> cpu_hotplug.lock
    acpi_os_execute_deferred() workqueue
     ...
     acpi_processor_cst_has_changed()
      cpuidle_pause_and_lock()
       LOCK(cpuidle_lock)
      get_online_cpus()
       LOCK(cpu_hotplug.lock)
    
    Fix this by reversing the order acpi_processor_cst_has_changed() does
    thigs -- let it first execute the protection against CPU hotplug by
    calling get_online_cpus() and obtain the cpuidle lock only after that (and
    perform the symmentric change when allowing CPUs hotplug again and
    dropping cpuidle lock).
    
    Spotted by lockdep.
    
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Cc: All applicable <stable@vger.kernel.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 3dca36d4ad26..17f9ec501972 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1071,9 +1071,9 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 
 	if (pr->id == 0 && cpuidle_get_driver() == &acpi_idle_driver) {
 
-		cpuidle_pause_and_lock();
 		/* Protect against cpu-hotplug */
 		get_online_cpus();
+		cpuidle_pause_and_lock();
 
 		/* Disable all cpuidle devices */
 		for_each_online_cpu(cpu) {
@@ -1100,8 +1100,8 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 				cpuidle_enable_device(dev);
 			}
 		}
-		put_online_cpus();
 		cpuidle_resume_and_unlock();
+		put_online_cpus();
 	}
 
 	return 0;

commit 09da8dfa98682d871987145ed11e3232accac860
Merge: 3aacd625f201 7744064731a9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 24 15:51:02 2014 -0800

    Merge tag 'pm+acpi-3.14-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull ACPI and power management updates from Rafael Wysocki:
     "As far as the number of commits goes, the top spot belongs to ACPI
      this time with cpufreq in the second position and a handful of PM
      core, PNP and cpuidle updates.  They are fixes and cleanups mostly, as
      usual, with a couple of new features in the mix.
    
      The most visible change is probably that we will create struct
      acpi_device objects (visible in sysfs) for all devices represented in
      the ACPI tables regardless of their status and there will be a new
      sysfs attribute under those objects allowing user space to check that
      status via _STA.
    
      Consequently, ACPI device eject or generally hot-removal will not
      delete those objects, unless the table containing the corresponding
      namespace nodes is unloaded, which is extremely rare.  Also ACPI
      container hotplug will be handled quite a bit differently and cpufreq
      will support CPU boost ("turbo") generically and not only in the
      acpi-cpufreq driver.
    
      Specifics:
    
       - ACPI core changes to make it create a struct acpi_device object for
         every device represented in the ACPI tables during all namespace
         scans regardless of the current status of that device.  In
         accordance with this, ACPI hotplug operations will not delete those
         objects, unless the underlying ACPI tables go away.
    
       - On top of the above, new sysfs attribute for ACPI device objects
         allowing user space to check device status by triggering the
         execution of _STA for its ACPI object.  From Srinivas Pandruvada.
    
       - ACPI core hotplug changes reducing code duplication, integrating
         the PCI root hotplug with the core and reworking container hotplug.
    
       - ACPI core simplifications making it use ACPI_COMPANION() in the
         code "glueing" ACPI device objects to "physical" devices.
    
       - ACPICA update to upstream version 20131218.  This adds support for
         the DBG2 and PCCT tables to ACPICA, fixes some bugs and improves
         debug facilities.  From Bob Moore, Lv Zheng and Betty Dall.
    
       - Init code change to carry out the early ACPI initialization
         earlier.  That should allow us to use ACPI during the timekeeping
         initialization and possibly to simplify the EFI initialization too.
         From Chun-Yi Lee.
    
       - Clenups of the inclusions of ACPI headers in many places all over
         from Lv Zheng and Rashika Kheria (work in progress).
    
       - New helper for ACPI _DSM execution and rework of the code in
         drivers that uses _DSM to execute it via the new helper.  From
         Jiang Liu.
    
       - New Win8 OSI blacklist entries from Takashi Iwai.
    
       - Assorted ACPI fixes and cleanups from Al Stone, Emil Goode, Hanjun
         Guo, Lan Tianyu, Masanari Iida, Oliver Neukum, Prarit Bhargava,
         Rashika Kheria, Tang Chen, Zhang Rui.
    
       - intel_pstate driver updates, including proper Baytrail support,
         from Dirk Brandewie and intel_pstate documentation from Ramkumar
         Ramachandra.
    
       - Generic CPU boost ("turbo") support for cpufreq from Lukasz
         Majewski.
    
       - powernow-k6 cpufreq driver fixes from Mikulas Patocka.
    
       - cpufreq core fixes and cleanups from Viresh Kumar, Jane Li, Mark
         Brown.
    
       - Assorted cpufreq drivers fixes and cleanups from Anson Huang, John
         Tobias, Paul Bolle, Paul Walmsley, Sachin Kamat, Shawn Guo, Viresh
         Kumar.
    
       - cpuidle cleanups from Bartlomiej Zolnierkiewicz.
    
       - Support for hibernation APM events from Bin Shi.
    
       - Hibernation fix to avoid bringing up nonboot CPUs with ACPI EC
         disabled during thaw transitions from Bjørn Mork.
    
       - PM core fixes and cleanups from Ben Dooks, Leonardo Potenza, Ulf
         Hansson.
    
       - PNP subsystem fixes and cleanups from Dmitry Torokhov, Levente
         Kurusa, Rashika Kheria.
    
       - New tool for profiling system suspend from Todd E Brandt and a
         cpupower tool cleanup from One Thousand Gnomes"
    
    * tag 'pm+acpi-3.14-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (153 commits)
      thermal: exynos: boost: Automatic enable/disable of BOOST feature (at Exynos4412)
      cpufreq: exynos4x12: Change L0 driver data to CPUFREQ_BOOST_FREQ
      Documentation: cpufreq / boost: Update BOOST documentation
      cpufreq: exynos: Extend Exynos cpufreq driver to support boost
      cpufreq / boost: Kconfig: Support for software-managed BOOST
      acpi-cpufreq: Adjust the code to use the common boost attribute
      cpufreq: Add boost frequency support in core
      intel_pstate: Add trace point to report internal state.
      cpufreq: introduce cpufreq_generic_get() routine
      ARM: SA1100: Create dummy clk_get_rate() to avoid build failures
      cpufreq: stats: create sysfs entries when cpufreq_stats is a module
      cpufreq: stats: free table and remove sysfs entry in a single routine
      cpufreq: stats: remove hotplug notifiers
      cpufreq: stats: handle cpufreq_unregister_driver() and suspend/resume properly
      cpufreq: speedstep: remove unused speedstep_get_state
      platform: introduce OF style 'modalias' support for platform bus
      PM / tools: new tool for suspend/resume performance optimization
      ACPI: fix module autoloading for ACPI enumerated devices
      ACPI: add module autoloading support for ACPI enumerated devices
      ACPI: fix create_modalias() return value handling
      ...

commit 9612a461c1e48f75ca1e1f0faf9c928761baae5b
Merge: 4ff913373a77 4955a5412cad
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Jan 17 01:56:47 2014 +0100

    Merge branch 'pm-cpuidle'
    
    * pm-cpuidle:
      intel_idle: remove superfluous dev->state_count initialization
      intel_idle: do C1E promotion disable quirk for hotplugged CPUs
      ACPI / cpuidle: remove dev->state_count setting
      ACPI / cpuidle: fix max idle state handling with hotplug CPU support
      POWERPC: pseries: cpuidle: use the common cpuidle_[un]register() routines
      POWERPC: pseries: cpuidle: remove superfluous dev->state_count initialization
      ARM: EXYNOS: cpuidle: fix AFTR mode check

commit 130a5f692425e6237229598a8624da0a247f33d5
Author: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
Date:   Fri Dec 20 19:47:27 2013 +0100

    ACPI / cpuidle: remove dev->state_count setting
    
    dev->state_count is now always equal to drv->state_count and
    drv->state_count no longer can change during driver's lifetime so
    the default dev->state_count initialization in cpuidle_enable_device()
    (called from cpuidle_register_device()) can be used instead.
    
    Signed-off-by: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
    Signed-off-by: Kyungmin Park <kyungmin.park@samsung.com>
    Cc: Len Brown <lenb@kernel.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 45e3b81d6c29..23c80e1372a9 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -953,8 +953,6 @@ static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,
 			break;
 	}
 
-	dev->state_count = count;
-
 	if (!count)
 		return -EINVAL;
 

commit 7ca380f60626d90cdd17cc60de5e756422e35b2a
Author: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
Date:   Fri Dec 20 19:47:26 2013 +0100

    ACPI / cpuidle: fix max idle state handling with hotplug CPU support
    
    acpi_processor_hotplug() calls acpi_processor_setup_cpuidle_cx()
    without calling acpi_processor_setup_cpuidle_states() first so it
    is possible that dev->state_count becomes different from
    drv->state_count (in case of SMP system with unsupported C2/C3
    states + enabled CPU hotplug and num_online_cpus() becoming > 1).
    
    The driver code assumes that cpuidle core will handle such cases
    but currently this is untrue (dev->state_count is used only for
    handling cpuidle state sysfs entries and drv->state_count is used
    for all other cases) and will not be fixed in the future as
    dev->state_count is planned to be removed.
    
    Fix the issue by checking for the max supported idle state in
    C2/C3 state's ->enter handler (acpi_idle_enter_simple() for C2/C3
    and acpi_idle_enter_bm() for C3 + bm_check flag set) and setting
    the C1 state (instead of higher states) when needed.
    
    Also remove no longer needed max idle state checks from
    acpi_processor_setup_cpuidle_[states,cx]().
    
    Signed-off-by: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
    Signed-off-by: Kyungmin Park <kyungmin.park@samsung.com>
    Cc: Len Brown <lenb@kernel.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 644516d9bde6..45e3b81d6c29 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -785,6 +785,13 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	if (unlikely(!pr))
 		return -EINVAL;
 
+#ifdef CONFIG_HOTPLUG_CPU
+	if ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) &&
+	    !pr->flags.has_cst &&
+	    !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
+		return acpi_idle_enter_c1(dev, drv, CPUIDLE_DRIVER_STATE_START);
+#endif
+
 	if (cx->entry_method == ACPI_CSTATE_FFH) {
 		if (current_set_polling_and_test())
 			return -EINVAL;
@@ -831,6 +838,13 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	if (unlikely(!pr))
 		return -EINVAL;
 
+#ifdef CONFIG_HOTPLUG_CPU
+	if ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) &&
+	    !pr->flags.has_cst &&
+	    !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
+		return acpi_idle_enter_c1(dev, drv, CPUIDLE_DRIVER_STATE_START);
+#endif
+
 	if (!cx->bm_sts_skip && acpi_idle_bm_check()) {
 		if (drv->safe_state_index >= 0) {
 			return drv->states[drv->safe_state_index].enter(dev,
@@ -932,12 +946,6 @@ static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,
 		if (!cx->valid)
 			continue;
 
-#ifdef CONFIG_HOTPLUG_CPU
-		if ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) &&
-		    !pr->flags.has_cst &&
-		    !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
-			continue;
-#endif
 		per_cpu(acpi_cstate[count], dev->cpu) = cx;
 
 		count++;
@@ -987,13 +995,6 @@ static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
 		if (!cx->valid)
 			continue;
 
-#ifdef CONFIG_HOTPLUG_CPU
-		if ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) &&
-		    !pr->flags.has_cst &&
-		    !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
-			continue;
-#endif
-
 		state = &drv->states[count];
 		snprintf(state->name, CPUIDLE_NAME_LEN, "C%d", i);
 		strncpy(state->desc, cx->desc, CPUIDLE_DESC_LEN);

commit 16824255394f55adf31b9a96a9965d8c15bdac4c
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Thu Dec 12 15:08:36 2013 +0100

    x86, acpi, idle: Restructure the mwait idle routines
    
    People seem to delight in writing wrong and broken mwait idle routines;
    collapse the lot.
    
    This leaves mwait_play_dead() the sole remaining user of __mwait() and
    new __mwait() users are probably doing it wrong.
    
    Also remove __sti_mwait() as its unused.
    
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Jacob Jun Pan <jacob.jun.pan@linux.intel.com>
    Cc: Mike Galbraith <bitbucket@online.de>
    Cc: Len Brown <lenb@kernel.org>
    Cc: Rui Zhang <rui.zhang@intel.com>
    Acked-by: Rafael Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20131212141654.616820819@infradead.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 644516d9bde6..f90c56c8379e 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -727,11 +727,6 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 	if (unlikely(!pr))
 		return -EINVAL;
 
-	if (cx->entry_method == ACPI_CSTATE_FFH) {
-		if (current_set_polling_and_test())
-			return -EINVAL;
-	}
-
 	lapic_timer_state_broadcast(pr, cx, 1);
 	acpi_idle_do_entry(cx);
 
@@ -785,11 +780,6 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	if (unlikely(!pr))
 		return -EINVAL;
 
-	if (cx->entry_method == ACPI_CSTATE_FFH) {
-		if (current_set_polling_and_test())
-			return -EINVAL;
-	}
-
 	/*
 	 * Must be done before busmaster disable as we might need to
 	 * access HPET !
@@ -841,11 +831,6 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		}
 	}
 
-	if (cx->entry_method == ACPI_CSTATE_FFH) {
-		if (current_set_polling_and_test())
-			return -EINVAL;
-	}
-
 	acpi_unlazy_tlb(smp_processor_id());
 
 	/* Tell the scheduler that we are going deep-idle: */

commit 43575faab3967b7b48aeb1c30f823b8233517552
Author: Al Stone <al.stone@linaro.org>
Date:   Mon Dec 16 17:01:37 2013 -0700

    ACPI / processor: initialize a variable to silence compiler warning
    
    In acpi_processor_resume(), the variable resumed_bm_rld is being
    used without being initialized, so initialize it.
    
    Signed-off-by: Al Stone <al.stone@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index a0cc5ef4f06f..799644c3888c 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -211,7 +211,7 @@ static int acpi_processor_suspend(void)
 
 static void acpi_processor_resume(void)
 {
-	u32 resumed_bm_rld;
+	u32 resumed_bm_rld = 0;
 
 	acpi_read_bit_register(ACPI_BITREG_BUS_MASTER_RLD, &resumed_bm_rld);
 	if (resumed_bm_rld == saved_bm_rld)

commit cad1525a5e7443cd93368a22e5b7571c373c8cc0
Author: Al Stone <al.stone@linaro.org>
Date:   Wed Dec 4 12:59:11 2013 -0700

    ACPI: remove trailing whitespace
    
    Minor cleanup: remove some extra trailing white space.
    
    Signed-off-by: Al Stone <al.stone@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index d2d44e0190a3..a0cc5ef4f06f 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -596,7 +596,7 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 		case ACPI_STATE_C2:
 			if (!cx->address)
 				break;
-			cx->valid = 1; 
+			cx->valid = 1;
 			break;
 
 		case ACPI_STATE_C3:

commit 8b48463f89429af408ff695244dc627e1acff4f7
Author: Lv Zheng <lv.zheng@intel.com>
Date:   Tue Dec 3 08:49:16 2013 +0800

    ACPI: Clean up inclusions of ACPI header files
    
    Replace direct inclusions of <acpi/acpi.h>, <acpi/acpi_bus.h> and
    <acpi/acpi_drivers.h>, which are incorrect, with <linux/acpi.h>
    inclusions and remove some inclusions of those files that aren't
    necessary.
    
    First of all, <acpi/acpi.h>, <acpi/acpi_bus.h> and <acpi/acpi_drivers.h>
    should not be included directly from any files that are built for
    CONFIG_ACPI unset, because that generally leads to build warnings about
    undefined symbols in !CONFIG_ACPI builds.  For CONFIG_ACPI set,
    <linux/acpi.h> includes those files and for CONFIG_ACPI unset it
    provides stub ACPI symbols to be used in that case.
    
    Second, there are ordering dependencies between those files that always
    have to be met.  Namely, it is required that <acpi/acpi_bus.h> be included
    prior to <acpi/acpi_drivers.h> so that the acpi_pci_root declarations the
    latter depends on are always there.  And <acpi/acpi.h> which provides
    basic ACPICA type declarations should always be included prior to any other
    ACPI headers in CONFIG_ACPI builds.  That also is taken care of including
    <linux/acpi.h> as appropriate.
    
    Signed-off-by: Lv Zheng <lv.zheng@intel.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Matthew Garrett <mjg59@srcf.ucam.org>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Acked-by: Bjorn Helgaas <bhelgaas@google.com> (drivers/pci stuff)
    Acked-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com> (Xen stuff)
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 644516d9bde6..d2d44e0190a3 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -35,6 +35,7 @@
 #include <linux/clockchips.h>
 #include <linux/cpuidle.h>
 #include <linux/syscore_ops.h>
+#include <acpi/processor.h>
 
 /*
  * Include the apic definitions for x86 to have the APIC timer related defines
@@ -46,9 +47,6 @@
 #include <asm/apic.h>
 #endif
 
-#include <acpi/acpi_bus.h>
-#include <acpi/processor.h>
-
 #define PREFIX "ACPI: "
 
 #define ACPI_PROCESSOR_CLASS            "processor"

commit f9300eaaac1ca300083ad41937923a90cc3a2394
Merge: 7f2dc5c4bcbf faddf2f5d278
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Nov 14 13:41:48 2013 +0900

    Merge tag 'pm+acpi-3.13-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull ACPI and power management updates from Rafael J Wysocki:
    
     - New power capping framework and the the Intel Running Average Power
       Limit (RAPL) driver using it from Srinivas Pandruvada and Jacob Pan.
    
     - Addition of the in-kernel switching feature to the arm_big_little
       cpufreq driver from Viresh Kumar and Nicolas Pitre.
    
     - cpufreq support for iMac G5 from Aaro Koskinen.
    
     - Baytrail processors support for intel_pstate from Dirk Brandewie.
    
     - cpufreq support for Midway/ECX-2000 from Mark Langsdorf.
    
     - ARM vexpress/TC2 cpufreq support from Sudeep KarkadaNagesha.
    
     - ACPI power management support for the I2C and SPI bus types from Mika
       Westerberg and Lv Zheng.
    
     - cpufreq core fixes and cleanups from Viresh Kumar, Srivatsa S Bhat,
       Stratos Karafotis, Xiaoguang Chen, Lan Tianyu.
    
     - cpufreq drivers updates (mostly fixes and cleanups) from Viresh
       Kumar, Aaro Koskinen, Jungseok Lee, Sudeep KarkadaNagesha, Lukasz
       Majewski, Manish Badarkhe, Hans-Christian Egtvedt, Evgeny Kapaev.
    
     - intel_pstate updates from Dirk Brandewie and Adrian Huang.
    
     - ACPICA update to version 20130927 includig fixes and cleanups and
       some reduction of divergences between the ACPICA code in the kernel
       and ACPICA upstream in order to improve the automatic ACPICA patch
       generation process.  From Bob Moore, Lv Zheng, Tomasz Nowicki, Naresh
       Bhat, Bjorn Helgaas, David E Box.
    
     - ACPI IPMI driver fixes and cleanups from Lv Zheng.
    
     - ACPI hotplug fixes and cleanups from Bjorn Helgaas, Toshi Kani, Zhang
       Yanfei, Rafael J Wysocki.
    
     - Conversion of the ACPI AC driver to the platform bus type and
       multiple driver fixes and cleanups related to ACPI from Zhang Rui.
    
     - ACPI processor driver fixes and cleanups from Hanjun Guo, Jiang Liu,
       Bartlomiej Zolnierkiewicz, Mathieu Rhéaume, Rafael J Wysocki.
    
     - Fixes and cleanups and new blacklist entries related to the ACPI
       video support from Aaron Lu, Felipe Contreras, Lennart Poettering,
       Kirill Tkhai.
    
     - cpuidle core cleanups from Viresh Kumar and Lorenzo Pieralisi.
    
     - cpuidle drivers fixes and cleanups from Daniel Lezcano, Jingoo Han,
       Bartlomiej Zolnierkiewicz, Prarit Bhargava.
    
     - devfreq updates from Sachin Kamat, Dan Carpenter, Manish Badarkhe.
    
     - Operation Performance Points (OPP) core updates from Nishanth Menon.
    
     - Runtime power management core fix from Rafael J Wysocki and update
       from Ulf Hansson.
    
     - Hibernation fixes from Aaron Lu and Rafael J Wysocki.
    
     - Device suspend/resume lockup detection mechanism from Benoit Goby.
    
     - Removal of unused proc directories created for various ACPI drivers
       from Lan Tianyu.
    
     - ACPI LPSS driver fix and new device IDs for the ACPI platform scan
       handler from Heikki Krogerus and Jarkko Nikula.
    
     - New ACPI _OSI blacklist entry for Toshiba NB100 from Levente Kurusa.
    
     - Assorted fixes and cleanups related to ACPI from Andy Shevchenko, Al
       Stone, Bartlomiej Zolnierkiewicz, Colin Ian King, Dan Carpenter,
       Felipe Contreras, Jianguo Wu, Lan Tianyu, Yinghai Lu, Mathias Krause,
       Liu Chuansheng.
    
     - Assorted PM fixes and cleanups from Andy Shevchenko, Thierry Reding,
       Jean-Christophe Plagniol-Villard.
    
    * tag 'pm+acpi-3.13-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (386 commits)
      cpufreq: conservative: fix requested_freq reduction issue
      ACPI / hotplug: Consolidate deferred execution of ACPI hotplug routines
      PM / runtime: Use pm_runtime_put_sync() in __device_release_driver()
      ACPI / event: remove unneeded NULL pointer check
      Revert "ACPI / video: Ignore BIOS initial backlight value for HP 250 G1"
      ACPI / video: Quirk initial backlight level 0
      ACPI / video: Fix initial level validity test
      intel_pstate: skip the driver if ACPI has power mgmt option
      PM / hibernate: Avoid overflow in hibernate_preallocate_memory()
      ACPI / hotplug: Do not execute "insert in progress" _OST
      ACPI / hotplug: Carry out PCI root eject directly
      ACPI / hotplug: Merge device hot-removal routines
      ACPI / hotplug: Make acpi_bus_hot_remove_device() internal
      ACPI / hotplug: Simplify device ejection routines
      ACPI / hotplug: Fix handle_root_bridge_removal()
      ACPI / hotplug: Refuse to hot-remove all objects with disabled hotplug
      ACPI / scan: Start matching drivers after trying scan handlers
      ACPI: Remove acpi_pci_slot_init() headers from internal.h
      ACPI / blacklist: fix name of ThinkPad Edge E530
      PowerCap: Fix build error with option -Werror=format-security
      ...
    
    Conflicts:
            arch/arm/mach-omap2/opp.c
            drivers/Kconfig
            drivers/spi/spi.c

commit ea8117478918a4734586d35ff530721b682425be
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Wed Sep 11 12:43:13 2013 +0200

    sched, idle: Fix the idle polling state logic
    
    Mike reported that commit 7d1a9417 ("x86: Use generic idle loop")
    regressed several workloads and caused excessive reschedule
    interrupts.
    
    The patch in question failed to notice that the x86 code had an
    inverted sense of the polling state versus the new generic code (x86:
    default polling, generic: default !polling).
    
    Fix the two prominent x86 mwait based idle drivers and introduce a few
    new generic polling helpers (fixing the wrong smp_mb__after_clear_bit
    usage).
    
    Also switch the idle routines to using tif_need_resched() which is an
    immediate TIF_NEED_RESCHED test as opposed to need_resched which will
    end up being slightly different.
    
    Reported-by: Mike Galbraith <bitbucket@online.de>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Cc: lenb@kernel.org
    Cc: tglx@linutronix.de
    Link: http://lkml.kernel.org/n/tip-nc03imb0etuefmzybzj7sprf@git.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index f98dd00b51a9..c7414a545a4f 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -119,17 +119,10 @@ static struct dmi_system_id processor_power_dmi_table[] = {
  */
 static void acpi_safe_halt(void)
 {
-	current_thread_info()->status &= ~TS_POLLING;
-	/*
-	 * TS_POLLING-cleared state must be visible before we
-	 * test NEED_RESCHED:
-	 */
-	smp_mb();
-	if (!need_resched()) {
+	if (!tif_need_resched()) {
 		safe_halt();
 		local_irq_disable();
 	}
-	current_thread_info()->status |= TS_POLLING;
 }
 
 #ifdef ARCH_APICTIMER_STOPS_ON_C3
@@ -737,6 +730,11 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 	if (unlikely(!pr))
 		return -EINVAL;
 
+	if (cx->entry_method == ACPI_CSTATE_FFH) {
+		if (current_set_polling_and_test())
+			return -EINVAL;
+	}
+
 	lapic_timer_state_broadcast(pr, cx, 1);
 	acpi_idle_do_entry(cx);
 
@@ -790,18 +788,9 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	if (unlikely(!pr))
 		return -EINVAL;
 
-	if (cx->entry_method != ACPI_CSTATE_FFH) {
-		current_thread_info()->status &= ~TS_POLLING;
-		/*
-		 * TS_POLLING-cleared state must be visible before we test
-		 * NEED_RESCHED:
-		 */
-		smp_mb();
-
-		if (unlikely(need_resched())) {
-			current_thread_info()->status |= TS_POLLING;
+	if (cx->entry_method == ACPI_CSTATE_FFH) {
+		if (current_set_polling_and_test())
 			return -EINVAL;
-		}
 	}
 
 	/*
@@ -819,9 +808,6 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 
 	sched_clock_idle_wakeup_event(0);
 
-	if (cx->entry_method != ACPI_CSTATE_FFH)
-		current_thread_info()->status |= TS_POLLING;
-
 	lapic_timer_state_broadcast(pr, cx, 0);
 	return index;
 }
@@ -858,18 +844,9 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		}
 	}
 
-	if (cx->entry_method != ACPI_CSTATE_FFH) {
-		current_thread_info()->status &= ~TS_POLLING;
-		/*
-		 * TS_POLLING-cleared state must be visible before we test
-		 * NEED_RESCHED:
-		 */
-		smp_mb();
-
-		if (unlikely(need_resched())) {
-			current_thread_info()->status |= TS_POLLING;
+	if (cx->entry_method == ACPI_CSTATE_FFH) {
+		if (current_set_polling_and_test())
 			return -EINVAL;
-		}
 	}
 
 	acpi_unlazy_tlb(smp_processor_id());
@@ -915,9 +892,6 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 
 	sched_clock_idle_wakeup_event(0);
 
-	if (cx->entry_method != ACPI_CSTATE_FFH)
-		current_thread_info()->status |= TS_POLLING;
-
 	lapic_timer_state_broadcast(pr, cx, 0);
 	return index;
 }

commit bf9b59f2571d0d0470f904842a283ac7957438cd
Author: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
Date:   Fri Aug 30 12:30:51 2013 +0200

    ACPI / processor: remove superfluous pr == NULL checks
    
    The only acpi_processor_get_power_info_fadt() user
    (acpi_processor_get_power_info()) dereferences pr before calling
    the function.
    
    The only acpi_processor_hotplug() user (acpi_cpu_soft_notify())
    checks for pr == NULL before calling the function.
    
    The only acpi_processor_cst_has_changed() user (acpi_processor_notify())
    checks for pr == NULL before calling the function.
    
    The only acpi_processor_power_init() user (__acpi_processor_start())
    dereferences pr before calling the function.
    
    Thus remove superfluous pr == NULL checks from affected functions.
    
    Also:
    
    While at it remove redundant brackets from acpi_processor_hotplug().
    
    Signed-off-by: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
    Signed-off-by: Kyungmin Park <kyungmin.park@samsung.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index f98dd00b51a9..35c8f2bbcc40 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -272,9 +272,6 @@ static void tsc_check_state(int state) { return; }
 static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 {
 
-	if (!pr)
-		return -EINVAL;
-
 	if (!pr->pblk)
 		return -ENODEV;
 
@@ -1076,12 +1073,8 @@ int acpi_processor_hotplug(struct acpi_processor *pr)
 	if (disabled_by_idle_boot_param())
 		return 0;
 
-	if (!pr)
-		return -EINVAL;
-
-	if (nocst) {
+	if (nocst)
 		return -ENODEV;
-	}
 
 	if (!pr->flags.power_setup_done)
 		return -ENODEV;
@@ -1108,9 +1101,6 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 	if (disabled_by_idle_boot_param())
 		return 0;
 
-	if (!pr)
-		return -EINVAL;
-
 	if (nocst)
 		return -ENODEV;
 
@@ -1183,9 +1173,6 @@ int acpi_processor_power_init(struct acpi_processor *pr)
 		first_run++;
 	}
 
-	if (!pr)
-		return -EINVAL;
-
 	if (acpi_gbl_FADT.cst_control && !nocst) {
 		status =
 		    acpi_os_write_port(acpi_gbl_FADT.smi_command, acpi_gbl_FADT.cst_control, 8);

commit fe7bf106ebc22730797ba9b51308b166d68b77f9
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Wed Jun 19 14:30:58 2013 -0400

    acpi: delete __cpuinit usage from all acpi files
    
    The __cpuinit type of throwaway sections might have made sense
    some time ago when RAM was more constrained, but now the savings
    do not offset the cost and complications.  For example, the fix in
    commit 5e427ec2d0 ("x86: Fix bit corruption at CPU resume time")
    is a good example of the nasty type of bugs that can be created
    with improper use of the various __init prefixes.
    
    After a discussion on LKML[1] it was decided that cpuinit should go
    the way of devinit and be phased out.  Once all the users are gone,
    we can then finally remove the macros themselves from linux/init.h.
    
    This removes all the drivers/acpi uses of the __cpuinit macros
    from all C files.
    
    [1] https://lkml.org/lkml/2013/5/20/589
    
    Cc: Len Brown <lenb@kernel.org>
    Cc: "Rafael J. Wysocki" <rjw@sisk.pl>
    Cc: linux-acpi@vger.kernel.org
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 0461ccc92c54..f98dd00b51a9 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -96,9 +96,7 @@ static int set_max_cstate(const struct dmi_system_id *id)
 	return 0;
 }
 
-/* Actually this shouldn't be __cpuinitdata, would be better to fix the
-   callers to only run once -AK */
-static struct dmi_system_id __cpuinitdata processor_power_dmi_table[] = {
+static struct dmi_system_id processor_power_dmi_table[] = {
 	{ set_max_cstate, "Clevo 5600D", {
 	  DMI_MATCH(DMI_BIOS_VENDOR,"Phoenix Technologies LTD"),
 	  DMI_MATCH(DMI_BIOS_VERSION,"SHE845M0.86C.0013.D.0302131307")},
@@ -1165,7 +1163,7 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 
 static int acpi_processor_registered;
 
-int __cpuinit acpi_processor_power_init(struct acpi_processor *pr)
+int acpi_processor_power_init(struct acpi_processor *pr)
 {
 	acpi_status status = 0;
 	int retval;

commit 95d45d4cab6540e3f2183d86662c255fa4332331
Author: Fengguang Wu <fengguang.wu@intel.com>
Date:   Tue Jun 11 00:55:10 2013 +0200

    ACPI / PM: acpi_processor_suspend() can be static
    
    Since acpi_processor_suspend() and acpi_processor_resume() need not
    be visible outside of the file they are defined in, make them
    static.
    
    [rjw: Changelog]
    Signed-off-by: Fengguang Wu <fengguang.wu@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index eb133c77aadb..0461ccc92c54 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -214,13 +214,13 @@ static void lapic_timer_state_broadcast(struct acpi_processor *pr,
 #ifdef CONFIG_PM_SLEEP
 static u32 saved_bm_rld;
 
-int acpi_processor_suspend(void)
+static int acpi_processor_suspend(void)
 {
 	acpi_read_bit_register(ACPI_BITREG_BUS_MASTER_RLD, &saved_bm_rld);
 	return 0;
 }
 
-void acpi_processor_resume(void)
+static void acpi_processor_resume(void)
 {
 	u32 resumed_bm_rld;
 

commit 0a3b15ac3cc3ddc791901e12bdc930b5fa11a30a
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu May 2 21:54:37 2013 +0200

    ACPI / PM: Move processor suspend/resume to syscore_ops
    
    The system suspend routine of the ACPI processor driver saves
    the BUS_MASTER_RLD register and its resume routine restores it.
    However, there can be only one such register in the system and it
    really should be saved after non-boot CPUs have been offlined and
    restored before they are put back online during resume.
    
    For this reason, move the saving and restoration of BUS_MASTER_RLD
    to syscore suspend and syscore resume, respectively, and drop the no
    longer necessary suspend/resume callbacks from the ACPI processor
    driver.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index f0df2c9434d2..eb133c77aadb 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -34,6 +34,7 @@
 #include <linux/sched.h>       /* need_resched() */
 #include <linux/clockchips.h>
 #include <linux/cpuidle.h>
+#include <linux/syscore_ops.h>
 
 /*
  * Include the apic definitions for x86 to have the APIC timer related defines
@@ -210,33 +211,41 @@ static void lapic_timer_state_broadcast(struct acpi_processor *pr,
 
 #endif
 
+#ifdef CONFIG_PM_SLEEP
 static u32 saved_bm_rld;
 
-static void acpi_idle_bm_rld_save(void)
+int acpi_processor_suspend(void)
 {
 	acpi_read_bit_register(ACPI_BITREG_BUS_MASTER_RLD, &saved_bm_rld);
+	return 0;
 }
-static void acpi_idle_bm_rld_restore(void)
+
+void acpi_processor_resume(void)
 {
 	u32 resumed_bm_rld;
 
 	acpi_read_bit_register(ACPI_BITREG_BUS_MASTER_RLD, &resumed_bm_rld);
+	if (resumed_bm_rld == saved_bm_rld)
+		return;
 
-	if (resumed_bm_rld != saved_bm_rld)
-		acpi_write_bit_register(ACPI_BITREG_BUS_MASTER_RLD, saved_bm_rld);
+	acpi_write_bit_register(ACPI_BITREG_BUS_MASTER_RLD, saved_bm_rld);
 }
 
-int acpi_processor_suspend(struct device *dev)
+static struct syscore_ops acpi_processor_syscore_ops = {
+	.suspend = acpi_processor_suspend,
+	.resume = acpi_processor_resume,
+};
+
+void acpi_processor_syscore_init(void)
 {
-	acpi_idle_bm_rld_save();
-	return 0;
+	register_syscore_ops(&acpi_processor_syscore_ops);
 }
 
-int acpi_processor_resume(struct device *dev)
+void acpi_processor_syscore_exit(void)
 {
-	acpi_idle_bm_rld_restore();
-	return 0;
+	unregister_syscore_ops(&acpi_processor_syscore_ops);
 }
+#endif /* CONFIG_PM_SLEEP */
 
 #if defined(CONFIG_X86)
 static void tsc_check_state(int state)

commit 554c06ba3ee29cf453fca17e9e61120b75aa476d
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Tue Apr 23 08:54:31 2013 +0000

    cpuidle: remove en_core_tk_irqen flag
    
    The en_core_tk_irqen flag is set in all the cpuidle driver which
    means it is not necessary to specify this flag.
    
    Remove the flag and the code related to it.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Kevin Hilman <khilman@linaro.org>  # for mach-omap2/*
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index ee255c60bdac..f0df2c9434d2 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -918,7 +918,6 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 struct cpuidle_driver acpi_idle_driver = {
 	.name =		"acpi_idle",
 	.owner =	THIS_MODULE,
-	.en_core_tk_irqen = 1,
 };
 
 /**

commit 6240a10dc55a954ce05a86d2f4bc27e473b6352c
Author: Alex Shi <alex.shi@intel.com>
Date:   Tue Apr 2 01:56:54 2013 +0200

    cpuidle / ACPI: recover percpu ACPI processor cstate
    
    Commit ac3ebafa81af76d6 "ACPI / idle: remove usage of the statedata"
    changed the percpu processor cstate to a unified cstate in ACPI idle.
    That caused all our NHM boxes to boot hang or panic.
    
    2178751 Task dump for CPU 1:
            2178752 swapper/1       R  running task     6736     0      1 0x00000000
            2178753  ffff8801e8029dc8 ffffffff8101cf96 ffff8801e8029e28 ffffffff813d294b
            2178754  0000000000000f99 0000000000000003 00000000003cf654 0000000025c17d03
            2178755  ffff8801e8029e38 ffff8801e74fc000 00000002590dc5c4 ffffffff8163cdb0
            2178756 Call Trace:
            2178757  [<ffffffff8101cf96>] ? acpi_processor_ffh_cstate_enter+0x2d/0x2f
            2178758  [<ffffffff813d294b>] acpi_idle_enter_bm+0x1b1/0x236
            2178759  [<ffffffff8163cdb0>] ? disable_cpuidle+0x10/0x10
            2178760  [<ffffffff8163cdc2>] cpuidle_enter+0x12/0x14
            2178761  [<ffffffff8163d286>] cpuidle_wrap_enter+0x2f/0x6d
            2178762  [<ffffffff8163d2d4>] cpuidle_enter_tk+0x10/0x12
            2178763  [<ffffffff8163cdd6>] cpuidle_enter_state+0x12/0x3a
            2178764  [<ffffffff8163d4a7>] cpuidle_idle_call+0xe8/0x161
            2178765  [<ffffffff81008d99>] cpu_idle+0x5e/0xa4
            2178766  [<ffffffff8174c6c1>] start_secondary+0x1a9/0x1ad
            2178767 Task dump for CPU 2:
    
    In fact, the ACPI idle is based on the assumption of difference percpu
    cstate structures that are necessary for the implementation to work
    cprrectly.  A unique acpi_processor_cx is not sifficient by far.
    
    This patch is just a quick fix re-introducing the percpu cstates.
    
    If someone really wants to unify the ACPI cstates, please make sure
    that the whole software infrastructure is changed and take hardware
    as well as many different kinds of BIOS settings into account.
    
    [rjw: Changelog]
    Reported-by: LKP project <lkp@linux.intel.com>
    Reported-by: Xie ChanglongX <changlongx.xie@intel.com>
    Tested-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Alex Shi <alex.shi@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index fc95308e9a11..ee255c60bdac 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -66,7 +66,8 @@ module_param(latency_factor, uint, 0644);
 
 static DEFINE_PER_CPU(struct cpuidle_device *, acpi_cpuidle_device);
 
-static struct acpi_processor_cx *acpi_cstate[CPUIDLE_STATE_MAX];
+static DEFINE_PER_CPU(struct acpi_processor_cx * [CPUIDLE_STATE_MAX],
+								acpi_cstate);
 
 static int disabled_by_idle_boot_param(void)
 {
@@ -722,7 +723,7 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 		struct cpuidle_driver *drv, int index)
 {
 	struct acpi_processor *pr;
-	struct acpi_processor_cx *cx = acpi_cstate[index];
+	struct acpi_processor_cx *cx = per_cpu(acpi_cstate[index], dev->cpu);
 
 	pr = __this_cpu_read(processors);
 
@@ -745,7 +746,7 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
  */
 static int acpi_idle_play_dead(struct cpuidle_device *dev, int index)
 {
-	struct acpi_processor_cx *cx = acpi_cstate[index];
+	struct acpi_processor_cx *cx = per_cpu(acpi_cstate[index], dev->cpu);
 
 	ACPI_FLUSH_CPU_CACHE();
 
@@ -775,7 +776,7 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 		struct cpuidle_driver *drv, int index)
 {
 	struct acpi_processor *pr;
-	struct acpi_processor_cx *cx = acpi_cstate[index];
+	struct acpi_processor_cx *cx = per_cpu(acpi_cstate[index], dev->cpu);
 
 	pr = __this_cpu_read(processors);
 
@@ -833,7 +834,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		struct cpuidle_driver *drv, int index)
 {
 	struct acpi_processor *pr;
-	struct acpi_processor_cx *cx = acpi_cstate[index];
+	struct acpi_processor_cx *cx = per_cpu(acpi_cstate[index], dev->cpu);
 
 	pr = __this_cpu_read(processors);
 
@@ -960,7 +961,7 @@ static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,
 		    !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
 			continue;
 #endif
-		acpi_cstate[count] = cx;
+		per_cpu(acpi_cstate[count], dev->cpu) = cx;
 
 		count++;
 		if (count == CPUIDLE_STATE_MAX)

commit ca62cf59ceef10ff2ebca0e7f764507186870270
Merge: 2e7d0f60d8b9 27be45700021
Author: Len Brown <len.brown@intel.com>
Date:   Mon Feb 18 00:25:53 2013 -0500

    Merge branch 'misc' into release
    
    Conflicts:
            arch/x86/kernel/process.c
    
    Signed-off-by: Len Brown <len.brown@intel.com>

commit 69fb3676df3329a7142803bb3502fa59dc0db2e3
Author: Len Brown <len.brown@intel.com>
Date:   Sun Feb 10 01:38:39 2013 -0500

    x86 idle: remove mwait_idle() and "idle=mwait" cmdline param
    
    mwait_idle() is a C1-only idle loop intended to be more efficient
    than HLT, starting on Pentium-4 HT-enabled processors.
    
    But mwait_idle() has been replaced by the more general
    mwait_idle_with_hints(), which handles both C1 and deeper C-states.
    ACPI processor_idle and intel_idle use only mwait_idle_with_hints(),
    and no longer use mwait_idle().
    
    Here we simplify the x86 native idle code by removing mwait_idle(),
    and the "idle=mwait" bootparam used to invoke it.
    
    Since Linux 3.0 there has been a boot-time warning when "idle=mwait"
    was invoked saying it would be removed in 2012.  This removal
    was also noted in the (now removed:-) feature-removal-schedule.txt.
    
    After this change, kernels configured with
    (CONFIG_ACPI=n && CONFIG_INTEL_IDLE=n) when run on hardware
    that supports MWAIT will simply use HLT.  If MWAIT is desired
    on those systems, cpuidle and the cpuidle drivers above
    can be enabled.
    
    Signed-off-by: Len Brown <len.brown@intel.com>
    Cc: x86@kernel.org

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index ed9a1cc690be..52a5e3a4cdc3 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -84,7 +84,6 @@ static DEFINE_PER_CPU(struct cpuidle_device *, acpi_cpuidle_device);
 static int disabled_by_idle_boot_param(void)
 {
 	return boot_option_idle_override == IDLE_POLL ||
-		boot_option_idle_override == IDLE_FORCE_MWAIT ||
 		boot_option_idle_override == IDLE_HALT;
 }
 

commit ac3ebafa81af76d65e4fb45c6388f08e90ddcc6d
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Mon Feb 4 22:44:43 2013 +0000

    ACPI / idle: remove usage of the statedata
    
    Len Brown sent a patch to remove this field in the intel_idle driver.
    The other user of this field is the davinci cpuidle driver and a
    patch has been sent to remove the usage of it.
    
    This patch removes the last user of this field.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 68370659df68..8b433cb08a33 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -66,6 +66,8 @@ module_param(latency_factor, uint, 0644);
 
 static DEFINE_PER_CPU(struct cpuidle_device *, acpi_cpuidle_device);
 
+static struct acpi_processor_cx *acpi_cstate[CPUIDLE_STATE_MAX];
+
 static int disabled_by_idle_boot_param(void)
 {
 	return boot_option_idle_override == IDLE_POLL ||
@@ -721,8 +723,7 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 		struct cpuidle_driver *drv, int index)
 {
 	struct acpi_processor *pr;
-	struct cpuidle_state_usage *state_usage = &dev->states_usage[index];
-	struct acpi_processor_cx *cx = cpuidle_get_statedata(state_usage);
+	struct acpi_processor_cx *cx = acpi_cstate[index];
 
 	pr = __this_cpu_read(processors);
 
@@ -745,8 +746,7 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
  */
 static int acpi_idle_play_dead(struct cpuidle_device *dev, int index)
 {
-	struct cpuidle_state_usage *state_usage = &dev->states_usage[index];
-	struct acpi_processor_cx *cx = cpuidle_get_statedata(state_usage);
+	struct acpi_processor_cx *cx = acpi_cstate[index];
 
 	ACPI_FLUSH_CPU_CACHE();
 
@@ -776,8 +776,7 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 		struct cpuidle_driver *drv, int index)
 {
 	struct acpi_processor *pr;
-	struct cpuidle_state_usage *state_usage = &dev->states_usage[index];
-	struct acpi_processor_cx *cx = cpuidle_get_statedata(state_usage);
+	struct acpi_processor_cx *cx = acpi_cstate[index];
 
 	pr = __this_cpu_read(processors);
 
@@ -835,8 +834,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		struct cpuidle_driver *drv, int index)
 {
 	struct acpi_processor *pr;
-	struct cpuidle_state_usage *state_usage = &dev->states_usage[index];
-	struct acpi_processor_cx *cx = cpuidle_get_statedata(state_usage);
+	struct acpi_processor_cx *cx = acpi_cstate[index];
 
 	pr = __this_cpu_read(processors);
 
@@ -935,7 +933,6 @@ static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,
 {
 	int i, count = CPUIDLE_DRIVER_STATE_START;
 	struct acpi_processor_cx *cx;
-	struct cpuidle_state_usage *state_usage;
 
 	if (!pr->flags.power_setup_done)
 		return -EINVAL;
@@ -954,7 +951,6 @@ static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,
 
 	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {
 		cx = &pr->power.states[i];
-		state_usage = &dev->states_usage[count];
 
 		if (!cx->valid)
 			continue;
@@ -965,8 +961,7 @@ static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,
 		    !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
 			continue;
 #endif
-
-		cpuidle_set_statedata(state_usage, cx);
+		acpi_cstate[count] = cx;
 
 		count++;
 		if (count == CPUIDLE_STATE_MAX)

commit 6ef0f086beafb3c7d81cd3de81d886d105ea25b2
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Mon Feb 4 22:44:42 2013 +0000

    ACPI / idle: pass the cpuidle_device parameter
    
    The cpuidle_device is retrieved in the function by using directly
    the global variable. But the caller of this function already have
    this device and it can be passed as a parameter. That is one small
    step to encapsulate the code more.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 82626e9abe78..68370659df68 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -928,13 +928,14 @@ struct cpuidle_driver acpi_idle_driver = {
  * device i.e. per-cpu data
  *
  * @pr: the ACPI processor
+ * @dev : the cpuidle device
  */
-static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr)
+static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,
+					   struct cpuidle_device *dev)
 {
 	int i, count = CPUIDLE_DRIVER_STATE_START;
 	struct acpi_processor_cx *cx;
 	struct cpuidle_state_usage *state_usage;
-	struct cpuidle_device *dev = per_cpu(acpi_cpuidle_device, pr->id);
 
 	if (!pr->flags.power_setup_done)
 		return -EINVAL;
@@ -1089,7 +1090,7 @@ int acpi_processor_hotplug(struct acpi_processor *pr)
 	cpuidle_disable_device(dev);
 	acpi_processor_get_power_info(pr);
 	if (pr->flags.power) {
-		acpi_processor_setup_cpuidle_cx(pr);
+		acpi_processor_setup_cpuidle_cx(pr, dev);
 		ret = cpuidle_enable_device(dev);
 	}
 	cpuidle_resume_and_unlock();
@@ -1147,8 +1148,8 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 				continue;
 			acpi_processor_get_power_info(_pr);
 			if (_pr->flags.power) {
-				acpi_processor_setup_cpuidle_cx(_pr);
 				dev = per_cpu(acpi_cpuidle_device, cpu);
+				acpi_processor_setup_cpuidle_cx(_pr, dev);
 				cpuidle_enable_device(dev);
 			}
 		}
@@ -1217,7 +1218,7 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr)
 			return -ENOMEM;
 		per_cpu(acpi_cpuidle_device, pr->id) = dev;
 
-		acpi_processor_setup_cpuidle_cx(pr);
+		acpi_processor_setup_cpuidle_cx(pr, dev);
 
 		/* Register per-cpu cpuidle_device. Cpuidle driver
 		 * must already be registered before registering device

commit e2668fb53ffd3e01c3116f65a9047a25e4c66399
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Mon Feb 4 22:44:41 2013 +0000

    ACPI / idle : remove pointless headers
    
    These different headers are not needed.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 5cb5f247d2be..82626e9abe78 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -28,19 +28,12 @@
  * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  */
 
-#include <linux/kernel.h>
 #include <linux/module.h>
-#include <linux/init.h>
-#include <linux/cpufreq.h>
-#include <linux/slab.h>
 #include <linux/acpi.h>
 #include <linux/dmi.h>
-#include <linux/moduleparam.h>
-#include <linux/sched.h>	/* need_resched() */
-#include <linux/pm_qos.h>
+#include <linux/sched.h>       /* need_resched() */
 #include <linux/clockchips.h>
 #include <linux/cpuidle.h>
-#include <linux/irqflags.h>
 
 /*
  * Include the apic definitions for x86 to have the APIC timer related defines
@@ -52,12 +45,8 @@
 #include <asm/apic.h>
 #endif
 
-#include <asm/io.h>
-#include <asm/uaccess.h>
-
 #include <acpi/acpi_bus.h>
 #include <acpi/processor.h>
-#include <asm/processor.h>
 
 #define PREFIX "ACPI: "
 

commit 41cdb0efc42ed3c10f56e0740db28eff086af62b
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Mon Feb 4 22:44:40 2013 +0000

    ACPI / idle: remove unused definition
    
    The different definitions are not used anywhere in the code.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index ed9a1cc690be..5cb5f247d2be 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -64,10 +64,6 @@
 #define ACPI_PROCESSOR_CLASS            "processor"
 #define _COMPONENT              ACPI_PROCESSOR_COMPONENT
 ACPI_MODULE_NAME("processor_idle");
-#define PM_TIMER_TICK_NS		(1000000000ULL/PM_TIMER_FREQUENCY)
-#define C2_OVERHEAD			1	/* 1us */
-#define C3_OVERHEAD			1	/* 1us */
-#define PM_TIMER_TICKS_TO_US(p)		(((p) * 1000)/(PM_TIMER_FREQUENCY/1000))
 
 static unsigned int max_cstate __read_mostly = ACPI_PROCESSOR_MAX_POWER;
 module_param(max_cstate, uint, 0000);

commit f427e5f1cf75bba84cccdac1d8a90552d9ae1065
Author: Thomas Schlichter <thomas.schlichter@web.de>
Date:   Sat Jan 19 00:28:22 2013 +0100

    ACPI / processor: Get power info before updating the C-states
    
    acpi_processor_get_power_info() has to be called before
    acpi_processor_setup_cpuidle_states() to have the latest
    information available. This fixes the missing C-state information
    after AC-->DC transition.
    
    Signed-off-by: Thomas Schlichter <thomas.schlichter@web.de>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index fea6f8d71fa3..ed9a1cc690be 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1152,6 +1152,7 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 		}
 
 		/* Populate Updated C-state information */
+		acpi_processor_get_power_info(pr);
 		acpi_processor_setup_cpuidle_states(pr);
 
 		/* Enable all cpuidle devices */

commit b88a634a903d9670aa5f2f785aa890628ce0dece
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Wed Jan 16 23:40:07 2013 +0100

    ACPI / cpuidle: Fix NULL pointer issues when cpuidle is disabled
    
    If cpuidle is disabled, that means that:
    
            per_cpu(acpi_cpuidle_device, pr->id)
    
    is set to NULL as the acpi_processor_power_init ends up failing at
    
             retval = cpuidle_register_driver(&acpi_idle_driver)
    
    (in acpi_processor_power_init) and never sets the per_cpu idle
    device.  So when acpi_processor_hotplug on CPU online notification
    tries to reference said device it crashes:
    
    cpu 3 spinlock event irq 62
    BUG: unable to handle kernel NULL pointer dereference at 0000000000000004
    IP: [<ffffffff81381013>] acpi_processor_setup_cpuidle_cx+0x3f/0x105
    PGD a259b067 PUD ab38b067 PMD 0
    Oops: 0002 [#1] SMP
    odules linked in: dm_multipath dm_mod xen_evtchn iscsi_boot_sysfs iscsi_tcp libiscsi_tcp libiscsi scsi_transport_iscsi libcrc32c crc32c nouveau mxm_wmi wmi radeon ttm sg sr_mod sd_mod cdrom ata_generic ata_piix libata crc32c_intel scsi_mod atl1c i915 fbcon tileblit font bitblit softcursor drm_kms_helper video xen_blkfront xen_netfront fb_sys_fops sysimgblt sysfillrect syscopyarea xenfs xen_privcmd mperf
    CPU 1
    Pid: 3047, comm: bash Not tainted 3.8.0-rc3upstream-00250-g165c029 #1 MSI MS-7680/H61M-P23 (MS-7680)
    RIP: e030:[<ffffffff81381013>]  [<ffffffff81381013>] acpi_processor_setup_cpuidle_cx+0x3f/0x105
    RSP: e02b:ffff88001742dca8  EFLAGS: 00010202
    RAX: 0000000000010be9 RBX: ffff8800a0a61800 RCX: ffff880105380000
    RDX: 0000000000000003 RSI: 0000000000000200 RDI: ffff8800a0a61800
    RBP: ffff88001742dce8 R08: ffffffff81812360 R09: 0000000000000200
    R10: aaaaaaaaaaaaaaaa R11: 0000000000000001 R12: ffff8800a0a61800
    R13: 00000000ffffff01 R14: 0000000000000000 R15: ffffffff81a907a0
    FS:  00007fd6942f7700(0000) GS:ffff880105280000(0000) knlGS:0000000000000000
    CS:  e033 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 0000000000000004 CR3: 00000000a6773000 CR4: 0000000000042660
    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
    Process bash (pid: 3047, threadinfo ffff88001742c000, task ffff880017944000)
    Stack:
     0000000000000150 ffff880100f59e00 ffff88001742dcd8 ffff8800a0a61800
     0000000000000000 00000000ffffff01 0000000000000000 ffffffff81a907a0
     ffff88001742dd18 ffffffff813815b1 ffff88001742dd08 ffffffff810ae336
    Call Trace:
     [<ffffffff813815b1>] acpi_processor_hotplug+0x7c/0x9f
     [<ffffffff810ae336>] ? schedule_delayed_work_on+0x16/0x20
     [<ffffffff8137ee8f>] acpi_cpu_soft_notify+0x90/0xca
     [<ffffffff8166023d>] notifier_call_chain+0x4d/0x70
     [<ffffffff810bc369>] __raw_notifier_call_chain+0x9/0x10
     [<ffffffff81094a4b>] __cpu_notify+0x1b/0x30
     [<ffffffff81652cf7>] _cpu_up+0x103/0x14b
     [<ffffffff81652e18>] cpu_up+0xd9/0xec
     [<ffffffff8164a254>] store_online+0x94/0xd0
     [<ffffffff814122fb>] dev_attr_store+0x1b/0x20
     [<ffffffff81216404>] sysfs_write_file+0xf4/0x170
    
    This patch fixes it.
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index f1a5da44591d..fea6f8d71fa3 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -958,6 +958,9 @@ static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr)
 		return -EINVAL;
 	}
 
+	if (!dev)
+		return -EINVAL;
+
 	dev->cpu = pr->id;
 
 	if (max_cstate == 0)

commit a474a515497ef3566cfc17a2cab3d54d6d50ff1c
Author: Julius Werner <jwerner@chromium.org>
Date:   Tue Nov 27 14:17:58 2012 +0100

    cpuidle: Measure idle state durations with monotonic clock
    
    Many cpuidle drivers measure their time spent in an idle state by
    reading the wallclock time before and after idling and calculating the
    difference. This leads to erroneous results when the wallclock time gets
    updated by another processor in the meantime, adding that clock
    adjustment to the idle state's time counter.
    
    If the clock adjustment was negative, the result is even worse due to an
    erroneous cast from int to unsigned long long of the last_residency
    variable. The negative 32 bit integer will zero-extend and result in a
    forward time jump of roughly four billion milliseconds or 1.3 hours on
    the idle state residency counter.
    
    This patch changes all affected cpuidle drivers to either use the
    monotonic clock for their measurements or make use of the generic time
    measurement wrapper in cpuidle.c, which was already working correctly.
    Some superfluous CLIs/STIs in the ACPI code are removed (interrupts
    should always already be disabled before entering the idle function, and
    not get reenabled until the generic wrapper has performed its second
    measurement). It also removes the erroneous cast, making sure that
    negative residency values are applied correctly even though they should
    not appear anymore.
    
    Signed-off-by: Julius Werner <jwerner@chromium.org>
    Reviewed-by: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Tested-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Len Brown <len.brown@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index e8086c725305..f1a5da44591d 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -735,31 +735,18 @@ static inline void acpi_idle_do_entry(struct acpi_processor_cx *cx)
 static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 		struct cpuidle_driver *drv, int index)
 {
-	ktime_t  kt1, kt2;
-	s64 idle_time;
 	struct acpi_processor *pr;
 	struct cpuidle_state_usage *state_usage = &dev->states_usage[index];
 	struct acpi_processor_cx *cx = cpuidle_get_statedata(state_usage);
 
 	pr = __this_cpu_read(processors);
-	dev->last_residency = 0;
 
 	if (unlikely(!pr))
 		return -EINVAL;
 
-	local_irq_disable();
-
-
 	lapic_timer_state_broadcast(pr, cx, 1);
-	kt1 = ktime_get_real();
 	acpi_idle_do_entry(cx);
-	kt2 = ktime_get_real();
-	idle_time =  ktime_to_us(ktime_sub(kt2, kt1));
-
-	/* Update device last_residency*/
-	dev->last_residency = (int)idle_time;
 
-	local_irq_enable();
 	lapic_timer_state_broadcast(pr, cx, 0);
 
 	return index;
@@ -806,19 +793,12 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	struct acpi_processor *pr;
 	struct cpuidle_state_usage *state_usage = &dev->states_usage[index];
 	struct acpi_processor_cx *cx = cpuidle_get_statedata(state_usage);
-	ktime_t  kt1, kt2;
-	s64 idle_time_ns;
-	s64 idle_time;
 
 	pr = __this_cpu_read(processors);
-	dev->last_residency = 0;
 
 	if (unlikely(!pr))
 		return -EINVAL;
 
-	local_irq_disable();
-
-
 	if (cx->entry_method != ACPI_CSTATE_FFH) {
 		current_thread_info()->status &= ~TS_POLLING;
 		/*
@@ -829,7 +809,6 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 
 		if (unlikely(need_resched())) {
 			current_thread_info()->status |= TS_POLLING;
-			local_irq_enable();
 			return -EINVAL;
 		}
 	}
@@ -843,22 +822,12 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	if (cx->type == ACPI_STATE_C3)
 		ACPI_FLUSH_CPU_CACHE();
 
-	kt1 = ktime_get_real();
 	/* Tell the scheduler that we are going deep-idle: */
 	sched_clock_idle_sleep_event();
 	acpi_idle_do_entry(cx);
-	kt2 = ktime_get_real();
-	idle_time_ns = ktime_to_ns(ktime_sub(kt2, kt1));
-	idle_time = idle_time_ns;
-	do_div(idle_time, NSEC_PER_USEC);
 
-	/* Update device last_residency*/
-	dev->last_residency = (int)idle_time;
+	sched_clock_idle_wakeup_event(0);
 
-	/* Tell the scheduler how much we idled: */
-	sched_clock_idle_wakeup_event(idle_time_ns);
-
-	local_irq_enable();
 	if (cx->entry_method != ACPI_CSTATE_FFH)
 		current_thread_info()->status |= TS_POLLING;
 
@@ -883,13 +852,8 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	struct acpi_processor *pr;
 	struct cpuidle_state_usage *state_usage = &dev->states_usage[index];
 	struct acpi_processor_cx *cx = cpuidle_get_statedata(state_usage);
-	ktime_t  kt1, kt2;
-	s64 idle_time_ns;
-	s64 idle_time;
-
 
 	pr = __this_cpu_read(processors);
-	dev->last_residency = 0;
 
 	if (unlikely(!pr))
 		return -EINVAL;
@@ -899,16 +863,11 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 			return drv->states[drv->safe_state_index].enter(dev,
 						drv, drv->safe_state_index);
 		} else {
-			local_irq_disable();
 			acpi_safe_halt();
-			local_irq_enable();
 			return -EBUSY;
 		}
 	}
 
-	local_irq_disable();
-
-
 	if (cx->entry_method != ACPI_CSTATE_FFH) {
 		current_thread_info()->status &= ~TS_POLLING;
 		/*
@@ -919,7 +878,6 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 
 		if (unlikely(need_resched())) {
 			current_thread_info()->status |= TS_POLLING;
-			local_irq_enable();
 			return -EINVAL;
 		}
 	}
@@ -934,7 +892,6 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	 */
 	lapic_timer_state_broadcast(pr, cx, 1);
 
-	kt1 = ktime_get_real();
 	/*
 	 * disable bus master
 	 * bm_check implies we need ARB_DIS
@@ -965,18 +922,9 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		c3_cpu_count--;
 		raw_spin_unlock(&c3_lock);
 	}
-	kt2 = ktime_get_real();
-	idle_time_ns = ktime_to_ns(ktime_sub(kt2, kt1));
-	idle_time = idle_time_ns;
-	do_div(idle_time, NSEC_PER_USEC);
-
-	/* Update device last_residency*/
-	dev->last_residency = (int)idle_time;
 
-	/* Tell the scheduler how much we idled: */
-	sched_clock_idle_wakeup_event(idle_time_ns);
+	sched_clock_idle_wakeup_event(0);
 
-	local_irq_enable();
 	if (cx->entry_method != ACPI_CSTATE_FFH)
 		current_thread_info()->status |= TS_POLLING;
 
@@ -987,6 +935,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 struct cpuidle_driver acpi_idle_driver = {
 	.name =		"acpi_idle",
 	.owner =	THIS_MODULE,
+	.en_core_tk_irqen = 1,
 };
 
 /**

commit e8b1b59dc8e42a47c4ce541bd1767ffac206b29c
Author: Wei Yongjun <yongjun_wei@trendmicro.com.cn>
Date:   Mon Oct 8 08:40:42 2012 +0800

    cpuidle / ACPI: fix potential NULL pointer dereference
    
    The dereference should be moved below the NULL test.
    
    dpatch engine is used to auto generate this patch.
    (https://github.com/weiyj/dpatch)
    
    Signed-off-by: Wei Yongjun <yongjun_wei@trendmicro.com.cn>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 3655ab923812..e8086c725305 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1132,7 +1132,7 @@ static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
 int acpi_processor_hotplug(struct acpi_processor *pr)
 {
 	int ret = 0;
-	struct cpuidle_device *dev = per_cpu(acpi_cpuidle_device, pr->id);
+	struct cpuidle_device *dev;
 
 	if (disabled_by_idle_boot_param())
 		return 0;
@@ -1147,6 +1147,7 @@ int acpi_processor_hotplug(struct acpi_processor *pr)
 	if (!pr->flags.power_setup_done)
 		return -ENODEV;
 
+	dev = per_cpu(acpi_cpuidle_device, pr->id);
 	cpuidle_pause_and_lock();
 	cpuidle_disable_device(dev);
 	acpi_processor_get_power_info(pr);

commit 3d339dcbb56d8d70c1b959aff87d74adc3a84eea
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Mon Sep 17 23:01:56 2012 +0200

    cpuidle / ACPI : move cpuidle_device field out of the acpi_processor_power structure
    
    Currently we have the cpuidle_device field in the acpi_processor_power structure.
    This adds a dependency between processor.h and cpuidle.h
    
    Although it is not a real problem, removing this dependency has the benefit of
    separating a bit more the cpuidle code from the rest of the acpi code.
    Also, the compilation should be a bit improved because we do no longer
    include cpuidle.h in processor.h. The preprocessor was generating 30418 loc
    and with this patch it generates 30256 loc for processor_thermal.c, a file
    which is not concerned at all by cpuidle, like processor_perflib.c and
    processor_throttling.c.
    
    That may sound ridiculous, but "small streams make big rivers" :P
    
    This patch moves this field into a static global per cpu variable like what is
    done in the intel_idle driver.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index c46a44a8c860..3655ab923812 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -79,6 +79,8 @@ module_param(bm_check_disable, uint, 0000);
 static unsigned int latency_factor __read_mostly = 2;
 module_param(latency_factor, uint, 0644);
 
+static DEFINE_PER_CPU(struct cpuidle_device *, acpi_cpuidle_device);
+
 static int disabled_by_idle_boot_param(void)
 {
 	return boot_option_idle_override == IDLE_POLL ||
@@ -998,7 +1000,7 @@ static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr)
 	int i, count = CPUIDLE_DRIVER_STATE_START;
 	struct acpi_processor_cx *cx;
 	struct cpuidle_state_usage *state_usage;
-	struct cpuidle_device *dev = &pr->power.dev;
+	struct cpuidle_device *dev = per_cpu(acpi_cpuidle_device, pr->id);
 
 	if (!pr->flags.power_setup_done)
 		return -EINVAL;
@@ -1130,6 +1132,7 @@ static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
 int acpi_processor_hotplug(struct acpi_processor *pr)
 {
 	int ret = 0;
+	struct cpuidle_device *dev = per_cpu(acpi_cpuidle_device, pr->id);
 
 	if (disabled_by_idle_boot_param())
 		return 0;
@@ -1145,11 +1148,11 @@ int acpi_processor_hotplug(struct acpi_processor *pr)
 		return -ENODEV;
 
 	cpuidle_pause_and_lock();
-	cpuidle_disable_device(&pr->power.dev);
+	cpuidle_disable_device(dev);
 	acpi_processor_get_power_info(pr);
 	if (pr->flags.power) {
 		acpi_processor_setup_cpuidle_cx(pr);
-		ret = cpuidle_enable_device(&pr->power.dev);
+		ret = cpuidle_enable_device(dev);
 	}
 	cpuidle_resume_and_unlock();
 
@@ -1160,6 +1163,7 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 {
 	int cpu;
 	struct acpi_processor *_pr;
+	struct cpuidle_device *dev;
 
 	if (disabled_by_idle_boot_param())
 		return 0;
@@ -1190,7 +1194,8 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 			_pr = per_cpu(processors, cpu);
 			if (!_pr || !_pr->flags.power_setup_done)
 				continue;
-			cpuidle_disable_device(&_pr->power.dev);
+			dev = per_cpu(acpi_cpuidle_device, cpu);
+			cpuidle_disable_device(dev);
 		}
 
 		/* Populate Updated C-state information */
@@ -1204,7 +1209,8 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 			acpi_processor_get_power_info(_pr);
 			if (_pr->flags.power) {
 				acpi_processor_setup_cpuidle_cx(_pr);
-				cpuidle_enable_device(&_pr->power.dev);
+				dev = per_cpu(acpi_cpuidle_device, cpu);
+				cpuidle_enable_device(dev);
 			}
 		}
 		put_online_cpus();
@@ -1220,6 +1226,7 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr)
 {
 	acpi_status status = 0;
 	int retval;
+	struct cpuidle_device *dev;
 	static int first_run;
 
 	if (disabled_by_idle_boot_param())
@@ -1265,11 +1272,18 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr)
 			printk(KERN_DEBUG "ACPI: %s registered with cpuidle\n",
 					acpi_idle_driver.name);
 		}
+
+		dev = kzalloc(sizeof(*dev), GFP_KERNEL);
+		if (!dev)
+			return -ENOMEM;
+		per_cpu(acpi_cpuidle_device, pr->id) = dev;
+
+		acpi_processor_setup_cpuidle_cx(pr);
+
 		/* Register per-cpu cpuidle_device. Cpuidle driver
 		 * must already be registered before registering device
 		 */
-		acpi_processor_setup_cpuidle_cx(pr);
-		retval = cpuidle_register_device(&pr->power.dev);
+		retval = cpuidle_register_device(dev);
 		if (retval) {
 			if (acpi_processor_registered == 0)
 				cpuidle_unregister_driver(&acpi_idle_driver);
@@ -1282,11 +1296,13 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr)
 
 int acpi_processor_power_exit(struct acpi_processor *pr)
 {
+	struct cpuidle_device *dev = per_cpu(acpi_cpuidle_device, pr->id);
+
 	if (disabled_by_idle_boot_param())
 		return 0;
 
 	if (pr->flags.power) {
-		cpuidle_unregister_device(&pr->power.dev);
+		cpuidle_unregister_device(dev);
 		acpi_processor_registered--;
 		if (acpi_processor_registered == 0)
 			cpuidle_unregister_driver(&acpi_idle_driver);

commit 38a991b625ae3898f18149f8fa287338647a4c9f
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Sat Sep 15 22:42:54 2012 +0200

    ACPI / processor: remove unused function parameter
    
    The 'device' parameter is not used neither in acpi_processor_power_init
    and acpi_processor_power_exit. This patch removes it.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index de896242d144..c46a44a8c860 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1216,8 +1216,7 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 
 static int acpi_processor_registered;
 
-int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
-			      struct acpi_device *device)
+int __cpuinit acpi_processor_power_init(struct acpi_processor *pr)
 {
 	acpi_status status = 0;
 	int retval;
@@ -1281,8 +1280,7 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 	return 0;
 }
 
-int acpi_processor_power_exit(struct acpi_processor *pr,
-			      struct acpi_device *device)
+int acpi_processor_power_exit(struct acpi_processor *pr)
 {
 	if (disabled_by_idle_boot_param())
 		return 0;

commit c59687f8466df36633d937cc298aad465d704990
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Wed Sep 5 15:13:48 2012 +0200

    cpuidle / ACPI : remove power from acpi_processor_cx structure
    
    Remove the unused power field from struct struct acpi_processor_cx.
    
    [rjw: Modified changelog.]
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index ad3730b4038b..de896242d144 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -483,8 +483,6 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 		if (obj->type != ACPI_TYPE_INTEGER)
 			continue;
 
-		cx.power = obj->integer.value;
-
 		current_count++;
 		memcpy(&(pr->power.states[current_count]), &cx, sizeof(cx));
 

commit 476525004ac7e2f990b6956efcd44d0780c2ab4c
Merge: bd22dc17e499 ec033d0a0290
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 26 14:28:55 2012 -0700

    Merge branch 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux
    
    Pull ACPI & power management update from Len Brown:
     "Re-write of the turbostat tool.
         lower overhead was necessary for measuring very large system when
         they are very idle.
    
      IVB support in intel_idle
         It's what I run on my IVB, others should be able to also:-)
    
      ACPICA core update
         We have found some bugs due to divergence between Linux and the
         upstream ACPICA base.  Most of these patches are to reduce that
         divergence to reduce the risk of future bugs.
    
      Some cpuidle updates, mostly for non-Intel
         More will be coming, as they depend on this part.
    
      Some thermal management changes needed by non-ACPI systems.
    
      Some _OST (OS Status Indication) updates for hot ACPI hot-plug."
    
    * 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux: (51 commits)
      Thermal: Documentation update
      Thermal: Add Hysteresis attributes
      Thermal: Make Thermal trip points writeable
      ACPI/AC: prevent OOPS on some boxes due to missing check power_supply_register() return value check
      tools/power: turbostat: fix large c1% issue
      tools/power: turbostat v2 - re-write for efficiency
      ACPICA: Update to version 20120711
      ACPICA: AcpiSrc: Fix some translation issues for Linux conversion
      ACPICA: Update header files copyrights to 2012
      ACPICA: Add new ACPI table load/unload external interfaces
      ACPICA: Split file: tbxface.c -> tbxfload.c
      ACPICA: Add PCC address space to space ID decode function
      ACPICA: Fix some comment fields
      ACPICA: Table manager: deploy new firmware error/warning interfaces
      ACPICA: Add new interfaces for BIOS(firmware) errors and warnings
      ACPICA: Split exception code utilities to a new file, utexcep.c
      ACPI: acpi_pad: tune round_robin_time
      ACPICA: Update to version 20120620
      ACPICA: Add support for implicit notify on multiple devices
      ACPICA: Update comments; no functional change
      ...

commit ec033d0a02901551346b9f43f8ff9bad51378891
Merge: fa7584e13ac8 819f1a64beb6 f712c71f7b2b a58e1150225c 20ff51a36b2c 1b0a0e9a15b9 6edab08c24f9 c2f4191a9c4d f197ac13f6ee 8eaa8d6ca277 b9c7aff481f1 c3ae331d1c2f
Author: Len Brown <len.brown@intel.com>
Date:   Thu Jul 26 00:03:58 2012 -0400

    Merge branches 'acpi_pad', 'acpica', 'apei-bugzilla-43282', 'battery', 'cpuidle-coupled', 'cpuidle-tweaks', 'intel_idle-ivb', 'ost', 'red-hat-bz-772730', 'thermal', 'thermal-spear' and 'turbostat-v2' into release

commit 6148d38b37ce9468cdf5a37ca49b4ac5c091e8fa
Merge: d52fdf13377c 18468843fac3
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Thu Jul 19 00:03:35 2012 +0200

    Merge branch 'pm-acpi'
    
    * pm-acpi: (24 commits)
      olpc-xo15-sci: Use struct dev_pm_ops for power management
      ACPI / PM: Drop PM callbacks from the ACPI bus type
      ACPI / PM: Drop legacy driver PM callbacks that are not used any more
      ACPI / PM: Do not execute legacy driver PM callbacks
      acpi_power_meter: Use struct dev_pm_ops for power management
      fujitsu-tablet: Use struct dev_pm_ops for power management
      classmate-laptop: Use struct dev_pm_ops for power management
      xo15-ebook: Use struct dev_pm_ops for power management
      toshiba_bluetooth: Use struct dev_pm_ops for power management
      panasonic-laptop: Use struct dev_pm_ops for power management
      sony-laptop: Use struct dev_pm_ops for power management
      hp_accel: Use struct dev_pm_ops for power management
      toshiba_acpi: Use struct dev_pm_ops for power management
      ACPI: Use struct dev_pm_ops for power management in the SBS driver
      ACPI: Use struct dev_pm_ops for power management in the power driver
      ACPI: Use struct dev_pm_ops for power management in the button driver
      ACPI: Use struct dev_pm_ops for power management in the battery driver
      ACPI: Use struct dev_pm_ops for power management in the AC driver
      ACPI: Use struct dev_pm_ops for power management in processor driver
      ACPI: Use struct dev_pm_ops for power management in the thermal driver
      ...

commit aa713cc3b22ccd24dc55df4e0770490781fe6a76
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Tue Jul 17 22:16:04 2012 +0200

    cpuilde / ACPI: remove time from acpi_processor_cx structure
    
    Remove the time field as it is not used.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index f355f1a1c211..4cf964803d7a 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -863,7 +863,6 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 		current_thread_info()->status |= TS_POLLING;
 
 	lapic_timer_state_broadcast(pr, cx, 0);
-	cx->time += idle_time;
 	return index;
 }
 
@@ -982,7 +981,6 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		current_thread_info()->status |= TS_POLLING;
 
 	lapic_timer_state_broadcast(pr, cx, 0);
-	cx->time += idle_time;
 	return index;
 }
 

commit 53b70951d9ef68420775b69e59ba720cc15c2643
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Tue Jul 17 22:16:00 2012 +0200

    cpuidle / ACPI: remove usage from acpi_processor_cx structure
    
    Remove the usage field as it is not used.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index b0d2bbe59096..f355f1a1c211 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -760,7 +760,6 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 	dev->last_residency = (int)idle_time;
 
 	local_irq_enable();
-	cx->usage++;
 	lapic_timer_state_broadcast(pr, cx, 0);
 
 	return index;
@@ -863,8 +862,6 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	if (cx->entry_method != ACPI_CSTATE_FFH)
 		current_thread_info()->status |= TS_POLLING;
 
-	cx->usage++;
-
 	lapic_timer_state_broadcast(pr, cx, 0);
 	cx->time += idle_time;
 	return index;
@@ -984,8 +981,6 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	if (cx->entry_method != ACPI_CSTATE_FFH)
 		current_thread_info()->status |= TS_POLLING;
 
-	cx->usage++;
-
 	lapic_timer_state_broadcast(pr, cx, 0);
 	cx->time += idle_time;
 	return index;

commit 64d45f07b433090ee1329cf74989d973875028cb
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Tue Jul 17 22:15:24 2012 +0200

    cpuidle / ACPI : remove latency_ticks from acpi_processor_cx structure
    
    Remove the latency_ticks field as it is not used.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index d8366ee75716..b0d2bbe59096 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -583,7 +583,6 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 	 */
 	cx->valid = 1;
 
-	cx->latency_ticks = cx->latency;
 	/*
 	 * On older chipsets, BM_RLD needs to be set
 	 * in order for Bus Master activity to wake the
@@ -616,7 +615,6 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 			if (!cx->address)
 				break;
 			cx->valid = 1; 
-			cx->latency_ticks = cx->latency; /* Normalize latency */
 			break;
 
 		case ACPI_STATE_C3:

commit ba494beeaa69bc0fb01eb89464ad5d57d26e3901
Author: Bob Moore <robert.moore@intel.com>
Date:   Thu Jul 12 09:40:10 2012 +0800

    ACPICA: AcpiSrc: Fix some translation issues for Linux conversion
    
    Fixes issues like this:
    
    i_aSL -> iASL
    00-7_f -> 00-7F
    local_fADT -> local_FADT
    execute_oSI -> execute_OSI
    
    Also, in function headers, the parameters are now translated to
    lower case (with underscores if necessary.)
    
    Signed-off-by: Bob Moore <robert.moore@intel.com>
    Signed-off-by: Lin Ming <ming.m.lin@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index f3decb30223f..50faa93bb97b 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -304,16 +304,16 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 	pr->power.states[ACPI_STATE_C3].address = pr->pblk + 5;
 
 	/* determine latencies from FADT */
-	pr->power.states[ACPI_STATE_C2].latency = acpi_gbl_FADT.C2latency;
-	pr->power.states[ACPI_STATE_C3].latency = acpi_gbl_FADT.C3latency;
+	pr->power.states[ACPI_STATE_C2].latency = acpi_gbl_FADT.c2_latency;
+	pr->power.states[ACPI_STATE_C3].latency = acpi_gbl_FADT.c3_latency;
 
 	/*
 	 * FADT specified C2 latency must be less than or equal to
 	 * 100 microseconds.
 	 */
-	if (acpi_gbl_FADT.C2latency > ACPI_PROCESSOR_MAX_C2_LATENCY) {
+	if (acpi_gbl_FADT.c2_latency > ACPI_PROCESSOR_MAX_C2_LATENCY) {
 		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
-			"C2 latency too large [%d]\n", acpi_gbl_FADT.C2latency));
+			"C2 latency too large [%d]\n", acpi_gbl_FADT.c2_latency));
 		/* invalidate C2 */
 		pr->power.states[ACPI_STATE_C2].address = 0;
 	}
@@ -322,9 +322,9 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 	 * FADT supplied C3 latency must be less than or equal to
 	 * 1000 microseconds.
 	 */
-	if (acpi_gbl_FADT.C3latency > ACPI_PROCESSOR_MAX_C3_LATENCY) {
+	if (acpi_gbl_FADT.c3_latency > ACPI_PROCESSOR_MAX_C3_LATENCY) {
 		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
-			"C3 latency too large [%d]\n", acpi_gbl_FADT.C3latency));
+			"C3 latency too large [%d]\n", acpi_gbl_FADT.c3_latency));
 		/* invalidate C3 */
 		pr->power.states[ACPI_STATE_C3].address = 0;
 	}

commit 8651f97bd951d0bb1c10fa24e3fa3455193f3548
Author: Preeti U Murthy <preeti@linux.vnet.ibm.com>
Date:   Mon Jul 9 10:12:56 2012 +0200

    PM / cpuidle: System resume hang fix with cpuidle
    
    On certain bios, resume hangs if cpus are allowed to enter idle states
    during suspend [1].
    
    This was fixed in apci idle driver [2].But intel_idle driver does not
    have this fix. Thus instead of replicating the fix in both the idle
    drivers, or in more platform specific idle drivers if needed, the
    more general cpuidle infrastructure could handle this.
    
    A suspend callback in cpuidle_driver could handle this fix. But
    a cpuidle_driver provides only basic functionalities like platform idle
    state detection capability and mechanisms to support entry and exit
    into CPU idle states. All other cpuidle functions are found in the
    cpuidle generic infrastructure for good reason that all cpuidle
    drivers, irrepective of their platforms will support these functions.
    
    One option therefore would be to register a suspend callback in cpuidle
    which handles this fix. This could be called through a PM_SUSPEND_PREPARE
    notifier. But this is too generic a notfier for a driver to handle.
    
    Also, ideally the job of cpuidle is not to handle side effects of suspend.
    It should expose the interfaces which "handle cpuidle 'during' suspend"
    or any other operation, which the subsystems call during that respective
    operation.
    
    The fix demands that during suspend, no cpus should be allowed to enter
    deep C-states. The interface cpuidle_uninstall_idle_handler() in cpuidle
    ensures that. Not just that it also kicks all the cpus which are already
    in idle out of their idle states which was being done during cpu hotplug
    through a CPU_DYING_FROZEN callbacks.
    
    Now the question arises about when during suspend should
    cpuidle_uninstall_idle_handler() be called. Since we are dealing with
    drivers it seems best to call this function during dpm_suspend().
    Delaying the call till dpm_suspend_noirq() does no harm, as long as it is
    before cpu_hotplug_begin() to avoid race conditions with cpu hotpulg
    operations. In dpm_suspend_noirq(), it would be wise to place this call
    before suspend_device_irqs() to avoid ugly interactions with the same.
    
    Ananlogously, during resume.
    
    References:
    [1] https://bugs.launchpad.net/ubuntu/+source/linux/+bug/674075.
    [2] http://marc.info/?l=linux-pm&m=133958534231884&w=2
    
    Reported-and-tested-by: Dave Hansen <dave@linux.vnet.ibm.com>
    Signed-off-by: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Reviewed-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 47a8caa89dbe..d8366ee75716 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -221,10 +221,6 @@ static void lapic_timer_state_broadcast(struct acpi_processor *pr,
 
 #endif
 
-/*
- * Suspend / resume control
- */
-static int acpi_idle_suspend;
 static u32 saved_bm_rld;
 
 static void acpi_idle_bm_rld_save(void)
@@ -243,21 +239,13 @@ static void acpi_idle_bm_rld_restore(void)
 
 int acpi_processor_suspend(struct acpi_device * device, pm_message_t state)
 {
-	if (acpi_idle_suspend == 1)
-		return 0;
-
 	acpi_idle_bm_rld_save();
-	acpi_idle_suspend = 1;
 	return 0;
 }
 
 int acpi_processor_resume(struct acpi_device * device)
 {
-	if (acpi_idle_suspend == 0)
-		return 0;
-
 	acpi_idle_bm_rld_restore();
-	acpi_idle_suspend = 0;
 	return 0;
 }
 
@@ -763,11 +751,6 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 
 	local_irq_disable();
 
-	if (acpi_idle_suspend) {
-		local_irq_enable();
-		cpu_relax();
-		return -EBUSY;
-	}
 
 	lapic_timer_state_broadcast(pr, cx, 1);
 	kt1 = ktime_get_real();
@@ -838,11 +821,6 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 
 	local_irq_disable();
 
-	if (acpi_idle_suspend) {
-		local_irq_enable();
-		cpu_relax();
-		return -EBUSY;
-	}
 
 	if (cx->entry_method != ACPI_CSTATE_FFH) {
 		current_thread_info()->status &= ~TS_POLLING;
@@ -928,8 +906,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 						drv, drv->safe_state_index);
 		} else {
 			local_irq_disable();
-			if (!acpi_idle_suspend)
-				acpi_safe_halt();
+			acpi_safe_halt();
 			local_irq_enable();
 			return -EBUSY;
 		}
@@ -937,11 +914,6 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 
 	local_irq_disable();
 
-	if (acpi_idle_suspend) {
-		local_irq_enable();
-		cpu_relax();
-		return -EBUSY;
-	}
 
 	if (cx->entry_method != ACPI_CSTATE_FFH) {
 		current_thread_info()->status &= ~TS_POLLING;

commit e8110b64af8b7cce96d1878276770c76cb9c01d5
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Wed Jun 27 23:26:26 2012 +0200

    ACPI: Use struct dev_pm_ops for power management in processor driver
    
    Make the ACPI processor driver define its PM callbacks through
    a struct dev_pm_ops object rather than by using legacy PM hooks
    in struct acpi_device_ops.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index e28af8d38239..6d9ec3e0b52e 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -241,7 +241,7 @@ static void acpi_idle_bm_rld_restore(void)
 		acpi_write_bit_register(ACPI_BITREG_BUS_MASTER_RLD, saved_bm_rld);
 }
 
-int acpi_processor_suspend(struct acpi_device * device)
+int acpi_processor_suspend(struct device *dev)
 {
 	if (acpi_idle_suspend == 1)
 		return 0;
@@ -251,7 +251,7 @@ int acpi_processor_suspend(struct acpi_device * device)
 	return 0;
 }
 
-int acpi_processor_resume(struct acpi_device * device)
+int acpi_processor_resume(struct device *dev)
 {
 	if (acpi_idle_suspend == 0)
 		return 0;

commit 17621e11fda095459e2f986c019f52686c7a4ffb
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Wed Jun 27 23:25:38 2012 +0200

    ACPI / PM: Drop pm_message_t argument from device suspend callback
    
    None of the drivers implementing the ACPI device suspend callback
    uses the pm_message_t argument of it, so this argument may be dropped
    entirely from that callback.  This will simplify switching the ACPI
    bus type to PM handling based on struct dev_pm_ops.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 47a8caa89dbe..e28af8d38239 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -241,7 +241,7 @@ static void acpi_idle_bm_rld_restore(void)
 		acpi_write_bit_register(ACPI_BITREG_BUS_MASTER_RLD, saved_bm_rld);
 }
 
-int acpi_processor_suspend(struct acpi_device * device, pm_message_t state)
+int acpi_processor_suspend(struct acpi_device * device)
 {
 	if (acpi_idle_suspend == 1)
 		return 0;

commit 75cc52358799bd6001e7d1a47847f997f5ae99f0
Author: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
Date:   Mon Jun 25 23:59:54 2012 +0200

    PM / ACPI: Fix suspend/resume regression caused by cpuidle cleanup.
    
    Commit e978aa7d7d57d04eb5f88a7507c4fb98577def77 ( cpuidle: Move
    dev->last_residency update to driver enter routine; remove dev->last_state)
    was  breaking suspend on laptops, as reported in the below link
            - https://lkml.org/lkml/2011/11/11/164
    
    This was fixed in commit 3439a8da16bcad6b0982ece938c9f8299bb53584
    (ACPI / cpuidle: Remove acpi_idle_suspend (to fix suspend regression)
    by removing acpi_idle_suspend flag.
            - https://lkml.org/lkml/2011/11/14/74
    
    But this did fix did not work on all systems
    as Suspend/resume regression was reported on Lenovo S10-3
    recently by Dave.
            - https://lkml.org/lkml/2012/5/27/115
    It looked like with commit e978aa7d broke suspend and
    with commit 3439a8da resume was not working with acpi_idle driver.
    
    This patch fixes the regression that caused this issue
    in the first place. acpi_idle_suspend flag is essential on
    some x86 systems to prevent the cpus from going to deeper C-states
    when suspend is triggered ( commit b04e7bdb984 )
    So reverting the commit 3439a8da is essential.
    
    By default, irqs are disabled in cpu_idle arch specific call
    and re-enabled in idle state return path . During suspend,
    the acpi_idle_suspend flag is set, which
    prevents the cpus from going to deeper idle states,
    it is essential to enabling the irqs in this return path too.
    
    To address the suspend issue,
    we were not re-enabling the interrupts while returning from
    acpi_idle_enter_bm() routine if acpi_idle_suspend flag is set.
    and this caused suspend failure.
    
    In addition to the above, to improve the readability of the code,
    return of -ENIVAL is replaced with -EBUSY in acpi_idle_suspend
    return path. Implying that the system is currently busy when suspend
    is in progress, which prevents the cpus from entering deeper C-states.
    
    Reported-and-Tested-by: Dav Hansen <dave@linux.vnet.ibm.com>
    Tested-by: Preeti Murthy <preeti@linux.vnet.ibm.com>
    Signed-off-by: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Reviewed-by: Srivatsa S Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index f3decb30223f..47a8caa89dbe 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -224,6 +224,7 @@ static void lapic_timer_state_broadcast(struct acpi_processor *pr,
 /*
  * Suspend / resume control
  */
+static int acpi_idle_suspend;
 static u32 saved_bm_rld;
 
 static void acpi_idle_bm_rld_save(void)
@@ -242,13 +243,21 @@ static void acpi_idle_bm_rld_restore(void)
 
 int acpi_processor_suspend(struct acpi_device * device, pm_message_t state)
 {
+	if (acpi_idle_suspend == 1)
+		return 0;
+
 	acpi_idle_bm_rld_save();
+	acpi_idle_suspend = 1;
 	return 0;
 }
 
 int acpi_processor_resume(struct acpi_device * device)
 {
+	if (acpi_idle_suspend == 0)
+		return 0;
+
 	acpi_idle_bm_rld_restore();
+	acpi_idle_suspend = 0;
 	return 0;
 }
 
@@ -754,6 +763,12 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 
 	local_irq_disable();
 
+	if (acpi_idle_suspend) {
+		local_irq_enable();
+		cpu_relax();
+		return -EBUSY;
+	}
+
 	lapic_timer_state_broadcast(pr, cx, 1);
 	kt1 = ktime_get_real();
 	acpi_idle_do_entry(cx);
@@ -823,6 +838,12 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 
 	local_irq_disable();
 
+	if (acpi_idle_suspend) {
+		local_irq_enable();
+		cpu_relax();
+		return -EBUSY;
+	}
+
 	if (cx->entry_method != ACPI_CSTATE_FFH) {
 		current_thread_info()->status &= ~TS_POLLING;
 		/*
@@ -907,14 +928,21 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 						drv, drv->safe_state_index);
 		} else {
 			local_irq_disable();
-			acpi_safe_halt();
+			if (!acpi_idle_suspend)
+				acpi_safe_halt();
 			local_irq_enable();
-			return -EINVAL;
+			return -EBUSY;
 		}
 	}
 
 	local_irq_disable();
 
+	if (acpi_idle_suspend) {
+		local_irq_enable();
+		cpu_relax();
+		return -EBUSY;
+	}
+
 	if (cx->entry_method != ACPI_CSTATE_FFH) {
 		current_thread_info()->status &= ~TS_POLLING;
 		/*

commit eeaab2d8af2cf1d36d7086f22e9de42d6dd2995c
Merge: ee01e6633733 aaef292acf3a
Author: Len Brown <len.brown@intel.com>
Date:   Fri Apr 6 21:48:59 2012 -0400

    Merge branches 'idle-fix' and 'misc' into release

commit 54f70077768e9aba37d9c5030b43497b6d5084fb
Author: Luck, Tony <tony.luck@intel.com>
Date:   Tue Apr 3 09:37:28 2012 -0700

    ACPI processor: Use safe_halt() rather than halt() in acpi_idle_play_dead()
    
    ACPI code is shared by arch/x86 and arch/ia64. ia64 doesn't provide a plain
    "halt()" function.  Use safe_halt() instead.
    
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Tested-by: Boris Ostrovsky <boris.ostrovsky@amd.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 6b1d32a161ae..784f9a7beb17 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -786,7 +786,7 @@ static int acpi_idle_play_dead(struct cpuidle_device *dev, int index)
 	while (1) {
 
 		if (cx->entry_method == ACPI_CSTATE_HALT)
-			halt();
+			safe_halt();
 		else if (cx->entry_method == ACPI_CSTATE_SYSTEMIO) {
 			inb(cx->address);
 			/* See comment in acpi_idle_do_entry() */

commit 1a05e4678724c4a5fe7b9e4e208b616dfe8c3a32
Merge: 5aa3c16c6b19 d1ff4b1cdbab cf450136bfde 02401c06b7f6 6fe0d0628245 9f324bda970c 372399787788 3e80acd1af40 344e222edf48 2815ab92ba3a 15aaa3465483 b60e7f616685
Author: Len Brown <len.brown@intel.com>
Date:   Fri Mar 30 16:10:37 2012 -0400

    Merge branches 'acpica', 'bgrt', 'bz-11533', 'cpuidle', 'ec', 'hotplug', 'misc', 'red-hat-bz-727865', 'thermal', 'throttling', 'turbostat' and 'video' into release
    
    Signed-off-by: Len Brown <len.brown@intel.com>

commit 9505626d7bfeb5bd4b85acb483831ac640b2a5e8
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Feb 28 13:27:44 2012 -0800

    ACPI: Fix unprotected smp_processor_id() in acpi_processor_cst_has_changed()
    
    The acpi_processor_cst_has_changed() function is invoked from a
    CPU_ONLINE or CPU_DEAD function, which might well execute on CPU 0
    even though the CPU being hotplugged is some other CPU.  In addition,
    acpi_processor_cst_has_changed() invokes smp_processor_id() without
    protection, resulting in splats when onlining CPUs.
    
    This commit therefore changes the smp_processor_id() to pr->id, as is
    used elsewhere in the code, for example, in acpi_processor_add().
    
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Tested-by: Yong Zhang <yong.zhang0@gmail.com>
    Acked-by: Rafael J. Wysocki <rjw@sisk.pl>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 0e8e2de2ed3e..9e57b06d1f24 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1159,8 +1159,7 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 	 * to make the code that updates C-States be called once.
 	 */
 
-	if (smp_processor_id() == 0 &&
-			cpuidle_get_driver() == &acpi_idle_driver) {
+	if (pr->id == 0 && cpuidle_get_driver() == &acpi_idle_driver) {
 
 		cpuidle_pause_and_lock();
 		/* Protect against cpu-hotplug */

commit 1a022e3f1be11730bd8747b1af96a0274bf6356e
Author: Boris Ostrovsky <boris.ostrovsky@amd.com>
Date:   Tue Mar 13 19:55:09 2012 +0100

    idle, x86: Allow off-lined CPU to enter deeper C states
    
    Currently when a CPU is off-lined it enters either MWAIT-based idle or,
    if MWAIT is not desired or supported, HLT-based idle (which places the
    processor in C1 state). This patch allows processors without MWAIT
    support to stay in states deeper than C1.
    
    Signed-off-by: Boris Ostrovsky <boris.ostrovsky@amd.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 0e8e2de2ed3e..6b1d32a161ae 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -770,6 +770,35 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 	return index;
 }
 
+
+/**
+ * acpi_idle_play_dead - enters an ACPI state for long-term idle (i.e. off-lining)
+ * @dev: the target CPU
+ * @index: the index of suggested state
+ */
+static int acpi_idle_play_dead(struct cpuidle_device *dev, int index)
+{
+	struct cpuidle_state_usage *state_usage = &dev->states_usage[index];
+	struct acpi_processor_cx *cx = cpuidle_get_statedata(state_usage);
+
+	ACPI_FLUSH_CPU_CACHE();
+
+	while (1) {
+
+		if (cx->entry_method == ACPI_CSTATE_HALT)
+			halt();
+		else if (cx->entry_method == ACPI_CSTATE_SYSTEMIO) {
+			inb(cx->address);
+			/* See comment in acpi_idle_do_entry() */
+			inl(acpi_gbl_FADT.xpm_timer_block.address);
+		} else
+			return -ENODEV;
+	}
+
+	/* Never reached */
+	return 0;
+}
+
 /**
  * acpi_idle_enter_simple - enters an ACPI state without BM handling
  * @dev: the target CPU
@@ -1077,12 +1106,14 @@ static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
 				state->flags |= CPUIDLE_FLAG_TIME_VALID;
 
 			state->enter = acpi_idle_enter_c1;
+			state->enter_dead = acpi_idle_play_dead;
 			drv->safe_state_index = count;
 			break;
 
 			case ACPI_STATE_C2:
 			state->flags |= CPUIDLE_FLAG_TIME_VALID;
 			state->enter = acpi_idle_enter_simple;
+			state->enter_dead = acpi_idle_play_dead;
 			drv->safe_state_index = count;
 			break;
 

commit 3439a8da16bcad6b0982ece938c9f8299bb53584
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Sat Nov 12 23:17:27 2011 +0100

    ACPI / cpuidle: Remove acpi_idle_suspend (to fix suspend regression)
    
    After commit e978aa7d7d57 ("cpuidle: Move dev->last_residency update to
    driver enter routine; remove dev->last_state") setting acpi_idle_suspend
    to 1 by acpi_processor_suspend() causes the ACPI cpuidle routines to
    return error codes continuously, which in turn causes cpuidle to lock up
    (hard).
    
    However, acpi_idle_suspend doesn't appear to be useful for any
    particular purpose (it's racy and doesn't really provide any real
    protection), so it can be removed, which makes the problem go away.
    
    Reported-and-tested-by: Tomas M. <tmezzadra@gmail.com>
    Reported-and-tested-by: Ferenc Wagner <wferi@niif.hu>
    Tested-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 73b2909dddfe..0e8e2de2ed3e 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -224,7 +224,6 @@ static void lapic_timer_state_broadcast(struct acpi_processor *pr,
 /*
  * Suspend / resume control
  */
-static int acpi_idle_suspend;
 static u32 saved_bm_rld;
 
 static void acpi_idle_bm_rld_save(void)
@@ -243,21 +242,13 @@ static void acpi_idle_bm_rld_restore(void)
 
 int acpi_processor_suspend(struct acpi_device * device, pm_message_t state)
 {
-	if (acpi_idle_suspend == 1)
-		return 0;
-
 	acpi_idle_bm_rld_save();
-	acpi_idle_suspend = 1;
 	return 0;
 }
 
 int acpi_processor_resume(struct acpi_device * device)
 {
-	if (acpi_idle_suspend == 0)
-		return 0;
-
 	acpi_idle_bm_rld_restore();
-	acpi_idle_suspend = 0;
 	return 0;
 }
 
@@ -763,13 +754,6 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 
 	local_irq_disable();
 
-	/* Do not access any ACPI IO ports in suspend path */
-	if (acpi_idle_suspend) {
-		local_irq_enable();
-		cpu_relax();
-		return -EINVAL;
-	}
-
 	lapic_timer_state_broadcast(pr, cx, 1);
 	kt1 = ktime_get_real();
 	acpi_idle_do_entry(cx);
@@ -810,13 +794,6 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 
 	local_irq_disable();
 
-	if (acpi_idle_suspend) {
-		local_irq_enable();
-		cpu_relax();
-		return -EINVAL;
-	}
-
-
 	if (cx->entry_method != ACPI_CSTATE_FFH) {
 		current_thread_info()->status &= ~TS_POLLING;
 		/*
@@ -895,12 +872,6 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	if (unlikely(!pr))
 		return -EINVAL;
 
-
-	if (acpi_idle_suspend) {
-		cpu_relax();
-		return -EINVAL;
-	}
-
 	if (!cx->bm_sts_skip && acpi_idle_bm_check()) {
 		if (drv->safe_state_index >= 0) {
 			return drv->states[drv->safe_state_index].enter(dev,

commit 3c00303206c3a1ccd86579efdc90bc35f140962e
Merge: 83dbb15e9cd7 efb90582c575
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 7 10:13:52 2011 -0800

    Merge branch 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux
    
    * 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux:
      cpuidle: Single/Global registration of idle states
      cpuidle: Split cpuidle_state structure and move per-cpu statistics fields
      cpuidle: Remove CPUIDLE_FLAG_IGNORE and dev->prepare()
      cpuidle: Move dev->last_residency update to driver enter routine; remove dev->last_state
      ACPI: Fix CONFIG_ACPI_DOCK=n compiler warning
      ACPI: Export FADT pm_profile integer value to userspace
      thermal: Prevent polling from happening during system suspend
      ACPI: Drop ACPI_NO_HARDWARE_INIT
      ACPI atomicio: Convert width in bits to bytes in __acpi_ioremap_fast()
      PNPACPI: Simplify disabled resource registration
      ACPI: Fix possible recursive locking in hwregs.c
      ACPI: use kstrdup()
      mrst pmu: update comment
      tools/power turbostat: less verbose debugging

commit 46bcfad7a819bd17ac4e831b04405152d59784ab
Author: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
Date:   Fri Oct 28 16:20:42 2011 +0530

    cpuidle: Single/Global registration of idle states
    
    This patch makes the cpuidle_states structure global (single copy)
    instead of per-cpu. The statistics needed on per-cpu basis
    by the governor are kept per-cpu. This simplifies the cpuidle
    subsystem as state registration is done by single cpu only.
    Having single copy of cpuidle_states saves memory. Rare case
    of asymmetric C-states can be handled within the cpuidle driver
    and architectures such as POWER do not have asymmetric C-states.
    
    Having single/global registration of all the idle states,
    dynamic C-state transitions on x86 are handled by
    the boot cpu. Here, the boot cpu  would disable all the devices,
    re-populate the states and later enable all the devices,
    irrespective of the cpu that would receive the notification first.
    
    Reference:
    https://lkml.org/lkml/2011/4/25/83
    
    Signed-off-by: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Signed-off-by: Trinabh Gupta <g.trinabh@gmail.com>
    Tested-by: Jean Pihet <j-pihet@ti.com>
    Reviewed-by: Kevin Hilman <khilman@ti.com>
    Acked-by: Arjan van de Ven <arjan@linux.intel.com>
    Acked-by: Kevin Hilman <khilman@ti.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index b98c75285690..24fe3afa7119 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -741,11 +741,13 @@ static inline void acpi_idle_do_entry(struct acpi_processor_cx *cx)
 /**
  * acpi_idle_enter_c1 - enters an ACPI C1 state-type
  * @dev: the target CPU
+ * @drv: cpuidle driver containing cpuidle state info
  * @index: index of target state
  *
  * This is equivalent to the HALT instruction.
  */
-static int acpi_idle_enter_c1(struct cpuidle_device *dev, int index)
+static int acpi_idle_enter_c1(struct cpuidle_device *dev,
+		struct cpuidle_driver *drv, int index)
 {
 	ktime_t  kt1, kt2;
 	s64 idle_time;
@@ -787,9 +789,11 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev, int index)
 /**
  * acpi_idle_enter_simple - enters an ACPI state without BM handling
  * @dev: the target CPU
+ * @drv: cpuidle driver with cpuidle state information
  * @index: the index of suggested state
  */
-static int acpi_idle_enter_simple(struct cpuidle_device *dev, int index)
+static int acpi_idle_enter_simple(struct cpuidle_device *dev,
+		struct cpuidle_driver *drv, int index)
 {
 	struct acpi_processor *pr;
 	struct cpuidle_state_usage *state_usage = &dev->states_usage[index];
@@ -869,11 +873,13 @@ static DEFINE_SPINLOCK(c3_lock);
 /**
  * acpi_idle_enter_bm - enters C3 with proper BM handling
  * @dev: the target CPU
+ * @drv: cpuidle driver containing state data
  * @index: the index of suggested state
  *
  * If BM is detected, the deepest non-C3 idle state is entered instead.
  */
-static int acpi_idle_enter_bm(struct cpuidle_device *dev, int index)
+static int acpi_idle_enter_bm(struct cpuidle_device *dev,
+		struct cpuidle_driver *drv, int index)
 {
 	struct acpi_processor *pr;
 	struct cpuidle_state_usage *state_usage = &dev->states_usage[index];
@@ -896,9 +902,9 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev, int index)
 	}
 
 	if (!cx->bm_sts_skip && acpi_idle_bm_check()) {
-		if (dev->safe_state_index >= 0) {
-			return dev->states[dev->safe_state_index].enter(dev,
-						dev->safe_state_index);
+		if (drv->safe_state_index >= 0) {
+			return drv->states[drv->safe_state_index].enter(dev,
+						drv, drv->safe_state_index);
 		} else {
 			local_irq_disable();
 			acpi_safe_halt();
@@ -993,14 +999,15 @@ struct cpuidle_driver acpi_idle_driver = {
 };
 
 /**
- * acpi_processor_setup_cpuidle - prepares and configures CPUIDLE
+ * acpi_processor_setup_cpuidle_cx - prepares and configures CPUIDLE
+ * device i.e. per-cpu data
+ *
  * @pr: the ACPI processor
  */
-static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
+static int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr)
 {
 	int i, count = CPUIDLE_DRIVER_STATE_START;
 	struct acpi_processor_cx *cx;
-	struct cpuidle_state *state;
 	struct cpuidle_state_usage *state_usage;
 	struct cpuidle_device *dev = &pr->power.dev;
 
@@ -1012,18 +1019,12 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 	}
 
 	dev->cpu = pr->id;
-	dev->safe_state_index = -1;
-	for (i = 0; i < CPUIDLE_STATE_MAX; i++) {
-		dev->states[i].name[0] = '\0';
-		dev->states[i].desc[0] = '\0';
-	}
 
 	if (max_cstate == 0)
 		max_cstate = 1;
 
 	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {
 		cx = &pr->power.states[i];
-		state = &dev->states[count];
 		state_usage = &dev->states_usage[count];
 
 		if (!cx->valid)
@@ -1035,8 +1036,64 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 		    !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
 			continue;
 #endif
+
 		cpuidle_set_statedata(state_usage, cx);
 
+		count++;
+		if (count == CPUIDLE_STATE_MAX)
+			break;
+	}
+
+	dev->state_count = count;
+
+	if (!count)
+		return -EINVAL;
+
+	return 0;
+}
+
+/**
+ * acpi_processor_setup_cpuidle states- prepares and configures cpuidle
+ * global state data i.e. idle routines
+ *
+ * @pr: the ACPI processor
+ */
+static int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)
+{
+	int i, count = CPUIDLE_DRIVER_STATE_START;
+	struct acpi_processor_cx *cx;
+	struct cpuidle_state *state;
+	struct cpuidle_driver *drv = &acpi_idle_driver;
+
+	if (!pr->flags.power_setup_done)
+		return -EINVAL;
+
+	if (pr->flags.power == 0)
+		return -EINVAL;
+
+	drv->safe_state_index = -1;
+	for (i = 0; i < CPUIDLE_STATE_MAX; i++) {
+		drv->states[i].name[0] = '\0';
+		drv->states[i].desc[0] = '\0';
+	}
+
+	if (max_cstate == 0)
+		max_cstate = 1;
+
+	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {
+		cx = &pr->power.states[i];
+
+		if (!cx->valid)
+			continue;
+
+#ifdef CONFIG_HOTPLUG_CPU
+		if ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) &&
+		    !pr->flags.has_cst &&
+		    !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
+			continue;
+#endif
+
+		state = &drv->states[count];
 		snprintf(state->name, CPUIDLE_NAME_LEN, "C%d", i);
 		strncpy(state->desc, cx->desc, CPUIDLE_DESC_LEN);
 		state->exit_latency = cx->latency;
@@ -1049,13 +1106,13 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 				state->flags |= CPUIDLE_FLAG_TIME_VALID;
 
 			state->enter = acpi_idle_enter_c1;
-			dev->safe_state_index = count;
+			drv->safe_state_index = count;
 			break;
 
 			case ACPI_STATE_C2:
 			state->flags |= CPUIDLE_FLAG_TIME_VALID;
 			state->enter = acpi_idle_enter_simple;
-			dev->safe_state_index = count;
+			drv->safe_state_index = count;
 			break;
 
 			case ACPI_STATE_C3:
@@ -1071,7 +1128,7 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 			break;
 	}
 
-	dev->state_count = count;
+	drv->state_count = count;
 
 	if (!count)
 		return -EINVAL;
@@ -1079,7 +1136,7 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 	return 0;
 }
 
-int acpi_processor_cst_has_changed(struct acpi_processor *pr)
+int acpi_processor_hotplug(struct acpi_processor *pr)
 {
 	int ret = 0;
 
@@ -1100,7 +1157,7 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 	cpuidle_disable_device(&pr->power.dev);
 	acpi_processor_get_power_info(pr);
 	if (pr->flags.power) {
-		acpi_processor_setup_cpuidle(pr);
+		acpi_processor_setup_cpuidle_cx(pr);
 		ret = cpuidle_enable_device(&pr->power.dev);
 	}
 	cpuidle_resume_and_unlock();
@@ -1108,10 +1165,72 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 	return ret;
 }
 
+int acpi_processor_cst_has_changed(struct acpi_processor *pr)
+{
+	int cpu;
+	struct acpi_processor *_pr;
+
+	if (disabled_by_idle_boot_param())
+		return 0;
+
+	if (!pr)
+		return -EINVAL;
+
+	if (nocst)
+		return -ENODEV;
+
+	if (!pr->flags.power_setup_done)
+		return -ENODEV;
+
+	/*
+	 * FIXME:  Design the ACPI notification to make it once per
+	 * system instead of once per-cpu.  This condition is a hack
+	 * to make the code that updates C-States be called once.
+	 */
+
+	if (smp_processor_id() == 0 &&
+			cpuidle_get_driver() == &acpi_idle_driver) {
+
+		cpuidle_pause_and_lock();
+		/* Protect against cpu-hotplug */
+		get_online_cpus();
+
+		/* Disable all cpuidle devices */
+		for_each_online_cpu(cpu) {
+			_pr = per_cpu(processors, cpu);
+			if (!_pr || !_pr->flags.power_setup_done)
+				continue;
+			cpuidle_disable_device(&_pr->power.dev);
+		}
+
+		/* Populate Updated C-state information */
+		acpi_processor_setup_cpuidle_states(pr);
+
+		/* Enable all cpuidle devices */
+		for_each_online_cpu(cpu) {
+			_pr = per_cpu(processors, cpu);
+			if (!_pr || !_pr->flags.power_setup_done)
+				continue;
+			acpi_processor_get_power_info(_pr);
+			if (_pr->flags.power) {
+				acpi_processor_setup_cpuidle_cx(_pr);
+				cpuidle_enable_device(&_pr->power.dev);
+			}
+		}
+		put_online_cpus();
+		cpuidle_resume_and_unlock();
+	}
+
+	return 0;
+}
+
+static int acpi_processor_registered;
+
 int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 			      struct acpi_device *device)
 {
 	acpi_status status = 0;
+	int retval;
 	static int first_run;
 
 	if (disabled_by_idle_boot_param())
@@ -1148,9 +1267,26 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 	 * platforms that only support C1.
 	 */
 	if (pr->flags.power) {
-		acpi_processor_setup_cpuidle(pr);
-		if (cpuidle_register_device(&pr->power.dev))
-			return -EIO;
+		/* Register acpi_idle_driver if not already registered */
+		if (!acpi_processor_registered) {
+			acpi_processor_setup_cpuidle_states(pr);
+			retval = cpuidle_register_driver(&acpi_idle_driver);
+			if (retval)
+				return retval;
+			printk(KERN_DEBUG "ACPI: %s registered with cpuidle\n",
+					acpi_idle_driver.name);
+		}
+		/* Register per-cpu cpuidle_device. Cpuidle driver
+		 * must already be registered before registering device
+		 */
+		acpi_processor_setup_cpuidle_cx(pr);
+		retval = cpuidle_register_device(&pr->power.dev);
+		if (retval) {
+			if (acpi_processor_registered == 0)
+				cpuidle_unregister_driver(&acpi_idle_driver);
+			return retval;
+		}
+		acpi_processor_registered++;
 	}
 	return 0;
 }
@@ -1161,8 +1297,13 @@ int acpi_processor_power_exit(struct acpi_processor *pr,
 	if (disabled_by_idle_boot_param())
 		return 0;
 
-	cpuidle_unregister_device(&pr->power.dev);
-	pr->flags.power_setup_done = 0;
+	if (pr->flags.power) {
+		cpuidle_unregister_device(&pr->power.dev);
+		acpi_processor_registered--;
+		if (acpi_processor_registered == 0)
+			cpuidle_unregister_driver(&acpi_idle_driver);
+	}
 
+	pr->flags.power_setup_done = 0;
 	return 0;
 }

commit 4202735e8ab6ecfb0381631a0d0b58fefe0bd4e2
Author: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
Date:   Fri Oct 28 16:20:33 2011 +0530

    cpuidle: Split cpuidle_state structure and move per-cpu statistics fields
    
    This is the first step towards global registration of cpuidle
    states. The statistics used primarily by the governor are per-cpu
    and have to be split from rest of the fields inside cpuidle_state,
    which would be made global i.e. single copy. The driver_data field
    is also per-cpu and moved.
    
    Signed-off-by: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Signed-off-by: Trinabh Gupta <g.trinabh@gmail.com>
    Tested-by: Jean Pihet <j-pihet@ti.com>
    Reviewed-by: Kevin Hilman <khilman@ti.com>
    Acked-by: Arjan van de Ven <arjan@linux.intel.com>
    Acked-by: Kevin Hilman <khilman@ti.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 9cd08cecb347..b98c75285690 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -745,14 +745,13 @@ static inline void acpi_idle_do_entry(struct acpi_processor_cx *cx)
  *
  * This is equivalent to the HALT instruction.
  */
-static int acpi_idle_enter_c1(struct cpuidle_device *dev,
-				int index)
+static int acpi_idle_enter_c1(struct cpuidle_device *dev, int index)
 {
 	ktime_t  kt1, kt2;
 	s64 idle_time;
 	struct acpi_processor *pr;
-	struct cpuidle_state *state = &dev->states[index];
-	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
+	struct cpuidle_state_usage *state_usage = &dev->states_usage[index];
+	struct acpi_processor_cx *cx = cpuidle_get_statedata(state_usage);
 
 	pr = __this_cpu_read(processors);
 	dev->last_residency = 0;
@@ -790,12 +789,11 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
  * @dev: the target CPU
  * @index: the index of suggested state
  */
-static int acpi_idle_enter_simple(struct cpuidle_device *dev,
-				int index)
+static int acpi_idle_enter_simple(struct cpuidle_device *dev, int index)
 {
 	struct acpi_processor *pr;
-	struct cpuidle_state *state = &dev->states[index];
-	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
+	struct cpuidle_state_usage *state_usage = &dev->states_usage[index];
+	struct acpi_processor_cx *cx = cpuidle_get_statedata(state_usage);
 	ktime_t  kt1, kt2;
 	s64 idle_time_ns;
 	s64 idle_time;
@@ -875,12 +873,11 @@ static DEFINE_SPINLOCK(c3_lock);
  *
  * If BM is detected, the deepest non-C3 idle state is entered instead.
  */
-static int acpi_idle_enter_bm(struct cpuidle_device *dev,
-				int index)
+static int acpi_idle_enter_bm(struct cpuidle_device *dev, int index)
 {
 	struct acpi_processor *pr;
-	struct cpuidle_state *state = &dev->states[index];
-	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
+	struct cpuidle_state_usage *state_usage = &dev->states_usage[index];
+	struct acpi_processor_cx *cx = cpuidle_get_statedata(state_usage);
 	ktime_t  kt1, kt2;
 	s64 idle_time_ns;
 	s64 idle_time;
@@ -1004,6 +1001,7 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 	int i, count = CPUIDLE_DRIVER_STATE_START;
 	struct acpi_processor_cx *cx;
 	struct cpuidle_state *state;
+	struct cpuidle_state_usage *state_usage;
 	struct cpuidle_device *dev = &pr->power.dev;
 
 	if (!pr->flags.power_setup_done)
@@ -1026,6 +1024,7 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {
 		cx = &pr->power.states[i];
 		state = &dev->states[count];
+		state_usage = &dev->states_usage[count];
 
 		if (!cx->valid)
 			continue;
@@ -1036,7 +1035,7 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 		    !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
 			continue;
 #endif
-		cpuidle_set_statedata(state, cx);
+		cpuidle_set_statedata(state_usage, cx);
 
 		snprintf(state->name, CPUIDLE_NAME_LEN, "C%d", i);
 		strncpy(state->desc, cx->desc, CPUIDLE_DESC_LEN);

commit e978aa7d7d57d04eb5f88a7507c4fb98577def77
Author: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
Date:   Fri Oct 28 16:20:09 2011 +0530

    cpuidle: Move dev->last_residency update to driver enter routine; remove dev->last_state
    
    Cpuidle governor only suggests the state to enter using the
    governor->select() interface, but allows the low level driver to
    override the recommended state. The actual entered state
    may be different because of software or hardware demotion. Software
    demotion is done by the back-end cpuidle driver and can be accounted
    correctly. Current cpuidle code uses last_state field to capture the
    actual state entered and based on that updates the statistics for the
    state entered.
    
    Ideally the driver enter routine should update the counters,
    and it should return the state actually entered rather than the time
    spent there. The generic cpuidle code should simply handle where
    the counters live in the sysfs namespace, not updating the counters.
    
    Reference:
    https://lkml.org/lkml/2011/3/25/52
    
    Signed-off-by: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Signed-off-by: Trinabh Gupta <g.trinabh@gmail.com>
    Tested-by: Jean Pihet <j-pihet@ti.com>
    Reviewed-by: Kevin Hilman <khilman@ti.com>
    Acked-by: Arjan van de Ven <arjan@linux.intel.com>
    Acked-by: Kevin Hilman <khilman@ti.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 431ab11c8c1b..9cd08cecb347 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -741,22 +741,24 @@ static inline void acpi_idle_do_entry(struct acpi_processor_cx *cx)
 /**
  * acpi_idle_enter_c1 - enters an ACPI C1 state-type
  * @dev: the target CPU
- * @state: the state data
+ * @index: index of target state
  *
  * This is equivalent to the HALT instruction.
  */
 static int acpi_idle_enter_c1(struct cpuidle_device *dev,
-			      struct cpuidle_state *state)
+				int index)
 {
 	ktime_t  kt1, kt2;
 	s64 idle_time;
 	struct acpi_processor *pr;
+	struct cpuidle_state *state = &dev->states[index];
 	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
 
 	pr = __this_cpu_read(processors);
+	dev->last_residency = 0;
 
 	if (unlikely(!pr))
-		return 0;
+		return -EINVAL;
 
 	local_irq_disable();
 
@@ -764,7 +766,7 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 	if (acpi_idle_suspend) {
 		local_irq_enable();
 		cpu_relax();
-		return 0;
+		return -EINVAL;
 	}
 
 	lapic_timer_state_broadcast(pr, cx, 1);
@@ -773,37 +775,46 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 	kt2 = ktime_get_real();
 	idle_time =  ktime_to_us(ktime_sub(kt2, kt1));
 
+	/* Update device last_residency*/
+	dev->last_residency = (int)idle_time;
+
 	local_irq_enable();
 	cx->usage++;
 	lapic_timer_state_broadcast(pr, cx, 0);
 
-	return idle_time;
+	return index;
 }
 
 /**
  * acpi_idle_enter_simple - enters an ACPI state without BM handling
  * @dev: the target CPU
- * @state: the state data
+ * @index: the index of suggested state
  */
 static int acpi_idle_enter_simple(struct cpuidle_device *dev,
-				  struct cpuidle_state *state)
+				int index)
 {
 	struct acpi_processor *pr;
+	struct cpuidle_state *state = &dev->states[index];
 	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
 	ktime_t  kt1, kt2;
 	s64 idle_time_ns;
 	s64 idle_time;
 
 	pr = __this_cpu_read(processors);
+	dev->last_residency = 0;
 
 	if (unlikely(!pr))
-		return 0;
-
-	if (acpi_idle_suspend)
-		return(acpi_idle_enter_c1(dev, state));
+		return -EINVAL;
 
 	local_irq_disable();
 
+	if (acpi_idle_suspend) {
+		local_irq_enable();
+		cpu_relax();
+		return -EINVAL;
+	}
+
+
 	if (cx->entry_method != ACPI_CSTATE_FFH) {
 		current_thread_info()->status &= ~TS_POLLING;
 		/*
@@ -815,7 +826,7 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 		if (unlikely(need_resched())) {
 			current_thread_info()->status |= TS_POLLING;
 			local_irq_enable();
-			return 0;
+			return -EINVAL;
 		}
 	}
 
@@ -837,6 +848,9 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	idle_time = idle_time_ns;
 	do_div(idle_time, NSEC_PER_USEC);
 
+	/* Update device last_residency*/
+	dev->last_residency = (int)idle_time;
+
 	/* Tell the scheduler how much we idled: */
 	sched_clock_idle_wakeup_event(idle_time_ns);
 
@@ -848,7 +862,7 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 
 	lapic_timer_state_broadcast(pr, cx, 0);
 	cx->time += idle_time;
-	return idle_time;
+	return index;
 }
 
 static int c3_cpu_count;
@@ -857,14 +871,15 @@ static DEFINE_SPINLOCK(c3_lock);
 /**
  * acpi_idle_enter_bm - enters C3 with proper BM handling
  * @dev: the target CPU
- * @state: the state data
+ * @index: the index of suggested state
  *
  * If BM is detected, the deepest non-C3 idle state is entered instead.
  */
 static int acpi_idle_enter_bm(struct cpuidle_device *dev,
-			      struct cpuidle_state *state)
+				int index)
 {
 	struct acpi_processor *pr;
+	struct cpuidle_state *state = &dev->states[index];
 	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
 	ktime_t  kt1, kt2;
 	s64 idle_time_ns;
@@ -872,22 +887,26 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 
 
 	pr = __this_cpu_read(processors);
+	dev->last_residency = 0;
 
 	if (unlikely(!pr))
-		return 0;
+		return -EINVAL;
 
-	if (acpi_idle_suspend)
-		return(acpi_idle_enter_c1(dev, state));
+
+	if (acpi_idle_suspend) {
+		cpu_relax();
+		return -EINVAL;
+	}
 
 	if (!cx->bm_sts_skip && acpi_idle_bm_check()) {
-		if (dev->safe_state) {
-			dev->last_state = dev->safe_state;
-			return dev->safe_state->enter(dev, dev->safe_state);
+		if (dev->safe_state_index >= 0) {
+			return dev->states[dev->safe_state_index].enter(dev,
+						dev->safe_state_index);
 		} else {
 			local_irq_disable();
 			acpi_safe_halt();
 			local_irq_enable();
-			return 0;
+			return -EINVAL;
 		}
 	}
 
@@ -904,7 +923,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		if (unlikely(need_resched())) {
 			current_thread_info()->status |= TS_POLLING;
 			local_irq_enable();
-			return 0;
+			return -EINVAL;
 		}
 	}
 
@@ -954,6 +973,9 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	idle_time = idle_time_ns;
 	do_div(idle_time, NSEC_PER_USEC);
 
+	/* Update device last_residency*/
+	dev->last_residency = (int)idle_time;
+
 	/* Tell the scheduler how much we idled: */
 	sched_clock_idle_wakeup_event(idle_time_ns);
 
@@ -965,7 +987,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 
 	lapic_timer_state_broadcast(pr, cx, 0);
 	cx->time += idle_time;
-	return idle_time;
+	return index;
 }
 
 struct cpuidle_driver acpi_idle_driver = {
@@ -992,6 +1014,7 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 	}
 
 	dev->cpu = pr->id;
+	dev->safe_state_index = -1;
 	for (i = 0; i < CPUIDLE_STATE_MAX; i++) {
 		dev->states[i].name[0] = '\0';
 		dev->states[i].desc[0] = '\0';
@@ -1027,13 +1050,13 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 				state->flags |= CPUIDLE_FLAG_TIME_VALID;
 
 			state->enter = acpi_idle_enter_c1;
-			dev->safe_state = state;
+			dev->safe_state_index = count;
 			break;
 
 			case ACPI_STATE_C2:
 			state->flags |= CPUIDLE_FLAG_TIME_VALID;
 			state->enter = acpi_idle_enter_simple;
-			dev->safe_state = state;
+			dev->safe_state_index = count;
 			break;
 
 			case ACPI_STATE_C3:

commit 3cfef9524677a4ecb392d6fbffe6ebce6302f1d4
Merge: 982653009b88 68cc3990a545
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Oct 26 16:17:32 2011 +0200

    Merge branch 'core-locking-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    * 'core-locking-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (27 commits)
      rtmutex: Add missing rcu_read_unlock() in debug_rt_mutex_print_deadlock()
      lockdep: Comment all warnings
      lib: atomic64: Change the type of local lock to raw_spinlock_t
      locking, lib/atomic64: Annotate atomic64_lock::lock as raw
      locking, x86, iommu: Annotate qi->q_lock as raw
      locking, x86, iommu: Annotate irq_2_ir_lock as raw
      locking, x86, iommu: Annotate iommu->register_lock as raw
      locking, dma, ipu: Annotate bank_lock as raw
      locking, ARM: Annotate low level hw locks as raw
      locking, drivers/dca: Annotate dca_lock as raw
      locking, powerpc: Annotate uic->lock as raw
      locking, x86: mce: Annotate cmci_discover_lock as raw
      locking, ACPI: Annotate c3_lock as raw
      locking, oprofile: Annotate oprofilefs lock as raw
      locking, video: Annotate vga console lock as raw
      locking, latencytop: Annotate latency_lock as raw
      locking, timer_stats: Annotate table_lock as raw
      locking, rwsem: Annotate inner lock as raw
      locking, semaphores: Annotate inner lock as raw
      locking, sched: Annotate thread_group_cputimer as raw
      ...
    
    Fix up conflicts in kernel/posix-cpu-timers.c manually: making
    cputimer->cputime a raw lock conflicted with the ABBA fix in commit
    bcd5cff7216f ("cputimer: Cure lock inversion").

commit e12f65f7a49905c013263ac522af224892aafc00
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 25 18:14:37 2009 +0200

    locking, ACPI: Annotate c3_lock as raw
    
    We cannot preempt this lock on -rt as we are in an
    interrupt disabled region and about to go into deep sleep.
    
    In mainline this change documents the low level nature of
    the lock - otherwise there's no functional difference. Lockdep
    and Sparse checking will work as usual.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Len Brown <len.brown@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 431ab11c8c1b..3e0531405997 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -852,7 +852,7 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 }
 
 static int c3_cpu_count;
-static DEFINE_SPINLOCK(c3_lock);
+static DEFINE_RAW_SPINLOCK(c3_lock);
 
 /**
  * acpi_idle_enter_bm - enters C3 with proper BM handling
@@ -930,12 +930,12 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	 * without doing anything.
 	 */
 	if (pr->flags.bm_check && pr->flags.bm_control) {
-		spin_lock(&c3_lock);
+		raw_spin_lock(&c3_lock);
 		c3_cpu_count++;
 		/* Disable bus master arbitration when all CPUs are in C3 */
 		if (c3_cpu_count == num_online_cpus())
 			acpi_write_bit_register(ACPI_BITREG_ARB_DISABLE, 1);
-		spin_unlock(&c3_lock);
+		raw_spin_unlock(&c3_lock);
 	} else if (!pr->flags.bm_check) {
 		ACPI_FLUSH_CPU_CACHE();
 	}
@@ -944,10 +944,10 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 
 	/* Re-enable bus master arbitration */
 	if (pr->flags.bm_check && pr->flags.bm_control) {
-		spin_lock(&c3_lock);
+		raw_spin_lock(&c3_lock);
 		acpi_write_bit_register(ACPI_BITREG_ARB_DISABLE, 0);
 		c3_cpu_count--;
-		spin_unlock(&c3_lock);
+		raw_spin_unlock(&c3_lock);
 	}
 	kt2 = ktime_get_real();
 	idle_time_ns = ktime_to_ns(ktime_sub(kt2, kt1));

commit e8db0be1245de16a6cc6365506abc392c3c212d4
Author: Jean Pihet <j-pihet@ti.com>
Date:   Thu Aug 25 15:35:03 2011 +0200

    PM QoS: Move and rename the implementation files
    
    The PM QoS implementation files are better named
    kernel/power/qos.c and include/linux/pm_qos.h.
    
    The PM QoS support is compiled under the CONFIG_PM option.
    
    Signed-off-by: Jean Pihet <j-pihet@ti.com>
    Acked-by: markgross <markgross@thegnar.org>
    Reviewed-by: Kevin Hilman <khilman@ti.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 431ab11c8c1b..2e69e09ff03e 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -37,7 +37,7 @@
 #include <linux/dmi.h>
 #include <linux/moduleparam.h>
 #include <linux/sched.h>	/* need_resched() */
-#include <linux/pm_qos_params.h>
+#include <linux/pm_qos.h>
 #include <linux/clockchips.h>
 #include <linux/cpuidle.h>
 #include <linux/irqflags.h>

commit 02c68a02018669d1817c43c42de800975cbec467
Author: Len Brown <len.brown@intel.com>
Date:   Fri Apr 1 16:59:53 2011 -0400

    x86 idle: clarify AMD erratum 400 workaround
    
    The workaround for AMD erratum 400 uses the term "c1e" falsely suggesting:
    1. Intel C1E is somehow involved
    2. All AMD processors with C1E are involved
    
    Use the string "amd_c1e" instead of simply "c1e" to clarify that
    this workaround is specific to AMD's version of C1E.
    Use the string "e400" to clarify that the workaround is specific
    to AMD processors with Erratum 400.
    
    This patch is text-substitution only, with no functional change.
    
    cc: x86@kernel.org
    Acked-by: Borislav Petkov <borislav.petkov@amd.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index d615b7d69bca..431ab11c8c1b 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -161,7 +161,7 @@ static void lapic_timer_check_state(int state, struct acpi_processor *pr,
 	if (cpu_has(&cpu_data(pr->id), X86_FEATURE_ARAT))
 		return;
 
-	if (c1e_detected)
+	if (amd_e400_c1e_detected)
 		type = ACPI_STATE_C1;
 
 	/*

commit 56dbed129df3fdd4caf9018b6e7599ee258a5420
Merge: 2a2d31c8dc6f f878133bf022
Author: Len Brown <len.brown@intel.com>
Date:   Wed Jan 12 18:06:06 2011 -0500

    Merge branch 'linus' into idle-test

commit 0aae9f923bcc476a8e4725dd3ac37547b9816ee5
Author: Len Brown <len.brown@intel.com>
Date:   Wed Jan 12 02:22:56 2011 -0500

    ACPI: processor_idle: delete use of NOP CPUIDLE_FLAGs
    
    CPUIDLE_FLAG_SHALLOW
    CPUIDLE_FLAG_BALANCED
    CPUIDLE_FLAG_DEEP
    CPUIDLE_FLAG_CHECK_BM
    
    were set by acpi_processor_setup_cpuidle(),
    but never used by cpuidle or by acpi_idle.
    So stop setting them.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index eefd4aa0e71d..70599d2ada61 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1023,7 +1023,6 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 		state->flags = 0;
 		switch (cx->type) {
 			case ACPI_STATE_C1:
-			state->flags |= CPUIDLE_FLAG_SHALLOW;
 			if (cx->entry_method == ACPI_CSTATE_FFH)
 				state->flags |= CPUIDLE_FLAG_TIME_VALID;
 
@@ -1032,16 +1031,13 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 			break;
 
 			case ACPI_STATE_C2:
-			state->flags |= CPUIDLE_FLAG_BALANCED;
 			state->flags |= CPUIDLE_FLAG_TIME_VALID;
 			state->enter = acpi_idle_enter_simple;
 			dev->safe_state = state;
 			break;
 
 			case ACPI_STATE_C3:
-			state->flags |= CPUIDLE_FLAG_DEEP;
 			state->flags |= CPUIDLE_FLAG_TIME_VALID;
-			state->flags |= CPUIDLE_FLAG_CHECK_BM;
 			state->enter = pr->flags.bm_check ?
 					acpi_idle_enter_bm :
 					acpi_idle_enter_simple;

commit d18960494f65ca4fa0d67c865aaca99452070d15
Author: Thomas Renninger <trenn@suse.de>
Date:   Wed Nov 3 17:06:14 2010 +0100

    ACPI, intel_idle: Cleanup idle= internal variables
    
    Having four variables for the same thing:
      idle_halt, idle_nomwait, force_mwait and boot_option_idle_overrides
    is rather confusing and unnecessary complex.
    
    if idle= boot param is passed, only set up one variable:
    boot_option_idle_overrides
    
    Introduces following functional changes/fixes:
      - intel_idle driver does not register if any idle=xy
        boot param is passed.
      - processor_idle.c will also not register a cpuidle driver
        and get active if idle=halt is passed.
        Before a cpuidle driver with one (C1, halt) state got registered
        Now the default_idle function will be used which finally uses
        the same idle call to enter sleep state (safe_halt()), but
        without registering a whole cpuidle driver.
    
    That means idle= param will always avoid cpuidle drivers to register
    with one exception (same behavior as before):
    idle=nomwait
    may still register acpi_idle cpuidle driver, but C1 will not use
    mwait, but hlt. This can be a workaround for IO based deeper sleep
    states where C1 mwait causes problems.
    
    Signed-off-by: Thomas Renninger <trenn@suse.de>
    cc: x86@kernel.org
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index dcb38f8ddfda..eefd4aa0e71d 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -79,6 +79,13 @@ module_param(bm_check_disable, uint, 0000);
 static unsigned int latency_factor __read_mostly = 2;
 module_param(latency_factor, uint, 0644);
 
+static int disabled_by_idle_boot_param(void)
+{
+	return boot_option_idle_override == IDLE_POLL ||
+		boot_option_idle_override == IDLE_FORCE_MWAIT ||
+		boot_option_idle_override == IDLE_HALT;
+}
+
 /*
  * IBM ThinkPad R40e crashes mysteriously when going into C2 or C3.
  * For now disable this. Probably a bug somewhere else.
@@ -455,7 +462,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 				continue;
 			}
 			if (cx.type == ACPI_STATE_C1 &&
-					(idle_halt || idle_nomwait)) {
+			    (boot_option_idle_override == IDLE_NOMWAIT)) {
 				/*
 				 * In most cases the C1 space_id obtained from
 				 * _CST object is FIXED_HARDWARE access mode.
@@ -1058,7 +1065,7 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 {
 	int ret = 0;
 
-	if (boot_option_idle_override)
+	if (disabled_by_idle_boot_param())
 		return 0;
 
 	if (!pr)
@@ -1089,19 +1096,10 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 	acpi_status status = 0;
 	static int first_run;
 
-	if (boot_option_idle_override)
+	if (disabled_by_idle_boot_param())
 		return 0;
 
 	if (!first_run) {
-		if (idle_halt) {
-			/*
-			 * When the boot option of "idle=halt" is added, halt
-			 * is used for CPU IDLE.
-			 * In such case C2/C3 is meaningless. So the max_cstate
-			 * is set to one.
-			 */
-			max_cstate = 1;
-		}
 		dmi_check_system(processor_power_dmi_table);
 		max_cstate = acpi_processor_cstate_check(max_cstate);
 		if (max_cstate < ACPI_C_STATES_MAX)
@@ -1142,7 +1140,7 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 int acpi_processor_power_exit(struct acpi_processor *pr,
 			      struct acpi_device *device)
 {
-	if (boot_option_idle_override)
+	if (disabled_by_idle_boot_param())
 		return 0;
 
 	cpuidle_unregister_device(&pr->power.dev);

commit 4a6f4fe8377720e5a279fdbb769946c242e936d3
Author: Christoph Lameter <cl@linux.com>
Date:   Mon Dec 6 11:16:24 2010 -0600

    drivers: Replace __get_cpu_var with __this_cpu_read if not used for an address.
    
    __get_cpu_var() can be replaced with this_cpu_read and will then use a single
    read instruction with implied address calculation to access the correct per cpu
    instance.
    
    However, the address of a per cpu variable passed to __this_cpu_read() cannot be
    determed (since its an implied address conversion through segment prefixes).
    Therefore apply this only to uses of __get_cpu_var where the addres of the
    variable is not used.
    
    V3->V4:
            - Move one instance of this_cpu_inc_return to a later patch
              so that this one can go in without percpu infrastructrure
              changes.
    
    Sedat: fixed compile failure caused by an extra ')'.
    
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Sedat Dilek <sedat.dilek@gmail.com>
    Acked-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Christoph Lameter <cl@linux.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index dcb38f8ddfda..a765b823aa9e 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -746,7 +746,7 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 	struct acpi_processor *pr;
 	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
 
-	pr = __get_cpu_var(processors);
+	pr = __this_cpu_read(processors);
 
 	if (unlikely(!pr))
 		return 0;
@@ -787,7 +787,7 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	s64 idle_time_ns;
 	s64 idle_time;
 
-	pr = __get_cpu_var(processors);
+	pr = __this_cpu_read(processors);
 
 	if (unlikely(!pr))
 		return 0;
@@ -864,7 +864,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	s64 idle_time;
 
 
-	pr = __get_cpu_var(processors);
+	pr = __this_cpu_read(processors);
 
 	if (unlikely(!pr))
 		return 0;

commit 474829e875ab93512dbe0a713f564d3cd3874bc9
Merge: 27afe58fe60f 7e3184244177
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 26 17:28:37 2010 -0700

    Merge branch 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-acpi-2.6
    
    * 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-acpi-2.6: (53 commits)
      ACPI: install ACPI table handler before any dynamic tables being loaded
      ACPI / PM: Blacklist another machine that needs acpi_sleep=nonvs
      ACPI: Page based coalescing of I/O remappings optimization
      ACPI: Convert simple locking to RCU based locking
      ACPI: Pre-map 'system event' related register blocks
      ACPI: Add interfaces for ioremapping/iounmapping ACPI registers
      ACPI: Maintain a list of ACPI memory mapped I/O remappings
      ACPI: Fix ioremap size for MMIO reads and writes
      ACPI / Battery: Return -ENODEV for unknown values in get_property()
      ACPI / PM: Fix reference counting of power resources
      Subject: [PATCH] ACPICA: Fix Scope() op in module level code
      ACPI battery: support percentage battery remaining capacity
      ACPI: Make Embedded Controller command timeout delay configurable
      ACPI dock: move some functions to .init.text
      ACPI: thermal: remove unused limit code
      ACPI: static sleep_states[] and acpi_gts_bfs_check
      ACPI: remove dead code
      ACPI: delete dedicated MAINTAINERS entries for ACPI EC and BATTERY drivers
      ACPI: Only processor needs CPU_IDLE
      ACPICA: Update version to 20101013
      ...

commit 0f3f164d9794f57d8afb033819f508a486c1304d
Author: Len Brown <len.brown@intel.com>
Date:   Fri Oct 15 21:25:02 2010 -0400

    acpi_idle: delete bogus data from cpuidle_state.power_usage
    
    The mW data in this field comes from AML _CST,
    which was typed in by a BIOS writer, and is thus
    considered unreliable.
    
    Linux does not use it for making any decisions.
    We do display it in sysfs where somebody might
    read it and assume it is meaningful, so delete it.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index f4428e82b352..07a8bb6506f7 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1013,7 +1013,6 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 		strncpy(state->desc, cx->desc, CPUIDLE_DESC_LEN);
 		state->exit_latency = cx->latency;
 		state->target_residency = cx->latency * latency_factor;
-		state->power_usage = cx->power;
 
 		state->flags = 0;
 		switch (cx->type) {

commit eaeca2e9a7dbd8f05a8a47e66e3e1de105426f0b
Author: Thomas Renninger <trenn@suse.de>
Date:   Fri Oct 1 10:54:53 2010 +0200

    ACPI: Remove unused #define ACPI_PROCESSOR_FILE_POWER
    
    Looks like a left over from /proc/acpi/processor/*/power which got removed
    
    Signed-off-by: Thomas Renninger <trenn@suse.de>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index f4428e82b352..175c89a5ca90 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -64,7 +64,6 @@
 #define ACPI_PROCESSOR_CLASS            "processor"
 #define _COMPONENT              ACPI_PROCESSOR_COMPONENT
 ACPI_MODULE_NAME("processor_idle");
-#define ACPI_PROCESSOR_FILE_POWER	"power"
 #define PM_TIMER_TICK_NS		(1000000000ULL/PM_TIMER_FREQUENCY)
 #define C2_OVERHEAD			1	/* 1us */
 #define C3_OVERHEAD			1	/* 1us */

commit 95ee46aa8698f2000647dfb362400fadbb5807cf
Merge: cfa806f05980 92fa5bd9a946
Author: Len Brown <len.brown@intel.com>
Date:   Sun Aug 15 01:06:31 2010 -0400

    Merge branch 'linus' into release
    
    Conflicts:
            drivers/acpi/debug.c
    
    Signed-off-by: Len Brown <len.brown@intel.com>

commit cfa806f059801dbe7e435745eb2e187c8bfe1e7f
Author: Andi Kleen <andi@firstfloor.org>
Date:   Tue Jul 20 15:18:36 2010 -0700

    gcc-4.6: ACPI: fix unused but set variables in ACPI
    
    Some minor improvements in error handling, but overall it was mostly dead
    code.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 5cbc0cb73e2c..07bc74d8356e 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -722,13 +722,12 @@ static inline void acpi_idle_do_entry(struct acpi_processor_cx *cx)
 	} else if (cx->entry_method == ACPI_CSTATE_HALT) {
 		acpi_safe_halt();
 	} else {
-		int unused;
 		/* IO port based C-state */
 		inb(cx->address);
 		/* Dummy wait op - must do something useless after P_LVL2 read
 		   because chipsets cannot guarantee that STPCLK# signal
 		   gets asserted in time to freeze execution properly. */
-		unused = inl(acpi_gbl_FADT.xpm_timer_block.address);
+		inl(acpi_gbl_FADT.xpm_timer_block.address);
 	}
 	start_critical_timings();
 }

commit d09fe55510257f1acd21ea80a9bdd7c72b5895b3
Author: Zhang Rui <rui.zhang@intel.com>
Date:   Thu Jul 15 10:46:41 2010 +0800

    ACPI processor: remove deprecated ACPI procfs I/F
    
    Remove deprecated ACPI processor procfs I/F, including:
    /proc/acpi/processor/CPUX/power
    /proc/acpi/processor/CPUX/limit
    /proc/acpi/processor/CPUX/info
    
    /proc/acpi/processor/CPUX/throttling still exists,
    as we don't have sysfs I/F available for now.
    
    Signed-off-by: Zhang Rui <rui.zhang@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index e9a8026d39f0..5cbc0cb73e2c 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -33,8 +33,6 @@
 #include <linux/init.h>
 #include <linux/cpufreq.h>
 #include <linux/slab.h>
-#include <linux/proc_fs.h>
-#include <linux/seq_file.h>
 #include <linux/acpi.h>
 #include <linux/dmi.h>
 #include <linux/moduleparam.h>
@@ -82,13 +80,6 @@ module_param(bm_check_disable, uint, 0000);
 static unsigned int latency_factor __read_mostly = 2;
 module_param(latency_factor, uint, 0644);
 
-#ifdef CONFIG_ACPI_PROCFS
-static u64 us_to_pm_timer_ticks(s64 t)
-{
-	return div64_u64(t * PM_TIMER_FREQUENCY, 1000000);
-}
-#endif
-
 /*
  * IBM ThinkPad R40e crashes mysteriously when going into C2 or C3.
  * For now disable this. Probably a bug somewhere else.
@@ -689,78 +680,6 @@ static int acpi_processor_get_power_info(struct acpi_processor *pr)
 	return 0;
 }
 
-#ifdef CONFIG_ACPI_PROCFS
-static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
-{
-	struct acpi_processor *pr = seq->private;
-	unsigned int i;
-
-
-	if (!pr)
-		goto end;
-
-	seq_printf(seq, "active state:            C%zd\n"
-		   "max_cstate:              C%d\n"
-		   "maximum allowed latency: %d usec\n",
-		   pr->power.state ? pr->power.state - pr->power.states : 0,
-		   max_cstate, pm_qos_request(PM_QOS_CPU_DMA_LATENCY));
-
-	seq_puts(seq, "states:\n");
-
-	for (i = 1; i <= pr->power.count; i++) {
-		seq_printf(seq, "   %cC%d:                  ",
-			   (&pr->power.states[i] ==
-			    pr->power.state ? '*' : ' '), i);
-
-		if (!pr->power.states[i].valid) {
-			seq_puts(seq, "<not supported>\n");
-			continue;
-		}
-
-		switch (pr->power.states[i].type) {
-		case ACPI_STATE_C1:
-			seq_printf(seq, "type[C1] ");
-			break;
-		case ACPI_STATE_C2:
-			seq_printf(seq, "type[C2] ");
-			break;
-		case ACPI_STATE_C3:
-			seq_printf(seq, "type[C3] ");
-			break;
-		default:
-			seq_printf(seq, "type[--] ");
-			break;
-		}
-
-		seq_puts(seq, "promotion[--] ");
-
-		seq_puts(seq, "demotion[--] ");
-
-		seq_printf(seq, "latency[%03d] usage[%08d] duration[%020Lu]\n",
-			   pr->power.states[i].latency,
-			   pr->power.states[i].usage,
-			   us_to_pm_timer_ticks(pr->power.states[i].time));
-	}
-
-      end:
-	return 0;
-}
-
-static int acpi_processor_power_open_fs(struct inode *inode, struct file *file)
-{
-	return single_open(file, acpi_processor_power_seq_show,
-			   PDE(inode)->data);
-}
-
-static const struct file_operations acpi_processor_power_fops = {
-	.owner = THIS_MODULE,
-	.open = acpi_processor_power_open_fs,
-	.read = seq_read,
-	.llseek = seq_lseek,
-	.release = single_release,
-};
-#endif
-
 /**
  * acpi_idle_bm_check - checks if bus master activity was detected
  */
@@ -1172,9 +1091,6 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 {
 	acpi_status status = 0;
 	static int first_run;
-#ifdef CONFIG_ACPI_PROCFS
-	struct proc_dir_entry *entry = NULL;
-#endif
 
 	if (boot_option_idle_override)
 		return 0;
@@ -1223,15 +1139,6 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 		if (cpuidle_register_device(&pr->power.dev))
 			return -EIO;
 	}
-#ifdef CONFIG_ACPI_PROCFS
-	/* 'power' [R] */
-	entry = proc_create_data(ACPI_PROCESSOR_FILE_POWER,
-				 S_IRUGO, acpi_device_dir(device),
-				 &acpi_processor_power_fops,
-				 acpi_driver_data(device));
-	if (!entry)
-		return -EIO;
-#endif
 	return 0;
 }
 
@@ -1244,11 +1151,5 @@ int acpi_processor_power_exit(struct acpi_processor *pr,
 	cpuidle_unregister_device(&pr->power.dev);
 	pr->flags.power_setup_done = 0;
 
-#ifdef CONFIG_ACPI_PROCFS
-	if (acpi_device_dir(device))
-		remove_proc_entry(ACPI_PROCESSOR_FILE_POWER,
-				  acpi_device_dir(device));
-#endif
-
 	return 0;
 }

commit b62ad9ab181a67207a4c8c373461b587c4861a68
Merge: af390084359a b29230769e34
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Aug 6 13:18:29 2010 -0700

    Merge branch 'timers-timekeeping-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'timers-timekeeping-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      um: Fix read_persistent_clock fallout
      kgdb: Do not access xtime directly
      powerpc: Clean up obsolete code relating to decrementer and timebase
      powerpc: Rework VDSO gettimeofday to prevent time going backwards
      clocksource: Add __clocksource_updatefreq_hz/khz methods
      x86: Convert common clocksources to use clocksource_register_hz/khz
      timekeeping: Make xtime and wall_to_monotonic static
      hrtimer: Cleanup direct access to wall_to_monotonic
      um: Convert to use read_persistent_clock
      timkeeping: Fix update_vsyscall to provide wall_to_monotonic offset
      powerpc: Cleanup xtime usage
      powerpc: Simplify update_vsyscall
      time: Kill off CONFIG_GENERIC_TIME
      time: Implement timespec_add
      x86: Fix vtime/file timestamp inconsistencies
    
    Trivial conflicts in Documentation/feature-removal-schedule.txt
    
    Much less trivial conflicts in arch/powerpc/kernel/time.c resolved as
    per Thomas' earlier merge commit 47916be4e28c ("Merge branch
    'powerpc.cherry-picks' into timers/clocksource")

commit e8c534ec068af1a0845aceda373a9bfd2de62030
Author: Michal Schmidt <mschmidt@redhat.com>
Date:   Tue Jul 27 18:53:35 2010 +0200

    x86: Fix keeping track of AMD C1E
    
    Accomodate the original C1E-aware idle routine to the different times
    during boot when the BIOS enables C1E. While at it, remove the synthetic
    CPUID flag in favor of a single global setting which denotes C1E status
    on the system.
    
    [ hpa: changed c1e_enabled to be a bool; clarified cpu bit 3:21 comment ]
    
    Signed-off-by: Michal Schmidt <mschmidt@redhat.com>
    LKML-Reference: <20100727165335.GA11630@aftab>
    Signed-off-by: Borislav Petkov <borislav.petkov@amd.com>
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index e9a8026d39f0..eead3f581fb5 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -164,7 +164,7 @@ static void lapic_timer_check_state(int state, struct acpi_processor *pr,
 	if (cpu_has(&cpu_data(pr->id), X86_FEATURE_ARAT))
 		return;
 
-	if (boot_cpu_has(X86_FEATURE_AMDC1E))
+	if (c1e_detected)
 		type = ACPI_STATE_C1;
 
 	/*

commit 592913ecb87a9e06f98ddb55b298f1a66bf94c6b
Author: John Stultz <johnstul@us.ibm.com>
Date:   Tue Jul 13 17:56:20 2010 -0700

    time: Kill off CONFIG_GENERIC_TIME
    
    Now that all arches have been converted over to use generic time via
    clocksources or arch_gettimeoffset(), we can remove the GENERIC_TIME
    config option and simplify the generic code.
    
    Signed-off-by: John Stultz <johnstul@us.ibm.com>
    LKML-Reference: <1279068988-21864-4-git-send-email-johnstul@us.ibm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index e9a8026d39f0..294e10b5480a 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -264,7 +264,7 @@ int acpi_processor_resume(struct acpi_device * device)
 	return 0;
 }
 
-#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86)
+#if defined(CONFIG_X86)
 static void tsc_check_state(int state)
 {
 	switch (boot_cpu_data.x86_vendor) {

commit bbac30edb39a80426e4a3420a5ec635eb4466f63
Merge: 4a973f2495fb 6c9c0fd062a6
Author: Len Brown <len.brown@intel.com>
Date:   Thu Jul 22 18:19:12 2010 -0400

    Merge branch 'misc' into release

commit d3e7e99f2faf9f44ec0a3379f735b41c9173dfa1
Author: Len Brown <len.brown@intel.com>
Date:   Thu Jul 22 17:23:10 2010 -0400

    ACPI: create "processor.bm_check_disable" boot param
    
    processor.bm_check_disable=1" prevents Linux from checking BM_STS
    before entering C3-type cpu power states.
    
    This may be useful for a system running acpi_idle
    where the BIOS exports FADT C-states, _CST IO C-states,
    or _CST FFH C-states with the BM_STS bit set;
    while configuring the chipset to set BM_STS
    more frequently than perhaps is optimal.
    
    Note that such systems may have been developed
    using a tickful OS that would quickly clear BM_STS,
    rather than a tickless OS that may go for some time
    between checking and clearing BM_STS.
    
    Note also that an alternative for newer systems
    is to use the intel_idle driver, which always
    ignores BM_STS, relying Linux device drivers
    to register constraints explicitly via PM_QOS.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=15886
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index b351342f1faf..1d4104855296 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -76,6 +76,8 @@ static unsigned int max_cstate __read_mostly = ACPI_PROCESSOR_MAX_POWER;
 module_param(max_cstate, uint, 0000);
 static unsigned int nocst __read_mostly;
 module_param(nocst, uint, 0000);
+static int bm_check_disable __read_mostly;
+module_param(bm_check_disable, uint, 0000);
 
 static unsigned int latency_factor __read_mostly = 2;
 module_param(latency_factor, uint, 0644);
@@ -763,6 +765,9 @@ static int acpi_idle_bm_check(void)
 {
 	u32 bm_status = 0;
 
+	if (bm_check_disable)
+		return 0;
+
 	acpi_read_bit_register(ACPI_BITREG_BUS_MASTER_STATUS, &bm_status);
 	if (bm_status)
 		acpi_write_bit_register(ACPI_BITREG_BUS_MASTER_STATUS, 1);

commit 718be4aaf3613cf7c2d097f925abc3d3553c0605
Author: Len Brown <len.brown@intel.com>
Date:   Thu Jul 22 16:54:27 2010 -0400

    ACPI: skip checking BM_STS if the BIOS doesn't ask for it
    
    It turns out that there is a bit in the _CST for Intel FFH C3
    that tells the OS if we should be checking BM_STS or not.
    
    Linux has been unconditionally checking BM_STS.
    If the chip-set is configured to enable BM_STS,
    it can retard or completely prevent entry into
    deep C-states -- as illustrated by turbostat:
    
    http://userweb.kernel.org/~lenb/acpi/utils/pmtools/turbostat/
    
    ref: Intel Processor Vendor-Specific ACPI Interface Specification
    table 4 "_CST FFH GAS Field Encoding"
    Bit 1: Set to 1 if OSPM should use Bus Master avoidance for this C-state
    
    https://bugzilla.kernel.org/show_bug.cgi?id=15886
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index b1b385692f46..b351342f1faf 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -947,7 +947,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	if (acpi_idle_suspend)
 		return(acpi_idle_enter_c1(dev, state));
 
-	if (acpi_idle_bm_check()) {
+	if (!cx->bm_sts_skip && acpi_idle_bm_check()) {
 		if (dev->safe_state) {
 			dev->last_state = dev->safe_state;
 			return dev->safe_state->enter(dev, dev->safe_state);

commit 6c9c0fd062a6540dbee233151679b5f03ce433d9
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Tue Jul 20 15:18:35 2010 -0700

    ACPI: fix unused function warning
    
    CONFIG_ACPI_PROCFS=n:
    
    drivers/acpi/processor_idle.c:83: warning: 'us_to_pm_timer_ticks' defined but not used.
    
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index b1b385692f46..d0035946b6b9 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -80,10 +80,13 @@ module_param(nocst, uint, 0000);
 static unsigned int latency_factor __read_mostly = 2;
 module_param(latency_factor, uint, 0644);
 
+#ifdef CONFIG_ACPI_PROCFS
 static u64 us_to_pm_timer_ticks(s64 t)
 {
 	return div64_u64(t * PM_TIMER_FREQUENCY, 1000000);
 }
+#endif
+
 /*
  * IBM ThinkPad R40e crashes mysteriously when going into C2 or C3.
  * For now disable this. Probably a bug somewhere else.

commit bceefad59ab66d1b1a815a1738744ea013da966e
Author: Venkatesh Pallipadi <venki@google.com>
Date:   Wed Jun 2 10:01:09 2010 -0700

    ACPI: Eliminate us to pm ticks conversion in common path
    
    acpi_enter_[simple|bm] routines does us to pm tick conversion on every
    idle wakeup and the value is only used in /proc/acpi display. We can
    store the time in us and convert it into pm ticks before printing instead and
    avoid the conversion in the common path.
    
    Signed-off-by: Venkatesh Pallipadi <venki@google.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 6b38a6b43ce8..b1b385692f46 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -80,7 +80,7 @@ module_param(nocst, uint, 0000);
 static unsigned int latency_factor __read_mostly = 2;
 module_param(latency_factor, uint, 0644);
 
-static s64 us_to_pm_timer_ticks(s64 t)
+static u64 us_to_pm_timer_ticks(s64 t)
 {
 	return div64_u64(t * PM_TIMER_FREQUENCY, 1000000);
 }
@@ -731,10 +731,10 @@ static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
 
 		seq_puts(seq, "demotion[--] ");
 
-		seq_printf(seq, "latency[%03d] usage[%08d] duration[%020llu]\n",
+		seq_printf(seq, "latency[%03d] usage[%08d] duration[%020Lu]\n",
 			   pr->power.states[i].latency,
 			   pr->power.states[i].usage,
-			   (unsigned long long)pr->power.states[i].time);
+			   us_to_pm_timer_ticks(pr->power.states[i].time));
 	}
 
       end:
@@ -861,7 +861,6 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	ktime_t  kt1, kt2;
 	s64 idle_time_ns;
 	s64 idle_time;
-	s64 sleep_ticks = 0;
 
 	pr = __get_cpu_var(processors);
 
@@ -906,8 +905,6 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	idle_time = idle_time_ns;
 	do_div(idle_time, NSEC_PER_USEC);
 
-	sleep_ticks = us_to_pm_timer_ticks(idle_time);
-
 	/* Tell the scheduler how much we idled: */
 	sched_clock_idle_wakeup_event(idle_time_ns);
 
@@ -918,7 +915,7 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	cx->usage++;
 
 	lapic_timer_state_broadcast(pr, cx, 0);
-	cx->time += sleep_ticks;
+	cx->time += idle_time;
 	return idle_time;
 }
 
@@ -940,7 +937,6 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	ktime_t  kt1, kt2;
 	s64 idle_time_ns;
 	s64 idle_time;
-	s64 sleep_ticks = 0;
 
 
 	pr = __get_cpu_var(processors);
@@ -1026,7 +1022,6 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	idle_time = idle_time_ns;
 	do_div(idle_time, NSEC_PER_USEC);
 
-	sleep_ticks = us_to_pm_timer_ticks(idle_time);
 	/* Tell the scheduler how much we idled: */
 	sched_clock_idle_wakeup_event(idle_time_ns);
 
@@ -1037,7 +1032,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	cx->usage++;
 
 	lapic_timer_state_broadcast(pr, cx, 0);
-	cx->time += sleep_ticks;
+	cx->time += idle_time;
 	return idle_time;
 }
 

commit 157317ba3ec3e5a4d9683b8d24ba40b4f8f3296b
Author: Zhao Yakui <yakui.zhao@intel.com>
Date:   Wed Jun 2 11:04:09 2010 +0800

    ACPI: Fix the incorrect calculation about C-state idle time
    
    The C-state idle time is not calculated correctly, which will return the wrong
    residency time in C-state. It will have the following effects:
       1.  The system can't choose the deeper C-state when it is idle next time.
    Of course the system power is increased. E.g. On one server machine about 40W
    idle power is increased.
       2.  The powertop shows that it will stay in C0 running state about 95% time
    although the system is idle at most time.
    
    2.6.35-rc1 regression caused-by: 2da513f582a96c053aacc2c92873978d2ea7abff
    (ACPI: Minor cleanup eliminating redundant PMTIMER_TICKS to NS conversion)
    
    Signed-off-by: Zhao Yakui <yakui.zhao@intel.com>
    Reported-by: Yu Zhidong <zhidong.yu@intel.com>
    Tested-by: Yu Zhidong <zhidong.yu@intel.com>
    Acked-by: Venkatesh Pallipadi <venki@google.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 2e8c27d48f2b..6b38a6b43ce8 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1022,7 +1022,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		spin_unlock(&c3_lock);
 	}
 	kt2 = ktime_get_real();
-	idle_time_ns = ktime_to_us(ktime_sub(kt2, kt1));
+	idle_time_ns = ktime_to_ns(ktime_sub(kt2, kt1));
 	idle_time = idle_time_ns;
 	do_div(idle_time, NSEC_PER_USEC);
 

commit e4f2e5eaac8f5f903ca4a8cc944d26e68745d6bb
Merge: 9a90e09854a3 2671717265ae
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 28 16:14:17 2010 -0700

    Merge branch 'idle-release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-idle-2.6
    
    * 'idle-release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-idle-2.6:
      intel_idle: native hardware cpuidle driver for latest Intel processors
      ACPI: acpi_idle: touch TS_POLLING only in the non-MWAIT case
      acpi_pad: uses MONITOR/MWAIT, so it doesn't need to clear TS_POLLING
      sched: clarify commment for TS_POLLING
      ACPI: allow a native cpuidle driver to displace ACPI
      cpuidle: make cpuidle_curr_driver static
      cpuidle: add cpuidle_unregister_driver() error check
      cpuidle: fail to register if !CONFIG_CPU_IDLE

commit 9a90e09854a3c7cc603ab8fc9163f77bb1f66cfa
Merge: d372e7fe4698 d3b383338f10
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 28 14:42:18 2010 -0700

    Merge branch 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-acpi-2.6
    
    * 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-acpi-2.6: (27 commits)
      ACPI: Don't let acpi_pad needlessly mark TSC unstable
      drivers/acpi/sleep.h: Checkpatch cleanup
      ACPI: Minor cleanup eliminating redundant PMTIMER_TICKS to NS conversion
      ACPI: delete unused c-state promotion/demotion data strucutures
      ACPI: video: fix acpi_backlight=video
      ACPI: EC: Use kmemdup
      drivers/acpi: use kasprintf
      ACPI, APEI, EINJ injection parameters support
      Add x64 support to debugfs
      ACPI, APEI, Use ERST for persistent storage of MCE
      ACPI, APEI, Error Record Serialization Table (ERST) support
      ACPI, APEI, Generic Hardware Error Source memory error support
      ACPI, APEI, UEFI Common Platform Error Record (CPER) header
      Unified UUID/GUID definition
      ACPI Hardware Error Device (PNP0C33) support
      ACPI, APEI, PCIE AER, use general HEST table parsing in AER firmware_first setup
      ACPI, APEI, Document for APEI
      ACPI, APEI, EINJ support
      ACPI, APEI, HEST table parsing
      ACPI, APEI, APEI supporting infrastructure
      ...

commit 2da513f582a96c053aacc2c92873978d2ea7abff
Author: Venkatesh Pallipadi <venki@google.com>
Date:   Thu Apr 22 16:48:33 2010 -0700

    ACPI: Minor cleanup eliminating redundant PMTIMER_TICKS to NS conversion
    
    acpi_enter_[simple,bm] does
    idle timing in ns, convert it to timeval, then to us, then to
    pmtimer_ticks and then back to ns.
    
    This patch changes things to
    idle timing in ns, convert it to us, and then to pmtimer_ticks.
    
    Just saves an imul along this path, but makes the code cleaner.
    
    Signed-off-by: Venkatesh Pallipadi <venki@google.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 63a3d4b8c238..43fe52f9834b 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -859,6 +859,7 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	struct acpi_processor *pr;
 	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
 	ktime_t  kt1, kt2;
+	s64 idle_time_ns;
 	s64 idle_time;
 	s64 sleep_ticks = 0;
 
@@ -900,12 +901,14 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	sched_clock_idle_sleep_event();
 	acpi_idle_do_entry(cx);
 	kt2 = ktime_get_real();
-	idle_time =  ktime_to_us(ktime_sub(kt2, kt1));
+	idle_time_ns = ktime_to_ns(ktime_sub(kt2, kt1));
+	idle_time = idle_time_ns;
+	do_div(idle_time, NSEC_PER_USEC);
 
 	sleep_ticks = us_to_pm_timer_ticks(idle_time);
 
 	/* Tell the scheduler how much we idled: */
-	sched_clock_idle_wakeup_event(sleep_ticks*PM_TIMER_TICK_NS);
+	sched_clock_idle_wakeup_event(idle_time_ns);
 
 	local_irq_enable();
 	current_thread_info()->status |= TS_POLLING;
@@ -933,6 +936,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	struct acpi_processor *pr;
 	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
 	ktime_t  kt1, kt2;
+	s64 idle_time_ns;
 	s64 idle_time;
 	s64 sleep_ticks = 0;
 
@@ -1015,11 +1019,13 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		spin_unlock(&c3_lock);
 	}
 	kt2 = ktime_get_real();
-	idle_time =  ktime_to_us(ktime_sub(kt2, kt1));
+	idle_time_ns = ktime_to_us(ktime_sub(kt2, kt1));
+	idle_time = idle_time_ns;
+	do_div(idle_time, NSEC_PER_USEC);
 
 	sleep_ticks = us_to_pm_timer_ticks(idle_time);
 	/* Tell the scheduler how much we idled: */
-	sched_clock_idle_wakeup_event(sleep_ticks*PM_TIMER_TICK_NS);
+	sched_clock_idle_wakeup_event(idle_time_ns);
 
 	local_irq_enable();
 	current_thread_info()->status |= TS_POLLING;

commit 02cf4f9808382af7265cafc33dc86ec5875526aa
Author: Len Brown <len.brown@intel.com>
Date:   Mon May 24 14:27:44 2010 -0400

    ACPI: acpi_idle: touch TS_POLLING only in the non-MWAIT case
    
    commit d306ebc28649b89877a22158fe0076f06cc46f60
    (ACPI: Be in TS_POLLING state during mwait based C-state entry)
    fixed an important power & performance issue where ACPI c2 and c3 C-states
    were clearing TS_POLLING even when using MWAIT (ACPI_STATE_FFH).
    That bug had been causing us to receive redundant scheduling interrups
    when we had already been woken up by MONITOR/MWAIT.
    
    Following up on that...
    
    In the MWAIT case, we don't have to subsequently
    check need_resched(), as that c heck was there
    for the TS_POLLING-clearing case.
    
    Note that not only does the cpuidle calling function
    already check need_resched() before calling us, the
    low-level entry into monitor/mwait calls it twice --
    guaranteeing that a write to the trigger address
    can not go un-noticed.
    
    Also, in this case, we don't have to set TS_POLLING
    when we wake, because we never cleared it.
    
    Signed-off-by: Len Brown <len.brown@intel.com>
    Acked-by: Venkatesh Pallipadi <venki@google.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 5939e7f7d8e9..a4166e2abb92 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -881,6 +881,7 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 		return(acpi_idle_enter_c1(dev, state));
 
 	local_irq_disable();
+
 	if (cx->entry_method != ACPI_CSTATE_FFH) {
 		current_thread_info()->status &= ~TS_POLLING;
 		/*
@@ -888,12 +889,12 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 		 * NEED_RESCHED:
 		 */
 		smp_mb();
-	}
 
-	if (unlikely(need_resched())) {
-		current_thread_info()->status |= TS_POLLING;
-		local_irq_enable();
-		return 0;
+		if (unlikely(need_resched())) {
+			current_thread_info()->status |= TS_POLLING;
+			local_irq_enable();
+			return 0;
+		}
 	}
 
 	/*
@@ -918,7 +919,8 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	sched_clock_idle_wakeup_event(sleep_ticks*PM_TIMER_TICK_NS);
 
 	local_irq_enable();
-	current_thread_info()->status |= TS_POLLING;
+	if (cx->entry_method != ACPI_CSTATE_FFH)
+		current_thread_info()->status |= TS_POLLING;
 
 	cx->usage++;
 
@@ -968,6 +970,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	}
 
 	local_irq_disable();
+
 	if (cx->entry_method != ACPI_CSTATE_FFH) {
 		current_thread_info()->status &= ~TS_POLLING;
 		/*
@@ -975,12 +978,12 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		 * NEED_RESCHED:
 		 */
 		smp_mb();
-	}
 
-	if (unlikely(need_resched())) {
-		current_thread_info()->status |= TS_POLLING;
-		local_irq_enable();
-		return 0;
+		if (unlikely(need_resched())) {
+			current_thread_info()->status |= TS_POLLING;
+			local_irq_enable();
+			return 0;
+		}
 	}
 
 	acpi_unlazy_tlb(smp_processor_id());
@@ -1032,7 +1035,8 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	sched_clock_idle_wakeup_event(sleep_ticks*PM_TIMER_TICK_NS);
 
 	local_irq_enable();
-	current_thread_info()->status |= TS_POLLING;
+	if (cx->entry_method != ACPI_CSTATE_FFH)
+		current_thread_info()->status |= TS_POLLING;
 
 	cx->usage++;
 

commit 34a18d6fe5430184e4ca96eeb074ee671d89fe7b
Author: Len Brown <len.brown@intel.com>
Date:   Fri May 21 19:40:02 2010 -0400

    ACPI: delete unused c-state promotion/demotion data strucutures
    
    These were used before cpuidle by the native ACPI idle driver,
    which tracked promotion and demotion between states.
    
    The code was referenced by CONFIG_ACPI_PROCFS
    for /proc/acpi/processor/*/power,
    but as we no longer do promotion/demotion, that
    reference has been a NOP since the transition.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 5939e7f7d8e9..63a3d4b8c238 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -727,19 +727,9 @@ static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
 			break;
 		}
 
-		if (pr->power.states[i].promotion.state)
-			seq_printf(seq, "promotion[C%zd] ",
-				   (pr->power.states[i].promotion.state -
-				    pr->power.states));
-		else
-			seq_puts(seq, "promotion[--] ");
-
-		if (pr->power.states[i].demotion.state)
-			seq_printf(seq, "demotion[C%zd] ",
-				   (pr->power.states[i].demotion.state -
-				    pr->power.states));
-		else
-			seq_puts(seq, "demotion[--] ");
+		seq_puts(seq, "promotion[--] ");
+
+		seq_puts(seq, "demotion[--] ");
 
 		seq_printf(seq, "latency[%03d] usage[%08d] duration[%020llu]\n",
 			   pr->power.states[i].latency,

commit ed77134bfccf5e75b6cbadab268e559dbe6a4ebb
Author: Mark Gross <mgross@linux.intel.com>
Date:   Thu May 6 01:59:26 2010 +0200

    PM QOS update
    
    This patch changes the string based list management to a handle base
    implementation to help with the hot path use of pm-qos, it also renames
    much of the API to use "request" as opposed to "requirement" that was
    used in the initial implementation.  I did this because request more
    accurately represents what it actually does.
    
    Also, I added a string based ABI for users wanting to use a string
    interface.  So if the user writes 0xDDDDDDDD formatted hex it will be
    accepted by the interface.  (someone asked me for it and I don't think
    it hurts anything.)
    
    This patch updates some documentation input I got from Randy.
    
    Signed-off-by: markgross <mgross@linux.intel.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 5939e7f7d8e9..c3817e1f32c7 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -698,7 +698,7 @@ static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
 		   "max_cstate:              C%d\n"
 		   "maximum allowed latency: %d usec\n",
 		   pr->power.state ? pr->power.state - pr->power.states : 0,
-		   max_cstate, pm_qos_requirement(PM_QOS_CPU_DMA_LATENCY));
+		   max_cstate, pm_qos_request(PM_QOS_CPU_DMA_LATENCY));
 
 	seq_puts(seq, "states:\n");
 

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 37dfce749398..5939e7f7d8e9 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -32,6 +32,7 @@
 #include <linux/module.h>
 #include <linux/init.h>
 #include <linux/cpufreq.h>
+#include <linux/slab.h>
 #include <linux/proc_fs.h>
 #include <linux/seq_file.h>
 #include <linux/acpi.h>

commit bc535154137601400ffe44c2a7be047ca041fe06
Merge: d03ab7ff335b 439913fffd39
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Mar 1 10:36:22 2010 -0800

    Merge branch 'acpica' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-acpi-2.6
    
    * 'acpica' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-acpi-2.6:
      ACPI: replace acpi_integer by u64
      ACPICA: Update version to 20100121.
      ACPICA: Remove unused uint32_struct type
      ACPICA: Disassembler: Remove obsolete "Integer64" field in parse object
      ACPICA: Remove obsolete ACPI_INTEGER (acpi_integer) type
      ACPICA: Predefined name repair: fix NULL package elements
      ACPICA: AcpiGetDevices: Eliminate unnecessary _STA calls
      ACPICA: Update all ACPICA copyrights and signons to 2010
      ACPICA: Update for new gcc-4 warning options

commit d306ebc28649b89877a22158fe0076f06cc46f60
Author: Pallipadi, Venkatesh <venkatesh.pallipadi@intel.com>
Date:   Wed Feb 10 10:35:31 2010 -0800

    ACPI: Be in TS_POLLING state during mwait based C-state entry
    
    ACPI deep C-state entry had a long standing bug/missing feature, wherein we were sending
    resched IPIs when an idle CPU is in mwait based deep C-state. Only mwait based C1 was using
    the write to the monitored address to wake up mwait'ing CPU.
    
    This patch changes the code to retain TS_POLLING bit if we are entering an mwait based
    deep C-state.
    
    The patch has been verified to reduce the number of resched IPIs in general and also
    improves the performance/power on workloads with low system utilization (i.e., when mwait based
    deep C-states are being used).
    
    Fixes "netperf ~50% regression with 2.6.33-rc1, bisect to 1b9508f"
    http://marc.info/?l=linux-kernel&m=126441481427331&w=4
    
    Reported-by: Lin Ming <ming.m.lin@intel.com>
    Tested-by: Alex Shi <alex.shi@intel.com>
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index e88e8ae04fdb..cc978a8c00b7 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -880,12 +880,14 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 		return(acpi_idle_enter_c1(dev, state));
 
 	local_irq_disable();
-	current_thread_info()->status &= ~TS_POLLING;
-	/*
-	 * TS_POLLING-cleared state must be visible before we test
-	 * NEED_RESCHED:
-	 */
-	smp_mb();
+	if (cx->entry_method != ACPI_CSTATE_FFH) {
+		current_thread_info()->status &= ~TS_POLLING;
+		/*
+		 * TS_POLLING-cleared state must be visible before we test
+		 * NEED_RESCHED:
+		 */
+		smp_mb();
+	}
 
 	if (unlikely(need_resched())) {
 		current_thread_info()->status |= TS_POLLING;
@@ -965,12 +967,14 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	}
 
 	local_irq_disable();
-	current_thread_info()->status &= ~TS_POLLING;
-	/*
-	 * TS_POLLING-cleared state must be visible before we test
-	 * NEED_RESCHED:
-	 */
-	smp_mb();
+	if (cx->entry_method != ACPI_CSTATE_FFH) {
+		current_thread_info()->status &= ~TS_POLLING;
+		/*
+		 * TS_POLLING-cleared state must be visible before we test
+		 * NEED_RESCHED:
+		 */
+		smp_mb();
+	}
 
 	if (unlikely(need_resched())) {
 		current_thread_info()->status |= TS_POLLING;

commit 370d5cd88509b93b76eb2f5f97efbd71c25061cb
Author: Arjan van de Ven <arjan@linux.intel.com>
Date:   Wed Jan 27 15:25:39 2010 -0800

    ACPI: fix High cpu temperature with 2.6.32
    
    Since the rewrite of the CPU idle governor in 2.6.32, two laptops have
    surfaced where the BIOS advertises a C2 power state, but for some reason
    this state is not functioning (as verified in both cases by powertop
    before the patch in .32).
    
    The old governor had the accidental behavior that if a non-working state
    was chosen too many times, it would end up falling back to C1.  The new
    governor works differently and this accidental behavior is no longer
    there; the result is a high temperature on these two machines.
    
    This patch adds these 2 machines to the DMI table for C state anomalies;
    by just not using C2 both these machines are better off (the TSC can be
    used instead of the pm timer, giving a performance boost for example).
    
    Addresses http://bugzilla.kernel.org/show_bug.cgi?id=14742
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Reported-by: <akwatts@ymail.com>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 7c0441f63b39..e88e8ae04fdb 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -110,6 +110,14 @@ static struct dmi_system_id __cpuinitdata processor_power_dmi_table[] = {
 	  DMI_MATCH(DMI_BIOS_VENDOR,"Phoenix Technologies LTD"),
 	  DMI_MATCH(DMI_BIOS_VERSION,"SHE845M0.86C.0013.D.0302131307")},
 	 (void *)2},
+	{ set_max_cstate, "Pavilion zv5000", {
+	  DMI_MATCH(DMI_SYS_VENDOR, "Hewlett-Packard"),
+	  DMI_MATCH(DMI_PRODUCT_NAME,"Pavilion zv5000 (DS502A#ABA)")},
+	 (void *)1},
+	{ set_max_cstate, "Asus L8400B", {
+	  DMI_MATCH(DMI_SYS_VENDOR, "ASUSTeK Computer Inc."),
+	  DMI_MATCH(DMI_PRODUCT_NAME,"L8400B series Notebook PC")},
+	 (void *)1},
 	{},
 };
 

commit 439913fffd39374c3737186b22d2d56c3a0ae526
Author: Lin Ming <ming.m.lin@intel.com>
Date:   Thu Jan 28 10:53:19 2010 +0800

    ACPI: replace acpi_integer by u64
    
    acpi_integer is now obsolete and removed from the ACPICA code base,
    replaced by u64.
    
    Signed-off-by: Lin Ming <ming.m.lin@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 7c0441f63b39..3455d7abf5f3 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -352,7 +352,7 @@ static int acpi_processor_get_power_info_default(struct acpi_processor *pr)
 static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 {
 	acpi_status status = 0;
-	acpi_integer count;
+	u64 count;
 	int current_count;
 	int i;
 	struct acpi_buffer buffer = { ACPI_ALLOCATE_BUFFER, NULL };

commit d22edd293ff3f1e2d252f164fe2cf744620cb660
Author: Len Brown <len.brown@intel.com>
Date:   Tue Jan 19 23:29:09 2010 -0500

    ACPI: delete acpi_processor_power_verify_c2()
    
    no functional change -- cleanup only.
    
    acpi_processor_power_verify_c2() was nearly empty due to a previous patch,
    so expand its remains into its one caller and delete it.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 2c543b42eb1c..7c0441f63b39 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -516,23 +516,6 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 	return status;
 }
 
-static void acpi_processor_power_verify_c2(struct acpi_processor_cx *cx)
-{
-
-	if (!cx->address)
-		return;
-
-	/*
-	 * Otherwise we've met all of our C2 requirements.
-	 * Normalize the C2 latency to expidite policy
-	 */
-	cx->valid = 1;
-
-	cx->latency_ticks = cx->latency;
-
-	return;
-}
-
 static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 					   struct acpi_processor_cx *cx)
 {
@@ -631,7 +614,10 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 			break;
 
 		case ACPI_STATE_C2:
-			acpi_processor_power_verify_c2(cx);
+			if (!cx->address)
+				break;
+			cx->valid = 1; 
+			cx->latency_ticks = cx->latency; /* Normalize latency */
 			break;
 
 		case ACPI_STATE_C3:

commit a6d72c189f6c4292ba1a323e8af24083790529f8
Author: Len Brown <len.brown@intel.com>
Date:   Tue Jan 19 23:10:04 2010 -0500

    ACPI: allow C3 > 1000usec
    
    Do for C3 what the previous patch did for C2.
    
    The C2 patch was in response to a highly visible
    and multiply reported C-state/turbo failure,
    while this change has no bug report in-hand.
    
    This will enable C3 in Linux on systems where BIOS
    overstates C3 latency in _CST.  It will also enable
    future systems which may actually have C3 > 1000usec.
    
    Linux has always ignored ACPI BIOS C3 with exit latency > 1000 usec,
    and the ACPI spec is clear that is correct FADT-supplied C3.
    
    However, the ACPI spec explicitly states that _CST-supplied C-states
    have no latency limits.
    
    So move the 1000usec C3 test out of the code shared
    by FADT and _CST code-paths, and into the FADT-specific path.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 8f6da9acc8e4..2c543b42eb1c 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -316,6 +316,17 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 		pr->power.states[ACPI_STATE_C2].address = 0;
 	}
 
+	/*
+	 * FADT supplied C3 latency must be less than or equal to
+	 * 1000 microseconds.
+	 */
+	if (acpi_gbl_FADT.C3latency > ACPI_PROCESSOR_MAX_C3_LATENCY) {
+		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
+			"C3 latency too large [%d]\n", acpi_gbl_FADT.C3latency));
+		/* invalidate C3 */
+		pr->power.states[ACPI_STATE_C3].address = 0;
+	}
+
 	ACPI_DEBUG_PRINT((ACPI_DB_INFO,
 			  "lvl2[0x%08x] lvl3[0x%08x]\n",
 			  pr->power.states[ACPI_STATE_C2].address,
@@ -532,16 +543,6 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 	if (!cx->address)
 		return;
 
-	/*
-	 * C3 latency must be less than or equal to 1000
-	 * microseconds.
-	 */
-	else if (cx->latency > ACPI_PROCESSOR_MAX_C3_LATENCY) {
-		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
-				  "latency too large [%d]\n", cx->latency));
-		return;
-	}
-
 	/*
 	 * PIIX4 Erratum #18: We don't support C3 when Type-F (fast)
 	 * DMA transfers are used by any ISA device to avoid livelock.

commit 5d76b6f6c17572e662f5c99c2023adae92100855
Author: Len Brown <len.brown@intel.com>
Date:   Tue Jan 19 22:41:14 2010 -0500

    ACPI: enable C2 and Turbo-mode on Nehalem notebooks on A/C
    
    Linux has always ignored ACPI BIOS C2 with exit latency > 100 usec,
    and the ACPI spec is clear that is correct FADT-supplied C2.
    
    However, the ACPI spec explicitly states that _CST-supplied C-states
    have no latency limits.
    
    So move the 100usec C2 test out of the code shared
    by FADT and _CST code-paths, and into the FADT-specific path.
    
    This bug has not been visible until Nehalem, which advertises
    a CPU-C2 worst case exit latency on servers of 205usec.
    That (incorrect) figure is being used by BIOS writers
    on mobile Nehalem systems for the AC configuration.
    Thus, Linux ignores C2 leaving just C1, which is
    saves less power, and also impacts performance
    by preventing the use of turbo mode.
    
    http://bugzilla.kernel.org/show_bug.cgi?id=15064
    
    Tested-by: Alex Chiang <achiang@hp.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index d1676b1754d9..8f6da9acc8e4 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -305,6 +305,17 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 	pr->power.states[ACPI_STATE_C2].latency = acpi_gbl_FADT.C2latency;
 	pr->power.states[ACPI_STATE_C3].latency = acpi_gbl_FADT.C3latency;
 
+	/*
+	 * FADT specified C2 latency must be less than or equal to
+	 * 100 microseconds.
+	 */
+	if (acpi_gbl_FADT.C2latency > ACPI_PROCESSOR_MAX_C2_LATENCY) {
+		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
+			"C2 latency too large [%d]\n", acpi_gbl_FADT.C2latency));
+		/* invalidate C2 */
+		pr->power.states[ACPI_STATE_C2].address = 0;
+	}
+
 	ACPI_DEBUG_PRINT((ACPI_DB_INFO,
 			  "lvl2[0x%08x] lvl3[0x%08x]\n",
 			  pr->power.states[ACPI_STATE_C2].address,
@@ -500,16 +511,6 @@ static void acpi_processor_power_verify_c2(struct acpi_processor_cx *cx)
 	if (!cx->address)
 		return;
 
-	/*
-	 * C2 latency must be less than or equal to 100
-	 * microseconds.
-	 */
-	else if (cx->latency > ACPI_PROCESSOR_MAX_C2_LATENCY) {
-		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
-				  "latency too large [%d]\n", cx->latency));
-		return;
-	}
-
 	/*
 	 * Otherwise we've met all of our C2 requirements.
 	 * Normalize the C2 latency to expidite policy

commit 918aae42aa9b611a3663b16ae849fdedc67c2292
Author: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
Date:   Mon Dec 14 17:10:06 2009 +0900

    ACPI: fix for lapic_timer_propagate_broadcast()
    
    I got following warning on ia64 box:
      In function 'acpi_processor_power_verify':
      642: warning: passing argument 2 of 'smp_call_function_single' from
      incompatible pointer type
    
    This smp_call_function_single() was introduced by a commit
    f833bab87fca5c3ce13778421b1365845843b976:
    
     > @@ -162,8 +162,9 @@
     >               pr->power.timer_broadcast_on_state = state;
     >  }
     >
     > -static void lapic_timer_propagate_broadcast(struct acpi_processor *pr)
     > +static void lapic_timer_propagate_broadcast(void *arg)
     >  {
     > +       struct acpi_processor *pr = (struct acpi_processor *) arg;
     >         unsigned long reason;
     >
     >         reason = pr->power.timer_broadcast_on_state < INT_MAX ?
     > @@ -635,7 +636,8 @@
     >                 working++;
     >         }
     >
     > -       lapic_timer_propagate_broadcast(pr);
     > +       smp_call_function_single(pr->id, lapic_timer_propagate_broadcast,
     > +                                pr, 1);
     >
     >         return (working);
     >  }
    
    The problem is that the lapic_timer_propagate_broadcast() has 2 versions:
    One is real code that modified in the above commit, and the other is NOP
    code that used when !ARCH_APICTIMER_STOPS_ON_C3:
    
      static void lapic_timer_propagate_broadcast(struct acpi_processor *pr) { }
    
    So I got warning because of !ARCH_APICTIMER_STOPS_ON_C3.
    
    We really want to do nothing here on !ARCH_APICTIMER_STOPS_ON_C3, so
    modify lapic_timer_propagate_broadcast() of real version to use
    smp_call_function_single() in it.
    
    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Acked-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index bbd066e7f854..d1676b1754d9 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -164,7 +164,7 @@ static void lapic_timer_check_state(int state, struct acpi_processor *pr,
 		pr->power.timer_broadcast_on_state = state;
 }
 
-static void lapic_timer_propagate_broadcast(void *arg)
+static void __lapic_timer_propagate_broadcast(void *arg)
 {
 	struct acpi_processor *pr = (struct acpi_processor *) arg;
 	unsigned long reason;
@@ -175,6 +175,12 @@ static void lapic_timer_propagate_broadcast(void *arg)
 	clockevents_notify(reason, &pr->id);
 }
 
+static void lapic_timer_propagate_broadcast(struct acpi_processor *pr)
+{
+	smp_call_function_single(pr->id, __lapic_timer_propagate_broadcast,
+				 (void *)pr, 1);
+}
+
 /* Power(C) State timer broadcast control */
 static void lapic_timer_state_broadcast(struct acpi_processor *pr,
 				       struct acpi_processor_cx *cx,
@@ -638,8 +644,7 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 		working++;
 	}
 
-	smp_call_function_single(pr->id, lapic_timer_propagate_broadcast,
-				 pr, 1);
+	lapic_timer_propagate_broadcast(pr);
 
 	return (working);
 }

commit 569ec4cc779c8aae03a4659939d08822c9e4a242
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Sep 27 11:58:36 2009 -0700

    ACPI: kill "unused variable ‘i’" warning
    
    Commit 3d5b6fb47a8e68fa311ca2c3447e7f8a7c3a9cf3 ("ACPI: Kill overly
    verbose "power state" log messages") removed the actual use of this
    variable, but didn't remove the variable itself, resulting in build
    warnings like
    
      drivers/acpi/processor_idle.c: In function ‘acpi_processor_power_init’:
      drivers/acpi/processor_idle.c:1169: warning: unused variable ‘i’
    
    Just get rid of the now unused variable.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 706eacf49f4e..bbd066e7f854 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1166,7 +1166,6 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 #ifdef CONFIG_ACPI_PROCFS
 	struct proc_dir_entry *entry = NULL;
 #endif
-	unsigned int i;
 
 	if (boot_option_idle_override)
 		return 0;

commit 3d5b6fb47a8e68fa311ca2c3447e7f8a7c3a9cf3
Author: Roland Dreier <rdreier@cisco.com>
Date:   Thu Sep 24 14:52:36 2009 -0700

    ACPI: Kill overly verbose "power state" log messages
    
    I was recently lucky enough to get a 64-CPU system, so my kernel log
    ends up with 64 lines like:
    
        ACPI: CPU0 (power states: C1[C1] C2[C3])
    
    This is pretty useless clutter because this info is already available
    after boot from both /sys/devices/system/cpu/cpu*/cpuidle/state?/ as
    well as /proc/acpi/processor/CPU*/power.
    
    So just delete the code that prints the C-states in processor_idle.c.
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index cc61a6220102..706eacf49f4e 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1214,13 +1214,6 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 		acpi_processor_setup_cpuidle(pr);
 		if (cpuidle_register_device(&pr->power.dev))
 			return -EIO;
-
-		printk(KERN_INFO PREFIX "CPU%d (power states:", pr->id);
-		for (i = 1; i <= pr->power.count; i++)
-			if (pr->power.states[i].valid)
-				printk(" C%d[C%d]", i,
-				       pr->power.states[i].type);
-		printk(")\n");
 	}
 #ifdef CONFIG_ACPI_PROCFS
 	/* 'power' [R] */

commit cbeee13570adfb0af494a07074958e4888c2351c
Merge: 7ef0143e2f89 b188e4ce3b79
Author: Len Brown <len.brown@intel.com>
Date:   Sat Sep 19 02:10:40 2009 -0400

    Merge branch 'processor-procfs-2.6.32' into release

commit a192a9580bcc41692be1f36b77c3b681827f566a
Author: Len Brown <len.brown@intel.com>
Date:   Tue Jul 28 16:45:54 2009 -0400

    ACPI: Move definition of PREFIX from acpi_bus.h to internal..h
    
    Linux/ACPI core files using internal.h all PREFIX "ACPI: ",
    however, not all ACPI drivers use/want it -- and they
    should not have to #undef PREFIX to define their own.
    
    Add GPL commment to internal.h while we are there.
    
    This does not change any actual console output,
    asside from a whitespace fix.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 66393d5c4c7c..22aab1fc9b45 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -60,6 +60,8 @@
 #include <acpi/processor.h>
 #include <asm/processor.h>
 
+#define PREFIX "ACPI: "
+
 #define ACPI_PROCESSOR_CLASS            "processor"
 #define _COMPONENT              ACPI_PROCESSOR_COMPONENT
 ACPI_MODULE_NAME("processor_idle");

commit f833bab87fca5c3ce13778421b1365845843b976
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Mon Aug 17 14:34:59 2009 -0700

    clockevent: Prevent dead lock on clockevents_lock
    
    Currently clockevents_notify() is called with interrupts enabled at
    some places and interrupts disabled at some other places.
    
    This results in a deadlock in this scenario.
    
    cpu A holds clockevents_lock in clockevents_notify() with irqs enabled
    cpu B waits for clockevents_lock in clockevents_notify() with irqs disabled
    cpu C doing set_mtrr() which will try to rendezvous of all the cpus.
    
    This will result in C and A come to the rendezvous point and waiting
    for B. B is stuck forever waiting for the spinlock and thus not
    reaching the rendezvous point.
    
    Fix the clockevents code so that clockevents_lock is taken with
    interrupts disabled and thus avoid the above deadlock.
    
    Also call lapic_timer_propagate_broadcast() on the destination cpu so
    that we avoid calling smp_call_function() in the clockevents notifier
    chain.
    
    This issue left us wondering if we need to change the MTRR rendezvous
    logic to use stop machine logic (instead of smp_call_function) or add
    a check in spinlock debug code to see if there are other spinlocks
    which gets taken under both interrupts enabled/disabled conditions.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Cc: "Pallipadi Venkatesh" <venkatesh.pallipadi@intel.com>
    Cc: "Brown Len" <len.brown@intel.com>
    LKML-Reference: <1250544899.2709.210.camel@sbs-t61.sc.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 0efa59e7e3af..66393d5c4c7c 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -162,8 +162,9 @@ static void lapic_timer_check_state(int state, struct acpi_processor *pr,
 		pr->power.timer_broadcast_on_state = state;
 }
 
-static void lapic_timer_propagate_broadcast(struct acpi_processor *pr)
+static void lapic_timer_propagate_broadcast(void *arg)
 {
+	struct acpi_processor *pr = (struct acpi_processor *) arg;
 	unsigned long reason;
 
 	reason = pr->power.timer_broadcast_on_state < INT_MAX ?
@@ -635,7 +636,8 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 		working++;
 	}
 
-	lapic_timer_propagate_broadcast(pr);
+	smp_call_function_single(pr->id, lapic_timer_propagate_broadcast,
+				 pr, 1);
 
 	return (working);
 }

commit b188e4ce3b7965ecc8d45191042cc9d25f6b90ee
Author: Len Brown <len.brown@intel.com>
Date:   Wed Jun 24 01:48:32 2009 -0400

    ACPI: fix CONFIG_ACPI_PROCFS=n build warning
    
    drivers/acpi/processor_idle.c:1162: warning: unused variable ‘entry’
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 67b2fa1b5b63..b85d9f022716 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1160,7 +1160,9 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 {
 	acpi_status status = 0;
 	static int first_run;
+#ifdef CONFIG_ACPI_PROCFS
 	struct proc_dir_entry *entry = NULL;
+#endif
 	unsigned int i;
 
 	if (boot_option_idle_override)

commit fbe8cddd2d85979d273d7937a2b8a47498694d91
Merge: 4e8a2372f925 e86435eb91b2 7fe2a6c275a5 0705495d9010 35a7c64fbc77 152a4e630f7f 86e437f077c6 c8d72a5e7698 7a04b8491a07 ee1ca48fae7e 9eccbc2f67ef 7e275cc4e8e2 7b768f07dce4 8cb24c8fd70e 113b3a2b9015 d73772474f6e 056c308d3e48 871043bc463e
Author: Len Brown <len.brown@intel.com>
Date:   Wed Jun 24 01:19:50 2009 -0400

    Merge branches 'acerhdf', 'acpi-pci-bind', 'bjorn-pci-root', 'bugzilla-12904', 'bugzilla-13121', 'bugzilla-13396', 'bugzilla-13533', 'bugzilla-13612', 'c3_lock', 'hid-cleanups', 'misc-2.6.31', 'pdc-leak-fix', 'pnpacpi', 'power_nocheck', 'thinkpad_acpi', 'video' and 'wmi' into release

commit 74cad4ee9839669ad920257678ea0bf0a818cd3b
Author: Zhao Yakui <yakui.zhao@intel.com>
Date:   Wed Jun 24 11:49:49 2009 +0800

    ACPI: Make ACPI processor proc I/F depend on the ACPI_PROCFS
    
    Now whether the ACPI processor proc I/F is registered depends on the
    CONFIG_PROC. It had better depend on the CONFIG_ACPI_PROCFS.
    When the CONFIG_ACPI_PROCFS is unset in kernel configuration, the
    ACPI processor proc I/F won't be registered.
    
    Signed-off-by: Zhao Yakui <yakui.zhao@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 10a2d913635a..67b2fa1b5b63 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -679,6 +679,7 @@ static int acpi_processor_get_power_info(struct acpi_processor *pr)
 	return 0;
 }
 
+#ifdef CONFIG_ACPI_PROCFS
 static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
 {
 	struct acpi_processor *pr = seq->private;
@@ -758,7 +759,7 @@ static const struct file_operations acpi_processor_power_fops = {
 	.llseek = seq_lseek,
 	.release = single_release,
 };
-
+#endif
 
 /**
  * acpi_idle_bm_check - checks if bus master activity was detected
@@ -1216,7 +1217,7 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 				       pr->power.states[i].type);
 		printk(")\n");
 	}
-
+#ifdef CONFIG_ACPI_PROCFS
 	/* 'power' [R] */
 	entry = proc_create_data(ACPI_PROCESSOR_FILE_POWER,
 				 S_IRUGO, acpi_device_dir(device),
@@ -1224,6 +1225,7 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 				 acpi_driver_data(device));
 	if (!entry)
 		return -EIO;
+#endif
 	return 0;
 }
 
@@ -1236,9 +1238,11 @@ int acpi_processor_power_exit(struct acpi_processor *pr,
 	cpuidle_unregister_device(&pr->power.dev);
 	pr->flags.power_setup_done = 0;
 
+#ifdef CONFIG_ACPI_PROCFS
 	if (acpi_device_dir(device))
 		remove_proc_entry(ACPI_PROCESSOR_FILE_POWER,
 				  acpi_device_dir(device));
+#endif
 
 	return 0;
 }

commit 7e275cc4e8e20f82740bf40ae2f5695e9e35ff09
Author: Len Brown <len.brown@intel.com>
Date:   Fri May 15 02:08:44 2009 -0400

    ACPI: idle: rename lapic timer workaround routines
    
    cosmetic only.  The lapic_timer workaround routines
    are specific to the lapic_timer, and are not acpi-generic.
    
    old:
    
    acpi_timer_check_state()
    acpi_propagate_timer_broadcast()
    acpi_state_timer_broadcast()
    
    new:
    
    lapic_timer_check_state()
    lapic_timer_propagate_broadcast()
    lapic_timer_state_broadcast()
    
    also, simplify the code in acpi_processor_power_verify()
    so that lapic_timer_check_state() is simply called
    from one place for all valid C-states, including C1.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 10a2d913635a..1f60ccbd4c39 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -139,7 +139,7 @@ static void acpi_safe_halt(void)
  * are affected too. We pick the most conservative approach: we assume
  * that the local APIC stops in both C2 and C3.
  */
-static void acpi_timer_check_state(int state, struct acpi_processor *pr,
+static void lapic_timer_check_state(int state, struct acpi_processor *pr,
 				   struct acpi_processor_cx *cx)
 {
 	struct acpi_processor_power *pwr = &pr->power;
@@ -162,7 +162,7 @@ static void acpi_timer_check_state(int state, struct acpi_processor *pr,
 		pr->power.timer_broadcast_on_state = state;
 }
 
-static void acpi_propagate_timer_broadcast(struct acpi_processor *pr)
+static void lapic_timer_propagate_broadcast(struct acpi_processor *pr)
 {
 	unsigned long reason;
 
@@ -173,7 +173,7 @@ static void acpi_propagate_timer_broadcast(struct acpi_processor *pr)
 }
 
 /* Power(C) State timer broadcast control */
-static void acpi_state_timer_broadcast(struct acpi_processor *pr,
+static void lapic_timer_state_broadcast(struct acpi_processor *pr,
 				       struct acpi_processor_cx *cx,
 				       int broadcast)
 {
@@ -190,10 +190,10 @@ static void acpi_state_timer_broadcast(struct acpi_processor *pr,
 
 #else
 
-static void acpi_timer_check_state(int state, struct acpi_processor *pr,
+static void lapic_timer_check_state(int state, struct acpi_processor *pr,
 				   struct acpi_processor_cx *cstate) { }
-static void acpi_propagate_timer_broadcast(struct acpi_processor *pr) { }
-static void acpi_state_timer_broadcast(struct acpi_processor *pr,
+static void lapic_timer_propagate_broadcast(struct acpi_processor *pr) { }
+static void lapic_timer_state_broadcast(struct acpi_processor *pr,
 				       struct acpi_processor_cx *cx,
 				       int broadcast)
 {
@@ -614,29 +614,25 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 		switch (cx->type) {
 		case ACPI_STATE_C1:
 			cx->valid = 1;
-			acpi_timer_check_state(i, pr, cx);
 			break;
 
 		case ACPI_STATE_C2:
 			acpi_processor_power_verify_c2(cx);
-			if (cx->valid)
-				acpi_timer_check_state(i, pr, cx);
 			break;
 
 		case ACPI_STATE_C3:
 			acpi_processor_power_verify_c3(pr, cx);
-			if (cx->valid)
-				acpi_timer_check_state(i, pr, cx);
 			break;
 		}
-		if (cx->valid)
-			tsc_check_state(cx->type);
+		if (!cx->valid)
+			continue;
 
-		if (cx->valid)
-			working++;
+		lapic_timer_check_state(i, pr, cx);
+		tsc_check_state(cx->type);
+		working++;
 	}
 
-	acpi_propagate_timer_broadcast(pr);
+	lapic_timer_propagate_broadcast(pr);
 
 	return (working);
 }
@@ -839,7 +835,7 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 		return 0;
 	}
 
-	acpi_state_timer_broadcast(pr, cx, 1);
+	lapic_timer_state_broadcast(pr, cx, 1);
 	kt1 = ktime_get_real();
 	acpi_idle_do_entry(cx);
 	kt2 = ktime_get_real();
@@ -847,7 +843,7 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 
 	local_irq_enable();
 	cx->usage++;
-	acpi_state_timer_broadcast(pr, cx, 0);
+	lapic_timer_state_broadcast(pr, cx, 0);
 
 	return idle_time;
 }
@@ -892,7 +888,7 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	 * Must be done before busmaster disable as we might need to
 	 * access HPET !
 	 */
-	acpi_state_timer_broadcast(pr, cx, 1);
+	lapic_timer_state_broadcast(pr, cx, 1);
 
 	if (cx->type == ACPI_STATE_C3)
 		ACPI_FLUSH_CPU_CACHE();
@@ -914,7 +910,7 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 
 	cx->usage++;
 
-	acpi_state_timer_broadcast(pr, cx, 0);
+	lapic_timer_state_broadcast(pr, cx, 0);
 	cx->time += sleep_ticks;
 	return idle_time;
 }
@@ -981,7 +977,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	 * Must be done before busmaster disable as we might need to
 	 * access HPET !
 	 */
-	acpi_state_timer_broadcast(pr, cx, 1);
+	lapic_timer_state_broadcast(pr, cx, 1);
 
 	kt1 = ktime_get_real();
 	/*
@@ -1026,7 +1022,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 
 	cx->usage++;
 
-	acpi_state_timer_broadcast(pr, cx, 0);
+	lapic_timer_state_broadcast(pr, cx, 0);
 	cx->time += sleep_ticks;
 	return idle_time;
 }

commit ee1ca48fae7e575d5e399d4fdcfe0afc1212a64c
Author: Pallipadi, Venkatesh <venkatesh.pallipadi@intel.com>
Date:   Thu May 21 17:09:10 2009 -0700

    ACPI: Disable ARB_DISABLE on platforms where it is not needed
    
    ARB_DISABLE is a NOP on all of the recent Intel platforms.
    
    For such platforms, reduce contention on c3_lock
    by skipping the fake ARB_DISABLE.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 72069ba5f1ed..4840c79fd8e0 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -512,7 +512,8 @@ static void acpi_processor_power_verify_c2(struct acpi_processor_cx *cx)
 static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 					   struct acpi_processor_cx *cx)
 {
-	static int bm_check_flag;
+	static int bm_check_flag = -1;
+	static int bm_control_flag = -1;
 
 
 	if (!cx->address)
@@ -542,12 +543,14 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 	}
 
 	/* All the logic here assumes flags.bm_check is same across all CPUs */
-	if (!bm_check_flag) {
+	if (bm_check_flag == -1) {
 		/* Determine whether bm_check is needed based on CPU  */
 		acpi_processor_power_init_bm_check(&(pr->flags), pr->id);
 		bm_check_flag = pr->flags.bm_check;
+		bm_control_flag = pr->flags.bm_control;
 	} else {
 		pr->flags.bm_check = bm_check_flag;
+		pr->flags.bm_control = bm_control_flag;
 	}
 
 	if (pr->flags.bm_check) {

commit 7d60e8ab0d5507229dfbdf456501cc378610fa01
Author: Shaohua Li <shaohua.li@intel.com>
Date:   Tue May 19 16:09:54 2009 +0800

    cpuidle: fix AMD C1E suspend hang
    
    When AMD C1E is enabled, local APIC timer will stop even in C1. To avoid
    suspend/resume hang, this patch removes C1 and replace it with a cpu_relax() in
    suspend/resume path. This hasn't any impact in runtime path.
    
    http://bugzilla.kernel.org/show_bug.cgi?id=13233
    
    [ impact: avoid suspend/resume hang in AMD CPU with C1E enabled ]
    
    Tested-by: Dmitry Lyzhyn <thisistempbox@yahoo.com>
    Signed-off-by: Shaohua Li <shaohua.li@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 6b7bcc7e3e1d..10a2d913635a 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -834,8 +834,8 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 
 	/* Do not access any ACPI IO ports in suspend path */
 	if (acpi_idle_suspend) {
-		acpi_safe_halt();
 		local_irq_enable();
+		cpu_relax();
 		return 0;
 	}
 

commit 87ad57bacb25c3f24c54f142ef445f68277705f0
Author: Shaohua Li <shaohua.li@intel.com>
Date:   Tue May 19 16:09:42 2009 +0800

    cpuidle: makes AMD C1E work in acpi_idle
    
    When AMD C1E is enabled, local APIC timer will stop even in C1.
    This patch uses broadcast IPI to replace local APIC timer in C1.
    
    http://bugzilla.kernel.org/show_bug.cgi?id=13233
    
    [ impact: avoid boot hang in AMD CPU with C1E enabled ]
    
    Tested-by: Dmitry Lyzhyn <thisistempbox@yahoo.com>
    Signed-off-by: Shaohua Li <shaohua.li@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 72069ba5f1ed..6b7bcc7e3e1d 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -148,6 +148,9 @@ static void acpi_timer_check_state(int state, struct acpi_processor *pr,
 	if (cpu_has(&cpu_data(pr->id), X86_FEATURE_ARAT))
 		return;
 
+	if (boot_cpu_has(X86_FEATURE_AMDC1E))
+		type = ACPI_STATE_C1;
+
 	/*
 	 * Check, if one of the previous states already marked the lapic
 	 * unstable
@@ -611,6 +614,7 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 		switch (cx->type) {
 		case ACPI_STATE_C1:
 			cx->valid = 1;
+			acpi_timer_check_state(i, pr, cx);
 			break;
 
 		case ACPI_STATE_C2:
@@ -835,6 +839,7 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 		return 0;
 	}
 
+	acpi_state_timer_broadcast(pr, cx, 1);
 	kt1 = ktime_get_real();
 	acpi_idle_do_entry(cx);
 	kt2 = ktime_get_real();
@@ -842,6 +847,7 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 
 	local_irq_enable();
 	cx->usage++;
+	acpi_state_timer_broadcast(pr, cx, 0);
 
 	return idle_time;
 }

commit 4e3507f7189111b0cb66c30def3423c6aba8f85a
Merge: 7c7327d96642 815ab0fd4057 519917634162 5afc4abe7902 ecb4aed78dcf 19bde778c1fd 4973b22aa8c7 975b3c474c13 29321357ac6d a0bf284bfedd bd32005e126a
Author: Len Brown <len.brown@intel.com>
Date:   Sat May 16 01:55:59 2009 -0400

    Merge branches 'release', 'bugzilla-13032', 'bugzilla-13041+', 'bugzilla-13121', 'bugzilla-13165', 'bugzilla-13243', 'bugzilla-13259', 'resume-sci-en-regression', 'thermal-regression', 'tsc-regression' and 'asus-2.6.30' into release

commit a0bf284bfedd6dc95bbee7ebf5ccf3b5f753a008
Author: Len Brown <len.brown@intel.com>
Date:   Fri May 15 01:29:31 2009 -0400

    ACPI: Idle C-states disabled by max_cstate should not disable the TSC
    
    Processor idle power states C2 and C3 stop the TSC on many machines.
    Linux recognizes this situation and marks the TSC as unstable:
    
    Marking TSC unstable due to TSC halts in idle
    
    But if those same machines are booted with "processor.max_cstate=1",
    then there is no need to validate C2 and C3, and no need to
    disable the TSC, which can be reliably used as a clocksource.
    
    Signed-off-by: Len Brown <len.brown@intel.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index e39a40a2ceae..e65476fdf40d 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -582,7 +582,7 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 
 	pr->power.timer_broadcast_on_state = INT_MAX;
 
-	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
+	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {
 		struct acpi_processor_cx *cx = &pr->power.states[i];
 
 		switch (cx->type) {

commit 520daf7217bc1806c02eb4cfa7805447a3da2f66
Author: Len Brown <len.brown@intel.com>
Date:   Thu May 14 17:27:38 2009 -0400

    ACPI: idle: fix init-time TSC check regression
    
    A previous 2.6.30 patch, a71e4917dc0ebbcb5a0ecb7ca3486643c1c9a6e2,
    (ACPI: idle: mark_tsc_unstable() at init-time, not run-time)
    erroneously disabled the TSC on systems that did not actually
    have valid deep C-states.
    
    Move the check after the deep-C-states are validated,
    via new helper, tsc_check_state(), hich replaces tsc_halts_in_c().
    
    Signed-off-by: Len Brown <len.brown@intel.com>
    Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Frans Pop <elendil@planet.nl>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index f7ca8c55956b..e39a40a2ceae 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -216,7 +216,7 @@ int acpi_processor_resume(struct acpi_device * device)
 }
 
 #if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86)
-static int tsc_halts_in_c(int state)
+static void tsc_check_state(int state)
 {
 	switch (boot_cpu_data.x86_vendor) {
 	case X86_VENDOR_AMD:
@@ -226,13 +226,17 @@ static int tsc_halts_in_c(int state)
 		 * C/P/S0/S1 states when this bit is set.
 		 */
 		if (boot_cpu_has(X86_FEATURE_NONSTOP_TSC))
-			return 0;
+			return;
 
 		/*FALL THROUGH*/
 	default:
-		return state > ACPI_STATE_C1;
+		/* TSC could halt in idle, so notify users */
+		if (state > ACPI_STATE_C1)
+			mark_tsc_unstable("TSC halts in idle");
 	}
 }
+#else
+static void tsc_check_state(int state) { return; }
 #endif
 
 static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
@@ -581,11 +585,6 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
 		struct acpi_processor_cx *cx = &pr->power.states[i];
 
-#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86)
-		/* TSC could halt in idle, so notify users */
-		if (tsc_halts_in_c(cx->type))
-			mark_tsc_unstable("TSC halts in idle");;
-#endif
 		switch (cx->type) {
 		case ACPI_STATE_C1:
 			cx->valid = 1;
@@ -603,6 +602,8 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 				acpi_timer_check_state(i, pr, cx);
 			break;
 		}
+		if (cx->valid)
+			tsc_check_state(cx->type);
 
 		if (cx->valid)
 			working++;

commit 815ab0fd40579ad2aa42058298073503648762b9
Author: Len Brown <len.brown@intel.com>
Date:   Thu May 7 22:19:45 2009 -0400

    ACPI: suspend: restore BM_RLD on resume
    
    In 2.6.29,
    31878dd86b7df9a147f5e6cc6e07092b4308782b
    "ACPI: remove BM_RLD access from idle entry path"
    moved BM_RLD initialization to init-time from run time.
    
    But we discovered that some BIOS do not restore BM_RLD
    after suspend, causing device errors on C3 and C4
    after resume.  So now the kernel restores BM_RLD.
    
    http://bugzilla.kernel.org/show_bug.cgi?id=13032
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index f7ca8c55956b..c1d59cfdb5fb 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -202,15 +202,38 @@ static void acpi_state_timer_broadcast(struct acpi_processor *pr,
  * Suspend / resume control
  */
 static int acpi_idle_suspend;
+static u32 saved_bm_rld;
+
+static void acpi_idle_bm_rld_save(void)
+{
+	acpi_read_bit_register(ACPI_BITREG_BUS_MASTER_RLD, &saved_bm_rld);
+}
+static void acpi_idle_bm_rld_restore(void)
+{
+	u32 resumed_bm_rld;
+
+	acpi_read_bit_register(ACPI_BITREG_BUS_MASTER_RLD, &resumed_bm_rld);
+
+	if (resumed_bm_rld != saved_bm_rld)
+		acpi_write_bit_register(ACPI_BITREG_BUS_MASTER_RLD, saved_bm_rld);
+}
 
 int acpi_processor_suspend(struct acpi_device * device, pm_message_t state)
 {
+	if (acpi_idle_suspend == 1)
+		return 0;
+
+	acpi_idle_bm_rld_save();
 	acpi_idle_suspend = 1;
 	return 0;
 }
 
 int acpi_processor_resume(struct acpi_device * device)
 {
+	if (acpi_idle_suspend == 0)
+		return 0;
+
+	acpi_idle_bm_rld_restore();
 	acpi_idle_suspend = 0;
 	return 0;
 }

commit 9c18f0b7095c7981c48f41aae8abdaa06a76d9b3
Merge: 3869e929bb38 615dfd93e234
Author: Len Brown <len.brown@intel.com>
Date:   Fri Apr 24 10:42:03 2009 -0400

    Merge branch 'bugzilla-13142' into release

commit 3869e929bb38499b37f8cd76ec96ab6e5a169efb
Merge: 2d40570786c7 f461ddea0af8
Author: Len Brown <len.brown@intel.com>
Date:   Fri Apr 24 10:41:31 2009 -0400

    Merge branch 'hpet' into release

commit 615dfd93e2346b604232b559e7ea0835d24abe26
Author: Len Brown <len.brown@intel.com>
Date:   Thu Apr 23 23:21:29 2009 -0400

    ACPI: prevent processor.max_cstate=0 boot crash
    
    As processor.max_cstate is an init-time-only modparam,
    sanity checking it at init-time is sufficient.
    
    http://bugzilla.kernel.org/show_bug.cgi?id=13142
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 6fe121434ffb..436127e0eec3 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1037,6 +1037,9 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 		dev->states[i].desc[0] = '\0';
 	}
 
+	if (max_cstate == 0)
+		max_cstate = 1;
+
 	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {
 		cx = &pr->power.states[i];
 		state = &dev->states[count];

commit f461ddea0af8b98e2b7940eba9c693b0ee44d64a
Author: Len Brown <len.brown@intel.com>
Date:   Thu Apr 23 18:59:43 2009 -0400

    ACPI/hpet: prevent boot hang when hpet=force used on ICH-4M
    
    Linux tells ICH4 users that they can (manually) invoke
    "hpet=force" to enable the undocumented ICH-4M HPET.
    The HPET becomes available for both clocksource and clockevents.
    
    But as of ff69f2bba67bd45514923aaedbf40fe351787c59
    (acpi: fix of pmtimer overflow that make Cx states time incorrect)
    the HPET may be used via clocksource for idle accounting, and
    hpet=force on an ICH4 box hangs boot.
    
    It turns out that touching the MMIO HPET withing
    the ARB_DIS part of C3 will hang the hardware.
    
    The fix is to simply move the timer access outside
    the ARB_DIS region.  This is a no-op on modern hardware
    because ARB_DIS is no longer used.
    
    http://bugzilla.kernel.org/show_bug.cgi?id=13087
    
    Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 6fe121434ffb..ea23c64bd766 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -955,6 +955,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	 */
 	acpi_state_timer_broadcast(pr, cx, 1);
 
+	kt1 = ktime_get_real();
 	/*
 	 * disable bus master
 	 * bm_check implies we need ARB_DIS
@@ -976,10 +977,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		ACPI_FLUSH_CPU_CACHE();
 	}
 
-	kt1 = ktime_get_real();
 	acpi_idle_do_entry(cx);
-	kt2 = ktime_get_real();
-	idle_time =  ktime_to_us(ktime_sub(kt2, kt1));
 
 	/* Re-enable bus master arbitration */
 	if (pr->flags.bm_check && pr->flags.bm_control) {
@@ -988,6 +986,8 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		c3_cpu_count--;
 		spin_unlock(&c3_lock);
 	}
+	kt2 = ktime_get_real();
+	idle_time =  ktime_to_us(ktime_sub(kt2, kt1));
 
 #if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86)
 	/* TSC could halt in idle, so notify users */

commit 92614610774072ea68131f16e024ee8fc15be9be
Author: Len Brown <len.brown@intel.com>
Date:   Wed Apr 22 19:28:15 2009 -0400

    ACPI: delete obsolete "bus master activity" proc field
    
    Linux-2.6.29 deleted the legacy ACPI idle handler, leaving
    the CPU_IDLE handler, which does not track bus master activity.
    
    So delete the unused bm_activity field -- it is confusing to
    print an always zero value.
    
    This patch could break programs that parse
    /proc/acpi/processor/*/power, since it deletes this
    line from that file:
    
    bus master activity:     00000000
    
    http://bugzilla.kernel.org/show_bug.cgi?id=13145
    is not fixed by this patch, but provoked this patch.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 9d1f01ee65db..eed3b458ebac 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -662,11 +662,9 @@ static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
 
 	seq_printf(seq, "active state:            C%zd\n"
 		   "max_cstate:              C%d\n"
-		   "bus master activity:     %08x\n"
 		   "maximum allowed latency: %d usec\n",
 		   pr->power.state ? pr->power.state - pr->power.states : 0,
-		   max_cstate, (unsigned)pr->power.bm_activity,
-		   pm_qos_requirement(PM_QOS_CPU_DMA_LATENCY));
+		   max_cstate, pm_qos_requirement(PM_QOS_CPU_DMA_LATENCY));
 
 	seq_puts(seq, "states:\n");
 

commit a71e4917dc0ebbcb5a0ecb7ca3486643c1c9a6e2
Author: Len Brown <len.brown@intel.com>
Date:   Tue Apr 21 00:50:11 2009 -0400

    ACPI: idle: mark_tsc_unstable() at init-time, not run-time
    
    The c2 and c3 idle handlers check tsc_halts_in_c()
    after every time they return from idle.  Um, when?:-)
    
    Move this check to init-time to remove the unnecessary
    run-time overhead, and also to have the check complete before
    the first entry into the idle handler.
    
    ff69f2bba67bd45514923aaedbf40fe351787c59
    (acpi: fix of pmtimer overflow that make Cx states time incorrect)
    replaced the hard-coded use of the PM-timer inside idle,
    with ktime_get_readl(), which possibly uses the TSC --
    so it is now especially prudent to detect a broken TSC
    before entering idle.
    
    http://bugzilla.kernel.org/show_bug.cgi?id=13087
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 6fe121434ffb..9d1f01ee65db 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -581,6 +581,11 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
 		struct acpi_processor_cx *cx = &pr->power.states[i];
 
+#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86)
+		/* TSC could halt in idle, so notify users */
+		if (tsc_halts_in_c(cx->type))
+			mark_tsc_unstable("TSC halts in idle");;
+#endif
 		switch (cx->type) {
 		case ACPI_STATE_C1:
 			cx->valid = 1;
@@ -871,11 +876,6 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	kt2 = ktime_get_real();
 	idle_time =  ktime_to_us(ktime_sub(kt2, kt1));
 
-#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86)
-	/* TSC could halt in idle, so notify users */
-	if (tsc_halts_in_c(cx->type))
-		mark_tsc_unstable("TSC halts in idle");;
-#endif
 	sleep_ticks = us_to_pm_timer_ticks(idle_time);
 
 	/* Tell the scheduler how much we idled: */
@@ -989,11 +989,6 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		spin_unlock(&c3_lock);
 	}
 
-#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86)
-	/* TSC could halt in idle, so notify users */
-	if (tsc_halts_in_c(ACPI_STATE_C3))
-		mark_tsc_unstable("TSC halts in idle");
-#endif
 	sleep_ticks = us_to_pm_timer_ticks(idle_time);
 	/* Tell the scheduler how much we idled: */
 	sched_clock_idle_wakeup_event(sleep_ticks*PM_TIMER_TICK_NS);

commit db954b5898dd3ef3ef93f4144158ea8f97deb058
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon Apr 6 18:51:29 2009 -0700

    x86 ACPI: Add support for Always Running APIC timer
    
    Add support for Always Running APIC timer, CPUID_0x6_EAX_Bit2.
    This bit means the APIC timer continues to run even when CPU is
    in deep C-states.
    
    The advantage is that we can use LAPIC timer on these CPUs
    always, and there is no need for "slow to read and program"
    external timers (HPET/PIT) and the timer broadcast logic
    and related code in C-state entry and exit.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Acked-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 4e6e758bd397..6fe121434ffb 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -145,6 +145,9 @@ static void acpi_timer_check_state(int state, struct acpi_processor *pr,
 	struct acpi_processor_power *pwr = &pr->power;
 	u8 type = local_apic_timer_c2_ok ? ACPI_STATE_C3 : ACPI_STATE_C2;
 
+	if (cpu_has(&cpu_data(pr->id), X86_FEATURE_ARAT))
+		return;
+
 	/*
 	 * Check, if one of the previous states already marked the lapic
 	 * unstable

commit 2ddb9f17ba026122b53b34fb4182ece91e24cf92
Merge: a3b2c5e413ce ff69f2bba67b
Author: Len Brown <len.brown@intel.com>
Date:   Sun Apr 5 01:39:07 2009 -0400

    Merge branch 'pmtimer-overflow' into release

commit 67dc092187626ac55a60877485f78bc291cbfa81
Author: Thomas Renninger <trenn@suse.de>
Date:   Thu Apr 2 14:11:20 2009 +0200

    ACPI: Remove R40e c-state blacklist
    
    The recent ACPICA patch
    (ACPICA: FADT: Favor 32-bit register addresses for compatibility)
    makes machine to use the right FADT HW addresses
    and C-states now work fine.
    
    http://bugzilla.kernel.org/show_bug.cgi?id=8246
    
    Signed-off-by: Thomas Renninger <trenn@suse.de>
    Tested-by: Mark Doughty <me@markdoughty.co.uk>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 5c69e85c1e4d..397f2a7fee48 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -101,57 +101,6 @@ static int set_max_cstate(const struct dmi_system_id *id)
 /* Actually this shouldn't be __cpuinitdata, would be better to fix the
    callers to only run once -AK */
 static struct dmi_system_id __cpuinitdata processor_power_dmi_table[] = {
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET70WW")}, (void *)1},
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET60WW")}, (void *)1},
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET43WW") }, (void*)1},
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET45WW") }, (void*)1},
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET47WW") }, (void*)1},
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET50WW") }, (void*)1},
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET52WW") }, (void*)1},
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET55WW") }, (void*)1},
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET56WW") }, (void*)1},
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET59WW") }, (void*)1},
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET60WW") }, (void*)1},
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET61WW") }, (void*)1},
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET62WW") }, (void*)1},
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET64WW") }, (void*)1},
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET65WW") }, (void*)1},
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET68WW") }, (void*)1},
-	{ set_max_cstate, "Medion 41700", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"Phoenix Technologies LTD"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"R01-A1J")}, (void *)1},
 	{ set_max_cstate, "Clevo 5600D", {
 	  DMI_MATCH(DMI_BIOS_VENDOR,"Phoenix Technologies LTD"),
 	  DMI_MATCH(DMI_BIOS_VERSION,"SHE845M0.86C.0013.D.0302131307")},

commit 50ffba1bd3120b069617455545bc27bcf3cf7579
Author: Bob Moore <robert.moore@intel.com>
Date:   Mon Feb 23 15:02:07 2009 +0800

    ACPICA: Rename ACPI bit register access functions
    
    Rename acpi_get_register and acpi_set_register to clarify the
    purpose of these functions. New names are acpi_read_bit_register
    and acpi_write_bit_register.
    
    Signed-off-by: Bob Moore <robert.moore@intel.com>
    Signed-off-by: Lin Ming <ming.m.lin@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 6946047d0096..5c69e85c1e4d 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -630,7 +630,7 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 	 * In either case, the proper way to
 	 * handle BM_RLD is to set it and leave it set.
 	 */
-	acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 1);
+	acpi_write_bit_register(ACPI_BITREG_BUS_MASTER_RLD, 1);
 
 	return;
 }
@@ -800,9 +800,9 @@ static int acpi_idle_bm_check(void)
 {
 	u32 bm_status = 0;
 
-	acpi_get_register(ACPI_BITREG_BUS_MASTER_STATUS, &bm_status);
+	acpi_read_bit_register(ACPI_BITREG_BUS_MASTER_STATUS, &bm_status);
 	if (bm_status)
-		acpi_set_register(ACPI_BITREG_BUS_MASTER_STATUS, 1);
+		acpi_write_bit_register(ACPI_BITREG_BUS_MASTER_STATUS, 1);
 	/*
 	 * PIIX4 Erratum #18: Note that BM_STS doesn't always reflect
 	 * the true state of bus mastering activity; forcing us to
@@ -1028,7 +1028,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		c3_cpu_count++;
 		/* Disable bus master arbitration when all CPUs are in C3 */
 		if (c3_cpu_count == num_online_cpus())
-			acpi_set_register(ACPI_BITREG_ARB_DISABLE, 1);
+			acpi_write_bit_register(ACPI_BITREG_ARB_DISABLE, 1);
 		spin_unlock(&c3_lock);
 	} else if (!pr->flags.bm_check) {
 		ACPI_FLUSH_CPU_CACHE();
@@ -1041,7 +1041,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	/* Re-enable bus master arbitration */
 	if (pr->flags.bm_check && pr->flags.bm_control) {
 		spin_lock(&c3_lock);
-		acpi_set_register(ACPI_BITREG_ARB_DISABLE, 0);
+		acpi_write_bit_register(ACPI_BITREG_ARB_DISABLE, 0);
 		c3_cpu_count--;
 		spin_unlock(&c3_lock);
 	}

commit 9892dd23cbbfab1f7d4818622296e415979a9c77
Author: Bob Moore <robert.moore@intel.com>
Date:   Wed Feb 18 15:10:07 2009 +0800

    ACPICA: Optimize ACPI register locking
    
    Removed locking for reads from the ACPI bit registers in PM1
    Status, Enable, Control, and PM2 Control. The lock is not required
    when reading the single-bit registers. The acpi_get_register_unlocked
    function is no longer needed and has been removed. This will
    improve performance for reads on these registers.  ACPICA BZ 760.
    
    http://www.acpica.org/bugzilla/show_bug.cgi?id=760
    
    Signed-off-by: Bob Moore <robert.moore@intel.com>
    Signed-off-by: Lin Ming <ming.m.lin@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 7bc22a471fe3..6946047d0096 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -800,7 +800,7 @@ static int acpi_idle_bm_check(void)
 {
 	u32 bm_status = 0;
 
-	acpi_get_register_unlocked(ACPI_BITREG_BUS_MASTER_STATUS, &bm_status);
+	acpi_get_register(ACPI_BITREG_BUS_MASTER_STATUS, &bm_status);
 	if (bm_status)
 		acpi_set_register(ACPI_BITREG_BUS_MASTER_STATUS, 1);
 	/*

commit ff69f2bba67bd45514923aaedbf40fe351787c59
Author: alex.shi <alex.shi@intel.com>
Date:   Wed Mar 4 11:55:26 2009 -0800

    acpi: fix of pmtimer overflow that make Cx states time incorrect
    
    We found Cx states time abnormal in our some of machines which have 16
    LCPUs, the C0 take too many time while system is really idle when kernel
    enabled tickless and highres.  powertop output is below:
    
         PowerTOP version 1.9       (C) 2007 Intel Corporation
    
    Cn                Avg residency       P-states (frequencies)
    C0 (cpu running)        (40.5%)         2.53 Ghz     0.0%
    C1                0.0ms ( 0.0%)         2.53 Ghz     0.0%
    C2              128.8ms (59.5%)         2.40 Ghz     0.0%
                                            1.60 Ghz   100.0%
    
    Wakeups-from-idle per second :  4.7     interval: 20.0s
    no ACPI power usage estimate available
    
    Top causes for wakeups:
      41.4% ( 24.9)       <interrupt> : extra timer interrupt
      20.2% ( 12.2)     <kernel core> : usb_hcd_poll_rh_status
    (rh_timer_func)
    
    After tacking detailed for this issue, Yakui and I find it is due to 24
    bit PM timer overflows when some of cpu sleep more than 4 seconds.  With
    tickless kernel, the CPU want to sleep as much as possible when system
    idle.  But the Cx sleep time are recorded by pmtimer which length is
    determined by BIOS.  The current Cx time was gotten in the following
    function from driver/acpi/processor_idle.c:
    
    static inline u32 ticks_elapsed(u32 t1, u32 t2)
    {
           if (t2 >= t1)
                   return (t2 - t1);
           else if (!(acpi_gbl_FADT.flags & ACPI_FADT_32BIT_TIMER))
                   return (((0x00FFFFFF - t1) + t2) & 0x00FFFFFF);
           else
                   return ((0xFFFFFFFF - t1) + t2);
    }
    
    If pmtimer is 24 bits and it take 5 seconds from t1 to t2, in above
    function, just about 1 seconds ticks was recorded.  So the Cx time will be
    reduced about 4 seconds.  and this is why we see above powertop output.
    
    To resolve this problem, Yakui and I use ktime_get() to record the Cx
    states time instead of PM timer as the following patch.  the patch was
    tested with i386/x86_64 modes on several platforms.
    
    Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Tested-by: Alex Shi <alex.shi@intel.com>
    Signed-off-by: Alex Shi <alex.shi@intel.com>
    Signed-off-by: Yakui.zhao <yakui.zhao@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 7bc22a471fe3..879af875c213 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -64,7 +64,6 @@
 #define _COMPONENT              ACPI_PROCESSOR_COMPONENT
 ACPI_MODULE_NAME("processor_idle");
 #define ACPI_PROCESSOR_FILE_POWER	"power"
-#define US_TO_PM_TIMER_TICKS(t)		((t * (PM_TIMER_FREQUENCY/1000)) / 1000)
 #define PM_TIMER_TICK_NS		(1000000000ULL/PM_TIMER_FREQUENCY)
 #define C2_OVERHEAD			1	/* 1us */
 #define C3_OVERHEAD			1	/* 1us */
@@ -78,6 +77,10 @@ module_param(nocst, uint, 0000);
 static unsigned int latency_factor __read_mostly = 2;
 module_param(latency_factor, uint, 0644);
 
+static s64 us_to_pm_timer_ticks(s64 t)
+{
+	return div64_u64(t * PM_TIMER_FREQUENCY, 1000000);
+}
 /*
  * IBM ThinkPad R40e crashes mysteriously when going into C2 or C3.
  * For now disable this. Probably a bug somewhere else.
@@ -159,25 +162,6 @@ static struct dmi_system_id __cpuinitdata processor_power_dmi_table[] = {
 	{},
 };
 
-static inline u32 ticks_elapsed(u32 t1, u32 t2)
-{
-	if (t2 >= t1)
-		return (t2 - t1);
-	else if (!(acpi_gbl_FADT.flags & ACPI_FADT_32BIT_TIMER))
-		return (((0x00FFFFFF - t1) + t2) & 0x00FFFFFF);
-	else
-		return ((0xFFFFFFFF - t1) + t2);
-}
-
-static inline u32 ticks_elapsed_in_us(u32 t1, u32 t2)
-{
-	if (t2 >= t1)
-		return PM_TIMER_TICKS_TO_US(t2 - t1);
-	else if (!(acpi_gbl_FADT.flags & ACPI_FADT_32BIT_TIMER))
-		return PM_TIMER_TICKS_TO_US(((0x00FFFFFF - t1) + t2) & 0x00FFFFFF);
-	else
-		return PM_TIMER_TICKS_TO_US((0xFFFFFFFF - t1) + t2);
-}
 
 /*
  * Callers should disable interrupts before the call and enable
@@ -853,7 +837,8 @@ static inline void acpi_idle_do_entry(struct acpi_processor_cx *cx)
 static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 			      struct cpuidle_state *state)
 {
-	u32 t1, t2;
+	ktime_t  kt1, kt2;
+	s64 idle_time;
 	struct acpi_processor *pr;
 	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
 
@@ -871,14 +856,15 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 		return 0;
 	}
 
-	t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
+	kt1 = ktime_get_real();
 	acpi_idle_do_entry(cx);
-	t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
+	kt2 = ktime_get_real();
+	idle_time =  ktime_to_us(ktime_sub(kt2, kt1));
 
 	local_irq_enable();
 	cx->usage++;
 
-	return ticks_elapsed_in_us(t1, t2);
+	return idle_time;
 }
 
 /**
@@ -891,8 +877,9 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 {
 	struct acpi_processor *pr;
 	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
-	u32 t1, t2;
-	int sleep_ticks = 0;
+	ktime_t  kt1, kt2;
+	s64 idle_time;
+	s64 sleep_ticks = 0;
 
 	pr = __get_cpu_var(processors);
 
@@ -925,18 +912,19 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	if (cx->type == ACPI_STATE_C3)
 		ACPI_FLUSH_CPU_CACHE();
 
-	t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
+	kt1 = ktime_get_real();
 	/* Tell the scheduler that we are going deep-idle: */
 	sched_clock_idle_sleep_event();
 	acpi_idle_do_entry(cx);
-	t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
+	kt2 = ktime_get_real();
+	idle_time =  ktime_to_us(ktime_sub(kt2, kt1));
 
 #if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86)
 	/* TSC could halt in idle, so notify users */
 	if (tsc_halts_in_c(cx->type))
 		mark_tsc_unstable("TSC halts in idle");;
 #endif
-	sleep_ticks = ticks_elapsed(t1, t2);
+	sleep_ticks = us_to_pm_timer_ticks(idle_time);
 
 	/* Tell the scheduler how much we idled: */
 	sched_clock_idle_wakeup_event(sleep_ticks*PM_TIMER_TICK_NS);
@@ -948,7 +936,7 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 
 	acpi_state_timer_broadcast(pr, cx, 0);
 	cx->time += sleep_ticks;
-	return ticks_elapsed_in_us(t1, t2);
+	return idle_time;
 }
 
 static int c3_cpu_count;
@@ -966,8 +954,10 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 {
 	struct acpi_processor *pr;
 	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
-	u32 t1, t2;
-	int sleep_ticks = 0;
+	ktime_t  kt1, kt2;
+	s64 idle_time;
+	s64 sleep_ticks = 0;
+
 
 	pr = __get_cpu_var(processors);
 
@@ -1034,9 +1024,10 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		ACPI_FLUSH_CPU_CACHE();
 	}
 
-	t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
+	kt1 = ktime_get_real();
 	acpi_idle_do_entry(cx);
-	t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
+	kt2 = ktime_get_real();
+	idle_time =  ktime_to_us(ktime_sub(kt2, kt1));
 
 	/* Re-enable bus master arbitration */
 	if (pr->flags.bm_check && pr->flags.bm_control) {
@@ -1051,7 +1042,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	if (tsc_halts_in_c(ACPI_STATE_C3))
 		mark_tsc_unstable("TSC halts in idle");
 #endif
-	sleep_ticks = ticks_elapsed(t1, t2);
+	sleep_ticks = us_to_pm_timer_ticks(idle_time);
 	/* Tell the scheduler how much we idled: */
 	sched_clock_idle_wakeup_event(sleep_ticks*PM_TIMER_TICK_NS);
 
@@ -1062,7 +1053,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 
 	acpi_state_timer_broadcast(pr, cx, 0);
 	cx->time += sleep_ticks;
-	return ticks_elapsed_in_us(t1, t2);
+	return idle_time;
 }
 
 struct cpuidle_driver acpi_idle_driver = {

commit 9fdd54f206722ecee7fd7ba9dba26140450e7c32
Author: Len Brown <len.brown@intel.com>
Date:   Fri Feb 6 12:24:17 2009 -0500

    ACPI: delete CPU_IDLE=n code
    
    CPU_IDLE=y has been default for ACPI=y since Nov-2007,
    and has shipped in many distributions since then.
    
    Here we delete the CPU_IDLE=n ACPI idle code, since
    nobody should be using it, and we don't want to
    maintain two versions.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 7eab733ae96e..7bc22a471fe3 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -66,43 +66,17 @@ ACPI_MODULE_NAME("processor_idle");
 #define ACPI_PROCESSOR_FILE_POWER	"power"
 #define US_TO_PM_TIMER_TICKS(t)		((t * (PM_TIMER_FREQUENCY/1000)) / 1000)
 #define PM_TIMER_TICK_NS		(1000000000ULL/PM_TIMER_FREQUENCY)
-#ifndef CONFIG_CPU_IDLE
-#define C2_OVERHEAD			4	/* 1us (3.579 ticks per us) */
-#define C3_OVERHEAD			4	/* 1us (3.579 ticks per us) */
-static void (*pm_idle_save) (void) __read_mostly;
-#else
 #define C2_OVERHEAD			1	/* 1us */
 #define C3_OVERHEAD			1	/* 1us */
-#endif
 #define PM_TIMER_TICKS_TO_US(p)		(((p) * 1000)/(PM_TIMER_FREQUENCY/1000))
 
 static unsigned int max_cstate __read_mostly = ACPI_PROCESSOR_MAX_POWER;
-#ifdef CONFIG_CPU_IDLE
 module_param(max_cstate, uint, 0000);
-#else
-module_param(max_cstate, uint, 0644);
-#endif
 static unsigned int nocst __read_mostly;
 module_param(nocst, uint, 0000);
 
-#ifndef CONFIG_CPU_IDLE
-/*
- * bm_history -- bit-mask with a bit per jiffy of bus-master activity
- * 1000 HZ: 0xFFFFFFFF: 32 jiffies = 32ms
- * 800 HZ: 0xFFFFFFFF: 32 jiffies = 40ms
- * 100 HZ: 0x0000000F: 4 jiffies = 40ms
- * reduce history for more aggressive entry into C3
- */
-static unsigned int bm_history __read_mostly =
-    (HZ >= 800 ? 0xFFFFFFFF : ((1U << (HZ / 25)) - 1));
-module_param(bm_history, uint, 0644);
-
-static int acpi_processor_set_power_policy(struct acpi_processor *pr);
-
-#else	/* CONFIG_CPU_IDLE */
 static unsigned int latency_factor __read_mostly = 2;
 module_param(latency_factor, uint, 0644);
-#endif
 
 /*
  * IBM ThinkPad R40e crashes mysteriously when going into C2 or C3.
@@ -224,51 +198,6 @@ static void acpi_safe_halt(void)
 	current_thread_info()->status |= TS_POLLING;
 }
 
-#ifndef CONFIG_CPU_IDLE
-
-static void
-acpi_processor_power_activate(struct acpi_processor *pr,
-			      struct acpi_processor_cx *new)
-{
-	struct acpi_processor_cx *old;
-
-	if (!pr || !new)
-		return;
-
-	old = pr->power.state;
-
-	if (old)
-		old->promotion.count = 0;
-	new->demotion.count = 0;
-
-	pr->power.state = new;
-
-	return;
-}
-
-static atomic_t c3_cpu_count;
-
-/* Common C-state entry for C2, C3, .. */
-static void acpi_cstate_enter(struct acpi_processor_cx *cstate)
-{
-	/* Don't trace irqs off for idle */
-	stop_critical_timings();
-	if (cstate->entry_method == ACPI_CSTATE_FFH) {
-		/* Call into architectural FFH based C-state */
-		acpi_processor_ffh_cstate_enter(cstate);
-	} else {
-		int unused;
-		/* IO port based C-state */
-		inb(cstate->address);
-		/* Dummy wait op - must do something useless after P_LVL2 read
-		   because chipsets cannot guarantee that STPCLK# signal
-		   gets asserted in time to freeze execution properly. */
-		unused = inl(acpi_gbl_FADT.xpm_timer_block.address);
-	}
-	start_critical_timings();
-}
-#endif /* !CONFIG_CPU_IDLE */
-
 #ifdef ARCH_APICTIMER_STOPS_ON_C3
 
 /*
@@ -370,421 +299,6 @@ static int tsc_halts_in_c(int state)
 }
 #endif
 
-#ifndef CONFIG_CPU_IDLE
-static void acpi_processor_idle(void)
-{
-	struct acpi_processor *pr = NULL;
-	struct acpi_processor_cx *cx = NULL;
-	struct acpi_processor_cx *next_state = NULL;
-	int sleep_ticks = 0;
-	u32 t1, t2 = 0;
-
-	/*
-	 * Interrupts must be disabled during bus mastering calculations and
-	 * for C2/C3 transitions.
-	 */
-	local_irq_disable();
-
-	pr = __get_cpu_var(processors);
-	if (!pr) {
-		local_irq_enable();
-		return;
-	}
-
-	/*
-	 * Check whether we truly need to go idle, or should
-	 * reschedule:
-	 */
-	if (unlikely(need_resched())) {
-		local_irq_enable();
-		return;
-	}
-
-	cx = pr->power.state;
-	if (!cx || acpi_idle_suspend) {
-		if (pm_idle_save) {
-			pm_idle_save(); /* enables IRQs */
-		} else {
-			acpi_safe_halt();
-			local_irq_enable();
-		}
-
-		return;
-	}
-
-	/*
-	 * Check BM Activity
-	 * -----------------
-	 * Check for bus mastering activity (if required), record, and check
-	 * for demotion.
-	 */
-	if (pr->flags.bm_check) {
-		u32 bm_status = 0;
-		unsigned long diff = jiffies - pr->power.bm_check_timestamp;
-
-		if (diff > 31)
-			diff = 31;
-
-		pr->power.bm_activity <<= diff;
-
-		acpi_get_register_unlocked(ACPI_BITREG_BUS_MASTER_STATUS, &bm_status);
-		if (bm_status) {
-			pr->power.bm_activity |= 0x1;
-			acpi_set_register(ACPI_BITREG_BUS_MASTER_STATUS, 1);
-		}
-		/*
-		 * PIIX4 Erratum #18: Note that BM_STS doesn't always reflect
-		 * the true state of bus mastering activity; forcing us to
-		 * manually check the BMIDEA bit of each IDE channel.
-		 */
-		else if (errata.piix4.bmisx) {
-			if ((inb_p(errata.piix4.bmisx + 0x02) & 0x01)
-			    || (inb_p(errata.piix4.bmisx + 0x0A) & 0x01))
-				pr->power.bm_activity |= 0x1;
-		}
-
-		pr->power.bm_check_timestamp = jiffies;
-
-		/*
-		 * If bus mastering is or was active this jiffy, demote
-		 * to avoid a faulty transition.  Note that the processor
-		 * won't enter a low-power state during this call (to this
-		 * function) but should upon the next.
-		 *
-		 * TBD: A better policy might be to fallback to the demotion
-		 *      state (use it for this quantum only) istead of
-		 *      demoting -- and rely on duration as our sole demotion
-		 *      qualification.  This may, however, introduce DMA
-		 *      issues (e.g. floppy DMA transfer overrun/underrun).
-		 */
-		if ((pr->power.bm_activity & 0x1) &&
-		    cx->demotion.threshold.bm) {
-			local_irq_enable();
-			next_state = cx->demotion.state;
-			goto end;
-		}
-	}
-
-#ifdef CONFIG_HOTPLUG_CPU
-	/*
-	 * Check for P_LVL2_UP flag before entering C2 and above on
-	 * an SMP system. We do it here instead of doing it at _CST/P_LVL
-	 * detection phase, to work cleanly with logical CPU hotplug.
-	 */
-	if ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) &&
-	    !pr->flags.has_cst && !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
-		cx = &pr->power.states[ACPI_STATE_C1];
-#endif
-
-	/*
-	 * Sleep:
-	 * ------
-	 * Invoke the current Cx state to put the processor to sleep.
-	 */
-	if (cx->type == ACPI_STATE_C2 || cx->type == ACPI_STATE_C3) {
-		current_thread_info()->status &= ~TS_POLLING;
-		/*
-		 * TS_POLLING-cleared state must be visible before we
-		 * test NEED_RESCHED:
-		 */
-		smp_mb();
-		if (need_resched()) {
-			current_thread_info()->status |= TS_POLLING;
-			local_irq_enable();
-			return;
-		}
-	}
-
-	switch (cx->type) {
-
-	case ACPI_STATE_C1:
-		/*
-		 * Invoke C1.
-		 * Use the appropriate idle routine, the one that would
-		 * be used without acpi C-states.
-		 */
-		if (pm_idle_save) {
-			pm_idle_save(); /* enables IRQs */
-		} else {
-			acpi_safe_halt();
-			local_irq_enable();
-		}
-
-		/*
-		 * TBD: Can't get time duration while in C1, as resumes
-		 *      go to an ISR rather than here.  Need to instrument
-		 *      base interrupt handler.
-		 *
-		 * Note: the TSC better not stop in C1, sched_clock() will
-		 *       skew otherwise.
-		 */
-		sleep_ticks = 0xFFFFFFFF;
-
-		break;
-
-	case ACPI_STATE_C2:
-		/* Get start time (ticks) */
-		t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
-		/* Tell the scheduler that we are going deep-idle: */
-		sched_clock_idle_sleep_event();
-		/* Invoke C2 */
-		acpi_state_timer_broadcast(pr, cx, 1);
-		acpi_cstate_enter(cx);
-		/* Get end time (ticks) */
-		t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
-
-#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86)
-		/* TSC halts in C2, so notify users */
-		if (tsc_halts_in_c(ACPI_STATE_C2))
-			mark_tsc_unstable("possible TSC halt in C2");
-#endif
-		/* Compute time (ticks) that we were actually asleep */
-		sleep_ticks = ticks_elapsed(t1, t2);
-
-		/* Tell the scheduler how much we idled: */
-		sched_clock_idle_wakeup_event(sleep_ticks*PM_TIMER_TICK_NS);
-
-		/* Re-enable interrupts */
-		local_irq_enable();
-		/* Do not account our idle-switching overhead: */
-		sleep_ticks -= cx->latency_ticks + C2_OVERHEAD;
-
-		current_thread_info()->status |= TS_POLLING;
-		acpi_state_timer_broadcast(pr, cx, 0);
-		break;
-
-	case ACPI_STATE_C3:
-		acpi_unlazy_tlb(smp_processor_id());
-		/*
-		 * Must be done before busmaster disable as we might
-		 * need to access HPET !
-		 */
-		acpi_state_timer_broadcast(pr, cx, 1);
-		/*
-		 * disable bus master
-		 * bm_check implies we need ARB_DIS
-		 * !bm_check implies we need cache flush
-		 * bm_control implies whether we can do ARB_DIS
-		 *
-		 * That leaves a case where bm_check is set and bm_control is
-		 * not set. In that case we cannot do much, we enter C3
-		 * without doing anything.
-		 */
-		if (pr->flags.bm_check && pr->flags.bm_control) {
-			if (atomic_inc_return(&c3_cpu_count) ==
-			    num_online_cpus()) {
-				/*
-				 * All CPUs are trying to go to C3
-				 * Disable bus master arbitration
-				 */
-				acpi_set_register(ACPI_BITREG_ARB_DISABLE, 1);
-			}
-		} else if (!pr->flags.bm_check) {
-			/* SMP with no shared cache... Invalidate cache  */
-			ACPI_FLUSH_CPU_CACHE();
-		}
-
-		/* Get start time (ticks) */
-		t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
-		/* Invoke C3 */
-		/* Tell the scheduler that we are going deep-idle: */
-		sched_clock_idle_sleep_event();
-		acpi_cstate_enter(cx);
-		/* Get end time (ticks) */
-		t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
-		if (pr->flags.bm_check && pr->flags.bm_control) {
-			/* Enable bus master arbitration */
-			atomic_dec(&c3_cpu_count);
-			acpi_set_register(ACPI_BITREG_ARB_DISABLE, 0);
-		}
-
-#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86)
-		/* TSC halts in C3, so notify users */
-		if (tsc_halts_in_c(ACPI_STATE_C3))
-			mark_tsc_unstable("TSC halts in C3");
-#endif
-		/* Compute time (ticks) that we were actually asleep */
-		sleep_ticks = ticks_elapsed(t1, t2);
-		/* Tell the scheduler how much we idled: */
-		sched_clock_idle_wakeup_event(sleep_ticks*PM_TIMER_TICK_NS);
-
-		/* Re-enable interrupts */
-		local_irq_enable();
-		/* Do not account our idle-switching overhead: */
-		sleep_ticks -= cx->latency_ticks + C3_OVERHEAD;
-
-		current_thread_info()->status |= TS_POLLING;
-		acpi_state_timer_broadcast(pr, cx, 0);
-		break;
-
-	default:
-		local_irq_enable();
-		return;
-	}
-	cx->usage++;
-	if ((cx->type != ACPI_STATE_C1) && (sleep_ticks > 0))
-		cx->time += sleep_ticks;
-
-	next_state = pr->power.state;
-
-#ifdef CONFIG_HOTPLUG_CPU
-	/* Don't do promotion/demotion */
-	if ((cx->type == ACPI_STATE_C1) && (num_online_cpus() > 1) &&
-	    !pr->flags.has_cst && !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED)) {
-		next_state = cx;
-		goto end;
-	}
-#endif
-
-	/*
-	 * Promotion?
-	 * ----------
-	 * Track the number of longs (time asleep is greater than threshold)
-	 * and promote when the count threshold is reached.  Note that bus
-	 * mastering activity may prevent promotions.
-	 * Do not promote above max_cstate.
-	 */
-	if (cx->promotion.state &&
-	    ((cx->promotion.state - pr->power.states) <= max_cstate)) {
-		if (sleep_ticks > cx->promotion.threshold.ticks &&
-		  cx->promotion.state->latency <=
-				pm_qos_requirement(PM_QOS_CPU_DMA_LATENCY)) {
-			cx->promotion.count++;
-			cx->demotion.count = 0;
-			if (cx->promotion.count >=
-			    cx->promotion.threshold.count) {
-				if (pr->flags.bm_check) {
-					if (!
-					    (pr->power.bm_activity & cx->
-					     promotion.threshold.bm)) {
-						next_state =
-						    cx->promotion.state;
-						goto end;
-					}
-				} else {
-					next_state = cx->promotion.state;
-					goto end;
-				}
-			}
-		}
-	}
-
-	/*
-	 * Demotion?
-	 * ---------
-	 * Track the number of shorts (time asleep is less than time threshold)
-	 * and demote when the usage threshold is reached.
-	 */
-	if (cx->demotion.state) {
-		if (sleep_ticks < cx->demotion.threshold.ticks) {
-			cx->demotion.count++;
-			cx->promotion.count = 0;
-			if (cx->demotion.count >= cx->demotion.threshold.count) {
-				next_state = cx->demotion.state;
-				goto end;
-			}
-		}
-	}
-
-      end:
-	/*
-	 * Demote if current state exceeds max_cstate
-	 * or if the latency of the current state is unacceptable
-	 */
-	if ((pr->power.state - pr->power.states) > max_cstate ||
-		pr->power.state->latency >
-				pm_qos_requirement(PM_QOS_CPU_DMA_LATENCY)) {
-		if (cx->demotion.state)
-			next_state = cx->demotion.state;
-	}
-
-	/*
-	 * New Cx State?
-	 * -------------
-	 * If we're going to start using a new Cx state we must clean up
-	 * from the previous and prepare to use the new.
-	 */
-	if (next_state != pr->power.state)
-		acpi_processor_power_activate(pr, next_state);
-}
-
-static int acpi_processor_set_power_policy(struct acpi_processor *pr)
-{
-	unsigned int i;
-	unsigned int state_is_set = 0;
-	struct acpi_processor_cx *lower = NULL;
-	struct acpi_processor_cx *higher = NULL;
-	struct acpi_processor_cx *cx;
-
-
-	if (!pr)
-		return -EINVAL;
-
-	/*
-	 * This function sets the default Cx state policy (OS idle handler).
-	 * Our scheme is to promote quickly to C2 but more conservatively
-	 * to C3.  We're favoring C2  for its characteristics of low latency
-	 * (quick response), good power savings, and ability to allow bus
-	 * mastering activity.  Note that the Cx state policy is completely
-	 * customizable and can be altered dynamically.
-	 */
-
-	/* startup state */
-	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
-		cx = &pr->power.states[i];
-		if (!cx->valid)
-			continue;
-
-		if (!state_is_set)
-			pr->power.state = cx;
-		state_is_set++;
-		break;
-	}
-
-	if (!state_is_set)
-		return -ENODEV;
-
-	/* demotion */
-	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
-		cx = &pr->power.states[i];
-		if (!cx->valid)
-			continue;
-
-		if (lower) {
-			cx->demotion.state = lower;
-			cx->demotion.threshold.ticks = cx->latency_ticks;
-			cx->demotion.threshold.count = 1;
-			if (cx->type == ACPI_STATE_C3)
-				cx->demotion.threshold.bm = bm_history;
-		}
-
-		lower = cx;
-	}
-
-	/* promotion */
-	for (i = (ACPI_PROCESSOR_MAX_POWER - 1); i > 0; i--) {
-		cx = &pr->power.states[i];
-		if (!cx->valid)
-			continue;
-
-		if (higher) {
-			cx->promotion.state = higher;
-			cx->promotion.threshold.ticks = cx->latency_ticks;
-			if (cx->type >= ACPI_STATE_C2)
-				cx->promotion.threshold.count = 4;
-			else
-				cx->promotion.threshold.count = 10;
-			if (higher->type == ACPI_STATE_C3)
-				cx->promotion.threshold.bm = bm_history;
-		}
-
-		higher = cx;
-	}
-
-	return 0;
-}
-#endif /* !CONFIG_CPU_IDLE */
-
 static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 {
 
@@ -1027,11 +541,7 @@ static void acpi_processor_power_verify_c2(struct acpi_processor_cx *cx)
 	 */
 	cx->valid = 1;
 
-#ifndef CONFIG_CPU_IDLE
-	cx->latency_ticks = US_TO_PM_TIMER_TICKS(cx->latency);
-#else
 	cx->latency_ticks = cx->latency;
-#endif
 
 	return;
 }
@@ -1111,11 +621,7 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 	 */
 	cx->valid = 1;
 
-#ifndef CONFIG_CPU_IDLE
-	cx->latency_ticks = US_TO_PM_TIMER_TICKS(cx->latency);
-#else
 	cx->latency_ticks = cx->latency;
-#endif
 	/*
 	 * On older chipsets, BM_RLD needs to be set
 	 * in order for Bus Master activity to wake the
@@ -1189,20 +695,6 @@ static int acpi_processor_get_power_info(struct acpi_processor *pr)
 
 	pr->power.count = acpi_processor_power_verify(pr);
 
-#ifndef CONFIG_CPU_IDLE
-	/*
-	 * Set Default Policy
-	 * ------------------
-	 * Now that we know which states are supported, set the default
-	 * policy.  Note that this policy can be changed dynamically
-	 * (e.g. encourage deeper sleeps to conserve battery life when
-	 * not on AC).
-	 */
-	result = acpi_processor_set_power_policy(pr);
-	if (result)
-		return result;
-#endif
-
 	/*
 	 * if one state of type C2 or C3 is available, mark this
 	 * CPU as being "idle manageable"
@@ -1300,69 +792,6 @@ static const struct file_operations acpi_processor_power_fops = {
 	.release = single_release,
 };
 
-#ifndef CONFIG_CPU_IDLE
-
-int acpi_processor_cst_has_changed(struct acpi_processor *pr)
-{
-	int result = 0;
-
-	if (boot_option_idle_override)
-		return 0;
-
-	if (!pr)
-		return -EINVAL;
-
-	if (nocst) {
-		return -ENODEV;
-	}
-
-	if (!pr->flags.power_setup_done)
-		return -ENODEV;
-
-	/*
-	 * Fall back to the default idle loop, when pm_idle_save had
-	 * been initialized.
-	 */
-	if (pm_idle_save) {
-		pm_idle = pm_idle_save;
-		/* Relies on interrupts forcing exit from idle. */
-		synchronize_sched();
-	}
-
-	pr->flags.power = 0;
-	result = acpi_processor_get_power_info(pr);
-	if ((pr->flags.power == 1) && (pr->flags.power_setup_done))
-		pm_idle = acpi_processor_idle;
-
-	return result;
-}
-
-#ifdef CONFIG_SMP
-static void smp_callback(void *v)
-{
-	/* we already woke the CPU up, nothing more to do */
-}
-
-/*
- * This function gets called when a part of the kernel has a new latency
- * requirement.  This means we need to get all processors out of their C-state,
- * and then recalculate a new suitable C-state. Just do a cross-cpu IPI; that
- * wakes them all right up.
- */
-static int acpi_processor_latency_notify(struct notifier_block *b,
-		unsigned long l, void *v)
-{
-	smp_call_function(smp_callback, NULL, 1);
-	return NOTIFY_OK;
-}
-
-static struct notifier_block acpi_processor_latency_notifier = {
-	.notifier_call = acpi_processor_latency_notify,
-};
-
-#endif
-
-#else /* CONFIG_CPU_IDLE */
 
 /**
  * acpi_idle_bm_check - checks if bus master activity was detected
@@ -1756,8 +1185,6 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 	return ret;
 }
 
-#endif /* CONFIG_CPU_IDLE */
-
 int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 			      struct acpi_device *device)
 {
@@ -1786,10 +1213,6 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 			       "ACPI: processor limited to max C-state %d\n",
 			       max_cstate);
 		first_run++;
-#if !defined(CONFIG_CPU_IDLE) && defined(CONFIG_SMP)
-		pm_qos_add_notifier(PM_QOS_CPU_DMA_LATENCY,
-				&acpi_processor_latency_notifier);
-#endif
 	}
 
 	if (!pr)
@@ -1813,11 +1236,9 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 	 * platforms that only support C1.
 	 */
 	if (pr->flags.power) {
-#ifdef CONFIG_CPU_IDLE
 		acpi_processor_setup_cpuidle(pr);
 		if (cpuidle_register_device(&pr->power.dev))
 			return -EIO;
-#endif
 
 		printk(KERN_INFO PREFIX "CPU%d (power states:", pr->id);
 		for (i = 1; i <= pr->power.count; i++)
@@ -1825,13 +1246,6 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 				printk(" C%d[C%d]", i,
 				       pr->power.states[i].type);
 		printk(")\n");
-
-#ifndef CONFIG_CPU_IDLE
-		if (pr->id == 0) {
-			pm_idle_save = pm_idle;
-			pm_idle = acpi_processor_idle;
-		}
-#endif
 	}
 
 	/* 'power' [R] */
@@ -1850,34 +1264,12 @@ int acpi_processor_power_exit(struct acpi_processor *pr,
 	if (boot_option_idle_override)
 		return 0;
 
-#ifdef CONFIG_CPU_IDLE
 	cpuidle_unregister_device(&pr->power.dev);
-#endif
 	pr->flags.power_setup_done = 0;
 
 	if (acpi_device_dir(device))
 		remove_proc_entry(ACPI_PROCESSOR_FILE_POWER,
 				  acpi_device_dir(device));
 
-#ifndef CONFIG_CPU_IDLE
-
-	/* Unregister the idle handler when processor #0 is removed. */
-	if (pr->id == 0) {
-		if (pm_idle_save)
-			pm_idle = pm_idle_save;
-
-		/*
-		 * We are about to unload the current idle thread pm callback
-		 * (pm_idle), Wait for all processors to update cached/local
-		 * copies of pm_idle before proceeding.
-		 */
-		cpu_idle_wait();
-#ifdef CONFIG_SMP
-		pm_qos_remove_notifier(PM_QOS_CPU_DMA_LATENCY,
-				&acpi_processor_latency_notifier);
-#endif
-	}
-#endif
-
 	return 0;
 }

commit 31878dd86b7df9a147f5e6cc6e07092b4308782b
Author: Len Brown <len.brown@intel.com>
Date:   Wed Jan 28 18:28:09 2009 -0500

    ACPI: remove BM_RLD access from idle entry path
    
    It is true that BM_RLD needs to be set to enable
    bus master activity to wake an older chipset (eg PIIX4) from C3.
    
    This is contrary to the erroneous wording the ACPI 2.0, 3.0
    specifications that suggests that BM_RLD is an indicator
    rather than a control bit.
    
    ACPI 1.0's correct wording should be restored in ACPI 4.0:
    http://www.acpica.org/bugzilla/show_bug.cgi?id=689
    
    But the kernel should not have to clear BM_RLD
    when entering a non C3-type state just to set
    it again when entering a C3-type C-state.
    
    We should be able to set BM_RLD at boot time
    and leave it alone -- removing the overhead of
    accessing this IO register from the idle entry path.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index ae0010821ce3..7eab733ae96e 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -241,26 +241,6 @@ acpi_processor_power_activate(struct acpi_processor *pr,
 		old->promotion.count = 0;
 	new->demotion.count = 0;
 
-	/* Cleanup from old state. */
-	if (old) {
-		switch (old->type) {
-		case ACPI_STATE_C3:
-			/* Disable bus master reload */
-			if (new->type != ACPI_STATE_C3 && pr->flags.bm_check)
-				acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 0);
-			break;
-		}
-	}
-
-	/* Prepare to use new state. */
-	switch (new->type) {
-	case ACPI_STATE_C3:
-		/* Enable bus master reload */
-		if (old->type != ACPI_STATE_C3 && pr->flags.bm_check)
-			acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 1);
-		break;
-	}
-
 	pr->power.state = new;
 
 	return;
@@ -1121,7 +1101,6 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 					  " for C3 to be enabled on SMP systems\n"));
 			return;
 		}
-		acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 0);
 	}
 
 	/*
@@ -1137,6 +1116,15 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 #else
 	cx->latency_ticks = cx->latency;
 #endif
+	/*
+	 * On older chipsets, BM_RLD needs to be set
+	 * in order for Bus Master activity to wake the
+	 * system from C3.  Newer chipsets handle DMA
+	 * during C3 automatically and BM_RLD is a NOP.
+	 * In either case, the proper way to
+	 * handle BM_RLD is to set it and leave it set.
+	 */
+	acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 1);
 
 	return;
 }
@@ -1399,25 +1387,6 @@ static int acpi_idle_bm_check(void)
 	return bm_status;
 }
 
-/**
- * acpi_idle_update_bm_rld - updates the BM_RLD bit depending on target state
- * @pr: the processor
- * @target: the new target state
- */
-static inline void acpi_idle_update_bm_rld(struct acpi_processor *pr,
-					   struct acpi_processor_cx *target)
-{
-	if (pr->flags.bm_rld_set && target->type != ACPI_STATE_C3) {
-		acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 0);
-		pr->flags.bm_rld_set = 0;
-	}
-
-	if (!pr->flags.bm_rld_set && target->type == ACPI_STATE_C3) {
-		acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 1);
-		pr->flags.bm_rld_set = 1;
-	}
-}
-
 /**
  * acpi_idle_do_entry - a helper function that does C2 and C3 type entry
  * @cx: cstate data
@@ -1473,9 +1442,6 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 		return 0;
 	}
 
-	if (pr->flags.bm_check)
-		acpi_idle_update_bm_rld(pr, cx);
-
 	t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 	acpi_idle_do_entry(cx);
 	t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
@@ -1527,9 +1493,6 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	 */
 	acpi_state_timer_broadcast(pr, cx, 1);
 
-	if (pr->flags.bm_check)
-		acpi_idle_update_bm_rld(pr, cx);
-
 	if (cx->type == ACPI_STATE_C3)
 		ACPI_FLUSH_CPU_CACHE();
 
@@ -1621,8 +1584,6 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	 */
 	acpi_state_timer_broadcast(pr, cx, 1);
 
-	acpi_idle_update_bm_rld(pr, cx);
-
 	/*
 	 * disable bus master
 	 * bm_check implies we need ARB_DIS

commit a2b7b01c072435b7832ab392167545a1b38cabc3
Author: Len Brown <len.brown@intel.com>
Date:   Wed Jan 28 12:47:15 2009 -0500

    ACPI: remove locking from PM1x_STS register reads
    
    PM1a_STS and PM1b_STS are twins that get OR'd together
    on reads, and all writes are repeated to both.
    
    The fields in PM1x_STS are single bits only,
    there are no multi-bit fields.
    
    So it is not necessary to lock PM1x_STS reads against
    writes because it is impossible to read an intermediate
    value of a single bit.  It will either be 0 or 1,
    even if a write is in progress during the read.
    Reads are asynchronous to writes no matter if a lock
    is used or not.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 66a9d8145562..ae0010821ce3 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -447,7 +447,7 @@ static void acpi_processor_idle(void)
 
 		pr->power.bm_activity <<= diff;
 
-		acpi_get_register(ACPI_BITREG_BUS_MASTER_STATUS, &bm_status);
+		acpi_get_register_unlocked(ACPI_BITREG_BUS_MASTER_STATUS, &bm_status);
 		if (bm_status) {
 			pr->power.bm_activity |= 0x1;
 			acpi_set_register(ACPI_BITREG_BUS_MASTER_STATUS, 1);
@@ -1383,7 +1383,7 @@ static int acpi_idle_bm_check(void)
 {
 	u32 bm_status = 0;
 
-	acpi_get_register(ACPI_BITREG_BUS_MASTER_STATUS, &bm_status);
+	acpi_get_register_unlocked(ACPI_BITREG_BUS_MASTER_STATUS, &bm_status);
 	if (bm_status)
 		acpi_set_register(ACPI_BITREG_BUS_MASTER_STATUS, 1);
 	/*

commit ba84be2338d3a2b6020d39279335bb06fcd332e1
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Jan 6 14:41:07 2009 -0800

    remove linux/hardirq.h from asm-generic/local.h
    
    While looking at reducing the amount of architecture namespace pollution
    in the generic kernel, I found that asm/irq.h is included in the vast
    majority of compilations on ARM (around 650 files.)
    
    Since asm/irq.h includes a sub-architecture include file on ARM, this
    causes a negative impact on the ccache's ability to re-use the build
    results from other sub-architectures, so we have a desire to reduce the
    dependencies on asm/irq.h.
    
    It turns out that a major cause of this is the needless include of
    linux/hardirq.h into asm-generic/local.h.  The patch below removes this
    include, resulting in some 250 to 300 files (around half) of the kernel
    then omitting asm/irq.h.
    
    My test builds still succeed, provided two ARM files are fixed
    (arch/arm/kernel/traps.c and arch/arm/mm/fault.c) - so there may be
    negative impacts for this on other architectures.
    
    Note that x86 does not include asm/irq.h nor linux/hardirq.h in its
    asm/local.h, so this patch can be viewed as bringing the generic version
    into line with the x86 version.
    
    [kosaki.motohiro@jp.fujitsu.com: add #include <linux/irqflags.h> to acpi/processor_idle.c]
    [adobriyan@gmail.com: fix sparc64]
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 38aca048e951..66a9d8145562 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -41,6 +41,7 @@
 #include <linux/pm_qos_params.h>
 #include <linux/clockchips.h>
 #include <linux/cpuidle.h>
+#include <linux/irqflags.h>
 
 /*
  * Include the apic definitions for x86 to have the APIC timer related defines

commit 40fb17152c50a69dc304dd632131c2f41281ce44
Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon Nov 17 16:11:37 2008 -0800

    x86: support always running TSC on Intel CPUs
    
    Impact: reward non-stop TSCs with good TSC-based clocksources, etc.
    
    Add support for CPUID_0x80000007_Bit8 on Intel CPUs as well. This bit means
    that the TSC is invariant with C/P/T states and always runs at constant
    frequency.
    
    With Intel CPUs, we have 3 classes
    * CPUs where TSC runs at constant rate and does not stop n C-states
    * CPUs where TSC runs at constant rate, but will stop in deep C-states
    * CPUs where TSC rate will vary based on P/T-states and TSC will stop in deep
      C-states.
    
    To cover these 3, one feature bit (CONSTANT_TSC) is not enough. So, add a
    second bit (NONSTOP_TSC). CONSTANT_TSC indicates that the TSC runs at
    constant frequency irrespective of P/T-states, and NONSTOP_TSC indicates
    that TSC does not stop in deep C-states.
    
    CPUID_0x8000000_Bit8 indicates both these feature bit can be set.
    We still have CONSTANT_TSC _set_ and NONSTOP_TSC _not_set_ on some older Intel
    CPUs, based on model checks. We can use TSC on such CPUs for time, as long as
    those CPUs do not support/enter deep C-states.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 5f8d746a9b81..38aca048e951 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -374,15 +374,15 @@ static int tsc_halts_in_c(int state)
 {
 	switch (boot_cpu_data.x86_vendor) {
 	case X86_VENDOR_AMD:
+	case X86_VENDOR_INTEL:
 		/*
 		 * AMD Fam10h TSC will tick in all
 		 * C/P/S0/S1 states when this bit is set.
 		 */
-		if (boot_cpu_has(X86_FEATURE_CONSTANT_TSC))
+		if (boot_cpu_has(X86_FEATURE_NONSTOP_TSC))
 			return 0;
+
 		/*FALL THROUGH*/
-	case X86_VENDOR_INTEL:
-		/* Several cases known where TSC halts in C2 too */
 	default:
 		return state > ACPI_STATE_C1;
 	}

commit 89595b8f2850a080d290bf778ec933ea1d99f78e
Author: Bjorn Helgaas <bjorn.helgaas@hp.com>
Date:   Fri Nov 7 16:57:45 2008 -0700

    ACPI: consolidate ACPI_*_COMPONENT definitions in acpi_drivers.h
    
    Move all the component definitions for drivers to a single shared place,
    include/acpi/acpi_drivers.h.
    
    Signed-off-by: Bjorn Helgaas <bjorn.helgaas@hp.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 81b40ed5379e..5f8d746a9b81 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -59,7 +59,6 @@
 #include <acpi/processor.h>
 #include <asm/processor.h>
 
-#define ACPI_PROCESSOR_COMPONENT        0x01000000
 #define ACPI_PROCESSOR_CLASS            "processor"
 #define _COMPONENT              ACPI_PROCESSOR_COMPONENT
 ACPI_MODULE_NAME("processor_idle");

commit addbad46ed0906cd584784423b9d0babc7476446
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon Sep 29 15:24:28 2008 -0700

    cpuidle: update the last_state acpi cpuidle reflecting actual state entered
    
    reflect the actual state entered in dev->last_state, when actaul state entered
    is different from intended one.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index cf5b1b7b684f..81b40ed5379e 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1587,6 +1587,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 
 	if (acpi_idle_bm_check()) {
 		if (dev->safe_state) {
+			dev->last_state = dev->safe_state;
 			return dev->safe_state->enter(dev, dev->safe_state);
 		} else {
 			local_irq_disable();

commit d0057413a7a277e104cf315faa1b55b60b4a5482
Author: Pavel Machek <pavel@suse.cz>
Date:   Tue Aug 12 12:24:34 2008 +0200

    acpi: trivial cleanups
    
    Trivial cleanups for ACPI. Fix misspelling in printk(), fix mismerge,
    add file header.
    
    AK: removed file header
    
    Signed-off-by: Pavel Machek <pavel@suse.cz>
    Signed-off-by: Andi Kleen <ak@linux.intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 283c08f5f4d4..cf5b1b7b684f 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -41,7 +41,6 @@
 #include <linux/pm_qos_params.h>
 #include <linux/clockchips.h>
 #include <linux/cpuidle.h>
-#include <linux/cpuidle.h>
 
 /*
  * Include the apic definitions for x86 to have the APIC timer related defines

commit b032bf70df2e43149ce2b4e9a865b076c6140753
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Jul 27 23:47:12 2008 +0200

    ACPI/CPUIDLE: prevent setting pm_idle to NULL
    
    pm_idle_save resp. pm_idle_old can be NULL when the restore code in
    acpi_processor_cst_has_changed() resp. cpuidle_uninstall_idle_handler()
    is called. This can set pm_idle unconditinally to NULL, which causes the
    kernel to panic when calling pm_idle in the x86 idle code. This was
    covered by an extra check for !pm_idle in the x86 idle code, which was
    removed during the x86 idle code refactoring.
    
    Instead of restoring the pm_idle check in the x86 code prevent the
    acpi/cpuidle code to set pm_idle to NULL.
    
    Reported by: Dhaval Giani http://lkml.org/lkml/2008/7/2/309
    Based on a debug patch from Ingo Molnar
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index b7f2963693a7..283c08f5f4d4 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1332,9 +1332,15 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 	if (!pr->flags.power_setup_done)
 		return -ENODEV;
 
-	/* Fall back to the default idle loop */
-	pm_idle = pm_idle_save;
-	synchronize_sched();	/* Relies on interrupts forcing exit from idle. */
+	/*
+	 * Fall back to the default idle loop, when pm_idle_save had
+	 * been initialized.
+	 */
+	if (pm_idle_save) {
+		pm_idle = pm_idle_save;
+		/* Relies on interrupts forcing exit from idle. */
+		synchronize_sched();
+	}
 
 	pr->flags.power = 0;
 	result = acpi_processor_get_power_info(pr);
@@ -1896,7 +1902,8 @@ int acpi_processor_power_exit(struct acpi_processor *pr,
 
 	/* Unregister the idle handler when processor #0 is removed. */
 	if (pr->id == 0) {
-		pm_idle = pm_idle_save;
+		if (pm_idle_save)
+			pm_idle = pm_idle_save;
 
 		/*
 		 * We are about to unload the current idle thread pm callback

commit dcf309974555d17019c6a8e1a425238f17990b71
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Fri Jul 25 18:00:42 2008 -0400

    ftrace: disable tracing on acpi idle calls
    
    The acpi idle waits calls local_irq_save and then uses mwait to go into
    idle. The tracer gets reenabled at local_irq_save but does not detect that
    the idle allows for wake ups.
    
    This patch adds code to disable the tracing when acpi puts the CPU to idle.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index d592dbb1d12a..b7f2963693a7 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -272,6 +272,8 @@ static atomic_t c3_cpu_count;
 /* Common C-state entry for C2, C3, .. */
 static void acpi_cstate_enter(struct acpi_processor_cx *cstate)
 {
+	/* Don't trace irqs off for idle */
+	stop_critical_timings();
 	if (cstate->entry_method == ACPI_CSTATE_FFH) {
 		/* Call into architectural FFH based C-state */
 		acpi_processor_ffh_cstate_enter(cstate);
@@ -284,6 +286,7 @@ static void acpi_cstate_enter(struct acpi_processor_cx *cstate)
 		   gets asserted in time to freeze execution properly. */
 		unused = inl(acpi_gbl_FADT.xpm_timer_block.address);
 	}
+	start_critical_timings();
 }
 #endif /* !CONFIG_CPU_IDLE */
 
@@ -1418,6 +1421,8 @@ static inline void acpi_idle_update_bm_rld(struct acpi_processor *pr,
  */
 static inline void acpi_idle_do_entry(struct acpi_processor_cx *cx)
 {
+	/* Don't trace irqs off for idle */
+	stop_critical_timings();
 	if (cx->entry_method == ACPI_CSTATE_FFH) {
 		/* Call into architectural FFH based C-state */
 		acpi_processor_ffh_cstate_enter(cx);
@@ -1432,6 +1437,7 @@ static inline void acpi_idle_do_entry(struct acpi_processor_cx *cx)
 		   gets asserted in time to freeze execution properly. */
 		unused = inl(acpi_gbl_FADT.xpm_timer_block.address);
 	}
+	start_critical_timings();
 }
 
 /**

commit da5e09a1b3e5a9fc0b15a3feb64e921ccc55ba74
Author: Zhao Yakui <yakui.zhao@intel.com>
Date:   Tue Jun 24 18:01:09 2008 +0800

    ACPI : Create "idle=nomwait" bootparam
    
    "idle=nomwait" disables the use of the MWAIT
    instruction from both C1 (C1_FFH) and deeper (C2C3_FFH)
    C-states.
    
    When MWAIT is unavailable, the BIOS and OS generally
    negotiate to use the HALT instruction for C1,
    and use IO accesses for deeper C-states.
    
    This option is useful for power and performance
    comparisons, and also to work around BIOS bugs
    where broken MWAIT support is advertised.
    
    http://bugzilla.kernel.org/show_bug.cgi?id=10807
    http://bugzilla.kernel.org/show_bug.cgi?id=10914
    
    Signed-off-by: Zhao Yakui <yakui.zhao@intel.com>
    Signed-off-by: Li Shaohua <shaohua.li@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>
    Signed-off-by: Andi Kleen <ak@linux.intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index c75c7ace8c13..d592dbb1d12a 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -957,13 +957,17 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 			} else {
 				continue;
 			}
-			if (cx.type == ACPI_STATE_C1 && idle_halt) {
+			if (cx.type == ACPI_STATE_C1 &&
+					(idle_halt || idle_nomwait)) {
 				/*
 				 * In most cases the C1 space_id obtained from
 				 * _CST object is FIXED_HARDWARE access mode.
 				 * But when the option of idle=halt is added,
 				 * the entry_method type should be changed from
 				 * CSTATE_FFH to CSTATE_HALT.
+				 * When the option of idle=nomwait is added,
+				 * the C1 entry_method type should be
+				 * CSTATE_HALT.
 				 */
 				cx.entry_method = ACPI_CSTATE_HALT;
 				snprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI HLT");

commit c1e3b377ad48febba6f91b8ae42c44ee4d4ab45e
Author: Zhao Yakui <yakui.zhao@intel.com>
Date:   Tue Jun 24 17:58:53 2008 +0800

    ACPI: Create "idle=halt" bootparam
    
    "idle=halt" limits the idle loop to using
    the halt instruction.  No MWAIT, no IO accesses,
    no C-states deeper than C1.
    
    If something is broken in the idle code,
    "idle=halt" is a less severe workaround
    than "idle=poll" which disables all power savings.
    
    Signed-off-by: Zhao Yakui <yakui.zhao@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>
    Signed-off-by: Andi Kleen <ak@linux.intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 0fc310e7dfd6..c75c7ace8c13 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -41,6 +41,7 @@
 #include <linux/pm_qos_params.h>
 #include <linux/clockchips.h>
 #include <linux/cpuidle.h>
+#include <linux/cpuidle.h>
 
 /*
  * Include the apic definitions for x86 to have the APIC timer related defines
@@ -57,6 +58,7 @@
 
 #include <acpi/acpi_bus.h>
 #include <acpi/processor.h>
+#include <asm/processor.h>
 
 #define ACPI_PROCESSOR_COMPONENT        0x01000000
 #define ACPI_PROCESSOR_CLASS            "processor"
@@ -955,6 +957,17 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 			} else {
 				continue;
 			}
+			if (cx.type == ACPI_STATE_C1 && idle_halt) {
+				/*
+				 * In most cases the C1 space_id obtained from
+				 * _CST object is FIXED_HARDWARE access mode.
+				 * But when the option of idle=halt is added,
+				 * the entry_method type should be changed from
+				 * CSTATE_FFH to CSTATE_HALT.
+				 */
+				cx.entry_method = ACPI_CSTATE_HALT;
+				snprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI HLT");
+			}
 		} else {
 			snprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI IOPORT 0x%x",
 				 cx.address);
@@ -1780,6 +1793,15 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 		return 0;
 
 	if (!first_run) {
+		if (idle_halt) {
+			/*
+			 * When the boot option of "idle=halt" is added, halt
+			 * is used for CPU IDLE.
+			 * In such case C2/C3 is meaningless. So the max_cstate
+			 * is set to one.
+			 */
+			max_cstate = 1;
+		}
 		dmi_check_system(processor_power_dmi_table);
 		max_cstate = acpi_processor_cstate_check(max_cstate);
 		if (max_cstate < ACPI_C_STATES_MAX)

commit 706546d02384b64e083bd9130c56eaa599c66038
Author: Mike Travis <travis@sgi.com>
Date:   Mon Jun 9 16:22:23 2008 -0700

    ACPI: change processors from array to per_cpu variable
    
    Change processors from an array sized by NR_CPUS to a per_cpu variable.
    
    Signed-off-by: Mike Travis <travis@sgi.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Len Brown <len.brown@intel.com>
    Signed-off-by: Andi Kleen <ak@linux.intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 4976e5db2b3f..0fc310e7dfd6 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -401,7 +401,7 @@ static void acpi_processor_idle(void)
 	 */
 	local_irq_disable();
 
-	pr = processors[smp_processor_id()];
+	pr = __get_cpu_var(processors);
 	if (!pr) {
 		local_irq_enable();
 		return;
@@ -1431,7 +1431,7 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 	struct acpi_processor *pr;
 	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
 
-	pr = processors[smp_processor_id()];
+	pr = __get_cpu_var(processors);
 
 	if (unlikely(!pr))
 		return 0;
@@ -1471,7 +1471,7 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	u32 t1, t2;
 	int sleep_ticks = 0;
 
-	pr = processors[smp_processor_id()];
+	pr = __get_cpu_var(processors);
 
 	if (unlikely(!pr))
 		return 0;
@@ -1549,7 +1549,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	u32 t1, t2;
 	int sleep_ticks = 0;
 
-	pr = processors[smp_processor_id()];
+	pr = __get_cpu_var(processors);
 
 	if (unlikely(!pr))
 		return 0;

commit 8691e5a8f691cc2a4fda0651e8d307aaba0e7d68
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Fri Jun 6 11:18:06 2008 +0200

    smp_call_function: get rid of the unused nonatomic/retry argument
    
    It's never used and the comments refer to nonatomic and retry
    interchangably. So get rid of it.
    
    Acked-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 556ee1585192..4976e5db2b3f 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1339,7 +1339,7 @@ static void smp_callback(void *v)
 static int acpi_processor_latency_notify(struct notifier_block *b,
 		unsigned long l, void *v)
 {
-	smp_call_function(smp_callback, NULL, 0, 1);
+	smp_call_function(smp_callback, NULL, 1);
 	return NOTIFY_OK;
 }
 

commit dcb84f335bee9c9a7781cfc5d74492dccaf066d2
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon May 19 19:09:27 2008 -0400

    cpuidle acpi driver: fix oops on AC<->DC
    
    cpuidle and acpi driver interaction bug with the way cpuidle_register_driver()
    is called. Due to this bug, there will be oops on
    AC<->DC on some systems, where they support C-states in one DC and not in AC.
    
    The current code does
    ON BOOT:
            Look at CST and other C-state info to see whether more than C1 is
            supported. If it is, then acpi processor_idle does a
            cpuidle_register_driver() call, which internally enables the device.
    
    ON CST change notification (AC<->DC) and on suspend-resume:
            acpi driver temporarily disables device, updates the device with
            any new C-states, and reenables the device.
    
    The problem is is on boot, there are no C2, C3 states supported and we skip
    the register. Later on AC<->DC, we may get a CST notification and we try
    to reevaluate CST and enabled the device, without actually registering it.
    This causes breakage as we try to create /sys fs sub directory, without the
    parent directory which is created at register time.
    
    Thanks to Sanjeev for reporting the problem here.
    http://bugzilla.kernel.org/show_bug.cgi?id=10394
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 2dd2c1f3a01c..556ee1585192 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1669,6 +1669,7 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 		return -EINVAL;
 	}
 
+	dev->cpu = pr->id;
 	for (i = 0; i < CPUIDLE_STATE_MAX; i++) {
 		dev->states[i].name[0] = '\0';
 		dev->states[i].desc[0] = '\0';
@@ -1738,7 +1739,7 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 
 int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 {
-	int ret;
+	int ret = 0;
 
 	if (boot_option_idle_override)
 		return 0;
@@ -1756,8 +1757,10 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 	cpuidle_pause_and_lock();
 	cpuidle_disable_device(&pr->power.dev);
 	acpi_processor_get_power_info(pr);
-	acpi_processor_setup_cpuidle(pr);
-	ret = cpuidle_enable_device(&pr->power.dev);
+	if (pr->flags.power) {
+		acpi_processor_setup_cpuidle(pr);
+		ret = cpuidle_enable_device(&pr->power.dev);
+	}
 	cpuidle_resume_and_unlock();
 
 	return ret;
@@ -1813,7 +1816,6 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 	if (pr->flags.power) {
 #ifdef CONFIG_CPU_IDLE
 		acpi_processor_setup_cpuidle(pr);
-		pr->power.dev.cpu = pr->id;
 		if (cpuidle_register_device(&pr->power.dev))
 			return -EIO;
 #endif
@@ -1850,8 +1852,7 @@ int acpi_processor_power_exit(struct acpi_processor *pr,
 		return 0;
 
 #ifdef CONFIG_CPU_IDLE
-	if (pr->flags.power)
-		cpuidle_unregister_device(&pr->power.dev);
+	cpuidle_unregister_device(&pr->power.dev);
 #endif
 	pr->flags.power_setup_done = 0;
 

commit 08acd4f8af42affd8cbed81cc1b69fa12ddb213f
Merge: ccf2779544ee 008238b54ac2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 30 11:52:52 2008 -0700

    Merge branch 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-acpi-2.6
    
    * 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-acpi-2.6: (179 commits)
      ACPI: Fix acpi_processor_idle and idle= boot parameters interaction
      acpi: fix section mismatch warning in pnpacpi
      intel_menlo: fix build warning
      ACPI: Cleanup: Remove unneeded, multiple local dummy variables
      ACPI: video - fix permissions on some proc entries
      ACPI: video - properly handle errors when registering proc elements
      ACPI: video - do not store invalid entries in attached_array list
      ACPI: re-name acpi_pm_ops to acpi_suspend_ops
      ACER_WMI/ASUS_LAPTOP: fix build bug
      thinkpad_acpi: fix possible NULL pointer dereference if kstrdup failed
      ACPI: check a return value correctly in acpi_power_get_context()
      #if 0 acpi/bay.c:eject_removable_drive()
      eeepc-laptop: add hwmon fan control
      eeepc-laptop: add backlight
      eeepc-laptop: add base driver
      ACPI: thinkpad-acpi: bump up version to 0.20
      ACPI: thinkpad-acpi: fix selects in Kconfig
      ACPI: thinkpad-acpi: use a private workqueue
      ACPI: thinkpad-acpi: fluff really minor fix
      ACPI: thinkpad-acpi: use uppercase for "LED" on user documentation
      ...
    
    Fixed conflicts in drivers/acpi/video.c and drivers/misc/intel_menlow.c
    manually.

commit 96916090f488986a4ebb8e9ffa6a3b50881d5ccd
Merge: 75a44ce00b31 729b2bdbfa19 2f67a0695dc3 51ae796f7fa1 ce52ddf58cbc e1faa9da284d 36a913586597 9448b0d43e55 99bda83e8b31 1071695f17da 7aa0f1a8b1f7 68f12ae5d778 66fb9d120e91
Author: Len Brown <len.brown@intel.com>
Date:   Wed Apr 30 13:58:00 2008 -0400

    Merge branches 'release', 'acpica', 'bugzilla-10224', 'bugzilla-9772', 'bugzilla-9916', 'ec', 'eeepc', 'idle', 'misc', 'pm-legacy', 'sysfs-links-2.6.26', 'thermal', 'thinkpad' and 'video' into release

commit 36a913586597cab1cd565e9bf348d037f0df955b
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Wed Apr 30 13:57:15 2008 -0400

    ACPI: Fix acpi_processor_idle and idle= boot parameters interaction
    
    acpi_processor_idle and "idle=" boot parameter interaction is broken.
    The problem is that, at boot time acpi driver is checking for "idle=" boot
    option and not registering the acpi idle handler. But, when there is a CST
    changed callback (typically when switching AC <-> battery or suspend-resume)
    there are no checks for boot_option_idle_override and acpi idle handler tries
    to get installed with nasty side effects.
    
    With CPU_IDLE configured this issue causes results in a nasty oops on CST
    change callback and without CPU_IDLE there is no oops, but boot option
    of "idle=" gets ignored and acpi idle handler gets installed.
    
    Change the behavior to not do anything in acpi idle handler when there is a
    "idle=" boot option.
    
    Note that the problem is only there when "idle=" boot option is used.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 836362b50faa..47b167c731a0 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1299,6 +1299,8 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 {
 	int result = 0;
 
+	if (boot_option_idle_override)
+		return 0;
 
 	if (!pr)
 		return -EINVAL;
@@ -1738,6 +1740,9 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 {
 	int ret;
 
+	if (boot_option_idle_override)
+		return 0;
+
 	if (!pr)
 		return -EINVAL;
 
@@ -1768,6 +1773,8 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 	struct proc_dir_entry *entry = NULL;
 	unsigned int i;
 
+	if (boot_option_idle_override)
+		return 0;
 
 	if (!first_run) {
 		dmi_check_system(processor_power_dmi_table);
@@ -1803,7 +1810,7 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 	 * Note that we use previously set idle handler will be used on
 	 * platforms that only support C1.
 	 */
-	if ((pr->flags.power) && (!boot_option_idle_override)) {
+	if (pr->flags.power) {
 #ifdef CONFIG_CPU_IDLE
 		acpi_processor_setup_cpuidle(pr);
 		pr->power.dev.cpu = pr->id;
@@ -1843,8 +1850,11 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 int acpi_processor_power_exit(struct acpi_processor *pr,
 			      struct acpi_device *device)
 {
+	if (boot_option_idle_override)
+		return 0;
+
 #ifdef CONFIG_CPU_IDLE
-	if ((pr->flags.power) && (!boot_option_idle_override))
+	if (pr->flags.power)
 		cpuidle_unregister_device(&pr->power.dev);
 #endif
 	pr->flags.power_setup_done = 0;

commit cf7acfab032ff262f42954328cdfd20a5d9aaaac
Author: Denis V. Lunev <den@openvz.org>
Date:   Tue Apr 29 01:02:27 2008 -0700

    acpi: use non-racy method for proc entries creation
    
    Use proc_create()/proc_create_data() to make sure that ->proc_fops and ->data
    be setup before gluing PDE to main tree.
    
    Add correct ->owner to proc_fops to fix reading/module unloading race.
    
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Cc: Len Brown <lenb@kernel.org>
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 0d90ff5fd117..789d4947ed31 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1282,6 +1282,7 @@ static int acpi_processor_power_open_fs(struct inode *inode, struct file *file)
 }
 
 static const struct file_operations acpi_processor_power_fops = {
+	.owner = THIS_MODULE,
 	.open = acpi_processor_power_open_fs,
 	.read = seq_read,
 	.llseek = seq_lseek,
@@ -1822,16 +1823,12 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 	}
 
 	/* 'power' [R] */
-	entry = create_proc_entry(ACPI_PROCESSOR_FILE_POWER,
-				  S_IRUGO, acpi_device_dir(device));
+	entry = proc_create_data(ACPI_PROCESSOR_FILE_POWER,
+				 S_IRUGO, acpi_device_dir(device),
+				 &acpi_processor_power_fops,
+				 acpi_driver_data(device));
 	if (!entry)
 		return -EIO;
-	else {
-		entry->proc_fops = &acpi_processor_power_fops;
-		entry->data = acpi_driver_data(device);
-		entry->owner = THIS_MODULE;
-	}
-
 	return 0;
 }
 

commit 7f424a8b08c26dc14ac5c17164014539ac9a5c65
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Apr 25 17:39:01 2008 +0200

    fix idle (arch, acpi and apm) and lockdep
    
    OK, so 25-mm1 gave a lockdep error which made me look into this.
    
    The first thing that I noticed was the horrible mess; the second thing I
    saw was hacks like: 71e93d15612c61c2e26a169567becf088e71b8ff
    
    The problem is that arch idle routines are somewhat inconsitent with
    their IRQ state handling and instead of fixing _that_, we go paper over
    the problem.
    
    So the thing I've tried to do is set a standard for idle routines and
    fix them all up to adhere to that. So the rules are:
    
      idle routines are entered with IRQs disabled
      idle routines will exit with IRQs enabled
    
    Nearly all already did this in one form or another.
    
    Merge the 32 and 64 bit bits so they no longer have different bugs.
    
    As for the actual lockdep warning; __sti_mwait() did a plainly un-annotated
    irq-enable.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Tested-by: Bob Copeland <me@bobcopeland.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 788da9781f80..0d90ff5fd117 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -418,13 +418,12 @@ static void acpi_processor_idle(void)
 
 	cx = pr->power.state;
 	if (!cx || acpi_idle_suspend) {
-		if (pm_idle_save)
-			pm_idle_save();
-		else
+		if (pm_idle_save) {
+			pm_idle_save(); /* enables IRQs */
+		} else {
 			acpi_safe_halt();
-
-		if (irqs_disabled())
 			local_irq_enable();
+		}
 
 		return;
 	}
@@ -520,10 +519,12 @@ static void acpi_processor_idle(void)
 		 * Use the appropriate idle routine, the one that would
 		 * be used without acpi C-states.
 		 */
-		if (pm_idle_save)
-			pm_idle_save();
-		else
+		if (pm_idle_save) {
+			pm_idle_save(); /* enables IRQs */
+		} else {
 			acpi_safe_halt();
+			local_irq_enable();
+		}
 
 		/*
 		 * TBD: Can't get time duration while in C1, as resumes
@@ -534,8 +535,6 @@ static void acpi_processor_idle(void)
 		 *       skew otherwise.
 		 */
 		sleep_ticks = 0xFFFFFFFF;
-		if (irqs_disabled())
-			local_irq_enable();
 
 		break;
 

commit 0fda6b403f0eca66ad8a7c946b3996e359100443
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Wed Apr 9 21:31:46 2008 -0400

    2.6.25 regression: powertop says 120K wakeups/sec
    
    Patch to fix huge number of wakeups reported due to recent changes in
    processor_idle.c. The problem was that the entry_method determination was
    broken due to one of the recent commits (bc71bec91f987) causing
    C1 entry to not to go to halt.
    
    http://lkml.org/lkml/2008/3/22/124
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 788da9781f80..836362b50faa 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -848,6 +848,7 @@ static int acpi_processor_get_power_info_default(struct acpi_processor *pr)
 		/* all processors need to support C1 */
 		pr->power.states[ACPI_STATE_C1].type = ACPI_STATE_C1;
 		pr->power.states[ACPI_STATE_C1].valid = 1;
+		pr->power.states[ACPI_STATE_C1].entry_method = ACPI_CSTATE_HALT;
 	}
 	/* the C0 state only exists as a filler in our array */
 	pr->power.states[ACPI_STATE_C0].valid = 1;
@@ -960,6 +961,9 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 				 cx.address);
 		}
 
+		if (cx.type == ACPI_STATE_C1) {
+			cx.valid = 1;
+		}
 
 		obj = &(element->package.elements[2]);
 		if (obj->type != ACPI_TYPE_INTEGER)

commit 8e92b6605da989c0aa8ff7e33306f36f0efd957c
Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Fri Feb 29 10:24:32 2008 -0800

    cpuidle: fix 100% C0 statistics regression
    
    commit 9b12e18cdc1553de62d931e73443c806347cd974
    'ACPI: cpuidle: Support C1 idle time accounting'
    was implicated in a 100% C0 idle regression.
    http://bugzilla.kernel.org/show_bug.cgi?id=10076
    
    It pointed out a potential problem where the menu governor
    may get confused by the C-state residency time from poll
    idle or C1 idle, where this timing info is not accurate.
    This inaccuracy is due to interrupts being handled
    before we account for C-state exit.
    
    Do not mark TIME_VALID for CO poll state.
    Mark C1 time as valid only with the MWAIT (CSTATE_FFH) entry method.
    
    This makes governors use the timing information only when it is correct and
    eliminates any wrong policy decisions that may result from invalid timing
    information.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 1468f1e92cac..788da9781f80 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1693,7 +1693,9 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 		switch (cx->type) {
 			case ACPI_STATE_C1:
 			state->flags |= CPUIDLE_FLAG_SHALLOW;
-			state->flags |= CPUIDLE_FLAG_TIME_VALID;
+			if (cx->entry_method == ACPI_CSTATE_FFH)
+				state->flags |= CPUIDLE_FLAG_TIME_VALID;
+
 			state->enter = acpi_idle_enter_c1;
 			dev->safe_state = state;
 			break;

commit 996520c1fdd2948addb629be56c9febf2967e02b
Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon Mar 24 14:24:10 2008 -0700

    ACPI: fix mis-merge -- invoke acpi_unlazy_tlb() only on C3 entry
    
    This original patch
    http://ussg.iu.edu/hypermail/linux/kernel/0712.2/1451.html
    was intending to add acpi_unlazy_tlb() to acpi_idle_enter_bm(),
    which is used for C3 entry.
    
    But it was merged incorrectly as commmit
    
    bde6f5f59c2b2b48a7a849c129d5b48838fe77ee
    'x86: voluntary leave_mm before entering ACPI C3'
    
    so the call was instead added to acpi_idle_enter_simple()
    (which is C2 entry routine), probably due to identical
    context in that function.
    
    Move the call back to acpi_idle_enter_bm().
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index e8e2d8869236..1468f1e92cac 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1487,7 +1487,6 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 		return 0;
 	}
 
-	acpi_unlazy_tlb(smp_processor_id());
 	/*
 	 * Must be done before busmaster disable as we might need to
 	 * access HPET !
@@ -1577,6 +1576,8 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		return 0;
 	}
 
+	acpi_unlazy_tlb(smp_processor_id());
+
 	/* Tell the scheduler that we are going deep-idle: */
 	sched_clock_idle_sleep_event();
 	/*

commit 71e93d15612c61c2e26a169567becf088e71b8ff
Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Thu Mar 13 17:18:19 2008 -0700

    ACPI: lockdep warning on boot, 2.6.25-rc5
    
    This avoids the harmless WARNING by lockdep in acpi_processor_idle().
    
    The reason for WARNING is because at the depth of idle handling code,
    some of the idle handlers disable interrupts, some times, while returning from
    the idle handler. After return, acpi_processor_idle and few other routines
    in the file did an unconditional local_irq_enable(). With LOCKDEP, enabling
    irq when it is already enabled generates the below WARNING.
    
    > > [    0.593038] ------------[ cut here ]------------
    > > [    0.593267] WARNING: at kernel/lockdep.c:2035 trace_hardirqs_on+0xa0/0x115()
    > > [    0.593596] Modules linked in:
    > > [    0.593756] Pid: 0, comm: swapper Not tainted 2.6.25-rc5 #8
    > > [    0.594017]
    > > [    0.594017] Call Trace:
    > > [    0.594216]  [<ffffffff80231663>] warn_on_slowpath+0x58/0x6b
    > > [    0.594495]  [<ffffffff80495966>] ? _spin_unlock_irqrestore+0x38/0x47
    > > [    0.594809]  [<ffffffff80329a86>] ? acpi_os_release_lock+0x9/0xb
    > > [    0.595103]  [<ffffffff80337840>] ? acpi_set_register+0x161/0x173
    > > [    0.595401]  [<ffffffff8034c8d4>] ? acpi_processor_idle+0x1de/0x546
    > > [    0.595706]  [<ffffffff8020a23b>] ? default_idle+0x0/0x73
    > > [    0.595970]  [<ffffffff8024fc0e>] trace_hardirqs_on+0xa0/0x115
    > > [    0.596049]  [<ffffffff8034c6f6>] ? acpi_processor_idle+0x0/0x546
    > > [    0.596346]  [<ffffffff8034c8d4>] acpi_processor_idle+0x1de/0x546
    > > [    0.596642]  [<ffffffff8020a23b>] ? default_idle+0x0/0x73
    > > [    0.596912]  [<ffffffff8034c6f6>] ? acpi_processor_idle+0x0/0x546
    > > [    0.597209]  [<ffffffff8020a23b>] ? default_idle+0x0/0x73
    > > [    0.597472]  [<ffffffff8020a355>] cpu_idle+0xa7/0xd1
    > > [    0.597717]  [<ffffffff80485fa1>] rest_init+0x55/0x57
    > > [    0.597957]  [<ffffffff8062fb49>] start_kernel+0x29d/0x2a8
    > > [    0.598215]  [<ffffffff8062f1da>] _sinittext+0x1da/0x1e1
    > > [    0.598464]
    > > [    0.598546] ---[ end trace 778e504de7e3b1e3 ]---
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 6f3b217699e9..e8e2d8869236 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -216,8 +216,10 @@ static void acpi_safe_halt(void)
 	 * test NEED_RESCHED:
 	 */
 	smp_mb();
-	if (!need_resched())
+	if (!need_resched()) {
 		safe_halt();
+		local_irq_disable();
+	}
 	current_thread_info()->status |= TS_POLLING;
 }
 
@@ -421,7 +423,9 @@ static void acpi_processor_idle(void)
 		else
 			acpi_safe_halt();
 
-		local_irq_enable();
+		if (irqs_disabled())
+			local_irq_enable();
+
 		return;
 	}
 
@@ -530,7 +534,9 @@ static void acpi_processor_idle(void)
 		 *       skew otherwise.
 		 */
 		sleep_ticks = 0xFFFFFFFF;
-		local_irq_enable();
+		if (irqs_disabled())
+			local_irq_enable();
+
 		break;
 
 	case ACPI_STATE_C2:

commit 6133116849219f4e657ead39c7ac3922583f5a6e
Author: Pavel Machek <pavel@ucw.cz>
Date:   Tue Feb 19 11:00:29 2008 +0100

    ACPI: TSC breaks atkbd suspend
    
    TSC is used even on machines when CONFIG_X86_TSC is not set (X86_TSC
    means _require_ TSC), but it is not properly disabled when it is
    unusable, because ACPI code understood the config switch as "may use
    TSC".
    
    This actually fixes suspend problems on my x60.
    
    Signed-off-by: Pavel Machek <pavel@suse.cz>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 980e1c33e6c5..6f3b217699e9 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -364,7 +364,7 @@ int acpi_processor_resume(struct acpi_device * device)
 	return 0;
 }
 
-#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86_TSC)
+#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86)
 static int tsc_halts_in_c(int state)
 {
 	switch (boot_cpu_data.x86_vendor) {
@@ -544,7 +544,7 @@ static void acpi_processor_idle(void)
 		/* Get end time (ticks) */
 		t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 
-#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86_TSC)
+#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86)
 		/* TSC halts in C2, so notify users */
 		if (tsc_halts_in_c(ACPI_STATE_C2))
 			mark_tsc_unstable("possible TSC halt in C2");
@@ -609,7 +609,7 @@ static void acpi_processor_idle(void)
 			acpi_set_register(ACPI_BITREG_ARB_DISABLE, 0);
 		}
 
-#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86_TSC)
+#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86)
 		/* TSC halts in C3, so notify users */
 		if (tsc_halts_in_c(ACPI_STATE_C3))
 			mark_tsc_unstable("TSC halts in C3");
@@ -1500,7 +1500,7 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	acpi_idle_do_entry(cx);
 	t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 
-#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86_TSC)
+#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86)
 	/* TSC could halt in idle, so notify users */
 	if (tsc_halts_in_c(cx->type))
 		mark_tsc_unstable("TSC halts in idle");;
@@ -1614,7 +1614,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		spin_unlock(&c3_lock);
 	}
 
-#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86_TSC)
+#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86)
 	/* TSC could halt in idle, so notify users */
 	if (tsc_halts_in_c(ACPI_STATE_C3))
 		mark_tsc_unstable("TSC halts in idle");

commit f60d63f642d824914677fb40330671117dc39c3b
Merge: 46c1fbdb7191 fe8e288a63f2 6bf69b5ebf22
Author: Len Brown <len.brown@intel.com>
Date:   Thu Feb 14 02:44:28 2008 -0500

    Merge branches 'release', 'dmi', 'idle' and 'misc' into release

commit 4fcb2fcd4d0678b8ae103d257dcb28074cbfc7fa
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon Feb 11 17:46:31 2008 -0800

    ACPI, cpuidle: Clarify C-state description in sysfs
    
    Add a new sysfs entry under cpuidle states. desc - can be used by driver to
    communicate to userspace any specific information about the state.
    This helps in identifying the exact hardware C-states behind the ACPI C-state
    definition.
    
    Idea is to export this through powertop, which will help to map the C-state
    reported by powertop to actual hardware C-state.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 32003fdc91e8..baa389b908e2 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -945,11 +945,16 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 				 * Otherwise, ignore this info and continue.
 				 */
 				cx.entry_method = ACPI_CSTATE_HALT;
+				snprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI HLT");
 			} else {
 				continue;
 			}
+		} else {
+			snprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI IOPORT 0x%x",
+				 cx.address);
 		}
 
+
 		obj = &(element->package.elements[2]);
 		if (obj->type != ACPI_TYPE_INTEGER)
 			continue;
@@ -1643,6 +1648,11 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 		return -EINVAL;
 	}
 
+	for (i = 0; i < CPUIDLE_STATE_MAX; i++) {
+		dev->states[i].name[0] = '\0';
+		dev->states[i].desc[0] = '\0';
+	}
+
 	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {
 		cx = &pr->power.states[i];
 		state = &dev->states[count];
@@ -1659,6 +1669,7 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 		cpuidle_set_statedata(state, cx);
 
 		snprintf(state->name, CPUIDLE_NAME_LEN, "C%d", i);
+		strncpy(state->desc, cx->desc, CPUIDLE_DESC_LEN);
 		state->exit_latency = cx->latency;
 		state->target_residency = cx->latency * latency_factor;
 		state->power_usage = cx->power;

commit b077fbada161479d9a32a7730d2822d5e737b306
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon Feb 11 15:20:27 2008 -0800

    ACPI: fix suspend regression due to idle update
    
    Earlier patch (bc71bec91f9875ef825d12104acf3bf4ca215fa4) broke
    suspend resume on many laptops. The problem was reported by
    Carlos R. Mafra and Calvin Walton, who bisected the issue to above patch.
    
    The problem was because, C2 and C3 code were calling acpi_idle_enter_c1
    directly, with C2 or C3 as state parameter, while suspend/resume was in
    progress. The patch bc71bec started making use of that state information,
    assuming that it would always be referring to C1 state. This caused the
    problem with suspend-resume as we ended up using C2/C3 state indirectly.
    
    Fix this by adding acpi_idle_suspend check in enter_c1.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 32003fdc91e8..1f022b0846d4 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1420,6 +1420,14 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 		return 0;
 
 	local_irq_disable();
+
+	/* Do not access any ACPI IO ports in suspend path */
+	if (acpi_idle_suspend) {
+		acpi_safe_halt();
+		local_irq_enable();
+		return 0;
+	}
+
 	if (pr->flags.bm_check)
 		acpi_idle_update_bm_rld(pr, cx);
 

commit acf63867ae06ef95eea7bf445ded2f05528a81b1
Merge: c64768a7d671 f757397097d0 9a0b841586c3
Author: Len Brown <len.brown@intel.com>
Date:   Thu Feb 7 03:11:05 2008 -0500

    Merge branches 'release', 'cpuidle-2.6.25' and 'idle' into release

commit 9a0b841586c3c6c846effdbe75885c2ebc0031b0
Author: venkatesh.pallipadi@intel.com <venkatesh.pallipadi@intel.com>
Date:   Thu Jan 31 17:35:06 2008 -0800

    cpuidle: Add a poll_idle method
    
    Add a default poll idle state with 0 latency. Provides an option to users
    to use poll_idle by using 0 as the latency requirement.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index fea71597b40a..32488e6f76ab 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1628,7 +1628,7 @@ struct cpuidle_driver acpi_idle_driver = {
  */
 static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 {
-	int i, count = 0;
+	int i, count = CPUIDLE_DRIVER_STATE_START;
 	struct acpi_processor_cx *cx;
 	struct cpuidle_state *state;
 	struct cpuidle_device *dev = &pr->power.dev;
@@ -1687,6 +1687,8 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 		}
 
 		count++;
+		if (count == CPUIDLE_STATE_MAX)
+			break;
 	}
 
 	dev->state_count = count;

commit 9b12e18cdc1553de62d931e73443c806347cd974
Author: venkatesh.pallipadi@intel.com <venkatesh.pallipadi@intel.com>
Date:   Thu Jan 31 17:35:05 2008 -0800

    ACPI: cpuidle: Support C1 idle time accounting
    
    Show C1 idle time in /sysfs cpuidle interface. C1 idle time may not
    be entirely accurate in all cases. It includes the time spent
    in the interrupt handler after wakeup with "hlt" based C1. But, it will
    be accurate with "mwait" based C1.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 4ba3a9a473dd..fea71597b40a 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1407,8 +1407,10 @@ static inline void acpi_idle_do_entry(struct acpi_processor_cx *cx)
 static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 			      struct cpuidle_state *state)
 {
+	u32 t1, t2;
 	struct acpi_processor *pr;
 	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
+
 	pr = processors[smp_processor_id()];
 
 	if (unlikely(!pr))
@@ -1418,12 +1420,14 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 	if (pr->flags.bm_check)
 		acpi_idle_update_bm_rld(pr, cx);
 
+	t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 	acpi_idle_do_entry(cx);
+	t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 
 	local_irq_enable();
 	cx->usage++;
 
-	return 0;
+	return ticks_elapsed_in_us(t1, t2);
 }
 
 /**
@@ -1660,6 +1664,7 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 		switch (cx->type) {
 			case ACPI_STATE_C1:
 			state->flags |= CPUIDLE_FLAG_SHALLOW;
+			state->flags |= CPUIDLE_FLAG_TIME_VALID;
 			state->enter = acpi_idle_enter_c1;
 			dev->safe_state = state;
 			break;

commit bc71bec91f9875ef825d12104acf3bf4ca215fa4
Author: venkatesh.pallipadi@intel.com <venkatesh.pallipadi@intel.com>
Date:   Thu Jan 31 17:35:04 2008 -0800

    ACPI: enable MWAIT for C1 idle
    
    Add MWAIT idle for C1 state instead of halt, on platforms that support
    C1 state with MWAIT.
    
    Renames cx->space_id to something more appropriate.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 106a22948aa9..4ba3a9a473dd 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -265,7 +265,7 @@ static atomic_t c3_cpu_count;
 /* Common C-state entry for C2, C3, .. */
 static void acpi_cstate_enter(struct acpi_processor_cx *cstate)
 {
-	if (cstate->space_id == ACPI_CSTATE_FFH) {
+	if (cstate->entry_method == ACPI_CSTATE_FFH) {
 		/* Call into architectural FFH based C-state */
 		acpi_processor_ffh_cstate_enter(cstate);
 	} else {
@@ -929,20 +929,20 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 		cx.address = reg->address;
 		cx.index = current_count + 1;
 
-		cx.space_id = ACPI_CSTATE_SYSTEMIO;
+		cx.entry_method = ACPI_CSTATE_SYSTEMIO;
 		if (reg->space_id == ACPI_ADR_SPACE_FIXED_HARDWARE) {
 			if (acpi_processor_ffh_cstate_probe
 					(pr->id, &cx, reg) == 0) {
-				cx.space_id = ACPI_CSTATE_FFH;
-			} else if (cx.type != ACPI_STATE_C1) {
+				cx.entry_method = ACPI_CSTATE_FFH;
+			} else if (cx.type == ACPI_STATE_C1) {
 				/*
 				 * C1 is a special case where FIXED_HARDWARE
 				 * can be handled in non-MWAIT way as well.
 				 * In that case, save this _CST entry info.
-				 * That is, we retain space_id of SYSTEM_IO for
-				 * halt based C1.
 				 * Otherwise, ignore this info and continue.
 				 */
+				cx.entry_method = ACPI_CSTATE_HALT;
+			} else {
 				continue;
 			}
 		}
@@ -1376,12 +1376,16 @@ static inline void acpi_idle_update_bm_rld(struct acpi_processor *pr,
 /**
  * acpi_idle_do_entry - a helper function that does C2 and C3 type entry
  * @cx: cstate data
+ *
+ * Caller disables interrupt before call and enables interrupt after return.
  */
 static inline void acpi_idle_do_entry(struct acpi_processor_cx *cx)
 {
-	if (cx->space_id == ACPI_CSTATE_FFH) {
+	if (cx->entry_method == ACPI_CSTATE_FFH) {
 		/* Call into architectural FFH based C-state */
 		acpi_processor_ffh_cstate_enter(cx);
+	} else if (cx->entry_method == ACPI_CSTATE_HALT) {
+		acpi_safe_halt();
 	} else {
 		int unused;
 		/* IO port based C-state */
@@ -1414,7 +1418,7 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 	if (pr->flags.bm_check)
 		acpi_idle_update_bm_rld(pr, cx);
 
-	acpi_safe_halt();
+	acpi_idle_do_entry(cx);
 
 	local_irq_enable();
 	cx->usage++;

commit 2e906655baf1c6f6fccd212fc9e6499dc6928b80
Author: venkatesh.pallipadi@intel.com <venkatesh.pallipadi@intel.com>
Date:   Thu Jan 31 17:35:03 2008 -0800

    ACPI: idle: Fix acpi_safe_halt usages and interrupt enabling/disabling
    
    acpi_safe_halt() needs interrupts to be disabled for atomic
    need_resched check and safe halt. Otherwise we may miss an
    interrupt and go into halt.
    
    acpi_safe_halt() also does not enable interrupts on all return paths.
    
    So the callers should handle enable and disable interrupts around it.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 199ea2146153..106a22948aa9 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -201,6 +201,10 @@ static inline u32 ticks_elapsed_in_us(u32 t1, u32 t2)
 		return PM_TIMER_TICKS_TO_US((0xFFFFFFFF - t1) + t2);
 }
 
+/*
+ * Callers should disable interrupts before the call and enable
+ * interrupts after return.
+ */
 static void acpi_safe_halt(void)
 {
 	current_thread_info()->status &= ~TS_POLLING;
@@ -413,6 +417,8 @@ static void acpi_processor_idle(void)
 			pm_idle_save();
 		else
 			acpi_safe_halt();
+
+		local_irq_enable();
 		return;
 	}
 
@@ -521,6 +527,7 @@ static void acpi_processor_idle(void)
 		 *       skew otherwise.
 		 */
 		sleep_ticks = 0xFFFFFFFF;
+		local_irq_enable();
 		break;
 
 	case ACPI_STATE_C2:
@@ -1403,11 +1410,13 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 	if (unlikely(!pr))
 		return 0;
 
+	local_irq_disable();
 	if (pr->flags.bm_check)
 		acpi_idle_update_bm_rld(pr, cx);
 
 	acpi_safe_halt();
 
+	local_irq_enable();
 	cx->usage++;
 
 	return 0;
@@ -1517,7 +1526,9 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		if (dev->safe_state) {
 			return dev->safe_state->enter(dev, dev->safe_state);
 		} else {
+			local_irq_disable();
 			acpi_safe_halt();
+			local_irq_enable();
 			return 0;
 		}
 	}

commit f011e2e2df3393c16b0fdc48e855e909b7e021ee
Author: Mark Gross <mgross@linux.intel.com>
Date:   Mon Feb 4 22:30:09 2008 -0800

    latency.c: use QoS infrastructure
    
    Replace latency.c use with pm_qos_params use.
    
    Signed-off-by: mark gross <mgross@linux.intel.com>
    Cc: "John W. Linville" <linville@tuxdriver.com>
    Cc: Len Brown <lenb@kernel.org>
    Cc: Jaroslav Kysela <perex@suse.cz>
    Cc: Takashi Iwai <tiwai@suse.de>
    Cc: Arjan van de Ven <arjan@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index eb1f82f79153..199ea2146153 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -38,7 +38,7 @@
 #include <linux/dmi.h>
 #include <linux/moduleparam.h>
 #include <linux/sched.h>	/* need_resched() */
-#include <linux/latency.h>
+#include <linux/pm_qos_params.h>
 #include <linux/clockchips.h>
 #include <linux/cpuidle.h>
 
@@ -648,7 +648,8 @@ static void acpi_processor_idle(void)
 	if (cx->promotion.state &&
 	    ((cx->promotion.state - pr->power.states) <= max_cstate)) {
 		if (sleep_ticks > cx->promotion.threshold.ticks &&
-		  cx->promotion.state->latency <= system_latency_constraint()) {
+		  cx->promotion.state->latency <=
+				pm_qos_requirement(PM_QOS_CPU_DMA_LATENCY)) {
 			cx->promotion.count++;
 			cx->demotion.count = 0;
 			if (cx->promotion.count >=
@@ -692,7 +693,8 @@ static void acpi_processor_idle(void)
 	 * or if the latency of the current state is unacceptable
 	 */
 	if ((pr->power.state - pr->power.states) > max_cstate ||
-		pr->power.state->latency > system_latency_constraint()) {
+		pr->power.state->latency >
+				pm_qos_requirement(PM_QOS_CPU_DMA_LATENCY)) {
 		if (cx->demotion.state)
 			next_state = cx->demotion.state;
 	}
@@ -1200,7 +1202,7 @@ static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
 		   "maximum allowed latency: %d usec\n",
 		   pr->power.state ? pr->power.state - pr->power.states : 0,
 		   max_cstate, (unsigned)pr->power.bm_activity,
-		   system_latency_constraint());
+		   pm_qos_requirement(PM_QOS_CPU_DMA_LATENCY));
 
 	seq_puts(seq, "states:\n");
 
@@ -1718,8 +1720,9 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 			       "ACPI: processor limited to max C-state %d\n",
 			       max_cstate);
 		first_run++;
-#if !defined (CONFIG_CPU_IDLE) && defined (CONFIG_SMP)
-		register_latency_notifier(&acpi_processor_latency_notifier);
+#if !defined(CONFIG_CPU_IDLE) && defined(CONFIG_SMP)
+		pm_qos_add_notifier(PM_QOS_CPU_DMA_LATENCY,
+				&acpi_processor_latency_notifier);
 #endif
 	}
 
@@ -1806,7 +1809,8 @@ int acpi_processor_power_exit(struct acpi_processor *pr,
 		 */
 		cpu_idle_wait();
 #ifdef CONFIG_SMP
-		unregister_latency_notifier(&acpi_processor_latency_notifier);
+		pm_qos_remove_notifier(PM_QOS_CPU_DMA_LATENCY,
+				&acpi_processor_latency_notifier);
 #endif
 	}
 #endif

commit ddb25f9ac1c4b4f9ba0bdacd7850a921a0c6886c
Author: Andi Kleen <ak@suse.de>
Date:   Wed Jan 30 13:32:41 2008 +0100

    x86: don't disable TSC in any C states on AMD Fam10h
    
    The ACPI code currently disables TSC use in any C2 and C3
    states. But the AMD Fam10h BKDG documents that the TSC
    will never stop in any C states when the CONSTANT_TSC bit is
    set. Make this disabling conditional on CONSTANT_TSC
    not set on AMD.
    
    I actually think this is true on Intel too for C2 states
    on CPUs with p-state invariant TSC, but this needs
    further discussions with Len to really confirm :-)
    
    So far it is only enabled on AMD.
    
    Cc: lenb@kernel.org
    
    Signed-off-by: Andi Kleen <ak@suse.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 0721a8183c89..eb1f82f79153 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -357,6 +357,26 @@ int acpi_processor_resume(struct acpi_device * device)
 	return 0;
 }
 
+#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86_TSC)
+static int tsc_halts_in_c(int state)
+{
+	switch (boot_cpu_data.x86_vendor) {
+	case X86_VENDOR_AMD:
+		/*
+		 * AMD Fam10h TSC will tick in all
+		 * C/P/S0/S1 states when this bit is set.
+		 */
+		if (boot_cpu_has(X86_FEATURE_CONSTANT_TSC))
+			return 0;
+		/*FALL THROUGH*/
+	case X86_VENDOR_INTEL:
+		/* Several cases known where TSC halts in C2 too */
+	default:
+		return state > ACPI_STATE_C1;
+	}
+}
+#endif
+
 #ifndef CONFIG_CPU_IDLE
 static void acpi_processor_idle(void)
 {
@@ -516,7 +536,8 @@ static void acpi_processor_idle(void)
 
 #if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86_TSC)
 		/* TSC halts in C2, so notify users */
-		mark_tsc_unstable("possible TSC halt in C2");
+		if (tsc_halts_in_c(ACPI_STATE_C2))
+			mark_tsc_unstable("possible TSC halt in C2");
 #endif
 		/* Compute time (ticks) that we were actually asleep */
 		sleep_ticks = ticks_elapsed(t1, t2);
@@ -580,7 +601,8 @@ static void acpi_processor_idle(void)
 
 #if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86_TSC)
 		/* TSC halts in C3, so notify users */
-		mark_tsc_unstable("TSC halts in C3");
+		if (tsc_halts_in_c(ACPI_STATE_C3))
+			mark_tsc_unstable("TSC halts in C3");
 #endif
 		/* Compute time (ticks) that we were actually asleep */
 		sleep_ticks = ticks_elapsed(t1, t2);
@@ -1445,7 +1467,8 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 
 #if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86_TSC)
 	/* TSC could halt in idle, so notify users */
-	mark_tsc_unstable("TSC halts in idle");;
+	if (tsc_halts_in_c(cx->type))
+		mark_tsc_unstable("TSC halts in idle");;
 #endif
 	sleep_ticks = ticks_elapsed(t1, t2);
 
@@ -1556,7 +1579,8 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 
 #if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86_TSC)
 	/* TSC could halt in idle, so notify users */
-	mark_tsc_unstable("TSC halts in idle");
+	if (tsc_halts_in_c(ACPI_STATE_C3))
+		mark_tsc_unstable("TSC halts in idle");
 #endif
 	sleep_ticks = ticks_elapsed(t1, t2);
 	/* Tell the scheduler how much we idled: */

commit bde6f5f59c2b2b48a7a849c129d5b48838fe77ee
Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Wed Jan 30 13:32:01 2008 +0100

    x86: voluntary leave_mm before entering ACPI C3
    
    Aviod TLB flush IPIs during C3 states by voluntary leave_mm()
    before entering C3.
    
    The performance impact of TLB flush on C3 should not be significant with
    respect to C3 wakeup latency. Also, CPUs tend to flush TLB in hardware while in
    C3 anyways.
    
    On a 8 logical CPU system, running make -j2, the number of tlbflush IPIs goes
    down from 40 per second to ~ 0. Total number of interrupts during the run
    of this workload was ~1200 per second, which makes it ~3% savings in wakeups.
    
    There was no measurable performance or power impact however.
    
    [ akpm@linux-foundation.org: symbol export fixes. ]
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 2235f4e02d26..0721a8183c89 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -534,6 +534,7 @@ static void acpi_processor_idle(void)
 		break;
 
 	case ACPI_STATE_C3:
+		acpi_unlazy_tlb(smp_processor_id());
 		/*
 		 * Must be done before busmaster disable as we might
 		 * need to access HPET !
@@ -1423,6 +1424,7 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 		return 0;
 	}
 
+	acpi_unlazy_tlb(smp_processor_id());
 	/*
 	 * Must be done before busmaster disable as we might need to
 	 * access HPET !

commit 5b3f0e6c1c9638b11a1063bf93c60a0766550b02
Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon Jan 7 17:50:10 2008 -0500

    ACPI: Reintroduce run time configurable max_cstate for !CPU_IDLE case
    
    This was writeable in 2.6.23 but the cpuidle merge made it read-only.  But
    some people's scripts (ie: Mark's) were writing to it.
    
    As an unhappy compromise, make max_cstate writeable again if the kernel was
    configured without CONFIG_CPU_IDLE.
    
    http://bugzilla.kernel.org/show_bug.cgi?id=9683
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Cc: Mark Lord <lkml@rtr.ca>
    Cc: Arjan van de Ven <arjan@infradead.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: "Rafael J. Wysocki" <rjw@sisk.pl>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 2fe34cc73c13..2235f4e02d26 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -76,7 +76,11 @@ static void (*pm_idle_save) (void) __read_mostly;
 #define PM_TIMER_TICKS_TO_US(p)		(((p) * 1000)/(PM_TIMER_FREQUENCY/1000))
 
 static unsigned int max_cstate __read_mostly = ACPI_PROCESSOR_MAX_POWER;
+#ifdef CONFIG_CPU_IDLE
 module_param(max_cstate, uint, 0000);
+#else
+module_param(max_cstate, uint, 0644);
+#endif
 static unsigned int nocst __read_mostly;
 module_param(nocst, uint, 0000);
 

commit 25de5718356e264820625600a9edca1df5ff26f8
Author: Len Brown <len.brown@intel.com>
Date:   Fri Dec 14 00:24:15 2007 -0500

    cpuidle: default processor.latency_factor=2
    
    More aggressively request deep C-states.
    
    Note that the job of the OS is to minimize latency
    impact to expected break events such as interrupts.
    
    It is not the job of the OS to try to calculate if
    the C-state will reach energy break-even.
    The platform doesn't give the OS enough information
    for it to make that calculation.  Thus, it is up
    to the platform to decide if it is worth it to
    go as deep as the OS requested it to, or if it
    should internally demote to a more shallow C-state.
    
    But the converse is not true.  The platform can not
    promote into a deeper C-state than the OS requested
    else it may violate latency constraints.  So it is
    important that the OS be aggressive in giving the
    platform permission to enter deep C-states.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 26ade1f3f5cd..bc99b7b9094f 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -95,7 +95,7 @@ module_param(bm_history, uint, 0644);
 static int acpi_processor_set_power_policy(struct acpi_processor *pr);
 
 #else	/* CONFIG_CPU_IDLE */
-static unsigned int latency_factor __read_mostly = 6;
+static unsigned int latency_factor __read_mostly = 2;
 module_param(latency_factor, uint, 0644);
 #endif
 

commit 4963f62045b64f93c45fbcb6f8f0baf1e3e7a127
Author: Len Brown <len.brown@intel.com>
Date:   Thu Dec 13 23:50:45 2007 -0500

    cpuidle: create processor.latency_factor tunable
    
    Start with default value of 6, so by default,
    there is no functional change in this patch.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index f996d0e37689..26ade1f3f5cd 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -94,6 +94,9 @@ module_param(bm_history, uint, 0644);
 
 static int acpi_processor_set_power_policy(struct acpi_processor *pr);
 
+#else	/* CONFIG_CPU_IDLE */
+static unsigned int latency_factor __read_mostly = 6;
+module_param(latency_factor, uint, 0644);
 #endif
 
 /*
@@ -1576,7 +1579,7 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 
 		snprintf(state->name, CPUIDLE_NAME_LEN, "C%d", i);
 		state->exit_latency = cx->latency;
-		state->target_residency = cx->latency * 6;
+		state->target_residency = cx->latency * latency_factor;
 		state->power_usage = cx->power;
 
 		state->flags = 0;

commit e17bcb43a26a7111f851b5ff6d1258ecd355de75
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Dec 7 19:16:17 2007 +0100

    ACPI: move timer broadcast before busmaster disable
    
    The timer broadcast code might access HPET, which should not be
    accessed after the busmaster disable.
    
    In acpi_idle_enter_simple() this change also prevents, that we modify
    the busmaster state without going actually idle. This might leave the
    ACPI bm state in a stale state, when we leave the function early in
    the need_resched() check.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index b1fbee3f7fe1..2fe34cc73c13 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -530,6 +530,11 @@ static void acpi_processor_idle(void)
 		break;
 
 	case ACPI_STATE_C3:
+		/*
+		 * Must be done before busmaster disable as we might
+		 * need to access HPET !
+		 */
+		acpi_state_timer_broadcast(pr, cx, 1);
 		/*
 		 * disable bus master
 		 * bm_check implies we need ARB_DIS
@@ -557,7 +562,6 @@ static void acpi_processor_idle(void)
 		/* Get start time (ticks) */
 		t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 		/* Invoke C3 */
-		acpi_state_timer_broadcast(pr, cx, 1);
 		/* Tell the scheduler that we are going deep-idle: */
 		sched_clock_idle_sleep_event();
 		acpi_cstate_enter(cx);
@@ -1401,9 +1405,6 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	if (acpi_idle_suspend)
 		return(acpi_idle_enter_c1(dev, state));
 
-	if (pr->flags.bm_check)
-		acpi_idle_update_bm_rld(pr, cx);
-
 	local_irq_disable();
 	current_thread_info()->status &= ~TS_POLLING;
 	/*
@@ -1418,13 +1419,21 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 		return 0;
 	}
 
+	/*
+	 * Must be done before busmaster disable as we might need to
+	 * access HPET !
+	 */
+	acpi_state_timer_broadcast(pr, cx, 1);
+
+	if (pr->flags.bm_check)
+		acpi_idle_update_bm_rld(pr, cx);
+
 	if (cx->type == ACPI_STATE_C3)
 		ACPI_FLUSH_CPU_CACHE();
 
 	t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 	/* Tell the scheduler that we are going deep-idle: */
 	sched_clock_idle_sleep_event();
-	acpi_state_timer_broadcast(pr, cx, 1);
 	acpi_idle_do_entry(cx);
 	t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 

commit ff1ea52fa317a5658b6415b25169c5e531f54876
Merge: b5faa4b89e4d f44d9efd3510
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Mon Nov 26 19:41:28 2007 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/x86/linux-2.6-x86
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/x86/linux-2.6-x86:
      x86: fix APIC related bootup crash on Athlon XP CPUs
      time: add ADJ_OFFSET_SS_READ
      x86: export the symbol empty_zero_page on the 32-bit x86 architecture
      x86: fix kprobes_64.c inlining borkage
      pci: use pci=bfsort for HP DL385 G2, DL585 G2
      x86: correctly set UTS_MACHINE for "make ARCH=x86"
      lockdep: annotate do_debug() trap handler
      x86: turn off iommu merge by default
      x86: fix ACPI compile for LOCAL_APIC=n
      x86: printk kernel version in WARN_ON and other dump_stack users
      ACPI: Set max_cstate to 1 for early Opterons.
      x86: fix NMI watchdog & 'stopped time' problem

commit c1c306344669ca40255e36192b101060ffbb1271
Author: Alexey Starikovskiy <aystarik@gmail.com>
Date:   Mon Nov 26 20:42:19 2007 +0100

    ACPI: Set max_cstate to 1 for early Opterons.
    
    AMD Opteron processors before CG revision don't like C-states > 1.
    
    This solves the long standing bugzilla #5303 and probably some more
    on affected machines:
    
      http://bugzilla.kernel.org/show_bug.cgi?id=5303
    
    [ tglx@linutronix.de: reworked the patch so it does not wreck ia64 ]
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index f996d0e37689..b52109bd06d2 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1658,6 +1658,7 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 
 	if (!first_run) {
 		dmi_check_system(processor_power_dmi_table);
+		max_cstate = acpi_processor_cstate_check(max_cstate);
 		if (max_cstate < ACPI_C_STATES_MAX)
 			printk(KERN_NOTICE
 			       "ACPI: processor limited to max C-state %d\n",

commit 95b00786f3b8fa99f53931361beeb4c10504ad87
Merge: 22201f740285 ddc081a19585
Author: Len Brown <len.brown@intel.com>
Date:   Tue Nov 20 01:18:37 2007 -0500

    Pull cpuidle into release branch

commit ddc081a19585c8ba5aad437779950c2ef215360a
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon Nov 19 21:43:22 2007 -0500

    cpuidle: fix HP nx6125 regression
    
    Fix for http://bugzilla.kernel.org/show_bug.cgi?id=9355
    
    cpuidle always used to fallback to C2 if there is some bm activity while
    entering C3. But, presence of C2 is not always guaranteed. Change cpuidle
    algorithm to detect a safe_state to fallback in case of bm_activity and
    use that state instead of C2.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 1af0694e8520..8904f5c82a1c 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -197,6 +197,19 @@ static inline u32 ticks_elapsed_in_us(u32 t1, u32 t2)
 		return PM_TIMER_TICKS_TO_US((0xFFFFFFFF - t1) + t2);
 }
 
+static void acpi_safe_halt(void)
+{
+	current_thread_info()->status &= ~TS_POLLING;
+	/*
+	 * TS_POLLING-cleared state must be visible before we
+	 * test NEED_RESCHED:
+	 */
+	smp_mb();
+	if (!need_resched())
+		safe_halt();
+	current_thread_info()->status |= TS_POLLING;
+}
+
 #ifndef CONFIG_CPU_IDLE
 
 static void
@@ -239,19 +252,6 @@ acpi_processor_power_activate(struct acpi_processor *pr,
 	return;
 }
 
-static void acpi_safe_halt(void)
-{
-	current_thread_info()->status &= ~TS_POLLING;
-	/*
-	 * TS_POLLING-cleared state must be visible before we
-	 * test NEED_RESCHED:
-	 */
-	smp_mb();
-	if (!need_resched())
-		safe_halt();
-	current_thread_info()->status |= TS_POLLING;
-}
-
 static atomic_t c3_cpu_count;
 
 /* Common C-state entry for C2, C3, .. */
@@ -1385,15 +1385,7 @@ static int acpi_idle_enter_c1(struct cpuidle_device *dev,
 	if (pr->flags.bm_check)
 		acpi_idle_update_bm_rld(pr, cx);
 
-	current_thread_info()->status &= ~TS_POLLING;
-	/*
-	 * TS_POLLING-cleared state must be visible before we test
-	 * NEED_RESCHED:
-	 */
-	smp_mb();
-	if (!need_resched())
-		safe_halt();
-	current_thread_info()->status |= TS_POLLING;
+	acpi_safe_halt();
 
 	cx->usage++;
 
@@ -1493,6 +1485,15 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	if (acpi_idle_suspend)
 		return(acpi_idle_enter_c1(dev, state));
 
+	if (acpi_idle_bm_check()) {
+		if (dev->safe_state) {
+			return dev->safe_state->enter(dev, dev->safe_state);
+		} else {
+			acpi_safe_halt();
+			return 0;
+		}
+	}
+
 	local_irq_disable();
 	current_thread_info()->status &= ~TS_POLLING;
 	/*
@@ -1515,49 +1516,39 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	 */
 	acpi_state_timer_broadcast(pr, cx, 1);
 
-	if (acpi_idle_bm_check()) {
-		cx = pr->power.bm_state;
-
-		acpi_idle_update_bm_rld(pr, cx);
-
-		t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
-		acpi_idle_do_entry(cx);
-		t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
-	} else {
-		acpi_idle_update_bm_rld(pr, cx);
+	acpi_idle_update_bm_rld(pr, cx);
 
-		/*
-		 * disable bus master
-		 * bm_check implies we need ARB_DIS
-		 * !bm_check implies we need cache flush
-		 * bm_control implies whether we can do ARB_DIS
-		 *
-		 * That leaves a case where bm_check is set and bm_control is
-		 * not set. In that case we cannot do much, we enter C3
-		 * without doing anything.
-		 */
-		if (pr->flags.bm_check && pr->flags.bm_control) {
-			spin_lock(&c3_lock);
-			c3_cpu_count++;
-			/* Disable bus master arbitration when all CPUs are in C3 */
-			if (c3_cpu_count == num_online_cpus())
-				acpi_set_register(ACPI_BITREG_ARB_DISABLE, 1);
-			spin_unlock(&c3_lock);
-		} else if (!pr->flags.bm_check) {
-			ACPI_FLUSH_CPU_CACHE();
-		}
+	/*
+	 * disable bus master
+	 * bm_check implies we need ARB_DIS
+	 * !bm_check implies we need cache flush
+	 * bm_control implies whether we can do ARB_DIS
+	 *
+	 * That leaves a case where bm_check is set and bm_control is
+	 * not set. In that case we cannot do much, we enter C3
+	 * without doing anything.
+	 */
+	if (pr->flags.bm_check && pr->flags.bm_control) {
+		spin_lock(&c3_lock);
+		c3_cpu_count++;
+		/* Disable bus master arbitration when all CPUs are in C3 */
+		if (c3_cpu_count == num_online_cpus())
+			acpi_set_register(ACPI_BITREG_ARB_DISABLE, 1);
+		spin_unlock(&c3_lock);
+	} else if (!pr->flags.bm_check) {
+		ACPI_FLUSH_CPU_CACHE();
+	}
 
-		t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
-		acpi_idle_do_entry(cx);
-		t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
+	t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
+	acpi_idle_do_entry(cx);
+	t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 
-		/* Re-enable bus master arbitration */
-		if (pr->flags.bm_check && pr->flags.bm_control) {
-			spin_lock(&c3_lock);
-			acpi_set_register(ACPI_BITREG_ARB_DISABLE, 0);
-			c3_cpu_count--;
-			spin_unlock(&c3_lock);
-		}
+	/* Re-enable bus master arbitration */
+	if (pr->flags.bm_check && pr->flags.bm_control) {
+		spin_lock(&c3_lock);
+		acpi_set_register(ACPI_BITREG_ARB_DISABLE, 0);
+		c3_cpu_count--;
+		spin_unlock(&c3_lock);
 	}
 
 #if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86_TSC)
@@ -1626,12 +1617,14 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 			case ACPI_STATE_C1:
 			state->flags |= CPUIDLE_FLAG_SHALLOW;
 			state->enter = acpi_idle_enter_c1;
+			dev->safe_state = state;
 			break;
 
 			case ACPI_STATE_C2:
 			state->flags |= CPUIDLE_FLAG_BALANCED;
 			state->flags |= CPUIDLE_FLAG_TIME_VALID;
 			state->enter = acpi_idle_enter_simple;
+			dev->safe_state = state;
 			break;
 
 			case ACPI_STATE_C3:
@@ -1652,14 +1645,6 @@ static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
 	if (!count)
 		return -EINVAL;
 
-	/* find the deepest state that can handle active BM */
-	if (pr->flags.bm_check) {
-		for (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++)
-			if (pr->power.states[i].type == ACPI_STATE_C3)
-				break;
-		pr->power.bm_state = &pr->power.states[i-1];
-	}
-
 	return 0;
 }
 

commit 5062911830a66df0c0ad28c387a8c0623cb0d28c
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon Nov 19 19:49:00 2007 -0500

    cpuidle: add sched_clock_idle_[sleep|wakeup]_event() hooks
    
    Port 2aa44d0567ed21b47b87d68819415d48194cb923
    (sched: sched_clock_idle_[sleep|wakeup]_event()) to cpuidle.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 943a88069001..1af0694e8520 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1411,6 +1411,8 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	struct acpi_processor *pr;
 	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
 	u32 t1, t2;
+	int sleep_ticks = 0;
+
 	pr = processors[smp_processor_id()];
 
 	if (unlikely(!pr))
@@ -1440,6 +1442,8 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 		ACPI_FLUSH_CPU_CACHE();
 
 	t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
+	/* Tell the scheduler that we are going deep-idle: */
+	sched_clock_idle_sleep_event();
 	acpi_state_timer_broadcast(pr, cx, 1);
 	acpi_idle_do_entry(cx);
 	t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
@@ -1448,6 +1452,10 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	/* TSC could halt in idle, so notify users */
 	mark_tsc_unstable("TSC halts in idle");;
 #endif
+	sleep_ticks = ticks_elapsed(t1, t2);
+
+	/* Tell the scheduler how much we idled: */
+	sched_clock_idle_wakeup_event(sleep_ticks*PM_TIMER_TICK_NS);
 
 	local_irq_enable();
 	current_thread_info()->status |= TS_POLLING;
@@ -1455,7 +1463,7 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	cx->usage++;
 
 	acpi_state_timer_broadcast(pr, cx, 0);
-	cx->time += ticks_elapsed(t1, t2);
+	cx->time += sleep_ticks;
 	return ticks_elapsed_in_us(t1, t2);
 }
 
@@ -1475,6 +1483,8 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	struct acpi_processor *pr;
 	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
 	u32 t1, t2;
+	int sleep_ticks = 0;
+
 	pr = processors[smp_processor_id()];
 
 	if (unlikely(!pr))
@@ -1497,6 +1507,8 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 		return 0;
 	}
 
+	/* Tell the scheduler that we are going deep-idle: */
+	sched_clock_idle_sleep_event();
 	/*
 	 * Must be done before busmaster disable as we might need to
 	 * access HPET !
@@ -1552,6 +1564,9 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	/* TSC could halt in idle, so notify users */
 	mark_tsc_unstable("TSC halts in idle");
 #endif
+	sleep_ticks = ticks_elapsed(t1, t2);
+	/* Tell the scheduler how much we idled: */
+	sched_clock_idle_wakeup_event(sleep_ticks*PM_TIMER_TICK_NS);
 
 	local_irq_enable();
 	current_thread_info()->status |= TS_POLLING;
@@ -1559,7 +1574,7 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	cx->usage++;
 
 	acpi_state_timer_broadcast(pr, cx, 0);
-	cx->time += ticks_elapsed(t1, t2);
+	cx->time += sleep_ticks;
 	return ticks_elapsed_in_us(t1, t2);
 }
 

commit c9c860e5349ef62cd9226694b3aa625ef66f504e
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon Nov 19 19:48:00 2007 -0500

    cpuidle: fix C3 for no bus-master control case
    
    Port 18eab8550397f1f3d4b8b2c5257c88dae25d58ed
    (Enable C3 even when PM2_control is zero) to cpuidle.
    
    Without this patch, some systems will notice a regression
    when enabling CPU_IDLE -- C3 would no longer be available.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 0cad56ca342b..943a88069001 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1514,23 +1514,38 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	} else {
 		acpi_idle_update_bm_rld(pr, cx);
 
-		spin_lock(&c3_lock);
-		c3_cpu_count++;
-		/* Disable bus master arbitration when all CPUs are in C3 */
-		if (c3_cpu_count == num_online_cpus())
-			acpi_set_register(ACPI_BITREG_ARB_DISABLE, 1);
-		spin_unlock(&c3_lock);
+		/*
+		 * disable bus master
+		 * bm_check implies we need ARB_DIS
+		 * !bm_check implies we need cache flush
+		 * bm_control implies whether we can do ARB_DIS
+		 *
+		 * That leaves a case where bm_check is set and bm_control is
+		 * not set. In that case we cannot do much, we enter C3
+		 * without doing anything.
+		 */
+		if (pr->flags.bm_check && pr->flags.bm_control) {
+			spin_lock(&c3_lock);
+			c3_cpu_count++;
+			/* Disable bus master arbitration when all CPUs are in C3 */
+			if (c3_cpu_count == num_online_cpus())
+				acpi_set_register(ACPI_BITREG_ARB_DISABLE, 1);
+			spin_unlock(&c3_lock);
+		} else if (!pr->flags.bm_check) {
+			ACPI_FLUSH_CPU_CACHE();
+		}
 
 		t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 		acpi_idle_do_entry(cx);
 		t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 
-		spin_lock(&c3_lock);
 		/* Re-enable bus master arbitration */
-		if (c3_cpu_count == num_online_cpus())
+		if (pr->flags.bm_check && pr->flags.bm_control) {
+			spin_lock(&c3_lock);
 			acpi_set_register(ACPI_BITREG_ARB_DISABLE, 0);
-		c3_cpu_count--;
-		spin_unlock(&c3_lock);
+			c3_cpu_count--;
+			spin_unlock(&c3_lock);
+		}
 	}
 
 #if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86_TSC)

commit c4ec20717313daafba59225f812db89595952b83
Merge: ec2626815bf9 00a2b433557f
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Fri Oct 19 13:12:46 2007 -0700

    Merge branch 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-acpi-2.6
    
    * 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-acpi-2.6: (41 commits)
      ACPICA: hw: Don't carry spinlock over suspend
      ACPICA: hw: remove use_lock flag from acpi_hw_register_{read, write}
      ACPI: cpuidle: port idle timer suspend/resume workaround to cpuidle
      ACPI: clean up acpi_enter_sleep_state_prep
      Hibernation: Make sure that ACPI is enabled in acpi_hibernation_finish
      ACPI: suppress uninitialized var warning
      cpuidle: consolidate 2.6.22 cpuidle branch into one patch
      ACPI: thinkpad-acpi: skip blanks before the data when parsing sysfs
      ACPI: AC: Add sysfs interface
      ACPI: SBS: Add sysfs alarm
      ACPI: SBS: Add ACPI_PROCFS around procfs handling code.
      ACPI: SBS: Add support for power_supply class (and sysfs)
      ACPI: SBS: Make SBS reads table-driven.
      ACPI: SBS: Simplify data structures in SBS
      ACPI: SBS: Split host controller (ACPI0001) from SBS driver (ACPI0002)
      ACPI: EC: Add new query handler to list head.
      ACPI: Add acpi_bus_generate_event4() function
      ACPI: Battery: add sysfs alarm
      ACPI: Battery: Add sysfs support
      ACPI: Battery: Misc clean-ups, no functional changes
      ...
    
    Fix up conflicts in drivers/misc/thinkpad_acpi.[ch] manually

commit 43ca7ec96f01bd921e772112729005d4474fdbf4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Oct 12 23:04:23 2007 +0200

    ACPI: remove the now unused ifdef code
    
    The conversion of x86-64 to clock events makes the
     #ifdef CONFIG_GENERIC_CLOCKEVENTS
     n the timer broadcast functions useless. Remove it.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: john stultz <johnstul@us.ibm.com>
    Cc: Andi Kleen <ak@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 1e8287b4f40c..1f6fb38de017 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -276,21 +276,12 @@ static void acpi_timer_check_state(int state, struct acpi_processor *pr,
 
 static void acpi_propagate_timer_broadcast(struct acpi_processor *pr)
 {
-#ifdef CONFIG_GENERIC_CLOCKEVENTS
 	unsigned long reason;
 
 	reason = pr->power.timer_broadcast_on_state < INT_MAX ?
 		CLOCK_EVT_NOTIFY_BROADCAST_ON : CLOCK_EVT_NOTIFY_BROADCAST_OFF;
 
 	clockevents_notify(reason, &pr->id);
-#else
-	cpumask_t mask = cpumask_of_cpu(pr->id);
-
-	if (pr->power.timer_broadcast_on_state < INT_MAX)
-		on_each_cpu(switch_APIC_timer_to_ipi, &mask, 1, 1);
-	else
-		on_each_cpu(switch_ipi_to_APIC_timer, &mask, 1, 1);
-#endif
 }
 
 /* Power(C) State timer broadcast control */
@@ -298,8 +289,6 @@ static void acpi_state_timer_broadcast(struct acpi_processor *pr,
 				       struct acpi_processor_cx *cx,
 				       int broadcast)
 {
-#ifdef CONFIG_GENERIC_CLOCKEVENTS
-
 	int state = cx - pr->power.states;
 
 	if (state >= pr->power.timer_broadcast_on_state) {
@@ -309,7 +298,6 @@ static void acpi_state_timer_broadcast(struct acpi_processor *pr,
 			CLOCK_EVT_NOTIFY_BROADCAST_EXIT;
 		clockevents_notify(reason, &pr->id);
 	}
-#endif
 }
 
 #else

commit e196441bdf2dbf0526b28a6829c39557c236d611
Author: Len Brown <len.brown@intel.com>
Date:   Thu Oct 4 01:23:47 2007 -0400

    ACPI: cpuidle: port idle timer suspend/resume workaround to cpuidle
    
    Some timers stop during C2 and C3, and so there are various
    generations of timer broadcast workarounds to deal with that.
    But that (already complex) code gets confused during suspend.
    
    As it is unlikely that deep C-states would save much power
    during the actual suspend/resume process anyway, deep C-states
    were disabled via the addition of .suspend/.resume hooks
    in to the ACPI processor driver.
    
    Here that workaround is ported to the cpuidle version of
    the ACPI idle loop.  Technically, ACPI could un-register
    itself from cpuidle on .suspend, but that code path
    is currently quite cumbersome.  So instead,
    we simply invoke C1 from the C2 and C3 handlers
    for the duration of .suspend/.resume.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 99da6a790857..0cad56ca342b 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1416,6 +1416,9 @@ static int acpi_idle_enter_simple(struct cpuidle_device *dev,
 	if (unlikely(!pr))
 		return 0;
 
+	if (acpi_idle_suspend)
+		return(acpi_idle_enter_c1(dev, state));
+
 	if (pr->flags.bm_check)
 		acpi_idle_update_bm_rld(pr, cx);
 
@@ -1477,6 +1480,9 @@ static int acpi_idle_enter_bm(struct cpuidle_device *dev,
 	if (unlikely(!pr))
 		return 0;
 
+	if (acpi_idle_suspend)
+		return(acpi_idle_enter_c1(dev, state));
+
 	local_irq_disable();
 	current_thread_info()->status &= ~TS_POLLING;
 	/*

commit 4f86d3a8e297205780cca027e974fd5f81064780
Author: Len Brown <len.brown@intel.com>
Date:   Wed Oct 3 18:58:00 2007 -0400

    cpuidle: consolidate 2.6.22 cpuidle branch into one patch
    
    commit e5a16b1f9eec0af7cfa0830304b41c1c0833cf9f
    Author: Len Brown <len.brown@intel.com>
    Date:   Tue Oct 2 23:44:44 2007 -0400
    
        cpuidle: shrink diff
    
        processor_idle.c |  440 +++++++++++++++++++++++++++++++++++++++++--
        1 file changed, 429 insertions(+), 11 deletions(-)
    
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit dfbb9d5aedfb18848a3e0d6f6e3e4969febb209c
    Author: Len Brown <len.brown@intel.com>
    Date:   Wed Sep 26 02:17:55 2007 -0400
    
        cpuidle: reduce diff size
    
        Reduces the cpuidle processor_idle.c diff vs 2.6.22 from this
         processor_idle.c | 2006 ++++++++++++++++++++++++++-----------------
         1 file changed, 1219 insertions(+), 787 deletions(-)
    
        to this:
         processor_idle.c |  502 +++++++++++++++++++++++++++++++++++++++----
         1 file changed, 458 insertions(+), 44 deletions(-)
    
        ...for the purpose of making the cpuilde patch less invasive
        and easier to review.
    
        no functional changes.  build tested only.
    
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 889172fc915f5a7fe20f35b133cbd205ce69bf6c
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Thu Sep 13 13:40:05 2007 -0700
    
        cpuidle: Retain old ACPI policy for !CONFIG_CPU_IDLE
    
        Retain the old policy in processor_idle, so that when CPU_IDLE is not
        configured, old C-state policy will still be used. This provides a
        clean gradual migration path from old ACPI policy to new cpuidle
        based policy.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 9544a8181edc7ecc33b3bfd69271571f98ed08bc
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Thu Sep 13 13:39:17 2007 -0700
    
        cpuidle: Configure governors by default
    
        Quoting Len "Do not give an option to users to shoot themselves in the foot".
    
        Remove the configurability of ladder and menu governors as they are
        needed for default policy of cpuidle. That way users will not be able to
        have cpuidle without any policy loosing all C-state power savings.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 8975059a2c1e56cfe83d1bcf031bcf4cb39be743
    Author: Adam Belay <abelay@novell.com>
    Date:   Tue Aug 21 18:27:07 2007 -0400
    
        CPUIDLE: load ACPI properly when CPUIDLE is disabled
    
        Change the registration return codes for when CPUIDLE
        support is not compiled into the kernel.  As a result, the ACPI
        processor driver will load properly even if CPUIDLE is unavailable.
        However, it may be possible to cleanup the ACPI processor driver further
        and eliminate some dead code paths.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit e0322e2b58dd1b12ec669bf84693efe0dc2414a8
    Author: Adam Belay <abelay@novell.com>
    Date:   Tue Aug 21 18:26:06 2007 -0400
    
        CPUIDLE: remove cpuidle_get_bm_activity()
    
        Remove cpuidle_get_bm_activity() and updates governors
        accordingly.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 18a6e770d5c82ba26653e53d240caa617e09e9ab
    Author: Adam Belay <abelay@novell.com>
    Date:   Tue Aug 21 18:25:58 2007 -0400
    
        CPUIDLE: max_cstate fix
    
        Currently max_cstate is limited to 0, resulting in no idle processor
        power management on ACPI platforms.  This patch restores the value to
        the array size.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 1fdc0887286179b40ce24bcdbde663172e205ef0
    Author: Adam Belay <abelay@novell.com>
    Date:   Tue Aug 21 18:25:40 2007 -0400
    
        CPUIDLE: handle BM detection inside the ACPI Processor driver
    
        Update the ACPI processor driver to detect BM activity and
        limit state entry depth internally, rather than exposing such
        requirements to CPUIDLE.  As a result, CPUIDLE can drop this
        ACPI-specific interface and become more platform independent.  BM
        activity is now handled much more aggressively than it was in the
        original implementation, so some testing coverage may be needed to
        verify that this doesn't introduce any DMA buffer under-run issues.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 0ef38840db666f48e3cdd2b769da676c57228dd9
    Author: Adam Belay <abelay@novell.com>
    Date:   Tue Aug 21 18:25:14 2007 -0400
    
        CPUIDLE: menu governor updates
    
        Tweak the menu governor to more effectively handle non-timer
        break events.  Non-timer break events are detected by comparing the
        actual sleep time to the expected sleep time.  In future revisions, it
        may be more reliable to use the timer data structures directly.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit bb4d74fca63fa96cf3ace644b15ae0f12b7df5a1
    Author: Adam Belay <abelay@novell.com>
    Date:   Tue Aug 21 18:24:40 2007 -0400
    
        CPUIDLE: fix 'current_governor' sysfs entry
    
        Allow the "current_governor" sysfs entry to properly handle
        input terminated with '\n'.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit df3c71559bb69b125f1a48971bf0d17f78bbdf47
    Author: Len Brown <len.brown@intel.com>
    Date:   Sun Aug 12 02:00:45 2007 -0400
    
        cpuidle: fix IA64 build (again)
    
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit a02064579e3f9530fd31baae16b1fc46b5a7bca8
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Sun Aug 12 01:39:27 2007 -0400
    
        cpuidle: Remove support for runtime changing of max_cstate
    
        Remove support for runtime changeability of max_cstate. Drivers can use
        use latency APIs.
    
        max_cstate can still be used as a boot time option and dmi override.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 0912a44b13adf22f5e3f607d263aed23b4910d7e
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Sun Aug 12 01:39:16 2007 -0400
    
        cpuidle: Remove ACPI cstate_limit calls from ipw2100
    
        ipw2100 already has code to use accetable_latency interfaces to limit the
        C-state. Remove the calls to acpi_set_cstate_limit and acpi_get_cstate_limit
        as they are redundant.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit c649a76e76be6bff1fd770d0a775798813a3f6e0
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Sun Aug 12 01:35:39 2007 -0400
    
        cpuidle: compile fix for pause and resume functions
    
        Fix the compilation failure when cpuidle is not compiled in.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Acked-by: Adam Belay <adam.belay@novell.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 2305a5920fb8ee6ccec1c62ade05aa8351091d71
    Author: Adam Belay <abelay@novell.com>
    Date:   Thu Jul 19 00:49:00 2007 -0400
    
        cpuidle: re-write
    
        Some portions have been rewritten to make the code cleaner and lighter
        weight.  The following is a list of changes:
    
        1.) the state name is now included in the sysfs interface
        2.) detection, hotplug, and available state modifications are handled by
        CPUIDLE drivers directly
        3.) the CPUIDLE idle handler is only ever installed when at least one
        cpuidle_device is enabled and ready
        4.) the menu governor BM code no longer overflows
        5.) the sysfs attributes are now printed as unsigned integers, avoiding
        negative values
        6.) a variety of other small cleanups
    
        Also, Idle drivers are no longer swappable during runtime through the
        CPUIDLE sysfs inteface.  On i386 and x86_64 most idle handlers (e.g.
        poll, mwait, halt, etc.) don't benefit from an infrastructure that
        supports multiple states, so I think using a more general case idle
        handler selection mechanism would be cleaner.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Acked-by: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit df25b6b56955714e6e24b574d88d1fd11f0c3ee5
    Author: Len Brown <len.brown@intel.com>
    Date:   Tue Jul 24 17:08:21 2007 -0400
    
        cpuidle: fix IA64 buid
    
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit fd6ada4c14488755ff7068860078c437431fbccd
    Author: Adrian Bunk <bunk@stusta.de>
    Date:   Mon Jul 9 11:33:13 2007 -0700
    
        cpuidle: static
    
        make cpuidle_replace_governor() static
    
        Signed-off-by: Adrian Bunk <bunk@stusta.de>
        Cc: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit c1d4a2cebcadf2429c0c72e1d29aa2a9684c32e0
    Author: Adrian Bunk <bunk@stusta.de>
    Date:   Tue Jul 3 00:54:40 2007 -0400
    
        cpuidle: static
    
        This patch makes the needlessly global struct menu_governor static.
    
        Signed-off-by: Adrian Bunk <bunk@stusta.de>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit dbf8780c6e8d572c2c273da97ed1cca7608fd999
    Author: Andrew Morton <akpm@linux-foundation.org>
    Date:   Tue Jul 3 00:49:14 2007 -0400
    
        export symbol tick_nohz_get_sleep_length
    
        ERROR: "tick_nohz_get_sleep_length" [drivers/cpuidle/governors/menu.ko] undefined!
        ERROR: "tick_nohz_get_idle_jiffies" [drivers/cpuidle/governors/menu.ko] undefined!
    
        And please be sure to get your changes to core kernel suitably reviewed.
    
        Cc: Adam Belay <abelay@novell.com>
        Cc: Venki Pallipadi <venkatesh.pallipadi@intel.com>
        Cc: Ingo Molnar <mingo@elte.hu>
        Cc: Thomas Gleixner <tglx@linutronix.de>
        Cc: john stultz <johnstul@us.ibm.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 29f0e248e7017be15f99febf9143a2cef00b2961
    Author: Andrew Morton <akpm@linux-foundation.org>
    Date:   Tue Jul 3 00:43:04 2007 -0400
    
        tick.h needs hrtimer.h
    
        It uses hrtimers.
    
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit e40cede7d63a029e92712a3fe02faee60cc38fb4
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Tue Jul 3 00:40:34 2007 -0400
    
        cpuidle: first round of documentation updates
    
        Documentation changes based on Pavel's feedback.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 83b42be2efece386976507555c29e7773a0dfcd1
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Tue Jul 3 00:39:25 2007 -0400
    
        cpuidle: add rating to the governors and pick the one with highest rating by default
    
        Introduce a governor rating scheme to pick the right governor by default.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit d2a74b8c5e8f22def4709330d4bfc4a29209b71c
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Tue Jul 3 00:38:08 2007 -0400
    
        cpuidle: make cpuidle sysfs driver governor switch off by default
    
        Make default cpuidle sysfs to show current_governor and current_driver in
        read-only mode.  More elaborate available_governors and available_drivers with
        writeable current_governor and current_driver interface only appear with
        "cpuidle_sysfs_switch" boot parameter.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 1f60a0e80bf83cf6b55c8845bbe5596ed8f6307b
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Tue Jul 3 00:37:00 2007 -0400
    
        cpuidle: menu governor: change the early break condition
    
        Change the C-state early break out algorithm in menu governor.
    
        We only look at early breakouts that result in wakeups shorter than idle
        state's target_residency.  If such a breakout is frequent enough, eliminate
        the particular idle state upto a timeout period.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 45a42095cf64b003b4a69be3ce7f434f97d7af51
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Tue Jul 3 00:35:38 2007 -0400
    
        cpuidle: fix uninitialized variable in sysfs routine
    
        Fix the uninitialized usage of ret.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 80dca7cdba3e6ee13eae277660873ab9584eb3be
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Tue Jul 3 00:34:16 2007 -0400
    
        cpuidle: reenable /proc/acpi//power interface for the time being
    
        Keep /proc/acpi/processor/CPU*/power around for a while as powertop depends
        on it. It will be marked deprecated and removed in future. powertop can use
        cpuidle interfaces instead.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 589c37c2646c5e3813a51255a5ee1159cb4c33fc
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Tue Jul 3 00:32:37 2007 -0400
    
        cpuidle: menu governor and hrtimer compile fix
    
        Compile fix for menu governor.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 0ba80bd9ab3ed304cb4f19b722e4cc6740588b5e
    Author: Len Brown <len.brown@intel.com>
    Date:   Thu May 31 22:51:43 2007 -0400
    
        cpuidle: build fix - cpuidle vs ipw2100 module
    
        ERROR: "acpi_set_cstate_limit" [drivers/net/wireless/ipw2100.ko] undefined!
    
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit d7d8fa7f96a7f7682be7c6cc0cc53fa7a18c3b58
    Author: Adam Belay <abelay@novell.com>
    Date:   Sat Mar 24 03:47:07 2007 -0400
    
        cpuidle: add the 'menu' governor
    
        Here is my first take at implementing an idle PM governor that takes
        full advantage of NO_HZ.  I call it the 'menu' governor because it
        considers the full list of idle states before each entry.
    
        I've kept the implementation fairly simple.  It attempts to guess the
        next residency time and then chooses a state that would meet at least
        the break-even point between power savings and entry cost.  To this end,
        it selects the deepest idle state that satisfies the following
        constraints:
             1. If the idle time elapsed since bus master activity was detected
                is below a threshold (currently 20 ms), then limit the selection
                to C2-type or above.
             2. Do not choose a state with a break-even residency that exceeds
                the expected time remaining until the next timer interrupt.
             3. Do not choose a state with a break-even residency that exceeds
                the elapsed time between the last pair of break events,
                excluding timer interrupts.
    
        This governor has an advantage over "ladder" governor because it
        proactively checks how much time remains until the next timer interrupt
        using the tick infrastructure.  Also, it handles device interrupt
        activity more intelligently by not including timer interrupts in break
        event calculations.  Finally, it doesn't make policy decisions using the
        number of state entries, which can have variable residency times (NO_HZ
        makes these potentially very large), and instead only considers sleep
        time deltas.
    
        The menu governor can be selected during runtime using the cpuidle sysfs
        interface like so:
        "echo "menu" > /sys/devices/system/cpu/cpuidle/current_governor"
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit a4bec7e65aa3b7488b879d971651cc99a6c410fe
    Author: Adam Belay <abelay@novell.com>
    Date:   Sat Mar 24 03:47:03 2007 -0400
    
        cpuidle: export time until next timer interrupt using NO_HZ
    
        Expose information about the time remaining until the next
        timer interrupt expires by utilizing the dynticks infrastructure.
        Also modify the main idle loop to allow dynticks to handle
        non-interrupt break events (e.g. DMA).  Finally, expose sleep ticks
        information to external code.  Thomas Gleixner is responsible for much
        of the code in this patch.  However, I've made some additional changes,
        so I'm probably responsible if there are any bugs or oversights :)
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 2929d8996fbc77f41a5ff86bb67cdde3ca7d2d72
    Author: Adam Belay <abelay@novell.com>
    Date:   Sat Mar 24 03:46:58 2007 -0400
    
        cpuidle: governor API changes
    
        This patch prepares cpuidle for the menu governor.  It adds an optional
        stage after idle state entry to give the governor an opportunity to
        check why the state was exited.  Also it makes sure the idle loop
        returns after each state entry, allowing the appropriate dynticks code
        to run.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 3a7fd42f9825c3b03e364ca59baa751bb350775f
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Thu Apr 26 00:03:59 2007 -0700
    
        cpuidle: hang fix
    
        Prevent hang on x86-64, when ACPI processor driver is added as a module on
        a system that does not support C-states.
    
        x86-64 expects all idle handlers to enable interrupts before returning from
        idle handler.  This is due to enter_idle(), exit_idle() races.  Make
        cpuidle_idle_call() confirm to this when there is no pm_idle_old.
    
        Also, cpuidle look at the return values of attch_driver() and set
        current_driver to NULL if attach fails on all CPUs.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 4893339a142afbd5b7c01ffadfd53d14746e858e
    Author: Shaohua Li <shaohua.li@intel.com>
    Date:   Thu Apr 26 10:40:09 2007 +0800
    
        cpuidle: add support for max_cstate limit
    
        With CPUIDLE framework, the max_cstate (to limit max cpu c-state)
        parameter is ingored. Some systems require it to ignore C2/C3
        and some drivers like ipw require it too.
    
        Signed-off-by: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 43bbbbe1cb998cbd2df656f55bb3bfe30f30e7d1
    Author: Shaohua Li <shaohua.li@intel.com>
    Date:   Thu Apr 26 10:40:13 2007 +0800
    
        cpuidle: add cpuidle_fore_redetect_devices API
    
        add cpuidle_force_redetect_devices API,
        which forces all CPU redetect idle states.
        Next patch will use it.
    
        Signed-off-by: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit d1edadd608f24836def5ec483d2edccfb37b1d19
    Author: Shaohua Li <shaohua.li@intel.com>
    Date:   Thu Apr 26 10:40:01 2007 +0800
    
        cpuidle: fix sysfs related issue
    
        Fix the cpuidle sysfs issue.
        a. make kobject dynamicaly allocated
        b. fixed sysfs init issue to avoid suspend/resume issue
    
        Signed-off-by: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 7169a5cc0d67b263978859672e86c13c23a5570d
    Author: Randy Dunlap <randy.dunlap@oracle.com>
    Date:   Wed Mar 28 22:52:53 2007 -0400
    
        cpuidle: 1-bit field must be unsigned
    
        A 1-bit bitfield has no room for a sign bit.
        drivers/cpuidle/governors/ladder.c:54:16: error: dubious bitfield without explicit `signed' or `unsigned'
    
        Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
        Cc: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 4658620158dc2fbd9e4bcb213c5b6fb5d05ba7d4
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Wed Mar 28 22:52:41 2007 -0400
    
        cpuidle: fix boot hang
    
        Patch for cpuidle boot hang reported by Larry Finger here.
        http://www.ussg.iu.edu/hypermail/linux/kernel/0703.2/2025.html
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Cc: Larry Finger <larry.finger@lwfinger.net>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit c17e168aa6e5fe3851baaae8df2fbc1cf11443a9
    Author: Len Brown <len.brown@intel.com>
    Date:   Wed Mar 7 04:37:53 2007 -0500
    
        cpuidle: ladder does not depend on ACPI
    
        build fix for CONFIG_ACPI=n
    
        In file included from drivers/cpuidle/governors/ladder.c:21:
        include/acpi/processor.h:88: error: expected specifier-qualifier-list before âacpi_integerâ
        include/acpi/processor.h:106: error: expected specifier-qualifier-list before âacpi_integerâ
        include/acpi/processor.h:168: error: expected specifier-qualifier-list before âacpi_handleâ
    
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 8c91d958246bde68db0c3f0c57b535962ce861cb
    Author: Adrian Bunk <bunk@stusta.de>
    Date:   Tue Mar 6 02:29:40 2007 -0800
    
        cpuidle: make code static
    
        This patch makes the following needlessly global code static:
        - driver.c: __cpuidle_find_driver()
        - governor.c: __cpuidle_find_governor()
        - ladder.c: struct ladder_governor
    
        Signed-off-by: Adrian Bunk <bunk@stusta.de>
        Cc: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Cc: Adam Belay <abelay@novell.com>
        Cc: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 0c39dc3187094c72c33ab65a64d2017b21f372d2
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Wed Mar 7 02:38:22 2007 -0500
    
        cpu_idle: fix build break
    
        This patch fixes a build breakage with !CONFIG_HOTPLUG_CPU and
        CONFIG_CPU_IDLE.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Adrian Bunk <bunk@stusta.de>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 8112e3b115659b07df340ef170515799c0105f82
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Tue Mar 6 02:29:39 2007 -0800
    
        cpuidle: build fix for !CPU_IDLE
    
        Fix the compile issues when CPU_IDLE is not configured.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Cc: Adam Belay <abelay@novell.com>
        Cc: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 1eb4431e9599cd25e0d9872f3c2c8986821839dd
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Thu Feb 22 13:54:57 2007 -0800
    
        cpuidle take2: Basic documentation for cpuidle
    
        Documentation for cpuidle infrastructure
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Adam Belay <abelay@novell.com>
        Signed-off-by: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit ef5f15a8b79123a047285ec2e3899108661df779
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Thu Feb 22 13:54:03 2007 -0800
    
        cpuidle take2: Hookup ACPI C-states driver with cpuidle
    
        Hookup ACPI C-states onto generic cpuidle infrastructure.
    
        drivers/acpi/procesor_idle.c is now a ACPI C-states driver that registers as
        a driver in cpuidle infrastructure and the policy part is removed from
        drivers/acpi/processor_idle.c. We use governor in cpuidle instead.
    
        Signed-off-by: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Adam Belay <abelay@novell.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 987196fa82d4db52c407e8c9d5dec884ba602183
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Thu Feb 22 13:52:57 2007 -0800
    
        cpuidle take2: Core cpuidle infrastructure
    
        Announcing 'cpuidle', a new CPU power management infrastructure to manage
        idle CPUs in a clean and efficient manner.
        cpuidle separates out the drivers that can provide support for multiple types
        of idle states and policy governors that decide on what idle state to use
        at run time.
        A cpuidle driver can support multiple idle states based on parameters like
        varying power consumption, wakeup latency, etc (ACPI C-states for example).
        A cpuidle governor can be usage model specific (laptop, server,
        laptop on battery etc).
        Main advantage of the infrastructure being, it allows independent development
        of drivers and governors and allows for better CPU power management.
    
        A huge thanks to Adam Belay and Shaohua Li who were part of this mini-project
        since its beginning and are greatly responsible for this patchset.
    
        This patch:
    
        Core cpuidle infrastructure.
        Introduces a new abstraction layer for cpuidle:
        * which manages drivers that can support multiple idles states. Drivers
          can be generic or particular to specific hardware/platform
        * allows pluging in multiple policy governors that can take idle state policy
          decision
        * The core also has a set of sysfs interfaces with which administrato can know
          about supported drivers and governors and switch them at run time.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Signed-off-by: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index f18261368e76..99da6a790857 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -40,6 +40,7 @@
 #include <linux/sched.h>	/* need_resched() */
 #include <linux/latency.h>
 #include <linux/clockchips.h>
+#include <linux/cpuidle.h>
 
 /*
  * Include the apic definitions for x86 to have the APIC timer related defines
@@ -64,14 +65,22 @@ ACPI_MODULE_NAME("processor_idle");
 #define ACPI_PROCESSOR_FILE_POWER	"power"
 #define US_TO_PM_TIMER_TICKS(t)		((t * (PM_TIMER_FREQUENCY/1000)) / 1000)
 #define PM_TIMER_TICK_NS		(1000000000ULL/PM_TIMER_FREQUENCY)
+#ifndef CONFIG_CPU_IDLE
 #define C2_OVERHEAD			4	/* 1us (3.579 ticks per us) */
 #define C3_OVERHEAD			4	/* 1us (3.579 ticks per us) */
 static void (*pm_idle_save) (void) __read_mostly;
-module_param(max_cstate, uint, 0644);
+#else
+#define C2_OVERHEAD			1	/* 1us */
+#define C3_OVERHEAD			1	/* 1us */
+#endif
+#define PM_TIMER_TICKS_TO_US(p)		(((p) * 1000)/(PM_TIMER_FREQUENCY/1000))
 
+static unsigned int max_cstate __read_mostly = ACPI_PROCESSOR_MAX_POWER;
+module_param(max_cstate, uint, 0000);
 static unsigned int nocst __read_mostly;
 module_param(nocst, uint, 0000);
 
+#ifndef CONFIG_CPU_IDLE
 /*
  * bm_history -- bit-mask with a bit per jiffy of bus-master activity
  * 1000 HZ: 0xFFFFFFFF: 32 jiffies = 32ms
@@ -82,9 +91,10 @@ module_param(nocst, uint, 0000);
 static unsigned int bm_history __read_mostly =
     (HZ >= 800 ? 0xFFFFFFFF : ((1U << (HZ / 25)) - 1));
 module_param(bm_history, uint, 0644);
-/* --------------------------------------------------------------------------
-                                Power Management
-   -------------------------------------------------------------------------- */
+
+static int acpi_processor_set_power_policy(struct acpi_processor *pr);
+
+#endif
 
 /*
  * IBM ThinkPad R40e crashes mysteriously when going into C2 or C3.
@@ -177,6 +187,18 @@ static inline u32 ticks_elapsed(u32 t1, u32 t2)
 		return ((0xFFFFFFFF - t1) + t2);
 }
 
+static inline u32 ticks_elapsed_in_us(u32 t1, u32 t2)
+{
+	if (t2 >= t1)
+		return PM_TIMER_TICKS_TO_US(t2 - t1);
+	else if (!(acpi_gbl_FADT.flags & ACPI_FADT_32BIT_TIMER))
+		return PM_TIMER_TICKS_TO_US(((0x00FFFFFF - t1) + t2) & 0x00FFFFFF);
+	else
+		return PM_TIMER_TICKS_TO_US((0xFFFFFFFF - t1) + t2);
+}
+
+#ifndef CONFIG_CPU_IDLE
+
 static void
 acpi_processor_power_activate(struct acpi_processor *pr,
 			      struct acpi_processor_cx *new)
@@ -248,6 +270,7 @@ static void acpi_cstate_enter(struct acpi_processor_cx *cstate)
 		unused = inl(acpi_gbl_FADT.xpm_timer_block.address);
 	}
 }
+#endif /* !CONFIG_CPU_IDLE */
 
 #ifdef ARCH_APICTIMER_STOPS_ON_C3
 
@@ -342,6 +365,7 @@ int acpi_processor_resume(struct acpi_device * device)
 	return 0;
 }
 
+#ifndef CONFIG_CPU_IDLE
 static void acpi_processor_idle(void)
 {
 	struct acpi_processor *pr = NULL;
@@ -439,7 +463,7 @@ static void acpi_processor_idle(void)
 	 * an SMP system. We do it here instead of doing it at _CST/P_LVL
 	 * detection phase, to work cleanly with logical CPU hotplug.
 	 */
-	if ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) && 
+	if ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) &&
 	    !pr->flags.has_cst && !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
 		cx = &pr->power.states[ACPI_STATE_C1];
 #endif
@@ -739,6 +763,7 @@ static int acpi_processor_set_power_policy(struct acpi_processor *pr)
 
 	return 0;
 }
+#endif /* !CONFIG_CPU_IDLE */
 
 static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 {
@@ -756,7 +781,7 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 #ifndef CONFIG_HOTPLUG_CPU
 	/*
 	 * Check for P_LVL2_UP flag before entering C2 and above on
-	 * an SMP system. 
+	 * an SMP system.
 	 */
 	if ((num_online_cpus() > 1) &&
 	    !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
@@ -957,7 +982,12 @@ static void acpi_processor_power_verify_c2(struct acpi_processor_cx *cx)
 	 * Normalize the C2 latency to expidite policy
 	 */
 	cx->valid = 1;
+
+#ifndef CONFIG_CPU_IDLE
 	cx->latency_ticks = US_TO_PM_TIMER_TICKS(cx->latency);
+#else
+	cx->latency_ticks = cx->latency;
+#endif
 
 	return;
 }
@@ -1037,7 +1067,12 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 	 * use this in our C3 policy
 	 */
 	cx->valid = 1;
+
+#ifndef CONFIG_CPU_IDLE
 	cx->latency_ticks = US_TO_PM_TIMER_TICKS(cx->latency);
+#else
+	cx->latency_ticks = cx->latency;
+#endif
 
 	return;
 }
@@ -1102,6 +1137,7 @@ static int acpi_processor_get_power_info(struct acpi_processor *pr)
 
 	pr->power.count = acpi_processor_power_verify(pr);
 
+#ifndef CONFIG_CPU_IDLE
 	/*
 	 * Set Default Policy
 	 * ------------------
@@ -1113,6 +1149,7 @@ static int acpi_processor_get_power_info(struct acpi_processor *pr)
 	result = acpi_processor_set_power_policy(pr);
 	if (result)
 		return result;
+#endif
 
 	/*
 	 * if one state of type C2 or C3 is available, mark this
@@ -1129,35 +1166,6 @@ static int acpi_processor_get_power_info(struct acpi_processor *pr)
 	return 0;
 }
 
-int acpi_processor_cst_has_changed(struct acpi_processor *pr)
-{
-	int result = 0;
-
-
-	if (!pr)
-		return -EINVAL;
-
-	if (nocst) {
-		return -ENODEV;
-	}
-
-	if (!pr->flags.power_setup_done)
-		return -ENODEV;
-
-	/* Fall back to the default idle loop */
-	pm_idle = pm_idle_save;
-	synchronize_sched();	/* Relies on interrupts forcing exit from idle. */
-
-	pr->flags.power = 0;
-	result = acpi_processor_get_power_info(pr);
-	if ((pr->flags.power == 1) && (pr->flags.power_setup_done))
-		pm_idle = acpi_processor_idle;
-
-	return result;
-}
-
-/* proc interface */
-
 static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
 {
 	struct acpi_processor *pr = seq->private;
@@ -1239,6 +1247,35 @@ static const struct file_operations acpi_processor_power_fops = {
 	.release = single_release,
 };
 
+#ifndef CONFIG_CPU_IDLE
+
+int acpi_processor_cst_has_changed(struct acpi_processor *pr)
+{
+	int result = 0;
+
+
+	if (!pr)
+		return -EINVAL;
+
+	if (nocst) {
+		return -ENODEV;
+	}
+
+	if (!pr->flags.power_setup_done)
+		return -ENODEV;
+
+	/* Fall back to the default idle loop */
+	pm_idle = pm_idle_save;
+	synchronize_sched();	/* Relies on interrupts forcing exit from idle. */
+
+	pr->flags.power = 0;
+	result = acpi_processor_get_power_info(pr);
+	if ((pr->flags.power == 1) && (pr->flags.power_setup_done))
+		pm_idle = acpi_processor_idle;
+
+	return result;
+}
+
 #ifdef CONFIG_SMP
 static void smp_callback(void *v)
 {
@@ -1261,7 +1298,360 @@ static int acpi_processor_latency_notify(struct notifier_block *b,
 static struct notifier_block acpi_processor_latency_notifier = {
 	.notifier_call = acpi_processor_latency_notify,
 };
+
+#endif
+
+#else /* CONFIG_CPU_IDLE */
+
+/**
+ * acpi_idle_bm_check - checks if bus master activity was detected
+ */
+static int acpi_idle_bm_check(void)
+{
+	u32 bm_status = 0;
+
+	acpi_get_register(ACPI_BITREG_BUS_MASTER_STATUS, &bm_status);
+	if (bm_status)
+		acpi_set_register(ACPI_BITREG_BUS_MASTER_STATUS, 1);
+	/*
+	 * PIIX4 Erratum #18: Note that BM_STS doesn't always reflect
+	 * the true state of bus mastering activity; forcing us to
+	 * manually check the BMIDEA bit of each IDE channel.
+	 */
+	else if (errata.piix4.bmisx) {
+		if ((inb_p(errata.piix4.bmisx + 0x02) & 0x01)
+		    || (inb_p(errata.piix4.bmisx + 0x0A) & 0x01))
+			bm_status = 1;
+	}
+	return bm_status;
+}
+
+/**
+ * acpi_idle_update_bm_rld - updates the BM_RLD bit depending on target state
+ * @pr: the processor
+ * @target: the new target state
+ */
+static inline void acpi_idle_update_bm_rld(struct acpi_processor *pr,
+					   struct acpi_processor_cx *target)
+{
+	if (pr->flags.bm_rld_set && target->type != ACPI_STATE_C3) {
+		acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 0);
+		pr->flags.bm_rld_set = 0;
+	}
+
+	if (!pr->flags.bm_rld_set && target->type == ACPI_STATE_C3) {
+		acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 1);
+		pr->flags.bm_rld_set = 1;
+	}
+}
+
+/**
+ * acpi_idle_do_entry - a helper function that does C2 and C3 type entry
+ * @cx: cstate data
+ */
+static inline void acpi_idle_do_entry(struct acpi_processor_cx *cx)
+{
+	if (cx->space_id == ACPI_CSTATE_FFH) {
+		/* Call into architectural FFH based C-state */
+		acpi_processor_ffh_cstate_enter(cx);
+	} else {
+		int unused;
+		/* IO port based C-state */
+		inb(cx->address);
+		/* Dummy wait op - must do something useless after P_LVL2 read
+		   because chipsets cannot guarantee that STPCLK# signal
+		   gets asserted in time to freeze execution properly. */
+		unused = inl(acpi_gbl_FADT.xpm_timer_block.address);
+	}
+}
+
+/**
+ * acpi_idle_enter_c1 - enters an ACPI C1 state-type
+ * @dev: the target CPU
+ * @state: the state data
+ *
+ * This is equivalent to the HALT instruction.
+ */
+static int acpi_idle_enter_c1(struct cpuidle_device *dev,
+			      struct cpuidle_state *state)
+{
+	struct acpi_processor *pr;
+	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
+	pr = processors[smp_processor_id()];
+
+	if (unlikely(!pr))
+		return 0;
+
+	if (pr->flags.bm_check)
+		acpi_idle_update_bm_rld(pr, cx);
+
+	current_thread_info()->status &= ~TS_POLLING;
+	/*
+	 * TS_POLLING-cleared state must be visible before we test
+	 * NEED_RESCHED:
+	 */
+	smp_mb();
+	if (!need_resched())
+		safe_halt();
+	current_thread_info()->status |= TS_POLLING;
+
+	cx->usage++;
+
+	return 0;
+}
+
+/**
+ * acpi_idle_enter_simple - enters an ACPI state without BM handling
+ * @dev: the target CPU
+ * @state: the state data
+ */
+static int acpi_idle_enter_simple(struct cpuidle_device *dev,
+				  struct cpuidle_state *state)
+{
+	struct acpi_processor *pr;
+	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
+	u32 t1, t2;
+	pr = processors[smp_processor_id()];
+
+	if (unlikely(!pr))
+		return 0;
+
+	if (pr->flags.bm_check)
+		acpi_idle_update_bm_rld(pr, cx);
+
+	local_irq_disable();
+	current_thread_info()->status &= ~TS_POLLING;
+	/*
+	 * TS_POLLING-cleared state must be visible before we test
+	 * NEED_RESCHED:
+	 */
+	smp_mb();
+
+	if (unlikely(need_resched())) {
+		current_thread_info()->status |= TS_POLLING;
+		local_irq_enable();
+		return 0;
+	}
+
+	if (cx->type == ACPI_STATE_C3)
+		ACPI_FLUSH_CPU_CACHE();
+
+	t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
+	acpi_state_timer_broadcast(pr, cx, 1);
+	acpi_idle_do_entry(cx);
+	t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
+
+#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86_TSC)
+	/* TSC could halt in idle, so notify users */
+	mark_tsc_unstable("TSC halts in idle");;
+#endif
+
+	local_irq_enable();
+	current_thread_info()->status |= TS_POLLING;
+
+	cx->usage++;
+
+	acpi_state_timer_broadcast(pr, cx, 0);
+	cx->time += ticks_elapsed(t1, t2);
+	return ticks_elapsed_in_us(t1, t2);
+}
+
+static int c3_cpu_count;
+static DEFINE_SPINLOCK(c3_lock);
+
+/**
+ * acpi_idle_enter_bm - enters C3 with proper BM handling
+ * @dev: the target CPU
+ * @state: the state data
+ *
+ * If BM is detected, the deepest non-C3 idle state is entered instead.
+ */
+static int acpi_idle_enter_bm(struct cpuidle_device *dev,
+			      struct cpuidle_state *state)
+{
+	struct acpi_processor *pr;
+	struct acpi_processor_cx *cx = cpuidle_get_statedata(state);
+	u32 t1, t2;
+	pr = processors[smp_processor_id()];
+
+	if (unlikely(!pr))
+		return 0;
+
+	local_irq_disable();
+	current_thread_info()->status &= ~TS_POLLING;
+	/*
+	 * TS_POLLING-cleared state must be visible before we test
+	 * NEED_RESCHED:
+	 */
+	smp_mb();
+
+	if (unlikely(need_resched())) {
+		current_thread_info()->status |= TS_POLLING;
+		local_irq_enable();
+		return 0;
+	}
+
+	/*
+	 * Must be done before busmaster disable as we might need to
+	 * access HPET !
+	 */
+	acpi_state_timer_broadcast(pr, cx, 1);
+
+	if (acpi_idle_bm_check()) {
+		cx = pr->power.bm_state;
+
+		acpi_idle_update_bm_rld(pr, cx);
+
+		t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
+		acpi_idle_do_entry(cx);
+		t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
+	} else {
+		acpi_idle_update_bm_rld(pr, cx);
+
+		spin_lock(&c3_lock);
+		c3_cpu_count++;
+		/* Disable bus master arbitration when all CPUs are in C3 */
+		if (c3_cpu_count == num_online_cpus())
+			acpi_set_register(ACPI_BITREG_ARB_DISABLE, 1);
+		spin_unlock(&c3_lock);
+
+		t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
+		acpi_idle_do_entry(cx);
+		t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
+
+		spin_lock(&c3_lock);
+		/* Re-enable bus master arbitration */
+		if (c3_cpu_count == num_online_cpus())
+			acpi_set_register(ACPI_BITREG_ARB_DISABLE, 0);
+		c3_cpu_count--;
+		spin_unlock(&c3_lock);
+	}
+
+#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86_TSC)
+	/* TSC could halt in idle, so notify users */
+	mark_tsc_unstable("TSC halts in idle");
+#endif
+
+	local_irq_enable();
+	current_thread_info()->status |= TS_POLLING;
+
+	cx->usage++;
+
+	acpi_state_timer_broadcast(pr, cx, 0);
+	cx->time += ticks_elapsed(t1, t2);
+	return ticks_elapsed_in_us(t1, t2);
+}
+
+struct cpuidle_driver acpi_idle_driver = {
+	.name =		"acpi_idle",
+	.owner =	THIS_MODULE,
+};
+
+/**
+ * acpi_processor_setup_cpuidle - prepares and configures CPUIDLE
+ * @pr: the ACPI processor
+ */
+static int acpi_processor_setup_cpuidle(struct acpi_processor *pr)
+{
+	int i, count = 0;
+	struct acpi_processor_cx *cx;
+	struct cpuidle_state *state;
+	struct cpuidle_device *dev = &pr->power.dev;
+
+	if (!pr->flags.power_setup_done)
+		return -EINVAL;
+
+	if (pr->flags.power == 0) {
+		return -EINVAL;
+	}
+
+	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {
+		cx = &pr->power.states[i];
+		state = &dev->states[count];
+
+		if (!cx->valid)
+			continue;
+
+#ifdef CONFIG_HOTPLUG_CPU
+		if ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) &&
+		    !pr->flags.has_cst &&
+		    !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
+			continue;
 #endif
+		cpuidle_set_statedata(state, cx);
+
+		snprintf(state->name, CPUIDLE_NAME_LEN, "C%d", i);
+		state->exit_latency = cx->latency;
+		state->target_residency = cx->latency * 6;
+		state->power_usage = cx->power;
+
+		state->flags = 0;
+		switch (cx->type) {
+			case ACPI_STATE_C1:
+			state->flags |= CPUIDLE_FLAG_SHALLOW;
+			state->enter = acpi_idle_enter_c1;
+			break;
+
+			case ACPI_STATE_C2:
+			state->flags |= CPUIDLE_FLAG_BALANCED;
+			state->flags |= CPUIDLE_FLAG_TIME_VALID;
+			state->enter = acpi_idle_enter_simple;
+			break;
+
+			case ACPI_STATE_C3:
+			state->flags |= CPUIDLE_FLAG_DEEP;
+			state->flags |= CPUIDLE_FLAG_TIME_VALID;
+			state->flags |= CPUIDLE_FLAG_CHECK_BM;
+			state->enter = pr->flags.bm_check ?
+					acpi_idle_enter_bm :
+					acpi_idle_enter_simple;
+			break;
+		}
+
+		count++;
+	}
+
+	dev->state_count = count;
+
+	if (!count)
+		return -EINVAL;
+
+	/* find the deepest state that can handle active BM */
+	if (pr->flags.bm_check) {
+		for (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++)
+			if (pr->power.states[i].type == ACPI_STATE_C3)
+				break;
+		pr->power.bm_state = &pr->power.states[i-1];
+	}
+
+	return 0;
+}
+
+int acpi_processor_cst_has_changed(struct acpi_processor *pr)
+{
+	int ret;
+
+	if (!pr)
+		return -EINVAL;
+
+	if (nocst) {
+		return -ENODEV;
+	}
+
+	if (!pr->flags.power_setup_done)
+		return -ENODEV;
+
+	cpuidle_pause_and_lock();
+	cpuidle_disable_device(&pr->power.dev);
+	acpi_processor_get_power_info(pr);
+	acpi_processor_setup_cpuidle(pr);
+	ret = cpuidle_enable_device(&pr->power.dev);
+	cpuidle_resume_and_unlock();
+
+	return ret;
+}
+
+#endif /* CONFIG_CPU_IDLE */
 
 int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 			      struct acpi_device *device)
@@ -1279,7 +1669,7 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 			       "ACPI: processor limited to max C-state %d\n",
 			       max_cstate);
 		first_run++;
-#ifdef CONFIG_SMP
+#if !defined (CONFIG_CPU_IDLE) && defined (CONFIG_SMP)
 		register_latency_notifier(&acpi_processor_latency_notifier);
 #endif
 	}
@@ -1297,6 +1687,7 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 	}
 
 	acpi_processor_get_power_info(pr);
+	pr->flags.power_setup_done = 1;
 
 	/*
 	 * Install the idle handler if processor power management is supported.
@@ -1304,6 +1695,13 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 	 * platforms that only support C1.
 	 */
 	if ((pr->flags.power) && (!boot_option_idle_override)) {
+#ifdef CONFIG_CPU_IDLE
+		acpi_processor_setup_cpuidle(pr);
+		pr->power.dev.cpu = pr->id;
+		if (cpuidle_register_device(&pr->power.dev))
+			return -EIO;
+#endif
+
 		printk(KERN_INFO PREFIX "CPU%d (power states:", pr->id);
 		for (i = 1; i <= pr->power.count; i++)
 			if (pr->power.states[i].valid)
@@ -1311,10 +1709,12 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 				       pr->power.states[i].type);
 		printk(")\n");
 
+#ifndef CONFIG_CPU_IDLE
 		if (pr->id == 0) {
 			pm_idle_save = pm_idle;
 			pm_idle = acpi_processor_idle;
 		}
+#endif
 	}
 
 	/* 'power' [R] */
@@ -1328,21 +1728,24 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 		entry->owner = THIS_MODULE;
 	}
 
-	pr->flags.power_setup_done = 1;
-
 	return 0;
 }
 
 int acpi_processor_power_exit(struct acpi_processor *pr,
 			      struct acpi_device *device)
 {
-
+#ifdef CONFIG_CPU_IDLE
+	if ((pr->flags.power) && (!boot_option_idle_override))
+		cpuidle_unregister_device(&pr->power.dev);
+#endif
 	pr->flags.power_setup_done = 0;
 
 	if (acpi_device_dir(device))
 		remove_proc_entry(ACPI_PROCESSOR_FILE_POWER,
 				  acpi_device_dir(device));
 
+#ifndef CONFIG_CPU_IDLE
+
 	/* Unregister the idle handler when processor #0 is removed. */
 	if (pr->id == 0) {
 		pm_idle = pm_idle_save;
@@ -1357,6 +1760,7 @@ int acpi_processor_power_exit(struct acpi_processor *pr,
 		unregister_latency_notifier(&acpi_processor_latency_notifier);
 #endif
 	}
+#endif
 
 	return 0;
 }

commit 1855256c497ecfefc730df6032243f26855ce52c
Author: Jeff Garzik <jeff@garzik.org>
Date:   Wed Oct 3 15:15:40 2007 -0400

    drivers/firmware: const-ify DMI API and internals
    
    Three main sets of changes:
    
    1) dmi_get_system_info() return value should have been marked const,
       since callers should not be changing that data.
    
    2) const-ify DMI internals, since DMI firmware tables should,
       whenever possible, be marked const to ensure we never ever write to
       that data area.
    
    3) const-ify DMI API, to enable marking tables const where possible
       in low-level drivers.
    
    And if we're really lucky, this might enable some additional
    optimizations on the part of the compiler.
    
    The bulk of the changes are #2 and #3, which are interrelated.  #1 could
    have been a separate patch, but it was so small compared to the others,
    it was easier to roll it into this changeset.
    
    Signed-off-by: Jeff Garzik <jgarzik@redhat.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index f18261368e76..1e8287b4f40c 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -92,7 +92,7 @@ module_param(bm_history, uint, 0644);
  *
  * To skip this limit, boot/load with a large max_cstate limit.
  */
-static int set_max_cstate(struct dmi_system_id *id)
+static int set_max_cstate(const struct dmi_system_id *id)
 {
 	if (max_cstate > ACPI_PROCESSOR_MAX_POWER)
 		return 0;

commit b04e7bdb984e3b7f62fb7f44146a529f88cc7639
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Sep 22 22:29:05 2007 +0000

    ACPI: disable lower idle C-states across suspend/resume
    
    device_suspend() calls ACPI suspend functions, which seems to have undesired
    side effects on lower idle C-states. It took me some time to realize that
    especially the VAIO BIOSes (both Andrews jinxed UP and my elfstruck SMP one)
    show this effect. I'm quite sure that other bug reports against suspend/resume
    about turning the system into a brick have the same root cause.
    
    After fishing in the dark for quite some time, I realized that removing the ACPI
    processor module before suspend (this removes the lower C-state functionality)
    made the problem disappear. Interestingly enough the propability of having a
    bricked box is influenced by various factors (interrupts, size of the ram image,
    ...). Even adding a bunch of printks in the wrong places made the problem go
    away. The previous periodic tick implementation simply pampered over the
    problem, which explains why the dyntick / clockevents changes made this more
    prominent.
    
    We avoid complex functionality during the boot process and we have to do the
    same during suspend/resume. It is a similar scenario and equaly fragile.
    
    Add suspend / resume functions to the ACPI processor code and disable the lower
    idle C-states across suspend/resume. Fall back to the default idle
    implementation (halt) instead.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Len Brown <lenb@kernel.org>
    Cc: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Cc: Rafael J. Wysocki <rjw@sisk.pl>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index d9b8af763e1e..f18261368e76 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -325,6 +325,23 @@ static void acpi_state_timer_broadcast(struct acpi_processor *pr,
 
 #endif
 
+/*
+ * Suspend / resume control
+ */
+static int acpi_idle_suspend;
+
+int acpi_processor_suspend(struct acpi_device * device, pm_message_t state)
+{
+	acpi_idle_suspend = 1;
+	return 0;
+}
+
+int acpi_processor_resume(struct acpi_device * device)
+{
+	acpi_idle_suspend = 0;
+	return 0;
+}
+
 static void acpi_processor_idle(void)
 {
 	struct acpi_processor *pr = NULL;
@@ -355,7 +372,7 @@ static void acpi_processor_idle(void)
 	}
 
 	cx = pr->power.state;
-	if (!cx) {
+	if (!cx || acpi_idle_suspend) {
 		if (pm_idle_save)
 			pm_idle_save();
 		else

commit 2aa44d0567ed21b47b87d68819415d48194cb923
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Aug 23 15:18:02 2007 +0200

    sched: sched_clock_idle_[sleep|wakeup]_event()
    
    construct a more or less wall-clock time out of sched_clock(), by
    using ACPI-idle's existing knowledge about how much time we spent
    idling. This allows the rq clock to work around TSC-stops-in-C2,
    TSC-gets-corrupted-in-C3 type of problems.
    
    ( Besides the scheduler's statistics this also benefits blktrace and
      printk-timestamps as well. )
    
    Furthermore, the precise before-C2/C3-sleep and after-C2/C3-wakeup
    callbacks allow the scheduler to get out the most of the period where
    the CPU has a reliable TSC. This results in slightly more precise
    task statistics.
    
    the ACPI bits were acked by Len.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index a8634a0655fc..d9b8af763e1e 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -63,6 +63,7 @@
 ACPI_MODULE_NAME("processor_idle");
 #define ACPI_PROCESSOR_FILE_POWER	"power"
 #define US_TO_PM_TIMER_TICKS(t)		((t * (PM_TIMER_FREQUENCY/1000)) / 1000)
+#define PM_TIMER_TICK_NS		(1000000000ULL/PM_TIMER_FREQUENCY)
 #define C2_OVERHEAD			4	/* 1us (3.579 ticks per us) */
 #define C3_OVERHEAD			4	/* 1us (3.579 ticks per us) */
 static void (*pm_idle_save) (void) __read_mostly;
@@ -462,6 +463,9 @@ static void acpi_processor_idle(void)
 		 * TBD: Can't get time duration while in C1, as resumes
 		 *      go to an ISR rather than here.  Need to instrument
 		 *      base interrupt handler.
+		 *
+		 * Note: the TSC better not stop in C1, sched_clock() will
+		 *       skew otherwise.
 		 */
 		sleep_ticks = 0xFFFFFFFF;
 		break;
@@ -469,6 +473,8 @@ static void acpi_processor_idle(void)
 	case ACPI_STATE_C2:
 		/* Get start time (ticks) */
 		t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
+		/* Tell the scheduler that we are going deep-idle: */
+		sched_clock_idle_sleep_event();
 		/* Invoke C2 */
 		acpi_state_timer_broadcast(pr, cx, 1);
 		acpi_cstate_enter(cx);
@@ -479,17 +485,22 @@ static void acpi_processor_idle(void)
 		/* TSC halts in C2, so notify users */
 		mark_tsc_unstable("possible TSC halt in C2");
 #endif
+		/* Compute time (ticks) that we were actually asleep */
+		sleep_ticks = ticks_elapsed(t1, t2);
+
+		/* Tell the scheduler how much we idled: */
+		sched_clock_idle_wakeup_event(sleep_ticks*PM_TIMER_TICK_NS);
+
 		/* Re-enable interrupts */
 		local_irq_enable();
+		/* Do not account our idle-switching overhead: */
+		sleep_ticks -= cx->latency_ticks + C2_OVERHEAD;
+
 		current_thread_info()->status |= TS_POLLING;
-		/* Compute time (ticks) that we were actually asleep */
-		sleep_ticks =
-		    ticks_elapsed(t1, t2) - cx->latency_ticks - C2_OVERHEAD;
 		acpi_state_timer_broadcast(pr, cx, 0);
 		break;
 
 	case ACPI_STATE_C3:
-
 		/*
 		 * disable bus master
 		 * bm_check implies we need ARB_DIS
@@ -518,6 +529,8 @@ static void acpi_processor_idle(void)
 		t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 		/* Invoke C3 */
 		acpi_state_timer_broadcast(pr, cx, 1);
+		/* Tell the scheduler that we are going deep-idle: */
+		sched_clock_idle_sleep_event();
 		acpi_cstate_enter(cx);
 		/* Get end time (ticks) */
 		t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
@@ -531,12 +544,17 @@ static void acpi_processor_idle(void)
 		/* TSC halts in C3, so notify users */
 		mark_tsc_unstable("TSC halts in C3");
 #endif
+		/* Compute time (ticks) that we were actually asleep */
+		sleep_ticks = ticks_elapsed(t1, t2);
+		/* Tell the scheduler how much we idled: */
+		sched_clock_idle_wakeup_event(sleep_ticks*PM_TIMER_TICK_NS);
+
 		/* Re-enable interrupts */
 		local_irq_enable();
+		/* Do not account our idle-switching overhead: */
+		sleep_ticks -= cx->latency_ticks + C3_OVERHEAD;
+
 		current_thread_info()->status |= TS_POLLING;
-		/* Compute time (ticks) that we were actually asleep */
-		sleep_ticks =
-		    ticks_elapsed(t1, t2) - cx->latency_ticks - C3_OVERHEAD;
 		acpi_state_timer_broadcast(pr, cx, 0);
 		break;
 

commit ed3110efb538d7acbf635095c1382118f7414f75
Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Tue Jul 31 12:04:31 2007 -0700

    ACPI: fix "Time Problems with 2.6.23-rc1-gf695baf2"
    
    Enable C3 without bm control only for CST based C3.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index a898991f77cb..a8634a0655fc 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -969,11 +969,17 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 	}
 
 	if (pr->flags.bm_check) {
-		/* bus mastering control is necessary */
 		if (!pr->flags.bm_control) {
-			/* In this case we enter C3 without bus mastering */
-			ACPI_DEBUG_PRINT((ACPI_DB_INFO,
-				"C3 support without bus mastering control\n"));
+			if (pr->flags.has_cst != 1) {
+				/* bus mastering control is necessary */
+				ACPI_DEBUG_PRINT((ACPI_DB_INFO,
+					"C3 support requires BM control\n"));
+				return;
+			} else {
+				/* Here we enter C3 without bus mastering */
+				ACPI_DEBUG_PRINT((ACPI_DB_INFO,
+					"C3 support without BM control\n"));
+			}
 		}
 	} else {
 		/*

commit f79e3185dd0f8650022518d7624c876d8929061b
Merge: e8b495fe09bc 8b8eb7d8cfc6
Author: Len Brown <len.brown@intel.com>
Date:   Sun Jul 22 02:27:40 2007 -0400

    Pull misc into release branch
    
    Conflicts:
    
            Documentation/feature-removal-schedule.txt

commit 0aa366f351d044703e25c8425e508170e80d83b1
Author: Tony Luck <tony.luck@intel.com>
Date:   Fri Jul 20 11:22:30 2007 -0700

    [IA64] Convert to generic timekeeping/clocksource
    
    This is a merge of Peter Keilty's initial patch (which was
    revived by Bob Picco) for this with Hidetoshi Seto's fixes
    and scaling improvements.
    
    Acked-by: Bob Picco <bob.picco@hp.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 80ffc7829916..bb5d23be4260 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -475,7 +475,7 @@ static void acpi_processor_idle(void)
 		/* Get end time (ticks) */
 		t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 
-#ifdef CONFIG_GENERIC_TIME
+#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86_TSC)
 		/* TSC halts in C2, so notify users */
 		mark_tsc_unstable("possible TSC halt in C2");
 #endif
@@ -517,7 +517,7 @@ static void acpi_processor_idle(void)
 			acpi_set_register(ACPI_BITREG_ARB_DISABLE, 0);
 		}
 
-#ifdef CONFIG_GENERIC_TIME
+#if defined (CONFIG_GENERIC_TIME) && defined (CONFIG_X86_TSC)
 		/* TSC halts in C3, so notify users */
 		mark_tsc_unstable("TSC halts in C3");
 #endif

commit 18eab8550397f1f3d4b8b2c5257c88dae25d58ed
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Fri Jun 15 19:37:00 2007 -0400

    ACPI: Enable C3 even when PM2_control is zero
    
    On systems that do not have pm2_control_block, we cannot really use
    ARB_DISABLE before C3. We used to disable C3 totally on such systems.
    
    To be compatible with Windows, we need to enable C3 on such systems now.
    We just skip ARB_DISABLE step before entering the C3-state and assume
    hardware is handling things correctly. Also, ACPI spec is not clear
    about pm2_control is _needed_ for C3 or not.
    
    We have atleast one system that need this to enable C3.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index ee5759bef945..36dc1d26520a 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -488,7 +488,17 @@ static void acpi_processor_idle(void)
 
 	case ACPI_STATE_C3:
 
-		if (pr->flags.bm_check) {
+		/*
+		 * disable bus master
+		 * bm_check implies we need ARB_DIS
+		 * !bm_check implies we need cache flush
+		 * bm_control implies whether we can do ARB_DIS
+		 *
+		 * That leaves a case where bm_check is set and bm_control is
+		 * not set. In that case we cannot do much, we enter C3
+		 * without doing anything.
+		 */
+		if (pr->flags.bm_check && pr->flags.bm_control) {
 			if (atomic_inc_return(&c3_cpu_count) ==
 			    num_online_cpus()) {
 				/*
@@ -497,7 +507,7 @@ static void acpi_processor_idle(void)
 				 */
 				acpi_set_register(ACPI_BITREG_ARB_DISABLE, 1);
 			}
-		} else {
+		} else if (!pr->flags.bm_check) {
 			/* SMP with no shared cache... Invalidate cache  */
 			ACPI_FLUSH_CPU_CACHE();
 		}
@@ -509,7 +519,7 @@ static void acpi_processor_idle(void)
 		acpi_cstate_enter(cx);
 		/* Get end time (ticks) */
 		t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
-		if (pr->flags.bm_check) {
+		if (pr->flags.bm_check && pr->flags.bm_control) {
 			/* Enable bus master arbitration */
 			atomic_dec(&c3_cpu_count);
 			acpi_set_register(ACPI_BITREG_ARB_DISABLE, 0);
@@ -959,9 +969,9 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 	if (pr->flags.bm_check) {
 		/* bus mastering control is necessary */
 		if (!pr->flags.bm_control) {
+			/* In this case we enter C3 without bus mastering */
 			ACPI_DEBUG_PRINT((ACPI_DB_INFO,
-					  "C3 support requires bus mastering control\n"));
-			return;
+				"C3 support without bus mastering control\n"));
 		}
 	} else {
 		/*

commit d5a3d32a042126f65a008e0e5204ef92ad2ee55d
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Fri Jun 15 19:36:00 2007 -0400

    ACPI: fix 2.6.20 SMP boot regression
    
    Always disable/enable interrupts in the acpi idle routine,
    even in the error path.
    
    This is required as the 2.6.20 change in git commit d331e739f5ad2aaa9...
    "Fix interrupt race in idle callback" expects the idle handler
    to enable interrupt before returning.
    
    There was a case in acpi idle routine, in which interrupt was not being
    enabled before return, which caused the system to hang at bootup, while
    enabling C-states on an SMP system.
    
    The signature of the hang was that "processor.nocst"
    was required to enable boot.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index ee5759bef945..80ffc7829916 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -332,16 +332,18 @@ static void acpi_processor_idle(void)
 	int sleep_ticks = 0;
 	u32 t1, t2 = 0;
 
-	pr = processors[smp_processor_id()];
-	if (!pr)
-		return;
-
 	/*
 	 * Interrupts must be disabled during bus mastering calculations and
 	 * for C2/C3 transitions.
 	 */
 	local_irq_disable();
 
+	pr = processors[smp_processor_id()];
+	if (!pr) {
+		local_irq_enable();
+		return;
+	}
+
 	/*
 	 * Check whether we truly need to go idle, or should
 	 * reschedule:

commit 5a90cf205c922707ffed2d8f87cefd942e96b0ba
Author: john stultz <johnstul@us.ibm.com>
Date:   Wed May 2 19:27:08 2007 +0200

    [PATCH] x86: Log reason why TSC was marked unstable
    
    Change mark_tsc_unstable() so it takes a string argument, which holds the
    reason the TSC was marked unstable.
    
    This is then displayed the first time mark_tsc_unstable is called.
    
    This should help us better debug why the TSC was marked unstable on certain
    systems and allow us to make sure we're not being overly paranoid when
    throwing out this troublesome clocksource.
    
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andi Kleen <ak@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Andi Kleen <ak@suse.de>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index ae0654cd11ea..ee5759bef945 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -475,7 +475,7 @@ static void acpi_processor_idle(void)
 
 #ifdef CONFIG_GENERIC_TIME
 		/* TSC halts in C2, so notify users */
-		mark_tsc_unstable();
+		mark_tsc_unstable("possible TSC halt in C2");
 #endif
 		/* Re-enable interrupts */
 		local_irq_enable();
@@ -517,7 +517,7 @@ static void acpi_processor_idle(void)
 
 #ifdef CONFIG_GENERIC_TIME
 		/* TSC halts in C3, so notify users */
-		mark_tsc_unstable();
+		mark_tsc_unstable("TSC halts in C3");
 #endif
 		/* Re-enable interrupts */
 		local_irq_enable();

commit d8938801d10945ac2fbe0f41ded43f6276660a17
Author: Ray Lee <ray-lk@madrabbit.org>
Date:   Wed Apr 25 14:12:00 2007 -0400

    ACPI: remove duplicate include
    
    Thomas's patch for including <asm/apic.h> for x86 UP builds came into
    Linus's tree from two different directions, both of which were merged.
    This reverts the latter, yanking out the duplicate #include and comment.
    
    Signed-off-by: Ray Lee <ray-lk@madrabbit.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index cdf78943af4d..ae0654cd11ea 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -51,14 +51,6 @@
 #include <asm/apic.h>
 #endif
 
-/*
- * Include the apic definitions for x86 to have the APIC timer related defines
- * available also for UP (on SMP it gets magically included via linux/smp.h).
- */
-#ifdef CONFIG_X86
-#include <asm/apic.h>
-#endif
-
 #include <asm/io.h>
 #include <asm/uaccess.h>
 

commit e585bef815c0315f2730d7bb4e15b82602454efd
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Mar 23 16:08:01 2007 +0100

    [PATCH] i386: add command line option "local_apic_timer_c2_ok"
    
    It turned out that it is almost impossible to trust ACPI, BIOS & Co.
    regarding the C states. This was the reason to switch the local apic
    timer off in C2 state already. OTOH there are sane and well behaving
    systems, which get punished by that decision.
    
    Allow the user to confirm that the local apic timer is trustworthy in C2
    state. This keeps the default behaviour on the safe side.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 60773005b8af..cdf78943af4d 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -268,6 +268,7 @@ static void acpi_timer_check_state(int state, struct acpi_processor *pr,
 				   struct acpi_processor_cx *cx)
 {
 	struct acpi_processor_power *pwr = &pr->power;
+	u8 type = local_apic_timer_c2_ok ? ACPI_STATE_C3 : ACPI_STATE_C2;
 
 	/*
 	 * Check, if one of the previous states already marked the lapic
@@ -276,7 +277,7 @@ static void acpi_timer_check_state(int state, struct acpi_processor *pr,
 	if (pwr->timer_broadcast_on_state < state)
 		return;
 
-	if (cx->type >= ACPI_STATE_C2)
+	if (cx->type >= type)
 		pr->power.timer_broadcast_on_state = state;
 }
 

commit 296d93cd0205433489b0689533426ce0a8cf2dec
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Fri Mar 23 08:03:47 2007 -0700

    Revert "ACPI: Only use IPI on known broken machines (AMD, Dothan/BaniasPentium M)"
    
    This reverts commit 25496caec111481161e7f06bbfa12a533c43cc6f, which
    broke bootup on at least Ingo's ThinkPad T60.  Need to figure out
    exactly what is wrong before we can re-do the logic.
    
    Requested-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Thomas Renninger <trenn@suse.de>
    Cc: Len Brown <len.brown@intel.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 562124ed785e..60773005b8af 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -89,12 +89,6 @@ module_param(nocst, uint, 0000);
 static unsigned int bm_history __read_mostly =
     (HZ >= 800 ? 0xFFFFFFFF : ((1U << (HZ / 25)) - 1));
 module_param(bm_history, uint, 0644);
-
-static unsigned use_ipi = 2;
-module_param(use_ipi, uint, 0644);
-MODULE_PARM_DESC(use_ipi, "IPI (vs. LAPIC) irqs for not waking up from C2/C3"
-		 " machines. 0=apic, 1=ipi, 2=auto\n");
-
 /* --------------------------------------------------------------------------
                                 Power Management
    -------------------------------------------------------------------------- */
@@ -266,8 +260,9 @@ static void acpi_cstate_enter(struct acpi_processor_cx *cstate)
 
 /*
  * Some BIOS implementations switch to C3 in the published C2 state.
- * This seems to be a common problem on AMD boxen and Intel Dothan/Banias
- * Pentium M machines.
+ * This seems to be a common problem on AMD boxen, but other vendors
+ * are affected too. We pick the most conservative approach: we assume
+ * that the local APIC stops in both C2 and C3.
  */
 static void acpi_timer_check_state(int state, struct acpi_processor *pr,
 				   struct acpi_processor_cx *cx)
@@ -281,17 +276,8 @@ static void acpi_timer_check_state(int state, struct acpi_processor *pr,
 	if (pwr->timer_broadcast_on_state < state)
 		return;
 
-	if (cx->type >= ACPI_STATE_C2) {
-		if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD)
-			pr->power.timer_broadcast_on_state = state;
-		else if ((boot_cpu_data.x86_vendor == X86_VENDOR_INTEL &&
-			  boot_cpu_data.x86 == 6) &&
-			 (boot_cpu_data.x86_model == 13 ||
-			  boot_cpu_data.x86_model == 9))
-		{
-			pr->power.timer_broadcast_on_state = state;
-		}
-	}
+	if (cx->type >= ACPI_STATE_C2)
+		pr->power.timer_broadcast_on_state = state;
 }
 
 static void acpi_propagate_timer_broadcast(struct acpi_processor *pr)
@@ -306,16 +292,10 @@ static void acpi_propagate_timer_broadcast(struct acpi_processor *pr)
 #else
 	cpumask_t mask = cpumask_of_cpu(pr->id);
 
-	if (use_ipi == 0)
+	if (pr->power.timer_broadcast_on_state < INT_MAX)
 		on_each_cpu(switch_APIC_timer_to_ipi, &mask, 1, 1);
-	else if (use_ipi == 1)
+	else
 		on_each_cpu(switch_ipi_to_APIC_timer, &mask, 1, 1);
-	else {
-		if (pr->power.timer_broadcast_on_state < INT_MAX)
-			on_each_cpu(switch_APIC_timer_to_ipi, &mask, 1, 1);
-		else
-			on_each_cpu(switch_ipi_to_APIC_timer, &mask, 1, 1);
-	}
 #endif
 }
 
@@ -1033,13 +1013,13 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 
 		case ACPI_STATE_C2:
 			acpi_processor_power_verify_c2(cx);
-			if (cx->valid && use_ipi != 0 && use_ipi != 1)
+			if (cx->valid)
 				acpi_timer_check_state(i, pr, cx);
 			break;
 
 		case ACPI_STATE_C3:
 			acpi_processor_power_verify_c3(pr, cx);
-			if (cx->valid && use_ipi != 0 && use_ipi != 1)
+			if (cx->valid)
 				acpi_timer_check_state(i, pr, cx);
 			break;
 		}

commit 25496caec111481161e7f06bbfa12a533c43cc6f
Author: Thomas Renninger <trenn@suse.de>
Date:   Tue Feb 27 12:13:00 2007 -0500

    ACPI: Only use IPI on known broken machines (AMD, Dothan/BaniasPentium M)
    
    Use IPI for blacklisted CPUs, add parameter IPI vs LAPIC
    
    Currently, Linux disables lapic timer for all machines with C2 and higher
    C-state support.
    
    According to Intel only specific Intel models (Banias/Dothan) are broken
    in respect of not waking up from C2 with lapic.
    
    However, I am not sure about the naming of the parameter and how it
    could/should get integrated into the dyntick part
    (CONFIG_GENERIC_CLOCKEVENTS). There, a more fine grained check (TSC
    still running?, ..) is needed? Does this make sense (always use
    CLOCK_EVT_NOTIFY_BROADCAST_ON, but use OFF if forced by use_ipi=0:
    clockevents_notify(use_ipi ? CLOCK_EVT_NOTIFY_BROADCAST_ON :
    CLOCK_EVT_NOTIFY_BROADCAST_OFF, &pr->id);
    
    Signed-off-by: Thomas Renninger <trenn@suse.de>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 60773005b8af..562124ed785e 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -89,6 +89,12 @@ module_param(nocst, uint, 0000);
 static unsigned int bm_history __read_mostly =
     (HZ >= 800 ? 0xFFFFFFFF : ((1U << (HZ / 25)) - 1));
 module_param(bm_history, uint, 0644);
+
+static unsigned use_ipi = 2;
+module_param(use_ipi, uint, 0644);
+MODULE_PARM_DESC(use_ipi, "IPI (vs. LAPIC) irqs for not waking up from C2/C3"
+		 " machines. 0=apic, 1=ipi, 2=auto\n");
+
 /* --------------------------------------------------------------------------
                                 Power Management
    -------------------------------------------------------------------------- */
@@ -260,9 +266,8 @@ static void acpi_cstate_enter(struct acpi_processor_cx *cstate)
 
 /*
  * Some BIOS implementations switch to C3 in the published C2 state.
- * This seems to be a common problem on AMD boxen, but other vendors
- * are affected too. We pick the most conservative approach: we assume
- * that the local APIC stops in both C2 and C3.
+ * This seems to be a common problem on AMD boxen and Intel Dothan/Banias
+ * Pentium M machines.
  */
 static void acpi_timer_check_state(int state, struct acpi_processor *pr,
 				   struct acpi_processor_cx *cx)
@@ -276,8 +281,17 @@ static void acpi_timer_check_state(int state, struct acpi_processor *pr,
 	if (pwr->timer_broadcast_on_state < state)
 		return;
 
-	if (cx->type >= ACPI_STATE_C2)
-		pr->power.timer_broadcast_on_state = state;
+	if (cx->type >= ACPI_STATE_C2) {
+		if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD)
+			pr->power.timer_broadcast_on_state = state;
+		else if ((boot_cpu_data.x86_vendor == X86_VENDOR_INTEL &&
+			  boot_cpu_data.x86 == 6) &&
+			 (boot_cpu_data.x86_model == 13 ||
+			  boot_cpu_data.x86_model == 9))
+		{
+			pr->power.timer_broadcast_on_state = state;
+		}
+	}
 }
 
 static void acpi_propagate_timer_broadcast(struct acpi_processor *pr)
@@ -292,10 +306,16 @@ static void acpi_propagate_timer_broadcast(struct acpi_processor *pr)
 #else
 	cpumask_t mask = cpumask_of_cpu(pr->id);
 
-	if (pr->power.timer_broadcast_on_state < INT_MAX)
+	if (use_ipi == 0)
 		on_each_cpu(switch_APIC_timer_to_ipi, &mask, 1, 1);
-	else
+	else if (use_ipi == 1)
 		on_each_cpu(switch_ipi_to_APIC_timer, &mask, 1, 1);
+	else {
+		if (pr->power.timer_broadcast_on_state < INT_MAX)
+			on_each_cpu(switch_APIC_timer_to_ipi, &mask, 1, 1);
+		else
+			on_each_cpu(switch_ipi_to_APIC_timer, &mask, 1, 1);
+	}
 #endif
 }
 
@@ -1013,13 +1033,13 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 
 		case ACPI_STATE_C2:
 			acpi_processor_power_verify_c2(cx);
-			if (cx->valid)
+			if (cx->valid && use_ipi != 0 && use_ipi != 1)
 				acpi_timer_check_state(i, pr, cx);
 			break;
 
 		case ACPI_STATE_C3:
 			acpi_processor_power_verify_c3(pr, cx);
-			if (cx->valid)
+			if (cx->valid && use_ipi != 0 && use_ipi != 1)
 				acpi_timer_check_state(i, pr, cx);
 			break;
 		}

commit c0cd79d11412969b6b8fa1624cdc1277db82e2fe
Merge: 81450b73dde0 db2d4ccdc8f9
Author: Len Brown <len.brown@intel.com>
Date:   Fri Feb 16 22:10:32 2007 -0500

    Pull fluff into release branch
    
    Conflicts:
    
            arch/x86_64/pci/mmconfig.c
            drivers/acpi/bay.c
    
    Signed-off-by: Len Brown <len.brown@intel.com>

commit 81450b73dde07f473a4a7208b209b4c8b7251d90
Merge: 8a03d9a498ea 0539771d7236
Author: Len Brown <len.brown@intel.com>
Date:   Fri Feb 16 18:52:41 2007 -0500

    Pull misc-for-upstream into release branch
    
    Conflicts:
    
            drivers/usb/misc/appledisplay.c
    
    Signed-off-by: Len Brown <len.brown@intel.com>

commit e9e2cdb412412326c4827fc78ba27f410d837e6e
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Feb 16 01:28:04 2007 -0800

    [PATCH] clockevents: i386 drivers
    
    Add clockevent drivers for i386: lapic (local) and PIT/HPET (global).  Update
    the timer IRQ to call into the PIT/HPET driver's event handler and the
    lapic-timer IRQ to call into the lapic clockevent driver.  The assignement of
    timer functionality is delegated to the core framework code and replaces the
    compile and runtime evalution in do_timer_interrupt_hook()
    
    Use the clockevents broadcast support and implement the lapic_broadcast
    function for ACPI.
    
    No changes to existing functionality.
    
    [ kdump fix from Vivek Goyal <vgoyal@in.ibm.com> ]
    [ fixes based on review feedback from Arjan van de Ven <arjan@infradead.org> ]
    Cleanups-from: Adrian Bunk <bunk@stusta.de>
    Build-fixes-from: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Cc: john stultz <johnstul@us.ibm.com>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Cc: Andi Kleen <ak@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 4ea6d8b20d17..8206fc1ecc58 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -39,6 +39,7 @@
 #include <linux/moduleparam.h>
 #include <linux/sched.h>	/* need_resched() */
 #include <linux/latency.h>
+#include <linux/clockchips.h>
 
 /*
  * Include the apic definitions for x86 to have the APIC timer related defines
@@ -274,12 +275,40 @@ static void acpi_timer_check_state(int state, struct acpi_processor *pr,
 
 static void acpi_propagate_timer_broadcast(struct acpi_processor *pr)
 {
+#ifdef CONFIG_GENERIC_CLOCKEVENTS
+	unsigned long reason;
+
+	reason = pr->power.timer_broadcast_on_state < INT_MAX ?
+		CLOCK_EVT_NOTIFY_BROADCAST_ON : CLOCK_EVT_NOTIFY_BROADCAST_OFF;
+
+	clockevents_notify(reason, &pr->id);
+#else
 	cpumask_t mask = cpumask_of_cpu(pr->id);
 
 	if (pr->power.timer_broadcast_on_state < INT_MAX)
 		on_each_cpu(switch_APIC_timer_to_ipi, &mask, 1, 1);
 	else
 		on_each_cpu(switch_ipi_to_APIC_timer, &mask, 1, 1);
+#endif
+}
+
+/* Power(C) State timer broadcast control */
+static void acpi_state_timer_broadcast(struct acpi_processor *pr,
+				       struct acpi_processor_cx *cx,
+				       int broadcast)
+{
+#ifdef CONFIG_GENERIC_CLOCKEVENTS
+
+	int state = cx - pr->power.states;
+
+	if (state >= pr->power.timer_broadcast_on_state) {
+		unsigned long reason;
+
+		reason = broadcast ?  CLOCK_EVT_NOTIFY_BROADCAST_ENTER :
+			CLOCK_EVT_NOTIFY_BROADCAST_EXIT;
+		clockevents_notify(reason, &pr->id);
+	}
+#endif
 }
 
 #else
@@ -287,6 +316,11 @@ static void acpi_propagate_timer_broadcast(struct acpi_processor *pr)
 static void acpi_timer_check_state(int state, struct acpi_processor *pr,
 				   struct acpi_processor_cx *cstate) { }
 static void acpi_propagate_timer_broadcast(struct acpi_processor *pr) { }
+static void acpi_state_timer_broadcast(struct acpi_processor *pr,
+				       struct acpi_processor_cx *cx,
+				       int broadcast)
+{
+}
 
 #endif
 
@@ -434,6 +468,7 @@ static void acpi_processor_idle(void)
 		/* Get start time (ticks) */
 		t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 		/* Invoke C2 */
+		acpi_state_timer_broadcast(pr, cx, 1);
 		acpi_cstate_enter(cx);
 		/* Get end time (ticks) */
 		t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
@@ -448,6 +483,7 @@ static void acpi_processor_idle(void)
 		/* Compute time (ticks) that we were actually asleep */
 		sleep_ticks =
 		    ticks_elapsed(t1, t2) - cx->latency_ticks - C2_OVERHEAD;
+		acpi_state_timer_broadcast(pr, cx, 0);
 		break;
 
 	case ACPI_STATE_C3:
@@ -469,6 +505,7 @@ static void acpi_processor_idle(void)
 		/* Get start time (ticks) */
 		t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 		/* Invoke C3 */
+		acpi_state_timer_broadcast(pr, cx, 1);
 		acpi_cstate_enter(cx);
 		/* Get end time (ticks) */
 		t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
@@ -488,6 +525,7 @@ static void acpi_processor_idle(void)
 		/* Compute time (ticks) that we were actually asleep */
 		sleep_ticks =
 		    ticks_elapsed(t1, t2) - cx->latency_ticks - C3_OVERHEAD;
+		acpi_state_timer_broadcast(pr, cx, 0);
 		break;
 
 	default:

commit 169a0abbe32813af4904cc1605c0f7ea0534f77b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Feb 16 01:27:55 2007 -0800

    [PATCH] ACPI keep track of timer broadcasting
    
    This is a preperatory patch for highres/dyntick:
    
    - replace the big #ifdef ARCH_APICTIMER_STOPS_ON_C3 hackery by functions
    
    - remove the double switch in the power verify function (in the worst case
      we switched ipi to apic and 20usec later apic to ipi)
    
    - keep track of the the state which stops local APIC timer
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Cc: Len Brown <len.brown@intel.com>
    Cc: <linux-acpi@vger.kernel.org>
    Cc: Andi Kleen <ak@suse.de>
    Cc: john stultz <johnstul@us.ibm.com>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index e34af7772a66..4ea6d8b20d17 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -248,6 +248,48 @@ static void acpi_cstate_enter(struct acpi_processor_cx *cstate)
 	}
 }
 
+#ifdef ARCH_APICTIMER_STOPS_ON_C3
+
+/*
+ * Some BIOS implementations switch to C3 in the published C2 state.
+ * This seems to be a common problem on AMD boxen, but other vendors
+ * are affected too. We pick the most conservative approach: we assume
+ * that the local APIC stops in both C2 and C3.
+ */
+static void acpi_timer_check_state(int state, struct acpi_processor *pr,
+				   struct acpi_processor_cx *cx)
+{
+	struct acpi_processor_power *pwr = &pr->power;
+
+	/*
+	 * Check, if one of the previous states already marked the lapic
+	 * unstable
+	 */
+	if (pwr->timer_broadcast_on_state < state)
+		return;
+
+	if (cx->type >= ACPI_STATE_C2)
+		pr->power.timer_broadcast_on_state = state;
+}
+
+static void acpi_propagate_timer_broadcast(struct acpi_processor *pr)
+{
+	cpumask_t mask = cpumask_of_cpu(pr->id);
+
+	if (pr->power.timer_broadcast_on_state < INT_MAX)
+		on_each_cpu(switch_APIC_timer_to_ipi, &mask, 1, 1);
+	else
+		on_each_cpu(switch_ipi_to_APIC_timer, &mask, 1, 1);
+}
+
+#else
+
+static void acpi_timer_check_state(int state, struct acpi_processor *pr,
+				   struct acpi_processor_cx *cstate) { }
+static void acpi_propagate_timer_broadcast(struct acpi_processor *pr) { }
+
+#endif
+
 static void acpi_processor_idle(void)
 {
 	struct acpi_processor *pr = NULL;
@@ -914,11 +956,7 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 	unsigned int i;
 	unsigned int working = 0;
 
-#ifdef ARCH_APICTIMER_STOPS_ON_C3
-	int timer_broadcast = 0;
-	cpumask_t mask = cpumask_of_cpu(pr->id);
-	on_each_cpu(switch_ipi_to_APIC_timer, &mask, 1, 1);
-#endif
+	pr->power.timer_broadcast_on_state = INT_MAX;
 
 	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
 		struct acpi_processor_cx *cx = &pr->power.states[i];
@@ -930,21 +968,14 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 
 		case ACPI_STATE_C2:
 			acpi_processor_power_verify_c2(cx);
-#ifdef ARCH_APICTIMER_STOPS_ON_C3
-			/* Some AMD systems fake C3 as C2, but still
-			   have timer troubles */
-			if (cx->valid && 
-				boot_cpu_data.x86_vendor == X86_VENDOR_AMD)
-				timer_broadcast++;
-#endif
+			if (cx->valid)
+				acpi_timer_check_state(i, pr, cx);
 			break;
 
 		case ACPI_STATE_C3:
 			acpi_processor_power_verify_c3(pr, cx);
-#ifdef ARCH_APICTIMER_STOPS_ON_C3
 			if (cx->valid)
-				timer_broadcast++;
-#endif
+				acpi_timer_check_state(i, pr, cx);
 			break;
 		}
 
@@ -952,10 +983,7 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 			working++;
 	}
 
-#ifdef ARCH_APICTIMER_STOPS_ON_C3
-	if (timer_broadcast)
-		on_each_cpu(switch_APIC_timer_to_ipi, &mask, 1, 1);
-#endif
+	acpi_propagate_timer_broadcast(pr);
 
 	return (working);
 }

commit 3434933b17fa64adddf83059603c61296f6e1ee2
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Feb 16 01:27:54 2007 -0800

    [PATCH] ACPI: fix missing include for UP
    
    apic.h does not get included on UP compiles.  That way the
    APICTIMER_STOPS_ON_C3 is not there and UP boxen have no support for timer
    broadcasting.  This was never noticed, because the lapic timer is only used
    for profiling on UP.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Cc: john stultz <johnstul@us.ibm.com>
    Cc: Len Brown <len.brown@intel.com>
    Cc: Andi Kleen <ak@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 6c6751b1405b..e34af7772a66 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -40,6 +40,16 @@
 #include <linux/sched.h>	/* need_resched() */
 #include <linux/latency.h>
 
+/*
+ * Include the apic definitions for x86 to have the APIC timer related defines
+ * available also for UP (on SMP it gets magically included via linux/smp.h).
+ * asm/acpi.h is not an option, as it would require more include magic. Also
+ * creating an empty asm-ia64/apic.h would just trade pest vs. cholera.
+ */
+#ifdef CONFIG_X86
+#include <asm/apic.h>
+#endif
+
 #include <asm/io.h>
 #include <asm/uaccess.h>
 

commit 5c95d3f5783ab184f64b7848f0a871352c35c3cf
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 15 23:25:53 2007 -0500

    ACPI: include apic.h in processor driver for benefit of UP kernels
    
    apic.h does not get included on UP compiles.  That way the
    APICTIMER_STOPS_ON_C3 is not there and UP boxen have no support for timer
    broadcasting.  This was never noticed, because the lapic timer is only used
    for profiling on UP.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Cc: john stultz <johnstul@us.ibm.com>
    Cc: Andi Kleen <ak@suse.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 6c6751b1405b..59fac8d79412 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -40,6 +40,14 @@
 #include <linux/sched.h>	/* need_resched() */
 #include <linux/latency.h>
 
+/*
+ * Include the apic definitions for x86 to have the APIC timer related defines
+ * available also for UP (on SMP it gets magically included via linux/smp.h).
+ */
+#ifdef CONFIG_X86
+#include <asm/apic.h>
+#endif
+
 #include <asm/io.h>
 #include <asm/uaccess.h>
 

commit 7cda93e008e1a477970adbf82dba81a5d4f0ae40
Author: Len Brown <len.brown@intel.com>
Date:   Mon Feb 12 23:50:02 2007 -0500

    ACPI: delete extra #defines in /drivers/acpi/ drivers
    
    Cosmetic only.
    
    Except in a single case, #define ACPI_*_DRIVER_NAME
    were invoked 0 or 1 times.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index a26433d1a16e..92f5185464d2 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -48,7 +48,6 @@
 
 #define ACPI_PROCESSOR_COMPONENT        0x01000000
 #define ACPI_PROCESSOR_CLASS            "processor"
-#define ACPI_PROCESSOR_DRIVER_NAME      "ACPI Processor Driver"
 #define _COMPONENT              ACPI_PROCESSOR_COMPONENT
 ACPI_MODULE_NAME("processor_idle");
 #define ACPI_PROCESSOR_FILE_POWER	"power"

commit f52fd66d2ea794010c2d7536cf8e6abed0ac4947
Author: Len Brown <len.brown@intel.com>
Date:   Mon Feb 12 22:42:12 2007 -0500

    ACPI: clean up ACPI_MODULE_NAME() use
    
    cosmetic only
    
    Make "module name" actually match the file name.
    Invoke with ';' as leaving it off confuses Lindent and gcc doesn't care.
    Fix indentation where Lindent did get confused.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 6c6751b1405b..a26433d1a16e 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -50,7 +50,7 @@
 #define ACPI_PROCESSOR_CLASS            "processor"
 #define ACPI_PROCESSOR_DRIVER_NAME      "ACPI Processor Driver"
 #define _COMPONENT              ACPI_PROCESSOR_COMPONENT
-ACPI_MODULE_NAME("acpi_processor")
+ACPI_MODULE_NAME("processor_idle");
 #define ACPI_PROCESSOR_FILE_POWER	"power"
 #define US_TO_PM_TIMER_TICKS(t)		((t * (PM_TIMER_FREQUENCY/1000)) / 1000)
 #define C2_OVERHEAD			4	/* 1us (3.579 ticks per us) */

commit b0b7eaaf0c7aefd118d3ff8640fbed75a9fad9a1
Author: Alexey Starikovskiy <alexey.y.starikovskiy@linux.intel.com>
Date:   Thu Jan 25 22:39:44 2007 -0500

    ACPICA: fix gcc build warnings
    
    drivers/acpi/namespace/nsparse.c:126: warning: int format, different type arg (arg 7)
    drivers/acpi/tables/tbfadt.c:224: warning: unsigned int format, different type arg (arg 6)
    drivers/acpi/utilities/utdebug.c:184: warning: cast from pointer to integer of different size
    drivers/acpi/utilities/utdebug.c:184: warning: cast from pointer to integer of different size
    drivers/acpi/utilities/utdebug.c:197: warning: cast from pointer to integer of different size
    drivers/acpi/processor_idle.c:1093: warning: long long unsigned int format, u64 arg (arg 5)
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 1d633f7e64fb..6c6751b1405b 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1090,7 +1090,7 @@ static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
 		seq_printf(seq, "latency[%03d] usage[%08d] duration[%020llu]\n",
 			   pr->power.states[i].latency,
 			   pr->power.states[i].usage,
-			   pr->power.states[i].time);
+			   (unsigned long long)pr->power.states[i].time);
 	}
 
       end:

commit cee324b145a1e5488b34191de670e5ed1d346ebb
Author: Alexey Starikovskiy <alexey.y.starikovskiy@intel.com>
Date:   Fri Feb 2 19:48:22 2007 +0300

    ACPICA: use new ACPI headers.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index db21dda5837d..1d633f7e64fb 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -160,7 +160,7 @@ static inline u32 ticks_elapsed(u32 t1, u32 t2)
 {
 	if (t2 >= t1)
 		return (t2 - t1);
-	else if (!(acpi_fadt.flags & ACPI_FADT_32BIT_TIMER))
+	else if (!(acpi_gbl_FADT.flags & ACPI_FADT_32BIT_TIMER))
 		return (((0x00FFFFFF - t1) + t2) & 0x00FFFFFF);
 	else
 		return ((0xFFFFFFFF - t1) + t2);
@@ -234,7 +234,7 @@ static void acpi_cstate_enter(struct acpi_processor_cx *cstate)
 		/* Dummy wait op - must do something useless after P_LVL2 read
 		   because chipsets cannot guarantee that STPCLK# signal
 		   gets asserted in time to freeze execution properly. */
-		unused = inl(acpi_fadt.xpm_timer_block.address);
+		unused = inl(acpi_gbl_FADT.xpm_timer_block.address);
 	}
 }
 
@@ -334,7 +334,7 @@ static void acpi_processor_idle(void)
 	 * detection phase, to work cleanly with logical CPU hotplug.
 	 */
 	if ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) && 
-	    !pr->flags.has_cst && !(acpi_fadt.flags & ACPI_FADT_C2_MP_SUPPORTED))
+	    !pr->flags.has_cst && !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
 		cx = &pr->power.states[ACPI_STATE_C1];
 #endif
 
@@ -380,11 +380,11 @@ static void acpi_processor_idle(void)
 
 	case ACPI_STATE_C2:
 		/* Get start time (ticks) */
-		t1 = inl(acpi_fadt.xpm_timer_block.address);
+		t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 		/* Invoke C2 */
 		acpi_cstate_enter(cx);
 		/* Get end time (ticks) */
-		t2 = inl(acpi_fadt.xpm_timer_block.address);
+		t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 
 #ifdef CONFIG_GENERIC_TIME
 		/* TSC halts in C2, so notify users */
@@ -415,11 +415,11 @@ static void acpi_processor_idle(void)
 		}
 
 		/* Get start time (ticks) */
-		t1 = inl(acpi_fadt.xpm_timer_block.address);
+		t1 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 		/* Invoke C3 */
 		acpi_cstate_enter(cx);
 		/* Get end time (ticks) */
-		t2 = inl(acpi_fadt.xpm_timer_block.address);
+		t2 = inl(acpi_gbl_FADT.xpm_timer_block.address);
 		if (pr->flags.bm_check) {
 			/* Enable bus master arbitration */
 			atomic_dec(&c3_cpu_count);
@@ -451,7 +451,7 @@ static void acpi_processor_idle(void)
 #ifdef CONFIG_HOTPLUG_CPU
 	/* Don't do promotion/demotion */
 	if ((cx->type == ACPI_STATE_C1) && (num_online_cpus() > 1) &&
-	    !pr->flags.has_cst && !(acpi_fadt.flags & ACPI_FADT_C2_MP_SUPPORTED)) {
+	    !pr->flags.has_cst && !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED)) {
 		next_state = cx;
 		goto end;
 	}
@@ -622,7 +622,7 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 	 * an SMP system. 
 	 */
 	if ((num_online_cpus() > 1) &&
-	    !(acpi_fadt.flags & ACPI_FADT_C2_MP_SUPPORTED))
+	    !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))
 		return -ENODEV;
 #endif
 
@@ -631,8 +631,8 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 	pr->power.states[ACPI_STATE_C3].address = pr->pblk + 5;
 
 	/* determine latencies from FADT */
-	pr->power.states[ACPI_STATE_C2].latency = acpi_fadt.C2latency;
-	pr->power.states[ACPI_STATE_C3].latency = acpi_fadt.C3latency;
+	pr->power.states[ACPI_STATE_C2].latency = acpi_gbl_FADT.C2latency;
+	pr->power.states[ACPI_STATE_C3].latency = acpi_gbl_FADT.C3latency;
 
 	ACPI_DEBUG_PRINT((ACPI_DB_INFO,
 			  "lvl2[0x%08x] lvl3[0x%08x]\n",
@@ -878,7 +878,7 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 		 * WBINVD should be set in fadt, for C3 state to be
 		 * supported on when bm_check is not required.
 		 */
-		if (!(acpi_fadt.flags & ACPI_FADT_WBINVD)) {
+		if (!(acpi_gbl_FADT.flags & ACPI_FADT_WBINVD)) {
 			ACPI_DEBUG_PRINT((ACPI_DB_INFO,
 					  "Cache invalidation should work properly"
 					  " for C3 to be enabled on SMP systems\n"));
@@ -1158,9 +1158,9 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 	if (!pr)
 		return -EINVAL;
 
-	if (acpi_fadt.cst_control && !nocst) {
+	if (acpi_gbl_FADT.cst_control && !nocst) {
 		status =
-		    acpi_os_write_port(acpi_fadt.smi_command, acpi_fadt.cst_control, 8);
+		    acpi_os_write_port(acpi_gbl_FADT.smi_command, acpi_gbl_FADT.cst_control, 8);
 		if (ACPI_FAILURE(status)) {
 			ACPI_EXCEPTION((AE_INFO, status,
 					"Notifying BIOS of _CST ability failed"));

commit d8c71b6d3b21cf21ad775e1cf6da95bf87bd5ad4
Author: Bob Moore <robert.moore@intel.com>
Date:   Fri Feb 2 19:48:21 2007 +0300

    ACPICA: Remove obsolete Flags parameter.
    
    Remove flags parameter for acpi_{get,set}_register().
    It is no longer necessary now that these functions use a
    spinlock for mutual exclusion.
    
    Signed-off-by: Alexey Starikovskiy <alexey.y.starikovskiy@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 9fa3d3965bb3..db21dda5837d 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -187,8 +187,7 @@ acpi_processor_power_activate(struct acpi_processor *pr,
 		case ACPI_STATE_C3:
 			/* Disable bus master reload */
 			if (new->type != ACPI_STATE_C3 && pr->flags.bm_check)
-				acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 0,
-						  ACPI_MTX_DO_NOT_LOCK);
+				acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 0);
 			break;
 		}
 	}
@@ -198,8 +197,7 @@ acpi_processor_power_activate(struct acpi_processor *pr,
 	case ACPI_STATE_C3:
 		/* Enable bus master reload */
 		if (old->type != ACPI_STATE_C3 && pr->flags.bm_check)
-			acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 1,
-					  ACPI_MTX_DO_NOT_LOCK);
+			acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 1);
 		break;
 	}
 
@@ -291,12 +289,10 @@ static void acpi_processor_idle(void)
 
 		pr->power.bm_activity <<= diff;
 
-		acpi_get_register(ACPI_BITREG_BUS_MASTER_STATUS,
-				  &bm_status, ACPI_MTX_DO_NOT_LOCK);
+		acpi_get_register(ACPI_BITREG_BUS_MASTER_STATUS, &bm_status);
 		if (bm_status) {
 			pr->power.bm_activity |= 0x1;
-			acpi_set_register(ACPI_BITREG_BUS_MASTER_STATUS,
-					  1, ACPI_MTX_DO_NOT_LOCK);
+			acpi_set_register(ACPI_BITREG_BUS_MASTER_STATUS, 1);
 		}
 		/*
 		 * PIIX4 Erratum #18: Note that BM_STS doesn't always reflect
@@ -411,8 +407,7 @@ static void acpi_processor_idle(void)
 				 * All CPUs are trying to go to C3
 				 * Disable bus master arbitration
 				 */
-				acpi_set_register(ACPI_BITREG_ARB_DISABLE, 1,
-						  ACPI_MTX_DO_NOT_LOCK);
+				acpi_set_register(ACPI_BITREG_ARB_DISABLE, 1);
 			}
 		} else {
 			/* SMP with no shared cache... Invalidate cache  */
@@ -428,8 +423,7 @@ static void acpi_processor_idle(void)
 		if (pr->flags.bm_check) {
 			/* Enable bus master arbitration */
 			atomic_dec(&c3_cpu_count);
-			acpi_set_register(ACPI_BITREG_ARB_DISABLE, 0,
-					  ACPI_MTX_DO_NOT_LOCK);
+			acpi_set_register(ACPI_BITREG_ARB_DISABLE, 0);
 		}
 
 #ifdef CONFIG_GENERIC_TIME
@@ -890,8 +884,7 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 					  " for C3 to be enabled on SMP systems\n"));
 			return;
 		}
-		acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD,
-				  0, ACPI_MTX_DO_NOT_LOCK);
+		acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 0);
 	}
 
 	/*

commit ad71860a17ba33eb0e673e9e2cf5ba0d8e3e3fdd
Author: Alexey Starikovskiy <alexey.y.starikovskiy@intel.com>
Date:   Fri Feb 2 19:48:19 2007 +0300

    ACPICA: minimal patch to integrate new tables into Linux
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 3f30af21574e..9fa3d3965bb3 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -160,7 +160,7 @@ static inline u32 ticks_elapsed(u32 t1, u32 t2)
 {
 	if (t2 >= t1)
 		return (t2 - t1);
-	else if (!acpi_fadt.tmr_val_ext)
+	else if (!(acpi_fadt.flags & ACPI_FADT_32BIT_TIMER))
 		return (((0x00FFFFFF - t1) + t2) & 0x00FFFFFF);
 	else
 		return ((0xFFFFFFFF - t1) + t2);
@@ -236,7 +236,7 @@ static void acpi_cstate_enter(struct acpi_processor_cx *cstate)
 		/* Dummy wait op - must do something useless after P_LVL2 read
 		   because chipsets cannot guarantee that STPCLK# signal
 		   gets asserted in time to freeze execution properly. */
-		unused = inl(acpi_fadt.xpm_tmr_blk.address);
+		unused = inl(acpi_fadt.xpm_timer_block.address);
 	}
 }
 
@@ -338,7 +338,7 @@ static void acpi_processor_idle(void)
 	 * detection phase, to work cleanly with logical CPU hotplug.
 	 */
 	if ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) && 
-	    !pr->flags.has_cst && !acpi_fadt.plvl2_up)
+	    !pr->flags.has_cst && !(acpi_fadt.flags & ACPI_FADT_C2_MP_SUPPORTED))
 		cx = &pr->power.states[ACPI_STATE_C1];
 #endif
 
@@ -384,11 +384,11 @@ static void acpi_processor_idle(void)
 
 	case ACPI_STATE_C2:
 		/* Get start time (ticks) */
-		t1 = inl(acpi_fadt.xpm_tmr_blk.address);
+		t1 = inl(acpi_fadt.xpm_timer_block.address);
 		/* Invoke C2 */
 		acpi_cstate_enter(cx);
 		/* Get end time (ticks) */
-		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
+		t2 = inl(acpi_fadt.xpm_timer_block.address);
 
 #ifdef CONFIG_GENERIC_TIME
 		/* TSC halts in C2, so notify users */
@@ -420,11 +420,11 @@ static void acpi_processor_idle(void)
 		}
 
 		/* Get start time (ticks) */
-		t1 = inl(acpi_fadt.xpm_tmr_blk.address);
+		t1 = inl(acpi_fadt.xpm_timer_block.address);
 		/* Invoke C3 */
 		acpi_cstate_enter(cx);
 		/* Get end time (ticks) */
-		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
+		t2 = inl(acpi_fadt.xpm_timer_block.address);
 		if (pr->flags.bm_check) {
 			/* Enable bus master arbitration */
 			atomic_dec(&c3_cpu_count);
@@ -457,7 +457,7 @@ static void acpi_processor_idle(void)
 #ifdef CONFIG_HOTPLUG_CPU
 	/* Don't do promotion/demotion */
 	if ((cx->type == ACPI_STATE_C1) && (num_online_cpus() > 1) &&
-	    !pr->flags.has_cst && !acpi_fadt.plvl2_up) {
+	    !pr->flags.has_cst && !(acpi_fadt.flags & ACPI_FADT_C2_MP_SUPPORTED)) {
 		next_state = cx;
 		goto end;
 	}
@@ -627,7 +627,8 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 	 * Check for P_LVL2_UP flag before entering C2 and above on
 	 * an SMP system. 
 	 */
-	if ((num_online_cpus() > 1) && !acpi_fadt.plvl2_up)
+	if ((num_online_cpus() > 1) &&
+	    !(acpi_fadt.flags & ACPI_FADT_C2_MP_SUPPORTED))
 		return -ENODEV;
 #endif
 
@@ -636,8 +637,8 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 	pr->power.states[ACPI_STATE_C3].address = pr->pblk + 5;
 
 	/* determine latencies from FADT */
-	pr->power.states[ACPI_STATE_C2].latency = acpi_fadt.plvl2_lat;
-	pr->power.states[ACPI_STATE_C3].latency = acpi_fadt.plvl3_lat;
+	pr->power.states[ACPI_STATE_C2].latency = acpi_fadt.C2latency;
+	pr->power.states[ACPI_STATE_C3].latency = acpi_fadt.C3latency;
 
 	ACPI_DEBUG_PRINT((ACPI_DB_INFO,
 			  "lvl2[0x%08x] lvl3[0x%08x]\n",
@@ -883,7 +884,7 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 		 * WBINVD should be set in fadt, for C3 state to be
 		 * supported on when bm_check is not required.
 		 */
-		if (acpi_fadt.wb_invd != 1) {
+		if (!(acpi_fadt.flags & ACPI_FADT_WBINVD)) {
 			ACPI_DEBUG_PRINT((ACPI_DB_INFO,
 					  "Cache invalidation should work properly"
 					  " for C3 to be enabled on SMP systems\n"));
@@ -1164,9 +1165,9 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 	if (!pr)
 		return -EINVAL;
 
-	if (acpi_fadt.cst_cnt && !nocst) {
+	if (acpi_fadt.cst_control && !nocst) {
 		status =
-		    acpi_os_write_port(acpi_fadt.smi_cmd, acpi_fadt.cst_cnt, 8);
+		    acpi_os_write_port(acpi_fadt.smi_command, acpi_fadt.cst_control, 8);
 		if (ACPI_FAILURE(status)) {
 			ACPI_EXCEPTION((AE_INFO, status,
 					"Notifying BIOS of _CST ability failed"));

commit 18ed1c051317ac3a685120cead2adb192b802347
Merge: dab6df630867 36bcbec7ce21
Author: Linus Torvalds <torvalds@woody.osdl.org>
Date:   Fri Dec 22 18:46:56 2006 -0800

    Merge branch 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-acpi-2.6
    
    * 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-acpi-2.6: (68 commits)
      ACPI: replace kmalloc+memset with kzalloc
      ACPI: Add support for acpi_load_table/acpi_unload_table_id
      fbdev: update after backlight argument change
      ACPI: video: Add dev argument for backlight_device_register
      ACPI: Implement acpi_video_get_next_level()
      ACPI: Kconfig - depend on PM rather than selecting it
      ACPI: fix NULL check in drivers/acpi/osl.c
      ACPI: make drivers/acpi/ec.c:ec_ecdt static
      ACPI: prevent processor module from loading on failures
      ACPI: fix single linked list manipulation
      ACPI: ibm_acpi: allow clean removal
      ACPI: fix git automerge failure
      ACPI: ibm_acpi: respond to workqueue update
      ACPI: dock: add uevent to indicate change in device status
      ACPI: ec: Lindent once again
      ACPI: ec: Change #define to enums there possible.
      ACPI: ec: Style changes.
      ACPI: ec: Acquire Global Lock under EC mutex.
      ACPI: ec: Drop udelay() from poll mode. Loop by reading status field instead.
      ACPI: ec: Rename gpe_bit to gpe
      ...

commit 0888f06ac99f993df2bb4c479f5b9306dafe154f
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Dec 22 01:11:56 2006 -0800

    [PATCH] sched: fix bad missed wakeups in the i386, x86_64, ia64, ACPI and APM idle code
    
    Fernando Lopez-Lezcano reported frequent scheduling latencies and audio
    xruns starting at the 2.6.18-rt kernel, and those problems persisted all
    until current -rt kernels. The latencies were serious and unjustified by
    system load, often in the milliseconds range.
    
    After a patient and heroic multi-month effort of Fernando, where he
    tested dozens of kernels, tried various configs, boot options,
    test-patches of mine and provided latency traces of those incidents, the
    following 'smoking gun' trace was captured by him:
    
                     _------=> CPU#
                    / _-----=> irqs-off
                   | / _----=> need-resched
                   || / _---=> hardirq/softirq
                   ||| / _--=> preempt-depth
                   |||| /
                   |||||     delay
       cmd     pid ||||| time  |   caller
          \   /    |||||   \   |   /
      IRQ_19-1479  1D..1    0us : __trace_start_sched_wakeup (try_to_wake_up)
      IRQ_19-1479  1D..1    0us : __trace_start_sched_wakeup <<...>-5856> (37 0)
      IRQ_19-1479  1D..1    0us : __trace_start_sched_wakeup (c01262ba 0 0)
      IRQ_19-1479  1D..1    0us : resched_task (try_to_wake_up)
      IRQ_19-1479  1D..1    0us : __spin_unlock_irqrestore (try_to_wake_up)
      ...
      <idle>-0     1...1   11us!: default_idle (cpu_idle)
      ...
      <idle>-0     0Dn.1  602us : smp_apic_timer_interrupt (c0103baf 1 0)
      ...
       <...>-5856  0D..2  618us : __switch_to (__schedule)
       <...>-5856  0D..2  618us : __schedule <<idle>-0> (20 162)
       <...>-5856  0D..2  619us : __spin_unlock_irq (__schedule)
       <...>-5856  0...1  619us : trace_stop_sched_switched (__schedule)
       <...>-5856  0D..1  619us : trace_stop_sched_switched <<...>-5856> (37 0)
    
    what is visible in this trace is that CPU#1 ran try_to_wake_up() for
    PID:5856, it placed PID:5856 on CPU#0's runqueue and ran resched_task()
    for CPU#0. But it decided to not send an IPI that no CPU - due to
    TS_POLLING. But CPU#0 never woke up after its NEED_RESCHED bit was set,
    and only rescheduled to PID:5856 upon the next lapic timer IRQ. The
    result was a 600+ usecs latency and a missed wakeup!
    
    the bug turned out to be an idle-wakeup bug introduced into the mainline
    kernel this summer via an optimization in the x86_64 tree:
    
        commit 495ab9c045e1b0e5c82951b762257fe1c9d81564
        Author: Andi Kleen <ak@suse.de>
        Date:   Mon Jun 26 13:59:11 2006 +0200
    
        [PATCH] i386/x86-64/ia64: Move polling flag into thread_info_status
    
        During some profiling I noticed that default_idle causes a lot of
        memory traffic. I think that is caused by the atomic operations
        to clear/set the polling flag in thread_info. There is actually
        no reason to make this atomic - only the idle thread does it
        to itself, other CPUs only read it. So I moved it into ti->status.
    
    the problem is this type of change:
    
            if (!hlt_counter && boot_cpu_data.hlt_works_ok) {
    -               clear_thread_flag(TIF_POLLING_NRFLAG);
    +               current_thread_info()->status &= ~TS_POLLING;
                    smp_mb__after_clear_bit();
                    while (!need_resched()) {
                            local_irq_disable();
    
    this changes clear_thread_flag() to an explicit clearing of TS_POLLING.
    clear_thread_flag() is defined as:
    
            clear_bit(flag, &ti->flags);
    
    and clear_bit() is a LOCK-ed atomic instruction on all x86 platforms:
    
      static inline void clear_bit(int nr, volatile unsigned long * addr)
      {
              __asm__ __volatile__( LOCK_PREFIX
                      "btrl %1,%0"
    
    hence smp_mb__after_clear_bit() is defined as a simple compile barrier:
    
      #define smp_mb__after_clear_bit()       barrier()
    
    but the explicit TS_POLLING clearing introduced by the patch:
    
    +               current_thread_info()->status &= ~TS_POLLING;
    
    is not an atomic op! So the clearing of the TS_POLLING bit is freely
    reorderable with the reading of the NEED_RESCHED bit - and both now
    reside in different memory addresses.
    
    CPU idle wakeup very much depends on ordered memory ops, the clearing of
    the TS_POLLING flag must always be done before we test need_resched()
    and hit the idle instruction(s). [Symmetrically, the wakeup code needs
    to set NEED_RESCHED before it tests the TS_POLLING flag, so memory
    ordering is paramount.]
    
    Fernando's dual-core Athlon64 system has a sufficiently advanced memory
    ordering model so that it triggered this scenario very often.
    
    ( And it also turned out that the reason why these latencies never
      triggered on my testsystems is that i routinely use idle=poll, which
      was the only idle variant not affected by this bug. )
    
    The fix is to change the smp_mb__after_clear_bit() to an smp_mb(), to
    act as an absolute barrier between the TS_POLLING write and the
    NEED_RESCHED read. This affects almost all idling methods (default,
    ACPI, APM), on all 3 x86 architectures: i386, x86_64, ia64.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Tested-by: Fernando Lopez-Lezcano <nando@ccrma.Stanford.EDU>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 65b3f056ad89..6dac6050bb5a 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -211,7 +211,11 @@ acpi_processor_power_activate(struct acpi_processor *pr,
 static void acpi_safe_halt(void)
 {
 	current_thread_info()->status &= ~TS_POLLING;
-	smp_mb__after_clear_bit();
+	/*
+	 * TS_POLLING-cleared state must be visible before we
+	 * test NEED_RESCHED:
+	 */
+	smp_mb();
 	if (!need_resched())
 		safe_halt();
 	current_thread_info()->status |= TS_POLLING;
@@ -345,7 +349,11 @@ static void acpi_processor_idle(void)
 	 */
 	if (cx->type == ACPI_STATE_C2 || cx->type == ACPI_STATE_C3) {
 		current_thread_info()->status &= ~TS_POLLING;
-		smp_mb__after_clear_bit();
+		/*
+		 * TS_POLLING-cleared state must be visible before we
+		 * test NEED_RESCHED:
+		 */
+		smp_mb();
 		if (need_resched()) {
 			current_thread_info()->status |= TS_POLLING;
 			local_irq_enable();

commit cece901481bafbf14de8cbd3a89ae869ea881055
Merge: cfee47f99bc1 50dd096973f1
Author: Len Brown <len.brown@intel.com>
Date:   Sat Dec 16 01:04:27 2006 -0500

    Pull style into test branch
    
    Conflicts:
    
            drivers/acpi/button.c
            drivers/acpi/ec.c
            drivers/acpi/osl.c
            drivers/acpi/sbs.c

commit c5a114f1fb2d3c54be62779a705e088471063b47
Author: Darrick J. Wong <djwong@us.ibm.com>
Date:   Thu Oct 19 23:28:28 2006 -0700

    [PATCH] fix "ACPI: Processor native C-states using MWAIT"
    
    This patch breaks C-state discovery on my IBM IntelliStation Z30 because
    the return value of acpi_processor_get_power_info_fadt is not assigned to
    "result" in the case that acpi_processor_get_power_info_cst returns
    -ENODEV.  Thus, if ACPI provides C-state data via the FADT and not _CST (as
    is the case on this machine), we incorrectly exit the function with -ENODEV
    after reading the FADT.  The attached patch sets the value of result so
    that we don't exit early.
    
    Signed-off-by: Darrick J. Wong <djwong@us.ibm.com>
    Acked-by: "Pallipadi, Venkatesh" <venkatesh.pallipadi@intel.com>
    Acked-by: "Brown, Len" <len.brown@intel.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index e67144cf3c8b..65b3f056ad89 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -962,7 +962,7 @@ static int acpi_processor_get_power_info(struct acpi_processor *pr)
 
 	result = acpi_processor_get_power_info_cst(pr);
 	if (result == -ENODEV)
-		acpi_processor_get_power_info_fadt(pr);
+		result = acpi_processor_get_power_info_fadt(pr);
 
 	if (result)
 		return result;

commit 1fec74a9cda95772887c82ede5c0ac60f5be857e
Author: Andrew Morton <akpm@osdl.org>
Date:   Tue Oct 17 00:09:58 2006 -0700

    [PATCH] acpi_processor_latency_notifier(): UP warning fix
    
    drivers/acpi/processor_idle.c:1112: warning: 'smp_callback' defined but not used
    
    Cc: Len Brown <lenb@kernel.org>
    Cc: Arjan van de Ven <arjan@infradead.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 526387dc3799..e67144cf3c8b 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1108,6 +1108,7 @@ static const struct file_operations acpi_processor_power_fops = {
 	.release = single_release,
 };
 
+#ifdef CONFIG_SMP
 static void smp_callback(void *v)
 {
 	/* we already woke the CPU up, nothing more to do */
@@ -1129,6 +1130,7 @@ static int acpi_processor_latency_notify(struct notifier_block *b,
 static struct notifier_block acpi_processor_latency_notifier = {
 	.notifier_call = acpi_processor_latency_notify,
 };
+#endif
 
 int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 			      struct acpi_device *device)
@@ -1146,7 +1148,9 @@ int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 			       "ACPI: processor limited to max C-state %d\n",
 			       max_cstate);
 		first_run++;
+#ifdef CONFIG_SMP
 		register_latency_notifier(&acpi_processor_latency_notifier);
+#endif
 	}
 
 	if (!pr)
@@ -1218,7 +1222,9 @@ int acpi_processor_power_exit(struct acpi_processor *pr,
 		 * copies of pm_idle before proceeding.
 		 */
 		cpu_idle_wait();
+#ifdef CONFIG_SMP
 		unregister_latency_notifier(&acpi_processor_latency_notifier);
+#endif
 	}
 
 	return 0;

commit 9aaed2b42d00d4abb2748d72d599a8033600e2bf
Merge: 18d508bf5144 a790b323fb1b
Author: Len Brown <len.brown@intel.com>
Date:   Sat Oct 14 02:28:07 2006 -0400

    Pull trivial into test branch

commit 7af8b66004fa827958b4871112e59a07db5b3f6b
Author: Pierre Ossman <drzeus@drzeus.cx>
Date:   Tue Oct 10 14:20:31 2006 -0700

    ACPI: fix section for CPU init functions
    
    The ACPI processor init functions should be marked as __cpuinit as they use
    structures marked with __cpuinitdata.
    
    Signed-off-by: Pierre Ossman <drzeus@drzeus.cx>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 0a395fca843b..8537c429a02e 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1105,7 +1105,7 @@ static struct notifier_block acpi_processor_latency_notifier = {
 	.notifier_call = acpi_processor_latency_notify,
 };
 
-int acpi_processor_power_init(struct acpi_processor *pr,
+int __cpuinit acpi_processor_power_init(struct acpi_processor *pr,
 			      struct acpi_device *device)
 {
 	acpi_status status = 0;

commit 50dd096973f1d95aa03c6a6d9e148d706b62b68e
Author: Jan Engelhardt <jengelh@linux01.gwdg.de>
Date:   Sun Oct 1 00:28:50 2006 +0200

    ACPI: Remove unnecessary from/to-void* and to-void casts in drivers/acpi
    
    Signed-off-by: Jan Engelhardt <jengelh@gmx.de>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 0a395fca843b..4504684671f6 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -671,7 +671,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 		return -ENODEV;
 	}
 
-	cst = (union acpi_object *)buffer.pointer;
+	cst = buffer.pointer;
 
 	/* There must be at least 2 elements */
 	if (!cst || (cst->type != ACPI_TYPE_PACKAGE) || cst->package.count < 2) {
@@ -700,14 +700,14 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 
 		memset(&cx, 0, sizeof(cx));
 
-		element = (union acpi_object *)&(cst->package.elements[i]);
+		element = &(cst->package.elements[i]);
 		if (element->type != ACPI_TYPE_PACKAGE)
 			continue;
 
 		if (element->package.count != 4)
 			continue;
 
-		obj = (union acpi_object *)&(element->package.elements[0]);
+		obj = &(element->package.elements[0]);
 
 		if (obj->type != ACPI_TYPE_BUFFER)
 			continue;
@@ -722,7 +722,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 		    0 : reg->address;
 
 		/* There should be an easy way to extract an integer... */
-		obj = (union acpi_object *)&(element->package.elements[1]);
+		obj = &(element->package.elements[1]);
 		if (obj->type != ACPI_TYPE_INTEGER)
 			continue;
 
@@ -735,13 +735,13 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 		if ((cx.type < ACPI_STATE_C2) || (cx.type > ACPI_STATE_C3))
 			continue;
 
-		obj = (union acpi_object *)&(element->package.elements[2]);
+		obj = &(element->package.elements[2]);
 		if (obj->type != ACPI_TYPE_INTEGER)
 			continue;
 
 		cx.latency = obj->integer.value;
 
-		obj = (union acpi_object *)&(element->package.elements[3]);
+		obj = &(element->package.elements[3]);
 		if (obj->type != ACPI_TYPE_INTEGER)
 			continue;
 
@@ -1004,7 +1004,7 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 
 static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
 {
-	struct acpi_processor *pr = (struct acpi_processor *)seq->private;
+	struct acpi_processor *pr = seq->private;
 	unsigned int i;
 
 

commit 991528d7348667924176f3e29addea0675298944
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon Sep 25 16:28:13 2006 -0700

    ACPI: Processor native C-states using MWAIT
    
    Intel processors starting with the Core Duo support
    support processor native C-state using the MWAIT instruction.
    Refer: Intel Architecture Software Developer's Manual
    http://www.intel.com/design/Pentium4/manuals/253668.htm
    
    Platform firmware exports the support for Native C-state to OS using
    ACPI _PDC and _CST methods.
    Refer: Intel Processor Vendor-Specific ACPI: Interface Specification
    http://www.intel.com/technology/iapc/acpi/downloads/302223.htm
    
    With Processor Native C-state, we use 'MWAIT' instruction on the processor
    to enter different C-states (C1, C2, C3).  We won't use the special IO
    ports to enter C-state and no SMM mode etc required to enter C-state.
    Overall this will mean better C-state support.
    
    One major advantage of using MWAIT for all C-states is, with this and
    "treat interrupt as break event" feature of MWAIT, we can now get accurate
    timing for the time spent in C1, C2, ..  states.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 0a395fca843b..429a39dbd75d 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -219,6 +219,23 @@ static void acpi_safe_halt(void)
 
 static atomic_t c3_cpu_count;
 
+/* Common C-state entry for C2, C3, .. */
+static void acpi_cstate_enter(struct acpi_processor_cx *cstate)
+{
+	if (cstate->space_id == ACPI_CSTATE_FFH) {
+		/* Call into architectural FFH based C-state */
+		acpi_processor_ffh_cstate_enter(cstate);
+	} else {
+		int unused;
+		/* IO port based C-state */
+		inb(cstate->address);
+		/* Dummy wait op - must do something useless after P_LVL2 read
+		   because chipsets cannot guarantee that STPCLK# signal
+		   gets asserted in time to freeze execution properly. */
+		unused = inl(acpi_fadt.xpm_tmr_blk.address);
+	}
+}
+
 static void acpi_processor_idle(void)
 {
 	struct acpi_processor *pr = NULL;
@@ -361,11 +378,7 @@ static void acpi_processor_idle(void)
 		/* Get start time (ticks) */
 		t1 = inl(acpi_fadt.xpm_tmr_blk.address);
 		/* Invoke C2 */
-		inb(cx->address);
-		/* Dummy wait op - must do something useless after P_LVL2 read
-		   because chipsets cannot guarantee that STPCLK# signal
-		   gets asserted in time to freeze execution properly. */
-		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
+		acpi_cstate_enter(cx);
 		/* Get end time (ticks) */
 		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
 
@@ -401,9 +414,7 @@ static void acpi_processor_idle(void)
 		/* Get start time (ticks) */
 		t1 = inl(acpi_fadt.xpm_tmr_blk.address);
 		/* Invoke C3 */
-		inb(cx->address);
-		/* Dummy wait op (see above) */
-		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
+		acpi_cstate_enter(cx);
 		/* Get end time (ticks) */
 		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
 		if (pr->flags.bm_check) {
@@ -628,20 +639,16 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 	return 0;
 }
 
-static int acpi_processor_get_power_info_default_c1(struct acpi_processor *pr)
+static int acpi_processor_get_power_info_default(struct acpi_processor *pr)
 {
-
-	/* Zero initialize all the C-states info. */
-	memset(pr->power.states, 0, sizeof(pr->power.states));
-
-	/* set the first C-State to C1 */
-	pr->power.states[ACPI_STATE_C1].type = ACPI_STATE_C1;
-
-	/* the C0 state only exists as a filler in our array,
-	 * and all processors need to support C1 */
+	if (!pr->power.states[ACPI_STATE_C1].valid) {
+		/* set the first C-State to C1 */
+		/* all processors need to support C1 */
+		pr->power.states[ACPI_STATE_C1].type = ACPI_STATE_C1;
+		pr->power.states[ACPI_STATE_C1].valid = 1;
+	}
+	/* the C0 state only exists as a filler in our array */
 	pr->power.states[ACPI_STATE_C0].valid = 1;
-	pr->power.states[ACPI_STATE_C1].valid = 1;
-
 	return 0;
 }
 
@@ -658,12 +665,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 	if (nocst)
 		return -ENODEV;
 
-	current_count = 1;
-
-	/* Zero initialize C2 onwards and prepare for fresh CST lookup */
-	for (i = 2; i < ACPI_PROCESSOR_MAX_POWER; i++)
-		memset(&(pr->power.states[i]), 0, 
-				sizeof(struct acpi_processor_cx));
+	current_count = 0;
 
 	status = acpi_evaluate_object(pr->handle, "_CST", NULL, &buffer);
 	if (ACPI_FAILURE(status)) {
@@ -718,22 +720,39 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 		    (reg->space_id != ACPI_ADR_SPACE_FIXED_HARDWARE))
 			continue;
 
-		cx.address = (reg->space_id == ACPI_ADR_SPACE_FIXED_HARDWARE) ?
-		    0 : reg->address;
-
 		/* There should be an easy way to extract an integer... */
 		obj = (union acpi_object *)&(element->package.elements[1]);
 		if (obj->type != ACPI_TYPE_INTEGER)
 			continue;
 
 		cx.type = obj->integer.value;
-
-		if ((cx.type != ACPI_STATE_C1) &&
-		    (reg->space_id != ACPI_ADR_SPACE_SYSTEM_IO))
-			continue;
-
-		if ((cx.type < ACPI_STATE_C2) || (cx.type > ACPI_STATE_C3))
-			continue;
+		/*
+		 * Some buggy BIOSes won't list C1 in _CST -
+		 * Let acpi_processor_get_power_info_default() handle them later
+		 */
+		if (i == 1 && cx.type != ACPI_STATE_C1)
+			current_count++;
+
+		cx.address = reg->address;
+		cx.index = current_count + 1;
+
+		cx.space_id = ACPI_CSTATE_SYSTEMIO;
+		if (reg->space_id == ACPI_ADR_SPACE_FIXED_HARDWARE) {
+			if (acpi_processor_ffh_cstate_probe
+					(pr->id, &cx, reg) == 0) {
+				cx.space_id = ACPI_CSTATE_FFH;
+			} else if (cx.type != ACPI_STATE_C1) {
+				/*
+				 * C1 is a special case where FIXED_HARDWARE
+				 * can be handled in non-MWAIT way as well.
+				 * In that case, save this _CST entry info.
+				 * That is, we retain space_id of SYSTEM_IO for
+				 * halt based C1.
+				 * Otherwise, ignore this info and continue.
+				 */
+				continue;
+			}
+		}
 
 		obj = (union acpi_object *)&(element->package.elements[2]);
 		if (obj->type != ACPI_TYPE_INTEGER)
@@ -938,12 +957,18 @@ static int acpi_processor_get_power_info(struct acpi_processor *pr)
 	/* NOTE: the idle thread may not be running while calling
 	 * this function */
 
-	/* Adding C1 state */
-	acpi_processor_get_power_info_default_c1(pr);
+	/* Zero initialize all the C-states info. */
+	memset(pr->power.states, 0, sizeof(pr->power.states));
+
 	result = acpi_processor_get_power_info_cst(pr);
 	if (result == -ENODEV)
 		acpi_processor_get_power_info_fadt(pr);
 
+	if (result)
+		return result;
+
+	acpi_processor_get_power_info_default(pr);
+
 	pr->power.count = acpi_processor_power_verify(pr);
 
 	/*

commit 5c87579e65ee4f419b2369407f82326d38b5d2d8
Author: Arjan van de Ven <arjan@linux.intel.com>
Date:   Sat Sep 30 23:27:17 2006 -0700

    [PATCH] maximum latency tracking infrastructure
    
    Add infrastructure to track "maximum allowable latency" for power saving
    policies.
    
    The reason for adding this infrastructure is that power management in the
    idle loop needs to make a tradeoff between latency and power savings
    (deeper power save modes have a longer latency to running code again).  The
    code that today makes this tradeoff just does a rather simple algorithm;
    however this is not good enough: There are devices and use cases where a
    lower latency is required than that the higher power saving states provide.
     An example would be audio playback, but another example is the ipw2100
    wireless driver that right now has a very direct and ugly acpi hook to
    disable some higher power states randomly when it gets certain types of
    error.
    
    The proposed solution is to have an interface where drivers can
    
    * announce the maximum latency (in microseconds) that they can deal with
    * modify this latency
    * give up their constraint
    
    and a function where the code that decides on power saving strategy can
    query the current global desired maximum.
    
    This patch has a user of each side: on the consumer side, ACPI is patched
    to use this, on the producer side the ipw2100 driver is patched.
    
    A generic maximum latency is also registered of 2 timer ticks (more and you
    lose accurate time tracking after all).
    
    While the existing users of the patch are x86 specific, the infrastructure
    is not.  I'd like to ask the arch maintainers of other architectures if the
    infrastructure is generic enough for their use (assuming the architecture
    has such a tradeoff as concept at all), and the sound/multimedia driver
    owners to look at the driver facing API to see if this is something they
    can use.
    
    [akpm@osdl.org: cleanups]
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Jesse Barnes <jesse.barnes@intel.com>
    Cc: "Brown, Len" <len.brown@intel.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 71066066d626..0a395fca843b 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -38,6 +38,7 @@
 #include <linux/dmi.h>
 #include <linux/moduleparam.h>
 #include <linux/sched.h>	/* need_resched() */
+#include <linux/latency.h>
 
 #include <asm/io.h>
 #include <asm/uaccess.h>
@@ -453,7 +454,8 @@ static void acpi_processor_idle(void)
 	 */
 	if (cx->promotion.state &&
 	    ((cx->promotion.state - pr->power.states) <= max_cstate)) {
-		if (sleep_ticks > cx->promotion.threshold.ticks) {
+		if (sleep_ticks > cx->promotion.threshold.ticks &&
+		  cx->promotion.state->latency <= system_latency_constraint()) {
 			cx->promotion.count++;
 			cx->demotion.count = 0;
 			if (cx->promotion.count >=
@@ -494,8 +496,10 @@ static void acpi_processor_idle(void)
       end:
 	/*
 	 * Demote if current state exceeds max_cstate
+	 * or if the latency of the current state is unacceptable
 	 */
-	if ((pr->power.state - pr->power.states) > max_cstate) {
+	if ((pr->power.state - pr->power.states) > max_cstate ||
+		pr->power.state->latency > system_latency_constraint()) {
 		if (cx->demotion.state)
 			next_state = cx->demotion.state;
 	}
@@ -1009,9 +1013,11 @@ static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
 
 	seq_printf(seq, "active state:            C%zd\n"
 		   "max_cstate:              C%d\n"
-		   "bus master activity:     %08x\n",
+		   "bus master activity:     %08x\n"
+		   "maximum allowed latency: %d usec\n",
 		   pr->power.state ? pr->power.state - pr->power.states : 0,
-		   max_cstate, (unsigned)pr->power.bm_activity);
+		   max_cstate, (unsigned)pr->power.bm_activity,
+		   system_latency_constraint());
 
 	seq_puts(seq, "states:\n");
 
@@ -1077,6 +1083,28 @@ static const struct file_operations acpi_processor_power_fops = {
 	.release = single_release,
 };
 
+static void smp_callback(void *v)
+{
+	/* we already woke the CPU up, nothing more to do */
+}
+
+/*
+ * This function gets called when a part of the kernel has a new latency
+ * requirement.  This means we need to get all processors out of their C-state,
+ * and then recalculate a new suitable C-state. Just do a cross-cpu IPI; that
+ * wakes them all right up.
+ */
+static int acpi_processor_latency_notify(struct notifier_block *b,
+		unsigned long l, void *v)
+{
+	smp_call_function(smp_callback, NULL, 0, 1);
+	return NOTIFY_OK;
+}
+
+static struct notifier_block acpi_processor_latency_notifier = {
+	.notifier_call = acpi_processor_latency_notify,
+};
+
 int acpi_processor_power_init(struct acpi_processor *pr,
 			      struct acpi_device *device)
 {
@@ -1093,6 +1121,7 @@ int acpi_processor_power_init(struct acpi_processor *pr,
 			       "ACPI: processor limited to max C-state %d\n",
 			       max_cstate);
 		first_run++;
+		register_latency_notifier(&acpi_processor_latency_notifier);
 	}
 
 	if (!pr)
@@ -1164,6 +1193,7 @@ int acpi_processor_power_exit(struct acpi_processor *pr,
 		 * copies of pm_idle before proceeding.
 		 */
 		cpu_idle_wait();
+		unregister_latency_notifier(&acpi_processor_latency_notifier);
 	}
 
 	return 0;

commit d75080328affb4b268da430b7074cc8139cc662a
Author: Arjan van de Ven <arjan@infradead.org>
Date:   Tue Jul 4 13:06:00 2006 -0400

    ACPI: add 'const' to several ACPI file_operations
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 8e9c26aae8fe..71066066d626 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1070,7 +1070,7 @@ static int acpi_processor_power_open_fs(struct inode *inode, struct file *file)
 			   PDE(inode)->data);
 }
 
-static struct file_operations acpi_processor_power_fops = {
+static const struct file_operations acpi_processor_power_fops = {
 	.open = acpi_processor_power_open_fs,
 	.read = seq_read,
 	.llseek = seq_lseek,

commit 02438d8771ae6a4b215938959827692026380bf9
Author: Len Brown <len.brown@intel.com>
Date:   Fri Jun 30 03:19:10 2006 -0400

    ACPI: delete acpi_os_free(), use kfree() directly
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index e439eb77d283..8e9c26aae8fe 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -768,7 +768,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 		status = -EFAULT;
 
       end:
-	acpi_os_free(buffer.pointer);
+	kfree(buffer.pointer);
 
 	return status;
 }

commit f1b2ad5d2a8e1791d806ef244164d19c3d5c8b83
Merge: a51a69c0ed95 c4a001b1ea32
Author: Len Brown <len.brown@intel.com>
Date:   Thu Jun 29 15:58:09 2006 -0400

    Pull c-states into release branch

commit f831335d42a9aed26449a264266763fb542dbbe3
Author: Bartlomiej Swiercz <swierczu@dmcs.p.lodz.pl>
Date:   Mon May 29 07:16:00 2006 -0400

    ACPI: additional blacklist entry for ThinkPad R40e
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 5551bfbc47aa..2278b21b5eb8 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -97,6 +97,9 @@ static int set_max_cstate(struct dmi_system_id *id)
 /* Actually this shouldn't be __cpuinitdata, would be better to fix the
    callers to only run once -AK */
 static struct dmi_system_id __cpuinitdata processor_power_dmi_table[] = {
+	{ set_max_cstate, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET70WW")}, (void *)1},
 	{ set_max_cstate, "IBM ThinkPad R40e", {
 	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
 	  DMI_MATCH(DMI_BIOS_VERSION,"1SET60WW")}, (void *)1},

commit b488f02156d3deb08f5ad7816d565c370a8cc6f1
Author: Andreas Mohr <[andi@rhlx01.fht-esslingen.de]>
Date:   Mon Jun 26 15:58:00 2006 -0400

    ACPI: restore comment justifying 'extra' P_LVLx access
    
    While trying to look for superfluous I/O accesses that can be optimized
    away, I stumbled upon this ACPI sleep I/O access and couldn't figure out
    why the hell this dummy op was necessary.
    After more than one hour of internet research, I had collected a sufficient
    number of documents (among those very old kernel versions) that finally
    told me what this dummy read was about: STPCLK# doesn't get asserted in time
    on (some) chipsets, which is why we need to have a dummy I/O read to delay
    further instruction processing until the CPU is fully stopped.
    
    Signed-off-by: Andreas Mohr <andi@lisas.de>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 89d3fd4c3cd2..5551bfbc47aa 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -365,7 +365,9 @@ static void acpi_processor_idle(void)
 		t1 = inl(acpi_fadt.xpm_tmr_blk.address);
 		/* Invoke C2 */
 		inb(cx->address);
-		/* Dummy op - must do something useless after P_LVL2 read */
+		/* Dummy wait op - must do something useless after P_LVL2 read
+		   because chipsets cannot guarantee that STPCLK# signal
+		   gets asserted in time to freeze execution properly. */
 		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
 		/* Get end time (ticks) */
 		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
@@ -403,7 +405,7 @@ static void acpi_processor_idle(void)
 		t1 = inl(acpi_fadt.xpm_tmr_blk.address);
 		/* Invoke C3 */
 		inb(cx->address);
-		/* Dummy op - must do something useless after P_LVL3 read */
+		/* Dummy wait op (see above) */
 		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
 		/* Get end time (ticks) */
 		t2 = inl(acpi_fadt.xpm_tmr_blk.address);

commit c4a001b1ea32e09f7556178249b8885418858b5c
Author: Dominik Brodowski <linux@dominikbrodowski.net>
Date:   Sat Jun 24 19:37:00 2006 -0400

    ACPI: C-States: only demote on current bus mastering activity
    
    Only if bus master activity is going on at the present, we should avoid
    entering C3-type sleep, as it might be a faulty transition.  As long as the
    bm_activity bitmask was based on the number of calls to the ACPI idle
    function, looking at previous moments made sense.  Now, with it being based on
    what happened this jiffy, looking at this jiffy should be sufficient.
    
    Signed-off-by: Dominik Brodowski <linux@dominikbrodowski.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index af9f2afd72da..f8d2b2f47fd4 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -287,10 +287,10 @@ static void acpi_processor_idle(void)
 		pr->power.bm_check_timestamp = jiffies;
 
 		/*
-		 * Apply bus mastering demotion policy.  Automatically demote
+		 * If bus mastering is or was active this jiffy, demote
 		 * to avoid a faulty transition.  Note that the processor
 		 * won't enter a low-power state during this call (to this
-		 * funciton) but should upon the next.
+		 * function) but should upon the next.
 		 *
 		 * TBD: A better policy might be to fallback to the demotion
 		 *      state (use it for this quantum only) istead of
@@ -298,7 +298,8 @@ static void acpi_processor_idle(void)
 		 *      qualification.  This may, however, introduce DMA
 		 *      issues (e.g. floppy DMA transfer overrun/underrun).
 		 */
-		if (pr->power.bm_activity & cx->demotion.threshold.bm) {
+		if ((pr->power.bm_activity & 0x1) &&
+		    cx->demotion.threshold.bm) {
 			local_irq_enable();
 			next_state = cx->demotion.state;
 			goto end;

commit c5ab81ca01ad4a8870b456f93dd2fb3d815f91d9
Author: Dominik Brodowski <linux@dominikbrodowski.net>
Date:   Sat Jun 24 19:37:00 2006 -0400

    ACPI: C-States: bm_activity improvements
    
    Do not assume there was bus mastering activity if the idle handler didn't get
    called, as there's only reason to not enter C3-type sleep if there is bus
    master activity going on.  Only for the "promotion" into C3-type sleep bus
    mastering activity is taken into account, and there only current bus mastering
    activity, and not pure guessing should lead to the decision on whether to
    enter C3-type sleep or not.
    
    Also, as bm_activity is a jiffy-based bitmask (bit 0: bus mastering activity
    during this juffy, bit 31: bus mastering activity 31 jiffies ago), fix the
    setting of bit 0, as it might be called multiple times within one jiffy.
    
    Signed-off-by: Dominik Brodowski <linux@dominikbrodowski.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 6d1e238e2375..af9f2afd72da 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -3,7 +3,7 @@
  *
  *  Copyright (C) 2001, 2002 Andy Grover <andrew.grover@intel.com>
  *  Copyright (C) 2001, 2002 Paul Diefenbaugh <paul.s.diefenbaugh@intel.com>
- *  Copyright (C) 2004       Dominik Brodowski <linux@brodo.de>
+ *  Copyright (C) 2004, 2005 Dominik Brodowski <linux@brodo.de>
  *  Copyright (C) 2004  Anil S Keshavamurthy <anil.s.keshavamurthy@intel.com>
  *  			- Added processor hotplug support
  *  Copyright (C) 2005  Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
@@ -261,21 +261,15 @@ static void acpi_processor_idle(void)
 		u32 bm_status = 0;
 		unsigned long diff = jiffies - pr->power.bm_check_timestamp;
 
-		if (diff > 32)
-			diff = 32;
+		if (diff > 31)
+			diff = 31;
 
-		while (diff) {
-			/* if we didn't get called, assume there was busmaster activity */
-			diff--;
-			if (diff)
-				pr->power.bm_activity |= 0x1;
-			pr->power.bm_activity <<= 1;
-		}
+		pr->power.bm_activity <<= diff;
 
 		acpi_get_register(ACPI_BITREG_BUS_MASTER_STATUS,
 				  &bm_status, ACPI_MTX_DO_NOT_LOCK);
 		if (bm_status) {
-			pr->power.bm_activity++;
+			pr->power.bm_activity |= 0x1;
 			acpi_set_register(ACPI_BITREG_BUS_MASTER_STATUS,
 					  1, ACPI_MTX_DO_NOT_LOCK);
 		}
@@ -287,7 +281,7 @@ static void acpi_processor_idle(void)
 		else if (errata.piix4.bmisx) {
 			if ((inb_p(errata.piix4.bmisx + 0x02) & 0x01)
 			    || (inb_p(errata.piix4.bmisx + 0x0A) & 0x01))
-				pr->power.bm_activity++;
+				pr->power.bm_activity |= 0x1;
 		}
 
 		pr->power.bm_check_timestamp = jiffies;

commit a3c6598f92cf27d3d201a2a5b052563148156837
Author: Dominik Brodowski <linux@dominikbrodowski.net>
Date:   Sat Jun 24 19:37:00 2006 -0400

    ACPI: C-States: accounting of sleep states
    
    Track the actual time spent in C-States (C2 upwards, we can't determine this
    for C1), not only the number of invocations.  This is especially useful for
    dynamic ticks / "tickless systems", but is also of interest on normal systems,
    as any interrupt activity leads to C-States being exited, not only the timer
    interrupt.
    
    The time is being measured in PM timer ticks, so an increase by one equals 279
    nanoseconds.
    
    Signed-off-by: Dominik Brodowski <linux@dominikbrodowski.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 89d3fd4c3cd2..6d1e238e2375 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -322,8 +322,6 @@ static void acpi_processor_idle(void)
 		cx = &pr->power.states[ACPI_STATE_C1];
 #endif
 
-	cx->usage++;
-
 	/*
 	 * Sleep:
 	 * ------
@@ -430,6 +428,9 @@ static void acpi_processor_idle(void)
 		local_irq_enable();
 		return;
 	}
+	cx->usage++;
+	if ((cx->type != ACPI_STATE_C1) && (sleep_ticks > 0))
+		cx->time += sleep_ticks;
 
 	next_state = pr->power.state;
 
@@ -1053,9 +1054,10 @@ static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
 		else
 			seq_puts(seq, "demotion[--] ");
 
-		seq_printf(seq, "latency[%03d] usage[%08d]\n",
+		seq_printf(seq, "latency[%03d] usage[%08d] duration[%020llu]\n",
 			   pr->power.states[i].latency,
-			   pr->power.states[i].usage);
+			   pr->power.states[i].usage,
+			   pr->power.states[i].time);
 	}
 
       end:

commit d550d98d3317378d93a4869db204725d270ec812
Author: Patrick Mochel <mochel@linux.intel.com>
Date:   Tue Jun 27 00:41:40 2006 -0400

    ACPI: delete tracing macros from drivers/acpi/*.c
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 786851da85c6..89d3fd4c3cd2 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -517,10 +517,9 @@ static int acpi_processor_set_power_policy(struct acpi_processor *pr)
 	struct acpi_processor_cx *higher = NULL;
 	struct acpi_processor_cx *cx;
 
-	ACPI_FUNCTION_TRACE("acpi_processor_set_power_policy");
 
 	if (!pr)
-		return_VALUE(-EINVAL);
+		return -EINVAL;
 
 	/*
 	 * This function sets the default Cx state policy (OS idle handler).
@@ -544,7 +543,7 @@ static int acpi_processor_set_power_policy(struct acpi_processor *pr)
 	}
 
 	if (!state_is_set)
-		return_VALUE(-ENODEV);
+		return -ENODEV;
 
 	/* demotion */
 	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
@@ -583,18 +582,17 @@ static int acpi_processor_set_power_policy(struct acpi_processor *pr)
 		higher = cx;
 	}
 
-	return_VALUE(0);
+	return 0;
 }
 
 static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 {
-	ACPI_FUNCTION_TRACE("acpi_processor_get_power_info_fadt");
 
 	if (!pr)
-		return_VALUE(-EINVAL);
+		return -EINVAL;
 
 	if (!pr->pblk)
-		return_VALUE(-ENODEV);
+		return -ENODEV;
 
 	/* if info is obtained from pblk/fadt, type equals state */
 	pr->power.states[ACPI_STATE_C2].type = ACPI_STATE_C2;
@@ -606,7 +604,7 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 	 * an SMP system. 
 	 */
 	if ((num_online_cpus() > 1) && !acpi_fadt.plvl2_up)
-		return_VALUE(-ENODEV);
+		return -ENODEV;
 #endif
 
 	/* determine C2 and C3 address from pblk */
@@ -622,12 +620,11 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 			  pr->power.states[ACPI_STATE_C2].address,
 			  pr->power.states[ACPI_STATE_C3].address));
 
-	return_VALUE(0);
+	return 0;
 }
 
 static int acpi_processor_get_power_info_default_c1(struct acpi_processor *pr)
 {
-	ACPI_FUNCTION_TRACE("acpi_processor_get_power_info_default_c1");
 
 	/* Zero initialize all the C-states info. */
 	memset(pr->power.states, 0, sizeof(pr->power.states));
@@ -640,7 +637,7 @@ static int acpi_processor_get_power_info_default_c1(struct acpi_processor *pr)
 	pr->power.states[ACPI_STATE_C0].valid = 1;
 	pr->power.states[ACPI_STATE_C1].valid = 1;
 
-	return_VALUE(0);
+	return 0;
 }
 
 static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
@@ -652,10 +649,9 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 	struct acpi_buffer buffer = { ACPI_ALLOCATE_BUFFER, NULL };
 	union acpi_object *cst;
 
-	ACPI_FUNCTION_TRACE("acpi_processor_get_power_info_cst");
 
 	if (nocst)
-		return_VALUE(-ENODEV);
+		return -ENODEV;
 
 	current_count = 1;
 
@@ -667,7 +663,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 	status = acpi_evaluate_object(pr->handle, "_CST", NULL, &buffer);
 	if (ACPI_FAILURE(status)) {
 		ACPI_DEBUG_PRINT((ACPI_DB_INFO, "No _CST, giving up\n"));
-		return_VALUE(-ENODEV);
+		return -ENODEV;
 	}
 
 	cst = (union acpi_object *)buffer.pointer;
@@ -773,15 +769,14 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
       end:
 	acpi_os_free(buffer.pointer);
 
-	return_VALUE(status);
+	return status;
 }
 
 static void acpi_processor_power_verify_c2(struct acpi_processor_cx *cx)
 {
-	ACPI_FUNCTION_TRACE("acpi_processor_get_power_verify_c2");
 
 	if (!cx->address)
-		return_VOID;
+		return;
 
 	/*
 	 * C2 latency must be less than or equal to 100
@@ -790,7 +785,7 @@ static void acpi_processor_power_verify_c2(struct acpi_processor_cx *cx)
 	else if (cx->latency > ACPI_PROCESSOR_MAX_C2_LATENCY) {
 		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
 				  "latency too large [%d]\n", cx->latency));
-		return_VOID;
+		return;
 	}
 
 	/*
@@ -800,7 +795,7 @@ static void acpi_processor_power_verify_c2(struct acpi_processor_cx *cx)
 	cx->valid = 1;
 	cx->latency_ticks = US_TO_PM_TIMER_TICKS(cx->latency);
 
-	return_VOID;
+	return;
 }
 
 static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
@@ -808,10 +803,9 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 {
 	static int bm_check_flag;
 
-	ACPI_FUNCTION_TRACE("acpi_processor_get_power_verify_c3");
 
 	if (!cx->address)
-		return_VOID;
+		return;
 
 	/*
 	 * C3 latency must be less than or equal to 1000
@@ -820,7 +814,7 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 	else if (cx->latency > ACPI_PROCESSOR_MAX_C3_LATENCY) {
 		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
 				  "latency too large [%d]\n", cx->latency));
-		return_VOID;
+		return;
 	}
 
 	/*
@@ -833,7 +827,7 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 	else if (errata.piix4.fdma) {
 		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
 				  "C3 not supported on PIIX4 with Type-F DMA\n"));
-		return_VOID;
+		return;
 	}
 
 	/* All the logic here assumes flags.bm_check is same across all CPUs */
@@ -850,7 +844,7 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 		if (!pr->flags.bm_control) {
 			ACPI_DEBUG_PRINT((ACPI_DB_INFO,
 					  "C3 support requires bus mastering control\n"));
-			return_VOID;
+			return;
 		}
 	} else {
 		/*
@@ -861,7 +855,7 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 			ACPI_DEBUG_PRINT((ACPI_DB_INFO,
 					  "Cache invalidation should work properly"
 					  " for C3 to be enabled on SMP systems\n"));
-			return_VOID;
+			return;
 		}
 		acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD,
 				  0, ACPI_MTX_DO_NOT_LOCK);
@@ -876,7 +870,7 @@ static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
 	cx->valid = 1;
 	cx->latency_ticks = US_TO_PM_TIMER_TICKS(cx->latency);
 
-	return_VOID;
+	return;
 }
 
 static int acpi_processor_power_verify(struct acpi_processor *pr)
@@ -935,7 +929,6 @@ static int acpi_processor_get_power_info(struct acpi_processor *pr)
 	unsigned int i;
 	int result;
 
-	ACPI_FUNCTION_TRACE("acpi_processor_get_power_info");
 
 	/* NOTE: the idle thread may not be running while calling
 	 * this function */
@@ -958,7 +951,7 @@ static int acpi_processor_get_power_info(struct acpi_processor *pr)
 	 */
 	result = acpi_processor_set_power_policy(pr);
 	if (result)
-		return_VALUE(result);
+		return result;
 
 	/*
 	 * if one state of type C2 or C3 is available, mark this
@@ -972,24 +965,23 @@ static int acpi_processor_get_power_info(struct acpi_processor *pr)
 		}
 	}
 
-	return_VALUE(0);
+	return 0;
 }
 
 int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 {
 	int result = 0;
 
-	ACPI_FUNCTION_TRACE("acpi_processor_cst_has_changed");
 
 	if (!pr)
-		return_VALUE(-EINVAL);
+		return -EINVAL;
 
 	if (nocst) {
-		return_VALUE(-ENODEV);
+		return -ENODEV;
 	}
 
 	if (!pr->flags.power_setup_done)
-		return_VALUE(-ENODEV);
+		return -ENODEV;
 
 	/* Fall back to the default idle loop */
 	pm_idle = pm_idle_save;
@@ -1000,7 +992,7 @@ int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 	if ((pr->flags.power == 1) && (pr->flags.power_setup_done))
 		pm_idle = acpi_processor_idle;
 
-	return_VALUE(result);
+	return result;
 }
 
 /* proc interface */
@@ -1010,7 +1002,6 @@ static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
 	struct acpi_processor *pr = (struct acpi_processor *)seq->private;
 	unsigned int i;
 
-	ACPI_FUNCTION_TRACE("acpi_processor_power_seq_show");
 
 	if (!pr)
 		goto end;
@@ -1068,7 +1059,7 @@ static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
 	}
 
       end:
-	return_VALUE(0);
+	return 0;
 }
 
 static int acpi_processor_power_open_fs(struct inode *inode, struct file *file)
@@ -1092,7 +1083,6 @@ int acpi_processor_power_init(struct acpi_processor *pr,
 	struct proc_dir_entry *entry = NULL;
 	unsigned int i;
 
-	ACPI_FUNCTION_TRACE("acpi_processor_power_init");
 
 	if (!first_run) {
 		dmi_check_system(processor_power_dmi_table);
@@ -1104,7 +1094,7 @@ int acpi_processor_power_init(struct acpi_processor *pr,
 	}
 
 	if (!pr)
-		return_VALUE(-EINVAL);
+		return -EINVAL;
 
 	if (acpi_fadt.cst_cnt && !nocst) {
 		status =
@@ -1149,13 +1139,12 @@ int acpi_processor_power_init(struct acpi_processor *pr,
 
 	pr->flags.power_setup_done = 1;
 
-	return_VALUE(0);
+	return 0;
 }
 
 int acpi_processor_power_exit(struct acpi_processor *pr,
 			      struct acpi_device *device)
 {
-	ACPI_FUNCTION_TRACE("acpi_processor_power_exit");
 
 	pr->flags.power_setup_done = 0;
 
@@ -1175,5 +1164,5 @@ int acpi_processor_power_exit(struct acpi_processor *pr,
 		cpu_idle_wait();
 	}
 
-	return_VALUE(0);
+	return 0;
 }

commit 6468463abd7051fcc29f3ee7c931f9bbbb26f5a4
Author: Len Brown <len.brown@intel.com>
Date:   Mon Jun 26 23:41:38 2006 -0400

    ACPI: un-export ACPI_ERROR() -- use printk(KERN_ERR...)
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 52ada5322447..786851da85c6 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -674,7 +674,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 
 	/* There must be at least 2 elements */
 	if (!cst || (cst->type != ACPI_TYPE_PACKAGE) || cst->package.count < 2) {
-		ACPI_ERROR((AE_INFO, "not enough elements in _CST"));
+		printk(KERN_ERR PREFIX "not enough elements in _CST\n");
 		status = -EFAULT;
 		goto end;
 	}
@@ -683,7 +683,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 
 	/* Validate number of power states. */
 	if (count < 1 || count != cst->package.count - 1) {
-		ACPI_ERROR((AE_INFO, "count given by _CST is not valid"));
+		printk(KERN_ERR PREFIX "count given by _CST is not valid\n");
 		status = -EFAULT;
 		goto end;
 	}

commit a6fc67202e0224e6c9d1d285cc0b444bce887ed5
Author: Thomas Renninger <trenn@suse.de>
Date:   Mon Jun 26 23:58:43 2006 -0400

    ACPI: Enable ACPI error messages w/o CONFIG_ACPI_DEBUG
    
    Signed-off-by: Thomas Renninger <trenn@suse.de>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 8a74bf3efd8e..52ada5322447 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -674,8 +674,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 
 	/* There must be at least 2 elements */
 	if (!cst || (cst->type != ACPI_TYPE_PACKAGE) || cst->package.count < 2) {
-		ACPI_DEBUG_PRINT((ACPI_DB_ERROR,
-				  "not enough elements in _CST\n"));
+		ACPI_ERROR((AE_INFO, "not enough elements in _CST"));
 		status = -EFAULT;
 		goto end;
 	}
@@ -684,8 +683,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 
 	/* Validate number of power states. */
 	if (count < 1 || count != cst->package.count - 1) {
-		ACPI_DEBUG_PRINT((ACPI_DB_ERROR,
-				  "count given by _CST is not valid\n"));
+		ACPI_ERROR((AE_INFO, "count given by _CST is not valid"));
 		status = -EFAULT;
 		goto end;
 	}
@@ -1112,8 +1110,8 @@ int acpi_processor_power_init(struct acpi_processor *pr,
 		status =
 		    acpi_os_write_port(acpi_fadt.smi_cmd, acpi_fadt.cst_cnt, 8);
 		if (ACPI_FAILURE(status)) {
-			ACPI_DEBUG_PRINT((ACPI_DB_ERROR,
-					  "Notifying BIOS of _CST ability failed\n"));
+			ACPI_EXCEPTION((AE_INFO, status,
+					"Notifying BIOS of _CST ability failed"));
 		}
 	}
 
@@ -1142,9 +1140,7 @@ int acpi_processor_power_init(struct acpi_processor *pr,
 	entry = create_proc_entry(ACPI_PROCESSOR_FILE_POWER,
 				  S_IRUGO, acpi_device_dir(device));
 	if (!entry)
-		ACPI_DEBUG_PRINT((ACPI_DB_ERROR,
-				  "Unable to create '%s' fs entry\n",
-				  ACPI_PROCESSOR_FILE_POWER));
+		return -EIO;
 	else {
 		entry->proc_fops = &acpi_processor_power_fops;
 		entry->data = acpi_driver_data(device);

commit 81a07d7588d376c530d006e24d7981304ce96e16
Merge: 8871e73fdbde 8501a2fbe762
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Mon Jun 26 10:51:09 2006 -0700

    Merge branch 'x86-64'
    
    * x86-64: (83 commits)
      [PATCH] x86_64: x86_64 stack usage debugging
      [PATCH] x86_64: (resend) x86_64 stack overflow debugging
      [PATCH] x86_64: msi_apic.c build fix
      [PATCH] x86_64: i386/x86-64 Add nmi watchdog support for new Intel CPUs
      [PATCH] x86_64: Avoid broadcasting NMI IPIs
      [PATCH] x86_64: fix apic error on bootup
      [PATCH] x86_64: enlarge window for stack growth
      [PATCH] x86_64: Minor string functions optimizations
      [PATCH] x86_64: Move export symbols to their C functions
      [PATCH] x86_64: Standardize i386/x86_64 handling of NMI_VECTOR
      [PATCH] x86_64: Fix modular pc speaker
      [PATCH] x86_64: remove sys32_ni_syscall()
      [PATCH] x86_64: Do not use -ffunction-sections for modules
      [PATCH] x86_64: Add cpu_relax to apic_wait_icr_idle
      [PATCH] x86_64: adjust kstack_depth_to_print default
      [PATCH] i386/x86-64: adjust /proc/interrupts column headings
      [PATCH] x86_64: Fix race in cpu_local_* on preemptible kernels
      [PATCH] x86_64: Fix fast check in safe_smp_processor_id
      [PATCH] x86_64: x86_64 setup.c - printing cmp related boottime information
      [PATCH] i386/x86-64/ia64: Move polling flag into thread_info_status
      ...
    
    Manual resolve of trivial conflict in arch/i386/kernel/Makefile

commit 495ab9c045e1b0e5c82951b762257fe1c9d81564
Author: Andi Kleen <ak@suse.de>
Date:   Mon Jun 26 13:59:11 2006 +0200

    [PATCH] i386/x86-64/ia64: Move polling flag into thread_info_status
    
    During some profiling I noticed that default_idle causes a lot of
    memory traffic. I think that is caused by the atomic operations
    to clear/set the polling flag in thread_info. There is actually
    no reason to make this atomic - only the idle thread does it
    to itself, other CPUs only read it. So I moved it into ti->status.
    
    Converted i386/x86-64/ia64 for now because that was the easiest
    way to fix ACPI which also manipulates these flags in its idle
    function.
    
    Cc: Nick Piggin <npiggin@novell.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Len Brown <len.brown@intel.com>
    Signed-off-by: Andi Kleen <ak@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 3b97a5eae9e8..74173ce6aaf4 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -206,11 +206,11 @@ acpi_processor_power_activate(struct acpi_processor *pr,
 
 static void acpi_safe_halt(void)
 {
-	clear_thread_flag(TIF_POLLING_NRFLAG);
+	current_thread_info()->status &= ~TS_POLLING;
 	smp_mb__after_clear_bit();
 	if (!need_resched())
 		safe_halt();
-	set_thread_flag(TIF_POLLING_NRFLAG);
+	current_thread_info()->status |= TS_POLLING;
 }
 
 static atomic_t c3_cpu_count;
@@ -330,10 +330,10 @@ static void acpi_processor_idle(void)
 	 * Invoke the current Cx state to put the processor to sleep.
 	 */
 	if (cx->type == ACPI_STATE_C2 || cx->type == ACPI_STATE_C3) {
-		clear_thread_flag(TIF_POLLING_NRFLAG);
+		current_thread_info()->status &= ~TS_POLLING;
 		smp_mb__after_clear_bit();
 		if (need_resched()) {
-			set_thread_flag(TIF_POLLING_NRFLAG);
+			current_thread_info()->status |= TS_POLLING;
 			local_irq_enable();
 			return;
 		}
@@ -371,7 +371,7 @@ static void acpi_processor_idle(void)
 		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
 		/* Re-enable interrupts */
 		local_irq_enable();
-		set_thread_flag(TIF_POLLING_NRFLAG);
+		current_thread_info()->status |= TS_POLLING;
 		/* Compute time (ticks) that we were actually asleep */
 		sleep_ticks =
 		    ticks_elapsed(t1, t2) - cx->latency_ticks - C2_OVERHEAD;
@@ -411,7 +411,7 @@ static void acpi_processor_idle(void)
 
 		/* Re-enable interrupts */
 		local_irq_enable();
-		set_thread_flag(TIF_POLLING_NRFLAG);
+		current_thread_info()->status |= TS_POLLING;
 		/* Compute time (ticks) that we were actually asleep */
 		sleep_ticks =
 		    ticks_elapsed(t1, t2) - cx->latency_ticks - C3_OVERHEAD;

commit 539eb11e6e904f2cd4f62908cc5e44d724879721
Author: john stultz <johnstul@us.ibm.com>
Date:   Mon Jun 26 00:25:10 2006 -0700

    [PATCH] Time: i386 Conversion - part 2: Rework TSC Support
    
    As part of the i386 conversion to the generic timekeeping infrastructure, this
    introduces a new tsc.c file.  The code in this file replaces the TSC
    initialization, management and access code currently in timer_tsc.c (which
    will be removed) that we want to preserve.
    
    The code also introduces the following functionality:
    
    o tsc_khz: like cpu_khz but stores the TSC frequency on systems that do not
      change TSC frequency w/ CPU frequency
    
    o check/mark_tsc_unstable: accessor/modifier flag for TSC timekeeping
      usability
    
    o minor cleanups to calibration math.
    
    This patch also includes a one line __cpuinitdata fix from Zwane Mwaikambo.
    
    Signed-off-by: John Stultz <johnstul@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 3b97a5eae9e8..a5f4f2aa007a 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -369,6 +369,11 @@ static void acpi_processor_idle(void)
 		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
 		/* Get end time (ticks) */
 		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
+
+#ifdef CONFIG_GENERIC_TIME
+		/* TSC halts in C2, so notify users */
+		mark_tsc_unstable();
+#endif
 		/* Re-enable interrupts */
 		local_irq_enable();
 		set_thread_flag(TIF_POLLING_NRFLAG);
@@ -409,6 +414,10 @@ static void acpi_processor_idle(void)
 					  ACPI_MTX_DO_NOT_LOCK);
 		}
 
+#ifdef CONFIG_GENERIC_TIME
+		/* TSC halts in C3, so notify users */
+		mark_tsc_unstable();
+#endif
 		/* Re-enable interrupts */
 		local_irq_enable();
 		set_thread_flag(TIF_POLLING_NRFLAG);

commit b6835052a6aa00536343b6d2127fc65cd814a040
Author: Andreas Mohr <andi@rhlx01.fht-esslingen.de>
Date:   Thu Apr 27 05:25:00 2006 -0400

    ACPI: apply "__read_mostly" to processor_idle.c loop module parameters and friends
    
    make pm_idle_save, nocst and bm_history __read_mostly
    remove initializer from static 'first_run'.
    
    Signed-off-by: Andreas Mohr <andi@lisas.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 80fa43471f48..3b97a5eae9e8 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -54,10 +54,10 @@ ACPI_MODULE_NAME("acpi_processor")
 #define US_TO_PM_TIMER_TICKS(t)		((t * (PM_TIMER_FREQUENCY/1000)) / 1000)
 #define C2_OVERHEAD			4	/* 1us (3.579 ticks per us) */
 #define C3_OVERHEAD			4	/* 1us (3.579 ticks per us) */
-static void (*pm_idle_save) (void);
+static void (*pm_idle_save) (void) __read_mostly;
 module_param(max_cstate, uint, 0644);
 
-static unsigned int nocst = 0;
+static unsigned int nocst __read_mostly;
 module_param(nocst, uint, 0000);
 
 /*
@@ -67,7 +67,7 @@ module_param(nocst, uint, 0000);
  * 100 HZ: 0x0000000F: 4 jiffies = 40ms
  * reduce history for more aggressive entry into C3
  */
-static unsigned int bm_history =
+static unsigned int bm_history __read_mostly =
     (HZ >= 800 ? 0xFFFFFFFF : ((1U << (HZ / 25)) - 1));
 module_param(bm_history, uint, 0644);
 /* --------------------------------------------------------------------------
@@ -1081,7 +1081,7 @@ int acpi_processor_power_init(struct acpi_processor *pr,
 			      struct acpi_device *device)
 {
 	acpi_status status = 0;
-	static int first_run = 0;
+	static int first_run;
 	struct proc_dir_entry *entry = NULL;
 	unsigned int i;
 

commit 0b5c59a1e41636afa77b90d34e8c394d8d929733
Author: Andi Kleen <ak@suse.de>
Date:   Sun Mar 26 02:24:07 2006 +0100

    [PATCH] Fix compilation of processor_idle.c on IA64
    
    Broken earlier by me by a x86-64 patch.
    
    The code was optimized away, but the compiler still complained about an
    undeclared function.
    
    Signed-off-by: Andi Kleen <ak@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 2be895895943..80fa43471f48 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -876,10 +876,10 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 {
 	unsigned int i;
 	unsigned int working = 0;
-	int timer_broadcast = 0;
-	cpumask_t mask = cpumask_of_cpu(pr->id);
 
 #ifdef ARCH_APICTIMER_STOPS_ON_C3
+	int timer_broadcast = 0;
+	cpumask_t mask = cpumask_of_cpu(pr->id);
 	on_each_cpu(switch_ipi_to_APIC_timer, &mask, 1, 1);
 #endif
 
@@ -915,8 +915,10 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 			working++;
 	}
 
+#ifdef ARCH_APICTIMER_STOPS_ON_C3
 	if (timer_broadcast)
 		on_each_cpu(switch_APIC_timer_to_ipi, &mask, 1, 1);
+#endif
 
 	return (working);
 }

commit bd6633476922b7b51227f7f704c2546e763ae5ed
Author: Andi Kleen <ak@suse.de>
Date:   Sat Mar 25 16:31:07 2006 +0100

    [PATCH] x86_64: Force broadcast timer on AMD systems with C3 too.
    
    Signed-off-by: Andi Kleen <ak@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index eb730a80952c..2be895895943 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -876,14 +876,11 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 {
 	unsigned int i;
 	unsigned int working = 0;
-
-#ifdef ARCH_APICTIMER_STOPS_ON_C3
-	struct cpuinfo_x86 *c = cpu_data + pr->id;
+	int timer_broadcast = 0;
 	cpumask_t mask = cpumask_of_cpu(pr->id);
 
-	if (c->x86_vendor == X86_VENDOR_INTEL) {
-		on_each_cpu(switch_ipi_to_APIC_timer, &mask, 1, 1);
-	}
+#ifdef ARCH_APICTIMER_STOPS_ON_C3
+	on_each_cpu(switch_ipi_to_APIC_timer, &mask, 1, 1);
 #endif
 
 	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
@@ -896,15 +893,20 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 
 		case ACPI_STATE_C2:
 			acpi_processor_power_verify_c2(cx);
+#ifdef ARCH_APICTIMER_STOPS_ON_C3
+			/* Some AMD systems fake C3 as C2, but still
+			   have timer troubles */
+			if (cx->valid && 
+				boot_cpu_data.x86_vendor == X86_VENDOR_AMD)
+				timer_broadcast++;
+#endif
 			break;
 
 		case ACPI_STATE_C3:
 			acpi_processor_power_verify_c3(pr, cx);
 #ifdef ARCH_APICTIMER_STOPS_ON_C3
-			if (cx->valid && c->x86_vendor == X86_VENDOR_INTEL) {
-				on_each_cpu(switch_APIC_timer_to_ipi,
-						&mask, 1, 1);
-			}
+			if (cx->valid)
+				timer_broadcast++;
 #endif
 			break;
 		}
@@ -913,6 +915,9 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 			working++;
 	}
 
+	if (timer_broadcast)
+		on_each_cpu(switch_APIC_timer_to_ipi, &mask, 1, 1);
+
 	return (working);
 }
 

commit 7ded56895c11a656408b6ff21086ae04a6a7cda0
Author: Ashok Raj <Ashok.Raj@intel.com>
Date:   Fri Feb 3 21:51:23 2006 +0100

    [PATCH] x86_64: data/functions wrongly marked as __init with cpu hotplug.
    
    attached patch is 2 more cases i found via running the reference_init.pl
    script. These were easy to spot just knowing the file names. There is
    one another about init/main.c that i cant exactly zero in. (partly
    because i dont know how to interpret the data thats spewed out of the tool).
    
    Signed-off-by: Ashok Raj <ashok.raj@intel.com>
    Signed-off-by: Andi Kleen <ak@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 3bfca093a870..eb730a80952c 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -94,7 +94,9 @@ static int set_max_cstate(struct dmi_system_id *id)
 	return 0;
 }
 
-static struct dmi_system_id __initdata processor_power_dmi_table[] = {
+/* Actually this shouldn't be __cpuinitdata, would be better to fix the
+   callers to only run once -AK */
+static struct dmi_system_id __cpuinitdata processor_power_dmi_table[] = {
 	{ set_max_cstate, "IBM ThinkPad R40e", {
 	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
 	  DMI_MATCH(DMI_BIOS_VERSION,"1SET60WW")}, (void *)1},

commit 76b461c21468f41837283b7888d55f1c0671f719
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Fri Feb 3 21:50:47 2006 +0100

    [PATCH] x86_64: Only switch to IPI broadcast timer on Intel when C3 is supported
    
    Bug in apic timer removal on C3 patch. We should switch to IPI from APIC timer
    only when C3 state is valid.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Andi Kleen <ak@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index be2dae52f6fa..3bfca093a870 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -899,7 +899,7 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 		case ACPI_STATE_C3:
 			acpi_processor_power_verify_c3(pr, cx);
 #ifdef ARCH_APICTIMER_STOPS_ON_C3
-			if (c->x86_vendor == X86_VENDOR_INTEL) {
+			if (cx->valid && c->x86_vendor == X86_VENDOR_INTEL) {
 				on_each_cpu(switch_APIC_timer_to_ipi,
 						&mask, 1, 1);
 			}

commit 9fdb62af92c741addbea15545f214a6e89460865
Merge: 3ee68c4af3fd 876c184b31dc 729b4d4ce198 cf8247884018 dacd9b803555 63c94b68ec30 35f652b5ef4e 1a38416cea8a 4a90c7e86202 aea19aa0780d 757b18661ea0 c4bb6f5ad968
Author: Len Brown <len.brown@intel.com>
Date:   Tue Jan 24 17:52:48 2006 -0500

    [ACPI] merge 3549 4320 4485 4588 4980 5483 5651 acpica asus fops pnpacpi branches into release
    
    Signed-off-by: Len Brown <len.brown@intel.com>

commit 6eb0a0fd059598ee0d49c6283ce25cccd743e9fc
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Wed Jan 11 22:44:21 2006 +0100

    [PATCH] i386: Handle missing local APIC timer interrupts on C3 state
    
    Whenever we see that a CPU is capable of C3 (during ACPI cstate init), we
    disable local APIC timer and switch to using a broadcast from external timer
    interrupt (IRQ 0). This is needed because Intel CPUs stop the local
    APIC timer in C3.  This is currently only enabled for Intel CPUs.
    
    Patch below adds the code for i386 and also the ACPI hunk.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Andi Kleen <ak@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 807b0df308f1..cc049338e418 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -843,6 +843,15 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 	unsigned int i;
 	unsigned int working = 0;
 
+#ifdef ARCH_APICTIMER_STOPS_ON_C3
+	struct cpuinfo_x86 *c = cpu_data + pr->id;
+	cpumask_t mask = cpumask_of_cpu(pr->id);
+
+	if (c->x86_vendor == X86_VENDOR_INTEL) {
+		on_each_cpu(switch_ipi_to_APIC_timer, &mask, 1, 1);
+	}
+#endif
+
 	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
 		struct acpi_processor_cx *cx = &pr->power.states[i];
 
@@ -857,6 +866,12 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 
 		case ACPI_STATE_C3:
 			acpi_processor_power_verify_c3(pr, cx);
+#ifdef ARCH_APICTIMER_STOPS_ON_C3
+			if (c->x86_vendor == X86_VENDOR_INTEL) {
+				on_each_cpu(switch_APIC_timer_to_ipi,
+						&mask, 1, 1);
+			}
+#endif
 			break;
 		}
 

commit 876c184b31dc73cc3f38c5b86dee55d091a56769
Author: Thomas Rosner <kernel-bugs@digital-trauma.de>
Date:   Fri Jan 6 01:31:00 2006 -0500

    [ACPI] Disable C2/C3 for _all_ IBM R40e Laptops
    
    This adds all known BIOS versions of IBM R40e Laptops to the C2/C3
    processor state blacklist and thus prevents them from crashing.
    workaround for http://bugzilla.kernel.org/show_bug.cgi?id=3549
    
    Signed-off-by: Thomas Rosner <kernel-bugs@digital-trauma.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 807b0df308f1..552420e1f890 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -95,22 +95,57 @@ static int set_max_cstate(struct dmi_system_id *id)
 }
 
 static struct dmi_system_id __initdata processor_power_dmi_table[] = {
-	{set_max_cstate, "IBM ThinkPad R40e", {
-					       DMI_MATCH(DMI_BIOS_VENDOR,
-							 "IBM"),
-					       DMI_MATCH(DMI_BIOS_VERSION,
-							 "1SET60WW")},
-	 (void *)1},
-	{set_max_cstate, "Medion 41700", {
-					  DMI_MATCH(DMI_BIOS_VENDOR,
-						    "Phoenix Technologies LTD"),
-					  DMI_MATCH(DMI_BIOS_VERSION,
-						    "R01-A1J")}, (void *)1},
-	{set_max_cstate, "Clevo 5600D", {
-					 DMI_MATCH(DMI_BIOS_VENDOR,
-						   "Phoenix Technologies LTD"),
-					 DMI_MATCH(DMI_BIOS_VERSION,
-						   "SHE845M0.86C.0013.D.0302131307")},
+	{ set_max_cstate, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET60WW")}, (void *)1},
+	{ set_max_cstate, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET43WW") }, (void*)1},
+	{ set_max_cstate, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET45WW") }, (void*)1},
+	{ set_max_cstate, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET47WW") }, (void*)1},
+	{ set_max_cstate, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET50WW") }, (void*)1},
+	{ set_max_cstate, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET52WW") }, (void*)1},
+	{ set_max_cstate, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET55WW") }, (void*)1},
+	{ set_max_cstate, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET56WW") }, (void*)1},
+	{ set_max_cstate, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET59WW") }, (void*)1},
+	{ set_max_cstate, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET60WW") }, (void*)1},
+	{ set_max_cstate, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET61WW") }, (void*)1},
+	{ set_max_cstate, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET62WW") }, (void*)1},
+	{ set_max_cstate, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET64WW") }, (void*)1},
+	{ set_max_cstate, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET65WW") }, (void*)1},
+	{ set_max_cstate, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET68WW") }, (void*)1},
+	{ set_max_cstate, "Medion 41700", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"Phoenix Technologies LTD"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"R01-A1J")}, (void *)1},
+	{ set_max_cstate, "Clevo 5600D", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"Phoenix Technologies LTD"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"SHE845M0.86C.0013.D.0302131307")},
 	 (void *)2},
 	{},
 };

commit 927fe18397b3b1194a5b26b1d388d97e391e5fd2
Merge: e4f5c82a92c2 1e483969930a
Author: Len Brown <len.brown@intel.com>
Date:   Mon Dec 5 17:08:40 2005 -0500

    Pull 5165 into release branch

commit 1e483969930a82e16767884449f3a121a817ef00
Author: David Shaohua Li <shaohua.li@intel.com>
Date:   Thu Dec 1 17:00:00 2005 -0500

    [ACPI] correct earlier SMP deep C-states on HT patch
    
    http://bugzilla.kernel.org/show_bug.cgi?id=5165
    
    Change polarity of test for PLVL2_UP flag.
    Skip promotion/demotion code when not needed.
    
    Signed-off-by: Shaohua Li <shaohua.li@intel.com>
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 83fd1b6c10c4..800f99c4c0ef 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -278,8 +278,6 @@ static void acpi_processor_idle(void)
 		}
 	}
 
-	cx->usage++;
-
 #ifdef CONFIG_HOTPLUG_CPU
 	/*
 	 * Check for P_LVL2_UP flag before entering C2 and above on
@@ -287,9 +285,12 @@ static void acpi_processor_idle(void)
 	 * detection phase, to work cleanly with logical CPU hotplug.
 	 */
 	if ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) && 
-	    !pr->flags.has_cst && acpi_fadt.plvl2_up)
-		cx->type = ACPI_STATE_C1;
+	    !pr->flags.has_cst && !acpi_fadt.plvl2_up)
+		cx = &pr->power.states[ACPI_STATE_C1];
 #endif
+
+	cx->usage++;
+
 	/*
 	 * Sleep:
 	 * ------
@@ -378,6 +379,15 @@ static void acpi_processor_idle(void)
 
 	next_state = pr->power.state;
 
+#ifdef CONFIG_HOTPLUG_CPU
+	/* Don't do promotion/demotion */
+	if ((cx->type == ACPI_STATE_C1) && (num_online_cpus() > 1) &&
+	    !pr->flags.has_cst && !acpi_fadt.plvl2_up) {
+		next_state = cx;
+		goto end;
+	}
+#endif
+
 	/*
 	 * Promotion?
 	 * ----------
@@ -549,7 +559,7 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 	 * Check for P_LVL2_UP flag before entering C2 and above on
 	 * an SMP system. 
 	 */
-	if ((num_online_cpus() > 1) && acpi_fadt.plvl2_up)
+	if ((num_online_cpus() > 1) && !acpi_fadt.plvl2_up)
 		return_VALUE(-ENODEV);
 #endif
 

commit af2eb17bac41a116b73d85b3fb160405c32bea5b
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Fri Dec 2 23:09:06 2005 -0800

    Add missing "local_irq_enable()" to C2/C3 exit logic
    
    Silly bug crept in with the C2/C3 TIF_POLLING_NRFLAG fixes.
    
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index acd875e0caca..5f51057518b0 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -296,6 +296,7 @@ static void acpi_processor_idle(void)
 		smp_mb__after_clear_bit();
 		if (need_resched()) {
 			set_thread_flag(TIF_POLLING_NRFLAG);
+			local_irq_enable();
 			return;
 		}
 	}

commit 2a298a35ebe060a6f2b06b20c2a34ea188ddfd37
Author: Nick Piggin <nickpiggin@yahoo.com.au>
Date:   Fri Dec 2 12:44:19 2005 +1100

    [PATCH] Fix TIF_POLLING_NRFLAG in ACPI idle routines
    
    Commit 64c7c8f88559624abdbe12b5da6502e8879f8d28 broke the ACPI C2 and C3
    sleep states, because it left TIF_POLLING_NRFLAG active even though
    those states do not actually poll the reschedule flag at all.  As a
    result, the CPU wouldn't get sent an IPI when it was to be woken up, and
    would only notice that it had runnable processes on the next timer tick.
    
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 83fd1b6c10c4..acd875e0caca 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -169,15 +169,11 @@ acpi_processor_power_activate(struct acpi_processor *pr,
 
 static void acpi_safe_halt(void)
 {
-	int polling = test_thread_flag(TIF_POLLING_NRFLAG);
-	if (polling) {
-		clear_thread_flag(TIF_POLLING_NRFLAG);
-		smp_mb__after_clear_bit();
-	}
+	clear_thread_flag(TIF_POLLING_NRFLAG);
+	smp_mb__after_clear_bit();
 	if (!need_resched())
 		safe_halt();
-	if (polling)
-		set_thread_flag(TIF_POLLING_NRFLAG);
+	set_thread_flag(TIF_POLLING_NRFLAG);
 }
 
 static atomic_t c3_cpu_count;
@@ -295,6 +291,15 @@ static void acpi_processor_idle(void)
 	 * ------
 	 * Invoke the current Cx state to put the processor to sleep.
 	 */
+	if (cx->type == ACPI_STATE_C2 || cx->type == ACPI_STATE_C3) {
+		clear_thread_flag(TIF_POLLING_NRFLAG);
+		smp_mb__after_clear_bit();
+		if (need_resched()) {
+			set_thread_flag(TIF_POLLING_NRFLAG);
+			return;
+		}
+	}
+
 	switch (cx->type) {
 
 	case ACPI_STATE_C1:
@@ -327,6 +332,7 @@ static void acpi_processor_idle(void)
 		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
 		/* Re-enable interrupts */
 		local_irq_enable();
+		set_thread_flag(TIF_POLLING_NRFLAG);
 		/* Compute time (ticks) that we were actually asleep */
 		sleep_ticks =
 		    ticks_elapsed(t1, t2) - cx->latency_ticks - C2_OVERHEAD;
@@ -366,6 +372,7 @@ static void acpi_processor_idle(void)
 
 		/* Re-enable interrupts */
 		local_irq_enable();
+		set_thread_flag(TIF_POLLING_NRFLAG);
 		/* Compute time (ticks) that we were actually asleep */
 		sleep_ticks =
 		    ticks_elapsed(t1, t2) - cx->latency_ticks - C3_OVERHEAD;

commit cf82478840188f8c8494c1d7a668a8ae170d0e07
Author: Janosch Machowinski <jmachowinski@gmx.de>
Date:   Sat Aug 20 08:02:00 2005 -0400

    [ACPI] handle BIOS with implicit C1 in _CST
    
    The ASUS M6Ne specifies C2, implying C1
    but not explicitly specifying it.
    
    http://bugzilla.kernel.org/show_bug.cgi?id=4485
    
    Signed-off-by: Janosch Machowinski <jmachowinski@gmx.de>
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 83fd1b6c10c4..40c9f9ca5965 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -532,18 +532,10 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 	if (!pr->pblk)
 		return_VALUE(-ENODEV);
 
-	memset(pr->power.states, 0, sizeof(pr->power.states));
-
 	/* if info is obtained from pblk/fadt, type equals state */
-	pr->power.states[ACPI_STATE_C1].type = ACPI_STATE_C1;
 	pr->power.states[ACPI_STATE_C2].type = ACPI_STATE_C2;
 	pr->power.states[ACPI_STATE_C3].type = ACPI_STATE_C3;
 
-	/* the C0 state only exists as a filler in our array,
-	 * and all processors need to support C1 */
-	pr->power.states[ACPI_STATE_C0].valid = 1;
-	pr->power.states[ACPI_STATE_C1].valid = 1;
-
 #ifndef CONFIG_HOTPLUG_CPU
 	/*
 	 * Check for P_LVL2_UP flag before entering C2 and above on
@@ -573,12 +565,11 @@ static int acpi_processor_get_power_info_default_c1(struct acpi_processor *pr)
 {
 	ACPI_FUNCTION_TRACE("acpi_processor_get_power_info_default_c1");
 
+	/* Zero initialize all the C-states info. */
 	memset(pr->power.states, 0, sizeof(pr->power.states));
 
-	/* if info is obtained from pblk/fadt, type equals state */
+	/* set the first C-State to C1 */
 	pr->power.states[ACPI_STATE_C1].type = ACPI_STATE_C1;
-	pr->power.states[ACPI_STATE_C2].type = ACPI_STATE_C2;
-	pr->power.states[ACPI_STATE_C3].type = ACPI_STATE_C3;
 
 	/* the C0 state only exists as a filler in our array,
 	 * and all processors need to support C1 */
@@ -592,6 +583,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 {
 	acpi_status status = 0;
 	acpi_integer count;
+	int current_count;
 	int i;
 	struct acpi_buffer buffer = { ACPI_ALLOCATE_BUFFER, NULL };
 	union acpi_object *cst;
@@ -601,10 +593,12 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 	if (nocst)
 		return_VALUE(-ENODEV);
 
-	pr->power.count = 0;
-	for (i = 0; i < ACPI_PROCESSOR_MAX_POWER; i++)
-		memset(&(pr->power.states[i]), 0,
-		       sizeof(struct acpi_processor_cx));
+	current_count = 1;
+
+	/* Zero initialize C2 onwards and prepare for fresh CST lookup */
+	for (i = 2; i < ACPI_PROCESSOR_MAX_POWER; i++)
+		memset(&(pr->power.states[i]), 0, 
+				sizeof(struct acpi_processor_cx));
 
 	status = acpi_evaluate_object(pr->handle, "_CST", NULL, &buffer);
 	if (ACPI_FAILURE(status)) {
@@ -632,16 +626,6 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 		goto end;
 	}
 
-	/* We support up to ACPI_PROCESSOR_MAX_POWER. */
-	if (count > ACPI_PROCESSOR_MAX_POWER) {
-		printk(KERN_WARNING
-		       "Limiting number of power states to max (%d)\n",
-		       ACPI_PROCESSOR_MAX_POWER);
-		printk(KERN_WARNING
-		       "Please increase ACPI_PROCESSOR_MAX_POWER if needed.\n");
-		count = ACPI_PROCESSOR_MAX_POWER;
-	}
-
 	/* Tell driver that at least _CST is supported. */
 	pr->flags.has_cst = 1;
 
@@ -685,7 +669,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 		    (reg->space_id != ACPI_ADR_SPACE_SYSTEM_IO))
 			continue;
 
-		if ((cx.type < ACPI_STATE_C1) || (cx.type > ACPI_STATE_C3))
+		if ((cx.type < ACPI_STATE_C2) || (cx.type > ACPI_STATE_C3))
 			continue;
 
 		obj = (union acpi_object *)&(element->package.elements[2]);
@@ -700,15 +684,28 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 
 		cx.power = obj->integer.value;
 
-		(pr->power.count)++;
-		memcpy(&(pr->power.states[pr->power.count]), &cx, sizeof(cx));
+		current_count++;
+		memcpy(&(pr->power.states[current_count]), &cx, sizeof(cx));
+
+		/*
+		 * We support total ACPI_PROCESSOR_MAX_POWER - 1
+		 * (From 1 through ACPI_PROCESSOR_MAX_POWER - 1)
+		 */
+		if (current_count >= (ACPI_PROCESSOR_MAX_POWER - 1)) {
+			printk(KERN_WARNING
+			       "Limiting number of power states to max (%d)\n",
+			       ACPI_PROCESSOR_MAX_POWER);
+			printk(KERN_WARNING
+			       "Please increase ACPI_PROCESSOR_MAX_POWER if needed.\n");
+			break;
+		}
 	}
 
 	ACPI_DEBUG_PRINT((ACPI_DB_INFO, "Found %d power states\n",
-			  pr->power.count));
+			  current_count));
 
 	/* Validate number of power states discovered */
-	if (pr->power.count < 2)
+	if (current_count < 2)
 		status = -EFAULT;
 
       end:
@@ -859,12 +856,13 @@ static int acpi_processor_get_power_info(struct acpi_processor *pr)
 	/* NOTE: the idle thread may not be running while calling
 	 * this function */
 
+	/* Adding C1 state */
+	acpi_processor_get_power_info_default_c1(pr);
 	result = acpi_processor_get_power_info_cst(pr);
 	if (result == -ENODEV)
-		result = acpi_processor_get_power_info_fadt(pr);
+		acpi_processor_get_power_info_fadt(pr);
 
-	if ((result) || (acpi_processor_power_verify(pr) < 2))
-		result = acpi_processor_get_power_info_default_c1(pr);
+	pr->power.count = acpi_processor_power_verify(pr);
 
 	/*
 	 * Set Default Policy

commit 05131ecc99ea9da7f45ba3058fe8a2c1d0ceeab8
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Sun Oct 23 16:31:00 2005 -0400

    [ACPI] Avoid BIOS inflicted crashes by evaluating _PDC only once
    
    Linux invokes the AML _PDC method (Processor Driver Capabilities)
    to tell the BIOS what features it can handle.  While the ACPI
    spec says nothing about the OS invoking _PDC multiple times,
    doing so with changing bits seems to hopelessly confuse the BIOS
    on multiple platforms up to and including crashing the system.
    
    Factor out the _PDC invocation so Linux invokes it only once.
    
    http://bugzilla.kernel.org/show_bug.cgi?id=5483
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 70d8a6ec0920..1915c377bfc6 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -1014,8 +1014,6 @@ int acpi_processor_power_init(struct acpi_processor *pr,
 		}
 	}
 
-	acpi_processor_power_init_pdc(&(pr->power), pr->id);
-	acpi_processor_set_pdc(pr, pr->power.pdc);
 	acpi_processor_get_power_info(pr);
 
 	/*

commit 4c0335526c95d90a1d958e0059f40a5745fc7c5d
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Thu Sep 15 12:20:00 2005 -0400

    [ACPI] Add support for FADT P_LVL2_UP flag
    which tells us if C2 is valid for UP-only, or SMP.
    
    As there is no separate bit for C3,  use P_LVL2_UP
    bit to cover both C2 and C3.
    
    http://bugzilla.kernel.org/show_bug.cgi?id=5165
    
    Signed-off-by: Venkatesh Pallipadi<venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>
    (cherry picked from 28b86b368af3944eb383078fc5797caf2dc8ce44 commit)

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 5b6a9865300e..83fd1b6c10c4 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -280,6 +280,16 @@ static void acpi_processor_idle(void)
 
 	cx->usage++;
 
+#ifdef CONFIG_HOTPLUG_CPU
+	/*
+	 * Check for P_LVL2_UP flag before entering C2 and above on
+	 * an SMP system. We do it here instead of doing it at _CST/P_LVL
+	 * detection phase, to work cleanly with logical CPU hotplug.
+	 */
+	if ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) && 
+	    !pr->flags.has_cst && acpi_fadt.plvl2_up)
+		cx->type = ACPI_STATE_C1;
+#endif
 	/*
 	 * Sleep:
 	 * ------
@@ -534,6 +544,15 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 	pr->power.states[ACPI_STATE_C0].valid = 1;
 	pr->power.states[ACPI_STATE_C1].valid = 1;
 
+#ifndef CONFIG_HOTPLUG_CPU
+	/*
+	 * Check for P_LVL2_UP flag before entering C2 and above on
+	 * an SMP system. 
+	 */
+	if ((num_online_cpus() > 1) && acpi_fadt.plvl2_up)
+		return_VALUE(-ENODEV);
+#endif
+
 	/* determine C2 and C3 address from pblk */
 	pr->power.states[ACPI_STATE_C2].address = pr->pblk + 4;
 	pr->power.states[ACPI_STATE_C3].address = pr->pblk + 5;

commit 6d93c64803a5fea84839789aae13290419c62d92
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Thu Sep 15 12:19:00 2005 -0400

    [ACPI] Prefer _CST over FADT for C-state capabilities
    
    Note: This ACPI standard compliance may cause regression
    on some system, if they have _CST present, but _CST value
    is bogus. "nocst" module parameter should workaround
    that regression.
    
    http://bugzilla.kernel.org/show_bug.cgi?id=5165
    
    Signed-off-by: Venkatesh Pallipadi<venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>
    (cherry picked from 883baf7f7e81cca26f4683ae0d25ba48f094cc08 commit)

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 70d8a6ec0920..5b6a9865300e 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -690,7 +690,7 @@ static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 
 	/* Validate number of power states discovered */
 	if (pr->power.count < 2)
-		status = -ENODEV;
+		status = -EFAULT;
 
       end:
 	acpi_os_free(buffer.pointer);
@@ -841,11 +841,11 @@ static int acpi_processor_get_power_info(struct acpi_processor *pr)
 	 * this function */
 
 	result = acpi_processor_get_power_info_cst(pr);
-	if ((result) || (acpi_processor_power_verify(pr) < 2)) {
+	if (result == -ENODEV)
 		result = acpi_processor_get_power_info_fadt(pr);
-		if ((result) || (acpi_processor_power_verify(pr) < 2))
-			result = acpi_processor_get_power_info_default_c1(pr);
-	}
+
+	if ((result) || (acpi_processor_power_verify(pr) < 2))
+		result = acpi_processor_get_power_info_default_c1(pr);
 
 	/*
 	 * Set Default Policy

commit 2203d6ed448ff3b777ee6bb614a53e686b483e5b
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Fri Nov 18 07:29:51 2005 -0800

    Fix ACPI processor power block initialization
    
    Properly clear the memory, and set "pr->flags.power" only if a C2 or
    deeper state is valid (to make the code match both the comment and
    previous behaviour).
    
    This fixes a boot-time lockup reported by Maneesh Soni when using
    "maxcpus=1".
    
    Acked-by: Maneesh Soni <maneesh@in.ibm.com>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 573b6a97bb1f..70d8a6ec0920 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -514,8 +514,6 @@ static int acpi_processor_set_power_policy(struct acpi_processor *pr)
 
 static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 {
-	int i;
-
 	ACPI_FUNCTION_TRACE("acpi_processor_get_power_info_fadt");
 
 	if (!pr)
@@ -524,8 +522,7 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 	if (!pr->pblk)
 		return_VALUE(-ENODEV);
 
-	for (i = 0; i < ACPI_PROCESSOR_MAX_POWER; i++)
-		memset(pr->power.states, 0, sizeof(struct acpi_processor_cx));
+	memset(pr->power.states, 0, sizeof(pr->power.states));
 
 	/* if info is obtained from pblk/fadt, type equals state */
 	pr->power.states[ACPI_STATE_C1].type = ACPI_STATE_C1;
@@ -555,13 +552,9 @@ static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 
 static int acpi_processor_get_power_info_default_c1(struct acpi_processor *pr)
 {
-	int i;
-
 	ACPI_FUNCTION_TRACE("acpi_processor_get_power_info_default_c1");
 
-	for (i = 0; i < ACPI_PROCESSOR_MAX_POWER; i++)
-		memset(&(pr->power.states[i]), 0,
-		       sizeof(struct acpi_processor_cx));
+	memset(pr->power.states, 0, sizeof(pr->power.states));
 
 	/* if info is obtained from pblk/fadt, type equals state */
 	pr->power.states[ACPI_STATE_C1].type = ACPI_STATE_C1;
@@ -873,7 +866,8 @@ static int acpi_processor_get_power_info(struct acpi_processor *pr)
 	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
 		if (pr->power.states[i].valid) {
 			pr->power.count = i;
-			pr->flags.power = 1;
+			if (pr->power.states[i].type >= ACPI_STATE_C2)
+				pr->flags.power = 1;
 		}
 	}
 

commit 64c7c8f88559624abdbe12b5da6502e8879f8d28
Author: Nick Piggin <nickpiggin@yahoo.com.au>
Date:   Tue Nov 8 21:39:04 2005 -0800

    [PATCH] sched: resched and cpu_idle rework
    
    Make some changes to the NEED_RESCHED and POLLING_NRFLAG to reduce
    confusion, and make their semantics rigid.  Improves efficiency of
    resched_task and some cpu_idle routines.
    
    * In resched_task:
    - TIF_NEED_RESCHED is only cleared with the task's runqueue lock held,
      and as we hold it during resched_task, then there is no need for an
      atomic test and set there. The only other time this should be set is
      when the task's quantum expires, in the timer interrupt - this is
      protected against because the rq lock is irq-safe.
    
    - If TIF_NEED_RESCHED is set, then we don't need to do anything. It
      won't get unset until the task get's schedule()d off.
    
    - If we are running on the same CPU as the task we resched, then set
      TIF_NEED_RESCHED and no further action is required.
    
    - If we are running on another CPU, and TIF_POLLING_NRFLAG is *not* set
      after TIF_NEED_RESCHED has been set, then we need to send an IPI.
    
    Using these rules, we are able to remove the test and set operation in
    resched_task, and make clear the previously vague semantics of
    POLLING_NRFLAG.
    
    * In idle routines:
    - Enter cpu_idle with preempt disabled. When the need_resched() condition
      becomes true, explicitly call schedule(). This makes things a bit clearer
      (IMO), but haven't updated all architectures yet.
    
    - Many do a test and clear of TIF_NEED_RESCHED for some reason. According
      to the resched_task rules, this isn't needed (and actually breaks the
      assumption that TIF_NEED_RESCHED is only cleared with the runqueue lock
      held). So remove that. Generally one less locked memory op when switching
      to the idle thread.
    
    - Many idle routines clear TIF_POLLING_NRFLAG, and only set it in the inner
      most polling idle loops. The above resched_task semantics allow it to be
      set until before the last time need_resched() is checked before going into
      a halt requiring interrupt wakeup.
    
      Many idle routines simply never enter such a halt, and so POLLING_NRFLAG
      can be always left set, completely eliminating resched IPIs when rescheduling
      the idle task.
    
      POLLING_NRFLAG width can be increased, to reduce the chance of resched IPIs.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Con Kolivas <kernel@kolivas.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 161db4acfb91..573b6a97bb1f 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -167,6 +167,19 @@ acpi_processor_power_activate(struct acpi_processor *pr,
 	return;
 }
 
+static void acpi_safe_halt(void)
+{
+	int polling = test_thread_flag(TIF_POLLING_NRFLAG);
+	if (polling) {
+		clear_thread_flag(TIF_POLLING_NRFLAG);
+		smp_mb__after_clear_bit();
+	}
+	if (!need_resched())
+		safe_halt();
+	if (polling)
+		set_thread_flag(TIF_POLLING_NRFLAG);
+}
+
 static atomic_t c3_cpu_count;
 
 static void acpi_processor_idle(void)
@@ -177,7 +190,7 @@ static void acpi_processor_idle(void)
 	int sleep_ticks = 0;
 	u32 t1, t2 = 0;
 
-	pr = processors[raw_smp_processor_id()];
+	pr = processors[smp_processor_id()];
 	if (!pr)
 		return;
 
@@ -197,8 +210,13 @@ static void acpi_processor_idle(void)
 	}
 
 	cx = pr->power.state;
-	if (!cx)
-		goto easy_out;
+	if (!cx) {
+		if (pm_idle_save)
+			pm_idle_save();
+		else
+			acpi_safe_halt();
+		return;
+	}
 
 	/*
 	 * Check BM Activity
@@ -278,7 +296,8 @@ static void acpi_processor_idle(void)
 		if (pm_idle_save)
 			pm_idle_save();
 		else
-			safe_halt();
+			acpi_safe_halt();
+
 		/*
 		 * TBD: Can't get time duration while in C1, as resumes
 		 *      go to an ISR rather than here.  Need to instrument
@@ -414,16 +433,6 @@ static void acpi_processor_idle(void)
 	 */
 	if (next_state != pr->power.state)
 		acpi_processor_power_activate(pr, next_state);
-
-	return;
-
-      easy_out:
-	/* do C1 instead of busy loop */
-	if (pm_idle_save)
-		pm_idle_save();
-	else
-		safe_halt();
-	return;
 }
 
 static int acpi_processor_set_power_policy(struct acpi_processor *pr)

commit 4e57b6817880946a3a78d5d8cad1ace363f7e449
Author: Tim Schmielau <tim@physik3.uni-rostock.de>
Date:   Sun Oct 30 15:03:48 2005 -0800

    [PATCH] fix missing includes
    
    I recently picked up my older work to remove unnecessary #includes of
    sched.h, starting from a patch by Dave Jones to not include sched.h
    from module.h. This reduces the number of indirect includes of sched.h
    by ~300. Another ~400 pointless direct includes can be removed after
    this disentangling (patch to follow later).
    However, quite a few indirect includes need to be fixed up for this.
    
    In order to feed the patches through -mm with as little disturbance as
    possible, I've split out the fixes I accumulated up to now (complete for
    i386 and x86_64, more archs to follow later) and post them before the real
    patch.  This way this large part of the patch is kept simple with only
    adding #includes, and all hunks are independent of each other.  So if any
    hunk rejects or gets in the way of other patches, just drop it.  My scripts
    will pick it up again in the next round.
    
    Signed-off-by: Tim Schmielau <tim@physik3.uni-rostock.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 26a3a4016115..161db4acfb91 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -37,6 +37,7 @@
 #include <linux/acpi.h>
 #include <linux/dmi.h>
 #include <linux/moduleparam.h>
+#include <linux/sched.h>	/* need_resched() */
 
 #include <asm/io.h>
 #include <asm/uaccess.h>

commit 4be44fcd3bf648b782f4460fd06dfae6c42ded4b
Author: Len Brown <len.brown@intel.com>
Date:   Fri Aug 5 00:44:28 2005 -0400

    [ACPI] Lindent all ACPI files
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 2c04740c6543..26a3a4016115 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -48,15 +48,12 @@
 #define ACPI_PROCESSOR_CLASS            "processor"
 #define ACPI_PROCESSOR_DRIVER_NAME      "ACPI Processor Driver"
 #define _COMPONENT              ACPI_PROCESSOR_COMPONENT
-ACPI_MODULE_NAME                ("acpi_processor")
-
+ACPI_MODULE_NAME("acpi_processor")
 #define ACPI_PROCESSOR_FILE_POWER	"power"
-
 #define US_TO_PM_TIMER_TICKS(t)		((t * (PM_TIMER_FREQUENCY/1000)) / 1000)
 #define C2_OVERHEAD			4	/* 1us (3.579 ticks per us) */
 #define C3_OVERHEAD			4	/* 1us (3.579 ticks per us) */
-
-static void (*pm_idle_save)(void);
+static void (*pm_idle_save) (void);
 module_param(max_cstate, uint, 0644);
 
 static unsigned int nocst = 0;
@@ -69,7 +66,8 @@ module_param(nocst, uint, 0000);
  * 100 HZ: 0x0000000F: 4 jiffies = 40ms
  * reduce history for more aggressive entry into C3
  */
-static unsigned int bm_history = (HZ >= 800 ? 0xFFFFFFFF : ((1U << (HZ / 25)) - 1));
+static unsigned int bm_history =
+    (HZ >= 800 ? 0xFFFFFFFF : ((1U << (HZ / 25)) - 1));
 module_param(bm_history, uint, 0644);
 /* --------------------------------------------------------------------------
                                 Power Management
@@ -87,34 +85,36 @@ static int set_max_cstate(struct dmi_system_id *id)
 		return 0;
 
 	printk(KERN_NOTICE PREFIX "%s detected - limiting to C%ld max_cstate."
-		" Override with \"processor.max_cstate=%d\"\n", id->ident,
-		(long)id->driver_data, ACPI_PROCESSOR_MAX_POWER + 1);
+	       " Override with \"processor.max_cstate=%d\"\n", id->ident,
+	       (long)id->driver_data, ACPI_PROCESSOR_MAX_POWER + 1);
 
 	max_cstate = (long)id->driver_data;
 
 	return 0;
 }
 
-
 static struct dmi_system_id __initdata processor_power_dmi_table[] = {
-	{ set_max_cstate, "IBM ThinkPad R40e", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET60WW") }, (void*)1},
-	{ set_max_cstate, "Medion 41700", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"Phoenix Technologies LTD"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"R01-A1J") }, (void*)1},
-	{ set_max_cstate, "Clevo 5600D", {
-	  DMI_MATCH(DMI_BIOS_VENDOR,"Phoenix Technologies LTD"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"SHE845M0.86C.0013.D.0302131307") },
-	  (void*)2},
+	{set_max_cstate, "IBM ThinkPad R40e", {
+					       DMI_MATCH(DMI_BIOS_VENDOR,
+							 "IBM"),
+					       DMI_MATCH(DMI_BIOS_VERSION,
+							 "1SET60WW")},
+	 (void *)1},
+	{set_max_cstate, "Medion 41700", {
+					  DMI_MATCH(DMI_BIOS_VENDOR,
+						    "Phoenix Technologies LTD"),
+					  DMI_MATCH(DMI_BIOS_VERSION,
+						    "R01-A1J")}, (void *)1},
+	{set_max_cstate, "Clevo 5600D", {
+					 DMI_MATCH(DMI_BIOS_VENDOR,
+						   "Phoenix Technologies LTD"),
+					 DMI_MATCH(DMI_BIOS_VERSION,
+						   "SHE845M0.86C.0013.D.0302131307")},
+	 (void *)2},
 	{},
 };
 
-
-static inline u32
-ticks_elapsed (
-	u32			t1,
-	u32			t2)
+static inline u32 ticks_elapsed(u32 t1, u32 t2)
 {
 	if (t2 >= t1)
 		return (t2 - t1);
@@ -124,13 +124,11 @@ ticks_elapsed (
 		return ((0xFFFFFFFF - t1) + t2);
 }
 
-
 static void
-acpi_processor_power_activate (
-	struct acpi_processor	*pr,
-	struct acpi_processor_cx  *new)
+acpi_processor_power_activate(struct acpi_processor *pr,
+			      struct acpi_processor_cx *new)
 {
-	struct acpi_processor_cx  *old;
+	struct acpi_processor_cx *old;
 
 	if (!pr || !new)
 		return;
@@ -139,7 +137,7 @@ acpi_processor_power_activate (
 
 	if (old)
 		old->promotion.count = 0;
- 	new->demotion.count = 0;
+	new->demotion.count = 0;
 
 	/* Cleanup from old state. */
 	if (old) {
@@ -147,7 +145,8 @@ acpi_processor_power_activate (
 		case ACPI_STATE_C3:
 			/* Disable bus master reload */
 			if (new->type != ACPI_STATE_C3 && pr->flags.bm_check)
-				acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 0, ACPI_MTX_DO_NOT_LOCK);
+				acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 0,
+						  ACPI_MTX_DO_NOT_LOCK);
 			break;
 		}
 	}
@@ -157,7 +156,8 @@ acpi_processor_power_activate (
 	case ACPI_STATE_C3:
 		/* Enable bus master reload */
 		if (old->type != ACPI_STATE_C3 && pr->flags.bm_check)
-			acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 1, ACPI_MTX_DO_NOT_LOCK);
+			acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 1,
+					  ACPI_MTX_DO_NOT_LOCK);
 		break;
 	}
 
@@ -166,17 +166,15 @@ acpi_processor_power_activate (
 	return;
 }
 
+static atomic_t c3_cpu_count;
 
-static atomic_t 	c3_cpu_count;
-
-
-static void acpi_processor_idle (void)
+static void acpi_processor_idle(void)
 {
-	struct acpi_processor	*pr = NULL;
+	struct acpi_processor *pr = NULL;
 	struct acpi_processor_cx *cx = NULL;
 	struct acpi_processor_cx *next_state = NULL;
-	int			sleep_ticks = 0;
-	u32			t1, t2 = 0;
+	int sleep_ticks = 0;
+	u32 t1, t2 = 0;
 
 	pr = processors[raw_smp_processor_id()];
 	if (!pr)
@@ -208,8 +206,8 @@ static void acpi_processor_idle (void)
 	 * for demotion.
 	 */
 	if (pr->flags.bm_check) {
-		u32		bm_status = 0;
-		unsigned long	diff = jiffies - pr->power.bm_check_timestamp;
+		u32 bm_status = 0;
+		unsigned long diff = jiffies - pr->power.bm_check_timestamp;
 
 		if (diff > 32)
 			diff = 32;
@@ -223,11 +221,11 @@ static void acpi_processor_idle (void)
 		}
 
 		acpi_get_register(ACPI_BITREG_BUS_MASTER_STATUS,
-			&bm_status, ACPI_MTX_DO_NOT_LOCK);
+				  &bm_status, ACPI_MTX_DO_NOT_LOCK);
 		if (bm_status) {
 			pr->power.bm_activity++;
 			acpi_set_register(ACPI_BITREG_BUS_MASTER_STATUS,
-				1, ACPI_MTX_DO_NOT_LOCK);
+					  1, ACPI_MTX_DO_NOT_LOCK);
 		}
 		/*
 		 * PIIX4 Erratum #18: Note that BM_STS doesn't always reflect
@@ -236,7 +234,7 @@ static void acpi_processor_idle (void)
 		 */
 		else if (errata.piix4.bmisx) {
 			if ((inb_p(errata.piix4.bmisx + 0x02) & 0x01)
-				|| (inb_p(errata.piix4.bmisx + 0x0A) & 0x01))
+			    || (inb_p(errata.piix4.bmisx + 0x0A) & 0x01))
 				pr->power.bm_activity++;
 		}
 
@@ -281,7 +279,7 @@ static void acpi_processor_idle (void)
 		else
 			safe_halt();
 		/*
-                 * TBD: Can't get time duration while in C1, as resumes
+		 * TBD: Can't get time duration while in C1, as resumes
 		 *      go to an ISR rather than here.  Need to instrument
 		 *      base interrupt handler.
 		 */
@@ -300,26 +298,27 @@ static void acpi_processor_idle (void)
 		/* Re-enable interrupts */
 		local_irq_enable();
 		/* Compute time (ticks) that we were actually asleep */
-		sleep_ticks = ticks_elapsed(t1, t2) - cx->latency_ticks - C2_OVERHEAD;
+		sleep_ticks =
+		    ticks_elapsed(t1, t2) - cx->latency_ticks - C2_OVERHEAD;
 		break;
 
 	case ACPI_STATE_C3:
-		
+
 		if (pr->flags.bm_check) {
 			if (atomic_inc_return(&c3_cpu_count) ==
-					num_online_cpus()) {
+			    num_online_cpus()) {
 				/*
 				 * All CPUs are trying to go to C3
 				 * Disable bus master arbitration
 				 */
 				acpi_set_register(ACPI_BITREG_ARB_DISABLE, 1,
-					ACPI_MTX_DO_NOT_LOCK);
+						  ACPI_MTX_DO_NOT_LOCK);
 			}
 		} else {
 			/* SMP with no shared cache... Invalidate cache  */
 			ACPI_FLUSH_CPU_CACHE();
 		}
-		
+
 		/* Get start time (ticks) */
 		t1 = inl(acpi_fadt.xpm_tmr_blk.address);
 		/* Invoke C3 */
@@ -331,13 +330,15 @@ static void acpi_processor_idle (void)
 		if (pr->flags.bm_check) {
 			/* Enable bus master arbitration */
 			atomic_dec(&c3_cpu_count);
-			acpi_set_register(ACPI_BITREG_ARB_DISABLE, 0, ACPI_MTX_DO_NOT_LOCK);
+			acpi_set_register(ACPI_BITREG_ARB_DISABLE, 0,
+					  ACPI_MTX_DO_NOT_LOCK);
 		}
 
 		/* Re-enable interrupts */
 		local_irq_enable();
 		/* Compute time (ticks) that we were actually asleep */
-		sleep_ticks = ticks_elapsed(t1, t2) - cx->latency_ticks - C3_OVERHEAD;
+		sleep_ticks =
+		    ticks_elapsed(t1, t2) - cx->latency_ticks - C3_OVERHEAD;
 		break;
 
 	default:
@@ -359,15 +360,18 @@ static void acpi_processor_idle (void)
 	    ((cx->promotion.state - pr->power.states) <= max_cstate)) {
 		if (sleep_ticks > cx->promotion.threshold.ticks) {
 			cx->promotion.count++;
- 			cx->demotion.count = 0;
-			if (cx->promotion.count >= cx->promotion.threshold.count) {
+			cx->demotion.count = 0;
+			if (cx->promotion.count >=
+			    cx->promotion.threshold.count) {
 				if (pr->flags.bm_check) {
-					if (!(pr->power.bm_activity & cx->promotion.threshold.bm)) {
-						next_state = cx->promotion.state;
+					if (!
+					    (pr->power.bm_activity & cx->
+					     promotion.threshold.bm)) {
+						next_state =
+						    cx->promotion.state;
 						goto end;
 					}
-				}
-				else {
+				} else {
 					next_state = cx->promotion.state;
 					goto end;
 				}
@@ -392,7 +396,7 @@ static void acpi_processor_idle (void)
 		}
 	}
 
-end:
+      end:
 	/*
 	 * Demote if current state exceeds max_cstate
 	 */
@@ -412,7 +416,7 @@ static void acpi_processor_idle (void)
 
 	return;
 
- easy_out:
+      easy_out:
 	/* do C1 instead of busy loop */
 	if (pm_idle_save)
 		pm_idle_save();
@@ -421,10 +425,7 @@ static void acpi_processor_idle (void)
 	return;
 }
 
-
-static int
-acpi_processor_set_power_policy (
-	struct acpi_processor	*pr)
+static int acpi_processor_set_power_policy(struct acpi_processor *pr)
 {
 	unsigned int i;
 	unsigned int state_is_set = 0;
@@ -432,7 +433,7 @@ acpi_processor_set_power_policy (
 	struct acpi_processor_cx *higher = NULL;
 	struct acpi_processor_cx *cx;
 
- 	ACPI_FUNCTION_TRACE("acpi_processor_set_power_policy");
+	ACPI_FUNCTION_TRACE("acpi_processor_set_power_policy");
 
 	if (!pr)
 		return_VALUE(-EINVAL);
@@ -447,7 +448,7 @@ acpi_processor_set_power_policy (
 	 */
 
 	/* startup state */
-	for (i=1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
+	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
 		cx = &pr->power.states[i];
 		if (!cx->valid)
 			continue;
@@ -456,13 +457,13 @@ acpi_processor_set_power_policy (
 			pr->power.state = cx;
 		state_is_set++;
 		break;
- 	}
+	}
 
 	if (!state_is_set)
 		return_VALUE(-ENODEV);
 
 	/* demotion */
-	for (i=1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
+	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
 		cx = &pr->power.states[i];
 		if (!cx->valid)
 			continue;
@@ -485,7 +486,7 @@ acpi_processor_set_power_policy (
 			continue;
 
 		if (higher) {
-			cx->promotion.state  = higher;
+			cx->promotion.state = higher;
 			cx->promotion.threshold.ticks = cx->latency_ticks;
 			if (cx->type >= ACPI_STATE_C2)
 				cx->promotion.threshold.count = 4;
@@ -498,11 +499,10 @@ acpi_processor_set_power_policy (
 		higher = cx;
 	}
 
- 	return_VALUE(0);
+	return_VALUE(0);
 }
 
-
-static int acpi_processor_get_power_info_fadt (struct acpi_processor *pr)
+static int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)
 {
 	int i;
 
@@ -543,15 +543,14 @@ static int acpi_processor_get_power_info_fadt (struct acpi_processor *pr)
 	return_VALUE(0);
 }
 
-
-static int acpi_processor_get_power_info_default_c1 (struct acpi_processor *pr)
+static int acpi_processor_get_power_info_default_c1(struct acpi_processor *pr)
 {
 	int i;
 
 	ACPI_FUNCTION_TRACE("acpi_processor_get_power_info_default_c1");
 
 	for (i = 0; i < ACPI_PROCESSOR_MAX_POWER; i++)
-		memset(&(pr->power.states[i]), 0, 
+		memset(&(pr->power.states[i]), 0,
 		       sizeof(struct acpi_processor_cx));
 
 	/* if info is obtained from pblk/fadt, type equals state */
@@ -567,14 +566,13 @@ static int acpi_processor_get_power_info_default_c1 (struct acpi_processor *pr)
 	return_VALUE(0);
 }
 
-
-static int acpi_processor_get_power_info_cst (struct acpi_processor *pr)
+static int acpi_processor_get_power_info_cst(struct acpi_processor *pr)
 {
-	acpi_status		status = 0;
-	acpi_integer		count;
-	int			i;
-	struct acpi_buffer	buffer = {ACPI_ALLOCATE_BUFFER, NULL};
-	union acpi_object	*cst;
+	acpi_status status = 0;
+	acpi_integer count;
+	int i;
+	struct acpi_buffer buffer = { ACPI_ALLOCATE_BUFFER, NULL };
+	union acpi_object *cst;
 
 	ACPI_FUNCTION_TRACE("acpi_processor_get_power_info_cst");
 
@@ -583,20 +581,21 @@ static int acpi_processor_get_power_info_cst (struct acpi_processor *pr)
 
 	pr->power.count = 0;
 	for (i = 0; i < ACPI_PROCESSOR_MAX_POWER; i++)
-		memset(&(pr->power.states[i]), 0, 
+		memset(&(pr->power.states[i]), 0,
 		       sizeof(struct acpi_processor_cx));
 
 	status = acpi_evaluate_object(pr->handle, "_CST", NULL, &buffer);
 	if (ACPI_FAILURE(status)) {
 		ACPI_DEBUG_PRINT((ACPI_DB_INFO, "No _CST, giving up\n"));
 		return_VALUE(-ENODEV);
- 	}
+	}
 
-	cst = (union acpi_object *) buffer.pointer;
+	cst = (union acpi_object *)buffer.pointer;
 
 	/* There must be at least 2 elements */
 	if (!cst || (cst->type != ACPI_TYPE_PACKAGE) || cst->package.count < 2) {
-		ACPI_DEBUG_PRINT((ACPI_DB_ERROR, "not enough elements in _CST\n"));
+		ACPI_DEBUG_PRINT((ACPI_DB_ERROR,
+				  "not enough elements in _CST\n"));
 		status = -EFAULT;
 		goto end;
 	}
@@ -605,15 +604,19 @@ static int acpi_processor_get_power_info_cst (struct acpi_processor *pr)
 
 	/* Validate number of power states. */
 	if (count < 1 || count != cst->package.count - 1) {
-		ACPI_DEBUG_PRINT((ACPI_DB_ERROR, "count given by _CST is not valid\n"));
+		ACPI_DEBUG_PRINT((ACPI_DB_ERROR,
+				  "count given by _CST is not valid\n"));
 		status = -EFAULT;
 		goto end;
 	}
 
 	/* We support up to ACPI_PROCESSOR_MAX_POWER. */
 	if (count > ACPI_PROCESSOR_MAX_POWER) {
-		printk(KERN_WARNING "Limiting number of power states to max (%d)\n", ACPI_PROCESSOR_MAX_POWER);
-		printk(KERN_WARNING "Please increase ACPI_PROCESSOR_MAX_POWER if needed.\n");
+		printk(KERN_WARNING
+		       "Limiting number of power states to max (%d)\n",
+		       ACPI_PROCESSOR_MAX_POWER);
+		printk(KERN_WARNING
+		       "Please increase ACPI_PROCESSOR_MAX_POWER if needed.\n");
 		count = ACPI_PROCESSOR_MAX_POWER;
 	}
 
@@ -628,29 +631,29 @@ static int acpi_processor_get_power_info_cst (struct acpi_processor *pr)
 
 		memset(&cx, 0, sizeof(cx));
 
-		element = (union acpi_object *) &(cst->package.elements[i]);
+		element = (union acpi_object *)&(cst->package.elements[i]);
 		if (element->type != ACPI_TYPE_PACKAGE)
 			continue;
 
 		if (element->package.count != 4)
 			continue;
 
-		obj = (union acpi_object *) &(element->package.elements[0]);
+		obj = (union acpi_object *)&(element->package.elements[0]);
 
 		if (obj->type != ACPI_TYPE_BUFFER)
 			continue;
 
-		reg = (struct acpi_power_register *) obj->buffer.pointer;
+		reg = (struct acpi_power_register *)obj->buffer.pointer;
 
 		if (reg->space_id != ACPI_ADR_SPACE_SYSTEM_IO &&
-			(reg->space_id != ACPI_ADR_SPACE_FIXED_HARDWARE))
+		    (reg->space_id != ACPI_ADR_SPACE_FIXED_HARDWARE))
 			continue;
 
 		cx.address = (reg->space_id == ACPI_ADR_SPACE_FIXED_HARDWARE) ?
-			0 : reg->address;
+		    0 : reg->address;
 
 		/* There should be an easy way to extract an integer... */
-		obj = (union acpi_object *) &(element->package.elements[1]);
+		obj = (union acpi_object *)&(element->package.elements[1]);
 		if (obj->type != ACPI_TYPE_INTEGER)
 			continue;
 
@@ -660,17 +663,16 @@ static int acpi_processor_get_power_info_cst (struct acpi_processor *pr)
 		    (reg->space_id != ACPI_ADR_SPACE_SYSTEM_IO))
 			continue;
 
-		if ((cx.type < ACPI_STATE_C1) ||
-		    (cx.type > ACPI_STATE_C3))
+		if ((cx.type < ACPI_STATE_C1) || (cx.type > ACPI_STATE_C3))
 			continue;
 
-		obj = (union acpi_object *) &(element->package.elements[2]);
+		obj = (union acpi_object *)&(element->package.elements[2]);
 		if (obj->type != ACPI_TYPE_INTEGER)
 			continue;
 
 		cx.latency = obj->integer.value;
 
-		obj = (union acpi_object *) &(element->package.elements[3]);
+		obj = (union acpi_object *)&(element->package.elements[3]);
 		if (obj->type != ACPI_TYPE_INTEGER)
 			continue;
 
@@ -680,19 +682,19 @@ static int acpi_processor_get_power_info_cst (struct acpi_processor *pr)
 		memcpy(&(pr->power.states[pr->power.count]), &cx, sizeof(cx));
 	}
 
-	ACPI_DEBUG_PRINT((ACPI_DB_INFO, "Found %d power states\n", pr->power.count));
+	ACPI_DEBUG_PRINT((ACPI_DB_INFO, "Found %d power states\n",
+			  pr->power.count));
 
 	/* Validate number of power states discovered */
 	if (pr->power.count < 2)
 		status = -ENODEV;
 
-end:
+      end:
 	acpi_os_free(buffer.pointer);
 
 	return_VALUE(status);
 }
 
-
 static void acpi_processor_power_verify_c2(struct acpi_processor_cx *cx)
 {
 	ACPI_FUNCTION_TRACE("acpi_processor_get_power_verify_c2");
@@ -706,8 +708,7 @@ static void acpi_processor_power_verify_c2(struct acpi_processor_cx *cx)
 	 */
 	else if (cx->latency > ACPI_PROCESSOR_MAX_C2_LATENCY) {
 		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
-				  "latency too large [%d]\n",
-				  cx->latency));
+				  "latency too large [%d]\n", cx->latency));
 		return_VOID;
 	}
 
@@ -721,10 +722,8 @@ static void acpi_processor_power_verify_c2(struct acpi_processor_cx *cx)
 	return_VOID;
 }
 
-
-static void acpi_processor_power_verify_c3(
-	struct acpi_processor *pr,
-	struct acpi_processor_cx *cx)
+static void acpi_processor_power_verify_c3(struct acpi_processor *pr,
+					   struct acpi_processor_cx *cx)
 {
 	static int bm_check_flag;
 
@@ -739,8 +738,7 @@ static void acpi_processor_power_verify_c3(
 	 */
 	else if (cx->latency > ACPI_PROCESSOR_MAX_C3_LATENCY) {
 		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
-				  "latency too large [%d]\n",
-				  cx->latency));
+				  "latency too large [%d]\n", cx->latency));
 		return_VOID;
 	}
 
@@ -753,7 +751,7 @@ static void acpi_processor_power_verify_c3(
 	 */
 	else if (errata.piix4.fdma) {
 		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
-			"C3 not supported on PIIX4 with Type-F DMA\n"));
+				  "C3 not supported on PIIX4 with Type-F DMA\n"));
 		return_VOID;
 	}
 
@@ -770,7 +768,7 @@ static void acpi_processor_power_verify_c3(
 		/* bus mastering control is necessary */
 		if (!pr->flags.bm_control) {
 			ACPI_DEBUG_PRINT((ACPI_DB_INFO,
-			  "C3 support requires bus mastering control\n"));
+					  "C3 support requires bus mastering control\n"));
 			return_VOID;
 		}
 	} else {
@@ -780,12 +778,12 @@ static void acpi_processor_power_verify_c3(
 		 */
 		if (acpi_fadt.wb_invd != 1) {
 			ACPI_DEBUG_PRINT((ACPI_DB_INFO,
-			  "Cache invalidation should work properly"
-			  " for C3 to be enabled on SMP systems\n"));
+					  "Cache invalidation should work properly"
+					  " for C3 to be enabled on SMP systems\n"));
 			return_VOID;
 		}
 		acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD,
-				0, ACPI_MTX_DO_NOT_LOCK);
+				  0, ACPI_MTX_DO_NOT_LOCK);
 	}
 
 	/*
@@ -800,13 +798,12 @@ static void acpi_processor_power_verify_c3(
 	return_VOID;
 }
 
-
 static int acpi_processor_power_verify(struct acpi_processor *pr)
 {
 	unsigned int i;
 	unsigned int working = 0;
 
-	for (i=1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
+	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
 		struct acpi_processor_cx *cx = &pr->power.states[i];
 
 		switch (cx->type) {
@@ -830,8 +827,7 @@ static int acpi_processor_power_verify(struct acpi_processor *pr)
 	return (working);
 }
 
-static int acpi_processor_get_power_info (
-	struct acpi_processor	*pr)
+static int acpi_processor_get_power_info(struct acpi_processor *pr)
 {
 	unsigned int i;
 	int result;
@@ -874,16 +870,16 @@ static int acpi_processor_get_power_info (
 	return_VALUE(0);
 }
 
-int acpi_processor_cst_has_changed (struct acpi_processor *pr)
+int acpi_processor_cst_has_changed(struct acpi_processor *pr)
 {
- 	int			result = 0;
+	int result = 0;
 
 	ACPI_FUNCTION_TRACE("acpi_processor_cst_has_changed");
 
 	if (!pr)
- 		return_VALUE(-EINVAL);
+		return_VALUE(-EINVAL);
 
-	if ( nocst) {
+	if (nocst) {
 		return_VALUE(-ENODEV);
 	}
 
@@ -892,7 +888,7 @@ int acpi_processor_cst_has_changed (struct acpi_processor *pr)
 
 	/* Fall back to the default idle loop */
 	pm_idle = pm_idle_save;
-	synchronize_sched();  /* Relies on interrupts forcing exit from idle. */
+	synchronize_sched();	/* Relies on interrupts forcing exit from idle. */
 
 	pr->flags.power = 0;
 	result = acpi_processor_get_power_info(pr);
@@ -906,8 +902,8 @@ int acpi_processor_cst_has_changed (struct acpi_processor *pr)
 
 static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
 {
-	struct acpi_processor	*pr = (struct acpi_processor *)seq->private;
-	unsigned int		i;
+	struct acpi_processor *pr = (struct acpi_processor *)seq->private;
+	unsigned int i;
 
 	ACPI_FUNCTION_TRACE("acpi_processor_power_seq_show");
 
@@ -915,17 +911,17 @@ static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
 		goto end;
 
 	seq_printf(seq, "active state:            C%zd\n"
-			"max_cstate:              C%d\n"
-			"bus master activity:     %08x\n",
-			pr->power.state ? pr->power.state - pr->power.states : 0,
-			max_cstate,
-			(unsigned)pr->power.bm_activity);
+		   "max_cstate:              C%d\n"
+		   "bus master activity:     %08x\n",
+		   pr->power.state ? pr->power.state - pr->power.states : 0,
+		   max_cstate, (unsigned)pr->power.bm_activity);
 
 	seq_puts(seq, "states:\n");
 
 	for (i = 1; i <= pr->power.count; i++) {
 		seq_printf(seq, "   %cC%d:                  ",
-			(&pr->power.states[i] == pr->power.state?'*':' '), i);
+			   (&pr->power.states[i] ==
+			    pr->power.state ? '*' : ' '), i);
 
 		if (!pr->power.states[i].valid) {
 			seq_puts(seq, "<not supported>\n");
@@ -949,45 +945,46 @@ static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
 
 		if (pr->power.states[i].promotion.state)
 			seq_printf(seq, "promotion[C%zd] ",
-				(pr->power.states[i].promotion.state -
-				 pr->power.states));
+				   (pr->power.states[i].promotion.state -
+				    pr->power.states));
 		else
 			seq_puts(seq, "promotion[--] ");
 
 		if (pr->power.states[i].demotion.state)
 			seq_printf(seq, "demotion[C%zd] ",
-				(pr->power.states[i].demotion.state -
-				 pr->power.states));
+				   (pr->power.states[i].demotion.state -
+				    pr->power.states));
 		else
 			seq_puts(seq, "demotion[--] ");
 
 		seq_printf(seq, "latency[%03d] usage[%08d]\n",
-			pr->power.states[i].latency,
-			pr->power.states[i].usage);
+			   pr->power.states[i].latency,
+			   pr->power.states[i].usage);
 	}
 
-end:
+      end:
 	return_VALUE(0);
 }
 
 static int acpi_processor_power_open_fs(struct inode *inode, struct file *file)
 {
 	return single_open(file, acpi_processor_power_seq_show,
-						PDE(inode)->data);
+			   PDE(inode)->data);
 }
 
 static struct file_operations acpi_processor_power_fops = {
-	.open 		= acpi_processor_power_open_fs,
-	.read		= seq_read,
-	.llseek		= seq_lseek,
-	.release	= single_release,
+	.open = acpi_processor_power_open_fs,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release,
 };
 
-int acpi_processor_power_init(struct acpi_processor *pr, struct acpi_device *device)
+int acpi_processor_power_init(struct acpi_processor *pr,
+			      struct acpi_device *device)
 {
-	acpi_status		status = 0;
-	static int		first_run = 0;
-	struct proc_dir_entry	*entry = NULL;
+	acpi_status status = 0;
+	static int first_run = 0;
+	struct proc_dir_entry *entry = NULL;
 	unsigned int i;
 
 	ACPI_FUNCTION_TRACE("acpi_processor_power_init");
@@ -995,7 +992,9 @@ int acpi_processor_power_init(struct acpi_processor *pr, struct acpi_device *dev
 	if (!first_run) {
 		dmi_check_system(processor_power_dmi_table);
 		if (max_cstate < ACPI_C_STATES_MAX)
-			printk(KERN_NOTICE "ACPI: processor limited to max C-state %d\n", max_cstate);
+			printk(KERN_NOTICE
+			       "ACPI: processor limited to max C-state %d\n",
+			       max_cstate);
 		first_run++;
 	}
 
@@ -1003,7 +1002,8 @@ int acpi_processor_power_init(struct acpi_processor *pr, struct acpi_device *dev
 		return_VALUE(-EINVAL);
 
 	if (acpi_fadt.cst_cnt && !nocst) {
-		status = acpi_os_write_port(acpi_fadt.smi_cmd, acpi_fadt.cst_cnt, 8);
+		status =
+		    acpi_os_write_port(acpi_fadt.smi_cmd, acpi_fadt.cst_cnt, 8);
 		if (ACPI_FAILURE(status)) {
 			ACPI_DEBUG_PRINT((ACPI_DB_ERROR,
 					  "Notifying BIOS of _CST ability failed\n"));
@@ -1023,7 +1023,8 @@ int acpi_processor_power_init(struct acpi_processor *pr, struct acpi_device *dev
 		printk(KERN_INFO PREFIX "CPU%d (power states:", pr->id);
 		for (i = 1; i <= pr->power.count; i++)
 			if (pr->power.states[i].valid)
-				printk(" C%d[C%d]", i, pr->power.states[i].type);
+				printk(" C%d[C%d]", i,
+				       pr->power.states[i].type);
 		printk(")\n");
 
 		if (pr->id == 0) {
@@ -1034,11 +1035,11 @@ int acpi_processor_power_init(struct acpi_processor *pr, struct acpi_device *dev
 
 	/* 'power' [R] */
 	entry = create_proc_entry(ACPI_PROCESSOR_FILE_POWER,
-		S_IRUGO, acpi_device_dir(device));
+				  S_IRUGO, acpi_device_dir(device));
 	if (!entry)
 		ACPI_DEBUG_PRINT((ACPI_DB_ERROR,
-			"Unable to create '%s' fs entry\n",
-			ACPI_PROCESSOR_FILE_POWER));
+				  "Unable to create '%s' fs entry\n",
+				  ACPI_PROCESSOR_FILE_POWER));
 	else {
 		entry->proc_fops = &acpi_processor_power_fops;
 		entry->data = acpi_driver_data(device);
@@ -1050,14 +1051,16 @@ int acpi_processor_power_init(struct acpi_processor *pr, struct acpi_device *dev
 	return_VALUE(0);
 }
 
-int acpi_processor_power_exit(struct acpi_processor *pr, struct acpi_device *device)
+int acpi_processor_power_exit(struct acpi_processor *pr,
+			      struct acpi_device *device)
 {
 	ACPI_FUNCTION_TRACE("acpi_processor_power_exit");
 
 	pr->flags.power_setup_done = 0;
 
 	if (acpi_device_dir(device))
-		remove_proc_entry(ACPI_PROCESSOR_FILE_POWER,acpi_device_dir(device));
+		remove_proc_entry(ACPI_PROCESSOR_FILE_POWER,
+				  acpi_device_dir(device));
 
 	/* Unregister the idle handler when processor #0 is removed. */
 	if (pr->id == 0) {

commit 8066eff0a1a0703ad901dbe5646a47dbfc089ef2
Merge: 9a351e30d72d 79cda7d0e1c8
Author: Len Brown <len.brown@intel.com>
Date:   Wed Aug 3 18:15:15 2005 -0400

    /home/lenb/src/to-linus branch 'acpi-2.6.12'

commit 3d35600a9de8e2816d0e3726f64b7271af6fdda4
Author: Len Brown <len.brown@intel.com>
Date:   Wed Aug 3 00:22:52 2005 -0400

    [ACPI] fix 64-bit build warning in processor_idle.c
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index fd5458947851..8f7836678b29 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -86,12 +86,11 @@ static int set_max_cstate(struct dmi_system_id *id)
 	if (max_cstate > ACPI_PROCESSOR_MAX_POWER)
 		return 0;
 
-	printk(KERN_NOTICE PREFIX "%s detected - %s disabled."
+	printk(KERN_NOTICE PREFIX "%s detected - limiting to C%ld max_cstate."
 		" Override with \"processor.max_cstate=%d\"\n", id->ident,
-		((int)id->driver_data == 1)? "C2,C3":"C3",
-	       ACPI_PROCESSOR_MAX_POWER + 1);
+		(long)id->driver_data, ACPI_PROCESSOR_MAX_POWER + 1);
 
-	max_cstate = (int)id->driver_data;
+	max_cstate = (long)id->driver_data;
 
 	return 0;
 }

commit d6ac1a7910d22626bc77e73db091e00b810715f4
Merge: 577a4f8102d5 87bec66b9691
Author: Len Brown <len.brown@intel.com>
Date:   Fri Jul 29 23:31:17 2005 -0400

    /home/lenb/src/to-linus branch 'acpi-2.6.12'

commit 68ac767686fd72f37a25bb4895fb4ab0080ba755
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon Apr 25 14:38:00 2005 -0400

    [ACPI] delete boot-time printk()s from processor_idle.c
    
    http://bugzilla.kernel.org/show_bug.cgi?id=4401
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 3702725db97a..fd5458947851 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -768,7 +768,6 @@ static void acpi_processor_power_verify_c3(
 	}
 
 	if (pr->flags.bm_check) {
-		printk("Disabling BM access before entering C3\n");
 		/* bus mastering control is necessary */
 		if (!pr->flags.bm_control) {
 			ACPI_DEBUG_PRINT((ACPI_DB_INFO,
@@ -776,7 +775,6 @@ static void acpi_processor_power_verify_c3(
 			return_VOID;
 		}
 	} else {
-		printk("Invalidating cache before entering C3\n");
 		/*
 		 * WBINVD should be set in fadt, for C3 state to be
 		 * supported on when bm_check is not required.

commit 335f16be5d917334f56ec9ef7ecf983476ac0563
Author: David Shaohua Li <shaohua.li@intel.com>
Date:   Wed Jun 22 18:37:00 2005 -0400

    [ACPI] address boot-freeze with updated DMI blacklist for c-states
    
    http://bugzilla.kernel.org/show_bug.cgi?id=4763
    
    Signed-off-by: David Shaohua Li <shaohua.li@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 42b34f5df98b..3702725db97a 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -81,30 +81,33 @@ module_param(bm_history, uint, 0644);
  *
  * To skip this limit, boot/load with a large max_cstate limit.
  */
-static int no_c2c3(struct dmi_system_id *id)
+static int set_max_cstate(struct dmi_system_id *id)
 {
 	if (max_cstate > ACPI_PROCESSOR_MAX_POWER)
 		return 0;
 
-	printk(KERN_NOTICE PREFIX "%s detected - C2,C3 disabled."
+	printk(KERN_NOTICE PREFIX "%s detected - %s disabled."
 		" Override with \"processor.max_cstate=%d\"\n", id->ident,
+		((int)id->driver_data == 1)? "C2,C3":"C3",
 	       ACPI_PROCESSOR_MAX_POWER + 1);
 
-	max_cstate = 1;
+	max_cstate = (int)id->driver_data;
 
 	return 0;
 }
 
 
-
-
 static struct dmi_system_id __initdata processor_power_dmi_table[] = {
-	{ no_c2c3, "IBM ThinkPad R40e", {
+	{ set_max_cstate, "IBM ThinkPad R40e", {
 	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"1SET60WW") }},
-	{ no_c2c3, "Medion 41700", {
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET60WW") }, (void*)1},
+	{ set_max_cstate, "Medion 41700", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"Phoenix Technologies LTD"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"R01-A1J") }, (void*)1},
+	{ set_max_cstate, "Clevo 5600D", {
 	  DMI_MATCH(DMI_BIOS_VENDOR,"Phoenix Technologies LTD"),
-	  DMI_MATCH(DMI_BIOS_VERSION,"R01-A1J") }},
+	  DMI_MATCH(DMI_BIOS_VERSION,"SHE845M0.86C.0013.D.0302131307") },
+	  (void*)2},
 	{},
 };
 

commit 0b6b2f08c24a65535cb18893ca27516389c5fc0f
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Fri Jul 29 16:00:13 2005 -0400

    [ACPI] Fix memset arguments in acpi processor_idle.c
    
    http://bugzilla.kernel.org/show_bug.cgi?id=4954
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index aea745f4a8b0..42b34f5df98b 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -549,7 +549,8 @@ static int acpi_processor_get_power_info_default_c1 (struct acpi_processor *pr)
 	ACPI_FUNCTION_TRACE("acpi_processor_get_power_info_default_c1");
 
 	for (i = 0; i < ACPI_PROCESSOR_MAX_POWER; i++)
-		memset(pr->power.states, 0, sizeof(struct acpi_processor_cx));
+		memset(&(pr->power.states[i]), 0, 
+		       sizeof(struct acpi_processor_cx));
 
 	/* if info is obtained from pblk/fadt, type equals state */
 	pr->power.states[ACPI_STATE_C1].type = ACPI_STATE_C1;
@@ -580,7 +581,8 @@ static int acpi_processor_get_power_info_cst (struct acpi_processor *pr)
 
 	pr->power.count = 0;
 	for (i = 0; i < ACPI_PROCESSOR_MAX_POWER; i++)
-		memset(pr->power.states, 0, sizeof(struct acpi_processor_cx));
+		memset(&(pr->power.states[i]), 0, 
+		       sizeof(struct acpi_processor_cx));
 
 	status = acpi_evaluate_object(pr->handle, "_CST", NULL, &buffer);
 	if (ACPI_FAILURE(status)) {

commit 4a7164023959040e687e51663dee67cff4d2b770
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Fri Jul 29 15:51:36 2005 -0400

    [ACPI] Fix the regression with c1_default_handler on some systems
    where C-states come from FADT.
    
    Thanks to Kevin Radloff for identifying the issue and
    isolating it to exact line of code that is causing the issue.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 8f038cd29477..aea745f4a8b0 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -842,7 +842,7 @@ static int acpi_processor_get_power_info (
 	result = acpi_processor_get_power_info_cst(pr);
 	if ((result) || (acpi_processor_power_verify(pr) < 2)) {
 		result = acpi_processor_get_power_info_fadt(pr);
-		if (result)
+		if ((result) || (acpi_processor_power_verify(pr) < 2))
 			result = acpi_processor_get_power_info_default_c1(pr);
 	}
 

commit 5028770a42e7bc4d15791a44c28f0ad539323807
Merge: 9f02d6b7b43d d8683a0cb5d0
Author: Len Brown <len.brown@intel.com>
Date:   Tue Jul 12 17:21:56 2005 -0400

    [ACPI] merge acpi-2.6.12 branch into latest Linux 2.6.13-rc...
    
    Signed-off-by: Len Brown <len.brown@intel.com>

commit 02df8b9385c21fdba165bd380f60eca1d3b0578b
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Fri Apr 15 15:07:10 2005 -0400

    [ACPI] enable C2 and C3 idle power states on SMP
    http://bugzilla.kernel.org/show_bug.cgi?id=4401
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 79d5ca3066c6..8f038cd29477 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -6,6 +6,8 @@
  *  Copyright (C) 2004       Dominik Brodowski <linux@brodo.de>
  *  Copyright (C) 2004  Anil S Keshavamurthy <anil.s.keshavamurthy@intel.com>
  *  			- Added processor hotplug support
+ *  Copyright (C) 2005  Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
+ *  			- Added support for C3 on SMP
  *
  * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  *
@@ -142,7 +144,7 @@ acpi_processor_power_activate (
 		switch (old->type) {
 		case ACPI_STATE_C3:
 			/* Disable bus master reload */
-			if (new->type != ACPI_STATE_C3)
+			if (new->type != ACPI_STATE_C3 && pr->flags.bm_check)
 				acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 0, ACPI_MTX_DO_NOT_LOCK);
 			break;
 		}
@@ -152,7 +154,7 @@ acpi_processor_power_activate (
 	switch (new->type) {
 	case ACPI_STATE_C3:
 		/* Enable bus master reload */
-		if (old->type != ACPI_STATE_C3)
+		if (old->type != ACPI_STATE_C3 && pr->flags.bm_check)
 			acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 1, ACPI_MTX_DO_NOT_LOCK);
 		break;
 	}
@@ -163,6 +165,9 @@ acpi_processor_power_activate (
 }
 
 
+static atomic_t 	c3_cpu_count;
+
+
 static void acpi_processor_idle (void)
 {
 	struct acpi_processor	*pr = NULL;
@@ -297,8 +302,22 @@ static void acpi_processor_idle (void)
 		break;
 
 	case ACPI_STATE_C3:
-		/* Disable bus master arbitration */
-		acpi_set_register(ACPI_BITREG_ARB_DISABLE, 1, ACPI_MTX_DO_NOT_LOCK);
+		
+		if (pr->flags.bm_check) {
+			if (atomic_inc_return(&c3_cpu_count) ==
+					num_online_cpus()) {
+				/*
+				 * All CPUs are trying to go to C3
+				 * Disable bus master arbitration
+				 */
+				acpi_set_register(ACPI_BITREG_ARB_DISABLE, 1,
+					ACPI_MTX_DO_NOT_LOCK);
+			}
+		} else {
+			/* SMP with no shared cache... Invalidate cache  */
+			ACPI_FLUSH_CPU_CACHE();
+		}
+		
 		/* Get start time (ticks) */
 		t1 = inl(acpi_fadt.xpm_tmr_blk.address);
 		/* Invoke C3 */
@@ -307,8 +326,12 @@ static void acpi_processor_idle (void)
 		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
 		/* Get end time (ticks) */
 		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
-		/* Enable bus master arbitration */
-		acpi_set_register(ACPI_BITREG_ARB_DISABLE, 0, ACPI_MTX_DO_NOT_LOCK);
+		if (pr->flags.bm_check) {
+			/* Enable bus master arbitration */
+			atomic_dec(&c3_cpu_count);
+			acpi_set_register(ACPI_BITREG_ARB_DISABLE, 0, ACPI_MTX_DO_NOT_LOCK);
+		}
+
 		/* Re-enable interrupts */
 		local_irq_enable();
 		/* Compute time (ticks) that we were actually asleep */
@@ -552,9 +575,6 @@ static int acpi_processor_get_power_info_cst (struct acpi_processor *pr)
 
 	ACPI_FUNCTION_TRACE("acpi_processor_get_power_info_cst");
 
-	if (errata.smp)
-		return_VALUE(-ENODEV);
-
 	if (nocst)
 		return_VALUE(-ENODEV);
 
@@ -687,13 +707,6 @@ static void acpi_processor_power_verify_c2(struct acpi_processor_cx *cx)
 		return_VOID;
 	}
 
-	/* We're (currently) only supporting C2 on UP */
-	else if (errata.smp) {
-		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
-				  "C2 not supported in SMP mode\n"));
-		return_VOID;
-	}
-
 	/*
 	 * Otherwise we've met all of our C2 requirements.
 	 * Normalize the C2 latency to expidite policy
@@ -709,6 +722,8 @@ static void acpi_processor_power_verify_c3(
 	struct acpi_processor *pr,
 	struct acpi_processor_cx *cx)
 {
+	static int bm_check_flag;
+
 	ACPI_FUNCTION_TRACE("acpi_processor_get_power_verify_c3");
 
 	if (!cx->address)
@@ -725,20 +740,6 @@ static void acpi_processor_power_verify_c3(
 		return_VOID;
 	}
 
-	/* bus mastering control is necessary */
-	else if (!pr->flags.bm_control) {
-		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
-				  "C3 support requires bus mastering control\n"));
-		return_VOID;
-	}
-
-	/* We're (currently) only supporting C2 on UP */
-	else if (errata.smp) {
-		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
-				  "C3 not supported in SMP mode\n"));
-		return_VOID;
-	}
-
 	/*
 	 * PIIX4 Erratum #18: We don't support C3 when Type-F (fast)
 	 * DMA transfers are used by any ISA device to avoid livelock.
@@ -752,6 +753,39 @@ static void acpi_processor_power_verify_c3(
 		return_VOID;
 	}
 
+	/* All the logic here assumes flags.bm_check is same across all CPUs */
+	if (!bm_check_flag) {
+		/* Determine whether bm_check is needed based on CPU  */
+		acpi_processor_power_init_bm_check(&(pr->flags), pr->id);
+		bm_check_flag = pr->flags.bm_check;
+	} else {
+		pr->flags.bm_check = bm_check_flag;
+	}
+
+	if (pr->flags.bm_check) {
+		printk("Disabling BM access before entering C3\n");
+		/* bus mastering control is necessary */
+		if (!pr->flags.bm_control) {
+			ACPI_DEBUG_PRINT((ACPI_DB_INFO,
+			  "C3 support requires bus mastering control\n"));
+			return_VOID;
+		}
+	} else {
+		printk("Invalidating cache before entering C3\n");
+		/*
+		 * WBINVD should be set in fadt, for C3 state to be
+		 * supported on when bm_check is not required.
+		 */
+		if (acpi_fadt.wb_invd != 1) {
+			ACPI_DEBUG_PRINT((ACPI_DB_INFO,
+			  "Cache invalidation should work properly"
+			  " for C3 to be enabled on SMP systems\n"));
+			return_VOID;
+		}
+		acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD,
+				0, ACPI_MTX_DO_NOT_LOCK);
+	}
+
 	/*
 	 * Otherwise we've met all of our C3 requirements.
 	 * Normalize the C3 latency to expidite policy.  Enable
@@ -760,7 +794,6 @@ static void acpi_processor_power_verify_c3(
 	 */
 	cx->valid = 1;
 	cx->latency_ticks = US_TO_PM_TIMER_TICKS(cx->latency);
-	pr->flags.bm_check = 1;
 
 	return_VOID;
 }
@@ -848,7 +881,7 @@ int acpi_processor_cst_has_changed (struct acpi_processor *pr)
 	if (!pr)
  		return_VALUE(-EINVAL);
 
-	if (errata.smp || nocst) {
+	if ( nocst) {
 		return_VALUE(-ENODEV);
 	}
 
@@ -948,7 +981,6 @@ static struct file_operations acpi_processor_power_fops = {
 	.release	= single_release,
 };
 
-
 int acpi_processor_power_init(struct acpi_processor *pr, struct acpi_device *device)
 {
 	acpi_status		status = 0;
@@ -965,7 +997,10 @@ int acpi_processor_power_init(struct acpi_processor *pr, struct acpi_device *dev
 		first_run++;
 	}
 
-	if (!errata.smp && (pr->id == 0) && acpi_fadt.cst_cnt && !nocst) {
+	if (!pr)
+		return_VALUE(-EINVAL);
+
+	if (acpi_fadt.cst_cnt && !nocst) {
 		status = acpi_os_write_port(acpi_fadt.smi_cmd, acpi_fadt.cst_cnt, 8);
 		if (ACPI_FAILURE(status)) {
 			ACPI_DEBUG_PRINT((ACPI_DB_ERROR,
@@ -973,6 +1008,8 @@ int acpi_processor_power_init(struct acpi_processor *pr, struct acpi_device *dev
 		}
 	}
 
+	acpi_processor_power_init_pdc(&(pr->power), pr->id);
+	acpi_processor_set_pdc(pr, pr->power.pdc);
 	acpi_processor_get_power_info(pr);
 
 	/*

commit acf05f4b7f558051ea0028e8e617144123650272
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Thu Mar 31 23:23:15 2005 -0500

    [ACPI] update /proc/acpi/processor/*/power even if only C1 support
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index ff64d333e95f..79d5ca3066c6 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -519,6 +519,29 @@ static int acpi_processor_get_power_info_fadt (struct acpi_processor *pr)
 }
 
 
+static int acpi_processor_get_power_info_default_c1 (struct acpi_processor *pr)
+{
+	int i;
+
+	ACPI_FUNCTION_TRACE("acpi_processor_get_power_info_default_c1");
+
+	for (i = 0; i < ACPI_PROCESSOR_MAX_POWER; i++)
+		memset(pr->power.states, 0, sizeof(struct acpi_processor_cx));
+
+	/* if info is obtained from pblk/fadt, type equals state */
+	pr->power.states[ACPI_STATE_C1].type = ACPI_STATE_C1;
+	pr->power.states[ACPI_STATE_C2].type = ACPI_STATE_C2;
+	pr->power.states[ACPI_STATE_C3].type = ACPI_STATE_C3;
+
+	/* the C0 state only exists as a filler in our array,
+	 * and all processors need to support C1 */
+	pr->power.states[ACPI_STATE_C0].valid = 1;
+	pr->power.states[ACPI_STATE_C1].valid = 1;
+
+	return_VALUE(0);
+}
+
+
 static int acpi_processor_get_power_info_cst (struct acpi_processor *pr)
 {
 	acpi_status		status = 0;
@@ -787,10 +810,7 @@ static int acpi_processor_get_power_info (
 	if ((result) || (acpi_processor_power_verify(pr) < 2)) {
 		result = acpi_processor_get_power_info_fadt(pr);
 		if (result)
-			return_VALUE(result);
-
-		if (acpi_processor_power_verify(pr) < 2)
-			return_VALUE(-ENODEV);
+			result = acpi_processor_get_power_info_default_c1(pr);
 	}
 
 	/*
@@ -810,11 +830,10 @@ static int acpi_processor_get_power_info (
 	 * CPU as being "idle manageable"
 	 */
 	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
-		if (pr->power.states[i].valid)
+		if (pr->power.states[i].valid) {
 			pr->power.count = i;
-		if ((pr->power.states[i].valid) &&
-		    (pr->power.states[i].type >= ACPI_STATE_C2))
 			pr->flags.power = 1;
+		}
 	}
 
 	return_VALUE(0);

commit 39c715b71740c4a78ba4769fb54826929bac03cb
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Jun 21 17:14:34 2005 -0700

    [PATCH] smp_processor_id() cleanup
    
    This patch implements a number of smp_processor_id() cleanup ideas that
    Arjan van de Ven and I came up with.
    
    The previous __smp_processor_id/_smp_processor_id/smp_processor_id API
    spaghetti was hard to follow both on the implementational and on the
    usage side.
    
    Some of the complexity arose from picking wrong names, some of the
    complexity comes from the fact that not all architectures defined
    __smp_processor_id.
    
    In the new code, there are two externally visible symbols:
    
     - smp_processor_id(): debug variant.
    
     - raw_smp_processor_id(): nondebug variant. Replaces all existing
       uses of _smp_processor_id() and __smp_processor_id(). Defined
       by every SMP architecture in include/asm-*/smp.h.
    
    There is one new internal symbol, dependent on DEBUG_PREEMPT:
    
     - debug_smp_processor_id(): internal debug variant, mapped to
                                 smp_processor_id().
    
    Also, i moved debug_smp_processor_id() from lib/kernel_lock.c into a new
    lib/smp_processor_id.c file.  All related comments got updated and/or
    clarified.
    
    I have build/boot tested the following 8 .config combinations on x86:
    
     {SMP,UP} x {PREEMPT,!PREEMPT} x {DEBUG_PREEMPT,!DEBUG_PREEMPT}
    
    I have also build/boot tested x64 on UP/PREEMPT/DEBUG_PREEMPT.  (Other
    architectures are untested, but should work just fine.)
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Arjan van de Ven <arjan@infradead.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index ff64d333e95f..c9d671cf7857 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -171,7 +171,7 @@ static void acpi_processor_idle (void)
 	int			sleep_ticks = 0;
 	u32			t1, t2 = 0;
 
-	pr = processors[_smp_processor_id()];
+	pr = processors[raw_smp_processor_id()];
 	if (!pr)
 		return;
 

commit fbd568a3e61a7decb8a754ad952aaa5b5c82e9e5
Author: Paul E. McKenney <paulmck@us.ibm.com>
Date:   Sun May 1 08:59:04 2005 -0700

    [PATCH] Change synchronize_kernel to _rcu and _sched
    
    This patch changes calls to synchronize_kernel(), deprecated in the earlier
    "Deprecate synchronize_kernel, GPL replacement" patch to instead call the new
    synchronize_rcu() and synchronize_sched() APIs.
    
    Signed-off-by: Paul E. McKenney <paulmck@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 05a17812d521..ff64d333e95f 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -838,7 +838,7 @@ int acpi_processor_cst_has_changed (struct acpi_processor *pr)
 
 	/* Fall back to the default idle loop */
 	pm_idle = pm_idle_save;
-	synchronize_kernel();
+	synchronize_sched();  /* Relies on interrupts forcing exit from idle. */
 
 	pr->flags.power = 0;
 	result = acpi_processor_get_power_info(pr);

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
new file mode 100644
index 000000000000..05a17812d521
--- /dev/null
+++ b/drivers/acpi/processor_idle.c
@@ -0,0 +1,1017 @@
+/*
+ * processor_idle - idle state submodule to the ACPI processor driver
+ *
+ *  Copyright (C) 2001, 2002 Andy Grover <andrew.grover@intel.com>
+ *  Copyright (C) 2001, 2002 Paul Diefenbaugh <paul.s.diefenbaugh@intel.com>
+ *  Copyright (C) 2004       Dominik Brodowski <linux@brodo.de>
+ *  Copyright (C) 2004  Anil S Keshavamurthy <anil.s.keshavamurthy@intel.com>
+ *  			- Added processor hotplug support
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of the GNU General Public License as published by
+ *  the Free Software Foundation; either version 2 of the License, or (at
+ *  your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful, but
+ *  WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ *  General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  59 Temple Place, Suite 330, Boston, MA 02111-1307 USA.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/cpufreq.h>
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+#include <linux/acpi.h>
+#include <linux/dmi.h>
+#include <linux/moduleparam.h>
+
+#include <asm/io.h>
+#include <asm/uaccess.h>
+
+#include <acpi/acpi_bus.h>
+#include <acpi/processor.h>
+
+#define ACPI_PROCESSOR_COMPONENT        0x01000000
+#define ACPI_PROCESSOR_CLASS            "processor"
+#define ACPI_PROCESSOR_DRIVER_NAME      "ACPI Processor Driver"
+#define _COMPONENT              ACPI_PROCESSOR_COMPONENT
+ACPI_MODULE_NAME                ("acpi_processor")
+
+#define ACPI_PROCESSOR_FILE_POWER	"power"
+
+#define US_TO_PM_TIMER_TICKS(t)		((t * (PM_TIMER_FREQUENCY/1000)) / 1000)
+#define C2_OVERHEAD			4	/* 1us (3.579 ticks per us) */
+#define C3_OVERHEAD			4	/* 1us (3.579 ticks per us) */
+
+static void (*pm_idle_save)(void);
+module_param(max_cstate, uint, 0644);
+
+static unsigned int nocst = 0;
+module_param(nocst, uint, 0000);
+
+/*
+ * bm_history -- bit-mask with a bit per jiffy of bus-master activity
+ * 1000 HZ: 0xFFFFFFFF: 32 jiffies = 32ms
+ * 800 HZ: 0xFFFFFFFF: 32 jiffies = 40ms
+ * 100 HZ: 0x0000000F: 4 jiffies = 40ms
+ * reduce history for more aggressive entry into C3
+ */
+static unsigned int bm_history = (HZ >= 800 ? 0xFFFFFFFF : ((1U << (HZ / 25)) - 1));
+module_param(bm_history, uint, 0644);
+/* --------------------------------------------------------------------------
+                                Power Management
+   -------------------------------------------------------------------------- */
+
+/*
+ * IBM ThinkPad R40e crashes mysteriously when going into C2 or C3.
+ * For now disable this. Probably a bug somewhere else.
+ *
+ * To skip this limit, boot/load with a large max_cstate limit.
+ */
+static int no_c2c3(struct dmi_system_id *id)
+{
+	if (max_cstate > ACPI_PROCESSOR_MAX_POWER)
+		return 0;
+
+	printk(KERN_NOTICE PREFIX "%s detected - C2,C3 disabled."
+		" Override with \"processor.max_cstate=%d\"\n", id->ident,
+	       ACPI_PROCESSOR_MAX_POWER + 1);
+
+	max_cstate = 1;
+
+	return 0;
+}
+
+
+
+
+static struct dmi_system_id __initdata processor_power_dmi_table[] = {
+	{ no_c2c3, "IBM ThinkPad R40e", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"IBM"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"1SET60WW") }},
+	{ no_c2c3, "Medion 41700", {
+	  DMI_MATCH(DMI_BIOS_VENDOR,"Phoenix Technologies LTD"),
+	  DMI_MATCH(DMI_BIOS_VERSION,"R01-A1J") }},
+	{},
+};
+
+
+static inline u32
+ticks_elapsed (
+	u32			t1,
+	u32			t2)
+{
+	if (t2 >= t1)
+		return (t2 - t1);
+	else if (!acpi_fadt.tmr_val_ext)
+		return (((0x00FFFFFF - t1) + t2) & 0x00FFFFFF);
+	else
+		return ((0xFFFFFFFF - t1) + t2);
+}
+
+
+static void
+acpi_processor_power_activate (
+	struct acpi_processor	*pr,
+	struct acpi_processor_cx  *new)
+{
+	struct acpi_processor_cx  *old;
+
+	if (!pr || !new)
+		return;
+
+	old = pr->power.state;
+
+	if (old)
+		old->promotion.count = 0;
+ 	new->demotion.count = 0;
+
+	/* Cleanup from old state. */
+	if (old) {
+		switch (old->type) {
+		case ACPI_STATE_C3:
+			/* Disable bus master reload */
+			if (new->type != ACPI_STATE_C3)
+				acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 0, ACPI_MTX_DO_NOT_LOCK);
+			break;
+		}
+	}
+
+	/* Prepare to use new state. */
+	switch (new->type) {
+	case ACPI_STATE_C3:
+		/* Enable bus master reload */
+		if (old->type != ACPI_STATE_C3)
+			acpi_set_register(ACPI_BITREG_BUS_MASTER_RLD, 1, ACPI_MTX_DO_NOT_LOCK);
+		break;
+	}
+
+	pr->power.state = new;
+
+	return;
+}
+
+
+static void acpi_processor_idle (void)
+{
+	struct acpi_processor	*pr = NULL;
+	struct acpi_processor_cx *cx = NULL;
+	struct acpi_processor_cx *next_state = NULL;
+	int			sleep_ticks = 0;
+	u32			t1, t2 = 0;
+
+	pr = processors[_smp_processor_id()];
+	if (!pr)
+		return;
+
+	/*
+	 * Interrupts must be disabled during bus mastering calculations and
+	 * for C2/C3 transitions.
+	 */
+	local_irq_disable();
+
+	/*
+	 * Check whether we truly need to go idle, or should
+	 * reschedule:
+	 */
+	if (unlikely(need_resched())) {
+		local_irq_enable();
+		return;
+	}
+
+	cx = pr->power.state;
+	if (!cx)
+		goto easy_out;
+
+	/*
+	 * Check BM Activity
+	 * -----------------
+	 * Check for bus mastering activity (if required), record, and check
+	 * for demotion.
+	 */
+	if (pr->flags.bm_check) {
+		u32		bm_status = 0;
+		unsigned long	diff = jiffies - pr->power.bm_check_timestamp;
+
+		if (diff > 32)
+			diff = 32;
+
+		while (diff) {
+			/* if we didn't get called, assume there was busmaster activity */
+			diff--;
+			if (diff)
+				pr->power.bm_activity |= 0x1;
+			pr->power.bm_activity <<= 1;
+		}
+
+		acpi_get_register(ACPI_BITREG_BUS_MASTER_STATUS,
+			&bm_status, ACPI_MTX_DO_NOT_LOCK);
+		if (bm_status) {
+			pr->power.bm_activity++;
+			acpi_set_register(ACPI_BITREG_BUS_MASTER_STATUS,
+				1, ACPI_MTX_DO_NOT_LOCK);
+		}
+		/*
+		 * PIIX4 Erratum #18: Note that BM_STS doesn't always reflect
+		 * the true state of bus mastering activity; forcing us to
+		 * manually check the BMIDEA bit of each IDE channel.
+		 */
+		else if (errata.piix4.bmisx) {
+			if ((inb_p(errata.piix4.bmisx + 0x02) & 0x01)
+				|| (inb_p(errata.piix4.bmisx + 0x0A) & 0x01))
+				pr->power.bm_activity++;
+		}
+
+		pr->power.bm_check_timestamp = jiffies;
+
+		/*
+		 * Apply bus mastering demotion policy.  Automatically demote
+		 * to avoid a faulty transition.  Note that the processor
+		 * won't enter a low-power state during this call (to this
+		 * funciton) but should upon the next.
+		 *
+		 * TBD: A better policy might be to fallback to the demotion
+		 *      state (use it for this quantum only) istead of
+		 *      demoting -- and rely on duration as our sole demotion
+		 *      qualification.  This may, however, introduce DMA
+		 *      issues (e.g. floppy DMA transfer overrun/underrun).
+		 */
+		if (pr->power.bm_activity & cx->demotion.threshold.bm) {
+			local_irq_enable();
+			next_state = cx->demotion.state;
+			goto end;
+		}
+	}
+
+	cx->usage++;
+
+	/*
+	 * Sleep:
+	 * ------
+	 * Invoke the current Cx state to put the processor to sleep.
+	 */
+	switch (cx->type) {
+
+	case ACPI_STATE_C1:
+		/*
+		 * Invoke C1.
+		 * Use the appropriate idle routine, the one that would
+		 * be used without acpi C-states.
+		 */
+		if (pm_idle_save)
+			pm_idle_save();
+		else
+			safe_halt();
+		/*
+                 * TBD: Can't get time duration while in C1, as resumes
+		 *      go to an ISR rather than here.  Need to instrument
+		 *      base interrupt handler.
+		 */
+		sleep_ticks = 0xFFFFFFFF;
+		break;
+
+	case ACPI_STATE_C2:
+		/* Get start time (ticks) */
+		t1 = inl(acpi_fadt.xpm_tmr_blk.address);
+		/* Invoke C2 */
+		inb(cx->address);
+		/* Dummy op - must do something useless after P_LVL2 read */
+		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
+		/* Get end time (ticks) */
+		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
+		/* Re-enable interrupts */
+		local_irq_enable();
+		/* Compute time (ticks) that we were actually asleep */
+		sleep_ticks = ticks_elapsed(t1, t2) - cx->latency_ticks - C2_OVERHEAD;
+		break;
+
+	case ACPI_STATE_C3:
+		/* Disable bus master arbitration */
+		acpi_set_register(ACPI_BITREG_ARB_DISABLE, 1, ACPI_MTX_DO_NOT_LOCK);
+		/* Get start time (ticks) */
+		t1 = inl(acpi_fadt.xpm_tmr_blk.address);
+		/* Invoke C3 */
+		inb(cx->address);
+		/* Dummy op - must do something useless after P_LVL3 read */
+		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
+		/* Get end time (ticks) */
+		t2 = inl(acpi_fadt.xpm_tmr_blk.address);
+		/* Enable bus master arbitration */
+		acpi_set_register(ACPI_BITREG_ARB_DISABLE, 0, ACPI_MTX_DO_NOT_LOCK);
+		/* Re-enable interrupts */
+		local_irq_enable();
+		/* Compute time (ticks) that we were actually asleep */
+		sleep_ticks = ticks_elapsed(t1, t2) - cx->latency_ticks - C3_OVERHEAD;
+		break;
+
+	default:
+		local_irq_enable();
+		return;
+	}
+
+	next_state = pr->power.state;
+
+	/*
+	 * Promotion?
+	 * ----------
+	 * Track the number of longs (time asleep is greater than threshold)
+	 * and promote when the count threshold is reached.  Note that bus
+	 * mastering activity may prevent promotions.
+	 * Do not promote above max_cstate.
+	 */
+	if (cx->promotion.state &&
+	    ((cx->promotion.state - pr->power.states) <= max_cstate)) {
+		if (sleep_ticks > cx->promotion.threshold.ticks) {
+			cx->promotion.count++;
+ 			cx->demotion.count = 0;
+			if (cx->promotion.count >= cx->promotion.threshold.count) {
+				if (pr->flags.bm_check) {
+					if (!(pr->power.bm_activity & cx->promotion.threshold.bm)) {
+						next_state = cx->promotion.state;
+						goto end;
+					}
+				}
+				else {
+					next_state = cx->promotion.state;
+					goto end;
+				}
+			}
+		}
+	}
+
+	/*
+	 * Demotion?
+	 * ---------
+	 * Track the number of shorts (time asleep is less than time threshold)
+	 * and demote when the usage threshold is reached.
+	 */
+	if (cx->demotion.state) {
+		if (sleep_ticks < cx->demotion.threshold.ticks) {
+			cx->demotion.count++;
+			cx->promotion.count = 0;
+			if (cx->demotion.count >= cx->demotion.threshold.count) {
+				next_state = cx->demotion.state;
+				goto end;
+			}
+		}
+	}
+
+end:
+	/*
+	 * Demote if current state exceeds max_cstate
+	 */
+	if ((pr->power.state - pr->power.states) > max_cstate) {
+		if (cx->demotion.state)
+			next_state = cx->demotion.state;
+	}
+
+	/*
+	 * New Cx State?
+	 * -------------
+	 * If we're going to start using a new Cx state we must clean up
+	 * from the previous and prepare to use the new.
+	 */
+	if (next_state != pr->power.state)
+		acpi_processor_power_activate(pr, next_state);
+
+	return;
+
+ easy_out:
+	/* do C1 instead of busy loop */
+	if (pm_idle_save)
+		pm_idle_save();
+	else
+		safe_halt();
+	return;
+}
+
+
+static int
+acpi_processor_set_power_policy (
+	struct acpi_processor	*pr)
+{
+	unsigned int i;
+	unsigned int state_is_set = 0;
+	struct acpi_processor_cx *lower = NULL;
+	struct acpi_processor_cx *higher = NULL;
+	struct acpi_processor_cx *cx;
+
+ 	ACPI_FUNCTION_TRACE("acpi_processor_set_power_policy");
+
+	if (!pr)
+		return_VALUE(-EINVAL);
+
+	/*
+	 * This function sets the default Cx state policy (OS idle handler).
+	 * Our scheme is to promote quickly to C2 but more conservatively
+	 * to C3.  We're favoring C2  for its characteristics of low latency
+	 * (quick response), good power savings, and ability to allow bus
+	 * mastering activity.  Note that the Cx state policy is completely
+	 * customizable and can be altered dynamically.
+	 */
+
+	/* startup state */
+	for (i=1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
+		cx = &pr->power.states[i];
+		if (!cx->valid)
+			continue;
+
+		if (!state_is_set)
+			pr->power.state = cx;
+		state_is_set++;
+		break;
+ 	}
+
+	if (!state_is_set)
+		return_VALUE(-ENODEV);
+
+	/* demotion */
+	for (i=1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
+		cx = &pr->power.states[i];
+		if (!cx->valid)
+			continue;
+
+		if (lower) {
+			cx->demotion.state = lower;
+			cx->demotion.threshold.ticks = cx->latency_ticks;
+			cx->demotion.threshold.count = 1;
+			if (cx->type == ACPI_STATE_C3)
+				cx->demotion.threshold.bm = bm_history;
+		}
+
+		lower = cx;
+	}
+
+	/* promotion */
+	for (i = (ACPI_PROCESSOR_MAX_POWER - 1); i > 0; i--) {
+		cx = &pr->power.states[i];
+		if (!cx->valid)
+			continue;
+
+		if (higher) {
+			cx->promotion.state  = higher;
+			cx->promotion.threshold.ticks = cx->latency_ticks;
+			if (cx->type >= ACPI_STATE_C2)
+				cx->promotion.threshold.count = 4;
+			else
+				cx->promotion.threshold.count = 10;
+			if (higher->type == ACPI_STATE_C3)
+				cx->promotion.threshold.bm = bm_history;
+		}
+
+		higher = cx;
+	}
+
+ 	return_VALUE(0);
+}
+
+
+static int acpi_processor_get_power_info_fadt (struct acpi_processor *pr)
+{
+	int i;
+
+	ACPI_FUNCTION_TRACE("acpi_processor_get_power_info_fadt");
+
+	if (!pr)
+		return_VALUE(-EINVAL);
+
+	if (!pr->pblk)
+		return_VALUE(-ENODEV);
+
+	for (i = 0; i < ACPI_PROCESSOR_MAX_POWER; i++)
+		memset(pr->power.states, 0, sizeof(struct acpi_processor_cx));
+
+	/* if info is obtained from pblk/fadt, type equals state */
+	pr->power.states[ACPI_STATE_C1].type = ACPI_STATE_C1;
+	pr->power.states[ACPI_STATE_C2].type = ACPI_STATE_C2;
+	pr->power.states[ACPI_STATE_C3].type = ACPI_STATE_C3;
+
+	/* the C0 state only exists as a filler in our array,
+	 * and all processors need to support C1 */
+	pr->power.states[ACPI_STATE_C0].valid = 1;
+	pr->power.states[ACPI_STATE_C1].valid = 1;
+
+	/* determine C2 and C3 address from pblk */
+	pr->power.states[ACPI_STATE_C2].address = pr->pblk + 4;
+	pr->power.states[ACPI_STATE_C3].address = pr->pblk + 5;
+
+	/* determine latencies from FADT */
+	pr->power.states[ACPI_STATE_C2].latency = acpi_fadt.plvl2_lat;
+	pr->power.states[ACPI_STATE_C3].latency = acpi_fadt.plvl3_lat;
+
+	ACPI_DEBUG_PRINT((ACPI_DB_INFO,
+			  "lvl2[0x%08x] lvl3[0x%08x]\n",
+			  pr->power.states[ACPI_STATE_C2].address,
+			  pr->power.states[ACPI_STATE_C3].address));
+
+	return_VALUE(0);
+}
+
+
+static int acpi_processor_get_power_info_cst (struct acpi_processor *pr)
+{
+	acpi_status		status = 0;
+	acpi_integer		count;
+	int			i;
+	struct acpi_buffer	buffer = {ACPI_ALLOCATE_BUFFER, NULL};
+	union acpi_object	*cst;
+
+	ACPI_FUNCTION_TRACE("acpi_processor_get_power_info_cst");
+
+	if (errata.smp)
+		return_VALUE(-ENODEV);
+
+	if (nocst)
+		return_VALUE(-ENODEV);
+
+	pr->power.count = 0;
+	for (i = 0; i < ACPI_PROCESSOR_MAX_POWER; i++)
+		memset(pr->power.states, 0, sizeof(struct acpi_processor_cx));
+
+	status = acpi_evaluate_object(pr->handle, "_CST", NULL, &buffer);
+	if (ACPI_FAILURE(status)) {
+		ACPI_DEBUG_PRINT((ACPI_DB_INFO, "No _CST, giving up\n"));
+		return_VALUE(-ENODEV);
+ 	}
+
+	cst = (union acpi_object *) buffer.pointer;
+
+	/* There must be at least 2 elements */
+	if (!cst || (cst->type != ACPI_TYPE_PACKAGE) || cst->package.count < 2) {
+		ACPI_DEBUG_PRINT((ACPI_DB_ERROR, "not enough elements in _CST\n"));
+		status = -EFAULT;
+		goto end;
+	}
+
+	count = cst->package.elements[0].integer.value;
+
+	/* Validate number of power states. */
+	if (count < 1 || count != cst->package.count - 1) {
+		ACPI_DEBUG_PRINT((ACPI_DB_ERROR, "count given by _CST is not valid\n"));
+		status = -EFAULT;
+		goto end;
+	}
+
+	/* We support up to ACPI_PROCESSOR_MAX_POWER. */
+	if (count > ACPI_PROCESSOR_MAX_POWER) {
+		printk(KERN_WARNING "Limiting number of power states to max (%d)\n", ACPI_PROCESSOR_MAX_POWER);
+		printk(KERN_WARNING "Please increase ACPI_PROCESSOR_MAX_POWER if needed.\n");
+		count = ACPI_PROCESSOR_MAX_POWER;
+	}
+
+	/* Tell driver that at least _CST is supported. */
+	pr->flags.has_cst = 1;
+
+	for (i = 1; i <= count; i++) {
+		union acpi_object *element;
+		union acpi_object *obj;
+		struct acpi_power_register *reg;
+		struct acpi_processor_cx cx;
+
+		memset(&cx, 0, sizeof(cx));
+
+		element = (union acpi_object *) &(cst->package.elements[i]);
+		if (element->type != ACPI_TYPE_PACKAGE)
+			continue;
+
+		if (element->package.count != 4)
+			continue;
+
+		obj = (union acpi_object *) &(element->package.elements[0]);
+
+		if (obj->type != ACPI_TYPE_BUFFER)
+			continue;
+
+		reg = (struct acpi_power_register *) obj->buffer.pointer;
+
+		if (reg->space_id != ACPI_ADR_SPACE_SYSTEM_IO &&
+			(reg->space_id != ACPI_ADR_SPACE_FIXED_HARDWARE))
+			continue;
+
+		cx.address = (reg->space_id == ACPI_ADR_SPACE_FIXED_HARDWARE) ?
+			0 : reg->address;
+
+		/* There should be an easy way to extract an integer... */
+		obj = (union acpi_object *) &(element->package.elements[1]);
+		if (obj->type != ACPI_TYPE_INTEGER)
+			continue;
+
+		cx.type = obj->integer.value;
+
+		if ((cx.type != ACPI_STATE_C1) &&
+		    (reg->space_id != ACPI_ADR_SPACE_SYSTEM_IO))
+			continue;
+
+		if ((cx.type < ACPI_STATE_C1) ||
+		    (cx.type > ACPI_STATE_C3))
+			continue;
+
+		obj = (union acpi_object *) &(element->package.elements[2]);
+		if (obj->type != ACPI_TYPE_INTEGER)
+			continue;
+
+		cx.latency = obj->integer.value;
+
+		obj = (union acpi_object *) &(element->package.elements[3]);
+		if (obj->type != ACPI_TYPE_INTEGER)
+			continue;
+
+		cx.power = obj->integer.value;
+
+		(pr->power.count)++;
+		memcpy(&(pr->power.states[pr->power.count]), &cx, sizeof(cx));
+	}
+
+	ACPI_DEBUG_PRINT((ACPI_DB_INFO, "Found %d power states\n", pr->power.count));
+
+	/* Validate number of power states discovered */
+	if (pr->power.count < 2)
+		status = -ENODEV;
+
+end:
+	acpi_os_free(buffer.pointer);
+
+	return_VALUE(status);
+}
+
+
+static void acpi_processor_power_verify_c2(struct acpi_processor_cx *cx)
+{
+	ACPI_FUNCTION_TRACE("acpi_processor_get_power_verify_c2");
+
+	if (!cx->address)
+		return_VOID;
+
+	/*
+	 * C2 latency must be less than or equal to 100
+	 * microseconds.
+	 */
+	else if (cx->latency > ACPI_PROCESSOR_MAX_C2_LATENCY) {
+		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
+				  "latency too large [%d]\n",
+				  cx->latency));
+		return_VOID;
+	}
+
+	/* We're (currently) only supporting C2 on UP */
+	else if (errata.smp) {
+		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
+				  "C2 not supported in SMP mode\n"));
+		return_VOID;
+	}
+
+	/*
+	 * Otherwise we've met all of our C2 requirements.
+	 * Normalize the C2 latency to expidite policy
+	 */
+	cx->valid = 1;
+	cx->latency_ticks = US_TO_PM_TIMER_TICKS(cx->latency);
+
+	return_VOID;
+}
+
+
+static void acpi_processor_power_verify_c3(
+	struct acpi_processor *pr,
+	struct acpi_processor_cx *cx)
+{
+	ACPI_FUNCTION_TRACE("acpi_processor_get_power_verify_c3");
+
+	if (!cx->address)
+		return_VOID;
+
+	/*
+	 * C3 latency must be less than or equal to 1000
+	 * microseconds.
+	 */
+	else if (cx->latency > ACPI_PROCESSOR_MAX_C3_LATENCY) {
+		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
+				  "latency too large [%d]\n",
+				  cx->latency));
+		return_VOID;
+	}
+
+	/* bus mastering control is necessary */
+	else if (!pr->flags.bm_control) {
+		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
+				  "C3 support requires bus mastering control\n"));
+		return_VOID;
+	}
+
+	/* We're (currently) only supporting C2 on UP */
+	else if (errata.smp) {
+		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
+				  "C3 not supported in SMP mode\n"));
+		return_VOID;
+	}
+
+	/*
+	 * PIIX4 Erratum #18: We don't support C3 when Type-F (fast)
+	 * DMA transfers are used by any ISA device to avoid livelock.
+	 * Note that we could disable Type-F DMA (as recommended by
+	 * the erratum), but this is known to disrupt certain ISA
+	 * devices thus we take the conservative approach.
+	 */
+	else if (errata.piix4.fdma) {
+		ACPI_DEBUG_PRINT((ACPI_DB_INFO,
+			"C3 not supported on PIIX4 with Type-F DMA\n"));
+		return_VOID;
+	}
+
+	/*
+	 * Otherwise we've met all of our C3 requirements.
+	 * Normalize the C3 latency to expidite policy.  Enable
+	 * checking of bus mastering status (bm_check) so we can
+	 * use this in our C3 policy
+	 */
+	cx->valid = 1;
+	cx->latency_ticks = US_TO_PM_TIMER_TICKS(cx->latency);
+	pr->flags.bm_check = 1;
+
+	return_VOID;
+}
+
+
+static int acpi_processor_power_verify(struct acpi_processor *pr)
+{
+	unsigned int i;
+	unsigned int working = 0;
+
+	for (i=1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
+		struct acpi_processor_cx *cx = &pr->power.states[i];
+
+		switch (cx->type) {
+		case ACPI_STATE_C1:
+			cx->valid = 1;
+			break;
+
+		case ACPI_STATE_C2:
+			acpi_processor_power_verify_c2(cx);
+			break;
+
+		case ACPI_STATE_C3:
+			acpi_processor_power_verify_c3(pr, cx);
+			break;
+		}
+
+		if (cx->valid)
+			working++;
+	}
+
+	return (working);
+}
+
+static int acpi_processor_get_power_info (
+	struct acpi_processor	*pr)
+{
+	unsigned int i;
+	int result;
+
+	ACPI_FUNCTION_TRACE("acpi_processor_get_power_info");
+
+	/* NOTE: the idle thread may not be running while calling
+	 * this function */
+
+	result = acpi_processor_get_power_info_cst(pr);
+	if ((result) || (acpi_processor_power_verify(pr) < 2)) {
+		result = acpi_processor_get_power_info_fadt(pr);
+		if (result)
+			return_VALUE(result);
+
+		if (acpi_processor_power_verify(pr) < 2)
+			return_VALUE(-ENODEV);
+	}
+
+	/*
+	 * Set Default Policy
+	 * ------------------
+	 * Now that we know which states are supported, set the default
+	 * policy.  Note that this policy can be changed dynamically
+	 * (e.g. encourage deeper sleeps to conserve battery life when
+	 * not on AC).
+	 */
+	result = acpi_processor_set_power_policy(pr);
+	if (result)
+		return_VALUE(result);
+
+	/*
+	 * if one state of type C2 or C3 is available, mark this
+	 * CPU as being "idle manageable"
+	 */
+	for (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {
+		if (pr->power.states[i].valid)
+			pr->power.count = i;
+		if ((pr->power.states[i].valid) &&
+		    (pr->power.states[i].type >= ACPI_STATE_C2))
+			pr->flags.power = 1;
+	}
+
+	return_VALUE(0);
+}
+
+int acpi_processor_cst_has_changed (struct acpi_processor *pr)
+{
+ 	int			result = 0;
+
+	ACPI_FUNCTION_TRACE("acpi_processor_cst_has_changed");
+
+	if (!pr)
+ 		return_VALUE(-EINVAL);
+
+	if (errata.smp || nocst) {
+		return_VALUE(-ENODEV);
+	}
+
+	if (!pr->flags.power_setup_done)
+		return_VALUE(-ENODEV);
+
+	/* Fall back to the default idle loop */
+	pm_idle = pm_idle_save;
+	synchronize_kernel();
+
+	pr->flags.power = 0;
+	result = acpi_processor_get_power_info(pr);
+	if ((pr->flags.power == 1) && (pr->flags.power_setup_done))
+		pm_idle = acpi_processor_idle;
+
+	return_VALUE(result);
+}
+
+/* proc interface */
+
+static int acpi_processor_power_seq_show(struct seq_file *seq, void *offset)
+{
+	struct acpi_processor	*pr = (struct acpi_processor *)seq->private;
+	unsigned int		i;
+
+	ACPI_FUNCTION_TRACE("acpi_processor_power_seq_show");
+
+	if (!pr)
+		goto end;
+
+	seq_printf(seq, "active state:            C%zd\n"
+			"max_cstate:              C%d\n"
+			"bus master activity:     %08x\n",
+			pr->power.state ? pr->power.state - pr->power.states : 0,
+			max_cstate,
+			(unsigned)pr->power.bm_activity);
+
+	seq_puts(seq, "states:\n");
+
+	for (i = 1; i <= pr->power.count; i++) {
+		seq_printf(seq, "   %cC%d:                  ",
+			(&pr->power.states[i] == pr->power.state?'*':' '), i);
+
+		if (!pr->power.states[i].valid) {
+			seq_puts(seq, "<not supported>\n");
+			continue;
+		}
+
+		switch (pr->power.states[i].type) {
+		case ACPI_STATE_C1:
+			seq_printf(seq, "type[C1] ");
+			break;
+		case ACPI_STATE_C2:
+			seq_printf(seq, "type[C2] ");
+			break;
+		case ACPI_STATE_C3:
+			seq_printf(seq, "type[C3] ");
+			break;
+		default:
+			seq_printf(seq, "type[--] ");
+			break;
+		}
+
+		if (pr->power.states[i].promotion.state)
+			seq_printf(seq, "promotion[C%zd] ",
+				(pr->power.states[i].promotion.state -
+				 pr->power.states));
+		else
+			seq_puts(seq, "promotion[--] ");
+
+		if (pr->power.states[i].demotion.state)
+			seq_printf(seq, "demotion[C%zd] ",
+				(pr->power.states[i].demotion.state -
+				 pr->power.states));
+		else
+			seq_puts(seq, "demotion[--] ");
+
+		seq_printf(seq, "latency[%03d] usage[%08d]\n",
+			pr->power.states[i].latency,
+			pr->power.states[i].usage);
+	}
+
+end:
+	return_VALUE(0);
+}
+
+static int acpi_processor_power_open_fs(struct inode *inode, struct file *file)
+{
+	return single_open(file, acpi_processor_power_seq_show,
+						PDE(inode)->data);
+}
+
+static struct file_operations acpi_processor_power_fops = {
+	.open 		= acpi_processor_power_open_fs,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+
+int acpi_processor_power_init(struct acpi_processor *pr, struct acpi_device *device)
+{
+	acpi_status		status = 0;
+	static int		first_run = 0;
+	struct proc_dir_entry	*entry = NULL;
+	unsigned int i;
+
+	ACPI_FUNCTION_TRACE("acpi_processor_power_init");
+
+	if (!first_run) {
+		dmi_check_system(processor_power_dmi_table);
+		if (max_cstate < ACPI_C_STATES_MAX)
+			printk(KERN_NOTICE "ACPI: processor limited to max C-state %d\n", max_cstate);
+		first_run++;
+	}
+
+	if (!errata.smp && (pr->id == 0) && acpi_fadt.cst_cnt && !nocst) {
+		status = acpi_os_write_port(acpi_fadt.smi_cmd, acpi_fadt.cst_cnt, 8);
+		if (ACPI_FAILURE(status)) {
+			ACPI_DEBUG_PRINT((ACPI_DB_ERROR,
+					  "Notifying BIOS of _CST ability failed\n"));
+		}
+	}
+
+	acpi_processor_get_power_info(pr);
+
+	/*
+	 * Install the idle handler if processor power management is supported.
+	 * Note that we use previously set idle handler will be used on
+	 * platforms that only support C1.
+	 */
+	if ((pr->flags.power) && (!boot_option_idle_override)) {
+		printk(KERN_INFO PREFIX "CPU%d (power states:", pr->id);
+		for (i = 1; i <= pr->power.count; i++)
+			if (pr->power.states[i].valid)
+				printk(" C%d[C%d]", i, pr->power.states[i].type);
+		printk(")\n");
+
+		if (pr->id == 0) {
+			pm_idle_save = pm_idle;
+			pm_idle = acpi_processor_idle;
+		}
+	}
+
+	/* 'power' [R] */
+	entry = create_proc_entry(ACPI_PROCESSOR_FILE_POWER,
+		S_IRUGO, acpi_device_dir(device));
+	if (!entry)
+		ACPI_DEBUG_PRINT((ACPI_DB_ERROR,
+			"Unable to create '%s' fs entry\n",
+			ACPI_PROCESSOR_FILE_POWER));
+	else {
+		entry->proc_fops = &acpi_processor_power_fops;
+		entry->data = acpi_driver_data(device);
+		entry->owner = THIS_MODULE;
+	}
+
+	pr->flags.power_setup_done = 1;
+
+	return_VALUE(0);
+}
+
+int acpi_processor_power_exit(struct acpi_processor *pr, struct acpi_device *device)
+{
+	ACPI_FUNCTION_TRACE("acpi_processor_power_exit");
+
+	pr->flags.power_setup_done = 0;
+
+	if (acpi_device_dir(device))
+		remove_proc_entry(ACPI_PROCESSOR_FILE_POWER,acpi_device_dir(device));
+
+	/* Unregister the idle handler when processor #0 is removed. */
+	if (pr->id == 0) {
+		pm_idle = pm_idle_save;
+
+		/*
+		 * We are about to unload the current idle thread pm callback
+		 * (pm_idle), Wait for all processors to update cached/local
+		 * copies of pm_idle before proceeding.
+		 */
+		cpu_idle_wait();
+	}
+
+	return_VALUE(0);
+}
