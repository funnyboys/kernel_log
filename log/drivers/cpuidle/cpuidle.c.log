commit 10e8b11eb3195e11450c509d4dd3984d707a4167
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu Jun 25 13:52:53 2020 +0200

    cpuidle: Rearrange s2idle-specific idle state entry code
    
    Implement call_cpuidle_s2idle() in analogy with call_cpuidle()
    for the s2idle-specific idle state entry and invoke it from
    cpuidle_idle_call() to make the s2idle-specific idle entry code
    path look more similar to the "regular" idle entry one.
    
    No intentional functional impact.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Chen Yu <yu.c.chen@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index e092789187c6..87197319ab06 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -13,7 +13,6 @@
 #include <linux/mutex.h>
 #include <linux/sched.h>
 #include <linux/sched/clock.h>
-#include <linux/sched/idle.h>
 #include <linux/notifier.h>
 #include <linux/pm_qos.h>
 #include <linux/cpu.h>
@@ -187,9 +186,10 @@ int cpuidle_enter_s2idle(struct cpuidle_driver *drv, struct cpuidle_device *dev)
 	 * be frozen safely.
 	 */
 	index = find_deepest_state(drv, dev, U64_MAX, 0, true);
-	if (index > 0 && !current_clr_polling_and_test())
+	if (index > 0) {
 		enter_s2idle_proper(drv, dev, index);
-
+		local_irq_enable();
+	}
 	return index;
 }
 #endif /* CONFIG_SUSPEND */

commit 81e6737518a1e392ead4e568a4ee70bb7c371458
Author: Chen Yu <yu.c.chen@intel.com>
Date:   Tue Jun 23 14:31:31 2020 +0800

    PM: s2idle: Clear _TIF_POLLING_NRFLAG before suspend to idle
    
    Suspend to idle was found to not work on Goldmont CPU recently.
    
    The issue happens due to:
    
     1. On Goldmont the CPU in idle can only be woken up via IPIs,
        not POLLING mode, due to commit 08e237fa56a1 ("x86/cpu: Add
        workaround for MONITOR instruction erratum on Goldmont based
        CPUs")
    
     2. When the CPU is entering suspend to idle process, the
        _TIF_POLLING_NRFLAG remains on, because cpuidle_enter_s2idle()
        doesn't match call_cpuidle() exactly.
    
     3. Commit b2a02fc43a1f ("smp: Optimize send_call_function_single_ipi()")
        makes use of _TIF_POLLING_NRFLAG to avoid sending IPIs to idle
        CPUs.
    
     4. As a result, some IPIs related functions might not work
        well during suspend to idle on Goldmont. For example, one
        suspected victim:
    
        tick_unfreeze() -> timekeeping_resume() -> hrtimers_resume()
        -> clock_was_set() -> on_each_cpu() might wait forever,
        because the IPIs will not be sent to the CPUs which are
        sleeping with _TIF_POLLING_NRFLAG set, and Goldmont CPU
        could not be woken up by only setting _TIF_NEED_RESCHED
        on the monitor address.
    
    To avoid that, clear the _TIF_POLLING_NRFLAG flag before invoking
    enter_s2idle_proper() in cpuidle_enter_s2idle() in analogy with the
    call_cpuidle() code flow.
    
    Fixes: b2a02fc43a1f ("smp: Optimize send_call_function_single_ipi()")
    Suggested-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Suggested-by: Rafael J. Wysocki <rafael@kernel.org>
    Reported-by: kbuild test robot <lkp@intel.com>
    Signed-off-by: Chen Yu <yu.c.chen@intel.com>
    [ rjw: Subject / changelog ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index c149d9e20dfd..e092789187c6 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -13,6 +13,7 @@
 #include <linux/mutex.h>
 #include <linux/sched.h>
 #include <linux/sched/clock.h>
+#include <linux/sched/idle.h>
 #include <linux/notifier.h>
 #include <linux/pm_qos.h>
 #include <linux/cpu.h>
@@ -186,7 +187,7 @@ int cpuidle_enter_s2idle(struct cpuidle_driver *drv, struct cpuidle_device *dev)
 	 * be frozen safely.
 	 */
 	index = find_deepest_state(drv, dev, U64_MAX, 0, true);
-	if (index > 0)
+	if (index > 0 && !current_clr_polling_and_test())
 		enter_s2idle_proper(drv, dev, index);
 
 	return index;

commit 3a4a0042228a854d9b1073050620820b4a977e6e
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Wed Feb 12 00:02:30 2020 +0100

    PM: QoS: Drop PM_QOS_CPU_DMA_LATENCY notifier chain
    
    Notice that pm_qos_remove_notifier() is not used at all and the only
    caller of pm_qos_add_notifier() is the cpuidle core, which only needs
    the PM_QOS_CPU_DMA_LATENCY notifier to invoke wake_up_all_idle_cpus()
    upon changes of the PM_QOS_CPU_DMA_LATENCY target value.
    
    First, to ensure that wake_up_all_idle_cpus() will be called
    whenever the PM_QOS_CPU_DMA_LATENCY target value changes, modify the
    pm_qos_add/update/remove_request() family of functions to check if
    the effective constraint for the PM_QOS_CPU_DMA_LATENCY has changed
    and call wake_up_all_idle_cpus() directly in that case.
    
    Next, drop the PM_QOS_CPU_DMA_LATENCY notifier from cpuidle as it is
    not necessary any more.
    
    Finally, drop both pm_qos_add_notifier() and pm_qos_remove_notifier(),
    as they have no callers now, along with cpu_dma_lat_notifier which is
    only used by them.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    Reviewed-by: Amit Kucheria <amit.kucheria@linaro.org>
    Tested-by: Amit Kucheria <amit.kucheria@linaro.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index de81298051b3..c149d9e20dfd 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -736,53 +736,15 @@ int cpuidle_register(struct cpuidle_driver *drv,
 }
 EXPORT_SYMBOL_GPL(cpuidle_register);
 
-#ifdef CONFIG_SMP
-
-/*
- * This function gets called when a part of the kernel has a new latency
- * requirement.  This means we need to get all processors out of their C-state,
- * and then recalculate a new suitable C-state. Just do a cross-cpu IPI; that
- * wakes them all right up.
- */
-static int cpuidle_latency_notify(struct notifier_block *b,
-		unsigned long l, void *v)
-{
-	wake_up_all_idle_cpus();
-	return NOTIFY_OK;
-}
-
-static struct notifier_block cpuidle_latency_notifier = {
-	.notifier_call = cpuidle_latency_notify,
-};
-
-static inline void latency_notifier_init(struct notifier_block *n)
-{
-	pm_qos_add_notifier(PM_QOS_CPU_DMA_LATENCY, n);
-}
-
-#else /* CONFIG_SMP */
-
-#define latency_notifier_init(x) do { } while (0)
-
-#endif /* CONFIG_SMP */
-
 /**
  * cpuidle_init - core initializer
  */
 static int __init cpuidle_init(void)
 {
-	int ret;
-
 	if (cpuidle_disabled())
 		return -ENODEV;
 
-	ret = cpuidle_add_interface(cpu_subsys.dev_root);
-	if (ret)
-		return ret;
-
-	latency_notifier_init(&cpuidle_latency_notifier);
-
-	return 0;
+	return cpuidle_add_interface(cpu_subsys.dev_root);
 }
 
 module_param(off, int, 0444);

commit e6cf623ba3f83118b0f75be2cc1675931e21c887
Merge: cefb9409ff99 a32991822163
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu Jan 23 00:35:50 2020 +0100

    Merge branch 'intel_idle+acpi'
    
    Merge changes updating the ACPI processor driver in order to export
    acpi_processor_evaluate_cst() to the code outside of it and adding
    ACPI support to the intel_idle driver based on that.
    
    * intel_idle+acpi:
      Documentation: admin-guide: PM: Add intel_idle document
      intel_idle: Use ACPI _CST on server systems
      intel_idle: Add module parameter to prevent ACPI _CST from being used
      intel_idle: Allow ACPI _CST to be used for selected known processors
      cpuidle: Allow idle states to be disabled by default
      intel_idle: Use ACPI _CST for processor models without C-state tables
      intel_idle: Refactor intel_idle_cpuidle_driver_init()
      ACPI: processor: Export acpi_processor_evaluate_cst()
      ACPI: processor: Make ACPI_PROCESSOR_CSTATE depend on ACPI_PROCESSOR
      ACPI: processor: Clean up acpi_processor_evaluate_cst()
      ACPI: processor: Introduce acpi_processor_evaluate_cst()
      ACPI: processor: Export function to claim _CST control

commit cefb9409ff995fcc98ce44a07b549ba1b827c31b
Author: Benjamin Gaignard <benjamin.gaignard@st.com>
Date:   Tue Jan 21 09:27:58 2020 +0100

    cpuidle: fix cpuidle_find_deepest_state() kerneldoc warnings
    
    Fix cpuidle_find_deepest_state() kernel documentation to avoid
    warnings when compiling with W=1.
    
    Signed-off-by: Benjamin Gaignard <benjamin.gaignard@st.com>
    Acked-by: Randy Dunlap <rdunlap@infradead.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 33d19c8eb027..ad064d84da5e 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -121,6 +121,9 @@ void cpuidle_use_deepest_state(u64 latency_limit_ns)
  * cpuidle_find_deepest_state - Find the deepest available idle state.
  * @drv: cpuidle driver for the given CPU.
  * @dev: cpuidle device for the given CPU.
+ * @latency_limit_ns: Idle state exit latency limit
+ *
+ * Return: the index of the deepest available idle state.
  */
 int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
 			       struct cpuidle_device *dev,

commit 75a80267410e38ab76c4ceb39753f96d72113781
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Dec 13 09:56:13 2019 +0100

    cpuidle: Allow idle states to be disabled by default
    
    In certain situations it may be useful to prevent some idle states
    from being used by default while allowing user space to enable them
    later on.
    
    For this purpose, introduce a new state flag, CPUIDLE_FLAG_OFF, to
    mark idle states that should be disabled by default, make the core
    set CPUIDLE_STATE_DISABLED_BY_USER for those states at the
    initialization time and add a new state attribute in sysfs,
    "default_status", to inform user space of the initial status of
    the given idle state ("disabled" if CPUIDLE_FLAG_OFF is set for it,
    "enabled" otherwise).
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 33d19c8eb027..a2af7bb8f0a5 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -572,10 +572,14 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 	if (!try_module_get(drv->owner))
 		return -EINVAL;
 
-	for (i = 0; i < drv->state_count; i++)
+	for (i = 0; i < drv->state_count; i++) {
 		if (drv->states[i].flags & CPUIDLE_FLAG_UNUSABLE)
 			dev->states_usage[i].disable |= CPUIDLE_STATE_DISABLED_BY_DRIVER;
 
+		if (drv->states[i].flags & CPUIDLE_FLAG_OFF)
+			dev->states_usage[i].disable |= CPUIDLE_STATE_DISABLED_BY_USER;
+	}
+
 	per_cpu(cpuidle_devices, dev->cpu) = dev;
 	list_add(&dev->device_list, &cpuidle_detected_devices);
 

commit d4d8140176972fdb3f00bffc88e63af781de8d67
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Wed Dec 11 11:30:50 2019 +0100

    cpuidle: Drop unnecessary type cast in cpuidle_poll_time()
    
    The data type of the target_residency_ns field in struct cpuidle_state
    is u64, so it does not need to be cast into u64.
    
    Get rid of the unnecessary type cast.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 15877b431143..33d19c8eb027 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -381,7 +381,7 @@ u64 cpuidle_poll_time(struct cpuidle_driver *drv,
 		if (dev->states_usage[i].disable)
 			continue;
 
-		limit_ns = (u64)drv->states[i].target_residency_ns;
+		limit_ns = drv->states[i].target_residency_ns;
 		break;
 	}
 

commit 36fcb4292473cb9c9ce7706d038bcf0eda5cabeb
Author: Marcelo Tosatti <mtosatti@redhat.com>
Date:   Fri Dec 6 13:07:41 2019 -0200

    cpuidle: use first valid target residency as poll time
    
    Commit 259231a04561 ("cpuidle: add poll_limit_ns to cpuidle_device
    structure") changed, by mistake, the target residency from the first
    available sleep state to the last available sleep state (which should
    be longer).
    
    This might cause excessive polling.
    
    Fixes: 259231a04561 ("cpuidle: add poll_limit_ns to cpuidle_device structure")
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: 5.4+ <stable@vger.kernel.org> # 5.4+
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 0005be5ea2b4..15877b431143 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -382,6 +382,7 @@ u64 cpuidle_poll_time(struct cpuidle_driver *drv,
 			continue;
 
 		limit_ns = (u64)drv->states[i].target_residency_ns;
+		break;
 	}
 
 	dev->poll_limit_ns = limit_ns;

commit ba1e78a1dc0ca3e92f0be82279e6ba24177af7d6
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu Nov 21 19:41:51 2019 +0100

    cpuidle: Drop disabled field from struct cpuidle_state
    
    After recent cpuidle updates the "disabled" field in struct
    cpuidle_state is only used by two drivers (intel_idle and shmobile
    cpuidle) for marking unusable idle states, but that may as well be
    achieved with the help of a state flag, so define an "unusable" idle
    state flag, CPUIDLE_FLAG_UNUSABLE, make the drivers in question use
    it instead of the "disabled" field and make the core set
    CPUIDLE_STATE_DISABLED_BY_DRIVER for the idle states with that flag
    set.
    
    After the above changes, the "disabled" field in struct cpuidle_state
    is not used any more, so drop it.
    
    No intentional functional impact.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 569dbac443bd..0005be5ea2b4 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -572,7 +572,7 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 		return -EINVAL;
 
 	for (i = 0; i < drv->state_count; i++)
-		if (drv->states[i].disabled)
+		if (drv->states[i].flags & CPUIDLE_FLAG_UNUSABLE)
 			dev->states_usage[i].disable |= CPUIDLE_STATE_DISABLED_BY_DRIVER;
 
 	per_cpu(cpuidle_devices, dev->cpu) = dev;

commit 5aa9ba6312e36c18626e73506b92d1513d815435
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Sat Nov 16 14:16:13 2019 +0100

    cpuidle: Pass exit latency limit to cpuidle_use_deepest_state()
    
    Modify cpuidle_use_deepest_state() to take an additional exit latency
    limit argument to be passed to find_deepest_idle_state() and make
    cpuidle_idle_call() pass dev->forced_idle_latency_limit_ns to it for
    forced idle.
    
    Suggested-by: Rafael J. Wysocki <rafael@kernel.org>
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    [ rjw: Rebase and rearrange code, subject & changelog ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 12077db1158e..569dbac443bd 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -123,9 +123,10 @@ void cpuidle_use_deepest_state(u64 latency_limit_ns)
  * @dev: cpuidle device for the given CPU.
  */
 int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
-			       struct cpuidle_device *dev)
+			       struct cpuidle_device *dev,
+			       u64 latency_limit_ns)
 {
-	return find_deepest_state(drv, dev, U64_MAX, 0, false);
+	return find_deepest_state(drv, dev, latency_limit_ns, 0, false);
 }
 
 #ifdef CONFIG_SUSPEND

commit c55b51a06b01d67a99457bb82a8c31081c7faa23
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Sat Nov 16 14:16:12 2019 +0100

    cpuidle: Allow idle injection to apply exit latency limit
    
    In some cases it may be useful to specify an exit latency limit for
    the idle state to be used during CPU idle time injection.
    
    Instead of duplicating the information in struct cpuidle_device
    or propagating the latency limit in the call stack, replace the
    use_deepest_state field with forced_latency_limit_ns to represent
    that limit, so that the deepest idle state with exit latency within
    that limit is forced (i.e. no governors) when it is set.
    
    A zero exit latency limit for forced idle means to use governors in
    the usual way (analogous to use_deepest_state equal to "false" before
    this change).
    
    Additionally, add play_idle_precise() taking two arguments, the
    duration of forced idle and the idle state exit latency limit, both
    in nanoseconds, and redefine play_idle() as a wrapper around that
    new function.
    
    This change is preparatory, no functional impact is expected.
    
    Suggested-by: Rafael J. Wysocki <rafael@kernel.org>
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    [ rjw: Subject, changelog, cpuidle_use_deepest_state() kerneldoc, whitespace ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index bf9b030cd7e1..12077db1158e 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -99,20 +99,21 @@ static int find_deepest_state(struct cpuidle_driver *drv,
 }
 
 /**
- * cpuidle_use_deepest_state - Set/clear governor override flag.
- * @enable: New value of the flag.
+ * cpuidle_use_deepest_state - Set/unset governor override mode.
+ * @latency_limit_ns: Idle state exit latency limit (or no override if 0).
  *
- * Set/unset the current CPU to use the deepest idle state (override governors
- * going forward if set).
+ * If @latency_limit_ns is nonzero, set the current CPU to use the deepest idle
+ * state with exit latency within @latency_limit_ns (override governors going
+ * forward), or do not override governors if it is zero.
  */
-void cpuidle_use_deepest_state(bool enable)
+void cpuidle_use_deepest_state(u64 latency_limit_ns)
 {
 	struct cpuidle_device *dev;
 
 	preempt_disable();
 	dev = cpuidle_get_device();
 	if (dev)
-		dev->use_deepest_state = enable;
+		dev->forced_idle_latency_limit_ns = latency_limit_ns;
 	preempt_enable();
 }
 

commit c1d51f684c72b5eb2aecbbd47be3a2977a2dc903
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu Nov 7 15:25:12 2019 +0100

    cpuidle: Use nanoseconds as the unit of time
    
    Currently, the cpuidle subsystem uses microseconds as the unit of
    time which (among other things) causes the idle loop to incur some
    integer division overhead for no clear benefit.
    
    In order to allow cpuidle to measure time in nanoseconds, add two
    new fields, exit_latency_ns and target_residency_ns, to represent the
    exit latency and target residency of an idle state in nanoseconds,
    respectively, to struct cpuidle_state and initialize them with the
    help of the corresponding values in microseconds provided by drivers.
    Additionally, change cpuidle_governor_latency_req() to return the
    idle state exit latency constraint in nanoseconds.
    
    Also meeasure idle state residency (last_residency_ns in struct
    cpuidle_device and time_ns in struct cpuidle_driver) in nanoseconds
    and update the cpuidle core and governors accordingly.
    
    However, the menu governor still computes typical intervals in
    microseconds to avoid integer overflows.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Doug Smythies <dsmythies@telus.net>
    Tested-by: Doug Smythies <dsmythies@telus.net>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 44ae39f2b47a..bf9b030cd7e1 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -75,24 +75,24 @@ int cpuidle_play_dead(void)
 
 static int find_deepest_state(struct cpuidle_driver *drv,
 			      struct cpuidle_device *dev,
-			      unsigned int max_latency,
+			      u64 max_latency_ns,
 			      unsigned int forbidden_flags,
 			      bool s2idle)
 {
-	unsigned int latency_req = 0;
+	u64 latency_req = 0;
 	int i, ret = 0;
 
 	for (i = 1; i < drv->state_count; i++) {
 		struct cpuidle_state *s = &drv->states[i];
 
 		if (dev->states_usage[i].disable ||
-		    s->exit_latency <= latency_req ||
-		    s->exit_latency > max_latency ||
+		    s->exit_latency_ns <= latency_req ||
+		    s->exit_latency_ns > max_latency_ns ||
 		    (s->flags & forbidden_flags) ||
 		    (s2idle && !s->enter_s2idle))
 			continue;
 
-		latency_req = s->exit_latency;
+		latency_req = s->exit_latency_ns;
 		ret = i;
 	}
 	return ret;
@@ -124,7 +124,7 @@ void cpuidle_use_deepest_state(bool enable)
 int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
 			       struct cpuidle_device *dev)
 {
-	return find_deepest_state(drv, dev, UINT_MAX, 0, false);
+	return find_deepest_state(drv, dev, U64_MAX, 0, false);
 }
 
 #ifdef CONFIG_SUSPEND
@@ -180,7 +180,7 @@ int cpuidle_enter_s2idle(struct cpuidle_driver *drv, struct cpuidle_device *dev)
 	 * that interrupts won't be enabled when it exits and allows the tick to
 	 * be frozen safely.
 	 */
-	index = find_deepest_state(drv, dev, UINT_MAX, 0, true);
+	index = find_deepest_state(drv, dev, U64_MAX, 0, true);
 	if (index > 0)
 		enter_s2idle_proper(drv, dev, index);
 
@@ -209,7 +209,7 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	 * CPU as a broadcast timer, this call may fail if it is not available.
 	 */
 	if (broadcast && tick_broadcast_enter()) {
-		index = find_deepest_state(drv, dev, target_state->exit_latency,
+		index = find_deepest_state(drv, dev, target_state->exit_latency_ns,
 					   CPUIDLE_FLAG_TIMER_STOP, false);
 		if (index < 0) {
 			default_idle_call();
@@ -247,7 +247,7 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 		local_irq_enable();
 
 	if (entered_state >= 0) {
-		s64 diff, delay = drv->states[entered_state].exit_latency;
+		s64 diff, delay = drv->states[entered_state].exit_latency_ns;
 		int i;
 
 		/*
@@ -255,15 +255,13 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 		 * This can be moved to within driver enter routine,
 		 * but that results in multiple copies of same code.
 		 */
-		diff = ktime_us_delta(time_end, time_start);
-		if (diff > INT_MAX)
-			diff = INT_MAX;
+		diff = ktime_sub(time_end, time_start);
 
-		dev->last_residency = (int)diff;
-		dev->states_usage[entered_state].time += dev->last_residency;
+		dev->last_residency_ns = diff;
+		dev->states_usage[entered_state].time_ns += diff;
 		dev->states_usage[entered_state].usage++;
 
-		if (diff < drv->states[entered_state].target_residency) {
+		if (diff < drv->states[entered_state].target_residency_ns) {
 			for (i = entered_state - 1; i >= 0; i--) {
 				if (dev->states_usage[i].disable)
 					continue;
@@ -281,14 +279,14 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 				 * Update if a deeper state would have been a
 				 * better match for the observed idle duration.
 				 */
-				if (diff - delay >= drv->states[i].target_residency)
+				if (diff - delay >= drv->states[i].target_residency_ns)
 					dev->states_usage[entered_state].below++;
 
 				break;
 			}
 		}
 	} else {
-		dev->last_residency = 0;
+		dev->last_residency_ns = 0;
 	}
 
 	return entered_state;
@@ -381,7 +379,7 @@ u64 cpuidle_poll_time(struct cpuidle_driver *drv,
 		if (dev->states_usage[i].disable)
 			continue;
 
-		limit_ns = (u64)drv->states[i].target_residency * NSEC_PER_USEC;
+		limit_ns = (u64)drv->states[i].target_residency_ns;
 	}
 
 	dev->poll_limit_ns = limit_ns;
@@ -552,7 +550,7 @@ static void __cpuidle_unregister_device(struct cpuidle_device *dev)
 static void __cpuidle_device_init(struct cpuidle_device *dev)
 {
 	memset(dev->states_usage, 0, sizeof(dev->states_usage));
-	dev->last_residency = 0;
+	dev->last_residency_ns = 0;
 	dev->next_hrtimer = 0;
 }
 

commit 99e98d3fb1008ef7416e16a1fd355cb73a253502
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Nov 4 12:16:17 2019 +0100

    cpuidle: Consolidate disabled state checks
    
    There are two reasons why CPU idle states may be disabled: either
    because the driver has disabled them or because they have been
    disabled by user space via sysfs.
    
    In the former case, the state's "disabled" flag is set once during
    the initialization of the driver and it is never cleared later (it
    is read-only effectively).  In the latter case, the "disable" field
    of the given state's cpuidle_state_usage struct is set and it may be
    changed via sysfs.  Thus checking whether or not an idle state has
    been disabled involves reading these two flags every time.
    
    In order to avoid the additional check of the state's "disabled" flag
    (which is effectively read-only anyway), use the value of it at the
    init time to set a (new) flag in the "disable" field of that state's
    cpuidle_state_usage structure and use the sysfs interface to
    manipulate another (new) flag in it.  This way the state is disabled
    whenever the "disable" field of its cpuidle_state_usage structure is
    nonzero, whatever the reason, and it is the only place to look into
    to check whether or not the state has been disabled.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 0895b988fa92..44ae39f2b47a 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -84,12 +84,12 @@ static int find_deepest_state(struct cpuidle_driver *drv,
 
 	for (i = 1; i < drv->state_count; i++) {
 		struct cpuidle_state *s = &drv->states[i];
-		struct cpuidle_state_usage *su = &dev->states_usage[i];
 
-		if (s->disabled || su->disable || s->exit_latency <= latency_req
-		    || s->exit_latency > max_latency
-		    || (s->flags & forbidden_flags)
-		    || (s2idle && !s->enter_s2idle))
+		if (dev->states_usage[i].disable ||
+		    s->exit_latency <= latency_req ||
+		    s->exit_latency > max_latency ||
+		    (s->flags & forbidden_flags) ||
+		    (s2idle && !s->enter_s2idle))
 			continue;
 
 		latency_req = s->exit_latency;
@@ -265,8 +265,7 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 
 		if (diff < drv->states[entered_state].target_residency) {
 			for (i = entered_state - 1; i >= 0; i--) {
-				if (drv->states[i].disabled ||
-				    dev->states_usage[i].disable)
+				if (dev->states_usage[i].disable)
 					continue;
 
 				/* Shallower states are enabled, so update. */
@@ -275,8 +274,7 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 			}
 		} else if (diff > delay) {
 			for (i = entered_state + 1; i < drv->state_count; i++) {
-				if (drv->states[i].disabled ||
-				    dev->states_usage[i].disable)
+				if (dev->states_usage[i].disable)
 					continue;
 
 				/*
@@ -380,7 +378,7 @@ u64 cpuidle_poll_time(struct cpuidle_driver *drv,
 
 	limit_ns = TICK_NSEC;
 	for (i = 1; i < drv->state_count; i++) {
-		if (drv->states[i].disabled || dev->states_usage[i].disable)
+		if (dev->states_usage[i].disable)
 			continue;
 
 		limit_ns = (u64)drv->states[i].target_residency * NSEC_PER_USEC;
@@ -567,12 +565,16 @@ static void __cpuidle_device_init(struct cpuidle_device *dev)
  */
 static int __cpuidle_register_device(struct cpuidle_device *dev)
 {
-	int ret;
 	struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
+	int i, ret;
 
 	if (!try_module_get(drv->owner))
 		return -EINVAL;
 
+	for (i = 0; i < drv->state_count; i++)
+		if (drv->states[i].disabled)
+			dev->states_usage[i].disable |= CPUIDLE_STATE_DISABLED_BY_DRIVER;
+
 	per_cpu(cpuidle_devices, dev->cpu) = dev;
 	list_add(&dev->device_list, &cpuidle_detected_devices);
 

commit 259231a045616c4101d023a8f4dcc8379af265a6
Author: Marcelo Tosatti <mtosatti@redhat.com>
Date:   Wed Jul 3 20:51:26 2019 -0300

    cpuidle: add poll_limit_ns to cpuidle_device structure
    
    Add a poll_limit_ns variable to cpuidle_device structure.
    
    Calculate and configure it in the new cpuidle_poll_time
    function, in case its zero.
    
    Individual governors are allowed to override this value.
    
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 0f4b7c45df3e..0895b988fa92 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -361,6 +361,36 @@ void cpuidle_reflect(struct cpuidle_device *dev, int index)
 		cpuidle_curr_governor->reflect(dev, index);
 }
 
+/**
+ * cpuidle_poll_time - return amount of time to poll for,
+ * governors can override dev->poll_limit_ns if necessary
+ *
+ * @drv:   the cpuidle driver tied with the cpu
+ * @dev:   the cpuidle device
+ *
+ */
+u64 cpuidle_poll_time(struct cpuidle_driver *drv,
+		      struct cpuidle_device *dev)
+{
+	int i;
+	u64 limit_ns;
+
+	if (dev->poll_limit_ns)
+		return dev->poll_limit_ns;
+
+	limit_ns = TICK_NSEC;
+	for (i = 1; i < drv->state_count; i++) {
+		if (drv->states[i].disabled || dev->states_usage[i].disable)
+			continue;
+
+		limit_ns = (u64)drv->states[i].target_residency * NSEC_PER_USEC;
+	}
+
+	dev->poll_limit_ns = limit_ns;
+
+	return dev->poll_limit_ns;
+}
+
 /**
  * cpuidle_install_idle_handler - installs the cpuidle idle loop handler
  */

commit 6f9b83ac877fb5558d76b9f78590f3afd1bdf421
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Wed Mar 27 15:35:47 2019 +0100

    cpuidle: Export the next timer expiration for CPUs
    
    To be able to predict the sleep duration for a CPU entering idle, it
    is essential to know the expiration time of the next timer.  Both the
    teo and the menu cpuidle governors already use this information for
    CPU idle state selection.
    
    Moving forward, a similar prediction needs to be made for a group of
    idle CPUs rather than for a single one and the following changes
    implement a new genpd governor for that purpose.
    
    In order to support that feature, add a new function called
    tick_nohz_get_next_hrtimer() that will return the next hrtimer
    expiration time of a given CPU to be invoked after deciding
    whether or not to stop the scheduler tick on that CPU.
    
    Make the cpuidle core call tick_nohz_get_next_hrtimer() right
    before invoking the ->enter() callback provided by the cpuidle
    driver for the given state and store its return value in the
    per-CPU struct cpuidle_device, so as to make it available to code
    outside of cpuidle.
    
    Note that at the point when cpuidle calls tick_nohz_get_next_hrtimer(),
    the governor's ->select() callback has already returned and indicated
    whether or not the tick should be stopped, so in fact the value
    returned by tick_nohz_get_next_hrtimer() always is the next hrtimer
    expiration time for the given CPU, possibly including the tick (if
    it hasn't been stopped).
    
    Co-developed-by: Lina Iyer <lina.iyer@linaro.org>
    Co-developed-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    [ rjw: Subject & changelog ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 7f108309e871..0f4b7c45df3e 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -328,9 +328,23 @@ int cpuidle_select(struct cpuidle_driver *drv, struct cpuidle_device *dev,
 int cpuidle_enter(struct cpuidle_driver *drv, struct cpuidle_device *dev,
 		  int index)
 {
+	int ret = 0;
+
+	/*
+	 * Store the next hrtimer, which becomes either next tick or the next
+	 * timer event, whatever expires first. Additionally, to make this data
+	 * useful for consumers outside cpuidle, we rely on that the governor's
+	 * ->select() callback have decided, whether to stop the tick or not.
+	 */
+	WRITE_ONCE(dev->next_hrtimer, tick_nohz_get_next_hrtimer());
+
 	if (cpuidle_state_is_coupled(drv, index))
-		return cpuidle_enter_state_coupled(dev, drv, index);
-	return cpuidle_enter_state(dev, drv, index);
+		ret = cpuidle_enter_state_coupled(dev, drv, index);
+	else
+		ret = cpuidle_enter_state(dev, drv, index);
+
+	WRITE_ONCE(dev->next_hrtimer, 0);
+	return ret;
 }
 
 /**
@@ -511,6 +525,7 @@ static void __cpuidle_device_init(struct cpuidle_device *dev)
 {
 	memset(dev->states_usage, 0, sizeof(dev->states_usage));
 	dev->last_residency = 0;
+	dev->next_hrtimer = 0;
 }
 
 /**

commit 04dab58a39d402162a7effe7278df8cd41557252
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Dec 10 12:30:23 2018 +0100

    cpuidle: Add 'above' and 'below' idle state metrics
    
    Add two new metrics for CPU idle states, "above" and "below", to count
    the number of times the given state had been asked for (or entered
    from the kernel's perspective), but the observed idle duration turned
    out to be too short or too long for it (respectively).
    
    These metrics help to estimate the quality of the CPU idle governor
    in use.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index f7c58043e50f..7f108309e871 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -202,7 +202,6 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	struct cpuidle_state *target_state = &drv->states[index];
 	bool broadcast = !!(target_state->flags & CPUIDLE_FLAG_TIMER_STOP);
 	ktime_t time_start, time_end;
-	s64 diff;
 
 	/*
 	 * Tell the time framework to switch to a broadcast timer because our
@@ -248,6 +247,9 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 		local_irq_enable();
 
 	if (entered_state >= 0) {
+		s64 diff, delay = drv->states[entered_state].exit_latency;
+		int i;
+
 		/*
 		 * Update cpuidle counters
 		 * This can be moved to within driver enter routine,
@@ -260,6 +262,33 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 		dev->last_residency = (int)diff;
 		dev->states_usage[entered_state].time += dev->last_residency;
 		dev->states_usage[entered_state].usage++;
+
+		if (diff < drv->states[entered_state].target_residency) {
+			for (i = entered_state - 1; i >= 0; i--) {
+				if (drv->states[i].disabled ||
+				    dev->states_usage[i].disable)
+					continue;
+
+				/* Shallower states are enabled, so update. */
+				dev->states_usage[entered_state].above++;
+				break;
+			}
+		} else if (diff > delay) {
+			for (i = entered_state + 1; i < drv->state_count; i++) {
+				if (drv->states[i].disabled ||
+				    dev->states_usage[i].disable)
+					continue;
+
+				/*
+				 * Update if a deeper state would have been a
+				 * better match for the observed idle duration.
+				 */
+				if (diff - delay >= drv->states[i].target_residency)
+					dev->states_usage[entered_state].below++;
+
+				break;
+			}
+		}
 	} else {
 		dev->last_residency = 0;
 	}

commit 61cb5758d3c46bc1ba87694fefc0d9653613ce6b
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Wed Dec 5 23:45:34 2018 +0100

    cpuidle: Add cpuidle.governor= command line parameter
    
    Add cpuidle.governor= command line parameter to allow the default
    cpuidle governor to be replaced.
    
    That is useful, for example, if someone running a tickful kernel
    wants to use the menu governor on it.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 4a97446f66d8..f7c58043e50f 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -702,4 +702,5 @@ static int __init cpuidle_init(void)
 }
 
 module_param(off, int, 0444);
+module_param_string(governor, param_governor, CPUIDLE_NAME_LEN, 0444);
 core_initcall(cpuidle_init);

commit 7037b43e0076cce1c07c72540e219fb5db7ea01f
Author: Fieah Lim <kw@fieahl.im>
Date:   Tue Sep 11 05:47:25 2018 +0800

    cpuidle: enter_state: Don't needlessly calculate diff time
    
    Currently, ktime_us_delta() is invoked unconditionally to compute the
    idle residency of the CPU, but it only makes sense to do that if a
    valid idle state has been entered, so move the ktime_us_delta()
    invocation after the entered_state >= 0 check.
    
    While at it, merge two comment blocks in there into one and drop
    a space between type casting of diff.
    
    This patch has no functional changes.
    
    Signed-off-by: Fieah Lim <kw@fieahl.im>
    [ rjw: Changelog cleanup, comment format fix ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 6df894d65d9e..4a97446f66d8 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -247,17 +247,17 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	if (!cpuidle_state_is_coupled(drv, index))
 		local_irq_enable();
 
-	diff = ktime_us_delta(time_end, time_start);
-	if (diff > INT_MAX)
-		diff = INT_MAX;
-
-	dev->last_residency = (int) diff;
-
 	if (entered_state >= 0) {
-		/* Update cpuidle counters */
-		/* This can be moved to within driver enter routine
+		/*
+		 * Update cpuidle counters
+		 * This can be moved to within driver enter routine,
 		 * but that results in multiple copies of same code.
 		 */
+		diff = ktime_us_delta(time_end, time_start);
+		if (diff > INT_MAX)
+			diff = INT_MAX;
+
+		dev->last_residency = (int)diff;
 		dev->states_usage[entered_state].time += dev->last_residency;
 		dev->states_usage[entered_state].usage++;
 	} else {

commit 45f1ff59e27ca59d33cc1a317e669d90022ccf7d
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu Mar 22 17:50:49 2018 +0100

    cpuidle: Return nohz hint from cpuidle_select()
    
    Add a new pointer argument to cpuidle_select() and to the ->select
    cpuidle governor callback to allow a boolean value indicating
    whether or not the tick should be stopped before entering the
    selected state to be returned from there.
    
    Make the ladder governor ignore that pointer (to preserve its
    current behavior) and make the menu governor return 'false" through
    it if:
     (1) the idle exit latency is constrained at 0, or
     (2) the selected state is a polling one, or
     (3) the expected idle period duration is within the tick period
         range.
    
    In addition to that, the correction factor computations in the menu
    governor need to take the possibility that the tick may not be
    stopped into account to avoid artificially small correction factor
    values.  To that end, add a mechanism to record tick wakeups, as
    suggested by Peter Zijlstra, and use it to modify the menu_update()
    behavior when tick wakeup occurs.  Namely, if the CPU is woken up by
    the tick and the return value of tick_nohz_get_sleep_length() is not
    within the tick boundary, the predicted idle duration is likely too
    short, so make menu_update() try to compensate for that by updating
    the governor statistics as though the CPU was idle for a long time.
    
    Since the value returned through the new argument pointer of
    cpuidle_select() is not used by its caller yet, this change by
    itself is not expected to alter the functionality of the code.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 0003e9a02637..6df894d65d9e 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -272,12 +272,18 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
  *
  * @drv: the cpuidle driver
  * @dev: the cpuidle device
+ * @stop_tick: indication on whether or not to stop the tick
  *
  * Returns the index of the idle state.  The return value must not be negative.
+ *
+ * The memory location pointed to by @stop_tick is expected to be written the
+ * 'false' boolean value if the scheduler tick should not be stopped before
+ * entering the returned state.
  */
-int cpuidle_select(struct cpuidle_driver *drv, struct cpuidle_device *dev)
+int cpuidle_select(struct cpuidle_driver *drv, struct cpuidle_device *dev,
+		   bool *stop_tick)
 {
-	return cpuidle_curr_governor->select(drv, dev);
+	return cpuidle_curr_governor->select(drv, dev, stop_tick);
 }
 
 /**

commit 64bdff698092aa6be28c3b248f887022eec77902
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Wed Mar 14 12:27:21 2018 +0100

    PM: cpuidle/suspend: Add s2idle usage and time state attributes
    
    Add a new attribute group called "s2idle" under the sysfs directory
    of each cpuidle state that supports the ->enter_s2idle callback
    and put two new attributes, "usage" and "time", into that group to
    represent the number of times the given state was requested for
    suspend-to-idle and the total time spent in suspend-to-idle after
    requesting that state, respectively.
    
    That will allow diagnostic information related to suspend-to-idle
    to be collected without enabling advanced debug features and
    analyzing dmesg output.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 68a16827f45f..0003e9a02637 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -131,6 +131,10 @@ int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
 static void enter_s2idle_proper(struct cpuidle_driver *drv,
 				struct cpuidle_device *dev, int index)
 {
+	ktime_t time_start, time_end;
+
+	time_start = ns_to_ktime(local_clock());
+
 	/*
 	 * trace_suspend_resume() called by tick_freeze() for the last CPU
 	 * executing it contains RCU usage regarded as invalid in the idle
@@ -152,6 +156,11 @@ static void enter_s2idle_proper(struct cpuidle_driver *drv,
 	 */
 	RCU_NONIDLE(tick_unfreeze());
 	start_critical_timings();
+
+	time_end = ns_to_ktime(local_clock());
+
+	dev->states_usage[index].s2idle_time += ktime_us_delta(time_end, time_start);
+	dev->states_usage[index].s2idle_usage++;
 }
 
 /**

commit 3fc74bd8a723c91a5b4627079c511fcaf3c75017
Author: Gaurav Jindal <gauravjindal1104@gmail.com>
Date:   Sat Sep 2 00:56:38 2017 +0530

    cpuidle: Avoid assignment in if () argument
    
    Clean up cpuidle_enable_device() to avoid doing an assignment
    in an expression evaluated as an argument of if (), which also
    makes the code in question more readable.
    
    Signed-off-by: Gaurav Jindal <gauravjindal1104@gmail.com>
    [ rjw: Subject & changelog ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 27f9648b61c2..68a16827f45f 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -403,9 +403,11 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 	if (ret)
 		return ret;
 
-	if (cpuidle_curr_governor->enable &&
-	    (ret = cpuidle_curr_governor->enable(drv, dev)))
-		goto fail_sysfs;
+	if (cpuidle_curr_governor->enable) {
+		ret = cpuidle_curr_governor->enable(drv, dev);
+		if (ret)
+			goto fail_sysfs;
+	}
 
 	smp_wmb();
 

commit e7b06a09e7d87ec0d6d8b17eec50fbb93667eee1
Author: Gaurav Jindal <gauravjindal1104@gmail.com>
Date:   Fri Sep 1 20:37:26 2017 +0530

    cpuidle: Clean up cpuidle_enable_device() error handling a bit
    
    Do not fetch per CPU drv if cpuidle_curr_governor is NULL
    to avoid useless per CPU processing.
    
    Signed-off-by: Gaurav Jindal <gauravjindal1104@gmail.com>
    [ rjw: Subject & changelog ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index ed4df58a855e..27f9648b61c2 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -388,9 +388,12 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 	if (dev->enabled)
 		return 0;
 
+	if (!cpuidle_curr_governor)
+		return -EIO;
+
 	drv = cpuidle_get_cpu_driver(dev);
 
-	if (!drv || !cpuidle_curr_governor)
+	if (!drv)
 		return -EIO;
 
 	if (!dev->registered)

commit f187851b9b4a76952b1158b86434563dd2031103
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri Sep 1 14:29:56 2017 +1000

    cpuidle: fix broadcast control when broadcast can not be entered
    
    When failing to enter broadcast timer mode for an idle state that
    requires it, a new state is selected that does not require broadcast,
    but the broadcast variable remains set. This causes
    tick_broadcast_exit to be called despite not having entered broadcast
    mode.
    
    This causes the WARN_ON_ONCE(!irqs_disabled()) to trigger in some
    cases. It does not appear to cause problems for code today, but seems
    to violate the interface so should be fixed.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 484cc8909d5c..ed4df58a855e 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -208,6 +208,7 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 			return -EBUSY;
 		}
 		target_state = &drv->states[index];
+		broadcast = false;
 	}
 
 	/* Take note of the planned idle state. */

commit 28ba086ed30fb3fb714598aa029b894c3754fa7b
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu Aug 10 00:14:45 2017 +0200

    PM / s2idle: Rename ->enter_freeze to ->enter_s2idle
    
    Rename the ->enter_freeze cpuidle driver callback to ->enter_s2idle
    to make it clear that it is used for entering suspend-to-idle and
    rename the related functions, variables and so on accordingly.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 60bb64f4329d..484cc8909d5c 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -77,7 +77,7 @@ static int find_deepest_state(struct cpuidle_driver *drv,
 			      struct cpuidle_device *dev,
 			      unsigned int max_latency,
 			      unsigned int forbidden_flags,
-			      bool freeze)
+			      bool s2idle)
 {
 	unsigned int latency_req = 0;
 	int i, ret = 0;
@@ -89,7 +89,7 @@ static int find_deepest_state(struct cpuidle_driver *drv,
 		if (s->disabled || su->disable || s->exit_latency <= latency_req
 		    || s->exit_latency > max_latency
 		    || (s->flags & forbidden_flags)
-		    || (freeze && !s->enter_freeze))
+		    || (s2idle && !s->enter_s2idle))
 			continue;
 
 		latency_req = s->exit_latency;
@@ -128,7 +128,7 @@ int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
 }
 
 #ifdef CONFIG_SUSPEND
-static void enter_freeze_proper(struct cpuidle_driver *drv,
+static void enter_s2idle_proper(struct cpuidle_driver *drv,
 				struct cpuidle_device *dev, int index)
 {
 	/*
@@ -143,7 +143,7 @@ static void enter_freeze_proper(struct cpuidle_driver *drv,
 	 * suspended is generally unsafe.
 	 */
 	stop_critical_timings();
-	drv->states[index].enter_freeze(dev, drv, index);
+	drv->states[index].enter_s2idle(dev, drv, index);
 	WARN_ON(!irqs_disabled());
 	/*
 	 * timekeeping_resume() that will be called by tick_unfreeze() for the
@@ -155,25 +155,25 @@ static void enter_freeze_proper(struct cpuidle_driver *drv,
 }
 
 /**
- * cpuidle_enter_freeze - Enter an idle state suitable for suspend-to-idle.
+ * cpuidle_enter_s2idle - Enter an idle state suitable for suspend-to-idle.
  * @drv: cpuidle driver for the given CPU.
  * @dev: cpuidle device for the given CPU.
  *
- * If there are states with the ->enter_freeze callback, find the deepest of
+ * If there are states with the ->enter_s2idle callback, find the deepest of
  * them and enter it with frozen tick.
  */
-int cpuidle_enter_freeze(struct cpuidle_driver *drv, struct cpuidle_device *dev)
+int cpuidle_enter_s2idle(struct cpuidle_driver *drv, struct cpuidle_device *dev)
 {
 	int index;
 
 	/*
-	 * Find the deepest state with ->enter_freeze present, which guarantees
+	 * Find the deepest state with ->enter_s2idle present, which guarantees
 	 * that interrupts won't be enabled when it exits and allows the tick to
 	 * be frozen safely.
 	 */
 	index = find_deepest_state(drv, dev, UINT_MAX, 0, true);
 	if (index > 0)
-		enter_freeze_proper(drv, dev, index);
+		enter_s2idle_proper(drv, dev, index);
 
 	return index;
 }

commit f9fccdb9efef60dbcf84d493514b475c41aa866f
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Apr 21 12:43:59 2017 +0200

    cpuidle: Fix idle time tracking
    
    Ville reported that on his Core2, which has TSC stop in idle, we would
    always report very short idle durations. He tracked this down to
    commit:
    
      e93e59ce5b85 ("cpuidle: Replace ktime_get() with local_clock()")
    
    which replaces ktime_get() with local_clock().
    
    Add a sched_clock_idle_wakeup_event() call, which will re-sync the
    clock with ktime_get_ns() when TSC is unstable and no-op otherwise.
    
    Reported-by: Ville Syrj채l채 <ville.syrjala@linux.intel.com>
    Tested-by: Ville Syrj채l채 <ville.syrjala@linux.intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J . Wysocki <rafael.j.wysocki@intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Fixes: e93e59ce5b85 ("cpuidle: Replace ktime_get() with local_clock()")
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 2706be7ed334..60bb64f4329d 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -220,6 +220,7 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	entered_state = target_state->enter(dev, drv, index);
 	start_critical_timings();
 
+	sched_clock_idle_wakeup_event();
 	time_end = ns_to_ktime(local_clock());
 	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);
 

commit 41dc750ea67f317c0deedde713d1728425524ef2
Author: Li, Fei <fei.li@intel.com>
Date:   Thu Apr 27 01:47:25 2017 +0000

    cpuidle: check dev before usage in cpuidle_use_deepest_state()
    
    In case of there is no cpuidle devices registered, dev will be null, and
    panic will be triggered like below;
    In this patch, add checking of dev before usage, like that done in
    cpuidle_idle_call.
    
    Panic without fix:
    [  184.961328] BUG: unable to handle kernel NULL pointer dereference at
      (null)
    [  184.961328] IP: cpuidle_use_deepest_state+0x30/0x60
    ...
    [  184.961328]  play_idle+0x8d/0x210
    [  184.961328]  ? __schedule+0x359/0x8e0
    [  184.961328]  ? _raw_spin_unlock_irqrestore+0x28/0x50
    [  184.961328]  ? kthread_queue_delayed_work+0x41/0x80
    [  184.961328]  clamp_idle_injection_func+0x64/0x1e0
    
    Fixes: bb8313b603eb8 (cpuidle: Allow enforcing deepest idle state selection)
    Signed-off-by: Li, Fei <fei.li@intel.com>
    Tested-by: Shi, Feng <fengx.shi@intel.com>
    Reviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Cc: 4.10+ <stable@vger.kernel.org> # 4.10+
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 548b90be7685..2706be7ed334 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -111,7 +111,8 @@ void cpuidle_use_deepest_state(bool enable)
 
 	preempt_disable();
 	dev = cpuidle_get_device();
-	dev->use_deepest_state = enable;
+	if (dev)
+		dev->use_deepest_state = enable;
 	preempt_enable();
 }
 

commit e601757102cfd3eeae068f53b3bc1234f3a2b2e9
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 1 16:36:40 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/clock.h>
    
    We are going to split <linux/sched/clock.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and .c files.
    
    Create a trivial placeholder <linux/sched/clock.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 62810ff3b00f..548b90be7685 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -12,6 +12,7 @@
 #include <linux/kernel.h>
 #include <linux/mutex.h>
 #include <linux/sched.h>
+#include <linux/sched/clock.h>
 #include <linux/notifier.h>
 #include <linux/pm_qos.h>
 #include <linux/cpu.h>

commit 0e7414b7aa8b294fddefbad020798f7c8ebe1622
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu Dec 1 23:31:32 2016 +0100

    cpuidle: Add a kerneldoc comment to cpuidle_use_deepest_state()
    
    Since cpuidle_use_deepest_state() is not static, add a proper
    kerneldoc comment to it to document its purpose.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index afc005b917fe..62810ff3b00f 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -97,7 +97,13 @@ static int find_deepest_state(struct cpuidle_driver *drv,
 	return ret;
 }
 
-/* Set the current cpu to use the deepest idle state, override governors */
+/**
+ * cpuidle_use_deepest_state - Set/clear governor override flag.
+ * @enable: New value of the flag.
+ *
+ * Set/unset the current CPU to use the deepest idle state (override governors
+ * going forward if set).
+ */
 void cpuidle_use_deepest_state(bool enable)
 {
 	struct cpuidle_device *dev;

commit bb8313b603eb8fd52de48a079bfcd72dcab2ef1e
Author: Jacob Pan <jacob.jun.pan@linux.intel.com>
Date:   Mon Nov 28 23:03:04 2016 -0800

    cpuidle: Allow enforcing deepest idle state selection
    
    When idle injection is used to cap power, we need to override the
    governor's choice of idle states.
    
    For this reason, make it possible the deepest idle state selection to
    be enforced by setting a flag on a given CPU to achieve the maximum
    potential power draw reduction.
    
    Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
    [ rjw: Subject & changelog ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index c73207abb5a4..afc005b917fe 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -97,7 +97,17 @@ static int find_deepest_state(struct cpuidle_driver *drv,
 	return ret;
 }
 
-#ifdef CONFIG_SUSPEND
+/* Set the current cpu to use the deepest idle state, override governors */
+void cpuidle_use_deepest_state(bool enable)
+{
+	struct cpuidle_device *dev;
+
+	preempt_disable();
+	dev = cpuidle_get_device();
+	dev->use_deepest_state = enable;
+	preempt_enable();
+}
+
 /**
  * cpuidle_find_deepest_state - Find the deepest available idle state.
  * @drv: cpuidle driver for the given CPU.
@@ -109,6 +119,7 @@ int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
 	return find_deepest_state(drv, dev, UINT_MAX, 0, false);
 }
 
+#ifdef CONFIG_SUSPEND
 static void enter_freeze_proper(struct cpuidle_driver *drv,
 				struct cpuidle_device *dev, int index)
 {

commit dbd1b8ea43b17e2ed4acda72f83ea17f69408682
Author: Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
Date:   Fri Jul 1 09:24:14 2016 -0500

    cpuidle: Fix last_residency division
    
    Snooze is a poll idle state in powernv and pseries platforms. Snooze
    has a timeout so that if a CPU stays in snooze for more than target
    residency of the next available idle state, then it would exit
    thereby giving chance to the cpuidle governor to re-evaluate and
    promote the CPU to a deeper idle state. Therefore whenever snooze
    exits due to this timeout, its last_residency will be target_residency
    of the next deeper state.
    
    Commit e93e59ce5b85 "cpuidle: Replace ktime_get() with local_clock()"
    changed the math around last_residency calculation. Specifically,
    while converting last_residency value from nano- to microseconds, it
    carries out right shift by 10. Because of that, in snooze timeout
    exit scenarios last_residency calculated is roughly 2.3% less than
    target_residency of the next available state. This pattern is picked
    up by get_typical_interval() in the menu governor and therefore
    expected_interval in menu_select() is frequently less than the
    target_residency of any state other than snooze.
    
    Due to this we are entering snooze at a higher rate, thereby
    affecting the single thread performance.
    
    Fix this by using more precise division via ktime_us_delta().
    
    Fixes: e93e59ce5b85 "cpuidle: Replace ktime_get() with local_clock()"
    Reported-by: Anton Blanchard <anton@samba.org>
    Bisected-by: Shilpasri G Bhat <shilpa.bhat@linux.vnet.ibm.com>
    Signed-off-by: Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Balbir Singh <bsingharora@gmail.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index a4d0059e232c..c73207abb5a4 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -173,7 +173,7 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 
 	struct cpuidle_state *target_state = &drv->states[index];
 	bool broadcast = !!(target_state->flags & CPUIDLE_FLAG_TIMER_STOP);
-	u64 time_start, time_end;
+	ktime_t time_start, time_end;
 	s64 diff;
 
 	/*
@@ -195,13 +195,13 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	sched_idle_set_state(target_state);
 
 	trace_cpu_idle_rcuidle(index, dev->cpu);
-	time_start = local_clock();
+	time_start = ns_to_ktime(local_clock());
 
 	stop_critical_timings();
 	entered_state = target_state->enter(dev, drv, index);
 	start_critical_timings();
 
-	time_end = local_clock();
+	time_end = ns_to_ktime(local_clock());
 	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);
 
 	/* The cpu is no longer idle or about to enter idle. */
@@ -217,11 +217,7 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	if (!cpuidle_state_is_coupled(drv, index))
 		local_irq_enable();
 
-	/*
-	 * local_clock() returns the time in nanosecond, let's shift
-	 * by 10 (divide by 1024) to have microsecond based time.
-	 */
-	diff = (time_end - time_start) >> 10;
+	diff = ktime_us_delta(time_end, time_start);
 	if (diff > INT_MAX)
 		diff = INT_MAX;
 

commit e7387da52028b072489c45efeb7a916c0205ebd2
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Tue May 17 16:54:00 2016 +0200

    cpuidle: Fix cpuidle_state_is_coupled() argument in cpuidle_enter()
    
    Commit 0b89e9aa2856 (cpuidle: delay enabling interrupts until all
    coupled CPUs leave idle) rightfully fixed a regression by letting
    the coupled idle state framework to handle local interrupt enabling
    when the CPU is exiting an idle state.
    
    The current code checks if the idle state is coupled and, if so, it
    will let the coupled code to enable interrupts. This way, it can
    decrement the ready-count before handling the interrupt. This
    mechanism prevents the other CPUs from waiting for a CPU which is
    handling interrupts.
    
    But the check is done against the state index returned by the back
    end driver's ->enter functions which could be different from the
    initial index passed as parameter to the cpuidle_enter_state()
    function.
    
     entered_state = target_state->enter(dev, drv, index);
    
     [ ... ]
    
     if (!cpuidle_state_is_coupled(drv, entered_state))
            local_irq_enable();
    
     [ ... ]
    
    If the 'index' is referring to a coupled idle state but the
    'entered_state' is *not* coupled, then the interrupts are enabled
    again. All CPUs blocked on the sync barrier may busy loop longer
    if the CPU has interrupts to handle before decrementing the
    ready-count. That's consuming more energy than saving.
    
    Fixes: 0b89e9aa2856 (cpuidle: delay enabling interrupts until all coupled CPUs leave idle)
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: 3.15+ <stable@vger.kernel.org> # 3.15+
    [ rjw: Subject & changelog ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 2b8e6ce62e81..a4d0059e232c 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -214,7 +214,7 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 		tick_broadcast_exit();
 	}
 
-	if (!cpuidle_state_is_coupled(drv, entered_state))
+	if (!cpuidle_state_is_coupled(drv, index))
 		local_irq_enable();
 
 	/*

commit e93e59ce5b85e6c2b444f09fd1f707274ec066dc
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Thu Apr 21 10:56:30 2016 +0200

    cpuidle: Replace ktime_get() with local_clock()
    
    The ktime_get() can have a non negligeable overhead, use local_clock()
    instead.
    
    In order to test the difference between ktime_get() and local_clock(),
    a quick hack has been added to trigger, via debugfs, 10000 times a
    call to ktime_get() and local_clock() and measure the elapsed time.
    
    Then the average value, the min and max is computed for each call.
    
    From userspace, the test above was called 100 times every 2 seconds.
    
    So, ktime_get() and local_clock() have been called 1000000 times in
    total.
    
    The results are:
    
    ktime_get():
    ============
     * average: 101 ns (stddev: 27.4)
     * maximum: 38313 ns
     * minimum: 65 ns
    
    local_clock():
    ==============
     * average: 60 ns (stddev: 9.8)
     * maximum: 13487 ns
     * minimum: 46 ns
    
    The local_clock() is faster and more stable.
    
    Even if it is a drop in the ocean, changing the ktime_get() by the
    local_clock() allows to save 80ns at idle time (entry + exit). And
    in some circumstances, especially when there are several CPUs racing
    for the clock access, we save tens of microseconds.
    
    The idle duration resulting from a diff is converted from nanosec to
    microsec. This could be done with integer division (div 1000) - which is
    an expensive operation or by 10 bits shifting (div 1024) - which is fast
    but unprecise.
    
    The following table gives some results at the limits.
    
     ------------------------------------------
    |   nsec   |   div(1000)   |   div(1024)   |
     ------------------------------------------
    |   1e3    |        1 usec |      976 nsec |
     ------------------------------------------
    |   1e6    |     1000 usec |      976 usec |
     ------------------------------------------
    |   1e9    |  1000000 usec |   976562 usec |
     ------------------------------------------
    
    There is a linear deviation of 2.34%. This loss of precision is acceptable
    in the context of the resulting diff which is used for statistics. These
    ones are processed to guess estimate an approximation of the duration of the
    next idle period which ends up into an idle state selection. The selection
    criteria takes into account the next duration based on large intervals,
    represented by the idle state's target residency.
    
    The 2^10 division is enough because the approximation regarding the 1e3
    division is lost in all the approximations done for the next idle duration
    computation.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    [ rjw: Subject ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index c2dd99ab1648..2b8e6ce62e81 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -173,7 +173,7 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 
 	struct cpuidle_state *target_state = &drv->states[index];
 	bool broadcast = !!(target_state->flags & CPUIDLE_FLAG_TIMER_STOP);
-	ktime_t time_start, time_end;
+	u64 time_start, time_end;
 	s64 diff;
 
 	/*
@@ -195,13 +195,13 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	sched_idle_set_state(target_state);
 
 	trace_cpu_idle_rcuidle(index, dev->cpu);
-	time_start = ktime_get();
+	time_start = local_clock();
 
 	stop_critical_timings();
 	entered_state = target_state->enter(dev, drv, index);
 	start_critical_timings();
 
-	time_end = ktime_get();
+	time_end = local_clock();
 	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);
 
 	/* The cpu is no longer idle or about to enter idle. */
@@ -217,7 +217,11 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	if (!cpuidle_state_is_coupled(drv, entered_state))
 		local_irq_enable();
 
-	diff = ktime_to_us(ktime_sub(time_end, time_start));
+	/*
+	 * local_clock() returns the time in nanosecond, let's shift
+	 * by 10 (divide by 1024) to have microsecond based time.
+	 */
+	diff = (time_end - time_start) >> 10;
 	if (diff > INT_MAX)
 		diff = INT_MAX;
 

commit c998c07836f985b24361629dc98506ec7893e7a0
Author: Dave Gerlach <d-gerlach@ti.com>
Date:   Tue Apr 5 14:05:38 2016 -0500

    cpuidle: Indicate when a device has been unregistered
    
    Currently the 'registered' member of the cpuidle_device struct is set
    to 1 during cpuidle_register_device. In this same function there are
    checks to see if the device is already registered to prevent duplicate
    calls to register the device, but this value is never set to 0 even on
    unregister of the device. Because of this, any attempt to call
    cpuidle_register_device after a call to cpuidle_unregister_device will
    fail which shouldn't be the case.
    
    To prevent this, set registered to 0 when the device is unregistered.
    
    Fixes: c878a52d3c7c (cpuidle: Check if device is already registered)
    Signed-off-by: Dave Gerlach <d-gerlach@ti.com>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: All applicable <stable@vger.kernel.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index f996efc56605..c2dd99ab1648 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -433,6 +433,8 @@ static void __cpuidle_unregister_device(struct cpuidle_device *dev)
 	list_del(&dev->device_list);
 	per_cpu(cpuidle_devices, dev->cpu) = NULL;
 	module_put(drv->owner);
+
+	dev->registered = 0;
 }
 
 static void __cpuidle_device_init(struct cpuidle_device *dev)

commit 6f16886b7c050c934305b1f285c3458ff1b6e4e4
Author: Sudeep Holla <Sudeep.Holla@arm.com>
Date:   Thu Jan 21 11:19:29 2016 +0000

    cpuidle: fix fallback mechanism for suspend to idle in absence of enter_freeze
    
    Commit 51164251f5c3 "sched / idle: Drop default_idle_call() fallback
    from call_cpuidle()" made find_deepest_state() return non-negative
    value and check all the states with index > 0.  Also as a result,
    find_deepest_state() returns 0 even when enter_freeze callbacks are not
    implemented and enter_freeze_proper() is called which ends up crashing
    the kernel.
    
    This patch updates the check for index > 0 in cpuidle_enter_freeze and
    cpuidle_idle_call(when idle_should_freeze is true) to restore the
    suspend-to-idle functionality in absence of enter_freeze callback.
    
    Fixes: 51164251f5c3 "sched / idle: Drop default_idle_call() fallback from call_cpuidle()"
    Signed-off-by: Sudeep Holla <sudeep.holla@arm.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 046423b0c5ca..f996efc56605 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -153,7 +153,7 @@ int cpuidle_enter_freeze(struct cpuidle_driver *drv, struct cpuidle_device *dev)
 	 * be frozen safely.
 	 */
 	index = find_deepest_state(drv, dev, UINT_MAX, 0, true);
-	if (index >= 0)
+	if (index > 0)
 		enter_freeze_proper(drv, dev, index);
 
 	return index;

commit 51164251f5c35e6596130ef0de94ffe65fe441e0
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Sat Jan 16 00:54:53 2016 +0100

    sched / idle: Drop default_idle_call() fallback from call_cpuidle()
    
    After commit 9c4b2867ed7c (cpuidle: menu: Fix menu_select() for
    CPUIDLE_DRIVER_STATE_START == 0) it is clear that menu_select()
    cannot return negative values.  Moreover, ladder_select_state()
    will never return a negative value too, so make find_deepest_state()
    return non-negative values too and drop the default_idle_call()
    fallback from call_cpuidle().
    
    This eliminates one branch from the idle loop and makes the governors
    and find_deepest_state() handle the case when all states have been
    disabled from sysfs consistently.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Tested-by: Sudeep Holla <sudeep.holla@arm.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 17a6dc0e2111..046423b0c5ca 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -79,9 +79,9 @@ static int find_deepest_state(struct cpuidle_driver *drv,
 			      bool freeze)
 {
 	unsigned int latency_req = 0;
-	int i, ret = -ENXIO;
+	int i, ret = 0;
 
-	for (i = 0; i < drv->state_count; i++) {
+	for (i = 1; i < drv->state_count; i++) {
 		struct cpuidle_state *s = &drv->states[i];
 		struct cpuidle_state_usage *su = &dev->states_usage[i];
 
@@ -243,7 +243,7 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
  * @drv: the cpuidle driver
  * @dev: the cpuidle device
  *
- * Returns the index of the idle state.
+ * Returns the index of the idle state.  The return value must not be negative.
  */
 int cpuidle_select(struct cpuidle_driver *drv, struct cpuidle_device *dev)
 {

commit ae982073095a44f004d7ffb9f271077abef9dbcf
Merge: f1a3c0b933e7 e625ccec1fa6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 1 19:45:46 2015 -0700

    Merge tag 'pm+acpi-4.3-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull power management and ACPI updates from Rafael Wysocki:
     "From the number of commits perspective, the biggest items are ACPICA
      and cpufreq changes with the latter taking the lead (over 50 commits).
    
      On the cpufreq front, there are many cleanups and minor fixes in the
      core and governors, driver updates etc.  We also have a new cpufreq
      driver for Mediatek MT8173 chips.
    
      ACPICA mostly updates its debug infrastructure and adds a number of
      fixes and cleanups for a good measure.
    
      The Operating Performance Points (OPP) framework is updated with new
      DT bindings and support for them among other things.
    
      We have a few updates of the generic power domains framework and a
      reorganization of the ACPI device enumeration code and bus type
      operations.
    
      And a lot of fixes and cleanups all over.
    
      Included is one branch from the MFD tree as it contains some
      PM-related driver core and ACPI PM changes a few other commits are
      based on.
    
      Specifics:
    
       - ACPICA update to upstream revision 20150818 including method
         tracing extensions to allow more in-depth AML debugging in the
         kernel and a number of assorted fixes and cleanups (Bob Moore, Lv
         Zheng, Markus Elfring).
    
       - ACPI sysfs code updates and a documentation update related to AML
         method tracing (Lv Zheng).
    
       - ACPI EC driver fix related to serialized evaluations of _Qxx
         methods and ACPI tools updates allowing the EC userspace tool to be
         built from the kernel source (Lv Zheng).
    
       - ACPI processor driver updates preparing it for future introduction
         of CPPC support and ACPI PCC mailbox driver updates (Ashwin
         Chaugule).
    
       - ACPI interrupts enumeration fix for a regression related to the
         handling of IRQ attribute conflicts between MADT and the ACPI
         namespace (Jiang Liu).
    
       - Fixes related to ACPI device PM (Mika Westerberg, Srinidhi
         Kasagar).
    
       - ACPI device registration code reorganization to separate the
         sysfs-related code and bus type operations from the rest (Rafael J
         Wysocki).
    
       - Assorted cleanups in the ACPI core (Jarkko Nikula, Mathias Krause,
         Andy Shevchenko, Rafael J Wysocki, Nicolas Iooss).
    
       - ACPI cpufreq driver and ia64 cpufreq driver fixes and cleanups (Pan
         Xinhui, Rafael J Wysocki).
    
       - cpufreq core cleanups on top of the previous changes allowing it to
         preseve its sysfs directories over system suspend/resume (Viresh
         Kumar, Rafael J Wysocki, Sebastian Andrzej Siewior).
    
       - cpufreq fixes and cleanups related to governors (Viresh Kumar).
    
       - cpufreq updates (core and the cpufreq-dt driver) related to the
         turbo/boost mode support (Viresh Kumar, Bartlomiej Zolnierkiewicz).
    
       - New DT bindings for Operating Performance Points (OPP), support for
         them in the OPP framework and in the cpufreq-dt driver plus related
         OPP framework fixes and cleanups (Viresh Kumar).
    
       - cpufreq powernv driver updates (Shilpasri G Bhat).
    
       - New cpufreq driver for Mediatek MT8173 (Pi-Cheng Chen).
    
       - Assorted cpufreq driver (speedstep-lib, sfi, integrator) cleanups
         and fixes (Abhilash Jindal, Andrzej Hajda, Cristian Ardelean).
    
       - intel_pstate driver updates including Skylake-S support, support
         for enabling HW P-states per CPU and an additional vendor bypass
         list entry (Kristen Carlson Accardi, Chen Yu, Ethan Zhao).
    
       - cpuidle core fixes related to the handling of coupled idle states
         (Xunlei Pang).
    
       - intel_idle driver updates including Skylake Client support and
         support for freeze-mode-specific idle states (Len Brown).
    
       - Driver core updates related to power management (Andy Shevchenko,
         Rafael J Wysocki).
    
       - Generic power domains framework fixes and cleanups (Jon Hunter,
         Geert Uytterhoeven, Rajendra Nayak, Ulf Hansson).
    
       - Device PM QoS framework update to allow the latency tolerance
         setting to be exposed to user space via sysfs (Mika Westerberg).
    
       - devfreq support for PPMUv2 in Exynos5433 and a fix for an incorrect
         exynos-ppmu DT binding (Chanwoo Choi, Javier Martinez Canillas).
    
       - System sleep support updates (Alan Stern, Len Brown, SungEun Kim).
    
       - rockchip-io AVS support updates (Heiko Stuebner).
    
       - PM core clocks support fixup (Colin Ian King).
    
       - Power capping RAPL driver update including support for Skylake H/S
         and Broadwell-H (Radivoje Jovanovic, Seiichi Ikarashi).
    
       - Generic device properties framework fixes related to the handling
         of static (driver-provided) property sets (Andy Shevchenko).
    
       - turbostat and cpupower updates (Len Brown, Shilpasri G Bhat,
         Shreyas B Prabhu)"
    
    * tag 'pm+acpi-4.3-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (180 commits)
      cpufreq: speedstep-lib: Use monotonic clock
      cpufreq: powernv: Increase the verbosity of OCC console messages
      cpufreq: sfi: use kmemdup rather than duplicating its implementation
      cpufreq: drop !cpufreq_driver check from cpufreq_parse_governor()
      cpufreq: rename cpufreq_real_policy as cpufreq_user_policy
      cpufreq: remove redundant 'policy' field from user_policy
      cpufreq: remove redundant 'governor' field from user_policy
      cpufreq: update user_policy.* on success
      cpufreq: use memcpy() to copy policy
      cpufreq: remove redundant CPUFREQ_INCOMPATIBLE notifier event
      cpufreq: mediatek: Add MT8173 cpufreq driver
      dt-bindings: mediatek: Add MT8173 CPU DVFS clock bindings
      PM / Domains: Fix typo in description of genpd_dev_pm_detach()
      PM / Domains: Remove unusable governor dummies
      PM / Domains: Make pm_genpd_init() available to modules
      PM / domains: Align column headers and data in pm_genpd_summary output
      powercap / RAPL: disable the 2nd power limit properly
      tools: cpupower: Fix error when running cpupower monitor
      PM / OPP: Drop unlikely before IS_ERR(_OR_NULL)
      PM / OPP: Fix static checker warning (broken 64bit big endian systems)
      ...

commit a1d8561172f369ba56d636df49a6b4d6d77e2123
Merge: 3959df1dfb95 ff277d4250fe
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Aug 31 20:26:22 2015 -0700

    Merge branch 'sched-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull scheduler updates from Ingo Molnar:
     "The biggest change in this cycle is the rewrite of the main SMP load
      balancing metric: the CPU load/utilization.  The main goal was to make
      the metric more precise and more representative - see the changelog of
      this commit for the gory details:
    
        9d89c257dfb9 ("sched/fair: Rewrite runnable load and utilization average tracking")
    
      It is done in a way that significantly reduces complexity of the code:
    
        5 files changed, 249 insertions(+), 494 deletions(-)
    
      and the performance testing results are encouraging.  Nevertheless we
      need to keep an eye on potential regressions, since this potentially
      affects every SMP workload in existence.
    
      This work comes from Yuyang Du.
    
      Other changes:
    
       - SCHED_DL updates.  (Andrea Parri)
    
       - Simplify architecture callbacks by removing finish_arch_switch().
         (Peter Zijlstra et al)
    
       - cputime accounting: guarantee stime + utime == rtime.  (Peter
         Zijlstra)
    
       - optimize idle CPU wakeups some more - inspired by Facebook server
         loads.  (Mike Galbraith)
    
       - stop_machine fixes and updates.  (Oleg Nesterov)
    
       - Introduce the 'trace_sched_waking' tracepoint.  (Peter Zijlstra)
    
       - sched/numa tweaks.  (Srikar Dronamraju)
    
       - misc fixes and small cleanups"
    
    * 'sched-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (44 commits)
      sched/deadline: Fix comment in enqueue_task_dl()
      sched/deadline: Fix comment in push_dl_tasks()
      sched: Change the sched_class::set_cpus_allowed() calling context
      sched: Make sched_class::set_cpus_allowed() unconditional
      sched: Fix a race between __kthread_bind() and sched_setaffinity()
      sched: Ensure a task has a non-normalized vruntime when returning back to CFS
      sched/numa: Fix NUMA_DIRECT topology identification
      tile: Reorganize _switch_to()
      sched, sparc32: Update scheduler comments in copy_thread()
      sched: Remove finish_arch_switch()
      sched, tile: Remove finish_arch_switch
      sched, sh: Fold finish_arch_switch() into switch_to()
      sched, score: Remove finish_arch_switch()
      sched, avr32: Remove finish_arch_switch()
      sched, MIPS: Get rid of finish_arch_switch()
      sched, arm: Remove finish_arch_switch()
      sched/fair: Clean up load average references
      sched/fair: Provide runnable_load_avg back to cfs_rq
      sched/fair: Remove task and group entity load when they are dead
      sched/fair: Init cfs_rq's sched_entity load average
      ...

commit 4c1ed5a6079078699128064664913ae7b079648f
Author: Xunlei Pang <pang.xunlei@linaro.org>
Date:   Tue Aug 4 13:48:56 2015 +0800

    cpuidle/coupled: Remove redundant 'dev' argument of cpuidle_state_is_coupled()
    
    For cpuidle_state_is_coupled(), 'dev' is not used, so remove it.
    
    Signed-off-by: Xunlei Pang <pang.xunlei@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 48b7228563ad..fe79cafb0f14 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -210,7 +210,7 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 		tick_broadcast_exit();
 	}
 
-	if (!cpuidle_state_is_coupled(dev, drv, entered_state))
+	if (!cpuidle_state_is_coupled(drv, entered_state))
 		local_irq_enable();
 
 	diff = ktime_to_us(ktime_sub(time_end, time_start));
@@ -259,7 +259,7 @@ int cpuidle_select(struct cpuidle_driver *drv, struct cpuidle_device *dev)
 int cpuidle_enter(struct cpuidle_driver *drv, struct cpuidle_device *dev,
 		  int index)
 {
-	if (cpuidle_state_is_coupled(dev, drv, index))
+	if (cpuidle_state_is_coupled(drv, index))
 		return cpuidle_enter_state_coupled(dev, drv, index);
 	return cpuidle_enter_state(dev, drv, index);
 }

commit 63caae8480921773b46adec0b6ddac9a844a042f
Author: Lucas Stach <l.stach@pengutronix.de>
Date:   Mon Jul 20 18:34:50 2015 +0200

    sched/idle: Move latency tracing stop/start calls deeper inside the idle loop
    
    Make sure to stop tracing only once we are past a point where
    all latency tracing events have been processed (irqs are not
    enabled again). This has the slight advantage of capturing more
    latency related events in the idle path, but most importantly it
    makes sure that latency tracing doesn't get re-enabled
    inadvertently when new events are coming in.
    
    This makes the irqsoff latency tracer useful again, as we stop
    capturing CPU sleep time as IRQ latency.
    
    Signed-off-by: Lucas Stach <l.stach@pengutronix.de>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rafael J. Wysocki <rjw@rjwysocki.net>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: kernel@pengutronix.de
    Cc: patchwork-lst@pengutronix.de
    Link: http://lkml.kernel.org/r/1437410090-3747-1-git-send-email-l.stach@pengutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index e8e2775c3821..a5d9f2e470ea 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -118,6 +118,7 @@ static void enter_freeze_proper(struct cpuidle_driver *drv,
 	 * cpuidle mechanism enables interrupts and doing that with timekeeping
 	 * suspended is generally unsafe.
 	 */
+	stop_critical_timings();
 	drv->states[index].enter_freeze(dev, drv, index);
 	WARN_ON(!irqs_disabled());
 	/*
@@ -126,6 +127,7 @@ static void enter_freeze_proper(struct cpuidle_driver *drv,
 	 * critical sections, so tell RCU about that.
 	 */
 	RCU_NONIDLE(tick_unfreeze());
+	start_critical_timings();
 }
 
 /**
@@ -190,7 +192,9 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	trace_cpu_idle_rcuidle(index, dev->cpu);
 	time_start = ktime_get();
 
+	stop_critical_timings();
 	entered_state = target_state->enter(dev, drv, index);
+	start_critical_timings();
 
 	time_end = ktime_get();
 	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);

commit ae0afb4f5d44d17a0fd135ae000e2acf12c53617
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu Jul 9 22:59:49 2015 +0200

    suspend-to-idle: Prevent RCU from complaining about tick_freeze()
    
    Put tick_freeze() under RCU_NONIDLE() to prevent RCU from complaining
    about suspicious RCU usage in idle by trace_suspend_resume() called
    from there.
    
    While at it, fix a comment related to another usage of RCU_NONIDLE()
    in enter_freeze_proper().
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Reviewed-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index e8e2775c3821..48b7228563ad 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -112,7 +112,12 @@ int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
 static void enter_freeze_proper(struct cpuidle_driver *drv,
 				struct cpuidle_device *dev, int index)
 {
-	tick_freeze();
+	/*
+	 * trace_suspend_resume() called by tick_freeze() for the last CPU
+	 * executing it contains RCU usage regarded as invalid in the idle
+	 * context, so tell RCU about that.
+	 */
+	RCU_NONIDLE(tick_freeze());
 	/*
 	 * The state used here cannot be a "coupled" one, because the "coupled"
 	 * cpuidle mechanism enables interrupts and doing that with timekeeping
@@ -122,7 +127,7 @@ static void enter_freeze_proper(struct cpuidle_driver *drv,
 	WARN_ON(!irqs_disabled());
 	/*
 	 * timekeeping_resume() that will be called by tick_unfreeze() for the
-	 * last CPU executing it calls functions containing RCU read-side
+	 * first CPU executing it calls functions containing RCU read-side
 	 * critical sections, so tell RCU about that.
 	 */
 	RCU_NONIDLE(tick_unfreeze());

commit ab232ba57043ca85b55ffd7125f3f2c2d7e732ec
Merge: 8ced6789da03 32e8d689dc12 56f487c78015
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Jun 19 01:18:02 2015 +0200

    Merge branches 'pm-sleep' and 'pm-runtime'
    
    * pm-sleep:
      PM / sleep: trace_device_pm_callback coverage in dpm_prepare/complete
      PM / wakeup: add a dummy wakeup_source to record statistics
      PM / sleep: Make suspend-to-idle-specific code depend on CONFIG_SUSPEND
      PM / sleep: Return -EBUSY from suspend_enter() on wakeup detection
      PM / tick: Add tracepoints for suspend-to-idle diagnostics
      PM / sleep: Fix symbol name in a comment in kernel/power/main.c
      leds / PM: fix hibernation on arm when gpio-led used with CPU led trigger
      ARM: omap-device: use SET_NOIRQ_SYSTEM_SLEEP_PM_OPS
      bus: omap_l3_noc: add missed callbacks for suspend-to-disk
      PM / sleep: Add macro to define common noirq system PM callbacks
      PM / sleep: Refine diagnostic messages in enter_state()
      PM / wakeup: validate wakeup source before activating it.
    
    * pm-runtime:
      PM / Runtime: Update last_busy in rpm_resume
      PM / runtime: add note about re-calling in during device probe()

commit 7d51d97925e6cbfa2f7f14e3e3aa363b35ee5c24
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu May 28 04:09:24 2015 +0200

    cpuidle: Do not use CPUIDLE_DRIVER_STATE_START in cpuidle.c
    
    The CPUIDLE_DRIVER_STATE_START symbol is defined as 1 only if
    CONFIG_ARCH_HAS_CPU_RELAX is set, otherwise it is defined as 0.
    However, if CONFIG_ARCH_HAS_CPU_RELAX is set, the first (index 0)
    entry in the cpuidle driver's table of states is overwritten with
    the default "poll" entry by the core.  The "state" defined by the
    "poll" entry doesn't provide ->enter_dead and ->enter_freeze
    callbacks and its exit_latency is 0.
    
    For this reason, it is not necessary to use CPUIDLE_DRIVER_STATE_START
    in cpuidle_play_dead() (->enter_dead is NULL, so the "poll state"
    will be skipped by the loop).
    
    It also is arguably unuseful to return states with exit_latency
    equal to 0 from find_deepest_state(), so the function can be modified
    to start the loop from index 0 and the "poll state" will be skipped by
    it as a result of the check against latency_req.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Reviewed-by: Preeti U Murthy <preeti@linux.vnet.ibm.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index af6dd599c464..7f1b8f507a56 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -65,7 +65,7 @@ int cpuidle_play_dead(void)
 		return -ENODEV;
 
 	/* Find lowest-power state that supports long-term idle */
-	for (i = drv->state_count - 1; i >= CPUIDLE_DRIVER_STATE_START; i--)
+	for (i = drv->state_count - 1; i >= 0; i--)
 		if (drv->states[i].enter_dead)
 			return drv->states[i].enter_dead(dev, i);
 
@@ -79,9 +79,9 @@ static int find_deepest_state(struct cpuidle_driver *drv,
 			      bool freeze)
 {
 	unsigned int latency_req = 0;
-	int i, ret = freeze ? -1 : CPUIDLE_DRIVER_STATE_START - 1;
+	int i, ret = -ENXIO;
 
-	for (i = CPUIDLE_DRIVER_STATE_START; i < drv->state_count; i++) {
+	for (i = 0; i < drv->state_count; i++) {
 		struct cpuidle_state *s = &drv->states[i];
 		struct cpuidle_state_usage *su = &dev->states_usage[i];
 

commit 87e9b9f1d86c2ee9a10c2a4186a72d0af4cc963e
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Sat May 16 01:38:15 2015 +0200

    PM / sleep: Make suspend-to-idle-specific code depend on CONFIG_SUSPEND
    
    Since idle_should_freeze() is defined to always return 'false'
    for CONFIG_SUSPEND unset, all of the code depending on it in
    cpuidle_idle_call() is not necessary in that case.
    
    Make that code depend on CONFIG_SUSPEND too to avoid building it
    when it is not going to be used.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 61c417b9e53f..71459f546145 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -92,6 +92,7 @@ static int find_deepest_state(struct cpuidle_driver *drv,
 	return ret;
 }
 
+#ifdef CONFIG_SUSPEND
 /**
  * cpuidle_find_deepest_state - Find the deepest available idle state.
  * @drv: cpuidle driver for the given CPU.
@@ -145,6 +146,7 @@ int cpuidle_enter_freeze(struct cpuidle_driver *drv, struct cpuidle_device *dev)
 
 	return index;
 }
+#endif /* CONFIG_SUSPEND */
 
 /**
  * cpuidle_enter_state - enter the state and update stats

commit 0d94039fabccaa81d87eafdac509d0dda4df2f7b
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Sun May 10 01:19:52 2015 +0200

    cpuidle: Select a different state on tick_broadcast_enter() failures
    
    If tick_broadcast_enter() fails in cpuidle_enter_state(),
    try to find another idle state to enter instead of invoking
    default_idle_call() immediately and returning -EBUSY which
    should increase the chances of saving some energy in those
    cases.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Reviewed-by: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Tested-by: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Tested-by: Sudeep Holla <sudeep.holla@arm.com>
    Acked-by: Kevin Hilman <khilman@linaro.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index a7b9e679a2ef..af6dd599c464 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -73,7 +73,10 @@ int cpuidle_play_dead(void)
 }
 
 static int find_deepest_state(struct cpuidle_driver *drv,
-			      struct cpuidle_device *dev, bool freeze)
+			      struct cpuidle_device *dev,
+			      unsigned int max_latency,
+			      unsigned int forbidden_flags,
+			      bool freeze)
 {
 	unsigned int latency_req = 0;
 	int i, ret = freeze ? -1 : CPUIDLE_DRIVER_STATE_START - 1;
@@ -83,6 +86,8 @@ static int find_deepest_state(struct cpuidle_driver *drv,
 		struct cpuidle_state_usage *su = &dev->states_usage[i];
 
 		if (s->disabled || su->disable || s->exit_latency <= latency_req
+		    || s->exit_latency > max_latency
+		    || (s->flags & forbidden_flags)
 		    || (freeze && !s->enter_freeze))
 			continue;
 
@@ -100,7 +105,7 @@ static int find_deepest_state(struct cpuidle_driver *drv,
 int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
 			       struct cpuidle_device *dev)
 {
-	return find_deepest_state(drv, dev, false);
+	return find_deepest_state(drv, dev, UINT_MAX, 0, false);
 }
 
 static void enter_freeze_proper(struct cpuidle_driver *drv,
@@ -139,7 +144,7 @@ int cpuidle_enter_freeze(struct cpuidle_driver *drv, struct cpuidle_device *dev)
 	 * that interrupts won't be enabled when it exits and allows the tick to
 	 * be frozen safely.
 	 */
-	index = find_deepest_state(drv, dev, true);
+	index = find_deepest_state(drv, dev, UINT_MAX, 0, true);
 	if (index >= 0)
 		enter_freeze_proper(drv, dev, index);
 
@@ -168,8 +173,13 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	 * CPU as a broadcast timer, this call may fail if it is not available.
 	 */
 	if (broadcast && tick_broadcast_enter()) {
-		default_idle_call();
-		return -EBUSY;
+		index = find_deepest_state(drv, dev, target_state->exit_latency,
+					   CPUIDLE_FLAG_TIMER_STOP, false);
+		if (index < 0) {
+			default_idle_call();
+			return -EBUSY;
+		}
+		target_state = &drv->states[index];
 	}
 
 	/* Take note of the planned idle state. */

commit 827a5aefc542b8fb17c00de06118e5cd0e3800f2
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Sun May 10 01:18:46 2015 +0200

    sched / idle: Call default_idle_call() from cpuidle_enter_state()
    
    The check of the cpuidle_enter() return value against -EBUSY
    made in call_cpuidle() will not be necessary any more if
    cpuidle_enter_state() calls default_idle_call() directly when it
    is about to return -EBUSY, so make that happen and eliminate the
    check.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Reviewed-by: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Tested-by: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Tested-by: Sudeep Holla <sudeep.holla@arm.com>
    Acked-by: Kevin Hilman <khilman@linaro.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 9306dd5f460e..a7b9e679a2ef 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -167,8 +167,10 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	 * local timer will be shut down.  If a local timer is used from another
 	 * CPU as a broadcast timer, this call may fail if it is not available.
 	 */
-	if (broadcast && tick_broadcast_enter())
+	if (broadcast && tick_broadcast_enter()) {
+		default_idle_call();
 		return -EBUSY;
+	}
 
 	/* Take note of the planned idle state. */
 	sched_idle_set_state(target_state);

commit faad38492814112e3e7ce94d90123bbe301fff33
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Sun May 10 01:18:03 2015 +0200

    sched / idle: Call idle_set_state() from cpuidle_enter_state()
    
    Introduce a wrapper function around idle_set_state() called
    sched_idle_set_state() that will pass this_rq() to it as the
    first argument and make cpuidle_enter_state() call the new
    function before and after entering the target state.
    
    At the same time, remove direct invocations of idle_set_state()
    from call_cpuidle().
    
    This will allow the invocation of default_idle_call() to be
    moved from call_cpuidle() to cpuidle_enter_state() safely
    and call_cpuidle() to be simplified a bit as a result.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Reviewed-by: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Tested-by: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Tested-by: Sudeep Holla <sudeep.holla@arm.com>
    Acked-by: Kevin Hilman <khilman@linaro.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 597f88443bdc..9306dd5f460e 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -170,6 +170,9 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	if (broadcast && tick_broadcast_enter())
 		return -EBUSY;
 
+	/* Take note of the planned idle state. */
+	sched_idle_set_state(target_state);
+
 	trace_cpu_idle_rcuidle(index, dev->cpu);
 	time_start = ktime_get();
 
@@ -178,6 +181,9 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	time_end = ktime_get();
 	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);
 
+	/* The cpu is no longer idle or about to enter idle. */
+	sched_idle_set_state(NULL);
+
 	if (broadcast) {
 		if (WARN_ON_ONCE(!irqs_disabled()))
 			local_irq_disable();

commit 7312280bd2ad9df1bcca236c5614091a0bd1504c
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Sat May 9 21:50:32 2015 +0200

    cpuidle: Fix the kerneldoc comment for cpuidle_enter_state()
    
    The kerneldoc comment for cpuidle_enter_state() doesn't match the
    function's header any more, so fix it.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 3b80b77a585d..597f88443bdc 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -150,7 +150,7 @@ int cpuidle_enter_freeze(struct cpuidle_driver *drv, struct cpuidle_device *dev)
  * cpuidle_enter_state - enter the state and update stats
  * @dev: cpuidle device for this cpu
  * @drv: cpuidle driver for this cpu
- * @next_state: index into drv->states of the state to enter
+ * @index: index into the states table in @drv of the state to enter
  */
 int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 			int index)

commit a802ea96454570f3c526dd9d7ad8c706e570444d
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon May 4 22:53:28 2015 +0200

    cpuidle: Check the sign of index in cpuidle_reflect()
    
    Avoid calling the governor's ->reflect method if the state index
    passed to cpuidle_reflect() is negative.
    
    This allows the analogous check to be dropped from menu_reflect(),
    so do that too, and ensures that arbitrary error codes can be
    passed to cpuidle_reflect() as the index with no adverse
    consequences.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Reviewed-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 61c417b9e53f..3b80b77a585d 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -249,7 +249,7 @@ int cpuidle_enter(struct cpuidle_driver *drv, struct cpuidle_device *dev,
  */
 void cpuidle_reflect(struct cpuidle_device *dev, int index)
 {
-	if (cpuidle_curr_governor->reflect)
+	if (cpuidle_curr_governor->reflect && index >= 0)
 		cpuidle_curr_governor->reflect(dev, index);
 }
 

commit df8d9eeadd0f7a216f2476351d5aee43c6550bf0
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Wed Apr 29 15:19:21 2015 +0200

    cpuidle: Run tick_broadcast_exit() with disabled interrupts
    
    Commit 335f49196fd6 (sched/idle: Use explicit broadcast oneshot
    control function) replaced clockevents_notify() invocations in
    cpuidle_idle_call() with direct calls to tick_broadcast_enter()
    and tick_broadcast_exit(), but it overlooked the fact that
    interrupts were already enabled before calling the latter which
    led to functional breakage on systems using idle states with the
    CPUIDLE_FLAG_TIMER_STOP flag set.
    
    Fix that by moving the invocations of tick_broadcast_enter()
    and tick_broadcast_exit() down into cpuidle_enter_state() where
    interrupts are still disabled when tick_broadcast_exit() is
    called.  Also ensure that interrupts will be disabled before
    running tick_broadcast_exit() even if they have been enabled by
    the idle state's ->enter callback.  Trigger a WARN_ON_ONCE() in
    that case, as we generally don't want that to happen for states
    with CPUIDLE_FLAG_TIMER_STOP set.
    
    Fixes: 335f49196fd6 (sched/idle: Use explicit broadcast oneshot control function)
    Reported-and-tested-by: Linus Walleij <linus.walleij@linaro.org>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Reported-and-tested-by: Sudeep Holla <sudeep.holla@arm.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 7a73a279e179..61c417b9e53f 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -158,9 +158,18 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	int entered_state;
 
 	struct cpuidle_state *target_state = &drv->states[index];
+	bool broadcast = !!(target_state->flags & CPUIDLE_FLAG_TIMER_STOP);
 	ktime_t time_start, time_end;
 	s64 diff;
 
+	/*
+	 * Tell the time framework to switch to a broadcast timer because our
+	 * local timer will be shut down.  If a local timer is used from another
+	 * CPU as a broadcast timer, this call may fail if it is not available.
+	 */
+	if (broadcast && tick_broadcast_enter())
+		return -EBUSY;
+
 	trace_cpu_idle_rcuidle(index, dev->cpu);
 	time_start = ktime_get();
 
@@ -169,6 +178,13 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	time_end = ktime_get();
 	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);
 
+	if (broadcast) {
+		if (WARN_ON_ONCE(!irqs_disabled()))
+			local_irq_disable();
+
+		tick_broadcast_exit();
+	}
+
 	if (!cpuidle_state_is_coupled(dev, drv, entered_state))
 		local_irq_enable();
 

commit d75e4af14e228bbe3f86e29bcecb8e6be98d4e04
Author: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
Date:   Tue Mar 31 20:15:09 2015 +0200

    cpuidle: remove state_count field from struct cpuidle_device
    
    Thomas Schlichter reports the following issue on his Samsung NC20:
    
    "The C-states C1 and C2 to the OS when connected to AC, and additionally
     provides the C3 C-state when disconnected from AC.  However, the number
     of C-states shown in sysfs is fixed to the number of C-states present
     at boot.
       If I boot with AC connected, I always only see the C-states up to C2
       even if I disconnect AC.
    
       The reason is commit 130a5f692425 (ACPI / cpuidle: remove dev->state_count
       setting).  It removes the update of dev->state_count, but sysfs uses
       exactly this variable to show the C-states.
    
       The fix is to use drv->state_count in sysfs.  As this is currently the
       last user of dev->state_count, this variable can be completely removed."
    
    Remove dev->state_count as per the above.
    
    Reported-by: Thomas Schlichter <thomas.schlichter@web.de>
    Signed-off-by: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
    Signed-off-by: Kyungmin Park <kyungmin.park@samsung.com>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: 3.14+ <stable@vger.kernel.org> # 3.14+
    [ rjw: Changelog ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 080bd2dbde4b..7a73a279e179 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -330,9 +330,6 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 	if (!dev->registered)
 		return -EINVAL;
 
-	if (!dev->state_count)
-		dev->state_count = drv->state_count;
-
 	ret = cpuidle_add_device_sysfs(dev);
 	if (ret)
 		return ret;

commit ef2b22ac540c018bd574d1846ab95b9bfcf38702
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Mar 2 22:26:55 2015 +0100

    cpuidle / sleep: Use broadcast timer for states that stop local timer
    
    Commit 381063133246 (PM / sleep: Re-implement suspend-to-idle handling)
    overlooked the fact that entering some sufficiently deep idle states
    by CPUs may cause their local timers to stop and in those cases it
    is necessary to switch over to a broadcast timer prior to entering
    the idle state.  If the cpuidle driver in use does not provide
    the new ->enter_freeze callback for any of the idle states, that
    problem affects suspend-to-idle too, but it is not taken into account
    after the changes made by commit 381063133246.
    
    Fix that by changing the definition of cpuidle_enter_freeze() and
    re-arranging of the code in cpuidle_idle_call(), so the former does
    not call cpuidle_enter() any more and the fallback case is handled
    by cpuidle_idle_call() directly.
    
    Fixes: 381063133246 (PM / sleep: Re-implement suspend-to-idle handling)
    Reported-and-tested-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 8b3e132b6a01..080bd2dbde4b 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -44,8 +44,8 @@ void disable_cpuidle(void)
 	off = 1;
 }
 
-static bool cpuidle_not_available(struct cpuidle_driver *drv,
-				  struct cpuidle_device *dev)
+bool cpuidle_not_available(struct cpuidle_driver *drv,
+			   struct cpuidle_device *dev)
 {
 	return off || !initialized || !drv || !dev || !dev->enabled;
 }
@@ -72,14 +72,8 @@ int cpuidle_play_dead(void)
 	return -ENODEV;
 }
 
-/**
- * cpuidle_find_deepest_state - Find deepest state meeting specific conditions.
- * @drv: cpuidle driver for the given CPU.
- * @dev: cpuidle device for the given CPU.
- * @freeze: Whether or not the state should be suitable for suspend-to-idle.
- */
-static int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
-				      struct cpuidle_device *dev, bool freeze)
+static int find_deepest_state(struct cpuidle_driver *drv,
+			      struct cpuidle_device *dev, bool freeze)
 {
 	unsigned int latency_req = 0;
 	int i, ret = freeze ? -1 : CPUIDLE_DRIVER_STATE_START - 1;
@@ -98,6 +92,17 @@ static int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
 	return ret;
 }
 
+/**
+ * cpuidle_find_deepest_state - Find the deepest available idle state.
+ * @drv: cpuidle driver for the given CPU.
+ * @dev: cpuidle device for the given CPU.
+ */
+int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
+			       struct cpuidle_device *dev)
+{
+	return find_deepest_state(drv, dev, false);
+}
+
 static void enter_freeze_proper(struct cpuidle_driver *drv,
 				struct cpuidle_device *dev, int index)
 {
@@ -119,46 +124,26 @@ static void enter_freeze_proper(struct cpuidle_driver *drv,
 
 /**
  * cpuidle_enter_freeze - Enter an idle state suitable for suspend-to-idle.
+ * @drv: cpuidle driver for the given CPU.
+ * @dev: cpuidle device for the given CPU.
  *
  * If there are states with the ->enter_freeze callback, find the deepest of
- * them and enter it with frozen tick.  Otherwise, find the deepest state
- * available and enter it normally.
- *
- * Returns with enabled interrupts.
+ * them and enter it with frozen tick.
  */
-void cpuidle_enter_freeze(void)
+int cpuidle_enter_freeze(struct cpuidle_driver *drv, struct cpuidle_device *dev)
 {
-	struct cpuidle_device *dev = __this_cpu_read(cpuidle_devices);
-	struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
 	int index;
 
-	if (cpuidle_not_available(drv, dev))
-		goto fallback;
-
 	/*
 	 * Find the deepest state with ->enter_freeze present, which guarantees
 	 * that interrupts won't be enabled when it exits and allows the tick to
 	 * be frozen safely.
 	 */
-	index = cpuidle_find_deepest_state(drv, dev, true);
-	if (index >= 0) {
+	index = find_deepest_state(drv, dev, true);
+	if (index >= 0)
 		enter_freeze_proper(drv, dev, index);
-		local_irq_enable();
-		return;
-	}
 
-	/*
-	 * It is not safe to freeze the tick, find the deepest state available
-	 * at all and try to enter it normally.
-	 */
-	index = cpuidle_find_deepest_state(drv, dev, false);
-	if (index >= 0) {
-		cpuidle_enter(drv, dev, index);
-		return;
-	}
-
- fallback:
-	arch_cpu_idle();
+	return index;
 }
 
 /**
@@ -217,9 +202,6 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
  */
 int cpuidle_select(struct cpuidle_driver *drv, struct cpuidle_device *dev)
 {
-	if (cpuidle_not_available(drv, dev))
-		return -ENODEV;
-
 	return cpuidle_curr_governor->select(drv, dev);
 }
 

commit 31a3409065d1d5bf0f12ad76b8c7f471134bf596
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Feb 27 00:39:56 2015 +0100

    cpuidle / sleep: Do sanity checks in cpuidle_enter_freeze() too
    
    Modify cpuidle_enter_freeze() to do the sanity checks done by
    cpuidle_select() to avoid crashing the suspend-to-idle code
    path in case something is missing.
    
    Fixes: 381063133246 (PM / sleep: Re-implement suspend-to-idle handling)
    Original-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index b573f584b15a..8b3e132b6a01 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -44,6 +44,12 @@ void disable_cpuidle(void)
 	off = 1;
 }
 
+static bool cpuidle_not_available(struct cpuidle_driver *drv,
+				  struct cpuidle_device *dev)
+{
+	return off || !initialized || !drv || !dev || !dev->enabled;
+}
+
 /**
  * cpuidle_play_dead - cpu off-lining
  *
@@ -126,6 +132,9 @@ void cpuidle_enter_freeze(void)
 	struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
 	int index;
 
+	if (cpuidle_not_available(drv, dev))
+		goto fallback;
+
 	/*
 	 * Find the deepest state with ->enter_freeze present, which guarantees
 	 * that interrupts won't be enabled when it exits and allows the tick to
@@ -143,10 +152,13 @@ void cpuidle_enter_freeze(void)
 	 * at all and try to enter it normally.
 	 */
 	index = cpuidle_find_deepest_state(drv, dev, false);
-	if (index >= 0)
+	if (index >= 0) {
 		cpuidle_enter(drv, dev, index);
-	else
-		arch_cpu_idle();
+		return;
+	}
+
+ fallback:
+	arch_cpu_idle();
 }
 
 /**
@@ -205,12 +217,9 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
  */
 int cpuidle_select(struct cpuidle_driver *drv, struct cpuidle_device *dev)
 {
-	if (off || !initialized)
+	if (cpuidle_not_available(drv, dev))
 		return -ENODEV;
 
-	if (!drv || !dev || !dev->enabled)
-		return -EBUSY;
-
 	return cpuidle_curr_governor->select(drv, dev);
 }
 

commit 01e04f466e12e883907937eb04a9010533363f55
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Feb 27 00:39:21 2015 +0100

    idle / sleep: Avoid excessive disabling and enabling interrupts
    
    Disabling interrupts at the end of cpuidle_enter_freeze() is not
    useful, because its caller, cpuidle_idle_call(), re-enables them
    right away after invoking it.
    
    To avoid that unnecessary back and forth dance with interrupts,
    make cpuidle_enter_freeze() enable interrupts after calling
    enter_freeze_proper() and drop the local_irq_disable() at its
    end, so that all of the code paths in it end up with interrupts
    enabled.  Then, cpuidle_idle_call() will not need to re-enable
    interrupts after calling cpuidle_enter_freeze() any more, because
    the latter will return with interrupts enabled, in analogy with
    cpuidle_enter().
    
    Reported-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 4d534582514e..b573f584b15a 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -117,6 +117,8 @@ static void enter_freeze_proper(struct cpuidle_driver *drv,
  * If there are states with the ->enter_freeze callback, find the deepest of
  * them and enter it with frozen tick.  Otherwise, find the deepest state
  * available and enter it normally.
+ *
+ * Returns with enabled interrupts.
  */
 void cpuidle_enter_freeze(void)
 {
@@ -132,6 +134,7 @@ void cpuidle_enter_freeze(void)
 	index = cpuidle_find_deepest_state(drv, dev, true);
 	if (index >= 0) {
 		enter_freeze_proper(drv, dev, index);
+		local_irq_enable();
 		return;
 	}
 
@@ -144,9 +147,6 @@ void cpuidle_enter_freeze(void)
 		cpuidle_enter(drv, dev, index);
 	else
 		arch_cpu_idle();
-
-	/* Interrupts are enabled again here. */
-	local_irq_disable();
 }
 
 /**

commit 124cf9117c5f93cc5b324530b7e105b09c729d5d
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Feb 13 23:50:43 2015 +0100

    PM / sleep: Make it possible to quiesce timers during suspend-to-idle
    
    The efficiency of suspend-to-idle depends on being able to keep CPUs
    in the deepest available idle states for as much time as possible.
    Ideally, they should only be brought out of idle by system wakeup
    interrupts.
    
    However, timer interrupts occurring periodically prevent that from
    happening and it is not practical to chase all of the "misbehaving"
    timers in a whack-a-mole fashion.  A much more effective approach is
    to suspend the local ticks for all CPUs and the entire timekeeping
    along the lines of what is done during full suspend, which also
    helps to keep suspend-to-idle and full suspend reasonably similar.
    
    The idea is to suspend the local tick on each CPU executing
    cpuidle_enter_freeze() and to make the last of them suspend the
    entire timekeeping.  That should prevent timer interrupts from
    triggering until an IO interrupt wakes up one of the CPUs.  It
    needs to be done with interrupts disabled on all of the CPUs,
    though, because otherwise the suspended clocksource might be
    accessed by an interrupt handler which might lead to fatal
    consequences.
    
    Unfortunately, the existing ->enter callbacks provided by cpuidle
    drivers generally cannot be used for implementing that, because some
    of them re-enable interrupts temporarily and some idle entry methods
    cause interrupts to be re-enabled automatically on exit.  Also some
    of these callbacks manipulate local clock event devices of the CPUs
    which really shouldn't be done after suspending their ticks.
    
    To overcome that difficulty, introduce a new cpuidle state callback,
    ->enter_freeze, that will be guaranteed (1) to keep interrupts
    disabled all the time (and return with interrupts disabled) and (2)
    not to touch the CPU timer devices.  Modify cpuidle_enter_freeze() to
    look for the deepest available idle state with ->enter_freeze present
    and to make the CPU execute that callback with suspended tick (and the
    last of the online CPUs to execute it with suspended timekeeping).
    
    Suggested-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 23a8d6cc8d30..4d534582514e 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -20,6 +20,7 @@
 #include <linux/hrtimer.h>
 #include <linux/module.h>
 #include <linux/suspend.h>
+#include <linux/tick.h>
 #include <trace/events/power.h>
 
 #include "cpuidle.h"
@@ -69,18 +70,20 @@ int cpuidle_play_dead(void)
  * cpuidle_find_deepest_state - Find deepest state meeting specific conditions.
  * @drv: cpuidle driver for the given CPU.
  * @dev: cpuidle device for the given CPU.
+ * @freeze: Whether or not the state should be suitable for suspend-to-idle.
  */
 static int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
-				      struct cpuidle_device *dev)
+				      struct cpuidle_device *dev, bool freeze)
 {
 	unsigned int latency_req = 0;
-	int i, ret = CPUIDLE_DRIVER_STATE_START - 1;
+	int i, ret = freeze ? -1 : CPUIDLE_DRIVER_STATE_START - 1;
 
 	for (i = CPUIDLE_DRIVER_STATE_START; i < drv->state_count; i++) {
 		struct cpuidle_state *s = &drv->states[i];
 		struct cpuidle_state_usage *su = &dev->states_usage[i];
 
-		if (s->disabled || su->disable || s->exit_latency <= latency_req)
+		if (s->disabled || su->disable || s->exit_latency <= latency_req
+		    || (freeze && !s->enter_freeze))
 			continue;
 
 		latency_req = s->exit_latency;
@@ -89,10 +92,31 @@ static int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
 	return ret;
 }
 
+static void enter_freeze_proper(struct cpuidle_driver *drv,
+				struct cpuidle_device *dev, int index)
+{
+	tick_freeze();
+	/*
+	 * The state used here cannot be a "coupled" one, because the "coupled"
+	 * cpuidle mechanism enables interrupts and doing that with timekeeping
+	 * suspended is generally unsafe.
+	 */
+	drv->states[index].enter_freeze(dev, drv, index);
+	WARN_ON(!irqs_disabled());
+	/*
+	 * timekeeping_resume() that will be called by tick_unfreeze() for the
+	 * last CPU executing it calls functions containing RCU read-side
+	 * critical sections, so tell RCU about that.
+	 */
+	RCU_NONIDLE(tick_unfreeze());
+}
+
 /**
  * cpuidle_enter_freeze - Enter an idle state suitable for suspend-to-idle.
  *
- * Find the deepest state available and enter it.
+ * If there are states with the ->enter_freeze callback, find the deepest of
+ * them and enter it with frozen tick.  Otherwise, find the deepest state
+ * available and enter it normally.
  */
 void cpuidle_enter_freeze(void)
 {
@@ -100,7 +124,22 @@ void cpuidle_enter_freeze(void)
 	struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
 	int index;
 
-	index = cpuidle_find_deepest_state(drv, dev);
+	/*
+	 * Find the deepest state with ->enter_freeze present, which guarantees
+	 * that interrupts won't be enabled when it exits and allows the tick to
+	 * be frozen safely.
+	 */
+	index = cpuidle_find_deepest_state(drv, dev, true);
+	if (index >= 0) {
+		enter_freeze_proper(drv, dev, index);
+		return;
+	}
+
+	/*
+	 * It is not safe to freeze the tick, find the deepest state available
+	 * at all and try to enter it normally.
+	 */
+	index = cpuidle_find_deepest_state(drv, dev, false);
 	if (index >= 0)
 		cpuidle_enter(drv, dev, index);
 	else

commit 3810631332465d967ba5e27ea2c7dff2c9afac6c
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu Feb 12 23:33:15 2015 +0100

    PM / sleep: Re-implement suspend-to-idle handling
    
    In preparation for adding support for quiescing timers in the final
    stage of suspend-to-idle transitions, rework the freeze_enter()
    function making the system wait on a wakeup event, the freeze_wake()
    function terminating the suspend-to-idle loop and the mechanism by
    which deep idle states are entered during suspend-to-idle.
    
    First of all, introduce a simple state machine for suspend-to-idle
    and make the code in question use it.
    
    Second, prevent freeze_enter() from losing wakeup events due to race
    conditions and ensure that the number of online CPUs won't change
    while it is being executed.  In addition to that, make it force
    all of the CPUs re-enter the idle loop in case they are in idle
    states already (so they can enter deeper idle states if possible).
    
    Next, drop cpuidle_use_deepest_state() and replace use_deepest_state
    checks in cpuidle_select() and cpuidle_reflect() with a single
    suspend-to-idle state check in cpuidle_idle_call().
    
    Finally, introduce cpuidle_enter_freeze() that will simply find the
    deepest idle state available to the given CPU and enter it using
    cpuidle_enter().
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 125150dc6e81..23a8d6cc8d30 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -19,6 +19,7 @@
 #include <linux/ktime.h>
 #include <linux/hrtimer.h>
 #include <linux/module.h>
+#include <linux/suspend.h>
 #include <trace/events/power.h>
 
 #include "cpuidle.h"
@@ -32,7 +33,6 @@ LIST_HEAD(cpuidle_detected_devices);
 static int enabled_devices;
 static int off __read_mostly;
 static int initialized __read_mostly;
-static bool use_deepest_state __read_mostly;
 
 int cpuidle_disabled(void)
 {
@@ -66,24 +66,9 @@ int cpuidle_play_dead(void)
 }
 
 /**
- * cpuidle_use_deepest_state - Enable/disable the "deepest idle" mode.
- * @enable: Whether enable or disable the feature.
- *
- * If the "deepest idle" mode is enabled, cpuidle will ignore the governor and
- * always use the state with the greatest exit latency (out of the states that
- * are not disabled).
- *
- * This function can only be called after cpuidle_pause() to avoid races.
- */
-void cpuidle_use_deepest_state(bool enable)
-{
-	use_deepest_state = enable;
-}
-
-/**
- * cpuidle_find_deepest_state - Find the state of the greatest exit latency.
- * @drv: cpuidle driver for a given CPU.
- * @dev: cpuidle device for a given CPU.
+ * cpuidle_find_deepest_state - Find deepest state meeting specific conditions.
+ * @drv: cpuidle driver for the given CPU.
+ * @dev: cpuidle device for the given CPU.
  */
 static int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
 				      struct cpuidle_device *dev)
@@ -104,6 +89,27 @@ static int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
 	return ret;
 }
 
+/**
+ * cpuidle_enter_freeze - Enter an idle state suitable for suspend-to-idle.
+ *
+ * Find the deepest state available and enter it.
+ */
+void cpuidle_enter_freeze(void)
+{
+	struct cpuidle_device *dev = __this_cpu_read(cpuidle_devices);
+	struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
+	int index;
+
+	index = cpuidle_find_deepest_state(drv, dev);
+	if (index >= 0)
+		cpuidle_enter(drv, dev, index);
+	else
+		arch_cpu_idle();
+
+	/* Interrupts are enabled again here. */
+	local_irq_disable();
+}
+
 /**
  * cpuidle_enter_state - enter the state and update stats
  * @dev: cpuidle device for this cpu
@@ -166,9 +172,6 @@ int cpuidle_select(struct cpuidle_driver *drv, struct cpuidle_device *dev)
 	if (!drv || !dev || !dev->enabled)
 		return -EBUSY;
 
-	if (unlikely(use_deepest_state))
-		return cpuidle_find_deepest_state(drv, dev);
-
 	return cpuidle_curr_governor->select(drv, dev);
 }
 
@@ -200,7 +203,7 @@ int cpuidle_enter(struct cpuidle_driver *drv, struct cpuidle_device *dev,
  */
 void cpuidle_reflect(struct cpuidle_device *dev, int index)
 {
-	if (cpuidle_curr_governor->reflect && !unlikely(use_deepest_state))
+	if (cpuidle_curr_governor->reflect)
 		cpuidle_curr_governor->reflect(dev, index);
 }
 

commit 442bf3aaf55a91ebfec71da46a4ee10a3c905bcc
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Thu Sep 4 11:32:09 2014 -0400

    sched: Let the scheduler see CPU idle states
    
    When the cpu enters idle, it stores the cpuidle state pointer in its
    struct rq instance which in turn could be used to make a better decision
    when balancing tasks.
    
    As soon as the cpu exits its idle state, the struct rq reference is
    cleared.
    
    There are a couple of situations where the idle state pointer could be changed
    while it is being consulted:
    
    1. For x86/acpi with dynamic c-states, when a laptop switches from battery
       to AC that could result on removing the deeper idle state. The acpi driver
       triggers:
            'acpi_processor_cst_has_changed'
                    'cpuidle_pause_and_lock'
                            'cpuidle_uninstall_idle_handler'
                                    'kick_all_cpus_sync'.
    
    All cpus will exit their idle state and the pointed object will be set to
    NULL.
    
    2. The cpuidle driver is unloaded. Logically that could happen but not
    in practice because the drivers are always compiled in and 95% of them are
    not coded to unregister themselves.  In any case, the unloading code must
    call 'cpuidle_unregister_device', that calls 'cpuidle_pause_and_lock'
    leading to 'kick_all_cpus_sync' as mentioned above.
    
    A race can happen if we use the pointer and then one of these two scenarios
    occurs at the same moment.
    
    In order to be safe, the idle state pointer stored in the rq must be
    used inside a rcu_read_lock section where we are protected with the
    'rcu_barrier' in the 'cpuidle_uninstall_idle_handler' function. The
    idle_get_state() and idle_put_state() accessors should be used to that
    effect.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: linux-pm@vger.kernel.org
    Cc: linaro-kernel@lists.linaro.org
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/n/tip-@git.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index d31e04ca8703..125150dc6e81 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -225,6 +225,12 @@ void cpuidle_uninstall_idle_handler(void)
 		initialized = 0;
 		wake_up_all_idle_cpus();
 	}
+
+	/*
+	 * Make sure external observers (such as the scheduler)
+	 * are done looking at pointed idle states.
+	 */
+	synchronize_rcu();
 }
 
 /**

commit 2ed903c5485bad0eafdd3d59ff993598736e4f31
Author: Chuansheng Liu <chuansheng.liu@intel.com>
Date:   Thu Sep 4 15:17:55 2014 +0800

    cpuidle: Use wake_up_all_idle_cpus() to wake up all idle cpus
    
    Currently kick_all_cpus_sync() or smp_call_function() can not
    break the polling idle cpu immediately.
    
    Instead using wake_up_all_idle_cpus() which can wake up the polling idle
    cpu quickly is much more helpful for power.
    
    Signed-off-by: Chuansheng Liu <chuansheng.liu@intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: linux-pm@vger.kernel.org
    Cc: changcheng.liu@intel.com
    Cc: xiaoming.wang@intel.com
    Cc: souvik.k.chakravarty@intel.com
    Cc: luto@amacapital.net
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Rafael J. Wysocki <rjw@rjwysocki.net>
    Cc: linux-pm@vger.kernel.org
    Link: http://lkml.kernel.org/r/1409815075-4180-3-git-send-email-chuansheng.liu@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index ee9df5e3f5eb..d31e04ca8703 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -223,7 +223,7 @@ void cpuidle_uninstall_idle_handler(void)
 {
 	if (enabled_devices) {
 		initialized = 0;
-		kick_all_cpus_sync();
+		wake_up_all_idle_cpus();
 	}
 }
 
@@ -530,11 +530,6 @@ EXPORT_SYMBOL_GPL(cpuidle_register);
 
 #ifdef CONFIG_SMP
 
-static void smp_callback(void *v)
-{
-	/* we already woke the CPU up, nothing more to do */
-}
-
 /*
  * This function gets called when a part of the kernel has a new latency
  * requirement.  This means we need to get all processors out of their C-state,
@@ -544,7 +539,7 @@ static void smp_callback(void *v)
 static int cpuidle_latency_notify(struct notifier_block *b,
 		unsigned long l, void *v)
 {
-	smp_call_function(smp_callback, NULL, 1);
+	wake_up_all_idle_cpus();
 	return NOTIFY_OK;
 }
 

commit 30fe6884021b9fa0124609e898a6341be188eb44
Author: Sandeep Tripathy <sandeep.tripathy@linaro.org>
Date:   Wed Jul 2 15:00:58 2014 +0530

    cpuidle: move idle traces to cpuidle_enter_state()
    
    idle_exit event is the first event after a core exits
    idle state. So this should be traced before local irq
    is ebabled. Likewise idle_entry is the last event before
    a core enters idle state. This will ease visualising the
    cpu idle state from kernel traces.
    
    Signed-off-by: Sandeep Tripathy <sandeep.tripathy@linaro.org>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    [rjw: Subject, rebase]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index cb7019977c50..ee9df5e3f5eb 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -119,11 +119,13 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	ktime_t time_start, time_end;
 	s64 diff;
 
+	trace_cpu_idle_rcuidle(index, dev->cpu);
 	time_start = ktime_get();
 
 	entered_state = target_state->enter(dev, drv, index);
 
 	time_end = ktime_get();
+	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);
 
 	if (!cpuidle_state_is_coupled(dev, drv, entered_state))
 		local_irq_enable();

commit a6220fc19afc07fe77cfd16f5b8e568615517091
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon May 5 00:51:54 2014 +0200

    PM / suspend: Always use deepest C-state in the "freeze" sleep state
    
    If freeze_enter() is called, we want to bypass the current cpuidle
    governor and always use the deepest available (that is, not disabled)
    C-state, because we want to save as much energy as reasonably possible
    then and runtime latency constraints don't matter at that point, since
    the system is in a sleep state anyway.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Tested-by: Aubrey Li <aubrey.li@linux.intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index f38359f64cc6..cb7019977c50 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -32,6 +32,7 @@ LIST_HEAD(cpuidle_detected_devices);
 static int enabled_devices;
 static int off __read_mostly;
 static int initialized __read_mostly;
+static bool use_deepest_state __read_mostly;
 
 int cpuidle_disabled(void)
 {
@@ -64,6 +65,45 @@ int cpuidle_play_dead(void)
 	return -ENODEV;
 }
 
+/**
+ * cpuidle_use_deepest_state - Enable/disable the "deepest idle" mode.
+ * @enable: Whether enable or disable the feature.
+ *
+ * If the "deepest idle" mode is enabled, cpuidle will ignore the governor and
+ * always use the state with the greatest exit latency (out of the states that
+ * are not disabled).
+ *
+ * This function can only be called after cpuidle_pause() to avoid races.
+ */
+void cpuidle_use_deepest_state(bool enable)
+{
+	use_deepest_state = enable;
+}
+
+/**
+ * cpuidle_find_deepest_state - Find the state of the greatest exit latency.
+ * @drv: cpuidle driver for a given CPU.
+ * @dev: cpuidle device for a given CPU.
+ */
+static int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
+				      struct cpuidle_device *dev)
+{
+	unsigned int latency_req = 0;
+	int i, ret = CPUIDLE_DRIVER_STATE_START - 1;
+
+	for (i = CPUIDLE_DRIVER_STATE_START; i < drv->state_count; i++) {
+		struct cpuidle_state *s = &drv->states[i];
+		struct cpuidle_state_usage *su = &dev->states_usage[i];
+
+		if (s->disabled || su->disable || s->exit_latency <= latency_req)
+			continue;
+
+		latency_req = s->exit_latency;
+		ret = i;
+	}
+	return ret;
+}
+
 /**
  * cpuidle_enter_state - enter the state and update stats
  * @dev: cpuidle device for this cpu
@@ -124,6 +164,9 @@ int cpuidle_select(struct cpuidle_driver *drv, struct cpuidle_device *dev)
 	if (!drv || !dev || !dev->enabled)
 		return -EBUSY;
 
+	if (unlikely(use_deepest_state))
+		return cpuidle_find_deepest_state(drv, dev);
+
 	return cpuidle_curr_governor->select(drv, dev);
 }
 
@@ -155,7 +198,7 @@ int cpuidle_enter(struct cpuidle_driver *drv, struct cpuidle_device *dev,
  */
 void cpuidle_reflect(struct cpuidle_device *dev, int index)
 {
-	if (cpuidle_curr_governor->reflect)
+	if (cpuidle_curr_governor->reflect && !unlikely(use_deepest_state))
 		cpuidle_curr_governor->reflect(dev, index);
 }
 

commit 52c324f8a87b336496d0f5e9d8dff1aa32bb08cd
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu May 1 00:13:47 2014 +0200

    cpuidle: Combine cpuidle_enabled() with cpuidle_select()
    
    Since both cpuidle_enabled() and cpuidle_select() are only called by
    cpuidle_idle_call(), it is not really useful to keep them separate
    and combining them will help to avoid complicating cpuidle_idle_call()
    even further if governors are changed to return error codes sometimes.
    
    This code modification shouldn't lead to any functional changes.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 8236746e46bb..f38359f64cc6 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -64,26 +64,6 @@ int cpuidle_play_dead(void)
 	return -ENODEV;
 }
 
-/**
- * cpuidle_enabled - check if the cpuidle framework is ready
- * @dev: cpuidle device for this cpu
- * @drv: cpuidle driver for this cpu
- *
- * Return 0 on success, otherwise:
- * -NODEV : the cpuidle framework is not available
- * -EBUSY : the cpuidle framework is not initialized
- */
-int cpuidle_enabled(struct cpuidle_driver *drv, struct cpuidle_device *dev)
-{
-	if (off || !initialized)
-		return -ENODEV;
-
-	if (!drv || !dev || !dev->enabled)
-		return -EBUSY;
-
-	return 0;
-}
-
 /**
  * cpuidle_enter_state - enter the state and update stats
  * @dev: cpuidle device for this cpu
@@ -138,6 +118,12 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
  */
 int cpuidle_select(struct cpuidle_driver *drv, struct cpuidle_device *dev)
 {
+	if (off || !initialized)
+		return -ENODEV;
+
+	if (!drv || !dev || !dev->enabled)
+		return -EBUSY;
+
 	return cpuidle_curr_governor->select(drv, dev);
 }
 

commit 05bf58ca4b8f0be7d7af830f943f6d6b2c9ccee1
Merge: d23082257d83 a1d028bd6d2b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 2 16:22:27 2014 -0700

    Merge branch 'sched-idle-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull sched/idle changes from Ingo Molnar:
     "More idle code reorganization, to prepare for more integration.
    
      (Sent separately because it depended on pending timer work, which is
      now upstream)"
    
    * 'sched-idle-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      sched/idle: Add more comments to the code
      sched/idle: Move idle conditions in cpuidle_idle main function
      sched/idle: Reorganize the idle loop
      cpuidle/idle: Move the cpuidle_idle_call function to idle.c
      idle/cpuidle: Split cpuidle_idle_call main function into smaller functions

commit 4dedde7c7a18f55180574f934dbc1be84ca0400b
Merge: 683b6c6f82a6 0ecfe310f451
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 1 12:48:54 2014 -0700

    Merge tag 'pm+acpi-3.15-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull ACPI and power management updates from Rafael Wysocki:
     "The majority of this material spent some time in linux-next, some of
      it even several weeks.  There are a few relatively fresh commits in
      it, but they are mostly fixes and simple cleanups.
    
      ACPI took the lead this time, both in terms of the number of commits
      and the number of modified lines of code, cpufreq follows and there
      are a few changes in the PM core and in cpuidle too.
    
      A new feature that already got some LWN.net's attention is the device
      PM QoS extension allowing latency tolerance requirements to be
      propagated from leaf devices to their ancestors with hardware
      interfaces for specifying latency tolerance.  That should help systems
      with hardware-driven power management to avoid going too far with it
      in cases when there are latency tolerance constraints.
    
      There also are some significant changes in the ACPI core related to
      the way in which hotplug notifications are handled.  They affect PCI
      hotplug (ACPIPHP) and the ACPI dock station code too.  The bottom line
      is that all those notification now go through the root notify handler
      and are propagated to the interested subsystems by means of callbacks
      instead of having to install a notify handler for each device object
      that we can potentially get hotplug notifications for.
    
      In addition to that ACPICA will now advertise "Windows 2013"
      compatibility for _OSI, because some systems out there don't work
      correctly if that is not done (some of them don't even boot).
    
      On the system suspend side of things, all of the device suspend and
      resume callbacks, except for ->prepare() and ->complete(), are now
      going to be executed asynchronously as that turns out to speed up
      system suspend and resume on some platforms quite significantly and we
      have a few more optimizations in that area.
    
      Apart from that, there are some new device IDs and fixes and cleanups
      all over.  In particular, the system suspend and resume handling by
      cpufreq should be improved and the cpuidle menu governor should be a
      bit more robust now.
    
      Specifics:
    
       - Device PM QoS support for latency tolerance constraints on systems
         with hardware interfaces allowing such constraints to be specified.
         That is necessary to prevent hardware-driven power management from
         becoming overly aggressive on some systems and to prevent power
         management features leading to excessive latencies from being used
         in some cases.
    
       - Consolidation of the handling of ACPI hotplug notifications for
         device objects.  This causes all device hotplug notifications to go
         through the root notify handler (that was executed for all of them
         anyway before) that propagates them to individual subsystems, if
         necessary, by executing callbacks provided by those subsystems
         (those callbacks are associated with struct acpi_device objects
         during device enumeration).  As a result, the code in question
         becomes both smaller in size and more straightforward and all of
         those changes should not affect users.
    
       - ACPICA update, including fixes related to the handling of _PRT in
         cases when it is broken and the addition of "Windows 2013" to the
         list of supported "features" for _OSI (which is necessary to
         support systems that work incorrectly or don't even boot without
         it).  Changes from Bob Moore and Lv Zheng.
    
       - Consolidation of ACPI _OST handling from Jiang Liu.
    
       - ACPI battery and AC fixes allowing unusual system configurations to
         be handled by that code from Alexander Mezin.
    
       - New device IDs for the ACPI LPSS driver from Chiau Ee Chew.
    
       - ACPI fan and thermal optimizations related to system suspend and
         resume from Aaron Lu.
    
       - Cleanups related to ACPI video from Jean Delvare.
    
       - Assorted ACPI fixes and cleanups from Al Stone, Hanjun Guo, Lan
         Tianyu, Paul Bolle, Tomasz Nowicki.
    
       - Intel RAPL (Running Average Power Limits) driver cleanups from
         Jacob Pan.
    
       - intel_pstate fixes and cleanups from Dirk Brandewie.
    
       - cpufreq fixes related to system suspend/resume handling from Viresh
         Kumar.
    
       - cpufreq core fixes and cleanups from Viresh Kumar, Stratos
         Karafotis, Saravana Kannan, Rashika Kheria, Joe Perches.
    
       - cpufreq drivers updates from Viresh Kumar, Zhuoyu Zhang, Rob
         Herring.
    
       - cpuidle fixes related to the menu governor from Tuukka Tikkanen.
    
       - cpuidle fix related to coupled CPUs handling from Paul Burton.
    
       - Asynchronous execution of all device suspend and resume callbacks,
         except for ->prepare and ->complete, during system suspend and
         resume from Chuansheng Liu.
    
       - Delayed resuming of runtime-suspended devices during system suspend
         for the PCI bus type and ACPI PM domain.
    
       - New set of PM helper routines to allow device runtime PM callbacks
         to be used during system suspend and resume more easily from Ulf
         Hansson.
    
       - Assorted fixes and cleanups in the PM core from Geert Uytterhoeven,
         Prabhakar Lad, Philipp Zabel, Rashika Kheria, Sebastian Capella.
    
       - devfreq fix from Saravana Kannan"
    
    * tag 'pm+acpi-3.15-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (162 commits)
      PM / devfreq: Rewrite devfreq_update_status() to fix multiple bugs
      PM / sleep: Correct whitespace errors in <linux/pm.h>
      intel_pstate: Set core to min P state during core offline
      cpufreq: Add stop CPU callback to cpufreq_driver interface
      cpufreq: Remove unnecessary braces
      cpufreq: Fix checkpatch errors and warnings
      cpufreq: powerpc: add cpufreq transition latency for FSL e500mc SoCs
      MAINTAINERS: Reorder maintainer addresses for PM and ACPI
      PM / Runtime: Update runtime_idle() documentation for return value meaning
      video / output: Drop display output class support
      fujitsu-laptop: Drop unneeded include
      acer-wmi: Stop selecting VIDEO_OUTPUT_CONTROL
      ACPI / gpu / drm: Stop selecting VIDEO_OUTPUT_CONTROL
      ACPI / video: fix ACPI_VIDEO dependencies
      cpufreq: remove unused notifier: CPUFREQ_{SUSPENDCHANGE|RESUMECHANGE}
      cpufreq: Do not allow ->setpolicy drivers to provide ->target
      cpufreq: arm_big_little: set 'physical_cluster' for each CPU
      cpufreq: arm_big_little: make vexpress driver depend on bL core driver
      ACPI / button: Add ACPI Button event via netlink routine
      ACPI: Remove duplicate definitions of PREFIX
      ...

commit 0b89e9aa28566cd3e96651dbdd769b026a476d49
Author: Paul Burton <paul.burton@imgtec.com>
Date:   Thu Mar 6 11:02:01 2014 +0000

    cpuidle: delay enabling interrupts until all coupled CPUs leave idle
    
    As described by a comment at the end of cpuidle_enter_state_coupled it
    can be inefficient for coupled idle states to return with IRQs enabled
    since they may proceed to service an interrupt instead of clearing the
    coupled idle state. Until they have finished & cleared the idle state
    all CPUs coupled with them will spin rather than being able to enter a
    safe idle state.
    
    Commits e1689795a784 "cpuidle: Add common time keeping and irq
    enabling" and 554c06ba3ee2 "cpuidle: remove en_core_tk_irqen flag" led
    to the cpuidle_enter_state enabling interrupts for all idle states,
    including coupled ones, making this inefficiency unavoidable by drivers
    & the local_irq_enable near the end of cpuidle_enter_state_coupled
    redundant. This patch avoids enabling interrupts in cpuidle_enter_state
    after a coupled state has been entered, allowing them to remain disabled
    until all coupled CPUs have exited the idle state and
    cpuidle_enter_state_coupled re-enables them.
    
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Paul Burton <paul.burton@imgtec.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index a55e68f2cfc8..366e6840ec46 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -85,7 +85,8 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 
 	time_end = ktime_get();
 
-	local_irq_enable();
+	if (!cpuidle_state_is_coupled(dev, drv, entered_state))
+		local_irq_enable();
 
 	diff = ktime_to_us(ktime_sub(time_end, time_start));
 	if (diff > INT_MAX)

commit 30cdd69e2a266505ca8229c944d361ff350a6959
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Mon Mar 3 08:48:51 2014 +0100

    cpuidle/idle: Move the cpuidle_idle_call function to idle.c
    
    The cpuidle_idle_call does nothing more than calling the three individuals
    function and is no longer used by any arch specific code but only in the
    cpuidle framework code.
    
    We can move this function into the idle task code to ensure better
    proximity to the scheduler code.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Nicolas Pitre <nicolas.pitre@linaro.org>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Cc: rjw@rjwysocki.net
    Cc: preeti@linux.vnet.ibm.com
    Link: http://lkml.kernel.org/r/1393832934-11625-2-git-send-email-daniel.lezcano@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 1506d69b3f0f..166a7322a2b6 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -172,55 +172,6 @@ void cpuidle_reflect(struct cpuidle_device *dev, int index)
 		cpuidle_curr_governor->reflect(dev, index);
 }
 
-/**
- * cpuidle_idle_call - the main idle loop
- *
- * NOTE: no locks or semaphores should be used here
- * return non-zero on failure
- */
-int cpuidle_idle_call(void)
-{
-	struct cpuidle_device *dev = __this_cpu_read(cpuidle_devices);
-	struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
-	int next_state, entered_state, ret;
-	bool broadcast;
-
-	ret = cpuidle_enabled(drv, dev);
-	if (ret < 0)
-		return ret;
-
-	/* ask the governor for the next state */
-	next_state = cpuidle_select(drv, dev);
-
-	if (need_resched()) {
-		dev->last_residency = 0;
-		/* give the governor an opportunity to reflect on the outcome */
-		cpuidle_reflect(dev, next_state);
-		local_irq_enable();
-		return 0;
-	}
-
-	broadcast = !!(drv->states[next_state].flags & CPUIDLE_FLAG_TIMER_STOP);
-
-	if (broadcast &&
-	    clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_ENTER, &dev->cpu))
-		return -EBUSY;
-
-	trace_cpu_idle_rcuidle(next_state, dev->cpu);
-
-	entered_state = cpuidle_enter(drv, dev, next_state);
-
-	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);
-
-	if (broadcast)
-		clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_EXIT, &dev->cpu);
-
-	/* give the governor an opportunity to reflect on the outcome */
-	cpuidle_reflect(dev, entered_state);
-
-	return 0;
-}
-
 /**
  * cpuidle_install_idle_handler - installs the cpuidle idle loop handler
  */

commit 907e30f1bb4a9656d351aa705c1e5931da908701
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Mon Mar 3 08:48:50 2014 +0100

    idle/cpuidle: Split cpuidle_idle_call main function into smaller functions
    
    In order to allow better integration between the cpuidle framework and the
    scheduler, reducing the distance between these two sub-components will
    facilitate this integration by moving part of the cpuidle code in the idle
    task file and, because idle.c is in the sched directory, we have access to
    the scheduler's private structures.
    
    This patch splits the cpuidle_idle_call main entry function into 3 calls
    to a newly added API:
    
     1. select the idle state
     2. enter the idle state
     3. reflect the idle state
    
    The cpuidle_idle_call calls these three functions to implement the main
    idle entry function.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Cc: rjw@rjwysocki.net
    Cc: preeti@linux.vnet.ibm.com
    Link: http://lkml.kernel.org/r/1393832934-11625-1-git-send-email-daniel.lezcano@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 09d05ab262be..1506d69b3f0f 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -64,6 +64,26 @@ int cpuidle_play_dead(void)
 	return -ENODEV;
 }
 
+/**
+ * cpuidle_enabled - check if the cpuidle framework is ready
+ * @dev: cpuidle device for this cpu
+ * @drv: cpuidle driver for this cpu
+ *
+ * Return 0 on success, otherwise:
+ * -NODEV : the cpuidle framework is not available
+ * -EBUSY : the cpuidle framework is not initialized
+ */
+int cpuidle_enabled(struct cpuidle_driver *drv, struct cpuidle_device *dev)
+{
+	if (off || !initialized)
+		return -ENODEV;
+
+	if (!drv || !dev || !dev->enabled)
+		return -EBUSY;
+
+	return 0;
+}
+
 /**
  * cpuidle_enter_state - enter the state and update stats
  * @dev: cpuidle device for this cpu
@@ -107,6 +127,51 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 	return entered_state;
 }
 
+/**
+ * cpuidle_select - ask the cpuidle framework to choose an idle state
+ *
+ * @drv: the cpuidle driver
+ * @dev: the cpuidle device
+ *
+ * Returns the index of the idle state.
+ */
+int cpuidle_select(struct cpuidle_driver *drv, struct cpuidle_device *dev)
+{
+	return cpuidle_curr_governor->select(drv, dev);
+}
+
+/**
+ * cpuidle_enter - enter into the specified idle state
+ *
+ * @drv:   the cpuidle driver tied with the cpu
+ * @dev:   the cpuidle device
+ * @index: the index in the idle state table
+ *
+ * Returns the index in the idle state, < 0 in case of error.
+ * The error code depends on the backend driver
+ */
+int cpuidle_enter(struct cpuidle_driver *drv, struct cpuidle_device *dev,
+		  int index)
+{
+	if (cpuidle_state_is_coupled(dev, drv, index))
+		return cpuidle_enter_state_coupled(dev, drv, index);
+	return cpuidle_enter_state(dev, drv, index);
+}
+
+/**
+ * cpuidle_reflect - tell the underlying governor what was the state
+ * we were in
+ *
+ * @dev  : the cpuidle device
+ * @index: the index in the idle state table
+ *
+ */
+void cpuidle_reflect(struct cpuidle_device *dev, int index)
+{
+	if (cpuidle_curr_governor->reflect)
+		cpuidle_curr_governor->reflect(dev, index);
+}
+
 /**
  * cpuidle_idle_call - the main idle loop
  *
@@ -116,26 +181,21 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 int cpuidle_idle_call(void)
 {
 	struct cpuidle_device *dev = __this_cpu_read(cpuidle_devices);
-	struct cpuidle_driver *drv;
-	int next_state, entered_state;
+	struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
+	int next_state, entered_state, ret;
 	bool broadcast;
 
-	if (off || !initialized)
-		return -ENODEV;
-
-	/* check if the device is ready */
-	if (!dev || !dev->enabled)
-		return -EBUSY;
-
-	drv = cpuidle_get_cpu_driver(dev);
+	ret = cpuidle_enabled(drv, dev);
+	if (ret < 0)
+		return ret;
 
 	/* ask the governor for the next state */
-	next_state = cpuidle_curr_governor->select(drv, dev);
+	next_state = cpuidle_select(drv, dev);
+
 	if (need_resched()) {
 		dev->last_residency = 0;
 		/* give the governor an opportunity to reflect on the outcome */
-		if (cpuidle_curr_governor->reflect)
-			cpuidle_curr_governor->reflect(dev, next_state);
+		cpuidle_reflect(dev, next_state);
 		local_irq_enable();
 		return 0;
 	}
@@ -146,14 +206,9 @@ int cpuidle_idle_call(void)
 	    clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_ENTER, &dev->cpu))
 		return -EBUSY;
 
-
 	trace_cpu_idle_rcuidle(next_state, dev->cpu);
 
-	if (cpuidle_state_is_coupled(dev, drv, next_state))
-		entered_state = cpuidle_enter_state_coupled(dev, drv,
-							    next_state);
-	else
-		entered_state = cpuidle_enter_state(dev, drv, next_state);
+	entered_state = cpuidle_enter(drv, dev, next_state);
 
 	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);
 
@@ -161,8 +216,7 @@ int cpuidle_idle_call(void)
 		clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_EXIT, &dev->cpu);
 
 	/* give the governor an opportunity to reflect on the outcome */
-	if (cpuidle_curr_governor->reflect)
-		cpuidle_curr_governor->reflect(dev, entered_state);
+	cpuidle_reflect(dev, entered_state);
 
 	return 0;
 }

commit ba8f20c2eb4158a443e9d6a909aee5010efa0c69
Author: Preeti U Murthy <preeti@linux.vnet.ibm.com>
Date:   Fri Feb 7 13:36:52 2014 +0530

    cpuidle: Handle clockevents_notify(BROADCAST_ENTER) failure
    
    Some archs set the CPUIDLE_FLAG_TIMER_STOP flag for idle states in which the
    local timers stop. The cpuidle_idle_call() currently handles such idle states
    by calling into the broadcast framework so as to wakeup CPUs at their next
    wakeup event. With the hrtimer mode of broadcast, the BROADCAST_ENTER call
    into the broadcast frameowork can fail for archs that do not have an external
    clock device to handle wakeups and the CPU in question has thus to be made
    the stand by CPU. This patch handles such cases by failing the call into
    cpuidle so that the arch can take some default action. The arch will certainly
    not enter a similar idle state because a failed cpuidle call will also implicitly
    indicate that the broadcast framework has not registered this CPU to be woken up.
    Hence we are safe if we fail the cpuidle call.
    
    In the process move the functions that trace idle statistics just before and
    after the entry and exit into idle states respectively. In other
    scenarios where the call to cpuidle fails, we end up not tracing idle
    entry and exit since a decision on an idle state could not be taken. Similarly
    when the call to broadcast framework fails, we skip tracing idle statistics
    because we are in no further position to take a decision on an alternative
    idle state to enter into.
    
    Signed-off-by: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Cc: deepthi@linux.vnet.ibm.com
    Cc: paulmck@linux.vnet.ibm.com
    Cc: fweisbec@gmail.com
    Cc: paulus@samba.org
    Cc: srivatsa.bhat@linux.vnet.ibm.com
    Cc: svaidy@linux.vnet.ibm.com
    Cc: peterz@infradead.org
    Cc: benh@kernel.crashing.org
    Acked-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: linuxppc-dev@lists.ozlabs.org
    Link: http://lkml.kernel.org/r/20140207080652.17187.66344.stgit@preeti.in.ibm.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index a55e68f2cfc8..09d05ab262be 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -140,12 +140,14 @@ int cpuidle_idle_call(void)
 		return 0;
 	}
 
-	trace_cpu_idle_rcuidle(next_state, dev->cpu);
-
 	broadcast = !!(drv->states[next_state].flags & CPUIDLE_FLAG_TIMER_STOP);
 
-	if (broadcast)
-		clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_ENTER, &dev->cpu);
+	if (broadcast &&
+	    clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_ENTER, &dev->cpu))
+		return -EBUSY;
+
+
+	trace_cpu_idle_rcuidle(next_state, dev->cpu);
 
 	if (cpuidle_state_is_coupled(dev, drv, next_state))
 		entered_state = cpuidle_enter_state_coupled(dev, drv,
@@ -153,11 +155,11 @@ int cpuidle_idle_call(void)
 	else
 		entered_state = cpuidle_enter_state(dev, drv, next_state);
 
+	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);
+
 	if (broadcast)
 		clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_EXIT, &dev->cpu);
 
-	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);
-
 	/* give the governor an opportunity to reflect on the outcome */
 	if (cpuidle_curr_governor->reflect)
 		cpuidle_curr_governor->reflect(dev, entered_state);

commit 813e8e3d6aaa0b511126cce15c16a931afffe768
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Tue Dec 3 10:59:58 2013 -0500

    cpuidle: Check for dev before deregistering it.
    
    If not, we could end up in the unfortunate situation where
    we dereference a NULL pointer b/c we have cpuidle disabled.
    
    This is the case when booting under Xen (which uses the
    ACPI P/C states but disables the CPU idle driver) - and can
    be easily reproduced when booting with cpuidle.off=1.
    
    BUG: unable to handle kernel NULL pointer dereference at           (null)
    IP: [<ffffffff8156db4a>] cpuidle_unregister_device+0x2a/0x90
    .. snip..
    Call Trace:
     [<ffffffff813b15b4>] acpi_processor_power_exit+0x3c/0x5c
     [<ffffffff813af0a9>] acpi_processor_stop+0x61/0xb6
     [<ffffffff814215bf>] __device_release_driver+0fffff81421653>] device_release_driver+0x23/0x30
     [<ffffffff81420ed8>] bus_remove_device+0x108/0x180
     [<ffffffff8141d9d9>] device_del+0x129/0x1c0
     [<ffffffff813cb4b0>] ? unregister_xenbus_watch+0x1f0/0x1f0
     [<ffffffff8141da8e>] device_unregister+0x1e/0x60
     [<ffffffff814243e9>] unregister_cpu+0x39/0x60
     [<ffffffff81019e03>] arch_unregister_cpu+0x23/0x30
     [<ffffffff813c3c51>] handle_vcpu_hotplug_event+0xc1/0xe0
     [<ffffffff813cb4f5>] xenwatch_thread+0x45/0x120
     [<ffffffff810af010>] ? abort_exclusive_wait+0xb0/0xb0
     [<ffffffff8108ec42>] kthread+0xd2/0xf0
     [<ffffffff8108eb70>] ? kthread_create_on_node+0x180/0x180
     [<ffffffff816ce17c>] ret_from_fork+0x7c/0xb0
     [<ffffffff8108eb70>] ? kthread_create_on_node+0x180/0x180
    
    This problem also appears in 3.12 and could be a candidate for backport.
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: All applicable <stable@vger.kernel.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 2a991e468f78..a55e68f2cfc8 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -400,7 +400,7 @@ EXPORT_SYMBOL_GPL(cpuidle_register_device);
  */
 void cpuidle_unregister_device(struct cpuidle_device *dev)
 {
-	if (dev->registered == 0)
+	if (!dev || dev->registered == 0)
 		return;
 
 	cpuidle_pause_and_lock();

commit d7c7f103262bc2248548ed0e113e916e843c4eeb
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Thu Oct 3 21:26:54 2013 +0530

    cpuidle: don't call poll_idle_init() for every cpu
    
    poll_idle_init() just initializes drv->states[0] and so that is
    required to be done only once for each driver.  Currently, it is
    called from cpuidle_enable_device() which is called for every CPU
    that the driver supports.  That is not required, so move it to a
    better place and call it from __cpuidle_register_driver() so that
    the initialization is carried out only once.
    
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 039a807b217a..2a991e468f78 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -226,45 +226,6 @@ void cpuidle_resume(void)
 	mutex_unlock(&cpuidle_lock);
 }
 
-#ifdef CONFIG_ARCH_HAS_CPU_RELAX
-static int poll_idle(struct cpuidle_device *dev,
-		struct cpuidle_driver *drv, int index)
-{
-	ktime_t	t1, t2;
-	s64 diff;
-
-	t1 = ktime_get();
-	local_irq_enable();
-	while (!need_resched())
-		cpu_relax();
-
-	t2 = ktime_get();
-	diff = ktime_to_us(ktime_sub(t2, t1));
-	if (diff > INT_MAX)
-		diff = INT_MAX;
-
-	dev->last_residency = (int) diff;
-
-	return index;
-}
-
-static void poll_idle_init(struct cpuidle_driver *drv)
-{
-	struct cpuidle_state *state = &drv->states[0];
-
-	snprintf(state->name, CPUIDLE_NAME_LEN, "POLL");
-	snprintf(state->desc, CPUIDLE_DESC_LEN, "CPUIDLE CORE POLL IDLE");
-	state->exit_latency = 0;
-	state->target_residency = 0;
-	state->power_usage = -1;
-	state->flags = 0;
-	state->enter = poll_idle;
-	state->disabled = false;
-}
-#else
-static void poll_idle_init(struct cpuidle_driver *drv) {}
-#endif /* CONFIG_ARCH_HAS_CPU_RELAX */
-
 /**
  * cpuidle_enable_device - enables idle PM for a CPU
  * @dev: the CPU
@@ -294,8 +255,6 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 	if (!dev->state_count)
 		dev->state_count = drv->state_count;
 
-	poll_idle_init(drv);
-
 	ret = cpuidle_add_device_sysfs(dev);
 	if (ret)
 		return ret;

commit 6d281e97a1c53abb73477a34806c1a000409c4b9
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Thu Oct 3 21:26:49 2013 +0530

    cpuidle: replace multiline statements with single line in cpuidle_idle_call()
    
    Few statements in cpuidle_idle_call() are broken into multiple lines,
    although that isn't really necessary. Convert those to single line.
    
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 86e805986d6f..039a807b217a 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -145,8 +145,7 @@ int cpuidle_idle_call(void)
 	broadcast = !!(drv->states[next_state].flags & CPUIDLE_FLAG_TIMER_STOP);
 
 	if (broadcast)
-		clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_ENTER,
-				   &dev->cpu);
+		clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_ENTER, &dev->cpu);
 
 	if (cpuidle_state_is_coupled(dev, drv, next_state))
 		entered_state = cpuidle_enter_state_coupled(dev, drv,
@@ -155,8 +154,7 @@ int cpuidle_idle_call(void)
 		entered_state = cpuidle_enter_state(dev, drv, next_state);
 
 	if (broadcast)
-		clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_EXIT,
-				   &dev->cpu);
+		clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_EXIT, &dev->cpu);
 
 	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);
 

commit fb11c9c63f995afbe0e909f061d9866a722cb4bf
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Thu Oct 3 21:26:48 2013 +0530

    cpuidle: reduce code duplication inside cpuidle_idle_call()
    
    We are doing this twice in cpuidle_idle_call() routine:
            drv->states[next_state].flags & CPUIDLE_FLAG_TIMER_STOP
    
    Would be better if we actually store this in a local variable and
    use that. That reduces code duplication and likely makes this piece
    of code run faster (in case the compiler wasn't able to optimize it
    earlier)
    
    [rjw: Cast the result of bitwise AND to bool explicitly using !!]
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 518b542cad54..86e805986d6f 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -118,6 +118,7 @@ int cpuidle_idle_call(void)
 	struct cpuidle_device *dev = __this_cpu_read(cpuidle_devices);
 	struct cpuidle_driver *drv;
 	int next_state, entered_state;
+	bool broadcast;
 
 	if (off || !initialized)
 		return -ENODEV;
@@ -141,7 +142,9 @@ int cpuidle_idle_call(void)
 
 	trace_cpu_idle_rcuidle(next_state, dev->cpu);
 
-	if (drv->states[next_state].flags & CPUIDLE_FLAG_TIMER_STOP)
+	broadcast = !!(drv->states[next_state].flags & CPUIDLE_FLAG_TIMER_STOP);
+
+	if (broadcast)
 		clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_ENTER,
 				   &dev->cpu);
 
@@ -151,7 +154,7 @@ int cpuidle_idle_call(void)
 	else
 		entered_state = cpuidle_enter_state(dev, drv, next_state);
 
-	if (drv->states[next_state].flags & CPUIDLE_FLAG_TIMER_STOP)
+	if (broadcast)
 		clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_EXIT,
 				   &dev->cpu);
 

commit 9b29a86f04f87cdb9eaacadf2e2d33a55af1c7cc
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Thu Oct 3 21:26:47 2013 +0530

    cpuidle: merge two if() statements for checking error cases
    
    Two checks cpuidle_idle_call() cause the same error code to be
    returned if they fail, so merge them for clarity.
    
    [rjw: Changelog]
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 8c91badff00b..518b542cad54 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -119,10 +119,7 @@ int cpuidle_idle_call(void)
 	struct cpuidle_driver *drv;
 	int next_state, entered_state;
 
-	if (off)
-		return -ENODEV;
-
-	if (!initialized)
+	if (off || !initialized)
 		return -ENODEV;
 
 	/* check if the device is ready */

commit 47182668ca140ae067d5961ec8c59edf646b36c7
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Thu Oct 3 21:26:46 2013 +0530

    cpuidle: rearrange __cpuidle_register_device() to keep minimal exit points
    
    This patch rearranges __cpuidle_register_device() a bit in order to
    reduce the number of exit points in that function.
    
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 211e504263fa..8c91badff00b 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -383,13 +383,12 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 	list_add(&dev->device_list, &cpuidle_detected_devices);
 
 	ret = cpuidle_coupled_register_device(dev);
-	if (ret) {
+	if (ret)
 		__cpuidle_unregister_device(dev);
-		return ret;
-	}
+	else
+		dev->registered = 1;
 
-	dev->registered = 1;
-	return 0;
+	return ret;
 }
 
 /**

commit 267d4bf8ee6dbde889f4c55d0188f561616dbc7a
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Thu Oct 3 21:26:43 2013 +0530

    cpuidle: make __cpuidle_device_init() return void
    
    The only value returned by __cpuidle_device_init() is 0, so it very
    well may be a void function.  Make that happen.
    
    [rjw: Changelog]
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 8827c02af87c..211e504263fa 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -358,12 +358,10 @@ static void __cpuidle_unregister_device(struct cpuidle_device *dev)
 	module_put(drv->owner);
 }
 
-static int __cpuidle_device_init(struct cpuidle_device *dev)
+static void __cpuidle_device_init(struct cpuidle_device *dev)
 {
 	memset(dev->states_usage, 0, sizeof(dev->states_usage));
 	dev->last_residency = 0;
-
-	return 0;
 }
 
 /**
@@ -410,9 +408,7 @@ int cpuidle_register_device(struct cpuidle_device *dev)
 	if (dev->registered)
 		goto out_unlock;
 
-	ret = __cpuidle_device_init(dev);
-	if (ret)
-		goto out_unlock;
+	__cpuidle_device_init(dev);
 
 	ret = __cpuidle_register_device(dev);
 	if (ret)

commit caf4a36e818ba8df4e002b7dfa4eff5b8384dda0
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Thu Oct 3 21:26:41 2013 +0530

    cpuidle: Fix comments in cpuidle core
    
    Some comments in cpuidle core files contain trivial mistakes.
    This patch fixes them.
    
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index d75040ddd2b3..8827c02af87c 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -516,7 +516,7 @@ int cpuidle_register(struct cpuidle_driver *drv,
 
 #ifdef CONFIG_ARCH_NEEDS_CPU_IDLE_COUPLED
 		/*
-		 * On multiplatform for ARM, the coupled idle states could
+		 * On multiplatform for ARM, the coupled idle states could be
 		 * enabled in the kernel even if the cpuidle driver does not
 		 * use it. Note, coupled_cpus is a struct copy.
 		 */

commit c878a52d3c7cabab5b24460825c24eafd8be7058
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Wed Jun 12 15:08:55 2013 +0200

    cpuidle: Check if device is already registered
    
    Make __cpuidle_register_device() check whether or not the device has
    been registered already and return -EBUSY immediately if that's the
    case.
    
    [rjw: Changelog]
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 5b63185da59b..d75040ddd2b3 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -400,13 +400,16 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
  */
 int cpuidle_register_device(struct cpuidle_device *dev)
 {
-	int ret;
+	int ret = -EBUSY;
 
 	if (!dev)
 		return -EINVAL;
 
 	mutex_lock(&cpuidle_lock);
 
+	if (dev->registered)
+		goto out_unlock;
+
 	ret = __cpuidle_device_init(dev);
 	if (ret)
 		goto out_unlock;

commit 5df0aa7341bd94ca2023a60c64c63faeb6ec209d
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Wed Jun 12 15:08:54 2013 +0200

    cpuidle: Introduce __cpuidle_device_init()
    
    Add __cpuidle_device_init() for initializing the cpuidle_device
    structure.
    
    [rjw: Changelog]
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index d78c6d89272f..5b63185da59b 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -276,7 +276,7 @@ static void poll_idle_init(struct cpuidle_driver *drv) {}
  */
 int cpuidle_enable_device(struct cpuidle_device *dev)
 {
-	int ret, i;
+	int ret;
 	struct cpuidle_driver *drv;
 
 	if (!dev)
@@ -306,12 +306,6 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 	    (ret = cpuidle_curr_governor->enable(drv, dev)))
 		goto fail_sysfs;
 
-	for (i = 0; i < dev->state_count; i++) {
-		dev->states_usage[i].usage = 0;
-		dev->states_usage[i].time = 0;
-	}
-	dev->last_residency = 0;
-
 	smp_wmb();
 
 	dev->enabled = 1;
@@ -364,6 +358,14 @@ static void __cpuidle_unregister_device(struct cpuidle_device *dev)
 	module_put(drv->owner);
 }
 
+static int __cpuidle_device_init(struct cpuidle_device *dev)
+{
+	memset(dev->states_usage, 0, sizeof(dev->states_usage));
+	dev->last_residency = 0;
+
+	return 0;
+}
+
 /**
  * __cpuidle_register_device - internal register function called before register
  * and enable routines
@@ -405,6 +407,10 @@ int cpuidle_register_device(struct cpuidle_device *dev)
 
 	mutex_lock(&cpuidle_lock);
 
+	ret = __cpuidle_device_init(dev);
+	if (ret)
+		goto out_unlock;
+
 	ret = __cpuidle_register_device(dev);
 	if (ret)
 		goto out_unlock;

commit f6bb51a53a7535c79d6c65862d6b48e83340b337
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Wed Jun 12 15:08:53 2013 +0200

    cpuidle: Introduce __cpuidle_unregister_device()
    
    To reduce code duplication related to the unregistration of cpuidle
    devices, introduce __cpuidle_unregister_device() and move all of the
    unregistration code to that function.
    
    [rjw: Changelog]
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 4deed977f209..d78c6d89272f 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -42,8 +42,6 @@ void disable_cpuidle(void)
 	off = 1;
 }
 
-static int __cpuidle_register_device(struct cpuidle_device *dev);
-
 /**
  * cpuidle_play_dead - cpu off-lining
  *
@@ -357,6 +355,15 @@ void cpuidle_disable_device(struct cpuidle_device *dev)
 
 EXPORT_SYMBOL_GPL(cpuidle_disable_device);
 
+static void __cpuidle_unregister_device(struct cpuidle_device *dev)
+{
+	struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
+
+	list_del(&dev->device_list);
+	per_cpu(cpuidle_devices, dev->cpu) = NULL;
+	module_put(drv->owner);
+}
+
 /**
  * __cpuidle_register_device - internal register function called before register
  * and enable routines
@@ -374,24 +381,15 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 
 	per_cpu(cpuidle_devices, dev->cpu) = dev;
 	list_add(&dev->device_list, &cpuidle_detected_devices);
-	ret = cpuidle_add_sysfs(dev);
-	if (ret)
-		goto err_sysfs;
 
 	ret = cpuidle_coupled_register_device(dev);
-	if (ret)
-		goto err_coupled;
+	if (ret) {
+		__cpuidle_unregister_device(dev);
+		return ret;
+	}
 
 	dev->registered = 1;
 	return 0;
-
-err_coupled:
-	cpuidle_remove_sysfs(dev);
-err_sysfs:
-	list_del(&dev->device_list);
-	per_cpu(cpuidle_devices, dev->cpu) = NULL;
-	module_put(drv->owner);
-	return ret;
 }
 
 /**
@@ -407,22 +405,30 @@ int cpuidle_register_device(struct cpuidle_device *dev)
 
 	mutex_lock(&cpuidle_lock);
 
-	if ((ret = __cpuidle_register_device(dev))) {
-		mutex_unlock(&cpuidle_lock);
-		return ret;
-	}
+	ret = __cpuidle_register_device(dev);
+	if (ret)
+		goto out_unlock;
+
+	ret = cpuidle_add_sysfs(dev);
+	if (ret)
+		goto out_unregister;
 
 	ret = cpuidle_enable_device(dev);
-	if (ret) {
-		mutex_unlock(&cpuidle_lock);
-		return ret;
-	}
+	if (ret)
+		goto out_sysfs;
 
 	cpuidle_install_idle_handler();
 
+out_unlock:
 	mutex_unlock(&cpuidle_lock);
 
-	return 0;
+	return ret;
+
+out_sysfs:
+	cpuidle_remove_sysfs(dev);
+out_unregister:
+	__cpuidle_unregister_device(dev);
+	goto out_unlock;
 }
 
 EXPORT_SYMBOL_GPL(cpuidle_register_device);
@@ -433,8 +439,6 @@ EXPORT_SYMBOL_GPL(cpuidle_register_device);
  */
 void cpuidle_unregister_device(struct cpuidle_device *dev)
 {
-	struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
-
 	if (dev->registered == 0)
 		return;
 
@@ -443,14 +447,12 @@ void cpuidle_unregister_device(struct cpuidle_device *dev)
 	cpuidle_disable_device(dev);
 
 	cpuidle_remove_sysfs(dev);
-	list_del(&dev->device_list);
-	per_cpu(cpuidle_devices, dev->cpu) = NULL;
+
+	__cpuidle_unregister_device(dev);
 
 	cpuidle_coupled_unregister_device(dev);
 
 	cpuidle_resume_and_unlock();
-
-	module_put(drv->owner);
 }
 
 EXPORT_SYMBOL_GPL(cpuidle_unregister_device);

commit 10b9d3f8a4d5c82bff5b232a0063669dc0e0d725
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Wed Jun 12 15:08:49 2013 +0200

    cpuidle: Check cpuidle_enable_device() return value
    
    We previously changed the ordering of the cpuidle framework
    initialization so that the governors are registered before the
    drivers which can register their devices right from the start.
    
    Now, we can safely remove the __cpuidle_register_device() call hack
    in cpuidle_enable_device() and check if the driver has been
    registered before enabling it.  Then, cpuidle_register_device() can
    consistently check the cpuidle_enable_device() return value when
    enabling the device.
    
    [rjw: Changelog]
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index fdc432f18022..4deed977f209 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -292,15 +292,12 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 	if (!drv || !cpuidle_curr_governor)
 		return -EIO;
 
+	if (!dev->registered)
+		return -EINVAL;
+
 	if (!dev->state_count)
 		dev->state_count = drv->state_count;
 
-	if (dev->registered == 0) {
-		ret = __cpuidle_register_device(dev);
-		if (ret)
-			return ret;
-	}
-
 	poll_idle_init(drv);
 
 	ret = cpuidle_add_device_sysfs(dev);
@@ -415,13 +412,17 @@ int cpuidle_register_device(struct cpuidle_device *dev)
 		return ret;
 	}
 
-	cpuidle_enable_device(dev);
+	ret = cpuidle_enable_device(dev);
+	if (ret) {
+		mutex_unlock(&cpuidle_lock);
+		return ret;
+	}
+
 	cpuidle_install_idle_handler();
 
 	mutex_unlock(&cpuidle_lock);
 
 	return 0;
-
 }
 
 EXPORT_SYMBOL_GPL(cpuidle_register_device);

commit 82467a5a885ddd9f80309682159da8db510e7832
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Fri Jun 7 21:53:09 2013 +0000

    cpuidle: simplify multiple driver support
    
    Commit bf4d1b5 (cpuidle: support multiple drivers) introduced support
    for using multiple cpuidle drivers at the same time.  It added a
    couple of new APIs to register the driver per CPU, but that led to
    some unnecessary code complexity related to the kernel config options
    deciding whether or not the multiple driver support is enabled.  The
    code has to work as it did before when the multiple driver support is
    not enabled and the multiple driver support has to be compatible with
    the previously existing API.
    
    Remove the new API, not used by any driver in the tree yet (but
    needed for the HMP cpuidle drivers that will be submitted soon), and
    add a new cpumask pointer to the cpuidle driver structure that will
    point to the mask of CPUs handled by the given driver.  That will
    allow the cpuidle_[un]register_driver() API to be used for the
    multiple driver support along with the cpuidle_[un]register()
    functions added recently.
    
    [rjw: Changelog]
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index c3a93fece819..fdc432f18022 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -466,7 +466,7 @@ void cpuidle_unregister(struct cpuidle_driver *drv)
 	int cpu;
 	struct cpuidle_device *device;
 
-	for_each_possible_cpu(cpu) {
+	for_each_cpu(cpu, drv->cpumask) {
 		device = &per_cpu(cpuidle_dev, cpu);
 		cpuidle_unregister_device(device);
 	}
@@ -498,7 +498,7 @@ int cpuidle_register(struct cpuidle_driver *drv,
 		return ret;
 	}
 
-	for_each_possible_cpu(cpu) {
+	for_each_cpu(cpu, drv->cpumask) {
 		device = &per_cpu(cpuidle_dev, cpu);
 		device->cpu = cpu;
 

commit 1c192d047a0ddc8e25a8b8f43c80c93330bdf929
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Tue Apr 23 15:28:44 2013 +0000

    cpuidle: fix comment format
    
    Fix comment format for the kernel doc script.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 49e8d302af55..c3a93fece819 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -454,7 +454,7 @@ void cpuidle_unregister_device(struct cpuidle_device *dev)
 
 EXPORT_SYMBOL_GPL(cpuidle_unregister_device);
 
-/*
+/**
  * cpuidle_unregister: unregister a driver and the devices. This function
  * can be used only if the driver has been previously registered through
  * the cpuidle_register function.

commit 4c637b2175a0dc65d533494225525c6c82d73293
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Tue Apr 23 08:54:33 2013 +0000

    cpuidle: make a single register function for all
    
    The usual scheme to initialize a cpuidle driver on a SMP is:
    
            cpuidle_register_driver(drv);
            for_each_possible_cpu(cpu) {
                    device = &per_cpu(cpuidle_dev, cpu);
                    cpuidle_register_device(device);
            }
    
    This code is duplicated in each cpuidle driver.
    
    On UP systems, it is done this way:
    
            cpuidle_register_driver(drv);
            device = &per_cpu(cpuidle_dev, cpu);
            cpuidle_register_device(device);
    
    On UP, the macro 'for_each_cpu' does one iteration:
    
    #define for_each_cpu(cpu, mask)                 \
            for ((cpu) = 0; (cpu) < 1; (cpu)++, (void)mask)
    
    Hence, the initialization loop is the same for UP than SMP.
    
    Beside, we saw different bugs / mis-initialization / return code unchecked in
    the different drivers, the code is duplicated including bugs. After fixing all
    these ones, it appears the initialization pattern is the same for everyone.
    
    Please note, some drivers are doing dev->state_count = drv->state_count. This is
    not necessary because it is done by the cpuidle_enable_device function in the
    cpuidle framework. This is true, until you have the same states for all your
    devices. Otherwise, the 'low level' API should be used instead with the specific
    initialization for the driver.
    
    Let's add a wrapper function doing this initialization with a cpumask parameter
    for the coupled idle states and use it for all the drivers.
    
    That will save a lot of LOC, consolidate the code, and the modifications in the
    future could be done in a single place. Another benefit is the consolidation of
    the cpuidle_device variable which is now in the cpuidle framework and no longer
    spread accross the different arch specific drivers.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 0da795b9dbbf..49e8d302af55 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -24,6 +24,7 @@
 #include "cpuidle.h"
 
 DEFINE_PER_CPU(struct cpuidle_device *, cpuidle_devices);
+DEFINE_PER_CPU(struct cpuidle_device, cpuidle_dev);
 
 DEFINE_MUTEX(cpuidle_lock);
 LIST_HEAD(cpuidle_detected_devices);
@@ -453,6 +454,77 @@ void cpuidle_unregister_device(struct cpuidle_device *dev)
 
 EXPORT_SYMBOL_GPL(cpuidle_unregister_device);
 
+/*
+ * cpuidle_unregister: unregister a driver and the devices. This function
+ * can be used only if the driver has been previously registered through
+ * the cpuidle_register function.
+ *
+ * @drv: a valid pointer to a struct cpuidle_driver
+ */
+void cpuidle_unregister(struct cpuidle_driver *drv)
+{
+	int cpu;
+	struct cpuidle_device *device;
+
+	for_each_possible_cpu(cpu) {
+		device = &per_cpu(cpuidle_dev, cpu);
+		cpuidle_unregister_device(device);
+	}
+
+	cpuidle_unregister_driver(drv);
+}
+EXPORT_SYMBOL_GPL(cpuidle_unregister);
+
+/**
+ * cpuidle_register: registers the driver and the cpu devices with the
+ * coupled_cpus passed as parameter. This function is used for all common
+ * initialization pattern there are in the arch specific drivers. The
+ * devices is globally defined in this file.
+ *
+ * @drv         : a valid pointer to a struct cpuidle_driver
+ * @coupled_cpus: a cpumask for the coupled states
+ *
+ * Returns 0 on success, < 0 otherwise
+ */
+int cpuidle_register(struct cpuidle_driver *drv,
+		     const struct cpumask *const coupled_cpus)
+{
+	int ret, cpu;
+	struct cpuidle_device *device;
+
+	ret = cpuidle_register_driver(drv);
+	if (ret) {
+		pr_err("failed to register cpuidle driver\n");
+		return ret;
+	}
+
+	for_each_possible_cpu(cpu) {
+		device = &per_cpu(cpuidle_dev, cpu);
+		device->cpu = cpu;
+
+#ifdef CONFIG_ARCH_NEEDS_CPU_IDLE_COUPLED
+		/*
+		 * On multiplatform for ARM, the coupled idle states could
+		 * enabled in the kernel even if the cpuidle driver does not
+		 * use it. Note, coupled_cpus is a struct copy.
+		 */
+		if (coupled_cpus)
+			device->coupled_cpus = *coupled_cpus;
+#endif
+		ret = cpuidle_register_device(device);
+		if (!ret)
+			continue;
+
+		pr_err("Failed to register cpuidle device for cpu%d\n", cpu);
+
+		cpuidle_unregister(drv);
+		break;
+	}
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(cpuidle_register);
+
 #ifdef CONFIG_SMP
 
 static void smp_callback(void *v)

commit 554c06ba3ee29cf453fca17e9e61120b75aa476d
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Tue Apr 23 08:54:31 2013 +0000

    cpuidle: remove en_core_tk_irqen flag
    
    The en_core_tk_irqen flag is set in all the cpuidle driver which
    means it is not necessary to specify this flag.
    
    Remove the flag and the code related to it.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Kevin Hilman <khilman@linaro.org>  # for mach-omap2/*
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index c50037029184..0da795b9dbbf 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -43,24 +43,6 @@ void disable_cpuidle(void)
 
 static int __cpuidle_register_device(struct cpuidle_device *dev);
 
-static inline int cpuidle_enter(struct cpuidle_device *dev,
-				struct cpuidle_driver *drv, int index)
-{
-	struct cpuidle_state *target_state = &drv->states[index];
-	return target_state->enter(dev, drv, index);
-}
-
-static inline int cpuidle_enter_tk(struct cpuidle_device *dev,
-			       struct cpuidle_driver *drv, int index)
-{
-	return cpuidle_wrap_enter(dev, drv, index, cpuidle_enter);
-}
-
-typedef int (*cpuidle_enter_t)(struct cpuidle_device *dev,
-			       struct cpuidle_driver *drv, int index);
-
-static cpuidle_enter_t cpuidle_enter_ops;
-
 /**
  * cpuidle_play_dead - cpu off-lining
  *
@@ -90,11 +72,27 @@ int cpuidle_play_dead(void)
  * @next_state: index into drv->states of the state to enter
  */
 int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
-		int next_state)
+			int index)
 {
 	int entered_state;
 
-	entered_state = cpuidle_enter_ops(dev, drv, next_state);
+	struct cpuidle_state *target_state = &drv->states[index];
+	ktime_t time_start, time_end;
+	s64 diff;
+
+	time_start = ktime_get();
+
+	entered_state = target_state->enter(dev, drv, index);
+
+	time_end = ktime_get();
+
+	local_irq_enable();
+
+	diff = ktime_to_us(ktime_sub(time_end, time_start));
+	if (diff > INT_MAX)
+		diff = INT_MAX;
+
+	dev->last_residency = (int) diff;
 
 	if (entered_state >= 0) {
 		/* Update cpuidle counters */
@@ -231,37 +229,6 @@ void cpuidle_resume(void)
 	mutex_unlock(&cpuidle_lock);
 }
 
-/**
- * cpuidle_wrap_enter - performs timekeeping and irqen around enter function
- * @dev: pointer to a valid cpuidle_device object
- * @drv: pointer to a valid cpuidle_driver object
- * @index: index of the target cpuidle state.
- */
-int cpuidle_wrap_enter(struct cpuidle_device *dev,
-				struct cpuidle_driver *drv, int index,
-				int (*enter)(struct cpuidle_device *dev,
-					struct cpuidle_driver *drv, int index))
-{
-	ktime_t time_start, time_end;
-	s64 diff;
-
-	time_start = ktime_get();
-
-	index = enter(dev, drv, index);
-
-	time_end = ktime_get();
-
-	local_irq_enable();
-
-	diff = ktime_to_us(ktime_sub(time_end, time_start));
-	if (diff > INT_MAX)
-		diff = INT_MAX;
-
-	dev->last_residency = (int) diff;
-
-	return index;
-}
-
 #ifdef CONFIG_ARCH_HAS_CPU_RELAX
 static int poll_idle(struct cpuidle_device *dev,
 		struct cpuidle_driver *drv, int index)
@@ -333,9 +300,6 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 			return ret;
 	}
 
-	cpuidle_enter_ops = drv->en_core_tk_irqen ?
-		cpuidle_enter_tk : cpuidle_enter;
-
 	poll_idle_init(drv);
 
 	ret = cpuidle_add_device_sysfs(dev);

commit b60e6a0eb0273132cbb60a9806abf5f47a4aee1c
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Thu Mar 21 12:21:31 2013 +0000

    cpuidle : handle clockevent notify from the cpuidle framework
    
    When a cpu enters a deep idle state, the local timers are stopped and
    the time framework falls back to the timer device used as a broadcast
    timer.
    
    The different cpuidle drivers are calling clockevents_notify ENTER/EXIT
    when the idle state stops the local timer.
    
    Add a new flag CPUIDLE_FLAG_TIMER_STOP which can be set by the cpuidle
    drivers. If the flag is set, the cpuidle core code takes care of the
    notification on behalf of the driver to avoid pointless code duplication.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index eba69290e074..c50037029184 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -8,6 +8,7 @@
  * This code is licenced under the GPL.
  */
 
+#include <linux/clockchips.h>
 #include <linux/kernel.h>
 #include <linux/mutex.h>
 #include <linux/sched.h>
@@ -146,12 +147,20 @@ int cpuidle_idle_call(void)
 
 	trace_cpu_idle_rcuidle(next_state, dev->cpu);
 
+	if (drv->states[next_state].flags & CPUIDLE_FLAG_TIMER_STOP)
+		clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_ENTER,
+				   &dev->cpu);
+
 	if (cpuidle_state_is_coupled(dev, drv, next_state))
 		entered_state = cpuidle_enter_state_coupled(dev, drv,
 							    next_state);
 	else
 		entered_state = cpuidle_enter_state(dev, drv, next_state);
 
+	if (drv->states[next_state].flags & CPUIDLE_FLAG_TIMER_STOP)
+		clockevents_notify(CLOCK_EVT_NOTIFY_BROADCAST_EXIT,
+				   &dev->cpu);
+
 	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);
 
 	/* give the governor an opportunity to reflect on the outcome */

commit 43720bd6014327ac454434496cb953edcdb9f8d6
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Fri Jan 11 13:43:45 2013 +0100

    PM / tracing: remove deprecated power trace API
    
    The text in Documentation said it would be removed in 2.6.41;
    the text in the Kconfig said removal in the 3.1 release.  Either
    way you look at it, we are well past both, so push it off a cliff.
    
    Note that the POWER_CSTATE and the POWER_PSTATE are part of the
    legacy tracing API.  Remove all tracepoints which use these flags.
    As can be seen from context, most already have a trace entry via
    trace_cpu_idle anyways.
    
    Also, the cpufreq/cpufreq.c PSTATE one is actually unpaired, as
    compared to the CSTATE ones which all have a clear start/stop.
    As part of this, the trace_power_frequency also becomes orphaned,
    so it too is deleted.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index e1f6860e069c..eba69290e074 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -144,7 +144,6 @@ int cpuidle_idle_call(void)
 		return 0;
 	}
 
-	trace_power_start_rcuidle(POWER_CSTATE, next_state, dev->cpu);
 	trace_cpu_idle_rcuidle(next_state, dev->cpu);
 
 	if (cpuidle_state_is_coupled(dev, drv, next_state))
@@ -153,7 +152,6 @@ int cpuidle_idle_call(void)
 	else
 		entered_state = cpuidle_enter_state(dev, drv, next_state);
 
-	trace_power_end_rcuidle(dev->cpu);
 	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);
 
 	/* give the governor an opportunity to reflect on the outcome */

commit 8aef33a7cf40ca9da188e8578b2abe7267a38c52
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Tue Jan 15 14:18:04 2013 +0100

    cpuidle: remove the power_specified field in the driver
    
    We realized that the power usage field is never filled and when it
    is filled for tegra, the power_specified flag is not set causing all
    of these values to be reset when the driver is initialized with
    set_power_state().
    
    However, the power_specified flag can be simply removed under the
    assumption that the states are always backward sorted, which is the
    case with the current code.
    
    This change allows the menu governor select function and the
    cpuidle_play_dead() to be simplified.  Moreover, the
    set_power_states() function can removed as it does not make sense
    any more.
    
    Drop the power_specified flag from struct cpuidle_driver and make
    the related changes as described above.
    
    As a consequence, this also fixes the bug where on the dynamic
    C-states system, the power fields are not initialized.
    
    [rjw: Changelog]
    References: https://bugzilla.kernel.org/show_bug.cgi?id=42870
    References: https://bugzilla.kernel.org/show_bug.cgi?id=43349
    References: https://lkml.org/lkml/2012/10/16/518
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index fb4a7dd57f94..e1f6860e069c 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -69,24 +69,15 @@ int cpuidle_play_dead(void)
 {
 	struct cpuidle_device *dev = __this_cpu_read(cpuidle_devices);
 	struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
-	int i, dead_state = -1;
-	int power_usage = INT_MAX;
+	int i;
 
 	if (!drv)
 		return -ENODEV;
 
 	/* Find lowest-power state that supports long-term idle */
-	for (i = CPUIDLE_DRIVER_STATE_START; i < drv->state_count; i++) {
-		struct cpuidle_state *s = &drv->states[i];
-
-		if (s->power_usage < power_usage && s->enter_dead) {
-			power_usage = s->power_usage;
-			dead_state = i;
-		}
-	}
-
-	if (dead_state != -1)
-		return drv->states[dead_state].enter_dead(dev, dead_state);
+	for (i = drv->state_count - 1; i >= CPUIDLE_DRIVER_STATE_START; i--)
+		if (drv->states[i].enter_dead)
+			return drv->states[i].enter_dead(dev, i);
 
 	return -ENODEV;
 }

commit 0e5537b30d3029d784226ab51c2b923d1155b553
Author: Sivaram Nair <sivaramn@nvidia.com>
Date:   Tue Dec 18 13:52:50 2012 +0100

    cpuidle: Fix finding state with min power_usage
    
    Since cpuidle_state.power_usage is a signed value, use INT_MAX (instead
    of -1) to init the local copies so that functions that tries to find
    cpuidle states with minimum power usage works correctly even if they use
    non-negative values.
    
    Signed-off-by: Sivaram Nair <sivaramn@nvidia.com>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 8df53dd8dbe1..fb4a7dd57f94 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -70,7 +70,7 @@ int cpuidle_play_dead(void)
 	struct cpuidle_device *dev = __this_cpu_read(cpuidle_devices);
 	struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
 	int i, dead_state = -1;
-	int power_usage = -1;
+	int power_usage = INT_MAX;
 
 	if (!drv)
 		return -ENODEV;

commit a474a515497ef3566cfc17a2cab3d54d6d50ff1c
Author: Julius Werner <jwerner@chromium.org>
Date:   Tue Nov 27 14:17:58 2012 +0100

    cpuidle: Measure idle state durations with monotonic clock
    
    Many cpuidle drivers measure their time spent in an idle state by
    reading the wallclock time before and after idling and calculating the
    difference. This leads to erroneous results when the wallclock time gets
    updated by another processor in the meantime, adding that clock
    adjustment to the idle state's time counter.
    
    If the clock adjustment was negative, the result is even worse due to an
    erroneous cast from int to unsigned long long of the last_residency
    variable. The negative 32 bit integer will zero-extend and result in a
    forward time jump of roughly four billion milliseconds or 1.3 hours on
    the idle state residency counter.
    
    This patch changes all affected cpuidle drivers to either use the
    monotonic clock for their measurements or make use of the generic time
    measurement wrapper in cpuidle.c, which was already working correctly.
    Some superfluous CLIs/STIs in the ACPI code are removed (interrupts
    should always already be disabled before entering the idle function, and
    not get reenabled until the generic wrapper has performed its second
    measurement). It also removes the erroneous cast, making sure that
    negative residency values are applied correctly even though they should
    not appear anymore.
    
    Signed-off-by: Julius Werner <jwerner@chromium.org>
    Reviewed-by: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Tested-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Len Brown <len.brown@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 711dd83fd3ba..8df53dd8dbe1 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -109,8 +109,7 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 		/* This can be moved to within driver enter routine
 		 * but that results in multiple copies of same code.
 		 */
-		dev->states_usage[entered_state].time +=
-				(unsigned long long)dev->last_residency;
+		dev->states_usage[entered_state].time += dev->last_residency;
 		dev->states_usage[entered_state].usage++;
 	} else {
 		dev->last_residency = 0;

commit bf4d1b5ddb78f86078ac6ae0415802d5f0c68f92
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Wed Oct 31 16:44:48 2012 +0000

    cpuidle: support multiple drivers
    
    With the tegra3 and the big.LITTLE [1] new architectures, several cpus
    with different characteristics (latencies and states) can co-exists on the
    system.
    
    The cpuidle framework has the limitation of handling only identical cpus.
    
    This patch removes this limitation by introducing the multiple driver support
    for cpuidle.
    
    This option is configurable at compile time and should be enabled for the
    architectures mentioned above. So there is no impact for the other platforms
    if the option is disabled. The option defaults to 'n'. Note the multiple drivers
    support is also compatible with the existing drivers, even if just one driver is
    needed, all the cpu will be tied to this driver using an extra small chunk of
    processor memory.
    
    The multiple driver support use a per-cpu driver pointer instead of a global
    variable and the accessor to this variable are done from a cpu context.
    
    In order to keep the compatibility with the existing drivers, the function
    'cpuidle_register_driver' and 'cpuidle_unregister_driver' will register
    the specified driver for all the cpus.
    
    The semantic for the output of /sys/devices/system/cpu/cpuidle/current_driver
    remains the same except the driver name will be related to the current cpu.
    
    The /sys/devices/system/cpu/cpu[0-9]/cpuidle/driver/name files are added
    allowing to read the per cpu driver name.
    
    [1] http://lwn.net/Articles/481055/
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Acked-by: Peter De Schrijver <pdeschrijver@nvidia.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index ce4cac706dd1..711dd83fd3ba 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -68,7 +68,7 @@ static cpuidle_enter_t cpuidle_enter_ops;
 int cpuidle_play_dead(void)
 {
 	struct cpuidle_device *dev = __this_cpu_read(cpuidle_devices);
-	struct cpuidle_driver *drv = cpuidle_get_driver();
+	struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
 	int i, dead_state = -1;
 	int power_usage = -1;
 
@@ -128,7 +128,7 @@ int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
 int cpuidle_idle_call(void)
 {
 	struct cpuidle_device *dev = __this_cpu_read(cpuidle_devices);
-	struct cpuidle_driver *drv = cpuidle_get_driver();
+	struct cpuidle_driver *drv;
 	int next_state, entered_state;
 
 	if (off)
@@ -141,6 +141,8 @@ int cpuidle_idle_call(void)
 	if (!dev || !dev->enabled)
 		return -EBUSY;
 
+	drv = cpuidle_get_cpu_driver(dev);
+
 	/* ask the governor for the next state */
 	next_state = cpuidle_curr_governor->select(drv, dev);
 	if (need_resched()) {
@@ -312,15 +314,19 @@ static void poll_idle_init(struct cpuidle_driver *drv) {}
 int cpuidle_enable_device(struct cpuidle_device *dev)
 {
 	int ret, i;
-	struct cpuidle_driver *drv = cpuidle_get_driver();
+	struct cpuidle_driver *drv;
 
 	if (!dev)
 		return -EINVAL;
 
 	if (dev->enabled)
 		return 0;
+
+	drv = cpuidle_get_cpu_driver(dev);
+
 	if (!drv || !cpuidle_curr_governor)
 		return -EIO;
+
 	if (!dev->state_count)
 		dev->state_count = drv->state_count;
 
@@ -335,7 +341,8 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 
 	poll_idle_init(drv);
 
-	if ((ret = cpuidle_add_state_sysfs(dev)))
+	ret = cpuidle_add_device_sysfs(dev);
+	if (ret)
 		return ret;
 
 	if (cpuidle_curr_governor->enable &&
@@ -356,7 +363,7 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 	return 0;
 
 fail_sysfs:
-	cpuidle_remove_state_sysfs(dev);
+	cpuidle_remove_device_sysfs(dev);
 
 	return ret;
 }
@@ -372,17 +379,20 @@ EXPORT_SYMBOL_GPL(cpuidle_enable_device);
  */
 void cpuidle_disable_device(struct cpuidle_device *dev)
 {
+	struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
+
 	if (!dev || !dev->enabled)
 		return;
-	if (!cpuidle_get_driver() || !cpuidle_curr_governor)
+
+	if (!drv || !cpuidle_curr_governor)
 		return;
 
 	dev->enabled = 0;
 
 	if (cpuidle_curr_governor->disable)
-		cpuidle_curr_governor->disable(cpuidle_get_driver(), dev);
+		cpuidle_curr_governor->disable(drv, dev);
 
-	cpuidle_remove_state_sysfs(dev);
+	cpuidle_remove_device_sysfs(dev);
 	enabled_devices--;
 }
 
@@ -398,9 +408,9 @@ EXPORT_SYMBOL_GPL(cpuidle_disable_device);
 static int __cpuidle_register_device(struct cpuidle_device *dev)
 {
 	int ret;
-	struct cpuidle_driver *cpuidle_driver = cpuidle_get_driver();
+	struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
 
-	if (!try_module_get(cpuidle_driver->owner))
+	if (!try_module_get(drv->owner))
 		return -EINVAL;
 
 	per_cpu(cpuidle_devices, dev->cpu) = dev;
@@ -421,7 +431,7 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 err_sysfs:
 	list_del(&dev->device_list);
 	per_cpu(cpuidle_devices, dev->cpu) = NULL;
-	module_put(cpuidle_driver->owner);
+	module_put(drv->owner);
 	return ret;
 }
 
@@ -460,7 +470,7 @@ EXPORT_SYMBOL_GPL(cpuidle_register_device);
  */
 void cpuidle_unregister_device(struct cpuidle_device *dev)
 {
-	struct cpuidle_driver *cpuidle_driver = cpuidle_get_driver();
+	struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
 
 	if (dev->registered == 0)
 		return;
@@ -477,7 +487,7 @@ void cpuidle_unregister_device(struct cpuidle_device *dev)
 
 	cpuidle_resume_and_unlock();
 
-	module_put(cpuidle_driver->owner);
+	module_put(drv->owner);
 }
 
 EXPORT_SYMBOL_GPL(cpuidle_unregister_device);

commit d73d68dc49e09143e8e3bef10670a021c26ec4a5
Author: Youquan Song <youquan.song@intel.com>
Date:   Fri Oct 26 12:26:59 2012 +0200

    cpuidle: Set residency to 0 if target Cstate not enter
    
    When cpuidle governor choose a C-state to enter for idle CPU, but it notice that
    there is tasks request to be executed. So the idle CPU will not really enter
    the target C-state and go to run task.
    
    In this situation, it will use the residency of previous really entered target
    C-states. Obviously, it is not reasonable.
    
    So, this patch fix it by set the target C-state residency to 0.
    
    Signed-off-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Youquan Song <youquan.song@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index f4b8fc50c0f2..ce4cac706dd1 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -144,6 +144,10 @@ int cpuidle_idle_call(void)
 	/* ask the governor for the next state */
 	next_state = cpuidle_curr_governor->select(drv, dev);
 	if (need_resched()) {
+		dev->last_residency = 0;
+		/* give the governor an opportunity to reflect on the outcome */
+		if (cpuidle_curr_governor->reflect)
+			cpuidle_curr_governor->reflect(dev, next_state);
 		local_irq_enable();
 		return 0;
 	}

commit e45a00d679a788217f35ee4214a32d6d1924160b
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Fri Oct 26 12:26:32 2012 +0200

    cpuidle / sysfs: move kobj initialization in the syfs file
    
    Move the kobj initialization and completion in the sysfs.c
    and encapsulate the code more.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index b511ac39cc85..f4b8fc50c0f2 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -399,8 +399,6 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 	if (!try_module_get(cpuidle_driver->owner))
 		return -EINVAL;
 
-	init_completion(&dev->kobj_unregister);
-
 	per_cpu(cpuidle_devices, dev->cpu) = dev;
 	list_add(&dev->device_list, &cpuidle_detected_devices);
 	ret = cpuidle_add_sysfs(dev);
@@ -416,7 +414,6 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 
 err_coupled:
 	cpuidle_remove_sysfs(dev);
-	wait_for_completion(&dev->kobj_unregister);
 err_sysfs:
 	list_del(&dev->device_list);
 	per_cpu(cpuidle_devices, dev->cpu) = NULL;
@@ -470,7 +467,6 @@ void cpuidle_unregister_device(struct cpuidle_device *dev)
 
 	cpuidle_remove_sysfs(dev);
 	list_del(&dev->device_list);
-	wait_for_completion(&dev->kobj_unregister);
 	per_cpu(cpuidle_devices, dev->cpu) = NULL;
 
 	cpuidle_coupled_unregister_device(dev);

commit 1aef40e288acfb3cc28ff77528b34ef66683bed6
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Fri Oct 26 12:26:24 2012 +0200

    cpuidle / sysfs: change function parameter
    
    The function needs the cpuidle_device which is initially passed to the
    caller.
    
    The current code gets the struct device from the struct cpuidle_device,
    pass it the cpuidle_add_sysfs function. This function calls
    per_cpu(cpuidle_devices, cpu) to get the cpuidle_device.
    
    This patch pass the cpuidle_device instead and simplify the code.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 7f15b8514a18..b511ac39cc85 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -394,7 +394,6 @@ EXPORT_SYMBOL_GPL(cpuidle_disable_device);
 static int __cpuidle_register_device(struct cpuidle_device *dev)
 {
 	int ret;
-	struct device *cpu_dev = get_cpu_device((unsigned long)dev->cpu);
 	struct cpuidle_driver *cpuidle_driver = cpuidle_get_driver();
 
 	if (!try_module_get(cpuidle_driver->owner))
@@ -404,7 +403,7 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 
 	per_cpu(cpuidle_devices, dev->cpu) = dev;
 	list_add(&dev->device_list, &cpuidle_detected_devices);
-	ret = cpuidle_add_sysfs(cpu_dev);
+	ret = cpuidle_add_sysfs(dev);
 	if (ret)
 		goto err_sysfs;
 
@@ -416,7 +415,7 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 	return 0;
 
 err_coupled:
-	cpuidle_remove_sysfs(cpu_dev);
+	cpuidle_remove_sysfs(dev);
 	wait_for_completion(&dev->kobj_unregister);
 err_sysfs:
 	list_del(&dev->device_list);
@@ -460,7 +459,6 @@ EXPORT_SYMBOL_GPL(cpuidle_register_device);
  */
 void cpuidle_unregister_device(struct cpuidle_device *dev)
 {
-	struct device *cpu_dev = get_cpu_device((unsigned long)dev->cpu);
 	struct cpuidle_driver *cpuidle_driver = cpuidle_get_driver();
 
 	if (dev->registered == 0)
@@ -470,7 +468,7 @@ void cpuidle_unregister_device(struct cpuidle_device *dev)
 
 	cpuidle_disable_device(dev);
 
-	cpuidle_remove_sysfs(cpu_dev);
+	cpuidle_remove_sysfs(dev);
 	list_del(&dev->device_list);
 	wait_for_completion(&dev->kobj_unregister);
 	per_cpu(cpuidle_devices, dev->cpu) = NULL;

commit cf31cd1a0c692a1445c80756055875088fa29982
Author: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
Date:   Mon Oct 8 13:43:08 2012 +0530

    ACPI idle, CPU hotplug: Fix NULL pointer dereference during hotplug
    
    On a KVM guest, when a CPU is taken offline and brought back online, we hit
    the following NULL pointer dereference:
    
    [   45.400843] Unregister pv shared memory for cpu 1
    [   45.412331] smpboot: CPU 1 is now offline
    [   45.529894] SMP alternatives: lockdep: fixing up alternatives
    [   45.533472] smpboot: Booting Node 0 Processor 1 APIC 0x1
    [   45.411526] kvm-clock: cpu 1, msr 0:7d14601, secondary cpu clock
    [   45.571370] KVM setup async PF for cpu 1
    [   45.572331] kvm-stealtime: cpu 1, msr 7d0e040
    [   45.575031] BUG: unable to handle kernel NULL pointer dereference at           (null)
    [   45.576017] IP: [<ffffffff81519f98>] cpuidle_disable_device+0x18/0x80
    [   45.576017] PGD 5dfb067 PUD 5da8067 PMD 0
    [   45.576017] Oops: 0000 [#1] SMP
    [   45.576017] Modules linked in:
    [   45.576017] CPU 0
    [   45.576017] Pid: 607, comm: stress_cpu_hotp Not tainted 3.6.0-padata-tp-debug #3 Bochs Bochs
    [   45.576017] RIP: 0010:[<ffffffff81519f98>]  [<ffffffff81519f98>] cpuidle_disable_device+0x18/0x80
    [   45.576017] RSP: 0018:ffff880005d93ce8  EFLAGS: 00010286
    [   45.576017] RAX: ffff880005d93fd8 RBX: 0000000000000000 RCX: 0000000000000006
    [   45.576017] RDX: 0000000000000006 RSI: 2222222222222222 RDI: 0000000000000000
    [   45.576017] RBP: ffff880005d93cf8 R08: 2222222222222222 R09: 2222222222222222
    [   45.576017] R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
    [   45.576017] R13: 0000000000000000 R14: ffffffff81c8cca0 R15: 0000000000000001
    [   45.576017] FS:  00007f91936ae700(0000) GS:ffff880007c00000(0000) knlGS:0000000000000000
    [   45.576017] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [   45.576017] CR2: 0000000000000000 CR3: 0000000005db3000 CR4: 00000000000006f0
    [   45.576017] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [   45.576017] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
    [   45.576017] Process stress_cpu_hotp (pid: 607, threadinfo ffff880005d92000, task ffff8800066bbf40)
    [   45.576017] Stack:
    [   45.576017]  ffff880007a96400 0000000000000000 ffff880005d93d28 ffffffff813ac689
    [   45.576017]  ffff880007a96400 ffff880007a96400 0000000000000002 ffffffff81cd8d01
    [   45.576017]  ffff880005d93d58 ffffffff813aa498 0000000000000001 00000000ffffffdd
    [   45.576017] Call Trace:
    [   45.576017]  [<ffffffff813ac689>] acpi_processor_hotplug+0x55/0x97
    [   45.576017]  [<ffffffff813aa498>] acpi_cpu_soft_notify+0x93/0xce
    [   45.576017]  [<ffffffff816ae47d>] notifier_call_chain+0x5d/0x110
    [   45.576017]  [<ffffffff8109730e>] __raw_notifier_call_chain+0xe/0x10
    [   45.576017]  [<ffffffff81069050>] __cpu_notify+0x20/0x40
    [   45.576017]  [<ffffffff81069085>] cpu_notify+0x15/0x20
    [   45.576017]  [<ffffffff816978f1>] _cpu_up+0xee/0x137
    [   45.576017]  [<ffffffff81697983>] cpu_up+0x49/0x59
    [   45.576017]  [<ffffffff8168758d>] store_online+0x9d/0xe0
    [   45.576017]  [<ffffffff8140a9f8>] dev_attr_store+0x18/0x30
    [   45.576017]  [<ffffffff812322c0>] sysfs_write_file+0xe0/0x150
    [   45.576017]  [<ffffffff811b389c>] vfs_write+0xac/0x180
    [   45.576017]  [<ffffffff811b3be2>] sys_write+0x52/0xa0
    [   45.576017]  [<ffffffff816b31e9>] system_call_fastpath+0x16/0x1b
    [   45.576017] Code: 48 c7 c7 40 e5 ca 81 e8 07 d0 18 00 5d c3 0f 1f 44 00 00 0f 1f 44 00 00 55 48 89 e5 48 83 ec 10 48 89 5d f0 4c 89 65 f8 48 89 fb <f6> 07 02 75 13 48 8b 5d f0 4c 8b 65 f8 c9 c3 66 0f 1f 84 00 00
    [   45.576017] RIP  [<ffffffff81519f98>] cpuidle_disable_device+0x18/0x80
    [   45.576017]  RSP <ffff880005d93ce8>
    [   45.576017] CR2: 0000000000000000
    [   45.656079] ---[ end trace 433d6c9ac0b02cef ]---
    
    Analysis:
    Commit 3d339dc (cpuidle / ACPI : move cpuidle_device field out of the
    acpi_processor_power structure()) made the allocation of the dev structure
    (struct cpuidle) of a CPU dynamic, whereas previously it was statically
    allocated. And this dynamic allocation occurs in acpi_processor_power_init()
    if pr->flags.power evaluates to non-zero.
    
    On KVM guests, pr->flags.power evaluates to zero, hence dev is never
    allocated. This causes the NULL pointer (dev) dereference in
    cpuidle_disable_device() during a subsequent CPU online operation. Fix this
    by ensuring that dev is non-NULL before dereferencing.
    
    Signed-off-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index e28f6ea46f1a..7f15b8514a18 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -368,7 +368,7 @@ EXPORT_SYMBOL_GPL(cpuidle_enable_device);
  */
 void cpuidle_disable_device(struct cpuidle_device *dev)
 {
-	if (!dev->enabled)
+	if (!dev || !dev->enabled)
 		return;
 	if (!cpuidle_get_driver() || !cpuidle_curr_governor)
 		return;

commit 476525004ac7e2f990b6956efcd44d0780c2ab4c
Merge: bd22dc17e499 ec033d0a0290
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 26 14:28:55 2012 -0700

    Merge branch 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux
    
    Pull ACPI & power management update from Len Brown:
     "Re-write of the turbostat tool.
         lower overhead was necessary for measuring very large system when
         they are very idle.
    
      IVB support in intel_idle
         It's what I run on my IVB, others should be able to also:-)
    
      ACPICA core update
         We have found some bugs due to divergence between Linux and the
         upstream ACPICA base.  Most of these patches are to reduce that
         divergence to reduce the risk of future bugs.
    
      Some cpuidle updates, mostly for non-Intel
         More will be coming, as they depend on this part.
    
      Some thermal management changes needed by non-ACPI systems.
    
      Some _OST (OS Status Indication) updates for hot ACPI hot-plug."
    
    * 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux: (51 commits)
      Thermal: Documentation update
      Thermal: Add Hysteresis attributes
      Thermal: Make Thermal trip points writeable
      ACPI/AC: prevent OOPS on some boxes due to missing check power_supply_register() return value check
      tools/power: turbostat: fix large c1% issue
      tools/power: turbostat v2 - re-write for efficiency
      ACPICA: Update to version 20120711
      ACPICA: AcpiSrc: Fix some translation issues for Linux conversion
      ACPICA: Update header files copyrights to 2012
      ACPICA: Add new ACPI table load/unload external interfaces
      ACPICA: Split file: tbxface.c -> tbxfload.c
      ACPICA: Add PCC address space to space ID decode function
      ACPICA: Fix some comment fields
      ACPICA: Table manager: deploy new firmware error/warning interfaces
      ACPICA: Add new interfaces for BIOS(firmware) errors and warnings
      ACPICA: Split exception code utilities to a new file, utexcep.c
      ACPI: acpi_pad: tune round_robin_time
      ACPICA: Update to version 20120620
      ACPICA: Add support for implicit notify on multiple devices
      ACPICA: Update comments; no functional change
      ...

commit ec033d0a02901551346b9f43f8ff9bad51378891
Merge: fa7584e13ac8 819f1a64beb6 f712c71f7b2b a58e1150225c 20ff51a36b2c 1b0a0e9a15b9 6edab08c24f9 c2f4191a9c4d f197ac13f6ee 8eaa8d6ca277 b9c7aff481f1 c3ae331d1c2f
Author: Len Brown <len.brown@intel.com>
Date:   Thu Jul 26 00:03:58 2012 -0400

    Merge branches 'acpi_pad', 'acpica', 'apei-bugzilla-43282', 'battery', 'cpuidle-coupled', 'cpuidle-tweaks', 'intel_idle-ivb', 'ost', 'red-hat-bz-772730', 'thermal', 'thermal-spear' and 'turbostat-v2' into release

commit 7791bd230c6fe65348456564743f99fa066f00e7
Merge: 3db0bc97678d 8e9afafdad59
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Thu Jul 19 00:03:17 2012 +0200

    Merge branch 'pm-domains'
    
    * pm-domains:
      PM / Domains: Fix build warning for CONFIG_PM_RUNTIME unset
      PM / Domains: Replace plain integer with NULL pointer in domain.c file
      PM / Domains: Add missing static storage class specifier in domain.c file
      PM / Domains: Allow device callbacks to be added at any time
      PM / Domains: Add device domain data reference counter
      PM / Domains: Add preliminary support for cpuidle, v2
      PM / Domains: Do not stop devices after restoring their states
      PM / Domains: Use subsystem runtime suspend/resume callbacks by default

commit 8651f97bd951d0bb1c10fa24e3fa3455193f3548
Author: Preeti U Murthy <preeti@linux.vnet.ibm.com>
Date:   Mon Jul 9 10:12:56 2012 +0200

    PM / cpuidle: System resume hang fix with cpuidle
    
    On certain bios, resume hangs if cpus are allowed to enter idle states
    during suspend [1].
    
    This was fixed in apci idle driver [2].But intel_idle driver does not
    have this fix. Thus instead of replicating the fix in both the idle
    drivers, or in more platform specific idle drivers if needed, the
    more general cpuidle infrastructure could handle this.
    
    A suspend callback in cpuidle_driver could handle this fix. But
    a cpuidle_driver provides only basic functionalities like platform idle
    state detection capability and mechanisms to support entry and exit
    into CPU idle states. All other cpuidle functions are found in the
    cpuidle generic infrastructure for good reason that all cpuidle
    drivers, irrepective of their platforms will support these functions.
    
    One option therefore would be to register a suspend callback in cpuidle
    which handles this fix. This could be called through a PM_SUSPEND_PREPARE
    notifier. But this is too generic a notfier for a driver to handle.
    
    Also, ideally the job of cpuidle is not to handle side effects of suspend.
    It should expose the interfaces which "handle cpuidle 'during' suspend"
    or any other operation, which the subsystems call during that respective
    operation.
    
    The fix demands that during suspend, no cpus should be allowed to enter
    deep C-states. The interface cpuidle_uninstall_idle_handler() in cpuidle
    ensures that. Not just that it also kicks all the cpus which are already
    in idle out of their idle states which was being done during cpu hotplug
    through a CPU_DYING_FROZEN callbacks.
    
    Now the question arises about when during suspend should
    cpuidle_uninstall_idle_handler() be called. Since we are dealing with
    drivers it seems best to call this function during dpm_suspend().
    Delaying the call till dpm_suspend_noirq() does no harm, as long as it is
    before cpu_hotplug_begin() to avoid race conditions with cpu hotpulg
    operations. In dpm_suspend_noirq(), it would be wise to place this call
    before suspend_device_irqs() to avoid ugly interactions with the same.
    
    Ananlogously, during resume.
    
    References:
    [1] https://bugs.launchpad.net/ubuntu/+source/linux/+bug/674075.
    [2] http://marc.info/?l=linux-pm&m=133958534231884&w=2
    
    Reported-and-tested-by: Dave Hansen <dave@linux.vnet.ibm.com>
    Signed-off-by: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Reviewed-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 04e4b7674a47..efa9a2ca30e7 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -201,6 +201,22 @@ void cpuidle_resume_and_unlock(void)
 
 EXPORT_SYMBOL_GPL(cpuidle_resume_and_unlock);
 
+/* Currently used in suspend/resume path to suspend cpuidle */
+void cpuidle_pause(void)
+{
+	mutex_lock(&cpuidle_lock);
+	cpuidle_uninstall_idle_handler();
+	mutex_unlock(&cpuidle_lock);
+}
+
+/* Currently used in suspend/resume path to resume cpuidle */
+void cpuidle_resume(void)
+{
+	mutex_lock(&cpuidle_lock);
+	cpuidle_install_idle_handler();
+	mutex_unlock(&cpuidle_lock);
+}
+
 /**
  * cpuidle_wrap_enter - performs timekeeping and irqen around enter function
  * @dev: pointer to a valid cpuidle_device object

commit cbc9ef0287ab764d3da0129efa673808df641fe3
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Tue Jul 3 19:07:42 2012 +0200

    PM / Domains: Add preliminary support for cpuidle, v2
    
    On some systems there are CPU cores located in the same power
    domains as I/O devices.  Then, power can only be removed from the
    domain if all I/O devices in it are not in use and the CPU core
    is idle.  Add preliminary support for that to the generic PM domains
    framework.
    
    First, the platform is expected to provide a cpuidle driver with one
    extra state designated for use with the generic PM domains code.
    This state should be initially disabled and its exit_latency value
    should be set to whatever time is needed to bring up the CPU core
    itself after restoring power to it, not including the domain's
    power on latency.  Its .enter() callback should point to a procedure
    that will remove power from the domain containing the CPU core at
    the end of the CPU power transition.
    
    The remaining characteristics of the extra cpuidle state, referred to
    as the "domain" cpuidle state below, (e.g. power usage, target
    residency) should be populated in accordance with the properties of
    the hardware.
    
    Next, the platform should execute genpd_attach_cpuidle() on the PM
    domain containing the CPU core.  That will cause the generic PM
    domains framework to treat that domain in a special way such that:
    
     * When all devices in the domain have been suspended and it is about
       to be turned off, the states of the devices will be saved, but
       power will not be removed from the domain.  Instead, the "domain"
       cpuidle state will be enabled so that power can be removed from
       the domain when the CPU core is idle and the state has been chosen
       as the target by the cpuidle governor.
    
     * When the first I/O device in the domain is resumed and
       __pm_genpd_poweron(() is called for the first time after
       power has been removed from the domain, the "domain" cpuidle
       state will be disabled to avoid subsequent surprise power removals
       via cpuidle.
    
    The effective exit_latency value of the "domain" cpuidle state
    depends on the time needed to bring up the CPU core itself after
    restoring power to it as well as on the power on latency of the
    domain containing the CPU core.  Thus the "domain" cpuidle state's
    exit_latency has to be recomputed every time the domain's power on
    latency is updated, which may happen every time power is restored
    to the domain, if the measured power on latency is greater than
    the latency stored in the corresponding generic_pm_domain structure.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Reviewed-by: Kevin Hilman <khilman@ti.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 04e4b7674a47..0132706251df 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -265,6 +265,7 @@ static void poll_idle_init(struct cpuidle_driver *drv)
 	state->power_usage = -1;
 	state->flags = 0;
 	state->enter = poll_idle;
+	state->disabled = false;
 }
 #else
 static void poll_idle_init(struct cpuidle_driver *drv) {}

commit dc7fd275ae60ef8edf952aff2a62462f5d892fd4
Author: ShuoX Liu <shuox.liu@intel.com>
Date:   Tue Jul 3 19:05:31 2012 +0200

    cpuidle: move field disable from per-driver to per-cpu
    
    Andrew J.Schorr raises a question.  When he changes the disable setting on
    a single CPU, it affects all the other CPUs.  Basically, currently, the
    disable field is per-driver instead of per-cpu.  All the C states of the
    same driver are shared by all CPU in the same machine.
    
    The patch changes the `disable' field to per-cpu, so we could set this
    separately for each cpu.
    
    Signed-off-by: ShuoX Liu <shuox.liu@intel.com>
    Reported-by: Andrew J.Schorr <aschorr@telemetry-investments.com>
    Reviewed-by: Yanmin Zhang <yanmin_zhang@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index d90519cec880..04e4b7674a47 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -265,7 +265,6 @@ static void poll_idle_init(struct cpuidle_driver *drv)
 	state->power_usage = -1;
 	state->flags = 0;
 	state->enter = poll_idle;
-	state->disable = 0;
 }
 #else
 static void poll_idle_init(struct cpuidle_driver *drv) {}

commit 4126c0197bc8c58a0bb7fcda07b01b596b6fb4c5
Author: Colin Cross <ccross@android.com>
Date:   Mon May 7 17:57:41 2012 -0700

    cpuidle: add support for states that affect multiple cpus
    
    On some ARM SMP SoCs (OMAP4460, Tegra 2, and probably more), the
    cpus cannot be independently powered down, either due to
    sequencing restrictions (on Tegra 2, cpu 0 must be the last to
    power down), or due to HW bugs (on OMAP4460, a cpu powering up
    will corrupt the gic state unless the other cpu runs a work
    around).  Each cpu has a power state that it can enter without
    coordinating with the other cpu (usually Wait For Interrupt, or
    WFI), and one or more "coupled" power states that affect blocks
    shared between the cpus (L2 cache, interrupt controller, and
    sometimes the whole SoC).  Entering a coupled power state must
    be tightly controlled on both cpus.
    
    The easiest solution to implementing coupled cpu power states is
    to hotplug all but one cpu whenever possible, usually using a
    cpufreq governor that looks at cpu load to determine when to
    enable the secondary cpus.  This causes problems, as hotplug is an
    expensive operation, so the number of hotplug transitions must be
    minimized, leading to very slow response to loads, often on the
    order of seconds.
    
    This file implements an alternative solution, where each cpu will
    wait in the WFI state until all cpus are ready to enter a coupled
    state, at which point the coupled state function will be called
    on all cpus at approximately the same time.
    
    Once all cpus are ready to enter idle, they are woken by an smp
    cross call.  At this point, there is a chance that one of the
    cpus will find work to do, and choose not to enter idle.  A
    final pass is needed to guarantee that all cpus will call the
    power state enter function at the same time.  During this pass,
    each cpu will increment the ready counter, and continue once the
    ready counter matches the number of online coupled cpus.  If any
    cpu exits idle, the other cpus will decrement their counter and
    retry.
    
    To use coupled cpuidle states, a cpuidle driver must:
    
       Set struct cpuidle_device.coupled_cpus to the mask of all
       coupled cpus, usually the same as cpu_possible_mask if all cpus
       are part of the same cluster.  The coupled_cpus mask must be
       set in the struct cpuidle_device for each cpu.
    
       Set struct cpuidle_device.safe_state to a state that is not a
       coupled state.  This is usually WFI.
    
       Set CPUIDLE_FLAG_COUPLED in struct cpuidle_state.flags for each
       state that affects multiple cpus.
    
       Provide a struct cpuidle_state.enter function for each state
       that affects multiple cpus.  This function is guaranteed to be
       called on all cpus at approximately the same time.  The driver
       should ensure that the cpus all abort together if any cpu tries
       to abort once the function is called.
    
    update1:
    
    cpuidle: coupled: fix count of online cpus
    
    online_count was never incremented on boot, and was also counting
    cpus that were not part of the coupled set.  Fix both issues by
    introducting a new function that counts online coupled cpus, and
    call it from register as well as the hotplug notifier.
    
    update2:
    
    cpuidle: coupled: fix decrementing ready count
    
    cpuidle_coupled_set_not_ready sometimes refuses to decrement the
    ready count in order to prevent a race condition.  This makes it
    unsuitable for use when finished with idle.  Add a new function
    cpuidle_coupled_set_done that decrements both the ready count and
    waiting count, and call it after idle is complete.
    
    Cc: Amit Kucheria <amit.kucheria@linaro.org>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Trinabh Gupta <g.trinabh@gmail.com>
    Cc: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Reviewed-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Tested-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Reviewed-by: Kevin Hilman <khilman@ti.com>
    Tested-by: Kevin Hilman <khilman@ti.com>
    Signed-off-by: Colin Cross <ccross@android.com>
    Acked-by: Rafael J. Wysocki <rjw@sisk.pl>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 4540672a2e1c..e81cfda295a5 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -171,7 +171,11 @@ int cpuidle_idle_call(void)
 	trace_power_start_rcuidle(POWER_CSTATE, next_state, dev->cpu);
 	trace_cpu_idle_rcuidle(next_state, dev->cpu);
 
-	entered_state = cpuidle_enter_state(dev, drv, next_state);
+	if (cpuidle_state_is_coupled(dev, drv, next_state))
+		entered_state = cpuidle_enter_state_coupled(dev, drv,
+							    next_state);
+	else
+		entered_state = cpuidle_enter_state(dev, drv, next_state);
 
 	trace_power_end_rcuidle(dev->cpu);
 	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);
@@ -407,9 +411,16 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 	if (ret)
 		goto err_sysfs;
 
+	ret = cpuidle_coupled_register_device(dev);
+	if (ret)
+		goto err_coupled;
+
 	dev->registered = 1;
 	return 0;
 
+err_coupled:
+	cpuidle_remove_sysfs(cpu_dev);
+	wait_for_completion(&dev->kobj_unregister);
 err_sysfs:
 	list_del(&dev->device_list);
 	per_cpu(cpuidle_devices, dev->cpu) = NULL;
@@ -464,6 +475,8 @@ void cpuidle_unregister_device(struct cpuidle_device *dev)
 	wait_for_completion(&dev->kobj_unregister);
 	per_cpu(cpuidle_devices, dev->cpu) = NULL;
 
+	cpuidle_coupled_unregister_device(dev);
+
 	cpuidle_resume_and_unlock();
 
 	module_put(cpuidle_driver->owner);

commit 3af272ab75c7a0c7fa5ae5507724d961f7e7718b
Author: Colin Cross <ccross@android.com>
Date:   Mon May 7 17:57:40 2012 -0700

    cpuidle: fix error handling in __cpuidle_register_device
    
    Fix the error handling in __cpuidle_register_device to include
    the missing list_del.  Move it to a label, which will simplify
    the error handling when coupled states are added.
    
    Reviewed-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Tested-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Reviewed-by: Kevin Hilman <khilman@ti.com>
    Tested-by: Kevin Hilman <khilman@ti.com>
    Signed-off-by: Colin Cross <ccross@android.com>
    Reviewed-by: Rafael J. Wysocki <rjw@sisk.pl>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 3e3e3e4d9581..4540672a2e1c 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -403,13 +403,18 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 
 	per_cpu(cpuidle_devices, dev->cpu) = dev;
 	list_add(&dev->device_list, &cpuidle_detected_devices);
-	if ((ret = cpuidle_add_sysfs(cpu_dev))) {
-		module_put(cpuidle_driver->owner);
-		return ret;
-	}
+	ret = cpuidle_add_sysfs(cpu_dev);
+	if (ret)
+		goto err_sysfs;
 
 	dev->registered = 1;
 	return 0;
+
+err_sysfs:
+	list_del(&dev->device_list);
+	per_cpu(cpuidle_devices, dev->cpu) = NULL;
+	module_put(cpuidle_driver->owner);
+	return ret;
 }
 
 /**

commit 56cfbf74a17c40f3a741398103c9f5d5a6806715
Author: Colin Cross <ccross@android.com>
Date:   Mon May 7 17:57:39 2012 -0700

    cpuidle: refactor out cpuidle_enter_state
    
    Split the code to enter a state and update the stats into a helper
    function, cpuidle_enter_state, and export it.  This function will
    be called by the coupled state code to handle entering the safe
    state and the final coupled state.
    
    Reviewed-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Tested-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Reviewed-by: Kevin Hilman <khilman@ti.com>
    Tested-by: Kevin Hilman <khilman@ti.com>
    Signed-off-by: Colin Cross <ccross@android.com>
    Reviewed-by: Rafael J. Wysocki <rjw@sisk.pl>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 2f0083a51a9a..3e3e3e4d9581 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -102,6 +102,34 @@ int cpuidle_play_dead(void)
 	return -ENODEV;
 }
 
+/**
+ * cpuidle_enter_state - enter the state and update stats
+ * @dev: cpuidle device for this cpu
+ * @drv: cpuidle driver for this cpu
+ * @next_state: index into drv->states of the state to enter
+ */
+int cpuidle_enter_state(struct cpuidle_device *dev, struct cpuidle_driver *drv,
+		int next_state)
+{
+	int entered_state;
+
+	entered_state = cpuidle_enter_ops(dev, drv, next_state);
+
+	if (entered_state >= 0) {
+		/* Update cpuidle counters */
+		/* This can be moved to within driver enter routine
+		 * but that results in multiple copies of same code.
+		 */
+		dev->states_usage[entered_state].time +=
+				(unsigned long long)dev->last_residency;
+		dev->states_usage[entered_state].usage++;
+	} else {
+		dev->last_residency = 0;
+	}
+
+	return entered_state;
+}
+
 /**
  * cpuidle_idle_call - the main idle loop
  *
@@ -143,23 +171,11 @@ int cpuidle_idle_call(void)
 	trace_power_start_rcuidle(POWER_CSTATE, next_state, dev->cpu);
 	trace_cpu_idle_rcuidle(next_state, dev->cpu);
 
-	entered_state = cpuidle_enter_ops(dev, drv, next_state);
+	entered_state = cpuidle_enter_state(dev, drv, next_state);
 
 	trace_power_end_rcuidle(dev->cpu);
 	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);
 
-	if (entered_state >= 0) {
-		/* Update cpuidle counters */
-		/* This can be moved to within driver enter routine
-		 * but that results in multiple copies of same code.
-		 */
-		dev->states_usage[entered_state].time +=
-				(unsigned long long)dev->last_residency;
-		dev->states_usage[entered_state].usage++;
-	} else {
-		dev->last_residency = 0;
-	}
-
 	/* give the governor an opportunity to reflect on the outcome */
 	if (cpuidle_curr_governor->reflect)
 		cpuidle_curr_governor->reflect(dev, entered_state);

commit 1b0a0e9a15b976d91f3b5ae619c6a8964c2818eb
Author: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
Date:   Fri May 4 14:06:02 2012 -0700

    cpuidle: add checks to avoid NULL pointer dereference
    
    The existing check for dev == NULL in __cpuidle_register_device() is
    rendered useless because dev is dereferenced before the check itself.
    Moreover, correctly speaking, it is the job of the callers of this
    function, i.e., cpuidle_register_device() & cpuidle_enable_device() (which
    also happen to be exported functions) to ensure that
    __cpuidle_register_device() is called with a non-NULL dev.
    
    So add the necessary dev == NULL checks in the two callers and remove the
    (useless) check from __cpuidle_register_device().
    
    Signed-off-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Acked-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 588b44aa1de4..8ffef26ffdcf 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -285,6 +285,9 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 	int ret, i;
 	struct cpuidle_driver *drv = cpuidle_get_driver();
 
+	if (!dev)
+		return -EINVAL;
+
 	if (dev->enabled)
 		return 0;
 	if (!drv || !cpuidle_curr_governor)
@@ -369,8 +372,6 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 	struct device *cpu_dev = get_cpu_device((unsigned long)dev->cpu);
 	struct cpuidle_driver *cpuidle_driver = cpuidle_get_driver();
 
-	if (!dev)
-		return -EINVAL;
 	if (!try_module_get(cpuidle_driver->owner))
 		return -EINVAL;
 
@@ -395,6 +396,9 @@ int cpuidle_register_device(struct cpuidle_device *dev)
 {
 	int ret;
 
+	if (!dev)
+		return -EINVAL;
+
 	mutex_lock(&cpuidle_lock);
 
 	if ((ret = __cpuidle_register_device(dev))) {

commit 0aeb9cac6f8a6fc68acfb07d30b62ad6106a6384
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Fri May 4 14:06:02 2012 -0700

    cpuidle: remove unused hrtimer_peek_ahead_timers() call
    
      commit 9a6558371bcd01c2973b7638181db4ccc34eab4f
      Author: Arjan van de Ven <arjan@linux.intel.com>
      Date:   Sun Nov 9 12:45:10 2008 -0800
    
         regression: disable timer peek-ahead for 2.6.28
    
         It's showing up as regressions; disabling it very likely just papers
         over an underlying issue, but time is running out for 2.6.28, lets get
         back to this for 2.6.29
    
     Many years has passed since 2008, so it seems ok to remove whole `#if 0' block.
    
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Kevin Hilman <khilman@ti.com>
    Cc: Trinabh Gupta <g.trinabh@gmail.com>
    Cc: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Cc: Arjan van de Ven <arjan@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 2f0083a51a9a..588b44aa1de4 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -124,15 +124,6 @@ int cpuidle_idle_call(void)
 	if (!dev || !dev->enabled)
 		return -EBUSY;
 
-#if 0
-	/* shows regressions, re-enable for 2.6.29 */
-	/*
-	 * run any timers that can be run now, at this point
-	 * before calculating the idle duration etc.
-	 */
-	hrtimer_peek_ahead_timers();
-#endif
-
 	/* ask the governor for the next state */
 	next_state = cpuidle_curr_governor->select(drv, dev);
 	if (need_resched()) {

commit 4a1625133d4faaefcec0dc175941f49b186918d9
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 7 17:59:48 2012 +0000

    cpuidle: Use kick_all_cpus_sync()
    
    kick_all_cpus_sync() is the core implementation of cpu_idle_wait()
    which is copied all over the arch code.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20120507175652.119842173@linutronix.de

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 2f0083a51a9a..d90519cec880 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -40,17 +40,6 @@ void disable_cpuidle(void)
 	off = 1;
 }
 
-#if defined(CONFIG_ARCH_HAS_CPU_IDLE_WAIT)
-static void cpuidle_kick_cpus(void)
-{
-	cpu_idle_wait();
-}
-#elif defined(CONFIG_SMP)
-# error "Arch needs cpu_idle_wait() equivalent here"
-#else /* !CONFIG_ARCH_HAS_CPU_IDLE_WAIT && !CONFIG_SMP */
-static void cpuidle_kick_cpus(void) {}
-#endif
-
 static int __cpuidle_register_device(struct cpuidle_device *dev);
 
 static inline int cpuidle_enter(struct cpuidle_device *dev,
@@ -186,7 +175,7 @@ void cpuidle_uninstall_idle_handler(void)
 {
 	if (enabled_devices) {
 		initialized = 0;
-		cpuidle_kick_cpus();
+		kick_all_cpus_sync();
 	}
 }
 

commit eeaab2d8af2cf1d36d7086f22e9de42d6dd2995c
Merge: ee01e6633733 aaef292acf3a
Author: Len Brown <len.brown@intel.com>
Date:   Fri Apr 6 21:48:59 2012 -0400

    Merge branches 'idle-fix' and 'misc' into release

commit ee01e663373343c63e0e3d364d09f6155378dbcc
Author: Toshi Kani <toshi.kani@hp.com>
Date:   Sat Mar 31 21:37:02 2012 -0600

    cpuidle: Fix panic in CPU off-lining with no idle driver
    
    Fix a NULL pointer dereference panic in cpuidle_play_dead() during
    CPU off-lining when no cpuidle driver is registered.  A cpuidle
    driver may be registered at boot-time based on CPU type.  This patch
    allows an off-lined CPU to enter HLT-based idle in this condition.
    
    Signed-off-by: Toshi Kani <toshi.kani@hp.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@amd.com>
    Reviewed-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Tested-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 3e146b2ada4a..a71376a45d8e 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -74,7 +74,7 @@ static cpuidle_enter_t cpuidle_enter_ops;
 /**
  * cpuidle_play_dead - cpu off-lining
  *
- * Only returns in case of an error
+ * Returns in case of an error or no driver
  */
 int cpuidle_play_dead(void)
 {
@@ -83,6 +83,9 @@ int cpuidle_play_dead(void)
 	int i, dead_state = -1;
 	int power_usage = -1;
 
+	if (!drv)
+		return -ENODEV;
+
 	/* Find lowest-power state that supports long-term idle */
 	for (i = CPUIDLE_DRIVER_STATE_START; i < drv->state_count; i++) {
 		struct cpuidle_state *s = &drv->states[i];

commit a335750b9a039a9d4cd727cdccacfb90fd63c4e8
Merge: 10f3cb41d48a d326f44e5f22
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Mar 30 16:45:38 2012 -0700

    Merge branch 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux
    
    Pull ACPI & Power Management changes from Len Brown:
     - ACPI 5.0 after-ripples, ACPICA/Linux divergence cleanup
     - cpuidle evolving, more ARM use
     - thermal sub-system evolving, ditto
     - assorted other PM bits
    
    Fix up conflicts in various cpuidle implementations due to ARM cpuidle
    cleanups (ARM at91 self-refresh and cpu idle code rewritten into
    "standby" in asm conflicting with the consolidation of cpuidle time
    keeping), trivial SH include file context conflict and RCU tracing fixes
    in generic code.
    
    * 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux: (77 commits)
      ACPI throttling: fix endian bug in acpi_read_throttling_status()
      Disable MCP limit exceeded messages from Intel IPS driver
      ACPI video: Don't start video device until its associated input device has been allocated
      ACPI video: Harden video bus adding.
      ACPI: Add support for exposing BGRT data
      ACPI: export acpi_kobj
      ACPI: Fix logic for removing mappings in 'acpi_unmap'
      CPER failed to handle generic error records with multiple sections
      ACPI: Clean redundant codes in scan.c
      ACPI: Fix unprotected smp_processor_id() in acpi_processor_cst_has_changed()
      ACPI: consistently use should_use_kmap()
      PNPACPI: Fix device ref leaking in acpi_pnp_match
      ACPI: Fix use-after-free in acpi_map_lsapic
      ACPI: processor_driver: add missing kfree
      ACPI, APEI: Fix incorrect APEI register bit width check and usage
      Update documentation for parameter *notrigger* in einj.txt
      ACPI, APEI, EINJ, new parameter to control trigger action
      ACPI, APEI, EINJ, limit the range of einj_param
      ACPI, APEI, Fix ERST header length check
      cpuidle: power_usage should be declared signed integer
      ...

commit 1a022e3f1be11730bd8747b1af96a0274bf6356e
Author: Boris Ostrovsky <boris.ostrovsky@amd.com>
Date:   Tue Mar 13 19:55:09 2012 +0100

    idle, x86: Allow off-lined CPU to enter deeper C states
    
    Currently when a CPU is off-lined it enters either MWAIT-based idle or,
    if MWAIT is not desired or supported, HLT-based idle (which places the
    processor in C1 state). This patch allows processors without MWAIT
    support to stay in states deeper than C1.
    
    Signed-off-by: Boris Ostrovsky <boris.ostrovsky@amd.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index f7cab5e9c4d6..3e146b2ada4a 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -71,6 +71,34 @@ typedef int (*cpuidle_enter_t)(struct cpuidle_device *dev,
 
 static cpuidle_enter_t cpuidle_enter_ops;
 
+/**
+ * cpuidle_play_dead - cpu off-lining
+ *
+ * Only returns in case of an error
+ */
+int cpuidle_play_dead(void)
+{
+	struct cpuidle_device *dev = __this_cpu_read(cpuidle_devices);
+	struct cpuidle_driver *drv = cpuidle_get_driver();
+	int i, dead_state = -1;
+	int power_usage = -1;
+
+	/* Find lowest-power state that supports long-term idle */
+	for (i = CPUIDLE_DRIVER_STATE_START; i < drv->state_count; i++) {
+		struct cpuidle_state *s = &drv->states[i];
+
+		if (s->power_usage < power_usage && s->enter_dead) {
+			power_usage = s->power_usage;
+			dead_state = i;
+		}
+	}
+
+	if (dead_state != -1)
+		return drv->states[dead_state].enter_dead(dev, dead_state);
+
+	return -ENODEV;
+}
+
 /**
  * cpuidle_idle_call - the main idle loop
  *

commit fc850f39ea54c760ce438a601cfea8ab80c4898e
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Mon Mar 26 14:51:26 2012 +0200

    cpuidle: use the driver's state_count as default
    
    If the state_count is not initialized for the device use
    the driver's state count as the default. That will prevent
    to add it manually in the cpuidle driver initialization
    routine and will save us from duplicate line of code.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 77304b6b8aef..f7cab5e9c4d6 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -268,7 +268,7 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 	if (!drv || !cpuidle_curr_governor)
 		return -EIO;
 	if (!dev->state_count)
-		return -EINVAL;
+		dev->state_count = drv->state_count;
 
 	if (dev->registered == 0) {
 		ret = __cpuidle_register_device(dev);

commit 3a53396b0381ec9d5180fd8fe7a681c8ce95fd9a
Author: ShuoX Liu <shuox.liu@intel.com>
Date:   Wed Mar 28 15:19:11 2012 -0700

    cpuidle: add a sysfs entry to disable specific C state for debug purpose.
    
    Some C states of new CPU might be not good.  One reason is BIOS might
    configure them incorrectly.  To help developers root cause it quickly, the
    patch adds a new sysfs entry, so developers could disable specific C state
    manually.
    
    In addition, C state might have much impact on performance tuning, as it
    takes much time to enter/exit C states, which might delay interrupt
    processing.  With the new debug option, developers could check if a deep C
    state could impact performance and how much impact it could cause.
    
    Also add this option in Documentation/cpuidle/sysfs.txt.
    
    [akpm@linux-foundation.org: check kstrtol return value]
    Signed-off-by: ShuoX Liu <shuox.liu@intel.com>
    Reviewed-by: Yanmin Zhang <yanmin_zhang@intel.com>
    Reviewed-and-Tested-by: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 4869b5500234..77304b6b8aef 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -245,6 +245,7 @@ static void poll_idle_init(struct cpuidle_driver *drv)
 	state->power_usage = -1;
 	state->flags = 0;
 	state->enter = poll_idle;
+	state->disable = 0;
 }
 #else
 static void poll_idle_init(struct cpuidle_driver *drv) {}

commit e1689795a784a7c41ac4cf9032794986b095a133
Author: Robert Lee <rob.lee@linaro.org>
Date:   Tue Mar 20 15:22:42 2012 -0500

    cpuidle: Add common time keeping and irq enabling
    
    Make necessary changes to implement time keeping and irq enabling
    in the core cpuidle code.  This will allow the removal of these
    functionalities from various platform cpuidle implementations whose
    timekeeping and irq enabling follows the form in this common code.
    
    Signed-off-by: Robert Lee <rob.lee@linaro.org>
    Tested-by: Jean Pihet <j-pihet@ti.com>
    Tested-by: Amit Daniel <amit.kachhap@linaro.org>
    Tested-by: Robert Lee <rob.lee@linaro.org>
    Reviewed-by: Kevin Hilman <khilman@ti.com>
    Reviewed-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Reviewed-by: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Acked-by: Jean Pihet <j-pihet@ti.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 59f4261c753a..4869b5500234 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -53,6 +53,24 @@ static void cpuidle_kick_cpus(void) {}
 
 static int __cpuidle_register_device(struct cpuidle_device *dev);
 
+static inline int cpuidle_enter(struct cpuidle_device *dev,
+				struct cpuidle_driver *drv, int index)
+{
+	struct cpuidle_state *target_state = &drv->states[index];
+	return target_state->enter(dev, drv, index);
+}
+
+static inline int cpuidle_enter_tk(struct cpuidle_device *dev,
+			       struct cpuidle_driver *drv, int index)
+{
+	return cpuidle_wrap_enter(dev, drv, index, cpuidle_enter);
+}
+
+typedef int (*cpuidle_enter_t)(struct cpuidle_device *dev,
+			       struct cpuidle_driver *drv, int index);
+
+static cpuidle_enter_t cpuidle_enter_ops;
+
 /**
  * cpuidle_idle_call - the main idle loop
  *
@@ -63,7 +81,6 @@ int cpuidle_idle_call(void)
 {
 	struct cpuidle_device *dev = __this_cpu_read(cpuidle_devices);
 	struct cpuidle_driver *drv = cpuidle_get_driver();
-	struct cpuidle_state *target_state;
 	int next_state, entered_state;
 
 	if (off)
@@ -92,12 +109,10 @@ int cpuidle_idle_call(void)
 		return 0;
 	}
 
-	target_state = &drv->states[next_state];
-
 	trace_power_start(POWER_CSTATE, next_state, dev->cpu);
 	trace_cpu_idle(next_state, dev->cpu);
 
-	entered_state = target_state->enter(dev, drv, next_state);
+	entered_state = cpuidle_enter_ops(dev, drv, next_state);
 
 	trace_power_end(dev->cpu);
 	trace_cpu_idle(PWR_EVENT_EXIT, dev->cpu);
@@ -110,6 +125,8 @@ int cpuidle_idle_call(void)
 		dev->states_usage[entered_state].time +=
 				(unsigned long long)dev->last_residency;
 		dev->states_usage[entered_state].usage++;
+	} else {
+		dev->last_residency = 0;
 	}
 
 	/* give the governor an opportunity to reflect on the outcome */
@@ -164,6 +181,37 @@ void cpuidle_resume_and_unlock(void)
 
 EXPORT_SYMBOL_GPL(cpuidle_resume_and_unlock);
 
+/**
+ * cpuidle_wrap_enter - performs timekeeping and irqen around enter function
+ * @dev: pointer to a valid cpuidle_device object
+ * @drv: pointer to a valid cpuidle_driver object
+ * @index: index of the target cpuidle state.
+ */
+int cpuidle_wrap_enter(struct cpuidle_device *dev,
+				struct cpuidle_driver *drv, int index,
+				int (*enter)(struct cpuidle_device *dev,
+					struct cpuidle_driver *drv, int index))
+{
+	ktime_t time_start, time_end;
+	s64 diff;
+
+	time_start = ktime_get();
+
+	index = enter(dev, drv, index);
+
+	time_end = ktime_get();
+
+	local_irq_enable();
+
+	diff = ktime_to_us(ktime_sub(time_end, time_start));
+	if (diff > INT_MAX)
+		diff = INT_MAX;
+
+	dev->last_residency = (int) diff;
+
+	return index;
+}
+
 #ifdef CONFIG_ARCH_HAS_CPU_RELAX
 static int poll_idle(struct cpuidle_device *dev,
 		struct cpuidle_driver *drv, int index)
@@ -212,10 +260,11 @@ static void poll_idle_init(struct cpuidle_driver *drv) {}
 int cpuidle_enable_device(struct cpuidle_device *dev)
 {
 	int ret, i;
+	struct cpuidle_driver *drv = cpuidle_get_driver();
 
 	if (dev->enabled)
 		return 0;
-	if (!cpuidle_get_driver() || !cpuidle_curr_governor)
+	if (!drv || !cpuidle_curr_governor)
 		return -EIO;
 	if (!dev->state_count)
 		return -EINVAL;
@@ -226,13 +275,16 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 			return ret;
 	}
 
-	poll_idle_init(cpuidle_get_driver());
+	cpuidle_enter_ops = drv->en_core_tk_irqen ?
+		cpuidle_enter_tk : cpuidle_enter;
+
+	poll_idle_init(drv);
 
 	if ((ret = cpuidle_add_state_sysfs(dev)))
 		return ret;
 
 	if (cpuidle_curr_governor->enable &&
-	    (ret = cpuidle_curr_governor->enable(cpuidle_get_driver(), dev)))
+	    (ret = cpuidle_curr_governor->enable(drv, dev)))
 		goto fail_sysfs;
 
 	for (i = 0; i < dev->state_count; i++) {

commit 76027ea863fc02698da536b4970784eed3caa635
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Tue Feb 7 09:46:01 2012 -0500

    cpuidle/tracing: Denote the tracepoints as being in rcu_idle_exit() section
    
    As the tracepoints in the cpuidle code are called when rcu_idle_exit() is in
    effect, the _rcuidle() version must be used, otherwise the rcu_read_lock()s
    that protect the tracepoint will not be honored.
    
    Cc: Len Brown <len.brown@intel.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>
    Reviewed-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 59f4261c753a..6588f43017bd 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -94,13 +94,13 @@ int cpuidle_idle_call(void)
 
 	target_state = &drv->states[next_state];
 
-	trace_power_start(POWER_CSTATE, next_state, dev->cpu);
-	trace_cpu_idle(next_state, dev->cpu);
+	trace_power_start_rcuidle(POWER_CSTATE, next_state, dev->cpu);
+	trace_cpu_idle_rcuidle(next_state, dev->cpu);
 
 	entered_state = target_state->enter(dev, drv, next_state);
 
-	trace_power_end(dev->cpu);
-	trace_cpu_idle(PWR_EVENT_EXIT, dev->cpu);
+	trace_power_end_rcuidle(dev->cpu);
+	trace_cpu_idle_rcuidle(PWR_EVENT_EXIT, dev->cpu);
 
 	if (entered_state >= 0) {
 		/* Update cpuidle counters */

commit 8a25a2fd126c621f44f3aeaef80d51f00fc11639
Author: Kay Sievers <kay.sievers@vrfy.org>
Date:   Wed Dec 21 14:29:42 2011 -0800

    cpu: convert 'cpu' and 'machinecheck' sysdev_class to a regular subsystem
    
    This moves the 'cpu sysdev_class' over to a regular 'cpu' subsystem
    and converts the devices to regular devices. The sysdev drivers are
    implemented as subsystem interfaces now.
    
    After all sysdev classes are ported to regular driver core entities, the
    sysdev implementation will be entirely removed from the kernel.
    
    Userspace relies on events and generic sysfs subsystem infrastructure
    from sysdev devices, which are made available with this conversion.
    
    Cc: Haavard Skinnemoen <hskinnemoen@gmail.com>
    Cc: Hans-Christian Egtvedt <egtvedt@samfundet.no>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Borislav Petkov <bp@amd64.org>
    Cc: Tigran Aivazian <tigran@aivazian.fsnet.co.uk>
    Cc: Len Brown <lenb@kernel.org>
    Cc: Zhang Rui <rui.zhang@intel.com>
    Cc: Dave Jones <davej@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Russell King <rmk+kernel@arm.linux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: "Rafael J. Wysocki" <rjw@sisk.pl>
    Cc: "Srivatsa S. Bhat" <srivatsa.bhat@linux.vnet.ibm.com>
    Signed-off-by: Kay Sievers <kay.sievers@vrfy.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 06ce2680d00d..59f4261c753a 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -291,10 +291,10 @@ EXPORT_SYMBOL_GPL(cpuidle_disable_device);
 static int __cpuidle_register_device(struct cpuidle_device *dev)
 {
 	int ret;
-	struct sys_device *sys_dev = get_cpu_sysdev((unsigned long)dev->cpu);
+	struct device *cpu_dev = get_cpu_device((unsigned long)dev->cpu);
 	struct cpuidle_driver *cpuidle_driver = cpuidle_get_driver();
 
-	if (!sys_dev)
+	if (!dev)
 		return -EINVAL;
 	if (!try_module_get(cpuidle_driver->owner))
 		return -EINVAL;
@@ -303,7 +303,7 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 
 	per_cpu(cpuidle_devices, dev->cpu) = dev;
 	list_add(&dev->device_list, &cpuidle_detected_devices);
-	if ((ret = cpuidle_add_sysfs(sys_dev))) {
+	if ((ret = cpuidle_add_sysfs(cpu_dev))) {
 		module_put(cpuidle_driver->owner);
 		return ret;
 	}
@@ -344,7 +344,7 @@ EXPORT_SYMBOL_GPL(cpuidle_register_device);
  */
 void cpuidle_unregister_device(struct cpuidle_device *dev)
 {
-	struct sys_device *sys_dev = get_cpu_sysdev((unsigned long)dev->cpu);
+	struct device *cpu_dev = get_cpu_device((unsigned long)dev->cpu);
 	struct cpuidle_driver *cpuidle_driver = cpuidle_get_driver();
 
 	if (dev->registered == 0)
@@ -354,7 +354,7 @@ void cpuidle_unregister_device(struct cpuidle_device *dev)
 
 	cpuidle_disable_device(dev);
 
-	cpuidle_remove_sysfs(sys_dev);
+	cpuidle_remove_sysfs(cpu_dev);
 	list_del(&dev->device_list);
 	wait_for_completion(&dev->kobj_unregister);
 	per_cpu(cpuidle_devices, dev->cpu) = NULL;
@@ -411,7 +411,7 @@ static int __init cpuidle_init(void)
 	if (cpuidle_disabled())
 		return -ENODEV;
 
-	ret = cpuidle_add_class_sysfs(&cpu_sysdev_class);
+	ret = cpuidle_add_interface(cpu_subsys.dev_root);
 	if (ret)
 		return ret;
 

commit 3c00303206c3a1ccd86579efdc90bc35f140962e
Merge: 83dbb15e9cd7 efb90582c575
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 7 10:13:52 2011 -0800

    Merge branch 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux
    
    * 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux:
      cpuidle: Single/Global registration of idle states
      cpuidle: Split cpuidle_state structure and move per-cpu statistics fields
      cpuidle: Remove CPUIDLE_FLAG_IGNORE and dev->prepare()
      cpuidle: Move dev->last_residency update to driver enter routine; remove dev->last_state
      ACPI: Fix CONFIG_ACPI_DOCK=n compiler warning
      ACPI: Export FADT pm_profile integer value to userspace
      thermal: Prevent polling from happening during system suspend
      ACPI: Drop ACPI_NO_HARDWARE_INIT
      ACPI atomicio: Convert width in bits to bytes in __acpi_ioremap_fast()
      PNPACPI: Simplify disabled resource registration
      ACPI: Fix possible recursive locking in hwregs.c
      ACPI: use kstrdup()
      mrst pmu: update comment
      tools/power turbostat: less verbose debugging

commit 46bcfad7a819bd17ac4e831b04405152d59784ab
Author: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
Date:   Fri Oct 28 16:20:42 2011 +0530

    cpuidle: Single/Global registration of idle states
    
    This patch makes the cpuidle_states structure global (single copy)
    instead of per-cpu. The statistics needed on per-cpu basis
    by the governor are kept per-cpu. This simplifies the cpuidle
    subsystem as state registration is done by single cpu only.
    Having single copy of cpuidle_states saves memory. Rare case
    of asymmetric C-states can be handled within the cpuidle driver
    and architectures such as POWER do not have asymmetric C-states.
    
    Having single/global registration of all the idle states,
    dynamic C-state transitions on x86 are handled by
    the boot cpu. Here, the boot cpu  would disable all the devices,
    re-populate the states and later enable all the devices,
    irrespective of the cpu that would receive the notification first.
    
    Reference:
    https://lkml.org/lkml/2011/4/25/83
    
    Signed-off-by: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Signed-off-by: Trinabh Gupta <g.trinabh@gmail.com>
    Tested-by: Jean Pihet <j-pihet@ti.com>
    Reviewed-by: Kevin Hilman <khilman@ti.com>
    Acked-by: Arjan van de Ven <arjan@linux.intel.com>
    Acked-by: Kevin Hilman <khilman@ti.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 7127e92fa8a1..7a57b11eaa8d 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -61,6 +61,7 @@ static int __cpuidle_register_device(struct cpuidle_device *dev);
 int cpuidle_idle_call(void)
 {
 	struct cpuidle_device *dev = __this_cpu_read(cpuidle_devices);
+	struct cpuidle_driver *drv = cpuidle_get_driver();
 	struct cpuidle_state *target_state;
 	int next_state, entered_state;
 
@@ -84,18 +85,18 @@ int cpuidle_idle_call(void)
 #endif
 
 	/* ask the governor for the next state */
-	next_state = cpuidle_curr_governor->select(dev);
+	next_state = cpuidle_curr_governor->select(drv, dev);
 	if (need_resched()) {
 		local_irq_enable();
 		return 0;
 	}
 
-	target_state = &dev->states[next_state];
+	target_state = &drv->states[next_state];
 
 	trace_power_start(POWER_CSTATE, next_state, dev->cpu);
 	trace_cpu_idle(next_state, dev->cpu);
 
-	entered_state = target_state->enter(dev, next_state);
+	entered_state = target_state->enter(dev, drv, next_state);
 
 	trace_power_end(dev->cpu);
 	trace_cpu_idle(PWR_EVENT_EXIT, dev->cpu);
@@ -163,7 +164,8 @@ void cpuidle_resume_and_unlock(void)
 EXPORT_SYMBOL_GPL(cpuidle_resume_and_unlock);
 
 #ifdef CONFIG_ARCH_HAS_CPU_RELAX
-static int poll_idle(struct cpuidle_device *dev, int index)
+static int poll_idle(struct cpuidle_device *dev,
+		struct cpuidle_driver *drv, int index)
 {
 	ktime_t	t1, t2;
 	s64 diff;
@@ -183,12 +185,9 @@ static int poll_idle(struct cpuidle_device *dev, int index)
 	return index;
 }
 
-static void poll_idle_init(struct cpuidle_device *dev)
+static void poll_idle_init(struct cpuidle_driver *drv)
 {
-	struct cpuidle_state *state = &dev->states[0];
-	struct cpuidle_state_usage *state_usage = &dev->states_usage[0];
-
-	cpuidle_set_statedata(state_usage, NULL);
+	struct cpuidle_state *state = &drv->states[0];
 
 	snprintf(state->name, CPUIDLE_NAME_LEN, "POLL");
 	snprintf(state->desc, CPUIDLE_DESC_LEN, "CPUIDLE CORE POLL IDLE");
@@ -199,7 +198,7 @@ static void poll_idle_init(struct cpuidle_device *dev)
 	state->enter = poll_idle;
 }
 #else
-static void poll_idle_init(struct cpuidle_device *dev) {}
+static void poll_idle_init(struct cpuidle_driver *drv) {}
 #endif /* CONFIG_ARCH_HAS_CPU_RELAX */
 
 /**
@@ -226,13 +225,13 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 			return ret;
 	}
 
-	poll_idle_init(dev);
+	poll_idle_init(cpuidle_get_driver());
 
 	if ((ret = cpuidle_add_state_sysfs(dev)))
 		return ret;
 
 	if (cpuidle_curr_governor->enable &&
-	    (ret = cpuidle_curr_governor->enable(dev)))
+	    (ret = cpuidle_curr_governor->enable(cpuidle_get_driver(), dev)))
 		goto fail_sysfs;
 
 	for (i = 0; i < dev->state_count; i++) {
@@ -273,7 +272,7 @@ void cpuidle_disable_device(struct cpuidle_device *dev)
 	dev->enabled = 0;
 
 	if (cpuidle_curr_governor->disable)
-		cpuidle_curr_governor->disable(dev);
+		cpuidle_curr_governor->disable(cpuidle_get_driver(), dev);
 
 	cpuidle_remove_state_sysfs(dev);
 	enabled_devices--;
@@ -301,26 +300,6 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 
 	init_completion(&dev->kobj_unregister);
 
-	/*
-	 * cpuidle driver should set the dev->power_specified bit
-	 * before registering the device if the driver provides
-	 * power_usage numbers.
-	 *
-	 * For those devices whose ->power_specified is not set,
-	 * we fill in power_usage with decreasing values as the
-	 * cpuidle code has an implicit assumption that state Cn
-	 * uses less power than C(n-1).
-	 *
-	 * With CONFIG_ARCH_HAS_CPU_RELAX, C0 is already assigned
-	 * an power value of -1.  So we use -2, -3, etc, for other
-	 * c-states.
-	 */
-	if (!dev->power_specified) {
-		int i;
-		for (i = CPUIDLE_DRIVER_STATE_START; i < dev->state_count; i++)
-			dev->states[i].power_usage = -1 - i;
-	}
-
 	per_cpu(cpuidle_devices, dev->cpu) = dev;
 	list_add(&dev->device_list, &cpuidle_detected_devices);
 	if ((ret = cpuidle_add_sysfs(sys_dev))) {

commit 4202735e8ab6ecfb0381631a0d0b58fefe0bd4e2
Author: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
Date:   Fri Oct 28 16:20:33 2011 +0530

    cpuidle: Split cpuidle_state structure and move per-cpu statistics fields
    
    This is the first step towards global registration of cpuidle
    states. The statistics used primarily by the governor are per-cpu
    and have to be split from rest of the fields inside cpuidle_state,
    which would be made global i.e. single copy. The driver_data field
    is also per-cpu and moved.
    
    Signed-off-by: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Signed-off-by: Trinabh Gupta <g.trinabh@gmail.com>
    Tested-by: Jean Pihet <j-pihet@ti.com>
    Reviewed-by: Kevin Hilman <khilman@ti.com>
    Acked-by: Arjan van de Ven <arjan@linux.intel.com>
    Acked-by: Kevin Hilman <khilman@ti.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index f66bcf9bfe93..7127e92fa8a1 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -105,9 +105,9 @@ int cpuidle_idle_call(void)
 		/* This can be moved to within driver enter routine
 		 * but that results in multiple copies of same code.
 		 */
-		dev->states[entered_state].time +=
+		dev->states_usage[entered_state].time +=
 				(unsigned long long)dev->last_residency;
-		dev->states[entered_state].usage++;
+		dev->states_usage[entered_state].usage++;
 	}
 
 	/* give the governor an opportunity to reflect on the outcome */
@@ -186,8 +186,9 @@ static int poll_idle(struct cpuidle_device *dev, int index)
 static void poll_idle_init(struct cpuidle_device *dev)
 {
 	struct cpuidle_state *state = &dev->states[0];
+	struct cpuidle_state_usage *state_usage = &dev->states_usage[0];
 
-	cpuidle_set_statedata(state, NULL);
+	cpuidle_set_statedata(state_usage, NULL);
 
 	snprintf(state->name, CPUIDLE_NAME_LEN, "POLL");
 	snprintf(state->desc, CPUIDLE_DESC_LEN, "CPUIDLE CORE POLL IDLE");
@@ -235,8 +236,8 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 		goto fail_sysfs;
 
 	for (i = 0; i < dev->state_count; i++) {
-		dev->states[i].usage = 0;
-		dev->states[i].time = 0;
+		dev->states_usage[i].usage = 0;
+		dev->states_usage[i].time = 0;
 	}
 	dev->last_residency = 0;
 

commit b25edc42bfb9602f0503474b2c94701d5536ce60
Author: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
Date:   Fri Oct 28 16:20:24 2011 +0530

    cpuidle: Remove CPUIDLE_FLAG_IGNORE and dev->prepare()
    
    The cpuidle_device->prepare() mechanism causes updates to the
    cpuidle_state[].flags, setting and clearing CPUIDLE_FLAG_IGNORE
    to tell the governor not to chose a state on a per-cpu basis at
    run-time. State demotion is now handled by the driver and it returns
    the actual state entered. Hence, this mechanism is not required.
    Also this removes per-cpu flags from cpuidle_state enabling
    it to be made global.
    
    Reference:
    https://lkml.org/lkml/2011/3/25/52
    
    Signed-off-by: Deepthi Dharwar <deepthi@linux.vnet.ibm>
    Signed-off-by: Trinabh Gupta <g.trinabh@gmail.com>
    Tested-by: Jean Pihet <j-pihet@ti.com>
    Acked-by: Arjan van de Ven <arjan@linux.intel.com>
    Reviewed-by: Kevin Hilman <khilman@ti.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 88bd12104396..f66bcf9bfe93 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -83,16 +83,6 @@ int cpuidle_idle_call(void)
 	hrtimer_peek_ahead_timers();
 #endif
 
-	/*
-	 * Call the device's prepare function before calling the
-	 * governor's select function.  ->prepare gives the device's
-	 * cpuidle driver a chance to update any dynamic information
-	 * of its cpuidle states for the current idle period, e.g.
-	 * state availability, latencies, residencies, etc.
-	 */
-	if (dev->prepare)
-		dev->prepare(dev);
-
 	/* ask the governor for the next state */
 	next_state = cpuidle_curr_governor->select(dev);
 	if (need_resched()) {

commit e978aa7d7d57d04eb5f88a7507c4fb98577def77
Author: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
Date:   Fri Oct 28 16:20:09 2011 +0530

    cpuidle: Move dev->last_residency update to driver enter routine; remove dev->last_state
    
    Cpuidle governor only suggests the state to enter using the
    governor->select() interface, but allows the low level driver to
    override the recommended state. The actual entered state
    may be different because of software or hardware demotion. Software
    demotion is done by the back-end cpuidle driver and can be accounted
    correctly. Current cpuidle code uses last_state field to capture the
    actual state entered and based on that updates the statistics for the
    state entered.
    
    Ideally the driver enter routine should update the counters,
    and it should return the state actually entered rather than the time
    spent there. The generic cpuidle code should simply handle where
    the counters live in the sysfs namespace, not updating the counters.
    
    Reference:
    https://lkml.org/lkml/2011/3/25/52
    
    Signed-off-by: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Signed-off-by: Trinabh Gupta <g.trinabh@gmail.com>
    Tested-by: Jean Pihet <j-pihet@ti.com>
    Reviewed-by: Kevin Hilman <khilman@ti.com>
    Acked-by: Arjan van de Ven <arjan@linux.intel.com>
    Acked-by: Kevin Hilman <khilman@ti.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index d4c542372886..88bd12104396 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -62,7 +62,7 @@ int cpuidle_idle_call(void)
 {
 	struct cpuidle_device *dev = __this_cpu_read(cpuidle_devices);
 	struct cpuidle_state *target_state;
-	int next_state;
+	int next_state, entered_state;
 
 	if (off)
 		return -ENODEV;
@@ -102,26 +102,27 @@ int cpuidle_idle_call(void)
 
 	target_state = &dev->states[next_state];
 
-	/* enter the state and update stats */
-	dev->last_state = target_state;
-
 	trace_power_start(POWER_CSTATE, next_state, dev->cpu);
 	trace_cpu_idle(next_state, dev->cpu);
 
-	dev->last_residency = target_state->enter(dev, target_state);
+	entered_state = target_state->enter(dev, next_state);
 
 	trace_power_end(dev->cpu);
 	trace_cpu_idle(PWR_EVENT_EXIT, dev->cpu);
 
-	if (dev->last_state)
-		target_state = dev->last_state;
-
-	target_state->time += (unsigned long long)dev->last_residency;
-	target_state->usage++;
+	if (entered_state >= 0) {
+		/* Update cpuidle counters */
+		/* This can be moved to within driver enter routine
+		 * but that results in multiple copies of same code.
+		 */
+		dev->states[entered_state].time +=
+				(unsigned long long)dev->last_residency;
+		dev->states[entered_state].usage++;
+	}
 
 	/* give the governor an opportunity to reflect on the outcome */
 	if (cpuidle_curr_governor->reflect)
-		cpuidle_curr_governor->reflect(dev);
+		cpuidle_curr_governor->reflect(dev, entered_state);
 
 	return 0;
 }
@@ -172,11 +173,10 @@ void cpuidle_resume_and_unlock(void)
 EXPORT_SYMBOL_GPL(cpuidle_resume_and_unlock);
 
 #ifdef CONFIG_ARCH_HAS_CPU_RELAX
-static int poll_idle(struct cpuidle_device *dev, struct cpuidle_state *st)
+static int poll_idle(struct cpuidle_device *dev, int index)
 {
 	ktime_t	t1, t2;
 	s64 diff;
-	int ret;
 
 	t1 = ktime_get();
 	local_irq_enable();
@@ -188,8 +188,9 @@ static int poll_idle(struct cpuidle_device *dev, struct cpuidle_state *st)
 	if (diff > INT_MAX)
 		diff = INT_MAX;
 
-	ret = (int) diff;
-	return ret;
+	dev->last_residency = (int) diff;
+
+	return index;
 }
 
 static void poll_idle_init(struct cpuidle_device *dev)
@@ -248,7 +249,6 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 		dev->states[i].time = 0;
 	}
 	dev->last_residency = 0;
-	dev->last_state = NULL;
 
 	smp_wmb();
 

commit 884b17e109d61e95ee4c652cf6873341bf1dca63
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Mon Aug 29 17:52:39 2011 -0400

    cpuidle: Add module.h to drivers/cpuidle files as required.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 0df014110097..becd6d99203b 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -17,6 +17,7 @@
 #include <linux/cpuidle.h>
 #include <linux/ktime.h>
 #include <linux/hrtimer.h>
+#include <linux/module.h>
 #include <trace/events/power.h>
 
 #include "cpuidle.h"

commit e8db0be1245de16a6cc6365506abc392c3c212d4
Author: Jean Pihet <j-pihet@ti.com>
Date:   Thu Aug 25 15:35:03 2011 +0200

    PM QoS: Move and rename the implementation files
    
    The PM QoS implementation files are better named
    kernel/power/qos.c and include/linux/pm_qos.h.
    
    The PM QoS support is compiled under the CONFIG_PM option.
    
    Signed-off-by: Jean Pihet <j-pihet@ti.com>
    Acked-by: markgross <markgross@thegnar.org>
    Reviewed-by: Kevin Hilman <khilman@ti.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index d4c542372886..0df014110097 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -12,7 +12,7 @@
 #include <linux/mutex.h>
 #include <linux/sched.h>
 #include <linux/notifier.h>
-#include <linux/pm_qos_params.h>
+#include <linux/pm_qos.h>
 #include <linux/cpu.h>
 #include <linux/cpuidle.h>
 #include <linux/ktime.h>

commit a0bfa1373859e9d11dc92561a8667588803e42d8
Author: Len Brown <len.brown@intel.com>
Date:   Fri Apr 1 19:34:59 2011 -0400

    cpuidle: stop depending on pm_idle
    
    cpuidle users should call cpuidle_call_idle() directly
    rather than via (pm_idle)() function pointer.
    
    Architecture may choose to continue using (pm_idle)(),
    but cpuidle need not depend on it:
    
      my_arch_cpu_idle()
            ...
            if(cpuidle_call_idle())
                    pm_idle();
    
    cc: Kevin Hilman <khilman@deeprootsystems.com>
    cc: Paul Mundt <lethal@linux-sh.org>
    cc: x86@kernel.org
    Acked-by: H. Peter Anvin <hpa@linux.intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 041df0b056b2..d4c542372886 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -25,10 +25,10 @@ DEFINE_PER_CPU(struct cpuidle_device *, cpuidle_devices);
 
 DEFINE_MUTEX(cpuidle_lock);
 LIST_HEAD(cpuidle_detected_devices);
-static void (*pm_idle_old)(void);
 
 static int enabled_devices;
 static int off __read_mostly;
+static int initialized __read_mostly;
 
 int cpuidle_disabled(void)
 {
@@ -56,25 +56,23 @@ static int __cpuidle_register_device(struct cpuidle_device *dev);
  * cpuidle_idle_call - the main idle loop
  *
  * NOTE: no locks or semaphores should be used here
+ * return non-zero on failure
  */
-static void cpuidle_idle_call(void)
+int cpuidle_idle_call(void)
 {
 	struct cpuidle_device *dev = __this_cpu_read(cpuidle_devices);
 	struct cpuidle_state *target_state;
 	int next_state;
 
+	if (off)
+		return -ENODEV;
+
+	if (!initialized)
+		return -ENODEV;
+
 	/* check if the device is ready */
-	if (!dev || !dev->enabled) {
-		if (pm_idle_old)
-			pm_idle_old();
-		else
-#if defined(CONFIG_ARCH_HAS_DEFAULT_IDLE)
-			default_idle();
-#else
-			local_irq_enable();
-#endif
-		return;
-	}
+	if (!dev || !dev->enabled)
+		return -EBUSY;
 
 #if 0
 	/* shows regressions, re-enable for 2.6.29 */
@@ -99,7 +97,7 @@ static void cpuidle_idle_call(void)
 	next_state = cpuidle_curr_governor->select(dev);
 	if (need_resched()) {
 		local_irq_enable();
-		return;
+		return 0;
 	}
 
 	target_state = &dev->states[next_state];
@@ -124,6 +122,8 @@ static void cpuidle_idle_call(void)
 	/* give the governor an opportunity to reflect on the outcome */
 	if (cpuidle_curr_governor->reflect)
 		cpuidle_curr_governor->reflect(dev);
+
+	return 0;
 }
 
 /**
@@ -131,10 +131,10 @@ static void cpuidle_idle_call(void)
  */
 void cpuidle_install_idle_handler(void)
 {
-	if (enabled_devices && (pm_idle != cpuidle_idle_call)) {
+	if (enabled_devices) {
 		/* Make sure all changes finished before we switch to new idle */
 		smp_wmb();
-		pm_idle = cpuidle_idle_call;
+		initialized = 1;
 	}
 }
 
@@ -143,8 +143,8 @@ void cpuidle_install_idle_handler(void)
  */
 void cpuidle_uninstall_idle_handler(void)
 {
-	if (enabled_devices && pm_idle_old && (pm_idle != pm_idle_old)) {
-		pm_idle = pm_idle_old;
+	if (enabled_devices) {
+		initialized = 0;
 		cpuidle_kick_cpus();
 	}
 }
@@ -440,8 +440,6 @@ static int __init cpuidle_init(void)
 	if (cpuidle_disabled())
 		return -ENODEV;
 
-	pm_idle_old = pm_idle;
-
 	ret = cpuidle_add_class_sysfs(&cpu_sysdev_class);
 	if (ret)
 		return ret;

commit d91ee5863b71e8c90eaf6035bff3078a85e2e7b5
Author: Len Brown <len.brown@intel.com>
Date:   Fri Apr 1 18:28:35 2011 -0400

    cpuidle: replace xen access to x86 pm_idle and default_idle
    
    When a Xen Dom0 kernel boots on a hypervisor, it gets access
    to the raw-hardware ACPI tables.  While it parses the idle tables
    for the hypervisor's beneift, it uses HLT for its own idle.
    
    Rather than have xen scribble on pm_idle and access default_idle,
    have it simply disable_cpuidle() so acpi_idle will not load and
    architecture default HLT will be used.
    
    cc: xen-devel@lists.xensource.com
    Tested-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Acked-by: H. Peter Anvin <hpa@linux.intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index faae2c357bab..041df0b056b2 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -34,6 +34,10 @@ int cpuidle_disabled(void)
 {
 	return off;
 }
+void disable_cpuidle(void)
+{
+	off = 1;
+}
 
 #if defined(CONFIG_ARCH_HAS_CPU_IDLE_WAIT)
 static void cpuidle_kick_cpus(void)

commit 62027aea23fcd14478abdddd3b74a4e0f5fb2984
Author: Len Brown <len.brown@intel.com>
Date:   Fri Apr 1 18:13:10 2011 -0400

    cpuidle: create bootparam "cpuidle.off=1"
    
    useful for disabling cpuidle to fall back
    to architecture-default idle loop
    
    cpuidle drivers and governors will fail to register.
    on x86 they'll say so:
    
    intel_idle: intel_idle yielding to (null)
    ACPI: acpi_idle yielding to (null)
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index bf5092455a8f..faae2c357bab 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -28,6 +28,12 @@ LIST_HEAD(cpuidle_detected_devices);
 static void (*pm_idle_old)(void);
 
 static int enabled_devices;
+static int off __read_mostly;
+
+int cpuidle_disabled(void)
+{
+	return off;
+}
 
 #if defined(CONFIG_ARCH_HAS_CPU_IDLE_WAIT)
 static void cpuidle_kick_cpus(void)
@@ -427,6 +433,9 @@ static int __init cpuidle_init(void)
 {
 	int ret;
 
+	if (cpuidle_disabled())
+		return -ENODEV;
+
 	pm_idle_old = pm_idle;
 
 	ret = cpuidle_add_class_sysfs(&cpu_sysdev_class);
@@ -438,4 +447,5 @@ static int __init cpuidle_init(void)
 	return 0;
 }
 
+module_param(off, int, 0444);
 core_initcall(cpuidle_init);

commit 43952886f0b8b3c344c3392b88de067d5fa5419a
Merge: 56dbed129df3 f77cfe4ea217
Author: Len Brown <len.brown@intel.com>
Date:   Wed Jan 12 18:06:19 2011 -0500

    Merge branch 'cpuidle-perf-events' into idle-test

commit 56dbed129df3fdd4caf9018b6e7599ee258a5420
Merge: 2a2d31c8dc6f f878133bf022
Author: Len Brown <len.brown@intel.com>
Date:   Wed Jan 12 18:06:06 2011 -0500

    Merge branch 'linus' into idle-test

commit f77cfe4ea21760268c0277fa3e4b02dfd2a2c2f4
Author: Thomas Renninger <trenn@suse.de>
Date:   Fri Jan 7 11:29:44 2011 +0100

    cpuidle/x86/perf: fix power:cpu_idle double end events and throw cpu_idle events from the cpuidle layer
    
    Currently intel_idle and acpi_idle driver show double cpu_idle "exit idle"
    events -> this patch fixes it and makes cpu_idle events throwing less complex.
    
    It also introduces cpu_idle events for all architectures which use
    the cpuidle subsystem, namely:
      - arch/arm/mach-at91/cpuidle.c
      - arch/arm/mach-davinci/cpuidle.c
      - arch/arm/mach-kirkwood/cpuidle.c
      - arch/arm/mach-omap2/cpuidle34xx.c
      - arch/drivers/acpi/processor_idle.c (for all cases, not only mwait)
      - arch/x86/kernel/process.c (did throw events before, but was a mess)
      - drivers/idle/intel_idle.c (did throw events before)
    
    Convention should be:
    Fire cpu_idle events inside the current pm_idle function (not somewhere
    down the the callee tree) to keep things easy.
    
    Current possible pm_idle functions in X86:
    c1e_idle, poll_idle, cpuidle_idle_call, mwait_idle, default_idle
    -> this is really easy is now.
    
    This affects userspace:
    The type field of the cpu_idle power event can now direclty get
    mapped to:
    /sys/devices/system/cpu/cpuX/cpuidle/stateX/{name,desc,usage,time,...}
    instead of throwing very CPU/mwait specific values.
    This change is not visible for the intel_idle driver.
    For the acpi_idle driver it should only be visible if the vendor
    misses out C-states in his BIOS.
    Another (perf timechart) patch reads out cpuidle info of cpu_idle
    events from:
    /sys/.../cpuidle/stateX/*, then the cpuidle events are mapped
    to the correct C-/cpuidle state again, even if e.g. vendors miss
    out C-states in their BIOS and for example only export C1 and C3.
    -> everything is fine.
    
    Signed-off-by: Thomas Renninger <trenn@suse.de>
    CC: Robert Schoene <robert.schoene@tu-dresden.de>
    CC: Jean Pihet <j-pihet@ti.com>
    CC: Arjan van de Ven <arjan@linux.intel.com>
    CC: Ingo Molnar <mingo@elte.hu>
    CC: Frederic Weisbecker <fweisbec@gmail.com>
    CC: linux-pm@lists.linux-foundation.org
    CC: linux-acpi@vger.kernel.org
    CC: linux-kernel@vger.kernel.org
    CC: linux-perf-users@vger.kernel.org
    CC: linux-omap@vger.kernel.org
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 386888f10df0..e4855c33f897 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -96,7 +96,15 @@ static void cpuidle_idle_call(void)
 
 	/* enter the state and update stats */
 	dev->last_state = target_state;
+
+	trace_power_start(POWER_CSTATE, next_state, dev->cpu);
+	trace_cpu_idle(next_state, dev->cpu);
+
 	dev->last_residency = target_state->enter(dev, target_state);
+
+	trace_power_end(dev->cpu);
+	trace_cpu_idle(PWR_EVENT_EXIT, dev->cpu);
+
 	if (dev->last_state)
 		target_state = dev->last_state;
 
@@ -106,8 +114,6 @@ static void cpuidle_idle_call(void)
 	/* give the governor an opportunity to reflect on the outcome */
 	if (cpuidle_curr_governor->reflect)
 		cpuidle_curr_governor->reflect(dev);
-	trace_power_end(smp_processor_id());
-	trace_cpu_idle(PWR_EVENT_EXIT, smp_processor_id());
 }
 
 /**

commit d247632c08c674864d438733280422ddb7130ff8
Author: Len Brown <len.brown@intel.com>
Date:   Wed Jan 12 02:34:59 2011 -0500

    cpuidle: delete NOP CPUIDLE_FLAG_POLL
    
    it serves no purpose
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 37e446041306..dd5f1eafd6f2 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -186,7 +186,7 @@ static void poll_idle_init(struct cpuidle_device *dev)
 	state->exit_latency = 0;
 	state->target_residency = 0;
 	state->power_usage = -1;
-	state->flags = CPUIDLE_FLAG_POLL;
+	state->flags = 0;
 	state->enter = poll_idle;
 }
 #else

commit 720f1c3010db6a411358b962a2007969117840bc
Author: Thomas Renninger <trenn@suse.de>
Date:   Fri Jan 7 11:29:43 2011 +0100

    cpuidle: Rename X86 specific idle poll state[0] from C0 to POLL
    
    C0 means and is well know as "not idle".
    All documentation out there uses this term as "running"/"not idle"
    state. Also Linux userspace tools (e.g. cpufreq-aperf and turbostat)
    show C0 residency which there is correct, but means something totally
    else than cpuidle "POLL" state.
    
    Signed-off-by: Thomas Renninger <trenn@suse.de>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 97df791c74cb..37e446041306 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -181,7 +181,7 @@ static void poll_idle_init(struct cpuidle_device *dev)
 
 	cpuidle_set_statedata(state, NULL);
 
-	snprintf(state->name, CPUIDLE_NAME_LEN, "C0");
+	snprintf(state->name, CPUIDLE_NAME_LEN, "POLL");
 	snprintf(state->desc, CPUIDLE_DESC_LEN, "CPUIDLE CORE POLL IDLE");
 	state->exit_latency = 0;
 	state->target_residency = 0;

commit d8c216cfa57e8a579f41729cbb88c97835d9ac8d
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Sat Jan 8 00:29:20 2011 +0100

    cpuidle: Make cpuidle_enable_device() call poll_idle_init()
    
    The following scenario is possible with the current cpuidle code and
    the ACPI cpuidle driver:
    (1) acpi_processor_cst_has_changed() is called,
    (2) cpuidle_disable_device() is called,
    (3) cpuidle_remove_state_sysfs() is called to remove the (presumably
        outdated) states info from sysfs,
    (3) acpi_processor_get_power_info() is called, the first entry in the
        pr->power.states[] table is filled with zeros,
    (4) acpi_processor_setup_cpuidle() is called and it doesn't fill the
        first entry in pr->power.states[],
    (5) cpuidle_enable_device() is called,
    (6) __cpuidle_register_device() is _not_ called, since the device has
        already been registered,
    (7) Consequently, poll_idle_init() is _not_ called either,
    (8) cpuidle_add_state_sysfs() is called to create the sysfs attributes
        for the new states and it uses the bogus first table entry from
        acpi_processor_get_power_info() for creating state0.
    
    This problem is avoided if cpuidle_enable_device()
    unconditionally calls poll_idle_init().
    
    Reported-by: Len Brown <len.brown@intel.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Signed-off-by: Len Brown <len.brown@intel.com>
    cc: stable@kernel.org

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index a50710843378..97df791c74cb 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -154,6 +154,45 @@ void cpuidle_resume_and_unlock(void)
 
 EXPORT_SYMBOL_GPL(cpuidle_resume_and_unlock);
 
+#ifdef CONFIG_ARCH_HAS_CPU_RELAX
+static int poll_idle(struct cpuidle_device *dev, struct cpuidle_state *st)
+{
+	ktime_t	t1, t2;
+	s64 diff;
+	int ret;
+
+	t1 = ktime_get();
+	local_irq_enable();
+	while (!need_resched())
+		cpu_relax();
+
+	t2 = ktime_get();
+	diff = ktime_to_us(ktime_sub(t2, t1));
+	if (diff > INT_MAX)
+		diff = INT_MAX;
+
+	ret = (int) diff;
+	return ret;
+}
+
+static void poll_idle_init(struct cpuidle_device *dev)
+{
+	struct cpuidle_state *state = &dev->states[0];
+
+	cpuidle_set_statedata(state, NULL);
+
+	snprintf(state->name, CPUIDLE_NAME_LEN, "C0");
+	snprintf(state->desc, CPUIDLE_DESC_LEN, "CPUIDLE CORE POLL IDLE");
+	state->exit_latency = 0;
+	state->target_residency = 0;
+	state->power_usage = -1;
+	state->flags = CPUIDLE_FLAG_POLL;
+	state->enter = poll_idle;
+}
+#else
+static void poll_idle_init(struct cpuidle_device *dev) {}
+#endif /* CONFIG_ARCH_HAS_CPU_RELAX */
+
 /**
  * cpuidle_enable_device - enables idle PM for a CPU
  * @dev: the CPU
@@ -178,6 +217,8 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 			return ret;
 	}
 
+	poll_idle_init(dev);
+
 	if ((ret = cpuidle_add_state_sysfs(dev)))
 		return ret;
 
@@ -232,45 +273,6 @@ void cpuidle_disable_device(struct cpuidle_device *dev)
 
 EXPORT_SYMBOL_GPL(cpuidle_disable_device);
 
-#ifdef CONFIG_ARCH_HAS_CPU_RELAX
-static int poll_idle(struct cpuidle_device *dev, struct cpuidle_state *st)
-{
-	ktime_t	t1, t2;
-	s64 diff;
-	int ret;
-
-	t1 = ktime_get();
-	local_irq_enable();
-	while (!need_resched())
-		cpu_relax();
-
-	t2 = ktime_get();
-	diff = ktime_to_us(ktime_sub(t2, t1));
-	if (diff > INT_MAX)
-		diff = INT_MAX;
-
-	ret = (int) diff;
-	return ret;
-}
-
-static void poll_idle_init(struct cpuidle_device *dev)
-{
-	struct cpuidle_state *state = &dev->states[0];
-
-	cpuidle_set_statedata(state, NULL);
-
-	snprintf(state->name, CPUIDLE_NAME_LEN, "C0");
-	snprintf(state->desc, CPUIDLE_DESC_LEN, "CPUIDLE CORE POLL IDLE");
-	state->exit_latency = 0;
-	state->target_residency = 0;
-	state->power_usage = -1;
-	state->flags = CPUIDLE_FLAG_POLL;
-	state->enter = poll_idle;
-}
-#else
-static void poll_idle_init(struct cpuidle_device *dev) {}
-#endif /* CONFIG_ARCH_HAS_CPU_RELAX */
-
 /**
  * __cpuidle_register_device - internal register function called before register
  * and enable routines
@@ -291,8 +293,6 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 
 	init_completion(&dev->kobj_unregister);
 
-	poll_idle_init(dev);
-
 	/*
 	 * cpuidle driver should set the dev->power_specified bit
 	 * before registering the device if the driver provides

commit 72eb6a791459c87a0340318840bb3bd9252b627b
Merge: 23d69b09b78c 55ee4ef30241
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 7 17:02:58 2011 -0800

    Merge branch 'for-2.6.38' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/percpu
    
    * 'for-2.6.38' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/percpu: (30 commits)
      gameport: use this_cpu_read instead of lookup
      x86: udelay: Use this_cpu_read to avoid address calculation
      x86: Use this_cpu_inc_return for nmi counter
      x86: Replace uses of current_cpu_data with this_cpu ops
      x86: Use this_cpu_ops to optimize code
      vmstat: User per cpu atomics to avoid interrupt disable / enable
      irq_work: Use per cpu atomics instead of regular atomics
      cpuops: Use cmpxchg for xchg to avoid lock semantics
      x86: this_cpu_cmpxchg and this_cpu_xchg operations
      percpu: Generic this_cpu_cmpxchg() and this_cpu_xchg support
      percpu,x86: relocate this_cpu_add_return() and friends
      connector: Use this_cpu operations
      xen: Use this_cpu_inc_return
      taskstats: Use this_cpu_ops
      random: Use this_cpu_inc_return
      fs: Use this_cpu_inc_return in buffer.c
      highmem: Use this_cpu_xx_return() operations
      vmstat: Use this_cpu_inc_return for vm statistics
      x86: Support for this_cpu_add, sub, dec, inc_return
      percpu: Generic support for this_cpu_add, sub, dec, inc_return
      ...
    
    Fixed up conflicts: in arch/x86/kernel/{apic/nmi.c, apic/x2apic_uv_x.c, process.c}
    as per Tejun.

commit 25e41933b58777f2d020c3b0186b430ea004ec28
Author: Thomas Renninger <trenn@suse.de>
Date:   Mon Jan 3 17:50:44 2011 +0100

    perf: Clean up power events by introducing new, more generic ones
    
    Add these new power trace events:
    
     power:cpu_idle
     power:cpu_frequency
     power:machine_suspend
    
    The old C-state/idle accounting events:
      power:power_start
      power:power_end
    
    Have now a replacement (but we are still keeping the old
    tracepoints for compatibility):
    
      power:cpu_idle
    
    and
      power:power_frequency
    
    is replaced with:
      power:cpu_frequency
    
    power:machine_suspend is newly introduced.
    
    Jean Pihet has a patch integrated into the generic layer
    (kernel/power/suspend.c) which will make use of it.
    
    the type= field got removed from both, it was never
    used and the type is differed by the event type itself.
    
    perf timechart userspace tool gets adjusted in a separate patch.
    
    Signed-off-by: Thomas Renninger <trenn@suse.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Arjan van de Ven <arjan@linux.intel.com>
    Acked-by: Jean Pihet <jean.pihet@newoldbits.com>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: rjw@sisk.pl
    LKML-Reference: <1294073445-14812-3-git-send-email-trenn@suse.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    LKML-Reference: <1290072314-31155-2-git-send-email-trenn@suse.de>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index a50710843378..08d5f05378d9 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -107,6 +107,7 @@ static void cpuidle_idle_call(void)
 	if (cpuidle_curr_governor->reflect)
 		cpuidle_curr_governor->reflect(dev);
 	trace_power_end(smp_processor_id());
+	trace_cpu_idle(PWR_EVENT_EXIT, smp_processor_id());
 }
 
 /**

commit 4a6f4fe8377720e5a279fdbb769946c242e936d3
Author: Christoph Lameter <cl@linux.com>
Date:   Mon Dec 6 11:16:24 2010 -0600

    drivers: Replace __get_cpu_var with __this_cpu_read if not used for an address.
    
    __get_cpu_var() can be replaced with this_cpu_read and will then use a single
    read instruction with implied address calculation to access the correct per cpu
    instance.
    
    However, the address of a per cpu variable passed to __this_cpu_read() cannot be
    determed (since its an implied address conversion through segment prefixes).
    Therefore apply this only to uses of __get_cpu_var where the addres of the
    variable is not used.
    
    V3->V4:
            - Move one instance of this_cpu_inc_return to a later patch
              so that this one can go in without percpu infrastructrure
              changes.
    
    Sedat: fixed compile failure caused by an extra ')'.
    
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Sedat Dilek <sedat.dilek@gmail.com>
    Acked-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Christoph Lameter <cl@linux.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index a50710843378..978ff292a3fa 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -49,7 +49,7 @@ static int __cpuidle_register_device(struct cpuidle_device *dev);
  */
 static void cpuidle_idle_call(void)
 {
-	struct cpuidle_device *dev = __get_cpu_var(cpuidle_devices);
+	struct cpuidle_device *dev = __this_cpu_read(cpuidle_devices);
 	struct cpuidle_state *target_state;
 	int next_state;
 

commit 71abbbf856a0e70ca478782505c800891260ba84
Author: Ai Li <aili@codeaurora.org>
Date:   Mon Aug 9 17:20:13 2010 -0700

    cpuidle: extend cpuidle and menu governor to handle dynamic states
    
    On some SoC chips, HW resources may be in use during any particular idle
    period.  As a consequence, the cpuidle states that the SoC is safe to
    enter can change from idle period to idle period.  In addition, the
    latency and threshold of each cpuidle state can vary, depending on the
    operating condition when the CPU becomes idle, e.g.  the current cpu
    frequency, the current state of the HW blocks, etc.
    
    cpuidle core and the menu governor, in the current form, are geared
    towards cpuidle states that are static, i.e.  the availabiltiy of the
    states, their latencies, their thresholds are non-changing during run
    time.  cpuidle does not provide any hook that cpuidle drivers can use to
    adjust those values on the fly for the current idle period before the menu
    governor selects the target cpuidle state.
    
    This patch extends cpuidle core and the menu governor to handle states
    that are dynamic.  There are three additions in the patch and the patch
    maintains backwards-compatibility with existing cpuidle drivers.
    
    1) add prepare() to struct cpuidle_device.  A cpuidle driver can hook
       into the callback and cpuidle will call prepare() before calling the
       governor's select function.  The callback gives the cpuidle driver a
       chance to update the dynamic information of the cpuidle states for the
       current idle period, e.g.  state availability, latencies, thresholds,
       power values, etc.
    
    2) add CPUIDLE_FLAG_IGNORE as one of the state flags.  In the prepare()
       function, a cpuidle driver can set/clear the flag to indicate to the
       menu governor whether a cpuidle state should be ignored, i.e.  not
       available, during the current idle period.
    
    3) add power_specified bit to struct cpuidle_device.  The menu governor
       currently assumes that the cpuidle states are arranged in the order of
       increasing latency, threshold, and power savings.  This is true or can
       be made true for static states.  Once the state parameters are dynamic,
       the latencies, thresholds, and power savings for the cpuidle states can
       increase or decrease by different amounts from idle period to idle
       period.  So the assumption of increasing latency, threshold, and power
       savings from Cn to C(n+1) can no longer be guaranteed.
    
    It can be straightforward to calculate the power consumption of each
    available state and to specify it in power_usage for the idle period.
    Using the power_usage fields, the menu governor then selects the state
    that has the lowest power consumption and that still satisfies all other
    critieria.  The power_specified bit defaults to 0.  For existing cpuidle
    drivers, cpuidle detects that power_specified is 0 and fills in a dummy
    set of power_usage values.
    
    Signed-off-by: Ai Li <aili@codeaurora.org>
    Cc: Len Brown <len.brown@intel.com>
    Acked-by: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Venkatesh Pallipadi <venki@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index dbefe15bd582..a50710843378 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -74,6 +74,17 @@ static void cpuidle_idle_call(void)
 	 */
 	hrtimer_peek_ahead_timers();
 #endif
+
+	/*
+	 * Call the device's prepare function before calling the
+	 * governor's select function.  ->prepare gives the device's
+	 * cpuidle driver a chance to update any dynamic information
+	 * of its cpuidle states for the current idle period, e.g.
+	 * state availability, latencies, residencies, etc.
+	 */
+	if (dev->prepare)
+		dev->prepare(dev);
+
 	/* ask the governor for the next state */
 	next_state = cpuidle_curr_governor->select(dev);
 	if (need_resched()) {
@@ -282,6 +293,26 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 
 	poll_idle_init(dev);
 
+	/*
+	 * cpuidle driver should set the dev->power_specified bit
+	 * before registering the device if the driver provides
+	 * power_usage numbers.
+	 *
+	 * For those devices whose ->power_specified is not set,
+	 * we fill in power_usage with decreasing values as the
+	 * cpuidle code has an implicit assumption that state Cn
+	 * uses less power than C(n-1).
+	 *
+	 * With CONFIG_ARCH_HAS_CPU_RELAX, C0 is already assigned
+	 * an power value of -1.  So we use -2, -3, etc, for other
+	 * c-states.
+	 */
+	if (!dev->power_specified) {
+		int i;
+		for (i = CPUIDLE_DRIVER_STATE_START; i < dev->state_count; i++)
+			dev->states[i].power_usage = -1 - i;
+	}
+
 	per_cpu(cpuidle_devices, dev->cpu) = dev;
 	list_add(&dev->device_list, &cpuidle_detected_devices);
 	if ((ret = cpuidle_add_sysfs(sys_dev))) {

commit 6f4f2723d08534fd4e407e1ef8500b0f4d12c30c
Author: Thomas Renninger <trenn@suse.de>
Date:   Tue Apr 20 13:17:36 2010 +0200

    [CPUFREQ] x86 cpufreq: Make trace_power_frequency cpufreq driver independent
    
    and fix the broken case if a core's frequency depends on others.
    
    trace_power_frequency was only implemented in a rather ungeneric way
    in acpi-cpufreq driver's target() function only.
    -> Move the call to trace_power_frequency to
       cpufreq.c:cpufreq_notify_transition() where CPUFREQ_POSTCHANGE
       notifier is triggered.
       This will support power frequency tracing by all cpufreq drivers
    
    trace_power_frequency did not trace frequency changes correctly when
    the userspace governor was used or when CPU cores' frequency depend
    on each other.
    -> Moving this into the CPUFREQ_POSTCHANGE notifier and pass the cpu
       which gets switched automatically fixes this.
    
    Robert Schoene provided some important fixes on top of my initial
    quick shot version which are integrated in this patch:
    - Forgot some changes in power_end trace (TP_printk/variable names)
    - Variable dummy in power_end must now be cpu_id
    - Use static 64 bit variable instead of unsigned int for cpu_id
    
    Signed-off-by: Thomas Renninger <trenn@suse.de>
    CC: davej@redhat.com
    CC: arjan@infradead.org
    CC: linux-kernel@vger.kernel.org
    CC: robert.schoene@tu-dresden.de
    Tested-by: robert.schoene@tu-dresden.de
    Signed-off-by: Dave Jones <davej@redhat.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 199488576a05..dbefe15bd582 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -95,7 +95,7 @@ static void cpuidle_idle_call(void)
 	/* give the governor an opportunity to reflect on the outcome */
 	if (cpuidle_curr_governor->reflect)
 		cpuidle_curr_governor->reflect(dev);
-	trace_power_end(0);
+	trace_power_end(smp_processor_id());
 }
 
 /**

commit 752138df0dc2daaae09379c754caeb08c97905dc
Author: Len Brown <len.brown@intel.com>
Date:   Sat May 22 16:57:26 2010 -0400

    cpuidle: make cpuidle_curr_driver static
    
    cpuidle_register_driver() sets cpuidle_curr_driver
    cpuidle_unregister_driver() clears cpuidle_curr_driver
    
    We should't expose cpuidle_curr_driver to
    potential modification except via these interfaces.
    So make it static and create cpuidle_get_driver() to observe it.
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 12fdd3987a36..199488576a05 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -156,7 +156,7 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 
 	if (dev->enabled)
 		return 0;
-	if (!cpuidle_curr_driver || !cpuidle_curr_governor)
+	if (!cpuidle_get_driver() || !cpuidle_curr_governor)
 		return -EIO;
 	if (!dev->state_count)
 		return -EINVAL;
@@ -207,7 +207,7 @@ void cpuidle_disable_device(struct cpuidle_device *dev)
 {
 	if (!dev->enabled)
 		return;
-	if (!cpuidle_curr_driver || !cpuidle_curr_governor)
+	if (!cpuidle_get_driver() || !cpuidle_curr_governor)
 		return;
 
 	dev->enabled = 0;
@@ -271,10 +271,11 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 {
 	int ret;
 	struct sys_device *sys_dev = get_cpu_sysdev((unsigned long)dev->cpu);
+	struct cpuidle_driver *cpuidle_driver = cpuidle_get_driver();
 
 	if (!sys_dev)
 		return -EINVAL;
-	if (!try_module_get(cpuidle_curr_driver->owner))
+	if (!try_module_get(cpuidle_driver->owner))
 		return -EINVAL;
 
 	init_completion(&dev->kobj_unregister);
@@ -284,7 +285,7 @@ static int __cpuidle_register_device(struct cpuidle_device *dev)
 	per_cpu(cpuidle_devices, dev->cpu) = dev;
 	list_add(&dev->device_list, &cpuidle_detected_devices);
 	if ((ret = cpuidle_add_sysfs(sys_dev))) {
-		module_put(cpuidle_curr_driver->owner);
+		module_put(cpuidle_driver->owner);
 		return ret;
 	}
 
@@ -325,6 +326,7 @@ EXPORT_SYMBOL_GPL(cpuidle_register_device);
 void cpuidle_unregister_device(struct cpuidle_device *dev)
 {
 	struct sys_device *sys_dev = get_cpu_sysdev((unsigned long)dev->cpu);
+	struct cpuidle_driver *cpuidle_driver = cpuidle_get_driver();
 
 	if (dev->registered == 0)
 		return;
@@ -340,7 +342,7 @@ void cpuidle_unregister_device(struct cpuidle_device *dev)
 
 	cpuidle_resume_and_unlock();
 
-	module_put(cpuidle_curr_driver->owner);
+	module_put(cpuidle_driver->owner);
 }
 
 EXPORT_SYMBOL_GPL(cpuidle_unregister_device);

commit 246eb7f0ed1a8aeddec5313137767658f378949b
Author: Kevin Hilman <khilman@deeprootsystems.com>
Date:   Mon Oct 26 16:50:18 2009 -0700

    cpuidle: always return with interrupts enabled
    
    In the case where cpuidle_idle_call() returns before changing state due to
    a need_resched(), it was returning with IRQs disabled.
    
    The idle path assumes that the platform specific idle code returns with
    interrupts enabled (although this too is undocumented AFAICT) and on ARM
    we have a WARN_ON(!(irqs_disabled()) when returning from the idle loop, so
    the user-visible effects were only a warning since interrupts were
    eventually re-enabled later.
    
    On x86, this same problem exists, but there is no WARN_ON() to detect it.
    As on ARM, the interrupts are eventually re-enabled, so I'm not sure of
    any actual bugs triggered by this.  It's primarily a
    correctness/consistency fix.
    
    This patch ensures IRQs are (re)enabled before returning.
    
    Reported-by: Hemanth V <hemanthv@ti.com>
    Signed-off-by: Kevin Hilman <khilman@deeprootsystems.com>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Len Brown <len.brown@intel.com>
    Cc: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: "Rafael J. Wysocki" <rjw@sisk.pl>
    Tested-by: Martin Michlmayr <tbm@cyrius.com>
    Cc: <stable@kernel.org>         [2.6.31.x]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index ad41f19b8e3f..12fdd3987a36 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -76,8 +76,11 @@ static void cpuidle_idle_call(void)
 #endif
 	/* ask the governor for the next state */
 	next_state = cpuidle_curr_governor->select(dev);
-	if (need_resched())
+	if (need_resched()) {
+		local_irq_enable();
 		return;
+	}
+
 	target_state = &dev->states[next_state];
 
 	/* enter the state and update stats */

commit 288f023e708efd89d77ce9acf977a33a623ae83d
Author: Arjan van de Ven <arjan@infradead.org>
Date:   Sat Sep 19 13:35:33 2009 +0200

    tracing, x86, cpuidle: Move the end point of a C state in the power tracer
    
    The "end of a C state" trace point currently happens before
    the code runs that corrects the TSC for having stopped during idle.
    
    The result of this is that the timestamp of the end-of-C-state event
    is garbage on cpus where the TSC stops during idle.
    
    This patch moves the end point of the C state to after the timekeeping
    engine of the kernel has been corrected.
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Len Brown <len.brown@intel.com>
    Cc: fweisbec@gmail.com
    Cc: peterz@infradead.org
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <20090919133533.139c2a46@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 8504a2108557..ad41f19b8e3f 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -17,6 +17,7 @@
 #include <linux/cpuidle.h>
 #include <linux/ktime.h>
 #include <linux/hrtimer.h>
+#include <trace/events/power.h>
 
 #include "cpuidle.h"
 
@@ -91,6 +92,7 @@ static void cpuidle_idle_call(void)
 	/* give the governor an opportunity to reflect on the outcome */
 	if (cpuidle_curr_governor->reflect)
 		cpuidle_curr_governor->reflect(dev);
+	trace_power_end(0);
 }
 
 /**

commit 9a6558371bcd01c2973b7638181db4ccc34eab4f
Author: Arjan van de Ven <arjan@linux.intel.com>
Date:   Sun Nov 9 12:45:10 2008 -0800

    regression: disable timer peek-ahead for 2.6.28
    
    It's showing up as regressions; disabling it very likely just papers
    over an underlying issue, but time is running out for 2.6.28, lets get
    back to this for 2.6.29
    
    Fixes: #11826 and #11893
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 5bed73329ef8..8504a2108557 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -65,12 +65,14 @@ static void cpuidle_idle_call(void)
 		return;
 	}
 
+#if 0
+	/* shows regressions, re-enable for 2.6.29 */
 	/*
 	 * run any timers that can be run now, at this point
 	 * before calculating the idle duration etc.
 	 */
 	hrtimer_peek_ahead_timers();
-
+#endif
 	/* ask the governor for the next state */
 	next_state = cpuidle_curr_governor->select(dev);
 	if (need_resched())

commit 1f6d6e8ebe73ba9d9d4c693f7f6f50f661dbd6e4
Merge: db563fc2e805 268a3dcfea20
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 23 10:53:02 2008 -0700

    Merge branch 'v28-range-hrtimers-for-linus-v2' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'v28-range-hrtimers-for-linus-v2' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (37 commits)
      hrtimers: add missing docbook comments to struct hrtimer
      hrtimers: simplify hrtimer_peek_ahead_timers()
      hrtimers: fix docbook comments
      DECLARE_PER_CPU needs linux/percpu.h
      hrtimers: fix typo
      rangetimers: fix the bug reported by Ingo for real
      rangetimer: fix BUG_ON reported by Ingo
      rangetimer: fix x86 build failure for the !HRTIMERS case
      select: fix alpha OSF wrapper
      select: fix alpha OSF wrapper
      hrtimer: peek at the timer queue just before going idle
      hrtimer: make the futex() system call use the per process slack value
      hrtimer: make the nanosleep() syscall use the per process slack
      hrtimer: fix signed/unsigned bug in slack estimator
      hrtimer: show the timer ranges in /proc/timer_list
      hrtimer: incorporate feedback from Peter Zijlstra
      hrtimer: add a hrtimer_start_range() function
      hrtimer: another build fix
      hrtimer: fix build bug found by Ingo
      hrtimer: make select() and poll() use the hrtimer range feature
      ...

commit 89cedfefca1d446ee2598fd3bcbb23ee3802e26a
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Thu Oct 16 19:00:08 2008 -0400

    cpuidle: upon BIOS bug, default to default_idle rather than polling
    
    http://bugzilla.kernel.org/show_bug.cgi?id=11345
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index eb2cade562db..bb6e3b338043 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -56,7 +56,11 @@ static void cpuidle_idle_call(void)
 		if (pm_idle_old)
 			pm_idle_old();
 		else
+#if defined(CONFIG_ARCH_HAS_DEFAULT_IDLE)
+			default_idle();
+#else
 			local_irq_enable();
+#endif
 		return;
 	}
 

commit 887e301aa1105326f1412a98749024263b1031c7
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon Sep 29 15:24:27 2008 -0700

    cpuidle: use last_state which can reflect the actual state entered
    
    cpuidle accounts the idle time for the C-state it was trying to enter and
    not to the actual state that the driver eventually entered. The driver may
    select a different state than the one chosen by cpuidle due to
    constraints like bus-mastering, etc.
    
    Change the time acounting code to look at the dev->last_state after
    returning from target_state->enter(). Driver can modify dev->last_state
    internally, inside the enter routine to reflect the actual C-state
    entered.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Tested-by: Kevin Hilman <khilman@deeprootsystems.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 5ce07b517c58..eb2cade562db 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -67,8 +67,11 @@ static void cpuidle_idle_call(void)
 	target_state = &dev->states[next_state];
 
 	/* enter the state and update stats */
-	dev->last_residency = target_state->enter(dev, target_state);
 	dev->last_state = target_state;
+	dev->last_residency = target_state->enter(dev, target_state);
+	if (dev->last_state)
+		target_state = dev->last_state;
+
 	target_state->time += (unsigned long long)dev->last_residency;
 	target_state->usage++;
 

commit 2e94d1f71f7e4404d997e6fb4f1618aa147d76f9
Author: Arjan van de Ven <arjan@linux.intel.com>
Date:   Wed Sep 10 16:06:00 2008 -0700

    hrtimer: peek at the timer queue just before going idle
    
    As part of going idle, we already look at the time of the next timer event to determine
    which C-state to select etc.
    
    This patch adds functionality that causes the timers that are past their
    soft expire time, to fire at this time, before we calculate the next wakeup
    time. This functionality will thus avoid wakeups by running timers before
    going idle rather than specially waking up for it.
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 5ce07b517c58..2e3148499368 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -16,6 +16,7 @@
 #include <linux/cpu.h>
 #include <linux/cpuidle.h>
 #include <linux/ktime.h>
+#include <linux/hrtimer.h>
 
 #include "cpuidle.h"
 
@@ -60,6 +61,12 @@ static void cpuidle_idle_call(void)
 		return;
 	}
 
+	/*
+	 * run any timers that can be run now, at this point
+	 * before calculating the idle duration etc.
+	 */
+	hrtimer_peek_ahead_timers();
+
 	/* ask the governor for the next state */
 	next_state = cpuidle_curr_governor->select(dev);
 	if (need_resched())

commit b032bf70df2e43149ce2b4e9a865b076c6140753
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Jul 27 23:47:12 2008 +0200

    ACPI/CPUIDLE: prevent setting pm_idle to NULL
    
    pm_idle_save resp. pm_idle_old can be NULL when the restore code in
    acpi_processor_cst_has_changed() resp. cpuidle_uninstall_idle_handler()
    is called. This can set pm_idle unconditinally to NULL, which causes the
    kernel to panic when calling pm_idle in the x86 idle code. This was
    covered by an extra check for !pm_idle in the x86 idle code, which was
    removed during the x86 idle code refactoring.
    
    Instead of restoring the pm_idle check in the x86 code prevent the
    acpi/cpuidle code to set pm_idle to NULL.
    
    Reported by: Dhaval Giani http://lkml.org/lkml/2008/7/2/309
    Based on a debug patch from Ingo Molnar
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 5405769020a1..5ce07b517c58 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -94,7 +94,7 @@ void cpuidle_install_idle_handler(void)
  */
 void cpuidle_uninstall_idle_handler(void)
 {
-	if (enabled_devices && (pm_idle != pm_idle_old)) {
+	if (enabled_devices && pm_idle_old && (pm_idle != pm_idle_old)) {
 		pm_idle = pm_idle_old;
 		cpuidle_kick_cpus();
 	}

commit 8691e5a8f691cc2a4fda0651e8d307aaba0e7d68
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Fri Jun 6 11:18:06 2008 +0200

    smp_call_function: get rid of the unused nonatomic/retry argument
    
    It's never used and the comments refer to nonatomic and retry
    interchangably. So get rid of it.
    
    Acked-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 23554b676d6e..5405769020a1 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -340,7 +340,7 @@ static void smp_callback(void *v)
 static int cpuidle_latency_notify(struct notifier_block *b,
 		unsigned long l, void *v)
 {
-	smp_call_function(smp_callback, NULL, 0, 1);
+	smp_call_function(smp_callback, NULL, 1);
 	return NOTIFY_OK;
 }
 

commit dcb84f335bee9c9a7781cfc5d74492dccaf066d2
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon May 19 19:09:27 2008 -0400

    cpuidle acpi driver: fix oops on AC<->DC
    
    cpuidle and acpi driver interaction bug with the way cpuidle_register_driver()
    is called. Due to this bug, there will be oops on
    AC<->DC on some systems, where they support C-states in one DC and not in AC.
    
    The current code does
    ON BOOT:
            Look at CST and other C-state info to see whether more than C1 is
            supported. If it is, then acpi processor_idle does a
            cpuidle_register_driver() call, which internally enables the device.
    
    ON CST change notification (AC<->DC) and on suspend-resume:
            acpi driver temporarily disables device, updates the device with
            any new C-states, and reenables the device.
    
    The problem is is on boot, there are no C2, C3 states supported and we skip
    the register. Later on AC<->DC, we may get a CST notification and we try
    to reevaluate CST and enabled the device, without actually registering it.
    This causes breakage as we try to create /sys fs sub directory, without the
    parent directory which is created at register time.
    
    Thanks to Sanjeev for reporting the problem here.
    http://bugzilla.kernel.org/show_bug.cgi?id=10394
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index fc555a90bb21..23554b676d6e 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -38,6 +38,8 @@ static void cpuidle_kick_cpus(void)
 static void cpuidle_kick_cpus(void) {}
 #endif
 
+static int __cpuidle_register_device(struct cpuidle_device *dev);
+
 /**
  * cpuidle_idle_call - the main idle loop
  *
@@ -138,6 +140,12 @@ int cpuidle_enable_device(struct cpuidle_device *dev)
 	if (!dev->state_count)
 		return -EINVAL;
 
+	if (dev->registered == 0) {
+		ret = __cpuidle_register_device(dev);
+		if (ret)
+			return ret;
+	}
+
 	if ((ret = cpuidle_add_state_sysfs(dev)))
 		return ret;
 
@@ -232,10 +240,13 @@ static void poll_idle_init(struct cpuidle_device *dev) {}
 #endif /* CONFIG_ARCH_HAS_CPU_RELAX */
 
 /**
- * cpuidle_register_device - registers a CPU's idle PM feature
+ * __cpuidle_register_device - internal register function called before register
+ * and enable routines
  * @dev: the cpu
+ *
+ * cpuidle_lock mutex must be held before this is called
  */
-int cpuidle_register_device(struct cpuidle_device *dev)
+static int __cpuidle_register_device(struct cpuidle_device *dev)
 {
 	int ret;
 	struct sys_device *sys_dev = get_cpu_sysdev((unsigned long)dev->cpu);
@@ -247,18 +258,34 @@ int cpuidle_register_device(struct cpuidle_device *dev)
 
 	init_completion(&dev->kobj_unregister);
 
-	mutex_lock(&cpuidle_lock);
-
 	poll_idle_init(dev);
 
 	per_cpu(cpuidle_devices, dev->cpu) = dev;
 	list_add(&dev->device_list, &cpuidle_detected_devices);
 	if ((ret = cpuidle_add_sysfs(sys_dev))) {
-		mutex_unlock(&cpuidle_lock);
 		module_put(cpuidle_curr_driver->owner);
 		return ret;
 	}
 
+	dev->registered = 1;
+	return 0;
+}
+
+/**
+ * cpuidle_register_device - registers a CPU's idle PM feature
+ * @dev: the cpu
+ */
+int cpuidle_register_device(struct cpuidle_device *dev)
+{
+	int ret;
+
+	mutex_lock(&cpuidle_lock);
+
+	if ((ret = __cpuidle_register_device(dev))) {
+		mutex_unlock(&cpuidle_lock);
+		return ret;
+	}
+
 	cpuidle_enable_device(dev);
 	cpuidle_install_idle_handler();
 
@@ -278,6 +305,9 @@ void cpuidle_unregister_device(struct cpuidle_device *dev)
 {
 	struct sys_device *sys_dev = get_cpu_sysdev((unsigned long)dev->cpu);
 
+	if (dev->registered == 0)
+		return;
+
 	cpuidle_pause_and_lock();
 
 	cpuidle_disable_device(dev);

commit 8e92b6605da989c0aa8ff7e33306f36f0efd957c
Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Fri Feb 29 10:24:32 2008 -0800

    cpuidle: fix 100% C0 statistics regression
    
    commit 9b12e18cdc1553de62d931e73443c806347cd974
    'ACPI: cpuidle: Support C1 idle time accounting'
    was implicated in a 100% C0 idle regression.
    http://bugzilla.kernel.org/show_bug.cgi?id=10076
    
    It pointed out a potential problem where the menu governor
    may get confused by the C-state residency time from poll
    idle or C1 idle, where this timing info is not accurate.
    This inaccuracy is due to interrupts being handled
    before we account for C-state exit.
    
    Do not mark TIME_VALID for CO poll state.
    Mark C1 time as valid only with the MWAIT (CSTATE_FFH) entry method.
    
    This makes governors use the timing information only when it is correct and
    eliminates any wrong policy decisions that may result from invalid timing
    information.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index d42deb310ac7..fc555a90bb21 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -224,7 +224,7 @@ static void poll_idle_init(struct cpuidle_device *dev)
 	state->exit_latency = 0;
 	state->target_residency = 0;
 	state->power_usage = -1;
-	state->flags = CPUIDLE_FLAG_POLL | CPUIDLE_FLAG_TIME_VALID;
+	state->flags = CPUIDLE_FLAG_POLL;
 	state->enter = poll_idle;
 }
 #else

commit 8b78cf602fd3bd97c0080edd22fe8fd5d0fa7832
Author: Yi Yang <yi.y.yang@intel.com>
Date:   Mon Feb 25 08:46:12 2008 +0800

    cpuidle: fix cpuidle time and usage overflow
    
    cpuidle C-state sysfs node time and usage are very easy to overflow because
    they are all of unsigned int type, time will overflow within about two hours,
    usage will take longer time to overflow, but they are increasing for ever.
    
    This patch will convert them to unsigned long long.
    
    Signed-off-by: Yi Yang <yi.y.yang@intel.com>
    Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index d73663a52324..d42deb310ac7 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -67,7 +67,7 @@ static void cpuidle_idle_call(void)
 	/* enter the state and update stats */
 	dev->last_residency = target_state->enter(dev, target_state);
 	dev->last_state = target_state;
-	target_state->time += dev->last_residency;
+	target_state->time += (unsigned long long)dev->last_residency;
 	target_state->usage++;
 
 	/* give the governor an opportunity to reflect on the outcome */

commit 4fcb2fcd4d0678b8ae103d257dcb28074cbfc7fa
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon Feb 11 17:46:31 2008 -0800

    ACPI, cpuidle: Clarify C-state description in sysfs
    
    Add a new sysfs entry under cpuidle states. desc - can be used by driver to
    communicate to userspace any specific information about the state.
    This helps in identifying the exact hardware C-states behind the ACPI C-state
    definition.
    
    Idea is to export this through powertop, which will help to map the C-state
    reported by powertop to actual hardware C-state.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 60f71e6345e3..d73663a52324 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -219,7 +219,8 @@ static void poll_idle_init(struct cpuidle_device *dev)
 
 	cpuidle_set_statedata(state, NULL);
 
-	snprintf(state->name, CPUIDLE_NAME_LEN, "C0 (poll idle)");
+	snprintf(state->name, CPUIDLE_NAME_LEN, "C0");
+	snprintf(state->desc, CPUIDLE_DESC_LEN, "CPUIDLE CORE POLL IDLE");
 	state->exit_latency = 0;
 	state->target_residency = 0;
 	state->power_usage = -1;

commit a6869cc4cfd633d909918f1489a6a8ac668cd6aa
Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Fri Feb 8 17:05:44 2008 -0800

    cpuidle: build fix for non-x86
    
    The last posted version of this patch gave compile error
    on IA64. So, here goes yet another rewrite of the patch.
    
    Convert cpu_idle_wait() to cpuidle_kick_cpus() which is
    SMP-only, and gives error on non supported CPU.
    
    Changes from last patch sent by Kevin:
    Moved the definition of kick_cpus back to cpuidle.c from cpuidle.h:
    * Having it in .h gives #error on archs which includes the header file without
      actually having CPU_IDLE configured. To make it work in .h, we need one more
      #ifdef around that code which makes it messy.
    * Also, the function is only called from one file. So, it can be in declared
      statically in .c rather than making it available to everyone who includes
      the .h file.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Kevin Hilman <khilman@mvista.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 2c4b2d47973e..60f71e6345e3 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -27,6 +27,17 @@ static void (*pm_idle_old)(void);
 
 static int enabled_devices;
 
+#if defined(CONFIG_ARCH_HAS_CPU_IDLE_WAIT)
+static void cpuidle_kick_cpus(void)
+{
+	cpu_idle_wait();
+}
+#elif defined(CONFIG_SMP)
+# error "Arch needs cpu_idle_wait() equivalent here"
+#else /* !CONFIG_ARCH_HAS_CPU_IDLE_WAIT && !CONFIG_SMP */
+static void cpuidle_kick_cpus(void) {}
+#endif
+
 /**
  * cpuidle_idle_call - the main idle loop
  *
@@ -83,7 +94,7 @@ void cpuidle_uninstall_idle_handler(void)
 {
 	if (enabled_devices && (pm_idle != pm_idle_old)) {
 		pm_idle = pm_idle_old;
-		cpu_idle_wait();
+		cpuidle_kick_cpus();
 	}
 }
 

commit 9b7131542178f5f948e4bb6bea6e1c545e697b06
Author: Len Brown <len.brown@intel.com>
Date:   Thu Feb 7 04:16:34 2008 -0500

    Revert "cpuidle: build fix for non-x86"
    
    This reverts commit f757397097d0713c949af76dccabb65a2785782e.
    which ironically broke the ia64 build

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index d868d737742f..2c4b2d47973e 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -83,7 +83,7 @@ void cpuidle_uninstall_idle_handler(void)
 {
 	if (enabled_devices && (pm_idle != pm_idle_old)) {
 		pm_idle = pm_idle_old;
-		cpuidle_kick_cpus();
+		cpu_idle_wait();
 	}
 }
 

commit acf63867ae06ef95eea7bf445ded2f05528a81b1
Merge: c64768a7d671 f757397097d0 9a0b841586c3
Author: Len Brown <len.brown@intel.com>
Date:   Thu Feb 7 03:11:05 2008 -0500

    Merge branches 'release', 'cpuidle-2.6.25' and 'idle' into release

commit 9a0b841586c3c6c846effdbe75885c2ebc0031b0
Author: venkatesh.pallipadi@intel.com <venkatesh.pallipadi@intel.com>
Date:   Thu Jan 31 17:35:06 2008 -0800

    cpuidle: Add a poll_idle method
    
    Add a default poll idle state with 0 latency. Provides an option to users
    to use poll_idle by using 0 as the latency requirement.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index 2a98d99cbd46..2c4b2d47973e 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -15,6 +15,7 @@
 #include <linux/pm_qos_params.h>
 #include <linux/cpu.h>
 #include <linux/cpuidle.h>
+#include <linux/ktime.h>
 
 #include "cpuidle.h"
 
@@ -180,6 +181,44 @@ void cpuidle_disable_device(struct cpuidle_device *dev)
 
 EXPORT_SYMBOL_GPL(cpuidle_disable_device);
 
+#ifdef CONFIG_ARCH_HAS_CPU_RELAX
+static int poll_idle(struct cpuidle_device *dev, struct cpuidle_state *st)
+{
+	ktime_t	t1, t2;
+	s64 diff;
+	int ret;
+
+	t1 = ktime_get();
+	local_irq_enable();
+	while (!need_resched())
+		cpu_relax();
+
+	t2 = ktime_get();
+	diff = ktime_to_us(ktime_sub(t2, t1));
+	if (diff > INT_MAX)
+		diff = INT_MAX;
+
+	ret = (int) diff;
+	return ret;
+}
+
+static void poll_idle_init(struct cpuidle_device *dev)
+{
+	struct cpuidle_state *state = &dev->states[0];
+
+	cpuidle_set_statedata(state, NULL);
+
+	snprintf(state->name, CPUIDLE_NAME_LEN, "C0 (poll idle)");
+	state->exit_latency = 0;
+	state->target_residency = 0;
+	state->power_usage = -1;
+	state->flags = CPUIDLE_FLAG_POLL | CPUIDLE_FLAG_TIME_VALID;
+	state->enter = poll_idle;
+}
+#else
+static void poll_idle_init(struct cpuidle_device *dev) {}
+#endif /* CONFIG_ARCH_HAS_CPU_RELAX */
+
 /**
  * cpuidle_register_device - registers a CPU's idle PM feature
  * @dev: the cpu
@@ -198,6 +237,8 @@ int cpuidle_register_device(struct cpuidle_device *dev)
 
 	mutex_lock(&cpuidle_lock);
 
+	poll_idle_init(dev);
+
 	per_cpu(cpuidle_devices, dev->cpu) = dev;
 	list_add(&dev->device_list, &cpuidle_detected_devices);
 	if ((ret = cpuidle_add_sysfs(sys_dev))) {

commit d82b35186eaa816267f044bd70cc0acb3c7971a3
Author: Mark Gross <mgross@linux.intel.com>
Date:   Mon Feb 4 22:30:08 2008 -0800

    pm qos infrastructure and interface
    
    The following patch is a generalization of the latency.c implementation done
    by Arjan last year.  It provides infrastructure for more than one parameter,
    and exposes a user mode interface for processes to register pm_qos
    expectations of processes.
    
    This interface provides a kernel and user mode interface for registering
    performance expectations by drivers, subsystems and user space applications on
    one of the parameters.
    
    Currently we have {cpu_dma_latency, network_latency, network_throughput} as
    the initial set of pm_qos parameters.
    
    The infrastructure exposes multiple misc device nodes one per implemented
    parameter.  The set of parameters implement is defined by pm_qos_power_init()
    and pm_qos_params.h.  This is done because having the available parameters
    being runtime configurable or changeable from a driver was seen as too easy to
    abuse.
    
    For each parameter a list of performance requirements is maintained along with
    an aggregated target value.  The aggregated target value is updated with
    changes to the requirement list or elements of the list.  Typically the
    aggregated target value is simply the max or min of the requirement values
    held in the parameter list elements.
    
    >From kernel mode the use of this interface is simple:
    
    pm_qos_add_requirement(param_id, name, target_value):
    
      Will insert a named element in the list for that identified PM_QOS
      parameter with the target value.  Upon change to this list the new target is
      recomputed and any registered notifiers are called only if the target value
      is now different.
    
    pm_qos_update_requirement(param_id, name, new_target_value):
    
      Will search the list identified by the param_id for the named list element
      and then update its target value, calling the notification tree if the
      aggregated target is changed.  with that name is already registered.
    
    pm_qos_remove_requirement(param_id, name):
    
      Will search the identified list for the named element and remove it, after
      removal it will update the aggregate target and call the notification tree
      if the target was changed as a result of removing the named requirement.
    
    >From user mode:
    
      Only processes can register a pm_qos requirement.  To provide for
      automatic cleanup for process the interface requires the process to register
      its parameter requirements in the following way:
    
      To register the default pm_qos target for the specific parameter, the
      process must open one of /dev/[cpu_dma_latency, network_latency,
      network_throughput]
    
      As long as the device node is held open that process has a registered
      requirement on the parameter.  The name of the requirement is
      "process_<PID>" derived from the current->pid from within the open system
      call.
    
      To change the requested target value the process needs to write a s32
      value to the open device node.  This translates to a
      pm_qos_update_requirement call.
    
      To remove the user mode request for a target value simply close the device
      node.
    
    [akpm@linux-foundation.org: fix warnings]
    [akpm@linux-foundation.org: fix build]
    [akpm@linux-foundation.org: fix build again]
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: mark gross <mgross@linux.intel.com>
    Cc: "John W. Linville" <linville@tuxdriver.com>
    Cc: Len Brown <lenb@kernel.org>
    Cc: Jaroslav Kysela <perex@suse.cz>
    Cc: Takashi Iwai <tiwai@suse.de>
    Cc: Arjan van de Ven <arjan@infradead.org>
    Cc: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Cc: Adam Belay <abelay@novell.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index d2fabe7863a9..2a98d99cbd46 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -12,7 +12,7 @@
 #include <linux/mutex.h>
 #include <linux/sched.h>
 #include <linux/notifier.h>
-#include <linux/latency.h>
+#include <linux/pm_qos_params.h>
 #include <linux/cpu.h>
 #include <linux/cpuidle.h>
 
@@ -265,7 +265,10 @@ static struct notifier_block cpuidle_latency_notifier = {
 	.notifier_call = cpuidle_latency_notify,
 };
 
-#define latency_notifier_init(x) do { register_latency_notifier(x); } while (0)
+static inline void latency_notifier_init(struct notifier_block *n)
+{
+	pm_qos_add_notifier(PM_QOS_CPU_DMA_LATENCY, n);
+}
 
 #else /* CONFIG_SMP */
 

commit f757397097d0713c949af76dccabb65a2785782e
Author: Kevin Hilman <khilman@mvista.com>
Date:   Thu Jan 31 17:28:18 2008 -0800

    cpuidle: build fix for non-x86
    
    Convert cpu_idle_wait() to cpuidle_kick_cpus() macro which is
    SMP-only, and gives error on non supported CPU.
    
    Signed-off-by: Kevin Hilman <khilman@mvista.com>
    Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Acked-by: Rafael J. Wysocki <rjw@sisk.pl>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index d2fabe7863a9..794962d9f48b 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -82,7 +82,7 @@ void cpuidle_uninstall_idle_handler(void)
 {
 	if (enabled_devices && (pm_idle != pm_idle_old)) {
 		pm_idle = pm_idle_old;
-		cpu_idle_wait();
+		cpuidle_kick_cpus();
 	}
 }
 

commit 83788c0caed3a425f64fa88fde7c78746b9cdd76
Author: Adrian Bunk <bunk@kernel.org>
Date:   Mon Oct 29 13:49:13 2007 +0100

    cpuidle: remove unused exports
    
    This patch removes the following unused exports:
    - cpuidle_devices
    - cpuidle_register_governor
    - cpuidle_unregister_governor
    
    Signed-off-by: Adrian Bunk <bunk@kernel.org>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
index fdf4106b817b..d2fabe7863a9 100644
--- a/drivers/cpuidle/cpuidle.c
+++ b/drivers/cpuidle/cpuidle.c
@@ -19,7 +19,6 @@
 #include "cpuidle.h"
 
 DEFINE_PER_CPU(struct cpuidle_device *, cpuidle_devices);
-EXPORT_PER_CPU_SYMBOL_GPL(cpuidle_devices);
 
 DEFINE_MUTEX(cpuidle_lock);
 LIST_HEAD(cpuidle_detected_devices);

commit 4f86d3a8e297205780cca027e974fd5f81064780
Author: Len Brown <len.brown@intel.com>
Date:   Wed Oct 3 18:58:00 2007 -0400

    cpuidle: consolidate 2.6.22 cpuidle branch into one patch
    
    commit e5a16b1f9eec0af7cfa0830304b41c1c0833cf9f
    Author: Len Brown <len.brown@intel.com>
    Date:   Tue Oct 2 23:44:44 2007 -0400
    
        cpuidle: shrink diff
    
        processor_idle.c |  440 +++++++++++++++++++++++++++++++++++++++++--
        1 file changed, 429 insertions(+), 11 deletions(-)
    
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit dfbb9d5aedfb18848a3e0d6f6e3e4969febb209c
    Author: Len Brown <len.brown@intel.com>
    Date:   Wed Sep 26 02:17:55 2007 -0400
    
        cpuidle: reduce diff size
    
        Reduces the cpuidle processor_idle.c diff vs 2.6.22 from this
         processor_idle.c | 2006 ++++++++++++++++++++++++++-----------------
         1 file changed, 1219 insertions(+), 787 deletions(-)
    
        to this:
         processor_idle.c |  502 +++++++++++++++++++++++++++++++++++++++----
         1 file changed, 458 insertions(+), 44 deletions(-)
    
        ...for the purpose of making the cpuilde patch less invasive
        and easier to review.
    
        no functional changes.  build tested only.
    
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 889172fc915f5a7fe20f35b133cbd205ce69bf6c
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Thu Sep 13 13:40:05 2007 -0700
    
        cpuidle: Retain old ACPI policy for !CONFIG_CPU_IDLE
    
        Retain the old policy in processor_idle, so that when CPU_IDLE is not
        configured, old C-state policy will still be used. This provides a
        clean gradual migration path from old ACPI policy to new cpuidle
        based policy.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 9544a8181edc7ecc33b3bfd69271571f98ed08bc
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Thu Sep 13 13:39:17 2007 -0700
    
        cpuidle: Configure governors by default
    
        Quoting Len "Do not give an option to users to shoot themselves in the foot".
    
        Remove the configurability of ladder and menu governors as they are
        needed for default policy of cpuidle. That way users will not be able to
        have cpuidle without any policy loosing all C-state power savings.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 8975059a2c1e56cfe83d1bcf031bcf4cb39be743
    Author: Adam Belay <abelay@novell.com>
    Date:   Tue Aug 21 18:27:07 2007 -0400
    
        CPUIDLE: load ACPI properly when CPUIDLE is disabled
    
        Change the registration return codes for when CPUIDLE
        support is not compiled into the kernel.  As a result, the ACPI
        processor driver will load properly even if CPUIDLE is unavailable.
        However, it may be possible to cleanup the ACPI processor driver further
        and eliminate some dead code paths.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit e0322e2b58dd1b12ec669bf84693efe0dc2414a8
    Author: Adam Belay <abelay@novell.com>
    Date:   Tue Aug 21 18:26:06 2007 -0400
    
        CPUIDLE: remove cpuidle_get_bm_activity()
    
        Remove cpuidle_get_bm_activity() and updates governors
        accordingly.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 18a6e770d5c82ba26653e53d240caa617e09e9ab
    Author: Adam Belay <abelay@novell.com>
    Date:   Tue Aug 21 18:25:58 2007 -0400
    
        CPUIDLE: max_cstate fix
    
        Currently max_cstate is limited to 0, resulting in no idle processor
        power management on ACPI platforms.  This patch restores the value to
        the array size.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 1fdc0887286179b40ce24bcdbde663172e205ef0
    Author: Adam Belay <abelay@novell.com>
    Date:   Tue Aug 21 18:25:40 2007 -0400
    
        CPUIDLE: handle BM detection inside the ACPI Processor driver
    
        Update the ACPI processor driver to detect BM activity and
        limit state entry depth internally, rather than exposing such
        requirements to CPUIDLE.  As a result, CPUIDLE can drop this
        ACPI-specific interface and become more platform independent.  BM
        activity is now handled much more aggressively than it was in the
        original implementation, so some testing coverage may be needed to
        verify that this doesn't introduce any DMA buffer under-run issues.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 0ef38840db666f48e3cdd2b769da676c57228dd9
    Author: Adam Belay <abelay@novell.com>
    Date:   Tue Aug 21 18:25:14 2007 -0400
    
        CPUIDLE: menu governor updates
    
        Tweak the menu governor to more effectively handle non-timer
        break events.  Non-timer break events are detected by comparing the
        actual sleep time to the expected sleep time.  In future revisions, it
        may be more reliable to use the timer data structures directly.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit bb4d74fca63fa96cf3ace644b15ae0f12b7df5a1
    Author: Adam Belay <abelay@novell.com>
    Date:   Tue Aug 21 18:24:40 2007 -0400
    
        CPUIDLE: fix 'current_governor' sysfs entry
    
        Allow the "current_governor" sysfs entry to properly handle
        input terminated with '\n'.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit df3c71559bb69b125f1a48971bf0d17f78bbdf47
    Author: Len Brown <len.brown@intel.com>
    Date:   Sun Aug 12 02:00:45 2007 -0400
    
        cpuidle: fix IA64 build (again)
    
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit a02064579e3f9530fd31baae16b1fc46b5a7bca8
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Sun Aug 12 01:39:27 2007 -0400
    
        cpuidle: Remove support for runtime changing of max_cstate
    
        Remove support for runtime changeability of max_cstate. Drivers can use
        use latency APIs.
    
        max_cstate can still be used as a boot time option and dmi override.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 0912a44b13adf22f5e3f607d263aed23b4910d7e
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Sun Aug 12 01:39:16 2007 -0400
    
        cpuidle: Remove ACPI cstate_limit calls from ipw2100
    
        ipw2100 already has code to use accetable_latency interfaces to limit the
        C-state. Remove the calls to acpi_set_cstate_limit and acpi_get_cstate_limit
        as they are redundant.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit c649a76e76be6bff1fd770d0a775798813a3f6e0
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Sun Aug 12 01:35:39 2007 -0400
    
        cpuidle: compile fix for pause and resume functions
    
        Fix the compilation failure when cpuidle is not compiled in.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Acked-by: Adam Belay <adam.belay@novell.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 2305a5920fb8ee6ccec1c62ade05aa8351091d71
    Author: Adam Belay <abelay@novell.com>
    Date:   Thu Jul 19 00:49:00 2007 -0400
    
        cpuidle: re-write
    
        Some portions have been rewritten to make the code cleaner and lighter
        weight.  The following is a list of changes:
    
        1.) the state name is now included in the sysfs interface
        2.) detection, hotplug, and available state modifications are handled by
        CPUIDLE drivers directly
        3.) the CPUIDLE idle handler is only ever installed when at least one
        cpuidle_device is enabled and ready
        4.) the menu governor BM code no longer overflows
        5.) the sysfs attributes are now printed as unsigned integers, avoiding
        negative values
        6.) a variety of other small cleanups
    
        Also, Idle drivers are no longer swappable during runtime through the
        CPUIDLE sysfs inteface.  On i386 and x86_64 most idle handlers (e.g.
        poll, mwait, halt, etc.) don't benefit from an infrastructure that
        supports multiple states, so I think using a more general case idle
        handler selection mechanism would be cleaner.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Acked-by: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit df25b6b56955714e6e24b574d88d1fd11f0c3ee5
    Author: Len Brown <len.brown@intel.com>
    Date:   Tue Jul 24 17:08:21 2007 -0400
    
        cpuidle: fix IA64 buid
    
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit fd6ada4c14488755ff7068860078c437431fbccd
    Author: Adrian Bunk <bunk@stusta.de>
    Date:   Mon Jul 9 11:33:13 2007 -0700
    
        cpuidle: static
    
        make cpuidle_replace_governor() static
    
        Signed-off-by: Adrian Bunk <bunk@stusta.de>
        Cc: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit c1d4a2cebcadf2429c0c72e1d29aa2a9684c32e0
    Author: Adrian Bunk <bunk@stusta.de>
    Date:   Tue Jul 3 00:54:40 2007 -0400
    
        cpuidle: static
    
        This patch makes the needlessly global struct menu_governor static.
    
        Signed-off-by: Adrian Bunk <bunk@stusta.de>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit dbf8780c6e8d572c2c273da97ed1cca7608fd999
    Author: Andrew Morton <akpm@linux-foundation.org>
    Date:   Tue Jul 3 00:49:14 2007 -0400
    
        export symbol tick_nohz_get_sleep_length
    
        ERROR: "tick_nohz_get_sleep_length" [drivers/cpuidle/governors/menu.ko] undefined!
        ERROR: "tick_nohz_get_idle_jiffies" [drivers/cpuidle/governors/menu.ko] undefined!
    
        And please be sure to get your changes to core kernel suitably reviewed.
    
        Cc: Adam Belay <abelay@novell.com>
        Cc: Venki Pallipadi <venkatesh.pallipadi@intel.com>
        Cc: Ingo Molnar <mingo@elte.hu>
        Cc: Thomas Gleixner <tglx@linutronix.de>
        Cc: john stultz <johnstul@us.ibm.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 29f0e248e7017be15f99febf9143a2cef00b2961
    Author: Andrew Morton <akpm@linux-foundation.org>
    Date:   Tue Jul 3 00:43:04 2007 -0400
    
        tick.h needs hrtimer.h
    
        It uses hrtimers.
    
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit e40cede7d63a029e92712a3fe02faee60cc38fb4
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Tue Jul 3 00:40:34 2007 -0400
    
        cpuidle: first round of documentation updates
    
        Documentation changes based on Pavel's feedback.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 83b42be2efece386976507555c29e7773a0dfcd1
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Tue Jul 3 00:39:25 2007 -0400
    
        cpuidle: add rating to the governors and pick the one with highest rating by default
    
        Introduce a governor rating scheme to pick the right governor by default.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit d2a74b8c5e8f22def4709330d4bfc4a29209b71c
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Tue Jul 3 00:38:08 2007 -0400
    
        cpuidle: make cpuidle sysfs driver governor switch off by default
    
        Make default cpuidle sysfs to show current_governor and current_driver in
        read-only mode.  More elaborate available_governors and available_drivers with
        writeable current_governor and current_driver interface only appear with
        "cpuidle_sysfs_switch" boot parameter.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 1f60a0e80bf83cf6b55c8845bbe5596ed8f6307b
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Tue Jul 3 00:37:00 2007 -0400
    
        cpuidle: menu governor: change the early break condition
    
        Change the C-state early break out algorithm in menu governor.
    
        We only look at early breakouts that result in wakeups shorter than idle
        state's target_residency.  If such a breakout is frequent enough, eliminate
        the particular idle state upto a timeout period.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 45a42095cf64b003b4a69be3ce7f434f97d7af51
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Tue Jul 3 00:35:38 2007 -0400
    
        cpuidle: fix uninitialized variable in sysfs routine
    
        Fix the uninitialized usage of ret.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 80dca7cdba3e6ee13eae277660873ab9584eb3be
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Tue Jul 3 00:34:16 2007 -0400
    
        cpuidle: reenable /proc/acpi//power interface for the time being
    
        Keep /proc/acpi/processor/CPU*/power around for a while as powertop depends
        on it. It will be marked deprecated and removed in future. powertop can use
        cpuidle interfaces instead.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 589c37c2646c5e3813a51255a5ee1159cb4c33fc
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Tue Jul 3 00:32:37 2007 -0400
    
        cpuidle: menu governor and hrtimer compile fix
    
        Compile fix for menu governor.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 0ba80bd9ab3ed304cb4f19b722e4cc6740588b5e
    Author: Len Brown <len.brown@intel.com>
    Date:   Thu May 31 22:51:43 2007 -0400
    
        cpuidle: build fix - cpuidle vs ipw2100 module
    
        ERROR: "acpi_set_cstate_limit" [drivers/net/wireless/ipw2100.ko] undefined!
    
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit d7d8fa7f96a7f7682be7c6cc0cc53fa7a18c3b58
    Author: Adam Belay <abelay@novell.com>
    Date:   Sat Mar 24 03:47:07 2007 -0400
    
        cpuidle: add the 'menu' governor
    
        Here is my first take at implementing an idle PM governor that takes
        full advantage of NO_HZ.  I call it the 'menu' governor because it
        considers the full list of idle states before each entry.
    
        I've kept the implementation fairly simple.  It attempts to guess the
        next residency time and then chooses a state that would meet at least
        the break-even point between power savings and entry cost.  To this end,
        it selects the deepest idle state that satisfies the following
        constraints:
             1. If the idle time elapsed since bus master activity was detected
                is below a threshold (currently 20 ms), then limit the selection
                to C2-type or above.
             2. Do not choose a state with a break-even residency that exceeds
                the expected time remaining until the next timer interrupt.
             3. Do not choose a state with a break-even residency that exceeds
                the elapsed time between the last pair of break events,
                excluding timer interrupts.
    
        This governor has an advantage over "ladder" governor because it
        proactively checks how much time remains until the next timer interrupt
        using the tick infrastructure.  Also, it handles device interrupt
        activity more intelligently by not including timer interrupts in break
        event calculations.  Finally, it doesn't make policy decisions using the
        number of state entries, which can have variable residency times (NO_HZ
        makes these potentially very large), and instead only considers sleep
        time deltas.
    
        The menu governor can be selected during runtime using the cpuidle sysfs
        interface like so:
        "echo "menu" > /sys/devices/system/cpu/cpuidle/current_governor"
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit a4bec7e65aa3b7488b879d971651cc99a6c410fe
    Author: Adam Belay <abelay@novell.com>
    Date:   Sat Mar 24 03:47:03 2007 -0400
    
        cpuidle: export time until next timer interrupt using NO_HZ
    
        Expose information about the time remaining until the next
        timer interrupt expires by utilizing the dynticks infrastructure.
        Also modify the main idle loop to allow dynticks to handle
        non-interrupt break events (e.g. DMA).  Finally, expose sleep ticks
        information to external code.  Thomas Gleixner is responsible for much
        of the code in this patch.  However, I've made some additional changes,
        so I'm probably responsible if there are any bugs or oversights :)
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 2929d8996fbc77f41a5ff86bb67cdde3ca7d2d72
    Author: Adam Belay <abelay@novell.com>
    Date:   Sat Mar 24 03:46:58 2007 -0400
    
        cpuidle: governor API changes
    
        This patch prepares cpuidle for the menu governor.  It adds an optional
        stage after idle state entry to give the governor an opportunity to
        check why the state was exited.  Also it makes sure the idle loop
        returns after each state entry, allowing the appropriate dynticks code
        to run.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 3a7fd42f9825c3b03e364ca59baa751bb350775f
    Author: Venki Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Thu Apr 26 00:03:59 2007 -0700
    
        cpuidle: hang fix
    
        Prevent hang on x86-64, when ACPI processor driver is added as a module on
        a system that does not support C-states.
    
        x86-64 expects all idle handlers to enable interrupts before returning from
        idle handler.  This is due to enter_idle(), exit_idle() races.  Make
        cpuidle_idle_call() confirm to this when there is no pm_idle_old.
    
        Also, cpuidle look at the return values of attch_driver() and set
        current_driver to NULL if attach fails on all CPUs.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 4893339a142afbd5b7c01ffadfd53d14746e858e
    Author: Shaohua Li <shaohua.li@intel.com>
    Date:   Thu Apr 26 10:40:09 2007 +0800
    
        cpuidle: add support for max_cstate limit
    
        With CPUIDLE framework, the max_cstate (to limit max cpu c-state)
        parameter is ingored. Some systems require it to ignore C2/C3
        and some drivers like ipw require it too.
    
        Signed-off-by: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 43bbbbe1cb998cbd2df656f55bb3bfe30f30e7d1
    Author: Shaohua Li <shaohua.li@intel.com>
    Date:   Thu Apr 26 10:40:13 2007 +0800
    
        cpuidle: add cpuidle_fore_redetect_devices API
    
        add cpuidle_force_redetect_devices API,
        which forces all CPU redetect idle states.
        Next patch will use it.
    
        Signed-off-by: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit d1edadd608f24836def5ec483d2edccfb37b1d19
    Author: Shaohua Li <shaohua.li@intel.com>
    Date:   Thu Apr 26 10:40:01 2007 +0800
    
        cpuidle: fix sysfs related issue
    
        Fix the cpuidle sysfs issue.
        a. make kobject dynamicaly allocated
        b. fixed sysfs init issue to avoid suspend/resume issue
    
        Signed-off-by: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 7169a5cc0d67b263978859672e86c13c23a5570d
    Author: Randy Dunlap <randy.dunlap@oracle.com>
    Date:   Wed Mar 28 22:52:53 2007 -0400
    
        cpuidle: 1-bit field must be unsigned
    
        A 1-bit bitfield has no room for a sign bit.
        drivers/cpuidle/governors/ladder.c:54:16: error: dubious bitfield without explicit `signed' or `unsigned'
    
        Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
        Cc: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 4658620158dc2fbd9e4bcb213c5b6fb5d05ba7d4
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Wed Mar 28 22:52:41 2007 -0400
    
        cpuidle: fix boot hang
    
        Patch for cpuidle boot hang reported by Larry Finger here.
        http://www.ussg.iu.edu/hypermail/linux/kernel/0703.2/2025.html
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Cc: Larry Finger <larry.finger@lwfinger.net>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit c17e168aa6e5fe3851baaae8df2fbc1cf11443a9
    Author: Len Brown <len.brown@intel.com>
    Date:   Wed Mar 7 04:37:53 2007 -0500
    
        cpuidle: ladder does not depend on ACPI
    
        build fix for CONFIG_ACPI=n
    
        In file included from drivers/cpuidle/governors/ladder.c:21:
        include/acpi/processor.h:88: error: expected specifier-qualifier-list before 창acpi_integer창
        include/acpi/processor.h:106: error: expected specifier-qualifier-list before 창acpi_integer창
        include/acpi/processor.h:168: error: expected specifier-qualifier-list before 창acpi_handle창
    
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 8c91d958246bde68db0c3f0c57b535962ce861cb
    Author: Adrian Bunk <bunk@stusta.de>
    Date:   Tue Mar 6 02:29:40 2007 -0800
    
        cpuidle: make code static
    
        This patch makes the following needlessly global code static:
        - driver.c: __cpuidle_find_driver()
        - governor.c: __cpuidle_find_governor()
        - ladder.c: struct ladder_governor
    
        Signed-off-by: Adrian Bunk <bunk@stusta.de>
        Cc: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Cc: Adam Belay <abelay@novell.com>
        Cc: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 0c39dc3187094c72c33ab65a64d2017b21f372d2
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Wed Mar 7 02:38:22 2007 -0500
    
        cpu_idle: fix build break
    
        This patch fixes a build breakage with !CONFIG_HOTPLUG_CPU and
        CONFIG_CPU_IDLE.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Adrian Bunk <bunk@stusta.de>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 8112e3b115659b07df340ef170515799c0105f82
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Tue Mar 6 02:29:39 2007 -0800
    
        cpuidle: build fix for !CPU_IDLE
    
        Fix the compile issues when CPU_IDLE is not configured.
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Cc: Adam Belay <abelay@novell.com>
        Cc: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 1eb4431e9599cd25e0d9872f3c2c8986821839dd
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Thu Feb 22 13:54:57 2007 -0800
    
        cpuidle take2: Basic documentation for cpuidle
    
        Documentation for cpuidle infrastructure
    
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Adam Belay <abelay@novell.com>
        Signed-off-by: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit ef5f15a8b79123a047285ec2e3899108661df779
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Thu Feb 22 13:54:03 2007 -0800
    
        cpuidle take2: Hookup ACPI C-states driver with cpuidle
    
        Hookup ACPI C-states onto generic cpuidle infrastructure.
    
        drivers/acpi/procesor_idle.c is now a ACPI C-states driver that registers as
        a driver in cpuidle infrastructure and the policy part is removed from
        drivers/acpi/processor_idle.c. We use governor in cpuidle instead.
    
        Signed-off-by: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Adam Belay <abelay@novell.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    commit 987196fa82d4db52c407e8c9d5dec884ba602183
    Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Date:   Thu Feb 22 13:52:57 2007 -0800
    
        cpuidle take2: Core cpuidle infrastructure
    
        Announcing 'cpuidle', a new CPU power management infrastructure to manage
        idle CPUs in a clean and efficient manner.
        cpuidle separates out the drivers that can provide support for multiple types
        of idle states and policy governors that decide on what idle state to use
        at run time.
        A cpuidle driver can support multiple idle states based on parameters like
        varying power consumption, wakeup latency, etc (ACPI C-states for example).
        A cpuidle governor can be usage model specific (laptop, server,
        laptop on battery etc).
        Main advantage of the infrastructure being, it allows independent development
        of drivers and governors and allows for better CPU power management.
    
        A huge thanks to Adam Belay and Shaohua Li who were part of this mini-project
        since its beginning and are greatly responsible for this patchset.
    
        This patch:
    
        Core cpuidle infrastructure.
        Introduces a new abstraction layer for cpuidle:
        * which manages drivers that can support multiple idles states. Drivers
          can be generic or particular to specific hardware/platform
        * allows pluging in multiple policy governors that can take idle state policy
          decision
        * The core also has a set of sysfs interfaces with which administrato can know
          about supported drivers and governors and switch them at run time.
    
        Signed-off-by: Adam Belay <abelay@novell.com>
        Signed-off-by: Shaohua Li <shaohua.li@intel.com>
        Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
        Signed-off-by: Len Brown <len.brown@intel.com>
    
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/drivers/cpuidle/cpuidle.c b/drivers/cpuidle/cpuidle.c
new file mode 100644
index 000000000000..fdf4106b817b
--- /dev/null
+++ b/drivers/cpuidle/cpuidle.c
@@ -0,0 +1,295 @@
+/*
+ * cpuidle.c - core cpuidle infrastructure
+ *
+ * (C) 2006-2007 Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
+ *               Shaohua Li <shaohua.li@intel.com>
+ *               Adam Belay <abelay@novell.com>
+ *
+ * This code is licenced under the GPL.
+ */
+
+#include <linux/kernel.h>
+#include <linux/mutex.h>
+#include <linux/sched.h>
+#include <linux/notifier.h>
+#include <linux/latency.h>
+#include <linux/cpu.h>
+#include <linux/cpuidle.h>
+
+#include "cpuidle.h"
+
+DEFINE_PER_CPU(struct cpuidle_device *, cpuidle_devices);
+EXPORT_PER_CPU_SYMBOL_GPL(cpuidle_devices);
+
+DEFINE_MUTEX(cpuidle_lock);
+LIST_HEAD(cpuidle_detected_devices);
+static void (*pm_idle_old)(void);
+
+static int enabled_devices;
+
+/**
+ * cpuidle_idle_call - the main idle loop
+ *
+ * NOTE: no locks or semaphores should be used here
+ */
+static void cpuidle_idle_call(void)
+{
+	struct cpuidle_device *dev = __get_cpu_var(cpuidle_devices);
+	struct cpuidle_state *target_state;
+	int next_state;
+
+	/* check if the device is ready */
+	if (!dev || !dev->enabled) {
+		if (pm_idle_old)
+			pm_idle_old();
+		else
+			local_irq_enable();
+		return;
+	}
+
+	/* ask the governor for the next state */
+	next_state = cpuidle_curr_governor->select(dev);
+	if (need_resched())
+		return;
+	target_state = &dev->states[next_state];
+
+	/* enter the state and update stats */
+	dev->last_residency = target_state->enter(dev, target_state);
+	dev->last_state = target_state;
+	target_state->time += dev->last_residency;
+	target_state->usage++;
+
+	/* give the governor an opportunity to reflect on the outcome */
+	if (cpuidle_curr_governor->reflect)
+		cpuidle_curr_governor->reflect(dev);
+}
+
+/**
+ * cpuidle_install_idle_handler - installs the cpuidle idle loop handler
+ */
+void cpuidle_install_idle_handler(void)
+{
+	if (enabled_devices && (pm_idle != cpuidle_idle_call)) {
+		/* Make sure all changes finished before we switch to new idle */
+		smp_wmb();
+		pm_idle = cpuidle_idle_call;
+	}
+}
+
+/**
+ * cpuidle_uninstall_idle_handler - uninstalls the cpuidle idle loop handler
+ */
+void cpuidle_uninstall_idle_handler(void)
+{
+	if (enabled_devices && (pm_idle != pm_idle_old)) {
+		pm_idle = pm_idle_old;
+		cpu_idle_wait();
+	}
+}
+
+/**
+ * cpuidle_pause_and_lock - temporarily disables CPUIDLE
+ */
+void cpuidle_pause_and_lock(void)
+{
+	mutex_lock(&cpuidle_lock);
+	cpuidle_uninstall_idle_handler();
+}
+
+EXPORT_SYMBOL_GPL(cpuidle_pause_and_lock);
+
+/**
+ * cpuidle_resume_and_unlock - resumes CPUIDLE operation
+ */
+void cpuidle_resume_and_unlock(void)
+{
+	cpuidle_install_idle_handler();
+	mutex_unlock(&cpuidle_lock);
+}
+
+EXPORT_SYMBOL_GPL(cpuidle_resume_and_unlock);
+
+/**
+ * cpuidle_enable_device - enables idle PM for a CPU
+ * @dev: the CPU
+ *
+ * This function must be called between cpuidle_pause_and_lock and
+ * cpuidle_resume_and_unlock when used externally.
+ */
+int cpuidle_enable_device(struct cpuidle_device *dev)
+{
+	int ret, i;
+
+	if (dev->enabled)
+		return 0;
+	if (!cpuidle_curr_driver || !cpuidle_curr_governor)
+		return -EIO;
+	if (!dev->state_count)
+		return -EINVAL;
+
+	if ((ret = cpuidle_add_state_sysfs(dev)))
+		return ret;
+
+	if (cpuidle_curr_governor->enable &&
+	    (ret = cpuidle_curr_governor->enable(dev)))
+		goto fail_sysfs;
+
+	for (i = 0; i < dev->state_count; i++) {
+		dev->states[i].usage = 0;
+		dev->states[i].time = 0;
+	}
+	dev->last_residency = 0;
+	dev->last_state = NULL;
+
+	smp_wmb();
+
+	dev->enabled = 1;
+
+	enabled_devices++;
+	return 0;
+
+fail_sysfs:
+	cpuidle_remove_state_sysfs(dev);
+
+	return ret;
+}
+
+EXPORT_SYMBOL_GPL(cpuidle_enable_device);
+
+/**
+ * cpuidle_disable_device - disables idle PM for a CPU
+ * @dev: the CPU
+ *
+ * This function must be called between cpuidle_pause_and_lock and
+ * cpuidle_resume_and_unlock when used externally.
+ */
+void cpuidle_disable_device(struct cpuidle_device *dev)
+{
+	if (!dev->enabled)
+		return;
+	if (!cpuidle_curr_driver || !cpuidle_curr_governor)
+		return;
+
+	dev->enabled = 0;
+
+	if (cpuidle_curr_governor->disable)
+		cpuidle_curr_governor->disable(dev);
+
+	cpuidle_remove_state_sysfs(dev);
+	enabled_devices--;
+}
+
+EXPORT_SYMBOL_GPL(cpuidle_disable_device);
+
+/**
+ * cpuidle_register_device - registers a CPU's idle PM feature
+ * @dev: the cpu
+ */
+int cpuidle_register_device(struct cpuidle_device *dev)
+{
+	int ret;
+	struct sys_device *sys_dev = get_cpu_sysdev((unsigned long)dev->cpu);
+
+	if (!sys_dev)
+		return -EINVAL;
+	if (!try_module_get(cpuidle_curr_driver->owner))
+		return -EINVAL;
+
+	init_completion(&dev->kobj_unregister);
+
+	mutex_lock(&cpuidle_lock);
+
+	per_cpu(cpuidle_devices, dev->cpu) = dev;
+	list_add(&dev->device_list, &cpuidle_detected_devices);
+	if ((ret = cpuidle_add_sysfs(sys_dev))) {
+		mutex_unlock(&cpuidle_lock);
+		module_put(cpuidle_curr_driver->owner);
+		return ret;
+	}
+
+	cpuidle_enable_device(dev);
+	cpuidle_install_idle_handler();
+
+	mutex_unlock(&cpuidle_lock);
+
+	return 0;
+
+}
+
+EXPORT_SYMBOL_GPL(cpuidle_register_device);
+
+/**
+ * cpuidle_unregister_device - unregisters a CPU's idle PM feature
+ * @dev: the cpu
+ */
+void cpuidle_unregister_device(struct cpuidle_device *dev)
+{
+	struct sys_device *sys_dev = get_cpu_sysdev((unsigned long)dev->cpu);
+
+	cpuidle_pause_and_lock();
+
+	cpuidle_disable_device(dev);
+
+	cpuidle_remove_sysfs(sys_dev);
+	list_del(&dev->device_list);
+	wait_for_completion(&dev->kobj_unregister);
+	per_cpu(cpuidle_devices, dev->cpu) = NULL;
+
+	cpuidle_resume_and_unlock();
+
+	module_put(cpuidle_curr_driver->owner);
+}
+
+EXPORT_SYMBOL_GPL(cpuidle_unregister_device);
+
+#ifdef CONFIG_SMP
+
+static void smp_callback(void *v)
+{
+	/* we already woke the CPU up, nothing more to do */
+}
+
+/*
+ * This function gets called when a part of the kernel has a new latency
+ * requirement.  This means we need to get all processors out of their C-state,
+ * and then recalculate a new suitable C-state. Just do a cross-cpu IPI; that
+ * wakes them all right up.
+ */
+static int cpuidle_latency_notify(struct notifier_block *b,
+		unsigned long l, void *v)
+{
+	smp_call_function(smp_callback, NULL, 0, 1);
+	return NOTIFY_OK;
+}
+
+static struct notifier_block cpuidle_latency_notifier = {
+	.notifier_call = cpuidle_latency_notify,
+};
+
+#define latency_notifier_init(x) do { register_latency_notifier(x); } while (0)
+
+#else /* CONFIG_SMP */
+
+#define latency_notifier_init(x) do { } while (0)
+
+#endif /* CONFIG_SMP */
+
+/**
+ * cpuidle_init - core initializer
+ */
+static int __init cpuidle_init(void)
+{
+	int ret;
+
+	pm_idle_old = pm_idle;
+
+	ret = cpuidle_add_class_sysfs(&cpu_sysdev_class);
+	if (ret)
+		return ret;
+
+	latency_notifier_init(&cpuidle_latency_notifier);
+
+	return 0;
+}
+
+core_initcall(cpuidle_init);
