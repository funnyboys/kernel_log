commit 1acba6a817852d4aa7916d5c4f2c82f702ee9224
Author: Valentine Fatiev <valentinef@mellanox.com>
Date:   Wed May 27 16:47:05 2020 +0300

    IB/ipoib: Fix double free of skb in case of multicast traffic in CM mode
    
    When connected mode is set, and we have connected and datagram traffic in
    parallel, ipoib might crash with double free of datagram skb.
    
    The current mechanism assumes that the order in the completion queue is
    the same as the order of sent packets for all QPs. Order is kept only for
    specific QP, in case of mixed UD and CM traffic we have few QPs (one UD and
    few CM's) in parallel.
    
    The problem:
    ----------------------------------------------------------
    
    Transmit queue:
    -----------------
    UD skb pointer kept in queue itself, CM skb kept in spearate queue and
    uses transmit queue as a placeholder to count the number of total
    transmitted packets.
    
    0   1   2   3   4  5  6  7  8   9  10  11 12 13 .........127
    ------------------------------------------------------------
    NL ud1 UD2 CM1 ud3 cm2 cm3 ud4 cm4 ud5 NL NL NL ...........
    ------------------------------------------------------------
        ^                                  ^
       tail                               head
    
    Completion queue (problematic scenario) - the order not the same as in
    the transmit queue:
    
      1  2  3  4  5  6  7  8  9
    ------------------------------------
     ud1 CM1 UD2 ud3 cm2 cm3 ud4 cm4 ud5
    ------------------------------------
    
    1. CM1 'wc' processing
       - skb freed in cm separate ring.
       - tx_tail of transmit queue increased although UD2 is not freed.
         Now driver assumes UD2 index is already freed and it could be used for
         new transmitted skb.
    
    0   1   2   3   4  5  6  7  8   9  10  11 12 13 .........127
    ------------------------------------------------------------
    NL NL  UD2 CM1 ud3 cm2 cm3 ud4 cm4 ud5 NL NL NL ...........
    ------------------------------------------------------------
            ^   ^                       ^
          (Bad)tail                    head
    (Bad - Could be used for new SKB)
    
    In this case (due to heavy load) UD2 skb pointer could be replaced by new
    transmitted packet UD_NEW, as the driver assumes its free.  At this point
    we will have to process two 'wc' with same index but we have only one
    pointer to free.
    
    During second attempt to free the same skb we will have NULL pointer
    exception.
    
    2. UD2 'wc' processing
       - skb freed according the index we got from 'wc', but it was already
         overwritten by mistake. So actually the skb that was released is the
         skb of the new transmitted packet and not the original one.
    
    3. UD_NEW 'wc' processing
       - attempt to free already freed skb. NUll pointer exception.
    
    The fix:
    -----------------------------------------------------------------------
    
    The fix is to stop using the UD ring as a placeholder for CM packets, the
    cyclic ring variables tx_head and tx_tail will manage the UD tx_ring, a
    new cyclic variables global_tx_head and global_tx_tail are introduced for
    managing and counting the overall outstanding sent packets, then the send
    queue will be stopped and waken based on these variables only.
    
    Note that no locking is needed since global_tx_head is updated in the xmit
    flow and global_tx_tail is updated in the NAPI flow only.  A previous
    attempt tried to use one variable to count the outstanding sent packets,
    but it did not work since xmit and NAPI flows can run at the same time and
    the counter will be updated wrongly. Thus, we use the same simple cyclic
    head and tail scheme that we have today for the UD tx_ring.
    
    Fixes: 2c104ea68350 ("IB/ipoib: Get rid of the tx_outstanding variable in all modes")
    Link: https://lore.kernel.org/r/20200527134705.480068-1-leon@kernel.org
    Signed-off-by: Valentine Fatiev <valentinef@mellanox.com>
    Signed-off-by: Alaa Hleihel <alaa@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Acked-by: Doug Ledford <dledford@redhat.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index e188a95984b5..9a3379c49541 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -377,8 +377,12 @@ struct ipoib_dev_priv {
 	struct ipoib_rx_buf *rx_ring;
 
 	struct ipoib_tx_buf *tx_ring;
+	/* cyclic ring variables for managing tx_ring, for UD only */
 	unsigned int	     tx_head;
 	unsigned int	     tx_tail;
+	/* cyclic ring variables for counting overall outstanding send WRs */
+	unsigned int	     global_tx_head;
+	unsigned int	     global_tx_tail;
 	struct ib_sge	     tx_sge[MAX_SKB_FRAGS + 1];
 	struct ib_ud_wr      tx_wr;
 	struct ib_wc	     send_wc[MAX_SEND_CQE];

commit 968707207141aba5b32871b300dcc601da3afe5c
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Thu Feb 20 09:12:38 2020 +0200

    RDMA/ipoib: Don't set constant driver version
    
    There is no need to set driver version in in-tree kernel code.
    
    Link: https://lore.kernel.org/r/20200220071239.231800-2-leon@kernel.org
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 2aa3457a30ce..e188a95984b5 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -838,6 +838,4 @@ extern int ipoib_debug_level;
 
 #define IPOIB_QPN(ha) (be32_to_cpup((__be32 *) ha) & 0xffffff)
 
-extern const char ipoib_driver_version[];
-
 #endif /* _IPOIB_H */

commit 6a8a2aa62da2fbe51f5449993fd366398048f465
Merge: a163afc88556 8834f5600cf3
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Mon Feb 4 14:53:42 2019 -0700

    Merge tag 'v5.0-rc5' into rdma.git for-next
    
    Linux 5.0-rc5
    
    Needed to merge the include/uapi changes so we have an up to date
    single-tree for these files. Patches already posted are also expected to
    need this for dependencies.

commit 6ab4aba00f811a5265acc4d3eb1863bb3ca60562
Author: Feras Daoud <ferasda@mellanox.com>
Date:   Thu Jan 24 14:33:19 2019 +0200

    IB/ipoib: Fix for use-after-free in ipoib_cm_tx_start
    
    The following BUG was reported by kasan:
    
     BUG: KASAN: use-after-free in ipoib_cm_tx_start+0x430/0x1390 [ib_ipoib]
     Read of size 80 at addr ffff88034c30bcd0 by task kworker/u16:1/24020
    
     Workqueue: ipoib_wq ipoib_cm_tx_start [ib_ipoib]
     Call Trace:
      dump_stack+0x9a/0xeb
      print_address_description+0xe3/0x2e0
      kasan_report+0x18a/0x2e0
      ? ipoib_cm_tx_start+0x430/0x1390 [ib_ipoib]
      memcpy+0x1f/0x50
      ipoib_cm_tx_start+0x430/0x1390 [ib_ipoib]
      ? kvm_clock_read+0x1f/0x30
      ? ipoib_cm_skb_reap+0x610/0x610 [ib_ipoib]
      ? __lock_is_held+0xc2/0x170
      ? process_one_work+0x880/0x1960
      ? process_one_work+0x912/0x1960
      process_one_work+0x912/0x1960
      ? wq_pool_ids_show+0x310/0x310
      ? lock_acquire+0x145/0x440
      worker_thread+0x87/0xbb0
      ? process_one_work+0x1960/0x1960
      kthread+0x314/0x3d0
      ? kthread_create_worker_on_cpu+0xc0/0xc0
      ret_from_fork+0x3a/0x50
    
     Allocated by task 0:
      kasan_kmalloc+0xa0/0xd0
      kmem_cache_alloc_trace+0x168/0x3e0
      path_rec_create+0xa2/0x1f0 [ib_ipoib]
      ipoib_start_xmit+0xa98/0x19e0 [ib_ipoib]
      dev_hard_start_xmit+0x159/0x8d0
      sch_direct_xmit+0x226/0xb40
      __dev_queue_xmit+0x1d63/0x2950
      neigh_update+0x889/0x1770
      arp_process+0xc47/0x21f0
      arp_rcv+0x462/0x760
      __netif_receive_skb_core+0x1546/0x2da0
      netif_receive_skb_internal+0xf2/0x590
      napi_gro_receive+0x28e/0x390
      ipoib_ib_handle_rx_wc_rss+0x873/0x1b60 [ib_ipoib]
      ipoib_rx_poll_rss+0x17d/0x320 [ib_ipoib]
      net_rx_action+0x427/0xe30
      __do_softirq+0x28e/0xc42
    
     Freed by task 26680:
      __kasan_slab_free+0x11d/0x160
      kfree+0xf5/0x360
      ipoib_flush_paths+0x532/0x9d0 [ib_ipoib]
      ipoib_set_mode_rss+0x1ad/0x560 [ib_ipoib]
      set_mode+0xc8/0x150 [ib_ipoib]
      kernfs_fop_write+0x279/0x440
      __vfs_write+0xd8/0x5c0
      vfs_write+0x15e/0x470
      ksys_write+0xb8/0x180
      do_syscall_64+0x9b/0x420
      entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
     The buggy address belongs to the object at ffff88034c30bcc8
                    which belongs to the cache kmalloc-512 of size 512
     The buggy address is located 8 bytes inside of
                    512-byte region [ffff88034c30bcc8, ffff88034c30bec8)
     The buggy address belongs to the page:
    
    The following race between change mode and xmit flow is the reason for
    this use-after-free:
    
    Change mode     Send packet 1 to GID XX      Send packet 2 to GID XX
         |                    |                             |
       start                  |                             |
         |                    |                             |
         |                    |                             |
         |         Create new path for GID XX               |
         |           and update neigh path                  |
         |                    |                             |
         |                    |                             |
         |                    |                             |
     flush_paths              |                             |
                              |                             |
                   queue_work(cm.start_task)                |
                              |                 Path for GID XX not found
                              |                      create new path
                              |
                              |
                   start_task runs with old
                        released path
    
    There is no locking to protect the lifetime of the path through the
    ipoib_cm_tx struct, so delete it entirely and always use the newly looked
    up path under the priv->lock.
    
    Fixes: 546481c2816e ("IB/ipoib: Fix memory corruption in ipoib cm mode connect flow")
    Signed-off-by: Feras Daoud <ferasda@mellanox.com>
    Reviewed-by: Erez Shitrit <erezsh@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 1da119d901a9..73e808c1e6ad 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -248,7 +248,6 @@ struct ipoib_cm_tx {
 	struct list_head     list;
 	struct net_device   *dev;
 	struct ipoib_neigh  *neigh;
-	struct ipoib_path   *path;
 	struct ipoib_tx_buf *tx_ring;
 	unsigned int	     tx_head;
 	unsigned int	     tx_tail;

commit 2e061c691c3f46a4932a40f7bf440bacd011e1e2
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Tue Jan 22 16:18:00 2019 +0100

    infiniband: ipoib: no need to check return value of debugfs_create functions
    
    When calling debugfs functions, there is no need to ever check the
    return value.  The function can work or not, but the code logic should
    never do something different based on this.
    
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 1da119d901a9..5941d660add1 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -781,12 +781,12 @@ static inline void ipoib_cm_handle_tx_wc(struct net_device *dev, struct ib_wc *w
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
 void ipoib_create_debug_files(struct net_device *dev);
 void ipoib_delete_debug_files(struct net_device *dev);
-int ipoib_register_debugfs(void);
+void ipoib_register_debugfs(void);
 void ipoib_unregister_debugfs(void);
 #else
 static inline void ipoib_create_debug_files(struct net_device *dev) { }
 static inline void ipoib_delete_debug_files(struct net_device *dev) { }
-static inline int ipoib_register_debugfs(void) { return 0; }
+static inline void ipoib_register_debugfs(void) { }
 static inline void ipoib_unregister_debugfs(void) { }
 #endif
 

commit 5d6b0cb3369df425de75c94c98eb3f1a86659022
Author: Denis Drozdov <denisd@mellanox.com>
Date:   Tue Aug 14 14:22:35 2018 +0300

    RDMA/netdev: Fix netlink support in IPoIB
    
    IPoIB netlink support was broken by the below commit since integrating
    the rdma_netdev support relies on an allocation flow for netdevs that
    was controlled by the ipoib driver while netdev's rtnl_newlink
    implementation assumes that the netdev will be allocated by netlink.
    Such situation leads to crash in __ipoib_device_add, once trying to
    reuse netlink device.
    
    This patch fixes the kernel oops for both mlx4 and mlx5
    devices triggered by the following command:
    
    Fixes: cd565b4b51e5 ("IB/IPoIB: Support acceleration options callbacks")
    Signed-off-by: Denis Drozdov <denisd@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Feras Daoud <ferasda@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 1abe3c62f106..1da119d901a9 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -499,8 +499,10 @@ void ipoib_reap_ah(struct work_struct *work);
 struct ipoib_path *__path_find(struct net_device *dev, void *gid);
 void ipoib_mark_paths_invalid(struct net_device *dev);
 void ipoib_flush_paths(struct net_device *dev);
-struct ipoib_dev_priv *ipoib_intf_alloc(struct ib_device *hca, u8 port,
-					const char *format);
+struct net_device *ipoib_intf_alloc(struct ib_device *hca, u8 port,
+				    const char *format);
+int ipoib_intf_init(struct ib_device *hca, u8 port, const char *format,
+		    struct net_device *dev);
 void ipoib_ib_tx_timer_func(struct timer_list *t);
 void ipoib_ib_dev_flush_light(struct work_struct *work);
 void ipoib_ib_dev_flush_normal(struct work_struct *work);
@@ -531,6 +533,8 @@ int ipoib_dma_map_tx(struct ib_device *ca, struct ipoib_tx_buf *tx_req);
 void ipoib_dma_unmap_tx(struct ipoib_dev_priv *priv,
 			struct ipoib_tx_buf *tx_req);
 
+struct rtnl_link_ops *ipoib_get_link_ops(void);
+
 static inline void ipoib_build_sge(struct ipoib_dev_priv *priv,
 				   struct ipoib_tx_buf *tx_req)
 {

commit 25405d98a2aa0b9983bb9c36b0b00815d39394f4
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Sun Jul 29 11:34:58 2018 +0300

    IB/ipoib: Do not remove child devices from within the ndo_uninit
    
    Switching to priv_destructor and needs_free_netdev created a subtle
    ordering problem in ipoib_remove_one.
    
    Now that unregister_netdev frees the netdev and priv we must ensure that
    the children are unregistered before trying to unregister the parent,
    or child unregister will use after free.
    
    The solution is to unregister the children, then parent, in the same batch
    all while holding the rtnl_lock. This closes all the races where a new
    child could have been added and ensures proper ordering.
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 804cb4bee57d..1abe3c62f106 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -330,6 +330,13 @@ struct ipoib_dev_priv {
 
 	unsigned long flags;
 
+	/*
+	 * This protects access to the child_intfs list.
+	 * To READ from child_intfs the RTNL or vlan_rwsem read side must be
+	 * held.  To WRITE RTNL and the vlan_rwsem write side must be held (in
+	 * that order) This lock exists because we have a few contexts where
+	 * we need the child_intfs, but do not want to grab the RTNL.
+	 */
 	struct rw_semaphore vlan_rwsem;
 	struct mutex mcast_mutex;
 

commit ee190ab734ba4d3c7887bd193ce8124385738e44
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Sun Jul 29 11:34:57 2018 +0300

    IB/ipoib: Get rid of the sysfs_mutex
    
    This mutex was introduced to deal with the deadlock formed by calling
    unregister_netdev from within the sysfs callback of a netdev.
    
    Now that we have priv_destructor and needs_free_netdev we can switch
    to the more targeted solution of running the unregister from a
    work queue. This avoids the deadlock and gets rid of the mutex.
    
    The next patch in the series needs this mutex eliminated to create
    atomicity of unregisteration.
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index d2cb0a8500e3..804cb4bee57d 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -332,7 +332,6 @@ struct ipoib_dev_priv {
 
 	struct rw_semaphore vlan_rwsem;
 	struct mutex mcast_mutex;
-	struct mutex sysfs_mutex;
 
 	struct rb_root  path_tree;
 	struct list_head path_list;

commit 9f49a5b5c21d58aa84e16cfdc5e99e49faefcb7a
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Sun Jul 29 11:34:56 2018 +0300

    RDMA/netdev: Use priv_destructor for netdev cleanup
    
    Now that the unregister_netdev flow for IPoIB no longer relies on external
    code we can now introduce the use of priv_destructor and
    needs_free_netdev.
    
    The rdma_netdev flow is switched to use the netdev common priv_destructor
    instead of the special free_rdma_netdev and the IPOIB ULP adjusted:
     - priv_destructor needs to switch to point to the ULP's destructor
       which will then call the rdma_ndev's in the right order
     - We need to be careful around the error unwind of register_netdev
       as it sometimes calls priv_destructor on failure
     - ULPs need to use ndo_init/uninit to ensure proper ordering
       of failures around register_netdev
    
    Switching to priv_destructor is a necessary pre-requisite to using
    the rtnl new_link mechanism.
    
    The VNIC user for rdma_netdev should also be revised, but that is left for
    another patch.
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Denis Drozdov <denisd@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 02ad1a60dc80..d2cb0a8500e3 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -323,6 +323,7 @@ struct ipoib_dev_priv {
 	spinlock_t lock;
 
 	struct net_device *dev;
+	void (*next_priv_destructor)(struct net_device *dev);
 
 	struct napi_struct send_napi;
 	struct napi_struct recv_napi;
@@ -481,6 +482,7 @@ static inline void ipoib_put_ah(struct ipoib_ah *ah)
 	kref_put(&ah->ref, ipoib_free_ah);
 }
 int ipoib_open(struct net_device *dev);
+void ipoib_intf_free(struct net_device *dev);
 int ipoib_add_pkey_attr(struct net_device *dev);
 int ipoib_add_umcast_attr(struct net_device *dev);
 

commit eaeb398425089cb3c8edc81a406109db94b2705c
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Sun Jul 29 11:34:55 2018 +0300

    IB/ipoib: Move init code to ndo_init
    
    Now that we have a proper ndo_uninit, move code that naturally pairs
    with the ndo_uninit into ndo_init. This allows the netdev core to natually
    handle ordering.
    
    This fixes the situation where register_netdev can fail before calling
    ndo_init, in which case it wouldn't call ndo_uninit either.
    
    Also move a bunch of duplicated init code that is shared between child
    and parent for clarity. Now the child and parent register functions look
    very similar.
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 04fc5ad1b69f..02ad1a60dc80 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -508,8 +508,6 @@ void ipoib_ib_dev_down(struct net_device *dev);
 int ipoib_ib_dev_stop_default(struct net_device *dev);
 void ipoib_pkey_dev_check_presence(struct net_device *dev);
 
-int ipoib_dev_init(struct net_device *dev, struct ib_device *ca, int port);
-
 void ipoib_mcast_join_task(struct work_struct *work);
 void ipoib_mcast_carrier_on_task(struct work_struct *work);
 void ipoib_mcast_send(struct net_device *dev, u8 *daddr, struct sk_buff *skb);
@@ -597,7 +595,6 @@ void ipoib_pkey_open(struct ipoib_dev_priv *priv);
 void ipoib_drain_cq(struct net_device *dev);
 
 void ipoib_set_ethtool_ops(struct net_device *dev);
-void ipoib_set_dev_features(struct ipoib_dev_priv *priv, struct ib_device *hca);
 
 #define IPOIB_FLAGS_RC		0x80
 #define IPOIB_FLAGS_UC		0x40

commit 7cbee87c17965ede0eba2e7ba41d0a38ebd2249c
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Sun Jul 29 11:34:53 2018 +0300

    IB/ipoib: Move all uninit code into ndo_uninit
    
    Currently uninit is sometimes done twice in error flows, and is sprinkled
    a bit all over the place.
    
    Improve the clarity of the design by moving all uninit only into
    ndo_uinit.
    
    Some duplication is removed:
     - Sometimes IPOIB_STOP_NEIGH_GC was done before unregister, but
       this duplicates the process in ipoib_neigh_hash_init
     - Flushing priv->wq was sometimes done before unregister,
       but that duplicates what has been done in ndo_uninit
    
    Uniniting the IB event queue must remain before unregister_netdev as it
    requires the RTNL lock to be dropped, this is moved to a helper to make
    that flow really clear and remove some duplication in error flows.
    
    If register_netdev fails (and ndo_init is NULL) then it almost always
    calls ndo_uninit, which lets us remove all the extra code from the error
    unwinds. The next patch in the series will close the 'almost always' hole
    by pairing a proper ndo_init with ndo_uninit.
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index c619c0098ba6..04fc5ad1b69f 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -509,7 +509,6 @@ int ipoib_ib_dev_stop_default(struct net_device *dev);
 void ipoib_pkey_dev_check_presence(struct net_device *dev);
 
 int ipoib_dev_init(struct net_device *dev, struct ib_device *ca, int port);
-void ipoib_dev_cleanup(struct net_device *dev);
 
 void ipoib_mcast_join_task(struct work_struct *work);
 void ipoib_mcast_carrier_on_task(struct work_struct *work);

commit cda8daf17914a261986d6d4b7294599736d5a463
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Sun Jul 29 11:34:52 2018 +0300

    IB/ipoib: Use cancel_delayed_work_sync for neigh-clean task
    
    The neigh_reap_task is self restarting, but so long as we call
    cancel_delayed_work_sync() it will be guaranteed to not be running and
    never start again. Thus we don't need to have the racy
    IPOIB_STOP_NEIGH_GC bit, or the confusing mismatch of places sometimes
    calling flush_workqueue after the cancel.
    
    This fixes a situation where the GC work could have been left running
    in some rare situations.
    
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 9eebb705d994..c619c0098ba6 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -91,7 +91,6 @@ enum {
 	IPOIB_STOP_REAPER	  = 7,
 	IPOIB_FLAG_ADMIN_CM	  = 9,
 	IPOIB_FLAG_UMCAST	  = 10,
-	IPOIB_STOP_NEIGH_GC	  = 11,
 	IPOIB_NEIGH_TBL_FLUSH	  = 12,
 	IPOIB_FLAG_DEV_ADDR_SET	  = 13,
 	IPOIB_FLAG_DEV_ADDR_CTRL  = 14,

commit 577e07ffbad9960551a6821b74af90a216ac10e2
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Sun Jul 29 11:34:51 2018 +0300

    IB/ipoib: Get rid of IPOIB_FLAG_GOING_DOWN
    
    This essentially duplicates the netdev's reg_state, so just use that
    directly. The reg_state is updated under the rntl_lock, and all places
    using GOING_DOWN already acquire the rtnl_lock so checking is safe.
    
    Since the only place we use GOING_DOWN is for the parent device this
    does not fix any bugs, but it is a step to tidy up the unregister flow
    so that after later patches the flow is uniform and sane.
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index e255a7e5a4c3..9eebb705d994 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -95,7 +95,6 @@ enum {
 	IPOIB_NEIGH_TBL_FLUSH	  = 12,
 	IPOIB_FLAG_DEV_ADDR_SET	  = 13,
 	IPOIB_FLAG_DEV_ADDR_CTRL  = 14,
-	IPOIB_FLAG_GOING_DOWN	  = 15,
 
 	IPOIB_MAX_BACKOFF_SECONDS = 16,
 

commit 3fda24324582ae790961137ecb88b3f0f2feb1f0
Author: Kamal Heib <kamalheib1@gmail.com>
Date:   Mon Jul 9 22:21:03 2018 +0300

    RDMA/ipoib: Fix return code from ipoib_cm_dev_init
    
    The proper return code is -EOPNOTSUPP and not -ENOSYS when the function
    isn't supported, also make sure to return the right error code
    from ipoib_transport_dev_init() when ipoib_cm_dev_init() is supported.
    
    Signed-off-by: Kamal Heib <kamalheib1@gmail.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 3dd130afb571..e255a7e5a4c3 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -729,7 +729,7 @@ void ipoib_cm_dev_stop(struct net_device *dev)
 static inline
 int ipoib_cm_dev_init(struct net_device *dev)
 {
-	return -ENOSYS;
+	return -EOPNOTSUPP;
 }
 
 static inline

commit 0578cdad190b19b23965cb05aebaf2aeb4b6b7e5
Author: Kamal Heib <kamalheib1@gmail.com>
Date:   Thu Jul 5 00:52:48 2018 +0300

    RDMA/ipoib: Prefer unsigned int to bare use of unsigned
    
    This commit replaces all the unsigned definitions in favour of 'unsigned
    int' which is preferred.
    
    Signed-off-by: Kamal Heib <kamalheib1@gmail.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index a50b062ed13e..3dd130afb571 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -252,11 +252,11 @@ struct ipoib_cm_tx {
 	struct ipoib_neigh  *neigh;
 	struct ipoib_path   *path;
 	struct ipoib_tx_buf *tx_ring;
-	unsigned	     tx_head;
-	unsigned	     tx_tail;
+	unsigned int	     tx_head;
+	unsigned int	     tx_tail;
 	unsigned long	     flags;
 	u32		     mtu;
-	unsigned             max_send_sge;
+	unsigned int         max_send_sge;
 };
 
 struct ipoib_cm_rx_buf {
@@ -373,8 +373,8 @@ struct ipoib_dev_priv {
 	struct ipoib_rx_buf *rx_ring;
 
 	struct ipoib_tx_buf *tx_ring;
-	unsigned	     tx_head;
-	unsigned	     tx_tail;
+	unsigned int	     tx_head;
+	unsigned int	     tx_tail;
 	struct ib_sge	     tx_sge[MAX_SKB_FRAGS + 1];
 	struct ib_ud_wr      tx_wr;
 	struct ib_wc	     send_wc[MAX_SEND_CQE];
@@ -404,7 +404,7 @@ struct ipoib_dev_priv {
 #endif
 	u64	hca_caps;
 	struct ipoib_ethtool_st ethtool;
-	unsigned max_send_sge;
+	unsigned int max_send_sge;
 	bool sm_fullmember_sendonly_support;
 	const struct net_device_ops	*rn_ops;
 };
@@ -414,7 +414,7 @@ struct ipoib_ah {
 	struct ib_ah	  *ah;
 	struct list_head   list;
 	struct kref	   ref;
-	unsigned	   last_send;
+	unsigned int	   last_send;
 	int  		   valid;
 };
 

commit fa9391dbad4b868512ed22a7e41765f881a8a935
Author: Doug Ledford <dledford@redhat.com>
Date:   Fri May 18 11:36:09 2018 -0400

    RDMA/ipoib: Update paths on CLIENT_REREG/SM_CHANGE events
    
    We do a light flush on CLIENT_REREG and SM_CHANGE events.  This goes
    through and marks paths invalid. But we weren't always checking for this
    validity when we needed to, and so we could keep using a path marked
    invalid.  What's more, once we establish a path with a valid ah, we put
    a pointer to the ah in the neigh struct directly, so even if we mark the
    path as invalid, as long as the neigh has a direct pointer to the ah, it
    keeps using the old, outdated ah.
    
    To fix this we do several things.
    
    1) Put the valid flag in the ah instead of the path struct, so when we
    put the ah pointer directly in the neigh struct, we can easily check the
    validity of the ah on send events.
    2) Check the neigh->ah and neigh->ah->valid elements in the needed
    places, and if we have an ah, but it's invalid, then invoke a refresh of
    the ah.
    3) Fix the various places that check for path, but didn't check for
    path->valid (now path->ah && path->ah->valid).
    
    Reported-by: Evgenii Smirnov <evgenii.smirnov@profitbricks.com>
    Fixes: ee1e2c82c245 ("IPoIB: Refresh paths instead of flushing them on SM change events")
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 308e0ce49289..a50b062ed13e 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -415,6 +415,7 @@ struct ipoib_ah {
 	struct list_head   list;
 	struct kref	   ref;
 	unsigned	   last_send;
+	int  		   valid;
 };
 
 struct ipoib_path {
@@ -431,7 +432,6 @@ struct ipoib_path {
 
 	struct rb_node	      rb_node;
 	struct list_head      list;
-	int  		      valid;
 };
 
 struct ipoib_neigh {

commit 12ed56bad92265c4430712afd8fa37090dd7888a
Author: Yuval Shaia <yuval.shaia@oracle.com>
Date:   Sun Apr 1 09:22:18 2018 +0300

    IB/ipoib: Delete unused struct
    
    This structure is not needed since the introduction of commit
    'c42687784b9a ("IB/ipoib: Scatter-Gather support in connected mode")'
    
    Signed-off-by: Yuval Shaia <yuval.shaia@oracle.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Reviewed-by: Zhu Yanjun <yanjun.zhu@oracle.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 8033a006277f..308e0ce49289 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -193,11 +193,6 @@ struct ipoib_tx_buf {
 	u64		mapping[MAX_SKB_FRAGS + 1];
 };
 
-struct ipoib_cm_tx_buf {
-	struct sk_buff *skb;
-	u64		mapping;
-};
-
 struct ib_cm_id;
 
 struct ipoib_cm_data {

commit b9595c5bac87af09cc3e82553244893b76632df6
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Thu Oct 19 07:56:44 2017 +0300

    IB/ipoib: Change number of TX wqe to 64
    
    NAPI budget is 64 packets, while maximum polling size for
    the send CQ is 16. Let's bring them in sync, so the NAPI
    budget will be reused completely.
    
    Cc: Kamal Heib <kamalh@mellanox.com>
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Reviewed-by: Alex Vesker <valex@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index b534d9412a1e..8033a006277f 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -111,7 +111,7 @@ enum {
 	IPOIB_MCAST_FLAG_BUSY	  = 2,
 	IPOIB_MCAST_FLAG_ATTACHED = 3,
 
-	MAX_SEND_CQE		  = 16,
+	MAX_SEND_CQE		  = 64,
 	IPOIB_CM_COPYBREAK	  = 256,
 
 	IPOIB_NON_CHILD		  = 0,

commit 8966e28d2e40cfc9f694bd02dabc49afb78d7160
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Thu Oct 19 07:56:43 2017 +0300

    IB/ipoib: Use NAPI in UD/TX flows
    
    Instead of explicit call to poll_cq of the tx ring, use the NAPI mechanism
    to handle the completions of each packet that has been sent to the HW.
    
    The next major changes were taken:
     * The driver init completion function in the creation of the send CQ,
       that function triggers the napi scheduling.
     * The driver uses CQ for RX for both modes UD and CM, and CQ for TX
       for CM and UD.
    
    Cc: Kamal Heib <kamalh@mellanox.com>
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Reviewed-by: Alex Vesker <valex@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 19c3ba2368d2..b534d9412a1e 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -331,7 +331,8 @@ struct ipoib_dev_priv {
 
 	struct net_device *dev;
 
-	struct napi_struct napi;
+	struct napi_struct send_napi;
+	struct napi_struct recv_napi;
 
 	unsigned long flags;
 
@@ -408,7 +409,6 @@ struct ipoib_dev_priv {
 #endif
 	u64	hca_caps;
 	struct ipoib_ethtool_st ethtool;
-	struct timer_list poll_timer;
 	unsigned max_send_sge;
 	bool sm_fullmember_sendonly_support;
 	const struct net_device_ops	*rn_ops;
@@ -475,9 +475,10 @@ extern struct workqueue_struct *ipoib_workqueue;
 
 /* functions */
 
-int ipoib_poll(struct napi_struct *napi, int budget);
-void ipoib_ib_completion(struct ib_cq *cq, void *dev_ptr);
-void ipoib_send_comp_handler(struct ib_cq *cq, void *dev_ptr);
+int ipoib_rx_poll(struct napi_struct *napi, int budget);
+int ipoib_tx_poll(struct napi_struct *napi, int budget);
+void ipoib_ib_rx_completion(struct ib_cq *cq, void *ctx_ptr);
+void ipoib_ib_tx_completion(struct ib_cq *cq, void *ctx_ptr);
 
 struct ipoib_ah *ipoib_create_ah(struct net_device *dev,
 				 struct ib_pd *pd, struct rdma_ah_attr *attr);

commit 2c104ea68350b7f49c4ae207afa6e7f7f5c81546
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Thu Oct 19 07:56:42 2017 +0300

    IB/ipoib: Get rid of the tx_outstanding variable in all modes
    
    The first step toward using NAPI in the UD/TX flow is to separate
    between two flows, the NAPI and the xmit, meaning no use of shared
    variables between both flows.
    
    This patch takes out the tx_outstanding variable that was used in both
    flows and instead the driver uses the 2 cyclic ring variables: tx_head
    and tx_tail, tx_head used in the xmit flow and tx_tail in the NAPI flow.
    
    Cc: Kamal Heib <kamalh@mellanox.com>
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Reviewed-by: Alex Vesker <valex@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 7cc2b755413d..19c3ba2368d2 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -381,7 +381,6 @@ struct ipoib_dev_priv {
 	unsigned	     tx_tail;
 	struct ib_sge	     tx_sge[MAX_SKB_FRAGS + 1];
 	struct ib_ud_wr      tx_wr;
-	unsigned	     tx_outstanding;
 	struct ib_wc	     send_wc[MAX_SEND_CQE];
 
 	struct ib_recv_wr    rx_wr;

commit 6d290d69ac52b3b311d2ef0da4825dc6f1ea8997
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Oct 4 17:45:54 2017 -0700

    IB/ipoib: Convert timers to use timer_setup()
    
    In preparation for unconditionally passing the struct timer_list pointer to
    all timer callbacks, switch to using the new timer_setup() and from_timer()
    to pass the timer pointer explicitly.
    
    Cc: Doug Ledford <dledford@redhat.com>
    Cc: Sean Hefty <sean.hefty@intel.com>
    Cc: Hal Rosenstock <hal.rosenstock@gmail.com>
    Cc: Leon Romanovsky <leon@kernel.org>
    Cc: Alex Vesker <valex@mellanox.com>
    Cc: Erez Shitrit <erezsh@mellanox.com>
    Cc: Zhu Yanjun <yanjun.zhu@oracle.com>
    Cc: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Cc: Paolo Abeni <pabeni@redhat.com>
    Cc: Ira Weiny <ira.weiny@intel.com>
    Cc: Yuval Shaia <yuval.shaia@oracle.com>
    Cc: linux-rdma@vger.kernel.org
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 4a5c7a07a631..7cc2b755413d 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -500,7 +500,7 @@ void ipoib_mark_paths_invalid(struct net_device *dev);
 void ipoib_flush_paths(struct net_device *dev);
 struct ipoib_dev_priv *ipoib_intf_alloc(struct ib_device *hca, u8 port,
 					const char *format);
-void ipoib_ib_tx_timer_func(unsigned long ctx);
+void ipoib_ib_tx_timer_func(struct timer_list *t);
 void ipoib_ib_dev_flush_light(struct work_struct *work);
 void ipoib_ib_dev_flush_normal(struct work_struct *work);
 void ipoib_ib_dev_flush_heavy(struct work_struct *work);

commit 69956d83267e29e38cda7d506c4085932789fef2
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Thu Aug 17 15:50:50 2017 +0300

    IB/ipoib: Sync between remove_one to sysfs calls that use rtnl_lock
    
    In order to avoid deadlock between sysfs functions (like create/delete
    child) and remove_one (both of them are using the sysfs lock and
    rtnl_lock) the driver will use a state mutex for sync.
    
    That will fix traces as the following:
    schedule+0x3e/0x90
    kernfs_drain+0x75/0xf0
    ? wait_woken+0x90/0x90
    __kernfs_remove+0x12e/0x1c0
    kernfs_remove+0x25/0x40
    sysfs_remove_dir+0x57/0x90
    kobject_del+0x22/0x60
    device_del+0x195/0x230
     pm_runtime_set_memalloc_noio+0xac/0xf0
    netdev_unregister_kobject+0x71/0x80
    rollback_registered_many+0x205/0x2f0
    rollback_registered+0x31/0x40
    unregister_netdevice_queue+0x58/0xb0
    unregister_netdev+0x20/0x30
    ipoib_remove_one+0xb7/0x240 [ib_ipoib]
    ib_unregister_device+0xbc/0x1b0 [ib_core]
    ib_unregister_mad_agent+0x29/0x30 [ib_core]
    mlx4_ib_remove+0x67/0x280 [mlx4_ib]
    INFO: task echo:24082 blocked for more than 120 seconds.
    Tainted: G           OE   4.1.12-37.5.1.el6uek.x86_64 #2
    "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this
    message.
    Call Trace:
    schedule+0x3e/0x90
    schedule_preempt_disabled+0xe/0x10
    __mutex_lock_slowpath+0x95/0x110
    ? _rcu_barrier+0x177/0x220
    mutex_lock+0x23/0x40
    rtnl_lock+0x15/0x20
    netdev_run_todo+0x81/0x1f0
    rtnl_unlock+0xe/0x10
    ipoib_vlan_delete+0x12f/0x1c0 [ib_ipoib]
    delete_child+0x69/0x80 [ib_ipoib]
    dev_attr_store+0x20/0x30
    sysfs_kf_write+0x41/0x50
    
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Reviewed-by: Alex Vesker <valex@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 16c1af1c706e..4a5c7a07a631 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -337,6 +337,7 @@ struct ipoib_dev_priv {
 
 	struct rw_semaphore vlan_rwsem;
 	struct mutex mcast_mutex;
+	struct mutex sysfs_mutex;
 
 	struct rb_root  path_tree;
 	struct list_head path_list;

commit b0e32e20e3c63778d8c20a40d8bec8b18baffecb
Merge: d3cf4d9915c4 870201f95fcb
Author: Doug Ledford <dledford@redhat.com>
Date:   Fri Aug 18 14:12:04 2017 -0400

    Merge branch 'k.o/for-4.13-rc' into k.o/for-next
    
    Merging our (hopefully) final -rc pull branch into our for-next branch
    because some of our pending patches won't apply cleanly without having
    the -rc patches in our tree.
    
    Signed-off-by: Doug Ledford <dledford@redhat.com>

commit 7e93e2cb835c4301663c1ac5e0135d2e06e1c5e8
Author: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
Date:   Thu Jun 8 13:37:45 2017 -0400

    IB/IPoIB: Increase local_lid to 32 bits
    
    IPoIB contains local_lid field which is 16 bits in
    length, increase it to 32 bits.
    
    Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Reviewed-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index ff50a7bd66d8..9e738104c2a1 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -366,7 +366,7 @@ struct ipoib_dev_priv {
 	u32		  qkey;
 
 	union ib_gid local_gid;
-	u16	     local_lid;
+	u32	     local_lid;
 
 	unsigned int admin_mtu;
 	unsigned int mcast_mtu;

commit edf3f301db7af7e784d06f7059dfc8a69359af13
Author: Feras Daoud <ferasda@mellanox.com>
Date:   Mon Jul 10 18:45:41 2017 +0300

    IB/ipoib: Fix race between light events and interface restart
    
    A potential race between light_event and interface restart
    may attach multicast group to an already attached QP.
    
    Scenario:
    light_event flow goes through ipoib_mcast_dev_flush function,
    if a context switch occurs before calling ipoib_mcast_remove_list,
    then we may face a situation where the broadcast of the priv is null
    and the corresponding QP is not detached yet.
    If an "interface restart" runs during the previous context switch,
    the following scenario occurs:
    When the device goes up, ipoib_ib_dev_up function will be called,
    it will send a new registration request to the broadcast group and then
    attach the group to the QP that was not detached before.
    
         IPOIB_FLUSH_LIGHT                                          INTERFACE RESTART
    
        __ipoib_ib_dev_flush                                                |
            |                                                               |
            |                                                               |
            |                                                               |
        ipoib_mcast_dev_flush                                               |
        Move mcast list and broadcast to remove_list                        |
            |                                                               |
            |                                                               |
        Context Switch-->                                                   |
            |                                                       ipoib_ib_dev_down
            |                                                               |
            |                                                               |
            |                                                       ipoib_ib_dev_up
            |                                                               |
            |                                                               |
            |                                                       ipoib_mcast_join_task
            |                                                       allocate new broadcast
            |                                                               |
            |                                                               |
            |                                                       Attach QP to multicast group
            |                                                               |
            |                                                               |
            |                                                       <--Context Switch
        ipoib_mcast_leave
        Detach QP from multicast group
    
    Signed-off-by: Feras Daoud <ferasda@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index ff50a7bd66d8..7ac25059c40f 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -336,6 +336,7 @@ struct ipoib_dev_priv {
 	unsigned long flags;
 
 	struct rw_semaphore vlan_rwsem;
+	struct mutex mcast_mutex;
 
 	struct rb_root  path_tree;
 	struct list_head path_list;

commit c2f8fc4ec4400901e5561d4815deca19f395deb6
Author: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
Date:   Thu Apr 27 19:05:58 2017 -0400

    IB/SA: Rename ib_sa_path_rec to sa_path_rec
    
    Rename ib_sa_path_rec to a more generic sa_path_rec.
    This is part of extending ib_sa to also support OPA
    path records in addition to the IB defined path records.
    
    Reviewed-by: Don Hiatt <don.hiatt@intel.com>
    Reviewed-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index fc9b0a3964f1..ff50a7bd66d8 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -423,7 +423,7 @@ struct ipoib_ah {
 
 struct ipoib_path {
 	struct net_device    *dev;
-	struct ib_sa_path_rec pathrec;
+	struct sa_path_rec pathrec;
 	struct ipoib_ah      *ah;
 	struct sk_buff_head   queue;
 

commit 90898850ec4e7b3ba0f9a35cc7169ff19ff367a6
Author: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
Date:   Sat Apr 29 14:41:18 2017 -0400

    IB/core: Rename struct ib_ah_attr to rdma_ah_attr
    
    This patch simply renames struct ib_ah_attr to
    rdma_ah_attr as these fields specify attributes that are
    not necessarily specific to IB.
    
    Reviewed-by: Ira Weiny <ira.weiny@intel.com>
    Reviewed-by: Don Hiatt <don.hiatt@intel.com>
    Reviewed-by: Niranjana Vishwanathapura <niranjana.vishwanathapura@intel.com>
    Reviewed-by: Sean Hefty <sean.hefty@intel.com>
    Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 7c8de226e7f7..fc9b0a3964f1 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -479,7 +479,7 @@ void ipoib_ib_completion(struct ib_cq *cq, void *dev_ptr);
 void ipoib_send_comp_handler(struct ib_cq *cq, void *dev_ptr);
 
 struct ipoib_ah *ipoib_create_ah(struct net_device *dev,
-				 struct ib_pd *pd, struct ib_ah_attr *attr);
+				 struct ib_pd *pd, struct rdma_ah_attr *attr);
 void ipoib_free_ah(struct kref *kref);
 static inline void ipoib_put_ah(struct ipoib_ah *ah)
 {

commit ee1c60b1bff8f258fa530def3459726f8e922caf
Author: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
Date:   Mon Mar 20 19:38:08 2017 -0400

    IB/SA: Modify SA to implicitly cache Class Port info
    
    SA will query and cache class port info as part of
    its initialization. SA will also invalidate and
    refresh the cache based on specific events. Callers such
    as IPoIB and CM can query the SA to get the classportinfo
    information. Apart from making the caller code much simpler,
    this change puts the onus on the SA to query and maintain
    classportinfo much like how it maitains the address handle to the SM.
    
    Reviewed-by: Ira Weiny <ira.weiny@intel.com>
    Reviewed-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 2ae1f0883c9b..7c8de226e7f7 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -496,7 +496,6 @@ void ipoib_reap_ah(struct work_struct *work);
 struct ipoib_path *__path_find(struct net_device *dev, void *gid);
 void ipoib_mark_paths_invalid(struct net_device *dev);
 void ipoib_flush_paths(struct net_device *dev);
-int ipoib_check_sm_sendonly_fullmember_support(struct ipoib_dev_priv *priv);
 struct ipoib_dev_priv *ipoib_intf_alloc(struct ib_device *hca, u8 port,
 					const char *format);
 void ipoib_ib_tx_timer_func(unsigned long ctx);

commit cd565b4b51e5fe258d6ce9ddc167ee51f3044ba5
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Mon Apr 10 11:22:30 2017 +0300

    IB/IPoIB: Support acceleration options callbacks
    
    IPoIB driver now uses the new set of callback functions.
    
    If the hardware provider supports the new ipoib_options implementation,
    the driver uses the callbacks in its data path flows, otherwise it uses the
    driver default implementation for all data flows in its code.
    
    The default implementation wasn't change and it is exactly as it was before
    introduction of acceleration support.
    
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Reviewed-by: Alex Vesker <valex@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 9a912830c8e0..2ae1f0883c9b 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -52,7 +52,6 @@
 #include <rdma/ib_pack.h>
 #include <rdma/ib_sa.h>
 #include <linux/sched.h>
-
 /* constants */
 
 enum ipoib_flush_level {
@@ -153,8 +152,12 @@ static inline void skb_add_pseudo_hdr(struct sk_buff *skb)
 	skb_pull(skb, IPOIB_HARD_LEN);
 }
 
-/* Keep the refactoring compile able */
-#define ipoib_priv netdev_priv
+static inline struct ipoib_dev_priv *ipoib_priv(const struct net_device *dev)
+{
+	struct rdma_netdev *rn = netdev_priv(dev);
+
+	return rn->clnt_priv;
+}
 
 /* Used for all multicast joins (broadcast, IPv4 mcast and IPv6 mcast) */
 struct ipoib_mcast {
@@ -407,6 +410,7 @@ struct ipoib_dev_priv {
 	struct timer_list poll_timer;
 	unsigned max_send_sge;
 	bool sm_fullmember_sendonly_support;
+	const struct net_device_ops	*rn_ops;
 };
 
 struct ipoib_ah {
@@ -485,16 +489,16 @@ int ipoib_open(struct net_device *dev);
 int ipoib_add_pkey_attr(struct net_device *dev);
 int ipoib_add_umcast_attr(struct net_device *dev);
 
-void ipoib_send(struct net_device *dev, struct sk_buff *skb,
-		struct ipoib_ah *address, u32 dqpn);
+int ipoib_send(struct net_device *dev, struct sk_buff *skb,
+	       struct ib_ah *address, u32 dqpn);
 void ipoib_reap_ah(struct work_struct *work);
 
 struct ipoib_path *__path_find(struct net_device *dev, void *gid);
 void ipoib_mark_paths_invalid(struct net_device *dev);
 void ipoib_flush_paths(struct net_device *dev);
 int ipoib_check_sm_sendonly_fullmember_support(struct ipoib_dev_priv *priv);
-struct ipoib_dev_priv *ipoib_intf_alloc(const char *format);
-
+struct ipoib_dev_priv *ipoib_intf_alloc(struct ib_device *hca, u8 port,
+					const char *format);
 void ipoib_ib_tx_timer_func(unsigned long ctx);
 void ipoib_ib_dev_flush_light(struct work_struct *work);
 void ipoib_ib_dev_flush_normal(struct work_struct *work);
@@ -502,8 +506,9 @@ void ipoib_ib_dev_flush_heavy(struct work_struct *work);
 void ipoib_pkey_event(struct work_struct *work);
 void ipoib_ib_dev_cleanup(struct net_device *dev);
 
-void ipoib_dev_uninit_default(struct net_device *dev);
+int ipoib_ib_dev_open_default(struct net_device *dev);
 int ipoib_ib_dev_open(struct net_device *dev);
+int ipoib_ib_dev_stop(struct net_device *dev);
 void ipoib_ib_dev_up(struct net_device *dev);
 void ipoib_ib_dev_down(struct net_device *dev);
 int ipoib_ib_dev_stop_default(struct net_device *dev);
@@ -566,8 +571,10 @@ void ipoib_path_iter_read(struct ipoib_path_iter *iter,
 			  struct ipoib_path *path);
 #endif
 
-int ipoib_mcast_attach(struct net_device *dev, u16 mlid,
-		       union ib_gid *mgid, int set_qkey);
+int ipoib_mcast_attach(struct net_device *dev, struct ib_device *hca,
+		       union ib_gid *mgid, u16 mlid, int set_qkey, u32 qkey);
+int ipoib_mcast_detach(struct net_device *dev, struct ib_device *hca,
+		       union ib_gid *mgid, u16 mlid);
 void ipoib_mcast_remove_list(struct list_head *remove_list);
 void ipoib_check_and_add_mcast_sendonly(struct ipoib_dev_priv *priv, u8 *mgid,
 				struct list_head *remove_list);
@@ -591,7 +598,7 @@ void __exit ipoib_netlink_fini(void);
 void ipoib_set_umcast(struct net_device *ndev, int umcast_val);
 int  ipoib_set_mode(struct net_device *dev, const char *buf);
 
-void ipoib_setup(struct net_device *dev);
+void ipoib_setup_common(struct net_device *dev);
 
 void ipoib_pkey_open(struct ipoib_dev_priv *priv);
 void ipoib_drain_cq(struct net_device *dev);

commit c1048aff7e62bc561603fd14ad84b975ad7085b6
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Mon Apr 10 11:22:29 2017 +0300

    IB/IPoIB: Use defined function for netdev_priv function
    
    Make ipoib_priv point to netdev_priv where the code calls netdev_priv.
    
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Reviewed-by: Alex Vesker <valex@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 353e34353b9f..9a912830c8e0 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -153,6 +153,9 @@ static inline void skb_add_pseudo_hdr(struct sk_buff *skb)
 	skb_pull(skb, IPOIB_HARD_LEN);
 }
 
+/* Keep the refactoring compile able */
+#define ipoib_priv netdev_priv
+
 /* Used for all multicast joins (broadcast, IPv4 mcast and IPv6 mcast) */
 struct ipoib_mcast {
 	struct ib_sa_mcmember_rec mcmember;
@@ -608,14 +611,14 @@ extern int ipoib_max_conn_qp;
 
 static inline int ipoib_cm_admin_enabled(struct net_device *dev)
 {
-	struct ipoib_dev_priv *priv = netdev_priv(dev);
+	struct ipoib_dev_priv *priv = ipoib_priv(dev);
 	return IPOIB_CM_SUPPORTED(dev->dev_addr) &&
 		test_bit(IPOIB_FLAG_ADMIN_CM, &priv->flags);
 }
 
 static inline int ipoib_cm_enabled(struct net_device *dev, u8 *hwaddr)
 {
-	struct ipoib_dev_priv *priv = netdev_priv(dev);
+	struct ipoib_dev_priv *priv = ipoib_priv(dev);
 	return IPOIB_CM_SUPPORTED(hwaddr) &&
 		test_bit(IPOIB_FLAG_ADMIN_CM, &priv->flags);
 }
@@ -638,13 +641,13 @@ static inline void ipoib_cm_set(struct ipoib_neigh *neigh, struct ipoib_cm_tx *t
 
 static inline int ipoib_cm_has_srq(struct net_device *dev)
 {
-	struct ipoib_dev_priv *priv = netdev_priv(dev);
+	struct ipoib_dev_priv *priv = ipoib_priv(dev);
 	return !!priv->cm.srq;
 }
 
 static inline unsigned int ipoib_cm_max_mtu(struct net_device *dev)
 {
-	struct ipoib_dev_priv *priv = netdev_priv(dev);
+	struct ipoib_dev_priv *priv = ipoib_priv(dev);
 	return priv->cm.max_cm_mtu;
 }
 

commit 10adcbd2d5a085dad89ca2857e436a907c435273
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Mon Apr 10 11:22:28 2017 +0300

    IB/IPoIB: Rename qpn to be dqpn in ipoib_send and post_send functions
    
    Change of function parameter name from qpn to be dqpn.
    
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Reviewed-by: Alex Vesker <valex@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 596c73d01add..353e34353b9f 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -483,7 +483,7 @@ int ipoib_add_pkey_attr(struct net_device *dev);
 int ipoib_add_umcast_attr(struct net_device *dev);
 
 void ipoib_send(struct net_device *dev, struct sk_buff *skb,
-		struct ipoib_ah *address, u32 qpn);
+		struct ipoib_ah *address, u32 dqpn);
 void ipoib_reap_ah(struct work_struct *work);
 
 struct ipoib_path *__path_find(struct net_device *dev, void *gid);

commit 7ce1a3ee02642a9677662d0786732027ff729cda
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Mon Apr 10 11:22:27 2017 +0300

    IB/IPoIB: Separate control from HW operation on ipoib_open/stop ndo
    
    This patch is preparing the netdev part at the IPoIB driver to be able
    to use the ipoib_options.
    
    It deals with the two flows from the .ndo: ipoib_open and ipoib_stop.
    
    The code is rearranged as follows:
     * All operations which deal with the hardware resources, (for example
       change QP state, post-receive etc.) are performed in one place.
     * All operations that are control oriented (like restart multicast task,
       start the reap_ah etc.) are performed in separate place.
    
    The functions that deal with the hardware resources now located at
    __ipoib_ib_dev_open for the ipoib_open flow and __ipoib_ib_dev_stop
    for ipoib_stop.
    
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Reviewed-by: Alex Vesker <valex@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index bc71a90c57e3..596c73d01add 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -503,7 +503,7 @@ void ipoib_dev_uninit_default(struct net_device *dev);
 int ipoib_ib_dev_open(struct net_device *dev);
 void ipoib_ib_dev_up(struct net_device *dev);
 void ipoib_ib_dev_down(struct net_device *dev);
-void ipoib_ib_dev_stop(struct net_device *dev);
+int ipoib_ib_dev_stop_default(struct net_device *dev);
 void ipoib_pkey_dev_check_presence(struct net_device *dev);
 
 int ipoib_dev_init(struct net_device *dev, struct ib_device *ca, int port);

commit 515ed4f3aab4e8a0855d0cdfd9753a419ccfb297
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Mon Apr 10 11:22:26 2017 +0300

    IB/IPoIB: Separate control and data related initializations
    
    This patch prepares init and teardown flows so we can call them
    through ipoib_options function pointers.
    
    It arranges that area of code as the following:
     * All operations which deal with the resource allocation/deletion
       are performed in one place.
     * All operations that are control oriented, meaning that they are not
       connected to a specific hardware, are performed in a separate place.
    
    The operations for allocation of hardware resources are now in the
    function ipoib_dev_init_default, and the deletion of all the resources
    are in ipoib_dev_uninit_default
    
    The only exception is the creation of the PD object,
    which is used both for resource allocation (create QP etc.)
    and for control flows like creating AH.
    
    It also does:
     * Move creation of rx_ring and tx_ring to be in the resources
       allocation area.
     * Move the function ipoib_ib_dev_open that does the open device
       to the control area instead of the dev_init which creates resources.
    
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Reviewed-by: Alex Vesker <valex@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index bed233bf45c3..bc71a90c57e3 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -492,13 +492,14 @@ void ipoib_flush_paths(struct net_device *dev);
 int ipoib_check_sm_sendonly_fullmember_support(struct ipoib_dev_priv *priv);
 struct ipoib_dev_priv *ipoib_intf_alloc(const char *format);
 
-int ipoib_ib_dev_init(struct net_device *dev, struct ib_device *ca, int port);
+void ipoib_ib_tx_timer_func(unsigned long ctx);
 void ipoib_ib_dev_flush_light(struct work_struct *work);
 void ipoib_ib_dev_flush_normal(struct work_struct *work);
 void ipoib_ib_dev_flush_heavy(struct work_struct *work);
 void ipoib_pkey_event(struct work_struct *work);
 void ipoib_ib_dev_cleanup(struct net_device *dev);
 
+void ipoib_dev_uninit_default(struct net_device *dev);
 int ipoib_ib_dev_open(struct net_device *dev);
 void ipoib_ib_dev_up(struct net_device *dev);
 void ipoib_ib_dev_down(struct net_device *dev);

commit 5c37077fd025c0fa3aa3ab2e6b607d653a4fc604
Author: Zhu Yanjun <yanjun.zhu@oracle.com>
Date:   Wed Jan 18 23:16:06 2017 -0500

    IB/ipoib: Remove the unnecessary error check
    
    The function ipoib_mcast_start_thread/ipoib_ib_dev_up always return zero.
    As such, in the function ipoib_open, err_stop will never be reached.
    So remove this err_stop and change the return type of the function
    ipoib_mcast_start_thread/ipoib_ib_dev_up to void.
    
    Signed-off-by: Zhu Yanjun <yanjun.zhu@oracle.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 6dac79454708..bed233bf45c3 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -500,7 +500,7 @@ void ipoib_pkey_event(struct work_struct *work);
 void ipoib_ib_dev_cleanup(struct net_device *dev);
 
 int ipoib_ib_dev_open(struct net_device *dev);
-int ipoib_ib_dev_up(struct net_device *dev);
+void ipoib_ib_dev_up(struct net_device *dev);
 void ipoib_ib_dev_down(struct net_device *dev);
 void ipoib_ib_dev_stop(struct net_device *dev);
 void ipoib_pkey_dev_check_presence(struct net_device *dev);
@@ -513,7 +513,7 @@ void ipoib_mcast_carrier_on_task(struct work_struct *work);
 void ipoib_mcast_send(struct net_device *dev, u8 *daddr, struct sk_buff *skb);
 
 void ipoib_mcast_restart_task(struct work_struct *work);
-int ipoib_mcast_start_thread(struct net_device *dev);
+void ipoib_mcast_start_thread(struct net_device *dev);
 int ipoib_mcast_stop_thread(struct net_device *dev);
 
 void ipoib_mcast_dev_down(struct net_device *dev);

commit dfc0e5550664a727a59921db7d9e7a41c21d03bb
Author: Zhu Yanjun <yanjun.zhu@oracle.com>
Date:   Thu Jan 12 02:39:01 2017 -0500

    IB/ipoib: function interface change
    
    The ipoib_ib_dev_down/ipoib_ib_dev_stop return zero unconditionally
    and the callers never check the returned values,
    change the return type to void and remove the redundant return values.
    
    Reviewed-by: Shan Hai <shan.hai@oracle.com>
    Signed-off-by: Zhu Yanjun <yanjun.zhu@oracle.com>
    Reviewed-by: Yuval Shaia <yuval.shaia@oracle.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index f5680642960a..6dac79454708 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -501,8 +501,8 @@ void ipoib_ib_dev_cleanup(struct net_device *dev);
 
 int ipoib_ib_dev_open(struct net_device *dev);
 int ipoib_ib_dev_up(struct net_device *dev);
-int ipoib_ib_dev_down(struct net_device *dev);
-int ipoib_ib_dev_stop(struct net_device *dev);
+void ipoib_ib_dev_down(struct net_device *dev);
+void ipoib_ib_dev_stop(struct net_device *dev);
 void ipoib_pkey_dev_check_presence(struct net_device *dev);
 
 int ipoib_dev_init(struct net_device *dev, struct ib_device *ca, int port);

commit f7534f45dcbc1a2ecb486b019db0443188e957d6
Author: Zhu Yanjun <yanjun.zhu@oracle.com>
Date:   Thu Jan 5 03:56:08 2017 -0500

    IB/ipoib: Remove unnecessary returned value check
    
    In the function ipoib_set_dev_features, the returned value is always 0.
    As such, it is not necessary to check the returned value.
    This is not a bug. It is a trivial problem.
    
    Reviewed-by: Guanglei Li <guanglei.li@oracle.com>
    Signed-off-by: Zhu Yanjun <yanjun.zhu@oracle.com>
    Reviewed-by: Yuval Shaia <yuval.shaia@oracle.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index da12717a3eb7..f5680642960a 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -593,7 +593,7 @@ void ipoib_pkey_open(struct ipoib_dev_priv *priv);
 void ipoib_drain_cq(struct net_device *dev);
 
 void ipoib_set_ethtool_ops(struct net_device *dev);
-int ipoib_set_dev_features(struct ipoib_dev_priv *priv, struct ib_device *hca);
+void ipoib_set_dev_features(struct ipoib_dev_priv *priv, struct ib_device *hca);
 
 #define IPOIB_FLAGS_RC		0x80
 #define IPOIB_FLAGS_UC		0x40

commit fc791b6335152c5278dc4a4991bcb2d329f806f9
Author: Paolo Abeni <pabeni@redhat.com>
Date:   Thu Oct 13 18:26:56 2016 +0200

    IB/ipoib: move back IB LL address into the hard header
    
    After the commit 9207f9d45b0a ("net: preserve IP control block
    during GSO segmentation"), the GSO CB and the IPoIB CB conflict.
    That destroy the IPoIB address information cached there,
    causing a severe performance regression, as better described here:
    
    http://marc.info/?l=linux-kernel&m=146787279825501&w=2
    
    This change moves the data cached by the IPoIB driver from the
    skb control lock into the IPoIB hard header, as done before
    the commit 936d7de3d736 ("IPoIB: Stop lying about hard_header_len
    and use skb->cb to stash LL addresses").
    In order to avoid GRO issue, on packet reception, the IPoIB driver
    stash into the skb a dummy pseudo header, so that the received
    packets have actually a hard header matching the declared length.
    To avoid changing the connected mode maximum mtu, the allocated
    head buffer size is increased by the pseudo header length.
    
    After this commit, IPoIB performances are back to pre-regression
    value.
    
    v2 -> v3: rebased
    v1 -> v2: avoid changing the max mtu, increasing the head buf size
    
    Fixes: 9207f9d45b0a ("net: preserve IP control block during GSO segmentation")
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 7b8d2d9e2263..da12717a3eb7 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -63,6 +63,8 @@ enum ipoib_flush_level {
 
 enum {
 	IPOIB_ENCAP_LEN		  = 4,
+	IPOIB_PSEUDO_LEN	  = 20,
+	IPOIB_HARD_LEN		  = IPOIB_ENCAP_LEN + IPOIB_PSEUDO_LEN,
 
 	IPOIB_UD_HEAD_SIZE	  = IB_GRH_BYTES + IPOIB_ENCAP_LEN,
 	IPOIB_UD_RX_SG		  = 2, /* max buffer needed for 4K mtu */
@@ -134,15 +136,21 @@ struct ipoib_header {
 	u16	reserved;
 };
 
-struct ipoib_cb {
-	struct qdisc_skb_cb	qdisc_cb;
-	u8			hwaddr[INFINIBAND_ALEN];
+struct ipoib_pseudo_header {
+	u8	hwaddr[INFINIBAND_ALEN];
 };
 
-static inline struct ipoib_cb *ipoib_skb_cb(const struct sk_buff *skb)
+static inline void skb_add_pseudo_hdr(struct sk_buff *skb)
 {
-	BUILD_BUG_ON(sizeof(skb->cb) < sizeof(struct ipoib_cb));
-	return (struct ipoib_cb *)skb->cb;
+	char *data = skb_push(skb, IPOIB_PSEUDO_LEN);
+
+	/*
+	 * only the ipoib header is present now, make room for a dummy
+	 * pseudo header and set skb field accordingly
+	 */
+	memset(data, 0, IPOIB_PSEUDO_LEN);
+	skb_reset_mac_header(skb);
+	skb_pull(skb, IPOIB_HARD_LEN);
 }
 
 /* Used for all multicast joins (broadcast, IPv4 mcast and IPv6 mcast) */

commit b9044ac8292fc94bee33f6f08acaed3ac55f0c75
Merge: 1fde76f173e4 2937f3757519
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Oct 9 17:04:33 2016 -0700

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma
    
    Pull main rdma updates from Doug Ledford:
     "This is the main pull request for the rdma stack this release.  The
      code has been through 0day and I had it tagged for linux-next testing
      for a couple days.
    
      Summary:
    
       - updates to mlx5
    
       - updates to mlx4 (two conflicts, both minor and easily resolved)
    
       - updates to iw_cxgb4 (one conflict, not so obvious to resolve,
         proper resolution is to keep the code in cxgb4_main.c as it is in
         Linus' tree as attach_uld was refactored and moved into
         cxgb4_uld.c)
    
       - improvements to uAPI (moved vendor specific API elements to uAPI
         area)
    
       - add hns-roce driver and hns and hns-roce ACPI reset support
    
       - conversion of all rdma code away from deprecated
         create_singlethread_workqueue
    
       - security improvement: remove unsafe ib_get_dma_mr (breaks lustre in
         staging)"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma: (75 commits)
      staging/lustre: Disable InfiniBand support
      iw_cxgb4: add fast-path for small REG_MR operations
      cxgb4: advertise support for FR_NSMR_TPTE_WR
      IB/core: correctly handle rdma_rw_init_mrs() failure
      IB/srp: Fix infinite loop when FMR sg[0].offset != 0
      IB/srp: Remove an unused argument
      IB/core: Improve ib_map_mr_sg() documentation
      IB/mlx4: Fix possible vl/sl field mismatch in LRH header in QP1 packets
      IB/mthca: Move user vendor structures
      IB/nes: Move user vendor structures
      IB/ocrdma: Move user vendor structures
      IB/mlx4: Move user vendor structures
      IB/cxgb4: Move user vendor structures
      IB/cxgb3: Move user vendor structures
      IB/mlx5: Move and decouple user vendor structures
      IB/{core,hw}: Add constant for node_desc
      ipoib: Make ipoib_warn ratelimited
      IB/mlx4/alias_GUID: Remove deprecated create_singlethread_workqueue
      IB/ipoib_verbs: Remove deprecated create_singlethread_workqueue
      IB/ipoib: Remove deprecated create_singlethread_workqueue
      ...

commit 32f7451d1c6214169848cfea331e2c9d4067a650
Author: kernel@kyup.com <kernel@kyup.com>
Date:   Mon Aug 8 17:14:22 2016 +0300

    ipoib: Make ipoib_warn ratelimited
    
    In certain cases it's possible to be flooded by warning messages. To
    cope with such situations make the ipoib_warn macro be ratelimited.
    To prevent accidental limiting of legitimate, bursty messages make
    the limit fairly liberal by allowing up to 100 messages in 10 seconds.
    
    Signed-off-by: Nikolay Borisov <kernel@kyup.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 4f7d9b48df64..7899167536e3 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -771,7 +771,13 @@ static inline void ipoib_unregister_debugfs(void) { }
 #define ipoib_printk(level, priv, format, arg...)	\
 	printk(level "%s: " format, ((struct ipoib_dev_priv *) priv)->dev->name , ## arg)
 #define ipoib_warn(priv, format, arg...)		\
-	ipoib_printk(KERN_WARNING, priv, format , ## arg)
+do {							\
+	static DEFINE_RATELIMIT_STATE(_rs,		\
+		10 * HZ /*10 seconds */,		\
+		100);		\
+	if (__ratelimit(&_rs))				\
+		ipoib_printk(KERN_WARNING, priv, format , ## arg);\
+} while (0)
 
 extern int ipoib_sendq_size;
 extern int ipoib_recvq_size;

commit 546481c2816ea3c061ee9d5658eb48070f69212e
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Sun Aug 28 10:58:31 2016 +0300

    IB/ipoib: Fix memory corruption in ipoib cm mode connect flow
    
    When a new CM connection is being requested, ipoib driver copies data
    from the path pointer in the CM/tx object, the path object might be
    invalid at the point and memory corruption will happened later when now
    the CM driver will try using that data.
    
    The next scenario demonstrates it:
            neigh_add_path --> ipoib_cm_create_tx -->
            queue_work (pointer to path is in the cm/tx struct)
            #while the work is still in the queue,
            #the port goes down and causes the ipoib_flush_paths:
            ipoib_flush_paths --> path_free --> kfree(path)
            #at this point the work scheduled starts.
            ipoib_cm_tx_start --> copy from the (invalid)path pointer:
            (memcpy(&pathrec, &p->path->pathrec, sizeof pathrec);)
             -> memory corruption.
    
    To fix that the driver now starts the CM/tx connection only if that
    specific path exists in the general paths database.
    This check is protected with the relevant locks, and uses the gid from
    the neigh member in the CM/tx object which is valid according to the ref
    count that was taken by the CM/tx.
    
    Fixes: 839fcaba35 ('IPoIB: Connected mode experimental support')
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 4f7d9b48df64..9dbfcc0ab577 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -478,6 +478,7 @@ void ipoib_send(struct net_device *dev, struct sk_buff *skb,
 		struct ipoib_ah *address, u32 qpn);
 void ipoib_reap_ah(struct work_struct *work);
 
+struct ipoib_path *__path_find(struct net_device *dev, void *gid);
 void ipoib_mark_paths_invalid(struct net_device *dev);
 void ipoib_flush_paths(struct net_device *dev);
 int ipoib_check_sm_sendonly_fullmember_support(struct ipoib_dev_priv *priv);

commit 198b12f77084244d310888dd5d643083cb5c2aa1
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Sat Jun 4 15:15:20 2016 +0300

    IB/IPoIB: Fix race between ipoib_remove_one to sysfs functions
    
    In ipoib_remove_one the driver holds the rtnl_lock and tries to do some
    operation like dev_change_flags or unregister_netdev, while sysfs
    callback like ipoib_vlan_delete holds sysfs mutex and tries to hold the
    rtnl_lock via rtnl_trylock() and restart_syscall() if the lock is not
    free, meanwhile ipoib_remove_one tries to get the sysfs lock in order to
    free its sysfs directory, and we will get  a->b, b->a deadlock.
    
        Trace like the following:
    
            schedule+0x37/0x80
            schedule_preempt_disabled+0xe/0x10
            __mutex_lock_slowpath+0xb5/0x120
            mutex_lock+0x23/0x40
            rtnl_lock+0x15/0x20
            netdev_run_todo+0x17c/0x320
            rtnl_unlock+0xe/0x10
            ipoib_vlan_delete+0x11b/0x1b0 [ib_ipoib]
            delete_child+0x54/0x80 [ib_ipoib]
            dev_attr_store+0x18/0x30
            sysfs_kf_write+0x37/0x40
            mutex_lock+0x16/0x40
            SyS_write+0x55/0xc0
            entry_SYSCALL_64_fastpath+0x16/0x75
        And
            schedule+0x37/0x80
            __kernfs_remove+0x1a8/0x260
            ? wake_atomic_t_function+0x60/0x60
            kernfs_remove+0x25/0x40
            sysfs_remove_dir+0x50/0x80
            kobject_del+0x18/0x50
            device_del+0x19f/0x260
            netdev_unregister_kobject+0x6a/0x80
            rollback_registered_many+0x1fd/0x340
            rollback_registered+0x3c/0x70
            unregister_netdevice_queue+0x55/0xc0
            unregister_netdev+0x20/0x30
            ipoib_remove_one+0x114/0x1b0 [ib_ipoib]
            ib_unregister_client+0x4a/0x170 [ib_core]
            ? find_module_all+0x71/0xa0
            ipoib_cleanup_module+0x10/0x94 [ib_ipoib]
            SyS_delete_module+0x1b5/0x210
            entry_SYSCALL_64_fastpath+0x16/0x75
    
    The fix is by checking the flag IPOIB_FLAG_INTF_ON_DESTROY in order to
    get out from the sysfs function.
    
    Fixes: 862096a8bbf8 ("IB/ipoib: Add more rtnl_link_ops callbacks")
    Fixes: 9baa0b036410 ("IB/ipoib: Add rtnl_link_ops support")
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index bab7db6fa9ab..4f7d9b48df64 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -94,6 +94,7 @@ enum {
 	IPOIB_NEIGH_TBL_FLUSH	  = 12,
 	IPOIB_FLAG_DEV_ADDR_SET	  = 13,
 	IPOIB_FLAG_DEV_ADDR_CTRL  = 14,
+	IPOIB_FLAG_GOING_DOWN	  = 15,
 
 	IPOIB_MAX_BACKOFF_SECONDS = 16,
 

commit 492a7e67ff83fc59adb768de25ccaecd33d46beb
Author: Mark Bloch <markb@mellanox.com>
Date:   Wed May 18 16:42:43 2016 +0300

    IB/IPoIB: Allow setting the device address
    
    In IB networks, and specifically in IPoIB/rdmacm traffic, the device
    address of an IPoIB interface is used as a means to exchange information
    between nodes needed for communication.
    
    Currently an IPoIB interface will always be created with a device
    address based on its node GUID without a way to change that.
    
    This change adds the ability to set the device address of an IPoIB
    interface by value. We use the set mac address ndo to do that.
    
    The flow should be broken down to two:
    1) The GID value is already in the GID table,
       in this case the interface will be able to set carrier up.
    
    2) The GID value is not yet in the GID table,
       in this case the interface won't try to join the multicast group
       and will wait (listen on GID_CHANGE event) until the GID is inserted.
    
    In order to track those changes, we add a new flag:
    * IPOIB_FLAG_DEV_ADDR_SET.
    
    When set, it means the dev_addr is a based on a value in the gid
    table. this bit will be cleared upon a dev_addr change triggered
    by the user and set after validation.
    
    Per IB spec the port GUID can't change if the module is loaded.
    port GUID is the basis for GID at index 0 which is the basis for
    the default device address of a ipoib interface.
    
    The issue is that there are devices that don't follow the spec,
    they change the port GUID while HCA is powered on, so in order
    not to break userspace applications. We need to check if the
    user wanted to control the device address and we assume that
    if he sets the device address back to be based on GID index 0,
    he no longer wishs to control it.
    
    In order to track this, we add an additional flag:
    * IPOIB_FLAG_DEV_ADDR_CTRL
    
    When setting the device address, there is no validation of the upper
    twelve bytes of the device address (flags, qpn, subnet prefix) as those
    bytes are not under the control of the user.
    
    Signed-off-by: Mark Bloch <markb@mellanox.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index c51f618f6120..bab7db6fa9ab 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -92,6 +92,8 @@ enum {
 	IPOIB_FLAG_UMCAST	  = 10,
 	IPOIB_STOP_NEIGH_GC	  = 11,
 	IPOIB_NEIGH_TBL_FLUSH	  = 12,
+	IPOIB_FLAG_DEV_ADDR_SET	  = 13,
+	IPOIB_FLAG_DEV_ADDR_CTRL  = 14,
 
 	IPOIB_MAX_BACKOFF_SECONDS = 16,
 

commit 3b56113016400a4e2b9870c368ebb8080cb5739b
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Wed May 25 22:02:07 2016 +0300

    IB/ipoib: Support SendOnlyFullMember MCG for SendOnly join
    
    Check (via an SA query) if the SM supports the new option for SendOnly
    multicast joins.
    If the SM supports that option it will use the new join state to create
    such multicast group.
    If SendOnlyFullMember is supported, we wouldn't use faked FullMember state
    join for SendOnly MCG, use the correct state if supported.
    
    This check is performed at every invocation of mcast_restart task, to be
    sure that the driver stays in sync with the current state of the SM.
    
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index caec8e9c4666..c51f618f6120 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -392,6 +392,7 @@ struct ipoib_dev_priv {
 	struct ipoib_ethtool_st ethtool;
 	struct timer_list poll_timer;
 	unsigned max_send_sge;
+	bool sm_fullmember_sendonly_support;
 };
 
 struct ipoib_ah {
@@ -476,6 +477,7 @@ void ipoib_reap_ah(struct work_struct *work);
 
 void ipoib_mark_paths_invalid(struct net_device *dev);
 void ipoib_flush_paths(struct net_device *dev);
+int ipoib_check_sm_sendonly_fullmember_support(struct ipoib_dev_priv *priv);
 struct ipoib_dev_priv *ipoib_intf_alloc(const char *format);
 
 int ipoib_ib_dev_init(struct net_device *dev, struct ib_device *ca, int port);

commit fb532d6a79b96a4c8f678024d7ed3549ff0ca916
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Tue Feb 23 10:25:25 2016 +0200

    IB/{core, ulp} Support above 32 possible device capability flags
    
    The old bitwise device_cap_flags variable was limited to u32 which
    has all bits already defined. In order to overcome it, we converted
    device_cap_flags variable to be u64 type.
    
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Reviewed-by: Matan Barak <matanb@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 85be0de3ab26..caec8e9c4666 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -388,7 +388,7 @@ struct ipoib_dev_priv {
 	struct dentry *mcg_dentry;
 	struct dentry *path_dentry;
 #endif
-	int	hca_caps;
+	u64	hca_caps;
 	struct ipoib_ethtool_st ethtool;
 	struct timer_list poll_timer;
 	unsigned max_send_sge;

commit 78a50a5e6068955494117b37b03379dacaf830b7
Author: Hans Westgaard Ry <hans.westgaard.ry@oracle.com>
Date:   Wed Mar 2 13:44:28 2016 +0100

    IB/ipoib: Add handling for sending of skb with many frags
    
    IPoIB converts skb-fragments to sge adding 1 extra sge when SG is enabled.
    Current codepath assumes that the max number of sge a device support
    is at least MAX_SKB_FRAGS+1, there is no interaction with upper layers
    to limit number of fragments in an skb if a device suports fewer
    sges. The assumptions also lead to requesting a fixed number of sge
    when IPoIB creates queue-pairs with SG enabled.
    
    A fallback/slowpath is implemented using skb_linearize to
    handle cases where the conversion would result in more sges than supported.
    
    Signed-off-by: Hans Westgaard Ry <hans.westgaard.ry@oracle.com>
    Reviewed-by: Håkon Bugge <haakon.bugge@oracle.com>
    Reviewed-by: Wei Lin Guay <wei.lin.guay@oracle.com>
    Reviewed-by: Yuval Shaia <yuval.shaia@oracle.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index a6f3eab0f350..85be0de3ab26 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -244,6 +244,7 @@ struct ipoib_cm_tx {
 	unsigned	     tx_tail;
 	unsigned long	     flags;
 	u32		     mtu;
+	unsigned             max_send_sge;
 };
 
 struct ipoib_cm_rx_buf {
@@ -390,6 +391,7 @@ struct ipoib_dev_priv {
 	int	hca_caps;
 	struct ipoib_ethtool_st ethtool;
 	struct timer_list poll_timer;
+	unsigned max_send_sge;
 };
 
 struct ipoib_ah {

commit 50be28de6febbec4535fad2cf0870afbc524e735
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Thu Jan 7 09:28:08 2016 +0200

    IB/IPoIB: Fix kernel panic on multicast flow
    
    ipoib_mcast_restart_task calls ipoib_mcast_remove_list with the
    parameter mcast->dev. That mcast is a temporary (used as an iterator)
    variable that may be uninitialized.
    There is no need to send the variable dev to the function, as each mcast
    has its dev as a member in the mcast struct.
    
    This causes the next panic:
    RIP: 0010: ipoib_mcast_leave+0x6d/0xf0 [ib_ipoib]
    RSP: 0018: EFLAGS: 00010246
    RAX: f0201 RBX: 24e00 RCX: 00000
    ....
    ....
    Stack:
    Call Trace:
            ipoib_mcast_remove_list+0x3a/0x70 [ib_ipoib]
            ipoib_mcast_restart_task+0x3bb/0x520 [ib_ipoib]
            process_one_work+0x164/0x470
            worker_thread+0x11d/0x420
            ...
    
    Fixes: 5a0e81f6f483 ('IB/IPoIB: factor out common multicast list removal code')
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Reported-by: Doron Tsur <doront@mellanox.com>
    Reviewed-by: Christoph Lameter <cl@linux.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index a924933d9340..a6f3eab0f350 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -548,7 +548,7 @@ void ipoib_path_iter_read(struct ipoib_path_iter *iter,
 
 int ipoib_mcast_attach(struct net_device *dev, u16 mlid,
 		       union ib_gid *mgid, int set_qkey);
-void ipoib_mcast_remove_list(struct net_device *dev, struct list_head *remove_list);
+void ipoib_mcast_remove_list(struct list_head *remove_list);
 void ipoib_check_and_add_mcast_sendonly(struct ipoib_dev_priv *priv, u8 *mgid,
 				struct list_head *remove_list);
 

commit 432c55fff402da3ad7716485e30e8c05010cfe68
Author: Christoph Lameter <cl@linux.com>
Date:   Mon Dec 21 08:42:54 2015 -0600

    IB/IPoIB: Move multicast specific code out of ipoib_main.c
    
    Code cleanup to move multicast specific code that checks for
    a sendonly join to ipoib_multicast.c. This allows the removal
    of the export of __ipoib_mcast_find().
    
    Signed-off-by: Christoph Lameter <cl@linux.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 989c40940598..a924933d9340 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -549,7 +549,8 @@ void ipoib_path_iter_read(struct ipoib_path_iter *iter,
 int ipoib_mcast_attach(struct net_device *dev, u16 mlid,
 		       union ib_gid *mgid, int set_qkey);
 void ipoib_mcast_remove_list(struct net_device *dev, struct list_head *remove_list);
-struct ipoib_mcast *__ipoib_mcast_find(struct net_device *dev, void *mgid);
+void ipoib_check_and_add_mcast_sendonly(struct ipoib_dev_priv *priv, u8 *mgid,
+				struct list_head *remove_list);
 
 int ipoib_init_qp(struct net_device *dev);
 int ipoib_transport_dev_init(struct net_device *dev, struct ib_device *ca);

commit 5a0e81f6f4838816a265b948a6439c9fcd76b017
Author: Christoph Lameter <cl@linux.com>
Date:   Mon Dec 21 08:42:53 2015 -0600

    IB/IPoIB: factor out common multicast list removal code
    
    Code cleanup to remove multicast specific code from ipoib_main.c
    
    The removal of a list of multicast groups occurs in three places.
    Create a new function ipoib_mcast_remove_list(). Use this new
    function in ipoib_main.c too.
    That in turn allows the dropping of two functions that were
    exported from ipoib_multicast.c for expiration of mc groups.
    
    Reviewed-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Christoph Lameter <cl@linux.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 3ede10309754..989c40940598 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -495,7 +495,6 @@ void ipoib_dev_cleanup(struct net_device *dev);
 void ipoib_mcast_join_task(struct work_struct *work);
 void ipoib_mcast_carrier_on_task(struct work_struct *work);
 void ipoib_mcast_send(struct net_device *dev, u8 *daddr, struct sk_buff *skb);
-void ipoib_mcast_free(struct ipoib_mcast *mc);
 
 void ipoib_mcast_restart_task(struct work_struct *work);
 int ipoib_mcast_start_thread(struct net_device *dev);
@@ -549,7 +548,7 @@ void ipoib_path_iter_read(struct ipoib_path_iter *iter,
 
 int ipoib_mcast_attach(struct net_device *dev, u16 mlid,
 		       union ib_gid *mgid, int set_qkey);
-int ipoib_mcast_leave(struct net_device *dev, struct ipoib_mcast *mcast);
+void ipoib_mcast_remove_list(struct net_device *dev, struct list_head *remove_list);
 struct ipoib_mcast *__ipoib_mcast_find(struct net_device *dev, void *mgid);
 
 int ipoib_init_qp(struct net_device *dev);

commit 63e8790d39a2d7c9a0ebeab987a6033d184bc6ba
Merge: 95893dde99d9 eb14ab3ba140
Author: Doug Ledford <dledford@redhat.com>
Date:   Wed Oct 28 22:23:34 2015 -0400

    Merge branch 'wr-cleanup' into k.o/for-4.4

commit 0b5c9279e568d90903acedc2b9b832d8d78e8288
Author: Christoph Lameter <cl@linux.com>
Date:   Sun Oct 11 18:49:42 2015 -0500

    IB/ipoib: For sendonly join free the multicast group on leave
    
    When we leave the multicast group on expiration of a neighbor we
    do not free the mcast structure. This results in a memory leak
    that causes ib_dealloc_pd to fail and print a WARN_ON message
    and backtrace.
    
    Fixes: bd99b2e05c4d (IB/ipoib: Expire sendonly multicast joins)
    Signed-off-by: Christoph Lameter <cl@linux.com>
    Tested-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 4cd5428a2399..edc5b8565d6d 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -495,6 +495,7 @@ void ipoib_dev_cleanup(struct net_device *dev);
 void ipoib_mcast_join_task(struct work_struct *work);
 void ipoib_mcast_carrier_on_task(struct work_struct *work);
 void ipoib_mcast_send(struct net_device *dev, u8 *daddr, struct sk_buff *skb);
+void ipoib_mcast_free(struct ipoib_mcast *mc);
 
 void ipoib_mcast_restart_task(struct work_struct *work);
 int ipoib_mcast_start_thread(struct net_device *dev);

commit e622f2f4ad2142d2a613a57fb85f8cf737935ef5
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Oct 8 09:16:33 2015 +0100

    IB: split struct ib_send_wr
    
    This patch split up struct ib_send_wr so that all non-trivial verbs
    use their own structure which embedds struct ib_send_wr.  This dramaticly
    shrinks the size of a WR for most common operations:
    
    sizeof(struct ib_send_wr) (old):        96
    
    sizeof(struct ib_send_wr):              48
    sizeof(struct ib_rdma_wr):              64
    sizeof(struct ib_atomic_wr):            96
    sizeof(struct ib_ud_wr):                88
    sizeof(struct ib_fast_reg_wr):          88
    sizeof(struct ib_bind_mw_wr):           96
    sizeof(struct ib_sig_handover_wr):      80
    
    And with Sagi's pending MR rework the fast registration WR will also be
    down to a reasonable size:
    
    sizeof(struct ib_fastreg_wr):           64
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Bart Van Assche <bart.vanassche@sandisk.com> [srp, srpt]
    Reviewed-by: Chuck Lever <chuck.lever@oracle.com> [sunrpc]
    Tested-by: Haggai Eran <haggaie@mellanox.com>
    Tested-by: Sagi Grimberg <sagig@mellanox.com>
    Tested-by: Steve Wise <swise@opengridcomputing.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 4cd5428a2399..453860ade65e 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -360,7 +360,7 @@ struct ipoib_dev_priv {
 	unsigned	     tx_head;
 	unsigned	     tx_tail;
 	struct ib_sge	     tx_sge[MAX_SKB_FRAGS + 1];
-	struct ib_send_wr    tx_wr;
+	struct ib_ud_wr      tx_wr;
 	unsigned	     tx_outstanding;
 	struct ib_wc	     send_wc[MAX_SEND_CQE];
 
@@ -527,7 +527,7 @@ static inline void ipoib_build_sge(struct ipoib_dev_priv *priv,
 		priv->tx_sge[i + off].addr = mapping[i + off];
 		priv->tx_sge[i + off].length = skb_frag_size(&frags[i]);
 	}
-	priv->tx_wr.num_sge	     = nr_frags + off;
+	priv->tx_wr.wr.num_sge	     = nr_frags + off;
 }
 
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG

commit 2866196f294954ce9fa226825c8c1eaa64c7da8a
Author: Doug Ledford <dledford@redhat.com>
Date:   Fri Sep 25 22:30:24 2015 -0400

    IB/ipoib: increase the max mcast backlog queue
    
    When performing sendonly joins, we queue the packets that trigger
    the join until the join completes.  This may take on the order of
    hundreds of milliseconds.  It is easy to have many more than three
    packets come in during that time.  Expand the maximum queue depth
    in order to try and prevent dropped packets during the time it
    takes to join the multicast group.
    
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 4ff4e5290354..4cd5428a2399 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -80,7 +80,7 @@ enum {
 	IPOIB_NUM_WC		  = 4,
 
 	IPOIB_MAX_PATH_REC_QUEUE  = 3,
-	IPOIB_MAX_MCAST_QUEUE	  = 3,
+	IPOIB_MAX_MCAST_QUEUE	  = 64,
 
 	IPOIB_FLAG_OPER_UP	  = 0,
 	IPOIB_FLAG_INITIALIZED	  = 1,

commit bd99b2e05c4df2a428e5c9dd338289089d0e26df
Author: Christoph Lameter <cl@linux.com>
Date:   Thu Sep 24 12:00:05 2015 -0500

    IB/ipoib: Expire sendonly multicast joins
    
    On neighbor expiration, check to see if the neighbor was actually a
    sendonly multicast join, and if so, leave the multicast group as we
    expire the neighbor.
    
    Signed-off-by: Christoph Lameter <cl@linux.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index ca2873698d75..4ff4e5290354 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -548,6 +548,8 @@ void ipoib_path_iter_read(struct ipoib_path_iter *iter,
 
 int ipoib_mcast_attach(struct net_device *dev, u16 mlid,
 		       union ib_gid *mgid, int set_qkey);
+int ipoib_mcast_leave(struct net_device *dev, struct ipoib_mcast *mcast);
+struct ipoib_mcast *__ipoib_mcast_find(struct net_device *dev, void *mgid);
 
 int ipoib_init_qp(struct net_device *dev);
 int ipoib_transport_dev_init(struct net_device *dev, struct ib_device *ca);

commit 77b1f99660ed60694e1d0e3a63096c1f252debfd
Author: Jason Gunthorpe <jgunthorpe@obsidianresearch.com>
Date:   Thu Jul 30 17:22:17 2015 -0600

    IB/ipoib: Remove ib_get_dma_mr calls
    
    The pd now has a local_dma_lkey member which completely replaces
    ib_get_dma_mr, use it instead.
    
    Signed-off-by: Jason Gunthorpe <jgunthorpe@obsidianresearch.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 79859c4d43c9..ca2873698d75 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -342,7 +342,6 @@ struct ipoib_dev_priv {
 	u16		  pkey;
 	u16		  pkey_index;
 	struct ib_pd	 *pd;
-	struct ib_mr	 *mr;
 	struct ib_cq	 *recv_cq;
 	struct ib_cq	 *send_cq;
 	struct ib_qp	 *qp;

commit c42687784b9a6b9733fee701ed236a5fe088fac4
Author: Yuval Shaia <yuval.shaia@oracle.com>
Date:   Sun Jul 12 01:24:09 2015 -0700

    IB/ipoib: Scatter-Gather support in connected mode
    
    By default, IPoIB-CM driver uses 64k MTU. Larger MTU gives better
    performance.
    This MTU plus overhead puts the memory allocation for IP based packets at
    32 4k pages (order 5), which have to be contiguous.
    When the system memory under pressure, it was observed that allocating 128k
    contiguous physical memory is difficult and causes serious errors (such as
    system becomes unusable).
    
    This enhancement resolve the issue by removing the physically contiguous
    memory requirement using Scatter/Gather feature that exists in Linux stack.
    
    With this fix Scatter-Gather will be supported also in connected mode.
    
    This change reverts some of the change made in commit e112373fd6aa
    ("IPoIB/cm: Reduce connected mode TX object size").
    
    The ability to use SG in IPoIB CM is possible because the coupling
    between NETIF_F_SG and NETIF_F_CSUM was removed in commit
    ec5f06156423 ("net: Kill link between CSUM and SG features.")
    
    Signed-off-by: Yuval Shaia <yuval.shaia@oracle.com>
    Acked-by: Christian Marie <christian@ponies.io>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index bd94b0a6e9e5..79859c4d43c9 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -239,7 +239,7 @@ struct ipoib_cm_tx {
 	struct net_device   *dev;
 	struct ipoib_neigh  *neigh;
 	struct ipoib_path   *path;
-	struct ipoib_cm_tx_buf *tx_ring;
+	struct ipoib_tx_buf *tx_ring;
 	unsigned	     tx_head;
 	unsigned	     tx_tail;
 	unsigned long	     flags;
@@ -504,6 +504,33 @@ int ipoib_mcast_stop_thread(struct net_device *dev);
 void ipoib_mcast_dev_down(struct net_device *dev);
 void ipoib_mcast_dev_flush(struct net_device *dev);
 
+int ipoib_dma_map_tx(struct ib_device *ca, struct ipoib_tx_buf *tx_req);
+void ipoib_dma_unmap_tx(struct ipoib_dev_priv *priv,
+			struct ipoib_tx_buf *tx_req);
+
+static inline void ipoib_build_sge(struct ipoib_dev_priv *priv,
+				   struct ipoib_tx_buf *tx_req)
+{
+	int i, off;
+	struct sk_buff *skb = tx_req->skb;
+	skb_frag_t *frags = skb_shinfo(skb)->frags;
+	int nr_frags = skb_shinfo(skb)->nr_frags;
+	u64 *mapping = tx_req->mapping;
+
+	if (skb_headlen(skb)) {
+		priv->tx_sge[0].addr         = mapping[0];
+		priv->tx_sge[0].length       = skb_headlen(skb);
+		off = 1;
+	} else
+		off = 0;
+
+	for (i = 0; i < nr_frags; ++i) {
+		priv->tx_sge[i + off].addr = mapping[i + off];
+		priv->tx_sge[i + off].length = skb_frag_size(&frags[i]);
+	}
+	priv->tx_wr.num_sge	     = nr_frags + off;
+}
+
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
 struct ipoib_mcast_iter *ipoib_mcast_iter_init(struct net_device *dev);
 int ipoib_mcast_iter_next(struct ipoib_mcast_iter *iter);

commit 0e5544d9bff432bfcac49ecf237738cc7cf3d032
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Thu Apr 2 13:39:04 2015 +0300

    IB/ipoib: Remove IPOIB_MCAST_RUN bit
    
    After Doug Ledford's changes there is no need in that bit, it's
    semantic becomes subset of the IPOIB_FLAG_OPER_UP bit.
    
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 2703d9a3e9b4..bd94b0a6e9e5 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -87,7 +87,6 @@ enum {
 	IPOIB_FLAG_ADMIN_UP	  = 2,
 	IPOIB_PKEY_ASSIGNED	  = 3,
 	IPOIB_FLAG_SUBINTERFACE	  = 5,
-	IPOIB_MCAST_RUN		  = 6,
 	IPOIB_STOP_REAPER	  = 7,
 	IPOIB_FLAG_ADMIN_CM	  = 9,
 	IPOIB_FLAG_UMCAST	  = 10,

commit 2c0107309550b332f83f8be366521557f4b3fd5a
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Thu Apr 2 13:39:02 2015 +0300

    IB/ipoib: Handle QP in SQE state
    
    As the result of a completion error the QP can moved to SQE state by
    the hardware. Since it's not the Error state, there are no flushes
    and hence the driver doesn't know about that.
    
    The fix creates a task that after completion with error which is not a
    flush tracks the QP state and if it is in SQE state moves it back to RTS.
    
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 769044c25ca5..2703d9a3e9b4 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -299,6 +299,11 @@ struct ipoib_neigh_table {
 	struct completion		deleted;
 };
 
+struct ipoib_qp_state_validate {
+	struct work_struct work;
+	struct ipoib_dev_priv   *priv;
+};
+
 /*
  * Device private locking: network stack tx_lock protects members used
  * in TX fast path, lock protects everything else.  lock nests inside

commit a44878d100630a34a44f54960115b81e449858db
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Thu Apr 2 13:39:00 2015 +0300

    IB/ipoib: Use one linear skb in RX flow
    
    The current code in the RX flow uses two sg entries for each incoming
    packet, the first one was for the IB headers and the second for the rest
    of the data, that causes two  dma map/unmap and two allocations, and few
    more actions that were done at the data path.
    
    Use only one linear skb on each incoming packet, for the data (IB
    headers and payload), that reduces the packet processing in the
    data-path (only one skb, no frags, the first frag was not used anyway,
    less memory allocations) and the dma handling (only one dma map/unmap
    over each incoming packet instead of two map/unmap per each incoming packet).
    
    After commit 73d3fe6d1c6d ("gro: fix aggregation for skb using frag_list") from
    Eric Dumazet, we will get full aggregation for large packets.
    
    When running bandwidth tests before and after the (over the card's numa node),
    using "netperf -H 1.1.1.3 -T -t TCP_STREAM", the results before are ~12Gbs before
    and after ~16Gbs on my setup (Mellanox's ConnectX3).
    
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index c79dcd5ee8ad..769044c25ca5 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -434,11 +434,6 @@ struct ipoib_neigh {
 #define IPOIB_UD_MTU(ib_mtu)		(ib_mtu - IPOIB_ENCAP_LEN)
 #define IPOIB_UD_BUF_SIZE(ib_mtu)	(ib_mtu + IB_GRH_BYTES)
 
-static inline int ipoib_ud_need_sg(unsigned int ib_mtu)
-{
-	return IPOIB_UD_BUF_SIZE(ib_mtu) > PAGE_SIZE;
-}
-
 void ipoib_neigh_dtor(struct ipoib_neigh *neigh);
 static inline void ipoib_neigh_put(struct ipoib_neigh *neigh)
 {

commit 69911416d87d6673c48d23a9fbc060e85f41fc73
Author: Doug Ledford <dledford@redhat.com>
Date:   Sat Feb 21 19:27:05 2015 -0500

    IB/ipoib: fix MCAST_FLAG_BUSY usage
    
    Commit a9c8ba5884 ("IPoIB: Fix usage of uninitialized multicast
    objects") added a new flag MCAST_JOIN_STARTED, but was not very strict
    in how it was used.  We didn't always initialize the completion struct
    before we set the flag, and we didn't always call complete on the
    completion struct from all paths that complete it.  And when we did
    complete it, sometimes we continued to touch the mcast entry after
    the completion, opening us up to possible use after free issues.
    
    This made it less than totally effective, and certainly made its use
    confusing.  And in the flush function we would use the presence of this
    flag to signal that we should wait on the completion struct, but we never
    cleared this flag, ever.
    
    In order to make things clearer and aid in resolving the rtnl deadlock
    bug I've been chasing, I cleaned this up a bit.
    
     1) Remove the MCAST_JOIN_STARTED flag entirely
     2) Change MCAST_FLAG_BUSY so it now only means a join is in-flight
     3) Test mcast->mc directly to see if we have completed
        ib_sa_join_multicast (using IS_ERR_OR_NULL)
     4) Make sure that before setting MCAST_FLAG_BUSY we always initialize
        the mcast->done completion struct
     5) Make sure that before calling complete(&mcast->done), we always clear
        the MCAST_FLAG_BUSY bit
     6) Take the mcast_mutex before we call ib_sa_multicast_join and also
        take the mutex in our join callback.  This forces
        ib_sa_multicast_join to return and set mcast->mc before we process
        the callback.  This way, our callback can safely clear mcast->mc
        if there is an error on the join and we will do the right thing as
        a result in mcast_dev_flush.
     7) Because we need the mutex to synchronize mcast->mc, we can no
        longer call mcast_sendonly_join directly from mcast_send and
        instead must add sendonly join processing to the mcast_join_task
     8) Make MCAST_RUN mean that we have a working mcast subsystem, not that
        we have a running task.  We know when we need to reschedule our
        join task thread and don't need a flag to tell us.
     9) Add a helper for rescheduling the join task thread
    
    A number of different races are resolved with these changes.  These
    races existed with the old MCAST_FLAG_BUSY usage, the
    MCAST_JOIN_STARTED flag was an attempt to address them, and while it
    helped, a determined effort could still trip things up.
    
    One race looks something like this:
    
    Thread 1                             Thread 2
    ib_sa_join_multicast (as part of running restart mcast task)
      alloc member
      call callback
                                         ifconfig ib0 down
                                         wait_for_completion
        callback call completes
                                         wait_for_completion in
                                         mcast_dev_flush completes
                                           mcast->mc is PTR_ERR_OR_NULL
                                           so we skip ib_sa_leave_multicast
        return from callback
      return from ib_sa_join_multicast
    set mcast->mc = return from ib_sa_multicast
    
    We now have a permanently unbalanced join/leave issue that trips up the
    refcounting in core/multicast.c
    
    Another like this:
    
    Thread 1                   Thread 2         Thread 3
    ib_sa_multicast_join
                                                ifconfig ib0 down
                                                priv->broadcast = NULL
                               join_complete
                                                wait_for_completion
                               mcast->mc is not yet set, so don't clear
    return from ib_sa_join_multicast and set mcast->mc
                               complete
                               return -EAGAIN (making mcast->mc invalid)
                                                call ib_sa_multicast_leave
                                                on invalid mcast->mc, hang
                                                forever
    
    By holding the mutex around ib_sa_multicast_join and taking the mutex
    early in the callback, we force mcast->mc to be valid at the time we
    run the callback.  This allows us to clear mcast->mc if there is an
    error and the join is going to fail.  We do this before we complete
    the mcast.  In this way, mcast_dev_flush always sees consistent state
    in regards to mcast->mc membership at the time that the
    wait_for_completion() returns.
    
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 9ef432ae72e8..c79dcd5ee8ad 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -98,9 +98,15 @@ enum {
 
 	IPOIB_MCAST_FLAG_FOUND	  = 0,	/* used in set_multicast_list */
 	IPOIB_MCAST_FLAG_SENDONLY = 1,
-	IPOIB_MCAST_FLAG_BUSY	  = 2,	/* joining or already joined */
+	/*
+	 * For IPOIB_MCAST_FLAG_BUSY
+	 * When set, in flight join and mcast->mc is unreliable
+	 * When clear and mcast->mc IS_ERR_OR_NULL, need to restart or
+	 *   haven't started yet
+	 * When clear and mcast->mc is valid pointer, join was successful
+	 */
+	IPOIB_MCAST_FLAG_BUSY	  = 2,
 	IPOIB_MCAST_FLAG_ATTACHED = 3,
-	IPOIB_MCAST_JOIN_STARTED  = 4,
 
 	MAX_SEND_CQE		  = 16,
 	IPOIB_CM_COPYBREAK	  = 256,
@@ -148,6 +154,7 @@ struct ipoib_mcast {
 
 	unsigned long created;
 	unsigned long backoff;
+	unsigned long delay_until;
 
 	unsigned long flags;
 	unsigned char logcount;

commit efc82eeeae4ece716091d8540079b7f276ca1ad5
Author: Doug Ledford <dledford@redhat.com>
Date:   Sat Feb 21 19:27:04 2015 -0500

    IB/ipoib: No longer use flush as a parameter
    
    Various places in the IPoIB code had a deadlock related to flushing
    the ipoib workqueue.  Now that we have per device workqueues and a
    specific flush workqueue, there is no longer a deadlock issue with
    flushing the device specific workqueues and we can do so unilaterally.
    
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index e940cd9f8471..9ef432ae72e8 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -478,10 +478,10 @@ void ipoib_ib_dev_flush_heavy(struct work_struct *work);
 void ipoib_pkey_event(struct work_struct *work);
 void ipoib_ib_dev_cleanup(struct net_device *dev);
 
-int ipoib_ib_dev_open(struct net_device *dev, int flush);
+int ipoib_ib_dev_open(struct net_device *dev);
 int ipoib_ib_dev_up(struct net_device *dev);
-int ipoib_ib_dev_down(struct net_device *dev, int flush);
-int ipoib_ib_dev_stop(struct net_device *dev, int flush);
+int ipoib_ib_dev_down(struct net_device *dev);
+int ipoib_ib_dev_stop(struct net_device *dev);
 void ipoib_pkey_dev_check_presence(struct net_device *dev);
 
 int ipoib_dev_init(struct net_device *dev, struct ib_device *ca, int port);
@@ -493,7 +493,7 @@ void ipoib_mcast_send(struct net_device *dev, u8 *daddr, struct sk_buff *skb);
 
 void ipoib_mcast_restart_task(struct work_struct *work);
 int ipoib_mcast_start_thread(struct net_device *dev);
-int ipoib_mcast_stop_thread(struct net_device *dev, int flush);
+int ipoib_mcast_stop_thread(struct net_device *dev);
 
 void ipoib_mcast_dev_down(struct net_device *dev);
 void ipoib_mcast_dev_flush(struct net_device *dev);

commit 0b39578bcde4298a392fb2df16235c316d932127
Author: Doug Ledford <dledford@redhat.com>
Date:   Sat Feb 21 19:27:03 2015 -0500

    IB/ipoib: Use dedicated workqueues per interface
    
    During my recent work on the rtnl lock deadlock in the IPoIB driver, I
    saw that even once I fixed the apparent races for a single device, as
    soon as that device had any children, new races popped up.  It turns
    out that this is because no matter how well we protect against races
    on a single device, the fact that all devices use the same workqueue,
    and flush_workqueue() flushes *everything* from that workqueue means
    that we would also have to prevent all races between different devices
    (for instance, ipoib_mcast_restart_task on interface ib0 can race with
    ipoib_mcast_flush_dev on interface ib0.8002, resulting in a deadlock on
    the rtnl_lock).
    
    There are several possible solutions to this problem:
    
    Make carrier_on_task and mcast_restart_task try to take the rtnl for
    some set period of time and if they fail, then bail.  This runs the
    real risk of dropping work on the floor, which can end up being its
    own separate kind of deadlock.
    
    Set some global flag in the driver that says some device is in the
    middle of going down, letting all tasks know to bail.  Again, this can
    drop work on the floor.
    
    Or the method this patch attempts to use, which is when we bring an
    interface up, create a workqueue specifically for that interface, so
    that when we take it back down, we are flushing only those tasks
    associated with our interface.  In addition, keep the global
    workqueue, but now limit it to only flush tasks.  In this way, the
    flush tasks can always flush the device specific work queues without
    having deadlock issues.
    
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index d7562beb5423..e940cd9f8471 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -317,6 +317,7 @@ struct ipoib_dev_priv {
 	struct list_head multicast_list;
 	struct rb_root multicast_tree;
 
+	struct workqueue_struct *wq;
 	struct delayed_work mcast_task;
 	struct work_struct carrier_on_task;
 	struct work_struct flush_light;

commit e7a623d2df28a477efb6cf60471a4e2225e2e8e4
Author: Roland Dreier <roland@purestorage.com>
Date:   Fri Jan 30 15:39:20 2015 -0800

    Revert "IPoIB: fix MCAST_FLAG_BUSY usage"
    
    This reverts commit 016d9fb25cd9817ea9c723f4f7ecd978636b4489.
    
    The series of IPoIB bug fixes that went into 3.19-rc1 introduce
    regressions, and after trying to sort things out, we decided to revert
    to 3.18's IPoIB driver and get things right for 3.20.
    
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index f4c1b20b23b2..d7562beb5423 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -98,15 +98,9 @@ enum {
 
 	IPOIB_MCAST_FLAG_FOUND	  = 0,	/* used in set_multicast_list */
 	IPOIB_MCAST_FLAG_SENDONLY = 1,
-	/*
-	 * For IPOIB_MCAST_FLAG_BUSY
-	 * When set, in flight join and mcast->mc is unreliable
-	 * When clear and mcast->mc IS_ERR_OR_NULL, need to restart or
-	 *   haven't started yet
-	 * When clear and mcast->mc is valid pointer, join was successful
-	 */
-	IPOIB_MCAST_FLAG_BUSY	  = 2,
+	IPOIB_MCAST_FLAG_BUSY	  = 2,	/* joining or already joined */
 	IPOIB_MCAST_FLAG_ATTACHED = 3,
+	IPOIB_MCAST_JOIN_STARTED  = 4,
 
 	MAX_SEND_CQE		  = 16,
 	IPOIB_CM_COPYBREAK	  = 256,

commit 0306eda2269f961d77c09b1badc0031438c21f44
Author: Roland Dreier <roland@purestorage.com>
Date:   Fri Jan 30 15:38:55 2015 -0800

    Revert "IPoIB: Use dedicated workqueues per interface"
    
    This reverts commit 5141861cd5e17eac9676ff49c5abfafbea2b0e98.
    
    The series of IPoIB bug fixes that went into 3.19-rc1 introduce
    regressions, and after trying to sort things out, we decided to revert
    to 3.18's IPoIB driver and get things right for 3.20.
    
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 45fd10a72ec1..f4c1b20b23b2 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -323,7 +323,6 @@ struct ipoib_dev_priv {
 	struct list_head multicast_list;
 	struct rb_root multicast_tree;
 
-	struct workqueue_struct *wq;
 	struct delayed_work mcast_task;
 	struct work_struct carrier_on_task;
 	struct work_struct flush_light;

commit 4e0ab200fa4594d16bb7fc697ec4d9edfb5a43f0
Author: Roland Dreier <roland@purestorage.com>
Date:   Fri Jan 30 15:38:46 2015 -0800

    Revert "IPoIB: Make ipoib_mcast_stop_thread flush the workqueue"
    
    This reverts commit bb42a6dd02fb2901a69dbec2358810735b14b186.
    
    The series of IPoIB bug fixes that went into 3.19-rc1 introduce
    regressions, and after trying to sort things out, we decided to revert
    to 3.18's IPoIB driver and get things right for 3.20.
    
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 28dc927c0e8b..45fd10a72ec1 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -499,7 +499,7 @@ void ipoib_mcast_send(struct net_device *dev, u8 *daddr, struct sk_buff *skb);
 
 void ipoib_mcast_restart_task(struct work_struct *work);
 int ipoib_mcast_start_thread(struct net_device *dev);
-int ipoib_mcast_stop_thread(struct net_device *dev);
+int ipoib_mcast_stop_thread(struct net_device *dev, int flush);
 
 void ipoib_mcast_dev_down(struct net_device *dev);
 void ipoib_mcast_dev_flush(struct net_device *dev);

commit a84544a4feb2cf5cafdf3cce3269da0c3b4fcc45
Author: Roland Dreier <roland@purestorage.com>
Date:   Fri Jan 30 15:38:35 2015 -0800

    Revert "IPoIB: No longer use flush as a parameter"
    
    This reverts commit ce347ab90eaabc69a6146d41943981d51e7a9b82.
    
    The series of IPoIB bug fixes that went into 3.19-rc1 introduce
    regressions, and after trying to sort things out, we decided to revert
    to 3.18's IPoIB driver and get things right for 3.20.
    
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 8ba80a6d3a46..28dc927c0e8b 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -484,10 +484,10 @@ void ipoib_ib_dev_flush_heavy(struct work_struct *work);
 void ipoib_pkey_event(struct work_struct *work);
 void ipoib_ib_dev_cleanup(struct net_device *dev);
 
-int ipoib_ib_dev_open(struct net_device *dev);
+int ipoib_ib_dev_open(struct net_device *dev, int flush);
 int ipoib_ib_dev_up(struct net_device *dev);
-int ipoib_ib_dev_down(struct net_device *dev);
-int ipoib_ib_dev_stop(struct net_device *dev);
+int ipoib_ib_dev_down(struct net_device *dev, int flush);
+int ipoib_ib_dev_stop(struct net_device *dev, int flush);
 void ipoib_pkey_dev_check_presence(struct net_device *dev);
 
 int ipoib_dev_init(struct net_device *dev, struct ib_device *ca, int port);

commit ce347ab90eaabc69a6146d41943981d51e7a9b82
Author: Doug Ledford <dledford@redhat.com>
Date:   Wed Dec 10 11:47:05 2014 -0500

    IPoIB: No longer use flush as a parameter
    
    Various places in the IPoIB code had a deadlock related to flushing
    the ipoib workqueue.  Now that we have per device workqueues and a
    specific flush workqueue, there is no longer a deadlock issue with
    flushing the device specific workqueues and we can do so unilaterally.
    
    Signed-off-by: Doug Ledford <dledford@redhat.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 28dc927c0e8b..8ba80a6d3a46 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -484,10 +484,10 @@ void ipoib_ib_dev_flush_heavy(struct work_struct *work);
 void ipoib_pkey_event(struct work_struct *work);
 void ipoib_ib_dev_cleanup(struct net_device *dev);
 
-int ipoib_ib_dev_open(struct net_device *dev, int flush);
+int ipoib_ib_dev_open(struct net_device *dev);
 int ipoib_ib_dev_up(struct net_device *dev);
-int ipoib_ib_dev_down(struct net_device *dev, int flush);
-int ipoib_ib_dev_stop(struct net_device *dev, int flush);
+int ipoib_ib_dev_down(struct net_device *dev);
+int ipoib_ib_dev_stop(struct net_device *dev);
 void ipoib_pkey_dev_check_presence(struct net_device *dev);
 
 int ipoib_dev_init(struct net_device *dev, struct ib_device *ca, int port);

commit bb42a6dd02fb2901a69dbec2358810735b14b186
Author: Doug Ledford <dledford@redhat.com>
Date:   Wed Dec 10 11:47:04 2014 -0500

    IPoIB: Make ipoib_mcast_stop_thread flush the workqueue
    
    We used to pass a flush variable to mcast_stop_thread to indicate if
    we should flush the workqueue or not.  This was due to some code
    trying to flush a workqueue that it was currently running on which is
    a no-no.  Now that we have per-device work queues, and now that
    ipoib_mcast_restart_task has taken the fact that it is queued on a
    single thread workqueue with all of the ipoib_mcast_join_task's and
    therefore has no need to stop the join task while it runs, we can do
    away with the flush parameter and unilaterally flush always.
    
    Signed-off-by: Doug Ledford <dledford@redhat.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 45fd10a72ec1..28dc927c0e8b 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -499,7 +499,7 @@ void ipoib_mcast_send(struct net_device *dev, u8 *daddr, struct sk_buff *skb);
 
 void ipoib_mcast_restart_task(struct work_struct *work);
 int ipoib_mcast_start_thread(struct net_device *dev);
-int ipoib_mcast_stop_thread(struct net_device *dev, int flush);
+int ipoib_mcast_stop_thread(struct net_device *dev);
 
 void ipoib_mcast_dev_down(struct net_device *dev);
 void ipoib_mcast_dev_flush(struct net_device *dev);

commit 5141861cd5e17eac9676ff49c5abfafbea2b0e98
Author: Doug Ledford <dledford@redhat.com>
Date:   Wed Dec 10 11:47:03 2014 -0500

    IPoIB: Use dedicated workqueues per interface
    
    During my recent work on the rtnl lock deadlock in the IPoIB driver, I
    saw that even once I fixed the apparent races for a single device, as
    soon as that device had any children, new races popped up.  It turns
    out that this is because no matter how well we protect against races
    on a single device, the fact that all devices use the same workqueue,
    and flush_workqueue() flushes *everything* from that workqueue, we can
    have one device in the middle of a down and holding the rtnl lock and
    another totally unrelated device needing to run mcast_restart_task,
    which wants the rtnl lock and will loop trying to take it unless is
    sees its own FLAG_ADMIN_UP flag go away.  Because the unrelated
    interface will never see its own ADMIN_UP flag drop, the interface
    going down will deadlock trying to flush the queue.  There are several
    possible solutions to this problem:
    
    Make carrier_on_task and mcast_restart_task try to take the rtnl for
    some set period of time and if they fail, then bail.  This runs the
    real risk of dropping work on the floor, which can end up being its
    own separate kind of deadlock.
    
    Set some global flag in the driver that says some device is in the
    middle of going down, letting all tasks know to bail.  Again, this can
    drop work on the floor.  I suppose if our own ADMIN_UP flag doesn't go
    away, then maybe after a few tries on the rtnl lock we can queue our
    own task back up as a delayed work and return and avoid dropping work
    on the floor that way.  But I'm not 100% convinced that we won't cause
    other problems.
    
    Or the method this patch attempts to use, which is when we bring an
    interface up, create a workqueue specifically for that interface, so
    that when we take it back down, we are flushing only those tasks
    associated with our interface.  In addition, keep the global
    workqueue, but now limit it to only flush tasks.  In this way, the
    flush tasks can always flush the device specific work queues without
    having deadlock issues.
    
    Signed-off-by: Doug Ledford <dledford@redhat.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index f4c1b20b23b2..45fd10a72ec1 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -323,6 +323,7 @@ struct ipoib_dev_priv {
 	struct list_head multicast_list;
 	struct rb_root multicast_tree;
 
+	struct workqueue_struct *wq;
 	struct delayed_work mcast_task;
 	struct work_struct carrier_on_task;
 	struct work_struct flush_light;

commit 016d9fb25cd9817ea9c723f4f7ecd978636b4489
Author: Doug Ledford <dledford@redhat.com>
Date:   Wed Dec 10 11:47:00 2014 -0500

    IPoIB: fix MCAST_FLAG_BUSY usage
    
    Commit a9c8ba5884 ("IPoIB: Fix usage of uninitialized multicast
    objects") added a new flag MCAST_JOIN_STARTED, but was not very strict
    in how it was used.  We didn't always initialize the completion struct
    before we set the flag, and we didn't always call complete on the
    completion struct from all paths that complete it.  This made it less
    than totally effective, and certainly made its use confusing.  And in
    the flush function we would use the presence of this flag to signal
    that we should wait on the completion struct, but we never cleared
    this flag, ever.  This is further muddied by the fact that we overload
    the MCAST_FLAG_BUSY flag to mean two different things: we have a join
    in flight, and we have succeeded in getting an ib_sa_join_multicast.
    
    In order to make things clearer and aid in resolving the rtnl deadlock
    bug I've been chasing, I cleaned this up a bit.
    
     1) Remove the MCAST_JOIN_STARTED flag entirely
     2) Un-overload MCAST_FLAG_BUSY so it now only means a join is in-flight
     3) Test on mcast->mc directly to see if we have completed
        ib_sa_join_multicast (using IS_ERR_OR_NULL)
     4) Make sure that before setting MCAST_FLAG_BUSY we always initialize
        the mcast->done completion struct
     5) Make sure that before calling complete(&mcast->done), we always clear
        the MCAST_FLAG_BUSY bit
     6) Take the mcast_mutex before we call ib_sa_multicast_join and also
        take the mutex in our join callback.  This forces
        ib_sa_multicast_join to return and set mcast->mc before we process
        the callback.  This way, our callback can safely clear mcast->mc
        if there is an error on the join and we will do the right thing as
        a result in mcast_dev_flush.
     7) Because we need the mutex to synchronize mcast->mc, we can no
        longer call mcast_sendonly_join directly from mcast_send and
        instead must add sendonly join processing to the mcast_join_task
    
    A number of different races are resolved with these changes.  These
    races existed with the old MCAST_FLAG_BUSY usage, the
    MCAST_JOIN_STARTED flag was an attempt to address them, and while it
    helped, a determined effort could still trip things up.
    
    One race looks something like this:
    
    Thread 1                             Thread 2
    ib_sa_join_multicast (as part of running restart mcast task)
      alloc member
      call callback
                                         ifconfig ib0 down
                                         wait_for_completion
        callback call completes
                                         wait_for_completion in
                                         mcast_dev_flush completes
                                           mcast->mc is PTR_ERR_OR_NULL
                                           so we skip ib_sa_leave_multicast
        return from callback
      return from ib_sa_join_multicast
    set mcast->mc = return from ib_sa_multicast
    
    We now have a permanently unbalanced join/leave issue that trips up the
    refcounting in core/multicast.c
    
    Another like this:
    
    Thread 1                   Thread 2         Thread 3
    ib_sa_multicast_join
                                                ifconfig ib0 down
                                                priv->broadcast = NULL
                               join_complete
                                                wait_for_completion
                               mcast->mc is not yet set, so don't clear
    return from ib_sa_join_multicast and set mcast->mc
                               complete
                               return -EAGAIN (making mcast->mc invalid)
                                                call ib_sa_multicast_leave
                                                on invalid mcast->mc, hang
                                                forever
    
    By holding the mutex around ib_sa_multicast_join and taking the mutex
    early in the callback, we force mcast->mc to be valid at the time we
    run the callback.  This allows us to clear mcast->mc if there is an
    error and the join is going to fail.  We do this before we complete
    the mcast.  In this way, mcast_dev_flush always sees consistent state
    in regards to mcast->mc membership at the time that the
    wait_for_completion() returns.
    
    Signed-off-by: Doug Ledford <dledford@redhat.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index d7562beb5423..f4c1b20b23b2 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -98,9 +98,15 @@ enum {
 
 	IPOIB_MCAST_FLAG_FOUND	  = 0,	/* used in set_multicast_list */
 	IPOIB_MCAST_FLAG_SENDONLY = 1,
-	IPOIB_MCAST_FLAG_BUSY	  = 2,	/* joining or already joined */
+	/*
+	 * For IPOIB_MCAST_FLAG_BUSY
+	 * When set, in flight join and mcast->mc is unreliable
+	 * When clear and mcast->mc IS_ERR_OR_NULL, need to restart or
+	 *   haven't started yet
+	 * When clear and mcast->mc is valid pointer, join was successful
+	 */
+	IPOIB_MCAST_FLAG_BUSY	  = 2,
 	IPOIB_MCAST_FLAG_ATTACHED = 3,
-	IPOIB_MCAST_JOIN_STARTED  = 4,
 
 	MAX_SEND_CQE		  = 16,
 	IPOIB_CM_COPYBREAK	  = 256,

commit b49fe36208b45f76dfbcfcd3afd952a33fa9f5ce
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Sep 18 11:00:27 2014 -0700

    ipoib: validate struct ipoib_cb size
    
    To catch future errors sooner.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 3edce617c31b..d7562beb5423 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -131,6 +131,12 @@ struct ipoib_cb {
 	u8			hwaddr[INFINIBAND_ALEN];
 };
 
+static inline struct ipoib_cb *ipoib_skb_cb(const struct sk_buff *skb)
+{
+	BUILD_BUG_ON(sizeof(skb->cb) < sizeof(struct ipoib_cb));
+	return (struct ipoib_cb *)skb->cb;
+}
+
 /* Used for all multicast joins (broadcast, IPv4 mcast and IPv6 mcast) */
 struct ipoib_mcast {
 	struct ib_sa_mcmember_rec mcmember;

commit 4eae374845affc3ebf8ccfc38d554a86adc95003
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Tue Jul 8 12:45:12 2014 +0300

    IB/ipoib: Avoid flushing the workqueue from worker context
    
    The error flow of ipoib_ib_dev_open() invokes ipoib_ib_dev_stop() with
    workqueue flushing enabled, which deadlocks if the open procedure
    itself was called by a worker thread.
    
    Fix this by adding a flush enabled flag to ipoib_ib_dev_open() and set
    it accordingly from the locations where such a call is made.
    
    The call trace was the following:
    
     [<ffffffff81095bc4>] ? flush_workqueue+0x54/0x80
     [<ffffffffa056c657>] ? ipoib_ib_dev_stop+0x447/0x650 [ib_ipoib]
     [<ffffffffa056cc34>] ? ipoib_ib_dev_open+0x284/0x430 [ib_ipoib]
     [<ffffffffa05674a8>] ? ipoib_open+0x78/0x1d0 [ib_ipoib]
     [<ffffffffa05697b8>] ? ipoib_pkey_open+0x38/0x40 [ib_ipoib]
     [<ffffffffa056cf3c>] ? __ipoib_ib_dev_flush+0x15c/0x2c0 [ib_ipoib]
     [<ffffffffa056ce56>] ? __ipoib_ib_dev_flush+0x76/0x2c0 [ib_ipoib]
     [<ffffffffa056d0a0>] ? ipoib_ib_dev_flush_heavy+0x0/0x20 [ib_ipoib]
     [<ffffffffa056d0ba>] ? ipoib_ib_dev_flush_heavy+0x1a/0x20 [ib_ipoib]
     [<ffffffff81094d20>] ? worker_thread+0x170/0x2a0
     [<ffffffff8109b2a0>] ? autoremove_wake_function+0x0/0x40
    
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Acked-by: Alex Estrin <alex.estrin@intel.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 683d23ac7cbf..3edce617c31b 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -471,7 +471,7 @@ void ipoib_ib_dev_flush_heavy(struct work_struct *work);
 void ipoib_pkey_event(struct work_struct *work);
 void ipoib_ib_dev_cleanup(struct net_device *dev);
 
-int ipoib_ib_dev_open(struct net_device *dev);
+int ipoib_ib_dev_open(struct net_device *dev, int flush);
 int ipoib_ib_dev_up(struct net_device *dev);
 int ipoib_ib_dev_down(struct net_device *dev, int flush);
 int ipoib_ib_dev_stop(struct net_device *dev, int flush);

commit db84f88037592f069f5c1fc7f6b00ae6f5eb2e84
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Tue Jul 8 12:45:11 2014 +0300

    IB/ipoib: Use P_Key change event instead of P_Key polling mechanism
    
    The current code use a dedicated polling logic to determine when the P_Key
    assigned to the ipoib device is present in HCA port table and act accordingly.
    
    Move to use the code which acts upon getting PKEY_CHANGE event to handle this
    task and remove the P_Key polling logic/thread as they add extra complexity
    which isn't needed.
    
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Acked-by: Alex Estrin <alex.estrin@intel.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index c639f90cfda4..683d23ac7cbf 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -86,7 +86,6 @@ enum {
 	IPOIB_FLAG_INITIALIZED	  = 1,
 	IPOIB_FLAG_ADMIN_UP	  = 2,
 	IPOIB_PKEY_ASSIGNED	  = 3,
-	IPOIB_PKEY_STOP		  = 4,
 	IPOIB_FLAG_SUBINTERFACE	  = 5,
 	IPOIB_MCAST_RUN		  = 6,
 	IPOIB_STOP_REAPER	  = 7,
@@ -312,7 +311,6 @@ struct ipoib_dev_priv {
 	struct list_head multicast_list;
 	struct rb_root multicast_tree;
 
-	struct delayed_work pkey_poll_task;
 	struct delayed_work mcast_task;
 	struct work_struct carrier_on_task;
 	struct work_struct flush_light;
@@ -477,6 +475,7 @@ int ipoib_ib_dev_open(struct net_device *dev);
 int ipoib_ib_dev_up(struct net_device *dev);
 int ipoib_ib_dev_down(struct net_device *dev, int flush);
 int ipoib_ib_dev_stop(struct net_device *dev, int flush);
+void ipoib_pkey_dev_check_presence(struct net_device *dev);
 
 int ipoib_dev_init(struct net_device *dev, struct ib_device *ca, int port);
 void ipoib_dev_cleanup(struct net_device *dev);
@@ -532,8 +531,7 @@ int  ipoib_set_mode(struct net_device *dev, const char *buf);
 
 void ipoib_setup(struct net_device *dev);
 
-void ipoib_pkey_poll(struct work_struct *work);
-int ipoib_pkey_dev_delay_open(struct net_device *dev);
+void ipoib_pkey_open(struct ipoib_dev_priv *priv);
 void ipoib_drain_cq(struct net_device *dev);
 
 void ipoib_set_ethtool_ops(struct net_device *dev);

commit a9c8ba588495547d1598f1b83d5eb086bef65e4b
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Wed Oct 16 17:37:51 2013 +0300

    IPoIB: Fix usage of uninitialized multicast objects
    
    The driver should avoid calling ib_sa_free_multicast on the mcast->mc
    object until it finishes its initialization state.  Otherwise we can
    crash when ipoib_mcast_dev_flush() attempts to use the uninitialized
    multicast object.
    
    Instead, only call wait_for_completion() for multicast entries that
    started the join process, meaning that ib_sa_join_multicast() finished.
    
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index ec9190eff09c..c639f90cfda4 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -101,6 +101,7 @@ enum {
 	IPOIB_MCAST_FLAG_SENDONLY = 1,
 	IPOIB_MCAST_FLAG_BUSY	  = 2,	/* joining or already joined */
 	IPOIB_MCAST_FLAG_ATTACHED = 3,
+	IPOIB_MCAST_JOIN_STARTED  = 4,
 
 	MAX_SEND_CQE		  = 16,
 	IPOIB_CM_COPYBREAK	  = 256,
@@ -151,6 +152,7 @@ struct ipoib_mcast {
 	struct sk_buff_head pkt_queue;
 
 	struct net_device *dev;
+	struct completion done;
 };
 
 struct ipoib_rx_buf {

commit f47944cc2dba3c7e6f753b81e9f713f4d12bdd5a
Author: Erez Shitrit <erezsh@mellanox.com>
Date:   Wed Oct 16 17:37:49 2013 +0300

    IPoIB: Fix deadlock between dev_change_flags() and __ipoib_dev_flush()
    
    When ipoib interface is going down it takes all of its children with
    it, under mutex.
    
    For each child, dev_change_flags() is called.  That function calls
    ipoib_stop() via the ndo, and causes flush of the workqueue.
    Sometimes in the workqueue an __ipoib_dev_flush work() is waiting and
    when invoked tries to get the same mutex, which leads to a deadlock,
    as seen below.
    
    The solution is to switch to rw-sem instead of mutex.
    
    The deadlock:
    [11028.165303]  [<ffffffff812b0977>] ? vgacon_scroll+0x107/0x2e0
    [11028.171844]  [<ffffffff814eaac5>] schedule_timeout+0x215/0x2e0
    [11028.178465]  [<ffffffff8105a5c3>] ? perf_event_task_sched_out+0x33/0x80
    [11028.185962]  [<ffffffff814ea743>] wait_for_common+0x123/0x180
    [11028.192491]  [<ffffffff8105fa40>] ? default_wake_function+0x0/0x20
    [11028.199504]  [<ffffffff814ea85d>] wait_for_completion+0x1d/0x20
    [11028.206224]  [<ffffffff8108b4f1>] flush_cpu_workqueue+0x61/0x90
    [11028.212948]  [<ffffffff8108b5a0>] ? wq_barrier_func+0x0/0x20
    [11028.219375]  [<ffffffff8108bfc4>] flush_workqueue+0x54/0x80
    [11028.225712]  [<ffffffffa05a0576>] ipoib_mcast_stop_thread+0x66/0x90 [ib_ipoib]
    [11028.233988]  [<ffffffffa059ccea>] ipoib_ib_dev_down+0x6a/0x100 [ib_ipoib]
    [11028.241678]  [<ffffffffa059849a>] ipoib_stop+0x8a/0x140 [ib_ipoib]
    [11028.248692]  [<ffffffff8142adf1>] dev_close+0x71/0xc0
    [11028.254447]  [<ffffffff8142a631>] dev_change_flags+0xa1/0x1d0
    [11028.261062]  [<ffffffffa059851b>] ipoib_stop+0x10b/0x140 [ib_ipoib]
    [11028.268172]  [<ffffffff8142adf1>] dev_close+0x71/0xc0
    [11028.273922]  [<ffffffff8142a631>] dev_change_flags+0xa1/0x1d0
    [11028.280452]  [<ffffffff8148f20b>] devinet_ioctl+0x5eb/0x6a0
    [11028.286786]  [<ffffffff814903b8>] inet_ioctl+0x88/0xa0
    [11028.292633]  [<ffffffff8141591a>] sock_ioctl+0x7a/0x280
    [11028.298576]  [<ffffffff81189012>] vfs_ioctl+0x22/0xa0
    [11028.304326]  [<ffffffff81140540>] ? unmap_region+0x110/0x130
    [11028.310756]  [<ffffffff811891b4>] do_vfs_ioctl+0x84/0x580
    [11028.316897]  [<ffffffff81189731>] sys_ioctl+0x81/0xa0
    
    and
    
    11028.017533]  [<ffffffff8105a5c3>] ? perf_event_task_sched_out+0x33/0x80
    [11028.025030]  [<ffffffff8100bb8e>] ? apic_timer_interrupt+0xe/0x20
    [11028.031945]  [<ffffffff814eb2ae>] __mutex_lock_slowpath+0x13e/0x180
    [11028.039053]  [<ffffffff814eb14b>] mutex_lock+0x2b/0x50
    [11028.044910]  [<ffffffffa059f7e7>] __ipoib_ib_dev_flush+0x37/0x210 [ib_ipoib]
    [11028.052894]  [<ffffffffa059fa00>] ? ipoib_ib_dev_flush_light+0x0/0x20 [ib_ipoib]
    [11028.061363]  [<ffffffffa059fa17>] ipoib_ib_dev_flush_light+0x17/0x20 [ib_ipoib]
    [11028.069738]  [<ffffffff8108b120>] worker_thread+0x170/0x2a0
    [11028.076068]  [<ffffffff81090990>] ? autoremove_wake_function+0x0/0x40
    [11028.083374]  [<ffffffff8108afb0>] ? worker_thread+0x0/0x2a0
    [11028.089709]  [<ffffffff81090626>] kthread+0x96/0xa0
    [11028.095266]  [<ffffffff8100c0ca>] child_rip+0xa/0x20
    [11028.100921]  [<ffffffff81090590>] ? kthread+0x0/0xa0
    [11028.106573]  [<ffffffff8100c0c0>] ? child_rip+0x0/0x20
    [11028.112423] INFO: task ifconfig:23640 blocked for more than 120 seconds.
    
    Signed-off-by: Erez Shitrit <erezsh@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index eb71aaa26a9a..ec9190eff09c 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -299,7 +299,7 @@ struct ipoib_dev_priv {
 
 	unsigned long flags;
 
-	struct mutex vlan_mutex;
+	struct rw_semaphore vlan_rwsem;
 
 	struct rb_root  path_tree;
 	struct list_head path_list;

commit 4b48680b5572ee78834c276548e16ac5316908cb
Author: Yan Burman <yanb@mellanox.com>
Date:   Tue Feb 19 15:40:23 2013 +0000

    IPoIB: Add version and firmware info to ethtool reporting
    
    Implement version info as well as report firmware version and bus info
    of the underlying IB HW device.
    
    Signed-off-by: Yan Burman <yanb@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index a7ac0977cb5e..eb71aaa26a9a 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -762,4 +762,6 @@ extern int ipoib_debug_level;
 
 #define IPOIB_QPN(ha) (be32_to_cpup((__be32 *) ha) & 0xffffff)
 
+extern const char ipoib_driver_version[];
+
 #endif /* _IPOIB_H */

commit 9d1ad66e3eae0faf3f19a618da74b4c377474845
Author: Shlomo Pongratz <shlomop@mellanox.com>
Date:   Tue Feb 19 15:40:22 2013 +0000

    IPoIB: Fix ipoib_neigh hashing to use the correct daddr octets
    
    The hash function introduced in commit b63b70d877 ("IPoIB: Use a
    private hash table for path lookup in xmit path") was designd to use
    the 3 octets of the IPoIB HW address that holds the remote QPN.
    However, this currently isn't the case on little-endian machines,
    because the the code there uses the flags part (octet[0]) and not the
    last octet of the QPN (octet[3]).  Fix this.
    
    The fix caused a checkpatch warning on line over 80 characters, to
    solve that changed the name of the temp variable that holds the daddr.
    
    Signed-off-by: Shlomo Pongratz <shlomop@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 07ca6fd5546b..a7ac0977cb5e 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -117,6 +117,8 @@ enum {
 #define	IPOIB_OP_CM     (0)
 #endif
 
+#define IPOIB_QPN_MASK ((__force u32) cpu_to_be32(0xFFFFFF))
+
 /* structs */
 
 struct ipoib_header {

commit 71d9c5f9e60846fa40c9efadda122d9cf275c1d2
Author: Roland Dreier <roland@purestorage.com>
Date:   Tue Oct 2 21:23:43 2012 -0700

    IPoIB: Fix build with CONFIG_INFINIBAND_IPOIB_CM=n
    
    With the new netlink support in commit 862096a8bbf8 ("IB/ipoib: Add more
    rtnl_link_ops callbacks") we need ipoib_set_mode() to be available even
    if connected mode isn't built.  Move the function from ipoib_cm.c to
    ipoib_main.c (and make a few CM-related macros available unconditonally).
    
    This fixes the build error
    
        drivers/built-in.o: In function 'ipoib_changelink':
        ipoib_netlink.c:(.text+0x6a5fc9): undefined reference to 'ipoib_set_mode'
        ipoib_netlink.c:(.text+0x6a5fe3): undefined reference to 'ipoib_set_mode'
    
    when CONFIG_INFINIBAND_IPOIB_CM isn't set.
    
    Reported-by: Randy Dunlap <rdunlap@xenotime.net>
    Reported-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 196eb52f0035..07ca6fd5546b 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -535,14 +535,14 @@ void ipoib_drain_cq(struct net_device *dev);
 void ipoib_set_ethtool_ops(struct net_device *dev);
 int ipoib_set_dev_features(struct ipoib_dev_priv *priv, struct ib_device *hca);
 
-#ifdef CONFIG_INFINIBAND_IPOIB_CM
-
 #define IPOIB_FLAGS_RC		0x80
 #define IPOIB_FLAGS_UC		0x40
 
 /* We don't support UC connections at the moment */
 #define IPOIB_CM_SUPPORTED(ha)   (ha[0] & (IPOIB_FLAGS_RC))
 
+#ifdef CONFIG_INFINIBAND_IPOIB_CM
+
 extern int ipoib_max_conn_qp;
 
 static inline int ipoib_cm_admin_enabled(struct net_device *dev)

commit 862096a8bbf8f992f6d0a1a8786ffd3fc7437e48
Author: Or Gerlitz <ogerlitz@mellanox.com>
Date:   Thu Sep 27 12:06:02 2012 +0000

    IB/ipoib: Add more rtnl_link_ops callbacks
    
    Add the rtnl_link_ops changelink and fill_info callbacks, through
    which the admin can now set/get the driver mode, etc policies.
    Maintain the proprietary sysfs entries only for legacy childs.
    
    For child devices, set dev->iflink to point to the parent
    device ifindex, such that user space tools can now correctly
    show the uplink relation as done for vlan, macvlan, etc
    devices. Pointed out by Patrick McHardy <kaber@trash.net>
    
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index ac48f86f2384..196eb52f0035 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -523,6 +523,9 @@ int __ipoib_vlan_add(struct ipoib_dev_priv *ppriv, struct ipoib_dev_priv *priv,
 int  __init ipoib_netlink_init(void);
 void __exit ipoib_netlink_fini(void);
 
+void ipoib_set_umcast(struct net_device *ndev, int umcast_val);
+int  ipoib_set_mode(struct net_device *dev, const char *buf);
+
 void ipoib_setup(struct net_device *dev);
 
 void ipoib_pkey_poll(struct work_struct *work);

commit 6a06e5e1bb217be077e1f8ee2745b4c5b1aa02db
Merge: d9f72f359e00 6672d90fe779
Author: David S. Miller <davem@davemloft.net>
Date:   Fri Sep 28 14:40:49 2012 -0400

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Conflicts:
            drivers/net/team/team.c
            drivers/net/usb/qmi_wwan.c
            net/batman-adv/bat_iv_ogm.c
            net/ipv4/fib_frontend.c
            net/ipv4/route.c
            net/l2tp/l2tp_netlink.c
    
    The team, fib_frontend, route, and l2tp_netlink conflicts were simply
    overlapping changes.
    
    qmi_wwan and bat_iv_ogm were of the "use HEAD" variety.
    
    With help from Antonio Quartulli.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 9baa0b0364103dd726384c71db30b74044754743
Author: Or Gerlitz <ogerlitz@mellanox.com>
Date:   Thu Sep 13 05:56:36 2012 +0000

    IB/ipoib: Add rtnl_link_ops support
    
    Add rtnl_link_ops to IPoIB, with the first usage being child device
    create/delete through them. Childs devices are now either legacy ones,
    created/deleted through the ipoib sysfs entries, or RTNL ones.
    
    Adding support for RTNL childs involved refactoring of ipoib_vlan_add
    which is now used by both the sysfs and the link_ops code.
    
    Also, added ndo_uninit entry to support calling unregister_netdevice_queue
    from the rtnl dellink entry. This required removal of calls to
    ipoib_dev_cleanup from the driver in flows which use unregister_netdevice,
    since the networking core will invoke ipoib_uninit which does exactly that.
    
    Signed-off-by: Erez Shitrit <erezsh@mellanox.co.il>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index ca43901ed861..381f51b2ed61 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -104,6 +104,10 @@ enum {
 
 	MAX_SEND_CQE		  = 16,
 	IPOIB_CM_COPYBREAK	  = 256,
+
+	IPOIB_NON_CHILD		  = 0,
+	IPOIB_LEGACY_CHILD	  = 1,
+	IPOIB_RTNL_CHILD	  = 2,
 };
 
 #define	IPOIB_OP_RECV   (1ul << 31)
@@ -350,6 +354,7 @@ struct ipoib_dev_priv {
 	struct net_device *parent;
 	struct list_head child_intfs;
 	struct list_head list;
+	int    child_type;
 
 #ifdef CONFIG_INFINIBAND_IPOIB_CM
 	struct ipoib_cm_dev_priv cm;
@@ -509,6 +514,14 @@ void ipoib_event(struct ib_event_handler *handler,
 int ipoib_vlan_add(struct net_device *pdev, unsigned short pkey);
 int ipoib_vlan_delete(struct net_device *pdev, unsigned short pkey);
 
+int __ipoib_vlan_add(struct ipoib_dev_priv *ppriv, struct ipoib_dev_priv *priv,
+		     u16 pkey, int child_type);
+
+int  __init ipoib_netlink_init(void);
+void __exit ipoib_netlink_fini(void);
+
+void ipoib_setup(struct net_device *dev);
+
 void ipoib_pkey_poll(struct work_struct *work);
 int ipoib_pkey_dev_delay_open(struct net_device *dev);
 void ipoib_drain_cq(struct net_device *dev);

commit b5120a6e11e90d98d8a752545ac60bfa1ea95f1a
Author: Shlomo Pongratz <shlomop@mellanox.com>
Date:   Wed Aug 29 15:14:34 2012 +0000

    IPoIB: Fix AB-BA deadlock when deleting neighbours
    
    Lockdep points out a circular locking dependency betwwen the ipoib
    device priv spinlock (priv->lock) and the neighbour table rwlock
    (ntbl->rwlock).
    
    In the normal path, ie neigbour garbage collection task, the neigh
    table rwlock is taken first and then if the neighbour needs to be
    deleted, priv->lock is taken.
    
    However in some error paths, such as in ipoib_cm_handle_tx_wc(),
    priv->lock is taken first and then ipoib_neigh_free routine is called
    which in turn takes the neighbour table ntbl->rwlock.
    
    The solution is to get rid the neigh table rwlock completely and use
    only priv->lock.
    
    Signed-off-by: Shlomo Pongratz <shlomop@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index e6bbeae1c309..0af216d21f87 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -274,7 +274,6 @@ struct ipoib_neigh_hash {
 
 struct ipoib_neigh_table {
 	struct ipoib_neigh_hash __rcu  *htbl;
-	rwlock_t			rwlock;
 	atomic_t			entries;
 	struct completion		flushed;
 	struct completion		deleted;

commit 66172c09938bfc4efdcf9b5e0246a85b9b76dd54
Author: Shlomo Pongratz <shlomop@mellanox.com>
Date:   Wed Aug 29 15:14:33 2012 +0000

    IPoIB: Fix memory leak in the neigh table deletion flow
    
    If the neighbours hash table is empty when unloading the module, then
    ipoib_flush_neighs(), the cleanup routine, isn't called and the
    memory used for the hash table itself leaked.
    
    To fix this, ipoib_flush_neighs() is allways called, and another
    completion object is added to signal when the table is freed.
    
    Once invoked, ipoib_flush_neighs() flushes all the neighbours (if
    there are any), calls the the hash table RCU free routine, which now
    signals completion of the deletion process, and waits for the last
    neighbour to be freed.
    
    Signed-off-by: Shlomo Pongratz <shlomop@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index ca43901ed861..e6bbeae1c309 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -262,7 +262,10 @@ struct ipoib_ethtool_st {
 	u16     max_coalesced_frames;
 };
 
+struct ipoib_neigh_table;
+
 struct ipoib_neigh_hash {
+	struct ipoib_neigh_table       *ntbl;
 	struct ipoib_neigh __rcu      **buckets;
 	struct rcu_head			rcu;
 	u32				mask;
@@ -274,6 +277,7 @@ struct ipoib_neigh_table {
 	rwlock_t			rwlock;
 	atomic_t			entries;
 	struct completion		flushed;
+	struct completion		deleted;
 };
 
 /*

commit b63b70d8774175b6f8393c495fe455f0fba55ce1
Author: Shlomo Pongratz <shlomop@mellanox.com>
Date:   Tue Jul 24 17:05:22 2012 +0000

    IPoIB: Use a private hash table for path lookup in xmit path
    
    Dave Miller <davem@davemloft.net> provided a detailed description of
    why the way IPoIB is using neighbours for its own ipoib_neigh struct
    is buggy:
    
        Any time an ipoib_neigh is changed, a sequence like the following is made:
    
                            spin_lock_irqsave(&priv->lock, flags);
                            /*
                             * It's safe to call ipoib_put_ah() inside
                             * priv->lock here, because we know that
                             * path->ah will always hold one more reference,
                             * so ipoib_put_ah() will never do more than
                             * decrement the ref count.
                             */
                            if (neigh->ah)
                                    ipoib_put_ah(neigh->ah);
                            list_del(&neigh->list);
                            ipoib_neigh_free(dev, neigh);
                            spin_unlock_irqrestore(&priv->lock, flags);
                            ipoib_path_lookup(skb, n, dev);
    
        This doesn't work, because you're leaving a stale pointer to the freed up
        ipoib_neigh in the special neigh->ha pointer cookie.  Yes, it even fails
        with all the locking done to protect _changes_ to *ipoib_neigh(n), and
        with the code in ipoib_neigh_free() that NULLs out the pointer.
    
        The core issue is that read side calls to *to_ipoib_neigh(n) are not
        being synchronized at all, they are performed without any locking.  So
        whether we hold the lock or not when making changes to *ipoib_neigh(n)
        you still can have threads see references to freed up ipoib_neigh
        objects.
    
            cpu 1                   cpu 2
            n = *ipoib_neigh()
                                    *ipoib_neigh() = NULL
                                    kfree(n)
            n->foo == OOPS
    
        [..]
    
        Perhaps the ipoib code can have a private path database it manages
        entirely itself, which holds all the necessary information and is
        looked up by some generic key which is available easily at transmit
        time and does not involve generic neighbour entries.
    
    See <http://marc.info/?l=linux-rdma&m=132812793105624&w=2> and
    <http://marc.info/?l=linux-rdma&w=2&r=1&s=allows+references+to+freed+memory&q=b>
    for the full discussion.
    
    This patch aims to solve the race conditions found in the IPoIB driver.
    
    The patch removes the connection between the core networking neighbour
    structure and the ipoib_neigh structure.  In addition to avoiding the
    race described above, it allows us to handle SKBs carrying IP packets
    that don't have any associated neighbour.
    
    We add an ipoib_neigh hash table with N buckets where the key is the
    destination hardware address.  The ipoib_neigh is fetched from the
    hash table and instead of the stashed location in the neighbour
    structure. The hash table uses both RCU and reference counting to
    guarantee that no ipoib_neigh instance is ever deleted while in use.
    
    Fetching the ipoib_neigh structure instance from the hash also makes
    the special code in ipoib_start_xmit that handles remote and local
    bonding failover redundant.
    
    Aged ipoib_neigh instances are deleted by a garbage collection task
    that runs every M seconds and deletes every ipoib_neigh instance that
    was idle for at least 2*M seconds. The deletion is safe since the
    ipoib_neigh instances are protected using RCU and reference count
    mechanisms.
    
    The number of buckets (N) and frequency of running the GC thread (M),
    are taken from the exported arb_tbl.
    
    Signed-off-by: Shlomo Pongratz <shlomop@mellanox.com>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 86df632ea612..ca43901ed861 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -92,6 +92,8 @@ enum {
 	IPOIB_STOP_REAPER	  = 7,
 	IPOIB_FLAG_ADMIN_CM	  = 9,
 	IPOIB_FLAG_UMCAST	  = 10,
+	IPOIB_STOP_NEIGH_GC	  = 11,
+	IPOIB_NEIGH_TBL_FLUSH	  = 12,
 
 	IPOIB_MAX_BACKOFF_SECONDS = 16,
 
@@ -260,6 +262,20 @@ struct ipoib_ethtool_st {
 	u16     max_coalesced_frames;
 };
 
+struct ipoib_neigh_hash {
+	struct ipoib_neigh __rcu      **buckets;
+	struct rcu_head			rcu;
+	u32				mask;
+	u32				size;
+};
+
+struct ipoib_neigh_table {
+	struct ipoib_neigh_hash __rcu  *htbl;
+	rwlock_t			rwlock;
+	atomic_t			entries;
+	struct completion		flushed;
+};
+
 /*
  * Device private locking: network stack tx_lock protects members used
  * in TX fast path, lock protects everything else.  lock nests inside
@@ -279,6 +295,8 @@ struct ipoib_dev_priv {
 	struct rb_root  path_tree;
 	struct list_head path_list;
 
+	struct ipoib_neigh_table ntbl;
+
 	struct ipoib_mcast *broadcast;
 	struct list_head multicast_list;
 	struct rb_root multicast_tree;
@@ -291,7 +309,7 @@ struct ipoib_dev_priv {
 	struct work_struct flush_heavy;
 	struct work_struct restart_task;
 	struct delayed_work ah_reap_task;
-
+	struct delayed_work neigh_reap_task;
 	struct ib_device *ca;
 	u8		  port;
 	u16		  pkey;
@@ -377,13 +395,16 @@ struct ipoib_neigh {
 #ifdef CONFIG_INFINIBAND_IPOIB_CM
 	struct ipoib_cm_tx *cm;
 #endif
-	union ib_gid	    dgid;
+	u8     daddr[INFINIBAND_ALEN];
 	struct sk_buff_head queue;
 
-	struct neighbour   *neighbour;
 	struct net_device *dev;
 
 	struct list_head    list;
+	struct ipoib_neigh __rcu *hnext;
+	struct rcu_head     rcu;
+	atomic_t	    refcnt;
+	unsigned long       alive;
 };
 
 #define IPOIB_UD_MTU(ib_mtu)		(ib_mtu - IPOIB_ENCAP_LEN)
@@ -394,21 +415,17 @@ static inline int ipoib_ud_need_sg(unsigned int ib_mtu)
 	return IPOIB_UD_BUF_SIZE(ib_mtu) > PAGE_SIZE;
 }
 
-/*
- * We stash a pointer to our private neighbour information after our
- * hardware address in neigh->ha.  The ALIGN() expression here makes
- * sure that this pointer is stored aligned so that an unaligned
- * load is not needed to dereference it.
- */
-static inline struct ipoib_neigh **to_ipoib_neigh(struct neighbour *neigh)
+void ipoib_neigh_dtor(struct ipoib_neigh *neigh);
+static inline void ipoib_neigh_put(struct ipoib_neigh *neigh)
 {
-	return (void*) neigh + ALIGN(offsetof(struct neighbour, ha) +
-				     INFINIBAND_ALEN, sizeof(void *));
+	if (atomic_dec_and_test(&neigh->refcnt))
+		ipoib_neigh_dtor(neigh);
 }
-
-struct ipoib_neigh *ipoib_neigh_alloc(struct neighbour *neigh,
+struct ipoib_neigh *ipoib_neigh_get(struct net_device *dev, u8 *daddr);
+struct ipoib_neigh *ipoib_neigh_alloc(u8 *daddr,
 				      struct net_device *dev);
-void ipoib_neigh_free(struct net_device *dev, struct ipoib_neigh *neigh);
+void ipoib_neigh_free(struct ipoib_neigh *neigh);
+void ipoib_del_neighs_by_gid(struct net_device *dev, u8 *gid);
 
 extern struct workqueue_struct *ipoib_workqueue;
 
@@ -425,7 +442,6 @@ static inline void ipoib_put_ah(struct ipoib_ah *ah)
 {
 	kref_put(&ah->ref, ipoib_free_ah);
 }
-
 int ipoib_open(struct net_device *dev);
 int ipoib_add_pkey_attr(struct net_device *dev);
 int ipoib_add_umcast_attr(struct net_device *dev);
@@ -455,7 +471,7 @@ void ipoib_dev_cleanup(struct net_device *dev);
 
 void ipoib_mcast_join_task(struct work_struct *work);
 void ipoib_mcast_carrier_on_task(struct work_struct *work);
-void ipoib_mcast_send(struct net_device *dev, void *mgid, struct sk_buff *skb);
+void ipoib_mcast_send(struct net_device *dev, u8 *daddr, struct sk_buff *skb);
 
 void ipoib_mcast_restart_task(struct work_struct *work);
 int ipoib_mcast_start_thread(struct net_device *dev);
@@ -517,10 +533,10 @@ static inline int ipoib_cm_admin_enabled(struct net_device *dev)
 		test_bit(IPOIB_FLAG_ADMIN_CM, &priv->flags);
 }
 
-static inline int ipoib_cm_enabled(struct net_device *dev, struct neighbour *n)
+static inline int ipoib_cm_enabled(struct net_device *dev, u8 *hwaddr)
 {
 	struct ipoib_dev_priv *priv = netdev_priv(dev);
-	return IPOIB_CM_SUPPORTED(n->ha) &&
+	return IPOIB_CM_SUPPORTED(hwaddr) &&
 		test_bit(IPOIB_FLAG_ADMIN_CM, &priv->flags);
 }
 
@@ -575,7 +591,7 @@ static inline int ipoib_cm_admin_enabled(struct net_device *dev)
 {
 	return 0;
 }
-static inline int ipoib_cm_enabled(struct net_device *dev, struct neighbour *n)
+static inline int ipoib_cm_enabled(struct net_device *dev, u8 *hwaddr)
 
 {
 	return 0;

commit 936d7de3d736e0737542641269436f4b5968e9ef
Author: Roland Dreier <roland@purestorage.com>
Date:   Tue Feb 7 14:51:21 2012 +0000

    IPoIB: Stop lying about hard_header_len and use skb->cb to stash LL addresses
    
    Commit a0417fa3a18a ("net: Make qdisc_skb_cb upper size bound
    explicit.") made it possible for a netdev driver to use skb->cb
    between its header_ops.create method and its .ndo_start_xmit
    method.  Use this in ipoib_hard_header() to stash away the LL address
    (GID + QPN), instead of the "ipoib_pseudoheader" hack.  This allows
    IPoIB to stop lying about its hard_header_len, which will let us fix
    the L2 check for GRO.
    
    Signed-off-by: Roland Dreier <roland@purestorage.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index b3cc1e062b17..86df632ea612 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -44,6 +44,7 @@
 #include <linux/mutex.h>
 
 #include <net/neighbour.h>
+#include <net/sch_generic.h>
 
 #include <linux/atomic.h>
 
@@ -117,8 +118,9 @@ struct ipoib_header {
 	u16	reserved;
 };
 
-struct ipoib_pseudoheader {
-	u8  hwaddr[INFINIBAND_ALEN];
+struct ipoib_cb {
+	struct qdisc_skb_cb	qdisc_cb;
+	u8			hwaddr[INFINIBAND_ALEN];
 };
 
 /* Used for all multicast joins (broadcast, IPv4 mcast and IPv6 mcast) */

commit 60063497a95e716c9a689af3be2687d261f115b4
Author: Arun Sharma <asharma@fb.com>
Date:   Tue Jul 26 16:09:06 2011 -0700

    atomic: use <linux/atomic.h>
    
    This allows us to move duplicated code in <asm/atomic.h>
    (atomic_inc_not_zero() for now) to <linux/atomic.h>
    
    Signed-off-by: Arun Sharma <asharma@fb.com>
    Reviewed-by: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: David Miller <davem@davemloft.net>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Acked-by: Mike Frysinger <vapier@gentoo.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 7b6985a2e652..b3cc1e062b17 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -45,7 +45,7 @@
 
 #include <net/neighbour.h>
 
-#include <asm/atomic.h>
+#include <linux/atomic.h>
 
 #include <rdma/ib_verbs.h>
 #include <rdma/ib_pack.h>

commit 3d96c74d8983b16bc7ecb196e61a2173fcc3f09f
Author: Michał Mirosław <mirq-linux@rere.qmqm.pl>
Date:   Tue Apr 19 00:43:20 2011 +0000

    net: infiniband/ulp/ipoib: convert to hw_features
    
    Signed-off-by: Michał Mirosław <mirq-linux@rere.qmqm.pl>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index ab97f92fc257..7b6985a2e652 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -91,7 +91,6 @@ enum {
 	IPOIB_STOP_REAPER	  = 7,
 	IPOIB_FLAG_ADMIN_CM	  = 9,
 	IPOIB_FLAG_UMCAST	  = 10,
-	IPOIB_FLAG_CSUM		  = 11,
 
 	IPOIB_MAX_BACKOFF_SECONDS = 16,
 

commit 19e364f6801e38972673278adedaab1abf6f854c
Author: Or Gerlitz <ogerlitz@voltaire.com>
Date:   Mon Jan 10 17:41:54 2011 -0800

    IPoIB: Remove LRO support
    
    As a first step in moving from LRO to GRO, revert commit af40da894e9
    ("IPoIB: add LRO support").  Also eliminate the ethtool set_flags
    callback which isn't needed anymore.  Finally, we need to include
    <linux/sched.h> directly to get the declaration of restart_syscall()
    (which used to be included implicitly through <linux/inet_lro.h>).
    
    Cc: Ben Hutchings <bhutchings@solarflare.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Vladimir Sokolovsky <vlad@mellanox.co.il>
    Signed-off-by: Or Gerlitz <ogerlitz@voltaire.com>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 753a983a5fdc..ab97f92fc257 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -50,7 +50,7 @@
 #include <rdma/ib_verbs.h>
 #include <rdma/ib_pack.h>
 #include <rdma/ib_sa.h>
-#include <linux/inet_lro.h>
+#include <linux/sched.h>
 
 /* constants */
 
@@ -100,9 +100,6 @@ enum {
 	IPOIB_MCAST_FLAG_BUSY	  = 2,	/* joining or already joined */
 	IPOIB_MCAST_FLAG_ATTACHED = 3,
 
-	IPOIB_MAX_LRO_DESCRIPTORS = 8,
-	IPOIB_LRO_MAX_AGGR 	  = 64,
-
 	MAX_SEND_CQE		  = 16,
 	IPOIB_CM_COPYBREAK	  = 256,
 };
@@ -262,11 +259,6 @@ struct ipoib_ethtool_st {
 	u16     max_coalesced_frames;
 };
 
-struct ipoib_lro {
-	struct net_lro_mgr lro_mgr;
-	struct net_lro_desc lro_desc[IPOIB_MAX_LRO_DESCRIPTORS];
-};
-
 /*
  * Device private locking: network stack tx_lock protects members used
  * in TX fast path, lock protects everything else.  lock nests inside
@@ -352,8 +344,6 @@ struct ipoib_dev_priv {
 	int	hca_caps;
 	struct ipoib_ethtool_st ethtool;
 	struct timer_list poll_timer;
-
-	struct ipoib_lro lro;
 };
 
 struct ipoib_ah {

commit 8c165a8383ef56e84b541fa638be5cf1440010e7
Author: Harvey Harrison <harvey.harrison@gmail.com>
Date:   Tue Oct 28 22:37:41 2008 -0700

    infiniband: remove IPOIB_GID_RAW_ARG, IPOIB_GID_ARG, IPOIB_GID_FMT
    
    Signed-off-by: Harvey Harrison <harvey.harrison@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index e0c7dfabf2b4..753a983a5fdc 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -732,29 +732,6 @@ extern int ipoib_debug_level;
 	do { (void) (priv); } while (0)
 #endif /* CONFIG_INFINIBAND_IPOIB_DEBUG_DATA */
 
-
-#define IPOIB_GID_FMT		"%2.2x%2.2x:%2.2x%2.2x:%2.2x%2.2x:%2.2x%2.2x:" \
-				"%2.2x%2.2x:%2.2x%2.2x:%2.2x%2.2x:%2.2x%2.2x"
-
-#define IPOIB_GID_RAW_ARG(gid)	((u8 *)(gid))[0], \
-				((u8 *)(gid))[1], \
-				((u8 *)(gid))[2], \
-				((u8 *)(gid))[3], \
-				((u8 *)(gid))[4], \
-				((u8 *)(gid))[5], \
-				((u8 *)(gid))[6], \
-				((u8 *)(gid))[7], \
-				((u8 *)(gid))[8], \
-				((u8 *)(gid))[9], \
-				((u8 *)(gid))[10],\
-				((u8 *)(gid))[11],\
-				((u8 *)(gid))[12],\
-				((u8 *)(gid))[13],\
-				((u8 *)(gid))[14],\
-				((u8 *)(gid))[15]
-
-#define IPOIB_GID_ARG(gid)	IPOIB_GID_RAW_ARG((gid).raw)
-
 #define IPOIB_QPN(ha) (be32_to_cpup((__be32 *) ha) & 0xffffff)
 
 #endif /* _IPOIB_H */

commit 83bb63f62bda28be88b21216fbb59838a10f2348
Author: Or Gerlitz <ogerlitz@voltaire.com>
Date:   Wed Oct 22 15:49:49 2008 -0700

    IPoIB: Set netdev offload features properly for child (VLAN) interfaces
    
    Child devices were created without any offload features set, fix this by
    moving the code that computes the features into generic function which is
    now called through non-child and child device creation.
    
    Signed-off-by: Or Gerlitz <ogerlitz@voltaire.com>
    
    -- v1 has a bug where the 'result' flag in ipoib_vlan_add may be used uninitialized
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 68ba5c3482e4..e0c7dfabf2b4 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -507,6 +507,7 @@ int ipoib_pkey_dev_delay_open(struct net_device *dev);
 void ipoib_drain_cq(struct net_device *dev);
 
 void ipoib_set_ethtool_ops(struct net_device *dev);
+int ipoib_set_dev_features(struct ipoib_dev_priv *priv, struct ib_device *hca);
 
 #ifdef CONFIG_INFINIBAND_IPOIB_CM
 

commit 943c246e9ba9078a61b6bcc5b4a8131ce8befb64
Author: Roland Dreier <rolandd@cisco.com>
Date:   Tue Sep 30 10:36:21 2008 -0700

    IPoIB: Use netif_tx_lock() and get rid of private tx_lock, LLTX
    
    Currently, IPoIB is an LLTX driver that uses its own IRQ-disabling
    tx_lock.  Not only do we want to get rid of LLTX, this actually causes
    problems because of the skb_orphan() done with this tx_lock held: some
    skb destructors expect to be run with interrupts enabled.
    
    The simplest fix for this is to get rid of the driver-private tx_lock
    and stop using LLTX.  We kill off priv->tx_lock and use
    netif_tx_lock[_bh]() instead; the patch to do this is a tiny bit
    tricky because we need to update places that take priv->lock inside
    the tx_lock to disable IRQs, rather than relying on tx_lock having
    already disabled IRQs.
    
    Also, there are a couple of places where we need to disable BHs to
    make sure we have a consistent context to call netif_tx_lock() (since
    we no longer can use _irqsave() variants), and we also have to change
    ipoib_send_comp_handler() to call drain_tx_cq() through a timer rather
    than directly, because ipoib_send_comp_handler() runs in interrupt
    context and drain_tx_cq() must run in BH context so it can call
    netif_tx_lock().
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 05eb41b8ab63..68ba5c3482e4 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -268,10 +268,9 @@ struct ipoib_lro {
 };
 
 /*
- * Device private locking: tx_lock protects members used in TX fast
- * path (and we use LLTX so upper layers don't do extra locking).
- * lock protects everything else.  lock nests inside of tx_lock (ie
- * tx_lock must be acquired first if needed).
+ * Device private locking: network stack tx_lock protects members used
+ * in TX fast path, lock protects everything else.  lock nests inside
+ * of tx_lock (ie tx_lock must be acquired first if needed).
  */
 struct ipoib_dev_priv {
 	spinlock_t lock;
@@ -320,7 +319,6 @@ struct ipoib_dev_priv {
 
 	struct ipoib_rx_buf *rx_ring;
 
-	spinlock_t	     tx_lock;
 	struct ipoib_tx_buf *tx_ring;
 	unsigned	     tx_head;
 	unsigned	     tx_tail;

commit e8224e4b804b4fd26723191c1891101a5959bb8a
Author: Yossi Etigin <yossi.openib@gmail.com>
Date:   Tue Sep 16 11:57:45 2008 -0700

    IPoIB: Fix deadlock on RTNL between bcast join comp and ipoib_stop()
    
    Taking rtnl_lock in ipoib_mcast_join_complete() causes a deadlock with
    ipoib_stop().  We avoid it by scheduling the piece of code that takes
    the lock on ipoib_workqueue instead of executing it directly.  This
    works because we only flush the ipoib_workqueue with the RTNL not held.
    
    The deadlock happens because ipoib_stop() calls ipoib_ib_dev_down()
    which calls ipoib_mcast_dev_flush(), which calls ipoib_mcast_free(),
    which calls ipoib_mcast_leave(). The latter calls
    ib_sa_free_multicast(), and this waits until the multicast completion
    handler finishes.  This handler is ipoib_mcast_join_complete(), which
    waits for the rtnl_lock(), which was already taken by ipoib_stop().
    
    This bug was introduced in commit a77a57a1 ("IPoIB: Fix deadlock on
    RTNL in ipoib_stop()").
    
    Signed-off-by: Yossi Etigin <yosefe@voltaire.com>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index b0ffc9abe8c0..05eb41b8ab63 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -293,6 +293,7 @@ struct ipoib_dev_priv {
 
 	struct delayed_work pkey_poll_task;
 	struct delayed_work mcast_task;
+	struct work_struct carrier_on_task;
 	struct work_struct flush_light;
 	struct work_struct flush_normal;
 	struct work_struct flush_heavy;
@@ -464,6 +465,7 @@ int ipoib_dev_init(struct net_device *dev, struct ib_device *ca, int port);
 void ipoib_dev_cleanup(struct net_device *dev);
 
 void ipoib_mcast_join_task(struct work_struct *work);
+void ipoib_mcast_carrier_on_task(struct work_struct *work);
 void ipoib_mcast_send(struct net_device *dev, void *mgid, struct sk_buff *skb);
 
 void ipoib_mcast_restart_task(struct work_struct *work);

commit bc3a290b51aaefc6a6af2d6e6d52ed32387c416c
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Mon Jul 14 23:48:52 2008 -0700

    IPoIB: Double default RX/TX ring sizes
    
    Increase IPoIB ring sizes to twice their original sizes (RX: 128->256,
    TX: 64->128) to act as a shock absorber for high traffic peaks.  With
    the current settings, we have seen cases that there are many calls to
    netif_stop_queue(), which causes degradation in throughput.  Also,
    larger receive buffer sizes help IPoIB in CM mode to avoid experiencing
    RNR NAK conditions due to insufficient receive buffers at the SRQ.
    
    Signed-off-by: Eli Cohen <eli@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 0281c8fecc90..b0ffc9abe8c0 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -70,8 +70,8 @@ enum {
 	IPOIB_CM_BUF_SIZE	  = IPOIB_CM_MTU  + IPOIB_ENCAP_LEN,
 	IPOIB_CM_HEAD_SIZE	  = IPOIB_CM_BUF_SIZE % PAGE_SIZE,
 	IPOIB_CM_RX_SG		  = ALIGN(IPOIB_CM_BUF_SIZE, PAGE_SIZE) / PAGE_SIZE,
-	IPOIB_RX_RING_SIZE	  = 128,
-	IPOIB_TX_RING_SIZE	  = 64,
+	IPOIB_RX_RING_SIZE	  = 256,
+	IPOIB_TX_RING_SIZE	  = 128,
 	IPOIB_MAX_QUEUE_SIZE	  = 8192,
 	IPOIB_MIN_QUEUE_SIZE	  = 2,
 	IPOIB_CM_MAX_CONN_QP	  = 4096,

commit e112373fd6aa280bd2cbc0d5cc3809115325a1be
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Mon Jul 14 23:48:52 2008 -0700

    IPoIB/cm: Reduce connected mode TX object size
    
    Since IPoIB connected mode does not NETIF_F_SG, we only have one DMA
    mapping per send, so we don't need a mapping[] array.  Define a new
    struct with a single u64 mapping member and use it for the CM tx_ring.
    
    Signed-off-by: Eli Cohen <eli@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index a89b9fbe1ef4..0281c8fecc90 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -157,6 +157,11 @@ struct ipoib_tx_buf {
 	u64		mapping[MAX_SKB_FRAGS + 1];
 };
 
+struct ipoib_cm_tx_buf {
+	struct sk_buff *skb;
+	u64		mapping;
+};
+
 struct ib_cm_id;
 
 struct ipoib_cm_data {
@@ -215,7 +220,7 @@ struct ipoib_cm_tx {
 	struct net_device   *dev;
 	struct ipoib_neigh  *neigh;
 	struct ipoib_path   *path;
-	struct ipoib_tx_buf *tx_ring;
+	struct ipoib_cm_tx_buf *tx_ring;
 	unsigned	     tx_head;
 	unsigned	     tx_tail;
 	unsigned long	     flags;

commit 9eae554c171e086c89ab83da2a2d3c8bf958fcb5
Author: Roland Dreier <rolandd@cisco.com>
Date:   Mon Jul 14 23:48:50 2008 -0700

    IPoIB: Get rid of ipoib_mcast_detach() wrapper
    
    ipoib_mcast_detach() does nothing except call ib_detach_mcast(), so just
    use the core API in the one place that does a multicast group detach.
    
    add/remove: 0/1 grow/shrink: 0/1 up/down: 0/-105 (-105)
    function                                     old     new   delta
    ipoib_mcast_leave                            357     319     -38
    ipoib_mcast_detach                            67       -     -67
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 7b46e2d7b3c2..a89b9fbe1ef4 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -486,8 +486,6 @@ void ipoib_path_iter_read(struct ipoib_path_iter *iter,
 
 int ipoib_mcast_attach(struct net_device *dev, u16 mlid,
 		       union ib_gid *mgid, int set_qkey);
-int ipoib_mcast_detach(struct net_device *dev, u16 mlid,
-		       union ib_gid *mgid);
 
 int ipoib_init_qp(struct net_device *dev);
 int ipoib_transport_dev_init(struct net_device *dev, struct ib_device *ca);

commit d0de13622d5ac658efe7c51521dbdbe0752aa3dd
Author: Eli Cohen <eli@mellanox.co.il>
Date:   Mon Jul 14 23:48:50 2008 -0700

    IPoIB: Only set Q_Key once: after joining broadcast group
    
    The current code will set the Q_Key for any join of a non-sendonly
    multicast group.  The operation involves a modify QP operation, which
    is fairly heavyweight, and is only really required after the join of
    the broadcast group.  Fix this by adding a parameter to ipoib_mcast_attach()
    to control when the Q_Key is set.
    
    Signed-off-by: Eli Cohen <eli@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index b8753222c870..7b46e2d7b3c2 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -485,7 +485,7 @@ void ipoib_path_iter_read(struct ipoib_path_iter *iter,
 #endif
 
 int ipoib_mcast_attach(struct net_device *dev, u16 mlid,
-		       union ib_gid *mgid);
+		       union ib_gid *mgid, int set_qkey);
 int ipoib_mcast_detach(struct net_device *dev, u16 mlid,
 		       union ib_gid *mgid);
 

commit 5892eff91ad60ba365ae7f75050ce464036c5396
Author: Eli Cohen <eli@mellanox.co.il>
Date:   Mon Jul 14 23:48:50 2008 -0700

    IPoIB: Remove priv->mcast_mutex
    
    No need for a mutex around calls to ib_attach_mcast/ib_detach_mcast
    since these operations are synchronized at the HW driver layer.
    
    Signed-off-by: Eli Cohen <eli@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 66a897567ea9..b8753222c870 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -277,7 +277,6 @@ struct ipoib_dev_priv {
 
 	unsigned long flags;
 
-	struct mutex mcast_mutex;
 	struct mutex vlan_mutex;
 
 	struct rb_root  path_tree;

commit c03d4731b5b6de45b95a10bf1d510dde423d6757
Author: Eli Cohen <eli@mellanox.co.il>
Date:   Mon Jul 14 23:48:50 2008 -0700

    IPoIB: Remove unused IPOIB_MCAST_STARTED code
    
    The IPOIB_MCAST_STARTED flag is not used at all since commit b3e2749b
    ("IPoIB: Don't drop multicast sends when they can be queued"), so
    remove it.
    
    Signed-off-by: Eli Cohen <eli@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index bb19587c5eaf..66a897567ea9 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -89,7 +89,6 @@ enum {
 	IPOIB_FLAG_SUBINTERFACE	  = 5,
 	IPOIB_MCAST_RUN		  = 6,
 	IPOIB_STOP_REAPER	  = 7,
-	IPOIB_MCAST_STARTED	  = 8,
 	IPOIB_FLAG_ADMIN_CM	  = 9,
 	IPOIB_FLAG_UMCAST	  = 10,
 	IPOIB_FLAG_CSUM		  = 11,

commit ee1e2c82c245a5fb2864e9dbcdaab3390fde3fcc
Author: Moni Shoua <monis@Voltaire.COM>
Date:   Mon Jul 14 23:48:49 2008 -0700

    IPoIB: Refresh paths instead of flushing them on SM change events
    
    The patch tries to solve the problem of device going down and paths being
    flushed on an SM change event. The method is to mark the paths as candidates for
    refresh (by setting the new valid flag to 0), and wait for an ARP
    probe a new path record query.
    
    The solution requires a different and less intrusive handling of SM
    change event. For that, the second argument of the flush function
    changes its meaning from a boolean flag to a level.  In most cases, SM
    failover doesn't cause LID change so traffic won't stop.  In the rare
    cases of LID change, the remote host (the one that hadn't changed its
    LID) will lose connectivity until paths are refreshed. This is no
    worse than the current state.  In fact, preventing the device from
    going down saves packets that otherwise would be lost.
    
    Signed-off-by: Moni Levy <monil@voltaire.com>
    Signed-off-by: Moni Shoua <monis@voltaire.com>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 2c522572e3c5..bb19587c5eaf 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -54,6 +54,12 @@
 
 /* constants */
 
+enum ipoib_flush_level {
+	IPOIB_FLUSH_LIGHT,
+	IPOIB_FLUSH_NORMAL,
+	IPOIB_FLUSH_HEAVY
+};
+
 enum {
 	IPOIB_ENCAP_LEN		  = 4,
 
@@ -284,10 +290,11 @@ struct ipoib_dev_priv {
 
 	struct delayed_work pkey_poll_task;
 	struct delayed_work mcast_task;
-	struct work_struct flush_task;
+	struct work_struct flush_light;
+	struct work_struct flush_normal;
+	struct work_struct flush_heavy;
 	struct work_struct restart_task;
 	struct delayed_work ah_reap_task;
-	struct work_struct pkey_event_task;
 
 	struct ib_device *ca;
 	u8		  port;
@@ -369,6 +376,7 @@ struct ipoib_path {
 
 	struct rb_node	      rb_node;
 	struct list_head      list;
+	int  		      valid;
 };
 
 struct ipoib_neigh {
@@ -433,11 +441,14 @@ void ipoib_send(struct net_device *dev, struct sk_buff *skb,
 		struct ipoib_ah *address, u32 qpn);
 void ipoib_reap_ah(struct work_struct *work);
 
+void ipoib_mark_paths_invalid(struct net_device *dev);
 void ipoib_flush_paths(struct net_device *dev);
 struct ipoib_dev_priv *ipoib_intf_alloc(const char *format);
 
 int ipoib_ib_dev_init(struct net_device *dev, struct ib_device *ca, int port);
-void ipoib_ib_dev_flush(struct work_struct *work);
+void ipoib_ib_dev_flush_light(struct work_struct *work);
+void ipoib_ib_dev_flush_normal(struct work_struct *work);
+void ipoib_ib_dev_flush_heavy(struct work_struct *work);
 void ipoib_pkey_event(struct work_struct *work);
 void ipoib_ib_dev_cleanup(struct net_device *dev);
 

commit af40da894e96d5c826d38be3ea53ee00d9de0367
Author: Vladimir Sokolovsky <vlad@mellanox.co.il>
Date:   Mon Jul 14 23:48:48 2008 -0700

    IPoIB: add LRO support
    
    Add "ipoib_use_lro" module parameter to enable LRO and an
    "ipoib_lro_max_aggr" module parameter to set the max number of packets
    to be aggregated.  Make LRO controllable and LRO statistics accessible
    through ethtool.
    
    Signed-off-by: Vladimir Sokolovsky <vlad@mellanox.co.il>
    Signed-off-by: Eli Cohen <eli@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 8754b364f229..2c522572e3c5 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -50,6 +50,7 @@
 #include <rdma/ib_verbs.h>
 #include <rdma/ib_pack.h>
 #include <rdma/ib_sa.h>
+#include <linux/inet_lro.h>
 
 /* constants */
 
@@ -94,6 +95,9 @@ enum {
 	IPOIB_MCAST_FLAG_BUSY	  = 2,	/* joining or already joined */
 	IPOIB_MCAST_FLAG_ATTACHED = 3,
 
+	IPOIB_MAX_LRO_DESCRIPTORS = 8,
+	IPOIB_LRO_MAX_AGGR 	  = 64,
+
 	MAX_SEND_CQE		  = 16,
 	IPOIB_CM_COPYBREAK	  = 256,
 };
@@ -248,6 +252,11 @@ struct ipoib_ethtool_st {
 	u16     max_coalesced_frames;
 };
 
+struct ipoib_lro {
+	struct net_lro_mgr lro_mgr;
+	struct net_lro_desc lro_desc[IPOIB_MAX_LRO_DESCRIPTORS];
+};
+
 /*
  * Device private locking: tx_lock protects members used in TX fast
  * path (and we use LLTX so upper layers don't do extra locking).
@@ -334,6 +343,8 @@ struct ipoib_dev_priv {
 	int	hca_caps;
 	struct ipoib_ethtool_st ethtool;
 	struct timer_list poll_timer;
+
+	struct ipoib_lro lro;
 };
 
 struct ipoib_ah {

commit f89271da32bc1a636cf4eb078e615930886cd013
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Mon Jul 14 23:48:44 2008 -0700

    IPoIB: Copy small received SKBs in connected mode
    
    The connected mode implementation in the IPoIB driver has a large
    overhead in the way SKBs are handled in the receive flow.  It usually
    allocates an SKB with as big as was used in the currently received SKB
    and moves unused fragments from the old SKB to the new one. This
    involves a loop on all the remaining fragments and incurs overhead on
    the CPU.  This patch, for small SKBs, allocates an SKB just large
    enough to contain the received data and copies to it the data from the
    received SKB.  The newly allocated SKB is passed to the stack and the
    old SKB is reposted.
    
    When running netperf, UDP small messages, without this pach I get:
    
        UDP UNIDIRECTIONAL SEND TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to
        14.4.3.178 (14.4.3.178) port 0 AF_INET
        Socket  Message  Elapsed      Messages
        Size    Size     Time         Okay Errors   Throughput
        bytes   bytes    secs            #      #   10^6bits/sec
    
        114688     128   10.00     5142034      0     526.31
        114688           10.00     1130489            115.71
    
    With this patch I get both send and receive at ~315 mbps.
    
    The reason that send performance actually slows down is as follows:
    When using this patch, the overhead of the CPU for handling RX packets
    is dramatically reduced.  As a result, we do not experience RNR NAK
    messages from the receiver which cause the connection to be closed and
    reopened again; when the patch is not used, the receiver cannot handle
    the packets fast enough so there is less time to post new buffers and
    hence the mentioned RNR NACKs.  So what happens is that the
    application *thinks* it posted a certain number of packets for
    transmission but these packets are flushed and do not really get
    transmitted.  Since the connection gets opened and closed many times,
    each time netperf gets the CPU time that otherwise would have been
    given to IPoIB to actually transmit the packets.  This can be verified
    when looking at the port counters -- the output of ifconfig and the
    oputput of netperf (this is for the case without the patch):
    
        tx packets
        ==========
        port counter:   1,543,996
        ifconfig:       1,581,426
        netperf:        5,142,034
    
        rx packets
        ==========
        netperf         1,1304,089
    
    Signed-off-by: Eli Cohen <eli@mellanox.co.il>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 0dcbab3203c9..8754b364f229 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -95,6 +95,7 @@ enum {
 	IPOIB_MCAST_FLAG_ATTACHED = 3,
 
 	MAX_SEND_CQE		  = 16,
+	IPOIB_CM_COPYBREAK	  = 256,
 };
 
 #define	IPOIB_OP_RECV   (1ul << 31)

commit f3781d2e89f12dd5afa046dc56032af6e39bd116
Author: Roland Dreier <rolandd@cisco.com>
Date:   Mon Jul 14 23:48:44 2008 -0700

    RDMA: Remove subversion $Id tags
    
    They don't get updated by git and so they're worse than useless.
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index ca126fc2b853..0dcbab3203c9 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -30,8 +30,6 @@
  * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
  * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
  * SOFTWARE.
- *
- * $Id: ipoib.h 1358 2004-12-17 22:00:11Z roland $
  */
 
 #ifndef _IPOIB_H

commit 57ce41d1d18279cc90223f3deadca70c7de1cfca
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Wed Apr 30 20:02:45 2008 -0700

    IB/ipoib: Fix transmit queue stalling forever
    
    Commit f56bcd80 ("IPoIB: Use separate CQ for UD send completions")
    introduced a bug where the transmit queue could get stopped and never
    woken up.  The problem is that send completions are only polled at the
    end of the xmit function, so if the send queue fills up and the xmit
    path stops the queue, then there is no way for send completions to
    ever get polled, and so the transmit queue stays stopped forever.
    
    Fix this by arming the send CQ just before posting the last send
    request that fills the send queue.  Then, when the completion event
    handler is called, drain the send CQ.  Since it is possible that not
    enough send completions are in the CQ, verify that the the net queue
    has been woken up after draining the send CQ, and if not arm a timer
    and drain again at the timer function.
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 9044f8803532..ca126fc2b853 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -334,6 +334,7 @@ struct ipoib_dev_priv {
 #endif
 	int	hca_caps;
 	struct ipoib_ethtool_st ethtool;
+	struct timer_list poll_timer;
 };
 
 struct ipoib_ah {
@@ -404,6 +405,7 @@ extern struct workqueue_struct *ipoib_workqueue;
 
 int ipoib_poll(struct napi_struct *napi, int budget);
 void ipoib_ib_completion(struct ib_cq *cq, void *dev_ptr);
+void ipoib_send_comp_handler(struct ib_cq *cq, void *dev_ptr);
 
 struct ipoib_ah *ipoib_create_ah(struct net_device *dev,
 				 struct ib_pd *pd, struct ib_ah_attr *attr);

commit f56bcd8013566d4ad4759ae5fc85a6660e4655c7
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Tue Apr 29 13:46:53 2008 -0700

    IPoIB: Use separate CQ for UD send completions
    
    Use a dedicated CQ for UD send completions. Also, do not arm the UD
    send CQ, which reduces the number of interrupts generated.  This patch
    farther reduces overhead by not calling poll CQ for every posted send
    WR -- it does polls only when there 16 or more outstanding work requests.
    
    Signed-off-by: Eli Cohen <eli@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index f1f142dc64b1..9044f8803532 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -95,6 +95,8 @@ enum {
 	IPOIB_MCAST_FLAG_SENDONLY = 1,
 	IPOIB_MCAST_FLAG_BUSY	  = 2,	/* joining or already joined */
 	IPOIB_MCAST_FLAG_ATTACHED = 3,
+
+	MAX_SEND_CQE		  = 16,
 };
 
 #define	IPOIB_OP_RECV   (1ul << 31)
@@ -285,7 +287,8 @@ struct ipoib_dev_priv {
 	u16		  pkey_index;
 	struct ib_pd	 *pd;
 	struct ib_mr	 *mr;
-	struct ib_cq	 *cq;
+	struct ib_cq	 *recv_cq;
+	struct ib_cq	 *send_cq;
 	struct ib_qp	 *qp;
 	u32		  qkey;
 
@@ -305,6 +308,7 @@ struct ipoib_dev_priv {
 	struct ib_sge	     tx_sge[MAX_SKB_FRAGS + 1];
 	struct ib_send_wr    tx_wr;
 	unsigned	     tx_outstanding;
+	struct ib_wc	     send_wc[MAX_SEND_CQE];
 
 	struct ib_recv_wr    rx_wr;
 	struct ib_sge	     rx_sge[IPOIB_UD_RX_SG];
@@ -662,7 +666,6 @@ static inline int ipoib_register_debugfs(void) { return 0; }
 static inline void ipoib_unregister_debugfs(void) { }
 #endif
 
-
 #define ipoib_printk(level, priv, format, arg...)	\
 	printk(level "%s: " format, ((struct ipoib_dev_priv *) priv)->dev->name , ## arg)
 #define ipoib_warn(priv, format, arg...)		\

commit bc7b3a36ba02e4053ca38653e6a753082d9add03
Author: Shirley Ma <mashirle@us.ibm.com>
Date:   Wed Apr 23 11:55:45 2008 -0700

    IPoIB: Handle 4K IB MTU for UD (datagram) mode
    
    This patch enables IPoIB to use 4K UD messages (when the underlying
    device and fabrics support a 4K MTU) by using two scatter buffers when
    PAGE_SIZE is less than or equal to thhe HCA IB MTU size.  The first
    buffer is for IPoIB header + GRH header, and the second buffer is the
    IPoIB payload, which is 4K-4.
    
    Signed-off-by: Shirley Ma <xma@us.ibm.com>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 73b2b176ad0e..f1f142dc64b1 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -56,11 +56,11 @@
 /* constants */
 
 enum {
-	IPOIB_PACKET_SIZE	  = 2048,
-	IPOIB_BUF_SIZE		  = IPOIB_PACKET_SIZE + IB_GRH_BYTES,
-
 	IPOIB_ENCAP_LEN		  = 4,
 
+	IPOIB_UD_HEAD_SIZE	  = IB_GRH_BYTES + IPOIB_ENCAP_LEN,
+	IPOIB_UD_RX_SG		  = 2, /* max buffer needed for 4K mtu */
+
 	IPOIB_CM_MTU		  = 0x10000 - 0x10, /* padding to align header to 16 */
 	IPOIB_CM_BUF_SIZE	  = IPOIB_CM_MTU  + IPOIB_ENCAP_LEN,
 	IPOIB_CM_HEAD_SIZE	  = IPOIB_CM_BUF_SIZE % PAGE_SIZE,
@@ -139,7 +139,7 @@ struct ipoib_mcast {
 
 struct ipoib_rx_buf {
 	struct sk_buff *skb;
-	u64		mapping;
+	u64		mapping[IPOIB_UD_RX_SG];
 };
 
 struct ipoib_tx_buf {
@@ -294,6 +294,7 @@ struct ipoib_dev_priv {
 
 	unsigned int admin_mtu;
 	unsigned int mcast_mtu;
+	unsigned int max_ib_mtu;
 
 	struct ipoib_rx_buf *rx_ring;
 
@@ -305,6 +306,9 @@ struct ipoib_dev_priv {
 	struct ib_send_wr    tx_wr;
 	unsigned	     tx_outstanding;
 
+	struct ib_recv_wr    rx_wr;
+	struct ib_sge	     rx_sge[IPOIB_UD_RX_SG];
+
 	struct ib_wc ibwc[IPOIB_NUM_WC];
 
 	struct list_head dead_ahs;
@@ -366,6 +370,14 @@ struct ipoib_neigh {
 	struct list_head    list;
 };
 
+#define IPOIB_UD_MTU(ib_mtu)		(ib_mtu - IPOIB_ENCAP_LEN)
+#define IPOIB_UD_BUF_SIZE(ib_mtu)	(ib_mtu + IB_GRH_BYTES)
+
+static inline int ipoib_ud_need_sg(unsigned int ib_mtu)
+{
+	return IPOIB_UD_BUF_SIZE(ib_mtu) > PAGE_SIZE;
+}
+
 /*
  * We stash a pointer to our private neighbour information after our
  * hardware address in neigh->ha.  The ALIGN() expression here makes

commit 28d52b3cd8d48ef0ff77d4a8a7a21fc2816bb0a5
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Wed Apr 16 21:09:33 2008 -0700

    IPoIB: Support modifying IPoIB CQ event moderation
    
    This can be used to tune at run time the parameters controlling the
    event (interrupt) generation rate and thus reduce the overhead
    incurred by handling interrupts resulting in better throughput.  Since
    IPoIB uses a single CQ for both RX and TX, RX is chosen to dictate
    configuration for both RX and TX.
    
    Signed-off-by: Eli Cohen <eli@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 3524d65f2e57..73b2b176ad0e 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -242,6 +242,11 @@ struct ipoib_cm_dev_priv {
 	int			num_frags;
 };
 
+struct ipoib_ethtool_st {
+	u16     coalesce_usecs;
+	u16     max_coalesced_frames;
+};
+
 /*
  * Device private locking: tx_lock protects members used in TX fast
  * path (and we use LLTX so upper layers don't do extra locking).
@@ -320,6 +325,7 @@ struct ipoib_dev_priv {
 	struct dentry *path_dentry;
 #endif
 	int	hca_caps;
+	struct ipoib_ethtool_st ethtool;
 };
 
 struct ipoib_ah {

commit 82c24c18afc5e1c2a955bdc2762b19721283365c
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Wed Apr 16 21:09:32 2008 -0700

    IPoIB: Add basic ethtool support
    
    Just add the infrastructure so we can add functionality later.
    
    Signed-off-by: Eli Cohen <eli@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 19a41ff90d15..3524d65f2e57 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -460,6 +460,8 @@ void ipoib_pkey_poll(struct work_struct *work);
 int ipoib_pkey_dev_delay_open(struct net_device *dev);
 void ipoib_drain_cq(struct net_device *dev);
 
+void ipoib_set_ethtool_ops(struct net_device *dev);
+
 #ifdef CONFIG_INFINIBAND_IPOIB_CM
 
 #define IPOIB_FLAGS_RC		0x80

commit 40ca1988e03c001747d0b4cc1b25cf38297c9f9e
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Wed Apr 16 21:09:27 2008 -0700

    IPoIB: Add LSO support
    
    For HCAs that support TCP segmentation offload (IB_DEVICE_UD_TSO), set
    NETIF_F_TSO and use HW LSO to offload TCP segmentation.
    
    Signed-off-by: Eli Cohen <eli@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 08930ca41a30..19a41ff90d15 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -319,6 +319,7 @@ struct ipoib_dev_priv {
 	struct dentry *mcg_dentry;
 	struct dentry *path_dentry;
 #endif
+	int	hca_caps;
 };
 
 struct ipoib_ah {

commit 6046136c742e32d5e6431cdcd8957638d1816821
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Wed Apr 16 21:01:10 2008 -0700

    IPoIB: Use checksum offload support if available
    
    For HCAs that support checksum offload (ie that set IB_DEVICE_UD_IP_CSUM
    in the device capabilities flags), have IPoIB set NETIF_F_IP_CSUM and
    use the HCA to generate and verify IP checksums.
    
    Signed-off-by: Eli Cohen <eli@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 054fab8e27a0..08930ca41a30 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -87,6 +87,7 @@ enum {
 	IPOIB_MCAST_STARTED	  = 8,
 	IPOIB_FLAG_ADMIN_CM	  = 9,
 	IPOIB_FLAG_UMCAST	  = 10,
+	IPOIB_FLAG_CSUM		  = 11,
 
 	IPOIB_MAX_BACKOFF_SECONDS = 16,
 

commit a9d1884925c80b96a621939a4fef5d74de58debe
Author: Eli Cohen <eli@dev.mellanox.co.il>
Date:   Thu Feb 14 13:15:28 2008 +0200

    IPoIB: Remove unused struct ipoib_cm_tx.ibwc member
    
    struct ipoib_cm_tx.ibwc is unused since commit 1b524963 ("IPoIB/cm:
    Use common CQ for CM send completions"), so remove it.
    
    Signed-off-by: Eli Cohen <eli@mellanox.co.il>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index f9b7caa54143..054fab8e27a0 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -209,7 +209,6 @@ struct ipoib_cm_tx {
 	unsigned	     tx_tail;
 	unsigned long	     flags;
 	u32		     mtu;
-	struct ib_wc	     ibwc[IPOIB_NUM_WC];
 };
 
 struct ipoib_cm_rx_buf {

commit 7143740d26098aca84ecc7376ccfe2c58fd0412e
Author: Eli Cohen <eli@mellanox.co.il>
Date:   Wed Jan 30 18:30:53 2008 +0200

    IPoIB: Add send gather support
    
    This patch acts as a preparation for using checksum offload for IB
    devices capable of inserting/verifying checksum in IP packets.  The
    patch does not actaully turn on NETIF_F_SG - we defer that to the
    patches adding checksum offload capabilities.
    
    We only add support for send gathers for datagram mode, since existing
    HW does not support checksum offload on connected QPs.
    
    Signed-off-by: Michael S. Tsirkin <mst@mellanox.co.il>
    Signed-off-by: Eli Cohen <eli@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index fe250c60607d..f9b7caa54143 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -143,7 +143,7 @@ struct ipoib_rx_buf {
 
 struct ipoib_tx_buf {
 	struct sk_buff *skb;
-	u64		mapping;
+	u64		mapping[MAX_SKB_FRAGS + 1];
 };
 
 struct ib_cm_id;
@@ -296,7 +296,7 @@ struct ipoib_dev_priv {
 	struct ipoib_tx_buf *tx_ring;
 	unsigned	     tx_head;
 	unsigned	     tx_tail;
-	struct ib_sge	     tx_sge;
+	struct ib_sge	     tx_sge[MAX_SKB_FRAGS + 1];
 	struct ib_send_wr    tx_wr;
 	unsigned	     tx_outstanding;
 

commit 586a693448676de5174e752426ced69ec79ab174
Author: Pradeep Satyanarayana <pradeeps@linux.vnet.ibm.com>
Date:   Fri Dec 21 13:08:23 2007 -0800

    IPoIB/CM: Enable SRQ support on HCAs that support fewer than 16 SG entries
    
    Some HCAs (such as ehca2) support SRQ, but only support fewer than 16 SG
    entries for SRQs.  Currently IPoIB/CM implicitly assumes all HCAs will
    support 16 SG entries for SRQs (to handle a 64K MTU with 4K pages). This
    patch removes that restriction by limiting the maximum MTU in connected
    mode to what the maximum number of SRQ SG entries allows.
    
    This patch addresses <https://bugs.openfabrics.org/show_bug.cgi?id=728>
    
    Signed-off-by: Pradeep Satyanarayana <pradeeps@linux.vnet.ibm.com>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index d35025f0652b..fe250c60607d 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -238,6 +238,8 @@ struct ipoib_cm_dev_priv {
 	struct ib_sge		rx_sge[IPOIB_CM_RX_SG];
 	struct ib_recv_wr       rx_wr;
 	int			nonsrq_conn_qp;
+	int			max_cm_mtu;
+	int			num_frags;
 };
 
 /*
@@ -503,6 +505,12 @@ static inline int ipoib_cm_has_srq(struct net_device *dev)
 	return !!priv->cm.srq;
 }
 
+static inline unsigned int ipoib_cm_max_mtu(struct net_device *dev)
+{
+	struct ipoib_dev_priv *priv = netdev_priv(dev);
+	return priv->cm.max_cm_mtu;
+}
+
 void ipoib_cm_send(struct net_device *dev, struct sk_buff *skb, struct ipoib_cm_tx *tx);
 int ipoib_cm_dev_open(struct net_device *dev);
 void ipoib_cm_dev_stop(struct net_device *dev);
@@ -552,6 +560,11 @@ static inline int ipoib_cm_has_srq(struct net_device *dev)
 	return 0;
 }
 
+static inline unsigned int ipoib_cm_max_mtu(struct net_device *dev)
+{
+	return 0;
+}
+
 static inline
 void ipoib_cm_send(struct net_device *dev, struct sk_buff *skb, struct ipoib_cm_tx *tx)
 {

commit 68e995a295720439ad2bf8677114cdf9d262d905
Author: Pradeep Satyanarayana <pradeeps@linux.vnet.ibm.com>
Date:   Fri Jan 25 14:15:24 2008 -0800

    IPoIB/cm: Add connected mode support for devices without SRQs
    
    Some IB adapters (notably IBM's eHCA) do not implement SRQs (shared
    receive queues).  The current IPoIB connected mode support only works
    on devices that support SRQs.
    
    Fix this by adding support for using the receive queue of each
    connected mode receive QP.  The disadvantage of this compared to using
    an SRQ is that it means a full queue of receives must be posted for
    each remote connected mode peer, which means that total memory usage
    is potentially much higher than when using SRQs.  To manage this, add
    a new module parameter "max_nonsrq_conn_qp" that limits the number of
    connections allowed per interface.
    
    The rest of the changes are fairly straightforward: we use a table of
    struct ipoib_cm_rx to hold all the active connections, and put the
    table index of the connection in the high bits of receive WR IDs.
    This is needed because we cannot rely on the struct ib_wc.qp field for
    non-SRQ receive completions.  Most of the rest of the changes just
    test whether or not an SRQ is available, and post receives or find
    received packets in the right place depending on the answer.
    
    Cleaning up dead connections actually becomes simpler, because we do
    not have to do the "last WQE reached" dance that is required to
    destroy QPs attached to an SRQ.  We just move the QP to the error
    state and wait for all pending receives to be flushed.
    
    Signed-off-by: Pradeep Satyanarayana <pradeeps@linux.vnet.ibm.com>
    
    [ Completely rewritten and split up, based on Pradeep's work.  Several
      bugs fixed and no doubt several bugs introduced.  - Roland ]
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index a376fb6ffa0e..d35025f0652b 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -69,6 +69,7 @@ enum {
 	IPOIB_TX_RING_SIZE	  = 64,
 	IPOIB_MAX_QUEUE_SIZE	  = 8192,
 	IPOIB_MIN_QUEUE_SIZE	  = 2,
+	IPOIB_CM_MAX_CONN_QP	  = 4096,
 
 	IPOIB_NUM_WC		  = 4,
 
@@ -188,10 +189,12 @@ enum ipoib_cm_state {
 struct ipoib_cm_rx {
 	struct ib_cm_id	       *id;
 	struct ib_qp	       *qp;
+	struct ipoib_cm_rx_buf *rx_ring;
 	struct list_head	list;
 	struct net_device      *dev;
 	unsigned long		jiffies;
 	enum ipoib_cm_state	state;
+	int			recv_count;
 };
 
 struct ipoib_cm_tx {
@@ -234,6 +237,7 @@ struct ipoib_cm_dev_priv {
 	struct ib_wc		ibwc[IPOIB_NUM_WC];
 	struct ib_sge		rx_sge[IPOIB_CM_RX_SG];
 	struct ib_recv_wr       rx_wr;
+	int			nonsrq_conn_qp;
 };
 
 /*
@@ -461,6 +465,8 @@ void ipoib_drain_cq(struct net_device *dev);
 /* We don't support UC connections at the moment */
 #define IPOIB_CM_SUPPORTED(ha)   (ha[0] & (IPOIB_FLAGS_RC))
 
+extern int ipoib_max_conn_qp;
+
 static inline int ipoib_cm_admin_enabled(struct net_device *dev)
 {
 	struct ipoib_dev_priv *priv = netdev_priv(dev);
@@ -491,6 +497,12 @@ static inline void ipoib_cm_set(struct ipoib_neigh *neigh, struct ipoib_cm_tx *t
 	neigh->cm = tx;
 }
 
+static inline int ipoib_cm_has_srq(struct net_device *dev)
+{
+	struct ipoib_dev_priv *priv = netdev_priv(dev);
+	return !!priv->cm.srq;
+}
+
 void ipoib_cm_send(struct net_device *dev, struct sk_buff *skb, struct ipoib_cm_tx *tx);
 int ipoib_cm_dev_open(struct net_device *dev);
 void ipoib_cm_dev_stop(struct net_device *dev);
@@ -508,6 +520,8 @@ void ipoib_cm_handle_tx_wc(struct net_device *dev, struct ib_wc *wc);
 
 struct ipoib_cm_tx;
 
+#define ipoib_max_conn_qp 0
+
 static inline int ipoib_cm_admin_enabled(struct net_device *dev)
 {
 	return 0;
@@ -533,6 +547,11 @@ static inline void ipoib_cm_set(struct ipoib_neigh *neigh, struct ipoib_cm_tx *t
 {
 }
 
+static inline int ipoib_cm_has_srq(struct net_device *dev)
+{
+	return 0;
+}
+
 static inline
 void ipoib_cm_send(struct net_device *dev, struct sk_buff *skb, struct ipoib_cm_tx *tx)
 {

commit 2337f80941ac22f747ce6fd2c7a79e91d911a3ce
Author: Roland Dreier <rolandd@cisco.com>
Date:   Tue Oct 23 19:57:54 2007 -0700

    IPoIB: Trivial formatting cleanups
    
    Fix whitespace blunders, convert "foo* bar" to "foo *bar", etc.
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index eb7edab0e836..a376fb6ffa0e 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -56,42 +56,42 @@
 /* constants */
 
 enum {
-	IPOIB_PACKET_SIZE         = 2048,
-	IPOIB_BUF_SIZE 		  = IPOIB_PACKET_SIZE + IB_GRH_BYTES,
+	IPOIB_PACKET_SIZE	  = 2048,
+	IPOIB_BUF_SIZE		  = IPOIB_PACKET_SIZE + IB_GRH_BYTES,
 
-	IPOIB_ENCAP_LEN 	  = 4,
+	IPOIB_ENCAP_LEN		  = 4,
 
-	IPOIB_CM_MTU              = 0x10000 - 0x10, /* padding to align header to 16 */
-	IPOIB_CM_BUF_SIZE         = IPOIB_CM_MTU  + IPOIB_ENCAP_LEN,
-	IPOIB_CM_HEAD_SIZE 	  = IPOIB_CM_BUF_SIZE % PAGE_SIZE,
-	IPOIB_CM_RX_SG            = ALIGN(IPOIB_CM_BUF_SIZE, PAGE_SIZE) / PAGE_SIZE,
-	IPOIB_RX_RING_SIZE 	  = 128,
-	IPOIB_TX_RING_SIZE 	  = 64,
+	IPOIB_CM_MTU		  = 0x10000 - 0x10, /* padding to align header to 16 */
+	IPOIB_CM_BUF_SIZE	  = IPOIB_CM_MTU  + IPOIB_ENCAP_LEN,
+	IPOIB_CM_HEAD_SIZE	  = IPOIB_CM_BUF_SIZE % PAGE_SIZE,
+	IPOIB_CM_RX_SG		  = ALIGN(IPOIB_CM_BUF_SIZE, PAGE_SIZE) / PAGE_SIZE,
+	IPOIB_RX_RING_SIZE	  = 128,
+	IPOIB_TX_RING_SIZE	  = 64,
 	IPOIB_MAX_QUEUE_SIZE	  = 8192,
 	IPOIB_MIN_QUEUE_SIZE	  = 2,
 
-	IPOIB_NUM_WC 		  = 4,
+	IPOIB_NUM_WC		  = 4,
 
 	IPOIB_MAX_PATH_REC_QUEUE  = 3,
-	IPOIB_MAX_MCAST_QUEUE     = 3,
-
-	IPOIB_FLAG_OPER_UP 	  = 0,
-	IPOIB_FLAG_INITIALIZED    = 1,
-	IPOIB_FLAG_ADMIN_UP 	  = 2,
-	IPOIB_PKEY_ASSIGNED 	  = 3,
-	IPOIB_PKEY_STOP 	  = 4,
-	IPOIB_FLAG_SUBINTERFACE   = 5,
-	IPOIB_MCAST_RUN 	  = 6,
-	IPOIB_STOP_REAPER         = 7,
-	IPOIB_MCAST_STARTED       = 8,
-	IPOIB_FLAG_ADMIN_CM 	  = 9,
+	IPOIB_MAX_MCAST_QUEUE	  = 3,
+
+	IPOIB_FLAG_OPER_UP	  = 0,
+	IPOIB_FLAG_INITIALIZED	  = 1,
+	IPOIB_FLAG_ADMIN_UP	  = 2,
+	IPOIB_PKEY_ASSIGNED	  = 3,
+	IPOIB_PKEY_STOP		  = 4,
+	IPOIB_FLAG_SUBINTERFACE	  = 5,
+	IPOIB_MCAST_RUN		  = 6,
+	IPOIB_STOP_REAPER	  = 7,
+	IPOIB_MCAST_STARTED	  = 8,
+	IPOIB_FLAG_ADMIN_CM	  = 9,
 	IPOIB_FLAG_UMCAST	  = 10,
 
 	IPOIB_MAX_BACKOFF_SECONDS = 16,
 
-	IPOIB_MCAST_FLAG_FOUND 	  = 0,	/* used in set_multicast_list */
+	IPOIB_MCAST_FLAG_FOUND	  = 0,	/* used in set_multicast_list */
 	IPOIB_MCAST_FLAG_SENDONLY = 1,
-	IPOIB_MCAST_FLAG_BUSY 	  = 2,	/* joining or already joined */
+	IPOIB_MCAST_FLAG_BUSY	  = 2,	/* joining or already joined */
 	IPOIB_MCAST_FLAG_ATTACHED = 3,
 };
 
@@ -117,7 +117,7 @@ struct ipoib_pseudoheader {
 struct ipoib_mcast {
 	struct ib_sa_mcmember_rec mcmember;
 	struct ib_sa_multicast	 *mc;
-	struct ipoib_ah          *ah;
+	struct ipoib_ah		 *ah;
 
 	struct rb_node    rb_node;
 	struct list_head  list;
@@ -186,27 +186,27 @@ enum ipoib_cm_state {
 };
 
 struct ipoib_cm_rx {
-	struct ib_cm_id     *id;
-	struct ib_qp        *qp;
-	struct list_head     list;
-	struct net_device   *dev;
-	unsigned long        jiffies;
-	enum ipoib_cm_state  state;
+	struct ib_cm_id	       *id;
+	struct ib_qp	       *qp;
+	struct list_head	list;
+	struct net_device      *dev;
+	unsigned long		jiffies;
+	enum ipoib_cm_state	state;
 };
 
 struct ipoib_cm_tx {
-	struct ib_cm_id     *id;
-	struct ib_qp        *qp;
+	struct ib_cm_id	    *id;
+	struct ib_qp	    *qp;
 	struct list_head     list;
 	struct net_device   *dev;
 	struct ipoib_neigh  *neigh;
 	struct ipoib_path   *path;
 	struct ipoib_tx_buf *tx_ring;
-	unsigned             tx_head;
-	unsigned             tx_tail;
-	unsigned long        flags;
-	u32                  mtu;
-	struct ib_wc         ibwc[IPOIB_NUM_WC];
+	unsigned	     tx_head;
+	unsigned	     tx_tail;
+	unsigned long	     flags;
+	u32		     mtu;
+	struct ib_wc	     ibwc[IPOIB_NUM_WC];
 };
 
 struct ipoib_cm_rx_buf {
@@ -215,24 +215,24 @@ struct ipoib_cm_rx_buf {
 };
 
 struct ipoib_cm_dev_priv {
-	struct ib_srq  	       *srq;
+	struct ib_srq	       *srq;
 	struct ipoib_cm_rx_buf *srq_ring;
-	struct ib_cm_id        *id;
-	struct list_head        passive_ids;   /* state: LIVE */
-	struct list_head        rx_error_list; /* state: ERROR */
-	struct list_head        rx_flush_list; /* state: FLUSH, drain not started */
-	struct list_head        rx_drain_list; /* state: FLUSH, drain started */
-	struct list_head        rx_reap_list;  /* state: FLUSH, drain done */
+	struct ib_cm_id	       *id;
+	struct list_head	passive_ids;   /* state: LIVE */
+	struct list_head	rx_error_list; /* state: ERROR */
+	struct list_head	rx_flush_list; /* state: FLUSH, drain not started */
+	struct list_head	rx_drain_list; /* state: FLUSH, drain started */
+	struct list_head	rx_reap_list;  /* state: FLUSH, drain done */
 	struct work_struct      start_task;
 	struct work_struct      reap_task;
 	struct work_struct      skb_task;
 	struct work_struct      rx_reap_task;
 	struct delayed_work     stale_task;
 	struct sk_buff_head     skb_queue;
-	struct list_head        start_list;
-	struct list_head        reap_list;
-	struct ib_wc            ibwc[IPOIB_NUM_WC];
-	struct ib_sge           rx_sge[IPOIB_CM_RX_SG];
+	struct list_head	start_list;
+	struct list_head	reap_list;
+	struct ib_wc		ibwc[IPOIB_NUM_WC];
+	struct ib_sge		rx_sge[IPOIB_CM_RX_SG];
 	struct ib_recv_wr       rx_wr;
 };
 
@@ -269,30 +269,30 @@ struct ipoib_dev_priv {
 	struct work_struct pkey_event_task;
 
 	struct ib_device *ca;
-	u8            	  port;
-	u16           	  pkey;
-	u16               pkey_index;
-	struct ib_pd  	 *pd;
-	struct ib_mr  	 *mr;
-	struct ib_cq  	 *cq;
-	struct ib_qp  	 *qp;
-	u32           	  qkey;
+	u8		  port;
+	u16		  pkey;
+	u16		  pkey_index;
+	struct ib_pd	 *pd;
+	struct ib_mr	 *mr;
+	struct ib_cq	 *cq;
+	struct ib_qp	 *qp;
+	u32		  qkey;
 
 	union ib_gid local_gid;
-	u16          local_lid;
+	u16	     local_lid;
 
 	unsigned int admin_mtu;
 	unsigned int mcast_mtu;
 
 	struct ipoib_rx_buf *rx_ring;
 
-	spinlock_t           tx_lock;
+	spinlock_t	     tx_lock;
 	struct ipoib_tx_buf *tx_ring;
-	unsigned             tx_head;
-	unsigned             tx_tail;
-	struct ib_sge        tx_sge;
+	unsigned	     tx_head;
+	unsigned	     tx_tail;
+	struct ib_sge	     tx_sge;
 	struct ib_send_wr    tx_wr;
-	unsigned             tx_outstanding;
+	unsigned	     tx_outstanding;
 
 	struct ib_wc ibwc[IPOIB_NUM_WC];
 
@@ -317,10 +317,10 @@ struct ipoib_dev_priv {
 
 struct ipoib_ah {
 	struct net_device *dev;
-	struct ib_ah      *ah;
+	struct ib_ah	  *ah;
 	struct list_head   list;
-	struct kref        ref;
-	unsigned           last_send;
+	struct kref	   ref;
+	unsigned	   last_send;
 };
 
 struct ipoib_path {
@@ -331,11 +331,11 @@ struct ipoib_path {
 
 	struct list_head      neigh_list;
 
-	int                   query_id;
+	int		      query_id;
 	struct ib_sa_query   *query;
 	struct completion     done;
 
-	struct rb_node        rb_node;
+	struct rb_node	      rb_node;
 	struct list_head      list;
 };
 
@@ -344,7 +344,7 @@ struct ipoib_neigh {
 #ifdef CONFIG_INFINIBAND_IPOIB_CM
 	struct ipoib_cm_tx *cm;
 #endif
-	union ib_gid        dgid;
+	union ib_gid	    dgid;
 	struct sk_buff_head queue;
 
 	struct neighbour   *neighbour;
@@ -455,8 +455,8 @@ void ipoib_drain_cq(struct net_device *dev);
 
 #ifdef CONFIG_INFINIBAND_IPOIB_CM
 
-#define IPOIB_FLAGS_RC          0x80
-#define IPOIB_FLAGS_UC          0x40
+#define IPOIB_FLAGS_RC		0x80
+#define IPOIB_FLAGS_UC		0x40
 
 /* We don't support UC connections at the moment */
 #define IPOIB_CM_SUPPORTED(ha)   (ha[0] & (IPOIB_FLAGS_RC))
@@ -500,7 +500,7 @@ void ipoib_cm_dev_cleanup(struct net_device *dev);
 struct ipoib_cm_tx *ipoib_cm_create_tx(struct net_device *dev, struct ipoib_path *path,
 				    struct ipoib_neigh *neigh);
 void ipoib_cm_destroy_tx(struct ipoib_cm_tx *tx);
-void ipoib_cm_skb_too_long(struct net_device* dev, struct sk_buff *skb,
+void ipoib_cm_skb_too_long(struct net_device *dev, struct sk_buff *skb,
 			   unsigned int mtu);
 void ipoib_cm_handle_rx_wc(struct net_device *dev, struct ib_wc *wc);
 void ipoib_cm_handle_tx_wc(struct net_device *dev, struct ib_wc *wc);
@@ -582,7 +582,7 @@ int ipoib_cm_add_mode_attr(struct net_device *dev)
 	return 0;
 }
 
-static inline void ipoib_cm_skb_too_long(struct net_device* dev, struct sk_buff *skb,
+static inline void ipoib_cm_skb_too_long(struct net_device *dev, struct sk_buff *skb,
 					 unsigned int mtu)
 {
 	dev_kfree_skb_any(skb);
@@ -624,12 +624,12 @@ extern struct ib_sa_client ipoib_sa_client;
 extern int ipoib_debug_level;
 
 #define ipoib_dbg(priv, format, arg...)			\
-	do {					        \
+	do {						\
 		if (ipoib_debug_level > 0)			\
 			ipoib_printk(KERN_DEBUG, priv, format , ## arg); \
 	} while (0)
 #define ipoib_dbg_mcast(priv, format, arg...)		\
-	do {					        \
+	do {						\
 		if (mcast_debug_level > 0)		\
 			ipoib_printk(KERN_DEBUG, priv, format , ## arg); \
 	} while (0)
@@ -642,7 +642,7 @@ extern int ipoib_debug_level;
 
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG_DATA
 #define ipoib_dbg_data(priv, format, arg...)		\
-	do {					        \
+	do {						\
 		if (data_debug_level > 0)		\
 			ipoib_printk(KERN_DEBUG, priv, format , ## arg); \
 	} while (0)

commit 0b776eb5426752d4e53354ac89e3710d857e09a7
Merge: 0d6810091cdb 77109cc2823f
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Tue Oct 23 09:56:11 2007 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/roland/infiniband
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/roland/infiniband:
      mlx4_core: Increase command timeout for INIT_HCA to 10 seconds
      IPoIB/cm: Use common CQ for CM send completions
      IB/uverbs: Fix checking of userspace object ownership
      IB/mlx4: Sanity check userspace send queue sizes
      IPoIB: Rewrite "if (!likely(...))" as "if (unlikely(!(...)))"
      IB/ehca: Enable large page MRs by default
      IB/ehca: Change meaning of hca_cap_mr_pgsize
      IB/ehca: Fix ehca_encode_hwpage_size() and alloc_fmr()
      IB/ehca: Fix masking error in {,re}reg_phys_mr()
      IB/ehca: Supply QP token for SRQ base QPs
      IPoIB: Use round_jiffies() for ah_reap_task
      RDMA/cma: Fix deadlock destroying listen requests
      RDMA/cma: Add locking around QP accesses
      IB/mthca: Avoid alignment traps when writing doorbells
      mlx4_core: Kill mlx4_write64_raw()

commit 1b524963fd2d7fb20ea68df497151aa9d17fbca4
Author: Michael S. Tsirkin <mst@mellanox.co.il>
Date:   Thu Aug 16 15:36:16 2007 +0300

    IPoIB/cm: Use common CQ for CM send completions
    
    Use the same CQ for CM send completions as for all other IPoIB
    completions.  This means all completions are processed via the same
    NAPI polling routine.  This should help reduce the number of
    interrupts for bi-directional traffic (such as TCP) and fixes "driver
    is hogging interrupts" errors reported for IPoIB send side, e.g.
    <https://bugs.openfabrics.org/show_bug.cgi?id=508>
    
    To do this, keep a per-interface counter of outstanding send WRs, and
    stop the interface when this counter reaches the send queue size to
    avoid CQ overruns.
    
    Signed-off-by: Michael S. Tsirkin <mst@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 6545fa798b12..0a00ea0e887d 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -84,9 +84,8 @@ enum {
 	IPOIB_MCAST_RUN 	  = 6,
 	IPOIB_STOP_REAPER         = 7,
 	IPOIB_MCAST_STARTED       = 8,
-	IPOIB_FLAG_NETIF_STOPPED  = 9,
-	IPOIB_FLAG_ADMIN_CM 	  = 10,
-	IPOIB_FLAG_UMCAST	  = 11,
+	IPOIB_FLAG_ADMIN_CM 	  = 9,
+	IPOIB_FLAG_UMCAST	  = 10,
 
 	IPOIB_MAX_BACKOFF_SECONDS = 16,
 
@@ -98,9 +97,9 @@ enum {
 
 #define	IPOIB_OP_RECV   (1ul << 31)
 #ifdef CONFIG_INFINIBAND_IPOIB_CM
-#define	IPOIB_CM_OP_SRQ (1ul << 30)
+#define	IPOIB_OP_CM     (1ul << 30)
 #else
-#define	IPOIB_CM_OP_SRQ (0)
+#define	IPOIB_OP_CM     (0)
 #endif
 
 /* structs */
@@ -197,7 +196,6 @@ struct ipoib_cm_rx {
 
 struct ipoib_cm_tx {
 	struct ib_cm_id     *id;
-	struct ib_cq        *cq;
 	struct ib_qp        *qp;
 	struct list_head     list;
 	struct net_device   *dev;
@@ -294,6 +292,7 @@ struct ipoib_dev_priv {
 	unsigned             tx_tail;
 	struct ib_sge        tx_sge;
 	struct ib_send_wr    tx_wr;
+	unsigned             tx_outstanding;
 
 	struct ib_wc ibwc[IPOIB_NUM_WC];
 
@@ -502,6 +501,7 @@ void ipoib_cm_destroy_tx(struct ipoib_cm_tx *tx);
 void ipoib_cm_skb_too_long(struct net_device* dev, struct sk_buff *skb,
 			   unsigned int mtu);
 void ipoib_cm_handle_rx_wc(struct net_device *dev, struct ib_wc *wc);
+void ipoib_cm_handle_tx_wc(struct net_device *dev, struct ib_wc *wc);
 #else
 
 struct ipoib_cm_tx;
@@ -590,6 +590,9 @@ static inline void ipoib_cm_handle_rx_wc(struct net_device *dev, struct ib_wc *w
 {
 }
 
+static inline void ipoib_cm_handle_tx_wc(struct net_device *dev, struct ib_wc *wc)
+{
+}
 #endif
 
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG

commit 732a2170f499ce7cf5f0bdd4f9e0b0c8337b67e1
Author: Moni Shoua <monis@voltaire.com>
Date:   Tue Oct 9 19:43:36 2007 -0700

    IB/ipoib: Bound the net device to the ipoib_neigh structue
    
    IPoIB uses a two layer neighboring scheme, such that for each struct neighbour
    whose device is an ipoib one, there is a struct ipoib_neigh buddy which is
    created on demand at the tx flow by an ipoib_neigh_alloc(skb->dst->neighbour)
    call.
    
    When using the bonding driver, neighbours are created by the net stack on behalf
    of the bonding (master) device. On the tx flow the bonding code gets an skb such
    that skb->dev points to the master device, it changes this skb to point on the
    slave device and calls the slave hard_start_xmit function.
    
    Under this scheme, ipoib_neigh_destructor assumption that for each struct
    neighbour it gets, n->dev is an ipoib device and hence netdev_priv(n->dev)
    can be casted to struct ipoib_dev_priv is buggy.
    
    To fix it, this patch adds a dev field to struct ipoib_neigh which is used
    instead of the struct neighbour dev one, when n->dev->flags has the
    IFF_MASTER bit set.
    
    Signed-off-by: Moni Shoua <monis at voltaire.com>
    Signed-off-by: Or Gerlitz <ogerlitz at voltaire.com>
    Acked-by: Roland Dreier <rdreier@cisco.com>
    Signed-off-by: Jeff Garzik <jeff@garzik.org>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 6545fa798b12..1b3327ad6bc4 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -349,6 +349,7 @@ struct ipoib_neigh {
 	struct sk_buff_head queue;
 
 	struct neighbour   *neighbour;
+	struct net_device *dev;
 
 	struct list_head    list;
 };
@@ -365,7 +366,8 @@ static inline struct ipoib_neigh **to_ipoib_neigh(struct neighbour *neigh)
 				     INFINIBAND_ALEN, sizeof(void *));
 }
 
-struct ipoib_neigh *ipoib_neigh_alloc(struct neighbour *neigh);
+struct ipoib_neigh *ipoib_neigh_alloc(struct neighbour *neigh,
+				      struct net_device *dev);
 void ipoib_neigh_free(struct net_device *dev, struct ipoib_neigh *neigh);
 
 extern struct workqueue_struct *ipoib_workqueue;

commit ce9d3c9a6a9aef61525be07fe6ba27d937236aa2
Merge: 038a5008b2f3 3d73c2884f45
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Thu Oct 11 19:43:13 2007 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/roland/infiniband
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/roland/infiniband: (87 commits)
      mlx4_core: Fix section mismatches
      IPoIB: Allow setting policy to ignore multicast groups
      IB/mthca: Mark error paths as unlikely() in post_srq_recv functions
      IB/ipath: Minor fix to ordering of freeing and zeroing of tid pages.
      IB/ipath: Remove redundant link state checks
      IB/ipath: Fix IB_EVENT_PORT_ERR event
      IB/ipath: Better handling of unexpected GPIO interrupts
      IB/ipath: Maintain active time on all chips
      IB/ipath: Fix QHT7040 serial number check
      IB/ipath: Indicate a couple of chip bugs to userspace
      IB/ipath: iba6110 rev4 no longer needs recv header overrun workaround
      IB/ipath: Use counters in ipath_poll and cleanup interrupts in ipath_close
      IB/ipath: Remove duplicate copy of LMC
      IB/ipath: Add ability to set the LMC via the sysfs debugging interface
      IB/ipath: Optimize completion queue entry insertion and polling
      IB/ipath: Implement IB_EVENT_QP_LAST_WQE_REACHED
      IB/ipath: Generate flush CQE when QP is in error state
      IB/ipath: Remove redundant code
      IB/ipath: Future proof eeprom checksum code (contents reading)
      IB/ipath: UC RDMA WRITE with IMMEDIATE doesn't send the immediate
      ...

commit de90351219a1f1fd3cb45cf6fcc4e9d6407fd2c9
Author: Roland Dreier <rolandd@cisco.com>
Date:   Fri Sep 28 15:33:51 2007 -0700

    [IPoIB]: Convert to netdevice internal stats
    
    Use the stats member of struct netdevice in IPoIB, so we can save
    memory by deleting the stats member of struct ipoib_dev_priv, and save
    code by deleting ipoib_get_stats().
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 35f3ca42bd60..34c6128d2a34 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -280,8 +280,6 @@ struct ipoib_dev_priv {
 
 	struct ib_event_handler event_handler;
 
-	struct net_device_stats stats;
-
 	struct net_device *parent;
 	struct list_head child_intfs;
 	struct list_head list;

commit bea3348eef27e6044b6161fd04c3152215f96411
Author: Stephen Hemminger <shemminger@linux-foundation.org>
Date:   Wed Oct 3 16:41:36 2007 -0700

    [NET]: Make NAPI polling independent of struct net_device objects.
    
    Several devices have multiple independant RX queues per net
    device, and some have a single interrupt doorbell for several
    queues.
    
    In either case, it's easier to support layouts like that if the
    structure representing the poll is independant from the net
    device itself.
    
    The signature of the ->poll() call back goes from:
    
            int foo_poll(struct net_device *dev, int *budget)
    
    to
    
            int foo_poll(struct napi_struct *napi, int budget)
    
    The caller is returned the number of RX packets processed (or
    the number of "NAPI credits" consumed if you want to get
    abstract).  The callee no longer messes around bumping
    dev->quota, *budget, etc. because that is all handled in the
    caller upon return.
    
    The napi_struct is to be embedded in the device driver private data
    structures.
    
    Furthermore, it is the driver's responsibility to disable all NAPI
    instances in it's ->stop() device close handler.  Since the
    napi_struct is privatized into the driver's private data structures,
    only the driver knows how to get at all of the napi_struct instances
    it may have per-device.
    
    With lots of help and suggestions from Rusty Russell, Roland Dreier,
    Michael Chan, Jeff Garzik, and Jamal Hadi Salim.
    
    Bug fixes from Thomas Graf, Roland Dreier, Peter Zijlstra,
    Joseph Fannin, Scott Wood, Hans J. Koch, and Michael Chan.
    
    [ Ported to current tree and all drivers converted.  Integrated
      Stephen's follow-on kerneldoc additions, and restored poll_list
      handling to the old style to fix mutual exclusion issues.  -DaveM ]
    
    Signed-off-by: Stephen Hemminger <shemminger@linux-foundation.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 285c143115cc..35f3ca42bd60 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -228,6 +228,8 @@ struct ipoib_dev_priv {
 
 	struct net_device *dev;
 
+	struct napi_struct napi;
+
 	unsigned long flags;
 
 	struct mutex mcast_mutex;
@@ -351,7 +353,7 @@ extern struct workqueue_struct *ipoib_workqueue;
 
 /* functions */
 
-int ipoib_poll(struct net_device *dev, int *budget);
+int ipoib_poll(struct napi_struct *napi, int budget);
 void ipoib_ib_completion(struct ib_cq *cq, void *dev_ptr);
 
 struct ipoib_ah *ipoib_create_ah(struct net_device *dev,

commit 335a64a5a958002bc238c90de695e120c3c8c120
Author: Or Gerlitz <ogerlitz@voltaire.com>
Date:   Mon Oct 8 10:13:00 2007 +0200

    IPoIB: Allow setting policy to ignore multicast groups
    
    The kernel IB stack allows (through the RDMA CM) userspace
    applications to join and use multicast groups from the IPoIB MGID
    range.  This allows multicast traffic to be handled directly from
    userspace QPs, without going through the kernel stack, which gives
    better performance for some applications.
    
    However, to fully interoperate with IP multicast, such userspace
    applications need to participate in IGMP reports and queries, or else
    routers may not forward the multicast traffic to the system where the
    application is running.  The simplest way to do this is to share the
    kernel IGMP implementation by using the IP_ADD_MEMBERSHIP option to
    join multicast groups that are being handled directly in userspace.
    
    However, in such cases, the actual multicast traffic should not also
    be handled by the IPoIB interface, because that would burn resources
    handling multicast packets that will just be discarded in the kernel.
    
    To handle this, this patch adds lookup on the database used for IB
    multicast group reference counting when IPoIB is joining multicast
    groups, and if a multicast group is already handled by user space,
    then the IPoIB kernel driver ignores the group.  This is controlled by
    a per-interface policy flag.  When the flag is set, IPoIB will not
    join and attach its QP to a multicast group which already has an entry
    in the database; when the flag is cleared, IPoIB will behave as before
    this change.
    
    For each IPoIB interface, the /sys/class/net/$intf/umcast attribute
    controls the policy flag.  The default value is off/0.
    
    Signed-off-by: Or Gerlitz <ogerlitz@voltaire.com>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index fc16bced8e54..a198ce8371db 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -86,6 +86,7 @@ enum {
 	IPOIB_MCAST_STARTED       = 8,
 	IPOIB_FLAG_NETIF_STOPPED  = 9,
 	IPOIB_FLAG_ADMIN_CM 	  = 10,
+	IPOIB_FLAG_UMCAST	  = 11,
 
 	IPOIB_MAX_BACKOFF_SECONDS = 16,
 
@@ -384,6 +385,7 @@ static inline void ipoib_put_ah(struct ipoib_ah *ah)
 
 int ipoib_open(struct net_device *dev);
 int ipoib_add_pkey_attr(struct net_device *dev);
+int ipoib_add_umcast_attr(struct net_device *dev);
 
 void ipoib_send(struct net_device *dev, struct sk_buff *skb,
 		struct ipoib_ah *address, u32 qpn);

commit 81668838c4583b19276b16382e0c61e21ef5adf0
Author: Sean Hefty <sean.hefty@intel.com>
Date:   Thu Aug 2 12:21:31 2007 -0700

    IPoIB: Specify Traffic Class with path record queries for QoS support
    
    To support QoS within and between subnets, modify IPoIB to request
    specific Traffic Class values with path record queries, using
    the value associated with the IPoIB broadcast group.
    
    Signed-off-by: Sean Hefty <sean.hefty@intel.com>
    
    [ See some comments I made on this at v1 and v2 of the posts
      <http://lists.openfabrics.org/pipermail/general/2007-August/039275.html>
      <http://lists.openfabrics.org/pipermail/general/2007-September/040312.html> ]
    
    Reviewed-by: Or Gerlitz <ogerlitz@voltaire.com>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 285c143115cc..fc16bced8e54 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -113,7 +113,27 @@ struct ipoib_pseudoheader {
 	u8  hwaddr[INFINIBAND_ALEN];
 };
 
-struct ipoib_mcast;
+/* Used for all multicast joins (broadcast, IPv4 mcast and IPv6 mcast) */
+struct ipoib_mcast {
+	struct ib_sa_mcmember_rec mcmember;
+	struct ib_sa_multicast	 *mc;
+	struct ipoib_ah          *ah;
+
+	struct rb_node    rb_node;
+	struct list_head  list;
+
+	unsigned long created;
+	unsigned long backoff;
+
+	unsigned long flags;
+	unsigned char logcount;
+
+	struct list_head  neigh_list;
+
+	struct sk_buff_head pkt_queue;
+
+	struct net_device *dev;
+};
 
 struct ipoib_rx_buf {
 	struct sk_buff *skb;

commit ec56dc0b7f6c3fec20bbc2e98ff1a06edf2fc9b9
Author: Michael S. Tsirkin <mst@dev.mellanox.co.il>
Date:   Mon May 28 14:37:27 2007 +0300

    IPoIB/cm: Fix performance regression on Mellanox
    
    commit 518b1646 ("IPoIB/cm: Fix SRQ WR leak") introduced a severe
    performance regression on Mellanox cards, because keeping a QP in the
    error state for extended periods of time moves hardware to the slow
    path (until the QP is destroyed).  For example, MPI latency goes from
    ~3 usecs to ~7 usecs.
    
    Fix this by posting a send WR on one of the QPs that are being
    flushed, instead of using a separate drain QP that is kept in the
    error state.
    
    This fixes bug <https://bugs.openfabrics.org/show_bug.cgi?id=636>,
    reported and bisected by Scott Weitzenkamp at Cisco and debugged by
    Sasha Mikheev at Voltaire.
    
    Signed-off-by: Michael S. Tsirkin <mst@dev.mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 158759e28a5b..285c143115cc 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -156,7 +156,7 @@ struct ipoib_cm_data {
  * - and then invoke a Destroy QP or Reset QP.
  *
  * We use the second option and wait for a completion on the
- * rx_drain_qp before destroying QPs attached to our SRQ.
+ * same CQ before destroying QPs attached to our SRQ.
  */
 
 enum ipoib_cm_state {
@@ -199,7 +199,6 @@ struct ipoib_cm_dev_priv {
 	struct ib_srq  	       *srq;
 	struct ipoib_cm_rx_buf *srq_ring;
 	struct ib_cm_id        *id;
-	struct ib_qp           *rx_drain_qp;   /* generates WR described in 10.3.1 */
 	struct list_head        passive_ids;   /* state: LIVE */
 	struct list_head        rx_error_list; /* state: ERROR */
 	struct list_head        rx_flush_list; /* state: FLUSH, drain not started */

commit 2dfbfc37121d307e1f1d24c2979382cb17b19347
Author: Michael S. Tsirkin <mst@dev.mellanox.co.il>
Date:   Thu May 24 18:32:46 2007 +0300

    IPoIB/cm: Drain cq in ipoib_cm_dev_stop()
    
    Since NAPI polling is disabled while ipoib_cm_dev_stop() is running,
    ipoib_cm_dev_stop() must poll the CQ itself in order to see the
    packets draining.
    
    Signed-off-by: Michael S. Tsirkin <mst@dev.mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index a0b3782c7625..158759e28a5b 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -429,6 +429,7 @@ int ipoib_vlan_delete(struct net_device *pdev, unsigned short pkey);
 
 void ipoib_pkey_poll(struct work_struct *work);
 int ipoib_pkey_dev_delay_open(struct net_device *dev);
+void ipoib_drain_cq(struct net_device *dev);
 
 #ifdef CONFIG_INFINIBAND_IPOIB_CM
 

commit 518b1646f8a31904ca637b8df0c1e31c34a7a3c2
Author: Michael S. Tsirkin <mst@dev.mellanox.co.il>
Date:   Mon May 21 15:04:59 2007 +0300

    IPoIB/cm: Fix SRQ WR leak
    
    SRQ WR leakage has been observed with IPoIB/CM: e.g. flipping ports on
    and off will, with time, leak out all WRs and then all connections
    will start getting RNR NAKs.  Fix this in the way suggested by spec:
    move the QP being destroyed to the error state, wait for "Last WQE
    Reached" event and then post WR on a "drain QP" connected to the same
    CQ.  Once we observe a completion on the drain QP, it's safe to call
    ib_destroy_qp.
    
    Signed-off-by: Michael S. Tsirkin <mst@dev.mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 93d4a9a1e1dd..a0b3782c7625 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -132,12 +132,46 @@ struct ipoib_cm_data {
 	__be32 mtu;
 };
 
+/*
+ * Quoting 10.3.1 Queue Pair and EE Context States:
+ *
+ * Note, for QPs that are associated with an SRQ, the Consumer should take the
+ * QP through the Error State before invoking a Destroy QP or a Modify QP to the
+ * Reset State.  The Consumer may invoke the Destroy QP without first performing
+ * a Modify QP to the Error State and waiting for the Affiliated Asynchronous
+ * Last WQE Reached Event. However, if the Consumer does not wait for the
+ * Affiliated Asynchronous Last WQE Reached Event, then WQE and Data Segment
+ * leakage may occur. Therefore, it is good programming practice to tear down a
+ * QP that is associated with an SRQ by using the following process:
+ *
+ * - Put the QP in the Error State
+ * - Wait for the Affiliated Asynchronous Last WQE Reached Event;
+ * - either:
+ *       drain the CQ by invoking the Poll CQ verb and either wait for CQ
+ *       to be empty or the number of Poll CQ operations has exceeded
+ *       CQ capacity size;
+ * - or
+ *       post another WR that completes on the same CQ and wait for this
+ *       WR to return as a WC;
+ * - and then invoke a Destroy QP or Reset QP.
+ *
+ * We use the second option and wait for a completion on the
+ * rx_drain_qp before destroying QPs attached to our SRQ.
+ */
+
+enum ipoib_cm_state {
+	IPOIB_CM_RX_LIVE,
+	IPOIB_CM_RX_ERROR, /* Ignored by stale task */
+	IPOIB_CM_RX_FLUSH  /* Last WQE Reached event observed */
+};
+
 struct ipoib_cm_rx {
 	struct ib_cm_id     *id;
 	struct ib_qp        *qp;
 	struct list_head     list;
 	struct net_device   *dev;
 	unsigned long        jiffies;
+	enum ipoib_cm_state  state;
 };
 
 struct ipoib_cm_tx {
@@ -165,10 +199,16 @@ struct ipoib_cm_dev_priv {
 	struct ib_srq  	       *srq;
 	struct ipoib_cm_rx_buf *srq_ring;
 	struct ib_cm_id        *id;
-	struct list_head        passive_ids;
+	struct ib_qp           *rx_drain_qp;   /* generates WR described in 10.3.1 */
+	struct list_head        passive_ids;   /* state: LIVE */
+	struct list_head        rx_error_list; /* state: ERROR */
+	struct list_head        rx_flush_list; /* state: FLUSH, drain not started */
+	struct list_head        rx_drain_list; /* state: FLUSH, drain started */
+	struct list_head        rx_reap_list;  /* state: FLUSH, drain done */
 	struct work_struct      start_task;
 	struct work_struct      reap_task;
 	struct work_struct      skb_task;
+	struct work_struct      rx_reap_task;
 	struct delayed_work     stale_task;
 	struct sk_buff_head     skb_queue;
 	struct list_head        start_list;

commit 26bbf13ce1ca21ec69175bcc4b995cb8ffdf8593
Author: Yosef Etigin <yosefe@voltaire.com>
Date:   Sat May 19 08:51:54 2007 -0700

    IPoIB: Handle P_Key table reordering
    
    SM reconfiguration or failover possibly causes a shuffling of the values
    in the P_Key table. Right now, IPoIB only queries for the P_Key index
    once when it creates the device QP, and hence there are problems if the
    index of a P_Key value changes.  Fix this by using the PKEY_CHANGE event
    to trigger a recheck of the P_Key index.
    
    Signed-off-by: Yosef Etigin <yosefe@voltaire.com>
    Acked-by: Michael S. Tsirkin <mst@dev.mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 87310eeb6df0..93d4a9a1e1dd 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -201,15 +201,17 @@ struct ipoib_dev_priv {
 	struct list_head multicast_list;
 	struct rb_root multicast_tree;
 
-	struct delayed_work pkey_task;
+	struct delayed_work pkey_poll_task;
 	struct delayed_work mcast_task;
 	struct work_struct flush_task;
 	struct work_struct restart_task;
 	struct delayed_work ah_reap_task;
+	struct work_struct pkey_event_task;
 
 	struct ib_device *ca;
 	u8            	  port;
 	u16           	  pkey;
+	u16               pkey_index;
 	struct ib_pd  	 *pd;
 	struct ib_mr  	 *mr;
 	struct ib_cq  	 *cq;
@@ -333,12 +335,13 @@ struct ipoib_dev_priv *ipoib_intf_alloc(const char *format);
 
 int ipoib_ib_dev_init(struct net_device *dev, struct ib_device *ca, int port);
 void ipoib_ib_dev_flush(struct work_struct *work);
+void ipoib_pkey_event(struct work_struct *work);
 void ipoib_ib_dev_cleanup(struct net_device *dev);
 
 int ipoib_ib_dev_open(struct net_device *dev);
 int ipoib_ib_dev_up(struct net_device *dev);
 int ipoib_ib_dev_down(struct net_device *dev, int flush);
-int ipoib_ib_dev_stop(struct net_device *dev);
+int ipoib_ib_dev_stop(struct net_device *dev, int flush);
 
 int ipoib_dev_init(struct net_device *dev, struct ib_device *ca, int port);
 void ipoib_dev_cleanup(struct net_device *dev);

commit 972d45fb43f0f0793fa275c4a22998106760cd61
Merge: 5b6b54982258 8d1cc86a6278
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Mon May 7 12:18:21 2007 -0700

    Merge branch 'for-linus' of master.kernel.org:/pub/scm/linux/kernel/git/roland/infiniband
    
    * 'for-linus' of master.kernel.org:/pub/scm/linux/kernel/git/roland/infiniband:
      IPoIB: Convert to NAPI
      IB: Return "maybe missed event" hint from ib_req_notify_cq()
      IB: Add CQ comp_vector support
      IB/ipath: Fix a race condition when generating ACKs
      IB/ipath: Fix two more spin lock problems
      IB/fmr_pool: Add prefix to all printks
      IB/srp: Set proc_name
      IB/srp: Add orig_dgid sysfs attribute to scsi_host
      IPoIB/cm: Don't crash if remote side uses one QP for both directions
      RDMA/cxgb3: Support for new abort logic
      RDMA/cxgb3: Initialize cpu_idx field in cpl_close_listserv_req message
      RDMA/cxgb3: Fail qp creation if the requested max_inline is too large
      RDMA/cxgb3: Fix TERM codes
      IPoIB/cm: Fix error handling in ipoib_cm_dev_open()
      IB/ipath: Don't corrupt pending mmap list when unmapped objects are freed
      IB/mthca: Work around kernel QP starvation
      IB/ipath: Don't put QP in timeout queue if waiting to send
      IB/ipath: Don't call spin_lock_irq() from interrupt context

commit 8d1cc86a6278687efbab7b8c294ab01efe4d4231
Author: Roland Dreier <rolandd@cisco.com>
Date:   Sun May 6 21:05:32 2007 -0700

    IPoIB: Convert to NAPI
    
    Convert the IP-over-InfiniBand network device driver over to using
    NAPI to handle completions for the main CQ.  This covers all receives
    as well as datagram mode sends; send completions for connected mode
    connections are still handled from interrupt context.
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index fd558267d1cb..15867af33c44 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -311,6 +311,7 @@ extern struct workqueue_struct *ipoib_workqueue;
 
 /* functions */
 
+int ipoib_poll(struct net_device *dev, int *budget);
 void ipoib_ib_completion(struct ib_cq *cq, void *dev_ptr);
 
 struct ipoib_ah *ipoib_create_ah(struct net_device *dev,

commit 6473d160b4aba8023bcf38519a5989694dfd51a7
Author: Jean Delvare <khali@linux-fr.org>
Date:   Tue Mar 6 02:45:12 2007 -0800

    PCI: Cleanup the includes of <linux/pci.h>
    
    I noticed that many source files include <linux/pci.h> while they do
    not appear to need it. Here is an attempt to clean it all up.
    
    In order to find all possibly affected files, I searched for all
    files including <linux/pci.h> but without any other occurence of "pci"
    or "PCI". I removed the include statement from all of these, then I
    compiled an allmodconfig kernel on both i386 and x86_64 and fixed the
    false positives manually.
    
    My tests covered 66% of the affected files, so there could be false
    positives remaining. Untested files are:
    
    arch/alpha/kernel/err_common.c
    arch/alpha/kernel/err_ev6.c
    arch/alpha/kernel/err_ev7.c
    arch/ia64/sn/kernel/huberror.c
    arch/ia64/sn/kernel/xpnet.c
    arch/m68knommu/kernel/dma.c
    arch/mips/lib/iomap.c
    arch/powerpc/platforms/pseries/ras.c
    arch/ppc/8260_io/enet.c
    arch/ppc/8260_io/fcc_enet.c
    arch/ppc/8xx_io/enet.c
    arch/ppc/syslib/ppc4xx_sgdma.c
    arch/sh64/mach-cayman/iomap.c
    arch/xtensa/kernel/xtensa_ksyms.c
    arch/xtensa/platform-iss/setup.c
    drivers/i2c/busses/i2c-at91.c
    drivers/i2c/busses/i2c-mpc.c
    drivers/media/video/saa711x.c
    drivers/misc/hdpuftrs/hdpu_cpustate.c
    drivers/misc/hdpuftrs/hdpu_nexus.c
    drivers/net/au1000_eth.c
    drivers/net/fec_8xx/fec_main.c
    drivers/net/fec_8xx/fec_mii.c
    drivers/net/fs_enet/fs_enet-main.c
    drivers/net/fs_enet/mac-fcc.c
    drivers/net/fs_enet/mac-fec.c
    drivers/net/fs_enet/mac-scc.c
    drivers/net/fs_enet/mii-bitbang.c
    drivers/net/fs_enet/mii-fec.c
    drivers/net/ibm_emac/ibm_emac_core.c
    drivers/net/lasi_82596.c
    drivers/parisc/hppb.c
    drivers/sbus/sbus.c
    drivers/video/g364fb.c
    drivers/video/platinumfb.c
    drivers/video/stifb.c
    drivers/video/valkyriefb.c
    include/asm-arm/arch-ixp4xx/dma.h
    sound/oss/au1550_ac97.c
    
    I would welcome test reports for these files. I am fine with removing
    the untested files from the patch if the general opinion is that these
    changes aren't safe. The tested part would still be nice to have.
    
    Note that this patch depends on another header fixup patch I submitted
    to LKML yesterday:
      [PATCH] scatterlist.h needs types.h
      http://lkml.org/lkml/2007/3/01/141
    
    Signed-off-by: Jean Delvare <khali@linux-fr.org>
    Cc: Badari Pulavarty <pbadari@us.ibm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index fd558267d1cb..d8f6bb4f53fc 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -41,7 +41,6 @@
 #include <linux/skbuff.h>
 #include <linux/netdevice.h>
 #include <linux/workqueue.h>
-#include <linux/pci.h>
 #include <linux/kref.h>
 #include <linux/if_infiniband.h>
 #include <linux/mutex.h>

commit 658bcef619f50d9eb6028452ff9e1ad4a96c2af9
Author: Roland Dreier <rolandd@cisco.com>
Date:   Wed Feb 21 20:28:05 2007 -0800

    IPoIB: Remove unused local_rate tracking
    
    Now that low-level drivers handle the conversion from an absolute rate
    to a relative rate, there's no need for the IPoIB driver to keep track
    of the local port's data rate.
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 2594db2030b3..fd558267d1cb 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -219,7 +219,6 @@ struct ipoib_dev_priv {
 
 	union ib_gid local_gid;
 	u16          local_lid;
-	u8           local_rate;
 
 	unsigned int admin_mtu;
 	unsigned int mcast_mtu;

commit 839fcaba355abaffb7b44f0f4504093acb0b11cf
Author: Michael S. Tsirkin <mst@mellanox.co.il>
Date:   Mon Feb 5 22:12:23 2007 +0200

    IPoIB: Connected mode experimental support
    
    The following patch adds experimental support for IPoIB connected
    mode, as defined by the draft from the IETF ipoib working group.  The
    idea is to increase performance by increasing the MTU from the maximum
    of 2K (theoretically 4K) supported by IPoIB on top of UD.  With this
    code, I'm able to get 800MByte/sec or more with netperf without
    options on a Mellanox 4x back-to-back DDR system.
    
    Some notes on code:
    1. SRQ is used for scalability to large cluster sizes
    2. Only RC connections are used (UC does not support SRQ now)
    3. Retry count is set to 0 since spec draft warns against retries
    4. Each connection is used for data transfers in only 1 direction, so
       each connection is either active(TX) or passive (RX).  2 sides that
       want to communicate create 2 connections.
    5. Each active (TX) connection has a separate CQ for send completions -
       this keeps the code simple without CQ resize and other tricks
    6. To detect stale passive side connections (where the remote side is
       down), we keep an LRU list of passive connections (updated once per
       second per connection) and destroy a connection after it has been
       unused for several seconds. The LRU rule makes it possible to avoid
       scanning connections that have recently been active.
    
    Signed-off-by: Michael S. Tsirkin <mst@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 07deee8f81ce..2594db2030b3 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -62,6 +62,10 @@ enum {
 
 	IPOIB_ENCAP_LEN 	  = 4,
 
+	IPOIB_CM_MTU              = 0x10000 - 0x10, /* padding to align header to 16 */
+	IPOIB_CM_BUF_SIZE         = IPOIB_CM_MTU  + IPOIB_ENCAP_LEN,
+	IPOIB_CM_HEAD_SIZE 	  = IPOIB_CM_BUF_SIZE % PAGE_SIZE,
+	IPOIB_CM_RX_SG            = ALIGN(IPOIB_CM_BUF_SIZE, PAGE_SIZE) / PAGE_SIZE,
 	IPOIB_RX_RING_SIZE 	  = 128,
 	IPOIB_TX_RING_SIZE 	  = 64,
 	IPOIB_MAX_QUEUE_SIZE	  = 8192,
@@ -81,6 +85,8 @@ enum {
 	IPOIB_MCAST_RUN 	  = 6,
 	IPOIB_STOP_REAPER         = 7,
 	IPOIB_MCAST_STARTED       = 8,
+	IPOIB_FLAG_NETIF_STOPPED  = 9,
+	IPOIB_FLAG_ADMIN_CM 	  = 10,
 
 	IPOIB_MAX_BACKOFF_SECONDS = 16,
 
@@ -90,6 +96,13 @@ enum {
 	IPOIB_MCAST_FLAG_ATTACHED = 3,
 };
 
+#define	IPOIB_OP_RECV   (1ul << 31)
+#ifdef CONFIG_INFINIBAND_IPOIB_CM
+#define	IPOIB_CM_OP_SRQ (1ul << 30)
+#else
+#define	IPOIB_CM_OP_SRQ (0)
+#endif
+
 /* structs */
 
 struct ipoib_header {
@@ -113,6 +126,59 @@ struct ipoib_tx_buf {
 	u64		mapping;
 };
 
+struct ib_cm_id;
+
+struct ipoib_cm_data {
+	__be32 qpn; /* High byte MUST be ignored on receive */
+	__be32 mtu;
+};
+
+struct ipoib_cm_rx {
+	struct ib_cm_id     *id;
+	struct ib_qp        *qp;
+	struct list_head     list;
+	struct net_device   *dev;
+	unsigned long        jiffies;
+};
+
+struct ipoib_cm_tx {
+	struct ib_cm_id     *id;
+	struct ib_cq        *cq;
+	struct ib_qp        *qp;
+	struct list_head     list;
+	struct net_device   *dev;
+	struct ipoib_neigh  *neigh;
+	struct ipoib_path   *path;
+	struct ipoib_tx_buf *tx_ring;
+	unsigned             tx_head;
+	unsigned             tx_tail;
+	unsigned long        flags;
+	u32                  mtu;
+	struct ib_wc         ibwc[IPOIB_NUM_WC];
+};
+
+struct ipoib_cm_rx_buf {
+	struct sk_buff *skb;
+	u64 mapping[IPOIB_CM_RX_SG];
+};
+
+struct ipoib_cm_dev_priv {
+	struct ib_srq  	       *srq;
+	struct ipoib_cm_rx_buf *srq_ring;
+	struct ib_cm_id        *id;
+	struct list_head        passive_ids;
+	struct work_struct      start_task;
+	struct work_struct      reap_task;
+	struct work_struct      skb_task;
+	struct delayed_work     stale_task;
+	struct sk_buff_head     skb_queue;
+	struct list_head        start_list;
+	struct list_head        reap_list;
+	struct ib_wc            ibwc[IPOIB_NUM_WC];
+	struct ib_sge           rx_sge[IPOIB_CM_RX_SG];
+	struct ib_recv_wr       rx_wr;
+};
+
 /*
  * Device private locking: tx_lock protects members used in TX fast
  * path (and we use LLTX so upper layers don't do extra locking).
@@ -179,6 +245,10 @@ struct ipoib_dev_priv {
 	struct list_head child_intfs;
 	struct list_head list;
 
+#ifdef CONFIG_INFINIBAND_IPOIB_CM
+	struct ipoib_cm_dev_priv cm;
+#endif
+
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
 	struct list_head fs_list;
 	struct dentry *mcg_dentry;
@@ -212,6 +282,9 @@ struct ipoib_path {
 
 struct ipoib_neigh {
 	struct ipoib_ah    *ah;
+#ifdef CONFIG_INFINIBAND_IPOIB_CM
+	struct ipoib_cm_tx *cm;
+#endif
 	union ib_gid        dgid;
 	struct sk_buff_head queue;
 
@@ -315,6 +388,146 @@ int ipoib_vlan_delete(struct net_device *pdev, unsigned short pkey);
 void ipoib_pkey_poll(struct work_struct *work);
 int ipoib_pkey_dev_delay_open(struct net_device *dev);
 
+#ifdef CONFIG_INFINIBAND_IPOIB_CM
+
+#define IPOIB_FLAGS_RC          0x80
+#define IPOIB_FLAGS_UC          0x40
+
+/* We don't support UC connections at the moment */
+#define IPOIB_CM_SUPPORTED(ha)   (ha[0] & (IPOIB_FLAGS_RC))
+
+static inline int ipoib_cm_admin_enabled(struct net_device *dev)
+{
+	struct ipoib_dev_priv *priv = netdev_priv(dev);
+	return IPOIB_CM_SUPPORTED(dev->dev_addr) &&
+		test_bit(IPOIB_FLAG_ADMIN_CM, &priv->flags);
+}
+
+static inline int ipoib_cm_enabled(struct net_device *dev, struct neighbour *n)
+{
+	struct ipoib_dev_priv *priv = netdev_priv(dev);
+	return IPOIB_CM_SUPPORTED(n->ha) &&
+		test_bit(IPOIB_FLAG_ADMIN_CM, &priv->flags);
+}
+
+static inline int ipoib_cm_up(struct ipoib_neigh *neigh)
+
+{
+	return test_bit(IPOIB_FLAG_OPER_UP, &neigh->cm->flags);
+}
+
+static inline struct ipoib_cm_tx *ipoib_cm_get(struct ipoib_neigh *neigh)
+{
+	return neigh->cm;
+}
+
+static inline void ipoib_cm_set(struct ipoib_neigh *neigh, struct ipoib_cm_tx *tx)
+{
+	neigh->cm = tx;
+}
+
+void ipoib_cm_send(struct net_device *dev, struct sk_buff *skb, struct ipoib_cm_tx *tx);
+int ipoib_cm_dev_open(struct net_device *dev);
+void ipoib_cm_dev_stop(struct net_device *dev);
+int ipoib_cm_dev_init(struct net_device *dev);
+int ipoib_cm_add_mode_attr(struct net_device *dev);
+void ipoib_cm_dev_cleanup(struct net_device *dev);
+struct ipoib_cm_tx *ipoib_cm_create_tx(struct net_device *dev, struct ipoib_path *path,
+				    struct ipoib_neigh *neigh);
+void ipoib_cm_destroy_tx(struct ipoib_cm_tx *tx);
+void ipoib_cm_skb_too_long(struct net_device* dev, struct sk_buff *skb,
+			   unsigned int mtu);
+void ipoib_cm_handle_rx_wc(struct net_device *dev, struct ib_wc *wc);
+#else
+
+struct ipoib_cm_tx;
+
+static inline int ipoib_cm_admin_enabled(struct net_device *dev)
+{
+	return 0;
+}
+static inline int ipoib_cm_enabled(struct net_device *dev, struct neighbour *n)
+
+{
+	return 0;
+}
+
+static inline int ipoib_cm_up(struct ipoib_neigh *neigh)
+
+{
+	return 0;
+}
+
+static inline struct ipoib_cm_tx *ipoib_cm_get(struct ipoib_neigh *neigh)
+{
+	return NULL;
+}
+
+static inline void ipoib_cm_set(struct ipoib_neigh *neigh, struct ipoib_cm_tx *tx)
+{
+}
+
+static inline
+void ipoib_cm_send(struct net_device *dev, struct sk_buff *skb, struct ipoib_cm_tx *tx)
+{
+	return;
+}
+
+static inline
+int ipoib_cm_dev_open(struct net_device *dev)
+{
+	return 0;
+}
+
+static inline
+void ipoib_cm_dev_stop(struct net_device *dev)
+{
+	return;
+}
+
+static inline
+int ipoib_cm_dev_init(struct net_device *dev)
+{
+	return -ENOSYS;
+}
+
+static inline
+void ipoib_cm_dev_cleanup(struct net_device *dev)
+{
+	return;
+}
+
+static inline
+struct ipoib_cm_tx *ipoib_cm_create_tx(struct net_device *dev, struct ipoib_path *path,
+				    struct ipoib_neigh *neigh)
+{
+	return NULL;
+}
+
+static inline
+void ipoib_cm_destroy_tx(struct ipoib_cm_tx *tx)
+{
+	return;
+}
+
+static inline
+int ipoib_cm_add_mode_attr(struct net_device *dev)
+{
+	return 0;
+}
+
+static inline void ipoib_cm_skb_too_long(struct net_device* dev, struct sk_buff *skb,
+					 unsigned int mtu)
+{
+	dev_kfree_skb_any(skb);
+}
+
+static inline void ipoib_cm_handle_rx_wc(struct net_device *dev, struct ib_wc *wc)
+{
+}
+
+#endif
+
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
 void ipoib_create_debug_files(struct net_device *dev);
 void ipoib_delete_debug_files(struct net_device *dev);
@@ -392,4 +605,6 @@ extern int ipoib_debug_level;
 
 #define IPOIB_GID_ARG(gid)	IPOIB_GID_RAW_ARG((gid).raw)
 
+#define IPOIB_QPN(ha) (be32_to_cpup((__be32 *) ha) & 0xffffff)
+
 #endif /* _IPOIB_H */

commit 37ccf9df974f55e99bf21278133b065cbbcf3f79
Author: Ralph Campbell <ralph.campbell@qlogic.com>
Date:   Tue Dec 12 14:30:48 2006 -0800

    IPoIB: Use the new verbs DMA mapping functions
    
    Convert IPoIB to use the new DMA mapping functions
    for kernel verbs consumers.
    
    Signed-off-by: Ralph Campbell <ralph.campbell@qlogic.com>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 99547996aba2..07deee8f81ce 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -105,12 +105,12 @@ struct ipoib_mcast;
 
 struct ipoib_rx_buf {
 	struct sk_buff *skb;
-	dma_addr_t	mapping;
+	u64		mapping;
 };
 
 struct ipoib_tx_buf {
 	struct sk_buff *skb;
-	DECLARE_PCI_UNMAP_ADDR(mapping)
+	u64		mapping;
 };
 
 /*

commit 4c1ac1b49122b805adfa4efc620592f68dccf5db
Merge: c4028958b6ec d916faace3ef
Author: David Howells <dhowells@redhat.com>
Date:   Tue Dec 5 14:37:56 2006 +0000

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux-2.6
    
    Conflicts:
    
            drivers/infiniband/core/iwcm.c
            drivers/net/chelsio/cxgb2.c
            drivers/net/wireless/bcm43xx/bcm43xx_main.c
            drivers/net/wireless/prism54/islpci_eth.c
            drivers/usb/core/hub.h
            drivers/usb/input/hid-core.c
            net/core/netpoll.c
    
    Fix up merge failures with Linus's head and fix new compilation failures.
    
    Signed-Off-By: David Howells <dhowells@redhat.com>

commit 2745b5b713bf3457d8977c62dc2b3aa61f4a14b0
Author: Michael S. Tsirkin <mst@mellanox.co.il>
Date:   Thu Nov 16 14:16:47 2006 +0200

    IPoIB: Fix skb leak when freeing neighbour
    
    ipoib_neigh_free() is sometimes called while neighbour is still alive,
    so it might still have queued skbs.  Fix skb leak in this case.
    
    Signed-off-by: Michael S. Tsirkin <mst@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 0b8a79d53a00..f2b61851a49c 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -233,7 +233,7 @@ static inline struct ipoib_neigh **to_ipoib_neigh(struct neighbour *neigh)
 }
 
 struct ipoib_neigh *ipoib_neigh_alloc(struct neighbour *neigh);
-void ipoib_neigh_free(struct ipoib_neigh *neigh);
+void ipoib_neigh_free(struct net_device *dev, struct ipoib_neigh *neigh);
 
 extern struct workqueue_struct *ipoib_workqueue;
 

commit c4028958b6ecad064b1a6303a6a5906d4fe48d73
Author: David Howells <dhowells@redhat.com>
Date:   Wed Nov 22 14:57:56 2006 +0000

    WorkStruct: make allyesconfig
    
    Fix up for make allyesconfig.
    
    Signed-Off-By: David Howells <dhowells@redhat.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 0b8a79d53a00..3b2ee0eba05e 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -136,11 +136,11 @@ struct ipoib_dev_priv {
 	struct list_head multicast_list;
 	struct rb_root multicast_tree;
 
-	struct work_struct pkey_task;
-	struct work_struct mcast_task;
+	struct delayed_work pkey_task;
+	struct delayed_work mcast_task;
 	struct work_struct flush_task;
 	struct work_struct restart_task;
-	struct work_struct ah_reap_task;
+	struct delayed_work ah_reap_task;
 
 	struct ib_device *ca;
 	u8            	  port;
@@ -254,13 +254,13 @@ int ipoib_add_pkey_attr(struct net_device *dev);
 
 void ipoib_send(struct net_device *dev, struct sk_buff *skb,
 		struct ipoib_ah *address, u32 qpn);
-void ipoib_reap_ah(void *dev_ptr);
+void ipoib_reap_ah(struct work_struct *work);
 
 void ipoib_flush_paths(struct net_device *dev);
 struct ipoib_dev_priv *ipoib_intf_alloc(const char *format);
 
 int ipoib_ib_dev_init(struct net_device *dev, struct ib_device *ca, int port);
-void ipoib_ib_dev_flush(void *dev);
+void ipoib_ib_dev_flush(struct work_struct *work);
 void ipoib_ib_dev_cleanup(struct net_device *dev);
 
 int ipoib_ib_dev_open(struct net_device *dev);
@@ -271,10 +271,10 @@ int ipoib_ib_dev_stop(struct net_device *dev);
 int ipoib_dev_init(struct net_device *dev, struct ib_device *ca, int port);
 void ipoib_dev_cleanup(struct net_device *dev);
 
-void ipoib_mcast_join_task(void *dev_ptr);
+void ipoib_mcast_join_task(struct work_struct *work);
 void ipoib_mcast_send(struct net_device *dev, void *mgid, struct sk_buff *skb);
 
-void ipoib_mcast_restart_task(void *dev_ptr);
+void ipoib_mcast_restart_task(struct work_struct *work);
 int ipoib_mcast_start_thread(struct net_device *dev);
 int ipoib_mcast_stop_thread(struct net_device *dev, int flush);
 
@@ -312,7 +312,7 @@ void ipoib_event(struct ib_event_handler *handler,
 int ipoib_vlan_add(struct net_device *pdev, unsigned short pkey);
 int ipoib_vlan_delete(struct net_device *pdev, unsigned short pkey);
 
-void ipoib_pkey_poll(void *dev);
+void ipoib_pkey_poll(struct work_struct *work);
 int ipoib_pkey_dev_delay_open(struct net_device *dev);
 
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG

commit c1a0b23bf477c2e1068905f4e2b5c3cee139e853
Author: Michael S. Tsirkin <mst@mellanox.co.il>
Date:   Mon Aug 21 16:40:12 2006 -0700

    IB/sa: Require SA registration
    
    Require users to register with SA module, to prevent the sa_query
    module text from going away while an SA query callback is still
    running.  Update all in-tree users for the new interface.
    
    Signed-off-by: Michael S. Tsirkin <mst@mellanox.co.il>
    Signed-off-by: Sean Hefty <sean.hefty@intel.com>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 474aa214ab57..0b8a79d53a00 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -336,6 +336,8 @@ static inline void ipoib_unregister_debugfs(void) { }
 extern int ipoib_sendq_size;
 extern int ipoib_recvq_size;
 
+extern struct ib_sa_client ipoib_sa_client;
+
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
 extern int ipoib_debug_level;
 

commit 8a7f752125a930a83f4d8dfe37fa5a081ab19d31
Author: Michael S. Tsirkin <mst@mellanox.co.il>
Date:   Wed Jul 19 17:44:37 2006 +0300

    IB/ipoib: Fix packet loss after hardware address update
    
    The neighbour ha field may get updated without destroying the
    neighbour.  In this case, the ha field gets out of sync with the
    address handle stored in ipoib_neigh->ah, with the result that
    the ah field would point to an incorrect path, resulting in all
    packets being lost.
    
    Signed-off-by: Michael S. Tsirkin <mst@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 3f89f5e19036..474aa214ab57 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -212,6 +212,7 @@ struct ipoib_path {
 
 struct ipoib_neigh {
 	struct ipoib_ah    *ah;
+	union ib_gid        dgid;
 	struct sk_buff_head queue;
 
 	struct neighbour   *neighbour;

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jörn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jörn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 491d2afaf5b4..3f89f5e19036 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -42,7 +42,6 @@
 #include <linux/netdevice.h>
 #include <linux/workqueue.h>
 #include <linux/pci.h>
-#include <linux/config.h>
 #include <linux/kref.h>
 #include <linux/if_infiniband.h>
 #include <linux/mutex.h>

commit 37c22a77212c13201497378cc8becc5c95d0f3f5
Author: Jack Morgenstein <jackm@mellanox.co.il>
Date:   Mon May 29 19:14:05 2006 +0300

    IPoIB: Fix kernel unaligned access on ia64
    
    Fix misaligned access faults on ia64: never cast a misaligned
    neighbour->ha + 4 pointer to union ib_gid type; pass a void * pointer
    instead.  The memcpy was being optimized to use full word accesses
    because the compiler thought that union ib_gid is always aligned.
    
    The cast in IPOIB_GID_ARG is safe, since it is fixed to access each
    byte separately.
    
    Signed-off-by: Jack Morgenstein <jackm@mellanox.co.il>
    Signed-off-by: Michael S. Tsirkin <mst@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 12a1e0572ef2..491d2afaf5b4 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -272,8 +272,7 @@ int ipoib_dev_init(struct net_device *dev, struct ib_device *ca, int port);
 void ipoib_dev_cleanup(struct net_device *dev);
 
 void ipoib_mcast_join_task(void *dev_ptr);
-void ipoib_mcast_send(struct net_device *dev, union ib_gid *mgid,
-		      struct sk_buff *skb);
+void ipoib_mcast_send(struct net_device *dev, void *mgid, struct sk_buff *skb);
 
 void ipoib_mcast_restart_task(void *dev_ptr);
 int ipoib_mcast_start_thread(struct net_device *dev);
@@ -369,15 +368,26 @@ extern int ipoib_debug_level;
 #endif /* CONFIG_INFINIBAND_IPOIB_DEBUG_DATA */
 
 
-#define IPOIB_GID_FMT		"%x:%x:%x:%x:%x:%x:%x:%x"
-
-#define IPOIB_GID_ARG(gid)	be16_to_cpup((__be16 *) ((gid).raw +  0)), \
-				be16_to_cpup((__be16 *) ((gid).raw +  2)), \
-				be16_to_cpup((__be16 *) ((gid).raw +  4)), \
-				be16_to_cpup((__be16 *) ((gid).raw +  6)), \
-				be16_to_cpup((__be16 *) ((gid).raw +  8)), \
-				be16_to_cpup((__be16 *) ((gid).raw + 10)), \
-				be16_to_cpup((__be16 *) ((gid).raw + 12)), \
-				be16_to_cpup((__be16 *) ((gid).raw + 14))
+#define IPOIB_GID_FMT		"%2.2x%2.2x:%2.2x%2.2x:%2.2x%2.2x:%2.2x%2.2x:" \
+				"%2.2x%2.2x:%2.2x%2.2x:%2.2x%2.2x:%2.2x%2.2x"
+
+#define IPOIB_GID_RAW_ARG(gid)	((u8 *)(gid))[0], \
+				((u8 *)(gid))[1], \
+				((u8 *)(gid))[2], \
+				((u8 *)(gid))[3], \
+				((u8 *)(gid))[4], \
+				((u8 *)(gid))[5], \
+				((u8 *)(gid))[6], \
+				((u8 *)(gid))[7], \
+				((u8 *)(gid))[8], \
+				((u8 *)(gid))[9], \
+				((u8 *)(gid))[10],\
+				((u8 *)(gid))[11],\
+				((u8 *)(gid))[12],\
+				((u8 *)(gid))[13],\
+				((u8 *)(gid))[14],\
+				((u8 *)(gid))[15]
+
+#define IPOIB_GID_ARG(gid)	IPOIB_GID_RAW_ARG((gid).raw)
 
 #endif /* _IPOIB_H */

commit 0f4852513fb07405ce88da40d8c497060561246e
Author: Shirley Ma <xma@us.ibm.com>
Date:   Mon Apr 10 09:43:58 2006 -0700

    IPoIB: Make send and receive queue sizes tunable
    
    Make IPoIB's send and receive queue sizes tunable via module
    parameters ("send_queue_size" and "recv_queue_size").  This allows the
    queue sizes to be enlarged to fix disastrously bad performance on some
    platforms and workloads, without bloating memory usage when large
    queues aren't needed.
    
    Signed-off-by: Shirley Ma <xma@us.ibm.com>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 374109df7303..12a1e0572ef2 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -65,6 +65,8 @@ enum {
 
 	IPOIB_RX_RING_SIZE 	  = 128,
 	IPOIB_TX_RING_SIZE 	  = 64,
+	IPOIB_MAX_QUEUE_SIZE	  = 8192,
+	IPOIB_MIN_QUEUE_SIZE	  = 2,
 
 	IPOIB_NUM_WC 		  = 4,
 
@@ -332,6 +334,8 @@ static inline void ipoib_unregister_debugfs(void) { }
 #define ipoib_warn(priv, format, arg...)		\
 	ipoib_printk(KERN_WARNING, priv, format , ## arg)
 
+extern int ipoib_sendq_size;
+extern int ipoib_recvq_size;
 
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
 extern int ipoib_debug_level;

commit d2e0655ede1d91c3a586455d03a4a2d57e659830
Author: Michael S. Tsirkin <mst@mellanox.co.il>
Date:   Tue Apr 4 19:59:40 2006 +0300

    IPoIB: Consolidate private neighbour data handling
    
    Consolidate IPoIB's private neighbour data handling into
    ipoib_neigh_alloc() and ipoib_neigh_free().  This will make it easier
    to keep track of the neighbour structures that IPoIB is handling, and
    is a nice cleanup of the code:
    
    add/remove: 2/1 grow/shrink: 1/8 up/down: 100/-178 (-78)
    function                                     old     new   delta
    ipoib_neigh_alloc                              -      61     +61
    ipoib_neigh_free                               -      36     +36
    ipoib_mcast_join_finish                     1288    1291      +3
    path_rec_completion                          575     573      -2
    ipoib_mcast_join_task                        664     660      -4
    ipoib_neigh_destructor                       101      92      -9
    ipoib_neigh_setup_dev                         14       3     -11
    ipoib_neigh_setup                             17       -     -17
    path_free                                    238     215     -23
    ipoib_mcast_free                             329     306     -23
    ipoib_mcast_send                             718     684     -34
    neigh_add_path                               705     650     -55
    
    Signed-off-by: Michael S. Tsirkin <mst@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index b640107fb732..374109df7303 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -230,6 +230,9 @@ static inline struct ipoib_neigh **to_ipoib_neigh(struct neighbour *neigh)
 				     INFINIBAND_ALEN, sizeof(void *));
 }
 
+struct ipoib_neigh *ipoib_neigh_alloc(struct neighbour *neigh);
+void ipoib_neigh_free(struct ipoib_neigh *neigh);
+
 extern struct workqueue_struct *ipoib_workqueue;
 
 /* functions */

commit 7a343d4c46bc59fe617f968e996ce2fd67c5d179
Author: Leonid Arsh <leonida@voltaire.com>
Date:   Thu Mar 23 19:52:51 2006 +0200

    IPoIB: P_Key change event handling
    
    This patch causes the network interface to respond to P_Key change
    events correctly.  As a result, you'll see a child interface in the
    "RUNNING" state (netif_carrier_on()) only when the corresponding P_Key
    is configured by the SM.  When SM removes a P_Key, the "RUNNING" state
    will be disabled for the corresponding network interface.  To
    implement this, I added IB_EVENT_PKEY_CHANGE event handling.  To
    prevent flushing the device before the device is open by the "delay
    open" mechanism, I added an additional device flag called
    IPOIB_FLAG_INITIALIZED.
    
    This also prevents the child network interface from trying to join to
    multicast groups until the PKEY is configured.  We used to get error
    messages like:
    
        ib0.f2f2: couldn't attach QP to multicast group ff12:401b:f2f2:0:0:0:ffff:ffff
    
    in this case.  To fix this, I just check IPOIB_FLAG_OPER_UP flag in
    ipoib_set_mcast_list().
    
    Signed-off-by: Leonid Arsh <leonida@voltaire.com>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 1251f86ec856..b640107fb732 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -72,13 +72,14 @@ enum {
 	IPOIB_MAX_MCAST_QUEUE     = 3,
 
 	IPOIB_FLAG_OPER_UP 	  = 0,
-	IPOIB_FLAG_ADMIN_UP 	  = 1,
-	IPOIB_PKEY_ASSIGNED 	  = 2,
-	IPOIB_PKEY_STOP 	  = 3,
-	IPOIB_FLAG_SUBINTERFACE   = 4,
-	IPOIB_MCAST_RUN 	  = 5,
-	IPOIB_STOP_REAPER         = 6,
-	IPOIB_MCAST_STARTED       = 7,
+	IPOIB_FLAG_INITIALIZED    = 1,
+	IPOIB_FLAG_ADMIN_UP 	  = 2,
+	IPOIB_PKEY_ASSIGNED 	  = 3,
+	IPOIB_PKEY_STOP 	  = 4,
+	IPOIB_FLAG_SUBINTERFACE   = 5,
+	IPOIB_MCAST_RUN 	  = 6,
+	IPOIB_STOP_REAPER         = 7,
+	IPOIB_MCAST_STARTED       = 8,
 
 	IPOIB_MAX_BACKOFF_SECONDS = 16,
 

commit 0b3ea0829cbcdaee6e018a83a2949ef458213f3b
Author: Jack Morgenstein <jackm@mellanox.co.il>
Date:   Mon Mar 20 10:08:24 2006 -0800

    IPoIB: Move ipoib_ib_dev_flush() to ipoib workqueue
    
    Move ipoib_ib_dev_flush() to ipoib's workqueue.  This keeps it ordered
    with respect to other work scheduled by the ipoib driver.  This fixes
    problems with races, for example:
     - ipoib_ib_dev_flush() has started running because of an IB event
     - user does ifconfig ib0 down
     - ipoib_mcast_stop_thread() gets called twice and waits for the same
       completion twice
    
    Signed-off-by: Jack Morgenstein <jackm@mellanox.co.il>
    Signed-off-by: Michael S. Tsirkin <mst@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 638eff745b2f..1251f86ec856 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -259,7 +259,7 @@ void ipoib_ib_dev_cleanup(struct net_device *dev);
 
 int ipoib_ib_dev_open(struct net_device *dev);
 int ipoib_ib_dev_up(struct net_device *dev);
-int ipoib_ib_dev_down(struct net_device *dev);
+int ipoib_ib_dev_down(struct net_device *dev, int flush);
 int ipoib_ib_dev_stop(struct net_device *dev);
 
 int ipoib_dev_init(struct net_device *dev, struct ib_device *ca, int port);

commit 44af79f9524c29d6850591cc972f2667a27234d4
Author: Michael S. Tsirkin <mst@mellanox.co.il>
Date:   Mon Feb 20 21:50:39 2006 -0800

    IPoIB: clarify to_ipoib_neigh()
    
    Cosmetic change: make alignment explicit in to_ipoib_neigh.
    
    Signed-off-by: Michael S. Tsirkin <mst@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 2f85a9a831b1..638eff745b2f 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -217,10 +217,16 @@ struct ipoib_neigh {
 	struct list_head    list;
 };
 
+/*
+ * We stash a pointer to our private neighbour information after our
+ * hardware address in neigh->ha.  The ALIGN() expression here makes
+ * sure that this pointer is stored aligned so that an unaligned
+ * load is not needed to dereference it.
+ */
 static inline struct ipoib_neigh **to_ipoib_neigh(struct neighbour *neigh)
 {
-	return (struct ipoib_neigh **) (neigh->ha + 24 -
-					(offsetof(struct neighbour, ha) & 4));
+	return (void*) neigh + ALIGN(offsetof(struct neighbour, ha) +
+				     INFINIBAND_ALEN, sizeof(void *));
 }
 
 extern struct workqueue_struct *ipoib_workqueue;

commit 479a079663bd4c5f3d2714643b1b8c406aaba3e0
Author: Michael S. Tsirkin <mst@mellanox.co.il>
Date:   Tue Feb 7 16:37:08 2006 -0800

    IPoIB: Don't start send-only joins while multicast thread is stopped
    
    Fix the following race scenario:
      - Device is up.
      - Port event or set mcast list triggers ipoib_mcast_stop_thread,
        this cancels the query and waits on mcast "done" completion.
      - Completion is called and "done" is set.
      - Meanwhile, ipoib_mcast_send arrives and starts a new query,
        re-initializing "done".
    
    Fix this by adding a "multicast started" bit and checking it before
    starting a send-only join.
    
    Signed-off-by: Michael S. Tsirkin <mst@mellanox.co.il>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index e0a5412b7e68..2f85a9a831b1 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -78,6 +78,7 @@ enum {
 	IPOIB_FLAG_SUBINTERFACE   = 4,
 	IPOIB_MCAST_RUN 	  = 5,
 	IPOIB_STOP_REAPER         = 6,
+	IPOIB_MCAST_STARTED       = 7,
 
 	IPOIB_MAX_BACKOFF_SECONDS = 16,
 

commit 95ed644fd12f53c6fc778f3f246974e5fe3a9468
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Jan 13 14:51:39 2006 -0800

    IB: convert from semaphores to mutexes
    
    semaphore to mutex conversion by Ingo and Arjan's script.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    [ Sanity-checked on real IB hardware ]
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 9923a15a9996..e0a5412b7e68 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -45,11 +45,11 @@
 #include <linux/config.h>
 #include <linux/kref.h>
 #include <linux/if_infiniband.h>
+#include <linux/mutex.h>
 
 #include <net/neighbour.h>
 
 #include <asm/atomic.h>
-#include <asm/semaphore.h>
 
 #include <rdma/ib_verbs.h>
 #include <rdma/ib_pack.h>
@@ -123,8 +123,8 @@ struct ipoib_dev_priv {
 
 	unsigned long flags;
 
-	struct semaphore mcast_mutex;
-	struct semaphore vlan_mutex;
+	struct mutex mcast_mutex;
+	struct mutex vlan_mutex;
 
 	struct rb_root  path_tree;
 	struct list_head path_list;

commit 1732b0ef3b3a02e3df328086fb3018741c5476da
Author: Roland Dreier <rolandd@cisco.com>
Date:   Mon Nov 7 10:33:11 2005 -0800

    [IPoIB] add path record information in debugfs
    
    Add ibX_path files to debugfs that contain information about the IPoIB
    path cache.  IPoIB ARP only gives GIDs, which the IPoIB driver must
    resolve to real IB paths through the ib_sa module.  For debugging,
    when the ARP table looks OK but traffic isn't flowing, it's useful to
    be able to see if the resolution from GID to path worked.
    
    Also clean up the formatting of the existing _mcg debugfs files.
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 0095acc0fbbe..9923a15a9996 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -179,6 +179,7 @@ struct ipoib_dev_priv {
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
 	struct list_head fs_list;
 	struct dentry *mcg_dentry;
+	struct dentry *path_dentry;
 #endif
 };
 
@@ -270,7 +271,6 @@ void ipoib_mcast_dev_flush(struct net_device *dev);
 
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
 struct ipoib_mcast_iter *ipoib_mcast_iter_init(struct net_device *dev);
-void ipoib_mcast_iter_free(struct ipoib_mcast_iter *iter);
 int ipoib_mcast_iter_next(struct ipoib_mcast_iter *iter);
 void ipoib_mcast_iter_read(struct ipoib_mcast_iter *iter,
 				  union ib_gid *gid,
@@ -278,6 +278,11 @@ void ipoib_mcast_iter_read(struct ipoib_mcast_iter *iter,
 				  unsigned int *queuelen,
 				  unsigned int *complete,
 				  unsigned int *send_only);
+
+struct ipoib_path_iter *ipoib_path_iter_init(struct net_device *dev);
+int ipoib_path_iter_next(struct ipoib_path_iter *iter);
+void ipoib_path_iter_read(struct ipoib_path_iter *iter,
+			  struct ipoib_path *path);
 #endif
 
 int ipoib_mcast_attach(struct net_device *dev, u16 mlid,
@@ -299,13 +304,13 @@ void ipoib_pkey_poll(void *dev);
 int ipoib_pkey_dev_delay_open(struct net_device *dev);
 
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
-int ipoib_create_debug_file(struct net_device *dev);
-void ipoib_delete_debug_file(struct net_device *dev);
+void ipoib_create_debug_files(struct net_device *dev);
+void ipoib_delete_debug_files(struct net_device *dev);
 int ipoib_register_debugfs(void);
 void ipoib_unregister_debugfs(void);
 #else
-static inline int ipoib_create_debug_file(struct net_device *dev) { return 0; }
-static inline void ipoib_delete_debug_file(struct net_device *dev) { }
+static inline void ipoib_create_debug_files(struct net_device *dev) { }
+static inline void ipoib_delete_debug_files(struct net_device *dev) { }
 static inline int ipoib_register_debugfs(void) { return 0; }
 static inline void ipoib_unregister_debugfs(void) { }
 #endif

commit 8ae5a8a24f7fe797027d481f88c1464b0e47eede
Author: Roland Dreier <rolandd@cisco.com>
Date:   Wed Nov 2 20:51:01 2005 -0800

    [IPoIB] don't compile debug code if debugging isn't enabled
    
    Don't build ipoib_mcast_iter_ functions if CONFIG_INFINIBAND_IPOIB_DEBUG
    is not enabled -- their only callers will not be built either.
    
    Also move the prototype for ipoib_open() to ipoib.h to fix a sparse warning.
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index c994a916a58a..0095acc0fbbe 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -235,6 +235,7 @@ static inline void ipoib_put_ah(struct ipoib_ah *ah)
 	kref_put(&ah->ref, ipoib_free_ah);
 }
 
+int ipoib_open(struct net_device *dev);
 int ipoib_add_pkey_attr(struct net_device *dev);
 
 void ipoib_send(struct net_device *dev, struct sk_buff *skb,
@@ -267,6 +268,7 @@ int ipoib_mcast_stop_thread(struct net_device *dev, int flush);
 void ipoib_mcast_dev_down(struct net_device *dev);
 void ipoib_mcast_dev_flush(struct net_device *dev);
 
+#ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
 struct ipoib_mcast_iter *ipoib_mcast_iter_init(struct net_device *dev);
 void ipoib_mcast_iter_free(struct ipoib_mcast_iter *iter);
 int ipoib_mcast_iter_next(struct ipoib_mcast_iter *iter);
@@ -276,6 +278,7 @@ void ipoib_mcast_iter_read(struct ipoib_mcast_iter *iter,
 				  unsigned int *queuelen,
 				  unsigned int *complete,
 				  unsigned int *send_only);
+#endif
 
 int ipoib_mcast_attach(struct net_device *dev, u16 mlid,
 		       union ib_gid *mgid);

commit 1993d683f39f77ddb46a662d7146247877d50b8f
Author: Roland Dreier <rolandd@cisco.com>
Date:   Fri Oct 28 15:30:34 2005 -0700

    [IPoIB] Drop RX packets when out of memory
    
    Change the way IPoIB handles RX packets when it can't allocate a new
    receive skbuff.  If the allocation of a new receive skb fails, we now
    drop the packet we just received and repost the original receive skb.
    This means that the receive ring always stays full and we don't have
    to monkey around with trying to schedule a refill task for later.
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 6b14bd1c60a0..c994a916a58a 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -100,7 +100,12 @@ struct ipoib_pseudoheader {
 
 struct ipoib_mcast;
 
-struct ipoib_buf {
+struct ipoib_rx_buf {
+	struct sk_buff *skb;
+	dma_addr_t	mapping;
+};
+
+struct ipoib_tx_buf {
 	struct sk_buff *skb;
 	DECLARE_PCI_UNMAP_ADDR(mapping)
 };
@@ -150,14 +155,14 @@ struct ipoib_dev_priv {
 	unsigned int admin_mtu;
 	unsigned int mcast_mtu;
 
-	struct ipoib_buf *rx_ring;
+	struct ipoib_rx_buf *rx_ring;
 
-	spinlock_t        tx_lock;
-	struct ipoib_buf *tx_ring;
-	unsigned          tx_head;
-	unsigned          tx_tail;
-	struct ib_sge     tx_sge;
-	struct ib_send_wr tx_wr;
+	spinlock_t           tx_lock;
+	struct ipoib_tx_buf *tx_ring;
+	unsigned             tx_head;
+	unsigned             tx_tail;
+	struct ib_sge        tx_sge;
+	struct ib_send_wr    tx_wr;
 
 	struct ib_wc ibwc[IPOIB_NUM_WC];
 

commit 5b6810e048435de508ef66aebd6b78db13d651b8
Author: Roland Dreier <rolandd@cisco.com>
Date:   Tue Oct 11 11:08:24 2005 -0700

    [IPoIB] Rename ipoib_create_qp() -> ipoib_init_qp() and fix error cleanup
    
    ipoib_create_qp() no longer creates IPoIB's QP, so it shouldn't
    destroy the QP on failure -- that unwinding happens elsewhere, so the
    current code can cause a double free.  While we're at it, the
    function's name should match what it actually does, so rename it to
    ipoib_init_qp().
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 4ea1c1ca85bc..6b14bd1c60a0 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -277,7 +277,7 @@ int ipoib_mcast_attach(struct net_device *dev, u16 mlid,
 int ipoib_mcast_detach(struct net_device *dev, u16 mlid,
 		       union ib_gid *mgid);
 
-int ipoib_qp_create(struct net_device *dev);
+int ipoib_init_qp(struct net_device *dev);
 int ipoib_transport_dev_init(struct net_device *dev, struct ib_device *ca);
 void ipoib_transport_dev_cleanup(struct net_device *dev);
 

commit 8d2cae0651502028bf64844508ab18528bbd65c2
Author: Roland Dreier <rolandd@cisco.com>
Date:   Tue Sep 20 10:52:04 2005 -0700

    [PATCH] IPoIB: Don't flush workqueue from within workqueue
    
    ipoib_mcast_restart_task() is always called from within the
    single-threaded IPoIB workqueue, so flushing the workqueue from within
    the function can lead to a recursion overflow.  But since we're
    running in a single-threaded workqueue, we're already synchronized
    against other items in the workqueue, so just get rid of the flush in
    ipoib_mcast_restart_task().
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index bea960b8191f..4ea1c1ca85bc 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -257,7 +257,7 @@ void ipoib_mcast_send(struct net_device *dev, union ib_gid *mgid,
 
 void ipoib_mcast_restart_task(void *dev_ptr);
 int ipoib_mcast_start_thread(struct net_device *dev);
-int ipoib_mcast_stop_thread(struct net_device *dev);
+int ipoib_mcast_stop_thread(struct net_device *dev, int flush);
 
 void ipoib_mcast_dev_down(struct net_device *dev);
 void ipoib_mcast_dev_flush(struct net_device *dev);

commit a4d61e84804f3b14cc35c5e2af768a07c0f64ef6
Author: Roland Dreier <roland@eddore.topspincom.com>
Date:   Thu Aug 25 13:40:04 2005 -0700

    [PATCH] IB: move include files to include/rdma
    
    Move the InfiniBand headers from drivers/infiniband/include to include/rdma.
    This allows InfiniBand-using code to live elsewhere, and lets us remove the
    ugly EXTRA_CFLAGS include path from the InfiniBand Makefiles.
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index e23041c7be8f..bea960b8191f 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -51,9 +51,9 @@
 #include <asm/atomic.h>
 #include <asm/semaphore.h>
 
-#include <ib_verbs.h>
-#include <ib_pack.h>
-#include <ib_sa.h>
+#include <rdma/ib_verbs.h>
+#include <rdma/ib_pack.h>
+#include <rdma/ib_sa.h>
 
 /* constants */
 

commit 97f52eb438be7caebe026421545619d8a0c1398a
Author: Sean Hefty <sean.hefty@intel.com>
Date:   Sat Aug 13 21:05:57 2005 -0700

    [PATCH] IB: sparse endianness cleanup
    
    Fix sparse warnings.  Use __be* where appropriate.
    
    Signed-off-by: Sean Hefty <sean.hefty@intel.com>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index b91d3ef01b92..e23041c7be8f 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -90,8 +90,8 @@ enum {
 /* structs */
 
 struct ipoib_header {
-	u16 proto;
-	u16 reserved;
+	__be16	proto;
+	u16	reserved;
 };
 
 struct ipoib_pseudoheader {

commit 2a1d9b7f09aaaacf235656cb32a40ba2c79590b3
Author: Roland Dreier <roland@eddore.topspincom.com>
Date:   Wed Aug 10 23:03:10 2005 -0700

    [PATCH] IB: Add copyright notices
    
    Make some lawyers happy and add copyright notices for people who
    forgot to include them when they actually touched the code.
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
index 04c98f54e9c4..b91d3ef01b92 100644
--- a/drivers/infiniband/ulp/ipoib/ipoib.h
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -1,5 +1,7 @@
 /*
  * Copyright (c) 2004, 2005 Topspin Communications.  All rights reserved.
+ * Copyright (c) 2005 Sun Microsystems, Inc. All rights reserved.
+ * Copyright (c) 2004 Voltaire, Inc. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/drivers/infiniband/ulp/ipoib/ipoib.h b/drivers/infiniband/ulp/ipoib/ipoib.h
new file mode 100644
index 000000000000..04c98f54e9c4
--- /dev/null
+++ b/drivers/infiniband/ulp/ipoib/ipoib.h
@@ -0,0 +1,353 @@
+/*
+ * Copyright (c) 2004, 2005 Topspin Communications.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ * $Id: ipoib.h 1358 2004-12-17 22:00:11Z roland $
+ */
+
+#ifndef _IPOIB_H
+#define _IPOIB_H
+
+#include <linux/list.h>
+#include <linux/skbuff.h>
+#include <linux/netdevice.h>
+#include <linux/workqueue.h>
+#include <linux/pci.h>
+#include <linux/config.h>
+#include <linux/kref.h>
+#include <linux/if_infiniband.h>
+
+#include <net/neighbour.h>
+
+#include <asm/atomic.h>
+#include <asm/semaphore.h>
+
+#include <ib_verbs.h>
+#include <ib_pack.h>
+#include <ib_sa.h>
+
+/* constants */
+
+enum {
+	IPOIB_PACKET_SIZE         = 2048,
+	IPOIB_BUF_SIZE 		  = IPOIB_PACKET_SIZE + IB_GRH_BYTES,
+
+	IPOIB_ENCAP_LEN 	  = 4,
+
+	IPOIB_RX_RING_SIZE 	  = 128,
+	IPOIB_TX_RING_SIZE 	  = 64,
+
+	IPOIB_NUM_WC 		  = 4,
+
+	IPOIB_MAX_PATH_REC_QUEUE  = 3,
+	IPOIB_MAX_MCAST_QUEUE     = 3,
+
+	IPOIB_FLAG_OPER_UP 	  = 0,
+	IPOIB_FLAG_ADMIN_UP 	  = 1,
+	IPOIB_PKEY_ASSIGNED 	  = 2,
+	IPOIB_PKEY_STOP 	  = 3,
+	IPOIB_FLAG_SUBINTERFACE   = 4,
+	IPOIB_MCAST_RUN 	  = 5,
+	IPOIB_STOP_REAPER         = 6,
+
+	IPOIB_MAX_BACKOFF_SECONDS = 16,
+
+	IPOIB_MCAST_FLAG_FOUND 	  = 0,	/* used in set_multicast_list */
+	IPOIB_MCAST_FLAG_SENDONLY = 1,
+	IPOIB_MCAST_FLAG_BUSY 	  = 2,	/* joining or already joined */
+	IPOIB_MCAST_FLAG_ATTACHED = 3,
+};
+
+/* structs */
+
+struct ipoib_header {
+	u16 proto;
+	u16 reserved;
+};
+
+struct ipoib_pseudoheader {
+	u8  hwaddr[INFINIBAND_ALEN];
+};
+
+struct ipoib_mcast;
+
+struct ipoib_buf {
+	struct sk_buff *skb;
+	DECLARE_PCI_UNMAP_ADDR(mapping)
+};
+
+/*
+ * Device private locking: tx_lock protects members used in TX fast
+ * path (and we use LLTX so upper layers don't do extra locking).
+ * lock protects everything else.  lock nests inside of tx_lock (ie
+ * tx_lock must be acquired first if needed).
+ */
+struct ipoib_dev_priv {
+	spinlock_t lock;
+
+	struct net_device *dev;
+
+	unsigned long flags;
+
+	struct semaphore mcast_mutex;
+	struct semaphore vlan_mutex;
+
+	struct rb_root  path_tree;
+	struct list_head path_list;
+
+	struct ipoib_mcast *broadcast;
+	struct list_head multicast_list;
+	struct rb_root multicast_tree;
+
+	struct work_struct pkey_task;
+	struct work_struct mcast_task;
+	struct work_struct flush_task;
+	struct work_struct restart_task;
+	struct work_struct ah_reap_task;
+
+	struct ib_device *ca;
+	u8            	  port;
+	u16           	  pkey;
+	struct ib_pd  	 *pd;
+	struct ib_mr  	 *mr;
+	struct ib_cq  	 *cq;
+	struct ib_qp  	 *qp;
+	u32           	  qkey;
+
+	union ib_gid local_gid;
+	u16          local_lid;
+	u8           local_rate;
+
+	unsigned int admin_mtu;
+	unsigned int mcast_mtu;
+
+	struct ipoib_buf *rx_ring;
+
+	spinlock_t        tx_lock;
+	struct ipoib_buf *tx_ring;
+	unsigned          tx_head;
+	unsigned          tx_tail;
+	struct ib_sge     tx_sge;
+	struct ib_send_wr tx_wr;
+
+	struct ib_wc ibwc[IPOIB_NUM_WC];
+
+	struct list_head dead_ahs;
+
+	struct ib_event_handler event_handler;
+
+	struct net_device_stats stats;
+
+	struct net_device *parent;
+	struct list_head child_intfs;
+	struct list_head list;
+
+#ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
+	struct list_head fs_list;
+	struct dentry *mcg_dentry;
+#endif
+};
+
+struct ipoib_ah {
+	struct net_device *dev;
+	struct ib_ah      *ah;
+	struct list_head   list;
+	struct kref        ref;
+	unsigned           last_send;
+};
+
+struct ipoib_path {
+	struct net_device    *dev;
+	struct ib_sa_path_rec pathrec;
+	struct ipoib_ah      *ah;
+	struct sk_buff_head   queue;
+
+	struct list_head      neigh_list;
+
+	int                   query_id;
+	struct ib_sa_query   *query;
+	struct completion     done;
+
+	struct rb_node        rb_node;
+	struct list_head      list;
+};
+
+struct ipoib_neigh {
+	struct ipoib_ah    *ah;
+	struct sk_buff_head queue;
+
+	struct neighbour   *neighbour;
+
+	struct list_head    list;
+};
+
+static inline struct ipoib_neigh **to_ipoib_neigh(struct neighbour *neigh)
+{
+	return (struct ipoib_neigh **) (neigh->ha + 24 -
+					(offsetof(struct neighbour, ha) & 4));
+}
+
+extern struct workqueue_struct *ipoib_workqueue;
+
+/* functions */
+
+void ipoib_ib_completion(struct ib_cq *cq, void *dev_ptr);
+
+struct ipoib_ah *ipoib_create_ah(struct net_device *dev,
+				 struct ib_pd *pd, struct ib_ah_attr *attr);
+void ipoib_free_ah(struct kref *kref);
+static inline void ipoib_put_ah(struct ipoib_ah *ah)
+{
+	kref_put(&ah->ref, ipoib_free_ah);
+}
+
+int ipoib_add_pkey_attr(struct net_device *dev);
+
+void ipoib_send(struct net_device *dev, struct sk_buff *skb,
+		struct ipoib_ah *address, u32 qpn);
+void ipoib_reap_ah(void *dev_ptr);
+
+void ipoib_flush_paths(struct net_device *dev);
+struct ipoib_dev_priv *ipoib_intf_alloc(const char *format);
+
+int ipoib_ib_dev_init(struct net_device *dev, struct ib_device *ca, int port);
+void ipoib_ib_dev_flush(void *dev);
+void ipoib_ib_dev_cleanup(struct net_device *dev);
+
+int ipoib_ib_dev_open(struct net_device *dev);
+int ipoib_ib_dev_up(struct net_device *dev);
+int ipoib_ib_dev_down(struct net_device *dev);
+int ipoib_ib_dev_stop(struct net_device *dev);
+
+int ipoib_dev_init(struct net_device *dev, struct ib_device *ca, int port);
+void ipoib_dev_cleanup(struct net_device *dev);
+
+void ipoib_mcast_join_task(void *dev_ptr);
+void ipoib_mcast_send(struct net_device *dev, union ib_gid *mgid,
+		      struct sk_buff *skb);
+
+void ipoib_mcast_restart_task(void *dev_ptr);
+int ipoib_mcast_start_thread(struct net_device *dev);
+int ipoib_mcast_stop_thread(struct net_device *dev);
+
+void ipoib_mcast_dev_down(struct net_device *dev);
+void ipoib_mcast_dev_flush(struct net_device *dev);
+
+struct ipoib_mcast_iter *ipoib_mcast_iter_init(struct net_device *dev);
+void ipoib_mcast_iter_free(struct ipoib_mcast_iter *iter);
+int ipoib_mcast_iter_next(struct ipoib_mcast_iter *iter);
+void ipoib_mcast_iter_read(struct ipoib_mcast_iter *iter,
+				  union ib_gid *gid,
+				  unsigned long *created,
+				  unsigned int *queuelen,
+				  unsigned int *complete,
+				  unsigned int *send_only);
+
+int ipoib_mcast_attach(struct net_device *dev, u16 mlid,
+		       union ib_gid *mgid);
+int ipoib_mcast_detach(struct net_device *dev, u16 mlid,
+		       union ib_gid *mgid);
+
+int ipoib_qp_create(struct net_device *dev);
+int ipoib_transport_dev_init(struct net_device *dev, struct ib_device *ca);
+void ipoib_transport_dev_cleanup(struct net_device *dev);
+
+void ipoib_event(struct ib_event_handler *handler,
+		 struct ib_event *record);
+
+int ipoib_vlan_add(struct net_device *pdev, unsigned short pkey);
+int ipoib_vlan_delete(struct net_device *pdev, unsigned short pkey);
+
+void ipoib_pkey_poll(void *dev);
+int ipoib_pkey_dev_delay_open(struct net_device *dev);
+
+#ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
+int ipoib_create_debug_file(struct net_device *dev);
+void ipoib_delete_debug_file(struct net_device *dev);
+int ipoib_register_debugfs(void);
+void ipoib_unregister_debugfs(void);
+#else
+static inline int ipoib_create_debug_file(struct net_device *dev) { return 0; }
+static inline void ipoib_delete_debug_file(struct net_device *dev) { }
+static inline int ipoib_register_debugfs(void) { return 0; }
+static inline void ipoib_unregister_debugfs(void) { }
+#endif
+
+
+#define ipoib_printk(level, priv, format, arg...)	\
+	printk(level "%s: " format, ((struct ipoib_dev_priv *) priv)->dev->name , ## arg)
+#define ipoib_warn(priv, format, arg...)		\
+	ipoib_printk(KERN_WARNING, priv, format , ## arg)
+
+
+#ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
+extern int ipoib_debug_level;
+
+#define ipoib_dbg(priv, format, arg...)			\
+	do {					        \
+		if (ipoib_debug_level > 0)			\
+			ipoib_printk(KERN_DEBUG, priv, format , ## arg); \
+	} while (0)
+#define ipoib_dbg_mcast(priv, format, arg...)		\
+	do {					        \
+		if (mcast_debug_level > 0)		\
+			ipoib_printk(KERN_DEBUG, priv, format , ## arg); \
+	} while (0)
+#else /* CONFIG_INFINIBAND_IPOIB_DEBUG */
+#define ipoib_dbg(priv, format, arg...)			\
+	do { (void) (priv); } while (0)
+#define ipoib_dbg_mcast(priv, format, arg...)		\
+	do { (void) (priv); } while (0)
+#endif /* CONFIG_INFINIBAND_IPOIB_DEBUG */
+
+#ifdef CONFIG_INFINIBAND_IPOIB_DEBUG_DATA
+#define ipoib_dbg_data(priv, format, arg...)		\
+	do {					        \
+		if (data_debug_level > 0)		\
+			ipoib_printk(KERN_DEBUG, priv, format , ## arg); \
+	} while (0)
+#else /* CONFIG_INFINIBAND_IPOIB_DEBUG_DATA */
+#define ipoib_dbg_data(priv, format, arg...)		\
+	do { (void) (priv); } while (0)
+#endif /* CONFIG_INFINIBAND_IPOIB_DEBUG_DATA */
+
+
+#define IPOIB_GID_FMT		"%x:%x:%x:%x:%x:%x:%x:%x"
+
+#define IPOIB_GID_ARG(gid)	be16_to_cpup((__be16 *) ((gid).raw +  0)), \
+				be16_to_cpup((__be16 *) ((gid).raw +  2)), \
+				be16_to_cpup((__be16 *) ((gid).raw +  4)), \
+				be16_to_cpup((__be16 *) ((gid).raw +  6)), \
+				be16_to_cpup((__be16 *) ((gid).raw +  8)), \
+				be16_to_cpup((__be16 *) ((gid).raw + 10)), \
+				be16_to_cpup((__be16 *) ((gid).raw + 12)), \
+				be16_to_cpup((__be16 *) ((gid).raw + 14))
+
+#endif /* _IPOIB_H */
