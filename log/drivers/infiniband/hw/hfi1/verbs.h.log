commit c593642c8be046915ca3a4a300243a68077cd207
Author: Pankaj Bharadiya <pankaj.laxminarayan.bharadiya@intel.com>
Date:   Mon Dec 9 10:31:43 2019 -0800

    treewide: Use sizeof_field() macro
    
    Replace all the occurrences of FIELD_SIZEOF() with sizeof_field() except
    at places where these are defined. Later patches will remove the unused
    definition of FIELD_SIZEOF().
    
    This patch is generated using following script:
    
    EXCLUDE_FILES="include/linux/stddef.h|include/linux/kernel.h"
    
    git grep -l -e "\bFIELD_SIZEOF\b" | while read file;
    do
    
            if [[ "$file" =~ $EXCLUDE_FILES ]]; then
                    continue
            fi
            sed -i  -e 's/\bFIELD_SIZEOF\b/sizeof_field/g' $file;
    done
    
    Signed-off-by: Pankaj Bharadiya <pankaj.laxminarayan.bharadiya@intel.com>
    Link: https://lore.kernel.org/r/20190924105839.110713-3-pankaj.laxminarayan.bharadiya@intel.com
    Co-developed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Acked-by: David Miller <davem@davemloft.net> # for net

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index b0e9bf7cd150..d36e3e14896d 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -107,9 +107,9 @@ enum {
 	HFI1_HAS_GRH = (1 << 0),
 };
 
-#define LRH_16B_BYTES (FIELD_SIZEOF(struct hfi1_16b_header, lrh))
+#define LRH_16B_BYTES (sizeof_field(struct hfi1_16b_header, lrh))
 #define LRH_16B_DWORDS (LRH_16B_BYTES / sizeof(u32))
-#define LRH_9B_BYTES (FIELD_SIZEOF(struct ib_header, lrh))
+#define LRH_9B_BYTES (sizeof_field(struct ib_header, lrh))
 #define LRH_9B_DWORDS (LRH_9B_BYTES / sizeof(u32))
 
 /* 24Bits for qpn, upper 8Bits reserved */

commit e26e7b88f6b7482cbff633c6fc9eaee3ecbd41b1
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Tue Oct 29 08:27:45 2019 +0200

    RDMA: Change MAD processing function to remove extra casting and parameter
    
    All users of process_mad() converts input pointers from ib_mad_hdr to be
    ib_mad, update the function declaration to use ib_mad directly.
    
    Also remove not used input MAD size parameter.
    
    Link: https://lore.kernel.org/r/20191029062745.7932-17-leon@kernel.org
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Tested-By: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index ae9582ddbc8f..b0e9bf7cd150 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -330,9 +330,8 @@ void hfi1_sys_guid_chg(struct hfi1_ibport *ibp);
 void hfi1_node_desc_chg(struct hfi1_ibport *ibp);
 int hfi1_process_mad(struct ib_device *ibdev, int mad_flags, u8 port,
 		     const struct ib_wc *in_wc, const struct ib_grh *in_grh,
-		     const struct ib_mad_hdr *in_mad, size_t in_mad_size,
-		     struct ib_mad_hdr *out_mad, size_t *out_mad_size,
-		     u16 *out_mad_pkey_index);
+		     const struct ib_mad *in_mad, struct ib_mad *out_mad,
+		     size_t *out_mad_size, u16 *out_mad_pkey_index);
 
 /*
  * The PSN_MASK and PSN_SHIFT allow for

commit 4bb02e9572af1383038d83ad196d7166c515f2ee
Author: Mike Marciniszyn <mike.marciniszyn@intel.com>
Date:   Fri Jun 14 12:32:44 2019 -0400

    IB/hfi1: Use aborts to trigger RC throttling
    
    SDMA and pio flushes will cause a lot of packets to be transmitted
    after a link has gone down, using a lot of CPU to retransmit
    packets.
    
    Fix for RC QPs by recognizing the flush status and:
    - Forcing a timer start
    - Putting the QP into a "send one" mode
    
    Fixes: 7724105686e7 ("IB/hfi1: add driver files")
    Reviewed-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 7ecb8ed4a1d9..ae9582ddbc8f 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -416,6 +416,7 @@ void hfi1_rc_hdrerr(
 
 u8 ah_to_sc(struct ib_device *ibdev, struct rdma_ah_attr *ah_attr);
 
+void hfi1_rc_verbs_aborted(struct rvt_qp *qp, struct hfi1_opa_header *opah);
 void hfi1_rc_send_complete(struct rvt_qp *qp, struct hfi1_opa_header *opah);
 
 void hfi1_ud_rcv(struct hfi1_packet *packet);

commit 270a9833b2697d455f6ae12669b8220d3ea48f18
Author: Mike Marciniszyn <mike.marciniszyn@intel.com>
Date:   Tue Feb 26 08:46:16 2019 -0800

    IB/hfi1: Add running average for adaptive pio
    
    The adaptive PIO implementation only considers the current packet size
    when deciding between SDMA and pio for a packet.
    
    This causes credit return forces if small and large packets are
    interleaved.
    
    Add a running average to avoid costly credit forces so that a large
    sequence of small packets is required to go below the threshold that
    chooses pio.
    
    Reviewed-by: Michael J. Ruhl <michael.j.ruhl@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 62ace0b2d17a..7ecb8ed4a1d9 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -170,6 +170,7 @@ struct hfi1_qp_priv {
 	struct tid_flow_state flow_state;
 	struct tid_rdma_qp_params tid_rdma;
 	struct rvt_qp *owner;
+	u16 s_running_pkt_size;
 	u8 hdr_type; /* 9B or 16B */
 	struct rvt_sge_state tid_ss;       /* SGE state pointer for 2nd leg */
 	atomic_t n_requests;               /* # of TID RDMA requests in the */

commit 3c6cb20a0d17d7a75778fb0935d6fa427c8177af
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 21:51:39 2019 -0800

    IB/hfi1: Add TID RDMA WRITE functionality into RDMA verbs
    
    This patch integrates TID RDMA WRITE protocol into normal RDMA verbs
    framework. The TID RDMA WRITE protocol is an end-to-end protocol
    between the hfi1 drivers on two OPA nodes that converts a qualified
    RDMA WRITE request into a TID RDMA WRITE request to avoid data copying
    on the responder side.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index bee3d21a548e..62ace0b2d17a 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -193,6 +193,7 @@ struct hfi1_qp_priv {
 	u32 r_tid_ack;      /* the TID RDMA request to be ACK'ed */
 	u32 r_tid_alloc;    /* Request for which we are allocating resources */
 	u32 pending_tid_w_segs; /* Num of pending tid write segments */
+	u32 pending_tid_w_resp; /* Num of pending tid write responses */
 	u32 alloc_w_segs;       /* Number of segments for which write */
 			       /* resources have been allocated for this QP */
 

commit 572f0c3301138961a596c522729afb5801135d6e
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 21:51:27 2019 -0800

    IB/hfi1: Add the dual leg code
    
    The "Second Leg" of the TID RDMA WRITE protocol deals with
    the transfer of data and ack packets, which are in the KDETH
    PSN space, as opposed to the IB PSN space.
    
    Therefore, the Second Leg could be considered as a separate
    state machine. As such, it is handled by a different work
    queue item which is scheduled along with the normal IB state
    machine work item.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 3e45149d22c4..bee3d21a548e 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -443,6 +443,9 @@ void hfi1_make_ruc_header(struct rvt_qp *qp, struct ib_other_headers *ohdr,
 			  u32 bth0, u32 bth1, u32 bth2, int middle,
 			  struct hfi1_pkt_state *ps);
 
+bool hfi1_schedule_send_yield(struct rvt_qp *qp, struct hfi1_pkt_state *ps,
+			      bool tid);
+
 void _hfi1_do_send(struct work_struct *work);
 
 void hfi1_do_send_from_rvt(struct rvt_qp *qp);

commit 70dcb2e3dc6aa827d74e09c830ea06c660274880
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 21:51:07 2019 -0800

    IB/hfi1: Add the TID second leg send packet builder
    
    To improve performance, the TID RDMA WRITE protocol is designed to
    own a second leg to send data and ack packets in the KDETH PSN space.
    This patch adds the packet builder for the requester side, which
    contains the state machine to build TID RDMA WRITE DATA and TID
    RDMA RESYNC packet.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index ce40ea9f43c3..3e45149d22c4 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -172,6 +172,8 @@ struct hfi1_qp_priv {
 	struct rvt_qp *owner;
 	u8 hdr_type; /* 9B or 16B */
 	struct rvt_sge_state tid_ss;       /* SGE state pointer for 2nd leg */
+	atomic_t n_requests;               /* # of TID RDMA requests in the */
+					   /* queue */
 	atomic_t n_tid_requests;            /* # of sent TID RDMA requests */
 	unsigned long tid_timer_timeout_jiffies;
 	unsigned long tid_retry_timeout_jiffies;

commit 6e38fca6b1524e9a9aa0d2a10d99975eef1791c1
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 21:50:56 2019 -0800

    IB/hfi1: Resend the TID RDMA WRITE DATA packets
    
    This patch adds the logic to resend TID RDMA WRITE DATA packets.
    The tracking indices will be reset properly so that the correct
    TID entries will be used.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index bfd642e831f7..ce40ea9f43c3 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -171,6 +171,7 @@ struct hfi1_qp_priv {
 	struct tid_rdma_qp_params tid_rdma;
 	struct rvt_qp *owner;
 	u8 hdr_type; /* 9B or 16B */
+	struct rvt_sge_state tid_ss;       /* SGE state pointer for 2nd leg */
 	atomic_t n_tid_requests;            /* # of sent TID RDMA requests */
 	unsigned long tid_timer_timeout_jiffies;
 	unsigned long tid_retry_timeout_jiffies;

commit 829eaee5d09a7500bdce9ed0bc6ec6861f8ae45b
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 21:50:24 2019 -0800

    IB/hfi1: Add TID RDMA retry timer
    
    This patch adds the TID RDMA retry timer to make sure that TID RDMA
    WRITE DATA packets for a segment are received successfully by the
    responder. This timer is generally armed when the last TID RDMA
    WRITE DATA packet for a segment is sent out and stopped when all
    TID RDMA DATA packets are acknowledged.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 30e3f5af5cf1..bfd642e831f7 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -164,6 +164,7 @@ struct hfi1_qp_priv {
 	u8 s_sc;		                  /* SC[0..4] for next packet */
 	struct iowait s_iowait;
 	struct timer_list s_tid_timer;            /* for timing tid wait */
+	struct timer_list s_tid_retry_timer;      /* for timing tid ack */
 	struct list_head tid_wait;                /* for queueing tid space */
 	struct hfi1_opfn_data opfn;
 	struct tid_flow_state flow_state;
@@ -172,6 +173,7 @@ struct hfi1_qp_priv {
 	u8 hdr_type; /* 9B or 16B */
 	atomic_t n_tid_requests;            /* # of sent TID RDMA requests */
 	unsigned long tid_timer_timeout_jiffies;
+	unsigned long tid_retry_timeout_jiffies;
 
 	/* variables for the TID RDMA SE state machine */
 	u8 s_state;

commit 9e93e967f7b452e6c9e4a33d0b42ff64fa7293c4
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 21:50:14 2019 -0800

    IB/hfi1: Add a function to receive TID RDMA ACK packet
    
    This patch adds a function to receive TID RDMA ACK packet, which could
    be an acknowledge to either a TID RDMA WRITE DATA packet or an TID
    RDMA RESYNC packet. For an ACK to TID RDMA WRITE DATA packet, the
    request segments are completed appropriately. For an ACK to a TID
    RDMA RESYNC packet, any pending segment flow information is updated
    accordingly.
    
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Ashutosh Dixit <ashutosh.dixit@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 3a97a39aeba4..30e3f5af5cf1 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -170,9 +170,12 @@ struct hfi1_qp_priv {
 	struct tid_rdma_qp_params tid_rdma;
 	struct rvt_qp *owner;
 	u8 hdr_type; /* 9B or 16B */
+	atomic_t n_tid_requests;            /* # of sent TID RDMA requests */
 	unsigned long tid_timer_timeout_jiffies;
 
 	/* variables for the TID RDMA SE state machine */
+	u8 s_state;
+	u8 s_retry;
 	u8 rnr_nak_state;       /* RNR NAK state */
 	u8 s_nak_state;
 	u32 s_nak_psn;
@@ -197,6 +200,7 @@ struct hfi1_qp_priv {
 
 	u32 r_next_psn_kdeth;
 	u32 r_next_psn_kdeth_save;
+	u32 s_resync_psn;
 	u8 sync_pt;           /* Set when QP reaches sync point */
 	u8 resync;
 };

commit 0f75e325aa11552599a18d7558970be16fc15c1a
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 21:50:03 2019 -0800

    IB/hfi1: Add a function to build TID RDMA ACK packet
    
    This patch adds a function to build TID RDMA ACJ packet, which is also
    in the KDETH PSN space for packet ordering. This packet is used to
    acknowledge the receiving of all the TID RDMA WRITE DATA packets
    before the given KDETH PSN. Similar to RC ACK packets, TID RDMA ACK
    packets could also be coalesced.
    
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Ashutosh Dixit <ashutosh.dixit@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index eec6e822635b..3a97a39aeba4 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -196,7 +196,9 @@ struct hfi1_qp_priv {
 	u8 timeout_shift;       /* account for number of packets per segment */
 
 	u32 r_next_psn_kdeth;
+	u32 r_next_psn_kdeth_save;
 	u8 sync_pt;           /* Set when QP reaches sync point */
+	u8 resync;
 };
 
 #define HFI1_QP_WQE_INVALID   ((u32)-1)

commit d72fe7d5008b5600a11f03a0dcb743fd7acb0085
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 21:49:51 2019 -0800

    IB/hfi1: Add a function to receive TID RDMA WRITE DATA packet
    
    This patch adds a function to receive TID RDMA WRITE DATA packet,
    which is in the KDETH PSN space in packet ordering. Due to the use
    of header suppression, software is generally only notified when
    the last data packet for a segment is received. This patch also
    adds code to handle KDETH EFLAGS errors for ingress TID RDMA WRITE
    DATA packets.
    
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Ashutosh Dixit <ashutosh.dixit@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index b2096c7c1132..eec6e822635b 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -174,6 +174,8 @@ struct hfi1_qp_priv {
 
 	/* variables for the TID RDMA SE state machine */
 	u8 rnr_nak_state;       /* RNR NAK state */
+	u8 s_nak_state;
+	u32 s_nak_psn;
 	u32 s_flags;
 	u32 s_tid_cur;
 	u32 s_tid_head;
@@ -193,6 +195,7 @@ struct hfi1_qp_priv {
 	u16 pkts_ps;            /* packets per segment */
 	u8 timeout_shift;       /* account for number of packets per segment */
 
+	u32 r_next_psn_kdeth;
 	u8 sync_pt;           /* Set when QP reaches sync point */
 };
 

commit 72a0ea99ec13bcb27784c1a48f4e8fda61586c26
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 21:49:31 2019 -0800

    IB/hfi1: Add a function to receive TID RDMA WRITE response
    
    This patch adds a function to receive TID RDMA WRITE response.
    The TID entries will be stored for encoding TID RDMA WRITE DATA
    packet later.
    
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Ashutosh Dixit <ashutosh.dixit@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 68a41f54bc78..b2096c7c1132 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -175,6 +175,9 @@ struct hfi1_qp_priv {
 	/* variables for the TID RDMA SE state machine */
 	u8 rnr_nak_state;       /* RNR NAK state */
 	u32 s_flags;
+	u32 s_tid_cur;
+	u32 s_tid_head;
+	u32 s_tid_tail;
 	u32 r_tid_head;     /* Most recently added TID RDMA request */
 	u32 r_tid_tail;     /* the last completed TID RDMA request */
 	u32 r_tid_ack;      /* the TID RDMA request to be ACK'ed */

commit 3c759e003a6a4d4b8fd0472f9501e8c45d775c26
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 21:49:19 2019 -0800

    IB/hfi1: Add TID resource timer
    
    This patch adds the TID resource timer, which is used by the responder
    to free any TID resources that are allocated for TID RDMA WRITE request
    and not returned by the requester after a reasonable time.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 3a501b09621e..68a41f54bc78 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -163,6 +163,7 @@ struct hfi1_qp_priv {
 	u32 tid_enqueue;                          /* saved when tid waited */
 	u8 s_sc;		                  /* SC[0..4] for next packet */
 	struct iowait s_iowait;
+	struct timer_list s_tid_timer;            /* for timing tid wait */
 	struct list_head tid_wait;                /* for queueing tid space */
 	struct hfi1_opfn_data opfn;
 	struct tid_flow_state flow_state;

commit 38d46d3676ed6ecba284eb49e4b675ca9891801a
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 21:49:09 2019 -0800

    IB/hfi1: Add a function to build TID RDMA WRITE response
    
    This patch adds the function to build TID RDMA WRITE response. The
    main role of the TID RDMA WRITE RESP packet is to send TID entries
    to the requester so that they can be used to encode TID RDMA WRITE
    DATA packet.
    
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Ashutosh Dixit <ashutosh.dixit@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 9ced8a4a7b76..3a501b09621e 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -200,6 +200,7 @@ struct hfi1_swqe_priv {
 };
 
 struct hfi1_ack_priv {
+	struct rvt_sge_state ss;               /* used for TID WRITE RESP */
 	struct tid_rdma_request tid_req;
 };
 

commit 07b923701e38f93b4725e64318e6483f890c1c1d
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 21:48:59 2019 -0800

    IB/hfi1: Add functions to receive TID RDMA WRITE request
    
    This patch adds the functions to receive TID RDMA WRITE request. The
    request will be stored in the QP's s_ack_queue. This patch also adds
    code to handle duplicate TID RDMA WRITE request and a function to
    allocate TID resources for data receiving on the responder side.
    
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Ashutosh Dixit <ashutosh.dixit@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 841727a684d5..9ced8a4a7b76 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -172,7 +172,15 @@ struct hfi1_qp_priv {
 	unsigned long tid_timer_timeout_jiffies;
 
 	/* variables for the TID RDMA SE state machine */
+	u8 rnr_nak_state;       /* RNR NAK state */
 	u32 s_flags;
+	u32 r_tid_head;     /* Most recently added TID RDMA request */
+	u32 r_tid_tail;     /* the last completed TID RDMA request */
+	u32 r_tid_ack;      /* the TID RDMA request to be ACK'ed */
+	u32 r_tid_alloc;    /* Request for which we are allocating resources */
+	u32 pending_tid_w_segs; /* Num of pending tid write segments */
+	u32 alloc_w_segs;       /* Number of segments for which write */
+			       /* resources have been allocated for this QP */
 
 	/* For TID RDMA READ */
 	u32 tid_r_reqs;         /* Num of tid reads requested */
@@ -180,8 +188,12 @@ struct hfi1_qp_priv {
 	u32 pending_tid_r_segs; /* Num of pending tid read segments */
 	u16 pkts_ps;            /* packets per segment */
 	u8 timeout_shift;       /* account for number of packets per segment */
+
+	u8 sync_pt;           /* Set when QP reaches sync point */
 };
 
+#define HFI1_QP_WQE_INVALID   ((u32)-1)
+
 struct hfi1_swqe_priv {
 	struct tid_rdma_request tid_req;
 	struct rvt_sge_state ss;  /* Used for TID RDMA READ Request */

commit a0b34f75ec209e40f06912380533ec525691544f
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Thu Jan 24 06:36:48 2019 -0800

    IB/hfi1: Add interlock between a TID RDMA request and other requests
    
    This locking mechanism is designed to provent vavious memory corruption
    scenarios from occurring when requests are pipelined, especially when
    RDMA READ/WRITE requests are interleaved with TID RDMA READ/WRITE
    requests:
    1. READ-AFTER-READ;
    2. READ-AFTER-WRITE;
    3. WRITE-AFTER-READ;
    When memory corruption is likely, a request will be held back until
    previous requests have been completed.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 7642b59ad5d2..841727a684d5 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -171,6 +171,9 @@ struct hfi1_qp_priv {
 	u8 hdr_type; /* 9B or 16B */
 	unsigned long tid_timer_timeout_jiffies;
 
+	/* variables for the TID RDMA SE state machine */
+	u32 s_flags;
+
 	/* For TID RDMA READ */
 	u32 tid_r_reqs;         /* Num of tid reads requested */
 	u32 tid_r_comp;         /* Num of tid reads completed */

commit 22d136d7566f193fc67cdfd9228aaa7d122a3a45
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Thu Jan 24 06:36:34 2019 -0800

    IB/hfi1: Add TID RDMA handlers
    
    This commit adds the TID RDMA READ pointers to the receiving opcode
    handlers. It also adds TID RDMA READ header sizes to header size table.
    A function to print the RHF EFLAGS errors is created so that it can be
    shared by both IB and TID RDMA receiving functions.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index c1574c0ed9a7..7642b59ad5d2 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -427,6 +427,10 @@ int hfi1_register_ib_device(struct hfi1_devdata *);
 
 void hfi1_unregister_ib_device(struct hfi1_devdata *);
 
+void hfi1_kdeth_eager_rcv(struct hfi1_packet *packet);
+
+void hfi1_kdeth_expected_rcv(struct hfi1_packet *packet);
+
 void hfi1_ib_rcv(struct hfi1_packet *packet);
 
 void hfi1_16B_rcv(struct hfi1_packet *packet);

commit 9905bf06e890c2a845ac8fd19d7e6b8987ef8df6
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Tue Feb 5 14:13:30 2019 -0800

    IB/hfi1: Add functions to receive TID RDMA READ response
    
    This patch adds the functions to receive TID RDMA READ response. The TID
    resource information in the KDETH packet header will direct the hardware
    to deliver the packet payload to the user buffer automatically and the
    software will handle the packet header for the last packet of a segment
    as all other packet headers are suppressed by default. The TID entries
    will be freed when all packets for a segment have been received. This
    patch also adds the functions to handle KDETH eflag errors, including
    flow sequence and generation errors, when a TID RDMA READ response
    packet is received . The flow sequence error can be recovered by software
    checking of the flow sequence and will disappear when the hardware flow
    is programmed with a new generation number.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 5e910c508360..c1574c0ed9a7 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -172,6 +172,8 @@ struct hfi1_qp_priv {
 	unsigned long tid_timer_timeout_jiffies;
 
 	/* For TID RDMA READ */
+	u32 tid_r_reqs;         /* Num of tid reads requested */
+	u32 tid_r_comp;         /* Num of tid reads completed */
 	u32 pending_tid_r_segs; /* Num of pending tid read segments */
 	u16 pkts_ps;            /* packets per segment */
 	u8 timeout_shift;       /* account for number of packets per segment */

commit d0d564a1caacc7f3f28f3e351ed89ed000e2de75
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 19:31:02 2019 -0800

    IB/hfi1: Add functions to receive TID RDMA READ request
    
    This patch adds the functions to receive TID RDMA READ request. The TID
    resource information will be stored and tracked. Duplicate request
    will also be handled properly.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 2965b0957855..5e910c508360 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -340,6 +340,11 @@ static inline struct tid_rdma_request *wqe_to_tid_req(struct rvt_swqe *wqe)
 	return &((struct hfi1_swqe_priv *)wqe->priv)->tid_req;
 }
 
+static inline struct tid_rdma_request *ack_to_tid_req(struct rvt_ack_entry *e)
+{
+	return &((struct hfi1_ack_priv *)e->priv)->tid_req;
+}
+
 /*
  * Look through all the active flows for a TID RDMA request and find
  * the one (if it exists) that contains the specified PSN.

commit 742a3826cf82395e304df99f6494d04b0dd03a84
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 19:30:40 2019 -0800

    IB/hfi1: Add functions to build TID RDMA READ request
    
    This patch adds the helper functions to build the TID RDMA READ request
    on the requester side. The key is to allocate TID resources (TID flow
    and TID entries) and send the resource information to the responder side
    along with the read request. Since the TID resources are limited, each
    TID RDMA READ request has to be split into segments with a default
    segment size of 256K. A software flow is allocated to track the data
    transaction for each segment. The work request opcode, packet opcode, and
    packet formats for TID RDMA READ protocol are also defined in this patch.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 20729454f181..2965b0957855 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -170,12 +170,16 @@ struct hfi1_qp_priv {
 	struct rvt_qp *owner;
 	u8 hdr_type; /* 9B or 16B */
 	unsigned long tid_timer_timeout_jiffies;
+
+	/* For TID RDMA READ */
+	u32 pending_tid_r_segs; /* Num of pending tid read segments */
 	u16 pkts_ps;            /* packets per segment */
 	u8 timeout_shift;       /* account for number of packets per segment */
 };
 
 struct hfi1_swqe_priv {
 	struct tid_rdma_request tid_req;
+	struct rvt_sge_state ss;  /* Used for TID RDMA READ Request */
 };
 
 struct hfi1_ack_priv {
@@ -331,6 +335,11 @@ static inline u32 delta_psn(u32 a, u32 b)
 	return (((int)a - (int)b) << PSN_SHIFT) >> PSN_SHIFT;
 }
 
+static inline struct tid_rdma_request *wqe_to_tid_req(struct rvt_swqe *wqe)
+{
+	return &((struct hfi1_swqe_priv *)wqe->priv)->tid_req;
+}
+
 /*
  * Look through all the active flows for a TID RDMA request and find
  * the one (if it exists) that contains the specified PSN.

commit 2f16a696a05d34ba8c920b2133a51f18107fdb8b
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 19:30:18 2019 -0800

    IB/hfi1: Add the counter n_tidwait
    
    This patch adds the counter n_tidwait to count the number of times the
    TID resource allocator has to wait for TID resources.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Ashutosh Dixit <ashutosh.dixit@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 94f198b47239..20729454f181 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -243,6 +243,7 @@ struct hfi1_ibdev {
 	struct kmem_cache *verbs_txreq_cache;
 	u64 n_txwait;
 	u64 n_kmem_wait;
+	u64 n_tidwait;
 
 	/* protect iowait lists */
 	seqlock_t iowait_lock ____cacheline_aligned_in_smp;

commit 838b6fd2d9ca29998869e4d1ecf4566efe807666
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 19:30:07 2019 -0800

    IB/hfi1: TID RDMA RcvArray programming and TID allocation
    
    TID entries are used by hfi1 hardware to receive data payload from
    incoming packets directly into a user buffer and thus avoid data copying
    by software. This patch implements the functions for TID allocation,
    freeing, and programming TID RcvArray entries in hardware for kernel
    clients. TID entries are managed via lists of TID groups similar to PSM.
    Furthermore, to track TID resource allocation for each request, software
    flows are also allocated and freed as needed. Since software flows
    consume large amount of memory for tracking TID allocation and freeing,
    it is generally desirable to allocate them dynamically in the send queue
    and only for TID RDMA requests, but pre-allocate them for receive queue
    because the send queue could have thousands of entries while the receive
    queue has only a limited number of entries.
    
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Ashutosh Dixit <ashutosh.dixit@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 9065e470bebb..94f198b47239 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -159,6 +159,7 @@ struct hfi1_qp_priv {
 	struct sdma_engine *s_sde;                /* current sde */
 	struct send_context *s_sendcontext;       /* current sendcontext */
 	struct hfi1_ctxtdata *rcd;                /* QP's receive context */
+	struct page **pages;                      /* for TID page scan */
 	u32 tid_enqueue;                          /* saved when tid waited */
 	u8 s_sc;		                  /* SC[0..4] for next packet */
 	struct iowait s_iowait;
@@ -173,6 +174,14 @@ struct hfi1_qp_priv {
 	u8 timeout_shift;       /* account for number of packets per segment */
 };
 
+struct hfi1_swqe_priv {
+	struct tid_rdma_request tid_req;
+};
+
+struct hfi1_ack_priv {
+	struct tid_rdma_request tid_req;
+};
+
 /*
  * This structure is used to hold commonly lookedup and computed values during
  * the send engine progress.
@@ -321,6 +330,21 @@ static inline u32 delta_psn(u32 a, u32 b)
 	return (((int)a - (int)b) << PSN_SHIFT) >> PSN_SHIFT;
 }
 
+/*
+ * Look through all the active flows for a TID RDMA request and find
+ * the one (if it exists) that contains the specified PSN.
+ */
+static inline u32 __full_flow_psn(struct flow_state *state, u32 psn)
+{
+	return mask_psn((state->generation << HFI1_KDETH_BTH_SEQ_SHIFT) |
+			(psn & HFI1_KDETH_BTH_SEQ_MASK));
+}
+
+static inline u32 full_flow_psn(struct tid_rdma_flow *flow, u32 psn)
+{
+	return __full_flow_psn(&flow->flow_state, psn);
+}
+
 struct verbs_txreq;
 void hfi1_put_txreq(struct verbs_txreq *tx);
 
@@ -403,6 +427,16 @@ static inline bool opa_bth_is_migration(struct ib_other_headers *ohdr)
 	return ohdr->bth[1] & cpu_to_be32(OPA_BTH_MIG_REQ);
 }
 
+void hfi1_wait_kmem(struct rvt_qp *qp);
+
+static inline void hfi1_trdma_send_complete(struct rvt_qp *qp,
+					    struct rvt_swqe *wqe,
+					    enum ib_wc_status status)
+{
+	trdma_clean_swqe(qp, wqe);
+	rvt_send_complete(qp, wqe, status);
+}
+
 extern const enum ib_wc_opcode ib_hfi1_wc_opcode[];
 
 extern const u8 hdr_len_by_opcode[];

commit 37356e78328186814e994e0ad1a1cfd6a142bef4
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Tue Feb 5 14:13:13 2019 -0800

    IB/hfi1: TID RDMA flow allocation
    
    The hfi1 hardware flow is a hardware flow-control mechanism for a KDETH
    data packet that is received on a hfi1 port. It validates the packet by
    checking both the generation and sequence. Each QP that uses the TID RDMA
    mechanism will allocate a hardware flow from its receiving context for
    any incoming KDETH data packets.
    
    This patch implements:
    (1) a function to allocate hardware flow
    (2) a function to free hardware flow
    (3) a function to initialize hardware flow generation for a receiving
        context
    (4) a wait mechanism if the hardware flow is not available
    (4) a function to remove the qp from the wait queue for hardware flow
        when the qp is reset or destroyed.
    
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Ashutosh Dixit <ashutosh.dixit@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index c8baa1e38ff6..9065e470bebb 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -159,9 +159,12 @@ struct hfi1_qp_priv {
 	struct sdma_engine *s_sde;                /* current sde */
 	struct send_context *s_sendcontext;       /* current sendcontext */
 	struct hfi1_ctxtdata *rcd;                /* QP's receive context */
+	u32 tid_enqueue;                          /* saved when tid waited */
 	u8 s_sc;		                  /* SC[0..4] for next packet */
 	struct iowait s_iowait;
+	struct list_head tid_wait;                /* for queueing tid space */
 	struct hfi1_opfn_data opfn;
+	struct tid_flow_state flow_state;
 	struct tid_rdma_qp_params tid_rdma;
 	struct rvt_qp *owner;
 	u8 hdr_type; /* 9B or 16B */

commit d22a207d74adb0b43742f83d025079207425928b
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 19:20:42 2019 -0800

    IB/hfi1: Add OPFN helper functions for TID RDMA feature
    
    This patch adds the OPFN helper functions to initialize, encode, decode,
    and reset OPFN parameters for the TID RDMA feature.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Ashutosh Dixit <ashutosh.dixit@intel.com>
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 8834119184b3..c8baa1e38ff6 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -161,8 +161,13 @@ struct hfi1_qp_priv {
 	struct hfi1_ctxtdata *rcd;                /* QP's receive context */
 	u8 s_sc;		                  /* SC[0..4] for next packet */
 	struct iowait s_iowait;
+	struct hfi1_opfn_data opfn;
+	struct tid_rdma_qp_params tid_rdma;
 	struct rvt_qp *owner;
 	u8 hdr_type; /* 9B or 16B */
+	unsigned long tid_timer_timeout_jiffies;
+	u16 pkts_ps;            /* packets per segment */
+	u8 timeout_shift;       /* account for number of packets per segment */
 };
 
 /*

commit 44e43d91ad4731d9e2e70c60eecc5982d6671e8c
Author: Mitko Haralanov <mitko.haralanov@intel.com>
Date:   Thu Jan 24 06:09:46 2019 -0800

    IB/hfi1: OPFN support discovery
    
    OPFN (Omni Path Feature Negotiation) support discovery allows a RC QP to
    announce that it supports OPFN and also discover if OPFN is supported by
    the peer QP. OPFN parameter negotiation is skipped unless OPFN support is
    first discovered. OPFN support is announced by claiming what was
    the reserved bit in dword 1 of OmniPath modified base transport header
    in requests and responses.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Ashutosh Dixit <ashutosh.dixit@intel.com>
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 1ad0b14bdb3c..8834119184b3 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -72,6 +72,7 @@ struct hfi1_packet;
 
 #include "iowait.h"
 #include "tid_rdma.h"
+#include "opfn.h"
 
 #define HFI1_MAX_RDMA_ATOMIC     16
 
@@ -356,7 +357,7 @@ u32 hfi1_make_grh(struct hfi1_ibport *ibp, struct ib_grh *hdr,
 		  const struct ib_global_route *grh, u32 hwords, u32 nwords);
 
 void hfi1_make_ruc_header(struct rvt_qp *qp, struct ib_other_headers *ohdr,
-			  u32 bth0, u32 bth2, int middle,
+			  u32 bth0, u32 bth1, u32 bth2, int middle,
 			  struct hfi1_pkt_state *ps);
 
 void _hfi1_do_send(struct work_struct *work);

commit 5190f052a3654aa1120ea4f9ff3bfac430459893
Author: Mike Marciniszyn <mike.marciniszyn@intel.com>
Date:   Wed Nov 28 10:22:31 2018 -0800

    IB/hfi1: Allow the driver to initialize QP priv struct
    
    This patch adds an interface to allow the driver to initialize the QP priv
    struct when the QP is created and after the qpn has been assigned.  A
    field is added to the QP priv struct to reference the rcd and two new
    files are added to contain the function to initialize the rcd field so
    that more TID RDMA related code can be added here later.
    
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 64c9054db5f3..1ad0b14bdb3c 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -71,6 +71,7 @@ struct hfi1_devdata;
 struct hfi1_packet;
 
 #include "iowait.h"
+#include "tid_rdma.h"
 
 #define HFI1_MAX_RDMA_ATOMIC     16
 
@@ -156,6 +157,7 @@ struct hfi1_qp_priv {
 	struct hfi1_ahg_info *s_ahg;              /* ahg info for next header */
 	struct sdma_engine *s_sde;                /* current sde */
 	struct send_context *s_sendcontext;       /* current sendcontext */
+	struct hfi1_ctxtdata *rcd;                /* QP's receive context */
 	u8 s_sc;		                  /* SC[0..4] for next packet */
 	struct iowait s_iowait;
 	struct rvt_qp *owner;

commit 116aa0330ec71b9872dfb3a3cc5202a72b5a1666
Author: Venkata Sandeep Dhanalakota <venkata.s.dhanalakota@intel.com>
Date:   Wed Sep 26 10:44:42 2018 -0700

    IB/{hfi1, qib, rdmavt}: Move send completion logic to rdmavt
    
    Moving send completion code into rdmavt in order to have shared logic
    between qib and hfi1 drivers.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Reviewed-by: Brian Welty <brian.welty@intel.com>
    Signed-off-by: Venkata Sandeep Dhanalakota <venkata.s.dhanalakota@intel.com>
    Signed-off-by: Harish Chegondi <harish.chegondi@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index eb99e8df6251..64c9054db5f3 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -363,9 +363,6 @@ void hfi1_do_send_from_rvt(struct rvt_qp *qp);
 
 void hfi1_do_send(struct rvt_qp *qp, bool in_thread);
 
-void hfi1_send_complete(struct rvt_qp *qp, struct rvt_swqe *wqe,
-			enum ib_wc_status status);
-
 void hfi1_send_rc_ack(struct hfi1_packet *packet, bool is_fecn);
 
 int hfi1_make_rc_req(struct rvt_qp *qp, struct hfi1_pkt_state *ps);

commit 019f118b94c895294debfaa394b267638fe2f648
Author: Brian Welty <brian.welty@intel.com>
Date:   Wed Sep 26 10:44:33 2018 -0700

    IB/{hfi1, qib, rdmavt}: Move copy SGE logic into rdmavt
    
    This patch moves hfi1_copy_sge() into rdmavt for sharing with qib.
    This patch also moves all the wss_*() functions into rdmavt as
    several wss_*() functions are called from hfi1_copy_sge()
    
    When SGE copy mode is adaptive, cacheless copy may be done in some cases
    for performance reasons. In those cases, X86 cacheless copy function
    is called since the drivers that use rdmavt and may set SGE copy mode
    to adaptive are X86 only. For this reason, this patch adds
    "depends on X86_64" to rdmavt/Kconfig.
    
    Reviewed-by: Ashutosh Dixit <ashutosh.dixit@intel.com>
    Reviewed-by: Michael J. Ruhl <michael.j.ruhl@intel.com>
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Brian Welty <brian.welty@intel.com>
    Signed-off-by: Harish Chegondi <harish.chegondi@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index d4164114396e..eb99e8df6251 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -315,9 +315,6 @@ void hfi1_put_txreq(struct verbs_txreq *tx);
 
 int hfi1_verbs_send(struct rvt_qp *qp, struct hfi1_pkt_state *ps);
 
-void hfi1_copy_sge(struct rvt_sge_state *ss, void *data, u32 length,
-		   bool release, bool copy_last);
-
 void hfi1_cnp_rcv(struct hfi1_packet *packet);
 
 void hfi1_uc_rcv(struct hfi1_packet *packet);
@@ -393,28 +390,6 @@ int hfi1_verbs_send_dma(struct rvt_qp *qp, struct hfi1_pkt_state *ps,
 int hfi1_verbs_send_pio(struct rvt_qp *qp, struct hfi1_pkt_state *ps,
 			u64 pbc);
 
-int hfi1_wss_init(void);
-void hfi1_wss_exit(void);
-
-/* platform specific: return the lowest level cache (llc) size, in KiB */
-static inline int wss_llc_size(void)
-{
-	/* assume that the boot CPU value is universal for all CPUs */
-	return boot_cpu_data.x86_cache_size;
-}
-
-/* platform specific: cacheless copy */
-static inline void cacheless_memcpy(void *dst, void *src, size_t n)
-{
-	/*
-	 * Use the only available X64 cacheless copy.  Add a __user cast
-	 * to quiet sparse.  The src agument is already in the kernel so
-	 * there are no security issues.  The extra fault recovery machinery
-	 * is not invoked.
-	 */
-	__copy_user_nocache(dst, (void __user *)src, n, 0);
-}
-
 static inline bool opa_bth_is_migration(struct ib_other_headers *ohdr)
 {
 	return ohdr->bth[1] & cpu_to_be32(OPA_BTH_MIG_REQ);

commit 5da0fc9dbf891a9c9e01a634f2126b5952afb3a6
Author: Dennis Dalessandro <dennis.dalessandro@intel.com>
Date:   Fri Sep 28 07:17:09 2018 -0700

    IB/hfi1: Prepare resource waits for dual leg
    
    Current implementation allows each qp to have only one send engine.  As
    such, each qp has only one list to queue prebuilt packets when send engine
    resources are not available. To improve performance, it is desired to
    support multiple send engines for each qp.
    
    This patch creates the framework to support two send engines
    (two legs) for each qp for the TID RDMA protocol, which can be easily
    extended to support more send engines. It achieves the goal by creating a
    leg specific struct, iowait_work in the iowait struct, to hold the
    work_struct and the tx_list as well as a pointer to the parent iowait
    struct.
    
    The hfi1_pkt_state now has an additional field to record the current legs
    work structure and that is now passed to all egress waiters to determine
    the leg that needs to wait via a new iowait helper.  The APIs are adjusted
    to use the new leg specific struct as required.
    
    Many new and modified helpers are added to support this change.
    
    Reviewed-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index bc77ffec51ce..d4164114396e 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -166,11 +166,13 @@ struct hfi1_qp_priv {
  * This structure is used to hold commonly lookedup and computed values during
  * the send engine progress.
  */
+struct iowait_work;
 struct hfi1_pkt_state {
 	struct hfi1_ibdev *dev;
 	struct hfi1_ibport *ibp;
 	struct hfi1_pportdata *ppd;
 	struct verbs_txreq *s_txreq;
+	struct iowait_work *wait;
 	unsigned long flags;
 	unsigned long timeout;
 	unsigned long timeout_int;
@@ -247,7 +249,7 @@ static inline struct hfi1_ibdev *to_idev(struct ib_device *ibdev)
 	return container_of(rdi, struct hfi1_ibdev, rdi);
 }
 
-static inline struct rvt_qp *iowait_to_qp(struct  iowait *s_iowait)
+static inline struct rvt_qp *iowait_to_qp(struct iowait *s_iowait)
 {
 	struct hfi1_qp_priv *priv;
 

commit d205a06a14796a24b3447bc5d27b7dedff4479d5
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Sep 26 10:26:44 2018 -0700

    IB/rdmavt: Rename check_send_wqe as setup_wqe
    
    The driver-provided function check_send_wqe allows the hardware driver to
    check and set up the incoming send wqe before it is inserted into the swqe
    ring. This patch will rename it as setup_wqe to better reflect its
    usage. In addition, this function is only called when all setup is
    complete in rdmavt.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 269ec338581b..bc77ffec51ce 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -343,8 +343,8 @@ int hfi1_check_modify_qp(struct rvt_qp *qp, struct ib_qp_attr *attr,
 void hfi1_modify_qp(struct rvt_qp *qp, struct ib_qp_attr *attr,
 		    int attr_mask, struct ib_udata *udata);
 void hfi1_restart_rc(struct rvt_qp *qp, u32 psn, int wait);
-int hfi1_check_send_wqe(struct rvt_qp *qp, struct rvt_swqe *wqe,
-			bool *call_send);
+int hfi1_setup_wqe(struct rvt_qp *qp, struct rvt_swqe *wqe,
+		   bool *call_send);
 
 extern const u32 rc_only_opcode;
 extern const u32 uc_only_opcode;

commit 0b79b27748cbec221e1ceabf63578198602bf01d
Author: Michael J. Ruhl <michael.j.ruhl@intel.com>
Date:   Mon Sep 10 09:49:27 2018 -0700

    IB/{hfi1, qib, rdmavt}: Schedule multi RC/UC packets instead of posting
    
    The post_send() path determines if it should post directly or, schedule
    the post for later.  The current logic is:
    
      if the swqe ring is empty or (for hfi1) wqe->length <= piothreshold
        post the send
      else
        schedule
    
    This can allow large requests to call the send engine directly.  Large
    requests can potentially produce a large number of packets prior to
    returning to the caller, blocking the caller from posting more requests,
    and allowing better parallel processing.
    
    Allow the driver(s) more say in this logic (pass call_send to the driver,
    rather than examining a return value).
    
    Update hfi1/qib logic to schedule the send engine if an RC or UC message
    is larger than the QP MTU size.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Reviewed-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Michael J. Ruhl <michael.j.ruhl@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index a4d06502f06d..269ec338581b 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -343,7 +343,8 @@ int hfi1_check_modify_qp(struct rvt_qp *qp, struct ib_qp_attr *attr,
 void hfi1_modify_qp(struct rvt_qp *qp, struct ib_qp_attr *attr,
 		    int attr_mask, struct ib_udata *udata);
 void hfi1_restart_rc(struct rvt_qp *qp, u32 psn, int wait);
-int hfi1_check_send_wqe(struct rvt_qp *qp, struct rvt_swqe *wqe);
+int hfi1_check_send_wqe(struct rvt_qp *qp, struct rvt_swqe *wqe,
+			bool *call_send);
 
 extern const u32 rc_only_opcode;
 extern const u32 uc_only_opcode;

commit 4171a693a5159e47f72eea3331bebf538dea9b83
Author: Don Hiatt <don.hiatt@intel.com>
Date:   Tue May 15 18:28:07 2018 -0700

    IB/hfi1: Define 16B Management Packets
    
    Add 16B Management Packet definition. This optimized packet
    format replaces the ib_other_headers and BTH with a source
    and destination QP number.
    
    To support these packets we introduce struct opa_16b_mgmt
    into the struct hfi1_16b_header.
    
    This packet format is only used for MAD packets using the
    IB_OPCODE_UD_SEND_ONLY opcode on QP0/1.
    
    The original 16B implementation failed to use 16B management
    packets so now we add their definition.
    
    Reviewed-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index a16fe5d3f7c4..a4d06502f06d 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -110,6 +110,12 @@ enum {
 #define LRH_9B_BYTES (FIELD_SIZEOF(struct ib_header, lrh))
 #define LRH_9B_DWORDS (LRH_9B_BYTES / sizeof(u32))
 
+/* 24Bits for qpn, upper 8Bits reserved */
+struct opa_16b_mgmt {
+	__be32 dest_qpn;
+	__be32 src_qpn;
+};
+
 struct hfi1_16b_header {
 	u32 lrh[4];
 	union {
@@ -118,6 +124,7 @@ struct hfi1_16b_header {
 			struct ib_other_headers oth;
 		} l;
 		struct ib_other_headers oth;
+		struct opa_16b_mgmt mgmt;
 	} u;
 } __packed;
 

commit 832369fa6410c93547264ad449ebbf16567bbccd
Author: Brian Welty <brian.welty@intel.com>
Date:   Wed May 2 06:44:03 2018 -0700

    IB/{hfi1, qib, rdmavt}: Move logic to allocate receive WQE into rdmavt
    
    Moving receive-side WQE allocation logic into rdmavt will allow
    further code reuse between qib and hfi1 drivers.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Brian Welty <brian.welty@intel.com>
    Signed-off-by: Harish Chegondi <harish.chegondi@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 081ca52e6621..a16fe5d3f7c4 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -328,8 +328,6 @@ void hfi1_ud_rcv(struct hfi1_packet *packet);
 
 int hfi1_lookup_pkey_idx(struct hfi1_ibport *ibp, u16 pkey);
 
-int hfi1_rvt_get_rwqe(struct rvt_qp *qp, int wr_id_only);
-
 void hfi1_migrate_qp(struct rvt_qp *qp);
 
 int hfi1_check_modify_qp(struct rvt_qp *qp, struct ib_qp_attr *attr,

commit a74d5307caba42fe9bbc180feb03003f14f9f45c
Author: Mitko Haralanov <mitko.haralanov@intel.com>
Date:   Wed May 2 06:43:24 2018 -0700

    IB/hfi1: Rework fault injection machinery
    
    The packet fault injection code present in the HFI1 driver had some
    issues which not only fragment the code but also created user
    confusion. Furthermore, it suffered from the following issues:
    
      1. The fault_packet method only worked for received packets. This
         meant that the only fault injection mode available for sent
         packets is fault_opcode, which did not allow for random packet
         drops on all egressing packets.
      2. The mask available for the fault_opcode mode did not really work
         due to the fact that the opcode values are not bits in a bitmask but
         rather sequential integer values. Creating a opcode/mask pair that
         would successfully capture a set of packets was nearly impossible.
      3. The code was fragmented and used too many debugfs entries to
         operate and control. This was confusing to users.
      4. It did not allow filtering fault injection on a per direction basis -
         egress vs. ingress.
    
    In order to improve or fix the above issues, the following changes have
    been made:
    
       1. The fault injection methods have been combined into a single fault
          injection facility. As such, the fault injection has been plugged
          into both the send and receive code paths. Regardless of method used
          the fault injection will operate on both egress and ingress packets.
       2. The type of fault injection - by packet or by opcode - is now controlled
          by changing the boolean value of the file "opcode_mode". When the value
          is set to True, fault injection is done by opcode. Otherwise, by
          packet.
       2. The masking ability has been removed in favor of a bitmap that holds
          opcodes of interest (one bit per opcode, a total of 256 bits). This
          works in tandem with the "opcode_mode" value. When the value of
          "opcode_mode" is False, this bitmap is ignored. When the value is
          True, the bitmap lists all opcodes to be considered for fault injection.
          By default, the bitmap is empty. When the user wants to filter by opcode,
          the user sets the corresponding bit in the bitmap by echo'ing the bit
          position into the 'opcodes' file. This gets around the issue that the set
          of opcodes does not lend itself to effective masks and allow for extremely
          fine-grained filtering by opcode.
       4. fault_packet and fault_opcode methods have been combined. Hence, there
          is only one debugfs directory controlling the entire operation of the
          fault injection machinery. This reduces the number of debugfs entries
          and provides a more unified user experience.
       5. A new control files - "direction" - is provided to allow the user to
          control the direction of packets, which are subject to fault injection.
       6. A new control file - "skip_usec" - is added that would allow the user
          to specify a "timeout" during which no fault injection will occur.
    
    In addition, the following bug fixes have been applied:
    
       1. The fault injection code has been split into its own header and source
          files. This was done to better organize the code and support conditional
          compilation without littering the code with #ifdef's.
       2. The method by which the TX PIO packets were being marked for drop
          conflicted with the way send contexts were being setup. As a result,
          the send context was repeatedly being reset.
       3. The fault injection only makes sense when the user can control it
          through the debugfs entries. However, a kernel configuration can
          enable fault injection but keep fault injection debugfs entries
          disabled. Therefore, it makes sense that the HFI fault injection
          code depends on both.
       4. Error suppression did not take into account the method by which PIO
          packets were being dropped. Therefore, even with error suppression
          turned on, errors would still be displayed to the screen. A larger
          enough packet drop percentage would case the kernel to crash because
          the driver would be stuck printing errors.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Reviewed-by: Don Hiatt <don.hiatt@intel.com>
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 2d787b8346ca..081ca52e6621 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -1,5 +1,5 @@
 /*
- * Copyright(c) 2015 - 2017 Intel Corporation.
+ * Copyright(c) 2015 - 2018 Intel Corporation.
  *
  * This file is provided under a dual BSD/GPLv2 license.  When using or
  * redistributing this file, you may do so under either license.
@@ -227,9 +227,7 @@ struct hfi1_ibdev {
 	/* per HFI symlinks to above */
 	struct dentry *hfi1_ibdev_link;
 #ifdef CONFIG_FAULT_INJECTION
-	struct fault_opcode *fault_opcode;
-	struct fault_packet *fault_packet;
-	bool fault_suppress_err;
+	struct fault *fault;
 #endif
 #endif
 };

commit 78d3633ba9c2351fc869271ee00284f46e6b15b2
Author: Mike Marciniszyn <mike.marciniszyn@intel.com>
Date:   Thu Feb 1 10:52:35 2018 -0800

    IB/hfi1: Remove blind constants from 16B update
    
    These values were introduced as part of the 16B code to
    account for the varying size of the LRH between the differing
    packet formats.
    
    Replace the blind constants with defines based on FIELD_SIZEOF()
    calls.
    
    Fixes: 5b6cabb0db77 ("IB/hfi1: Add 16B RC/UC support")
    Reviewed-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 4ea040df334b..2d787b8346ca 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -105,6 +105,11 @@ enum {
 	HFI1_HAS_GRH = (1 << 0),
 };
 
+#define LRH_16B_BYTES (FIELD_SIZEOF(struct hfi1_16b_header, lrh))
+#define LRH_16B_DWORDS (LRH_16B_BYTES / sizeof(u32))
+#define LRH_9B_BYTES (FIELD_SIZEOF(struct ib_header, lrh))
+#define LRH_9B_DWORDS (LRH_9B_BYTES / sizeof(u32))
+
 struct hfi1_16b_header {
 	u32 lrh[4];
 	union {

commit bdaf96f6500880401fe692cd0bf57afb596b135c
Author: Sebastian Sanchez <sebastian.sanchez@intel.com>
Date:   Thu Feb 1 10:46:31 2018 -0800

    IB/hfi1: Look up ibport using a pointer in receive path
    
    In the receive path, hfi1_ibport is looked up by indexing into an
    array. A profile shows this to be expensive. The receive context
    data has a pointer to the ibport data, use that pointer instead.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Sebastian Sanchez <sebastian.sanchez@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index ffc933ea146f..4ea040df334b 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -358,8 +358,7 @@ void hfi1_do_send(struct rvt_qp *qp, bool in_thread);
 void hfi1_send_complete(struct rvt_qp *qp, struct rvt_swqe *wqe,
 			enum ib_wc_status status);
 
-void hfi1_send_rc_ack(struct hfi1_ctxtdata *rcd, struct rvt_qp *qp,
-		      bool is_fecn);
+void hfi1_send_rc_ack(struct hfi1_packet *packet, bool is_fecn);
 
 int hfi1_make_rc_req(struct rvt_qp *qp, struct hfi1_pkt_state *ps);
 

commit 6d6b8848c882b22e3170cc9f217101773e8bd8d2
Author: Sebastian Sanchez <sebastian.sanchez@intel.com>
Date:   Thu Feb 1 10:46:23 2018 -0800

    IB/hfi1: Optimize packet type comparison using 9B and bypass code paths
    
    The packet type comparison used to find out if a packet is a bypass
    packet in the hot path is an expensive operation as seen in a profile.
    
    Determine packet's pkey and migration bit through the bypass and 9B
    code paths instead.
    
    Reviewed-by: Don Hiatt <don.hiatt@intel.com>
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Sebastian Sanchez <sebastian.sanchez@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index c2aeb32bf482..ffc933ea146f 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -405,6 +405,11 @@ static inline void cacheless_memcpy(void *dst, void *src, size_t n)
 	__copy_user_nocache(dst, (void __user *)src, n, 0);
 }
 
+static inline bool opa_bth_is_migration(struct ib_other_headers *ohdr)
+{
+	return ohdr->bth[1] & cpu_to_be32(OPA_BTH_MIG_REQ);
+}
+
 extern const enum ib_wc_opcode ib_hfi1_wc_opcode[];
 
 extern const u8 hdr_len_by_opcode[];

commit 9636258f103bac6853e280beecf9e85674736a6a
Author: Mitko Haralanov <mitko.haralanov@intel.com>
Date:   Thu Feb 1 10:46:07 2018 -0800

    IB/hfi1: Remove dependence on qp->s_hdrwords
    
    The s_hdrwords variable was used to indicate whether a
    packet was already built on a previous iteration of the
    send engine. This variable assumed the protection of the
    QP's RVT_S_BUSY flag, which was required since the the
    QP's s_lock was dropped just prior to the packet being
    queued on the one of the egress mechanisms.
    
    Support for multiple send engine instantiations require
    that the field not be used due to concurency issues.
    The ps.txreq signals the "already built" without the
    potential concurency issues.
    
    Fix by getting rid of all s_hdrword usage.   A wrapper
    is added to test for the already built case that used to
    use s_hdrwords.
    
    What used to be stored in s_hdrwords is now in the txreq.
    The PBC is not counted, but is added in the pio/sdma code
    paths prior to posting the packet.
    
    Reviewed-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 87d1285a3340..c2aeb32bf482 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -245,17 +245,6 @@ static inline struct rvt_qp *iowait_to_qp(struct  iowait *s_iowait)
 	return priv->owner;
 }
 
-/*
- * Send if not busy or waiting for I/O and either
- * a RC response is pending or we can process send work requests.
- */
-static inline int hfi1_send_ok(struct rvt_qp *qp)
-{
-	return !(qp->s_flags & (RVT_S_BUSY | RVT_S_ANY_WAIT_IO)) &&
-		(qp->s_hdrwords || (qp->s_flags & RVT_S_RESP_PENDING) ||
-		 !(qp->s_flags & RVT_S_ANY_WAIT_SEND));
-}
-
 /*
  * This must be called with s_lock held.
  */

commit 6165467921a891bc79675cdb7f2791d8331f592c
Author: Grzegorz Morys <grzegorz.morys@intel.com>
Date:   Sun Aug 13 08:08:58 2017 -0700

    IB/hfi1: Remove HFI1_VERBS_31BIT_PSN option
    
    Remove HFI1_VERBS_31BIT_PSN Kconfig option leaving only 31-bit PSNs
    available. The option was implemented in the early days of the driver
    and is no longer needed.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Grzegorz Morys <grzegorz.morys@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 56ead87a7f65..87d1285a3340 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -280,13 +280,8 @@ int hfi1_process_mad(struct ib_device *ibdev, int mad_flags, u8 port,
  * necessarily be at least one bit less than
  * the container holding the PSN.
  */
-#ifndef CONFIG_HFI1_VERBS_31BIT_PSN
-#define PSN_MASK 0xFFFFFF
-#define PSN_SHIFT 8
-#else
 #define PSN_MASK 0x7FFFFFFF
 #define PSN_SHIFT 1
-#endif
 #define PSN_MODIFY_MASK 0xFFFFFF
 
 /*

commit 566d53a8264452ee75aa6eb1f2f1970391c1a271
Author: Don Hiatt <don.hiatt@intel.com>
Date:   Fri Aug 4 13:54:47 2017 -0700

    IB/hfi1: Enhance PIO/SDMA send for 16B
    
    PIO/SDMA send logic now uses the hdr_type field to determine
    the type of packet that has been constructed. Based on the hdr_type,
    certain things such as PBC flags, padding count and the LT extra
    trailing bytes are determined.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index b164298a51c6..56ead87a7f65 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -163,6 +163,7 @@ struct hfi1_pkt_state {
 	unsigned long timeout;
 	unsigned long timeout_int;
 	int cpu;
+	u8 opcode;
 	bool in_thread;
 	bool pkts_sent;
 };

commit 5b6cabb0db772042906cdc0fc235fe2a4f5a6000
Author: Don Hiatt <don.hiatt@intel.com>
Date:   Fri Aug 4 13:54:41 2017 -0700

    IB/hfi1: Add 16B RC/UC support
    
    Add 16B bypass packet support for RC/UC traffic types.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index ab1618e32d9c..b164298a51c6 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -373,7 +373,8 @@ void hfi1_do_send(struct rvt_qp *qp, bool in_thread);
 void hfi1_send_complete(struct rvt_qp *qp, struct rvt_swqe *wqe,
 			enum ib_wc_status status);
 
-void hfi1_send_rc_ack(struct hfi1_ctxtdata *, struct rvt_qp *qp, int is_fecn);
+void hfi1_send_rc_ack(struct hfi1_ctxtdata *rcd, struct rvt_qp *qp,
+		      bool is_fecn);
 
 int hfi1_make_rc_req(struct rvt_qp *qp, struct hfi1_pkt_state *ps);
 

commit 51e658f5dd362cc8666f3f5ec1986660e3e51047
Author: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
Date:   Fri Aug 4 13:54:35 2017 -0700

    IB/rdmavt, hfi1, qib: Enhance rdmavt and hfi1 to use 32 bit lids
    
    Increase lid used in hfi1 driver to 32 bits. qib continues
    to use 16 bit lids.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 4928ee4f92c1..ab1618e32d9c 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -334,8 +334,6 @@ void hfi1_rc_hdrerr(
 
 u8 ah_to_sc(struct ib_device *ibdev, struct rdma_ah_attr *ah_attr);
 
-struct ib_ah *hfi1_create_qp0_ah(struct hfi1_ibport *ibp, u16 dlid);
-
 void hfi1_rc_send_complete(struct rvt_qp *qp, struct hfi1_opa_header *opah);
 
 void hfi1_ud_rcv(struct hfi1_packet *packet);

commit 88733e3b845024cb2324a68469a4a25fdd9c0a6c
Author: Don Hiatt <don.hiatt@intel.com>
Date:   Fri Aug 4 13:54:23 2017 -0700

    IB/hfi1: Add 16B UD support
    
    Add 16B bypass packet support for UD traffic types.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index d3dd0c01b8f6..4928ee4f92c1 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -259,7 +259,7 @@ static inline int hfi1_send_ok(struct rvt_qp *qp)
  * This must be called with s_lock held.
  */
 void hfi1_bad_pkey(struct hfi1_ibport *ibp, u32 key, u32 sl,
-		   u32 qp1, u32 qp2, u16 lid1, u16 lid2);
+		   u32 qp1, u32 qp2, u32 lid1, u32 lid2);
 void hfi1_cap_mask_chg(struct rvt_dev_info *rdi, u8 port_num);
 void hfi1_sys_guid_chg(struct hfi1_ibport *ibp);
 void hfi1_node_desc_chg(struct hfi1_ibport *ibp);

commit d98bb7f7e6fa29d45008370084d5cabac7ac69ed
Author: Don Hiatt <don.hiatt@intel.com>
Date:   Fri Aug 4 13:54:16 2017 -0700

    IB/hfi1: Determine 9B/16B L2 header type based on Address handle
    
    When address handle attributes are initialized, the LIDs are
    transformed to be in the 32 bit LID space.
    When constructing the header, hfi1 driver will look at the LID
    to determine the packet header to be created.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 68577a0c922b..d3dd0c01b8f6 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -147,6 +147,7 @@ struct hfi1_qp_priv {
 	u8 s_sc;		                  /* SC[0..4] for next packet */
 	struct iowait s_iowait;
 	struct rvt_qp *owner;
+	u8 hdr_type; /* 9B or 16B */
 };
 
 /*

commit 5786adf3fde7aa22a68eedac9c59e40da76ffbfb
Author: Don Hiatt <don.hiatt@intel.com>
Date:   Fri Aug 4 13:54:10 2017 -0700

    IB/hfi1: Add support to process 16B header errors
    
    Enhance hdr_rcverr() to also handle errors during
    16B bypass packet receive.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 20224100cbc5..68577a0c922b 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -95,6 +95,7 @@ struct hfi1_packet;
 #define HFI1_VENDOR_IPG		cpu_to_be16(0xFFA0)
 
 #define IB_DEFAULT_GID_PREFIX	cpu_to_be64(0xfe80000000000000ULL)
+#define OPA_BTH_MIG_REQ		BIT(31)
 
 #define RC_OP(x) IB_OPCODE_RC_##x
 #define UC_OP(x) IB_OPCODE_UC_##x

commit 30e07416cf48801f127019c1dfece8039f1da8e2
Author: Don Hiatt <don.hiatt@intel.com>
Date:   Fri Aug 4 13:54:04 2017 -0700

    IB/hfi1: Add support to send 16B bypass packets
    
    We introduce struct hfi1_opa_header as a union
    of ib (9B) and 16B headers.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 590aab270f98..20224100cbc5 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -115,6 +115,14 @@ struct hfi1_16b_header {
 	} u;
 } __packed;
 
+struct hfi1_opa_header {
+	union {
+		struct ib_header ibh; /* 9B header */
+		struct hfi1_16b_header opah; /* 16B header */
+	};
+	u8 hdr_type; /* 9B or 16B */
+} __packed;
+
 struct hfi1_ahg_info {
 	u32 ahgdesc[2];
 	u16 tx_flags;
@@ -124,7 +132,7 @@ struct hfi1_ahg_info {
 
 struct hfi1_sdma_header {
 	__le64 pbc;
-	struct ib_header hdr;
+	struct hfi1_opa_header hdr;
 } __packed;
 
 /*
@@ -326,7 +334,7 @@ u8 ah_to_sc(struct ib_device *ibdev, struct rdma_ah_attr *ah_attr);
 
 struct ib_ah *hfi1_create_qp0_ah(struct hfi1_ibport *ibp, u16 dlid);
 
-void hfi1_rc_send_complete(struct rvt_qp *qp, struct ib_header *hdr);
+void hfi1_rc_send_complete(struct rvt_qp *qp, struct hfi1_opa_header *opah);
 
 void hfi1_ud_rcv(struct hfi1_packet *packet);
 
@@ -347,16 +355,6 @@ int hfi1_check_send_wqe(struct rvt_qp *qp, struct rvt_swqe *wqe);
 extern const u32 rc_only_opcode;
 extern const u32 uc_only_opcode;
 
-static inline u8 get_opcode(struct ib_header *h)
-{
-	u16 lnh = be16_to_cpu(h->lrh[0]) & 3;
-
-	if (lnh == IB_LNH_IBA_LOCAL)
-		return be32_to_cpu(h->u.oth.bth[0]) >> 24;
-	else
-		return be32_to_cpu(h->u.l.oth.bth[0]) >> 24;
-}
-
 int hfi1_ruc_check_hdr(struct hfi1_ibport *ibp, struct hfi1_packet *packet);
 
 u32 hfi1_make_grh(struct hfi1_ibport *ibp, struct ib_grh *hdr,

commit 72c07e2b671eda1cf3e8ebabc664f542f673b997
Author: Don Hiatt <don.hiatt@intel.com>
Date:   Fri Aug 4 13:53:58 2017 -0700

    IB/hfi1: Add support to receive 16B bypass packets
    
    We introduce a struct hfi1_16b_header to support 16B headers.
    16B bypass packets are received by the driver and processed
    similar to 9B packets. Add basic support to handle 16B packets.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 34267c7ef85a..590aab270f98 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -104,6 +104,17 @@ enum {
 	HFI1_HAS_GRH = (1 << 0),
 };
 
+struct hfi1_16b_header {
+	u32 lrh[4];
+	union {
+		struct {
+			struct ib_grh grh;
+			struct ib_other_headers oth;
+		} l;
+		struct ib_other_headers oth;
+	} u;
+} __packed;
+
 struct hfi1_ahg_info {
 	u32 ahgdesc[2];
 	u16 tx_flags;
@@ -378,6 +389,8 @@ void hfi1_unregister_ib_device(struct hfi1_devdata *);
 
 void hfi1_ib_rcv(struct hfi1_packet *packet);
 
+void hfi1_16B_rcv(struct hfi1_packet *packet);
+
 unsigned hfi1_get_npkeys(struct hfi1_devdata *);
 
 int hfi1_verbs_send_dma(struct rvt_qp *qp, struct hfi1_pkt_state *ps,

commit bcad29137a9731bfa5e16d64bf8e8a71a268ac88
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Mon Jul 24 07:45:37 2017 -0700

    IB/hfi1: Serve the most starved iowait entry first
    
    When an egress resource(SDMA descriptors, pio credits) is not available,
    a sending thread will be put on the resource's wait queue. When the
    resource becomes available again, up to a fixed number of sending threads
    can be awakened sequentially and removed from the wait queue, depending
    on the number of waiting threads and the number of free resources. Since
    each awakened sending thread will send as many packets as possible, it
    is highly likely that the first sending thread will consume all the
    egress resources. Subsequently, it will be put back to the end of the wait
    queue. Depending on the timing when the later sending threads wake up,
    they may not be able to send any packet and be again put back to the end
    of the wait queue sequentially, right behind the first sending thread.
    This starvation cycle continues until some sending threads exceed their
    retry limit and consequently fail.
    
    This patch fixes the issue by two simple approaches:
    (1) Any starved sending thread will be put to the head of the wait queue
    while a served sending thread will be put to the tail;
    (2) The most starved sending thread will be served first.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index fdf1e1fb880c..34267c7ef85a 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -143,6 +143,7 @@ struct hfi1_pkt_state {
 	unsigned long timeout_int;
 	int cpu;
 	bool in_thread;
+	bool pkts_sent;
 };
 
 #define HFI1_PSN_CREDIT  16

commit 13d84914db56c1afd1c9bf4f41e9bf91f061a7dd
Author: Dennis Dalessandro <dennis.dalessandro@intel.com>
Date:   Mon May 29 17:22:01 2017 -0700

    IB/hfi1,qib: Do not send QKey trap for UD qps
    
    According to IBTA spec a QKey violation should not result in a bad qkey
    trap being triggered for UD queue pairs. Also since it is a silent error
    we do not increment the q_key violation or the dropped packet counters.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 17b38cd5f654..fdf1e1fb880c 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -236,8 +236,8 @@ static inline int hfi1_send_ok(struct rvt_qp *qp)
 /*
  * This must be called with s_lock held.
  */
-void hfi1_bad_pqkey(struct hfi1_ibport *ibp, __be16 trap_num, u32 key, u32 sl,
-		    u32 qp1, u32 qp2, u16 lid1, u16 lid2);
+void hfi1_bad_pkey(struct hfi1_ibport *ibp, u32 key, u32 sl,
+		   u32 qp1, u32 qp2, u16 lid1, u16 lid2);
 void hfi1_cap_mask_chg(struct rvt_dev_info *rdi, u8 port_num);
 void hfi1_sys_guid_chg(struct hfi1_ibport *ibp);
 void hfi1_node_desc_chg(struct hfi1_ibport *ibp);

commit 9039746cdf39dcbf2ddfcc4a68f729cbbbc853df
Author: Don Hiatt <don.hiatt@intel.com>
Date:   Fri May 12 09:20:20 2017 -0700

    IB/hfi1: Setup common IB fields in hfi1_packet struct
    
    We move many common IB fields into the hfi1_packet structure and
    set them up in a single function. This allows us to set the fields
    in a single place and not deal with them throughout the driver.
    
    Reviewed-by: Brian Welty <brian.welty@intel.com>
    Reviewed-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index cd635d0c1d3b..17b38cd5f654 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -307,8 +307,7 @@ void hfi1_rc_rcv(struct hfi1_packet *packet);
 
 void hfi1_rc_hdrerr(
 	struct hfi1_ctxtdata *rcd,
-	struct ib_header *hdr,
-	u32 rcv_flags,
+	struct hfi1_packet *packet,
 	struct rvt_qp *qp);
 
 u8 ah_to_sc(struct ib_device *ibdev, struct rdma_ah_attr *ah_attr);
@@ -346,8 +345,7 @@ static inline u8 get_opcode(struct ib_header *h)
 		return be32_to_cpu(h->u.l.oth.bth[0]) >> 24;
 }
 
-int hfi1_ruc_check_hdr(struct hfi1_ibport *ibp, struct ib_header *hdr,
-		       int has_grh, struct rvt_qp *qp, u32 bth0);
+int hfi1_ruc_check_hdr(struct hfi1_ibport *ibp, struct hfi1_packet *packet);
 
 u32 hfi1_make_grh(struct hfi1_ibport *ibp, struct ib_grh *hdr,
 		  const struct ib_global_route *grh, u32 hwords, u32 nwords);

commit dd1ed1081750a1ce4daeeb53a0ae91af599ecdad
Author: Mike Marciniszyn <mike.marciniszyn@intel.com>
Date:   Thu May 4 05:14:10 2017 -0700

    IB/hfi1: Fix yield logic in send engine
    
    When there are many RC QPs and an RDMA READ request
    is sent, timeouts occur on the requester side because
    of fairness among RC QPs on their relative SDMA engine
    on the responder side.  This also hits write and send, but
    to a lesser extent.
    
    Complicating the issue is that the current code checks if workqueue
    is congested before scheduling other QPs, however, this
    check is based on the number of active entries in the
    workqueue, which was found to be too big to for
    workqueue_congested() to be effective.
    
    Fix by reducing the number of active entries as revealed by
    experimentation from the default of num_sdma to
    HFI1_MAX_ACTIVE_WORKQUEUE_ENTRIES.  Retry counts were monitored
    to determine the correct value.
    
    Tracing to investigate any future issues is also added.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Sebastian Sanchez <sebastian.sanchez@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index c0913c6c8002..cd635d0c1d3b 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -139,6 +139,10 @@ struct hfi1_pkt_state {
 	struct hfi1_pportdata *ppd;
 	struct verbs_txreq *s_txreq;
 	unsigned long flags;
+	unsigned long timeout;
+	unsigned long timeout_int;
+	int cpu;
+	bool in_thread;
 };
 
 #define HFI1_PSN_CREDIT  16

commit 688f21c0be9e3ddd6c5b2241daeb9fe978c0e081
Author: Mike Marciniszyn <mike.marciniszyn@intel.com>
Date:   Thu May 4 05:14:04 2017 -0700

    IB/hfi1, IB/rdmavt: Move r_adefered to r_lock cache line
    
    This field is causing excessive cache line bouncing.
    
    There are spare bytes in the r_lock cache line so the best approach
    is to make an rvt QP field and remove from the hfi1 priv field.
    
    Signed-off-by: Sebastian Sanchez <sebastian.sanchez@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 52ff275caf54..c0913c6c8002 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -125,7 +125,6 @@ struct hfi1_qp_priv {
 	struct sdma_engine *s_sde;                /* current sde */
 	struct send_context *s_sendcontext;       /* current sendcontext */
 	u8 s_sc;		                  /* SC[0..4] for next packet */
-	u8 r_adefered;                            /* number of acks defered */
 	struct iowait s_iowait;
 	struct rvt_qp *owner;
 };

commit d8966fcd4c25708c3a76ea7619644218373df639
Author: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
Date:   Sat Apr 29 14:41:28 2017 -0400

    IB/core: Use rdma_ah_attr accessor functions
    
    Modify core and driver components to use accessor functions
    introduced to access individual fields of rdma_ah_attr
    
    Reviewed-by: Ira Weiny <ira.weiny@intel.com>
    Reviewed-by: Don Hiatt <don.hiatt@intel.com>
    Reviewed-by: Sean Hefty <sean.hefty@intel.com>
    Reviewed-by: Niranjana Vishwanathapura <niranjana.vishwanathapura@intel.com>
    Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index fb7f0a234fdd..52ff275caf54 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -347,7 +347,7 @@ int hfi1_ruc_check_hdr(struct hfi1_ibport *ibp, struct ib_header *hdr,
 		       int has_grh, struct rvt_qp *qp, u32 bth0);
 
 u32 hfi1_make_grh(struct hfi1_ibport *ibp, struct ib_grh *hdr,
-		  struct ib_global_route *grh, u32 hwords, u32 nwords);
+		  const struct ib_global_route *grh, u32 hwords, u32 nwords);
 
 void hfi1_make_ruc_header(struct rvt_qp *qp, struct ib_other_headers *ohdr,
 			  u32 bth0, u32 bth2, int middle,

commit 90898850ec4e7b3ba0f9a35cc7169ff19ff367a6
Author: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
Date:   Sat Apr 29 14:41:18 2017 -0400

    IB/core: Rename struct ib_ah_attr to rdma_ah_attr
    
    This patch simply renames struct ib_ah_attr to
    rdma_ah_attr as these fields specify attributes that are
    not necessarily specific to IB.
    
    Reviewed-by: Ira Weiny <ira.weiny@intel.com>
    Reviewed-by: Don Hiatt <don.hiatt@intel.com>
    Reviewed-by: Niranjana Vishwanathapura <niranjana.vishwanathapura@intel.com>
    Reviewed-by: Sean Hefty <sean.hefty@intel.com>
    Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 46b00ed9f2dc..fb7f0a234fdd 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -308,7 +308,7 @@ void hfi1_rc_hdrerr(
 	u32 rcv_flags,
 	struct rvt_qp *qp);
 
-u8 ah_to_sc(struct ib_device *ibdev, struct ib_ah_attr *ah_attr);
+u8 ah_to_sc(struct ib_device *ibdev, struct rdma_ah_attr *ah_attr);
 
 struct ib_ah *hfi1_create_qp0_ah(struct hfi1_ibport *ibp, u16 dlid);
 

commit b6eac931b9bb2bce4db7032c35b41e5e34ec22a5
Author: Mike Marciniszyn <mike.marciniszyn@intel.com>
Date:   Sun Apr 9 10:16:35 2017 -0700

    IB/hfi1: Prevent kernel QP post send hard lockups
    
    The driver progress routines can call cond_resched() when
    a timeslice is exhausted and irqs are enabled.
    
    If the ULP had been holding a spin lock without disabling irqs and
    the post send directly called the progress routine, the cond_resched()
    could yield allowing another thread from the same ULP to deadlock
    on that same lock.
    
    Correct by replacing the current hfi1_do_send() calldown with a unique
    one for post send and adding an argument to hfi1_do_send() to indicate
    that the send engine is running in a thread.   If the routine is not
    running in a thread, avoid calling cond_resched().
    
    CC: <stable@vger.kernel.org> # 4.7.x-
    Fixes: Commit 831464ce4b74 ("IB/hfi1: Don't call cond_resched in atomic mode when sending packets")
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 6c549e7a25e7..46b00ed9f2dc 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -1,5 +1,5 @@
 /*
- * Copyright(c) 2015, 2016 Intel Corporation.
+ * Copyright(c) 2015 - 2017 Intel Corporation.
  *
  * This file is provided under a dual BSD/GPLv2 license.  When using or
  * redistributing this file, you may do so under either license.
@@ -355,7 +355,9 @@ void hfi1_make_ruc_header(struct rvt_qp *qp, struct ib_other_headers *ohdr,
 
 void _hfi1_do_send(struct work_struct *work);
 
-void hfi1_do_send(struct rvt_qp *qp);
+void hfi1_do_send_from_rvt(struct rvt_qp *qp);
+
+void hfi1_do_send(struct rvt_qp *qp, bool in_thread);
 
 void hfi1_send_complete(struct rvt_qp *qp, struct rvt_swqe *wqe,
 			enum ib_wc_status status);

commit 243d9f436f89f95c304011bd32485afc27581986
Author: Don Hiatt <don.hiatt@intel.com>
Date:   Mon Mar 20 17:26:20 2017 -0700

    IB/hfi1: Add transmit fault injection feature
    
    Add ability to fault packets on transmit by opcode.
    Dropping by packet can be achieved by setting the mask to 0.
    
    In order to drop non-verbs traffic we set PbcInsertHrc
    to NONE (0x2). The packet will still be delivered to
    the receiving node but a KHdrHCRCErr (KDETH packet
    with a bad HCRC) will be triggered and the packet will
    not be delivered to the correct context.
    
    In order to drop regular verbs traffic we set the
    PbcTestEbp flag. The packet will still be delivered
    to the receiving node but a 'late ebp error' will
    be triggered and will be dropped.
    
    A global toggle (/sys/kernel/debug/hfi1/hfi1_X/fault_suppress_err)
    has been added to suppress the error messages on the receive
    node when a packet was faulted on the sending node.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 2756ec35b054..6c549e7a25e7 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -198,6 +198,7 @@ struct hfi1_ibdev {
 #ifdef CONFIG_FAULT_INJECTION
 	struct fault_opcode *fault_opcode;
 	struct fault_packet *fault_packet;
+	bool fault_suppress_err;
 #endif
 #endif
 };

commit 0181ce31b26021f7c2f9506112a05c847a36f0f2
Author: Don Hiatt <don.hiatt@intel.com>
Date:   Mon Mar 20 17:26:14 2017 -0700

    IB/hfi1: Add receive fault injection feature
    
    Add fault injection capability:
      - Drop packets unconditionally (fault_by_packet)
      - Drop packets based on opcode (fault_by_opcode)
    
    This feature reacts to the global FAULT_INJECTION
    config flag.
    
    The faulting traces have been added:
      - misc/fault_opcode
      - misc/fault_packet
    
    See 'Documentation/fault-injection/fault-injection.txt'
    for details.
    
    Examples:
      - Dropping packets by opcode:
        /sys/kernel/debug/hfi1/hfi1_X/fault_opcode
            # Enable fault
            echo Y > fault_by_opcode
            # Setprobability of dropping (0-100%)
            # echo 25 > probability
            # Set opcode
            echo 0x64 > opcode
            # Number of times to fault
            echo 3 > times
            # An optional mask allows you to fault
            # a range of opcodes
            echo 0xf0 > mask
        /sys/kernel/debug/hfi1/hfi1_X/fault_stats
        contains a value in parentheses to indicate
        number of each opcode dropped.
    
      - Dropping packets unconditionally
        /sys/kernel/debug/hfi1/hfi1_X/fault_packet
            # Enable fault
            echo Y > fault_by_packet
        /sys/kernel/debug/hfi1/hfi1_X/fault_packet/fault_stats
        contains the number of packets dropped.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 3a0b589e41c2..2756ec35b054 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -195,6 +195,10 @@ struct hfi1_ibdev {
 	struct dentry *hfi1_ibdev_dbg;
 	/* per HFI symlinks to above */
 	struct dentry *hfi1_ibdev_link;
+#ifdef CONFIG_FAULT_INJECTION
+	struct fault_opcode *fault_opcode;
+	struct fault_packet *fault_packet;
+#endif
 #endif
 };
 

commit 1198fcea8a7810d06069a85256d1ef9ec97d434b
Author: Brian Welty <brian.welty@intel.com>
Date:   Wed Feb 8 05:27:37 2017 -0800

    IB/hfi1, rdmavt: Move SGE state helper routines into rdmavt
    
    To improve code reuse, add small SGE state helper routines to rdmavt_mr.h.
    Leverage these in hfi1, including refactoring of hfi1_copy_sge.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Brian Welty <brian.welty@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 9fab6b3d12f6..3a0b589e41c2 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -291,8 +291,6 @@ int hfi1_verbs_send(struct rvt_qp *qp, struct hfi1_pkt_state *ps);
 void hfi1_copy_sge(struct rvt_sge_state *ss, void *data, u32 length,
 		   bool release, bool copy_last);
 
-void hfi1_skip_sge(struct rvt_sge_state *ss, u32 length, bool release);
-
 void hfi1_cnp_rcv(struct hfi1_packet *packet);
 
 void hfi1_uc_rcv(struct hfi1_packet *packet);

commit 0128fceaf934dbfca4537d4eb8c3a5f7e84562c8
Author: Brian Welty <brian.welty@intel.com>
Date:   Wed Feb 8 05:27:31 2017 -0800

    IB/hfi1, rdmavt: Update copy_sge to use boolean arguments
    
    Convert copy_sge and related SGE state functions to use boolean.
    For determining if QP is in user mode, add helper function in rdmavt_qp.h.
    This is used to determine if QP needs the last byte ordering.
    While here, change rvt_pd.user to a boolean.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Reviewed-by: Dean Luick <dean.luick@intel.com>
    Signed-off-by: Brian Welty <brian.welty@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 6e9e4bbf8ae4..9fab6b3d12f6 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -289,9 +289,9 @@ void hfi1_put_txreq(struct verbs_txreq *tx);
 int hfi1_verbs_send(struct rvt_qp *qp, struct hfi1_pkt_state *ps);
 
 void hfi1_copy_sge(struct rvt_sge_state *ss, void *data, u32 length,
-		   int release, int copy_last);
+		   bool release, bool copy_last);
 
-void hfi1_skip_sge(struct rvt_sge_state *ss, u32 length, int release);
+void hfi1_skip_sge(struct rvt_sge_state *ss, u32 length, bool release);
 
 void hfi1_cnp_rcv(struct hfi1_packet *packet);
 

commit 56acbbfb46d9d613858de2bffcc7dee4205682b7
Author: Venkata Sandeep Dhanalakota <venkata.s.dhanalakota@intel.com>
Date:   Wed Feb 8 05:27:19 2017 -0800

    IB/hfi1: Use new rdmavt timers
    
    Reduce hfi1 code footprint by using the rdmavt timers.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Reviewed-by: Brian Welty <brian.welty@intel.com>
    Signed-off-by: Venkata Sandeep Dhanalakota <venkata.s.dhanalakota@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index f359684d0b46..6e9e4bbf8ae4 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -127,7 +127,6 @@ struct hfi1_qp_priv {
 	u8 s_sc;		                  /* SC[0..4] for next packet */
 	u8 r_adefered;                            /* number of acks defered */
 	struct iowait s_iowait;
-	struct timer_list s_rnr_timer;
 	struct rvt_qp *owner;
 };
 
@@ -310,12 +309,6 @@ u8 ah_to_sc(struct ib_device *ibdev, struct ib_ah_attr *ah_attr);
 
 struct ib_ah *hfi1_create_qp0_ah(struct hfi1_ibport *ibp, u16 dlid);
 
-void hfi1_rc_rnr_retry(unsigned long arg);
-void hfi1_add_rnr_timer(struct rvt_qp *qp, u32 to);
-void hfi1_rc_timeout(unsigned long arg);
-void hfi1_del_timers_sync(struct rvt_qp *qp);
-void hfi1_stop_rc_timers(struct rvt_qp *qp);
-
 void hfi1_rc_send_complete(struct rvt_qp *qp, struct ib_header *hdr);
 
 void hfi1_ud_rcv(struct hfi1_packet *packet);
@@ -331,7 +324,7 @@ int hfi1_check_modify_qp(struct rvt_qp *qp, struct ib_qp_attr *attr,
 
 void hfi1_modify_qp(struct rvt_qp *qp, struct ib_qp_attr *attr,
 		    int attr_mask, struct ib_udata *udata);
-
+void hfi1_restart_rc(struct rvt_qp *qp, u32 psn, int wait);
 int hfi1_check_send_wqe(struct rvt_qp *qp, struct rvt_swqe *wqe);
 
 extern const u32 rc_only_opcode;

commit 696513e8cf39ccb8ee8010fd2157f095b3af6a91
Author: Brian Welty <brian.welty@intel.com>
Date:   Wed Feb 8 05:27:07 2017 -0800

    IB/hfi1, qib, rdmavt: Move AETH credit functions into rdmavt
    
    Add rvt_compute_aeth() and rvt_get_credit() as shared functions in
    rdmavt, moved from hfi1/qib logic.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Brian Welty <brian.welty@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 39b0074e9c43..f359684d0b46 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -259,15 +259,6 @@ int hfi1_process_mad(struct ib_device *ibdev, int mad_flags, u8 port,
 #endif
 #define PSN_MODIFY_MASK 0xFFFFFF
 
-/*
- * Compare the lower 24 bits of the msn values.
- * Returns an integer <, ==, or > than zero.
- */
-static inline int cmp_msn(u32 a, u32 b)
-{
-	return (((int)a) - ((int)b)) << 8;
-}
-
 /*
  * Compare two PSNs
  * Returns an integer <, ==, or > than zero.

commit beb5a0426794c9698c4e0349c626d819b5f3b2c7
Author: Brian Welty <brian.welty@intel.com>
Date:   Wed Feb 8 05:27:01 2017 -0800

    IB/hfi1, qib, rdmavt: Move two IB event functions into rdmavt
    
    Add rvt_rc_error() and rvt_comm_est() as shared functions in
    rdmavt, moved from hfi1/qib logic.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Brian Welty <brian.welty@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index e6b893010e6d..39b0074e9c43 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -327,8 +327,6 @@ void hfi1_stop_rc_timers(struct rvt_qp *qp);
 
 void hfi1_rc_send_complete(struct rvt_qp *qp, struct ib_header *hdr);
 
-void hfi1_rc_error(struct rvt_qp *qp, enum ib_wc_status err);
-
 void hfi1_ud_rcv(struct hfi1_packet *packet);
 
 int hfi1_lookup_pkey_idx(struct hfi1_ibport *ibp, u16 pkey);

commit a6cd5f08e085176fe8dbd4c57217058e53dfc4d9
Author: Jakub Pawlak <jakub.pawlak@intel.com>
Date:   Mon Oct 17 04:19:30 2016 -0700

    IB/hfi1: Unify access to GUID entries
    
    This patch consolidates the node GUIDs and the port GUID handling
    and unifies access to these items. The knowledge of hfi1 GUIDs'
    design and their location are kept in accessors to centralize access.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Reviewed-by: Brian Welty <brian.welty@intel.com>
    Signed-off-by: Jakub Pawlak <jakub.pawlak@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 7a8af39e99d4..e6b893010e6d 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -73,7 +73,6 @@ struct hfi1_packet;
 #include "iowait.h"
 
 #define HFI1_MAX_RDMA_ATOMIC     16
-#define HFI1_GUIDS_PER_PORT	5
 
 /*
  * Increment this value if any changes that break userspace ABI
@@ -169,8 +168,6 @@ struct hfi1_ibport {
 	struct rvt_qp __rcu *qp[2];
 	struct rvt_ibport rvp;
 
-	__be64 guids[HFI1_GUIDS_PER_PORT	- 1];	/* writable GUIDs */
-
 	/* the first 16 entries are sl_to_vl for !OPA */
 	u8 sl_to_sc[32];
 	u8 sc_to_sl[32];

commit 4e045572e2c2be674ed7e43cca7ca105e8a22f56
Author: Mike Marciniszyn <mike.marciniszyn@intel.com>
Date:   Mon Oct 10 06:14:28 2016 -0700

    IB/hfi1: Add unique txwait_lock for txreq events
    
    Profiling suggests that the read_seqbegin() in
    the txreq put logic is colliding with other uses
    of the iowait lock.
    
    The packet at a time use of this lock dictates a unique
    lock to avoid reader/writer collisions when the number
    of vTxWait events is low.
    
    In order to support a unique lock the iowait struct embedded
    in the QP is extended to remember the lock that protects the queue
    head.
    
    The QP destroy removes that QP from any wait list.  It doesn't
    need to know the head because of the linked list API, but it does
    need to know the lock required to protect the head.
    
    This also opens up the wait logic to have unique per resources locks
    which needs to be in future refinement.
    
    Reviewed-by: Sebastian Sanchez <sebastian.sanchez@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 1c3815d89eb7..7a8af39e99d4 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -180,18 +180,19 @@ struct hfi1_ibdev {
 	struct rvt_dev_info rdi; /* Must be first */
 
 	/* QP numbers are shared by all IB ports */
-	/* protect wait lists */
-	seqlock_t iowait_lock;
+	/* protect txwait list */
+	seqlock_t txwait_lock ____cacheline_aligned_in_smp;
 	struct list_head txwait;        /* list for wait verbs_txreq */
 	struct list_head memwait;       /* list for wait kernel memory */
-	struct list_head txreq_free;
 	struct kmem_cache *verbs_txreq_cache;
-	struct timer_list mem_timer;
+	u64 n_txwait;
+	u64 n_kmem_wait;
 
+	/* protect iowait lists */
+	seqlock_t iowait_lock ____cacheline_aligned_in_smp;
 	u64 n_piowait;
 	u64 n_piodrain;
-	u64 n_txwait;
-	u64 n_kmem_wait;
+	struct timer_list mem_timer;
 
 #ifdef CONFIG_DEBUG_FS
 	/* per HFI debugfs */

commit b374e060cc2aa31ceca885a7fe5bd591876c02b3
Author: Mike Marciniszyn <mike.marciniszyn@intel.com>
Date:   Sun Sep 25 07:40:58 2016 -0700

    IB/hfi1: Consolidate pio control masks into single definition
    
    This allows for adding additional pages of adaptive pio
    opcode control including manufacturer specific ones.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 0dd65eb46ebe..1c3815d89eb7 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -97,6 +97,9 @@ struct hfi1_packet;
 
 #define IB_DEFAULT_GID_PREFIX	cpu_to_be64(0xfe80000000000000ULL)
 
+#define RC_OP(x) IB_OPCODE_RC_##x
+#define UC_OP(x) IB_OPCODE_UC_##x
+
 /* flags passed by hfi1_ib_rcv() */
 enum {
 	HFI1_HAS_GRH = (1 << 0),

commit 261a4351844bcacb622d6d498a1bc98242b2db9e
Author: Mike Marciniszyn <mike.marciniszyn@intel.com>
Date:   Tue Sep 6 04:35:05 2016 -0700

    IB/qib,IB/hfi: Use core common header file
    
    Use common header file structs, defines, and accessors
    in the drivers.  The old declarations are removed.
    
    The repositioning of the includes allows for the removal
    of hfi1_message_header and replaces its use with ib_header.
    
    Also corrected are two issues with set_armed_to_active():
    - The "packet" parameter is now a pointer as it should have been
    - The etype is validated to insure that the header is correct
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Reviewed-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index d1b101c54828..0dd65eb46ebe 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -60,6 +60,7 @@
 #include <rdma/ib_pack.h>
 #include <rdma/ib_user_verbs.h>
 #include <rdma/ib_mad.h>
+#include <rdma/ib_hdrs.h>
 #include <rdma/rdma_vt.h>
 #include <rdma/rdmavt_qp.h>
 #include <rdma/rdmavt_cq.h>
@@ -80,16 +81,6 @@ struct hfi1_packet;
  */
 #define HFI1_UVERBS_ABI_VERSION       2
 
-#define IB_SEQ_NAK	(3 << 29)
-
-/* AETH NAK opcode values */
-#define IB_RNR_NAK                      0x20
-#define IB_NAK_PSN_ERROR                0x60
-#define IB_NAK_INVALID_REQUEST          0x61
-#define IB_NAK_REMOTE_ACCESS_ERROR      0x62
-#define IB_NAK_REMOTE_OPERATIONAL_ERROR 0x63
-#define IB_NAK_INVALID_RD_REQUEST       0x64
-
 /* IB Performance Manager status values */
 #define IB_PMA_SAMPLE_STATUS_DONE       0x00
 #define IB_PMA_SAMPLE_STATUS_STARTED    0x01
@@ -104,19 +95,6 @@ struct hfi1_packet;
 
 #define HFI1_VENDOR_IPG		cpu_to_be16(0xFFA0)
 
-#define IB_BTH_REQ_ACK		BIT(31)
-#define IB_BTH_SOLICITED	BIT(23)
-#define IB_BTH_MIG_REQ		BIT(22)
-
-#define IB_GRH_VERSION		6
-#define IB_GRH_VERSION_MASK	0xF
-#define IB_GRH_VERSION_SHIFT	28
-#define IB_GRH_TCLASS_MASK	0xFF
-#define IB_GRH_TCLASS_SHIFT	20
-#define IB_GRH_FLOW_MASK	0xFFFFF
-#define IB_GRH_FLOW_SHIFT	0
-#define IB_GRH_NEXT_HDR		0x1B
-
 #define IB_DEFAULT_GID_PREFIX	cpu_to_be64(0xfe80000000000000ULL)
 
 /* flags passed by hfi1_ib_rcv() */
@@ -124,60 +102,6 @@ enum {
 	HFI1_HAS_GRH = (1 << 0),
 };
 
-struct ib_reth {
-	__be64 vaddr;
-	__be32 rkey;
-	__be32 length;
-} __packed;
-
-struct ib_atomic_eth {
-	__be32 vaddr[2];        /* unaligned so access as 2 32-bit words */
-	__be32 rkey;
-	__be64 swap_data;
-	__be64 compare_data;
-} __packed;
-
-union ib_ehdrs {
-	struct {
-		__be32 deth[2];
-		__be32 imm_data;
-	} ud;
-	struct {
-		struct ib_reth reth;
-		__be32 imm_data;
-	} rc;
-	struct {
-		__be32 aeth;
-		__be32 atomic_ack_eth[2];
-	} at;
-	__be32 imm_data;
-	__be32 aeth;
-	__be32 ieth;
-	struct ib_atomic_eth atomic_eth;
-}  __packed;
-
-struct hfi1_other_headers {
-	__be32 bth[3];
-	union ib_ehdrs u;
-} __packed;
-
-/*
- * Note that UD packets with a GRH header are 8+40+12+8 = 68 bytes
- * long (72 w/ imm_data).  Only the first 56 bytes of the IB header
- * will be in the eager header buffer.  The remaining 12 or 16 bytes
- * are in the data buffer.
- */
-struct hfi1_ib_header {
-	__be16 lrh[4];
-	union {
-		struct {
-			struct ib_grh grh;
-			struct hfi1_other_headers oth;
-		} l;
-		struct hfi1_other_headers oth;
-	} u;
-} __packed;
-
 struct hfi1_ahg_info {
 	u32 ahgdesc[2];
 	u16 tx_flags;
@@ -187,7 +111,7 @@ struct hfi1_ahg_info {
 
 struct hfi1_sdma_header {
 	__le64 pbc;
-	struct hfi1_ib_header hdr;
+	struct ib_header hdr;
 } __packed;
 
 /*
@@ -386,7 +310,7 @@ void hfi1_rc_rcv(struct hfi1_packet *packet);
 
 void hfi1_rc_hdrerr(
 	struct hfi1_ctxtdata *rcd,
-	struct hfi1_ib_header *hdr,
+	struct ib_header *hdr,
 	u32 rcv_flags,
 	struct rvt_qp *qp);
 
@@ -400,7 +324,7 @@ void hfi1_rc_timeout(unsigned long arg);
 void hfi1_del_timers_sync(struct rvt_qp *qp);
 void hfi1_stop_rc_timers(struct rvt_qp *qp);
 
-void hfi1_rc_send_complete(struct rvt_qp *qp, struct hfi1_ib_header *hdr);
+void hfi1_rc_send_complete(struct rvt_qp *qp, struct ib_header *hdr);
 
 void hfi1_rc_error(struct rvt_qp *qp, enum ib_wc_status err);
 
@@ -423,7 +347,7 @@ int hfi1_check_send_wqe(struct rvt_qp *qp, struct rvt_swqe *wqe);
 extern const u32 rc_only_opcode;
 extern const u32 uc_only_opcode;
 
-static inline u8 get_opcode(struct hfi1_ib_header *h)
+static inline u8 get_opcode(struct ib_header *h)
 {
 	u16 lnh = be16_to_cpu(h->lrh[0]) & 3;
 
@@ -433,13 +357,13 @@ static inline u8 get_opcode(struct hfi1_ib_header *h)
 		return be32_to_cpu(h->u.l.oth.bth[0]) >> 24;
 }
 
-int hfi1_ruc_check_hdr(struct hfi1_ibport *ibp, struct hfi1_ib_header *hdr,
+int hfi1_ruc_check_hdr(struct hfi1_ibport *ibp, struct ib_header *hdr,
 		       int has_grh, struct rvt_qp *qp, u32 bth0);
 
 u32 hfi1_make_grh(struct hfi1_ibport *ibp, struct ib_grh *hdr,
 		  struct ib_global_route *grh, u32 hwords, u32 nwords);
 
-void hfi1_make_ruc_header(struct rvt_qp *qp, struct hfi1_other_headers *ohdr,
+void hfi1_make_ruc_header(struct rvt_qp *qp, struct ib_other_headers *ohdr,
 			  u32 bth0, u32 bth2, int middle,
 			  struct hfi1_pkt_state *ps);
 

commit d4d602e9a3035d039befdd37df5213b430948f28
Author: Don Hiatt <don.hiatt@intel.com>
Date:   Mon Jul 25 13:40:22 2016 -0700

    IB/hfi1: Rename hfi1_pio_header to hfi1_sdma_header.
    
    hfi1_pio_header should really be called hfi1_sdma_header
    as it is only used for sdma transmits.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Reviewed-by: Dean Luick <dean.luick@intel.com>
    Reviewed-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index d44550fdd39f..d1b101c54828 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -185,7 +185,7 @@ struct hfi1_ahg_info {
 	u8 ahgidx;
 };
 
-struct hfi1_pio_header {
+struct hfi1_sdma_header {
 	__le64 pbc;
 	struct hfi1_ib_header hdr;
 } __packed;

commit a9b6b3bc295d2360480d32049c32661e809c7c5c
Author: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
Date:   Mon Jul 25 13:40:16 2016 -0700

    IB/hfi1: Rename struct ahg_ib_header to struct hfi1_ahg_info
    
    struct ahg_ib_header has no header specific information.
    Rename it to struct hfi1_ahg_info
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Reviewed-by: Dean Luick <dean.luick@intel.com>
    Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 4bd1cd42e981..d44550fdd39f 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -178,7 +178,7 @@ struct hfi1_ib_header {
 	} u;
 } __packed;
 
-struct ahg_ib_header {
+struct hfi1_ahg_info {
 	u32 ahgdesc[2];
 	u16 tx_flags;
 	u8 ahgcount;
@@ -195,7 +195,7 @@ struct hfi1_pio_header {
  * pair is made common
  */
 struct hfi1_qp_priv {
-	struct ahg_ib_header *s_hdr;              /* next header to send */
+	struct hfi1_ahg_info *s_ahg;              /* ahg info for next header */
 	struct sdma_engine *s_sde;                /* current sde */
 	struct send_context *s_sendcontext;       /* current sendcontext */
 	u8 s_sc;		                  /* SC[0..4] for next packet */

commit bd24ef5eca75b00c9d98533f5644750de2f29a65
Author: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
Date:   Mon Jul 25 13:40:10 2016 -0700

    IB/hfi1: Remove unused elements from struct ahg_ib_header
    
    sde and hfi1_ib_header are not used anymore.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Reviewed-by: Dean Luick <dean.luick@intel.com>
    Reviewed-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 488356775627..4bd1cd42e981 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -179,12 +179,10 @@ struct hfi1_ib_header {
 } __packed;
 
 struct ahg_ib_header {
-	struct sdma_engine *sde;
 	u32 ahgdesc[2];
 	u16 tx_flags;
 	u8 ahgcount;
 	u8 ahgidx;
-	struct hfi1_ib_header ibh;
 };
 
 struct hfi1_pio_header {

commit 23f7d0d29e842360cc20bf03460f52f14ced915d
Author: Jianxin Xiong <jianxin.xiong@intel.com>
Date:   Tue May 24 12:50:10 2016 -0700

    IB/hfi1, qib: Add ieth to the packet header definitions
    
    A new union member "ieth" (Invalidate Extended Transport Header) is
    added to the packet header definition in preparation of supporting
    the send with invalidate opcode.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jianxin Xiong <jianxin.xiong@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
index 3ee223983b20..488356775627 100644
--- a/drivers/infiniband/hw/hfi1/verbs.h
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -152,6 +152,7 @@ union ib_ehdrs {
 	} at;
 	__be32 imm_data;
 	__be32 aeth;
+	__be32 ieth;
 	struct ib_atomic_eth atomic_eth;
 }  __packed;
 

commit f48ad614c100783be1e7e777dc36328001b83999
Author: Dennis Dalessandro <dennis.dalessandro@intel.com>
Date:   Thu May 19 05:26:51 2016 -0700

    IB/hfi1: Move driver out of staging
    
    The TODO list for the hfi1 driver was completed during 4.6. In addition
    other objections raised (which are far beyond what was in the TODO list)
    have been addressed as well. It is now time to remove the driver from
    staging and into the drivers/infiniband sub-tree.
    
    Reviewed-by: Jubin John <jubin.john@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs.h b/drivers/infiniband/hw/hfi1/verbs.h
new file mode 100644
index 000000000000..3ee223983b20
--- /dev/null
+++ b/drivers/infiniband/hw/hfi1/verbs.h
@@ -0,0 +1,530 @@
+/*
+ * Copyright(c) 2015, 2016 Intel Corporation.
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *  - Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  - Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *  - Neither the name of Intel Corporation nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ */
+
+#ifndef HFI1_VERBS_H
+#define HFI1_VERBS_H
+
+#include <linux/types.h>
+#include <linux/seqlock.h>
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/kref.h>
+#include <linux/workqueue.h>
+#include <linux/kthread.h>
+#include <linux/completion.h>
+#include <linux/slab.h>
+#include <rdma/ib_pack.h>
+#include <rdma/ib_user_verbs.h>
+#include <rdma/ib_mad.h>
+#include <rdma/rdma_vt.h>
+#include <rdma/rdmavt_qp.h>
+#include <rdma/rdmavt_cq.h>
+
+struct hfi1_ctxtdata;
+struct hfi1_pportdata;
+struct hfi1_devdata;
+struct hfi1_packet;
+
+#include "iowait.h"
+
+#define HFI1_MAX_RDMA_ATOMIC     16
+#define HFI1_GUIDS_PER_PORT	5
+
+/*
+ * Increment this value if any changes that break userspace ABI
+ * compatibility are made.
+ */
+#define HFI1_UVERBS_ABI_VERSION       2
+
+#define IB_SEQ_NAK	(3 << 29)
+
+/* AETH NAK opcode values */
+#define IB_RNR_NAK                      0x20
+#define IB_NAK_PSN_ERROR                0x60
+#define IB_NAK_INVALID_REQUEST          0x61
+#define IB_NAK_REMOTE_ACCESS_ERROR      0x62
+#define IB_NAK_REMOTE_OPERATIONAL_ERROR 0x63
+#define IB_NAK_INVALID_RD_REQUEST       0x64
+
+/* IB Performance Manager status values */
+#define IB_PMA_SAMPLE_STATUS_DONE       0x00
+#define IB_PMA_SAMPLE_STATUS_STARTED    0x01
+#define IB_PMA_SAMPLE_STATUS_RUNNING    0x02
+
+/* Mandatory IB performance counter select values. */
+#define IB_PMA_PORT_XMIT_DATA   cpu_to_be16(0x0001)
+#define IB_PMA_PORT_RCV_DATA    cpu_to_be16(0x0002)
+#define IB_PMA_PORT_XMIT_PKTS   cpu_to_be16(0x0003)
+#define IB_PMA_PORT_RCV_PKTS    cpu_to_be16(0x0004)
+#define IB_PMA_PORT_XMIT_WAIT   cpu_to_be16(0x0005)
+
+#define HFI1_VENDOR_IPG		cpu_to_be16(0xFFA0)
+
+#define IB_BTH_REQ_ACK		BIT(31)
+#define IB_BTH_SOLICITED	BIT(23)
+#define IB_BTH_MIG_REQ		BIT(22)
+
+#define IB_GRH_VERSION		6
+#define IB_GRH_VERSION_MASK	0xF
+#define IB_GRH_VERSION_SHIFT	28
+#define IB_GRH_TCLASS_MASK	0xFF
+#define IB_GRH_TCLASS_SHIFT	20
+#define IB_GRH_FLOW_MASK	0xFFFFF
+#define IB_GRH_FLOW_SHIFT	0
+#define IB_GRH_NEXT_HDR		0x1B
+
+#define IB_DEFAULT_GID_PREFIX	cpu_to_be64(0xfe80000000000000ULL)
+
+/* flags passed by hfi1_ib_rcv() */
+enum {
+	HFI1_HAS_GRH = (1 << 0),
+};
+
+struct ib_reth {
+	__be64 vaddr;
+	__be32 rkey;
+	__be32 length;
+} __packed;
+
+struct ib_atomic_eth {
+	__be32 vaddr[2];        /* unaligned so access as 2 32-bit words */
+	__be32 rkey;
+	__be64 swap_data;
+	__be64 compare_data;
+} __packed;
+
+union ib_ehdrs {
+	struct {
+		__be32 deth[2];
+		__be32 imm_data;
+	} ud;
+	struct {
+		struct ib_reth reth;
+		__be32 imm_data;
+	} rc;
+	struct {
+		__be32 aeth;
+		__be32 atomic_ack_eth[2];
+	} at;
+	__be32 imm_data;
+	__be32 aeth;
+	struct ib_atomic_eth atomic_eth;
+}  __packed;
+
+struct hfi1_other_headers {
+	__be32 bth[3];
+	union ib_ehdrs u;
+} __packed;
+
+/*
+ * Note that UD packets with a GRH header are 8+40+12+8 = 68 bytes
+ * long (72 w/ imm_data).  Only the first 56 bytes of the IB header
+ * will be in the eager header buffer.  The remaining 12 or 16 bytes
+ * are in the data buffer.
+ */
+struct hfi1_ib_header {
+	__be16 lrh[4];
+	union {
+		struct {
+			struct ib_grh grh;
+			struct hfi1_other_headers oth;
+		} l;
+		struct hfi1_other_headers oth;
+	} u;
+} __packed;
+
+struct ahg_ib_header {
+	struct sdma_engine *sde;
+	u32 ahgdesc[2];
+	u16 tx_flags;
+	u8 ahgcount;
+	u8 ahgidx;
+	struct hfi1_ib_header ibh;
+};
+
+struct hfi1_pio_header {
+	__le64 pbc;
+	struct hfi1_ib_header hdr;
+} __packed;
+
+/*
+ * hfi1 specific data structures that will be hidden from rvt after the queue
+ * pair is made common
+ */
+struct hfi1_qp_priv {
+	struct ahg_ib_header *s_hdr;              /* next header to send */
+	struct sdma_engine *s_sde;                /* current sde */
+	struct send_context *s_sendcontext;       /* current sendcontext */
+	u8 s_sc;		                  /* SC[0..4] for next packet */
+	u8 r_adefered;                            /* number of acks defered */
+	struct iowait s_iowait;
+	struct timer_list s_rnr_timer;
+	struct rvt_qp *owner;
+};
+
+/*
+ * This structure is used to hold commonly lookedup and computed values during
+ * the send engine progress.
+ */
+struct hfi1_pkt_state {
+	struct hfi1_ibdev *dev;
+	struct hfi1_ibport *ibp;
+	struct hfi1_pportdata *ppd;
+	struct verbs_txreq *s_txreq;
+	unsigned long flags;
+};
+
+#define HFI1_PSN_CREDIT  16
+
+struct hfi1_opcode_stats {
+	u64 n_packets;          /* number of packets */
+	u64 n_bytes;            /* total number of bytes */
+};
+
+struct hfi1_opcode_stats_perctx {
+	struct hfi1_opcode_stats stats[256];
+};
+
+static inline void inc_opstats(
+	u32 tlen,
+	struct hfi1_opcode_stats *stats)
+{
+#ifdef CONFIG_DEBUG_FS
+	stats->n_bytes += tlen;
+	stats->n_packets++;
+#endif
+}
+
+struct hfi1_ibport {
+	struct rvt_qp __rcu *qp[2];
+	struct rvt_ibport rvp;
+
+	__be64 guids[HFI1_GUIDS_PER_PORT	- 1];	/* writable GUIDs */
+
+	/* the first 16 entries are sl_to_vl for !OPA */
+	u8 sl_to_sc[32];
+	u8 sc_to_sl[32];
+};
+
+struct hfi1_ibdev {
+	struct rvt_dev_info rdi; /* Must be first */
+
+	/* QP numbers are shared by all IB ports */
+	/* protect wait lists */
+	seqlock_t iowait_lock;
+	struct list_head txwait;        /* list for wait verbs_txreq */
+	struct list_head memwait;       /* list for wait kernel memory */
+	struct list_head txreq_free;
+	struct kmem_cache *verbs_txreq_cache;
+	struct timer_list mem_timer;
+
+	u64 n_piowait;
+	u64 n_piodrain;
+	u64 n_txwait;
+	u64 n_kmem_wait;
+
+#ifdef CONFIG_DEBUG_FS
+	/* per HFI debugfs */
+	struct dentry *hfi1_ibdev_dbg;
+	/* per HFI symlinks to above */
+	struct dentry *hfi1_ibdev_link;
+#endif
+};
+
+static inline struct hfi1_ibdev *to_idev(struct ib_device *ibdev)
+{
+	struct rvt_dev_info *rdi;
+
+	rdi = container_of(ibdev, struct rvt_dev_info, ibdev);
+	return container_of(rdi, struct hfi1_ibdev, rdi);
+}
+
+static inline struct rvt_qp *iowait_to_qp(struct  iowait *s_iowait)
+{
+	struct hfi1_qp_priv *priv;
+
+	priv = container_of(s_iowait, struct hfi1_qp_priv, s_iowait);
+	return priv->owner;
+}
+
+/*
+ * Send if not busy or waiting for I/O and either
+ * a RC response is pending or we can process send work requests.
+ */
+static inline int hfi1_send_ok(struct rvt_qp *qp)
+{
+	return !(qp->s_flags & (RVT_S_BUSY | RVT_S_ANY_WAIT_IO)) &&
+		(qp->s_hdrwords || (qp->s_flags & RVT_S_RESP_PENDING) ||
+		 !(qp->s_flags & RVT_S_ANY_WAIT_SEND));
+}
+
+/*
+ * This must be called with s_lock held.
+ */
+void hfi1_bad_pqkey(struct hfi1_ibport *ibp, __be16 trap_num, u32 key, u32 sl,
+		    u32 qp1, u32 qp2, u16 lid1, u16 lid2);
+void hfi1_cap_mask_chg(struct rvt_dev_info *rdi, u8 port_num);
+void hfi1_sys_guid_chg(struct hfi1_ibport *ibp);
+void hfi1_node_desc_chg(struct hfi1_ibport *ibp);
+int hfi1_process_mad(struct ib_device *ibdev, int mad_flags, u8 port,
+		     const struct ib_wc *in_wc, const struct ib_grh *in_grh,
+		     const struct ib_mad_hdr *in_mad, size_t in_mad_size,
+		     struct ib_mad_hdr *out_mad, size_t *out_mad_size,
+		     u16 *out_mad_pkey_index);
+
+/*
+ * The PSN_MASK and PSN_SHIFT allow for
+ * 1) comparing two PSNs
+ * 2) returning the PSN with any upper bits masked
+ * 3) returning the difference between to PSNs
+ *
+ * The number of significant bits in the PSN must
+ * necessarily be at least one bit less than
+ * the container holding the PSN.
+ */
+#ifndef CONFIG_HFI1_VERBS_31BIT_PSN
+#define PSN_MASK 0xFFFFFF
+#define PSN_SHIFT 8
+#else
+#define PSN_MASK 0x7FFFFFFF
+#define PSN_SHIFT 1
+#endif
+#define PSN_MODIFY_MASK 0xFFFFFF
+
+/*
+ * Compare the lower 24 bits of the msn values.
+ * Returns an integer <, ==, or > than zero.
+ */
+static inline int cmp_msn(u32 a, u32 b)
+{
+	return (((int)a) - ((int)b)) << 8;
+}
+
+/*
+ * Compare two PSNs
+ * Returns an integer <, ==, or > than zero.
+ */
+static inline int cmp_psn(u32 a, u32 b)
+{
+	return (((int)a) - ((int)b)) << PSN_SHIFT;
+}
+
+/*
+ * Return masked PSN
+ */
+static inline u32 mask_psn(u32 a)
+{
+	return a & PSN_MASK;
+}
+
+/*
+ * Return delta between two PSNs
+ */
+static inline u32 delta_psn(u32 a, u32 b)
+{
+	return (((int)a - (int)b) << PSN_SHIFT) >> PSN_SHIFT;
+}
+
+struct verbs_txreq;
+void hfi1_put_txreq(struct verbs_txreq *tx);
+
+int hfi1_verbs_send(struct rvt_qp *qp, struct hfi1_pkt_state *ps);
+
+void hfi1_copy_sge(struct rvt_sge_state *ss, void *data, u32 length,
+		   int release, int copy_last);
+
+void hfi1_skip_sge(struct rvt_sge_state *ss, u32 length, int release);
+
+void hfi1_cnp_rcv(struct hfi1_packet *packet);
+
+void hfi1_uc_rcv(struct hfi1_packet *packet);
+
+void hfi1_rc_rcv(struct hfi1_packet *packet);
+
+void hfi1_rc_hdrerr(
+	struct hfi1_ctxtdata *rcd,
+	struct hfi1_ib_header *hdr,
+	u32 rcv_flags,
+	struct rvt_qp *qp);
+
+u8 ah_to_sc(struct ib_device *ibdev, struct ib_ah_attr *ah_attr);
+
+struct ib_ah *hfi1_create_qp0_ah(struct hfi1_ibport *ibp, u16 dlid);
+
+void hfi1_rc_rnr_retry(unsigned long arg);
+void hfi1_add_rnr_timer(struct rvt_qp *qp, u32 to);
+void hfi1_rc_timeout(unsigned long arg);
+void hfi1_del_timers_sync(struct rvt_qp *qp);
+void hfi1_stop_rc_timers(struct rvt_qp *qp);
+
+void hfi1_rc_send_complete(struct rvt_qp *qp, struct hfi1_ib_header *hdr);
+
+void hfi1_rc_error(struct rvt_qp *qp, enum ib_wc_status err);
+
+void hfi1_ud_rcv(struct hfi1_packet *packet);
+
+int hfi1_lookup_pkey_idx(struct hfi1_ibport *ibp, u16 pkey);
+
+int hfi1_rvt_get_rwqe(struct rvt_qp *qp, int wr_id_only);
+
+void hfi1_migrate_qp(struct rvt_qp *qp);
+
+int hfi1_check_modify_qp(struct rvt_qp *qp, struct ib_qp_attr *attr,
+			 int attr_mask, struct ib_udata *udata);
+
+void hfi1_modify_qp(struct rvt_qp *qp, struct ib_qp_attr *attr,
+		    int attr_mask, struct ib_udata *udata);
+
+int hfi1_check_send_wqe(struct rvt_qp *qp, struct rvt_swqe *wqe);
+
+extern const u32 rc_only_opcode;
+extern const u32 uc_only_opcode;
+
+static inline u8 get_opcode(struct hfi1_ib_header *h)
+{
+	u16 lnh = be16_to_cpu(h->lrh[0]) & 3;
+
+	if (lnh == IB_LNH_IBA_LOCAL)
+		return be32_to_cpu(h->u.oth.bth[0]) >> 24;
+	else
+		return be32_to_cpu(h->u.l.oth.bth[0]) >> 24;
+}
+
+int hfi1_ruc_check_hdr(struct hfi1_ibport *ibp, struct hfi1_ib_header *hdr,
+		       int has_grh, struct rvt_qp *qp, u32 bth0);
+
+u32 hfi1_make_grh(struct hfi1_ibport *ibp, struct ib_grh *hdr,
+		  struct ib_global_route *grh, u32 hwords, u32 nwords);
+
+void hfi1_make_ruc_header(struct rvt_qp *qp, struct hfi1_other_headers *ohdr,
+			  u32 bth0, u32 bth2, int middle,
+			  struct hfi1_pkt_state *ps);
+
+void _hfi1_do_send(struct work_struct *work);
+
+void hfi1_do_send(struct rvt_qp *qp);
+
+void hfi1_send_complete(struct rvt_qp *qp, struct rvt_swqe *wqe,
+			enum ib_wc_status status);
+
+void hfi1_send_rc_ack(struct hfi1_ctxtdata *, struct rvt_qp *qp, int is_fecn);
+
+int hfi1_make_rc_req(struct rvt_qp *qp, struct hfi1_pkt_state *ps);
+
+int hfi1_make_uc_req(struct rvt_qp *qp, struct hfi1_pkt_state *ps);
+
+int hfi1_make_ud_req(struct rvt_qp *qp, struct hfi1_pkt_state *ps);
+
+int hfi1_register_ib_device(struct hfi1_devdata *);
+
+void hfi1_unregister_ib_device(struct hfi1_devdata *);
+
+void hfi1_ib_rcv(struct hfi1_packet *packet);
+
+unsigned hfi1_get_npkeys(struct hfi1_devdata *);
+
+int hfi1_verbs_send_dma(struct rvt_qp *qp, struct hfi1_pkt_state *ps,
+			u64 pbc);
+
+int hfi1_verbs_send_pio(struct rvt_qp *qp, struct hfi1_pkt_state *ps,
+			u64 pbc);
+
+int hfi1_wss_init(void);
+void hfi1_wss_exit(void);
+
+/* platform specific: return the lowest level cache (llc) size, in KiB */
+static inline int wss_llc_size(void)
+{
+	/* assume that the boot CPU value is universal for all CPUs */
+	return boot_cpu_data.x86_cache_size;
+}
+
+/* platform specific: cacheless copy */
+static inline void cacheless_memcpy(void *dst, void *src, size_t n)
+{
+	/*
+	 * Use the only available X64 cacheless copy.  Add a __user cast
+	 * to quiet sparse.  The src agument is already in the kernel so
+	 * there are no security issues.  The extra fault recovery machinery
+	 * is not invoked.
+	 */
+	__copy_user_nocache(dst, (void __user *)src, n, 0);
+}
+
+extern const enum ib_wc_opcode ib_hfi1_wc_opcode[];
+
+extern const u8 hdr_len_by_opcode[];
+
+extern const int ib_rvt_state_ops[];
+
+extern __be64 ib_hfi1_sys_image_guid;    /* in network order */
+
+extern unsigned int hfi1_max_cqes;
+
+extern unsigned int hfi1_max_cqs;
+
+extern unsigned int hfi1_max_qp_wrs;
+
+extern unsigned int hfi1_max_qps;
+
+extern unsigned int hfi1_max_sges;
+
+extern unsigned int hfi1_max_mcast_grps;
+
+extern unsigned int hfi1_max_mcast_qp_attached;
+
+extern unsigned int hfi1_max_srqs;
+
+extern unsigned int hfi1_max_srq_sges;
+
+extern unsigned int hfi1_max_srq_wrs;
+
+extern unsigned short piothreshold;
+
+extern const u32 ib_hfi1_rnr_table[];
+
+#endif                          /* HFI1_VERBS_H */
