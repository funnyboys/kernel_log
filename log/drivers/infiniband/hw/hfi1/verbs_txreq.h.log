commit 0dc63bbee0fa6da20283ae6e22e99c6fde25ed8e
Author: Kieran Bingham <kieran.bingham+renesas@ideasonboard.com>
Date:   Tue Jun 9 13:45:55 2020 +0100

    RDMA/hfi1: Fix trivial mis-spelling of 'descriptor'
    
    The word 'descriptor' is misspelled throughout the tree.
    
    Fix it up accordingly:
        decriptors -> descriptors
    
    Link: https://lore.kernel.org/r/20200609124610.3445662-3-kieran.bingham+renesas@ideasonboard.com
    Link: https://lore.kernel.org/r/20200609124610.3445662-12-kieran.bingham+renesas@ideasonboard.com
    Signed-off-by: Kieran Bingham <kieran.bingham+renesas@ideasonboard.com>
    Acked-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs_txreq.h b/drivers/infiniband/hw/hfi1/verbs_txreq.h
index bfa6e081cb56..d2d526c5a756 100644
--- a/drivers/infiniband/hw/hfi1/verbs_txreq.h
+++ b/drivers/infiniband/hw/hfi1/verbs_txreq.h
@@ -91,7 +91,7 @@ static inline struct verbs_txreq *get_txreq(struct hfi1_ibdev *dev,
 	tx->mr = NULL;
 	tx->sde = priv->s_sde;
 	tx->psc = priv->s_sendcontext;
-	/* so that we can test if the sdma decriptors are there */
+	/* so that we can test if the sdma descriptors are there */
 	tx->txreq.num_desc = 0;
 	/* Set the header type */
 	tx->phdr.hdr.hdr_type = priv->hdr_type;

commit 3230f4a8d44e4a0bb7afea814b280b5129521f52
Author: Mike Marciniszyn <mike.marciniszyn@intel.com>
Date:   Fri Jun 14 12:32:32 2019 -0400

    IB/hfi1: Silence txreq allocation warnings
    
    The following warning can happen when a memory shortage
    occurs during txreq allocation:
    
    [10220.939246] SLUB: Unable to allocate memory on node -1, gfp=0xa20(GFP_ATOMIC)
    [10220.939246] Hardware name: Intel Corporation S2600WT2R/S2600WT2R, BIOS SE5C610.86B.01.01.0018.C4.072020161249 07/20/2016
    [10220.939247]   cache: mnt_cache, object size: 384, buffer size: 384, default order: 2, min order: 0
    [10220.939260] Workqueue: hfi0_0 _hfi1_do_send [hfi1]
    [10220.939261]   node 0: slabs: 1026568, objs: 43115856, free: 0
    [10220.939262] Call Trace:
    [10220.939262]   node 1: slabs: 820872, objs: 34476624, free: 0
    [10220.939263]  dump_stack+0x5a/0x73
    [10220.939265]  warn_alloc+0x103/0x190
    [10220.939267]  ? wake_all_kswapds+0x54/0x8b
    [10220.939268]  __alloc_pages_slowpath+0x86c/0xa2e
    [10220.939270]  ? __alloc_pages_nodemask+0x2fe/0x320
    [10220.939271]  __alloc_pages_nodemask+0x2fe/0x320
    [10220.939273]  new_slab+0x475/0x550
    [10220.939275]  ___slab_alloc+0x36c/0x520
    [10220.939287]  ? hfi1_make_rc_req+0x90/0x18b0 [hfi1]
    [10220.939299]  ? __get_txreq+0x54/0x160 [hfi1]
    [10220.939310]  ? hfi1_make_rc_req+0x90/0x18b0 [hfi1]
    [10220.939312]  __slab_alloc+0x40/0x61
    [10220.939323]  ? hfi1_make_rc_req+0x90/0x18b0 [hfi1]
    [10220.939325]  kmem_cache_alloc+0x181/0x1b0
    [10220.939336]  hfi1_make_rc_req+0x90/0x18b0 [hfi1]
    [10220.939348]  ? hfi1_verbs_send_dma+0x386/0xa10 [hfi1]
    [10220.939359]  ? find_prev_entry+0xb0/0xb0 [hfi1]
    [10220.939371]  hfi1_do_send+0x1d9/0x3f0 [hfi1]
    [10220.939372]  process_one_work+0x171/0x380
    [10220.939374]  worker_thread+0x49/0x3f0
    [10220.939375]  kthread+0xf8/0x130
    [10220.939377]  ? max_active_store+0x80/0x80
    [10220.939378]  ? kthread_bind+0x10/0x10
    [10220.939379]  ret_from_fork+0x35/0x40
    [10220.939381] SLUB: Unable to allocate memory on node -1, gfp=0xa20(GFP_ATOMIC)
    
    The shortage is handled properly so the message isn't needed. Silence by
    adding the no warn option to the slab allocation.
    
    Fixes: 45842abbb292 ("staging/rdma/hfi1: move txreq header code")
    Cc: <stable@vger.kernel.org>
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs_txreq.h b/drivers/infiniband/hw/hfi1/verbs_txreq.h
index b002e96eb335..bfa6e081cb56 100644
--- a/drivers/infiniband/hw/hfi1/verbs_txreq.h
+++ b/drivers/infiniband/hw/hfi1/verbs_txreq.h
@@ -72,6 +72,7 @@ struct hfi1_ibdev;
 struct verbs_txreq *__get_txreq(struct hfi1_ibdev *dev,
 				struct rvt_qp *qp);
 
+#define VERBS_TXREQ_GFP (GFP_ATOMIC | __GFP_NOWARN)
 static inline struct verbs_txreq *get_txreq(struct hfi1_ibdev *dev,
 					    struct rvt_qp *qp)
 	__must_hold(&qp->slock)
@@ -79,7 +80,7 @@ static inline struct verbs_txreq *get_txreq(struct hfi1_ibdev *dev,
 	struct verbs_txreq *tx;
 	struct hfi1_qp_priv *priv = qp->priv;
 
-	tx = kmem_cache_alloc(dev->verbs_txreq_cache, GFP_ATOMIC);
+	tx = kmem_cache_alloc(dev->verbs_txreq_cache, VERBS_TXREQ_GFP);
 	if (unlikely(!tx)) {
 		/* call slow path to get the lock */
 		tx = __get_txreq(dev, qp);

commit 34025fb0c4c9d6b2e294f8f8f0a82491a13c83a2
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Wed Jan 23 21:52:19 2019 -0800

    IB/hfi1: Prioritize the sending of ACK packets
    
    ACK packets are generally associated with request completion and resource
    release and therefore should be sent first. This patch optimizes the
    send engine by using the following policies:
    (1) QPs with RVT_S_ACK_PENDING bit set in qp->s_flags or qpriv->s_flags
    should have their priority incremented;
    (2) QPs with ACK or TID-ACK packet queued should have their priority
    incremented;
    (3) When a QP is queued to the wait list due to resource constraints, it
    will be queued to the head if it has ACK packet to send;
    (4) When selecting qps to run from the wait list, the one with the highest
    priority and starve_cnt will be selected; each priority will be equivalent
    to a fixed number of starve_cnt (16).
    
    Reviewed-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs_txreq.h b/drivers/infiniband/hw/hfi1/verbs_txreq.h
index 2a77af26a231..b002e96eb335 100644
--- a/drivers/infiniband/hw/hfi1/verbs_txreq.h
+++ b/drivers/infiniband/hw/hfi1/verbs_txreq.h
@@ -94,6 +94,7 @@ static inline struct verbs_txreq *get_txreq(struct hfi1_ibdev *dev,
 	tx->txreq.num_desc = 0;
 	/* Set the header type */
 	tx->phdr.hdr.hdr_type = priv->hdr_type;
+	tx->txreq.flags = 0;
 	return tx;
 }
 

commit 5da0fc9dbf891a9c9e01a634f2126b5952afb3a6
Author: Dennis Dalessandro <dennis.dalessandro@intel.com>
Date:   Fri Sep 28 07:17:09 2018 -0700

    IB/hfi1: Prepare resource waits for dual leg
    
    Current implementation allows each qp to have only one send engine.  As
    such, each qp has only one list to queue prebuilt packets when send engine
    resources are not available. To improve performance, it is desired to
    support multiple send engines for each qp.
    
    This patch creates the framework to support two send engines
    (two legs) for each qp for the TID RDMA protocol, which can be easily
    extended to support more send engines. It achieves the goal by creating a
    leg specific struct, iowait_work in the iowait struct, to hold the
    work_struct and the tx_list as well as a pointer to the parent iowait
    struct.
    
    The hfi1_pkt_state now has an additional field to record the current legs
    work structure and that is now passed to all egress waiters to determine
    the leg that needs to wait via a new iowait helper.  The APIs are adjusted
    to use the new leg specific struct as required.
    
    Many new and modified helpers are added to support this change.
    
    Reviewed-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs_txreq.h b/drivers/infiniband/hw/hfi1/verbs_txreq.h
index 1c19bbc764b2..2a77af26a231 100644
--- a/drivers/infiniband/hw/hfi1/verbs_txreq.h
+++ b/drivers/infiniband/hw/hfi1/verbs_txreq.h
@@ -102,22 +102,19 @@ static inline struct sdma_txreq *get_sdma_txreq(struct verbs_txreq *tx)
 	return &tx->txreq;
 }
 
-static inline struct verbs_txreq *get_waiting_verbs_txreq(struct rvt_qp *qp)
+static inline struct verbs_txreq *get_waiting_verbs_txreq(struct iowait_work *w)
 {
 	struct sdma_txreq *stx;
-	struct hfi1_qp_priv *priv = qp->priv;
 
-	stx = iowait_get_txhead(&priv->s_iowait);
+	stx = iowait_get_txhead(w);
 	if (stx)
 		return container_of(stx, struct verbs_txreq, txreq);
 	return NULL;
 }
 
-static inline bool verbs_txreq_queued(struct rvt_qp *qp)
+static inline bool verbs_txreq_queued(struct iowait_work *w)
 {
-	struct hfi1_qp_priv *priv = qp->priv;
-
-	return iowait_packet_queued(&priv->s_iowait);
+	return iowait_packet_queued(w);
 }
 
 void hfi1_put_txreq(struct verbs_txreq *tx);

commit b697d7d8c741f27b728a878fc55852b06d0f6f5e
Author: Michael J. Ruhl <michael.j.ruhl@intel.com>
Date:   Wed Jun 20 09:29:08 2018 -0700

    IB/hfi1: Fix incorrect mixing of ERR_PTR and NULL return values
    
    The __get_txreq() function can return a pointer, ERR_PTR(-EBUSY), or NULL.
    All of the relevant call sites look for IS_ERR, so the NULL return would
    lead to a NULL pointer exception.
    
    Do not use the ERR_PTR mechanism for this function.
    
    Update all call sites to handle the return value correctly.
    
    Clean up error paths to reflect return value.
    
    Fixes: 45842abbb292 ("staging/rdma/hfi1: move txreq header code")
    Cc: <stable@vger.kernel.org> # 4.9.x+
    Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Reviewed-by: Kamenee Arumugam <kamenee.arumugam@intel.com>
    Signed-off-by: Michael J. Ruhl <michael.j.ruhl@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs_txreq.h b/drivers/infiniband/hw/hfi1/verbs_txreq.h
index 729244c3086c..1c19bbc764b2 100644
--- a/drivers/infiniband/hw/hfi1/verbs_txreq.h
+++ b/drivers/infiniband/hw/hfi1/verbs_txreq.h
@@ -1,5 +1,5 @@
 /*
- * Copyright(c) 2016 Intel Corporation.
+ * Copyright(c) 2016 - 2018 Intel Corporation.
  *
  * This file is provided under a dual BSD/GPLv2 license.  When using or
  * redistributing this file, you may do so under either license.
@@ -83,7 +83,7 @@ static inline struct verbs_txreq *get_txreq(struct hfi1_ibdev *dev,
 	if (unlikely(!tx)) {
 		/* call slow path to get the lock */
 		tx = __get_txreq(dev, qp);
-		if (IS_ERR(tx))
+		if (!tx)
 			return tx;
 	}
 	tx->qp = qp;

commit 9636258f103bac6853e280beecf9e85674736a6a
Author: Mitko Haralanov <mitko.haralanov@intel.com>
Date:   Thu Feb 1 10:46:07 2018 -0800

    IB/hfi1: Remove dependence on qp->s_hdrwords
    
    The s_hdrwords variable was used to indicate whether a
    packet was already built on a previous iteration of the
    send engine. This variable assumed the protection of the
    QP's RVT_S_BUSY flag, which was required since the the
    QP's s_lock was dropped just prior to the packet being
    queued on the one of the egress mechanisms.
    
    Support for multiple send engine instantiations require
    that the field not be used due to concurency issues.
    The ps.txreq signals the "already built" without the
    potential concurency issues.
    
    Fix by getting rid of all s_hdrword usage.   A wrapper
    is added to test for the already built case that used to
    use s_hdrwords.
    
    What used to be stored in s_hdrwords is now in the txreq.
    The PBC is not counted, but is added in the pio/sdma code
    paths prior to posting the packet.
    
    Reviewed-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs_txreq.h b/drivers/infiniband/hw/hfi1/verbs_txreq.h
index cec7a4b34d16..729244c3086c 100644
--- a/drivers/infiniband/hw/hfi1/verbs_txreq.h
+++ b/drivers/infiniband/hw/hfi1/verbs_txreq.h
@@ -113,6 +113,13 @@ static inline struct verbs_txreq *get_waiting_verbs_txreq(struct rvt_qp *qp)
 	return NULL;
 }
 
+static inline bool verbs_txreq_queued(struct rvt_qp *qp)
+{
+	struct hfi1_qp_priv *priv = qp->priv;
+
+	return iowait_packet_queued(&priv->s_iowait);
+}
+
 void hfi1_put_txreq(struct verbs_txreq *tx);
 int verbs_txreq_init(struct hfi1_ibdev *dev);
 void verbs_txreq_exit(struct hfi1_ibdev *dev);

commit a8979cc55c0034fbe129904936cfc4b5bf41e59b
Author: Kaike Wan <kaike.wan@intel.com>
Date:   Mon Oct 9 12:38:26 2017 -0700

    IB/hfi1: Set hdr_type when tx req is allocated
    
    Setting the protocol type should be part of initializing the tx request.
    For UC and RC, the current protocol type is part of the qp priv structure.
    For ud requests, it needs to be adjusted dynamically, based on the AV
    posted with the WQE. This patch will simplify the initialization of the
    tx request.
    
    Fixes: 5b6cabb0db77 ("IB/hfi1: Add 16B RC/UC support")
    Reviewed-by: Don Hiatt <don.hiatt@intel.com>
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Kaike Wan <kaike.wan@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs_txreq.h b/drivers/infiniband/hw/hfi1/verbs_txreq.h
index 76216f2ef35a..cec7a4b34d16 100644
--- a/drivers/infiniband/hw/hfi1/verbs_txreq.h
+++ b/drivers/infiniband/hw/hfi1/verbs_txreq.h
@@ -92,6 +92,8 @@ static inline struct verbs_txreq *get_txreq(struct hfi1_ibdev *dev,
 	tx->psc = priv->s_sendcontext;
 	/* so that we can test if the sdma decriptors are there */
 	tx->txreq.num_desc = 0;
+	/* Set the header type */
+	tx->phdr.hdr.hdr_type = priv->hdr_type;
 	return tx;
 }
 

commit e922ae06e90a37ab0b212f844e8aed9b6021cf21
Author: Don Hiatt <don.hiatt@intel.com>
Date:   Wed Dec 7 19:33:00 2016 -0800

    IB/hfi1: Remove dependence on qp->s_cur_size
    
    The qp->s_cur_size field assumes that the S_BUSY bit protects
    the field from modification after the slock is dropped. Scaling the
    send engine to multiple cores would break that assumption.
    
    Correct the issue by carrying the payload size in the txreq structure.
    
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs_txreq.h b/drivers/infiniband/hw/hfi1/verbs_txreq.h
index 5660897593ba..76216f2ef35a 100644
--- a/drivers/infiniband/hw/hfi1/verbs_txreq.h
+++ b/drivers/infiniband/hw/hfi1/verbs_txreq.h
@@ -65,6 +65,7 @@ struct verbs_txreq {
 	struct sdma_engine     *sde;
 	struct send_context     *psc;
 	u16                     hdr_dwords;
+	u16			s_cur_size;
 };
 
 struct hfi1_ibdev;

commit d4d602e9a3035d039befdd37df5213b430948f28
Author: Don Hiatt <don.hiatt@intel.com>
Date:   Mon Jul 25 13:40:22 2016 -0700

    IB/hfi1: Rename hfi1_pio_header to hfi1_sdma_header.
    
    hfi1_pio_header should really be called hfi1_sdma_header
    as it is only used for sdma transmits.
    
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Reviewed-by: Dean Luick <dean.luick@intel.com>
    Reviewed-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Don Hiatt <don.hiatt@intel.com>
    Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs_txreq.h b/drivers/infiniband/hw/hfi1/verbs_txreq.h
index a1d6e0807f97..5660897593ba 100644
--- a/drivers/infiniband/hw/hfi1/verbs_txreq.h
+++ b/drivers/infiniband/hw/hfi1/verbs_txreq.h
@@ -56,7 +56,7 @@
 #include "iowait.h"
 
 struct verbs_txreq {
-	struct hfi1_pio_header	phdr;
+	struct hfi1_sdma_header	phdr;
 	struct sdma_txreq       txreq;
 	struct rvt_qp           *qp;
 	struct rvt_swqe         *wqe;

commit 2aee309d3e01447c55fdf89cef05a0e2be372655
Author: Mike Marciniszyn <mike.marciniszyn@intel.com>
Date:   Fri Jun 17 19:17:49 2016 -0700

    IB/hfi1: Fix deadlock with txreq allocation slow path
    
    A failure in the get_txreq() inline will result in a
    slow path retry using __get_txreq().
    
    __get_txreq() attempts to procure the qp s_lock, which
    is already held in all callers.
    
    Fix by deleting the s_lock maintenance in __get_txreq()
    and add sparse syntax hooks to future proof the code.
    
    Cc: Stable <stable@vger.kernel.org> # 4.6+
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs_txreq.h b/drivers/infiniband/hw/hfi1/verbs_txreq.h
index 1cf69b2fe4a5..a1d6e0807f97 100644
--- a/drivers/infiniband/hw/hfi1/verbs_txreq.h
+++ b/drivers/infiniband/hw/hfi1/verbs_txreq.h
@@ -73,6 +73,7 @@ struct verbs_txreq *__get_txreq(struct hfi1_ibdev *dev,
 
 static inline struct verbs_txreq *get_txreq(struct hfi1_ibdev *dev,
 					    struct rvt_qp *qp)
+	__must_hold(&qp->slock)
 {
 	struct verbs_txreq *tx;
 	struct hfi1_qp_priv *priv = qp->priv;

commit f48ad614c100783be1e7e777dc36328001b83999
Author: Dennis Dalessandro <dennis.dalessandro@intel.com>
Date:   Thu May 19 05:26:51 2016 -0700

    IB/hfi1: Move driver out of staging
    
    The TODO list for the hfi1 driver was completed during 4.6. In addition
    other objections raised (which are far beyond what was in the TODO list)
    have been addressed as well. It is now time to remove the driver from
    staging and into the drivers/infiniband sub-tree.
    
    Reviewed-by: Jubin John <jubin.john@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

diff --git a/drivers/infiniband/hw/hfi1/verbs_txreq.h b/drivers/infiniband/hw/hfi1/verbs_txreq.h
new file mode 100644
index 000000000000..1cf69b2fe4a5
--- /dev/null
+++ b/drivers/infiniband/hw/hfi1/verbs_txreq.h
@@ -0,0 +1,116 @@
+/*
+ * Copyright(c) 2016 Intel Corporation.
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *  - Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  - Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *  - Neither the name of Intel Corporation nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ */
+
+#ifndef HFI1_VERBS_TXREQ_H
+#define HFI1_VERBS_TXREQ_H
+
+#include <linux/types.h>
+#include <linux/slab.h>
+
+#include "verbs.h"
+#include "sdma_txreq.h"
+#include "iowait.h"
+
+struct verbs_txreq {
+	struct hfi1_pio_header	phdr;
+	struct sdma_txreq       txreq;
+	struct rvt_qp           *qp;
+	struct rvt_swqe         *wqe;
+	struct rvt_mregion	*mr;
+	struct rvt_sge_state    *ss;
+	struct sdma_engine     *sde;
+	struct send_context     *psc;
+	u16                     hdr_dwords;
+};
+
+struct hfi1_ibdev;
+struct verbs_txreq *__get_txreq(struct hfi1_ibdev *dev,
+				struct rvt_qp *qp);
+
+static inline struct verbs_txreq *get_txreq(struct hfi1_ibdev *dev,
+					    struct rvt_qp *qp)
+{
+	struct verbs_txreq *tx;
+	struct hfi1_qp_priv *priv = qp->priv;
+
+	tx = kmem_cache_alloc(dev->verbs_txreq_cache, GFP_ATOMIC);
+	if (unlikely(!tx)) {
+		/* call slow path to get the lock */
+		tx = __get_txreq(dev, qp);
+		if (IS_ERR(tx))
+			return tx;
+	}
+	tx->qp = qp;
+	tx->mr = NULL;
+	tx->sde = priv->s_sde;
+	tx->psc = priv->s_sendcontext;
+	/* so that we can test if the sdma decriptors are there */
+	tx->txreq.num_desc = 0;
+	return tx;
+}
+
+static inline struct sdma_txreq *get_sdma_txreq(struct verbs_txreq *tx)
+{
+	return &tx->txreq;
+}
+
+static inline struct verbs_txreq *get_waiting_verbs_txreq(struct rvt_qp *qp)
+{
+	struct sdma_txreq *stx;
+	struct hfi1_qp_priv *priv = qp->priv;
+
+	stx = iowait_get_txhead(&priv->s_iowait);
+	if (stx)
+		return container_of(stx, struct verbs_txreq, txreq);
+	return NULL;
+}
+
+void hfi1_put_txreq(struct verbs_txreq *tx);
+int verbs_txreq_init(struct hfi1_ibdev *dev);
+void verbs_txreq_exit(struct hfi1_ibdev *dev);
+
+#endif                         /* HFI1_VERBS_TXREQ_H */
