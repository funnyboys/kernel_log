commit 0102e4efda76d0721bc744dd80258eb6cfa25fc3
Author: Yan Yankovskyi <yyankovskyi@gmail.com>
Date:   Mon Mar 23 18:15:11 2020 +0200

    xen: Use evtchn_type_t as a type for event channels
    
    Make event channel functions pass event channel port using
    evtchn_port_t type. It eliminates signed <-> unsigned conversion.
    
    Signed-off-by: Yan Yankovskyi <yyankovskyi@gmail.com>
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Link: https://lore.kernel.org/r/20200323152343.GA28422@kbp1-lhp-F74019
    Signed-off-by: Juergen Gross <jgross@suse.com>

diff --git a/drivers/xen/gntdev-common.h b/drivers/xen/gntdev-common.h
index 9a3960ecff6c..20d7d059dadb 100644
--- a/drivers/xen/gntdev-common.h
+++ b/drivers/xen/gntdev-common.h
@@ -15,6 +15,7 @@
 #include <linux/mman.h>
 #include <linux/mmu_notifier.h>
 #include <linux/types.h>
+#include <xen/interface/event_channel.h>
 
 struct gntdev_dmabuf_priv;
 
@@ -38,7 +39,7 @@ struct gntdev_unmap_notify {
 	int flags;
 	/* Address relative to the start of the gntdev_grant_map. */
 	int addr;
-	int event;
+	evtchn_port_t event;
 };
 
 struct gntdev_grant_map {

commit 3b06ac6707c196b5036fe013c460da86c9060085
Author: Juergen Gross <jgross@suse.com>
Date:   Thu Nov 7 12:15:45 2019 +0100

    xen/gntdev: replace global limit of mapped pages by limit per call
    
    Today there is a global limit of pages mapped via /dev/xen/gntdev set
    to 1 million pages per default. There is no reason why that limit is
    existing, as total number of grant mappings is limited by the
    hypervisor anyway and preferring kernel mappings over userspace ones
    doesn't make sense. It should be noted that the gntdev device is
    usable by root only.
    
    Additionally checking of that limit is fragile, as the number of pages
    to map via one call is specified in a 32-bit unsigned variable which
    isn't tested to stay within reasonable limits (the only test is the
    value to be <= zero, which basically excludes only calls without any
    mapping requested). So trying to map e.g. 0xffff0000 pages while
    already nearly 1000000 pages are mapped will effectively lower the
    global number of mapped pages such that a parallel call mapping a
    reasonable amount of pages can succeed in spite of the global limit
    being violated.
    
    So drop the global limit and introduce per call limit instead. This
    per call limit (default: 65536 grant mappings) protects against
    allocating insane large arrays in the kernel for doing a hypercall
    which will fail anyway in case a user is e.g. trying to map billions
    of pages.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Reviewed-by: Oleksandr Andrushchenko <oleksandr_andrushchenko@epam.com>
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Signed-off-by: Juergen Gross <jgross@suse.com>

diff --git a/drivers/xen/gntdev-common.h b/drivers/xen/gntdev-common.h
index 91e44c04f787..9a3960ecff6c 100644
--- a/drivers/xen/gntdev-common.h
+++ b/drivers/xen/gntdev-common.h
@@ -81,7 +81,7 @@ void gntdev_add_map(struct gntdev_priv *priv, struct gntdev_grant_map *add);
 
 void gntdev_put_map(struct gntdev_priv *priv, struct gntdev_grant_map *map);
 
-bool gntdev_account_mapped_pages(int count);
+bool gntdev_test_page_count(unsigned int count);
 
 int gntdev_map_grant_pages(struct gntdev_grant_map *map);
 

commit d3eeb1d77c5d0af9df442db63722928238310a86
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Tue Nov 12 16:22:31 2019 -0400

    xen/gntdev: use mmu_interval_notifier_insert
    
    gntdev simply wants to monitor a specific VMA for any notifier events,
    this can be done straightforwardly using mmu_interval_notifier_insert()
    over the VMA's VA range.
    
    The notifier should be attached until the original VMA is destroyed.
    
    It is unclear if any of this is even sane, but at least a lot of duplicate
    code is removed.
    
    Link: https://lore.kernel.org/r/20191112202231.3856-15-jgg@ziepe.ca
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

diff --git a/drivers/xen/gntdev-common.h b/drivers/xen/gntdev-common.h
index 2f8b949c3eeb..91e44c04f787 100644
--- a/drivers/xen/gntdev-common.h
+++ b/drivers/xen/gntdev-common.h
@@ -21,15 +21,8 @@ struct gntdev_dmabuf_priv;
 struct gntdev_priv {
 	/* Maps with visible offsets in the file descriptor. */
 	struct list_head maps;
-	/*
-	 * Maps that are not visible; will be freed on munmap.
-	 * Only populated if populate_freeable_maps == 1
-	 */
-	struct list_head freeable_maps;
 	/* lock protects maps and freeable_maps. */
 	struct mutex lock;
-	struct mm_struct *mm;
-	struct mmu_notifier mn;
 
 #ifdef CONFIG_XEN_GRANT_DMA_ALLOC
 	/* Device for which DMA memory is allocated. */
@@ -49,6 +42,7 @@ struct gntdev_unmap_notify {
 };
 
 struct gntdev_grant_map {
+	struct mmu_interval_notifier notifier;
 	struct list_head next;
 	struct vm_area_struct *vma;
 	int index;

commit 932d6562179efe8e2460a0343dbe0fcacf288a9e
Author: Oleksandr Andrushchenko <oleksandr_andrushchenko@epam.com>
Date:   Fri Jul 20 12:01:48 2018 +0300

    xen/gntdev: Add initial support for dma-buf UAPI
    
    Add UAPI and IOCTLs for dma-buf grant device driver extension:
    the extension allows userspace processes and kernel modules to
    use Xen backed dma-buf implementation. With this extension grant
    references to the pages of an imported dma-buf can be exported
    for other domain use and grant references coming from a foreign
    domain can be converted into a local dma-buf for local export.
    Implement basic initialization and stubs for Xen DMA buffers'
    support.
    
    Signed-off-by: Oleksandr Andrushchenko <oleksandr_andrushchenko@epam.com>
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Signed-off-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>

diff --git a/drivers/xen/gntdev-common.h b/drivers/xen/gntdev-common.h
index 2346c198f72e..2f8b949c3eeb 100644
--- a/drivers/xen/gntdev-common.h
+++ b/drivers/xen/gntdev-common.h
@@ -16,6 +16,8 @@
 #include <linux/mmu_notifier.h>
 #include <linux/types.h>
 
+struct gntdev_dmabuf_priv;
+
 struct gntdev_priv {
 	/* Maps with visible offsets in the file descriptor. */
 	struct list_head maps;
@@ -33,6 +35,10 @@ struct gntdev_priv {
 	/* Device for which DMA memory is allocated. */
 	struct device *dma_dev;
 #endif
+
+#ifdef CONFIG_XEN_GNTDEV_DMABUF
+	struct gntdev_dmabuf_priv *dmabuf_priv;
+#endif
 };
 
 struct gntdev_unmap_notify {

commit 1d314567553883d9f606cc59e8e66f465a4b6ccd
Author: Oleksandr Andrushchenko <oleksandr_andrushchenko@epam.com>
Date:   Fri Jul 20 12:01:47 2018 +0300

    xen/gntdev: Make private routines/structures accessible
    
    This is in preparation for adding support of DMA buffer
    functionality: make map/unmap related code and structures, used
    privately by gntdev, ready for dma-buf extension, which will re-use
    these. Rename corresponding structures as those become non-private
    to gntdev now.
    
    Signed-off-by: Oleksandr Andrushchenko <oleksandr_andrushchenko@epam.com>
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Signed-off-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>

diff --git a/drivers/xen/gntdev-common.h b/drivers/xen/gntdev-common.h
new file mode 100644
index 000000000000..2346c198f72e
--- /dev/null
+++ b/drivers/xen/gntdev-common.h
@@ -0,0 +1,88 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+
+/*
+ * Common functionality of grant device.
+ *
+ * Copyright (c) 2006-2007, D G Murray.
+ *           (c) 2009 Gerd Hoffmann <kraxel@redhat.com>
+ *           (c) 2018 Oleksandr Andrushchenko, EPAM Systems Inc.
+ */
+
+#ifndef _GNTDEV_COMMON_H
+#define _GNTDEV_COMMON_H
+
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/mmu_notifier.h>
+#include <linux/types.h>
+
+struct gntdev_priv {
+	/* Maps with visible offsets in the file descriptor. */
+	struct list_head maps;
+	/*
+	 * Maps that are not visible; will be freed on munmap.
+	 * Only populated if populate_freeable_maps == 1
+	 */
+	struct list_head freeable_maps;
+	/* lock protects maps and freeable_maps. */
+	struct mutex lock;
+	struct mm_struct *mm;
+	struct mmu_notifier mn;
+
+#ifdef CONFIG_XEN_GRANT_DMA_ALLOC
+	/* Device for which DMA memory is allocated. */
+	struct device *dma_dev;
+#endif
+};
+
+struct gntdev_unmap_notify {
+	int flags;
+	/* Address relative to the start of the gntdev_grant_map. */
+	int addr;
+	int event;
+};
+
+struct gntdev_grant_map {
+	struct list_head next;
+	struct vm_area_struct *vma;
+	int index;
+	int count;
+	int flags;
+	refcount_t users;
+	struct gntdev_unmap_notify notify;
+	struct ioctl_gntdev_grant_ref *grants;
+	struct gnttab_map_grant_ref   *map_ops;
+	struct gnttab_unmap_grant_ref *unmap_ops;
+	struct gnttab_map_grant_ref   *kmap_ops;
+	struct gnttab_unmap_grant_ref *kunmap_ops;
+	struct page **pages;
+	unsigned long pages_vm_start;
+
+#ifdef CONFIG_XEN_GRANT_DMA_ALLOC
+	/*
+	 * If dmabuf_vaddr is not NULL then this mapping is backed by DMA
+	 * capable memory.
+	 */
+
+	struct device *dma_dev;
+	/* Flags used to create this DMA buffer: GNTDEV_DMA_FLAG_XXX. */
+	int dma_flags;
+	void *dma_vaddr;
+	dma_addr_t dma_bus_addr;
+	/* Needed to avoid allocation in gnttab_dma_free_pages(). */
+	xen_pfn_t *frames;
+#endif
+};
+
+struct gntdev_grant_map *gntdev_alloc_map(struct gntdev_priv *priv, int count,
+					  int dma_flags);
+
+void gntdev_add_map(struct gntdev_priv *priv, struct gntdev_grant_map *add);
+
+void gntdev_put_map(struct gntdev_priv *priv, struct gntdev_grant_map *map);
+
+bool gntdev_account_mapped_pages(int count);
+
+int gntdev_map_grant_pages(struct gntdev_grant_map *map);
+
+#endif
