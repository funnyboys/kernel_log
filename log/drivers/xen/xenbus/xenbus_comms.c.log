commit 8130b9d5b5abf26f9927b487c15319a187775f34
Author: Dongli Zhang <dongli.zhang@oracle.com>
Date:   Tue Mar 3 14:14:23 2020 -0800

    xenbus: req->err should be updated before req->state
    
    This patch adds the barrier to guarantee that req->err is always updated
    before req->state.
    
    Otherwise, read_reply() would not return ERR_PTR(req->err) but
    req->body, when process_writes()->xb_write() is failed.
    
    Signed-off-by: Dongli Zhang <dongli.zhang@oracle.com>
    Link: https://lore.kernel.org/r/20200303221423.21962-2-dongli.zhang@oracle.com
    Reviewed-by: Julien Grall <jgrall@amazon.com>
    Signed-off-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>

diff --git a/drivers/xen/xenbus/xenbus_comms.c b/drivers/xen/xenbus/xenbus_comms.c
index 852ed161fc2a..eb5151fc8efa 100644
--- a/drivers/xen/xenbus/xenbus_comms.c
+++ b/drivers/xen/xenbus/xenbus_comms.c
@@ -397,6 +397,8 @@ static int process_writes(void)
 	if (state.req->state == xb_req_state_aborted)
 		kfree(state.req);
 	else {
+		/* write err, then update state */
+		virt_wmb();
 		state.req->state = xb_req_state_got_reply;
 		wake_up(&state.req->wq);
 	}

commit 1b6a51e86cce38cf4d48ce9c242120283ae2f603
Author: Dongli Zhang <dongli.zhang@oracle.com>
Date:   Tue Mar 3 14:14:22 2020 -0800

    xenbus: req->body should be updated before req->state
    
    The req->body should be updated before req->state is updated and the
    order should be guaranteed by a barrier.
    
    Otherwise, read_reply() might return req->body = NULL.
    
    Below is sample callstack when the issue is reproduced on purpose by
    reordering the updates of req->body and req->state and adding delay in
    code between updates of req->state and req->body.
    
    [   22.356105] general protection fault: 0000 [#1] SMP PTI
    [   22.361185] CPU: 2 PID: 52 Comm: xenwatch Not tainted 5.5.0xen+ #6
    [   22.366727] Hardware name: Xen HVM domU, BIOS ...
    [   22.372245] RIP: 0010:_parse_integer_fixup_radix+0x6/0x60
    ... ...
    [   22.392163] RSP: 0018:ffffb2d64023fdf0 EFLAGS: 00010246
    [   22.395933] RAX: 0000000000000000 RBX: 75746e7562755f6d RCX: 0000000000000000
    [   22.400871] RDX: 0000000000000000 RSI: ffffb2d64023fdfc RDI: 75746e7562755f6d
    [   22.405874] RBP: 0000000000000000 R08: 00000000000001e8 R09: 0000000000cdcdcd
    [   22.410945] R10: ffffb2d6402ffe00 R11: ffff9d95395eaeb0 R12: ffff9d9535935000
    [   22.417613] R13: ffff9d9526d4a000 R14: ffff9d9526f4f340 R15: ffff9d9537654000
    [   22.423726] FS:  0000000000000000(0000) GS:ffff9d953bc80000(0000) knlGS:0000000000000000
    [   22.429898] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [   22.434342] CR2: 000000c4206a9000 CR3: 00000001ea3fc002 CR4: 00000000001606e0
    [   22.439645] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [   22.444941] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [   22.450342] Call Trace:
    [   22.452509]  simple_strtoull+0x27/0x70
    [   22.455572]  xenbus_transaction_start+0x31/0x50
    [   22.459104]  netback_changed+0x76c/0xcc1 [xen_netfront]
    [   22.463279]  ? find_watch+0x40/0x40
    [   22.466156]  xenwatch_thread+0xb4/0x150
    [   22.469309]  ? wait_woken+0x80/0x80
    [   22.472198]  kthread+0x10e/0x130
    [   22.474925]  ? kthread_park+0x80/0x80
    [   22.477946]  ret_from_fork+0x35/0x40
    [   22.480968] Modules linked in: xen_kbdfront xen_fbfront(+) xen_netfront xen_blkfront
    [   22.486783] ---[ end trace a9222030a747c3f7 ]---
    [   22.490424] RIP: 0010:_parse_integer_fixup_radix+0x6/0x60
    
    The virt_rmb() is added in the 'true' path of test_reply(). The "while"
    is changed to "do while" so that test_reply() is used as a read memory
    barrier.
    
    Signed-off-by: Dongli Zhang <dongli.zhang@oracle.com>
    Link: https://lore.kernel.org/r/20200303221423.21962-1-dongli.zhang@oracle.com
    Reviewed-by: Julien Grall <jgrall@amazon.com>
    Signed-off-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>

diff --git a/drivers/xen/xenbus/xenbus_comms.c b/drivers/xen/xenbus/xenbus_comms.c
index d239fc3c5e3d..852ed161fc2a 100644
--- a/drivers/xen/xenbus/xenbus_comms.c
+++ b/drivers/xen/xenbus/xenbus_comms.c
@@ -313,6 +313,8 @@ static int process_msg(void)
 			req->msg.type = state.msg.type;
 			req->msg.len = state.msg.len;
 			req->body = state.body;
+			/* write body, then update state */
+			virt_wmb();
 			req->state = xb_req_state_got_reply;
 			req->cb(req);
 		} else

commit 29fee6eed2811ff1089b30fc579a2d19d78016ab
Author: Joao Martins <joao.m.martins@oracle.com>
Date:   Fri Feb 2 17:42:33 2018 +0000

    xenbus: track caller request id
    
    Commit fd8aa9095a95 ("xen: optimize xenbus driver for multiple concurrent
    xenstore accesses") optimized xenbus concurrent accesses but in doing so
    broke UABI of /dev/xen/xenbus. Through /dev/xen/xenbus applications are in
    charge of xenbus message exchange with the correct header and body. Now,
    after the mentioned commit the replies received by application will no
    longer have the header req_id echoed back as it was on request (see
    specification below for reference), because that particular field is being
    overwritten by kernel.
    
    struct xsd_sockmsg
    {
      uint32_t type;  /* XS_??? */
      uint32_t req_id;/* Request identifier, echoed in daemon's response.  */
      uint32_t tx_id; /* Transaction id (0 if not related to a transaction). */
      uint32_t len;   /* Length of data following this. */
    
      /* Generally followed by nul-terminated string(s). */
    };
    
    Before there was only one request at a time so req_id could simply be
    forwarded back and forth. To allow simultaneous requests we need a
    different req_id for each message thus kernel keeps a monotonic increasing
    counter for this field and is written on every request irrespective of
    userspace value.
    
    Forwarding again the req_id on userspace requests is not a solution because
    we would open the possibility of userspace-generated req_id colliding with
    kernel ones. So this patch instead takes another route which is to
    artificially keep user req_id while keeping the xenbus logic as is. We do
    that by saving the original req_id before xs_send(), use the private kernel
    counter as req_id and then once reply comes and was validated, we restore
    back the original req_id.
    
    Cc: <stable@vger.kernel.org> # 4.11
    Fixes: fd8aa9095a ("xen: optimize xenbus driver for multiple concurrent xenstore accesses")
    Reported-by: Bhavesh Davda <bhavesh.davda@oracle.com>
    Signed-off-by: Joao Martins <joao.m.martins@oracle.com>
    Reviewed-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Juergen Gross <jgross@suse.com>

diff --git a/drivers/xen/xenbus/xenbus_comms.c b/drivers/xen/xenbus/xenbus_comms.c
index 5b081a01779d..d239fc3c5e3d 100644
--- a/drivers/xen/xenbus/xenbus_comms.c
+++ b/drivers/xen/xenbus/xenbus_comms.c
@@ -309,6 +309,7 @@ static int process_msg(void)
 			goto out;
 
 		if (req->state == xb_req_state_wait_reply) {
+			req->msg.req_id = req->caller_req_id;
 			req->msg.type = state.msg.type;
 			req->msg.len = state.msg.len;
 			req->body = state.body;

commit 1a3fc2c402810bf336882e695abd1678dbc8d279
Author: Juergen Gross <jgross@suse.com>
Date:   Thu Jun 8 16:03:42 2017 +0200

    xen: avoid deadlock in xenbus driver
    
    There has been a report about a deadlock in the xenbus driver:
    
    [  247.979498] ======================================================
    [  247.985688] WARNING: possible circular locking dependency detected
    [  247.991882] 4.12.0-rc4-00022-gc4b25c0 #575 Not tainted
    [  247.997040] ------------------------------------------------------
    [  248.003232] xenbus/91 is trying to acquire lock:
    [  248.007875]  (&u->msgbuffer_mutex){+.+.+.}, at: [<ffff00000863e904>]
    xenbus_dev_queue_reply+0x3c/0x230
    [  248.017163]
    [  248.017163] but task is already holding lock:
    [  248.023096]  (xb_write_mutex){+.+...}, at: [<ffff00000863a940>]
    xenbus_thread+0x5f0/0x798
    [  248.031267]
    [  248.031267] which lock already depends on the new lock.
    [  248.031267]
    [  248.039615]
    [  248.039615] the existing dependency chain (in reverse order) is:
    [  248.047176]
    [  248.047176] -> #1 (xb_write_mutex){+.+...}:
    [  248.052943]        __lock_acquire+0x1728/0x1778
    [  248.057498]        lock_acquire+0xc4/0x288
    [  248.061630]        __mutex_lock+0x84/0x868
    [  248.065755]        mutex_lock_nested+0x3c/0x50
    [  248.070227]        xs_send+0x164/0x1f8
    [  248.074015]        xenbus_dev_request_and_reply+0x6c/0x88
    [  248.079427]        xenbus_file_write+0x260/0x420
    [  248.084073]        __vfs_write+0x48/0x138
    [  248.088113]        vfs_write+0xa8/0x1b8
    [  248.091983]        SyS_write+0x54/0xb0
    [  248.095768]        el0_svc_naked+0x24/0x28
    [  248.099897]
    [  248.099897] -> #0 (&u->msgbuffer_mutex){+.+.+.}:
    [  248.106088]        print_circular_bug+0x80/0x2e0
    [  248.110730]        __lock_acquire+0x1768/0x1778
    [  248.115288]        lock_acquire+0xc4/0x288
    [  248.119417]        __mutex_lock+0x84/0x868
    [  248.123545]        mutex_lock_nested+0x3c/0x50
    [  248.128016]        xenbus_dev_queue_reply+0x3c/0x230
    [  248.133005]        xenbus_thread+0x788/0x798
    [  248.137306]        kthread+0x110/0x140
    [  248.141087]        ret_from_fork+0x10/0x40
    
    It is rather easy to avoid by dropping xb_write_mutex before calling
    xenbus_dev_queue_reply().
    
    Fixes: fd8aa9095a95c02dcc35540a263267c29b8fda9d ("xen: optimize xenbus
    driver for multiple concurrent xenstore accesses").
    
    Cc: <stable@vger.kernel.org> # 4.11
    Reported-by: Andre Przywara <andre.przywara@arm.com>
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Tested-by: Andre Przywara <andre.przywara@arm.com>
    Signed-off-by: Juergen Gross <jgross@suse.com>

diff --git a/drivers/xen/xenbus/xenbus_comms.c b/drivers/xen/xenbus/xenbus_comms.c
index 856ada5d39c9..5b081a01779d 100644
--- a/drivers/xen/xenbus/xenbus_comms.c
+++ b/drivers/xen/xenbus/xenbus_comms.c
@@ -299,17 +299,7 @@ static int process_msg(void)
 		mutex_lock(&xb_write_mutex);
 		list_for_each_entry(req, &xs_reply_list, list) {
 			if (req->msg.req_id == state.msg.req_id) {
-				if (req->state == xb_req_state_wait_reply) {
-					req->msg.type = state.msg.type;
-					req->msg.len = state.msg.len;
-					req->body = state.body;
-					req->state = xb_req_state_got_reply;
-					list_del(&req->list);
-					req->cb(req);
-				} else {
-					list_del(&req->list);
-					kfree(req);
-				}
+				list_del(&req->list);
 				err = 0;
 				break;
 			}
@@ -317,6 +307,15 @@ static int process_msg(void)
 		mutex_unlock(&xb_write_mutex);
 		if (err)
 			goto out;
+
+		if (req->state == xb_req_state_wait_reply) {
+			req->msg.type = state.msg.type;
+			req->msg.len = state.msg.len;
+			req->body = state.body;
+			req->state = xb_req_state_got_reply;
+			req->cb(req);
+		} else
+			kfree(req);
 	}
 
 	mutex_unlock(&xs_response_mutex);

commit fd8aa9095a95c02dcc35540a263267c29b8fda9d
Author: Juergen Gross <jgross@suse.com>
Date:   Thu Feb 9 14:39:58 2017 +0100

    xen: optimize xenbus driver for multiple concurrent xenstore accesses
    
    Handling of multiple concurrent Xenstore accesses through xenbus driver
    either from the kernel or user land is rather lame today: xenbus is
    capable to have one access active only at one point of time.
    
    Rewrite xenbus to handle multiple requests concurrently by making use
    of the request id of the Xenstore protocol. This requires to:
    
    - Instead of blocking inside xb_read() when trying to read data from
      the xenstore ring buffer do so only in the main loop of
      xenbus_thread().
    
    - Instead of doing writes to the xenstore ring buffer in the context of
      the caller just queue the request and do the write in the dedicated
      xenbus thread.
    
    - Instead of just forwarding the request id specified by the caller of
      xenbus to xenstore use a xenbus internal unique request id. This will
      allow multiple outstanding requests.
    
    - Modify the locking scheme in order to allow multiple requests being
      active in parallel.
    
    - Instead of waiting for the reply of a user's xenstore request after
      writing the request to the xenstore ring buffer return directly to
      the caller and do the waiting in the read path.
    
    Additionally signal handling was optimized by avoiding waking up the
    xenbus thread or sending an event to Xenstore in case the addressed
    entity is known to be running already.
    
    As a result communication with Xenstore is sped up by a factor of up
    to 5: depending on the request type (read or write) and the amount of
    data transferred the gain was at least 20% (small reads) and went up to
    a factor of 5 for large writes.
    
    In the end some more rough edges of xenbus have been smoothed:
    
    - Handling of memory shortage when reading from xenstore ring buffer in
      the xenbus driver was not optimal: it was busy looping and issuing a
      warning in each loop.
    
    - In case of xenstore not running in dom0 but in a stubdom we end up
      with two xenbus threads running as the initialization of xenbus in
      dom0 expecting a local xenstored will be redone later when connecting
      to the xenstore domain. Up to now this was no problem as locking
      would prevent the two xenbus threads interfering with each other, but
      this was just a waste of kernel resources.
    
    - An out of memory situation while writing to or reading from the
      xenstore ring buffer no longer will lead to a possible loss of
      synchronization with xenstore.
    
    - The user read and write part are now interruptible by signals.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>

diff --git a/drivers/xen/xenbus/xenbus_comms.c b/drivers/xen/xenbus/xenbus_comms.c
index c21ec02643e1..856ada5d39c9 100644
--- a/drivers/xen/xenbus/xenbus_comms.c
+++ b/drivers/xen/xenbus/xenbus_comms.c
@@ -34,6 +34,7 @@
 
 #include <linux/wait.h>
 #include <linux/interrupt.h>
+#include <linux/kthread.h>
 #include <linux/sched.h>
 #include <linux/err.h>
 #include <xen/xenbus.h>
@@ -42,11 +43,22 @@
 #include <xen/page.h>
 #include "xenbus.h"
 
+/* A list of replies. Currently only one will ever be outstanding. */
+LIST_HEAD(xs_reply_list);
+
+/* A list of write requests. */
+LIST_HEAD(xb_write_list);
+DECLARE_WAIT_QUEUE_HEAD(xb_waitq);
+DEFINE_MUTEX(xb_write_mutex);
+
+/* Protect xenbus reader thread against save/restore. */
+DEFINE_MUTEX(xs_response_mutex);
+
 static int xenbus_irq;
+static struct task_struct *xenbus_task;
 
 static DECLARE_WORK(probe_work, xenbus_probe);
 
-static DECLARE_WAIT_QUEUE_HEAD(xb_waitq);
 
 static irqreturn_t wake_waiting(int irq, void *unused)
 {
@@ -84,30 +96,31 @@ static const void *get_input_chunk(XENSTORE_RING_IDX cons,
 	return buf + MASK_XENSTORE_IDX(cons);
 }
 
+static int xb_data_to_write(void)
+{
+	struct xenstore_domain_interface *intf = xen_store_interface;
+
+	return (intf->req_prod - intf->req_cons) != XENSTORE_RING_SIZE &&
+		!list_empty(&xb_write_list);
+}
+
 /**
  * xb_write - low level write
  * @data: buffer to send
  * @len: length of buffer
  *
- * Returns 0 on success, error otherwise.
+ * Returns number of bytes written or -err.
  */
-int xb_write(const void *data, unsigned len)
+static int xb_write(const void *data, unsigned int len)
 {
 	struct xenstore_domain_interface *intf = xen_store_interface;
 	XENSTORE_RING_IDX cons, prod;
-	int rc;
+	unsigned int bytes = 0;
 
 	while (len != 0) {
 		void *dst;
 		unsigned int avail;
 
-		rc = wait_event_interruptible(
-			xb_waitq,
-			(intf->req_prod - intf->req_cons) !=
-			XENSTORE_RING_SIZE);
-		if (rc < 0)
-			return rc;
-
 		/* Read indexes, then verify. */
 		cons = intf->req_cons;
 		prod = intf->req_prod;
@@ -115,6 +128,11 @@ int xb_write(const void *data, unsigned len)
 			intf->req_cons = intf->req_prod = 0;
 			return -EIO;
 		}
+		if (!xb_data_to_write())
+			return bytes;
+
+		/* Must write data /after/ reading the consumer index. */
+		virt_mb();
 
 		dst = get_output_chunk(cons, prod, intf->req, &avail);
 		if (avail == 0)
@@ -122,52 +140,45 @@ int xb_write(const void *data, unsigned len)
 		if (avail > len)
 			avail = len;
 
-		/* Must write data /after/ reading the consumer index. */
-		virt_mb();
-
 		memcpy(dst, data, avail);
 		data += avail;
 		len -= avail;
+		bytes += avail;
 
 		/* Other side must not see new producer until data is there. */
 		virt_wmb();
 		intf->req_prod += avail;
 
 		/* Implies mb(): other side will see the updated producer. */
-		notify_remote_via_evtchn(xen_store_evtchn);
+		if (prod <= intf->req_cons)
+			notify_remote_via_evtchn(xen_store_evtchn);
 	}
 
-	return 0;
+	return bytes;
 }
 
-int xb_data_to_read(void)
+static int xb_data_to_read(void)
 {
 	struct xenstore_domain_interface *intf = xen_store_interface;
 	return (intf->rsp_cons != intf->rsp_prod);
 }
 
-int xb_wait_for_data_to_read(void)
-{
-	return wait_event_interruptible(xb_waitq, xb_data_to_read());
-}
-
-int xb_read(void *data, unsigned len)
+static int xb_read(void *data, unsigned int len)
 {
 	struct xenstore_domain_interface *intf = xen_store_interface;
 	XENSTORE_RING_IDX cons, prod;
-	int rc;
+	unsigned int bytes = 0;
 
 	while (len != 0) {
 		unsigned int avail;
 		const char *src;
 
-		rc = xb_wait_for_data_to_read();
-		if (rc < 0)
-			return rc;
-
 		/* Read indexes, then verify. */
 		cons = intf->rsp_cons;
 		prod = intf->rsp_prod;
+		if (cons == prod)
+			return bytes;
+
 		if (!check_indexes(cons, prod)) {
 			intf->rsp_cons = intf->rsp_prod = 0;
 			return -EIO;
@@ -185,17 +196,243 @@ int xb_read(void *data, unsigned len)
 		memcpy(data, src, avail);
 		data += avail;
 		len -= avail;
+		bytes += avail;
 
 		/* Other side must not see free space until we've copied out */
 		virt_mb();
 		intf->rsp_cons += avail;
 
-		pr_debug("Finished read of %i bytes (%i to go)\n", avail, len);
-
 		/* Implies mb(): other side will see the updated consumer. */
-		notify_remote_via_evtchn(xen_store_evtchn);
+		if (intf->rsp_prod - cons >= XENSTORE_RING_SIZE)
+			notify_remote_via_evtchn(xen_store_evtchn);
+	}
+
+	return bytes;
+}
+
+static int process_msg(void)
+{
+	static struct {
+		struct xsd_sockmsg msg;
+		char *body;
+		union {
+			void *alloc;
+			struct xs_watch_event *watch;
+		};
+		bool in_msg;
+		bool in_hdr;
+		unsigned int read;
+	} state;
+	struct xb_req_data *req;
+	int err;
+	unsigned int len;
+
+	if (!state.in_msg) {
+		state.in_msg = true;
+		state.in_hdr = true;
+		state.read = 0;
+
+		/*
+		 * We must disallow save/restore while reading a message.
+		 * A partial read across s/r leaves us out of sync with
+		 * xenstored.
+		 * xs_response_mutex is locked as long as we are processing one
+		 * message. state.in_msg will be true as long as we are holding
+		 * the lock here.
+		 */
+		mutex_lock(&xs_response_mutex);
+
+		if (!xb_data_to_read()) {
+			/* We raced with save/restore: pending data 'gone'. */
+			mutex_unlock(&xs_response_mutex);
+			state.in_msg = false;
+			return 0;
+		}
+	}
+
+	if (state.in_hdr) {
+		if (state.read != sizeof(state.msg)) {
+			err = xb_read((void *)&state.msg + state.read,
+				      sizeof(state.msg) - state.read);
+			if (err < 0)
+				goto out;
+			state.read += err;
+			if (state.read != sizeof(state.msg))
+				return 0;
+			if (state.msg.len > XENSTORE_PAYLOAD_MAX) {
+				err = -EINVAL;
+				goto out;
+			}
+		}
+
+		len = state.msg.len + 1;
+		if (state.msg.type == XS_WATCH_EVENT)
+			len += sizeof(*state.watch);
+
+		state.alloc = kmalloc(len, GFP_NOIO | __GFP_HIGH);
+		if (!state.alloc)
+			return -ENOMEM;
+
+		if (state.msg.type == XS_WATCH_EVENT)
+			state.body = state.watch->body;
+		else
+			state.body = state.alloc;
+		state.in_hdr = false;
+		state.read = 0;
+	}
+
+	err = xb_read(state.body + state.read, state.msg.len - state.read);
+	if (err < 0)
+		goto out;
+
+	state.read += err;
+	if (state.read != state.msg.len)
+		return 0;
+
+	state.body[state.msg.len] = '\0';
+
+	if (state.msg.type == XS_WATCH_EVENT) {
+		state.watch->len = state.msg.len;
+		err = xs_watch_msg(state.watch);
+	} else {
+		err = -ENOENT;
+		mutex_lock(&xb_write_mutex);
+		list_for_each_entry(req, &xs_reply_list, list) {
+			if (req->msg.req_id == state.msg.req_id) {
+				if (req->state == xb_req_state_wait_reply) {
+					req->msg.type = state.msg.type;
+					req->msg.len = state.msg.len;
+					req->body = state.body;
+					req->state = xb_req_state_got_reply;
+					list_del(&req->list);
+					req->cb(req);
+				} else {
+					list_del(&req->list);
+					kfree(req);
+				}
+				err = 0;
+				break;
+			}
+		}
+		mutex_unlock(&xb_write_mutex);
+		if (err)
+			goto out;
 	}
 
+	mutex_unlock(&xs_response_mutex);
+
+	state.in_msg = false;
+	state.alloc = NULL;
+	return err;
+
+ out:
+	mutex_unlock(&xs_response_mutex);
+	state.in_msg = false;
+	kfree(state.alloc);
+	state.alloc = NULL;
+	return err;
+}
+
+static int process_writes(void)
+{
+	static struct {
+		struct xb_req_data *req;
+		int idx;
+		unsigned int written;
+	} state;
+	void *base;
+	unsigned int len;
+	int err = 0;
+
+	if (!xb_data_to_write())
+		return 0;
+
+	mutex_lock(&xb_write_mutex);
+
+	if (!state.req) {
+		state.req = list_first_entry(&xb_write_list,
+					     struct xb_req_data, list);
+		state.idx = -1;
+		state.written = 0;
+	}
+
+	if (state.req->state == xb_req_state_aborted)
+		goto out_err;
+
+	while (state.idx < state.req->num_vecs) {
+		if (state.idx < 0) {
+			base = &state.req->msg;
+			len = sizeof(state.req->msg);
+		} else {
+			base = state.req->vec[state.idx].iov_base;
+			len = state.req->vec[state.idx].iov_len;
+		}
+		err = xb_write(base + state.written, len - state.written);
+		if (err < 0)
+			goto out_err;
+		state.written += err;
+		if (state.written != len)
+			goto out;
+
+		state.idx++;
+		state.written = 0;
+	}
+
+	list_del(&state.req->list);
+	state.req->state = xb_req_state_wait_reply;
+	list_add_tail(&state.req->list, &xs_reply_list);
+	state.req = NULL;
+
+ out:
+	mutex_unlock(&xb_write_mutex);
+
+	return 0;
+
+ out_err:
+	state.req->msg.type = XS_ERROR;
+	state.req->err = err;
+	list_del(&state.req->list);
+	if (state.req->state == xb_req_state_aborted)
+		kfree(state.req);
+	else {
+		state.req->state = xb_req_state_got_reply;
+		wake_up(&state.req->wq);
+	}
+
+	mutex_unlock(&xb_write_mutex);
+
+	state.req = NULL;
+
+	return err;
+}
+
+static int xb_thread_work(void)
+{
+	return xb_data_to_read() || xb_data_to_write();
+}
+
+static int xenbus_thread(void *unused)
+{
+	int err;
+
+	while (!kthread_should_stop()) {
+		if (wait_event_interruptible(xb_waitq, xb_thread_work()))
+			continue;
+
+		err = process_msg();
+		if (err == -ENOMEM)
+			schedule();
+		else if (err)
+			pr_warn_ratelimited("error %d while reading message\n",
+					    err);
+
+		err = process_writes();
+		if (err)
+			pr_warn_ratelimited("error %d while writing message\n",
+					    err);
+	}
+
+	xenbus_task = NULL;
 	return 0;
 }
 
@@ -223,6 +460,7 @@ int xb_init_comms(void)
 		rebind_evtchn_irq(xen_store_evtchn, xenbus_irq);
 	} else {
 		int err;
+
 		err = bind_evtchn_to_irqhandler(xen_store_evtchn, wake_waiting,
 						0, "xenbus", &xb_waitq);
 		if (err < 0) {
@@ -231,6 +469,13 @@ int xb_init_comms(void)
 		}
 
 		xenbus_irq = err;
+
+		if (!xenbus_task) {
+			xenbus_task = kthread_run(xenbus_thread, NULL,
+						  "xenbus");
+			if (IS_ERR(xenbus_task))
+				return PTR_ERR(xenbus_task);
+		}
 	}
 
 	return 0;

commit 332f791dc98d98116f4473b726f67c9321b0f31e
Author: Juergen Gross <jgross@suse.com>
Date:   Thu Feb 9 14:39:56 2017 +0100

    xen: clean up xenbus internal headers
    
    The xenbus driver has an awful mixture of internally and globally
    visible headers: some of the internally used only stuff is defined in
    the global header include/xen/xenbus.h while some stuff defined in
    internal headers is used by other drivers, too.
    
    Clean this up by moving the externally used symbols to
    include/xen/xenbus.h and the symbols used internally only to a new
    header drivers/xen/xenbus/xenbus.h replacing xenbus_comms.h and
    xenbus_probe.h
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Signed-off-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>

diff --git a/drivers/xen/xenbus/xenbus_comms.c b/drivers/xen/xenbus/xenbus_comms.c
index ecdecce80a6c..c21ec02643e1 100644
--- a/drivers/xen/xenbus/xenbus_comms.c
+++ b/drivers/xen/xenbus/xenbus_comms.c
@@ -40,7 +40,7 @@
 #include <asm/xen/hypervisor.h>
 #include <xen/events.h>
 #include <xen/page.h>
-#include "xenbus_comms.h"
+#include "xenbus.h"
 
 static int xenbus_irq;
 

commit 5bb0c9be2ac9a98513d43969e2b5c3d02cb271c8
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Sun Dec 27 18:02:16 2015 +0200

    xenbus: use virt_xxx barriers
    
    drivers/xen/xenbus/xenbus_comms.c uses
    full memory barriers to communicate with the other side.
    
    For guests compiled with CONFIG_SMP, smp_wmb and smp_mb
    would be sufficient, so mb() and wmb() here are only needed if
    a non-SMP guest runs on an SMP host.
    
    Switch to virt_xxx barriers which serve this exact purpose.
    
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Acked-by: David Vrabel <david.vrabel@citrix.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>

diff --git a/drivers/xen/xenbus/xenbus_comms.c b/drivers/xen/xenbus/xenbus_comms.c
index fdb0f339d0a7..ecdecce80a6c 100644
--- a/drivers/xen/xenbus/xenbus_comms.c
+++ b/drivers/xen/xenbus/xenbus_comms.c
@@ -123,14 +123,14 @@ int xb_write(const void *data, unsigned len)
 			avail = len;
 
 		/* Must write data /after/ reading the consumer index. */
-		mb();
+		virt_mb();
 
 		memcpy(dst, data, avail);
 		data += avail;
 		len -= avail;
 
 		/* Other side must not see new producer until data is there. */
-		wmb();
+		virt_wmb();
 		intf->req_prod += avail;
 
 		/* Implies mb(): other side will see the updated producer. */
@@ -180,14 +180,14 @@ int xb_read(void *data, unsigned len)
 			avail = len;
 
 		/* Must read data /after/ reading the producer index. */
-		rmb();
+		virt_rmb();
 
 		memcpy(data, src, avail);
 		data += avail;
 		len -= avail;
 
 		/* Other side must not see free space until we've copied out */
-		mb();
+		virt_mb();
 		intf->rsp_cons += avail;
 
 		pr_debug("Finished read of %i bytes (%i to go)\n", avail, len);

commit 283c0972d53769ee44750cad4c27e3f5fa26ec1f
Author: Joe Perches <joe@perches.com>
Date:   Fri Jun 28 03:21:41 2013 -0700

    xen: Convert printks to pr_<level>
    
    Convert printks to pr_<level> (excludes printk(KERN_DEBUG...)
    to be more consistent throughout the xen subsystem.
    
    Add pr_fmt with KBUILD_MODNAME or "xen:" KBUILD_MODNAME
    Coalesce formats and add missing word spaces
    Add missing newlines
    Align arguments and reflow to 80 columns
    Remove DRV_NAME from formats as pr_fmt adds the same content
    
    This does change some of the prefixes of these messages
    but it also does make them more consistent.
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/drivers/xen/xenbus/xenbus_comms.c b/drivers/xen/xenbus/xenbus_comms.c
index c5aa55c5d371..fdb0f339d0a7 100644
--- a/drivers/xen/xenbus/xenbus_comms.c
+++ b/drivers/xen/xenbus/xenbus_comms.c
@@ -30,6 +30,8 @@
  * IN THE SOFTWARE.
  */
 
+#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
+
 #include <linux/wait.h>
 #include <linux/interrupt.h>
 #include <linux/sched.h>
@@ -205,13 +207,12 @@ int xb_init_comms(void)
 	struct xenstore_domain_interface *intf = xen_store_interface;
 
 	if (intf->req_prod != intf->req_cons)
-		printk(KERN_ERR "XENBUS request ring is not quiescent "
-		       "(%08x:%08x)!\n", intf->req_cons, intf->req_prod);
+		pr_err("request ring is not quiescent (%08x:%08x)!\n",
+		       intf->req_cons, intf->req_prod);
 
 	if (intf->rsp_prod != intf->rsp_cons) {
-		printk(KERN_WARNING "XENBUS response ring is not quiescent "
-		       "(%08x:%08x): fixing up\n",
-		       intf->rsp_cons, intf->rsp_prod);
+		pr_warn("response ring is not quiescent (%08x:%08x): fixing up\n",
+			intf->rsp_cons, intf->rsp_prod);
 		/* breaks kdump */
 		if (!reset_devices)
 			intf->rsp_cons = intf->rsp_prod;
@@ -225,7 +226,7 @@ int xb_init_comms(void)
 		err = bind_evtchn_to_irqhandler(xen_store_evtchn, wake_waiting,
 						0, "xenbus", &xb_waitq);
 		if (err < 0) {
-			printk(KERN_ERR "XENBUS request irq failed %i\n", err);
+			pr_err("request irq failed %i\n", err);
 			return err;
 		}
 

commit ecc635f90adfe1b7cd5fd354f49edfbf24aa4e3e
Author: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
Date:   Fri Sep 14 12:13:12 2012 +0100

    xen/arm: compile and run xenbus
    
    bind_evtchn_to_irqhandler can legitimately return 0 (irq 0): it is not
    an error.
    
    If Linux is running as an HVM domain and is running as Dom0, use
    xenstored_local_init to initialize the xenstore page and event channel.
    
    Changes in v4:
    - do not xs_reset_watches on dom0.
    
    Changes in v2:
    - refactor xenbus_init.
    
    Signed-off-by: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    [v5: Fixed case switch indentations]
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/drivers/xen/xenbus/xenbus_comms.c b/drivers/xen/xenbus/xenbus_comms.c
index 52fe7ad07666..c5aa55c5d371 100644
--- a/drivers/xen/xenbus/xenbus_comms.c
+++ b/drivers/xen/xenbus/xenbus_comms.c
@@ -224,7 +224,7 @@ int xb_init_comms(void)
 		int err;
 		err = bind_evtchn_to_irqhandler(xen_store_evtchn, wake_waiting,
 						0, "xenbus", &xb_waitq);
-		if (err <= 0) {
+		if (err < 0) {
 			printk(KERN_ERR "XENBUS request irq failed %i\n", err);
 			return err;
 		}

commit d2fb4c51c7471a23f0a95526b624c14cec62603d
Author: Daniel De Graaf <dgdegra@tycho.nsa.gov>
Date:   Tue May 8 09:46:57 2012 -0400

    xenbus: Add support for xenbus backend in stub domain
    
    Add an ioctl to the /dev/xen/xenbus_backend device allowing the xenbus
    backend to be started after the kernel has booted. This allows xenstore
    to run in a different domain from the dom0.
    
    Signed-off-by: Daniel De Graaf <dgdegra@tycho.nsa.gov>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/drivers/xen/xenbus/xenbus_comms.c b/drivers/xen/xenbus/xenbus_comms.c
index 2eff7a6aaa20..52fe7ad07666 100644
--- a/drivers/xen/xenbus/xenbus_comms.c
+++ b/drivers/xen/xenbus/xenbus_comms.c
@@ -234,3 +234,9 @@ int xb_init_comms(void)
 
 	return 0;
 }
+
+void xb_deinit_comms(void)
+{
+	unbind_from_irqhandler(xenbus_irq, &xb_waitq);
+	xenbus_irq = 0;
+}

commit 116df6f004af81925dcaa90d4a3b76da6b009427
Author: Olaf Hering <olaf@aepfle.de>
Date:   Thu Aug 25 18:34:45 2011 +0200

    xen/pv-on-hvm kexec+kdump: reset PV devices in kexec or crash kernel
    
    After triggering a crash dump in a HVM guest, the PV backend drivers
    will remain in Connected state. When the kdump kernel starts the PV
    drivers will skip such devices. As a result, no root device is found and
    the vmcore cant be saved.
    
    A similar situation happens after a kexec boot, here the devices will be
    in the Closed state.
    
    With this change all frontend devices with state XenbusStateConnected or
    XenbusStateClosed will be reset by changing the state file to Closing ->
    Closed -> Initializing.  This will trigger a disconnect in the backend
    drivers. Now the frontend drivers will find the backend drivers in state
    Initwait and can connect.
    
    Signed-off-by: Olaf Hering <olaf@aepfle.de>
    [v2:
      - add timeout when waiting for backend state change
      (based on feedback from Ian Campell)
      - extent printk message to include backend string
      - add comment to fall-through case in xenbus_reset_frontend]
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/drivers/xen/xenbus/xenbus_comms.c b/drivers/xen/xenbus/xenbus_comms.c
index 090c61ee8fd0..2eff7a6aaa20 100644
--- a/drivers/xen/xenbus/xenbus_comms.c
+++ b/drivers/xen/xenbus/xenbus_comms.c
@@ -212,7 +212,9 @@ int xb_init_comms(void)
 		printk(KERN_WARNING "XENBUS response ring is not quiescent "
 		       "(%08x:%08x): fixing up\n",
 		       intf->rsp_cons, intf->rsp_prod);
-		intf->rsp_cons = intf->rsp_prod;
+		/* breaks kdump */
+		if (!reset_devices)
+			intf->rsp_cons = intf->rsp_prod;
 	}
 
 	if (xenbus_irq) {

commit 7d88d32a4670af583c896e5ecd3929b78538ca62
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Mon May 26 23:31:26 2008 +0100

    xenbus: rebind irq on restore
    
    When restoring, rebind the existing xenbus irq to the new xenbus event
    channel.  (It turns out in practice that this is always the same, and
    is never updated on restore.  That's a bug, but Xeno-linux has been
    like this for a long time, so it can't really be fixed.)
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/drivers/xen/xenbus/xenbus_comms.c b/drivers/xen/xenbus/xenbus_comms.c
index 6efbe3f29ca5..090c61ee8fd0 100644
--- a/drivers/xen/xenbus/xenbus_comms.c
+++ b/drivers/xen/xenbus/xenbus_comms.c
@@ -203,7 +203,6 @@ int xb_read(void *data, unsigned len)
 int xb_init_comms(void)
 {
 	struct xenstore_domain_interface *intf = xen_store_interface;
-	int err;
 
 	if (intf->req_prod != intf->req_cons)
 		printk(KERN_ERR "XENBUS request ring is not quiescent "
@@ -216,18 +215,20 @@ int xb_init_comms(void)
 		intf->rsp_cons = intf->rsp_prod;
 	}
 
-	if (xenbus_irq)
-		unbind_from_irqhandler(xenbus_irq, &xb_waitq);
+	if (xenbus_irq) {
+		/* Already have an irq; assume we're resuming */
+		rebind_evtchn_irq(xen_store_evtchn, xenbus_irq);
+	} else {
+		int err;
+		err = bind_evtchn_to_irqhandler(xen_store_evtchn, wake_waiting,
+						0, "xenbus", &xb_waitq);
+		if (err <= 0) {
+			printk(KERN_ERR "XENBUS request irq failed %i\n", err);
+			return err;
+		}
 
-	err = bind_evtchn_to_irqhandler(
-		xen_store_evtchn, wake_waiting,
-		0, "xenbus", &xb_waitq);
-	if (err <= 0) {
-		printk(KERN_ERR "XENBUS request irq failed %i\n", err);
-		return err;
+		xenbus_irq = err;
 	}
 
-	xenbus_irq = err;
-
 	return 0;
 }

commit 4bac07c993d03434ea902d3d4290d9e45944b66c
Author: Jeremy Fitzhardinge <jeremy@xensource.com>
Date:   Tue Jul 17 18:37:06 2007 -0700

    xen: add the Xenbus sysfs and virtual device hotplug driver
    
    This communicates with the machine control software via a registry
    residing in a controlling virtual machine. This allows dynamic
    creation, destruction and modification of virtual device
    configurations (network devices, block devices and CPUS, to name some
    examples).
    
    [ Greg, would you mind giving this a review?  Thanks -J ]
    
    Signed-off-by: Ian Pratt <ian.pratt@xensource.com>
    Signed-off-by: Christian Limpach <Christian.Limpach@cl.cam.ac.uk>
    Signed-off-by: Jeremy Fitzhardinge <jeremy@xensource.com>
    Signed-off-by: Chris Wright <chrisw@sous-sol.org>
    Cc: Greg KH <greg@kroah.com>

diff --git a/drivers/xen/xenbus/xenbus_comms.c b/drivers/xen/xenbus/xenbus_comms.c
new file mode 100644
index 000000000000..6efbe3f29ca5
--- /dev/null
+++ b/drivers/xen/xenbus/xenbus_comms.c
@@ -0,0 +1,233 @@
+/******************************************************************************
+ * xenbus_comms.c
+ *
+ * Low level code to talks to Xen Store: ringbuffer and event channel.
+ *
+ * Copyright (C) 2005 Rusty Russell, IBM Corporation
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License version 2
+ * as published by the Free Software Foundation; or, when distributed
+ * separately from the Linux kernel or incorporated into other
+ * software packages, subject to the following license:
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this source file (the "Software"), to deal in the Software without
+ * restriction, including without limitation the rights to use, copy, modify,
+ * merge, publish, distribute, sublicense, and/or sell copies of the Software,
+ * and to permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
+ * IN THE SOFTWARE.
+ */
+
+#include <linux/wait.h>
+#include <linux/interrupt.h>
+#include <linux/sched.h>
+#include <linux/err.h>
+#include <xen/xenbus.h>
+#include <asm/xen/hypervisor.h>
+#include <xen/events.h>
+#include <xen/page.h>
+#include "xenbus_comms.h"
+
+static int xenbus_irq;
+
+static DECLARE_WORK(probe_work, xenbus_probe);
+
+static DECLARE_WAIT_QUEUE_HEAD(xb_waitq);
+
+static irqreturn_t wake_waiting(int irq, void *unused)
+{
+	if (unlikely(xenstored_ready == 0)) {
+		xenstored_ready = 1;
+		schedule_work(&probe_work);
+	}
+
+	wake_up(&xb_waitq);
+	return IRQ_HANDLED;
+}
+
+static int check_indexes(XENSTORE_RING_IDX cons, XENSTORE_RING_IDX prod)
+{
+	return ((prod - cons) <= XENSTORE_RING_SIZE);
+}
+
+static void *get_output_chunk(XENSTORE_RING_IDX cons,
+			      XENSTORE_RING_IDX prod,
+			      char *buf, uint32_t *len)
+{
+	*len = XENSTORE_RING_SIZE - MASK_XENSTORE_IDX(prod);
+	if ((XENSTORE_RING_SIZE - (prod - cons)) < *len)
+		*len = XENSTORE_RING_SIZE - (prod - cons);
+	return buf + MASK_XENSTORE_IDX(prod);
+}
+
+static const void *get_input_chunk(XENSTORE_RING_IDX cons,
+				   XENSTORE_RING_IDX prod,
+				   const char *buf, uint32_t *len)
+{
+	*len = XENSTORE_RING_SIZE - MASK_XENSTORE_IDX(cons);
+	if ((prod - cons) < *len)
+		*len = prod - cons;
+	return buf + MASK_XENSTORE_IDX(cons);
+}
+
+/**
+ * xb_write - low level write
+ * @data: buffer to send
+ * @len: length of buffer
+ *
+ * Returns 0 on success, error otherwise.
+ */
+int xb_write(const void *data, unsigned len)
+{
+	struct xenstore_domain_interface *intf = xen_store_interface;
+	XENSTORE_RING_IDX cons, prod;
+	int rc;
+
+	while (len != 0) {
+		void *dst;
+		unsigned int avail;
+
+		rc = wait_event_interruptible(
+			xb_waitq,
+			(intf->req_prod - intf->req_cons) !=
+			XENSTORE_RING_SIZE);
+		if (rc < 0)
+			return rc;
+
+		/* Read indexes, then verify. */
+		cons = intf->req_cons;
+		prod = intf->req_prod;
+		if (!check_indexes(cons, prod)) {
+			intf->req_cons = intf->req_prod = 0;
+			return -EIO;
+		}
+
+		dst = get_output_chunk(cons, prod, intf->req, &avail);
+		if (avail == 0)
+			continue;
+		if (avail > len)
+			avail = len;
+
+		/* Must write data /after/ reading the consumer index. */
+		mb();
+
+		memcpy(dst, data, avail);
+		data += avail;
+		len -= avail;
+
+		/* Other side must not see new producer until data is there. */
+		wmb();
+		intf->req_prod += avail;
+
+		/* Implies mb(): other side will see the updated producer. */
+		notify_remote_via_evtchn(xen_store_evtchn);
+	}
+
+	return 0;
+}
+
+int xb_data_to_read(void)
+{
+	struct xenstore_domain_interface *intf = xen_store_interface;
+	return (intf->rsp_cons != intf->rsp_prod);
+}
+
+int xb_wait_for_data_to_read(void)
+{
+	return wait_event_interruptible(xb_waitq, xb_data_to_read());
+}
+
+int xb_read(void *data, unsigned len)
+{
+	struct xenstore_domain_interface *intf = xen_store_interface;
+	XENSTORE_RING_IDX cons, prod;
+	int rc;
+
+	while (len != 0) {
+		unsigned int avail;
+		const char *src;
+
+		rc = xb_wait_for_data_to_read();
+		if (rc < 0)
+			return rc;
+
+		/* Read indexes, then verify. */
+		cons = intf->rsp_cons;
+		prod = intf->rsp_prod;
+		if (!check_indexes(cons, prod)) {
+			intf->rsp_cons = intf->rsp_prod = 0;
+			return -EIO;
+		}
+
+		src = get_input_chunk(cons, prod, intf->rsp, &avail);
+		if (avail == 0)
+			continue;
+		if (avail > len)
+			avail = len;
+
+		/* Must read data /after/ reading the producer index. */
+		rmb();
+
+		memcpy(data, src, avail);
+		data += avail;
+		len -= avail;
+
+		/* Other side must not see free space until we've copied out */
+		mb();
+		intf->rsp_cons += avail;
+
+		pr_debug("Finished read of %i bytes (%i to go)\n", avail, len);
+
+		/* Implies mb(): other side will see the updated consumer. */
+		notify_remote_via_evtchn(xen_store_evtchn);
+	}
+
+	return 0;
+}
+
+/**
+ * xb_init_comms - Set up interrupt handler off store event channel.
+ */
+int xb_init_comms(void)
+{
+	struct xenstore_domain_interface *intf = xen_store_interface;
+	int err;
+
+	if (intf->req_prod != intf->req_cons)
+		printk(KERN_ERR "XENBUS request ring is not quiescent "
+		       "(%08x:%08x)!\n", intf->req_cons, intf->req_prod);
+
+	if (intf->rsp_prod != intf->rsp_cons) {
+		printk(KERN_WARNING "XENBUS response ring is not quiescent "
+		       "(%08x:%08x): fixing up\n",
+		       intf->rsp_cons, intf->rsp_prod);
+		intf->rsp_cons = intf->rsp_prod;
+	}
+
+	if (xenbus_irq)
+		unbind_from_irqhandler(xenbus_irq, &xb_waitq);
+
+	err = bind_evtchn_to_irqhandler(
+		xen_store_evtchn, wake_waiting,
+		0, "xenbus", &xb_waitq);
+	if (err <= 0) {
+		printk(KERN_ERR "XENBUS request irq failed %i\n", err);
+		return err;
+	}
+
+	xenbus_irq = err;
+
+	return 0;
+}
