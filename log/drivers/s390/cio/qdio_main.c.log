commit c920c545286270302d29fd63c05c3bd84828daee
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Tue Jun 2 14:26:36 2020 +0200

    s390/qdio: warn about unexpected SLSB states
    
    The way we produce SBALs to the device (first update q->nr_buf_used,
    then update the SLSB) should ensure that we never see some of the
    SLSB states when scanning the queue for progress.
    So make some noise if we do, this implies a bug in our SBAL tracking.
    
    Also tweak the WARN msg to provide more information.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index f42129c02927..0c919a11a46e 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -503,15 +503,18 @@ static int get_inbound_buffer_frontier(struct qdio_q *q, unsigned int start)
 			account_sbals_error(q, count);
 		return count;
 	case SLSB_CU_INPUT_EMPTY:
-	case SLSB_P_INPUT_NOT_INIT:
-	case SLSB_P_INPUT_ACK:
 		if (q->irq_ptr->perf_stat_enabled)
 			q->q_stats.nr_sbal_nop++;
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in nop:%1d %#02x",
 			      q->nr, start);
 		return 0;
+	case SLSB_P_INPUT_NOT_INIT:
+	case SLSB_P_INPUT_ACK:
+		/* We should never see this state, throw a WARN: */
 	default:
-		WARN_ON_ONCE(1);
+		dev_WARN_ONCE(&q->irq_ptr->cdev->dev, 1,
+			      "found state %#x at index %u on queue %u\n",
+			      state, start, q->nr);
 		return 0;
 	}
 }
@@ -716,11 +719,14 @@ static int get_outbound_buffer_frontier(struct qdio_q *q, unsigned int start)
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out primed:%1d",
 			      q->nr);
 		return 0;
-	case SLSB_P_OUTPUT_NOT_INIT:
 	case SLSB_P_OUTPUT_HALTED:
 		return 0;
+	case SLSB_P_OUTPUT_NOT_INIT:
+		/* We should never see this state, throw a WARN: */
 	default:
-		WARN_ON_ONCE(1);
+		dev_WARN_ONCE(&q->irq_ptr->cdev->dev, 1,
+			      "found state %#x at index %u on queue %u\n",
+			      state, start, q->nr);
 		return 0;
 	}
 }

commit 3d6c6f20d961209972a075ddc50b9a7207e9796e
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Tue Jun 2 14:23:32 2020 +0200

    s390/qdio: clean up usage of qdio_data
    
    This removes the last remaining accesses to ->qdio_data from internal
    code. Just pass the qdio_irq struct where needed instead.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 1aa94683d789..f42129c02927 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -916,10 +916,10 @@ static void qdio_int_handler_pci(struct qdio_irq *irq_ptr)
 	}
 }
 
-static void qdio_handle_activate_check(struct ccw_device *cdev,
-				unsigned long intparm, int cstat, int dstat)
+static void qdio_handle_activate_check(struct qdio_irq *irq_ptr,
+				       unsigned long intparm, int cstat,
+				       int dstat)
 {
-	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 	struct qdio_q *q;
 
 	DBF_ERROR("%4x ACT CHECK", irq_ptr->schid.sch_no);
@@ -946,11 +946,9 @@ static void qdio_handle_activate_check(struct ccw_device *cdev,
 	lgr_info_log();
 }
 
-static void qdio_establish_handle_irq(struct ccw_device *cdev, int cstat,
+static void qdio_establish_handle_irq(struct qdio_irq *irq_ptr, int cstat,
 				      int dstat)
 {
-	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
-
 	DBF_DEV_EVENT(DBF_INFO, irq_ptr, "qest irq");
 
 	if (cstat)
@@ -997,7 +995,7 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 
 	switch (irq_ptr->state) {
 	case QDIO_IRQ_STATE_INACTIVE:
-		qdio_establish_handle_irq(cdev, cstat, dstat);
+		qdio_establish_handle_irq(irq_ptr, cstat, dstat);
 		break;
 	case QDIO_IRQ_STATE_CLEANUP:
 		qdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);
@@ -1009,7 +1007,7 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 			return;
 		}
 		if (cstat || dstat)
-			qdio_handle_activate_check(cdev, intparm, cstat,
+			qdio_handle_activate_check(irq_ptr, intparm, cstat,
 						   dstat);
 		break;
 	case QDIO_IRQ_STATE_STOPPED:
@@ -1513,12 +1511,11 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 int do_QDIO(struct ccw_device *cdev, unsigned int callflags,
 	    int q_nr, unsigned int bufnr, unsigned int count)
 {
-	struct qdio_irq *irq_ptr;
+	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 
 	if (bufnr >= QDIO_MAX_BUFFERS_PER_Q || count > QDIO_MAX_BUFFERS_PER_Q)
 		return -EINVAL;
 
-	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)
 		return -ENODEV;
 

commit a87ee11607b853a31c8612d9f47b7fe974953b77
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Tue Apr 21 11:35:00 2020 +0100

    s390/qdio: reduce SLSB writes during Input Queue processing
    
    Streamline the processing of QDIO Input Queues, and remove some
    intermittent SLSB updates (no deleting of old ACKs, no redundant
    transitions through NOT_INIT).
    
    Rather than counting ACKs, we now keep track of the whole batch of
    SBALs that were completed during the current polling cycle.
    Most completed SBALs stay in their initial state (ie. PRIMED or ERROR),
    except that the most recent SBAL in each sub-run is ACKed for
    IRQ reduction.
    
    The only logic changes happen in inbound_handle_work(), the other
    delta is just a renaming of the variables that track the SBAL batch.
    
    Note that in particular we don't need to flip the _oldest_ SBAL to
    an idle state (eg. NOT_INIT or ACKed) as a guard against catching our
    own tail. Since get_inbound_buffer_frontier() will never scan more than
    the remaining nr_buf_used SBALs, this scenario just doesn't occur.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index bb137f962c3f..1aa94683d789 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -400,15 +400,15 @@ int debug_get_buf_state(struct qdio_q *q, unsigned int bufnr,
 
 static inline void qdio_stop_polling(struct qdio_q *q)
 {
-	if (!q->u.in.ack_count)
+	if (!q->u.in.batch_count)
 		return;
 
 	qperf_inc(q, stop_polling);
 
 	/* show the card that we are not polling anymore */
-	set_buf_states(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT,
-		       q->u.in.ack_count);
-	q->u.in.ack_count = 0;
+	set_buf_states(q, q->u.in.batch_start, SLSB_P_INPUT_NOT_INIT,
+		       q->u.in.batch_count);
+	q->u.in.batch_count = 0;
 }
 
 static inline void account_sbals(struct qdio_q *q, unsigned int count)
@@ -448,42 +448,13 @@ static void process_buffer_error(struct qdio_q *q, unsigned int start,
 static inline void inbound_handle_work(struct qdio_q *q, unsigned int start,
 				       int count, bool auto_ack)
 {
-	int new;
+	/* ACK the newest SBAL: */
+	if (!auto_ack)
+		set_buf_state(q, add_buf(start, count - 1), SLSB_P_INPUT_ACK);
 
-	if (auto_ack) {
-		if (!q->u.in.ack_count) {
-			q->u.in.ack_count = count;
-			q->u.in.ack_start = start;
-			return;
-		}
-
-		/* delete the previous ACK's */
-		set_buf_states(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT,
-			       q->u.in.ack_count);
-		q->u.in.ack_count = count;
-		q->u.in.ack_start = start;
-		return;
-	}
-
-	/*
-	 * ACK the newest buffer. The ACK will be removed in qdio_stop_polling
-	 * or by the next inbound run.
-	 */
-	new = add_buf(start, count - 1);
-	set_buf_state(q, new, SLSB_P_INPUT_ACK);
-
-	/* delete the previous ACKs */
-	if (q->u.in.ack_count)
-		set_buf_states(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT,
-			       q->u.in.ack_count);
-
-	q->u.in.ack_count = 1;
-	q->u.in.ack_start = new;
-	count--;
-	if (!count)
-		return;
-	/* need to change ALL buffers to get more interrupts */
-	set_buf_states(q, start, SLSB_P_INPUT_NOT_INIT, count);
+	if (!q->u.in.batch_count)
+		q->u.in.batch_start = start;
+	q->u.in.batch_count += count;
 }
 
 static int get_inbound_buffer_frontier(struct qdio_q *q, unsigned int start)
@@ -1453,12 +1424,12 @@ static int handle_inbound(struct qdio_q *q, unsigned int callflags,
 
 	qperf_inc(q, inbound_call);
 
-	/* If any ACKed SBALs are returned to HW, adjust ACK tracking: */
-	overlap = min(count - sub_buf(q->u.in.ack_start, bufnr),
-		      q->u.in.ack_count);
+	/* If any processed SBALs are returned to HW, adjust our tracking: */
+	overlap = min_t(int, count - sub_buf(q->u.in.batch_start, bufnr),
+			     q->u.in.batch_count);
 	if (overlap > 0) {
-		q->u.in.ack_start = add_buf(q->u.in.ack_start, overlap);
-		q->u.in.ack_count -= overlap;
+		q->u.in.batch_start = add_buf(q->u.in.batch_start, overlap);
+		q->u.in.batch_count -= overlap;
 	}
 
 	count = set_buf_states(q, bufnr, SLSB_CU_INPUT_EMPTY, count);

commit c119a8a3c395b0850f131728bdddd166d172842f
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Fri May 8 17:00:21 2020 +0200

    s390/qdio: fine-tune SLSB update
    
    xchg() for a single-byte location assembles to a 4-byte Compare&Swap,
    wrapped into a non-trivial amount of retry code that deals with
    concurrent modifications to the unaffected bytes.
    
    Change it to a simple byte-store, but preserve the memory ordering
    semantics that the CS provided.
    This simplifies the generated code for a hot path, and in theory also
    allows us to amortize the memory barriers over multiple SLSB updates.
    
    CC: Andreas Krebbel <krebbel@linux.ibm.com>
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 610c05f59589..bb137f962c3f 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -254,10 +254,17 @@ static inline int set_buf_states(struct qdio_q *q, int bufnr,
 	if (is_qebsm(q))
 		return qdio_do_sqbs(q, state, bufnr, count);
 
+	/* Ensure that all preceding changes to the SBALs are visible: */
+	mb();
+
 	for (i = 0; i < count; i++) {
-		xchg(&q->slsb.val[bufnr], state);
+		WRITE_ONCE(q->slsb.val[bufnr], state);
 		bufnr = next_buf(bufnr);
 	}
+
+	/* Make our SLSB changes visible: */
+	mb();
+
 	return count;
 }
 

commit a0138f59265aff4a21356ba9319171f421575b52
Author: Alexandra Winter <wintera@linux.ibm.com>
Date:   Thu Apr 16 15:08:41 2020 +0200

    s390/cio, s390/qeth: cleanup PNSO CHSC
    
    CHSC3D (PNSO - perform network subchannel operation) is used for
    OC0 (Store-network-bridging-information) as well as for
    OC3 (Store-network-address-information). So common fields are renamed
    from *brinfo* to *pnso*.
    Also *_bridge_host_* is changed into *_addr_change_*, e.g.
    qeth_bridge_host_event to qeth_addr_change_event, for the
    same reasons.
    The keywords in the card traces are changed accordingly.
    
    Remove unused L3 types, as PNSO will only return Layer2 entries.
    
    Make PNSO CHSC implementation more consistent with existing API usage:
    Add new function ccw_device_pnso() to drivers/s390/cio/device_ops.c and
    the function declaration to arch/s390/include/asm/ccwdev.h, which takes
    a struct ccw_device * as parameter instead of schid and calls
    chsc_pnso().
    
    PNSO CHSC has no strict relationship to qdio. So move the calling
    function from qdio to qeth_l2 and move the necessary structures to a
    new file arch/s390/include/asm/chsc.h.
    
    Do response code evaluation only in chsc_error_from_response() and
    use return code in all other places. qeth_anset_makerc() was meant to
    evaluate the PNSO response code, but never did, because pnso_rc was
    already non-zero.
    
    Indentation was corrected in some places.
    
    Signed-off-by: Alexandra Winter <wintera@linux.ibm.com>
    Reviewed-by: Peter Oberparleiter <oberpar@linux.ibm.com>
    Reviewed-by: Vineeth Vijayan <vneethv@linux.ibm.com>
    Reviewed-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index b0e84fba54dd..610c05f59589 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1705,94 +1705,6 @@ int qdio_stop_irq(struct ccw_device *cdev)
 }
 EXPORT_SYMBOL(qdio_stop_irq);
 
-/**
- * qdio_pnso_brinfo() - perform network subchannel op #0 - bridge info.
- * @schid:		Subchannel ID.
- * @cnc:		Boolean Change-Notification Control
- * @response:		Response code will be stored at this address
- * @cb: 		Callback function will be executed for each element
- *			of the address list
- * @priv:		Pointer to pass to the callback function.
- *
- * Performs "Store-network-bridging-information list" operation and calls
- * the callback function for every entry in the list. If "change-
- * notification-control" is set, further changes in the address list
- * will be reported via the IPA command.
- */
-int qdio_pnso_brinfo(struct subchannel_id schid,
-		int cnc, u16 *response,
-		void (*cb)(void *priv, enum qdio_brinfo_entry_type type,
-				void *entry),
-		void *priv)
-{
-	struct chsc_pnso_area *rr;
-	int rc;
-	u32 prev_instance = 0;
-	int isfirstblock = 1;
-	int i, size, elems;
-
-	rr = (struct chsc_pnso_area *)get_zeroed_page(GFP_KERNEL);
-	if (rr == NULL)
-		return -ENOMEM;
-	do {
-		/* on the first iteration, naihdr.resume_token will be zero */
-		rc = chsc_pnso_brinfo(schid, rr, rr->naihdr.resume_token, cnc);
-		if (rc != 0 && rc != -EBUSY)
-			goto out;
-		if (rr->response.code != 1) {
-			rc = -EIO;
-			continue;
-		} else
-			rc = 0;
-
-		if (cb == NULL)
-			continue;
-
-		size = rr->naihdr.naids;
-		elems = (rr->response.length -
-				sizeof(struct chsc_header) -
-				sizeof(struct chsc_brinfo_naihdr)) /
-				size;
-
-		if (!isfirstblock && (rr->naihdr.instance != prev_instance)) {
-			/* Inform the caller that they need to scrap */
-			/* the data that was already reported via cb */
-				rc = -EAGAIN;
-				break;
-		}
-		isfirstblock = 0;
-		prev_instance = rr->naihdr.instance;
-		for (i = 0; i < elems; i++)
-			switch (size) {
-			case sizeof(struct qdio_brinfo_entry_l3_ipv6):
-				(*cb)(priv, l3_ipv6_addr,
-						&rr->entries.l3_ipv6[i]);
-				break;
-			case sizeof(struct qdio_brinfo_entry_l3_ipv4):
-				(*cb)(priv, l3_ipv4_addr,
-						&rr->entries.l3_ipv4[i]);
-				break;
-			case sizeof(struct qdio_brinfo_entry_l2):
-				(*cb)(priv, l2_addr_lnid,
-						&rr->entries.l2[i]);
-				break;
-			default:
-				WARN_ON_ONCE(1);
-				rc = -EIO;
-				goto out;
-			}
-	} while (rr->response.code == 0x0107 ||  /* channel busy */
-		  (rr->response.code == 1 && /* list stored */
-		   /* resume token is non-zero => list incomplete */
-		   (rr->naihdr.resume_token.t1 || rr->naihdr.resume_token.t2)));
-	(*response) = rr->response.code;
-
-out:
-	free_page((unsigned long)rr);
-	return rc;
-}
-EXPORT_SYMBOL_GPL(qdio_pnso_brinfo);
-
 static int __init init_QDIO(void)
 {
 	int rc;

commit cafebf8653b3d689b3411daa0d3d7b67fc4f2edb
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Thu May 7 10:21:53 2020 +0200

    s390/qdio: remove q->first_to_kick
    
    q->first_to_kick is obsolete, and can be replaced by q->first_to_check.
    
    Both cursors start off at 0. Out of the three code paths that update
    first_to_check, the qdio_inspect_queue() path is irrelevant as it
    doesn't even touch first_to_kick anymore.
    This leaves us with the two tasklet-driven code paths. Here any update
    to first_to_check is followed by a call to qdio_kick_handler(), which
    advances first_to_kick by the same amount.
    
    So the two cursors will differ only for a tiny moment. Drivers have no
    way of deterministically observing this difference, and thus it doesn't
    matter which of the cursors we use for reporting an error to q->handler.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index d9acf492f73c..b0e84fba54dd 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -143,7 +143,7 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 		DBF_ERROR("%4x EQBS ERROR", SCH_NO(q));
 		DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
 		q->handler(q->irq_ptr->cdev, QDIO_ERROR_GET_BUF_STATE, q->nr,
-			   q->first_to_kick, count, q->irq_ptr->int_parm);
+			   q->first_to_check, count, q->irq_ptr->int_parm);
 		return 0;
 	}
 }
@@ -191,7 +191,7 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 		DBF_ERROR("%4x SQBS ERROR", SCH_NO(q));
 		DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
 		q->handler(q->irq_ptr->cdev, QDIO_ERROR_SET_BUF_STATE, q->nr,
-			   q->first_to_kick, count, q->irq_ptr->int_parm);
+			   q->first_to_check, count, q->irq_ptr->int_parm);
 		return 0;
 	}
 }
@@ -622,10 +622,9 @@ static inline unsigned long qdio_aob_for_buffer(struct qdio_output_q *q,
 	return phys_aob;
 }
 
-static void qdio_kick_handler(struct qdio_q *q, unsigned int count)
+static void qdio_kick_handler(struct qdio_q *q, unsigned int start,
+			      unsigned int count)
 {
-	int start = q->first_to_kick;
-
 	if (unlikely(q->irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))
 		return;
 
@@ -642,7 +641,6 @@ static void qdio_kick_handler(struct qdio_q *q, unsigned int count)
 		   q->irq_ptr->int_parm);
 
 	/* for the next time */
-	q->first_to_kick = add_buf(start, count);
 	q->qdio_error = 0;
 }
 
@@ -666,9 +664,9 @@ static void __qdio_inbound_processing(struct qdio_q *q)
 	if (count == 0)
 		return;
 
+	qdio_kick_handler(q, start, count);
 	start = add_buf(start, count);
 	q->first_to_check = start;
-	qdio_kick_handler(q, count);
 
 	if (!qdio_inbound_q_done(q, start)) {
 		/* means poll time is not yet over */
@@ -824,7 +822,7 @@ static void __qdio_outbound_processing(struct qdio_q *q)
 	count = qdio_outbound_q_moved(q, start);
 	if (count) {
 		q->first_to_check = add_buf(start, count);
-		qdio_kick_handler(q, count);
+		qdio_kick_handler(q, start, count);
 	}
 
 	if (queue_type(q) == QDIO_ZFCP_QFMT && !pci_out_supported(q->irq_ptr) &&
@@ -945,7 +943,6 @@ static void qdio_handle_activate_check(struct ccw_device *cdev,
 {
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 	struct qdio_q *q;
-	int count;
 
 	DBF_ERROR("%4x ACT CHECK", irq_ptr->schid.sch_no);
 	DBF_ERROR("intp :%lx", intparm);
@@ -960,9 +957,8 @@ static void qdio_handle_activate_check(struct ccw_device *cdev,
 		goto no_handler;
 	}
 
-	count = sub_buf(q->first_to_check, q->first_to_kick);
 	q->handler(q->irq_ptr->cdev, QDIO_ERROR_ACTIVATE,
-		   q->nr, q->first_to_kick, count, irq_ptr->int_parm);
+		   q->nr, q->first_to_check, 0, irq_ptr->int_parm);
 no_handler:
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_STOPPED);
 	/*

commit 0623b7dda24f313bf210119ee6c5a4bdec6ce52d
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Sat May 9 15:12:05 2020 +0200

    s390/qdio: fix up qdio_start_irq() kerneldoc
    
    Document the actual semantics, correcting an old copy & paste mistake.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index f5596265b053..d9acf492f73c 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1566,7 +1566,7 @@ int do_QDIO(struct ccw_device *cdev, unsigned int callflags,
 EXPORT_SYMBOL_GPL(do_QDIO);
 
 /**
- * qdio_start_irq - process input buffers
+ * qdio_start_irq - enable interrupt processing for the device
  * @cdev: associated ccw_device for the qdio subchannel
  *
  * Return codes

commit c70d82e96644bd660ea53209c19f75cd86c560d6
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Tue Apr 21 10:38:18 2020 +0200

    s390/qdio: add IRQ reduction for error SBALs
    
    SBALs in PRIMED or ERROR state represent new work on the Input Queue.
    But while inbound_primed() does all sorts of ACK management for new
    PRIMED work, the same handling is currently missing for ERROR work.
    In particular the path for ERROR work doesn't clear up _old_ ACKs.
    
    Treat ERROR work the same as PRIMED work, but consider that the QEBSM
    auto-ACK feature doesn't apply here. So we need to set the ACK manually,
    as if it was a non-QEBSM device.
    
    Note that this doesn't aspire to actually improve performance, the main
    goal is to just unify the code paths and have consistent behaviour.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index eea3032e68c0..f5596265b053 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -438,15 +438,12 @@ static void process_buffer_error(struct qdio_q *q, unsigned int start,
 		  q->sbal[start]->element[15].sflags);
 }
 
-static inline void inbound_primed(struct qdio_q *q, unsigned int start,
-				  int count)
+static inline void inbound_handle_work(struct qdio_q *q, unsigned int start,
+				       int count, bool auto_ack)
 {
 	int new;
 
-	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in prim:%1d %02x", q->nr, count);
-
-	/* for QEBSM the ACK was already set by EQBS */
-	if (is_qebsm(q)) {
+	if (auto_ack) {
 		if (!q->u.in.ack_count) {
 			q->u.in.ack_count = count;
 			q->u.in.ack_start = start;
@@ -507,19 +504,21 @@ static int get_inbound_buffer_frontier(struct qdio_q *q, unsigned int start)
 
 	switch (state) {
 	case SLSB_P_INPUT_PRIMED:
-		inbound_primed(q, start, count);
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in prim:%1d %02x", q->nr,
+			      count);
+
+		inbound_handle_work(q, start, count, is_qebsm(q));
 		if (atomic_sub_return(count, &q->nr_buf_used) == 0)
 			qperf_inc(q, inbound_queue_full);
 		if (q->irq_ptr->perf_stat_enabled)
 			account_sbals(q, count);
 		return count;
 	case SLSB_P_INPUT_ERROR:
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in err:%1d %02x", q->nr,
+			      count);
+
 		process_buffer_error(q, start, count);
-		/*
-		 * Interrupts may be avoided as long as the error is present
-		 * so change the buffer state immediately to avoid starvation.
-		 */
-		set_buf_states(q, start, SLSB_P_INPUT_NOT_INIT, count);
+		inbound_handle_work(q, start, count, false);
 		if (atomic_sub_return(count, &q->nr_buf_used) == 0)
 			qperf_inc(q, inbound_queue_full);
 		if (q->irq_ptr->perf_stat_enabled)

commit 1db85d0e73f3b017c63afcdec1197d4d0736c362
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Tue Apr 21 10:26:22 2020 +0200

    s390/qdio: refactor ACK processing for primed SBALs
    
    inbound_primed() currently has two code paths - one for QEBSM that knows
    how to deal with multiple ACKs, and a non-QEBSM path that strictly
    assumes a single ACK on the queue.
    
    In preparation for a subsequent patch, slightly adjust the non-QEBSM
    path so that it can manage a queue with multiple ACKs.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index c3d696bb106b..eea3032e68c0 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -466,15 +466,14 @@ static inline void inbound_primed(struct qdio_q *q, unsigned int start,
 	 * or by the next inbound run.
 	 */
 	new = add_buf(start, count - 1);
-	if (q->u.in.ack_count) {
-		/* reset the previous ACK but first set the new one */
-		set_buf_state(q, new, SLSB_P_INPUT_ACK);
-		set_buf_state(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT);
-	} else {
-		q->u.in.ack_count = 1;
-		set_buf_state(q, new, SLSB_P_INPUT_ACK);
-	}
+	set_buf_state(q, new, SLSB_P_INPUT_ACK);
+
+	/* delete the previous ACKs */
+	if (q->u.in.ack_count)
+		set_buf_states(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT,
+			       q->u.in.ack_count);
 
+	q->u.in.ack_count = 1;
 	q->u.in.ack_start = new;
 	count--;
 	if (!count)

commit 9de6c08700ce9fab4589c1a44cec2a21812ab565
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Tue Apr 21 10:22:01 2020 +0200

    s390/qdio: simplify overlap calculation on Input refill
    
    Refilling the Input Queue requires additional checks, as the refilled
    SBALs can overlap with the ACKs that qdio maintains on the queue.
    
    This code path is way too complex, and does a whole bunch of wrap-around
    checks that the modulo arithmetic in sub_buf() takes care of by itself.
    So shrink down all that code into a few lines of equivalent
    functionality.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 4bd6dbfe8387..c3d696bb106b 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1438,24 +1438,6 @@ int qdio_activate(struct ccw_device *cdev)
 }
 EXPORT_SYMBOL_GPL(qdio_activate);
 
-static inline int buf_in_between(int bufnr, int start, int count)
-{
-	int end = add_buf(start, count);
-
-	if (end > start) {
-		if (bufnr >= start && bufnr < end)
-			return 1;
-		else
-			return 0;
-	}
-
-	/* wrap-around case */
-	if (bufnr >= start || bufnr < end)
-		return 1;
-	else
-		return 0;
-}
-
 /**
  * handle_inbound - reset processed input buffers
  * @q: queue containing the buffers
@@ -1466,36 +1448,18 @@ static inline int buf_in_between(int bufnr, int start, int count)
 static int handle_inbound(struct qdio_q *q, unsigned int callflags,
 			  int bufnr, int count)
 {
-	int diff;
+	int overlap;
 
 	qperf_inc(q, inbound_call);
 
-	if (!q->u.in.ack_count)
-		goto set;
-
-	/* protect against stop polling setting an ACK for an emptied slsb */
-	if (count == QDIO_MAX_BUFFERS_PER_Q) {
-		/* overwriting everything, just delete polling status */
-		q->u.in.ack_count = 0;
-		goto set;
-	} else if (buf_in_between(q->u.in.ack_start, bufnr, count)) {
-		if (is_qebsm(q)) {
-			/* partial overwrite, just update ack_start */
-			diff = add_buf(bufnr, count);
-			diff = sub_buf(diff, q->u.in.ack_start);
-			q->u.in.ack_count -= diff;
-			if (q->u.in.ack_count <= 0) {
-				q->u.in.ack_count = 0;
-				goto set;
-			}
-			q->u.in.ack_start = add_buf(q->u.in.ack_start, diff);
-		} else {
-			/* the only ACK will be deleted */
-			q->u.in.ack_count = 0;
-		}
+	/* If any ACKed SBALs are returned to HW, adjust ACK tracking: */
+	overlap = min(count - sub_buf(q->u.in.ack_start, bufnr),
+		      q->u.in.ack_count);
+	if (overlap > 0) {
+		q->u.in.ack_start = add_buf(q->u.in.ack_start, overlap);
+		q->u.in.ack_count -= overlap;
 	}
 
-set:
 	count = set_buf_states(q, bufnr, SLSB_CU_INPUT_EMPTY, count);
 	atomic_add(count, &q->nr_buf_used);
 

commit 19d4c761c1d2354e6c1deb6e1d31c949028b92d6
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Tue Apr 21 17:20:00 2020 +0200

    s390/qdio: remove always-true condition
    
    buf_in_between() gets passed q->u.in.ack_start as 'bufnr' parameter.
    
    The ack_start always ranges between 0 and QDIO_MAX_BUFFERS_PER_Q - 1,
    so the subsequent check will always return true. Remove it.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 68985871b6bf..4bd6dbfe8387 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1450,8 +1450,7 @@ static inline int buf_in_between(int bufnr, int start, int count)
 	}
 
 	/* wrap-around case */
-	if ((bufnr >= start && bufnr <= QDIO_MAX_BUFFERS_PER_Q) ||
-	    (bufnr < end))
+	if (bufnr >= start || bufnr < end)
 		return 1;
 	else
 		return 0;

commit 9b7012dfc33db9c44add10ab58033fe167a15f13
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Fri Apr 17 14:20:00 2020 +0200

    s390/qdio: de-duplicate tiqdio_inbound_processing()
    
    Except for some initial thinint-only steps, the processing is identical
    to the non-thinint case. So re-use the existing helper.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index ef0be46f3e04..68985871b6bf 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -880,47 +880,17 @@ static inline void qdio_check_outbound_pci_queues(struct qdio_irq *irq)
 			qdio_tasklet_schedule(out);
 }
 
-static void __tiqdio_inbound_processing(struct qdio_q *q)
+void tiqdio_inbound_processing(unsigned long data)
 {
-	unsigned int start = q->first_to_check;
-	int count;
+	struct qdio_q *q = (struct qdio_q *)data;
 
-	qperf_inc(q, tasklet_inbound);
 	if (need_siga_sync(q) && need_siga_sync_after_ai(q))
 		qdio_sync_queues(q);
 
 	/* The interrupt could be caused by a PCI request: */
 	qdio_check_outbound_pci_queues(q->irq_ptr);
 
-	count = qdio_inbound_q_moved(q, start);
-	if (count == 0)
-		return;
-
-	start = add_buf(start, count);
-	q->first_to_check = start;
-	qdio_kick_handler(q, count);
-
-	if (!qdio_inbound_q_done(q, start)) {
-		qperf_inc(q, tasklet_inbound_resched);
-		if (!qdio_tasklet_schedule(q))
-			return;
-	}
-
-	qdio_stop_polling(q);
-	/*
-	 * We need to check again to not lose initiative after
-	 * resetting the ACK state.
-	 */
-	if (!qdio_inbound_q_done(q, start)) {
-		qperf_inc(q, tasklet_inbound_resched2);
-		qdio_tasklet_schedule(q);
-	}
-}
-
-void tiqdio_inbound_processing(unsigned long data)
-{
-	struct qdio_q *q = (struct qdio_q *)data;
-	__tiqdio_inbound_processing(q);
+	__qdio_inbound_processing(q);
 }
 
 static inline void qdio_set_state(struct qdio_irq *irq_ptr,

commit d188cac39753c8419d2b168436a632711896ea4e
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Thu Apr 2 23:48:00 2020 +0200

    s390/qdio: keep track of allocated queue count
    
    Knowing how many queues we initially allocated allows us to
    1) sanity-check a subsequent qdio_establish() request, and
    2) walk the queue arrays without further checks. Apply this while
       cleanly splitting qdio_free_queues() into two separate helpers.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Steffen Maier <maier@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 09bb69028d67..ef0be46f3e04 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1205,6 +1205,7 @@ int qdio_free(struct ccw_device *cdev)
 	cdev->private->qdio_data = NULL;
 	mutex_unlock(&irq_ptr->setup_mutex);
 
+	qdio_free_async_data(irq_ptr);
 	qdio_free_queues(irq_ptr);
 	free_page((unsigned long) irq_ptr->qdr);
 	free_page(irq_ptr->chsc_page);
@@ -1340,6 +1341,10 @@ int qdio_establish(struct ccw_device *cdev,
 	if (!irq_ptr)
 		return -ENODEV;
 
+	if (init_data->no_input_qs > irq_ptr->max_input_qs ||
+	    init_data->no_output_qs > irq_ptr->max_output_qs)
+		return -EINVAL;
+
 	if ((init_data->no_input_qs && !init_data->input_handler) ||
 	    (init_data->no_output_qs && !init_data->output_handler))
 		return -EINVAL;

commit 2a7cf35c4056facd35c952e8000519034376eef7
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Thu Apr 2 23:30:41 2020 +0200

    s390/qdio: roll-back after queue allocation error
    
    When qdio_allocate_qs() fails, have it deal with its previous
    allocations.
    This way qdio_allocate() doesn't need to clean up afterwards.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Steffen Maier <maier@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 579caba8ea93..09bb69028d67 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1271,7 +1271,6 @@ int qdio_allocate(struct ccw_device *cdev, unsigned int no_input_qs,
 	return 0;
 
 err_queues:
-	qdio_free_queues(irq_ptr);
 	free_page((unsigned long) irq_ptr->qdr);
 err_qdr:
 	free_page(irq_ptr->chsc_page);

commit edbf3b2a87db6357fba54520c1baf605e08557b3
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Thu Apr 2 23:22:18 2020 +0200

    s390/qdio: do more fine-grained allocation roll-back
    
    Instead of having a catch-all qdio_release_memory() helper, free the
    individual allocations from the respective error path.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Steffen Maier <maier@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 2abb1d2a0629..579caba8ea93 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1205,7 +1205,10 @@ int qdio_free(struct ccw_device *cdev)
 	cdev->private->qdio_data = NULL;
 	mutex_unlock(&irq_ptr->setup_mutex);
 
-	qdio_release_memory(irq_ptr);
+	qdio_free_queues(irq_ptr);
+	free_page((unsigned long) irq_ptr->qdr);
+	free_page(irq_ptr->chsc_page);
+	free_page((unsigned long) irq_ptr);
 	return 0;
 }
 EXPORT_SYMBOL_GPL(qdio_free);
@@ -1221,6 +1224,7 @@ int qdio_allocate(struct ccw_device *cdev, unsigned int no_input_qs,
 {
 	struct subchannel_id schid;
 	struct qdio_irq *irq_ptr;
+	int rc = -ENOMEM;
 
 	ccw_device_get_schid(cdev, &schid);
 	DBF_EVENT("qallocate:%4x", schid.sch_no);
@@ -1232,12 +1236,12 @@ int qdio_allocate(struct ccw_device *cdev, unsigned int no_input_qs,
 	/* irq_ptr must be in GFP_DMA since it contains ccw1.cda */
 	irq_ptr = (void *) get_zeroed_page(GFP_KERNEL | GFP_DMA);
 	if (!irq_ptr)
-		goto out_err;
+		return -ENOMEM;
 
 	irq_ptr->cdev = cdev;
 	mutex_init(&irq_ptr->setup_mutex);
 	if (qdio_allocate_dbf(irq_ptr))
-		goto out_rel;
+		goto err_dbf;
 
 	DBF_DEV_EVENT(DBF_ERR, irq_ptr, "alloc niq:%1u noq:%1u", no_input_qs,
 		      no_output_qs);
@@ -1250,24 +1254,31 @@ int qdio_allocate(struct ccw_device *cdev, unsigned int no_input_qs,
 	 */
 	irq_ptr->chsc_page = get_zeroed_page(GFP_KERNEL);
 	if (!irq_ptr->chsc_page)
-		goto out_rel;
+		goto err_chsc;
 
 	/* qdr is used in ccw1.cda which is u32 */
 	irq_ptr->qdr = (struct qdr *) get_zeroed_page(GFP_KERNEL | GFP_DMA);
 	if (!irq_ptr->qdr)
-		goto out_rel;
+		goto err_qdr;
 
-	if (qdio_allocate_qs(irq_ptr, no_input_qs, no_output_qs))
-		goto out_rel;
+	rc = qdio_allocate_qs(irq_ptr, no_input_qs, no_output_qs);
+	if (rc)
+		goto err_queues;
 
 	INIT_LIST_HEAD(&irq_ptr->entry);
 	cdev->private->qdio_data = irq_ptr;
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);
 	return 0;
-out_rel:
-	qdio_release_memory(irq_ptr);
-out_err:
-	return -ENOMEM;
+
+err_queues:
+	qdio_free_queues(irq_ptr);
+	free_page((unsigned long) irq_ptr->qdr);
+err_qdr:
+	free_page(irq_ptr->chsc_page);
+err_chsc:
+err_dbf:
+	free_page((unsigned long) irq_ptr);
+	return rc;
 }
 EXPORT_SYMBOL_GPL(qdio_allocate);
 

commit 3050f022df6a08cb3c968b9be01c163092c568d3
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Thu Apr 2 11:37:50 2020 +0200

    s390/qdio: consolidate thinint init/exit
    
    Wrap the init/exit steps for thinint into a single helper that follows
    the established naming scheme.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Steffen Maier <maier@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 80cc811bd2e0..2abb1d2a0629 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1861,16 +1861,11 @@ static int __init init_QDIO(void)
 	rc = qdio_setup_init();
 	if (rc)
 		goto out_debug;
-	rc = tiqdio_allocate_memory();
+	rc = qdio_thinint_init();
 	if (rc)
 		goto out_cache;
-	rc = tiqdio_register_thinints();
-	if (rc)
-		goto out_ti;
 	return 0;
 
-out_ti:
-	tiqdio_free_memory();
 out_cache:
 	qdio_setup_exit();
 out_debug:
@@ -1880,8 +1875,7 @@ static int __init init_QDIO(void)
 
 static void __exit exit_QDIO(void)
 {
-	tiqdio_unregister_thinints();
-	tiqdio_free_memory();
+	qdio_thinint_exit();
 	qdio_setup_exit();
 	qdio_debug_exit();
 }

commit 68a381746f20e5435206173e22d0a011ef78790e
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Thu Apr 9 09:55:05 2020 +0200

    s390/qdio: tear down thinint indicator after early error
    
    qdio_establish() calls qdio_establish_thinint(), but later has an error
    exit path that doesn't roll this call back. Fix it.
    
    Fixes: 779e6e1c724d ("[S390] qdio: new qdio driver.")
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index da5a11138020..80cc811bd2e0 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1363,6 +1363,7 @@ int qdio_establish(struct ccw_device *cdev,
 	if (rc) {
 		DBF_ERROR("%4x est IO ERR", irq_ptr->schid.sch_no);
 		DBF_ERROR("rc:%4x", rc);
+		qdio_shutdown_thinint(irq_ptr);
 		qdio_shutdown_irq(irq_ptr);
 		mutex_unlock(&irq_ptr->setup_mutex);
 		return rc;

commit 7b942b4be971d49cb185ce4690d7fbf94636e88a
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Thu Apr 9 10:55:16 2020 +0200

    s390/qdio: consistently restore the IRQ handler
    
    For rolling back after an error, qdio_establish() calls qdio_shutdown().
    If the error occurs early enough, then the qdio_irq's state still is
    QDIO_IRQ_STATE_INACTIVE and qdio_shutdown() does nothing.
    
    But at _any_ point where qdio_establish() bails out in this way,
    qdio_setup_irq() will have already replaced the IRQ handler. This then
    won't be restored after an early error, and the device can end up being
    returned to the device driver with qdio's IRQ handler still installed.
    
    Slightly reorder qdio_setup_irq() so we can be 100% sure that the IRQ
    handler was replaced. Then fix the bug in qdio_establish() by calling a
    helper that rolls back only the IRQ handler modification.
    
    Also use the new helper in qdio_shutdown() to keep things in sync, and
    slightly clean up the locking while doing so.
    This makes minor semantical changes, but holding setup_mutex gives us
    sufficient leeway to eg. pull qdio_shutdown_thinint() outside of the
    ccwdev lock's scope.
    
    Fixes: 779e6e1c724d ("[S390] qdio: new qdio driver.")
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index bcc3ab14e72d..da5a11138020 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1154,35 +1154,27 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 
 	/* cleanup subchannel */
 	spin_lock_irq(get_ccwdev_lock(cdev));
-
+	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_CLEANUP);
 	if (how & QDIO_FLAG_CLEANUP_USING_CLEAR)
 		rc = ccw_device_clear(cdev, QDIO_DOING_CLEANUP);
 	else
 		/* default behaviour is halt */
 		rc = ccw_device_halt(cdev, QDIO_DOING_CLEANUP);
+	spin_unlock_irq(get_ccwdev_lock(cdev));
 	if (rc) {
 		DBF_ERROR("%4x SHUTD ERR", irq_ptr->schid.sch_no);
 		DBF_ERROR("rc:%4d", rc);
 		goto no_cleanup;
 	}
 
-	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_CLEANUP);
-	spin_unlock_irq(get_ccwdev_lock(cdev));
 	wait_event_interruptible_timeout(cdev->private->wait_q,
 		irq_ptr->state == QDIO_IRQ_STATE_INACTIVE ||
 		irq_ptr->state == QDIO_IRQ_STATE_ERR,
 		10 * HZ);
-	spin_lock_irq(get_ccwdev_lock(cdev));
 
 no_cleanup:
 	qdio_shutdown_thinint(irq_ptr);
-
-	/* restore interrupt handler */
-	if ((void *)cdev->handler == (void *)qdio_int_handler) {
-		cdev->handler = irq_ptr->orig_handler;
-		cdev->private->intparm = 0;
-	}
-	spin_unlock_irq(get_ccwdev_lock(cdev));
+	qdio_shutdown_irq(irq_ptr);
 
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);
 	mutex_unlock(&irq_ptr->setup_mutex);
@@ -1352,8 +1344,8 @@ int qdio_establish(struct ccw_device *cdev,
 
 	rc = qdio_establish_thinint(irq_ptr);
 	if (rc) {
+		qdio_shutdown_irq(irq_ptr);
 		mutex_unlock(&irq_ptr->setup_mutex);
-		qdio_shutdown(cdev, QDIO_FLAG_CLEANUP_USING_CLEAR);
 		return rc;
 	}
 
@@ -1371,8 +1363,8 @@ int qdio_establish(struct ccw_device *cdev,
 	if (rc) {
 		DBF_ERROR("%4x est IO ERR", irq_ptr->schid.sch_no);
 		DBF_ERROR("rc:%4x", rc);
+		qdio_shutdown_irq(irq_ptr);
 		mutex_unlock(&irq_ptr->setup_mutex);
-		qdio_shutdown(cdev, QDIO_FLAG_CLEANUP_USING_CLEAR);
 		return rc;
 	}
 

commit 9c159bbc14ba196d590dc1a2fe7931ccfe73db98
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Fri Mar 20 14:00:00 2020 +0100

    s390/qdio: clear DSCI early for polling drivers
    
    Polling drivers in a configuration with 1 Input Queue currently keep
    their DSCI armed all the way through the poll cycle, until
    qdio_start_irq() clears it.
    
    _Any_ intermittent QDIO interrupt delivered to tiqdio_thinint_handler()
    will thus cause
    1) the 'adapter_int' statistic to be incremented,
    2) a call to tiqdio_call_inq_handlers() for this device, and then
    3) the 'int_discarded' statistics to be incremented.
    
    This causes overhead & complexity in the IRQ path, along with ambiguity
    in the statistics.
    On the other hand the device should be in IRQ avoidance mode during a
    poll cycle, so there won't be a lot of DSCI ping-pong that this
    micro-optimization could prevent.
    
    So align the DSCI handling with what we already do for devices with
    multiple Input Queues: clear it right away while processing the IRQ.
    
    For the non-polling path this means that we no longer need to handle
    the 1-queue case separately.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 9d6e51bcd072..bcc3ab14e72d 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1643,8 +1643,6 @@ int qdio_start_irq(struct ccw_device *cdev)
 	if (!irq_ptr)
 		return -ENODEV;
 
-	clear_nonshared_ind(irq_ptr);
-
 	for_each_input_queue(irq_ptr, q, i)
 		qdio_stop_polling(q);
 

commit 1da1092dbf61a0c0aab02048232f5e9fcab15861
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Fri Mar 20 14:00:00 2020 +0100

    s390/qdio: remove cdev from init_data
    
    It's no longer needed.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index bf617b455428..9d6e51bcd072 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1322,11 +1322,12 @@ static void qdio_trace_init_data(struct qdio_irq *irq,
 
 /**
  * qdio_establish - establish queues on a qdio subchannel
+ * @cdev: associated ccw device
  * @init_data: initialization data
  */
-int qdio_establish(struct qdio_initialize *init_data)
+int qdio_establish(struct ccw_device *cdev,
+		   struct qdio_initialize *init_data)
 {
-	struct ccw_device *cdev = init_data->cdev;
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 	struct subchannel_id schid;
 	int rc;

commit 3db1db93e34325e14bb29f8f1d904020c409bea6
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Fri Mar 20 14:00:00 2020 +0100

    s390/qdio: cleanly split alloc and establish
    
    All that qdio_allocate() actually uses from the init_data is the cdev,
    and the number of Input and Output Queues. Have the driver pass those as
    parameters, and defer the init_data processing into qdio_establish().
    This includes writing per-device(!) trace entries, and most of the
    sanity checks.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index c890848064fe..bf617b455428 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1220,27 +1220,21 @@ EXPORT_SYMBOL_GPL(qdio_free);
 
 /**
  * qdio_allocate - allocate qdio queues and associated data
- * @init_data: initialization data
+ * @cdev: associated ccw device
+ * @no_input_qs: allocate this number of Input Queues
+ * @no_output_qs: allocate this number of Output Queues
  */
-int qdio_allocate(struct qdio_initialize *init_data)
+int qdio_allocate(struct ccw_device *cdev, unsigned int no_input_qs,
+		  unsigned int no_output_qs)
 {
-	struct ccw_device *cdev = init_data->cdev;
 	struct subchannel_id schid;
 	struct qdio_irq *irq_ptr;
 
 	ccw_device_get_schid(cdev, &schid);
 	DBF_EVENT("qallocate:%4x", schid.sch_no);
 
-	if ((init_data->no_input_qs && !init_data->input_handler) ||
-	    (init_data->no_output_qs && !init_data->output_handler))
-		return -EINVAL;
-
-	if ((init_data->no_input_qs > QDIO_MAX_QUEUES_PER_IRQ) ||
-	    (init_data->no_output_qs > QDIO_MAX_QUEUES_PER_IRQ))
-		return -EINVAL;
-
-	if ((!init_data->input_sbal_addr_array) ||
-	    (!init_data->output_sbal_addr_array))
+	if (no_input_qs > QDIO_MAX_QUEUES_PER_IRQ ||
+	    no_output_qs > QDIO_MAX_QUEUES_PER_IRQ)
 		return -EINVAL;
 
 	/* irq_ptr must be in GFP_DMA since it contains ccw1.cda */
@@ -1250,9 +1244,12 @@ int qdio_allocate(struct qdio_initialize *init_data)
 
 	irq_ptr->cdev = cdev;
 	mutex_init(&irq_ptr->setup_mutex);
-	if (qdio_allocate_dbf(init_data, irq_ptr))
+	if (qdio_allocate_dbf(irq_ptr))
 		goto out_rel;
 
+	DBF_DEV_EVENT(DBF_ERR, irq_ptr, "alloc niq:%1u noq:%1u", no_input_qs,
+		      no_output_qs);
+
 	/*
 	 * Allocate a page for the chsc calls in qdio_establish.
 	 * Must be pre-allocated since a zfcp recovery will call
@@ -1268,8 +1265,7 @@ int qdio_allocate(struct qdio_initialize *init_data)
 	if (!irq_ptr->qdr)
 		goto out_rel;
 
-	if (qdio_allocate_qs(irq_ptr, init_data->no_input_qs,
-			     init_data->no_output_qs))
+	if (qdio_allocate_qs(irq_ptr, no_input_qs, no_output_qs))
 		goto out_rel;
 
 	INIT_LIST_HEAD(&irq_ptr->entry);
@@ -1305,6 +1301,25 @@ static void qdio_detect_hsicq(struct qdio_irq *irq_ptr)
 	DBF_EVENT("use_cq:%d", use_cq);
 }
 
+static void qdio_trace_init_data(struct qdio_irq *irq,
+				 struct qdio_initialize *data)
+{
+	DBF_DEV_EVENT(DBF_ERR, irq, "qfmt:%1u", data->q_format);
+	DBF_DEV_HEX(irq, data->adapter_name, 8, DBF_ERR);
+	DBF_DEV_EVENT(DBF_ERR, irq, "qpff%4x", data->qib_param_field_format);
+	DBF_DEV_HEX(irq, &data->qib_param_field, sizeof(void *), DBF_ERR);
+	DBF_DEV_HEX(irq, &data->input_slib_elements, sizeof(void *), DBF_ERR);
+	DBF_DEV_HEX(irq, &data->output_slib_elements, sizeof(void *), DBF_ERR);
+	DBF_DEV_EVENT(DBF_ERR, irq, "niq:%1u noq:%1u", data->no_input_qs,
+		      data->no_output_qs);
+	DBF_DEV_HEX(irq, &data->input_handler, sizeof(void *), DBF_ERR);
+	DBF_DEV_HEX(irq, &data->output_handler, sizeof(void *), DBF_ERR);
+	DBF_DEV_HEX(irq, &data->int_parm, sizeof(long), DBF_ERR);
+	DBF_DEV_HEX(irq, &data->input_sbal_addr_array, sizeof(void *), DBF_ERR);
+	DBF_DEV_HEX(irq, &data->output_sbal_addr_array, sizeof(void *),
+		    DBF_ERR);
+}
+
 /**
  * qdio_establish - establish queues on a qdio subchannel
  * @init_data: initialization data
@@ -1322,7 +1337,16 @@ int qdio_establish(struct qdio_initialize *init_data)
 	if (!irq_ptr)
 		return -ENODEV;
 
+	if ((init_data->no_input_qs && !init_data->input_handler) ||
+	    (init_data->no_output_qs && !init_data->output_handler))
+		return -EINVAL;
+
+	if (!init_data->input_sbal_addr_array ||
+	    !init_data->output_sbal_addr_array)
+		return -EINVAL;
+
 	mutex_lock(&irq_ptr->setup_mutex);
+	qdio_trace_init_data(irq_ptr, init_data);
 	qdio_setup_irq(irq_ptr, init_data);
 
 	rc = qdio_establish_thinint(irq_ptr);

commit ad0bf4eb91c2f9b93479b679e5472094ddb76da8
Merge: 5364abc57993 1058c163dc31
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Apr 4 09:45:50 2020 -0700

    Merge tag 's390-5.7-1' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 updates from Vasily Gorbik:
    
     - Update maintainers. Niklas Schnelle takes over zpci and Vineeth
       Vijayan common io code.
    
     - Extend cpuinfo to include topology information.
    
     - Add new extended counters for IBM z15 and sampling buffer allocation
       rework in perf code.
    
     - Add control over zeroing out memory during system restart.
    
     - CCA protected key block version 2 support and other
       fixes/improvements in crypto code.
    
     - Convert to new fallthrough; annotations.
    
     - Replace zero-length arrays with flexible-arrays.
    
     - QDIO debugfs and other small improvements.
    
     - Drop 2-level paging support optimization for compat tasks. Varios mm
       cleanups.
    
     - Remove broken and unused hibernate / power management support.
    
     - Remove fake numa support which does not bring any benefits.
    
     - Exclude offline CPUs from CPU topology masks to be more consistent
       with other architectures.
    
     - Prevent last branching instruction address leaking to userspace.
    
     - Other small various fixes and improvements all over the code.
    
    * tag 's390-5.7-1' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux: (57 commits)
      s390/mm: cleanup init_new_context() callback
      s390/mm: cleanup virtual memory constants usage
      s390/mm: remove page table downgrade support
      s390/qdio: set qdio_irq->cdev at allocation time
      s390/qdio: remove unused function declarations
      s390/ccwgroup: remove pm support
      s390/ap: remove power management code from ap bus and drivers
      s390/zcrypt: use kvmalloc instead of kmalloc for 256k alloc
      s390/mm: cleanup arch_get_unmapped_area() and friends
      s390/ism: remove pm support
      s390/cio: use fallthrough;
      s390/vfio: use fallthrough;
      s390/zcrypt: use fallthrough;
      s390: use fallthrough;
      s390/cpum_sf: Fix wrong page count in error message
      s390/diag: fix display of diagnose call statistics
      s390/ap: Remove ap device suspend and resume callbacks
      s390/pci: Improve handling of unset UID
      s390/pci: Fix zpci_alloc_domain() over allocation
      s390/qdio: pass ISC as parameter to chsc_sadc()
      ...

commit b2745655be3658cd422ba2b07cf19eb64e0c0eaf
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Fri Mar 20 14:00:00 2020 +0100

    s390/qdio: set qdio_irq->cdev at allocation time
    
    Set up qdio_irq->cdev right when the qdio_irq struct is allocated, so
    that all subsequent code can rely on this pointer.
    
    Then convert two helper functions to not pass a cdev parameter around.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 2886b95f4741..e93155dbe887 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1229,10 +1229,11 @@ EXPORT_SYMBOL_GPL(qdio_free);
  */
 int qdio_allocate(struct qdio_initialize *init_data)
 {
+	struct ccw_device *cdev = init_data->cdev;
 	struct subchannel_id schid;
 	struct qdio_irq *irq_ptr;
 
-	ccw_device_get_schid(init_data->cdev, &schid);
+	ccw_device_get_schid(cdev, &schid);
 	DBF_EVENT("qallocate:%4x", schid.sch_no);
 
 	if ((init_data->no_input_qs && !init_data->input_handler) ||
@@ -1252,6 +1253,7 @@ int qdio_allocate(struct qdio_initialize *init_data)
 	if (!irq_ptr)
 		goto out_err;
 
+	irq_ptr->cdev = cdev;
 	mutex_init(&irq_ptr->setup_mutex);
 	if (qdio_allocate_dbf(init_data, irq_ptr))
 		goto out_rel;
@@ -1276,7 +1278,7 @@ int qdio_allocate(struct qdio_initialize *init_data)
 		goto out_rel;
 
 	INIT_LIST_HEAD(&irq_ptr->entry);
-	init_data->cdev->private->qdio_data = irq_ptr;
+	cdev->private->qdio_data = irq_ptr;
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);
 	return 0;
 out_rel:
@@ -1372,8 +1374,8 @@ int qdio_establish(struct qdio_initialize *init_data)
 	qdio_init_buf_states(irq_ptr);
 
 	mutex_unlock(&irq_ptr->setup_mutex);
-	qdio_print_subchannel_info(irq_ptr, cdev);
-	qdio_setup_debug_entries(irq_ptr, cdev);
+	qdio_print_subchannel_info(irq_ptr);
+	qdio_setup_debug_entries(irq_ptr);
 	return 0;
 }
 EXPORT_SYMBOL_GPL(qdio_establish);

commit 0a6e634535f1b47b00501c0b563a827eb1f8ec8c
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Wed Mar 25 10:35:00 2020 +0100

    s390/qdio: extend polling support to multiple queues
    
    When the support for polling drivers was initially added, it only
    considered Input Queue 0. But as QDIO interrupts are actually for the
    full device and not a single queue, this doesn't really fit for
    configurations where multiple Input Queues are used.
    
    Rework the qdio code so that interrupts for a polling driver are not
    split up into actions for each queue. Instead deliver the interrupt as
    a single event, and let the driver decide which queue needs what action.
    
    When re-enabling the QDIO interrupt via qdio_start_irq(), this means
    that the qdio code needs to
    (1) put _all_ eligible queues back into a state where they raise IRQs,
    (2) and afterwards check _all_ eligible queues for new work to bridge
        the race window.
    
    On the qeth side of things (as the only qdio polling driver), we can now
    add CQ polling support to the main NAPI poll routine. It doesn't consume
    NAPI budget, and to avoid hogging the CPU we yield control after
    completing one full queue worth of buffers.
    The subsequent qdio_start_irq() will check for any additional work, and
    have us re-schedule the NAPI instance accordingly.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Acked-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 3475317c42e5..02ced5949287 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -950,19 +950,14 @@ static void qdio_int_handler_pci(struct qdio_irq *irq_ptr)
 	if (unlikely(irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))
 		return;
 
-	for_each_input_queue(irq_ptr, q, i) {
-		if (q->u.in.queue_start_poll) {
-			/* skip if polling is enabled or already in work */
-			if (test_and_set_bit(QDIO_QUEUE_IRQS_DISABLED,
-				     &q->u.in.queue_irq_state)) {
-				QDIO_PERF_STAT_INC(irq_ptr, int_discarded);
-				continue;
-			}
-			q->u.in.queue_start_poll(q->irq_ptr->cdev, q->nr,
-						 q->irq_ptr->int_parm);
-		} else {
+	if (irq_ptr->irq_poll) {
+		if (!test_and_set_bit(QDIO_IRQ_DISABLED, &irq_ptr->poll_state))
+			irq_ptr->irq_poll(irq_ptr->cdev, irq_ptr->int_parm);
+		else
+			QDIO_PERF_STAT_INC(irq_ptr, int_discarded);
+	} else {
+		for_each_input_queue(irq_ptr, q, i)
 			tasklet_schedule(&q->tasklet);
-		}
 	}
 
 	if (!pci_out_supported(irq_ptr) || !irq_ptr->scan_threshold)
@@ -1610,24 +1605,26 @@ EXPORT_SYMBOL_GPL(do_QDIO);
 /**
  * qdio_start_irq - process input buffers
  * @cdev: associated ccw_device for the qdio subchannel
- * @nr: input queue number
  *
  * Return codes
  *   0 - success
  *   1 - irqs not started since new data is available
  */
-int qdio_start_irq(struct ccw_device *cdev, int nr)
+int qdio_start_irq(struct ccw_device *cdev)
 {
 	struct qdio_q *q;
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
+	unsigned int i;
 
 	if (!irq_ptr)
 		return -ENODEV;
-	q = irq_ptr->input_qs[nr];
 
 	clear_nonshared_ind(irq_ptr);
-	qdio_stop_polling(q);
-	clear_bit(QDIO_QUEUE_IRQS_DISABLED, &q->u.in.queue_irq_state);
+
+	for_each_input_queue(irq_ptr, q, i)
+		qdio_stop_polling(q);
+
+	clear_bit(QDIO_IRQ_DISABLED, &irq_ptr->poll_state);
 
 	/*
 	 * We need to check again to not lose initiative after
@@ -1635,13 +1632,16 @@ int qdio_start_irq(struct ccw_device *cdev, int nr)
 	 */
 	if (test_nonshared_ind(irq_ptr))
 		goto rescan;
-	if (!qdio_inbound_q_done(q, q->first_to_check))
-		goto rescan;
+
+	for_each_input_queue(irq_ptr, q, i) {
+		if (!qdio_inbound_q_done(q, q->first_to_check))
+			goto rescan;
+	}
+
 	return 0;
 
 rescan:
-	if (test_and_set_bit(QDIO_QUEUE_IRQS_DISABLED,
-			     &q->u.in.queue_irq_state))
+	if (test_and_set_bit(QDIO_IRQ_DISABLED, &irq_ptr->poll_state))
 		return 0;
 	else
 		return 1;
@@ -1729,23 +1729,19 @@ EXPORT_SYMBOL(qdio_get_next_buffers);
 /**
  * qdio_stop_irq - disable interrupt processing for the device
  * @cdev: associated ccw_device for the qdio subchannel
- * @nr: input queue number
  *
  * Return codes
  *   0 - interrupts were already disabled
  *   1 - interrupts successfully disabled
  */
-int qdio_stop_irq(struct ccw_device *cdev, int nr)
+int qdio_stop_irq(struct ccw_device *cdev)
 {
-	struct qdio_q *q;
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 
 	if (!irq_ptr)
 		return -ENODEV;
-	q = irq_ptr->input_qs[nr];
 
-	if (test_and_set_bit(QDIO_QUEUE_IRQS_DISABLED,
-			     &q->u.in.queue_irq_state))
+	if (test_and_set_bit(QDIO_IRQ_DISABLED, &irq_ptr->poll_state))
 		return 0;
 	else
 		return 1;

commit 014816b66218d9f5f90e6d92951abc9d3749b4cd
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Mon Feb 10 14:58:07 2020 +0100

    s390/qdio: reduce access to cdev->private->qdio_data
    
    Remove all usage of cdev->private->qdio_data that's buried deep in
    internal code. This should only be used by the exported driver API,
    which can then pass around a proper qdio_irq pointer.
    
    Also trivially merge some initializations with their definitions.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 3475317c42e5..2886b95f4741 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1105,9 +1105,8 @@ int qdio_get_ssqd_desc(struct ccw_device *cdev,
 }
 EXPORT_SYMBOL_GPL(qdio_get_ssqd_desc);
 
-static void qdio_shutdown_queues(struct ccw_device *cdev)
+static void qdio_shutdown_queues(struct qdio_irq *irq_ptr)
 {
-	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 	struct qdio_q *q;
 	int i;
 
@@ -1155,7 +1154,7 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_STOPPED);
 
 	tiqdio_remove_device(irq_ptr);
-	qdio_shutdown_queues(cdev);
+	qdio_shutdown_queues(irq_ptr);
 	qdio_shutdown_debug_entries(irq_ptr);
 
 	/* cleanup subchannel */
@@ -1316,19 +1315,18 @@ static void qdio_detect_hsicq(struct qdio_irq *irq_ptr)
 int qdio_establish(struct qdio_initialize *init_data)
 {
 	struct ccw_device *cdev = init_data->cdev;
+	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 	struct subchannel_id schid;
-	struct qdio_irq *irq_ptr;
 	int rc;
 
 	ccw_device_get_schid(cdev, &schid);
 	DBF_EVENT("qestablish:%4x", schid.sch_no);
 
-	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)
 		return -ENODEV;
 
 	mutex_lock(&irq_ptr->setup_mutex);
-	qdio_setup_irq(init_data);
+	qdio_setup_irq(irq_ptr, init_data);
 
 	rc = qdio_establish_thinint(irq_ptr);
 	if (rc) {
@@ -1386,14 +1384,13 @@ EXPORT_SYMBOL_GPL(qdio_establish);
  */
 int qdio_activate(struct ccw_device *cdev)
 {
+	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 	struct subchannel_id schid;
-	struct qdio_irq *irq_ptr;
 	int rc;
 
 	ccw_device_get_schid(cdev, &schid);
 	DBF_EVENT("qactivate:%4x", schid.sch_no);
 
-	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)
 		return -ENODEV;
 

commit 0b6f499022b6a87d04f56edd2bf863ea76923206
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Mon Nov 25 14:18:29 2019 +0100

    s390/qdio: simplify ACK tracking
    
    Current code uses a 'polling' flag to keep track of whether an Input
    Queue has any ACKed SBALs. QEBSM devices might have multiple ACKed
    SBALs, and those are tracked separately with 'ack_count'.
    
    By also setting ack_count for non-QEBSM devices (to a fixed value of 1),
    we can use 'ack_count != 0' as replacement for the polling flag.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index f8b897b7e78b..3475317c42e5 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -393,19 +393,15 @@ int debug_get_buf_state(struct qdio_q *q, unsigned int bufnr,
 
 static inline void qdio_stop_polling(struct qdio_q *q)
 {
-	if (!q->u.in.polling)
+	if (!q->u.in.ack_count)
 		return;
 
-	q->u.in.polling = 0;
 	qperf_inc(q, stop_polling);
 
 	/* show the card that we are not polling anymore */
-	if (is_qebsm(q)) {
-		set_buf_states(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT,
-			       q->u.in.ack_count);
-		q->u.in.ack_count = 0;
-	} else
-		set_buf_state(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT);
+	set_buf_states(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT,
+		       q->u.in.ack_count);
+	q->u.in.ack_count = 0;
 }
 
 static inline void account_sbals(struct qdio_q *q, unsigned int count)
@@ -451,8 +447,7 @@ static inline void inbound_primed(struct qdio_q *q, unsigned int start,
 
 	/* for QEBSM the ACK was already set by EQBS */
 	if (is_qebsm(q)) {
-		if (!q->u.in.polling) {
-			q->u.in.polling = 1;
+		if (!q->u.in.ack_count) {
 			q->u.in.ack_count = count;
 			q->u.in.ack_start = start;
 			return;
@@ -471,12 +466,12 @@ static inline void inbound_primed(struct qdio_q *q, unsigned int start,
 	 * or by the next inbound run.
 	 */
 	new = add_buf(start, count - 1);
-	if (q->u.in.polling) {
+	if (q->u.in.ack_count) {
 		/* reset the previous ACK but first set the new one */
 		set_buf_state(q, new, SLSB_P_INPUT_ACK);
 		set_buf_state(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT);
 	} else {
-		q->u.in.polling = 1;
+		q->u.in.ack_count = 1;
 		set_buf_state(q, new, SLSB_P_INPUT_ACK);
 	}
 
@@ -1479,13 +1474,12 @@ static int handle_inbound(struct qdio_q *q, unsigned int callflags,
 
 	qperf_inc(q, inbound_call);
 
-	if (!q->u.in.polling)
+	if (!q->u.in.ack_count)
 		goto set;
 
 	/* protect against stop polling setting an ACK for an emptied slsb */
 	if (count == QDIO_MAX_BUFFERS_PER_Q) {
 		/* overwriting everything, just delete polling status */
-		q->u.in.polling = 0;
 		q->u.in.ack_count = 0;
 		goto set;
 	} else if (buf_in_between(q->u.in.ack_start, bufnr, count)) {
@@ -1495,15 +1489,14 @@ static int handle_inbound(struct qdio_q *q, unsigned int callflags,
 			diff = sub_buf(diff, q->u.in.ack_start);
 			q->u.in.ack_count -= diff;
 			if (q->u.in.ack_count <= 0) {
-				q->u.in.polling = 0;
 				q->u.in.ack_count = 0;
 				goto set;
 			}
 			q->u.in.ack_start = add_buf(q->u.in.ack_start, diff);
+		} else {
+			/* the only ACK will be deleted */
+			q->u.in.ack_count = 0;
 		}
-		else
-			/* the only ACK will be deleted, so stop polling */
-			q->u.in.polling = 0;
 	}
 
 set:

commit 386403a115f95997c2715691226e11a7b5cffcfd
Merge: 642356cb5f4a 622dc5ad8052
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 25 20:02:57 2019 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net-next
    
    Pull networking updates from David Miller:
     "Another merge window, another pull full of stuff:
    
       1) Support alternative names for network devices, from Jiri Pirko.
    
       2) Introduce per-netns netdev notifiers, also from Jiri Pirko.
    
       3) Support MSG_PEEK in vsock/virtio, from Matias Ezequiel Vara
          Larsen.
    
       4) Allow compiling out the TLS TOE code, from Jakub Kicinski.
    
       5) Add several new tracepoints to the kTLS code, also from Jakub.
    
       6) Support set channels ethtool callback in ena driver, from Sameeh
          Jubran.
    
       7) New SCTP events SCTP_ADDR_ADDED, SCTP_ADDR_REMOVED,
          SCTP_ADDR_MADE_PRIM, and SCTP_SEND_FAILED_EVENT. From Xin Long.
    
       8) Add XDP support to mvneta driver, from Lorenzo Bianconi.
    
       9) Lots of netfilter hw offload fixes, cleanups and enhancements,
          from Pablo Neira Ayuso.
    
      10) PTP support for aquantia chips, from Egor Pomozov.
    
      11) Add UDP segmentation offload support to igb, ixgbe, and i40e. From
          Josh Hunt.
    
      12) Add smart nagle to tipc, from Jon Maloy.
    
      13) Support L2 field rewrite by TC offloads in bnxt_en, from Venkat
          Duvvuru.
    
      14) Add a flow mask cache to OVS, from Tonghao Zhang.
    
      15) Add XDP support to ice driver, from Maciej Fijalkowski.
    
      16) Add AF_XDP support to ice driver, from Krzysztof Kazimierczak.
    
      17) Support UDP GSO offload in atlantic driver, from Igor Russkikh.
    
      18) Support it in stmmac driver too, from Jose Abreu.
    
      19) Support TIPC encryption and auth, from Tuong Lien.
    
      20) Introduce BPF trampolines, from Alexei Starovoitov.
    
      21) Make page_pool API more numa friendly, from Saeed Mahameed.
    
      22) Introduce route hints to ipv4 and ipv6, from Paolo Abeni.
    
      23) Add UDP segmentation offload to cxgb4, Rahul Lakkireddy"
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net-next: (1857 commits)
      libbpf: Fix usage of u32 in userspace code
      mm: Implement no-MMU variant of vmalloc_user_node_flags
      slip: Fix use-after-free Read in slip_open
      net: dsa: sja1105: fix sja1105_parse_rgmii_delays()
      macvlan: schedule bc_work even if error
      enetc: add support Credit Based Shaper(CBS) for hardware offload
      net: phy: add helpers phy_(un)lock_mdio_bus
      mdio_bus: don't use managed reset-controller
      ax88179_178a: add ethtool_op_get_ts_info()
      mlxsw: spectrum_router: Fix use of uninitialized adjacency index
      mlxsw: spectrum_router: After underlay moves, demote conflicting tunnels
      bpf: Simplify __bpf_arch_text_poke poke type handling
      bpf: Introduce BPF_TRACE_x helper for the tracing tests
      bpf: Add bpf_jit_blinding_enabled for !CONFIG_BPF_JIT
      bpf, testing: Add various tail call test cases
      bpf, x86: Emit patchable direct jump as tail call
      bpf: Constant map key tracking for prog array pokes
      bpf: Add poke dependency tracking for prog array maps
      bpf: Add initial poke descriptor table for jit images
      bpf: Move owner type, jited info into array auxiliary data
      ...

commit b7f143d093e10cd39ae4a22d2f57ac853017f49e
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Thu Oct 31 13:42:14 2019 +0100

    s390/qdio: implement IQD Multi-Write
    
    This allows IQD drivers to send out multiple SBALs with a single SIGA
    instruction.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Alexandra Winter <wintera@linux.ibm.com>
    Acked-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 5b63c505a2f7..7368407030b0 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -310,18 +310,19 @@ static inline int qdio_siga_sync_q(struct qdio_q *q)
 		return qdio_siga_sync(q, q->mask, 0);
 }
 
-static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit,
-	unsigned long aob)
+static int qdio_siga_output(struct qdio_q *q, unsigned int count,
+			    unsigned int *busy_bit, unsigned long aob)
 {
 	unsigned long schid = *((u32 *) &q->irq_ptr->schid);
 	unsigned int fc = QDIO_SIGA_WRITE;
 	u64 start_time = 0;
 	int retries = 0, cc;
-	unsigned long laob = 0;
 
-	if (aob) {
-		fc = QDIO_SIGA_WRITEQ;
-		laob = aob;
+	if (queue_type(q) == QDIO_IQDIO_QFMT && !multicast_outbound(q)) {
+		if (count > 1)
+			fc = QDIO_SIGA_WRITEM;
+		else if (aob)
+			fc = QDIO_SIGA_WRITEQ;
 	}
 
 	if (is_qebsm(q)) {
@@ -329,7 +330,7 @@ static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit,
 		fc |= QDIO_SIGA_QEBSM_FLAG;
 	}
 again:
-	cc = do_siga_output(schid, q->mask, busy_bit, fc, laob);
+	cc = do_siga_output(schid, q->mask, busy_bit, fc, aob);
 
 	/* hipersocket busy condition */
 	if (unlikely(*busy_bit)) {
@@ -781,7 +782,8 @@ static inline int qdio_outbound_q_moved(struct qdio_q *q, unsigned int start)
 	return count;
 }
 
-static int qdio_kick_outbound_q(struct qdio_q *q, unsigned long aob)
+static int qdio_kick_outbound_q(struct qdio_q *q, unsigned int count,
+				unsigned long aob)
 {
 	int retries = 0, cc;
 	unsigned int busy_bit;
@@ -793,7 +795,7 @@ static int qdio_kick_outbound_q(struct qdio_q *q, unsigned long aob)
 retry:
 	qperf_inc(q, siga_write);
 
-	cc = qdio_siga_output(q, &busy_bit, aob);
+	cc = qdio_siga_output(q, count, &busy_bit, aob);
 	switch (cc) {
 	case 0:
 		break;
@@ -1526,7 +1528,7 @@ static int handle_inbound(struct qdio_q *q, unsigned int callflags,
  * @count: how many buffers are filled
  */
 static int handle_outbound(struct qdio_q *q, unsigned int callflags,
-			   int bufnr, int count)
+			   unsigned int bufnr, unsigned int count)
 {
 	const unsigned int scan_threshold = q->irq_ptr->scan_threshold;
 	unsigned char state = 0;
@@ -1549,13 +1551,10 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 	if (queue_type(q) == QDIO_IQDIO_QFMT) {
 		unsigned long phys_aob = 0;
 
-		/* One SIGA-W per buffer required for unicast HSI */
-		WARN_ON_ONCE(count > 1 && !multicast_outbound(q));
-
-		if (q->u.out.use_cq)
+		if (q->u.out.use_cq && count == 1)
 			phys_aob = qdio_aob_for_buffer(&q->u.out, bufnr);
 
-		rc = qdio_kick_outbound_q(q, phys_aob);
+		rc = qdio_kick_outbound_q(q, count, phys_aob);
 	} else if (need_siga_sync(q)) {
 		rc = qdio_siga_sync_q(q);
 	} else if (count < QDIO_MAX_BUFFERS_PER_Q &&
@@ -1564,7 +1563,7 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 		/* The previous buffer is not processed yet, tack on. */
 		qperf_inc(q, fast_requeue);
 	} else {
-		rc = qdio_kick_outbound_q(q, 0);
+		rc = qdio_kick_outbound_q(q, count, 0);
 	}
 
 	/* Let drivers implement their own completion scanning: */

commit 6d76c898d82d94d066d870ba0180ec79bd3ceea5
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Fri Oct 4 11:07:13 2019 +0200

    s390/qdio: don't attempt IRQ avoidance on Output SBALs
    
    Output interrupts are not subject to SLSB-based avoidance, so remove the
    gratuitous SLSB updates for Output SBALs in ERROR state.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index d0c85862c258..2b797cbb9d57 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -423,9 +423,6 @@ static inline void account_sbals(struct qdio_q *q, unsigned int count)
 static void process_buffer_error(struct qdio_q *q, unsigned int start,
 				 int count)
 {
-	unsigned char state = (q->is_input_q) ? SLSB_P_INPUT_NOT_INIT :
-					SLSB_P_OUTPUT_NOT_INIT;
-
 	q->qdio_error = QDIO_ERROR_SLSB_STATE;
 
 	/* special handling for no target buffer empty */
@@ -433,7 +430,7 @@ static void process_buffer_error(struct qdio_q *q, unsigned int start,
 	    q->sbal[start]->element[15].sflags == 0x10) {
 		qperf_inc(q, target_full);
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "OUTFULL FTC:%02x", start);
-		goto set;
+		return;
 	}
 
 	DBF_ERROR("%4x BUF ERROR", SCH_NO(q));
@@ -442,13 +439,6 @@ static void process_buffer_error(struct qdio_q *q, unsigned int start,
 	DBF_ERROR("F14:%2x F15:%2x",
 		  q->sbal[start]->element[14].sflags,
 		  q->sbal[start]->element[15].sflags);
-
-set:
-	/*
-	 * Interrupts may be avoided as long as the error is present
-	 * so change the buffer state immediately to avoid starvation.
-	 */
-	set_buf_states(q, start, state, count);
 }
 
 static inline void inbound_primed(struct qdio_q *q, unsigned int start,
@@ -530,6 +520,11 @@ static int get_inbound_buffer_frontier(struct qdio_q *q, unsigned int start)
 		return count;
 	case SLSB_P_INPUT_ERROR:
 		process_buffer_error(q, start, count);
+		/*
+		 * Interrupts may be avoided as long as the error is present
+		 * so change the buffer state immediately to avoid starvation.
+		 */
+		set_buf_states(q, start, SLSB_P_INPUT_NOT_INIT, count);
 		if (atomic_sub_return(count, &q->nr_buf_used) == 0)
 			qperf_inc(q, inbound_queue_full);
 		if (q->irq_ptr->perf_stat_enabled)

commit 94c43bdaa0073c43a0a1b12e65c51070f02a0642
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Tue Jul 23 11:55:27 2019 +0200

    s390/qdio: simplify thinint device registration
    
    On an interrupt, tiqdio_thinint_handler() walks a list of all objects
    that might require attention, and checks their DSCI. This list is
    awkwardly built from Input Queues, even though the IRQs are per-device
    and the queue is then only used to dereference its qdio_irq parent.
    
    To simplify the logic, change the code so that tiq_list contains
    qdio_irq entries.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 8512255ddc33..d0c85862c258 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1162,7 +1162,7 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 	 */
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_STOPPED);
 
-	tiqdio_remove_input_queues(irq_ptr);
+	tiqdio_remove_device(irq_ptr);
 	qdio_shutdown_queues(cdev);
 	qdio_shutdown_debug_entries(irq_ptr);
 
@@ -1284,6 +1284,7 @@ int qdio_allocate(struct qdio_initialize *init_data)
 			     init_data->no_output_qs))
 		goto out_rel;
 
+	INIT_LIST_HEAD(&irq_ptr->entry);
 	init_data->cdev->private->qdio_data = irq_ptr;
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);
 	return 0;
@@ -1428,7 +1429,7 @@ int qdio_activate(struct ccw_device *cdev)
 	}
 
 	if (is_thinint_irq(irq_ptr))
-		tiqdio_add_input_queues(irq_ptr);
+		tiqdio_add_device(irq_ptr);
 
 	/* wait for subchannel to become active */
 	msleep(5);

commit 4611281021e9835da825b79ba9b62a31670e0791
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Mon Sep 30 15:42:35 2019 +0200

    s390/qdio: add statistics helper macro
    
    qperf_inc() takes a queue as input, but actually updates the statistics
    in its qdio_irq parent.
    In some contexts we already have access to the qdio_irq struct, and can
    avoid the additional dereference.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 675f00235776..8512255ddc33 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -963,7 +963,7 @@ static void qdio_int_handler_pci(struct qdio_irq *irq_ptr)
 			/* skip if polling is enabled or already in work */
 			if (test_and_set_bit(QDIO_QUEUE_IRQS_DISABLED,
 				     &q->u.in.queue_irq_state)) {
-				qperf_inc(q, int_discarded);
+				QDIO_PERF_STAT_INC(irq_ptr, int_discarded);
 				continue;
 			}
 			q->u.in.queue_start_poll(q->irq_ptr->cdev, q->nr,

commit 4e79a5d41e8b053d1448ed4681a3db0a28f80c99
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Mon Aug 19 17:20:05 2019 +0200

    s390/qdio: reduce log level for EQBS partial
    
    Partial EQBS completion is no significant event, and the WARN ends up
    spamming the debug logs for no good reason.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 5b63c505a2f7..675f00235776 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -131,7 +131,7 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 	case 96:
 		/* not all buffers processed */
 		qperf_inc(q, eqbs_partial);
-		DBF_DEV_EVENT(DBF_WARN, q->irq_ptr, "EQBS part:%02x",
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "EQBS part:%02x",
 			tmp_count);
 		return count - tmp_count;
 	case 97:

commit 313dc689b16c08b081939ee9b87dac3736c780e3
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Fri Aug 23 11:48:48 2019 +0200

    s390/qdio: let drivers opt-out from Output Queue scanning
    
    If a driver wants to use the new Output Queue poll code, then the qdio
    layer must disable its internal Queue scanning. Let the driver select
    this mode by passing a special scan_threshold of 0.
    
    As the scan_threshold is the same for all Output Queues, also move it
    into the main qdio_irq struct. This allows for fast opt-out checking, a
    driver is expected to operate either _all_ or none of its Output Queues
    in polling mode.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Acked-by: Vasily Gorbik <gor@linux.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 5efba0d29190..5b63c505a2f7 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -880,7 +880,7 @@ static inline void qdio_check_outbound_pci_queues(struct qdio_irq *irq)
 	struct qdio_q *out;
 	int i;
 
-	if (!pci_out_supported(irq))
+	if (!pci_out_supported(irq) || !irq->scan_threshold)
 		return;
 
 	for_each_output_queue(irq, out, i)
@@ -973,7 +973,7 @@ static void qdio_int_handler_pci(struct qdio_irq *irq_ptr)
 		}
 	}
 
-	if (!pci_out_supported(irq_ptr))
+	if (!pci_out_supported(irq_ptr) || !irq_ptr->scan_threshold)
 		return;
 
 	for_each_output_queue(irq_ptr, q, i) {
@@ -1528,6 +1528,7 @@ static int handle_inbound(struct qdio_q *q, unsigned int callflags,
 static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 			   int bufnr, int count)
 {
+	const unsigned int scan_threshold = q->irq_ptr->scan_threshold;
 	unsigned char state = 0;
 	int used, rc = 0;
 
@@ -1566,8 +1567,12 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 		rc = qdio_kick_outbound_q(q, 0);
 	}
 
+	/* Let drivers implement their own completion scanning: */
+	if (!scan_threshold)
+		return rc;
+
 	/* in case of SIGA errors we must process the error immediately */
-	if (used >= q->u.out.scan_threshold || rc)
+	if (used >= scan_threshold || rc)
 		qdio_tasklet_schedule(q);
 	else
 		/* free the SBALs in case of no further traffic */

commit 7c47f5afdeef763599f1ae22d29b8c3904c58315
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Fri Aug 23 11:48:47 2019 +0200

    s390/qdio: enable drivers to poll for Output completions
    
    While commit d36deae75011 ("qdio: extend API to allow polling") enhanced
    the qdio layer so that drivers can poll their Input Queues, we don't
    have the corresponding infrastructure for Output Queues yet.
    
    Factor out a helper that scans a single QDIO Queue, so that qeth can
    implement TX NAPI on top of it.
    While doing so, remove the duplicated tracking of the next-to-scan index
    (q->first_to_check vs q->first_to_kick) in this code path.
    
    qdio_handle_aobs() needs to move slightly upwards in the code hierarchy,
    so that it's still called from the polling path.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Acked-by: Vasily Gorbik <gor@linux.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 4142c85e77d8..5efba0d29190 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -647,8 +647,6 @@ static void qdio_kick_handler(struct qdio_q *q, unsigned int count)
 		qperf_inc(q, outbound_handler);
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "koh: s:%02x c:%02x",
 			      start, count);
-		if (q->u.out.use_cq)
-			qdio_handle_aobs(q, start, count);
 	}
 
 	q->handler(q->irq_ptr->cdev, q->qdio_error, q->nr, start, count,
@@ -774,8 +772,11 @@ static inline int qdio_outbound_q_moved(struct qdio_q *q, unsigned int start)
 
 	count = get_outbound_buffer_frontier(q, start);
 
-	if (count)
+	if (count) {
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out moved:%1d", q->nr);
+		if (q->u.out.use_cq)
+			qdio_handle_aobs(q, start, count);
+	}
 
 	return count;
 }
@@ -1655,6 +1656,44 @@ int qdio_start_irq(struct ccw_device *cdev, int nr)
 }
 EXPORT_SYMBOL(qdio_start_irq);
 
+static int __qdio_inspect_queue(struct qdio_q *q, unsigned int *bufnr,
+				unsigned int *error)
+{
+	unsigned int start = q->first_to_check;
+	int count;
+
+	count = q->is_input_q ? qdio_inbound_q_moved(q, start) :
+				qdio_outbound_q_moved(q, start);
+	if (count == 0)
+		return 0;
+
+	*bufnr = start;
+	*error = q->qdio_error;
+
+	/* for the next time */
+	q->first_to_check = add_buf(start, count);
+	q->qdio_error = 0;
+
+	return count;
+}
+
+int qdio_inspect_queue(struct ccw_device *cdev, unsigned int nr, bool is_input,
+		       unsigned int *bufnr, unsigned int *error)
+{
+	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
+	struct qdio_q *q;
+
+	if (!irq_ptr)
+		return -ENODEV;
+	q = is_input ? irq_ptr->input_qs[nr] : irq_ptr->output_qs[nr];
+
+	if (need_siga_sync(q))
+		qdio_siga_sync_q(q);
+
+	return __qdio_inspect_queue(q, bufnr, error);
+}
+EXPORT_SYMBOL_GPL(qdio_inspect_queue);
+
 /**
  * qdio_get_next_buffers - process input buffers
  * @cdev: associated ccw_device for the qdio subchannel
@@ -1672,13 +1711,10 @@ int qdio_get_next_buffers(struct ccw_device *cdev, int nr, int *bufnr,
 {
 	struct qdio_q *q;
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
-	unsigned int start;
-	int count;
 
 	if (!irq_ptr)
 		return -ENODEV;
 	q = irq_ptr->input_qs[nr];
-	start = q->first_to_check;
 
 	/*
 	 * Cannot rely on automatic sync after interrupt since queues may
@@ -1689,25 +1725,11 @@ int qdio_get_next_buffers(struct ccw_device *cdev, int nr, int *bufnr,
 
 	qdio_check_outbound_pci_queues(irq_ptr);
 
-	count = qdio_inbound_q_moved(q, start);
-	if (count == 0)
-		return 0;
-
-	start = add_buf(start, count);
-	q->first_to_check = start;
-
 	/* Note: upper-layer MUST stop processing immediately here ... */
 	if (unlikely(q->irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))
 		return -EIO;
 
-	*bufnr = q->first_to_kick;
-	*error = q->qdio_error;
-
-	/* for the next time */
-	q->first_to_kick = add_buf(q->first_to_kick, count);
-	q->qdio_error = 0;
-
-	return count;
+	return __qdio_inspect_queue(q, bufnr, error);
 }
 EXPORT_SYMBOL(qdio_get_next_buffers);
 

commit 69e96207ebf90ff8d5bac457134b0d4569f6634e
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Mon Jul 1 14:19:29 2019 +0200

    s390/qdio: restrict QAOB usage to IQD unicast queues
    
    The IQD mcast queue doesn't support QAOB mode, so skip the
    qdio_enable_async_operation() setup call for this queue. This avoids
    the allocation of an unneeded QAOB pointer array, and sets up q->use_cq
    properly so that drivers are prohibited from using QAOBs for mcast
    traffic.
    
    Take this opportunity to streamline the q->use_cq and aob != 0 checks.
    The path to qdio_siga_output() is straight-forward, we don't need to
    worry about being called with bad operands.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 7f5adf02f095..4142c85e77d8 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -319,9 +319,7 @@ static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit,
 	int retries = 0, cc;
 	unsigned long laob = 0;
 
-	WARN_ON_ONCE(aob && ((queue_type(q) != QDIO_IQDIO_QFMT) ||
-			     !q->u.out.use_cq));
-	if (q->u.out.use_cq && aob != 0) {
+	if (aob) {
 		fc = QDIO_SIGA_WRITEQ;
 		laob = aob;
 	}
@@ -621,9 +619,6 @@ static inline unsigned long qdio_aob_for_buffer(struct qdio_output_q *q,
 {
 	unsigned long phys_aob = 0;
 
-	if (!q->use_cq)
-		return 0;
-
 	if (!q->aobs[bufnr]) {
 		struct qaob *aob = qdio_allocate_aob();
 		q->aobs[bufnr] = aob;
@@ -1308,6 +1303,8 @@ static void qdio_detect_hsicq(struct qdio_irq *irq_ptr)
 
 	for_each_output_queue(irq_ptr, q, i) {
 		if (use_cq) {
+			if (multicast_outbound(q))
+				continue;
 			if (qdio_enable_async_operation(&q->u.out) < 0) {
 				use_cq = 0;
 				continue;
@@ -1553,7 +1550,8 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 		/* One SIGA-W per buffer required for unicast HSI */
 		WARN_ON_ONCE(count > 1 && !multicast_outbound(q));
 
-		phys_aob = qdio_aob_for_buffer(&q->u.out, bufnr);
+		if (q->u.out.use_cq)
+			phys_aob = qdio_aob_for_buffer(&q->u.out, bufnr);
 
 		rc = qdio_kick_outbound_q(q, phys_aob);
 	} else if (need_siga_sync(q)) {

commit a6ec414a4dd529eeac5c3ea51c661daba3397108
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Thu Jul 11 18:17:36 2019 +0200

    s390/qdio: add sanity checks to the fast-requeue path
    
    If the device driver were to send out a full queue's worth of SBALs,
    current code would end up discovering the last of those SBALs as PRIMED
    and erroneously skip the SIGA-w. This immediately stalls the queue.
    
    Add a check to not attempt fast-requeue in this case. While at it also
    make sure that the state of the previous SBAL was successfully extracted
    before inspecting it.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Jens Remus <jremus@linux.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 730c4e68094b..7f5adf02f095 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1558,13 +1558,13 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 		rc = qdio_kick_outbound_q(q, phys_aob);
 	} else if (need_siga_sync(q)) {
 		rc = qdio_siga_sync_q(q);
+	} else if (count < QDIO_MAX_BUFFERS_PER_Q &&
+		   get_buf_state(q, prev_buf(bufnr), &state, 0) > 0 &&
+		   state == SLSB_CU_OUTPUT_PRIMED) {
+		/* The previous buffer is not processed yet, tack on. */
+		qperf_inc(q, fast_requeue);
 	} else {
-		/* try to fast requeue buffers */
-		get_buf_state(q, prev_buf(bufnr), &state, 0);
-		if (state != SLSB_CU_OUTPUT_PRIMED)
-			rc = qdio_kick_outbound_q(q, 0);
-		else
-			qperf_inc(q, fast_requeue);
+		rc = qdio_kick_outbound_q(q, 0);
 	}
 
 	/* in case of SIGA errors we must process the error immediately */

commit 04310324c6f482921c071444833e70fe861b73d9
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Mon Jun 3 07:47:04 2019 +0200

    s390/qdio: handle PENDING state for QEBSM devices
    
    When a CQ-enabled device uses QEBSM for SBAL state inspection,
    get_buf_states() can return the PENDING state for an Output Queue.
    get_outbound_buffer_frontier() isn't prepared for this, and any PENDING
    buffer will permanently stall all further completion processing on this
    Queue.
    
    This isn't a concern for non-QEBSM devices, as get_buf_states() for such
    devices will manually turn PENDING buffers into EMPTY ones.
    
    Fixes: 104ea556ee7f ("qdio: support asynchronous delivery of storage blocks")
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 7b7620de2acd..730c4e68094b 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -736,6 +736,7 @@ static int get_outbound_buffer_frontier(struct qdio_q *q, unsigned int start)
 
 	switch (state) {
 	case SLSB_P_OUTPUT_EMPTY:
+	case SLSB_P_OUTPUT_PENDING:
 		/* the adapter got it */
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr,
 			"out empty:%1d %02x", q->nr, count);

commit a698e1372800b7e5dde2e461c1d3948c2e06032a
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Fri Apr 26 09:37:41 2019 +0200

    s390/qdio: optimize state inspection of HW-owned SBALs
    
    When get_buf_states() gets called with count > 1, it scans the
    corresponding number of SBAL states until it encounters a mismatch.
    
    But when these SBALs are in a HW-owned state, the callers don't actually
    care _how many_ such SBALs are on the queue. If we can't process the
    first SBAL, we can't process any of the following SBALs either. So when
    the first SBAL is HW-owned, skip the scan of the remaining SBALs and
    thus save some CPU time.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Jens Remus <jremus@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index be93172555ec..7b7620de2acd 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -205,17 +205,22 @@ static inline int get_buf_states(struct qdio_q *q, unsigned int bufnr,
 				 int auto_ack, int merge_pending)
 {
 	unsigned char __state = 0;
-	int i;
+	int i = 1;
 
 	if (is_qebsm(q))
 		return qdio_do_eqbs(q, state, bufnr, count, auto_ack);
 
 	/* get initial state: */
 	__state = q->slsb.val[bufnr];
+
+	/* Bail out early if there is no work on the queue: */
+	if (__state & SLSB_OWNER_CU)
+		goto out;
+
 	if (merge_pending && __state == SLSB_P_OUTPUT_PENDING)
 		__state = SLSB_P_OUTPUT_EMPTY;
 
-	for (i = 1; i < count; i++) {
+	for (; i < count; i++) {
 		bufnr = next_buf(bufnr);
 
 		/* merge PENDING into EMPTY: */
@@ -228,6 +233,8 @@ static inline int get_buf_states(struct qdio_q *q, unsigned int bufnr,
 		if (q->slsb.val[bufnr] != __state)
 			break;
 	}
+
+out:
 	*state = __state;
 	return i;
 }

commit 5a19d67027283c77f51b971485c3e579d94b5a2f
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Fri Apr 26 09:30:11 2019 +0200

    s390/qdio: use get_buf_state() in debug_get_buf_state()
    
    For a 1-SBAL state inspection, use the corresponding helper.
    No functional change, just reducing the number of immediate callers to
    get_buf_states().
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Jens Remus <jremus@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 957c2a8dfc13..be93172555ec 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -382,7 +382,7 @@ int debug_get_buf_state(struct qdio_q *q, unsigned int bufnr,
 {
 	if (need_siga_sync(q))
 		qdio_siga_sync_q(q);
-	return get_buf_states(q, bufnr, state, 1, 0, 0);
+	return get_buf_state(q, bufnr, state, 0);
 }
 
 static inline void qdio_stop_polling(struct qdio_q *q)

commit 3060781f2664d34af641247aeac62696405a3fde
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Mon Apr 1 10:08:08 2019 +0200

    s390/qdio: allow to scan all Output SBALs in one go
    
    Old code restricted the number of inspected SBALs to
    QDIO_MAX_BUFFERS_PER_Q - 1, as otherwise the first_to_check and
    first_to_kick cursors could overlap. Subsequent code would then assume that
    there was no progress on the queue, when in fact _all_ SBALs on the queue
    were ready-to-process.
    
    This limitation no longer applies, so allow the queue-scan code to inspect
    all SBALs on the queue. Note that qeth requires an additional patch
    ("s390/qeth: stop/wake TX queues based on their fill level"), to avoid
    potential queue stalls when all 128 SBALs are reported as ready-to-process.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index cfce255521ac..957c2a8dfc13 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -719,11 +719,7 @@ static int get_outbound_buffer_frontier(struct qdio_q *q, unsigned int start)
 		    multicast_outbound(q)))
 			qdio_siga_sync_q(q);
 
-	/*
-	 * Don't check 128 buffers, as otherwise qdio_inbound_q_moved
-	 * would return 0.
-	 */
-	count = min(atomic_read(&q->nr_buf_used), QDIO_MAX_BUFFERS_MASK);
+	count = atomic_read(&q->nr_buf_used);
 	if (!count)
 		return 0;
 

commit 6bcf74e2d15c8339f0e4a0f0613638873098e85f
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Mon Apr 8 13:32:12 2019 +0200

    s390/qdio: consolidate index tracking for queue scan
    
    qdio.ko offers a small number of high-level functions to drive the
    scanning of a QDIO queue for ready-to-process SBALs:
    qdio_get_next_buffers(), __[ti]qdio_inbound_processing() and
    __qdio_outbound_processing().
    
    Let each of those functions maintain the 'start' index for their current
    scan, and pass it to lower-level helpers as needed. This improves the
    code's overall layering, and allows us to eliminate the additional
    first_to_kick cursor with a follow-on patch.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Jens Remus <jremus@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 045f2aad0b3c..cfce255521ac 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -492,9 +492,8 @@ static inline void inbound_primed(struct qdio_q *q, unsigned int start,
 	set_buf_states(q, start, SLSB_P_INPUT_NOT_INIT, count);
 }
 
-static int get_inbound_buffer_frontier(struct qdio_q *q)
+static int get_inbound_buffer_frontier(struct qdio_q *q, unsigned int start)
 {
-	unsigned int start = q->first_to_check;
 	unsigned char state = 0;
 	int count;
 
@@ -519,7 +518,6 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	switch (state) {
 	case SLSB_P_INPUT_PRIMED:
 		inbound_primed(q, start, count);
-		q->first_to_check = add_buf(start, count);
 		if (atomic_sub_return(count, &q->nr_buf_used) == 0)
 			qperf_inc(q, inbound_queue_full);
 		if (q->irq_ptr->perf_stat_enabled)
@@ -527,7 +525,6 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 		return count;
 	case SLSB_P_INPUT_ERROR:
 		process_buffer_error(q, start, count);
-		q->first_to_check = add_buf(start, count);
 		if (atomic_sub_return(count, &q->nr_buf_used) == 0)
 			qperf_inc(q, inbound_queue_full);
 		if (q->irq_ptr->perf_stat_enabled)
@@ -547,11 +544,11 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	}
 }
 
-static int qdio_inbound_q_moved(struct qdio_q *q)
+static int qdio_inbound_q_moved(struct qdio_q *q, unsigned int start)
 {
 	int count;
 
-	count = get_inbound_buffer_frontier(q);
+	count = get_inbound_buffer_frontier(q, start);
 
 	if (count && !is_thinint_irq(q->irq_ptr) && MACHINE_IS_LPAR)
 		q->u.in.timestamp = get_tod_clock();
@@ -559,9 +556,8 @@ static int qdio_inbound_q_moved(struct qdio_q *q)
 	return count;
 }
 
-static inline int qdio_inbound_q_done(struct qdio_q *q)
+static inline int qdio_inbound_q_done(struct qdio_q *q, unsigned int start)
 {
-	unsigned int start = q->first_to_check;
 	unsigned char state = 0;
 
 	if (!atomic_read(&q->nr_buf_used))
@@ -672,17 +668,20 @@ static inline int qdio_tasklet_schedule(struct qdio_q *q)
 
 static void __qdio_inbound_processing(struct qdio_q *q)
 {
+	unsigned int start = q->first_to_check;
 	int count;
 
 	qperf_inc(q, tasklet_inbound);
 
-	count = qdio_inbound_q_moved(q);
+	count = qdio_inbound_q_moved(q, start);
 	if (count == 0)
 		return;
 
+	start = add_buf(start, count);
+	q->first_to_check = start;
 	qdio_kick_handler(q, count);
 
-	if (!qdio_inbound_q_done(q)) {
+	if (!qdio_inbound_q_done(q, start)) {
 		/* means poll time is not yet over */
 		qperf_inc(q, tasklet_inbound_resched);
 		if (!qdio_tasklet_schedule(q))
@@ -694,7 +693,7 @@ static void __qdio_inbound_processing(struct qdio_q *q)
 	 * We need to check again to not lose initiative after
 	 * resetting the ACK state.
 	 */
-	if (!qdio_inbound_q_done(q)) {
+	if (!qdio_inbound_q_done(q, start)) {
 		qperf_inc(q, tasklet_inbound_resched2);
 		qdio_tasklet_schedule(q);
 	}
@@ -706,9 +705,8 @@ void qdio_inbound_processing(unsigned long data)
 	__qdio_inbound_processing(q);
 }
 
-static int get_outbound_buffer_frontier(struct qdio_q *q)
+static int get_outbound_buffer_frontier(struct qdio_q *q, unsigned int start)
 {
-	unsigned int start = q->first_to_check;
 	unsigned char state = 0;
 	int count;
 
@@ -740,13 +738,11 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 			"out empty:%1d %02x", q->nr, count);
 
 		atomic_sub(count, &q->nr_buf_used);
-		q->first_to_check = add_buf(start, count);
 		if (q->irq_ptr->perf_stat_enabled)
 			account_sbals(q, count);
 		return count;
 	case SLSB_P_OUTPUT_ERROR:
 		process_buffer_error(q, start, count);
-		q->first_to_check = add_buf(start, count);
 		atomic_sub(count, &q->nr_buf_used);
 		if (q->irq_ptr->perf_stat_enabled)
 			account_sbals_error(q, count);
@@ -773,11 +769,11 @@ static inline int qdio_outbound_q_done(struct qdio_q *q)
 	return atomic_read(&q->nr_buf_used) == 0;
 }
 
-static inline int qdio_outbound_q_moved(struct qdio_q *q)
+static inline int qdio_outbound_q_moved(struct qdio_q *q, unsigned int start)
 {
 	int count;
 
-	count = get_outbound_buffer_frontier(q);
+	count = get_outbound_buffer_frontier(q, start);
 
 	if (count)
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out moved:%1d", q->nr);
@@ -829,14 +825,17 @@ static int qdio_kick_outbound_q(struct qdio_q *q, unsigned long aob)
 
 static void __qdio_outbound_processing(struct qdio_q *q)
 {
+	unsigned int start = q->first_to_check;
 	int count;
 
 	qperf_inc(q, tasklet_outbound);
 	WARN_ON_ONCE(atomic_read(&q->nr_buf_used) < 0);
 
-	count = qdio_outbound_q_moved(q);
-	if (count)
+	count = qdio_outbound_q_moved(q, start);
+	if (count) {
+		q->first_to_check = add_buf(start, count);
 		qdio_kick_handler(q, count);
+	}
 
 	if (queue_type(q) == QDIO_ZFCP_QFMT && !pci_out_supported(q->irq_ptr) &&
 	    !qdio_outbound_q_done(q))
@@ -891,6 +890,7 @@ static inline void qdio_check_outbound_pci_queues(struct qdio_irq *irq)
 
 static void __tiqdio_inbound_processing(struct qdio_q *q)
 {
+	unsigned int start = q->first_to_check;
 	int count;
 
 	qperf_inc(q, tasklet_inbound);
@@ -900,13 +900,15 @@ static void __tiqdio_inbound_processing(struct qdio_q *q)
 	/* The interrupt could be caused by a PCI request: */
 	qdio_check_outbound_pci_queues(q->irq_ptr);
 
-	count = qdio_inbound_q_moved(q);
+	count = qdio_inbound_q_moved(q, start);
 	if (count == 0)
 		return;
 
+	start = add_buf(start, count);
+	q->first_to_check = start;
 	qdio_kick_handler(q, count);
 
-	if (!qdio_inbound_q_done(q)) {
+	if (!qdio_inbound_q_done(q, start)) {
 		qperf_inc(q, tasklet_inbound_resched);
 		if (!qdio_tasklet_schedule(q))
 			return;
@@ -917,7 +919,7 @@ static void __tiqdio_inbound_processing(struct qdio_q *q)
 	 * We need to check again to not lose initiative after
 	 * resetting the ACK state.
 	 */
-	if (!qdio_inbound_q_done(q)) {
+	if (!qdio_inbound_q_done(q, start)) {
 		qperf_inc(q, tasklet_inbound_resched2);
 		qdio_tasklet_schedule(q);
 	}
@@ -1637,7 +1639,7 @@ int qdio_start_irq(struct ccw_device *cdev, int nr)
 	 */
 	if (test_nonshared_ind(irq_ptr))
 		goto rescan;
-	if (!qdio_inbound_q_done(q))
+	if (!qdio_inbound_q_done(q, q->first_to_check))
 		goto rescan;
 	return 0;
 
@@ -1668,11 +1670,13 @@ int qdio_get_next_buffers(struct ccw_device *cdev, int nr, int *bufnr,
 {
 	struct qdio_q *q;
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
+	unsigned int start;
 	int count;
 
 	if (!irq_ptr)
 		return -ENODEV;
 	q = irq_ptr->input_qs[nr];
+	start = q->first_to_check;
 
 	/*
 	 * Cannot rely on automatic sync after interrupt since queues may
@@ -1683,10 +1687,13 @@ int qdio_get_next_buffers(struct ccw_device *cdev, int nr, int *bufnr,
 
 	qdio_check_outbound_pci_queues(irq_ptr);
 
-	count = qdio_inbound_q_moved(q);
+	count = qdio_inbound_q_moved(q, start);
 	if (count == 0)
 		return 0;
 
+	start = add_buf(start, count);
+	q->first_to_check = start;
+
 	/* Note: upper-layer MUST stop processing immediately here ... */
 	if (unlikely(q->irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))
 		return -EIO;

commit 5b2ad270529ff8abfd8a324ceece1ae1704875a0
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Mon Apr 8 11:19:54 2019 +0200

    s390/qdio: limit direct access to first_to_check cursor
    
    Refactor all the low-level helpers to take the first_to_check cursor as
    parameter, rather than accessing it directly.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Jens Remus <jremus@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 0ccd3b30af78..045f2aad0b3c 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -415,7 +415,8 @@ static inline void account_sbals(struct qdio_q *q, unsigned int count)
 	q->q_stats.nr_sbals[pos]++;
 }
 
-static void process_buffer_error(struct qdio_q *q, int count)
+static void process_buffer_error(struct qdio_q *q, unsigned int start,
+				 int count)
 {
 	unsigned char state = (q->is_input_q) ? SLSB_P_INPUT_NOT_INIT :
 					SLSB_P_OUTPUT_NOT_INIT;
@@ -424,29 +425,29 @@ static void process_buffer_error(struct qdio_q *q, int count)
 
 	/* special handling for no target buffer empty */
 	if (queue_type(q) == QDIO_IQDIO_QFMT && !q->is_input_q &&
-	    q->sbal[q->first_to_check]->element[15].sflags == 0x10) {
+	    q->sbal[start]->element[15].sflags == 0x10) {
 		qperf_inc(q, target_full);
-		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "OUTFULL FTC:%02x",
-			      q->first_to_check);
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "OUTFULL FTC:%02x", start);
 		goto set;
 	}
 
 	DBF_ERROR("%4x BUF ERROR", SCH_NO(q));
 	DBF_ERROR((q->is_input_q) ? "IN:%2d" : "OUT:%2d", q->nr);
-	DBF_ERROR("FTC:%3d C:%3d", q->first_to_check, count);
+	DBF_ERROR("FTC:%3d C:%3d", start, count);
 	DBF_ERROR("F14:%2x F15:%2x",
-		  q->sbal[q->first_to_check]->element[14].sflags,
-		  q->sbal[q->first_to_check]->element[15].sflags);
+		  q->sbal[start]->element[14].sflags,
+		  q->sbal[start]->element[15].sflags);
 
 set:
 	/*
 	 * Interrupts may be avoided as long as the error is present
 	 * so change the buffer state immediately to avoid starvation.
 	 */
-	set_buf_states(q, q->first_to_check, state, count);
+	set_buf_states(q, start, state, count);
 }
 
-static inline void inbound_primed(struct qdio_q *q, int count)
+static inline void inbound_primed(struct qdio_q *q, unsigned int start,
+				  int count)
 {
 	int new;
 
@@ -457,7 +458,7 @@ static inline void inbound_primed(struct qdio_q *q, int count)
 		if (!q->u.in.polling) {
 			q->u.in.polling = 1;
 			q->u.in.ack_count = count;
-			q->u.in.ack_start = q->first_to_check;
+			q->u.in.ack_start = start;
 			return;
 		}
 
@@ -465,7 +466,7 @@ static inline void inbound_primed(struct qdio_q *q, int count)
 		set_buf_states(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT,
 			       q->u.in.ack_count);
 		q->u.in.ack_count = count;
-		q->u.in.ack_start = q->first_to_check;
+		q->u.in.ack_start = start;
 		return;
 	}
 
@@ -473,7 +474,7 @@ static inline void inbound_primed(struct qdio_q *q, int count)
 	 * ACK the newest buffer. The ACK will be removed in qdio_stop_polling
 	 * or by the next inbound run.
 	 */
-	new = add_buf(q->first_to_check, count - 1);
+	new = add_buf(start, count - 1);
 	if (q->u.in.polling) {
 		/* reset the previous ACK but first set the new one */
 		set_buf_state(q, new, SLSB_P_INPUT_ACK);
@@ -488,11 +489,12 @@ static inline void inbound_primed(struct qdio_q *q, int count)
 	if (!count)
 		return;
 	/* need to change ALL buffers to get more interrupts */
-	set_buf_states(q, q->first_to_check, SLSB_P_INPUT_NOT_INIT, count);
+	set_buf_states(q, start, SLSB_P_INPUT_NOT_INIT, count);
 }
 
 static int get_inbound_buffer_frontier(struct qdio_q *q)
 {
+	unsigned int start = q->first_to_check;
 	unsigned char state = 0;
 	int count;
 
@@ -510,22 +512,22 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	 * No siga sync here, as a PCI or we after a thin interrupt
 	 * already sync'ed the queues.
 	 */
-	count = get_buf_states(q, q->first_to_check, &state, count, 1, 0);
+	count = get_buf_states(q, start, &state, count, 1, 0);
 	if (!count)
 		return 0;
 
 	switch (state) {
 	case SLSB_P_INPUT_PRIMED:
-		inbound_primed(q, count);
-		q->first_to_check = add_buf(q->first_to_check, count);
+		inbound_primed(q, start, count);
+		q->first_to_check = add_buf(start, count);
 		if (atomic_sub_return(count, &q->nr_buf_used) == 0)
 			qperf_inc(q, inbound_queue_full);
 		if (q->irq_ptr->perf_stat_enabled)
 			account_sbals(q, count);
 		return count;
 	case SLSB_P_INPUT_ERROR:
-		process_buffer_error(q, count);
-		q->first_to_check = add_buf(q->first_to_check, count);
+		process_buffer_error(q, start, count);
+		q->first_to_check = add_buf(start, count);
 		if (atomic_sub_return(count, &q->nr_buf_used) == 0)
 			qperf_inc(q, inbound_queue_full);
 		if (q->irq_ptr->perf_stat_enabled)
@@ -537,7 +539,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 		if (q->irq_ptr->perf_stat_enabled)
 			q->q_stats.nr_sbal_nop++;
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in nop:%1d %#02x",
-			q->nr, q->first_to_check);
+			      q->nr, start);
 		return 0;
 	default:
 		WARN_ON_ONCE(1);
@@ -559,6 +561,7 @@ static int qdio_inbound_q_moved(struct qdio_q *q)
 
 static inline int qdio_inbound_q_done(struct qdio_q *q)
 {
+	unsigned int start = q->first_to_check;
 	unsigned char state = 0;
 
 	if (!atomic_read(&q->nr_buf_used))
@@ -566,7 +569,7 @@ static inline int qdio_inbound_q_done(struct qdio_q *q)
 
 	if (need_siga_sync(q))
 		qdio_siga_sync_q(q);
-	get_buf_state(q, q->first_to_check, &state, 0);
+	get_buf_state(q, start, &state, 0);
 
 	if (state == SLSB_P_INPUT_PRIMED || state == SLSB_P_INPUT_ERROR)
 		/* more work coming */
@@ -584,8 +587,7 @@ static inline int qdio_inbound_q_done(struct qdio_q *q)
 	 * has (probably) not moved (see qdio_inbound_processing).
 	 */
 	if (get_tod_clock_fast() > q->u.in.timestamp + QDIO_INPUT_THRESHOLD) {
-		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in done:%02x",
-			      q->first_to_check);
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in done:%02x", start);
 		return 1;
 	} else
 		return 0;
@@ -706,6 +708,7 @@ void qdio_inbound_processing(unsigned long data)
 
 static int get_outbound_buffer_frontier(struct qdio_q *q)
 {
+	unsigned int start = q->first_to_check;
 	unsigned char state = 0;
 	int count;
 
@@ -726,8 +729,7 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 	if (!count)
 		return 0;
 
-	count = get_buf_states(q, q->first_to_check, &state, count, 0,
-			       q->u.out.use_cq);
+	count = get_buf_states(q, start, &state, count, 0, q->u.out.use_cq);
 	if (!count)
 		return 0;
 
@@ -738,13 +740,13 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 			"out empty:%1d %02x", q->nr, count);
 
 		atomic_sub(count, &q->nr_buf_used);
-		q->first_to_check = add_buf(q->first_to_check, count);
+		q->first_to_check = add_buf(start, count);
 		if (q->irq_ptr->perf_stat_enabled)
 			account_sbals(q, count);
 		return count;
 	case SLSB_P_OUTPUT_ERROR:
-		process_buffer_error(q, count);
-		q->first_to_check = add_buf(q->first_to_check, count);
+		process_buffer_error(q, start, count);
+		q->first_to_check = add_buf(start, count);
 		atomic_sub(count, &q->nr_buf_used);
 		if (q->irq_ptr->perf_stat_enabled)
 			account_sbals_error(q, count);

commit dccbbaff174df174bb30c21e05d7b732d013ea1a
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Thu Mar 28 10:45:11 2019 +0100

    s390/qdio: eliminate queue's last_move cursor
    
    This cursor is used for debugging only. But since
    commit "s390/qdio: pass up count of ready-to-process SBALs" it effectively
    duplicates the first_to_check cursor, diverging for just a short moment
    when get_*_buffer_frontier() updates q->first_to_check.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Jens Remus <jremus@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index b6bc02efa0d0..0ccd3b30af78 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -551,11 +551,8 @@ static int qdio_inbound_q_moved(struct qdio_q *q)
 
 	count = get_inbound_buffer_frontier(q);
 
-	if (count) {
-		q->last_move = q->first_to_check;
-		if (!is_thinint_irq(q->irq_ptr) && MACHINE_IS_LPAR)
-			q->u.in.timestamp = get_tod_clock();
-	}
+	if (count && !is_thinint_irq(q->irq_ptr) && MACHINE_IS_LPAR)
+		q->u.in.timestamp = get_tod_clock();
 
 	return count;
 }
@@ -780,10 +777,8 @@ static inline int qdio_outbound_q_moved(struct qdio_q *q)
 
 	count = get_outbound_buffer_frontier(q);
 
-	if (count) {
-		q->last_move = q->first_to_check;
+	if (count)
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out moved:%1d", q->nr);
-	}
 
 	return count;
 }

commit 65e4f776385ac5cab021ad8d992e851375305906
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Thu Mar 28 10:43:46 2019 +0100

    s390/qdio: simplify SBAL range calculation
    
    When passing a range of ready-to-process SBALs to the upper-layer
    driver, use the available 'count' instead of calculating the distance
    between the first_to_check and first_to_kick cursors.
    
    This simplifies the logic of the queue-scan path, and opens up the
    possibility of scanning all 128 SBALs in one go (as determining the
    reported count no longer requires wrap-around safe arithmetic on the
    queue's cursors).
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Jens Remus <jremus@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 195f35256cc5..b6bc02efa0d0 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -636,17 +636,13 @@ static inline unsigned long qdio_aob_for_buffer(struct qdio_output_q *q,
 	return phys_aob;
 }
 
-static void qdio_kick_handler(struct qdio_q *q)
+static void qdio_kick_handler(struct qdio_q *q, unsigned int count)
 {
 	int start = q->first_to_kick;
-	int end = q->first_to_check;
-	int count;
 
 	if (unlikely(q->irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))
 		return;
 
-	count = sub_buf(end, start);
-
 	if (q->is_input_q) {
 		qperf_inc(q, inbound_handler);
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "kih s:%02x c:%02x", start, count);
@@ -662,7 +658,7 @@ static void qdio_kick_handler(struct qdio_q *q)
 		   q->irq_ptr->int_parm);
 
 	/* for the next time */
-	q->first_to_kick = end;
+	q->first_to_kick = add_buf(start, count);
 	q->qdio_error = 0;
 }
 
@@ -685,7 +681,7 @@ static void __qdio_inbound_processing(struct qdio_q *q)
 	if (count == 0)
 		return;
 
-	qdio_kick_handler(q);
+	qdio_kick_handler(q, count);
 
 	if (!qdio_inbound_q_done(q)) {
 		/* means poll time is not yet over */
@@ -843,7 +839,7 @@ static void __qdio_outbound_processing(struct qdio_q *q)
 
 	count = qdio_outbound_q_moved(q);
 	if (count)
-		qdio_kick_handler(q);
+		qdio_kick_handler(q, count);
 
 	if (queue_type(q) == QDIO_ZFCP_QFMT && !pci_out_supported(q->irq_ptr) &&
 	    !qdio_outbound_q_done(q))
@@ -911,7 +907,7 @@ static void __tiqdio_inbound_processing(struct qdio_q *q)
 	if (count == 0)
 		return;
 
-	qdio_kick_handler(q);
+	qdio_kick_handler(q, count);
 
 	if (!qdio_inbound_q_done(q)) {
 		qperf_inc(q, tasklet_inbound_resched);
@@ -1674,7 +1670,6 @@ int qdio_get_next_buffers(struct ccw_device *cdev, int nr, int *bufnr,
 			  int *error)
 {
 	struct qdio_q *q;
-	int start, end;
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 	int count;
 
@@ -1699,15 +1694,14 @@ int qdio_get_next_buffers(struct ccw_device *cdev, int nr, int *bufnr,
 	if (unlikely(q->irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))
 		return -EIO;
 
-	start = q->first_to_kick;
-	end = q->first_to_check;
-	*bufnr = start;
+	*bufnr = q->first_to_kick;
 	*error = q->qdio_error;
 
 	/* for the next time */
-	q->first_to_kick = end;
+	q->first_to_kick = add_buf(q->first_to_kick, count);
 	q->qdio_error = 0;
-	return sub_buf(end, start);
+
+	return count;
 }
 EXPORT_SYMBOL(qdio_get_next_buffers);
 

commit b39544c6e02fdf86c394a9367b10e707b800f4d7
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Thu Mar 28 10:39:25 2019 +0100

    s390/qdio: pass up count of ready-to-process SBALs
    
    When qdio_{in,out}bound_q_moved() scans a queue for pending work, it
    currently only returns a boolean to its caller. The interface to the
    upper-layer-drivers (qdio_kick_handler() and qdio_get_next_buffers())
    then re-calculates the number of pending SBALs from the
    q->first_to_check and q->first_to_kick cursors.
    
    Refactor this so that whenever get_{in,out}bound_buffer_frontier()
    adjusted the queue's first_to_check cursor, it also returns the
    corresponding count of ready-to-process SBALs (and 0 else).
    A subsequent patch will then make use of this additional information.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Jens Remus <jremus@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index c25a40ecc105..195f35256cc5 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -504,7 +504,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	 */
 	count = min(atomic_read(&q->nr_buf_used), QDIO_MAX_BUFFERS_MASK);
 	if (!count)
-		goto out;
+		return 0;
 
 	/*
 	 * No siga sync here, as a PCI or we after a thin interrupt
@@ -512,7 +512,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	 */
 	count = get_buf_states(q, q->first_to_check, &state, count, 1, 0);
 	if (!count)
-		goto out;
+		return 0;
 
 	switch (state) {
 	case SLSB_P_INPUT_PRIMED:
@@ -522,7 +522,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 			qperf_inc(q, inbound_queue_full);
 		if (q->irq_ptr->perf_stat_enabled)
 			account_sbals(q, count);
-		break;
+		return count;
 	case SLSB_P_INPUT_ERROR:
 		process_buffer_error(q, count);
 		q->first_to_check = add_buf(q->first_to_check, count);
@@ -530,7 +530,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 			qperf_inc(q, inbound_queue_full);
 		if (q->irq_ptr->perf_stat_enabled)
 			account_sbals_error(q, count);
-		break;
+		return count;
 	case SLSB_CU_INPUT_EMPTY:
 	case SLSB_P_INPUT_NOT_INIT:
 	case SLSB_P_INPUT_ACK:
@@ -538,27 +538,26 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 			q->q_stats.nr_sbal_nop++;
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in nop:%1d %#02x",
 			q->nr, q->first_to_check);
-		break;
+		return 0;
 	default:
 		WARN_ON_ONCE(1);
+		return 0;
 	}
-out:
-	return q->first_to_check;
 }
 
 static int qdio_inbound_q_moved(struct qdio_q *q)
 {
-	int bufnr;
+	int count;
 
-	bufnr = get_inbound_buffer_frontier(q);
+	count = get_inbound_buffer_frontier(q);
 
-	if (bufnr != q->last_move) {
-		q->last_move = bufnr;
+	if (count) {
+		q->last_move = q->first_to_check;
 		if (!is_thinint_irq(q->irq_ptr) && MACHINE_IS_LPAR)
 			q->u.in.timestamp = get_tod_clock();
-		return 1;
-	} else
-		return 0;
+	}
+
+	return count;
 }
 
 static inline int qdio_inbound_q_done(struct qdio_q *q)
@@ -678,9 +677,12 @@ static inline int qdio_tasklet_schedule(struct qdio_q *q)
 
 static void __qdio_inbound_processing(struct qdio_q *q)
 {
+	int count;
+
 	qperf_inc(q, tasklet_inbound);
 
-	if (!qdio_inbound_q_moved(q))
+	count = qdio_inbound_q_moved(q);
+	if (count == 0)
 		return;
 
 	qdio_kick_handler(q);
@@ -729,12 +731,12 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 	 */
 	count = min(atomic_read(&q->nr_buf_used), QDIO_MAX_BUFFERS_MASK);
 	if (!count)
-		goto out;
+		return 0;
 
 	count = get_buf_states(q, q->first_to_check, &state, count, 0,
 			       q->u.out.use_cq);
 	if (!count)
-		goto out;
+		return 0;
 
 	switch (state) {
 	case SLSB_P_OUTPUT_EMPTY:
@@ -746,31 +748,28 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 		q->first_to_check = add_buf(q->first_to_check, count);
 		if (q->irq_ptr->perf_stat_enabled)
 			account_sbals(q, count);
-
-		break;
+		return count;
 	case SLSB_P_OUTPUT_ERROR:
 		process_buffer_error(q, count);
 		q->first_to_check = add_buf(q->first_to_check, count);
 		atomic_sub(count, &q->nr_buf_used);
 		if (q->irq_ptr->perf_stat_enabled)
 			account_sbals_error(q, count);
-		break;
+		return count;
 	case SLSB_CU_OUTPUT_PRIMED:
 		/* the adapter has not fetched the output yet */
 		if (q->irq_ptr->perf_stat_enabled)
 			q->q_stats.nr_sbal_nop++;
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out primed:%1d",
 			      q->nr);
-		break;
+		return 0;
 	case SLSB_P_OUTPUT_NOT_INIT:
 	case SLSB_P_OUTPUT_HALTED:
-		break;
+		return 0;
 	default:
 		WARN_ON_ONCE(1);
+		return 0;
 	}
-
-out:
-	return q->first_to_check;
 }
 
 /* all buffers processed? */
@@ -781,16 +780,16 @@ static inline int qdio_outbound_q_done(struct qdio_q *q)
 
 static inline int qdio_outbound_q_moved(struct qdio_q *q)
 {
-	int bufnr;
+	int count;
 
-	bufnr = get_outbound_buffer_frontier(q);
+	count = get_outbound_buffer_frontier(q);
 
-	if (bufnr != q->last_move) {
-		q->last_move = bufnr;
+	if (count) {
+		q->last_move = q->first_to_check;
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out moved:%1d", q->nr);
-		return 1;
-	} else
-		return 0;
+	}
+
+	return count;
 }
 
 static int qdio_kick_outbound_q(struct qdio_q *q, unsigned long aob)
@@ -837,10 +836,13 @@ static int qdio_kick_outbound_q(struct qdio_q *q, unsigned long aob)
 
 static void __qdio_outbound_processing(struct qdio_q *q)
 {
+	int count;
+
 	qperf_inc(q, tasklet_outbound);
 	WARN_ON_ONCE(atomic_read(&q->nr_buf_used) < 0);
 
-	if (qdio_outbound_q_moved(q))
+	count = qdio_outbound_q_moved(q);
+	if (count)
 		qdio_kick_handler(q);
 
 	if (queue_type(q) == QDIO_ZFCP_QFMT && !pci_out_supported(q->irq_ptr) &&
@@ -896,6 +898,8 @@ static inline void qdio_check_outbound_pci_queues(struct qdio_irq *irq)
 
 static void __tiqdio_inbound_processing(struct qdio_q *q)
 {
+	int count;
+
 	qperf_inc(q, tasklet_inbound);
 	if (need_siga_sync(q) && need_siga_sync_after_ai(q))
 		qdio_sync_queues(q);
@@ -903,7 +907,8 @@ static void __tiqdio_inbound_processing(struct qdio_q *q)
 	/* The interrupt could be caused by a PCI request: */
 	qdio_check_outbound_pci_queues(q->irq_ptr);
 
-	if (!qdio_inbound_q_moved(q))
+	count = qdio_inbound_q_moved(q);
+	if (count == 0)
 		return;
 
 	qdio_kick_handler(q);
@@ -1671,6 +1676,7 @@ int qdio_get_next_buffers(struct ccw_device *cdev, int nr, int *bufnr,
 	struct qdio_q *q;
 	int start, end;
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
+	int count;
 
 	if (!irq_ptr)
 		return -ENODEV;
@@ -1685,7 +1691,8 @@ int qdio_get_next_buffers(struct ccw_device *cdev, int nr, int *bufnr,
 
 	qdio_check_outbound_pci_queues(irq_ptr);
 
-	if (!qdio_inbound_q_moved(q))
+	count = qdio_inbound_q_moved(q);
+	if (count == 0)
 		return 0;
 
 	/* Note: upper-layer MUST stop processing immediately here ... */

commit 2f2f3839fb8d0fb548fa6ee2d3bec656dc61f1ac
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Tue Oct 30 08:21:27 2018 +0100

    s390/qdio: clean up qdio_check_outbound_after_thinint()
    
    This helper is not thinint-specific, qdio_get_next_buffers() also calls it
    for non-thinint devices. So give it a more fitting name, and while at it
    adjust its parameter.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 02d515fa10a1..c25a40ecc105 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -881,9 +881,8 @@ void qdio_outbound_timer(struct timer_list *t)
 	qdio_tasklet_schedule(q);
 }
 
-static inline void qdio_check_outbound_after_thinint(struct qdio_q *q)
+static inline void qdio_check_outbound_pci_queues(struct qdio_irq *irq)
 {
-	struct qdio_irq *irq = q->irq_ptr;
 	struct qdio_q *out;
 	int i;
 
@@ -901,11 +900,8 @@ static void __tiqdio_inbound_processing(struct qdio_q *q)
 	if (need_siga_sync(q) && need_siga_sync_after_ai(q))
 		qdio_sync_queues(q);
 
-	/*
-	 * The interrupt could be caused by a PCI request. Check the
-	 * PCI capable outbound queues.
-	 */
-	qdio_check_outbound_after_thinint(q);
+	/* The interrupt could be caused by a PCI request: */
+	qdio_check_outbound_pci_queues(q->irq_ptr);
 
 	if (!qdio_inbound_q_moved(q))
 		return;
@@ -1687,8 +1683,7 @@ int qdio_get_next_buffers(struct ccw_device *cdev, int nr, int *bufnr,
 	if (need_siga_sync(q))
 		qdio_sync_queues(q);
 
-	/* check the PCI capable outbound queues. */
-	qdio_check_outbound_after_thinint(q);
+	qdio_check_outbound_pci_queues(irq_ptr);
 
 	if (!qdio_inbound_q_moved(q))
 		return 0;

commit f85b2b297c16b6d9fa8d9f2f26b73b5571dfb859
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Tue Oct 30 08:19:54 2018 +0100

    s390/qdio: clean up pci_out_supported()
    
    pci_out_supported() currently takes a single queue as parameter, even
    though Output IRQ support is a per-device feature. Adjust the parameter,
    so that the macro can also be used in code paths with no access to a queue
    struct. This allows us to remove the remaining open-coded checks for
    QIB_AC_OUTBOUND_PCI_SUPPORTED.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 9537e656e927..02d515fa10a1 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -371,7 +371,7 @@ static inline int qdio_siga_input(struct qdio_q *q)
 static inline void qdio_sync_queues(struct qdio_q *q)
 {
 	/* PCI capable outbound queues will also be scanned so sync them too */
-	if (pci_out_supported(q))
+	if (pci_out_supported(q->irq_ptr))
 		qdio_siga_sync_all(q);
 	else
 		qdio_siga_sync_q(q);
@@ -718,7 +718,7 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 
 	if (need_siga_sync(q))
 		if (((queue_type(q) != QDIO_IQDIO_QFMT) &&
-		    !pci_out_supported(q)) ||
+		    !pci_out_supported(q->irq_ptr)) ||
 		    (queue_type(q) == QDIO_IQDIO_QFMT &&
 		    multicast_outbound(q)))
 			qdio_siga_sync_q(q);
@@ -843,9 +843,9 @@ static void __qdio_outbound_processing(struct qdio_q *q)
 	if (qdio_outbound_q_moved(q))
 		qdio_kick_handler(q);
 
-	if (queue_type(q) == QDIO_ZFCP_QFMT)
-		if (!pci_out_supported(q) && !qdio_outbound_q_done(q))
-			goto sched;
+	if (queue_type(q) == QDIO_ZFCP_QFMT && !pci_out_supported(q->irq_ptr) &&
+	    !qdio_outbound_q_done(q))
+		goto sched;
 
 	if (q->u.out.pci_out_enabled)
 		return;
@@ -883,13 +883,14 @@ void qdio_outbound_timer(struct timer_list *t)
 
 static inline void qdio_check_outbound_after_thinint(struct qdio_q *q)
 {
+	struct qdio_irq *irq = q->irq_ptr;
 	struct qdio_q *out;
 	int i;
 
-	if (!pci_out_supported(q))
+	if (!pci_out_supported(irq))
 		return;
 
-	for_each_output_queue(q->irq_ptr, out, i)
+	for_each_output_queue(irq, out, i)
 		if (!qdio_outbound_q_done(out))
 			qdio_tasklet_schedule(out);
 }
@@ -976,7 +977,7 @@ static void qdio_int_handler_pci(struct qdio_irq *irq_ptr)
 		}
 	}
 
-	if (!(irq_ptr->qib.ac & QIB_AC_OUTBOUND_PCI_SUPPORTED))
+	if (!pci_out_supported(irq_ptr))
 		return;
 
 	for_each_output_queue(irq_ptr, q, i) {

commit ccc413f621432fcb5dabb751d42148795f59a816
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Tue May 15 21:17:38 2018 +0200

    s390/qdio: clean up AOB handling
    
    I've stumbled over this too many times now... AOBs are only ever used on
    Output Queues. So in qdio_kick_handler(), move the call to their handler
    into the Output-only path, and get rid of the convoluted contains_aobs()
    helper. No functional change.
    
    While at it, also remove
    1. the unused sbal_state->aob field. For processing an async completion,
       upper-layer drivers get their AOB pointer from the CQ buffer.
    2. an unused EXPORT for qdio_allocate_aob(). External users would have
       no way of passing an allocated AOB back into qdio.ko anyways...
    
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 9c7d9da42ba0..9537e656e927 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -595,19 +595,11 @@ static inline int qdio_inbound_q_done(struct qdio_q *q)
 		return 0;
 }
 
-static inline int contains_aobs(struct qdio_q *q)
-{
-	return !q->is_input_q && q->u.out.use_cq;
-}
-
 static inline void qdio_handle_aobs(struct qdio_q *q, int start, int count)
 {
 	unsigned char state = 0;
 	int j, b = start;
 
-	if (!contains_aobs(q))
-		return;
-
 	for (j = 0; j < count; ++j) {
 		get_buf_state(q, b, &state, 0);
 		if (state == SLSB_P_OUTPUT_PENDING) {
@@ -618,8 +610,6 @@ static inline void qdio_handle_aobs(struct qdio_q *q, int start, int count)
 			q->u.out.sbal_state[b].flags |=
 				QDIO_OUTBUF_STATE_FLAG_PENDING;
 			q->u.out.aobs[b] = NULL;
-		} else if (state == SLSB_P_OUTPUT_EMPTY) {
-			q->u.out.sbal_state[b].aob = NULL;
 		}
 		b = next_buf(b);
 	}
@@ -638,7 +628,6 @@ static inline unsigned long qdio_aob_for_buffer(struct qdio_output_q *q,
 		q->aobs[bufnr] = aob;
 	}
 	if (q->aobs[bufnr]) {
-		q->sbal_state[bufnr].aob = q->aobs[bufnr];
 		q->aobs[bufnr]->user1 = (u64) q->sbal_state[bufnr].user;
 		phys_aob = virt_to_phys(q->aobs[bufnr]);
 		WARN_ON_ONCE(phys_aob & 0xFF);
@@ -666,10 +655,10 @@ static void qdio_kick_handler(struct qdio_q *q)
 		qperf_inc(q, outbound_handler);
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "koh: s:%02x c:%02x",
 			      start, count);
+		if (q->u.out.use_cq)
+			qdio_handle_aobs(q, start, count);
 	}
 
-	qdio_handle_aobs(q, start, count);
-
 	q->handler(q->irq_ptr->cdev, q->qdio_error, q->nr, start, count,
 		   q->irq_ptr->int_parm);
 

commit 64e03ff72623b8c2ea89ca3cb660094e019ed4ae
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Wed May 16 09:37:25 2018 +0200

    s390/qdio: reset old sbal_state flags
    
    When allocating a new AOB fails, handle_outbound() is still capable of
    transmitting the selected buffer (just without async completion).
    
    But if a previous transfer on this queue slot used async completion, its
    sbal_state flags field is still set to QDIO_OUTBUF_STATE_FLAG_PENDING.
    So when the upper layer driver sees this stale flag, it expects an async
    completion that never happens.
    
    Fix this by unconditionally clearing the flags field.
    
    Fixes: 104ea556ee7f ("qdio: support asynchronous delivery of storage blocks")
    Cc: <stable@vger.kernel.org> #v3.2+
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index f4ca72dd862f..9c7d9da42ba0 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -631,21 +631,20 @@ static inline unsigned long qdio_aob_for_buffer(struct qdio_output_q *q,
 	unsigned long phys_aob = 0;
 
 	if (!q->use_cq)
-		goto out;
+		return 0;
 
 	if (!q->aobs[bufnr]) {
 		struct qaob *aob = qdio_allocate_aob();
 		q->aobs[bufnr] = aob;
 	}
 	if (q->aobs[bufnr]) {
-		q->sbal_state[bufnr].flags = QDIO_OUTBUF_STATE_FLAG_NONE;
 		q->sbal_state[bufnr].aob = q->aobs[bufnr];
 		q->aobs[bufnr]->user1 = (u64) q->sbal_state[bufnr].user;
 		phys_aob = virt_to_phys(q->aobs[bufnr]);
 		WARN_ON_ONCE(phys_aob & 0xFF);
 	}
 
-out:
+	q->sbal_state[bufnr].flags = 0;
 	return phys_aob;
 }
 

commit 89286320a236d245834075fa13adb0bdd827ecaa
Author: Julian Wiedmann <jwi@linux.vnet.ibm.com>
Date:   Wed Mar 21 17:14:00 2018 +0100

    s390/qdio: clear intparm during shutdown
    
    During shutdown, qdio returns its ccw device back to control by the
    upper-layer driver. But there is a remote chance that by the time where the
    IRQ handler gets switched back, the interrupt for the preceding
    ccw_device_{clear,halt} hasn't been presented yet.
    Upper-layer drivers would then need to handle this IRQ - and since the IO
    is issued with an intparm, it could very well be confused with whatever
    intparm mechanism the driver uses itself (eg intparm == request address).
    
    So when switching over the IRQ handler, also clear the intparm and have
    upper-layer drivers deal with any such delayed interrupt as if it was
    unsolicited.
    
    Suggested-by: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Signed-off-by: Julian Wiedmann <jwi@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index a337281337a7..f4ca72dd862f 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1207,8 +1207,10 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 	qdio_shutdown_thinint(irq_ptr);
 
 	/* restore interrupt handler */
-	if ((void *)cdev->handler == (void *)qdio_int_handler)
+	if ((void *)cdev->handler == (void *)qdio_int_handler) {
 		cdev->handler = irq_ptr->orig_handler;
+		cdev->private->intparm = 0;
+	}
 	spin_unlock_irq(get_ccwdev_lock(cdev));
 
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);

commit 88bf319fc2d6d971ef8692c2cae7f96708340461
Author: Julian Wiedmann <jwi@linux.vnet.ibm.com>
Date:   Tue Mar 6 17:58:49 2018 +0100

    s390/qdio: split up CCQ handling for EQBS / SQBS
    
    Get rid of the confusing two-stage translation in a hot path, and only
    handle CCQs that we anticipate for the respective command. Any
    unexpected value (such as CCQ 97 (rc == 1) for SQBS) should be
    considered a severe HW/driver bug, and traced as such.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.vnet.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index de647b7e17b1..a337281337a7 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -98,22 +98,6 @@ static inline int do_siga_output(unsigned long schid, unsigned long mask,
 	return cc;
 }
 
-static inline int qdio_check_ccq(struct qdio_q *q, unsigned int ccq)
-{
-	/* all done or next buffer state different */
-	if (ccq == 0 || ccq == 32)
-		return 0;
-	/* no buffer processed */
-	if (ccq == 97)
-		return 1;
-	/* not all buffers processed */
-	if (ccq == 96)
-		return 2;
-	/* notify devices immediately */
-	DBF_ERROR("%4x ccq:%3d", SCH_NO(q), ccq);
-	return -EIO;
-}
-
 /**
  * qdio_do_eqbs - extract buffer states for QEBSM
  * @q: queue to manipulate
@@ -128,7 +112,7 @@ static inline int qdio_check_ccq(struct qdio_q *q, unsigned int ccq)
 static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 			int start, int count, int auto_ack)
 {
-	int rc, tmp_count = count, tmp_start = start, nr = q->nr;
+	int tmp_count = count, tmp_start = start, nr = q->nr;
 	unsigned int ccq = 0;
 
 	qperf_inc(q, eqbs);
@@ -138,27 +122,30 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 again:
 	ccq = do_eqbs(q->irq_ptr->sch_token, state, nr, &tmp_start, &tmp_count,
 		      auto_ack);
-	rc = qdio_check_ccq(q, ccq);
-	if (!rc)
-		return count - tmp_count;
-
-	if (rc == 1) {
-		DBF_DEV_EVENT(DBF_WARN, q->irq_ptr, "EQBS again:%2d", ccq);
-		goto again;
-	}
 
-	if (rc == 2) {
+	switch (ccq) {
+	case 0:
+	case 32:
+		/* all done, or next buffer state different */
+		return count - tmp_count;
+	case 96:
+		/* not all buffers processed */
 		qperf_inc(q, eqbs_partial);
 		DBF_DEV_EVENT(DBF_WARN, q->irq_ptr, "EQBS part:%02x",
 			tmp_count);
 		return count - tmp_count;
+	case 97:
+		/* no buffer processed */
+		DBF_DEV_EVENT(DBF_WARN, q->irq_ptr, "EQBS again:%2d", ccq);
+		goto again;
+	default:
+		DBF_ERROR("%4x ccq:%3d", SCH_NO(q), ccq);
+		DBF_ERROR("%4x EQBS ERROR", SCH_NO(q));
+		DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
+		q->handler(q->irq_ptr->cdev, QDIO_ERROR_GET_BUF_STATE, q->nr,
+			   q->first_to_kick, count, q->irq_ptr->int_parm);
+		return 0;
 	}
-
-	DBF_ERROR("%4x EQBS ERROR", SCH_NO(q));
-	DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
-	q->handler(q->irq_ptr->cdev, QDIO_ERROR_GET_BUF_STATE,
-		   q->nr, q->first_to_kick, count, q->irq_ptr->int_parm);
-	return 0;
 }
 
 /**
@@ -178,7 +165,6 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 	unsigned int ccq = 0;
 	int tmp_count = count, tmp_start = start;
 	int nr = q->nr;
-	int rc;
 
 	if (!count)
 		return 0;
@@ -188,23 +174,26 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 		nr += q->irq_ptr->nr_input_qs;
 again:
 	ccq = do_sqbs(q->irq_ptr->sch_token, state, nr, &tmp_start, &tmp_count);
-	rc = qdio_check_ccq(q, ccq);
-	if (!rc) {
+
+	switch (ccq) {
+	case 0:
+	case 32:
+		/* all done, or active buffer adapter-owned */
 		WARN_ON_ONCE(tmp_count);
 		return count - tmp_count;
-	}
-
-	if (rc == 1 || rc == 2) {
+	case 96:
+		/* not all buffers processed */
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "SQBS again:%2d", ccq);
 		qperf_inc(q, sqbs_partial);
 		goto again;
+	default:
+		DBF_ERROR("%4x ccq:%3d", SCH_NO(q), ccq);
+		DBF_ERROR("%4x SQBS ERROR", SCH_NO(q));
+		DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
+		q->handler(q->irq_ptr->cdev, QDIO_ERROR_SET_BUF_STATE, q->nr,
+			   q->first_to_kick, count, q->irq_ptr->int_parm);
+		return 0;
 	}
-
-	DBF_ERROR("%4x SQBS ERROR", SCH_NO(q));
-	DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
-	q->handler(q->irq_ptr->cdev, QDIO_ERROR_SET_BUF_STATE,
-		   q->nr, q->first_to_kick, count, q->irq_ptr->int_parm);
-	return 0;
 }
 
 /*

commit dae55b6fef58530c13df074bcc182c096609339e
Author: Julian Wiedmann <jwi@linux.vnet.ibm.com>
Date:   Mon Mar 5 09:39:38 2018 +0100

    s390/qdio: don't retry EQBS after CCQ 96
    
    Immediate retry of EQBS after CCQ 96 means that we potentially misreport
    the state of buffers inspected during the first EQBS call.
    
    This occurs when
    1. the first EQBS finds all inspected buffers still in the initial state
       set by the driver (ie INPUT EMPTY or OUTPUT PRIMED),
    2. the EQBS terminates early with CCQ 96, and
    3. by the time that the second EQBS comes around, the state of those
       previously inspected buffers has changed.
    
    If the state reported by the second EQBS is 'driver-owned', all we know
    is that the previous buffers are driver-owned now as well. But we can't
    tell if they all have the same state. So for instance
    - the second EQBS reports OUTPUT EMPTY, but any number of the previous
      buffers could be OUTPUT ERROR by now,
    - the second EQBS reports OUTPUT ERROR, but any number of the previous
      buffers could be OUTPUT EMPTY by now.
    
    Effectively, this can result in both over- and underreporting of errors.
    
    If the state reported by the second EQBS is 'HW-owned', that doesn't
    guarantee that the previous buffers have not been switched to
    driver-owned in the mean time. So for instance
    - the second EQBS reports INPUT EMPTY, but any number of the previous
      buffers could be INPUT PRIMED (or INPUT ERROR) by now.
    
    This would result in failure to process pending work on the queue. If
    it's the final check before yielding initiative, this can cause
    a (temporary) queue stall due to IRQ avoidance.
    
    Fixes: 25f269f17316 ("[S390] qdio: EQBS retry after CCQ 96")
    Cc: <stable@vger.kernel.org> #v3.2+
    Signed-off-by: Julian Wiedmann <jwi@linux.vnet.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 63c6e9cf958f..de647b7e17b1 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -128,7 +128,7 @@ static inline int qdio_check_ccq(struct qdio_q *q, unsigned int ccq)
 static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 			int start, int count, int auto_ack)
 {
-	int rc, tmp_count = count, tmp_start = start, nr = q->nr, retried = 0;
+	int rc, tmp_count = count, tmp_start = start, nr = q->nr;
 	unsigned int ccq = 0;
 
 	qperf_inc(q, eqbs);
@@ -151,14 +151,7 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 		qperf_inc(q, eqbs_partial);
 		DBF_DEV_EVENT(DBF_WARN, q->irq_ptr, "EQBS part:%02x",
 			tmp_count);
-		/*
-		 * Retry once, if that fails bail out and process the
-		 * extracted buffers before trying again.
-		 */
-		if (!retried++)
-			goto again;
-		else
-			return count - tmp_count;
+		return count - tmp_count;
 	}
 
 	DBF_ERROR("%4x EQBS ERROR", SCH_NO(q));

commit c11a3dfd6fedd5266c2f9d7286981dc804dfb7cc
Author: Julian Wiedmann <jwi@linux.vnet.ibm.com>
Date:   Wed Mar 7 14:19:43 2018 +0100

    s390/qdio: restrict buffer merging to eligible devices
    
    Only attempt to merge PENDING into EMPTY buffers for devices where
    the PENDING state is actually expected (ie. IQD with CQ).
    This might speed up the hot path a little bit.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.vnet.ibm.com>
    Reviewed-by: Ursula Braun <ubraun@linux.vnet.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index bd26df85f559..63c6e9cf958f 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -761,7 +761,8 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 	if (!count)
 		goto out;
 
-	count = get_buf_states(q, q->first_to_check, &state, count, 0, 1);
+	count = get_buf_states(q, q->first_to_check, &state, count, 0,
+			       q->u.out.use_cq);
 	if (!count)
 		goto out;
 

commit 0cf1e05157b9e5530dcc3ca9fec9bf617fc93375
Author: Julian Wiedmann <jwi@linux.vnet.ibm.com>
Date:   Wed Mar 7 14:01:01 2018 +0100

    s390/qdio: don't merge ERROR output buffers
    
    On an Output queue, both EMPTY and PENDING buffer states imply that the
    buffer is ready for completion-processing by the upper-layer drivers.
    
    So for a non-QEBSM Output queue, get_buf_states() merges mixed
    batches of PENDING and EMPTY buffers into one large batch of EMPTY
    buffers. The upper-layer driver (ie. qeth) later distuingishes PENDING
    from EMPTY by inspecting the slsb_state for
    QDIO_OUTBUF_STATE_FLAG_PENDING.
    
    But the merge logic in get_buf_states() contains a bug that causes us to
    erronously also merge ERROR buffers into such a batch of EMPTY buffers
    (ERROR is 0xaf, EMPTY is 0xa1; so ERROR & EMPTY == EMPTY).
    Effectively, most outbound ERROR buffers are currently discarded
    silently and processed as if they had succeeded.
    
    Note that this affects _all_ non-QEBSM device types, not just IQD with CQ.
    
    Fix it by explicitly spelling out the exact conditions for merging.
    
    For extracting the "get initial state" part out of the loop, this relies
    on the fact that get_buf_states() is never called with a count of 0. The
    QEBSM path already strictly requires this, and the two callers with
    variable 'count' make sure of it.
    
    Fixes: 104ea556ee7f ("qdio: support asynchronous delivery of storage blocks")
    Cc: <stable@vger.kernel.org> #v3.2+
    Signed-off-by: Julian Wiedmann <jwi@linux.vnet.ibm.com>
    Reviewed-by: Ursula Braun <ubraun@linux.vnet.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 6b340e6e29ac..bd26df85f559 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -214,7 +214,10 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 	return 0;
 }
 
-/* returns number of examined buffers and their common state in *state */
+/*
+ * Returns number of examined buffers and their common state in *state.
+ * Requested number of buffers-to-examine must be > 0.
+ */
 static inline int get_buf_states(struct qdio_q *q, unsigned int bufnr,
 				 unsigned char *state, unsigned int count,
 				 int auto_ack, int merge_pending)
@@ -225,17 +228,23 @@ static inline int get_buf_states(struct qdio_q *q, unsigned int bufnr,
 	if (is_qebsm(q))
 		return qdio_do_eqbs(q, state, bufnr, count, auto_ack);
 
-	for (i = 0; i < count; i++) {
-		if (!__state) {
-			__state = q->slsb.val[bufnr];
-			if (merge_pending && __state == SLSB_P_OUTPUT_PENDING)
-				__state = SLSB_P_OUTPUT_EMPTY;
-		} else if (merge_pending) {
-			if ((q->slsb.val[bufnr] & __state) != __state)
-				break;
-		} else if (q->slsb.val[bufnr] != __state)
-			break;
+	/* get initial state: */
+	__state = q->slsb.val[bufnr];
+	if (merge_pending && __state == SLSB_P_OUTPUT_PENDING)
+		__state = SLSB_P_OUTPUT_EMPTY;
+
+	for (i = 1; i < count; i++) {
 		bufnr = next_buf(bufnr);
+
+		/* merge PENDING into EMPTY: */
+		if (merge_pending &&
+		    q->slsb.val[bufnr] == SLSB_P_OUTPUT_PENDING &&
+		    __state == SLSB_P_OUTPUT_EMPTY)
+			continue;
+
+		/* stop if next state differs from initial state: */
+		if (q->slsb.val[bufnr] != __state)
+			break;
 	}
 	*state = __state;
 	return i;

commit 152485bf76907ac7a2cc0a63b0822b23ef25da56
Author: Julian Wiedmann <jwi@linux.vnet.ibm.com>
Date:   Wed Dec 6 08:53:33 2017 +0100

    s390/qdio: simplify math in get_*_buffer_frontier()
    
    When determining the buffer count that get_buf_states() should
    be queried for, 'count' is capped at 127 buffers.
    So the check
            q->first_to_check == (q->first_to_check + count) % 128
    can be reduced to
            count == 0
    
    This helps to emphasize that get_buf_states() is really only
    called with count > 0.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.vnet.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index d5b02de02a3a..6b340e6e29ac 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -502,8 +502,8 @@ static inline void inbound_primed(struct qdio_q *q, int count)
 
 static int get_inbound_buffer_frontier(struct qdio_q *q)
 {
-	int count, stop;
 	unsigned char state = 0;
+	int count;
 
 	q->timestamp = get_tod_clock_fast();
 
@@ -512,9 +512,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	 * would return 0.
 	 */
 	count = min(atomic_read(&q->nr_buf_used), QDIO_MAX_BUFFERS_MASK);
-	stop = add_buf(q->first_to_check, count);
-
-	if (q->first_to_check == stop)
+	if (!count)
 		goto out;
 
 	/*
@@ -734,8 +732,8 @@ void qdio_inbound_processing(unsigned long data)
 
 static int get_outbound_buffer_frontier(struct qdio_q *q)
 {
-	int count, stop;
 	unsigned char state = 0;
+	int count;
 
 	q->timestamp = get_tod_clock_fast();
 
@@ -751,8 +749,7 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 	 * would return 0.
 	 */
 	count = min(atomic_read(&q->nr_buf_used), QDIO_MAX_BUFFERS_MASK);
-	stop = add_buf(q->first_to_check, count);
-	if (q->first_to_check == stop)
+	if (!count)
 		goto out;
 
 	count = get_buf_states(q, q->first_to_check, &state, count, 0, 1);

commit 364e3f90f8e9198681ccccad4bea2f681a8ffba2
Author: Sebastian Ott <sebott@linux.vnet.ibm.com>
Date:   Mon Jan 29 12:55:29 2018 +0100

    s390/cio: fix kernel-doc usage
    
    Fix the kernel-doc usage in cio to get rid of (W=1) build warnings like:
    drivers/s390/cio/cio.c:1068: warning: No description found for parameter 'sch'
    
    Signed-off-by: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 95b0efe28afb..d5b02de02a3a 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -72,6 +72,7 @@ static inline int do_siga_input(unsigned long schid, unsigned int mask,
  * @mask: which output queues to process
  * @bb: busy bit indicator, set only if SIGA-w/wt could not access a buffer
  * @fc: function code to perform
+ * @aob: asynchronous operation block
  *
  * Returns condition code.
  * Note: For IQDC unicast queues only the highest priority queue is processed.
@@ -1761,9 +1762,6 @@ EXPORT_SYMBOL(qdio_stop_irq);
  * @response:		Response code will be stored at this address
  * @cb: 		Callback function will be executed for each element
  *			of the address list
- * @priv:		Pointer passed from the caller to qdio_pnso_brinfo()
- * @type:		Type of the address entry passed to the callback
- * @entry:		Entry containg the address of the specified type
  * @priv:		Pointer to pass to the callback function.
  *
  * Performs "Store-network-bridging-information list" operation and calls

commit b23481fbfc567fea256a69b307ced283c56aba99
Author: Julian Wiedmann <jwi@linux.vnet.ibm.com>
Date:   Mon Oct 23 09:38:18 2017 +0200

    s390/qdio: restrict target-full handling to IQDIO
    
    The 'no target buffer empty' error code only applies to HiperSockets.
    If this code is reported on a different queue type, be sure to make the
    same amount of noise as for any other error code.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.vnet.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index d681e6b56add..95b0efe28afb 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -431,8 +431,8 @@ static void process_buffer_error(struct qdio_q *q, int count)
 	q->qdio_error = QDIO_ERROR_SLSB_STATE;
 
 	/* special handling for no target buffer empty */
-	if ((!q->is_input_q &&
-	    (q->sbal[q->first_to_check]->element[15].sflags) == 0x10)) {
+	if (queue_type(q) == QDIO_IQDIO_QFMT && !q->is_input_q &&
+	    q->sbal[q->first_to_check]->element[15].sflags == 0x10) {
 		qperf_inc(q, target_full);
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "OUTFULL FTC:%02x",
 			      q->first_to_check);

commit 0b926ac304a9b315f0ce8ce2ae5373b5a0478b68
Author: Julian Wiedmann <jwi@linux.vnet.ibm.com>
Date:   Mon Oct 23 09:40:16 2017 +0200

    s390/qdio: consider ERROR buffers for inbound-full condition
    
    In the unlikely case that an ERROR buffer (presented by the HW)
    consumed the last available slot on the input queue, increment the
    corresponding statistics counter.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.vnet.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 59b4a3370cd5..d681e6b56add 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -536,7 +536,8 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	case SLSB_P_INPUT_ERROR:
 		process_buffer_error(q, count);
 		q->first_to_check = add_buf(q->first_to_check, count);
-		atomic_sub(count, &q->nr_buf_used);
+		if (atomic_sub_return(count, &q->nr_buf_used) == 0)
+			qperf_inc(q, inbound_queue_full);
 		if (q->irq_ptr->perf_stat_enabled)
 			account_sbals_error(q, count);
 		break;

commit 724117b77bbe2b28f27728d58a432ed22630e33f
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Tue Nov 14 18:38:02 2017 +0100

    s390: cio: add SPDX identifiers to the remaining files
    
    It's good to have SPDX identifiers in all files to make it easier to
    audit the kernel tree for correct licenses.
    
    Update the drivers/s390/cio/ files with the correct SPDX license
    identifier based on the license text in the file itself.  The SPDX
    identifier is a legally binding shorthand, which can be used instead of
    the full boiler plate text.
    
    This work is based on a script and data from Thomas Gleixner, Philippe
    Ombredanne, and Kate Stewart.
    
    Cc: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Cc: Peter Oberparleiter <oberpar@linux.vnet.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Cornelia Huck <cohuck@redhat.com>
    Cc: Dong Jia Shi <bjsdjshi@linux.vnet.ibm.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: Philippe Ombredanne <pombredanne@nexb.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index ed4852fab44b..59b4a3370cd5 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * Linux for s390 qdio support, buffer handling, qdio API and module support.
  *

commit cb9f780aa93b752ec935e6771a251717d867e603
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Oct 4 17:54:35 2017 -0700

    s390: qdio: Convert timers to use timer_setup()
    
    In preparation for unconditionally passing the struct timer_list pointer to
    all timer callbacks, switch to using the new timer_setup() and from_timer()
    to pass the timer pointer explicitly.
    
    Cc: Peter Oberparleiter <oberpar@linux.vnet.ibm.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    [sebott: fixed compile error due to invalid struct member]
    Signed-off-by: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index a4ad39ba3873..ed4852fab44b 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -894,9 +894,9 @@ void qdio_outbound_processing(unsigned long data)
 	__qdio_outbound_processing(q);
 }
 
-void qdio_outbound_timer(unsigned long data)
+void qdio_outbound_timer(struct timer_list *t)
 {
-	struct qdio_q *q = (struct qdio_q *)data;
+	struct qdio_q *q = from_timer(q, t, u.out.timer);
 
 	qdio_tasklet_schedule(q);
 }

commit f83435c42ee6e4233cc07130e2cf5022b95e1d32
Author: Julian Wiedmann <jwi@linux.vnet.ibm.com>
Date:   Mon Nov 21 11:34:25 2016 +0100

    s390/qdio: improve some debug prints
    
    With multiple input queues, these DBFs turned out to be not
    very helpful...
    
    Signed-off-by: Julian Wiedmann <jwi@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 71bf9bded485..a4ad39ba3873 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -457,7 +457,7 @@ static inline void inbound_primed(struct qdio_q *q, int count)
 {
 	int new;
 
-	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in prim: %02x", count);
+	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in prim:%1d %02x", q->nr, count);
 
 	/* for QEBSM the ACK was already set by EQBS */
 	if (is_qebsm(q)) {
@@ -544,7 +544,8 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	case SLSB_P_INPUT_ACK:
 		if (q->irq_ptr->perf_stat_enabled)
 			q->q_stats.nr_sbal_nop++;
-		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in nop");
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in nop:%1d %#02x",
+			q->nr, q->first_to_check);
 		break;
 	default:
 		WARN_ON_ONCE(1);

commit 9bce8b2cbebf9f11b41021ccb98c6b18d1796edd
Author: Ursula Braun <ursula.braun@de.ibm.com>
Date:   Fri Aug 5 12:33:10 2016 +0200

    s390/qdio: avoid reschedule of outbound tasklet once killed
    
    During qdio_shutdown the queue tasklets are killed for all inbound and
    outbound queues. The queue structures might be freed after
    qdio_shutdown.
    Thus it must be guaranteed that these queue tasklets are not rescheduled
    after that. In addition the outbound queue timers are deleted and it
    must
    be guaranteed that these timers are not restarted after qdio_shutdown
    processing. Timer deletion should make use of del_timer_sync() to make
    sure qdio_outbound_timer() is finished on other CPUs as well. Queue
    tasklets should be scheduled in state QDIO_IRQ_STATE_ACTIVE only.
    
    Signed-off-by: Ursula Braun <ubraun@linux.vnet.ibm.com>
    Reviewed-by: Benjamin Block <bblock@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index fda3b2617ec9..71bf9bded485 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -686,6 +686,15 @@ static void qdio_kick_handler(struct qdio_q *q)
 	q->qdio_error = 0;
 }
 
+static inline int qdio_tasklet_schedule(struct qdio_q *q)
+{
+	if (likely(q->irq_ptr->state == QDIO_IRQ_STATE_ACTIVE)) {
+		tasklet_schedule(&q->tasklet);
+		return 0;
+	}
+	return -EPERM;
+}
+
 static void __qdio_inbound_processing(struct qdio_q *q)
 {
 	qperf_inc(q, tasklet_inbound);
@@ -698,10 +707,8 @@ static void __qdio_inbound_processing(struct qdio_q *q)
 	if (!qdio_inbound_q_done(q)) {
 		/* means poll time is not yet over */
 		qperf_inc(q, tasklet_inbound_resched);
-		if (likely(q->irq_ptr->state != QDIO_IRQ_STATE_STOPPED)) {
-			tasklet_schedule(&q->tasklet);
+		if (!qdio_tasklet_schedule(q))
 			return;
-		}
 	}
 
 	qdio_stop_polling(q);
@@ -711,8 +718,7 @@ static void __qdio_inbound_processing(struct qdio_q *q)
 	 */
 	if (!qdio_inbound_q_done(q)) {
 		qperf_inc(q, tasklet_inbound_resched2);
-		if (likely(q->irq_ptr->state != QDIO_IRQ_STATE_STOPPED))
-			tasklet_schedule(&q->tasklet);
+		qdio_tasklet_schedule(q);
 	}
 }
 
@@ -869,16 +875,15 @@ static void __qdio_outbound_processing(struct qdio_q *q)
 	 * is noticed and outbound_handler is called after some time.
 	 */
 	if (qdio_outbound_q_done(q))
-		del_timer(&q->u.out.timer);
+		del_timer_sync(&q->u.out.timer);
 	else
-		if (!timer_pending(&q->u.out.timer))
+		if (!timer_pending(&q->u.out.timer) &&
+		    likely(q->irq_ptr->state == QDIO_IRQ_STATE_ACTIVE))
 			mod_timer(&q->u.out.timer, jiffies + 10 * HZ);
 	return;
 
 sched:
-	if (unlikely(q->irq_ptr->state == QDIO_IRQ_STATE_STOPPED))
-		return;
-	tasklet_schedule(&q->tasklet);
+	qdio_tasklet_schedule(q);
 }
 
 /* outbound tasklet */
@@ -892,9 +897,7 @@ void qdio_outbound_timer(unsigned long data)
 {
 	struct qdio_q *q = (struct qdio_q *)data;
 
-	if (unlikely(q->irq_ptr->state == QDIO_IRQ_STATE_STOPPED))
-		return;
-	tasklet_schedule(&q->tasklet);
+	qdio_tasklet_schedule(q);
 }
 
 static inline void qdio_check_outbound_after_thinint(struct qdio_q *q)
@@ -907,7 +910,7 @@ static inline void qdio_check_outbound_after_thinint(struct qdio_q *q)
 
 	for_each_output_queue(q->irq_ptr, out, i)
 		if (!qdio_outbound_q_done(out))
-			tasklet_schedule(&out->tasklet);
+			qdio_tasklet_schedule(out);
 }
 
 static void __tiqdio_inbound_processing(struct qdio_q *q)
@@ -929,10 +932,8 @@ static void __tiqdio_inbound_processing(struct qdio_q *q)
 
 	if (!qdio_inbound_q_done(q)) {
 		qperf_inc(q, tasklet_inbound_resched);
-		if (likely(q->irq_ptr->state != QDIO_IRQ_STATE_STOPPED)) {
-			tasklet_schedule(&q->tasklet);
+		if (!qdio_tasklet_schedule(q))
 			return;
-		}
 	}
 
 	qdio_stop_polling(q);
@@ -942,8 +943,7 @@ static void __tiqdio_inbound_processing(struct qdio_q *q)
 	 */
 	if (!qdio_inbound_q_done(q)) {
 		qperf_inc(q, tasklet_inbound_resched2);
-		if (likely(q->irq_ptr->state != QDIO_IRQ_STATE_STOPPED))
-			tasklet_schedule(&q->tasklet);
+		qdio_tasklet_schedule(q);
 	}
 }
 
@@ -977,7 +977,7 @@ static void qdio_int_handler_pci(struct qdio_irq *irq_ptr)
 	int i;
 	struct qdio_q *q;
 
-	if (unlikely(irq_ptr->state == QDIO_IRQ_STATE_STOPPED))
+	if (unlikely(irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))
 		return;
 
 	for_each_input_queue(irq_ptr, q, i) {
@@ -1003,7 +1003,7 @@ static void qdio_int_handler_pci(struct qdio_irq *irq_ptr)
 			continue;
 		if (need_siga_sync(q) && need_siga_sync_out_after_pci(q))
 			qdio_siga_sync_q(q);
-		tasklet_schedule(&q->tasklet);
+		qdio_tasklet_schedule(q);
 	}
 }
 
@@ -1145,7 +1145,7 @@ static void qdio_shutdown_queues(struct ccw_device *cdev)
 		tasklet_kill(&q->tasklet);
 
 	for_each_output_queue(irq_ptr, q, i) {
-		del_timer(&q->u.out.timer);
+		del_timer_sync(&q->u.out.timer);
 		tasklet_kill(&q->tasklet);
 	}
 }
@@ -1585,10 +1585,11 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 
 	/* in case of SIGA errors we must process the error immediately */
 	if (used >= q->u.out.scan_threshold || rc)
-		tasklet_schedule(&q->tasklet);
+		qdio_tasklet_schedule(q);
 	else
 		/* free the SBALs in case of no further traffic */
-		if (!timer_pending(&q->u.out.timer))
+		if (!timer_pending(&q->u.out.timer) &&
+		    likely(q->irq_ptr->state == QDIO_IRQ_STATE_ACTIVE))
 			mod_timer(&q->u.out.timer, jiffies + HZ);
 	return rc;
 }

commit 6e30c549f6cab7a41d0934cea80822a2211132ae
Author: Sebastian Ott <sebott@linux.vnet.ibm.com>
Date:   Tue Aug 2 16:01:39 2016 +0200

    s390/qdio: remove checks for ccw device internal state
    
    Prior to starting IO qdio checks for the internal state of the ccw
    device. These checks happen without locking, so consistency between
    state evaluation and starting of the IO is not guaranteed.
    
    Since the internal state is checked during ccw_device_start it is
    safe to get rid of these additional checks.
    
    Signed-off-by: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Reviewed-by: Cornelia Huck <cornelia.huck@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index da969789936d..fda3b2617ec9 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1352,9 +1352,6 @@ int qdio_establish(struct qdio_initialize *init_data)
 	if (!irq_ptr)
 		return -ENODEV;
 
-	if (cdev->private->state != DEV_STATE_ONLINE)
-		return -EINVAL;
-
 	mutex_lock(&irq_ptr->setup_mutex);
 	qdio_setup_irq(init_data);
 
@@ -1425,9 +1422,6 @@ int qdio_activate(struct ccw_device *cdev)
 	if (!irq_ptr)
 		return -ENODEV;
 
-	if (cdev->private->state != DEV_STATE_ONLINE)
-		return -EINVAL;
-
 	mutex_lock(&irq_ptr->setup_mutex);
 	if (irq_ptr->state == QDIO_IRQ_STATE_INACTIVE) {
 		rc = -EBUSY;

commit ddebf6612c5dcc479725867b9fd9a4d98f41350f
Author: Sebastian Ott <sebott@linux.vnet.ibm.com>
Date:   Fri Jul 29 14:00:27 2016 +0200

    s390/qdio: fix double return code evaluation
    
    qdio sometimes checks return codes twice. First with the ccw device's
    lock held and then a 2nd time after the lock is released. Simplify
    the code by releasing the lock earlier and unify the return code
    evaluation.
    
    Signed-off-by: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Reviewed-by: Ursula Braun <ubraun@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index b200f27489a7..da969789936d 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1375,13 +1375,10 @@ int qdio_establish(struct qdio_initialize *init_data)
 	ccw_device_set_options_mask(cdev, 0);
 
 	rc = ccw_device_start(cdev, &irq_ptr->ccw, QDIO_DOING_ESTABLISH, 0, 0);
+	spin_unlock_irq(get_ccwdev_lock(cdev));
 	if (rc) {
 		DBF_ERROR("%4x est IO ERR", irq_ptr->schid.sch_no);
 		DBF_ERROR("rc:%4x", rc);
-	}
-	spin_unlock_irq(get_ccwdev_lock(cdev));
-
-	if (rc) {
 		mutex_unlock(&irq_ptr->setup_mutex);
 		qdio_shutdown(cdev, QDIO_FLAG_CLEANUP_USING_CLEAR);
 		return rc;
@@ -1447,14 +1444,12 @@ int qdio_activate(struct ccw_device *cdev)
 
 	rc = ccw_device_start(cdev, &irq_ptr->ccw, QDIO_DOING_ACTIVATE,
 			      0, DOIO_DENY_PREFETCH);
+	spin_unlock_irq(get_ccwdev_lock(cdev));
 	if (rc) {
 		DBF_ERROR("%4x act IO ERR", irq_ptr->schid.sch_no);
 		DBF_ERROR("rc:%4x", rc);
-	}
-	spin_unlock_irq(get_ccwdev_lock(cdev));
-
-	if (rc)
 		goto out;
+	}
 
 	if (is_thinint_irq(irq_ptr))
 		tiqdio_add_input_queues(irq_ptr);

commit a48ed867153c6d2f6d058267213a82dbd8b6737a
Author: Sebastian Ott <sebott@linux.vnet.ibm.com>
Date:   Fri Jul 29 13:41:20 2016 +0200

    s390/qdio: get rid of spin_lock_irqsave usage
    
    All qdio functions that use spin_lock_irqsave are never used
    from irq context. Thus it is safe to convert all of them to
    use spin_lock_irq.
    
    Signed-off-by: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Reviewed-by: Ursula Braun <ubraun@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 94e96207d42d..b200f27489a7 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1160,7 +1160,6 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 	struct subchannel_id schid;
 	int rc;
-	unsigned long flags;
 
 	if (!irq_ptr)
 		return -ENODEV;
@@ -1190,7 +1189,7 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 	qdio_shutdown_debug_entries(irq_ptr);
 
 	/* cleanup subchannel */
-	spin_lock_irqsave(get_ccwdev_lock(cdev), flags);
+	spin_lock_irq(get_ccwdev_lock(cdev));
 
 	if (how & QDIO_FLAG_CLEANUP_USING_CLEAR)
 		rc = ccw_device_clear(cdev, QDIO_DOING_CLEANUP);
@@ -1204,12 +1203,12 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 	}
 
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_CLEANUP);
-	spin_unlock_irqrestore(get_ccwdev_lock(cdev), flags);
+	spin_unlock_irq(get_ccwdev_lock(cdev));
 	wait_event_interruptible_timeout(cdev->private->wait_q,
 		irq_ptr->state == QDIO_IRQ_STATE_INACTIVE ||
 		irq_ptr->state == QDIO_IRQ_STATE_ERR,
 		10 * HZ);
-	spin_lock_irqsave(get_ccwdev_lock(cdev), flags);
+	spin_lock_irq(get_ccwdev_lock(cdev));
 
 no_cleanup:
 	qdio_shutdown_thinint(irq_ptr);
@@ -1217,7 +1216,7 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 	/* restore interrupt handler */
 	if ((void *)cdev->handler == (void *)qdio_int_handler)
 		cdev->handler = irq_ptr->orig_handler;
-	spin_unlock_irqrestore(get_ccwdev_lock(cdev), flags);
+	spin_unlock_irq(get_ccwdev_lock(cdev));
 
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);
 	mutex_unlock(&irq_ptr->setup_mutex);
@@ -1344,7 +1343,6 @@ int qdio_establish(struct qdio_initialize *init_data)
 	struct ccw_device *cdev = init_data->cdev;
 	struct subchannel_id schid;
 	struct qdio_irq *irq_ptr;
-	unsigned long saveflags;
 	int rc;
 
 	ccw_device_get_schid(cdev, &schid);
@@ -1373,7 +1371,7 @@ int qdio_establish(struct qdio_initialize *init_data)
 	irq_ptr->ccw.count = irq_ptr->equeue.count;
 	irq_ptr->ccw.cda = (u32)((addr_t)irq_ptr->qdr);
 
-	spin_lock_irqsave(get_ccwdev_lock(cdev), saveflags);
+	spin_lock_irq(get_ccwdev_lock(cdev));
 	ccw_device_set_options_mask(cdev, 0);
 
 	rc = ccw_device_start(cdev, &irq_ptr->ccw, QDIO_DOING_ESTABLISH, 0, 0);
@@ -1381,7 +1379,7 @@ int qdio_establish(struct qdio_initialize *init_data)
 		DBF_ERROR("%4x est IO ERR", irq_ptr->schid.sch_no);
 		DBF_ERROR("rc:%4x", rc);
 	}
-	spin_unlock_irqrestore(get_ccwdev_lock(cdev), saveflags);
+	spin_unlock_irq(get_ccwdev_lock(cdev));
 
 	if (rc) {
 		mutex_unlock(&irq_ptr->setup_mutex);
@@ -1422,7 +1420,6 @@ int qdio_activate(struct ccw_device *cdev)
 	struct subchannel_id schid;
 	struct qdio_irq *irq_ptr;
 	int rc;
-	unsigned long saveflags;
 
 	ccw_device_get_schid(cdev, &schid);
 	DBF_EVENT("qactivate:%4x", schid.sch_no);
@@ -1445,7 +1442,7 @@ int qdio_activate(struct ccw_device *cdev)
 	irq_ptr->ccw.count = irq_ptr->aqueue.count;
 	irq_ptr->ccw.cda = 0;
 
-	spin_lock_irqsave(get_ccwdev_lock(cdev), saveflags);
+	spin_lock_irq(get_ccwdev_lock(cdev));
 	ccw_device_set_options(cdev, CCWDEV_REPORT_ALL);
 
 	rc = ccw_device_start(cdev, &irq_ptr->ccw, QDIO_DOING_ACTIVATE,
@@ -1454,7 +1451,7 @@ int qdio_activate(struct ccw_device *cdev)
 		DBF_ERROR("%4x act IO ERR", irq_ptr->schid.sch_no);
 		DBF_ERROR("rc:%4x", rc);
 	}
-	spin_unlock_irqrestore(get_ccwdev_lock(cdev), saveflags);
+	spin_unlock_irq(get_ccwdev_lock(cdev));
 
 	if (rc)
 		goto out;

commit 9080c92494f0d7e2bca1197bbddcc417117057c3
Author: Sebastian Ott <sebott@linux.vnet.ibm.com>
Date:   Thu Jul 28 20:30:31 2016 +0200

    s390/qdio: obtain subchannel_id via ccw_device_get_schid()
    
    We want to get rid of the copy of struct subchannel_id maintained in
    ccw_device_private, so obtain it using ccw_device_get_schid().
    
    Signed-off-by: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Reviewed-by: Cornelia Huck <cornelia.huck@de.ibm.com>
    Reviewed-by: Ursula Braun <ubraun@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 4bb5262f7aee..94e96207d42d 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1066,10 +1066,12 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 		      struct irb *irb)
 {
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
+	struct subchannel_id schid;
 	int cstat, dstat;
 
 	if (!intparm || !irq_ptr) {
-		DBF_ERROR("qint:%4x", cdev->private->schid.sch_no);
+		ccw_device_get_schid(cdev, &schid);
+		DBF_ERROR("qint:%4x", schid.sch_no);
 		return;
 	}
 
@@ -1122,12 +1124,14 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 int qdio_get_ssqd_desc(struct ccw_device *cdev,
 		       struct qdio_ssqd_desc *data)
 {
+	struct subchannel_id schid;
 
 	if (!cdev || !cdev->private)
 		return -EINVAL;
 
-	DBF_EVENT("get ssqd:%4x", cdev->private->schid.sch_no);
-	return qdio_setup_get_ssqd(NULL, &cdev->private->schid, data);
+	ccw_device_get_schid(cdev, &schid);
+	DBF_EVENT("get ssqd:%4x", schid.sch_no);
+	return qdio_setup_get_ssqd(NULL, &schid, data);
 }
 EXPORT_SYMBOL_GPL(qdio_get_ssqd_desc);
 
@@ -1154,6 +1158,7 @@ static void qdio_shutdown_queues(struct ccw_device *cdev)
 int qdio_shutdown(struct ccw_device *cdev, int how)
 {
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
+	struct subchannel_id schid;
 	int rc;
 	unsigned long flags;
 
@@ -1161,7 +1166,8 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 		return -ENODEV;
 
 	WARN_ON_ONCE(irqs_disabled());
-	DBF_EVENT("qshutdown:%4x", cdev->private->schid.sch_no);
+	ccw_device_get_schid(cdev, &schid);
+	DBF_EVENT("qshutdown:%4x", schid.sch_no);
 
 	mutex_lock(&irq_ptr->setup_mutex);
 	/*
@@ -1228,11 +1234,13 @@ EXPORT_SYMBOL_GPL(qdio_shutdown);
 int qdio_free(struct ccw_device *cdev)
 {
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
+	struct subchannel_id schid;
 
 	if (!irq_ptr)
 		return -ENODEV;
 
-	DBF_EVENT("qfree:%4x", cdev->private->schid.sch_no);
+	ccw_device_get_schid(cdev, &schid);
+	DBF_EVENT("qfree:%4x", schid.sch_no);
 	DBF_DEV_EVENT(DBF_ERR, irq_ptr, "dbf abandoned");
 	mutex_lock(&irq_ptr->setup_mutex);
 
@@ -1251,9 +1259,11 @@ EXPORT_SYMBOL_GPL(qdio_free);
  */
 int qdio_allocate(struct qdio_initialize *init_data)
 {
+	struct subchannel_id schid;
 	struct qdio_irq *irq_ptr;
 
-	DBF_EVENT("qallocate:%4x", init_data->cdev->private->schid.sch_no);
+	ccw_device_get_schid(init_data->cdev, &schid);
+	DBF_EVENT("qallocate:%4x", schid.sch_no);
 
 	if ((init_data->no_input_qs && !init_data->input_handler) ||
 	    (init_data->no_output_qs && !init_data->output_handler))
@@ -1331,12 +1341,14 @@ static void qdio_detect_hsicq(struct qdio_irq *irq_ptr)
  */
 int qdio_establish(struct qdio_initialize *init_data)
 {
-	struct qdio_irq *irq_ptr;
 	struct ccw_device *cdev = init_data->cdev;
+	struct subchannel_id schid;
+	struct qdio_irq *irq_ptr;
 	unsigned long saveflags;
 	int rc;
 
-	DBF_EVENT("qestablish:%4x", cdev->private->schid.sch_no);
+	ccw_device_get_schid(cdev, &schid);
+	DBF_EVENT("qestablish:%4x", schid.sch_no);
 
 	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)
@@ -1407,11 +1419,13 @@ EXPORT_SYMBOL_GPL(qdio_establish);
  */
 int qdio_activate(struct ccw_device *cdev)
 {
+	struct subchannel_id schid;
 	struct qdio_irq *irq_ptr;
 	int rc;
 	unsigned long saveflags;
 
-	DBF_EVENT("qactivate:%4x", cdev->private->schid.sch_no);
+	ccw_device_get_schid(cdev, &schid);
+	DBF_EVENT("qactivate:%4x", schid.sch_no);
 
 	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)

commit ec6674c6382819542446b727a2bf54f3dd879ca2
Author: Eugene Crosser <Eugene.Crosser@ru.ibm.com>
Date:   Tue Oct 6 15:12:29 2015 +0200

    s390/qdio: fix WARN_ON_ONCE condition
    
    If HiperSockets Completion Queueing is enabled, qdio always
    issues a warning, since the condition is always met.
    This patch fixes the condition in WARN_ON_ONCE that was always
    true.
    
    Signed-off-by: Eugene Crosser <Eugene.Crosser@ru.ibm.com>
    Signed-off-by: Ursula Braun <ursula.braun@de.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 848e3b64ea6e..4bb5262f7aee 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -319,6 +319,8 @@ static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit,
 	int retries = 0, cc;
 	unsigned long laob = 0;
 
+	WARN_ON_ONCE(aob && ((queue_type(q) != QDIO_IQDIO_QFMT) ||
+			     !q->u.out.use_cq));
 	if (q->u.out.use_cq && aob != 0) {
 		fc = QDIO_SIGA_WRITEQ;
 		laob = aob;
@@ -329,8 +331,6 @@ static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit,
 		fc |= QDIO_SIGA_QEBSM_FLAG;
 	}
 again:
-	WARN_ON_ONCE((aob && queue_type(q) != QDIO_IQDIO_QFMT) ||
-		(aob && fc != QDIO_SIGA_WRITEQ));
 	cc = do_siga_output(schid, q->mask, busy_bit, fc, laob);
 
 	/* hipersocket busy condition */

commit 613c4e0459603cc04384723b08fd62103b5eaaaf
Author: Stefan Raspl <raspl@linux.vnet.ibm.com>
Date:   Thu Jun 12 14:24:45 2014 +0200

    qdio: Keep device-specific dbf entries
    
    Keep the per-device dbf entries until module is removed, with
    proper error checking for debug feature setup.
    
    Signed-off-by: Stefan Raspl <raspl@linux.vnet.ibm.com>
    Reviewed-by: Steffen Maier <maier@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index f5f42c431409..848e3b64ea6e 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1233,12 +1233,10 @@ int qdio_free(struct ccw_device *cdev)
 		return -ENODEV;
 
 	DBF_EVENT("qfree:%4x", cdev->private->schid.sch_no);
+	DBF_DEV_EVENT(DBF_ERR, irq_ptr, "dbf abandoned");
 	mutex_lock(&irq_ptr->setup_mutex);
 
-	if (irq_ptr->debug_area != NULL) {
-		debug_unregister(irq_ptr->debug_area);
-		irq_ptr->debug_area = NULL;
-	}
+	irq_ptr->debug_area = NULL;
 	cdev->private->qdio_data = NULL;
 	mutex_unlock(&irq_ptr->setup_mutex);
 
@@ -1275,7 +1273,8 @@ int qdio_allocate(struct qdio_initialize *init_data)
 		goto out_err;
 
 	mutex_init(&irq_ptr->setup_mutex);
-	qdio_allocate_dbf(init_data, irq_ptr);
+	if (qdio_allocate_dbf(init_data, irq_ptr))
+		goto out_rel;
 
 	/*
 	 * Allocate a page for the chsc calls in qdio_establish.

commit 92bdae5d9c95c9dece7886cbdf1f50548b44e60a
Author: Fabian Frederick <fabf@skynet.be>
Date:   Tue Jun 3 21:55:15 2014 +0200

    s390/qdio: replace shift loop by ilog2
    
    account_sbals is called by get_inbound_buffer_frontier and
    get_outbound_buffer_frontier with 'count' value > 0 so we can safely
    convert shift loop to ilog2.
    
    Cc: Joe Perches <joe@perches.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Fabian Frederick <fabf@skynet.be>
    Signed-off-by: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 77466c4faabb..f5f42c431409 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -409,17 +409,16 @@ static inline void qdio_stop_polling(struct qdio_q *q)
 		set_buf_state(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT);
 }
 
-static inline void account_sbals(struct qdio_q *q, int count)
+static inline void account_sbals(struct qdio_q *q, unsigned int count)
 {
-	int pos = 0;
+	int pos;
 
 	q->q_stats.nr_sbal_total += count;
 	if (count == QDIO_MAX_BUFFERS_MASK) {
 		q->q_stats.nr_sbals[7]++;
 		return;
 	}
-	while (count >>= 1)
-		pos++;
+	pos = ilog2(count);
 	q->q_stats.nr_sbals[pos]++;
 }
 

commit 0f308f4f9e3ddd85869bb128e37f8dd08f3f513c
Author: Ursula Braun <ursula.braun@de.ibm.com>
Date:   Tue Jan 28 13:06:47 2014 +0100

    s390/qdio: correct program-controlled interruption checking
    
    Get rid of compile warning in qdio_int_handler_pci() when checking
    for program-controlled interruption on outbound queues.
    
    Signed-off-by: Ursula Braun <ursula.braun@de.ibm.com>
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index c883a085c059..77466c4faabb 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -996,7 +996,7 @@ static void qdio_int_handler_pci(struct qdio_irq *irq_ptr)
 		}
 	}
 
-	if (!pci_out_supported(q))
+	if (!(irq_ptr->qib.ac & QIB_AC_OUTBOUND_PCI_SUPPORTED))
 		return;
 
 	for_each_output_queue(irq_ptr, q, i) {

commit 1c59a861d6982edf3f9905ad2098575336ae904d
Author: Eugene Crosser <Eugene.Crosser@ru.ibm.com>
Date:   Wed Apr 24 12:00:23 2013 +0200

    s390/qdio: bridgeport support - CHSC part
    
    Introduce function for the "Perform network-subchannel operation"
    CHSC command with operation code "bridgeport information",
    and bit definitions for "characteristics" pertaning to this command.
    
    Signed-off-by: Eugene Crosser <eugene.crosser@ru.ibm.com>
    Reviewed-by: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 3e602e8affa7..c883a085c059 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1752,6 +1752,97 @@ int qdio_stop_irq(struct ccw_device *cdev, int nr)
 }
 EXPORT_SYMBOL(qdio_stop_irq);
 
+/**
+ * qdio_pnso_brinfo() - perform network subchannel op #0 - bridge info.
+ * @schid:		Subchannel ID.
+ * @cnc:		Boolean Change-Notification Control
+ * @response:		Response code will be stored at this address
+ * @cb: 		Callback function will be executed for each element
+ *			of the address list
+ * @priv:		Pointer passed from the caller to qdio_pnso_brinfo()
+ * @type:		Type of the address entry passed to the callback
+ * @entry:		Entry containg the address of the specified type
+ * @priv:		Pointer to pass to the callback function.
+ *
+ * Performs "Store-network-bridging-information list" operation and calls
+ * the callback function for every entry in the list. If "change-
+ * notification-control" is set, further changes in the address list
+ * will be reported via the IPA command.
+ */
+int qdio_pnso_brinfo(struct subchannel_id schid,
+		int cnc, u16 *response,
+		void (*cb)(void *priv, enum qdio_brinfo_entry_type type,
+				void *entry),
+		void *priv)
+{
+	struct chsc_pnso_area *rr;
+	int rc;
+	u32 prev_instance = 0;
+	int isfirstblock = 1;
+	int i, size, elems;
+
+	rr = (struct chsc_pnso_area *)get_zeroed_page(GFP_KERNEL);
+	if (rr == NULL)
+		return -ENOMEM;
+	do {
+		/* on the first iteration, naihdr.resume_token will be zero */
+		rc = chsc_pnso_brinfo(schid, rr, rr->naihdr.resume_token, cnc);
+		if (rc != 0 && rc != -EBUSY)
+			goto out;
+		if (rr->response.code != 1) {
+			rc = -EIO;
+			continue;
+		} else
+			rc = 0;
+
+		if (cb == NULL)
+			continue;
+
+		size = rr->naihdr.naids;
+		elems = (rr->response.length -
+				sizeof(struct chsc_header) -
+				sizeof(struct chsc_brinfo_naihdr)) /
+				size;
+
+		if (!isfirstblock && (rr->naihdr.instance != prev_instance)) {
+			/* Inform the caller that they need to scrap */
+			/* the data that was already reported via cb */
+				rc = -EAGAIN;
+				break;
+		}
+		isfirstblock = 0;
+		prev_instance = rr->naihdr.instance;
+		for (i = 0; i < elems; i++)
+			switch (size) {
+			case sizeof(struct qdio_brinfo_entry_l3_ipv6):
+				(*cb)(priv, l3_ipv6_addr,
+						&rr->entries.l3_ipv6[i]);
+				break;
+			case sizeof(struct qdio_brinfo_entry_l3_ipv4):
+				(*cb)(priv, l3_ipv4_addr,
+						&rr->entries.l3_ipv4[i]);
+				break;
+			case sizeof(struct qdio_brinfo_entry_l2):
+				(*cb)(priv, l2_addr_lnid,
+						&rr->entries.l2[i]);
+				break;
+			default:
+				WARN_ON_ONCE(1);
+				rc = -EIO;
+				goto out;
+			}
+	} while (rr->response.code == 0x0107 ||  /* channel busy */
+		  (rr->response.code == 1 && /* list stored */
+		   /* resume token is non-zero => list incomplete */
+		   (rr->naihdr.resume_token.t1 || rr->naihdr.resume_token.t2)));
+	(*response) = rr->response.code;
+
+out:
+	free_page((unsigned long)rr);
+	return rc;
+}
+EXPORT_SYMBOL_GPL(qdio_pnso_brinfo);
+
 static int __init init_QDIO(void)
 {
 	int rc;

commit eddf0d5b31dda679a98f3e5615a510b8f065cb5d
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Sep 16 06:59:50 2013 +0200

    s390/qdio: fix atomic_sub() misusage
    
    get_inbound_buffer_frontier() makes use of the return value of atomic_sub()
    which shouldn't work, since atomic_sub() is supposed to return void.
    This only works on s390 because atomic_sub() gets mapped to atomic_sub_return()
    with a define without changing it's return value to void.
    
    So use atomic_sub_return() instead of atomic_sub() in qeth code before fixing
    atomic ops.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index bbd3e511c771..3e602e8affa7 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -528,7 +528,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	case SLSB_P_INPUT_PRIMED:
 		inbound_primed(q, count);
 		q->first_to_check = add_buf(q->first_to_check, count);
-		if (atomic_sub(count, &q->nr_buf_used) == 0)
+		if (atomic_sub_return(count, &q->nr_buf_used) == 0)
 			qperf_inc(q, inbound_queue_full);
 		if (q->irq_ptr->perf_stat_enabled)
 			account_sbals(q, count);

commit 8c071b0f19dfa230335d22ce56a8fab5bd20cedc
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Thu Oct 17 12:38:17 2013 +0200

    s390/time: correct use of store clock fast
    
    The result of the store-clock-fast (STCKF) instruction is a bit fuzzy.
    It can happen that the value stored on one CPU is smaller than the value
    stored on another CPU, although the order of the stores is the other
    way around. This can cause deltas of get_tod_clock() values to become
    negative when they should not be.
    
    We need to be more careful with store-clock-fast, this patch partially
    reverts git commit e4b7b4238e666682555461fa52eecd74652f36bb "time:
    always use stckf instead of stck if available". The get_tod_clock()
    function now uses the store-clock-extended (STCKE) instruction.
    get_tod_clock_fast() can be used if the fuzziness of store-clock-fast
    is acceptable e.g. for wait loops local to a CPU.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 8ed52aa49122..bbd3e511c771 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -338,10 +338,10 @@ static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit,
 		retries++;
 
 		if (!start_time) {
-			start_time = get_tod_clock();
+			start_time = get_tod_clock_fast();
 			goto again;
 		}
-		if ((get_tod_clock() - start_time) < QDIO_BUSY_BIT_PATIENCE)
+		if (get_tod_clock_fast() - start_time < QDIO_BUSY_BIT_PATIENCE)
 			goto again;
 	}
 	if (retries) {
@@ -504,7 +504,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	int count, stop;
 	unsigned char state = 0;
 
-	q->timestamp = get_tod_clock();
+	q->timestamp = get_tod_clock_fast();
 
 	/*
 	 * Don't check 128 buffers, as otherwise qdio_inbound_q_moved
@@ -595,7 +595,7 @@ static inline int qdio_inbound_q_done(struct qdio_q *q)
 	 * At this point we know, that inbound first_to_check
 	 * has (probably) not moved (see qdio_inbound_processing).
 	 */
-	if (get_tod_clock() > q->u.in.timestamp + QDIO_INPUT_THRESHOLD) {
+	if (get_tod_clock_fast() > q->u.in.timestamp + QDIO_INPUT_THRESHOLD) {
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in done:%02x",
 			      q->first_to_check);
 		return 1;
@@ -728,7 +728,7 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 	int count, stop;
 	unsigned char state = 0;
 
-	q->timestamp = get_tod_clock();
+	q->timestamp = get_tod_clock_fast();
 
 	if (need_siga_sync(q))
 		if (((queue_type(q) != QDIO_IQDIO_QFMT) &&

commit dae7fd42961e9ae9386f527b6d0e14f6e3da2317
Author: Sebastian Ott <sebott@linux.vnet.ibm.com>
Date:   Fri Jul 5 09:22:11 2013 +0200

    s390/qdio: remove unused variable
    
    Fix a "set but not used" warning found via make W=1.
    
    Signed-off-by: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index fb1c1e0483ed..8ed52aa49122 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1497,7 +1497,7 @@ static inline int buf_in_between(int bufnr, int start, int count)
 static int handle_inbound(struct qdio_q *q, unsigned int callflags,
 			  int bufnr, int count)
 {
-	int used, diff;
+	int diff;
 
 	qperf_inc(q, inbound_call);
 
@@ -1530,7 +1530,7 @@ static int handle_inbound(struct qdio_q *q, unsigned int callflags,
 
 set:
 	count = set_buf_states(q, bufnr, SLSB_CU_INPUT_EMPTY, count);
-	used = atomic_add_return(count, &q->nr_buf_used) - count;
+	atomic_add(count, &q->nr_buf_used);
 
 	if (need_siga_in(q))
 		return qdio_siga_input(q);

commit 1d46d331259e0f9e55637dc9b8fdf867f9897767
Author: Sebastian Ott <sebott@linux.vnet.ibm.com>
Date:   Fri May 17 16:39:51 2013 +0200

    s390/qdio: remove unused function
    
    Remove the unused function qdio_trace_aob.
    
    Acked-by: Ursula Braun <ursula.braun@de.ibm.com>
    Signed-off-by: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 843051bc20f1..fb1c1e0483ed 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -608,50 +608,6 @@ static inline int contains_aobs(struct qdio_q *q)
 	return !q->is_input_q && q->u.out.use_cq;
 }
 
-static inline void qdio_trace_aob(struct qdio_irq *irq, struct qdio_q *q,
-				int i, struct qaob *aob)
-{
-	int tmp;
-
-	DBF_DEV_EVENT(DBF_INFO, irq, "AOB%d:%lx", i,
-			(unsigned long) virt_to_phys(aob));
-	DBF_DEV_EVENT(DBF_INFO, irq, "RES00:%lx",
-			(unsigned long) aob->res0[0]);
-	DBF_DEV_EVENT(DBF_INFO, irq, "RES01:%lx",
-			(unsigned long) aob->res0[1]);
-	DBF_DEV_EVENT(DBF_INFO, irq, "RES02:%lx",
-			(unsigned long) aob->res0[2]);
-	DBF_DEV_EVENT(DBF_INFO, irq, "RES03:%lx",
-			(unsigned long) aob->res0[3]);
-	DBF_DEV_EVENT(DBF_INFO, irq, "RES04:%lx",
-			(unsigned long) aob->res0[4]);
-	DBF_DEV_EVENT(DBF_INFO, irq, "RES05:%lx",
-			(unsigned long) aob->res0[5]);
-	DBF_DEV_EVENT(DBF_INFO, irq, "RES1:%x", aob->res1);
-	DBF_DEV_EVENT(DBF_INFO, irq, "RES2:%x", aob->res2);
-	DBF_DEV_EVENT(DBF_INFO, irq, "RES3:%x", aob->res3);
-	DBF_DEV_EVENT(DBF_INFO, irq, "AORC:%u", aob->aorc);
-	DBF_DEV_EVENT(DBF_INFO, irq, "FLAGS:%u", aob->flags);
-	DBF_DEV_EVENT(DBF_INFO, irq, "CBTBS:%u", aob->cbtbs);
-	DBF_DEV_EVENT(DBF_INFO, irq, "SBC:%u", aob->sb_count);
-	for (tmp = 0; tmp < QDIO_MAX_ELEMENTS_PER_BUFFER; ++tmp) {
-		DBF_DEV_EVENT(DBF_INFO, irq, "SBA%d:%lx", tmp,
-				(unsigned long) aob->sba[tmp]);
-		DBF_DEV_EVENT(DBF_INFO, irq, "rSBA%d:%lx", tmp,
-				(unsigned long) q->sbal[i]->element[tmp].addr);
-		DBF_DEV_EVENT(DBF_INFO, irq, "DC%d:%u", tmp, aob->dcount[tmp]);
-		DBF_DEV_EVENT(DBF_INFO, irq, "rDC%d:%u", tmp,
-				q->sbal[i]->element[tmp].length);
-	}
-	DBF_DEV_EVENT(DBF_INFO, irq, "USER0:%lx", (unsigned long) aob->user0);
-	for (tmp = 0; tmp < 2; ++tmp) {
-		DBF_DEV_EVENT(DBF_INFO, irq, "RES4%d:%lx", tmp,
-			(unsigned long) aob->res4[tmp]);
-	}
-	DBF_DEV_EVENT(DBF_INFO, irq, "USER1:%lx", (unsigned long) aob->user1);
-	DBF_DEV_EVENT(DBF_INFO, irq, "USER2:%lx", (unsigned long) aob->user2);
-}
-
 static inline void qdio_handle_aobs(struct qdio_q *q, int start, int count)
 {
 	unsigned char state = 0;

commit aa2383f815c3720f1f406d2f574dfb65aedce2ec
Author: Stefan Raspl <raspl@linux.vnet.ibm.com>
Date:   Tue Feb 26 13:08:34 2013 +0100

    qdio: remove unused parameters
    
    Remove unused function parameters.
    
    Signed-off-by: Stefan Raspl <raspl@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index abc550e5dd35..843051bc20f1 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1226,7 +1226,7 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 
 	tiqdio_remove_input_queues(irq_ptr);
 	qdio_shutdown_queues(cdev);
-	qdio_shutdown_debug_entries(irq_ptr, cdev);
+	qdio_shutdown_debug_entries(irq_ptr);
 
 	/* cleanup subchannel */
 	spin_lock_irqsave(get_ccwdev_lock(cdev), flags);

commit 1aae0560d160ee6ebef927a35e4f405306a079df
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed Jan 30 09:49:40 2013 +0100

    s390/time: rename tod clock access functions
    
    Fix name clash with some common code device drivers and add "tod"
    to all tod clock access function names.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 1671d3461f29..abc550e5dd35 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -338,10 +338,10 @@ static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit,
 		retries++;
 
 		if (!start_time) {
-			start_time = get_clock();
+			start_time = get_tod_clock();
 			goto again;
 		}
-		if ((get_clock() - start_time) < QDIO_BUSY_BIT_PATIENCE)
+		if ((get_tod_clock() - start_time) < QDIO_BUSY_BIT_PATIENCE)
 			goto again;
 	}
 	if (retries) {
@@ -504,7 +504,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	int count, stop;
 	unsigned char state = 0;
 
-	q->timestamp = get_clock();
+	q->timestamp = get_tod_clock();
 
 	/*
 	 * Don't check 128 buffers, as otherwise qdio_inbound_q_moved
@@ -563,7 +563,7 @@ static int qdio_inbound_q_moved(struct qdio_q *q)
 	if (bufnr != q->last_move) {
 		q->last_move = bufnr;
 		if (!is_thinint_irq(q->irq_ptr) && MACHINE_IS_LPAR)
-			q->u.in.timestamp = get_clock();
+			q->u.in.timestamp = get_tod_clock();
 		return 1;
 	} else
 		return 0;
@@ -595,7 +595,7 @@ static inline int qdio_inbound_q_done(struct qdio_q *q)
 	 * At this point we know, that inbound first_to_check
 	 * has (probably) not moved (see qdio_inbound_processing).
 	 */
-	if (get_clock() > q->u.in.timestamp + QDIO_INPUT_THRESHOLD) {
+	if (get_tod_clock() > q->u.in.timestamp + QDIO_INPUT_THRESHOLD) {
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in done:%02x",
 			      q->first_to_check);
 		return 1;
@@ -772,7 +772,7 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 	int count, stop;
 	unsigned char state = 0;
 
-	q->timestamp = get_clock();
+	q->timestamp = get_tod_clock();
 
 	if (need_siga_sync(q))
 		if (((queue_type(q) != QDIO_IQDIO_QFMT) &&

commit ce1d801462ce75f9ba84e0bb32a05e1a7c881efe
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Wed Oct 24 12:38:35 2012 +0200

    s390/qdio: rework BUG's and WARN_ON's
    
    Remove or replace BUG/BUG_ON where possible and convert WARN_ON
    to WARN_ON_ONCE if they can occur freqeuently as pointed out by:
    https://lkml.org/lkml/2012/9/27/461
    
    Checks have been removed if:
    - the error condition leads to a hardware error which gets logged
      and in most cases stops the device
    - the error condition is a null pointer access
    - the error condition is just pointless or already handled at
      another location
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index e06fa03ea1e4..1671d3461f29 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -129,7 +129,6 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 	int rc, tmp_count = count, tmp_start = start, nr = q->nr, retried = 0;
 	unsigned int ccq = 0;
 
-	BUG_ON(!q->irq_ptr->sch_token);
 	qperf_inc(q, eqbs);
 
 	if (!q->is_input_q)
@@ -147,7 +146,6 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 	}
 
 	if (rc == 2) {
-		BUG_ON(tmp_count == count);
 		qperf_inc(q, eqbs_partial);
 		DBF_DEV_EVENT(DBF_WARN, q->irq_ptr, "EQBS part:%02x",
 			tmp_count);
@@ -189,8 +187,6 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 
 	if (!count)
 		return 0;
-
-	BUG_ON(!q->irq_ptr->sch_token);
 	qperf_inc(q, sqbs);
 
 	if (!q->is_input_q)
@@ -199,7 +195,7 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 	ccq = do_sqbs(q->irq_ptr->sch_token, state, nr, &tmp_start, &tmp_count);
 	rc = qdio_check_ccq(q, ccq);
 	if (!rc) {
-		WARN_ON(tmp_count);
+		WARN_ON_ONCE(tmp_count);
 		return count - tmp_count;
 	}
 
@@ -224,9 +220,6 @@ static inline int get_buf_states(struct qdio_q *q, unsigned int bufnr,
 	unsigned char __state = 0;
 	int i;
 
-	BUG_ON(bufnr > QDIO_MAX_BUFFERS_MASK);
-	BUG_ON(count > QDIO_MAX_BUFFERS_PER_Q);
-
 	if (is_qebsm(q))
 		return qdio_do_eqbs(q, state, bufnr, count, auto_ack);
 
@@ -258,9 +251,6 @@ static inline int set_buf_states(struct qdio_q *q, int bufnr,
 {
 	int i;
 
-	BUG_ON(bufnr > QDIO_MAX_BUFFERS_MASK);
-	BUG_ON(count > QDIO_MAX_BUFFERS_PER_Q);
-
 	if (is_qebsm(q))
 		return qdio_do_sqbs(q, state, bufnr, count);
 
@@ -345,7 +335,6 @@ static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit,
 
 	/* hipersocket busy condition */
 	if (unlikely(*busy_bit)) {
-		WARN_ON(queue_type(q) != QDIO_IQDIO_QFMT || cc != 2);
 		retries++;
 
 		if (!start_time) {
@@ -559,7 +548,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in nop");
 		break;
 	default:
-		BUG();
+		WARN_ON_ONCE(1);
 	}
 out:
 	return q->first_to_check;
@@ -678,12 +667,10 @@ static inline void qdio_handle_aobs(struct qdio_q *q, int start, int count)
 			if (aob == NULL)
 				continue;
 
-			BUG_ON(q->u.out.sbal_state == NULL);
 			q->u.out.sbal_state[b].flags |=
 				QDIO_OUTBUF_STATE_FLAG_PENDING;
 			q->u.out.aobs[b] = NULL;
 		} else if (state == SLSB_P_OUTPUT_EMPTY) {
-			BUG_ON(q->u.out.sbal_state == NULL);
 			q->u.out.sbal_state[b].aob = NULL;
 		}
 		b = next_buf(b);
@@ -703,12 +690,11 @@ static inline unsigned long qdio_aob_for_buffer(struct qdio_output_q *q,
 		q->aobs[bufnr] = aob;
 	}
 	if (q->aobs[bufnr]) {
-		BUG_ON(q->sbal_state == NULL);
 		q->sbal_state[bufnr].flags = QDIO_OUTBUF_STATE_FLAG_NONE;
 		q->sbal_state[bufnr].aob = q->aobs[bufnr];
 		q->aobs[bufnr]->user1 = (u64) q->sbal_state[bufnr].user;
 		phys_aob = virt_to_phys(q->aobs[bufnr]);
-		BUG_ON(phys_aob & 0xFF);
+		WARN_ON_ONCE(phys_aob & 0xFF);
 	}
 
 out:
@@ -809,8 +795,6 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 		goto out;
 
 	switch (state) {
-	case SLSB_P_OUTPUT_PENDING:
-		BUG();
 	case SLSB_P_OUTPUT_EMPTY:
 		/* the adapter got it */
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr,
@@ -840,7 +824,7 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 	case SLSB_P_OUTPUT_HALTED:
 		break;
 	default:
-		BUG();
+		WARN_ON_ONCE(1);
 	}
 
 out:
@@ -912,7 +896,7 @@ static int qdio_kick_outbound_q(struct qdio_q *q, unsigned long aob)
 static void __qdio_outbound_processing(struct qdio_q *q)
 {
 	qperf_inc(q, tasklet_outbound);
-	BUG_ON(atomic_read(&q->nr_buf_used) < 0);
+	WARN_ON_ONCE(atomic_read(&q->nr_buf_used) < 0);
 
 	if (qdio_outbound_q_moved(q))
 		qdio_kick_handler(q);
@@ -1138,16 +1122,10 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 		irq_ptr->perf_stat.qdio_int++;
 
 	if (IS_ERR(irb)) {
-		switch (PTR_ERR(irb)) {
-		case -EIO:
-			DBF_ERROR("%4x IO error", irq_ptr->schid.sch_no);
-			qdio_set_state(irq_ptr, QDIO_IRQ_STATE_ERR);
-			wake_up(&cdev->private->wait_q);
-			return;
-		default:
-			WARN_ON(1);
-			return;
-		}
+		DBF_ERROR("%4x IO error", irq_ptr->schid.sch_no);
+		qdio_set_state(irq_ptr, QDIO_IRQ_STATE_ERR);
+		wake_up(&cdev->private->wait_q);
+		return;
 	}
 	qdio_irq_check_sense(irq_ptr, irb);
 	cstat = irb->scsw.cmd.cstat;
@@ -1173,7 +1151,7 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 	case QDIO_IRQ_STATE_STOPPED:
 		break;
 	default:
-		WARN_ON(1);
+		WARN_ON_ONCE(1);
 	}
 	wake_up(&cdev->private->wait_q);
 }
@@ -1227,7 +1205,7 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 	if (!irq_ptr)
 		return -ENODEV;
 
-	BUG_ON(irqs_disabled());
+	WARN_ON_ONCE(irqs_disabled());
 	DBF_EVENT("qshutdown:%4x", cdev->private->schid.sch_no);
 
 	mutex_lock(&irq_ptr->setup_mutex);
@@ -1358,7 +1336,6 @@ int qdio_allocate(struct qdio_initialize *init_data)
 	irq_ptr->qdr = (struct qdr *) get_zeroed_page(GFP_KERNEL | GFP_DMA);
 	if (!irq_ptr->qdr)
 		goto out_rel;
-	WARN_ON((unsigned long)irq_ptr->qdr & 0xfff);
 
 	if (qdio_allocate_qs(irq_ptr, init_data->no_input_qs,
 			     init_data->no_output_qs))
@@ -1597,9 +1574,7 @@ static int handle_inbound(struct qdio_q *q, unsigned int callflags,
 
 set:
 	count = set_buf_states(q, bufnr, SLSB_CU_INPUT_EMPTY, count);
-
 	used = atomic_add_return(count, &q->nr_buf_used) - count;
-	BUG_ON(used + count > QDIO_MAX_BUFFERS_PER_Q);
 
 	if (need_siga_in(q))
 		return qdio_siga_input(q);
@@ -1624,7 +1599,6 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 
 	count = set_buf_states(q, bufnr, SLSB_CU_OUTPUT_PRIMED, count);
 	used = atomic_add_return(count, &q->nr_buf_used);
-	BUG_ON(used > QDIO_MAX_BUFFERS_PER_Q);
 
 	if (used == QDIO_MAX_BUFFERS_PER_Q)
 		qperf_inc(q, outbound_queue_full);
@@ -1678,7 +1652,6 @@ int do_QDIO(struct ccw_device *cdev, unsigned int callflags,
 {
 	struct qdio_irq *irq_ptr;
 
-
 	if (bufnr >= QDIO_MAX_BUFFERS_PER_Q || count > QDIO_MAX_BUFFERS_PER_Q)
 		return -EINVAL;
 
@@ -1721,8 +1694,6 @@ int qdio_start_irq(struct ccw_device *cdev, int nr)
 		return -ENODEV;
 	q = irq_ptr->input_qs[nr];
 
-	WARN_ON(queue_irqs_enabled(q));
-
 	clear_nonshared_ind(irq_ptr);
 	qdio_stop_polling(q);
 	clear_bit(QDIO_QUEUE_IRQS_DISABLED, &q->u.in.queue_irq_state);
@@ -1769,7 +1740,6 @@ int qdio_get_next_buffers(struct ccw_device *cdev, int nr, int *bufnr,
 	if (!irq_ptr)
 		return -ENODEV;
 	q = irq_ptr->input_qs[nr];
-	WARN_ON(queue_irqs_enabled(q));
 
 	/*
 	 * Cannot rely on automatic sync after interrupt since queues may

commit a53c8fab3f87c995c30ac226a03af95361243144
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Fri Jul 20 11:15:04 2012 +0200

    s390/comments: unify copyright messages and remove file names
    
    Remove the file name from the comment at top of many files. In most
    cases the file name was wrong anyway, so it's rather pointless.
    
    Also unify the IBM copyright statement. We did have a lot of sightly
    different statements and wanted to change them one after another
    whenever a file gets touched. However that never happened. Instead
    people start to take the old/"wrong" statements to use as a template
    for new files.
    So unify all of them in one go.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 7493efafa0d5..e06fa03ea1e4 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1,9 +1,7 @@
 /*
- * linux/drivers/s390/cio/qdio_main.c
- *
  * Linux for s390 qdio support, buffer handling, qdio API and module support.
  *
- * Copyright 2000,2008 IBM Corp.
+ * Copyright IBM Corp. 2000, 2008
  * Author(s): Utz Bacher <utz.bacher@de.ibm.com>
  *	      Jan Glauber <jang@linux.vnet.ibm.com>
  * 2.6 cio integration by Cornelia Huck <cornelia.huck@de.ibm.com>

commit 473e66baad1e83e6c5dfdca65aba03bf21727202
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed May 9 16:27:39 2012 +0200

    s390/time: always use stckf instead of stck if available
    
    The store clock fast instruction saves a couple of instructions compared
    to the store clock instruction. Always use stckf instead of stck if it
    is available.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Reviewed-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 19902cdc6fac..7493efafa0d5 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -517,7 +517,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	int count, stop;
 	unsigned char state = 0;
 
-	q->timestamp = get_clock_fast();
+	q->timestamp = get_clock();
 
 	/*
 	 * Don't check 128 buffers, as otherwise qdio_inbound_q_moved
@@ -788,7 +788,7 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 	int count, stop;
 	unsigned char state = 0;
 
-	q->timestamp = get_clock_fast();
+	q->timestamp = get_clock();
 
 	if (need_siga_sync(q))
 		if (((queue_type(q) != QDIO_IQDIO_QFMT) &&

commit 1549d13f4c5f0ca77b66bd725287d0b3f877eb6b
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Wed May 9 16:27:34 2012 +0200

    s390/qdio: Cleanup error handling to drivers
    
    Various improvements of qdio error reporting to the
    upper-layer drivers (qeth, zfcp):
    
    - Split QDIO_ERROR_ACTIVATE_CHECK_CONDITION into:
    
      QDIO_ERROR_ACTIVATE: qdio termination interrupt
      QDIO_ERROR_GET_BUF_STATE: QIOASSIST eqbs error
      QDIO_ERROR_SET_BUF_STATE: QIOASSIST sqbs error
    
      Add QDIO_ERROR_FATAL / QDIO_ERROR_TEMPORARY masks
      to ease recovery decision in upper-layer drivers.
    
    - Don't (ab-)use qdio handler errors as return codes
      for do_QDIO but use standard error codes:
    
      -ENOBUFS: temporary target CC=2 condition
      -EBUSY: unresolved SIGA-W CC=2 busy condition
      -EIO: I/O error (CC=1, CC=3)
    
    - Remove unneeded memory clobber from SIGA-R
    - Remove EX_TABLE entry on SIGA-W, we want to see these errors
    
    Reviewed-by: Ursula Braun <ursula.braun@de.ibm.com>
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 35c685c374e9..19902cdc6fac 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -63,7 +63,7 @@ static inline int do_siga_input(unsigned long schid, unsigned int mask,
 		"	ipm	%0\n"
 		"	srl	%0,28\n"
 		: "=d" (cc)
-		: "d" (__fc), "d" (__schid), "d" (__mask) : "cc", "memory");
+		: "d" (__fc), "d" (__schid), "d" (__mask) : "cc");
 	return cc;
 }
 
@@ -74,7 +74,7 @@ static inline int do_siga_input(unsigned long schid, unsigned int mask,
  * @bb: busy bit indicator, set only if SIGA-w/wt could not access a buffer
  * @fc: function code to perform
  *
- * Returns cc or QDIO_ERROR_SIGA_ACCESS_EXCEPTION.
+ * Returns condition code.
  * Note: For IQDC unicast queues only the highest priority queue is processed.
  */
 static inline int do_siga_output(unsigned long schid, unsigned long mask,
@@ -85,18 +85,16 @@ static inline int do_siga_output(unsigned long schid, unsigned long mask,
 	register unsigned long __schid asm("1") = schid;
 	register unsigned long __mask asm("2") = mask;
 	register unsigned long __aob asm("3") = aob;
-	int cc = QDIO_ERROR_SIGA_ACCESS_EXCEPTION;
+	int cc;
 
 	asm volatile(
 		"	siga	0\n"
-		"0:	ipm	%0\n"
+		"	ipm	%0\n"
 		"	srl	%0,28\n"
-		"1:\n"
-		EX_TABLE(0b, 1b)
-		: "+d" (cc), "+d" (__fc), "+d" (__schid), "+d" (__mask),
-		  "+d" (__aob)
-		: : "cc", "memory");
-	*bb = ((unsigned int) __fc) >> 31;
+		: "=d" (cc), "+d" (__fc), "+d" (__aob)
+		: "d" (__schid), "d" (__mask)
+		: "cc");
+	*bb = __fc >> 31;
 	return cc;
 }
 
@@ -167,7 +165,7 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 
 	DBF_ERROR("%4x EQBS ERROR", SCH_NO(q));
 	DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
-	q->handler(q->irq_ptr->cdev, QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
+	q->handler(q->irq_ptr->cdev, QDIO_ERROR_GET_BUF_STATE,
 		   q->nr, q->first_to_kick, count, q->irq_ptr->int_parm);
 	return 0;
 }
@@ -215,7 +213,7 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 
 	DBF_ERROR("%4x SQBS ERROR", SCH_NO(q));
 	DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
-	q->handler(q->irq_ptr->cdev, QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
+	q->handler(q->irq_ptr->cdev, QDIO_ERROR_SET_BUF_STATE,
 		   q->nr, q->first_to_kick, count, q->irq_ptr->int_parm);
 	return 0;
 }
@@ -313,7 +311,7 @@ static inline int qdio_siga_sync(struct qdio_q *q, unsigned int output,
 	cc = do_siga_sync(schid, output, input, fc);
 	if (unlikely(cc))
 		DBF_ERROR("%4x SIGA-S:%2d", SCH_NO(q), cc);
-	return cc;
+	return (cc) ? -EIO : 0;
 }
 
 static inline int qdio_siga_sync_q(struct qdio_q *q)
@@ -384,7 +382,7 @@ static inline int qdio_siga_input(struct qdio_q *q)
 	cc = do_siga_input(schid, q->mask, fc);
 	if (unlikely(cc))
 		DBF_ERROR("%4x SIGA-R:%2d", SCH_NO(q), cc);
-	return cc;
+	return (cc) ? -EIO : 0;
 }
 
 #define qdio_siga_sync_out(q) qdio_siga_sync(q, ~0U, 0)
@@ -443,7 +441,7 @@ static void process_buffer_error(struct qdio_q *q, int count)
 	unsigned char state = (q->is_input_q) ? SLSB_P_INPUT_NOT_INIT :
 					SLSB_P_OUTPUT_NOT_INIT;
 
-	q->qdio_error |= QDIO_ERROR_SLSB_STATE;
+	q->qdio_error = QDIO_ERROR_SLSB_STATE;
 
 	/* special handling for no target buffer empty */
 	if ((!q->is_input_q &&
@@ -575,7 +573,7 @@ static int qdio_inbound_q_moved(struct qdio_q *q)
 
 	bufnr = get_inbound_buffer_frontier(q);
 
-	if ((bufnr != q->last_move) || q->qdio_error) {
+	if (bufnr != q->last_move) {
 		q->last_move = bufnr;
 		if (!is_thinint_irq(q->irq_ptr) && MACHINE_IS_LPAR)
 			q->u.in.timestamp = get_clock();
@@ -863,7 +861,7 @@ static inline int qdio_outbound_q_moved(struct qdio_q *q)
 
 	bufnr = get_outbound_buffer_frontier(q);
 
-	if ((bufnr != q->last_move) || q->qdio_error) {
+	if (bufnr != q->last_move) {
 		q->last_move = bufnr;
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out moved:%1d", q->nr);
 		return 1;
@@ -894,13 +892,16 @@ static int qdio_kick_outbound_q(struct qdio_q *q, unsigned long aob)
 				goto retry;
 			}
 			DBF_ERROR("%4x cc2 BBC:%1d", SCH_NO(q), q->nr);
-			cc |= QDIO_ERROR_SIGA_BUSY;
-		} else
+			cc = -EBUSY;
+		} else {
 			DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-w cc2:%1d", q->nr);
+			cc = -ENOBUFS;
+		}
 		break;
 	case 1:
 	case 3:
 		DBF_ERROR("%4x SIGA-W:%1d", SCH_NO(q), cc);
+		cc = -EIO;
 		break;
 	}
 	if (retries) {
@@ -1090,7 +1091,7 @@ static void qdio_handle_activate_check(struct ccw_device *cdev,
 	}
 
 	count = sub_buf(q->first_to_check, q->first_to_kick);
-	q->handler(q->irq_ptr->cdev, QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
+	q->handler(q->irq_ptr->cdev, QDIO_ERROR_ACTIVATE,
 		   q->nr, q->first_to_kick, count, irq_ptr->int_parm);
 no_handler:
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_STOPPED);
@@ -1691,7 +1692,7 @@ int do_QDIO(struct ccw_device *cdev, unsigned int callflags,
 		      "do%02x b:%02x c:%02x", callflags, bufnr, count);
 
 	if (irq_ptr->state != QDIO_IRQ_STATE_ACTIVE)
-		return -EBUSY;
+		return -EIO;
 	if (!count)
 		return 0;
 	if (callflags & QDIO_FLAG_SYNC_INPUT)

commit 61d84979ab9826c292812059f99248603da28fba
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Fri Mar 23 11:13:04 2012 +0100

    [S390] qdio: log all adapter characteristics
    
    Log all adapter characteristics in the s390dbf to ease debugging of
    new features.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Reported-by: Raymond Higgs <rayhiggs@us.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 2a0dfcb0bc42..35c685c374e9 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1458,7 +1458,6 @@ int qdio_establish(struct qdio_initialize *init_data)
 	}
 
 	qdio_setup_ssqd_info(irq_ptr);
-	DBF_EVENT("qib ac:%4x", irq_ptr->qib.ac);
 
 	qdio_detect_hsicq(irq_ptr);
 

commit 3ab121ab18669226742891416fe7ecc86dadb047
Author: Michael Holzheu <holzheu@linux.vnet.ibm.com>
Date:   Sun Mar 11 11:59:32 2012 -0400

    [S390] kernel: Add z/VM LGR detection
    
    Currently the following mechanisms are available to move active
    Linux on System z instances between machines:
    * z/VM 6.2 SSI (Single System Image)
    * Suspend/resume
    For moving Linux instances in this patch the term LGR (Linux Guest
    Relocation) is used. Because such an operation is critical, it
    should be detectable from Linux. With this patch for both, a live
    system and a kernel dump, the information about LGRs is accessible.
    To identify a guest, stsi and stfle data is used. A new function
    lgr_info_log() compares the current data (lgr_info_cur) with the
    last recorded one (lgr_info_last). In case the two data sets differ,
    lgr_info_cur is logged to the "lgr" s390dbf.
    
    The following trigger points call lgr_info_log():
    * panic
    * die
    * kdump
    * LGR timer
    * PSW restart
    * QDIO recovery
    * resume
    
    This patch also changes the s390dbf hex_ascii view. Now only printable ASCII
    characters are shown.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Michael Holzheu <holzheu@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 770a740a393c..2a0dfcb0bc42 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -18,6 +18,7 @@
 #include <linux/atomic.h>
 #include <asm/debug.h>
 #include <asm/qdio.h>
+#include <asm/ipl.h>
 
 #include "cio.h"
 #include "css.h"
@@ -1093,6 +1094,11 @@ static void qdio_handle_activate_check(struct ccw_device *cdev,
 		   q->nr, q->first_to_kick, count, irq_ptr->int_parm);
 no_handler:
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_STOPPED);
+	/*
+	 * In case of z/VM LGR (Live Guest Migration) QDIO recovery will happen.
+	 * Therefore we call the LGR detection function here.
+	 */
+	lgr_info_log();
 }
 
 static void qdio_establish_handle_irq(struct ccw_device *cdev, int cstat,

commit 7b3cc67d4445995a025a4b55a7dc687b6829b4ca
Author: Steffen Maier <maier@linux.vnet.ibm.com>
Date:   Fri Mar 2 17:32:58 2012 +0100

    [S390] qdio: fix handler function arguments for zfcp data router
    
    Git commit 25f269f17316549e "[S390] qdio: EQBS retry after CCQ 96"
    introduced a regression in regard to the zfcp data router.
    Revoke the incorrect simplification of the function call arguments
    for the qdio handler to make the zfcp hardware data router working
    again.
    
    This is applicable to 3.2+ kernels.
    
    Signed-off-by: Steffen Maier <maier@linux.vnet.ibm.com>
    Reviewed-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 3ef8d071c64a..770a740a393c 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -167,7 +167,7 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 	DBF_ERROR("%4x EQBS ERROR", SCH_NO(q));
 	DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
 	q->handler(q->irq_ptr->cdev, QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
-		   0, -1, -1, q->irq_ptr->int_parm);
+		   q->nr, q->first_to_kick, count, q->irq_ptr->int_parm);
 	return 0;
 }
 
@@ -215,7 +215,7 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 	DBF_ERROR("%4x SQBS ERROR", SCH_NO(q));
 	DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
 	q->handler(q->irq_ptr->cdev, QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
-		   0, -1, -1, q->irq_ptr->int_parm);
+		   q->nr, q->first_to_kick, count, q->irq_ptr->int_parm);
 	return 0;
 }
 

commit 5f4026f8b2e4c5e26713d6c707592a33326a88c4
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Sun Oct 30 15:17:20 2011 +0100

    [S390] qdio: prevent dsci access without adapter interrupts
    
    A kernel panic may occur during sending or receiving network packets
    on a machine without adapter interrupts since commit d36deae.
    The bug is triggered by writing to the shared indicator address which
    is set to 0 if the machine doesn't have adapter interrupts.
    
    Make the reading and setting of the shared indicator dependent on the
    adapter interrupt feature and while at it move the code to the
    file containing the adapter interrupt related code.
    
    Thanks to Jan Jaeger for tracking this down.
    
    Reported-by: Jan Jaeger <jan.jaeger@westnet.com.au>
    Tested-by: Jan Jaeger <jan.jaeger@westnet.com.au>
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 2fcdc0b2f0aa..3ef8d071c64a 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1719,9 +1719,7 @@ int qdio_start_irq(struct ccw_device *cdev, int nr)
 
 	WARN_ON(queue_irqs_enabled(q));
 
-	if (!shared_ind(q))
-		xchg(q->irq_ptr->dsci, 0);
-
+	clear_nonshared_ind(irq_ptr);
 	qdio_stop_polling(q);
 	clear_bit(QDIO_QUEUE_IRQS_DISABLED, &q->u.in.queue_irq_state);
 
@@ -1729,7 +1727,7 @@ int qdio_start_irq(struct ccw_device *cdev, int nr)
 	 * We need to check again to not lose initiative after
 	 * resetting the ACK state.
 	 */
-	if (!shared_ind(q) && *q->irq_ptr->dsci)
+	if (test_nonshared_ind(irq_ptr))
 		goto rescan;
 	if (!qdio_inbound_q_done(q))
 		goto rescan;

commit c4736d968254d71eba6814b2234a4e63f40aca15
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Sun Oct 30 15:17:11 2011 +0100

    [S390] sparse: fix sparse static warnings
    
    Make functions and data static to avoid sparse warnings.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index ab9de1be77a3..2fcdc0b2f0aa 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -281,7 +281,7 @@ static inline int set_buf_state(struct qdio_q *q, int bufnr,
 }
 
 /* set slsb states to initial state */
-void qdio_init_buf_states(struct qdio_irq *irq_ptr)
+static void qdio_init_buf_states(struct qdio_irq *irq_ptr)
 {
 	struct qdio_q *q;
 	int i;

commit 6ffed94ea73c0c15e3201d4d479b6efe8343fb96
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Sun Oct 30 15:17:08 2011 +0100

    [S390] qdio: remove multicast polling
    
    The multicast poll check for the outbound queue is redundant since
    3d6c76f "[S390] qdio: outbound tasklet scan threshold". Remove the check.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 5ec5317f7903..ab9de1be77a3 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -921,10 +921,6 @@ static void __qdio_outbound_processing(struct qdio_q *q)
 		if (!pci_out_supported(q) && !qdio_outbound_q_done(q))
 			goto sched;
 
-	if ((queue_type(q) == QDIO_IQDIO_QFMT) &&
-	    (atomic_read(&q->nr_buf_used)) > QDIO_IQDIO_POLL_LVL)
-		goto sched;
-
 	if (q->u.out.pci_out_enabled)
 		return;
 

commit 2768b2ded129ee92a8f8bf9049983c6b37ed44bf
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Sun Oct 30 15:17:07 2011 +0100

    [S390] qdio: reset outbound SBAL error states
    
    Don't leave outbound SBALs in error state after a target full condition.
    Reset the state to not initialized to make the error handling consistent
    across all types of errors.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 7c567b2268a7..5ec5317f7903 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -450,7 +450,7 @@ static void process_buffer_error(struct qdio_q *q, int count)
 		qperf_inc(q, target_full);
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "OUTFULL FTC:%02x",
 			      q->first_to_check);
-		return;
+		goto set;
 	}
 
 	DBF_ERROR("%4x BUF ERROR", SCH_NO(q));
@@ -460,6 +460,7 @@ static void process_buffer_error(struct qdio_q *q, int count)
 		  q->sbal[q->first_to_check]->element[14].sflags,
 		  q->sbal[q->first_to_check]->element[15].sflags);
 
+set:
 	/*
 	 * Interrupts may be avoided as long as the error is present
 	 * so change the buffer state immediately to avoid starvation.

commit 25f269f17316549e026c5dd0db7526411a504de6
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Sun Oct 30 15:17:06 2011 +0100

    [S390] qdio: EQBS retry after CCQ 96
    
    Running under z/VM with QIOASSIST enabled, qdio queues could stall if EQBS
    did not extract all SBAL states. Add an instant retry for EQBS and, if the
    retry fails, set up a timer to ensure outstanding SBALs are processed later.
    
    While at it, optimize qdio_do_eqbs and qdio_do_sqbs to eliminate 3 jumps on
    the hot path.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index a76d6764ce67..7c567b2268a7 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -104,9 +104,12 @@ static inline int qdio_check_ccq(struct qdio_q *q, unsigned int ccq)
 	/* all done or next buffer state different */
 	if (ccq == 0 || ccq == 32)
 		return 0;
-	/* not all buffers processed */
-	if (ccq == 96 || ccq == 97)
+	/* no buffer processed */
+	if (ccq == 97)
 		return 1;
+	/* not all buffers processed */
+	if (ccq == 96)
+		return 2;
 	/* notify devices immediately */
 	DBF_ERROR("%4x ccq:%3d", SCH_NO(q), ccq);
 	return -EIO;
@@ -126,10 +129,8 @@ static inline int qdio_check_ccq(struct qdio_q *q, unsigned int ccq)
 static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 			int start, int count, int auto_ack)
 {
+	int rc, tmp_count = count, tmp_start = start, nr = q->nr, retried = 0;
 	unsigned int ccq = 0;
-	int tmp_count = count, tmp_start = start;
-	int nr = q->nr;
-	int rc;
 
 	BUG_ON(!q->irq_ptr->sch_token);
 	qperf_inc(q, eqbs);
@@ -140,30 +141,34 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 	ccq = do_eqbs(q->irq_ptr->sch_token, state, nr, &tmp_start, &tmp_count,
 		      auto_ack);
 	rc = qdio_check_ccq(q, ccq);
-
-	/* At least one buffer was processed, return and extract the remaining
-	 * buffers later.
-	 */
-	if ((ccq == 96) && (count != tmp_count)) {
-		qperf_inc(q, eqbs_partial);
-		return (count - tmp_count);
-	}
+	if (!rc)
+		return count - tmp_count;
 
 	if (rc == 1) {
 		DBF_DEV_EVENT(DBF_WARN, q->irq_ptr, "EQBS again:%2d", ccq);
 		goto again;
 	}
 
-	if (rc < 0) {
-		DBF_ERROR("%4x EQBS ERROR", SCH_NO(q));
-		DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
-		q->handler(q->irq_ptr->cdev,
-			   QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
-			   q->nr, q->first_to_kick, count,
-			   q->irq_ptr->int_parm);
-		return 0;
+	if (rc == 2) {
+		BUG_ON(tmp_count == count);
+		qperf_inc(q, eqbs_partial);
+		DBF_DEV_EVENT(DBF_WARN, q->irq_ptr, "EQBS part:%02x",
+			tmp_count);
+		/*
+		 * Retry once, if that fails bail out and process the
+		 * extracted buffers before trying again.
+		 */
+		if (!retried++)
+			goto again;
+		else
+			return count - tmp_count;
 	}
-	return count - tmp_count;
+
+	DBF_ERROR("%4x EQBS ERROR", SCH_NO(q));
+	DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
+	q->handler(q->irq_ptr->cdev, QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
+		   0, -1, -1, q->irq_ptr->int_parm);
+	return 0;
 }
 
 /**
@@ -196,22 +201,22 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 again:
 	ccq = do_sqbs(q->irq_ptr->sch_token, state, nr, &tmp_start, &tmp_count);
 	rc = qdio_check_ccq(q, ccq);
-	if (rc == 1) {
+	if (!rc) {
+		WARN_ON(tmp_count);
+		return count - tmp_count;
+	}
+
+	if (rc == 1 || rc == 2) {
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "SQBS again:%2d", ccq);
 		qperf_inc(q, sqbs_partial);
 		goto again;
 	}
-	if (rc < 0) {
-		DBF_ERROR("%4x SQBS ERROR", SCH_NO(q));
-		DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
-		q->handler(q->irq_ptr->cdev,
-			   QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
-			   q->nr, q->first_to_kick, count,
-			   q->irq_ptr->int_parm);
-		return 0;
-	}
-	WARN_ON(tmp_count);
-	return count - tmp_count;
+
+	DBF_ERROR("%4x SQBS ERROR", SCH_NO(q));
+	DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
+	q->handler(q->irq_ptr->cdev, QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
+		   0, -1, -1, q->irq_ptr->int_parm);
+	return 0;
 }
 
 /* returns number of examined buffers and their common state in *state */
@@ -915,10 +920,6 @@ static void __qdio_outbound_processing(struct qdio_q *q)
 		if (!pci_out_supported(q) && !qdio_outbound_q_done(q))
 			goto sched;
 
-	/* bail out for HiperSockets unicast queues */
-	if (queue_type(q) == QDIO_IQDIO_QFMT && !multicast_outbound(q))
-		return;
-
 	if ((queue_type(q) == QDIO_IQDIO_QFMT) &&
 	    (atomic_read(&q->nr_buf_used)) > QDIO_IQDIO_POLL_LVL)
 		goto sched;
@@ -928,8 +929,8 @@ static void __qdio_outbound_processing(struct qdio_q *q)
 
 	/*
 	 * Now we know that queue type is either qeth without pci enabled
-	 * or HiperSockets multicast. Make sure buffer switch from PRIMED to
-	 * EMPTY is noticed and outbound_handler is called after some time.
+	 * or HiperSockets. Make sure buffer switch from PRIMED to EMPTY
+	 * is noticed and outbound_handler is called after some time.
 	 */
 	if (qdio_outbound_q_done(q))
 		del_timer(&q->u.out.timer);

commit a2b86019826cb97fd964fbaf101410c64cd78681
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Sun Oct 30 15:17:05 2011 +0100

    [S390] qdio: add timestamp for last queue scan time
    
    Add a timestamp per queue and update the timestamp when the queue is
    scanned. Add the queue timestamps and the timestamp of the last
    adapter interrupt to the debugfs output. The timestamps are useful
    for debugging stall conditions.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 7ded1b26fd25..a76d6764ce67 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -512,6 +512,8 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	int count, stop;
 	unsigned char state = 0;
 
+	q->timestamp = get_clock_fast();
+
 	/*
 	 * Don't check 128 buffers, as otherwise qdio_inbound_q_moved
 	 * would return 0.
@@ -781,6 +783,8 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 	int count, stop;
 	unsigned char state = 0;
 
+	q->timestamp = get_clock_fast();
+
 	if (need_siga_sync(q))
 		if (((queue_type(q) != QDIO_IQDIO_QFMT) &&
 		    !pci_out_supported(q)) ||

commit de400d6b78d15a73023485f050bc6b1709dc7a79
Author: Peter Oberparleiter <peter.oberparleiter@de.ibm.com>
Date:   Sun Oct 30 15:16:04 2011 +0100

    [S390] fix mismatch in summation of I/O IRQ statistics
    
    Current IRQ statistics support does not show detail counts for I/O
    interrupts which are processed internally only. The result is a
    summation count which is way off such as this one:
    
               CPU0       CPU1       CPU2
    I/O:       1331        710        442
    [...]
    QAI:         15         16         16   [I/O] QDIO Adapter Interrupt
    QDI:          1          0          0   [I/O] QDIO Interrupt
    DAS:        706        645        381   [I/O] DASD
    C15:         26         10          0   [I/O] 3215
    C70:          0          0          0   [I/O] 3270
    TAP:          0          0          0   [I/O] Tape
    VMR:          0          0          0   [I/O] Unit Record Devices
    LCS:          0          0          0   [I/O] LCS
    CLW:          0          0          0   [I/O] CLAW
    CTC:          0          0          0   [I/O] CTC
    APB:          0          0          0   [I/O] AP Bus
    
    Fix this by moving I/O interrupt accounting into the common I/O layer.
    
    Signed-off-by: Peter Oberparleiter <peter.oberparleiter@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 6547ff469410..7ded1b26fd25 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -15,7 +15,6 @@
 #include <linux/delay.h>
 #include <linux/gfp.h>
 #include <linux/io.h>
-#include <linux/kernel_stat.h>
 #include <linux/atomic.h>
 #include <asm/debug.h>
 #include <asm/qdio.h>
@@ -1128,7 +1127,6 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 		return;
 	}
 
-	kstat_cpu(smp_processor_id()).irqs[IOINT_QDI]++;
 	if (irq_ptr->perf_stat_enabled)
 		irq_ptr->perf_stat.qdio_int++;
 

commit ec7ae517537ae5c7b0b2cd7f562dfa3e7a05b954
Merge: 97d2eb13a019 590134fa78fb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 28 16:44:18 2011 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6: (204 commits)
      [SCSI] qla4xxx: export address/port of connection (fix udev disk names)
      [SCSI] ipr: Fix BUG on adapter dump timeout
      [SCSI] megaraid_sas: Fix instance access in megasas_reset_timer
      [SCSI] hpsa: change confusing message to be more clear
      [SCSI] iscsi class: fix vlan configuration
      [SCSI] qla4xxx: fix data alignment and use nl helpers
      [SCSI] iscsi class: fix link local mispelling
      [SCSI] iscsi class: Replace iscsi_get_next_target_id with IDA
      [SCSI] aacraid: use lower snprintf() limit
      [SCSI] lpfc 8.3.27: Change driver version to 8.3.27
      [SCSI] lpfc 8.3.27: T10 additions for SLI4
      [SCSI] lpfc 8.3.27: Fix queue allocation failure recovery
      [SCSI] lpfc 8.3.27: Change algorithm for getting physical port name
      [SCSI] lpfc 8.3.27: Changed worst case mailbox timeout
      [SCSI] lpfc 8.3.27: Miscellanous logic and interface fixes
      [SCSI] megaraid_sas: Changelog and version update
      [SCSI] megaraid_sas: Add driver workaround for PERC5/1068 kdump kernel panic
      [SCSI] megaraid_sas: Add multiple MSI-X vector/multiple reply queue support
      [SCSI] megaraid_sas: Add support for MegaRAID 9360/9380 12GB/s controllers
      [SCSI] megaraid_sas: Clear FUSION_IN_RESET before enabling interrupts
      ...

commit dfe5bb506172307e43287b8962348fb85801c0f4
Author: Swen Schillig <swen@vnet.ibm.com>
Date:   Mon Aug 15 14:40:31 2011 +0200

    [SCSI] qdio: base support for hardware data router with zfcp
    
    FICON Express8S supports hardware data router, which requires an
    adapted qdio request format.
    This part 1/2 provides the qdio base required for exploitation in
    zfcp.
    
    Signed-off-by: Swen Schillig <swen@vnet.ibm.com>
    Signed-off-by: Steffen Maier <maier@linux.vnet.ibm.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 288c9140290e..d2c1f1becd4f 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -156,7 +156,8 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 		DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
 		q->handler(q->irq_ptr->cdev,
 			   QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
-			   0, -1, -1, q->irq_ptr->int_parm);
+			   q->nr, q->first_to_kick, count,
+			   q->irq_ptr->int_parm);
 		return 0;
 	}
 	return count - tmp_count;
@@ -202,7 +203,8 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 		DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
 		q->handler(q->irq_ptr->cdev,
 			   QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
-			   0, -1, -1, q->irq_ptr->int_parm);
+			   q->nr, q->first_to_kick, count,
+			   q->irq_ptr->int_parm);
 		return 0;
 	}
 	WARN_ON(tmp_count);
@@ -942,6 +944,7 @@ static void qdio_handle_activate_check(struct ccw_device *cdev,
 {
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 	struct qdio_q *q;
+	int count;
 
 	DBF_ERROR("%4x ACT CHECK", irq_ptr->schid.sch_no);
 	DBF_ERROR("intp :%lx", intparm);
@@ -955,8 +958,10 @@ static void qdio_handle_activate_check(struct ccw_device *cdev,
 		dump_stack();
 		goto no_handler;
 	}
+
+	count = sub_buf(q->first_to_check, q->first_to_kick);
 	q->handler(q->irq_ptr->cdev, QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
-		   0, -1, -1, irq_ptr->int_parm);
+		   q->nr, q->first_to_kick, count, irq_ptr->int_parm);
 no_handler:
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_STOPPED);
 }

commit 9cb7284f3058d272758ebaaa8f6f924cb99792bc
Author: frank.blaschka@de.ibm.com <frank.blaschka@de.ibm.com>
Date:   Mon Aug 8 01:33:56 2011 +0000

    qdio: support forced signal adapter indications
    
    This patch ensures that signal adapter commands are issued if they are
    indicated to be required.
    
    Signed-off-by: Einar Lueck <elelueck@de.ibm.com>
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Frank Blaschka <frank.blaschka@de.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index a7153f2f3aff..9a122280246c 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1592,12 +1592,9 @@ static int handle_inbound(struct qdio_q *q, unsigned int callflags,
 	used = atomic_add_return(count, &q->nr_buf_used) - count;
 	BUG_ON(used + count > QDIO_MAX_BUFFERS_PER_Q);
 
-	/* no need to signal as long as the adapter had free buffers */
-	if (used)
-		return 0;
-
 	if (need_siga_in(q))
 		return qdio_siga_input(q);
+
 	return 0;
 }
 

commit 104ea556ee7f40039c9c635d0c267b1fde084a81
Author: frank.blaschka@de.ibm.com <frank.blaschka@de.ibm.com>
Date:   Mon Aug 8 01:33:55 2011 +0000

    qdio: support asynchronous delivery of storage blocks
    
    This patch introduces support for asynchronous delivery of storage blocks for
    Hipersockets. Upper layers may exploit this functionality to reuse SBALs for
    which the delivery status is still pending.
    
    Signed-off-by: Einar Lueck <elelueck@de.ibm.com>
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Frank Blaschka <frank.blaschka@de.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 288c9140290e..a7153f2f3aff 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -14,6 +14,7 @@
 #include <linux/timer.h>
 #include <linux/delay.h>
 #include <linux/gfp.h>
+#include <linux/io.h>
 #include <linux/kernel_stat.h>
 #include <linux/atomic.h>
 #include <asm/debug.h>
@@ -77,11 +78,13 @@ static inline int do_siga_input(unsigned long schid, unsigned int mask,
  * Note: For IQDC unicast queues only the highest priority queue is processed.
  */
 static inline int do_siga_output(unsigned long schid, unsigned long mask,
-				 unsigned int *bb, unsigned int fc)
+				 unsigned int *bb, unsigned int fc,
+				 unsigned long aob)
 {
 	register unsigned long __fc asm("0") = fc;
 	register unsigned long __schid asm("1") = schid;
 	register unsigned long __mask asm("2") = mask;
+	register unsigned long __aob asm("3") = aob;
 	int cc = QDIO_ERROR_SIGA_ACCESS_EXCEPTION;
 
 	asm volatile(
@@ -90,7 +93,8 @@ static inline int do_siga_output(unsigned long schid, unsigned long mask,
 		"	srl	%0,28\n"
 		"1:\n"
 		EX_TABLE(0b, 1b)
-		: "+d" (cc), "+d" (__fc), "+d" (__schid), "+d" (__mask)
+		: "+d" (cc), "+d" (__fc), "+d" (__schid), "+d" (__mask),
+		  "+d" (__aob)
 		: : "cc", "memory");
 	*bb = ((unsigned int) __fc) >> 31;
 	return cc;
@@ -212,7 +216,7 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 /* returns number of examined buffers and their common state in *state */
 static inline int get_buf_states(struct qdio_q *q, unsigned int bufnr,
 				 unsigned char *state, unsigned int count,
-				 int auto_ack)
+				 int auto_ack, int merge_pending)
 {
 	unsigned char __state = 0;
 	int i;
@@ -224,9 +228,14 @@ static inline int get_buf_states(struct qdio_q *q, unsigned int bufnr,
 		return qdio_do_eqbs(q, state, bufnr, count, auto_ack);
 
 	for (i = 0; i < count; i++) {
-		if (!__state)
+		if (!__state) {
 			__state = q->slsb.val[bufnr];
-		else if (q->slsb.val[bufnr] != __state)
+			if (merge_pending && __state == SLSB_P_OUTPUT_PENDING)
+				__state = SLSB_P_OUTPUT_EMPTY;
+		} else if (merge_pending) {
+			if ((q->slsb.val[bufnr] & __state) != __state)
+				break;
+		} else if (q->slsb.val[bufnr] != __state)
 			break;
 		bufnr = next_buf(bufnr);
 	}
@@ -237,7 +246,7 @@ static inline int get_buf_states(struct qdio_q *q, unsigned int bufnr,
 static inline int get_buf_state(struct qdio_q *q, unsigned int bufnr,
 				unsigned char *state, int auto_ack)
 {
-	return get_buf_states(q, bufnr, state, 1, auto_ack);
+	return get_buf_states(q, bufnr, state, 1, auto_ack, 0);
 }
 
 /* wrap-around safe setting of slsb states, returns number of changed buffers */
@@ -308,19 +317,28 @@ static inline int qdio_siga_sync_q(struct qdio_q *q)
 		return qdio_siga_sync(q, q->mask, 0);
 }
 
-static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit)
+static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit,
+	unsigned long aob)
 {
 	unsigned long schid = *((u32 *) &q->irq_ptr->schid);
 	unsigned int fc = QDIO_SIGA_WRITE;
 	u64 start_time = 0;
 	int retries = 0, cc;
+	unsigned long laob = 0;
+
+	if (q->u.out.use_cq && aob != 0) {
+		fc = QDIO_SIGA_WRITEQ;
+		laob = aob;
+	}
 
 	if (is_qebsm(q)) {
 		schid = q->irq_ptr->sch_token;
 		fc |= QDIO_SIGA_QEBSM_FLAG;
 	}
 again:
-	cc = do_siga_output(schid, q->mask, busy_bit, fc);
+	WARN_ON_ONCE((aob && queue_type(q) != QDIO_IQDIO_QFMT) ||
+		(aob && fc != QDIO_SIGA_WRITEQ));
+	cc = do_siga_output(schid, q->mask, busy_bit, fc, laob);
 
 	/* hipersocket busy condition */
 	if (unlikely(*busy_bit)) {
@@ -379,7 +397,7 @@ int debug_get_buf_state(struct qdio_q *q, unsigned int bufnr,
 {
 	if (need_siga_sync(q))
 		qdio_siga_sync_q(q);
-	return get_buf_states(q, bufnr, state, 1, 0);
+	return get_buf_states(q, bufnr, state, 1, 0, 0);
 }
 
 static inline void qdio_stop_polling(struct qdio_q *q)
@@ -507,7 +525,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	 * No siga sync here, as a PCI or we after a thin interrupt
 	 * already sync'ed the queues.
 	 */
-	count = get_buf_states(q, q->first_to_check, &state, count, 1);
+	count = get_buf_states(q, q->first_to_check, &state, count, 1, 0);
 	if (!count)
 		goto out;
 
@@ -590,6 +608,107 @@ static inline int qdio_inbound_q_done(struct qdio_q *q)
 		return 0;
 }
 
+static inline int contains_aobs(struct qdio_q *q)
+{
+	return !q->is_input_q && q->u.out.use_cq;
+}
+
+static inline void qdio_trace_aob(struct qdio_irq *irq, struct qdio_q *q,
+				int i, struct qaob *aob)
+{
+	int tmp;
+
+	DBF_DEV_EVENT(DBF_INFO, irq, "AOB%d:%lx", i,
+			(unsigned long) virt_to_phys(aob));
+	DBF_DEV_EVENT(DBF_INFO, irq, "RES00:%lx",
+			(unsigned long) aob->res0[0]);
+	DBF_DEV_EVENT(DBF_INFO, irq, "RES01:%lx",
+			(unsigned long) aob->res0[1]);
+	DBF_DEV_EVENT(DBF_INFO, irq, "RES02:%lx",
+			(unsigned long) aob->res0[2]);
+	DBF_DEV_EVENT(DBF_INFO, irq, "RES03:%lx",
+			(unsigned long) aob->res0[3]);
+	DBF_DEV_EVENT(DBF_INFO, irq, "RES04:%lx",
+			(unsigned long) aob->res0[4]);
+	DBF_DEV_EVENT(DBF_INFO, irq, "RES05:%lx",
+			(unsigned long) aob->res0[5]);
+	DBF_DEV_EVENT(DBF_INFO, irq, "RES1:%x", aob->res1);
+	DBF_DEV_EVENT(DBF_INFO, irq, "RES2:%x", aob->res2);
+	DBF_DEV_EVENT(DBF_INFO, irq, "RES3:%x", aob->res3);
+	DBF_DEV_EVENT(DBF_INFO, irq, "AORC:%u", aob->aorc);
+	DBF_DEV_EVENT(DBF_INFO, irq, "FLAGS:%u", aob->flags);
+	DBF_DEV_EVENT(DBF_INFO, irq, "CBTBS:%u", aob->cbtbs);
+	DBF_DEV_EVENT(DBF_INFO, irq, "SBC:%u", aob->sb_count);
+	for (tmp = 0; tmp < QDIO_MAX_ELEMENTS_PER_BUFFER; ++tmp) {
+		DBF_DEV_EVENT(DBF_INFO, irq, "SBA%d:%lx", tmp,
+				(unsigned long) aob->sba[tmp]);
+		DBF_DEV_EVENT(DBF_INFO, irq, "rSBA%d:%lx", tmp,
+				(unsigned long) q->sbal[i]->element[tmp].addr);
+		DBF_DEV_EVENT(DBF_INFO, irq, "DC%d:%u", tmp, aob->dcount[tmp]);
+		DBF_DEV_EVENT(DBF_INFO, irq, "rDC%d:%u", tmp,
+				q->sbal[i]->element[tmp].length);
+	}
+	DBF_DEV_EVENT(DBF_INFO, irq, "USER0:%lx", (unsigned long) aob->user0);
+	for (tmp = 0; tmp < 2; ++tmp) {
+		DBF_DEV_EVENT(DBF_INFO, irq, "RES4%d:%lx", tmp,
+			(unsigned long) aob->res4[tmp]);
+	}
+	DBF_DEV_EVENT(DBF_INFO, irq, "USER1:%lx", (unsigned long) aob->user1);
+	DBF_DEV_EVENT(DBF_INFO, irq, "USER2:%lx", (unsigned long) aob->user2);
+}
+
+static inline void qdio_handle_aobs(struct qdio_q *q, int start, int count)
+{
+	unsigned char state = 0;
+	int j, b = start;
+
+	if (!contains_aobs(q))
+		return;
+
+	for (j = 0; j < count; ++j) {
+		get_buf_state(q, b, &state, 0);
+		if (state == SLSB_P_OUTPUT_PENDING) {
+			struct qaob *aob = q->u.out.aobs[b];
+			if (aob == NULL)
+				continue;
+
+			BUG_ON(q->u.out.sbal_state == NULL);
+			q->u.out.sbal_state[b].flags |=
+				QDIO_OUTBUF_STATE_FLAG_PENDING;
+			q->u.out.aobs[b] = NULL;
+		} else if (state == SLSB_P_OUTPUT_EMPTY) {
+			BUG_ON(q->u.out.sbal_state == NULL);
+			q->u.out.sbal_state[b].aob = NULL;
+		}
+		b = next_buf(b);
+	}
+}
+
+static inline unsigned long qdio_aob_for_buffer(struct qdio_output_q *q,
+					int bufnr)
+{
+	unsigned long phys_aob = 0;
+
+	if (!q->use_cq)
+		goto out;
+
+	if (!q->aobs[bufnr]) {
+		struct qaob *aob = qdio_allocate_aob();
+		q->aobs[bufnr] = aob;
+	}
+	if (q->aobs[bufnr]) {
+		BUG_ON(q->sbal_state == NULL);
+		q->sbal_state[bufnr].flags = QDIO_OUTBUF_STATE_FLAG_NONE;
+		q->sbal_state[bufnr].aob = q->aobs[bufnr];
+		q->aobs[bufnr]->user1 = (u64) q->sbal_state[bufnr].user;
+		phys_aob = virt_to_phys(q->aobs[bufnr]);
+		BUG_ON(phys_aob & 0xFF);
+	}
+
+out:
+	return phys_aob;
+}
+
 static void qdio_kick_handler(struct qdio_q *q)
 {
 	int start = q->first_to_kick;
@@ -610,6 +729,8 @@ static void qdio_kick_handler(struct qdio_q *q)
 			      start, count);
 	}
 
+	qdio_handle_aobs(q, start, count);
+
 	q->handler(q->irq_ptr->cdev, q->qdio_error, q->nr, start, count,
 		   q->irq_ptr->int_parm);
 
@@ -672,23 +793,26 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 	 */
 	count = min(atomic_read(&q->nr_buf_used), QDIO_MAX_BUFFERS_MASK);
 	stop = add_buf(q->first_to_check, count);
-
 	if (q->first_to_check == stop)
-		return q->first_to_check;
+		goto out;
 
-	count = get_buf_states(q, q->first_to_check, &state, count, 0);
+	count = get_buf_states(q, q->first_to_check, &state, count, 0, 1);
 	if (!count)
-		return q->first_to_check;
+		goto out;
 
 	switch (state) {
+	case SLSB_P_OUTPUT_PENDING:
+		BUG();
 	case SLSB_P_OUTPUT_EMPTY:
 		/* the adapter got it */
-		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out empty:%1d %02x", q->nr, count);
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr,
+			"out empty:%1d %02x", q->nr, count);
 
 		atomic_sub(count, &q->nr_buf_used);
 		q->first_to_check = add_buf(q->first_to_check, count);
 		if (q->irq_ptr->perf_stat_enabled)
 			account_sbals(q, count);
+
 		break;
 	case SLSB_P_OUTPUT_ERROR:
 		process_buffer_error(q, count);
@@ -701,7 +825,8 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 		/* the adapter has not fetched the output yet */
 		if (q->irq_ptr->perf_stat_enabled)
 			q->q_stats.nr_sbal_nop++;
-		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out primed:%1d", q->nr);
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out primed:%1d",
+			      q->nr);
 		break;
 	case SLSB_P_OUTPUT_NOT_INIT:
 	case SLSB_P_OUTPUT_HALTED:
@@ -709,6 +834,8 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 	default:
 		BUG();
 	}
+
+out:
 	return q->first_to_check;
 }
 
@@ -732,7 +859,7 @@ static inline int qdio_outbound_q_moved(struct qdio_q *q)
 		return 0;
 }
 
-static int qdio_kick_outbound_q(struct qdio_q *q)
+static int qdio_kick_outbound_q(struct qdio_q *q, unsigned long aob)
 {
 	int retries = 0, cc;
 	unsigned int busy_bit;
@@ -744,7 +871,7 @@ static int qdio_kick_outbound_q(struct qdio_q *q)
 retry:
 	qperf_inc(q, siga_write);
 
-	cc = qdio_siga_output(q, &busy_bit);
+	cc = qdio_siga_output(q, &busy_bit, aob);
 	switch (cc) {
 	case 0:
 		break;
@@ -921,8 +1048,9 @@ static void qdio_int_handler_pci(struct qdio_irq *irq_ptr)
 			}
 			q->u.in.queue_start_poll(q->irq_ptr->cdev, q->nr,
 						 q->irq_ptr->int_parm);
-		} else
+		} else {
 			tasklet_schedule(&q->tasklet);
+		}
 	}
 
 	if (!pci_out_supported(q))
@@ -1236,6 +1364,26 @@ int qdio_allocate(struct qdio_initialize *init_data)
 }
 EXPORT_SYMBOL_GPL(qdio_allocate);
 
+static void qdio_detect_hsicq(struct qdio_irq *irq_ptr)
+{
+	struct qdio_q *q = irq_ptr->input_qs[0];
+	int i, use_cq = 0;
+
+	if (irq_ptr->nr_input_qs > 1 && queue_type(q) == QDIO_IQDIO_QFMT)
+		use_cq = 1;
+
+	for_each_output_queue(irq_ptr, q, i) {
+		if (use_cq) {
+			if (qdio_enable_async_operation(&q->u.out) < 0) {
+				use_cq = 0;
+				continue;
+			}
+		} else
+			qdio_disable_async_operation(&q->u.out);
+	}
+	DBF_EVENT("use_cq:%d", use_cq);
+}
+
 /**
  * qdio_establish - establish queues on a qdio subchannel
  * @init_data: initialization data
@@ -1301,6 +1449,8 @@ int qdio_establish(struct qdio_initialize *init_data)
 	qdio_setup_ssqd_info(irq_ptr);
 	DBF_EVENT("qib ac:%4x", irq_ptr->qib.ac);
 
+	qdio_detect_hsicq(irq_ptr);
+
 	/* qebsm is now setup if available, initialize buffer states */
 	qdio_init_buf_states(irq_ptr);
 
@@ -1480,17 +1630,21 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 		q->u.out.pci_out_enabled = 0;
 
 	if (queue_type(q) == QDIO_IQDIO_QFMT) {
-		/* One SIGA-W per buffer required for unicast HiperSockets. */
+		unsigned long phys_aob = 0;
+
+		/* One SIGA-W per buffer required for unicast HSI */
 		WARN_ON_ONCE(count > 1 && !multicast_outbound(q));
 
-		rc = qdio_kick_outbound_q(q);
+		phys_aob = qdio_aob_for_buffer(&q->u.out, bufnr);
+
+		rc = qdio_kick_outbound_q(q, phys_aob);
 	} else if (need_siga_sync(q)) {
 		rc = qdio_siga_sync_q(q);
 	} else {
 		/* try to fast requeue buffers */
 		get_buf_state(q, prev_buf(bufnr), &state, 0);
 		if (state != SLSB_CU_OUTPUT_PRIMED)
-			rc = qdio_kick_outbound_q(q);
+			rc = qdio_kick_outbound_q(q, 0);
 		else
 			qperf_inc(q, fast_requeue);
 	}
@@ -1518,6 +1672,7 @@ int do_QDIO(struct ccw_device *cdev, unsigned int callflags,
 {
 	struct qdio_irq *irq_ptr;
 
+
 	if (bufnr >= QDIO_MAX_BUFFERS_PER_Q || count > QDIO_MAX_BUFFERS_PER_Q)
 		return -EINVAL;
 
@@ -1562,7 +1717,7 @@ int qdio_start_irq(struct ccw_device *cdev, int nr)
 
 	WARN_ON(queue_irqs_enabled(q));
 
-	if (!shared_ind(q->irq_ptr->dsci))
+	if (!shared_ind(q))
 		xchg(q->irq_ptr->dsci, 0);
 
 	qdio_stop_polling(q);
@@ -1572,7 +1727,7 @@ int qdio_start_irq(struct ccw_device *cdev, int nr)
 	 * We need to check again to not lose initiative after
 	 * resetting the ACK state.
 	 */
-	if (!shared_ind(q->irq_ptr->dsci) && *q->irq_ptr->dsci)
+	if (!shared_ind(q) && *q->irq_ptr->dsci)
 		goto rescan;
 	if (!qdio_inbound_q_done(q))
 		goto rescan;

commit be8d97a540cec5d272b1e08e27741a3c3aa38f66
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Wed Aug 3 16:44:17 2011 +0200

    [S390] qdio: 2nd stage retry on SIGA-W busy conditions
    
    The SIGA-W may return with the busy bit set which means the device was
    blocked. The busy loop which retries the SIGA-W for 100us may not be
    long enough when running under a heavily loaded hypervisor.
    
    Extend the retry mechanism by adding a longer second stage which retries
    the SIGA-W for up to 10s. In difference to the first retry loop the second
    stage is using mdelay to stop the cpu between the retries and thereby
    avoid additional preassure in on the hypervisor.
    If the second stage retry is successfull a device reset is avoided.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index e58169c32474..288c9140290e 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -313,7 +313,7 @@ static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit)
 	unsigned long schid = *((u32 *) &q->irq_ptr->schid);
 	unsigned int fc = QDIO_SIGA_WRITE;
 	u64 start_time = 0;
-	int cc;
+	int retries = 0, cc;
 
 	if (is_qebsm(q)) {
 		schid = q->irq_ptr->sch_token;
@@ -325,6 +325,7 @@ static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit)
 	/* hipersocket busy condition */
 	if (unlikely(*busy_bit)) {
 		WARN_ON(queue_type(q) != QDIO_IQDIO_QFMT || cc != 2);
+		retries++;
 
 		if (!start_time) {
 			start_time = get_clock();
@@ -333,6 +334,11 @@ static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit)
 		if ((get_clock() - start_time) < QDIO_BUSY_BIT_PATIENCE)
 			goto again;
 	}
+	if (retries) {
+		DBF_DEV_EVENT(DBF_WARN, q->irq_ptr,
+			      "%4x cc2 BB1:%1d", SCH_NO(q), q->nr);
+		DBF_DEV_EVENT(DBF_WARN, q->irq_ptr, "count:%u", retries);
+	}
 	return cc;
 }
 
@@ -728,13 +734,14 @@ static inline int qdio_outbound_q_moved(struct qdio_q *q)
 
 static int qdio_kick_outbound_q(struct qdio_q *q)
 {
+	int retries = 0, cc;
 	unsigned int busy_bit;
-	int cc;
 
 	if (!need_siga_out(q))
 		return 0;
 
 	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-w:%1d", q->nr);
+retry:
 	qperf_inc(q, siga_write);
 
 	cc = qdio_siga_output(q, &busy_bit);
@@ -743,7 +750,11 @@ static int qdio_kick_outbound_q(struct qdio_q *q)
 		break;
 	case 2:
 		if (busy_bit) {
-			DBF_ERROR("%4x cc2 REP:%1d", SCH_NO(q), q->nr);
+			while (++retries < QDIO_BUSY_BIT_RETRIES) {
+				mdelay(QDIO_BUSY_BIT_RETRY_DELAY);
+				goto retry;
+			}
+			DBF_ERROR("%4x cc2 BBC:%1d", SCH_NO(q), q->nr);
 			cc |= QDIO_ERROR_SIGA_BUSY;
 		} else
 			DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-w cc2:%1d", q->nr);
@@ -753,6 +764,10 @@ static int qdio_kick_outbound_q(struct qdio_q *q)
 		DBF_ERROR("%4x SIGA-W:%1d", SCH_NO(q), cc);
 		break;
 	}
+	if (retries) {
+		DBF_ERROR("%4x cc2 BB2:%1d", SCH_NO(q), q->nr);
+		DBF_ERROR("count:%u", retries);
+	}
 	return cc;
 }
 

commit 60063497a95e716c9a689af3be2687d261f115b4
Author: Arun Sharma <asharma@fb.com>
Date:   Tue Jul 26 16:09:06 2011 -0700

    atomic: use <linux/atomic.h>
    
    This allows us to move duplicated code in <asm/atomic.h>
    (atomic_inc_not_zero() for now) to <linux/atomic.h>
    
    Signed-off-by: Arun Sharma <asharma@fb.com>
    Reviewed-by: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: David Miller <davem@davemloft.net>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Acked-by: Mike Frysinger <vapier@gentoo.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 570d4da10696..e58169c32474 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -15,7 +15,7 @@
 #include <linux/delay.h>
 #include <linux/gfp.h>
 #include <linux/kernel_stat.h>
-#include <asm/atomic.h>
+#include <linux/atomic.h>
 #include <asm/debug.h>
 #include <asm/qdio.h>
 

commit 3ec90878bade9280dee87c9e27d759f1cee07e70
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Mon Jun 6 14:14:40 2011 +0200

    [S390] qdio: Split SBAL entry flags
    
    The qdio SBAL entry flag is made-up of four different values that are
    independent of one another. Some of the bits are reserved by the
    hardware and should not be changed by qdio. Currently all four values
    are overwritten since the SBAL entry flag is defined as an u32.
    
    Split the SBAL entry flag into four u8's as defined by the hardware
    and don't touch the reserved bits.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 55e8f721e38a..570d4da10696 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -416,7 +416,7 @@ static void process_buffer_error(struct qdio_q *q, int count)
 
 	/* special handling for no target buffer empty */
 	if ((!q->is_input_q &&
-	    (q->sbal[q->first_to_check]->element[15].flags & 0xff) == 0x10)) {
+	    (q->sbal[q->first_to_check]->element[15].sflags) == 0x10)) {
 		qperf_inc(q, target_full);
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "OUTFULL FTC:%02x",
 			      q->first_to_check);
@@ -427,8 +427,8 @@ static void process_buffer_error(struct qdio_q *q, int count)
 	DBF_ERROR((q->is_input_q) ? "IN:%2d" : "OUT:%2d", q->nr);
 	DBF_ERROR("FTC:%3d C:%3d", q->first_to_check, count);
 	DBF_ERROR("F14:%2x F15:%2x",
-		  q->sbal[q->first_to_check]->element[14].flags & 0xff,
-		  q->sbal[q->first_to_check]->element[15].flags & 0xff);
+		  q->sbal[q->first_to_check]->element[14].sflags,
+		  q->sbal[q->first_to_check]->element[15].sflags);
 
 	/*
 	 * Interrupts may be avoided as long as the error is present

commit c26001d4e9133fe45e47eee18cfd826219e71fb9
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Mon May 23 10:24:38 2011 +0200

    [S390] qdio: prevent compile warning
    
    Prevent the following compile warning for !CONFIG_64BIT:
    
      CC      drivers/s390/cio/qdio_main.o
    drivers/s390/cio/qdio_main.c: In function handle_outbound:
    drivers/s390/cio/qdio_main.c:1449: warning: state may be used uninitialized in this function
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index e8f267eb8887..55e8f721e38a 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1446,7 +1446,7 @@ static int handle_inbound(struct qdio_q *q, unsigned int callflags,
 static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 			   int bufnr, int count)
 {
-	unsigned char state;
+	unsigned char state = 0;
 	int used, rc = 0;
 
 	qperf_inc(q, outbound_call);

commit bffbbd2df4196a73ffdc16709866dd96eb66aad8
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Wed Apr 20 10:15:33 2011 +0200

    [S390] qdio: reset error states immediately
    
    The qdio hardware may surpress further interrupts as long as a SBAL is in
    the error state. That can lead to unnotified data in the SBALs following
    the error state. To prevent this behaviour change the SBAL[s] in error
    state immediately to another program owned state so interrupts are again
    received for further traffic on the device.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index c532ba929ccd..e8f267eb8887 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -407,8 +407,11 @@ static inline void account_sbals(struct qdio_q *q, int count)
 	q->q_stats.nr_sbals[pos]++;
 }
 
-static void announce_buffer_error(struct qdio_q *q, int count)
+static void process_buffer_error(struct qdio_q *q, int count)
 {
+	unsigned char state = (q->is_input_q) ? SLSB_P_INPUT_NOT_INIT :
+					SLSB_P_OUTPUT_NOT_INIT;
+
 	q->qdio_error |= QDIO_ERROR_SLSB_STATE;
 
 	/* special handling for no target buffer empty */
@@ -426,6 +429,12 @@ static void announce_buffer_error(struct qdio_q *q, int count)
 	DBF_ERROR("F14:%2x F15:%2x",
 		  q->sbal[q->first_to_check]->element[14].flags & 0xff,
 		  q->sbal[q->first_to_check]->element[15].flags & 0xff);
+
+	/*
+	 * Interrupts may be avoided as long as the error is present
+	 * so change the buffer state immediately to avoid starvation.
+	 */
+	set_buf_states(q, q->first_to_check, state, count);
 }
 
 static inline void inbound_primed(struct qdio_q *q, int count)
@@ -506,8 +515,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 			account_sbals(q, count);
 		break;
 	case SLSB_P_INPUT_ERROR:
-		announce_buffer_error(q, count);
-		/* process the buffer, the upper layer will take care of it */
+		process_buffer_error(q, count);
 		q->first_to_check = add_buf(q->first_to_check, count);
 		atomic_sub(count, &q->nr_buf_used);
 		if (q->irq_ptr->perf_stat_enabled)
@@ -677,8 +685,7 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 			account_sbals(q, count);
 		break;
 	case SLSB_P_OUTPUT_ERROR:
-		announce_buffer_error(q, count);
-		/* process the buffer, the upper layer will take care of it */
+		process_buffer_error(q, count);
 		q->first_to_check = add_buf(q->first_to_check, count);
 		atomic_sub(count, &q->nr_buf_used);
 		if (q->irq_ptr->perf_stat_enabled)

commit aa5c8df398266a141fb5ff0e77cbc7904a3e0648
Author: Sebastian Ott <sebott@linux.vnet.ibm.com>
Date:   Mon Apr 4 09:43:31 2011 +0200

    [S390] qdio: fix init sequence
    
    Reorder the initialization sequence of the qdio module to avoid
    writing to an uninitialized debug feature entry. Also reorder
    the exit function to restore a consistent cleanup path.
    
    Signed-off-by: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 479c665e9e7c..c532ba929ccd 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1649,26 +1649,26 @@ static int __init init_QDIO(void)
 {
 	int rc;
 
-	rc = qdio_setup_init();
+	rc = qdio_debug_init();
 	if (rc)
 		return rc;
+	rc = qdio_setup_init();
+	if (rc)
+		goto out_debug;
 	rc = tiqdio_allocate_memory();
 	if (rc)
 		goto out_cache;
-	rc = qdio_debug_init();
-	if (rc)
-		goto out_ti;
 	rc = tiqdio_register_thinints();
 	if (rc)
-		goto out_debug;
+		goto out_ti;
 	return 0;
 
-out_debug:
-	qdio_debug_exit();
 out_ti:
 	tiqdio_free_memory();
 out_cache:
 	qdio_setup_exit();
+out_debug:
+	qdio_debug_exit();
 	return rc;
 }
 
@@ -1676,8 +1676,8 @@ static void __exit exit_QDIO(void)
 {
 	tiqdio_unregister_thinints();
 	tiqdio_free_memory();
-	qdio_debug_exit();
 	qdio_setup_exit();
+	qdio_debug_exit();
 }
 
 module_init(init_QDIO);

commit 9a26513eb67ec4b2cb1744834076afad21b68aac
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Wed Mar 23 10:16:01 2011 +0100

    [S390] qdio: prevent handling of buffers if count is zero
    
    Exit do_QDIO early if the buffer count is zero to prevent side effects
    in the following functions.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 5640c89cd9de..479c665e9e7c 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1508,7 +1508,8 @@ int do_QDIO(struct ccw_device *cdev, unsigned int callflags,
 
 	if (irq_ptr->state != QDIO_IRQ_STATE_ACTIVE)
 		return -EBUSY;
-
+	if (!count)
+		return 0;
 	if (callflags & QDIO_FLAG_SYNC_INPUT)
 		return handle_inbound(irq_ptr->input_qs[q_nr],
 				      callflags, bufnr, count);

commit 6fa1098ac1bc2ad19627a08ae654caf360bc85aa
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Mon Jan 31 11:30:08 2011 +0100

    [S390] qdio: prevent compile warning under CONFIG_32BIT
    
    Prevent the following compiler warning if compiling a 31 bit kernel:
    
    drivers/s390/cio/qdio_main.c: In function get_outbound_buffer_frontier:
    drivers/s390/cio/qdio_main.c:646:16: warning: state may be used uninitialized in this function
      CC      lib/radix-tree.o
      CC      drivers/s390/scsi/zfcp_cfdc.o
    drivers/s390/cio/qdio_main.c: In function qdio_inbound_q_moved:
    drivers/s390/cio/qdio_main.c:479:16: warning: state may be used uninitialized in this function
    drivers/s390/cio/qdio_main.c:479:16: note: state was declared here
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index e9fff2b9bce2..5640c89cd9de 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -476,7 +476,7 @@ static inline void inbound_primed(struct qdio_q *q, int count)
 static int get_inbound_buffer_frontier(struct qdio_q *q)
 {
 	int count, stop;
-	unsigned char state;
+	unsigned char state = 0;
 
 	/*
 	 * Don't check 128 buffers, as otherwise qdio_inbound_q_moved
@@ -643,7 +643,7 @@ void qdio_inbound_processing(unsigned long data)
 static int get_outbound_buffer_frontier(struct qdio_q *q)
 {
 	int count, stop;
-	unsigned char state;
+	unsigned char state = 0;
 
 	if (need_siga_sync(q))
 		if (((queue_type(q) != QDIO_IQDIO_QFMT) &&

commit 90adac58d1a4daf3560739ff5b76497d5ece16c4
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Wed Jan 5 12:47:54 2011 +0100

    [S390] qdio: cleanup SIGA sync
    
    Simplify the SIGA sync code and add unlikely annotations. In polling mode
    SBALs may be accessed without interrupt, so call SIGA sync before every scan.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 8a722f208325..e9fff2b9bce2 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -286,9 +286,6 @@ static inline int qdio_siga_sync(struct qdio_q *q, unsigned int output,
 	unsigned int fc = QDIO_SIGA_SYNC;
 	int cc;
 
-	if (!need_siga_sync(q))
-		return 0;
-
 	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-s:%1d", q->nr);
 	qperf_inc(q, siga_sync);
 
@@ -311,16 +308,6 @@ static inline int qdio_siga_sync_q(struct qdio_q *q)
 		return qdio_siga_sync(q, q->mask, 0);
 }
 
-static inline int qdio_siga_sync_out(struct qdio_q *q)
-{
-	return qdio_siga_sync(q, ~0U, 0);
-}
-
-static inline int qdio_siga_sync_all(struct qdio_q *q)
-{
-	return qdio_siga_sync(q, ~0U, ~0U);
-}
-
 static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit)
 {
 	unsigned long schid = *((u32 *) &q->irq_ptr->schid);
@@ -369,21 +356,23 @@ static inline int qdio_siga_input(struct qdio_q *q)
 	return cc;
 }
 
-static inline void qdio_sync_after_thinint(struct qdio_q *q)
+#define qdio_siga_sync_out(q) qdio_siga_sync(q, ~0U, 0)
+#define qdio_siga_sync_all(q) qdio_siga_sync(q, ~0U, ~0U)
+
+static inline void qdio_sync_queues(struct qdio_q *q)
 {
-	if (pci_out_supported(q)) {
-		if (need_siga_sync_thinint(q))
-			qdio_siga_sync_all(q);
-		else if (need_siga_sync_out_thinint(q))
-			qdio_siga_sync_out(q);
-	} else
+	/* PCI capable outbound queues will also be scanned so sync them too */
+	if (pci_out_supported(q))
+		qdio_siga_sync_all(q);
+	else
 		qdio_siga_sync_q(q);
 }
 
 int debug_get_buf_state(struct qdio_q *q, unsigned int bufnr,
 			unsigned char *state)
 {
-	qdio_siga_sync_q(q);
+	if (need_siga_sync(q))
+		qdio_siga_sync_q(q);
 	return get_buf_states(q, bufnr, state, 1, 0);
 }
 
@@ -560,7 +549,8 @@ static inline int qdio_inbound_q_done(struct qdio_q *q)
 	if (!atomic_read(&q->nr_buf_used))
 		return 1;
 
-	qdio_siga_sync_q(q);
+	if (need_siga_sync(q))
+		qdio_siga_sync_q(q);
 	get_buf_state(q, q->first_to_check, &state, 0);
 
 	if (state == SLSB_P_INPUT_PRIMED || state == SLSB_P_INPUT_ERROR)
@@ -655,9 +645,12 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 	int count, stop;
 	unsigned char state;
 
-	if (((queue_type(q) != QDIO_IQDIO_QFMT) && !pci_out_supported(q)) ||
-	    (queue_type(q) == QDIO_IQDIO_QFMT && multicast_outbound(q)))
-		qdio_siga_sync_q(q);
+	if (need_siga_sync(q))
+		if (((queue_type(q) != QDIO_IQDIO_QFMT) &&
+		    !pci_out_supported(q)) ||
+		    (queue_type(q) == QDIO_IQDIO_QFMT &&
+		    multicast_outbound(q)))
+			qdio_siga_sync_q(q);
 
 	/*
 	 * Don't check 128 buffers, as otherwise qdio_inbound_q_moved
@@ -829,7 +822,8 @@ static inline void qdio_check_outbound_after_thinint(struct qdio_q *q)
 static void __tiqdio_inbound_processing(struct qdio_q *q)
 {
 	qperf_inc(q, tasklet_inbound);
-	qdio_sync_after_thinint(q);
+	if (need_siga_sync(q) && need_siga_sync_after_ai(q))
+		qdio_sync_queues(q);
 
 	/*
 	 * The interrupt could be caused by a PCI request. Check the
@@ -909,16 +903,14 @@ static void qdio_int_handler_pci(struct qdio_irq *irq_ptr)
 			tasklet_schedule(&q->tasklet);
 	}
 
-	if (!(irq_ptr->qib.ac & QIB_AC_OUTBOUND_PCI_SUPPORTED))
+	if (!pci_out_supported(q))
 		return;
 
 	for_each_output_queue(irq_ptr, q, i) {
 		if (qdio_outbound_q_done(q))
 			continue;
-
-		if (!siga_syncs_out_pci(q))
+		if (need_siga_sync(q) && need_siga_sync_out_after_pci(q))
 			qdio_siga_sync_q(q);
-
 		tasklet_schedule(&q->tasklet);
 	}
 }
@@ -1470,7 +1462,7 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 		WARN_ON_ONCE(count > 1 && !multicast_outbound(q));
 
 		rc = qdio_kick_outbound_q(q);
-	} else if (unlikely(need_siga_sync(q))) {
+	} else if (need_siga_sync(q)) {
 		rc = qdio_siga_sync_q(q);
 	} else {
 		/* try to fast requeue buffers */
@@ -1597,12 +1589,14 @@ int qdio_get_next_buffers(struct ccw_device *cdev, int nr, int *bufnr,
 	q = irq_ptr->input_qs[nr];
 	WARN_ON(queue_irqs_enabled(q));
 
-	qdio_sync_after_thinint(q);
-
 	/*
-	 * The interrupt could be caused by a PCI request. Check the
-	 * PCI capable outbound queues.
+	 * Cannot rely on automatic sync after interrupt since queues may
+	 * also be examined without interrupt.
 	 */
+	if (need_siga_sync(q))
+		qdio_sync_queues(q);
+
+	/* check the PCI capable outbound queues. */
 	qdio_check_outbound_after_thinint(q);
 
 	if (!qdio_inbound_q_moved(q))

commit 110da31709023de61735f2d8a3e52c20c23bb570
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Wed Jan 5 12:47:53 2011 +0100

    [S390] qdio: remove enhanced SIGA
    
    HiperSocket devices only use one SBAL per qdio call without the enhanced SIGA
    feature. Since that feature is currently not used remove it from the qdio code
    so the compiler can generate better code for the HiperSocket outbound path.
    While at it mark the SIGA error conditions as unlikely.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 99823477d57e..8a722f208325 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -298,7 +298,7 @@ static inline int qdio_siga_sync(struct qdio_q *q, unsigned int output,
 	}
 
 	cc = do_siga_sync(schid, output, input, fc);
-	if (cc)
+	if (unlikely(cc))
 		DBF_ERROR("%4x SIGA-S:%2d", SCH_NO(q), cc);
 	return cc;
 }
@@ -328,9 +328,6 @@ static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit)
 	u64 start_time = 0;
 	int cc;
 
-	if (q->u.out.use_enh_siga)
-		fc = 3;
-
 	if (is_qebsm(q)) {
 		schid = q->irq_ptr->sch_token;
 		fc |= QDIO_SIGA_QEBSM_FLAG;
@@ -339,7 +336,7 @@ static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit)
 	cc = do_siga_output(schid, q->mask, busy_bit, fc);
 
 	/* hipersocket busy condition */
-	if (*busy_bit) {
+	if (unlikely(*busy_bit)) {
 		WARN_ON(queue_type(q) != QDIO_IQDIO_QFMT || cc != 2);
 
 		if (!start_time) {
@@ -367,7 +364,7 @@ static inline int qdio_siga_input(struct qdio_q *q)
 	}
 
 	cc = do_siga_input(schid, q->mask, fc);
-	if (cc)
+	if (unlikely(cc))
 		DBF_ERROR("%4x SIGA-R:%2d", SCH_NO(q), cc);
 	return cc;
 }
@@ -1288,7 +1285,6 @@ int qdio_establish(struct qdio_initialize *init_data)
 	}
 
 	qdio_setup_ssqd_info(irq_ptr);
-	DBF_EVENT("qDmmwc:%2x", irq_ptr->ssqd_desc.mmwc);
 	DBF_EVENT("qib ac:%4x", irq_ptr->qib.ac);
 
 	/* qebsm is now setup if available, initialize buffer states */
@@ -1466,48 +1462,25 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 	if (callflags & QDIO_FLAG_PCI_OUT) {
 		q->u.out.pci_out_enabled = 1;
 		qperf_inc(q, pci_request_int);
-	}
-	else
+	} else
 		q->u.out.pci_out_enabled = 0;
 
 	if (queue_type(q) == QDIO_IQDIO_QFMT) {
-		if (multicast_outbound(q))
+		/* One SIGA-W per buffer required for unicast HiperSockets. */
+		WARN_ON_ONCE(count > 1 && !multicast_outbound(q));
+
+		rc = qdio_kick_outbound_q(q);
+	} else if (unlikely(need_siga_sync(q))) {
+		rc = qdio_siga_sync_q(q);
+	} else {
+		/* try to fast requeue buffers */
+		get_buf_state(q, prev_buf(bufnr), &state, 0);
+		if (state != SLSB_CU_OUTPUT_PRIMED)
 			rc = qdio_kick_outbound_q(q);
 		else
-			if ((q->irq_ptr->ssqd_desc.mmwc > 1) &&
-			    (count > 1) &&
-			    (count <= q->irq_ptr->ssqd_desc.mmwc)) {
-				/* exploit enhanced SIGA */
-				q->u.out.use_enh_siga = 1;
-				rc = qdio_kick_outbound_q(q);
-			} else {
-				/*
-				* One siga-w per buffer required for unicast
-				* HiperSockets.
-				*/
-				q->u.out.use_enh_siga = 0;
-				while (count--) {
-					rc = qdio_kick_outbound_q(q);
-					if (rc)
-						goto out;
-				}
-			}
-		goto out;
+			qperf_inc(q, fast_requeue);
 	}
 
-	if (need_siga_sync(q)) {
-		qdio_siga_sync_q(q);
-		goto out;
-	}
-
-	/* try to fast requeue buffers */
-	get_buf_state(q, prev_buf(bufnr), &state, 0);
-	if (state != SLSB_CU_OUTPUT_PRIMED)
-		rc = qdio_kick_outbound_q(q);
-	else
-		qperf_inc(q, fast_requeue);
-
-out:
 	/* in case of SIGA errors we must process the error immediately */
 	if (used >= q->u.out.scan_threshold || rc)
 		tasklet_schedule(&q->tasklet);

commit 958c0ba403cb6a693b54be2389f9ef53377fa259
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Wed Jan 5 12:47:52 2011 +0100

    [S390] qdio: use proper QEBSM operand for SIGA-R and SIGA-S
    
    If QIOASSIST is enabled for a qdio device the SIGA instruction requires
    a modified function code. This function code modifier was missing for
    SIGA-R and SIGA-S which can lead to a kernel panic caused by an
    operand exception.
    
    Cc: stable@kernel.org
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index af86875bede4..99823477d57e 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -30,11 +30,12 @@ MODULE_AUTHOR("Utz Bacher <utz.bacher@de.ibm.com>,"\
 MODULE_DESCRIPTION("QDIO base support");
 MODULE_LICENSE("GPL");
 
-static inline int do_siga_sync(struct subchannel_id schid,
-			       unsigned int out_mask, unsigned int in_mask)
+static inline int do_siga_sync(unsigned long schid,
+			       unsigned int out_mask, unsigned int in_mask,
+			       unsigned int fc)
 {
-	register unsigned long __fc asm ("0") = 2;
-	register struct subchannel_id __schid asm ("1") = schid;
+	register unsigned long __fc asm ("0") = fc;
+	register unsigned long __schid asm ("1") = schid;
 	register unsigned long out asm ("2") = out_mask;
 	register unsigned long in asm ("3") = in_mask;
 	int cc;
@@ -48,10 +49,11 @@ static inline int do_siga_sync(struct subchannel_id schid,
 	return cc;
 }
 
-static inline int do_siga_input(struct subchannel_id schid, unsigned int mask)
+static inline int do_siga_input(unsigned long schid, unsigned int mask,
+				unsigned int fc)
 {
-	register unsigned long __fc asm ("0") = 1;
-	register struct subchannel_id __schid asm ("1") = schid;
+	register unsigned long __fc asm ("0") = fc;
+	register unsigned long __schid asm ("1") = schid;
 	register unsigned long __mask asm ("2") = mask;
 	int cc;
 
@@ -280,6 +282,8 @@ void qdio_init_buf_states(struct qdio_irq *irq_ptr)
 static inline int qdio_siga_sync(struct qdio_q *q, unsigned int output,
 			  unsigned int input)
 {
+	unsigned long schid = *((u32 *) &q->irq_ptr->schid);
+	unsigned int fc = QDIO_SIGA_SYNC;
 	int cc;
 
 	if (!need_siga_sync(q))
@@ -288,7 +292,12 @@ static inline int qdio_siga_sync(struct qdio_q *q, unsigned int output,
 	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-s:%1d", q->nr);
 	qperf_inc(q, siga_sync);
 
-	cc = do_siga_sync(q->irq_ptr->schid, output, input);
+	if (is_qebsm(q)) {
+		schid = q->irq_ptr->sch_token;
+		fc |= QDIO_SIGA_QEBSM_FLAG;
+	}
+
+	cc = do_siga_sync(schid, output, input, fc);
 	if (cc)
 		DBF_ERROR("%4x SIGA-S:%2d", SCH_NO(q), cc);
 	return cc;
@@ -314,8 +323,8 @@ static inline int qdio_siga_sync_all(struct qdio_q *q)
 
 static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit)
 {
-	unsigned long schid;
-	unsigned int fc = 0;
+	unsigned long schid = *((u32 *) &q->irq_ptr->schid);
+	unsigned int fc = QDIO_SIGA_WRITE;
 	u64 start_time = 0;
 	int cc;
 
@@ -324,11 +333,8 @@ static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit)
 
 	if (is_qebsm(q)) {
 		schid = q->irq_ptr->sch_token;
-		fc |= 0x80;
+		fc |= QDIO_SIGA_QEBSM_FLAG;
 	}
-	else
-		schid = *((u32 *)&q->irq_ptr->schid);
-
 again:
 	cc = do_siga_output(schid, q->mask, busy_bit, fc);
 
@@ -348,12 +354,19 @@ static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit)
 
 static inline int qdio_siga_input(struct qdio_q *q)
 {
+	unsigned long schid = *((u32 *) &q->irq_ptr->schid);
+	unsigned int fc = QDIO_SIGA_READ;
 	int cc;
 
 	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-r:%1d", q->nr);
 	qperf_inc(q, siga_read);
 
-	cc = do_siga_input(q->irq_ptr->schid, q->mask);
+	if (is_qebsm(q)) {
+		schid = q->irq_ptr->sch_token;
+		fc |= QDIO_SIGA_QEBSM_FLAG;
+	}
+
+	cc = do_siga_input(schid, q->mask, fc);
 	if (cc)
 		DBF_ERROR("%4x SIGA-R:%2d", SCH_NO(q), cc);
 	return cc;

commit 0195843bfda90a215f3b72c9aac2fd0bc9244b67
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Wed Jan 5 12:47:51 2011 +0100

    [S390] qdio: outbound queue full counter
    
    Add a counter for outbound queue full events to the qdio statistics.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 4c0109900c74..af86875bede4 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1447,6 +1447,9 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 	used = atomic_add_return(count, &q->nr_buf_used);
 	BUG_ON(used > QDIO_MAX_BUFFERS_PER_Q);
 
+	if (used == QDIO_MAX_BUFFERS_PER_Q)
+		qperf_inc(q, outbound_queue_full);
+
 	if (callflags & QDIO_FLAG_PCI_OUT) {
 		q->u.out.pci_out_enabled = 1;
 		qperf_inc(q, pci_request_int);

commit 3d6c76ff32bb9b2ebf6e859855d315eb42e3df50
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Wed Jan 5 12:47:50 2011 +0100

    [S390] qdio: outbound tasklet scan threshold
    
    Introduce a scan treshold for the qdio outbound queues. By setting the
    threshold the driver can tell qdio after how much used SBALs qdio
    should schedule the outbound tasklet that scans the queue for finished
    SBALs. The threshold is specific by the drivers because a
    Hipersockets device is much faster in utilizing outbound buffers than a
    ZFCP or OSA device.
    
    The default values after how many used SBALs the tasklet should run are:
    
    OSA:          > 31 SBALs
    Hipersockets: > 7 SBALs
    zfcp:         > 55 SBALs
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 6621de94f3ad..4c0109900c74 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1492,7 +1492,13 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 		qperf_inc(q, fast_requeue);
 
 out:
-	tasklet_schedule(&q->tasklet);
+	/* in case of SIGA errors we must process the error immediately */
+	if (used >= q->u.out.scan_threshold || rc)
+		tasklet_schedule(&q->tasklet);
+	else
+		/* free the SBALs in case of no further traffic */
+		if (!timer_pending(&q->u.out.timer))
+			mod_timer(&q->u.out.timer, jiffies + HZ);
 	return rc;
 }
 

commit 4f325184f2d4c1f2258873b2a333005dc4dfcbc0
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Wed Jan 5 12:47:49 2011 +0100

    [S390] qdio: prevent race for shared indicators
    
    If the shared indicator is used the following race leads to
    an inbound stall:
    
    Device                  CPU0                    CPU1
    ========================================================
    
    non-shared DSCI =>1
    ALSI => 1
                            Thin INT
                            ALSI => 0
    
                            non-shared DSCI
                            tasklets scheduled
    
    shared DSCI => 1
    ALSI => 1
    
                            shared DSCI => 0
                            ALSI ? -> set
                                                    Thin INT
                                                    ALSI => 0
                            ALSI was set,
                            shared DSCI => 1
    
    After that no more interrupts occur because the DSCI is still set.
    Fix that race by only resetting the shared DSCI if it was actually
    set so the tasklets for all shared devices are scheduled and will
    run after the interrupt.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 194ea8c182b2..6621de94f3ad 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1552,7 +1552,7 @@ int qdio_start_irq(struct ccw_device *cdev, int nr)
 
 	WARN_ON(queue_irqs_enabled(q));
 
-	if (!shared_ind(q->irq_ptr))
+	if (!shared_ind(q->irq_ptr->dsci))
 		xchg(q->irq_ptr->dsci, 0);
 
 	qdio_stop_polling(q);
@@ -1562,7 +1562,7 @@ int qdio_start_irq(struct ccw_device *cdev, int nr)
 	 * We need to check again to not lose initiative after
 	 * resetting the ACK state.
 	 */
-	if (!shared_ind(q->irq_ptr) && *q->irq_ptr->dsci)
+	if (!shared_ind(q->irq_ptr->dsci) && *q->irq_ptr->dsci)
 		goto rescan;
 	if (!qdio_inbound_q_done(q))
 		goto rescan;

commit 30d77c3e1cbdff304b16ae02cb56baaa308e42fd
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Wed Jan 5 12:47:29 2011 +0100

    [S390] qdio: add qdio interrupts to interrupt statistics
    
    Count traditional qdio interrupts and adapter interrupts for qdio
    in the interrupt statistics.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 5fcfa7f9e9ef..194ea8c182b2 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -14,6 +14,7 @@
 #include <linux/timer.h>
 #include <linux/delay.h>
 #include <linux/gfp.h>
+#include <linux/kernel_stat.h>
 #include <asm/atomic.h>
 #include <asm/debug.h>
 #include <asm/qdio.h>
@@ -970,6 +971,7 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 		return;
 	}
 
+	kstat_cpu(smp_processor_id()).irqs[IOINT_QDI]++;
 	if (irq_ptr->perf_stat_enabled)
 		irq_ptr->perf_stat.qdio_int++;
 

commit d36deae75011a7890f0e730dd0f867c64081cb50
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Tue Sep 7 21:14:39 2010 +0000

    qdio: extend API to allow polling
    
    Extend the qdio API to allow polling in the upper-layer driver. This
    is needed by qeth to use NAPI.
    
    To use the new interface the upper-layer driver must specify the
    queue_start_poll(). This callback is used to signal the upper-layer
    driver that is has initiative and must process the inbound queue by
    calling qdio_get_next_buffers(). If the upper-layer driver wants to
    stop polling it calls qdio_start_irq().
    
    Since adapter interrupts are not completely stoppable qdio implements
    a software bit QDIO_QUEUE_IRQS_DISABLED to safely disable interrupts for an
    input queue.
    
    The old interface is preserved and will be used as is by zfcp.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Frank Blaschka <frank.blaschka@de.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 00520f9a7a8e..5fcfa7f9e9ef 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -884,8 +884,19 @@ static void qdio_int_handler_pci(struct qdio_irq *irq_ptr)
 	if (unlikely(irq_ptr->state == QDIO_IRQ_STATE_STOPPED))
 		return;
 
-	for_each_input_queue(irq_ptr, q, i)
-		tasklet_schedule(&q->tasklet);
+	for_each_input_queue(irq_ptr, q, i) {
+		if (q->u.in.queue_start_poll) {
+			/* skip if polling is enabled or already in work */
+			if (test_and_set_bit(QDIO_QUEUE_IRQS_DISABLED,
+				     &q->u.in.queue_irq_state)) {
+				qperf_inc(q, int_discarded);
+				continue;
+			}
+			q->u.in.queue_start_poll(q->irq_ptr->cdev, q->nr,
+						 q->irq_ptr->int_parm);
+		} else
+			tasklet_schedule(&q->tasklet);
+	}
 
 	if (!(irq_ptr->qib.ac & QIB_AC_OUTBOUND_PCI_SUPPORTED))
 		return;
@@ -1519,6 +1530,129 @@ int do_QDIO(struct ccw_device *cdev, unsigned int callflags,
 }
 EXPORT_SYMBOL_GPL(do_QDIO);
 
+/**
+ * qdio_start_irq - process input buffers
+ * @cdev: associated ccw_device for the qdio subchannel
+ * @nr: input queue number
+ *
+ * Return codes
+ *   0 - success
+ *   1 - irqs not started since new data is available
+ */
+int qdio_start_irq(struct ccw_device *cdev, int nr)
+{
+	struct qdio_q *q;
+	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
+
+	if (!irq_ptr)
+		return -ENODEV;
+	q = irq_ptr->input_qs[nr];
+
+	WARN_ON(queue_irqs_enabled(q));
+
+	if (!shared_ind(q->irq_ptr))
+		xchg(q->irq_ptr->dsci, 0);
+
+	qdio_stop_polling(q);
+	clear_bit(QDIO_QUEUE_IRQS_DISABLED, &q->u.in.queue_irq_state);
+
+	/*
+	 * We need to check again to not lose initiative after
+	 * resetting the ACK state.
+	 */
+	if (!shared_ind(q->irq_ptr) && *q->irq_ptr->dsci)
+		goto rescan;
+	if (!qdio_inbound_q_done(q))
+		goto rescan;
+	return 0;
+
+rescan:
+	if (test_and_set_bit(QDIO_QUEUE_IRQS_DISABLED,
+			     &q->u.in.queue_irq_state))
+		return 0;
+	else
+		return 1;
+
+}
+EXPORT_SYMBOL(qdio_start_irq);
+
+/**
+ * qdio_get_next_buffers - process input buffers
+ * @cdev: associated ccw_device for the qdio subchannel
+ * @nr: input queue number
+ * @bufnr: first filled buffer number
+ * @error: buffers are in error state
+ *
+ * Return codes
+ *   < 0 - error
+ *   = 0 - no new buffers found
+ *   > 0 - number of processed buffers
+ */
+int qdio_get_next_buffers(struct ccw_device *cdev, int nr, int *bufnr,
+			  int *error)
+{
+	struct qdio_q *q;
+	int start, end;
+	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
+
+	if (!irq_ptr)
+		return -ENODEV;
+	q = irq_ptr->input_qs[nr];
+	WARN_ON(queue_irqs_enabled(q));
+
+	qdio_sync_after_thinint(q);
+
+	/*
+	 * The interrupt could be caused by a PCI request. Check the
+	 * PCI capable outbound queues.
+	 */
+	qdio_check_outbound_after_thinint(q);
+
+	if (!qdio_inbound_q_moved(q))
+		return 0;
+
+	/* Note: upper-layer MUST stop processing immediately here ... */
+	if (unlikely(q->irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))
+		return -EIO;
+
+	start = q->first_to_kick;
+	end = q->first_to_check;
+	*bufnr = start;
+	*error = q->qdio_error;
+
+	/* for the next time */
+	q->first_to_kick = end;
+	q->qdio_error = 0;
+	return sub_buf(end, start);
+}
+EXPORT_SYMBOL(qdio_get_next_buffers);
+
+/**
+ * qdio_stop_irq - disable interrupt processing for the device
+ * @cdev: associated ccw_device for the qdio subchannel
+ * @nr: input queue number
+ *
+ * Return codes
+ *   0 - interrupts were already disabled
+ *   1 - interrupts successfully disabled
+ */
+int qdio_stop_irq(struct ccw_device *cdev, int nr)
+{
+	struct qdio_q *q;
+	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
+
+	if (!irq_ptr)
+		return -ENODEV;
+	q = irq_ptr->input_qs[nr];
+
+	if (test_and_set_bit(QDIO_QUEUE_IRQS_DISABLED,
+			     &q->u.in.queue_irq_state))
+		return 0;
+	else
+		return 1;
+}
+EXPORT_SYMBOL(qdio_stop_irq);
+
 static int __init init_QDIO(void)
 {
 	int rc;

commit cc961d400e06e78c7aa39aeab1f001eb8f76ef90
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Mon May 17 10:00:19 2010 +0200

    [S390] qdio: remove API wrappers
    
    Remove qdio API wrappers used by qeth and replace them by calling the
    appropriate functions directly.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index dafb3e5bdad7..00520f9a7a8e 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1023,30 +1023,6 @@ int qdio_get_ssqd_desc(struct ccw_device *cdev,
 }
 EXPORT_SYMBOL_GPL(qdio_get_ssqd_desc);
 
-/**
- * qdio_cleanup - shutdown queues and free data structures
- * @cdev: associated ccw device
- * @how: use halt or clear to shutdown
- *
- * This function calls qdio_shutdown() for @cdev with method @how.
- * and qdio_free(). The qdio_free() return value is ignored since
- * !irq_ptr is already checked.
- */
-int qdio_cleanup(struct ccw_device *cdev, int how)
-{
-	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
-	int rc;
-
-	if (!irq_ptr)
-		return -ENODEV;
-
-	rc = qdio_shutdown(cdev, how);
-
-	qdio_free(cdev);
-	return rc;
-}
-EXPORT_SYMBOL_GPL(qdio_cleanup);
-
 static void qdio_shutdown_queues(struct ccw_device *cdev)
 {
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
@@ -1163,28 +1139,6 @@ int qdio_free(struct ccw_device *cdev)
 }
 EXPORT_SYMBOL_GPL(qdio_free);
 
-/**
- * qdio_initialize - allocate and establish queues for a qdio subchannel
- * @init_data: initialization data
- *
- * This function first allocates queues via qdio_allocate() and on success
- * establishes them via qdio_establish().
- */
-int qdio_initialize(struct qdio_initialize *init_data)
-{
-	int rc;
-
-	rc = qdio_allocate(init_data);
-	if (rc)
-		return rc;
-
-	rc = qdio_establish(init_data);
-	if (rc)
-		qdio_free(init_data->cdev);
-	return rc;
-}
-EXPORT_SYMBOL_GPL(qdio_initialize);
-
 /**
  * qdio_allocate - allocate qdio queues and associated data
  * @init_data: initialization data

commit 3a601bfef33c82537511c7d970d8010c38aaecd1
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Mon May 17 10:00:17 2010 +0200

    [S390] qdio: dont convert timestamps to microseconds
    
    Don't convert timestamps to microseconds, use timestamps returned by
    get_clock() directly.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index f4fd6cd4dc08..dafb3e5bdad7 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -336,10 +336,10 @@ static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit)
 		WARN_ON(queue_type(q) != QDIO_IQDIO_QFMT || cc != 2);
 
 		if (!start_time) {
-			start_time = get_usecs();
+			start_time = get_clock();
 			goto again;
 		}
-		if ((get_usecs() - start_time) < QDIO_BUSY_BIT_PATIENCE)
+		if ((get_clock() - start_time) < QDIO_BUSY_BIT_PATIENCE)
 			goto again;
 	}
 	return cc;
@@ -536,7 +536,7 @@ static int qdio_inbound_q_moved(struct qdio_q *q)
 	if ((bufnr != q->last_move) || q->qdio_error) {
 		q->last_move = bufnr;
 		if (!is_thinint_irq(q->irq_ptr) && MACHINE_IS_LPAR)
-			q->u.in.timestamp = get_usecs();
+			q->u.in.timestamp = get_clock();
 		return 1;
 	} else
 		return 0;
@@ -567,7 +567,7 @@ static inline int qdio_inbound_q_done(struct qdio_q *q)
 	 * At this point we know, that inbound first_to_check
 	 * has (probably) not moved (see qdio_inbound_processing).
 	 */
-	if (get_usecs() > q->u.in.timestamp + QDIO_INPUT_THRESHOLD) {
+	if (get_clock() > q->u.in.timestamp + QDIO_INPUT_THRESHOLD) {
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in done:%02x",
 			      q->first_to_check);
 		return 1;

commit f3eb20fafdc10aea0fb13b113ac3b9a3dc9a5dc6
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Mon May 17 10:00:15 2010 +0200

    [S390] qdio: prevent starvation on PCI devices
    
    If adapter interrupts are not available and traditional IO interrupts
    are used for qdio the inbound tasklet continued to run if new data
    arrived. That could possibly block other tasklets scheduled on the
    same CPU. If new data arrives schedule the tasklet again instead of
    directly processing the new data.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 1fc81268330e..f4fd6cd4dc08 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -606,7 +606,7 @@ static void qdio_kick_handler(struct qdio_q *q)
 static void __qdio_inbound_processing(struct qdio_q *q)
 {
 	qperf_inc(q, tasklet_inbound);
-again:
+
 	if (!qdio_inbound_q_moved(q))
 		return;
 
@@ -615,7 +615,10 @@ static void __qdio_inbound_processing(struct qdio_q *q)
 	if (!qdio_inbound_q_done(q)) {
 		/* means poll time is not yet over */
 		qperf_inc(q, tasklet_inbound_resched);
-		goto again;
+		if (likely(q->irq_ptr->state != QDIO_IRQ_STATE_STOPPED)) {
+			tasklet_schedule(&q->tasklet);
+			return;
+		}
 	}
 
 	qdio_stop_polling(q);
@@ -625,7 +628,8 @@ static void __qdio_inbound_processing(struct qdio_q *q)
 	 */
 	if (!qdio_inbound_q_done(q)) {
 		qperf_inc(q, tasklet_inbound_resched2);
-		goto again;
+		if (likely(q->irq_ptr->state != QDIO_IRQ_STATE_STOPPED))
+			tasklet_schedule(&q->tasklet);
 	}
 }
 

commit 09a308f384c4ad2fb45959f5da9918e812207c50
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Mon May 17 10:00:14 2010 +0200

    [S390] qdio: count number of qdio interrupts
    
    Add missing increment for the qdio interrupt counter.
    
    Signed-off-by: Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 88be7b9ea6e1..1fc81268330e 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -955,6 +955,9 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 		return;
 	}
 
+	if (irq_ptr->perf_stat_enabled)
+		irq_ptr->perf_stat.qdio_int++;
+
 	if (IS_ERR(irb)) {
 		switch (PTR_ERR(irb)) {
 		case -EIO:

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 4f8f74311778..88be7b9ea6e1 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -13,6 +13,7 @@
 #include <linux/kernel.h>
 #include <linux/timer.h>
 #include <linux/delay.h>
+#include <linux/gfp.h>
 #include <asm/atomic.h>
 #include <asm/debug.h>
 #include <asm/qdio.h>

commit bd6e8a162ecdec4f1d8895b0f330f75425993567
Author: Ursula Braun <ursula.braun@de.ibm.com>
Date:   Mon Mar 8 12:25:18 2010 +0100

    [S390] qdio: add missing bracket
    
    Add a missing bracket to only log the outbound handler event in the
    appropriate case.
    
    Signed-off-by: Ursula Braun <ursula.braun@de.ibm.com>
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 232ef047ba34..4f8f74311778 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -588,10 +588,11 @@ static void qdio_kick_handler(struct qdio_q *q)
 	if (q->is_input_q) {
 		qperf_inc(q, inbound_handler);
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "kih s:%02x c:%02x", start, count);
-	} else
+	} else {
 		qperf_inc(q, outbound_handler);
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "koh: s:%02x c:%02x",
 			      start, count);
+	}
 
 	q->handler(q->irq_ptr->cdev, q->qdio_error, q->nr, start, count,
 		   q->irq_ptr->int_parm);

commit 27d71602b4a605fbb31088e69ac12187e69a9443
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Fri Feb 26 22:37:38 2010 +0100

    [S390] add MACHINE_IS_LPAR flag
    
    Introduce the MACHINE_IS_LPAR flag for code that should only be
    executed if Linux is running in an LPAR.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 35dfc3cb2aae..232ef047ba34 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -534,7 +534,7 @@ static int qdio_inbound_q_moved(struct qdio_q *q)
 
 	if ((bufnr != q->last_move) || q->qdio_error) {
 		q->last_move = bufnr;
-		if (!is_thinint_irq(q->irq_ptr) && !MACHINE_IS_VM)
+		if (!is_thinint_irq(q->irq_ptr) && MACHINE_IS_LPAR)
 			q->u.in.timestamp = get_usecs();
 		return 1;
 	} else

commit d307297f73077b4dc8110eb998108ffc467e8e6c
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Fri Feb 26 22:37:36 2010 +0100

    [S390] qdio: account processed SBAL during queue scan
    
    Add counters for the number of processed SBALs. The numbers summarize
    how many SBALs were processed at each queue scan and indicate the
    utilization of the queue. Furthermore the number of unsuccessfull
    queue scans, SBAL errors and the total number of processed
    SBALs are accounted.
    
    Also regroup struct qdio_q to move read-mostly and write-mostly data
    into different cachelines.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 62b654af9237..35dfc3cb2aae 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -392,6 +392,20 @@ static inline void qdio_stop_polling(struct qdio_q *q)
 		set_buf_state(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT);
 }
 
+static inline void account_sbals(struct qdio_q *q, int count)
+{
+	int pos = 0;
+
+	q->q_stats.nr_sbal_total += count;
+	if (count == QDIO_MAX_BUFFERS_MASK) {
+		q->q_stats.nr_sbals[7]++;
+		return;
+	}
+	while (count >>= 1)
+		pos++;
+	q->q_stats.nr_sbals[pos]++;
+}
+
 static void announce_buffer_error(struct qdio_q *q, int count)
 {
 	q->qdio_error |= QDIO_ERROR_SLSB_STATE;
@@ -487,16 +501,22 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 		q->first_to_check = add_buf(q->first_to_check, count);
 		if (atomic_sub(count, &q->nr_buf_used) == 0)
 			qperf_inc(q, inbound_queue_full);
+		if (q->irq_ptr->perf_stat_enabled)
+			account_sbals(q, count);
 		break;
 	case SLSB_P_INPUT_ERROR:
 		announce_buffer_error(q, count);
 		/* process the buffer, the upper layer will take care of it */
 		q->first_to_check = add_buf(q->first_to_check, count);
 		atomic_sub(count, &q->nr_buf_used);
+		if (q->irq_ptr->perf_stat_enabled)
+			account_sbals_error(q, count);
 		break;
 	case SLSB_CU_INPUT_EMPTY:
 	case SLSB_P_INPUT_NOT_INIT:
 	case SLSB_P_INPUT_ACK:
+		if (q->irq_ptr->perf_stat_enabled)
+			q->q_stats.nr_sbal_nop++;
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in nop");
 		break;
 	default:
@@ -643,15 +663,21 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 
 		atomic_sub(count, &q->nr_buf_used);
 		q->first_to_check = add_buf(q->first_to_check, count);
+		if (q->irq_ptr->perf_stat_enabled)
+			account_sbals(q, count);
 		break;
 	case SLSB_P_OUTPUT_ERROR:
 		announce_buffer_error(q, count);
 		/* process the buffer, the upper layer will take care of it */
 		q->first_to_check = add_buf(q->first_to_check, count);
 		atomic_sub(count, &q->nr_buf_used);
+		if (q->irq_ptr->perf_stat_enabled)
+			account_sbals_error(q, count);
 		break;
 	case SLSB_CU_OUTPUT_PRIMED:
 		/* the adapter has not fetched the output yet */
+		if (q->irq_ptr->perf_stat_enabled)
+			q->q_stats.nr_sbal_nop++;
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out primed:%1d", q->nr);
 		break;
 	case SLSB_P_OUTPUT_NOT_INIT:

commit 959153d34544b7237bad263e73a5abdf94fc7722
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Tue Feb 9 09:46:08 2010 +0100

    [S390] qdio: prevent call trace if CHPID is offline
    
    If a CHPID is offline during a device shutdown the ccw_device_halt|clear
    may fail and the qdio device stays in state STOPPED until the shutdown is
    finished. If an interrupt occurs before the device is set to INACTIVE
    the STOPPED state triggers a WARN_ON in the interrupt handler.
    Prevent this WARN_ON by catching the STOPPED state in the interrupt
    handler.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 5781c5d10cff..62b654af9237 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -960,6 +960,8 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 			qdio_handle_activate_check(cdev, intparm, cstat,
 						   dstat);
 		break;
+	case QDIO_IRQ_STATE_STOPPED:
+		break;
 	default:
 		WARN_ON(1);
 	}

commit 4c52228d1b83ef67d4fa381c2ade70122c9e3c34
Author: Ursula Braun <ursula.braun@de.ibm.com>
Date:   Tue Feb 9 09:46:07 2010 +0100

    [S390] qdio: continue polling for buffer state ERROR
    
    Inbound traffic handling may hang if next buffer to check is in
    state ERROR, polling is stopped and the final check for further
    available inbound buffers disregards buffers in state ERROR.
    This patch includes state ERROR when checking availability of
    more inbound buffers.
    
    Cc: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Ursula Braun <ursula.braun@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 999fe80c4051..5781c5d10cff 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -531,7 +531,7 @@ static inline int qdio_inbound_q_done(struct qdio_q *q)
 	qdio_siga_sync_q(q);
 	get_buf_state(q, q->first_to_check, &state, 0);
 
-	if (state == SLSB_P_INPUT_PRIMED)
+	if (state == SLSB_P_INPUT_PRIMED || state == SLSB_P_INPUT_ERROR)
 		/* more work coming */
 		return 0;
 

commit 6486cda6c6b15368e2c925d89b4e9ed13e67b91b
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Mon Jan 4 09:05:42 2010 +0100

    [S390] qdio: convert global statistics to per-device stats
    
    Revamp the qdio performance statistics and move them from procfs to
    debugfs using the seq_file interface. Since the statistics are not
    intended for the general user the removal of /proc/qdio_perf should
    not surprise anyone.
    
    The per device statistics are disabled by default, writing 1 to
    /<debugfs mountpoint>/qdio/<device bus ID>/statistics enables the
    statistics for the given device.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index b2275c5000e7..999fe80c4051 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -22,7 +22,6 @@
 #include "device.h"
 #include "qdio.h"
 #include "qdio_debug.h"
-#include "qdio_perf.h"
 
 MODULE_AUTHOR("Utz Bacher <utz.bacher@de.ibm.com>,"\
 	"Jan Glauber <jang@linux.vnet.ibm.com>");
@@ -126,7 +125,7 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 	int rc;
 
 	BUG_ON(!q->irq_ptr->sch_token);
-	qdio_perf_stat_inc(&perf_stats.debug_eqbs_all);
+	qperf_inc(q, eqbs);
 
 	if (!q->is_input_q)
 		nr += q->irq_ptr->nr_input_qs;
@@ -139,7 +138,7 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 	 * buffers later.
 	 */
 	if ((ccq == 96) && (count != tmp_count)) {
-		qdio_perf_stat_inc(&perf_stats.debug_eqbs_incomplete);
+		qperf_inc(q, eqbs_partial);
 		return (count - tmp_count);
 	}
 
@@ -182,7 +181,7 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 		return 0;
 
 	BUG_ON(!q->irq_ptr->sch_token);
-	qdio_perf_stat_inc(&perf_stats.debug_sqbs_all);
+	qperf_inc(q, sqbs);
 
 	if (!q->is_input_q)
 		nr += q->irq_ptr->nr_input_qs;
@@ -191,7 +190,7 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 	rc = qdio_check_ccq(q, ccq);
 	if (rc == 1) {
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "SQBS again:%2d", ccq);
-		qdio_perf_stat_inc(&perf_stats.debug_sqbs_incomplete);
+		qperf_inc(q, sqbs_partial);
 		goto again;
 	}
 	if (rc < 0) {
@@ -285,7 +284,7 @@ static inline int qdio_siga_sync(struct qdio_q *q, unsigned int output,
 		return 0;
 
 	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-s:%1d", q->nr);
-	qdio_perf_stat_inc(&perf_stats.siga_sync);
+	qperf_inc(q, siga_sync);
 
 	cc = do_siga_sync(q->irq_ptr->schid, output, input);
 	if (cc)
@@ -350,7 +349,7 @@ static inline int qdio_siga_input(struct qdio_q *q)
 	int cc;
 
 	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-r:%1d", q->nr);
-	qdio_perf_stat_inc(&perf_stats.siga_in);
+	qperf_inc(q, siga_read);
 
 	cc = do_siga_input(q->irq_ptr->schid, q->mask);
 	if (cc)
@@ -382,7 +381,7 @@ static inline void qdio_stop_polling(struct qdio_q *q)
 		return;
 
 	q->u.in.polling = 0;
-	qdio_perf_stat_inc(&perf_stats.debug_stop_polling);
+	qperf_inc(q, stop_polling);
 
 	/* show the card that we are not polling anymore */
 	if (is_qebsm(q)) {
@@ -400,7 +399,7 @@ static void announce_buffer_error(struct qdio_q *q, int count)
 	/* special handling for no target buffer empty */
 	if ((!q->is_input_q &&
 	    (q->sbal[q->first_to_check]->element[15].flags & 0xff) == 0x10)) {
-		qdio_perf_stat_inc(&perf_stats.outbound_target_full);
+		qperf_inc(q, target_full);
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "OUTFULL FTC:%02x",
 			      q->first_to_check);
 		return;
@@ -487,7 +486,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 		inbound_primed(q, count);
 		q->first_to_check = add_buf(q->first_to_check, count);
 		if (atomic_sub(count, &q->nr_buf_used) == 0)
-			qdio_perf_stat_inc(&perf_stats.inbound_queue_full);
+			qperf_inc(q, inbound_queue_full);
 		break;
 	case SLSB_P_INPUT_ERROR:
 		announce_buffer_error(q, count);
@@ -567,9 +566,10 @@ static void qdio_kick_handler(struct qdio_q *q)
 	count = sub_buf(end, start);
 
 	if (q->is_input_q) {
-		qdio_perf_stat_inc(&perf_stats.inbound_handler);
+		qperf_inc(q, inbound_handler);
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "kih s:%02x c:%02x", start, count);
 	} else
+		qperf_inc(q, outbound_handler);
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "koh: s:%02x c:%02x",
 			      start, count);
 
@@ -583,24 +583,28 @@ static void qdio_kick_handler(struct qdio_q *q)
 
 static void __qdio_inbound_processing(struct qdio_q *q)
 {
-	qdio_perf_stat_inc(&perf_stats.tasklet_inbound);
+	qperf_inc(q, tasklet_inbound);
 again:
 	if (!qdio_inbound_q_moved(q))
 		return;
 
 	qdio_kick_handler(q);
 
-	if (!qdio_inbound_q_done(q))
+	if (!qdio_inbound_q_done(q)) {
 		/* means poll time is not yet over */
+		qperf_inc(q, tasklet_inbound_resched);
 		goto again;
+	}
 
 	qdio_stop_polling(q);
 	/*
 	 * We need to check again to not lose initiative after
 	 * resetting the ACK state.
 	 */
-	if (!qdio_inbound_q_done(q))
+	if (!qdio_inbound_q_done(q)) {
+		qperf_inc(q, tasklet_inbound_resched2);
 		goto again;
+	}
 }
 
 void qdio_inbound_processing(unsigned long data)
@@ -688,7 +692,7 @@ static int qdio_kick_outbound_q(struct qdio_q *q)
 		return 0;
 
 	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-w:%1d", q->nr);
-	qdio_perf_stat_inc(&perf_stats.siga_out);
+	qperf_inc(q, siga_write);
 
 	cc = qdio_siga_output(q, &busy_bit);
 	switch (cc) {
@@ -711,7 +715,7 @@ static int qdio_kick_outbound_q(struct qdio_q *q)
 
 static void __qdio_outbound_processing(struct qdio_q *q)
 {
-	qdio_perf_stat_inc(&perf_stats.tasklet_outbound);
+	qperf_inc(q, tasklet_outbound);
 	BUG_ON(atomic_read(&q->nr_buf_used) < 0);
 
 	if (qdio_outbound_q_moved(q))
@@ -739,12 +743,9 @@ static void __qdio_outbound_processing(struct qdio_q *q)
 	 */
 	if (qdio_outbound_q_done(q))
 		del_timer(&q->u.out.timer);
-	else {
-		if (!timer_pending(&q->u.out.timer)) {
+	else
+		if (!timer_pending(&q->u.out.timer))
 			mod_timer(&q->u.out.timer, jiffies + 10 * HZ);
-			qdio_perf_stat_inc(&perf_stats.debug_tl_out_timer);
-		}
-	}
 	return;
 
 sched:
@@ -784,7 +785,7 @@ static inline void qdio_check_outbound_after_thinint(struct qdio_q *q)
 
 static void __tiqdio_inbound_processing(struct qdio_q *q)
 {
-	qdio_perf_stat_inc(&perf_stats.thinint_inbound);
+	qperf_inc(q, tasklet_inbound);
 	qdio_sync_after_thinint(q);
 
 	/*
@@ -799,7 +800,7 @@ static void __tiqdio_inbound_processing(struct qdio_q *q)
 	qdio_kick_handler(q);
 
 	if (!qdio_inbound_q_done(q)) {
-		qdio_perf_stat_inc(&perf_stats.thinint_inbound_loop);
+		qperf_inc(q, tasklet_inbound_resched);
 		if (likely(q->irq_ptr->state != QDIO_IRQ_STATE_STOPPED)) {
 			tasklet_schedule(&q->tasklet);
 			return;
@@ -812,7 +813,7 @@ static void __tiqdio_inbound_processing(struct qdio_q *q)
 	 * resetting the ACK state.
 	 */
 	if (!qdio_inbound_q_done(q)) {
-		qdio_perf_stat_inc(&perf_stats.thinint_inbound_loop2);
+		qperf_inc(q, tasklet_inbound_resched2);
 		if (likely(q->irq_ptr->state != QDIO_IRQ_STATE_STOPPED))
 			tasklet_schedule(&q->tasklet);
 	}
@@ -851,8 +852,6 @@ static void qdio_int_handler_pci(struct qdio_irq *irq_ptr)
 	if (unlikely(irq_ptr->state == QDIO_IRQ_STATE_STOPPED))
 		return;
 
-	qdio_perf_stat_inc(&perf_stats.pci_int);
-
 	for_each_input_queue(irq_ptr, q, i)
 		tasklet_schedule(&q->tasklet);
 
@@ -923,8 +922,6 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 	int cstat, dstat;
 
-	qdio_perf_stat_inc(&perf_stats.qdio_int);
-
 	if (!intparm || !irq_ptr) {
 		DBF_ERROR("qint:%4x", cdev->private->schid.sch_no);
 		return;
@@ -1383,6 +1380,8 @@ static int handle_inbound(struct qdio_q *q, unsigned int callflags,
 {
 	int used, diff;
 
+	qperf_inc(q, inbound_call);
+
 	if (!q->u.in.polling)
 		goto set;
 
@@ -1438,14 +1437,16 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 	unsigned char state;
 	int used, rc = 0;
 
-	qdio_perf_stat_inc(&perf_stats.outbound_handler);
+	qperf_inc(q, outbound_call);
 
 	count = set_buf_states(q, bufnr, SLSB_CU_OUTPUT_PRIMED, count);
 	used = atomic_add_return(count, &q->nr_buf_used);
 	BUG_ON(used > QDIO_MAX_BUFFERS_PER_Q);
 
-	if (callflags & QDIO_FLAG_PCI_OUT)
+	if (callflags & QDIO_FLAG_PCI_OUT) {
 		q->u.out.pci_out_enabled = 1;
+		qperf_inc(q, pci_request_int);
+	}
 	else
 		q->u.out.pci_out_enabled = 0;
 
@@ -1484,7 +1485,7 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 	if (state != SLSB_CU_OUTPUT_PRIMED)
 		rc = qdio_kick_outbound_q(q);
 	else
-		qdio_perf_stat_inc(&perf_stats.fast_requeue);
+		qperf_inc(q, fast_requeue);
 
 out:
 	tasklet_schedule(&q->tasklet);
@@ -1540,16 +1541,11 @@ static int __init init_QDIO(void)
 	rc = qdio_debug_init();
 	if (rc)
 		goto out_ti;
-	rc = qdio_setup_perf_stats();
-	if (rc)
-		goto out_debug;
 	rc = tiqdio_register_thinints();
 	if (rc)
-		goto out_perf;
+		goto out_debug;
 	return 0;
 
-out_perf:
-	qdio_remove_perf_stats();
 out_debug:
 	qdio_debug_exit();
 out_ti:
@@ -1563,7 +1559,6 @@ static void __exit exit_QDIO(void)
 {
 	tiqdio_unregister_thinints();
 	tiqdio_free_memory();
-	qdio_remove_perf_stats();
 	qdio_debug_exit();
 	qdio_setup_exit();
 }

commit 8bcd9b04fdbab9cee4948501f8862af2a288f1b5
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Fri Dec 18 17:43:26 2009 +0100

    [S390] qdio: add counter for input queue full condition
    
    Add a counter to the qdio performance statistics that indicates that no
    free buffers were left in the input queue. If the counter gets increased
    it means that the qdio adapter filled all available buffers and possibly
    had more buffers ready but could not transmit them.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 4be6e84b9599..b2275c5000e7 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -486,7 +486,8 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	case SLSB_P_INPUT_PRIMED:
 		inbound_primed(q, count);
 		q->first_to_check = add_buf(q->first_to_check, count);
-		atomic_sub(count, &q->nr_buf_used);
+		if (atomic_sub(count, &q->nr_buf_used) == 0)
+			qdio_perf_stat_inc(&perf_stats.inbound_queue_full);
 		break;
 	case SLSB_P_INPUT_ERROR:
 		announce_buffer_error(q, count);

commit 6541f7b68f229aacd2e453bc9e94335fc56419fe
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Tue Sep 22 22:58:40 2009 +0200

    [S390] qdio: change state of all primed input buffers
    
    If input buffers stay in primed state qdio may not receive further interrupts
    for the input queue depending on the firmware. That can cause a connection
    hang on OSA cards.
    
    Change the state of all primed input buffers that are not acknowledged to
    not initialized.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 21766c791ad6..4be6e84b9599 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -455,6 +455,8 @@ static inline void inbound_primed(struct qdio_q *q, int count)
 	count--;
 	if (!count)
 		return;
+	/* need to change ALL buffers to get more interrupts */
+	set_buf_states(q, q->first_to_check, SLSB_P_INPUT_NOT_INIT, count);
 }
 
 static int get_inbound_buffer_frontier(struct qdio_q *q)

commit 1d7e1500a6acfc89415aa2524e2c475c980ac42a
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Tue Sep 22 22:58:39 2009 +0200

    [S390] qdio: reduce per device debug messages
    
    Even if turned off the debug message overhead is measurable in the hot path.
    Reduce the number of debug message calls in do_QDIO and qdio_kick_handler.
    Also use hex numbers to save space in the debug entries.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 9aef402a5f1b..21766c791ad6 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -401,7 +401,7 @@ static void announce_buffer_error(struct qdio_q *q, int count)
 	if ((!q->is_input_q &&
 	    (q->sbal[q->first_to_check]->element[15].flags & 0xff) == 0x10)) {
 		qdio_perf_stat_inc(&perf_stats.outbound_target_full);
-		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "OUTFULL FTC:%3d",
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "OUTFULL FTC:%02x",
 			      q->first_to_check);
 		return;
 	}
@@ -418,7 +418,7 @@ static inline void inbound_primed(struct qdio_q *q, int count)
 {
 	int new;
 
-	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in prim: %3d", count);
+	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in prim: %02x", count);
 
 	/* for QEBSM the ACK was already set by EQBS */
 	if (is_qebsm(q)) {
@@ -545,7 +545,7 @@ static inline int qdio_inbound_q_done(struct qdio_q *q)
 	 * has (probably) not moved (see qdio_inbound_processing).
 	 */
 	if (get_usecs() > q->u.in.timestamp + QDIO_INPUT_THRESHOLD) {
-		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in done:%3d",
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in done:%02x",
 			      q->first_to_check);
 		return 1;
 	} else
@@ -565,11 +565,10 @@ static void qdio_kick_handler(struct qdio_q *q)
 
 	if (q->is_input_q) {
 		qdio_perf_stat_inc(&perf_stats.inbound_handler);
-		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "kih s:%3d c:%3d", start, count);
-	} else {
-		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "koh: nr:%1d", q->nr);
-		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "s:%3d c:%3d", start, count);
-	}
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "kih s:%02x c:%02x", start, count);
+	} else
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "koh: s:%02x c:%02x",
+			      start, count);
 
 	q->handler(q->irq_ptr->cdev, q->qdio_error, q->nr, start, count,
 		   q->irq_ptr->int_parm);
@@ -633,7 +632,7 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 	switch (state) {
 	case SLSB_P_OUTPUT_EMPTY:
 		/* the adapter got it */
-		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out empty:%1d %3d", q->nr, count);
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out empty:%1d %02x", q->nr, count);
 
 		atomic_sub(count, &q->nr_buf_used);
 		q->first_to_check = add_buf(q->first_to_check, count);
@@ -1481,10 +1480,9 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
 	get_buf_state(q, prev_buf(bufnr), &state, 0);
 	if (state != SLSB_CU_OUTPUT_PRIMED)
 		rc = qdio_kick_outbound_q(q);
-	else {
-		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "fast-req");
+	else
 		qdio_perf_stat_inc(&perf_stats.fast_requeue);
-	}
+
 out:
 	tasklet_schedule(&q->tasklet);
 	return rc;
@@ -1510,12 +1508,8 @@ int do_QDIO(struct ccw_device *cdev, unsigned int callflags,
 	if (!irq_ptr)
 		return -ENODEV;
 
-	if (callflags & QDIO_FLAG_SYNC_INPUT)
-		DBF_DEV_EVENT(DBF_INFO, irq_ptr, "doQDIO input");
-	else
-		DBF_DEV_EVENT(DBF_INFO, irq_ptr, "doQDIO output");
-	DBF_DEV_EVENT(DBF_INFO, irq_ptr, "q:%1d flag:%4x", q_nr, callflags);
-	DBF_DEV_EVENT(DBF_INFO, irq_ptr, "buf:%2d cnt:%3d", bufnr, count);
+	DBF_DEV_EVENT(DBF_INFO, irq_ptr,
+		      "do%02x b:%02x c:%02x", callflags, bufnr, count);
 
 	if (irq_ptr->state != QDIO_IRQ_STATE_ACTIVE)
 		return -EBUSY;

commit e2910bcf8ca762b306767a0894ab1987be014c9e
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Fri Sep 11 10:28:19 2009 +0200

    [S390] qdio: continue polling if the queue is not finished
    
    With commit c38f96080955854e54df9cb392bc674e1ae330e1 polling was
    stopped for the queue even if new data is available.
    
    Return immediately after scheduling the queue tasklet if the queue
    is not done.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 0038750ad945..9aef402a5f1b 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -798,8 +798,10 @@ static void __tiqdio_inbound_processing(struct qdio_q *q)
 
 	if (!qdio_inbound_q_done(q)) {
 		qdio_perf_stat_inc(&perf_stats.thinint_inbound_loop);
-		if (likely(q->irq_ptr->state != QDIO_IRQ_STATE_STOPPED))
+		if (likely(q->irq_ptr->state != QDIO_IRQ_STATE_STOPPED)) {
 			tasklet_schedule(&q->tasklet);
+			return;
+		}
 	}
 
 	qdio_stop_polling(q);

commit 6618241b47cd131503610d8df68dd6f4948e5c1a
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Mon Jun 22 12:08:15 2009 +0200

    [S390] qdio: Sanitize do_QDIO sanity checks
    
    Remove unneeded sanity checks from do_QDIO since this is the hot path.
    Change the type of bufnr and count to unsigned int so the check for the
    maximum value works.
    
    Reported-by: Roel Kluin <roel.kluin@gmail.com>
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 75b521963a4e..0038750ad945 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1497,18 +1497,13 @@ static int handle_outbound(struct qdio_q *q, unsigned int callflags,
  * @count: how many buffers to process
  */
 int do_QDIO(struct ccw_device *cdev, unsigned int callflags,
-	    int q_nr, int bufnr, int count)
+	    int q_nr, unsigned int bufnr, unsigned int count)
 {
 	struct qdio_irq *irq_ptr;
 
-	if ((bufnr > QDIO_MAX_BUFFERS_PER_Q) ||
-	    (count > QDIO_MAX_BUFFERS_PER_Q) ||
-	    (q_nr >= QDIO_MAX_QUEUES_PER_IRQ))
+	if (bufnr >= QDIO_MAX_BUFFERS_PER_Q || count > QDIO_MAX_BUFFERS_PER_Q)
 		return -EINVAL;
 
-	if (!count)
-		return 0;
-
 	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)
 		return -ENODEV;

commit f0a0b15e0f3aff0a25f21f58bef8e40e80b16dc6
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Mon Jun 22 12:08:14 2009 +0200

    [S390] qdio: leave inbound SBALs primed
    
    It is not required to change the state of primed SBALs. Leaving them
    primed saves a SQBS instruction under z/VM.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 779b7741d495..75b521963a4e 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -455,13 +455,6 @@ static inline void inbound_primed(struct qdio_q *q, int count)
 	count--;
 	if (!count)
 		return;
-
-	/*
-	 * Need to change all PRIMED buffers to NOT_INIT, otherwise
-	 * we're loosing initiative in the thinint code.
-	 */
-	set_buf_states(q, q->first_to_check, SLSB_P_INPUT_NOT_INIT,
-		       count);
 }
 
 static int get_inbound_buffer_frontier(struct qdio_q *q)

commit 36e3e72120e27939233e4bd88a8d74b3a2377428
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Mon Jun 22 12:08:12 2009 +0200

    [S390] qdio: extract all primed SBALs at once
    
    For devices without QIOASSIST primed SBALS were extracted in a loop.
    Remove the loop since get_buf_states can already return more than
    one primed SBAL.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 127e78eef651..779b7741d495 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -476,19 +476,13 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	count = min(atomic_read(&q->nr_buf_used), QDIO_MAX_BUFFERS_MASK);
 	stop = add_buf(q->first_to_check, count);
 
-	/*
-	 * No siga sync here, as a PCI or we after a thin interrupt
-	 * will sync the queues.
-	 */
-
-	/* need to set count to 1 for non-qebsm */
-	if (!is_qebsm(q))
-		count = 1;
-
-check_next:
 	if (q->first_to_check == stop)
 		goto out;
 
+	/*
+	 * No siga sync here, as a PCI or we after a thin interrupt
+	 * already sync'ed the queues.
+	 */
 	count = get_buf_states(q, q->first_to_check, &state, count, 1);
 	if (!count)
 		goto out;
@@ -496,14 +490,9 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	switch (state) {
 	case SLSB_P_INPUT_PRIMED:
 		inbound_primed(q, count);
-		/*
-		 * No siga-sync needed for non-qebsm here, as the inbound queue
-		 * will be synced on the next siga-r, resp.
-		 * qdio_inbound_q_done will do the siga-sync.
-		 */
 		q->first_to_check = add_buf(q->first_to_check, count);
 		atomic_sub(count, &q->nr_buf_used);
-		goto check_next;
+		break;
 	case SLSB_P_INPUT_ERROR:
 		announce_buffer_error(q, count);
 		/* process the buffer, the upper layer will take care of it */
@@ -641,11 +630,6 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 	count = min(atomic_read(&q->nr_buf_used), QDIO_MAX_BUFFERS_MASK);
 	stop = add_buf(q->first_to_check, count);
 
-	/* need to set count to 1 for non-qebsm */
-	if (!is_qebsm(q))
-		count = 1;
-
-check_next:
 	if (q->first_to_check == stop)
 		return q->first_to_check;
 
@@ -660,13 +644,7 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 
 		atomic_sub(count, &q->nr_buf_used);
 		q->first_to_check = add_buf(q->first_to_check, count);
-		/*
-		 * We fetch all buffer states at once. get_buf_states may
-		 * return count < stop. For QEBSM we do not loop.
-		 */
-		if (is_qebsm(q))
-			break;
-		goto check_next;
+		break;
 	case SLSB_P_OUTPUT_ERROR:
 		announce_buffer_error(q, count);
 		/* process the buffer, the upper layer will take care of it */

commit 9a2c160a8cbd5b3253672b3bac462c64d0d2eef7
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Mon Jun 22 12:08:11 2009 +0200

    [S390] qdio: fix check for running under z/VM
    
    The check whether qdio runs under z/VM was incorrect since SIGA-Sync is not
    set if the device runs with QIOASSIST. Use MACHINE_IS_VM instead to prevent
    polling under z/VM.
    
    Merge qdio_inbound_q_done and tiqdio_is_inbound_q_done.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 377d881385cf..127e78eef651 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -499,7 +499,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 		/*
 		 * No siga-sync needed for non-qebsm here, as the inbound queue
 		 * will be synced on the next siga-r, resp.
-		 * tiqdio_is_inbound_q_done will do the siga-sync.
+		 * qdio_inbound_q_done will do the siga-sync.
 		 */
 		q->first_to_check = add_buf(q->first_to_check, count);
 		atomic_sub(count, &q->nr_buf_used);
@@ -530,35 +530,32 @@ static int qdio_inbound_q_moved(struct qdio_q *q)
 
 	if ((bufnr != q->last_move) || q->qdio_error) {
 		q->last_move = bufnr;
-		if (!need_siga_sync(q) && !pci_out_supported(q))
+		if (!is_thinint_irq(q->irq_ptr) && !MACHINE_IS_VM)
 			q->u.in.timestamp = get_usecs();
-
-		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in moved");
 		return 1;
 	} else
 		return 0;
 }
 
-static int qdio_inbound_q_done(struct qdio_q *q)
+static inline int qdio_inbound_q_done(struct qdio_q *q)
 {
 	unsigned char state = 0;
 
 	if (!atomic_read(&q->nr_buf_used))
 		return 1;
 
-	/*
-	 * We need that one for synchronization with the adapter, as it
-	 * does a kind of PCI avoidance.
-	 */
 	qdio_siga_sync_q(q);
-
 	get_buf_state(q, q->first_to_check, &state, 0);
+
 	if (state == SLSB_P_INPUT_PRIMED)
-		/* we got something to do */
+		/* more work coming */
 		return 0;
 
-	/* on VM, we don't poll, so the q is always done here */
-	if (need_siga_sync(q) || pci_out_supported(q))
+	if (is_thinint_irq(q->irq_ptr))
+		return 1;
+
+	/* don't poll under z/VM */
+	if (MACHINE_IS_VM)
 		return 1;
 
 	/*
@@ -569,27 +566,8 @@ static int qdio_inbound_q_done(struct qdio_q *q)
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in done:%3d",
 			      q->first_to_check);
 		return 1;
-	} else {
-		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in notd:%3d",
-			      q->first_to_check);
-		return 0;
-	}
-}
-
-static inline int tiqdio_inbound_q_done(struct qdio_q *q)
-{
-	unsigned char state = 0;
-
-	if (!atomic_read(&q->nr_buf_used))
-		return 1;
-
-	qdio_siga_sync_q(q);
-	get_buf_state(q, q->first_to_check, &state, 0);
-
-	if (state == SLSB_P_INPUT_PRIMED)
-		/* more work coming */
+	} else
 		return 0;
-	return 1;
 }
 
 static void qdio_kick_handler(struct qdio_q *q)
@@ -847,7 +825,7 @@ static void __tiqdio_inbound_processing(struct qdio_q *q)
 
 	qdio_kick_handler(q);
 
-	if (!tiqdio_inbound_q_done(q)) {
+	if (!qdio_inbound_q_done(q)) {
 		qdio_perf_stat_inc(&perf_stats.thinint_inbound_loop);
 		if (likely(q->irq_ptr->state != QDIO_IRQ_STATE_STOPPED))
 			tasklet_schedule(&q->tasklet);
@@ -858,7 +836,7 @@ static void __tiqdio_inbound_processing(struct qdio_q *q)
 	 * We need to check again to not lose initiative after
 	 * resetting the ACK state.
 	 */
-	if (!tiqdio_inbound_q_done(q)) {
+	if (!qdio_inbound_q_done(q)) {
 		qdio_perf_stat_inc(&perf_stats.thinint_inbound_loop2);
 		if (likely(q->irq_ptr->state != QDIO_IRQ_STATE_STOPPED))
 			tasklet_schedule(&q->tasklet);

commit 60b5df2f12f2ab54bfa7c1f0f0ce3f5953e73c0b
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Mon Jun 22 12:08:10 2009 +0200

    [S390] qdio: move adapter interrupt tasklet code
    
    Move the adapter interrupt tasklet function to the qdio main code
    since all the functions used by the tasklet are located there.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index d79cf5bf0e62..377d881385cf 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -231,8 +231,8 @@ static inline int get_buf_states(struct qdio_q *q, unsigned int bufnr,
 	return i;
 }
 
-inline int get_buf_state(struct qdio_q *q, unsigned int bufnr,
-		  unsigned char *state, int auto_ack)
+static inline int get_buf_state(struct qdio_q *q, unsigned int bufnr,
+				unsigned char *state, int auto_ack)
 {
 	return get_buf_states(q, bufnr, state, 1, auto_ack);
 }
@@ -276,7 +276,7 @@ void qdio_init_buf_states(struct qdio_irq *irq_ptr)
 			       QDIO_MAX_BUFFERS_PER_Q);
 }
 
-static int qdio_siga_sync(struct qdio_q *q, unsigned int output,
+static inline int qdio_siga_sync(struct qdio_q *q, unsigned int output,
 			  unsigned int input)
 {
 	int cc;
@@ -293,7 +293,7 @@ static int qdio_siga_sync(struct qdio_q *q, unsigned int output,
 	return cc;
 }
 
-inline int qdio_siga_sync_q(struct qdio_q *q)
+static inline int qdio_siga_sync_q(struct qdio_q *q)
 {
 	if (q->is_input_q)
 		return qdio_siga_sync(q, 0, q->mask);
@@ -358,8 +358,7 @@ static inline int qdio_siga_input(struct qdio_q *q)
 	return cc;
 }
 
-/* called from thinint inbound handler */
-void qdio_sync_after_thinint(struct qdio_q *q)
+static inline void qdio_sync_after_thinint(struct qdio_q *q)
 {
 	if (pci_out_supported(q)) {
 		if (need_siga_sync_thinint(q))
@@ -370,7 +369,14 @@ void qdio_sync_after_thinint(struct qdio_q *q)
 		qdio_siga_sync_q(q);
 }
 
-inline void qdio_stop_polling(struct qdio_q *q)
+int debug_get_buf_state(struct qdio_q *q, unsigned int bufnr,
+			unsigned char *state)
+{
+	qdio_siga_sync_q(q);
+	return get_buf_states(q, bufnr, state, 1, 0);
+}
+
+static inline void qdio_stop_polling(struct qdio_q *q)
 {
 	if (!q->u.in.polling)
 		return;
@@ -516,7 +522,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	return q->first_to_check;
 }
 
-int qdio_inbound_q_moved(struct qdio_q *q)
+static int qdio_inbound_q_moved(struct qdio_q *q)
 {
 	int bufnr;
 
@@ -570,7 +576,23 @@ static int qdio_inbound_q_done(struct qdio_q *q)
 	}
 }
 
-void qdio_kick_handler(struct qdio_q *q)
+static inline int tiqdio_inbound_q_done(struct qdio_q *q)
+{
+	unsigned char state = 0;
+
+	if (!atomic_read(&q->nr_buf_used))
+		return 1;
+
+	qdio_siga_sync_q(q);
+	get_buf_state(q, q->first_to_check, &state, 0);
+
+	if (state == SLSB_P_INPUT_PRIMED)
+		/* more work coming */
+		return 0;
+	return 1;
+}
+
+static void qdio_kick_handler(struct qdio_q *q)
 {
 	int start = q->first_to_kick;
 	int end = q->first_to_check;
@@ -619,7 +641,6 @@ static void __qdio_inbound_processing(struct qdio_q *q)
 		goto again;
 }
 
-/* inbound tasklet */
 void qdio_inbound_processing(unsigned long data)
 {
 	struct qdio_q *q = (struct qdio_q *)data;
@@ -797,8 +818,7 @@ void qdio_outbound_timer(unsigned long data)
 	tasklet_schedule(&q->tasklet);
 }
 
-/* called from thinint inbound tasklet */
-void qdio_check_outbound_after_thinint(struct qdio_q *q)
+static inline void qdio_check_outbound_after_thinint(struct qdio_q *q)
 {
 	struct qdio_q *out;
 	int i;
@@ -811,6 +831,46 @@ void qdio_check_outbound_after_thinint(struct qdio_q *q)
 			tasklet_schedule(&out->tasklet);
 }
 
+static void __tiqdio_inbound_processing(struct qdio_q *q)
+{
+	qdio_perf_stat_inc(&perf_stats.thinint_inbound);
+	qdio_sync_after_thinint(q);
+
+	/*
+	 * The interrupt could be caused by a PCI request. Check the
+	 * PCI capable outbound queues.
+	 */
+	qdio_check_outbound_after_thinint(q);
+
+	if (!qdio_inbound_q_moved(q))
+		return;
+
+	qdio_kick_handler(q);
+
+	if (!tiqdio_inbound_q_done(q)) {
+		qdio_perf_stat_inc(&perf_stats.thinint_inbound_loop);
+		if (likely(q->irq_ptr->state != QDIO_IRQ_STATE_STOPPED))
+			tasklet_schedule(&q->tasklet);
+	}
+
+	qdio_stop_polling(q);
+	/*
+	 * We need to check again to not lose initiative after
+	 * resetting the ACK state.
+	 */
+	if (!tiqdio_inbound_q_done(q)) {
+		qdio_perf_stat_inc(&perf_stats.thinint_inbound_loop2);
+		if (likely(q->irq_ptr->state != QDIO_IRQ_STATE_STOPPED))
+			tasklet_schedule(&q->tasklet);
+	}
+}
+
+void tiqdio_inbound_processing(unsigned long data)
+{
+	struct qdio_q *q = (struct qdio_q *)data;
+	__tiqdio_inbound_processing(q);
+}
+
 static inline void qdio_set_state(struct qdio_irq *irq_ptr,
 				  enum qdio_irq_states state)
 {

commit 6b9d8e80bb9edd0c9fe948a6ef105391de56b012
Author: Roel Kluin <roel.kluin@gmail.com>
Date:   Fri Jun 12 10:26:34 2009 +0200

    [S390] qdio: fix access beyond ARRAY_SIZE of irq_ptr->{in,out}put_qs
    
    Do not go beyond ARRAY_SIZE of irq_ptr->{in,out}put_qs
    
    Signed-off-by: Roel Kluin <roel.kluin@gmail.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index ba4facc37011..d79cf5bf0e62 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1494,7 +1494,7 @@ int do_QDIO(struct ccw_device *cdev, unsigned int callflags,
 
 	if ((bufnr > QDIO_MAX_BUFFERS_PER_Q) ||
 	    (count > QDIO_MAX_BUFFERS_PER_Q) ||
-	    (q_nr > QDIO_MAX_QUEUES_PER_IRQ))
+	    (q_nr >= QDIO_MAX_QUEUES_PER_IRQ))
 		return -EINVAL;
 
 	if (!count)

commit 4c57542320e73b9ff46b04092273dbcc184a4fb6
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Fri Jun 12 10:26:28 2009 +0200

    [S390] qdio: simplify error handling in irq handler
    
    The check for the device status in qdio_establish_handle_irq()
    had dead code. Remove the unused code and simplify the error
    handling.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index accd957454e7..ba4facc37011 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -881,42 +881,26 @@ static void qdio_handle_activate_check(struct ccw_device *cdev,
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_STOPPED);
 }
 
-static int qdio_establish_check_errors(struct ccw_device *cdev, int cstat,
-				       int dstat)
+static void qdio_establish_handle_irq(struct ccw_device *cdev, int cstat,
+				      int dstat)
 {
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 
-	if (cstat || (dstat & ~(DEV_STAT_CHN_END | DEV_STAT_DEV_END))) {
-		DBF_ERROR("EQ:ck con");
-		goto error;
-	}
+	DBF_DEV_EVENT(DBF_INFO, irq_ptr, "qest irq");
 
-	if (!(dstat & DEV_STAT_DEV_END)) {
-		DBF_ERROR("EQ:no dev");
+	if (cstat)
 		goto error;
-	}
-
-	if (dstat & ~(DEV_STAT_CHN_END | DEV_STAT_DEV_END)) {
-		DBF_ERROR("EQ: bad io");
+	if (dstat & ~(DEV_STAT_DEV_END | DEV_STAT_CHN_END))
 		goto error;
-	}
-	return 0;
+	if (!(dstat & DEV_STAT_DEV_END))
+		goto error;
+	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_ESTABLISHED);
+	return;
+
 error:
 	DBF_ERROR("%4x EQ:error", irq_ptr->schid.sch_no);
 	DBF_ERROR("ds: %2x cs:%2x", dstat, cstat);
-
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_ERR);
-	return 1;
-}
-
-static void qdio_establish_handle_irq(struct ccw_device *cdev, int cstat,
-				      int dstat)
-{
-	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
-
-	DBF_DEV_EVENT(DBF_INFO, irq_ptr, "qest irq");
-	if (!qdio_establish_check_errors(cdev, cstat, dstat))
-		qdio_set_state(irq_ptr, QDIO_IRQ_STATE_ESTABLISHED);
 }
 
 /* qdio interrupt handler */
@@ -946,7 +930,6 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 		}
 	}
 	qdio_irq_check_sense(irq_ptr, irb);
-
 	cstat = irb->scsw.cmd.cstat;
 	dstat = irb->scsw.cmd.dstat;
 
@@ -954,22 +937,19 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 	case QDIO_IRQ_STATE_INACTIVE:
 		qdio_establish_handle_irq(cdev, cstat, dstat);
 		break;
-
 	case QDIO_IRQ_STATE_CLEANUP:
 		qdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);
 		break;
-
 	case QDIO_IRQ_STATE_ESTABLISHED:
 	case QDIO_IRQ_STATE_ACTIVE:
 		if (cstat & SCHN_STAT_PCI) {
 			qdio_int_handler_pci(irq_ptr);
 			return;
 		}
-		if ((cstat & ~SCHN_STAT_PCI) || dstat) {
+		if (cstat || dstat)
 			qdio_handle_activate_check(cdev, intparm, cstat,
 						   dstat);
-			break;
-		}
+		break;
 	default:
 		WARN_ON(1);
 	}

commit 75cb71f3184f3dd5b78d991d5e0e047774865f5d
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Tue Apr 14 15:36:22 2009 +0200

    [S390] qdio: remove dead timeout handler
    
    The QDIO ccw devices are started by ccw_device_start so no timeout
    can occur for the interrupt handler. Remove the dead code.
    
    In case of an I/O error set the device state to error and wake up
    a possibly running qdio_shutdown waiter.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 9e8a2914259b..accd957454e7 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -881,42 +881,6 @@ static void qdio_handle_activate_check(struct ccw_device *cdev,
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_STOPPED);
 }
 
-static void qdio_call_shutdown(struct work_struct *work)
-{
-	struct ccw_device_private *priv;
-	struct ccw_device *cdev;
-
-	priv = container_of(work, struct ccw_device_private, kick_work);
-	cdev = priv->cdev;
-	qdio_shutdown(cdev, QDIO_FLAG_CLEANUP_USING_CLEAR);
-	put_device(&cdev->dev);
-}
-
-static void qdio_int_error(struct ccw_device *cdev)
-{
-	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
-
-	switch (irq_ptr->state) {
-	case QDIO_IRQ_STATE_INACTIVE:
-	case QDIO_IRQ_STATE_CLEANUP:
-		qdio_set_state(irq_ptr, QDIO_IRQ_STATE_ERR);
-		break;
-	case QDIO_IRQ_STATE_ESTABLISHED:
-	case QDIO_IRQ_STATE_ACTIVE:
-		qdio_set_state(irq_ptr, QDIO_IRQ_STATE_STOPPED);
-		if (get_device(&cdev->dev)) {
-			/* Can't call shutdown from interrupt context. */
-			PREPARE_WORK(&cdev->private->kick_work,
-				     qdio_call_shutdown);
-			queue_work(ccw_device_work, &cdev->private->kick_work);
-		}
-		break;
-	default:
-		WARN_ON(1);
-	}
-	wake_up(&cdev->private->wait_q);
-}
-
 static int qdio_establish_check_errors(struct ccw_device *cdev, int cstat,
 				       int dstat)
 {
@@ -973,10 +937,8 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 		switch (PTR_ERR(irb)) {
 		case -EIO:
 			DBF_ERROR("%4x IO error", irq_ptr->schid.sch_no);
-			return;
-		case -ETIMEDOUT:
-			DBF_ERROR("%4x IO timeout", irq_ptr->schid.sch_no);
-			qdio_int_error(cdev);
+			qdio_set_state(irq_ptr, QDIO_IRQ_STATE_ERR);
+			wake_up(&cdev->private->wait_q);
 			return;
 		default:
 			WARN_ON(1);
@@ -1001,7 +963,6 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 	case QDIO_IRQ_STATE_ACTIVE:
 		if (cstat & SCHN_STAT_PCI) {
 			qdio_int_handler_pci(irq_ptr);
-			/* no state change so no need to wake up wait_q */
 			return;
 		}
 		if ((cstat & ~SCHN_STAT_PCI) || dstat) {

commit 9c8a08d7a74b07ab2c47e259231d9d0f0047a3c1
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Mar 26 15:24:32 2009 +0100

    [S390] qdio: merge inbound and outbound handler functions
    
    The inbound and outbound handlers are nearly identical if the outbound
    handler uses first_to_check as end index instead of last_move. Since both
    values are identical at that point the handlers can be merged.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index e53ac67e1e48..9e8a2914259b 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -570,29 +570,30 @@ static int qdio_inbound_q_done(struct qdio_q *q)
 	}
 }
 
-void qdio_kick_inbound_handler(struct qdio_q *q)
+void qdio_kick_handler(struct qdio_q *q)
 {
-	int count, start, end;
-
-	qdio_perf_stat_inc(&perf_stats.inbound_handler);
-
-	start = q->first_to_kick;
-	end = q->first_to_check;
-	if (end >= start)
-		count = end - start;
-	else
-		count = end + QDIO_MAX_BUFFERS_PER_Q - start;
-
-	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "kih s:%3d c:%3d", start, count);
+	int start = q->first_to_kick;
+	int end = q->first_to_check;
+	int count;
 
 	if (unlikely(q->irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))
 		return;
 
-	q->handler(q->irq_ptr->cdev, q->qdio_error, q->nr,
-		   start, count, q->irq_ptr->int_parm);
+	count = sub_buf(end, start);
+
+	if (q->is_input_q) {
+		qdio_perf_stat_inc(&perf_stats.inbound_handler);
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "kih s:%3d c:%3d", start, count);
+	} else {
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "koh: nr:%1d", q->nr);
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "s:%3d c:%3d", start, count);
+	}
+
+	q->handler(q->irq_ptr->cdev, q->qdio_error, q->nr, start, count,
+		   q->irq_ptr->int_parm);
 
 	/* for the next time */
-	q->first_to_kick = q->first_to_check;
+	q->first_to_kick = end;
 	q->qdio_error = 0;
 }
 
@@ -603,7 +604,7 @@ static void __qdio_inbound_processing(struct qdio_q *q)
 	if (!qdio_inbound_q_moved(q))
 		return;
 
-	qdio_kick_inbound_handler(q);
+	qdio_kick_handler(q);
 
 	if (!qdio_inbound_q_done(q))
 		/* means poll time is not yet over */
@@ -736,38 +737,13 @@ static int qdio_kick_outbound_q(struct qdio_q *q)
 	return cc;
 }
 
-static void qdio_kick_outbound_handler(struct qdio_q *q)
-{
-	int start, end, count;
-
-	start = q->first_to_kick;
-	end = q->last_move;
-	if (end >= start)
-		count = end - start;
-	else
-		count = end + QDIO_MAX_BUFFERS_PER_Q - start;
-
-	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "kickouth: %1d", q->nr);
-	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "s:%3d c:%3d", start, count);
-
-	if (unlikely(q->irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))
-		return;
-
-	q->handler(q->irq_ptr->cdev, q->qdio_error, q->nr, start, count,
-		   q->irq_ptr->int_parm);
-
-	/* for the next time: */
-	q->first_to_kick = q->last_move;
-	q->qdio_error = 0;
-}
-
 static void __qdio_outbound_processing(struct qdio_q *q)
 {
 	qdio_perf_stat_inc(&perf_stats.tasklet_outbound);
 	BUG_ON(atomic_read(&q->nr_buf_used) < 0);
 
 	if (qdio_outbound_q_moved(q))
-		qdio_kick_outbound_handler(q);
+		qdio_kick_handler(q);
 
 	if (queue_type(q) == QDIO_ZFCP_QFMT)
 		if (!pci_out_supported(q) && !qdio_outbound_q_done(q))

commit d303b6fd858370c22d5c70c313669e3521a5f758
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Mar 26 15:24:31 2009 +0100

    [S390] qdio: report SIGA errors directly
    
    Errors from SIGA instructions are stored in the per queue qdio_error
    and reported back when the queue handler is called. That opens a race
    when multiple error conditions occur simultanously.
    
    Report SIGA errors immediately in the return value of do_QDIO so the
    upper layer can react and SIGA errors no longer interfere with other
    errors.
    
    Move the SIGA error handling in qeth from the outbound handler to
    qeth_flush_buffers.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 31b9318149ba..e53ac67e1e48 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -706,13 +706,13 @@ static inline int qdio_outbound_q_moved(struct qdio_q *q)
 		return 0;
 }
 
-static void qdio_kick_outbound_q(struct qdio_q *q)
+static int qdio_kick_outbound_q(struct qdio_q *q)
 {
 	unsigned int busy_bit;
 	int cc;
 
 	if (!need_siga_out(q))
-		return;
+		return 0;
 
 	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-w:%1d", q->nr);
 	qdio_perf_stat_inc(&perf_stats.siga_out);
@@ -724,19 +724,16 @@ static void qdio_kick_outbound_q(struct qdio_q *q)
 	case 2:
 		if (busy_bit) {
 			DBF_ERROR("%4x cc2 REP:%1d", SCH_NO(q), q->nr);
-			q->qdio_error = cc | QDIO_ERROR_SIGA_BUSY;
-		} else {
-			DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-w cc2:%1d",
-				      q->nr);
-			q->qdio_error = cc;
-		}
+			cc |= QDIO_ERROR_SIGA_BUSY;
+		} else
+			DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-w cc2:%1d", q->nr);
 		break;
 	case 1:
 	case 3:
 		DBF_ERROR("%4x SIGA-W:%1d", SCH_NO(q), cc);
-		q->qdio_error = cc;
 		break;
 	}
+	return cc;
 }
 
 static void qdio_kick_outbound_handler(struct qdio_q *q)
@@ -766,18 +763,12 @@ static void qdio_kick_outbound_handler(struct qdio_q *q)
 
 static void __qdio_outbound_processing(struct qdio_q *q)
 {
-	unsigned long flags;
-
 	qdio_perf_stat_inc(&perf_stats.tasklet_outbound);
-	spin_lock_irqsave(&q->lock, flags);
-
 	BUG_ON(atomic_read(&q->nr_buf_used) < 0);
 
 	if (qdio_outbound_q_moved(q))
 		qdio_kick_outbound_handler(q);
 
-	spin_unlock_irqrestore(&q->lock, flags);
-
 	if (queue_type(q) == QDIO_ZFCP_QFMT)
 		if (!pci_out_supported(q) && !qdio_outbound_q_done(q))
 			goto sched;
@@ -1457,10 +1448,10 @@ static inline int buf_in_between(int bufnr, int start, int count)
  * @bufnr: first buffer to process
  * @count: how many buffers are emptied
  */
-static void handle_inbound(struct qdio_q *q, unsigned int callflags,
-			   int bufnr, int count)
+static int handle_inbound(struct qdio_q *q, unsigned int callflags,
+			  int bufnr, int count)
 {
-	int used, cc, diff;
+	int used, diff;
 
 	if (!q->u.in.polling)
 		goto set;
@@ -1497,13 +1488,11 @@ static void handle_inbound(struct qdio_q *q, unsigned int callflags,
 
 	/* no need to signal as long as the adapter had free buffers */
 	if (used)
-		return;
+		return 0;
 
-	if (need_siga_in(q)) {
-		cc = qdio_siga_input(q);
-		if (cc)
-			q->qdio_error = cc;
-	}
+	if (need_siga_in(q))
+		return qdio_siga_input(q);
+	return 0;
 }
 
 /**
@@ -1513,11 +1502,11 @@ static void handle_inbound(struct qdio_q *q, unsigned int callflags,
  * @bufnr: first buffer to process
  * @count: how many buffers are filled
  */
-static void handle_outbound(struct qdio_q *q, unsigned int callflags,
-			    int bufnr, int count)
+static int handle_outbound(struct qdio_q *q, unsigned int callflags,
+			   int bufnr, int count)
 {
 	unsigned char state;
-	int used;
+	int used, rc = 0;
 
 	qdio_perf_stat_inc(&perf_stats.outbound_handler);
 
@@ -1532,27 +1521,26 @@ static void handle_outbound(struct qdio_q *q, unsigned int callflags,
 
 	if (queue_type(q) == QDIO_IQDIO_QFMT) {
 		if (multicast_outbound(q))
-			qdio_kick_outbound_q(q);
+			rc = qdio_kick_outbound_q(q);
 		else
 			if ((q->irq_ptr->ssqd_desc.mmwc > 1) &&
 			    (count > 1) &&
 			    (count <= q->irq_ptr->ssqd_desc.mmwc)) {
 				/* exploit enhanced SIGA */
 				q->u.out.use_enh_siga = 1;
-				qdio_kick_outbound_q(q);
+				rc = qdio_kick_outbound_q(q);
 			} else {
 				/*
 				* One siga-w per buffer required for unicast
 				* HiperSockets.
 				*/
 				q->u.out.use_enh_siga = 0;
-				while (count--)
-					qdio_kick_outbound_q(q);
+				while (count--) {
+					rc = qdio_kick_outbound_q(q);
+					if (rc)
+						goto out;
+				}
 			}
-
-		/* report CC=2 conditions synchronously */
-		if (q->qdio_error)
-			__qdio_outbound_processing(q);
 		goto out;
 	}
 
@@ -1564,13 +1552,14 @@ static void handle_outbound(struct qdio_q *q, unsigned int callflags,
 	/* try to fast requeue buffers */
 	get_buf_state(q, prev_buf(bufnr), &state, 0);
 	if (state != SLSB_CU_OUTPUT_PRIMED)
-		qdio_kick_outbound_q(q);
+		rc = qdio_kick_outbound_q(q);
 	else {
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "fast-req");
 		qdio_perf_stat_inc(&perf_stats.fast_requeue);
 	}
 out:
 	tasklet_schedule(&q->tasklet);
+	return rc;
 }
 
 /**
@@ -1609,14 +1598,12 @@ int do_QDIO(struct ccw_device *cdev, unsigned int callflags,
 		return -EBUSY;
 
 	if (callflags & QDIO_FLAG_SYNC_INPUT)
-		handle_inbound(irq_ptr->input_qs[q_nr], callflags, bufnr,
-			       count);
+		return handle_inbound(irq_ptr->input_qs[q_nr],
+				      callflags, bufnr, count);
 	else if (callflags & QDIO_FLAG_SYNC_OUTPUT)
-		handle_outbound(irq_ptr->output_qs[q_nr], callflags, bufnr,
-				count);
-	else
-		return -EINVAL;
-	return 0;
+		return handle_outbound(irq_ptr->output_qs[q_nr],
+				       callflags, bufnr, count);
+	return -EINVAL;
 }
 EXPORT_SYMBOL_GPL(do_QDIO);
 

commit e85dea0e415617b5c5627f38c71b33fbc7f94a85
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Mar 26 15:24:29 2009 +0100

    [S390] qdio: seperate last move index and polling index
    
    The index value that indicated that the input queue moved was also used to
    store the index of the first acknowledged buffer. For non-qebsm only the
    newest buffer is acknowledged which may be different from the last move index
    so two seperate values are needed to track the input queue.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 61ba765936a6..31b9318149ba 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -380,11 +380,11 @@ inline void qdio_stop_polling(struct qdio_q *q)
 
 	/* show the card that we are not polling anymore */
 	if (is_qebsm(q)) {
-		set_buf_states(q, q->last_move_ftc, SLSB_P_INPUT_NOT_INIT,
+		set_buf_states(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT,
 			       q->u.in.ack_count);
 		q->u.in.ack_count = 0;
 	} else
-		set_buf_state(q, q->last_move_ftc, SLSB_P_INPUT_NOT_INIT);
+		set_buf_state(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT);
 }
 
 static void announce_buffer_error(struct qdio_q *q, int count)
@@ -419,15 +419,15 @@ static inline void inbound_primed(struct qdio_q *q, int count)
 		if (!q->u.in.polling) {
 			q->u.in.polling = 1;
 			q->u.in.ack_count = count;
-			q->last_move_ftc = q->first_to_check;
+			q->u.in.ack_start = q->first_to_check;
 			return;
 		}
 
 		/* delete the previous ACK's */
-		set_buf_states(q, q->last_move_ftc, SLSB_P_INPUT_NOT_INIT,
+		set_buf_states(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT,
 			       q->u.in.ack_count);
 		q->u.in.ack_count = count;
-		q->last_move_ftc = q->first_to_check;
+		q->u.in.ack_start = q->first_to_check;
 		return;
 	}
 
@@ -439,18 +439,13 @@ static inline void inbound_primed(struct qdio_q *q, int count)
 	if (q->u.in.polling) {
 		/* reset the previous ACK but first set the new one */
 		set_buf_state(q, new, SLSB_P_INPUT_ACK);
-		set_buf_state(q, q->last_move_ftc, SLSB_P_INPUT_NOT_INIT);
+		set_buf_state(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT);
 	} else {
 		q->u.in.polling = 1;
 		set_buf_state(q, new, SLSB_P_INPUT_ACK);
 	}
 
-	/*
-	 * last_move_ftc points to the ACK'ed buffer and not to the last turns
-	 * first_to_check like for qebsm. Since it is only used to check if
-	 * the queue front moved in qdio_inbound_q_done this is not a problem.
-	 */
-	q->last_move_ftc = new;
+	q->u.in.ack_start = new;
 	count--;
 	if (!count)
 		return;
@@ -527,7 +522,8 @@ int qdio_inbound_q_moved(struct qdio_q *q)
 
 	bufnr = get_inbound_buffer_frontier(q);
 
-	if ((bufnr != q->last_move_ftc) || q->qdio_error) {
+	if ((bufnr != q->last_move) || q->qdio_error) {
+		q->last_move = bufnr;
 		if (!need_siga_sync(q) && !pci_out_supported(q))
 			q->u.in.timestamp = get_usecs();
 
@@ -702,8 +698,8 @@ static inline int qdio_outbound_q_moved(struct qdio_q *q)
 
 	bufnr = get_outbound_buffer_frontier(q);
 
-	if ((bufnr != q->last_move_ftc) || q->qdio_error) {
-		q->last_move_ftc = bufnr;
+	if ((bufnr != q->last_move) || q->qdio_error) {
+		q->last_move = bufnr;
 		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out moved:%1d", q->nr);
 		return 1;
 	} else
@@ -748,7 +744,7 @@ static void qdio_kick_outbound_handler(struct qdio_q *q)
 	int start, end, count;
 
 	start = q->first_to_kick;
-	end = q->last_move_ftc;
+	end = q->last_move;
 	if (end >= start)
 		count = end - start;
 	else
@@ -764,7 +760,7 @@ static void qdio_kick_outbound_handler(struct qdio_q *q)
 		   q->irq_ptr->int_parm);
 
 	/* for the next time: */
-	q->first_to_kick = q->last_move_ftc;
+	q->first_to_kick = q->last_move;
 	q->qdio_error = 0;
 }
 
@@ -1475,18 +1471,18 @@ static void handle_inbound(struct qdio_q *q, unsigned int callflags,
 		q->u.in.polling = 0;
 		q->u.in.ack_count = 0;
 		goto set;
-	} else if (buf_in_between(q->last_move_ftc, bufnr, count)) {
+	} else if (buf_in_between(q->u.in.ack_start, bufnr, count)) {
 		if (is_qebsm(q)) {
-			/* partial overwrite, just update last_move_ftc */
+			/* partial overwrite, just update ack_start */
 			diff = add_buf(bufnr, count);
-			diff = sub_buf(diff, q->last_move_ftc);
+			diff = sub_buf(diff, q->u.in.ack_start);
 			q->u.in.ack_count -= diff;
 			if (q->u.in.ack_count <= 0) {
 				q->u.in.polling = 0;
 				q->u.in.ack_count = 0;
 				goto set;
 			}
-			q->last_move_ftc = add_buf(q->last_move_ftc, diff);
+			q->u.in.ack_start = add_buf(q->u.in.ack_start, diff);
 		}
 		else
 			/* the only ACK will be deleted, so stop polling */

commit 3fdf1e18cbc7c58f2d5604315ddae3596725bc6a
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Mar 26 15:24:28 2009 +0100

    [S390] qdio: move ACK to newest buffer for devices without QEBSM
    
    The ACKnowledgement state should be set on the newest SBAL so an
    adapter interrupt surpression check needs to scan fewer SBALs.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 8e6bc9cddfa0..61ba765936a6 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -440,12 +440,16 @@ static inline void inbound_primed(struct qdio_q *q, int count)
 		/* reset the previous ACK but first set the new one */
 		set_buf_state(q, new, SLSB_P_INPUT_ACK);
 		set_buf_state(q, q->last_move_ftc, SLSB_P_INPUT_NOT_INIT);
-	}
-	else {
+	} else {
 		q->u.in.polling = 1;
-		set_buf_state(q, q->first_to_check, SLSB_P_INPUT_ACK);
+		set_buf_state(q, new, SLSB_P_INPUT_ACK);
 	}
 
+	/*
+	 * last_move_ftc points to the ACK'ed buffer and not to the last turns
+	 * first_to_check like for qebsm. Since it is only used to check if
+	 * the queue front moved in qdio_inbound_q_done this is not a problem.
+	 */
 	q->last_move_ftc = new;
 	count--;
 	if (!count)
@@ -455,7 +459,7 @@ static inline void inbound_primed(struct qdio_q *q, int count)
 	 * Need to change all PRIMED buffers to NOT_INIT, otherwise
 	 * we're loosing initiative in the thinint code.
 	 */
-	set_buf_states(q, next_buf(q->first_to_check), SLSB_P_INPUT_NOT_INIT,
+	set_buf_states(q, q->first_to_check, SLSB_P_INPUT_NOT_INIT,
 		       count);
 }
 
@@ -1480,7 +1484,6 @@ static void handle_inbound(struct qdio_q *q, unsigned int callflags,
 			if (q->u.in.ack_count <= 0) {
 				q->u.in.polling = 0;
 				q->u.in.ack_count = 0;
-				/* TODO: must we set last_move_ftc to something meaningful? */
 				goto set;
 			}
 			q->last_move_ftc = add_buf(q->last_move_ftc, diff);

commit 700e982f28f5e13cef8eea93ac8c6702f699d894
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Mar 26 15:24:27 2009 +0100

    [S390] qdio: call qdio_free also if qdio_shutdown fails
    
    qdio_cleanup is a wrapper function that should call qdio_shutdown and
    qdio_free. qdio_free was not called if an error occured in qdio_shutdown
    resulting in a missing free of allocated resources.
    
    Call qdio_free regardless of the return value of qdio_shutdown.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 1974ec7bf0ed..8e6bc9cddfa0 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1073,8 +1073,9 @@ EXPORT_SYMBOL_GPL(qdio_get_ssqd_desc);
  * @cdev: associated ccw device
  * @how: use halt or clear to shutdown
  *
- * This function calls qdio_shutdown() for @cdev with method @how
- * and on success qdio_free() for @cdev.
+ * This function calls qdio_shutdown() for @cdev with method @how.
+ * and qdio_free(). The qdio_free() return value is ignored since
+ * !irq_ptr is already checked.
  */
 int qdio_cleanup(struct ccw_device *cdev, int how)
 {
@@ -1085,8 +1086,8 @@ int qdio_cleanup(struct ccw_device *cdev, int how)
 		return -ENODEV;
 
 	rc = qdio_shutdown(cdev, how);
-	if (rc == 0)
-		rc = qdio_free(cdev);
+
+	qdio_free(cdev);
 	return rc;
 }
 EXPORT_SYMBOL_GPL(qdio_cleanup);

commit c38f96080955854e54df9cb392bc674e1ae330e1
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Mar 26 15:24:26 2009 +0100

    [S390] qdio: proper kill of qdio tasklets
    
    The queue tasklets were stopped with tasklet_disable. Although tasklet_disable
    prevents the tasklet from beeing executed it is still possible that a tasklet
    is scheduled on a CPU at that point. A following qdio_establish calls
    tasklet_init which clears the tasklet count and the tasklet state leading to
    the following Oops:
    
        <2>kernel BUG at kernel/softirq.c:392!
        <4>illegal operation: 0001 [#1] SMP
        <4>Modules linked in: iptable_filter ip_tables x_tables dm_round_robin dm_multipath scsi_dh sg sd_mod crc_t10dif nfs lockd nfs
    _acl sunrpc fuse loop dm_mod qeth_l3 ipv6 zfcp qeth scsi_transport_fc qdio scsi_tgt scsi_mod chsc_sch ccwgroup dasd_eckd_mod dasdm
    od ext3 mbcache jbd
        <4>Supported: Yes
        <4>CPU: 0 Not tainted 2.6.27.13-1.1.mz13-default #1
        <4>Process blast.LzS_64 (pid: 16445, task: 000000006cc02538, ksp: 000000006cb67998)
        <4>Krnl PSW : 0704c00180000000 00000000001399f4 (tasklet_action+0xc8/0x1d4)
        <4>           R:0 T:1 IO:1 EX:1 Key:0 M:1 W:0 P:0 AS:3 CC:0 PM:0 EA:3
        <4>Krnl GPRS: ffffffff00000030 0000000000000002 0000000000000002 fffffffffffffffe
        <4>           000000000013aabe 00000000003b6a18 fffffffffffffffd 0000000000000000
        <4>           00000000006705a8 000000007d0914a8 000000007d0914b0 000000007fecfd30
        <4>           0000000000000000 00000000003b63e8 000000007fecfd90 000000007fecfd30
        <4>Krnl Code: 00000000001399e8: b9200021            cgr     %r2,%r1
        <4>           00000000001399ec: a7740004            brc     7,1399f4
        <4>           00000000001399f0: a7f40001            brc     15,1399f2
        <4>          >00000000001399f4: c0100027e8ee        larl    %r1,636bd0
        <4>           00000000001399fa: bf1f1008            icm     %r1,15,8(%r1)
        <4>           00000000001399fe: a7840019            brc     8,139a30
        <4>           0000000000139a02: c0300027e8ef        larl    %r3,636be0
        <4>           0000000000139a08: e3c030000004        lg      %r12,0(%r3)
        <4>Call Trace:
        <4>([<0000000000139c12>] tasklet_hi_action+0x112/0x1d4)
        <4> [<000000000013aabe>] __do_softirq+0xde/0x1c4
        <4> [<000000000010fa2e>] do_softirq+0x96/0xb0
        <4> [<000000000013a8d8>] irq_exit+0x70/0xcc
        <4> [<000000000010d1d8>] do_extint+0xf0/0x110
        <4> [<0000000000113b10>] ext_no_vtime+0x16/0x1a
        <4> [<000003e0000a3662>] ext3_dirty_inode+0xe6/0xe8 [ext3]
        <4>([<00000000001f6cf2>] __mark_inode_dirty+0x52/0x1d4)
        <4> [<000003e0000a44f0>] ext3_ordered_write_end+0x138/0x190 [ext3]
        <4> [<000000000018d5ec>] generic_perform_write+0x174/0x230
        <4> [<0000000000190144>] generic_file_buffered_write+0xb4/0x194
        <4> [<0000000000190864>] __generic_file_aio_write_nolock+0x418/0x454
        <4> [<0000000000190ee2>] generic_file_aio_write+0x76/0xe4
        <4> [<000003e0000a05c2>] ext3_file_write+0x3e/0xc8 [ext3]
        <4> [<00000000001cc2fe>] do_sync_write+0xd6/0x120
        <4> [<00000000001ccfc8>] vfs_write+0xac/0x184
        <4> [<00000000001cd218>] SyS_write+0x68/0xe0
        <4> [<0000000000113402>] sysc_noemu+0x10/0x16
        <4> [<0000020000043188>] 0x20000043188
        <4>Last Breaking-Event-Address:
        <4> [<00000000001399f0>] tasklet_action+0xc4/0x1d4
        <6>qdio: 0.0.c61b ZFCP on SC f67 using AI:1 QEBSM:0 PCI:1 TDD:1 SIGA: W AOP
        <4> <0>Kernel panic - not syncing: Fatal exception in interrupt
    
    Use tasklet_kill instead of tasklet_disbale. Since tasklet_schedule must not be
    called after tasklet_kill use the QDIO_IRQ_STATE_STOPPED to inidicate that a
    queue is going down and prevent further tasklet schedules in that case.
    
    Remove superflous tasklet_schedule from input queue setup, at that time
    the queues are not ready so the schedule results in a NOP.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index fa902703996c..1974ec7bf0ed 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -778,21 +778,17 @@ static void __qdio_outbound_processing(struct qdio_q *q)
 
 	spin_unlock_irqrestore(&q->lock, flags);
 
-	if (queue_type(q) == QDIO_ZFCP_QFMT) {
+	if (queue_type(q) == QDIO_ZFCP_QFMT)
 		if (!pci_out_supported(q) && !qdio_outbound_q_done(q))
-			tasklet_schedule(&q->tasklet);
-		return;
-	}
+			goto sched;
 
 	/* bail out for HiperSockets unicast queues */
 	if (queue_type(q) == QDIO_IQDIO_QFMT && !multicast_outbound(q))
 		return;
 
 	if ((queue_type(q) == QDIO_IQDIO_QFMT) &&
-	    (atomic_read(&q->nr_buf_used)) > QDIO_IQDIO_POLL_LVL) {
-		tasklet_schedule(&q->tasklet);
-		return;
-	}
+	    (atomic_read(&q->nr_buf_used)) > QDIO_IQDIO_POLL_LVL)
+		goto sched;
 
 	if (q->u.out.pci_out_enabled)
 		return;
@@ -810,6 +806,12 @@ static void __qdio_outbound_processing(struct qdio_q *q)
 			qdio_perf_stat_inc(&perf_stats.debug_tl_out_timer);
 		}
 	}
+	return;
+
+sched:
+	if (unlikely(q->irq_ptr->state == QDIO_IRQ_STATE_STOPPED))
+		return;
+	tasklet_schedule(&q->tasklet);
 }
 
 /* outbound tasklet */
@@ -822,6 +824,9 @@ void qdio_outbound_processing(unsigned long data)
 void qdio_outbound_timer(unsigned long data)
 {
 	struct qdio_q *q = (struct qdio_q *)data;
+
+	if (unlikely(q->irq_ptr->state == QDIO_IRQ_STATE_STOPPED))
+		return;
 	tasklet_schedule(&q->tasklet);
 }
 
@@ -863,6 +868,9 @@ static void qdio_int_handler_pci(struct qdio_irq *irq_ptr)
 	int i;
 	struct qdio_q *q;
 
+	if (unlikely(irq_ptr->state == QDIO_IRQ_STATE_STOPPED))
+		return;
+
 	qdio_perf_stat_inc(&perf_stats.pci_int);
 
 	for_each_input_queue(irq_ptr, q, i)
@@ -1090,11 +1098,11 @@ static void qdio_shutdown_queues(struct ccw_device *cdev)
 	int i;
 
 	for_each_input_queue(irq_ptr, q, i)
-		tasklet_disable(&q->tasklet);
+		tasklet_kill(&q->tasklet);
 
 	for_each_output_queue(irq_ptr, q, i) {
-		tasklet_disable(&q->tasklet);
 		del_timer(&q->u.out.timer);
+		tasklet_kill(&q->tasklet);
 	}
 }
 
@@ -1125,6 +1133,12 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 		return 0;
 	}
 
+	/*
+	 * Indicate that the device is going down. Scheduling the queue
+	 * tasklets is forbidden from here on.
+	 */
+	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_STOPPED);
+
 	tiqdio_remove_input_queues(irq_ptr);
 	qdio_shutdown_queues(cdev);
 	qdio_shutdown_debug_entries(irq_ptr, cdev);
@@ -1556,7 +1570,6 @@ static void handle_outbound(struct qdio_q *q, unsigned int callflags,
 		qdio_perf_stat_inc(&perf_stats.fast_requeue);
 	}
 out:
-	/* Fixme: could wait forever if called from process context */
 	tasklet_schedule(&q->tasklet);
 }
 

commit e4c14e2085cd32f61e9ffc47d5b20d4f5f7639f3
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Mar 26 15:24:25 2009 +0100

    [S390] qdio: Dont call qdio_shutdown in case qdio_activate fails
    
    Remove the call to qdio_shutdown from qdio_activate since the upper-layer
    drivers are responsible to call qdio_shutdown when qdio_activate returns
    with an error.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 5100996201d1..fa902703996c 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1404,9 +1404,8 @@ int qdio_activate(struct ccw_device *cdev)
 	switch (irq_ptr->state) {
 	case QDIO_IRQ_STATE_STOPPED:
 	case QDIO_IRQ_STATE_ERR:
-		mutex_unlock(&irq_ptr->setup_mutex);
-		qdio_shutdown(cdev, QDIO_FLAG_CLEANUP_USING_CLEAR);
-		return -EIO;
+		rc = -EIO;
+		break;
 	default:
 		qdio_set_state(irq_ptr, QDIO_IRQ_STATE_ACTIVE);
 		rc = 0;

commit b454740246d14b0a9c00220696f9020eaa15ca12
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Mar 26 15:24:24 2009 +0100

    [S390] qdio: add missing tiq_list locking
    
    Add a mutex to protect the tiq_list. Although reading the list is done
    using RCU adding and removing elements from the list must still
    happen locked since multiple qdio devices may change the list in parallel
    otherwise.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 10cb0f8726e5..5100996201d1 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1112,6 +1112,7 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 	if (!irq_ptr)
 		return -ENODEV;
 
+	BUG_ON(irqs_disabled());
 	DBF_EVENT("qshutdown:%4x", cdev->private->schid.sch_no);
 
 	mutex_lock(&irq_ptr->setup_mutex);

commit 73ac36ea14fd18ea3dc057e41b16ff31a3c0bd5a
Author: Coly Li <coyli@suse.de>
Date:   Wed Jan 7 18:09:16 2009 -0800

    fix similar typos to successfull
    
    When I review ocfs2 code, find there are 2 typos to "successfull".  After
    doing grep "successfull " in kernel tree, 22 typos found totally -- great
    minds always think alike :)
    
    This patch fixes all the similar typos. Thanks for Randy's ack and comments.
    
    Signed-off-by: Coly Li <coyli@suse.de>
    Acked-by: Randy Dunlap <randy.dunlap@oracle.com>
    Acked-by: Roland Dreier <rolandd@cisco.com>
    Cc: Jeremy Kerr <jk@ozlabs.org>
    Cc: Jeff Garzik <jeff@garzik.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Cc: Mark Fasheh <mfasheh@suse.com>
    Cc: Vlad Yasevich <vladislav.yasevich@hp.com>
    Cc: Sridhar Samudrala <sri@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 744f928a59ea..10cb0f8726e5 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -114,7 +114,7 @@ static inline int qdio_check_ccq(struct qdio_q *q, unsigned int ccq)
  * @count: count of buffers to examine
  * @auto_ack: automatically acknowledge buffers
  *
- * Returns the number of successfull extracted equal buffer states.
+ * Returns the number of successfully extracted equal buffer states.
  * Stops processing if a state is different from the last buffers state.
  */
 static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,

commit 7a0b4cbc7d7d99763511b488b08bbc2607ddd1e3
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Dec 25 13:38:48 2008 +0100

    [S390] qdio: fix error reporting for hipersockets
    
    Hipersocket connections can encounter temporary busy conditions.
    In case of the busy bit set we retry the SIGA operation immediatelly.
    If the busy condition still persists after 100 ms we fail and report
    the error to the upper layer. The second stage retry logic is removed.
    In case of ongoing busy conditions the upper layer needs to reset the
    connection.
    
    The reporting of a SIGA error is now done synchronously to allow the
    network driver to requeue the buffers. Also no error trace is created
    for the temporary SIGA errors so the error message view is not flooded.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 0b4c09cf6a47..744f928a59ea 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -74,7 +74,7 @@ static inline int do_siga_input(struct subchannel_id schid, unsigned int mask)
  * Note: For IQDC unicast queues only the highest priority queue is processed.
  */
 static inline int do_siga_output(unsigned long schid, unsigned long mask,
-				 u32 *bb, unsigned int fc)
+				 unsigned int *bb, unsigned int fc)
 {
 	register unsigned long __fc asm("0") = fc;
 	register unsigned long __schid asm("1") = schid;
@@ -284,8 +284,7 @@ static int qdio_siga_sync(struct qdio_q *q, unsigned int output,
 	if (!need_siga_sync(q))
 		return 0;
 
-	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-s:");
-	DBF_DEV_HEX(DBF_INFO, q->irq_ptr, q, sizeof(void *));
+	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-s:%1d", q->nr);
 	qdio_perf_stat_inc(&perf_stats.siga_sync);
 
 	cc = do_siga_sync(q->irq_ptr->schid, output, input);
@@ -312,46 +311,37 @@ static inline int qdio_siga_sync_all(struct qdio_q *q)
 	return qdio_siga_sync(q, ~0U, ~0U);
 }
 
-static inline int qdio_do_siga_output(struct qdio_q *q, unsigned int *busy_bit)
+static int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit)
 {
-	unsigned int fc = 0;
 	unsigned long schid;
+	unsigned int fc = 0;
+	u64 start_time = 0;
+	int cc;
 
-	if (q->u.out.use_enh_siga) {
+	if (q->u.out.use_enh_siga)
 		fc = 3;
-	}
-	if (!is_qebsm(q))
-		schid = *((u32 *)&q->irq_ptr->schid);
-	else {
+
+	if (is_qebsm(q)) {
 		schid = q->irq_ptr->sch_token;
 		fc |= 0x80;
 	}
-	return do_siga_output(schid, q->mask, busy_bit, fc);
-}
-
-static int qdio_siga_output(struct qdio_q *q)
-{
-	int cc;
-	u32 busy_bit;
-	u64 start_time = 0;
+	else
+		schid = *((u32 *)&q->irq_ptr->schid);
 
-	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-w:%1d", q->nr);
-	qdio_perf_stat_inc(&perf_stats.siga_out);
 again:
-	cc = qdio_do_siga_output(q, &busy_bit);
-	if (queue_type(q) == QDIO_IQDIO_QFMT && cc == 2 && busy_bit) {
-		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-w bb:%2d", q->nr);
+	cc = do_siga_output(schid, q->mask, busy_bit, fc);
+
+	/* hipersocket busy condition */
+	if (*busy_bit) {
+		WARN_ON(queue_type(q) != QDIO_IQDIO_QFMT || cc != 2);
 
-		if (!start_time)
+		if (!start_time) {
 			start_time = get_usecs();
-		else if ((get_usecs() - start_time) < QDIO_BUSY_BIT_PATIENCE)
+			goto again;
+		}
+		if ((get_usecs() - start_time) < QDIO_BUSY_BIT_PATIENCE)
 			goto again;
 	}
-
-	if (cc == 2 && busy_bit)
-		cc |= QDIO_ERROR_SIGA_BUSY;
-	if (cc)
-		DBF_ERROR("%4x SIGA-W:%2d", SCH_NO(q), cc);
 	return cc;
 }
 
@@ -399,7 +389,7 @@ inline void qdio_stop_polling(struct qdio_q *q)
 
 static void announce_buffer_error(struct qdio_q *q, int count)
 {
-	q->qdio_error = QDIO_ERROR_SLSB_STATE;
+	q->qdio_error |= QDIO_ERROR_SLSB_STATE;
 
 	/* special handling for no target buffer empty */
 	if ((!q->is_input_q &&
@@ -716,68 +706,36 @@ static inline int qdio_outbound_q_moved(struct qdio_q *q)
 		return 0;
 }
 
-/*
- * VM could present us cc=2 and busy bit set on SIGA-write
- * during reconfiguration of their Guest LAN (only in iqdio mode,
- * otherwise qdio is asynchronous and cc=2 and busy bit there will take
- * the queues down immediately).
- *
- * Therefore qdio_siga_output will try for a short time constantly,
- * if such a condition occurs. If it doesn't change, it will
- * increase the busy_siga_counter and save the timestamp, and
- * schedule the queue for later processing. qdio_outbound_processing
- * will check out the counter. If non-zero, it will call qdio_kick_outbound_q
- * as often as the value of the counter. This will attempt further SIGA
- * instructions. For each successful SIGA, the counter is
- * decreased, for failing SIGAs the counter remains the same, after
- * all. After some time of no movement, qdio_kick_outbound_q will
- * finally fail and reflect corresponding error codes to call
- * the upper layer module and have it take the queues down.
- *
- * Note that this is a change from the original HiperSockets design
- * (saying cc=2 and busy bit means take the queues down), but in
- * these days Guest LAN didn't exist... excessive cc=2 with busy bit
- * conditions will still take the queues down, but the threshold is
- * higher due to the Guest LAN environment.
- *
- * Called from outbound tasklet and do_QDIO handler.
- */
 static void qdio_kick_outbound_q(struct qdio_q *q)
 {
-	int rc;
-
-	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "kickoutq:%1d", q->nr);
+	unsigned int busy_bit;
+	int cc;
 
 	if (!need_siga_out(q))
 		return;
 
-	rc = qdio_siga_output(q);
-	switch (rc) {
+	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-w:%1d", q->nr);
+	qdio_perf_stat_inc(&perf_stats.siga_out);
+
+	cc = qdio_siga_output(q, &busy_bit);
+	switch (cc) {
 	case 0:
-		/* TODO: improve error handling for CC=0 case */
-		if (q->u.out.timestamp)
-			DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "cc2 rslv:%4x",
-				      atomic_read(&q->u.out.busy_siga_counter));
-		/* went smooth this time, reset timestamp */
-		q->u.out.timestamp = 0;
 		break;
-	/* cc=2 and busy bit */
-	case (2 | QDIO_ERROR_SIGA_BUSY):
-		atomic_inc(&q->u.out.busy_siga_counter);
-
-		/* if the last siga was successful, save timestamp here */
-		if (!q->u.out.timestamp)
-			q->u.out.timestamp = get_usecs();
-
-		/* if we're in time, don't touch qdio_error */
-		if (get_usecs() - q->u.out.timestamp < QDIO_BUSY_BIT_GIVE_UP) {
-			tasklet_schedule(&q->tasklet);
-			break;
+	case 2:
+		if (busy_bit) {
+			DBF_ERROR("%4x cc2 REP:%1d", SCH_NO(q), q->nr);
+			q->qdio_error = cc | QDIO_ERROR_SIGA_BUSY;
+		} else {
+			DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-w cc2:%1d",
+				      q->nr);
+			q->qdio_error = cc;
 		}
-		DBF_ERROR("%4x cc2 REP:%1d", SCH_NO(q), q->nr);
-	default:
-		/* for plain cc=1, 2 or 3 */
-		q->qdio_error = rc;
+		break;
+	case 1:
+	case 3:
+		DBF_ERROR("%4x SIGA-W:%1d", SCH_NO(q), cc);
+		q->qdio_error = cc;
+		break;
 	}
 }
 
@@ -808,22 +766,18 @@ static void qdio_kick_outbound_handler(struct qdio_q *q)
 
 static void __qdio_outbound_processing(struct qdio_q *q)
 {
-	int siga_attempts;
+	unsigned long flags;
 
 	qdio_perf_stat_inc(&perf_stats.tasklet_outbound);
-
-	/* see comment in qdio_kick_outbound_q */
-	siga_attempts = atomic_read(&q->u.out.busy_siga_counter);
-	while (siga_attempts--) {
-		atomic_dec(&q->u.out.busy_siga_counter);
-		qdio_kick_outbound_q(q);
-	}
+	spin_lock_irqsave(&q->lock, flags);
 
 	BUG_ON(atomic_read(&q->nr_buf_used) < 0);
 
 	if (qdio_outbound_q_moved(q))
 		qdio_kick_outbound_handler(q);
 
+	spin_unlock_irqrestore(&q->lock, flags);
+
 	if (queue_type(q) == QDIO_ZFCP_QFMT) {
 		if (!pci_out_supported(q) && !qdio_outbound_q_done(q))
 			tasklet_schedule(&q->tasklet);
@@ -1491,7 +1445,7 @@ static inline int buf_in_between(int bufnr, int start, int count)
 static void handle_inbound(struct qdio_q *q, unsigned int callflags,
 			   int bufnr, int count)
 {
-	int used, rc, diff;
+	int used, cc, diff;
 
 	if (!q->u.in.polling)
 		goto set;
@@ -1532,9 +1486,9 @@ static void handle_inbound(struct qdio_q *q, unsigned int callflags,
 		return;
 
 	if (need_siga_in(q)) {
-		rc = qdio_siga_input(q);
-		if (rc)
-			q->qdio_error = rc;
+		cc = qdio_siga_input(q);
+		if (cc)
+			q->qdio_error = cc;
 	}
 }
 
@@ -1581,6 +1535,10 @@ static void handle_outbound(struct qdio_q *q, unsigned int callflags,
 				while (count--)
 					qdio_kick_outbound_q(q);
 			}
+
+		/* report CC=2 conditions synchronously */
+		if (q->qdio_error)
+			__qdio_outbound_processing(q);
 		goto out;
 	}
 

commit 50f769df1c4bea766c4eb927eae35728fb93e305
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Dec 25 13:38:47 2008 +0100

    [S390] qdio: improve inbound buffer acknowledgement
    
    - Use automatic acknowledgement of incoming buffers in QEBSM mode
    - Move ACK for non-QEBSM mode always to the newest buffer to prevent
      a race with qdio_stop_polling
    - Remove the polling spinlock, the upper layer drivers return new buffers
      in the same code path and could not run in parallel
    - Don't flood the error log in case of no-target-buffer-empty
    - In handle_inbound we check if we would overwrite an ACK'ed buffer, if so
      advance the pointer to the oldest ACK'ed buffer so we don't overwrite an
      empty buffer in qdio_stop_polling
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index c810214d3d08..0b4c09cf6a47 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -112,12 +112,13 @@ static inline int qdio_check_ccq(struct qdio_q *q, unsigned int ccq)
  * @state: state of the extracted buffers
  * @start: buffer number to start at
  * @count: count of buffers to examine
+ * @auto_ack: automatically acknowledge buffers
  *
  * Returns the number of successfull extracted equal buffer states.
  * Stops processing if a state is different from the last buffers state.
  */
 static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
-			int start, int count)
+			int start, int count, int auto_ack)
 {
 	unsigned int ccq = 0;
 	int tmp_count = count, tmp_start = start;
@@ -130,7 +131,8 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 	if (!q->is_input_q)
 		nr += q->irq_ptr->nr_input_qs;
 again:
-	ccq = do_eqbs(q->irq_ptr->sch_token, state, nr, &tmp_start, &tmp_count);
+	ccq = do_eqbs(q->irq_ptr->sch_token, state, nr, &tmp_start, &tmp_count,
+		      auto_ack);
 	rc = qdio_check_ccq(q, ccq);
 
 	/* At least one buffer was processed, return and extract the remaining
@@ -176,6 +178,9 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 	int nr = q->nr;
 	int rc;
 
+	if (!count)
+		return 0;
+
 	BUG_ON(!q->irq_ptr->sch_token);
 	qdio_perf_stat_inc(&perf_stats.debug_sqbs_all);
 
@@ -203,7 +208,8 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 
 /* returns number of examined buffers and their common state in *state */
 static inline int get_buf_states(struct qdio_q *q, unsigned int bufnr,
-				 unsigned char *state, unsigned int count)
+				 unsigned char *state, unsigned int count,
+				 int auto_ack)
 {
 	unsigned char __state = 0;
 	int i;
@@ -212,7 +218,7 @@ static inline int get_buf_states(struct qdio_q *q, unsigned int bufnr,
 	BUG_ON(count > QDIO_MAX_BUFFERS_PER_Q);
 
 	if (is_qebsm(q))
-		return qdio_do_eqbs(q, state, bufnr, count);
+		return qdio_do_eqbs(q, state, bufnr, count, auto_ack);
 
 	for (i = 0; i < count; i++) {
 		if (!__state)
@@ -226,9 +232,9 @@ static inline int get_buf_states(struct qdio_q *q, unsigned int bufnr,
 }
 
 inline int get_buf_state(struct qdio_q *q, unsigned int bufnr,
-		  unsigned char *state)
+		  unsigned char *state, int auto_ack)
 {
-	return get_buf_states(q, bufnr, state, 1);
+	return get_buf_states(q, bufnr, state, 1, auto_ack);
 }
 
 /* wrap-around safe setting of slsb states, returns number of changed buffers */
@@ -376,29 +382,91 @@ void qdio_sync_after_thinint(struct qdio_q *q)
 
 inline void qdio_stop_polling(struct qdio_q *q)
 {
-	spin_lock_bh(&q->u.in.lock);
-	if (!q->u.in.polling) {
-		spin_unlock_bh(&q->u.in.lock);
+	if (!q->u.in.polling)
 		return;
-	}
+
 	q->u.in.polling = 0;
 	qdio_perf_stat_inc(&perf_stats.debug_stop_polling);
 
 	/* show the card that we are not polling anymore */
-	set_buf_state(q, q->last_move_ftc, SLSB_P_INPUT_NOT_INIT);
-	spin_unlock_bh(&q->u.in.lock);
+	if (is_qebsm(q)) {
+		set_buf_states(q, q->last_move_ftc, SLSB_P_INPUT_NOT_INIT,
+			       q->u.in.ack_count);
+		q->u.in.ack_count = 0;
+	} else
+		set_buf_state(q, q->last_move_ftc, SLSB_P_INPUT_NOT_INIT);
 }
 
-static void announce_buffer_error(struct qdio_q *q)
+static void announce_buffer_error(struct qdio_q *q, int count)
 {
+	q->qdio_error = QDIO_ERROR_SLSB_STATE;
+
+	/* special handling for no target buffer empty */
+	if ((!q->is_input_q &&
+	    (q->sbal[q->first_to_check]->element[15].flags & 0xff) == 0x10)) {
+		qdio_perf_stat_inc(&perf_stats.outbound_target_full);
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "OUTFULL FTC:%3d",
+			      q->first_to_check);
+		return;
+	}
+
 	DBF_ERROR("%4x BUF ERROR", SCH_NO(q));
 	DBF_ERROR((q->is_input_q) ? "IN:%2d" : "OUT:%2d", q->nr);
-	DBF_ERROR("FTC:%3d", q->first_to_check);
+	DBF_ERROR("FTC:%3d C:%3d", q->first_to_check, count);
 	DBF_ERROR("F14:%2x F15:%2x",
 		  q->sbal[q->first_to_check]->element[14].flags & 0xff,
 		  q->sbal[q->first_to_check]->element[15].flags & 0xff);
+}
 
-	q->qdio_error = QDIO_ERROR_SLSB_STATE;
+static inline void inbound_primed(struct qdio_q *q, int count)
+{
+	int new;
+
+	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in prim: %3d", count);
+
+	/* for QEBSM the ACK was already set by EQBS */
+	if (is_qebsm(q)) {
+		if (!q->u.in.polling) {
+			q->u.in.polling = 1;
+			q->u.in.ack_count = count;
+			q->last_move_ftc = q->first_to_check;
+			return;
+		}
+
+		/* delete the previous ACK's */
+		set_buf_states(q, q->last_move_ftc, SLSB_P_INPUT_NOT_INIT,
+			       q->u.in.ack_count);
+		q->u.in.ack_count = count;
+		q->last_move_ftc = q->first_to_check;
+		return;
+	}
+
+	/*
+	 * ACK the newest buffer. The ACK will be removed in qdio_stop_polling
+	 * or by the next inbound run.
+	 */
+	new = add_buf(q->first_to_check, count - 1);
+	if (q->u.in.polling) {
+		/* reset the previous ACK but first set the new one */
+		set_buf_state(q, new, SLSB_P_INPUT_ACK);
+		set_buf_state(q, q->last_move_ftc, SLSB_P_INPUT_NOT_INIT);
+	}
+	else {
+		q->u.in.polling = 1;
+		set_buf_state(q, q->first_to_check, SLSB_P_INPUT_ACK);
+	}
+
+	q->last_move_ftc = new;
+	count--;
+	if (!count)
+		return;
+
+	/*
+	 * Need to change all PRIMED buffers to NOT_INIT, otherwise
+	 * we're loosing initiative in the thinint code.
+	 */
+	set_buf_states(q, next_buf(q->first_to_check), SLSB_P_INPUT_NOT_INIT,
+		       count);
 }
 
 static int get_inbound_buffer_frontier(struct qdio_q *q)
@@ -406,13 +474,6 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	int count, stop;
 	unsigned char state;
 
-	/*
-	 * If we still poll don't update last_move_ftc, keep the
-	 * previously ACK buffer there.
-	 */
-	if (!q->u.in.polling)
-		q->last_move_ftc = q->first_to_check;
-
 	/*
 	 * Don't check 128 buffers, as otherwise qdio_inbound_q_moved
 	 * would return 0.
@@ -433,34 +494,13 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	if (q->first_to_check == stop)
 		goto out;
 
-	count = get_buf_states(q, q->first_to_check, &state, count);
+	count = get_buf_states(q, q->first_to_check, &state, count, 1);
 	if (!count)
 		goto out;
 
 	switch (state) {
 	case SLSB_P_INPUT_PRIMED:
-		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in prim: %3d", count);
-
-		/*
-		 * Only ACK the first buffer. The ACK will be removed in
-		 * qdio_stop_polling.
-		 */
-		if (q->u.in.polling)
-			state = SLSB_P_INPUT_NOT_INIT;
-		else {
-			q->u.in.polling = 1;
-			state = SLSB_P_INPUT_ACK;
-		}
-		set_buf_state(q, q->first_to_check, state);
-
-		/*
-		 * Need to change all PRIMED buffers to NOT_INIT, otherwise
-		 * we're loosing initiative in the thinint code.
-		 */
-		if (count > 1)
-			set_buf_states(q, next_buf(q->first_to_check),
-				       SLSB_P_INPUT_NOT_INIT, count - 1);
-
+		inbound_primed(q, count);
 		/*
 		 * No siga-sync needed for non-qebsm here, as the inbound queue
 		 * will be synced on the next siga-r, resp.
@@ -470,7 +510,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 		atomic_sub(count, &q->nr_buf_used);
 		goto check_next;
 	case SLSB_P_INPUT_ERROR:
-		announce_buffer_error(q);
+		announce_buffer_error(q, count);
 		/* process the buffer, the upper layer will take care of it */
 		q->first_to_check = add_buf(q->first_to_check, count);
 		atomic_sub(count, &q->nr_buf_used);
@@ -516,7 +556,7 @@ static int qdio_inbound_q_done(struct qdio_q *q)
 	 */
 	qdio_siga_sync_q(q);
 
-	get_buf_state(q, q->first_to_check, &state);
+	get_buf_state(q, q->first_to_check, &state, 0);
 	if (state == SLSB_P_INPUT_PRIMED)
 		/* we got something to do */
 		return 0;
@@ -619,7 +659,7 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 	if (q->first_to_check == stop)
 		return q->first_to_check;
 
-	count = get_buf_states(q, q->first_to_check, &state, count);
+	count = get_buf_states(q, q->first_to_check, &state, count, 0);
 	if (!count)
 		return q->first_to_check;
 
@@ -638,7 +678,7 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 			break;
 		goto check_next;
 	case SLSB_P_OUTPUT_ERROR:
-		announce_buffer_error(q);
+		announce_buffer_error(q, count);
 		/* process the buffer, the upper layer will take care of it */
 		q->first_to_check = add_buf(q->first_to_check, count);
 		atomic_sub(count, &q->nr_buf_used);
@@ -1451,23 +1491,38 @@ static inline int buf_in_between(int bufnr, int start, int count)
 static void handle_inbound(struct qdio_q *q, unsigned int callflags,
 			   int bufnr, int count)
 {
-	unsigned long flags;
-	int used, rc;
+	int used, rc, diff;
 
-	/*
-	 * do_QDIO could run in parallel with the queue tasklet so the
-	 * upper-layer programm could empty the ACK'ed buffer here.
-	 * If that happens we must clear the polling flag, otherwise
-	 * qdio_stop_polling() could set the buffer to NOT_INIT after
-	 * it was set to EMPTY which would kill us.
-	 */
-	spin_lock_irqsave(&q->u.in.lock, flags);
-	if (q->u.in.polling)
-		if (buf_in_between(q->last_move_ftc, bufnr, count))
+	if (!q->u.in.polling)
+		goto set;
+
+	/* protect against stop polling setting an ACK for an emptied slsb */
+	if (count == QDIO_MAX_BUFFERS_PER_Q) {
+		/* overwriting everything, just delete polling status */
+		q->u.in.polling = 0;
+		q->u.in.ack_count = 0;
+		goto set;
+	} else if (buf_in_between(q->last_move_ftc, bufnr, count)) {
+		if (is_qebsm(q)) {
+			/* partial overwrite, just update last_move_ftc */
+			diff = add_buf(bufnr, count);
+			diff = sub_buf(diff, q->last_move_ftc);
+			q->u.in.ack_count -= diff;
+			if (q->u.in.ack_count <= 0) {
+				q->u.in.polling = 0;
+				q->u.in.ack_count = 0;
+				/* TODO: must we set last_move_ftc to something meaningful? */
+				goto set;
+			}
+			q->last_move_ftc = add_buf(q->last_move_ftc, diff);
+		}
+		else
+			/* the only ACK will be deleted, so stop polling */
 			q->u.in.polling = 0;
+	}
 
+set:
 	count = set_buf_states(q, bufnr, SLSB_CU_INPUT_EMPTY, count);
-	spin_unlock_irqrestore(&q->u.in.lock, flags);
 
 	used = atomic_add_return(count, &q->nr_buf_used) - count;
 	BUG_ON(used + count > QDIO_MAX_BUFFERS_PER_Q);
@@ -1535,7 +1590,7 @@ static void handle_outbound(struct qdio_q *q, unsigned int callflags,
 	}
 
 	/* try to fast requeue buffers */
-	get_buf_state(q, prev_buf(bufnr), &state);
+	get_buf_state(q, prev_buf(bufnr), &state, 0);
 	if (state != SLSB_CU_OUTPUT_PRIMED)
 		qdio_kick_outbound_q(q);
 	else {

commit 22f9934767f49012ffbae753b28b8055bd28348f
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Dec 25 13:38:46 2008 +0100

    [S390] qdio: rework debug feature logging
    
    - make qdio_trace a per device view
    - remove s390dbf exceptions
    - remove CONFIG_QDIO_DEBUG, not needed anymore if we check for the level
      before calling sprintf
    - use snprintf for dbf entries
    - add start markers to see if the dbf view wrapped
    - add a global error view for all queues
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 9e6ab41e5a3c..c810214d3d08 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -95,8 +95,6 @@ static inline int do_siga_output(unsigned long schid, unsigned long mask,
 
 static inline int qdio_check_ccq(struct qdio_q *q, unsigned int ccq)
 {
-	char dbf_text[15];
-
 	/* all done or next buffer state different */
 	if (ccq == 0 || ccq == 32)
 		return 0;
@@ -104,8 +102,7 @@ static inline int qdio_check_ccq(struct qdio_q *q, unsigned int ccq)
 	if (ccq == 96 || ccq == 97)
 		return 1;
 	/* notify devices immediately */
-	sprintf(dbf_text, "%d", ccq);
-	QDIO_DBF_TEXT2(1, trace, dbf_text);
+	DBF_ERROR("%4x ccq:%3d", SCH_NO(q), ccq);
 	return -EIO;
 }
 
@@ -126,7 +123,6 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 	int tmp_count = count, tmp_start = start;
 	int nr = q->nr;
 	int rc;
-	char dbf_text[15];
 
 	BUG_ON(!q->irq_ptr->sch_token);
 	qdio_perf_stat_inc(&perf_stats.debug_eqbs_all);
@@ -144,15 +140,15 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 		qdio_perf_stat_inc(&perf_stats.debug_eqbs_incomplete);
 		return (count - tmp_count);
 	}
+
 	if (rc == 1) {
-		QDIO_DBF_TEXT5(1, trace, "eqAGAIN");
+		DBF_DEV_EVENT(DBF_WARN, q->irq_ptr, "EQBS again:%2d", ccq);
 		goto again;
 	}
 
 	if (rc < 0) {
-		QDIO_DBF_TEXT2(1, trace, "eqberr");
-		sprintf(dbf_text, "%2x,%2x,%d,%d", count, tmp_count, ccq, nr);
-		QDIO_DBF_TEXT2(1, trace, dbf_text);
+		DBF_ERROR("%4x EQBS ERROR", SCH_NO(q));
+		DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
 		q->handler(q->irq_ptr->cdev,
 			   QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
 			   0, -1, -1, q->irq_ptr->int_parm);
@@ -179,7 +175,6 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 	int tmp_count = count, tmp_start = start;
 	int nr = q->nr;
 	int rc;
-	char dbf_text[15];
 
 	BUG_ON(!q->irq_ptr->sch_token);
 	qdio_perf_stat_inc(&perf_stats.debug_sqbs_all);
@@ -190,17 +185,13 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 	ccq = do_sqbs(q->irq_ptr->sch_token, state, nr, &tmp_start, &tmp_count);
 	rc = qdio_check_ccq(q, ccq);
 	if (rc == 1) {
-		QDIO_DBF_TEXT5(1, trace, "sqAGAIN");
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "SQBS again:%2d", ccq);
 		qdio_perf_stat_inc(&perf_stats.debug_sqbs_incomplete);
 		goto again;
 	}
 	if (rc < 0) {
-		QDIO_DBF_TEXT3(1, trace, "sqberr");
-		sprintf(dbf_text, "%2x,%2x", count, tmp_count);
-		QDIO_DBF_TEXT3(1, trace, dbf_text);
-		sprintf(dbf_text, "%d,%d", ccq, nr);
-		QDIO_DBF_TEXT3(1, trace, dbf_text);
-
+		DBF_ERROR("%4x SQBS ERROR", SCH_NO(q));
+		DBF_ERROR("%3d%3d%2d", count, tmp_count, nr);
 		q->handler(q->irq_ptr->cdev,
 			   QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
 			   0, -1, -1, q->irq_ptr->int_parm);
@@ -287,14 +278,13 @@ static int qdio_siga_sync(struct qdio_q *q, unsigned int output,
 	if (!need_siga_sync(q))
 		return 0;
 
+	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-s:");
+	DBF_DEV_HEX(DBF_INFO, q->irq_ptr, q, sizeof(void *));
 	qdio_perf_stat_inc(&perf_stats.siga_sync);
 
 	cc = do_siga_sync(q->irq_ptr->schid, output, input);
-	if (cc) {
-		QDIO_DBF_TEXT4(0, trace, "sigasync");
-		QDIO_DBF_HEX4(0, trace, &q, sizeof(void *));
-		QDIO_DBF_HEX3(0, trace, &cc, sizeof(int *));
-	}
+	if (cc)
+		DBF_ERROR("%4x SIGA-S:%2d", SCH_NO(q), cc);
 	return cc;
 }
 
@@ -338,17 +328,13 @@ static int qdio_siga_output(struct qdio_q *q)
 	int cc;
 	u32 busy_bit;
 	u64 start_time = 0;
-	char dbf_text[15];
-
-	QDIO_DBF_TEXT5(0, trace, "sigaout");
-	QDIO_DBF_HEX5(0, trace, &q, sizeof(void *));
 
+	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-w:%1d", q->nr);
 	qdio_perf_stat_inc(&perf_stats.siga_out);
 again:
 	cc = qdio_do_siga_output(q, &busy_bit);
 	if (queue_type(q) == QDIO_IQDIO_QFMT && cc == 2 && busy_bit) {
-		sprintf(dbf_text, "bb%4x%2x", q->irq_ptr->schid.sch_no, q->nr);
-		QDIO_DBF_TEXT3(0, trace, dbf_text);
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-w bb:%2d", q->nr);
 
 		if (!start_time)
 			start_time = get_usecs();
@@ -359,7 +345,7 @@ static int qdio_siga_output(struct qdio_q *q)
 	if (cc == 2 && busy_bit)
 		cc |= QDIO_ERROR_SIGA_BUSY;
 	if (cc)
-		QDIO_DBF_HEX3(0, trace, &cc, sizeof(int *));
+		DBF_ERROR("%4x SIGA-W:%2d", SCH_NO(q), cc);
 	return cc;
 }
 
@@ -367,14 +353,12 @@ static inline int qdio_siga_input(struct qdio_q *q)
 {
 	int cc;
 
-	QDIO_DBF_TEXT4(0, trace, "sigain");
-	QDIO_DBF_HEX4(0, trace, &q, sizeof(void *));
-
+	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-r:%1d", q->nr);
 	qdio_perf_stat_inc(&perf_stats.siga_in);
 
 	cc = do_siga_input(q->irq_ptr->schid, q->mask);
 	if (cc)
-		QDIO_DBF_HEX3(0, trace, &cc, sizeof(int *));
+		DBF_ERROR("%4x SIGA-R:%2d", SCH_NO(q), cc);
 	return cc;
 }
 
@@ -407,18 +391,12 @@ inline void qdio_stop_polling(struct qdio_q *q)
 
 static void announce_buffer_error(struct qdio_q *q)
 {
-	char dbf_text[15];
-
-	if (q->is_input_q)
-		QDIO_DBF_TEXT3(1, trace, "inperr");
-	else
-		QDIO_DBF_TEXT3(0, trace, "outperr");
-
-	sprintf(dbf_text, "%x-%x-%x", q->first_to_check,
-		q->sbal[q->first_to_check]->element[14].flags,
-		q->sbal[q->first_to_check]->element[15].flags);
-	QDIO_DBF_TEXT3(1, trace, dbf_text);
-	QDIO_DBF_HEX2(1, trace, q->sbal[q->first_to_check], 256);
+	DBF_ERROR("%4x BUF ERROR", SCH_NO(q));
+	DBF_ERROR((q->is_input_q) ? "IN:%2d" : "OUT:%2d", q->nr);
+	DBF_ERROR("FTC:%3d", q->first_to_check);
+	DBF_ERROR("F14:%2x F15:%2x",
+		  q->sbal[q->first_to_check]->element[14].flags & 0xff,
+		  q->sbal[q->first_to_check]->element[15].flags & 0xff);
 
 	q->qdio_error = QDIO_ERROR_SLSB_STATE;
 }
@@ -461,7 +439,7 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 
 	switch (state) {
 	case SLSB_P_INPUT_PRIMED:
-		QDIO_DBF_TEXT5(0, trace, "inptprim");
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in prim: %3d", count);
 
 		/*
 		 * Only ACK the first buffer. The ACK will be removed in
@@ -500,13 +478,12 @@ static int get_inbound_buffer_frontier(struct qdio_q *q)
 	case SLSB_CU_INPUT_EMPTY:
 	case SLSB_P_INPUT_NOT_INIT:
 	case SLSB_P_INPUT_ACK:
-		QDIO_DBF_TEXT5(0, trace, "inpnipro");
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in nop");
 		break;
 	default:
 		BUG();
 	}
 out:
-	QDIO_DBF_HEX4(0, trace, &q->first_to_check, sizeof(int));
 	return q->first_to_check;
 }
 
@@ -520,8 +497,7 @@ int qdio_inbound_q_moved(struct qdio_q *q)
 		if (!need_siga_sync(q) && !pci_out_supported(q))
 			q->u.in.timestamp = get_usecs();
 
-		QDIO_DBF_TEXT4(0, trace, "inhasmvd");
-		QDIO_DBF_HEX4(0, trace, &q, sizeof(void *));
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in moved");
 		return 1;
 	} else
 		return 0;
@@ -530,9 +506,6 @@ int qdio_inbound_q_moved(struct qdio_q *q)
 static int qdio_inbound_q_done(struct qdio_q *q)
 {
 	unsigned char state = 0;
-#ifdef CONFIG_QDIO_DEBUG
-	char dbf_text[15];
-#endif
 
 	if (!atomic_read(&q->nr_buf_used))
 		return 1;
@@ -557,20 +530,12 @@ static int qdio_inbound_q_done(struct qdio_q *q)
 	 * has (probably) not moved (see qdio_inbound_processing).
 	 */
 	if (get_usecs() > q->u.in.timestamp + QDIO_INPUT_THRESHOLD) {
-#ifdef CONFIG_QDIO_DEBUG
-		QDIO_DBF_TEXT4(0, trace, "inqisdon");
-		QDIO_DBF_HEX4(0, trace, &q, sizeof(void *));
-		sprintf(dbf_text, "pf%02x", q->first_to_check);
-		QDIO_DBF_TEXT4(0, trace, dbf_text);
-#endif /* CONFIG_QDIO_DEBUG */
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in done:%3d",
+			      q->first_to_check);
 		return 1;
 	} else {
-#ifdef CONFIG_QDIO_DEBUG
-		QDIO_DBF_TEXT4(0, trace, "inqisntd");
-		QDIO_DBF_HEX4(0, trace, &q, sizeof(void *));
-		sprintf(dbf_text, "pf%02x", q->first_to_check);
-		QDIO_DBF_TEXT4(0, trace, dbf_text);
-#endif /* CONFIG_QDIO_DEBUG */
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in notd:%3d",
+			      q->first_to_check);
 		return 0;
 	}
 }
@@ -578,9 +543,6 @@ static int qdio_inbound_q_done(struct qdio_q *q)
 void qdio_kick_inbound_handler(struct qdio_q *q)
 {
 	int count, start, end;
-#ifdef CONFIG_QDIO_DEBUG
-	char dbf_text[15];
-#endif
 
 	qdio_perf_stat_inc(&perf_stats.inbound_handler);
 
@@ -591,10 +553,7 @@ void qdio_kick_inbound_handler(struct qdio_q *q)
 	else
 		count = end + QDIO_MAX_BUFFERS_PER_Q - start;
 
-#ifdef CONFIG_QDIO_DEBUG
-	sprintf(dbf_text, "s=%2xc=%2x", start, count);
-	QDIO_DBF_TEXT4(0, trace, dbf_text);
-#endif /* CONFIG_QDIO_DEBUG */
+	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "kih s:%3d c:%3d", start, count);
 
 	if (unlikely(q->irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))
 		return;
@@ -667,7 +626,7 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 	switch (state) {
 	case SLSB_P_OUTPUT_EMPTY:
 		/* the adapter got it */
-		QDIO_DBF_TEXT5(0, trace, "outpempt");
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out empty:%1d %3d", q->nr, count);
 
 		atomic_sub(count, &q->nr_buf_used);
 		q->first_to_check = add_buf(q->first_to_check, count);
@@ -686,7 +645,7 @@ static int get_outbound_buffer_frontier(struct qdio_q *q)
 		break;
 	case SLSB_CU_OUTPUT_PRIMED:
 		/* the adapter has not fetched the output yet */
-		QDIO_DBF_TEXT5(0, trace, "outpprim");
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out primed:%1d", q->nr);
 		break;
 	case SLSB_P_OUTPUT_NOT_INIT:
 	case SLSB_P_OUTPUT_HALTED:
@@ -711,8 +670,7 @@ static inline int qdio_outbound_q_moved(struct qdio_q *q)
 
 	if ((bufnr != q->last_move_ftc) || q->qdio_error) {
 		q->last_move_ftc = bufnr;
-		QDIO_DBF_TEXT4(0, trace, "oqhasmvd");
-		QDIO_DBF_HEX4(0, trace, &q, sizeof(void *));
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out moved:%1d", q->nr);
 		return 1;
 	} else
 		return 0;
@@ -747,12 +705,8 @@ static inline int qdio_outbound_q_moved(struct qdio_q *q)
 static void qdio_kick_outbound_q(struct qdio_q *q)
 {
 	int rc;
-#ifdef CONFIG_QDIO_DEBUG
-	char dbf_text[15];
 
-	QDIO_DBF_TEXT5(0, trace, "kickoutq");
-	QDIO_DBF_HEX5(0, trace, &q, sizeof(void *));
-#endif /* CONFIG_QDIO_DEBUG */
+	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "kickoutq:%1d", q->nr);
 
 	if (!need_siga_out(q))
 		return;
@@ -761,15 +715,9 @@ static void qdio_kick_outbound_q(struct qdio_q *q)
 	switch (rc) {
 	case 0:
 		/* TODO: improve error handling for CC=0 case */
-#ifdef CONFIG_QDIO_DEBUG
-		if (q->u.out.timestamp) {
-			QDIO_DBF_TEXT3(0, trace, "cc2reslv");
-			sprintf(dbf_text, "%4x%2x%2x", q->irq_ptr->schid.sch_no,
-				q->nr,
-				atomic_read(&q->u.out.busy_siga_counter));
-			QDIO_DBF_TEXT3(0, trace, dbf_text);
-		}
-#endif /* CONFIG_QDIO_DEBUG */
+		if (q->u.out.timestamp)
+			DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "cc2 rslv:%4x",
+				      atomic_read(&q->u.out.busy_siga_counter));
 		/* went smooth this time, reset timestamp */
 		q->u.out.timestamp = 0;
 		break;
@@ -786,12 +734,7 @@ static void qdio_kick_outbound_q(struct qdio_q *q)
 			tasklet_schedule(&q->tasklet);
 			break;
 		}
-		QDIO_DBF_TEXT2(0, trace, "cc2REPRT");
-#ifdef CONFIG_QDIO_DEBUG
-		sprintf(dbf_text, "%4x%2x%2x", q->irq_ptr->schid.sch_no, q->nr,
-			atomic_read(&q->u.out.busy_siga_counter));
-		QDIO_DBF_TEXT3(0, trace, dbf_text);
-#endif /* CONFIG_QDIO_DEBUG */
+		DBF_ERROR("%4x cc2 REP:%1d", SCH_NO(q), q->nr);
 	default:
 		/* for plain cc=1, 2 or 3 */
 		q->qdio_error = rc;
@@ -801,9 +744,6 @@ static void qdio_kick_outbound_q(struct qdio_q *q)
 static void qdio_kick_outbound_handler(struct qdio_q *q)
 {
 	int start, end, count;
-#ifdef CONFIG_QDIO_DEBUG
-	char dbf_text[15];
-#endif
 
 	start = q->first_to_kick;
 	end = q->last_move_ftc;
@@ -812,13 +752,8 @@ static void qdio_kick_outbound_handler(struct qdio_q *q)
 	else
 		count = end + QDIO_MAX_BUFFERS_PER_Q - start;
 
-#ifdef CONFIG_QDIO_DEBUG
-	QDIO_DBF_TEXT4(0, trace, "kickouth");
-	QDIO_DBF_HEX4(0, trace, &q, sizeof(void *));
-
-	sprintf(dbf_text, "s=%2xc=%2x", start, count);
-	QDIO_DBF_TEXT4(0, trace, dbf_text);
-#endif /* CONFIG_QDIO_DEBUG */
+	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "kickouth: %1d", q->nr);
+	DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "s:%3d c:%3d", start, count);
 
 	if (unlikely(q->irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))
 		return;
@@ -913,27 +848,18 @@ void qdio_check_outbound_after_thinint(struct qdio_q *q)
 static inline void qdio_set_state(struct qdio_irq *irq_ptr,
 				  enum qdio_irq_states state)
 {
-#ifdef CONFIG_QDIO_DEBUG
-	char dbf_text[15];
-
-	QDIO_DBF_TEXT5(0, trace, "newstate");
-	sprintf(dbf_text, "%4x%4x", irq_ptr->schid.sch_no, state);
-	QDIO_DBF_TEXT5(0, trace, dbf_text);
-#endif /* CONFIG_QDIO_DEBUG */
+	DBF_DEV_EVENT(DBF_INFO, irq_ptr, "newstate: %1d", state);
 
 	irq_ptr->state = state;
 	mb();
 }
 
-static void qdio_irq_check_sense(struct subchannel_id schid, struct irb *irb)
+static void qdio_irq_check_sense(struct qdio_irq *irq_ptr, struct irb *irb)
 {
-	char dbf_text[15];
-
 	if (irb->esw.esw0.erw.cons) {
-		sprintf(dbf_text, "sens%4x", schid.sch_no);
-		QDIO_DBF_TEXT2(1, trace, dbf_text);
-		QDIO_DBF_HEX0(0, trace, irb, 64);
-		QDIO_DBF_HEX0(0, trace, irb->ecw, 64);
+		DBF_ERROR("%4x sense:", irq_ptr->schid.sch_no);
+		DBF_ERROR_HEX(irb, 64);
+		DBF_ERROR_HEX(irb->ecw, 64);
 	}
 }
 
@@ -967,14 +893,10 @@ static void qdio_handle_activate_check(struct ccw_device *cdev,
 {
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 	struct qdio_q *q;
-	char dbf_text[15];
 
-	QDIO_DBF_TEXT2(1, trace, "ick2");
-	sprintf(dbf_text, "%s", dev_name(&cdev->dev));
-	QDIO_DBF_TEXT2(1, trace, dbf_text);
-	QDIO_DBF_HEX2(0, trace, &intparm, sizeof(int));
-	QDIO_DBF_HEX2(0, trace, &dstat, sizeof(int));
-	QDIO_DBF_HEX2(0, trace, &cstat, sizeof(int));
+	DBF_ERROR("%4x ACT CHECK", irq_ptr->schid.sch_no);
+	DBF_ERROR("intp :%lx", intparm);
+	DBF_ERROR("ds: %2x cs:%2x", dstat, cstat);
 
 	if (irq_ptr->nr_input_qs) {
 		q = irq_ptr->input_qs[0];
@@ -1027,28 +949,29 @@ static void qdio_int_error(struct ccw_device *cdev)
 }
 
 static int qdio_establish_check_errors(struct ccw_device *cdev, int cstat,
-					   int dstat)
+				       int dstat)
 {
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 
 	if (cstat || (dstat & ~(DEV_STAT_CHN_END | DEV_STAT_DEV_END))) {
-		QDIO_DBF_TEXT2(1, setup, "eq:ckcon");
+		DBF_ERROR("EQ:ck con");
 		goto error;
 	}
 
 	if (!(dstat & DEV_STAT_DEV_END)) {
-		QDIO_DBF_TEXT2(1, setup, "eq:no de");
+		DBF_ERROR("EQ:no dev");
 		goto error;
 	}
 
 	if (dstat & ~(DEV_STAT_CHN_END | DEV_STAT_DEV_END)) {
-		QDIO_DBF_TEXT2(1, setup, "eq:badio");
+		DBF_ERROR("EQ: bad io");
 		goto error;
 	}
 	return 0;
 error:
-	QDIO_DBF_HEX2(0, trace, &cstat, sizeof(int));
-	QDIO_DBF_HEX2(0, trace, &dstat, sizeof(int));
+	DBF_ERROR("%4x EQ:error", irq_ptr->schid.sch_no);
+	DBF_ERROR("ds: %2x cs:%2x", dstat, cstat);
+
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_ERR);
 	return 1;
 }
@@ -1057,12 +980,8 @@ static void qdio_establish_handle_irq(struct ccw_device *cdev, int cstat,
 				      int dstat)
 {
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
-	char dbf_text[15];
-
-	sprintf(dbf_text, "qehi%4x", cdev->private->schid.sch_no);
-	QDIO_DBF_TEXT0(0, setup, dbf_text);
-	QDIO_DBF_TEXT0(0, trace, dbf_text);
 
+	DBF_DEV_EVENT(DBF_INFO, irq_ptr, "qest irq");
 	if (!qdio_establish_check_errors(cdev, cstat, dstat))
 		qdio_set_state(irq_ptr, QDIO_IRQ_STATE_ESTABLISHED);
 }
@@ -1073,25 +992,21 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 {
 	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 	int cstat, dstat;
-	char dbf_text[15];
 
 	qdio_perf_stat_inc(&perf_stats.qdio_int);
 
 	if (!intparm || !irq_ptr) {
-		sprintf(dbf_text, "qihd%4x", cdev->private->schid.sch_no);
-		QDIO_DBF_TEXT2(1, setup, dbf_text);
+		DBF_ERROR("qint:%4x", cdev->private->schid.sch_no);
 		return;
 	}
 
 	if (IS_ERR(irb)) {
 		switch (PTR_ERR(irb)) {
 		case -EIO:
-			sprintf(dbf_text, "ierr%4x", irq_ptr->schid.sch_no);
-			QDIO_DBF_TEXT2(1, setup, dbf_text);
+			DBF_ERROR("%4x IO error", irq_ptr->schid.sch_no);
 			return;
 		case -ETIMEDOUT:
-			sprintf(dbf_text, "qtoh%4x", irq_ptr->schid.sch_no);
-			QDIO_DBF_TEXT2(1, setup, dbf_text);
+			DBF_ERROR("%4x IO timeout", irq_ptr->schid.sch_no);
 			qdio_int_error(cdev);
 			return;
 		default:
@@ -1099,7 +1014,7 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 			return;
 		}
 	}
-	qdio_irq_check_sense(irq_ptr->schid, irb);
+	qdio_irq_check_sense(irq_ptr, irb);
 
 	cstat = irb->scsw.cmd.cstat;
 	dstat = irb->scsw.cmd.dstat;
@@ -1142,14 +1057,11 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 int qdio_get_ssqd_desc(struct ccw_device *cdev,
 		       struct qdio_ssqd_desc *data)
 {
-	char dbf_text[15];
 
 	if (!cdev || !cdev->private)
 		return -EINVAL;
 
-	sprintf(dbf_text, "qssq%4x", cdev->private->schid.sch_no);
-	QDIO_DBF_TEXT0(0, setup, dbf_text);
-
+	DBF_EVENT("get ssqd:%4x", cdev->private->schid.sch_no);
 	return qdio_setup_get_ssqd(NULL, &cdev->private->schid, data);
 }
 EXPORT_SYMBOL_GPL(qdio_get_ssqd_desc);
@@ -1164,14 +1076,9 @@ EXPORT_SYMBOL_GPL(qdio_get_ssqd_desc);
  */
 int qdio_cleanup(struct ccw_device *cdev, int how)
 {
-	struct qdio_irq *irq_ptr;
-	char dbf_text[15];
+	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 	int rc;
 
-	sprintf(dbf_text, "qcln%4x", cdev->private->schid.sch_no);
-	QDIO_DBF_TEXT0(0, setup, dbf_text);
-
-	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)
 		return -ENODEV;
 
@@ -1204,18 +1111,15 @@ static void qdio_shutdown_queues(struct ccw_device *cdev)
  */
 int qdio_shutdown(struct ccw_device *cdev, int how)
 {
-	struct qdio_irq *irq_ptr;
+	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 	int rc;
 	unsigned long flags;
-	char dbf_text[15];
 
-	sprintf(dbf_text, "qshu%4x", cdev->private->schid.sch_no);
-	QDIO_DBF_TEXT0(0, setup, dbf_text);
-
-	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)
 		return -ENODEV;
 
+	DBF_EVENT("qshutdown:%4x", cdev->private->schid.sch_no);
+
 	mutex_lock(&irq_ptr->setup_mutex);
 	/*
 	 * Subchannel was already shot down. We cannot prevent being called
@@ -1239,10 +1143,8 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 		/* default behaviour is halt */
 		rc = ccw_device_halt(cdev, QDIO_DOING_CLEANUP);
 	if (rc) {
-		sprintf(dbf_text, "sher%4x", irq_ptr->schid.sch_no);
-		QDIO_DBF_TEXT0(0, setup, dbf_text);
-		sprintf(dbf_text, "rc=%d", rc);
-		QDIO_DBF_TEXT0(0, setup, dbf_text);
+		DBF_ERROR("%4x SHUTD ERR", irq_ptr->schid.sch_no);
+		DBF_ERROR("rc:%4d", rc);
 		goto no_cleanup;
 	}
 
@@ -1276,17 +1178,18 @@ EXPORT_SYMBOL_GPL(qdio_shutdown);
  */
 int qdio_free(struct ccw_device *cdev)
 {
-	struct qdio_irq *irq_ptr;
-	char dbf_text[15];
-
-	sprintf(dbf_text, "qfre%4x", cdev->private->schid.sch_no);
-	QDIO_DBF_TEXT0(0, setup, dbf_text);
+	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
 
-	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)
 		return -ENODEV;
 
+	DBF_EVENT("qfree:%4x", cdev->private->schid.sch_no);
 	mutex_lock(&irq_ptr->setup_mutex);
+
+	if (irq_ptr->debug_area != NULL) {
+		debug_unregister(irq_ptr->debug_area);
+		irq_ptr->debug_area = NULL;
+	}
 	cdev->private->qdio_data = NULL;
 	mutex_unlock(&irq_ptr->setup_mutex);
 
@@ -1305,10 +1208,6 @@ EXPORT_SYMBOL_GPL(qdio_free);
 int qdio_initialize(struct qdio_initialize *init_data)
 {
 	int rc;
-	char dbf_text[15];
-
-	sprintf(dbf_text, "qini%4x", init_data->cdev->private->schid.sch_no);
-	QDIO_DBF_TEXT0(0, setup, dbf_text);
 
 	rc = qdio_allocate(init_data);
 	if (rc)
@@ -1328,10 +1227,8 @@ EXPORT_SYMBOL_GPL(qdio_initialize);
 int qdio_allocate(struct qdio_initialize *init_data)
 {
 	struct qdio_irq *irq_ptr;
-	char dbf_text[15];
 
-	sprintf(dbf_text, "qalc%4x", init_data->cdev->private->schid.sch_no);
-	QDIO_DBF_TEXT0(0, setup, dbf_text);
+	DBF_EVENT("qallocate:%4x", init_data->cdev->private->schid.sch_no);
 
 	if ((init_data->no_input_qs && !init_data->input_handler) ||
 	    (init_data->no_output_qs && !init_data->output_handler))
@@ -1345,16 +1242,13 @@ int qdio_allocate(struct qdio_initialize *init_data)
 	    (!init_data->output_sbal_addr_array))
 		return -EINVAL;
 
-	qdio_allocate_do_dbf(init_data);
-
 	/* irq_ptr must be in GFP_DMA since it contains ccw1.cda */
 	irq_ptr = (void *) get_zeroed_page(GFP_KERNEL | GFP_DMA);
 	if (!irq_ptr)
 		goto out_err;
-	QDIO_DBF_TEXT0(0, setup, "irq_ptr:");
-	QDIO_DBF_HEX0(0, setup, &irq_ptr, sizeof(void *));
 
 	mutex_init(&irq_ptr->setup_mutex);
+	qdio_allocate_dbf(init_data, irq_ptr);
 
 	/*
 	 * Allocate a page for the chsc calls in qdio_establish.
@@ -1372,9 +1266,6 @@ int qdio_allocate(struct qdio_initialize *init_data)
 		goto out_rel;
 	WARN_ON((unsigned long)irq_ptr->qdr & 0xfff);
 
-	QDIO_DBF_TEXT0(0, setup, "qdr:");
-	QDIO_DBF_HEX0(0, setup, &irq_ptr->qdr, sizeof(void *));
-
 	if (qdio_allocate_qs(irq_ptr, init_data->no_input_qs,
 			     init_data->no_output_qs))
 		goto out_rel;
@@ -1395,14 +1286,12 @@ EXPORT_SYMBOL_GPL(qdio_allocate);
  */
 int qdio_establish(struct qdio_initialize *init_data)
 {
-	char dbf_text[20];
 	struct qdio_irq *irq_ptr;
 	struct ccw_device *cdev = init_data->cdev;
 	unsigned long saveflags;
 	int rc;
 
-	sprintf(dbf_text, "qest%4x", cdev->private->schid.sch_no);
-	QDIO_DBF_TEXT0(0, setup, dbf_text);
+	DBF_EVENT("qestablish:%4x", cdev->private->schid.sch_no);
 
 	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)
@@ -1432,10 +1321,8 @@ int qdio_establish(struct qdio_initialize *init_data)
 
 	rc = ccw_device_start(cdev, &irq_ptr->ccw, QDIO_DOING_ESTABLISH, 0, 0);
 	if (rc) {
-		sprintf(dbf_text, "eq:io%4x", irq_ptr->schid.sch_no);
-		QDIO_DBF_TEXT2(1, setup, dbf_text);
-		sprintf(dbf_text, "eq:rc%4x", rc);
-		QDIO_DBF_TEXT2(1, setup, dbf_text);
+		DBF_ERROR("%4x est IO ERR", irq_ptr->schid.sch_no);
+		DBF_ERROR("rc:%4x", rc);
 	}
 	spin_unlock_irqrestore(get_ccwdev_lock(cdev), saveflags);
 
@@ -1456,10 +1343,8 @@ int qdio_establish(struct qdio_initialize *init_data)
 	}
 
 	qdio_setup_ssqd_info(irq_ptr);
-	sprintf(dbf_text, "qDmmwc%2x", irq_ptr->ssqd_desc.mmwc);
-	QDIO_DBF_TEXT2(0, setup, dbf_text);
-	sprintf(dbf_text, "qib ac%2x", irq_ptr->qib.ac);
-	QDIO_DBF_TEXT2(0, setup, dbf_text);
+	DBF_EVENT("qDmmwc:%2x", irq_ptr->ssqd_desc.mmwc);
+	DBF_EVENT("qib ac:%4x", irq_ptr->qib.ac);
 
 	/* qebsm is now setup if available, initialize buffer states */
 	qdio_init_buf_states(irq_ptr);
@@ -1480,10 +1365,8 @@ int qdio_activate(struct ccw_device *cdev)
 	struct qdio_irq *irq_ptr;
 	int rc;
 	unsigned long saveflags;
-	char dbf_text[20];
 
-	sprintf(dbf_text, "qact%4x", cdev->private->schid.sch_no);
-	QDIO_DBF_TEXT0(0, setup, dbf_text);
+	DBF_EVENT("qactivate:%4x", cdev->private->schid.sch_no);
 
 	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)
@@ -1509,10 +1392,8 @@ int qdio_activate(struct ccw_device *cdev)
 	rc = ccw_device_start(cdev, &irq_ptr->ccw, QDIO_DOING_ACTIVATE,
 			      0, DOIO_DENY_PREFETCH);
 	if (rc) {
-		sprintf(dbf_text, "aq:io%4x", irq_ptr->schid.sch_no);
-		QDIO_DBF_TEXT2(1, setup, dbf_text);
-		sprintf(dbf_text, "aq:rc%4x", rc);
-		QDIO_DBF_TEXT2(1, setup, dbf_text);
+		DBF_ERROR("%4x act IO ERR", irq_ptr->schid.sch_no);
+		DBF_ERROR("rc:%4x", rc);
 	}
 	spin_unlock_irqrestore(get_ccwdev_lock(cdev), saveflags);
 
@@ -1658,7 +1539,7 @@ static void handle_outbound(struct qdio_q *q, unsigned int callflags,
 	if (state != SLSB_CU_OUTPUT_PRIMED)
 		qdio_kick_outbound_q(q);
 	else {
-		QDIO_DBF_TEXT5(0, trace, "fast-req");
+		DBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "fast-req");
 		qdio_perf_stat_inc(&perf_stats.fast_requeue);
 	}
 out:
@@ -1678,12 +1559,6 @@ int do_QDIO(struct ccw_device *cdev, unsigned int callflags,
 	    int q_nr, int bufnr, int count)
 {
 	struct qdio_irq *irq_ptr;
-#ifdef CONFIG_QDIO_DEBUG
-	char dbf_text[20];
-
-	sprintf(dbf_text, "doQD%4x", cdev->private->schid.sch_no);
-	QDIO_DBF_TEXT3(0, trace, dbf_text);
-#endif /* CONFIG_QDIO_DEBUG */
 
 	if ((bufnr > QDIO_MAX_BUFFERS_PER_Q) ||
 	    (count > QDIO_MAX_BUFFERS_PER_Q) ||
@@ -1697,33 +1572,24 @@ int do_QDIO(struct ccw_device *cdev, unsigned int callflags,
 	if (!irq_ptr)
 		return -ENODEV;
 
-#ifdef CONFIG_QDIO_DEBUG
 	if (callflags & QDIO_FLAG_SYNC_INPUT)
-		QDIO_DBF_HEX3(0, trace, &irq_ptr->input_qs[q_nr],
-			      sizeof(void *));
+		DBF_DEV_EVENT(DBF_INFO, irq_ptr, "doQDIO input");
 	else
-		QDIO_DBF_HEX3(0, trace, &irq_ptr->output_qs[q_nr],
-			      sizeof(void *));
-
-	sprintf(dbf_text, "flag%04x", callflags);
-	QDIO_DBF_TEXT3(0, trace, dbf_text);
-	sprintf(dbf_text, "qi%02xct%02x", bufnr, count);
-	QDIO_DBF_TEXT3(0, trace, dbf_text);
-#endif /* CONFIG_QDIO_DEBUG */
+		DBF_DEV_EVENT(DBF_INFO, irq_ptr, "doQDIO output");
+	DBF_DEV_EVENT(DBF_INFO, irq_ptr, "q:%1d flag:%4x", q_nr, callflags);
+	DBF_DEV_EVENT(DBF_INFO, irq_ptr, "buf:%2d cnt:%3d", bufnr, count);
 
 	if (irq_ptr->state != QDIO_IRQ_STATE_ACTIVE)
 		return -EBUSY;
 
 	if (callflags & QDIO_FLAG_SYNC_INPUT)
-		handle_inbound(irq_ptr->input_qs[q_nr],
-			       callflags, bufnr, count);
+		handle_inbound(irq_ptr->input_qs[q_nr], callflags, bufnr,
+			       count);
 	else if (callflags & QDIO_FLAG_SYNC_OUTPUT)
-		handle_outbound(irq_ptr->output_qs[q_nr],
-				callflags, bufnr, count);
-	else {
-		QDIO_DBF_TEXT3(1, trace, "doQD:inv");
+		handle_outbound(irq_ptr->output_qs[q_nr], callflags, bufnr,
+				count);
+	else
 		return -EINVAL;
-	}
 	return 0;
 }
 EXPORT_SYMBOL_GPL(do_QDIO);

commit 9a1ce28aeb7a8b1666eaa9f104c1a2f5a149f9df
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Dec 25 13:38:45 2008 +0100

    [S390] qdio: fix compile warning under 31 bit
    
    The QEBSM instructions are only available for CONFIG_64BIT, they are not
    used under 31 bit. Make compiler happy about the false positive:
    
    drivers/s390/cio/qdio_main.c: In function ?qdio_inbound_q_done?:
    drivers/s390/cio/qdio_main.c:532: warning: ?state? may be used uninitialized in this function
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index a44a8c5b91be..9e6ab41e5a3c 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -529,7 +529,7 @@ int qdio_inbound_q_moved(struct qdio_q *q)
 
 static int qdio_inbound_q_done(struct qdio_q *q)
 {
-	unsigned char state;
+	unsigned char state = 0;
 #ifdef CONFIG_QDIO_DEBUG
 	char dbf_text[15];
 #endif

commit 23589d057ac2da81e456d4a9dcdd9135fd96f493
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Dec 25 13:38:44 2008 +0100

    [S390] qdio: add eqbs/sqbs instruction counters
    
    Add counters for the eqbs and sqbs instructions that indicate how often
    we issued the instructions and how often the instructions returned with
    less buffers than specified.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 7572a0057623..a44a8c5b91be 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -129,6 +129,7 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 	char dbf_text[15];
 
 	BUG_ON(!q->irq_ptr->sch_token);
+	qdio_perf_stat_inc(&perf_stats.debug_eqbs_all);
 
 	if (!q->is_input_q)
 		nr += q->irq_ptr->nr_input_qs;
@@ -139,8 +140,10 @@ static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
 	/* At least one buffer was processed, return and extract the remaining
 	 * buffers later.
 	 */
-	if ((ccq == 96) && (count != tmp_count))
+	if ((ccq == 96) && (count != tmp_count)) {
+		qdio_perf_stat_inc(&perf_stats.debug_eqbs_incomplete);
 		return (count - tmp_count);
+	}
 	if (rc == 1) {
 		QDIO_DBF_TEXT5(1, trace, "eqAGAIN");
 		goto again;
@@ -179,6 +182,7 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 	char dbf_text[15];
 
 	BUG_ON(!q->irq_ptr->sch_token);
+	qdio_perf_stat_inc(&perf_stats.debug_sqbs_all);
 
 	if (!q->is_input_q)
 		nr += q->irq_ptr->nr_input_qs;
@@ -187,6 +191,7 @@ static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
 	rc = qdio_check_ccq(q, ccq);
 	if (rc == 1) {
 		QDIO_DBF_TEXT5(1, trace, "sqAGAIN");
+		qdio_perf_stat_inc(&perf_stats.debug_sqbs_incomplete);
 		goto again;
 	}
 	if (rc < 0) {

commit bbd50e172f75b1d12ef9b1bcf593b51a44199016
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Dec 25 13:38:43 2008 +0100

    [S390] qdio: fix qeth port count detection
    
    qeth needs to get the port count information before
    qdio has allocated a page for the chsc operation.
    Extend qdio_get_ssqd_desc() to store the data in the
    specified structure.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 7c8659151993..7572a0057623 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1129,23 +1129,23 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 /**
  * qdio_get_ssqd_desc - get qdio subchannel description
  * @cdev: ccw device to get description for
+ * @data: where to store the ssqd
  *
- * Returns a pointer to the saved qdio subchannel description,
- * or NULL for not setup qdio devices.
+ * Returns 0 or an error code. The results of the chsc are stored in the
+ * specified structure.
  */
-struct qdio_ssqd_desc *qdio_get_ssqd_desc(struct ccw_device *cdev)
+int qdio_get_ssqd_desc(struct ccw_device *cdev,
+		       struct qdio_ssqd_desc *data)
 {
-	struct qdio_irq *irq_ptr;
 	char dbf_text[15];
 
+	if (!cdev || !cdev->private)
+		return -EINVAL;
+
 	sprintf(dbf_text, "qssq%4x", cdev->private->schid.sch_no);
 	QDIO_DBF_TEXT0(0, setup, dbf_text);
 
-	irq_ptr = cdev->private->qdio_data;
-	if (!irq_ptr)
-		return NULL;
-
-	return &irq_ptr->ssqd_desc;
+	return qdio_setup_get_ssqd(NULL, &cdev->private->schid, data);
 }
 EXPORT_SYMBOL_GPL(qdio_get_ssqd_desc);
 

commit 7c045aa2c8eb731996b0c5c6552356b8946e6894
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Tue Oct 28 11:10:13 2008 +0100

    [S390] qdio: prevent double qdio shutdown in case of I/O errors
    
    In case of I/O errors on a qdio subchannel qdio_shutdown may be
    called twice by the qdio driver and by zfcp. Remove the
    superfluous shutdown from qdio and let the upper layer driver
    handle the error condition.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index a50682d2a0fa..7c8659151993 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1083,7 +1083,6 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 		case -EIO:
 			sprintf(dbf_text, "ierr%4x", irq_ptr->schid.sch_no);
 			QDIO_DBF_TEXT2(1, setup, dbf_text);
-			qdio_int_error(cdev);
 			return;
 		case -ETIMEDOUT:
 			sprintf(dbf_text, "qtoh%4x", irq_ptr->schid.sch_no);

commit 7a0f475513fa573bc8e072021960313da32f0ee3
Author: Klaus-Dieter Wacker <kdwacker@de.ibm.com>
Date:   Fri Oct 10 21:33:18 2008 +0200

    [S390] qdio enhanced SIGA (iqdio) support.
    
    Add support for z10 HiperSockets multiwrite SBALs on output
    queues. This is used on LPAR with EDDP enabled devices.
    
    Signed-off-by: Klaus-Dieter Wacker <kdwacker@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 719066ec0c01..a50682d2a0fa 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -316,6 +316,9 @@ static inline int qdio_do_siga_output(struct qdio_q *q, unsigned int *busy_bit)
 	unsigned int fc = 0;
 	unsigned long schid;
 
+	if (q->u.out.use_enh_siga) {
+		fc = 3;
+	}
 	if (!is_qebsm(q))
 		schid = *((u32 *)&q->irq_ptr->schid);
 	else {
@@ -1449,6 +1452,8 @@ int qdio_establish(struct qdio_initialize *init_data)
 	}
 
 	qdio_setup_ssqd_info(irq_ptr);
+	sprintf(dbf_text, "qDmmwc%2x", irq_ptr->ssqd_desc.mmwc);
+	QDIO_DBF_TEXT2(0, setup, dbf_text);
 	sprintf(dbf_text, "qib ac%2x", irq_ptr->qib.ac);
 	QDIO_DBF_TEXT2(0, setup, dbf_text);
 
@@ -1621,12 +1626,21 @@ static void handle_outbound(struct qdio_q *q, unsigned int callflags,
 		if (multicast_outbound(q))
 			qdio_kick_outbound_q(q);
 		else
-			/*
-			 * One siga-w per buffer required for unicast
-			 * HiperSockets.
-			 */
-			while (count--)
+			if ((q->irq_ptr->ssqd_desc.mmwc > 1) &&
+			    (count > 1) &&
+			    (count <= q->irq_ptr->ssqd_desc.mmwc)) {
+				/* exploit enhanced SIGA */
+				q->u.out.use_enh_siga = 1;
 				qdio_kick_outbound_q(q);
+			} else {
+				/*
+				* One siga-w per buffer required for unicast
+				* HiperSockets.
+				*/
+				q->u.out.use_enh_siga = 0;
+				while (count--)
+					qdio_kick_outbound_q(q);
+			}
 		goto out;
 	}
 

commit 9286b7ed682615c1508210f85d26e4c9a5cbf126
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Fri Oct 10 21:33:13 2008 +0200

    [S390] bus_id ->dev_name() conversions in qdio
    
    Use dev_name() in the new qdio driver.
    
    Signed-off-by: Cornelia Huck <cornelia.huck@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 9307512132fe..719066ec0c01 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -962,7 +962,7 @@ static void qdio_handle_activate_check(struct ccw_device *cdev,
 	char dbf_text[15];
 
 	QDIO_DBF_TEXT2(1, trace, "ick2");
-	sprintf(dbf_text, "%s", cdev->dev.bus_id);
+	sprintf(dbf_text, "%s", dev_name(&cdev->dev));
 	QDIO_DBF_TEXT2(1, trace, dbf_text);
 	QDIO_DBF_HEX2(0, trace, &intparm, sizeof(int));
 	QDIO_DBF_HEX2(0, trace, &dstat, sizeof(int));

commit 4bcb3a37180ee4dffaef8298f373b334a7bedabb
Author: Ursula Braun <ursula.braun@de.ibm.com>
Date:   Fri Oct 10 21:33:04 2008 +0200

    [S390] qdio: speed up multicast traffic on full HiperSocket queue
    
    If an asynchronous HiperSockets queue runs full, no further packet
    can be sent. In this case the next initiative to give transmitted
    skbs back to the stack is triggered only by a 10-seconds qdio timer.
    This timer has been introduced for low multicast traffic scenarios
    to guarantee freeing of skbs in a limited amount of time. For high
    HiperSocket multicast traffic scenarios progress checking on the
    outbound queue should be enforced by tasklet rescheduling.
    
    Signed-off-by: Ursula Braun <ursula.braun@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index e6eabc853422..9307512132fe 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -851,6 +851,12 @@ static void __qdio_outbound_processing(struct qdio_q *q)
 	if (queue_type(q) == QDIO_IQDIO_QFMT && !multicast_outbound(q))
 		return;
 
+	if ((queue_type(q) == QDIO_IQDIO_QFMT) &&
+	    (atomic_read(&q->nr_buf_used)) > QDIO_IQDIO_POLL_LVL) {
+		tasklet_schedule(&q->tasklet);
+		return;
+	}
+
 	if (q->u.out.pci_out_enabled)
 		return;
 

commit 0686e402c365c92396d4c7abfaa24810f9cb77cc
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Aug 21 19:46:35 2008 +0200

    [S390] qdio: remove the module_get & module_put pair
    
    Increasing the qdio reference count for every used subchannel
    is unnecessary since unloading qdio (if build as a module) is
    only possible if other modules that use qdio are unloaded.
    Unloading modules that use qdio in turn requires that these
    modules shut down all qdio subchannels. Therefore the additional
    module_get reference is not needed.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index 444fc7e521d4..e6eabc853422 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1251,7 +1251,6 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 
 	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);
 	mutex_unlock(&irq_ptr->setup_mutex);
-	module_put(THIS_MODULE);
 	if (rc)
 		return rc;
 	return 0;
@@ -1399,9 +1398,6 @@ int qdio_establish(struct qdio_initialize *init_data)
 	if (cdev->private->state != DEV_STATE_ONLINE)
 		return -EINVAL;
 
-	if (!try_module_get(THIS_MODULE))
-		return -EINVAL;
-
 	mutex_lock(&irq_ptr->setup_mutex);
 	qdio_setup_irq(init_data);
 

commit 58eb27cd7f4f1de2932b3e0e39ea54a27e9fef43
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Aug 21 19:46:34 2008 +0200

    [S390] qdio: improve s390 debug feature usage
    
    Improve s390 debug feature usage:
    - log busy bit in dbf
    - increase size of dbf views
    - consistent logging of qdio api calls to setup view
    - print subchannel number so one can associate the interface
      with the dbf data
    - only log events to one view
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index d15648514a0f..444fc7e521d4 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -330,6 +330,7 @@ static int qdio_siga_output(struct qdio_q *q)
 	int cc;
 	u32 busy_bit;
 	u64 start_time = 0;
+	char dbf_text[15];
 
 	QDIO_DBF_TEXT5(0, trace, "sigaout");
 	QDIO_DBF_HEX5(0, trace, &q, sizeof(void *));
@@ -338,6 +339,9 @@ static int qdio_siga_output(struct qdio_q *q)
 again:
 	cc = qdio_do_siga_output(q, &busy_bit);
 	if (queue_type(q) == QDIO_IQDIO_QFMT && cc == 2 && busy_bit) {
+		sprintf(dbf_text, "bb%4x%2x", q->irq_ptr->schid.sch_no, q->nr);
+		QDIO_DBF_TEXT3(0, trace, dbf_text);
+
 		if (!start_time)
 			start_time = get_usecs();
 		else if ((get_usecs() - start_time) < QDIO_BUSY_BIT_PATIENCE)
@@ -748,16 +752,18 @@ static void qdio_kick_outbound_q(struct qdio_q *q)
 	rc = qdio_siga_output(q);
 	switch (rc) {
 	case 0:
-		/* went smooth this time, reset timestamp */
-		q->u.out.timestamp = 0;
-
 		/* TODO: improve error handling for CC=0 case */
 #ifdef CONFIG_QDIO_DEBUG
-		QDIO_DBF_TEXT3(0, trace, "cc2reslv");
-		sprintf(dbf_text, "%4x%2x%2x", q->irq_ptr->schid.sch_no, q->nr,
-			atomic_read(&q->u.out.busy_siga_counter));
-		QDIO_DBF_TEXT3(0, trace, dbf_text);
+		if (q->u.out.timestamp) {
+			QDIO_DBF_TEXT3(0, trace, "cc2reslv");
+			sprintf(dbf_text, "%4x%2x%2x", q->irq_ptr->schid.sch_no,
+				q->nr,
+				atomic_read(&q->u.out.busy_siga_counter));
+			QDIO_DBF_TEXT3(0, trace, dbf_text);
+		}
 #endif /* CONFIG_QDIO_DEBUG */
+		/* went smooth this time, reset timestamp */
+		q->u.out.timestamp = 0;
 		break;
 	/* cc=2 and busy bit */
 	case (2 | QDIO_ERROR_SIGA_BUSY):
@@ -1066,14 +1072,12 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 	if (IS_ERR(irb)) {
 		switch (PTR_ERR(irb)) {
 		case -EIO:
-			sprintf(dbf_text, "ierr%4x",
-				cdev->private->schid.sch_no);
+			sprintf(dbf_text, "ierr%4x", irq_ptr->schid.sch_no);
 			QDIO_DBF_TEXT2(1, setup, dbf_text);
 			qdio_int_error(cdev);
 			return;
 		case -ETIMEDOUT:
-			sprintf(dbf_text, "qtoh%4x",
-				cdev->private->schid.sch_no);
+			sprintf(dbf_text, "qtoh%4x", irq_ptr->schid.sch_no);
 			QDIO_DBF_TEXT2(1, setup, dbf_text);
 			qdio_int_error(cdev);
 			return;
@@ -1124,8 +1128,10 @@ void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
 struct qdio_ssqd_desc *qdio_get_ssqd_desc(struct ccw_device *cdev)
 {
 	struct qdio_irq *irq_ptr;
+	char dbf_text[15];
 
-	QDIO_DBF_TEXT0(0, setup, "getssqd");
+	sprintf(dbf_text, "qssq%4x", cdev->private->schid.sch_no);
+	QDIO_DBF_TEXT0(0, setup, dbf_text);
 
 	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)
@@ -1149,14 +1155,13 @@ int qdio_cleanup(struct ccw_device *cdev, int how)
 	char dbf_text[15];
 	int rc;
 
+	sprintf(dbf_text, "qcln%4x", cdev->private->schid.sch_no);
+	QDIO_DBF_TEXT0(0, setup, dbf_text);
+
 	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)
 		return -ENODEV;
 
-	sprintf(dbf_text, "qcln%4x", irq_ptr->schid.sch_no);
-	QDIO_DBF_TEXT1(0, trace, dbf_text);
-	QDIO_DBF_TEXT0(0, setup, dbf_text);
-
 	rc = qdio_shutdown(cdev, how);
 	if (rc == 0)
 		rc = qdio_free(cdev);
@@ -1191,6 +1196,9 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 	unsigned long flags;
 	char dbf_text[15];
 
+	sprintf(dbf_text, "qshu%4x", cdev->private->schid.sch_no);
+	QDIO_DBF_TEXT0(0, setup, dbf_text);
+
 	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)
 		return -ENODEV;
@@ -1205,10 +1213,6 @@ int qdio_shutdown(struct ccw_device *cdev, int how)
 		return 0;
 	}
 
-	sprintf(dbf_text, "qsqs%4x", irq_ptr->schid.sch_no);
-	QDIO_DBF_TEXT1(0, trace, dbf_text);
-	QDIO_DBF_TEXT0(0, setup, dbf_text);
-
 	tiqdio_remove_input_queues(irq_ptr);
 	qdio_shutdown_queues(cdev);
 	qdio_shutdown_debug_entries(irq_ptr, cdev);
@@ -1263,16 +1267,14 @@ int qdio_free(struct ccw_device *cdev)
 	struct qdio_irq *irq_ptr;
 	char dbf_text[15];
 
+	sprintf(dbf_text, "qfre%4x", cdev->private->schid.sch_no);
+	QDIO_DBF_TEXT0(0, setup, dbf_text);
+
 	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)
 		return -ENODEV;
 
 	mutex_lock(&irq_ptr->setup_mutex);
-
-	sprintf(dbf_text, "qfqs%4x", irq_ptr->schid.sch_no);
-	QDIO_DBF_TEXT1(0, trace, dbf_text);
-	QDIO_DBF_TEXT0(0, setup, dbf_text);
-
 	cdev->private->qdio_data = NULL;
 	mutex_unlock(&irq_ptr->setup_mutex);
 
@@ -1295,7 +1297,6 @@ int qdio_initialize(struct qdio_initialize *init_data)
 
 	sprintf(dbf_text, "qini%4x", init_data->cdev->private->schid.sch_no);
 	QDIO_DBF_TEXT0(0, setup, dbf_text);
-	QDIO_DBF_TEXT0(0, trace, dbf_text);
 
 	rc = qdio_allocate(init_data);
 	if (rc)
@@ -1319,7 +1320,6 @@ int qdio_allocate(struct qdio_initialize *init_data)
 
 	sprintf(dbf_text, "qalc%4x", init_data->cdev->private->schid.sch_no);
 	QDIO_DBF_TEXT0(0, setup, dbf_text);
-	QDIO_DBF_TEXT0(0, trace, dbf_text);
 
 	if ((init_data->no_input_qs && !init_data->input_handler) ||
 	    (init_data->no_output_qs && !init_data->output_handler))
@@ -1389,6 +1389,9 @@ int qdio_establish(struct qdio_initialize *init_data)
 	unsigned long saveflags;
 	int rc;
 
+	sprintf(dbf_text, "qest%4x", cdev->private->schid.sch_no);
+	QDIO_DBF_TEXT0(0, setup, dbf_text);
+
 	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)
 		return -ENODEV;
@@ -1399,10 +1402,6 @@ int qdio_establish(struct qdio_initialize *init_data)
 	if (!try_module_get(THIS_MODULE))
 		return -EINVAL;
 
-	sprintf(dbf_text, "qest%4x", cdev->private->schid.sch_no);
-	QDIO_DBF_TEXT0(0, setup, dbf_text);
-	QDIO_DBF_TEXT0(0, trace, dbf_text);
-
 	mutex_lock(&irq_ptr->setup_mutex);
 	qdio_setup_irq(init_data);
 
@@ -1472,6 +1471,9 @@ int qdio_activate(struct ccw_device *cdev)
 	unsigned long saveflags;
 	char dbf_text[20];
 
+	sprintf(dbf_text, "qact%4x", cdev->private->schid.sch_no);
+	QDIO_DBF_TEXT0(0, setup, dbf_text);
+
 	irq_ptr = cdev->private->qdio_data;
 	if (!irq_ptr)
 		return -ENODEV;
@@ -1485,10 +1487,6 @@ int qdio_activate(struct ccw_device *cdev)
 		goto out;
 	}
 
-	sprintf(dbf_text, "qact%4x", irq_ptr->schid.sch_no);
-	QDIO_DBF_TEXT2(0, setup, dbf_text);
-	QDIO_DBF_TEXT2(0, trace, dbf_text);
-
 	irq_ptr->ccw.cmd_code = irq_ptr->aqueue.cmd;
 	irq_ptr->ccw.flags = CCW_FLAG_SLI;
 	irq_ptr->ccw.count = irq_ptr->aqueue.count;
@@ -1663,7 +1661,7 @@ int do_QDIO(struct ccw_device *cdev, unsigned int callflags,
 #ifdef CONFIG_QDIO_DEBUG
 	char dbf_text[20];
 
-	sprintf(dbf_text, "doQD%04x", cdev->private->schid.sch_no);
+	sprintf(dbf_text, "doQD%4x", cdev->private->schid.sch_no);
 	QDIO_DBF_TEXT3(0, trace, dbf_text);
 #endif /* CONFIG_QDIO_DEBUG */
 

commit 3b8e3004aea95c687e8991583e7b150ec1416ff3
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Fri Aug 1 16:39:17 2008 +0200

    [S390] qdio: make sure qdr is aligned to page size
    
    kzalloc does not guarantee the required alignment of qdr to page size,
    use get_zeroed_page instead.
    
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
index d10c73cc1688..d15648514a0f 100644
--- a/drivers/s390/cio/qdio_main.c
+++ b/drivers/s390/cio/qdio_main.c
@@ -1355,7 +1355,7 @@ int qdio_allocate(struct qdio_initialize *init_data)
 		goto out_rel;
 
 	/* qdr is used in ccw1.cda which is u32 */
-	irq_ptr->qdr = kzalloc(sizeof(struct qdr), GFP_KERNEL | GFP_DMA);
+	irq_ptr->qdr = (struct qdr *) get_zeroed_page(GFP_KERNEL | GFP_DMA);
 	if (!irq_ptr->qdr)
 		goto out_rel;
 	WARN_ON((unsigned long)irq_ptr->qdr & 0xfff);

commit 779e6e1c724d30e0fd1baca78b852e41e3a23c1d
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Thu Jul 17 17:16:48 2008 +0200

    [S390] qdio: new qdio driver.
    
    List of major changes:
    - split qdio driver into several files
    - seperation of thin interrupt code
    - improved handling for multiple thin interrupt devices
    - inbound and outbound processing now always runs in tasklet context
    - significant less tasklet schedules per interrupt needed
    - merged qebsm with non-qebsm handling
    - cleanup qdio interface and added kerneldoc
    - coding style
    
    Reviewed-by: Cornelia Huck <cornelia.huck@de.ibm.com>
    Reviewed-by: Utz Bacher <utz.bacher@de.ibm.com>
    Reviewed-by: Ursula Braun <braunu@de.ibm.com>
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/drivers/s390/cio/qdio_main.c b/drivers/s390/cio/qdio_main.c
new file mode 100644
index 000000000000..d10c73cc1688
--- /dev/null
+++ b/drivers/s390/cio/qdio_main.c
@@ -0,0 +1,1755 @@
+/*
+ * linux/drivers/s390/cio/qdio_main.c
+ *
+ * Linux for s390 qdio support, buffer handling, qdio API and module support.
+ *
+ * Copyright 2000,2008 IBM Corp.
+ * Author(s): Utz Bacher <utz.bacher@de.ibm.com>
+ *	      Jan Glauber <jang@linux.vnet.ibm.com>
+ * 2.6 cio integration by Cornelia Huck <cornelia.huck@de.ibm.com>
+ */
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/timer.h>
+#include <linux/delay.h>
+#include <asm/atomic.h>
+#include <asm/debug.h>
+#include <asm/qdio.h>
+
+#include "cio.h"
+#include "css.h"
+#include "device.h"
+#include "qdio.h"
+#include "qdio_debug.h"
+#include "qdio_perf.h"
+
+MODULE_AUTHOR("Utz Bacher <utz.bacher@de.ibm.com>,"\
+	"Jan Glauber <jang@linux.vnet.ibm.com>");
+MODULE_DESCRIPTION("QDIO base support");
+MODULE_LICENSE("GPL");
+
+static inline int do_siga_sync(struct subchannel_id schid,
+			       unsigned int out_mask, unsigned int in_mask)
+{
+	register unsigned long __fc asm ("0") = 2;
+	register struct subchannel_id __schid asm ("1") = schid;
+	register unsigned long out asm ("2") = out_mask;
+	register unsigned long in asm ("3") = in_mask;
+	int cc;
+
+	asm volatile(
+		"	siga	0\n"
+		"	ipm	%0\n"
+		"	srl	%0,28\n"
+		: "=d" (cc)
+		: "d" (__fc), "d" (__schid), "d" (out), "d" (in) : "cc");
+	return cc;
+}
+
+static inline int do_siga_input(struct subchannel_id schid, unsigned int mask)
+{
+	register unsigned long __fc asm ("0") = 1;
+	register struct subchannel_id __schid asm ("1") = schid;
+	register unsigned long __mask asm ("2") = mask;
+	int cc;
+
+	asm volatile(
+		"	siga	0\n"
+		"	ipm	%0\n"
+		"	srl	%0,28\n"
+		: "=d" (cc)
+		: "d" (__fc), "d" (__schid), "d" (__mask) : "cc", "memory");
+	return cc;
+}
+
+/**
+ * do_siga_output - perform SIGA-w/wt function
+ * @schid: subchannel id or in case of QEBSM the subchannel token
+ * @mask: which output queues to process
+ * @bb: busy bit indicator, set only if SIGA-w/wt could not access a buffer
+ * @fc: function code to perform
+ *
+ * Returns cc or QDIO_ERROR_SIGA_ACCESS_EXCEPTION.
+ * Note: For IQDC unicast queues only the highest priority queue is processed.
+ */
+static inline int do_siga_output(unsigned long schid, unsigned long mask,
+				 u32 *bb, unsigned int fc)
+{
+	register unsigned long __fc asm("0") = fc;
+	register unsigned long __schid asm("1") = schid;
+	register unsigned long __mask asm("2") = mask;
+	int cc = QDIO_ERROR_SIGA_ACCESS_EXCEPTION;
+
+	asm volatile(
+		"	siga	0\n"
+		"0:	ipm	%0\n"
+		"	srl	%0,28\n"
+		"1:\n"
+		EX_TABLE(0b, 1b)
+		: "+d" (cc), "+d" (__fc), "+d" (__schid), "+d" (__mask)
+		: : "cc", "memory");
+	*bb = ((unsigned int) __fc) >> 31;
+	return cc;
+}
+
+static inline int qdio_check_ccq(struct qdio_q *q, unsigned int ccq)
+{
+	char dbf_text[15];
+
+	/* all done or next buffer state different */
+	if (ccq == 0 || ccq == 32)
+		return 0;
+	/* not all buffers processed */
+	if (ccq == 96 || ccq == 97)
+		return 1;
+	/* notify devices immediately */
+	sprintf(dbf_text, "%d", ccq);
+	QDIO_DBF_TEXT2(1, trace, dbf_text);
+	return -EIO;
+}
+
+/**
+ * qdio_do_eqbs - extract buffer states for QEBSM
+ * @q: queue to manipulate
+ * @state: state of the extracted buffers
+ * @start: buffer number to start at
+ * @count: count of buffers to examine
+ *
+ * Returns the number of successfull extracted equal buffer states.
+ * Stops processing if a state is different from the last buffers state.
+ */
+static int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,
+			int start, int count)
+{
+	unsigned int ccq = 0;
+	int tmp_count = count, tmp_start = start;
+	int nr = q->nr;
+	int rc;
+	char dbf_text[15];
+
+	BUG_ON(!q->irq_ptr->sch_token);
+
+	if (!q->is_input_q)
+		nr += q->irq_ptr->nr_input_qs;
+again:
+	ccq = do_eqbs(q->irq_ptr->sch_token, state, nr, &tmp_start, &tmp_count);
+	rc = qdio_check_ccq(q, ccq);
+
+	/* At least one buffer was processed, return and extract the remaining
+	 * buffers later.
+	 */
+	if ((ccq == 96) && (count != tmp_count))
+		return (count - tmp_count);
+	if (rc == 1) {
+		QDIO_DBF_TEXT5(1, trace, "eqAGAIN");
+		goto again;
+	}
+
+	if (rc < 0) {
+		QDIO_DBF_TEXT2(1, trace, "eqberr");
+		sprintf(dbf_text, "%2x,%2x,%d,%d", count, tmp_count, ccq, nr);
+		QDIO_DBF_TEXT2(1, trace, dbf_text);
+		q->handler(q->irq_ptr->cdev,
+			   QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
+			   0, -1, -1, q->irq_ptr->int_parm);
+		return 0;
+	}
+	return count - tmp_count;
+}
+
+/**
+ * qdio_do_sqbs - set buffer states for QEBSM
+ * @q: queue to manipulate
+ * @state: new state of the buffers
+ * @start: first buffer number to change
+ * @count: how many buffers to change
+ *
+ * Returns the number of successfully changed buffers.
+ * Does retrying until the specified count of buffer states is set or an
+ * error occurs.
+ */
+static int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,
+			int count)
+{
+	unsigned int ccq = 0;
+	int tmp_count = count, tmp_start = start;
+	int nr = q->nr;
+	int rc;
+	char dbf_text[15];
+
+	BUG_ON(!q->irq_ptr->sch_token);
+
+	if (!q->is_input_q)
+		nr += q->irq_ptr->nr_input_qs;
+again:
+	ccq = do_sqbs(q->irq_ptr->sch_token, state, nr, &tmp_start, &tmp_count);
+	rc = qdio_check_ccq(q, ccq);
+	if (rc == 1) {
+		QDIO_DBF_TEXT5(1, trace, "sqAGAIN");
+		goto again;
+	}
+	if (rc < 0) {
+		QDIO_DBF_TEXT3(1, trace, "sqberr");
+		sprintf(dbf_text, "%2x,%2x", count, tmp_count);
+		QDIO_DBF_TEXT3(1, trace, dbf_text);
+		sprintf(dbf_text, "%d,%d", ccq, nr);
+		QDIO_DBF_TEXT3(1, trace, dbf_text);
+
+		q->handler(q->irq_ptr->cdev,
+			   QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
+			   0, -1, -1, q->irq_ptr->int_parm);
+		return 0;
+	}
+	WARN_ON(tmp_count);
+	return count - tmp_count;
+}
+
+/* returns number of examined buffers and their common state in *state */
+static inline int get_buf_states(struct qdio_q *q, unsigned int bufnr,
+				 unsigned char *state, unsigned int count)
+{
+	unsigned char __state = 0;
+	int i;
+
+	BUG_ON(bufnr > QDIO_MAX_BUFFERS_MASK);
+	BUG_ON(count > QDIO_MAX_BUFFERS_PER_Q);
+
+	if (is_qebsm(q))
+		return qdio_do_eqbs(q, state, bufnr, count);
+
+	for (i = 0; i < count; i++) {
+		if (!__state)
+			__state = q->slsb.val[bufnr];
+		else if (q->slsb.val[bufnr] != __state)
+			break;
+		bufnr = next_buf(bufnr);
+	}
+	*state = __state;
+	return i;
+}
+
+inline int get_buf_state(struct qdio_q *q, unsigned int bufnr,
+		  unsigned char *state)
+{
+	return get_buf_states(q, bufnr, state, 1);
+}
+
+/* wrap-around safe setting of slsb states, returns number of changed buffers */
+static inline int set_buf_states(struct qdio_q *q, int bufnr,
+				 unsigned char state, int count)
+{
+	int i;
+
+	BUG_ON(bufnr > QDIO_MAX_BUFFERS_MASK);
+	BUG_ON(count > QDIO_MAX_BUFFERS_PER_Q);
+
+	if (is_qebsm(q))
+		return qdio_do_sqbs(q, state, bufnr, count);
+
+	for (i = 0; i < count; i++) {
+		xchg(&q->slsb.val[bufnr], state);
+		bufnr = next_buf(bufnr);
+	}
+	return count;
+}
+
+static inline int set_buf_state(struct qdio_q *q, int bufnr,
+				unsigned char state)
+{
+	return set_buf_states(q, bufnr, state, 1);
+}
+
+/* set slsb states to initial state */
+void qdio_init_buf_states(struct qdio_irq *irq_ptr)
+{
+	struct qdio_q *q;
+	int i;
+
+	for_each_input_queue(irq_ptr, q, i)
+		set_buf_states(q, 0, SLSB_P_INPUT_NOT_INIT,
+			       QDIO_MAX_BUFFERS_PER_Q);
+	for_each_output_queue(irq_ptr, q, i)
+		set_buf_states(q, 0, SLSB_P_OUTPUT_NOT_INIT,
+			       QDIO_MAX_BUFFERS_PER_Q);
+}
+
+static int qdio_siga_sync(struct qdio_q *q, unsigned int output,
+			  unsigned int input)
+{
+	int cc;
+
+	if (!need_siga_sync(q))
+		return 0;
+
+	qdio_perf_stat_inc(&perf_stats.siga_sync);
+
+	cc = do_siga_sync(q->irq_ptr->schid, output, input);
+	if (cc) {
+		QDIO_DBF_TEXT4(0, trace, "sigasync");
+		QDIO_DBF_HEX4(0, trace, &q, sizeof(void *));
+		QDIO_DBF_HEX3(0, trace, &cc, sizeof(int *));
+	}
+	return cc;
+}
+
+inline int qdio_siga_sync_q(struct qdio_q *q)
+{
+	if (q->is_input_q)
+		return qdio_siga_sync(q, 0, q->mask);
+	else
+		return qdio_siga_sync(q, q->mask, 0);
+}
+
+static inline int qdio_siga_sync_out(struct qdio_q *q)
+{
+	return qdio_siga_sync(q, ~0U, 0);
+}
+
+static inline int qdio_siga_sync_all(struct qdio_q *q)
+{
+	return qdio_siga_sync(q, ~0U, ~0U);
+}
+
+static inline int qdio_do_siga_output(struct qdio_q *q, unsigned int *busy_bit)
+{
+	unsigned int fc = 0;
+	unsigned long schid;
+
+	if (!is_qebsm(q))
+		schid = *((u32 *)&q->irq_ptr->schid);
+	else {
+		schid = q->irq_ptr->sch_token;
+		fc |= 0x80;
+	}
+	return do_siga_output(schid, q->mask, busy_bit, fc);
+}
+
+static int qdio_siga_output(struct qdio_q *q)
+{
+	int cc;
+	u32 busy_bit;
+	u64 start_time = 0;
+
+	QDIO_DBF_TEXT5(0, trace, "sigaout");
+	QDIO_DBF_HEX5(0, trace, &q, sizeof(void *));
+
+	qdio_perf_stat_inc(&perf_stats.siga_out);
+again:
+	cc = qdio_do_siga_output(q, &busy_bit);
+	if (queue_type(q) == QDIO_IQDIO_QFMT && cc == 2 && busy_bit) {
+		if (!start_time)
+			start_time = get_usecs();
+		else if ((get_usecs() - start_time) < QDIO_BUSY_BIT_PATIENCE)
+			goto again;
+	}
+
+	if (cc == 2 && busy_bit)
+		cc |= QDIO_ERROR_SIGA_BUSY;
+	if (cc)
+		QDIO_DBF_HEX3(0, trace, &cc, sizeof(int *));
+	return cc;
+}
+
+static inline int qdio_siga_input(struct qdio_q *q)
+{
+	int cc;
+
+	QDIO_DBF_TEXT4(0, trace, "sigain");
+	QDIO_DBF_HEX4(0, trace, &q, sizeof(void *));
+
+	qdio_perf_stat_inc(&perf_stats.siga_in);
+
+	cc = do_siga_input(q->irq_ptr->schid, q->mask);
+	if (cc)
+		QDIO_DBF_HEX3(0, trace, &cc, sizeof(int *));
+	return cc;
+}
+
+/* called from thinint inbound handler */
+void qdio_sync_after_thinint(struct qdio_q *q)
+{
+	if (pci_out_supported(q)) {
+		if (need_siga_sync_thinint(q))
+			qdio_siga_sync_all(q);
+		else if (need_siga_sync_out_thinint(q))
+			qdio_siga_sync_out(q);
+	} else
+		qdio_siga_sync_q(q);
+}
+
+inline void qdio_stop_polling(struct qdio_q *q)
+{
+	spin_lock_bh(&q->u.in.lock);
+	if (!q->u.in.polling) {
+		spin_unlock_bh(&q->u.in.lock);
+		return;
+	}
+	q->u.in.polling = 0;
+	qdio_perf_stat_inc(&perf_stats.debug_stop_polling);
+
+	/* show the card that we are not polling anymore */
+	set_buf_state(q, q->last_move_ftc, SLSB_P_INPUT_NOT_INIT);
+	spin_unlock_bh(&q->u.in.lock);
+}
+
+static void announce_buffer_error(struct qdio_q *q)
+{
+	char dbf_text[15];
+
+	if (q->is_input_q)
+		QDIO_DBF_TEXT3(1, trace, "inperr");
+	else
+		QDIO_DBF_TEXT3(0, trace, "outperr");
+
+	sprintf(dbf_text, "%x-%x-%x", q->first_to_check,
+		q->sbal[q->first_to_check]->element[14].flags,
+		q->sbal[q->first_to_check]->element[15].flags);
+	QDIO_DBF_TEXT3(1, trace, dbf_text);
+	QDIO_DBF_HEX2(1, trace, q->sbal[q->first_to_check], 256);
+
+	q->qdio_error = QDIO_ERROR_SLSB_STATE;
+}
+
+static int get_inbound_buffer_frontier(struct qdio_q *q)
+{
+	int count, stop;
+	unsigned char state;
+
+	/*
+	 * If we still poll don't update last_move_ftc, keep the
+	 * previously ACK buffer there.
+	 */
+	if (!q->u.in.polling)
+		q->last_move_ftc = q->first_to_check;
+
+	/*
+	 * Don't check 128 buffers, as otherwise qdio_inbound_q_moved
+	 * would return 0.
+	 */
+	count = min(atomic_read(&q->nr_buf_used), QDIO_MAX_BUFFERS_MASK);
+	stop = add_buf(q->first_to_check, count);
+
+	/*
+	 * No siga sync here, as a PCI or we after a thin interrupt
+	 * will sync the queues.
+	 */
+
+	/* need to set count to 1 for non-qebsm */
+	if (!is_qebsm(q))
+		count = 1;
+
+check_next:
+	if (q->first_to_check == stop)
+		goto out;
+
+	count = get_buf_states(q, q->first_to_check, &state, count);
+	if (!count)
+		goto out;
+
+	switch (state) {
+	case SLSB_P_INPUT_PRIMED:
+		QDIO_DBF_TEXT5(0, trace, "inptprim");
+
+		/*
+		 * Only ACK the first buffer. The ACK will be removed in
+		 * qdio_stop_polling.
+		 */
+		if (q->u.in.polling)
+			state = SLSB_P_INPUT_NOT_INIT;
+		else {
+			q->u.in.polling = 1;
+			state = SLSB_P_INPUT_ACK;
+		}
+		set_buf_state(q, q->first_to_check, state);
+
+		/*
+		 * Need to change all PRIMED buffers to NOT_INIT, otherwise
+		 * we're loosing initiative in the thinint code.
+		 */
+		if (count > 1)
+			set_buf_states(q, next_buf(q->first_to_check),
+				       SLSB_P_INPUT_NOT_INIT, count - 1);
+
+		/*
+		 * No siga-sync needed for non-qebsm here, as the inbound queue
+		 * will be synced on the next siga-r, resp.
+		 * tiqdio_is_inbound_q_done will do the siga-sync.
+		 */
+		q->first_to_check = add_buf(q->first_to_check, count);
+		atomic_sub(count, &q->nr_buf_used);
+		goto check_next;
+	case SLSB_P_INPUT_ERROR:
+		announce_buffer_error(q);
+		/* process the buffer, the upper layer will take care of it */
+		q->first_to_check = add_buf(q->first_to_check, count);
+		atomic_sub(count, &q->nr_buf_used);
+		break;
+	case SLSB_CU_INPUT_EMPTY:
+	case SLSB_P_INPUT_NOT_INIT:
+	case SLSB_P_INPUT_ACK:
+		QDIO_DBF_TEXT5(0, trace, "inpnipro");
+		break;
+	default:
+		BUG();
+	}
+out:
+	QDIO_DBF_HEX4(0, trace, &q->first_to_check, sizeof(int));
+	return q->first_to_check;
+}
+
+int qdio_inbound_q_moved(struct qdio_q *q)
+{
+	int bufnr;
+
+	bufnr = get_inbound_buffer_frontier(q);
+
+	if ((bufnr != q->last_move_ftc) || q->qdio_error) {
+		if (!need_siga_sync(q) && !pci_out_supported(q))
+			q->u.in.timestamp = get_usecs();
+
+		QDIO_DBF_TEXT4(0, trace, "inhasmvd");
+		QDIO_DBF_HEX4(0, trace, &q, sizeof(void *));
+		return 1;
+	} else
+		return 0;
+}
+
+static int qdio_inbound_q_done(struct qdio_q *q)
+{
+	unsigned char state;
+#ifdef CONFIG_QDIO_DEBUG
+	char dbf_text[15];
+#endif
+
+	if (!atomic_read(&q->nr_buf_used))
+		return 1;
+
+	/*
+	 * We need that one for synchronization with the adapter, as it
+	 * does a kind of PCI avoidance.
+	 */
+	qdio_siga_sync_q(q);
+
+	get_buf_state(q, q->first_to_check, &state);
+	if (state == SLSB_P_INPUT_PRIMED)
+		/* we got something to do */
+		return 0;
+
+	/* on VM, we don't poll, so the q is always done here */
+	if (need_siga_sync(q) || pci_out_supported(q))
+		return 1;
+
+	/*
+	 * At this point we know, that inbound first_to_check
+	 * has (probably) not moved (see qdio_inbound_processing).
+	 */
+	if (get_usecs() > q->u.in.timestamp + QDIO_INPUT_THRESHOLD) {
+#ifdef CONFIG_QDIO_DEBUG
+		QDIO_DBF_TEXT4(0, trace, "inqisdon");
+		QDIO_DBF_HEX4(0, trace, &q, sizeof(void *));
+		sprintf(dbf_text, "pf%02x", q->first_to_check);
+		QDIO_DBF_TEXT4(0, trace, dbf_text);
+#endif /* CONFIG_QDIO_DEBUG */
+		return 1;
+	} else {
+#ifdef CONFIG_QDIO_DEBUG
+		QDIO_DBF_TEXT4(0, trace, "inqisntd");
+		QDIO_DBF_HEX4(0, trace, &q, sizeof(void *));
+		sprintf(dbf_text, "pf%02x", q->first_to_check);
+		QDIO_DBF_TEXT4(0, trace, dbf_text);
+#endif /* CONFIG_QDIO_DEBUG */
+		return 0;
+	}
+}
+
+void qdio_kick_inbound_handler(struct qdio_q *q)
+{
+	int count, start, end;
+#ifdef CONFIG_QDIO_DEBUG
+	char dbf_text[15];
+#endif
+
+	qdio_perf_stat_inc(&perf_stats.inbound_handler);
+
+	start = q->first_to_kick;
+	end = q->first_to_check;
+	if (end >= start)
+		count = end - start;
+	else
+		count = end + QDIO_MAX_BUFFERS_PER_Q - start;
+
+#ifdef CONFIG_QDIO_DEBUG
+	sprintf(dbf_text, "s=%2xc=%2x", start, count);
+	QDIO_DBF_TEXT4(0, trace, dbf_text);
+#endif /* CONFIG_QDIO_DEBUG */
+
+	if (unlikely(q->irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))
+		return;
+
+	q->handler(q->irq_ptr->cdev, q->qdio_error, q->nr,
+		   start, count, q->irq_ptr->int_parm);
+
+	/* for the next time */
+	q->first_to_kick = q->first_to_check;
+	q->qdio_error = 0;
+}
+
+static void __qdio_inbound_processing(struct qdio_q *q)
+{
+	qdio_perf_stat_inc(&perf_stats.tasklet_inbound);
+again:
+	if (!qdio_inbound_q_moved(q))
+		return;
+
+	qdio_kick_inbound_handler(q);
+
+	if (!qdio_inbound_q_done(q))
+		/* means poll time is not yet over */
+		goto again;
+
+	qdio_stop_polling(q);
+	/*
+	 * We need to check again to not lose initiative after
+	 * resetting the ACK state.
+	 */
+	if (!qdio_inbound_q_done(q))
+		goto again;
+}
+
+/* inbound tasklet */
+void qdio_inbound_processing(unsigned long data)
+{
+	struct qdio_q *q = (struct qdio_q *)data;
+	__qdio_inbound_processing(q);
+}
+
+static int get_outbound_buffer_frontier(struct qdio_q *q)
+{
+	int count, stop;
+	unsigned char state;
+
+	if (((queue_type(q) != QDIO_IQDIO_QFMT) && !pci_out_supported(q)) ||
+	    (queue_type(q) == QDIO_IQDIO_QFMT && multicast_outbound(q)))
+		qdio_siga_sync_q(q);
+
+	/*
+	 * Don't check 128 buffers, as otherwise qdio_inbound_q_moved
+	 * would return 0.
+	 */
+	count = min(atomic_read(&q->nr_buf_used), QDIO_MAX_BUFFERS_MASK);
+	stop = add_buf(q->first_to_check, count);
+
+	/* need to set count to 1 for non-qebsm */
+	if (!is_qebsm(q))
+		count = 1;
+
+check_next:
+	if (q->first_to_check == stop)
+		return q->first_to_check;
+
+	count = get_buf_states(q, q->first_to_check, &state, count);
+	if (!count)
+		return q->first_to_check;
+
+	switch (state) {
+	case SLSB_P_OUTPUT_EMPTY:
+		/* the adapter got it */
+		QDIO_DBF_TEXT5(0, trace, "outpempt");
+
+		atomic_sub(count, &q->nr_buf_used);
+		q->first_to_check = add_buf(q->first_to_check, count);
+		/*
+		 * We fetch all buffer states at once. get_buf_states may
+		 * return count < stop. For QEBSM we do not loop.
+		 */
+		if (is_qebsm(q))
+			break;
+		goto check_next;
+	case SLSB_P_OUTPUT_ERROR:
+		announce_buffer_error(q);
+		/* process the buffer, the upper layer will take care of it */
+		q->first_to_check = add_buf(q->first_to_check, count);
+		atomic_sub(count, &q->nr_buf_used);
+		break;
+	case SLSB_CU_OUTPUT_PRIMED:
+		/* the adapter has not fetched the output yet */
+		QDIO_DBF_TEXT5(0, trace, "outpprim");
+		break;
+	case SLSB_P_OUTPUT_NOT_INIT:
+	case SLSB_P_OUTPUT_HALTED:
+		break;
+	default:
+		BUG();
+	}
+	return q->first_to_check;
+}
+
+/* all buffers processed? */
+static inline int qdio_outbound_q_done(struct qdio_q *q)
+{
+	return atomic_read(&q->nr_buf_used) == 0;
+}
+
+static inline int qdio_outbound_q_moved(struct qdio_q *q)
+{
+	int bufnr;
+
+	bufnr = get_outbound_buffer_frontier(q);
+
+	if ((bufnr != q->last_move_ftc) || q->qdio_error) {
+		q->last_move_ftc = bufnr;
+		QDIO_DBF_TEXT4(0, trace, "oqhasmvd");
+		QDIO_DBF_HEX4(0, trace, &q, sizeof(void *));
+		return 1;
+	} else
+		return 0;
+}
+
+/*
+ * VM could present us cc=2 and busy bit set on SIGA-write
+ * during reconfiguration of their Guest LAN (only in iqdio mode,
+ * otherwise qdio is asynchronous and cc=2 and busy bit there will take
+ * the queues down immediately).
+ *
+ * Therefore qdio_siga_output will try for a short time constantly,
+ * if such a condition occurs. If it doesn't change, it will
+ * increase the busy_siga_counter and save the timestamp, and
+ * schedule the queue for later processing. qdio_outbound_processing
+ * will check out the counter. If non-zero, it will call qdio_kick_outbound_q
+ * as often as the value of the counter. This will attempt further SIGA
+ * instructions. For each successful SIGA, the counter is
+ * decreased, for failing SIGAs the counter remains the same, after
+ * all. After some time of no movement, qdio_kick_outbound_q will
+ * finally fail and reflect corresponding error codes to call
+ * the upper layer module and have it take the queues down.
+ *
+ * Note that this is a change from the original HiperSockets design
+ * (saying cc=2 and busy bit means take the queues down), but in
+ * these days Guest LAN didn't exist... excessive cc=2 with busy bit
+ * conditions will still take the queues down, but the threshold is
+ * higher due to the Guest LAN environment.
+ *
+ * Called from outbound tasklet and do_QDIO handler.
+ */
+static void qdio_kick_outbound_q(struct qdio_q *q)
+{
+	int rc;
+#ifdef CONFIG_QDIO_DEBUG
+	char dbf_text[15];
+
+	QDIO_DBF_TEXT5(0, trace, "kickoutq");
+	QDIO_DBF_HEX5(0, trace, &q, sizeof(void *));
+#endif /* CONFIG_QDIO_DEBUG */
+
+	if (!need_siga_out(q))
+		return;
+
+	rc = qdio_siga_output(q);
+	switch (rc) {
+	case 0:
+		/* went smooth this time, reset timestamp */
+		q->u.out.timestamp = 0;
+
+		/* TODO: improve error handling for CC=0 case */
+#ifdef CONFIG_QDIO_DEBUG
+		QDIO_DBF_TEXT3(0, trace, "cc2reslv");
+		sprintf(dbf_text, "%4x%2x%2x", q->irq_ptr->schid.sch_no, q->nr,
+			atomic_read(&q->u.out.busy_siga_counter));
+		QDIO_DBF_TEXT3(0, trace, dbf_text);
+#endif /* CONFIG_QDIO_DEBUG */
+		break;
+	/* cc=2 and busy bit */
+	case (2 | QDIO_ERROR_SIGA_BUSY):
+		atomic_inc(&q->u.out.busy_siga_counter);
+
+		/* if the last siga was successful, save timestamp here */
+		if (!q->u.out.timestamp)
+			q->u.out.timestamp = get_usecs();
+
+		/* if we're in time, don't touch qdio_error */
+		if (get_usecs() - q->u.out.timestamp < QDIO_BUSY_BIT_GIVE_UP) {
+			tasklet_schedule(&q->tasklet);
+			break;
+		}
+		QDIO_DBF_TEXT2(0, trace, "cc2REPRT");
+#ifdef CONFIG_QDIO_DEBUG
+		sprintf(dbf_text, "%4x%2x%2x", q->irq_ptr->schid.sch_no, q->nr,
+			atomic_read(&q->u.out.busy_siga_counter));
+		QDIO_DBF_TEXT3(0, trace, dbf_text);
+#endif /* CONFIG_QDIO_DEBUG */
+	default:
+		/* for plain cc=1, 2 or 3 */
+		q->qdio_error = rc;
+	}
+}
+
+static void qdio_kick_outbound_handler(struct qdio_q *q)
+{
+	int start, end, count;
+#ifdef CONFIG_QDIO_DEBUG
+	char dbf_text[15];
+#endif
+
+	start = q->first_to_kick;
+	end = q->last_move_ftc;
+	if (end >= start)
+		count = end - start;
+	else
+		count = end + QDIO_MAX_BUFFERS_PER_Q - start;
+
+#ifdef CONFIG_QDIO_DEBUG
+	QDIO_DBF_TEXT4(0, trace, "kickouth");
+	QDIO_DBF_HEX4(0, trace, &q, sizeof(void *));
+
+	sprintf(dbf_text, "s=%2xc=%2x", start, count);
+	QDIO_DBF_TEXT4(0, trace, dbf_text);
+#endif /* CONFIG_QDIO_DEBUG */
+
+	if (unlikely(q->irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))
+		return;
+
+	q->handler(q->irq_ptr->cdev, q->qdio_error, q->nr, start, count,
+		   q->irq_ptr->int_parm);
+
+	/* for the next time: */
+	q->first_to_kick = q->last_move_ftc;
+	q->qdio_error = 0;
+}
+
+static void __qdio_outbound_processing(struct qdio_q *q)
+{
+	int siga_attempts;
+
+	qdio_perf_stat_inc(&perf_stats.tasklet_outbound);
+
+	/* see comment in qdio_kick_outbound_q */
+	siga_attempts = atomic_read(&q->u.out.busy_siga_counter);
+	while (siga_attempts--) {
+		atomic_dec(&q->u.out.busy_siga_counter);
+		qdio_kick_outbound_q(q);
+	}
+
+	BUG_ON(atomic_read(&q->nr_buf_used) < 0);
+
+	if (qdio_outbound_q_moved(q))
+		qdio_kick_outbound_handler(q);
+
+	if (queue_type(q) == QDIO_ZFCP_QFMT) {
+		if (!pci_out_supported(q) && !qdio_outbound_q_done(q))
+			tasklet_schedule(&q->tasklet);
+		return;
+	}
+
+	/* bail out for HiperSockets unicast queues */
+	if (queue_type(q) == QDIO_IQDIO_QFMT && !multicast_outbound(q))
+		return;
+
+	if (q->u.out.pci_out_enabled)
+		return;
+
+	/*
+	 * Now we know that queue type is either qeth without pci enabled
+	 * or HiperSockets multicast. Make sure buffer switch from PRIMED to
+	 * EMPTY is noticed and outbound_handler is called after some time.
+	 */
+	if (qdio_outbound_q_done(q))
+		del_timer(&q->u.out.timer);
+	else {
+		if (!timer_pending(&q->u.out.timer)) {
+			mod_timer(&q->u.out.timer, jiffies + 10 * HZ);
+			qdio_perf_stat_inc(&perf_stats.debug_tl_out_timer);
+		}
+	}
+}
+
+/* outbound tasklet */
+void qdio_outbound_processing(unsigned long data)
+{
+	struct qdio_q *q = (struct qdio_q *)data;
+	__qdio_outbound_processing(q);
+}
+
+void qdio_outbound_timer(unsigned long data)
+{
+	struct qdio_q *q = (struct qdio_q *)data;
+	tasklet_schedule(&q->tasklet);
+}
+
+/* called from thinint inbound tasklet */
+void qdio_check_outbound_after_thinint(struct qdio_q *q)
+{
+	struct qdio_q *out;
+	int i;
+
+	if (!pci_out_supported(q))
+		return;
+
+	for_each_output_queue(q->irq_ptr, out, i)
+		if (!qdio_outbound_q_done(out))
+			tasklet_schedule(&out->tasklet);
+}
+
+static inline void qdio_set_state(struct qdio_irq *irq_ptr,
+				  enum qdio_irq_states state)
+{
+#ifdef CONFIG_QDIO_DEBUG
+	char dbf_text[15];
+
+	QDIO_DBF_TEXT5(0, trace, "newstate");
+	sprintf(dbf_text, "%4x%4x", irq_ptr->schid.sch_no, state);
+	QDIO_DBF_TEXT5(0, trace, dbf_text);
+#endif /* CONFIG_QDIO_DEBUG */
+
+	irq_ptr->state = state;
+	mb();
+}
+
+static void qdio_irq_check_sense(struct subchannel_id schid, struct irb *irb)
+{
+	char dbf_text[15];
+
+	if (irb->esw.esw0.erw.cons) {
+		sprintf(dbf_text, "sens%4x", schid.sch_no);
+		QDIO_DBF_TEXT2(1, trace, dbf_text);
+		QDIO_DBF_HEX0(0, trace, irb, 64);
+		QDIO_DBF_HEX0(0, trace, irb->ecw, 64);
+	}
+}
+
+/* PCI interrupt handler */
+static void qdio_int_handler_pci(struct qdio_irq *irq_ptr)
+{
+	int i;
+	struct qdio_q *q;
+
+	qdio_perf_stat_inc(&perf_stats.pci_int);
+
+	for_each_input_queue(irq_ptr, q, i)
+		tasklet_schedule(&q->tasklet);
+
+	if (!(irq_ptr->qib.ac & QIB_AC_OUTBOUND_PCI_SUPPORTED))
+		return;
+
+	for_each_output_queue(irq_ptr, q, i) {
+		if (qdio_outbound_q_done(q))
+			continue;
+
+		if (!siga_syncs_out_pci(q))
+			qdio_siga_sync_q(q);
+
+		tasklet_schedule(&q->tasklet);
+	}
+}
+
+static void qdio_handle_activate_check(struct ccw_device *cdev,
+				unsigned long intparm, int cstat, int dstat)
+{
+	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
+	struct qdio_q *q;
+	char dbf_text[15];
+
+	QDIO_DBF_TEXT2(1, trace, "ick2");
+	sprintf(dbf_text, "%s", cdev->dev.bus_id);
+	QDIO_DBF_TEXT2(1, trace, dbf_text);
+	QDIO_DBF_HEX2(0, trace, &intparm, sizeof(int));
+	QDIO_DBF_HEX2(0, trace, &dstat, sizeof(int));
+	QDIO_DBF_HEX2(0, trace, &cstat, sizeof(int));
+
+	if (irq_ptr->nr_input_qs) {
+		q = irq_ptr->input_qs[0];
+	} else if (irq_ptr->nr_output_qs) {
+		q = irq_ptr->output_qs[0];
+	} else {
+		dump_stack();
+		goto no_handler;
+	}
+	q->handler(q->irq_ptr->cdev, QDIO_ERROR_ACTIVATE_CHECK_CONDITION,
+		   0, -1, -1, irq_ptr->int_parm);
+no_handler:
+	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_STOPPED);
+}
+
+static void qdio_call_shutdown(struct work_struct *work)
+{
+	struct ccw_device_private *priv;
+	struct ccw_device *cdev;
+
+	priv = container_of(work, struct ccw_device_private, kick_work);
+	cdev = priv->cdev;
+	qdio_shutdown(cdev, QDIO_FLAG_CLEANUP_USING_CLEAR);
+	put_device(&cdev->dev);
+}
+
+static void qdio_int_error(struct ccw_device *cdev)
+{
+	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
+
+	switch (irq_ptr->state) {
+	case QDIO_IRQ_STATE_INACTIVE:
+	case QDIO_IRQ_STATE_CLEANUP:
+		qdio_set_state(irq_ptr, QDIO_IRQ_STATE_ERR);
+		break;
+	case QDIO_IRQ_STATE_ESTABLISHED:
+	case QDIO_IRQ_STATE_ACTIVE:
+		qdio_set_state(irq_ptr, QDIO_IRQ_STATE_STOPPED);
+		if (get_device(&cdev->dev)) {
+			/* Can't call shutdown from interrupt context. */
+			PREPARE_WORK(&cdev->private->kick_work,
+				     qdio_call_shutdown);
+			queue_work(ccw_device_work, &cdev->private->kick_work);
+		}
+		break;
+	default:
+		WARN_ON(1);
+	}
+	wake_up(&cdev->private->wait_q);
+}
+
+static int qdio_establish_check_errors(struct ccw_device *cdev, int cstat,
+					   int dstat)
+{
+	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
+
+	if (cstat || (dstat & ~(DEV_STAT_CHN_END | DEV_STAT_DEV_END))) {
+		QDIO_DBF_TEXT2(1, setup, "eq:ckcon");
+		goto error;
+	}
+
+	if (!(dstat & DEV_STAT_DEV_END)) {
+		QDIO_DBF_TEXT2(1, setup, "eq:no de");
+		goto error;
+	}
+
+	if (dstat & ~(DEV_STAT_CHN_END | DEV_STAT_DEV_END)) {
+		QDIO_DBF_TEXT2(1, setup, "eq:badio");
+		goto error;
+	}
+	return 0;
+error:
+	QDIO_DBF_HEX2(0, trace, &cstat, sizeof(int));
+	QDIO_DBF_HEX2(0, trace, &dstat, sizeof(int));
+	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_ERR);
+	return 1;
+}
+
+static void qdio_establish_handle_irq(struct ccw_device *cdev, int cstat,
+				      int dstat)
+{
+	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
+	char dbf_text[15];
+
+	sprintf(dbf_text, "qehi%4x", cdev->private->schid.sch_no);
+	QDIO_DBF_TEXT0(0, setup, dbf_text);
+	QDIO_DBF_TEXT0(0, trace, dbf_text);
+
+	if (!qdio_establish_check_errors(cdev, cstat, dstat))
+		qdio_set_state(irq_ptr, QDIO_IRQ_STATE_ESTABLISHED);
+}
+
+/* qdio interrupt handler */
+void qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,
+		      struct irb *irb)
+{
+	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
+	int cstat, dstat;
+	char dbf_text[15];
+
+	qdio_perf_stat_inc(&perf_stats.qdio_int);
+
+	if (!intparm || !irq_ptr) {
+		sprintf(dbf_text, "qihd%4x", cdev->private->schid.sch_no);
+		QDIO_DBF_TEXT2(1, setup, dbf_text);
+		return;
+	}
+
+	if (IS_ERR(irb)) {
+		switch (PTR_ERR(irb)) {
+		case -EIO:
+			sprintf(dbf_text, "ierr%4x",
+				cdev->private->schid.sch_no);
+			QDIO_DBF_TEXT2(1, setup, dbf_text);
+			qdio_int_error(cdev);
+			return;
+		case -ETIMEDOUT:
+			sprintf(dbf_text, "qtoh%4x",
+				cdev->private->schid.sch_no);
+			QDIO_DBF_TEXT2(1, setup, dbf_text);
+			qdio_int_error(cdev);
+			return;
+		default:
+			WARN_ON(1);
+			return;
+		}
+	}
+	qdio_irq_check_sense(irq_ptr->schid, irb);
+
+	cstat = irb->scsw.cmd.cstat;
+	dstat = irb->scsw.cmd.dstat;
+
+	switch (irq_ptr->state) {
+	case QDIO_IRQ_STATE_INACTIVE:
+		qdio_establish_handle_irq(cdev, cstat, dstat);
+		break;
+
+	case QDIO_IRQ_STATE_CLEANUP:
+		qdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);
+		break;
+
+	case QDIO_IRQ_STATE_ESTABLISHED:
+	case QDIO_IRQ_STATE_ACTIVE:
+		if (cstat & SCHN_STAT_PCI) {
+			qdio_int_handler_pci(irq_ptr);
+			/* no state change so no need to wake up wait_q */
+			return;
+		}
+		if ((cstat & ~SCHN_STAT_PCI) || dstat) {
+			qdio_handle_activate_check(cdev, intparm, cstat,
+						   dstat);
+			break;
+		}
+	default:
+		WARN_ON(1);
+	}
+	wake_up(&cdev->private->wait_q);
+}
+
+/**
+ * qdio_get_ssqd_desc - get qdio subchannel description
+ * @cdev: ccw device to get description for
+ *
+ * Returns a pointer to the saved qdio subchannel description,
+ * or NULL for not setup qdio devices.
+ */
+struct qdio_ssqd_desc *qdio_get_ssqd_desc(struct ccw_device *cdev)
+{
+	struct qdio_irq *irq_ptr;
+
+	QDIO_DBF_TEXT0(0, setup, "getssqd");
+
+	irq_ptr = cdev->private->qdio_data;
+	if (!irq_ptr)
+		return NULL;
+
+	return &irq_ptr->ssqd_desc;
+}
+EXPORT_SYMBOL_GPL(qdio_get_ssqd_desc);
+
+/**
+ * qdio_cleanup - shutdown queues and free data structures
+ * @cdev: associated ccw device
+ * @how: use halt or clear to shutdown
+ *
+ * This function calls qdio_shutdown() for @cdev with method @how
+ * and on success qdio_free() for @cdev.
+ */
+int qdio_cleanup(struct ccw_device *cdev, int how)
+{
+	struct qdio_irq *irq_ptr;
+	char dbf_text[15];
+	int rc;
+
+	irq_ptr = cdev->private->qdio_data;
+	if (!irq_ptr)
+		return -ENODEV;
+
+	sprintf(dbf_text, "qcln%4x", irq_ptr->schid.sch_no);
+	QDIO_DBF_TEXT1(0, trace, dbf_text);
+	QDIO_DBF_TEXT0(0, setup, dbf_text);
+
+	rc = qdio_shutdown(cdev, how);
+	if (rc == 0)
+		rc = qdio_free(cdev);
+	return rc;
+}
+EXPORT_SYMBOL_GPL(qdio_cleanup);
+
+static void qdio_shutdown_queues(struct ccw_device *cdev)
+{
+	struct qdio_irq *irq_ptr = cdev->private->qdio_data;
+	struct qdio_q *q;
+	int i;
+
+	for_each_input_queue(irq_ptr, q, i)
+		tasklet_disable(&q->tasklet);
+
+	for_each_output_queue(irq_ptr, q, i) {
+		tasklet_disable(&q->tasklet);
+		del_timer(&q->u.out.timer);
+	}
+}
+
+/**
+ * qdio_shutdown - shut down a qdio subchannel
+ * @cdev: associated ccw device
+ * @how: use halt or clear to shutdown
+ */
+int qdio_shutdown(struct ccw_device *cdev, int how)
+{
+	struct qdio_irq *irq_ptr;
+	int rc;
+	unsigned long flags;
+	char dbf_text[15];
+
+	irq_ptr = cdev->private->qdio_data;
+	if (!irq_ptr)
+		return -ENODEV;
+
+	mutex_lock(&irq_ptr->setup_mutex);
+	/*
+	 * Subchannel was already shot down. We cannot prevent being called
+	 * twice since cio may trigger a shutdown asynchronously.
+	 */
+	if (irq_ptr->state == QDIO_IRQ_STATE_INACTIVE) {
+		mutex_unlock(&irq_ptr->setup_mutex);
+		return 0;
+	}
+
+	sprintf(dbf_text, "qsqs%4x", irq_ptr->schid.sch_no);
+	QDIO_DBF_TEXT1(0, trace, dbf_text);
+	QDIO_DBF_TEXT0(0, setup, dbf_text);
+
+	tiqdio_remove_input_queues(irq_ptr);
+	qdio_shutdown_queues(cdev);
+	qdio_shutdown_debug_entries(irq_ptr, cdev);
+
+	/* cleanup subchannel */
+	spin_lock_irqsave(get_ccwdev_lock(cdev), flags);
+
+	if (how & QDIO_FLAG_CLEANUP_USING_CLEAR)
+		rc = ccw_device_clear(cdev, QDIO_DOING_CLEANUP);
+	else
+		/* default behaviour is halt */
+		rc = ccw_device_halt(cdev, QDIO_DOING_CLEANUP);
+	if (rc) {
+		sprintf(dbf_text, "sher%4x", irq_ptr->schid.sch_no);
+		QDIO_DBF_TEXT0(0, setup, dbf_text);
+		sprintf(dbf_text, "rc=%d", rc);
+		QDIO_DBF_TEXT0(0, setup, dbf_text);
+		goto no_cleanup;
+	}
+
+	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_CLEANUP);
+	spin_unlock_irqrestore(get_ccwdev_lock(cdev), flags);
+	wait_event_interruptible_timeout(cdev->private->wait_q,
+		irq_ptr->state == QDIO_IRQ_STATE_INACTIVE ||
+		irq_ptr->state == QDIO_IRQ_STATE_ERR,
+		10 * HZ);
+	spin_lock_irqsave(get_ccwdev_lock(cdev), flags);
+
+no_cleanup:
+	qdio_shutdown_thinint(irq_ptr);
+
+	/* restore interrupt handler */
+	if ((void *)cdev->handler == (void *)qdio_int_handler)
+		cdev->handler = irq_ptr->orig_handler;
+	spin_unlock_irqrestore(get_ccwdev_lock(cdev), flags);
+
+	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);
+	mutex_unlock(&irq_ptr->setup_mutex);
+	module_put(THIS_MODULE);
+	if (rc)
+		return rc;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(qdio_shutdown);
+
+/**
+ * qdio_free - free data structures for a qdio subchannel
+ * @cdev: associated ccw device
+ */
+int qdio_free(struct ccw_device *cdev)
+{
+	struct qdio_irq *irq_ptr;
+	char dbf_text[15];
+
+	irq_ptr = cdev->private->qdio_data;
+	if (!irq_ptr)
+		return -ENODEV;
+
+	mutex_lock(&irq_ptr->setup_mutex);
+
+	sprintf(dbf_text, "qfqs%4x", irq_ptr->schid.sch_no);
+	QDIO_DBF_TEXT1(0, trace, dbf_text);
+	QDIO_DBF_TEXT0(0, setup, dbf_text);
+
+	cdev->private->qdio_data = NULL;
+	mutex_unlock(&irq_ptr->setup_mutex);
+
+	qdio_release_memory(irq_ptr);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(qdio_free);
+
+/**
+ * qdio_initialize - allocate and establish queues for a qdio subchannel
+ * @init_data: initialization data
+ *
+ * This function first allocates queues via qdio_allocate() and on success
+ * establishes them via qdio_establish().
+ */
+int qdio_initialize(struct qdio_initialize *init_data)
+{
+	int rc;
+	char dbf_text[15];
+
+	sprintf(dbf_text, "qini%4x", init_data->cdev->private->schid.sch_no);
+	QDIO_DBF_TEXT0(0, setup, dbf_text);
+	QDIO_DBF_TEXT0(0, trace, dbf_text);
+
+	rc = qdio_allocate(init_data);
+	if (rc)
+		return rc;
+
+	rc = qdio_establish(init_data);
+	if (rc)
+		qdio_free(init_data->cdev);
+	return rc;
+}
+EXPORT_SYMBOL_GPL(qdio_initialize);
+
+/**
+ * qdio_allocate - allocate qdio queues and associated data
+ * @init_data: initialization data
+ */
+int qdio_allocate(struct qdio_initialize *init_data)
+{
+	struct qdio_irq *irq_ptr;
+	char dbf_text[15];
+
+	sprintf(dbf_text, "qalc%4x", init_data->cdev->private->schid.sch_no);
+	QDIO_DBF_TEXT0(0, setup, dbf_text);
+	QDIO_DBF_TEXT0(0, trace, dbf_text);
+
+	if ((init_data->no_input_qs && !init_data->input_handler) ||
+	    (init_data->no_output_qs && !init_data->output_handler))
+		return -EINVAL;
+
+	if ((init_data->no_input_qs > QDIO_MAX_QUEUES_PER_IRQ) ||
+	    (init_data->no_output_qs > QDIO_MAX_QUEUES_PER_IRQ))
+		return -EINVAL;
+
+	if ((!init_data->input_sbal_addr_array) ||
+	    (!init_data->output_sbal_addr_array))
+		return -EINVAL;
+
+	qdio_allocate_do_dbf(init_data);
+
+	/* irq_ptr must be in GFP_DMA since it contains ccw1.cda */
+	irq_ptr = (void *) get_zeroed_page(GFP_KERNEL | GFP_DMA);
+	if (!irq_ptr)
+		goto out_err;
+	QDIO_DBF_TEXT0(0, setup, "irq_ptr:");
+	QDIO_DBF_HEX0(0, setup, &irq_ptr, sizeof(void *));
+
+	mutex_init(&irq_ptr->setup_mutex);
+
+	/*
+	 * Allocate a page for the chsc calls in qdio_establish.
+	 * Must be pre-allocated since a zfcp recovery will call
+	 * qdio_establish. In case of low memory and swap on a zfcp disk
+	 * we may not be able to allocate memory otherwise.
+	 */
+	irq_ptr->chsc_page = get_zeroed_page(GFP_KERNEL);
+	if (!irq_ptr->chsc_page)
+		goto out_rel;
+
+	/* qdr is used in ccw1.cda which is u32 */
+	irq_ptr->qdr = kzalloc(sizeof(struct qdr), GFP_KERNEL | GFP_DMA);
+	if (!irq_ptr->qdr)
+		goto out_rel;
+	WARN_ON((unsigned long)irq_ptr->qdr & 0xfff);
+
+	QDIO_DBF_TEXT0(0, setup, "qdr:");
+	QDIO_DBF_HEX0(0, setup, &irq_ptr->qdr, sizeof(void *));
+
+	if (qdio_allocate_qs(irq_ptr, init_data->no_input_qs,
+			     init_data->no_output_qs))
+		goto out_rel;
+
+	init_data->cdev->private->qdio_data = irq_ptr;
+	qdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);
+	return 0;
+out_rel:
+	qdio_release_memory(irq_ptr);
+out_err:
+	return -ENOMEM;
+}
+EXPORT_SYMBOL_GPL(qdio_allocate);
+
+/**
+ * qdio_establish - establish queues on a qdio subchannel
+ * @init_data: initialization data
+ */
+int qdio_establish(struct qdio_initialize *init_data)
+{
+	char dbf_text[20];
+	struct qdio_irq *irq_ptr;
+	struct ccw_device *cdev = init_data->cdev;
+	unsigned long saveflags;
+	int rc;
+
+	irq_ptr = cdev->private->qdio_data;
+	if (!irq_ptr)
+		return -ENODEV;
+
+	if (cdev->private->state != DEV_STATE_ONLINE)
+		return -EINVAL;
+
+	if (!try_module_get(THIS_MODULE))
+		return -EINVAL;
+
+	sprintf(dbf_text, "qest%4x", cdev->private->schid.sch_no);
+	QDIO_DBF_TEXT0(0, setup, dbf_text);
+	QDIO_DBF_TEXT0(0, trace, dbf_text);
+
+	mutex_lock(&irq_ptr->setup_mutex);
+	qdio_setup_irq(init_data);
+
+	rc = qdio_establish_thinint(irq_ptr);
+	if (rc) {
+		mutex_unlock(&irq_ptr->setup_mutex);
+		qdio_shutdown(cdev, QDIO_FLAG_CLEANUP_USING_CLEAR);
+		return rc;
+	}
+
+	/* establish q */
+	irq_ptr->ccw.cmd_code = irq_ptr->equeue.cmd;
+	irq_ptr->ccw.flags = CCW_FLAG_SLI;
+	irq_ptr->ccw.count = irq_ptr->equeue.count;
+	irq_ptr->ccw.cda = (u32)((addr_t)irq_ptr->qdr);
+
+	spin_lock_irqsave(get_ccwdev_lock(cdev), saveflags);
+	ccw_device_set_options_mask(cdev, 0);
+
+	rc = ccw_device_start(cdev, &irq_ptr->ccw, QDIO_DOING_ESTABLISH, 0, 0);
+	if (rc) {
+		sprintf(dbf_text, "eq:io%4x", irq_ptr->schid.sch_no);
+		QDIO_DBF_TEXT2(1, setup, dbf_text);
+		sprintf(dbf_text, "eq:rc%4x", rc);
+		QDIO_DBF_TEXT2(1, setup, dbf_text);
+	}
+	spin_unlock_irqrestore(get_ccwdev_lock(cdev), saveflags);
+
+	if (rc) {
+		mutex_unlock(&irq_ptr->setup_mutex);
+		qdio_shutdown(cdev, QDIO_FLAG_CLEANUP_USING_CLEAR);
+		return rc;
+	}
+
+	wait_event_interruptible_timeout(cdev->private->wait_q,
+		irq_ptr->state == QDIO_IRQ_STATE_ESTABLISHED ||
+		irq_ptr->state == QDIO_IRQ_STATE_ERR, HZ);
+
+	if (irq_ptr->state != QDIO_IRQ_STATE_ESTABLISHED) {
+		mutex_unlock(&irq_ptr->setup_mutex);
+		qdio_shutdown(cdev, QDIO_FLAG_CLEANUP_USING_CLEAR);
+		return -EIO;
+	}
+
+	qdio_setup_ssqd_info(irq_ptr);
+	sprintf(dbf_text, "qib ac%2x", irq_ptr->qib.ac);
+	QDIO_DBF_TEXT2(0, setup, dbf_text);
+
+	/* qebsm is now setup if available, initialize buffer states */
+	qdio_init_buf_states(irq_ptr);
+
+	mutex_unlock(&irq_ptr->setup_mutex);
+	qdio_print_subchannel_info(irq_ptr, cdev);
+	qdio_setup_debug_entries(irq_ptr, cdev);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(qdio_establish);
+
+/**
+ * qdio_activate - activate queues on a qdio subchannel
+ * @cdev: associated cdev
+ */
+int qdio_activate(struct ccw_device *cdev)
+{
+	struct qdio_irq *irq_ptr;
+	int rc;
+	unsigned long saveflags;
+	char dbf_text[20];
+
+	irq_ptr = cdev->private->qdio_data;
+	if (!irq_ptr)
+		return -ENODEV;
+
+	if (cdev->private->state != DEV_STATE_ONLINE)
+		return -EINVAL;
+
+	mutex_lock(&irq_ptr->setup_mutex);
+	if (irq_ptr->state == QDIO_IRQ_STATE_INACTIVE) {
+		rc = -EBUSY;
+		goto out;
+	}
+
+	sprintf(dbf_text, "qact%4x", irq_ptr->schid.sch_no);
+	QDIO_DBF_TEXT2(0, setup, dbf_text);
+	QDIO_DBF_TEXT2(0, trace, dbf_text);
+
+	irq_ptr->ccw.cmd_code = irq_ptr->aqueue.cmd;
+	irq_ptr->ccw.flags = CCW_FLAG_SLI;
+	irq_ptr->ccw.count = irq_ptr->aqueue.count;
+	irq_ptr->ccw.cda = 0;
+
+	spin_lock_irqsave(get_ccwdev_lock(cdev), saveflags);
+	ccw_device_set_options(cdev, CCWDEV_REPORT_ALL);
+
+	rc = ccw_device_start(cdev, &irq_ptr->ccw, QDIO_DOING_ACTIVATE,
+			      0, DOIO_DENY_PREFETCH);
+	if (rc) {
+		sprintf(dbf_text, "aq:io%4x", irq_ptr->schid.sch_no);
+		QDIO_DBF_TEXT2(1, setup, dbf_text);
+		sprintf(dbf_text, "aq:rc%4x", rc);
+		QDIO_DBF_TEXT2(1, setup, dbf_text);
+	}
+	spin_unlock_irqrestore(get_ccwdev_lock(cdev), saveflags);
+
+	if (rc)
+		goto out;
+
+	if (is_thinint_irq(irq_ptr))
+		tiqdio_add_input_queues(irq_ptr);
+
+	/* wait for subchannel to become active */
+	msleep(5);
+
+	switch (irq_ptr->state) {
+	case QDIO_IRQ_STATE_STOPPED:
+	case QDIO_IRQ_STATE_ERR:
+		mutex_unlock(&irq_ptr->setup_mutex);
+		qdio_shutdown(cdev, QDIO_FLAG_CLEANUP_USING_CLEAR);
+		return -EIO;
+	default:
+		qdio_set_state(irq_ptr, QDIO_IRQ_STATE_ACTIVE);
+		rc = 0;
+	}
+out:
+	mutex_unlock(&irq_ptr->setup_mutex);
+	return rc;
+}
+EXPORT_SYMBOL_GPL(qdio_activate);
+
+static inline int buf_in_between(int bufnr, int start, int count)
+{
+	int end = add_buf(start, count);
+
+	if (end > start) {
+		if (bufnr >= start && bufnr < end)
+			return 1;
+		else
+			return 0;
+	}
+
+	/* wrap-around case */
+	if ((bufnr >= start && bufnr <= QDIO_MAX_BUFFERS_PER_Q) ||
+	    (bufnr < end))
+		return 1;
+	else
+		return 0;
+}
+
+/**
+ * handle_inbound - reset processed input buffers
+ * @q: queue containing the buffers
+ * @callflags: flags
+ * @bufnr: first buffer to process
+ * @count: how many buffers are emptied
+ */
+static void handle_inbound(struct qdio_q *q, unsigned int callflags,
+			   int bufnr, int count)
+{
+	unsigned long flags;
+	int used, rc;
+
+	/*
+	 * do_QDIO could run in parallel with the queue tasklet so the
+	 * upper-layer programm could empty the ACK'ed buffer here.
+	 * If that happens we must clear the polling flag, otherwise
+	 * qdio_stop_polling() could set the buffer to NOT_INIT after
+	 * it was set to EMPTY which would kill us.
+	 */
+	spin_lock_irqsave(&q->u.in.lock, flags);
+	if (q->u.in.polling)
+		if (buf_in_between(q->last_move_ftc, bufnr, count))
+			q->u.in.polling = 0;
+
+	count = set_buf_states(q, bufnr, SLSB_CU_INPUT_EMPTY, count);
+	spin_unlock_irqrestore(&q->u.in.lock, flags);
+
+	used = atomic_add_return(count, &q->nr_buf_used) - count;
+	BUG_ON(used + count > QDIO_MAX_BUFFERS_PER_Q);
+
+	/* no need to signal as long as the adapter had free buffers */
+	if (used)
+		return;
+
+	if (need_siga_in(q)) {
+		rc = qdio_siga_input(q);
+		if (rc)
+			q->qdio_error = rc;
+	}
+}
+
+/**
+ * handle_outbound - process filled outbound buffers
+ * @q: queue containing the buffers
+ * @callflags: flags
+ * @bufnr: first buffer to process
+ * @count: how many buffers are filled
+ */
+static void handle_outbound(struct qdio_q *q, unsigned int callflags,
+			    int bufnr, int count)
+{
+	unsigned char state;
+	int used;
+
+	qdio_perf_stat_inc(&perf_stats.outbound_handler);
+
+	count = set_buf_states(q, bufnr, SLSB_CU_OUTPUT_PRIMED, count);
+	used = atomic_add_return(count, &q->nr_buf_used);
+	BUG_ON(used > QDIO_MAX_BUFFERS_PER_Q);
+
+	if (callflags & QDIO_FLAG_PCI_OUT)
+		q->u.out.pci_out_enabled = 1;
+	else
+		q->u.out.pci_out_enabled = 0;
+
+	if (queue_type(q) == QDIO_IQDIO_QFMT) {
+		if (multicast_outbound(q))
+			qdio_kick_outbound_q(q);
+		else
+			/*
+			 * One siga-w per buffer required for unicast
+			 * HiperSockets.
+			 */
+			while (count--)
+				qdio_kick_outbound_q(q);
+		goto out;
+	}
+
+	if (need_siga_sync(q)) {
+		qdio_siga_sync_q(q);
+		goto out;
+	}
+
+	/* try to fast requeue buffers */
+	get_buf_state(q, prev_buf(bufnr), &state);
+	if (state != SLSB_CU_OUTPUT_PRIMED)
+		qdio_kick_outbound_q(q);
+	else {
+		QDIO_DBF_TEXT5(0, trace, "fast-req");
+		qdio_perf_stat_inc(&perf_stats.fast_requeue);
+	}
+out:
+	/* Fixme: could wait forever if called from process context */
+	tasklet_schedule(&q->tasklet);
+}
+
+/**
+ * do_QDIO - process input or output buffers
+ * @cdev: associated ccw_device for the qdio subchannel
+ * @callflags: input or output and special flags from the program
+ * @q_nr: queue number
+ * @bufnr: buffer number
+ * @count: how many buffers to process
+ */
+int do_QDIO(struct ccw_device *cdev, unsigned int callflags,
+	    int q_nr, int bufnr, int count)
+{
+	struct qdio_irq *irq_ptr;
+#ifdef CONFIG_QDIO_DEBUG
+	char dbf_text[20];
+
+	sprintf(dbf_text, "doQD%04x", cdev->private->schid.sch_no);
+	QDIO_DBF_TEXT3(0, trace, dbf_text);
+#endif /* CONFIG_QDIO_DEBUG */
+
+	if ((bufnr > QDIO_MAX_BUFFERS_PER_Q) ||
+	    (count > QDIO_MAX_BUFFERS_PER_Q) ||
+	    (q_nr > QDIO_MAX_QUEUES_PER_IRQ))
+		return -EINVAL;
+
+	if (!count)
+		return 0;
+
+	irq_ptr = cdev->private->qdio_data;
+	if (!irq_ptr)
+		return -ENODEV;
+
+#ifdef CONFIG_QDIO_DEBUG
+	if (callflags & QDIO_FLAG_SYNC_INPUT)
+		QDIO_DBF_HEX3(0, trace, &irq_ptr->input_qs[q_nr],
+			      sizeof(void *));
+	else
+		QDIO_DBF_HEX3(0, trace, &irq_ptr->output_qs[q_nr],
+			      sizeof(void *));
+
+	sprintf(dbf_text, "flag%04x", callflags);
+	QDIO_DBF_TEXT3(0, trace, dbf_text);
+	sprintf(dbf_text, "qi%02xct%02x", bufnr, count);
+	QDIO_DBF_TEXT3(0, trace, dbf_text);
+#endif /* CONFIG_QDIO_DEBUG */
+
+	if (irq_ptr->state != QDIO_IRQ_STATE_ACTIVE)
+		return -EBUSY;
+
+	if (callflags & QDIO_FLAG_SYNC_INPUT)
+		handle_inbound(irq_ptr->input_qs[q_nr],
+			       callflags, bufnr, count);
+	else if (callflags & QDIO_FLAG_SYNC_OUTPUT)
+		handle_outbound(irq_ptr->output_qs[q_nr],
+				callflags, bufnr, count);
+	else {
+		QDIO_DBF_TEXT3(1, trace, "doQD:inv");
+		return -EINVAL;
+	}
+	return 0;
+}
+EXPORT_SYMBOL_GPL(do_QDIO);
+
+static int __init init_QDIO(void)
+{
+	int rc;
+
+	rc = qdio_setup_init();
+	if (rc)
+		return rc;
+	rc = tiqdio_allocate_memory();
+	if (rc)
+		goto out_cache;
+	rc = qdio_debug_init();
+	if (rc)
+		goto out_ti;
+	rc = qdio_setup_perf_stats();
+	if (rc)
+		goto out_debug;
+	rc = tiqdio_register_thinints();
+	if (rc)
+		goto out_perf;
+	return 0;
+
+out_perf:
+	qdio_remove_perf_stats();
+out_debug:
+	qdio_debug_exit();
+out_ti:
+	tiqdio_free_memory();
+out_cache:
+	qdio_setup_exit();
+	return rc;
+}
+
+static void __exit exit_QDIO(void)
+{
+	tiqdio_unregister_thinints();
+	tiqdio_free_memory();
+	qdio_remove_perf_stats();
+	qdio_debug_exit();
+	qdio_setup_exit();
+}
+
+module_init(init_QDIO);
+module_exit(exit_QDIO);
