commit e689fbab3ddd92557134ef92c40a780a33299d05
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Wed Feb 20 15:37:44 2019 -0500

    dm: remove unused _rq_tio_cache and _rq_cache
    
    Also move dm_rq_target_io structure definition from dm-rq.h to dm-rq.c
    
    Fixes: 6a23e05c2fe3c6 ("dm: remove legacy request-based IO path")
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm-rq.h b/drivers/md/dm-rq.h
index b39245545229..1eea0da641db 100644
--- a/drivers/md/dm-rq.h
+++ b/drivers/md/dm-rq.h
@@ -16,22 +16,6 @@
 
 struct mapped_device;
 
-/*
- * One of these is allocated per request.
- */
-struct dm_rq_target_io {
-	struct mapped_device *md;
-	struct dm_target *ti;
-	struct request *orig, *clone;
-	struct kthread_work work;
-	blk_status_t error;
-	union map_info info;
-	struct dm_stats_aux stats_aux;
-	unsigned long duration_jiffies;
-	unsigned n_sectors;
-	unsigned completed;
-};
-
 /*
  * For request-based dm - the bio clones we allocate are embedded in these
  * structs.

commit 6a23e05c2fe3c64ec012fd81e51e3ab51e4f2f9f
Author: Jens Axboe <axboe@kernel.dk>
Date:   Wed Oct 10 20:49:26 2018 -0600

    dm: remove legacy request-based IO path
    
    dm supports both, and since we're killing off the legacy path in
    general, get rid of it in dm.
    
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm-rq.h b/drivers/md/dm-rq.h
index f43c45460aac..b39245545229 100644
--- a/drivers/md/dm-rq.h
+++ b/drivers/md/dm-rq.h
@@ -46,10 +46,6 @@ struct dm_rq_clone_bio_info {
 	struct bio clone;
 };
 
-bool dm_use_blk_mq_default(void);
-bool dm_use_blk_mq(struct mapped_device *md);
-
-int dm_old_init_request_queue(struct mapped_device *md, struct dm_table *t);
 int dm_mq_init_request_queue(struct mapped_device *md, struct dm_table *t);
 void dm_mq_cleanup_mapped_device(struct mapped_device *md);
 

commit dc6364b5170dc446fca076d6523aaebc339d6511
Author: Ming Lei <ming.lei@redhat.com>
Date:   Thu Aug 24 20:19:52 2017 +0800

    dm rq: do not update rq partially in each ending bio
    
    We don't need to update the original dm request partially when ending
    each cloned bio: just update original dm request once when the whole
    cloned request is finished.  This still allows full support for partial
    completion because a new 'completed' counter accounts for incremental
    progress as the clone bios complete.
    
    Partial request update can be a bit expensive, so we should try to avoid
    it, especially because it is run in softirq context.
    
    Avoiding all the partial request updates fixes both hard lockup and
    soft lockups that were easily reproduced while running Laurence's
    test[1] on IB/SRP.
    
    BTW, after d4acf3650c7c ("block: Make blk_mq_delay_kick_requeue_list()
    rerun the queue at a quiet time"), we need to make the test more
    aggressive for reproducing the lockup:
    
            1) run hammer_write.sh 32 or 64 concurrently.
            2) write 8M each time
    
    [1] https://marc.info/?l=linux-block&m=150220185510245&w=2
    
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm-rq.h b/drivers/md/dm-rq.h
index 9813922e4fe5..f43c45460aac 100644
--- a/drivers/md/dm-rq.h
+++ b/drivers/md/dm-rq.h
@@ -29,6 +29,7 @@ struct dm_rq_target_io {
 	struct dm_stats_aux stats_aux;
 	unsigned long duration_jiffies;
 	unsigned n_sectors;
+	unsigned completed;
 };
 
 /*

commit 2a842acab109f40f0d7d10b38e9ca88390628996
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 3 09:38:04 2017 +0200

    block: introduce new block status code type
    
    Currently we use nornal Linux errno values in the block layer, and while
    we accept any error a few have overloaded magic meanings.  This patch
    instead introduces a new  blk_status_t value that holds block layer specific
    status codes and explicitly explains their meaning.  Helpers to convert from
    and to the previous special meanings are provided for now, but I suspect
    we want to get rid of them in the long run - those drivers that have a
    errno input (e.g. networking) usually get errnos that don't know about
    the special block layer overloads, and similarly returning them to userspace
    will usually return somethings that strictly speaking isn't correct
    for file system operations, but that's left as an exercise for later.
    
    For now the set of errors is a very limited set that closely corresponds
    to the previous overloaded errno values, but there is some low hanging
    fruite to improve it.
    
    blk_status_t (ab)uses the sparse __bitwise annotations to allow for sparse
    typechecking, so that we can easily catch places passing the wrong values.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/md/dm-rq.h b/drivers/md/dm-rq.h
index f0020d21b95f..9813922e4fe5 100644
--- a/drivers/md/dm-rq.h
+++ b/drivers/md/dm-rq.h
@@ -24,7 +24,7 @@ struct dm_rq_target_io {
 	struct dm_target *ti;
 	struct request *orig, *clone;
 	struct kthread_work work;
-	int error;
+	blk_status_t error;
 	union map_info info;
 	struct dm_stats_aux stats_aux;
 	unsigned long duration_jiffies;

commit eb8db831be80692bf4bda3dfc55001daf64ec299
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Jan 22 18:32:46 2017 +0100

    dm: always defer request allocation to the owner of the request_queue
    
    DM already calls blk_mq_alloc_request on the request_queue of the
    underlying device if it is a blk-mq device.  But now that we allow drivers
    to allocate additional data and initialize it ahead of time we need to do
    the same for all drivers.   Doing so and using the new cmd_size
    infrastructure in the block layer greatly simplifies the dm-rq and mpath
    code, and should also make arbitrary combinations of SQ and MQ devices
    with SQ or MQ device mapper tables easily possible as a further step.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/md/dm-rq.h b/drivers/md/dm-rq.h
index 4da06cae7bad..f0020d21b95f 100644
--- a/drivers/md/dm-rq.h
+++ b/drivers/md/dm-rq.h
@@ -48,7 +48,7 @@ struct dm_rq_clone_bio_info {
 bool dm_use_blk_mq_default(void);
 bool dm_use_blk_mq(struct mapped_device *md);
 
-int dm_old_init_request_queue(struct mapped_device *md);
+int dm_old_init_request_queue(struct mapped_device *md, struct dm_table *t);
 int dm_mq_init_request_queue(struct mapped_device *md, struct dm_table *t);
 void dm_mq_cleanup_mapped_device(struct mapped_device *md);
 

commit e0c107526960d1348cfe21f12bcfb3348fd7e8ab
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Wed Sep 14 10:36:39 2016 -0400

    dm rq: introduce dm_mq_kick_requeue_list()
    
    Make it possible for a request-based target to kick the DM device's
    blk-mq request_queue's requeue_list.
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>

diff --git a/drivers/md/dm-rq.h b/drivers/md/dm-rq.h
index 9e6f0a3773d4..4da06cae7bad 100644
--- a/drivers/md/dm-rq.h
+++ b/drivers/md/dm-rq.h
@@ -55,6 +55,8 @@ void dm_mq_cleanup_mapped_device(struct mapped_device *md);
 void dm_start_queue(struct request_queue *q);
 void dm_stop_queue(struct request_queue *q);
 
+void dm_mq_kick_requeue_list(struct mapped_device *md);
+
 unsigned dm_get_reserved_rq_based_ios(void);
 
 ssize_t dm_attr_rq_based_seq_io_merge_deadline_show(struct mapped_device *md, char *buf);

commit e83068a5faafb8ca65d3b58bd1e1e3959ce1ddce
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Tue May 24 21:16:51 2016 -0400

    dm mpath: add optional "queue_mode" feature
    
    Allow a user to specify an optional feature 'queue_mode <mode>' where
    <mode> may be "bio", "rq" or "mq" -- which corresponds to bio-based,
    request_fn rq-based, and blk-mq rq-based respectively.
    
    If the queue_mode feature isn't specified the default for the
    "multipath" target is still "rq" but if dm_mod.use_blk_mq is set to Y
    it'll default to mode "mq".
    
    This new queue_mode feature introduces the ability for each multipath
    device to have its own queue_mode (whereas before this feature all
    multipath devices effectively had to have the same queue_mode).
    
    This commit also goes a long way to eliminate the awkward (ab)use of
    DM_TYPE_*, the associated filter_md_type() and other relatively fragile
    and difficult to maintain code.
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm-rq.h b/drivers/md/dm-rq.h
index 1559f6486024..9e6f0a3773d4 100644
--- a/drivers/md/dm-rq.h
+++ b/drivers/md/dm-rq.h
@@ -49,7 +49,7 @@ bool dm_use_blk_mq_default(void);
 bool dm_use_blk_mq(struct mapped_device *md);
 
 int dm_old_init_request_queue(struct mapped_device *md);
-int dm_mq_init_request_queue(struct mapped_device *md, struct dm_target *immutable_tgt);
+int dm_mq_init_request_queue(struct mapped_device *md, struct dm_table *t);
 void dm_mq_cleanup_mapped_device(struct mapped_device *md);
 
 void dm_start_queue(struct request_queue *q);

commit 4cc96131afce3eaae7c13dff41c6ba771cf10e96
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Thu May 12 16:28:10 2016 -0400

    dm: move request-based code out to dm-rq.[hc]
    
    Add some seperation between bio-based and request-based DM core code.
    
    'struct mapped_device' and other DM core only structures and functions
    have been moved to dm-core.h and all relevant DM core .c files have been
    updated to include dm-core.h rather than dm.h
    
    DM targets should _never_ include dm-core.h!
    
    [block core merge conflict resolution from Stephen Rothwell]
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>

diff --git a/drivers/md/dm-rq.h b/drivers/md/dm-rq.h
new file mode 100644
index 000000000000..1559f6486024
--- /dev/null
+++ b/drivers/md/dm-rq.h
@@ -0,0 +1,64 @@
+/*
+ * Internal header file for device mapper
+ *
+ * Copyright (C) 2016 Red Hat, Inc. All rights reserved.
+ *
+ * This file is released under the LGPL.
+ */
+
+#ifndef DM_RQ_INTERNAL_H
+#define DM_RQ_INTERNAL_H
+
+#include <linux/bio.h>
+#include <linux/kthread.h>
+
+#include "dm-stats.h"
+
+struct mapped_device;
+
+/*
+ * One of these is allocated per request.
+ */
+struct dm_rq_target_io {
+	struct mapped_device *md;
+	struct dm_target *ti;
+	struct request *orig, *clone;
+	struct kthread_work work;
+	int error;
+	union map_info info;
+	struct dm_stats_aux stats_aux;
+	unsigned long duration_jiffies;
+	unsigned n_sectors;
+};
+
+/*
+ * For request-based dm - the bio clones we allocate are embedded in these
+ * structs.
+ *
+ * We allocate these with bio_alloc_bioset, using the front_pad parameter when
+ * the bioset is created - this means the bio has to come at the end of the
+ * struct.
+ */
+struct dm_rq_clone_bio_info {
+	struct bio *orig;
+	struct dm_rq_target_io *tio;
+	struct bio clone;
+};
+
+bool dm_use_blk_mq_default(void);
+bool dm_use_blk_mq(struct mapped_device *md);
+
+int dm_old_init_request_queue(struct mapped_device *md);
+int dm_mq_init_request_queue(struct mapped_device *md, struct dm_target *immutable_tgt);
+void dm_mq_cleanup_mapped_device(struct mapped_device *md);
+
+void dm_start_queue(struct request_queue *q);
+void dm_stop_queue(struct request_queue *q);
+
+unsigned dm_get_reserved_rq_based_ios(void);
+
+ssize_t dm_attr_rq_based_seq_io_merge_deadline_show(struct mapped_device *md, char *buf);
+ssize_t dm_attr_rq_based_seq_io_merge_deadline_store(struct mapped_device *md,
+						     const char *buf, size_t count);
+
+#endif
