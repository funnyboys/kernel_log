commit bcb44433bba5eaff293888ef22ffa07f1f0347d6
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Wed Apr 3 12:23:11 2019 -0400

    dm: disable DISCARD if the underlying storage no longer supports it
    
    Storage devices which report supporting discard commands like
    WRITE_SAME_16 with unmap, but reject discard commands sent to the
    storage device.  This is a clear storage firmware bug but it doesn't
    change the fact that should a program cause discards to be sent to a
    multipath device layered on this buggy storage, all paths can end up
    failed at the same time from the discards, causing possible I/O loss.
    
    The first discard to a path will fail with Illegal Request, Invalid
    field in cdb, e.g.:
     kernel: sd 8:0:8:19: [sdfn] tag#0 FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE
     kernel: sd 8:0:8:19: [sdfn] tag#0 Sense Key : Illegal Request [current]
     kernel: sd 8:0:8:19: [sdfn] tag#0 Add. Sense: Invalid field in cdb
     kernel: sd 8:0:8:19: [sdfn] tag#0 CDB: Write same(16) 93 08 00 00 00 00 00 a0 08 00 00 00 80 00 00 00
     kernel: blk_update_request: critical target error, dev sdfn, sector 10487808
    
    The SCSI layer converts this to the BLK_STS_TARGET error number, the sd
    device disables its support for discard on this path, and because of the
    BLK_STS_TARGET error multipath fails the discard without failing any
    path or retrying down a different path.  But subsequent discards can
    cause path failures.  Any discards sent to the path which already failed
    a discard ends up failing with EIO from blk_cloned_rq_check_limits with
    an "over max size limit" error since the discard limit was set to 0 by
    the sd driver for the path.  As the error is EIO, this now fails the
    path and multipath tries to send the discard down the next path.  This
    cycle continues as discards are sent until all paths fail.
    
    Fix this by training DM core to disable DISCARD if the underlying
    storage already did so.
    
    Also, fix branching in dm_done() and clone_endio() to reflect the
    mutually exclussive nature of the IO operations in question.
    
    Cc: stable@vger.kernel.org
    Reported-by: David Jeffery <djeffery@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
index 95c6d86ab5e8..c4ef1fceead6 100644
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@ -115,6 +115,7 @@ struct mapped_device {
 	struct srcu_struct io_barrier;
 };
 
+void disable_discard(struct mapped_device *md);
 void disable_write_same(struct mapped_device *md);
 void disable_write_zeroes(struct mapped_device *md);
 

commit dbe3ece1287dafe4113c64ada3113c39f344c64a
Author: Jens Axboe <axboe@kernel.dk>
Date:   Wed Dec 19 09:13:34 2018 -0700

    dm: don't reuse bio for flushes
    
    DM currently has a statically allocated bio that it uses to issue empty
    flushes. It doesn't submit this bio, it just uses it for maintaining
    state while setting up clones. Multiple users can access this bio at the
    same time. This wasn't previously an issue, even if it was a bit iffy,
    but with the blkg associations it can become one.
    
    We setup the blkg association, then clone bio's and submit, then remove
    the blkg assocation again. But since we can have multiple tasks doing
    this at the same time, against multiple blkg's, then we can either lose
    references to a blkg, or put it twice. The latter causes complaints on
    the percpu ref being <= 0 when released, and can cause use-after-free as
    well. Ming reports that xfstest generic/475 triggers this:
    
    ------------[ cut here ]------------
    percpu ref (blkg_release) <= 0 (0) after switching to atomic
    WARNING: CPU: 13 PID: 0 at lib/percpu-refcount.c:155 percpu_ref_switch_to_atomic_rcu+0x2c9/0x4a0
    
    Switch to just using an on-stack bio for this, and get rid of the
    embedded bio.
    
    Fixes: 5cdf2e3fea5e ("blkcg: associate blkg when associating a device")
    Reported-by: Ming Lei <ming.lei@redhat.com>
    Tested-by: Ming Lei <ming.lei@redhat.com>
    Reviewed-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
index 6fe883fac471..95c6d86ab5e8 100644
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@ -106,9 +106,6 @@ struct mapped_device {
 
 	struct block_device *bdev;
 
-	/* zero-length flush that will be cloned and submitted to targets */
-	struct bio flush_bio;
-
 	struct dm_stats stats;
 
 	/* for blk-mq request-based DM support */

commit 6f75723190d88e1319bea623bfe0292bf3917965
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Thu Dec 6 11:41:22 2018 -0500

    dm: remove the pending IO accounting
    
    Remove the "pending" atomic counters, that duplicate block-core's
    in_flight counters, and update md_in_flight() to look at percpu
    in_flight counters.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
index 224d44503a06..6fe883fac471 100644
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@ -65,7 +65,6 @@ struct mapped_device {
 	 */
 	struct work_struct work;
 	wait_queue_head_t wait;
-	atomic_t pending[2];
 	spinlock_t deferred_lock;
 	struct bio_list deferred;
 
@@ -119,7 +118,6 @@ struct mapped_device {
 	struct srcu_struct io_barrier;
 };
 
-int md_in_flight(struct mapped_device *md);
 void disable_write_same(struct mapped_device *md);
 void disable_write_zeroes(struct mapped_device *md);
 

commit 6a23e05c2fe3c64ec012fd81e51e3ab51e4f2f9f
Author: Jens Axboe <axboe@kernel.dk>
Date:   Wed Oct 10 20:49:26 2018 -0600

    dm: remove legacy request-based IO path
    
    dm supports both, and since we're killing off the legacy path in
    general, get rid of it in dm.
    
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
index 7d480c930eaf..224d44503a06 100644
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@ -112,18 +112,8 @@ struct mapped_device {
 
 	struct dm_stats stats;
 
-	struct kthread_worker kworker;
-	struct task_struct *kworker_task;
-
-	/* for request-based merge heuristic in dm_request_fn() */
-	unsigned seq_rq_merge_deadline_usecs;
-	int last_rq_rw;
-	sector_t last_rq_pos;
-	ktime_t last_rq_start_time;
-
 	/* for blk-mq request-based DM support */
 	struct blk_mq_tag_set *tag_set;
-	bool use_blk_mq:1;
 	bool init_tio_pdu:1;
 
 	struct srcu_struct io_barrier;

commit 72d711c8768805b5f8cf2d23c575dfd188993e12
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Tue May 22 18:26:20 2018 -0400

    dm: adjust structure members to improve alignment
    
    Eliminate most holes in DM data structures that were modified by
    commit 6f1c819c21 ("dm: convert to bioset_init()/mempool_init()").
    Also prevent structure members from unnecessarily spanning cache
    lines.
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
index f21c5d21bf1b..7d480c930eaf 100644
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@ -31,6 +31,9 @@ struct dm_kobject_holder {
 struct mapped_device {
 	struct mutex suspend_lock;
 
+	struct mutex table_devices_lock;
+	struct list_head table_devices;
+
 	/*
 	 * The current mapping (struct dm_table *).
 	 * Use dm_get_live_table{_fast} or take suspend_lock for
@@ -38,17 +41,14 @@ struct mapped_device {
 	 */
 	void __rcu *map;
 
-	struct list_head table_devices;
-	struct mutex table_devices_lock;
-
 	unsigned long flags;
 
-	struct request_queue *queue;
-	int numa_node_id;
-
-	enum dm_queue_mode type;
 	/* Protect queue and type against concurrent access. */
 	struct mutex type_lock;
+	enum dm_queue_mode type;
+
+	int numa_node_id;
+	struct request_queue *queue;
 
 	atomic_t holders;
 	atomic_t open_count;
@@ -56,21 +56,21 @@ struct mapped_device {
 	struct dm_target *immutable_target;
 	struct target_type *immutable_target_type;
 
+	char name[16];
 	struct gendisk *disk;
 	struct dax_device *dax_dev;
-	char name[16];
-
-	void *interface_ptr;
 
 	/*
 	 * A list of ios that arrived while we were suspended.
 	 */
-	atomic_t pending[2];
-	wait_queue_head_t wait;
 	struct work_struct work;
+	wait_queue_head_t wait;
+	atomic_t pending[2];
 	spinlock_t deferred_lock;
 	struct bio_list deferred;
 
+	void *interface_ptr;
+
 	/*
 	 * Event handling.
 	 */
@@ -83,17 +83,17 @@ struct mapped_device {
 	/* the number of internal suspends */
 	unsigned internal_suspend_count;
 
-	/*
-	 * Processing queue (flush)
-	 */
-	struct workqueue_struct *wq;
-
 	/*
 	 * io objects are allocated from here.
 	 */
 	struct bio_set io_bs;
 	struct bio_set bs;
 
+	/*
+	 * Processing queue (flush)
+	 */
+	struct workqueue_struct *wq;
+
 	/*
 	 * freeze/thaw support require holding onto a super block
 	 */
@@ -102,11 +102,11 @@ struct mapped_device {
 	/* forced geometry settings */
 	struct hd_geometry geometry;
 
-	struct block_device *bdev;
-
 	/* kobject and completion */
 	struct dm_kobject_holder kobj_holder;
 
+	struct block_device *bdev;
+
 	/* zero-length flush that will be cloned and submitted to targets */
 	struct bio flush_bio;
 

commit 6f1c819c219f7841079f0f43ab62727a55b0d849
Author: Kent Overstreet <kent.overstreet@gmail.com>
Date:   Sun May 20 18:25:53 2018 -0400

    dm: convert to bioset_init()/mempool_init()
    
    Convert dm to embedded bio sets.
    
    Acked-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Kent Overstreet <kent.overstreet@gmail.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
index 3222e21cbbf8..f21c5d21bf1b 100644
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@ -91,8 +91,8 @@ struct mapped_device {
 	/*
 	 * io objects are allocated from here.
 	 */
-	struct bio_set *io_bs;
-	struct bio_set *bs;
+	struct bio_set io_bs;
+	struct bio_set bs;
 
 	/*
 	 * freeze/thaw support require holding onto a super block

commit c12c9a3c3860c76ba273798c0c34c6f1294cc759
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Fri Jan 12 09:32:21 2018 -0500

    dm: various cleanups to md->queue initialization code
    
    Also, add dm_sysfs_init() error handling to dm_create().
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
index 124ffa2d6b9a..3222e21cbbf8 100644
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@ -129,8 +129,6 @@ struct mapped_device {
 	struct srcu_struct io_barrier;
 };
 
-void dm_init_md_queue(struct mapped_device *md);
-void dm_init_normal_md_queue(struct mapped_device *md);
 int md_in_flight(struct mapped_device *md);
 void disable_write_same(struct mapped_device *md);
 void disable_write_zeroes(struct mapped_device *md);

commit dde1e1ec4c08c3b7a4cee6cdad53948680d9fe39
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Mon Dec 11 23:28:13 2017 -0500

    dm: remove now unused bio-based io_pool and _io_cache
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
index 8a7dc8f9e40f..124ffa2d6b9a 100644
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@ -92,8 +92,6 @@ struct mapped_device {
 	 * io objects are allocated from here.
 	 */
 	struct bio_set *io_bs;
-	mempool_t *io_pool;
-
 	struct bio_set *bs;
 
 	/*

commit 64f52b0e31489b46465cff2e61ab2e1f60a3b4eb
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Mon Dec 11 23:17:47 2017 -0500

    dm: improve performance by moving dm_io structure to per-bio-data
    
    Eliminates need for a separate mempool to allocate 'struct dm_io'
    objects from.  As such, it saves an extra mempool allocation for each
    original bio that DM core is issued.
    
    This complicates the per-bio-data accessor functions by needing to
    conditonally add extra padding to get to a target's per-bio-data.  But
    in the end this provides a decent performance improvement for all
    bio-based DM devices.
    
    On an NVMe-loop based testbed to a ramdisk (~3100 MB/s): bio-based
    DM linear performance improved by 2% (went from 2665 to 2777 MB/s).
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
index 6a14f945783c..8a7dc8f9e40f 100644
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@ -91,6 +91,7 @@ struct mapped_device {
 	/*
 	 * io objects are allocated from here.
 	 */
+	struct bio_set *io_bs;
 	mempool_t *io_pool;
 
 	struct bio_set *bs;

commit 856eb0916d181da6d043cc33e03f54d5c5bbe54a
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Tue Oct 31 19:33:02 2017 -0400

    dm: allocate struct mapped_device with kvzalloc
    
    The structure srcu_struct can be very big, its size is proportional to the
    value CONFIG_NR_CPUS. The Fedora kernel has CONFIG_NR_CPUS 8192, the field
    io_barrier in the struct mapped_device has 84kB in the debugging kernel
    and 50kB in the non-debugging kernel. The large size may result in failure
    of the function kzalloc_node.
    
    In order to avoid the allocation failure, we use the function
    kvzalloc_node, this function falls back to vmalloc if a large contiguous
    chunk of memory is not available. This patch also moves the field
    io_barrier to the last position of struct mapped_device - the reason is
    that on many processor architectures, short memory offsets result in
    smaller code than long memory offsets - on x86-64 it reduces code size by
    320 bytes.
    
    Note to stable kernel maintainers - the kernels 4.11 and older don't have
    the function kvzalloc_node, you can use the function vzalloc_node instead.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
index 203144762f36..6a14f945783c 100644
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@ -29,7 +29,6 @@ struct dm_kobject_holder {
  * DM targets must _not_ deference a mapped_device to directly access its members!
  */
 struct mapped_device {
-	struct srcu_struct io_barrier;
 	struct mutex suspend_lock;
 
 	/*
@@ -127,6 +126,8 @@ struct mapped_device {
 	struct blk_mq_tag_set *tag_set;
 	bool use_blk_mq:1;
 	bool init_tio_pdu:1;
+
+	struct srcu_struct io_barrier;
 };
 
 void dm_init_md_queue(struct mapped_device *md);

commit 62e082430ea4bb5b28909ca4375bb683931e22aa
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Wed Sep 20 07:29:49 2017 -0400

    dm ioctl: fix alignment of event number in the device list
    
    The size of struct dm_name_list is different on 32-bit and 64-bit
    kernels (so "(nl + 1)" differs between 32-bit and 64-bit kernels).
    
    This mismatch caused some harmless difference in padding when using 32-bit
    or 64-bit kernel. Commit 23d70c5e52dd ("dm ioctl: report event number in
    DM_LIST_DEVICES") added reporting event number in the output of
    DM_LIST_DEVICES_CMD. This difference in padding makes it impossible for
    userspace to determine the location of the event number (the location
    would be different when running on 32-bit and 64-bit kernels).
    
    Fix the padding by using offsetof(struct dm_name_list, name) instead of
    sizeof(struct dm_name_list) to determine the location of entries.
    
    Also, the ioctl version number is incremented to 37 so that userspace
    can use the version number to determine that the event number is present
    and correctly located.
    
    In addition, a global event is now raised when a DM device is created,
    removed, renamed or when table is swapped, so that the user can monitor
    for device changes.
    
    Reported-by: Eugene Syromiatnikov <esyr@redhat.com>
    Fixes: 23d70c5e52dd ("dm ioctl: report event number in DM_LIST_DEVICES")
    Cc: stable@vger.kernel.org # 4.13
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
index 24eddbdf2ab4..203144762f36 100644
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@ -149,5 +149,6 @@ static inline bool dm_message_test_buffer_overflow(char *result, unsigned maxlen
 
 extern atomic_t dm_global_event_nr;
 extern wait_queue_head_t dm_global_eventq;
+void dm_issue_global_event(void);
 
 #endif

commit 93e6442c76a0d26ad028c5df9b4a1e3096d9c36b
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Mon Jan 16 16:05:59 2017 -0500

    dm: add basic support for using the select or poll function
    
    Add the ability to poll on the /dev/mapper/control device.  The select
    or poll function waits until any event happens on any dm device since
    opening the /dev/mapper/control device.  When select or poll returns the
    device as readable, we must close and reopen the device to wait for new
    dm events.
    
    Usage:
    1. open the /dev/mapper/control device
    2. scan the event numbers of all devices we are interested in and process
       them
    3. call select, poll or epoll on the handle (it waits until some new event
       happens since opening the device)
    4. close the /dev/mapper/control handle
    5. go to step 1
    
    The next commit allows to re-arm the polling without closing and
    reopening the device.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Andy Grover <agrover@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
index 52ca8d059e82..24eddbdf2ab4 100644
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@ -147,4 +147,7 @@ static inline bool dm_message_test_buffer_overflow(char *result, unsigned maxlen
 	return !maxlen || strlen(result) + 1 >= maxlen;
 }
 
+extern atomic_t dm_global_event_nr;
+extern wait_queue_head_t dm_global_eventq;
+
 #endif

commit 53ef7d0e208fa38c3f63d287e0c3ab174f1e1235
Merge: c6a677c6f37b 736163671bcb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 5 18:49:20 2017 -0700

    Merge tag 'libnvdimm-for-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm
    
    Pull libnvdimm updates from Dan Williams:
     "The bulk of this has been in multiple -next releases. There were a few
      late breaking fixes and small features that got added in the last
      couple days, but the whole set has received a build success
      notification from the kbuild robot.
    
      Change summary:
    
       - Region media error reporting: A libnvdimm region device is the
         parent to one or more namespaces. To date, media errors have been
         reported via the "badblocks" attribute attached to pmem block
         devices for namespaces in "raw" or "memory" mode. Given that
         namespaces can be in "device-dax" or "btt-sector" mode this new
         interface reports media errors generically, i.e. independent of
         namespace modes or state.
    
         This subsequently allows userspace tooling to craft "ACPI 6.1
         Section 9.20.7.6 Function Index 4 - Clear Uncorrectable Error"
         requests and submit them via the ioctl path for NVDIMM root bus
         devices.
    
       - Introduce 'struct dax_device' and 'struct dax_operations': Prompted
         by a request from Linus and feedback from Christoph this allows for
         dax capable drivers to publish their own custom dax operations.
         This fixes the broken assumption that all dax operations are
         related to a persistent memory device, and makes it easier for
         other architectures and platforms to add customized persistent
         memory support.
    
       - 'libnvdimm' core updates: A new "deep_flush" sysfs attribute is
         available for storage appliance applications to manually trigger
         memory controllers to drain write-pending buffers that would
         otherwise be flushed automatically by the platform ADR
         (asynchronous-DRAM-refresh) mechanism at a power loss event.
         Support for "locked" DIMMs is included to prevent namespaces from
         surfacing when the namespace label data area is locked. Finally,
         fixes for various reported deadlocks and crashes, also tagged for
         -stable.
    
       - ACPI / nfit driver updates: General updates of the nfit driver to
         add DSM command overrides, ACPI 6.1 health state flags support, DSM
         payload debug available by default, and various fixes.
    
      Acknowledgements that came after the branch was pushed:
    
       - commmit 565851c972b5 "device-dax: fix sysfs attribute deadlock":
         Tested-by: Yi Zhang <yizhan@redhat.com>
    
       - commit 23f498448362 "libnvdimm: rework region badblocks clearing"
         Tested-by: Toshi Kani <toshi.kani@hpe.com>"
    
    * tag 'libnvdimm-for-4.12' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm: (52 commits)
      libnvdimm, pfn: fix 'npfns' vs section alignment
      libnvdimm: handle locked label storage areas
      libnvdimm: convert NDD_ flags to use bitops, introduce NDD_LOCKED
      brd: fix uninitialized use of brd->dax_dev
      block, dax: use correct format string in bdev_dax_supported
      device-dax: fix sysfs attribute deadlock
      libnvdimm: restore "libnvdimm: band aid btt vs clear poison locking"
      libnvdimm: fix nvdimm_bus_lock() vs device_lock() ordering
      libnvdimm: rework region badblocks clearing
      acpi, nfit: kill ACPI_NFIT_DEBUG
      libnvdimm: fix clear length of nvdimm_forget_poison()
      libnvdimm, pmem: fix a NULL pointer BUG in nd_pmem_notify
      libnvdimm, region: sysfs trigger for nvdimm_flush()
      libnvdimm: fix phys_addr for nvdimm_clear_poison
      x86, dax, pmem: remove indirection around memcpy_from_pmem()
      block: remove block_device_operations ->direct_access()
      block, dax: convert bdev_dax_supported() to dax_direct_access()
      filesystem-dax: convert to dax_direct_access()
      Revert "block: use DAX for partition table reads"
      ext2, ext4, xfs: retrieve dax_device for iomap operations
      ...

commit d35a878ae1c50977b55e352fd46e36e35add72a0
Merge: e5021876c91d 390020ad2af9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 3 10:31:20 2017 -0700

    Merge tag 'for-4.12/dm-changes' of git://git.kernel.org/pub/scm/linux/kernel/git/device-mapper/linux-dm
    
    Pull device mapper updates from Mike Snitzer:
    
     - A major update for DM cache that reduces the latency for deciding
       whether blocks should migrate to/from the cache. The bio-prison-v2
       interface supports this improvement by enabling direct dispatch of
       work to workqueues rather than having to delay the actual work
       dispatch to the DM cache core. So the dm-cache policies are much more
       nimble by being able to drive IO as they see fit. One immediate
       benefit from the improved latency is a cache that should be much more
       adaptive to changing workloads.
    
     - Add a new DM integrity target that emulates a block device that has
       additional per-sector tags that can be used for storing integrity
       information.
    
     - Add a new authenticated encryption feature to the DM crypt target
       that builds on the capabilities provided by the DM integrity target.
    
     - Add MD interface for switching the raid4/5/6 journal mode and update
       the DM raid target to use it to enable aid4/5/6 journal write-back
       support.
    
     - Switch the DM verity target over to using the asynchronous hash
       crypto API (this helps work better with architectures that have
       access to off-CPU algorithm providers, which should reduce CPU
       utilization).
    
     - Various request-based DM and DM multipath fixes and improvements from
       Bart and Christoph.
    
     - A DM thinp target fix for a bio structure leak that occurs for each
       discard IFF discard passdown is enabled.
    
     - A fix for a possible deadlock in DM bufio and a fix to re-check the
       new buffer allocation watermark in the face of competing admin
       changes to the 'max_cache_size_bytes' tunable.
    
     - A couple DM core cleanups.
    
    * tag 'for-4.12/dm-changes' of git://git.kernel.org/pub/scm/linux/kernel/git/device-mapper/linux-dm: (50 commits)
      dm bufio: check new buffer allocation watermark every 30 seconds
      dm bufio: avoid a possible ABBA deadlock
      dm mpath: make it easier to detect unintended I/O request flushes
      dm mpath: cleanup QUEUE_IF_NO_PATH bit manipulation by introducing assign_bit()
      dm mpath: micro-optimize the hot path relative to MPATHF_QUEUE_IF_NO_PATH
      dm: introduce enum dm_queue_mode to cleanup related code
      dm mpath: verify __pg_init_all_paths locking assumptions at runtime
      dm: verify suspend_locking assumptions at runtime
      dm block manager: remove an unused argument from dm_block_manager_create()
      dm rq: check blk_mq_register_dev() return value in dm_mq_init_request_queue()
      dm mpath: delay requeuing while path initialization is in progress
      dm mpath: avoid that path removal can trigger an infinite loop
      dm mpath: split and rename activate_path() to prepare for its expanded use
      dm ioctl: prevent stack leak in dm ioctl call
      dm integrity: use previously calculated log2 of sectors_per_block
      dm integrity: use hex2bin instead of open-coded variant
      dm crypt: replace custom implementation of hex2bin()
      dm crypt: remove obsolete references to per-CPU state
      dm verity: switch to using asynchronous hash crypto API
      dm crypt: use WQ_HIGHPRI for the IO and crypt workqueues
      ...

commit 7e0d574f2683a2346c978613a72ff07afc89b17a
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Thu Apr 27 10:11:23 2017 -0700

    dm: introduce enum dm_queue_mode to cleanup related code
    
    Introduce an enumeration type for the queue mode.  This patch does
    not change any functionality but makes the DM code easier to read.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
index 136fda3ff9e5..b92f74d9a982 100644
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@ -47,7 +47,7 @@ struct mapped_device {
 	struct request_queue *queue;
 	int numa_node_id;
 
-	unsigned type;
+	enum dm_queue_mode type;
 	/* Protect queue and type against concurrent access. */
 	struct mutex type_lock;
 

commit f26c5719b2d7b00de69eb83eb1c1c831759fdc9b
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed Apr 12 12:35:44 2017 -0700

    dm: add dax_device and dax_operations support
    
    Allocate a dax_device to represent the capacity of a device-mapper
    instance. Provide a ->direct_access() method via the new dax_operations
    indirection that mirrors the functionality of the current direct_access
    support via block_device_operations.  Once fs/dax.c has been converted
    to use dax_operations the old dm_blk_direct_access() will be removed.
    
    A new helper dm_dax_get_live_target() is introduced to separate some of
    the dm-specifics from the direct_access implementation.
    
    This enabling is only for the top-level dm representation to upper
    layers. Converting target direct_access implementations is deferred to a
    separate patch.
    
    Cc: Toshi Kani <toshi.kani@hpe.com>
    Reviewed-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
index 136fda3ff9e5..538630190f66 100644
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@ -58,6 +58,7 @@ struct mapped_device {
 	struct target_type *immutable_target_type;
 
 	struct gendisk *disk;
+	struct dax_device *dax_dev;
 	char name[16];
 
 	void *interface_ptr;

commit ac62d6208a7977107a47be4eb8566d6e5034b5f5
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Apr 5 19:21:05 2017 +0200

    dm: support REQ_OP_WRITE_ZEROES
    
    Copy & paste from the REQ_OP_WRITE_SAME code.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
index 136fda3ff9e5..fea5bd52ada8 100644
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@ -132,6 +132,7 @@ void dm_init_md_queue(struct mapped_device *md);
 void dm_init_normal_md_queue(struct mapped_device *md);
 int md_in_flight(struct mapped_device *md);
 void disable_write_same(struct mapped_device *md);
+void disable_write_zeroes(struct mapped_device *md);
 
 static inline struct completion *dm_get_completion_from_kobject(struct kobject *kobj)
 {

commit eb8db831be80692bf4bda3dfc55001daf64ec299
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Jan 22 18:32:46 2017 +0100

    dm: always defer request allocation to the owner of the request_queue
    
    DM already calls blk_mq_alloc_request on the request_queue of the
    underlying device if it is a blk-mq device.  But now that we allow drivers
    to allocate additional data and initialize it ahead of time we need to do
    the same for all drivers.   Doing so and using the new cmd_size
    infrastructure in the block layer greatly simplifies the dm-rq and mpath
    code, and should also make arbitrary combinations of SQ and MQ devices
    with SQ or MQ device mapper tables easily possible as a further step.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
index 40ceba1fe8be..136fda3ff9e5 100644
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@ -92,7 +92,6 @@ struct mapped_device {
 	 * io objects are allocated from here.
 	 */
 	mempool_t *io_pool;
-	mempool_t *rq_pool;
 
 	struct bio_set *bs;
 

commit 4cc96131afce3eaae7c13dff41c6ba771cf10e96
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Thu May 12 16:28:10 2016 -0400

    dm: move request-based code out to dm-rq.[hc]
    
    Add some seperation between bio-based and request-based DM core code.
    
    'struct mapped_device' and other DM core only structures and functions
    have been moved to dm-core.h and all relevant DM core .c files have been
    updated to include dm-core.h rather than dm.h
    
    DM targets should _never_ include dm-core.h!
    
    [block core merge conflict resolution from Stephen Rothwell]
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>

diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h
new file mode 100644
index 000000000000..40ceba1fe8be
--- /dev/null
+++ b/drivers/md/dm-core.h
@@ -0,0 +1,149 @@
+/*
+ * Internal header file _only_ for device mapper core
+ *
+ * Copyright (C) 2016 Red Hat, Inc. All rights reserved.
+ *
+ * This file is released under the LGPL.
+ */
+
+#ifndef DM_CORE_INTERNAL_H
+#define DM_CORE_INTERNAL_H
+
+#include <linux/kthread.h>
+#include <linux/ktime.h>
+#include <linux/blk-mq.h>
+
+#include <trace/events/block.h>
+
+#include "dm.h"
+
+#define DM_RESERVED_MAX_IOS		1024
+
+struct dm_kobject_holder {
+	struct kobject kobj;
+	struct completion completion;
+};
+
+/*
+ * DM core internal structure that used directly by dm.c and dm-rq.c
+ * DM targets must _not_ deference a mapped_device to directly access its members!
+ */
+struct mapped_device {
+	struct srcu_struct io_barrier;
+	struct mutex suspend_lock;
+
+	/*
+	 * The current mapping (struct dm_table *).
+	 * Use dm_get_live_table{_fast} or take suspend_lock for
+	 * dereference.
+	 */
+	void __rcu *map;
+
+	struct list_head table_devices;
+	struct mutex table_devices_lock;
+
+	unsigned long flags;
+
+	struct request_queue *queue;
+	int numa_node_id;
+
+	unsigned type;
+	/* Protect queue and type against concurrent access. */
+	struct mutex type_lock;
+
+	atomic_t holders;
+	atomic_t open_count;
+
+	struct dm_target *immutable_target;
+	struct target_type *immutable_target_type;
+
+	struct gendisk *disk;
+	char name[16];
+
+	void *interface_ptr;
+
+	/*
+	 * A list of ios that arrived while we were suspended.
+	 */
+	atomic_t pending[2];
+	wait_queue_head_t wait;
+	struct work_struct work;
+	spinlock_t deferred_lock;
+	struct bio_list deferred;
+
+	/*
+	 * Event handling.
+	 */
+	wait_queue_head_t eventq;
+	atomic_t event_nr;
+	atomic_t uevent_seq;
+	struct list_head uevent_list;
+	spinlock_t uevent_lock; /* Protect access to uevent_list */
+
+	/* the number of internal suspends */
+	unsigned internal_suspend_count;
+
+	/*
+	 * Processing queue (flush)
+	 */
+	struct workqueue_struct *wq;
+
+	/*
+	 * io objects are allocated from here.
+	 */
+	mempool_t *io_pool;
+	mempool_t *rq_pool;
+
+	struct bio_set *bs;
+
+	/*
+	 * freeze/thaw support require holding onto a super block
+	 */
+	struct super_block *frozen_sb;
+
+	/* forced geometry settings */
+	struct hd_geometry geometry;
+
+	struct block_device *bdev;
+
+	/* kobject and completion */
+	struct dm_kobject_holder kobj_holder;
+
+	/* zero-length flush that will be cloned and submitted to targets */
+	struct bio flush_bio;
+
+	struct dm_stats stats;
+
+	struct kthread_worker kworker;
+	struct task_struct *kworker_task;
+
+	/* for request-based merge heuristic in dm_request_fn() */
+	unsigned seq_rq_merge_deadline_usecs;
+	int last_rq_rw;
+	sector_t last_rq_pos;
+	ktime_t last_rq_start_time;
+
+	/* for blk-mq request-based DM support */
+	struct blk_mq_tag_set *tag_set;
+	bool use_blk_mq:1;
+	bool init_tio_pdu:1;
+};
+
+void dm_init_md_queue(struct mapped_device *md);
+void dm_init_normal_md_queue(struct mapped_device *md);
+int md_in_flight(struct mapped_device *md);
+void disable_write_same(struct mapped_device *md);
+
+static inline struct completion *dm_get_completion_from_kobject(struct kobject *kobj)
+{
+	return &container_of(kobj, struct dm_kobject_holder, kobj)->completion;
+}
+
+unsigned __dm_get_module_param(unsigned *module_param, unsigned def, unsigned max);
+
+static inline bool dm_message_test_buffer_overflow(char *result, unsigned maxlen)
+{
+	return !maxlen || strlen(result) + 1 >= maxlen;
+}
+
+#endif
