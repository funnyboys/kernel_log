commit 123d87d553e26f67e7be318c97c971b6b5fb1daa
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Fri Aug 23 09:55:26 2019 -0400

    dm: make dm_table_find_target return NULL
    
    Currently, if we pass too high sector number to dm_table_find_target, it
    returns zeroed dm_target structure and callers test if the structure is
    zeroed with the macro dm_target_is_valid.
    
    However, returning NULL is common practice to indicate errors.
    
    This patch refactors the dm code, so that dm_table_find_target returns
    NULL and its callers test the returned value for NULL. The macro
    dm_target_is_valid is deleted. In alloc_targets, we no longer allocate an
    extra zeroed target.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 0475673337f3..d7c4f6606b5f 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -85,11 +85,6 @@ struct target_type *dm_get_immutable_target_type(struct mapped_device *md);
 
 int dm_setup_md_queue(struct mapped_device *md, struct dm_table *t);
 
-/*
- * To check the return value from dm_table_find_target().
- */
-#define dm_target_is_valid(t) ((t)->table)
-
 /*
  * To check whether the target type is bio-based or not (request-based).
  */

commit 2e9ee0955d3c2d3db56aa02ba6f948ba35d5e9c1
Author: Pankaj Gupta <pagupta@redhat.com>
Date:   Fri Jul 5 19:33:25 2019 +0530

    dm: enable synchronous dax
    
    This patch sets dax device 'DAXDEV_SYNC' flag if all the target
    devices of device mapper support synchrononous DAX. If device
    mapper consists of both synchronous and asynchronous dax devices,
    we don't set 'DAXDEV_SYNC' flag.
    
    'dm_table_supports_dax' is refactored to pass 'iterate_devices_fn'
    as argument so that the callers can pass the appropriate functions.
    
    Suggested-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Pankaj Gupta <pagupta@redhat.com>
    Reviewed-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 17e3db54404c..0475673337f3 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -72,7 +72,10 @@ bool dm_table_bio_based(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);
 void dm_table_free_md_mempools(struct dm_table *t);
 struct dm_md_mempools *dm_table_get_md_mempools(struct dm_table *t);
-bool dm_table_supports_dax(struct dm_table *t, int blocksize);
+bool dm_table_supports_dax(struct dm_table *t, iterate_devices_callout_fn fn,
+			   int *blocksize);
+int device_supports_dax(struct dm_target *ti, struct dm_dev *dev,
+			   sector_t start, sector_t len, void *data);
 
 void dm_lock_md_type(struct mapped_device *md);
 void dm_unlock_md_type(struct mapped_device *md);

commit 7bf7eac8d648057519adb6fce1e31458c902212c
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu May 16 13:26:29 2019 -0700

    dax: Arrange for dax_supported check to span multiple devices
    
    Pankaj reports that starting with commit ad428cdb525a "dax: Check the
    end of the block-device capacity with dax_direct_access()" device-mapper
    no longer allows dax operation. This results from the stricter checks in
    __bdev_dax_supported() that validate that the start and end of a
    block-device map to the same 'pagemap' instance.
    
    Teach the dax-core and device-mapper to validate the 'pagemap' on a
    per-target basis. This is accomplished by refactoring the
    bdev_dax_supported() internals into generic_fsdax_supported() which
    takes a sector range to validate. Consequently generic_fsdax_supported()
    is suitable to be used in a device-mapper ->iterate_devices() callback.
    A new ->dax_supported() operation is added to allow composite devices to
    split and route upper-level bdev_dax_supported() requests.
    
    Fixes: ad428cdb525a ("dax: Check the end of the block-device...")
    Cc: <stable@vger.kernel.org>
    Cc: Ira Weiny <ira.weiny@intel.com>
    Cc: Dave Jiang <dave.jiang@intel.com>
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Vishal Verma <vishal.l.verma@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Reported-by: Pankaj Gupta <pagupta@redhat.com>
    Reviewed-by: Pankaj Gupta <pagupta@redhat.com>
    Tested-by: Pankaj Gupta <pagupta@redhat.com>
    Tested-by: Vaibhav Jain <vaibhav@linux.ibm.com>
    Reviewed-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 2d539b82ec08..17e3db54404c 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -72,6 +72,7 @@ bool dm_table_bio_based(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);
 void dm_table_free_md_mempools(struct dm_table *t);
 struct dm_md_mempools *dm_table_get_md_mempools(struct dm_table *t);
+bool dm_table_supports_dax(struct dm_table *t, int blocksize);
 
 void dm_lock_md_type(struct mapped_device *md);
 void dm_unlock_md_type(struct mapped_device *md);

commit 6a23e05c2fe3c64ec012fd81e51e3ab51e4f2f9f
Author: Jens Axboe <axboe@kernel.dk>
Date:   Wed Oct 10 20:49:26 2018 -0600

    dm: remove legacy request-based IO path
    
    dm supports both, and since we're killing off the legacy path in
    general, get rid of it in dm.
    
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 114a81b27c37..2d539b82ec08 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -70,7 +70,6 @@ struct dm_target *dm_table_get_immutable_target(struct dm_table *t);
 struct dm_target *dm_table_get_wildcard_target(struct dm_table *t);
 bool dm_table_bio_based(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);
-bool dm_table_all_blk_mq_devices(struct dm_table *t);
 void dm_table_free_md_mempools(struct dm_table *t);
 struct dm_md_mempools *dm_table_get_md_mempools(struct dm_table *t);
 

commit f6e7baadd96bd746d3fb584959d3f152189d05e1
Author: Brian Norris <briannorris@chromium.org>
Date:   Tue Mar 28 11:31:02 2017 -0700

    dm: move dm_table_destroy() to same header as dm_table_create()
    
    If anyone is going to use dm_table_create(), they probably should be
    able to use dm_table_destroy() too. Move the dm_table_destroy()
    definition outside the private header, near dm_table_create()
    
    Signed-off-by: Brian Norris <briannorris@chromium.org>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 7c66c316add3..114a81b27c37 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -49,7 +49,6 @@ struct dm_md_mempools;
 /*-----------------------------------------------------------------
  * Internal table functions.
  *---------------------------------------------------------------*/
-void dm_table_destroy(struct dm_table *t);
 void dm_table_event_callback(struct dm_table *t,
 			     void (*fn)(void *), void *context);
 struct dm_target *dm_table_get_target(struct dm_table *t, unsigned int index);

commit 0776aa0e30aa31b2fad606457e9d3faf39d88314
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Fri Dec 8 14:40:52 2017 -0500

    dm: ensure bio-based DM's bioset and io_pool support targets' maximum IOs
    
    alloc_multiple_bios() assumes it can allocate the requested number of
    bios but until now there was no gaurantee that the mempools would be
    accomodating.
    
    Suggested-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 36399bb875dd..7c66c316add3 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -206,7 +206,8 @@ void dm_kcopyd_exit(void);
  * Mempool operations
  */
 struct dm_md_mempools *dm_alloc_md_mempools(struct mapped_device *md, enum dm_queue_mode type,
-					    unsigned integrity, unsigned per_bio_data_size);
+					    unsigned integrity, unsigned per_bio_data_size,
+					    unsigned min_pool_size);
 void dm_free_md_mempools(struct dm_md_mempools *pools);
 
 /*

commit 2a0b4682e09d76466f7b8f5e347ae2ff02f033af
Author: Elena Reshetova <elena.reshetova@intel.com>
Date:   Fri Oct 20 10:37:38 2017 +0300

    dm: convert dm_dev_internal.count from atomic_t to refcount_t
    
    atomic_t variables are currently used to implement reference
    counters with the following properties:
     - counter is initialized to 1 using atomic_set()
     - a resource is freed upon counter reaching zero
     - once counter reaches zero, its further
       increments aren't allowed
     - counter schema uses basic atomic operations
       (set, inc, inc_not_zero, dec_and_test, etc.)
    
    Such atomic variables should be converted to a newly provided
    refcount_t type and API that prevents accidental counter overflows
    and underflows. This is important since overflows and underflows
    can lead to use-after-free situation and be exploitable.
    
    The variable dm_dev_internal.count is used as pure reference counter.
    Convert it to refcount_t and fix up the operations.
    
    Suggested-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: David Windsor <dwindsor@gmail.com>
    Reviewed-by: Hans Liljestrand <ishkamiel@gmail.com>
    Signed-off-by: Elena Reshetova <elena.reshetova@intel.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 38c84c0a35d4..36399bb875dd 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -19,6 +19,7 @@
 #include <linux/hdreg.h>
 #include <linux/completion.h>
 #include <linux/kobject.h>
+#include <linux/refcount.h>
 
 #include "dm-stats.h"
 
@@ -38,7 +39,7 @@
  */
 struct dm_dev_internal {
 	struct list_head list;
-	atomic_t count;
+	refcount_t count;
 	struct dm_dev *dm_dev;
 };
 

commit 7e0d574f2683a2346c978613a72ff07afc89b17a
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Thu Apr 27 10:11:23 2017 -0700

    dm: introduce enum dm_queue_mode to cleanup related code
    
    Introduce an enumeration type for the queue mode.  This patch does
    not change any functionality but makes the DM code easier to read.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index f298b01f7ab3..38c84c0a35d4 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -64,7 +64,7 @@ void dm_table_presuspend_undo_targets(struct dm_table *t);
 void dm_table_postsuspend_targets(struct dm_table *t);
 int dm_table_resume_targets(struct dm_table *t);
 int dm_table_any_congested(struct dm_table *t, int bdi_bits);
-unsigned dm_table_get_type(struct dm_table *t);
+enum dm_queue_mode dm_table_get_type(struct dm_table *t);
 struct target_type *dm_table_get_immutable_target_type(struct dm_table *t);
 struct dm_target *dm_table_get_immutable_target(struct dm_table *t);
 struct dm_target *dm_table_get_wildcard_target(struct dm_table *t);
@@ -76,8 +76,8 @@ struct dm_md_mempools *dm_table_get_md_mempools(struct dm_table *t);
 
 void dm_lock_md_type(struct mapped_device *md);
 void dm_unlock_md_type(struct mapped_device *md);
-void dm_set_md_type(struct mapped_device *md, unsigned type);
-unsigned dm_get_md_type(struct mapped_device *md);
+void dm_set_md_type(struct mapped_device *md, enum dm_queue_mode type);
+enum dm_queue_mode dm_get_md_type(struct mapped_device *md);
 struct target_type *dm_get_immutable_target_type(struct mapped_device *md);
 
 int dm_setup_md_queue(struct mapped_device *md, struct dm_table *t);
@@ -204,7 +204,7 @@ void dm_kcopyd_exit(void);
 /*
  * Mempool operations
  */
-struct dm_md_mempools *dm_alloc_md_mempools(struct mapped_device *md, unsigned type,
+struct dm_md_mempools *dm_alloc_md_mempools(struct mapped_device *md, enum dm_queue_mode type,
 					    unsigned integrity, unsigned per_bio_data_size);
 void dm_free_md_mempools(struct dm_md_mempools *pools);
 

commit eb8db831be80692bf4bda3dfc55001daf64ec299
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Jan 22 18:32:46 2017 +0100

    dm: always defer request allocation to the owner of the request_queue
    
    DM already calls blk_mq_alloc_request on the request_queue of the
    underlying device if it is a blk-mq device.  But now that we allow drivers
    to allocate additional data and initialize it ahead of time we need to do
    the same for all drivers.   Doing so and using the new cmd_size
    infrastructure in the block layer greatly simplifies the dm-rq and mpath
    code, and should also make arbitrary combinations of SQ and MQ devices
    with SQ or MQ device mapper tables easily possible as a further step.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index f0aad08b9654..f298b01f7ab3 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -95,8 +95,7 @@ int dm_setup_md_queue(struct mapped_device *md, struct dm_table *t);
 /*
  * To check whether the target type is request-based or not (bio-based).
  */
-#define dm_target_request_based(t) (((t)->type->map_rq != NULL) || \
-				    ((t)->type->clone_and_map_rq != NULL))
+#define dm_target_request_based(t) ((t)->type->clone_and_map_rq != NULL)
 
 /*
  * To check whether the target type is a hybrid (capable of being

commit 545ed20e6df68a4d2584a29a2a28ee8b2f7e9547
Author: Toshi Kani <toshi.kani@hpe.com>
Date:   Wed Jun 22 17:54:53 2016 -0600

    dm: add infrastructure for DAX support
    
    Change mapped device to implement direct_access function,
    dm_blk_direct_access(), which calls a target direct_access function.
    'struct target_type' is extended to have target direct_access interface.
    This function limits direct accessible size to the dm_target's limit
    with max_io_len().
    
    Add dm_table_supports_dax() to iterate all targets and associated block
    devices to check for DAX support.  To add DAX support to a DM target the
    target must only implement the direct_access function.
    
    Add a new dm type, DM_TYPE_DAX_BIO_BASED, which indicates that mapped
    device supports DAX and is bio based.  This new type is used to assure
    that all target devices have DAX support and remain that way after
    QUEUE_FLAG_DAX is set in mapped device.
    
    At initial table load, QUEUE_FLAG_DAX is set to mapped device when setting
    DM_TYPE_DAX_BIO_BASED to the type.  Any subsequent table load to the
    mapped device must have the same type, or else it fails per the check in
    table_load().
    
    Signed-off-by: Toshi Kani <toshi.kani@hpe.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 2e0e4a53a312..f0aad08b9654 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -68,6 +68,7 @@ unsigned dm_table_get_type(struct dm_table *t);
 struct target_type *dm_table_get_immutable_target_type(struct dm_table *t);
 struct dm_target *dm_table_get_immutable_target(struct dm_table *t);
 struct dm_target *dm_table_get_wildcard_target(struct dm_table *t);
+bool dm_table_bio_based(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);
 bool dm_table_all_blk_mq_devices(struct dm_table *t);
 void dm_table_free_md_mempools(struct dm_table *t);

commit e83068a5faafb8ca65d3b58bd1e1e3959ce1ddce
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Tue May 24 21:16:51 2016 -0400

    dm mpath: add optional "queue_mode" feature
    
    Allow a user to specify an optional feature 'queue_mode <mode>' where
    <mode> may be "bio", "rq" or "mq" -- which corresponds to bio-based,
    request_fn rq-based, and blk-mq rq-based respectively.
    
    If the queue_mode feature isn't specified the default for the
    "multipath" target is still "rq" but if dm_mod.use_blk_mq is set to Y
    it'll default to mode "mq".
    
    This new queue_mode feature introduces the ability for each multipath
    device to have its own queue_mode (whereas before this feature all
    multipath devices effectively had to have the same queue_mode).
    
    This commit also goes a long way to eliminate the awkward (ab)use of
    DM_TYPE_*, the associated filter_md_type() and other relatively fragile
    and difficult to maintain code.
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index b611b3064a7c..2e0e4a53a312 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -33,14 +33,6 @@
  */
 #define DM_STATUS_NOFLUSH_FLAG		(1 << 0)
 
-/*
- * Type of table and mapped_device's mempool
- */
-#define DM_TYPE_NONE			0
-#define DM_TYPE_BIO_BASED		1
-#define DM_TYPE_REQUEST_BASED		2
-#define DM_TYPE_MQ_REQUEST_BASED	3
-
 /*
  * List of devices that a metadevice uses and should open/close.
  */
@@ -77,7 +69,7 @@ struct target_type *dm_table_get_immutable_target_type(struct dm_table *t);
 struct dm_target *dm_table_get_immutable_target(struct dm_table *t);
 struct dm_target *dm_table_get_wildcard_target(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);
-bool dm_table_mq_request_based(struct dm_table *t);
+bool dm_table_all_blk_mq_devices(struct dm_table *t);
 void dm_table_free_md_mempools(struct dm_table *t);
 struct dm_md_mempools *dm_table_get_md_mempools(struct dm_table *t);
 

commit 4cc96131afce3eaae7c13dff41c6ba771cf10e96
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Thu May 12 16:28:10 2016 -0400

    dm: move request-based code out to dm-rq.[hc]
    
    Add some seperation between bio-based and request-based DM core code.
    
    'struct mapped_device' and other DM core only structures and functions
    have been moved to dm-core.h and all relevant DM core .c files have been
    updated to include dm-core.h rather than dm.h
    
    DM targets should _never_ include dm-core.h!
    
    [block core merge conflict resolution from Stephen Rothwell]
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 13a758ec0f88..b611b3064a7c 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -13,6 +13,7 @@
 #include <linux/fs.h>
 #include <linux/device-mapper.h>
 #include <linux/list.h>
+#include <linux/moduleparam.h>
 #include <linux/blkdev.h>
 #include <linux/backing-dev.h>
 #include <linux/hdreg.h>
@@ -161,16 +162,6 @@ void dm_interface_exit(void);
 /*
  * sysfs interface
  */
-struct dm_kobject_holder {
-	struct kobject kobj;
-	struct completion completion;
-};
-
-static inline struct completion *dm_get_completion_from_kobject(struct kobject *kobj)
-{
-	return &container_of(kobj, struct dm_kobject_holder, kobj)->completion;
-}
-
 int dm_sysfs_init(struct mapped_device *md);
 void dm_sysfs_exit(struct mapped_device *md);
 struct kobject *dm_kobject(struct mapped_device *md);
@@ -212,8 +203,6 @@ int dm_kobject_uevent(struct mapped_device *md, enum kobject_action action,
 void dm_internal_suspend(struct mapped_device *md);
 void dm_internal_resume(struct mapped_device *md);
 
-bool dm_use_blk_mq(struct mapped_device *md);
-
 int dm_io_init(void);
 void dm_io_exit(void);
 
@@ -228,18 +217,8 @@ struct dm_md_mempools *dm_alloc_md_mempools(struct mapped_device *md, unsigned t
 void dm_free_md_mempools(struct dm_md_mempools *pools);
 
 /*
- * Helpers that are used by DM core
+ * Various helpers
  */
 unsigned dm_get_reserved_bio_based_ios(void);
-unsigned dm_get_reserved_rq_based_ios(void);
-
-static inline bool dm_message_test_buffer_overflow(char *result, unsigned maxlen)
-{
-	return !maxlen || strlen(result) + 1 >= maxlen;
-}
-
-ssize_t dm_attr_rq_based_seq_io_merge_deadline_show(struct mapped_device *md, char *buf);
-ssize_t dm_attr_rq_based_seq_io_merge_deadline_store(struct mapped_device *md,
-						     const char *buf, size_t count);
 
 #endif

commit 591ddcfc4bfad28e096787b1159942124d49cd1e
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Sun Jan 31 12:05:42 2016 -0500

    dm: allow immutable request-based targets to use blk-mq pdu
    
    This will allow DM multipath to use a portion of the blk-mq pdu space
    for target data (e.g. struct dm_mpath_io).
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 4305a513c801..13a758ec0f88 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -86,7 +86,7 @@ void dm_set_md_type(struct mapped_device *md, unsigned type);
 unsigned dm_get_md_type(struct mapped_device *md);
 struct target_type *dm_get_immutable_target_type(struct mapped_device *md);
 
-int dm_setup_md_queue(struct mapped_device *md);
+int dm_setup_md_queue(struct mapped_device *md, struct dm_table *t);
 
 /*
  * To check the return value from dm_table_find_target().

commit 16f122661dbb3dfefc60788b528b54ad702005aa
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Sun Jan 31 17:22:27 2016 -0500

    dm: optimize dm_mq_queue_rq()
    
    DM multipath is the only dm-mq target.  But that aside, request-based DM
    only supports tables with a single target that is immutable.  Leverage
    this fact in dm_mq_queue_rq() by using the 'immutable_target' stored in
    the mapped_device when the table was made active.  This saves the need
    to even take the read-side of the SRCU via dm_{get,put}_live_table.
    
    If the active DM table does not have an immutable target (e.g. "error"
    target was swapped in) then fallback to the slow-path where the target
    is looked up from the live table.
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 53df2585571b..4305a513c801 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -73,6 +73,7 @@ int dm_table_resume_targets(struct dm_table *t);
 int dm_table_any_congested(struct dm_table *t, int bdi_bits);
 unsigned dm_table_get_type(struct dm_table *t);
 struct target_type *dm_table_get_immutable_target_type(struct dm_table *t);
+struct dm_target *dm_table_get_immutable_target(struct dm_table *t);
 struct dm_target *dm_table_get_wildcard_target(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);
 bool dm_table_mq_request_based(struct dm_table *t);

commit f083b09b7819c785db4f82a81f68da3bccfb04bf
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Sat Feb 6 18:38:46 2016 -0500

    dm: set DM_TARGET_WILDCARD feature on "error" target
    
    The DM_TARGET_WILDCARD feature indicates that the "error" target may
    replace any target; even immutable targets.  This feature will be useful
    to preserve the ability to replace the "multipath" target even once it
    is formally converted over to having the DM_TARGET_IMMUTABLE feature.
    
    Also, implicit in the DM_TARGET_WILDCARD feature flag being set is that
    .map, .map_rq, .clone_and_map_rq and .release_clone_rq are all defined
    in the target_type.
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 7edcf97dfa5a..53df2585571b 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -73,6 +73,7 @@ int dm_table_resume_targets(struct dm_table *t);
 int dm_table_any_congested(struct dm_table *t, int bdi_bits);
 unsigned dm_table_get_type(struct dm_table *t);
 struct target_type *dm_table_get_immutable_target_type(struct dm_table *t);
+struct dm_target *dm_table_get_wildcard_target(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);
 bool dm_table_mq_request_based(struct dm_table *t);
 void dm_table_free_md_mempools(struct dm_table *t);

commit 8ae126660fddbeebb9251a174e6fa45b6ad8f932
Author: Kent Overstreet <kent.overstreet@gmail.com>
Date:   Mon Apr 27 23:48:34 2015 -0700

    block: kill merge_bvec_fn() completely
    
    As generic_make_request() is now able to handle arbitrarily sized bios,
    it's no longer necessary for each individual block driver to define its
    own ->merge_bvec_fn() callback. Remove every invocation completely.
    
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Lars Ellenberg <drbd-dev@lists.linbit.com>
    Cc: drbd-user@lists.linbit.com
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Yehuda Sadeh <yehuda@inktank.com>
    Cc: Sage Weil <sage@inktank.com>
    Cc: Alex Elder <elder@kernel.org>
    Cc: ceph-devel@vger.kernel.org
    Cc: Alasdair Kergon <agk@redhat.com>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: dm-devel@redhat.com
    Cc: Neil Brown <neilb@suse.de>
    Cc: linux-raid@vger.kernel.org
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: "Martin K. Petersen" <martin.petersen@oracle.com>
    Acked-by: NeilBrown <neilb@suse.de> (for the 'md' bits)
    Acked-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Kent Overstreet <kent.overstreet@gmail.com>
    [dpark: also remove ->merge_bvec_fn() in dm-thin as well as
     dm-era-target, and resolve merge conflicts]
    Signed-off-by: Dongsu Park <dpark@posteo.net>
    Signed-off-by: Ming Lin <ming.l@ssi.samsung.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 4e984993d40a..7edcf97dfa5a 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -78,8 +78,6 @@ bool dm_table_mq_request_based(struct dm_table *t);
 void dm_table_free_md_mempools(struct dm_table *t);
 struct dm_md_mempools *dm_table_get_md_mempools(struct dm_table *t);
 
-int dm_queue_merge_is_compulsory(struct request_queue *q);
-
 void dm_lock_md_type(struct mapped_device *md);
 void dm_unlock_md_type(struct mapped_device *md);
 void dm_set_md_type(struct mapped_device *md, unsigned type);

commit 22165fa79814e71e7a5974b3c37a5028ed16c8f9
Merge: a2f54be94f4c b5451e456840
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jun 26 12:35:01 2015 -0700

    Merge tag 'dm-4.2-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/device-mapper/linux-dm
    
    Pull device mapper fixes from Mike Snitzer:
     "Apologies for not pressing this request-based DM partial completion
      issue further, it was an oversight on my part.  We'll have to get it
      fixed up properly and revisit for a future release.
    
       - Revert block and DM core changes the removed request-based DM's
         ability to handle partial request completions -- otherwise with the
         current SCSI LLDs these changes could lead to silent data
         corruption.
    
       - Fix two DM version bumps that were missing from the initial 4.2 DM
         pull request (enabled userspace lvm2 to know certain changes have
         been made)"
    
    * tag 'dm-4.2-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/device-mapper/linux-dm:
      dm cache policy smq: fix "default" version to be 1.4.0
      dm: bump the ioctl version to 4.32.0
      Revert "block, dm: don't copy bios for request clones"
      Revert "dm: do not allocate any mempools for blk-mq request-based DM"

commit 78d8e58a086b214dddf1fd463e20a7e1d82d7866
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Fri Jun 26 10:01:13 2015 -0400

    Revert "block, dm: don't copy bios for request clones"
    
    This reverts commit 5f1b670d0bef508a5554d92525f5f6d00d640b38.
    
    Justification for revert as reported in this dm-devel post:
    https://www.redhat.com/archives/dm-devel/2015-June/msg00160.html
    
    this change should not be pushed to mainline yet.
    
    Firstly, Christoph has a newer version of the patch that fixes silent
    data corruption problem:
      https://www.redhat.com/archives/dm-devel/2015-May/msg00229.html
    
    And the new version still depends on LLDDs to always complete requests
    to the end when error happens, while block API doesn't enforce such a
    requirement. If the assumption is ever broken, the inconsistency between
    request and bio (e.g. rq->__sector and rq->bio) will cause silent data
    corruption:
      https://www.redhat.com/archives/dm-devel/2015-June/msg00022.html
    
    Reported-by: Junichi Nomura <j-nomura@ce.jp.nec.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index e6e66d087b26..6123c2bf9150 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -222,9 +222,8 @@ void dm_kcopyd_exit(void);
 /*
  * Mempool operations
  */
-struct dm_md_mempools *dm_alloc_bio_mempools(unsigned integrity,
-					     unsigned per_bio_data_size);
-struct dm_md_mempools *dm_alloc_rq_mempools(struct mapped_device *md, unsigned type);
+struct dm_md_mempools *dm_alloc_md_mempools(struct mapped_device *md, unsigned type,
+					    unsigned integrity, unsigned per_bio_data_size);
 void dm_free_md_mempools(struct dm_md_mempools *pools);
 
 /*

commit 66114cad64bf76a155fec1f0fff0de771cf909d5
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 22 17:13:32 2015 -0400

    writeback: separate out include/linux/backing-dev-defs.h
    
    With the planned cgroup writeback support, backing-dev related
    declarations will be more widely used across block and cgroup;
    unfortunately, including backing-dev.h from include/linux/blkdev.h
    makes cyclic include dependency quite likely.
    
    This patch separates out backing-dev-defs.h which only has the
    essential definitions and updates blkdev.h to include it.  c files
    which need access to more backing-dev details now include
    backing-dev.h directly.  This takes backing-dev.h off the common
    include dependency chain making it a lot easier to use it across block
    and cgroup.
    
    v2: fs/fat build failure fixed.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index e6e66d087b26..7fff744f0865 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -14,6 +14,7 @@
 #include <linux/device-mapper.h>
 #include <linux/list.h>
 #include <linux/blkdev.h>
+#include <linux/backing-dev.h>
 #include <linux/hdreg.h>
 #include <linux/completion.h>
 #include <linux/kobject.h>

commit 5f1b670d0bef508a5554d92525f5f6d00d640b38
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri May 22 09:14:04 2015 -0400

    block, dm: don't copy bios for request clones
    
    Currently dm-multipath has to clone the bios for every request sent
    to the lower devices, which wastes cpu cycles and ties down memory.
    
    This patch instead adds a new REQ_CLONE flag that instructs req_bio_endio
    to not complete bios attached to a request, which we set on clone
    requests similar to bios in a flush sequence.  With this change I/O
    errors on a path failure only get propagated to dm-multipath, which
    can then either resubmit the I/O or complete the bios on the original
    request.
    
    I've done some basic testing of this on a Linux target with ALUA support,
    and it survives path failures during I/O nicely.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 6123c2bf9150..e6e66d087b26 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -222,8 +222,9 @@ void dm_kcopyd_exit(void);
 /*
  * Mempool operations
  */
-struct dm_md_mempools *dm_alloc_md_mempools(struct mapped_device *md, unsigned type,
-					    unsigned integrity, unsigned per_bio_data_size);
+struct dm_md_mempools *dm_alloc_bio_mempools(unsigned integrity,
+					     unsigned per_bio_data_size);
+struct dm_md_mempools *dm_alloc_rq_mempools(struct mapped_device *md, unsigned type);
 void dm_free_md_mempools(struct dm_md_mempools *pools);
 
 /*

commit 17e149b8f73ba116e71e25930dd6f2eb3828792d
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Wed Mar 11 15:01:09 2015 -0400

    dm: add 'use_blk_mq' module param and expose in per-device ro sysfs attr
    
    Request-based DM's blk-mq support defaults to off; but a user can easily
    change the default using the dm_mod.use_blk_mq module/boot option.
    
    Also, you can check what mode a given request-based DM device is using
    with: cat /sys/block/dm-X/dm/use_blk_mq
    
    This change enabled further cleanup and reduced work (e.g. the
    md->io_pool and md->rq_pool isn't created if using blk-mq).
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 5522422cc6c4..6123c2bf9150 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -211,6 +211,8 @@ int dm_kobject_uevent(struct mapped_device *md, enum kobject_action action,
 void dm_internal_suspend(struct mapped_device *md);
 void dm_internal_resume(struct mapped_device *md);
 
+bool dm_use_blk_mq(struct mapped_device *md);
+
 int dm_io_init(void);
 void dm_io_exit(void);
 
@@ -220,7 +222,8 @@ void dm_kcopyd_exit(void);
 /*
  * Mempool operations
  */
-struct dm_md_mempools *dm_alloc_md_mempools(unsigned type, unsigned integrity, unsigned per_bio_data_size);
+struct dm_md_mempools *dm_alloc_md_mempools(struct mapped_device *md, unsigned type,
+					    unsigned integrity, unsigned per_bio_data_size);
 void dm_free_md_mempools(struct dm_md_mempools *pools);
 
 /*

commit 0ce65797a77ee780f62909d3128bf08b9735718b
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Thu Feb 26 00:50:28 2015 -0500

    dm: impose configurable deadline for dm_request_fn's merge heuristic
    
    Otherwise, for sequential workloads, the dm_request_fn can allow
    excessive request merging at the expense of increased service time.
    
    Add a per-device sysfs attribute to allow the user to control how long a
    request, that is a reasonable merge candidate, can be queued on the
    request queue.  The resolution of this request dispatch deadline is in
    microseconds (ranging from 1 to 100000 usecs), to set a 20us deadline:
      echo 20 > /sys/block/dm-7/dm/rq_based_seq_io_merge_deadline
    
    The dm_request_fn's merge heuristic and associated extra accounting is
    disabled by default (rq_based_seq_io_merge_deadline is 0).
    
    This sysfs attribute is not applicable to bio-based DM devices so it
    will only ever report 0 for them.
    
    By allowing a request to remain on the queue it will block others
    requests on the queue.  But introducing a short dequeue delay has proven
    very effective at enabling certain sequential IO workloads on really
    fast, yet IOPS constrained, devices to build up slightly larger IOs --
    yielding 90+% throughput improvements.  Having precise control over the
    time taken to wait for larger requests to build affords control beyond
    that of waiting for certain IO sizes to accumulate (which would require
    a deadline anyway).  This knob will only ever make sense with sequential
    IO workloads and the particular value used is storage configuration
    specific.
    
    Given the expected niche use-case for when this knob is useful it has
    been deemed acceptable to expose this relatively crude method for
    crafting optimal IO on specific storage -- especially given the solution
    is simple yet effective.  In the context of DM multipath, it is
    advisable to tune this sysfs attribute to a value that offers the best
    performance for the common case (e.g. if 4 paths are expected active,
    tune for that; if paths fail then performance may be slightly reduced).
    
    Alternatives were explored to have request-based DM autotune this value
    (e.g. if/when paths fail) but they were quickly deemed too fragile and
    complex to warrant further design and development time.  If this problem
    proves more common as faster storage emerges we'll have to look at
    elevating a generic solution into the block core.
    
    Tested-by: Shiva Krishna Merla <shivakrishna.merla@netapp.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index db495863fa5f..5522422cc6c4 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -234,4 +234,8 @@ static inline bool dm_message_test_buffer_overflow(char *result, unsigned maxlen
 	return !maxlen || strlen(result) + 1 >= maxlen;
 }
 
+ssize_t dm_attr_rq_based_seq_io_merge_deadline_show(struct mapped_device *md, char *buf);
+ssize_t dm_attr_rq_based_seq_io_merge_deadline_store(struct mapped_device *md,
+						     const char *buf, size_t count);
+
 #endif

commit d56b9b28a4a5d9e61dd99154b986e760373e2392
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Mon Feb 23 19:10:15 2015 -0500

    dm: remove request-based DM queue's lld_busy_fn hook
    
    DM multipath is the only caller of blk_lld_busy() -- which calls a
    queue's lld_busy_fn hook.  Request-based DM doesn't support stacking
    multipath devices so there is no reason to register the lld_busy_fn hook
    on a multipath device's queue using blk_queue_lld_busy().
    
    As such, remove functions dm_lld_busy and dm_table_any_busy_target.
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 59f53e79db82..db495863fa5f 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -70,7 +70,6 @@ void dm_table_presuspend_undo_targets(struct dm_table *t);
 void dm_table_postsuspend_targets(struct dm_table *t);
 int dm_table_resume_targets(struct dm_table *t);
 int dm_table_any_congested(struct dm_table *t, int bdi_bits);
-int dm_table_any_busy_target(struct dm_table *t);
 unsigned dm_table_get_type(struct dm_table *t);
 struct target_type *dm_table_get_immutable_target_type(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);

commit 65803c2059832fb99b992728157f7924c2e42d4b
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Thu Dec 18 16:26:47 2014 -0500

    dm table: train hybrid target type detection to select blk-mq if appropriate
    
    Otherwise replacing the multipath target with the error target fails:
      device-mapper: ioctl: can't change device type after initial table load.
    
    The error target was mistakenly considered to be target type
    DM_TYPE_REQUEST_BASED rather than DM_TYPE_MQ_REQUEST_BASED even if the
    target it was to replace was of type DM_TYPE_MQ_REQUEST_BASED.
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 84d79784b866..59f53e79db82 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -101,7 +101,8 @@ int dm_setup_md_queue(struct mapped_device *md);
 /*
  * To check whether the target type is request-based or not (bio-based).
  */
-#define dm_target_request_based(t) ((t)->type->map_rq != NULL)
+#define dm_target_request_based(t) (((t)->type->map_rq != NULL) || \
+				    ((t)->type->clone_and_map_rq != NULL))
 
 /*
  * To check whether the target type is a hybrid (capable of being

commit e5863d9ad754926e7d3f38b43ac8bd48ef73b097
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Wed Dec 17 21:08:12 2014 -0500

    dm: allocate requests in target when stacking on blk-mq devices
    
    For blk-mq request-based DM the responsibility of allocating a cloned
    request is transfered from DM core to the target type.  Doing so
    enables the cloned request to be allocated from the appropriate
    blk-mq request_queue's pool (only the DM target, e.g. multipath, can
    know which block device to send a given cloned request to).
    
    Care was taken to preserve compatibility with old-style block request
    completion that requires request-based DM _not_ acquire the clone
    request's queue lock in the completion path.  As such, there are now 2
    different request-based DM target_type interfaces:
    1) the original .map_rq() interface will continue to be used for
       non-blk-mq devices -- the preallocated clone request is passed in
       from DM core.
    2) a new .clone_and_map_rq() and .release_clone_rq() will be used for
       blk-mq devices -- blk_get_request() and blk_put_request() are used
       respectively from these hooks.
    
    dm_table_set_type() was updated to detect if the request-based target is
    being stacked on blk-mq devices, if so DM_TYPE_MQ_REQUEST_BASED is set.
    DM core disallows switching the DM table's type after it is set.  This
    means that there is no mixing of non-blk-mq and blk-mq devices within
    the same request-based DM table.
    
    [This patch was started by Keith and later heavily modified by Mike]
    
    Tested-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Keith Busch <keith.busch@intel.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 84b0f9e4ba6c..84d79784b866 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -34,9 +34,10 @@
 /*
  * Type of table and mapped_device's mempool
  */
-#define DM_TYPE_NONE		0
-#define DM_TYPE_BIO_BASED	1
-#define DM_TYPE_REQUEST_BASED	2
+#define DM_TYPE_NONE			0
+#define DM_TYPE_BIO_BASED		1
+#define DM_TYPE_REQUEST_BASED		2
+#define DM_TYPE_MQ_REQUEST_BASED	3
 
 /*
  * List of devices that a metadevice uses and should open/close.
@@ -73,6 +74,7 @@ int dm_table_any_busy_target(struct dm_table *t);
 unsigned dm_table_get_type(struct dm_table *t);
 struct target_type *dm_table_get_immutable_target_type(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);
+bool dm_table_mq_request_based(struct dm_table *t);
 void dm_table_free_md_mempools(struct dm_table *t);
 struct dm_md_mempools *dm_table_get_md_mempools(struct dm_table *t);
 

commit ffcc39364160663cda1a3c358f4537302a92459b
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Tue Oct 28 18:34:52 2014 -0400

    dm: enhance internal suspend and resume interface
    
    Rename dm_internal_{suspend,resume} to dm_internal_{suspend,resume}_fast
    -- dm-stats will continue using these methods to avoid all the extra
    suspend/resume logic that is not needed in order to quickly flush IO.
    
    Introduce dm_internal_suspend_noflush() variant that actually calls the
    mapped_device's target callbacks -- otherwise target-specific hooks are
    avoided (e.g. dm-thin's thin_presuspend and thin_postsuspend).  Common
    code between dm_internal_{suspend_noflush,resume} and
    dm_{suspend,resume} was factored out as __dm_{suspend,resume}.
    
    Update dm_internal_{suspend_noflush,resume} to always take and release
    the mapped_device's suspend_lock.  Also update dm_{suspend,resume} to be
    aware of potential for DM_INTERNAL_SUSPEND_FLAG to be set and respond
    accordingly by interruptibly waiting for the DM_INTERNAL_SUSPEND_FLAG to
    be cleared.  Add lockdep annotation to dm_suspend() and dm_resume().
    
    The existing DM_SUSPEND_FLAG remains unchanged.
    DM_INTERNAL_SUSPEND_FLAG is set by dm_internal_suspend_noflush() and
    cleared by dm_internal_resume().
    
    Both DM_SUSPEND_FLAG and DM_INTERNAL_SUSPEND_FLAG may be set if a device
    was already suspended when dm_internal_suspend_noflush() was called --
    this can be thought of as a "nested suspend".  A "nested suspend" can
    occur with legacy userspace dm-thin code that might suspend all active
    thin volumes before suspending the pool for resize.
    
    But otherwise, in the normal dm-thin-pool suspend case moving forward:
    the thin-pool will have DM_SUSPEND_FLAG set and all active thins from
    that thin-pool will have DM_INTERNAL_SUSPEND_FLAG set.
    
    Also add DM_INTERNAL_SUSPEND_FLAG to status report.  This new
    DM_INTERNAL_SUSPEND_FLAG state is being reported to assist with
    debugging (e.g. 'dmsetup info' will report an internally suspended
    device accordingly).
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Acked-by: Joe Thornber <ejt@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 781994093bf5..84b0f9e4ba6c 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -129,6 +129,15 @@ int dm_deleting_md(struct mapped_device *md);
  */
 int dm_suspended_md(struct mapped_device *md);
 
+/*
+ * Internal suspend and resume methods.
+ */
+int dm_suspended_internally_md(struct mapped_device *md);
+void dm_internal_suspend_fast(struct mapped_device *md);
+void dm_internal_resume_fast(struct mapped_device *md);
+void dm_internal_suspend_noflush(struct mapped_device *md);
+void dm_internal_resume(struct mapped_device *md);
+
 /*
  * Test if the device is scheduled for deferred remove.
  */

commit d67ee213fa5700c7da526fe5bcccd485cfa63d8b
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Tue Oct 28 20:13:31 2014 -0400

    dm: add presuspend_undo hook to target_type
    
    The DM thin-pool target now must undo the changes performed during
    pool_presuspend() so introduce presuspend_undo hook in target_type.
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Acked-by: Joe Thornber <ejt@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 988c7fb7b145..781994093bf5 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -65,6 +65,7 @@ void dm_table_set_restrictions(struct dm_table *t, struct request_queue *q,
 			       struct queue_limits *limits);
 struct list_head *dm_table_get_devices(struct dm_table *t);
 void dm_table_presuspend_targets(struct dm_table *t);
+void dm_table_presuspend_undo_targets(struct dm_table *t);
 void dm_table_postsuspend_targets(struct dm_table *t);
 int dm_table_resume_targets(struct dm_table *t);
 int dm_table_any_congested(struct dm_table *t, int bdi_bits);

commit 86f1152b117a404229fd6f08ec3faca779f37b92
Author: Benjamin Marzinski <bmarzins@redhat.com>
Date:   Wed Aug 13 13:53:43 2014 -0500

    dm: allow active and inactive tables to share dm_devs
    
    Until this change, when loading a new DM table, DM core would re-open
    all of the devices in the DM table.  Now, DM core will avoid redundant
    device opens (and closes when destroying the old table) if the old
    table already has a device open using the same mode.  This is achieved
    by managing reference counts on the table_devices that DM core now
    stores in the mapped_device structure (rather than in the dm_table
    structure).  So a mapped_device's active and inactive dm_tables' dm_dev
    lists now just point to the dm_devs stored in the mapped_device's
    table_devices list.
    
    This improvement in DM core's device reference counting has the
    side-effect of fixing a long-standing limitation of the multipath
    target: a DM multipath table couldn't include any paths that were unusable
    (failed).  For example: if all paths have failed and you add a new,
    working, path to the table; you can't use it since the table load would
    fail due to it still containing failed paths.  Now a re-load of a
    multipath table can include failed devices and when those devices become
    active again they can be used instantly.
    
    The device list code in dm.c isn't a straight copy/paste from the code in
    dm-table.c, but it's very close (aside from some variable renames).  One
    subtle difference is that find_table_device for the tables_devices list
    will only match devices with the same name and mode.  This is because we
    don't want to upgrade a device's mode in the active table when an
    inactive table is loaded.
    
    Access to the mapped_device structure's tables_devices list requires a
    mutex (tables_devices_lock), so that tables cannot be created and
    destroyed concurrently.
    
    Signed-off-by: Benjamin Marzinski <bmarzins@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index e81d2152fa68..988c7fb7b145 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -44,7 +44,7 @@
 struct dm_dev_internal {
 	struct list_head list;
 	atomic_t count;
-	struct dm_dev dm_dev;
+	struct dm_dev *dm_dev;
 };
 
 struct dm_table;
@@ -188,6 +188,9 @@ int dm_cancel_deferred_remove(struct mapped_device *md);
 int dm_request_based(struct mapped_device *md);
 sector_t dm_get_size(struct mapped_device *md);
 struct request_queue *dm_get_md_queue(struct mapped_device *md);
+int dm_get_table_device(struct mapped_device *md, dev_t dev, fmode_t mode,
+			struct dm_dev **result);
+void dm_put_table_device(struct mapped_device *md, struct dm_dev *d);
 struct dm_stats *dm_get_stats(struct mapped_device *md);
 
 int dm_kobject_uevent(struct mapped_device *md, enum kobject_action action,

commit a7ffb6a53391c2690263675f13c79a273301d2b3
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Thu Jul 10 12:23:07 2014 -0400

    dm table: make dm_table_supports_discards static
    
    The function dm_table_supports_discards is only called from
    dm-table.c:dm_table_set_restrictions().  So move it above
    dm_table_set_restrictions and make it static.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index ed76126aac54..e81d2152fa68 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -72,7 +72,6 @@ int dm_table_any_busy_target(struct dm_table *t);
 unsigned dm_table_get_type(struct dm_table *t);
 struct target_type *dm_table_get_immutable_target_type(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);
-bool dm_table_supports_discards(struct dm_table *t);
 void dm_table_free_md_mempools(struct dm_table *t);
 struct dm_md_mempools *dm_table_get_md_mempools(struct dm_table *t);
 

commit 9974fa2c6a7d470ca3c201fe7dbac64bf4dd8d2a
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Fri Feb 28 15:33:43 2014 +0100

    dm table: add dm_table_run_md_queue_async
    
    Introduce dm_table_run_md_queue_async() to run the request_queue of the
    mapped_device associated with a request-based DM table.
    
    Also add dm_md_get_queue() wrapper to extract the request_queue from a
    mapped_device.
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 88cc58c5871a..ed76126aac54 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -188,6 +188,7 @@ int dm_lock_for_deletion(struct mapped_device *md, bool mark_deferred, bool only
 int dm_cancel_deferred_remove(struct mapped_device *md);
 int dm_request_based(struct mapped_device *md);
 sector_t dm_get_size(struct mapped_device *md);
+struct request_queue *dm_get_md_queue(struct mapped_device *md);
 struct dm_stats *dm_get_stats(struct mapped_device *md);
 
 int dm_kobject_uevent(struct mapped_device *md, enum kobject_action action,

commit 473c36dfeecf4e49db928f3284b2fbe981f8c284
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Thu Feb 13 13:43:32 2014 -0500

    dm: make dm_table_alloc_md_mempools static
    
    Make the function dm_table_alloc_md_mempools static because it is not
    called from another file.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index c4569f02f50f..88cc58c5871a 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -73,7 +73,6 @@ unsigned dm_table_get_type(struct dm_table *t);
 struct target_type *dm_table_get_immutable_target_type(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);
 bool dm_table_supports_discards(struct dm_table *t);
-int dm_table_alloc_md_mempools(struct dm_table *t);
 void dm_table_free_md_mempools(struct dm_table *t);
 struct dm_md_mempools *dm_table_get_md_mempools(struct dm_table *t);
 

commit 2995fa78e423d7193f3b57835f6c1c75006a0315
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Mon Jan 13 19:37:54 2014 -0500

    dm sysfs: fix a module unload race
    
    This reverts commit be35f48610 ("dm: wait until embedded kobject is
    released before destroying a device") and provides an improved fix.
    
    The kobject release code that calls the completion must be placed in a
    non-module file, otherwise there is a module unload race (if the process
    calling dm_kobject_release is preempted and the DM module unloaded after
    the completion is triggered, but before dm_kobject_release returns).
    
    To fix this race, this patch moves the completion code to dm-builtin.c
    which is always compiled directly into the kernel if BLK_DEV_DM is
    selected.
    
    The patch introduces a new dm_kobject_holder structure, its purpose is
    to keep the completion and kobject in one place, so that it can be
    accessed from non-module code without the need to export the layout of
    struct mapped_device to that code.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Cc: stable@vger.kernel.org

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 1ab2028559ca..c4569f02f50f 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -16,6 +16,7 @@
 #include <linux/blkdev.h>
 #include <linux/hdreg.h>
 #include <linux/completion.h>
+#include <linux/kobject.h>
 
 #include "dm-stats.h"
 
@@ -149,11 +150,25 @@ void dm_interface_exit(void);
 /*
  * sysfs interface
  */
+struct dm_kobject_holder {
+	struct kobject kobj;
+	struct completion completion;
+};
+
+static inline struct completion *dm_get_completion_from_kobject(struct kobject *kobj)
+{
+	return &container_of(kobj, struct dm_kobject_holder, kobj)->completion;
+}
+
 int dm_sysfs_init(struct mapped_device *md);
 void dm_sysfs_exit(struct mapped_device *md);
 struct kobject *dm_kobject(struct mapped_device *md);
 struct mapped_device *dm_get_from_kobject(struct kobject *kobj);
-struct completion *dm_get_completion_from_kobject(struct kobject *kobj);
+
+/*
+ * The kobject helper
+ */
+void dm_kobject_release(struct kobject *kobj);
 
 /*
  * Targets for linear and striped mappings

commit be35f486108227e10fe5d96fd42fb2b344c59983
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Mon Jan 6 23:01:22 2014 -0500

    dm: wait until embedded kobject is released before destroying a device
    
    There may be other parts of the kernel holding a reference on the dm
    kobject.  We must wait until all references are dropped before
    deallocating the mapped_device structure.
    
    The dm_kobject_release method signals that all references are dropped
    via completion.  But dm_kobject_release doesn't free the kobject (which
    is embedded in the mapped_device structure).
    
    This is the sequence of operations:
    * when destroying a DM device, call kobject_put from dm_sysfs_exit
    * wait until all users stop using the kobject, when it happens the
      release method is called
    * the release method signals the completion and should return without
      delay
    * the dm device removal code that waits on the completion continues
    * the dm device removal code drops the dm_mod reference the device had
    * the dm device removal code frees the mapped_device structure that
      contains the kobject
    
    Using kobject this way should avoid the module unload race that was
    mentioned at the beginning of this thread:
    https://lkml.org/lkml/2014/1/4/83
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Cc: stable@vger.kernel.org

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index c57ba550f69e..1ab2028559ca 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -15,6 +15,7 @@
 #include <linux/list.h>
 #include <linux/blkdev.h>
 #include <linux/hdreg.h>
+#include <linux/completion.h>
 
 #include "dm-stats.h"
 
@@ -152,6 +153,7 @@ int dm_sysfs_init(struct mapped_device *md);
 void dm_sysfs_exit(struct mapped_device *md);
 struct kobject *dm_kobject(struct mapped_device *md);
 struct mapped_device *dm_get_from_kobject(struct kobject *kobj);
+struct completion *dm_get_completion_from_kobject(struct kobject *kobj);
 
 /*
  * Targets for linear and striped mappings

commit 2c140a246dc0bc085b98eddde978060fcec1080c
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Fri Nov 1 18:27:41 2013 -0400

    dm: allow remove to be deferred
    
    This patch allows the removal of an open device to be deferred until
    it is closed.  (Previously such a removal attempt would fail.)
    
    The deferred remove functionality is enabled by setting the flag
    DM_DEFERRED_REMOVE in the ioctl structure on DM_DEV_REMOVE or
    DM_REMOVE_ALL ioctl.
    
    On return from DM_DEV_REMOVE, the flag DM_DEFERRED_REMOVE indicates if
    the device was removed immediately or flagged to be removed on close -
    if the flag is clear, the device was removed.
    
    On return from DM_DEV_STATUS and other ioctls, the flag
    DM_DEFERRED_REMOVE is set if the device is scheduled to be removed on
    closure.
    
    A device that is scheduled to be deleted can be revived using the
    message "@cancel_deferred_remove". This message clears the
    DMF_DEFERRED_REMOVE flag so that the device won't be deleted on close.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 1d1ad7b7e527..c57ba550f69e 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -128,6 +128,16 @@ int dm_deleting_md(struct mapped_device *md);
  */
 int dm_suspended_md(struct mapped_device *md);
 
+/*
+ * Test if the device is scheduled for deferred remove.
+ */
+int dm_test_deferred_remove_flag(struct mapped_device *md);
+
+/*
+ * Try to remove devices marked for deferred removal.
+ */
+void dm_deferred_remove(void);
+
 /*
  * The device-mapper can be driven through one of two interfaces;
  * ioctl or filesystem, depending which patch you have applied.
@@ -158,7 +168,8 @@ void dm_stripe_exit(void);
 void dm_destroy(struct mapped_device *md);
 void dm_destroy_immediate(struct mapped_device *md);
 int dm_open_count(struct mapped_device *md);
-int dm_lock_for_deletion(struct mapped_device *md);
+int dm_lock_for_deletion(struct mapped_device *md, bool mark_deferred, bool only_deferred);
+int dm_cancel_deferred_remove(struct mapped_device *md);
 int dm_request_based(struct mapped_device *md);
 sector_t dm_get_size(struct mapped_device *md);
 struct dm_stats *dm_get_stats(struct mapped_device *md);

commit e8603136cb04ec2d0c9b4b5be7a071fc003cb399
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Thu Sep 12 18:06:12 2013 -0400

    dm: add reserved_bio_based_ios module parameter
    
    Allow user to change the number of IOs that are reserved by
    bio-based DM's mempools by writing to this file:
    /sys/module/dm_mod/parameters/reserved_bio_based_ios
    
    The default value is RESERVED_BIO_BASED_IOS (16).  The maximum allowed
    value is RESERVED_MAX_IOS (1024).
    
    Export dm_get_reserved_bio_based_ios() for use by DM targets and core
    code.  Switch to sizing dm-io's mempool and bioset using DM core's
    configurable 'reserved_bio_based_ios'.
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Frank Mayhar <fmayhar@google.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 15396501e0b3..1d1ad7b7e527 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -184,6 +184,7 @@ void dm_free_md_mempools(struct dm_md_mempools *pools);
 /*
  * Helpers that are used by DM core
  */
+unsigned dm_get_reserved_bio_based_ios(void);
 unsigned dm_get_reserved_rq_based_ios(void);
 
 static inline bool dm_message_test_buffer_overflow(char *result, unsigned maxlen)

commit f47908269fb53d522a956b78612a0037f5faf8e7
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Thu Sep 12 18:06:12 2013 -0400

    dm: add reserved_rq_based_ios module parameter
    
    Allow user to change the number of IOs that are reserved by
    request-based DM's mempools by writing to this file:
    /sys/module/dm_mod/parameters/reserved_rq_based_ios
    
    The default value is RESERVED_REQUEST_BASED_IOS (256).  The maximum
    allowed value is RESERVED_MAX_IOS (1024).
    
    Export dm_get_reserved_rq_based_ios() for use by DM targets and core
    code.  Switch to sizing dm-mpath's mempool using DM core's configurable
    'reserved_rq_based_ios'.
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Frank Mayhar <fmayhar@google.com>
    Acked-by: Mikulas Patocka <mpatocka@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 5e604cc7b4aa..15396501e0b3 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -184,6 +184,8 @@ void dm_free_md_mempools(struct dm_md_mempools *pools);
 /*
  * Helpers that are used by DM core
  */
+unsigned dm_get_reserved_rq_based_ios(void);
+
 static inline bool dm_message_test_buffer_overflow(char *result, unsigned maxlen)
 {
 	return !maxlen || strlen(result) + 1 >= maxlen;

commit fd2ed4d252701d3bbed4cd3e3d267ad469bb832a
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Fri Aug 16 10:54:23 2013 -0400

    dm: add statistics support
    
    Support the collection of I/O statistics on user-defined regions of
    a DM device.  If no regions are defined no statistics are collected so
    there isn't any performance impact.  Only bio-based DM devices are
    currently supported.
    
    Each user-defined region specifies a starting sector, length and step.
    Individual statistics will be collected for each step-sized area within
    the range specified.
    
    The I/O statistics counters for each step-sized area of a region are
    in the same format as /sys/block/*/stat or /proc/diskstats but extra
    counters (12 and 13) are provided: total time spent reading and
    writing in milliseconds.  All these counters may be accessed by sending
    the @stats_print message to the appropriate DM device via dmsetup.
    
    The creation of DM statistics will allocate memory via kmalloc or
    fallback to using vmalloc space.  At most, 1/4 of the overall system
    memory may be allocated by DM statistics.  The admin can see how much
    memory is used by reading
    /sys/module/dm_mod/parameters/stats_current_allocated_bytes
    
    See Documentation/device-mapper/statistics.txt for more details.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 8b4c075d9a2f..5e604cc7b4aa 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -16,6 +16,8 @@
 #include <linux/blkdev.h>
 #include <linux/hdreg.h>
 
+#include "dm-stats.h"
+
 /*
  * Suspend feature flags
  */
@@ -157,10 +159,16 @@ void dm_destroy(struct mapped_device *md);
 void dm_destroy_immediate(struct mapped_device *md);
 int dm_open_count(struct mapped_device *md);
 int dm_lock_for_deletion(struct mapped_device *md);
+int dm_request_based(struct mapped_device *md);
+sector_t dm_get_size(struct mapped_device *md);
+struct dm_stats *dm_get_stats(struct mapped_device *md);
 
 int dm_kobject_uevent(struct mapped_device *md, enum kobject_action action,
 		      unsigned cookie);
 
+void dm_internal_suspend(struct mapped_device *md);
+void dm_internal_resume(struct mapped_device *md);
+
 int dm_io_init(void);
 void dm_io_exit(void);
 
@@ -173,4 +181,12 @@ void dm_kcopyd_exit(void);
 struct dm_md_mempools *dm_alloc_md_mempools(unsigned type, unsigned integrity, unsigned per_bio_data_size);
 void dm_free_md_mempools(struct dm_md_mempools *pools);
 
+/*
+ * Helpers that are used by DM core
+ */
+static inline bool dm_message_test_buffer_overflow(char *result, unsigned maxlen)
+{
+	return !maxlen || strlen(result) + 1 >= maxlen;
+}
+
 #endif

commit 169e2cc279c443085f7e423561eb1fe6158ade44
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Thu Aug 22 18:21:38 2013 -0400

    dm: allow error target to replace bio-based and request-based targets
    
    It may be useful to switch a request-based table to the "error" target.
    Enhance the DM core to allow a hybrid target_type which is capable of
    handling either bios (via .map) or requests (via .map_rq).
    
    Add a request-based map function (.map_rq) to the "error" target_type;
    making it DM's first hybrid target.  Train dm_table_set_type() to prefer
    the mapped device's established type (request-based or bio-based).  If
    the mapped device doesn't have an established type default to making the
    table with the hybrid target(s) bio-based.
    
    Tested 'dmsetup wipe_table' to work on both bio-based and request-based
    devices.
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Joe Jin <joe.jin@oracle.com>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Acked-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 45b97da1bd06..8b4c075d9a2f 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -88,11 +88,22 @@ int dm_setup_md_queue(struct mapped_device *md);
  */
 #define dm_target_is_valid(t) ((t)->table)
 
+/*
+ * To check whether the target type is bio-based or not (request-based).
+ */
+#define dm_target_bio_based(t) ((t)->type->map != NULL)
+
 /*
  * To check whether the target type is request-based or not (bio-based).
  */
 #define dm_target_request_based(t) ((t)->type->map_rq != NULL)
 
+/*
+ * To check whether the target type is a hybrid (capable of being
+ * either request-based or bio-based).
+ */
+#define dm_target_hybrid(t) (dm_target_bio_based(t) && dm_target_request_based(t))
+
 /*-----------------------------------------------------------------
  * A registry of target types.
  *---------------------------------------------------------------*/

commit c0820cf5ad09522bdd9ff68e84841a09c9f339d8
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Fri Dec 21 20:23:38 2012 +0000

    dm: introduce per_bio_data
    
    Introduce a field per_bio_data_size in struct dm_target.
    
    Targets can set this field in the constructor. If a target sets this
    field to a non-zero value, "per_bio_data_size" bytes of auxiliary data
    are allocated for each bio submitted to the target. These data can be
    used for any purpose by the target and help us improve performance by
    removing some per-target mempools.
    
    Per-bio data is accessed with dm_per_bio_data. The
    argument data_size must be the same as the value per_bio_data_size in
    dm_target.
    
    If the target has a pointer to per_bio_data, it can get a pointer to
    the bio with dm_bio_from_per_bio_data() function (data_size must be the
    same as the value passed to dm_per_bio_data).
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 6a99fefaa743..45b97da1bd06 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -159,7 +159,7 @@ void dm_kcopyd_exit(void);
 /*
  * Mempool operations
  */
-struct dm_md_mempools *dm_alloc_md_mempools(unsigned type, unsigned integrity);
+struct dm_md_mempools *dm_alloc_md_mempools(unsigned type, unsigned integrity, unsigned per_bio_data_size);
 void dm_free_md_mempools(struct dm_md_mempools *pools);
 
 #endif

commit 3ae706561637331aa578e52bb89ecbba5edcb7a9
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Wed Sep 26 23:45:45 2012 +0100

    dm: retain table limits when swapping to new table with no devices
    
    Add a safety net that will re-use the DM device's existing limits in the
    event that DM device has a temporary table that doesn't have any
    component devices.  This is to reduce the chance that requests not
    respecting the hardware limits will reach the device.
    
    DM recalculates queue limits based only on devices which currently exist
    in the table.  This creates a problem in the event all devices are
    temporarily removed such as all paths being lost in multipath.  DM will
    reset the limits to the maximum permissible, which can then assemble
    requests which exceed the limits of the paths when the paths are
    restored.  The request will fail the blk_rq_check_limits() test when
    sent to a path with lower limits, and will be retried without end by
    multipath.  This became a much bigger issue after v3.6 commit fe86cdcef
    ("block: do not artificially constrain max_sectors for stacking
    drivers").
    
    Reported-by: David Jeffery <djeffery@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 52eef493d266..6a99fefaa743 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -54,6 +54,7 @@ void dm_table_event_callback(struct dm_table *t,
 			     void (*fn)(void *), void *context);
 struct dm_target *dm_table_get_target(struct dm_table *t, unsigned int index);
 struct dm_target *dm_table_find_target(struct dm_table *t, sector_t sector);
+bool dm_table_has_no_data_devices(struct dm_table *table);
 int dm_calculate_queue_limits(struct dm_table *table,
 			      struct queue_limits *limits);
 void dm_table_set_restrictions(struct dm_table *t, struct request_queue *q,

commit 1f4e0ff07980820977f45d6a5dbc81d3bb9ce4d3
Author: Alasdair G Kergon <agk@redhat.com>
Date:   Fri Jul 27 15:08:16 2012 +0100

    dm thin: commit before gathering status
    
    Commit outstanding metadata before returning the status for a dm thin
    pool so that the numbers reported are as up-to-date as possible.
    
    The commit is not performed if the device is suspended or if
    the DM_NOFLUSH_FLAG is supplied by userspace and passed to the target
    through a new 'status_flags' parameter in the target's dm_status_fn.
    
    The userspace dmsetup tool will support the --noflush flag with the
    'dmsetup status' and 'dmsetup wait' commands from version 1.02.76
    onwards.
    
    Tested-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index b7dacd59d8d7..52eef493d266 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -22,6 +22,11 @@
 #define DM_SUSPEND_LOCKFS_FLAG		(1 << 0)
 #define DM_SUSPEND_NOFLUSH_FLAG		(1 << 1)
 
+/*
+ * Status feature flags
+ */
+#define DM_STATUS_NOFLUSH_FLAG		(1 << 0)
+
 /*
  * Type of table and mapped_device's mempool
  */

commit 36a0456fbf2d9680bf9af81b39daf4a8e22cb1b8
Author: Alasdair G Kergon <agk@redhat.com>
Date:   Mon Oct 31 20:19:04 2011 +0000

    dm table: add immutable feature
    
    Introduce DM_TARGET_IMMUTABLE to indicate that the target type cannot be mixed
    with any other target type, and once loaded into a device, it cannot be
    replaced with a table containing a different type.
    
    The thin provisioning pool device will use this.
    
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 6745dbd278a4..b7dacd59d8d7 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -60,6 +60,7 @@ int dm_table_resume_targets(struct dm_table *t);
 int dm_table_any_congested(struct dm_table *t, int bdi_bits);
 int dm_table_any_busy_target(struct dm_table *t);
 unsigned dm_table_get_type(struct dm_table *t);
+struct target_type *dm_table_get_immutable_target_type(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);
 bool dm_table_supports_discards(struct dm_table *t);
 int dm_table_alloc_md_mempools(struct dm_table *t);
@@ -72,6 +73,7 @@ void dm_lock_md_type(struct mapped_device *md);
 void dm_unlock_md_type(struct mapped_device *md);
 void dm_set_md_type(struct mapped_device *md, unsigned type);
 unsigned dm_get_md_type(struct mapped_device *md);
+struct target_type *dm_get_immutable_target_type(struct mapped_device *md);
 
 int dm_setup_md_queue(struct mapped_device *md);
 

commit d5b9dd04bd74b774b8e8d93ced7a0d15ad403fa9
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Tue Aug 2 12:32:04 2011 +0100

    dm: ignore merge_bvec for snapshots when safe
    
    Add a new flag DMF_MERGE_IS_OPTIONAL to struct mapped_device to indicate
    whether the device can accept bios larger than the size its merge
    function returns.  When set, use this to send large bios to snapshots
    which can split them if necessary.  Snapshot I/O may be significantly
    fragmented and this approach seems to improve peformance.
    
    Before the patch, dm_set_device_limits restricted bio size to page size
    if the underlying device had a merge function and the target didn't
    provide a merge function.  After the patch, dm_set_device_limits
    restricts bio size to page size if the underlying device has a merge
    function, doesn't have DMF_MERGE_IS_OPTIONAL flag and the target doesn't
    provide a merge function.
    
    The snapshot target can't provide a merge function because when the merge
    function is called, it is impossible to determine where the bio will be
    remapped.  Previously this led us to impose a 4k limit, which we can
    now remove if the snapshot store is located on a device without a merge
    function.  Together with another patch for optimizing full chunk writes,
    it improves performance from 29MB/s to 40MB/s when writing to the
    filesystem on snapshot store.
    
    If the snapshot store is placed on a non-dm device with a merge function
    (such as md-raid), device mapper still limits all bios to page size.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 1aaf16746da8..6745dbd278a4 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -66,6 +66,8 @@ int dm_table_alloc_md_mempools(struct dm_table *t);
 void dm_table_free_md_mempools(struct dm_table *t);
 struct dm_md_mempools *dm_table_get_md_mempools(struct dm_table *t);
 
+int dm_queue_merge_is_compulsory(struct request_queue *q);
+
 void dm_lock_md_type(struct mapped_device *md);
 void dm_unlock_md_type(struct mapped_device *md);
 void dm_set_md_type(struct mapped_device *md, unsigned type);

commit a91a2785b200864aef2270ed6a3babac7a253a20
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Thu Mar 17 11:11:05 2011 +0100

    block: Require subsystems to explicitly allocate bio_set integrity mempool
    
    MD and DM create a new bio_set for every metadevice. Each bio_set has an
    integrity mempool attached regardless of whether the metadevice is
    capable of passing integrity metadata. This is a waste of memory.
    
    Instead we defer the allocation decision to MD and DM since we know at
    metadevice creation time whether integrity passthrough is needed or not.
    
    Automatic integrity mempool allocation can then be removed from
    bioset_create() and we make an explicit integrity allocation for the
    fs_bio_set.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reported-by: Zdenek Kabelac <zkabelac@redhat.com>
    Acked-by: Mike Snitzer <snizer@redhat.com>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 0c2dd5f4af76..1aaf16746da8 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -149,7 +149,7 @@ void dm_kcopyd_exit(void);
 /*
  * Mempool operations
  */
-struct dm_md_mempools *dm_alloc_md_mempools(unsigned type);
+struct dm_md_mempools *dm_alloc_md_mempools(unsigned type, unsigned integrity);
 void dm_free_md_mempools(struct dm_md_mempools *pools);
 
 #endif

commit 5ae89a8720c28caf35c4e53711d77df2856c404e
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Thu Aug 12 04:14:08 2010 +0100

    dm: linear support discard
    
    Allow discards to be passed through to linear mappings if at least one
    underlying device supports it.  Discards will be forwarded only to
    devices that support them.
    
    A target that supports discards should set num_discard_requests to
    indicate how many times each discard request must be submitted to it.
    
    Verify table's underlying devices support discards prior to setting the
    associated DM device as capable of discards (via QUEUE_FLAG_DISCARD).
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Reviewed-by: Joe Thornber <thornber@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 0d7b374c5dc2..0c2dd5f4af76 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -61,6 +61,7 @@ int dm_table_any_congested(struct dm_table *t, int bdi_bits);
 int dm_table_any_busy_target(struct dm_table *t);
 unsigned dm_table_get_type(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);
+bool dm_table_supports_discards(struct dm_table *t);
 int dm_table_alloc_md_mempools(struct dm_table *t);
 void dm_table_free_md_mempools(struct dm_table *t);
 struct dm_md_mempools *dm_table_get_md_mempools(struct dm_table *t);

commit 26803b9f06d365122fae82e7554a66ef8278e0bb
Author: Will Drewry <wad@chromium.org>
Date:   Thu Aug 12 04:14:03 2010 +0100

    dm ioctl: refactor dm_table_complete
    
    This change unifies the various checks and finalization that occurs on a
    table prior to use.  By doing so, it allows table construction without
    traversing the dm-ioctl interface.
    
    Signed-off-by: Will Drewry <wad@chromium.org>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 450fbd98c48c..0d7b374c5dc2 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -59,7 +59,6 @@ void dm_table_postsuspend_targets(struct dm_table *t);
 int dm_table_resume_targets(struct dm_table *t);
 int dm_table_any_congested(struct dm_table *t, int bdi_bits);
 int dm_table_any_busy_target(struct dm_table *t);
-int dm_table_set_type(struct dm_table *t);
 unsigned dm_table_get_type(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);
 int dm_table_alloc_md_mempools(struct dm_table *t);

commit 4a0b4ddf261fc89c050fe0a10ec57a61251d7ac0
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Thu Aug 12 04:14:02 2010 +0100

    dm: do not initialise full request queue when bio based
    
    Change bio-based mapped devices no longer to have a fully initialized
    request_queue (request_fn, elevator, etc).  This means bio-based DM
    devices no longer register elevator sysfs attributes ('iosched/' tree
    or 'scheduler' other than "none").
    
    In contrast, a request-based DM device will continue to have a full
    request_queue and will register elevator sysfs attributes.  Therefore
    a user can determine a DM device's type by checking if elevator sysfs
    attributes exist.
    
    First allocate a minimalist request_queue structure for a DM device
    (needed for both bio and request-based DM).
    
    Initialization of a full request_queue is deferred until it is known
    that the DM device is request-based, at the end of the table load
    sequence.
    
    Factor DM device's request_queue initialization:
    - common to both request-based and bio-based into dm_init_md_queue().
    - specific to request-based into dm_init_request_based_queue().
    
    The md->type_lock mutex is used to protect md->queue, in addition to
    md->type, during table_load().
    
    A DM device's first table_load will establish the immutable md->type.
    But md->queue initialization, based on md->type, may fail at that time
    (because blk_init_allocated_queue cannot allocate memory).  Therefore
    any subsequent table_load must (re)try dm_setup_md_queue independently of
    establishing md->type.
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Acked-by: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 1db782530ce6..450fbd98c48c 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -71,6 +71,8 @@ void dm_unlock_md_type(struct mapped_device *md);
 void dm_set_md_type(struct mapped_device *md, unsigned type);
 unsigned dm_get_md_type(struct mapped_device *md);
 
+int dm_setup_md_queue(struct mapped_device *md);
+
 /*
  * To check the return value from dm_table_find_target().
  */

commit a5664dad7e1a278d2915c2bf79cf42250e12d7db
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Thu Aug 12 04:14:01 2010 +0100

    dm ioctl: make bio or request based device type immutable
    
    Determine whether a mapped device is bio-based or request-based when
    loading its first (inactive) table and don't allow that to be changed
    later.
    
    This patch performs different device initialisation in each of the two
    cases.  (We don't think it's necessary to add code to support changing
    between the two types.)
    
    Allowed md->type transitions:
      DM_TYPE_NONE to DM_TYPE_BIO_BASED
      DM_TYPE_NONE to DM_TYPE_REQUEST_BASED
    
    We now prevent table_load from replacing the inactive table with a
    conflicting type of table even after an explicit table_clear.
    
    Introduce 'type_lock' into the struct mapped_device to protect md->type
    and to prepare for the next patch that will change the queue
    initialization and allocate memory while md->type_lock is held.
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Acked-by: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    
     drivers/md/dm-ioctl.c    |   15 +++++++++++++++
     drivers/md/dm.c          |   37 ++++++++++++++++++++++++++++++-------
     drivers/md/dm.h          |    5 +++++
     include/linux/dm-ioctl.h |    4 ++--
     4 files changed, 52 insertions(+), 9 deletions(-)

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 8223671e4901..1db782530ce6 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -66,6 +66,11 @@ int dm_table_alloc_md_mempools(struct dm_table *t);
 void dm_table_free_md_mempools(struct dm_table *t);
 struct dm_md_mempools *dm_table_get_md_mempools(struct dm_table *t);
 
+void dm_lock_md_type(struct mapped_device *md);
+void dm_unlock_md_type(struct mapped_device *md);
+void dm_set_md_type(struct mapped_device *md, unsigned type);
+unsigned dm_get_md_type(struct mapped_device *md);
+
 /*
  * To check the return value from dm_table_find_target().
  */

commit 3f77316de0ec0fd208467fbee8d9edc70e2c73b2
Author: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
Date:   Thu Aug 12 04:13:56 2010 +0100

    dm: separate device deletion from dm_put
    
    This patch separates the device deletion code from dm_put()
    to make sure the deletion happens in the process context.
    
    By this patch, device deletion always occurs in an ioctl (process)
    context and dm_put() can be called in interrupt context.
    As a result, the request-based dm's bad dm_put() usage pointed out
    by Mikulas below disappears.
        http://marc.info/?l=dm-devel&m=126699981019735&w=2
    
    Without this patch, I confirmed there is a case to crash the system:
        dm_put() => dm_table_destroy() => vfree() => BUG_ON(in_interrupt())
    
    Some more backgrounds and details:
    In request-based dm, a device opener can remove a mapped_device
    while the last request is still completing, because bios in the last
    request complete first and then the device opener can close and remove
    the mapped_device before the last request completes:
      CPU0                                          CPU1
      =================================================================
      <<INTERRUPT>>
      blk_end_request_all(clone_rq)
        blk_update_request(clone_rq)
          bio_endio(clone_bio) == end_clone_bio
            blk_update_request(orig_rq)
              bio_endio(orig_bio)
                                                    <<I/O completed>>
                                                    dm_blk_close()
                                                    dev_remove()
                                                      dm_put(md)
                                                        <<Free md>>
       blk_finish_request(clone_rq)
         ....
         dm_end_request(clone_rq)
           free_rq_clone(clone_rq)
           blk_end_request_all(orig_rq)
           rq_completed(md)
    
    So request-based dm used dm_get()/dm_put() to hold md for each I/O
    until its request completion handling is fully done.
    However, the final dm_put() can call the device deletion code which
    must not be run in interrupt context and may cause kernel panic.
    
    To solve the problem, this patch moves the device deletion code,
    dm_destroy(), to predetermined places that is actually deleting
    the mapped_device in ioctl (process) context, and changes dm_put()
    just to decrement the reference count of the mapped_device.
    By this change, dm_put() can be used in any context and the symmetric
    model below is introduced:
        dm_create():  create a mapped_device
        dm_destroy(): destroy a mapped_device
        dm_get():     increment the reference count of a mapped_device
        dm_put():     decrement the reference count of a mapped_device
    
    dm_destroy() waits for all references of the mapped_device to disappear,
    then deletes the mapped_device.
    
    dm_destroy() uses active waiting with msleep(1), since deleting
    the mapped_device isn't performance-critical task.
    And since at this point, nobody opens the mapped_device and no new
    reference will be taken, the pending counts are just for racing
    completing activity and will eventually decrease to zero.
    
    For the unlikely case of the forced module unload, dm_destroy_immediate(),
    which doesn't wait and forcibly deletes the mapped_device, is also
    introduced and used in dm_hash_remove_all().  Otherwise, "rmmod -f"
    may be stuck and never return.
    And now, because the mapped_device is deleted at this point, subsequent
    accesses to the mapped_device may cause NULL pointer references.
    
    Cc: stable@kernel.org
    Signed-off-by: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index bad1724d4869..8223671e4901 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -122,6 +122,11 @@ void dm_linear_exit(void);
 int dm_stripe_init(void);
 void dm_stripe_exit(void);
 
+/*
+ * mapped_device operations
+ */
+void dm_destroy(struct mapped_device *md);
+void dm_destroy_immediate(struct mapped_device *md);
 int dm_open_count(struct mapped_device *md);
 int dm_lock_for_deletion(struct mapped_device *md);
 

commit 3abf85b5b5851b5f28d3d8a920ebb844edd08352
Author: Peter Rajnoha <prajnoha@redhat.com>
Date:   Sat Mar 6 02:32:31 2010 +0000

    dm ioctl: introduce flag indicating uevent was generated
    
    Set a new DM_UEVENT_GENERATED_FLAG when returning from ioctls to
    indicate that a uevent was actually generated.  This tells the userspace
    caller that it may need to wait for the event to be processed.
    
    Signed-off-by: Peter Rajnoha <prajnoha@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 8dadaa5bc396..bad1724d4869 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -125,8 +125,8 @@ void dm_stripe_exit(void);
 int dm_open_count(struct mapped_device *md);
 int dm_lock_for_deletion(struct mapped_device *md);
 
-void dm_kobject_uevent(struct mapped_device *md, enum kobject_action action,
-		       unsigned cookie);
+int dm_kobject_uevent(struct mapped_device *md, enum kobject_action action,
+		      unsigned cookie);
 
 int dm_io_init(void);
 void dm_io_exit(void);

commit 4f186f8bbfa92bf1a2b39f7a8674348bfdba9437
Author: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
Date:   Thu Dec 10 23:52:26 2009 +0000

    dm: rename dm_suspended to dm_suspended_md
    
    This patch renames dm_suspended() to dm_suspended_md() and
    keeps it internal to dm.
    No functional change.
    
    Signed-off-by: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Cc: Mike Anderson <andmike@linux.vnet.ibm.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 604a5f2a2383..8dadaa5bc396 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -93,6 +93,11 @@ int dm_split_args(int *argc, char ***argvp, char *input);
  */
 int dm_deleting_md(struct mapped_device *md);
 
+/*
+ * Is this mapped_device suspended?
+ */
+int dm_suspended_md(struct mapped_device *md);
+
 /*
  * The device-mapper can be driven through one of two interfaces;
  * ioctl or filesystem, depending which patch you have applied.

commit 432a212c0dd0f4ca386cf37c5b740ac9dbda4479
Author: Mike Anderson <andmike@linux.vnet.ibm.com>
Date:   Thu Dec 10 23:52:20 2009 +0000

    dm: add dm_deleting_md function
    
    Add dm_deleting_md to check whether or not a given mapped
    device is currently being deleted.
    
    Signed-off-by: Mike Anderson <andmike@linux.vnet.ibm.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 4a95e8fa3607..604a5f2a2383 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -88,6 +88,11 @@ int dm_target_iterate(void (*iter_func)(struct target_type *tt,
 
 int dm_split_args(int *argc, char ***argvp, char *input);
 
+/*
+ * Is this mapped_device being deleted?
+ */
+int dm_deleting_md(struct mapped_device *md);
+
 /*
  * The device-mapper can be driven through one of two interfaces;
  * ioctl or filesystem, depending which patch you have applied.

commit 952b355760c196ec014dd0b6878f85a11496e3da
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Thu Dec 10 23:51:57 2009 +0000

    dm io: use slab for struct io
    
    Allocate "struct io" from a slab.
    
    This patch changes dm-io, so that "struct io" is allocated from a slab cache.
    It used to be allocated with kmalloc. Allocating from a slab will be needed
    for the next patch, because it requires a special alignment of "struct io"
    and kmalloc cannot meet this alignment.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index a7663eba17e2..4a95e8fa3607 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -118,6 +118,9 @@ int dm_lock_for_deletion(struct mapped_device *md);
 void dm_kobject_uevent(struct mapped_device *md, enum kobject_action action,
 		       unsigned cookie);
 
+int dm_io_init(void);
+void dm_io_exit(void);
+
 int dm_kcopyd_init(void);
 void dm_kcopyd_exit(void);
 

commit a732c207d19e899845ae47139708af898daaf9fd
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Thu Jul 23 20:30:40 2009 +0100

    dm: remove queue next_ordered workaround for barriers
    
    This patch removes DM's bio-based vs request-based conditional setting
    of next_ordered.  For bio-based DM the next_ordered check is no longer a
    concern (as that check is now in the __make_request path).  For
    request-based DM the default of QUEUE_ORDERED_NONE is now appropriate.
    
    bio-based DM was changed to work-around the previously misplaced
    next_ordered check with this commit:
    99360b4c18f7675b50d283301d46d755affe75fd
    
    request-based DM does not yet support barriers but reacted to the above
    bio-based DM change with this commit:
    5d67aa2366ccb8257d103d0b43df855605c3c086
    
    The above changes are no longer needed given Neil Brown's recent fix to
    put the next_ordered check in the __make_request path:
    db64f680ba4b5c56c4be59f0698000df89ff0281
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Cc: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Cc: NeilBrown <neilb@suse.de>
    Acked-by: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
    Acked-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 23278ae80f08..a7663eba17e2 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -61,7 +61,6 @@ int dm_table_any_congested(struct dm_table *t, int bdi_bits);
 int dm_table_any_busy_target(struct dm_table *t);
 int dm_table_set_type(struct dm_table *t);
 unsigned dm_table_get_type(struct dm_table *t);
-bool dm_table_bio_based(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);
 int dm_table_alloc_md_mempools(struct dm_table *t);
 void dm_table_free_md_mempools(struct dm_table *t);

commit 5d67aa2366ccb8257d103d0b43df855605c3c086
Author: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
Date:   Mon Jun 22 10:12:36 2009 +0100

    dm: do not set QUEUE_ORDERED_DRAIN if request based
    
    Request-based dm doesn't have barrier support yet.
    So we need to set QUEUE_ORDERED_DRAIN only for bio-based dm.
    Since the device type is decided at the first table loading time,
    the flag set is deferred until then.
    
    Signed-off-by: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Acked-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index a7663eba17e2..23278ae80f08 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -61,6 +61,7 @@ int dm_table_any_congested(struct dm_table *t, int bdi_bits);
 int dm_table_any_busy_target(struct dm_table *t);
 int dm_table_set_type(struct dm_table *t);
 unsigned dm_table_get_type(struct dm_table *t);
+bool dm_table_bio_based(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);
 int dm_table_alloc_md_mempools(struct dm_table *t);
 void dm_table_free_md_mempools(struct dm_table *t);

commit e6ee8c0b767540f59e20da3ced282601db8aa502
Author: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
Date:   Mon Jun 22 10:12:36 2009 +0100

    dm: enable request based option
    
    This patch enables request-based dm.
    
    o Request-based dm and bio-based dm coexist, since there are
      some target drivers which are more fitting to bio-based dm.
      Also, there are other bio-based devices in the kernel
      (e.g. md, loop).
      Since bio-based device can't receive struct request,
      there are some limitations on device stacking between
      bio-based and request-based.
    
                         type of underlying device
                       bio-based      request-based
       ----------------------------------------------
        bio-based         OK                OK
        request-based     --                OK
    
      The device type is recognized by the queue flag in the kernel,
      so dm follows that.
    
    o The type of a dm device is decided at the first table binding time.
      Once the type of a dm device is decided, the type can't be changed.
    
    o Mempool allocations are deferred to at the table loading time, since
      mempools for request-based dm are different from those for bio-based
      dm and needed mempool type is fixed by the type of table.
    
    o Currently, request-based dm supports only tables that have a single
      target.  To support multiple targets, we need to support request
      splitting or prevent bio/request from spanning multiple targets.
      The former needs lots of changes in the block layer, and the latter
      needs that all target drivers support merge() function.
      Both will take a time.
    
    Signed-off-by: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 8dcabb1caff1..a7663eba17e2 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -22,6 +22,13 @@
 #define DM_SUSPEND_LOCKFS_FLAG		(1 << 0)
 #define DM_SUSPEND_NOFLUSH_FLAG		(1 << 1)
 
+/*
+ * Type of table and mapped_device's mempool
+ */
+#define DM_TYPE_NONE		0
+#define DM_TYPE_BIO_BASED	1
+#define DM_TYPE_REQUEST_BASED	2
+
 /*
  * List of devices that a metadevice uses and should open/close.
  */
@@ -32,6 +39,7 @@ struct dm_dev_internal {
 };
 
 struct dm_table;
+struct dm_md_mempools;
 
 /*-----------------------------------------------------------------
  * Internal table functions.
@@ -51,12 +59,23 @@ void dm_table_postsuspend_targets(struct dm_table *t);
 int dm_table_resume_targets(struct dm_table *t);
 int dm_table_any_congested(struct dm_table *t, int bdi_bits);
 int dm_table_any_busy_target(struct dm_table *t);
+int dm_table_set_type(struct dm_table *t);
+unsigned dm_table_get_type(struct dm_table *t);
+bool dm_table_request_based(struct dm_table *t);
+int dm_table_alloc_md_mempools(struct dm_table *t);
+void dm_table_free_md_mempools(struct dm_table *t);
+struct dm_md_mempools *dm_table_get_md_mempools(struct dm_table *t);
 
 /*
  * To check the return value from dm_table_find_target().
  */
 #define dm_target_is_valid(t) ((t)->table)
 
+/*
+ * To check whether the target type is request-based or not (bio-based).
+ */
+#define dm_target_request_based(t) ((t)->type->map_rq != NULL)
+
 /*-----------------------------------------------------------------
  * A registry of target types.
  *---------------------------------------------------------------*/
@@ -102,4 +121,10 @@ void dm_kobject_uevent(struct mapped_device *md, enum kobject_action action,
 int dm_kcopyd_init(void);
 void dm_kcopyd_exit(void);
 
+/*
+ * Mempool operations
+ */
+struct dm_md_mempools *dm_alloc_md_mempools(unsigned type);
+void dm_free_md_mempools(struct dm_md_mempools *pools);
+
 #endif

commit cec47e3d4a861e1d942b3a580d0bbef2700d2bb2
Author: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
Date:   Mon Jun 22 10:12:35 2009 +0100

    dm: prepare for request based option
    
    This patch adds core functions for request-based dm.
    
    When struct mapped device (md) is initialized, md->queue has
    an I/O scheduler and the following functions are used for
    request-based dm as the queue functions:
        make_request_fn: dm_make_request()
        pref_fn:         dm_prep_fn()
        request_fn:      dm_request_fn()
        softirq_done_fn: dm_softirq_done()
        lld_busy_fn:     dm_lld_busy()
    Actual initializations are done in another patch (PATCH 2).
    
    Below is a brief summary of how request-based dm behaves, including:
      - making request from bio
      - cloning, mapping and dispatching request
      - completing request and bio
      - suspending md
      - resuming md
    
      bio to request
      ==============
      md->queue->make_request_fn() (dm_make_request()) calls __make_request()
      for a bio submitted to the md.
      Then, the bio is kept in the queue as a new request or merged into
      another request in the queue if possible.
    
      Cloning and Mapping
      ===================
      Cloning and mapping are done in md->queue->request_fn() (dm_request_fn()),
      when requests are dispatched after they are sorted by the I/O scheduler.
    
      dm_request_fn() checks busy state of underlying devices using
      target's busy() function and stops dispatching requests to keep them
      on the dm device's queue if busy.
      It helps better I/O merging, since no merge is done for a request
      once it is dispatched to underlying devices.
    
      Actual cloning and mapping are done in dm_prep_fn() and map_request()
      called from dm_request_fn().
      dm_prep_fn() clones not only request but also bios of the request
      so that dm can hold bio completion in error cases and prevent
      the bio submitter from noticing the error.
      (See the "Completion" section below for details.)
    
      After the cloning, the clone is mapped by target's map_rq() function
        and inserted to underlying device's queue using
        blk_insert_cloned_request().
    
      Completion
      ==========
      Request completion can be hooked by rq->end_io(), but then, all bios
      in the request will have been completed even error cases, and the bio
      submitter will have noticed the error.
      To prevent the bio completion in error cases, request-based dm clones
      both bio and request and hooks both bio->bi_end_io() and rq->end_io():
          bio->bi_end_io(): end_clone_bio()
          rq->end_io():     end_clone_request()
    
      Summary of the request completion flow is below:
      blk_end_request() for a clone request
        => blk_update_request()
           => bio->bi_end_io() == end_clone_bio() for each clone bio
              => Free the clone bio
              => Success: Complete the original bio (blk_update_request())
                 Error:   Don't complete the original bio
        => blk_finish_request()
           => rq->end_io() == end_clone_request()
              => blk_complete_request()
                 => dm_softirq_done()
                    => Free the clone request
                    => Success: Complete the original request (blk_end_request())
                       Error:   Requeue the original request
    
      end_clone_bio() completes the original request on the size of
      the original bio in successful cases.
      Even if all bios in the original request are completed by that
      completion, the original request must not be completed yet to keep
      the ordering of request completion for the stacking.
      So end_clone_bio() uses blk_update_request() instead of
      blk_end_request().
      In error cases, end_clone_bio() doesn't complete the original bio.
      It just frees the cloned bio and gives over the error handling to
      end_clone_request().
    
      end_clone_request(), which is called with queue lock held, completes
      the clone request and the original request in a softirq context
      (dm_softirq_done()), which has no queue lock, to avoid a deadlock
      issue on submission of another request during the completion:
          - The submitted request may be mapped to the same device
          - Request submission requires queue lock, but the queue lock
            has been held by itself and it doesn't know that
    
      The clone request has no clone bio when dm_softirq_done() is called.
      So target drivers can't resubmit it again even error cases.
      Instead, they can ask dm core for requeueing and remapping
      the original request in that cases.
    
      suspend
      =======
      Request-based dm uses stopping md->queue as suspend of the md.
      For noflush suspend, just stops md->queue.
    
      For flush suspend, inserts a marker request to the tail of md->queue.
      And dispatches all requests in md->queue until the marker comes to
      the front of md->queue.  Then, stops dispatching request and waits
      for the all dispatched requests to complete.
      After that, completes the marker request, stops md->queue and
      wake up the waiter on the suspend queue, md->wait.
    
      resume
      ======
      Starts md->queue.
    
    Signed-off-by: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 604e85caadf6..8dcabb1caff1 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -50,6 +50,7 @@ void dm_table_presuspend_targets(struct dm_table *t);
 void dm_table_postsuspend_targets(struct dm_table *t);
 int dm_table_resume_targets(struct dm_table *t);
 int dm_table_any_congested(struct dm_table *t, int bdi_bits);
+int dm_table_any_busy_target(struct dm_table *t);
 
 /*
  * To check the return value from dm_table_find_target().

commit 754c5fc7ebb417b23601a6222a6005cc2e7f2913
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Mon Jun 22 10:12:34 2009 +0100

    dm: calculate queue limits during resume not load
    
    Currently, device-mapper maintains a separate instance of 'struct
    queue_limits' for each table of each device.  When the configuration of
    a device is to be changed, first its table is loaded and this structure
    is populated, then the device is 'resumed' and the calculated
    queue_limits are applied.
    
    This places restrictions on how userspace may process related devices,
    where it is often advantageous to 'load' tables for several devices
    at once before 'resuming' them together.  As the new queue_limits
    only take effect after the 'resume', if they are changing and one
    device uses another, the latter must be 'resumed' before the former
    may be 'loaded'.
    
    This patch moves the calculation of these queue_limits out of
    the 'load' operation into 'resume'.  Since we are no longer
    pre-calculating this struct, we no longer need to maintain copies
    within our dm structs.
    
    dm_set_device_limits() now passes the 'start' of the device's
    data area (aka pe_start) as the 'offset' to blk_stack_limits().
    
    init_valid_queue_limits() is replaced by blk_set_default_limits().
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Cc: martin.petersen@oracle.com
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index b5935c610c44..604e85caadf6 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -41,7 +41,10 @@ void dm_table_event_callback(struct dm_table *t,
 			     void (*fn)(void *), void *context);
 struct dm_target *dm_table_get_target(struct dm_table *t, unsigned int index);
 struct dm_target *dm_table_find_target(struct dm_table *t, sector_t sector);
-void dm_table_set_restrictions(struct dm_table *t, struct request_queue *q);
+int dm_calculate_queue_limits(struct dm_table *table,
+			      struct queue_limits *limits);
+void dm_table_set_restrictions(struct dm_table *t, struct request_queue *q,
+			       struct queue_limits *limits);
 struct list_head *dm_table_get_devices(struct dm_table *t);
 void dm_table_presuspend_targets(struct dm_table *t);
 void dm_table_postsuspend_targets(struct dm_table *t);

commit 60935eb21d3c5bac79618000f38f92c249d153c4
Author: Milan Broz <mbroz@redhat.com>
Date:   Mon Jun 22 10:12:30 2009 +0100

    dm ioctl: support cookies for udev
    
    Add support for passing a 32 bit "cookie" into the kernel with the
    DM_SUSPEND, DM_DEV_RENAME and DM_DEV_REMOVE ioctls.  The (unsigned)
    value of this cookie is returned to userspace alongside the uevents
    issued by these ioctls in the variable DM_COOKIE.
    
    This means the userspace process issuing these ioctls can be notified
    by udev after udev has completed any actions triggered.
    
    To minimise the interface extension, we pass the cookie into the
    kernel in the event_nr field which is otherwise unused when calling
    these ioctls.  Incrementing the version number allows userspace to
    determine in advance whether or not the kernel supports the cookie.
    If the kernel does support this but userspace does not, there should
    be no impact as the new variable will just get ignored.
    
    Signed-off-by: Milan Broz <mbroz@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index a31506d93e91..b5935c610c44 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -92,7 +92,8 @@ void dm_stripe_exit(void);
 int dm_open_count(struct mapped_device *md);
 int dm_lock_for_deletion(struct mapped_device *md);
 
-void dm_kobject_uevent(struct mapped_device *md);
+void dm_kobject_uevent(struct mapped_device *md, enum kobject_action action,
+		       unsigned cookie);
 
 int dm_kcopyd_init(void);
 void dm_kcopyd_exit(void);

commit 692d0eb9e02cf81fb387ff891f53840db2f3110a
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Thu Apr 9 00:27:13 2009 +0100

    dm: remove limited barrier support
    
    Prepare for full barrier implementation: first remove the restricted support.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index b48397c0abbd..a31506d93e91 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -52,7 +52,6 @@ int dm_table_any_congested(struct dm_table *t, int bdi_bits);
  * To check the return value from dm_table_find_target().
  */
 #define dm_target_is_valid(t) ((t)->table)
-int dm_table_barrier_ok(struct dm_table *t);
 
 /*-----------------------------------------------------------------
  * A registry of target types.

commit 45194e4f89fbdd97a2b7d2698c05f0b00c19e820
Author: Cheng Renquan <crquan@gmail.com>
Date:   Thu Apr 2 19:55:28 2009 +0100

    dm target: remove struct tt_internal
    
    The tt_internal is really just a list_head to manage registered target_type
    in a double linked list,
    
    Here embed the list_head into target_type directly,
    1. to avoid kmalloc/kfree;
    2. then tt_internal is really unneeded;
    
    Cc: stable@kernel.org
    Signed-off-by: Cheng Renquan <crquan@gmail.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Reviewed-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 20194e000c5a..b48397c0abbd 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -60,7 +60,7 @@ int dm_table_barrier_ok(struct dm_table *t);
 int dm_target_init(void);
 void dm_target_exit(void);
 struct target_type *dm_get_target_type(const char *name);
-void dm_put_target_type(struct target_type *t);
+void dm_put_target_type(struct target_type *tt);
 int dm_target_iterate(void (*iter_func)(struct target_type *tt,
 					void *param), void *param);
 

commit 784aae735d9b0bba3f8b9faef4c8b30df3bf0128
Author: Milan Broz <mbroz@redhat.com>
Date:   Tue Jan 6 03:05:12 2009 +0000

    dm: add name and uuid to sysfs
    
    Implement simple read-only sysfs entry for device-mapper block device.
    
    This patch adds a simple sysfs directory named "dm" under block device
    properties and implements
            - name attribute (string containing mapped device name)
            - uuid attribute (string containing UUID, or empty string if not set)
    
    The kobject is embedded in mapped_device struct, so no additional
    memory allocation is needed for initializing sysfs entry.
    
    During the processing of sysfs attribute we need to lock mapped device
    which is done by a new function dm_get_from_kobj, which returns the md
    associated with kobject and increases the usage count.
    
    Each 'show attribute' function is responsible for its own locking.
    
    Signed-off-by: Milan Broz <mbroz@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index bbbe9110f3bf..20194e000c5a 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -73,6 +73,14 @@ int dm_split_args(int *argc, char ***argvp, char *input);
 int dm_interface_init(void);
 void dm_interface_exit(void);
 
+/*
+ * sysfs interface
+ */
+int dm_sysfs_init(struct mapped_device *md);
+void dm_sysfs_exit(struct mapped_device *md);
+struct kobject *dm_kobject(struct mapped_device *md);
+struct mapped_device *dm_get_from_kobject(struct kobject *kobj);
+
 /*
  * Targets for linear and striped mappings
  */

commit d58168763f74d1edbc296d7038c60efe6493fdd4
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Tue Jan 6 03:05:10 2009 +0000

    dm table: rework reference counting
    
    Rework table reference counting.
    
    The existing code uses a reference counter. When the last reference is
    dropped and the counter reaches zero, the table destructor is called.
    Table reference counters are acquired/released from upcalls from other
    kernel code (dm_any_congested, dm_merge_bvec, dm_unplug_all).
    If the reference counter reaches zero in one of the upcalls, the table
    destructor is called from almost random kernel code.
    
    This leads to various problems:
    * dm_any_congested being called under a spinlock, which calls the
      destructor, which calls some sleeping function.
    * the destructor attempting to take a lock that is already taken by the
      same process.
    * stale reference from some other kernel code keeps the table
      constructed, which keeps some devices open, even after successful
      return from "dmsetup remove". This can confuse lvm and prevent closing
      of underlying devices or reusing device minor numbers.
    
    The patch changes reference counting so that the table destructor can be
    called only at predetermined places.
    
    The table has always exactly one reference from either mapped_device->map
    or hash_cell->new_map. After this patch, this reference is not counted
    in table->holders.  A pair of dm_create_table/dm_destroy_table functions
    is used for table creation/destruction.
    
    Temporary references from the other code increase table->holders. A pair
    of dm_table_get/dm_table_put functions is used to manipulate it.
    
    When the table is about to be destroyed, we wait for table->holders to
    reach 0. Then, we call the table destructor.  We use active waiting with
    msleep(1), because the situation happens rarely (to one user in 5 years)
    and removing the device isn't performance-critical task: the user doesn't
    care if it takes one tick more or not.
    
    This way, the destructor is called only at specific points
    (dm_table_destroy function) and the above problems associated with lazy
    destruction can't happen.
    
    Finally remove the temporary protection added to dm_any_congested().
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 5b5d08ba9e92..bbbe9110f3bf 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -36,6 +36,7 @@ struct dm_table;
 /*-----------------------------------------------------------------
  * Internal table functions.
  *---------------------------------------------------------------*/
+void dm_table_destroy(struct dm_table *t);
 void dm_table_event_callback(struct dm_table *t,
 			     void (*fn)(void *), void *context);
 struct dm_target *dm_table_get_target(struct dm_table *t, unsigned int index);

commit ab4c1424882be9cd70b89abf2b484add355712fa
Author: Andi Kleen <ak@suse.de>
Date:   Tue Jan 6 03:05:09 2009 +0000

    dm: support barriers on simple devices
    
    Implement barrier support for single device DM devices
    
    This patch implements barrier support in DM for the common case of dm linear
    just remapping a single underlying device. In this case we can safely
    pass the barrier through because there can be no reordering between
    devices.
    
     NB. Any DM device might cease to support barriers if it gets
         reconfigured so code must continue to allow for a possible
         -EOPNOTSUPP on every barrier bio submitted.  - agk
    
    Signed-off-by: Andi Kleen <ak@suse.de>
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 0ade60cdef42..5b5d08ba9e92 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -51,6 +51,7 @@ int dm_table_any_congested(struct dm_table *t, int bdi_bits);
  * To check the return value from dm_table_find_target().
  */
 #define dm_target_is_valid(t) ((t)->table)
+int dm_table_barrier_ok(struct dm_table *t);
 
 /*-----------------------------------------------------------------
  * A registry of target types.

commit d63a5ce3c0d25c96bdadc78792e5b48b846e899d
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Tue Oct 21 17:44:57 2008 +0100

    dm: publish array_too_big
    
    Move array_too_big to include/linux/device-mapper.h because it is
    used by targets.
    
    Remove the test from dm-raid1 as the number of mirror legs is limited
    such that it can never fail.  (Even for stripes it seems rather
    unlikely.)
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index cd189da2b2fa..0ade60cdef42 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -62,15 +62,6 @@ void dm_put_target_type(struct target_type *t);
 int dm_target_iterate(void (*iter_func)(struct target_type *tt,
 					void *param), void *param);
 
-/*-----------------------------------------------------------------
- * Useful inlines.
- *---------------------------------------------------------------*/
-static inline int array_too_big(unsigned long fixed, unsigned long obj,
-				unsigned long num)
-{
-	return (num > (ULONG_MAX - fixed) / obj);
-}
-
 int dm_split_args(int *argc, char ***argvp, char *input);
 
 /*

commit 54160904260fa764ba6e2dc738770be30fdf9553
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Fri Oct 10 13:37:12 2008 +0100

    dm: publish dm_vcalloc
    
    Publish dm_vcalloc in include/linux/device-mapper.h because this function is
    used by targets.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 8812208978e3..cd189da2b2fa 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -89,7 +89,6 @@ void dm_linear_exit(void);
 int dm_stripe_init(void);
 void dm_stripe_exit(void);
 
-void *dm_vcalloc(unsigned long nmemb, unsigned long elem_size);
 int dm_open_count(struct mapped_device *md);
 int dm_lock_for_deletion(struct mapped_device *md);
 

commit ea0ec640940c2ae3a8d71af3249fccf06a9997a3
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Fri Oct 10 13:37:11 2008 +0100

    dm: publish dm_table_unplug_all
    
    Publish dm_table_unplug_all in include/linux/device-mapper.h because this
    function is used by targets.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 911d434361dd..8812208978e3 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -46,7 +46,6 @@ void dm_table_presuspend_targets(struct dm_table *t);
 void dm_table_postsuspend_targets(struct dm_table *t);
 int dm_table_resume_targets(struct dm_table *t);
 int dm_table_any_congested(struct dm_table *t, int bdi_bits);
-void dm_table_unplug_all(struct dm_table *t);
 
 /*
  * To check the return value from dm_table_find_target().

commit 89343da077ad564ed130c46e5ea6a79388410fa5
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Fri Oct 10 13:37:10 2008 +0100

    dm: publish dm_get_mapinfo
    
    Publish dm_get_mapinfo in include/linux/device-mapper.h because this function
    is used by targets.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 65f2f562220e..911d434361dd 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -91,7 +91,6 @@ int dm_stripe_init(void);
 void dm_stripe_exit(void);
 
 void *dm_vcalloc(unsigned long nmemb, unsigned long elem_size);
-union map_info *dm_get_mapinfo(struct bio *bio);
 int dm_open_count(struct mapped_device *md);
 int dm_lock_for_deletion(struct mapped_device *md);
 

commit 82b1519b345d61dcfae526e3fcb08128f39f9bcc
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Fri Oct 10 13:37:09 2008 +0100

    dm: export struct dm_dev
    
    Split struct dm_dev in two and publish the part that other targets need in
    include/linux/device-mapper.h.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 1e59a0b0a78a..65f2f562220e 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -25,13 +25,10 @@
 /*
  * List of devices that a metadevice uses and should open/close.
  */
-struct dm_dev {
+struct dm_dev_internal {
 	struct list_head list;
-
 	atomic_t count;
-	int mode;
-	struct block_device *bdev;
-	char name[16];
+	struct dm_dev dm_dev;
 };
 
 struct dm_table;

commit c8da2f8dd86d70559ec4e50251f6a755b42bd5b4
Author: Adrian Bunk <bunk@kernel.org>
Date:   Mon Jul 21 12:00:27 2008 +0100

    dm log: make dm_dirty_log init and exit static
    
    dm_dirty_log_{init,exit}() can now become static.
    
    Signed-off-by: Adrian Bunk <bunk@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 8c03b634e62e..1e59a0b0a78a 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -100,12 +100,6 @@ int dm_lock_for_deletion(struct mapped_device *md);
 
 void dm_kobject_uevent(struct mapped_device *md);
 
-/*
- * Dirty log
- */
-int dm_dirty_log_init(void);
-void dm_dirty_log_exit(void);
-
 int dm_kcopyd_init(void);
 void dm_kcopyd_exit(void);
 

commit 0da336e5fab75c712ba8c67f3135d5a20528465f
Author: Alasdair G Kergon <agk@redhat.com>
Date:   Thu Apr 24 21:43:52 2008 +0100

    dm: expose macros
    
    Make dm.h macros and inlines available in include/linux/device-mapper.h
    
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 9a6023c9bc6b..8c03b634e62e 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -16,67 +16,6 @@
 #include <linux/blkdev.h>
 #include <linux/hdreg.h>
 
-#define DM_NAME "device-mapper"
-
-#define DMERR(f, arg...) \
-	printk(KERN_ERR DM_NAME ": " DM_MSG_PREFIX ": " f "\n", ## arg)
-#define DMERR_LIMIT(f, arg...) \
-	do { \
-		if (printk_ratelimit())	\
-			printk(KERN_ERR DM_NAME ": " DM_MSG_PREFIX ": " \
-			       f "\n", ## arg); \
-	} while (0)
-
-#define DMWARN(f, arg...) \
-	printk(KERN_WARNING DM_NAME ": " DM_MSG_PREFIX ": " f "\n", ## arg)
-#define DMWARN_LIMIT(f, arg...) \
-	do { \
-		if (printk_ratelimit())	\
-			printk(KERN_WARNING DM_NAME ": " DM_MSG_PREFIX ": " \
-			       f "\n", ## arg); \
-	} while (0)
-
-#define DMINFO(f, arg...) \
-	printk(KERN_INFO DM_NAME ": " DM_MSG_PREFIX ": " f "\n", ## arg)
-#define DMINFO_LIMIT(f, arg...) \
-	do { \
-		if (printk_ratelimit())	\
-			printk(KERN_INFO DM_NAME ": " DM_MSG_PREFIX ": " f \
-			       "\n", ## arg); \
-	} while (0)
-
-#ifdef CONFIG_DM_DEBUG
-#  define DMDEBUG(f, arg...) \
-	printk(KERN_DEBUG DM_NAME ": " DM_MSG_PREFIX " DEBUG: " f "\n", ## arg)
-#  define DMDEBUG_LIMIT(f, arg...) \
-	do { \
-		if (printk_ratelimit())	\
-			printk(KERN_DEBUG DM_NAME ": " DM_MSG_PREFIX ": " f \
-			       "\n", ## arg); \
-	} while (0)
-#else
-#  define DMDEBUG(f, arg...) do {} while (0)
-#  define DMDEBUG_LIMIT(f, arg...) do {} while (0)
-#endif
-
-#define DMEMIT(x...) sz += ((sz >= maxlen) ? \
-			  0 : scnprintf(result + sz, maxlen - sz, x))
-
-#define SECTOR_SHIFT 9
-
-/*
- * Definitions of return values from target end_io function.
- */
-#define DM_ENDIO_INCOMPLETE	1
-#define DM_ENDIO_REQUEUE	2
-
-/*
- * Definitions of return values from target map function.
- */
-#define DM_MAPIO_SUBMITTED	0
-#define DM_MAPIO_REMAPPED	1
-#define DM_MAPIO_REQUEUE	DM_ENDIO_REQUEUE
-
 /*
  * Suspend feature flags
  */
@@ -136,34 +75,6 @@ static inline int array_too_big(unsigned long fixed, unsigned long obj,
 	return (num > (ULONG_MAX - fixed) / obj);
 }
 
-/*
- * Ceiling(n / sz)
- */
-#define dm_div_up(n, sz) (((n) + (sz) - 1) / (sz))
-
-#define dm_sector_div_up(n, sz) ( \
-{ \
-	sector_t _r = ((n) + (sz) - 1); \
-	sector_div(_r, (sz)); \
-	_r; \
-} \
-)
-
-/*
- * ceiling(n / size) * size
- */
-#define dm_round_up(n, sz) (dm_div_up((n), (sz)) * (sz))
-
-static inline sector_t to_sector(unsigned long n)
-{
-	return (n >> 9);
-}
-
-static inline unsigned long to_bytes(sector_t n)
-{
-	return (n << 9);
-}
-
 int dm_split_args(int *argc, char ***argvp, char *input);
 
 /*

commit 945fa4d283a3a472186c11028f6fea1e77a91d14
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Thu Apr 24 21:43:49 2008 +0100

    dm kcopyd: remove redundant client counting
    
    Remove client counting code that is no longer needed.
    
    Initialization and destruction is made globally from dm_init and dm_exit and is
    not based on client counts. Initialization allocates only one empty slab cache,
    so there is no negative impact from performing the initialization always,
    regardless of whether some client uses kcopyd or not.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 17f2d6a8b124..9a6023c9bc6b 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -195,4 +195,7 @@ void dm_kobject_uevent(struct mapped_device *md);
 int dm_dirty_log_init(void);
 void dm_dirty_log_exit(void);
 
+int dm_kcopyd_init(void);
+void dm_kcopyd_exit(void);
+
 #endif

commit 416cd17b1982217bca3dc41b9f00b0b38fdaadad
Author: Heinz Mauelshagen <hjm@redhat.com>
Date:   Thu Apr 24 21:43:35 2008 +0100

    dm log: clean interface
    
    Clean up the dm-log interface to prepare for publishing it in include/linux.
    
    Signed-off-by: Heinz Mauelshagen <hjm@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index b4584a39383b..17f2d6a8b124 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -189,4 +189,10 @@ int dm_lock_for_deletion(struct mapped_device *md);
 
 void dm_kobject_uevent(struct mapped_device *md);
 
+/*
+ * Dirty log
+ */
+int dm_dirty_log_init(void);
+void dm_dirty_log_exit(void);
+
 #endif

commit 69267a30bed1fabec658058c63845528a8b813d4
Author: Alasdair G Kergon <agk@redhat.com>
Date:   Thu Dec 13 14:15:57 2007 +0000

    dm: trigger change uevent on rename
    
    Insert a missing KOBJ_CHANGE notification when a device is renamed.
    
    Cc: Scott James Remnant <scott@ubuntu.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 177297a88ebd..b4584a39383b 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -187,4 +187,6 @@ union map_info *dm_get_mapinfo(struct bio *bio);
 int dm_open_count(struct mapped_device *md);
 int dm_lock_for_deletion(struct mapped_device *md);
 
+void dm_kobject_uevent(struct mapped_device *md);
+
 #endif

commit 512875bd9661368da6f993205a61213b79ba1df0
Author: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
Date:   Thu Dec 13 14:15:25 2007 +0000

    dm: table detect io beyond device
    
    This patch fixes a panic on shrinking a DM device if there is
    outstanding I/O to the part of the device that is being removed.
    (Normally this doesn't happen - a filesystem would be resized first,
    for example.)
    
    The bug is that __clone_and_map() assumes dm_table_find_target()
    always returns a valid pointer.  It may fail if a bio arrives from the
    block layer but its target sector is no longer included in the DM
    btree.
    
    This patch appends an empty entry to table->targets[] which will
    be returned by a lookup beyond the end of the device.
    
    After calling dm_table_find_target(), __clone_and_map() and target_message()
    check for this condition using
    dm_target_is_valid().
    
    Sample test script to trigger oops:

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 4b3faa45277e..177297a88ebd 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -112,6 +112,11 @@ int dm_table_resume_targets(struct dm_table *t);
 int dm_table_any_congested(struct dm_table *t, int bdi_bits);
 void dm_table_unplug_all(struct dm_table *t);
 
+/*
+ * To check the return value from dm_table_find_target().
+ */
+#define dm_target_is_valid(t) ((t)->table)
+
 /*-----------------------------------------------------------------
  * A registry of target types.
  *---------------------------------------------------------------*/

commit fd5d806266935179deda1502101624832eacd01f
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Tue Oct 16 11:05:02 2007 +0200

    block: convert blkdev_issue_flush() to use empty barriers
    
    Then we can get rid of ->issue_flush_fn() and all the driver private
    implementations of that.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 462ee652a890..4b3faa45277e 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -111,7 +111,6 @@ void dm_table_postsuspend_targets(struct dm_table *t);
 int dm_table_resume_targets(struct dm_table *t);
 int dm_table_any_congested(struct dm_table *t, int bdi_bits);
 void dm_table_unplug_all(struct dm_table *t);
-int dm_table_flush_all(struct dm_table *t);
 
 /*-----------------------------------------------------------------
  * A registry of target types.

commit d0d444c7d48c14d59f665887c758fde248f1cb37
Author: Jonathan Brassow <jbrassow@redhat.com>
Date:   Thu Jul 12 17:28:42 2007 +0100

    dm: add ratelimit logging macros
    
    Add ratelimit extension to dm logging macros.
    
    Signed-off-by: Jonathan Brassow <jbrassow@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 2f796b1436b2..462ee652a890 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -18,13 +18,45 @@
 
 #define DM_NAME "device-mapper"
 
-#define DMERR(f, arg...) printk(KERN_ERR DM_NAME ": " DM_MSG_PREFIX ": " f "\n", ## arg)
-#define DMWARN(f, arg...) printk(KERN_WARNING DM_NAME ": " DM_MSG_PREFIX ": " f "\n", ## arg)
-#define DMINFO(f, arg...) printk(KERN_INFO DM_NAME ": " DM_MSG_PREFIX ": " f "\n", ## arg)
+#define DMERR(f, arg...) \
+	printk(KERN_ERR DM_NAME ": " DM_MSG_PREFIX ": " f "\n", ## arg)
+#define DMERR_LIMIT(f, arg...) \
+	do { \
+		if (printk_ratelimit())	\
+			printk(KERN_ERR DM_NAME ": " DM_MSG_PREFIX ": " \
+			       f "\n", ## arg); \
+	} while (0)
+
+#define DMWARN(f, arg...) \
+	printk(KERN_WARNING DM_NAME ": " DM_MSG_PREFIX ": " f "\n", ## arg)
+#define DMWARN_LIMIT(f, arg...) \
+	do { \
+		if (printk_ratelimit())	\
+			printk(KERN_WARNING DM_NAME ": " DM_MSG_PREFIX ": " \
+			       f "\n", ## arg); \
+	} while (0)
+
+#define DMINFO(f, arg...) \
+	printk(KERN_INFO DM_NAME ": " DM_MSG_PREFIX ": " f "\n", ## arg)
+#define DMINFO_LIMIT(f, arg...) \
+	do { \
+		if (printk_ratelimit())	\
+			printk(KERN_INFO DM_NAME ": " DM_MSG_PREFIX ": " f \
+			       "\n", ## arg); \
+	} while (0)
+
 #ifdef CONFIG_DM_DEBUG
-#  define DMDEBUG(f, arg...) printk(KERN_DEBUG DM_NAME ": " DM_MSG_PREFIX " DEBUG: " f "\n", ## arg)
+#  define DMDEBUG(f, arg...) \
+	printk(KERN_DEBUG DM_NAME ": " DM_MSG_PREFIX " DEBUG: " f "\n", ## arg)
+#  define DMDEBUG_LIMIT(f, arg...) \
+	do { \
+		if (printk_ratelimit())	\
+			printk(KERN_DEBUG DM_NAME ": " DM_MSG_PREFIX ": " f \
+			       "\n", ## arg); \
+	} while (0)
 #else
 #  define DMDEBUG(f, arg...) do {} while (0)
+#  define DMDEBUG_LIMIT(f, arg...) do {} while (0)
 #endif
 
 #define DMEMIT(x...) sz += ((sz >= maxlen) ? \

commit 2e93ccc1933d08d32d9bde3784c3823e67b9b030
Author: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
Date:   Fri Dec 8 02:41:09 2006 -0800

    [PATCH] dm: suspend: add noflush pushback
    
    In device-mapper I/O is sometimes queued within targets for later processing.
    For example the multipath target can be configured to store I/O when no paths
    are available instead of returning it -EIO.
    
    This patch allows the device-mapper core to instruct a target to transfer the
    contents of any such in-target queue back into the core.  This frees up the
    resources used by the target so the core can replace that target with an
    alternative one and then resend the I/O to it.  Without this patch the only
    way to change the target in such circumstances involves returning the I/O with
    an error back to the filesystem/application.  In the multipath case, this
    patch will let us add new paths for existing I/O to try after all the existing
    paths have failed.
    
        DMF_NOFLUSH_SUSPENDING
        ----------------------
    
    If the DM_NOFLUSH_FLAG ioctl option is specified at suspend time, the
    DMF_NOFLUSH_SUSPENDING flag is set in md->flags during dm_suspend().  It
    is always cleared before dm_suspend() returns.
    
    The flag must be visible while the target is flushing pending I/Os so it
    is set before presuspend where the flush starts and unset after the wait
    for md->pending where the flush ends.
    
    Target drivers can check this flag by calling dm_noflush_suspending().
    
        DM_MAPIO_REQUEUE / DM_ENDIO_REQUEUE
        -----------------------------------
    
    A target's map() function can now return DM_MAPIO_REQUEUE to request the
    device mapper core queue the bio.
    
    Similarly, a target's end_io() function can return DM_ENDIO_REQUEUE to request
    the same.  This has been labelled 'pushback'.
    
    The __map_bio() and clone_endio() functions in the core treat these return
    values as errors and call dec_pending() to end the I/O.
    
        dec_pending
        -----------
    
    dec_pending() saves the pushback request in struct dm_io->error.  Once all
    the split clones have ended, dec_pending() will put the original bio on
    the md->pushback list.  Note that this supercedes any I/O errors.
    
    It is possible for the suspend with DM_NOFLUSH_FLAG to be aborted while
    in progress (e.g. by user interrupt).  dec_pending() checks for this and
    returns -EIO if it happened.
    
        pushdback list and pushback_lock
        --------------------------------
    
    The bio is queued on md->pushback temporarily in dec_pending(), and after
    all pending I/Os return, md->pushback is merged into md->deferred in
    dm_suspend() for re-issuing at resume time.
    
    md->pushback_lock protects md->pushback.
    The lock should be held with irq disabled because dec_pending() can be
    called from interrupt context.
    
    Queueing bios to md->pushback in dec_pending() must be done atomically
    with the check for DMF_NOFLUSH_SUSPENDING flag.  So md->pushback_lock is
    held when checking the flag.  Otherwise dec_pending() may queue a bio to
    md->pushback after the interrupted dm_suspend() flushes md->pushback.
    Then the bio would be left in md->pushback.
    
    Flag setting in dm_suspend() can be done without md->pushback_lock because
    the flag is checked only after presuspend and the set value is already
    made visible via the target's presuspend function.
    
    The flag can be checked without md->pushback_lock (e.g. the first part of
    the dec_pending() or target drivers), because the flag is checked again
    with md->pushback_lock held when the bio is really queued to md->pushback
    as described above.  So even if the flag is cleared after the lockless
    checkings, the bio isn't left in md->pushback but returned to applications
    with -EIO.
    
        Other notes on the current patch
        --------------------------------
    
    - md->pushback is added to the struct mapped_device instead of using
      md->deferred directly because md->io_lock which protects md->deferred is
      rw_semaphore and can't be used in interrupt context like dec_pending(),
      and md->io_lock protects the DMF_BLOCK_IO flag of md->flags too.
    
    - Don't issue lock_fs() in dm_suspend() if the DM_NOFLUSH_FLAG
      ioctl option is specified, because I/Os generated by lock_fs() would be
      pushed back and never return if there were no valid devices.
    
    - If an error occurs in dm_suspend() after the DMF_NOFLUSH_SUSPENDING
      flag is set, md->pushback must be flushed because I/Os may be queued to
      the list already.  (flush_and_out label in dm_suspend())
    
        Test results
        ------------
    
    I have tested using multipath target with the next patch.
    
    The following tests are for regression/compatibility:
      - I/Os succeed when valid paths exist;
      - I/Os fail when there are no valid paths and queue_if_no_path is not
        set;
      - I/Os are queued in the multipath target when there are no valid paths and
        queue_if_no_path is set;
      - The queued I/Os above fail when suspend is issued without the
        DM_NOFLUSH_FLAG ioctl option.  I/Os spanning 2 multipath targets also
        fail.
    
    The following tests are for the normal code path of new pushback feature:
      - Queued I/Os in the multipath target are flushed from the target
        but don't return when suspend is issued with the DM_NOFLUSH_FLAG
        ioctl option;
      - The I/Os above are queued in the multipath target again when
        resume is issued without path recovery;
      - The I/Os above succeed when resume is issued after path recovery
        or table load;
      - Queued I/Os in the multipath target succeed when resume is issued
        with the DM_NOFLUSH_FLAG ioctl option after table load. I/Os
        spanning 2 multipath targets also succeed.
    
    The following tests are for the error paths of the new pushback feature:
      - When the bdget_disk() fails in dm_suspend(), the
        DMF_NOFLUSH_SUSPENDING flag is cleared and I/Os already queued to the
        pushback list are flushed properly.
      - When suspend with the DM_NOFLUSH_FLAG ioctl option is interrupted,
          o I/Os which had already been queued to the pushback list
            at the time don't return, and are re-issued at resume time;
          o I/Os which hadn't been returned at the time return with EIO.
    
    Signed-off-by: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Cc: dm-devel@redhat.com
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index c307ca9a4c33..2f796b1436b2 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -36,12 +36,14 @@
  * Definitions of return values from target end_io function.
  */
 #define DM_ENDIO_INCOMPLETE	1
+#define DM_ENDIO_REQUEUE	2
 
 /*
  * Definitions of return values from target map function.
  */
 #define DM_MAPIO_SUBMITTED	0
 #define DM_MAPIO_REMAPPED	1
+#define DM_MAPIO_REQUEUE	DM_ENDIO_REQUEUE
 
 /*
  * Suspend feature flags

commit 81fdb096dbcedcc3b94c7e47b59362b5214891e2
Author: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
Date:   Fri Dec 8 02:41:07 2006 -0800

    [PATCH] dm: ioctl: add noflush suspend
    
    Provide a dm ioctl option to request noflush suspending.  (See next patch for
    what this is for.) As the interface is extended, the version number is
    incremented.
    
    Other than accepting the new option through the interface, There is no change
    to existing behaviour.
    
    Test results:
    Confirmed the option is given from user-space correctly.
    
    Signed-off-by: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Cc: dm-devel@redhat.com
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 293d5ce62a21..c307ca9a4c33 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -47,6 +47,7 @@
  * Suspend feature flags
  */
 #define DM_SUSPEND_LOCKFS_FLAG		(1 << 0)
+#define DM_SUSPEND_NOFLUSH_FLAG		(1 << 1)
 
 /*
  * List of devices that a metadevice uses and should open/close.

commit 45cbcd798354251b99694086af9d57c99e89bb43
Author: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
Date:   Fri Dec 8 02:41:05 2006 -0800

    [PATCH] dm: map and endio return code clarification
    
    Tighten the use of return values from the target map and end_io functions.
    Values of 2 and above are now explictly reserved for future use.  There are no
    existing targets using such values.
    
    The patch has no effect on existing behaviour.
    
    o Reserve return values of 2 and above from target map functions.
      Any positive value currently indicates "mapping complete", but all
      existing drivers use the value 1.  We now make that a requirement
      so we can assign new meaning to higher values in future.
    
      The new definition of return values from target map functions is:
          < 0 : error
          = 0 : The target will handle the io (DM_MAPIO_SUBMITTED).
          = 1 : Mapping completed (DM_MAPIO_REMAPPED).
          > 1 : Reserved (undefined).  Previously this was the same as '= 1'.
    
    o Reserve return values of 2 and above from target end_io functions
      for similar reasons.
      DM_ENDIO_INCOMPLETE is introduced for a return value of 1.
    
    Test results:
    
      I have tested by using the multipath target.
    
      I/Os succeed when valid paths exist.
    
      I/Os are queued in the multipath target when there are no valid paths and
    queue_if_no_path is set.
    
      I/Os fail when there are no valid paths and queue_if_no_path is not set.
    
    Signed-off-by: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Cc: dm-devel@redhat.com
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 81c98d6e35e9..293d5ce62a21 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -32,6 +32,17 @@
 
 #define SECTOR_SHIFT 9
 
+/*
+ * Definitions of return values from target end_io function.
+ */
+#define DM_ENDIO_INCOMPLETE	1
+
+/*
+ * Definitions of return values from target map function.
+ */
+#define DM_MAPIO_SUBMITTED	0
+#define DM_MAPIO_REMAPPED	1
+
 /*
  * Suspend feature flags
  */

commit a3d77d35be6f416a250c528c3ed5c70013a915e8
Author: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
Date:   Fri Dec 8 02:41:04 2006 -0800

    [PATCH] dm: suspend: parameter change
    
    Change the interface of dm_suspend() so that we can pass several options
    without increasing the number of parameters.  The existing 'do_lockfs' integer
    parameter is replaced by a flag DM_SUSPEND_LOCKFS_FLAG.
    
    There is no functional change to the code.
    
    Test results:
    I have tested 'dmsetup suspend' command with/without the '--nolockfs'
    option and confirmed the do_lockfs value is correctly set.
    
    Signed-off-by: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Cc: dm-devel@redhat.com
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index a48ec5e3c1f4..81c98d6e35e9 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -32,6 +32,11 @@
 
 #define SECTOR_SHIFT 9
 
+/*
+ * Suspend feature flags
+ */
+#define DM_SUSPEND_LOCKFS_FLAG		(1 << 0)
+
 /*
  * List of devices that a metadevice uses and should open/close.
  */

commit 8757b7764f13e336f3c0eb1f634440d4ee4c3a67
Author: Milan Broz <mbroz@redhat.com>
Date:   Tue Oct 3 01:15:36 2006 -0700

    [PATCH] dm table: add target preresume
    
    This patch adds a target preresume hook.
    
    It is called before the targets are resumed and if it returns an error the
    resume gets cancelled.
    
    The crypt target will use this to indicate that it is unable to process I/O
    because no encryption key has been supplied.
    
    Signed-off-by: Milan Broz <mbroz@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index fe701c4834fe..a48ec5e3c1f4 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -57,7 +57,7 @@ void dm_table_set_restrictions(struct dm_table *t, struct request_queue *q);
 struct list_head *dm_table_get_devices(struct dm_table *t);
 void dm_table_presuspend_targets(struct dm_table *t);
 void dm_table_postsuspend_targets(struct dm_table *t);
-void dm_table_resume_targets(struct dm_table *t);
+int dm_table_resume_targets(struct dm_table *t);
 int dm_table_any_congested(struct dm_table *t, int bdi_bits);
 void dm_table_unplug_all(struct dm_table *t);
 int dm_table_flush_all(struct dm_table *t);

commit cc1092019ce3d9b3e85a285b41e852ff94a6b590
Author: Bryn Reeves <breeves@redhat.com>
Date:   Tue Oct 3 01:15:35 2006 -0700

    [PATCH] dm: add debug macro
    
    Add CONFIG_DM_DEBUG and DMDEBUG() macro.
    
    Signed-off-by: Bryn Reeves <breeves@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 3c03c0ecab7e..fe701c4834fe 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -21,6 +21,11 @@
 #define DMERR(f, arg...) printk(KERN_ERR DM_NAME ": " DM_MSG_PREFIX ": " f "\n", ## arg)
 #define DMWARN(f, arg...) printk(KERN_WARNING DM_NAME ": " DM_MSG_PREFIX ": " f "\n", ## arg)
 #define DMINFO(f, arg...) printk(KERN_INFO DM_NAME ": " DM_MSG_PREFIX ": " f "\n", ## arg)
+#ifdef CONFIG_DM_DEBUG
+#  define DMDEBUG(f, arg...) printk(KERN_DEBUG DM_NAME ": " DM_MSG_PREFIX " DEBUG: " f "\n", ## arg)
+#else
+#  define DMDEBUG(f, arg...) do {} while (0)
+#endif
 
 #define DMEMIT(x...) sz += ((sz >= maxlen) ? \
 			  0 : scnprintf(result + sz, maxlen - sz, x))

commit 72d9486169a2a8353e022813185ba2f32d7dde69
Author: Alasdair G Kergon <agk@redhat.com>
Date:   Mon Jun 26 00:27:35 2006 -0700

    [PATCH] dm: improve error message consistency
    
    Tidy device-mapper error messages to include context information
    automatically.
    
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 9ebb24b037bc..3c03c0ecab7e 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -17,9 +17,10 @@
 #include <linux/hdreg.h>
 
 #define DM_NAME "device-mapper"
-#define DMWARN(f, x...) printk(KERN_WARNING DM_NAME ": " f "\n" , ## x)
-#define DMERR(f, x...) printk(KERN_ERR DM_NAME ": " f "\n" , ## x)
-#define DMINFO(f, x...) printk(KERN_INFO DM_NAME ": " f "\n" , ## x)
+
+#define DMERR(f, arg...) printk(KERN_ERR DM_NAME ": " DM_MSG_PREFIX ": " f "\n", ## arg)
+#define DMWARN(f, arg...) printk(KERN_WARNING DM_NAME ": " DM_MSG_PREFIX ": " f "\n", ## arg)
+#define DMINFO(f, arg...) printk(KERN_INFO DM_NAME ": " DM_MSG_PREFIX ": " f "\n", ## arg)
 
 #define DMEMIT(x...) sz += ((sz >= maxlen) ? \
 			  0 : scnprintf(result + sz, maxlen - sz, x))

commit 5c6bd75d06db512515a3781aa97e42df2faf0815
Author: Alasdair G Kergon <agk@redhat.com>
Date:   Mon Jun 26 00:27:34 2006 -0700

    [PATCH] dm: prevent removal if open
    
    If you misuse the device-mapper interface (or there's a bug in your userspace
    tools) it's possible to end up with 'unlinked' mapped devices that cannot be
    removed until you reboot (along with uninterruptible processes).
    
    This patch prevents you from removing a device that is still open.
    
    It introduces dm_lock_for_deletion() which is called when a device is about to
    be removed to ensure that nothing has it open and nothing further can open it.
     It uses a private open_count for this which also lets us remove one of the
    problematic bdget_disk() calls elsewhere.
    
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 71ddd1e23007..9ebb24b037bc 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -123,5 +123,7 @@ void dm_stripe_exit(void);
 
 void *dm_vcalloc(unsigned long nmemb, unsigned long elem_size);
 union map_info *dm_get_mapinfo(struct bio *bio);
+int dm_open_count(struct mapped_device *md);
+int dm_lock_for_deletion(struct mapped_device *md);
 
 #endif

commit 17b2f66f2a39a4e4d1ed456f35ee3bb598e41d35
Author: Alasdair G Kergon <agk@redhat.com>
Date:   Mon Jun 26 00:27:33 2006 -0700

    [PATCH] dm: add exports
    
    Move definitions of core device-mapper functions for manipulating mapped
    devices and their tables to <linux/device-mapper.h> advertising their
    availability for use elsewhere in the kernel.
    
    Protect the contents of device-mapper.h with ifdef __KERNEL__.  And throw
    in a few formatting clean-ups and extra comments.
    
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 2901ab943191..71ddd1e23007 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -39,88 +39,16 @@ struct dm_dev {
 };
 
 struct dm_table;
-struct mapped_device;
 
 /*-----------------------------------------------------------------
- * Functions for manipulating a struct mapped_device.
- * Drop the reference with dm_put when you finish with the object.
+ * Internal table functions.
  *---------------------------------------------------------------*/
-
-/*
- * DM_ANY_MINOR allocates any available minor number.
- */
-#define DM_ANY_MINOR (-1)
-int dm_create(int minor, struct mapped_device **md);
-
-void dm_set_mdptr(struct mapped_device *md, void *ptr);
-void *dm_get_mdptr(struct mapped_device *md);
-
-/*
- * Reference counting for md.
- */
-void dm_get(struct mapped_device *md);
-struct mapped_device *dm_get_md(dev_t dev);
-void dm_put(struct mapped_device *md);
-
-/*
- * A device can still be used while suspended, but I/O is deferred.
- */
-int dm_suspend(struct mapped_device *md, int with_lockfs);
-int dm_resume(struct mapped_device *md);
-
-/*
- * The device must be suspended before calling this method.
- */
-int dm_swap_table(struct mapped_device *md, struct dm_table *t);
-
-/*
- * Drop a reference on the table when you've finished with the
- * result.
- */
-struct dm_table *dm_get_table(struct mapped_device *md);
-
-/*
- * Event functions.
- */
-uint32_t dm_get_event_nr(struct mapped_device *md);
-int dm_wait_event(struct mapped_device *md, int event_nr);
-
-/*
- * Info functions.
- */
-struct gendisk *dm_disk(struct mapped_device *md);
-int dm_suspended(struct mapped_device *md);
-
-/*
- * Geometry functions.
- */
-int dm_get_geometry(struct mapped_device *md, struct hd_geometry *geo);
-int dm_set_geometry(struct mapped_device *md, struct hd_geometry *geo);
-
-/*-----------------------------------------------------------------
- * Functions for manipulating a table.  Tables are also reference
- * counted.
- *---------------------------------------------------------------*/
-int dm_table_create(struct dm_table **result, int mode,
-		    unsigned num_targets, struct mapped_device *md);
-
-void dm_table_get(struct dm_table *t);
-void dm_table_put(struct dm_table *t);
-
-int dm_table_add_target(struct dm_table *t, const char *type,
-			sector_t start,	sector_t len, char *params);
-int dm_table_complete(struct dm_table *t);
 void dm_table_event_callback(struct dm_table *t,
 			     void (*fn)(void *), void *context);
-void dm_table_event(struct dm_table *t);
-sector_t dm_table_get_size(struct dm_table *t);
 struct dm_target *dm_table_get_target(struct dm_table *t, unsigned int index);
 struct dm_target *dm_table_find_target(struct dm_table *t, sector_t sector);
 void dm_table_set_restrictions(struct dm_table *t, struct request_queue *q);
-unsigned int dm_table_get_num_targets(struct dm_table *t);
 struct list_head *dm_table_get_devices(struct dm_table *t);
-int dm_table_get_mode(struct dm_table *t);
-struct mapped_device *dm_table_get_md(struct dm_table *t);
 void dm_table_presuspend_targets(struct dm_table *t);
 void dm_table_postsuspend_targets(struct dm_table *t);
 void dm_table_resume_targets(struct dm_table *t);
@@ -138,7 +66,6 @@ void dm_put_target_type(struct target_type *t);
 int dm_target_iterate(void (*iter_func)(struct target_type *tt,
 					void *param), void *param);
 
-
 /*-----------------------------------------------------------------
  * Useful inlines.
  *---------------------------------------------------------------*/

commit 2b06cfff12f0f87c4bc4d4c4dd76997e72c360ba
Author: Alasdair G Kergon <agk@redhat.com>
Date:   Mon Jun 26 00:27:32 2006 -0700

    [PATCH] dm: consolidate creation functions
    
    Merge dm_create() and dm_create_with_minor() by introducing the special value
    DM_ANY_MINOR to request the allocation of the next available minor number.
    
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index fd90bc8f9e45..2901ab943191 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -2,7 +2,7 @@
  * Internal header file for device mapper
  *
  * Copyright (C) 2001, 2002 Sistina Software
- * Copyright (C) 2004 Red Hat, Inc. All rights reserved.
+ * Copyright (C) 2004-2006 Red Hat, Inc. All rights reserved.
  *
  * This file is released under the LGPL.
  */
@@ -45,16 +45,21 @@ struct mapped_device;
  * Functions for manipulating a struct mapped_device.
  * Drop the reference with dm_put when you finish with the object.
  *---------------------------------------------------------------*/
-int dm_create(struct mapped_device **md);
-int dm_create_with_minor(unsigned int minor, struct mapped_device **md);
+
+/*
+ * DM_ANY_MINOR allocates any available minor number.
+ */
+#define DM_ANY_MINOR (-1)
+int dm_create(int minor, struct mapped_device **md);
+
 void dm_set_mdptr(struct mapped_device *md, void *ptr);
 void *dm_get_mdptr(struct mapped_device *md);
-struct mapped_device *dm_get_md(dev_t dev);
 
 /*
  * Reference counting for md.
  */
 void dm_get(struct mapped_device *md);
+struct mapped_device *dm_get_md(dev_t dev);
 void dm_put(struct mapped_device *md);
 
 /*

commit 3ac51e741a46af7a20f55e79d3e3aeaa93c6c544
Author: Darrick J. Wong <djwong@us.ibm.com>
Date:   Mon Mar 27 01:17:54 2006 -0800

    [PATCH] dm store geometry
    
    Allow drive geometry to be stored with a new DM_DEV_SET_GEOMETRY ioctl.
    Device-mapper will now respond to HDIO_GETGEO.  If the geometry information is
    not available, zero will be returned for all of the parameters.
    
    Signed-off-by: Darrick J. Wong <djwong@us.ibm.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 79e800051a10..fd90bc8f9e45 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -14,6 +14,7 @@
 #include <linux/device-mapper.h>
 #include <linux/list.h>
 #include <linux/blkdev.h>
+#include <linux/hdreg.h>
 
 #define DM_NAME "device-mapper"
 #define DMWARN(f, x...) printk(KERN_WARNING DM_NAME ": " f "\n" , ## x)
@@ -85,6 +86,12 @@ int dm_wait_event(struct mapped_device *md, int event_nr);
 struct gendisk *dm_disk(struct mapped_device *md);
 int dm_suspended(struct mapped_device *md);
 
+/*
+ * Geometry functions.
+ */
+int dm_get_geometry(struct mapped_device *md, struct hd_geometry *geo);
+int dm_set_geometry(struct mapped_device *md, struct hd_geometry *geo);
+
 /*-----------------------------------------------------------------
  * Functions for manipulating a table.  Tables are also reference
  * counted.

commit 1134e5ae79bab61c05657ca35a6297cf87202e35
Author: Mike Anderson <andmike@us.ibm.com>
Date:   Mon Mar 27 01:17:54 2006 -0800

    [PATCH] dm table: store md
    
    Store an up-pointer to the owning struct mapped_device in every table when it
    is created.
    
    Access it with:
      struct mapped_device *dm_table_get_md(struct dm_table *t)
    
    Tables linked to md must be destroyed before the md itself.
    
    Signed-off-by: Mike Anderson <andmike@us.ibm.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 17ffa8d671a7..79e800051a10 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -89,7 +89,8 @@ int dm_suspended(struct mapped_device *md);
  * Functions for manipulating a table.  Tables are also reference
  * counted.
  *---------------------------------------------------------------*/
-int dm_table_create(struct dm_table **result, int mode, unsigned num_targets);
+int dm_table_create(struct dm_table **result, int mode,
+		    unsigned num_targets, struct mapped_device *md);
 
 void dm_table_get(struct dm_table *t);
 void dm_table_put(struct dm_table *t);
@@ -107,6 +108,7 @@ void dm_table_set_restrictions(struct dm_table *t, struct request_queue *q);
 unsigned int dm_table_get_num_targets(struct dm_table *t);
 struct list_head *dm_table_get_devices(struct dm_table *t);
 int dm_table_get_mode(struct dm_table *t);
+struct mapped_device *dm_table_get_md(struct dm_table *t);
 void dm_table_presuspend_targets(struct dm_table *t);
 void dm_table_postsuspend_targets(struct dm_table *t);
 void dm_table_resume_targets(struct dm_table *t);

commit 9ade92a9a5b0a3a10efa6551b8c67a9277bf0438
Author: Alasdair G Kergon <agk@redhat.com>
Date:   Mon Mar 27 01:17:53 2006 -0800

    [PATCH] dm: tidy mdptr
    
    Change dm_get_mdptr() to take a struct mapped_device instead of dev_t.
    
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 0ff11d6f8158..17ffa8d671a7 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -47,7 +47,7 @@ struct mapped_device;
 int dm_create(struct mapped_device **md);
 int dm_create_with_minor(unsigned int minor, struct mapped_device **md);
 void dm_set_mdptr(struct mapped_device *md, void *ptr);
-void *dm_get_mdptr(dev_t dev);
+void *dm_get_mdptr(struct mapped_device *md);
 struct mapped_device *dm_get_md(dev_t dev);
 
 /*

commit 4ee218cd67b385759993a6c840ea45f0ee0a8b30
Author: Andrew Morton <akpm@osdl.org>
Date:   Mon Mar 27 01:17:48 2006 -0800

    [PATCH] dm: remove SECTOR_FORMAT
    
    We don't know what type sector_t has.  Sometimes it's unsigned long, sometimes
    it's unsigned long long.  For example on ppc64 it's unsigned long with
    CONFIG_LBD=n and on x86_64 it's unsigned long long with CONFIG_LBD=n.
    
    The way to handle all of this is to always use unsigned long long and to
    always typecast the sector_t when printing it.
    
    Acked-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 4eaf075da217..0ff11d6f8158 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -23,16 +23,6 @@
 #define DMEMIT(x...) sz += ((sz >= maxlen) ? \
 			  0 : scnprintf(result + sz, maxlen - sz, x))
 
-/*
- * FIXME: I think this should be with the definition of sector_t
- * in types.h.
- */
-#ifdef CONFIG_LBD
-#define SECTOR_FORMAT "%llu"
-#else
-#define SECTOR_FORMAT "%lu"
-#endif
-
 #define SECTOR_SHIFT 9
 
 /*

commit aa8d7c2fbe619d8c0837296d2eaf4c14cebac198
Author: Alasdair G Kergon <agk@redhat.com>
Date:   Fri Jan 6 00:20:06 2006 -0800

    [PATCH] device-mapper: make lock_fs optional
    
    Devices only needs syncing when creating snapshots, so make this optional when
    suspending a device.
    
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 95a0cfbe5b4d..4eaf075da217 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -69,7 +69,7 @@ void dm_put(struct mapped_device *md);
 /*
  * A device can still be used while suspended, but I/O is deferred.
  */
-int dm_suspend(struct mapped_device *md);
+int dm_suspend(struct mapped_device *md, int with_lockfs);
 int dm_resume(struct mapped_device *md);
 
 /*

commit 2d5fe68987341a59a3fd97c71695efcabb0c6fd5
Author: Alasdair G Kergon <agk@redhat.com>
Date:   Fri Jan 6 00:20:04 2006 -0800

    [PATCH] device-mapper: scanf sector format change
    
    Use %llu not %Lu in sscanf/printf format strings.
    
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index ab078a249396..95a0cfbe5b4d 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -28,7 +28,7 @@
  * in types.h.
  */
 #ifdef CONFIG_LBD
-#define SECTOR_FORMAT "%Lu"
+#define SECTOR_FORMAT "%llu"
 #else
 #define SECTOR_FORMAT "%lu"
 #endif

commit d229a9589ff3b988d3f999cdcfa350f97a372673
Author: David Teigland <teigland@redhat.com>
Date:   Fri Jan 6 00:20:01 2006 -0800

    [PATCH] device-mapper: add dm_get_md
    
    Add dm_get_dev() to get a mapped device given its dev_t.
    
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index e38c3fc1a1db..ab078a249396 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -58,6 +58,7 @@ int dm_create(struct mapped_device **md);
 int dm_create_with_minor(unsigned int minor, struct mapped_device **md);
 void dm_set_mdptr(struct mapped_device *md, void *ptr);
 void *dm_get_mdptr(dev_t dev);
+struct mapped_device *dm_get_md(dev_t dev);
 
 /*
  * Reference counting for md.

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/drivers/md/dm.h b/drivers/md/dm.h
new file mode 100644
index 000000000000..e38c3fc1a1db
--- /dev/null
+++ b/drivers/md/dm.h
@@ -0,0 +1,195 @@
+/*
+ * Internal header file for device mapper
+ *
+ * Copyright (C) 2001, 2002 Sistina Software
+ * Copyright (C) 2004 Red Hat, Inc. All rights reserved.
+ *
+ * This file is released under the LGPL.
+ */
+
+#ifndef DM_INTERNAL_H
+#define DM_INTERNAL_H
+
+#include <linux/fs.h>
+#include <linux/device-mapper.h>
+#include <linux/list.h>
+#include <linux/blkdev.h>
+
+#define DM_NAME "device-mapper"
+#define DMWARN(f, x...) printk(KERN_WARNING DM_NAME ": " f "\n" , ## x)
+#define DMERR(f, x...) printk(KERN_ERR DM_NAME ": " f "\n" , ## x)
+#define DMINFO(f, x...) printk(KERN_INFO DM_NAME ": " f "\n" , ## x)
+
+#define DMEMIT(x...) sz += ((sz >= maxlen) ? \
+			  0 : scnprintf(result + sz, maxlen - sz, x))
+
+/*
+ * FIXME: I think this should be with the definition of sector_t
+ * in types.h.
+ */
+#ifdef CONFIG_LBD
+#define SECTOR_FORMAT "%Lu"
+#else
+#define SECTOR_FORMAT "%lu"
+#endif
+
+#define SECTOR_SHIFT 9
+
+/*
+ * List of devices that a metadevice uses and should open/close.
+ */
+struct dm_dev {
+	struct list_head list;
+
+	atomic_t count;
+	int mode;
+	struct block_device *bdev;
+	char name[16];
+};
+
+struct dm_table;
+struct mapped_device;
+
+/*-----------------------------------------------------------------
+ * Functions for manipulating a struct mapped_device.
+ * Drop the reference with dm_put when you finish with the object.
+ *---------------------------------------------------------------*/
+int dm_create(struct mapped_device **md);
+int dm_create_with_minor(unsigned int minor, struct mapped_device **md);
+void dm_set_mdptr(struct mapped_device *md, void *ptr);
+void *dm_get_mdptr(dev_t dev);
+
+/*
+ * Reference counting for md.
+ */
+void dm_get(struct mapped_device *md);
+void dm_put(struct mapped_device *md);
+
+/*
+ * A device can still be used while suspended, but I/O is deferred.
+ */
+int dm_suspend(struct mapped_device *md);
+int dm_resume(struct mapped_device *md);
+
+/*
+ * The device must be suspended before calling this method.
+ */
+int dm_swap_table(struct mapped_device *md, struct dm_table *t);
+
+/*
+ * Drop a reference on the table when you've finished with the
+ * result.
+ */
+struct dm_table *dm_get_table(struct mapped_device *md);
+
+/*
+ * Event functions.
+ */
+uint32_t dm_get_event_nr(struct mapped_device *md);
+int dm_wait_event(struct mapped_device *md, int event_nr);
+
+/*
+ * Info functions.
+ */
+struct gendisk *dm_disk(struct mapped_device *md);
+int dm_suspended(struct mapped_device *md);
+
+/*-----------------------------------------------------------------
+ * Functions for manipulating a table.  Tables are also reference
+ * counted.
+ *---------------------------------------------------------------*/
+int dm_table_create(struct dm_table **result, int mode, unsigned num_targets);
+
+void dm_table_get(struct dm_table *t);
+void dm_table_put(struct dm_table *t);
+
+int dm_table_add_target(struct dm_table *t, const char *type,
+			sector_t start,	sector_t len, char *params);
+int dm_table_complete(struct dm_table *t);
+void dm_table_event_callback(struct dm_table *t,
+			     void (*fn)(void *), void *context);
+void dm_table_event(struct dm_table *t);
+sector_t dm_table_get_size(struct dm_table *t);
+struct dm_target *dm_table_get_target(struct dm_table *t, unsigned int index);
+struct dm_target *dm_table_find_target(struct dm_table *t, sector_t sector);
+void dm_table_set_restrictions(struct dm_table *t, struct request_queue *q);
+unsigned int dm_table_get_num_targets(struct dm_table *t);
+struct list_head *dm_table_get_devices(struct dm_table *t);
+int dm_table_get_mode(struct dm_table *t);
+void dm_table_presuspend_targets(struct dm_table *t);
+void dm_table_postsuspend_targets(struct dm_table *t);
+void dm_table_resume_targets(struct dm_table *t);
+int dm_table_any_congested(struct dm_table *t, int bdi_bits);
+void dm_table_unplug_all(struct dm_table *t);
+int dm_table_flush_all(struct dm_table *t);
+
+/*-----------------------------------------------------------------
+ * A registry of target types.
+ *---------------------------------------------------------------*/
+int dm_target_init(void);
+void dm_target_exit(void);
+struct target_type *dm_get_target_type(const char *name);
+void dm_put_target_type(struct target_type *t);
+int dm_target_iterate(void (*iter_func)(struct target_type *tt,
+					void *param), void *param);
+
+
+/*-----------------------------------------------------------------
+ * Useful inlines.
+ *---------------------------------------------------------------*/
+static inline int array_too_big(unsigned long fixed, unsigned long obj,
+				unsigned long num)
+{
+	return (num > (ULONG_MAX - fixed) / obj);
+}
+
+/*
+ * Ceiling(n / sz)
+ */
+#define dm_div_up(n, sz) (((n) + (sz) - 1) / (sz))
+
+#define dm_sector_div_up(n, sz) ( \
+{ \
+	sector_t _r = ((n) + (sz) - 1); \
+	sector_div(_r, (sz)); \
+	_r; \
+} \
+)
+
+/*
+ * ceiling(n / size) * size
+ */
+#define dm_round_up(n, sz) (dm_div_up((n), (sz)) * (sz))
+
+static inline sector_t to_sector(unsigned long n)
+{
+	return (n >> 9);
+}
+
+static inline unsigned long to_bytes(sector_t n)
+{
+	return (n << 9);
+}
+
+int dm_split_args(int *argc, char ***argvp, char *input);
+
+/*
+ * The device-mapper can be driven through one of two interfaces;
+ * ioctl or filesystem, depending which patch you have applied.
+ */
+int dm_interface_init(void);
+void dm_interface_exit(void);
+
+/*
+ * Targets for linear and striped mappings
+ */
+int dm_linear_init(void);
+void dm_linear_exit(void);
+
+int dm_stripe_init(void);
+void dm_stripe_exit(void);
+
+void *dm_vcalloc(unsigned long nmemb, unsigned long elem_size);
+union map_info *dm_get_mapinfo(struct bio *bio);
+
+#endif
