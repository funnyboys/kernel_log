commit b144e45fc57649e15cbc79ff2d32a942af1d91d5
Author: Coly Li <colyli@suse.de>
Date:   Sun Mar 22 14:03:02 2020 +0800

    bcache: make bch_sectors_dirty_init() to be multithreaded
    
    When attaching a cached device (a.k.a backing device) to a cache
    device, bch_sectors_dirty_init() is called to count dirty sectors
    and stripes (see what bcache_dev_sectors_dirty_add() does) on the
    cache device.
    
    The counting is done by a single thread recursive function
    bch_btree_map_keys() to iterate all the bcache btree nodes.
    If the btree has huge number of nodes, bch_sectors_dirty_init() will
    take quite long time. In my testing, if the registering cache set has
    a existed UUID which matches a already registered cached device, the
    automatical attachment during the registration may take more than
    55 minutes. This is too long for waiting the bcache to work in real
    deployment.
    
    Fortunately when bch_sectors_dirty_init() is called, no other thread
    will access the btree yet, it is safe to do a read-only parallelized
    dirty sectors counting by multiple threads.
    
    This patch tries to create multiple threads, and each thread tries to
    one-by-one count dirty sectors from the sub-tree indexed by a root
    node key which the thread fetched. After the sub-tree is counted, the
    counting thread will continue to fetch another root node key, until
    the fetched key is NULL. How many threads in parallel depends on
    the number of keys from the btree root node, and the number of online
    CPU core. The thread number will be the less number but no more than
    BCH_DIRTY_INIT_THRD_MAX. If there are only 2 keys in root node, it
    can only be 2x times faster by this patch. But if there are 10 keys
    in the root node, with this patch it can be 10x times faster.
    
    Signed-off-by: Coly Li <colyli@suse.de>
    Cc: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 4e4c6810dc3c..b029843ce5b6 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -16,6 +16,7 @@
 
 #define BCH_AUTO_GC_DIRTY_THRESHOLD	50
 
+#define BCH_DIRTY_INIT_THRD_MAX	64
 /*
  * 14 (16384ths) is chosen here as something that each backing device
  * should be a reasonable fraction of the share, and not to blow up
@@ -23,6 +24,24 @@
  */
 #define WRITEBACK_SHARE_SHIFT   14
 
+struct bch_dirty_init_state;
+struct dirty_init_thrd_info {
+	struct bch_dirty_init_state	*state;
+	struct task_struct		*thread;
+};
+
+struct bch_dirty_init_state {
+	struct cache_set		*c;
+	struct bcache_device		*d;
+	int				total_threads;
+	int				key_idx;
+	spinlock_t			idx_lock;
+	atomic_t			started;
+	atomic_t			enough;
+	wait_queue_head_t		wait;
+	struct dirty_init_thrd_info	infos[BCH_DIRTY_INIT_THRD_MAX];
+};
+
 static inline uint64_t bcache_dev_sectors_dirty(struct bcache_device *d)
 {
 	uint64_t i, ret = 0;

commit 9951379b0ca88c95876ad9778b9099e19a95d566
Author: Daniel Axtens <dja@axtens.net>
Date:   Sat Feb 9 12:52:53 2019 +0800

    bcache: never writeback a discard operation
    
    Some users see panics like the following when performing fstrim on a
    bcached volume:
    
    [  529.803060] BUG: unable to handle kernel NULL pointer dereference at 0000000000000008
    [  530.183928] #PF error: [normal kernel read fault]
    [  530.412392] PGD 8000001f42163067 P4D 8000001f42163067 PUD 1f42168067 PMD 0
    [  530.750887] Oops: 0000 [#1] SMP PTI
    [  530.920869] CPU: 10 PID: 4167 Comm: fstrim Kdump: loaded Not tainted 5.0.0-rc1+ #3
    [  531.290204] Hardware name: HP ProLiant DL360 Gen9/ProLiant DL360 Gen9, BIOS P89 12/27/2015
    [  531.693137] RIP: 0010:blk_queue_split+0x148/0x620
    [  531.922205] Code: 60 38 89 55 a0 45 31 db 45 31 f6 45 31 c9 31 ff 89 4d 98 85 db 0f 84 7f 04 00 00 44 8b 6d 98 4c 89 ee 48 c1 e6 04 49 03 70 78 <8b> 46 08 44 8b 56 0c 48
    8b 16 44 29 e0 39 d8 48 89 55 a8 0f 47 c3
    [  532.838634] RSP: 0018:ffffb9b708df39b0 EFLAGS: 00010246
    [  533.093571] RAX: 00000000ffffffff RBX: 0000000000046000 RCX: 0000000000000000
    [  533.441865] RDX: 0000000000000200 RSI: 0000000000000000 RDI: 0000000000000000
    [  533.789922] RBP: ffffb9b708df3a48 R08: ffff940d3b3fdd20 R09: 0000000000000000
    [  534.137512] R10: ffffb9b708df3958 R11: 0000000000000000 R12: 0000000000000000
    [  534.485329] R13: 0000000000000000 R14: 0000000000000000 R15: ffff940d39212020
    [  534.833319] FS:  00007efec26e3840(0000) GS:ffff940d1f480000(0000) knlGS:0000000000000000
    [  535.224098] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  535.504318] CR2: 0000000000000008 CR3: 0000001f4e256004 CR4: 00000000001606e0
    [  535.851759] Call Trace:
    [  535.970308]  ? mempool_alloc_slab+0x15/0x20
    [  536.174152]  ? bch_data_insert+0x42/0xd0 [bcache]
    [  536.403399]  blk_mq_make_request+0x97/0x4f0
    [  536.607036]  generic_make_request+0x1e2/0x410
    [  536.819164]  submit_bio+0x73/0x150
    [  536.980168]  ? submit_bio+0x73/0x150
    [  537.149731]  ? bio_associate_blkg_from_css+0x3b/0x60
    [  537.391595]  ? _cond_resched+0x1a/0x50
    [  537.573774]  submit_bio_wait+0x59/0x90
    [  537.756105]  blkdev_issue_discard+0x80/0xd0
    [  537.959590]  ext4_trim_fs+0x4a9/0x9e0
    [  538.137636]  ? ext4_trim_fs+0x4a9/0x9e0
    [  538.324087]  ext4_ioctl+0xea4/0x1530
    [  538.497712]  ? _copy_to_user+0x2a/0x40
    [  538.679632]  do_vfs_ioctl+0xa6/0x600
    [  538.853127]  ? __do_sys_newfstat+0x44/0x70
    [  539.051951]  ksys_ioctl+0x6d/0x80
    [  539.212785]  __x64_sys_ioctl+0x1a/0x20
    [  539.394918]  do_syscall_64+0x5a/0x110
    [  539.568674]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    We have observed it where both:
    1) LVM/devmapper is involved (bcache backing device is LVM volume) and
    2) writeback cache is involved (bcache cache_mode is writeback)
    
    On one machine, we can reliably reproduce it with:
    
     # echo writeback > /sys/block/bcache0/bcache/cache_mode
       (not sure whether above line is required)
     # mount /dev/bcache0 /test
     # for i in {0..10}; do
            file="$(mktemp /test/zero.XXX)"
            dd if=/dev/zero of="$file" bs=1M count=256
            sync
            rm $file
        done
      # fstrim -v /test
    
    Observing this with tracepoints on, we see the following writes:
    
    fstrim-18019 [022] .... 91107.302026: bcache_write: 73f95583-561c-408f-a93a-4cbd2498f5c8 inode 0  DS 4260112 + 196352 hit 0 bypass 1
    fstrim-18019 [022] .... 91107.302050: bcache_write: 73f95583-561c-408f-a93a-4cbd2498f5c8 inode 0  DS 4456464 + 262144 hit 0 bypass 1
    fstrim-18019 [022] .... 91107.302075: bcache_write: 73f95583-561c-408f-a93a-4cbd2498f5c8 inode 0  DS 4718608 + 81920 hit 0 bypass 1
    fstrim-18019 [022] .... 91107.302094: bcache_write: 73f95583-561c-408f-a93a-4cbd2498f5c8 inode 0  DS 5324816 + 180224 hit 0 bypass 1
    fstrim-18019 [022] .... 91107.302121: bcache_write: 73f95583-561c-408f-a93a-4cbd2498f5c8 inode 0  DS 5505040 + 262144 hit 0 bypass 1
    fstrim-18019 [022] .... 91107.302145: bcache_write: 73f95583-561c-408f-a93a-4cbd2498f5c8 inode 0  DS 5767184 + 81920 hit 0 bypass 1
    fstrim-18019 [022] .... 91107.308777: bcache_write: 73f95583-561c-408f-a93a-4cbd2498f5c8 inode 0  DS 6373392 + 180224 hit 1 bypass 0
    <crash>
    
    Note the final one has different hit/bypass flags.
    
    This is because in should_writeback(), we were hitting a case where
    the partial stripe condition was returning true and so
    should_writeback() was returning true early.
    
    If that hadn't been the case, it would have hit the would_skip test, and
    as would_skip == s->iop.bypass == true, should_writeback() would have
    returned false.
    
    Looking at the git history from 'commit 72c270612bd3 ("bcache: Write out
    full stripes")', it looks like the idea was to optimise for raid5/6:
    
           * If a stripe is already dirty, force writes to that stripe to
             writeback mode - to help build up full stripes of dirty data
    
    To fix this issue, make sure that should_writeback() on a discard op
    never returns true.
    
    More details of debugging:
    https://www.spinics.net/lists/linux-bcache/msg06996.html
    
    Previous reports:
     - https://bugzilla.kernel.org/show_bug.cgi?id=201051
     - https://bugzilla.kernel.org/show_bug.cgi?id=196103
     - https://www.spinics.net/lists/linux-bcache/msg06885.html
    
    (Coly Li: minor modification to follow maximum 75 chars per line rule)
    
    Cc: Kent Overstreet <koverstreet@google.com>
    Cc: stable@vger.kernel.org
    Fixes: 72c270612bd3 ("bcache: Write out full stripes")
    Signed-off-by: Daniel Axtens <dja@axtens.net>
    Signed-off-by: Coly Li <colyli@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 6a743d3bb338..4e4c6810dc3c 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -71,6 +71,9 @@ static inline bool should_writeback(struct cached_dev *dc, struct bio *bio,
 	    in_use > bch_cutoff_writeback_sync)
 		return false;
 
+	if (bio_op(bio) == REQ_OP_DISCARD)
+		return false;
+
 	if (dc->partial_stripes_expensive &&
 	    bcache_dev_stripe_dirty(dc, bio->bi_iter.bi_sector,
 				    bio_sectors(bio)))

commit 9aaf51654672b16566c5fe787da3ca41ebf6d297
Author: Coly Li <colyli@suse.de>
Date:   Thu Dec 13 22:53:55 2018 +0800

    bcache: make cutoff_writeback and cutoff_writeback_sync tunable
    
    Currently the cutoff writeback and cutoff writeback sync thresholds are
    defined by CUTOFF_WRITEBACK (40) and CUTOFF_WRITEBACK_SYNC (70) as
    static values. Most of time these they work fine, but when people want
    to do research on bcache writeback mode performance tuning, there is no
    chance to modify the soft and hard cutoff writeback values.
    
    This patch introduces two module parameters bch_cutoff_writeback_sync
    and bch_cutoff_writeback which permit people to tune the values when
    loading bcache.ko. If they are not specified by module loading, current
    values CUTOFF_WRITEBACK_SYNC and CUTOFF_WRITEBACK will be used as
    default and nothing changes.
    
    When people want to tune this two values,
    - cutoff_writeback can be set in range [1, 70]
    - cutoff_writeback_sync can be set in range [1, 90]
    - cutoff_writeback always <= cutoff_writeback_sync
    
    The default values are strongly recommended to most of users for most of
    workloads. Anyway, if people wants to take their own risk to do research
    on new writeback cutoff tuning for their own workload, now they can make
    it.
    
    Signed-off-by: Coly Li <colyli@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index ce63be98a39d..6a743d3bb338 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -5,6 +5,9 @@
 #define CUTOFF_WRITEBACK	40
 #define CUTOFF_WRITEBACK_SYNC	70
 
+#define CUTOFF_WRITEBACK_MAX		70
+#define CUTOFF_WRITEBACK_SYNC_MAX	90
+
 #define MAX_WRITEBACKS_IN_PASS  5
 #define MAX_WRITESIZE_IN_PASS   5000	/* *512b */
 
@@ -55,6 +58,9 @@ static inline bool bcache_dev_stripe_dirty(struct cached_dev *dc,
 	}
 }
 
+extern unsigned int bch_cutoff_writeback;
+extern unsigned int bch_cutoff_writeback_sync;
+
 static inline bool should_writeback(struct cached_dev *dc, struct bio *bio,
 				    unsigned int cache_mode, bool would_skip)
 {
@@ -62,7 +68,7 @@ static inline bool should_writeback(struct cached_dev *dc, struct bio *bio,
 
 	if (cache_mode != CACHE_MODE_WRITEBACK ||
 	    test_bit(BCACHE_DEV_DETACHING, &dc->disk.flags) ||
-	    in_use > CUTOFF_WRITEBACK_SYNC)
+	    in_use > bch_cutoff_writeback_sync)
 		return false;
 
 	if (dc->partial_stripes_expensive &&
@@ -75,7 +81,7 @@ static inline bool should_writeback(struct cached_dev *dc, struct bio *bio,
 
 	return (op_is_sync(bio->bi_opf) ||
 		bio->bi_opf & (REQ_META|REQ_PRIO) ||
-		in_use <= CUTOFF_WRITEBACK);
+		in_use <= bch_cutoff_writeback);
 }
 
 static inline void bch_writeback_queue(struct cached_dev *dc)

commit 7a671d8ef821bf5743fdff17fae0600648345b03
Author: Coly Li <colyli@suse.de>
Date:   Thu Dec 13 22:53:53 2018 +0800

    bcache: option to automatically run gc thread after writeback
    
    The option gc_after_writeback is disabled by default, because garbage
    collection will discard SSD data which drops cached data.
    
    Echo 1 into /sys/fs/bcache/<UUID>/internal/gc_after_writeback will
    enable this option, which wakes up gc thread when writeback accomplished
    and all cached data is clean.
    
    This option is helpful for people who cares writing performance more. In
    heavy writing workload, all cached data can be clean only happens when
    writeback thread cleans all cached data in I/O idle time. In such
    situation a following gc running may help to shrink bcache B+ tree and
    discard more clean data, which may be helpful for future writing
    requests.
    
    If you are not sure whether this is helpful for your own workload,
    please leave it as disabled by default.
    
    Signed-off-by: Coly Li <colyli@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index d2b9fdbc8994..ce63be98a39d 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -11,6 +11,8 @@
 #define WRITEBACK_RATE_UPDATE_SECS_MAX		60
 #define WRITEBACK_RATE_UPDATE_SECS_DEFAULT	5
 
+#define BCH_AUTO_GC_DIRTY_THRESHOLD	50
+
 /*
  * 14 (16384ths) is chosen here as something that each backing device
  * should be a reasonable fraction of the share, and not to blow up

commit fc2d5988b5972bced859944986fb36d902ac3698
Author: Coly Li <colyli@suse.de>
Date:   Sat Aug 11 13:19:46 2018 +0800

    bcache: add identifier names to arguments of function definitions
    
    There are many function definitions do not have identifier argument names,
    scripts/checkpatch.pl complains warnings like this,
    
     WARNING: function definition argument 'struct bcache_device *' should
      also have an identifier name
      #16735: FILE: writeback.h:120:
      +void bch_sectors_dirty_init(struct bcache_device *);
    
    This patch adds identifier argument names to all bcache function
    definitions to fix such warnings.
    
    Signed-off-by: Coly Li <colyli@suse.de>
    Reviewed: Shenghui Wang <shhuiw@foxmail.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 76b691850c98..d2b9fdbc8994 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -96,10 +96,11 @@ static inline void bch_writeback_add(struct cached_dev *dc)
 	}
 }
 
-void bcache_dev_sectors_dirty_add(struct cache_set *, unsigned int, uint64_t, int);
+void bcache_dev_sectors_dirty_add(struct cache_set *c, unsigned int inode,
+				  uint64_t offset, int nr_sectors);
 
-void bch_sectors_dirty_init(struct bcache_device *);
-void bch_cached_dev_writeback_init(struct cached_dev *);
-int bch_cached_dev_writeback_start(struct cached_dev *);
+void bch_sectors_dirty_init(struct bcache_device *d);
+void bch_cached_dev_writeback_init(struct cached_dev *dc);
+int bch_cached_dev_writeback_start(struct cached_dev *dc);
 
 #endif

commit 6f10f7d1b02b1bbc305f88d7696445dd38b13881
Author: Coly Li <colyli@suse.de>
Date:   Sat Aug 11 13:19:44 2018 +0800

    bcache: style fix to replace 'unsigned' by 'unsigned int'
    
    This patch fixes warning reported by checkpatch.pl by replacing 'unsigned'
    with 'unsigned int'.
    
    Signed-off-by: Coly Li <colyli@suse.de>
    Reviewed-by: Shenghui Wang <shhuiw@foxmail.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 3745d7004c47..76b691850c98 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -28,7 +28,7 @@ static inline uint64_t bcache_dev_sectors_dirty(struct bcache_device *d)
 	return ret;
 }
 
-static inline unsigned offset_to_stripe(struct bcache_device *d,
+static inline unsigned int offset_to_stripe(struct bcache_device *d,
 					uint64_t offset)
 {
 	do_div(offset, d->stripe_size);
@@ -37,9 +37,9 @@ static inline unsigned offset_to_stripe(struct bcache_device *d,
 
 static inline bool bcache_dev_stripe_dirty(struct cached_dev *dc,
 					   uint64_t offset,
-					   unsigned nr_sectors)
+					   unsigned int nr_sectors)
 {
-	unsigned stripe = offset_to_stripe(&dc->disk, offset);
+	unsigned int stripe = offset_to_stripe(&dc->disk, offset);
 
 	while (1) {
 		if (atomic_read(dc->disk.stripe_sectors_dirty + stripe))
@@ -54,9 +54,9 @@ static inline bool bcache_dev_stripe_dirty(struct cached_dev *dc,
 }
 
 static inline bool should_writeback(struct cached_dev *dc, struct bio *bio,
-				    unsigned cache_mode, bool would_skip)
+				    unsigned int cache_mode, bool would_skip)
 {
-	unsigned in_use = dc->disk.c->gc_stats.in_use;
+	unsigned int in_use = dc->disk.c->gc_stats.in_use;
 
 	if (cache_mode != CACHE_MODE_WRITEBACK ||
 	    test_bit(BCACHE_DEV_DETACHING, &dc->disk.flags) ||
@@ -96,7 +96,7 @@ static inline void bch_writeback_add(struct cached_dev *dc)
 	}
 }
 
-void bcache_dev_sectors_dirty_add(struct cache_set *, unsigned, uint64_t, int);
+void bcache_dev_sectors_dirty_add(struct cache_set *, unsigned int, uint64_t, int);
 
 void bch_sectors_dirty_init(struct bcache_device *);
 void bch_cached_dev_writeback_init(struct cached_dev *);

commit 99a27d59bd7b2ce1a82a4e826e8e7881f4d4954d
Author: Tang Junhui <tang.junhui@zte.com.cn>
Date:   Thu Jul 26 12:17:33 2018 +0800

    bcache: simplify the calculation of the total amount of flash dirty data
    
    Currently we calculate the total amount of flash only devices dirty data
    by adding the dirty data of each flash only device under registering
    locker. It is very inefficient.
    
    In this patch, we add a member flash_dev_dirty_sectors in struct cache_set
    to record the total amount of flash only devices dirty data in real time,
    so we didn't need to calculate the total amount of dirty data any more.
    
    Signed-off-by: Tang Junhui <tang.junhui@zte.com.cn>
    Signed-off-by: Coly Li <colyli@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 610fb01de629..3745d7004c47 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -28,25 +28,6 @@ static inline uint64_t bcache_dev_sectors_dirty(struct bcache_device *d)
 	return ret;
 }
 
-static inline uint64_t  bcache_flash_devs_sectors_dirty(struct cache_set *c)
-{
-	uint64_t i, ret = 0;
-
-	mutex_lock(&bch_register_lock);
-
-	for (i = 0; i < c->devices_max_used; i++) {
-		struct bcache_device *d = c->devices[i];
-
-		if (!d || !UUID_FLASH_ONLY(&c->uuids[i]))
-			continue;
-		ret += bcache_dev_sectors_dirty(d);
-	}
-
-	mutex_unlock(&bch_register_lock);
-
-	return ret;
-}
-
 static inline unsigned offset_to_stripe(struct bcache_device *d,
 					uint64_t offset)
 {

commit fd01991d5c20098c5c1ffc4dca6c821cc60a2f74
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Sun Mar 18 17:36:26 2018 -0700

    bcache: Fix indentation
    
    This patch avoids that smatch complains about inconsistent indentation.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Reviewed-by: Michael Lyle <mlyle@lyle.org>
    Reviewed-by: Coly Li <colyli@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 0bba8f1c6cdf..610fb01de629 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -39,7 +39,7 @@ static inline uint64_t  bcache_flash_devs_sectors_dirty(struct cache_set *c)
 
 		if (!d || !UUID_FLASH_ONLY(&c->uuids[i]))
 			continue;
-	   ret += bcache_dev_sectors_dirty(d);
+		ret += bcache_dev_sectors_dirty(d);
 	}
 
 	mutex_unlock(&bch_register_lock);

commit 804f3c6981f5e4a506a8f14dc284cb218d0659ae
Author: Coly Li <colyli@suse.de>
Date:   Sun Mar 18 17:36:14 2018 -0700

    bcache: fix cached_dev->count usage for bch_cache_set_error()
    
    When bcache metadata I/O fails, bcache will call bch_cache_set_error()
    to retire the whole cache set. The expected behavior to retire a cache
    set is to unregister the cache set, and unregister all backing device
    attached to this cache set, then remove sysfs entries of the cache set
    and all attached backing devices, finally release memory of structs
    cache_set, cache, cached_dev and bcache_device.
    
    In my testing when journal I/O failure triggered by disconnected cache
    device, sometimes the cache set cannot be retired, and its sysfs
    entry /sys/fs/bcache/<uuid> still exits and the backing device also
    references it. This is not expected behavior.
    
    When metadata I/O failes, the call senquence to retire whole cache set is,
            bch_cache_set_error()
            bch_cache_set_unregister()
            bch_cache_set_stop()
            __cache_set_unregister()     <- called as callback by calling
                                            clousre_queue(&c->caching)
            cache_set_flush()            <- called as a callback when refcount
                                            of cache_set->caching is 0
            cache_set_free()             <- called as a callback when refcount
                                            of catch_set->cl is 0
            bch_cache_set_release()      <- called as a callback when refcount
                                            of catch_set->kobj is 0
    
    I find if kernel thread bch_writeback_thread() quits while-loop when
    kthread_should_stop() is true and searched_full_index is false, clousre
    callback cache_set_flush() set by continue_at() will never be called. The
    result is, bcache fails to retire whole cache set.
    
    cache_set_flush() will be called when refcount of closure c->caching is 0,
    and in function bcache_device_detach() refcount of closure c->caching is
    released to 0 by clousre_put(). In metadata error code path, function
    bcache_device_detach() is called by cached_dev_detach_finish(). This is a
    callback routine being called when cached_dev->count is 0. This refcount
    is decreased by cached_dev_put().
    
    The above dependence indicates, cache_set_flush() will be called when
    refcount of cache_set->cl is 0, and refcount of cache_set->cl to be 0
    when refcount of cache_dev->count is 0.
    
    The reason why sometimes cache_dev->count is not 0 (when metadata I/O fails
    and bch_cache_set_error() called) is, in bch_writeback_thread(), refcount
    of cache_dev is not decreased properly.
    
    In bch_writeback_thread(), cached_dev_put() is called only when
    searched_full_index is true and cached_dev->writeback_keys is empty, a.k.a
    there is no dirty data on cache. In most of run time it is correct, but
    when bch_writeback_thread() quits the while-loop while cache is still
    dirty, current code forget to call cached_dev_put() before this kernel
    thread exits. This is why sometimes cache_set_flush() is not executed and
    cache set fails to be retired.
    
    The reason to call cached_dev_put() in bch_writeback_rate() is, when the
    cache device changes from clean to dirty, cached_dev_get() is called, to
    make sure during writeback operatiions both backing and cache devices
    won't be released.
    
    Adding following code in bch_writeback_thread() does not work,
       static int bch_writeback_thread(void *arg)
            }
    
    +       if (atomic_read(&dc->has_dirty))
    +               cached_dev_put()
    +
            return 0;
     }
    because writeback kernel thread can be waken up and start via sysfs entry:
            echo 1 > /sys/block/bcache<N>/bcache/writeback_running
    It is difficult to check whether backing device is dirty without race and
    extra lock. So the above modification will introduce potential refcount
    underflow in some conditions.
    
    The correct fix is, to take cached dev refcount when creating the kernel
    thread, and put it before the kernel thread exits. Then bcache does not
    need to take a cached dev refcount when cache turns from clean to dirty,
    or to put a cached dev refcount when cache turns from ditry to clean. The
    writeback kernel thread is alwasy safe to reference data structure from
    cache set, cache and cached device (because a refcount of cache device is
    taken for it already), and no matter the kernel thread is stopped by I/O
    errors or system reboot, cached_dev->count can always be used correctly.
    
    The patch is simple, but understanding how it works is quite complicated.
    
    Changelog:
    v2: set dc->writeback_thread to NULL in this patch, as suggested by Hannes.
    v1: initial version for review.
    
    Signed-off-by: Coly Li <colyli@suse.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Michael Lyle <mlyle@lyle.org>
    Cc: Michael Lyle <mlyle@lyle.org>
    Cc: Junhui Tang <tang.junhui@zte.com.cn>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 587b25599856..0bba8f1c6cdf 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -105,8 +105,6 @@ static inline void bch_writeback_add(struct cached_dev *dc)
 {
 	if (!atomic_read(&dc->has_dirty) &&
 	    !atomic_xchg(&dc->has_dirty, 1)) {
-		refcount_inc(&dc->count);
-
 		if (BDEV_STATE(&dc->sb) != BDEV_STATE_DIRTY) {
 			SET_BDEV_STATE(&dc->sb, BDEV_STATE_DIRTY);
 			/* XXX: should do this synchronously */

commit 7a5e3ecbe5b7b58e9a78a3738b28244982822e1c
Author: Coly Li <colyli@suse.de>
Date:   Wed Feb 7 11:41:44 2018 -0800

    bcache: set writeback_rate_update_seconds in range [1, 60] seconds
    
    dc->writeback_rate_update_seconds can be set via sysfs and its value can
    be set to [1, ULONG_MAX].  It does not make sense to set such a large
    value, 60 seconds is long enough value considering the default 5 seconds
    works well for long time.
    
    Because dc->writeback_rate_update is a special delayed work, it re-arms
    itself inside the delayed work routine update_writeback_rate(). When
    stopping it by cancel_delayed_work_sync(), there should be a timeout to
    wait and make sure the re-armed delayed work is stopped too. A small max
    value of dc->writeback_rate_update_seconds is also helpful to decide a
    reasonable small timeout.
    
    This patch limits sysfs interface to set dc->writeback_rate_update_seconds
    in range of [1, 60] seconds, and replaces the hand-coded number by macros.
    
    Changelog:
    v2: fix a rebase typo in v4, which is pointed out by Michael Lyle.
    v1: initial version.
    
    Signed-off-by: Coly Li <colyli@suse.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Michael Lyle <mlyle@lyle.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 66f1c527fa24..587b25599856 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -8,6 +8,9 @@
 #define MAX_WRITEBACKS_IN_PASS  5
 #define MAX_WRITESIZE_IN_PASS   5000	/* *512b */
 
+#define WRITEBACK_RATE_UPDATE_SECS_MAX		60
+#define WRITEBACK_RATE_UPDATE_SECS_DEFAULT	5
+
 /*
  * 14 (16384ths) is chosen here as something that each backing device
  * should be a reasonable fraction of the share, and not to blow up

commit 616486ab52ab7f9739b066d958bdd20e65aefd74
Author: Michael Lyle <mlyle@lyle.org>
Date:   Mon Jan 8 12:21:30 2018 -0800

    bcache: fix writeback target calc on large devices
    
    Bcache needs to scale the dirty data in the cache over the multiple
    backing disks in order to calculate writeback rates for each.
    The previous code did this by multiplying the target number of dirty
    sectors by the backing device size, and expected it to fit into a
    uint64_t; this blows up on relatively small backing devices.
    
    The new approach figures out the bdev's share in 16384ths of the overall
    cached data.  This is chosen to cope well when bdevs drastically vary in
    size and to ensure that bcache can cross the petabyte boundary for each
    backing device.
    
    This has been improved based on Tang Junhui's feedback to ensure that
    every device gets a share of dirty data, no matter how small it is
    compared to the total backing pool.
    
    The existing mechanism is very limited; this is purely a bug fix to
    remove limits on volume size.  However, there still needs to be change
    to make this "fair" over many volumes where some are idle.
    
    Reported-by: Jack Douglas <jack@douglastechnology.co.uk>
    Signed-off-by: Michael Lyle <mlyle@lyle.org>
    Reviewed-by: Tang Junhui <tang.junhui@zte.com.cn>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index f102b1f9bc51..66f1c527fa24 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -8,6 +8,13 @@
 #define MAX_WRITEBACKS_IN_PASS  5
 #define MAX_WRITESIZE_IN_PASS   5000	/* *512b */
 
+/*
+ * 14 (16384ths) is chosen here as something that each backing device
+ * should be a reasonable fraction of the share, and not to blow up
+ * until individual backing devices are a petabyte.
+ */
+#define WRITEBACK_SHARE_SHIFT   14
+
 static inline uint64_t bcache_dev_sectors_dirty(struct bcache_device *d)
 {
 	uint64_t i, ret = 0;

commit 2831231d4c3f999d2d062b23dfbc8b0faa4bc6e0
Author: Coly Li <colyli@suse.de>
Date:   Mon Jan 8 12:21:28 2018 -0800

    bcache: reduce cache_set devices iteration by devices_max_used
    
    Member devices of struct cache_set is used to reference all attached
    bcache devices to this cache set. If it is treated as array of pointers,
    size of devices[] is indicated by member nr_uuids of struct cache_set.
    
    nr_uuids is calculated in drivers/md/super.c:bch_cache_set_alloc(),
            bucket_bytes(c) / sizeof(struct uuid_entry)
    Bucket size is determined by user space tool "make-bcache", by default it
    is 1024 sectors (defined in bcache-tools/make-bcache.c:main()). So default
    nr_uuids value is 4096 from the above calculation.
    
    Every time when bcache code iterates bcache devices of a cache set, all
    the 4096 pointers are checked even only 1 bcache device is attached to the
    cache set, that's a wast of time and unncessary.
    
    This patch adds a member devices_max_used to struct cache_set. Its value
    is 1 + the maximum used index of devices[] in a cache set. When iterating
    all valid bcache devices of a cache set, use c->devices_max_used in
    for-loop may reduce a lot of useless checking.
    
    Personally, my motivation of this patch is not for performance, I use it
    in bcache debugging, which helps me to narrow down the scape to check
    valid bcached devices of a cache set.
    
    Signed-off-by: Coly Li <colyli@suse.de>
    Reviewed-by: Michael Lyle <mlyle@lyle.org>
    Reviewed-by: Tang Junhui <tang.junhui@zte.com.cn>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 6d26927267f8..f102b1f9bc51 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -24,7 +24,7 @@ static inline uint64_t  bcache_flash_devs_sectors_dirty(struct cache_set *c)
 
 	mutex_lock(&bch_register_lock);
 
-	for (i = 0; i < c->nr_uuids; i++) {
+	for (i = 0; i < c->devices_max_used; i++) {
 		struct bcache_device *d = c->devices[i];
 
 		if (!d || !UUID_FLASH_ONLY(&c->uuids[i]))

commit 539d39eb27083405b82b9e604e88af01a9a46c63
Author: Tang Junhui <tang.junhui@zte.com.cn>
Date:   Mon Jan 8 12:21:22 2018 -0800

    bcache: fix wrong return value in bch_debug_init()
    
    in bch_debug_init(), ret is always 0, and the return value is useless,
    change it to return 0 if be success after calling debugfs_create_dir(),
    else return a non-zero value.
    
    Signed-off-by: Tang Junhui <tang.junhui@zte.com.cn>
    Reviewed-by: Michael Lyle <mlyle@lyle.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index a9e3ffb4b03c..6d26927267f8 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -5,6 +5,9 @@
 #define CUTOFF_WRITEBACK	40
 #define CUTOFF_WRITEBACK_SYNC	70
 
+#define MAX_WRITEBACKS_IN_PASS  5
+#define MAX_WRITESIZE_IN_PASS   5000	/* *512b */
+
 static inline uint64_t bcache_dev_sectors_dirty(struct bcache_device *d)
 {
 	uint64_t i, ret = 0;

commit e2c5923c349c1738fe8fda980874d93f6fb2e5b6
Merge: abc36be23635 a04b5de5050a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 14 15:32:19 2017 -0800

    Merge branch 'for-4.15/block' of git://git.kernel.dk/linux-block
    
    Pull core block layer updates from Jens Axboe:
     "This is the main pull request for block storage for 4.15-rc1.
    
      Nothing out of the ordinary in here, and no API changes or anything
      like that. Just various new features for drivers, core changes, etc.
      In particular, this pull request contains:
    
       - A patch series from Bart, closing the whole on blk/scsi-mq queue
         quescing.
    
       - A series from Christoph, building towards hidden gendisks (for
         multipath) and ability to move bio chains around.
    
       - NVMe
            - Support for native multipath for NVMe (Christoph).
            - Userspace notifications for AENs (Keith).
            - Command side-effects support (Keith).
            - SGL support (Chaitanya Kulkarni)
            - FC fixes and improvements (James Smart)
            - Lots of fixes and tweaks (Various)
    
       - bcache
            - New maintainer (Michael Lyle)
            - Writeback control improvements (Michael)
            - Various fixes (Coly, Elena, Eric, Liang, et al)
    
       - lightnvm updates, mostly centered around the pblk interface
         (Javier, Hans, and Rakesh).
    
       - Removal of unused bio/bvec kmap atomic interfaces (me, Christoph)
    
       - Writeback series that fix the much discussed hundreds of millions
         of sync-all units. This goes all the way, as discussed previously
         (me).
    
       - Fix for missing wakeup on writeback timer adjustments (Yafang
         Shao).
    
       - Fix laptop mode on blk-mq (me).
    
       - {mq,name} tupple lookup for IO schedulers, allowing us to have
         alias names. This means you can use 'deadline' on both !mq and on
         mq (where it's called mq-deadline). (me).
    
       - blktrace race fix, oopsing on sg load (me).
    
       - blk-mq optimizations (me).
    
       - Obscure waitqueue race fix for kyber (Omar).
    
       - NBD fixes (Josef).
    
       - Disable writeback throttling by default on bfq, like we do on cfq
         (Luca Miccio).
    
       - Series from Ming that enable us to treat flush requests on blk-mq
         like any other request. This is a really nice cleanup.
    
       - Series from Ming that improves merging on blk-mq with schedulers,
         getting us closer to flipping the switch on scsi-mq again.
    
       - BFQ updates (Paolo).
    
       - blk-mq atomic flags memory ordering fixes (Peter Z).
    
       - Loop cgroup support (Shaohua).
    
       - Lots of minor fixes from lots of different folks, both for core and
         driver code"
    
    * 'for-4.15/block' of git://git.kernel.dk/linux-block: (294 commits)
      nvme: fix visibility of "uuid" ns attribute
      blk-mq: fixup some comment typos and lengths
      ide: ide-atapi: fix compile error with defining macro DEBUG
      blk-mq: improve tag waiting setup for non-shared tags
      brd: remove unused brd_mutex
      blk-mq: only run the hardware queue if IO is pending
      block: avoid null pointer dereference on null disk
      fs: guard_bio_eod() needs to consider partitions
      xtensa/simdisk: fix compile error
      nvme: expose subsys attribute to sysfs
      nvme: create 'slaves' and 'holders' entries for hidden controllers
      block: create 'slaves' and 'holders' entries for hidden gendisks
      nvme: also expose the namespace identification sysfs files for mpath nodes
      nvme: implement multipath access to nvme subsystems
      nvme: track shared namespaces
      nvme: introduce a nvme_ns_ids structure
      nvme: track subsystems
      block, nvme: Introduce blk_mq_req_flags_t
      block, scsi: Make SCSI quiesce and resume work reliably
      block: Add the QUEUE_FLAG_PREEMPT_ONLY request queue flag
      ...

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index e35421d20d2e..151544740148 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _BCACHE_WRITEBACK_H
 #define _BCACHE_WRITEBACK_H
 

commit 3b304d24a718ae779ee9c7f2014dd3b2d0893b70
Author: Elena Reshetova <elena.reshetova@intel.com>
Date:   Mon Oct 30 14:46:32 2017 -0700

    bcache: convert cached_dev.count from atomic_t to refcount_t
    
    atomic_t variables are currently used to implement reference
    counters with the following properties:
     - counter is initialized to 1 using atomic_set()
     - a resource is freed upon counter reaching zero
     - once counter reaches zero, its further
       increments aren't allowed
     - counter schema uses basic atomic operations
       (set, inc, inc_not_zero, dec_and_test, etc.)
    
    Such atomic variables should be converted to a newly provided
    refcount_t type and API that prevents accidental counter overflows
    and underflows. This is important since overflows and underflows
    can lead to use-after-free situation and be exploitable.
    
    The variable cached_dev.count is used as pure reference counter.
    Convert it to refcount_t and fix up the operations.
    
    Suggested-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: David Windsor <dwindsor@gmail.com>
    Reviewed-by: Hans Liljestrand <ishkamiel@gmail.com>
    Reviewed-by: Michael Lyle <mlyle@lyle.org>
    Signed-off-by: Elena Reshetova <elena.reshetova@intel.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 34bcf49d737b..7d25bff37a9b 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -91,7 +91,7 @@ static inline void bch_writeback_add(struct cached_dev *dc)
 {
 	if (!atomic_read(&dc->has_dirty) &&
 	    !atomic_xchg(&dc->has_dirty, 1)) {
-		atomic_inc(&dc->count);
+		refcount_inc(&dc->count);
 
 		if (BDEV_STATE(&dc->sb) != BDEV_STATE_DIRTY) {
 			SET_BDEV_STATE(&dc->sb, BDEV_STATE_DIRTY);

commit b41c9b0266e8370033a7799f6806bfc70b7fd75f
Author: Eric Wheeler <bcache@linux.ewheeler.net>
Date:   Fri Oct 13 16:35:33 2017 -0700

    bcache: update bio->bi_opf bypass/writeback REQ_ flag hints
    
    Flag for bypass if the IO is for read-ahead or background, unless the
    read-ahead request is for metadata (eg, from gfs2).
            Bypass if:
                    bio->bi_opf & (REQ_RAHEAD|REQ_BACKGROUND) &&
                            !(bio->bi_opf & REQ_META))
    
            Writeback if:
                    op_is_sync(bio->bi_opf) ||
                            bio->bi_opf & (REQ_META|REQ_PRIO)
    
    Signed-off-by: Eric Wheeler <bcache@linux.ewheeler.net>
    Reviewed-by: Coly Li <colyli@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index e35421d20d2e..34bcf49d737b 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -76,7 +76,9 @@ static inline bool should_writeback(struct cached_dev *dc, struct bio *bio,
 	if (would_skip)
 		return false;
 
-	return op_is_sync(bio->bi_opf) || in_use <= CUTOFF_WRITEBACK;
+	return (op_is_sync(bio->bi_opf) ||
+		bio->bi_opf & (REQ_META|REQ_PRIO) ||
+		in_use <= CUTOFF_WRITEBACK);
 }
 
 static inline void bch_writeback_queue(struct cached_dev *dc)

commit 175206cf9ab63161dec74d9cd7f9992e062491f5
Author: Tang Junhui <tang.junhui@zte.com.cn>
Date:   Thu Sep 7 01:28:53 2017 +0800

    bcache: initialize dirty stripes in flash_dev_run()
    
    bcache uses a Proportion-Differentiation Controller algorithm to control
    writeback rate to cached devices. In the PD controller algorithm, dirty
    stripes of thin flash device should not be counted in, because flash only
    volumes never write back dirty data.
    
    Currently dirty stripe counter for thin flash device is not initialized
    when the thin flash device starts. Which means the following calculation
    in PD controller will reference an undefined dirty stripes number, and
    all cached devices attached to the same cache set where the thin flash
    device lies on may have an inaccurate writeback rate.
    
    This patch calles bch_sectors_dirty_init() in flash_dev_run(), to
    correctly initialize dirty stripe counter when the thin flash device
    starts to run. This patch also does following parameter data type change,
     -void bch_sectors_dirty_init(struct cached_dev *dc);
     +void bch_sectors_dirty_init(struct bcache_device *);
    to call this function conveniently in flash_dev_run().
    
    (Commit log is composed by Coly Li)
    
    Signed-off-by: Tang Junhui <tang.junhui@zte.com.cn>
    Reviewed-by: Coly Li <colyli@suse.de>
    Cc: stable@vger.kernel.org
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 8789b9c8c484..e35421d20d2e 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -103,7 +103,7 @@ static inline void bch_writeback_add(struct cached_dev *dc)
 
 void bcache_dev_sectors_dirty_add(struct cache_set *, unsigned, uint64_t, int);
 
-void bch_sectors_dirty_init(struct cached_dev *dc);
+void bch_sectors_dirty_init(struct bcache_device *);
 void bch_cached_dev_writeback_init(struct cached_dev *);
 int bch_cached_dev_writeback_start(struct cached_dev *);
 

commit a8394090a9129b40f9d90dcb7f4a49d60c727ca6
Author: Tang Junhui <tang.junhui@zte.com.cn>
Date:   Wed Sep 6 14:25:56 2017 +0800

    bcache: correct cache_dirty_target in __update_writeback_rate()
    
    __update_write_rate() uses a Proportion-Differentiation Controller
    algorithm to control writeback rate. A dirty target number is used in
    this PD controller to control writeback rate. A larger target number
    will make the writeback rate smaller, on the versus, a smaller target
    number will make the writeback rate larger.
    
    bcache uses the following steps to calculate the target number,
    1) cache_sectors = all-buckets-of-cache-set * buckets-size
    2) cache_dirty_target = cache_sectors * cached-device-writeback_percent
    3) target = cache_dirty_target *
    (sectors-of-cached-device/sectors-of-all-cached-devices-of-this-cache-set)
    
    The calculation at step 1) for cache_sectors is incorrect, which does
    not consider dirty blocks occupied by flash only volume.
    
    A flash only volume can be took as a bcache device without cached
    device. All data sectors allocated for it are persistent on cache device
    and marked dirty, they are not touched by bcache writeback and garbage
    collection code. So data blocks of flash only volume should be ignore
    when calculating cache_sectors of cache set.
    
    Current code does not subtract dirty sectors of flash only volume, which
    results a larger target number from the above 3 steps. And in sequence
    the cache device's writeback rate is smaller then a correct value,
    writeback speed is slower on all cached devices.
    
    This patch fixes the incorrect slower writeback rate by subtracting
    dirty sectors of flash only volumes in __update_writeback_rate().
    
    (Commit log composed by Coly Li to pass checkpatch.pl checking)
    
    Signed-off-by: Tang Junhui <tang.junhui@zte.com.cn>
    Reviewed-by: Coly Li <colyli@suse.de>
    Cc: stable@vger.kernel.org
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 629bd1a502fd..8789b9c8c484 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -14,6 +14,25 @@ static inline uint64_t bcache_dev_sectors_dirty(struct bcache_device *d)
 	return ret;
 }
 
+static inline uint64_t  bcache_flash_devs_sectors_dirty(struct cache_set *c)
+{
+	uint64_t i, ret = 0;
+
+	mutex_lock(&bch_register_lock);
+
+	for (i = 0; i < c->nr_uuids; i++) {
+		struct bcache_device *d = c->devices[i];
+
+		if (!d || !UUID_FLASH_ONLY(&c->uuids[i]))
+			continue;
+	   ret += bcache_dev_sectors_dirty(d);
+	}
+
+	mutex_unlock(&bch_register_lock);
+
+	return ret;
+}
+
 static inline unsigned offset_to_stripe(struct bcache_device *d,
 					uint64_t offset)
 {

commit 83b5df67c50995ed93b2b7adac3f002ad8bb6069
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Nov 1 07:40:05 2016 -0600

    bcache: use op_is_sync to check for synchronous requests
    
    (and remove one layer of masking for the op_is_write call next to it).
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 301eaf565167..629bd1a502fd 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -57,8 +57,7 @@ static inline bool should_writeback(struct cached_dev *dc, struct bio *bio,
 	if (would_skip)
 		return false;
 
-	return bio->bi_opf & REQ_SYNC ||
-		in_use <= CUTOFF_WRITEBACK;
+	return op_is_sync(bio->bi_opf) || in_use <= CUTOFF_WRITEBACK;
 }
 
 static inline void bch_writeback_queue(struct cached_dev *dc)

commit 1eff9d322a444245c67515edb52bc0eb68374aa8
Author: Jens Axboe <axboe@fb.com>
Date:   Fri Aug 5 15:35:16 2016 -0600

    block: rename bio bi_rw to bi_opf
    
    Since commit 63a4cc24867d, bio->bi_rw contains flags in the lower
    portion and the op code in the higher portions. This means that
    old code that relies on manually setting bi_rw is most likely
    going to be broken. Instead of letting that brokeness linger,
    rename the member, to force old and out-of-tree code to break
    at compile time instead of at runtime.
    
    No intended functional changes in this commit.
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 073a042aed24..301eaf565167 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -57,7 +57,7 @@ static inline bool should_writeback(struct cached_dev *dc, struct bio *bio,
 	if (would_skip)
 		return false;
 
-	return bio->bi_rw & REQ_SYNC ||
+	return bio->bi_opf & REQ_SYNC ||
 		in_use <= CUTOFF_WRITEBACK;
 }
 

commit 8d16ce540c94c9d366eb36fc91b7154d92d6397b
Author: Stefan Bader <stefan.bader@canonical.com>
Date:   Sun Nov 29 18:44:49 2015 -0800

    bcache: prevent crash on changing writeback_running
    
    Added a safeguard in the shutdown case. At least while not being
    attached it is also possible to trigger a kernel bug by writing into
    writeback_running. This change  adds the same check before trying to
    wake up the thread for that case.
    
    Signed-off-by: Stefan Bader <stefan.bader@canonical.com>
    Cc: Kent Overstreet <kent.overstreet@gmail.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 0a9dab187b79..073a042aed24 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -63,7 +63,8 @@ static inline bool should_writeback(struct cached_dev *dc, struct bio *bio,
 
 static inline void bch_writeback_queue(struct cached_dev *dc)
 {
-	wake_up_process(dc->writeback_thread);
+	if (!IS_ERR_OR_NULL(dc->writeback_thread))
+		wake_up_process(dc->writeback_thread);
 }
 
 static inline void bch_writeback_add(struct cached_dev *dc)

commit 9e5c353510b26500bd6b8309823ac9ef2837b761
Author: Slava Pestov <sp@daterainc.com>
Date:   Thu May 1 13:48:57 2014 -0700

    bcache: fix uninterruptible sleep in writeback thread
    
    There were two issues here:
    
    - writeback thread did not start until the device first became dirty
    - writeback thread used uninterruptible sleep once running
    
    Without this patch I see kernel warnings printed and a load average of
    1.52 after booting my test VM. With this patch the warnings are gone and
    the load average is near 0.00 as expected.
    
    Signed-off-by: Kent Overstreet <kmo@daterainc.com>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index e2f8598937ac..0a9dab187b79 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -85,6 +85,7 @@ static inline void bch_writeback_add(struct cached_dev *dc)
 void bcache_dev_sectors_dirty_add(struct cache_set *, unsigned, uint64_t, int);
 
 void bch_sectors_dirty_init(struct cached_dev *dc);
-int bch_cached_dev_writeback_init(struct cached_dev *);
+void bch_cached_dev_writeback_init(struct cached_dev *);
+int bch_cached_dev_writeback_start(struct cached_dev *);
 
 #endif

commit 4f024f3797c43cb4b73cd2c50cec728842d0e49e
Author: Kent Overstreet <kmo@daterainc.com>
Date:   Fri Oct 11 15:44:27 2013 -0700

    block: Abstract out bvec iterator
    
    Immutable biovecs are going to require an explicit iterator. To
    implement immutable bvecs, a later patch is going to add a bi_bvec_done
    member to this struct; for now, this patch effectively just renames
    things.
    
    Signed-off-by: Kent Overstreet <kmo@daterainc.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: "Ed L. Cashin" <ecashin@coraid.com>
    Cc: Nick Piggin <npiggin@kernel.dk>
    Cc: Lars Ellenberg <drbd-dev@lists.linbit.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Matthew Wilcox <willy@linux.intel.com>
    Cc: Geoff Levand <geoff@infradead.org>
    Cc: Yehuda Sadeh <yehuda@inktank.com>
    Cc: Sage Weil <sage@inktank.com>
    Cc: Alex Elder <elder@inktank.com>
    Cc: ceph-devel@vger.kernel.org
    Cc: Joshua Morris <josh.h.morris@us.ibm.com>
    Cc: Philip Kelleher <pjk1939@linux.vnet.ibm.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: "Michael S. Tsirkin" <mst@redhat.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Alasdair Kergon <agk@redhat.com>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: dm-devel@redhat.com
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: linux390@de.ibm.com
    Cc: Boaz Harrosh <bharrosh@panasas.com>
    Cc: Benny Halevy <bhalevy@tonian.com>
    Cc: "James E.J. Bottomley" <JBottomley@parallels.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: "Nicholas A. Bellinger" <nab@linux-iscsi.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Chris Mason <chris.mason@fusionio.com>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Cc: Andreas Dilger <adilger.kernel@dilger.ca>
    Cc: Jaegeuk Kim <jaegeuk.kim@samsung.com>
    Cc: Steven Whitehouse <swhiteho@redhat.com>
    Cc: Dave Kleikamp <shaggy@kernel.org>
    Cc: Joern Engel <joern@logfs.org>
    Cc: Prasad Joshi <prasadjoshi.linux@gmail.com>
    Cc: Trond Myklebust <Trond.Myklebust@netapp.com>
    Cc: KONISHI Ryusuke <konishi.ryusuke@lab.ntt.co.jp>
    Cc: Mark Fasheh <mfasheh@suse.com>
    Cc: Joel Becker <jlbec@evilplan.org>
    Cc: Ben Myers <bpm@sgi.com>
    Cc: xfs@oss.sgi.com
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Len Brown <len.brown@intel.com>
    Cc: Pavel Machek <pavel@ucw.cz>
    Cc: "Rafael J. Wysocki" <rjw@sisk.pl>
    Cc: Herton Ronaldo Krzesinski <herton.krzesinski@canonical.com>
    Cc: Ben Hutchings <ben@decadent.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Guo Chao <yan@linux.vnet.ibm.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Asai Thambi S P <asamymuthupa@micron.com>
    Cc: Selvan Mani <smani@micron.com>
    Cc: Sam Bradshaw <sbradshaw@micron.com>
    Cc: Wei Yongjun <yongjun_wei@trendmicro.com.cn>
    Cc: "Roger Pau Monné" <roger.pau@citrix.com>
    Cc: Jan Beulich <jbeulich@suse.com>
    Cc: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Cc: Ian Campbell <Ian.Campbell@citrix.com>
    Cc: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Jiang Liu <jiang.liu@huawei.com>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Cc: Jerome Marchand <jmarchand@redhat.com>
    Cc: Joe Perches <joe@perches.com>
    Cc: Peng Tao <tao.peng@emc.com>
    Cc: Andy Adamson <andros@netapp.com>
    Cc: fanchaoting <fanchaoting@cn.fujitsu.com>
    Cc: Jie Liu <jeff.liu@oracle.com>
    Cc: Sunil Mushran <sunil.mushran@gmail.com>
    Cc: "Martin K. Petersen" <martin.petersen@oracle.com>
    Cc: Namjae Jeon <namjae.jeon@samsung.com>
    Cc: Pankaj Kumar <pankaj.km@samsung.com>
    Cc: Dan Magenheimer <dan.magenheimer@oracle.com>
    Cc: Mel Gorman <mgorman@suse.de>6

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index c9ddcf4614b9..e2f8598937ac 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -50,7 +50,7 @@ static inline bool should_writeback(struct cached_dev *dc, struct bio *bio,
 		return false;
 
 	if (dc->partial_stripes_expensive &&
-	    bcache_dev_stripe_dirty(dc, bio->bi_sector,
+	    bcache_dev_stripe_dirty(dc, bio->bi_iter.bi_sector,
 				    bio_sectors(bio)))
 		return true;
 

commit c4d951ddb66fe1d087447b0ba65c4fa4446f1083
Author: Kent Overstreet <kmo@daterainc.com>
Date:   Wed Aug 21 17:49:09 2013 -0700

    bcache: Fix sysfs splat on shutdown with flash only devs
    
    Whoops.
    
    Signed-off-by: Kent Overstreet <kmo@daterainc.com>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index fe7d9d56492b..c9ddcf4614b9 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -45,7 +45,7 @@ static inline bool should_writeback(struct cached_dev *dc, struct bio *bio,
 	unsigned in_use = dc->disk.c->gc_stats.in_use;
 
 	if (cache_mode != CACHE_MODE_WRITEBACK ||
-	    atomic_read(&dc->disk.detaching) ||
+	    test_bit(BCACHE_DEV_DETACHING, &dc->disk.flags) ||
 	    in_use > CUTOFF_WRITEBACK_SYNC)
 		return false;
 

commit 48a915a87f0bd98c3d68d029acf223a2e5116f07
Author: Kent Overstreet <kmo@daterainc.com>
Date:   Thu Oct 31 15:43:22 2013 -0700

    bcache: Better full stripe scanning
    
    The old scanning-by-stripe code burned too much CPU, this should be
    better.
    
    Signed-off-by: Kent Overstreet <kmo@daterainc.com>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 60516bfa6052..fe7d9d56492b 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -14,22 +14,27 @@ static inline uint64_t bcache_dev_sectors_dirty(struct bcache_device *d)
 	return ret;
 }
 
-static inline bool bcache_dev_stripe_dirty(struct bcache_device *d,
+static inline unsigned offset_to_stripe(struct bcache_device *d,
+					uint64_t offset)
+{
+	do_div(offset, d->stripe_size);
+	return offset;
+}
+
+static inline bool bcache_dev_stripe_dirty(struct cached_dev *dc,
 					   uint64_t offset,
 					   unsigned nr_sectors)
 {
-	uint64_t stripe = offset;
-
-	do_div(stripe, d->stripe_size);
+	unsigned stripe = offset_to_stripe(&dc->disk, offset);
 
 	while (1) {
-		if (atomic_read(d->stripe_sectors_dirty + stripe))
+		if (atomic_read(dc->disk.stripe_sectors_dirty + stripe))
 			return true;
 
-		if (nr_sectors <= d->stripe_size)
+		if (nr_sectors <= dc->disk.stripe_size)
 			return false;
 
-		nr_sectors -= d->stripe_size;
+		nr_sectors -= dc->disk.stripe_size;
 		stripe++;
 	}
 }
@@ -45,7 +50,7 @@ static inline bool should_writeback(struct cached_dev *dc, struct bio *bio,
 		return false;
 
 	if (dc->partial_stripes_expensive &&
-	    bcache_dev_stripe_dirty(&dc->disk, bio->bi_sector,
+	    bcache_dev_stripe_dirty(dc, bio->bi_sector,
 				    bio_sectors(bio)))
 		return true;
 

commit 5e6926daac267dd99552ae613f041a9e88bbf258
Author: Kent Overstreet <kmo@daterainc.com>
Date:   Wed Jul 24 17:50:06 2013 -0700

    bcache: Convert writeback to a kthread
    
    This simplifies the writeback flow control quite a bit - previously, it
    was conceptually two coroutines, refill_dirty() and read_dirty(). This
    makes the code quite a bit more straightforward.
    
    Signed-off-by: Kent Overstreet <kmo@daterainc.com>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 34961888b5a9..60516bfa6052 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -56,11 +56,30 @@ static inline bool should_writeback(struct cached_dev *dc, struct bio *bio,
 		in_use <= CUTOFF_WRITEBACK;
 }
 
+static inline void bch_writeback_queue(struct cached_dev *dc)
+{
+	wake_up_process(dc->writeback_thread);
+}
+
+static inline void bch_writeback_add(struct cached_dev *dc)
+{
+	if (!atomic_read(&dc->has_dirty) &&
+	    !atomic_xchg(&dc->has_dirty, 1)) {
+		atomic_inc(&dc->count);
+
+		if (BDEV_STATE(&dc->sb) != BDEV_STATE_DIRTY) {
+			SET_BDEV_STATE(&dc->sb, BDEV_STATE_DIRTY);
+			/* XXX: should do this synchronously */
+			bch_write_bdev_super(dc, NULL);
+		}
+
+		bch_writeback_queue(dc);
+	}
+}
+
 void bcache_dev_sectors_dirty_add(struct cache_set *, unsigned, uint64_t, int);
-void bch_writeback_queue(struct cached_dev *);
-void bch_writeback_add(struct cached_dev *);
 
 void bch_sectors_dirty_init(struct cached_dev *dc);
-void bch_cached_dev_writeback_init(struct cached_dev *);
+int bch_cached_dev_writeback_init(struct cached_dev *);
 
 #endif

commit 2d679fc75678551485df62274edaed452becd16d
Author: Kent Overstreet <kmo@daterainc.com>
Date:   Sat Aug 17 02:13:15 2013 -0700

    bcache: Stripe size isn't necessarily a power of two
    
    Originally I got this right... except that the divides didn't use
    do_div(), which broke 32 bit kernels. When I went to fix that, I forgot
    that the raid stripe size usually isn't a power of two... doh
    
    Signed-off-by: Kent Overstreet <kmo@daterainc.com>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index c91f61bb95b6..34961888b5a9 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -18,16 +18,18 @@ static inline bool bcache_dev_stripe_dirty(struct bcache_device *d,
 					   uint64_t offset,
 					   unsigned nr_sectors)
 {
-	uint64_t stripe = offset >> d->stripe_size_bits;
+	uint64_t stripe = offset;
+
+	do_div(stripe, d->stripe_size);
 
 	while (1) {
 		if (atomic_read(d->stripe_sectors_dirty + stripe))
 			return true;
 
-		if (nr_sectors <= 1 << d->stripe_size_bits)
+		if (nr_sectors <= d->stripe_size)
 			return false;
 
-		nr_sectors -= 1 << d->stripe_size_bits;
+		nr_sectors -= d->stripe_size;
 		stripe++;
 	}
 }

commit 72c270612bd33192fa836ad0f2939af1ca218292
Author: Kent Overstreet <koverstreet@google.com>
Date:   Wed Jun 5 06:24:39 2013 -0700

    bcache: Write out full stripes
    
    Now that we're tracking dirty data per stripe, we can add two
    optimizations for raid5/6:
    
     * If a stripe is already dirty, force writes to that stripe to
       writeback mode - to help build up full stripes of dirty data
    
     * When flushing dirty data, preferentially write out full stripes first
       if there are any.
    
    Signed-off-by: Kent Overstreet <koverstreet@google.com>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
index 5ce9771df047..c91f61bb95b6 100644
--- a/drivers/md/bcache/writeback.h
+++ b/drivers/md/bcache/writeback.h
@@ -1,6 +1,9 @@
 #ifndef _BCACHE_WRITEBACK_H
 #define _BCACHE_WRITEBACK_H
 
+#define CUTOFF_WRITEBACK	40
+#define CUTOFF_WRITEBACK_SYNC	70
+
 static inline uint64_t bcache_dev_sectors_dirty(struct bcache_device *d)
 {
 	uint64_t i, ret = 0;
@@ -11,6 +14,46 @@ static inline uint64_t bcache_dev_sectors_dirty(struct bcache_device *d)
 	return ret;
 }
 
+static inline bool bcache_dev_stripe_dirty(struct bcache_device *d,
+					   uint64_t offset,
+					   unsigned nr_sectors)
+{
+	uint64_t stripe = offset >> d->stripe_size_bits;
+
+	while (1) {
+		if (atomic_read(d->stripe_sectors_dirty + stripe))
+			return true;
+
+		if (nr_sectors <= 1 << d->stripe_size_bits)
+			return false;
+
+		nr_sectors -= 1 << d->stripe_size_bits;
+		stripe++;
+	}
+}
+
+static inline bool should_writeback(struct cached_dev *dc, struct bio *bio,
+				    unsigned cache_mode, bool would_skip)
+{
+	unsigned in_use = dc->disk.c->gc_stats.in_use;
+
+	if (cache_mode != CACHE_MODE_WRITEBACK ||
+	    atomic_read(&dc->disk.detaching) ||
+	    in_use > CUTOFF_WRITEBACK_SYNC)
+		return false;
+
+	if (dc->partial_stripes_expensive &&
+	    bcache_dev_stripe_dirty(&dc->disk, bio->bi_sector,
+				    bio_sectors(bio)))
+		return true;
+
+	if (would_skip)
+		return false;
+
+	return bio->bi_rw & REQ_SYNC ||
+		in_use <= CUTOFF_WRITEBACK;
+}
+
 void bcache_dev_sectors_dirty_add(struct cache_set *, unsigned, uint64_t, int);
 void bch_writeback_queue(struct cached_dev *);
 void bch_writeback_add(struct cached_dev *);

commit 279afbad4e54acbd61bf88a54a73af3bbfdeb5dd
Author: Kent Overstreet <koverstreet@google.com>
Date:   Wed Jun 5 06:21:07 2013 -0700

    bcache: Track dirty data by stripe
    
    To make background writeback aware of raid5/6 stripes, we first need to
    track the amount of dirty data within each stripe - we do this by
    breaking up the existing sectors_dirty into per stripe atomic_ts
    
    Signed-off-by: Kent Overstreet <koverstreet@google.com>

diff --git a/drivers/md/bcache/writeback.h b/drivers/md/bcache/writeback.h
new file mode 100644
index 000000000000..5ce9771df047
--- /dev/null
+++ b/drivers/md/bcache/writeback.h
@@ -0,0 +1,21 @@
+#ifndef _BCACHE_WRITEBACK_H
+#define _BCACHE_WRITEBACK_H
+
+static inline uint64_t bcache_dev_sectors_dirty(struct bcache_device *d)
+{
+	uint64_t i, ret = 0;
+
+	for (i = 0; i < d->nr_stripes; i++)
+		ret += atomic_read(d->stripe_sectors_dirty + i);
+
+	return ret;
+}
+
+void bcache_dev_sectors_dirty_add(struct cache_set *, unsigned, uint64_t, int);
+void bch_writeback_queue(struct cached_dev *);
+void bch_writeback_add(struct cached_dev *);
+
+void bch_sectors_dirty_init(struct cached_dev *dc);
+void bch_cached_dev_writeback_init(struct cached_dev *);
+
+#endif
