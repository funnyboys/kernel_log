commit 78f57ef9d50a75326da73d352d7c27828495229a
Author: Coly Li <colyli@suse.de>
Date:   Thu Apr 9 22:17:20 2020 +0800

    md: use memalloc scope APIs in mddev_suspend()/mddev_resume()
    
    In raid5.c:resize_chunk(), scribble_alloc() is called with GFP_NOIO
    flag, then it is sent into kvmalloc_array() inside scribble_alloc().
    
    The problem is kvmalloc_array() eventually calls kvmalloc_node() which
    does not accept non GFP_KERNEL compatible flag like GFP_NOIO, then
    kmalloc_node() is called indeed to allocate physically continuous
    pages. When system memory is under heavy pressure, and the requesting
    size is large, there is high probability that allocating continueous
    pages will fail.
    
    But simply using GFP_KERNEL flag to call kvmalloc_array() is also
    progblematic. In the code path where scribble_alloc() is called, the
    raid array is suspended, if kvmalloc_node() triggers memory reclaim I/Os
    and such I/Os go back to the suspend raid array, deadlock will happen.
    
    What is desired here is to allocate non-physically (a.k.a virtually)
    continuous pages and avoid memory reclaim I/Os. Michal Hocko suggests
    to use the mmealloc sceope APIs to restrict memory reclaim I/O in
    allocating context, specifically to call memalloc_noio_save() when
    suspend the raid array and to call memalloc_noio_restore() when
    resume the raid array.
    
    This patch adds the memalloc scope APIs in mddev_suspend() and
    mddev_resume(), to restrict memory reclaim I/Os during the raid array
    is suspended. The benifit of adding the memalloc scope API in the
    unified entry point mddev_suspend()/mddev_resume() is, no matter which
    md raid array type (personality), we are sure the deadlock by recursive
    memory reclaim I/O won't happen on the suspending context.
    
    Please notice that the memalloc scope APIs only take effect on the raid
    array suspending context, if the memory allocation is from another new
    created kthread after raid array suspended, the recursive memory reclaim
    I/Os won't be restricted. The mddev_suspend()/mddev_resume() entries are
    used for the critical section where the raid metadata is modifying,
    creating a kthread to allocate memory inside the critical section is
    queer and very probably being buggy.
    
    Fixes: b330e6a49dc3 ("md: convert to kvmalloc")
    Suggested-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Coly Li <colyli@suse.de>
    Signed-off-by: Song Liu <songliubraving@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index acd681939112..612814d07d35 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -497,6 +497,7 @@ struct mddev {
 	void (*sync_super)(struct mddev *mddev, struct md_rdev *rdev);
 	struct md_cluster_info		*cluster_info;
 	unsigned int			good_device_nr;	/* good device num within cluster raid */
+	unsigned int			noio_flag; /* for memalloc scope API */
 
 	bool	has_superblocks:1;
 	bool	fail_last_dev:1;

commit 69b00b5bb23552d43e8bbed73ef6624604bb94a2
Author: Guoqing Jiang <guoqing.jiang@cloud.ionos.com>
Date:   Mon Dec 23 10:49:00 2019 +0100

    md: introduce a new struct for IO serialization
    
    Obviously, IO serialization could cause the degradation of
    performance a lot. In order to reduce the degradation, so a
    rb interval tree is added in raid1 to speed up the check of
    collision.
    
    So, a rb root is needed in md_rdev, then abstract all the
    serialize related members to a new struct (serial_in_rdev),
    embed it into md_rdev.
    
    Of course, we need to free the struct if it is not needed
    anymore, so rdev/rdevs_uninit_serial are added accordingly.
    And they should be called when destroty memory pool or can't
    alloc memory.
    
    And we need to consider to call mddev_destroy_serial_pool
    in case serialize_policy/write-behind is disabled, bitmap
    is destroyed or in __md_stop_writes.
    
    Signed-off-by: Guoqing Jiang <guoqing.jiang@cloud.ionos.com>
    Signed-off-by: Song Liu <songliubraving@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index f51a3afaee1b..acd681939112 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -32,6 +32,16 @@
  * be retried.
  */
 #define	MD_FAILFAST	(REQ_FAILFAST_DEV | REQ_FAILFAST_TRANSPORT)
+
+/*
+ * The struct embedded in rdev is used to serialize IO.
+ */
+struct serial_in_rdev {
+	struct rb_root_cached serial_rb;
+	spinlock_t serial_lock;
+	wait_queue_head_t serial_io_wait;
+};
+
 /*
  * MD's 'extended' device
  */
@@ -110,12 +120,7 @@ struct md_rdev {
 					   * in superblock.
 					   */
 
-	/*
-	 * The members for check collision of write IOs.
-	 */
-	struct list_head serial_list;
-	spinlock_t serial_list_lock;
-	wait_queue_head_t serial_io_wait;
+	struct serial_in_rdev *serial;  /* used for raid1 io serialization */
 
 	struct work_struct del_work;	/* used for delayed sysfs removal */
 
@@ -266,9 +271,10 @@ enum mddev_sb_flags {
 #define NR_SERIAL_INFOS		8
 /* record current range of serialize IOs */
 struct serial_info {
-	sector_t lo;
-	sector_t hi;
-	struct list_head list;
+	struct rb_node node;
+	sector_t start;		/* start sector of rb node */
+	sector_t last;		/* end sector of rb node */
+	sector_t _subtree_last; /* highest sector in subtree of rb node */
 };
 
 struct mddev {
@@ -740,6 +746,8 @@ extern void md_update_sb(struct mddev *mddev, int force);
 extern void md_kick_rdev_from_array(struct md_rdev * rdev);
 extern void mddev_create_serial_pool(struct mddev *mddev, struct md_rdev *rdev,
 				     bool is_suspend);
+extern void mddev_destroy_serial_pool(struct mddev *mddev, struct md_rdev *rdev,
+				      bool is_suspend);
 struct md_rdev *md_find_rdev_nr_rcu(struct mddev *mddev, int nr);
 struct md_rdev *md_find_rdev_rcu(struct mddev *mddev, dev_t dev);
 

commit 3938f5fb82aedbf39792ffee448c61c819e6ab38
Author: Guoqing Jiang <guoqing.jiang@cloud.ionos.com>
Date:   Mon Dec 23 10:48:56 2019 +0100

    md: add serialize_policy sysfs node for raid1
    
    With the new sysfs node, we can use it to control if raid1 array
    wants io serialization or not. So mddev_create_serial_pool and
    mddev_destroy_serial_pool are called in serialize_policy_store
    to enable or disable the serialization.
    
    Signed-off-by: Guoqing Jiang <guoqing.jiang@cloud.ionos.com>
    Signed-off-by: Song Liu <songliubraving@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index de04a8d3a67a..f51a3afaee1b 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -494,6 +494,7 @@ struct mddev {
 
 	bool	has_superblocks:1;
 	bool	fail_last_dev:1;
+	bool	serialize_policy:1;
 };
 
 enum recovery_flags {

commit 11d3a9f65018c9fb3d4f2032aec76af2ba98431c
Author: Guoqing Jiang <guoqing.jiang@cloud.ionos.com>
Date:   Mon Dec 23 10:48:55 2019 +0100

    md: prepare for enable raid1 io serialization
    
    1. The related resources (spin_lock, list and waitqueue) are needed for
    address raid1 reorder overlap issue too, in this case, rdev is set to
    NULL for mddev_create/destroy_serial_pool which implies all rdevs need
    to handle these resources.
    
    And also add "is_suspend" to mddev_destroy_serial_pool since it will
    be called under suspended situation, which also makes both create and
    destroy pool have same arguments.
    
    2. Introduce rdevs_init_serial which is called if raid1 io serialization
    is enabled since all rdevs need to init related stuffs.
    
    3. rdev_init_serial and clear_bit(CollisionCheck, &rdev->flags) should
    be called between suspend and resume.
    
    No need to export mddev_create_serial_pool since it is only called in
    md-mod module.
    
    Signed-off-by: Guoqing Jiang <guoqing.jiang@cloud.ionos.com>
    Signed-off-by: Song Liu <songliubraving@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 7b811645cec7..de04a8d3a67a 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -738,7 +738,7 @@ extern void md_reload_sb(struct mddev *mddev, int raid_disk);
 extern void md_update_sb(struct mddev *mddev, int force);
 extern void md_kick_rdev_from_array(struct md_rdev * rdev);
 extern void mddev_create_serial_pool(struct mddev *mddev, struct md_rdev *rdev,
-				 bool is_suspend);
+				     bool is_suspend);
 struct md_rdev *md_find_rdev_nr_rcu(struct mddev *mddev, int nr);
 struct md_rdev *md_find_rdev_rcu(struct mddev *mddev, dev_t dev);
 

commit 404659cf1e2570dad3cd117fa3bd71f06ecfd142
Author: Guoqing Jiang <guoqing.jiang@cloud.ionos.com>
Date:   Mon Dec 23 10:48:53 2019 +0100

    md: rename wb stuffs
    
    Previously, wb_info_pool and wb_list stuffs are introduced
    to address potential data inconsistence issue for write
    behind device.
    
    Now rename them to serial related name, since the same
    mechanism will be used to address reorder overlap write
    issue for raid1.
    
    Signed-off-by: Guoqing Jiang <guoqing.jiang@cloud.ionos.com>
    Signed-off-by: Song Liu <songliubraving@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 5f86f8adb0a4..7b811645cec7 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -111,11 +111,11 @@ struct md_rdev {
 					   */
 
 	/*
-	 * The members for check collision of write behind IOs.
+	 * The members for check collision of write IOs.
 	 */
-	struct list_head wb_list;
-	spinlock_t wb_list_lock;
-	wait_queue_head_t wb_io_wait;
+	struct list_head serial_list;
+	spinlock_t serial_list_lock;
+	wait_queue_head_t serial_io_wait;
 
 	struct work_struct del_work;	/* used for delayed sysfs removal */
 
@@ -201,9 +201,9 @@ enum flag_bits {
 				 * it didn't fail, so don't use FailFast
 				 * any more for metadata
 				 */
-	WBCollisionCheck,	/*
-				 * multiqueue device should check if there
-				 * is collision between write behind bios.
+	CollisionCheck,		/*
+				 * check if there is collision between raid1
+				 * serial bios.
 				 */
 };
 
@@ -263,9 +263,9 @@ enum mddev_sb_flags {
 	MD_SB_NEED_REWRITE,	/* metadata write needs to be repeated */
 };
 
-#define NR_WB_INFOS	8
-/* record current range of write behind IOs */
-struct wb_info {
+#define NR_SERIAL_INFOS		8
+/* record current range of serialize IOs */
+struct serial_info {
 	sector_t lo;
 	sector_t hi;
 	struct list_head list;
@@ -487,7 +487,7 @@ struct mddev {
 					  */
 	struct work_struct flush_work;
 	struct work_struct event_work;	/* used by dm to report failure event */
-	mempool_t *wb_info_pool;
+	mempool_t *serial_info_pool;
 	void (*sync_super)(struct mddev *mddev, struct md_rdev *rdev);
 	struct md_cluster_info		*cluster_info;
 	unsigned int			good_device_nr;	/* good device num within cluster raid */
@@ -737,7 +737,7 @@ extern struct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,
 extern void md_reload_sb(struct mddev *mddev, int raid_disk);
 extern void md_update_sb(struct mddev *mddev, int force);
 extern void md_kick_rdev_from_array(struct md_rdev * rdev);
-extern void mddev_create_wb_pool(struct mddev *mddev, struct md_rdev *rdev,
+extern void mddev_create_serial_pool(struct mddev *mddev, struct md_rdev *rdev,
 				 bool is_suspend);
 struct md_rdev *md_find_rdev_nr_rcu(struct mddev *mddev, int nr);
 struct md_rdev *md_find_rdev_rcu(struct mddev *mddev, dev_t dev);

commit 775d78319f1ceb32be8eb3b1202ccdc60e9cb7f1
Author: David Jeffery <djeffery@redhat.com>
Date:   Mon Sep 16 13:15:14 2019 -0400

    md: improve handling of bio with REQ_PREFLUSH in md_flush_request()
    
    If pers->make_request fails in md_flush_request(), the bio is lost. To
    fix this, pass back a bool to indicate if the original make_request call
    should continue to handle the I/O and instead of assuming the flush logic
    will push it to completion.
    
    Convert md_flush_request to return a bool and no longer calls the raid
    driver's make_request function.  If the return is true, then the md flush
    logic has or will complete the bio and the md make_request call is done.
    If false, then the md make_request function needs to keep processing like
    it is a normal bio. Let the original call to md_handle_request handle any
    need to retry sending the bio to the raid driver's make_request function
    should it be needed.
    
    Also mark md_flush_request and the make_request function pointer as
    __must_check to issue warnings should these critical return values be
    ignored.
    
    Fixes: 2bc13b83e629 ("md: batch flush requests.")
    Cc: stable@vger.kernel.org # # v4.19+
    Cc: NeilBrown <neilb@suse.com>
    Signed-off-by: David Jeffery <djeffery@redhat.com>
    Reviewed-by: Xiao Ni <xni@redhat.com>
    Signed-off-by: Song Liu <songliubraving@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index c5e3ff398b59..5f86f8adb0a4 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -550,7 +550,7 @@ struct md_personality
 	int level;
 	struct list_head list;
 	struct module *owner;
-	bool (*make_request)(struct mddev *mddev, struct bio *bio);
+	bool __must_check (*make_request)(struct mddev *mddev, struct bio *bio);
 	/*
 	 * start up works that do NOT require md_thread. tasks that
 	 * requires md_thread should go into start()
@@ -703,7 +703,7 @@ extern void md_error(struct mddev *mddev, struct md_rdev *rdev);
 extern void md_finish_reshape(struct mddev *mddev);
 
 extern int mddev_congested(struct mddev *mddev, int bits);
-extern void md_flush_request(struct mddev *mddev, struct bio *bio);
+extern bool __must_check md_flush_request(struct mddev *mddev, struct bio *bio);
 extern void md_super_write(struct mddev *mddev, struct md_rdev *rdev,
 			   sector_t sector, int size, struct page *page);
 extern int md_super_wait(struct mddev *mddev);

commit 62f7b1989c02feed9274131b2fd5e990de4aba6f
Author: Guilherme G. Piccoli <gpiccoli@canonical.com>
Date:   Tue Sep 3 16:49:00 2019 -0300

    md raid0/linear: Mark array as 'broken' and fail BIOs if a member is gone
    
    Currently md raid0/linear are not provided with any mechanism to validate
    if an array member got removed or failed. The driver keeps sending BIOs
    regardless of the state of array members, and kernel shows state 'clean'
    in the 'array_state' sysfs attribute. This leads to the following
    situation: if a raid0/linear array member is removed and the array is
    mounted, some user writing to this array won't realize that errors are
    happening unless they check dmesg or perform one fsync per written file.
    Despite udev signaling the member device is gone, 'mdadm' cannot issue the
    STOP_ARRAY ioctl successfully, given the array is mounted.
    
    In other words, no -EIO is returned and writes (except direct ones) appear
    normal. Meaning the user might think the wrote data is correctly stored in
    the array, but instead garbage was written given that raid0 does stripping
    (and so, it requires all its members to be working in order to not corrupt
    data). For md/linear, writes to the available members will work fine, but
    if the writes go to the missing member(s), it'll cause a file corruption
    situation, whereas the portion of the writes to the missing devices aren't
    written effectively.
    
    This patch changes this behavior: we check if the block device's gendisk
    is UP when submitting the BIO to the array member, and if it isn't, we flag
    the md device as MD_BROKEN and fail subsequent I/Os to that device; a read
    request to the array requiring data from a valid member is still completed.
    While flagging the device as MD_BROKEN, we also show a rate-limited warning
    in the kernel log.
    
    A new array state 'broken' was added too: it mimics the state 'clean' in
    every aspect, being useful only to distinguish if the array has some member
    missing. We rely on the MD_BROKEN flag to put the array in the 'broken'
    state. This state cannot be written in 'array_state' as it just shows
    one or more members of the array are missing but acts like 'clean', it
    wouldn't make sense to write it.
    
    With this patch, the filesystem reacts much faster to the event of missing
    array member: after some I/O errors, ext4 for instance aborts the journal
    and prevents corruption. Without this change, we're able to keep writing
    in the disk and after a machine reboot, e2fsck shows some severe fs errors
    that demand fixing. This patch was tested in ext4 and xfs filesystems, and
    requires a 'mdadm' counterpart to handle the 'broken' state.
    
    Cc: Song Liu <songliubraving@fb.com>
    Reviewed-by: NeilBrown <neilb@suse.de>
    Signed-off-by: Guilherme G. Piccoli <gpiccoli@canonical.com>
    Signed-off-by: Song Liu <songliubraving@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 1edcd967eb8e..c5e3ff398b59 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -251,6 +251,9 @@ enum mddev_flags {
 	MD_NOT_READY,		/* do_md_run() is active, so 'array_state'
 				 * must not report that array is ready yet
 				 */
+	MD_BROKEN,              /* This is used in RAID-0/LINEAR only, to stop
+				 * I/O in case an array member is gone/failed.
+				 */
 };
 
 enum mddev_sb_flags {
@@ -739,6 +742,19 @@ extern void mddev_create_wb_pool(struct mddev *mddev, struct md_rdev *rdev,
 struct md_rdev *md_find_rdev_nr_rcu(struct mddev *mddev, int nr);
 struct md_rdev *md_find_rdev_rcu(struct mddev *mddev, dev_t dev);
 
+static inline bool is_mddev_broken(struct md_rdev *rdev, const char *md_type)
+{
+	int flags = rdev->bdev->bd_disk->flags;
+
+	if (!(flags & GENHD_FL_UP)) {
+		if (!test_and_set_bit(MD_BROKEN, &rdev->mddev->flags))
+			pr_warn("md: %s: %s array has a missing/failed member\n",
+				mdname(rdev->mddev), md_type);
+		return true;
+	}
+	return false;
+}
+
 static inline void rdev_dec_pending(struct md_rdev *rdev, struct mddev *mddev)
 {
 	int faulty = test_bit(Faulty, &rdev->flags);

commit 9d4b45d6af442237560d0bb5502a012baa5234b7
Author: NeilBrown <neilb@suse.com>
Date:   Tue Aug 20 10:21:09 2019 +1000

    md: don't report active array_state until after revalidate_disk() completes.
    
    Until revalidate_disk() has completed, the size of a new md array will
    appear to be zero.
    So we shouldn't report, through array_state, that the array is active
    until that time.
    udev rules check array_state to see if the array is ready.  As soon as
    it appear to be zero, fsck can be run.  If it find the size to be
    zero, it will fail.
    
    So add a new flag to provide an interlock between do_md_run() and
    array_state_show().  This flag is set while do_md_run() is active and
    it prevents array_state_show() from reporting that the array is
    active.
    
    Before do_md_run() is called, ->pers will be NULL so array is
    definitely not active.
    After do_md_run() is called, revalidate_disk() will have run and the
    array will be completely ready.
    
    We also move various sysfs_notify*() calls out of md_run() into
    do_md_run() after MD_NOT_READY is cleared.  This ensure the
    information is ready before the notification is sent.
    
    Prior to v4.12, array_state_show() was called with the
    mddev->reconfig_mutex held, which provided exclusion with do_md_run().
    
    Note that MD_NOT_READY cleared twice.  This is deliberate to cover
    both success and error paths with minimal noise.
    
    Fixes: b7b17c9b67e5 ("md: remove mddev_lock() from md_attr_show()")
    Cc: stable@vger.kernel.org (v4.12++)
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Song Liu <songliubraving@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index b742659150a2..1edcd967eb8e 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -248,6 +248,9 @@ enum mddev_flags {
 	MD_UPDATING_SB,		/* md_check_recovery is updating the metadata
 				 * without explicitly holding reconfig_mutex.
 				 */
+	MD_NOT_READY,		/* do_md_run() is active, so 'array_state'
+				 * must not report that array is ready yet
+				 */
 };
 
 enum mddev_sb_flags {

commit 9a567843f7ce0037bfd4d5fdc58a09d0a527b28b
Author: Guoqing Jiang <jgq516@gmail.com>
Date:   Wed Jul 24 11:09:19 2019 +0200

    md: allow last device to be forcibly removed from RAID1/RAID10.
    
    When the 'last' device in a RAID1 or RAID10 reports an error,
    we do not mark it as failed.  This would serve little purpose
    as there is no risk of losing data beyond that which is obviously
    lost (as there is with RAID5), and there could be other sectors
    on the device which are readable, and only readable from this device.
    This in general this maximises access to data.
    
    However the current implementation also stops an admin from removing
    the last device by direct action.  This is rarely useful, but in many
    case is not harmful and can make automation easier by removing special
    cases.
    
    Also, if an attempt to write metadata fails the device must be marked
    as faulty, else an infinite loop will result, attempting to update
    the metadata on all non-faulty devices.
    
    So add 'fail_last_dev' member to 'struct mddev', then we can bypasses
    the 'last disk' checks for RAID1 and RAID10, and control the behavior
    per array by change sysfs node.
    
    Signed-off-by: NeilBrown <neilb@suse.de>
    [add sysfs node for fail_last_dev by Guoqing]
    Signed-off-by: Guoqing Jiang <guoqing.jiang@cloud.ionos.com>
    Signed-off-by: Song Liu <songliubraving@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 10f98200e2f8..b742659150a2 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -487,6 +487,7 @@ struct mddev {
 	unsigned int			good_device_nr;	/* good device num within cluster raid */
 
 	bool	has_superblocks:1;
+	bool	fail_last_dev:1;
 };
 
 enum recovery_flags {

commit 963c555e75b033202dd76cf6325a7b7c83d08d5f
Author: Guoqing Jiang <gqjiang@suse.com>
Date:   Fri Jun 14 17:10:36 2019 +0800

    md: introduce mddev_create/destroy_wb_pool for the change of member device
    
    Previously, we called rdev_init_wb to avoid potential data
    inconsistency when array is created.
    
    Now, we need to call the function and create mempool if a
    device is added or just be flaged as "writemostly". So
    mddev_create_wb_pool is introduced and called accordingly.
    And for safety reason, we mark implicit GFP_NOIO allocation
    scope for create mempool during mddev_suspend/mddev_resume.
    
    And mempool should be removed conversely after remove a
    member device or its's "writemostly" flag, which is done
    by call mddev_destroy_wb_pool.
    
    Reviewed-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Guoqing Jiang <gqjiang@suse.com>
    Signed-off-by: Song Liu <songliubraving@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index d449d514cff9..10f98200e2f8 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -730,6 +730,8 @@ extern struct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,
 extern void md_reload_sb(struct mddev *mddev, int raid_disk);
 extern void md_update_sb(struct mddev *mddev, int force);
 extern void md_kick_rdev_from_array(struct md_rdev * rdev);
+extern void mddev_create_wb_pool(struct mddev *mddev, struct md_rdev *rdev,
+				 bool is_suspend);
 struct md_rdev *md_find_rdev_nr_rcu(struct mddev *mddev, int nr);
 struct md_rdev *md_find_rdev_rcu(struct mddev *mddev, dev_t dev);
 

commit 3e148a3209792e04f63ec99701235c960765fc9a
Author: Guoqing Jiang <gqjiang@suse.com>
Date:   Wed Jun 19 17:30:46 2019 +0800

    md/raid1: fix potential data inconsistency issue with write behind device
    
    For write-behind mode, we think write IO is complete once it has
    reached all the non-writemostly devices. It works fine for single
    queue devices.
    
    But for multiqueue device, if there are lots of IOs come from upper
    layer, then the write-behind device could issue those IOs to different
    queues, depends on the each queue's delay, so there is no guarantee
    that those IOs can arrive in order.
    
    To address the issue, we need to check the collision among write
    behind IOs, we can only continue without collision, otherwise wait
    for the completion of previous collisioned IO.
    
    And WBCollision is introduced for multiqueue device which is worked
    under write-behind mode.
    
    But this patch doesn't handle below cases which could have the data
    inconsistency issue as well, these cases will be handled in later
    patches.
    
    1. modify max_write_behind by write backlog node.
    2. add or remove array's bitmap dynamically.
    3. the change of member disk.
    
    Reviewed-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Guoqing Jiang <gqjiang@suse.com>
    Signed-off-by: Song Liu <songliubraving@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 7c930c091193..d449d514cff9 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -109,6 +109,14 @@ struct md_rdev {
 					   * for reporting to userspace and storing
 					   * in superblock.
 					   */
+
+	/*
+	 * The members for check collision of write behind IOs.
+	 */
+	struct list_head wb_list;
+	spinlock_t wb_list_lock;
+	wait_queue_head_t wb_io_wait;
+
 	struct work_struct del_work;	/* used for delayed sysfs removal */
 
 	struct kernfs_node *sysfs_state; /* handle for 'state'
@@ -193,6 +201,10 @@ enum flag_bits {
 				 * it didn't fail, so don't use FailFast
 				 * any more for metadata
 				 */
+	WBCollisionCheck,	/*
+				 * multiqueue device should check if there
+				 * is collision between write behind bios.
+				 */
 };
 
 static inline int is_badblock(struct md_rdev *rdev, sector_t s, int sectors,
@@ -245,6 +257,14 @@ enum mddev_sb_flags {
 	MD_SB_NEED_REWRITE,	/* metadata write needs to be repeated */
 };
 
+#define NR_WB_INFOS	8
+/* record current range of write behind IOs */
+struct wb_info {
+	sector_t lo;
+	sector_t hi;
+	struct list_head list;
+};
+
 struct mddev {
 	void				*private;
 	struct md_personality		*pers;
@@ -461,6 +481,7 @@ struct mddev {
 					  */
 	struct work_struct flush_work;
 	struct work_struct event_work;	/* used by dm to report failure event */
+	mempool_t *wb_info_pool;
 	void (*sync_super)(struct mddev *mddev, struct md_rdev *rdev);
 	struct md_cluster_info		*cluster_info;
 	unsigned int			good_device_nr;	/* good device num within cluster raid */

commit af1a8899d22c8acda5514999cd797d7139e47e56
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 20 19:08:12 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 47
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 or at your option any
      later version you should have received a copy of the gnu general
      public license for example usr src linux copying if not write to the
      free software foundation inc 675 mass ave cambridge ma 02139 usa
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 20 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190520170858.552543146@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 257cb4c9e22b..7c930c091193 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -1,15 +1,8 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
 /*
    md.h : kernel internal structure of the Linux MD driver
           Copyright (C) 1996-98 Ingo Molnar, Gadi Oxman
 
-   This program is free software; you can redistribute it and/or modify
-   it under the terms of the GNU General Public License as published by
-   the Free Software Foundation; either version 2, or (at your option)
-   any later version.
-
-   You should have received a copy of the GNU General Public License
-   (for example /usr/src/linux/COPYING); if not, write to the Free
-   Software Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 */
 
 #ifndef _MD_MD_H

commit 2bc13b83e6298486371761de503faeffd15b7534
Author: NeilBrown <neilb@suse.com>
Date:   Fri Mar 29 10:46:17 2019 -0700

    md: batch flush requests.
    
    Currently if many flush requests are submitted to an md device is quick
    succession, they are serialized and can take a long to process them all.
    We don't really need to call flush all those times - a single flush call
    can satisfy all requests submitted before it started.
    So keep track of when the current flush started and when it finished,
    allow any pending flush that was requested before the flush started
    to complete without waiting any more.
    
    Test results from Xiao:
    
    Test is done on a raid10 device which is created by 4 SSDs. The tool is
    dbench.
    
    1. The latest linux stable kernel
      Operation                Count    AvgLat    MaxLat
      --------------------------------------------------
      Deltree                    768    10.509    78.305
      Flush                  2078376     0.013    10.094
      Close                  21787697     0.019    18.821
      LockX                    96580     0.007     3.184
      Mkdir                      384     0.008     0.062
      Rename                 1255883     0.191    23.534
      ReadX                  46495589     0.020    14.230
      WriteX                 14790591     7.123    60.706
      Unlink                 5989118     0.440    54.551
      UnlockX                  96580     0.005     2.736
      FIND_FIRST             10393845     0.042    12.079
      SET_FILE_INFORMATION   2415558     0.129    10.088
      QUERY_FILE_INFORMATION 4711725     0.005     8.462
      QUERY_PATH_INFORMATION 26883327     0.032    21.715
      QUERY_FS_INFORMATION   4929409     0.010     8.238
      NTCreateX              29660080     0.100    53.268
    
    Throughput 1034.88 MB/sec (sync open)  128 clients  128 procs
    max_latency=60.712 ms
    
    2. With patch1 "Revert "MD: fix lock contention for flush bios""
      Operation                Count    AvgLat    MaxLat
      --------------------------------------------------
      Deltree                    256     8.326    36.761
      Flush                   693291     3.974   180.269
      Close                  7266404     0.009    36.929
      LockX                    32160     0.006     0.840
      Mkdir                      128     0.008     0.021
      Rename                  418755     0.063    29.945
      ReadX                  15498708     0.007     7.216
      WriteX                 4932310    22.482   267.928
      Unlink                 1997557     0.109    47.553
      UnlockX                  32160     0.004     1.110
      FIND_FIRST             3465791     0.036     7.320
      SET_FILE_INFORMATION    805825     0.015     1.561
      QUERY_FILE_INFORMATION 1570950     0.005     2.403
      QUERY_PATH_INFORMATION 8965483     0.013    14.277
      QUERY_FS_INFORMATION   1643626     0.009     3.314
      NTCreateX              9892174     0.061    41.278
    
    Throughput 345.009 MB/sec (sync open)  128 clients  128 procs
    max_latency=267.939 m
    
    3. With patch1 and patch2
      Operation                Count    AvgLat    MaxLat
      --------------------------------------------------
      Deltree                    768     9.570    54.588
      Flush                  2061354     0.666    15.102
      Close                  21604811     0.012    25.697
      LockX                    95770     0.007     1.424
      Mkdir                      384     0.008     0.053
      Rename                 1245411     0.096    12.263
      ReadX                  46103198     0.011    12.116
      WriteX                 14667988     7.375    60.069
      Unlink                 5938936     0.173    30.905
      UnlockX                  95770     0.005     4.147
      FIND_FIRST             10306407     0.041    11.715
      SET_FILE_INFORMATION   2395987     0.048     7.640
      QUERY_FILE_INFORMATION 4672371     0.005     9.291
      QUERY_PATH_INFORMATION 26656735     0.018    19.719
      QUERY_FS_INFORMATION   4887940     0.010     7.654
      NTCreateX              29410811     0.059    28.551
    
    Throughput 1026.21 MB/sec (sync open)  128 clients  128 procs
    max_latency=60.075 ms
    
    Cc: <stable@vger.kernel.org> # v4.19+
    Tested-by: Xiao Ni <xni@redhat.com>
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 2deb84fa93f9..257cb4c9e22b 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -463,6 +463,9 @@ struct mddev {
 	 */
 	struct bio *flush_bio;
 	atomic_t flush_pending;
+	ktime_t start_flush, last_flush; /* last_flush is when the last completed
+					  * flush was started.
+					  */
 	struct work_struct flush_work;
 	struct work_struct event_work;	/* used by dm to report failure event */
 	void (*sync_super)(struct mddev *mddev, struct md_rdev *rdev);

commit 4bc034d35377196c854236133b07730a777c4aba
Author: NeilBrown <neilb@suse.com>
Date:   Fri Mar 29 10:46:16 2019 -0700

    Revert "MD: fix lock contention for flush bios"
    
    This reverts commit 5a409b4f56d50b212334f338cb8465d65550cd85.
    
    This patch has two problems.
    
    1/ it make multiple calls to submit_bio() from inside a make_request_fn.
     The bios thus submitted will be queued on current->bio_list and not
     submitted immediately.  As the bios are allocated from a mempool,
     this can theoretically result in a deadlock - all the pool of requests
     could be in various ->bio_list queues and a subsequent mempool_alloc
     could block waiting for one of them to be released.
    
    2/ It aims to handle a case when there are many concurrent flush requests.
      It handles this by submitting many requests in parallel - all of which
      are identical and so most of which do nothing useful.
      It would be more efficient to just send one lower-level request, but
      allow that to satisfy multiple upper-level requests.
    
    Fixes: 5a409b4f56d5 ("MD: fix lock contention for flush bios")
    Cc: <stable@vger.kernel.org> # v4.19+
    Tested-by: Xiao Ni <xni@redhat.com>
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index c52afb52c776..2deb84fa93f9 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -252,19 +252,6 @@ enum mddev_sb_flags {
 	MD_SB_NEED_REWRITE,	/* metadata write needs to be repeated */
 };
 
-#define NR_FLUSH_INFOS 8
-#define NR_FLUSH_BIOS 64
-struct flush_info {
-	struct bio			*bio;
-	struct mddev			*mddev;
-	struct work_struct		flush_work;
-	atomic_t			flush_pending;
-};
-struct flush_bio {
-	struct flush_info *fi;
-	struct md_rdev *rdev;
-};
-
 struct mddev {
 	void				*private;
 	struct md_personality		*pers;
@@ -470,8 +457,13 @@ struct mddev {
 						   * metadata and bitmap writes
 						   */
 
-	mempool_t			*flush_pool;
-	mempool_t			*flush_bio_pool;
+	/* Generic flush handling.
+	 * The last to finish preflush schedules a worker to submit
+	 * the rest of the request (without the REQ_PREFLUSH flag).
+	 */
+	struct bio *flush_bio;
+	atomic_t flush_pending;
+	struct work_struct flush_work;
 	struct work_struct event_work;	/* used by dm to report failure event */
 	void (*sync_super)(struct mddev *mddev, struct md_rdev *rdev);
 	struct md_cluster_info		*cluster_info;

commit 7564beda19b3646d781934d04fc382b738053e6f
Author: Guoqing Jiang <gqjiang@suse.com>
Date:   Thu Oct 18 16:37:42 2018 +0800

    md-cluster/raid10: support add disk under grow mode
    
    For clustered raid10 scenario, we need to let all the nodes
    know about that a new disk is added to the array, and the
    reshape caused by add new member just need to be happened in
    one node, but other nodes should know about the change.
    
    Since reshape means read data from somewhere (which is already
    used by array) and write data to unused region. Obviously, it
    is awful if one node is reading data from address while another
    node is writing to the same address. Considering we have
    implemented suspend writes in the resyncing area, so we can
    just broadcast the reading address to other nodes to avoid the
    trouble.
    
    For master node, it would call reshape_request then update sb
    during the reshape period. To avoid above trouble, we call
    resync_info_update to send RESYNC message in reshape_request.
    
    Then from slave node's view, it receives two type messages:
    1. RESYNCING message
    Slave node add the address (where master node reading data from)
    to suspend list.
    
    2. METADATA_UPDATED message
    Once slave nodes know the reshaping is started in master node,
    it is time to update reshape position and call start_reshape to
    follow master node's step. After reshape is done, only reshape
    position is need to be updated, so the majority task of reshaping
    is happened on the master node.
    
    Reviewed-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Guoqing Jiang <gqjiang@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 8afd6bfdbfb9..c52afb52c776 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -557,6 +557,7 @@ struct md_personality
 	int (*check_reshape) (struct mddev *mddev);
 	int (*start_reshape) (struct mddev *mddev);
 	void (*finish_reshape) (struct mddev *mddev);
+	void (*update_reshape_pos) (struct mddev *mddev);
 	/* quiesce suspends or resumes internal processing.
 	 * 1 - stop new actions and wait for action io to complete
 	 * 0 - return to normal behaviour

commit 0357ba27bd611ff496390fdb172fdb31ca475398
Author: Guoqing Jiang <gqjiang@suse.com>
Date:   Mon Jul 2 16:26:25 2018 +0800

    md-cluster: show array's status more accurate
    
    When resync or recovery is happening in one node,
    other nodes don't show the appropriate info now.
    
    For example, when create an array in master node
    without "--assume-clean", then assemble the array
    in slave nodes, you can see "resync=PENDING" when
    read /proc/mdstat in slave nodes. However, the info
    is confusing since "PENDING" status is introduced
    for start array in read-only mode.
    
    We introduce RESYNCING_REMOTE flag to indicate that
    resync thread is running in remote node. The flags
    is set when node receive RESYNCING msg. And we clear
    the REMOTE flag in following cases:
    
    1. resync or recover is finished in master node,
       which means slaves receive msg with both lo
       and hi are set to 0.
    2. node continues resync/recovery in recover_bitmaps.
    3. when resync_finish is called.
    
    Then we show accurate information in status_resync
    by check REMOTE flags and with other conditions.
    
    Signed-off-by: Guoqing Jiang <gqjiang@suse.com>
    Reviewed-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 2d148bdaba74..8afd6bfdbfb9 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -496,6 +496,7 @@ enum recovery_flags {
 	MD_RECOVERY_FROZEN,	/* User request to abort, and not restart, any action */
 	MD_RECOVERY_ERROR,	/* sync-action interrupted because io-error */
 	MD_RECOVERY_WAIT,	/* waiting for pers->start() to finish */
+	MD_RESYNCING_REMOTE,	/* remote node is running resync thread */
 };
 
 static inline int __must_check mddev_lock(struct mddev *mddev)

commit d60dafdca4b463405e5586df923f05b10e9ac2f9
Merge: 1329c20433fb 5a409b4f56d5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jun 9 12:01:36 2018 -0700

    Merge branch 'for-next' of git://git.kernel.org/pub/scm/linux/kernel/git/shli/md
    
    Pull MD updates from Shaohua Li:
     "A few fixes of MD for this merge window. Mostly bug fixes:
    
       - raid5 stripe batch fix from Amy
    
       - Read error handling for raid1 FailFast device from Gioh
    
       - raid10 recovery NULL pointer dereference fix from Guoqing
    
       - Support write hint for raid5 stripe cache from Mariusz
    
       - Fixes for device hot add/remove from Neil and Yufen
    
       - Improve flush bio scalability from Xiao"
    
    * 'for-next' of git://git.kernel.org/pub/scm/linux/kernel/git/shli/md:
      MD: fix lock contention for flush bios
      md/raid5: Assigning NULL to sh->batch_head before testing bit R5_Overlap of a stripe
      md/raid1: add error handling of read error from FailFast device
      md: fix NULL dereference of mddev->pers in remove_and_add_spares()
      raid5: copy write hint from origin bio to stripe
      md: fix two problems with setting the "re-add" device state.
      raid10: check bio in r10buf_pool_free to void NULL pointer dereference
      md: fix an error code format and remove unsed bio_sector

commit afeee514ce7f4cab605beedd03be71ebaf0c5fc8
Author: Kent Overstreet <kent.overstreet@gmail.com>
Date:   Sun May 20 18:25:52 2018 -0400

    md: convert to bioset_init()/mempool_init()
    
    Convert md to embedded bio sets.
    
    Signed-off-by: Kent Overstreet <kent.overstreet@gmail.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index fbc925cce810..3507cab22cb6 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -452,8 +452,8 @@ struct mddev {
 
 	struct attribute_group		*to_remove;
 
-	struct bio_set			*bio_set;
-	struct bio_set			*sync_set; /* for sync operations like
+	struct bio_set			bio_set;
+	struct bio_set			sync_set; /* for sync operations like
 						   * metadata and bitmap writes
 						   */
 

commit 5a409b4f56d50b212334f338cb8465d65550cd85
Author: Xiao Ni <xni@redhat.com>
Date:   Mon May 21 11:49:54 2018 +0800

    MD: fix lock contention for flush bios
    
    There is a lock contention when there are many processes which send flush bios
    to md device. eg. Create many lvs on one raid device and mkfs.xfs on each lv.
    
    Now it just can handle flush request sequentially. It needs to wait mddev->flush_bio
    to be NULL, otherwise get mddev->lock.
    
    This patch remove mddev->flush_bio and handle flush bio asynchronously.
    I did a test with command dbench -s 128 -t 300. This is the test result:
    
    =================Without the patch============================
     Operation                Count    AvgLat    MaxLat
     --------------------------------------------------
     Flush                    11165   167.595  5879.560
     Close                   107469     1.391  2231.094
     LockX                      384     0.003     0.019
     Rename                    5944     2.141  1856.001
     ReadX                   208121     0.003     0.074
     WriteX                   98259  1925.402 15204.895
     Unlink                   25198    13.264  3457.268
     UnlockX                    384     0.001     0.009
     FIND_FIRST               47111     0.012     0.076
     SET_FILE_INFORMATION     12966     0.007     0.065
     QUERY_FILE_INFORMATION   27921     0.004     0.085
     QUERY_PATH_INFORMATION  124650     0.005     5.766
     QUERY_FS_INFORMATION     22519     0.003     0.053
     NTCreateX               141086     4.291  2502.812
    
    Throughput 3.7181 MB/sec (sync open)  128 clients  128 procs  max_latency=15204.905 ms
    
    =================With the patch============================
     Operation                Count    AvgLat    MaxLat
     --------------------------------------------------
     Flush                     4500   174.134   406.398
     Close                    48195     0.060   467.062
     LockX                      256     0.003     0.029
     Rename                    2324     0.026     0.360
     ReadX                    78846     0.004     0.504
     WriteX                   66832   562.775  1467.037
     Unlink                    5516     3.665  1141.740
     UnlockX                    256     0.002     0.019
     FIND_FIRST               16428     0.015     0.313
     SET_FILE_INFORMATION      6400     0.009     0.520
     QUERY_FILE_INFORMATION   17865     0.003     0.089
     QUERY_PATH_INFORMATION   47060     0.078   416.299
     QUERY_FS_INFORMATION      7024     0.004     0.032
     NTCreateX                55921     0.854  1141.452
    
    Throughput 11.744 MB/sec (sync open)  128 clients  128 procs  max_latency=1467.041 ms
    
    The test is done on raid1 disk with two rotational disks
    
    V5: V4 is more complicated than the version with memory pool. So revert to the memory pool
    version
    
    V4: use address of fbio to do hash to choose free flush info.
    V3:
    Shaohua suggests mempool is overkill. In v3 it allocs memory during creating raid device
    and uses a simple bitmap to record which resource is free.
    
    Fix a bug from v2. It should set flush_pending to 1 at first.
    
    V2:
    Neil pointed out two problems. One is counting error problem and another is return value
    when allocat memory fails.
    1. counting error problem
    This isn't safe.  It is only safe to call rdev_dec_pending() on rdevs
    that you previously called
                              atomic_inc(&rdev->nr_pending);
    If an rdev was added to the list between the start and end of the flush,
    this will do something bad.
    
    Now it doesn't use bio_chain. It uses specified call back function for each
    flush bio.
    2. Returned on IO error when kmalloc fails is wrong.
    I use mempool suggested by Neil in V2
    3. Fixed some places pointed by Guoqing
    
    Suggested-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Xiao Ni <xni@redhat.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index fbc925cce810..ffcb1ae217fe 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -252,6 +252,19 @@ enum mddev_sb_flags {
 	MD_SB_NEED_REWRITE,	/* metadata write needs to be repeated */
 };
 
+#define NR_FLUSH_INFOS 8
+#define NR_FLUSH_BIOS 64
+struct flush_info {
+	struct bio			*bio;
+	struct mddev			*mddev;
+	struct work_struct		flush_work;
+	atomic_t			flush_pending;
+};
+struct flush_bio {
+	struct flush_info *fi;
+	struct md_rdev *rdev;
+};
+
 struct mddev {
 	void				*private;
 	struct md_personality		*pers;
@@ -457,13 +470,8 @@ struct mddev {
 						   * metadata and bitmap writes
 						   */
 
-	/* Generic flush handling.
-	 * The last to finish preflush schedules a worker to submit
-	 * the rest of the request (without the REQ_PREFLUSH flag).
-	 */
-	struct bio *flush_bio;
-	atomic_t flush_pending;
-	struct work_struct flush_work;
+	mempool_t			*flush_pool;
+	mempool_t			*flush_bio_pool;
 	struct work_struct event_work;	/* used by dm to report failure event */
 	void (*sync_super)(struct mddev *mddev, struct md_rdev *rdev);
 	struct md_cluster_info		*cluster_info;

commit 4b6c1060eaa6495aa5b0032e8f2d51dd936b1257
Author: Heinz Mauelshagen <heinzm@redhat.com>
Date:   Fri Feb 2 23:13:19 2018 +0100

    md: fix md_write_start() deadlock w/o metadata devices
    
    If no metadata devices are configured on raid1/4/5/6/10
    (e.g. via dm-raid), md_write_start() unconditionally waits
    for superblocks to be written thus deadlocking.
    
    Fix introduces mddev->has_superblocks bool, defines it in md_run()
    and checks for it in md_write_start() to conditionally avoid waiting.
    
    Once on it, check for non-existing superblocks in md_super_write().
    
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=198647
    Fixes: cc27b0c78c796 ("md: fix deadlock between mddev_suspend() and md_write_start()")
    
    Signed-off-by: Heinz Mauelshagen <heinzm@redhat.com>
    Signed-off-by: Shaohua Li <sh.li@alibaba-inc.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 58cd20a5e85e..fbc925cce810 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -468,6 +468,8 @@ struct mddev {
 	void (*sync_super)(struct mddev *mddev, struct md_rdev *rdev);
 	struct md_cluster_info		*cluster_info;
 	unsigned int			good_device_nr;	/* good device num within cluster raid */
+
+	bool	has_superblocks:1;
 };
 
 enum recovery_flags {

commit 1532d9e87e8b2377f12929f9e40724d5fbe6ecc5
Author: Tomasz Majchrzak <tomasz.majchrzak@intel.com>
Date:   Wed Dec 27 10:31:40 2017 +0100

    raid5-ppl: PPL support for disks with write-back cache enabled
    
    In order to provide data consistency with PPL for disks with write-back
    cache enabled all data has to be flushed to disks before next PPL
    entry. The disks to be flushed are marked in the bitmap. It's modified
    under a mutex and it's only read after PPL io unit is submitted.
    
    A limitation of 64 disks in the array has been introduced to keep data
    structures and implementation simple. RAID5 arrays with so many disks are
    not likely due to high risk of multiple disks failure. Such restriction
    should not be a real life limitation.
    
    With write-back cache disabled next PPL entry is submitted when data write
    for current one completes. Data flush defers next log submission so trigger
    it when there are no stripes for handling found.
    
    As PPL assures all data is flushed to disk at request completion, just
    acknowledge flush request when PPL is enabled.
    
    Signed-off-by: Tomasz Majchrzak <tomasz.majchrzak@intel.com>
    Signed-off-by: Shaohua Li <sh.li@alibaba-inc.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index be8f72a9e30b..58cd20a5e85e 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -710,6 +710,7 @@ extern void md_reload_sb(struct mddev *mddev, int raid_disk);
 extern void md_update_sb(struct mddev *mddev, int force);
 extern void md_kick_rdev_from_array(struct md_rdev * rdev);
 struct md_rdev *md_find_rdev_nr_rcu(struct mddev *mddev, int nr);
+struct md_rdev *md_find_rdev_rcu(struct mddev *mddev, dev_t dev);
 
 static inline void rdev_dec_pending(struct md_rdev *rdev, struct mddev *mddev)
 {

commit d5d885fd514fcebc9da5503c88aa0112df7514ef
Author: Song Liu <songliubraving@fb.com>
Date:   Sun Nov 19 22:17:01 2017 -0800

    md: introduce new personality funciton start()
    
    In do_md_run(), md threads should not wake up until the array is fully
    initialized in md_run(). However, in raid5_run(), raid5-cache may wake
    up mddev->thread to flush stripes that need to be written back. This
    design doesn't break badly right now. But it could lead to bad bug in
    the future.
    
    This patch tries to resolve this problem by splitting start up work
    into two personality functions, run() and start(). Tasks that do not
    require the md threads should go into run(), while task that require
    the md threads go into start().
    
    r5l_load_log() is moved to raid5_start(), so it is not called until
    the md threads are started in do_md_run().
    
    Signed-off-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 7d6bcf0eba0c..be8f72a9e30b 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -485,6 +485,7 @@ enum recovery_flags {
 	MD_RECOVERY_RESHAPE,	/* A reshape is happening */
 	MD_RECOVERY_FROZEN,	/* User request to abort, and not restart, any action */
 	MD_RECOVERY_ERROR,	/* sync-action interrupted because io-error */
+	MD_RECOVERY_WAIT,	/* waiting for pers->start() to finish */
 };
 
 static inline int __must_check mddev_lock(struct mddev *mddev)
@@ -523,7 +524,13 @@ struct md_personality
 	struct list_head list;
 	struct module *owner;
 	bool (*make_request)(struct mddev *mddev, struct bio *bio);
+	/*
+	 * start up works that do NOT require md_thread. tasks that
+	 * requires md_thread should go into start()
+	 */
 	int (*run)(struct mddev *mddev);
+	/* start up works that require md threads */
+	int (*start)(struct mddev *mddev);
 	void (*free)(struct mddev *mddev, void *priv);
 	void (*status)(struct seq_file *seq, struct mddev *mddev);
 	/* error_handler must set ->faulty and clear ->in_sync
@@ -687,6 +694,7 @@ extern int strict_strtoul_scaled(const char *cp, unsigned long *res, int scale);
 
 extern void mddev_init(struct mddev *mddev);
 extern int md_run(struct mddev *mddev);
+extern int md_start(struct mddev *mddev);
 extern void md_stop(struct mddev *mddev);
 extern void md_stop_writes(struct mddev *mddev);
 extern int md_rdev_init(struct md_rdev *rdev);

commit efa4b77b00b56138fb7e68d2fe8fd1b3c15cd503
Author: Shaohua Li <shli@fb.com>
Date:   Wed Oct 18 22:08:13 2017 -0700

    md: use lockdep_assert_held
    
    lockdep_assert_held is a better way to assert lock held, and it works
    for UP.
    
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 998b4ce1498f..7d6bcf0eba0c 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -500,11 +500,6 @@ static inline void mddev_lock_nointr(struct mddev *mddev)
 	mutex_lock(&mddev->reconfig_mutex);
 }
 
-static inline int mddev_is_locked(struct mddev *mddev)
-{
-	return mutex_is_locked(&mddev->reconfig_mutex);
-}
-
 static inline int mddev_trylock(struct mddev *mddev)
 {
 	return mutex_trylock(&mddev->reconfig_mutex);

commit b03e0ccb5ab9df3efbe51c87843a1ffbecbafa1f
Author: NeilBrown <neilb@suse.com>
Date:   Thu Oct 19 12:49:15 2017 +1100

    md: remove special meaning of ->quiesce(.., 2)
    
    The '2' argument means "wake up anything that is waiting".
    This is an inelegant part of the design and was added
    to help support management of suspend_lo/suspend_hi setting.
    Now that suspend_lo/hi is managed in mddev_suspend/resume,
    that need is gone.
    These is still a couple of places where we call 'quiesce'
    with an argument of '2', but they can safely be changed to
    call ->quiesce(.., 1); ->quiesce(.., 0) which
    achieve the same result at the small cost of pausing IO
    briefly.
    
    This removes a small "optimization" from suspend_{hi,lo}_store,
    but it isn't clear that optimization served a useful purpose.
    The code now is a lot clearer.
    
    Suggested-by: Shaohua Li <shli@kernel.org>
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 03fc641e5da1..998b4ce1498f 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -544,12 +544,11 @@ struct md_personality
 	int (*check_reshape) (struct mddev *mddev);
 	int (*start_reshape) (struct mddev *mddev);
 	void (*finish_reshape) (struct mddev *mddev);
-	/* quiesce moves between quiescence states
-	 * 0 - fully active
-	 * 1 - no new requests allowed
-	 * others - reserved
+	/* quiesce suspends or resumes internal processing.
+	 * 1 - stop new actions and wait for action io to complete
+	 * 0 - return to normal behaviour
 	 */
-	void (*quiesce) (struct mddev *mddev, int state);
+	void (*quiesce) (struct mddev *mddev, int quiesce);
 	/* takeover is used to transition an array from one
 	 * personality to another.  The new personality must be able
 	 * to handle the data in the current layout.

commit 35bfc52187f6df8779d0f1cebdb52b7f797baf4e
Author: NeilBrown <neilb@suse.com>
Date:   Tue Oct 17 13:46:43 2017 +1100

    md: allow metadata update while suspending.
    
    There are various deadlocks that can occur
    when a thread holds reconfig_mutex and calls
    ->quiesce(mddev, 1).
    As some write request block waiting for
    metadata to be updated (e.g. to record device
    failure), and as the md thread updates the metadata
    while the reconfig mutex is held, holding the mutex
    can stop write requests completing, and this prevents
    ->quiesce(mddev, 1) from completing.
    
    ->quiesce() is now usually called from mddev_suspend(),
    and it is always called with reconfig_mutex held.  So
    at this time it is safe for the thread to update metadata
    without explicitly taking the lock.
    
    So add 2 new flags, one which says the unlocked updates is
    allowed, and one which ways it is happening.  Then allow it
    while the quiesce completes, and then wait for it to finish.
    
    Reported-and-tested-by: Xiao Ni <xni@redhat.com>
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index d8287d3cd1bf..03fc641e5da1 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -237,6 +237,12 @@ enum mddev_flags {
 				 */
 	MD_HAS_PPL,		/* The raid array has PPL feature set */
 	MD_HAS_MULTIPLE_PPLS,	/* The raid array has multiple PPLs feature set */
+	MD_ALLOW_SB_UPDATE,	/* md_check_recovery is allowed to update
+				 * the metadata without taking reconfig_mutex.
+				 */
+	MD_UPDATING_SB,		/* md_check_recovery is updating the metadata
+				 * without explicitly holding reconfig_mutex.
+				 */
 };
 
 enum mddev_sb_flags {

commit 393debc23c7820211d1c8253dd6a8408a7628fe7
Author: Shaohua Li <shli@fb.com>
Date:   Thu Sep 21 10:23:35 2017 -0700

    md: separate request handling
    
    With commit cc27b0c78c79, pers->make_request could bail out without handling
    the bio. If that happens, we should retry.  The commit fixes md_make_request
    but not other call sites. Separate the request handling part, so other call
    sites can use it.
    
    Reported-by: Nate Dailey <nate.dailey@stratus.com>
    Fix: cc27b0c78c79(md: fix deadlock between mddev_suspend() and md_write_start())
    Cc: stable@vger.kernel.org
    Reviewed-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 561d22b9a9a8..d8287d3cd1bf 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -692,6 +692,7 @@ extern void md_stop_writes(struct mddev *mddev);
 extern int md_rdev_init(struct md_rdev *rdev);
 extern void md_rdev_clear(struct md_rdev *rdev);
 
+extern void md_handle_request(struct mddev *mddev, struct bio *bio);
 extern void mddev_suspend(struct mddev *mddev);
 extern void mddev_resume(struct mddev *mddev);
 extern struct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,

commit 3645e6d0dc80be4376f87acc9ee527768387c909
Merge: 15d8ffc96464 e8a27f836f16
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 7 12:41:48 2017 -0700

    Merge tag 'md/4.14-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/shli/md
    
    Pull MD updates from Shaohua Li:
     "This update mainly fixes bugs:
    
       - Make raid5 ppl support several ppl from Pawel
    
       - Several raid5-cache bug fixes from Song
    
       - Bitmap fixes from Neil and Me
    
       - One raid1/10 regression fix since 4.12 from Me
    
       - Other small fixes and cleanup"
    
    * tag 'md/4.14-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/shli/md:
      md/bitmap: disable bitmap_resize for file-backed bitmaps.
      raid5-ppl: Recovery support for multiple partial parity logs
      md: Runtime support for multiple ppls
      md/raid0: attach correct cgroup info in bio
      lib/raid6: align AVX512 constants to 512 bits, not bytes
      raid5: remove raid5_build_block
      md/r5cache: call mddev_lock/unlock() in r5c_journal_mode_show
      md: replace seq_release_private with seq_release
      md: notify about new spare disk in the container
      md/raid1/10: reset bio allocated from mempool
      md/raid5: release/flush io in raid5_do_work()
      md/bitmap: copy correct data for bitmap super

commit ddc088238cd6988bb4ac3776f403d7ff9d3c7a63
Author: Pawel Baldysiak <pawel.baldysiak@intel.com>
Date:   Wed Aug 16 17:13:45 2017 +0200

    md: Runtime support for multiple ppls
    
    Increase PPL area to 1MB and use it as circular buffer to store PPL. The
    entry with highest generation number is the latest one. If PPL to be
    written is larger then space left in a buffer, rewind the buffer to the
    start (don't wrap it).
    
    Signed-off-by: Pawel Baldysiak <pawel.baldysiak@intel.com>
    Signed-off-by: Artur Paszkiewicz <artur.paszkiewicz@intel.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 09db03455801..d4bdfa5c223b 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -236,6 +236,7 @@ enum mddev_flags {
 				 * never cause the array to become failed.
 				 */
 	MD_HAS_PPL,		/* The raid array has PPL feature set */
+	MD_HAS_MULTIPLE_PPLS,	/* The raid array has multiple PPLs feature set */
 };
 
 enum mddev_sb_flags {

commit 74d46992e0d9dee7f1f376de0d56d31614c8a17a
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Aug 23 19:10:32 2017 +0200

    block: replace bi_bdev with a gendisk pointer and partitions index
    
    This way we don't need a block_device structure to submit I/O.  The
    block_device has different life time rules from the gendisk and
    request_queue and is usually only available when the block device node
    is open.  Other callers need to explicitly create one (e.g. the lightnvm
    passthrough code, or the new nvme multipathing code).
    
    For the actual I/O path all that we need is the gendisk, which exists
    once per block device.  But given that the block layer also does
    partition remapping we additionally need a partition index, which is
    used for said remapping in generic_make_request.
    
    Note that all the block drivers generally want request_queue or
    sometimes the gendisk, so this removes a layer of indirection all
    over the stack.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 09db03455801..c0d436fb88f0 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -509,6 +509,11 @@ static inline void md_sync_acct(struct block_device *bdev, unsigned long nr_sect
 	atomic_add(nr_sectors, &bdev->bd_contains->bd_disk->sync_io);
 }
 
+static inline void md_sync_acct_bio(struct bio *bio, unsigned long nr_sectors)
+{
+	atomic_add(nr_sectors, &bio->bi_disk->sync_io);
+}
+
 struct md_personality
 {
 	char *name;
@@ -721,14 +726,14 @@ static inline void mddev_clear_unsupported_flags(struct mddev *mddev,
 static inline void mddev_check_writesame(struct mddev *mddev, struct bio *bio)
 {
 	if (bio_op(bio) == REQ_OP_WRITE_SAME &&
-	    !bdev_get_queue(bio->bi_bdev)->limits.max_write_same_sectors)
+	    !bio->bi_disk->queue->limits.max_write_same_sectors)
 		mddev->queue->limits.max_write_same_sectors = 0;
 }
 
 static inline void mddev_check_write_zeroes(struct mddev *mddev, struct bio *bio)
 {
 	if (bio_op(bio) == REQ_OP_WRITE_ZEROES &&
-	    !bdev_get_queue(bio->bi_bdev)->limits.max_write_zeroes_sectors)
+	    !bio->bi_disk->queue->limits.max_write_zeroes_sectors)
 		mddev->queue->limits.max_write_zeroes_sectors = 0;
 }
 #endif /* _MD_MD_H */

commit be453e7761d0e72d8a1b2fcfde6d1a7e53881190
Author: Ming Lei <ming.lei@redhat.com>
Date:   Fri Jul 14 16:14:44 2017 +0800

    md: raid1-10: move raid1/raid10 common code into raid1-10.c
    
    No function change, just move 'struct resync_pages' and related
    helpers into raid1-10.c
    
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 991769cc3615..09db03455801 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -731,57 +731,4 @@ static inline void mddev_check_write_zeroes(struct mddev *mddev, struct bio *bio
 	    !bdev_get_queue(bio->bi_bdev)->limits.max_write_zeroes_sectors)
 		mddev->queue->limits.max_write_zeroes_sectors = 0;
 }
-
-/* Maximum size of each resync request */
-#define RESYNC_BLOCK_SIZE (64*1024)
-#define RESYNC_PAGES ((RESYNC_BLOCK_SIZE + PAGE_SIZE-1) / PAGE_SIZE)
-
-/* for managing resync I/O pages */
-struct resync_pages {
-	void		*raid_bio;
-	struct page	*pages[RESYNC_PAGES];
-};
-
-static inline int resync_alloc_pages(struct resync_pages *rp,
-				     gfp_t gfp_flags)
-{
-	int i;
-
-	for (i = 0; i < RESYNC_PAGES; i++) {
-		rp->pages[i] = alloc_page(gfp_flags);
-		if (!rp->pages[i])
-			goto out_free;
-	}
-
-	return 0;
-
-out_free:
-	while (--i >= 0)
-		put_page(rp->pages[i]);
-	return -ENOMEM;
-}
-
-static inline void resync_free_pages(struct resync_pages *rp)
-{
-	int i;
-
-	for (i = 0; i < RESYNC_PAGES; i++)
-		put_page(rp->pages[i]);
-}
-
-static inline void resync_get_all_pages(struct resync_pages *rp)
-{
-	int i;
-
-	for (i = 0; i < RESYNC_PAGES; i++)
-		get_page(rp->pages[i]);
-}
-
-static inline struct page *resync_fetch_page(struct resync_pages *rp,
-					     unsigned idx)
-{
-	if (WARN_ON_ONCE(idx >= RESYNC_PAGES))
-		return NULL;
-	return rp->pages[idx];
-}
 #endif /* _MD_MD_H */

commit 022e510fcbda79183fd2cdc01abb01b4be80d03f
Author: Ming Lei <ming.lei@redhat.com>
Date:   Fri Jul 14 16:14:42 2017 +0800

    md: remove 'idx' from 'struct resync_pages'
    
    bio_add_page() won't fail for resync bio, and the page index for each
    bio is same, so remove it.
    
    More importantly the 'idx' of 'struct resync_pages' is initialized in
    mempool allocator function, the current way is wrong since mempool is
    only responsible for allocation, we can't use that for initialization.
    
    Suggested-by: NeilBrown <neilb@suse.com>
    Reported-by: NeilBrown <neilb@suse.com>
    Reported-and-tested-by: Patrick <dto@gmx.net>
    Fixes: f0250618361d(md: raid10: don't use bio's vec table to manage resync pages)
    Fixes: 98d30c5812c3(md: raid1: don't use bio's vec table to manage resync pages)
    Cc: stable@vger.kernel.org (4.12+)
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index b50eb4ac1b82..991769cc3615 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -738,7 +738,6 @@ static inline void mddev_check_write_zeroes(struct mddev *mddev, struct bio *bio
 
 /* for managing resync I/O pages */
 struct resync_pages {
-	unsigned	idx;	/* for get/put page from the pool */
 	void		*raid_bio;
 	struct page	*pages[RESYNC_PAGES];
 };

commit 4aaf7694f841edc96fe0f72958aabe59204b3611
Author: Guoqing Jiang <gqjiang@suse.com>
Date:   Tue Jul 4 11:20:30 2017 +0800

    md/bitmap: don't read page from device with Bitmap_sync
    
    The device owns Bitmap_sync flag needs recovery
    to become in sync, and read page from this type
    device could get stale status.
    
    Also add comments for Bitmap_sync bit per the
    suggestion from Shaohua and Neil.
    
    Previous disscussion can be found here:
    https://marc.info/?t=149760428900004&r=1&w=2
    
    Signed-off-by: Guoqing Jiang <gqjiang@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 991f0fe2dcc6..b50eb4ac1b82 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -134,7 +134,9 @@ enum flag_bits {
 	Faulty,			/* device is known to have a fault */
 	In_sync,		/* device is in_sync with rest of array */
 	Bitmap_sync,		/* ..actually, not quite In_sync.  Need a
-				 * bitmap-based recovery to get fully in sync
+				 * bitmap-based recovery to get fully in sync.
+				 * The bit is only meaningful before device
+				 * has been passed to pers->hot_add_disk.
 				 */
 	WriteMostly,		/* Avoid reading if at all possible */
 	AutoDetected,		/* added by auto-detect */

commit 5a85071c2cbcc7d8d8f764b33bf64c76e47d268d
Author: NeilBrown <neilb@suse.com>
Date:   Wed Jun 21 09:12:21 2017 +1000

    md: use a separate bio_set for synchronous IO.
    
    md devices allocate a bio_set and use it for two
    distinct purposes.
    mddev->bio_set is used to clone bios as part of sending
    upper level requests down to lower level devices,
    and it is also use for synchronous IO such as superblock
    and bitmap updates, and for correcting read errors.
    
    This multiple usage can lead to deadlocks.  It is likely
    that cloned bios might be queued for write and to be
    waiting for a metadata update before the write can be permitted.
    If the cloning exhausted mddev->bio_set, the metadata update
    may not be able to proceed.
    
    This scenario has been seen during heavy testing, with lots of IO and
    lots of memory pressure.
    
    Address this by adding a new bio_set specifically for synchronous IO.
    All synchronous IO goes directly to the underlying device and is not
    queued at the md level, so request using entries from the new
    mddev->sync_set will complete in a timely fashion.
    Requests that use mddev->bio_set will sometimes need to wait
    for synchronous IO, but will no longer risk deadlocking that iO.
    
    Also: small simplification in mddev_put(): there is no need to
    wait until the spinlock is released before calling bioset_free().
    
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 63d342d560b8..991f0fe2dcc6 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -444,6 +444,9 @@ struct mddev {
 	struct attribute_group		*to_remove;
 
 	struct bio_set			*bio_set;
+	struct bio_set			*sync_set; /* for sync operations like
+						   * metadata and bitmap writes
+						   */
 
 	/* Generic flush handling.
 	 * The last to finish preflush schedules a worker to submit

commit cc27b0c78c79680d128dbac79de0d40556d041bb
Author: NeilBrown <neilb@suse.com>
Date:   Mon Jun 5 16:49:39 2017 +1000

    md: fix deadlock between mddev_suspend() and md_write_start()
    
    If mddev_suspend() races with md_write_start() we can deadlock
    with mddev_suspend() waiting for the request that is currently
    in md_write_start() to complete the ->make_request() call,
    and md_write_start() waiting for the metadata to be updated
    to mark the array as 'dirty'.
    As metadata updates done by md_check_recovery() only happen then
    the mddev_lock() can be claimed, and as mddev_suspend() is often
    called with the lock held, these threads wait indefinitely for each
    other.
    
    We fix this by having md_write_start() abort if mddev_suspend()
    is happening, and ->make_request() aborts if md_write_start()
    aborted.
    md_make_request() can detect this abort, decrease the ->active_io
    count, and wait for mddev_suspend().
    
    Reported-by: Nix <nix@esperi.org.uk>
    Fix: 68866e425be2(MD: no sync IO while suspended)
    Cc: stable@vger.kernel.org
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 0fa1de42c42b..63d342d560b8 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -510,7 +510,7 @@ struct md_personality
 	int level;
 	struct list_head list;
 	struct module *owner;
-	void (*make_request)(struct mddev *mddev, struct bio *bio);
+	bool (*make_request)(struct mddev *mddev, struct bio *bio);
 	int (*run)(struct mddev *mddev);
 	void (*free)(struct mddev *mddev, void *priv);
 	void (*status)(struct seq_file *seq, struct mddev *mddev);
@@ -649,7 +649,7 @@ extern void md_wakeup_thread(struct md_thread *thread);
 extern void md_check_recovery(struct mddev *mddev);
 extern void md_reap_sync_thread(struct mddev *mddev);
 extern int mddev_init_writes_pending(struct mddev *mddev);
-extern void md_write_start(struct mddev *mddev, struct bio *bi);
+extern bool md_write_start(struct mddev *mddev, struct bio *bi);
 extern void md_write_inc(struct mddev *mddev, struct bio *bi);
 extern void md_write_end(struct mddev *mddev);
 extern void md_done_sync(struct mddev *mddev, int blocks, int ok);

commit a415c0f10627913793709ddb75add09d2ea334dc
Author: NeilBrown <neilb@suse.com>
Date:   Mon Jun 5 16:05:13 2017 +1000

    md: initialise ->writes_pending in personality modules.
    
    The new per-cpu counter for writes_pending is initialised in
    md_alloc(), which is not called by dm-raid.
    So dm-raid fails when md_write_start() is called.
    
    Move the initialization to the personality modules
    that need it.  This way it is always initialised when needed,
    but isn't unnecessarily initialized (requiring memory allocation)
    when the personality doesn't use writes_pending.
    
    Reported-by: Heinz Mauelshagen <heinzm@redhat.com>
    Fixes: 4ad23a976413 ("MD: use per-cpu counter for writes_pending")
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 11f15146ce51..0fa1de42c42b 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -648,6 +648,7 @@ extern void md_unregister_thread(struct md_thread **threadp);
 extern void md_wakeup_thread(struct md_thread *thread);
 extern void md_check_recovery(struct mddev *mddev);
 extern void md_reap_sync_thread(struct mddev *mddev);
+extern int mddev_init_writes_pending(struct mddev *mddev);
 extern void md_write_start(struct mddev *mddev, struct bio *bi);
 extern void md_write_inc(struct mddev *mddev, struct bio *bi);
 extern void md_write_end(struct mddev *mddev);

commit 2214c260c72b0bd94e6c1c19bf451686212025d3
Author: Artur Paszkiewicz <artur.paszkiewicz@intel.com>
Date:   Mon May 8 11:56:55 2017 +0200

    md: don't return -EAGAIN in md_allow_write for external metadata arrays
    
    This essentially reverts commit b5470dc5fc18 ("md: resolve external
    metadata handling deadlock in md_allow_write") with some adjustments.
    
    Since commit 6791875e2e53 ("md: make reconfig_mutex optional for writes
    to md sysfs files.") changing array_state to 'active' does not use
    mddev_lock() and will not cause a deadlock with md_allow_write(). This
    revert simplifies userspace tools that write to sysfs attributes like
    "stripe_cache_size" or "consistency_policy" because it removes the need
    for special handling for external metadata arrays, checking for EAGAIN
    and retrying the write.
    
    Signed-off-by: Artur Paszkiewicz <artur.paszkiewicz@intel.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 4e75d121bfcc..11f15146ce51 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -665,7 +665,7 @@ extern int sync_page_io(struct md_rdev *rdev, sector_t sector, int size,
 			bool metadata_op);
 extern void md_do_sync(struct md_thread *thread);
 extern void md_new_event(struct mddev *mddev);
-extern int md_allow_write(struct mddev *mddev);
+extern void md_allow_write(struct mddev *mddev);
 extern void md_wait_for_blocked_rdev(struct md_rdev *rdev, struct mddev *mddev);
 extern void md_set_array_sectors(struct mddev *mddev, sector_t array_sectors);
 extern int md_check_no_bitmap(struct mddev *mddev);

commit e265eb3a30543a237b2ebc4e0422ac82e55b07e4
Merge: 85724edecbdc b506335e5d2b
Author: Shaohua Li <shli@fb.com>
Date:   Mon May 1 14:09:21 2017 -0700

    Merge branch 'md-next' into md-linus

commit 3deff1a70d5901342f460f8cc36e5d0c5d51c319
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Apr 5 19:21:03 2017 +0200

    md: support REQ_OP_WRITE_ZEROES
    
    Copy & paste from the REQ_OP_WRITE_SAME code.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index dde8ecb760c8..1e76d64ce180 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -709,4 +709,11 @@ static inline void mddev_check_writesame(struct mddev *mddev, struct bio *bio)
 	    !bdev_get_queue(bio->bi_bdev)->limits.max_write_same_sectors)
 		mddev->queue->limits.max_write_same_sectors = 0;
 }
+
+static inline void mddev_check_write_zeroes(struct mddev *mddev, struct bio *bio)
+{
+	if (bio_op(bio) == REQ_OP_WRITE_ZEROES &&
+	    !bdev_get_queue(bio->bi_bdev)->limits.max_write_zeroes_sectors)
+		mddev->queue->limits.max_write_zeroes_sectors = 0;
+}
 #endif /* _MD_MD_H */

commit 513e2faa0138462ce014e1b0e226ca45c83bc6c1
Author: Ming Lei <tom.leiming@gmail.com>
Date:   Fri Mar 17 00:12:24 2017 +0800

    md: prepare for managing resync I/O pages in clean way
    
    Now resync I/O use bio's bec table to manage pages,
    this way is very hacky, and may not work any more
    once multipage bvec is introduced.
    
    So introduce helpers and new data structure for
    managing resync I/O pages more cleanly.
    
    Signed-off-by: Ming Lei <tom.leiming@gmail.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 31d2d70849b6..0418b29945e7 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -723,4 +723,54 @@ static inline void mddev_check_writesame(struct mddev *mddev, struct bio *bio)
 #define RESYNC_BLOCK_SIZE (64*1024)
 #define RESYNC_PAGES ((RESYNC_BLOCK_SIZE + PAGE_SIZE-1) / PAGE_SIZE)
 
+/* for managing resync I/O pages */
+struct resync_pages {
+	unsigned	idx;	/* for get/put page from the pool */
+	void		*raid_bio;
+	struct page	*pages[RESYNC_PAGES];
+};
+
+static inline int resync_alloc_pages(struct resync_pages *rp,
+				     gfp_t gfp_flags)
+{
+	int i;
+
+	for (i = 0; i < RESYNC_PAGES; i++) {
+		rp->pages[i] = alloc_page(gfp_flags);
+		if (!rp->pages[i])
+			goto out_free;
+	}
+
+	return 0;
+
+out_free:
+	while (--i >= 0)
+		put_page(rp->pages[i]);
+	return -ENOMEM;
+}
+
+static inline void resync_free_pages(struct resync_pages *rp)
+{
+	int i;
+
+	for (i = 0; i < RESYNC_PAGES; i++)
+		put_page(rp->pages[i]);
+}
+
+static inline void resync_get_all_pages(struct resync_pages *rp)
+{
+	int i;
+
+	for (i = 0; i < RESYNC_PAGES; i++)
+		get_page(rp->pages[i]);
+}
+
+static inline struct page *resync_fetch_page(struct resync_pages *rp,
+					     unsigned idx)
+{
+	if (WARN_ON_ONCE(idx >= RESYNC_PAGES))
+		return NULL;
+	return rp->pages[idx];
+}
+
 #endif /* _MD_MD_H */

commit d8e29fbc3bed181f2653fb89ac8c34e40db39c30
Author: Ming Lei <tom.leiming@gmail.com>
Date:   Fri Mar 17 00:12:23 2017 +0800

    md: move two macros into md.h
    
    Both raid1 and raid10 share common resync
    block size and page count, so move them into md.h.
    
    Signed-off-by: Ming Lei <tom.leiming@gmail.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 7a7847d1cc39..31d2d70849b6 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -718,4 +718,9 @@ static inline void mddev_check_writesame(struct mddev *mddev, struct bio *bio)
 	    !bdev_get_queue(bio->bi_bdev)->limits.max_write_same_sectors)
 		mddev->queue->limits.max_write_same_sectors = 0;
 }
+
+/* Maximum size of each resync request */
+#define RESYNC_BLOCK_SIZE (64*1024)
+#define RESYNC_PAGES ((RESYNC_BLOCK_SIZE + PAGE_SIZE-1) / PAGE_SIZE)
+
 #endif /* _MD_MD_H */

commit 4ad23a976413aa57fe5ba7a25953dc35ccca5b71
Author: NeilBrown <neilb@suse.com>
Date:   Wed Mar 15 14:05:14 2017 +1100

    MD: use per-cpu counter for writes_pending
    
    The 'writes_pending' counter is used to determine when the
    array is stable so that it can be marked in the superblock
    as "Clean".  Consequently it needs to be updated frequently
    but only checked for zero occasionally.  Recent changes to
    raid5 cause the count to be updated even more often - once
    per 4K rather than once per bio.  This provided
    justification for making the updates more efficient.
    
    So we replace the atomic counter a percpu-refcount.
    This can be incremented and decremented cheaply most of the
    time, and can be switched to "atomic" mode when more
    precise counting is needed.  As it is possible for multiple
    threads to want a precise count, we introduce a
    "sync_checker" counter to count the number of threads
    in "set_in_sync()", and only switch the refcount back
    to percpu mode when that is zero.
    
    We need to be careful about races between set_in_sync()
    setting ->in_sync to 1, and md_write_start() setting it
    to zero.  md_write_start() holds the rcu_read_lock()
    while checking if the refcount is in percpu mode.  If
    it is, then we know a switch to 'atomic' will not happen until
    after we call rcu_read_unlock(), in which case set_in_sync()
    will see the elevated count, and not set in_sync to 1.
    If it is not in percpu mode, we take the mddev->lock to
    ensure proper synchronization.
    
    It is no longer possible to quickly check if the count is zero, which
    we previously did to update a timer or to schedule the md_thread.
    So now we do these every time we decrement that counter, but make
    sure they are fast.
    
    mod_timer() already optimizes the case where the timeout value doesn't
    actually change.  We leverage that further by always rounding off the
    jiffies to the timeout value.  This may delay the marking of 'clean'
    slightly, but ensure we only perform atomic operation here when absolutely
    needed.
    
    md_wakeup_thread() current always calls wake_up(), even if
    THREAD_WAKEUP is already set.  That too can be optimised to avoid
    calls to wake_up().
    
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 0cd12721a536..7a7847d1cc39 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -409,7 +409,8 @@ struct mddev {
 							 */
 	unsigned int			safemode_delay;
 	struct timer_list		safemode_timer;
-	atomic_t			writes_pending;
+	struct percpu_ref		writes_pending;
+	int				sync_checkers;	/* # of threads checking writes_pending */
 	struct request_queue		*queue;	/* for plugging ... */
 
 	struct bitmap			*bitmap; /* the bitmap for the device */

commit 497280509f32340d90feac030bce18006a3e3605
Author: NeilBrown <neilb@suse.com>
Date:   Wed Mar 15 14:05:12 2017 +1100

    md/raid5: use md_write_start to count stripes, not bios
    
    We use md_write_start() to increase the count of pending writes, and
    md_write_end() to decrement the count.  We currently count bios
    submitted to md/raid5.  Change it count stripe_heads that a WRITE bio
    has been attached to.
    
    So now, raid5_make_request() calls md_write_start() and then
    md_write_end() to keep the count elevated during the setup of the
    request.
    
    add_stripe_bio() calls md_write_start() for each stripe_head, and the
    completion routines always call md_write_end(), instead of only
    calling it when raid5_dec_bi_active_stripes() returns 0.
    make_discard_request also calls md_write_start/end().
    
    The parallel between md_write_{start,end} and use of bi_phys_segments
    can be seen in that:
     Whenever we set bi_phys_segments to 1, we now call md_write_start.
     Whenever we increment it on non-read requests with
       raid5_inc_bi_active_stripes(), we now call md_write_start().
     Whenever we decrement bi_phys_segments on non-read requsts with
        raid5_dec_bi_active_stripes(), we now call md_write_end().
    
    This reduces our dependence on keeping a per-bio count of active
    stripes in bi_phys_segments.
    
    md_write_inc() is added which parallels md_write_start(), but requires
    that a write has already been started, and is certain never to sleep.
    This can be used inside a spinlocked region when adding to a write
    request.
    
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index e0940064c3ec..0cd12721a536 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -648,6 +648,7 @@ extern void md_wakeup_thread(struct md_thread *thread);
 extern void md_check_recovery(struct mddev *mddev);
 extern void md_reap_sync_thread(struct mddev *mddev);
 extern void md_write_start(struct mddev *mddev, struct bio *bi);
+extern void md_write_inc(struct mddev *mddev, struct bio *bi);
 extern void md_write_end(struct mddev *mddev);
 extern void md_done_sync(struct mddev *mddev, int blocks, int ok);
 extern void md_error(struct mddev *mddev, struct md_rdev *rdev);

commit ba903a3ea465bd2f2bb9316054b295e79a7a518e
Author: Artur Paszkiewicz <artur.paszkiewicz@intel.com>
Date:   Thu Mar 9 10:00:03 2017 +0100

    raid5-ppl: runtime PPL enabling or disabling
    
    Allow writing to 'consistency_policy' attribute when the array is
    active. Add a new function 'change_consistency_policy' to the
    md_personality operations structure to handle the change in the
    personality code. Values "ppl" and "resync" are accepted and
    turn PPL on and off respectively.
    
    When enabling PPL its location and size should first be set using
    'ppl_sector' and 'ppl_size' attributes and a valid PPL header should be
    written at this location on each member device.
    
    Enabling or disabling PPL is performed under a suspended array.  The
    raid5_reset_stripe_cache function frees the stripe cache and allocates
    it again in order to allocate or free the ppl_pages for the stripes in
    the stripe cache.
    
    Signed-off-by: Artur Paszkiewicz <artur.paszkiewicz@intel.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index a7b2f16452c4..e0940064c3ec 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -545,6 +545,8 @@ struct md_personality
 	/* congested implements bdi.congested_fn().
 	 * Will not be called while array is 'suspended' */
 	int (*congested)(struct mddev *mddev, int bits);
+	/* Changes the consistency policy of an active array. */
+	int (*change_consistency_policy)(struct mddev *mddev, const char *buf);
 };
 
 struct md_sysfs_entry {

commit ea0213e0c7cc1c1b52badf27bd7db4f50a67baaa
Author: Artur Paszkiewicz <artur.paszkiewicz@intel.com>
Date:   Thu Mar 9 09:59:57 2017 +0100

    md: superblock changes for PPL
    
    Include information about PPL location and size into mdp_superblock_1
    and copy it to/from rdev. Because PPL is mutually exclusive with bitmap,
    put it in place of 'bitmap_offset'. Add a new flag MD_FEATURE_PPL for
    'feature_map', analogically to MD_FEATURE_BITMAP_OFFSET. Add MD_HAS_PPL
    to mddev->flags to indicate that PPL is enabled on an array.
    
    Signed-off-by: Artur Paszkiewicz <artur.paszkiewicz@intel.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 1c00160b09f9..a7b2f16452c4 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -122,6 +122,13 @@ struct md_rdev {
 					   * sysfs entry */
 
 	struct badblocks badblocks;
+
+	struct {
+		short offset;	/* Offset from superblock to start of PPL.
+				 * Not used by external metadata. */
+		unsigned int size;	/* Size in sectors of the PPL space */
+		sector_t sector;	/* First sector of the PPL space */
+	} ppl;
 };
 enum flag_bits {
 	Faulty,			/* device is known to have a fault */
@@ -226,6 +233,7 @@ enum mddev_flags {
 				 * supported as calls to md_error() will
 				 * never cause the array to become failed.
 				 */
+	MD_HAS_PPL,		/* The raid array has PPL feature set */
 };
 
 enum mddev_sb_flags {

commit 0ba959774e93911caff596de6391f085fb640ac4
Author: Guoqing Jiang <gqjiang@suse.com>
Date:   Wed Mar 1 17:30:29 2017 +0800

    md-cluster: use sync way to handle METADATA_UPDATED msg
    
    Previously, when node received METADATA_UPDATED msg, it just
    need to wakeup mddev->thread, then md_reload_sb will be called
    eventually.
    
    We taken the asynchronous way to avoid a deadlock issue, the
    deadlock issue could happen when one node is receiving the
    METADATA_UPDATED msg (wants reconfig_mutex) and trying to run
    the path:
    
    md_check_recovery -> mddev_trylock(hold reconfig_mutex)
                      -> md_update_sb-metadata_update_start
                         (want EX on token however token is
                          got by the sending node)
    
    Since we will support resizing for clustered raid, and we
    need the metadata update handling to be synchronous so that
    the initiating node can detect failure, so we need to change
    the way for handling METADATA_UPDATED msg.
    
    But, we obviously need to avoid above deadlock with the
    sync way. To make this happen, we considered to not hold
    reconfig_mutex to call md_reload_sb, if some other thread
    has already taken reconfig_mutex and waiting for the 'token',
    then process_recvd_msg() can safely call md_reload_sb()
    without taking the mutex. This is because we can be certain
    that no other thread will take the mutex, and we also certain
    that the actions performed by md_reload_sb() won't interfere
    with anything that the other thread is in the middle of.
    
    To make this more concrete, we added a new cinfo->state bit
            MD_CLUSTER_HOLDING_MUTEX_FOR_RECVD
    
    Which is set in lock_token() just before dlm_lock_sync() is
    called, and cleared just after. As lock_token() is always
    called with reconfig_mutex() held (the specific case is the
    resync_info_update which is distinguished well in previous
    patch), if process_recvd_msg() finds that the new bit is set,
    then the mutex must be held by some other thread, and it will
    keep waiting.
    
    So process_metadata_update() can call md_reload_sb() if either
    mddev_trylock() succeeds, or if MD_CLUSTER_HOLDING_MUTEX_FOR_RECVD
    is set. The tricky bit is what to do if neither of these apply.
    We need to wait. Fortunately mddev_unlock() always calls wake_up()
    on mddev->thread->wqueue. So we can get lock_token() to call
    wake_up() on that when it sets the bit.
    
    There are also some related changes inside this commit:
    1. remove RELOAD_SB related codes since there are not valid anymore.
    2. mddev is added into md_cluster_info then we can get mddev inside
       lock_token.
    3. add new parameter for lock_token to distinguish reconfig_mutex
       is held or not.
    
    And, we need to set MD_CLUSTER_HOLDING_MUTEX_FOR_RECVD in below:
    1. set it before unregister thread, otherwise a deadlock could
       appear if stop a resyncing array.
       This is because md_unregister_thread(&cinfo->recv_thread) is
       blocked by recv_daemon -> process_recvd_msg
                              -> process_metadata_update.
       To resolve the issue, MD_CLUSTER_HOLDING_MUTEX_FOR_RECVD is
       also need to be set before unregister thread.
    2. set it in metadata_update_start to fix another deadlock.
            a. Node A sends METADATA_UPDATED msg (held Token lock).
            b. Node B wants to do resync, and is blocked since it can't
               get Token lock, but MD_CLUSTER_HOLDING_MUTEX_FOR_RECVD is
               not set since the callchain
               (md_do_sync -> sync_request
                           -> resync_info_update
                           -> sendmsg
                           -> lock_comm -> lock_token)
               doesn't hold reconfig_mutex.
            c. Node B trys to update sb (held reconfig_mutex), but stopped
               at wait_event() in metadata_update_start since we have set
               MD_CLUSTER_SEND_LOCK flag in lock_comm (step 2).
            d. Then Node B receives METADATA_UPDATED msg from A, of course
               recv_daemon is blocked forever.
       Since metadata_update_start always calls lock_token with reconfig_mutex,
       we need to set MD_CLUSTER_HOLDING_MUTEX_FOR_RECVD here as well, and
       lock_token don't need to set it twice unless lock_token is invoked from
       lock_comm.
    
    Finally, thanks to Neil for his great idea and help!
    
    Reviewed-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Guoqing Jiang <gqjiang@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index dde8ecb760c8..1c00160b09f9 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -219,9 +219,6 @@ enum mddev_flags {
 				 * it then */
 	MD_JOURNAL_CLEAN,	/* A raid with journal is already clean */
 	MD_HAS_JOURNAL,		/* The raid array has journal feature set */
-	MD_RELOAD_SB,		/* Reload the superblock because another node
-				 * updated it.
-				 */
 	MD_CLUSTER_RESYNC_LOCKED, /* cluster raid only, which means node
 				   * already took resync lock, need to
 				   * release the lock */

commit 99b3d74ec05c4a4c57766a90d65b53d78ab06404
Author: Shaohua Li <shli@fb.com>
Date:   Thu Feb 23 12:31:10 2017 -0800

    md: delete dead code
    
    Nobody is using mddev_check_plugged(), so delete the dead code
    
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index b8859cbf84b6..dde8ecb760c8 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -676,16 +676,10 @@ extern void mddev_resume(struct mddev *mddev);
 extern struct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,
 				   struct mddev *mddev);
 
-extern void md_unplug(struct blk_plug_cb *cb, bool from_schedule);
 extern void md_reload_sb(struct mddev *mddev, int raid_disk);
 extern void md_update_sb(struct mddev *mddev, int force);
 extern void md_kick_rdev_from_array(struct md_rdev * rdev);
 struct md_rdev *md_find_rdev_nr_rcu(struct mddev *mddev, int nr);
-static inline int mddev_check_plugged(struct mddev *mddev)
-{
-	return !!blk_check_plugged(md_unplug, mddev,
-				   sizeof(struct blk_plug_cb));
-}
 
 static inline void rdev_dec_pending(struct md_rdev *rdev, struct mddev *mddev)
 {

commit d7a1030839d35c04a620e841f406b9b2a8600041
Author: Ming Lei <tom.leiming@gmail.com>
Date:   Tue Feb 14 23:29:03 2017 +0800

    md: fast clone bio in bio_clone_mddev()
    
    Firstly bio_clone_mddev() is used in raid normal I/O and isn't
    in resync I/O path.
    
    Secondly all the direct access to bvec table in raid happens on
    resync I/O except for write behind of raid1, in which we still
    use bio_clone() for allocating new bvec table.
    
    So this patch replaces bio_clone() with bio_clone_fast()
    in bio_clone_mddev().
    
    Also kill bio_clone_mddev() and call bio_clone_fast() directly, as
    suggested by Christoph Hellwig.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Ming Lei <tom.leiming@gmail.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 42f8398181a8..b8859cbf84b6 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -673,8 +673,6 @@ extern void md_rdev_clear(struct md_rdev *rdev);
 
 extern void mddev_suspend(struct mddev *mddev);
 extern void mddev_resume(struct mddev *mddev);
-extern struct bio *bio_clone_mddev(struct bio *bio, gfp_t gfp_mask,
-				   struct mddev *mddev);
 extern struct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,
 				   struct mddev *mddev);
 

commit 26483819f89c5cf9d27620d70c95afeeeb9bece5
Author: Shaohua Li <shli@fb.com>
Date:   Mon Feb 13 16:21:49 2017 -0800

    md: disable WRITE SAME if it fails in underlayer disks
    
    This makes md do the same thing as dm for write same IO failure. Please
    see 7eee4ae(dm: disable WRITE SAME if it fails) for details why we need
    this.
    
    We did a little bit different than dm. Instead of disabling writesame in
    the first IO error, we disable it till next writesame IO coming after
    the first IO error. This way we don't need to clone a bio.
    
    Also reported here: https://bugzilla.kernel.org/show_bug.cgi?id=118581
    
    Suggested-by: NeilBrown <neilb@suse.com>
    Acked-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 2a514036a83d..42f8398181a8 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -710,4 +710,11 @@ static inline void mddev_clear_unsupported_flags(struct mddev *mddev,
 {
 	mddev->flags &= ~unsupported_flags;
 }
+
+static inline void mddev_check_writesame(struct mddev *mddev, struct bio *bio)
+{
+	if (bio_op(bio) == REQ_OP_WRITE_SAME &&
+	    !bdev_get_queue(bio->bi_bdev)->limits.max_write_same_sectors)
+		mddev->queue->limits.max_write_same_sectors = 0;
+}
 #endif /* _MD_MD_H */

commit 394ed8e4743b0cfc5496fe49059fbfc2bc8eae35
Author: Shaohua Li <shli@fb.com>
Date:   Wed Jan 4 16:10:19 2017 -0800

    md: cleanup mddev flag clear for takeover
    
    Commit 6995f0b (md: takeover should clear unrelated bits) clear
    unrelated bits, but it's quite fragile. To avoid error in the future,
    define a macro for unsupported mddev flags for each raid type and use it
    to clear unsupported mddev flags. This should be less error-prone.
    
    Suggested-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index e38936d05df1..2a514036a83d 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -212,6 +212,7 @@ extern int rdev_clear_badblocks(struct md_rdev *rdev, sector_t s, int sectors,
 				int is_new);
 struct md_cluster_info;
 
+/* change UNSUPPORTED_MDDEV_FLAGS for each array type if new flag is added */
 enum mddev_flags {
 	MD_ARRAY_FIRST_USE,	/* First use of array, needs initialization */
 	MD_CLOSING,		/* If set, we are closing the array, do not open
@@ -702,4 +703,11 @@ static inline int mddev_is_clustered(struct mddev *mddev)
 {
 	return mddev->cluster_info && mddev->bitmap_info.nodes > 1;
 }
+
+/* clear unsupported mddev_flags */
+static inline void mddev_clear_unsupported_flags(struct mddev *mddev,
+	unsigned long unsupported_flags)
+{
+	mddev->flags &= ~unsupported_flags;
+}
 #endif /* _MD_MD_H */

commit 2953079c692da067aeb6345659875b97378f9b0a
Author: Shaohua Li <shli@fb.com>
Date:   Thu Dec 8 15:48:19 2016 -0800

    md: separate flags for superblock changes
    
    The mddev->flags are used for different purposes. There are a lot of
    places we check/change the flags without masking unrelated flags, we
    could check/change unrelated flags. These usage are most for superblock
    write, so spearate superblock related flags. This should make the code
    clearer and also fix real bugs.
    
    Reviewed-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 5c08f84101fa..e38936d05df1 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -213,9 +213,6 @@ extern int rdev_clear_badblocks(struct md_rdev *rdev, sector_t s, int sectors,
 struct md_cluster_info;
 
 enum mddev_flags {
-	MD_CHANGE_DEVS,		/* Some device status has changed */
-	MD_CHANGE_CLEAN,	/* transition to or from 'clean' */
-	MD_CHANGE_PENDING,	/* switch from 'clean' to 'active' in progress */
 	MD_ARRAY_FIRST_USE,	/* First use of array, needs initialization */
 	MD_CLOSING,		/* If set, we are closing the array, do not open
 				 * it then */
@@ -231,11 +228,15 @@ enum mddev_flags {
 				 * supported as calls to md_error() will
 				 * never cause the array to become failed.
 				 */
-	MD_NEED_REWRITE,	/* metadata write needs to be repeated */
 };
-#define MD_UPDATE_SB_FLAGS (BIT(MD_CHANGE_DEVS) | \
-			    BIT(MD_CHANGE_CLEAN) | \
-			    BIT(MD_CHANGE_PENDING))	/* If these are set, md_update_sb needed */
+
+enum mddev_sb_flags {
+	MD_SB_CHANGE_DEVS,		/* Some device status has changed */
+	MD_SB_CHANGE_CLEAN,	/* transition to or from 'clean' */
+	MD_SB_CHANGE_PENDING,	/* switch from 'clean' to 'active' in progress */
+	MD_SB_NEED_REWRITE,	/* metadata write needs to be repeated */
+};
+
 struct mddev {
 	void				*private;
 	struct md_personality		*pers;
@@ -243,6 +244,7 @@ struct mddev {
 	int				md_minor;
 	struct list_head		disks;
 	unsigned long			flags;
+	unsigned long			sb_flags;
 
 	int				suspended;
 	atomic_t			active_io;

commit 46533ff7fefb7e9e3539494f5873b00091caa8eb
Author: NeilBrown <neilb@suse.com>
Date:   Fri Nov 18 16:16:11 2016 +1100

    md: Use REQ_FAILFAST_* on metadata writes where appropriate
    
    This can only be supported on personalities which ensure
    that md_error() never causes an array to enter the 'failed'
    state.  i.e. if marking a device Faulty would cause some
    data to be inaccessible, the device is status is left as
    non-Faulty.  This is true for RAID1 and RAID10.
    
    If we get a failure writing metadata but the device doesn't
    fail, it must be the last device so we re-write without
    FAILFAST to improve chance of success.  We also flag the
    device as LastDev so that future metadata updates don't
    waste time on failfast writes.
    
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index bc6712ef8c81..5c08f84101fa 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -29,6 +29,16 @@
 
 #define MaxSector (~(sector_t)0)
 
+/*
+ * These flags should really be called "NO_RETRY" rather than
+ * "FAILFAST" because they don't make any promise about time lapse,
+ * only about the number of retries, which will be zero.
+ * REQ_FAILFAST_DRIVER is not included because
+ * Commit: 4a27446f3e39 ("[SCSI] modify scsi to handle new fail fast flags.")
+ * seems to suggest that the errors it avoids retrying should usually
+ * be retried.
+ */
+#define	MD_FAILFAST	(REQ_FAILFAST_DEV | REQ_FAILFAST_TRANSPORT)
 /*
  * MD's 'extended' device
  */
@@ -177,6 +187,10 @@ enum flag_bits {
 				 * It is expects that no bad block log
 				 * is present.
 				 */
+	LastDev,		/* Seems to be the last working dev as
+				 * it didn't fail, so don't use FailFast
+				 * any more for metadata
+				 */
 };
 
 static inline int is_badblock(struct md_rdev *rdev, sector_t s, int sectors,
@@ -213,6 +227,11 @@ enum mddev_flags {
 	MD_CLUSTER_RESYNC_LOCKED, /* cluster raid only, which means node
 				   * already took resync lock, need to
 				   * release the lock */
+	MD_FAILFAST_SUPPORTED,	/* Using MD_FAILFAST on metadata writes is
+				 * supported as calls to md_error() will
+				 * never cause the array to become failed.
+				 */
+	MD_NEED_REWRITE,	/* metadata write needs to be repeated */
 };
 #define MD_UPDATE_SB_FLAGS (BIT(MD_CHANGE_DEVS) | \
 			    BIT(MD_CHANGE_CLEAN) | \
@@ -628,7 +647,7 @@ extern int mddev_congested(struct mddev *mddev, int bits);
 extern void md_flush_request(struct mddev *mddev, struct bio *bio);
 extern void md_super_write(struct mddev *mddev, struct md_rdev *rdev,
 			   sector_t sector, int size, struct page *page);
-extern void md_super_wait(struct mddev *mddev);
+extern int md_super_wait(struct mddev *mddev);
 extern int sync_page_io(struct md_rdev *rdev, sector_t sector, int size,
 			struct page *page, int op, int op_flags,
 			bool metadata_op);

commit 688834e6ae6b21e3d98b5cf2586aa4a9b515c3a0
Author: NeilBrown <neilb@suse.com>
Date:   Fri Nov 18 16:16:11 2016 +1100

    md/failfast: add failfast flag for md to be used by some personalities.
    
    This patch just adds a 'failfast' per-device flag which can be stored
    in v0.90 or v1.x metadata.
    The flag is not used yet but the intent is that it can be used for
    mirrored (raid1/raid10) arrays where low latency is more important
    than keeping all devices on-line.
    
    Setting the flag for a device effectively gives permission for that
    device to be marked as Faulty and excluded from the array on the first
    error.  The underlying driver will be directed not to retry requests
    that result in failures.  There is a proviso that the device must not
    be marked faulty if that would cause the array as a whole to fail, it
    may only be marked Faulty if the array remains functional, but is
    degraded.
    
    Failures on read requests will cause the device to be marked
    as Faulty immediately so that further reads will avoid that
    device.  No attempt will be made to correct read errors by
    over-writing with the correct data.
    
    It is expected that if transient errors, such as cable unplug, are
    possible, then something in user-space will revalidate failed
    devices and re-add them when they appear to be working again.
    
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index af6b33c30d2d..bc6712ef8c81 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -171,6 +171,12 @@ enum flag_bits {
 	ExternalBbl,            /* External metadata provides bad
 				 * block management for a disk
 				 */
+	FailFast,		/* Minimal retries should be attempted on
+				 * this device, so use REQ_FAILFAST_DEV.
+				 * Also don't try to repair failed reads.
+				 * It is expects that no bad block log
+				 * is present.
+				 */
 };
 
 static inline int is_badblock(struct md_rdev *rdev, sector_t s, int sectors,

commit be306c2989804ca5b90388df66fd3cf28ec74967
Author: NeilBrown <neilb@suse.com>
Date:   Wed Nov 9 10:21:33 2016 +1100

    md: define mddev flags, recovery flags and r1bio state bits using enums
    
    This is less error prone than using individual #defines.
    
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 21bd94fad96a..af6b33c30d2d 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -192,6 +192,25 @@ extern int rdev_clear_badblocks(struct md_rdev *rdev, sector_t s, int sectors,
 				int is_new);
 struct md_cluster_info;
 
+enum mddev_flags {
+	MD_CHANGE_DEVS,		/* Some device status has changed */
+	MD_CHANGE_CLEAN,	/* transition to or from 'clean' */
+	MD_CHANGE_PENDING,	/* switch from 'clean' to 'active' in progress */
+	MD_ARRAY_FIRST_USE,	/* First use of array, needs initialization */
+	MD_CLOSING,		/* If set, we are closing the array, do not open
+				 * it then */
+	MD_JOURNAL_CLEAN,	/* A raid with journal is already clean */
+	MD_HAS_JOURNAL,		/* The raid array has journal feature set */
+	MD_RELOAD_SB,		/* Reload the superblock because another node
+				 * updated it.
+				 */
+	MD_CLUSTER_RESYNC_LOCKED, /* cluster raid only, which means node
+				   * already took resync lock, need to
+				   * release the lock */
+};
+#define MD_UPDATE_SB_FLAGS (BIT(MD_CHANGE_DEVS) | \
+			    BIT(MD_CHANGE_CLEAN) | \
+			    BIT(MD_CHANGE_PENDING))	/* If these are set, md_update_sb needed */
 struct mddev {
 	void				*private;
 	struct md_personality		*pers;
@@ -199,21 +218,6 @@ struct mddev {
 	int				md_minor;
 	struct list_head		disks;
 	unsigned long			flags;
-#define MD_CHANGE_DEVS	0	/* Some device status has changed */
-#define MD_CHANGE_CLEAN 1	/* transition to or from 'clean' */
-#define MD_CHANGE_PENDING 2	/* switch from 'clean' to 'active' in progress */
-#define MD_UPDATE_SB_FLAGS (1 | 2 | 4)	/* If these are set, md_update_sb needed */
-#define MD_ARRAY_FIRST_USE 3    /* First use of array, needs initialization */
-#define MD_CLOSING	4	/* If set, we are closing the array, do not open
-				 * it then */
-#define MD_JOURNAL_CLEAN 5	/* A raid with journal is already clean */
-#define MD_HAS_JOURNAL	6	/* The raid array has journal feature set */
-#define MD_RELOAD_SB	7	/* Reload the superblock because another node
-				 * updated it.
-				 */
-#define MD_CLUSTER_RESYNC_LOCKED 8 /* cluster raid only, which means node
-				    * already took resync lock, need to
-				    * release the lock */
 
 	int				suspended;
 	atomic_t			active_io;
@@ -307,31 +311,6 @@ struct mddev {
 	int				parallel_resync;
 
 	int				ok_start_degraded;
-	/* recovery/resync flags
-	 * NEEDED:   we might need to start a resync/recover
-	 * RUNNING:  a thread is running, or about to be started
-	 * SYNC:     actually doing a resync, not a recovery
-	 * RECOVER:  doing recovery, or need to try it.
-	 * INTR:     resync needs to be aborted for some reason
-	 * DONE:     thread is done and is waiting to be reaped
-	 * REQUEST:  user-space has requested a sync (used with SYNC)
-	 * CHECK:    user-space request for check-only, no repair
-	 * RESHAPE:  A reshape is happening
-	 * ERROR:    sync-action interrupted because io-error
-	 *
-	 * If neither SYNC or RESHAPE are set, then it is a recovery.
-	 */
-#define	MD_RECOVERY_RUNNING	0
-#define	MD_RECOVERY_SYNC	1
-#define	MD_RECOVERY_RECOVER	2
-#define	MD_RECOVERY_INTR	3
-#define	MD_RECOVERY_DONE	4
-#define	MD_RECOVERY_NEEDED	5
-#define	MD_RECOVERY_REQUESTED	6
-#define	MD_RECOVERY_CHECK	7
-#define MD_RECOVERY_RESHAPE	8
-#define	MD_RECOVERY_FROZEN	9
-#define	MD_RECOVERY_ERROR	10
 
 	unsigned long			recovery;
 	/* If a RAID personality determines that recovery (of a particular
@@ -445,6 +424,23 @@ struct mddev {
 	unsigned int			good_device_nr;	/* good device num within cluster raid */
 };
 
+enum recovery_flags {
+	/*
+	 * If neither SYNC or RESHAPE are set, then it is a recovery.
+	 */
+	MD_RECOVERY_RUNNING,	/* a thread is running, or about to be started */
+	MD_RECOVERY_SYNC,	/* actually doing a resync, not a recovery */
+	MD_RECOVERY_RECOVER,	/* doing recovery, or need to try it. */
+	MD_RECOVERY_INTR,	/* resync needs to be aborted for some reason */
+	MD_RECOVERY_DONE,	/* thread is done and is waiting to be reaped */
+	MD_RECOVERY_NEEDED,	/* we might need to start a resync/recover */
+	MD_RECOVERY_REQUESTED,	/* user-space has requested a sync (used with SYNC) */
+	MD_RECOVERY_CHECK,	/* user-space request for check-only, no repair */
+	MD_RECOVERY_RESHAPE,	/* A reshape is happening */
+	MD_RECOVERY_FROZEN,	/* User request to abort, and not restart, any action */
+	MD_RECOVERY_ERROR,	/* sync-action interrupted because io-error */
+};
+
 static inline int __must_check mddev_lock(struct mddev *mddev)
 {
 	return mutex_lock_interruptible(&mddev->reconfig_mutex);

commit 35b785f7691aa82c4b0b262392439cfa6f22816d
Author: Tomasz Majchrzak <tomasz.majchrzak@intel.com>
Date:   Fri Oct 21 16:26:57 2016 +0200

    md: add bad block support for external metadata
    
    Add new rdev flag which external metadata handler can use to switch
    on/off bad block support. If new bad block is encountered, notify it via
    rdev 'unacknowledged_bad_blocks' sysfs file. If bad block has been
    cleared, notify update to rdev 'bad_blocks' sysfs file.
    
    When bad blocks support is being removed, just clear rdev flag. It is
    not necessary to reset badblocks->shift field. If there are bad blocks
    cleared or added at the same time, it is ok for those changes to be
    applied to the structure. The array is in blocked state and the drive
    which cannot handle bad blocks any more will be removed from the array
    before it is unlocked.
    
    Simplify state_show function by adding a separator at the end of each
    string and overwrite last separator with new line.
    
    Signed-off-by: Tomasz Majchrzak <tomasz.majchrzak@intel.com>
    Reviewed-by: Artur Paszkiewicz <artur.paszkiewicz@intel.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 2b2041773e79..21bd94fad96a 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -168,6 +168,9 @@ enum flag_bits {
 				 * so it is safe to remove without
 				 * another synchronize_rcu() call.
 				 */
+	ExternalBbl,            /* External metadata provides bad
+				 * block management for a disk
+				 */
 };
 
 static inline int is_badblock(struct md_rdev *rdev, sector_t s, int sectors,

commit af8d8e6f031589ccf32b08eea91def53db8cfa95
Author: Guoqing Jiang <gqjiang@suse.com>
Date:   Fri Aug 12 13:42:37 2016 +0800

    md: changes for MD_STILL_CLOSED flag
    
    When stop clustered raid while it is pending on resync,
    MD_STILL_CLOSED flag could be cleared since udev rule
    is triggered to open the mddev. So obviously array can't
    be stopped soon and returns EBUSY.
    
            mdadm -Ss          md-raid-arrays.rules
      set MD_STILL_CLOSED          md_open()
            ... ... ...          clear MD_STILL_CLOSED
            do_md_stop
    
    We make below changes to resolve this issue:
    
    1. rename MD_STILL_CLOSED to MD_CLOSING since it is set
       when stop array and it means we are stopping array.
    2. let md_open returns early if CLOSING is set, so no
       other threads will open array if one thread is trying
       to close it.
    3. no need to clear CLOSING bit in md_open because 1 has
       ensure the bit is cleared, then we also don't need to
       test CLOSING bit in do_md_stop.
    
    Reviewed-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Guoqing Jiang <gqjiang@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 20c667579ede..2b2041773e79 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -201,9 +201,8 @@ struct mddev {
 #define MD_CHANGE_PENDING 2	/* switch from 'clean' to 'active' in progress */
 #define MD_UPDATE_SB_FLAGS (1 | 2 | 4)	/* If these are set, md_update_sb needed */
 #define MD_ARRAY_FIRST_USE 3    /* First use of array, needs initialization */
-#define MD_STILL_CLOSED	4	/* If set, then array has not been opened since
-				 * md_ioctl checked on it.
-				 */
+#define MD_CLOSING	4	/* If set, we are closing the array, do not open
+				 * it then */
 #define MD_JOURNAL_CLEAN 5	/* A raid with journal is already clean */
 #define MD_HAS_JOURNAL	6	/* The raid array has journal feature set */
 #define MD_RELOAD_SB	7	/* Reload the superblock because another node

commit 3f35e210ed4617a68b6baa9b7ac6c72bf7e313d9
Merge: 194dc870a589 5d8817833c76
Author: Shaohua Li <shli@fb.com>
Date:   Thu Jul 28 09:34:14 2016 -0700

    Merge branch 'mymd/for-next' into mymd/for-linus

commit 0e3ef49eda5bae3aa75aa8c0276411bf0f27e03a
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Fri Jun 17 17:33:10 2016 +0200

    md: use seconds granularity for error logging
    
    The md code stores the exact time of the last error in the
    last_read_error variable using a timespec structure. It only
    ever uses the seconds portion of that though, so we can
    use a scalar for it.
    
    There won't be an overflow in 2038 here, because it already
    used monotonic time and 32-bit is enough for that, but I've
    decided to use time64_t for consistency in the conversion.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index dc65ca65b26e..fd56cfd8c368 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -99,7 +99,7 @@ struct md_rdev {
 	atomic_t	read_errors;	/* number of consecutive read errors that
 					 * we have tried to ignore.
 					 */
-	struct timespec last_read_error;	/* monotonic time since our
+	time64_t	last_read_error;	/* monotonic time since our
 						 * last read error
 						 */
 	atomic_t	corrected_errors; /* number of corrected read errors,

commit d787be4092e27728cb4c012bee9762098ef3c662
Author: NeilBrown <neilb@suse.com>
Date:   Thu Jun 2 16:19:53 2016 +1000

    md: reduce the number of synchronize_rcu() calls when multiple devices fail.
    
    Every time a device is removed with ->hot_remove_disk() a synchronize_rcu() call is made
    which can delay several milliseconds in some case.
    If lots of devices fail at once - as could happen with a large RAID10 where one set
    of devices are removed all at once - these delays can add up to be very inconcenient.
    
    As failure is not reversible we can check for that first, setting a
    separate flag if it is found, and then all synchronize_rcu() once for
    all the flagged devices.  Then ->hot_remove_disk() function can skip the
    synchronize_rcu() step if the flag is set.
    
    fix build error(Shaohua)
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 03b19aad4921..dc65ca65b26e 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -163,6 +163,11 @@ enum flag_bits {
 				 * than other devices in the array
 				 */
 	ClusterRemove,
+	RemoveSynchronized,	/* synchronize_rcu() was called after
+				 * this device was known to be faulty,
+				 * so it is safe to remove without
+				 * another synchronize_rcu() call.
+				 */
 };
 
 static inline int is_badblock(struct md_rdev *rdev, sector_t s, int sectors,

commit 28a8f0d317bf225ff15008f5dd66ae16242dd843
Author: Mike Christie <mchristi@redhat.com>
Date:   Sun Jun 5 14:32:25 2016 -0500

    block, drivers, fs: rename REQ_FLUSH to REQ_PREFLUSH
    
    To avoid confusion between REQ_OP_FLUSH, which is handled by
    request_fn drivers, and upper layers requesting the block layer
    perform a flush sequence along with possibly a WRITE, this patch
    renames REQ_FLUSH to REQ_PREFLUSH.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 2e0918fc376d..b4f335245bd6 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -424,7 +424,7 @@ struct mddev {
 
 	/* Generic flush handling.
 	 * The last to finish preflush schedules a worker to submit
-	 * the rest of the request (without the REQ_FLUSH flag).
+	 * the rest of the request (without the REQ_PREFLUSH flag).
 	 */
 	struct bio *flush_bio;
 	atomic_t flush_pending;

commit 796a5cf083c2631180ad209c3ebb7d11d776cd72
Author: Mike Christie <mchristi@redhat.com>
Date:   Sun Jun 5 14:32:07 2016 -0500

    md: use bio op accessors
    
    Separate the op from the rq_flag_bits and have md
    set/get the bio using bio_set_op_attrs/bio_op.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index b5c4be73e6e4..2e0918fc376d 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -618,7 +618,8 @@ extern void md_super_write(struct mddev *mddev, struct md_rdev *rdev,
 			   sector_t sector, int size, struct page *page);
 extern void md_super_wait(struct mddev *mddev);
 extern int sync_page_io(struct md_rdev *rdev, sector_t sector, int size,
-			struct page *page, int rw, bool metadata_op);
+			struct page *page, int op, int op_flags,
+			bool metadata_op);
 extern void md_do_sync(struct md_thread *thread);
 extern void md_new_event(struct mddev *mddev);
 extern int md_allow_write(struct mddev *mddev);

commit bb8bf15bd6f7c3432ce9ad631f2f59c49c1e1853
Author: Guoqing Jiang <gqjiang@suse.com>
Date:   Thu Jun 2 23:32:04 2016 -0400

    md-cluster: fix deadlock issue when add disk to an recoverying array
    
    Add a disk to an array which is performing recovery
    is a little complicated, we need to do both reap the
    sync thread and perform add disk for the case, then
    it caused deadlock as follows.
    
    linux44:~ # ps aux|grep md|grep D
    root      1822  0.0  0.0      0     0 ?        D    16:50   0:00 [md127_resync]
    root      1848  0.0  0.0  19860   952 pts/0    D+   16:50   0:00 mdadm --manage /dev/md127 --re-add /dev/vdb
    linux44:~ # cat /proc/1848/stack
    [<ffffffff8107afde>] kthread_stop+0x6e/0x120
    [<ffffffffa051ddb0>] md_unregister_thread+0x40/0x80 [md_mod]
    [<ffffffffa0526e45>] md_reap_sync_thread+0x15/0x150 [md_mod]
    [<ffffffffa05271e0>] action_store+0x260/0x270 [md_mod]
    [<ffffffffa05206b4>] md_attr_store+0xb4/0x100 [md_mod]
    [<ffffffff81214a7e>] sysfs_write_file+0xbe/0x140
    [<ffffffff811a6b98>] vfs_write+0xb8/0x1e0
    [<ffffffff811a75b8>] SyS_write+0x48/0xa0
    [<ffffffff8152a5c9>] system_call_fastpath+0x16/0x1b
    [<00007f068ea1ed30>] 0x7f068ea1ed30
    linux44:~ # cat /proc/1822/stack
    [<ffffffffa05251a6>] md_do_sync+0x846/0xf40 [md_mod]
    [<ffffffffa052402d>] md_thread+0x16d/0x180 [md_mod]
    [<ffffffff8107ad94>] kthread+0xb4/0xc0
    [<ffffffff8152a518>] ret_from_fork+0x58/0x90
    
                            Task1848                                Task1822
    md_attr_store (held reconfig_mutex by call mddev_lock())
                            action_store
                            md_reap_sync_thread
                            md_unregister_thread
                            kthread_stop                    md_wakeup_thread(mddev->thread);
                                                    wait_event(mddev->sb_wait, !test_bit(MD_CHANGE_PENDING))
    
    md_check_recovery is triggered by wakeup mddev->thread,
    but it can't clear MD_CHANGE_PENDING flag since it can't
    get lock which was held by md_attr_store already.
    
    To solve the deadlock problem, we move "->resync_finish()"
    from md_do_sync to md_reap_sync_thread (after md_update_sb),
    also MD_HELD_RESYNC_LOCK is introduced since it is possible
    that node can't get resync lock in md_do_sync.
    
    Then we do not need to wait for MD_CHANGE_PENDING is cleared
    or not since metadata should be updated after md_update_sb,
    so just call resync_finish if MD_HELD_RESYNC_LOCK is set.
    
    We also unified the code after skip label, since set PENDING
    for non-clustered case should be harmless.
    
    Reviewed-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Guoqing Jiang <gqjiang@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index b5c4be73e6e4..03b19aad4921 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -204,6 +204,9 @@ struct mddev {
 #define MD_RELOAD_SB	7	/* Reload the superblock because another node
 				 * updated it.
 				 */
+#define MD_CLUSTER_RESYNC_LOCKED 8 /* cluster raid only, which means node
+				    * already took resync lock, need to
+				    * release the lock */
 
 	int				suspended;
 	atomic_t			active_io;

commit 3c28c9ccafd8bfb30ede7f36bf099b071b977209
Merge: 4b43ea2a7c76 1501efadc524
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 15 12:28:00 2016 -0800

    Merge tag 'md/4.5' of git://neil.brown.name/md
    
    Pull md updates from Neil Brown:
     "Mostly clustered-raid1 and raid5 journal updates.  one Y2038 fix and
      other minor stuff.
    
      One patch removes me from the MAINTAINERS file and adds a record of my
      md maintainership to Credits"
    
    Many thanks to Neil, who has been around for a _looong_ time.
    
    * tag 'md/4.5' of git://neil.brown.name/md: (26 commits)
      md/raid: only permit hot-add of compatible integrity profiles
      Remove myself as MD Maintainer, and add to Credits.
      raid5-cache: handle journal hotadd in quiesce
      MD: add journal with array suspended
      md: set MD_HAS_JOURNAL in correct places
      md: Remove 'ready' field from mddev.
      md: remove unnecesary md_new_event_inintr
      raid5: allow r5l_io_unit allocations to fail
      raid5-cache: use a mempool for the metadata block
      raid5-cache: use a bio_set
      raid5-cache: add journal hot add/remove support
      drivers: md: use ktime_get_real_seconds()
      md: avoid warning for 32-bit sector_t
      raid5-cache: free meta_page earlier
      raid5-cache: simplify r5l_move_io_unit_list
      md: update comment for md_allow_write
      md-cluster: update comments for MD_CLUSTER_SEND_LOCKED_ALREADY
      md-cluster: Protect communication with mutexes
      md-cluster: Defer MD reloading to mddev->thread
      md-cluster: update the documentation
      ...

commit d080827f850ba4df5b955d5ca8c8c0fc92fe18c0
Merge: cbd88cd4c07f 8b63b6bfc1a5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 13 19:15:14 2016 -0800

    Merge tag 'libnvdimm-for-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm
    
    Pull libnvdimm updates from Dan Williams:
     "The bulk of this has appeared in -next and independently received a
      build success notification from the kbuild robot.  The 'for-4.5/block-
      dax' topic branch was rebased over the weekend to drop the "block
      device end-of-life" rework that Al would like to see re-implemented
      with a notifier, and to address bug reports against the badblocks
      integration.
    
      There is pending feedback against "libnvdimm: Add a poison list and
      export badblocks" received last week.  Linda identified some localized
      fixups that we will handle incrementally.
    
      Summary:
    
       - Media error handling: The 'badblocks' implementation that
         originated in md-raid is up-levelled to a generic capability of a
         block device.  This initial implementation is limited to being
         consulted in the pmem block-i/o path.  Later, 'badblocks' will be
         consulted when creating dax mappings.
    
       - Raw block device dax: For virtualization and other cases that want
         large contiguous mappings of persistent memory, add the capability
         to dax-mmap a block device directly.
    
       - Increased /dev/mem restrictions: Add an option to treat all
         io-memory as IORESOURCE_EXCLUSIVE, i.e. disable /dev/mem access
         while a driver is actively using an address range.  This behavior
         is controlled via the new CONFIG_IO_STRICT_DEVMEM option and can be
         overridden by the existing "iomem=relaxed" kernel command line
         option.
    
       - Miscellaneous fixes include a 'pfn'-device huge page alignment fix,
         block device shutdown crash fix, and other small libnvdimm fixes"
    
    * tag 'libnvdimm-for-4.5' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm: (32 commits)
      block: kill disk_{check|set|clear|alloc}_badblocks
      libnvdimm, pmem: nvdimm_read_bytes() badblocks support
      pmem, dax: disable dax in the presence of bad blocks
      pmem: fail io-requests to known bad blocks
      libnvdimm: convert to statically allocated badblocks
      libnvdimm: don't fail init for full badblocks list
      block, badblocks: introduce devm_init_badblocks
      block: clarify badblocks lifetime
      badblocks: rename badblocks_free to badblocks_exit
      libnvdimm, pmem: move definition of nvdimm_namespace_add_poison to nd.h
      libnvdimm: Add a poison list and export badblocks
      nfit_test: Enable DSMs for all test NFITs
      md: convert to use the generic badblocks code
      block: Add badblock management for gendisks
      badblocks: Add core badblock management code
      block: fix del_gendisk() vs blkdev_ioctl crash
      block: enable dax for raw block devices
      block: introduce bdev_file_inode()
      restrict /dev/mem to idle io memory ranges
      arch: consolidate CONFIG_STRICT_DEVM in lib/Kconfig.debug
      ...

commit 1501efadc524a0c99494b576923091589a52d2a4
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed Jan 13 16:00:07 2016 -0800

    md/raid: only permit hot-add of compatible integrity profiles
    
    It is not safe for an integrity profile to be changed while i/o is
    in-flight in the queue.  Prevent adding new disks or otherwise online
    spares to an array if the device has an incompatible integrity profile.
    
    The original change to the blk_integrity_unregister implementation in
    md, commmit c7bfced9a671 "md: suspend i/o during runtime
    blk_integrity_unregister" introduced an immediate hang regression.
    
    This policy of disallowing changes the integrity profile once one has
    been established is shared with DM.
    
    Here is an abbreviated log from a test run that:
    1/ Creates a degraded raid1 with an integrity-enabled device (pmem0s) [   59.076127]
    2/ Tries to add an integrity-disabled device (pmem1m) [   90.489209]
    3/ Retries with an integrity-enabled device (pmem1s) [  205.671277]
    
    [   59.076127] md/raid1:md0: active with 1 out of 2 mirrors
    [   59.078302] md: data integrity enabled on md0
    [..]
    [   90.489209] md0: incompatible integrity profile for pmem1m
    [..]
    [  205.671277] md: super_written gets error=-5
    [  205.677386] md/raid1:md0: Disk failure on pmem1m, disabling device.
    [  205.677386] md/raid1:md0: Operation continuing on 1 devices.
    [  205.683037] RAID1 conf printout:
    [  205.684699]  --- wd:1 rd:2
    [  205.685972]  disk 0, wo:0, o:1, dev:pmem0s
    [  205.687562]  disk 1, wo:1, o:1, dev:pmem1s
    [  205.691717] md: recovery of RAID array md0
    
    Fixes: c7bfced9a671 ("md: suspend i/o during runtime blk_integrity_unregister")
    Cc: <stable@vger.kernel.org>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Reported-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: NeilBrown <neilb@suse.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index fc6f7bbc9544..a491e220e738 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -660,7 +660,7 @@ extern void md_wait_for_blocked_rdev(struct md_rdev *rdev, struct mddev *mddev);
 extern void md_set_array_sectors(struct mddev *mddev, sector_t array_sectors);
 extern int md_check_no_bitmap(struct mddev *mddev);
 extern int md_integrity_register(struct mddev *mddev);
-extern void md_integrity_add_rdev(struct md_rdev *rdev, struct mddev *mddev);
+extern int md_integrity_add_rdev(struct md_rdev *rdev, struct mddev *mddev);
 extern int strict_strtoul_scaled(const char *cp, unsigned long *res, int scale);
 
 extern void mddev_init(struct mddev *mddev);

commit fc974ee2bffdde47d1e4b220cf326952cc2c4794
Author: Vishal Verma <vishal.l.verma@intel.com>
Date:   Thu Dec 24 19:20:34 2015 -0700

    md: convert to use the generic badblocks code
    
    Retain badblocks as part of rdev, but use the accessor functions from
    include/linux/badblocks for all manipulation.
    
    Signed-off-by: Vishal Verma <vishal.l.verma@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 2bea51edfab7..389afc420db6 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -17,6 +17,7 @@
 
 #include <linux/blkdev.h>
 #include <linux/backing-dev.h>
+#include <linux/badblocks.h>
 #include <linux/kobject.h>
 #include <linux/list.h>
 #include <linux/mm.h>
@@ -28,13 +29,6 @@
 
 #define MaxSector (~(sector_t)0)
 
-/* Bad block numbers are stored sorted in a single page.
- * 64bits is used for each block or extent.
- * 54 bits are sector number, 9 bits are extent size,
- * 1 bit is an 'acknowledged' flag.
- */
-#define MD_MAX_BADBLOCKS	(PAGE_SIZE/8)
-
 /*
  * MD's 'extended' device
  */
@@ -117,22 +111,7 @@ struct md_rdev {
 	struct kernfs_node *sysfs_state; /* handle for 'state'
 					   * sysfs entry */
 
-	struct badblocks {
-		int	count;		/* count of bad blocks */
-		int	unacked_exist;	/* there probably are unacknowledged
-					 * bad blocks.  This is only cleared
-					 * when a read discovers none
-					 */
-		int	shift;		/* shift from sectors to block size
-					 * a -ve shift means badblocks are
-					 * disabled.*/
-		u64	*page;		/* badblock list */
-		int	changed;
-		seqlock_t lock;
-
-		sector_t sector;
-		sector_t size;		/* in sectors */
-	} badblocks;
+	struct badblocks badblocks;
 };
 enum flag_bits {
 	Faulty,			/* device is known to have a fault */
@@ -185,22 +164,11 @@ enum flag_bits {
 				 */
 };
 
-#define BB_LEN_MASK	(0x00000000000001FFULL)
-#define BB_OFFSET_MASK	(0x7FFFFFFFFFFFFE00ULL)
-#define BB_ACK_MASK	(0x8000000000000000ULL)
-#define BB_MAX_LEN	512
-#define BB_OFFSET(x)	(((x) & BB_OFFSET_MASK) >> 9)
-#define BB_LEN(x)	(((x) & BB_LEN_MASK) + 1)
-#define BB_ACK(x)	(!!((x) & BB_ACK_MASK))
-#define BB_MAKE(a, l, ack) (((a)<<9) | ((l)-1) | ((u64)(!!(ack)) << 63))
-
-extern int md_is_badblock(struct badblocks *bb, sector_t s, int sectors,
-			  sector_t *first_bad, int *bad_sectors);
 static inline int is_badblock(struct md_rdev *rdev, sector_t s, int sectors,
 			      sector_t *first_bad, int *bad_sectors)
 {
 	if (unlikely(rdev->badblocks.count)) {
-		int rv = md_is_badblock(&rdev->badblocks, rdev->data_offset + s,
+		int rv = badblocks_check(&rdev->badblocks, rdev->data_offset + s,
 					sectors,
 					first_bad, bad_sectors);
 		if (rv)
@@ -213,8 +181,6 @@ extern int rdev_set_badblocks(struct md_rdev *rdev, sector_t s, int sectors,
 			      int is_new);
 extern int rdev_clear_badblocks(struct md_rdev *rdev, sector_t s, int sectors,
 				int is_new);
-extern void md_ack_all_badblocks(struct badblocks *bb);
-
 struct md_cluster_info;
 
 struct mddev {

commit 274d8cbde1bc3bdfb31c5d6a58113dff5cee4f87
Author: NeilBrown <neilb@suse.com>
Date:   Mon Jan 4 16:16:58 2016 +1100

    md: Remove 'ready' field from mddev.
    
    This field is always set in tandem with ->pers, and when it is tested
    ->pers is also tested.  So ->ready is not needed.
    
    It was needed once, but code rearrangement and locking changes have
    removed that needed.
    
    Signed-off-by: NeilBrown <neilb@suse.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index e16a17c37418..fc6f7bbc9544 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -246,8 +246,6 @@ struct mddev {
 						       * are happening, so run/
 						       * takeover/stop are not safe
 						       */
-	int				ready; /* See when safe to pass
-						* IO requests down */
 	struct gendisk			*gendisk;
 
 	struct kobject			kobj;

commit 9ebc6ef188a0656f3620835f9be7fe22c1644c1c
Author: Deepa Dinamani <deepa.kernel@gmail.com>
Date:   Mon Dec 21 10:51:01 2015 +1100

    drivers: md: use ktime_get_real_seconds()
    
    get_seconds() API is not y2038 safe on 32 bit systems and the API
    is deprecated. Replace it with calls to ktime_get_real_seconds()
    API instead. Change mddev structure types to time64_t accordingly.
    
    32 bit signed timestamps will overflow in the year 2038.
    
    Change the user interface mdu_array_info_s structure timestamps:
    ctime and utime values used in ioctls GET_ARRAY_INFO and
    SET_ARRAY_INFO to unsigned int. This will extend the field to last
    until the year 2106.
    The long term plan is to get rid of ctime and utime values in
    this structure as this information can be read from the on-disk
    meta data directly.
    
    Clamp the tim64_t timestamps to positive values with a max of U32_MAX
    when returning from GET_ARRAY_INFO ioctl to accommodate above changes
    in the data type of timestamps to unsigned int.
    
    v0.90 on disk meta data uses u32 for maintaining time stamps.
    So this will also last until year 2106.
    Assumption is that the usage of v0.90 will be deprecated by
    year 2106.
    
    Timestamp fields in the on disk meta data for v1.0 version already
    use 64 bit data types. Remove the truncation of the bits while
    writing to or reading from these from the disk.
    
    Signed-off-by: Deepa Dinamani <deepa.kernel@gmail.com>
    Reviewed-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: NeilBrown <neilb@suse.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 8817e623258a..e16a17c37418 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -264,7 +264,7 @@ struct mddev {
 							 * managed externally */
 	char				metadata_type[17]; /* externally set*/
 	int				chunk_sectors;
-	time_t				ctime, utime;
+	time64_t			ctime, utime;
 	int				level, layout;
 	char				clevel[16];
 	int				raid_disks;

commit 15858fa5b00c1067a8a8e53ea32f4a65f8bebbb8
Author: Guoqing Jiang <gqjiang@suse.com>
Date:   Mon Dec 21 10:51:00 2015 +1100

    md-cluster: Defer MD reloading to mddev->thread
    
    Reloading of superblock must be performed under reconfig_mutex. However,
    this cannot be done with md_reload_sb because it would deadlock with
    the message DLM lock. So, we defer it in md_check_recovery() which is
    executed by mddev->thread.
    
    This introduces a new flag, MD_RELOAD_SB, which if set, will reload the
    superblock. And good_device_nr is also added to 'struct mddev' which is
    used to get the num of the good device within cluster raid.
    
    Signed-off-by: Goldwyn Rodrigues <rgoldwyn@suse.com>
    Signed-off-by: Guoqing Jiang <gqjiang@suse.com>
    Signed-off-by: NeilBrown <neilb@suse.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index f7b17aef837d..8817e623258a 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -235,6 +235,9 @@ struct mddev {
 				 */
 #define MD_JOURNAL_CLEAN 5	/* A raid with journal is already clean */
 #define MD_HAS_JOURNAL	6	/* The raid array has journal feature set */
+#define MD_RELOAD_SB	7	/* Reload the superblock because another node
+				 * updated it.
+				 */
 
 	int				suspended;
 	atomic_t			active_io;
@@ -465,6 +468,7 @@ struct mddev {
 	struct work_struct event_work;	/* used by dm to report failure event */
 	void (*sync_super)(struct mddev *mddev, struct md_rdev *rdev);
 	struct md_cluster_info		*cluster_info;
+	unsigned int			good_device_nr;	/* good device num within cluster raid */
 };
 
 static inline int __must_check mddev_lock(struct mddev *mddev)

commit 659b254fa7392e32b59a30d4b61fb12c4cd440ff
Author: Guoqing Jiang <gqjiang@suse.com>
Date:   Mon Dec 21 10:50:59 2015 +1100

    md-cluster: remove a disk asynchronously from cluster environment
    
    For cluster raid, if one disk couldn't be reach in one node, then
    other nodes would receive the REMOVE message for the disk.
    
    In receiving node, we can't call md_kick_rdev_from_array to remove
    the disk from array synchronously since the disk might still be busy
    in this node. So let's set a ClusterRemove flag on the disk, then
    let the thread to do the removal job eventually.
    
    Signed-off-by: Guoqing Jiang <gqjiang@suse.com>
    Signed-off-by: Goldwyn Rodrigues <rgoldwyn@suse.com>
    Signed-off-by: NeilBrown <neilb@suse.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index ca0b643fe3c1..f7b17aef837d 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -183,6 +183,7 @@ enum flag_bits {
 				 * Usually, this device should be faster
 				 * than other devices in the array
 				 */
+	ClusterRemove,
 };
 
 #define BB_LEN_MASK	(0x00000000000001FFULL)

commit 9b15603dbd98ad1003355ef6ac7d682c75df81c1
Author: Shaohua Li <shli@fb.com>
Date:   Fri Dec 18 15:19:16 2015 +1100

    MD: change journal disk role to disk 0
    
    Neil pointed out setting journal disk role to raid_disks will confuse
    reshape if we support reshape eventually. Switching the role to 0 (we
    should be fine as long as the value >=0) and skip sysfs file creation to
    avoid error.
    
    Signed-off-by: Shaohua Li <shli@fb.com>
    Signed-off-by: NeilBrown <neilb@suse.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 2bea51edfab7..ca0b643fe3c1 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -566,7 +566,9 @@ static inline char * mdname (struct mddev * mddev)
 static inline int sysfs_link_rdev(struct mddev *mddev, struct md_rdev *rdev)
 {
 	char nm[20];
-	if (!test_bit(Replacement, &rdev->flags) && mddev->kobj.sd) {
+	if (!test_bit(Replacement, &rdev->flags) &&
+	    !test_bit(Journal, &rdev->flags) &&
+	    mddev->kobj.sd) {
 		sprintf(nm, "rd%d", rdev->raid_disk);
 		return sysfs_create_link(&mddev->kobj, &rdev->kobj, nm);
 	} else
@@ -576,7 +578,9 @@ static inline int sysfs_link_rdev(struct mddev *mddev, struct md_rdev *rdev)
 static inline void sysfs_unlink_rdev(struct mddev *mddev, struct md_rdev *rdev)
 {
 	char nm[20];
-	if (!test_bit(Replacement, &rdev->flags) && mddev->kobj.sd) {
+	if (!test_bit(Replacement, &rdev->flags) &&
+	    !test_bit(Journal, &rdev->flags) &&
+	    mddev->kobj.sd) {
 		sprintf(nm, "rd%d", rdev->raid_disk);
 		sysfs_remove_link(&mddev->kobj, nm);
 	}

commit a97b7896447a89749d9258fbb9d8c3faf48a7a4e
Author: Song Liu <songliubraving@fb.com>
Date:   Thu Oct 8 21:54:09 2015 -0700

    MD: add new bit to indicate raid array with journal
    
    If a raid array has journal feature bit set, add a new bit to indicate
    this. If the array is started without journal disk existing, we know
    there is something wrong.
    
    Signed-off-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Shaohua Li <shli@fb.com>
    Signed-off-by: NeilBrown <neilb@suse.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index e14e667a20e9..2bea51edfab7 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -233,6 +233,7 @@ struct mddev {
 				 * md_ioctl checked on it.
 				 */
 #define MD_JOURNAL_CLEAN 5	/* A raid with journal is already clean */
+#define MD_HAS_JOURNAL	6	/* The raid array has journal feature set */
 
 	int				suspended;
 	atomic_t			active_io;

commit bd18f6462f3d167a9b3ec27851c98f82694b2adf
Author: Shaohua Li <shli@fb.com>
Date:   Wed Sep 2 13:49:50 2015 -0700

    md: skip resync for raid array with journal
    
    If a raid array has journal, the journal can guarantee the consistency,
    we can skip resync after a unclean shutdown. The exception is raid
    creation or user initiated resync, which we still do a raid resync.
    
    Signed-off-by: Shaohua Li <shli@fb.com>
    Signed-off-by: NeilBrown <neilb@suse.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 2b0f62fb6146..e14e667a20e9 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -232,6 +232,7 @@ struct mddev {
 #define MD_STILL_CLOSED	4	/* If set, then array has not been opened since
 				 * md_ioctl checked on it.
 				 */
+#define MD_JOURNAL_CLEAN 5	/* A raid with journal is already clean */
 
 	int				suspended;
 	atomic_t			active_io;

commit 3069aa8def32b0c2b83cd27d1c37ed30b47ce879
Author: Shaohua Li <shli@fb.com>
Date:   Thu Aug 13 14:31:56 2015 -0700

    md: override md superblock recovery_offset for journal device
    
    Journal device stores data in a log structure. We need record the log
    start. Here we override md superblock recovery_offset for this purpose.
    This field of a journal device is meaningless otherwise.
    
    Signed-off-by: Shaohua Li <shli@fb.com>
    Signed-off-by: NeilBrown <neilb@suse.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 88dc6312f5d5..2b0f62fb6146 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -87,10 +87,16 @@ struct md_rdev {
 					 * array and could again if we did a partial
 					 * resync from the bitmap
 					 */
-	sector_t	recovery_offset;/* If this device has been partially
+	union {
+		sector_t recovery_offset;/* If this device has been partially
 					 * recovered, this is where we were
 					 * up to.
 					 */
+		sector_t journal_tail;	/* If this device is a journal device,
+					 * this is the journal tail (journal
+					 * recovery start point)
+					 */
+	};
 
 	atomic_t	nr_pending;	/* number of pending requests.
 					 * only maintained for arrays that

commit bac624f3f86a8c7db395c7f85ccad6a504b9c4b4
Author: Song Liu <songliubraving@fb.com>
Date:   Thu Aug 13 14:31:55 2015 -0700

    MD: add a new disk role to present write journal device
    
    Next patches will use a disk as raid5/6 journaling. We need a new disk
    role to present the journal device and add MD_FEATURE_JOURNAL to
    feature_map for backward compability.
    
    Signed-off-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Shaohua Li <shli@fb.com>
    Signed-off-by: NeilBrown <neilb@suse.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 2ea00356bb23..88dc6312f5d5 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -172,6 +172,11 @@ enum flag_bits {
 				 * This device is seen locally but not
 				 * by the whole cluster
 				 */
+	Journal,		/* This device is used as journal for
+				 * raid-5/6.
+				 * Usually, this device should be faster
+				 * than other devices in the array
+				 */
 };
 
 #define BB_LEN_MASK	(0x00000000000001FFULL)

commit 70bcecdb1534a7dcd82503b705c27a048d568c9d
Author: Goldwyn Rodrigues <rgoldwyn@suse.com>
Date:   Fri Aug 21 10:33:39 2015 -0500

    md-cluster: Improve md_reload_sb to be less error prone
    
    md_reload_sb is too simplistic and it explicitly needs to determine
    the changes made by the writing node. However, there are multiple areas
    where a simple reload could fail.
    
    Instead, read the superblock of one of the "good" rdevs and update
    the necessary information:
    
    - read the superblock into a newly allocated page, by temporarily
      swapping out rdev->sb_page and calling ->load_super.
    - if that fails return
    - if it succeeds, call check_sb_changes
      1. iterates over list of active devices and checks the matching
       dev_roles[] value.
            If that is 'faulty', the device must be  marked as faulty
             - call md_error to mark the device as faulty. Make sure
               not to set CHANGE_DEVS and wakeup mddev->thread or else
               it would initiate a resync process, which is the responsibility
               of the "primary" node.
             - clear the Blocked bit
             - Call remove_and_add_spares() to hot remove the device.
            If the device is 'spare':
             - call remove_and_add_spares() to get the number of spares
               added in this operation.
             - Reduce mddev->degraded to mark the array as not degraded.
      2. reset recovery_cp
    - read the rest of the rdevs to update recovery_offset. If recovery_offset
      is equal to MaxSector, call spare_active() to set it In_sync
    
    This required that recovery_offset be initialized to MaxSector, as
    opposed to zero so as to communicate the end of sync for a rdev.
    
    Signed-off-by: Goldwyn Rodrigues <rgoldwyn@suse.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index ab339571e57f..2ea00356bb23 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -658,7 +658,7 @@ extern struct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,
 				   struct mddev *mddev);
 
 extern void md_unplug(struct blk_plug_cb *cb, bool from_schedule);
-extern void md_reload_sb(struct mddev *mddev);
+extern void md_reload_sb(struct mddev *mddev, int raid_disk);
 extern void md_update_sb(struct mddev *mddev, int force);
 extern void md_kick_rdev_from_array(struct md_rdev * rdev);
 struct md_rdev *md_find_rdev_nr_rcu(struct mddev *mddev, int nr);

commit 8ae126660fddbeebb9251a174e6fa45b6ad8f932
Author: Kent Overstreet <kent.overstreet@gmail.com>
Date:   Mon Apr 27 23:48:34 2015 -0700

    block: kill merge_bvec_fn() completely
    
    As generic_make_request() is now able to handle arbitrarily sized bios,
    it's no longer necessary for each individual block driver to define its
    own ->merge_bvec_fn() callback. Remove every invocation completely.
    
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Lars Ellenberg <drbd-dev@lists.linbit.com>
    Cc: drbd-user@lists.linbit.com
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Yehuda Sadeh <yehuda@inktank.com>
    Cc: Sage Weil <sage@inktank.com>
    Cc: Alex Elder <elder@kernel.org>
    Cc: ceph-devel@vger.kernel.org
    Cc: Alasdair Kergon <agk@redhat.com>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: dm-devel@redhat.com
    Cc: Neil Brown <neilb@suse.de>
    Cc: linux-raid@vger.kernel.org
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: "Martin K. Petersen" <martin.petersen@oracle.com>
    Acked-by: NeilBrown <neilb@suse.de> (for the 'md' bits)
    Acked-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Kent Overstreet <kent.overstreet@gmail.com>
    [dpark: also remove ->merge_bvec_fn() in dm-thin as well as
     dm-era-target, and resolve merge conflicts]
    Signed-off-by: Dongsu Park <dpark@posteo.net>
    Signed-off-by: Ming Lin <ming.l@ssi.samsung.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 7da6e9c3cb53..ab339571e57f 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -134,10 +134,6 @@ enum flag_bits {
 	Bitmap_sync,		/* ..actually, not quite In_sync.  Need a
 				 * bitmap-based recovery to get fully in sync
 				 */
-	Unmerged,		/* device is being added to array and should
-				 * be considerred for bvec_merge_fn but not
-				 * yet for actual IO
-				 */
 	WriteMostly,		/* Avoid reading if at all possible */
 	AutoDetected,		/* added by auto-detect */
 	Blocked,		/* An error occurred but has not yet
@@ -374,10 +370,6 @@ struct mddev {
 	int				degraded;	/* whether md should consider
 							 * adding a spare
 							 */
-	int				merge_check_needed; /* at least one
-							     * member device
-							     * has a
-							     * merge_bvec_fn */
 
 	atomic_t			recovery_active; /* blocks scheduled, but not written */
 	wait_queue_head_t		recovery_wait;
@@ -532,10 +524,6 @@ struct md_personality
 	/* congested implements bdi.congested_fn().
 	 * Will not be called while array is 'suspended' */
 	int (*congested)(struct mddev *mddev, int bits);
-	/* mergeable_bvec is use to implement ->merge_bvec_fn */
-	int (*mergeable_bvec)(struct mddev *mddev,
-			      struct bvec_merge_data *bvm,
-			      struct bio_vec *biovec);
 };
 
 struct md_sysfs_entry {

commit 66114cad64bf76a155fec1f0fff0de771cf909d5
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 22 17:13:32 2015 -0400

    writeback: separate out include/linux/backing-dev-defs.h
    
    With the planned cgroup writeback support, backing-dev related
    declarations will be more widely used across block and cgroup;
    unfortunately, including backing-dev.h from include/linux/blkdev.h
    makes cyclic include dependency quite likely.
    
    This patch separates out backing-dev-defs.h which only has the
    essential definitions and updates blkdev.h to include it.  c files
    which need access to more backing-dev details now include
    backing-dev.h directly.  This takes backing-dev.h off the common
    include dependency chain making it a lot easier to use it across block
    and cgroup.
    
    v2: fs/fat build failure fixed.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 4046a6c6f223..7da6e9c3cb53 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -16,6 +16,7 @@
 #define _MD_MD_H
 
 #include <linux/blkdev.h>
+#include <linux/backing-dev.h>
 #include <linux/kobject.h>
 #include <linux/list.h>
 #include <linux/mm.h>

commit 09314799e4f0589e52bafcd0ca3556c60468bc0e
Author: NeilBrown <neilb@suse.de>
Date:   Thu Feb 19 16:04:40 2015 +1100

    md: remove 'go_faster' option from ->sync_request()
    
    This option is not well justified and testing suggests that
    it hardly ever makes any difference.
    
    The comment suggests there might be a need to wait for non-resync
    activity indicated by ->nr_waiting, however raise_barrier()
    already waits for all of that.
    
    So just remove it to simplify reasoning about speed limiting.
    
    This allows us to remove a 'FIXME' comment from raid5.c as that
    never used the flag.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index ecdce36ec6b8..4046a6c6f223 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -506,7 +506,7 @@ struct md_personality
 	int (*hot_add_disk) (struct mddev *mddev, struct md_rdev *rdev);
 	int (*hot_remove_disk) (struct mddev *mddev, struct md_rdev *rdev);
 	int (*spare_active) (struct mddev *mddev);
-	sector_t (*sync_request)(struct mddev *mddev, sector_t sector_nr, int *skipped, int go_faster);
+	sector_t (*sync_request)(struct mddev *mddev, sector_t sector_nr, int *skipped);
 	int (*resize) (struct mddev *mddev, sector_t sectors);
 	sector_t (*size) (struct mddev *mddev, sector_t sectors, int raid_disks);
 	int (*check_reshape) (struct mddev *mddev);

commit 57d051dccaef395e0d8c0fff02cfc3a77bacc88c
Author: Goldwyn Rodrigues <rgoldwyn@suse.de>
Date:   Tue Apr 14 10:43:55 2015 -0500

    md: Export and rename find_rdev_nr_rcu
    
    This is required by the clustering module (patches to follow) to
    find the device to remove or re-add.
    
    Signed-off-by: Goldwyn Rodrigues <rgoldwyn@suse.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index d98c0d764d8f..ecdce36ec6b8 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -672,6 +672,7 @@ extern void md_unplug(struct blk_plug_cb *cb, bool from_schedule);
 extern void md_reload_sb(struct mddev *mddev);
 extern void md_update_sb(struct mddev *mddev, int force);
 extern void md_kick_rdev_from_array(struct md_rdev * rdev);
+struct md_rdev *md_find_rdev_nr_rcu(struct mddev *mddev, int nr);
 static inline int mddev_check_plugged(struct mddev *mddev)
 {
 	return !!blk_check_plugged(md_unplug, mddev,

commit fb56dfef4e31f214cfbfa0eb8a1949591c20b118
Author: Goldwyn Rodrigues <rgoldwyn@suse.de>
Date:   Tue Apr 14 10:43:24 2015 -0500

    md: Export and rename kick_rdev_from_array
    
    This export is required for clustering module in order to
    co-ordinate remove/readd a rdev from all nodes.
    
    Signed-off-by: Goldwyn Rodrigues <rgoldwyn@suse.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 6dc0ce09f50c..d98c0d764d8f 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -671,6 +671,7 @@ extern struct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,
 extern void md_unplug(struct blk_plug_cb *cb, bool from_schedule);
 extern void md_reload_sb(struct mddev *mddev);
 extern void md_update_sb(struct mddev *mddev, int force);
+extern void md_kick_rdev_from_array(struct md_rdev * rdev);
 static inline int mddev_check_plugged(struct mddev *mddev)
 {
 	return !!blk_check_plugged(md_unplug, mddev,

commit 1aee41f637694d4bbf91c24195f2b63e3f6badd2
Author: Goldwyn Rodrigues <rgoldwyn@suse.com>
Date:   Wed Oct 29 18:51:31 2014 -0500

    Add new disk to clustered array
    
    Algorithm:
    1. Node 1 issues mdadm --manage /dev/mdX --add /dev/sdYY which issues
       ioctl(ADD_NEW_DISC with disc.state set to MD_DISK_CLUSTER_ADD)
    2. Node 1 sends NEWDISK with uuid and slot number
    3. Other nodes issue kobject_uevent_env with uuid and slot number
    (Steps 4,5 could be a udev rule)
    4. In userspace, the node searches for the disk, perhaps
       using blkid -t SUB_UUID=""
    5. Other nodes issue either of the following depending on whether the disk
       was found:
       ioctl(ADD_NEW_DISK with disc.state set to MD_DISK_CANDIDATE and
             disc.number set to slot number)
       ioctl(CLUSTERED_DISK_NACK)
    6. Other nodes drop lock on no-new-devs (CR) if device is found
    7. Node 1 attempts EX lock on no-new-devs
    8. If node 1 gets the lock, it sends METADATA_UPDATED after unmarking the disk
       as SpareLocal
    9. If not (get no-new-dev lock), it fails the operation and sends METADATA_UPDATED
    10. Other nodes understand if the device is added or not by reading the superblock again after receiving the METADATA_UPDATED message.
    
    Signed-off-by: Lidong Zhong <lzhong@suse.com>
    Signed-off-by: Goldwyn Rodrigues <rgoldwyn@suse.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index bfebcfdf54e6..6dc0ce09f50c 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -171,6 +171,10 @@ enum flag_bits {
 				 * a want_replacement device with same
 				 * raid_disk number.
 				 */
+	Candidate,		/* For clustered environments only:
+				 * This device is seen locally but not
+				 * by the whole cluster
+				 */
 };
 
 #define BB_LEN_MASK	(0x00000000000001FFULL)
@@ -666,6 +670,7 @@ extern struct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,
 
 extern void md_unplug(struct blk_plug_cb *cb, bool from_schedule);
 extern void md_reload_sb(struct mddev *mddev);
+extern void md_update_sb(struct mddev *mddev, int force);
 static inline int mddev_check_plugged(struct mddev *mddev)
 {
 	return !!blk_check_plugged(md_unplug, mddev,

commit 1d7e3e96117a864fe2ab3d02a14e49855319fdde
Author: Goldwyn Rodrigues <rgoldwyn@suse.com>
Date:   Sat Jun 7 01:53:00 2014 -0500

    Reload superblock if METADATA_UPDATED is received
    
    Re-reads the devices by invalidating the cache.
    Since we don't write to faulty devices, this is detected using
    events recorded in the devices. If it is old as compared to the mddev
    mark it is faulty.
    
    Signed-off-by: Goldwyn Rodrigues <rgoldwyn@suse.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 81e568090d8f..bfebcfdf54e6 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -665,6 +665,7 @@ extern struct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,
 				   struct mddev *mddev);
 
 extern void md_unplug(struct blk_plug_cb *cb, bool from_schedule);
+extern void md_reload_sb(struct mddev *mddev);
 static inline int mddev_check_plugged(struct mddev *mddev)
 {
 	return !!blk_check_plugged(md_unplug, mddev,

commit cf921cc19cf7c1e99f730a2faa02d80817d684a2
Author: Goldwyn Rodrigues <rgoldwyn@suse.com>
Date:   Sun Mar 30 00:42:49 2014 -0500

    Add node recovery callbacks
    
    DLM offers callbacks when a node fails and the lock remastery
    is performed:
    
    1. recover_prep: called when DLM discovers a node is down
    2. recover_slot: called when DLM identifies the node and recovery
                    can start
    3. recover_done: called when all nodes have completed recover_slot
    
    recover_slot() and recover_done() are also called when the node joins
    initially in order to inform the node with its slot number. These slot
    numbers start from one, so we deduct one to make it start with zero
    which the cluster-md code uses.
    
    Signed-off-by: Goldwyn Rodrigues <rgoldwyn@suse.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 80fc89976915..81e568090d8f 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -434,6 +434,7 @@ struct mddev {
 		unsigned long		max_write_behind; /* write-behind mode */
 		int			external;
 		int			nodes; /* Maximum number of nodes in the cluster */
+		char                    cluster_name[64]; /* Name of the cluster */
 	} bitmap_info;
 
 	atomic_t			max_corr_read_errors; /* max read retries */

commit c4ce867fdad200dfd8aa8cbe1eabc26c14c51635
Author: Goldwyn Rodrigues <rgoldwyn@suse.com>
Date:   Sat Mar 29 10:20:02 2014 -0500

    Introduce md_cluster_info
    
    md_cluster_info stores the cluster information in the MD device.
    
    The join() is called when mddev detects it is a clustered device.
    The main responsibilities are:
            1. Setup a DLM lockspace
            2. Setup all initial locks such as super block locks and bitmap lock (will come later)
    
    The leave() clears up the lockspace and all the locks held.
    
    Signed-off-by: Goldwyn Rodrigues <rgoldwyn@suse.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 018593197c4d..80fc89976915 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -203,6 +203,8 @@ extern int rdev_clear_badblocks(struct md_rdev *rdev, sector_t s, int sectors,
 				int is_new);
 extern void md_ack_all_badblocks(struct badblocks *bb);
 
+struct md_cluster_info;
+
 struct mddev {
 	void				*private;
 	struct md_personality		*pers;
@@ -431,6 +433,7 @@ struct mddev {
 		unsigned long		daemon_sleep; /* how many jiffies between updates? */
 		unsigned long		max_write_behind; /* write-behind mode */
 		int			external;
+		int			nodes; /* Maximum number of nodes in the cluster */
 	} bitmap_info;
 
 	atomic_t			max_corr_read_errors; /* max read retries */
@@ -449,6 +452,7 @@ struct mddev {
 	struct work_struct flush_work;
 	struct work_struct event_work;	/* used by dm to report failure event */
 	void (*sync_super)(struct mddev *mddev, struct md_rdev *rdev);
+	struct md_cluster_info		*cluster_info;
 };
 
 static inline int __must_check mddev_lock(struct mddev *mddev)
@@ -676,4 +680,8 @@ static inline void rdev_dec_pending(struct md_rdev *rdev, struct mddev *mddev)
 }
 
 extern struct md_cluster_operations *md_cluster_ops;
+static inline int mddev_is_clustered(struct mddev *mddev)
+{
+	return mddev->cluster_info && mddev->bitmap_info.nodes > 1;
+}
 #endif /* _MD_MD_H */

commit edb39c9deda87da5aad9c090e2e8eaf8470c852c
Author: Goldwyn Rodrigues <rgoldwyn@suse.com>
Date:   Sat Mar 29 10:01:53 2014 -0500

    Introduce md_cluster_operations to handle cluster functions
    
    This allows dynamic registering of cluster hooks.
    
    Signed-off-by: Goldwyn Rodrigues <rgoldwyn@suse.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 318ca8fd430f..018593197c4d 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -23,6 +23,7 @@
 #include <linux/timer.h>
 #include <linux/wait.h>
 #include <linux/workqueue.h>
+#include "md-cluster.h"
 
 #define MaxSector (~(sector_t)0)
 
@@ -608,6 +609,11 @@ static inline void safe_put_page(struct page *p)
 
 extern int register_md_personality(struct md_personality *p);
 extern int unregister_md_personality(struct md_personality *p);
+extern int register_md_cluster_operations(struct md_cluster_operations *ops,
+		struct module *module);
+extern int unregister_md_cluster_operations(void);
+extern int md_setup_cluster(struct mddev *mddev, int nodes);
+extern void md_cluster_stop(struct mddev *mddev);
 extern struct md_thread *md_register_thread(
 	void (*run)(struct md_thread *thread),
 	struct mddev *mddev,
@@ -669,4 +675,5 @@ static inline void rdev_dec_pending(struct md_rdev *rdev, struct mddev *mddev)
 	}
 }
 
+extern struct md_cluster_operations *md_cluster_ops;
 #endif /* _MD_MD_H */

commit dfe15ac1c6ad301b092ed295f0cfdb16cfaf5cfa
Author: Hannes Reinecke <hare@suse.de>
Date:   Thu Jul 26 11:12:18 2012 +0200

    md: wakeup thread upon rdev_dec_pending()
    
    After each call to rdev_dec_pending() we should wakeup the
    md thread if the device is found to be faulty.
    Otherwise we'll incur heavy delays on failing devices.
    
    Signed-off-by: Neil Brown <nfbrown@suse.de>
    Signed-off-by: Hannes Reinecke <hare@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 14367d919351..318ca8fd430f 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -474,13 +474,6 @@ static inline int mddev_trylock(struct mddev *mddev)
 }
 extern void mddev_unlock(struct mddev *mddev);
 
-static inline void rdev_dec_pending(struct md_rdev *rdev, struct mddev *mddev)
-{
-	int faulty = test_bit(Faulty, &rdev->flags);
-	if (atomic_dec_and_test(&rdev->nr_pending) && faulty)
-		set_bit(MD_RECOVERY_NEEDED, &mddev->recovery);
-}
-
 static inline void md_sync_acct(struct block_device *bdev, unsigned long nr_sectors)
 {
 	atomic_add(nr_sectors, &bdev->bd_contains->bd_disk->sync_io);
@@ -666,4 +659,14 @@ static inline int mddev_check_plugged(struct mddev *mddev)
 	return !!blk_check_plugged(md_unplug, mddev,
 				   sizeof(struct blk_plug_cb));
 }
+
+static inline void rdev_dec_pending(struct md_rdev *rdev, struct mddev *mddev)
+{
+	int faulty = test_bit(Faulty, &rdev->flags);
+	if (atomic_dec_and_test(&rdev->nr_pending) && faulty) {
+		set_bit(MD_RECOVERY_NEEDED, &mddev->recovery);
+		md_wakeup_thread(mddev->thread);
+	}
+}
+
 #endif /* _MD_MD_H */

commit 5c47daf6e76f657d961a96d89f6419fde8eda557
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 15 12:57:01 2014 +1100

    md: move mddev_lock and related to md.h
    
    The one which is not inline (mddev_unlock) gets EXPORTed.
    
    This makes the locking available to personality modules so that it
    doesn't have to be imposed upon them.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 6bf3faa951ec..14367d919351 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -450,6 +450,30 @@ struct mddev {
 	void (*sync_super)(struct mddev *mddev, struct md_rdev *rdev);
 };
 
+static inline int __must_check mddev_lock(struct mddev *mddev)
+{
+	return mutex_lock_interruptible(&mddev->reconfig_mutex);
+}
+
+/* Sometimes we need to take the lock in a situation where
+ * failure due to interrupts is not acceptable.
+ */
+static inline void mddev_lock_nointr(struct mddev *mddev)
+{
+	mutex_lock(&mddev->reconfig_mutex);
+}
+
+static inline int mddev_is_locked(struct mddev *mddev)
+{
+	return mutex_is_locked(&mddev->reconfig_mutex);
+}
+
+static inline int mddev_trylock(struct mddev *mddev)
+{
+	return mutex_trylock(&mddev->reconfig_mutex);
+}
+extern void mddev_unlock(struct mddev *mddev);
+
 static inline void rdev_dec_pending(struct md_rdev *rdev, struct mddev *mddev)
 {
 	int faulty = test_bit(Faulty, &rdev->flags);

commit 23da422b1951cb8dbcb7c3090057cb6d5ceedf49
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 15 12:57:01 2014 +1100

    md: use mddev->lock to protect updates to resync_{min,max}.
    
    There are interdependencies between these two sysfs attributes
    and whether a resync is currently running.
    
    Rather than depending on reconfig_mutex to ensure no races when
    testing these interdependencies are met, use the spinlock.
    This will allow the mutex to be remove from protecting this
    code in a subsequent patch.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index b4fbd6a63fcf..6bf3faa951ec 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -394,6 +394,8 @@ struct mddev {
 	 *   pers (also protected by reconfig_mutex and pending IO).
 	 *   clearing ->bitmap
 	 *   clearing ->bitmap_info.file
+	 *   changing ->resync_{min,max}
+	 *   setting MD_RECOVERY_RUNNING (which interacts with resync_{min,max})
 	 */
 	spinlock_t			lock;
 	wait_queue_head_t		sb_wait;	/* for waiting on superblock updates */

commit 4af1a04176bdb4688aa14f6c10d1d5131c036a9d
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 15 12:57:00 2014 +1100

    md: move GET_BITMAP_FILE ioctl out from mddev_lock.
    
    It makes more sense to report bitmap_info->file, rather than
    bitmap->file (the later is only available once the array is
    active).
    
    With that change, use mddev->lock to protect bitmap_info being
    set to NULL, and we can call get_bitmap_file() without taking
    the mutex.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 8770308a8052..b4fbd6a63fcf 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -393,6 +393,7 @@ struct mddev {
 	 *   in_sync - and related safemode and MD_CHANGE changes
 	 *   pers (also protected by reconfig_mutex and pending IO).
 	 *   clearing ->bitmap
+	 *   clearing ->bitmap_info.file
 	 */
 	spinlock_t			lock;
 	wait_queue_head_t		sb_wait;	/* for waiting on superblock updates */

commit 978a7a47cae79ae7a7b5a1e80bfcaef6ee700312
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 15 12:56:58 2014 +1100

    md/bitmap: protect clearing of ->bitmap by mddev->lock
    
    This makes it safe to inspect the struct while holding only
    the spinlock.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index e41559dccdc9..8770308a8052 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -392,6 +392,7 @@ struct mddev {
 	 *   clearing MD_CHANGE_*
 	 *   in_sync - and related safemode and MD_CHANGE changes
 	 *   pers (also protected by reconfig_mutex and pending IO).
+	 *   clearing ->bitmap
 	 */
 	spinlock_t			lock;
 	wait_queue_head_t		sb_wait;	/* for waiting on superblock updates */

commit 36d091f4759d194c99f0705d412afe208622b45a
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 15 12:56:58 2014 +1100

    md: protect ->pers changes with mddev->lock
    
    ->pers is already protected by ->reconfig_mutex, and
    cannot possibly change when there are threads running or
    outstanding IO.
    
    However there are some places where we access ->pers
    not in a thread or IO context, and where ->reconfig_mutex
    is unnecessarily heavy-weight:  level_show and md_seq_show().
    
    So protect all changes, and those accesses, with ->lock.
    This is a step toward taking those accesses out from under
    reconfig_mutex.
    
    [Fixed missing "mddev->pers" -> "pers" conversion, thanks to
     Dan Carpenter <dan.carpenter@oracle.com>]
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 37e7c17e56a6..e41559dccdc9 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -391,6 +391,7 @@ struct mddev {
 	 *   rdev superblocks, events
 	 *   clearing MD_CHANGE_*
 	 *   in_sync - and related safemode and MD_CHANGE changes
+	 *   pers (also protected by reconfig_mutex and pending IO).
 	 */
 	spinlock_t			lock;
 	wait_queue_head_t		sb_wait;	/* for waiting on superblock updates */

commit afa0f557cb15176570a18fb2a093e348a793afd4
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 15 12:56:58 2014 +1100

    md: rename ->stop to ->free
    
    Now that the ->stop function only frees the private data,
    rename is accordingly.
    
    Also pass in the private pointer as an arg rather than using
    mddev->private.  This flexibility will be useful in level_store().
    
    Finally, don't clear ->private.  It doesn't make sense to clear
    it seeing that isn't what we free, and it is no longer necessary
    to clear ->private (it was some time ago before  ->to_remove was
    introduced).
    
    Setting ->to_remove in ->free() is a bit of a wart, but not a
    big problem at the moment.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index bee5b852c33f..37e7c17e56a6 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -465,7 +465,7 @@ struct md_personality
 	struct module *owner;
 	void (*make_request)(struct mddev *mddev, struct bio *bio);
 	int (*run)(struct mddev *mddev);
-	int (*stop)(struct mddev *mddev);
+	void (*free)(struct mddev *mddev, void *priv);
 	void (*status)(struct seq_file *seq, struct mddev *mddev);
 	/* error_handler must set ->faulty and clear ->in_sync
 	 * if appropriate, and should abort recovery if needed

commit 64590f45ddc7147fa1968147a1f5b5c436b728fe
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 15 12:56:57 2014 +1100

    md: make merge_bvec_fn more robust in face of personality changes.
    
    There is no locking around calls to merge_bvec_fn(), so
    it is possible that calls which coincide with a level (or personality)
    change could go wrong.
    
    So create a central dispatch point for these functions and use
    rcu_read_lock().
    If the array is suspended, reject any merge that can be rejected.
    If not, we know it is safe to call the function.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index f2602280fac1..bee5b852c33f 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -499,6 +499,10 @@ struct md_personality
 	/* congested implements bdi.congested_fn().
 	 * Will not be called while array is 'suspended' */
 	int (*congested)(struct mddev *mddev, int bits);
+	/* mergeable_bvec is use to implement ->merge_bvec_fn */
+	int (*mergeable_bvec)(struct mddev *mddev,
+			      struct bvec_merge_data *bvm,
+			      struct bio_vec *biovec);
 };
 
 struct md_sysfs_entry {

commit 5c675f83c68fbdf9c0e103c1090b06be747fa62c
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 15 12:56:56 2014 +1100

    md: make ->congested robust against personality changes.
    
    There is currently no locking around calls to the 'congested'
    bdi function.  If called at an awkward time while an array is
    being converted from one level (or personality) to another, there
    is a tiny chance of running code in an unreferenced module etc.
    
    So add a 'congested' function to the md_personality operations
    structure, and call it with appropriate locking from a central
    'mddev_congested'.
    
    When the array personality is changing the array will be 'suspended'
    so no IO is processed.
    If mddev_congested detects this, it simply reports that the
    array is congested, which is a safe guess.
    As mddev_suspend calls synchronize_rcu(), mddev_congested can
    avoid races by included the whole call inside an rcu_read_lock()
    region.
    This require that the congested functions for all subordinate devices
    can be run under rcu_lock.  Fortunately this is the case.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index f0d15bdd96d4..f2602280fac1 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -496,6 +496,9 @@ struct md_personality
 	 * array.
 	 */
 	void *(*takeover) (struct mddev *mddev);
+	/* congested implements bdi.congested_fn().
+	 * Will not be called while array is 'suspended' */
+	int (*congested)(struct mddev *mddev, int bits);
 };
 
 struct md_sysfs_entry {

commit 85572d7c75fd5b9fa3fc911e1c99c68ec74903a0
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 15 12:56:56 2014 +1100

    md: rename mddev->write_lock to mddev->lock
    
    This lock is used for (slightly) more than helping with writing
    superblocks, and it will soon be extended further.  So the
    name is inappropriate.
    
    Also, the _irq variant hasn't been needed since 2.6.37 as it is
    never taking from interrupt or bh context.
    
    So:
      -rename write_lock to lock
      -document what it protects
      -remove _irq ... except in md_flush_request() as there
         is no wait_event_lock() (with no _irq).  This can be
         cleaned up after appropriate changes to wait.h.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 03cec5bdcaae..f0d15bdd96d4 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -386,7 +386,13 @@ struct mddev {
 
 	struct work_struct del_work;	/* used for delayed sysfs removal */
 
-	spinlock_t			write_lock;
+	/* "lock" protects:
+	 *   flush_bio transition from NULL to !NULL
+	 *   rdev superblocks, events
+	 *   clearing MD_CHANGE_*
+	 *   in_sync - and related safemode and MD_CHANGE changes
+	 */
+	spinlock_t			lock;
 	wait_queue_head_t		sb_wait;	/* for waiting on superblock updates */
 	atomic_t			pending_writes;	/* number of active superblock writes */
 

commit f72ffdd68616e3697bc782b21c82197aeb480fd5
Author: NeilBrown <neilb@suse.de>
Date:   Tue Sep 30 14:23:59 2014 +1000

    md: remove unwanted white space from md.c
    
    My editor shows much of this is RED.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index a49d991f3fe1..03cec5bdcaae 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -1,15 +1,15 @@
 /*
    md.h : kernel internal structure of the Linux MD driver
           Copyright (C) 1996-98 Ingo Molnar, Gadi Oxman
-	  
+
    This program is free software; you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation; either version 2, or (at your option)
    any later version.
-   
+
    You should have received a copy of the GNU General Public License
    (for example /usr/src/linux/COPYING); if not, write to the Free
-   Software Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.  
+   Software Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 */
 
 #ifndef _MD_MD_H
@@ -56,7 +56,7 @@ struct md_rdev {
 	__u64		sb_events;
 	sector_t	data_offset;	/* start of data in array */
 	sector_t	new_data_offset;/* only relevant while reshaping */
-	sector_t 	sb_start;	/* offset of the super block (in 512byte sectors) */
+	sector_t	sb_start;	/* offset of the super block (in 512byte sectors) */
 	int		sb_size;	/* bytes in the superblock */
 	int		preferred_minor;	/* autorun support */
 
@@ -239,7 +239,7 @@ struct mddev {
 					minor_version,
 					patch_version;
 	int				persistent;
-	int 				external;	/* metadata is
+	int				external;	/* metadata is
 							 * managed externally */
 	char				metadata_type[17]; /* externally set*/
 	int				chunk_sectors;
@@ -248,7 +248,7 @@ struct mddev {
 	char				clevel[16];
 	int				raid_disks;
 	int				max_disks;
-	sector_t			dev_sectors; 	/* used size of
+	sector_t			dev_sectors;	/* used size of
 							 * component devices */
 	sector_t			array_sectors; /* exported array size */
 	int				external_size; /* size managed
@@ -312,7 +312,7 @@ struct mddev {
 	int				parallel_resync;
 
 	int				ok_start_degraded;
-	/* recovery/resync flags 
+	/* recovery/resync flags
 	 * NEEDED:   we might need to start a resync/recover
 	 * RUNNING:  a thread is running, or about to be started
 	 * SYNC:     actually doing a resync, not a recovery
@@ -392,20 +392,20 @@ struct mddev {
 
 	unsigned int			safemode;	/* if set, update "clean" superblock
 							 * when no writes pending.
-							 */ 
+							 */
 	unsigned int			safemode_delay;
 	struct timer_list		safemode_timer;
-	atomic_t			writes_pending; 
+	atomic_t			writes_pending;
 	struct request_queue		*queue;	/* for plugging ... */
 
-	struct bitmap                   *bitmap; /* the bitmap for the device */
+	struct bitmap			*bitmap; /* the bitmap for the device */
 	struct {
 		struct file		*file; /* the bitmap file */
 		loff_t			offset; /* offset from superblock of
 						 * start of bitmap. May be
 						 * negative, but not '0'
 						 * For external metadata, offset
-						 * from start of device. 
+						 * from start of device.
 						 */
 		unsigned long		space; /* space available at this offset */
 		loff_t			default_offset; /* this is the offset to use when
@@ -421,7 +421,7 @@ struct mddev {
 		int			external;
 	} bitmap_info;
 
-	atomic_t 			max_corr_read_errors; /* max read retries */
+	atomic_t			max_corr_read_errors; /* max read retries */
 	struct list_head		all_mddevs;
 
 	struct attribute_group		*to_remove;
@@ -439,7 +439,6 @@ struct mddev {
 	void (*sync_super)(struct mddev *mddev, struct md_rdev *rdev);
 };
 
-
 static inline void rdev_dec_pending(struct md_rdev *rdev, struct mddev *mddev)
 {
 	int faulty = test_bit(Faulty, &rdev->flags);
@@ -449,7 +448,7 @@ static inline void rdev_dec_pending(struct md_rdev *rdev, struct mddev *mddev)
 
 static inline void md_sync_acct(struct block_device *bdev, unsigned long nr_sectors)
 {
-        atomic_add(nr_sectors, &bdev->bd_contains->bd_disk->sync_io);
+	atomic_add(nr_sectors, &bdev->bd_contains->bd_disk->sync_io);
 }
 
 struct md_personality
@@ -463,7 +462,7 @@ struct md_personality
 	int (*stop)(struct mddev *mddev);
 	void (*status)(struct seq_file *seq, struct mddev *mddev);
 	/* error_handler must set ->faulty and clear ->in_sync
-	 * if appropriate, and should abort recovery if needed 
+	 * if appropriate, and should abort recovery if needed
 	 */
 	void (*error_handler)(struct mddev *mddev, struct md_rdev *rdev);
 	int (*hot_add_disk) (struct mddev *mddev, struct md_rdev *rdev);
@@ -493,7 +492,6 @@ struct md_personality
 	void *(*takeover) (struct mddev *mddev);
 };
 
-
 struct md_sysfs_entry {
 	struct attribute attr;
 	ssize_t (*show)(struct mddev *, char *);
@@ -560,7 +558,7 @@ struct md_thread {
 	void			(*run) (struct md_thread *thread);
 	struct mddev		*mddev;
 	wait_queue_head_t	wqueue;
-	unsigned long           flags;
+	unsigned long		flags;
 	struct task_struct	*tsk;
 	unsigned long		timeout;
 	void			*private;
@@ -594,7 +592,7 @@ extern void md_flush_request(struct mddev *mddev, struct bio *bio);
 extern void md_super_write(struct mddev *mddev, struct md_rdev *rdev,
 			   sector_t sector, int size, struct page *page);
 extern void md_super_wait(struct mddev *mddev);
-extern int sync_page_io(struct md_rdev *rdev, sector_t sector, int size, 
+extern int sync_page_io(struct md_rdev *rdev, sector_t sector, int size,
 			struct page *page, int rw, bool metadata_op);
 extern void md_do_sync(struct md_thread *thread);
 extern void md_new_event(struct mddev *mddev);

commit 035328c202d26a824b8632fd3b00635db5aee5a2
Author: NeilBrown <neilb@suse.de>
Date:   Wed Apr 9 12:25:40 2014 +1000

    md/bitmap: don't abuse i_writecount for bitmap files.
    
    md bitmap code currently tries to use i_writecount to stop any other
    process from writing to out bitmap file.  But that is really an abuse
    and has bit-rotted so locking is all wrong.
    
    So discard that - root should be allowed to shoot self in foot.
    
    Still use it in a much less intrusive way to stop the same file being
    used as bitmap on two different array, and apply other checks to
    ensure the file is at least vaguely usable for bitmap storage
    (is regular, is open for write.  Support for ->bmap is already checked
    elsewhere).
    
    Reported-by: Al Viro <viro@ZenIV.linux.org.uk>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 07bba96de260..a49d991f3fe1 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -605,7 +605,6 @@ extern int md_check_no_bitmap(struct mddev *mddev);
 extern int md_integrity_register(struct mddev *mddev);
 extern void md_integrity_add_rdev(struct md_rdev *rdev, struct mddev *mddev);
 extern int strict_strtoul_scaled(const char *cp, unsigned long *res, int scale);
-extern void restore_bitmap_write_access(struct file *file);
 
 extern void mddev_init(struct mddev *mddev);
 extern int md_run(struct mddev *mddev);

commit d3bad75a6d57416cf7478ca2a1e42f699bc17ec5
Merge: 9f67627a0fea db4aad209bc9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 20 15:49:44 2014 -0800

    Merge tag 'driver-core-3.14-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/driver-core
    
    Pull driver core / sysfs patches from Greg KH:
     "Here's the big driver core and sysfs patch set for 3.14-rc1.
    
      There's a lot of work here moving sysfs logic out into a "kernfs" to
      allow other subsystems to also have a virtual filesystem with the same
      attributes of sysfs (handle device disconnect, dynamic creation /
      removal as needed / unneeded, etc)
    
      This is primarily being done for the cgroups filesystem, but the goal
      is to also move debugfs to it when it is ready, solving all of the
      known issues in that filesystem as well.  The code isn't completed
      yet, but all should be stable now (there is a big section that was
      reverted due to problems found when testing)
    
      There's also some other smaller fixes, and a driver core addition that
      allows for a "collection" of objects, that the DRM people will be
      using soon (it's in this tree to make merges after -rc1 easier)
    
      All of this has been in linux-next with no reported issues"
    
    * tag 'driver-core-3.14-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/driver-core: (113 commits)
      kernfs: associate a new kernfs_node with its parent on creation
      kernfs: add struct dentry declaration in kernfs.h
      kernfs: fix get_active failure handling in kernfs_seq_*()
      Revert "kernfs: fix get_active failure handling in kernfs_seq_*()"
      Revert "kernfs: replace kernfs_node->u.completion with kernfs_root->deactivate_waitq"
      Revert "kernfs: remove KERNFS_ACTIVE_REF and add kernfs_lockdep()"
      Revert "kernfs: remove KERNFS_REMOVED"
      Revert "kernfs: restructure removal path to fix possible premature return"
      Revert "kernfs: invoke kernfs_unmap_bin_file() directly from __kernfs_remove()"
      Revert "kernfs: remove kernfs_addrm_cxt"
      Revert "kernfs: make kernfs_get_active() block if the node is deactivated but not removed"
      Revert "kernfs: implement kernfs_{de|re}activate[_self]()"
      Revert "kernfs, sysfs, driver-core: implement kernfs_remove_self() and its wrappers"
      Revert "pci: use device_remove_file_self() instead of device_schedule_callback()"
      Revert "scsi: use device_remove_file_self() instead of device_schedule_callback()"
      Revert "s390: use device_remove_file_self() instead of device_schedule_callback()"
      Revert "sysfs, driver-core: remove unused {sysfs|device}_schedule_callback_owner()"
      Revert "kernfs: remove unnecessary NULL check in __kernfs_remove()"
      kernfs: remove unnecessary NULL check in __kernfs_remove()
      drivers/base: provide an infrastructure for componentised subsystems
      ...

commit 8313b8e57f55b15e5b7f7fc5d1630bbf686a9a97
Author: NeilBrown <neilb@suse.de>
Date:   Thu Dec 12 10:13:33 2013 +1100

    md: fix problem when adding device to read-only array with bitmap.
    
    If an array is started degraded, and then the missing device
    is found it can be re-added and a minimal bitmap-based recovery
    will bring it fully up-to-date.
    
    If the array is read-only a recovery would not be allowed.
    But also if the array is read-only and the missing device was
    present very recently, then there could be no need for any
    recovery at all, so we simply include the device in the read-only
    array without any recovery.
    
    However... if the missing device was removed a little longer ago
    it could be missing some updates, but if a bitmap is present it will
    be conditionally accepted pending a bitmap-based update.  We don't
    currently detect this case properly and will include that old
    device into the read-only array with no recovery even though it really
    needs a recovery.
    
    This patch keeps track of whether a bitmap-based-recovery is really
    needed or not in the new Bitmap_sync rdev flag.  If that is set,
    then the device will not be added to a read-only array.
    
    Cc: Andrei Warkentin <andreiw@vmware.com>
    Fixes: d70ed2e4fafdbef0800e73942482bb075c21578b
    Cc: stable@vger.kernel.org (3.2+)
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 2f5cc8a7ef3e..0095ec84ffc7 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -129,6 +129,9 @@ struct md_rdev {
 enum flag_bits {
 	Faulty,			/* device is known to have a fault */
 	In_sync,		/* device is in_sync with rest of array */
+	Bitmap_sync,		/* ..actually, not quite In_sync.  Need a
+				 * bitmap-based recovery to get fully in sync
+				 */
 	Unmerged,		/* device is being added to array and should
 				 * be considerred for bvec_merge_fn but not
 				 * yet for actual IO

commit 324a56e16e44baecac3ca799fd216154145c14bf
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Dec 11 14:11:53 2013 -0500

    kernfs: s/sysfs_dirent/kernfs_node/ and rename its friends accordingly
    
    kernfs has just been separated out from sysfs and we're already in
    full conflict mode.  Nothing can make the situation any worse.  Let's
    take the chance to name things properly.
    
    This patch performs the following renames.
    
    * s/sysfs_elem_dir/kernfs_elem_dir/
    * s/sysfs_elem_symlink/kernfs_elem_symlink/
    * s/sysfs_elem_attr/kernfs_elem_file/
    * s/sysfs_dirent/kernfs_node/
    * s/sd/kn/ in kernfs proper
    * s/parent_sd/parent/
    * s/target_sd/target/
    * s/dir_sd/parent/
    * s/to_sysfs_dirent()/rb_to_kn()/
    * misc renames of local vars when they conflict with the above
    
    Because md, mic and gpio dig into sysfs details, this patch ends up
    modifying them.  All are sysfs_dirent renames and trivial.  While we
    can avoid these by introducing a dummy wrapping struct sysfs_dirent
    around kernfs_node, given the limited usage outside kernfs and sysfs
    proper, I don't think such workaround is called for.
    
    This patch is strictly rename only and doesn't introduce any
    functional difference.
    
    - mic / gpio renames were missing.  Spotted by kbuild test robot.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Linus Walleij <linus.walleij@linaro.org>
    Cc: Ashutosh Dixit <ashutosh.dixit@intel.com>
    Cc: kbuild test robot <fengguang.wu@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 2f5cc8a7ef3e..389a3c93cdb7 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -106,7 +106,7 @@ struct md_rdev {
 					   */
 	struct work_struct del_work;	/* used for delayed sysfs removal */
 
-	struct sysfs_dirent *sysfs_state; /* handle for 'state'
+	struct kernfs_node *sysfs_state; /* handle for 'state'
 					   * sysfs entry */
 
 	struct badblocks {
@@ -376,10 +376,10 @@ struct mddev {
 	sector_t			resync_max;	/* resync should pause
 							 * when it gets here */
 
-	struct sysfs_dirent		*sysfs_state;	/* handle for 'array_state'
+	struct kernfs_node		*sysfs_state;	/* handle for 'array_state'
 							 * file in sysfs.
 							 */
-	struct sysfs_dirent		*sysfs_action;  /* handle for 'sync_action' */
+	struct kernfs_node		*sysfs_action;  /* handle for 'sync_action' */
 
 	struct work_struct del_work;	/* used for delayed sysfs removal */
 
@@ -498,13 +498,13 @@ struct md_sysfs_entry {
 };
 extern struct attribute_group md_bitmap_group;
 
-static inline struct sysfs_dirent *sysfs_get_dirent_safe(struct sysfs_dirent *sd, char *name)
+static inline struct kernfs_node *sysfs_get_dirent_safe(struct kernfs_node *sd, char *name)
 {
 	if (sd)
 		return sysfs_get_dirent(sd, name);
 	return sd;
 }
-static inline void sysfs_notify_dirent_safe(struct sysfs_dirent *sd)
+static inline void sysfs_notify_dirent_safe(struct kernfs_node *sd)
 {
 	if (sd)
 		sysfs_notify_dirent(sd);

commit 0910c0bdf7c291a41bc21e40a97389c9d4c1960d
Merge: 2821fe6b00a1 e37459b8e2c7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Nov 14 12:08:14 2013 +0900

    Merge branch 'for-3.13/core' of git://git.kernel.dk/linux-block
    
    Pull block IO core updates from Jens Axboe:
     "This is the pull request for the core changes in the block layer for
      3.13.  It contains:
    
       - The new blk-mq request interface.
    
         This is a new and more scalable queueing model that marries the
         best part of the request based interface we currently have (which
         is fully featured, but scales poorly) and the bio based "interface"
         which the new drivers for high IOPS devices end up using because
         it's much faster than the request based one.
    
         The bio interface has no block layer support, since it taps into
         the stack much earlier.  This means that drivers end up having to
         implement a lot of functionality on their own, like tagging,
         timeout handling, requeue, etc.  The blk-mq interface provides all
         these.  Some drivers even provide a switch to select bio or rq and
         has code to handle both, since things like merging only works in
         the rq model and hence is faster for some workloads.  This is a
         huge mess.  Conversion of these drivers nets us a substantial code
         reduction.  Initial results on converting SCSI to this model even
         shows an 8x improvement on single queue devices.  So while the
         model was intended to work on the newer multiqueue devices, it has
         substantial improvements for "classic" hardware as well.  This code
         has gone through extensive testing and development, it's now ready
         to go.  A pull request is coming to convert virtio-blk to this
         model will be will be coming as well, with more drivers scheduled
         for 3.14 conversion.
    
       - Two blktrace fixes from Jan and Chen Gang.
    
       - A plug merge fix from Alireza Haghdoost.
    
       - Conversion of __get_cpu_var() from Christoph Lameter.
    
       - Fix for sector_div() with 64-bit divider from Geert Uytterhoeven.
    
       - A fix for a race between request completion and the timeout
         handling from Jeff Moyer.  This is what caused the merge conflict
         with blk-mq/core, in case you are looking at that.
    
       - A dm stacking fix from Mike Snitzer.
    
       - A code consolidation fix and duplicated code removal from Kent
         Overstreet.
    
       - A handful of block bug fixes from Mikulas Patocka, fixing a loop
         crash and memory corruption on blk cg.
    
       - Elevator switch bug fix from Tomoki Sekiyama.
    
      A heads-up that I had to rebase this branch.  Initially the immutable
      bio_vecs had been queued up for inclusion, but a week later, it became
      clear that it wasn't fully cooked yet.  So the decision was made to
      pull this out and postpone it until 3.14.  It was a straight forward
      rebase, just pruning out the immutable series and the later fixes of
      problems with it.  The rest of the patches applied directly and no
      further changes were made"
    
    * 'for-3.13/core' of git://git.kernel.dk/linux-block: (31 commits)
      block: replace IS_ERR and PTR_ERR with PTR_ERR_OR_ZERO
      block: replace IS_ERR and PTR_ERR with PTR_ERR_OR_ZERO
      block: Do not call sector_div() with a 64-bit divisor
      kernel: trace: blktrace: remove redundent memcpy() in compat_blk_trace_setup()
      block: Consolidate duplicated bio_trim() implementations
      block: Use rw_copy_check_uvector()
      block: Enable sysfs nomerge control for I/O requests in the plug list
      block: properly stack underlying max_segment_size to DM device
      elevator: acquire q->sysfs_lock in elevator_change()
      elevator: Fix a race in elevator switching and md device initialization
      block: Replace __get_cpu_var uses
      bdi: test bdi_init failure
      block: fix a probe argument to blk_register_region
      loop: fix crash if blk_alloc_queue fails
      blk-core: Fix memory corruption if blkcg_init_queue fails
      block: fix race between request completion and timeout handling
      blktrace: Send BLK_TN_PROCESS events to all running traces
      blk-mq: don't disallow request merges for req->special being set
      blk-mq: mq plug list breakage
      blk-mq: fix for flush deadlock
      ...

commit 6678d83f18386eb103f8345024e52c5abe61725c
Author: Kent Overstreet <kmo@daterainc.com>
Date:   Wed Aug 7 11:14:32 2013 -0700

    block: Consolidate duplicated bio_trim() implementations
    
    Someone cut and pasted md's md_trim_bio() into xen-blkfront.c. Come on,
    we should know better than this.
    
    Signed-off-by: Kent Overstreet <kmo@daterainc.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 608050c43f17..c96456c16700 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -617,7 +617,6 @@ extern struct bio *bio_clone_mddev(struct bio *bio, gfp_t gfp_mask,
 				   struct mddev *mddev);
 extern struct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,
 				   struct mddev *mddev);
-extern void md_trim_bio(struct bio *bio, int offset, int size);
 
 extern void md_unplug(struct blk_plug_cb *cb, bool from_schedule);
 static inline int mddev_check_plugged(struct mddev *mddev)

commit 388975cccaaf11abd47525f664c76891c440481a
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Sep 11 23:19:13 2013 -0400

    sysfs: clean up sysfs_get_dirent()
    
    The pre-existing sysfs interfaces which take explicit namespace
    argument are weird in that they place the optional @ns in front of
    @name which is contrary to the established convention.  For example,
    we end up forcing vast majority of sysfs_get_dirent() users to do
    sysfs_get_dirent(parent, NULL, name), which is silly and error-prone
    especially as @ns and @name may be interchanged without causing
    compilation warning.
    
    This renames sysfs_get_dirent() to sysfs_get_dirent_ns() and swap the
    positions of @name and @ns, and sysfs_get_dirent() is now a wrapper
    around sysfs_get_dirent_ns().  This makes confusions a lot less
    likely.
    
    There are other interfaces which take @ns before @name.  They'll be
    updated by following patches.
    
    This patch doesn't introduce any functional changes.
    
    v2: EXPORT_SYMBOL_GPL() wasn't updated leading to undefined symbol
        error on module builds.  Reported by build test robot.  Fixed.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Kay Sievers <kay@vrfy.org>
    Cc: Fengguang Wu <fengguang.wu@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 608050c43f17..b0051f2fbc0c 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -501,7 +501,7 @@ extern struct attribute_group md_bitmap_group;
 static inline struct sysfs_dirent *sysfs_get_dirent_safe(struct sysfs_dirent *sd, char *name)
 {
 	if (sd)
-		return sysfs_get_dirent(sd, NULL, name);
+		return sysfs_get_dirent(sd, name);
 	return sd;
 }
 static inline void sysfs_notify_dirent_safe(struct sysfs_dirent *sd)

commit 260fa034ef7a4ff8b73068b48ac497edd5217491
Author: NeilBrown <neilb@suse.de>
Date:   Tue Aug 27 16:44:13 2013 +1000

    md: avoid deadlock when dirty buffers during md_stop.
    
    When the last process closes /dev/mdX sync_blockdev will be called so
    that all buffers get flushed.
    So if it is then opened for the STOP_ARRAY ioctl to be sent there will
    be nothing to flush.
    
    However if we open /dev/mdX in order to send the STOP_ARRAY ioctl just
    moments before some other process which was writing closes their file
    descriptor, then there won't be a 'last close' and the buffers might
    not get flushed.
    
    So do_md_stop() calls sync_blockdev().  However at this point it is
    holding ->reconfig_mutex.  So if the array is currently 'clean' then
    the writes from sync_blockdev() will not complete until the array
    can be marked dirty and that won't happen until some other thread
    can get ->reconfig_mutex.  So we deadlock.
    
    We need to move the sync_blockdev() call to before we take
    ->reconfig_mutex.
    However then some other thread could open /dev/mdX and write to it
    after we call sync_blockdev() and before we actually stop the array.
    This can leave dirty data in the page cache which is awkward.
    
    So introduce new flag MD_STILL_CLOSED.  Set it before calling
    sync_blockdev(), clear it if anyone does open the file, and abort the
    STOP_ARRAY attempt if it gets set before we lock against further
    opens.
    
    It is still possible to get problems if you open /dev/mdX, write to
    it, then issue the STOP_ARRAY ioctl.  Just don't do that.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 53283beda21b..608050c43f17 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -211,6 +211,9 @@ struct mddev {
 #define MD_CHANGE_PENDING 2	/* switch from 'clean' to 'active' in progress */
 #define MD_UPDATE_SB_FLAGS (1 | 2 | 4)	/* If these are set, md_update_sb needed */
 #define MD_ARRAY_FIRST_USE 3    /* First use of array, needs initialization */
+#define MD_STILL_CLOSED	4	/* If set, then array has not been opened since
+				 * md_ioctl checked on it.
+				 */
 
 	int				suspended;
 	atomic_t			active_io;

commit 7a0a5355cbc71efa430c3730ffbd67ae04abfe31
Author: NeilBrown <neilb@suse.de>
Date:   Tue Aug 27 16:28:23 2013 +1000

    md: Don't test all of mddev->flags at once.
    
    mddev->flags is mostly used to record if an update of the
    metadata is needed.  Sometimes the whole field is tested
    instead of just the important bits.  This makes it difficult
    to introduce more state bits.
    
    So replace all bare tests of mddev->flags with tests for the bits
    that actually need testing.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 20f02c0b5f2d..53283beda21b 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -204,11 +204,12 @@ struct mddev {
 	struct md_personality		*pers;
 	dev_t				unit;
 	int				md_minor;
-	struct list_head 		disks;
+	struct list_head		disks;
 	unsigned long			flags;
 #define MD_CHANGE_DEVS	0	/* Some device status has changed */
 #define MD_CHANGE_CLEAN 1	/* transition to or from 'clean' */
 #define MD_CHANGE_PENDING 2	/* switch from 'clean' to 'active' in progress */
+#define MD_UPDATE_SB_FLAGS (1 | 2 | 4)	/* If these are set, md_update_sb needed */
 #define MD_ARRAY_FIRST_USE 3    /* First use of array, needs initialization */
 
 	int				suspended;
@@ -218,7 +219,7 @@ struct mddev {
 						       * are happening, so run/
 						       * takeover/stop are not safe
 						       */
-	int				ready; /* See when safe to pass 
+	int				ready; /* See when safe to pass
 						* IO requests down */
 	struct gendisk			*gendisk;
 

commit c4a39551451666229b4ea5e8aae8ca0131d00665
Author: Jonathan Brassow <jbrassow@redhat.com>
Date:   Tue Jun 25 01:23:59 2013 -0500

    MD: Remember the last sync operation that was performed
    
    MD:  Remember the last sync operation that was performed
    
    This patch adds a field to the mddev structure to track the last
    sync operation that was performed.  This is especially useful when
    it comes to what is recorded in mismatch_cnt in sysfs.  If the
    last operation was "data-check", then it reports the number of
    descrepancies found by the user-initiated check.  If it was a
    "repair" operation, then it is reporting the number of
    descrepancies repaired.  etc.
    
    Signed-off-by: Jonathan Brassow <jbrassow@redhat.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 653f992b687a..20f02c0b5f2d 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -268,6 +268,14 @@ struct mddev {
 
 	struct md_thread		*thread;	/* management thread */
 	struct md_thread		*sync_thread;	/* doing resync or reconstruct */
+
+	/* 'last_sync_action' is initialized to "none".  It is set when a
+	 * sync operation (i.e "data-check", "requested-resync", "resync",
+	 * "recovery", or "reshape") is started.  It holds this value even
+	 * when the sync thread is "frozen" (interrupted) or "idle" (stopped
+	 * or finished).  It is overwritten when a new sync operation is begun.
+	 */
+	char				*last_sync_action;
 	sector_t			curr_resync;	/* last block scheduled */
 	/* As resync requests can complete out of order, we cannot easily track
 	 * how much resync has been completed.  So we occasionally pause until

commit a91d5ac04841ca1be340e8610e6d899fc8b419b5
Author: Jonathan Brassow <jbrassow@redhat.com>
Date:   Wed Apr 24 11:42:43 2013 +1000

    MD: Export 'md_reap_sync_thread' function
    
    MD: Export 'md_reap_sync_thread' function
    
    Make 'md_reap_sync_thread' available to other files, specifically dm-raid.c.
    - rename reap_sync_thread to md_reap_sync_thread
    - move the fn after md_check_recovery to match md.h declaration placement
    - export md_reap_sync_thread
    
    Signed-off-by: Jonathan Brassow <jbrassow@redhat.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index d90fb1a879e1..653f992b687a 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -567,6 +567,7 @@ extern struct md_thread *md_register_thread(
 extern void md_unregister_thread(struct md_thread **threadp);
 extern void md_wakeup_thread(struct md_thread *thread);
 extern void md_check_recovery(struct mddev *mddev);
+extern void md_reap_sync_thread(struct mddev *mddev);
 extern void md_write_start(struct mddev *mddev, struct bio *bi);
 extern void md_write_end(struct mddev *mddev);
 extern void md_done_sync(struct mddev *mddev, int blocks, int ok);

commit 90584fc93d461520a888f691144f0879283b3624
Author: Jonathan Brassow <jbrassow@redhat.com>
Date:   Thu Mar 7 16:24:26 2013 -0600

    MD: Prevent sysfs operations on uninitialized kobjects
    
    MD: Prevent sysfs operations on uninitialized kobjects
    
    Device-mapper does not use sysfs; but when device-mapper is leveraging
    MD's RAID personalities, MD sometimes attempts to update sysfs.  This
    patch adds checks for 'mddev-kobj.sd' in sysfs_[un]link_rdev to ensure
    it is about to operate on something valid.  This patch also checks for
    'mddev->kobj.sd' before calling 'sysfs_notify' in 'remove_and_add_spares'.
    Although 'sysfs_notify' already makes this check, doing so in
    'remove_and_add_spares' prevents an additional mutex operation.
    
    Signed-off-by: Jonathan Brassow <jbrassow@redhat.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index eca59c3074ef..d90fb1a879e1 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -506,7 +506,7 @@ static inline char * mdname (struct mddev * mddev)
 static inline int sysfs_link_rdev(struct mddev *mddev, struct md_rdev *rdev)
 {
 	char nm[20];
-	if (!test_bit(Replacement, &rdev->flags)) {
+	if (!test_bit(Replacement, &rdev->flags) && mddev->kobj.sd) {
 		sprintf(nm, "rd%d", rdev->raid_disk);
 		return sysfs_create_link(&mddev->kobj, &rdev->kobj, nm);
 	} else
@@ -516,7 +516,7 @@ static inline int sysfs_link_rdev(struct mddev *mddev, struct md_rdev *rdev)
 static inline void sysfs_unlink_rdev(struct mddev *mddev, struct md_rdev *rdev)
 {
 	char nm[20];
-	if (!test_bit(Replacement, &rdev->flags)) {
+	if (!test_bit(Replacement, &rdev->flags) && mddev->kobj.sd) {
 		sprintf(nm, "rd%d", rdev->raid_disk);
 		sysfs_remove_link(&mddev->kobj, nm);
 	}

commit ea88eeac0cb8328014b53d80ca631e8dc0dc18dc
Merge: 848b81415c42 a9add5d92b64
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 18 09:32:44 2012 -0800

    Merge tag 'md-3.8' of git://neil.brown.name/md
    
    Pull md update from Neil Brown:
     "Mostly just little fixes.  Probably biggest part is AVX accelerated
      RAID6 calculations."
    
    * tag 'md-3.8' of git://neil.brown.name/md:
      md/raid5: add blktrace calls
      md/raid5: use async_tx_quiesce() instead of open-coding it.
      md: Use ->curr_resync as last completed request when cleanly aborting resync.
      lib/raid6: build proper files on corresponding arch
      lib/raid6: Add AVX2 optimized gen_syndrome functions
      lib/raid6: Add AVX2 optimized recovery functions
      md: Update checkpoint of resync/recovery based on time.
      md:Add place to update ->recovery_cp.
      md.c: re-indent various 'switch' statements.
      md: close race between removing and adding a device.
      md: removed unused variable in calc_sb_1_csm.

commit 0a19caabf01ac138bf3668786939e50ea4d9c8ac
Author: majianpeng <majianpeng@gmail.com>
Date:   Mon Nov 19 19:57:34 2012 +0800

    md: Use ->curr_resync as last completed request when cleanly aborting resync.
    
    If a resync is aborted cleanly, ->curr_resync is a reliable
    record of where we got up to.
    If there was an error it is less reliable but we always know that
    ->curr_resync_completed is safe.
    
    So add a flag MD_RECOVERY_ERROR to differentiate between these cases
    and set recovery_cp accordingly.
    
    Signed-off-by: Jianpeng Ma <majianpeng@gmail.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index af443ab868db..c29e62ebc488 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -307,6 +307,7 @@ struct mddev {
 	 * REQUEST:  user-space has requested a sync (used with SYNC)
 	 * CHECK:    user-space request for check-only, no repair
 	 * RESHAPE:  A reshape is happening
+	 * ERROR:    sync-action interrupted because io-error
 	 *
 	 * If neither SYNC or RESHAPE are set, then it is a recovery.
 	 */
@@ -320,6 +321,7 @@ struct mddev {
 #define	MD_RECOVERY_CHECK	7
 #define MD_RECOVERY_RESHAPE	8
 #define	MD_RECOVERY_FROZEN	9
+#define	MD_RECOVERY_ERROR	10
 
 	unsigned long			recovery;
 	/* If a RAID personality determines that recovery (of a particular

commit eed8c02e680c04cd737e0a9cef74e68d8eb0cefa
Author: Lukas Czerner <lczerner@redhat.com>
Date:   Fri Nov 30 11:42:40 2012 +0100

    wait: add wait_event_lock_irq() interface
    
    New wait_event{_interruptible}_lock_irq{_cmd} macros added. This commit
    moves the private wait_event_lock_irq() macro from MD to regular wait
    includes, introduces new macro wait_event_lock_irq_cmd() instead of using
    the old method with omitting cmd parameter which is ugly and makes a use
    of new macros in the MD. It also introduces the _interruptible_ variant.
    
    The use of new interface is when one have a special lock to protect data
    structures used in the condition, or one also needs to invoke "cmd"
    before putting it to sleep.
    
    All new macros are expected to be called with the lock taken. The lock
    is released before sleep and is reacquired afterwards. We will leave the
    macro with the lock held.
    
    Note to DM: IMO this should also fix theoretical race on waitqueue while
    using simultaneously wait_event_lock_irq() and wait_event() because of
    lack of locking around current state setting and wait queue removal.
    
    Signed-off-by: Lukas Czerner <lczerner@redhat.com>
    Cc: Neil Brown <neilb@suse.de>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index af443ab868db..1e2fc3d9c74c 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -551,32 +551,6 @@ struct md_thread {
 
 #define THREAD_WAKEUP  0
 
-#define __wait_event_lock_irq(wq, condition, lock, cmd) 		\
-do {									\
-	wait_queue_t __wait;						\
-	init_waitqueue_entry(&__wait, current);				\
-									\
-	add_wait_queue(&wq, &__wait);					\
-	for (;;) {							\
-		set_current_state(TASK_UNINTERRUPTIBLE);		\
-		if (condition)						\
-			break;						\
-		spin_unlock_irq(&lock);					\
-		cmd;							\
-		schedule();						\
-		spin_lock_irq(&lock);					\
-	}								\
-	current->state = TASK_RUNNING;					\
-	remove_wait_queue(&wq, &__wait);				\
-} while (0)
-
-#define wait_event_lock_irq(wq, condition, lock, cmd) 			\
-do {									\
-	if (condition)	 						\
-		break;							\
-	__wait_event_lock_irq(wq, condition, lock, cmd);		\
-} while (0)
-
 static inline void safe_put_page(struct page *p)
 {
 	if (p) put_page(p);

commit 7f7583d420231b9d09897afd57a957011b606a5b
Author: Jianpeng Ma <majianpeng@gmail.com>
Date:   Thu Oct 11 14:17:59 2012 +1100

    Subject: [PATCH] md:change resync_mismatches to atomic64_t to avoid races
    
    Now that multiple threads can handle stripes, it is safer to
    use an atomic64_t for resync_mismatches, to avoid update races.
    
    Signed-off-by: Jianpeng Ma <majianpeng@gmail.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 93ada214b50e..af443ab868db 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -282,7 +282,7 @@ struct mddev {
 
 	sector_t			resync_max_sectors; /* may be set by personality */
 
-	sector_t			resync_mismatches; /* count of sectors where
+	atomic64_t			resync_mismatches; /* count of sectors where
 							    * parity/replica mismatch found
 							    */
 

commit 4ed8731d8e6bd2a88a30697fbf4f7e6e979a6c46
Author: Shaohua Li <shli@kernel.org>
Date:   Thu Oct 11 13:34:00 2012 +1100

    MD: change the parameter of md thread
    
    Change the thread parameter, so the thread can carry extra info. Next patch
    will use it.
    
    Signed-off-by: Shaohua Li <shli@fusionio.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index f385b038589d..93ada214b50e 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -540,12 +540,13 @@ static inline void sysfs_unlink_rdev(struct mddev *mddev, struct md_rdev *rdev)
 	list_for_each_entry_rcu(rdev, &((mddev)->disks), same_set)
 
 struct md_thread {
-	void			(*run) (struct mddev *mddev);
+	void			(*run) (struct md_thread *thread);
 	struct mddev		*mddev;
 	wait_queue_head_t	wqueue;
 	unsigned long           flags;
 	struct task_struct	*tsk;
 	unsigned long		timeout;
+	void			*private;
 };
 
 #define THREAD_WAKEUP  0
@@ -584,7 +585,7 @@ static inline void safe_put_page(struct page *p)
 extern int register_md_personality(struct md_personality *p);
 extern int unregister_md_personality(struct md_personality *p);
 extern struct md_thread *md_register_thread(
-	void (*run)(struct mddev *mddev),
+	void (*run)(struct md_thread *thread),
 	struct mddev *mddev,
 	const char *name);
 extern void md_unregister_thread(struct md_thread **threadp);
@@ -603,7 +604,7 @@ extern void md_super_write(struct mddev *mddev, struct md_rdev *rdev,
 extern void md_super_wait(struct mddev *mddev);
 extern int sync_page_io(struct md_rdev *rdev, sector_t sector, int size, 
 			struct page *page, int rw, bool metadata_op);
-extern void md_do_sync(struct mddev *mddev);
+extern void md_do_sync(struct md_thread *thread);
 extern void md_new_event(struct mddev *mddev);
 extern int md_allow_write(struct mddev *mddev);
 extern void md_wait_for_blocked_rdev(struct md_rdev *rdev, struct mddev *mddev);

commit 74018dc3063a2c729fc73041c0a9f03aac995920
Author: NeilBrown <neilb@suse.de>
Date:   Tue Jul 31 09:08:15 2012 +0200

    blk: pass from_schedule to non-request unplug functions.
    
    This will allow md/raid to know why the unplug was called,
    and will be able to act according - if !from_schedule it
    is safe to perform tasks which could themselves schedule.
    
    Signed-off-by: NeilBrown <neilb@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 8f998e08fb87..f385b038589d 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -629,7 +629,7 @@ extern struct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,
 				   struct mddev *mddev);
 extern void md_trim_bio(struct bio *bio, int offset, int size);
 
-extern void md_unplug(struct blk_plug_cb *cb);
+extern void md_unplug(struct blk_plug_cb *cb, bool from_schedule);
 static inline int mddev_check_plugged(struct mddev *mddev)
 {
 	return !!blk_check_plugged(md_unplug, mddev,

commit 9cbb17508808f8a6bdd83354b61e126ac4fa6fed
Author: NeilBrown <neilb@suse.de>
Date:   Tue Jul 31 09:08:14 2012 +0200

    blk: centralize non-request unplug handling.
    
    Both md and umem has similar code for getting notified on an
    blk_finish_plug event.
    Centralize this code in block/ and allow each driver to
    provide its distinctive difference.
    
    Signed-off-by: NeilBrown <neilb@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 91786c46b85c..8f998e08fb87 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -627,6 +627,12 @@ extern struct bio *bio_clone_mddev(struct bio *bio, gfp_t gfp_mask,
 				   struct mddev *mddev);
 extern struct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,
 				   struct mddev *mddev);
-extern int mddev_check_plugged(struct mddev *mddev);
 extern void md_trim_bio(struct bio *bio, int offset, int size);
+
+extern void md_unplug(struct blk_plug_cb *cb);
+static inline int mddev_check_plugged(struct mddev *mddev)
+{
+	return !!blk_check_plugged(md_unplug, mddev,
+				   sizeof(struct blk_plug_cb));
+}
 #endif /* _MD_MD_H */

commit 0021b7bc045e4b0b85d8c53614342aaf84ca96a5
Author: NeilBrown <neilb@suse.de>
Date:   Tue Jul 31 09:08:14 2012 +0200

    md: remove plug_cnt feature of plugging.
    
    This seemed like a good idea at the time, but after further thought I
    cannot see it making a difference other than very occasionally and
    testing to try to exercise the case it is most likely to help did not
    show any performance difference by removing it.
    
    So remove the counting of active plugs and allow 'pending writes' to
    be activated at any time, not just when no plugs are active.
    
    This is only relevant when there is a write-intent bitmap, and the
    updating of the bitmap will likely introduce enough delay that
    the single-threading of bitmap updates will be enough to collect large
    numbers of updates together.
    
    Removing this will make it easier to centralise the unplug code, and
    will clear the other for other unplug enhancements which have a
    measurable effect.
    
    Signed-off-by: NeilBrown <neilb@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 7b4a3c318cae..91786c46b85c 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -266,9 +266,6 @@ struct mddev {
 	int				new_chunk_sectors;
 	int				reshape_backwards;
 
-	atomic_t			plug_cnt;	/* If device is expecting
-							 * more bios soon.
-							 */
 	struct md_thread		*thread;	/* management thread */
 	struct md_thread		*sync_thread;	/* doing resync or reconstruct */
 	sector_t			curr_resync;	/* last block scheduled */

commit 6409bb05a9831f6af36a20b97cda13059c2ef1b6
Author: NeilBrown <neilb@suse.de>
Date:   Tue May 22 13:55:07 2012 +1000

    md/bitmap: add new 'space' attribute for bitmaps.
    
    If we are to allow bitmaps to be resized when the array is resized,
    we need to know how much space there is.
    
    So create an attribute to store this information and set appropriate
    defaults.
    
    It can be set more precisely via sysfs, or future metadata extensions
    may allow it to be recorded.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 360937389e64..7b4a3c318cae 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -393,10 +393,13 @@ struct mddev {
 						 * For external metadata, offset
 						 * from start of device. 
 						 */
+		unsigned long		space; /* space available at this offset */
 		loff_t			default_offset; /* this is the offset to use when
 							 * hot-adding a bitmap.  It should
 							 * eventually be settable by sysfs.
 							 */
+		unsigned long		default_space; /* space available at
+							* default offset */
 		struct mutex		mutex;
 		unsigned long		chunksize;
 		unsigned long		daemon_sleep; /* how many jiffies between updates? */

commit 545c87957f4d53867b62921625f36df8c4b1bc08
Author: NeilBrown <neilb@suse.de>
Date:   Tue May 22 13:54:30 2012 +1000

    md: dm-raid should call helper function to clear rdev.
    
    dm-raid currently open-codes the freeing of some members of
    and rdev.  It is more maintainable to have it call common code
    from md.c which does this for all call-sites.
    
    So remove free_disk_sb to md_rdev_clear, export it, and use it in
    dm-raid.c
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 98913e8dac1a..360937389e64 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -619,6 +619,7 @@ extern int md_run(struct mddev *mddev);
 extern void md_stop(struct mddev *mddev);
 extern void md_stop_writes(struct mddev *mddev);
 extern int md_rdev_init(struct md_rdev *rdev);
+extern void md_rdev_clear(struct md_rdev *rdev);
 
 extern void mddev_suspend(struct mddev *mddev);
 extern void mddev_resume(struct mddev *mddev);

commit c6563a8c38fde3c1c7fc925a10bde3ca20799301
Author: NeilBrown <neilb@suse.de>
Date:   Mon May 21 09:27:00 2012 +1000

    md: add possibility to change data-offset for devices.
    
    When reshaping we can avoid costly intermediate backup by
    changing the 'start' address of the array on the device
    (if there is enough room).
    
    So as a first step, allow such a change to be requested
    through sysfs, and recorded in v1.x metadata.
    
    (As we didn't previous check that all 'pad' fields were zero,
     we need a new FEATURE flag for this.
     A (belatedly) check that all remaining 'pad' fields are
     zero to avoid a repeat of this)
    
    The new data offset must be requested separately for each device.
    This allows each to have a different change in the data offset.
    This is not likely to be used often but as data_offset can be
    set per-device, new_data_offset should be too.
    
    This patch also removes the 'acknowledged' arg to rdev_set_badblocks as
    it is never used and never will be.  At the same time we add a new
    arg ('in_new') which is currently always zero but will be used more
    soon.
    
    When a reshape finishes we will need to update the data_offset
    and rdev->sectors.  So provide an exported function to do that.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index d51c0ca37777..98913e8dac1a 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -55,6 +55,7 @@ struct md_rdev {
 	int		sb_loaded;
 	__u64		sb_events;
 	sector_t	data_offset;	/* start of data in array */
+	sector_t	new_data_offset;/* only relevant while reshaping */
 	sector_t 	sb_start;	/* offset of the super block (in 512byte sectors) */
 	int		sb_size;	/* bytes in the superblock */
 	int		preferred_minor;	/* autorun support */
@@ -193,8 +194,9 @@ static inline int is_badblock(struct md_rdev *rdev, sector_t s, int sectors,
 	return 0;
 }
 extern int rdev_set_badblocks(struct md_rdev *rdev, sector_t s, int sectors,
-			      int acknowledged);
-extern int rdev_clear_badblocks(struct md_rdev *rdev, sector_t s, int sectors);
+			      int is_new);
+extern int rdev_clear_badblocks(struct md_rdev *rdev, sector_t s, int sectors,
+				int is_new);
 extern void md_ack_all_badblocks(struct badblocks *bb);
 
 struct mddev {
@@ -592,6 +594,7 @@ extern void md_write_start(struct mddev *mddev, struct bio *bi);
 extern void md_write_end(struct mddev *mddev);
 extern void md_done_sync(struct mddev *mddev, int blocks, int ok);
 extern void md_error(struct mddev *mddev, struct md_rdev *rdev);
+extern void md_finish_reshape(struct mddev *mddev);
 
 extern int mddev_congested(struct mddev *mddev, int bits);
 extern void md_flush_request(struct mddev *mddev, struct bio *bio);

commit 2c810cddc44d6f95cef75df3f07fc0850ff92417
Author: NeilBrown <neilb@suse.de>
Date:   Mon May 21 09:27:00 2012 +1000

    md: allow a reshape operation to be reversed.
    
    Currently a reshape operation always progresses from the start
    of the array to the end unless the number of devices is being
    reduced, in which case it progressed in the opposite direction.
    
    To reverse a partial reshape which changes the number of devices
    you can stop the array and re-assemble with the raid-disks numbers
    reversed and it will undo.
    
    However for a reshape that does not change the number of devices
    it is not possible to reverse the reshape in the middle - you have to
    wait until it completes.
    
    So add a 'reshape_direction' attribute with is either 'forwards' or
    'backwards' and can be explicitly set when delta_disks is zero.
    
    This will become more important when we allow the data_offset to
    change in a reshape.  Then the explicit statement of what direction is
    being used will be more useful.
    
    This can be enabled in raid5 trivially as it already supports
    reverse reshape and just needs to use a different trigger to request it.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 1c2063ccf48e..d51c0ca37777 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -262,6 +262,7 @@ struct mddev {
 	sector_t			reshape_position;
 	int				delta_disks, new_level, new_layout;
 	int				new_chunk_sectors;
+	int				reshape_backwards;
 
 	atomic_t			plug_cnt;	/* If device is expecting
 							 * more bios soon.

commit 050b66152f87c79e8d66aed0e7996f9336462d5f
Author: NeilBrown <neilb@suse.de>
Date:   Mon Mar 19 12:46:39 2012 +1100

    md/raid10: handle merge_bvec_fn in member devices.
    
    Currently we don't honour merge_bvec_fn in member devices so if there
    is one, we force all requests to be single-page at most.
    This is not ideal.
    
    So enhance the raid10 merge_bvec_fn to check that function in children
    as well.
    
    This introduces a small problem.  There is no locking around calls
    the ->merge_bvec_fn and subsequent calls to ->make_request.  So a
    device added between these could end up getting a request which
    violates its merge_bvec_fn.
    
    Currently the best we can do is synchronize_sched().  This will work
    providing no preemption happens.  If there is preemption, we just
    have to hope that new devices are largely consistent with old devices.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 39acfe90cc26..1c2063ccf48e 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -128,6 +128,10 @@ struct md_rdev {
 enum flag_bits {
 	Faulty,			/* device is known to have a fault */
 	In_sync,		/* device is in_sync with rest of array */
+	Unmerged,		/* device is being added to array and should
+				 * be considerred for bvec_merge_fn but not
+				 * yet for actual IO
+				 */
 	WriteMostly,		/* Avoid reading if at all possible */
 	AutoDetected,		/* added by auto-detect */
 	Blocked,		/* An error occurred but has not yet
@@ -345,6 +349,10 @@ struct mddev {
 	int				degraded;	/* whether md should consider
 							 * adding a spare
 							 */
+	int				merge_check_needed; /* at least one
+							     * member device
+							     * has a
+							     * merge_bvec_fn */
 
 	atomic_t			recovery_active; /* blocks scheduled, but not written */
 	wait_queue_head_t		recovery_wait;

commit dafb20fa34320a472deb7442f25a0c086e0feb33
Author: NeilBrown <neilb@suse.de>
Date:   Mon Mar 19 12:46:39 2012 +1100

    md: tidy up rdev_for_each usage.
    
    md.h has an 'rdev_for_each()' macro for iterating the rdevs in an
    mddev.  However it uses the 'safe' version of list_for_each_entry,
    and so requires the extra variable, but doesn't include 'safe' in the
    name, which is useful documentation.
    
    Consequently some places use this safe version without needing it, and
    many use an explicity list_for_each entry.
    
    So:
     - rename rdev_for_each to rdev_for_each_safe
     - create a new rdev_for_each which uses the plain
       list_for_each_entry,
     - use the 'safe' version only where needed, and convert all other
       list_for_each_entry calls to use rdev_for_each.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 44c63dfeeb2b..39acfe90cc26 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -519,7 +519,10 @@ static inline void sysfs_unlink_rdev(struct mddev *mddev, struct md_rdev *rdev)
 /*
  * iterates through the 'same array disks' ringlist
  */
-#define rdev_for_each(rdev, tmp, mddev)				\
+#define rdev_for_each(rdev, mddev)				\
+	list_for_each_entry(rdev, &((mddev)->disks), same_set)
+
+#define rdev_for_each_safe(rdev, tmp, mddev)				\
 	list_for_each_entry_safe(rdev, tmp, &((mddev)->disks), same_set)
 
 #define rdev_for_each_rcu(rdev, mddev)				\

commit 2d78f8c451785f030ac1676a18691896b59c69d8
Author: NeilBrown <neilb@suse.de>
Date:   Fri Dec 23 10:17:51 2011 +1100

    md: create externally visible flags for supporting hot-replace.
    
    hot-replace is a feature being added to md which will allow a
    device to be replaced without removing it from the array first.
    
    With hot-replace a spare can be activated and recovery can start while
    the original device is still in place, thus allowing a transition from
    an unreliable device to a reliable device without leaving the array
    degraded during the transition.  It can also be use when the original
    device is still reliable but it not wanted for some reason.
    
    This will eventually be supported in RAID4/5/6 and RAID10.
    
    This patch adds a super-block flag to distinguish the replacement
    device.  If an old kernel sees this flag it will reject the device.
    
    It also adds two per-device flags which are viewable and settable via
    sysfs.
       "want_replacement" can be set to request that a device be replaced.
       "replacement" is set to show that this device is replacing another
       device.
    
    The "rd%d" links in /sys/block/mdXx/md only apply to the original
    device, not the replacement.  We currently don't make links for the
    replacement - there doesn't seem to be a need.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 670c10e6b484..44c63dfeeb2b 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -72,34 +72,7 @@ struct md_rdev {
 	 * This reduces the burden of testing multiple flags in many cases
 	 */
 
-	unsigned long	flags;
-#define	Faulty		1		/* device is known to have a fault */
-#define	In_sync		2		/* device is in_sync with rest of array */
-#define	WriteMostly	4		/* Avoid reading if at all possible */
-#define	AutoDetected	7		/* added by auto-detect */
-#define Blocked		8		/* An error occurred but has not yet
-					 * been acknowledged by the metadata
-					 * handler, so don't allow writes
-					 * until it is cleared */
-#define WriteErrorSeen	9		/* A write error has been seen on this
-					 * device
-					 */
-#define FaultRecorded	10		/* Intermediate state for clearing
-					 * Blocked.  The Fault is/will-be
-					 * recorded in the metadata, but that
-					 * metadata hasn't been stored safely
-					 * on disk yet.
-					 */
-#define BlockedBadBlocks 11		/* A writer is blocked because they
-					 * found an unacknowledged bad-block.
-					 * This can safely be cleared at any
-					 * time, and the writer will re-check.
-					 * It may be set at any time, and at
-					 * worst the writer will timeout and
-					 * re-check.  So setting it as
-					 * accurately as possible is good, but
-					 * not absolutely critical.
-					 */
+	unsigned long	flags;	/* bit set of 'enum flag_bits' bits. */
 	wait_queue_head_t blocked_wait;
 
 	int desc_nr;			/* descriptor index in the superblock */
@@ -152,6 +125,44 @@ struct md_rdev {
 		sector_t size;		/* in sectors */
 	} badblocks;
 };
+enum flag_bits {
+	Faulty,			/* device is known to have a fault */
+	In_sync,		/* device is in_sync with rest of array */
+	WriteMostly,		/* Avoid reading if at all possible */
+	AutoDetected,		/* added by auto-detect */
+	Blocked,		/* An error occurred but has not yet
+				 * been acknowledged by the metadata
+				 * handler, so don't allow writes
+				 * until it is cleared */
+	WriteErrorSeen,		/* A write error has been seen on this
+				 * device
+				 */
+	FaultRecorded,		/* Intermediate state for clearing
+				 * Blocked.  The Fault is/will-be
+				 * recorded in the metadata, but that
+				 * metadata hasn't been stored safely
+				 * on disk yet.
+				 */
+	BlockedBadBlocks,	/* A writer is blocked because they
+				 * found an unacknowledged bad-block.
+				 * This can safely be cleared at any
+				 * time, and the writer will re-check.
+				 * It may be set at any time, and at
+				 * worst the writer will timeout and
+				 * re-check.  So setting it as
+				 * accurately as possible is good, but
+				 * not absolutely critical.
+				 */
+	WantReplacement,	/* This device is a candidate to be
+				 * hot-replaced, either because it has
+				 * reported some faults, or because
+				 * of explicit request.
+				 */
+	Replacement,		/* This device is a replacement for
+				 * a want_replacement device with same
+				 * raid_disk number.
+				 */
+};
 
 #define BB_LEN_MASK	(0x00000000000001FFULL)
 #define BB_OFFSET_MASK	(0x7FFFFFFFFFFFFE00ULL)
@@ -482,15 +493,20 @@ static inline char * mdname (struct mddev * mddev)
 static inline int sysfs_link_rdev(struct mddev *mddev, struct md_rdev *rdev)
 {
 	char nm[20];
-	sprintf(nm, "rd%d", rdev->raid_disk);
-	return sysfs_create_link(&mddev->kobj, &rdev->kobj, nm);
+	if (!test_bit(Replacement, &rdev->flags)) {
+		sprintf(nm, "rd%d", rdev->raid_disk);
+		return sysfs_create_link(&mddev->kobj, &rdev->kobj, nm);
+	} else
+		return 0;
 }
 
 static inline void sysfs_unlink_rdev(struct mddev *mddev, struct md_rdev *rdev)
 {
 	char nm[20];
-	sprintf(nm, "rd%d", rdev->raid_disk);
-	sysfs_remove_link(&mddev->kobj, nm);
+	if (!test_bit(Replacement, &rdev->flags)) {
+		sprintf(nm, "rd%d", rdev->raid_disk);
+		sysfs_remove_link(&mddev->kobj, nm);
+	}
 }
 
 /*

commit b8321b68d1445f308324517e45fb0a5c2b48e271
Author: NeilBrown <neilb@suse.de>
Date:   Fri Dec 23 10:17:51 2011 +1100

    md: change hot_remove_disk to take an rdev rather than a number.
    
    Soon an array will be able to have multiple devices with the
    same raid_disk number (an original and a replacement).  So removing
    a device based on the number won't work.  So pass the actual device
    handle instead.
    
    Reviewed-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index cf742d9306ec..670c10e6b484 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -428,7 +428,7 @@ struct md_personality
 	 */
 	void (*error_handler)(struct mddev *mddev, struct md_rdev *rdev);
 	int (*hot_add_disk) (struct mddev *mddev, struct md_rdev *rdev);
-	int (*hot_remove_disk) (struct mddev *mddev, int number);
+	int (*hot_remove_disk) (struct mddev *mddev, struct md_rdev *rdev);
 	int (*spare_active) (struct mddev *mddev);
 	sector_t (*sync_request)(struct mddev *mddev, sector_t sector_nr, int *skipped, int go_faster);
 	int (*resize) (struct mddev *mddev, sector_t sectors);

commit b4fdcb02f1e39c27058a885905bd0277370ba441
Merge: 044595d4e448 6dd9ad7df201
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 4 17:06:58 2011 -0700

    Merge branch 'for-3.2/core' of git://git.kernel.dk/linux-block
    
    * 'for-3.2/core' of git://git.kernel.dk/linux-block: (29 commits)
      block: don't call blk_drain_queue() if elevator is not up
      blk-throttle: use queue_is_locked() instead of lockdep_is_held()
      blk-throttle: Take blkcg->lock while traversing blkcg->policy_list
      blk-throttle: Free up policy node associated with deleted rule
      block: warn if tag is greater than real_max_depth.
      block: make gendisk hold a reference to its queue
      blk-flush: move the queue kick into
      blk-flush: fix invalid BUG_ON in blk_insert_flush
      block: Remove the control of complete cpu from bio.
      block: fix a typo in the blk-cgroup.h file
      block: initialize the bounce pool if high memory may be added later
      block: fix request_queue lifetime handling by making blk_queue_cleanup() properly shutdown
      block: drop @tsk from attempt_plug_merge() and explain sync rules
      block: make get_request[_wait]() fail if queue is dead
      block: reorganize throtl_get_tg() and blk_throtl_bio()
      block: reorganize queue draining
      block: drop unnecessary blk_get/put_queue() in scsi_cmd_ioctl() and blk_get_tg()
      block: pass around REQ_* flags instead of broken down booleans during request alloc/free
      block: move blk_throtl prototypes to block/blk.h
      block: fix genhd refcounting in blkio_policy_parse_and_set()
      ...
    
    Fix up trivial conflicts due to "mddev_t" -> "struct mddev" conversion
    and making the request functions be of type "void" instead of "int" in
     - drivers/md/{faulty.c,linear.c,md.c,md.h,multipath.c,raid0.c,raid1.c,raid10.c,raid5.c}
     - drivers/staging/zram/zram_drv.c

commit 5c04b426f2e8b46cfc7969a35b2631063a3c646c
Merge: 499337bb6511 899e3ee40496
Author: Jens Axboe <axboe@kernel.dk>
Date:   Wed Oct 19 14:30:42 2011 +0200

    Merge branch 'v3.1-rc10' into for-3.2/core
    
    Conflicts:
            block/blk-core.c
            include/linux/blkdev.h
    
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

commit 84fc4b56db85cb9e05326424049973a2036c9940
Author: NeilBrown <neilb@suse.de>
Date:   Tue Oct 11 16:49:58 2011 +1100

    md: rename "mdk_personality" to "md_personality"
    
    "mdk" doesn't mean anything any more.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index b618da59ca1c..51c1d91557e0 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -184,7 +184,7 @@ extern void md_ack_all_badblocks(struct badblocks *bb);
 
 struct mddev {
 	void				*private;
-	struct mdk_personality		*pers;
+	struct md_personality		*pers;
 	dev_t				unit;
 	int				md_minor;
 	struct list_head 		disks;
@@ -413,7 +413,7 @@ static inline void md_sync_acct(struct block_device *bdev, unsigned long nr_sect
         atomic_add(nr_sectors, &bdev->bd_contains->bd_disk->sync_io);
 }
 
-struct mdk_personality
+struct md_personality
 {
 	char *name;
 	int level;
@@ -551,8 +551,8 @@ static inline void safe_put_page(struct page *p)
 	if (p) put_page(p);
 }
 
-extern int register_md_personality(struct mdk_personality *p);
-extern int unregister_md_personality(struct mdk_personality *p);
+extern int register_md_personality(struct md_personality *p);
+extern int unregister_md_personality(struct md_personality *p);
 extern struct md_thread *md_register_thread(
 	void (*run)(struct mddev *mddev),
 	struct mddev *mddev,

commit 2b8bf3451d1e3133ebc3998721d14013a6c27114
Author: NeilBrown <neilb@suse.de>
Date:   Tue Oct 11 16:48:23 2011 +1100

    md: remove typedefs: mdk_thread_t -> struct md_thread
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 84a2c03c49c5..b618da59ca1c 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -251,8 +251,8 @@ struct mddev {
 	atomic_t			plug_cnt;	/* If device is expecting
 							 * more bios soon.
 							 */
-	struct mdk_thread_s		*thread;	/* management thread */
-	struct mdk_thread_s		*sync_thread;	/* doing resync or reconstruct */
+	struct md_thread		*thread;	/* management thread */
+	struct md_thread		*sync_thread;	/* doing resync or reconstruct */
 	sector_t			curr_resync;	/* last block scheduled */
 	/* As resync requests can complete out of order, we cannot easily track
 	 * how much resync has been completed.  So we occasionally pause until
@@ -509,14 +509,14 @@ static inline void sysfs_unlink_rdev(struct mddev *mddev, struct md_rdev *rdev)
 #define rdev_for_each_rcu(rdev, mddev)				\
 	list_for_each_entry_rcu(rdev, &((mddev)->disks), same_set)
 
-typedef struct mdk_thread_s {
+struct md_thread {
 	void			(*run) (struct mddev *mddev);
 	struct mddev		*mddev;
 	wait_queue_head_t	wqueue;
 	unsigned long           flags;
 	struct task_struct	*tsk;
 	unsigned long		timeout;
-} mdk_thread_t;
+};
 
 #define THREAD_WAKEUP  0
 
@@ -553,10 +553,12 @@ static inline void safe_put_page(struct page *p)
 
 extern int register_md_personality(struct mdk_personality *p);
 extern int unregister_md_personality(struct mdk_personality *p);
-extern mdk_thread_t * md_register_thread(void (*run) (struct mddev *mddev),
-				struct mddev *mddev, const char *name);
-extern void md_unregister_thread(mdk_thread_t **threadp);
-extern void md_wakeup_thread(mdk_thread_t *thread);
+extern struct md_thread *md_register_thread(
+	void (*run)(struct mddev *mddev),
+	struct mddev *mddev,
+	const char *name);
+extern void md_unregister_thread(struct md_thread **threadp);
+extern void md_wakeup_thread(struct md_thread *thread);
 extern void md_check_recovery(struct mddev *mddev);
 extern void md_write_start(struct mddev *mddev, struct bio *bi);
 extern void md_write_end(struct mddev *mddev);

commit fd01b88c75a718020ff77e7f560d33835e9b58de
Author: NeilBrown <neilb@suse.de>
Date:   Tue Oct 11 16:47:53 2011 +1100

    md: remove typedefs: mddev_t -> struct mddev
    
    Having mddev_t and 'struct mddev_s' is ugly and not preferred
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index b0e98c868c14..84a2c03c49c5 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -26,8 +26,6 @@
 
 #define MaxSector (~(sector_t)0)
 
-typedef struct mddev_s mddev_t;
-
 /* Bad block numbers are stored sorted in a single page.
  * 64bits is used for each block or extent.
  * 54 bits are sector number, 9 bits are extent size,
@@ -42,7 +40,7 @@ struct md_rdev {
 	struct list_head same_set;	/* RAID devices within the same set */
 
 	sector_t sectors;		/* Device size (in 512bytes sectors) */
-	mddev_t *mddev;			/* RAID array if running */
+	struct mddev *mddev;		/* RAID array if running */
 	int last_events;		/* IO event timestamp */
 
 	/*
@@ -184,8 +182,7 @@ extern int rdev_set_badblocks(struct md_rdev *rdev, sector_t s, int sectors,
 extern int rdev_clear_badblocks(struct md_rdev *rdev, sector_t s, int sectors);
 extern void md_ack_all_badblocks(struct badblocks *bb);
 
-struct mddev_s
-{
+struct mddev {
 	void				*private;
 	struct mdk_personality		*pers;
 	dev_t				unit;
@@ -400,11 +397,11 @@ struct mddev_s
 	atomic_t flush_pending;
 	struct work_struct flush_work;
 	struct work_struct event_work;	/* used by dm to report failure event */
-	void (*sync_super)(mddev_t *mddev, struct md_rdev *rdev);
+	void (*sync_super)(struct mddev *mddev, struct md_rdev *rdev);
 };
 
 
-static inline void rdev_dec_pending(struct md_rdev *rdev, mddev_t *mddev)
+static inline void rdev_dec_pending(struct md_rdev *rdev, struct mddev *mddev)
 {
 	int faulty = test_bit(Faulty, &rdev->flags);
 	if (atomic_dec_and_test(&rdev->nr_pending) && faulty)
@@ -422,29 +419,29 @@ struct mdk_personality
 	int level;
 	struct list_head list;
 	struct module *owner;
-	int (*make_request)(mddev_t *mddev, struct bio *bio);
-	int (*run)(mddev_t *mddev);
-	int (*stop)(mddev_t *mddev);
-	void (*status)(struct seq_file *seq, mddev_t *mddev);
+	int (*make_request)(struct mddev *mddev, struct bio *bio);
+	int (*run)(struct mddev *mddev);
+	int (*stop)(struct mddev *mddev);
+	void (*status)(struct seq_file *seq, struct mddev *mddev);
 	/* error_handler must set ->faulty and clear ->in_sync
 	 * if appropriate, and should abort recovery if needed 
 	 */
-	void (*error_handler)(mddev_t *mddev, struct md_rdev *rdev);
-	int (*hot_add_disk) (mddev_t *mddev, struct md_rdev *rdev);
-	int (*hot_remove_disk) (mddev_t *mddev, int number);
-	int (*spare_active) (mddev_t *mddev);
-	sector_t (*sync_request)(mddev_t *mddev, sector_t sector_nr, int *skipped, int go_faster);
-	int (*resize) (mddev_t *mddev, sector_t sectors);
-	sector_t (*size) (mddev_t *mddev, sector_t sectors, int raid_disks);
-	int (*check_reshape) (mddev_t *mddev);
-	int (*start_reshape) (mddev_t *mddev);
-	void (*finish_reshape) (mddev_t *mddev);
+	void (*error_handler)(struct mddev *mddev, struct md_rdev *rdev);
+	int (*hot_add_disk) (struct mddev *mddev, struct md_rdev *rdev);
+	int (*hot_remove_disk) (struct mddev *mddev, int number);
+	int (*spare_active) (struct mddev *mddev);
+	sector_t (*sync_request)(struct mddev *mddev, sector_t sector_nr, int *skipped, int go_faster);
+	int (*resize) (struct mddev *mddev, sector_t sectors);
+	sector_t (*size) (struct mddev *mddev, sector_t sectors, int raid_disks);
+	int (*check_reshape) (struct mddev *mddev);
+	int (*start_reshape) (struct mddev *mddev);
+	void (*finish_reshape) (struct mddev *mddev);
 	/* quiesce moves between quiescence states
 	 * 0 - fully active
 	 * 1 - no new requests allowed
 	 * others - reserved
 	 */
-	void (*quiesce) (mddev_t *mddev, int state);
+	void (*quiesce) (struct mddev *mddev, int state);
 	/* takeover is used to transition an array from one
 	 * personality to another.  The new personality must be able
 	 * to handle the data in the current layout.
@@ -454,14 +451,14 @@ struct mdk_personality
 	 * This needs to be installed and then ->run used to activate the
 	 * array.
 	 */
-	void *(*takeover) (mddev_t *mddev);
+	void *(*takeover) (struct mddev *mddev);
 };
 
 
 struct md_sysfs_entry {
 	struct attribute attr;
-	ssize_t (*show)(mddev_t *, char *);
-	ssize_t (*store)(mddev_t *, const char *, size_t);
+	ssize_t (*show)(struct mddev *, char *);
+	ssize_t (*store)(struct mddev *, const char *, size_t);
 };
 extern struct attribute_group md_bitmap_group;
 
@@ -477,19 +474,19 @@ static inline void sysfs_notify_dirent_safe(struct sysfs_dirent *sd)
 		sysfs_notify_dirent(sd);
 }
 
-static inline char * mdname (mddev_t * mddev)
+static inline char * mdname (struct mddev * mddev)
 {
 	return mddev->gendisk ? mddev->gendisk->disk_name : "mdX";
 }
 
-static inline int sysfs_link_rdev(mddev_t *mddev, struct md_rdev *rdev)
+static inline int sysfs_link_rdev(struct mddev *mddev, struct md_rdev *rdev)
 {
 	char nm[20];
 	sprintf(nm, "rd%d", rdev->raid_disk);
 	return sysfs_create_link(&mddev->kobj, &rdev->kobj, nm);
 }
 
-static inline void sysfs_unlink_rdev(mddev_t *mddev, struct md_rdev *rdev)
+static inline void sysfs_unlink_rdev(struct mddev *mddev, struct md_rdev *rdev)
 {
 	char nm[20];
 	sprintf(nm, "rd%d", rdev->raid_disk);
@@ -513,8 +510,8 @@ static inline void sysfs_unlink_rdev(mddev_t *mddev, struct md_rdev *rdev)
 	list_for_each_entry_rcu(rdev, &((mddev)->disks), same_set)
 
 typedef struct mdk_thread_s {
-	void			(*run) (mddev_t *mddev);
-	mddev_t			*mddev;
+	void			(*run) (struct mddev *mddev);
+	struct mddev		*mddev;
 	wait_queue_head_t	wqueue;
 	unsigned long           flags;
 	struct task_struct	*tsk;
@@ -556,46 +553,46 @@ static inline void safe_put_page(struct page *p)
 
 extern int register_md_personality(struct mdk_personality *p);
 extern int unregister_md_personality(struct mdk_personality *p);
-extern mdk_thread_t * md_register_thread(void (*run) (mddev_t *mddev),
-				mddev_t *mddev, const char *name);
+extern mdk_thread_t * md_register_thread(void (*run) (struct mddev *mddev),
+				struct mddev *mddev, const char *name);
 extern void md_unregister_thread(mdk_thread_t **threadp);
 extern void md_wakeup_thread(mdk_thread_t *thread);
-extern void md_check_recovery(mddev_t *mddev);
-extern void md_write_start(mddev_t *mddev, struct bio *bi);
-extern void md_write_end(mddev_t *mddev);
-extern void md_done_sync(mddev_t *mddev, int blocks, int ok);
-extern void md_error(mddev_t *mddev, struct md_rdev *rdev);
-
-extern int mddev_congested(mddev_t *mddev, int bits);
-extern void md_flush_request(mddev_t *mddev, struct bio *bio);
-extern void md_super_write(mddev_t *mddev, struct md_rdev *rdev,
+extern void md_check_recovery(struct mddev *mddev);
+extern void md_write_start(struct mddev *mddev, struct bio *bi);
+extern void md_write_end(struct mddev *mddev);
+extern void md_done_sync(struct mddev *mddev, int blocks, int ok);
+extern void md_error(struct mddev *mddev, struct md_rdev *rdev);
+
+extern int mddev_congested(struct mddev *mddev, int bits);
+extern void md_flush_request(struct mddev *mddev, struct bio *bio);
+extern void md_super_write(struct mddev *mddev, struct md_rdev *rdev,
 			   sector_t sector, int size, struct page *page);
-extern void md_super_wait(mddev_t *mddev);
+extern void md_super_wait(struct mddev *mddev);
 extern int sync_page_io(struct md_rdev *rdev, sector_t sector, int size, 
 			struct page *page, int rw, bool metadata_op);
-extern void md_do_sync(mddev_t *mddev);
-extern void md_new_event(mddev_t *mddev);
-extern int md_allow_write(mddev_t *mddev);
-extern void md_wait_for_blocked_rdev(struct md_rdev *rdev, mddev_t *mddev);
-extern void md_set_array_sectors(mddev_t *mddev, sector_t array_sectors);
-extern int md_check_no_bitmap(mddev_t *mddev);
-extern int md_integrity_register(mddev_t *mddev);
-extern void md_integrity_add_rdev(struct md_rdev *rdev, mddev_t *mddev);
+extern void md_do_sync(struct mddev *mddev);
+extern void md_new_event(struct mddev *mddev);
+extern int md_allow_write(struct mddev *mddev);
+extern void md_wait_for_blocked_rdev(struct md_rdev *rdev, struct mddev *mddev);
+extern void md_set_array_sectors(struct mddev *mddev, sector_t array_sectors);
+extern int md_check_no_bitmap(struct mddev *mddev);
+extern int md_integrity_register(struct mddev *mddev);
+extern void md_integrity_add_rdev(struct md_rdev *rdev, struct mddev *mddev);
 extern int strict_strtoul_scaled(const char *cp, unsigned long *res, int scale);
 extern void restore_bitmap_write_access(struct file *file);
 
-extern void mddev_init(mddev_t *mddev);
-extern int md_run(mddev_t *mddev);
-extern void md_stop(mddev_t *mddev);
-extern void md_stop_writes(mddev_t *mddev);
+extern void mddev_init(struct mddev *mddev);
+extern int md_run(struct mddev *mddev);
+extern void md_stop(struct mddev *mddev);
+extern void md_stop_writes(struct mddev *mddev);
 extern int md_rdev_init(struct md_rdev *rdev);
 
-extern void mddev_suspend(mddev_t *mddev);
-extern void mddev_resume(mddev_t *mddev);
+extern void mddev_suspend(struct mddev *mddev);
+extern void mddev_resume(struct mddev *mddev);
 extern struct bio *bio_clone_mddev(struct bio *bio, gfp_t gfp_mask,
-				   mddev_t *mddev);
+				   struct mddev *mddev);
 extern struct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,
-				   mddev_t *mddev);
-extern int mddev_check_plugged(mddev_t *mddev);
+				   struct mddev *mddev);
+extern int mddev_check_plugged(struct mddev *mddev);
 extern void md_trim_bio(struct bio *bio, int offset, int size);
 #endif /* _MD_MD_H */

commit 3cb03002000f133f9f97269edefd73611eafc873
Author: NeilBrown <neilb@suse.de>
Date:   Tue Oct 11 16:45:26 2011 +1100

    md: removing typedefs:  mdk_rdev_t -> struct md_rdev
    
    The typedefs are just annoying. 'mdk' probably refers to 'md_k.h'
    which used to be an include file that defined this thing.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index f412b6e3aa73..b0e98c868c14 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -27,7 +27,6 @@
 #define MaxSector (~(sector_t)0)
 
 typedef struct mddev_s mddev_t;
-typedef struct mdk_rdev_s mdk_rdev_t;
 
 /* Bad block numbers are stored sorted in a single page.
  * 64bits is used for each block or extent.
@@ -39,8 +38,7 @@ typedef struct mdk_rdev_s mdk_rdev_t;
 /*
  * MD's 'extended' device
  */
-struct mdk_rdev_s
-{
+struct md_rdev {
 	struct list_head same_set;	/* RAID devices within the same set */
 
 	sector_t sectors;		/* Device size (in 512bytes sectors) */
@@ -168,7 +166,7 @@ struct mdk_rdev_s
 
 extern int md_is_badblock(struct badblocks *bb, sector_t s, int sectors,
 			  sector_t *first_bad, int *bad_sectors);
-static inline int is_badblock(mdk_rdev_t *rdev, sector_t s, int sectors,
+static inline int is_badblock(struct md_rdev *rdev, sector_t s, int sectors,
 			      sector_t *first_bad, int *bad_sectors)
 {
 	if (unlikely(rdev->badblocks.count)) {
@@ -181,9 +179,9 @@ static inline int is_badblock(mdk_rdev_t *rdev, sector_t s, int sectors,
 	}
 	return 0;
 }
-extern int rdev_set_badblocks(mdk_rdev_t *rdev, sector_t s, int sectors,
+extern int rdev_set_badblocks(struct md_rdev *rdev, sector_t s, int sectors,
 			      int acknowledged);
-extern int rdev_clear_badblocks(mdk_rdev_t *rdev, sector_t s, int sectors);
+extern int rdev_clear_badblocks(struct md_rdev *rdev, sector_t s, int sectors);
 extern void md_ack_all_badblocks(struct badblocks *bb);
 
 struct mddev_s
@@ -402,11 +400,11 @@ struct mddev_s
 	atomic_t flush_pending;
 	struct work_struct flush_work;
 	struct work_struct event_work;	/* used by dm to report failure event */
-	void (*sync_super)(mddev_t *mddev, mdk_rdev_t *rdev);
+	void (*sync_super)(mddev_t *mddev, struct md_rdev *rdev);
 };
 
 
-static inline void rdev_dec_pending(mdk_rdev_t *rdev, mddev_t *mddev)
+static inline void rdev_dec_pending(struct md_rdev *rdev, mddev_t *mddev)
 {
 	int faulty = test_bit(Faulty, &rdev->flags);
 	if (atomic_dec_and_test(&rdev->nr_pending) && faulty)
@@ -431,8 +429,8 @@ struct mdk_personality
 	/* error_handler must set ->faulty and clear ->in_sync
 	 * if appropriate, and should abort recovery if needed 
 	 */
-	void (*error_handler)(mddev_t *mddev, mdk_rdev_t *rdev);
-	int (*hot_add_disk) (mddev_t *mddev, mdk_rdev_t *rdev);
+	void (*error_handler)(mddev_t *mddev, struct md_rdev *rdev);
+	int (*hot_add_disk) (mddev_t *mddev, struct md_rdev *rdev);
 	int (*hot_remove_disk) (mddev_t *mddev, int number);
 	int (*spare_active) (mddev_t *mddev);
 	sector_t (*sync_request)(mddev_t *mddev, sector_t sector_nr, int *skipped, int go_faster);
@@ -484,14 +482,14 @@ static inline char * mdname (mddev_t * mddev)
 	return mddev->gendisk ? mddev->gendisk->disk_name : "mdX";
 }
 
-static inline int sysfs_link_rdev(mddev_t *mddev, mdk_rdev_t *rdev)
+static inline int sysfs_link_rdev(mddev_t *mddev, struct md_rdev *rdev)
 {
 	char nm[20];
 	sprintf(nm, "rd%d", rdev->raid_disk);
 	return sysfs_create_link(&mddev->kobj, &rdev->kobj, nm);
 }
 
-static inline void sysfs_unlink_rdev(mddev_t *mddev, mdk_rdev_t *rdev)
+static inline void sysfs_unlink_rdev(mddev_t *mddev, struct md_rdev *rdev)
 {
 	char nm[20];
 	sprintf(nm, "rd%d", rdev->raid_disk);
@@ -566,23 +564,23 @@ extern void md_check_recovery(mddev_t *mddev);
 extern void md_write_start(mddev_t *mddev, struct bio *bi);
 extern void md_write_end(mddev_t *mddev);
 extern void md_done_sync(mddev_t *mddev, int blocks, int ok);
-extern void md_error(mddev_t *mddev, mdk_rdev_t *rdev);
+extern void md_error(mddev_t *mddev, struct md_rdev *rdev);
 
 extern int mddev_congested(mddev_t *mddev, int bits);
 extern void md_flush_request(mddev_t *mddev, struct bio *bio);
-extern void md_super_write(mddev_t *mddev, mdk_rdev_t *rdev,
+extern void md_super_write(mddev_t *mddev, struct md_rdev *rdev,
 			   sector_t sector, int size, struct page *page);
 extern void md_super_wait(mddev_t *mddev);
-extern int sync_page_io(mdk_rdev_t *rdev, sector_t sector, int size, 
+extern int sync_page_io(struct md_rdev *rdev, sector_t sector, int size, 
 			struct page *page, int rw, bool metadata_op);
 extern void md_do_sync(mddev_t *mddev);
 extern void md_new_event(mddev_t *mddev);
 extern int md_allow_write(mddev_t *mddev);
-extern void md_wait_for_blocked_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
+extern void md_wait_for_blocked_rdev(struct md_rdev *rdev, mddev_t *mddev);
 extern void md_set_array_sectors(mddev_t *mddev, sector_t array_sectors);
 extern int md_check_no_bitmap(mddev_t *mddev);
 extern int md_integrity_register(mddev_t *mddev);
-extern void md_integrity_add_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
+extern void md_integrity_add_rdev(struct md_rdev *rdev, mddev_t *mddev);
 extern int strict_strtoul_scaled(const char *cp, unsigned long *res, int scale);
 extern void restore_bitmap_write_access(struct file *file);
 
@@ -590,7 +588,7 @@ extern void mddev_init(mddev_t *mddev);
 extern int md_run(mddev_t *mddev);
 extern void md_stop(mddev_t *mddev);
 extern void md_stop_writes(mddev_t *mddev);
-extern int md_rdev_init(mdk_rdev_t *rdev);
+extern int md_rdev_init(struct md_rdev *rdev);
 
 extern void mddev_suspend(mddev_t *mddev);
 extern void mddev_resume(mddev_t *mddev);

commit 7e841526263b3e0042a423513147dfd06c8e998d
Author: Wang Sheng-Hui <shhuiw@gmail.com>
Date:   Wed Sep 21 15:37:46 2011 +1000

    trival: md_k.h should be md.h in the beginning comment of file md.h
    
    Signed-off-by: Wang Sheng-Hui <shhuiw@gmail.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 0a309dc29b45..f412b6e3aa73 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -1,5 +1,5 @@
 /*
-   md_k.h : kernel internal structure of the Linux MD driver
+   md.h : kernel internal structure of the Linux MD driver
           Copyright (C) 1996-98 Ingo Molnar, Gadi Oxman
 	  
    This program is free software; you can redistribute it and/or modify

commit 01f96c0a9922cd9919baf9d16febdf7016177a12
Author: NeilBrown <neilb@suse.de>
Date:   Wed Sep 21 15:30:20 2011 +1000

    md: Avoid waking up a thread after it has been freed.
    
    Two related problems:
    
    1/ some error paths call "md_unregister_thread(mddev->thread)"
       without subsequently clearing ->thread.  A subsequent call
       to mddev_unlock will try to wake the thread, and crash.
    
    2/ Most calls to md_wakeup_thread are protected against the thread
       disappeared either by:
          - holding the ->mutex
          - having an active request, so something else must be keeping
            the array active.
       However mddev_unlock calls md_wakeup_thread after dropping the
       mutex and without any certainty of an active request, so the
       ->thread could theoretically disappear.
       So we need a spinlock to provide some protections.
    
    So change md_unregister_thread to take a pointer to the thread
    pointer, and ensure that it always does the required locking, and
    clears the pointer properly.
    
    Reported-by: "Moshe Melnikov" <moshe@zadarastorage.com>
    Signed-off-by: NeilBrown <neilb@suse.de>
    cc: stable@kernel.org

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 1e586bb4452e..0a309dc29b45 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -560,7 +560,7 @@ extern int register_md_personality(struct mdk_personality *p);
 extern int unregister_md_personality(struct mdk_personality *p);
 extern mdk_thread_t * md_register_thread(void (*run) (mddev_t *mddev),
 				mddev_t *mddev, const char *name);
-extern void md_unregister_thread(mdk_thread_t *thread);
+extern void md_unregister_thread(mdk_thread_t **threadp);
 extern void md_wakeup_thread(mdk_thread_t *thread);
 extern void md_check_recovery(mddev_t *mddev);
 extern void md_write_start(mddev_t *mddev, struct bio *bi);

commit 5a7bbad27a410350e64a2d7f5ec18fc73836c14f
Author: Christoph Hellwig <hch@infradead.org>
Date:   Mon Sep 12 12:12:01 2011 +0200

    block: remove support for bio remapping from ->make_request
    
    There is very little benefit in allowing to let a ->make_request
    instance update the bios device and sector and loop around it in
    __generic_make_request when we can archive the same through calling
    generic_make_request from the driver and letting the loop in
    generic_make_request handle it.
    
    Note that various drivers got the return value from ->make_request and
    returned non-zero values for errors.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: NeilBrown <neilb@suse.de>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 1e586bb4452e..bd47847cf7ca 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -424,7 +424,7 @@ struct mdk_personality
 	int level;
 	struct list_head list;
 	struct module *owner;
-	int (*make_request)(mddev_t *mddev, struct bio *bio);
+	void (*make_request)(mddev_t *mddev, struct bio *bio);
 	int (*run)(mddev_t *mddev);
 	int (*stop)(mddev_t *mddev);
 	void (*status)(struct seq_file *seq, mddev_t *mddev);

commit de393cdea66cbd63c90725663f400c76faf1b255
Author: NeilBrown <neilb@suse.de>
Date:   Thu Jul 28 11:31:48 2011 +1000

    md: make it easier to wait for bad blocks to be acknowledged.
    
    It is only safe to choose not to write to a bad block if that bad
    block is safely recorded in metadata - i.e. if it has been
    'acknowledged'.
    
    If it hasn't we need to wait for the acknowledgement.
    
    We support that using rdev->blocked wait and
    md_wait_for_blocked_rdev by introducing a new device flag
    'BlockedBadBlock'.
    
    This flag is only advisory.
    It is cleared whenever we acknowledge a bad block, so that a waiter
    can re-check the particular bad blocks that it is interested it.
    
    It should be set by a caller when they find they need to wait.
    This (set after test) is inherently racy, but as
    md_wait_for_blocked_rdev already has a timeout, losing the race will
    have minimal impact.
    
    When we clear "Blocked" was also clear "BlockedBadBlocks" incase it
    was set incorrectly (see above race).
    
    We also modify the way we manage 'Blocked' to fit better with the new
    handling of 'BlockedBadBlocks' and to make it consistent between
    externally managed and internally managed metadata.   This requires
    that each raidXd loop checks if the metadata needs to be written and
    triggers a write (md_check_recovery) if needed.  Otherwise a queued
    write request might cause raidXd to wait for the metadata to write,
    and only that thread can write it.
    
    Before writing metadata, we set FaultRecorded for all devices that
    are Faulty, then after writing the metadata we clear Blocked for any
    device for which the Fault was certainly Recorded.
    
    The 'faulty' device flag now appears in sysfs if the device is faulty
    *or* it has unacknowledged bad blocks.  So user-space which does not
    understand bad blocks can continue to function correctly.
    User space which does, should not assume a device is faulty until it
    sees the 'faulty' flag, and then sees the list of unacknowledged bad
    blocks is empty.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index fa4b607854ac..1e586bb4452e 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -81,12 +81,29 @@ struct mdk_rdev_s
 #define	In_sync		2		/* device is in_sync with rest of array */
 #define	WriteMostly	4		/* Avoid reading if at all possible */
 #define	AutoDetected	7		/* added by auto-detect */
-#define Blocked		8		/* An error occurred on an externally
-					 * managed array, don't allow writes
+#define Blocked		8		/* An error occurred but has not yet
+					 * been acknowledged by the metadata
+					 * handler, so don't allow writes
 					 * until it is cleared */
 #define WriteErrorSeen	9		/* A write error has been seen on this
 					 * device
 					 */
+#define FaultRecorded	10		/* Intermediate state for clearing
+					 * Blocked.  The Fault is/will-be
+					 * recorded in the metadata, but that
+					 * metadata hasn't been stored safely
+					 * on disk yet.
+					 */
+#define BlockedBadBlocks 11		/* A writer is blocked because they
+					 * found an unacknowledged bad-block.
+					 * This can safely be cleared at any
+					 * time, and the writer will re-check.
+					 * It may be set at any time, and at
+					 * worst the writer will timeout and
+					 * re-check.  So setting it as
+					 * accurately as possible is good, but
+					 * not absolutely critical.
+					 */
 	wait_queue_head_t blocked_wait;
 
 	int desc_nr;			/* descriptor index in the superblock */
@@ -124,6 +141,10 @@ struct mdk_rdev_s
 
 	struct badblocks {
 		int	count;		/* count of bad blocks */
+		int	unacked_exist;	/* there probably are unacknowledged
+					 * bad blocks.  This is only cleared
+					 * when a read discovers none
+					 */
 		int	shift;		/* shift from sectors to block size
 					 * a -ve shift means badblocks are
 					 * disabled.*/

commit d7a9d443bc8a75a24873c0506f50051edfedc714
Author: NeilBrown <neilb@suse.de>
Date:   Thu Jul 28 11:31:48 2011 +1000

    md: add 'write_error' flag to component devices.
    
    If a device has ever seen a write error, we will want to handle
    known-bad-blocks differently.
    So create an appropriate state flag and export it via sysfs.
    
    Signed-off-by: NeilBrown <neilb@suse.de>
    Reviewed-by: Namhyung Kim <namhyung@gmail.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 7c3192c0a29a..fa4b607854ac 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -84,6 +84,9 @@ struct mdk_rdev_s
 #define Blocked		8		/* An error occurred on an externally
 					 * managed array, don't allow writes
 					 * until it is cleared */
+#define WriteErrorSeen	9		/* A write error has been seen on this
+					 * device
+					 */
 	wait_queue_head_t blocked_wait;
 
 	int desc_nr;			/* descriptor index in the superblock */

commit d2eb35acfdccbe2a3622ed6cc441a5482148423b
Author: NeilBrown <neilb@suse.de>
Date:   Thu Jul 28 11:31:48 2011 +1000

    md/raid1: avoid reading from known bad blocks.
    
    Now that we have a bad block list, we should not read from those
    blocks.
    There are several main parts to this:
      1/ read_balance needs to check for bad blocks, and return not only
         the chosen device, but also how many good blocks are available
         there.
      2/ fix_read_error needs to avoid trying to read from bad blocks.
      3/ read submission must be ready to issue multiple reads to
         different devices as different bad blocks on different devices
         could mean that a single large read cannot be served by any one
         device, but can still be served by the array.
         This requires keeping count of the number of outstanding requests
         per bio.  This count is stored in 'bi_phys_segments'
      4/ retrying a read needs to also be ready to submit a smaller read
         and queue another request for the rest.
    
    This does not yet handle bad blocks when reading to perform resync,
    recovery, or check.
    
    'md_trim_bio' will also be used for RAID10, so put it in md.c and
    export it.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index aea9e9ff8a33..7c3192c0a29a 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -575,4 +575,5 @@ extern struct bio *bio_clone_mddev(struct bio *bio, gfp_t gfp_mask,
 extern struct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,
 				   mddev_t *mddev);
 extern int mddev_check_plugged(mddev_t *mddev);
+extern void md_trim_bio(struct bio *bio, int offset, int size);
 #endif /* _MD_MD_H */

commit 2699b67223aca6b1450fc2f72e40fada952afc85
Author: NeilBrown <neilb@suse.de>
Date:   Thu Jul 28 11:31:47 2011 +1000

    md: load/store badblock list from v1.x metadata
    
    Space must have been allocated when array was created.
    A feature flag is set when the badblock list is non-empty, to
    ensure old kernels don't load and trust the whole device.
    
    We only update the on-disk badblocklist when it has changed.
    If the badblocklist (or other metadata) is stored on a bad block, we
    don't cope very well.
    
    If metadata has no room for bad block, flag bad-blocks as disabled,
    and do the same for 0.90 metadata.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 85af8433f8b8..aea9e9ff8a33 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -55,7 +55,7 @@ struct mdk_rdev_s
 	struct block_device *meta_bdev;
 	struct block_device *bdev;	/* block device handle */
 
-	struct page	*sb_page;
+	struct page	*sb_page, *bb_page;
 	int		sb_loaded;
 	__u64		sb_events;
 	sector_t	data_offset;	/* start of data in array */
@@ -127,6 +127,9 @@ struct mdk_rdev_s
 		u64	*page;		/* badblock list */
 		int	changed;
 		seqlock_t lock;
+
+		sector_t sector;
+		sector_t size;		/* in sectors */
 	} badblocks;
 };
 

commit 2230dfe4ccc3add340dc6d437965b2de1d269fde
Author: NeilBrown <neilb@suse.de>
Date:   Thu Jul 28 11:31:46 2011 +1000

    md: beginnings of bad block management.
    
    This the first step in allowing md to track bad-blocks per-device so
    that we can fail individual blocks rather than the whole device.
    
    This patch just adds a data structure for recording bad blocks, with
    routines to add, remove, search the list.
    
    Signed-off-by: NeilBrown <neilb@suse.de>
    Reviewed-by: Namhyung Kim <namhyung@gmail.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 7d906a96477a..85af8433f8b8 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -29,6 +29,13 @@
 typedef struct mddev_s mddev_t;
 typedef struct mdk_rdev_s mdk_rdev_t;
 
+/* Bad block numbers are stored sorted in a single page.
+ * 64bits is used for each block or extent.
+ * 54 bits are sector number, 9 bits are extent size,
+ * 1 bit is an 'acknowledged' flag.
+ */
+#define MD_MAX_BADBLOCKS	(PAGE_SIZE/8)
+
 /*
  * MD's 'extended' device
  */
@@ -111,8 +118,47 @@ struct mdk_rdev_s
 
 	struct sysfs_dirent *sysfs_state; /* handle for 'state'
 					   * sysfs entry */
+
+	struct badblocks {
+		int	count;		/* count of bad blocks */
+		int	shift;		/* shift from sectors to block size
+					 * a -ve shift means badblocks are
+					 * disabled.*/
+		u64	*page;		/* badblock list */
+		int	changed;
+		seqlock_t lock;
+	} badblocks;
 };
 
+#define BB_LEN_MASK	(0x00000000000001FFULL)
+#define BB_OFFSET_MASK	(0x7FFFFFFFFFFFFE00ULL)
+#define BB_ACK_MASK	(0x8000000000000000ULL)
+#define BB_MAX_LEN	512
+#define BB_OFFSET(x)	(((x) & BB_OFFSET_MASK) >> 9)
+#define BB_LEN(x)	(((x) & BB_LEN_MASK) + 1)
+#define BB_ACK(x)	(!!((x) & BB_ACK_MASK))
+#define BB_MAKE(a, l, ack) (((a)<<9) | ((l)-1) | ((u64)(!!(ack)) << 63))
+
+extern int md_is_badblock(struct badblocks *bb, sector_t s, int sectors,
+			  sector_t *first_bad, int *bad_sectors);
+static inline int is_badblock(mdk_rdev_t *rdev, sector_t s, int sectors,
+			      sector_t *first_bad, int *bad_sectors)
+{
+	if (unlikely(rdev->badblocks.count)) {
+		int rv = md_is_badblock(&rdev->badblocks, rdev->data_offset + s,
+					sectors,
+					first_bad, bad_sectors);
+		if (rv)
+			*first_bad -= rdev->data_offset;
+		return rv;
+	}
+	return 0;
+}
+extern int rdev_set_badblocks(mdk_rdev_t *rdev, sector_t s, int sectors,
+			      int acknowledged);
+extern int rdev_clear_badblocks(mdk_rdev_t *rdev, sector_t s, int sectors);
+extern void md_ack_all_badblocks(struct badblocks *bb);
+
 struct mddev_s
 {
 	void				*private;
@@ -517,7 +563,7 @@ extern void mddev_init(mddev_t *mddev);
 extern int md_run(mddev_t *mddev);
 extern void md_stop(mddev_t *mddev);
 extern void md_stop_writes(mddev_t *mddev);
-extern void md_rdev_init(mdk_rdev_t *rdev);
+extern int md_rdev_init(mdk_rdev_t *rdev);
 
 extern void mddev_suspend(mddev_t *mddev);
 extern void mddev_resume(mddev_t *mddev);

commit 3520fa4db7fc4ae1b0373dcecdaf720f620dab2d
Author: Jonathan Brassow <jbrassow@redhat.com>
Date:   Wed Jul 27 11:00:37 2011 +1000

    MD bitmap: Revert DM dirty log hooks
    
    
    Revert most of commit e384e58549a2e9a83071ad80280c1a9053cfd84c
      md/bitmap: prepare for storing write-intent-bitmap via dm-dirty-log.
    
    MD should not need to use DM's dirty log - we decided to use md's
    bitmaps instead.
    
    Keeping the DIV_ROUND_UP clean-ups that were part of commit
    e384e58549a2e9a83071ad80280c1a9053cfd84c, however.
    
    Signed-off-by: Jonathan Brassow <jbrassow@redhat.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index de5455d30d41..7d906a96477a 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -307,11 +307,6 @@ struct mddev_s
 							 * hot-adding a bitmap.  It should
 							 * eventually be settable by sysfs.
 							 */
-		/* When md is serving under dm, it might use a
-		 * dirty_log to store the bits.
-		 */
-		struct dm_dirty_log *log;
-
 		struct mutex		mutex;
 		unsigned long		chunksize;
 		unsigned long		daemon_sleep; /* how many jiffies between updates? */

commit 5389042ffa36976caa45a79af16081d759001fa7
Author: NeilBrown <neilb@suse.de>
Date:   Wed Jul 27 11:00:36 2011 +1000

    md: change managed of recovery_disabled.
    
    If we hit a read error while recovering a mirror, we want to abort the
    recovery without necessarily failing the disk - as having a disk this
    a read error is better than not having an array at all.
    
    Currently this is managed with a per-array flag "recovery_disabled"
    and is only implemented for RAID1.  For RAID10 we will need finer
    grained control as we might want to disable recovery for individual
    devices separately.
    
    So push more of the decision making into the personality.
    'recovery_disabled' is now a 'cookie' which is copied when the
    personality want to disable recovery and is changed when a device is
    added to the array as this is used as a trigger to 'try recovery
    again'.
    
    This will allow RAID10 to get the control that it needs.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 6863f722cd2a..de5455d30d41 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -239,9 +239,12 @@ struct mddev_s
 #define	MD_RECOVERY_FROZEN	9
 
 	unsigned long			recovery;
-	int				recovery_disabled; /* if we detect that recovery
-							    * will always fail, set this
-							    * so we don't loop trying */
+	/* If a RAID personality determines that recovery (of a particular
+	 * device) will fail due to a read error on the source device, it
+	 * takes a copy of this number and does not attempt recovery again
+	 * until this number changes.
+	 */
+	int				recovery_disabled;
 
 	int				in_sync;	/* know to not need resync */
 	/* 'open_mutex' avoids races between 'md_open' and 'do_md_stop', so

commit 36fad858a7404a9656122a9e560a224ae2a00979
Author: Namhyung Kim <namhyung@gmail.com>
Date:   Wed Jul 27 11:00:36 2011 +1000

    md: introduce link/unlink_rdev() helpers
    
    There are places where sysfs links to rdev are handled
    in a same way. Add the helper functions to consolidate
    them.
    
    Signed-off-by: Namhyung Kim <namhyung@gmail.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 1c26c7a08ae6..6863f722cd2a 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -413,6 +413,20 @@ static inline char * mdname (mddev_t * mddev)
 	return mddev->gendisk ? mddev->gendisk->disk_name : "mdX";
 }
 
+static inline int sysfs_link_rdev(mddev_t *mddev, mdk_rdev_t *rdev)
+{
+	char nm[20];
+	sprintf(nm, "rd%d", rdev->raid_disk);
+	return sysfs_create_link(&mddev->kobj, &rdev->kobj, nm);
+}
+
+static inline void sysfs_unlink_rdev(mddev_t *mddev, mdk_rdev_t *rdev)
+{
+	char nm[20];
+	sprintf(nm, "rd%d", rdev->raid_disk);
+	sysfs_remove_link(&mddev->kobj, nm);
+}
+
 /*
  * iterates through some rdev ringlist. It's safe to remove the
  * current 'rdev'. Dont touch 'tmp' though.

commit 9c81075f436f867f580c2edf2350c0898cffc9d0
Author: Jonathan Brassow <jbrassow@redhat.com>
Date:   Wed Jun 8 17:59:30 2011 -0500

    MD: support initial bitmap creation in-kernel
    
    Add bitmap support to the device-mapper specific metadata area.
    
    This patch allows the creation of the bitmap metadata area upon
    initial array creation via device-mapper.
    
    Signed-off-by: Jonathan Brassow <jbrassow@redhat.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 5e35535ab7c3..1c26c7a08ae6 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -124,6 +124,7 @@ struct mddev_s
 #define MD_CHANGE_DEVS	0	/* Some device status has changed */
 #define MD_CHANGE_CLEAN 1	/* transition to or from 'clean' */
 #define MD_CHANGE_PENDING 2	/* switch from 'clean' to 'active' in progress */
+#define MD_ARRAY_FIRST_USE 3    /* First use of array, needs initialization */
 
 	int				suspended;
 	atomic_t			active_io;

commit 076f968b37f0232d883749da8f5031df5dea7ade
Author: Jonathan Brassow <jbrassow@redhat.com>
Date:   Tue Jun 7 17:51:30 2011 -0500

    MD: add sync_super to mddev_t struct
    
    Add the 'sync_super' function pointer to MD array structure (struct mddev_s)
    
    If device-mapper (dm-raid.c) is to define its own on-disk superblock and be
    able to load it, there must still be a way for MD to initiate superblock
    updates.  The simplest way to make this happen is to provide a pointer in
    the MD array structure that can be set by device-mapper (or other module)
    with a function to do this.  If the function has been set, it will be used;
    otherwise, the method with be looked up via 'super_types' as usual.
    
    Signed-off-by: Jonathan Brassow <jbrassow@redhat.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 0b1fd3f1d85b..5e35535ab7c3 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -330,6 +330,7 @@ struct mddev_s
 	atomic_t flush_pending;
 	struct work_struct flush_work;
 	struct work_struct event_work;	/* used by dm to report failure event */
+	void (*sync_super)(mddev_t *mddev, mdk_rdev_t *rdev);
 };
 
 

commit 97658cdd3af7d01461874c93b89afa4a2465e7c6
Author: NeilBrown <neilb@suse.de>
Date:   Mon Apr 18 18:25:42 2011 +1000

    md: provide generic support for handling unplug callbacks.
    
    When an md device adds a request to a queue, it can call
    mddev_check_plugged.
    If this succeeds then we know that the md thread will be woken up
    shortly, and ->plug_cnt will be non-zero until then, so some
    processing can be delayed.
    
    If it fails, then no unplug callback is expected and the make_request
    function needs to do whatever is required to make the request happen.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index fad90228672f..0b1fd3f1d85b 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -179,6 +179,9 @@ struct mddev_s
 	int				delta_disks, new_level, new_layout;
 	int				new_chunk_sectors;
 
+	atomic_t			plug_cnt;	/* If device is expecting
+							 * more bios soon.
+							 */
 	struct mdk_thread_s		*thread;	/* management thread */
 	struct mdk_thread_s		*sync_thread;	/* doing resync or reconstruct */
 	sector_t			curr_resync;	/* last block scheduled */
@@ -508,4 +511,5 @@ extern struct bio *bio_clone_mddev(struct bio *bio, gfp_t gfp_mask,
 				   mddev_t *mddev);
 extern struct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,
 				   mddev_t *mddev);
+extern int mddev_check_plugged(mddev_t *mddev);
 #endif /* _MD_MD_H */

commit 482c083492ddaa32ef5864bae3d143dc8bcdf7d1
Author: NeilBrown <neilb@suse.de>
Date:   Mon Apr 18 18:25:42 2011 +1000

    md - remove old plugging code.
    
    md has some plugging infrastructure for RAID5 to use because the
    normal plugging infrastructure required a 'request_queue', and when
    called from dm, RAID5 doesn't have one of those available.
    
    This relied on the ->unplug_fn callback which doesn't exist any more.
    
    So remove all of that code, both in md and raid5.  Subsequent patches
    with restore the plugging functionality.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 52b407369e13..fad90228672f 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -29,26 +29,6 @@
 typedef struct mddev_s mddev_t;
 typedef struct mdk_rdev_s mdk_rdev_t;
 
-/* generic plugging support - like that provided with request_queue,
- * but does not require a request_queue
- */
-struct plug_handle {
-	void			(*unplug_fn)(struct plug_handle *);
-	struct timer_list	unplug_timer;
-	struct work_struct	unplug_work;
-	unsigned long		unplug_flag;
-};
-#define	PLUGGED_FLAG 1
-void plugger_init(struct plug_handle *plug,
-		  void (*unplug_fn)(struct plug_handle *));
-void plugger_set_plug(struct plug_handle *plug);
-int plugger_remove_plug(struct plug_handle *plug);
-static inline void plugger_flush(struct plug_handle *plug)
-{
-	del_timer_sync(&plug->unplug_timer);
-	cancel_work_sync(&plug->unplug_work);
-}
-
 /*
  * MD's 'extended' device
  */
@@ -336,7 +316,6 @@ struct mddev_s
 	struct list_head		all_mddevs;
 
 	struct attribute_group		*to_remove;
-	struct plug_handle		*plug; /* if used by personality */
 
 	struct bio_set			*bio_set;
 
@@ -516,7 +495,6 @@ extern int md_integrity_register(mddev_t *mddev);
 extern void md_integrity_add_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
 extern int strict_strtoul_scaled(const char *cp, unsigned long *res, int scale);
 extern void restore_bitmap_write_access(struct file *file);
-extern void md_unplug(mddev_t *mddev);
 
 extern void mddev_init(mddev_t *mddev);
 extern int md_run(mddev_t *mddev);

commit 25985edcedea6396277003854657b5f3cb31a628
Author: Lucas De Marchi <lucas.demarchi@profusion.mobi>
Date:   Wed Mar 30 22:57:33 2011 -0300

    Fix common misspellings
    
    Fixes generated by 'codespell' and manually reviewed.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 12215d437fcc..52b407369e13 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -94,7 +94,7 @@ struct mdk_rdev_s
 #define	In_sync		2		/* device is in_sync with rest of array */
 #define	WriteMostly	4		/* Avoid reading if at all possible */
 #define	AutoDetected	7		/* added by auto-detect */
-#define Blocked		8		/* An error occured on an externally
+#define Blocked		8		/* An error occurred on an externally
 					 * managed array, don't allow writes
 					 * until it is cleared */
 	wait_queue_head_t blocked_wait;

commit f0b4f7e2f29af678bd9af43422c537dcb6008603
Author: NeilBrown <neilb@suse.de>
Date:   Thu Feb 24 17:26:41 2011 +1100

    md: Fix - again - partition detection when array becomes active
    
    Revert
        b821eaa572fd737faaf6928ba046e571526c36c6
    and
        f3b99be19ded511a1bf05a148276239d9f13eefa
    
    When I wrote the first of these I had a wrong idea about the
    lifetime of 'struct block_device'.  It can disappear at any time that
    the block device is not open if it falls out of the inode cache.
    
    So relying on the 'size' recorded with it to detect when the
    device size has changed and so we need to revalidate, is wrong.
    
    Rather, we really do need the 'changed' attribute stored directly in
    the mddev and set/tested as appropriate.
    
    Without this patch, a sequence of:
       mknod / open / close / unlink
    
    (which can cause a block_device to be created and then destroyed)
    will result in a rescan of the partition table and consequence removal
    and addition of partitions.
    Several of these in a row can get udev racing to create and unlink and
    other code can get confused.
    
    With the patch, the rescan is only performed when needed and so there
    are no races.
    
    This is suitable for any stable kernel from 2.6.35.
    
    Reported-by: "Wojcik, Krzysztof" <krzysztof.wojcik@intel.com>
    Signed-off-by: NeilBrown <neilb@suse.de>
    Cc: stable@kernel.org

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 7e90b8593b2a..12215d437fcc 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -274,6 +274,8 @@ struct mddev_s
 	atomic_t			active;		/* general refcount */
 	atomic_t			openers;	/* number of active opens */
 
+	int				changed;	/* True if we might need to
+							 * reread partition info */
 	int				degraded;	/* whether md should consider
 							 * adding a spare
 							 */

commit f21e9ff7f77d41ceca4e1e5ee5a4efa5ad7a5e40
Author: NeilBrown <neilb@suse.de>
Date:   Mon Jan 31 12:10:09 2011 +1100

    md: Remove the AllReserved flag for component devices.
    
    This flag is not needed and is used badly.
    
    Devices that are included in a native-metadata array are reserved
    exclusively for that array - and currently have AllReserved set.
    They all are bd_claimed for the rdev and so cannot be shared.
    
    Devices that are included in external-metadata arrays can be shared
    among multiple arrays - providing there is no overlap.
    These are bd_claimed for md in general - not for a particular rdev.
    
    When changing the amount of a device that is used in an array we need
    to check for overlap.  This currently includes a check on AllReserved
    So even without overlap, sharing with an AllReserved device is not
    allowed.
    However the bd_claim usage already precludes sharing with these
    devices, so the test on AllReserved is not needed.  And in fact it is
    wrong.
    
    As this is the only use of AllReserved, simply remove all usage and
    definition of AllReserved.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index eec517ced31a..7e90b8593b2a 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -93,8 +93,6 @@ struct mdk_rdev_s
 #define	Faulty		1		/* device is known to have a fault */
 #define	In_sync		2		/* device is in_sync with rest of array */
 #define	WriteMostly	4		/* Avoid reading if at all possible */
-#define	AllReserved	6		/* If whole device is reserved for
-					 * one array */
 #define	AutoDetected	7		/* added by auto-detect */
 #define Blocked		8		/* An error occured on an externally
 					 * managed array, don't allow writes

commit a6ff7e089c7fca813c956ccbed824087e89a3a49
Author: Jonathan Brassow <jbrassow@redhat.com>
Date:   Fri Jan 14 09:14:34 2011 +1100

    md: separate meta and data devs
    
    Allow the metadata to be on a separate device from the
    data.
    
    This doesn't mean the data and metadata will by on separate
    physical devices - it simply gives device-mapper and userspace
    tools more flexibility.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 7e4f358a26a6..eec517ced31a 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -60,6 +60,12 @@ struct mdk_rdev_s
 	mddev_t *mddev;			/* RAID array if running */
 	int last_events;		/* IO event timestamp */
 
+	/*
+	 * If meta_bdev is non-NULL, it means that a separate device is
+	 * being used to store the metadata (superblock/bitmap) which
+	 * would otherwise be contained on the same device as the data (bdev).
+	 */
+	struct block_device *meta_bdev;
 	struct block_device *bdev;	/* block device handle */
 
 	struct page	*sb_page;

commit ccebd4c4159462c96397ae9af9c667bb394d7b70
Author: Jonathan Brassow <jbrassow@redhat.com>
Date:   Fri Jan 14 09:14:33 2011 +1100

    md-new-param-to_sync_page_io
    
    Add new parameter to 'sync_page_io'.
    
    The new parameter allows us to distinguish between metadata and data
    operations.  This becomes important later when we add the ability to
    use separate devices for data and metadata.
    
    Signed-off-by: Jonathan Brassow <jbrassow@redhat.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 229675a604f7..7e4f358a26a6 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -498,8 +498,8 @@ extern void md_flush_request(mddev_t *mddev, struct bio *bio);
 extern void md_super_write(mddev_t *mddev, mdk_rdev_t *rdev,
 			   sector_t sector, int size, struct page *page);
 extern void md_super_wait(mddev_t *mddev);
-extern int sync_page_io(mdk_rdev_t *rdev, sector_t sector, int size,
-			struct page *page, int rw);
+extern int sync_page_io(mdk_rdev_t *rdev, sector_t sector, int size, 
+			struct page *page, int rw, bool metadata_op);
 extern void md_do_sync(mddev_t *mddev);
 extern void md_new_event(mddev_t *mddev);
 extern int md_allow_write(mddev_t *mddev);

commit 0ca69886a8273ac1350143d562280bfcbe4760dc
Author: NeilBrown <neilb@suse.de>
Date:   Fri Jan 14 09:14:33 2011 +1100

    md: Ensure no IO request to get md device before it is properly initialised.
    
    When an md device is in the process of coming on line it is possible
    for an IO request (typically a partition table probe) to get through
    before the array is fully initialised, which can cause unexpected
    behaviour (e.g. a crash).
    
    So explicitly record when the array is ready for IO and don't allow IO
    through until then.
    
    There is no possibility for a similar problem when the array is going
    off-line as there must only be one 'open' at that time, and it is busy
    off-lining the array and so cannot send IO requests.  So no memory
    barrier is needed in md_stop()
    
    This has been a bug since commit 409c57f3801 in 2.6.30 which
    introduced md_make_request.  Before then, each personality would
    register its own make_request_fn when it was ready.
    This is suitable for any stable kernel from 2.6.30.y onwards.
    
    Cc: <stable@kernel.org>
    Signed-off-by: NeilBrown <neilb@suse.de>
    Reported-by:  "Hawrylewicz Czarnowski, Przemyslaw" <przemyslaw.hawrylewicz.czarnowski@intel.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index d05bab55df4e..229675a604f7 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -148,7 +148,8 @@ struct mddev_s
 						       * are happening, so run/
 						       * takeover/stop are not safe
 						       */
-
+	int				ready; /* See when safe to pass 
+						* IO requests down */
 	struct gendisk			*gendisk;
 
 	struct kobject			kobj;

commit a167f663243662aa9153c01086580a11cde9ffdc
Author: NeilBrown <neilb@suse.de>
Date:   Tue Oct 26 18:31:13 2010 +1100

    md: use separate bio pool for each md device.
    
    bio_clone and bio_alloc allocate from a common bio pool.
    If an md device is stacked with other devices that use this pool, or under
    something like swap which uses the pool, then the multiple calls on
    the pool can cause deadlocks.
    
    So allocate a local bio pool for each md array and use that rather
    than the common pool.
    
    This pool is used both for regular IO and metadata updates.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 5ee537135553..d05bab55df4e 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -331,6 +331,8 @@ struct mddev_s
 	struct attribute_group		*to_remove;
 	struct plug_handle		*plug; /* if used by personality */
 
+	struct bio_set			*bio_set;
+
 	/* Generic flush handling.
 	 * The last to finish preflush schedules a worker to submit
 	 * the rest of the request (without the REQ_FLUSH flag).
@@ -517,4 +519,8 @@ extern void md_rdev_init(mdk_rdev_t *rdev);
 
 extern void mddev_suspend(mddev_t *mddev);
 extern void mddev_resume(mddev_t *mddev);
+extern struct bio *bio_clone_mddev(struct bio *bio, gfp_t gfp_mask,
+				   mddev_t *mddev);
+extern struct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,
+				   mddev_t *mddev);
 #endif /* _MD_MD_H */

commit 2b193363ef68667ad717a6723165e0dccf99470f
Author: NeilBrown <neilb@suse.de>
Date:   Wed Oct 27 15:16:40 2010 +1100

    md: change type of first arg to sync_page_io.
    
    Currently sync_page_io takes a 'bdev'.
    Every caller passes 'rdev->bdev'.
    We will soon want another field out of the rdev in sync_page_io,
    So just pass the rdev instead of the bdev out of it.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 112a2c32db0c..5ee537135553 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -495,7 +495,7 @@ extern void md_flush_request(mddev_t *mddev, struct bio *bio);
 extern void md_super_write(mddev_t *mddev, mdk_rdev_t *rdev,
 			   sector_t sector, int size, struct page *page);
 extern void md_super_wait(mddev_t *mddev);
-extern int sync_page_io(struct block_device *bdev, sector_t sector, int size,
+extern int sync_page_io(mdk_rdev_t *rdev, sector_t sector, int size,
 			struct page *page, int rw);
 extern void md_do_sync(mddev_t *mddev);
 extern void md_new_event(mddev_t *mddev);

commit fa251f89903d73989e2f63e13d0eaed1e07ce0da
Merge: dd3932eddf42 cd07202cc826
Author: Jens Axboe <jaxboe@fusionio.com>
Date:   Tue Oct 19 09:13:04 2010 +0200

    Merge branch 'v2.6.36-rc8' into for-2.6.37/barrier
    
    Conflicts:
            block/blk-core.c
            drivers/block/loop.c
            mm/swapfile.c
    
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

commit e9c7469bb4f502dafc092166201bea1ad5fc0fbf
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Sep 3 11:56:18 2010 +0200

    md: implment REQ_FLUSH/FUA support
    
    This patch converts md to support REQ_FLUSH/FUA instead of now
    deprecated REQ_HARDBARRIER.  In the core part (md.c), the following
    changes are notable.
    
    * Unlike REQ_HARDBARRIER, REQ_FLUSH/FUA don't interfere with
      processing of other requests and thus there is no reason to mark the
      queue congested while FLUSH/FUA is in progress.
    
    * REQ_FLUSH/FUA failures are final and its users don't need retry
      logic.  Retry logic is removed.
    
    * Preflush needs to be issued to all member devices but FUA writes can
      be handled the same way as other writes - their processing can be
      deferred to request_queue of member devices.  md_barrier_request()
      is renamed to md_flush_request() and simplified accordingly.
    
    For linear, raid0 and multipath, the core changes are enough.  raid1,
    5 and 10 need the following conversions.
    
    * raid1: Handling of FLUSH/FUA bio's can simply be deferred to
      request_queues of member devices.  Barrier related logic removed.
    
    * raid5: Queue draining logic dropped.  FUA bit is propagated through
      biodrain and stripe resconstruction such that all the updated parts
      of the stripe are written out with FUA writes if any of the dirtying
      writes was FUA.  preread_active_stripes handling in make_request()
      is updated as suggested by Neil Brown.
    
    * raid10: FUA bit needs to be propagated to write clones.
    
    linear, raid0, 1, 5 and 10 tested.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Neil Brown <neilb@suse.de>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index a953fe2808ae..d8e2ab25103b 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -87,7 +87,6 @@ struct mdk_rdev_s
 #define	Faulty		1		/* device is known to have a fault */
 #define	In_sync		2		/* device is in_sync with rest of array */
 #define	WriteMostly	4		/* Avoid reading if at all possible */
-#define	BarriersNotsupp	5		/* REQ_HARDBARRIER is not supported */
 #define	AllReserved	6		/* If whole device is reserved for
 					 * one array */
 #define	AutoDetected	7		/* added by auto-detect */
@@ -273,13 +272,6 @@ struct mddev_s
 	int				degraded;	/* whether md should consider
 							 * adding a spare
 							 */
-	int				barriers_work;	/* initialised to true, cleared as soon
-							 * as a barrier request to slave
-							 * fails.  Only supported
-							 */
-	struct bio			*biolist; 	/* bios that need to be retried
-							 * because REQ_HARDBARRIER is not supported
-							 */
 
 	atomic_t			recovery_active; /* blocks scheduled, but not written */
 	wait_queue_head_t		recovery_wait;
@@ -339,16 +331,13 @@ struct mddev_s
 	struct attribute_group		*to_remove;
 	struct plug_handle		*plug; /* if used by personality */
 
-	/* Generic barrier handling.
-	 * If there is a pending barrier request, all other
-	 * writes are blocked while the devices are flushed.
-	 * The last to finish a flush schedules a worker to
-	 * submit the barrier request (without the barrier flag),
-	 * then submit more flush requests.
+	/* Generic flush handling.
+	 * The last to finish preflush schedules a worker to submit
+	 * the rest of the request (without the REQ_FLUSH flag).
 	 */
-	struct bio *barrier;
+	struct bio *flush_bio;
 	atomic_t flush_pending;
-	struct work_struct barrier_work;
+	struct work_struct flush_work;
 	struct work_struct event_work;	/* used by dm to report failure event */
 };
 
@@ -502,7 +491,7 @@ extern void md_done_sync(mddev_t *mddev, int blocks, int ok);
 extern void md_error(mddev_t *mddev, mdk_rdev_t *rdev);
 
 extern int mddev_congested(mddev_t *mddev, int bits);
-extern void md_barrier_request(mddev_t *mddev, struct bio *bio);
+extern void md_flush_request(mddev_t *mddev, struct bio *bio);
 extern void md_super_write(mddev_t *mddev, mdk_rdev_t *rdev,
 			   sector_t sector, int size, struct page *page);
 extern void md_super_wait(mddev_t *mddev);

commit 070dc6dd7103b6b3f7e4d46e754354a5c15f366e
Author: NeilBrown <neilb@suse.de>
Date:   Mon Aug 30 17:33:34 2010 +1000

    md: resolve confusion of MD_CHANGE_CLEAN
    
    MD_CHANGE_CLEAN is used for two different purposes and this leads to
    confusion.
    One of the purposes is largely mirrored by MD_CHANGE_PENDING which is
    not used for anything else, so have MD_CHANGE_PENDING take over that
    purpose fully.
    
    The two purposes are:
     1/ tell md_update_sb that an update is needed and that it is just a
       clean/dirty transition.
     2/ tell user-space that an transition from clean to dirty is pending
        (something wants to write), and tell te kernel (by clearin the
        flag) that the transition is OK.
    
    The first purpose remains wit MD_CHANGE_CLEAN, the second is moved
    fully to MD_CHANGE_PENDING.
    
    This means that various places which conditionally set or cleared
    MD_CHANGE_CLEAN no longer need to be conditional.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index a953fe2808ae..3931299788dc 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -140,7 +140,7 @@ struct mddev_s
 	unsigned long			flags;
 #define MD_CHANGE_DEVS	0	/* Some device status has changed */
 #define MD_CHANGE_CLEAN 1	/* transition to or from 'clean' */
-#define MD_CHANGE_PENDING 2	/* superblock update in progress */
+#define MD_CHANGE_PENDING 2	/* switch from 'clean' to 'active' in progress */
 
 	int				suspended;
 	atomic_t			active_io;

commit 3d30701b58970425e1d45994d6cb82f828924fdd
Merge: 8cbd84f2dd4e fd8aa2c1811b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Aug 10 15:38:19 2010 -0700

    Merge branch 'for-linus' of git://neil.brown.name/md
    
    * 'for-linus' of git://neil.brown.name/md: (24 commits)
      md: clean up do_md_stop
      md: fix another deadlock with removing sysfs attributes.
      md: move revalidate_disk() back outside open_mutex
      md/raid10: fix deadlock with unaligned read during resync
      md/bitmap:  separate out loading a bitmap from initialising the structures.
      md/bitmap: prepare for storing write-intent-bitmap via dm-dirty-log.
      md/bitmap: optimise scanning of empty bitmaps.
      md/bitmap: clean up plugging calls.
      md/bitmap: reduce dependence on sysfs.
      md/bitmap: white space clean up and similar.
      md/raid5: export raid5 unplugging interface.
      md/plug: optionally use plugger to unplug an array during resync/recovery.
      md/raid5: add simple plugging infrastructure.
      md/raid5: export is_congested test
      raid5: Don't set read-ahead when there is no queue
      md: add support for raising dm events.
      md: export various start/stop interfaces
      md: split out md_rdev_init
      md: be more careful setting MD_CHANGE_CLEAN
      md/raid5: ensure we create a unique name for kmem_cache when mddev has no gendisk
      ...

commit bb4f1e9d0e2ef93de8e36ca0f5f26625fcd70b7d
Author: NeilBrown <neilb@suse.de>
Date:   Sun Aug 8 21:18:03 2010 +1000

    md: fix another deadlock with removing sysfs attributes.
    
    Move the deletion of sysfs attributes from reconfig_mutex to
    open_mutex didn't really help as a process can try to take
    open_mutex while holding reconfig_mutex, so the same deadlock can
    happen, just requiring one more process to be involved in the chain.
    
    I looks like I cannot easily use locking to wait for the sysfs
    deletion to complete, so don't.
    
    The only things that we cannot do while the deletions are still
    pending is other things which can change the sysfs namespace: run,
    takeover, stop.  Each of these can fail with -EBUSY.
    So set a flag while doing a sysfs deletion, and fail run, takeover,
    stop if that flag is set.
    
    This is suitable for 2.6.35.x
    
    Cc: stable@kernel.org
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index cccbadb31bae..6f797eceae31 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -145,6 +145,10 @@ struct mddev_s
 	int				suspended;
 	atomic_t			active_io;
 	int				ro;
+	int				sysfs_active; /* set when sysfs deletes
+						       * are happening, so run/
+						       * takeover/stop are not safe
+						       */
 
 	struct gendisk			*gendisk;
 

commit 7b6d91daee5cac6402186ff224c3af39d79f4a0e
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Aug 7 18:20:39 2010 +0200

    block: unify flags for struct bio and struct request
    
    Remove the current bio flags and reuse the request flags for the bio, too.
    This allows to more easily trace the type of I/O from the filesystem
    down to the block driver.  There were two flags in the bio that were
    missing in the requests:  BIO_RW_UNPLUG and BIO_RW_AHEAD.  Also I've
    renamed two request flags that had a superflous RW in them.
    
    Note that the flags are in bio.h despite having the REQ_ name - as
    blkdev.h includes bio.h that is the only way to go for now.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 10597bfec000..fc56e0f21c80 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -67,7 +67,7 @@ struct mdk_rdev_s
 #define	Faulty		1		/* device is known to have a fault */
 #define	In_sync		2		/* device is in_sync with rest of array */
 #define	WriteMostly	4		/* Avoid reading if at all possible */
-#define	BarriersNotsupp	5		/* BIO_RW_BARRIER is not supported */
+#define	BarriersNotsupp	5		/* REQ_HARDBARRIER is not supported */
 #define	AllReserved	6		/* If whole device is reserved for
 					 * one array */
 #define	AutoDetected	7		/* added by auto-detect */
@@ -254,7 +254,7 @@ struct mddev_s
 							 * fails.  Only supported
 							 */
 	struct bio			*biolist; 	/* bios that need to be retried
-							 * because BIO_RW_BARRIER is not supported
+							 * because REQ_HARDBARRIER is not supported
 							 */
 
 	atomic_t			recovery_active; /* blocks scheduled, but not written */

commit e384e58549a2e9a83071ad80280c1a9053cfd84c
Author: NeilBrown <neilb@suse.de>
Date:   Tue Jun 1 19:37:34 2010 +1000

    md/bitmap: prepare for storing write-intent-bitmap via dm-dirty-log.
    
    This allows md/raid5 to fully work as a dm target.
    
    Normally md uses a 'filemap' which contains a list of pages of bits
    each of which may be written separately.
    dm-log uses and all-or-nothing approach to writing the log, so
    when using a dm-log, ->filemap is NULL and the flags normally stored
    in filemap_attr are stored in ->logattrs instead.
    
    
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 0a850780b5d1..cccbadb31bae 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -317,6 +317,11 @@ struct mddev_s
 							 * hot-adding a bitmap.  It should
 							 * eventually be settable by sysfs.
 							 */
+		/* When md is serving under dm, it might use a
+		 * dirty_log to store the bits.
+		 */
+		struct dm_dirty_log *log;
+
 		struct mutex		mutex;
 		unsigned long		chunksize;
 		unsigned long		daemon_sleep; /* how many jiffies between updates? */

commit b63d7c2e29bf9cc94989806f2df0cfca4976b830
Author: NeilBrown <neilb@suse.de>
Date:   Tue Jun 1 19:37:33 2010 +1000

    md/bitmap: clean up plugging calls.
    
    1/ use md_unplug in bitmap.c as we will soon be using bitmaps under
      arrays with no queue attached.
    
    2/ Don't bother plugging the queue when we set a bit in the bitmap.
       The reason for this was to encourage as many bits as possible to
       get set before we unplug and write stuff out.
       However every personality already plugs the queue after
       bitmap_startwrite either directly (raid1/raid10) or be setting
       STRIPE_BIT_DELAY which causes the queue to be plugged later
       (raid5).
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 209993207a55..0a850780b5d1 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -509,6 +509,7 @@ extern int md_integrity_register(mddev_t *mddev);
 extern void md_integrity_add_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
 extern int strict_strtoul_scaled(const char *cp, unsigned long *res, int scale);
 extern void restore_bitmap_write_access(struct file *file);
+extern void md_unplug(mddev_t *mddev);
 
 extern void mddev_init(mddev_t *mddev);
 extern int md_run(mddev_t *mddev);

commit ac2f40be46ce6ab3bec4c8c297d6923f941741ce
Author: NeilBrown <neilb@suse.de>
Date:   Tue Jun 1 19:37:31 2010 +1000

    md/bitmap: white space clean up and similar.
    
    Fixes some whitespace problems
    Fixed some checkpatch.pl complaints.
    Replaced kmalloc ... memset(0), with kzalloc
    Fixed an unlikely memory leak on an error path.
    Reformatted a number of 'if/else' sets, sometimes
    replacing goto with an else clause.
    Removed some old comments and commented-out code.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 57eb864a8249..209993207a55 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -319,7 +319,7 @@ struct mddev_s
 							 */
 		struct mutex		mutex;
 		unsigned long		chunksize;
-		unsigned long		daemon_sleep; /* how many seconds between updates? */
+		unsigned long		daemon_sleep; /* how many jiffies between updates? */
 		unsigned long		max_write_behind; /* write-behind mode */
 		int			external;
 	} bitmap_info;

commit 252ac5221a71be72b7e7c7b7482af91e9c962e8c
Author: NeilBrown <neilb@suse.de>
Date:   Tue Jun 1 19:37:29 2010 +1000

    md/plug: optionally use plugger to unplug an array during resync/recovery.
    
    If an array doesn't have a 'queue' then md_do_sync cannot
    unplug it.
    In that case it will have a 'plugger', so make that available
    to the mddev, and use it to unplug the array if needed.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 5be0d6921b9d..57eb864a8249 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -328,6 +328,8 @@ struct mddev_s
 	struct list_head		all_mddevs;
 
 	struct attribute_group		*to_remove;
+	struct plug_handle		*plug; /* if used by personality */
+
 	/* Generic barrier handling.
 	 * If there is a pending barrier request, all other
 	 * writes are blocked while the devices are flushed.

commit 2ac8740151b082f045e58010eb92560c3a23a0e9
Author: NeilBrown <neilb@suse.de>
Date:   Tue Jun 1 19:37:29 2010 +1000

    md/raid5: add simple plugging infrastructure.
    
    md/raid5 uses the plugging infrastructure provided by the block layer
    and 'struct request_queue'.  However when we plug raid5 under dm there
    is no request queue so we cannot use that.
    
    So create a similar infrastructure that is much lighter weight and use
    it for raid5.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index c88b04745e85..5be0d6921b9d 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -29,6 +29,26 @@
 typedef struct mddev_s mddev_t;
 typedef struct mdk_rdev_s mdk_rdev_t;
 
+/* generic plugging support - like that provided with request_queue,
+ * but does not require a request_queue
+ */
+struct plug_handle {
+	void			(*unplug_fn)(struct plug_handle *);
+	struct timer_list	unplug_timer;
+	struct work_struct	unplug_work;
+	unsigned long		unplug_flag;
+};
+#define	PLUGGED_FLAG 1
+void plugger_init(struct plug_handle *plug,
+		  void (*unplug_fn)(struct plug_handle *));
+void plugger_set_plug(struct plug_handle *plug);
+int plugger_remove_plug(struct plug_handle *plug);
+static inline void plugger_flush(struct plug_handle *plug)
+{
+	del_timer_sync(&plug->unplug_timer);
+	cancel_work_sync(&plug->unplug_work);
+}
+
 /*
  * MD's 'extended' device
  */

commit 768a418db102bb6aa6064e6090892b5c21ff1f9e
Author: NeilBrown <neilb@suse.de>
Date:   Mon Jul 26 11:49:55 2010 +1000

    md: add support for raising dm events.
    
    dm uses scheduled work to raise events to user-space.
    So allow md device to have work_structs and schedule them on an error.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 6e7e3495f6e4..c88b04745e85 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -318,6 +318,7 @@ struct mddev_s
 	struct bio *barrier;
 	atomic_t flush_pending;
 	struct work_struct barrier_work;
+	struct work_struct event_work;	/* used by dm to report failure event */
 };
 
 

commit 390ee602a142a93f2c7eb7bffee8e277058b8e0a
Author: NeilBrown <neilb@suse.de>
Date:   Tue Jun 1 19:37:27 2010 +1000

    md: export various start/stop interfaces
    
    export entry points for starting and stopping md arrays.
    This will be used by a module to make md/raid5 work under
    dm.
    Also stop calling md_stop_writes from md_stop, as that won't
    work well with dm - it will want to call the two separately.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index cc8030543e82..6e7e3495f6e4 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -487,5 +487,12 @@ extern void md_integrity_add_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
 extern int strict_strtoul_scaled(const char *cp, unsigned long *res, int scale);
 extern void restore_bitmap_write_access(struct file *file);
 
+extern void mddev_init(mddev_t *mddev);
+extern int md_run(mddev_t *mddev);
+extern void md_stop(mddev_t *mddev);
+extern void md_stop_writes(mddev_t *mddev);
 extern void md_rdev_init(mdk_rdev_t *rdev);
+
+extern void mddev_suspend(mddev_t *mddev);
+extern void mddev_resume(mddev_t *mddev);
 #endif /* _MD_MD_H */

commit e8bb9a839a26f076379e9cb9f46a879d210156f1
Author: NeilBrown <neilb@suse.de>
Date:   Tue Jun 1 19:37:26 2010 +1000

    md: split out md_rdev_init
    
    This functionality will be needed separately in a subsequent patch, so
    split it into it's own exported function.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 1e6405918eec..cc8030543e82 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -487,4 +487,5 @@ extern void md_integrity_add_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
 extern int strict_strtoul_scaled(const char *cp, unsigned long *res, int scale);
 extern void restore_bitmap_write_access(struct file *file);
 
+extern void md_rdev_init(mdk_rdev_t *rdev);
 #endif /* _MD_MD_H */

commit 00bcb4ac7ee7e557a491b614219142cea0ef16f4
Author: NeilBrown <neilb@suse.de>
Date:   Tue Jun 1 19:37:23 2010 +1000

    md: reduce dependence on sysfs.
    
    We will want md devices to live as dm targets where sysfs is not
    visible.  So allow md to not connect to sysfs.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 10597bfec000..1e6405918eec 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -382,6 +382,18 @@ struct md_sysfs_entry {
 };
 extern struct attribute_group md_bitmap_group;
 
+static inline struct sysfs_dirent *sysfs_get_dirent_safe(struct sysfs_dirent *sd, char *name)
+{
+	if (sd)
+		return sysfs_get_dirent(sd, NULL, name);
+	return sd;
+}
+static inline void sysfs_notify_dirent_safe(struct sysfs_dirent *sd)
+{
+	if (sd)
+		sysfs_notify_dirent(sd);
+}
+
 static inline char * mdname (mddev_t * mddev)
 {
 	return mddev->gendisk ? mddev->gendisk->disk_name : "mdX";

commit e93f68a1fc6244c05ad8fae28e75835ec74ab34e
Author: NeilBrown <neilb@suse.de>
Date:   Tue Jun 15 09:36:03 2010 +0100

    md: fix handling of array level takeover that re-arranges devices.
    
    Most array level changes leave the list of devices largely unchanged,
    possibly causing one at the end to become redundant.
    However conversions between RAID0 and RAID10 need to renumber
    all devices (except 0).
    
    This renumbering is currently being done in the ->run method when the
    new personality takes over.  However this is too late as the common
    code in md.c might already have invalidated some of the devices if
    they had a ->raid_disk number that appeared to high.
    
    Moving it into the ->takeover method is too early as the array is
    still active at that time and wrong ->raid_disk numbers could cause
    confusion.
    
    So add a ->new_raid_disk field to mdk_rdev_s and use it to communicate
    the new raid_disk number.
    Now the common code knows exactly which devices need to be renumbered,
    and which can be invalidated, and can do it all at a convenient time
    when the array is suspend.
    It can also update some symlinks in sysfs which previously were not be
    updated correctly.
    
    Reported-by: Maciej Trela <maciej.trela@intel.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 7ab5ea155452..10597bfec000 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -78,6 +78,9 @@ struct mdk_rdev_s
 
 	int desc_nr;			/* descriptor index in the superblock */
 	int raid_disk;			/* role of device in array */
+	int new_raid_disk;		/* role that the device will have in
+					 * the array after a level-change completes.
+					 */
 	int saved_raid_disk;		/* role that device used to have in the
 					 * array and could again if we did a partial
 					 * resync from the bitmap

commit a8707c08f4f718bb0ed65499d3f43201f6e41455
Author: NeilBrown <neilb@suse.de>
Date:   Tue May 18 09:28:43 2010 +1000

    md: simplify updating of event count to sometimes avoid updating spares.
    
    When updating the event count for a simple clean <-> dirty transition,
    we try to avoid updating the spares so they can safely spin-down.
    As the event_counts across an array must be +/- 1, this means
    decrementing the event_count on a dirty->clean transition.
    This is not always safe and we have to avoid the unsafe time.
    We current do this with a misguided idea about it being safe or
    not depending on whether the event_count is odd or even.  This
    approach only works reliably in a few common instances, but easily
    falls down.
    
    So instead, simply keep internal state concerning whether it is safe
    or not, and always assume it is not safe when an array is first
    assembled.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index a536f5458097..7ab5ea155452 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -150,6 +150,12 @@ struct mddev_s
 	int				external_size; /* size managed
 							* externally */
 	__u64				events;
+	/* If the last 'event' was simply a clean->dirty transition, and
+	 * we didn't write it to the spares, then it is safe and simple
+	 * to just decrement the event count on a dirty->clean transition.
+	 * So we record that possibility here.
+	 */
+	int				can_decrease_events;
 
 	char				uuid[16];
 

commit 21a52c6d05c15f862797736393915bfa8cd40ee9
Author: NeilBrown <neilb@suse.de>
Date:   Thu Apr 1 15:02:13 2010 +1100

    md: pass mddev to make_request functions rather than request_queue
    
    We used to pass the personality make_request function direct
    to the block layer so the first argument had to be a queue.
    But now we have the intermediary md_make_request so it makes
    at lot more sense to pass a struct mddev_s.
    It makes it possible to have an mddev without its own queue too.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 3225e25f3c2a..a536f5458097 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -330,7 +330,7 @@ struct mdk_personality
 	int level;
 	struct list_head list;
 	struct module *owner;
-	int (*make_request)(struct request_queue *q, struct bio *bio);
+	int (*make_request)(mddev_t *mddev, struct bio *bio);
 	int (*run)(mddev_t *mddev);
 	int (*stop)(mddev_t *mddev);
 	void (*status)(struct seq_file *seq, mddev_t *mddev);

commit b821eaa572fd737faaf6928ba046e571526c36c6
Author: NeilBrown <neilb@suse.de>
Date:   Mon Mar 29 11:18:15 2010 +1100

    md: remove ->changed and related code.
    
    We set ->changed to 1 and call check_disk_change at the end
    of md_open so that bd_invalidated would be set and thus
    partition rescan would happen appropriately.
    
    Now that we call revalidate_disk directly, which sets bd_invalidates,
    that indirection is no longer needed and can be removed.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index e4836c68b73e..3225e25f3c2a 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -237,7 +237,6 @@ struct mddev_s
 	atomic_t			active;		/* general refcount */
 	atomic_t			openers;	/* number of active opens */
 
-	int				changed;	/* true if we might need to reread partition info */
 	int				degraded;	/* whether md should consider
 							 * adding a spare
 							 */

commit c0cc75f84e0e413bce2dcabea74ef418da45c7c1
Author: NeilBrown <neilb@suse.de>
Date:   Mon Mar 22 10:28:51 2010 +1100

    md: discard StateChanged device flag.
    
    This was needed when sysfs files could only be 'notified'
    from process context.  Now that we have sys_notify_direct,
    we can call it directly from an interrupt.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 05145786b50f..e4836c68b73e 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -74,9 +74,6 @@ struct mdk_rdev_s
 #define Blocked		8		/* An error occured on an externally
 					 * managed array, don't allow writes
 					 * until it is cleared */
-#define StateChanged	9		/* Faulty or Blocked has changed during
-					 * interrupt, so it needs to be
-					 * notified by the thread */
 	wait_queue_head_t blocked_wait;
 
 	int desc_nr;			/* descriptor index in the superblock */

commit ee8b81b03dffa1c0075553d01c557714aedb85a1
Author: NeilBrown <neilb@suse.de>
Date:   Mon Mar 8 16:02:36 2010 +1100

    md: remove some dead fields from mddev_s
    
    These fields have never been used.
    commit 4b6d287f627b5fb6a49f78f9e81649ff98c62bb7
    added them, but also added identical files to bitmap_super_s,
    and only used the latter.
    
    So remove these unused fields.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 722f5dfe1953..05145786b50f 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -279,9 +279,6 @@ struct mddev_s
 	atomic_t			writes_pending; 
 	struct request_queue		*queue;	/* for plugging ... */
 
-	atomic_t                        write_behind; /* outstanding async IO */
-	unsigned int                    max_write_behind; /* 0 = sync */
-
 	struct bitmap                   *bitmap; /* the bitmap for the device */
 	struct {
 		struct file		*file; /* the bitmap file */

commit a64c876fd357906a1f7193723866562ad290654c
Author: NeilBrown <neilb@suse.de>
Date:   Wed Apr 14 17:15:37 2010 +1000

    md: manage redundancy group in sysfs when changing level.
    
    Some levels expect the 'redundancy group' to be present,
    others don't.
    So when we change level of an array we might need to
    add or remove this group.
    
    This requires fixing up the current practice of overloading ->private
    to indicate (when ->pers == NULL) that something needs to be removed.
    So create a new ->to_remove to fill that role.
    
    When changing levels, we may need to add or remove attributes.  When
    changing RAID5 -> RAID6, we both add and remove the same thing.  It is
    important to catch this and optimise it out as the removal is delayed
    until a lock is released, so trying to add immediately would cause
    problems.
    
    
    Cc: stable@kernel.org
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 8e4c75c00d46..722f5dfe1953 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -305,6 +305,7 @@ struct mddev_s
 	atomic_t 			max_corr_read_errors; /* max read retries */
 	struct list_head		all_mddevs;
 
+	struct attribute_group		*to_remove;
 	/* Generic barrier handling.
 	 * If there is a pending barrier request, all other
 	 * writes are blocked while the devices are flushed.

commit 1e50915fe0bbf7a46db0fa7e1e604d3fc95f057d
Author: Robert Becker <Rob.Becker@riverbed.com>
Date:   Mon Dec 14 12:49:58 2009 +1100

    raid: improve MD/raid10 handling of correctable read errors.
    
    We've noticed severe lasting performance degradation of our raid
    arrays when we have drives that yield large amounts of media errors.
    The raid10 module will queue each failed read for retry, and also
    will attempt call fix_read_error() to perform the read recovery.
    Read recovery is performed while the array is frozen, so repeated
    recovery attempts can degrade the performance of the array for
    extended periods of time.
    
    With this patch I propose adding a per md device max number of
    corrected read attempts.  Each rdev will maintain a count of
    read correction attempts in the rdev->read_errors field (not
    used currently for raid10). When we enter fix_read_error()
    we'll check to see when the last read error occurred, and
    divide the read error count by 2 for every hour since the
    last read error. If at that point our read error count
    exceeds the read error threshold, we'll fail the raid device.
    
    In addition in this patch I add sysfs nodes (get/set) for
    the per md max_read_errors attribute, the rdev->read_errors
    attribute, and added some printk's to indicate when
    fix_read_error fails to repair an rdev.
    
    For testing I used debugfs->fail_make_request to inject
    IO errors to the rdev while doing IO to the raid array.
    
    Signed-off-by: Robert Becker <Rob.Becker@riverbed.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index d9138885b87f..8e4c75c00d46 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -97,6 +97,9 @@ struct mdk_rdev_s
 	atomic_t	read_errors;	/* number of consecutive read errors that
 					 * we have tried to ignore.
 					 */
+	struct timespec last_read_error;	/* monotonic time since our
+						 * last read error
+						 */
 	atomic_t	corrected_errors; /* number of corrected read errors,
 					   * for reporting to userspace and storing
 					   * in superblock.
@@ -299,6 +302,7 @@ struct mddev_s
 		int			external;
 	} bitmap_info;
 
+	atomic_t 			max_corr_read_errors; /* max read retries */
 	struct list_head		all_mddevs;
 
 	/* Generic barrier handling.

commit ece5cff0da9e696c360fff592cb5f51b6419e4d6
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 14 12:49:56 2009 +1100

    md: Support write-intent bitmaps with externally managed metadata.
    
    In this case, the metadata needs to not be in the same
    sector as the bitmap.
    md will not read/write any bitmap metadata.  Config must be
    done via sysfs and when a recovery makes the array non-degraded
    again, writing 'true' to 'bitmap/can_clear' will allow bits in
    the bitmap to be cleared again.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index fce02073f1a4..d9138885b87f 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -296,6 +296,7 @@ struct mddev_s
 		unsigned long		chunksize;
 		unsigned long		daemon_sleep; /* how many seconds between updates? */
 		unsigned long		max_write_behind; /* write-behind mode */
+		int			external;
 	} bitmap_info;
 
 	struct list_head		all_mddevs;

commit 43a705076e51c5af21ec4260a35699775ea298f5
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 14 12:49:55 2009 +1100

    md: support updating bitmap parameters via sysfs.
    
    A new attribute directory 'bitmap' in 'md' is created which
    contains files for configuring the bitmap.
    'location' identifies where the bitmap is, either 'none',
    or 'file' or 'sector offset from metadata'.
    Writing 'location' can create or remove a bitmap.
    Adding a 'file' bitmap this way is not yet supported.
    'chunksize' and 'time_base' must be set before 'location'
    can be set.
    
    'chunksize' can be set before creating a bitmap, but is
    currently always over-ridden by the bitmap superblock.
    
    'time_base' and 'backlog' can be updated at any time.
    
    
    Signed-off-by: NeilBrown <neilb@suse.de>
    Reviewed-by: Andre Noll <maan@systemlinux.org>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index b5c306925d94..fce02073f1a4 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -372,7 +372,7 @@ struct md_sysfs_entry {
 	ssize_t (*show)(mddev_t *, char *);
 	ssize_t (*store)(mddev_t *, const char *, size_t);
 };
-
+extern struct attribute_group md_bitmap_group;
 
 static inline char * mdname (mddev_t * mddev)
 {
@@ -465,5 +465,6 @@ extern int md_check_no_bitmap(mddev_t *mddev);
 extern int md_integrity_register(mddev_t *mddev);
 extern void md_integrity_add_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
 extern int strict_strtoul_scaled(const char *cp, unsigned long *res, int scale);
+extern void restore_bitmap_write_access(struct file *file);
 
 #endif /* _MD_MD_H */

commit 72e02075a33f739e21430262f71da8e82db9dbb3
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 14 12:49:55 2009 +1100

    md: factor out parsing of fixed-point numbers
    
    safe_delay_store can parse fixed point numbers (for fractions
    of a second).  We will want to do that for another sysfs
    file soon, so factor out the code.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index df692953a12f..b5c306925d94 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -463,6 +463,7 @@ extern void md_wait_for_blocked_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
 extern void md_set_array_sectors(mddev_t *mddev, sector_t array_sectors);
 extern int md_check_no_bitmap(mddev_t *mddev);
 extern int md_integrity_register(mddev_t *mddev);
-void md_integrity_add_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
+extern void md_integrity_add_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
+extern int strict_strtoul_scaled(const char *cp, unsigned long *res, int scale);
 
 #endif /* _MD_MD_H */

commit f6af949c5672115313cc3c976d85b0533f607d7e
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 14 12:49:54 2009 +1100

    md: support bitmap offset appropriate for external-metadata arrays.
    
    For md arrays were metadata is managed externally, the kernel does not
    know about a superblock so the superblock offset is 0.
    If we want to have a write-intent-bitmap near the end of the
    devices of such an array, we should support sector_t sized offset.
    We need offset be possibly negative for when the bitmap is before
    the metadata, so use loff_t instead.
    
    Also add sanity check that bitmap does not overlap with data.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 4b07e0ab3841..df692953a12f 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -282,11 +282,13 @@ struct mddev_s
 	struct bitmap                   *bitmap; /* the bitmap for the device */
 	struct {
 		struct file		*file; /* the bitmap file */
-		long			offset; /* offset from superblock of
+		loff_t			offset; /* offset from superblock of
 						 * start of bitmap. May be
 						 * negative, but not '0'
+						 * For external metadata, offset
+						 * from start of device. 
 						 */
-		long			default_offset; /* this is the offset to use when
+		loff_t			default_offset; /* this is the offset to use when
 							 * hot-adding a bitmap.  It should
 							 * eventually be settable by sysfs.
 							 */

commit 42a04b5078ce73a32f85762551d5703c5bd646a1
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 14 12:49:53 2009 +1100

    md: move offset, daemon_sleep and chunksize out of bitmap structure
    
    ... and into bitmap_info.  These are all configuration parameters
    that need to be set before the bitmap is created.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 50e62ef32e9d..4b07e0ab3841 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -291,6 +291,9 @@ struct mddev_s
 							 * eventually be settable by sysfs.
 							 */
 		struct mutex		mutex;
+		unsigned long		chunksize;
+		unsigned long		daemon_sleep; /* how many seconds between updates? */
+		unsigned long		max_write_behind; /* write-behind mode */
 	} bitmap_info;
 
 	struct list_head		all_mddevs;

commit c3d9714e88c8685cf9bc837c3241fc005f95fb82
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 14 12:49:52 2009 +1100

    md: collect bitmap-specific fields into one structure.
    
    In preparation for making bitmap fields configurable via sysfs,
    start tidying up by making a single structure to contain the
    configuration fields.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index cb036868a9e9..50e62ef32e9d 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -280,16 +280,18 @@ struct mddev_s
 	unsigned int                    max_write_behind; /* 0 = sync */
 
 	struct bitmap                   *bitmap; /* the bitmap for the device */
-	struct file			*bitmap_file; /* the bitmap file */
-	long				bitmap_offset; /* offset from superblock of
-							* start of bitmap. May be
-							* negative, but not '0'
-							*/
-	long				default_bitmap_offset; /* this is the offset to use when
-								* hot-adding a bitmap.  It should
-								* eventually be settable by sysfs.
-								*/
-	struct mutex			bitmap_mutex;
+	struct {
+		struct file		*file; /* the bitmap file */
+		long			offset; /* offset from superblock of
+						 * start of bitmap. May be
+						 * negative, but not '0'
+						 */
+		long			default_offset; /* this is the offset to use when
+							 * hot-adding a bitmap.  It should
+							 * eventually be settable by sysfs.
+							 */
+		struct mutex		mutex;
+	} bitmap_info;
 
 	struct list_head		all_mddevs;
 

commit a2826aa92e2e14db372eda01d333267258944033
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 14 12:49:49 2009 +1100

    md: support barrier requests on all personalities.
    
    Previously barriers were only supported on RAID1.  This is because
    other levels requires synchronisation across all devices and so needed
    a different approach.
    Here is that approach.
    
    When a barrier arrives, we send a zero-length barrier to every active
    device.  When that completes - and if the original request was not
    empty -  we submit the barrier request itself (with the barrier flag
    cleared) and then submit a fresh load of zero length barriers.
    
    The barrier request itself is asynchronous, but any subsequent
    request will block until the barrier completes.
    
    The reason for clearing the barrier flag is that a barrier request is
    allowed to fail.  If we pass a non-empty barrier through a striping
    raid level it is conceivable that part of it could succeed and part
    could fail.  That would be way too hard to deal with.
    So if the first run of zero length barriers succeed, we assume all is
    sufficiently well that we send the request and ignore errors in the
    second run of barriers.
    
    RAID5 needs extra care as write requests may not have been submitted
    to the underlying devices yet.  So we flush the stripe cache before
    proceeding with the barrier.
    
    Note that the second set of zero-length barriers are submitted
    immediately after the original request is submitted.  Thus when
    a personality finds mddev->barrier to be set during make_request,
    it should not return from make_request until the corresponding
    per-device request(s) have been queued.
    
    That will be done in later patches.
    
    Signed-off-by: NeilBrown <neilb@suse.de>
    Reviewed-by: Andre Noll <maan@systemlinux.org>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 87430fea2875..cb036868a9e9 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -292,6 +292,17 @@ struct mddev_s
 	struct mutex			bitmap_mutex;
 
 	struct list_head		all_mddevs;
+
+	/* Generic barrier handling.
+	 * If there is a pending barrier request, all other
+	 * writes are blocked while the devices are flushed.
+	 * The last to finish a flush schedules a worker to
+	 * submit the barrier request (without the barrier flag),
+	 * then submit more flush requests.
+	 */
+	struct bio *barrier;
+	atomic_t flush_pending;
+	struct work_struct barrier_work;
 };
 
 
@@ -432,6 +443,7 @@ extern void md_done_sync(mddev_t *mddev, int blocks, int ok);
 extern void md_error(mddev_t *mddev, mdk_rdev_t *rdev);
 
 extern int mddev_congested(mddev_t *mddev, int bits);
+extern void md_barrier_request(mddev_t *mddev, struct bio *bio);
 extern void md_super_write(mddev_t *mddev, mdk_rdev_t *rdev,
 			   sector_t sector, int size, struct page *page);
 extern void md_super_wait(mddev_t *mddev);

commit aa5cbd103887011b4830355f88fb055f9ad2d556
Author: NeilBrown <neilb@suse.de>
Date:   Mon Dec 14 12:49:46 2009 +1100

    md/bitmap: protect against bitmap removal while being updated.
    
    A write intent bitmap can be removed from an array while the
    array is active.
    When this happens, all IO is suspended and flushed before the
    bitmap is removed.
    However it is possible that bitmap_daemon_work is still running to
    clear old bits from the bitmap.  If it is, it can dereference the
    bitmap after it has been freed.
    
    So introduce a new mutex to protect bitmap_daemon_work and get it
    before destroying a bitmap.
    
    This is suitable for any current -stable kernel.
    
    Signed-off-by: NeilBrown <neilb@suse.de>
    Cc: stable@kernel.org

diff --git a/drivers/md/md.h b/drivers/md/md.h
index f184b69ef337..87430fea2875 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -289,6 +289,7 @@ struct mddev_s
 								* hot-adding a bitmap.  It should
 								* eventually be settable by sysfs.
 								*/
+	struct mutex			bitmap_mutex;
 
 	struct list_head		all_mddevs;
 };

commit 3fa841d7e7266f6fcc1b3885b905f5153ba897d8
Author: NeilBrown <neilb@suse.de>
Date:   Wed Sep 23 18:10:29 2009 +1000

    md: report device as congested when suspended
    
    This should writeback from coming when the device is temporarily
    suspended.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index f55d2ff95133..f184b69ef337 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -430,6 +430,7 @@ extern void md_write_end(mddev_t *mddev);
 extern void md_done_sync(mddev_t *mddev, int blocks, int ok);
 extern void md_error(mddev_t *mddev, mdk_rdev_t *rdev);
 
+extern int mddev_congested(mddev_t *mddev, int bits);
 extern void md_super_write(mddev_t *mddev, mdk_rdev_t *rdev,
 			   sector_t sector, int size, struct page *page);
 extern void md_super_wait(mddev_t *mddev);

commit 411c94038594b2a3fd123d09bdec3fe2500e383d
Author: Anand Gadiyar <gadiyar@ti.com>
Date:   Tue Jul 7 15:24:23 2009 +0530

    trivial: fix typo "for for" in multiple files
    
    trivial: fix typo "for for" in multiple files
    
    Signed-off-by: Anand Gadiyar <gadiyar@ti.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index f8fc188bc762..f55d2ff95133 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -201,7 +201,7 @@ struct mddev_s
 	 * INTR:     resync needs to be aborted for some reason
 	 * DONE:     thread is done and is waiting to be reaped
 	 * REQUEST:  user-space has requested a sync (used with SYNC)
-	 * CHECK:    user-space request for for check-only, no repair
+	 * CHECK:    user-space request for check-only, no repair
 	 * RESHAPE:  A reshape is happening
 	 *
 	 * If neither SYNC or RESHAPE are set, then it is a recovery.

commit c8c00a6915a2e3d10416e8bdd3138429beb96210
Author: NeilBrown <neilb@suse.de>
Date:   Mon Aug 10 12:50:52 2009 +1000

    Remove deadlock potential in md_open
    
    A recent commit:
      commit 449aad3e25358812c43afc60918c5ad3819488e7
    
    introduced the possibility of an A-B/B-A deadlock between
    bd_mutex and reconfig_mutex.
    
    __blkdev_get holds bd_mutex while calling md_open which takes
       reconfig_mutex,
    do_md_run is always called with reconfig_mutex held, and it now
       takes bd_mutex in the call the revalidate_disk.
    
    This potential deadlock was not caught by lockdep due to the
    use of mutex_lock_interruptible_nexted which was introduced
    by
       commit d63a5a74dee87883fda6b7d170244acaac5b05e8
    do avoid a warning of an impossible deadlock.
    
    It is quite possible to split reconfig_mutex in to two locks.
    One protects the array data structures while it is being
    reconfigured, the other ensures that an array is never even partially
    open while it is being deactivated.
    In particular, the second lock prevents an open from completing
    between the time when do_md_stop checks if there are any active opens,
    and the time when the array is either set read-only, or when ->pers is
    set to NULL.  So we can be certain that no IO is in flight as the
    array is being destroyed.
    
    So create a new lock, open_mutex, just to ensure exclusion between
    'open' and 'stop'.
    
    This avoids the deadlock and also avoids the lockdep warning mentioned
    in commit d63a5a74d
    
    Reported-by: "Mike Snitzer" <snitzer@gmail.com>
    Reported-by: "H. Peter Anvin" <hpa@zytor.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 78f03168baf9..f8fc188bc762 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -223,6 +223,16 @@ struct mddev_s
 							    * so we don't loop trying */
 
 	int				in_sync;	/* know to not need resync */
+	/* 'open_mutex' avoids races between 'md_open' and 'do_md_stop', so
+	 * that we are never stopping an array while it is open.
+	 * 'reconfig_mutex' protects all other reconfiguration.
+	 * These locks are separate due to conflicting interactions
+	 * with bdev->bd_mutex.
+	 * Lock ordering is:
+	 *  reconfig_mutex -> bd_mutex : e.g. do_md_run -> revalidate_disk
+	 *  bd_mutex -> open_mutex:  e.g. __blkdev_get -> md_open
+	 */
+	struct mutex			open_mutex;
 	struct mutex			reconfig_mutex;
 	atomic_t			active;		/* general refcount */
 	atomic_t			openers;	/* number of active opens */

commit ac5e7113e74872928844d00085bd47c988f12728
Author: Andre Noll <maan@systemlinux.org>
Date:   Mon Aug 3 10:59:47 2009 +1000

    md: Push down data integrity code to personalities.
    
    This patch replaces md_integrity_check() by two new public functions:
    md_integrity_register() and md_integrity_add_rdev() which are both
    personality-independent.
    
    md_integrity_register() is called from the ->run and ->hot_remove
    methods of all personalities that support data integrity.  The
    function iterates over the component devices of the array and
    determines if all active devices are integrity capable and if their
    profiles match. If this is the case, the common profile is registered
    for the mddev via blk_integrity_register().
    
    The second new function, md_integrity_add_rdev() is called from the
    ->hot_add_disk methods, i.e. whenever a new device is being added
    to a raid array. If the new device does not support data integrity,
    or has a profile different from the one already registered, data
    integrity for the mddev is disabled.
    
    For raid0 and linear, only the call to md_integrity_register() from
    the ->run method is necessary.
    
    Signed-off-by: Andre Noll <maan@systemlinux.org>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 9430a110db93..78f03168baf9 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -431,5 +431,7 @@ extern int md_allow_write(mddev_t *mddev);
 extern void md_wait_for_blocked_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
 extern void md_set_array_sectors(mddev_t *mddev, sector_t array_sectors);
 extern int md_check_no_bitmap(mddev_t *mddev);
+extern int md_integrity_register(mddev_t *mddev);
+void md_integrity_add_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
 
 #endif /* _MD_MD_H */

commit 0894cc3066aaa3e75a99383c0d25feebf9b688ac
Author: Andre Noll <maan@systemlinux.org>
Date:   Thu Jun 18 08:49:23 2009 +1000

    md: Move check for bitmap presence to personality code.
    
    If the superblock of a component device indicates the presence of a
    bitmap but the corresponding raid personality does not support bitmaps
    (raid0, linear, multipath, faulty), then something is seriously wrong
    and we'd better refuse to run such an array.
    
    Currently, this check is performed while the superblocks are examined,
    i.e. before entering personality code. Therefore the generic md layer
    must know which raid levels support bitmaps and which do not.
    
    This patch avoids this layer violation without adding identical code
    to various personalities. This is accomplished by introducing a new
    public function to md.c, md_check_no_bitmap(), which replaces the
    hard-coded checks in the superblock loading functions.
    
    A call to md_check_no_bitmap() is added to the ->run method of each
    personality which does not support bitmaps and assembly is aborted
    if at least one component device contains a bitmap.
    
    Signed-off-by: Andre Noll <maan@systemlinux.org>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index ea2c441449d4..9430a110db93 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -430,5 +430,6 @@ extern void md_new_event(mddev_t *mddev);
 extern int md_allow_write(mddev_t *mddev);
 extern void md_wait_for_blocked_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
 extern void md_set_array_sectors(mddev_t *mddev, sector_t array_sectors);
+extern int md_check_no_bitmap(mddev_t *mddev);
 
 #endif /* _MD_MD_H */

commit 8190e754e0723de7cecb80bdd9eb93911dfa04a1
Author: NeilBrown <neilb@suse.de>
Date:   Thu Jun 18 08:48:58 2009 +1000

    md: remove chunksize rounding from common code.
    
    It is easiest to round sizes to multiples of chunk size in
    the personality code for those personalities which care.
    Those personalities now do the rounding, so we can
    remove that function from common code.
    
    Also remove the upper bound on the size of a chunk, and the lower
    bound on the size of a device (1 chunk), neither of which really buy
    us anything.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index bac7c2bf8616..ea2c441449d4 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -29,13 +29,6 @@
 typedef struct mddev_s mddev_t;
 typedef struct mdk_rdev_s mdk_rdev_t;
 
-/*
- * options passed in raidrun:
- */
-
-/* Currently this must fit in an 'int' */
-#define MAX_CHUNK_SIZE (1<<30)
-
 /*
  * MD's 'extended' device
  */

commit 50ac168a6e0a061bf5346d53aa9e7beb94c97527
Author: NeilBrown <neilb@suse.de>
Date:   Thu Jun 18 08:47:55 2009 +1000

    md: merge reconfig and check_reshape methods.
    
    The difference between these two methods is artificial.
    Both check that a pending reshape is valid, and perform any
    aspect of it that can be done immediately.
    'reconfig' handles chunk size and layout.
    'check_reshape' handles raid_disks.
    
    So make them just one method.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 815013f8da6c..bac7c2bf8616 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -326,7 +326,6 @@ struct mdk_personality
 	int (*check_reshape) (mddev_t *mddev);
 	int (*start_reshape) (mddev_t *mddev);
 	void (*finish_reshape) (mddev_t *mddev);
-	int (*reconfig) (mddev_t *mddev);
 	/* quiesce moves between quiescence states
 	 * 0 - fully active
 	 * 1 - no new requests allowed

commit 597a711b69cfff95c4b8f6069037e7ad3fc71f56
Author: NeilBrown <neilb@suse.de>
Date:   Thu Jun 18 08:47:42 2009 +1000

    md: remove unnecessary arguments from ->reconfig method.
    
    Passing the new layout and chunksize as args is not necessary as
    the mddev has fields for new_check and new_layout.
    
    This is preparation for combining the check_reshape and reconfig
    methods
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index e0a2b8e3985d..815013f8da6c 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -326,7 +326,7 @@ struct mdk_personality
 	int (*check_reshape) (mddev_t *mddev);
 	int (*start_reshape) (mddev_t *mddev);
 	void (*finish_reshape) (mddev_t *mddev);
-	int (*reconfig) (mddev_t *mddev, int layout, int chunk_size);
+	int (*reconfig) (mddev_t *mddev);
 	/* quiesce moves between quiescence states
 	 * 0 - fully active
 	 * 1 - no new requests allowed

commit 664e7c413f1e90eceb0b2596dd73a0832faec058
Author: Andre Noll <maan@systemlinux.org>
Date:   Thu Jun 18 08:45:27 2009 +1000

    md: Convert mddev->new_chunk to sectors.
    
    A straight-forward conversion which gets rid of some
    multiplications/divisions/shifts. The patch also introduces a couple
    of new ones, most of which are due to conf->chunk_size still being
    represented in bytes. This will be cleaned up in subsequent patches.
    
    Signed-off-by: Andre Noll <maan@systemlinux.org>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 5d78830043d0..e0a2b8e3985d 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -166,7 +166,8 @@ struct mddev_s
 	 * If reshape_position is MaxSector, then no reshape is happening (yet).
 	 */
 	sector_t			reshape_position;
-	int				delta_disks, new_level, new_layout, new_chunk;
+	int				delta_disks, new_level, new_layout;
+	int				new_chunk_sectors;
 
 	struct mdk_thread_s		*thread;	/* management thread */
 	struct mdk_thread_s		*sync_thread;	/* doing resync or reconstruct */

commit 9d8f0363623b3da12c43007cf77f5e1a4e8a5964
Author: Andre Noll <maan@systemlinux.org>
Date:   Thu Jun 18 08:45:01 2009 +1000

    md: Make mddev->chunk_size sector-based.
    
    This patch renames the chunk_size field to chunk_sectors with the
    implied change of semantics.  Since
    
            is_power_of_2(chunk_size) = is_power_of_2(chunk_sectors << 9)
                                      = is_power_of_2(chunk_sectors)
    
    these bits don't need an adjustment for the shift.
    
    Signed-off-by: Andre Noll <maan@systemlinux.org>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 8227ab909d44..5d78830043d0 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -145,7 +145,7 @@ struct mddev_s
 	int 				external;	/* metadata is
 							 * managed externally */
 	char				metadata_type[17]; /* externally set*/
-	int				chunk_size;
+	int				chunk_sectors;
 	time_t				ctime, utime;
 	int				level, layout;
 	char				clevel[16];

commit 63fe08177f92ce21929df8af6361491b98ad12cd
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Apr 14 12:01:53 2009 +1000

    md: tiny md.h cleanups
    
    - update inclusion guard and make sure it covers the whole file
     - remove superflous #ifdef CONFIG_BLOCK
     - make sure all required headers are included so that new users aren't
       required to include others before
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index e9b7f54c24d6..8227ab909d44 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -12,10 +12,17 @@
    Software Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.  
 */
 
-#ifndef _MD_K_H
-#define _MD_K_H
-
-#ifdef CONFIG_BLOCK
+#ifndef _MD_MD_H
+#define _MD_MD_H
+
+#include <linux/blkdev.h>
+#include <linux/kobject.h>
+#include <linux/list.h>
+#include <linux/mm.h>
+#include <linux/mutex.h>
+#include <linux/timer.h>
+#include <linux/wait.h>
+#include <linux/workqueue.h>
 
 #define MaxSector (~(sector_t)0)
 
@@ -408,10 +415,6 @@ static inline void safe_put_page(struct page *p)
 	if (p) put_page(p);
 }
 
-#endif /* CONFIG_BLOCK */
-#endif
-
-
 extern int register_md_personality(struct mdk_personality *p);
 extern int unregister_md_personality(struct mdk_personality *p);
 extern mdk_thread_t * md_register_thread(void (*run) (mddev_t *mddev),
@@ -434,3 +437,5 @@ extern void md_new_event(mddev_t *mddev);
 extern int md_allow_write(mddev_t *mddev);
 extern void md_wait_for_blocked_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
 extern void md_set_array_sectors(mddev_t *mddev, sector_t array_sectors);
+
+#endif /* _MD_MD_H */

commit cea9c22800773cecb1d41f4a6139f9eb6a95368b
Author: NeilBrown <neilb@suse.de>
Date:   Tue Mar 31 15:15:05 2009 +1100

    md: add explicit method to signal the end of a reshape.
    
    Currently raid5 (the only module that supports restriping)
    notices that the reshape has finished be sync_request being
    given a large value, and handles any cleanup them.
    
    This patch changes it so md_check_recovery calls into an
    explicit finish_reshape method as well.
    
    The clean-up from sync_request can do things that need to be
    done promptly, typically things local to the raid5_conf_t
    structure.
    
    The "finish_reshape" method is called under the mddev_lock
    so it can do things involving reconfiguring the device.
    
    This allows us to get rid of md_set_array_sectors_locked, which
    would have caused a deadlock if you tried to stop and array
    while a reshape was happening.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index d13e34f842e2..e9b7f54c24d6 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -317,6 +317,7 @@ struct mdk_personality
 	sector_t (*size) (mddev_t *mddev, sector_t sectors, int raid_disks);
 	int (*check_reshape) (mddev_t *mddev);
 	int (*start_reshape) (mddev_t *mddev);
+	void (*finish_reshape) (mddev_t *mddev);
 	int (*reconfig) (mddev_t *mddev, int layout, int chunk_size);
 	/* quiesce moves between quiescence states
 	 * 0 - fully active
@@ -433,4 +434,3 @@ extern void md_new_event(mddev_t *mddev);
 extern int md_allow_write(mddev_t *mddev);
 extern void md_wait_for_blocked_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
 extern void md_set_array_sectors(mddev_t *mddev, sector_t array_sectors);
-extern void md_set_array_sectors_lock(mddev_t *mddev, sector_t array_sectors);

commit b522adcde9c4d3fb7b579cfa9160d8bde7744be8
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Mar 31 15:00:31 2009 +1100

    md: 'array_size' sysfs attribute
    
    Allow userspace to set the size of the array according to the following
    semantics:
    
    1/ size must be <= to the size returned by mddev->pers->size(mddev, 0, 0)
       a) If size is set before the array is running, do_md_run will fail
          if size is greater than the default size
       b) A reshape attempt that reduces the default size to less than the set
          array size should be blocked
    2/ once userspace sets the size the kernel will not change it
    3/ writing 'default' to this attribute returns control of the size to the
       kernel and reverts to the size reported by the personality
    
    Also, convert locations that need to know the default size from directly
    reading ->array_sectors to <pers>_size.  Resync/reshape operations
    always follow the default size.
    
    Finally, fixup other locations that read a number of 1k-blocks from
    userspace to use strict_blocks_to_sectors() which checks for unsigned
    long long to sector_t overflow and blocks to sectors overflow.
    
    Reviewed-by: Andre Noll <maan@systemlinux.org>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index ce89dda24074..d13e34f842e2 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -147,6 +147,8 @@ struct mddev_s
 	sector_t			dev_sectors; 	/* used size of
 							 * component devices */
 	sector_t			array_sectors; /* exported array size */
+	int				external_size; /* size managed
+							* externally */
 	__u64				events;
 
 	char				uuid[16];
@@ -431,3 +433,4 @@ extern void md_new_event(mddev_t *mddev);
 extern int md_allow_write(mddev_t *mddev);
 extern void md_wait_for_blocked_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
 extern void md_set_array_sectors(mddev_t *mddev, sector_t array_sectors);
+extern void md_set_array_sectors_lock(mddev_t *mddev, sector_t array_sectors);

commit 1f403624bde3c678a166984b1e6a727a0ce06f2b
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Mar 31 14:59:03 2009 +1100

    md: centralize ->array_sectors modifications
    
    Get personalities out of the business of directly modifying
    ->array_sectors.  Lays groundwork to introduce policy on when
    ->array_sectors can be modified.
    
    Reviewed-by: Andre Noll <maan@systemlinux.org>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index d2c50da1ae7f..ce89dda24074 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -430,3 +430,4 @@ extern void md_do_sync(mddev_t *mddev);
 extern void md_new_event(mddev_t *mddev);
 extern int md_allow_write(mddev_t *mddev);
 extern void md_wait_for_blocked_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
+extern void md_set_array_sectors(mddev_t *mddev, sector_t array_sectors);

commit 80c3a6ce4ba4470379b9e6a4d9bcd9d2ee26ae03
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Mar 17 18:10:40 2009 -0700

    md: add 'size' as a personality method
    
    In preparation for giving userspace control over ->array_sectors we need
    to be able to retrieve the 'default' size, and the 'anticipated' size
    when a reshape is requested.  For personalities that do not reshape emit
    a warning if anything but the default size is requested.
    
    In the raid5 case we need to update ->previous_raid_disks to make the
    new 'default' size available.
    
    Reviewed-by: Andre Noll <maan@systemlinux.org>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 8034f62a9d28..d2c50da1ae7f 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -312,6 +312,7 @@ struct mdk_personality
 	int (*spare_active) (mddev_t *mddev);
 	sector_t (*sync_request)(mddev_t *mddev, sector_t sector_nr, int *skipped, int go_faster);
 	int (*resize) (mddev_t *mddev, sector_t sectors);
+	sector_t (*size) (mddev_t *mddev, sector_t sectors, int raid_disks);
 	int (*check_reshape) (mddev_t *mddev);
 	int (*start_reshape) (mddev_t *mddev);
 	int (*reconfig) (mddev_t *mddev, int layout, int chunk_size);

commit 245f46c2c221ef09c7db892f0e3fc2149be42052
Author: NeilBrown <neilb@suse.de>
Date:   Tue Mar 31 14:39:39 2009 +1100

    md: add ->takeover method to support changing the personality managing an array
    
    Implement this for RAID6 to be able to 'takeover' a RAID5 array.  The
    new RAID6 will use a layout which places Q on the last device, and
    that device will be missing.
    If there are any available spares, one will immediately have Q
    recovered onto it.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 84b22d67ba14..8034f62a9d28 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -321,6 +321,16 @@ struct mdk_personality
 	 * others - reserved
 	 */
 	void (*quiesce) (mddev_t *mddev, int state);
+	/* takeover is used to transition an array from one
+	 * personality to another.  The new personality must be able
+	 * to handle the data in the current layout.
+	 * e.g. 2drive raid1 -> 2drive raid5
+	 *      ndrive raid5 -> degraded n+1drive raid6 with special layout
+	 * If the takeover succeeds, a new 'private' structure is returned.
+	 * This needs to be installed and then ->run used to activate the
+	 * array.
+	 */
+	void *(*takeover) (mddev_t *mddev);
 };
 
 

commit 409c57f3801701dfee27a28103dda4831306cb20
Author: NeilBrown <neilb@suse.de>
Date:   Tue Mar 31 14:39:39 2009 +1100

    md: enable suspend/resume of md devices.
    
    To be able to change the 'level' of an md/raid array, we need to
    suspend the device so that no requests are active - then move some
    pointers around etc.
    
    The code already keeps counts of active requests and the ->quiesce
    function can be used to wait until those counts hit zero.
    However the quiesce function blocks new requests once they are all
    ready 'inside' the personality module, and that is too late if we want
    to replace the personality modules.
    
    So make all md requests come in through a common md_make_request
    function that keeps track of how many requests have entered the
    modules but may not yet be on the internal reference counts.
    Allow md_make_request to be blocked when we want to suspend the
    device, and make it possible to wait for all those in-transit requests
    to be added to internal lists so that ->quiesce can wait for them.
    
    There is still a problem that when a request completes, we drop the
    ref count inside the personality code so there is a short time between
    when the refcount hits zero, and when the personality code is no
    longer being used.
    The personality code never blocks (schedule or spinlock) between
    dropping the refcount and exiting the routine, so this should be safe
    (as put_module calls synchronize_sched() before unmapping the module
    code).
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index c07ea9118063..84b22d67ba14 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -119,6 +119,8 @@ struct mddev_s
 #define MD_CHANGE_CLEAN 1	/* transition to or from 'clean' */
 #define MD_CHANGE_PENDING 2	/* superblock update in progress */
 
+	int				suspended;
+	atomic_t			active_io;
 	int				ro;
 
 	struct gendisk			*gendisk;

commit dd8ac336c13fd8afdb082ebacb1cddd5cf727889
Author: Andre Noll <maan@systemlinux.org>
Date:   Tue Mar 31 14:33:13 2009 +1100

    md: Represent raid device size in sectors.
    
    This patch renames the "size" field of struct mdk_rdev_s to
    "sectors" and changes this field to store sectors instead of
    blocks.
    
    All users of this field, linear.c, raid0.c and md.c, are fixed up
    accordingly which gets rid of many multiplications and divisions.
    
    Signed-off-by: Andre Noll <maan@systemlinux.org>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index 946121236235..c07ea9118063 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -36,7 +36,7 @@ struct mdk_rdev_s
 {
 	struct list_head same_set;	/* RAID devices within the same set */
 
-	sector_t size;			/* Device size (in blocks) */
+	sector_t sectors;		/* Device size (in 512bytes sectors) */
 	mddev_t *mddev;			/* RAID array if running */
 	int last_events;		/* IO event timestamp */
 

commit 58c0fed400603a802968b23ddf78f029c5a84e41
Author: Andre Noll <maan@systemlinux.org>
Date:   Tue Mar 31 14:33:13 2009 +1100

    md: Make mddev->size sector-based.
    
    This patch renames the "size" field of struct mddev_s to "dev_sectors"
    and stores the number of 512-byte sectors instead of the number of
    1K-blocks in it.
    
    All users of that field, including raid levels 1,4-6,10, are adjusted
    accordingly. This simplifies the code a bit because it allows to get
    rid of a couple of divisions/multiplications by two.
    
    In order to make checkpatch happy, some minor coding style issues
    have also been addressed. In particular, size_store() now uses
    strict_strtoull() instead of simple_strtoull().
    
    Signed-off-by: Andre Noll <maan@systemlinux.org>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index bede26c9d4a9..946121236235 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -142,7 +142,8 @@ struct mddev_s
 	char				clevel[16];
 	int				raid_disks;
 	int				max_disks;
-	sector_t			size; /* used size of component devices */
+	sector_t			dev_sectors; 	/* used size of
+							 * component devices */
 	sector_t			array_sectors; /* exported array size */
 	__u64				events;
 

commit 97e4f42d62badb0f9fbc27c013e89bc1336a03bc
Author: NeilBrown <neilb@suse.de>
Date:   Tue Mar 31 14:33:13 2009 +1100

    md: occasionally checkpoint drive recovery to reduce duplicate effort after a crash
    
    Version 1.x metadata has the ability to record the status of a
    partially completed drive recovery.
    However we only update that record on a clean shutdown.
    It would be nice to update it on unclean shutdowns too, particularly
    when using a bitmap that removes much to the 'sync' effort after an
    unclean shutdown.
    
    One complication with checkpointing recovery is that we only know
    where we are up to in terms of IO requests started, not which ones
    have completed.  And we need to know what has completed to record
    how much is recovered.  So occasionally pause the recovery until all
    submitted requests are completed, then update the record of where
    we are up to.
    
    When we have a bitmap, we already do that pause occasionally to keep
    the bitmap up-to-date.  So enhance that code to record the recovery
    offset and schedule a superblock update.
    And when there is no bitmap, just pause 16 times during the resync to
    do a checkpoint.
    '16' is a fairly arbitrary number.  But we don't really have any good
    way to judge how often is acceptable, and it seems like a reasonable
    number for now.
    
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
index e78b3c1d55fd..bede26c9d4a9 100644
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@ -159,6 +159,13 @@ struct mddev_s
 	struct mdk_thread_s		*thread;	/* management thread */
 	struct mdk_thread_s		*sync_thread;	/* doing resync or reconstruct */
 	sector_t			curr_resync;	/* last block scheduled */
+	/* As resync requests can complete out of order, we cannot easily track
+	 * how much resync has been completed.  So we occasionally pause until
+	 * everything completes, then set curr_resync_completed to curr_resync.
+	 * As such it may be well behind the real resync mark, but it is a value
+	 * we are certain of.
+	 */
+	sector_t			curr_resync_completed;
 	unsigned long			resync_mark;	/* a recent timestamp */
 	sector_t			resync_mark_cnt;/* blocks written at resync_mark */
 	sector_t			curr_mark_cnt; /* blocks scheduled now */

commit 43b2e5d86d8bdd77386226db0bc961529492c043
Author: NeilBrown <neilb@suse.de>
Date:   Tue Mar 31 14:33:13 2009 +1100

    md: move md_k.h from include/linux/raid/ to drivers/md/
    
    It really is nicer to keep related code together..
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/drivers/md/md.h b/drivers/md/md.h
new file mode 100644
index 000000000000..e78b3c1d55fd
--- /dev/null
+++ b/drivers/md/md.h
@@ -0,0 +1,411 @@
+/*
+   md_k.h : kernel internal structure of the Linux MD driver
+          Copyright (C) 1996-98 Ingo Molnar, Gadi Oxman
+	  
+   This program is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 2, or (at your option)
+   any later version.
+   
+   You should have received a copy of the GNU General Public License
+   (for example /usr/src/linux/COPYING); if not, write to the Free
+   Software Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.  
+*/
+
+#ifndef _MD_K_H
+#define _MD_K_H
+
+#ifdef CONFIG_BLOCK
+
+#define MaxSector (~(sector_t)0)
+
+typedef struct mddev_s mddev_t;
+typedef struct mdk_rdev_s mdk_rdev_t;
+
+/*
+ * options passed in raidrun:
+ */
+
+/* Currently this must fit in an 'int' */
+#define MAX_CHUNK_SIZE (1<<30)
+
+/*
+ * MD's 'extended' device
+ */
+struct mdk_rdev_s
+{
+	struct list_head same_set;	/* RAID devices within the same set */
+
+	sector_t size;			/* Device size (in blocks) */
+	mddev_t *mddev;			/* RAID array if running */
+	int last_events;		/* IO event timestamp */
+
+	struct block_device *bdev;	/* block device handle */
+
+	struct page	*sb_page;
+	int		sb_loaded;
+	__u64		sb_events;
+	sector_t	data_offset;	/* start of data in array */
+	sector_t 	sb_start;	/* offset of the super block (in 512byte sectors) */
+	int		sb_size;	/* bytes in the superblock */
+	int		preferred_minor;	/* autorun support */
+
+	struct kobject	kobj;
+
+	/* A device can be in one of three states based on two flags:
+	 * Not working:   faulty==1 in_sync==0
+	 * Fully working: faulty==0 in_sync==1
+	 * Working, but not
+	 * in sync with array
+	 *                faulty==0 in_sync==0
+	 *
+	 * It can never have faulty==1, in_sync==1
+	 * This reduces the burden of testing multiple flags in many cases
+	 */
+
+	unsigned long	flags;
+#define	Faulty		1		/* device is known to have a fault */
+#define	In_sync		2		/* device is in_sync with rest of array */
+#define	WriteMostly	4		/* Avoid reading if at all possible */
+#define	BarriersNotsupp	5		/* BIO_RW_BARRIER is not supported */
+#define	AllReserved	6		/* If whole device is reserved for
+					 * one array */
+#define	AutoDetected	7		/* added by auto-detect */
+#define Blocked		8		/* An error occured on an externally
+					 * managed array, don't allow writes
+					 * until it is cleared */
+#define StateChanged	9		/* Faulty or Blocked has changed during
+					 * interrupt, so it needs to be
+					 * notified by the thread */
+	wait_queue_head_t blocked_wait;
+
+	int desc_nr;			/* descriptor index in the superblock */
+	int raid_disk;			/* role of device in array */
+	int saved_raid_disk;		/* role that device used to have in the
+					 * array and could again if we did a partial
+					 * resync from the bitmap
+					 */
+	sector_t	recovery_offset;/* If this device has been partially
+					 * recovered, this is where we were
+					 * up to.
+					 */
+
+	atomic_t	nr_pending;	/* number of pending requests.
+					 * only maintained for arrays that
+					 * support hot removal
+					 */
+	atomic_t	read_errors;	/* number of consecutive read errors that
+					 * we have tried to ignore.
+					 */
+	atomic_t	corrected_errors; /* number of corrected read errors,
+					   * for reporting to userspace and storing
+					   * in superblock.
+					   */
+	struct work_struct del_work;	/* used for delayed sysfs removal */
+
+	struct sysfs_dirent *sysfs_state; /* handle for 'state'
+					   * sysfs entry */
+};
+
+struct mddev_s
+{
+	void				*private;
+	struct mdk_personality		*pers;
+	dev_t				unit;
+	int				md_minor;
+	struct list_head 		disks;
+	unsigned long			flags;
+#define MD_CHANGE_DEVS	0	/* Some device status has changed */
+#define MD_CHANGE_CLEAN 1	/* transition to or from 'clean' */
+#define MD_CHANGE_PENDING 2	/* superblock update in progress */
+
+	int				ro;
+
+	struct gendisk			*gendisk;
+
+	struct kobject			kobj;
+	int				hold_active;
+#define	UNTIL_IOCTL	1
+#define	UNTIL_STOP	2
+
+	/* Superblock information */
+	int				major_version,
+					minor_version,
+					patch_version;
+	int				persistent;
+	int 				external;	/* metadata is
+							 * managed externally */
+	char				metadata_type[17]; /* externally set*/
+	int				chunk_size;
+	time_t				ctime, utime;
+	int				level, layout;
+	char				clevel[16];
+	int				raid_disks;
+	int				max_disks;
+	sector_t			size; /* used size of component devices */
+	sector_t			array_sectors; /* exported array size */
+	__u64				events;
+
+	char				uuid[16];
+
+	/* If the array is being reshaped, we need to record the
+	 * new shape and an indication of where we are up to.
+	 * This is written to the superblock.
+	 * If reshape_position is MaxSector, then no reshape is happening (yet).
+	 */
+	sector_t			reshape_position;
+	int				delta_disks, new_level, new_layout, new_chunk;
+
+	struct mdk_thread_s		*thread;	/* management thread */
+	struct mdk_thread_s		*sync_thread;	/* doing resync or reconstruct */
+	sector_t			curr_resync;	/* last block scheduled */
+	unsigned long			resync_mark;	/* a recent timestamp */
+	sector_t			resync_mark_cnt;/* blocks written at resync_mark */
+	sector_t			curr_mark_cnt; /* blocks scheduled now */
+
+	sector_t			resync_max_sectors; /* may be set by personality */
+
+	sector_t			resync_mismatches; /* count of sectors where
+							    * parity/replica mismatch found
+							    */
+
+	/* allow user-space to request suspension of IO to regions of the array */
+	sector_t			suspend_lo;
+	sector_t			suspend_hi;
+	/* if zero, use the system-wide default */
+	int				sync_speed_min;
+	int				sync_speed_max;
+
+	/* resync even though the same disks are shared among md-devices */
+	int				parallel_resync;
+
+	int				ok_start_degraded;
+	/* recovery/resync flags 
+	 * NEEDED:   we might need to start a resync/recover
+	 * RUNNING:  a thread is running, or about to be started
+	 * SYNC:     actually doing a resync, not a recovery
+	 * RECOVER:  doing recovery, or need to try it.
+	 * INTR:     resync needs to be aborted for some reason
+	 * DONE:     thread is done and is waiting to be reaped
+	 * REQUEST:  user-space has requested a sync (used with SYNC)
+	 * CHECK:    user-space request for for check-only, no repair
+	 * RESHAPE:  A reshape is happening
+	 *
+	 * If neither SYNC or RESHAPE are set, then it is a recovery.
+	 */
+#define	MD_RECOVERY_RUNNING	0
+#define	MD_RECOVERY_SYNC	1
+#define	MD_RECOVERY_RECOVER	2
+#define	MD_RECOVERY_INTR	3
+#define	MD_RECOVERY_DONE	4
+#define	MD_RECOVERY_NEEDED	5
+#define	MD_RECOVERY_REQUESTED	6
+#define	MD_RECOVERY_CHECK	7
+#define MD_RECOVERY_RESHAPE	8
+#define	MD_RECOVERY_FROZEN	9
+
+	unsigned long			recovery;
+	int				recovery_disabled; /* if we detect that recovery
+							    * will always fail, set this
+							    * so we don't loop trying */
+
+	int				in_sync;	/* know to not need resync */
+	struct mutex			reconfig_mutex;
+	atomic_t			active;		/* general refcount */
+	atomic_t			openers;	/* number of active opens */
+
+	int				changed;	/* true if we might need to reread partition info */
+	int				degraded;	/* whether md should consider
+							 * adding a spare
+							 */
+	int				barriers_work;	/* initialised to true, cleared as soon
+							 * as a barrier request to slave
+							 * fails.  Only supported
+							 */
+	struct bio			*biolist; 	/* bios that need to be retried
+							 * because BIO_RW_BARRIER is not supported
+							 */
+
+	atomic_t			recovery_active; /* blocks scheduled, but not written */
+	wait_queue_head_t		recovery_wait;
+	sector_t			recovery_cp;
+	sector_t			resync_min;	/* user requested sync
+							 * starts here */
+	sector_t			resync_max;	/* resync should pause
+							 * when it gets here */
+
+	struct sysfs_dirent		*sysfs_state;	/* handle for 'array_state'
+							 * file in sysfs.
+							 */
+	struct sysfs_dirent		*sysfs_action;  /* handle for 'sync_action' */
+
+	struct work_struct del_work;	/* used for delayed sysfs removal */
+
+	spinlock_t			write_lock;
+	wait_queue_head_t		sb_wait;	/* for waiting on superblock updates */
+	atomic_t			pending_writes;	/* number of active superblock writes */
+
+	unsigned int			safemode;	/* if set, update "clean" superblock
+							 * when no writes pending.
+							 */ 
+	unsigned int			safemode_delay;
+	struct timer_list		safemode_timer;
+	atomic_t			writes_pending; 
+	struct request_queue		*queue;	/* for plugging ... */
+
+	atomic_t                        write_behind; /* outstanding async IO */
+	unsigned int                    max_write_behind; /* 0 = sync */
+
+	struct bitmap                   *bitmap; /* the bitmap for the device */
+	struct file			*bitmap_file; /* the bitmap file */
+	long				bitmap_offset; /* offset from superblock of
+							* start of bitmap. May be
+							* negative, but not '0'
+							*/
+	long				default_bitmap_offset; /* this is the offset to use when
+								* hot-adding a bitmap.  It should
+								* eventually be settable by sysfs.
+								*/
+
+	struct list_head		all_mddevs;
+};
+
+
+static inline void rdev_dec_pending(mdk_rdev_t *rdev, mddev_t *mddev)
+{
+	int faulty = test_bit(Faulty, &rdev->flags);
+	if (atomic_dec_and_test(&rdev->nr_pending) && faulty)
+		set_bit(MD_RECOVERY_NEEDED, &mddev->recovery);
+}
+
+static inline void md_sync_acct(struct block_device *bdev, unsigned long nr_sectors)
+{
+        atomic_add(nr_sectors, &bdev->bd_contains->bd_disk->sync_io);
+}
+
+struct mdk_personality
+{
+	char *name;
+	int level;
+	struct list_head list;
+	struct module *owner;
+	int (*make_request)(struct request_queue *q, struct bio *bio);
+	int (*run)(mddev_t *mddev);
+	int (*stop)(mddev_t *mddev);
+	void (*status)(struct seq_file *seq, mddev_t *mddev);
+	/* error_handler must set ->faulty and clear ->in_sync
+	 * if appropriate, and should abort recovery if needed 
+	 */
+	void (*error_handler)(mddev_t *mddev, mdk_rdev_t *rdev);
+	int (*hot_add_disk) (mddev_t *mddev, mdk_rdev_t *rdev);
+	int (*hot_remove_disk) (mddev_t *mddev, int number);
+	int (*spare_active) (mddev_t *mddev);
+	sector_t (*sync_request)(mddev_t *mddev, sector_t sector_nr, int *skipped, int go_faster);
+	int (*resize) (mddev_t *mddev, sector_t sectors);
+	int (*check_reshape) (mddev_t *mddev);
+	int (*start_reshape) (mddev_t *mddev);
+	int (*reconfig) (mddev_t *mddev, int layout, int chunk_size);
+	/* quiesce moves between quiescence states
+	 * 0 - fully active
+	 * 1 - no new requests allowed
+	 * others - reserved
+	 */
+	void (*quiesce) (mddev_t *mddev, int state);
+};
+
+
+struct md_sysfs_entry {
+	struct attribute attr;
+	ssize_t (*show)(mddev_t *, char *);
+	ssize_t (*store)(mddev_t *, const char *, size_t);
+};
+
+
+static inline char * mdname (mddev_t * mddev)
+{
+	return mddev->gendisk ? mddev->gendisk->disk_name : "mdX";
+}
+
+/*
+ * iterates through some rdev ringlist. It's safe to remove the
+ * current 'rdev'. Dont touch 'tmp' though.
+ */
+#define rdev_for_each_list(rdev, tmp, head)				\
+	list_for_each_entry_safe(rdev, tmp, head, same_set)
+
+/*
+ * iterates through the 'same array disks' ringlist
+ */
+#define rdev_for_each(rdev, tmp, mddev)				\
+	list_for_each_entry_safe(rdev, tmp, &((mddev)->disks), same_set)
+
+#define rdev_for_each_rcu(rdev, mddev)				\
+	list_for_each_entry_rcu(rdev, &((mddev)->disks), same_set)
+
+typedef struct mdk_thread_s {
+	void			(*run) (mddev_t *mddev);
+	mddev_t			*mddev;
+	wait_queue_head_t	wqueue;
+	unsigned long           flags;
+	struct task_struct	*tsk;
+	unsigned long		timeout;
+} mdk_thread_t;
+
+#define THREAD_WAKEUP  0
+
+#define __wait_event_lock_irq(wq, condition, lock, cmd) 		\
+do {									\
+	wait_queue_t __wait;						\
+	init_waitqueue_entry(&__wait, current);				\
+									\
+	add_wait_queue(&wq, &__wait);					\
+	for (;;) {							\
+		set_current_state(TASK_UNINTERRUPTIBLE);		\
+		if (condition)						\
+			break;						\
+		spin_unlock_irq(&lock);					\
+		cmd;							\
+		schedule();						\
+		spin_lock_irq(&lock);					\
+	}								\
+	current->state = TASK_RUNNING;					\
+	remove_wait_queue(&wq, &__wait);				\
+} while (0)
+
+#define wait_event_lock_irq(wq, condition, lock, cmd) 			\
+do {									\
+	if (condition)	 						\
+		break;							\
+	__wait_event_lock_irq(wq, condition, lock, cmd);		\
+} while (0)
+
+static inline void safe_put_page(struct page *p)
+{
+	if (p) put_page(p);
+}
+
+#endif /* CONFIG_BLOCK */
+#endif
+
+
+extern int register_md_personality(struct mdk_personality *p);
+extern int unregister_md_personality(struct mdk_personality *p);
+extern mdk_thread_t * md_register_thread(void (*run) (mddev_t *mddev),
+				mddev_t *mddev, const char *name);
+extern void md_unregister_thread(mdk_thread_t *thread);
+extern void md_wakeup_thread(mdk_thread_t *thread);
+extern void md_check_recovery(mddev_t *mddev);
+extern void md_write_start(mddev_t *mddev, struct bio *bi);
+extern void md_write_end(mddev_t *mddev);
+extern void md_done_sync(mddev_t *mddev, int blocks, int ok);
+extern void md_error(mddev_t *mddev, mdk_rdev_t *rdev);
+
+extern void md_super_write(mddev_t *mddev, mdk_rdev_t *rdev,
+			   sector_t sector, int size, struct page *page);
+extern void md_super_wait(mddev_t *mddev);
+extern int sync_page_io(struct block_device *bdev, sector_t sector, int size,
+			struct page *page, int rw);
+extern void md_do_sync(mddev_t *mddev);
+extern void md_new_event(mddev_t *mddev);
+extern int md_allow_write(mddev_t *mddev);
+extern void md_wait_for_blocked_rdev(mdk_rdev_t *rdev, mddev_t *mddev);
