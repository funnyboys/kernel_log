commit 924a3541eab0d28101baf0831e4315593f06ba4a
Author: John Garry <john.garry@huawei.com>
Date:   Mon Jun 10 20:41:41 2019 +0800

    scsi: libsas: aic94xx: hisi_sas: mvsas: pm8001: Use dev_is_expander()
    
    Many times in libsas, and in LLDDs which use libsas, the check for an
    expander device is re-implemented or open coded.
    
    Use dev_is_expander() instead. We rename this from
    sas_dev_type_is_expander() to not spill so many lines in referencing.
    
    Signed-off-by: John Garry <john.garry@huawei.com>
    Reviewed-by: Jason Yan <yanaijie@huawei.com>
    Reviewed-by: Jack Wang <jinpu.wang@cloud.ionos.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index c552b4b59717..343d24c7e788 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -3101,7 +3101,7 @@ sci_io_request_construct(struct isci_host *ihost,
 		/* pass */;
 	else if (dev_is_sata(dev))
 		memset(&ireq->stp.cmd, 0, sizeof(ireq->stp.cmd));
-	else if (dev_is_expander(dev))
+	else if (dev_is_expander(dev->dev_type))
 		/* pass */;
 	else
 		return SCI_FAILURE_UNSUPPORTED_PROTOCOL;

commit 881a9a54da175aa5897b8fef7abe0f85a5242770
Author: Geert Uytterhoeven <geert+renesas@glider.be>
Date:   Fri Jun 7 13:34:26 2019 +0200

    scsi: isci: Grammar s/the its/its/
    
    Signed-off-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 1b18cf55167e..c552b4b59717 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -224,7 +224,7 @@ static void scu_ssp_request_construct_task_context(
 	idev = ireq->target_device;
 	iport = idev->owning_port;
 
-	/* Fill in the TC with the its required data */
+	/* Fill in the TC with its required data */
 	task_context->abort = 0;
 	task_context->priority = 0;
 	task_context->initiator_request = 1;
@@ -506,7 +506,7 @@ static void scu_sata_request_construct_task_context(
 	idev = ireq->target_device;
 	iport = idev->owning_port;
 
-	/* Fill in the TC with the its required data */
+	/* Fill in the TC with its required data */
 	task_context->abort = 0;
 	task_context->priority = SCU_TASK_PRIORITY_NORMAL;
 	task_context->initiator_request = 1;
@@ -3235,7 +3235,7 @@ sci_io_request_construct_smp(struct device *dev,
 	iport = idev->owning_port;
 
 	/*
-	 * Fill in the TC with the its required data
+	 * Fill in the TC with its required data
 	 * 00h
 	 */
 	task_context->priority = 0;

commit da7903092b880b25971ca9103cb0b934a44ace2b
Author: Gustavo A. R. Silva <gustavo@embeddedor.com>
Date:   Tue Nov 27 22:30:27 2018 -0600

    scsi: isci: request: mark expected switch fall-through
    
    In preparation to enabling -Wimplicit-fallthrough, mark switch cases where
    we are expecting to fall through.
    
    Notice that, in this particular case, a dash is added as a token in order
    to separate the "Fall through" annotation from the rest of the comment on
    the same line, which is what GCC is expecting to find.
    
    Signed-off-by: Gustavo A. R. Silva <gustavo@embeddedor.com>
    Acked-by: Artur Paszkiewicz <artur.paszkiewicz@intel.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 2f151708b59a..1b18cf55167e 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -894,7 +894,7 @@ sci_io_request_terminate(struct isci_request *ireq)
 		 * and don't wait for the task response.
 		 */
 		sci_change_state(&ireq->sm, SCI_REQ_ABORTING);
-		/* Fall through and handle like ABORTING... */
+		/* Fall through - and handle like ABORTING... */
 	case SCI_REQ_ABORTING:
 		if (!isci_remote_device_is_safe_to_abort(ireq->target_device))
 			set_bit(IREQ_PENDING_ABORT, &ireq->flags);

commit e9e9a103528c7e199ead6e5374c9c52cf16b5802
Author: Nathan Chancellor <natechancellor@gmail.com>
Date:   Wed Sep 26 17:11:50 2018 -0700

    scsi: isci: Use proper enumerated type in atapi_d2h_reg_frame_handler
    
    Clang warns when one enumerated type is implicitly converted to another.
    
    drivers/scsi/isci/request.c:1629:13: warning: implicit conversion from
    enumeration type 'enum sci_io_status' to different enumeration type
    'enum sci_status' [-Wenum-conversion]
                            status = SCI_IO_FAILURE_RESPONSE_VALID;
                                   ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    drivers/scsi/isci/request.c:1631:12: warning: implicit conversion from
    enumeration type 'enum sci_io_status' to different enumeration type
    'enum sci_status' [-Wenum-conversion]
                    status = SCI_IO_FAILURE_RESPONSE_VALID;
                           ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    
    status is of type sci_status but SCI_IO_FAILURE_RESPONSE_VALID is of
    type sci_io_status. Use SCI_FAILURE_IO_RESPONSE_VALID, which is from
    sci_status and has SCI_IO_FAILURE_RESPONSE_VALID's exact value since
    that is what SCI_IO_FAILURE_RESPONSE_VALID is mapped to in the isci.h
    file.
    
    Link: https://github.com/ClangBuiltLinux/linux/issues/153
    Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index ed197bc8e801..2f151708b59a 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -1626,9 +1626,9 @@ static enum sci_status atapi_d2h_reg_frame_handler(struct isci_request *ireq,
 
 	if (status == SCI_SUCCESS) {
 		if (ireq->stp.rsp.status & ATA_ERR)
-			status = SCI_IO_FAILURE_RESPONSE_VALID;
+			status = SCI_FAILURE_IO_RESPONSE_VALID;
 	} else {
-		status = SCI_IO_FAILURE_RESPONSE_VALID;
+		status = SCI_FAILURE_IO_RESPONSE_VALID;
 	}
 
 	if (status != SCI_SUCCESS) {

commit f5f44c6ffe0b39ee37e1d2963ee0d48cbc1ec038
Author: Colin Ian King <colin.king@canonical.com>
Date:   Mon Jul 3 11:17:27 2017 +0100

    scsi: isci: fix typo in function names
    
    There are a couple of typos in function names and spelling of request
    where the letters u and e are swapped:
    
    scu_ssp_reqeust_construct_task_context
    scu_sata_reqeust_construct_task_context
    
    Fix the spelling of request.
    
    Signed-off-by: Colin Ian King <colin.king@canonical.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 47f66e949745..ed197bc8e801 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -213,7 +213,7 @@ static void sci_task_request_build_ssp_task_iu(struct isci_request *ireq)
  * @task_context:
  *
  */
-static void scu_ssp_reqeust_construct_task_context(
+static void scu_ssp_request_construct_task_context(
 	struct isci_request *ireq,
 	struct scu_task_context *task_context)
 {
@@ -425,7 +425,7 @@ static void scu_ssp_io_request_construct_task_context(struct isci_request *ireq,
 	u8 prot_type = scsi_get_prot_type(scmd);
 	u8 prot_op = scsi_get_prot_op(scmd);
 
-	scu_ssp_reqeust_construct_task_context(ireq, task_context);
+	scu_ssp_request_construct_task_context(ireq, task_context);
 
 	task_context->ssp_command_iu_length =
 		sizeof(struct ssp_cmd_iu) / sizeof(u32);
@@ -472,7 +472,7 @@ static void scu_ssp_task_request_construct_task_context(struct isci_request *ire
 {
 	struct scu_task_context *task_context = ireq->tc;
 
-	scu_ssp_reqeust_construct_task_context(ireq, task_context);
+	scu_ssp_request_construct_task_context(ireq, task_context);
 
 	task_context->control_frame                = 1;
 	task_context->priority                     = SCU_TASK_PRIORITY_HIGH;
@@ -495,7 +495,7 @@ static void scu_ssp_task_request_construct_task_context(struct isci_request *ire
  * the command buffer is complete. none Revisit task context construction to
  * determine what is common for SSP/SMP/STP task context structures.
  */
-static void scu_sata_reqeust_construct_task_context(
+static void scu_sata_request_construct_task_context(
 	struct isci_request *ireq,
 	struct scu_task_context *task_context)
 {
@@ -562,7 +562,7 @@ static void scu_stp_raw_request_construct_task_context(struct isci_request *ireq
 {
 	struct scu_task_context *task_context = ireq->tc;
 
-	scu_sata_reqeust_construct_task_context(ireq, task_context);
+	scu_sata_request_construct_task_context(ireq, task_context);
 
 	task_context->control_frame         = 0;
 	task_context->priority              = SCU_TASK_PRIORITY_NORMAL;
@@ -613,7 +613,7 @@ static void sci_stp_optimized_request_construct(struct isci_request *ireq,
 	struct scu_task_context *task_context = ireq->tc;
 
 	/* Build the STP task context structure */
-	scu_sata_reqeust_construct_task_context(ireq, task_context);
+	scu_sata_request_construct_task_context(ireq, task_context);
 
 	/* Copy over the SGL elements */
 	sci_request_build_sgl(ireq);
@@ -1401,7 +1401,7 @@ static enum sci_status sci_stp_request_pio_data_out_transmit_data(struct isci_re
  * @data_buffer: The buffer of data to be copied.
  * @length: The length of the data transfer.
  *
- * Copy the data from the buffer for the length specified to the IO reqeust SGL
+ * Copy the data from the buffer for the length specified to the IO request SGL
  * specified data region. enum sci_status
  */
 static enum sci_status

commit 63eb7b6bc7a35ce66dbf829850ad9b46fb3ecf5e
Author: Colin Ian King <colin.king@canonical.com>
Date:   Sat Nov 12 18:30:26 2016 +0000

    scsi: isci: fix typo in deg_dbg message
    
    Trivial fix to typo "repsonse" to "response" in dev_dbg message.
    
    Signed-off-by: Colin Ian King <colin.king@canonical.com>
    Reviewed-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index b709d2b20880..47f66e949745 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2473,7 +2473,7 @@ static void isci_request_process_response_iu(
 		"%s: resp_iu = %p "
 		"resp_iu->status = 0x%x,\nresp_iu->datapres = %d "
 		"resp_iu->response_data_len = %x, "
-		"resp_iu->sense_data_len = %x\nrepsonse data: ",
+		"resp_iu->sense_data_len = %x\nresponse data: ",
 		__func__,
 		resp_iu,
 		resp_iu->status,

commit 661ce1f0c4a69f92ad781d8d2c205c90dd9c5833
Author: Hannes Reinecke <hare@suse.de>
Date:   Mon Apr 25 12:45:45 2016 +0200

    libata/libsas: Define ATA_CMD_NCQ_NON_DATA
    
    Define the NCQ NON DATA command and update libsas to handle it
    correctly.
    
    Signed-off-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 29456e097a30..b709d2b20880 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -3171,7 +3171,8 @@ static enum sci_status isci_request_stp_request_construct(struct isci_request *i
 	if (qc && (qc->tf.command == ATA_CMD_FPDMA_WRITE ||
 		   qc->tf.command == ATA_CMD_FPDMA_READ ||
 		   qc->tf.command == ATA_CMD_FPDMA_RECV ||
-		   qc->tf.command == ATA_CMD_FPDMA_SEND)) {
+		   qc->tf.command == ATA_CMD_FPDMA_SEND ||
+		   qc->tf.command == ATA_CMD_NCQ_NON_DATA)) {
 		fis->sector_count = qc->tag << 3;
 		ireq->tc->type.stp.ncq_tag = qc->tag;
 	}

commit ef026b18bb8260e21b4a61685eac46ecdc490d00
Author: Hannes Reinecke <hare@suse.de>
Date:   Mon Apr 25 12:45:44 2016 +0200

    libsas: enable FPDMA SEND/RECEIVE
    
    Update libsas and dependent drivers to handle FPDMA
    SEND/RECEIVE correctly.
    
    Signed-off-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index cfd0084f1cd2..29456e097a30 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -3169,7 +3169,9 @@ static enum sci_status isci_request_stp_request_construct(struct isci_request *i
 	status = sci_io_request_construct_basic_sata(ireq);
 
 	if (qc && (qc->tf.command == ATA_CMD_FPDMA_WRITE ||
-		   qc->tf.command == ATA_CMD_FPDMA_READ)) {
+		   qc->tf.command == ATA_CMD_FPDMA_READ ||
+		   qc->tf.command == ATA_CMD_FPDMA_RECV ||
+		   qc->tf.command == ATA_CMD_FPDMA_SEND)) {
 		fis->sector_count = qc->tag << 3;
 		ireq->tc->type.stp.ncq_tag = qc->tag;
 	}

commit 1cbd772d9aaf6c697935cb855860b66cebacf950
Author: Hannes Reinecke <hare@suse.de>
Date:   Wed Nov 5 13:08:20 2014 +0100

    libsas: use ata_dev_classify()
    
    Use the ata device class from libata in libsas instead of checking
    the supported command set and switch to using ata_dev_classify()
    instead of our own method.
    
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 56e38096f0c4..cfd0084f1cd2 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -694,7 +694,7 @@ sci_io_request_construct_sata(struct isci_request *ireq,
 	}
 
 	/* ATAPI */
-	if (dev->sata_dev.command_set == ATAPI_COMMAND_SET &&
+	if (dev->sata_dev.class == ATA_DEV_ATAPI &&
 	    task->ata_task.fis.command == ATA_CMD_PACKET) {
 		sci_atapi_construct(ireq);
 		return SCI_SUCCESS;
@@ -2980,7 +2980,7 @@ static void sci_request_started_state_enter(struct sci_base_state_machine *sm)
 		state = SCI_REQ_SMP_WAIT_RESP;
 	} else if (task && sas_protocol_ata(task->task_proto) &&
 		   !task->ata_task.use_ncq) {
-		if (dev->sata_dev.command_set == ATAPI_COMMAND_SET &&
+		if (dev->sata_dev.class == ATA_DEV_ATAPI &&
 			task->ata_task.fis.command == ATA_CMD_PACKET) {
 			state = SCI_REQ_ATAPI_WAIT_H2D;
 		} else if (task->data_dir == DMA_NONE) {

commit 2193b1b16cc7c690f74f917c50004dd00c99088e
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Feb 6 12:23:15 2014 -0800

    [SCSI] isci: fix needless ata reset escalations
    
    isci is needlessly tying libata's hands by returning
    SAM_STAT_CHECK_CONDITION to some ata errors.  Instead, prefer
    SAS_PROTO_RESPONSE to let libata (via sas_ata_task_done()) disposition
    the device-to-host fis.
    
    For example isci is triggering an HSM Violation where AHCI is showing a
    simple media error for the same bus condition:
    
    isci:
    ata7.00: failed command: READ VERIFY SECTOR(S)
    ata7.00: cmd 40/00:01:00:00:00/00:00:00:00:00/e0 tag 0
             res 01/04:00:00:00:00/00:00:00:00:00/e0 Emask 0x3 (HSM violation)
    
    ahci:
    ata6.00: failed command: READ VERIFY SECTOR(S)
    ata6.00: cmd 40/00:01:00:00:00/00:00:00:00:00/e0 tag 0
             res 51/40:01:00:00:00/00:00:00:00:00/e0 Emask 0x9 (media error)
    
    Note that the isci response matches this from sas_ata_task_done():
            /* We saw a SAS error. Send a vague error. */
            [..]
            dev->sata_dev.fis[3] = 0x04; /* status err */
            dev->sata_dev.fis[2] = ATA_ERR;
    
    The end effect is that isci is needlessly triggering hard resets when
    they are not necessary.
    
    Reported-by: Xun Ni <xun.ni@intel.com>
    Tested-by: Nelson Cheng <nelson.cheng@intel.com>
    Acked-by: Lukasz Dorau <lukasz.dorau@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 99d2930b18c8..56e38096f0c4 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2723,13 +2723,9 @@ static void isci_process_stp_response(struct sas_task *task, struct dev_to_host_
 	memcpy(resp->ending_fis, fis, sizeof(*fis));
 	ts->buf_valid_size = sizeof(*resp);
 
-	/* If the device fault bit is set in the status register, then
-	 * set the sense data and return.
-	 */
-	if (fis->status & ATA_DF)
+	/* If an error is flagged let libata decode the fis */
+	if (ac_err_mask(fis->status))
 		ts->stat = SAS_PROTO_RESPONSE;
-	else if (fis->status & ATA_ERR)
-		ts->stat = SAM_STAT_CHECK_CONDITION;
 	else
 		ts->stat = SAM_STAT_GOOD;
 

commit e1be09808e030d57bb743618eb41e2bc31dd464c
Author: James Bottomley <JBottomley@Parallels.com>
Date:   Wed Jul 24 12:43:18 2013 -0700

    [SCSI] isci: fix breakage caused by >16byte CDB patch
    
    Oops, apparently no-one I cc'd at intel actually bothered to check this
    patch for the isci driver:
    
    commit e73823f7a2c921dcf068d34ea03bd682498d9e42
    Author: James Bottomley <JBottomley@Parallels.com>
    Date:   Tue May 7 15:38:18 2013 -0700
    
        [SCSI] libsas: implement > 16 byte CDB support
    
    sci_swab32_cpy needs multiples of four, so for commands that aren't that, it's
    rounding the wrong way.  fix by doing (len+3)/4 instead of len/4.
    
    Reported-by: Tony Luck <tony.luck@intel.com>
    Tested-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 7b082157eb79..99d2930b18c8 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -185,7 +185,7 @@ static void sci_io_request_build_ssp_command_iu(struct isci_request *ireq)
 	cmd_iu->_r_c = 0;
 
 	sci_swab32_cpy(&cmd_iu->cdb, task->ssp_task.cmd->cmnd,
-		       task->ssp_task.cmd->cmd_len / sizeof(u32));
+		       (task->ssp_task.cmd->cmd_len+3) / sizeof(u32));
 }
 
 static void sci_task_request_build_ssp_task_iu(struct isci_request *ireq)

commit e73823f7a2c921dcf068d34ea03bd682498d9e42
Author: James Bottomley <JBottomley@Parallels.com>
Date:   Tue May 7 15:38:18 2013 -0700

    [SCSI] libsas: implement > 16 byte CDB support
    
    Remove the arbitrary expectation in libsas that all SCSI commands are 16 bytes
    or less.  Instead do all copies via cmd->cmd_len (and use a pointer to this in
    the libsas task instead of a copy).  Note that this still doesn't enable > 16
    byte CDB support in the underlying drivers because their internal format has
    to be fixed and the wire format of > 16 byte CDBs according to the SAS spec is
    different.  the libsas drivers (isci, aic94xx, mvsas and pm8xxx are all
    updated for this change.
    
    Cc: Lukasz Dorau <lukasz.dorau@intel.com>
    Cc: Maciej Patelczyk <maciej.patelczyk@intel.com>
    Cc: Dave Jiang <dave.jiang@intel.com>
    Cc: Jack Wang <xjtuwjp@gmail.com>
    Cc: Lindar Liu <lindar_liu@usish.com>
    Cc: Xiangliang Yu <yuxiangl@marvell.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index e3e3bcbd5a9f..7b082157eb79 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -184,8 +184,8 @@ static void sci_io_request_build_ssp_command_iu(struct isci_request *ireq)
 	cmd_iu->task_attr = task->ssp_task.task_attr;
 	cmd_iu->_r_c = 0;
 
-	sci_swab32_cpy(&cmd_iu->cdb, task->ssp_task.cdb,
-		       sizeof(task->ssp_task.cdb) / sizeof(u32));
+	sci_swab32_cpy(&cmd_iu->cdb, task->ssp_task.cmd->cmnd,
+		       task->ssp_task.cmd->cmd_len / sizeof(u32));
 }
 
 static void sci_task_request_build_ssp_task_iu(struct isci_request *ireq)

commit aa9f8328fc51460e15da129caf622b6560fa8c99
Author: James Bottomley <JBottomley@Parallels.com>
Date:   Tue May 7 14:44:06 2013 -0700

    [SCSI] sas: unify the pointlessly separated enums sas_dev_type and sas_device_type
    
    These enums have been separate since the dawn of SAS, mainly because the
    latter is a procotol only enum and the former includes additional state
    for libsas.  The dichotomy causes endless confusion about which one you
    should use where and leads to pointless warnings like this:
    
    drivers/scsi/mvsas/mv_sas.c: In function 'mvs_update_phyinfo':
    drivers/scsi/mvsas/mv_sas.c:1162:34: warning: comparison between 'enum sas_device_type' and 'enum sas_dev_type' [-Wenum-compare]
    
    Fix by eliminating one of them.  The one kept is effectively the sas.h
    one, but call it sas_device_type and make sure the enums are all
    properly namespaced with the SAS_ prefix.
    
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 9594ab62702b..e3e3bcbd5a9f 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2978,7 +2978,7 @@ static void sci_request_started_state_enter(struct sci_base_state_machine *sm)
 	/* all unaccelerated request types (non ssp or ncq) handled with
 	 * substates
 	 */
-	if (!task && dev->dev_type == SAS_END_DEV) {
+	if (!task && dev->dev_type == SAS_END_DEVICE) {
 		state = SCI_REQ_TASK_WAIT_TC_COMP;
 	} else if (task && task->task_proto == SAS_PROTOCOL_SMP) {
 		state = SCI_REQ_SMP_WAIT_RESP;
@@ -3101,7 +3101,7 @@ sci_io_request_construct(struct isci_host *ihost,
 	if (idev->rnc.remote_node_index == SCIC_SDS_REMOTE_NODE_CONTEXT_INVALID_INDEX)
 		return SCI_FAILURE_INVALID_REMOTE_DEVICE;
 
-	if (dev->dev_type == SAS_END_DEV)
+	if (dev->dev_type == SAS_END_DEVICE)
 		/* pass */;
 	else if (dev_is_sata(dev))
 		memset(&ireq->stp.cmd, 0, sizeof(ireq->stp.cmd));
@@ -3125,7 +3125,7 @@ enum sci_status sci_task_request_construct(struct isci_host *ihost,
 	/* Build the common part of the request */
 	sci_general_request_construct(ihost, idev, ireq);
 
-	if (dev->dev_type == SAS_END_DEV || dev_is_sata(dev)) {
+	if (dev->dev_type == SAS_END_DEVICE || dev_is_sata(dev)) {
 		set_bit(IREQ_TMF, &ireq->flags);
 		memset(ireq->tc, 0, sizeof(struct scu_task_context));
 

commit 49bd665c5407a453736d3232ee58f2906b42e83c
Author: Maciej Patelczyk <maciej.patelczyk@intel.com>
Date:   Mon Oct 15 14:29:03 2012 +0200

    [SCSI] isci: copy fis 0x34 response into proper buffer
    
    SATA MICROCODE DOWNALOAD fails on isci driver. After receiving Register
    Device to Host (FIS 0x34) frame Initiator resets phy.
    In the frame handler routine response (FIS 0x34) was copied into wrong
    buffer and upper layer did not receive any answer which resulted in
    timeout and reset.
    This patch corrects this bug.
    
    Signed-off-by: Maciej Patelczyk <maciej.patelczyk@intel.com>
    Signed-off-by: Lukasz Dorau <lukasz.dorau@intel.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index c1bafc3f3fb1..9594ab62702b 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -1972,7 +1972,7 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 								      frame_index,
 								      (void **)&frame_buffer);
 
-			sci_controller_copy_sata_response(&ireq->stp.req,
+			sci_controller_copy_sata_response(&ireq->stp.rsp,
 							       frame_header,
 							       frame_buffer);
 

commit 4907cb7b193a4f91c1fd30cf679c035e3644c64d
Author: Anatol Pomozov <anatol.pomozov@gmail.com>
Date:   Sat Sep 1 10:31:09 2012 -0700

    treewide: fix comment/printk/variable typos
    
    Signed-off-by: Anatol Pomozov <anatol.pomozov@gmail.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 7a0431c73493..c1bafc3f3fb1 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2240,7 +2240,7 @@ static enum sci_status atapi_data_tc_completion_handler(struct isci_request *ire
 			status = ireq->sci_status;
 			sci_change_state(&idev->sm, SCI_STP_DEV_ATAPI_ERROR);
 		} else {
-			/* If receiving any non-sucess TC status, no UF
+			/* If receiving any non-success TC status, no UF
 			 * received yet, then an UF for the status fis
 			 * is coming after (XXX: suspect this is
 			 * actually a protocol error or a bug like the

commit f8381807ebdfffa34c2c5aa38eda33673d1a7adf
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Sun Mar 4 12:44:53 2012 +0000

    isci: Remove obviated host callback list.
    
    Since the callbacks to libsas now occur under scic_lock, there is no
    longer any reason to save the completed requests in a separate list
    for completion to libsas.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 6c530e4275e2..7a0431c73493 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2748,13 +2748,9 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 	enum exec_status status = SAS_ABORTED_TASK;
 
 	dev_dbg(&ihost->pdev->dev,
-		"%s: request = %p, task = %p,\n"
+		"%s: request = %p, task = %p, "
 		"task->data_dir = %d completion_status = 0x%x\n",
-		__func__,
-		request,
-		task,
-		task->data_dir,
-		completion_status);
+		__func__, request, task, task->data_dir, completion_status);
 
 	/* The request is done from an SCU HW perspective. */
 
@@ -2955,9 +2951,6 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 	}
 	spin_unlock_irqrestore(&task->task_state_lock, task_flags);
 
-	/* Add to the completed list. */
-	list_add(&request->completed_node, &ihost->requests_to_complete);
-
 	/* complete the io request to the core. */
 	sci_controller_complete_io(ihost, request->target_device, request);
 
@@ -2966,6 +2959,8 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 	 * task to recognize the already completed case.
 	 */
 	set_bit(IREQ_TERMINATED, &request->flags);
+
+	ireq_done(ihost, request, task);
 }
 
 static void sci_request_started_state_enter(struct sci_base_state_machine *sm)
@@ -3416,7 +3411,6 @@ static struct isci_request *isci_request_from_tag(struct isci_host *ihost, u16 t
 	ireq->io_request_completion = NULL;
 	ireq->flags = 0;
 	ireq->num_sg_entries = 0;
-	INIT_LIST_HEAD(&ireq->completed_node);
 
 	return ireq;
 }

commit 87805162b6af20d2ad386a49aec13b753cca523a
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Thu Mar 8 22:42:09 2012 -0800

    isci: Restore the ATAPI device RNC management code.
    
    The ATAPI specific and STP general RNC suspension code had been
    incorrectly removed from the remote device code.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 415d5f55d1c6..6c530e4275e2 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2118,6 +2118,9 @@ static enum sci_status stp_request_udma_await_tc_event(struct isci_request *ireq
 		 * completion.
 		 */
 		if (ireq->stp.rsp.fis_type == FIS_REGD2H) {
+			sci_remote_device_suspend(ireq->target_device,
+						  SCI_SW_SUSPEND_NORMAL);
+
 			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
 			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
 			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);

commit 28de92bef0fb0c3953aa73d31a961422ef900e6a
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Thu Mar 8 22:42:06 2012 -0800

    isci: Add protocol indicator for TMF requests.
    
    Requests contructed as task management requests need to have the protocol
    indicator set so the completion decode can observe any RNC suspension
    conditions.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 432585b04dc2..415d5f55d1c6 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -3130,6 +3130,12 @@ enum sci_status sci_task_request_construct(struct isci_host *ihost,
 	if (dev->dev_type == SAS_END_DEV || dev_is_sata(dev)) {
 		set_bit(IREQ_TMF, &ireq->flags);
 		memset(ireq->tc, 0, sizeof(struct scu_task_context));
+
+		/* Set the protocol indicator. */
+		if (dev_is_sata(dev))
+			ireq->protocol = SAS_PROTOCOL_STP;
+		else
+			ireq->protocol = SAS_PROTOCOL_SSP;
 	} else
 		status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;
 

commit 447bfbcee070a0b43dd6abc743063d7a02fe65ca
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Thu Mar 8 22:41:59 2012 -0800

    isci: Save the suspension hint for upcoming suspensions.
    
    In the case of a suspend call while in SCI_RNC_POSTING or INVALIDATING
    states, the LLHANG detect needed to be saved so the upcoming suspension
    would enable it correctly.  The unused suspend callback parameters were
    removed.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 809d3683d0c9..432585b04dc2 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2382,8 +2382,7 @@ static void sci_request_handle_suspending_completions(
 			&ireq->target_device->rnc,
 			SCI_HW_SUSPEND,
 			(is_tx_rx) ? SCU_EVENT_TL_RNC_SUSPEND_TX_RX
-				   : SCU_EVENT_TL_RNC_SUSPEND_TX,
-			NULL, NULL);
+				   : SCU_EVENT_TL_RNC_SUSPEND_TX);
 	}
 }
 

commit e3c84dfdb8f4c675b0ba5cf3fa252dc4056b7ddd
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Thu Mar 8 22:41:58 2012 -0800

    isci: Fix the terminated I/O to not call sas_task_abort().
    
    This addresses a regression from the commit "isci: Redesign
    device suspension, abort, cleanup." in which the sas_task end
    condition for terminated I/Os was made to call back on
    sas_task_abort()".
    This commit will be rolled into the original.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 48b409d68c0d..809d3683d0c9 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2832,7 +2832,7 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 			__func__, request, task);
 
 		/* The request was terminated explicitly. */
-		clear_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
+		set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 		response = SAS_TASK_UNDELIVERED;
 
 		/* See if the device has been/is being stopped. Note

commit c94fc1ad25de885e1c59f714f19bc726e7a21caf
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Thu Mar 8 22:41:58 2012 -0800

    isci: Distinguish between remote device suspension cases
    
    For NCQ error conditions among others, there is no need to enable
    the link layer hang detect timer.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 662f36de8052..48b409d68c0d 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2380,7 +2380,7 @@ static void sci_request_handle_suspending_completions(
 
 		sci_remote_node_context_suspend(
 			&ireq->target_device->rnc,
-			SCU_HARDWARE_SUSPENSION,
+			SCI_HW_SUSPEND,
 			(is_tx_rx) ? SCU_EVENT_TL_RNC_SUSPEND_TX_RX
 				   : SCU_EVENT_TL_RNC_SUSPEND_TX,
 			NULL, NULL);

commit d6b2a0e4a066ea51322e16e66b25028cb0b4ca7e
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Thu Mar 8 22:41:57 2012 -0800

    isci: Remove isci_device reqs_in_process and dev_node from isci_device.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index f4e80f31423c..662f36de8052 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2956,9 +2956,6 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 	/* Add to the completed list. */
 	list_add(&request->completed_node, &ihost->requests_to_complete);
 
-	/* Take the request off the device's pending request list. */
-	list_del_init(&request->dev_node);
-
 	/* complete the io request to the core. */
 	sci_controller_complete_io(ihost, request->target_device, request);
 
@@ -3412,7 +3409,6 @@ static struct isci_request *isci_request_from_tag(struct isci_host *ihost, u16 t
 	ireq->flags = 0;
 	ireq->num_sg_entries = 0;
 	INIT_LIST_HEAD(&ireq->completed_node);
-	INIT_LIST_HEAD(&ireq->dev_node);
 
 	return ireq;
 }
@@ -3496,17 +3492,9 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 		spin_unlock_irqrestore(&ihost->scic_lock, flags);
 		return status;
 	}
-
 	/* Either I/O started OK, or the core has signaled that
 	 * the device needs a target reset.
-	 *
-	 * In either case, hold onto the I/O for later.
-	 *
-	 * Update it's status and add it to the list in the
-	 * remote device object.
 	 */
-	list_add(&ireq->dev_node, &idev->reqs_in_process);
-
 	if (status != SCI_SUCCESS) {
 		/* The request did not really start in the
 		 * hardware, so clear the request handle

commit 14aaa9f0a318bd04cbb9d822524b817e95d8b343
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Thu Mar 8 22:41:54 2012 -0800

    isci: Redesign device suspension, abort, cleanup.
    
    This commit changes the means by which outstanding I/Os are handled
    for cleanup.
    The likelihood is that this commit will be broken into smaller pieces,
    however that will be a later revision.  Among the changes:
    
    - All completion structures have been removed from the tmf and
    abort paths.
    - Now using one completed I/O list, with the I/O completed in host bit being
    used to select error or normal callback paths.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 1f314d0d71d5..f4e80f31423c 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2491,9 +2491,6 @@ static void isci_request_process_response_iu(
  * @request: This parameter is the completed isci_request object.
  * @response_ptr: This parameter specifies the service response for the I/O.
  * @status_ptr: This parameter specifies the exec status for the I/O.
- * @complete_to_host_ptr: This parameter specifies the action to be taken by
- *    the LLDD with respect to completing this request or forcing an abort
- *    condition on the I/O.
  * @open_rej_reason: This parameter specifies the encoded reason for the
  *    abandon-class reject.
  *
@@ -2504,14 +2501,12 @@ static void isci_request_set_open_reject_status(
 	struct sas_task *task,
 	enum service_response *response_ptr,
 	enum exec_status *status_ptr,
-	enum isci_completion_selection *complete_to_host_ptr,
 	enum sas_open_rej_reason open_rej_reason)
 {
 	/* Task in the target is done. */
 	set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 	*response_ptr                     = SAS_TASK_UNDELIVERED;
 	*status_ptr                       = SAS_OPEN_REJECT;
-	*complete_to_host_ptr             = isci_perform_normal_io_completion;
 	task->task_status.open_rej_reason = open_rej_reason;
 }
 
@@ -2521,9 +2516,6 @@ static void isci_request_set_open_reject_status(
  * @request: This parameter is the completed isci_request object.
  * @response_ptr: This parameter specifies the service response for the I/O.
  * @status_ptr: This parameter specifies the exec status for the I/O.
- * @complete_to_host_ptr: This parameter specifies the action to be taken by
- *    the LLDD with respect to completing this request or forcing an abort
- *    condition on the I/O.
  *
  * none.
  */
@@ -2532,8 +2524,7 @@ static void isci_request_handle_controller_specific_errors(
 	struct isci_request *request,
 	struct sas_task *task,
 	enum service_response *response_ptr,
-	enum exec_status *status_ptr,
-	enum isci_completion_selection *complete_to_host_ptr)
+	enum exec_status *status_ptr)
 {
 	unsigned int cstatus;
 
@@ -2574,9 +2565,6 @@ static void isci_request_handle_controller_specific_errors(
 				*status_ptr = SAS_ABORTED_TASK;
 
 			set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
-
-			*complete_to_host_ptr =
-				isci_perform_normal_io_completion;
 		} else {
 			/* Task in the target is not done. */
 			*response_ptr = SAS_TASK_UNDELIVERED;
@@ -2587,9 +2575,6 @@ static void isci_request_handle_controller_specific_errors(
 				*status_ptr = SAM_STAT_TASK_ABORTED;
 
 			clear_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
-
-			*complete_to_host_ptr =
-				isci_perform_error_io_completion;
 		}
 
 		break;
@@ -2618,8 +2603,6 @@ static void isci_request_handle_controller_specific_errors(
 			*status_ptr = SAS_ABORTED_TASK;
 
 		set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
-
-		*complete_to_host_ptr = isci_perform_normal_io_completion;
 		break;
 
 
@@ -2630,7 +2613,7 @@ static void isci_request_handle_controller_specific_errors(
 
 		isci_request_set_open_reject_status(
 			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_WRONG_DEST);
+			SAS_OREJ_WRONG_DEST);
 		break;
 
 	case SCU_TASK_OPEN_REJECT_ZONE_VIOLATION:
@@ -2640,56 +2623,56 @@ static void isci_request_handle_controller_specific_errors(
 		 */
 		isci_request_set_open_reject_status(
 			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_RESV_AB0);
+			SAS_OREJ_RESV_AB0);
 		break;
 
 	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_1:
 
 		isci_request_set_open_reject_status(
 			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_RESV_AB1);
+			SAS_OREJ_RESV_AB1);
 		break;
 
 	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_2:
 
 		isci_request_set_open_reject_status(
 			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_RESV_AB2);
+			SAS_OREJ_RESV_AB2);
 		break;
 
 	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_3:
 
 		isci_request_set_open_reject_status(
 			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_RESV_AB3);
+			SAS_OREJ_RESV_AB3);
 		break;
 
 	case SCU_TASK_OPEN_REJECT_BAD_DESTINATION:
 
 		isci_request_set_open_reject_status(
 			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_BAD_DEST);
+			SAS_OREJ_BAD_DEST);
 		break;
 
 	case SCU_TASK_OPEN_REJECT_STP_RESOURCES_BUSY:
 
 		isci_request_set_open_reject_status(
 			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_STP_NORES);
+			SAS_OREJ_STP_NORES);
 		break;
 
 	case SCU_TASK_OPEN_REJECT_PROTOCOL_NOT_SUPPORTED:
 
 		isci_request_set_open_reject_status(
 			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_EPROTO);
+			SAS_OREJ_EPROTO);
 		break;
 
 	case SCU_TASK_OPEN_REJECT_CONNECTION_RATE_NOT_SUPPORTED:
 
 		isci_request_set_open_reject_status(
 			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_CONN_RATE);
+			SAS_OREJ_CONN_RATE);
 		break;
 
 	case SCU_TASK_DONE_LL_R_ERR:
@@ -2721,95 +2704,12 @@ static void isci_request_handle_controller_specific_errors(
 		*response_ptr = SAS_TASK_UNDELIVERED;
 		*status_ptr = SAM_STAT_TASK_ABORTED;
 
-		if (task->task_proto == SAS_PROTOCOL_SMP) {
+		if (task->task_proto == SAS_PROTOCOL_SMP)
 			set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
-
-			*complete_to_host_ptr = isci_perform_normal_io_completion;
-		} else {
+		else
 			clear_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
-
-			*complete_to_host_ptr = isci_perform_error_io_completion;
-		}
-		break;
-	}
-}
-
-/**
- * isci_task_save_for_upper_layer_completion() - This function saves the
- *    request for later completion to the upper layer driver.
- * @host: This parameter is a pointer to the host on which the the request
- *    should be queued (either as an error or success).
- * @request: This parameter is the completed request.
- * @response: This parameter is the response code for the completed task.
- * @status: This parameter is the status code for the completed task.
- *
- * none.
- */
-static void isci_task_save_for_upper_layer_completion(
-	struct isci_host *host,
-	struct isci_request *request,
-	enum service_response response,
-	enum exec_status status,
-	enum isci_completion_selection task_notification_selection)
-{
-	struct sas_task *task = isci_request_access_task(request);
-
-	task_notification_selection
-		= isci_task_set_completion_status(task, response, status,
-						  task_notification_selection);
-
-	/* Tasks aborted specifically by a call to the lldd_abort_task
-	 * function should not be completed to the host in the regular path.
-	 */
-	switch (task_notification_selection) {
-
-	case isci_perform_normal_io_completion:
-		/* Normal notification (task_done) */
-
-		/* Add to the completed list. */
-		list_add(&request->completed_node,
-			 &host->requests_to_complete);
-
-		/* Take the request off the device's pending request list. */
-		list_del_init(&request->dev_node);
-		break;
-
-	case isci_perform_aborted_io_completion:
-		/* No notification to libsas because this request is
-		 * already in the abort path.
-		 */
-		/* Wake up whatever process was waiting for this
-		 * request to complete.
-		 */
-		WARN_ON(request->io_request_completion == NULL);
-
-		if (request->io_request_completion != NULL) {
-
-			/* Signal whoever is waiting that this
-			* request is complete.
-			*/
-			complete(request->io_request_completion);
-		}
-		break;
-
-	case isci_perform_error_io_completion:
-		/* Use sas_task_abort */
-		/* Add to the aborted list. */
-		list_add(&request->completed_node,
-			 &host->requests_to_errorback);
-		break;
-
-	default:
-		/* Add to the error to libsas list. */
-		list_add(&request->completed_node,
-			 &host->requests_to_errorback);
 		break;
 	}
-	dev_dbg(&host->pdev->dev,
-		"%s: %d - task = %p, response=%d (%d), status=%d (%d)\n",
-		__func__, task_notification_selection, task,
-		(task) ? task->task_status.resp : 0, response,
-		(task) ? task->task_status.stat : 0, status);
 }
 
 static void isci_process_stp_response(struct sas_task *task, struct dev_to_host_fis *fis)
@@ -2844,9 +2744,6 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 	struct isci_remote_device *idev = request->target_device;
 	enum service_response response = SAS_TASK_UNDELIVERED;
 	enum exec_status status = SAS_ABORTED_TASK;
-	enum isci_request_status request_status;
-	enum isci_completion_selection complete_to_host
-		= isci_perform_normal_io_completion;
 
 	dev_dbg(&ihost->pdev->dev,
 		"%s: request = %p, task = %p,\n"
@@ -2857,282 +2754,158 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 		task->data_dir,
 		completion_status);
 
-	spin_lock(&request->state_lock);
-	request_status = request->status;
-
-	/* Decode the request status.  Note that if the request has been
-	 * aborted by a task management function, we don't care
-	 * what the status is.
-	 */
-	switch (request_status) {
-
-	case aborted:
-		/* "aborted" indicates that the request was aborted by a task
-		 * management function, since once a task management request is
-		 * perfomed by the device, the request only completes because
-		 * of the subsequent driver terminate.
-		 *
-		 * Aborted also means an external thread is explicitly managing
-		 * this request, so that we do not complete it up the stack.
-		 *
-		 * The target is still there (since the TMF was successful).
-		 */
-		set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
-		response = SAS_TASK_COMPLETE;
+	/* The request is done from an SCU HW perspective. */
 
-		/* See if the device has been/is being stopped. Note
-		 * that we ignore the quiesce state, since we are
-		 * concerned about the actual device state.
-		 */
-		if (!idev)
-			status = SAS_DEVICE_UNKNOWN;
-		else
-			status = SAS_ABORTED_TASK;
+	/* This is an active request being completed from the core. */
+	switch (completion_status) {
 
-		complete_to_host = isci_perform_aborted_io_completion;
-		/* This was an aborted request. */
+	case SCI_IO_FAILURE_RESPONSE_VALID:
+		dev_dbg(&ihost->pdev->dev,
+			"%s: SCI_IO_FAILURE_RESPONSE_VALID (%p/%p)\n",
+			__func__, request, task);
 
-		spin_unlock(&request->state_lock);
-		break;
+		if (sas_protocol_ata(task->task_proto)) {
+			isci_process_stp_response(task, &request->stp.rsp);
+		} else if (SAS_PROTOCOL_SSP == task->task_proto) {
 
-	case aborting:
-		/* aborting means that the task management function tried and
-		 * failed to abort the request. We need to note the request
-		 * as SAS_TASK_UNDELIVERED, so that the scsi mid layer marks the
-		 * target as down.
-		 *
-		 * Aborting also means an external thread is explicitly managing
-		 * this request, so that we do not complete it up the stack.
-		 */
-		set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
-		response = SAS_TASK_UNDELIVERED;
+			/* crack the iu response buffer. */
+			resp_iu = &request->ssp.rsp;
+			isci_request_process_response_iu(task, resp_iu,
+							 &ihost->pdev->dev);
 
-		if (!idev)
-			/* The device has been /is being stopped. Note that
-			 * we ignore the quiesce state, since we are
-			 * concerned about the actual device state.
-			 */
-			status = SAS_DEVICE_UNKNOWN;
-		else
-			status = SAS_PHY_DOWN;
+		} else if (SAS_PROTOCOL_SMP == task->task_proto) {
 
-		complete_to_host = isci_perform_aborted_io_completion;
+			dev_err(&ihost->pdev->dev,
+				"%s: SCI_IO_FAILURE_RESPONSE_VALID: "
+					"SAS_PROTOCOL_SMP protocol\n",
+				__func__);
 
-		/* This was an aborted request. */
+		} else
+			dev_err(&ihost->pdev->dev,
+				"%s: unknown protocol\n", __func__);
 
-		spin_unlock(&request->state_lock);
+		/* use the task status set in the task struct by the
+		* isci_request_process_response_iu call.
+		*/
+		set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
+		response = task->task_status.resp;
+		status = task->task_status.stat;
 		break;
 
-	case terminating:
+	case SCI_IO_SUCCESS:
+	case SCI_IO_SUCCESS_IO_DONE_EARLY:
 
-		/* This was an terminated request.  This happens when
-		 * the I/O is being terminated because of an action on
-		 * the device (reset, tear down, etc.), and the I/O needs
-		 * to be completed up the stack.
-		 */
+		response = SAS_TASK_COMPLETE;
+		status   = SAM_STAT_GOOD;
 		set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
-		response = SAS_TASK_UNDELIVERED;
 
-		/* See if the device has been/is being stopped. Note
-		 * that we ignore the quiesce state, since we are
-		 * concerned about the actual device state.
-		 */
-		if (!idev)
-			status = SAS_DEVICE_UNKNOWN;
-		else
-			status = SAS_ABORTED_TASK;
-
-		complete_to_host = isci_perform_aborted_io_completion;
-
-		/* This was a terminated request. */
-
-		spin_unlock(&request->state_lock);
-		break;
+		if (completion_status == SCI_IO_SUCCESS_IO_DONE_EARLY) {
 
-	case dead:
-		/* This was a terminated request that timed-out during the
-		 * termination process.  There is no task to complete to
-		 * libsas.
-		 */
-		complete_to_host = isci_perform_normal_io_completion;
-		spin_unlock(&request->state_lock);
-		break;
-
-	default:
-
-		/* The request is done from an SCU HW perspective. */
-		request->status = completed;
+			/* This was an SSP / STP / SATA transfer.
+			* There is a possibility that less data than
+			* the maximum was transferred.
+			*/
+			u32 transferred_length = sci_req_tx_bytes(request);
 
-		spin_unlock(&request->state_lock);
+			task->task_status.residual
+				= task->total_xfer_len - transferred_length;
 
-		/* This is an active request being completed from the core. */
-		switch (completion_status) {
+			/* If there were residual bytes, call this an
+			* underrun.
+			*/
+			if (task->task_status.residual != 0)
+				status = SAS_DATA_UNDERRUN;
 
-		case SCI_IO_FAILURE_RESPONSE_VALID:
 			dev_dbg(&ihost->pdev->dev,
-				"%s: SCI_IO_FAILURE_RESPONSE_VALID (%p/%p)\n",
-				__func__,
-				request,
-				task);
-
-			if (sas_protocol_ata(task->task_proto)) {
-				isci_process_stp_response(task, &request->stp.rsp);
-			} else if (SAS_PROTOCOL_SSP == task->task_proto) {
-
-				/* crack the iu response buffer. */
-				resp_iu = &request->ssp.rsp;
-				isci_request_process_response_iu(task, resp_iu,
-								 &ihost->pdev->dev);
-
-			} else if (SAS_PROTOCOL_SMP == task->task_proto) {
+				"%s: SCI_IO_SUCCESS_IO_DONE_EARLY %d\n",
+				__func__, status);
 
-				dev_err(&ihost->pdev->dev,
-					"%s: SCI_IO_FAILURE_RESPONSE_VALID: "
-					"SAS_PROTOCOL_SMP protocol\n",
-					__func__);
-
-			} else
-				dev_err(&ihost->pdev->dev,
-					"%s: unknown protocol\n", __func__);
-
-			/* use the task status set in the task struct by the
-			 * isci_request_process_response_iu call.
-			 */
-			set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
-			response = task->task_status.resp;
-			status = task->task_status.stat;
-			break;
-
-		case SCI_IO_SUCCESS:
-		case SCI_IO_SUCCESS_IO_DONE_EARLY:
-
-			response = SAS_TASK_COMPLETE;
-			status   = SAM_STAT_GOOD;
-			set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
-
-			if (completion_status == SCI_IO_SUCCESS_IO_DONE_EARLY) {
-
-				/* This was an SSP / STP / SATA transfer.
-				 * There is a possibility that less data than
-				 * the maximum was transferred.
-				 */
-				u32 transferred_length = sci_req_tx_bytes(request);
-
-				task->task_status.residual
-					= task->total_xfer_len - transferred_length;
+		} else
+			dev_dbg(&ihost->pdev->dev, "%s: SCI_IO_SUCCESS\n",
+				__func__);
+		break;
 
-				/* If there were residual bytes, call this an
-				 * underrun.
-				 */
-				if (task->task_status.residual != 0)
-					status = SAS_DATA_UNDERRUN;
+	case SCI_IO_FAILURE_TERMINATED:
 
-				dev_dbg(&ihost->pdev->dev,
-					"%s: SCI_IO_SUCCESS_IO_DONE_EARLY %d\n",
-					__func__,
-					status);
+		dev_dbg(&ihost->pdev->dev,
+			"%s: SCI_IO_FAILURE_TERMINATED (%p/%p)\n",
+			__func__, request, task);
 
-			} else
-				dev_dbg(&ihost->pdev->dev,
-					"%s: SCI_IO_SUCCESS\n",
-					__func__);
+		/* The request was terminated explicitly. */
+		clear_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
+		response = SAS_TASK_UNDELIVERED;
 
-			break;
+		/* See if the device has been/is being stopped. Note
+		* that we ignore the quiesce state, since we are
+		* concerned about the actual device state.
+		*/
+		if (!idev)
+			status = SAS_DEVICE_UNKNOWN;
+		else
+			status = SAS_ABORTED_TASK;
+		break;
 
-		case SCI_IO_FAILURE_TERMINATED:
-			dev_dbg(&ihost->pdev->dev,
-				"%s: SCI_IO_FAILURE_TERMINATED (%p/%p)\n",
-				__func__,
-				request,
-				task);
+	case SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR:
 
-			/* The request was terminated explicitly.  No handling
-			 * is needed in the SCSI error handler path.
-			 */
-			set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
-			response = SAS_TASK_UNDELIVERED;
+		isci_request_handle_controller_specific_errors(idev, request,
+							       task, &response,
+							       &status);
+		break;
 
-			/* See if the device has been/is being stopped. Note
-			 * that we ignore the quiesce state, since we are
-			 * concerned about the actual device state.
-			 */
-			if (!idev)
-				status = SAS_DEVICE_UNKNOWN;
-			else
-				status = SAS_ABORTED_TASK;
+	case SCI_IO_FAILURE_REMOTE_DEVICE_RESET_REQUIRED:
+		/* This is a special case, in that the I/O completion
+		* is telling us that the device needs a reset.
+		* In order for the device reset condition to be
+		* noticed, the I/O has to be handled in the error
+		* handler.  Set the reset flag and cause the
+		* SCSI error thread to be scheduled.
+		*/
+		spin_lock_irqsave(&task->task_state_lock, task_flags);
+		task->task_state_flags |= SAS_TASK_NEED_DEV_RESET;
+		spin_unlock_irqrestore(&task->task_state_lock, task_flags);
 
-			complete_to_host = isci_perform_normal_io_completion;
-			break;
+		/* Fail the I/O. */
+		response = SAS_TASK_UNDELIVERED;
+		status = SAM_STAT_TASK_ABORTED;
 
-		case SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR:
+		clear_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
+		break;
 
-			isci_request_handle_controller_specific_errors(
-				idev, request, task, &response, &status,
-				&complete_to_host);
+	case SCI_FAILURE_RETRY_REQUIRED:
 
-			break;
+		/* Fail the I/O so it can be retried. */
+		response = SAS_TASK_UNDELIVERED;
+		if (!idev)
+			status = SAS_DEVICE_UNKNOWN;
+		else
+			status = SAS_ABORTED_TASK;
 
-		case SCI_IO_FAILURE_REMOTE_DEVICE_RESET_REQUIRED:
-			/* This is a special case, in that the I/O completion
-			 * is telling us that the device needs a reset.
-			 * In order for the device reset condition to be
-			 * noticed, the I/O has to be handled in the error
-			 * handler.  Set the reset flag and cause the
-			 * SCSI error thread to be scheduled.
-			 */
-			spin_lock_irqsave(&task->task_state_lock, task_flags);
-			task->task_state_flags |= SAS_TASK_NEED_DEV_RESET;
-			spin_unlock_irqrestore(&task->task_state_lock, task_flags);
+		set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
+		break;
 
-			/* Fail the I/O. */
-			response = SAS_TASK_UNDELIVERED;
-			status = SAM_STAT_TASK_ABORTED;
 
-			complete_to_host = isci_perform_error_io_completion;
-			clear_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
-			break;
+	default:
+		/* Catch any otherwise unhandled error codes here. */
+		dev_dbg(&ihost->pdev->dev,
+			"%s: invalid completion code: 0x%x - "
+				"isci_request = %p\n",
+			__func__, completion_status, request);
 
-		case SCI_FAILURE_RETRY_REQUIRED:
+		response = SAS_TASK_UNDELIVERED;
 
-			/* Fail the I/O so it can be retried. */
-			response = SAS_TASK_UNDELIVERED;
-			if (!idev)
-				status = SAS_DEVICE_UNKNOWN;
-			else
-				status = SAS_ABORTED_TASK;
+		/* See if the device has been/is being stopped. Note
+		* that we ignore the quiesce state, since we are
+		* concerned about the actual device state.
+		*/
+		if (!idev)
+			status = SAS_DEVICE_UNKNOWN;
+		else
+			status = SAS_ABORTED_TASK;
 
-			complete_to_host = isci_perform_normal_io_completion;
+		if (SAS_PROTOCOL_SMP == task->task_proto)
 			set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
-			break;
-
-
-		default:
-			/* Catch any otherwise unhandled error codes here. */
-			dev_dbg(&ihost->pdev->dev,
-				 "%s: invalid completion code: 0x%x - "
-				 "isci_request = %p\n",
-				 __func__, completion_status, request);
-
-			response = SAS_TASK_UNDELIVERED;
-
-			/* See if the device has been/is being stopped. Note
-			 * that we ignore the quiesce state, since we are
-			 * concerned about the actual device state.
-			 */
-			if (!idev)
-				status = SAS_DEVICE_UNKNOWN;
-			else
-				status = SAS_ABORTED_TASK;
-
-			if (SAS_PROTOCOL_SMP == task->task_proto) {
-				set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
-				complete_to_host = isci_perform_normal_io_completion;
-			} else {
-				clear_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
-				complete_to_host = isci_perform_error_io_completion;
-			}
-			break;
-		}
+		else
+			clear_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 		break;
 	}
 
@@ -3167,10 +2940,24 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 		break;
 	}
 
-	/* Put the completed request on the correct list */
-	isci_task_save_for_upper_layer_completion(ihost, request, response,
-						  status, complete_to_host
-						  );
+	spin_lock_irqsave(&task->task_state_lock, task_flags);
+
+	task->task_status.resp = response;
+	task->task_status.stat = status;
+
+	if (test_bit(IREQ_COMPLETE_IN_TARGET, &request->flags)) {
+		/* Normal notification (task_done) */
+		task->task_state_flags |= SAS_TASK_STATE_DONE;
+		task->task_state_flags &= ~(SAS_TASK_AT_INITIATOR |
+					    SAS_TASK_STATE_PENDING);
+	}
+	spin_unlock_irqrestore(&task->task_state_lock, task_flags);
+
+	/* Add to the completed list. */
+	list_add(&request->completed_node, &ihost->requests_to_complete);
+
+	/* Take the request off the device's pending request list. */
+	list_del_init(&request->dev_node);
 
 	/* complete the io request to the core. */
 	sci_controller_complete_io(ihost, request->target_device, request);
@@ -3626,7 +3413,6 @@ static struct isci_request *isci_request_from_tag(struct isci_host *ihost, u16 t
 	ireq->num_sg_entries = 0;
 	INIT_LIST_HEAD(&ireq->completed_node);
 	INIT_LIST_HEAD(&ireq->dev_node);
-	isci_request_change_state(ireq, allocated);
 
 	return ireq;
 }
@@ -3721,15 +3507,12 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 	 */
 	list_add(&ireq->dev_node, &idev->reqs_in_process);
 
-	if (status == SCI_SUCCESS) {
-		isci_request_change_state(ireq, started);
-	} else {
+	if (status != SCI_SUCCESS) {
 		/* The request did not really start in the
 		 * hardware, so clear the request handle
 		 * here so no terminations will be done.
 		 */
 		set_bit(IREQ_TERMINATED, &ireq->flags);
-		isci_request_change_state(ireq, completed);
 	}
 	spin_unlock_irqrestore(&ihost->scic_lock, flags);
 

commit 726980d56908f2e230624394f03743689db3110c
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Thu Mar 8 22:41:50 2012 -0800

    isci: Terminate outstanding TCs on TX/RX RNC suspensions.
    
    TCs must only be terminated when RNCs are suspended.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 605dc68cbf79..1f314d0d71d5 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -863,6 +863,8 @@ sci_io_request_terminate(struct isci_request *ireq)
 
 	switch (state) {
 	case SCI_REQ_CONSTRUCTED:
+		/* Set to make sure no HW terminate posting is done: */
+		set_bit(IREQ_TC_ABORT_POSTED, &ireq->flags);
 		ireq->scu_status = SCU_TASK_DONE_TASK_ABORT;
 		ireq->sci_status = SCI_FAILURE_IO_TERMINATED;
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
@@ -883,8 +885,7 @@ sci_io_request_terminate(struct isci_request *ireq)
 	case SCI_REQ_ATAPI_WAIT_PIO_SETUP:
 	case SCI_REQ_ATAPI_WAIT_D2H:
 	case SCI_REQ_ATAPI_WAIT_TC_COMP:
-		sci_change_state(&ireq->sm, SCI_REQ_ABORTING);
-		return SCI_SUCCESS;
+		/* Fall through and change state to ABORTING... */
 	case SCI_REQ_TASK_WAIT_TC_RESP:
 		/* The task frame was already confirmed to have been
 		 * sent by the SCU HW.  Since the state machine is
@@ -893,20 +894,21 @@ sci_io_request_terminate(struct isci_request *ireq)
 		 * and don't wait for the task response.
 		 */
 		sci_change_state(&ireq->sm, SCI_REQ_ABORTING);
-		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
-		return SCI_SUCCESS;
+		/* Fall through and handle like ABORTING... */
 	case SCI_REQ_ABORTING:
-		/* If a request has a termination requested twice, return
-		 * a failure indication, since HW confirmation of the first
-		 * abort is still outstanding.
+		if (!isci_remote_device_is_safe_to_abort(ireq->target_device))
+			set_bit(IREQ_PENDING_ABORT, &ireq->flags);
+		else
+			clear_bit(IREQ_PENDING_ABORT, &ireq->flags);
+		/* If the request is only waiting on the remote device
+		 * suspension, return SUCCESS so the caller will wait too.
 		 */
+		return SCI_SUCCESS;
 	case SCI_REQ_COMPLETED:
 	default:
 		dev_warn(&ireq->owning_controller->pdev->dev,
 			 "%s: SCIC IO Request requested to abort while in wrong "
-			 "state %d\n",
-			 __func__,
-			 ireq->sm.current_state_id);
+			 "state %d\n", __func__, ireq->sm.current_state_id);
 		break;
 	}
 

commit ac78ed0f78eae5c3c918e132b5e2029cdc4fdedc
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Thu Mar 8 22:41:50 2012 -0800

    isci: Handle all suspending TC completions
    
    Add comprehensive decode for all TC completions that generate RNC
    suspensions.
    
    Note that this commit also removes unconditional resumptions of ATAPI
    devices when in the SCI_STP_DEV_ATAPI_ERROR state, and STP devices
    when in the SCI_STP_DEV_IDLE state. This is because the SCI_STP_DEV_IDLE
    and SCI_STP_DEV_ATAPI state entry functions manage the RNC resumption.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index dcd26eadf867..605dc68cbf79 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2116,9 +2116,6 @@ static enum sci_status stp_request_udma_await_tc_event(struct isci_request *ireq
 		 * completion.
 		 */
 		if (ireq->stp.rsp.fis_type == FIS_REGD2H) {
-			sci_remote_device_suspend(ireq->target_device,
-				SCU_EVENT_SPECIFIC(SCU_NORMALIZE_COMPLETION_STATUS(completion_code)));
-
 			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
 			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
 			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
@@ -2138,13 +2135,6 @@ static enum sci_status stp_request_udma_await_tc_event(struct isci_request *ireq
 	/* TODO We can retry the command for SCU_TASK_DONE_CMD_LL_R_ERR
 	 * - this comes only for B0
 	 */
-	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_INV_FIS_LEN):
-	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_MAX_PLD_ERR):
-	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_LL_R_ERR):
-	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_CMD_LL_R_ERR):
-		sci_remote_device_suspend(ireq->target_device,
-			SCU_EVENT_SPECIFIC(SCU_NORMALIZE_COMPLETION_STATUS(completion_code)));
-		/* Fall through to the default case */
 	default:
 		/* All other completion status cause the IO to be complete. */
 		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
@@ -2262,15 +2252,152 @@ static enum sci_status atapi_data_tc_completion_handler(struct isci_request *ire
 	return status;
 }
 
+static int sci_request_smp_completion_status_is_tx_suspend(
+	unsigned int completion_status)
+{
+	switch (completion_status) {
+	case SCU_TASK_OPEN_REJECT_WRONG_DESTINATION:
+	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_1:
+	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_2:
+	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_3:
+	case SCU_TASK_OPEN_REJECT_BAD_DESTINATION:
+	case SCU_TASK_OPEN_REJECT_ZONE_VIOLATION:
+		return 1;
+	}
+	return 0;
+}
+
+static int sci_request_smp_completion_status_is_tx_rx_suspend(
+	unsigned int completion_status)
+{
+	return 0; /* There are no Tx/Rx SMP suspend conditions. */
+}
+
+static int sci_request_ssp_completion_status_is_tx_suspend(
+	unsigned int completion_status)
+{
+	switch (completion_status) {
+	case SCU_TASK_DONE_TX_RAW_CMD_ERR:
+	case SCU_TASK_DONE_LF_ERR:
+	case SCU_TASK_OPEN_REJECT_WRONG_DESTINATION:
+	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_1:
+	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_2:
+	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_3:
+	case SCU_TASK_OPEN_REJECT_BAD_DESTINATION:
+	case SCU_TASK_OPEN_REJECT_ZONE_VIOLATION:
+	case SCU_TASK_OPEN_REJECT_STP_RESOURCES_BUSY:
+	case SCU_TASK_OPEN_REJECT_PROTOCOL_NOT_SUPPORTED:
+	case SCU_TASK_OPEN_REJECT_CONNECTION_RATE_NOT_SUPPORTED:
+		return 1;
+	}
+	return 0;
+}
+
+static int sci_request_ssp_completion_status_is_tx_rx_suspend(
+	unsigned int completion_status)
+{
+	return 0; /* There are no Tx/Rx SSP suspend conditions. */
+}
+
+static int sci_request_stpsata_completion_status_is_tx_suspend(
+	unsigned int completion_status)
+{
+	switch (completion_status) {
+	case SCU_TASK_DONE_TX_RAW_CMD_ERR:
+	case SCU_TASK_DONE_LL_R_ERR:
+	case SCU_TASK_DONE_LL_PERR:
+	case SCU_TASK_DONE_REG_ERR:
+	case SCU_TASK_DONE_SDB_ERR:
+	case SCU_TASK_OPEN_REJECT_WRONG_DESTINATION:
+	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_1:
+	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_2:
+	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_3:
+	case SCU_TASK_OPEN_REJECT_BAD_DESTINATION:
+	case SCU_TASK_OPEN_REJECT_ZONE_VIOLATION:
+	case SCU_TASK_OPEN_REJECT_STP_RESOURCES_BUSY:
+	case SCU_TASK_OPEN_REJECT_PROTOCOL_NOT_SUPPORTED:
+	case SCU_TASK_OPEN_REJECT_CONNECTION_RATE_NOT_SUPPORTED:
+		return 1;
+	}
+	return 0;
+}
+
+
+static int sci_request_stpsata_completion_status_is_tx_rx_suspend(
+	unsigned int completion_status)
+{
+	switch (completion_status) {
+	case SCU_TASK_DONE_LF_ERR:
+	case SCU_TASK_DONE_LL_SY_TERM:
+	case SCU_TASK_DONE_LL_LF_TERM:
+	case SCU_TASK_DONE_BREAK_RCVD:
+	case SCU_TASK_DONE_INV_FIS_LEN:
+	case SCU_TASK_DONE_UNEXP_FIS:
+	case SCU_TASK_DONE_UNEXP_SDBFIS:
+	case SCU_TASK_DONE_MAX_PLD_ERR:
+		return 1;
+	}
+	return 0;
+}
+
+static void sci_request_handle_suspending_completions(
+	struct isci_request *ireq,
+	u32 completion_code)
+{
+	int is_tx = 0;
+	int is_tx_rx = 0;
+
+	switch (ireq->protocol) {
+	case SAS_PROTOCOL_SMP:
+		is_tx = sci_request_smp_completion_status_is_tx_suspend(
+			completion_code);
+		is_tx_rx = sci_request_smp_completion_status_is_tx_rx_suspend(
+			completion_code);
+		break;
+	case SAS_PROTOCOL_SSP:
+		is_tx = sci_request_ssp_completion_status_is_tx_suspend(
+			completion_code);
+		is_tx_rx = sci_request_ssp_completion_status_is_tx_rx_suspend(
+			completion_code);
+		break;
+	case SAS_PROTOCOL_STP:
+		is_tx = sci_request_stpsata_completion_status_is_tx_suspend(
+			completion_code);
+		is_tx_rx =
+			sci_request_stpsata_completion_status_is_tx_rx_suspend(
+				completion_code);
+		break;
+	default:
+		dev_warn(&ireq->isci_host->pdev->dev,
+			 "%s: request %p has no valid protocol\n",
+			 __func__, ireq);
+		break;
+	}
+	if (is_tx || is_tx_rx) {
+		BUG_ON(is_tx && is_tx_rx);
+
+		sci_remote_node_context_suspend(
+			&ireq->target_device->rnc,
+			SCU_HARDWARE_SUSPENSION,
+			(is_tx_rx) ? SCU_EVENT_TL_RNC_SUSPEND_TX_RX
+				   : SCU_EVENT_TL_RNC_SUSPEND_TX,
+			NULL, NULL);
+	}
+}
+
 enum sci_status
 sci_io_request_tc_completion(struct isci_request *ireq,
-				  u32 completion_code)
+			     u32 completion_code)
 {
 	enum sci_base_request_states state;
 	struct isci_host *ihost = ireq->owning_controller;
 
 	state = ireq->sm.current_state_id;
 
+	/* Decode those completions that signal upcoming suspension events. */
+	sci_request_handle_suspending_completions(
+		ireq, SCU_GET_COMPLETION_TL_STATUS(completion_code));
+
 	switch (state) {
 	case SCI_REQ_STARTED:
 		return request_started_state_tc_event(ireq, completion_code);

commit abec912d71c44bbd642ce12ad98aab76f5a53163
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed Feb 15 13:58:42 2012 -0800

    isci: refactor initialization for S3/S4
    
    Based on an original implementation by Ed Nadolski and Artur Wojcik
    
    In preparation for S3/S4 support refactor initialization so that
    driver-load and resume-from-suspend can share the common init path of
    isci_host_init().  Organize the initialization into objects that are
    self-contained to the driver (initialized by isci_host_init) versus
    those that have some upward registration (initialized at allocation time
    asd_sas_phy, asd_sas_port, dma allocations).  The largest change is
    moving the the validation of the oem and module parameters from
    isci_host_init() to isci_host_alloc().
    
    The S3/S4 approach being taken is that libsas will be tasked with
    remembering the state of the domain and the lldd is free to be
    forgetful.  In the case of isci we'll just re-init using a subset of the
    normal driver load path.
    
    [clean up some unused / mis-indented function definitions in host.h]
    
    Signed-off-by: Ed Nadolski <edmund.nadolski@intel.com>
    Signed-off-by: Artur Wojcik <artur.wojcik@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 835ede848871..dcd26eadf867 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -92,11 +92,11 @@ static dma_addr_t to_sgl_element_pair_dma(struct isci_host *ihost,
 	if (idx == 0) {
 		offset = (void *) &ireq->tc->sgl_pair_ab -
 			 (void *) &ihost->task_context_table[0];
-		return ihost->task_context_dma + offset;
+		return ihost->tc_dma + offset;
 	} else if (idx == 1) {
 		offset = (void *) &ireq->tc->sgl_pair_cd -
 			 (void *) &ihost->task_context_table[0];
-		return ihost->task_context_dma + offset;
+		return ihost->tc_dma + offset;
 	}
 
 	return sci_io_request_get_dma_addr(ireq, &ireq->sg_table[idx - 2]);

commit c79dd80d73017a88a2c2ae46e7d5303cba6a32e0
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed Feb 1 00:44:14 2012 -0800

    isci: kill sci_phy_protocol and sci_request_protocol
    
    Holdovers from the initial driver cleanup, replace with enum sas_protocol.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 01844ef19656..835ede848871 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -730,7 +730,7 @@ static enum sci_status sci_io_request_construct_basic_ssp(struct isci_request *i
 {
 	struct sas_task *task = isci_request_access_task(ireq);
 
-	ireq->protocol = SCIC_SSP_PROTOCOL;
+	ireq->protocol = SAS_PROTOCOL_SSP;
 
 	scu_ssp_io_request_construct_task_context(ireq,
 						  task->data_dir,
@@ -763,7 +763,7 @@ static enum sci_status sci_io_request_construct_basic_sata(struct isci_request *
 	bool copy = false;
 	struct sas_task *task = isci_request_access_task(ireq);
 
-	ireq->protocol = SCIC_STP_PROTOCOL;
+	ireq->protocol = SAS_PROTOCOL_STP;
 
 	copy = (task->data_dir == DMA_NONE) ? false : true;
 
@@ -1070,7 +1070,7 @@ request_started_state_tc_event(struct isci_request *ireq,
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_UNEXP_SDBFIS):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_REG_ERR):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SDB_ERR):
-		if (ireq->protocol == SCIC_STP_PROTOCOL) {
+		if (ireq->protocol == SAS_PROTOCOL_STP) {
 			ireq->scu_status = SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
 					   SCU_COMPLETION_TL_STATUS_SHIFT;
 			ireq->sci_status = SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED;
@@ -3169,7 +3169,7 @@ sci_general_request_construct(struct isci_host *ihost,
 	sci_init_sm(&ireq->sm, sci_request_state_table, SCI_REQ_INIT);
 
 	ireq->target_device = idev;
-	ireq->protocol = SCIC_NO_PROTOCOL;
+	ireq->protocol = SAS_PROTOCOL_NONE;
 	ireq->saved_rx_frame_index = SCU_INVALID_FRAME_INDEX;
 
 	ireq->sci_status   = SCI_SUCCESS;
@@ -3310,7 +3310,7 @@ sci_io_request_construct_smp(struct device *dev,
 	if (!dma_map_sg(dev, sg, 1, DMA_TO_DEVICE))
 		return SCI_FAILURE;
 
-	ireq->protocol = SCIC_SMP_PROTOCOL;
+	ireq->protocol = SAS_PROTOCOL_SMP;
 
 	/* byte swap the smp request. */
 

commit 11cc51835af0e6fbb2da9cb012bdaaa036497b7f
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed Feb 1 00:23:10 2012 -0800

    isci: kill ->is_direct_attached
    
    domain_device ->parent conveys the same information.
    
    Occurrences of ->is_direct_attached appear next to incomplete open-coded
    versions of dev_is_sata(), clean those up as well.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 2def1e3960f6..01844ef19656 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -3193,7 +3193,7 @@ sci_io_request_construct(struct isci_host *ihost,
 
 	if (dev->dev_type == SAS_END_DEV)
 		/* pass */;
-	else if (dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP))
+	else if (dev_is_sata(dev))
 		memset(&ireq->stp.cmd, 0, sizeof(ireq->stp.cmd));
 	else if (dev_is_expander(dev))
 		/* pass */;
@@ -3215,8 +3215,7 @@ enum sci_status sci_task_request_construct(struct isci_host *ihost,
 	/* Build the common part of the request */
 	sci_general_request_construct(ihost, idev, ireq);
 
-	if (dev->dev_type == SAS_END_DEV ||
-	    dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP)) {
+	if (dev->dev_type == SAS_END_DEV || dev_is_sata(dev)) {
 		set_bit(IREQ_TMF, &ireq->flags);
 		memset(ireq->tc, 0, sizeof(struct scu_task_context));
 	} else

commit 424a6f6ef990b7e9f56f6627bfc6c46b493faeb4
Merge: 1ab142d49929 cd8df932d894
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 22 12:55:29 2012 -0700

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6
    
    SCSI updates from James Bottomley:
     "The update includes the usual assortment of driver updates (lpfc,
      qla2xxx, qla4xxx, bfa, bnx2fc, bnx2i, isci, fcoe, hpsa) plus a huge
      amount of infrastructure work in the SAS library and transport class
      as well as an iSCSI update.  There's also a new SCSI based virtio
      driver."
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6: (177 commits)
      [SCSI] qla4xxx: Update driver version to 5.02.00-k15
      [SCSI] qla4xxx: trivial cleanup
      [SCSI] qla4xxx: Fix sparse warning
      [SCSI] qla4xxx: Add support for multiple session per host.
      [SCSI] qla4xxx: Export CHAP index as sysfs attribute
      [SCSI] scsi_transport: Export CHAP index as sysfs attribute
      [SCSI] qla4xxx: Add support to display CHAP list and delete CHAP entry
      [SCSI] iscsi_transport: Add support to display CHAP list and delete CHAP entry
      [SCSI] pm8001: fix endian issue with code optimization.
      [SCSI] pm8001: Fix possible racing condition.
      [SCSI] pm8001: Fix bogus interrupt state flag issue.
      [SCSI] ipr: update PCI ID definitions for new adapters
      [SCSI] qla2xxx: handle default case in qla2x00_request_firmware()
      [SCSI] isci: improvements in driver unloading routine
      [SCSI] isci: improve phy event warnings
      [SCSI] isci: debug, provide state-enum-to-string conversions
      [SCSI] scsi_transport_sas: 'enable' phys on reset
      [SCSI] libsas: don't recover end devices attached to disabled phys
      [SCSI] libsas: fixup target_port_protocols for expanders that don't report sata
      [SCSI] libsas: set attached device type and target protocols for local phys
      ...

commit 77dfce076cbd76c04e90abff188d058cdbff78dd
Author: Cong Wang <amwang@redhat.com>
Date:   Fri Nov 25 23:14:23 2011 +0800

    scsi: remove the second argument of k[un]map_atomic()
    
    Signed-off-by: Cong Wang <amwang@redhat.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 192cb48d849a..ee0dc05c6269 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -1304,9 +1304,9 @@ sci_stp_request_pio_data_in_copy_data_buffer(struct isci_stp_request *stp_req,
 			struct page *page = sg_page(sg);
 
 			copy_len = min_t(int, total_len, sg_dma_len(sg));
-			kaddr = kmap_atomic(page, KM_IRQ0);
+			kaddr = kmap_atomic(page);
 			memcpy(kaddr + sg->offset, src_addr, copy_len);
-			kunmap_atomic(kaddr, KM_IRQ0);
+			kunmap_atomic(kaddr);
 			total_len -= copy_len;
 			src_addr += copy_len;
 			sg = sg_next(sg);
@@ -1654,7 +1654,7 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 		sci_unsolicited_frame_control_get_header(&ihost->uf_control,
 							 frame_index,
 							 &frame_header);
-		kaddr = kmap_atomic(sg_page(sg), KM_IRQ0);
+		kaddr = kmap_atomic(sg_page(sg));
 		rsp = kaddr + sg->offset;
 		sci_swab32_cpy(rsp, frame_header, 1);
 
@@ -1691,7 +1691,7 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 			ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
 			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		}
-		kunmap_atomic(kaddr, KM_IRQ0);
+		kunmap_atomic(kaddr);
 
 		sci_controller_release_frame(ihost, frame_index);
 
@@ -3023,10 +3023,10 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 		dma_unmap_sg(&ihost->pdev->dev, sg, 1, DMA_TO_DEVICE);
 
 		/* need to swab it back in case the command buffer is re-used */
-		kaddr = kmap_atomic(sg_page(sg), KM_IRQ0);
+		kaddr = kmap_atomic(sg_page(sg));
 		smp_req = kaddr + sg->offset;
 		sci_swab32_cpy(smp_req, smp_req, sg->length / sizeof(u32));
-		kunmap_atomic(kaddr, KM_IRQ0);
+		kunmap_atomic(kaddr);
 		break;
 	}
 	default:
@@ -3311,7 +3311,7 @@ sci_io_request_construct_smp(struct device *dev,
 	u8 req_len;
 	u32 cmd;
 
-	kaddr = kmap_atomic(sg_page(sg), KM_IRQ0);
+	kaddr = kmap_atomic(sg_page(sg));
 	smp_req = kaddr + sg->offset;
 	/*
 	 * Look at the SMP requests' header fields; for certain SAS 1.x SMP
@@ -3337,7 +3337,7 @@ sci_io_request_construct_smp(struct device *dev,
 	req_len = smp_req->req_len;
 	sci_swab32_cpy(smp_req, smp_req, sg->length / sizeof(u32));
 	cmd = *(u32 *) smp_req;
-	kunmap_atomic(kaddr, KM_IRQ0);
+	kunmap_atomic(kaddr);
 
 	if (!dma_map_sg(dev, sg, 1, DMA_TO_DEVICE))
 		return SCI_FAILURE;

commit d7a0ccdd9bd78b5b74d2963ec7ab67c9d896902a
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Feb 10 01:18:44 2012 -0800

    [SCSI] isci: debug, provide state-enum-to-string conversions
    
    Debugging the driver requires tracing the state transtions and tracing
    state names is less work than decoding numbers.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 1a39ce50529d..ab18ee0fe246 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -61,6 +61,16 @@
 #include "scu_event_codes.h"
 #include "sas.h"
 
+#undef C
+#define C(a) (#a)
+const char *req_state_name(enum sci_base_request_states state)
+{
+	static const char * const strings[] = REQUEST_STATES;
+
+	return strings[state];
+}
+#undef C
+
 static struct scu_sgl_element_pair *to_sgl_element_pair(struct isci_request *ireq,
 							int idx)
 {
@@ -910,7 +920,8 @@ enum sci_status sci_request_complete(struct isci_request *ireq)
 
 	state = ireq->sm.current_state_id;
 	if (WARN_ONCE(state != SCI_REQ_COMPLETED,
-		      "isci: request completion from wrong state (%d)\n", state))
+		      "isci: request completion from wrong state (%s)\n",
+		      req_state_name(state)))
 		return SCI_FAILURE_INVALID_STATE;
 
 	if (ireq->saved_rx_frame_index != SCU_INVALID_FRAME_INDEX)
@@ -931,8 +942,8 @@ enum sci_status sci_io_request_event_handler(struct isci_request *ireq,
 	state = ireq->sm.current_state_id;
 
 	if (state != SCI_REQ_STP_PIO_DATA_IN) {
-		dev_warn(&ihost->pdev->dev, "%s: (%x) in wrong state %d\n",
-			 __func__, event_code, state);
+		dev_warn(&ihost->pdev->dev, "%s: (%x) in wrong state %s\n",
+			 __func__, event_code, req_state_name(state));
 
 		return SCI_FAILURE_INVALID_STATE;
 	}
@@ -2306,12 +2317,8 @@ sci_io_request_tc_completion(struct isci_request *ireq,
 		return atapi_data_tc_completion_handler(ireq, completion_code);
 
 	default:
-		dev_warn(&ihost->pdev->dev,
-			 "%s: SCIC IO Request given task completion "
-			 "notification %x while in wrong state %d\n",
-			 __func__,
-			 completion_code,
-			 state);
+		dev_warn(&ihost->pdev->dev, "%s: %x in wrong state %s\n",
+			 __func__, completion_code, req_state_name(state));
 		return SCI_FAILURE_INVALID_STATE;
 	}
 }

commit 43a5ab151f0268459c4368292c2ddb2266b8f243
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Dec 8 23:20:44 2011 -0800

    [SCSI] isci: stop interpreting ->lldd_lu_reset() as an ata soft-reset
    
    Driving resets from libsas-eh is pre-mature as libata will make a
    decision about performing a softreset.  Currently libata determines
    whether to perform a softreset based on ata_eh_followup_srst_needed(),
    and none of those conditions apply to isci.
    
    Remove the srst implementation and translate ->lldd_lu_reset() for ata
    devices as a request to drive a reset via libata-eh.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 788daeedc89f..1a39ce50529d 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -666,18 +666,12 @@ sci_io_request_construct_sata(struct isci_request *ireq,
 	if (test_bit(IREQ_TMF, &ireq->flags)) {
 		struct isci_tmf *tmf = isci_request_access_tmf(ireq);
 
-		if (tmf->tmf_code == isci_tmf_sata_srst_high ||
-		    tmf->tmf_code == isci_tmf_sata_srst_low) {
-			scu_stp_raw_request_construct_task_context(ireq);
-			return SCI_SUCCESS;
-		} else {
-			dev_err(&ireq->owning_controller->pdev->dev,
-				"%s: Request 0x%p received un-handled SAT "
-				"management protocol 0x%x.\n",
-				__func__, ireq, tmf->tmf_code);
+		dev_err(&ireq->owning_controller->pdev->dev,
+			"%s: Request 0x%p received un-handled SAT "
+			"management protocol 0x%x.\n",
+			__func__, ireq, tmf->tmf_code);
 
-			return SCI_FAILURE;
-		}
+		return SCI_FAILURE;
 	}
 
 	if (!sas_protocol_ata(task->task_proto)) {
@@ -774,34 +768,6 @@ static enum sci_status sci_io_request_construct_basic_sata(struct isci_request *
 	return status;
 }
 
-enum sci_status sci_task_request_construct_sata(struct isci_request *ireq)
-{
-	enum sci_status status = SCI_SUCCESS;
-
-	/* check for management protocols */
-	if (test_bit(IREQ_TMF, &ireq->flags)) {
-		struct isci_tmf *tmf = isci_request_access_tmf(ireq);
-
-		if (tmf->tmf_code == isci_tmf_sata_srst_high ||
-		    tmf->tmf_code == isci_tmf_sata_srst_low) {
-			scu_stp_raw_request_construct_task_context(ireq);
-		} else {
-			dev_err(&ireq->owning_controller->pdev->dev,
-				"%s: Request 0x%p received un-handled SAT "
-				"Protocol 0x%x.\n",
-				__func__, ireq, tmf->tmf_code);
-
-			return SCI_FAILURE;
-		}
-	}
-
-	if (status != SCI_SUCCESS)
-		return status;
-	sci_change_state(&ireq->sm, SCI_REQ_CONSTRUCTED);
-
-	return status;
-}
-
 /**
  * sci_req_tx_bytes - bytes transferred when reply underruns request
  * @ireq: request that was terminated early
@@ -903,9 +869,6 @@ sci_io_request_terminate(struct isci_request *ireq)
 	case SCI_REQ_STP_PIO_WAIT_FRAME:
 	case SCI_REQ_STP_PIO_DATA_IN:
 	case SCI_REQ_STP_PIO_DATA_OUT:
-	case SCI_REQ_STP_SOFT_RESET_WAIT_H2D_ASSERTED:
-	case SCI_REQ_STP_SOFT_RESET_WAIT_H2D_DIAG:
-	case SCI_REQ_STP_SOFT_RESET_WAIT_D2H:
 	case SCI_REQ_ATAPI_WAIT_H2D:
 	case SCI_REQ_ATAPI_WAIT_PIO_SETUP:
 	case SCI_REQ_ATAPI_WAIT_D2H:
@@ -2085,59 +2048,6 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 		return status;
 	}
 
-	case SCI_REQ_STP_SOFT_RESET_WAIT_D2H: {
-		struct dev_to_host_fis *frame_header;
-		u32 *frame_buffer;
-
-		status = sci_unsolicited_frame_control_get_header(&ihost->uf_control,
-								       frame_index,
-								       (void **)&frame_header);
-		if (status != SCI_SUCCESS) {
-			dev_err(&ihost->pdev->dev,
-				"%s: SCIC IO Request 0x%p could not get frame "
-				"header for frame index %d, status %x\n",
-				__func__,
-				stp_req,
-				frame_index,
-				status);
-			return status;
-		}
-
-		switch (frame_header->fis_type) {
-		case FIS_REGD2H:
-			sci_unsolicited_frame_control_get_buffer(&ihost->uf_control,
-								      frame_index,
-								      (void **)&frame_buffer);
-
-			sci_controller_copy_sata_response(&ireq->stp.rsp,
-							       frame_header,
-							       frame_buffer);
-
-			/* The command has completed with error */
-			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
-			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
-			break;
-
-		default:
-			dev_warn(&ihost->pdev->dev,
-				 "%s: IO Request:0x%p Frame Id:%d protocol "
-				 "violation occurred\n",
-				 __func__,
-				 stp_req,
-				 frame_index);
-
-			ireq->scu_status = SCU_TASK_DONE_UNEXP_FIS;
-			ireq->sci_status = SCI_FAILURE_PROTOCOL_VIOLATION;
-			break;
-		}
-
-		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
-
-		/* Frame has been decoded return it to the controller */
-		sci_controller_release_frame(ihost, frame_index);
-
-		return status;
-	}
 	case SCI_REQ_ATAPI_WAIT_PIO_SETUP: {
 		struct sas_task *task = isci_request_access_task(ireq);
 
@@ -2235,57 +2145,6 @@ static enum sci_status stp_request_udma_await_tc_event(struct isci_request *ireq
 	return status;
 }
 
-static enum sci_status
-stp_request_soft_reset_await_h2d_asserted_tc_event(struct isci_request *ireq,
-						   u32 completion_code)
-{
-	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
-	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		ireq->scu_status = SCU_TASK_DONE_GOOD;
-		ireq->sci_status = SCI_SUCCESS;
-		sci_change_state(&ireq->sm, SCI_REQ_STP_SOFT_RESET_WAIT_H2D_DIAG);
-		break;
-
-	default:
-		/*
-		 * All other completion status cause the IO to be complete.
-		 * If a NAK was received, then it is up to the user to retry
-		 * the request.
-		 */
-		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
-		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
-		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
-		break;
-	}
-
-	return SCI_SUCCESS;
-}
-
-static enum sci_status
-stp_request_soft_reset_await_h2d_diagnostic_tc_event(struct isci_request *ireq,
-						     u32 completion_code)
-{
-	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
-	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		ireq->scu_status = SCU_TASK_DONE_GOOD;
-		ireq->sci_status = SCI_SUCCESS;
-		sci_change_state(&ireq->sm, SCI_REQ_STP_SOFT_RESET_WAIT_D2H);
-		break;
-
-	default:
-		/* All other completion status cause the IO to be complete.  If
-		 * a NAK was received, then it is up to the user to retry the
-		 * request.
-		 */
-		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
-		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
-		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
-		break;
-	}
-
-	return SCI_SUCCESS;
-}
-
 static enum sci_status atapi_raw_completion(struct isci_request *ireq, u32 completion_code,
 						  enum sci_base_request_states next)
 {
@@ -2431,14 +2290,6 @@ sci_io_request_tc_completion(struct isci_request *ireq,
 	case SCI_REQ_STP_PIO_DATA_OUT:
 		return pio_data_out_tx_done_tc_event(ireq, completion_code);
 
-	case SCI_REQ_STP_SOFT_RESET_WAIT_H2D_ASSERTED:
-		return stp_request_soft_reset_await_h2d_asserted_tc_event(ireq,
-									  completion_code);
-
-	case SCI_REQ_STP_SOFT_RESET_WAIT_H2D_DIAG:
-		return stp_request_soft_reset_await_h2d_diagnostic_tc_event(ireq,
-									    completion_code);
-
 	case SCI_REQ_ABORTING:
 		return request_aborting_state_tc_event(ireq,
 						       completion_code);
@@ -3212,10 +3063,6 @@ static void sci_request_started_state_enter(struct sci_base_state_machine *sm)
 	 */
 	if (!task && dev->dev_type == SAS_END_DEV) {
 		state = SCI_REQ_TASK_WAIT_TC_COMP;
-	} else if (!task &&
-		   (isci_request_access_tmf(ireq)->tmf_code == isci_tmf_sata_srst_high ||
-		    isci_request_access_tmf(ireq)->tmf_code == isci_tmf_sata_srst_low)) {
-		state = SCI_REQ_STP_SOFT_RESET_WAIT_H2D_ASSERTED;
 	} else if (task && task->task_proto == SAS_PROTOCOL_SMP) {
 		state = SCI_REQ_SMP_WAIT_RESP;
 	} else if (task && sas_protocol_ata(task->task_proto) &&
@@ -3272,31 +3119,6 @@ static void sci_stp_request_started_pio_await_h2d_completion_enter(struct sci_ba
 	ireq->target_device->working_request = ireq;
 }
 
-static void sci_stp_request_started_soft_reset_await_h2d_asserted_completion_enter(struct sci_base_state_machine *sm)
-{
-	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
-
-	ireq->target_device->working_request = ireq;
-}
-
-static void sci_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter(struct sci_base_state_machine *sm)
-{
-	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
-	struct scu_task_context *tc = ireq->tc;
-	struct host_to_dev_fis *h2d_fis;
-	enum sci_status status;
-
-	/* Clear the SRST bit */
-	h2d_fis = &ireq->stp.cmd;
-	h2d_fis->control = 0;
-
-	/* Clear the TC control bit */
-	tc->control_frame = 0;
-
-	status = sci_controller_continue_io(ireq);
-	WARN_ONCE(status != SCI_SUCCESS, "isci: continue io failure\n");
-}
-
 static const struct sci_base_state sci_request_state_table[] = {
 	[SCI_REQ_INIT] = { },
 	[SCI_REQ_CONSTRUCTED] = { },
@@ -3315,13 +3137,6 @@ static const struct sci_base_state sci_request_state_table[] = {
 	[SCI_REQ_STP_PIO_DATA_OUT] = { },
 	[SCI_REQ_STP_UDMA_WAIT_TC_COMP] = { },
 	[SCI_REQ_STP_UDMA_WAIT_D2H] = { },
-	[SCI_REQ_STP_SOFT_RESET_WAIT_H2D_ASSERTED] = {
-		.enter_state = sci_stp_request_started_soft_reset_await_h2d_asserted_completion_enter,
-	},
-	[SCI_REQ_STP_SOFT_RESET_WAIT_H2D_DIAG] = {
-		.enter_state = sci_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter,
-	},
-	[SCI_REQ_STP_SOFT_RESET_WAIT_D2H] = { },
 	[SCI_REQ_TASK_WAIT_TC_COMP] = { },
 	[SCI_REQ_TASK_WAIT_TC_RESP] = { },
 	[SCI_REQ_SMP_WAIT_RESP] = { },

commit 312d3e56119a4bc5c36a96818f87f650c069ddc2
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Nov 17 17:59:50 2011 -0800

    [SCSI] libsas: remove ata_port.lock management duties from lldds
    
    Each libsas driver (mvsas, pm8001, and isci) has invented a different
    method for managing the ap->lock.  The lock is held by the ata
    ->queuecommand() path.  mvsas drops it prior to acquiring any internal
    locks which allows it to hold its internal lock across calls to
    task->task_done().  This capability is important as it is the only way
    the driver can flush task->task_done() instances to guarantee that it no
    longer has any in-flight references to a domain_device at
    ->lldd_dev_gone() time.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 751368b46b44..788daeedc89f 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -3796,8 +3796,7 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 		/* Cause this task to be scheduled in the SCSI error
 		 * handler thread.
 		 */
-		isci_execpath_callback(ihost, task,
-				       sas_task_abort);
+		sas_task_abort(task);
 
 		/* Change the status, since we are holding
 		 * the I/O until it is managed by the SCSI

commit 3d2d752549150c2706f6bf8d8a2cceb89ef9f42e
Author: Dave Jiang <dave.jiang@intel.com>
Date:   Fri Feb 10 01:18:34 2012 -0800

    [SCSI] isci: T10 DIF support
    
    This allows the controller to do WRITE_INSERT and READ_STRIP for SAS
    disks that support protection information. SAS disks must be formatted
    with protection information to use this feature via sg_format.
    
      sg3_utils-1.32 -- sg_format version 1.19 20110730
      sg_format usage:
      sg_format --format --verbose --pinfo /dev/sda
    
    Acked-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 192cb48d849a..751368b46b44 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -53,6 +53,7 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
+#include <scsi/scsi_cmnd.h>
 #include "isci.h"
 #include "task.h"
 #include "request.h"
@@ -264,6 +265,141 @@ static void scu_ssp_reqeust_construct_task_context(
 	task_context->response_iu_lower = lower_32_bits(dma_addr);
 }
 
+static u8 scu_bg_blk_size(struct scsi_device *sdp)
+{
+	switch (sdp->sector_size) {
+	case 512:
+		return 0;
+	case 1024:
+		return 1;
+	case 4096:
+		return 3;
+	default:
+		return 0xff;
+	}
+}
+
+static u32 scu_dif_bytes(u32 len, u32 sector_size)
+{
+	return (len >> ilog2(sector_size)) * 8;
+}
+
+static void scu_ssp_ireq_dif_insert(struct isci_request *ireq, u8 type, u8 op)
+{
+	struct scu_task_context *tc = ireq->tc;
+	struct scsi_cmnd *scmd = ireq->ttype_ptr.io_task_ptr->uldd_task;
+	u8 blk_sz = scu_bg_blk_size(scmd->device);
+
+	tc->block_guard_enable = 1;
+	tc->blk_prot_en = 1;
+	tc->blk_sz = blk_sz;
+	/* DIF write insert */
+	tc->blk_prot_func = 0x2;
+
+	tc->transfer_length_bytes += scu_dif_bytes(tc->transfer_length_bytes,
+						   scmd->device->sector_size);
+
+	/* always init to 0, used by hw */
+	tc->interm_crc_val = 0;
+
+	tc->init_crc_seed = 0;
+	tc->app_tag_verify = 0;
+	tc->app_tag_gen = 0;
+	tc->ref_tag_seed_verify = 0;
+
+	/* always init to same as bg_blk_sz */
+	tc->UD_bytes_immed_val = scmd->device->sector_size;
+
+	tc->reserved_DC_0 = 0;
+
+	/* always init to 8 */
+	tc->DIF_bytes_immed_val = 8;
+
+	tc->reserved_DC_1 = 0;
+	tc->bgc_blk_sz = scmd->device->sector_size;
+	tc->reserved_E0_0 = 0;
+	tc->app_tag_gen_mask = 0;
+
+	/** setup block guard control **/
+	tc->bgctl = 0;
+
+	/* DIF write insert */
+	tc->bgctl_f.op = 0x2;
+
+	tc->app_tag_verify_mask = 0;
+
+	/* must init to 0 for hw */
+	tc->blk_guard_err = 0;
+
+	tc->reserved_E8_0 = 0;
+
+	if ((type & SCSI_PROT_DIF_TYPE1) || (type & SCSI_PROT_DIF_TYPE2))
+		tc->ref_tag_seed_gen = scsi_get_lba(scmd) & 0xffffffff;
+	else if (type & SCSI_PROT_DIF_TYPE3)
+		tc->ref_tag_seed_gen = 0;
+}
+
+static void scu_ssp_ireq_dif_strip(struct isci_request *ireq, u8 type, u8 op)
+{
+	struct scu_task_context *tc = ireq->tc;
+	struct scsi_cmnd *scmd = ireq->ttype_ptr.io_task_ptr->uldd_task;
+	u8 blk_sz = scu_bg_blk_size(scmd->device);
+
+	tc->block_guard_enable = 1;
+	tc->blk_prot_en = 1;
+	tc->blk_sz = blk_sz;
+	/* DIF read strip */
+	tc->blk_prot_func = 0x1;
+
+	tc->transfer_length_bytes += scu_dif_bytes(tc->transfer_length_bytes,
+						   scmd->device->sector_size);
+
+	/* always init to 0, used by hw */
+	tc->interm_crc_val = 0;
+
+	tc->init_crc_seed = 0;
+	tc->app_tag_verify = 0;
+	tc->app_tag_gen = 0;
+
+	if ((type & SCSI_PROT_DIF_TYPE1) || (type & SCSI_PROT_DIF_TYPE2))
+		tc->ref_tag_seed_verify = scsi_get_lba(scmd) & 0xffffffff;
+	else if (type & SCSI_PROT_DIF_TYPE3)
+		tc->ref_tag_seed_verify = 0;
+
+	/* always init to same as bg_blk_sz */
+	tc->UD_bytes_immed_val = scmd->device->sector_size;
+
+	tc->reserved_DC_0 = 0;
+
+	/* always init to 8 */
+	tc->DIF_bytes_immed_val = 8;
+
+	tc->reserved_DC_1 = 0;
+	tc->bgc_blk_sz = scmd->device->sector_size;
+	tc->reserved_E0_0 = 0;
+	tc->app_tag_gen_mask = 0;
+
+	/** setup block guard control **/
+	tc->bgctl = 0;
+
+	/* DIF read strip */
+	tc->bgctl_f.crc_verify = 1;
+	tc->bgctl_f.op = 0x1;
+	if ((type & SCSI_PROT_DIF_TYPE1) || (type & SCSI_PROT_DIF_TYPE2)) {
+		tc->bgctl_f.ref_tag_chk = 1;
+		tc->bgctl_f.app_f_detect = 1;
+	} else if (type & SCSI_PROT_DIF_TYPE3)
+		tc->bgctl_f.app_ref_f_detect = 1;
+
+	tc->app_tag_verify_mask = 0;
+
+	/* must init to 0 for hw */
+	tc->blk_guard_err = 0;
+
+	tc->reserved_E8_0 = 0;
+	tc->ref_tag_seed_gen = 0;
+}
+
 /**
  * This method is will fill in the SCU Task Context for a SSP IO request.
  * @sci_req:
@@ -274,6 +410,10 @@ static void scu_ssp_io_request_construct_task_context(struct isci_request *ireq,
 						      u32 len)
 {
 	struct scu_task_context *task_context = ireq->tc;
+	struct sas_task *sas_task = ireq->ttype_ptr.io_task_ptr;
+	struct scsi_cmnd *scmd = sas_task->uldd_task;
+	u8 prot_type = scsi_get_prot_type(scmd);
+	u8 prot_op = scsi_get_prot_op(scmd);
 
 	scu_ssp_reqeust_construct_task_context(ireq, task_context);
 
@@ -296,6 +436,13 @@ static void scu_ssp_io_request_construct_task_context(struct isci_request *ireq,
 
 	if (task_context->transfer_length_bytes > 0)
 		sci_request_build_sgl(ireq);
+
+	if (prot_type != SCSI_PROT_DIF_TYPE0) {
+		if (prot_op == SCSI_PROT_READ_STRIP)
+			scu_ssp_ireq_dif_strip(ireq, prot_type, prot_op);
+		else if (prot_op == SCSI_PROT_WRITE_INSERT)
+			scu_ssp_ireq_dif_insert(ireq, prot_type, prot_op);
+	}
 }
 
 /**

commit 3b34c169f8197e02529fa3ec703703c2ce418c57
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Thu Oct 27 15:05:22 2011 -0700

    [SCSI] isci: Remove redundant isci_request.ttype field.
    
    Use the existing IREQ_TMF flag as a request type indicator.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index bfc7379727b1..192cb48d849a 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -191,7 +191,7 @@ static void sci_task_request_build_ssp_task_iu(struct isci_request *ireq)
 
 	task_iu->task_func = isci_tmf->tmf_code;
 	task_iu->task_tag =
-		(ireq->ttype == tmf_task) ?
+		(test_bit(IREQ_TMF, &ireq->flags)) ?
 		isci_tmf->io_tag :
 		SCI_CONTROLLER_INVALID_IO_TAG;
 }
@@ -516,7 +516,7 @@ sci_io_request_construct_sata(struct isci_request *ireq,
 	struct domain_device *dev = ireq->target_device->domain_dev;
 
 	/* check for management protocols */
-	if (ireq->ttype == tmf_task) {
+	if (test_bit(IREQ_TMF, &ireq->flags)) {
 		struct isci_tmf *tmf = isci_request_access_tmf(ireq);
 
 		if (tmf->tmf_code == isci_tmf_sata_srst_high ||
@@ -632,7 +632,7 @@ enum sci_status sci_task_request_construct_sata(struct isci_request *ireq)
 	enum sci_status status = SCI_SUCCESS;
 
 	/* check for management protocols */
-	if (ireq->ttype == tmf_task) {
+	if (test_bit(IREQ_TMF, &ireq->flags)) {
 		struct isci_tmf *tmf = isci_request_access_tmf(ireq);
 
 		if (tmf->tmf_code == isci_tmf_sata_srst_high ||
@@ -2630,14 +2630,8 @@ static void isci_task_save_for_upper_layer_completion(
 	switch (task_notification_selection) {
 
 	case isci_perform_normal_io_completion:
-
 		/* Normal notification (task_done) */
-		dev_dbg(&host->pdev->dev,
-			"%s: Normal - task = %p, response=%d (%d), status=%d (%d)\n",
-			__func__,
-			task,
-			task->task_status.resp, response,
-			task->task_status.stat, status);
+
 		/* Add to the completed list. */
 		list_add(&request->completed_node,
 			 &host->requests_to_complete);
@@ -2650,13 +2644,6 @@ static void isci_task_save_for_upper_layer_completion(
 		/* No notification to libsas because this request is
 		 * already in the abort path.
 		 */
-		dev_dbg(&host->pdev->dev,
-			 "%s: Aborted - task = %p, response=%d (%d), status=%d (%d)\n",
-			 __func__,
-			 task,
-			 task->task_status.resp, response,
-			 task->task_status.stat, status);
-
 		/* Wake up whatever process was waiting for this
 		 * request to complete.
 		 */
@@ -2673,30 +2660,22 @@ static void isci_task_save_for_upper_layer_completion(
 
 	case isci_perform_error_io_completion:
 		/* Use sas_task_abort */
-		dev_dbg(&host->pdev->dev,
-			 "%s: Error - task = %p, response=%d (%d), status=%d (%d)\n",
-			 __func__,
-			 task,
-			 task->task_status.resp, response,
-			 task->task_status.stat, status);
 		/* Add to the aborted list. */
 		list_add(&request->completed_node,
 			 &host->requests_to_errorback);
 		break;
 
 	default:
-		dev_dbg(&host->pdev->dev,
-			 "%s: Unknown - task = %p, response=%d (%d), status=%d (%d)\n",
-			 __func__,
-			 task,
-			 task->task_status.resp, response,
-			 task->task_status.stat, status);
-
 		/* Add to the error to libsas list. */
 		list_add(&request->completed_node,
 			 &host->requests_to_errorback);
 		break;
 	}
+	dev_dbg(&host->pdev->dev,
+		"%s: %d - task = %p, response=%d (%d), status=%d (%d)\n",
+		__func__, task_notification_selection, task,
+		(task) ? task->task_status.resp : 0, response,
+		(task) ? task->task_status.stat : 0, status);
 }
 
 static void isci_process_stp_response(struct sas_task *task, struct dev_to_host_fis *fis)
@@ -3079,7 +3058,7 @@ static void sci_request_started_state_enter(struct sci_base_state_machine *sm)
 	/* XXX as hch said always creating an internal sas_task for tmf
 	 * requests would simplify the driver
 	 */
-	task = ireq->ttype == io_task ? isci_request_access_task(ireq) : NULL;
+	task = (test_bit(IREQ_TMF, &ireq->flags)) ? NULL : isci_request_access_task(ireq);
 
 	/* all unaccelerated request types (non ssp or ncq) handled with
 	 * substates
@@ -3563,7 +3542,7 @@ static struct isci_request *isci_io_request_from_tag(struct isci_host *ihost,
 
 	ireq = isci_request_from_tag(ihost, tag);
 	ireq->ttype_ptr.io_task_ptr = task;
-	ireq->ttype = io_task;
+	clear_bit(IREQ_TMF, &ireq->flags);
 	task->lldd_task = ireq;
 
 	return ireq;
@@ -3577,7 +3556,7 @@ struct isci_request *isci_tmf_request_from_tag(struct isci_host *ihost,
 
 	ireq = isci_request_from_tag(ihost, tag);
 	ireq->ttype_ptr.tmf_task_ptr = isci_tmf;
-	ireq->ttype = tmf_task;
+	set_bit(IREQ_TMF, &ireq->flags);
 
 	return ireq;
 }

commit 0e2e27990e2dcd415f7974e8460a2f05accdddfb
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Thu Oct 27 15:04:50 2011 -0700

    [SCSI] isci: Lookup device references through requests in completions.
    
    The LLDD needs to obtain a reference to the device through the request
    itself and not through the domain_device, because the
    domain_device.lldd_dev is set to NULL early in the lldd_dev_gone call.
    This relies on the fact that the isci_remote_device object is keeping a
    seperate reference count of outstanding requests.  TODO: unify the
    request count tracking with the isci_remote_device kref.
    
    The failure signature of this condition looks like the following
    log, where the important bits are the call to lldd_dev_gone followed
    by a crash in isci_terminate_request_core:
    
    [  229.151541] isci 0000:0b:00.0: isci_remote_device_gone: domain_device = ffff8801492d4800, isci_device = ffff880143c657d0, isci_port = ffff880143c63658
    [  229.166007] isci 0000:0b:00.0: isci_remote_device_stop: isci_device = ffff880143c657d0
    [  229.175317] isci 0000:0b:00.0: isci_terminate_pending_requests: idev=ffff880143c657d0 request=ffff88014741f000; task=ffff8801470f46c0 old_state=2
    [  229.189702] isci 0000:0b:00.0: isci_terminate_request_core: device = ffff880143c657d0; request = ffff88014741f000
    [  229.201339] isci 0000:0b:00.0: isci_terminate_request_core: before completion wait (ffff88014741f000/ffff880149715ad0)
    [  229.213414] isci 0000:0b:00.0: sci_controller_process_completions: completion queue entry:0x8000a0e9
    [  229.214401] BUG: unable to handle kernel NULL pointer dereference at 0000000000000228
    [  229.214401] IP:jdskirvi-testlbo [<ffffffffa00a58be>] sci_request_completed_state_enter+0x50/0xafb [isci]
    [  229.214401] PGD 13d19e067 PUD 13d104067 PMD 0
    [  229.214401] Oops: 0000 [#1] SMP
    [  229.214401] CPU 0 x kernel: [  226
    [  229.214401] Modules linked in: ipv6 dm_multipath uinput nouveau snd_hda_codec_realtek snd_hda_intel ttm drm_kms_helper drm snd_hda_codec snd_hwdep snd_pcm snd_timer i2c_algo_bit isci snd libsas ioatdma mxm_wmi iTCO_wdt soundcore snd_page_alloc scsi_transport_sas iTCO_vendor_support wmi dca video i2c_i801 i2c_core [last unloaded: speedstep_lib]
    [  229.214401]
    [  229.214401] Pid: 5, comm: kworker/u:0 Not tainted 3.0.0-isci-11.7.29+ #30.353196] Buffer  Intel Corporation Stoakley/Pearlcity Workstation
    [  229.214401] RIP: 0010:[<ffffffffa00a58be>] I/O error on dev [<ffffffffa00a58be>] sci_request_completed_state_enter+0x50/0xafb [isci]
    [  229.214401] RSP: 0018:ffff88014fc03d20  EFLAGS: 00010046
    [  229.214401] RAX: 0000000000000000 RBX: ffff88014741f000 RCX: 0000000000000000
    [  229.214401] RDX: ffffffffa00b2c90 RSI: 0000000000000017 RDI: ffff88014741f0a0
    [  229.214401] RBP: ffff88014fc03d90 R08: 0000000000000018 R09: 0000000000000000
    [  229.214401] R10: 0000000000000000 R11: ffffffff81a17d98 R12: 000000000000001d
    [  229.214401] R13: ffff8801470f46c0 R14: 0000000000000000 R15: 0000000000008000
    [  229.214401] FS:  0000000000000000(0000) GS:ffff88014fc00000(0000) knlGS:0000000000000000
    [  229.214401] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [  229.214401] CR2: 0000000000000228 CR3: 000000013ceaa000 CR4: 00000000000406f0
    [  229.214401] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [  229.214401] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
    [  229.214401] Process kworker/u:0 (pid: 5, threadinfo ffff880149714000, task ffff880149718000)
    [  229.214401] Call Trace:
    [  229.214401]  <IRQ>
    [  229.214401]  [<ffffffffa00aa6ce>] sci_change_state+0x4a/0x4f [isci]
    [  229.214401]  [<ffffffffa00a4ca6>] sci_io_request_tc_completion+0x79c/0x7a0 [isci]
    [  229.214401]  [<ffffffffa00acf35>] sci_controller_process_completions+0x14f/0x396 [isci]
    [  229.214401]  [<ffffffffa00abbda>] ? spin_lock_irq+0xe/0x10 [isci]
    [  229.214401]  [<ffffffffa00ad2cf>] isci_host_completion_routine+0x71/0x2be [isci]
    [  229.214401]  [<ffffffff8107c6b3>] ? mark_held_locks+0x52/0x70
    [  229.214401]  [<ffffffff810538e8>] tasklet_action+0x90/0xf1
    [  229.214401]  [<ffffffff81054050>] __do_softirq+0xe5/0x1bf
    [  229.214401]  [<ffffffff8106d9d1>] ? hrtimer_interrupt+0x129/0x1bb
    [  229.214401]  [<ffffffff814ff69c>] call_softirq+0x1c/0x30
    [  229.214401]  [<ffffffff8100bb67>] do_softirq+0x4b/0xa3
    [  229.214401]  [<ffffffff81053d84>] irq_exit+0x53/0xb4
    [  229.214401]  [<ffffffff814fffe7>] smp_apic_timer_interrupt+0x83/0x91
    [  229.214401]  [<ffffffff814fee53>] apic_timer_interrupt+0x13/0x20
    [  229.214401]  <EOI>
    [  229.214401]  [<ffffffff814f7ad4>] ? retint_restore_args+0x13/0x13
    [  229.214401]  [<ffffffff8107af29>] ? trace_hardirqs_off+0xd/0xf
    [  229.214401]  [<ffffffff8104ea71>] ? vprintk+0x40b/0x452
    [  229.214401]  [<ffffffff814f4b5a>] printk+0x41/0x47
    [  229.214401]  [<ffffffff81314484>] __dev_printk+0x78/0x7a
    [  229.214401]  [<ffffffff8131471e>] dev_printk+0x45/0x47
    [  229.214401]  [<ffffffffa00ae2a3>] isci_terminate_request_core+0x15d/0x317 [isci]
    [  229.214401]  [<ffffffffa00af1ad>] isci_terminate_pending_requests+0x1a4/0x204 [isci]
    [  229.214401]  [<ffffffffa00229f6>] ? sas_phye_oob_error+0xc3/0xc3 [libsas]
    [  229.214401]  [<ffffffffa00a7d9e>] isci_remote_device_nuke_requests+0xa6/0xff [isci]
    [  229.214401]  [<ffffffffa00a811a>] isci_remote_device_stop+0x7c/0x166 [isci]
    [  229.214401]  [<ffffffffa00229f6>] ? sas_phye_oob_error+0xc3/0xc3 [libsas]
    [  229.214401]  [<ffffffffa00a827a>] isci_remote_device_gone+0x76/0x7e [isci]
    [  229.214401]  [<ffffffffa002363e>] sas_notify_lldd_dev_gone+0x34/0x36 [libsas]
    [  229.214401]  [<ffffffffa0023945>] sas_unregister_dev+0x57/0x9c [libsas]
    [  229.214401]  [<ffffffffa00239c0>] sas_unregister_domain_devices+0x36/0x65 [libsas]
    [  229.214401]  [<ffffffffa0022cb8>] sas_deform_port+0x72/0x1ac [libsas]
    [  229.214401]  [<ffffffffa00229f6>] ? sas_phye_oob_error+0xc3/0xc3 [libsas]
    [  229.214401]  [<ffffffffa0022a34>] sas_phye_loss_of_signal+0x3e/0x42 [libsas]
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 565a9f0a9bc2..bfc7379727b1 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2728,9 +2728,9 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 	struct sas_task *task = isci_request_access_task(request);
 	struct ssp_response_iu *resp_iu;
 	unsigned long task_flags;
-	struct isci_remote_device *idev = isci_lookup_device(task->dev);
-	enum service_response response       = SAS_TASK_UNDELIVERED;
-	enum exec_status status         = SAS_ABORTED_TASK;
+	struct isci_remote_device *idev = request->target_device;
+	enum service_response response = SAS_TASK_UNDELIVERED;
+	enum exec_status status = SAS_ABORTED_TASK;
 	enum isci_request_status request_status;
 	enum isci_completion_selection complete_to_host
 		= isci_perform_normal_io_completion;
@@ -3061,7 +3061,6 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 
 	/* complete the io request to the core. */
 	sci_controller_complete_io(ihost, request->target_device, request);
-	isci_put_device(idev);
 
 	/* set terminated handle so it cannot be completed or
 	 * terminated again, and to cause any calls into abort

commit 7582ba8bdf5a119221ef663a327932cfc62bed79
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Wed Sep 28 18:47:51 2011 -0700

    [SCSI] isci: fix decode of DONE_CRC_ERR TC completion status
    
    DONE_CRC_ERR is not a RNC suspension condition, so do not change the
    state to expect the incoming suspension notification.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    [djbw: dropped DONE_CMD_LL_R_ERR change]
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 23a55043a923..565a9f0a9bc2 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2074,10 +2074,9 @@ static enum sci_status stp_request_udma_await_tc_event(struct isci_request *ireq
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_MAX_PLD_ERR):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_LL_R_ERR):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_CMD_LL_R_ERR):
-	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_CRC_ERR):
 		sci_remote_device_suspend(ireq->target_device,
 			SCU_EVENT_SPECIFIC(SCU_NORMALIZE_COMPLETION_STATUS(completion_code)));
-	/* Fall through to the default case */
+		/* Fall through to the default case */
 	default:
 		/* All other completion status cause the IO to be complete. */
 		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);

commit b50102d3e9a43a75379407c2080f696f61cb286b
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Sep 30 18:52:19 2011 -0700

    [SCSI] isci: atapi support
    
    Based on original implementation from Jiangbi Liu and Maciej Trela.
    
    ATAPI transfers happen in two-to-three stages.  The two stage atapi
    commands are those that include a dma data transfer.  The data transfer
    portion of these operations is handled by the hardware packet-dma
    acceleration.  The three-stage commands do not have a data transfer and
    are handled without hardware assistance in raw frame mode.
    
    stage1: transmit host-to-device fis to notify the device of an incoming
    atapi cdb.  Upon reception of the pio-setup-fis repost the task_context
    to perform the dma transfer of the cdb+data (go to stage3), or repost
    the task_context to transmit the cdb as a raw frame (go to stage 2).
    
    stage2: wait for hardware notification of the cdb transmission and then
    go to stage 3.
    
    stage3: wait for the arrival of the terminating device-to-host fis and
    terminate the command.
    
    To keep the implementation simple we only support ATAPI packet-dma
    protocol (for commands with data) to avoid needing to handle the data
    transfer manually (like we do for SATA-PIO).  This may affect
    compatibility for a small number of devices (see
    ATA_HORKAGE_ATAPI_MOD16_DMA).
    
    If the data-transfer underruns, or encounters an error the
    device-to-host fis is expected to arrive in the unsolicited frame queue
    to pass to libata for disposition.  However, in the DONE_UNEXP_FIS (data
    underrun) case it appears we need to craft a response.  In the
    DONE_REG_ERR case we do receive the UF and propagate it to libsas.
    
    Signed-off-by: Maciej Trela <maciej.trela@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 225b196800a2..23a55043a923 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -481,7 +481,29 @@ static void sci_stp_optimized_request_construct(struct isci_request *ireq,
 	}
 }
 
+static void sci_atapi_construct(struct isci_request *ireq)
+{
+	struct host_to_dev_fis *h2d_fis = &ireq->stp.cmd;
+	struct sas_task *task;
+
+	/* To simplify the implementation we take advantage of the
+	 * silicon's partial acceleration of atapi protocol (dma data
+	 * transfers), so we promote all commands to dma protocol.  This
+	 * breaks compatibility with ATA_HORKAGE_ATAPI_MOD16_DMA drives.
+	 */
+	h2d_fis->features |= ATAPI_PKT_DMA;
+
+	scu_stp_raw_request_construct_task_context(ireq);
+
+	task = isci_request_access_task(ireq);
+	if (task->data_dir == DMA_NONE)
+		task->total_xfer_len = 0;
 
+	/* clear the response so we can detect arrivial of an
+	 * unsolicited h2d fis
+	 */
+	ireq->stp.rsp.fis_type = 0;
+}
 
 static enum sci_status
 sci_io_request_construct_sata(struct isci_request *ireq,
@@ -491,6 +513,7 @@ sci_io_request_construct_sata(struct isci_request *ireq,
 {
 	enum sci_status status = SCI_SUCCESS;
 	struct sas_task *task = isci_request_access_task(ireq);
+	struct domain_device *dev = ireq->target_device->domain_dev;
 
 	/* check for management protocols */
 	if (ireq->ttype == tmf_task) {
@@ -519,6 +542,13 @@ sci_io_request_construct_sata(struct isci_request *ireq,
 
 	}
 
+	/* ATAPI */
+	if (dev->sata_dev.command_set == ATAPI_COMMAND_SET &&
+	    task->ata_task.fis.command == ATA_CMD_PACKET) {
+		sci_atapi_construct(ireq);
+		return SCI_SUCCESS;
+	}
+
 	/* non data */
 	if (task->data_dir == DMA_NONE) {
 		scu_stp_raw_request_construct_task_context(ireq);
@@ -627,7 +657,7 @@ enum sci_status sci_task_request_construct_sata(struct isci_request *ireq)
 
 /**
  * sci_req_tx_bytes - bytes transferred when reply underruns request
- * @sci_req: request that was terminated early
+ * @ireq: request that was terminated early
  */
 #define SCU_TASK_CONTEXT_SRAM 0x200000
 static u32 sci_req_tx_bytes(struct isci_request *ireq)
@@ -729,6 +759,10 @@ sci_io_request_terminate(struct isci_request *ireq)
 	case SCI_REQ_STP_SOFT_RESET_WAIT_H2D_ASSERTED:
 	case SCI_REQ_STP_SOFT_RESET_WAIT_H2D_DIAG:
 	case SCI_REQ_STP_SOFT_RESET_WAIT_D2H:
+	case SCI_REQ_ATAPI_WAIT_H2D:
+	case SCI_REQ_ATAPI_WAIT_PIO_SETUP:
+	case SCI_REQ_ATAPI_WAIT_D2H:
+	case SCI_REQ_ATAPI_WAIT_TC_COMP:
 		sci_change_state(&ireq->sm, SCI_REQ_ABORTING);
 		return SCI_SUCCESS;
 	case SCI_REQ_TASK_WAIT_TC_RESP:
@@ -1194,8 +1228,8 @@ static enum sci_status sci_stp_request_pio_data_out_transmit_data(struct isci_re
 {
 	struct isci_stp_request *stp_req = &ireq->stp.req;
 	struct scu_sgl_element_pair *sgl_pair;
+	enum sci_status status = SCI_SUCCESS;
 	struct scu_sgl_element *sgl;
-	enum sci_status status;
 	u32 offset;
 	u32 len = 0;
 
@@ -1249,7 +1283,7 @@ static enum sci_status sci_stp_request_pio_data_out_transmit_data(struct isci_re
  */
 static enum sci_status
 sci_stp_request_pio_data_in_copy_data_buffer(struct isci_stp_request *stp_req,
-						  u8 *data_buf, u32 len)
+					     u8 *data_buf, u32 len)
 {
 	struct isci_request *ireq;
 	u8 *src_addr;
@@ -1423,6 +1457,128 @@ static enum sci_status sci_stp_request_udma_general_frame_handler(struct isci_re
 	return status;
 }
 
+static enum sci_status process_unsolicited_fis(struct isci_request *ireq,
+					       u32 frame_index)
+{
+	struct isci_host *ihost = ireq->owning_controller;
+	enum sci_status status;
+	struct dev_to_host_fis *frame_header;
+	u32 *frame_buffer;
+
+	status = sci_unsolicited_frame_control_get_header(&ihost->uf_control,
+							  frame_index,
+							  (void **)&frame_header);
+
+	if (status != SCI_SUCCESS)
+		return status;
+
+	if (frame_header->fis_type != FIS_REGD2H) {
+		dev_err(&ireq->isci_host->pdev->dev,
+			"%s ERROR: invalid fis type 0x%X\n",
+			__func__, frame_header->fis_type);
+		return SCI_FAILURE;
+	}
+
+	sci_unsolicited_frame_control_get_buffer(&ihost->uf_control,
+						 frame_index,
+						 (void **)&frame_buffer);
+
+	sci_controller_copy_sata_response(&ireq->stp.rsp,
+					  (u32 *)frame_header,
+					  frame_buffer);
+
+	/* Frame has been decoded return it to the controller */
+	sci_controller_release_frame(ihost, frame_index);
+
+	return status;
+}
+
+static enum sci_status atapi_d2h_reg_frame_handler(struct isci_request *ireq,
+						   u32 frame_index)
+{
+	struct sas_task *task = isci_request_access_task(ireq);
+	enum sci_status status;
+
+	status = process_unsolicited_fis(ireq, frame_index);
+
+	if (status == SCI_SUCCESS) {
+		if (ireq->stp.rsp.status & ATA_ERR)
+			status = SCI_IO_FAILURE_RESPONSE_VALID;
+	} else {
+		status = SCI_IO_FAILURE_RESPONSE_VALID;
+	}
+
+	if (status != SCI_SUCCESS) {
+		ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
+		ireq->sci_status = status;
+	} else {
+		ireq->scu_status = SCU_TASK_DONE_GOOD;
+		ireq->sci_status = SCI_SUCCESS;
+	}
+
+	/* the d2h ufi is the end of non-data commands */
+	if (task->data_dir == DMA_NONE)
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
+
+	return status;
+}
+
+static void scu_atapi_reconstruct_raw_frame_task_context(struct isci_request *ireq)
+{
+	struct ata_device *dev = sas_to_ata_dev(ireq->target_device->domain_dev);
+	void *atapi_cdb = ireq->ttype_ptr.io_task_ptr->ata_task.atapi_packet;
+	struct scu_task_context *task_context = ireq->tc;
+
+	/* fill in the SCU Task Context for a DATA fis containing CDB in Raw Frame
+	 * type. The TC for previous Packet fis was already there, we only need to
+	 * change the H2D fis content.
+	 */
+	memset(&ireq->stp.cmd, 0, sizeof(struct host_to_dev_fis));
+	memcpy(((u8 *)&ireq->stp.cmd + sizeof(u32)), atapi_cdb, ATAPI_CDB_LEN);
+	memset(&(task_context->type.stp), 0, sizeof(struct stp_task_context));
+	task_context->type.stp.fis_type = FIS_DATA;
+	task_context->transfer_length_bytes = dev->cdb_len;
+}
+
+static void scu_atapi_construct_task_context(struct isci_request *ireq)
+{
+	struct ata_device *dev = sas_to_ata_dev(ireq->target_device->domain_dev);
+	struct sas_task *task = isci_request_access_task(ireq);
+	struct scu_task_context *task_context = ireq->tc;
+	int cdb_len = dev->cdb_len;
+
+	/* reference: SSTL 1.13.4.2
+	 * task_type, sata_direction
+	 */
+	if (task->data_dir == DMA_TO_DEVICE) {
+		task_context->task_type = SCU_TASK_TYPE_PACKET_DMA_OUT;
+		task_context->sata_direction = 0;
+	} else {
+		/* todo: for NO_DATA command, we need to send out raw frame. */
+		task_context->task_type = SCU_TASK_TYPE_PACKET_DMA_IN;
+		task_context->sata_direction = 1;
+	}
+
+	memset(&task_context->type.stp, 0, sizeof(task_context->type.stp));
+	task_context->type.stp.fis_type = FIS_DATA;
+
+	memset(&ireq->stp.cmd, 0, sizeof(ireq->stp.cmd));
+	memcpy(&ireq->stp.cmd.lbal, task->ata_task.atapi_packet, cdb_len);
+	task_context->ssp_command_iu_length = cdb_len / sizeof(u32);
+
+	/* task phase is set to TX_CMD */
+	task_context->task_phase = 0x1;
+
+	/* retry counter */
+	task_context->stp_retry_count = 0;
+
+	/* data transfer size. */
+	task_context->transfer_length_bytes = task->total_xfer_len;
+
+	/* setup sgl */
+	sci_request_build_sgl(ireq);
+}
+
 enum sci_status
 sci_io_request_frame_handler(struct isci_request *ireq,
 				  u32 frame_index)
@@ -1835,6 +1991,24 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 
 		return status;
 	}
+	case SCI_REQ_ATAPI_WAIT_PIO_SETUP: {
+		struct sas_task *task = isci_request_access_task(ireq);
+
+		sci_controller_release_frame(ihost, frame_index);
+		ireq->target_device->working_request = ireq;
+		if (task->data_dir == DMA_NONE) {
+			sci_change_state(&ireq->sm, SCI_REQ_ATAPI_WAIT_TC_COMP);
+			scu_atapi_reconstruct_raw_frame_task_context(ireq);
+		} else {
+			sci_change_state(&ireq->sm, SCI_REQ_ATAPI_WAIT_D2H);
+			scu_atapi_construct_task_context(ireq);
+		}
+
+		sci_controller_continue_io(ireq);
+		return SCI_SUCCESS;
+	}
+	case SCI_REQ_ATAPI_WAIT_D2H:
+		return atapi_d2h_reg_frame_handler(ireq, frame_index);
 	case SCI_REQ_ABORTING:
 		/*
 		 * TODO: Is it even possible to get an unsolicited frame in the
@@ -1966,6 +2140,112 @@ stp_request_soft_reset_await_h2d_diagnostic_tc_event(struct isci_request *ireq,
 	return SCI_SUCCESS;
 }
 
+static enum sci_status atapi_raw_completion(struct isci_request *ireq, u32 completion_code,
+						  enum sci_base_request_states next)
+{
+	enum sci_status status = SCI_SUCCESS;
+
+	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
+		ireq->scu_status = SCU_TASK_DONE_GOOD;
+		ireq->sci_status = SCI_SUCCESS;
+		sci_change_state(&ireq->sm, next);
+		break;
+	default:
+		/* All other completion status cause the IO to be complete.
+		 * If a NAK was received, then it is up to the user to retry
+		 * the request.
+		 */
+		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
+		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
+
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
+		break;
+	}
+
+	return status;
+}
+
+static enum sci_status atapi_data_tc_completion_handler(struct isci_request *ireq,
+							u32 completion_code)
+{
+	struct isci_remote_device *idev = ireq->target_device;
+	struct dev_to_host_fis *d2h = &ireq->stp.rsp;
+	enum sci_status status = SCI_SUCCESS;
+
+	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
+	case (SCU_TASK_DONE_GOOD << SCU_COMPLETION_TL_STATUS_SHIFT):
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
+		break;
+
+	case (SCU_TASK_DONE_UNEXP_FIS << SCU_COMPLETION_TL_STATUS_SHIFT): {
+		u16 len = sci_req_tx_bytes(ireq);
+
+		/* likely non-error data underrrun, workaround missing
+		 * d2h frame from the controller
+		 */
+		if (d2h->fis_type != FIS_REGD2H) {
+			d2h->fis_type = FIS_REGD2H;
+			d2h->flags = (1 << 6);
+			d2h->status = 0x50;
+			d2h->error = 0;
+			d2h->lbal = 0;
+			d2h->byte_count_low = len & 0xff;
+			d2h->byte_count_high = len >> 8;
+			d2h->device = 0xa0;
+			d2h->lbal_exp = 0;
+			d2h->lbam_exp = 0;
+			d2h->lbah_exp = 0;
+			d2h->_r_a = 0;
+			d2h->sector_count = 0x3;
+			d2h->sector_count_exp = 0;
+			d2h->_r_b = 0;
+			d2h->_r_c = 0;
+			d2h->_r_d = 0;
+		}
+
+		ireq->scu_status = SCU_TASK_DONE_GOOD;
+		ireq->sci_status = SCI_SUCCESS_IO_DONE_EARLY;
+		status = ireq->sci_status;
+
+		/* the hw will have suspended the rnc, so complete the
+		 * request upon pending resume
+		 */
+		sci_change_state(&idev->sm, SCI_STP_DEV_ATAPI_ERROR);
+		break;
+	}
+	case (SCU_TASK_DONE_EXCESS_DATA << SCU_COMPLETION_TL_STATUS_SHIFT):
+		/* In this case, there is no UF coming after.
+		 * compelte the IO now.
+		 */
+		ireq->scu_status = SCU_TASK_DONE_GOOD;
+		ireq->sci_status = SCI_SUCCESS;
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
+		break;
+
+	default:
+		if (d2h->fis_type == FIS_REGD2H) {
+			/* UF received change the device state to ATAPI_ERROR */
+			status = ireq->sci_status;
+			sci_change_state(&idev->sm, SCI_STP_DEV_ATAPI_ERROR);
+		} else {
+			/* If receiving any non-sucess TC status, no UF
+			 * received yet, then an UF for the status fis
+			 * is coming after (XXX: suspect this is
+			 * actually a protocol error or a bug like the
+			 * DONE_UNEXP_FIS case)
+			 */
+			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
+			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
+
+			sci_change_state(&ireq->sm, SCI_REQ_ATAPI_WAIT_D2H);
+		}
+		break;
+	}
+
+	return status;
+}
+
 enum sci_status
 sci_io_request_tc_completion(struct isci_request *ireq,
 				  u32 completion_code)
@@ -2017,6 +2297,17 @@ sci_io_request_tc_completion(struct isci_request *ireq,
 		return request_aborting_state_tc_event(ireq,
 						       completion_code);
 
+	case SCI_REQ_ATAPI_WAIT_H2D:
+		return atapi_raw_completion(ireq, completion_code,
+					    SCI_REQ_ATAPI_WAIT_PIO_SETUP);
+
+	case SCI_REQ_ATAPI_WAIT_TC_COMP:
+		return atapi_raw_completion(ireq, completion_code,
+					    SCI_REQ_ATAPI_WAIT_D2H);
+
+	case SCI_REQ_ATAPI_WAIT_D2H:
+		return atapi_data_tc_completion_handler(ireq, completion_code);
+
 	default:
 		dev_warn(&ihost->pdev->dev,
 			 "%s: SCIC IO Request given task completion "
@@ -2423,6 +2714,8 @@ static void isci_process_stp_response(struct sas_task *task, struct dev_to_host_
 	 */
 	if (fis->status & ATA_DF)
 		ts->stat = SAS_PROTO_RESPONSE;
+	else if (fis->status & ATA_ERR)
+		ts->stat = SAM_STAT_CHECK_CONDITION;
 	else
 		ts->stat = SAM_STAT_GOOD;
 
@@ -2782,6 +3075,7 @@ static void sci_request_started_state_enter(struct sci_base_state_machine *sm)
 {
 	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
 	struct domain_device *dev = ireq->target_device->domain_dev;
+	enum sci_base_request_states state;
 	struct sas_task *task;
 
 	/* XXX as hch said always creating an internal sas_task for tmf
@@ -2793,26 +3087,30 @@ static void sci_request_started_state_enter(struct sci_base_state_machine *sm)
 	 * substates
 	 */
 	if (!task && dev->dev_type == SAS_END_DEV) {
-		sci_change_state(sm, SCI_REQ_TASK_WAIT_TC_COMP);
+		state = SCI_REQ_TASK_WAIT_TC_COMP;
 	} else if (!task &&
 		   (isci_request_access_tmf(ireq)->tmf_code == isci_tmf_sata_srst_high ||
 		    isci_request_access_tmf(ireq)->tmf_code == isci_tmf_sata_srst_low)) {
-		sci_change_state(sm, SCI_REQ_STP_SOFT_RESET_WAIT_H2D_ASSERTED);
+		state = SCI_REQ_STP_SOFT_RESET_WAIT_H2D_ASSERTED;
 	} else if (task && task->task_proto == SAS_PROTOCOL_SMP) {
-		sci_change_state(sm, SCI_REQ_SMP_WAIT_RESP);
+		state = SCI_REQ_SMP_WAIT_RESP;
 	} else if (task && sas_protocol_ata(task->task_proto) &&
 		   !task->ata_task.use_ncq) {
-		u32 state;
-
-		if (task->data_dir == DMA_NONE)
+		if (dev->sata_dev.command_set == ATAPI_COMMAND_SET &&
+			task->ata_task.fis.command == ATA_CMD_PACKET) {
+			state = SCI_REQ_ATAPI_WAIT_H2D;
+		} else if (task->data_dir == DMA_NONE) {
 			state = SCI_REQ_STP_NON_DATA_WAIT_H2D;
-		else if (task->ata_task.dma_xfer)
+		} else if (task->ata_task.dma_xfer) {
 			state = SCI_REQ_STP_UDMA_WAIT_TC_COMP;
-		else /* PIO */
+		} else /* PIO */ {
 			state = SCI_REQ_STP_PIO_WAIT_H2D;
-
-		sci_change_state(sm, state);
+		}
+	} else {
+		/* SSP or NCQ are fully accelerated, no substates */
+		return;
 	}
+	sci_change_state(sm, state);
 }
 
 static void sci_request_completed_state_enter(struct sci_base_state_machine *sm)
@@ -2904,6 +3202,10 @@ static const struct sci_base_state sci_request_state_table[] = {
 	[SCI_REQ_TASK_WAIT_TC_RESP] = { },
 	[SCI_REQ_SMP_WAIT_RESP] = { },
 	[SCI_REQ_SMP_WAIT_TC_COMP] = { },
+	[SCI_REQ_ATAPI_WAIT_H2D] = { },
+	[SCI_REQ_ATAPI_WAIT_PIO_SETUP] = { },
+	[SCI_REQ_ATAPI_WAIT_D2H] = { },
+	[SCI_REQ_ATAPI_WAIT_TC_COMP] = { },
 	[SCI_REQ_COMPLETED] = {
 		.enter_state = sci_request_completed_state_enter,
 	},

commit 54b5e3a4bfa3452bc10cd4da672099ccc46b8c09
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed Sep 28 18:35:27 2011 -0700

    [SCSI] isci: fix support for large smp requests
    
    Kill the local smp response buffer.
    
    Besides being unnecessary, it is too small (currently truncates
    responses to 60 bytes).  The mid-layer will have already allocated a
    sufficiently sized buffer, just kmap and copy into it directly.
    
    Cc: <stable@kernel.org>
    Reported-by: Derick Marks <derick.w.marks@intel.com>
    Tested-by: Derick Marks <derick.w.marks@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index b5d3a8c4d329..225b196800a2 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -1490,29 +1490,30 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 		return SCI_SUCCESS;
 
 	case SCI_REQ_SMP_WAIT_RESP: {
-		struct smp_resp *rsp_hdr = &ireq->smp.rsp;
-		void *frame_header;
+		struct sas_task *task = isci_request_access_task(ireq);
+		struct scatterlist *sg = &task->smp_task.smp_resp;
+		void *frame_header, *kaddr;
+		u8 *rsp;
 
 		sci_unsolicited_frame_control_get_header(&ihost->uf_control,
-							      frame_index,
-							      &frame_header);
-
-		/* byte swap the header. */
-		word_cnt = SMP_RESP_HDR_SZ / sizeof(u32);
-		sci_swab32_cpy(rsp_hdr, frame_header, word_cnt);
+							 frame_index,
+							 &frame_header);
+		kaddr = kmap_atomic(sg_page(sg), KM_IRQ0);
+		rsp = kaddr + sg->offset;
+		sci_swab32_cpy(rsp, frame_header, 1);
 
-		if (rsp_hdr->frame_type == SMP_RESPONSE) {
+		if (rsp[0] == SMP_RESPONSE) {
 			void *smp_resp;
 
 			sci_unsolicited_frame_control_get_buffer(&ihost->uf_control,
-								      frame_index,
-								      &smp_resp);
+								 frame_index,
+								 &smp_resp);
 
-			word_cnt = (sizeof(struct smp_resp) - SMP_RESP_HDR_SZ) /
-				sizeof(u32);
-
-			sci_swab32_cpy(((u8 *) rsp_hdr) + SMP_RESP_HDR_SZ,
-				       smp_resp, word_cnt);
+			word_cnt = (sg->length/4)-1;
+			if (word_cnt > 0)
+				word_cnt = min_t(unsigned int, word_cnt,
+						 SCU_UNSOLICITED_FRAME_BUFFER_SIZE/4);
+			sci_swab32_cpy(rsp + 4, smp_resp, word_cnt);
 
 			ireq->scu_status = SCU_TASK_DONE_GOOD;
 			ireq->sci_status = SCI_SUCCESS;
@@ -1528,12 +1529,13 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 				__func__,
 				ireq,
 				frame_index,
-				rsp_hdr->frame_type);
+				rsp[0]);
 
 			ireq->scu_status = SCU_TASK_DONE_SMP_FRM_TYPE_ERR;
 			ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
 			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		}
+		kunmap_atomic(kaddr, KM_IRQ0);
 
 		sci_controller_release_frame(ihost, frame_index);
 
@@ -2603,18 +2605,7 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 			status   = SAM_STAT_GOOD;
 			set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 
-			if (task->task_proto == SAS_PROTOCOL_SMP) {
-				void *rsp = &request->smp.rsp;
-
-				dev_dbg(&ihost->pdev->dev,
-					"%s: SMP protocol completion\n",
-					__func__);
-
-				sg_copy_from_buffer(
-					&task->smp_task.smp_resp, 1,
-					rsp, sizeof(struct smp_resp));
-			} else if (completion_status
-				   == SCI_IO_SUCCESS_IO_DONE_EARLY) {
+			if (completion_status == SCI_IO_SUCCESS_IO_DONE_EARLY) {
 
 				/* This was an SSP / STP / SATA transfer.
 				 * There is a possibility that less data than

commit 39ea2c5b5ffaa344467da53e885cfa4ac0105050
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Fri Jul 29 17:17:05 2011 -0700

    [SCSI] isci: Leave requests alone if already terminating.
    
    Instead of immediately completing any request that has a second
    termination call made on it, wait for the TC done/abort HW event.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index b4cf998385b3..b5d3a8c4d329 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -732,12 +732,20 @@ sci_io_request_terminate(struct isci_request *ireq)
 		sci_change_state(&ireq->sm, SCI_REQ_ABORTING);
 		return SCI_SUCCESS;
 	case SCI_REQ_TASK_WAIT_TC_RESP:
+		/* The task frame was already confirmed to have been
+		 * sent by the SCU HW.  Since the state machine is
+		 * now only waiting for the task response itself,
+		 * abort the request and complete it immediately
+		 * and don't wait for the task response.
+		 */
 		sci_change_state(&ireq->sm, SCI_REQ_ABORTING);
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		return SCI_SUCCESS;
 	case SCI_REQ_ABORTING:
-		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
-		return SCI_SUCCESS;
+		/* If a request has a termination requested twice, return
+		 * a failure indication, since HW confirmation of the first
+		 * abort is still outstanding.
+		 */
 	case SCI_REQ_COMPLETED:
 	default:
 		dev_warn(&ireq->owning_controller->pdev->dev,

commit 1a878284473284f9577d44babf16d87152a05c33
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Jul 29 17:16:40 2011 -0700

    [SCSI] isci: fix sata response handling
    
    A bug (likely copy/paste) that has been carried from the original
    implementation.  The unsolicited frame handling structure returns the
    d2h fis in the isci_request.stp.rsp buffer.
    
    Cc: <stable@kernel.org>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index a46e07ac789f..b4cf998385b3 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2399,22 +2399,19 @@ static void isci_task_save_for_upper_layer_completion(
 	}
 }
 
-static void isci_request_process_stp_response(struct sas_task *task,
-					      void *response_buffer)
+static void isci_process_stp_response(struct sas_task *task, struct dev_to_host_fis *fis)
 {
-	struct dev_to_host_fis *d2h_reg_fis = response_buffer;
 	struct task_status_struct *ts = &task->task_status;
 	struct ata_task_resp *resp = (void *)&ts->buf[0];
 
-	resp->frame_len = le16_to_cpu(*(__le16 *)(response_buffer + 6));
-	memcpy(&resp->ending_fis[0], response_buffer + 16, 24);
+	resp->frame_len = sizeof(*fis);
+	memcpy(resp->ending_fis, fis, sizeof(*fis));
 	ts->buf_valid_size = sizeof(*resp);
 
-	/**
-	 * If the device fault bit is set in the status register, then
+	/* If the device fault bit is set in the status register, then
 	 * set the sense data and return.
 	 */
-	if (d2h_reg_fis->status & ATA_DF)
+	if (fis->status & ATA_DF)
 		ts->stat = SAS_PROTO_RESPONSE;
 	else
 		ts->stat = SAM_STAT_GOOD;
@@ -2428,7 +2425,6 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 {
 	struct sas_task *task = isci_request_access_task(request);
 	struct ssp_response_iu *resp_iu;
-	void *resp_buf;
 	unsigned long task_flags;
 	struct isci_remote_device *idev = isci_lookup_device(task->dev);
 	enum service_response response       = SAS_TASK_UNDELIVERED;
@@ -2565,9 +2561,7 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 				task);
 
 			if (sas_protocol_ata(task->task_proto)) {
-				resp_buf = &request->stp.rsp;
-				isci_request_process_stp_response(task,
-								  resp_buf);
+				isci_process_stp_response(task, &request->stp.rsp);
 			} else if (SAS_PROTOCOL_SSP == task->task_proto) {
 
 				/* crack the iu response buffer. */

commit a8a0a133b03c6863d0f77229d19befca4de905fa
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Jul 1 12:07:25 2011 -0700

    isci: pare back error messsages
    
    The messages emitted from task.c and some from request.c likely
    duplicate (in a less undertandable way) what is reported by the
    midlayer.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 33c8ed1741e6..a46e07ac789f 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2350,7 +2350,7 @@ static void isci_task_save_for_upper_layer_completion(
 		/* No notification to libsas because this request is
 		 * already in the abort path.
 		 */
-		dev_warn(&host->pdev->dev,
+		dev_dbg(&host->pdev->dev,
 			 "%s: Aborted - task = %p, response=%d (%d), status=%d (%d)\n",
 			 __func__,
 			 task,
@@ -2373,7 +2373,7 @@ static void isci_task_save_for_upper_layer_completion(
 
 	case isci_perform_error_io_completion:
 		/* Use sas_task_abort */
-		dev_warn(&host->pdev->dev,
+		dev_dbg(&host->pdev->dev,
 			 "%s: Error - task = %p, response=%d (%d), status=%d (%d)\n",
 			 __func__,
 			 task,
@@ -2385,7 +2385,7 @@ static void isci_task_save_for_upper_layer_completion(
 		break;
 
 	default:
-		dev_warn(&host->pdev->dev,
+		dev_dbg(&host->pdev->dev,
 			 "%s: Unknown - task = %p, response=%d (%d), status=%d (%d)\n",
 			 __func__,
 			 task,
@@ -2710,7 +2710,7 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 
 		default:
 			/* Catch any otherwise unhandled error codes here. */
-			dev_warn(&ihost->pdev->dev,
+			dev_dbg(&ihost->pdev->dev,
 				 "%s: invalid completion code: 0x%x - "
 				 "isci_request = %p\n",
 				 __func__, completion_status, request);
@@ -3164,7 +3164,7 @@ static enum sci_status isci_smp_request_build(struct isci_request *ireq)
 
 	status = sci_io_request_construct_smp(dev, ireq, task);
 	if (status != SCI_SUCCESS)
-		dev_warn(&ireq->isci_host->pdev->dev,
+		dev_dbg(&ireq->isci_host->pdev->dev,
 			 "%s: failed with status = %d\n",
 			 __func__,
 			 status);
@@ -3219,7 +3219,7 @@ static enum sci_status isci_io_request_build(struct isci_host *ihost,
 	status = sci_io_request_construct(ihost, idev, request);
 
 	if (status != SCI_SUCCESS) {
-		dev_warn(&ihost->pdev->dev,
+		dev_dbg(&ihost->pdev->dev,
 			 "%s: failed request construct\n",
 			 __func__);
 		return SCI_FAILURE;
@@ -3238,7 +3238,7 @@ static enum sci_status isci_io_request_build(struct isci_host *ihost,
 		status = isci_request_stp_request_construct(request);
 		break;
 	default:
-		dev_warn(&ihost->pdev->dev,
+		dev_dbg(&ihost->pdev->dev,
 			 "%s: unknown protocol\n", __func__);
 		return SCI_FAILURE;
 	}
@@ -3302,7 +3302,7 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 
 	status = isci_io_request_build(ihost, ireq, idev);
 	if (status != SCI_SUCCESS) {
-		dev_warn(&ihost->pdev->dev,
+		dev_dbg(&ihost->pdev->dev,
 			 "%s: request_construct failed - status = 0x%x\n",
 			 __func__,
 			 status);
@@ -3335,7 +3335,7 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 
 	if (status != SCI_SUCCESS &&
 	    status != SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
-		dev_warn(&ihost->pdev->dev,
+		dev_dbg(&ihost->pdev->dev,
 			 "%s: failed request start (0x%x)\n",
 			 __func__, status);
 		spin_unlock_irqrestore(&ihost->scic_lock, flags);

commit 16ba77091b44af28b3ff3318b4a2aa4fbf7d4c24
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Jul 1 10:52:55 2011 -0700

    isci: merge sata.[ch] into request.c
    
    Undo some needless separation.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 7c500bb6a8e0..33c8ed1741e6 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -56,7 +56,6 @@
 #include "isci.h"
 #include "task.h"
 #include "request.h"
-#include "sata.h"
 #include "scu_completion_codes.h"
 #include "scu_event_codes.h"
 #include "sas.h"
@@ -1092,16 +1091,6 @@ smp_request_await_tc_event(struct isci_request *ireq,
 	return SCI_SUCCESS;
 }
 
-void sci_stp_io_request_set_ncq_tag(struct isci_request *ireq,
-				     u16 ncq_tag)
-{
-	/**
-	 * @note This could be made to return an error to the user if the user
-	 *       attempts to set the NCQ tag in the wrong state.
-	 */
-	ireq->tc->type.stp.ncq_tag = ncq_tag;
-}
-
 static struct scu_sgl_element *pio_sgl_next(struct isci_stp_request *stp_req)
 {
 	struct scu_sgl_element *sgl;
@@ -2410,6 +2399,29 @@ static void isci_task_save_for_upper_layer_completion(
 	}
 }
 
+static void isci_request_process_stp_response(struct sas_task *task,
+					      void *response_buffer)
+{
+	struct dev_to_host_fis *d2h_reg_fis = response_buffer;
+	struct task_status_struct *ts = &task->task_status;
+	struct ata_task_resp *resp = (void *)&ts->buf[0];
+
+	resp->frame_len = le16_to_cpu(*(__le16 *)(response_buffer + 6));
+	memcpy(&resp->ending_fis[0], response_buffer + 16, 24);
+	ts->buf_valid_size = sizeof(*resp);
+
+	/**
+	 * If the device fault bit is set in the status register, then
+	 * set the sense data and return.
+	 */
+	if (d2h_reg_fis->status & ATA_DF)
+		ts->stat = SAS_PROTO_RESPONSE;
+	else
+		ts->stat = SAM_STAT_GOOD;
+
+	ts->resp = SAS_TASK_COMPLETE;
+}
+
 static void isci_request_io_request_complete(struct isci_host *ihost,
 					     struct isci_request *request,
 					     enum sci_io_status completion_status)
@@ -2985,34 +2997,29 @@ static enum sci_status isci_request_ssp_request_construct(
 	return status;
 }
 
-static enum sci_status isci_request_stp_request_construct(
-	struct isci_request *request)
+static enum sci_status isci_request_stp_request_construct(struct isci_request *ireq)
 {
-	struct sas_task *task = isci_request_access_task(request);
+	struct sas_task *task = isci_request_access_task(ireq);
+	struct host_to_dev_fis *fis = &ireq->stp.cmd;
+	struct ata_queued_cmd *qc = task->uldd_task;
 	enum sci_status status;
-	struct host_to_dev_fis *register_fis;
 
-	dev_dbg(&request->isci_host->pdev->dev,
-		"%s: request = %p\n",
+	dev_dbg(&ireq->isci_host->pdev->dev,
+		"%s: ireq = %p\n",
 		__func__,
-		request);
-
-	/* Get the host_to_dev_fis from the core and copy
-	 * the fis from the task into it.
-	 */
-	register_fis = isci_sata_task_to_fis_copy(task);
+		ireq);
 
-	status = sci_io_request_construct_basic_sata(request);
+	memcpy(fis, &task->ata_task.fis, sizeof(struct host_to_dev_fis));
+	if (!task->ata_task.device_control_reg_update)
+		fis->flags |= 0x80;
+	fis->flags &= 0xF0;
 
-	/* Set the ncq tag in the fis, from the queue
-	 * command in the task.
-	 */
-	if (isci_sata_is_task_ncq(task)) {
+	status = sci_io_request_construct_basic_sata(ireq);
 
-		isci_sata_set_ncq_tag(
-			register_fis,
-			task
-			);
+	if (qc && (qc->tf.command == ATA_CMD_FPDMA_WRITE ||
+		   qc->tf.command == ATA_CMD_FPDMA_READ)) {
+		fis->sector_count = qc->tag << 3;
+		ireq->tc->type.stp.ncq_tag = qc->tag;
 	}
 
 	return status;

commit 34a991587a5cc9f78960c2c9beea217866458c41
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Jul 1 02:25:15 2011 -0700

    isci: kill 'get/set' macros
    
    Most of these simple dereference macros are longer than their open coded
    equivalent.  Deleting enum sci_controller_mode is thrown in for good
    measure.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index bcb3c08c19a7..7c500bb6a8e0 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -211,22 +211,21 @@ static void scu_ssp_reqeust_construct_task_context(
 	struct isci_remote_device *idev;
 	struct isci_port *iport;
 
-	idev = sci_request_get_device(ireq);
-	iport = sci_request_get_port(ireq);
+	idev = ireq->target_device;
+	iport = idev->owning_port;
 
 	/* Fill in the TC with the its required data */
 	task_context->abort = 0;
 	task_context->priority = 0;
 	task_context->initiator_request = 1;
 	task_context->connection_rate = idev->connection_rate;
-	task_context->protocol_engine_index =
-		sci_controller_get_protocol_engine_group(controller);
-	task_context->logical_port_index = sci_port_get_index(iport);
+	task_context->protocol_engine_index = ISCI_PEG;
+	task_context->logical_port_index = iport->physical_port_index;
 	task_context->protocol_type = SCU_TASK_CONTEXT_PROTOCOL_SSP;
 	task_context->valid = SCU_TASK_CONTEXT_VALID;
 	task_context->context_type = SCU_TASK_CONTEXT_TYPE;
 
-	task_context->remote_node_index = sci_remote_device_get_index(idev);
+	task_context->remote_node_index = idev->rnc.remote_node_index;
 	task_context->command_code = 0;
 
 	task_context->link_layer_control = 0;
@@ -242,9 +241,8 @@ static void scu_ssp_reqeust_construct_task_context(
 	task_context->task_phase = 0x01;
 
 	ireq->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
-			      (sci_controller_get_protocol_engine_group(controller) <<
-			       SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
-			      (sci_port_get_index(iport) <<
+			      (ISCI_PEG << SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
+			      (iport->physical_port_index <<
 			       SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
 			      ISCI_TAG_TCI(ireq->io_tag));
 
@@ -349,23 +347,21 @@ static void scu_sata_reqeust_construct_task_context(
 	struct isci_remote_device *idev;
 	struct isci_port *iport;
 
-	idev = sci_request_get_device(ireq);
-	iport = sci_request_get_port(ireq);
+	idev = ireq->target_device;
+	iport = idev->owning_port;
 
 	/* Fill in the TC with the its required data */
 	task_context->abort = 0;
 	task_context->priority = SCU_TASK_PRIORITY_NORMAL;
 	task_context->initiator_request = 1;
 	task_context->connection_rate = idev->connection_rate;
-	task_context->protocol_engine_index =
-		sci_controller_get_protocol_engine_group(controller);
-	task_context->logical_port_index =
-		sci_port_get_index(iport);
+	task_context->protocol_engine_index = ISCI_PEG;
+	task_context->logical_port_index = iport->physical_port_index;
 	task_context->protocol_type = SCU_TASK_CONTEXT_PROTOCOL_STP;
 	task_context->valid = SCU_TASK_CONTEXT_VALID;
 	task_context->context_type = SCU_TASK_CONTEXT_TYPE;
 
-	task_context->remote_node_index = sci_remote_device_get_index(idev);
+	task_context->remote_node_index = idev->rnc.remote_node_index;
 	task_context->command_code = 0;
 
 	task_context->link_layer_control = 0;
@@ -385,11 +381,10 @@ static void scu_sata_reqeust_construct_task_context(
 	task_context->type.words[0] = *(u32 *)&ireq->stp.cmd;
 
 	ireq->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
-				 (sci_controller_get_protocol_engine_group(controller) <<
-				  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
-				 (sci_port_get_index(iport) <<
-				  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
-				 ISCI_TAG_TCI(ireq->io_tag));
+			      (ISCI_PEG << SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
+			      (iport->physical_port_index <<
+			       SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
+			      ISCI_TAG_TCI(ireq->io_tag));
 	/*
 	 * Copy the physical address for the command buffer to the SCU Task
 	 * Context. We must offset the command buffer by 4 bytes because the
@@ -716,10 +711,8 @@ sci_io_request_terminate(struct isci_request *ireq)
 
 	switch (state) {
 	case SCI_REQ_CONSTRUCTED:
-		sci_request_set_status(ireq,
-			SCU_TASK_DONE_TASK_ABORT,
-			SCI_FAILURE_IO_TERMINATED);
-
+		ireq->scu_status = SCU_TASK_DONE_TASK_ABORT;
+		ireq->sci_status = SCI_FAILURE_IO_TERMINATED;
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		return SCI_SUCCESS;
 	case SCI_REQ_STARTED:
@@ -848,9 +841,8 @@ request_started_state_tc_event(struct isci_request *ireq,
 	 */
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		sci_request_set_status(ireq,
-					    SCU_TASK_DONE_GOOD,
-					    SCI_SUCCESS);
+		ireq->scu_status = SCU_TASK_DONE_GOOD;
+		ireq->sci_status = SCI_SUCCESS;
 		break;
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_EARLY_RESP): {
 		/* There are times when the SCU hardware will return an early
@@ -868,13 +860,11 @@ request_started_state_tc_event(struct isci_request *ireq,
 			       word_cnt);
 
 		if (resp->status == 0) {
-			sci_request_set_status(ireq,
-						    SCU_TASK_DONE_GOOD,
-						    SCI_SUCCESS_IO_DONE_EARLY);
+			ireq->scu_status = SCU_TASK_DONE_GOOD;
+			ireq->sci_status = SCI_SUCCESS_IO_DONE_EARLY;
 		} else {
-			sci_request_set_status(ireq,
-						    SCU_TASK_DONE_CHECK_RESPONSE,
-						    SCI_FAILURE_IO_RESPONSE_VALID);
+			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
+			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
 		}
 		break;
 	}
@@ -885,9 +875,8 @@ request_started_state_tc_event(struct isci_request *ireq,
 			       &ireq->ssp.rsp,
 			       word_cnt);
 
-		sci_request_set_status(ireq,
-					    SCU_TASK_DONE_CHECK_RESPONSE,
-					    SCI_FAILURE_IO_RESPONSE_VALID);
+		ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
+		ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
 		break;
 	}
 
@@ -900,13 +889,12 @@ request_started_state_tc_event(struct isci_request *ireq,
 		datapres = resp_iu->datapres;
 
 		if (datapres == 1 || datapres == 2) {
-			sci_request_set_status(ireq,
-						    SCU_TASK_DONE_CHECK_RESPONSE,
-						    SCI_FAILURE_IO_RESPONSE_VALID);
-		} else
-			sci_request_set_status(ireq,
-						    SCU_TASK_DONE_GOOD,
-						    SCI_SUCCESS);
+			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
+			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
+		} else {
+			ireq->scu_status = SCU_TASK_DONE_GOOD;
+			ireq->sci_status = SCI_SUCCESS;
+		}
 		break;
 	/* only stp device gets suspended. */
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_ACK_NAK_TO):
@@ -921,15 +909,13 @@ request_started_state_tc_event(struct isci_request *ireq,
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_REG_ERR):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SDB_ERR):
 		if (ireq->protocol == SCIC_STP_PROTOCOL) {
-			sci_request_set_status(ireq,
-				SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
-				SCU_COMPLETION_TL_STATUS_SHIFT,
-				SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED);
+			ireq->scu_status = SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
+					   SCU_COMPLETION_TL_STATUS_SHIFT;
+			ireq->sci_status = SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED;
 		} else {
-			sci_request_set_status(ireq,
-				SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
-				SCU_COMPLETION_TL_STATUS_SHIFT,
-				SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
+			ireq->scu_status = SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
+					   SCU_COMPLETION_TL_STATUS_SHIFT;
+			ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
 		}
 		break;
 
@@ -944,10 +930,9 @@ request_started_state_tc_event(struct isci_request *ireq,
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_STP_RESOURCES_BUSY):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_PROTOCOL_NOT_SUPPORTED):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_CONNECTION_RATE_NOT_SUPPORTED):
-		sci_request_set_status(ireq,
-					    SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
-					    SCU_COMPLETION_TL_STATUS_SHIFT,
-					    SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED);
+		ireq->scu_status = SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
+				   SCU_COMPLETION_TL_STATUS_SHIFT;
+		ireq->sci_status = SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED;
 		break;
 
 	/* neither ssp nor stp gets suspended. */
@@ -967,11 +952,9 @@ request_started_state_tc_event(struct isci_request *ireq,
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_IIT_ENTRY_NV):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_RNCNV_OUTBOUND):
 	default:
-		sci_request_set_status(
-			ireq,
-			SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
-			SCU_COMPLETION_TL_STATUS_SHIFT,
-			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
+		ireq->scu_status = SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
+				   SCU_COMPLETION_TL_STATUS_SHIFT;
+		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
 		break;
 	}
 
@@ -991,9 +974,8 @@ request_aborting_state_tc_event(struct isci_request *ireq,
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case (SCU_TASK_DONE_GOOD << SCU_COMPLETION_TL_STATUS_SHIFT):
 	case (SCU_TASK_DONE_TASK_ABORT << SCU_COMPLETION_TL_STATUS_SHIFT):
-		sci_request_set_status(ireq, SCU_TASK_DONE_TASK_ABORT,
-					    SCI_FAILURE_IO_TERMINATED);
-
+		ireq->scu_status = SCU_TASK_DONE_TASK_ABORT;
+		ireq->sci_status = SCI_FAILURE_IO_TERMINATED;
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 
@@ -1012,9 +994,8 @@ static enum sci_status ssp_task_request_await_tc_event(struct isci_request *ireq
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		sci_request_set_status(ireq, SCU_TASK_DONE_GOOD,
-					    SCI_SUCCESS);
-
+		ireq->scu_status = SCU_TASK_DONE_GOOD;
+		ireq->sci_status = SCI_SUCCESS;
 		sci_change_state(&ireq->sm, SCI_REQ_TASK_WAIT_TC_RESP);
 		break;
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_ACK_NAK_TO):
@@ -1036,10 +1017,8 @@ static enum sci_status ssp_task_request_await_tc_event(struct isci_request *ireq
 		 * If a NAK was received, then it is up to the user to retry
 		 * the request.
 		 */
-		sci_request_set_status(ireq,
-			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
-
+		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
+		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
@@ -1057,12 +1036,10 @@ smp_request_await_response_tc_event(struct isci_request *ireq,
 		 * unexpected.  but if the TC has success status, we
 		 * complete the IO anyway.
 		 */
-		sci_request_set_status(ireq, SCU_TASK_DONE_GOOD,
-					    SCI_SUCCESS);
-
+		ireq->scu_status = SCU_TASK_DONE_GOOD;
+		ireq->sci_status = SCI_SUCCESS;
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
-
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_RESP_TO_ERR):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_UFI_ERR):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_FRM_TYPE_ERR):
@@ -1074,20 +1051,16 @@ smp_request_await_response_tc_event(struct isci_request *ireq,
 		 * these SMP_XXX_XX_ERR status. For these type of error,
 		 * we ask ihost user to retry the request.
 		 */
-		sci_request_set_status(ireq, SCU_TASK_DONE_SMP_RESP_TO_ERR,
-					    SCI_FAILURE_RETRY_REQUIRED);
-
+		ireq->scu_status = SCU_TASK_DONE_SMP_RESP_TO_ERR;
+		ireq->sci_status = SCI_FAILURE_RETRY_REQUIRED;
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
-
 	default:
 		/* All other completion status cause the IO to be complete.  If a NAK
 		 * was received, then it is up to the user to retry the request
 		 */
-		sci_request_set_status(ireq,
-					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
-
+		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
+		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
@@ -1101,9 +1074,8 @@ smp_request_await_tc_event(struct isci_request *ireq,
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		sci_request_set_status(ireq, SCU_TASK_DONE_GOOD,
-					    SCI_SUCCESS);
-
+		ireq->scu_status = SCU_TASK_DONE_GOOD;
+		ireq->sci_status = SCI_SUCCESS;
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	default:
@@ -1111,10 +1083,8 @@ smp_request_await_tc_event(struct isci_request *ireq,
 		 * complete.  If a NAK was received, then it is up to
 		 * the user to retry the request.
 		 */
-		sci_request_set_status(ireq,
-					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
-
+		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
+		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
@@ -1171,9 +1141,8 @@ stp_request_non_data_await_h2d_tc_event(struct isci_request *ireq,
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		sci_request_set_status(ireq, SCU_TASK_DONE_GOOD,
-					    SCI_SUCCESS);
-
+		ireq->scu_status = SCU_TASK_DONE_GOOD;
+		ireq->sci_status = SCI_SUCCESS;
 		sci_change_state(&ireq->sm, SCI_REQ_STP_NON_DATA_WAIT_D2H);
 		break;
 
@@ -1182,10 +1151,8 @@ stp_request_non_data_await_h2d_tc_event(struct isci_request *ireq,
 		 * complete.  If a NAK was received, then it is up to
 		 * the user to retry the request.
 		 */
-		sci_request_set_status(ireq,
-					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
-
+		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
+		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
@@ -1363,10 +1330,8 @@ stp_request_pio_await_h2d_completion_tc_event(struct isci_request *ireq,
 
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		sci_request_set_status(ireq,
-					    SCU_TASK_DONE_GOOD,
-					    SCI_SUCCESS);
-
+		ireq->scu_status = SCU_TASK_DONE_GOOD;
+		ireq->sci_status = SCI_SUCCESS;
 		sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
 		break;
 
@@ -1375,10 +1340,8 @@ stp_request_pio_await_h2d_completion_tc_event(struct isci_request *ireq,
 		 * complete.  If a NAK was received, then it is up to
 		 * the user to retry the request.
 		 */
-		sci_request_set_status(ireq,
-					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
-
+		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
+		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
@@ -1426,11 +1389,8 @@ pio_data_out_tx_done_tc_event(struct isci_request *ireq,
 		 * If a NAK was received, then it is up to the user to retry
 		 * the request.
 		 */
-		sci_request_set_status(
-			ireq,
-			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
-
+		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
+		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
@@ -1438,15 +1398,6 @@ pio_data_out_tx_done_tc_event(struct isci_request *ireq,
 	return status;
 }
 
-static void sci_stp_request_udma_complete_request(
-	struct isci_request *ireq,
-	u32 scu_status,
-	enum sci_status sci_status)
-{
-	sci_request_set_status(ireq, scu_status, sci_status);
-	sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
-}
-
 static enum sci_status sci_stp_request_udma_general_frame_handler(struct isci_request *ireq,
 								       u32 frame_index)
 {
@@ -1512,13 +1463,12 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 
 			if (resp_iu->datapres == 0x01 ||
 			    resp_iu->datapres == 0x02) {
-				sci_request_set_status(ireq,
-							    SCU_TASK_DONE_CHECK_RESPONSE,
-							    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
-			} else
-				sci_request_set_status(ireq,
-							    SCU_TASK_DONE_GOOD,
-							    SCI_SUCCESS);
+				ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
+				ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
+			} else {
+				ireq->scu_status = SCU_TASK_DONE_GOOD;
+				ireq->sci_status = SCI_SUCCESS;
+			}
 		} else {
 			/* not a response frame, why did it get forwarded? */
 			dev_err(&ihost->pdev->dev,
@@ -1567,9 +1517,8 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 			sci_swab32_cpy(((u8 *) rsp_hdr) + SMP_RESP_HDR_SZ,
 				       smp_resp, word_cnt);
 
-			sci_request_set_status(ireq, SCU_TASK_DONE_GOOD,
-						    SCI_SUCCESS);
-
+			ireq->scu_status = SCU_TASK_DONE_GOOD;
+			ireq->sci_status = SCI_SUCCESS;
 			sci_change_state(&ireq->sm, SCI_REQ_SMP_WAIT_TC_COMP);
 		} else {
 			/*
@@ -1584,10 +1533,8 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 				frame_index,
 				rsp_hdr->frame_type);
 
-			sci_request_set_status(ireq,
-						    SCU_TASK_DONE_SMP_FRM_TYPE_ERR,
-						    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
-
+			ireq->scu_status = SCU_TASK_DONE_SMP_FRM_TYPE_ERR;
+			ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
 			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		}
 
@@ -1602,16 +1549,14 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 
 	case SCI_REQ_STP_UDMA_WAIT_D2H:
 		/* Use the general frame handler to copy the resposne data */
-		status = sci_stp_request_udma_general_frame_handler(ireq,
-									 frame_index);
+		status = sci_stp_request_udma_general_frame_handler(ireq, frame_index);
 
 		if (status != SCI_SUCCESS)
 			return status;
 
-		sci_stp_request_udma_complete_request(ireq,
-							   SCU_TASK_DONE_CHECK_RESPONSE,
-							   SCI_FAILURE_IO_RESPONSE_VALID);
-
+		ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
+		ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		return SCI_SUCCESS;
 
 	case SCI_REQ_STP_NON_DATA_WAIT_D2H: {
@@ -1645,8 +1590,8 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 							       frame_buffer);
 
 			/* The command has completed with error */
-			sci_request_set_status(ireq, SCU_TASK_DONE_CHECK_RESPONSE,
-						    SCI_FAILURE_IO_RESPONSE_VALID);
+			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
+			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
 			break;
 
 		default:
@@ -1655,8 +1600,8 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 				  "violation occurred\n", __func__, stp_req,
 				  frame_index);
 
-			sci_request_set_status(ireq, SCU_TASK_DONE_UNEXP_FIS,
-						    SCI_FAILURE_PROTOCOL_VIOLATION);
+			ireq->scu_status = SCU_TASK_DONE_UNEXP_FIS;
+			ireq->sci_status = SCI_FAILURE_PROTOCOL_VIOLATION;
 			break;
 		}
 
@@ -1753,10 +1698,8 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 							       frame_header,
 							       frame_buffer);
 
-			sci_request_set_status(ireq,
-						    SCU_TASK_DONE_CHECK_RESPONSE,
-						    SCI_FAILURE_IO_RESPONSE_VALID);
-
+			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
+			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
 			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 			break;
 
@@ -1800,10 +1743,8 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 				frame_index,
 				frame_header->fis_type);
 
-			sci_request_set_status(ireq,
-						    SCU_TASK_DONE_GOOD,
-						    SCI_FAILURE_IO_REQUIRES_SCSI_ABORT);
-
+			ireq->scu_status = SCU_TASK_DONE_GOOD;
+			ireq->sci_status = SCI_FAILURE_IO_REQUIRES_SCSI_ABORT;
 			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 
 			/* Frame is decoded return it to the controller */
@@ -1833,10 +1774,8 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 			return status;
 
 		if ((stp_req->status & ATA_BUSY) == 0) {
-			sci_request_set_status(ireq,
-						    SCU_TASK_DONE_CHECK_RESPONSE,
-						    SCI_FAILURE_IO_RESPONSE_VALID);
-
+			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
+			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
 			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		} else {
 			sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
@@ -1873,9 +1812,8 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 							       frame_buffer);
 
 			/* The command has completed with error */
-			sci_request_set_status(ireq,
-						    SCU_TASK_DONE_CHECK_RESPONSE,
-						    SCI_FAILURE_IO_RESPONSE_VALID);
+			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
+			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
 			break;
 
 		default:
@@ -1886,9 +1824,8 @@ sci_io_request_frame_handler(struct isci_request *ireq,
 				 stp_req,
 				 frame_index);
 
-			sci_request_set_status(ireq,
-						    SCU_TASK_DONE_UNEXP_FIS,
-						    SCI_FAILURE_PROTOCOL_VIOLATION);
+			ireq->scu_status = SCU_TASK_DONE_UNEXP_FIS;
+			ireq->sci_status = SCI_FAILURE_PROTOCOL_VIOLATION;
 			break;
 		}
 
@@ -1927,9 +1864,9 @@ static enum sci_status stp_request_udma_await_tc_event(struct isci_request *ireq
 
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		sci_stp_request_udma_complete_request(ireq,
-							   SCU_TASK_DONE_GOOD,
-							   SCI_SUCCESS);
+		ireq->scu_status = SCU_TASK_DONE_GOOD;
+		ireq->sci_status = SCI_SUCCESS;
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_UNEXP_FIS):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_REG_ERR):
@@ -1941,9 +1878,9 @@ static enum sci_status stp_request_udma_await_tc_event(struct isci_request *ireq
 			sci_remote_device_suspend(ireq->target_device,
 				SCU_EVENT_SPECIFIC(SCU_NORMALIZE_COMPLETION_STATUS(completion_code)));
 
-			sci_stp_request_udma_complete_request(ireq,
-								   SCU_TASK_DONE_CHECK_RESPONSE,
-								   SCI_FAILURE_IO_RESPONSE_VALID);
+			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
+			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
+			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		} else {
 			/* If we have an error completion status for the
 			 * TC then we can expect a D2H register FIS from
@@ -1970,9 +1907,9 @@ static enum sci_status stp_request_udma_await_tc_event(struct isci_request *ireq
 	/* Fall through to the default case */
 	default:
 		/* All other completion status cause the IO to be complete. */
-		sci_stp_request_udma_complete_request(ireq,
-					SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-					SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
+		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
+		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
@@ -1985,9 +1922,8 @@ stp_request_soft_reset_await_h2d_asserted_tc_event(struct isci_request *ireq,
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		sci_request_set_status(ireq, SCU_TASK_DONE_GOOD,
-					    SCI_SUCCESS);
-
+		ireq->scu_status = SCU_TASK_DONE_GOOD;
+		ireq->sci_status = SCI_SUCCESS;
 		sci_change_state(&ireq->sm, SCI_REQ_STP_SOFT_RESET_WAIT_H2D_DIAG);
 		break;
 
@@ -1997,10 +1933,8 @@ stp_request_soft_reset_await_h2d_asserted_tc_event(struct isci_request *ireq,
 		 * If a NAK was received, then it is up to the user to retry
 		 * the request.
 		 */
-		sci_request_set_status(ireq,
-					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
-
+		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
+		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
@@ -2014,9 +1948,8 @@ stp_request_soft_reset_await_h2d_diagnostic_tc_event(struct isci_request *ireq,
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		sci_request_set_status(ireq, SCU_TASK_DONE_GOOD,
-					    SCI_SUCCESS);
-
+		ireq->scu_status = SCU_TASK_DONE_GOOD;
+		ireq->sci_status = SCI_SUCCESS;
 		sci_change_state(&ireq->sm, SCI_REQ_STP_SOFT_RESET_WAIT_D2H);
 		break;
 
@@ -2025,10 +1958,8 @@ stp_request_soft_reset_await_h2d_diagnostic_tc_event(struct isci_request *ireq,
 		 * a NAK was received, then it is up to the user to retry the
 		 * request.
 		 */
-		sci_request_set_status(ireq,
-			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
-
+		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
+		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
@@ -2504,7 +2435,7 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 		completion_status);
 
 	spin_lock(&request->state_lock);
-	request_status = isci_request_get_state(request);
+	request_status = request->status;
 
 	/* Decode the request status.  Note that if the request has been
 	 * aborted by a task management function, we don't care
@@ -2904,24 +2835,21 @@ static void sci_stp_request_started_non_data_await_h2d_completion_enter(struct s
 {
 	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
 
-	sci_remote_device_set_working_request(ireq->target_device,
-						   ireq);
+	ireq->target_device->working_request = ireq;
 }
 
 static void sci_stp_request_started_pio_await_h2d_completion_enter(struct sci_base_state_machine *sm)
 {
 	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
 
-	sci_remote_device_set_working_request(ireq->target_device,
-						   ireq);
+	ireq->target_device->working_request = ireq;
 }
 
 static void sci_stp_request_started_soft_reset_await_h2d_asserted_completion_enter(struct sci_base_state_machine *sm)
 {
 	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
 
-	sci_remote_device_set_working_request(ireq->target_device,
-						   ireq);
+	ireq->target_device->working_request = ireq;
 }
 
 static void sci_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter(struct sci_base_state_machine *sm)
@@ -3141,8 +3069,8 @@ sci_io_request_construct_smp(struct device *dev,
 
 	task_context = ireq->tc;
 
-	idev = sci_request_get_device(ireq);
-	iport = sci_request_get_port(ireq);
+	idev = ireq->target_device;
+	iport = idev->owning_port;
 
 	/*
 	 * Fill in the TC with the its required data
@@ -3151,9 +3079,8 @@ sci_io_request_construct_smp(struct device *dev,
 	task_context->priority = 0;
 	task_context->initiator_request = 1;
 	task_context->connection_rate = idev->connection_rate;
-	task_context->protocol_engine_index =
-		sci_controller_get_protocol_engine_group(ihost);
-	task_context->logical_port_index = sci_port_get_index(iport);
+	task_context->protocol_engine_index = ISCI_PEG;
+	task_context->logical_port_index = iport->physical_port_index;
 	task_context->protocol_type = SCU_TASK_CONTEXT_PROTOCOL_SMP;
 	task_context->abort = 0;
 	task_context->valid = SCU_TASK_CONTEXT_VALID;
@@ -3195,11 +3122,10 @@ sci_io_request_construct_smp(struct device *dev,
 	task_context->task_phase = 0;
 
 	ireq->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
-				 (sci_controller_get_protocol_engine_group(ihost) <<
-				  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
-				 (sci_port_get_index(iport) <<
-				  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
-				 ISCI_TAG_TCI(ireq->io_tag));
+			      (ISCI_PEG << SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
+			       (iport->physical_port_index <<
+				SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
+			      ISCI_TAG_TCI(ireq->io_tag));
 	/*
 	 * Copy the physical address for the command buffer to the SCU Task
 	 * Context command buffer should not contain command header.

commit 89a7301f21fb00e753089671eb9e4132aab8ea08
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Jun 30 19:14:33 2011 -0700

    isci: retire scic_sds_ and scic_ prefixes
    
    The distinction between scic_sds_ scic_ and sci_ are no longer relevant
    so just unify the prefixes on sci_.  The distinction between isci_ and
    sci_ is historically significant, and useful for comparing the old
    'core' to the current Linux driver. 'sci_' represents the former core as
    well as the routines that are closer to the hardware and protocol than
    their 'isci_' brethren. sci == sas controller interface.
    
    Also unwind the 'sds1' out of the parameter structs.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 36e674896bc5..bcb3c08c19a7 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -89,7 +89,7 @@ static dma_addr_t to_sgl_element_pair_dma(struct isci_host *ihost,
 		return ihost->task_context_dma + offset;
 	}
 
-	return scic_io_request_get_dma_addr(ireq, &ireq->sg_table[idx - 2]);
+	return sci_io_request_get_dma_addr(ireq, &ireq->sg_table[idx - 2]);
 }
 
 static void init_sgl_element(struct scu_sgl_element *e, struct scatterlist *sg)
@@ -100,7 +100,7 @@ static void init_sgl_element(struct scu_sgl_element *e, struct scatterlist *sg)
 	e->address_modifier = 0;
 }
 
-static void scic_sds_request_build_sgl(struct isci_request *ireq)
+static void sci_request_build_sgl(struct isci_request *ireq)
 {
 	struct isci_host *ihost = ireq->isci_host;
 	struct sas_task *task = isci_request_access_task(ireq);
@@ -158,7 +158,7 @@ static void scic_sds_request_build_sgl(struct isci_request *ireq)
 	}
 }
 
-static void scic_sds_io_request_build_ssp_command_iu(struct isci_request *ireq)
+static void sci_io_request_build_ssp_command_iu(struct isci_request *ireq)
 {
 	struct ssp_cmd_iu *cmd_iu;
 	struct sas_task *task = isci_request_access_task(ireq);
@@ -178,7 +178,7 @@ static void scic_sds_io_request_build_ssp_command_iu(struct isci_request *ireq)
 		       sizeof(task->ssp_task.cdb) / sizeof(u32));
 }
 
-static void scic_sds_task_request_build_ssp_task_iu(struct isci_request *ireq)
+static void sci_task_request_build_ssp_task_iu(struct isci_request *ireq)
 {
 	struct ssp_task_iu *task_iu;
 	struct sas_task *task = isci_request_access_task(ireq);
@@ -211,8 +211,8 @@ static void scu_ssp_reqeust_construct_task_context(
 	struct isci_remote_device *idev;
 	struct isci_port *iport;
 
-	idev = scic_sds_request_get_device(ireq);
-	iport = scic_sds_request_get_port(ireq);
+	idev = sci_request_get_device(ireq);
+	iport = sci_request_get_port(ireq);
 
 	/* Fill in the TC with the its required data */
 	task_context->abort = 0;
@@ -220,13 +220,13 @@ static void scu_ssp_reqeust_construct_task_context(
 	task_context->initiator_request = 1;
 	task_context->connection_rate = idev->connection_rate;
 	task_context->protocol_engine_index =
-		scic_sds_controller_get_protocol_engine_group(controller);
-	task_context->logical_port_index = scic_sds_port_get_index(iport);
+		sci_controller_get_protocol_engine_group(controller);
+	task_context->logical_port_index = sci_port_get_index(iport);
 	task_context->protocol_type = SCU_TASK_CONTEXT_PROTOCOL_SSP;
 	task_context->valid = SCU_TASK_CONTEXT_VALID;
 	task_context->context_type = SCU_TASK_CONTEXT_TYPE;
 
-	task_context->remote_node_index = scic_sds_remote_device_get_index(idev);
+	task_context->remote_node_index = sci_remote_device_get_index(idev);
 	task_context->command_code = 0;
 
 	task_context->link_layer_control = 0;
@@ -242,9 +242,9 @@ static void scu_ssp_reqeust_construct_task_context(
 	task_context->task_phase = 0x01;
 
 	ireq->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
-			      (scic_sds_controller_get_protocol_engine_group(controller) <<
+			      (sci_controller_get_protocol_engine_group(controller) <<
 			       SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
-			      (scic_sds_port_get_index(iport) <<
+			      (sci_port_get_index(iport) <<
 			       SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
 			      ISCI_TAG_TCI(ireq->io_tag));
 
@@ -252,7 +252,7 @@ static void scu_ssp_reqeust_construct_task_context(
 	 * Copy the physical address for the command buffer to the
 	 * SCU Task Context
 	 */
-	dma_addr = scic_io_request_get_dma_addr(ireq, &ireq->ssp.cmd);
+	dma_addr = sci_io_request_get_dma_addr(ireq, &ireq->ssp.cmd);
 
 	task_context->command_iu_upper = upper_32_bits(dma_addr);
 	task_context->command_iu_lower = lower_32_bits(dma_addr);
@@ -261,7 +261,7 @@ static void scu_ssp_reqeust_construct_task_context(
 	 * Copy the physical address for the response buffer to the
 	 * SCU Task Context
 	 */
-	dma_addr = scic_io_request_get_dma_addr(ireq, &ireq->ssp.rsp);
+	dma_addr = sci_io_request_get_dma_addr(ireq, &ireq->ssp.rsp);
 
 	task_context->response_iu_upper = upper_32_bits(dma_addr);
 	task_context->response_iu_lower = lower_32_bits(dma_addr);
@@ -298,7 +298,7 @@ static void scu_ssp_io_request_construct_task_context(struct isci_request *ireq,
 	task_context->transfer_length_bytes = len;
 
 	if (task_context->transfer_length_bytes > 0)
-		scic_sds_request_build_sgl(ireq);
+		sci_request_build_sgl(ireq);
 }
 
 /**
@@ -349,8 +349,8 @@ static void scu_sata_reqeust_construct_task_context(
 	struct isci_remote_device *idev;
 	struct isci_port *iport;
 
-	idev = scic_sds_request_get_device(ireq);
-	iport = scic_sds_request_get_port(ireq);
+	idev = sci_request_get_device(ireq);
+	iport = sci_request_get_port(ireq);
 
 	/* Fill in the TC with the its required data */
 	task_context->abort = 0;
@@ -358,14 +358,14 @@ static void scu_sata_reqeust_construct_task_context(
 	task_context->initiator_request = 1;
 	task_context->connection_rate = idev->connection_rate;
 	task_context->protocol_engine_index =
-		scic_sds_controller_get_protocol_engine_group(controller);
+		sci_controller_get_protocol_engine_group(controller);
 	task_context->logical_port_index =
-		scic_sds_port_get_index(iport);
+		sci_port_get_index(iport);
 	task_context->protocol_type = SCU_TASK_CONTEXT_PROTOCOL_STP;
 	task_context->valid = SCU_TASK_CONTEXT_VALID;
 	task_context->context_type = SCU_TASK_CONTEXT_TYPE;
 
-	task_context->remote_node_index = scic_sds_remote_device_get_index(idev);
+	task_context->remote_node_index = sci_remote_device_get_index(idev);
 	task_context->command_code = 0;
 
 	task_context->link_layer_control = 0;
@@ -385,9 +385,9 @@ static void scu_sata_reqeust_construct_task_context(
 	task_context->type.words[0] = *(u32 *)&ireq->stp.cmd;
 
 	ireq->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
-				 (scic_sds_controller_get_protocol_engine_group(controller) <<
+				 (sci_controller_get_protocol_engine_group(controller) <<
 				  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
-				 (scic_sds_port_get_index(iport) <<
+				 (sci_port_get_index(iport) <<
 				  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
 				 ISCI_TAG_TCI(ireq->io_tag));
 	/*
@@ -395,7 +395,7 @@ static void scu_sata_reqeust_construct_task_context(
 	 * Context. We must offset the command buffer by 4 bytes because the
 	 * first 4 bytes are transfered in the body of the TC.
 	 */
-	dma_addr = scic_io_request_get_dma_addr(ireq,
+	dma_addr = sci_io_request_get_dma_addr(ireq,
 						((char *) &ireq->stp.cmd) +
 						sizeof(u32));
 
@@ -420,7 +420,7 @@ static void scu_stp_raw_request_construct_task_context(struct isci_request *ireq
 	task_context->transfer_length_bytes = sizeof(struct host_to_dev_fis) - sizeof(u32);
 }
 
-static enum sci_status scic_sds_stp_pio_request_construct(struct isci_request *ireq,
+static enum sci_status sci_stp_pio_request_construct(struct isci_request *ireq,
 							  bool copy_rx_frame)
 {
 	struct isci_stp_request *stp_req = &ireq->stp.req;
@@ -432,7 +432,7 @@ static enum sci_status scic_sds_stp_pio_request_construct(struct isci_request *i
 	stp_req->sgl.set = SCU_SGL_ELEMENT_PAIR_A;
 
 	if (copy_rx_frame) {
-		scic_sds_request_build_sgl(ireq);
+		sci_request_build_sgl(ireq);
 		stp_req->sgl.index = 0;
 	} else {
 		/* The user does not want the data copied to the SGL buffer location */
@@ -454,7 +454,7 @@ static enum sci_status scic_sds_stp_pio_request_construct(struct isci_request *i
  * requests that are optimized by the silicon (i.e. UDMA, NCQ). This method
  * returns an indication as to whether the construction was successful.
  */
-static void scic_sds_stp_optimized_request_construct(struct isci_request *ireq,
+static void sci_stp_optimized_request_construct(struct isci_request *ireq,
 						     u8 optimized_task_type,
 						     u32 len,
 						     enum dma_data_direction dir)
@@ -465,7 +465,7 @@ static void scic_sds_stp_optimized_request_construct(struct isci_request *ireq,
 	scu_sata_reqeust_construct_task_context(ireq, task_context);
 
 	/* Copy over the SGL elements */
-	scic_sds_request_build_sgl(ireq);
+	sci_request_build_sgl(ireq);
 
 	/* Copy over the number of bytes to be transfered */
 	task_context->transfer_length_bytes = len;
@@ -490,7 +490,7 @@ static void scic_sds_stp_optimized_request_construct(struct isci_request *ireq,
 
 
 static enum sci_status
-scic_io_request_construct_sata(struct isci_request *ireq,
+sci_io_request_construct_sata(struct isci_request *ireq,
 			       u32 len,
 			       enum dma_data_direction dir,
 			       bool copy)
@@ -533,7 +533,7 @@ scic_io_request_construct_sata(struct isci_request *ireq,
 
 	/* NCQ */
 	if (task->ata_task.use_ncq) {
-		scic_sds_stp_optimized_request_construct(ireq,
+		sci_stp_optimized_request_construct(ireq,
 							 SCU_TASK_TYPE_FPDMAQ_READ,
 							 len, dir);
 		return SCI_SUCCESS;
@@ -541,17 +541,17 @@ scic_io_request_construct_sata(struct isci_request *ireq,
 
 	/* DMA */
 	if (task->ata_task.dma_xfer) {
-		scic_sds_stp_optimized_request_construct(ireq,
+		sci_stp_optimized_request_construct(ireq,
 							 SCU_TASK_TYPE_DMA_IN,
 							 len, dir);
 		return SCI_SUCCESS;
 	} else /* PIO */
-		return scic_sds_stp_pio_request_construct(ireq, copy);
+		return sci_stp_pio_request_construct(ireq, copy);
 
 	return status;
 }
 
-static enum sci_status scic_io_request_construct_basic_ssp(struct isci_request *ireq)
+static enum sci_status sci_io_request_construct_basic_ssp(struct isci_request *ireq)
 {
 	struct sas_task *task = isci_request_access_task(ireq);
 
@@ -561,28 +561,28 @@ static enum sci_status scic_io_request_construct_basic_ssp(struct isci_request *
 						  task->data_dir,
 						  task->total_xfer_len);
 
-	scic_sds_io_request_build_ssp_command_iu(ireq);
+	sci_io_request_build_ssp_command_iu(ireq);
 
 	sci_change_state(&ireq->sm, SCI_REQ_CONSTRUCTED);
 
 	return SCI_SUCCESS;
 }
 
-enum sci_status scic_task_request_construct_ssp(
+enum sci_status sci_task_request_construct_ssp(
 	struct isci_request *ireq)
 {
 	/* Construct the SSP Task SCU Task Context */
 	scu_ssp_task_request_construct_task_context(ireq);
 
 	/* Fill in the SSP Task IU */
-	scic_sds_task_request_build_ssp_task_iu(ireq);
+	sci_task_request_build_ssp_task_iu(ireq);
 
 	sci_change_state(&ireq->sm, SCI_REQ_CONSTRUCTED);
 
 	return SCI_SUCCESS;
 }
 
-static enum sci_status scic_io_request_construct_basic_sata(struct isci_request *ireq)
+static enum sci_status sci_io_request_construct_basic_sata(struct isci_request *ireq)
 {
 	enum sci_status status;
 	bool copy = false;
@@ -592,7 +592,7 @@ static enum sci_status scic_io_request_construct_basic_sata(struct isci_request
 
 	copy = (task->data_dir == DMA_NONE) ? false : true;
 
-	status = scic_io_request_construct_sata(ireq,
+	status = sci_io_request_construct_sata(ireq,
 						task->total_xfer_len,
 						task->data_dir,
 						copy);
@@ -603,7 +603,7 @@ static enum sci_status scic_io_request_construct_basic_sata(struct isci_request
 	return status;
 }
 
-enum sci_status scic_task_request_construct_sata(struct isci_request *ireq)
+enum sci_status sci_task_request_construct_sata(struct isci_request *ireq)
 {
 	enum sci_status status = SCI_SUCCESS;
 
@@ -648,7 +648,7 @@ static u32 sci_req_tx_bytes(struct isci_request *ireq)
 		 *   BAR1 is the scu_registers
 		 *   0x20002C = 0x200000 + 0x2c
 		 *            = start of task context SRAM + offset of (type.ssp.data_offset)
-		 *   TCi is the io_tag of struct scic_sds_request
+		 *   TCi is the io_tag of struct sci_request
 		 */
 		ret_val = readl(scu_reg_base +
 				(SCU_TASK_CONTEXT_SRAM + offsetof(struct scu_task_context, type.ssp.data_offset)) +
@@ -658,7 +658,7 @@ static u32 sci_req_tx_bytes(struct isci_request *ireq)
 	return ret_val;
 }
 
-enum sci_status scic_sds_request_start(struct isci_request *ireq)
+enum sci_status sci_request_start(struct isci_request *ireq)
 {
 	enum sci_base_request_states state;
 	struct scu_task_context *tc = ireq->tc;
@@ -708,7 +708,7 @@ enum sci_status scic_sds_request_start(struct isci_request *ireq)
 }
 
 enum sci_status
-scic_sds_io_request_terminate(struct isci_request *ireq)
+sci_io_request_terminate(struct isci_request *ireq)
 {
 	enum sci_base_request_states state;
 
@@ -716,7 +716,7 @@ scic_sds_io_request_terminate(struct isci_request *ireq)
 
 	switch (state) {
 	case SCI_REQ_CONSTRUCTED:
-		scic_sds_request_set_status(ireq,
+		sci_request_set_status(ireq,
 			SCU_TASK_DONE_TASK_ABORT,
 			SCI_FAILURE_IO_TERMINATED);
 
@@ -759,7 +759,7 @@ scic_sds_io_request_terminate(struct isci_request *ireq)
 	return SCI_FAILURE_INVALID_STATE;
 }
 
-enum sci_status scic_sds_request_complete(struct isci_request *ireq)
+enum sci_status sci_request_complete(struct isci_request *ireq)
 {
 	enum sci_base_request_states state;
 	struct isci_host *ihost = ireq->owning_controller;
@@ -770,7 +770,7 @@ enum sci_status scic_sds_request_complete(struct isci_request *ireq)
 		return SCI_FAILURE_INVALID_STATE;
 
 	if (ireq->saved_rx_frame_index != SCU_INVALID_FRAME_INDEX)
-		scic_sds_controller_release_frame(ihost,
+		sci_controller_release_frame(ihost,
 						  ireq->saved_rx_frame_index);
 
 	/* XXX can we just stop the machine and remove the 'final' state? */
@@ -778,7 +778,7 @@ enum sci_status scic_sds_request_complete(struct isci_request *ireq)
 	return SCI_SUCCESS;
 }
 
-enum sci_status scic_sds_io_request_event_handler(struct isci_request *ireq,
+enum sci_status sci_io_request_event_handler(struct isci_request *ireq,
 						  u32 event_code)
 {
 	enum sci_base_request_states state;
@@ -818,7 +818,7 @@ enum sci_status scic_sds_io_request_event_handler(struct isci_request *ireq,
  * @sci_req: This parameter specifies the request object for which to copy
  *    the response data.
  */
-static void scic_sds_io_request_copy_response(struct isci_request *ireq)
+static void sci_io_request_copy_response(struct isci_request *ireq)
 {
 	void *resp_buf;
 	u32 len;
@@ -848,7 +848,7 @@ request_started_state_tc_event(struct isci_request *ireq,
 	 */
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(ireq,
+		sci_request_set_status(ireq,
 					    SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 		break;
@@ -868,11 +868,11 @@ request_started_state_tc_event(struct isci_request *ireq,
 			       word_cnt);
 
 		if (resp->status == 0) {
-			scic_sds_request_set_status(ireq,
+			sci_request_set_status(ireq,
 						    SCU_TASK_DONE_GOOD,
 						    SCI_SUCCESS_IO_DONE_EARLY);
 		} else {
-			scic_sds_request_set_status(ireq,
+			sci_request_set_status(ireq,
 						    SCU_TASK_DONE_CHECK_RESPONSE,
 						    SCI_FAILURE_IO_RESPONSE_VALID);
 		}
@@ -885,7 +885,7 @@ request_started_state_tc_event(struct isci_request *ireq,
 			       &ireq->ssp.rsp,
 			       word_cnt);
 
-		scic_sds_request_set_status(ireq,
+		sci_request_set_status(ireq,
 					    SCU_TASK_DONE_CHECK_RESPONSE,
 					    SCI_FAILURE_IO_RESPONSE_VALID);
 		break;
@@ -900,11 +900,11 @@ request_started_state_tc_event(struct isci_request *ireq,
 		datapres = resp_iu->datapres;
 
 		if (datapres == 1 || datapres == 2) {
-			scic_sds_request_set_status(ireq,
+			sci_request_set_status(ireq,
 						    SCU_TASK_DONE_CHECK_RESPONSE,
 						    SCI_FAILURE_IO_RESPONSE_VALID);
 		} else
-			scic_sds_request_set_status(ireq,
+			sci_request_set_status(ireq,
 						    SCU_TASK_DONE_GOOD,
 						    SCI_SUCCESS);
 		break;
@@ -921,12 +921,12 @@ request_started_state_tc_event(struct isci_request *ireq,
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_REG_ERR):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SDB_ERR):
 		if (ireq->protocol == SCIC_STP_PROTOCOL) {
-			scic_sds_request_set_status(ireq,
+			sci_request_set_status(ireq,
 				SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
 				SCU_COMPLETION_TL_STATUS_SHIFT,
 				SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED);
 		} else {
-			scic_sds_request_set_status(ireq,
+			sci_request_set_status(ireq,
 				SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
 				SCU_COMPLETION_TL_STATUS_SHIFT,
 				SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
@@ -944,7 +944,7 @@ request_started_state_tc_event(struct isci_request *ireq,
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_STP_RESOURCES_BUSY):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_PROTOCOL_NOT_SUPPORTED):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_CONNECTION_RATE_NOT_SUPPORTED):
-		scic_sds_request_set_status(ireq,
+		sci_request_set_status(ireq,
 					    SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
 					    SCU_COMPLETION_TL_STATUS_SHIFT,
 					    SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED);
@@ -967,7 +967,7 @@ request_started_state_tc_event(struct isci_request *ireq,
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_IIT_ENTRY_NV):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_RNCNV_OUTBOUND):
 	default:
-		scic_sds_request_set_status(
+		sci_request_set_status(
 			ireq,
 			SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
 			SCU_COMPLETION_TL_STATUS_SHIFT,
@@ -991,7 +991,7 @@ request_aborting_state_tc_event(struct isci_request *ireq,
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case (SCU_TASK_DONE_GOOD << SCU_COMPLETION_TL_STATUS_SHIFT):
 	case (SCU_TASK_DONE_TASK_ABORT << SCU_COMPLETION_TL_STATUS_SHIFT):
-		scic_sds_request_set_status(ireq, SCU_TASK_DONE_TASK_ABORT,
+		sci_request_set_status(ireq, SCU_TASK_DONE_TASK_ABORT,
 					    SCI_FAILURE_IO_TERMINATED);
 
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
@@ -1012,7 +1012,7 @@ static enum sci_status ssp_task_request_await_tc_event(struct isci_request *ireq
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(ireq, SCU_TASK_DONE_GOOD,
+		sci_request_set_status(ireq, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
 		sci_change_state(&ireq->sm, SCI_REQ_TASK_WAIT_TC_RESP);
@@ -1036,7 +1036,7 @@ static enum sci_status ssp_task_request_await_tc_event(struct isci_request *ireq
 		 * If a NAK was received, then it is up to the user to retry
 		 * the request.
 		 */
-		scic_sds_request_set_status(ireq,
+		sci_request_set_status(ireq,
 			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
@@ -1057,7 +1057,7 @@ smp_request_await_response_tc_event(struct isci_request *ireq,
 		 * unexpected.  but if the TC has success status, we
 		 * complete the IO anyway.
 		 */
-		scic_sds_request_set_status(ireq, SCU_TASK_DONE_GOOD,
+		sci_request_set_status(ireq, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
@@ -1074,7 +1074,7 @@ smp_request_await_response_tc_event(struct isci_request *ireq,
 		 * these SMP_XXX_XX_ERR status. For these type of error,
 		 * we ask ihost user to retry the request.
 		 */
-		scic_sds_request_set_status(ireq, SCU_TASK_DONE_SMP_RESP_TO_ERR,
+		sci_request_set_status(ireq, SCU_TASK_DONE_SMP_RESP_TO_ERR,
 					    SCI_FAILURE_RETRY_REQUIRED);
 
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
@@ -1084,7 +1084,7 @@ smp_request_await_response_tc_event(struct isci_request *ireq,
 		/* All other completion status cause the IO to be complete.  If a NAK
 		 * was received, then it is up to the user to retry the request
 		 */
-		scic_sds_request_set_status(ireq,
+		sci_request_set_status(ireq,
 					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
@@ -1101,7 +1101,7 @@ smp_request_await_tc_event(struct isci_request *ireq,
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(ireq, SCU_TASK_DONE_GOOD,
+		sci_request_set_status(ireq, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
@@ -1111,7 +1111,7 @@ smp_request_await_tc_event(struct isci_request *ireq,
 		 * complete.  If a NAK was received, then it is up to
 		 * the user to retry the request.
 		 */
-		scic_sds_request_set_status(ireq,
+		sci_request_set_status(ireq,
 					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
@@ -1122,7 +1122,7 @@ smp_request_await_tc_event(struct isci_request *ireq,
 	return SCI_SUCCESS;
 }
 
-void scic_stp_io_request_set_ncq_tag(struct isci_request *ireq,
+void sci_stp_io_request_set_ncq_tag(struct isci_request *ireq,
 				     u16 ncq_tag)
 {
 	/**
@@ -1171,7 +1171,7 @@ stp_request_non_data_await_h2d_tc_event(struct isci_request *ireq,
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(ireq, SCU_TASK_DONE_GOOD,
+		sci_request_set_status(ireq, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
 		sci_change_state(&ireq->sm, SCI_REQ_STP_NON_DATA_WAIT_D2H);
@@ -1182,7 +1182,7 @@ stp_request_non_data_await_h2d_tc_event(struct isci_request *ireq,
 		 * complete.  If a NAK was received, then it is up to
 		 * the user to retry the request.
 		 */
-		scic_sds_request_set_status(ireq,
+		sci_request_set_status(ireq,
 					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
@@ -1198,7 +1198,7 @@ stp_request_non_data_await_h2d_tc_event(struct isci_request *ireq,
 /* transmit DATA_FIS from (current sgl + offset) for input
  * parameter length. current sgl and offset is alreay stored in the IO request
  */
-static enum sci_status scic_sds_stp_request_pio_data_out_trasmit_data_frame(
+static enum sci_status sci_stp_request_pio_data_out_trasmit_data_frame(
 	struct isci_request *ireq,
 	u32 length)
 {
@@ -1223,10 +1223,10 @@ static enum sci_status scic_sds_stp_request_pio_data_out_trasmit_data_frame(
 	task_context->type.stp.fis_type = FIS_DATA;
 
 	/* send the new TC out. */
-	return scic_controller_continue_io(ireq);
+	return sci_controller_continue_io(ireq);
 }
 
-static enum sci_status scic_sds_stp_request_pio_data_out_transmit_data(struct isci_request *ireq)
+static enum sci_status sci_stp_request_pio_data_out_transmit_data(struct isci_request *ireq)
 {
 	struct isci_stp_request *stp_req = &ireq->stp.req;
 	struct scu_sgl_element_pair *sgl_pair;
@@ -1252,7 +1252,7 @@ static enum sci_status scic_sds_stp_request_pio_data_out_transmit_data(struct is
 		return SCI_SUCCESS;
 
 	if (stp_req->pio_len >= len) {
-		status = scic_sds_stp_request_pio_data_out_trasmit_data_frame(ireq, len);
+		status = sci_stp_request_pio_data_out_trasmit_data_frame(ireq, len);
 		if (status != SCI_SUCCESS)
 			return status;
 		stp_req->pio_len -= len;
@@ -1261,7 +1261,7 @@ static enum sci_status scic_sds_stp_request_pio_data_out_transmit_data(struct is
 		sgl = pio_sgl_next(stp_req);
 		offset = 0;
 	} else if (stp_req->pio_len < len) {
-		scic_sds_stp_request_pio_data_out_trasmit_data_frame(ireq, stp_req->pio_len);
+		sci_stp_request_pio_data_out_trasmit_data_frame(ireq, stp_req->pio_len);
 
 		/* Sgl offset will be adjusted and saved for future */
 		offset += stp_req->pio_len;
@@ -1284,7 +1284,7 @@ static enum sci_status scic_sds_stp_request_pio_data_out_transmit_data(struct is
  * specified data region. enum sci_status
  */
 static enum sci_status
-scic_sds_stp_request_pio_data_in_copy_data_buffer(struct isci_stp_request *stp_req,
+sci_stp_request_pio_data_in_copy_data_buffer(struct isci_stp_request *stp_req,
 						  u8 *data_buf, u32 len)
 {
 	struct isci_request *ireq;
@@ -1328,7 +1328,7 @@ scic_sds_stp_request_pio_data_in_copy_data_buffer(struct isci_stp_request *stp_r
  *
  * Copy the data buffer to the io request data region. enum sci_status
  */
-static enum sci_status scic_sds_stp_request_pio_data_in_copy_data(
+static enum sci_status sci_stp_request_pio_data_in_copy_data(
 	struct isci_stp_request *stp_req,
 	u8 *data_buffer)
 {
@@ -1338,14 +1338,14 @@ static enum sci_status scic_sds_stp_request_pio_data_in_copy_data(
 	 * If there is less than 1K remaining in the transfer request
 	 * copy just the data for the transfer */
 	if (stp_req->pio_len < SCU_MAX_FRAME_BUFFER_SIZE) {
-		status = scic_sds_stp_request_pio_data_in_copy_data_buffer(
+		status = sci_stp_request_pio_data_in_copy_data_buffer(
 			stp_req, data_buffer, stp_req->pio_len);
 
 		if (status == SCI_SUCCESS)
 			stp_req->pio_len = 0;
 	} else {
 		/* We are transfering the whole frame so copy */
-		status = scic_sds_stp_request_pio_data_in_copy_data_buffer(
+		status = sci_stp_request_pio_data_in_copy_data_buffer(
 			stp_req, data_buffer, SCU_MAX_FRAME_BUFFER_SIZE);
 
 		if (status == SCI_SUCCESS)
@@ -1363,7 +1363,7 @@ stp_request_pio_await_h2d_completion_tc_event(struct isci_request *ireq,
 
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(ireq,
+		sci_request_set_status(ireq,
 					    SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
@@ -1375,7 +1375,7 @@ stp_request_pio_await_h2d_completion_tc_event(struct isci_request *ireq,
 		 * complete.  If a NAK was received, then it is up to
 		 * the user to retry the request.
 		 */
-		scic_sds_request_set_status(ireq,
+		sci_request_set_status(ireq,
 					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
@@ -1398,7 +1398,7 @@ pio_data_out_tx_done_tc_event(struct isci_request *ireq,
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
 		/* Transmit data */
 		if (stp_req->pio_len != 0) {
-			status = scic_sds_stp_request_pio_data_out_transmit_data(ireq);
+			status = sci_stp_request_pio_data_out_transmit_data(ireq);
 			if (status == SCI_SUCCESS) {
 				if (stp_req->pio_len == 0)
 					all_frames_transferred = true;
@@ -1426,7 +1426,7 @@ pio_data_out_tx_done_tc_event(struct isci_request *ireq,
 		 * If a NAK was received, then it is up to the user to retry
 		 * the request.
 		 */
-		scic_sds_request_set_status(
+		sci_request_set_status(
 			ireq,
 			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
@@ -1438,16 +1438,16 @@ pio_data_out_tx_done_tc_event(struct isci_request *ireq,
 	return status;
 }
 
-static void scic_sds_stp_request_udma_complete_request(
+static void sci_stp_request_udma_complete_request(
 	struct isci_request *ireq,
 	u32 scu_status,
 	enum sci_status sci_status)
 {
-	scic_sds_request_set_status(ireq, scu_status, sci_status);
+	sci_request_set_status(ireq, scu_status, sci_status);
 	sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 }
 
-static enum sci_status scic_sds_stp_request_udma_general_frame_handler(struct isci_request *ireq,
+static enum sci_status sci_stp_request_udma_general_frame_handler(struct isci_request *ireq,
 								       u32 frame_index)
 {
 	struct isci_host *ihost = ireq->owning_controller;
@@ -1455,28 +1455,28 @@ static enum sci_status scic_sds_stp_request_udma_general_frame_handler(struct is
 	enum sci_status status;
 	u32 *frame_buffer;
 
-	status = scic_sds_unsolicited_frame_control_get_header(&ihost->uf_control,
+	status = sci_unsolicited_frame_control_get_header(&ihost->uf_control,
 							       frame_index,
 							       (void **)&frame_header);
 
 	if ((status == SCI_SUCCESS) &&
 	    (frame_header->fis_type == FIS_REGD2H)) {
-		scic_sds_unsolicited_frame_control_get_buffer(&ihost->uf_control,
+		sci_unsolicited_frame_control_get_buffer(&ihost->uf_control,
 							      frame_index,
 							      (void **)&frame_buffer);
 
-		scic_sds_controller_copy_sata_response(&ireq->stp.rsp,
+		sci_controller_copy_sata_response(&ireq->stp.rsp,
 						       frame_header,
 						       frame_buffer);
 	}
 
-	scic_sds_controller_release_frame(ihost, frame_index);
+	sci_controller_release_frame(ihost, frame_index);
 
 	return status;
 }
 
 enum sci_status
-scic_sds_io_request_frame_handler(struct isci_request *ireq,
+sci_io_request_frame_handler(struct isci_request *ireq,
 				  u32 frame_index)
 {
 	struct isci_host *ihost = ireq->owning_controller;
@@ -1491,7 +1491,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		struct ssp_frame_hdr ssp_hdr;
 		void *frame_header;
 
-		scic_sds_unsolicited_frame_control_get_header(&ihost->uf_control,
+		sci_unsolicited_frame_control_get_header(&ihost->uf_control,
 							      frame_index,
 							      &frame_header);
 
@@ -1502,7 +1502,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 			struct ssp_response_iu *resp_iu;
 			ssize_t word_cnt = SSP_RESP_IU_MAX_SIZE / sizeof(u32);
 
-			scic_sds_unsolicited_frame_control_get_buffer(&ihost->uf_control,
+			sci_unsolicited_frame_control_get_buffer(&ihost->uf_control,
 								      frame_index,
 								      (void **)&resp_iu);
 
@@ -1512,11 +1512,11 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 
 			if (resp_iu->datapres == 0x01 ||
 			    resp_iu->datapres == 0x02) {
-				scic_sds_request_set_status(ireq,
+				sci_request_set_status(ireq,
 							    SCU_TASK_DONE_CHECK_RESPONSE,
 							    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 			} else
-				scic_sds_request_set_status(ireq,
+				sci_request_set_status(ireq,
 							    SCU_TASK_DONE_GOOD,
 							    SCI_SUCCESS);
 		} else {
@@ -1531,22 +1531,22 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		 * In any case we are done with this frame buffer return it to
 		 * the controller
 		 */
-		scic_sds_controller_release_frame(ihost, frame_index);
+		sci_controller_release_frame(ihost, frame_index);
 
 		return SCI_SUCCESS;
 	}
 
 	case SCI_REQ_TASK_WAIT_TC_RESP:
-		scic_sds_io_request_copy_response(ireq);
+		sci_io_request_copy_response(ireq);
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
-		scic_sds_controller_release_frame(ihost,frame_index);
+		sci_controller_release_frame(ihost, frame_index);
 		return SCI_SUCCESS;
 
 	case SCI_REQ_SMP_WAIT_RESP: {
 		struct smp_resp *rsp_hdr = &ireq->smp.rsp;
 		void *frame_header;
 
-		scic_sds_unsolicited_frame_control_get_header(&ihost->uf_control,
+		sci_unsolicited_frame_control_get_header(&ihost->uf_control,
 							      frame_index,
 							      &frame_header);
 
@@ -1557,7 +1557,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		if (rsp_hdr->frame_type == SMP_RESPONSE) {
 			void *smp_resp;
 
-			scic_sds_unsolicited_frame_control_get_buffer(&ihost->uf_control,
+			sci_unsolicited_frame_control_get_buffer(&ihost->uf_control,
 								      frame_index,
 								      &smp_resp);
 
@@ -1567,7 +1567,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 			sci_swab32_cpy(((u8 *) rsp_hdr) + SMP_RESP_HDR_SZ,
 				       smp_resp, word_cnt);
 
-			scic_sds_request_set_status(ireq, SCU_TASK_DONE_GOOD,
+			sci_request_set_status(ireq, SCU_TASK_DONE_GOOD,
 						    SCI_SUCCESS);
 
 			sci_change_state(&ireq->sm, SCI_REQ_SMP_WAIT_TC_COMP);
@@ -1584,31 +1584,31 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 				frame_index,
 				rsp_hdr->frame_type);
 
-			scic_sds_request_set_status(ireq,
+			sci_request_set_status(ireq,
 						    SCU_TASK_DONE_SMP_FRM_TYPE_ERR,
 						    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
 			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		}
 
-		scic_sds_controller_release_frame(ihost, frame_index);
+		sci_controller_release_frame(ihost, frame_index);
 
 		return SCI_SUCCESS;
 	}
 
 	case SCI_REQ_STP_UDMA_WAIT_TC_COMP:
-		return scic_sds_stp_request_udma_general_frame_handler(ireq,
+		return sci_stp_request_udma_general_frame_handler(ireq,
 								       frame_index);
 
 	case SCI_REQ_STP_UDMA_WAIT_D2H:
 		/* Use the general frame handler to copy the resposne data */
-		status = scic_sds_stp_request_udma_general_frame_handler(ireq,
+		status = sci_stp_request_udma_general_frame_handler(ireq,
 									 frame_index);
 
 		if (status != SCI_SUCCESS)
 			return status;
 
-		scic_sds_stp_request_udma_complete_request(ireq,
+		sci_stp_request_udma_complete_request(ireq,
 							   SCU_TASK_DONE_CHECK_RESPONSE,
 							   SCI_FAILURE_IO_RESPONSE_VALID);
 
@@ -1618,7 +1618,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		struct dev_to_host_fis *frame_header;
 		u32 *frame_buffer;
 
-		status = scic_sds_unsolicited_frame_control_get_header(&ihost->uf_control,
+		status = sci_unsolicited_frame_control_get_header(&ihost->uf_control,
 								       frame_index,
 								       (void **)&frame_header);
 
@@ -1636,16 +1636,16 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 
 		switch (frame_header->fis_type) {
 		case FIS_REGD2H:
-			scic_sds_unsolicited_frame_control_get_buffer(&ihost->uf_control,
+			sci_unsolicited_frame_control_get_buffer(&ihost->uf_control,
 								      frame_index,
 								      (void **)&frame_buffer);
 
-			scic_sds_controller_copy_sata_response(&ireq->stp.rsp,
+			sci_controller_copy_sata_response(&ireq->stp.rsp,
 							       frame_header,
 							       frame_buffer);
 
 			/* The command has completed with error */
-			scic_sds_request_set_status(ireq, SCU_TASK_DONE_CHECK_RESPONSE,
+			sci_request_set_status(ireq, SCU_TASK_DONE_CHECK_RESPONSE,
 						    SCI_FAILURE_IO_RESPONSE_VALID);
 			break;
 
@@ -1655,7 +1655,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 				  "violation occurred\n", __func__, stp_req,
 				  frame_index);
 
-			scic_sds_request_set_status(ireq, SCU_TASK_DONE_UNEXP_FIS,
+			sci_request_set_status(ireq, SCU_TASK_DONE_UNEXP_FIS,
 						    SCI_FAILURE_PROTOCOL_VIOLATION);
 			break;
 		}
@@ -1663,7 +1663,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 
 		/* Frame has been decoded return it to the controller */
-		scic_sds_controller_release_frame(ihost, frame_index);
+		sci_controller_release_frame(ihost, frame_index);
 
 		return status;
 	}
@@ -1673,7 +1673,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		struct dev_to_host_fis *frame_header;
 		u32 *frame_buffer;
 
-		status = scic_sds_unsolicited_frame_control_get_header(&ihost->uf_control,
+		status = sci_unsolicited_frame_control_get_header(&ihost->uf_control,
 								       frame_index,
 								       (void **)&frame_header);
 
@@ -1688,7 +1688,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		switch (frame_header->fis_type) {
 		case FIS_PIO_SETUP:
 			/* Get from the frame buffer the PIO Setup Data */
-			scic_sds_unsolicited_frame_control_get_buffer(&ihost->uf_control,
+			sci_unsolicited_frame_control_get_buffer(&ihost->uf_control,
 								      frame_index,
 								      (void **)&frame_buffer);
 
@@ -1704,7 +1704,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 			/* status: 4th byte in the 3rd dword */
 			stp_req->status = (frame_buffer[2] >> 24) & 0xff;
 
-			scic_sds_controller_copy_sata_response(&ireq->stp.rsp,
+			sci_controller_copy_sata_response(&ireq->stp.rsp,
 							       frame_header,
 							       frame_buffer);
 
@@ -1717,7 +1717,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 				sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_DATA_IN);
 			} else if (task->data_dir == DMA_TO_DEVICE) {
 				/* Transmit data */
-				status = scic_sds_stp_request_pio_data_out_transmit_data(ireq);
+				status = sci_stp_request_pio_data_out_transmit_data(ireq);
 				if (status != SCI_SUCCESS)
 					break;
 				sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_DATA_OUT);
@@ -1745,15 +1745,15 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 				break;
 			}
 
-			scic_sds_unsolicited_frame_control_get_buffer(&ihost->uf_control,
+			sci_unsolicited_frame_control_get_buffer(&ihost->uf_control,
 								      frame_index,
 								      (void **)&frame_buffer);
 
-			scic_sds_controller_copy_sata_response(&ireq->stp.req,
+			sci_controller_copy_sata_response(&ireq->stp.req,
 							       frame_header,
 							       frame_buffer);
 
-			scic_sds_request_set_status(ireq,
+			sci_request_set_status(ireq,
 						    SCU_TASK_DONE_CHECK_RESPONSE,
 						    SCI_FAILURE_IO_RESPONSE_VALID);
 
@@ -1766,7 +1766,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		}
 
 		/* Frame is decoded return it to the controller */
-		scic_sds_controller_release_frame(ihost, frame_index);
+		sci_controller_release_frame(ihost, frame_index);
 
 		return status;
 	}
@@ -1775,7 +1775,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		struct dev_to_host_fis *frame_header;
 		struct sata_fis_data *frame_buffer;
 
-		status = scic_sds_unsolicited_frame_control_get_header(&ihost->uf_control,
+		status = sci_unsolicited_frame_control_get_header(&ihost->uf_control,
 								       frame_index,
 								       (void **)&frame_header);
 
@@ -1800,14 +1800,14 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 				frame_index,
 				frame_header->fis_type);
 
-			scic_sds_request_set_status(ireq,
+			sci_request_set_status(ireq,
 						    SCU_TASK_DONE_GOOD,
 						    SCI_FAILURE_IO_REQUIRES_SCSI_ABORT);
 
 			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 
 			/* Frame is decoded return it to the controller */
-			scic_sds_controller_release_frame(ihost, frame_index);
+			sci_controller_release_frame(ihost, frame_index);
 			return status;
 		}
 
@@ -1815,15 +1815,15 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 			ireq->saved_rx_frame_index = frame_index;
 			stp_req->pio_len = 0;
 		} else {
-			scic_sds_unsolicited_frame_control_get_buffer(&ihost->uf_control,
+			sci_unsolicited_frame_control_get_buffer(&ihost->uf_control,
 								      frame_index,
 								      (void **)&frame_buffer);
 
-			status = scic_sds_stp_request_pio_data_in_copy_data(stp_req,
+			status = sci_stp_request_pio_data_in_copy_data(stp_req,
 									    (u8 *)frame_buffer);
 
 			/* Frame is decoded return it to the controller */
-			scic_sds_controller_release_frame(ihost, frame_index);
+			sci_controller_release_frame(ihost, frame_index);
 		}
 
 		/* Check for the end of the transfer, are there more
@@ -1833,7 +1833,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 			return status;
 
 		if ((stp_req->status & ATA_BUSY) == 0) {
-			scic_sds_request_set_status(ireq,
+			sci_request_set_status(ireq,
 						    SCU_TASK_DONE_CHECK_RESPONSE,
 						    SCI_FAILURE_IO_RESPONSE_VALID);
 
@@ -1848,7 +1848,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		struct dev_to_host_fis *frame_header;
 		u32 *frame_buffer;
 
-		status = scic_sds_unsolicited_frame_control_get_header(&ihost->uf_control,
+		status = sci_unsolicited_frame_control_get_header(&ihost->uf_control,
 								       frame_index,
 								       (void **)&frame_header);
 		if (status != SCI_SUCCESS) {
@@ -1864,16 +1864,16 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 
 		switch (frame_header->fis_type) {
 		case FIS_REGD2H:
-			scic_sds_unsolicited_frame_control_get_buffer(&ihost->uf_control,
+			sci_unsolicited_frame_control_get_buffer(&ihost->uf_control,
 								      frame_index,
 								      (void **)&frame_buffer);
 
-			scic_sds_controller_copy_sata_response(&ireq->stp.rsp,
+			sci_controller_copy_sata_response(&ireq->stp.rsp,
 							       frame_header,
 							       frame_buffer);
 
 			/* The command has completed with error */
-			scic_sds_request_set_status(ireq,
+			sci_request_set_status(ireq,
 						    SCU_TASK_DONE_CHECK_RESPONSE,
 						    SCI_FAILURE_IO_RESPONSE_VALID);
 			break;
@@ -1886,7 +1886,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 				 stp_req,
 				 frame_index);
 
-			scic_sds_request_set_status(ireq,
+			sci_request_set_status(ireq,
 						    SCU_TASK_DONE_UNEXP_FIS,
 						    SCI_FAILURE_PROTOCOL_VIOLATION);
 			break;
@@ -1895,7 +1895,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 
 		/* Frame has been decoded return it to the controller */
-		scic_sds_controller_release_frame(ihost, frame_index);
+		sci_controller_release_frame(ihost, frame_index);
 
 		return status;
 	}
@@ -1904,7 +1904,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		 * TODO: Is it even possible to get an unsolicited frame in the
 		 * aborting state?
 		 */
-		scic_sds_controller_release_frame(ihost, frame_index);
+		sci_controller_release_frame(ihost, frame_index);
 		return SCI_SUCCESS;
 
 	default:
@@ -1915,7 +1915,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 			 frame_index,
 			 state);
 
-		scic_sds_controller_release_frame(ihost, frame_index);
+		sci_controller_release_frame(ihost, frame_index);
 		return SCI_FAILURE_INVALID_STATE;
 	}
 }
@@ -1927,7 +1927,7 @@ static enum sci_status stp_request_udma_await_tc_event(struct isci_request *ireq
 
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_stp_request_udma_complete_request(ireq,
+		sci_stp_request_udma_complete_request(ireq,
 							   SCU_TASK_DONE_GOOD,
 							   SCI_SUCCESS);
 		break;
@@ -1938,10 +1938,10 @@ static enum sci_status stp_request_udma_await_tc_event(struct isci_request *ireq
 		 * completion.
 		 */
 		if (ireq->stp.rsp.fis_type == FIS_REGD2H) {
-			scic_sds_remote_device_suspend(ireq->target_device,
+			sci_remote_device_suspend(ireq->target_device,
 				SCU_EVENT_SPECIFIC(SCU_NORMALIZE_COMPLETION_STATUS(completion_code)));
 
-			scic_sds_stp_request_udma_complete_request(ireq,
+			sci_stp_request_udma_complete_request(ireq,
 								   SCU_TASK_DONE_CHECK_RESPONSE,
 								   SCI_FAILURE_IO_RESPONSE_VALID);
 		} else {
@@ -1965,12 +1965,12 @@ static enum sci_status stp_request_udma_await_tc_event(struct isci_request *ireq
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_LL_R_ERR):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_CMD_LL_R_ERR):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_CRC_ERR):
-		scic_sds_remote_device_suspend(ireq->target_device,
+		sci_remote_device_suspend(ireq->target_device,
 			SCU_EVENT_SPECIFIC(SCU_NORMALIZE_COMPLETION_STATUS(completion_code)));
 	/* Fall through to the default case */
 	default:
 		/* All other completion status cause the IO to be complete. */
-		scic_sds_stp_request_udma_complete_request(ireq,
+		sci_stp_request_udma_complete_request(ireq,
 					SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 					SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 		break;
@@ -1985,7 +1985,7 @@ stp_request_soft_reset_await_h2d_asserted_tc_event(struct isci_request *ireq,
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(ireq, SCU_TASK_DONE_GOOD,
+		sci_request_set_status(ireq, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
 		sci_change_state(&ireq->sm, SCI_REQ_STP_SOFT_RESET_WAIT_H2D_DIAG);
@@ -1997,7 +1997,7 @@ stp_request_soft_reset_await_h2d_asserted_tc_event(struct isci_request *ireq,
 		 * If a NAK was received, then it is up to the user to retry
 		 * the request.
 		 */
-		scic_sds_request_set_status(ireq,
+		sci_request_set_status(ireq,
 					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
@@ -2014,7 +2014,7 @@ stp_request_soft_reset_await_h2d_diagnostic_tc_event(struct isci_request *ireq,
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(ireq, SCU_TASK_DONE_GOOD,
+		sci_request_set_status(ireq, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
 		sci_change_state(&ireq->sm, SCI_REQ_STP_SOFT_RESET_WAIT_D2H);
@@ -2025,7 +2025,7 @@ stp_request_soft_reset_await_h2d_diagnostic_tc_event(struct isci_request *ireq,
 		 * a NAK was received, then it is up to the user to retry the
 		 * request.
 		 */
-		scic_sds_request_set_status(ireq,
+		sci_request_set_status(ireq,
 			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
@@ -2037,7 +2037,7 @@ stp_request_soft_reset_await_h2d_diagnostic_tc_event(struct isci_request *ireq,
 }
 
 enum sci_status
-scic_sds_io_request_tc_completion(struct isci_request *ireq,
+sci_io_request_tc_completion(struct isci_request *ireq,
 				  u32 completion_code)
 {
 	enum sci_base_request_states state;
@@ -2832,7 +2832,7 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 						  );
 
 	/* complete the io request to the core. */
-	scic_controller_complete_io(ihost, request->target_device, request);
+	sci_controller_complete_io(ihost, request->target_device, request);
 	isci_put_device(idev);
 
 	/* set terminated handle so it cannot be completed or
@@ -2842,7 +2842,7 @@ static void isci_request_io_request_complete(struct isci_host *ihost,
 	set_bit(IREQ_TERMINATED, &request->flags);
 }
 
-static void scic_sds_request_started_state_enter(struct sci_base_state_machine *sm)
+static void sci_request_started_state_enter(struct sci_base_state_machine *sm)
 {
 	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
 	struct domain_device *dev = ireq->target_device->domain_dev;
@@ -2879,7 +2879,7 @@ static void scic_sds_request_started_state_enter(struct sci_base_state_machine *
 	}
 }
 
-static void scic_sds_request_completed_state_enter(struct sci_base_state_machine *sm)
+static void sci_request_completed_state_enter(struct sci_base_state_machine *sm)
 {
 	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
 	struct isci_host *ihost = ireq->owning_controller;
@@ -2892,7 +2892,7 @@ static void scic_sds_request_completed_state_enter(struct sci_base_state_machine
 		isci_task_request_complete(ihost, ireq, ireq->sci_status);
 }
 
-static void scic_sds_request_aborting_state_enter(struct sci_base_state_machine *sm)
+static void sci_request_aborting_state_enter(struct sci_base_state_machine *sm)
 {
 	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
 
@@ -2900,31 +2900,31 @@ static void scic_sds_request_aborting_state_enter(struct sci_base_state_machine
 	ireq->tc->abort = 1;
 }
 
-static void scic_sds_stp_request_started_non_data_await_h2d_completion_enter(struct sci_base_state_machine *sm)
+static void sci_stp_request_started_non_data_await_h2d_completion_enter(struct sci_base_state_machine *sm)
 {
 	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
 
-	scic_sds_remote_device_set_working_request(ireq->target_device,
+	sci_remote_device_set_working_request(ireq->target_device,
 						   ireq);
 }
 
-static void scic_sds_stp_request_started_pio_await_h2d_completion_enter(struct sci_base_state_machine *sm)
+static void sci_stp_request_started_pio_await_h2d_completion_enter(struct sci_base_state_machine *sm)
 {
 	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
 
-	scic_sds_remote_device_set_working_request(ireq->target_device,
+	sci_remote_device_set_working_request(ireq->target_device,
 						   ireq);
 }
 
-static void scic_sds_stp_request_started_soft_reset_await_h2d_asserted_completion_enter(struct sci_base_state_machine *sm)
+static void sci_stp_request_started_soft_reset_await_h2d_asserted_completion_enter(struct sci_base_state_machine *sm)
 {
 	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
 
-	scic_sds_remote_device_set_working_request(ireq->target_device,
+	sci_remote_device_set_working_request(ireq->target_device,
 						   ireq);
 }
 
-static void scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter(struct sci_base_state_machine *sm)
+static void sci_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter(struct sci_base_state_machine *sm)
 {
 	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
 	struct scu_task_context *tc = ireq->tc;
@@ -2938,22 +2938,22 @@ static void scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_complet
 	/* Clear the TC control bit */
 	tc->control_frame = 0;
 
-	status = scic_controller_continue_io(ireq);
+	status = sci_controller_continue_io(ireq);
 	WARN_ONCE(status != SCI_SUCCESS, "isci: continue io failure\n");
 }
 
-static const struct sci_base_state scic_sds_request_state_table[] = {
+static const struct sci_base_state sci_request_state_table[] = {
 	[SCI_REQ_INIT] = { },
 	[SCI_REQ_CONSTRUCTED] = { },
 	[SCI_REQ_STARTED] = {
-		.enter_state = scic_sds_request_started_state_enter,
+		.enter_state = sci_request_started_state_enter,
 	},
 	[SCI_REQ_STP_NON_DATA_WAIT_H2D] = {
-		.enter_state = scic_sds_stp_request_started_non_data_await_h2d_completion_enter,
+		.enter_state = sci_stp_request_started_non_data_await_h2d_completion_enter,
 	},
 	[SCI_REQ_STP_NON_DATA_WAIT_D2H] = { },
 	[SCI_REQ_STP_PIO_WAIT_H2D] = {
-		.enter_state = scic_sds_stp_request_started_pio_await_h2d_completion_enter,
+		.enter_state = sci_stp_request_started_pio_await_h2d_completion_enter,
 	},
 	[SCI_REQ_STP_PIO_WAIT_FRAME] = { },
 	[SCI_REQ_STP_PIO_DATA_IN] = { },
@@ -2961,10 +2961,10 @@ static const struct sci_base_state scic_sds_request_state_table[] = {
 	[SCI_REQ_STP_UDMA_WAIT_TC_COMP] = { },
 	[SCI_REQ_STP_UDMA_WAIT_D2H] = { },
 	[SCI_REQ_STP_SOFT_RESET_WAIT_H2D_ASSERTED] = {
-		.enter_state = scic_sds_stp_request_started_soft_reset_await_h2d_asserted_completion_enter,
+		.enter_state = sci_stp_request_started_soft_reset_await_h2d_asserted_completion_enter,
 	},
 	[SCI_REQ_STP_SOFT_RESET_WAIT_H2D_DIAG] = {
-		.enter_state = scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter,
+		.enter_state = sci_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter,
 	},
 	[SCI_REQ_STP_SOFT_RESET_WAIT_D2H] = { },
 	[SCI_REQ_TASK_WAIT_TC_COMP] = { },
@@ -2972,20 +2972,20 @@ static const struct sci_base_state scic_sds_request_state_table[] = {
 	[SCI_REQ_SMP_WAIT_RESP] = { },
 	[SCI_REQ_SMP_WAIT_TC_COMP] = { },
 	[SCI_REQ_COMPLETED] = {
-		.enter_state = scic_sds_request_completed_state_enter,
+		.enter_state = sci_request_completed_state_enter,
 	},
 	[SCI_REQ_ABORTING] = {
-		.enter_state = scic_sds_request_aborting_state_enter,
+		.enter_state = sci_request_aborting_state_enter,
 	},
 	[SCI_REQ_FINAL] = { },
 };
 
 static void
-scic_sds_general_request_construct(struct isci_host *ihost,
+sci_general_request_construct(struct isci_host *ihost,
 				   struct isci_remote_device *idev,
 				   struct isci_request *ireq)
 {
-	sci_init_sm(&ireq->sm, scic_sds_request_state_table, SCI_REQ_INIT);
+	sci_init_sm(&ireq->sm, sci_request_state_table, SCI_REQ_INIT);
 
 	ireq->target_device = idev;
 	ireq->protocol = SCIC_NO_PROTOCOL;
@@ -2997,7 +2997,7 @@ scic_sds_general_request_construct(struct isci_host *ihost,
 }
 
 static enum sci_status
-scic_io_request_construct(struct isci_host *ihost,
+sci_io_request_construct(struct isci_host *ihost,
 			  struct isci_remote_device *idev,
 			  struct isci_request *ireq)
 {
@@ -3005,7 +3005,7 @@ scic_io_request_construct(struct isci_host *ihost,
 	enum sci_status status = SCI_SUCCESS;
 
 	/* Build the common part of the request */
-	scic_sds_general_request_construct(ihost, idev, ireq);
+	sci_general_request_construct(ihost, idev, ireq);
 
 	if (idev->rnc.remote_node_index == SCIC_SDS_REMOTE_NODE_CONTEXT_INVALID_INDEX)
 		return SCI_FAILURE_INVALID_REMOTE_DEVICE;
@@ -3024,7 +3024,7 @@ scic_io_request_construct(struct isci_host *ihost,
 	return status;
 }
 
-enum sci_status scic_task_request_construct(struct isci_host *ihost,
+enum sci_status sci_task_request_construct(struct isci_host *ihost,
 					    struct isci_remote_device *idev,
 					    u16 io_tag, struct isci_request *ireq)
 {
@@ -3032,7 +3032,7 @@ enum sci_status scic_task_request_construct(struct isci_host *ihost,
 	enum sci_status status = SCI_SUCCESS;
 
 	/* Build the common part of the request */
-	scic_sds_general_request_construct(ihost, idev, ireq);
+	sci_general_request_construct(ihost, idev, ireq);
 
 	if (dev->dev_type == SAS_END_DEV ||
 	    dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP)) {
@@ -3053,7 +3053,7 @@ static enum sci_status isci_request_ssp_request_construct(
 		"%s: request = %p\n",
 		__func__,
 		request);
-	status = scic_io_request_construct_basic_ssp(request);
+	status = sci_io_request_construct_basic_ssp(request);
 	return status;
 }
 
@@ -3074,7 +3074,7 @@ static enum sci_status isci_request_stp_request_construct(
 	 */
 	register_fis = isci_sata_task_to_fis_copy(task);
 
-	status = scic_io_request_construct_basic_sata(request);
+	status = sci_io_request_construct_basic_sata(request);
 
 	/* Set the ncq tag in the fis, from the queue
 	 * command in the task.
@@ -3091,7 +3091,7 @@ static enum sci_status isci_request_stp_request_construct(
 }
 
 static enum sci_status
-scic_io_request_construct_smp(struct device *dev,
+sci_io_request_construct_smp(struct device *dev,
 			      struct isci_request *ireq,
 			      struct sas_task *task)
 {
@@ -3141,8 +3141,8 @@ scic_io_request_construct_smp(struct device *dev,
 
 	task_context = ireq->tc;
 
-	idev = scic_sds_request_get_device(ireq);
-	iport = scic_sds_request_get_port(ireq);
+	idev = sci_request_get_device(ireq);
+	iport = sci_request_get_port(ireq);
 
 	/*
 	 * Fill in the TC with the its required data
@@ -3152,8 +3152,8 @@ scic_io_request_construct_smp(struct device *dev,
 	task_context->initiator_request = 1;
 	task_context->connection_rate = idev->connection_rate;
 	task_context->protocol_engine_index =
-		scic_sds_controller_get_protocol_engine_group(ihost);
-	task_context->logical_port_index = scic_sds_port_get_index(iport);
+		sci_controller_get_protocol_engine_group(ihost);
+	task_context->logical_port_index = sci_port_get_index(iport);
 	task_context->protocol_type = SCU_TASK_CONTEXT_PROTOCOL_SMP;
 	task_context->abort = 0;
 	task_context->valid = SCU_TASK_CONTEXT_VALID;
@@ -3195,9 +3195,9 @@ scic_io_request_construct_smp(struct device *dev,
 	task_context->task_phase = 0;
 
 	ireq->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
-				 (scic_sds_controller_get_protocol_engine_group(ihost) <<
+				 (sci_controller_get_protocol_engine_group(ihost) <<
 				  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
-				 (scic_sds_port_get_index(iport) <<
+				 (sci_port_get_index(iport) <<
 				  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
 				 ISCI_TAG_TCI(ireq->io_tag));
 	/*
@@ -3229,7 +3229,7 @@ static enum sci_status isci_smp_request_build(struct isci_request *ireq)
 	struct device *dev = &ireq->isci_host->pdev->dev;
 	enum sci_status status = SCI_FAILURE;
 
-	status = scic_io_request_construct_smp(dev, ireq, task);
+	status = sci_io_request_construct_smp(dev, ireq, task);
 	if (status != SCI_SUCCESS)
 		dev_warn(&ireq->isci_host->pdev->dev,
 			 "%s: failed with status = %d\n",
@@ -3283,7 +3283,7 @@ static enum sci_status isci_io_request_build(struct isci_host *ihost,
 			return SCI_FAILURE_INSUFFICIENT_RESOURCES;
 	}
 
-	status = scic_io_request_construct(ihost, idev, request);
+	status = sci_io_request_construct(ihost, idev, request);
 
 	if (status != SCI_SUCCESS) {
 		dev_warn(&ihost->pdev->dev,
@@ -3388,7 +3388,7 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 			 * request was built that way (ie.
 			 * ireq->is_task_management_request is false).
 			 */
-			status = scic_controller_start_task(ihost,
+			status = sci_controller_start_task(ihost,
 							    idev,
 							    ireq);
 		} else {
@@ -3396,7 +3396,7 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 		}
 	} else {
 		/* send the request, let the core assign the IO TAG.	*/
-		status = scic_controller_start_io(ihost, idev,
+		status = sci_controller_start_io(ihost, idev,
 						  ireq);
 	}
 

commit d9dcb4ba791de2a06b19ac47cd61601cf3d4e208
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Jun 30 17:38:32 2011 -0700

    isci: unify isci_host and scic_sds_controller
    
    Remove the distinction between these two implementations and unify on
    isci_host (local instances named ihost).  Hmmm, we had two
    'oem_parameters' instances, one was unused... nice.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 90ead662828d..36e674896bc5 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -74,19 +74,19 @@ static struct scu_sgl_element_pair *to_sgl_element_pair(struct isci_request *ire
 		return &ireq->sg_table[idx - 2];
 }
 
-static dma_addr_t to_sgl_element_pair_dma(struct scic_sds_controller *scic,
+static dma_addr_t to_sgl_element_pair_dma(struct isci_host *ihost,
 					  struct isci_request *ireq, u32 idx)
 {
 	u32 offset;
 
 	if (idx == 0) {
 		offset = (void *) &ireq->tc->sgl_pair_ab -
-			 (void *) &scic->task_context_table[0];
-		return scic->task_context_dma + offset;
+			 (void *) &ihost->task_context_table[0];
+		return ihost->task_context_dma + offset;
 	} else if (idx == 1) {
 		offset = (void *) &ireq->tc->sgl_pair_cd -
-			 (void *) &scic->task_context_table[0];
-		return scic->task_context_dma + offset;
+			 (void *) &ihost->task_context_table[0];
+		return ihost->task_context_dma + offset;
 	}
 
 	return scic_io_request_get_dma_addr(ireq, &ireq->sg_table[idx - 2]);
@@ -102,8 +102,7 @@ static void init_sgl_element(struct scu_sgl_element *e, struct scatterlist *sg)
 
 static void scic_sds_request_build_sgl(struct isci_request *ireq)
 {
-	struct isci_host *isci_host = ireq->isci_host;
-	struct scic_sds_controller *scic = &isci_host->sci;
+	struct isci_host *ihost = ireq->isci_host;
 	struct sas_task *task = isci_request_access_task(ireq);
 	struct scatterlist *sg = NULL;
 	dma_addr_t dma_addr;
@@ -125,7 +124,7 @@ static void scic_sds_request_build_sgl(struct isci_request *ireq)
 				memset(&scu_sg->B, 0, sizeof(scu_sg->B));
 
 			if (prev_sg) {
-				dma_addr = to_sgl_element_pair_dma(scic,
+				dma_addr = to_sgl_element_pair_dma(ihost,
 								   ireq,
 								   sg_idx);
 
@@ -141,7 +140,7 @@ static void scic_sds_request_build_sgl(struct isci_request *ireq)
 	} else {	/* handle when no sg */
 		scu_sg = to_sgl_element_pair(ireq, sg_idx);
 
-		dma_addr = dma_map_single(&isci_host->pdev->dev,
+		dma_addr = dma_map_single(&ihost->pdev->dev,
 					  task->scatter,
 					  task->total_xfer_len,
 					  task->data_dir);
@@ -508,7 +507,7 @@ scic_io_request_construct_sata(struct isci_request *ireq,
 			scu_stp_raw_request_construct_task_context(ireq);
 			return SCI_SUCCESS;
 		} else {
-			dev_err(scic_to_dev(ireq->owning_controller),
+			dev_err(&ireq->owning_controller->pdev->dev,
 				"%s: Request 0x%p received un-handled SAT "
 				"management protocol 0x%x.\n",
 				__func__, ireq, tmf->tmf_code);
@@ -518,7 +517,7 @@ scic_io_request_construct_sata(struct isci_request *ireq,
 	}
 
 	if (!sas_protocol_ata(task->task_proto)) {
-		dev_err(scic_to_dev(ireq->owning_controller),
+		dev_err(&ireq->owning_controller->pdev->dev,
 			"%s: Non-ATA protocol in SATA path: 0x%x\n",
 			__func__,
 			task->task_proto);
@@ -616,7 +615,7 @@ enum sci_status scic_task_request_construct_sata(struct isci_request *ireq)
 		    tmf->tmf_code == isci_tmf_sata_srst_low) {
 			scu_stp_raw_request_construct_task_context(ireq);
 		} else {
-			dev_err(scic_to_dev(ireq->owning_controller),
+			dev_err(&ireq->owning_controller->pdev->dev,
 				"%s: Request 0x%p received un-handled SAT "
 				"Protocol 0x%x.\n",
 				__func__, ireq, tmf->tmf_code);
@@ -639,11 +638,11 @@ enum sci_status scic_task_request_construct_sata(struct isci_request *ireq)
 #define SCU_TASK_CONTEXT_SRAM 0x200000
 static u32 sci_req_tx_bytes(struct isci_request *ireq)
 {
-	struct scic_sds_controller *scic = ireq->owning_controller;
+	struct isci_host *ihost = ireq->owning_controller;
 	u32 ret_val = 0;
 
-	if (readl(&scic->smu_registers->address_modifier) == 0) {
-		void __iomem *scu_reg_base = scic->scu_registers;
+	if (readl(&ihost->smu_registers->address_modifier) == 0) {
+		void __iomem *scu_reg_base = ihost->scu_registers;
 
 		/* get the bytes of data from the Address == BAR1 + 20002Ch + (256*TCi) where
 		 *   BAR1 is the scu_registers
@@ -663,11 +662,11 @@ enum sci_status scic_sds_request_start(struct isci_request *ireq)
 {
 	enum sci_base_request_states state;
 	struct scu_task_context *tc = ireq->tc;
-	struct scic_sds_controller *scic = ireq->owning_controller;
+	struct isci_host *ihost = ireq->owning_controller;
 
 	state = ireq->sm.current_state_id;
 	if (state != SCI_REQ_CONSTRUCTED) {
-		dev_warn(scic_to_dev(scic),
+		dev_warn(&ihost->pdev->dev,
 			"%s: SCIC IO Request requested to start while in wrong "
 			 "state %d\n", __func__, state);
 		return SCI_FAILURE_INVALID_STATE;
@@ -749,7 +748,7 @@ scic_sds_io_request_terminate(struct isci_request *ireq)
 		return SCI_SUCCESS;
 	case SCI_REQ_COMPLETED:
 	default:
-		dev_warn(scic_to_dev(ireq->owning_controller),
+		dev_warn(&ireq->owning_controller->pdev->dev,
 			 "%s: SCIC IO Request requested to abort while in wrong "
 			 "state %d\n",
 			 __func__,
@@ -763,7 +762,7 @@ scic_sds_io_request_terminate(struct isci_request *ireq)
 enum sci_status scic_sds_request_complete(struct isci_request *ireq)
 {
 	enum sci_base_request_states state;
-	struct scic_sds_controller *scic = ireq->owning_controller;
+	struct isci_host *ihost = ireq->owning_controller;
 
 	state = ireq->sm.current_state_id;
 	if (WARN_ONCE(state != SCI_REQ_COMPLETED,
@@ -771,7 +770,7 @@ enum sci_status scic_sds_request_complete(struct isci_request *ireq)
 		return SCI_FAILURE_INVALID_STATE;
 
 	if (ireq->saved_rx_frame_index != SCU_INVALID_FRAME_INDEX)
-		scic_sds_controller_release_frame(scic,
+		scic_sds_controller_release_frame(ihost,
 						  ireq->saved_rx_frame_index);
 
 	/* XXX can we just stop the machine and remove the 'final' state? */
@@ -783,12 +782,12 @@ enum sci_status scic_sds_io_request_event_handler(struct isci_request *ireq,
 						  u32 event_code)
 {
 	enum sci_base_request_states state;
-	struct scic_sds_controller *scic = ireq->owning_controller;
+	struct isci_host *ihost = ireq->owning_controller;
 
 	state = ireq->sm.current_state_id;
 
 	if (state != SCI_REQ_STP_PIO_DATA_IN) {
-		dev_warn(scic_to_dev(scic), "%s: (%x) in wrong state %d\n",
+		dev_warn(&ihost->pdev->dev, "%s: (%x) in wrong state %d\n",
 			 __func__, event_code, state);
 
 		return SCI_FAILURE_INVALID_STATE;
@@ -802,7 +801,7 @@ enum sci_status scic_sds_io_request_event_handler(struct isci_request *ireq,
 		sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
 		return SCI_SUCCESS;
 	default:
-		dev_err(scic_to_dev(scic),
+		dev_err(&ihost->pdev->dev,
 			"%s: pio request unexpected event %#x\n",
 			__func__, event_code);
 
@@ -1024,7 +1023,7 @@ static enum sci_status ssp_task_request_await_tc_event(struct isci_request *ireq
 		 * There is a potential for receiving multiple task responses if
 		 * we decide to send the task IU again.
 		 */
-		dev_warn(scic_to_dev(ireq->owning_controller),
+		dev_warn(&ireq->owning_controller->pdev->dev,
 			 "%s: TaskRequest:0x%p CompletionCode:%x - "
 			 "ACK/NAK timeout\n", __func__, ireq,
 			 completion_code);
@@ -1073,7 +1072,7 @@ smp_request_await_response_tc_event(struct isci_request *ireq,
 		 * response within 2 ms. This causes our hardware break
 		 * the connection and set TC completion with one of
 		 * these SMP_XXX_XX_ERR status. For these type of error,
-		 * we ask scic user to retry the request.
+		 * we ask ihost user to retry the request.
 		 */
 		scic_sds_request_set_status(ireq, SCU_TASK_DONE_SMP_RESP_TO_ERR,
 					    SCI_FAILURE_RETRY_REQUIRED);
@@ -1451,18 +1450,18 @@ static void scic_sds_stp_request_udma_complete_request(
 static enum sci_status scic_sds_stp_request_udma_general_frame_handler(struct isci_request *ireq,
 								       u32 frame_index)
 {
-	struct scic_sds_controller *scic = ireq->owning_controller;
+	struct isci_host *ihost = ireq->owning_controller;
 	struct dev_to_host_fis *frame_header;
 	enum sci_status status;
 	u32 *frame_buffer;
 
-	status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+	status = scic_sds_unsolicited_frame_control_get_header(&ihost->uf_control,
 							       frame_index,
 							       (void **)&frame_header);
 
 	if ((status == SCI_SUCCESS) &&
 	    (frame_header->fis_type == FIS_REGD2H)) {
-		scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+		scic_sds_unsolicited_frame_control_get_buffer(&ihost->uf_control,
 							      frame_index,
 							      (void **)&frame_buffer);
 
@@ -1471,7 +1470,7 @@ static enum sci_status scic_sds_stp_request_udma_general_frame_handler(struct is
 						       frame_buffer);
 	}
 
-	scic_sds_controller_release_frame(scic, frame_index);
+	scic_sds_controller_release_frame(ihost, frame_index);
 
 	return status;
 }
@@ -1480,7 +1479,7 @@ enum sci_status
 scic_sds_io_request_frame_handler(struct isci_request *ireq,
 				  u32 frame_index)
 {
-	struct scic_sds_controller *scic = ireq->owning_controller;
+	struct isci_host *ihost = ireq->owning_controller;
 	struct isci_stp_request *stp_req = &ireq->stp.req;
 	enum sci_base_request_states state;
 	enum sci_status status;
@@ -1492,7 +1491,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		struct ssp_frame_hdr ssp_hdr;
 		void *frame_header;
 
-		scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+		scic_sds_unsolicited_frame_control_get_header(&ihost->uf_control,
 							      frame_index,
 							      &frame_header);
 
@@ -1503,7 +1502,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 			struct ssp_response_iu *resp_iu;
 			ssize_t word_cnt = SSP_RESP_IU_MAX_SIZE / sizeof(u32);
 
-			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+			scic_sds_unsolicited_frame_control_get_buffer(&ihost->uf_control,
 								      frame_index,
 								      (void **)&resp_iu);
 
@@ -1522,7 +1521,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 							    SCI_SUCCESS);
 		} else {
 			/* not a response frame, why did it get forwarded? */
-			dev_err(scic_to_dev(scic),
+			dev_err(&ihost->pdev->dev,
 				"%s: SCIC IO Request 0x%p received unexpected "
 				"frame %d type 0x%02x\n", __func__, ireq,
 				frame_index, ssp_hdr.frame_type);
@@ -1532,7 +1531,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		 * In any case we are done with this frame buffer return it to
 		 * the controller
 		 */
-		scic_sds_controller_release_frame(scic, frame_index);
+		scic_sds_controller_release_frame(ihost, frame_index);
 
 		return SCI_SUCCESS;
 	}
@@ -1540,14 +1539,14 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 	case SCI_REQ_TASK_WAIT_TC_RESP:
 		scic_sds_io_request_copy_response(ireq);
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
-		scic_sds_controller_release_frame(scic,frame_index);
+		scic_sds_controller_release_frame(ihost,frame_index);
 		return SCI_SUCCESS;
 
 	case SCI_REQ_SMP_WAIT_RESP: {
 		struct smp_resp *rsp_hdr = &ireq->smp.rsp;
 		void *frame_header;
 
-		scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+		scic_sds_unsolicited_frame_control_get_header(&ihost->uf_control,
 							      frame_index,
 							      &frame_header);
 
@@ -1558,7 +1557,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		if (rsp_hdr->frame_type == SMP_RESPONSE) {
 			void *smp_resp;
 
-			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+			scic_sds_unsolicited_frame_control_get_buffer(&ihost->uf_control,
 								      frame_index,
 								      &smp_resp);
 
@@ -1577,7 +1576,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 			 * This was not a response frame why did it get
 			 * forwarded?
 			 */
-			dev_err(scic_to_dev(scic),
+			dev_err(&ihost->pdev->dev,
 				"%s: SCIC SMP Request 0x%p received unexpected "
 				"frame %d type 0x%02x\n",
 				__func__,
@@ -1592,7 +1591,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		}
 
-		scic_sds_controller_release_frame(scic, frame_index);
+		scic_sds_controller_release_frame(ihost, frame_index);
 
 		return SCI_SUCCESS;
 	}
@@ -1619,12 +1618,12 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		struct dev_to_host_fis *frame_header;
 		u32 *frame_buffer;
 
-		status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+		status = scic_sds_unsolicited_frame_control_get_header(&ihost->uf_control,
 								       frame_index,
 								       (void **)&frame_header);
 
 		if (status != SCI_SUCCESS) {
-			dev_err(scic_to_dev(scic),
+			dev_err(&ihost->pdev->dev,
 				"%s: SCIC IO Request 0x%p could not get frame "
 				"header for frame index %d, status %x\n",
 				__func__,
@@ -1637,7 +1636,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 
 		switch (frame_header->fis_type) {
 		case FIS_REGD2H:
-			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+			scic_sds_unsolicited_frame_control_get_buffer(&ihost->uf_control,
 								      frame_index,
 								      (void **)&frame_buffer);
 
@@ -1651,7 +1650,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 			break;
 
 		default:
-			dev_warn(scic_to_dev(scic),
+			dev_warn(&ihost->pdev->dev,
 				 "%s: IO Request:0x%p Frame Id:%d protocol "
 				  "violation occurred\n", __func__, stp_req,
 				  frame_index);
@@ -1664,7 +1663,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 
 		/* Frame has been decoded return it to the controller */
-		scic_sds_controller_release_frame(scic, frame_index);
+		scic_sds_controller_release_frame(ihost, frame_index);
 
 		return status;
 	}
@@ -1674,12 +1673,12 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		struct dev_to_host_fis *frame_header;
 		u32 *frame_buffer;
 
-		status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+		status = scic_sds_unsolicited_frame_control_get_header(&ihost->uf_control,
 								       frame_index,
 								       (void **)&frame_header);
 
 		if (status != SCI_SUCCESS) {
-			dev_err(scic_to_dev(scic),
+			dev_err(&ihost->pdev->dev,
 				"%s: SCIC IO Request 0x%p could not get frame "
 				"header for frame index %d, status %x\n",
 				__func__, stp_req, frame_index, status);
@@ -1689,7 +1688,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		switch (frame_header->fis_type) {
 		case FIS_PIO_SETUP:
 			/* Get from the frame buffer the PIO Setup Data */
-			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+			scic_sds_unsolicited_frame_control_get_buffer(&ihost->uf_control,
 								      frame_index,
 								      (void **)&frame_buffer);
 
@@ -1736,7 +1735,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 				 * FIS when it is still busy?  Do nothing since
 				 * we are still in the right state.
 				 */
-				dev_dbg(scic_to_dev(scic),
+				dev_dbg(&ihost->pdev->dev,
 					"%s: SCIC PIO Request 0x%p received "
 					"D2H Register FIS with BSY status "
 					"0x%x\n",
@@ -1746,7 +1745,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 				break;
 			}
 
-			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+			scic_sds_unsolicited_frame_control_get_buffer(&ihost->uf_control,
 								      frame_index,
 								      (void **)&frame_buffer);
 
@@ -1767,7 +1766,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		}
 
 		/* Frame is decoded return it to the controller */
-		scic_sds_controller_release_frame(scic, frame_index);
+		scic_sds_controller_release_frame(ihost, frame_index);
 
 		return status;
 	}
@@ -1776,12 +1775,12 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		struct dev_to_host_fis *frame_header;
 		struct sata_fis_data *frame_buffer;
 
-		status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+		status = scic_sds_unsolicited_frame_control_get_header(&ihost->uf_control,
 								       frame_index,
 								       (void **)&frame_header);
 
 		if (status != SCI_SUCCESS) {
-			dev_err(scic_to_dev(scic),
+			dev_err(&ihost->pdev->dev,
 				"%s: SCIC IO Request 0x%p could not get frame "
 				"header for frame index %d, status %x\n",
 				__func__,
@@ -1792,7 +1791,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		}
 
 		if (frame_header->fis_type != FIS_DATA) {
-			dev_err(scic_to_dev(scic),
+			dev_err(&ihost->pdev->dev,
 				"%s: SCIC PIO Request 0x%p received frame %d "
 				"with fis type 0x%02x when expecting a data "
 				"fis.\n",
@@ -1808,7 +1807,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 
 			/* Frame is decoded return it to the controller */
-			scic_sds_controller_release_frame(scic, frame_index);
+			scic_sds_controller_release_frame(ihost, frame_index);
 			return status;
 		}
 
@@ -1816,7 +1815,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 			ireq->saved_rx_frame_index = frame_index;
 			stp_req->pio_len = 0;
 		} else {
-			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+			scic_sds_unsolicited_frame_control_get_buffer(&ihost->uf_control,
 								      frame_index,
 								      (void **)&frame_buffer);
 
@@ -1824,7 +1823,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 									    (u8 *)frame_buffer);
 
 			/* Frame is decoded return it to the controller */
-			scic_sds_controller_release_frame(scic, frame_index);
+			scic_sds_controller_release_frame(ihost, frame_index);
 		}
 
 		/* Check for the end of the transfer, are there more
@@ -1849,11 +1848,11 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		struct dev_to_host_fis *frame_header;
 		u32 *frame_buffer;
 
-		status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+		status = scic_sds_unsolicited_frame_control_get_header(&ihost->uf_control,
 								       frame_index,
 								       (void **)&frame_header);
 		if (status != SCI_SUCCESS) {
-			dev_err(scic_to_dev(scic),
+			dev_err(&ihost->pdev->dev,
 				"%s: SCIC IO Request 0x%p could not get frame "
 				"header for frame index %d, status %x\n",
 				__func__,
@@ -1865,7 +1864,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 
 		switch (frame_header->fis_type) {
 		case FIS_REGD2H:
-			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+			scic_sds_unsolicited_frame_control_get_buffer(&ihost->uf_control,
 								      frame_index,
 								      (void **)&frame_buffer);
 
@@ -1880,7 +1879,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 			break;
 
 		default:
-			dev_warn(scic_to_dev(scic),
+			dev_warn(&ihost->pdev->dev,
 				 "%s: IO Request:0x%p Frame Id:%d protocol "
 				 "violation occurred\n",
 				 __func__,
@@ -1896,7 +1895,7 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 
 		/* Frame has been decoded return it to the controller */
-		scic_sds_controller_release_frame(scic, frame_index);
+		scic_sds_controller_release_frame(ihost, frame_index);
 
 		return status;
 	}
@@ -1905,18 +1904,18 @@ scic_sds_io_request_frame_handler(struct isci_request *ireq,
 		 * TODO: Is it even possible to get an unsolicited frame in the
 		 * aborting state?
 		 */
-		scic_sds_controller_release_frame(scic, frame_index);
+		scic_sds_controller_release_frame(ihost, frame_index);
 		return SCI_SUCCESS;
 
 	default:
-		dev_warn(scic_to_dev(scic),
+		dev_warn(&ihost->pdev->dev,
 			 "%s: SCIC IO Request given unexpected frame %x while "
 			 "in state %d\n",
 			 __func__,
 			 frame_index,
 			 state);
 
-		scic_sds_controller_release_frame(scic, frame_index);
+		scic_sds_controller_release_frame(ihost, frame_index);
 		return SCI_FAILURE_INVALID_STATE;
 	}
 }
@@ -2042,7 +2041,7 @@ scic_sds_io_request_tc_completion(struct isci_request *ireq,
 				  u32 completion_code)
 {
 	enum sci_base_request_states state;
-	struct scic_sds_controller *scic = ireq->owning_controller;
+	struct isci_host *ihost = ireq->owning_controller;
 
 	state = ireq->sm.current_state_id;
 
@@ -2089,7 +2088,7 @@ scic_sds_io_request_tc_completion(struct isci_request *ireq,
 						       completion_code);
 
 	default:
-		dev_warn(scic_to_dev(scic),
+		dev_warn(&ihost->pdev->dev,
 			 "%s: SCIC IO Request given task completion "
 			 "notification %x while in wrong state %d\n",
 			 __func__,
@@ -2480,7 +2479,7 @@ static void isci_task_save_for_upper_layer_completion(
 	}
 }
 
-static void isci_request_io_request_complete(struct isci_host *isci_host,
+static void isci_request_io_request_complete(struct isci_host *ihost,
 					     struct isci_request *request,
 					     enum sci_io_status completion_status)
 {
@@ -2495,7 +2494,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 	enum isci_completion_selection complete_to_host
 		= isci_perform_normal_io_completion;
 
-	dev_dbg(&isci_host->pdev->dev,
+	dev_dbg(&ihost->pdev->dev,
 		"%s: request = %p, task = %p,\n"
 		"task->data_dir = %d completion_status = 0x%x\n",
 		__func__,
@@ -2616,7 +2615,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 		switch (completion_status) {
 
 		case SCI_IO_FAILURE_RESPONSE_VALID:
-			dev_dbg(&isci_host->pdev->dev,
+			dev_dbg(&ihost->pdev->dev,
 				"%s: SCI_IO_FAILURE_RESPONSE_VALID (%p/%p)\n",
 				__func__,
 				request,
@@ -2631,17 +2630,17 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 				/* crack the iu response buffer. */
 				resp_iu = &request->ssp.rsp;
 				isci_request_process_response_iu(task, resp_iu,
-								 &isci_host->pdev->dev);
+								 &ihost->pdev->dev);
 
 			} else if (SAS_PROTOCOL_SMP == task->task_proto) {
 
-				dev_err(&isci_host->pdev->dev,
+				dev_err(&ihost->pdev->dev,
 					"%s: SCI_IO_FAILURE_RESPONSE_VALID: "
 					"SAS_PROTOCOL_SMP protocol\n",
 					__func__);
 
 			} else
-				dev_err(&isci_host->pdev->dev,
+				dev_err(&ihost->pdev->dev,
 					"%s: unknown protocol\n", __func__);
 
 			/* use the task status set in the task struct by the
@@ -2662,7 +2661,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 			if (task->task_proto == SAS_PROTOCOL_SMP) {
 				void *rsp = &request->smp.rsp;
 
-				dev_dbg(&isci_host->pdev->dev,
+				dev_dbg(&ihost->pdev->dev,
 					"%s: SMP protocol completion\n",
 					__func__);
 
@@ -2687,20 +2686,20 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 				if (task->task_status.residual != 0)
 					status = SAS_DATA_UNDERRUN;
 
-				dev_dbg(&isci_host->pdev->dev,
+				dev_dbg(&ihost->pdev->dev,
 					"%s: SCI_IO_SUCCESS_IO_DONE_EARLY %d\n",
 					__func__,
 					status);
 
 			} else
-				dev_dbg(&isci_host->pdev->dev,
+				dev_dbg(&ihost->pdev->dev,
 					"%s: SCI_IO_SUCCESS\n",
 					__func__);
 
 			break;
 
 		case SCI_IO_FAILURE_TERMINATED:
-			dev_dbg(&isci_host->pdev->dev,
+			dev_dbg(&ihost->pdev->dev,
 				"%s: SCI_IO_FAILURE_TERMINATED (%p/%p)\n",
 				__func__,
 				request,
@@ -2768,7 +2767,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 
 		default:
 			/* Catch any otherwise unhandled error codes here. */
-			dev_warn(&isci_host->pdev->dev,
+			dev_warn(&ihost->pdev->dev,
 				 "%s: invalid completion code: 0x%x - "
 				 "isci_request = %p\n",
 				 __func__, completion_status, request);
@@ -2802,11 +2801,11 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 			break;
 		if (task->num_scatter == 0)
 			/* 0 indicates a single dma address */
-			dma_unmap_single(&isci_host->pdev->dev,
+			dma_unmap_single(&ihost->pdev->dev,
 					 request->zero_scatter_daddr,
 					 task->total_xfer_len, task->data_dir);
 		else  /* unmap the sgl dma addresses */
-			dma_unmap_sg(&isci_host->pdev->dev, task->scatter,
+			dma_unmap_sg(&ihost->pdev->dev, task->scatter,
 				     request->num_sg_entries, task->data_dir);
 		break;
 	case SAS_PROTOCOL_SMP: {
@@ -2814,7 +2813,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 		struct smp_req *smp_req;
 		void *kaddr;
 
-		dma_unmap_sg(&isci_host->pdev->dev, sg, 1, DMA_TO_DEVICE);
+		dma_unmap_sg(&ihost->pdev->dev, sg, 1, DMA_TO_DEVICE);
 
 		/* need to swab it back in case the command buffer is re-used */
 		kaddr = kmap_atomic(sg_page(sg), KM_IRQ0);
@@ -2828,14 +2827,12 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 	}
 
 	/* Put the completed request on the correct list */
-	isci_task_save_for_upper_layer_completion(isci_host, request, response,
+	isci_task_save_for_upper_layer_completion(ihost, request, response,
 						  status, complete_to_host
 						  );
 
 	/* complete the io request to the core. */
-	scic_controller_complete_io(&isci_host->sci,
-				    request->target_device,
-				    request);
+	scic_controller_complete_io(ihost, request->target_device, request);
 	isci_put_device(idev);
 
 	/* set terminated handle so it cannot be completed or
@@ -2885,8 +2882,7 @@ static void scic_sds_request_started_state_enter(struct sci_base_state_machine *
 static void scic_sds_request_completed_state_enter(struct sci_base_state_machine *sm)
 {
 	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
-	struct scic_sds_controller *scic = ireq->owning_controller;
-	struct isci_host *ihost = scic_to_ihost(scic);
+	struct isci_host *ihost = ireq->owning_controller;
 
 	/* Tell the SCI_USER that the IO request is complete */
 	if (!test_bit(IREQ_TMF, &ireq->flags))
@@ -2985,7 +2981,7 @@ static const struct sci_base_state scic_sds_request_state_table[] = {
 };
 
 static void
-scic_sds_general_request_construct(struct scic_sds_controller *scic,
+scic_sds_general_request_construct(struct isci_host *ihost,
 				   struct isci_remote_device *idev,
 				   struct isci_request *ireq)
 {
@@ -3001,7 +2997,7 @@ scic_sds_general_request_construct(struct scic_sds_controller *scic,
 }
 
 static enum sci_status
-scic_io_request_construct(struct scic_sds_controller *scic,
+scic_io_request_construct(struct isci_host *ihost,
 			  struct isci_remote_device *idev,
 			  struct isci_request *ireq)
 {
@@ -3009,7 +3005,7 @@ scic_io_request_construct(struct scic_sds_controller *scic,
 	enum sci_status status = SCI_SUCCESS;
 
 	/* Build the common part of the request */
-	scic_sds_general_request_construct(scic, idev, ireq);
+	scic_sds_general_request_construct(ihost, idev, ireq);
 
 	if (idev->rnc.remote_node_index == SCIC_SDS_REMOTE_NODE_CONTEXT_INVALID_INDEX)
 		return SCI_FAILURE_INVALID_REMOTE_DEVICE;
@@ -3028,7 +3024,7 @@ scic_io_request_construct(struct scic_sds_controller *scic,
 	return status;
 }
 
-enum sci_status scic_task_request_construct(struct scic_sds_controller *scic,
+enum sci_status scic_task_request_construct(struct isci_host *ihost,
 					    struct isci_remote_device *idev,
 					    u16 io_tag, struct isci_request *ireq)
 {
@@ -3036,7 +3032,7 @@ enum sci_status scic_task_request_construct(struct scic_sds_controller *scic,
 	enum sci_status status = SCI_SUCCESS;
 
 	/* Build the common part of the request */
-	scic_sds_general_request_construct(scic, idev, ireq);
+	scic_sds_general_request_construct(ihost, idev, ireq);
 
 	if (dev->dev_type == SAS_END_DEV ||
 	    dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP)) {
@@ -3156,7 +3152,7 @@ scic_io_request_construct_smp(struct device *dev,
 	task_context->initiator_request = 1;
 	task_context->connection_rate = idev->connection_rate;
 	task_context->protocol_engine_index =
-		scic_sds_controller_get_protocol_engine_group(scic);
+		scic_sds_controller_get_protocol_engine_group(ihost);
 	task_context->logical_port_index = scic_sds_port_get_index(iport);
 	task_context->protocol_type = SCU_TASK_CONTEXT_PROTOCOL_SMP;
 	task_context->abort = 0;
@@ -3199,7 +3195,7 @@ scic_io_request_construct_smp(struct device *dev,
 	task_context->task_phase = 0;
 
 	ireq->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
-				 (scic_sds_controller_get_protocol_engine_group(scic) <<
+				 (scic_sds_controller_get_protocol_engine_group(ihost) <<
 				  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
 				 (scic_sds_port_get_index(iport) <<
 				  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
@@ -3245,7 +3241,7 @@ static enum sci_status isci_smp_request_build(struct isci_request *ireq)
 
 /**
  * isci_io_request_build() - This function builds the io request object.
- * @isci_host: This parameter specifies the ISCI host object
+ * @ihost: This parameter specifies the ISCI host object
  * @request: This parameter points to the isci_request object allocated in the
  *    request construct function.
  * @sci_device: This parameter is the handle for the sci core's remote device
@@ -3253,14 +3249,14 @@ static enum sci_status isci_smp_request_build(struct isci_request *ireq)
  *
  * SCI_SUCCESS on successfull completion, or specific failure code.
  */
-static enum sci_status isci_io_request_build(struct isci_host *isci_host,
+static enum sci_status isci_io_request_build(struct isci_host *ihost,
 					     struct isci_request *request,
 					     struct isci_remote_device *idev)
 {
 	enum sci_status status = SCI_SUCCESS;
 	struct sas_task *task = isci_request_access_task(request);
 
-	dev_dbg(&isci_host->pdev->dev,
+	dev_dbg(&ihost->pdev->dev,
 		"%s: idev = 0x%p; request = %p, "
 		"num_scatter = %d\n",
 		__func__,
@@ -3277,7 +3273,7 @@ static enum sci_status isci_io_request_build(struct isci_host *isci_host,
 	    !(SAS_PROTOCOL_SMP & task->task_proto)) {
 
 		request->num_sg_entries = dma_map_sg(
-			&isci_host->pdev->dev,
+			&ihost->pdev->dev,
 			task->scatter,
 			task->num_scatter,
 			task->data_dir
@@ -3287,10 +3283,10 @@ static enum sci_status isci_io_request_build(struct isci_host *isci_host,
 			return SCI_FAILURE_INSUFFICIENT_RESOURCES;
 	}
 
-	status = scic_io_request_construct(&isci_host->sci, idev, request);
+	status = scic_io_request_construct(ihost, idev, request);
 
 	if (status != SCI_SUCCESS) {
-		dev_warn(&isci_host->pdev->dev,
+		dev_warn(&ihost->pdev->dev,
 			 "%s: failed request construct\n",
 			 __func__);
 		return SCI_FAILURE;
@@ -3309,7 +3305,7 @@ static enum sci_status isci_io_request_build(struct isci_host *isci_host,
 		status = isci_request_stp_request_construct(request);
 		break;
 	default:
-		dev_warn(&isci_host->pdev->dev,
+		dev_warn(&ihost->pdev->dev,
 			 "%s: unknown protocol\n", __func__);
 		return SCI_FAILURE;
 	}
@@ -3392,7 +3388,7 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 			 * request was built that way (ie.
 			 * ireq->is_task_management_request is false).
 			 */
-			status = scic_controller_start_task(&ihost->sci,
+			status = scic_controller_start_task(ihost,
 							    idev,
 							    ireq);
 		} else {
@@ -3400,7 +3396,7 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 		}
 	} else {
 		/* send the request, let the core assign the IO TAG.	*/
-		status = scic_controller_start_io(&ihost->sci, idev,
+		status = scic_controller_start_io(ihost, idev,
 						  ireq);
 	}
 

commit 78a6f06e0e82125787d7aa308fe28c2c8381540c
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Jun 30 16:31:37 2011 -0700

    isci: unify isci_remote_device and scic_sds_remote_device
    
    Remove the distinction between these two implementations and unify on
    isci_remote_device (local instances named idev).
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 2d29abf3ce1f..90ead662828d 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -209,17 +209,17 @@ static void scu_ssp_reqeust_construct_task_context(
 	struct scu_task_context *task_context)
 {
 	dma_addr_t dma_addr;
-	struct scic_sds_remote_device *target_device;
+	struct isci_remote_device *idev;
 	struct isci_port *iport;
 
-	target_device = scic_sds_request_get_device(ireq);
+	idev = scic_sds_request_get_device(ireq);
 	iport = scic_sds_request_get_port(ireq);
 
 	/* Fill in the TC with the its required data */
 	task_context->abort = 0;
 	task_context->priority = 0;
 	task_context->initiator_request = 1;
-	task_context->connection_rate = target_device->connection_rate;
+	task_context->connection_rate = idev->connection_rate;
 	task_context->protocol_engine_index =
 		scic_sds_controller_get_protocol_engine_group(controller);
 	task_context->logical_port_index = scic_sds_port_get_index(iport);
@@ -227,8 +227,7 @@ static void scu_ssp_reqeust_construct_task_context(
 	task_context->valid = SCU_TASK_CONTEXT_VALID;
 	task_context->context_type = SCU_TASK_CONTEXT_TYPE;
 
-	task_context->remote_node_index =
-		scic_sds_remote_device_get_index(ireq->target_device);
+	task_context->remote_node_index = scic_sds_remote_device_get_index(idev);
 	task_context->command_code = 0;
 
 	task_context->link_layer_control = 0;
@@ -348,17 +347,17 @@ static void scu_sata_reqeust_construct_task_context(
 	struct scu_task_context *task_context)
 {
 	dma_addr_t dma_addr;
-	struct scic_sds_remote_device *target_device;
+	struct isci_remote_device *idev;
 	struct isci_port *iport;
 
-	target_device = scic_sds_request_get_device(ireq);
+	idev = scic_sds_request_get_device(ireq);
 	iport = scic_sds_request_get_port(ireq);
 
 	/* Fill in the TC with the its required data */
 	task_context->abort = 0;
 	task_context->priority = SCU_TASK_PRIORITY_NORMAL;
 	task_context->initiator_request = 1;
-	task_context->connection_rate = target_device->connection_rate;
+	task_context->connection_rate = idev->connection_rate;
 	task_context->protocol_engine_index =
 		scic_sds_controller_get_protocol_engine_group(controller);
 	task_context->logical_port_index =
@@ -367,8 +366,7 @@ static void scu_sata_reqeust_construct_task_context(
 	task_context->valid = SCU_TASK_CONTEXT_VALID;
 	task_context->context_type = SCU_TASK_CONTEXT_TYPE;
 
-	task_context->remote_node_index =
-		scic_sds_remote_device_get_index(ireq->target_device);
+	task_context->remote_node_index = scic_sds_remote_device_get_index(idev);
 	task_context->command_code = 0;
 
 	task_context->link_layer_control = 0;
@@ -2850,7 +2848,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 static void scic_sds_request_started_state_enter(struct sci_base_state_machine *sm)
 {
 	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
-	struct domain_device *dev = sci_dev_to_domain(ireq->target_device);
+	struct domain_device *dev = ireq->target_device->domain_dev;
 	struct sas_task *task;
 
 	/* XXX as hch said always creating an internal sas_task for tmf
@@ -2988,12 +2986,12 @@ static const struct sci_base_state scic_sds_request_state_table[] = {
 
 static void
 scic_sds_general_request_construct(struct scic_sds_controller *scic,
-				   struct scic_sds_remote_device *sci_dev,
+				   struct isci_remote_device *idev,
 				   struct isci_request *ireq)
 {
 	sci_init_sm(&ireq->sm, scic_sds_request_state_table, SCI_REQ_INIT);
 
-	ireq->target_device = sci_dev;
+	ireq->target_device = idev;
 	ireq->protocol = SCIC_NO_PROTOCOL;
 	ireq->saved_rx_frame_index = SCU_INVALID_FRAME_INDEX;
 
@@ -3004,16 +3002,16 @@ scic_sds_general_request_construct(struct scic_sds_controller *scic,
 
 static enum sci_status
 scic_io_request_construct(struct scic_sds_controller *scic,
-			  struct scic_sds_remote_device *sci_dev,
+			  struct isci_remote_device *idev,
 			  struct isci_request *ireq)
 {
-	struct domain_device *dev = sci_dev_to_domain(sci_dev);
+	struct domain_device *dev = idev->domain_dev;
 	enum sci_status status = SCI_SUCCESS;
 
 	/* Build the common part of the request */
-	scic_sds_general_request_construct(scic, sci_dev, ireq);
+	scic_sds_general_request_construct(scic, idev, ireq);
 
-	if (sci_dev->rnc.remote_node_index == SCIC_SDS_REMOTE_NODE_CONTEXT_INVALID_INDEX)
+	if (idev->rnc.remote_node_index == SCIC_SDS_REMOTE_NODE_CONTEXT_INVALID_INDEX)
 		return SCI_FAILURE_INVALID_REMOTE_DEVICE;
 
 	if (dev->dev_type == SAS_END_DEV)
@@ -3031,14 +3029,14 @@ scic_io_request_construct(struct scic_sds_controller *scic,
 }
 
 enum sci_status scic_task_request_construct(struct scic_sds_controller *scic,
-					    struct scic_sds_remote_device *sci_dev,
+					    struct isci_remote_device *idev,
 					    u16 io_tag, struct isci_request *ireq)
 {
-	struct domain_device *dev = sci_dev_to_domain(sci_dev);
+	struct domain_device *dev = idev->domain_dev;
 	enum sci_status status = SCI_SUCCESS;
 
 	/* Build the common part of the request */
-	scic_sds_general_request_construct(scic, sci_dev, ireq);
+	scic_sds_general_request_construct(scic, idev, ireq);
 
 	if (dev->dev_type == SAS_END_DEV ||
 	    dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP)) {
@@ -3102,7 +3100,7 @@ scic_io_request_construct_smp(struct device *dev,
 			      struct sas_task *task)
 {
 	struct scatterlist *sg = &task->smp_task.smp_req;
-	struct scic_sds_remote_device *sci_dev;
+	struct isci_remote_device *idev;
 	struct scu_task_context *task_context;
 	struct isci_port *iport;
 	struct smp_req *smp_req;
@@ -3147,7 +3145,7 @@ scic_io_request_construct_smp(struct device *dev,
 
 	task_context = ireq->tc;
 
-	sci_dev = scic_sds_request_get_device(ireq);
+	idev = scic_sds_request_get_device(ireq);
 	iport = scic_sds_request_get_port(ireq);
 
 	/*
@@ -3156,7 +3154,7 @@ scic_io_request_construct_smp(struct device *dev,
 	 */
 	task_context->priority = 0;
 	task_context->initiator_request = 1;
-	task_context->connection_rate = sci_dev->connection_rate;
+	task_context->connection_rate = idev->connection_rate;
 	task_context->protocol_engine_index =
 		scic_sds_controller_get_protocol_engine_group(scic);
 	task_context->logical_port_index = scic_sds_port_get_index(iport);
@@ -3166,7 +3164,7 @@ scic_io_request_construct_smp(struct device *dev,
 	task_context->context_type = SCU_TASK_CONTEXT_TYPE;
 
 	/* 04h */
-	task_context->remote_node_index = sci_dev->rnc.remote_node_index;
+	task_context->remote_node_index = idev->rnc.remote_node_index;
 	task_context->command_code = 0;
 	task_context->task_type = SCU_TASK_TYPE_SMP_REQUEST;
 
@@ -3257,17 +3255,16 @@ static enum sci_status isci_smp_request_build(struct isci_request *ireq)
  */
 static enum sci_status isci_io_request_build(struct isci_host *isci_host,
 					     struct isci_request *request,
-					     struct isci_remote_device *isci_device)
+					     struct isci_remote_device *idev)
 {
 	enum sci_status status = SCI_SUCCESS;
 	struct sas_task *task = isci_request_access_task(request);
-	struct scic_sds_remote_device *sci_device = &isci_device->sci;
 
 	dev_dbg(&isci_host->pdev->dev,
-		"%s: isci_device = 0x%p; request = %p, "
+		"%s: idev = 0x%p; request = %p, "
 		"num_scatter = %d\n",
 		__func__,
-		isci_device,
+		idev,
 		request,
 		task->num_scatter);
 
@@ -3290,8 +3287,7 @@ static enum sci_status isci_io_request_build(struct isci_host *isci_host,
 			return SCI_FAILURE_INSUFFICIENT_RESOURCES;
 	}
 
-	status = scic_io_request_construct(&isci_host->sci, sci_device,
-					   request);
+	status = scic_io_request_construct(&isci_host->sci, idev, request);
 
 	if (status != SCI_SUCCESS) {
 		dev_warn(&isci_host->pdev->dev,
@@ -3397,14 +3393,14 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 			 * ireq->is_task_management_request is false).
 			 */
 			status = scic_controller_start_task(&ihost->sci,
-							    &idev->sci,
+							    idev,
 							    ireq);
 		} else {
 			status = SCI_FAILURE;
 		}
 	} else {
 		/* send the request, let the core assign the IO TAG.	*/
-		status = scic_controller_start_io(&ihost->sci, &idev->sci,
+		status = scic_controller_start_io(&ihost->sci, idev,
 						  ireq);
 	}
 

commit ffe191c92ff195d73f9130b1490045ca2dd4c5e0
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed Jun 29 13:09:25 2011 -0700

    isci: unify isci_port and scic_sds_port
    
    Remove the distinction between these two implementations and unify on
    isci_port (local instances named iport).  The duplicate '->owning_port' and
    '->isci_port' in both isci_phy and isci_remote_device will be fixed in a later
    patch... this is just the straightforward rename/unification.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index c544bc79ce17..2d29abf3ce1f 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -210,10 +210,10 @@ static void scu_ssp_reqeust_construct_task_context(
 {
 	dma_addr_t dma_addr;
 	struct scic_sds_remote_device *target_device;
-	struct scic_sds_port *target_port;
+	struct isci_port *iport;
 
 	target_device = scic_sds_request_get_device(ireq);
-	target_port = scic_sds_request_get_port(ireq);
+	iport = scic_sds_request_get_port(ireq);
 
 	/* Fill in the TC with the its required data */
 	task_context->abort = 0;
@@ -222,8 +222,7 @@ static void scu_ssp_reqeust_construct_task_context(
 	task_context->connection_rate = target_device->connection_rate;
 	task_context->protocol_engine_index =
 		scic_sds_controller_get_protocol_engine_group(controller);
-	task_context->logical_port_index =
-		scic_sds_port_get_index(target_port);
+	task_context->logical_port_index = scic_sds_port_get_index(iport);
 	task_context->protocol_type = SCU_TASK_CONTEXT_PROTOCOL_SSP;
 	task_context->valid = SCU_TASK_CONTEXT_VALID;
 	task_context->context_type = SCU_TASK_CONTEXT_TYPE;
@@ -245,11 +244,11 @@ static void scu_ssp_reqeust_construct_task_context(
 	task_context->task_phase = 0x01;
 
 	ireq->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
-				     (scic_sds_controller_get_protocol_engine_group(controller) <<
-				      SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
-				     (scic_sds_port_get_index(target_port) <<
-				      SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
-				     ISCI_TAG_TCI(ireq->io_tag));
+			      (scic_sds_controller_get_protocol_engine_group(controller) <<
+			       SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
+			      (scic_sds_port_get_index(iport) <<
+			       SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
+			      ISCI_TAG_TCI(ireq->io_tag));
 
 	/*
 	 * Copy the physical address for the command buffer to the
@@ -350,10 +349,10 @@ static void scu_sata_reqeust_construct_task_context(
 {
 	dma_addr_t dma_addr;
 	struct scic_sds_remote_device *target_device;
-	struct scic_sds_port *target_port;
+	struct isci_port *iport;
 
 	target_device = scic_sds_request_get_device(ireq);
-	target_port = scic_sds_request_get_port(ireq);
+	iport = scic_sds_request_get_port(ireq);
 
 	/* Fill in the TC with the its required data */
 	task_context->abort = 0;
@@ -363,7 +362,7 @@ static void scu_sata_reqeust_construct_task_context(
 	task_context->protocol_engine_index =
 		scic_sds_controller_get_protocol_engine_group(controller);
 	task_context->logical_port_index =
-		scic_sds_port_get_index(target_port);
+		scic_sds_port_get_index(iport);
 	task_context->protocol_type = SCU_TASK_CONTEXT_PROTOCOL_STP;
 	task_context->valid = SCU_TASK_CONTEXT_VALID;
 	task_context->context_type = SCU_TASK_CONTEXT_TYPE;
@@ -391,7 +390,7 @@ static void scu_sata_reqeust_construct_task_context(
 	ireq->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
 				 (scic_sds_controller_get_protocol_engine_group(controller) <<
 				  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
-				 (scic_sds_port_get_index(target_port) <<
+				 (scic_sds_port_get_index(iport) <<
 				  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
 				 ISCI_TAG_TCI(ireq->io_tag));
 	/*
@@ -3105,7 +3104,7 @@ scic_io_request_construct_smp(struct device *dev,
 	struct scatterlist *sg = &task->smp_task.smp_req;
 	struct scic_sds_remote_device *sci_dev;
 	struct scu_task_context *task_context;
-	struct scic_sds_port *sci_port;
+	struct isci_port *iport;
 	struct smp_req *smp_req;
 	void *kaddr;
 	u8 req_len;
@@ -3149,7 +3148,7 @@ scic_io_request_construct_smp(struct device *dev,
 	task_context = ireq->tc;
 
 	sci_dev = scic_sds_request_get_device(ireq);
-	sci_port = scic_sds_request_get_port(ireq);
+	iport = scic_sds_request_get_port(ireq);
 
 	/*
 	 * Fill in the TC with the its required data
@@ -3160,7 +3159,7 @@ scic_io_request_construct_smp(struct device *dev,
 	task_context->connection_rate = sci_dev->connection_rate;
 	task_context->protocol_engine_index =
 		scic_sds_controller_get_protocol_engine_group(scic);
-	task_context->logical_port_index = scic_sds_port_get_index(sci_port);
+	task_context->logical_port_index = scic_sds_port_get_index(iport);
 	task_context->protocol_type = SCU_TASK_CONTEXT_PROTOCOL_SMP;
 	task_context->abort = 0;
 	task_context->valid = SCU_TASK_CONTEXT_VALID;
@@ -3204,7 +3203,7 @@ scic_io_request_construct_smp(struct device *dev,
 	ireq->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
 				 (scic_sds_controller_get_protocol_engine_group(scic) <<
 				  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
-				 (scic_sds_port_get_index(sci_port) <<
+				 (scic_sds_port_get_index(iport) <<
 				  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
 				 ISCI_TAG_TCI(ireq->io_tag));
 	/*

commit 5076a1a97e2fa61c847a5fdd4b1991faf7716da6
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Jun 27 14:57:03 2011 -0700

    isci: unify isci_request and scic_sds_request
    
    They are one in the same object so remove the distinction.  The near
    duplicate fields (owning_controller, and isci_host) will be cleaned up
    after the scic_sds_contoller isci_host unification.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 8520626b02fa..c544bc79ce17 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -61,35 +61,35 @@
 #include "scu_event_codes.h"
 #include "sas.h"
 
-static struct scu_sgl_element_pair *to_sgl_element_pair(struct scic_sds_request *sci_req,
+static struct scu_sgl_element_pair *to_sgl_element_pair(struct isci_request *ireq,
 							int idx)
 {
 	if (idx == 0)
-		return &sci_req->tc->sgl_pair_ab;
+		return &ireq->tc->sgl_pair_ab;
 	else if (idx == 1)
-		return &sci_req->tc->sgl_pair_cd;
+		return &ireq->tc->sgl_pair_cd;
 	else if (idx < 0)
 		return NULL;
 	else
-		return &sci_req->sg_table[idx - 2];
+		return &ireq->sg_table[idx - 2];
 }
 
 static dma_addr_t to_sgl_element_pair_dma(struct scic_sds_controller *scic,
-					  struct scic_sds_request *sci_req, u32 idx)
+					  struct isci_request *ireq, u32 idx)
 {
 	u32 offset;
 
 	if (idx == 0) {
-		offset = (void *) &sci_req->tc->sgl_pair_ab -
+		offset = (void *) &ireq->tc->sgl_pair_ab -
 			 (void *) &scic->task_context_table[0];
 		return scic->task_context_dma + offset;
 	} else if (idx == 1) {
-		offset = (void *) &sci_req->tc->sgl_pair_cd -
+		offset = (void *) &ireq->tc->sgl_pair_cd -
 			 (void *) &scic->task_context_table[0];
 		return scic->task_context_dma + offset;
 	}
 
-	return scic_io_request_get_dma_addr(sci_req, &sci_req->sg_table[idx - 2]);
+	return scic_io_request_get_dma_addr(ireq, &ireq->sg_table[idx - 2]);
 }
 
 static void init_sgl_element(struct scu_sgl_element *e, struct scatterlist *sg)
@@ -100,12 +100,11 @@ static void init_sgl_element(struct scu_sgl_element *e, struct scatterlist *sg)
 	e->address_modifier = 0;
 }
 
-static void scic_sds_request_build_sgl(struct scic_sds_request *sds_request)
+static void scic_sds_request_build_sgl(struct isci_request *ireq)
 {
-	struct isci_request *isci_request = sci_req_to_ireq(sds_request);
-	struct isci_host *isci_host = isci_request->isci_host;
+	struct isci_host *isci_host = ireq->isci_host;
 	struct scic_sds_controller *scic = &isci_host->sci;
-	struct sas_task *task = isci_request_access_task(isci_request);
+	struct sas_task *task = isci_request_access_task(ireq);
 	struct scatterlist *sg = NULL;
 	dma_addr_t dma_addr;
 	u32 sg_idx = 0;
@@ -116,7 +115,7 @@ static void scic_sds_request_build_sgl(struct scic_sds_request *sds_request)
 		sg = task->scatter;
 
 		while (sg) {
-			scu_sg = to_sgl_element_pair(sds_request, sg_idx);
+			scu_sg = to_sgl_element_pair(ireq, sg_idx);
 			init_sgl_element(&scu_sg->A, sg);
 			sg = sg_next(sg);
 			if (sg) {
@@ -127,7 +126,7 @@ static void scic_sds_request_build_sgl(struct scic_sds_request *sds_request)
 
 			if (prev_sg) {
 				dma_addr = to_sgl_element_pair_dma(scic,
-								   sds_request,
+								   ireq,
 								   sg_idx);
 
 				prev_sg->next_pair_upper =
@@ -140,14 +139,14 @@ static void scic_sds_request_build_sgl(struct scic_sds_request *sds_request)
 			sg_idx++;
 		}
 	} else {	/* handle when no sg */
-		scu_sg = to_sgl_element_pair(sds_request, sg_idx);
+		scu_sg = to_sgl_element_pair(ireq, sg_idx);
 
 		dma_addr = dma_map_single(&isci_host->pdev->dev,
 					  task->scatter,
 					  task->total_xfer_len,
 					  task->data_dir);
 
-		isci_request->zero_scatter_daddr = dma_addr;
+		ireq->zero_scatter_daddr = dma_addr;
 
 		scu_sg->A.length = task->total_xfer_len;
 		scu_sg->A.address_upper = upper_32_bits(dma_addr);
@@ -160,13 +159,12 @@ static void scic_sds_request_build_sgl(struct scic_sds_request *sds_request)
 	}
 }
 
-static void scic_sds_io_request_build_ssp_command_iu(struct scic_sds_request *sci_req)
+static void scic_sds_io_request_build_ssp_command_iu(struct isci_request *ireq)
 {
 	struct ssp_cmd_iu *cmd_iu;
-	struct isci_request *ireq = sci_req_to_ireq(sci_req);
 	struct sas_task *task = isci_request_access_task(ireq);
 
-	cmd_iu = &sci_req->ssp.cmd;
+	cmd_iu = &ireq->ssp.cmd;
 
 	memcpy(cmd_iu->LUN, task->ssp_task.LUN, 8);
 	cmd_iu->add_cdb_len = 0;
@@ -181,14 +179,13 @@ static void scic_sds_io_request_build_ssp_command_iu(struct scic_sds_request *sc
 		       sizeof(task->ssp_task.cdb) / sizeof(u32));
 }
 
-static void scic_sds_task_request_build_ssp_task_iu(struct scic_sds_request *sci_req)
+static void scic_sds_task_request_build_ssp_task_iu(struct isci_request *ireq)
 {
 	struct ssp_task_iu *task_iu;
-	struct isci_request *ireq = sci_req_to_ireq(sci_req);
 	struct sas_task *task = isci_request_access_task(ireq);
 	struct isci_tmf *isci_tmf = isci_request_access_tmf(ireq);
 
-	task_iu = &sci_req->ssp.tmf;
+	task_iu = &ireq->ssp.tmf;
 
 	memset(task_iu, 0, sizeof(struct ssp_task_iu));
 
@@ -208,15 +205,15 @@ static void scic_sds_task_request_build_ssp_task_iu(struct scic_sds_request *sci
  *
  */
 static void scu_ssp_reqeust_construct_task_context(
-	struct scic_sds_request *sds_request,
+	struct isci_request *ireq,
 	struct scu_task_context *task_context)
 {
 	dma_addr_t dma_addr;
 	struct scic_sds_remote_device *target_device;
 	struct scic_sds_port *target_port;
 
-	target_device = scic_sds_request_get_device(sds_request);
-	target_port = scic_sds_request_get_port(sds_request);
+	target_device = scic_sds_request_get_device(ireq);
+	target_port = scic_sds_request_get_port(ireq);
 
 	/* Fill in the TC with the its required data */
 	task_context->abort = 0;
@@ -232,7 +229,7 @@ static void scu_ssp_reqeust_construct_task_context(
 	task_context->context_type = SCU_TASK_CONTEXT_TYPE;
 
 	task_context->remote_node_index =
-		scic_sds_remote_device_get_index(sds_request->target_device);
+		scic_sds_remote_device_get_index(ireq->target_device);
 	task_context->command_code = 0;
 
 	task_context->link_layer_control = 0;
@@ -244,22 +241,21 @@ static void scu_ssp_reqeust_construct_task_context(
 
 	task_context->address_modifier = 0;
 
-	/* task_context->type.ssp.tag = sci_req->io_tag; */
+	/* task_context->type.ssp.tag = ireq->io_tag; */
 	task_context->task_phase = 0x01;
 
-	sds_request->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
+	ireq->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
 				     (scic_sds_controller_get_protocol_engine_group(controller) <<
 				      SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
 				     (scic_sds_port_get_index(target_port) <<
 				      SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
-				     ISCI_TAG_TCI(sds_request->io_tag));
+				     ISCI_TAG_TCI(ireq->io_tag));
 
 	/*
 	 * Copy the physical address for the command buffer to the
 	 * SCU Task Context
 	 */
-	dma_addr = scic_io_request_get_dma_addr(sds_request,
-						&sds_request->ssp.cmd);
+	dma_addr = scic_io_request_get_dma_addr(ireq, &ireq->ssp.cmd);
 
 	task_context->command_iu_upper = upper_32_bits(dma_addr);
 	task_context->command_iu_lower = lower_32_bits(dma_addr);
@@ -268,8 +264,7 @@ static void scu_ssp_reqeust_construct_task_context(
 	 * Copy the physical address for the response buffer to the
 	 * SCU Task Context
 	 */
-	dma_addr = scic_io_request_get_dma_addr(sds_request,
-						&sds_request->ssp.rsp);
+	dma_addr = scic_io_request_get_dma_addr(ireq, &ireq->ssp.rsp);
 
 	task_context->response_iu_upper = upper_32_bits(dma_addr);
 	task_context->response_iu_lower = lower_32_bits(dma_addr);
@@ -280,13 +275,13 @@ static void scu_ssp_reqeust_construct_task_context(
  * @sci_req:
  *
  */
-static void scu_ssp_io_request_construct_task_context(struct scic_sds_request *sci_req,
+static void scu_ssp_io_request_construct_task_context(struct isci_request *ireq,
 						      enum dma_data_direction dir,
 						      u32 len)
 {
-	struct scu_task_context *task_context = sci_req->tc;
+	struct scu_task_context *task_context = ireq->tc;
 
-	scu_ssp_reqeust_construct_task_context(sci_req, task_context);
+	scu_ssp_reqeust_construct_task_context(ireq, task_context);
 
 	task_context->ssp_command_iu_length =
 		sizeof(struct ssp_cmd_iu) / sizeof(u32);
@@ -306,7 +301,7 @@ static void scu_ssp_io_request_construct_task_context(struct scic_sds_request *s
 	task_context->transfer_length_bytes = len;
 
 	if (task_context->transfer_length_bytes > 0)
-		scic_sds_request_build_sgl(sci_req);
+		scic_sds_request_build_sgl(ireq);
 }
 
 /**
@@ -322,11 +317,11 @@ static void scu_ssp_io_request_construct_task_context(struct scic_sds_request *s
  *    constructed.
  *
  */
-static void scu_ssp_task_request_construct_task_context(struct scic_sds_request *sci_req)
+static void scu_ssp_task_request_construct_task_context(struct isci_request *ireq)
 {
-	struct scu_task_context *task_context = sci_req->tc;
+	struct scu_task_context *task_context = ireq->tc;
 
-	scu_ssp_reqeust_construct_task_context(sci_req, task_context);
+	scu_ssp_reqeust_construct_task_context(ireq, task_context);
 
 	task_context->control_frame                = 1;
 	task_context->priority                     = SCU_TASK_PRIORITY_HIGH;
@@ -350,15 +345,15 @@ static void scu_ssp_task_request_construct_task_context(struct scic_sds_request
  * determine what is common for SSP/SMP/STP task context structures.
  */
 static void scu_sata_reqeust_construct_task_context(
-	struct scic_sds_request *sci_req,
+	struct isci_request *ireq,
 	struct scu_task_context *task_context)
 {
 	dma_addr_t dma_addr;
 	struct scic_sds_remote_device *target_device;
 	struct scic_sds_port *target_port;
 
-	target_device = scic_sds_request_get_device(sci_req);
-	target_port = scic_sds_request_get_port(sci_req);
+	target_device = scic_sds_request_get_device(ireq);
+	target_port = scic_sds_request_get_port(ireq);
 
 	/* Fill in the TC with the its required data */
 	task_context->abort = 0;
@@ -374,7 +369,7 @@ static void scu_sata_reqeust_construct_task_context(
 	task_context->context_type = SCU_TASK_CONTEXT_TYPE;
 
 	task_context->remote_node_index =
-		scic_sds_remote_device_get_index(sci_req->target_device);
+		scic_sds_remote_device_get_index(ireq->target_device);
 	task_context->command_code = 0;
 
 	task_context->link_layer_control = 0;
@@ -391,21 +386,21 @@ static void scu_sata_reqeust_construct_task_context(
 		(sizeof(struct host_to_dev_fis) - sizeof(u32)) / sizeof(u32);
 
 	/* Set the first word of the H2D REG FIS */
-	task_context->type.words[0] = *(u32 *)&sci_req->stp.cmd;
+	task_context->type.words[0] = *(u32 *)&ireq->stp.cmd;
 
-	sci_req->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
+	ireq->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
 				 (scic_sds_controller_get_protocol_engine_group(controller) <<
 				  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
 				 (scic_sds_port_get_index(target_port) <<
 				  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
-				 ISCI_TAG_TCI(sci_req->io_tag));
+				 ISCI_TAG_TCI(ireq->io_tag));
 	/*
 	 * Copy the physical address for the command buffer to the SCU Task
 	 * Context. We must offset the command buffer by 4 bytes because the
 	 * first 4 bytes are transfered in the body of the TC.
 	 */
-	dma_addr = scic_io_request_get_dma_addr(sci_req,
-						((char *) &sci_req->stp.cmd) +
+	dma_addr = scic_io_request_get_dma_addr(ireq,
+						((char *) &ireq->stp.cmd) +
 						sizeof(u32));
 
 	task_context->command_iu_upper = upper_32_bits(dma_addr);
@@ -416,11 +411,11 @@ static void scu_sata_reqeust_construct_task_context(
 	task_context->response_iu_lower = 0;
 }
 
-static void scu_stp_raw_request_construct_task_context(struct scic_sds_request *sci_req)
+static void scu_stp_raw_request_construct_task_context(struct isci_request *ireq)
 {
-	struct scu_task_context *task_context = sci_req->tc;
+	struct scu_task_context *task_context = ireq->tc;
 
-	scu_sata_reqeust_construct_task_context(sci_req, task_context);
+	scu_sata_reqeust_construct_task_context(ireq, task_context);
 
 	task_context->control_frame         = 0;
 	task_context->priority              = SCU_TASK_PRIORITY_NORMAL;
@@ -429,20 +424,19 @@ static void scu_stp_raw_request_construct_task_context(struct scic_sds_request *
 	task_context->transfer_length_bytes = sizeof(struct host_to_dev_fis) - sizeof(u32);
 }
 
-static enum sci_status
-scic_sds_stp_pio_request_construct(struct scic_sds_request *sci_req,
-				   bool copy_rx_frame)
+static enum sci_status scic_sds_stp_pio_request_construct(struct isci_request *ireq,
+							  bool copy_rx_frame)
 {
-	struct isci_stp_request *stp_req = &sci_req->stp.req;
+	struct isci_stp_request *stp_req = &ireq->stp.req;
 
-	scu_stp_raw_request_construct_task_context(sci_req);
+	scu_stp_raw_request_construct_task_context(ireq);
 
 	stp_req->status = 0;
 	stp_req->sgl.offset = 0;
 	stp_req->sgl.set = SCU_SGL_ELEMENT_PAIR_A;
 
 	if (copy_rx_frame) {
-		scic_sds_request_build_sgl(sci_req);
+		scic_sds_request_build_sgl(ireq);
 		stp_req->sgl.index = 0;
 	} else {
 		/* The user does not want the data copied to the SGL buffer location */
@@ -464,18 +458,18 @@ scic_sds_stp_pio_request_construct(struct scic_sds_request *sci_req,
  * requests that are optimized by the silicon (i.e. UDMA, NCQ). This method
  * returns an indication as to whether the construction was successful.
  */
-static void scic_sds_stp_optimized_request_construct(struct scic_sds_request *sci_req,
+static void scic_sds_stp_optimized_request_construct(struct isci_request *ireq,
 						     u8 optimized_task_type,
 						     u32 len,
 						     enum dma_data_direction dir)
 {
-	struct scu_task_context *task_context = sci_req->tc;
+	struct scu_task_context *task_context = ireq->tc;
 
 	/* Build the STP task context structure */
-	scu_sata_reqeust_construct_task_context(sci_req, task_context);
+	scu_sata_reqeust_construct_task_context(ireq, task_context);
 
 	/* Copy over the SGL elements */
-	scic_sds_request_build_sgl(sci_req);
+	scic_sds_request_build_sgl(ireq);
 
 	/* Copy over the number of bytes to be transfered */
 	task_context->transfer_length_bytes = len;
@@ -500,13 +494,12 @@ static void scic_sds_stp_optimized_request_construct(struct scic_sds_request *sc
 
 
 static enum sci_status
-scic_io_request_construct_sata(struct scic_sds_request *sci_req,
+scic_io_request_construct_sata(struct isci_request *ireq,
 			       u32 len,
 			       enum dma_data_direction dir,
 			       bool copy)
 {
 	enum sci_status status = SCI_SUCCESS;
-	struct isci_request *ireq = sci_req_to_ireq(sci_req);
 	struct sas_task *task = isci_request_access_task(ireq);
 
 	/* check for management protocols */
@@ -515,20 +508,20 @@ scic_io_request_construct_sata(struct scic_sds_request *sci_req,
 
 		if (tmf->tmf_code == isci_tmf_sata_srst_high ||
 		    tmf->tmf_code == isci_tmf_sata_srst_low) {
-			scu_stp_raw_request_construct_task_context(sci_req);
+			scu_stp_raw_request_construct_task_context(ireq);
 			return SCI_SUCCESS;
 		} else {
-			dev_err(scic_to_dev(sci_req->owning_controller),
+			dev_err(scic_to_dev(ireq->owning_controller),
 				"%s: Request 0x%p received un-handled SAT "
 				"management protocol 0x%x.\n",
-				__func__, sci_req, tmf->tmf_code);
+				__func__, ireq, tmf->tmf_code);
 
 			return SCI_FAILURE;
 		}
 	}
 
 	if (!sas_protocol_ata(task->task_proto)) {
-		dev_err(scic_to_dev(sci_req->owning_controller),
+		dev_err(scic_to_dev(ireq->owning_controller),
 			"%s: Non-ATA protocol in SATA path: 0x%x\n",
 			__func__,
 			task->task_proto);
@@ -538,13 +531,13 @@ scic_io_request_construct_sata(struct scic_sds_request *sci_req,
 
 	/* non data */
 	if (task->data_dir == DMA_NONE) {
-		scu_stp_raw_request_construct_task_context(sci_req);
+		scu_stp_raw_request_construct_task_context(ireq);
 		return SCI_SUCCESS;
 	}
 
 	/* NCQ */
 	if (task->ata_task.use_ncq) {
-		scic_sds_stp_optimized_request_construct(sci_req,
+		scic_sds_stp_optimized_request_construct(ireq,
 							 SCU_TASK_TYPE_FPDMAQ_READ,
 							 len, dir);
 		return SCI_SUCCESS;
@@ -552,74 +545,71 @@ scic_io_request_construct_sata(struct scic_sds_request *sci_req,
 
 	/* DMA */
 	if (task->ata_task.dma_xfer) {
-		scic_sds_stp_optimized_request_construct(sci_req,
+		scic_sds_stp_optimized_request_construct(ireq,
 							 SCU_TASK_TYPE_DMA_IN,
 							 len, dir);
 		return SCI_SUCCESS;
 	} else /* PIO */
-		return scic_sds_stp_pio_request_construct(sci_req, copy);
+		return scic_sds_stp_pio_request_construct(ireq, copy);
 
 	return status;
 }
 
-static enum sci_status scic_io_request_construct_basic_ssp(struct scic_sds_request *sci_req)
+static enum sci_status scic_io_request_construct_basic_ssp(struct isci_request *ireq)
 {
-	struct isci_request *ireq = sci_req_to_ireq(sci_req);
 	struct sas_task *task = isci_request_access_task(ireq);
 
-	sci_req->protocol = SCIC_SSP_PROTOCOL;
+	ireq->protocol = SCIC_SSP_PROTOCOL;
 
-	scu_ssp_io_request_construct_task_context(sci_req,
+	scu_ssp_io_request_construct_task_context(ireq,
 						  task->data_dir,
 						  task->total_xfer_len);
 
-	scic_sds_io_request_build_ssp_command_iu(sci_req);
+	scic_sds_io_request_build_ssp_command_iu(ireq);
 
-	sci_change_state(&sci_req->sm, SCI_REQ_CONSTRUCTED);
+	sci_change_state(&ireq->sm, SCI_REQ_CONSTRUCTED);
 
 	return SCI_SUCCESS;
 }
 
 enum sci_status scic_task_request_construct_ssp(
-	struct scic_sds_request *sci_req)
+	struct isci_request *ireq)
 {
 	/* Construct the SSP Task SCU Task Context */
-	scu_ssp_task_request_construct_task_context(sci_req);
+	scu_ssp_task_request_construct_task_context(ireq);
 
 	/* Fill in the SSP Task IU */
-	scic_sds_task_request_build_ssp_task_iu(sci_req);
+	scic_sds_task_request_build_ssp_task_iu(ireq);
 
-	sci_change_state(&sci_req->sm, SCI_REQ_CONSTRUCTED);
+	sci_change_state(&ireq->sm, SCI_REQ_CONSTRUCTED);
 
 	return SCI_SUCCESS;
 }
 
-static enum sci_status scic_io_request_construct_basic_sata(struct scic_sds_request *sci_req)
+static enum sci_status scic_io_request_construct_basic_sata(struct isci_request *ireq)
 {
 	enum sci_status status;
 	bool copy = false;
-	struct isci_request *isci_request = sci_req_to_ireq(sci_req);
-	struct sas_task *task = isci_request_access_task(isci_request);
+	struct sas_task *task = isci_request_access_task(ireq);
 
-	sci_req->protocol = SCIC_STP_PROTOCOL;
+	ireq->protocol = SCIC_STP_PROTOCOL;
 
 	copy = (task->data_dir == DMA_NONE) ? false : true;
 
-	status = scic_io_request_construct_sata(sci_req,
+	status = scic_io_request_construct_sata(ireq,
 						task->total_xfer_len,
 						task->data_dir,
 						copy);
 
 	if (status == SCI_SUCCESS)
-		sci_change_state(&sci_req->sm, SCI_REQ_CONSTRUCTED);
+		sci_change_state(&ireq->sm, SCI_REQ_CONSTRUCTED);
 
 	return status;
 }
 
-enum sci_status scic_task_request_construct_sata(struct scic_sds_request *sci_req)
+enum sci_status scic_task_request_construct_sata(struct isci_request *ireq)
 {
 	enum sci_status status = SCI_SUCCESS;
-	struct isci_request *ireq = sci_req_to_ireq(sci_req);
 
 	/* check for management protocols */
 	if (ireq->ttype == tmf_task) {
@@ -627,12 +617,12 @@ enum sci_status scic_task_request_construct_sata(struct scic_sds_request *sci_re
 
 		if (tmf->tmf_code == isci_tmf_sata_srst_high ||
 		    tmf->tmf_code == isci_tmf_sata_srst_low) {
-			scu_stp_raw_request_construct_task_context(sci_req);
+			scu_stp_raw_request_construct_task_context(ireq);
 		} else {
-			dev_err(scic_to_dev(sci_req->owning_controller),
+			dev_err(scic_to_dev(ireq->owning_controller),
 				"%s: Request 0x%p received un-handled SAT "
 				"Protocol 0x%x.\n",
-				__func__, sci_req, tmf->tmf_code);
+				__func__, ireq, tmf->tmf_code);
 
 			return SCI_FAILURE;
 		}
@@ -640,7 +630,7 @@ enum sci_status scic_task_request_construct_sata(struct scic_sds_request *sci_re
 
 	if (status != SCI_SUCCESS)
 		return status;
-	sci_change_state(&sci_req->sm, SCI_REQ_CONSTRUCTED);
+	sci_change_state(&ireq->sm, SCI_REQ_CONSTRUCTED);
 
 	return status;
 }
@@ -650,9 +640,9 @@ enum sci_status scic_task_request_construct_sata(struct scic_sds_request *sci_re
  * @sci_req: request that was terminated early
  */
 #define SCU_TASK_CONTEXT_SRAM 0x200000
-static u32 sci_req_tx_bytes(struct scic_sds_request *sci_req)
+static u32 sci_req_tx_bytes(struct isci_request *ireq)
 {
-	struct scic_sds_controller *scic = sci_req->owning_controller;
+	struct scic_sds_controller *scic = ireq->owning_controller;
 	u32 ret_val = 0;
 
 	if (readl(&scic->smu_registers->address_modifier) == 0) {
@@ -666,19 +656,19 @@ static u32 sci_req_tx_bytes(struct scic_sds_request *sci_req)
 		 */
 		ret_val = readl(scu_reg_base +
 				(SCU_TASK_CONTEXT_SRAM + offsetof(struct scu_task_context, type.ssp.data_offset)) +
-				((sizeof(struct scu_task_context)) * ISCI_TAG_TCI(sci_req->io_tag)));
+				((sizeof(struct scu_task_context)) * ISCI_TAG_TCI(ireq->io_tag)));
 	}
 
 	return ret_val;
 }
 
-enum sci_status scic_sds_request_start(struct scic_sds_request *sci_req)
+enum sci_status scic_sds_request_start(struct isci_request *ireq)
 {
 	enum sci_base_request_states state;
-	struct scu_task_context *tc = sci_req->tc;
-	struct scic_sds_controller *scic = sci_req->owning_controller;
+	struct scu_task_context *tc = ireq->tc;
+	struct scic_sds_controller *scic = ireq->owning_controller;
 
-	state = sci_req->sm.current_state_id;
+	state = ireq->sm.current_state_id;
 	if (state != SCI_REQ_CONSTRUCTED) {
 		dev_warn(scic_to_dev(scic),
 			"%s: SCIC IO Request requested to start while in wrong "
@@ -686,19 +676,19 @@ enum sci_status scic_sds_request_start(struct scic_sds_request *sci_req)
 		return SCI_FAILURE_INVALID_STATE;
 	}
 
-	tc->task_index = ISCI_TAG_TCI(sci_req->io_tag);
+	tc->task_index = ISCI_TAG_TCI(ireq->io_tag);
 
 	switch (tc->protocol_type) {
 	case SCU_TASK_CONTEXT_PROTOCOL_SMP:
 	case SCU_TASK_CONTEXT_PROTOCOL_SSP:
 		/* SSP/SMP Frame */
-		tc->type.ssp.tag = sci_req->io_tag;
+		tc->type.ssp.tag = ireq->io_tag;
 		tc->type.ssp.target_port_transfer_tag = 0xFFFF;
 		break;
 
 	case SCU_TASK_CONTEXT_PROTOCOL_STP:
 		/* STP/SATA Frame
-		 * tc->type.stp.ncq_tag = sci_req->ncq_tag;
+		 * tc->type.stp.ncq_tag = ireq->ncq_tag;
 		 */
 		break;
 
@@ -713,28 +703,28 @@ enum sci_status scic_sds_request_start(struct scic_sds_request *sci_req)
 	}
 
 	/* Add to the post_context the io tag value */
-	sci_req->post_context |= ISCI_TAG_TCI(sci_req->io_tag);
+	ireq->post_context |= ISCI_TAG_TCI(ireq->io_tag);
 
 	/* Everything is good go ahead and change state */
-	sci_change_state(&sci_req->sm, SCI_REQ_STARTED);
+	sci_change_state(&ireq->sm, SCI_REQ_STARTED);
 
 	return SCI_SUCCESS;
 }
 
 enum sci_status
-scic_sds_io_request_terminate(struct scic_sds_request *sci_req)
+scic_sds_io_request_terminate(struct isci_request *ireq)
 {
 	enum sci_base_request_states state;
 
-	state = sci_req->sm.current_state_id;
+	state = ireq->sm.current_state_id;
 
 	switch (state) {
 	case SCI_REQ_CONSTRUCTED:
-		scic_sds_request_set_status(sci_req,
+		scic_sds_request_set_status(ireq,
 			SCU_TASK_DONE_TASK_ABORT,
 			SCI_FAILURE_IO_TERMINATED);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		return SCI_SUCCESS;
 	case SCI_REQ_STARTED:
 	case SCI_REQ_TASK_WAIT_TC_COMP:
@@ -751,54 +741,54 @@ scic_sds_io_request_terminate(struct scic_sds_request *sci_req)
 	case SCI_REQ_STP_SOFT_RESET_WAIT_H2D_ASSERTED:
 	case SCI_REQ_STP_SOFT_RESET_WAIT_H2D_DIAG:
 	case SCI_REQ_STP_SOFT_RESET_WAIT_D2H:
-		sci_change_state(&sci_req->sm, SCI_REQ_ABORTING);
+		sci_change_state(&ireq->sm, SCI_REQ_ABORTING);
 		return SCI_SUCCESS;
 	case SCI_REQ_TASK_WAIT_TC_RESP:
-		sci_change_state(&sci_req->sm, SCI_REQ_ABORTING);
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_ABORTING);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		return SCI_SUCCESS;
 	case SCI_REQ_ABORTING:
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		return SCI_SUCCESS;
 	case SCI_REQ_COMPLETED:
 	default:
-		dev_warn(scic_to_dev(sci_req->owning_controller),
+		dev_warn(scic_to_dev(ireq->owning_controller),
 			 "%s: SCIC IO Request requested to abort while in wrong "
 			 "state %d\n",
 			 __func__,
-			 sci_req->sm.current_state_id);
+			 ireq->sm.current_state_id);
 		break;
 	}
 
 	return SCI_FAILURE_INVALID_STATE;
 }
 
-enum sci_status scic_sds_request_complete(struct scic_sds_request *sci_req)
+enum sci_status scic_sds_request_complete(struct isci_request *ireq)
 {
 	enum sci_base_request_states state;
-	struct scic_sds_controller *scic = sci_req->owning_controller;
+	struct scic_sds_controller *scic = ireq->owning_controller;
 
-	state = sci_req->sm.current_state_id;
+	state = ireq->sm.current_state_id;
 	if (WARN_ONCE(state != SCI_REQ_COMPLETED,
 		      "isci: request completion from wrong state (%d)\n", state))
 		return SCI_FAILURE_INVALID_STATE;
 
-	if (sci_req->saved_rx_frame_index != SCU_INVALID_FRAME_INDEX)
+	if (ireq->saved_rx_frame_index != SCU_INVALID_FRAME_INDEX)
 		scic_sds_controller_release_frame(scic,
-						  sci_req->saved_rx_frame_index);
+						  ireq->saved_rx_frame_index);
 
 	/* XXX can we just stop the machine and remove the 'final' state? */
-	sci_change_state(&sci_req->sm, SCI_REQ_FINAL);
+	sci_change_state(&ireq->sm, SCI_REQ_FINAL);
 	return SCI_SUCCESS;
 }
 
-enum sci_status scic_sds_io_request_event_handler(struct scic_sds_request *sci_req,
+enum sci_status scic_sds_io_request_event_handler(struct isci_request *ireq,
 						  u32 event_code)
 {
 	enum sci_base_request_states state;
-	struct scic_sds_controller *scic = sci_req->owning_controller;
+	struct scic_sds_controller *scic = ireq->owning_controller;
 
-	state = sci_req->sm.current_state_id;
+	state = ireq->sm.current_state_id;
 
 	if (state != SCI_REQ_STP_PIO_DATA_IN) {
 		dev_warn(scic_to_dev(scic), "%s: (%x) in wrong state %d\n",
@@ -812,7 +802,7 @@ enum sci_status scic_sds_io_request_event_handler(struct scic_sds_request *sci_r
 		/* We are waiting for data and the SCU has R_ERR the data frame.
 		 * Go back to waiting for the D2H Register FIS
 		 */
-		sci_change_state(&sci_req->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
+		sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
 		return SCI_SUCCESS;
 	default:
 		dev_err(scic_to_dev(scic),
@@ -832,15 +822,14 @@ enum sci_status scic_sds_io_request_event_handler(struct scic_sds_request *sci_r
  * @sci_req: This parameter specifies the request object for which to copy
  *    the response data.
  */
-static void scic_sds_io_request_copy_response(struct scic_sds_request *sci_req)
+static void scic_sds_io_request_copy_response(struct isci_request *ireq)
 {
 	void *resp_buf;
 	u32 len;
 	struct ssp_response_iu *ssp_response;
-	struct isci_request *ireq = sci_req_to_ireq(sci_req);
 	struct isci_tmf *isci_tmf = isci_request_access_tmf(ireq);
 
-	ssp_response = &sci_req->ssp.rsp;
+	ssp_response = &ireq->ssp.rsp;
 
 	resp_buf = &isci_tmf->resp.resp_iu;
 
@@ -852,7 +841,7 @@ static void scic_sds_io_request_copy_response(struct scic_sds_request *sci_req)
 }
 
 static enum sci_status
-request_started_state_tc_event(struct scic_sds_request *sci_req,
+request_started_state_tc_event(struct isci_request *ireq,
 			       u32 completion_code)
 {
 	struct ssp_response_iu *resp_iu;
@@ -863,7 +852,7 @@ request_started_state_tc_event(struct scic_sds_request *sci_req,
 	 */
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(sci_req,
+		scic_sds_request_set_status(ireq,
 					    SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 		break;
@@ -875,19 +864,19 @@ request_started_state_tc_event(struct scic_sds_request *sci_req,
 		 * truly a failed request or a good request that just got
 		 * completed early.
 		 */
-		struct ssp_response_iu *resp = &sci_req->ssp.rsp;
+		struct ssp_response_iu *resp = &ireq->ssp.rsp;
 		ssize_t word_cnt = SSP_RESP_IU_MAX_SIZE / sizeof(u32);
 
-		sci_swab32_cpy(&sci_req->ssp.rsp,
-			       &sci_req->ssp.rsp,
+		sci_swab32_cpy(&ireq->ssp.rsp,
+			       &ireq->ssp.rsp,
 			       word_cnt);
 
 		if (resp->status == 0) {
-			scic_sds_request_set_status(sci_req,
+			scic_sds_request_set_status(ireq,
 						    SCU_TASK_DONE_GOOD,
 						    SCI_SUCCESS_IO_DONE_EARLY);
 		} else {
-			scic_sds_request_set_status(sci_req,
+			scic_sds_request_set_status(ireq,
 						    SCU_TASK_DONE_CHECK_RESPONSE,
 						    SCI_FAILURE_IO_RESPONSE_VALID);
 		}
@@ -896,11 +885,11 @@ request_started_state_tc_event(struct scic_sds_request *sci_req,
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_CHECK_RESPONSE): {
 		ssize_t word_cnt = SSP_RESP_IU_MAX_SIZE / sizeof(u32);
 
-		sci_swab32_cpy(&sci_req->ssp.rsp,
-			       &sci_req->ssp.rsp,
+		sci_swab32_cpy(&ireq->ssp.rsp,
+			       &ireq->ssp.rsp,
 			       word_cnt);
 
-		scic_sds_request_set_status(sci_req,
+		scic_sds_request_set_status(ireq,
 					    SCU_TASK_DONE_CHECK_RESPONSE,
 					    SCI_FAILURE_IO_RESPONSE_VALID);
 		break;
@@ -911,15 +900,15 @@ request_started_state_tc_event(struct scic_sds_request *sci_req,
 		 * guaranteed to be received before this completion status is
 		 * posted?
 		 */
-		resp_iu = &sci_req->ssp.rsp;
+		resp_iu = &ireq->ssp.rsp;
 		datapres = resp_iu->datapres;
 
 		if (datapres == 1 || datapres == 2) {
-			scic_sds_request_set_status(sci_req,
+			scic_sds_request_set_status(ireq,
 						    SCU_TASK_DONE_CHECK_RESPONSE,
 						    SCI_FAILURE_IO_RESPONSE_VALID);
 		} else
-			scic_sds_request_set_status(sci_req,
+			scic_sds_request_set_status(ireq,
 						    SCU_TASK_DONE_GOOD,
 						    SCI_SUCCESS);
 		break;
@@ -935,13 +924,13 @@ request_started_state_tc_event(struct scic_sds_request *sci_req,
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_UNEXP_SDBFIS):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_REG_ERR):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SDB_ERR):
-		if (sci_req->protocol == SCIC_STP_PROTOCOL) {
-			scic_sds_request_set_status(sci_req,
+		if (ireq->protocol == SCIC_STP_PROTOCOL) {
+			scic_sds_request_set_status(ireq,
 				SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
 				SCU_COMPLETION_TL_STATUS_SHIFT,
 				SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED);
 		} else {
-			scic_sds_request_set_status(sci_req,
+			scic_sds_request_set_status(ireq,
 				SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
 				SCU_COMPLETION_TL_STATUS_SHIFT,
 				SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
@@ -959,7 +948,7 @@ request_started_state_tc_event(struct scic_sds_request *sci_req,
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_STP_RESOURCES_BUSY):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_PROTOCOL_NOT_SUPPORTED):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_CONNECTION_RATE_NOT_SUPPORTED):
-		scic_sds_request_set_status(sci_req,
+		scic_sds_request_set_status(ireq,
 					    SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
 					    SCU_COMPLETION_TL_STATUS_SHIFT,
 					    SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED);
@@ -983,7 +972,7 @@ request_started_state_tc_event(struct scic_sds_request *sci_req,
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_RNCNV_OUTBOUND):
 	default:
 		scic_sds_request_set_status(
-			sci_req,
+			ireq,
 			SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
 			SCU_COMPLETION_TL_STATUS_SHIFT,
 			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
@@ -995,21 +984,21 @@ request_started_state_tc_event(struct scic_sds_request *sci_req,
 	 */
 
 	/* In all cases we will treat this as the completion of the IO req. */
-	sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+	sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 	return SCI_SUCCESS;
 }
 
 static enum sci_status
-request_aborting_state_tc_event(struct scic_sds_request *sci_req,
+request_aborting_state_tc_event(struct isci_request *ireq,
 				u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case (SCU_TASK_DONE_GOOD << SCU_COMPLETION_TL_STATUS_SHIFT):
 	case (SCU_TASK_DONE_TASK_ABORT << SCU_COMPLETION_TL_STATUS_SHIFT):
-		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_TASK_ABORT,
+		scic_sds_request_set_status(ireq, SCU_TASK_DONE_TASK_ABORT,
 					    SCI_FAILURE_IO_TERMINATED);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 
 	default:
@@ -1022,15 +1011,15 @@ request_aborting_state_tc_event(struct scic_sds_request *sci_req,
 	return SCI_SUCCESS;
 }
 
-static enum sci_status ssp_task_request_await_tc_event(struct scic_sds_request *sci_req,
+static enum sci_status ssp_task_request_await_tc_event(struct isci_request *ireq,
 						       u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
+		scic_sds_request_set_status(ireq, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_TASK_WAIT_TC_RESP);
+		sci_change_state(&ireq->sm, SCI_REQ_TASK_WAIT_TC_RESP);
 		break;
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_ACK_NAK_TO):
 		/* Currently, the decision is to simply allow the task request
@@ -1038,12 +1027,12 @@ static enum sci_status ssp_task_request_await_tc_event(struct scic_sds_request *
 		 * There is a potential for receiving multiple task responses if
 		 * we decide to send the task IU again.
 		 */
-		dev_warn(scic_to_dev(sci_req->owning_controller),
+		dev_warn(scic_to_dev(ireq->owning_controller),
 			 "%s: TaskRequest:0x%p CompletionCode:%x - "
-			 "ACK/NAK timeout\n", __func__, sci_req,
+			 "ACK/NAK timeout\n", __func__, ireq,
 			 completion_code);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_TASK_WAIT_TC_RESP);
+		sci_change_state(&ireq->sm, SCI_REQ_TASK_WAIT_TC_RESP);
 		break;
 	default:
 		/*
@@ -1051,11 +1040,11 @@ static enum sci_status ssp_task_request_await_tc_event(struct scic_sds_request *
 		 * If a NAK was received, then it is up to the user to retry
 		 * the request.
 		 */
-		scic_sds_request_set_status(sci_req,
+		scic_sds_request_set_status(ireq,
 			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
@@ -1063,7 +1052,7 @@ static enum sci_status ssp_task_request_await_tc_event(struct scic_sds_request *
 }
 
 static enum sci_status
-smp_request_await_response_tc_event(struct scic_sds_request *sci_req,
+smp_request_await_response_tc_event(struct isci_request *ireq,
 				    u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
@@ -1072,10 +1061,10 @@ smp_request_await_response_tc_event(struct scic_sds_request *sci_req,
 		 * unexpected.  but if the TC has success status, we
 		 * complete the IO anyway.
 		 */
-		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
+		scic_sds_request_set_status(ireq, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_RESP_TO_ERR):
@@ -1089,21 +1078,21 @@ smp_request_await_response_tc_event(struct scic_sds_request *sci_req,
 		 * these SMP_XXX_XX_ERR status. For these type of error,
 		 * we ask scic user to retry the request.
 		 */
-		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_SMP_RESP_TO_ERR,
+		scic_sds_request_set_status(ireq, SCU_TASK_DONE_SMP_RESP_TO_ERR,
 					    SCI_FAILURE_RETRY_REQUIRED);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 
 	default:
 		/* All other completion status cause the IO to be complete.  If a NAK
 		 * was received, then it is up to the user to retry the request
 		 */
-		scic_sds_request_set_status(sci_req,
+		scic_sds_request_set_status(ireq,
 					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
@@ -1111,50 +1100,50 @@ smp_request_await_response_tc_event(struct scic_sds_request *sci_req,
 }
 
 static enum sci_status
-smp_request_await_tc_event(struct scic_sds_request *sci_req,
+smp_request_await_tc_event(struct isci_request *ireq,
 			   u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
+		scic_sds_request_set_status(ireq, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	default:
 		/* All other completion status cause the IO to be
 		 * complete.  If a NAK was received, then it is up to
 		 * the user to retry the request.
 		 */
-		scic_sds_request_set_status(sci_req,
+		scic_sds_request_set_status(ireq,
 					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
 	return SCI_SUCCESS;
 }
 
-void scic_stp_io_request_set_ncq_tag(struct scic_sds_request *req,
+void scic_stp_io_request_set_ncq_tag(struct isci_request *ireq,
 				     u16 ncq_tag)
 {
 	/**
 	 * @note This could be made to return an error to the user if the user
 	 *       attempts to set the NCQ tag in the wrong state.
 	 */
-	req->tc->type.stp.ncq_tag = ncq_tag;
+	ireq->tc->type.stp.ncq_tag = ncq_tag;
 }
 
 static struct scu_sgl_element *pio_sgl_next(struct isci_stp_request *stp_req)
 {
 	struct scu_sgl_element *sgl;
 	struct scu_sgl_element_pair *sgl_pair;
-	struct scic_sds_request *sci_req = to_sci_req(stp_req);
+	struct isci_request *ireq = to_ireq(stp_req);
 	struct isci_stp_pio_sgl *pio_sgl = &stp_req->sgl;
 
-	sgl_pair = to_sgl_element_pair(sci_req, pio_sgl->index);
+	sgl_pair = to_sgl_element_pair(ireq, pio_sgl->index);
 	if (!sgl_pair)
 		sgl = NULL;
 	else if (pio_sgl->set == SCU_SGL_ELEMENT_PAIR_A) {
@@ -1172,7 +1161,7 @@ static struct scu_sgl_element *pio_sgl_next(struct isci_stp_request *stp_req)
 		} else {
 			pio_sgl->index++;
 			pio_sgl->set = SCU_SGL_ELEMENT_PAIR_A;
-			sgl_pair = to_sgl_element_pair(sci_req, pio_sgl->index);
+			sgl_pair = to_sgl_element_pair(ireq, pio_sgl->index);
 			sgl = &sgl_pair->A;
 		}
 	}
@@ -1181,15 +1170,15 @@ static struct scu_sgl_element *pio_sgl_next(struct isci_stp_request *stp_req)
 }
 
 static enum sci_status
-stp_request_non_data_await_h2d_tc_event(struct scic_sds_request *sci_req,
+stp_request_non_data_await_h2d_tc_event(struct isci_request *ireq,
 					u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
+		scic_sds_request_set_status(ireq, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_STP_NON_DATA_WAIT_D2H);
+		sci_change_state(&ireq->sm, SCI_REQ_STP_NON_DATA_WAIT_D2H);
 		break;
 
 	default:
@@ -1197,11 +1186,11 @@ stp_request_non_data_await_h2d_tc_event(struct scic_sds_request *sci_req,
 		 * complete.  If a NAK was received, then it is up to
 		 * the user to retry the request.
 		 */
-		scic_sds_request_set_status(sci_req,
+		scic_sds_request_set_status(ireq,
 					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
@@ -1214,18 +1203,18 @@ stp_request_non_data_await_h2d_tc_event(struct scic_sds_request *sci_req,
  * parameter length. current sgl and offset is alreay stored in the IO request
  */
 static enum sci_status scic_sds_stp_request_pio_data_out_trasmit_data_frame(
-	struct scic_sds_request *sci_req,
+	struct isci_request *ireq,
 	u32 length)
 {
-	struct isci_stp_request *stp_req = &sci_req->stp.req;
-	struct scu_task_context *task_context = sci_req->tc;
+	struct isci_stp_request *stp_req = &ireq->stp.req;
+	struct scu_task_context *task_context = ireq->tc;
 	struct scu_sgl_element_pair *sgl_pair;
 	struct scu_sgl_element *current_sgl;
 
 	/* Recycle the TC and reconstruct it for sending out DATA FIS containing
 	 * for the data from current_sgl+offset for the input length
 	 */
-	sgl_pair = to_sgl_element_pair(sci_req, stp_req->sgl.index);
+	sgl_pair = to_sgl_element_pair(ireq, stp_req->sgl.index);
 	if (stp_req->sgl.set == SCU_SGL_ELEMENT_PAIR_A)
 		current_sgl = &sgl_pair->A;
 	else
@@ -1238,12 +1227,12 @@ static enum sci_status scic_sds_stp_request_pio_data_out_trasmit_data_frame(
 	task_context->type.stp.fis_type = FIS_DATA;
 
 	/* send the new TC out. */
-	return scic_controller_continue_io(sci_req);
+	return scic_controller_continue_io(ireq);
 }
 
-static enum sci_status scic_sds_stp_request_pio_data_out_transmit_data(struct scic_sds_request *sci_req)
+static enum sci_status scic_sds_stp_request_pio_data_out_transmit_data(struct isci_request *ireq)
 {
-	struct isci_stp_request *stp_req = &sci_req->stp.req;
+	struct isci_stp_request *stp_req = &ireq->stp.req;
 	struct scu_sgl_element_pair *sgl_pair;
 	struct scu_sgl_element *sgl;
 	enum sci_status status;
@@ -1251,7 +1240,7 @@ static enum sci_status scic_sds_stp_request_pio_data_out_transmit_data(struct sc
 	u32 len = 0;
 
 	offset = stp_req->sgl.offset;
-	sgl_pair = to_sgl_element_pair(sci_req, stp_req->sgl.index);
+	sgl_pair = to_sgl_element_pair(ireq, stp_req->sgl.index);
 	if (WARN_ONCE(!sgl_pair, "%s: null sgl element", __func__))
 		return SCI_FAILURE;
 
@@ -1267,7 +1256,7 @@ static enum sci_status scic_sds_stp_request_pio_data_out_transmit_data(struct sc
 		return SCI_SUCCESS;
 
 	if (stp_req->pio_len >= len) {
-		status = scic_sds_stp_request_pio_data_out_trasmit_data_frame(sci_req, len);
+		status = scic_sds_stp_request_pio_data_out_trasmit_data_frame(ireq, len);
 		if (status != SCI_SUCCESS)
 			return status;
 		stp_req->pio_len -= len;
@@ -1276,7 +1265,7 @@ static enum sci_status scic_sds_stp_request_pio_data_out_transmit_data(struct sc
 		sgl = pio_sgl_next(stp_req);
 		offset = 0;
 	} else if (stp_req->pio_len < len) {
-		scic_sds_stp_request_pio_data_out_trasmit_data_frame(sci_req, stp_req->pio_len);
+		scic_sds_stp_request_pio_data_out_trasmit_data_frame(ireq, stp_req->pio_len);
 
 		/* Sgl offset will be adjusted and saved for future */
 		offset += stp_req->pio_len;
@@ -1302,7 +1291,6 @@ static enum sci_status
 scic_sds_stp_request_pio_data_in_copy_data_buffer(struct isci_stp_request *stp_req,
 						  u8 *data_buf, u32 len)
 {
-	struct scic_sds_request *sci_req;
 	struct isci_request *ireq;
 	u8 *src_addr;
 	int copy_len;
@@ -1311,8 +1299,7 @@ scic_sds_stp_request_pio_data_in_copy_data_buffer(struct isci_stp_request *stp_r
 	void *kaddr;
 	int total_len = len;
 
-	sci_req = to_sci_req(stp_req);
-	ireq = sci_req_to_ireq(sci_req);
+	ireq = to_ireq(stp_req);
 	task = isci_request_access_task(ireq);
 	src_addr = data_buf;
 
@@ -1373,18 +1360,18 @@ static enum sci_status scic_sds_stp_request_pio_data_in_copy_data(
 }
 
 static enum sci_status
-stp_request_pio_await_h2d_completion_tc_event(struct scic_sds_request *sci_req,
+stp_request_pio_await_h2d_completion_tc_event(struct isci_request *ireq,
 					      u32 completion_code)
 {
 	enum sci_status status = SCI_SUCCESS;
 
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(sci_req,
+		scic_sds_request_set_status(ireq,
 					    SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
+		sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
 		break;
 
 	default:
@@ -1392,11 +1379,11 @@ stp_request_pio_await_h2d_completion_tc_event(struct scic_sds_request *sci_req,
 		 * complete.  If a NAK was received, then it is up to
 		 * the user to retry the request.
 		 */
-		scic_sds_request_set_status(sci_req,
+		scic_sds_request_set_status(ireq,
 					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
@@ -1404,18 +1391,18 @@ stp_request_pio_await_h2d_completion_tc_event(struct scic_sds_request *sci_req,
 }
 
 static enum sci_status
-pio_data_out_tx_done_tc_event(struct scic_sds_request *sci_req,
+pio_data_out_tx_done_tc_event(struct isci_request *ireq,
 			      u32 completion_code)
 {
 	enum sci_status status = SCI_SUCCESS;
 	bool all_frames_transferred = false;
-	struct isci_stp_request *stp_req = &sci_req->stp.req;
+	struct isci_stp_request *stp_req = &ireq->stp.req;
 
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
 		/* Transmit data */
 		if (stp_req->pio_len != 0) {
-			status = scic_sds_stp_request_pio_data_out_transmit_data(sci_req);
+			status = scic_sds_stp_request_pio_data_out_transmit_data(ireq);
 			if (status == SCI_SUCCESS) {
 				if (stp_req->pio_len == 0)
 					all_frames_transferred = true;
@@ -1433,7 +1420,7 @@ pio_data_out_tx_done_tc_event(struct scic_sds_request *sci_req,
 			/*
 			 * Change the state to SCI_REQ_STP_PIO_DATA_IN
 			 * and wait for PIO_SETUP fis / or D2H REg fis. */
-			sci_change_state(&sci_req->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
+			sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
 		}
 		break;
 
@@ -1444,11 +1431,11 @@ pio_data_out_tx_done_tc_event(struct scic_sds_request *sci_req,
 		 * the request.
 		 */
 		scic_sds_request_set_status(
-			sci_req,
+			ireq,
 			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
@@ -1456,18 +1443,18 @@ pio_data_out_tx_done_tc_event(struct scic_sds_request *sci_req,
 }
 
 static void scic_sds_stp_request_udma_complete_request(
-	struct scic_sds_request *request,
+	struct isci_request *ireq,
 	u32 scu_status,
 	enum sci_status sci_status)
 {
-	scic_sds_request_set_status(request, scu_status, sci_status);
-	sci_change_state(&request->sm, SCI_REQ_COMPLETED);
+	scic_sds_request_set_status(ireq, scu_status, sci_status);
+	sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 }
 
-static enum sci_status scic_sds_stp_request_udma_general_frame_handler(struct scic_sds_request *sci_req,
+static enum sci_status scic_sds_stp_request_udma_general_frame_handler(struct isci_request *ireq,
 								       u32 frame_index)
 {
-	struct scic_sds_controller *scic = sci_req->owning_controller;
+	struct scic_sds_controller *scic = ireq->owning_controller;
 	struct dev_to_host_fis *frame_header;
 	enum sci_status status;
 	u32 *frame_buffer;
@@ -1482,7 +1469,7 @@ static enum sci_status scic_sds_stp_request_udma_general_frame_handler(struct sc
 							      frame_index,
 							      (void **)&frame_buffer);
 
-		scic_sds_controller_copy_sata_response(&sci_req->stp.rsp,
+		scic_sds_controller_copy_sata_response(&ireq->stp.rsp,
 						       frame_header,
 						       frame_buffer);
 	}
@@ -1493,16 +1480,16 @@ static enum sci_status scic_sds_stp_request_udma_general_frame_handler(struct sc
 }
 
 enum sci_status
-scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
+scic_sds_io_request_frame_handler(struct isci_request *ireq,
 				  u32 frame_index)
 {
-	struct scic_sds_controller *scic = sci_req->owning_controller;
-	struct isci_stp_request *stp_req = &sci_req->stp.req;
+	struct scic_sds_controller *scic = ireq->owning_controller;
+	struct isci_stp_request *stp_req = &ireq->stp.req;
 	enum sci_base_request_states state;
 	enum sci_status status;
 	ssize_t word_cnt;
 
-	state = sci_req->sm.current_state_id;
+	state = ireq->sm.current_state_id;
 	switch (state)  {
 	case SCI_REQ_STARTED: {
 		struct ssp_frame_hdr ssp_hdr;
@@ -1523,24 +1510,24 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 								      frame_index,
 								      (void **)&resp_iu);
 
-			sci_swab32_cpy(&sci_req->ssp.rsp, resp_iu, word_cnt);
+			sci_swab32_cpy(&ireq->ssp.rsp, resp_iu, word_cnt);
 
-			resp_iu = &sci_req->ssp.rsp;
+			resp_iu = &ireq->ssp.rsp;
 
 			if (resp_iu->datapres == 0x01 ||
 			    resp_iu->datapres == 0x02) {
-				scic_sds_request_set_status(sci_req,
+				scic_sds_request_set_status(ireq,
 							    SCU_TASK_DONE_CHECK_RESPONSE,
 							    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 			} else
-				scic_sds_request_set_status(sci_req,
+				scic_sds_request_set_status(ireq,
 							    SCU_TASK_DONE_GOOD,
 							    SCI_SUCCESS);
 		} else {
 			/* not a response frame, why did it get forwarded? */
 			dev_err(scic_to_dev(scic),
 				"%s: SCIC IO Request 0x%p received unexpected "
-				"frame %d type 0x%02x\n", __func__, sci_req,
+				"frame %d type 0x%02x\n", __func__, ireq,
 				frame_index, ssp_hdr.frame_type);
 		}
 
@@ -1554,13 +1541,13 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 	}
 
 	case SCI_REQ_TASK_WAIT_TC_RESP:
-		scic_sds_io_request_copy_response(sci_req);
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		scic_sds_io_request_copy_response(ireq);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		scic_sds_controller_release_frame(scic,frame_index);
 		return SCI_SUCCESS;
 
 	case SCI_REQ_SMP_WAIT_RESP: {
-		struct smp_resp *rsp_hdr = &sci_req->smp.rsp;
+		struct smp_resp *rsp_hdr = &ireq->smp.rsp;
 		void *frame_header;
 
 		scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
@@ -1584,10 +1571,10 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 			sci_swab32_cpy(((u8 *) rsp_hdr) + SMP_RESP_HDR_SZ,
 				       smp_resp, word_cnt);
 
-			scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
+			scic_sds_request_set_status(ireq, SCU_TASK_DONE_GOOD,
 						    SCI_SUCCESS);
 
-			sci_change_state(&sci_req->sm, SCI_REQ_SMP_WAIT_TC_COMP);
+			sci_change_state(&ireq->sm, SCI_REQ_SMP_WAIT_TC_COMP);
 		} else {
 			/*
 			 * This was not a response frame why did it get
@@ -1597,15 +1584,15 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 				"%s: SCIC SMP Request 0x%p received unexpected "
 				"frame %d type 0x%02x\n",
 				__func__,
-				sci_req,
+				ireq,
 				frame_index,
 				rsp_hdr->frame_type);
 
-			scic_sds_request_set_status(sci_req,
+			scic_sds_request_set_status(ireq,
 						    SCU_TASK_DONE_SMP_FRM_TYPE_ERR,
 						    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-			sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		}
 
 		scic_sds_controller_release_frame(scic, frame_index);
@@ -1614,18 +1601,18 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 	}
 
 	case SCI_REQ_STP_UDMA_WAIT_TC_COMP:
-		return scic_sds_stp_request_udma_general_frame_handler(sci_req,
+		return scic_sds_stp_request_udma_general_frame_handler(ireq,
 								       frame_index);
 
 	case SCI_REQ_STP_UDMA_WAIT_D2H:
 		/* Use the general frame handler to copy the resposne data */
-		status = scic_sds_stp_request_udma_general_frame_handler(sci_req,
+		status = scic_sds_stp_request_udma_general_frame_handler(ireq,
 									 frame_index);
 
 		if (status != SCI_SUCCESS)
 			return status;
 
-		scic_sds_stp_request_udma_complete_request(sci_req,
+		scic_sds_stp_request_udma_complete_request(ireq,
 							   SCU_TASK_DONE_CHECK_RESPONSE,
 							   SCI_FAILURE_IO_RESPONSE_VALID);
 
@@ -1657,12 +1644,12 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 								      frame_index,
 								      (void **)&frame_buffer);
 
-			scic_sds_controller_copy_sata_response(&sci_req->stp.rsp,
+			scic_sds_controller_copy_sata_response(&ireq->stp.rsp,
 							       frame_header,
 							       frame_buffer);
 
 			/* The command has completed with error */
-			scic_sds_request_set_status(sci_req, SCU_TASK_DONE_CHECK_RESPONSE,
+			scic_sds_request_set_status(ireq, SCU_TASK_DONE_CHECK_RESPONSE,
 						    SCI_FAILURE_IO_RESPONSE_VALID);
 			break;
 
@@ -1672,12 +1659,12 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 				  "violation occurred\n", __func__, stp_req,
 				  frame_index);
 
-			scic_sds_request_set_status(sci_req, SCU_TASK_DONE_UNEXP_FIS,
+			scic_sds_request_set_status(ireq, SCU_TASK_DONE_UNEXP_FIS,
 						    SCI_FAILURE_PROTOCOL_VIOLATION);
 			break;
 		}
 
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 
 		/* Frame has been decoded return it to the controller */
 		scic_sds_controller_release_frame(scic, frame_index);
@@ -1686,7 +1673,6 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 	}
 
 	case SCI_REQ_STP_PIO_WAIT_FRAME: {
-		struct isci_request *ireq = sci_req_to_ireq(sci_req);
 		struct sas_task *task = isci_request_access_task(ireq);
 		struct dev_to_host_fis *frame_header;
 		u32 *frame_buffer;
@@ -1722,28 +1708,28 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 			/* status: 4th byte in the 3rd dword */
 			stp_req->status = (frame_buffer[2] >> 24) & 0xff;
 
-			scic_sds_controller_copy_sata_response(&sci_req->stp.rsp,
+			scic_sds_controller_copy_sata_response(&ireq->stp.rsp,
 							       frame_header,
 							       frame_buffer);
 
-			sci_req->stp.rsp.status = stp_req->status;
+			ireq->stp.rsp.status = stp_req->status;
 
 			/* The next state is dependent on whether the
 			 * request was PIO Data-in or Data out
 			 */
 			if (task->data_dir == DMA_FROM_DEVICE) {
-				sci_change_state(&sci_req->sm, SCI_REQ_STP_PIO_DATA_IN);
+				sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_DATA_IN);
 			} else if (task->data_dir == DMA_TO_DEVICE) {
 				/* Transmit data */
-				status = scic_sds_stp_request_pio_data_out_transmit_data(sci_req);
+				status = scic_sds_stp_request_pio_data_out_transmit_data(ireq);
 				if (status != SCI_SUCCESS)
 					break;
-				sci_change_state(&sci_req->sm, SCI_REQ_STP_PIO_DATA_OUT);
+				sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_DATA_OUT);
 			}
 			break;
 
 		case FIS_SETDEVBITS:
-			sci_change_state(&sci_req->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
+			sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
 			break;
 
 		case FIS_REGD2H:
@@ -1767,15 +1753,15 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 								      frame_index,
 								      (void **)&frame_buffer);
 
-			scic_sds_controller_copy_sata_response(&sci_req->stp.req,
+			scic_sds_controller_copy_sata_response(&ireq->stp.req,
 							       frame_header,
 							       frame_buffer);
 
-			scic_sds_request_set_status(sci_req,
+			scic_sds_request_set_status(ireq,
 						    SCU_TASK_DONE_CHECK_RESPONSE,
 						    SCI_FAILURE_IO_RESPONSE_VALID);
 
-			sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 			break;
 
 		default:
@@ -1818,11 +1804,11 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 				frame_index,
 				frame_header->fis_type);
 
-			scic_sds_request_set_status(sci_req,
+			scic_sds_request_set_status(ireq,
 						    SCU_TASK_DONE_GOOD,
 						    SCI_FAILURE_IO_REQUIRES_SCSI_ABORT);
 
-			sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 
 			/* Frame is decoded return it to the controller */
 			scic_sds_controller_release_frame(scic, frame_index);
@@ -1830,7 +1816,7 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 		}
 
 		if (stp_req->sgl.index < 0) {
-			sci_req->saved_rx_frame_index = frame_index;
+			ireq->saved_rx_frame_index = frame_index;
 			stp_req->pio_len = 0;
 		} else {
 			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
@@ -1851,13 +1837,13 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 			return status;
 
 		if ((stp_req->status & ATA_BUSY) == 0) {
-			scic_sds_request_set_status(sci_req,
+			scic_sds_request_set_status(ireq,
 						    SCU_TASK_DONE_CHECK_RESPONSE,
 						    SCI_FAILURE_IO_RESPONSE_VALID);
 
-			sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		} else {
-			sci_change_state(&sci_req->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
+			sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
 		}
 		return status;
 	}
@@ -1886,12 +1872,12 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 								      frame_index,
 								      (void **)&frame_buffer);
 
-			scic_sds_controller_copy_sata_response(&sci_req->stp.rsp,
+			scic_sds_controller_copy_sata_response(&ireq->stp.rsp,
 							       frame_header,
 							       frame_buffer);
 
 			/* The command has completed with error */
-			scic_sds_request_set_status(sci_req,
+			scic_sds_request_set_status(ireq,
 						    SCU_TASK_DONE_CHECK_RESPONSE,
 						    SCI_FAILURE_IO_RESPONSE_VALID);
 			break;
@@ -1904,13 +1890,13 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 				 stp_req,
 				 frame_index);
 
-			scic_sds_request_set_status(sci_req,
+			scic_sds_request_set_status(ireq,
 						    SCU_TASK_DONE_UNEXP_FIS,
 						    SCI_FAILURE_PROTOCOL_VIOLATION);
 			break;
 		}
 
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 
 		/* Frame has been decoded return it to the controller */
 		scic_sds_controller_release_frame(scic, frame_index);
@@ -1938,14 +1924,14 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 	}
 }
 
-static enum sci_status stp_request_udma_await_tc_event(struct scic_sds_request *sci_req,
+static enum sci_status stp_request_udma_await_tc_event(struct isci_request *ireq,
 						       u32 completion_code)
 {
 	enum sci_status status = SCI_SUCCESS;
 
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_stp_request_udma_complete_request(sci_req,
+		scic_sds_stp_request_udma_complete_request(ireq,
 							   SCU_TASK_DONE_GOOD,
 							   SCI_SUCCESS);
 		break;
@@ -1955,11 +1941,11 @@ static enum sci_status stp_request_udma_await_tc_event(struct scic_sds_request *
 		 * Register FIS was received before we got the TC
 		 * completion.
 		 */
-		if (sci_req->stp.rsp.fis_type == FIS_REGD2H) {
-			scic_sds_remote_device_suspend(sci_req->target_device,
+		if (ireq->stp.rsp.fis_type == FIS_REGD2H) {
+			scic_sds_remote_device_suspend(ireq->target_device,
 				SCU_EVENT_SPECIFIC(SCU_NORMALIZE_COMPLETION_STATUS(completion_code)));
 
-			scic_sds_stp_request_udma_complete_request(sci_req,
+			scic_sds_stp_request_udma_complete_request(ireq,
 								   SCU_TASK_DONE_CHECK_RESPONSE,
 								   SCI_FAILURE_IO_RESPONSE_VALID);
 		} else {
@@ -1968,7 +1954,7 @@ static enum sci_status stp_request_udma_await_tc_event(struct scic_sds_request *
 			 * the device so we must change state to wait
 			 * for it
 			 */
-			sci_change_state(&sci_req->sm, SCI_REQ_STP_UDMA_WAIT_D2H);
+			sci_change_state(&ireq->sm, SCI_REQ_STP_UDMA_WAIT_D2H);
 		}
 		break;
 
@@ -1983,12 +1969,12 @@ static enum sci_status stp_request_udma_await_tc_event(struct scic_sds_request *
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_LL_R_ERR):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_CMD_LL_R_ERR):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_CRC_ERR):
-		scic_sds_remote_device_suspend(sci_req->target_device,
+		scic_sds_remote_device_suspend(ireq->target_device,
 			SCU_EVENT_SPECIFIC(SCU_NORMALIZE_COMPLETION_STATUS(completion_code)));
 	/* Fall through to the default case */
 	default:
 		/* All other completion status cause the IO to be complete. */
-		scic_sds_stp_request_udma_complete_request(sci_req,
+		scic_sds_stp_request_udma_complete_request(ireq,
 					SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 					SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 		break;
@@ -1998,15 +1984,15 @@ static enum sci_status stp_request_udma_await_tc_event(struct scic_sds_request *
 }
 
 static enum sci_status
-stp_request_soft_reset_await_h2d_asserted_tc_event(struct scic_sds_request *sci_req,
+stp_request_soft_reset_await_h2d_asserted_tc_event(struct isci_request *ireq,
 						   u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
+		scic_sds_request_set_status(ireq, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_STP_SOFT_RESET_WAIT_H2D_DIAG);
+		sci_change_state(&ireq->sm, SCI_REQ_STP_SOFT_RESET_WAIT_H2D_DIAG);
 		break;
 
 	default:
@@ -2015,11 +2001,11 @@ stp_request_soft_reset_await_h2d_asserted_tc_event(struct scic_sds_request *sci_
 		 * If a NAK was received, then it is up to the user to retry
 		 * the request.
 		 */
-		scic_sds_request_set_status(sci_req,
+		scic_sds_request_set_status(ireq,
 					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
@@ -2027,15 +2013,15 @@ stp_request_soft_reset_await_h2d_asserted_tc_event(struct scic_sds_request *sci_
 }
 
 static enum sci_status
-stp_request_soft_reset_await_h2d_diagnostic_tc_event(struct scic_sds_request *sci_req,
+stp_request_soft_reset_await_h2d_diagnostic_tc_event(struct isci_request *ireq,
 						     u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
+		scic_sds_request_set_status(ireq, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_STP_SOFT_RESET_WAIT_D2H);
+		sci_change_state(&ireq->sm, SCI_REQ_STP_SOFT_RESET_WAIT_D2H);
 		break;
 
 	default:
@@ -2043,11 +2029,11 @@ stp_request_soft_reset_await_h2d_diagnostic_tc_event(struct scic_sds_request *sc
 		 * a NAK was received, then it is up to the user to retry the
 		 * request.
 		 */
-		scic_sds_request_set_status(sci_req,
+		scic_sds_request_set_status(ireq,
 			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
+		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
@@ -2055,54 +2041,54 @@ stp_request_soft_reset_await_h2d_diagnostic_tc_event(struct scic_sds_request *sc
 }
 
 enum sci_status
-scic_sds_io_request_tc_completion(struct scic_sds_request *sci_req,
+scic_sds_io_request_tc_completion(struct isci_request *ireq,
 				  u32 completion_code)
 {
 	enum sci_base_request_states state;
-	struct scic_sds_controller *scic = sci_req->owning_controller;
+	struct scic_sds_controller *scic = ireq->owning_controller;
 
-	state = sci_req->sm.current_state_id;
+	state = ireq->sm.current_state_id;
 
 	switch (state) {
 	case SCI_REQ_STARTED:
-		return request_started_state_tc_event(sci_req, completion_code);
+		return request_started_state_tc_event(ireq, completion_code);
 
 	case SCI_REQ_TASK_WAIT_TC_COMP:
-		return ssp_task_request_await_tc_event(sci_req,
+		return ssp_task_request_await_tc_event(ireq,
 						       completion_code);
 
 	case SCI_REQ_SMP_WAIT_RESP:
-		return smp_request_await_response_tc_event(sci_req,
+		return smp_request_await_response_tc_event(ireq,
 							   completion_code);
 
 	case SCI_REQ_SMP_WAIT_TC_COMP:
-		return smp_request_await_tc_event(sci_req, completion_code);
+		return smp_request_await_tc_event(ireq, completion_code);
 
 	case SCI_REQ_STP_UDMA_WAIT_TC_COMP:
-		return stp_request_udma_await_tc_event(sci_req,
+		return stp_request_udma_await_tc_event(ireq,
 						       completion_code);
 
 	case SCI_REQ_STP_NON_DATA_WAIT_H2D:
-		return stp_request_non_data_await_h2d_tc_event(sci_req,
+		return stp_request_non_data_await_h2d_tc_event(ireq,
 							       completion_code);
 
 	case SCI_REQ_STP_PIO_WAIT_H2D:
-		return stp_request_pio_await_h2d_completion_tc_event(sci_req,
+		return stp_request_pio_await_h2d_completion_tc_event(ireq,
 								     completion_code);
 
 	case SCI_REQ_STP_PIO_DATA_OUT:
-		return pio_data_out_tx_done_tc_event(sci_req, completion_code);
+		return pio_data_out_tx_done_tc_event(ireq, completion_code);
 
 	case SCI_REQ_STP_SOFT_RESET_WAIT_H2D_ASSERTED:
-		return stp_request_soft_reset_await_h2d_asserted_tc_event(sci_req,
+		return stp_request_soft_reset_await_h2d_asserted_tc_event(ireq,
 									  completion_code);
 
 	case SCI_REQ_STP_SOFT_RESET_WAIT_H2D_DIAG:
-		return stp_request_soft_reset_await_h2d_diagnostic_tc_event(sci_req,
+		return stp_request_soft_reset_await_h2d_diagnostic_tc_event(ireq,
 									    completion_code);
 
 	case SCI_REQ_ABORTING:
-		return request_aborting_state_tc_event(sci_req,
+		return request_aborting_state_tc_event(ireq,
 						       completion_code);
 
 	default:
@@ -2201,7 +2187,7 @@ static void isci_request_handle_controller_specific_errors(
 {
 	unsigned int cstatus;
 
-	cstatus = request->sci.scu_status;
+	cstatus = request->scu_status;
 
 	dev_dbg(&request->isci_host->pdev->dev,
 		"%s: %p SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR "
@@ -2640,13 +2626,13 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 				task);
 
 			if (sas_protocol_ata(task->task_proto)) {
-				resp_buf = &request->sci.stp.rsp;
+				resp_buf = &request->stp.rsp;
 				isci_request_process_stp_response(task,
 								  resp_buf);
 			} else if (SAS_PROTOCOL_SSP == task->task_proto) {
 
 				/* crack the iu response buffer. */
-				resp_iu = &request->sci.ssp.rsp;
+				resp_iu = &request->ssp.rsp;
 				isci_request_process_response_iu(task, resp_iu,
 								 &isci_host->pdev->dev);
 
@@ -2677,7 +2663,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 			set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 
 			if (task->task_proto == SAS_PROTOCOL_SMP) {
-				void *rsp = &request->sci.smp.rsp;
+				void *rsp = &request->smp.rsp;
 
 				dev_dbg(&isci_host->pdev->dev,
 					"%s: SMP protocol completion\n",
@@ -2693,7 +2679,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 				 * There is a possibility that less data than
 				 * the maximum was transferred.
 				 */
-				u32 transferred_length = sci_req_tx_bytes(&request->sci);
+				u32 transferred_length = sci_req_tx_bytes(request);
 
 				task->task_status.residual
 					= task->total_xfer_len - transferred_length;
@@ -2851,8 +2837,8 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 
 	/* complete the io request to the core. */
 	scic_controller_complete_io(&isci_host->sci,
-				    request->sci.target_device,
-				    &request->sci);
+				    request->target_device,
+				    request);
 	isci_put_device(idev);
 
 	/* set terminated handle so it cannot be completed or
@@ -2864,9 +2850,8 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 
 static void scic_sds_request_started_state_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), sm);
-	struct isci_request *ireq = sci_req_to_ireq(sci_req);
-	struct domain_device *dev = sci_dev_to_domain(sci_req->target_device);
+	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
+	struct domain_device *dev = sci_dev_to_domain(ireq->target_device);
 	struct sas_task *task;
 
 	/* XXX as hch said always creating an internal sas_task for tmf
@@ -2902,66 +2887,65 @@ static void scic_sds_request_started_state_enter(struct sci_base_state_machine *
 
 static void scic_sds_request_completed_state_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), sm);
-	struct scic_sds_controller *scic = sci_req->owning_controller;
+	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
+	struct scic_sds_controller *scic = ireq->owning_controller;
 	struct isci_host *ihost = scic_to_ihost(scic);
-	struct isci_request *ireq = sci_req_to_ireq(sci_req);
 
 	/* Tell the SCI_USER that the IO request is complete */
 	if (!test_bit(IREQ_TMF, &ireq->flags))
 		isci_request_io_request_complete(ihost, ireq,
-						 sci_req->sci_status);
+						 ireq->sci_status);
 	else
-		isci_task_request_complete(ihost, ireq, sci_req->sci_status);
+		isci_task_request_complete(ihost, ireq, ireq->sci_status);
 }
 
 static void scic_sds_request_aborting_state_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), sm);
+	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
 
 	/* Setting the abort bit in the Task Context is required by the silicon. */
-	sci_req->tc->abort = 1;
+	ireq->tc->abort = 1;
 }
 
 static void scic_sds_stp_request_started_non_data_await_h2d_completion_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), sm);
+	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
 
-	scic_sds_remote_device_set_working_request(sci_req->target_device,
-						   sci_req);
+	scic_sds_remote_device_set_working_request(ireq->target_device,
+						   ireq);
 }
 
 static void scic_sds_stp_request_started_pio_await_h2d_completion_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), sm);
+	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
 
-	scic_sds_remote_device_set_working_request(sci_req->target_device,
-						   sci_req);
+	scic_sds_remote_device_set_working_request(ireq->target_device,
+						   ireq);
 }
 
 static void scic_sds_stp_request_started_soft_reset_await_h2d_asserted_completion_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), sm);
+	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
 
-	scic_sds_remote_device_set_working_request(sci_req->target_device,
-						   sci_req);
+	scic_sds_remote_device_set_working_request(ireq->target_device,
+						   ireq);
 }
 
 static void scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), sm);
-	struct scu_task_context *tc = sci_req->tc;
+	struct isci_request *ireq = container_of(sm, typeof(*ireq), sm);
+	struct scu_task_context *tc = ireq->tc;
 	struct host_to_dev_fis *h2d_fis;
 	enum sci_status status;
 
 	/* Clear the SRST bit */
-	h2d_fis = &sci_req->stp.cmd;
+	h2d_fis = &ireq->stp.cmd;
 	h2d_fis->control = 0;
 
 	/* Clear the TC control bit */
 	tc->control_frame = 0;
 
-	status = scic_controller_continue_io(sci_req);
+	status = scic_controller_continue_io(ireq);
 	WARN_ONCE(status != SCI_SUCCESS, "isci: continue io failure\n");
 }
 
@@ -3006,29 +2990,29 @@ static const struct sci_base_state scic_sds_request_state_table[] = {
 static void
 scic_sds_general_request_construct(struct scic_sds_controller *scic,
 				   struct scic_sds_remote_device *sci_dev,
-				   struct scic_sds_request *sci_req)
+				   struct isci_request *ireq)
 {
-	sci_init_sm(&sci_req->sm, scic_sds_request_state_table, SCI_REQ_INIT);
+	sci_init_sm(&ireq->sm, scic_sds_request_state_table, SCI_REQ_INIT);
 
-	sci_req->target_device = sci_dev;
-	sci_req->protocol = SCIC_NO_PROTOCOL;
-	sci_req->saved_rx_frame_index = SCU_INVALID_FRAME_INDEX;
+	ireq->target_device = sci_dev;
+	ireq->protocol = SCIC_NO_PROTOCOL;
+	ireq->saved_rx_frame_index = SCU_INVALID_FRAME_INDEX;
 
-	sci_req->sci_status   = SCI_SUCCESS;
-	sci_req->scu_status   = 0;
-	sci_req->post_context = 0xFFFFFFFF;
+	ireq->sci_status   = SCI_SUCCESS;
+	ireq->scu_status   = 0;
+	ireq->post_context = 0xFFFFFFFF;
 }
 
 static enum sci_status
 scic_io_request_construct(struct scic_sds_controller *scic,
 			  struct scic_sds_remote_device *sci_dev,
-			  struct scic_sds_request *sci_req)
+			  struct isci_request *ireq)
 {
 	struct domain_device *dev = sci_dev_to_domain(sci_dev);
 	enum sci_status status = SCI_SUCCESS;
 
 	/* Build the common part of the request */
-	scic_sds_general_request_construct(scic, sci_dev, sci_req);
+	scic_sds_general_request_construct(scic, sci_dev, ireq);
 
 	if (sci_dev->rnc.remote_node_index == SCIC_SDS_REMOTE_NODE_CONTEXT_INVALID_INDEX)
 		return SCI_FAILURE_INVALID_REMOTE_DEVICE;
@@ -3036,31 +3020,31 @@ scic_io_request_construct(struct scic_sds_controller *scic,
 	if (dev->dev_type == SAS_END_DEV)
 		/* pass */;
 	else if (dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP))
-		memset(&sci_req->stp.cmd, 0, sizeof(sci_req->stp.cmd));
+		memset(&ireq->stp.cmd, 0, sizeof(ireq->stp.cmd));
 	else if (dev_is_expander(dev))
 		/* pass */;
 	else
 		return SCI_FAILURE_UNSUPPORTED_PROTOCOL;
 
-	memset(sci_req->tc, 0, offsetof(struct scu_task_context, sgl_pair_ab));
+	memset(ireq->tc, 0, offsetof(struct scu_task_context, sgl_pair_ab));
 
 	return status;
 }
 
 enum sci_status scic_task_request_construct(struct scic_sds_controller *scic,
 					    struct scic_sds_remote_device *sci_dev,
-					    u16 io_tag, struct scic_sds_request *sci_req)
+					    u16 io_tag, struct isci_request *ireq)
 {
 	struct domain_device *dev = sci_dev_to_domain(sci_dev);
 	enum sci_status status = SCI_SUCCESS;
 
 	/* Build the common part of the request */
-	scic_sds_general_request_construct(scic, sci_dev, sci_req);
+	scic_sds_general_request_construct(scic, sci_dev, ireq);
 
 	if (dev->dev_type == SAS_END_DEV ||
 	    dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP)) {
-		set_bit(IREQ_TMF, &sci_req_to_ireq(sci_req)->flags);
-		memset(sci_req->tc, 0, sizeof(struct scu_task_context));
+		set_bit(IREQ_TMF, &ireq->flags);
+		memset(ireq->tc, 0, sizeof(struct scu_task_context));
 	} else
 		status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;
 
@@ -3076,7 +3060,7 @@ static enum sci_status isci_request_ssp_request_construct(
 		"%s: request = %p\n",
 		__func__,
 		request);
-	status = scic_io_request_construct_basic_ssp(&request->sci);
+	status = scic_io_request_construct_basic_ssp(request);
 	return status;
 }
 
@@ -3097,7 +3081,7 @@ static enum sci_status isci_request_stp_request_construct(
 	 */
 	register_fis = isci_sata_task_to_fis_copy(task);
 
-	status = scic_io_request_construct_basic_sata(&request->sci);
+	status = scic_io_request_construct_basic_sata(request);
 
 	/* Set the ncq tag in the fis, from the queue
 	 * command in the task.
@@ -3115,7 +3099,7 @@ static enum sci_status isci_request_stp_request_construct(
 
 static enum sci_status
 scic_io_request_construct_smp(struct device *dev,
-			      struct scic_sds_request *sci_req,
+			      struct isci_request *ireq,
 			      struct sas_task *task)
 {
 	struct scatterlist *sg = &task->smp_task.smp_req;
@@ -3158,14 +3142,14 @@ scic_io_request_construct_smp(struct device *dev,
 	if (!dma_map_sg(dev, sg, 1, DMA_TO_DEVICE))
 		return SCI_FAILURE;
 
-	sci_req->protocol = SCIC_SMP_PROTOCOL;
+	ireq->protocol = SCIC_SMP_PROTOCOL;
 
 	/* byte swap the smp request. */
 
-	task_context = sci_req->tc;
+	task_context = ireq->tc;
 
-	sci_dev = scic_sds_request_get_device(sci_req);
-	sci_port = scic_sds_request_get_port(sci_req);
+	sci_dev = scic_sds_request_get_device(ireq);
+	sci_port = scic_sds_request_get_port(ireq);
 
 	/*
 	 * Fill in the TC with the its required data
@@ -3217,12 +3201,12 @@ scic_io_request_construct_smp(struct device *dev,
 	 */
 	task_context->task_phase = 0;
 
-	sci_req->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
+	ireq->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
 				 (scic_sds_controller_get_protocol_engine_group(scic) <<
 				  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
 				 (scic_sds_port_get_index(sci_port) <<
 				  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
-				 ISCI_TAG_TCI(sci_req->io_tag));
+				 ISCI_TAG_TCI(ireq->io_tag));
 	/*
 	 * Copy the physical address for the command buffer to the SCU Task
 	 * Context command buffer should not contain command header.
@@ -3234,7 +3218,7 @@ scic_io_request_construct_smp(struct device *dev,
 	task_context->response_iu_upper = 0;
 	task_context->response_iu_lower = 0;
 
-	sci_change_state(&sci_req->sm, SCI_REQ_CONSTRUCTED);
+	sci_change_state(&ireq->sm, SCI_REQ_CONSTRUCTED);
 
 	return SCI_SUCCESS;
 }
@@ -3250,10 +3234,9 @@ static enum sci_status isci_smp_request_build(struct isci_request *ireq)
 {
 	struct sas_task *task = isci_request_access_task(ireq);
 	struct device *dev = &ireq->isci_host->pdev->dev;
-	struct scic_sds_request *sci_req = &ireq->sci;
 	enum sci_status status = SCI_FAILURE;
 
-	status = scic_io_request_construct_smp(dev, sci_req, task);
+	status = scic_io_request_construct_smp(dev, ireq, task);
 	if (status != SCI_SUCCESS)
 		dev_warn(&ireq->isci_host->pdev->dev,
 			 "%s: failed with status = %d\n",
@@ -3309,7 +3292,7 @@ static enum sci_status isci_io_request_build(struct isci_host *isci_host,
 	}
 
 	status = scic_io_request_construct(&isci_host->sci, sci_device,
-					   &request->sci);
+					   request);
 
 	if (status != SCI_SUCCESS) {
 		dev_warn(&isci_host->pdev->dev,
@@ -3344,7 +3327,7 @@ static struct isci_request *isci_request_from_tag(struct isci_host *ihost, u16 t
 	struct isci_request *ireq;
 
 	ireq = ihost->reqs[ISCI_TAG_TCI(tag)];
-	ireq->sci.io_tag = tag;
+	ireq->io_tag = tag;
 	ireq->io_request_completion = NULL;
 	ireq->flags = 0;
 	ireq->num_sg_entries = 0;
@@ -3416,14 +3399,14 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 			 */
 			status = scic_controller_start_task(&ihost->sci,
 							    &idev->sci,
-							    &ireq->sci);
+							    ireq);
 		} else {
 			status = SCI_FAILURE;
 		}
 	} else {
 		/* send the request, let the core assign the IO TAG.	*/
 		status = scic_controller_start_io(&ihost->sci, &idev->sci,
-						  &ireq->sci);
+						  ireq);
 	}
 
 	if (status != SCI_SUCCESS &&
@@ -3446,8 +3429,6 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 	list_add(&ireq->dev_node, &idev->reqs_in_process);
 
 	if (status == SCI_SUCCESS) {
-		/* Save the tag for possible task mgmt later. */
-		ireq->io_tag = ireq->sci.io_tag;
 		isci_request_change_state(ireq, started);
 	} else {
 		/* The request did not really start in the

commit ba7cb22342a66505a831bb7e4541fef90e0193c9
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Jun 27 11:56:41 2011 -0700

    isci: rename / clean up scic_sds_stp_request
    
    * Rename scic_sds_stp_request to isci_stp_request
    * Remove the unused fields and union indirection
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 3c7ed4e61b4a..8520626b02fa 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -433,24 +433,20 @@ static enum sci_status
 scic_sds_stp_pio_request_construct(struct scic_sds_request *sci_req,
 				   bool copy_rx_frame)
 {
-	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
-	struct scic_sds_stp_pio_request *pio = &stp_req->type.pio;
+	struct isci_stp_request *stp_req = &sci_req->stp.req;
 
 	scu_stp_raw_request_construct_task_context(sci_req);
 
-	pio->current_transfer_bytes = 0;
-	pio->ending_error = 0;
-	pio->ending_status = 0;
-
-	pio->request_current.sgl_offset = 0;
-	pio->request_current.sgl_set = SCU_SGL_ELEMENT_PAIR_A;
+	stp_req->status = 0;
+	stp_req->sgl.offset = 0;
+	stp_req->sgl.set = SCU_SGL_ELEMENT_PAIR_A;
 
 	if (copy_rx_frame) {
 		scic_sds_request_build_sgl(sci_req);
-		pio->request_current.sgl_index = 0;
+		stp_req->sgl.index = 0;
 	} else {
 		/* The user does not want the data copied to the SGL buffer location */
-		pio->request_current.sgl_index = -1;
+		stp_req->sgl.index = -1;
 	}
 
 	return SCI_SUCCESS;
@@ -1151,22 +1147,22 @@ void scic_stp_io_request_set_ncq_tag(struct scic_sds_request *req,
 	req->tc->type.stp.ncq_tag = ncq_tag;
 }
 
-static struct scu_sgl_element *pio_sgl_next(struct scic_sds_stp_request *stp_req)
+static struct scu_sgl_element *pio_sgl_next(struct isci_stp_request *stp_req)
 {
 	struct scu_sgl_element *sgl;
 	struct scu_sgl_element_pair *sgl_pair;
 	struct scic_sds_request *sci_req = to_sci_req(stp_req);
-	struct scic_sds_request_pio_sgl *pio_sgl = &stp_req->type.pio.request_current;
+	struct isci_stp_pio_sgl *pio_sgl = &stp_req->sgl;
 
-	sgl_pair = to_sgl_element_pair(sci_req, pio_sgl->sgl_index);
+	sgl_pair = to_sgl_element_pair(sci_req, pio_sgl->index);
 	if (!sgl_pair)
 		sgl = NULL;
-	else if (pio_sgl->sgl_set == SCU_SGL_ELEMENT_PAIR_A) {
+	else if (pio_sgl->set == SCU_SGL_ELEMENT_PAIR_A) {
 		if (sgl_pair->B.address_lower == 0 &&
 		    sgl_pair->B.address_upper == 0) {
 			sgl = NULL;
 		} else {
-			pio_sgl->sgl_set = SCU_SGL_ELEMENT_PAIR_B;
+			pio_sgl->set = SCU_SGL_ELEMENT_PAIR_B;
 			sgl = &sgl_pair->B;
 		}
 	} else {
@@ -1174,9 +1170,9 @@ static struct scu_sgl_element *pio_sgl_next(struct scic_sds_stp_request *stp_req
 		    sgl_pair->next_pair_upper == 0) {
 			sgl = NULL;
 		} else {
-			pio_sgl->sgl_index++;
-			pio_sgl->sgl_set = SCU_SGL_ELEMENT_PAIR_A;
-			sgl_pair = to_sgl_element_pair(sci_req, pio_sgl->sgl_index);
+			pio_sgl->index++;
+			pio_sgl->set = SCU_SGL_ELEMENT_PAIR_A;
+			sgl_pair = to_sgl_element_pair(sci_req, pio_sgl->index);
 			sgl = &sgl_pair->A;
 		}
 	}
@@ -1221,7 +1217,7 @@ static enum sci_status scic_sds_stp_request_pio_data_out_trasmit_data_frame(
 	struct scic_sds_request *sci_req,
 	u32 length)
 {
-	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
+	struct isci_stp_request *stp_req = &sci_req->stp.req;
 	struct scu_task_context *task_context = sci_req->tc;
 	struct scu_sgl_element_pair *sgl_pair;
 	struct scu_sgl_element *current_sgl;
@@ -1229,8 +1225,8 @@ static enum sci_status scic_sds_stp_request_pio_data_out_trasmit_data_frame(
 	/* Recycle the TC and reconstruct it for sending out DATA FIS containing
 	 * for the data from current_sgl+offset for the input length
 	 */
-	sgl_pair = to_sgl_element_pair(sci_req, stp_req->type.pio.request_current.sgl_index);
-	if (stp_req->type.pio.request_current.sgl_set == SCU_SGL_ELEMENT_PAIR_A)
+	sgl_pair = to_sgl_element_pair(sci_req, stp_req->sgl.index);
+	if (stp_req->sgl.set == SCU_SGL_ELEMENT_PAIR_A)
 		current_sgl = &sgl_pair->A;
 	else
 		current_sgl = &sgl_pair->B;
@@ -1247,54 +1243,48 @@ static enum sci_status scic_sds_stp_request_pio_data_out_trasmit_data_frame(
 
 static enum sci_status scic_sds_stp_request_pio_data_out_transmit_data(struct scic_sds_request *sci_req)
 {
-
-	struct scu_sgl_element *current_sgl;
-	u32 sgl_offset;
-	u32 remaining_bytes_in_current_sgl = 0;
-	enum sci_status status = SCI_SUCCESS;
-	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
+	struct isci_stp_request *stp_req = &sci_req->stp.req;
 	struct scu_sgl_element_pair *sgl_pair;
+	struct scu_sgl_element *sgl;
+	enum sci_status status;
+	u32 offset;
+	u32 len = 0;
 
-	sgl_offset = stp_req->type.pio.request_current.sgl_offset;
-	sgl_pair = to_sgl_element_pair(sci_req, stp_req->type.pio.request_current.sgl_index);
+	offset = stp_req->sgl.offset;
+	sgl_pair = to_sgl_element_pair(sci_req, stp_req->sgl.index);
 	if (WARN_ONCE(!sgl_pair, "%s: null sgl element", __func__))
 		return SCI_FAILURE;
 
-	if (stp_req->type.pio.request_current.sgl_set == SCU_SGL_ELEMENT_PAIR_A) {
-		current_sgl = &sgl_pair->A;
-		remaining_bytes_in_current_sgl = sgl_pair->A.length - sgl_offset;
+	if (stp_req->sgl.set == SCU_SGL_ELEMENT_PAIR_A) {
+		sgl = &sgl_pair->A;
+		len = sgl_pair->A.length - offset;
 	} else {
-		current_sgl = &sgl_pair->B;
-		remaining_bytes_in_current_sgl = sgl_pair->B.length - sgl_offset;
+		sgl = &sgl_pair->B;
+		len = sgl_pair->B.length - offset;
 	}
 
-	if (stp_req->type.pio.pio_transfer_bytes > 0) {
-		if (stp_req->type.pio.pio_transfer_bytes >= remaining_bytes_in_current_sgl) {
-			/* recycle the TC and send the H2D Data FIS from (current sgl + sgl_offset) and length = remaining_bytes_in_current_sgl */
-			status = scic_sds_stp_request_pio_data_out_trasmit_data_frame(sci_req, remaining_bytes_in_current_sgl);
-			if (status == SCI_SUCCESS) {
-				stp_req->type.pio.pio_transfer_bytes -= remaining_bytes_in_current_sgl;
-
-				/* update the current sgl, sgl_offset and save for future */
-				current_sgl = pio_sgl_next(stp_req);
-				sgl_offset = 0;
-			}
-		} else if (stp_req->type.pio.pio_transfer_bytes < remaining_bytes_in_current_sgl) {
-			/* recycle the TC and send the H2D Data FIS from (current sgl + sgl_offset) and length = type.pio.pio_transfer_bytes */
-			scic_sds_stp_request_pio_data_out_trasmit_data_frame(sci_req, stp_req->type.pio.pio_transfer_bytes);
+	if (stp_req->pio_len == 0)
+		return SCI_SUCCESS;
 
-			if (status == SCI_SUCCESS) {
-				/* Sgl offset will be adjusted and saved for future */
-				sgl_offset += stp_req->type.pio.pio_transfer_bytes;
-				current_sgl->address_lower += stp_req->type.pio.pio_transfer_bytes;
-				stp_req->type.pio.pio_transfer_bytes = 0;
-			}
-		}
+	if (stp_req->pio_len >= len) {
+		status = scic_sds_stp_request_pio_data_out_trasmit_data_frame(sci_req, len);
+		if (status != SCI_SUCCESS)
+			return status;
+		stp_req->pio_len -= len;
+
+		/* update the current sgl, offset and save for future */
+		sgl = pio_sgl_next(stp_req);
+		offset = 0;
+	} else if (stp_req->pio_len < len) {
+		scic_sds_stp_request_pio_data_out_trasmit_data_frame(sci_req, stp_req->pio_len);
+
+		/* Sgl offset will be adjusted and saved for future */
+		offset += stp_req->pio_len;
+		sgl->address_lower += stp_req->pio_len;
+		stp_req->pio_len = 0;
 	}
 
-	if (status == SCI_SUCCESS) {
-		stp_req->type.pio.request_current.sgl_offset = sgl_offset;
-	}
+	stp_req->sgl.offset = offset;
 
 	return status;
 }
@@ -1309,7 +1299,7 @@ static enum sci_status scic_sds_stp_request_pio_data_out_transmit_data(struct sc
  * specified data region. enum sci_status
  */
 static enum sci_status
-scic_sds_stp_request_pio_data_in_copy_data_buffer(struct scic_sds_stp_request *stp_req,
+scic_sds_stp_request_pio_data_in_copy_data_buffer(struct isci_stp_request *stp_req,
 						  u8 *data_buf, u32 len)
 {
 	struct scic_sds_request *sci_req;
@@ -1356,7 +1346,7 @@ scic_sds_stp_request_pio_data_in_copy_data_buffer(struct scic_sds_stp_request *s
  * Copy the data buffer to the io request data region. enum sci_status
  */
 static enum sci_status scic_sds_stp_request_pio_data_in_copy_data(
-	struct scic_sds_stp_request *sci_req,
+	struct isci_stp_request *stp_req,
 	u8 *data_buffer)
 {
 	enum sci_status status;
@@ -1364,19 +1354,19 @@ static enum sci_status scic_sds_stp_request_pio_data_in_copy_data(
 	/*
 	 * If there is less than 1K remaining in the transfer request
 	 * copy just the data for the transfer */
-	if (sci_req->type.pio.pio_transfer_bytes < SCU_MAX_FRAME_BUFFER_SIZE) {
+	if (stp_req->pio_len < SCU_MAX_FRAME_BUFFER_SIZE) {
 		status = scic_sds_stp_request_pio_data_in_copy_data_buffer(
-			sci_req, data_buffer, sci_req->type.pio.pio_transfer_bytes);
+			stp_req, data_buffer, stp_req->pio_len);
 
 		if (status == SCI_SUCCESS)
-			sci_req->type.pio.pio_transfer_bytes = 0;
+			stp_req->pio_len = 0;
 	} else {
 		/* We are transfering the whole frame so copy */
 		status = scic_sds_stp_request_pio_data_in_copy_data_buffer(
-			sci_req, data_buffer, SCU_MAX_FRAME_BUFFER_SIZE);
+			stp_req, data_buffer, SCU_MAX_FRAME_BUFFER_SIZE);
 
 		if (status == SCI_SUCCESS)
-			sci_req->type.pio.pio_transfer_bytes -= SCU_MAX_FRAME_BUFFER_SIZE;
+			stp_req->pio_len -= SCU_MAX_FRAME_BUFFER_SIZE;
 	}
 
 	return status;
@@ -1419,18 +1409,18 @@ pio_data_out_tx_done_tc_event(struct scic_sds_request *sci_req,
 {
 	enum sci_status status = SCI_SUCCESS;
 	bool all_frames_transferred = false;
-	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
+	struct isci_stp_request *stp_req = &sci_req->stp.req;
 
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
 		/* Transmit data */
-		if (stp_req->type.pio.pio_transfer_bytes != 0) {
+		if (stp_req->pio_len != 0) {
 			status = scic_sds_stp_request_pio_data_out_transmit_data(sci_req);
 			if (status == SCI_SUCCESS) {
-				if (stp_req->type.pio.pio_transfer_bytes == 0)
+				if (stp_req->pio_len == 0)
 					all_frames_transferred = true;
 			}
-		} else if (stp_req->type.pio.pio_transfer_bytes == 0) {
+		} else if (stp_req->pio_len == 0) {
 			/*
 			 * this will happen if the all data is written at the
 			 * first time after the pio setup fis is received
@@ -1507,7 +1497,7 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 				  u32 frame_index)
 {
 	struct scic_sds_controller *scic = sci_req->owning_controller;
-	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
+	struct isci_stp_request *stp_req = &sci_req->stp.req;
 	enum sci_base_request_states state;
 	enum sci_status status;
 	ssize_t word_cnt;
@@ -1727,16 +1717,16 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 			 */
 
 			/* transfer_count: first 16bits in the 4th dword */
-			stp_req->type.pio.pio_transfer_bytes = frame_buffer[3] & 0xffff;
+			stp_req->pio_len = frame_buffer[3] & 0xffff;
 
-			/* ending_status: 4th byte in the 3rd dword */
-			stp_req->type.pio.ending_status = (frame_buffer[2] >> 24) & 0xff;
+			/* status: 4th byte in the 3rd dword */
+			stp_req->status = (frame_buffer[2] >> 24) & 0xff;
 
 			scic_sds_controller_copy_sata_response(&sci_req->stp.rsp,
 							       frame_header,
 							       frame_buffer);
 
-			sci_req->stp.rsp.status = stp_req->type.pio.ending_status;
+			sci_req->stp.rsp.status = stp_req->status;
 
 			/* The next state is dependent on whether the
 			 * request was PIO Data-in or Data out
@@ -1839,9 +1829,9 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 			return status;
 		}
 
-		if (stp_req->type.pio.request_current.sgl_index < 0) {
+		if (stp_req->sgl.index < 0) {
 			sci_req->saved_rx_frame_index = frame_index;
-			stp_req->type.pio.pio_transfer_bytes = 0;
+			stp_req->pio_len = 0;
 		} else {
 			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
 								      frame_index,
@@ -1857,11 +1847,10 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 		/* Check for the end of the transfer, are there more
 		 * bytes remaining for this data transfer
 		 */
-		if (status != SCI_SUCCESS ||
-		    stp_req->type.pio.pio_transfer_bytes != 0)
+		if (status != SCI_SUCCESS || stp_req->pio_len != 0)
 			return status;
 
-		if ((stp_req->type.pio.ending_status & ATA_BUSY) == 0) {
+		if ((stp_req->status & ATA_BUSY) == 0) {
 			scic_sds_request_set_status(sci_req,
 						    SCU_TASK_DONE_CHECK_RESPONSE,
 						    SCI_FAILURE_IO_RESPONSE_VALID);

commit db0562509800a2d4cb5cb14a66413c30484f165c
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Jun 17 14:18:39 2011 -0700

    isci: preallocate requests
    
    the dma_pool interface is optimized for object_size << page_size which
    is not the case with isci_request objects and the dma_pool routines show
    up in the top of the profile.
    
    The old io_request_table which tracked whether tci slots were in-flight
    or not is replaced with an IREQ_ACTIVE flag per request.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 27376ba22483..3c7ed4e61b4a 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -3017,13 +3017,10 @@ static const struct sci_base_state scic_sds_request_state_table[] = {
 static void
 scic_sds_general_request_construct(struct scic_sds_controller *scic,
 				   struct scic_sds_remote_device *sci_dev,
-				   u16 io_tag,
 				   struct scic_sds_request *sci_req)
 {
 	sci_init_sm(&sci_req->sm, scic_sds_request_state_table, SCI_REQ_INIT);
 
-	sci_req->io_tag = io_tag;
-	sci_req->owning_controller = scic;
 	sci_req->target_device = sci_dev;
 	sci_req->protocol = SCIC_NO_PROTOCOL;
 	sci_req->saved_rx_frame_index = SCU_INVALID_FRAME_INDEX;
@@ -3031,20 +3028,18 @@ scic_sds_general_request_construct(struct scic_sds_controller *scic,
 	sci_req->sci_status   = SCI_SUCCESS;
 	sci_req->scu_status   = 0;
 	sci_req->post_context = 0xFFFFFFFF;
-	sci_req->tc = &scic->task_context_table[ISCI_TAG_TCI(io_tag)];
-	WARN_ONCE(io_tag == SCI_CONTROLLER_INVALID_IO_TAG, "straggling invalid tag usage\n");
 }
 
 static enum sci_status
 scic_io_request_construct(struct scic_sds_controller *scic,
 			  struct scic_sds_remote_device *sci_dev,
-			  u16 io_tag, struct scic_sds_request *sci_req)
+			  struct scic_sds_request *sci_req)
 {
 	struct domain_device *dev = sci_dev_to_domain(sci_dev);
 	enum sci_status status = SCI_SUCCESS;
 
 	/* Build the common part of the request */
-	scic_sds_general_request_construct(scic, sci_dev, io_tag, sci_req);
+	scic_sds_general_request_construct(scic, sci_dev, sci_req);
 
 	if (sci_dev->rnc.remote_node_index == SCIC_SDS_REMOTE_NODE_CONTEXT_INVALID_INDEX)
 		return SCI_FAILURE_INVALID_REMOTE_DEVICE;
@@ -3071,7 +3066,7 @@ enum sci_status scic_task_request_construct(struct scic_sds_controller *scic,
 	enum sci_status status = SCI_SUCCESS;
 
 	/* Build the common part of the request */
-	scic_sds_general_request_construct(scic, sci_dev, io_tag, sci_req);
+	scic_sds_general_request_construct(scic, sci_dev, sci_req);
 
 	if (dev->dev_type == SAS_END_DEV ||
 	    dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP)) {
@@ -3291,8 +3286,7 @@ static enum sci_status isci_smp_request_build(struct isci_request *ireq)
  */
 static enum sci_status isci_io_request_build(struct isci_host *isci_host,
 					     struct isci_request *request,
-					     struct isci_remote_device *isci_device,
-					     u16 tag)
+					     struct isci_remote_device *isci_device)
 {
 	enum sci_status status = SCI_SUCCESS;
 	struct sas_task *task = isci_request_access_task(request);
@@ -3325,11 +3319,8 @@ static enum sci_status isci_io_request_build(struct isci_host *isci_host,
 			return SCI_FAILURE_INSUFFICIENT_RESOURCES;
 	}
 
-	/* build the common request object. For now,
-	 * we will let the core allocate the IO tag.
-	 */
 	status = scic_io_request_construct(&isci_host->sci, sci_device,
-					   tag, &request->sci);
+					   &request->sci);
 
 	if (status != SCI_SUCCESS) {
 		dev_warn(&isci_host->pdev->dev,
@@ -3359,65 +3350,51 @@ static enum sci_status isci_io_request_build(struct isci_host *isci_host,
 	return SCI_SUCCESS;
 }
 
-static struct isci_request *isci_request_alloc_core(struct isci_host *ihost,
-						    gfp_t gfp_flags)
+static struct isci_request *isci_request_from_tag(struct isci_host *ihost, u16 tag)
 {
-	dma_addr_t handle;
 	struct isci_request *ireq;
 
-	ireq = dma_pool_alloc(ihost->dma_pool, gfp_flags, &handle);
-	if (!ireq) {
-		dev_warn(&ihost->pdev->dev,
-			 "%s: dma_pool_alloc returned NULL\n", __func__);
-		return NULL;
-	}
-
-	/* initialize the request object.	*/
-	spin_lock_init(&ireq->state_lock);
-	ireq->request_daddr = handle;
-	ireq->isci_host = ihost;
+	ireq = ihost->reqs[ISCI_TAG_TCI(tag)];
+	ireq->sci.io_tag = tag;
 	ireq->io_request_completion = NULL;
 	ireq->flags = 0;
 	ireq->num_sg_entries = 0;
 	INIT_LIST_HEAD(&ireq->completed_node);
 	INIT_LIST_HEAD(&ireq->dev_node);
-
 	isci_request_change_state(ireq, allocated);
 
 	return ireq;
 }
 
-static struct isci_request *isci_request_alloc_io(struct isci_host *ihost,
-						  struct sas_task *task,
-						  gfp_t gfp_flags)
+static struct isci_request *isci_io_request_from_tag(struct isci_host *ihost,
+						     struct sas_task *task,
+						     u16 tag)
 {
 	struct isci_request *ireq;
 
-	ireq = isci_request_alloc_core(ihost, gfp_flags);
-	if (ireq) {
-		ireq->ttype_ptr.io_task_ptr = task;
-		ireq->ttype = io_task;
-		task->lldd_task = ireq;
-	}
+	ireq = isci_request_from_tag(ihost, tag);
+	ireq->ttype_ptr.io_task_ptr = task;
+	ireq->ttype = io_task;
+	task->lldd_task = ireq;
+
 	return ireq;
 }
 
-struct isci_request *isci_request_alloc_tmf(struct isci_host *ihost,
-					    struct isci_tmf *isci_tmf,
-					    gfp_t gfp_flags)
+struct isci_request *isci_tmf_request_from_tag(struct isci_host *ihost,
+					       struct isci_tmf *isci_tmf,
+					       u16 tag)
 {
 	struct isci_request *ireq;
 
-	ireq = isci_request_alloc_core(ihost, gfp_flags);
-	if (ireq) {
-		ireq->ttype_ptr.tmf_task_ptr = isci_tmf;
-		ireq->ttype = tmf_task;
-	}
+	ireq = isci_request_from_tag(ihost, tag);
+	ireq->ttype_ptr.tmf_task_ptr = isci_tmf;
+	ireq->ttype = tmf_task;
+
 	return ireq;
 }
 
 int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *idev,
-			 struct sas_task *task, u16 tag, gfp_t gfp_flags)
+			 struct sas_task *task, u16 tag)
 {
 	enum sci_status status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;
 	struct isci_request *ireq;
@@ -3425,17 +3402,15 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 	int ret = 0;
 
 	/* do common allocation and init of request object. */
-	ireq = isci_request_alloc_io(ihost, task, gfp_flags);
-	if (!ireq)
-		goto out;
+	ireq = isci_io_request_from_tag(ihost, task, tag);
 
-	status = isci_io_request_build(ihost, ireq, idev, tag);
+	status = isci_io_request_build(ihost, ireq, idev);
 	if (status != SCI_SUCCESS) {
 		dev_warn(&ihost->pdev->dev,
 			 "%s: request_construct failed - status = 0x%x\n",
 			 __func__,
 			 status);
-		goto out;
+		return status;
 	}
 
 	spin_lock_irqsave(&ihost->scic_lock, flags);
@@ -3468,7 +3443,7 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 			 "%s: failed request start (0x%x)\n",
 			 __func__, status);
 		spin_unlock_irqrestore(&ihost->scic_lock, flags);
-		goto out;
+		return status;
 	}
 
 	/* Either I/O started OK, or the core has signaled that
@@ -3518,13 +3493,5 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 		status = SCI_SUCCESS;
 	}
 
- out:
-	if (status != SCI_SUCCESS) {
-		/* release dma memory on failure. */
-		isci_request_free(ihost, ireq);
-		ireq = NULL;
-		ret = SCI_FAILURE;
-	}
-
 	return ret;
 }

commit 38d8879baeb61b6946052739e7c03fa79b3a57f0
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Jun 23 14:33:48 2011 -0700

    isci: combine request flags
    
    Combine three bools into one unsigned long 'flags'.  Doesn't increase the
    request size due to packing. (to do: optimize the structure layout).
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 55859d5331b1..27376ba22483 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2183,7 +2183,7 @@ static void isci_request_set_open_reject_status(
 	enum sas_open_rej_reason open_rej_reason)
 {
 	/* Task in the target is done. */
-	request->complete_in_target       = true;
+	set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 	*response_ptr                     = SAS_TASK_UNDELIVERED;
 	*status_ptr                       = SAS_OPEN_REJECT;
 	*complete_to_host_ptr             = isci_perform_normal_io_completion;
@@ -2248,7 +2248,7 @@ static void isci_request_handle_controller_specific_errors(
 			else
 				*status_ptr = SAS_ABORTED_TASK;
 
-			request->complete_in_target = true;
+			set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 
 			*complete_to_host_ptr =
 				isci_perform_normal_io_completion;
@@ -2261,7 +2261,7 @@ static void isci_request_handle_controller_specific_errors(
 			else
 				*status_ptr = SAM_STAT_TASK_ABORTED;
 
-			request->complete_in_target = false;
+			clear_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 
 			*complete_to_host_ptr =
 				isci_perform_error_io_completion;
@@ -2292,7 +2292,7 @@ static void isci_request_handle_controller_specific_errors(
 		else
 			*status_ptr = SAS_ABORTED_TASK;
 
-		request->complete_in_target = true;
+		set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 
 		*complete_to_host_ptr = isci_perform_normal_io_completion;
 		break;
@@ -2397,11 +2397,11 @@ static void isci_request_handle_controller_specific_errors(
 		*status_ptr = SAM_STAT_TASK_ABORTED;
 
 		if (task->task_proto == SAS_PROTOCOL_SMP) {
-			request->complete_in_target = true;
+			set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 
 			*complete_to_host_ptr = isci_perform_normal_io_completion;
 		} else {
-			request->complete_in_target = false;
+			clear_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 
 			*complete_to_host_ptr = isci_perform_error_io_completion;
 		}
@@ -2552,7 +2552,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 		 *
 		 * The target is still there (since the TMF was successful).
 		 */
-		request->complete_in_target = true;
+		set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 		response = SAS_TASK_COMPLETE;
 
 		/* See if the device has been/is being stopped. Note
@@ -2579,7 +2579,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 		 * Aborting also means an external thread is explicitly managing
 		 * this request, so that we do not complete it up the stack.
 		 */
-		request->complete_in_target = true;
+		set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 		response = SAS_TASK_UNDELIVERED;
 
 		if (!idev)
@@ -2605,7 +2605,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 		 * the device (reset, tear down, etc.), and the I/O needs
 		 * to be completed up the stack.
 		 */
-		request->complete_in_target = true;
+		set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 		response = SAS_TASK_UNDELIVERED;
 
 		/* See if the device has been/is being stopped. Note
@@ -2675,7 +2675,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 			/* use the task status set in the task struct by the
 			 * isci_request_process_response_iu call.
 			 */
-			request->complete_in_target = true;
+			set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 			response = task->task_status.resp;
 			status = task->task_status.stat;
 			break;
@@ -2685,7 +2685,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 
 			response = SAS_TASK_COMPLETE;
 			status   = SAM_STAT_GOOD;
-			request->complete_in_target = true;
+			set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 
 			if (task->task_proto == SAS_PROTOCOL_SMP) {
 				void *rsp = &request->sci.smp.rsp;
@@ -2737,7 +2737,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 			/* The request was terminated explicitly.  No handling
 			 * is needed in the SCSI error handler path.
 			 */
-			request->complete_in_target = true;
+			set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 			response = SAS_TASK_UNDELIVERED;
 
 			/* See if the device has been/is being stopped. Note
@@ -2777,7 +2777,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 			status = SAM_STAT_TASK_ABORTED;
 
 			complete_to_host = isci_perform_error_io_completion;
-			request->complete_in_target = false;
+			clear_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 			break;
 
 		case SCI_FAILURE_RETRY_REQUIRED:
@@ -2790,7 +2790,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 				status = SAS_ABORTED_TASK;
 
 			complete_to_host = isci_perform_normal_io_completion;
-			request->complete_in_target = true;
+			set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 			break;
 
 
@@ -2813,10 +2813,10 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 				status = SAS_ABORTED_TASK;
 
 			if (SAS_PROTOCOL_SMP == task->task_proto) {
-				request->complete_in_target = true;
+				set_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 				complete_to_host = isci_perform_normal_io_completion;
 			} else {
-				request->complete_in_target = false;
+				clear_bit(IREQ_COMPLETE_IN_TARGET, &request->flags);
 				complete_to_host = isci_perform_error_io_completion;
 			}
 			break;
@@ -2870,7 +2870,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 	 * terminated again, and to cause any calls into abort
 	 * task to recognize the already completed case.
 	 */
-	request->terminated = true;
+	set_bit(IREQ_TERMINATED, &request->flags);
 }
 
 static void scic_sds_request_started_state_enter(struct sci_base_state_machine *sm)
@@ -2919,7 +2919,7 @@ static void scic_sds_request_completed_state_enter(struct sci_base_state_machine
 	struct isci_request *ireq = sci_req_to_ireq(sci_req);
 
 	/* Tell the SCI_USER that the IO request is complete */
-	if (sci_req->is_task_management_request == false)
+	if (!test_bit(IREQ_TMF, &ireq->flags))
 		isci_request_io_request_complete(ihost, ireq,
 						 sci_req->sci_status);
 	else
@@ -3032,8 +3032,6 @@ scic_sds_general_request_construct(struct scic_sds_controller *scic,
 	sci_req->scu_status   = 0;
 	sci_req->post_context = 0xFFFFFFFF;
 	sci_req->tc = &scic->task_context_table[ISCI_TAG_TCI(io_tag)];
-
-	sci_req->is_task_management_request = false;
 	WARN_ONCE(io_tag == SCI_CONTROLLER_INVALID_IO_TAG, "straggling invalid tag usage\n");
 }
 
@@ -3077,7 +3075,7 @@ enum sci_status scic_task_request_construct(struct scic_sds_controller *scic,
 
 	if (dev->dev_type == SAS_END_DEV ||
 	    dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP)) {
-		sci_req->is_task_management_request = true;
+		set_bit(IREQ_TMF, &sci_req_to_ireq(sci_req)->flags);
 		memset(sci_req->tc, 0, sizeof(struct scu_task_context));
 	} else
 		status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;
@@ -3379,12 +3377,8 @@ static struct isci_request *isci_request_alloc_core(struct isci_host *ihost,
 	ireq->request_daddr = handle;
 	ireq->isci_host = ihost;
 	ireq->io_request_completion = NULL;
-	ireq->terminated = false;
-
+	ireq->flags = 0;
 	ireq->num_sg_entries = 0;
-
-	ireq->complete_in_target = false;
-
 	INIT_LIST_HEAD(&ireq->completed_node);
 	INIT_LIST_HEAD(&ireq->dev_node);
 
@@ -3496,7 +3490,7 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 		 * hardware, so clear the request handle
 		 * here so no terminations will be done.
 		 */
-		ireq->terminated = true;
+		set_bit(IREQ_TERMINATED, &ireq->flags);
 		isci_request_change_state(ireq, completed);
 	}
 	spin_unlock_irqrestore(&ihost->scic_lock, flags);

commit 312e0c2455c18716cf640d4336dcb1e9e5053818
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Jun 28 13:47:09 2011 -0700

    isci: unify can_queue tracking on the tci_pool, uplevel tag assignment
    
    The tci_pool tracks our outstanding command slots which are also the 'index'
    portion of our tags.  Grabbing the tag early in ->lldd_execute_task let's us
    drop the isci_host_can_queue() and ->was_tag_assigned_by_user infrastructure.
    ->was_tag_assigned_by_user required the task context to be duplicated in
    request-local buffer.  With the tci established early we can build the
    task_context directly into its final location and skip a memcpy.
    
    With the task context buffer at a known address at request construction we
    have the opportunity/obligation to also fix sgl handling.  This rework feels
    like it belongs in another patch but the sgl handling and task_context are too
    intertwined.
    1/ fix the 'ab' pair embedded in the task context to point to the 'cd' pair in
       the task context (previously we were prematurely linking to the staging
       buffer).
    2/ fix the broken iteration of pio sgls that assumes all sgls are relative to
       the request, and does a dangerous looking reverse lookup of physical
       address to virtual address.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 08a7340b33bf..55859d5331b1 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -61,42 +61,50 @@
 #include "scu_event_codes.h"
 #include "sas.h"
 
-/**
- * This method returns the sgl element pair for the specificed sgl_pair index.
- * @sci_req: This parameter specifies the IO request for which to retrieve
- *    the Scatter-Gather List element pair.
- * @sgl_pair_index: This parameter specifies the index into the SGL element
- *    pair to be retrieved.
- *
- * This method returns a pointer to an struct scu_sgl_element_pair.
- */
-static struct scu_sgl_element_pair *scic_sds_request_get_sgl_element_pair(
-	struct scic_sds_request *sci_req,
-	u32 sgl_pair_index
-	) {
-	struct scu_task_context *task_context;
+static struct scu_sgl_element_pair *to_sgl_element_pair(struct scic_sds_request *sci_req,
+							int idx)
+{
+	if (idx == 0)
+		return &sci_req->tc->sgl_pair_ab;
+	else if (idx == 1)
+		return &sci_req->tc->sgl_pair_cd;
+	else if (idx < 0)
+		return NULL;
+	else
+		return &sci_req->sg_table[idx - 2];
+}
 
-	task_context = (struct scu_task_context *)sci_req->task_context_buffer;
+static dma_addr_t to_sgl_element_pair_dma(struct scic_sds_controller *scic,
+					  struct scic_sds_request *sci_req, u32 idx)
+{
+	u32 offset;
 
-	if (sgl_pair_index == 0) {
-		return &task_context->sgl_pair_ab;
-	} else if (sgl_pair_index == 1) {
-		return &task_context->sgl_pair_cd;
+	if (idx == 0) {
+		offset = (void *) &sci_req->tc->sgl_pair_ab -
+			 (void *) &scic->task_context_table[0];
+		return scic->task_context_dma + offset;
+	} else if (idx == 1) {
+		offset = (void *) &sci_req->tc->sgl_pair_cd -
+			 (void *) &scic->task_context_table[0];
+		return scic->task_context_dma + offset;
 	}
 
-	return &sci_req->sg_table[sgl_pair_index - 2];
+	return scic_io_request_get_dma_addr(sci_req, &sci_req->sg_table[idx - 2]);
+}
+
+static void init_sgl_element(struct scu_sgl_element *e, struct scatterlist *sg)
+{
+	e->length = sg_dma_len(sg);
+	e->address_upper = upper_32_bits(sg_dma_address(sg));
+	e->address_lower = lower_32_bits(sg_dma_address(sg));
+	e->address_modifier = 0;
 }
 
-/**
- * This function will build the SGL list for an IO request.
- * @sci_req: This parameter specifies the IO request for which to build
- *    the Scatter-Gather List.
- *
- */
 static void scic_sds_request_build_sgl(struct scic_sds_request *sds_request)
 {
 	struct isci_request *isci_request = sci_req_to_ireq(sds_request);
 	struct isci_host *isci_host = isci_request->isci_host;
+	struct scic_sds_controller *scic = &isci_host->sci;
 	struct sas_task *task = isci_request_access_task(isci_request);
 	struct scatterlist *sg = NULL;
 	dma_addr_t dma_addr;
@@ -108,25 +116,19 @@ static void scic_sds_request_build_sgl(struct scic_sds_request *sds_request)
 		sg = task->scatter;
 
 		while (sg) {
-			scu_sg = scic_sds_request_get_sgl_element_pair(
-					sds_request,
-					sg_idx);
-
-			SCU_SGL_COPY(scu_sg->A, sg);
-
+			scu_sg = to_sgl_element_pair(sds_request, sg_idx);
+			init_sgl_element(&scu_sg->A, sg);
 			sg = sg_next(sg);
-
 			if (sg) {
-				SCU_SGL_COPY(scu_sg->B, sg);
+				init_sgl_element(&scu_sg->B, sg);
 				sg = sg_next(sg);
 			} else
-				SCU_SGL_ZERO(scu_sg->B);
+				memset(&scu_sg->B, 0, sizeof(scu_sg->B));
 
 			if (prev_sg) {
-				dma_addr =
-					scic_io_request_get_dma_addr(
-							sds_request,
-							scu_sg);
+				dma_addr = to_sgl_element_pair_dma(scic,
+								   sds_request,
+								   sg_idx);
 
 				prev_sg->next_pair_upper =
 					upper_32_bits(dma_addr);
@@ -138,8 +140,7 @@ static void scic_sds_request_build_sgl(struct scic_sds_request *sds_request)
 			sg_idx++;
 		}
 	} else {	/* handle when no sg */
-		scu_sg = scic_sds_request_get_sgl_element_pair(sds_request,
-							       sg_idx);
+		scu_sg = to_sgl_element_pair(sds_request, sg_idx);
 
 		dma_addr = dma_map_single(&isci_host->pdev->dev,
 					  task->scatter,
@@ -246,35 +247,12 @@ static void scu_ssp_reqeust_construct_task_context(
 	/* task_context->type.ssp.tag = sci_req->io_tag; */
 	task_context->task_phase = 0x01;
 
-	if (sds_request->was_tag_assigned_by_user) {
-		/*
-		 * Build the task context now since we have already read
-		 * the data
-		 */
-		sds_request->post_context =
-			(SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
-			 (scic_sds_controller_get_protocol_engine_group(
-							controller) <<
-			  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
-			 (scic_sds_port_get_index(target_port) <<
-			  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
-			  ISCI_TAG_TCI(sds_request->io_tag));
-	} else {
-		/*
-		 * Build the task context now since we have already read
-		 * the data
-		 *
-		 * I/O tag index is not assigned because we have to wait
-		 * until we get a TCi
-		 */
-		sds_request->post_context =
-			(SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
-			 (scic_sds_controller_get_protocol_engine_group(
-							owning_controller) <<
-			  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
-			 (scic_sds_port_get_index(target_port) <<
-			  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT));
-	}
+	sds_request->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
+				     (scic_sds_controller_get_protocol_engine_group(controller) <<
+				      SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
+				     (scic_sds_port_get_index(target_port) <<
+				      SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
+				     ISCI_TAG_TCI(sds_request->io_tag));
 
 	/*
 	 * Copy the physical address for the command buffer to the
@@ -302,14 +280,11 @@ static void scu_ssp_reqeust_construct_task_context(
  * @sci_req:
  *
  */
-static void scu_ssp_io_request_construct_task_context(
-	struct scic_sds_request *sci_req,
-	enum dma_data_direction dir,
-	u32 len)
+static void scu_ssp_io_request_construct_task_context(struct scic_sds_request *sci_req,
+						      enum dma_data_direction dir,
+						      u32 len)
 {
-	struct scu_task_context *task_context;
-
-	task_context = scic_sds_request_get_task_context(sci_req);
+	struct scu_task_context *task_context = sci_req->tc;
 
 	scu_ssp_reqeust_construct_task_context(sci_req, task_context);
 
@@ -347,12 +322,9 @@ static void scu_ssp_io_request_construct_task_context(
  *    constructed.
  *
  */
-static void scu_ssp_task_request_construct_task_context(
-	struct scic_sds_request *sci_req)
+static void scu_ssp_task_request_construct_task_context(struct scic_sds_request *sci_req)
 {
-	struct scu_task_context *task_context;
-
-	task_context = scic_sds_request_get_task_context(sci_req);
+	struct scu_task_context *task_context = sci_req->tc;
 
 	scu_ssp_reqeust_construct_task_context(sci_req, task_context);
 
@@ -421,35 +393,12 @@ static void scu_sata_reqeust_construct_task_context(
 	/* Set the first word of the H2D REG FIS */
 	task_context->type.words[0] = *(u32 *)&sci_req->stp.cmd;
 
-	if (sci_req->was_tag_assigned_by_user) {
-		/*
-		 * Build the task context now since we have already read
-		 * the data
-		 */
-		sci_req->post_context =
-			(SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
-			 (scic_sds_controller_get_protocol_engine_group(
-							controller) <<
-			  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
-			 (scic_sds_port_get_index(target_port) <<
-			  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
-			  ISCI_TAG_TCI(sci_req->io_tag));
-	} else {
-		/*
-		 * Build the task context now since we have already read
-		 * the data.
-		 * I/O tag index is not assigned because we have to wait
-		 * until we get a TCi.
-		 */
-		sci_req->post_context =
-			(SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
-			 (scic_sds_controller_get_protocol_engine_group(
-							controller) <<
-			  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
-			 (scic_sds_port_get_index(target_port) <<
-			  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT));
-	}
-
+	sci_req->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
+				 (scic_sds_controller_get_protocol_engine_group(controller) <<
+				  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
+				 (scic_sds_port_get_index(target_port) <<
+				  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
+				 ISCI_TAG_TCI(sci_req->io_tag));
 	/*
 	 * Copy the physical address for the command buffer to the SCU Task
 	 * Context. We must offset the command buffer by 4 bytes because the
@@ -467,22 +416,9 @@ static void scu_sata_reqeust_construct_task_context(
 	task_context->response_iu_lower = 0;
 }
 
-
-
-/**
- * scu_stp_raw_request_construct_task_context -
- * @sci_req: This parameter specifies the STP request object for which to
- *    construct a RAW command frame task context.
- * @task_context: This parameter specifies the SCU specific task context buffer
- *    to construct.
- *
- * This method performs the operations common to all SATA/STP requests
- * utilizing the raw frame method. none
- */
-static void scu_stp_raw_request_construct_task_context(struct scic_sds_stp_request *stp_req,
-						       struct scu_task_context *task_context)
+static void scu_stp_raw_request_construct_task_context(struct scic_sds_request *sci_req)
 {
-	struct scic_sds_request *sci_req = to_sci_req(stp_req);
+	struct scu_task_context *task_context = sci_req->tc;
 
 	scu_sata_reqeust_construct_task_context(sci_req, task_context);
 
@@ -500,8 +436,7 @@ scic_sds_stp_pio_request_construct(struct scic_sds_request *sci_req,
 	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
 	struct scic_sds_stp_pio_request *pio = &stp_req->type.pio;
 
-	scu_stp_raw_request_construct_task_context(stp_req,
-						   sci_req->task_context_buffer);
+	scu_stp_raw_request_construct_task_context(sci_req);
 
 	pio->current_transfer_bytes = 0;
 	pio->ending_error = 0;
@@ -512,13 +447,10 @@ scic_sds_stp_pio_request_construct(struct scic_sds_request *sci_req,
 
 	if (copy_rx_frame) {
 		scic_sds_request_build_sgl(sci_req);
-		/* Since the IO request copy of the TC contains the same data as
-		 * the actual TC this pointer is vaild for either.
-		 */
-		pio->request_current.sgl_pair = &sci_req->task_context_buffer->sgl_pair_ab;
+		pio->request_current.sgl_index = 0;
 	} else {
 		/* The user does not want the data copied to the SGL buffer location */
-		pio->request_current.sgl_pair = NULL;
+		pio->request_current.sgl_index = -1;
 	}
 
 	return SCI_SUCCESS;
@@ -541,7 +473,7 @@ static void scic_sds_stp_optimized_request_construct(struct scic_sds_request *sc
 						     u32 len,
 						     enum dma_data_direction dir)
 {
-	struct scu_task_context *task_context = sci_req->task_context_buffer;
+	struct scu_task_context *task_context = sci_req->tc;
 
 	/* Build the STP task context structure */
 	scu_sata_reqeust_construct_task_context(sci_req, task_context);
@@ -587,8 +519,7 @@ scic_io_request_construct_sata(struct scic_sds_request *sci_req,
 
 		if (tmf->tmf_code == isci_tmf_sata_srst_high ||
 		    tmf->tmf_code == isci_tmf_sata_srst_low) {
-			scu_stp_raw_request_construct_task_context(&sci_req->stp.req,
-								   sci_req->task_context_buffer);
+			scu_stp_raw_request_construct_task_context(sci_req);
 			return SCI_SUCCESS;
 		} else {
 			dev_err(scic_to_dev(sci_req->owning_controller),
@@ -611,8 +542,7 @@ scic_io_request_construct_sata(struct scic_sds_request *sci_req,
 
 	/* non data */
 	if (task->data_dir == DMA_NONE) {
-		scu_stp_raw_request_construct_task_context(&sci_req->stp.req,
-							   sci_req->task_context_buffer);
+		scu_stp_raw_request_construct_task_context(sci_req);
 		return SCI_SUCCESS;
 	}
 
@@ -701,8 +631,7 @@ enum sci_status scic_task_request_construct_sata(struct scic_sds_request *sci_re
 
 		if (tmf->tmf_code == isci_tmf_sata_srst_high ||
 		    tmf->tmf_code == isci_tmf_sata_srst_low) {
-			scu_stp_raw_request_construct_task_context(&sci_req->stp.req,
-								   sci_req->task_context_buffer);
+			scu_stp_raw_request_construct_task_context(sci_req);
 		} else {
 			dev_err(scic_to_dev(sci_req->owning_controller),
 				"%s: Request 0x%p received un-handled SAT "
@@ -749,9 +678,9 @@ static u32 sci_req_tx_bytes(struct scic_sds_request *sci_req)
 
 enum sci_status scic_sds_request_start(struct scic_sds_request *sci_req)
 {
-	struct scic_sds_controller *scic = sci_req->owning_controller;
-	struct scu_task_context *task_context;
 	enum sci_base_request_states state;
+	struct scu_task_context *tc = sci_req->tc;
+	struct scic_sds_controller *scic = sci_req->owning_controller;
 
 	state = sci_req->sm.current_state_id;
 	if (state != SCI_REQ_CONSTRUCTED) {
@@ -761,61 +690,39 @@ enum sci_status scic_sds_request_start(struct scic_sds_request *sci_req)
 		return SCI_FAILURE_INVALID_STATE;
 	}
 
-	/* if necessary, allocate a TCi for the io request object and then will,
-	 * if necessary, copy the constructed TC data into the actual TC buffer.
-	 * If everything is successful the post context field is updated with
-	 * the TCi so the controller can post the request to the hardware.
-	 */
-	if (sci_req->io_tag == SCI_CONTROLLER_INVALID_IO_TAG)
-		sci_req->io_tag = scic_controller_allocate_io_tag(scic);
-
-	/* Record the IO Tag in the request */
-	if (sci_req->io_tag != SCI_CONTROLLER_INVALID_IO_TAG) {
-		task_context = sci_req->task_context_buffer;
-
-		task_context->task_index = ISCI_TAG_TCI(sci_req->io_tag);
-
-		switch (task_context->protocol_type) {
-		case SCU_TASK_CONTEXT_PROTOCOL_SMP:
-		case SCU_TASK_CONTEXT_PROTOCOL_SSP:
-			/* SSP/SMP Frame */
-			task_context->type.ssp.tag = sci_req->io_tag;
-			task_context->type.ssp.target_port_transfer_tag =
-				0xFFFF;
-			break;
+	tc->task_index = ISCI_TAG_TCI(sci_req->io_tag);
 
-		case SCU_TASK_CONTEXT_PROTOCOL_STP:
-			/* STP/SATA Frame
-			 * task_context->type.stp.ncq_tag = sci_req->ncq_tag;
-			 */
-			break;
-
-		case SCU_TASK_CONTEXT_PROTOCOL_NONE:
-			/* / @todo When do we set no protocol type? */
-			break;
+	switch (tc->protocol_type) {
+	case SCU_TASK_CONTEXT_PROTOCOL_SMP:
+	case SCU_TASK_CONTEXT_PROTOCOL_SSP:
+		/* SSP/SMP Frame */
+		tc->type.ssp.tag = sci_req->io_tag;
+		tc->type.ssp.target_port_transfer_tag = 0xFFFF;
+		break;
 
-		default:
-			/* This should never happen since we build the IO
-			 * requests */
-			break;
-		}
+	case SCU_TASK_CONTEXT_PROTOCOL_STP:
+		/* STP/SATA Frame
+		 * tc->type.stp.ncq_tag = sci_req->ncq_tag;
+		 */
+		break;
 
-		/*
-		 * Check to see if we need to copy the task context buffer
-		 * or have been building into the task context buffer */
-		if (sci_req->was_tag_assigned_by_user == false)
-			scic_sds_controller_copy_task_context(scic, sci_req);
+	case SCU_TASK_CONTEXT_PROTOCOL_NONE:
+		/* / @todo When do we set no protocol type? */
+		break;
 
-		/* Add to the post_context the io tag value */
-		sci_req->post_context |= ISCI_TAG_TCI(sci_req->io_tag);
+	default:
+		/* This should never happen since we build the IO
+		 * requests */
+		break;
+	}
 
-		/* Everything is good go ahead and change state */
-		sci_change_state(&sci_req->sm, SCI_REQ_STARTED);
+	/* Add to the post_context the io tag value */
+	sci_req->post_context |= ISCI_TAG_TCI(sci_req->io_tag);
 
-		return SCI_SUCCESS;
-	}
+	/* Everything is good go ahead and change state */
+	sci_change_state(&sci_req->sm, SCI_REQ_STARTED);
 
-	return SCI_FAILURE_INSUFFICIENT_RESOURCES;
+	return SCI_SUCCESS;
 }
 
 enum sci_status
@@ -880,9 +787,6 @@ enum sci_status scic_sds_request_complete(struct scic_sds_request *sci_req)
 		      "isci: request completion from wrong state (%d)\n", state))
 		return SCI_FAILURE_INVALID_STATE;
 
-	if (!sci_req->was_tag_assigned_by_user)
-		scic_controller_free_io_tag(scic, sci_req->io_tag);
-
 	if (sci_req->saved_rx_frame_index != SCU_INVALID_FRAME_INDEX)
 		scic_sds_controller_release_frame(scic,
 						  sci_req->saved_rx_frame_index);
@@ -1244,51 +1148,40 @@ void scic_stp_io_request_set_ncq_tag(struct scic_sds_request *req,
 	 * @note This could be made to return an error to the user if the user
 	 *       attempts to set the NCQ tag in the wrong state.
 	 */
-	req->task_context_buffer->type.stp.ncq_tag = ncq_tag;
+	req->tc->type.stp.ncq_tag = ncq_tag;
 }
 
-/**
- *
- * @sci_req:
- *
- * Get the next SGL element from the request. - Check on which SGL element pair
- * we are working - if working on SLG pair element A - advance to element B -
- * else - check to see if there are more SGL element pairs for this IO request
- * - if there are more SGL element pairs - advance to the next pair and return
- * element A struct scu_sgl_element*
- */
-static struct scu_sgl_element *scic_sds_stp_request_pio_get_next_sgl(struct scic_sds_stp_request *stp_req)
+static struct scu_sgl_element *pio_sgl_next(struct scic_sds_stp_request *stp_req)
 {
-	struct scu_sgl_element *current_sgl;
+	struct scu_sgl_element *sgl;
+	struct scu_sgl_element_pair *sgl_pair;
 	struct scic_sds_request *sci_req = to_sci_req(stp_req);
 	struct scic_sds_request_pio_sgl *pio_sgl = &stp_req->type.pio.request_current;
 
-	if (pio_sgl->sgl_set == SCU_SGL_ELEMENT_PAIR_A) {
-		if (pio_sgl->sgl_pair->B.address_lower == 0 &&
-		    pio_sgl->sgl_pair->B.address_upper == 0) {
-			current_sgl = NULL;
+	sgl_pair = to_sgl_element_pair(sci_req, pio_sgl->sgl_index);
+	if (!sgl_pair)
+		sgl = NULL;
+	else if (pio_sgl->sgl_set == SCU_SGL_ELEMENT_PAIR_A) {
+		if (sgl_pair->B.address_lower == 0 &&
+		    sgl_pair->B.address_upper == 0) {
+			sgl = NULL;
 		} else {
 			pio_sgl->sgl_set = SCU_SGL_ELEMENT_PAIR_B;
-			current_sgl = &pio_sgl->sgl_pair->B;
+			sgl = &sgl_pair->B;
 		}
 	} else {
-		if (pio_sgl->sgl_pair->next_pair_lower == 0 &&
-		    pio_sgl->sgl_pair->next_pair_upper == 0) {
-			current_sgl = NULL;
+		if (sgl_pair->next_pair_lower == 0 &&
+		    sgl_pair->next_pair_upper == 0) {
+			sgl = NULL;
 		} else {
-			u64 phys_addr;
-
-			phys_addr = pio_sgl->sgl_pair->next_pair_upper;
-			phys_addr <<= 32;
-			phys_addr |= pio_sgl->sgl_pair->next_pair_lower;
-
-			pio_sgl->sgl_pair = scic_request_get_virt_addr(sci_req, phys_addr);
+			pio_sgl->sgl_index++;
 			pio_sgl->sgl_set = SCU_SGL_ELEMENT_PAIR_A;
-			current_sgl = &pio_sgl->sgl_pair->A;
+			sgl_pair = to_sgl_element_pair(sci_req, pio_sgl->sgl_index);
+			sgl = &sgl_pair->A;
 		}
 	}
 
-	return current_sgl;
+	return sgl;
 }
 
 static enum sci_status
@@ -1328,21 +1221,19 @@ static enum sci_status scic_sds_stp_request_pio_data_out_trasmit_data_frame(
 	struct scic_sds_request *sci_req,
 	u32 length)
 {
-	struct scic_sds_controller *scic = sci_req->owning_controller;
 	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
-	struct scu_task_context *task_context;
+	struct scu_task_context *task_context = sci_req->tc;
+	struct scu_sgl_element_pair *sgl_pair;
 	struct scu_sgl_element *current_sgl;
 
 	/* Recycle the TC and reconstruct it for sending out DATA FIS containing
 	 * for the data from current_sgl+offset for the input length
 	 */
-	task_context = scic_sds_controller_get_task_context_buffer(scic,
-								   sci_req->io_tag);
-
+	sgl_pair = to_sgl_element_pair(sci_req, stp_req->type.pio.request_current.sgl_index);
 	if (stp_req->type.pio.request_current.sgl_set == SCU_SGL_ELEMENT_PAIR_A)
-		current_sgl = &stp_req->type.pio.request_current.sgl_pair->A;
+		current_sgl = &sgl_pair->A;
 	else
-		current_sgl = &stp_req->type.pio.request_current.sgl_pair->B;
+		current_sgl = &sgl_pair->B;
 
 	/* update the TC */
 	task_context->command_iu_upper = current_sgl->address_upper;
@@ -1362,18 +1253,21 @@ static enum sci_status scic_sds_stp_request_pio_data_out_transmit_data(struct sc
 	u32 remaining_bytes_in_current_sgl = 0;
 	enum sci_status status = SCI_SUCCESS;
 	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
+	struct scu_sgl_element_pair *sgl_pair;
 
 	sgl_offset = stp_req->type.pio.request_current.sgl_offset;
+	sgl_pair = to_sgl_element_pair(sci_req, stp_req->type.pio.request_current.sgl_index);
+	if (WARN_ONCE(!sgl_pair, "%s: null sgl element", __func__))
+		return SCI_FAILURE;
 
 	if (stp_req->type.pio.request_current.sgl_set == SCU_SGL_ELEMENT_PAIR_A) {
-		current_sgl = &(stp_req->type.pio.request_current.sgl_pair->A);
-		remaining_bytes_in_current_sgl = stp_req->type.pio.request_current.sgl_pair->A.length - sgl_offset;
+		current_sgl = &sgl_pair->A;
+		remaining_bytes_in_current_sgl = sgl_pair->A.length - sgl_offset;
 	} else {
-		current_sgl = &(stp_req->type.pio.request_current.sgl_pair->B);
-		remaining_bytes_in_current_sgl = stp_req->type.pio.request_current.sgl_pair->B.length - sgl_offset;
+		current_sgl = &sgl_pair->B;
+		remaining_bytes_in_current_sgl = sgl_pair->B.length - sgl_offset;
 	}
 
-
 	if (stp_req->type.pio.pio_transfer_bytes > 0) {
 		if (stp_req->type.pio.pio_transfer_bytes >= remaining_bytes_in_current_sgl) {
 			/* recycle the TC and send the H2D Data FIS from (current sgl + sgl_offset) and length = remaining_bytes_in_current_sgl */
@@ -1382,7 +1276,7 @@ static enum sci_status scic_sds_stp_request_pio_data_out_transmit_data(struct sc
 				stp_req->type.pio.pio_transfer_bytes -= remaining_bytes_in_current_sgl;
 
 				/* update the current sgl, sgl_offset and save for future */
-				current_sgl = scic_sds_stp_request_pio_get_next_sgl(stp_req);
+				current_sgl = pio_sgl_next(stp_req);
 				sgl_offset = 0;
 			}
 		} else if (stp_req->type.pio.pio_transfer_bytes < remaining_bytes_in_current_sgl) {
@@ -1945,7 +1839,7 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 			return status;
 		}
 
-		if (stp_req->type.pio.request_current.sgl_pair == NULL) {
+		if (stp_req->type.pio.request_current.sgl_index < 0) {
 			sci_req->saved_rx_frame_index = frame_index;
 			stp_req->type.pio.pio_transfer_bytes = 0;
 		} else {
@@ -2977,8 +2871,6 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 	 * task to recognize the already completed case.
 	 */
 	request->terminated = true;
-
-	isci_host_can_dequeue(isci_host, 1);
 }
 
 static void scic_sds_request_started_state_enter(struct sci_base_state_machine *sm)
@@ -3039,7 +2931,7 @@ static void scic_sds_request_aborting_state_enter(struct sci_base_state_machine
 	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), sm);
 
 	/* Setting the abort bit in the Task Context is required by the silicon. */
-	sci_req->task_context_buffer->abort = 1;
+	sci_req->tc->abort = 1;
 }
 
 static void scic_sds_stp_request_started_non_data_await_h2d_completion_enter(struct sci_base_state_machine *sm)
@@ -3069,7 +2961,7 @@ static void scic_sds_stp_request_started_soft_reset_await_h2d_asserted_completio
 static void scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter(struct sci_base_state_machine *sm)
 {
 	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), sm);
-	struct scu_task_context *task_context;
+	struct scu_task_context *tc = sci_req->tc;
 	struct host_to_dev_fis *h2d_fis;
 	enum sci_status status;
 
@@ -3078,9 +2970,7 @@ static void scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_complet
 	h2d_fis->control = 0;
 
 	/* Clear the TC control bit */
-	task_context = scic_sds_controller_get_task_context_buffer(
-		sci_req->owning_controller, sci_req->io_tag);
-	task_context->control_frame = 0;
+	tc->control_frame = 0;
 
 	status = scic_controller_continue_io(sci_req);
 	WARN_ONCE(status != SCI_SUCCESS, "isci: continue io failure\n");
@@ -3141,18 +3031,10 @@ scic_sds_general_request_construct(struct scic_sds_controller *scic,
 	sci_req->sci_status   = SCI_SUCCESS;
 	sci_req->scu_status   = 0;
 	sci_req->post_context = 0xFFFFFFFF;
+	sci_req->tc = &scic->task_context_table[ISCI_TAG_TCI(io_tag)];
 
 	sci_req->is_task_management_request = false;
-
-	if (io_tag == SCI_CONTROLLER_INVALID_IO_TAG) {
-		sci_req->was_tag_assigned_by_user = false;
-		sci_req->task_context_buffer = &sci_req->tc;
-	} else {
-		sci_req->was_tag_assigned_by_user = true;
-
-		sci_req->task_context_buffer =
-			scic_sds_controller_get_task_context_buffer(scic, io_tag);
-	}
+	WARN_ONCE(io_tag == SCI_CONTROLLER_INVALID_IO_TAG, "straggling invalid tag usage\n");
 }
 
 static enum sci_status
@@ -3178,8 +3060,7 @@ scic_io_request_construct(struct scic_sds_controller *scic,
 	else
 		return SCI_FAILURE_UNSUPPORTED_PROTOCOL;
 
-	memset(sci_req->task_context_buffer, 0,
-	       offsetof(struct scu_task_context, sgl_pair_ab));
+	memset(sci_req->tc, 0, offsetof(struct scu_task_context, sgl_pair_ab));
 
 	return status;
 }
@@ -3197,7 +3078,7 @@ enum sci_status scic_task_request_construct(struct scic_sds_controller *scic,
 	if (dev->dev_type == SAS_END_DEV ||
 	    dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP)) {
 		sci_req->is_task_management_request = true;
-		memset(sci_req->task_context_buffer, 0, sizeof(struct scu_task_context));
+		memset(sci_req->tc, 0, sizeof(struct scu_task_context));
 	} else
 		status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;
 
@@ -3299,7 +3180,7 @@ scic_io_request_construct_smp(struct device *dev,
 
 	/* byte swap the smp request. */
 
-	task_context = scic_sds_request_get_task_context(sci_req);
+	task_context = sci_req->tc;
 
 	sci_dev = scic_sds_request_get_device(sci_req);
 	sci_port = scic_sds_request_get_port(sci_req);
@@ -3354,33 +3235,12 @@ scic_io_request_construct_smp(struct device *dev,
 	 */
 	task_context->task_phase = 0;
 
-	if (sci_req->was_tag_assigned_by_user) {
-		/*
-		 * Build the task context now since we have already read
-		 * the data
-		 */
-		sci_req->post_context =
-			(SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
-			 (scic_sds_controller_get_protocol_engine_group(scic) <<
-			  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
-			 (scic_sds_port_get_index(sci_port) <<
-			  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
-			  ISCI_TAG_TCI(sci_req->io_tag));
-	} else {
-		/*
-		 * Build the task context now since we have already read
-		 * the data.
-		 * I/O tag index is not assigned because we have to wait
-		 * until we get a TCi.
-		 */
-		sci_req->post_context =
-			(SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
-			 (scic_sds_controller_get_protocol_engine_group(scic) <<
-			  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
-			 (scic_sds_port_get_index(sci_port) <<
-			  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT));
-	}
-
+	sci_req->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
+				 (scic_sds_controller_get_protocol_engine_group(scic) <<
+				  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
+				 (scic_sds_port_get_index(sci_port) <<
+				  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
+				 ISCI_TAG_TCI(sci_req->io_tag));
 	/*
 	 * Copy the physical address for the command buffer to the SCU Task
 	 * Context command buffer should not contain command header.
@@ -3431,10 +3291,10 @@ static enum sci_status isci_smp_request_build(struct isci_request *ireq)
  *
  * SCI_SUCCESS on successfull completion, or specific failure code.
  */
-static enum sci_status isci_io_request_build(
-	struct isci_host *isci_host,
-	struct isci_request *request,
-	struct isci_remote_device *isci_device)
+static enum sci_status isci_io_request_build(struct isci_host *isci_host,
+					     struct isci_request *request,
+					     struct isci_remote_device *isci_device,
+					     u16 tag)
 {
 	enum sci_status status = SCI_SUCCESS;
 	struct sas_task *task = isci_request_access_task(request);
@@ -3471,8 +3331,7 @@ static enum sci_status isci_io_request_build(
 	 * we will let the core allocate the IO tag.
 	 */
 	status = scic_io_request_construct(&isci_host->sci, sci_device,
-					   SCI_CONTROLLER_INVALID_IO_TAG,
-					   &request->sci);
+					   tag, &request->sci);
 
 	if (status != SCI_SUCCESS) {
 		dev_warn(&isci_host->pdev->dev,
@@ -3564,7 +3423,7 @@ struct isci_request *isci_request_alloc_tmf(struct isci_host *ihost,
 }
 
 int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *idev,
-			 struct sas_task *task, gfp_t gfp_flags)
+			 struct sas_task *task, u16 tag, gfp_t gfp_flags)
 {
 	enum sci_status status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;
 	struct isci_request *ireq;
@@ -3576,7 +3435,7 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 	if (!ireq)
 		goto out;
 
-	status = isci_io_request_build(ihost, ireq, idev);
+	status = isci_io_request_build(ihost, ireq, idev, tag);
 	if (status != SCI_SUCCESS) {
 		dev_warn(&ihost->pdev->dev,
 			 "%s: request_construct failed - status = 0x%x\n",
@@ -3599,18 +3458,16 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 			 */
 			status = scic_controller_start_task(&ihost->sci,
 							    &idev->sci,
-							    &ireq->sci,
-							    SCI_CONTROLLER_INVALID_IO_TAG);
+							    &ireq->sci);
 		} else {
 			status = SCI_FAILURE;
 		}
 	} else {
-
 		/* send the request, let the core assign the IO TAG.	*/
 		status = scic_controller_start_io(&ihost->sci, &idev->sci,
-						  &ireq->sci,
-						  SCI_CONTROLLER_INVALID_IO_TAG);
+						  &ireq->sci);
 	}
+
 	if (status != SCI_SUCCESS &&
 	    status != SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
 		dev_warn(&ihost->pdev->dev,
@@ -3647,23 +3504,23 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 	if (status ==
 	    SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
 		/* Signal libsas that we need the SCSI error
-		* handler thread to work on this I/O and that
-		* we want a device reset.
-		*/
+		 * handler thread to work on this I/O and that
+		 * we want a device reset.
+		 */
 		spin_lock_irqsave(&task->task_state_lock, flags);
 		task->task_state_flags |= SAS_TASK_NEED_DEV_RESET;
 		spin_unlock_irqrestore(&task->task_state_lock, flags);
 
 		/* Cause this task to be scheduled in the SCSI error
-		* handler thread.
-		*/
+		 * handler thread.
+		 */
 		isci_execpath_callback(ihost, task,
 				       sas_task_abort);
 
 		/* Change the status, since we are holding
-		* the I/O until it is managed by the SCSI
-		* error handler.
-		*/
+		 * the I/O until it is managed by the SCSI
+		 * error handler.
+		 */
 		status = SCI_SUCCESS;
 	}
 

commit 9274f45ea551421cd3bf329de9dd8d1e6208285a
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Thu Jun 23 17:09:02 2011 -0700

    isci: Terminate dev requests on FIS err bit rx in NCQ
    
    When the remote device transitions to a not-ready state because of
    an NCQ error condition, all outstanding requests to that device
    are terminated and completed to libsas on the normal path.  The
    device then waits for a READ LOG EXT command to issue on the task
    management path.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 1043fed2a40a..08a7340b33bf 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -3587,9 +3587,30 @@ int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *ide
 
 	spin_lock_irqsave(&ihost->scic_lock, flags);
 
-	/* send the request, let the core assign the IO TAG.	*/
-	status = scic_controller_start_io(&ihost->sci, &idev->sci, &ireq->sci,
-					  SCI_CONTROLLER_INVALID_IO_TAG);
+	if (test_bit(IDEV_IO_NCQERROR, &idev->flags)) {
+
+		if (isci_task_is_ncq_recovery(task)) {
+
+			/* The device is in an NCQ recovery state.  Issue the
+			 * request on the task side.  Note that it will
+			 * complete on the I/O request side because the
+			 * request was built that way (ie.
+			 * ireq->is_task_management_request is false).
+			 */
+			status = scic_controller_start_task(&ihost->sci,
+							    &idev->sci,
+							    &ireq->sci,
+							    SCI_CONTROLLER_INVALID_IO_TAG);
+		} else {
+			status = SCI_FAILURE;
+		}
+	} else {
+
+		/* send the request, let the core assign the IO TAG.	*/
+		status = scic_controller_start_io(&ihost->sci, &idev->sci,
+						  &ireq->sci,
+						  SCI_CONTROLLER_INVALID_IO_TAG);
+	}
 	if (status != SCI_SUCCESS &&
 	    status != SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
 		dev_warn(&ihost->pdev->dev,

commit e9bf709564e90abea25ca7aeae8c3de5cc6468d7
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Jun 16 16:59:56 2011 -0700

    isci: fix support for arbitrarily large smp requests
    
    Instead of duplicating the smp request buffer reuse the one provided by
    libsas.  This future proofs the driver to support arbitrarily large smp
    requests, and shrinks the request structure size by ~700 bytes.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 395084955150..1043fed2a40a 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2943,6 +2943,20 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 			dma_unmap_sg(&isci_host->pdev->dev, task->scatter,
 				     request->num_sg_entries, task->data_dir);
 		break;
+	case SAS_PROTOCOL_SMP: {
+		struct scatterlist *sg = &task->smp_task.smp_req;
+		struct smp_req *smp_req;
+		void *kaddr;
+
+		dma_unmap_sg(&isci_host->pdev->dev, sg, 1, DMA_TO_DEVICE);
+
+		/* need to swab it back in case the command buffer is re-used */
+		kaddr = kmap_atomic(sg_page(sg), KM_IRQ0);
+		smp_req = kaddr + sg->offset;
+		sci_swab32_cpy(smp_req, smp_req, sg->length / sizeof(u32));
+		kunmap_atomic(kaddr, KM_IRQ0);
+		break;
+	}
 	default:
 		break;
 	}
@@ -3160,7 +3174,7 @@ scic_io_request_construct(struct scic_sds_controller *scic,
 	else if (dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP))
 		memset(&sci_req->stp.cmd, 0, sizeof(sci_req->stp.cmd));
 	else if (dev_is_expander(dev))
-		memset(&sci_req->smp.cmd, 0, sizeof(sci_req->smp.cmd));
+		/* pass */;
 	else
 		return SCI_FAILURE_UNSUPPORTED_PROTOCOL;
 
@@ -3236,30 +3250,54 @@ static enum sci_status isci_request_stp_request_construct(
 	return status;
 }
 
-/*
- * This function will fill in the SCU Task Context for a SMP request. The
- *    following important settings are utilized: -# task_type ==
- *    SCU_TASK_TYPE_SMP.  This simply indicates that a normal request type
- *    (i.e. non-raw frame) is being utilized to perform task management. -#
- *    control_frame == 1.  This ensures that the proper endianess is set so
- *    that the bytes are transmitted in the right order for a smp request frame.
- * @sci_req: This parameter specifies the smp request object being
- *    constructed.
- *
- */
-static void
-scu_smp_request_construct_task_context(struct scic_sds_request *sci_req,
-				       ssize_t req_len)
+static enum sci_status
+scic_io_request_construct_smp(struct device *dev,
+			      struct scic_sds_request *sci_req,
+			      struct sas_task *task)
 {
-	dma_addr_t dma_addr;
+	struct scatterlist *sg = &task->smp_task.smp_req;
 	struct scic_sds_remote_device *sci_dev;
-	struct scic_sds_port *sci_port;
 	struct scu_task_context *task_context;
-	ssize_t word_cnt = sizeof(struct smp_req) / sizeof(u32);
+	struct scic_sds_port *sci_port;
+	struct smp_req *smp_req;
+	void *kaddr;
+	u8 req_len;
+	u32 cmd;
+
+	kaddr = kmap_atomic(sg_page(sg), KM_IRQ0);
+	smp_req = kaddr + sg->offset;
+	/*
+	 * Look at the SMP requests' header fields; for certain SAS 1.x SMP
+	 * functions under SAS 2.0, a zero request length really indicates
+	 * a non-zero default length.
+	 */
+	if (smp_req->req_len == 0) {
+		switch (smp_req->func) {
+		case SMP_DISCOVER:
+		case SMP_REPORT_PHY_ERR_LOG:
+		case SMP_REPORT_PHY_SATA:
+		case SMP_REPORT_ROUTE_INFO:
+			smp_req->req_len = 2;
+			break;
+		case SMP_CONF_ROUTE_INFO:
+		case SMP_PHY_CONTROL:
+		case SMP_PHY_TEST_FUNCTION:
+			smp_req->req_len = 9;
+			break;
+			/* Default - zero is a valid default for 2.0. */
+		}
+	}
+	req_len = smp_req->req_len;
+	sci_swab32_cpy(smp_req, smp_req, sg->length / sizeof(u32));
+	cmd = *(u32 *) smp_req;
+	kunmap_atomic(kaddr, KM_IRQ0);
+
+	if (!dma_map_sg(dev, sg, 1, DMA_TO_DEVICE))
+		return SCI_FAILURE;
+
+	sci_req->protocol = SCIC_SMP_PROTOCOL;
 
 	/* byte swap the smp request. */
-	sci_swab32_cpy(&sci_req->smp.cmd, &sci_req->smp.cmd,
-		       word_cnt);
 
 	task_context = scic_sds_request_get_task_context(sci_req);
 
@@ -3307,7 +3345,7 @@ scu_smp_request_construct_task_context(struct scic_sds_request *sci_req,
 	 * 18h ~ 30h, protocol specific
 	 * since commandIU has been build by framework at this point, we just
 	 * copy the frist DWord from command IU to this location. */
-	memcpy(&task_context->type.smp, &sci_req->smp.cmd, sizeof(u32));
+	memcpy(&task_context->type.smp, &cmd, sizeof(u32));
 
 	/*
 	 * 40h
@@ -3347,48 +3385,12 @@ scu_smp_request_construct_task_context(struct scic_sds_request *sci_req,
 	 * Copy the physical address for the command buffer to the SCU Task
 	 * Context command buffer should not contain command header.
 	 */
-	dma_addr = scic_io_request_get_dma_addr(sci_req,
-						((char *) &sci_req->smp.cmd) +
-						sizeof(u32));
-
-	task_context->command_iu_upper = upper_32_bits(dma_addr);
-	task_context->command_iu_lower = lower_32_bits(dma_addr);
+	task_context->command_iu_upper = upper_32_bits(sg_dma_address(sg));
+	task_context->command_iu_lower = lower_32_bits(sg_dma_address(sg) + sizeof(u32));
 
 	/* SMP response comes as UF, so no need to set response IU address. */
 	task_context->response_iu_upper = 0;
 	task_context->response_iu_lower = 0;
-}
-
-static enum sci_status
-scic_io_request_construct_smp(struct scic_sds_request *sci_req)
-{
-	struct smp_req *smp_req = &sci_req->smp.cmd;
-
-	sci_req->protocol = SCIC_SMP_PROTOCOL;
-
-	/*
-	 * Look at the SMP requests' header fields; for certain SAS 1.x SMP
-	 * functions under SAS 2.0, a zero request length really indicates
-	 * a non-zero default length.
-	 */
-	if (smp_req->req_len == 0) {
-		switch (smp_req->func) {
-		case SMP_DISCOVER:
-		case SMP_REPORT_PHY_ERR_LOG:
-		case SMP_REPORT_PHY_SATA:
-		case SMP_REPORT_ROUTE_INFO:
-			smp_req->req_len = 2;
-			break;
-		case SMP_CONF_ROUTE_INFO:
-		case SMP_PHY_CONTROL:
-		case SMP_PHY_TEST_FUNCTION:
-			smp_req->req_len = 9;
-			break;
-			/* Default - zero is a valid default for 2.0. */
-		}
-	}
-
-	scu_smp_request_construct_task_context(sci_req, smp_req->req_len);
 
 	sci_change_state(&sci_req->sm, SCI_REQ_CONSTRUCTED);
 
@@ -3404,24 +3406,12 @@ scic_io_request_construct_smp(struct scic_sds_request *sci_req)
  */
 static enum sci_status isci_smp_request_build(struct isci_request *ireq)
 {
-	enum sci_status status = SCI_FAILURE;
 	struct sas_task *task = isci_request_access_task(ireq);
+	struct device *dev = &ireq->isci_host->pdev->dev;
 	struct scic_sds_request *sci_req = &ireq->sci;
+	enum sci_status status = SCI_FAILURE;
 
-	dev_dbg(&ireq->isci_host->pdev->dev,
-		"%s: request = %p\n", __func__, ireq);
-
-	dev_dbg(&ireq->isci_host->pdev->dev,
-		"%s: smp_req len = %d\n",
-		__func__,
-		task->smp_task.smp_req.length);
-
-	/* copy the smp_command to the address; */
-	sg_copy_to_buffer(&task->smp_task.smp_req, 1,
-			  &sci_req->smp.cmd,
-			  sizeof(struct smp_req));
-
-	status = scic_io_request_construct_smp(sci_req);
+	status = scic_io_request_construct_smp(dev, sci_req, task);
 	if (status != SCI_SUCCESS)
 		dev_warn(&ireq->isci_host->pdev->dev,
 			 "%s: failed with status = %d\n",

commit ddcc7e347a891937be65358b43f40b7f81185f8f
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Jun 17 10:40:43 2011 -0700

    isci: fix dma_unmap_sg usage
    
    One bug and a cleanup:
    1/ Fix cases where we were unmapping invalid addresses (smp requests were
       being unmapped)
    
    [  604.662770] ------------[ cut here ]------------
    [  604.668026] WARNING: at lib/dma-debug.c:800 check_unmap+0x418/0x740()
    [  604.675315] Hardware name: SandyBridge Platform
    [  604.680465] isci 0000:03:00.0: DMA-API: device driver tries to free an invalid DMA memory address
    
    2/ The unmap routine is too large to be an inline function, and
       isci_request_io_request_get_next_sge is unused.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index f4fbca7b1fa3..395084955150 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2930,7 +2930,22 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 		break;
 	}
 
-	isci_request_unmap_sgl(request, isci_host->pdev);
+	switch (task->task_proto) {
+	case SAS_PROTOCOL_SSP:
+		if (task->data_dir == DMA_NONE)
+			break;
+		if (task->num_scatter == 0)
+			/* 0 indicates a single dma address */
+			dma_unmap_single(&isci_host->pdev->dev,
+					 request->zero_scatter_daddr,
+					 task->total_xfer_len, task->data_dir);
+		else  /* unmap the sgl dma addresses */
+			dma_unmap_sg(&isci_host->pdev->dev, task->scatter,
+				     request->num_sg_entries, task->data_dir);
+		break;
+	default:
+		break;
+	}
 
 	/* Put the completed request on the correct list */
 	isci_task_save_for_upper_layer_completion(isci_host, request, response,

commit 5edc33480c1c363ab361a881f2957b9fba5185cf
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Jun 16 17:20:35 2011 -0700

    isci: fix smp response frame overrun
    
    Due to a typo we currently copy way too much when copying over the
    response data, but since a request is likely backed by a full page
    allocation we don't corrupt live data.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index ebe160c83f91..f4fbca7b1fa3 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -1694,7 +1694,7 @@ scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
 								      frame_index,
 								      &smp_resp);
 
-			word_cnt = (sizeof(struct smp_req) - SMP_RESP_HDR_SZ) /
+			word_cnt = (sizeof(struct smp_resp) - SMP_RESP_HDR_SZ) /
 				sizeof(u32);
 
 			sci_swab32_cpy(((u8 *) rsp_hdr) + SMP_RESP_HDR_SZ,

commit ff60639dc9a461883db9192d2da0674a00339f12
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Jun 17 13:34:43 2011 -0700

    isci: kill device_sequence
    
    Now that we have upleveled device reassignment protection to the
    isci_remote_device reference count we no longer need this level of
    self-defense.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index fd6314abeb0b..ebe160c83f91 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -753,10 +753,6 @@ enum sci_status scic_sds_request_start(struct scic_sds_request *sci_req)
 	struct scu_task_context *task_context;
 	enum sci_base_request_states state;
 
-	if (sci_req->device_sequence !=
-	    scic_sds_remote_device_get_sequence(sci_req->target_device))
-		return SCI_FAILURE;
-
 	state = sci_req->sm.current_state_id;
 	if (state != SCI_REQ_CONSTRUCTED) {
 		dev_warn(scic_to_dev(scic),
@@ -3112,7 +3108,6 @@ scic_sds_general_request_construct(struct scic_sds_controller *scic,
 	sci_req->target_device = sci_dev;
 	sci_req->protocol = SCIC_NO_PROTOCOL;
 	sci_req->saved_rx_frame_index = SCU_INVALID_FRAME_INDEX;
-	sci_req->device_sequence = scic_sds_remote_device_get_sequence(sci_dev);
 
 	sci_req->sci_status   = SCI_SUCCESS;
 	sci_req->scu_status   = 0;

commit 209fae14fabfd48525e5630bebbbd4ca15090c60
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Jun 13 17:39:44 2011 -0700

    isci: atomic device lookup and reference counting
    
    We have unsafe references to remote devices that are notified to
    disappear at lldd_dev_gone.  In order to clean this up we need a single
    canonical source for device lookups and stable references once a lookup
    succeeds.  Towards that end guarantee that domain_device.lldd_dev is
    NULL as soon as we start the process of stopping a device.  Any code
    path that wants to safely lookup a remote device must do so through
    task->dev->lldd_dev (isci_lookup_device()).
    
    For in-flight references outside of scic_lock we need reference counting
    to ensure that the device is not recycled before we are done with it.
    Simplify device back references to just scic_sds_request.target_device
    which is now the only permissible internal reference that is maintained
    relative to the reference count.
    
    There were two occasions where we wanted new i/o's to be treated as
    SAS_TASK_UNDELIVERED but where the domain_dev->lldd_dev link is still
    intact.  Introduce a 'gone' flag to prevent i/o while waiting for libsas
    to take action on the port down event.
    
    One 'core' leftover is that we currently call
    scic_remote_device_destruct() from isci_remote_device_deconstruct()
    which is called when the 'core' says the device is stopped.  It would be
    more natural for the final put to trigger
    isci_remote_device_deconstruct() but this implementation is deferred as
    it requires other changes.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index f0813d076c50..fd6314abeb0b 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2313,7 +2313,7 @@ static void isci_request_set_open_reject_status(
  * none.
  */
 static void isci_request_handle_controller_specific_errors(
-	struct isci_remote_device *isci_device,
+	struct isci_remote_device *idev,
 	struct isci_request *request,
 	struct sas_task *task,
 	enum service_response *response_ptr,
@@ -2353,8 +2353,7 @@ static void isci_request_handle_controller_specific_errors(
 			 * that we ignore the quiesce state, since we are
 			 * concerned about the actual device state.
 			 */
-			if ((isci_device->status == isci_stopping) ||
-			    (isci_device->status == isci_stopped))
+			if (!idev)
 				*status_ptr = SAS_DEVICE_UNKNOWN;
 			else
 				*status_ptr = SAS_ABORTED_TASK;
@@ -2367,8 +2366,7 @@ static void isci_request_handle_controller_specific_errors(
 			/* Task in the target is not done. */
 			*response_ptr = SAS_TASK_UNDELIVERED;
 
-			if ((isci_device->status == isci_stopping) ||
-			    (isci_device->status == isci_stopped))
+			if (!idev)
 				*status_ptr = SAS_DEVICE_UNKNOWN;
 			else
 				*status_ptr = SAM_STAT_TASK_ABORTED;
@@ -2399,8 +2397,7 @@ static void isci_request_handle_controller_specific_errors(
 		 * that we ignore the quiesce state, since we are
 		 * concerned about the actual device state.
 		 */
-		if ((isci_device->status == isci_stopping) ||
-		    (isci_device->status == isci_stopped))
+		if (!idev)
 			*status_ptr = SAS_DEVICE_UNKNOWN;
 		else
 			*status_ptr = SAS_ABORTED_TASK;
@@ -2629,7 +2626,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 	struct ssp_response_iu *resp_iu;
 	void *resp_buf;
 	unsigned long task_flags;
-	struct isci_remote_device *isci_device   = request->isci_device;
+	struct isci_remote_device *idev = isci_lookup_device(task->dev);
 	enum service_response response       = SAS_TASK_UNDELIVERED;
 	enum exec_status status         = SAS_ABORTED_TASK;
 	enum isci_request_status request_status;
@@ -2672,9 +2669,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 		 * that we ignore the quiesce state, since we are
 		 * concerned about the actual device state.
 		 */
-		if ((isci_device->status == isci_stopping)
-		    || (isci_device->status == isci_stopped)
-		    )
+		if (!idev)
 			status = SAS_DEVICE_UNKNOWN;
 		else
 			status = SAS_ABORTED_TASK;
@@ -2697,8 +2692,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 		request->complete_in_target = true;
 		response = SAS_TASK_UNDELIVERED;
 
-		if ((isci_device->status == isci_stopping) ||
-		    (isci_device->status == isci_stopped))
+		if (!idev)
 			/* The device has been /is being stopped. Note that
 			 * we ignore the quiesce state, since we are
 			 * concerned about the actual device state.
@@ -2728,8 +2722,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 		 * that we ignore the quiesce state, since we are
 		 * concerned about the actual device state.
 		 */
-		if ((isci_device->status == isci_stopping) ||
-		    (isci_device->status == isci_stopped))
+		if (!idev)
 			status = SAS_DEVICE_UNKNOWN;
 		else
 			status = SAS_ABORTED_TASK;
@@ -2861,8 +2854,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 			 * that we ignore the quiesce state, since we are
 			 * concerned about the actual device state.
 			 */
-			if ((isci_device->status == isci_stopping) ||
-			    (isci_device->status == isci_stopped))
+			if (!idev)
 				status = SAS_DEVICE_UNKNOWN;
 			else
 				status = SAS_ABORTED_TASK;
@@ -2873,7 +2865,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 		case SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR:
 
 			isci_request_handle_controller_specific_errors(
-				isci_device, request, task, &response, &status,
+				idev, request, task, &response, &status,
 				&complete_to_host);
 
 			break;
@@ -2902,8 +2894,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 
 			/* Fail the I/O so it can be retried. */
 			response = SAS_TASK_UNDELIVERED;
-			if ((isci_device->status == isci_stopping) ||
-			    (isci_device->status == isci_stopped))
+			if (!idev)
 				status = SAS_DEVICE_UNKNOWN;
 			else
 				status = SAS_ABORTED_TASK;
@@ -2926,8 +2917,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 			 * that we ignore the quiesce state, since we are
 			 * concerned about the actual device state.
 			 */
-			if ((isci_device->status == isci_stopping) ||
-			    (isci_device->status == isci_stopped))
+			if (!idev)
 				status = SAS_DEVICE_UNKNOWN;
 			else
 				status = SAS_ABORTED_TASK;
@@ -2953,8 +2943,10 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 
 	/* complete the io request to the core. */
 	scic_controller_complete_io(&isci_host->sci,
-				    &isci_device->sci,
+				    request->sci.target_device,
 				    &request->sci);
+	isci_put_device(idev);
+
 	/* set terminated handle so it cannot be completed or
 	 * terminated again, and to cause any calls into abort
 	 * task to recognize the already completed case.
@@ -3511,7 +3503,6 @@ static enum sci_status isci_io_request_build(
 }
 
 static struct isci_request *isci_request_alloc_core(struct isci_host *ihost,
-						    struct isci_remote_device *idev,
 						    gfp_t gfp_flags)
 {
 	dma_addr_t handle;
@@ -3528,7 +3519,6 @@ static struct isci_request *isci_request_alloc_core(struct isci_host *ihost,
 	spin_lock_init(&ireq->state_lock);
 	ireq->request_daddr = handle;
 	ireq->isci_host = ihost;
-	ireq->isci_device = idev;
 	ireq->io_request_completion = NULL;
 	ireq->terminated = false;
 
@@ -3546,12 +3536,11 @@ static struct isci_request *isci_request_alloc_core(struct isci_host *ihost,
 
 static struct isci_request *isci_request_alloc_io(struct isci_host *ihost,
 						  struct sas_task *task,
-						  struct isci_remote_device *idev,
 						  gfp_t gfp_flags)
 {
 	struct isci_request *ireq;
 
-	ireq = isci_request_alloc_core(ihost, idev, gfp_flags);
+	ireq = isci_request_alloc_core(ihost, gfp_flags);
 	if (ireq) {
 		ireq->ttype_ptr.io_task_ptr = task;
 		ireq->ttype = io_task;
@@ -3562,12 +3551,11 @@ static struct isci_request *isci_request_alloc_io(struct isci_host *ihost,
 
 struct isci_request *isci_request_alloc_tmf(struct isci_host *ihost,
 					    struct isci_tmf *isci_tmf,
-					    struct isci_remote_device *idev,
 					    gfp_t gfp_flags)
 {
 	struct isci_request *ireq;
 
-	ireq = isci_request_alloc_core(ihost, idev, gfp_flags);
+	ireq = isci_request_alloc_core(ihost, gfp_flags);
 	if (ireq) {
 		ireq->ttype_ptr.tmf_task_ptr = isci_tmf;
 		ireq->ttype = tmf_task;
@@ -3575,21 +3563,16 @@ struct isci_request *isci_request_alloc_tmf(struct isci_host *ihost,
 	return ireq;
 }
 
-int isci_request_execute(struct isci_host *ihost, struct sas_task *task,
-			 gfp_t gfp_flags)
+int isci_request_execute(struct isci_host *ihost, struct isci_remote_device *idev,
+			 struct sas_task *task, gfp_t gfp_flags)
 {
 	enum sci_status status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;
-	struct scic_sds_remote_device *sci_dev;
-	struct isci_remote_device *idev;
 	struct isci_request *ireq;
 	unsigned long flags;
 	int ret = 0;
 
-	idev = task->dev->lldd_dev;
-	sci_dev = &idev->sci;
-
 	/* do common allocation and init of request object. */
-	ireq = isci_request_alloc_io(ihost, task, idev, gfp_flags);
+	ireq = isci_request_alloc_io(ihost, task, gfp_flags);
 	if (!ireq)
 		goto out;
 
@@ -3605,8 +3588,7 @@ int isci_request_execute(struct isci_host *ihost, struct sas_task *task,
 	spin_lock_irqsave(&ihost->scic_lock, flags);
 
 	/* send the request, let the core assign the IO TAG.	*/
-	status = scic_controller_start_io(&ihost->sci, sci_dev,
-					  &ireq->sci,
+	status = scic_controller_start_io(&ihost->sci, &idev->sci, &ireq->sci,
 					  SCI_CONTROLLER_INVALID_IO_TAG);
 	if (status != SCI_SUCCESS &&
 	    status != SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {

commit 0d0cf14c9bd2943ed5afd15df459f564d85eacde
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Jun 13 00:51:30 2011 -0700

    isci: cleanup request allocation
    
    Rather than return an error code and update a pointer that was passed by
    reference just return the request object directly (or null if allocation
    failed).
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 9d7531ad9a74..f0813d076c50 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -3510,172 +3510,110 @@ static enum sci_status isci_io_request_build(
 	return SCI_SUCCESS;
 }
 
-/**
- * isci_request_alloc_core() - This function gets the request object from the
- *    isci_host dma cache.
- * @isci_host: This parameter specifies the ISCI host object
- * @isci_request: This parameter will contain the pointer to the new
- *    isci_request object.
- * @isci_device: This parameter is the pointer to the isci remote device object
- *    that is the destination for this request.
- * @gfp_flags: This parameter specifies the os allocation flags.
- *
- * SCI_SUCCESS on successfull completion, or specific failure code.
- */
-static int isci_request_alloc_core(
-	struct isci_host *isci_host,
-	struct isci_request **isci_request,
-	struct isci_remote_device *isci_device,
-	gfp_t gfp_flags)
+static struct isci_request *isci_request_alloc_core(struct isci_host *ihost,
+						    struct isci_remote_device *idev,
+						    gfp_t gfp_flags)
 {
-	int ret = 0;
 	dma_addr_t handle;
-	struct isci_request *request;
-
+	struct isci_request *ireq;
 
-	/* get pointer to dma memory. This actually points
-	 * to both the isci_remote_device object and the
-	 * sci object. The isci object is at the beginning
-	 * of the memory allocated here.
-	 */
-	request = dma_pool_alloc(isci_host->dma_pool, gfp_flags, &handle);
-	if (!request) {
-		dev_warn(&isci_host->pdev->dev,
+	ireq = dma_pool_alloc(ihost->dma_pool, gfp_flags, &handle);
+	if (!ireq) {
+		dev_warn(&ihost->pdev->dev,
 			 "%s: dma_pool_alloc returned NULL\n", __func__);
-		return -ENOMEM;
+		return NULL;
 	}
 
 	/* initialize the request object.	*/
-	spin_lock_init(&request->state_lock);
-	request->request_daddr = handle;
-	request->isci_host = isci_host;
-	request->isci_device = isci_device;
-	request->io_request_completion = NULL;
-	request->terminated = false;
+	spin_lock_init(&ireq->state_lock);
+	ireq->request_daddr = handle;
+	ireq->isci_host = ihost;
+	ireq->isci_device = idev;
+	ireq->io_request_completion = NULL;
+	ireq->terminated = false;
 
-	request->num_sg_entries = 0;
+	ireq->num_sg_entries = 0;
 
-	request->complete_in_target = false;
+	ireq->complete_in_target = false;
 
-	INIT_LIST_HEAD(&request->completed_node);
-	INIT_LIST_HEAD(&request->dev_node);
+	INIT_LIST_HEAD(&ireq->completed_node);
+	INIT_LIST_HEAD(&ireq->dev_node);
 
-	*isci_request = request;
-	isci_request_change_state(request, allocated);
+	isci_request_change_state(ireq, allocated);
 
-	return ret;
+	return ireq;
 }
 
-static int isci_request_alloc_io(
-	struct isci_host *isci_host,
-	struct sas_task *task,
-	struct isci_request **isci_request,
-	struct isci_remote_device *isci_device,
-	gfp_t gfp_flags)
+static struct isci_request *isci_request_alloc_io(struct isci_host *ihost,
+						  struct sas_task *task,
+						  struct isci_remote_device *idev,
+						  gfp_t gfp_flags)
 {
-	int retval = isci_request_alloc_core(isci_host, isci_request,
-					     isci_device, gfp_flags);
-
-	if (!retval) {
-		(*isci_request)->ttype_ptr.io_task_ptr = task;
-		(*isci_request)->ttype                 = io_task;
+	struct isci_request *ireq;
 
-		task->lldd_task = *isci_request;
+	ireq = isci_request_alloc_core(ihost, idev, gfp_flags);
+	if (ireq) {
+		ireq->ttype_ptr.io_task_ptr = task;
+		ireq->ttype = io_task;
+		task->lldd_task = ireq;
 	}
-	return retval;
+	return ireq;
 }
 
-/**
- * isci_request_alloc_tmf() - This function gets the request object from the
- *    isci_host dma cache and initializes the relevant fields as a sas_task.
- * @isci_host: This parameter specifies the ISCI host object
- * @sas_task: This parameter is the task struct from the upper layer driver.
- * @isci_request: This parameter will contain the pointer to the new
- *    isci_request object.
- * @isci_device: This parameter is the pointer to the isci remote device object
- *    that is the destination for this request.
- * @gfp_flags: This parameter specifies the os allocation flags.
- *
- * SCI_SUCCESS on successfull completion, or specific failure code.
- */
-int isci_request_alloc_tmf(
-	struct isci_host *isci_host,
-	struct isci_tmf *isci_tmf,
-	struct isci_request **isci_request,
-	struct isci_remote_device *isci_device,
-	gfp_t gfp_flags)
+struct isci_request *isci_request_alloc_tmf(struct isci_host *ihost,
+					    struct isci_tmf *isci_tmf,
+					    struct isci_remote_device *idev,
+					    gfp_t gfp_flags)
 {
-	int retval = isci_request_alloc_core(isci_host, isci_request,
-					     isci_device, gfp_flags);
-
-	if (!retval) {
+	struct isci_request *ireq;
 
-		(*isci_request)->ttype_ptr.tmf_task_ptr = isci_tmf;
-		(*isci_request)->ttype = tmf_task;
+	ireq = isci_request_alloc_core(ihost, idev, gfp_flags);
+	if (ireq) {
+		ireq->ttype_ptr.tmf_task_ptr = isci_tmf;
+		ireq->ttype = tmf_task;
 	}
-	return retval;
+	return ireq;
 }
 
-/**
- * isci_request_execute() - This function allocates the isci_request object,
- *    all fills in some common fields.
- * @isci_host: This parameter specifies the ISCI host object
- * @sas_task: This parameter is the task struct from the upper layer driver.
- * @isci_request: This parameter will contain the pointer to the new
- *    isci_request object.
- * @gfp_flags: This parameter specifies the os allocation flags.
- *
- * SCI_SUCCESS on successfull completion, or specific failure code.
- */
-int isci_request_execute(
-	struct isci_host *isci_host,
-	struct sas_task *task,
-	struct isci_request **isci_request,
-	gfp_t gfp_flags)
+int isci_request_execute(struct isci_host *ihost, struct sas_task *task,
+			 gfp_t gfp_flags)
 {
-	int ret = 0;
-	struct scic_sds_remote_device *sci_device;
 	enum sci_status status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;
-	struct isci_remote_device *isci_device;
-	struct isci_request *request;
+	struct scic_sds_remote_device *sci_dev;
+	struct isci_remote_device *idev;
+	struct isci_request *ireq;
 	unsigned long flags;
+	int ret = 0;
 
-	isci_device = task->dev->lldd_dev;
-	sci_device = &isci_device->sci;
+	idev = task->dev->lldd_dev;
+	sci_dev = &idev->sci;
 
 	/* do common allocation and init of request object. */
-	ret = isci_request_alloc_io(
-		isci_host,
-		task,
-		&request,
-		isci_device,
-		gfp_flags
-		);
-
-	if (ret)
+	ireq = isci_request_alloc_io(ihost, task, idev, gfp_flags);
+	if (!ireq)
 		goto out;
 
-	status = isci_io_request_build(isci_host, request, isci_device);
+	status = isci_io_request_build(ihost, ireq, idev);
 	if (status != SCI_SUCCESS) {
-		dev_warn(&isci_host->pdev->dev,
+		dev_warn(&ihost->pdev->dev,
 			 "%s: request_construct failed - status = 0x%x\n",
 			 __func__,
 			 status);
 		goto out;
 	}
 
-	spin_lock_irqsave(&isci_host->scic_lock, flags);
+	spin_lock_irqsave(&ihost->scic_lock, flags);
 
 	/* send the request, let the core assign the IO TAG.	*/
-	status = scic_controller_start_io(&isci_host->sci, sci_device,
-					  &request->sci,
+	status = scic_controller_start_io(&ihost->sci, sci_dev,
+					  &ireq->sci,
 					  SCI_CONTROLLER_INVALID_IO_TAG);
 	if (status != SCI_SUCCESS &&
 	    status != SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
-		dev_warn(&isci_host->pdev->dev,
+		dev_warn(&ihost->pdev->dev,
 			 "%s: failed request start (0x%x)\n",
 			 __func__, status);
-		spin_unlock_irqrestore(&isci_host->scic_lock, flags);
+		spin_unlock_irqrestore(&ihost->scic_lock, flags);
 		goto out;
 	}
 
@@ -3687,21 +3625,21 @@ int isci_request_execute(
 	 * Update it's status and add it to the list in the
 	 * remote device object.
 	 */
-	list_add(&request->dev_node, &isci_device->reqs_in_process);
+	list_add(&ireq->dev_node, &idev->reqs_in_process);
 
 	if (status == SCI_SUCCESS) {
 		/* Save the tag for possible task mgmt later. */
-		request->io_tag = request->sci.io_tag;
-		isci_request_change_state(request, started);
+		ireq->io_tag = ireq->sci.io_tag;
+		isci_request_change_state(ireq, started);
 	} else {
 		/* The request did not really start in the
 		 * hardware, so clear the request handle
 		 * here so no terminations will be done.
 		 */
-		request->terminated = true;
-		isci_request_change_state(request, completed);
+		ireq->terminated = true;
+		isci_request_change_state(ireq, completed);
 	}
-	spin_unlock_irqrestore(&isci_host->scic_lock, flags);
+	spin_unlock_irqrestore(&ihost->scic_lock, flags);
 
 	if (status ==
 	    SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
@@ -3716,7 +3654,7 @@ int isci_request_execute(
 		/* Cause this task to be scheduled in the SCSI error
 		* handler thread.
 		*/
-		isci_execpath_callback(isci_host, task,
+		isci_execpath_callback(ihost, task,
 				       sas_task_abort);
 
 		/* Change the status, since we are holding
@@ -3729,11 +3667,10 @@ int isci_request_execute(
  out:
 	if (status != SCI_SUCCESS) {
 		/* release dma memory on failure. */
-		isci_request_free(isci_host, request);
-		request = NULL;
+		isci_request_free(ihost, ireq);
+		ireq = NULL;
 		ret = SCI_FAILURE;
 	}
 
-	*isci_request = request;
 	return ret;
 }

commit dd047c8e2bca22856050dbe0378a37cf44eecc97
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Jun 9 11:06:58 2011 -0700

    isci: cleanup tag macros
    
    A tag is a 16 bit number where the upper four bits is a sequence number
    and the remainder is the task context index (tci).  Sanitize the macro
    names and shave 256-bytes out of scic_sds_controller by reducing the size of
    io_request_sequence.
    
    scic_sds_io_tag_construct --> ISCI_TAG
    scic_sds_io_tag_get_sequence --> ISCI_TAG_SEQ
    scic_sds_io_tag_get_index() --> ISCI_TAG_TCI
    scic_sds_io_sequence_increment() [delete / open code]
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 433565c2b343..9d7531ad9a74 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -258,7 +258,7 @@ static void scu_ssp_reqeust_construct_task_context(
 			  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
 			 (scic_sds_port_get_index(target_port) <<
 			  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
-			 scic_sds_io_tag_get_index(sds_request->io_tag));
+			  ISCI_TAG_TCI(sds_request->io_tag));
 	} else {
 		/*
 		 * Build the task context now since we have already read
@@ -433,7 +433,7 @@ static void scu_sata_reqeust_construct_task_context(
 			  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
 			 (scic_sds_port_get_index(target_port) <<
 			  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
-			 scic_sds_io_tag_get_index(sci_req->io_tag));
+			  ISCI_TAG_TCI(sci_req->io_tag));
 	} else {
 		/*
 		 * Build the task context now since we have already read
@@ -741,7 +741,7 @@ static u32 sci_req_tx_bytes(struct scic_sds_request *sci_req)
 		 */
 		ret_val = readl(scu_reg_base +
 				(SCU_TASK_CONTEXT_SRAM + offsetof(struct scu_task_context, type.ssp.data_offset)) +
-				((sizeof(struct scu_task_context)) * scic_sds_io_tag_get_index(sci_req->io_tag)));
+				((sizeof(struct scu_task_context)) * ISCI_TAG_TCI(sci_req->io_tag)));
 	}
 
 	return ret_val;
@@ -777,7 +777,7 @@ enum sci_status scic_sds_request_start(struct scic_sds_request *sci_req)
 	if (sci_req->io_tag != SCI_CONTROLLER_INVALID_IO_TAG) {
 		task_context = sci_req->task_context_buffer;
 
-		task_context->task_index = scic_sds_io_tag_get_index(sci_req->io_tag);
+		task_context->task_index = ISCI_TAG_TCI(sci_req->io_tag);
 
 		switch (task_context->protocol_type) {
 		case SCU_TASK_CONTEXT_PROTOCOL_SMP:
@@ -811,7 +811,7 @@ enum sci_status scic_sds_request_start(struct scic_sds_request *sci_req)
 			scic_sds_controller_copy_task_context(scic, sci_req);
 
 		/* Add to the post_context the io tag value */
-		sci_req->post_context |= scic_sds_io_tag_get_index(sci_req->io_tag);
+		sci_req->post_context |= ISCI_TAG_TCI(sci_req->io_tag);
 
 		/* Everything is good go ahead and change state */
 		sci_change_state(&sci_req->sm, SCI_REQ_STARTED);
@@ -3325,7 +3325,7 @@ scu_smp_request_construct_task_context(struct scic_sds_request *sci_req,
 			  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
 			 (scic_sds_port_get_index(sci_port) <<
 			  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
-			 scic_sds_io_tag_get_index(sci_req->io_tag));
+			  ISCI_TAG_TCI(sci_req->io_tag));
 	} else {
 		/*
 		 * Build the task context now since we have already read

commit 77c852f312243192b1f2ce7fc56d678784786692
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Mon Jun 20 14:09:16 2011 -0700

    isci: Handle timed-out request terminations correctly
    
    In the situation where a termination of an I/O times-out,
    make sure that the linkage from the request to the task
    is severed completely.  Also make sure that the selection
    of tasks to terminate occurs under scic_lock.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 5879e5f308e6..433565c2b343 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2741,6 +2741,15 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 		spin_unlock(&request->state_lock);
 		break;
 
+	case dead:
+		/* This was a terminated request that timed-out during the
+		 * termination process.  There is no task to complete to
+		 * libsas.
+		 */
+		complete_to_host = isci_perform_normal_io_completion;
+		spin_unlock(&request->state_lock);
+		break;
+
 	default:
 
 		/* The request is done from an SCU HW perspective. */

commit f53a3a32c1e799e27f63bff7b42b4c36749e5e6f
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Mon Jun 20 14:09:11 2011 -0700

    isci: Requests that do not start must be set to "complete"
    
    Requests that fail at start because of a reset pending condition
    must be set to complete in order to allow for later cleanup.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 3a891d32c331..5879e5f308e6 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -3678,18 +3678,19 @@ int isci_request_execute(
 	 * Update it's status and add it to the list in the
 	 * remote device object.
 	 */
-	isci_request_change_state(request, started);
 	list_add(&request->dev_node, &isci_device->reqs_in_process);
 
 	if (status == SCI_SUCCESS) {
 		/* Save the tag for possible task mgmt later. */
 		request->io_tag = request->sci.io_tag;
+		isci_request_change_state(request, started);
 	} else {
 		/* The request did not really start in the
 		 * hardware, so clear the request handle
 		 * here so no terminations will be done.
 		 */
 		request->terminated = true;
+		isci_request_change_state(request, completed);
 	}
 	spin_unlock_irqrestore(&isci_host->scic_lock, flags);
 

commit cde76fbf1f27551a08860227765ae8d5026ac0d9
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Mon Jun 20 14:09:06 2011 -0700

    isci: Add decode for SMP request retry error condition
    
    There are situations with slow expanders in which a first attempt
    to execute an SMP request will fail with a timeout.  Immediate
    subsequent retries will generally succeed.  This change makes sure
    SMP I/O failures are immediately failed to libsas so that retries
    happen with no discovery process timeout delay.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 8bd1f7dbad37..3a891d32c331 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2508,9 +2508,16 @@ static void isci_request_handle_controller_specific_errors(
 		/* Task in the target is not done. */
 		*response_ptr = SAS_TASK_UNDELIVERED;
 		*status_ptr = SAM_STAT_TASK_ABORTED;
-		request->complete_in_target = false;
 
-		*complete_to_host_ptr = isci_perform_error_io_completion;
+		if (task->task_proto == SAS_PROTOCOL_SMP) {
+			request->complete_in_target = true;
+
+			*complete_to_host_ptr = isci_perform_normal_io_completion;
+		} else {
+			request->complete_in_target = false;
+
+			*complete_to_host_ptr = isci_perform_error_io_completion;
+		}
 		break;
 	}
 }
@@ -2882,6 +2889,21 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 			request->complete_in_target = false;
 			break;
 
+		case SCI_FAILURE_RETRY_REQUIRED:
+
+			/* Fail the I/O so it can be retried. */
+			response = SAS_TASK_UNDELIVERED;
+			if ((isci_device->status == isci_stopping) ||
+			    (isci_device->status == isci_stopped))
+				status = SAS_DEVICE_UNKNOWN;
+			else
+				status = SAS_ABORTED_TASK;
+
+			complete_to_host = isci_perform_normal_io_completion;
+			request->complete_in_target = true;
+			break;
+
+
 		default:
 			/* Catch any otherwise unhandled error codes here. */
 			dev_warn(&isci_host->pdev->dev,
@@ -2901,8 +2923,13 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 			else
 				status = SAS_ABORTED_TASK;
 
-			complete_to_host = isci_perform_error_io_completion;
-			request->complete_in_target = false;
+			if (SAS_PROTOCOL_SMP == task->task_proto) {
+				request->complete_in_target = true;
+				complete_to_host = isci_perform_normal_io_completion;
+			} else {
+				request->complete_in_target = false;
+				complete_to_host = isci_perform_error_io_completion;
+			}
 			break;
 		}
 		break;

commit 12ef65444de9d387a383b9991960848bed5bbe74
Author: Edmund Nadolski <edmund.nadolski@intel.com>
Date:   Thu Jun 2 00:10:50 2011 +0000

    isci: additional state machine cleanup
    
    Additional state machine cleanups:
    
     o Remove static functions sci_state_machine_exit_state() and
       sci_state_machine_enter_state()
     o Combines sci_base_state_machine_construct() and
       sci_base_state_machine_start() into a single function,
       sci_init_sm()
     o Remove sci_base_state_machine_stop() which is unused.
     o Kill state_machine.[ch]
    
    Signed-off-by: Edmund Nadolski <edmund.nadolski@intel.com>
    [fixed too large to inline functions]
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 89f0ab925c27..8bd1f7dbad37 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -3077,10 +3077,7 @@ scic_sds_general_request_construct(struct scic_sds_controller *scic,
 				   u16 io_tag,
 				   struct scic_sds_request *sci_req)
 {
-	sci_base_state_machine_construct(&sci_req->sm,
-					 scic_sds_request_state_table,
-					 SCI_REQ_INIT);
-	sci_base_state_machine_start(&sci_req->sm);
+	sci_init_sm(&sci_req->sm, scic_sds_request_state_table, SCI_REQ_INIT);
 
 	sci_req->io_tag = io_tag;
 	sci_req->owning_controller = scic;

commit e301370ac553a9a0ac0d1d25e769b86cf60395b3
Author: Edmund Nadolski <edmund.nadolski@intel.com>
Date:   Thu Jun 2 00:10:43 2011 +0000

    isci: state machine cleanup
    
    This cleans up several areas of the state machine mechanism:
    
     o Rename sci_base_state_machine_change_state to sci_change_state
     o Remove sci_base_state_machine_get_state function
     o Rename 'state_machine' struct member to 'sm' in client structs
     o Shorten the name of request states
     o Shorten state machine state names as follows:
            SCI_BASE_CONTROLLER_STATE_xxx to SCIC_xxx
            SCI_BASE_PHY_STATE_xxx to SCI_PHY_xxx
            SCIC_SDS_PHY_STARTING_SUBSTATE_xxx to SCI_PHY_SUB_xxx
            SCI_BASE_PORT_STATE_xxx to SCI_PORT_xxx and
            SCIC_SDS_PORT_READY_SUBSTATE_xxx to SCI_PORT_SUB_xxx
            SCI_BASE_REMOTE_DEVICE_STATE_xxx to SCI_DEV_xxx
            SCIC_SDS_STP_REMOTE_DEVICE_READY_SUBSTATE_xxx to SCI_STP_DEV_xxx
            SCIC_SDS_SMP_REMOTE_DEVICE_READY_SUBSTATE_xxx to SCI_SMP_DEV_xxx
            SCIC_SDS_REMOTE_NODE_CONTEXT_xxx_STATE to SCI_RNC_xxx
    
    Signed-off-by: Edmund Nadolski <edmund.nadolski@intel.com>
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 31c9b2c34259..89f0ab925c27 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -649,8 +649,7 @@ static enum sci_status scic_io_request_construct_basic_ssp(struct scic_sds_reque
 
 	scic_sds_io_request_build_ssp_command_iu(sci_req);
 
-	sci_base_state_machine_change_state(&sci_req->state_machine,
-					    SCI_BASE_REQUEST_STATE_CONSTRUCTED);
+	sci_change_state(&sci_req->sm, SCI_REQ_CONSTRUCTED);
 
 	return SCI_SUCCESS;
 }
@@ -664,8 +663,7 @@ enum sci_status scic_task_request_construct_ssp(
 	/* Fill in the SSP Task IU */
 	scic_sds_task_request_build_ssp_task_iu(sci_req);
 
-	sci_base_state_machine_change_state(&sci_req->state_machine,
-					    SCI_BASE_REQUEST_STATE_CONSTRUCTED);
+	sci_change_state(&sci_req->sm, SCI_REQ_CONSTRUCTED);
 
 	return SCI_SUCCESS;
 }
@@ -687,8 +685,7 @@ static enum sci_status scic_io_request_construct_basic_sata(struct scic_sds_requ
 						copy);
 
 	if (status == SCI_SUCCESS)
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_CONSTRUCTED);
+		sci_change_state(&sci_req->sm, SCI_REQ_CONSTRUCTED);
 
 	return status;
 }
@@ -718,8 +715,7 @@ enum sci_status scic_task_request_construct_sata(struct scic_sds_request *sci_re
 
 	if (status != SCI_SUCCESS)
 		return status;
-	sci_base_state_machine_change_state(&sci_req->state_machine,
-					    SCI_BASE_REQUEST_STATE_CONSTRUCTED);
+	sci_change_state(&sci_req->sm, SCI_REQ_CONSTRUCTED);
 
 	return status;
 }
@@ -761,8 +757,8 @@ enum sci_status scic_sds_request_start(struct scic_sds_request *sci_req)
 	    scic_sds_remote_device_get_sequence(sci_req->target_device))
 		return SCI_FAILURE;
 
-	state = sci_req->state_machine.current_state_id;
-	if (state != SCI_BASE_REQUEST_STATE_CONSTRUCTED) {
+	state = sci_req->sm.current_state_id;
+	if (state != SCI_REQ_CONSTRUCTED) {
 		dev_warn(scic_to_dev(scic),
 			"%s: SCIC IO Request requested to start while in wrong "
 			 "state %d\n", __func__, state);
@@ -818,8 +814,7 @@ enum sci_status scic_sds_request_start(struct scic_sds_request *sci_req)
 		sci_req->post_context |= scic_sds_io_tag_get_index(sci_req->io_tag);
 
 		/* Everything is good go ahead and change state */
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_STARTED);
+		sci_change_state(&sci_req->sm, SCI_REQ_STARTED);
 
 		return SCI_SUCCESS;
 	}
@@ -832,52 +827,47 @@ scic_sds_io_request_terminate(struct scic_sds_request *sci_req)
 {
 	enum sci_base_request_states state;
 
-	state = sci_req->state_machine.current_state_id;
+	state = sci_req->sm.current_state_id;
 
 	switch (state) {
-	case SCI_BASE_REQUEST_STATE_CONSTRUCTED:
+	case SCI_REQ_CONSTRUCTED:
 		scic_sds_request_set_status(sci_req,
 			SCU_TASK_DONE_TASK_ABORT,
 			SCI_FAILURE_IO_TERMINATED);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		return SCI_SUCCESS;
-	case SCI_BASE_REQUEST_STATE_STARTED:
-	case SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION:
-	case SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE:
-	case SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION:
-	case SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE:
-	case SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE:
-	case SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE:
-	case SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE:
-	case SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE:
-	case SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE:
-	case SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE:
-	case SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE:
-	case SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_ASSERTED_COMPLETION_SUBSTATE:
-	case SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE:
-	case SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE:
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_ABORTING);
+	case SCI_REQ_STARTED:
+	case SCI_REQ_TASK_WAIT_TC_COMP:
+	case SCI_REQ_SMP_WAIT_RESP:
+	case SCI_REQ_SMP_WAIT_TC_COMP:
+	case SCI_REQ_STP_UDMA_WAIT_TC_COMP:
+	case SCI_REQ_STP_UDMA_WAIT_D2H:
+	case SCI_REQ_STP_NON_DATA_WAIT_H2D:
+	case SCI_REQ_STP_NON_DATA_WAIT_D2H:
+	case SCI_REQ_STP_PIO_WAIT_H2D:
+	case SCI_REQ_STP_PIO_WAIT_FRAME:
+	case SCI_REQ_STP_PIO_DATA_IN:
+	case SCI_REQ_STP_PIO_DATA_OUT:
+	case SCI_REQ_STP_SOFT_RESET_WAIT_H2D_ASSERTED:
+	case SCI_REQ_STP_SOFT_RESET_WAIT_H2D_DIAG:
+	case SCI_REQ_STP_SOFT_RESET_WAIT_D2H:
+		sci_change_state(&sci_req->sm, SCI_REQ_ABORTING);
 		return SCI_SUCCESS;
-	case SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE:
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_ABORTING);
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+	case SCI_REQ_TASK_WAIT_TC_RESP:
+		sci_change_state(&sci_req->sm, SCI_REQ_ABORTING);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		return SCI_SUCCESS;
-	case SCI_BASE_REQUEST_STATE_ABORTING:
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+	case SCI_REQ_ABORTING:
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		return SCI_SUCCESS;
-	case SCI_BASE_REQUEST_STATE_COMPLETED:
+	case SCI_REQ_COMPLETED:
 	default:
 		dev_warn(scic_to_dev(sci_req->owning_controller),
 			 "%s: SCIC IO Request requested to abort while in wrong "
 			 "state %d\n",
 			 __func__,
-			 sci_base_state_machine_get_state(&sci_req->state_machine));
+			 sci_req->sm.current_state_id);
 		break;
 	}
 
@@ -889,8 +879,8 @@ enum sci_status scic_sds_request_complete(struct scic_sds_request *sci_req)
 	enum sci_base_request_states state;
 	struct scic_sds_controller *scic = sci_req->owning_controller;
 
-	state = sci_req->state_machine.current_state_id;
-	if (WARN_ONCE(state != SCI_BASE_REQUEST_STATE_COMPLETED,
+	state = sci_req->sm.current_state_id;
+	if (WARN_ONCE(state != SCI_REQ_COMPLETED,
 		      "isci: request completion from wrong state (%d)\n", state))
 		return SCI_FAILURE_INVALID_STATE;
 
@@ -902,8 +892,7 @@ enum sci_status scic_sds_request_complete(struct scic_sds_request *sci_req)
 						  sci_req->saved_rx_frame_index);
 
 	/* XXX can we just stop the machine and remove the 'final' state? */
-	sci_base_state_machine_change_state(&sci_req->state_machine,
-					    SCI_BASE_REQUEST_STATE_FINAL);
+	sci_change_state(&sci_req->sm, SCI_REQ_FINAL);
 	return SCI_SUCCESS;
 }
 
@@ -913,9 +902,9 @@ enum sci_status scic_sds_io_request_event_handler(struct scic_sds_request *sci_r
 	enum sci_base_request_states state;
 	struct scic_sds_controller *scic = sci_req->owning_controller;
 
-	state = sci_req->state_machine.current_state_id;
+	state = sci_req->sm.current_state_id;
 
-	if (state != SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE) {
+	if (state != SCI_REQ_STP_PIO_DATA_IN) {
 		dev_warn(scic_to_dev(scic), "%s: (%x) in wrong state %d\n",
 			 __func__, event_code, state);
 
@@ -927,8 +916,7 @@ enum sci_status scic_sds_io_request_event_handler(struct scic_sds_request *sci_r
 		/* We are waiting for data and the SCU has R_ERR the data frame.
 		 * Go back to waiting for the D2H Register FIS
 		 */
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE);
+		sci_change_state(&sci_req->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
 		return SCI_SUCCESS;
 	default:
 		dev_err(scic_to_dev(scic),
@@ -967,8 +955,9 @@ static void scic_sds_io_request_copy_response(struct scic_sds_request *sci_req)
 	memcpy(resp_buf, ssp_response->resp_data, len);
 }
 
-static enum sci_status request_started_state_tc_event(struct scic_sds_request *sci_req,
-						      u32 completion_code)
+static enum sci_status
+request_started_state_tc_event(struct scic_sds_request *sci_req,
+			       u32 completion_code)
 {
 	struct ssp_response_iu *resp_iu;
 	u8 datapres;
@@ -1110,13 +1099,13 @@ static enum sci_status request_started_state_tc_event(struct scic_sds_request *s
 	 */
 
 	/* In all cases we will treat this as the completion of the IO req. */
-	sci_base_state_machine_change_state(&sci_req->state_machine,
-					    SCI_BASE_REQUEST_STATE_COMPLETED);
+	sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 	return SCI_SUCCESS;
 }
 
-static enum sci_status request_aborting_state_tc_event(struct scic_sds_request *sci_req,
-						       u32 completion_code)
+static enum sci_status
+request_aborting_state_tc_event(struct scic_sds_request *sci_req,
+				u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case (SCU_TASK_DONE_GOOD << SCU_COMPLETION_TL_STATUS_SHIFT):
@@ -1124,8 +1113,7 @@ static enum sci_status request_aborting_state_tc_event(struct scic_sds_request *
 		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_TASK_ABORT,
 					    SCI_FAILURE_IO_TERMINATED);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		break;
 
 	default:
@@ -1146,8 +1134,7 @@ static enum sci_status ssp_task_request_await_tc_event(struct scic_sds_request *
 		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE);
+		sci_change_state(&sci_req->sm, SCI_REQ_TASK_WAIT_TC_RESP);
 		break;
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_ACK_NAK_TO):
 		/* Currently, the decision is to simply allow the task request
@@ -1160,27 +1147,28 @@ static enum sci_status ssp_task_request_await_tc_event(struct scic_sds_request *
 			 "ACK/NAK timeout\n", __func__, sci_req,
 			 completion_code);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE);
+		sci_change_state(&sci_req->sm, SCI_REQ_TASK_WAIT_TC_RESP);
 		break;
 	default:
-		/* All other completion status cause the IO to be complete.  If a NAK
-		 * was received, then it is up to the user to retry the request.
+		/*
+		 * All other completion status cause the IO to be complete.
+		 * If a NAK was received, then it is up to the user to retry
+		 * the request.
 		 */
 		scic_sds_request_set_status(sci_req,
 			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
 	return SCI_SUCCESS;
 }
 
-static enum sci_status smp_request_await_response_tc_event(struct scic_sds_request *sci_req,
-							   u32 completion_code)
+static enum sci_status
+smp_request_await_response_tc_event(struct scic_sds_request *sci_req,
+				    u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
@@ -1191,8 +1179,7 @@ static enum sci_status smp_request_await_response_tc_event(struct scic_sds_reque
 		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		break;
 
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_RESP_TO_ERR):
@@ -1209,8 +1196,7 @@ static enum sci_status smp_request_await_response_tc_event(struct scic_sds_reque
 		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_SMP_RESP_TO_ERR,
 					    SCI_FAILURE_RETRY_REQUIRED);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		break;
 
 	default:
@@ -1221,24 +1207,23 @@ static enum sci_status smp_request_await_response_tc_event(struct scic_sds_reque
 					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
 	return SCI_SUCCESS;
 }
 
-static enum sci_status smp_request_await_tc_event(struct scic_sds_request *sci_req,
-						  u32 completion_code)
+static enum sci_status
+smp_request_await_tc_event(struct scic_sds_request *sci_req,
+			   u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
 		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		break;
 	default:
 		/* All other completion status cause the IO to be
@@ -1249,8 +1234,7 @@ static enum sci_status smp_request_await_tc_event(struct scic_sds_request *sci_r
 					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
@@ -1311,16 +1295,16 @@ static struct scu_sgl_element *scic_sds_stp_request_pio_get_next_sgl(struct scic
 	return current_sgl;
 }
 
-static enum sci_status stp_request_non_data_await_h2d_tc_event(struct scic_sds_request *sci_req,
-							       u32 completion_code)
+static enum sci_status
+stp_request_non_data_await_h2d_tc_event(struct scic_sds_request *sci_req,
+					u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
 		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE);
+		sci_change_state(&sci_req->sm, SCI_REQ_STP_NON_DATA_WAIT_D2H);
 		break;
 
 	default:
@@ -1332,8 +1316,7 @@ static enum sci_status stp_request_non_data_await_h2d_tc_event(struct scic_sds_r
 					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
@@ -1509,17 +1492,19 @@ static enum sci_status scic_sds_stp_request_pio_data_in_copy_data(
 	return status;
 }
 
-static enum sci_status stp_request_pio_await_h2d_completion_tc_event(struct scic_sds_request *sci_req,
-								     u32 completion_code)
+static enum sci_status
+stp_request_pio_await_h2d_completion_tc_event(struct scic_sds_request *sci_req,
+					      u32 completion_code)
 {
 	enum sci_status status = SCI_SUCCESS;
 
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS);
+		scic_sds_request_set_status(sci_req,
+					    SCU_TASK_DONE_GOOD,
+					    SCI_SUCCESS);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE);
+		sci_change_state(&sci_req->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
 		break;
 
 	default:
@@ -1531,16 +1516,16 @@ static enum sci_status stp_request_pio_await_h2d_completion_tc_event(struct scic
 					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
 	return status;
 }
 
-static enum sci_status pio_data_out_tx_done_tc_event(struct scic_sds_request *sci_req,
-						     u32 completion_code)
+static enum sci_status
+pio_data_out_tx_done_tc_event(struct scic_sds_request *sci_req,
+			      u32 completion_code)
 {
 	enum sci_status status = SCI_SUCCESS;
 	bool all_frames_transferred = false;
@@ -1566,28 +1551,24 @@ static enum sci_status pio_data_out_tx_done_tc_event(struct scic_sds_request *sc
 		/* all data transferred. */
 		if (all_frames_transferred) {
 			/*
-			 * Change the state to SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_FRAME_SUBSTATE
+			 * Change the state to SCI_REQ_STP_PIO_DATA_IN
 			 * and wait for PIO_SETUP fis / or D2H REg fis. */
-			sci_base_state_machine_change_state(
-				&sci_req->state_machine,
-				SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE
-				);
+			sci_change_state(&sci_req->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
 		}
 		break;
+
 	default:
 		/*
-		 * All other completion status cause the IO to be complete.  If a NAK
-		 * was received, then it is up to the user to retry the request. */
+		 * All other completion status cause the IO to be complete.
+		 * If a NAK was received, then it is up to the user to retry
+		 * the request.
+		 */
 		scic_sds_request_set_status(
 			sci_req,
 			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
-			);
+			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_base_state_machine_change_state(
-			&sci_req->state_machine,
-			SCI_BASE_REQUEST_STATE_COMPLETED
-			);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
@@ -1600,8 +1581,7 @@ static void scic_sds_stp_request_udma_complete_request(
 	enum sci_status sci_status)
 {
 	scic_sds_request_set_status(request, scu_status, sci_status);
-	sci_base_state_machine_change_state(&request->state_machine,
-		SCI_BASE_REQUEST_STATE_COMPLETED);
+	sci_change_state(&request->sm, SCI_REQ_COMPLETED);
 }
 
 static enum sci_status scic_sds_stp_request_udma_general_frame_handler(struct scic_sds_request *sci_req,
@@ -1632,8 +1612,9 @@ static enum sci_status scic_sds_stp_request_udma_general_frame_handler(struct sc
 	return status;
 }
 
-enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
-						  u32 frame_index)
+enum sci_status
+scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
+				  u32 frame_index)
 {
 	struct scic_sds_controller *scic = sci_req->owning_controller;
 	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
@@ -1641,9 +1622,9 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 	enum sci_status status;
 	ssize_t word_cnt;
 
-	state = sci_req->state_machine.current_state_id;
+	state = sci_req->sm.current_state_id;
 	switch (state)  {
-	case SCI_BASE_REQUEST_STATE_STARTED: {
+	case SCI_REQ_STARTED: {
 		struct ssp_frame_hdr ssp_hdr;
 		void *frame_header;
 
@@ -1684,20 +1665,21 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 		}
 
 		/*
-		 * In any case we are done with this frame buffer return it to the
-		 * controller
+		 * In any case we are done with this frame buffer return it to
+		 * the controller
 		 */
 		scic_sds_controller_release_frame(scic, frame_index);
 
 		return SCI_SUCCESS;
 	}
-	case SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE:
+
+	case SCI_REQ_TASK_WAIT_TC_RESP:
 		scic_sds_io_request_copy_response(sci_req);
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		scic_sds_controller_release_frame(scic,frame_index);
 		return SCI_SUCCESS;
-	case SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE: {
+
+	case SCI_REQ_SMP_WAIT_RESP: {
 		struct smp_resp *rsp_hdr = &sci_req->smp.rsp;
 		void *frame_header;
 
@@ -1725,32 +1707,40 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 			scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
 						    SCI_SUCCESS);
 
-			sci_base_state_machine_change_state(&sci_req->state_machine,
-							    SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION);
+			sci_change_state(&sci_req->sm, SCI_REQ_SMP_WAIT_TC_COMP);
 		} else {
-			/* This was not a response frame why did it get forwarded? */
+			/*
+			 * This was not a response frame why did it get
+			 * forwarded?
+			 */
 			dev_err(scic_to_dev(scic),
-				"%s: SCIC SMP Request 0x%p received unexpected frame "
-				"%d type 0x%02x\n", __func__, sci_req,
-				frame_index, rsp_hdr->frame_type);
+				"%s: SCIC SMP Request 0x%p received unexpected "
+				"frame %d type 0x%02x\n",
+				__func__,
+				sci_req,
+				frame_index,
+				rsp_hdr->frame_type);
 
 			scic_sds_request_set_status(sci_req,
 						    SCU_TASK_DONE_SMP_FRM_TYPE_ERR,
 						    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-			sci_base_state_machine_change_state(&sci_req->state_machine,
-							    SCI_BASE_REQUEST_STATE_COMPLETED);
+			sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		}
 
 		scic_sds_controller_release_frame(scic, frame_index);
 
 		return SCI_SUCCESS;
 	}
-	case SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE:
-		return scic_sds_stp_request_udma_general_frame_handler(sci_req, frame_index);
-	case SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE:
+
+	case SCI_REQ_STP_UDMA_WAIT_TC_COMP:
+		return scic_sds_stp_request_udma_general_frame_handler(sci_req,
+								       frame_index);
+
+	case SCI_REQ_STP_UDMA_WAIT_D2H:
 		/* Use the general frame handler to copy the resposne data */
-		status = scic_sds_stp_request_udma_general_frame_handler(sci_req, frame_index);
+		status = scic_sds_stp_request_udma_general_frame_handler(sci_req,
+									 frame_index);
 
 		if (status != SCI_SUCCESS)
 			return status;
@@ -1758,8 +1748,10 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 		scic_sds_stp_request_udma_complete_request(sci_req,
 							   SCU_TASK_DONE_CHECK_RESPONSE,
 							   SCI_FAILURE_IO_RESPONSE_VALID);
+
 		return SCI_SUCCESS;
-	case SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE: {
+
+	case SCI_REQ_STP_NON_DATA_WAIT_D2H: {
 		struct dev_to_host_fis *frame_header;
 		u32 *frame_buffer;
 
@@ -1769,9 +1761,12 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 
 		if (status != SCI_SUCCESS) {
 			dev_err(scic_to_dev(scic),
-				"%s: SCIC IO Request 0x%p could not get frame header "
-				"for frame index %d, status %x\n",
-				__func__, stp_req, frame_index, status);
+				"%s: SCIC IO Request 0x%p could not get frame "
+				"header for frame index %d, status %x\n",
+				__func__,
+				stp_req,
+				frame_index,
+				status);
 
 			return status;
 		}
@@ -1802,15 +1797,15 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 			break;
 		}
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 
 		/* Frame has been decoded return it to the controller */
 		scic_sds_controller_release_frame(scic, frame_index);
 
 		return status;
 	}
-	case SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE: {
+
+	case SCI_REQ_STP_PIO_WAIT_FRAME: {
 		struct isci_request *ireq = sci_req_to_ireq(sci_req);
 		struct sas_task *task = isci_request_access_task(ireq);
 		struct dev_to_host_fis *frame_header;
@@ -1822,8 +1817,8 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 
 		if (status != SCI_SUCCESS) {
 			dev_err(scic_to_dev(scic),
-				"%s: SCIC IO Request 0x%p could not get frame header "
-				"for frame index %d, status %x\n",
+				"%s: SCIC IO Request 0x%p could not get frame "
+				"header for frame index %d, status %x\n",
 				__func__, stp_req, frame_index, status);
 			return status;
 		}
@@ -1835,9 +1830,10 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 								      frame_index,
 								      (void **)&frame_buffer);
 
-			/* Get the data from the PIO Setup The SCU Hardware returns
-			 * first word in the frame_header and the rest of the data is in
-			 * the frame buffer so we need to back up one dword
+			/* Get the data from the PIO Setup The SCU Hardware
+			 * returns first word in the frame_header and the rest
+			 * of the data is in the frame buffer so we need to
+			 * back up one dword
 			 */
 
 			/* transfer_count: first 16bits in the 4th dword */
@@ -1856,31 +1852,33 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 			 * request was PIO Data-in or Data out
 			 */
 			if (task->data_dir == DMA_FROM_DEVICE) {
-				sci_base_state_machine_change_state(&sci_req->state_machine,
-								    SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE);
+				sci_change_state(&sci_req->sm, SCI_REQ_STP_PIO_DATA_IN);
 			} else if (task->data_dir == DMA_TO_DEVICE) {
 				/* Transmit data */
 				status = scic_sds_stp_request_pio_data_out_transmit_data(sci_req);
 				if (status != SCI_SUCCESS)
 					break;
-				sci_base_state_machine_change_state(&sci_req->state_machine,
-								    SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE);
+				sci_change_state(&sci_req->sm, SCI_REQ_STP_PIO_DATA_OUT);
 			}
 			break;
+
 		case FIS_SETDEVBITS:
-			sci_base_state_machine_change_state(&sci_req->state_machine,
-							    SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE);
+			sci_change_state(&sci_req->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
 			break;
+
 		case FIS_REGD2H:
 			if (frame_header->status & ATA_BUSY) {
-				/* Now why is the drive sending a D2H Register FIS when
-				 * it is still busy?  Do nothing since we are still in
-				 * the right state.
+				/*
+				 * Now why is the drive sending a D2H Register
+				 * FIS when it is still busy?  Do nothing since
+				 * we are still in the right state.
 				 */
 				dev_dbg(scic_to_dev(scic),
 					"%s: SCIC PIO Request 0x%p received "
 					"D2H Register FIS with BSY status "
-					"0x%x\n", __func__, stp_req,
+					"0x%x\n",
+					__func__,
+					stp_req,
 					frame_header->status);
 				break;
 			}
@@ -1897,9 +1895,9 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 						    SCU_TASK_DONE_CHECK_RESPONSE,
 						    SCI_FAILURE_IO_RESPONSE_VALID);
 
-			sci_base_state_machine_change_state(&sci_req->state_machine,
-							    SCI_BASE_REQUEST_STATE_COMPLETED);
+			sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 			break;
+
 		default:
 			/* FIXME: what do we do here? */
 			break;
@@ -1910,7 +1908,8 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 
 		return status;
 	}
-	case SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE: {
+
+	case SCI_REQ_STP_PIO_DATA_IN: {
 		struct dev_to_host_fis *frame_header;
 		struct sata_fis_data *frame_buffer;
 
@@ -1920,9 +1919,12 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 
 		if (status != SCI_SUCCESS) {
 			dev_err(scic_to_dev(scic),
-				"%s: SCIC IO Request 0x%p could not get frame header "
-				"for frame index %d, status %x\n",
-				__func__, stp_req, frame_index, status);
+				"%s: SCIC IO Request 0x%p could not get frame "
+				"header for frame index %d, status %x\n",
+				__func__,
+				stp_req,
+				frame_index,
+				status);
 			return status;
 		}
 
@@ -1930,15 +1932,17 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 			dev_err(scic_to_dev(scic),
 				"%s: SCIC PIO Request 0x%p received frame %d "
 				"with fis type 0x%02x when expecting a data "
-				"fis.\n", __func__, stp_req, frame_index,
+				"fis.\n",
+				__func__,
+				stp_req,
+				frame_index,
 				frame_header->fis_type);
 
 			scic_sds_request_set_status(sci_req,
 						    SCU_TASK_DONE_GOOD,
 						    SCI_FAILURE_IO_REQUIRES_SCSI_ABORT);
 
-			sci_base_state_machine_change_state(&sci_req->state_machine,
-							    SCI_BASE_REQUEST_STATE_COMPLETED);
+			sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 
 			/* Frame is decoded return it to the controller */
 			scic_sds_controller_release_frame(scic, frame_index);
@@ -1972,15 +1976,14 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 						    SCU_TASK_DONE_CHECK_RESPONSE,
 						    SCI_FAILURE_IO_RESPONSE_VALID);
 
-			sci_base_state_machine_change_state(&sci_req->state_machine,
-							    SCI_BASE_REQUEST_STATE_COMPLETED);
+			sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		} else {
-			sci_base_state_machine_change_state(&sci_req->state_machine,
-							    SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE);
+			sci_change_state(&sci_req->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
 		}
 		return status;
 	}
-	case SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE: {
+
+	case SCI_REQ_STP_SOFT_RESET_WAIT_D2H: {
 		struct dev_to_host_fis *frame_header;
 		u32 *frame_buffer;
 
@@ -1989,9 +1992,12 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 								       (void **)&frame_header);
 		if (status != SCI_SUCCESS) {
 			dev_err(scic_to_dev(scic),
-				"%s: SCIC IO Request 0x%p could not get frame header "
-				"for frame index %d, status %x\n",
-				__func__, stp_req, frame_index, status);
+				"%s: SCIC IO Request 0x%p could not get frame "
+				"header for frame index %d, status %x\n",
+				__func__,
+				stp_req,
+				frame_index,
+				status);
 			return status;
 		}
 
@@ -2010,35 +2016,43 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 						    SCU_TASK_DONE_CHECK_RESPONSE,
 						    SCI_FAILURE_IO_RESPONSE_VALID);
 			break;
+
 		default:
 			dev_warn(scic_to_dev(scic),
 				 "%s: IO Request:0x%p Frame Id:%d protocol "
-				 "violation occurred\n", __func__, stp_req,
+				 "violation occurred\n",
+				 __func__,
+				 stp_req,
 				 frame_index);
 
-			scic_sds_request_set_status(sci_req, SCU_TASK_DONE_UNEXP_FIS,
+			scic_sds_request_set_status(sci_req,
+						    SCU_TASK_DONE_UNEXP_FIS,
 						    SCI_FAILURE_PROTOCOL_VIOLATION);
 			break;
 		}
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 
 		/* Frame has been decoded return it to the controller */
 		scic_sds_controller_release_frame(scic, frame_index);
 
 		return status;
 	}
-	case SCI_BASE_REQUEST_STATE_ABORTING:
-		/* TODO: Is it even possible to get an unsolicited frame in the
+	case SCI_REQ_ABORTING:
+		/*
+		 * TODO: Is it even possible to get an unsolicited frame in the
 		 * aborting state?
 		 */
 		scic_sds_controller_release_frame(scic, frame_index);
 		return SCI_SUCCESS;
+
 	default:
 		dev_warn(scic_to_dev(scic),
-			 "%s: SCIC IO Request given unexpected frame %x while in "
-			 "state %d\n", __func__, frame_index, state);
+			 "%s: SCIC IO Request given unexpected frame %x while "
+			 "in state %d\n",
+			 __func__,
+			 frame_index,
+			 state);
 
 		scic_sds_controller_release_frame(scic, frame_index);
 		return SCI_FAILURE_INVALID_STATE;
@@ -2075,8 +2089,7 @@ static enum sci_status stp_request_udma_await_tc_event(struct scic_sds_request *
 			 * the device so we must change state to wait
 			 * for it
 			 */
-			sci_base_state_machine_change_state(&sci_req->state_machine,
-				SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE);
+			sci_change_state(&sci_req->sm, SCI_REQ_STP_UDMA_WAIT_D2H);
 		}
 		break;
 
@@ -2105,45 +2118,45 @@ static enum sci_status stp_request_udma_await_tc_event(struct scic_sds_request *
 	return status;
 }
 
-static enum sci_status stp_request_soft_reset_await_h2d_asserted_tc_event(struct scic_sds_request *sci_req,
-									  u32 completion_code)
+static enum sci_status
+stp_request_soft_reset_await_h2d_asserted_tc_event(struct scic_sds_request *sci_req,
+						   u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
 		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-			SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE);
+		sci_change_state(&sci_req->sm, SCI_REQ_STP_SOFT_RESET_WAIT_H2D_DIAG);
 		break;
 
 	default:
 		/*
-		 * All other completion status cause the IO to be complete.  If a NAK
-		 * was received, then it is up to the user to retry the request. */
+		 * All other completion status cause the IO to be complete.
+		 * If a NAK was received, then it is up to the user to retry
+		 * the request.
+		 */
 		scic_sds_request_set_status(sci_req,
-			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
+					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
+					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
 	return SCI_SUCCESS;
 }
 
-static enum sci_status stp_request_soft_reset_await_h2d_diagnostic_tc_event(
-	struct scic_sds_request *sci_req,
-	u32 completion_code)
+static enum sci_status
+stp_request_soft_reset_await_h2d_diagnostic_tc_event(struct scic_sds_request *sci_req,
+						     u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
 		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-			SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE);
+		sci_change_state(&sci_req->sm, SCI_REQ_STP_SOFT_RESET_WAIT_D2H);
 		break;
 
 	default:
@@ -2155,8 +2168,7 @@ static enum sci_status stp_request_soft_reset_await_h2d_diagnostic_tc_event(
 			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
 			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_change_state(&sci_req->sm, SCI_REQ_COMPLETED);
 		break;
 	}
 
@@ -2164,42 +2176,64 @@ static enum sci_status stp_request_soft_reset_await_h2d_diagnostic_tc_event(
 }
 
 enum sci_status
-scic_sds_io_request_tc_completion(struct scic_sds_request *sci_req, u32 completion_code)
+scic_sds_io_request_tc_completion(struct scic_sds_request *sci_req,
+				  u32 completion_code)
 {
 	enum sci_base_request_states state;
 	struct scic_sds_controller *scic = sci_req->owning_controller;
 
-	state = sci_req->state_machine.current_state_id;
+	state = sci_req->sm.current_state_id;
 
 	switch (state) {
-		case SCI_BASE_REQUEST_STATE_STARTED:
-			return request_started_state_tc_event(sci_req, completion_code);
-		case SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION:
-			return ssp_task_request_await_tc_event(sci_req, completion_code);
-		case SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE:
-			return smp_request_await_response_tc_event(sci_req, completion_code);
-		case SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION:
-			return smp_request_await_tc_event(sci_req, completion_code);
-		case SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE:
-			return stp_request_udma_await_tc_event(sci_req, completion_code);
-		case SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE:
-			return stp_request_non_data_await_h2d_tc_event(sci_req, completion_code);
-		case SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE:
-			return stp_request_pio_await_h2d_completion_tc_event(sci_req, completion_code);
-		case SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE:
-			return pio_data_out_tx_done_tc_event(sci_req, completion_code);
-		case SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_ASSERTED_COMPLETION_SUBSTATE:
-			return stp_request_soft_reset_await_h2d_asserted_tc_event(sci_req, completion_code);
-		case SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE:
-			return stp_request_soft_reset_await_h2d_diagnostic_tc_event(sci_req, completion_code);
-		case SCI_BASE_REQUEST_STATE_ABORTING:
-			return request_aborting_state_tc_event(sci_req, completion_code);
-		default:
-			dev_warn(scic_to_dev(scic),
-				"%s: SCIC IO Request given task completion notification %x "
-				"while in wrong state %d\n", __func__, completion_code,
-				state);
-			return SCI_FAILURE_INVALID_STATE;
+	case SCI_REQ_STARTED:
+		return request_started_state_tc_event(sci_req, completion_code);
+
+	case SCI_REQ_TASK_WAIT_TC_COMP:
+		return ssp_task_request_await_tc_event(sci_req,
+						       completion_code);
+
+	case SCI_REQ_SMP_WAIT_RESP:
+		return smp_request_await_response_tc_event(sci_req,
+							   completion_code);
+
+	case SCI_REQ_SMP_WAIT_TC_COMP:
+		return smp_request_await_tc_event(sci_req, completion_code);
+
+	case SCI_REQ_STP_UDMA_WAIT_TC_COMP:
+		return stp_request_udma_await_tc_event(sci_req,
+						       completion_code);
+
+	case SCI_REQ_STP_NON_DATA_WAIT_H2D:
+		return stp_request_non_data_await_h2d_tc_event(sci_req,
+							       completion_code);
+
+	case SCI_REQ_STP_PIO_WAIT_H2D:
+		return stp_request_pio_await_h2d_completion_tc_event(sci_req,
+								     completion_code);
+
+	case SCI_REQ_STP_PIO_DATA_OUT:
+		return pio_data_out_tx_done_tc_event(sci_req, completion_code);
+
+	case SCI_REQ_STP_SOFT_RESET_WAIT_H2D_ASSERTED:
+		return stp_request_soft_reset_await_h2d_asserted_tc_event(sci_req,
+									  completion_code);
+
+	case SCI_REQ_STP_SOFT_RESET_WAIT_H2D_DIAG:
+		return stp_request_soft_reset_await_h2d_diagnostic_tc_event(sci_req,
+									    completion_code);
+
+	case SCI_REQ_ABORTING:
+		return request_aborting_state_tc_event(sci_req,
+						       completion_code);
+
+	default:
+		dev_warn(scic_to_dev(scic),
+			 "%s: SCIC IO Request given task completion "
+			 "notification %x while in wrong state %d\n",
+			 __func__,
+			 completion_code,
+			 state);
+		return SCI_FAILURE_INVALID_STATE;
 	}
 }
 
@@ -2896,7 +2930,7 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 
 static void scic_sds_request_started_state_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), state_machine);
+	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), sm);
 	struct isci_request *ireq = sci_req_to_ireq(sci_req);
 	struct domain_device *dev = sci_dev_to_domain(sci_req->target_device);
 	struct sas_task *task;
@@ -2910,34 +2944,31 @@ static void scic_sds_request_started_state_enter(struct sci_base_state_machine *
 	 * substates
 	 */
 	if (!task && dev->dev_type == SAS_END_DEV) {
-		sci_base_state_machine_change_state(sm,
-			SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION);
+		sci_change_state(sm, SCI_REQ_TASK_WAIT_TC_COMP);
 	} else if (!task &&
 		   (isci_request_access_tmf(ireq)->tmf_code == isci_tmf_sata_srst_high ||
 		    isci_request_access_tmf(ireq)->tmf_code == isci_tmf_sata_srst_low)) {
-		sci_base_state_machine_change_state(sm,
-			SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_ASSERTED_COMPLETION_SUBSTATE);
+		sci_change_state(sm, SCI_REQ_STP_SOFT_RESET_WAIT_H2D_ASSERTED);
 	} else if (task && task->task_proto == SAS_PROTOCOL_SMP) {
-		sci_base_state_machine_change_state(sm,
-			SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE);
+		sci_change_state(sm, SCI_REQ_SMP_WAIT_RESP);
 	} else if (task && sas_protocol_ata(task->task_proto) &&
 		   !task->ata_task.use_ncq) {
 		u32 state;
 
 		if (task->data_dir == DMA_NONE)
-			 state = SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE;
+			state = SCI_REQ_STP_NON_DATA_WAIT_H2D;
 		else if (task->ata_task.dma_xfer)
-			state = SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE;
+			state = SCI_REQ_STP_UDMA_WAIT_TC_COMP;
 		else /* PIO */
-			state = SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE;
+			state = SCI_REQ_STP_PIO_WAIT_H2D;
 
-		sci_base_state_machine_change_state(sm, state);
+		sci_change_state(sm, state);
 	}
 }
 
 static void scic_sds_request_completed_state_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), state_machine);
+	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), sm);
 	struct scic_sds_controller *scic = sci_req->owning_controller;
 	struct isci_host *ihost = scic_to_ihost(scic);
 	struct isci_request *ireq = sci_req_to_ireq(sci_req);
@@ -2952,7 +2983,7 @@ static void scic_sds_request_completed_state_enter(struct sci_base_state_machine
 
 static void scic_sds_request_aborting_state_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), state_machine);
+	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), sm);
 
 	/* Setting the abort bit in the Task Context is required by the silicon. */
 	sci_req->task_context_buffer->abort = 1;
@@ -2960,7 +2991,7 @@ static void scic_sds_request_aborting_state_enter(struct sci_base_state_machine
 
 static void scic_sds_stp_request_started_non_data_await_h2d_completion_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), state_machine);
+	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), sm);
 
 	scic_sds_remote_device_set_working_request(sci_req->target_device,
 						   sci_req);
@@ -2968,7 +2999,7 @@ static void scic_sds_stp_request_started_non_data_await_h2d_completion_enter(str
 
 static void scic_sds_stp_request_started_pio_await_h2d_completion_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), state_machine);
+	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), sm);
 
 	scic_sds_remote_device_set_working_request(sci_req->target_device,
 						   sci_req);
@@ -2976,7 +3007,7 @@ static void scic_sds_stp_request_started_pio_await_h2d_completion_enter(struct s
 
 static void scic_sds_stp_request_started_soft_reset_await_h2d_asserted_completion_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), state_machine);
+	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), sm);
 
 	scic_sds_remote_device_set_working_request(sci_req->target_device,
 						   sci_req);
@@ -2984,7 +3015,7 @@ static void scic_sds_stp_request_started_soft_reset_await_h2d_asserted_completio
 
 static void scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), state_machine);
+	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), sm);
 	struct scu_task_context *task_context;
 	struct host_to_dev_fis *h2d_fis;
 	enum sci_status status;
@@ -3003,51 +3034,53 @@ static void scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_complet
 }
 
 static const struct sci_base_state scic_sds_request_state_table[] = {
-	[SCI_BASE_REQUEST_STATE_INITIAL] = { },
-	[SCI_BASE_REQUEST_STATE_CONSTRUCTED] = { },
-	[SCI_BASE_REQUEST_STATE_STARTED] = {
+	[SCI_REQ_INIT] = { },
+	[SCI_REQ_CONSTRUCTED] = { },
+	[SCI_REQ_STARTED] = {
 		.enter_state = scic_sds_request_started_state_enter,
 	},
-	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE] = {
+	[SCI_REQ_STP_NON_DATA_WAIT_H2D] = {
 		.enter_state = scic_sds_stp_request_started_non_data_await_h2d_completion_enter,
 	},
-	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE] = {
+	[SCI_REQ_STP_NON_DATA_WAIT_D2H] = { },
+	[SCI_REQ_STP_PIO_WAIT_H2D] = {
 		.enter_state = scic_sds_stp_request_started_pio_await_h2d_completion_enter,
 	},
-	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_ASSERTED_COMPLETION_SUBSTATE] = {
+	[SCI_REQ_STP_PIO_WAIT_FRAME] = { },
+	[SCI_REQ_STP_PIO_DATA_IN] = { },
+	[SCI_REQ_STP_PIO_DATA_OUT] = { },
+	[SCI_REQ_STP_UDMA_WAIT_TC_COMP] = { },
+	[SCI_REQ_STP_UDMA_WAIT_D2H] = { },
+	[SCI_REQ_STP_SOFT_RESET_WAIT_H2D_ASSERTED] = {
 		.enter_state = scic_sds_stp_request_started_soft_reset_await_h2d_asserted_completion_enter,
 	},
-	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE] = {
+	[SCI_REQ_STP_SOFT_RESET_WAIT_H2D_DIAG] = {
 		.enter_state = scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter,
 	},
-	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE] = { },
-	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION] = { },
-	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE] = { },
-	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE] = { },
-	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION] = { },
-	[SCI_BASE_REQUEST_STATE_COMPLETED] = {
+	[SCI_REQ_STP_SOFT_RESET_WAIT_D2H] = { },
+	[SCI_REQ_TASK_WAIT_TC_COMP] = { },
+	[SCI_REQ_TASK_WAIT_TC_RESP] = { },
+	[SCI_REQ_SMP_WAIT_RESP] = { },
+	[SCI_REQ_SMP_WAIT_TC_COMP] = { },
+	[SCI_REQ_COMPLETED] = {
 		.enter_state = scic_sds_request_completed_state_enter,
 	},
-	[SCI_BASE_REQUEST_STATE_ABORTING] = {
+	[SCI_REQ_ABORTING] = {
 		.enter_state = scic_sds_request_aborting_state_enter,
 	},
-	[SCI_BASE_REQUEST_STATE_FINAL] = { },
+	[SCI_REQ_FINAL] = { },
 };
 
-static void scic_sds_general_request_construct(struct scic_sds_controller *scic,
-					       struct scic_sds_remote_device *sci_dev,
-					       u16 io_tag, struct scic_sds_request *sci_req)
+static void
+scic_sds_general_request_construct(struct scic_sds_controller *scic,
+				   struct scic_sds_remote_device *sci_dev,
+				   u16 io_tag,
+				   struct scic_sds_request *sci_req)
 {
-	sci_base_state_machine_construct(&sci_req->state_machine,
+	sci_base_state_machine_construct(&sci_req->sm,
 					 scic_sds_request_state_table,
-					 SCI_BASE_REQUEST_STATE_INITIAL);
-	sci_base_state_machine_start(&sci_req->state_machine);
+					 SCI_REQ_INIT);
+	sci_base_state_machine_start(&sci_req->sm);
 
 	sci_req->io_tag = io_tag;
 	sci_req->owning_controller = scic;
@@ -3322,8 +3355,7 @@ scic_io_request_construct_smp(struct scic_sds_request *sci_req)
 
 	scu_smp_request_construct_task_context(sci_req, smp_req->req_len);
 
-	sci_base_state_machine_change_state(&sci_req->state_machine,
-					    SCI_BASE_REQUEST_STATE_CONSTRUCTED);
+	sci_change_state(&sci_req->sm, SCI_REQ_CONSTRUCTED);
 
 	return SCI_SUCCESS;
 }

commit 8d2c65c09c9e0adc16070562e7944c1c3277f332
Author: Dave Jiang <dave.jiang@intel.com>
Date:   Wed Jun 1 09:03:08 2011 +0000

    isci: Removing unused variables compiler warnings
    
    Newer gcc's are better at identifying "set, but not used" variables.
    
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 7c0928ed9e63..31c9b2c34259 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -211,11 +211,9 @@ static void scu_ssp_reqeust_construct_task_context(
 	struct scu_task_context *task_context)
 {
 	dma_addr_t dma_addr;
-	struct scic_sds_controller *controller;
 	struct scic_sds_remote_device *target_device;
 	struct scic_sds_port *target_port;
 
-	controller = scic_sds_request_get_controller(sds_request);
 	target_device = scic_sds_request_get_device(sds_request);
 	target_port = scic_sds_request_get_port(sds_request);
 
@@ -384,11 +382,9 @@ static void scu_sata_reqeust_construct_task_context(
 	struct scu_task_context *task_context)
 {
 	dma_addr_t dma_addr;
-	struct scic_sds_controller *controller;
 	struct scic_sds_remote_device *target_device;
 	struct scic_sds_port *target_port;
 
-	controller = scic_sds_request_get_controller(sci_req);
 	target_device = scic_sds_request_get_device(sci_req);
 	target_port = scic_sds_request_get_port(sci_req);
 
@@ -677,12 +673,10 @@ enum sci_status scic_task_request_construct_ssp(
 static enum sci_status scic_io_request_construct_basic_sata(struct scic_sds_request *sci_req)
 {
 	enum sci_status status;
-	struct scic_sds_stp_request *stp_req;
 	bool copy = false;
 	struct isci_request *isci_request = sci_req_to_ireq(sci_req);
 	struct sas_task *task = isci_request_access_task(isci_request);
 
-	stp_req = &sci_req->stp.req;
 	sci_req->protocol = SCIC_STP_PROTOCOL;
 
 	copy = (task->data_dir == DMA_NONE) ? false : true;
@@ -3190,7 +3184,6 @@ scu_smp_request_construct_task_context(struct scic_sds_request *sci_req,
 				       ssize_t req_len)
 {
 	dma_addr_t dma_addr;
-	struct scic_sds_controller *scic;
 	struct scic_sds_remote_device *sci_dev;
 	struct scic_sds_port *sci_port;
 	struct scu_task_context *task_context;
@@ -3202,7 +3195,6 @@ scu_smp_request_construct_task_context(struct scic_sds_request *sci_req,
 
 	task_context = scic_sds_request_get_task_context(sci_req);
 
-	scic = scic_sds_request_get_controller(sci_req);
 	sci_dev = scic_sds_request_get_device(sci_req);
 	sci_port = scic_sds_request_get_port(sci_req);
 

commit 77d67385f7b4a630912fd567f104946be137f477
Author: Dave Jiang <dave.jiang@intel.com>
Date:   Wed May 25 02:21:57 2011 +0000

    isci: removing the kmalloc in smp request construct
    
    It doesn't look like there is any reason to do a kmalloc. We can do the
    byte swap in place and avoid the allocation. This allow us to remove
    a kmalloc and a memcpy.
    
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 063ef04080d5..7c0928ed9e63 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -3187,7 +3187,7 @@ static enum sci_status isci_request_stp_request_construct(
  */
 static void
 scu_smp_request_construct_task_context(struct scic_sds_request *sci_req,
-				       struct smp_req *smp_req)
+				       ssize_t req_len)
 {
 	dma_addr_t dma_addr;
 	struct scic_sds_controller *scic;
@@ -3197,7 +3197,7 @@ scu_smp_request_construct_task_context(struct scic_sds_request *sci_req,
 	ssize_t word_cnt = sizeof(struct smp_req) / sizeof(u32);
 
 	/* byte swap the smp request. */
-	sci_swab32_cpy(&sci_req->smp.cmd, smp_req,
+	sci_swab32_cpy(&sci_req->smp.cmd, &sci_req->smp.cmd,
 		       word_cnt);
 
 	task_context = scic_sds_request_get_task_context(sci_req);
@@ -3238,7 +3238,7 @@ scu_smp_request_construct_task_context(struct scic_sds_request *sci_req,
 	task_context->address_modifier = 0;
 
 	/* 10h */
-	task_context->ssp_command_iu_length = smp_req->req_len;
+	task_context->ssp_command_iu_length = req_len;
 
 	/* 14h */
 	task_context->transfer_length_bytes = 0;
@@ -3299,22 +3299,18 @@ scu_smp_request_construct_task_context(struct scic_sds_request *sci_req,
 	task_context->response_iu_lower = 0;
 }
 
-static enum sci_status scic_io_request_construct_smp(struct scic_sds_request *sci_req)
+static enum sci_status
+scic_io_request_construct_smp(struct scic_sds_request *sci_req)
 {
-	struct smp_req *smp_req = kmalloc(sizeof(*smp_req), GFP_KERNEL);
-
-	if (!smp_req)
-		return SCI_FAILURE_INSUFFICIENT_RESOURCES;
+	struct smp_req *smp_req = &sci_req->smp.cmd;
 
 	sci_req->protocol = SCIC_SMP_PROTOCOL;
 
-	/* Construct the SMP SCU Task Context */
-	memcpy(smp_req, &sci_req->smp.cmd, sizeof(*smp_req));
-
 	/*
 	 * Look at the SMP requests' header fields; for certain SAS 1.x SMP
 	 * functions under SAS 2.0, a zero request length really indicates
-	 * a non-zero default length. */
+	 * a non-zero default length.
+	 */
 	if (smp_req->req_len == 0) {
 		switch (smp_req->func) {
 		case SMP_DISCOVER:
@@ -3332,12 +3328,10 @@ static enum sci_status scic_io_request_construct_smp(struct scic_sds_request *sc
 		}
 	}
 
-	scu_smp_request_construct_task_context(sci_req, smp_req);
+	scu_smp_request_construct_task_context(sci_req, smp_req->req_len);
 
 	sci_base_state_machine_change_state(&sci_req->state_machine,
-		SCI_BASE_REQUEST_STATE_CONSTRUCTED);
-
-	kfree(smp_req);
+					    SCI_BASE_REQUEST_STATE_CONSTRUCTED);
 
 	return SCI_SUCCESS;
 }

commit 9269e0e898594c65dee6b20d4ed48e33dbbd4eeb
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu May 12 07:42:17 2011 -0700

    isci: add some type safety to the state machine interface
    
    Now that any given object type only has one state_machine we can use
    container_of() to get back to the given state machine owner.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index c63064ede38d..063ef04080d5 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -2900,10 +2900,9 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 	isci_host_can_dequeue(isci_host, 1);
 }
 
-static void scic_sds_request_started_state_enter(void *object)
+static void scic_sds_request_started_state_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = object;
-	struct sci_base_state_machine *sm = &sci_req->state_machine;
+	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), state_machine);
 	struct isci_request *ireq = sci_req_to_ireq(sci_req);
 	struct domain_device *dev = sci_dev_to_domain(sci_req->target_device);
 	struct sas_task *task;
@@ -2942,9 +2941,9 @@ static void scic_sds_request_started_state_enter(void *object)
 	}
 }
 
-static void scic_sds_request_completed_state_enter(void *object)
+static void scic_sds_request_completed_state_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = object;
+	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), state_machine);
 	struct scic_sds_controller *scic = sci_req->owning_controller;
 	struct isci_host *ihost = scic_to_ihost(scic);
 	struct isci_request *ireq = sci_req_to_ireq(sci_req);
@@ -2957,42 +2956,41 @@ static void scic_sds_request_completed_state_enter(void *object)
 		isci_task_request_complete(ihost, ireq, sci_req->sci_status);
 }
 
-static void scic_sds_request_aborting_state_enter(void *object)
+static void scic_sds_request_aborting_state_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = object;
+	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), state_machine);
 
 	/* Setting the abort bit in the Task Context is required by the silicon. */
 	sci_req->task_context_buffer->abort = 1;
 }
 
-static void scic_sds_stp_request_started_non_data_await_h2d_completion_enter(
-	void *object)
+static void scic_sds_stp_request_started_non_data_await_h2d_completion_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = object;
+	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), state_machine);
 
 	scic_sds_remote_device_set_working_request(sci_req->target_device,
 						   sci_req);
 }
 
-static void scic_sds_stp_request_started_pio_await_h2d_completion_enter(void *object)
+static void scic_sds_stp_request_started_pio_await_h2d_completion_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = object;
+	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), state_machine);
 
 	scic_sds_remote_device_set_working_request(sci_req->target_device,
 						   sci_req);
 }
 
-static void scic_sds_stp_request_started_soft_reset_await_h2d_asserted_completion_enter(void *object)
+static void scic_sds_stp_request_started_soft_reset_await_h2d_asserted_completion_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = object;
+	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), state_machine);
 
 	scic_sds_remote_device_set_working_request(sci_req->target_device,
 						   sci_req);
 }
 
-static void scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter(void *object)
+static void scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter(struct sci_base_state_machine *sm)
 {
-	struct scic_sds_request *sci_req = object;
+	struct scic_sds_request *sci_req = container_of(sm, typeof(*sci_req), state_machine);
 	struct scu_task_context *task_context;
 	struct host_to_dev_fis *h2d_fis;
 	enum sci_status status;
@@ -3052,8 +3050,9 @@ static void scic_sds_general_request_construct(struct scic_sds_controller *scic,
 					       struct scic_sds_remote_device *sci_dev,
 					       u16 io_tag, struct scic_sds_request *sci_req)
 {
-	sci_base_state_machine_construct(&sci_req->state_machine, sci_req,
-			scic_sds_request_state_table, SCI_BASE_REQUEST_STATE_INITIAL);
+	sci_base_state_machine_construct(&sci_req->state_machine,
+					 scic_sds_request_state_table,
+					 SCI_BASE_REQUEST_STATE_INITIAL);
 	sci_base_state_machine_start(&sci_req->state_machine);
 
 	sci_req->io_tag = io_tag;

commit 79e2b6b27699c916e3c7cda18a26d47fea6017fb
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed May 11 08:29:56 2011 -0700

    isci: remove the completion and event state handlers
    
    With these handlers gone the rest of the state handler infrastructure is
    removed.
    
    Added some WARN_ONCEs where previously we would cause NULL pointer
    dereferences or silently run handlers from a previous state.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index cb13b78d8026..c63064ede38d 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -890,21 +890,62 @@ scic_sds_io_request_terminate(struct scic_sds_request *sci_req)
 	return SCI_FAILURE_INVALID_STATE;
 }
 
-enum sci_status scic_sds_io_request_event_handler(
-	struct scic_sds_request *request,
-	u32 event_code)
+enum sci_status scic_sds_request_complete(struct scic_sds_request *sci_req)
 {
-	if (request->state_handlers->event_handler)
-		return request->state_handlers->event_handler(request, event_code);
+	enum sci_base_request_states state;
+	struct scic_sds_controller *scic = sci_req->owning_controller;
+
+	state = sci_req->state_machine.current_state_id;
+	if (WARN_ONCE(state != SCI_BASE_REQUEST_STATE_COMPLETED,
+		      "isci: request completion from wrong state (%d)\n", state))
+		return SCI_FAILURE_INVALID_STATE;
 
-	dev_warn(scic_to_dev(request->owning_controller),
-		 "%s: SCIC IO Request given event code notification %x while "
-		 "in wrong state %d\n",
-		 __func__,
-		 event_code,
-		 sci_base_state_machine_get_state(&request->state_machine));
+	if (!sci_req->was_tag_assigned_by_user)
+		scic_controller_free_io_tag(scic, sci_req->io_tag);
 
-	return SCI_FAILURE_INVALID_STATE;
+	if (sci_req->saved_rx_frame_index != SCU_INVALID_FRAME_INDEX)
+		scic_sds_controller_release_frame(scic,
+						  sci_req->saved_rx_frame_index);
+
+	/* XXX can we just stop the machine and remove the 'final' state? */
+	sci_base_state_machine_change_state(&sci_req->state_machine,
+					    SCI_BASE_REQUEST_STATE_FINAL);
+	return SCI_SUCCESS;
+}
+
+enum sci_status scic_sds_io_request_event_handler(struct scic_sds_request *sci_req,
+						  u32 event_code)
+{
+	enum sci_base_request_states state;
+	struct scic_sds_controller *scic = sci_req->owning_controller;
+
+	state = sci_req->state_machine.current_state_id;
+
+	if (state != SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE) {
+		dev_warn(scic_to_dev(scic), "%s: (%x) in wrong state %d\n",
+			 __func__, event_code, state);
+
+		return SCI_FAILURE_INVALID_STATE;
+	}
+
+	switch (scu_get_event_specifier(event_code)) {
+	case SCU_TASK_DONE_CRC_ERR << SCU_EVENT_SPECIFIC_CODE_SHIFT:
+		/* We are waiting for data and the SCU has R_ERR the data frame.
+		 * Go back to waiting for the D2H Register FIS
+		 */
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE);
+		return SCI_SUCCESS;
+	default:
+		dev_err(scic_to_dev(scic),
+			"%s: pio request unexpected event %#x\n",
+			__func__, event_code);
+
+		/* TODO Should we fail the PIO request when we get an
+		 * unexpected event?
+		 */
+		return SCI_FAILURE;
+	}
 }
 
 /*
@@ -1080,34 +1121,8 @@ static enum sci_status request_started_state_tc_event(struct scic_sds_request *s
 	return SCI_SUCCESS;
 }
 
-/*
- * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
- * object receives a scic_sds_request_complete() request. This method frees up
- * any io request resources that have been allocated and transitions the
- * request to its final state. Consider stopping the state machine instead of
- * transitioning to the final state? enum sci_status SCI_SUCCESS
- */
-static enum sci_status scic_sds_request_completed_state_complete_handler(
-	struct scic_sds_request *request)
-{
-	if (request->was_tag_assigned_by_user != true) {
-		scic_controller_free_io_tag(
-			request->owning_controller, request->io_tag);
-	}
-
-	if (request->saved_rx_frame_index != SCU_INVALID_FRAME_INDEX) {
-		scic_sds_controller_release_frame(
-			request->owning_controller, request->saved_rx_frame_index);
-	}
-
-	sci_base_state_machine_change_state(&request->state_machine,
-					    SCI_BASE_REQUEST_STATE_FINAL);
-	return SCI_SUCCESS;
-}
-
-static enum sci_status request_aborting_state_tc_event(
-	struct scic_sds_request *sci_req,
-	u32 completion_code)
+static enum sci_status request_aborting_state_tc_event(struct scic_sds_request *sci_req,
+						       u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case (SCU_TASK_DONE_GOOD << SCU_COMPLETION_TL_STATUS_SHIFT):
@@ -1585,48 +1600,6 @@ static enum sci_status pio_data_out_tx_done_tc_event(struct scic_sds_request *sc
 	return status;
 }
 
-/**
- *
- * @request: This is the request which is receiving the event.
- * @event_code: This is the event code that the request on which the request is
- *    expected to take action.
- *
- * This method will handle any link layer events while waiting for the data
- * frame. enum sci_status SCI_SUCCESS SCI_FAILURE
- */
-static enum sci_status scic_sds_stp_request_pio_data_in_await_data_event_handler(
-	struct scic_sds_request *request,
-	u32 event_code)
-{
-	enum sci_status status;
-
-	switch (scu_get_event_specifier(event_code)) {
-	case SCU_TASK_DONE_CRC_ERR << SCU_EVENT_SPECIFIC_CODE_SHIFT:
-		/*
-		 * We are waiting for data and the SCU has R_ERR the data frame.
-		 * Go back to waiting for the D2H Register FIS */
-		sci_base_state_machine_change_state(
-			&request->state_machine,
-			SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE
-			);
-
-		status = SCI_SUCCESS;
-		break;
-
-	default:
-		dev_err(scic_to_dev(request->owning_controller),
-			"%s: SCIC PIO Request 0x%p received unexpected "
-			"event 0x%08x\n",
-			__func__, request, event_code);
-
-		/* / @todo Should we fail the PIO request when we get an unexpected event? */
-		status = SCI_FAILURE;
-		break;
-	}
-
-	return status;
-}
-
 static void scic_sds_stp_request_udma_complete_request(
 	struct scic_sds_request *request,
 	u32 scu_status,
@@ -2236,37 +2209,6 @@ scic_sds_io_request_tc_completion(struct scic_sds_request *sci_req, u32 completi
 	}
 }
 
-
-
-static const struct scic_sds_io_request_state_handler scic_sds_request_state_handler_table[] = {
-	[SCI_BASE_REQUEST_STATE_INITIAL] = {},
-	[SCI_BASE_REQUEST_STATE_CONSTRUCTED] = {},
-	[SCI_BASE_REQUEST_STATE_STARTED] = { },
-	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION] = { },
-	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE] = { },
-	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE] = { },
-	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE] = {
-		.event_handler		= scic_sds_stp_request_pio_data_in_await_data_event_handler,
-	},
-	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_ASSERTED_COMPLETION_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE] = { },
-	[SCI_BASE_REQUEST_STATE_COMPLETED] = {
-		.complete_handler	= scic_sds_request_completed_state_complete_handler,
-	},
-	[SCI_BASE_REQUEST_STATE_ABORTING] = { },
-	[SCI_BASE_REQUEST_STATE_FINAL] = { },
-};
-
-
 /**
  * isci_request_process_response_iu() - This function sets the status and
  *    response iu, in the task struct, from the request object for the upper
@@ -2958,46 +2900,6 @@ static void isci_request_io_request_complete(struct isci_host *isci_host,
 	isci_host_can_dequeue(isci_host, 1);
 }
 
-/**
- * scic_sds_request_initial_state_enter() -
- * @object: This parameter specifies the base object for which the state
- *    transition is occurring.
- *
- * This method implements the actions taken when entering the
- * SCI_BASE_REQUEST_STATE_INITIAL state. This state is entered when the initial
- * base request is constructed. Entry into the initial state sets all handlers
- * for the io request object to their default handlers. none
- */
-static void scic_sds_request_initial_state_enter(void *object)
-{
-	struct scic_sds_request *sci_req = object;
-
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCI_BASE_REQUEST_STATE_INITIAL
-		);
-}
-
-/**
- * scic_sds_request_constructed_state_enter() -
- * @object: The io request object that is to enter the constructed state.
- *
- * This method implements the actions taken when entering the
- * SCI_BASE_REQUEST_STATE_CONSTRUCTED state. The method sets the state handlers
- * for the the constructed state. none
- */
-static void scic_sds_request_constructed_state_enter(void *object)
-{
-	struct scic_sds_request *sci_req = object;
-
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCI_BASE_REQUEST_STATE_CONSTRUCTED
-		);
-}
-
 static void scic_sds_request_started_state_enter(void *object)
 {
 	struct scic_sds_request *sci_req = object;
@@ -3011,12 +2913,6 @@ static void scic_sds_request_started_state_enter(void *object)
 	 */
 	task = ireq->ttype == io_task ? isci_request_access_task(ireq) : NULL;
 
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCI_BASE_REQUEST_STATE_STARTED
-		);
-
 	/* all unaccelerated request types (non ssp or ncq) handled with
 	 * substates
 	 */
@@ -3046,30 +2942,13 @@ static void scic_sds_request_started_state_enter(void *object)
 	}
 }
 
-/**
- * scic_sds_request_completed_state_enter() -
- * @object: This parameter specifies the base object for which the state
- *    transition is occurring.  This object is cast into a SCIC_SDS_IO_REQUEST
- *    object.
- *
- * This method implements the actions taken when entering the
- * SCI_BASE_REQUEST_STATE_COMPLETED state.  This state is entered when the
- * SCIC_SDS_IO_REQUEST has completed.  The method will decode the request
- * completion status and convert it to an enum sci_status to return in the
- * completion callback function. none
- */
 static void scic_sds_request_completed_state_enter(void *object)
 {
 	struct scic_sds_request *sci_req = object;
-	struct scic_sds_controller *scic =
-		scic_sds_request_get_controller(sci_req);
+	struct scic_sds_controller *scic = sci_req->owning_controller;
 	struct isci_host *ihost = scic_to_ihost(scic);
 	struct isci_request *ireq = sci_req_to_ireq(sci_req);
 
-	SET_STATE_HANDLER(sci_req,
-			  scic_sds_request_state_handler_table,
-			  SCI_BASE_REQUEST_STATE_COMPLETED);
-
 	/* Tell the SCI_USER that the IO request is complete */
 	if (sci_req->is_task_management_request == false)
 		isci_request_io_request_complete(ihost, ireq,
@@ -3078,93 +2957,12 @@ static void scic_sds_request_completed_state_enter(void *object)
 		isci_task_request_complete(ihost, ireq, sci_req->sci_status);
 }
 
-/**
- * scic_sds_request_aborting_state_enter() -
- * @object: This parameter specifies the base object for which the state
- *    transition is occurring.  This object is cast into a SCIC_SDS_IO_REQUEST
- *    object.
- *
- * This method implements the actions taken when entering the
- * SCI_BASE_REQUEST_STATE_ABORTING state. none
- */
 static void scic_sds_request_aborting_state_enter(void *object)
 {
 	struct scic_sds_request *sci_req = object;
 
 	/* Setting the abort bit in the Task Context is required by the silicon. */
 	sci_req->task_context_buffer->abort = 1;
-
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCI_BASE_REQUEST_STATE_ABORTING
-		);
-}
-
-/**
- * scic_sds_request_final_state_enter() -
- * @object: This parameter specifies the base object for which the state
- *    transition is occurring.  This is cast into a SCIC_SDS_IO_REQUEST object.
- *
- * This method implements the actions taken when entering the
- * SCI_BASE_REQUEST_STATE_FINAL state. The only action required is to put the
- * state handlers in place. none
- */
-static void scic_sds_request_final_state_enter(void *object)
-{
-	struct scic_sds_request *sci_req = object;
-
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCI_BASE_REQUEST_STATE_FINAL
-		);
-}
-
-static void scic_sds_io_request_started_task_mgmt_await_tc_completion_substate_enter(
-	void *object)
-{
-	struct scic_sds_request *sci_req = object;
-
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION
-		);
-}
-
-static void scic_sds_io_request_started_task_mgmt_await_task_response_substate_enter(
-	void *object)
-{
-	struct scic_sds_request *sci_req = object;
-
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE
-		);
-}
-
-static void scic_sds_smp_request_started_await_response_substate_enter(void *object)
-{
-	struct scic_sds_request *sci_req = object;
-
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE
-		);
-}
-
-static void scic_sds_smp_request_started_await_tc_completion_substate_enter(void *object)
-{
-	struct scic_sds_request *sci_req = object;
-
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION
-		);
 }
 
 static void scic_sds_stp_request_started_non_data_await_h2d_completion_enter(
@@ -3172,133 +2970,27 @@ static void scic_sds_stp_request_started_non_data_await_h2d_completion_enter(
 {
 	struct scic_sds_request *sci_req = object;
 
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE
-		);
-
-	scic_sds_remote_device_set_working_request(
-		sci_req->target_device, sci_req
-		);
-}
-
-static void scic_sds_stp_request_started_non_data_await_d2h_enter(void *object)
-{
-	struct scic_sds_request *sci_req = object;
-
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE
-		);
-}
-
-
-
-static void scic_sds_stp_request_started_pio_await_h2d_completion_enter(
-	void *object)
-{
-	struct scic_sds_request *sci_req = object;
-
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE
-		);
-
-	scic_sds_remote_device_set_working_request(
-		sci_req->target_device, sci_req);
-}
-
-static void scic_sds_stp_request_started_pio_await_frame_enter(void *object)
-{
-	struct scic_sds_request *sci_req = object;
-
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE
-		);
+	scic_sds_remote_device_set_working_request(sci_req->target_device,
+						   sci_req);
 }
 
-static void scic_sds_stp_request_started_pio_data_in_await_data_enter(
-	void *object)
+static void scic_sds_stp_request_started_pio_await_h2d_completion_enter(void *object)
 {
 	struct scic_sds_request *sci_req = object;
 
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE
-		);
+	scic_sds_remote_device_set_working_request(sci_req->target_device,
+						   sci_req);
 }
 
-static void scic_sds_stp_request_started_pio_data_out_transmit_data_enter(
-	void *object)
+static void scic_sds_stp_request_started_soft_reset_await_h2d_asserted_completion_enter(void *object)
 {
 	struct scic_sds_request *sci_req = object;
 
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE
-		);
+	scic_sds_remote_device_set_working_request(sci_req->target_device,
+						   sci_req);
 }
 
-
-
-static void scic_sds_stp_request_started_udma_await_tc_completion_enter(
-	void *object)
-{
-	struct scic_sds_request *sci_req = object;
-
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE
-		);
-}
-
-/**
- *
- *
- * This state is entered when there is an TC completion failure.  The hardware
- * received an unexpected condition while processing the IO request and now
- * will UF the D2H register FIS to complete the IO.
- */
-static void scic_sds_stp_request_started_udma_await_d2h_reg_fis_enter(
-	void *object)
-{
-	struct scic_sds_request *sci_req = object;
-
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE
-		);
-}
-
-
-
-static void scic_sds_stp_request_started_soft_reset_await_h2d_asserted_completion_enter(
-	void *object)
-{
-	struct scic_sds_request *sci_req = object;
-
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_ASSERTED_COMPLETION_SUBSTATE
-		);
-
-	scic_sds_remote_device_set_working_request(
-		sci_req->target_device, sci_req
-		);
-}
-
-static void scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter(
-	void *object)
+static void scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter(void *object)
 {
 	struct scic_sds_request *sci_req = object;
 	struct scu_task_context *task_context;
@@ -3315,91 +3007,45 @@ static void scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_complet
 	task_context->control_frame = 0;
 
 	status = scic_controller_continue_io(sci_req);
-	if (status == SCI_SUCCESS) {
-		SET_STATE_HANDLER(
-			sci_req,
-			scic_sds_request_state_handler_table,
-			SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE
-			);
-	}
-}
-
-static void scic_sds_stp_request_started_soft_reset_await_d2h_response_enter(
-	void *object)
-{
-	struct scic_sds_request *sci_req = object;
-
-	SET_STATE_HANDLER(
-		sci_req,
-		scic_sds_request_state_handler_table,
-		SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE
-		);
+	WARN_ONCE(status != SCI_SUCCESS, "isci: continue io failure\n");
 }
 
 static const struct sci_base_state scic_sds_request_state_table[] = {
-	[SCI_BASE_REQUEST_STATE_INITIAL] = {
-		.enter_state = scic_sds_request_initial_state_enter,
-	},
-	[SCI_BASE_REQUEST_STATE_CONSTRUCTED] = {
-		.enter_state = scic_sds_request_constructed_state_enter,
-	},
+	[SCI_BASE_REQUEST_STATE_INITIAL] = { },
+	[SCI_BASE_REQUEST_STATE_CONSTRUCTED] = { },
 	[SCI_BASE_REQUEST_STATE_STARTED] = {
 		.enter_state = scic_sds_request_started_state_enter,
 	},
 	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE] = {
 		.enter_state = scic_sds_stp_request_started_non_data_await_h2d_completion_enter,
 	},
-	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE] = {
-		.enter_state = scic_sds_stp_request_started_non_data_await_d2h_enter,
-	},
+	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE] = { },
 	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE] = {
 		.enter_state = scic_sds_stp_request_started_pio_await_h2d_completion_enter,
 	},
-	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE] = {
-		.enter_state = scic_sds_stp_request_started_pio_await_frame_enter,
-	},
-	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE] = {
-		.enter_state = scic_sds_stp_request_started_pio_data_in_await_data_enter,
-	},
-	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE] = {
-		.enter_state = scic_sds_stp_request_started_pio_data_out_transmit_data_enter,
-	},
-	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE] = {
-		.enter_state = scic_sds_stp_request_started_udma_await_tc_completion_enter,
-	},
-	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE] = {
-		.enter_state = scic_sds_stp_request_started_udma_await_d2h_reg_fis_enter,
-	},
+	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE] = { },
+	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE] = { },
+	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE] = { },
+	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE] = { },
+	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE] = { },
 	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_ASSERTED_COMPLETION_SUBSTATE] = {
 		.enter_state = scic_sds_stp_request_started_soft_reset_await_h2d_asserted_completion_enter,
 	},
 	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE] = {
 		.enter_state = scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter,
 	},
-	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE] = {
-		.enter_state = scic_sds_stp_request_started_soft_reset_await_d2h_response_enter,
-	},
-	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION] = {
-		.enter_state = scic_sds_io_request_started_task_mgmt_await_tc_completion_substate_enter,
-	},
-	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE] = {
-		.enter_state = scic_sds_io_request_started_task_mgmt_await_task_response_substate_enter,
-	},
-	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE] = {
-		.enter_state = scic_sds_smp_request_started_await_response_substate_enter,
-	},
-	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION] = {
-		.enter_state = scic_sds_smp_request_started_await_tc_completion_substate_enter,
-	},
+	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE] = { },
+	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION] = { },
+	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE] = { },
+	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE] = { },
+	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION] = { },
 	[SCI_BASE_REQUEST_STATE_COMPLETED] = {
 		.enter_state = scic_sds_request_completed_state_enter,
 	},
 	[SCI_BASE_REQUEST_STATE_ABORTING] = {
 		.enter_state = scic_sds_request_aborting_state_enter,
 	},
-	[SCI_BASE_REQUEST_STATE_FINAL] = {
-		.enter_state = scic_sds_request_final_state_enter,
-	},
+	[SCI_BASE_REQUEST_STATE_FINAL] = { },
 };
 
 static void scic_sds_general_request_construct(struct scic_sds_controller *scic,

commit a7e255a34220ba57eeeb75637c911974e54c08e7
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed May 11 08:27:47 2011 -0700

    isci: remove request task context completion state handler
    
    Unlike the other conversions this only updates
    scic_sds_io_request_tc_completion() to call the old state handlers directly
    (with less verbose names).  This was done for future patch readability, the
    implementations have only minor differences for different completion codes.
    Without a reference to the function name it would be difficult to dicern which
    state is being updated.  Considered changing the order to look up the
    completion code before the state but that was not a clean conversion either.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index b9f97e8cc5e0..cb13b78d8026 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -932,27 +932,14 @@ static void scic_sds_io_request_copy_response(struct scic_sds_request *sci_req)
 	memcpy(resp_buf, ssp_response->resp_data, len);
 }
 
-/*
- * scic_sds_request_started_state_tc_completion_handler() - This method process
- *    TC (task context) completions for normal IO request (i.e. Task/Abort
- *    Completions of type 0).  This method will update the
- *    SCIC_SDS_IO_REQUEST_T::status field.
- * @sci_req: This parameter specifies the request for which a completion
- *    occurred.
- * @completion_code: This parameter specifies the completion code received from
- *    the SCU.
- *
- */
-static enum sci_status
-scic_sds_request_started_state_tc_completion_handler(struct scic_sds_request *sci_req,
-						     u32 completion_code)
+static enum sci_status request_started_state_tc_event(struct scic_sds_request *sci_req,
+						      u32 completion_code)
 {
-	u8 datapres;
 	struct ssp_response_iu *resp_iu;
+	u8 datapres;
 
-	/*
-	 * TODO: Any SDMA return code of other than 0 is bad
-	 *       decode 0x003C0000 to determine SDMA status
+	/* TODO: Any SDMA return code of other than 0 is bad decode 0x003C0000
+	 * to determine SDMA status
 	 */
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
@@ -960,11 +947,8 @@ scic_sds_request_started_state_tc_completion_handler(struct scic_sds_request *sc
 					    SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 		break;
-
-	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_EARLY_RESP):
-	{
-		/*
-		 * There are times when the SCU hardware will return an early
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_EARLY_RESP): {
+		/* There are times when the SCU hardware will return an early
 		 * response because the io request specified more data than is
 		 * returned by the target device (mode pages, inquiry data,
 		 * etc.).  We must check the response stats to see if this is
@@ -979,21 +963,17 @@ scic_sds_request_started_state_tc_completion_handler(struct scic_sds_request *sc
 			       word_cnt);
 
 		if (resp->status == 0) {
-			scic_sds_request_set_status(
-				sci_req,
-				SCU_TASK_DONE_GOOD,
-				SCI_SUCCESS_IO_DONE_EARLY);
+			scic_sds_request_set_status(sci_req,
+						    SCU_TASK_DONE_GOOD,
+						    SCI_SUCCESS_IO_DONE_EARLY);
 		} else {
-			scic_sds_request_set_status(
-				sci_req,
-				SCU_TASK_DONE_CHECK_RESPONSE,
-				SCI_FAILURE_IO_RESPONSE_VALID);
+			scic_sds_request_set_status(sci_req,
+						    SCU_TASK_DONE_CHECK_RESPONSE,
+						    SCI_FAILURE_IO_RESPONSE_VALID);
 		}
+		break;
 	}
-	break;
-
-	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_CHECK_RESPONSE):
-	{
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_CHECK_RESPONSE): {
 		ssize_t word_cnt = SSP_RESP_IU_MAX_SIZE / sizeof(u32);
 
 		sci_swab32_cpy(&sci_req->ssp.rsp,
@@ -1007,24 +987,22 @@ scic_sds_request_started_state_tc_completion_handler(struct scic_sds_request *sc
 	}
 
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_RESP_LEN_ERR):
-		/*
-		 * / @todo With TASK_DONE_RESP_LEN_ERR is the response frame
+		/* TODO With TASK_DONE_RESP_LEN_ERR is the response frame
 		 * guaranteed to be received before this completion status is
 		 * posted?
 		 */
 		resp_iu = &sci_req->ssp.rsp;
 		datapres = resp_iu->datapres;
 
-		if ((datapres == 0x01) || (datapres == 0x02)) {
-			scic_sds_request_set_status(
-				sci_req,
-				SCU_TASK_DONE_CHECK_RESPONSE,
-				SCI_FAILURE_IO_RESPONSE_VALID);
+		if (datapres == 1 || datapres == 2) {
+			scic_sds_request_set_status(sci_req,
+						    SCU_TASK_DONE_CHECK_RESPONSE,
+						    SCI_FAILURE_IO_RESPONSE_VALID);
 		} else
-			scic_sds_request_set_status(
-				sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS);
+			scic_sds_request_set_status(sci_req,
+						    SCU_TASK_DONE_GOOD,
+						    SCI_SUCCESS);
 		break;
-
 	/* only stp device gets suspended. */
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_ACK_NAK_TO):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_LL_PERR):
@@ -1038,14 +1016,12 @@ scic_sds_request_started_state_tc_completion_handler(struct scic_sds_request *sc
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_REG_ERR):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SDB_ERR):
 		if (sci_req->protocol == SCIC_STP_PROTOCOL) {
-			scic_sds_request_set_status(
-				sci_req,
+			scic_sds_request_set_status(sci_req,
 				SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
 				SCU_COMPLETION_TL_STATUS_SHIFT,
 				SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED);
 		} else {
-			scic_sds_request_set_status(
-				sci_req,
+			scic_sds_request_set_status(sci_req,
 				SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
 				SCU_COMPLETION_TL_STATUS_SHIFT,
 				SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
@@ -1063,11 +1039,10 @@ scic_sds_request_started_state_tc_completion_handler(struct scic_sds_request *sc
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_STP_RESOURCES_BUSY):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_PROTOCOL_NOT_SUPPORTED):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_CONNECTION_RATE_NOT_SUPPORTED):
-		scic_sds_request_set_status(
-			sci_req,
-			SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
-			SCU_COMPLETION_TL_STATUS_SHIFT,
-			SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED);
+		scic_sds_request_set_status(sci_req,
+					    SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
+					    SCU_COMPLETION_TL_STATUS_SHIFT,
+					    SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED);
 		break;
 
 	/* neither ssp nor stp gets suspended. */
@@ -1105,22 +1080,6 @@ scic_sds_request_started_state_tc_completion_handler(struct scic_sds_request *sc
 	return SCI_SUCCESS;
 }
 
-enum sci_status
-scic_sds_io_request_tc_completion(struct scic_sds_request *request, u32 completion_code)
-{
-	if (request->state_handlers->tc_completion_handler)
-		return request->state_handlers->tc_completion_handler(request, completion_code);
-
-	dev_warn(scic_to_dev(request->owning_controller),
-		"%s: SCIC IO Request given task completion notification %x "
-		"while in wrong state %d\n",
-		__func__,
-		completion_code,
-		sci_base_state_machine_get_state(&request->state_machine));
-
-	return SCI_FAILURE_INVALID_STATE;
-}
-
 /*
  * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
  * object receives a scic_sds_request_complete() request. This method frees up
@@ -1146,54 +1105,32 @@ static enum sci_status scic_sds_request_completed_state_complete_handler(
 	return SCI_SUCCESS;
 }
 
-/*
- * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
- * object receives a scic_sds_request_task_completion() request. This method
- * decodes the completion type waiting for the abort task complete
- * notification. When the abort task complete is received the io request
- * transitions to the completed state. enum sci_status SCI_SUCCESS
- */
-static enum sci_status scic_sds_request_aborting_state_tc_completion_handler(
+static enum sci_status request_aborting_state_tc_event(
 	struct scic_sds_request *sci_req,
 	u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case (SCU_TASK_DONE_GOOD << SCU_COMPLETION_TL_STATUS_SHIFT):
 	case (SCU_TASK_DONE_TASK_ABORT << SCU_COMPLETION_TL_STATUS_SHIFT):
-		scic_sds_request_set_status(
-			sci_req, SCU_TASK_DONE_TASK_ABORT, SCI_FAILURE_IO_TERMINATED
-			);
+		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_TASK_ABORT,
+					    SCI_FAILURE_IO_TERMINATED);
 
 		sci_base_state_machine_change_state(&sci_req->state_machine,
 						    SCI_BASE_REQUEST_STATE_COMPLETED);
 		break;
 
 	default:
-		/*
-		 * Unless we get some strange error wait for the task abort to complete
-		 * TODO: Should there be a state change for this completion? */
+		/* Unless we get some strange error wait for the task abort to complete
+		 * TODO: Should there be a state change for this completion?
+		 */
 		break;
 	}
 
 	return SCI_SUCCESS;
 }
 
-/**
- * This method processes the completions transport layer (TL) status to
- *    determine if the RAW task management frame was sent successfully. If the
- *    raw frame was sent successfully, then the state for the task request
- *    transitions to waiting for a response frame.
- * @sci_req: This parameter specifies the request for which the TC
- *    completion was received.
- * @completion_code: This parameter indicates the completion status information
- *    for the TC.
- *
- * Indicate if the tc completion handler was successful. SCI_SUCCESS currently
- * this method always returns success.
- */
-static enum sci_status scic_sds_ssp_task_request_await_tc_completion_tc_completion_handler(
-	struct scic_sds_request *sci_req,
-	u32 completion_code)
+static enum sci_status ssp_task_request_await_tc_event(struct scic_sds_request *sci_req,
+						       u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
@@ -1203,33 +1140,27 @@ static enum sci_status scic_sds_ssp_task_request_await_tc_completion_tc_completi
 		sci_base_state_machine_change_state(&sci_req->state_machine,
 						    SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE);
 		break;
-
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_ACK_NAK_TO):
-		/*
-		 * Currently, the decision is to simply allow the task request to
-		 * timeout if the task IU wasn't received successfully.
-		 * There is a potential for receiving multiple task responses if we
-		 * decide to send the task IU again. */
+		/* Currently, the decision is to simply allow the task request
+		 * to timeout if the task IU wasn't received successfully.
+		 * There is a potential for receiving multiple task responses if
+		 * we decide to send the task IU again.
+		 */
 		dev_warn(scic_to_dev(sci_req->owning_controller),
 			 "%s: TaskRequest:0x%p CompletionCode:%x - "
-			 "ACK/NAK timeout\n",
-			 __func__,
-			 sci_req,
+			 "ACK/NAK timeout\n", __func__, sci_req,
 			 completion_code);
 
 		sci_base_state_machine_change_state(&sci_req->state_machine,
 						    SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE);
 		break;
-
 	default:
-		/*
-		 * All other completion status cause the IO to be complete.  If a NAK
-		 * was received, then it is up to the user to retry the request. */
-		scic_sds_request_set_status(
-			sci_req,
+		/* All other completion status cause the IO to be complete.  If a NAK
+		 * was received, then it is up to the user to retry the request.
+		 */
+		scic_sds_request_set_status(sci_req,
 			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
-			);
+			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
 		sci_base_state_machine_change_state(&sci_req->state_machine,
 						    SCI_BASE_REQUEST_STATE_COMPLETED);
@@ -1239,27 +1170,15 @@ static enum sci_status scic_sds_ssp_task_request_await_tc_completion_tc_completi
 	return SCI_SUCCESS;
 }
 
-/**
- * This method processes an abnormal TC completion while the SMP request is
- *    waiting for a response frame.  It decides what happened to the IO based
- *    on TC completion status.
- * @sci_req: This parameter specifies the request for which the TC
- *    completion was received.
- * @completion_code: This parameter indicates the completion status information
- *    for the TC.
- *
- * Indicate if the tc completion handler was successful. SCI_SUCCESS currently
- * this method always returns success.
- */
-static enum sci_status scic_sds_smp_request_await_response_tc_completion_handler(
-	struct scic_sds_request *sci_req,
-	u32 completion_code)
+static enum sci_status smp_request_await_response_tc_event(struct scic_sds_request *sci_req,
+							   u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		/*
-		 * In the AWAIT RESPONSE state, any TC completion is unexpected.
-		 * but if the TC has success status, we complete the IO anyway. */
+		/* In the AWAIT RESPONSE state, any TC completion is
+		 * unexpected.  but if the TC has success status, we
+		 * complete the IO anyway.
+		 */
 		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
 					    SCI_SUCCESS);
 
@@ -1271,11 +1190,13 @@ static enum sci_status scic_sds_smp_request_await_response_tc_completion_handler
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_UFI_ERR):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_FRM_TYPE_ERR):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_LL_RX_ERR):
-		/*
-		 * These status has been seen in a specific LSI expander, which sometimes
-		 * is not able to send smp response within 2 ms. This causes our hardware
-		 * break the connection and set TC completion with one of these SMP_XXX_XX_ERR
-		 * status. For these type of error, we ask scic user to retry the request. */
+		/* These status has been seen in a specific LSI
+		 * expander, which sometimes is not able to send smp
+		 * response within 2 ms. This causes our hardware break
+		 * the connection and set TC completion with one of
+		 * these SMP_XXX_XX_ERR status. For these type of error,
+		 * we ask scic user to retry the request.
+		 */
 		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_SMP_RESP_TO_ERR,
 					    SCI_FAILURE_RETRY_REQUIRED);
 
@@ -1284,14 +1205,12 @@ static enum sci_status scic_sds_smp_request_await_response_tc_completion_handler
 		break;
 
 	default:
-		/*
-		 * All other completion status cause the IO to be complete.  If a NAK
-		 * was received, then it is up to the user to retry the request. */
-		scic_sds_request_set_status(
-			sci_req,
-			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
-			);
+		/* All other completion status cause the IO to be complete.  If a NAK
+		 * was received, then it is up to the user to retry the request
+		 */
+		scic_sds_request_set_status(sci_req,
+					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
+					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
 		sci_base_state_machine_change_state(&sci_req->state_machine,
 						    SCI_BASE_REQUEST_STATE_COMPLETED);
@@ -1301,22 +1220,8 @@ static enum sci_status scic_sds_smp_request_await_response_tc_completion_handler
 	return SCI_SUCCESS;
 }
 
-/**
- * This method processes the completions transport layer (TL) status to
- *    determine if the SMP request was sent successfully. If the SMP request
- *    was sent successfully, then the state for the SMP request transits to
- *    waiting for a response frame.
- * @sci_req: This parameter specifies the request for which the TC
- *    completion was received.
- * @completion_code: This parameter indicates the completion status information
- *    for the TC.
- *
- * Indicate if the tc completion handler was successful. SCI_SUCCESS currently
- * this method always returns success.
- */
-static enum sci_status scic_sds_smp_request_await_tc_completion_tc_completion_handler(
-	struct scic_sds_request *sci_req,
-	u32 completion_code)
+static enum sci_status smp_request_await_tc_event(struct scic_sds_request *sci_req,
+						  u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
@@ -1326,20 +1231,17 @@ static enum sci_status scic_sds_smp_request_await_tc_completion_tc_completion_ha
 		sci_base_state_machine_change_state(&sci_req->state_machine,
 						    SCI_BASE_REQUEST_STATE_COMPLETED);
 		break;
-
 	default:
-		/*
-		 * All other completion status cause the IO to be complete.  If a NAK
-		 * was received, then it is up to the user to retry the request. */
-		scic_sds_request_set_status(
-			sci_req,
-			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
-			);
+		/* All other completion status cause the IO to be
+		 * complete.  If a NAK was received, then it is up to
+		 * the user to retry the request.
+		 */
+		scic_sds_request_set_status(sci_req,
+					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
+					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_base_state_machine_change_state(
-			&sci_req->state_machine,
-			SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
 		break;
 	}
 
@@ -1400,44 +1302,29 @@ static struct scu_sgl_element *scic_sds_stp_request_pio_get_next_sgl(struct scic
 	return current_sgl;
 }
 
-/**
- *
- * @sci_req:
- * @completion_code:
- *
- * This method processes a TC completion.  The expected TC completion is for
- * the transmission of the H2D register FIS containing the SATA/STP non-data
- * request. This method always successfully processes the TC completion.
- * SCI_SUCCESS This value is always returned.
- */
-static enum sci_status scic_sds_stp_request_non_data_await_h2d_tc_completion_handler(
-	struct scic_sds_request *sci_req,
-	u32 completion_code)
+static enum sci_status stp_request_non_data_await_h2d_tc_event(struct scic_sds_request *sci_req,
+							       u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(
-			sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS
-			);
+		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
+					    SCI_SUCCESS);
 
-		sci_base_state_machine_change_state(
-			&sci_req->state_machine,
-			SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE
-			);
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE);
 		break;
 
 	default:
-		/*
-		 * All other completion status cause the IO to be complete.  If a NAK
-		 * was received, then it is up to the user to retry the request. */
-		scic_sds_request_set_status(
-			sci_req,
-			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
-			);
+		/* All other completion status cause the IO to be
+		 * complete.  If a NAK was received, then it is up to
+		 * the user to retry the request.
+		 */
+		scic_sds_request_set_status(sci_req,
+					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
+					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_base_state_machine_change_state(
-			&sci_req->state_machine, SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
 		break;
 	}
 
@@ -1613,55 +1500,38 @@ static enum sci_status scic_sds_stp_request_pio_data_in_copy_data(
 	return status;
 }
 
-/**
- *
- * @sci_req:
- * @completion_code:
- *
- * enum sci_status
- */
-static enum sci_status scic_sds_stp_request_pio_await_h2d_completion_tc_completion_handler(
-	struct scic_sds_request *sci_req,
-	u32 completion_code)
+static enum sci_status stp_request_pio_await_h2d_completion_tc_event(struct scic_sds_request *sci_req,
+								     u32 completion_code)
 {
 	enum sci_status status = SCI_SUCCESS;
 
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(
-			sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS
-			);
+		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS);
 
-		sci_base_state_machine_change_state(
-			&sci_req->state_machine,
-			SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE
-			);
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE);
 		break;
 
 	default:
-		/*
-		 * All other completion status cause the IO to be complete.  If a NAK
-		 * was received, then it is up to the user to retry the request. */
-		scic_sds_request_set_status(
-			sci_req,
-			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
-			);
+		/* All other completion status cause the IO to be
+		 * complete.  If a NAK was received, then it is up to
+		 * the user to retry the request.
+		 */
+		scic_sds_request_set_status(sci_req,
+					    SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
+					    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_base_state_machine_change_state(
-			&sci_req->state_machine,
-			SCI_BASE_REQUEST_STATE_COMPLETED
-			);
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
 		break;
 	}
 
 	return status;
 }
 
-static enum sci_status scic_sds_stp_request_pio_data_out_await_data_transmit_completion_tc_completion_handler(
-
-	struct scic_sds_request *sci_req,
-	u32 completion_code)
+static enum sci_status pio_data_out_tx_done_tc_event(struct scic_sds_request *sci_req,
+						     u32 completion_code)
 {
 	enum sci_status status = SCI_SUCCESS;
 	bool all_frames_transferred = false;
@@ -1695,7 +1565,6 @@ static enum sci_status scic_sds_stp_request_pio_data_out_await_data_transmit_com
 				);
 		}
 		break;
-
 	default:
 		/*
 		 * All other completion status cause the IO to be complete.  If a NAK
@@ -2209,12 +2078,8 @@ enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_r
 	}
 }
 
-
-
-
-static enum sci_status scic_sds_stp_request_udma_await_tc_completion_tc_completion_handler(
-	struct scic_sds_request *sci_req,
-	u32 completion_code)
+static enum sci_status stp_request_udma_await_tc_event(struct scic_sds_request *sci_req,
+						       u32 completion_code)
 {
 	enum sci_status status = SCI_SUCCESS;
 
@@ -2226,9 +2091,10 @@ static enum sci_status scic_sds_stp_request_udma_await_tc_completion_tc_completi
 		break;
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_UNEXP_FIS):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_REG_ERR):
-		/*
-		 * We must check ther response buffer to see if the D2H Register FIS was
-		 * received before we got the TC completion. */
+		/* We must check ther response buffer to see if the D2H
+		 * Register FIS was received before we got the TC
+		 * completion.
+		 */
 		if (sci_req->stp.rsp.fis_type == FIS_REGD2H) {
 			scic_sds_remote_device_suspend(sci_req->target_device,
 				SCU_EVENT_SPECIFIC(SCU_NORMALIZE_COMPLETION_STATUS(completion_code)));
@@ -2237,18 +2103,22 @@ static enum sci_status scic_sds_stp_request_udma_await_tc_completion_tc_completi
 								   SCU_TASK_DONE_CHECK_RESPONSE,
 								   SCI_FAILURE_IO_RESPONSE_VALID);
 		} else {
-			/*
-			 * If we have an error completion status for the TC then we can expect a
-			 * D2H register FIS from the device so we must change state to wait for it */
+			/* If we have an error completion status for the
+			 * TC then we can expect a D2H register FIS from
+			 * the device so we must change state to wait
+			 * for it
+			 */
 			sci_base_state_machine_change_state(&sci_req->state_machine,
 				SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE);
 		}
 		break;
 
-	/*
-	 * / @todo Check to see if any of these completion status need to wait for
-	 * /       the device to host register fis. */
-	/* / @todo We can retry the command for SCU_TASK_DONE_CMD_LL_R_ERR - this comes only for B0 */
+	/* TODO Check to see if any of these completion status need to
+	 * wait for the device to host register fis.
+	 */
+	/* TODO We can retry the command for SCU_TASK_DONE_CMD_LL_R_ERR
+	 * - this comes only for B0
+	 */
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_INV_FIS_LEN):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_MAX_PLD_ERR):
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_LL_R_ERR):
@@ -2268,61 +2138,35 @@ static enum sci_status scic_sds_stp_request_udma_await_tc_completion_tc_completi
 	return status;
 }
 
-/**
- *
- * @sci_req:
- * @completion_code:
- *
- * This method processes a TC completion.  The expected TC completion is for
- * the transmission of the H2D register FIS containing the SATA/STP non-data
- * request. This method always successfully processes the TC completion.
- * SCI_SUCCESS This value is always returned.
- */
-static enum sci_status scic_sds_stp_request_soft_reset_await_h2d_asserted_tc_completion_handler(
-	struct scic_sds_request *sci_req,
-	u32 completion_code)
+static enum sci_status stp_request_soft_reset_await_h2d_asserted_tc_event(struct scic_sds_request *sci_req,
+									  u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(
-			sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS
-			);
+		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
+					    SCI_SUCCESS);
 
-		sci_base_state_machine_change_state(
-			&sci_req->state_machine,
-			SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE
-			);
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+			SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE);
 		break;
 
 	default:
 		/*
 		 * All other completion status cause the IO to be complete.  If a NAK
 		 * was received, then it is up to the user to retry the request. */
-		scic_sds_request_set_status(
-			sci_req,
+		scic_sds_request_set_status(sci_req,
 			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
-			);
+			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
-		sci_base_state_machine_change_state(
-			&sci_req->state_machine, SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
 		break;
 	}
 
 	return SCI_SUCCESS;
 }
 
-/**
- *
- * @sci_req:
- * @completion_code:
- *
- * This method processes a TC completion.  The expected TC completion is for
- * the transmission of the H2D register FIS containing the SATA/STP non-data
- * request. This method always successfully processes the TC completion.
- * SCI_SUCCESS This value is always returned.
- */
-static enum sci_status scic_sds_stp_request_soft_reset_await_h2d_diagnostic_tc_completion_handler(
+static enum sci_status stp_request_soft_reset_await_h2d_diagnostic_tc_event(
 	struct scic_sds_request *sci_req,
 	u32 completion_code)
 {
@@ -2336,70 +2180,89 @@ static enum sci_status scic_sds_stp_request_soft_reset_await_h2d_diagnostic_tc_c
 		break;
 
 	default:
-		/*
-		 * All other completion status cause the IO to be complete.  If a NAK
-		 * was received, then it is up to the user to retry the request. */
-		scic_sds_request_set_status(
-			sci_req,
+		/* All other completion status cause the IO to be complete.  If
+		 * a NAK was received, then it is up to the user to retry the
+		 * request.
+		 */
+		scic_sds_request_set_status(sci_req,
 			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
-			);
+			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 
 		sci_base_state_machine_change_state(&sci_req->state_machine,
-				SCI_BASE_REQUEST_STATE_COMPLETED);
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
 		break;
 	}
 
 	return SCI_SUCCESS;
 }
 
+enum sci_status
+scic_sds_io_request_tc_completion(struct scic_sds_request *sci_req, u32 completion_code)
+{
+	enum sci_base_request_states state;
+	struct scic_sds_controller *scic = sci_req->owning_controller;
+
+	state = sci_req->state_machine.current_state_id;
+
+	switch (state) {
+		case SCI_BASE_REQUEST_STATE_STARTED:
+			return request_started_state_tc_event(sci_req, completion_code);
+		case SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION:
+			return ssp_task_request_await_tc_event(sci_req, completion_code);
+		case SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE:
+			return smp_request_await_response_tc_event(sci_req, completion_code);
+		case SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION:
+			return smp_request_await_tc_event(sci_req, completion_code);
+		case SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE:
+			return stp_request_udma_await_tc_event(sci_req, completion_code);
+		case SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE:
+			return stp_request_non_data_await_h2d_tc_event(sci_req, completion_code);
+		case SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE:
+			return stp_request_pio_await_h2d_completion_tc_event(sci_req, completion_code);
+		case SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE:
+			return pio_data_out_tx_done_tc_event(sci_req, completion_code);
+		case SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_ASSERTED_COMPLETION_SUBSTATE:
+			return stp_request_soft_reset_await_h2d_asserted_tc_event(sci_req, completion_code);
+		case SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE:
+			return stp_request_soft_reset_await_h2d_diagnostic_tc_event(sci_req, completion_code);
+		case SCI_BASE_REQUEST_STATE_ABORTING:
+			return request_aborting_state_tc_event(sci_req, completion_code);
+		default:
+			dev_warn(scic_to_dev(scic),
+				"%s: SCIC IO Request given task completion notification %x "
+				"while in wrong state %d\n", __func__, completion_code,
+				state);
+			return SCI_FAILURE_INVALID_STATE;
+	}
+}
+
+
+
 static const struct scic_sds_io_request_state_handler scic_sds_request_state_handler_table[] = {
 	[SCI_BASE_REQUEST_STATE_INITIAL] = {},
 	[SCI_BASE_REQUEST_STATE_CONSTRUCTED] = {},
-	[SCI_BASE_REQUEST_STATE_STARTED] = {
-		.tc_completion_handler	= scic_sds_request_started_state_tc_completion_handler,
-	},
-	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION] = {
-		.tc_completion_handler	= scic_sds_ssp_task_request_await_tc_completion_tc_completion_handler,
-	},
+	[SCI_BASE_REQUEST_STATE_STARTED] = { },
+	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION] = { },
 	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE] = { },
-	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE] = {
-		.tc_completion_handler	= scic_sds_smp_request_await_response_tc_completion_handler,
-	},
-	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION] = {
-		.tc_completion_handler	=  scic_sds_smp_request_await_tc_completion_tc_completion_handler,
-	},
-	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE] = {
-		.tc_completion_handler	= scic_sds_stp_request_udma_await_tc_completion_tc_completion_handler,
-	},
+	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE] = { },
+	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION] = { },
+	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE] = { },
 	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE] = {
-		.tc_completion_handler	= scic_sds_stp_request_non_data_await_h2d_tc_completion_handler,
-	},
+	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE] = { },
 	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE] = { },
-	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE] = {
-		.tc_completion_handler	= scic_sds_stp_request_pio_await_h2d_completion_tc_completion_handler,
-	},
+	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE] = { },
 	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE] = { },
 	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE] = {
 		.event_handler		= scic_sds_stp_request_pio_data_in_await_data_event_handler,
 	},
-	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE] = {
-		.tc_completion_handler	= scic_sds_stp_request_pio_data_out_await_data_transmit_completion_tc_completion_handler,
-	},
-	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_ASSERTED_COMPLETION_SUBSTATE] = {
-		.tc_completion_handler	= scic_sds_stp_request_soft_reset_await_h2d_asserted_tc_completion_handler,
-	},
-	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE] = {
-		.tc_completion_handler	= scic_sds_stp_request_soft_reset_await_h2d_diagnostic_tc_completion_handler,
-	},
+	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE] = { },
+	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_ASSERTED_COMPLETION_SUBSTATE] = { },
+	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE] = { },
 	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE] = { },
 	[SCI_BASE_REQUEST_STATE_COMPLETED] = {
 		.complete_handler	= scic_sds_request_completed_state_complete_handler,
 	},
-	[SCI_BASE_REQUEST_STATE_ABORTING] = {
-		.tc_completion_handler	= scic_sds_request_aborting_state_tc_completion_handler,
-	},
+	[SCI_BASE_REQUEST_STATE_ABORTING] = { },
 	[SCI_BASE_REQUEST_STATE_FINAL] = { },
 };
 

commit d1c637c35b33ddd2b405956e04b50939bb10ed2a
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Wed May 11 08:27:47 2011 -0700

    isci: unify request frame handlers
    
    Unify the implementation in scic_sds_io_request_frame_handler and kill
    the state handler.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 41a418d8b337..b9f97e8cc5e0 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -907,34 +907,6 @@ enum sci_status scic_sds_io_request_event_handler(
 	return SCI_FAILURE_INVALID_STATE;
 }
 
-/**
- *
- * @sci_req: The SCIC_SDS_IO_REQUEST_T object for which the start
- *    operation is to be executed.
- * @frame_index: The frame index returned by the hardware for the reqeust
- *    object.
- *
- * This method invokes the core state frame handler for the
- * SCIC_SDS_IO_REQUEST_T object. enum sci_status
- */
-enum sci_status scic_sds_io_request_frame_handler(
-	struct scic_sds_request *request,
-	u32 frame_index)
-{
-	if (request->state_handlers->frame_handler)
-		return request->state_handlers->frame_handler(request, frame_index);
-
-	dev_warn(scic_to_dev(request->owning_controller),
-		 "%s: SCIC IO Request given unexpected frame %x while in "
-		 "state %d\n",
-		 __func__,
-		 frame_index,
-		 sci_base_state_machine_get_state(&request->state_machine));
-
-	scic_sds_controller_release_frame(request->owning_controller, frame_index);
-	return SCI_FAILURE_INVALID_STATE;
-}
-
 /*
  * This function copies response data for requests returning response data
  *    instead of sense data.
@@ -1149,81 +1121,6 @@ scic_sds_io_request_tc_completion(struct scic_sds_request *request, u32 completi
 	return SCI_FAILURE_INVALID_STATE;
 }
 
-/*
- * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
- * object receives a scic_sds_request_frame_handler() request. This method
- * first determines the frame type received.  If this is a response frame then
- * the response data is copied to the io request response buffer for processing
- * at completion time. If the frame type is not a response buffer an error is
- * logged. enum sci_status SCI_SUCCESS SCI_FAILURE_INVALID_PARAMETER_VALUE
- */
-static enum sci_status
-scic_sds_request_started_state_frame_handler(struct scic_sds_request *sci_req,
-					     u32 frame_index)
-{
-	enum sci_status status;
-	u32 *frame_header;
-	struct ssp_frame_hdr ssp_hdr;
-	ssize_t word_cnt;
-
-	status = scic_sds_unsolicited_frame_control_get_header(
-		&(scic_sds_request_get_controller(sci_req)->uf_control),
-		frame_index,
-		(void **)&frame_header);
-
-	word_cnt = sizeof(struct ssp_frame_hdr) / sizeof(u32);
-	sci_swab32_cpy(&ssp_hdr, frame_header, word_cnt);
-
-	if (ssp_hdr.frame_type == SSP_RESPONSE) {
-		struct ssp_response_iu *resp_iu;
-		ssize_t word_cnt = SSP_RESP_IU_MAX_SIZE / sizeof(u32);
-
-		status = scic_sds_unsolicited_frame_control_get_buffer(
-			&(scic_sds_request_get_controller(sci_req)->uf_control),
-			frame_index,
-			(void **)&resp_iu);
-
-		sci_swab32_cpy(&sci_req->ssp.rsp,
-			       resp_iu, word_cnt);
-
-		resp_iu = &sci_req->ssp.rsp;
-
-		if ((resp_iu->datapres == 0x01) ||
-		    (resp_iu->datapres == 0x02)) {
-			scic_sds_request_set_status(
-				sci_req,
-				SCU_TASK_DONE_CHECK_RESPONSE,
-				SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
-		} else
-			scic_sds_request_set_status(
-				sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS);
-	} else {
-		/* This was not a response frame why did it get forwarded? */
-		dev_err(scic_to_dev(sci_req->owning_controller),
-			"%s: SCIC IO Request 0x%p received unexpected "
-			"frame %d type 0x%02x\n",
-			__func__,
-			sci_req,
-			frame_index,
-			ssp_hdr.frame_type);
-	}
-
-	/*
-	 * In any case we are done with this frame buffer return it to the
-	 * controller
-	 */
-	scic_sds_controller_release_frame(
-		sci_req->owning_controller, frame_index);
-
-	return SCI_SUCCESS;
-}
-
-/*
- * *****************************************************************************
- * *  COMPLETED STATE HANDLERS
- * ***************************************************************************** */
-
-
 /*
  * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
  * object receives a scic_sds_request_complete() request. This method frees up
@@ -1281,24 +1178,6 @@ static enum sci_status scic_sds_request_aborting_state_tc_completion_handler(
 	return SCI_SUCCESS;
 }
 
-/*
- * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
- * object receives a scic_sds_request_frame_handler() request. This method
- * discards the unsolicited frame since we are waiting for the abort task
- * completion. enum sci_status SCI_SUCCESS
- */
-static enum sci_status scic_sds_request_aborting_state_frame_handler(
-	struct scic_sds_request *sci_req,
-	u32 frame_index)
-{
-	/* TODO: Is it even possible to get an unsolicited frame in the aborting state? */
-
-	scic_sds_controller_release_frame(
-		sci_req->owning_controller, frame_index);
-
-	return SCI_SUCCESS;
-}
-
 /**
  * This method processes the completions transport layer (TL) status to
  *    determine if the RAW task management frame was sent successfully. If the
@@ -1360,34 +1239,6 @@ static enum sci_status scic_sds_ssp_task_request_await_tc_completion_tc_completi
 	return SCI_SUCCESS;
 }
 
-/**
- * This method processes an unsolicited frame while the task mgmt request is
- *    waiting for a response frame.  It will copy the response data, release
- *    the unsolicited frame, and transition the request to the
- *    SCI_BASE_REQUEST_STATE_COMPLETED state.
- * @sci_req: This parameter specifies the request for which the
- *    unsolicited frame was received.
- * @frame_index: This parameter indicates the unsolicited frame index that
- *    should contain the response.
- *
- * This method returns an indication of whether the TC response frame was
- * handled successfully or not. SCI_SUCCESS Currently this value is always
- * returned and indicates successful processing of the TC response. Should
- * probably update to check frame type and make sure it is a response frame.
- */
-static enum sci_status scic_sds_ssp_task_request_await_tc_response_frame_handler(
-	struct scic_sds_request *request,
-	u32 frame_index)
-{
-	scic_sds_io_request_copy_response(request);
-
-	sci_base_state_machine_change_state(&request->state_machine,
-					    SCI_BASE_REQUEST_STATE_COMPLETED);
-	scic_sds_controller_release_frame(request->owning_controller,
-			frame_index);
-	return SCI_SUCCESS;
-}
-
 /**
  * This method processes an abnormal TC completion while the SMP request is
  *    waiting for a response frame.  It decides what happened to the IO based
@@ -1450,81 +1301,6 @@ static enum sci_status scic_sds_smp_request_await_response_tc_completion_handler
 	return SCI_SUCCESS;
 }
 
-/*
- * This function processes an unsolicited frame while the SMP request is waiting
- *    for a response frame.  It will copy the response data, release the
- *    unsolicited frame, and transition the request to the
- *    SCI_BASE_REQUEST_STATE_COMPLETED state.
- * @sci_req: This parameter specifies the request for which the
- *    unsolicited frame was received.
- * @frame_index: This parameter indicates the unsolicited frame index that
- *    should contain the response.
- *
- * This function returns an indication of whether the response frame was handled
- * successfully or not. SCI_SUCCESS Currently this value is always returned and
- * indicates successful processing of the TC response.
- */
-static enum sci_status
-scic_sds_smp_request_await_response_frame_handler(struct scic_sds_request *sci_req,
-						  u32 frame_index)
-{
-	enum sci_status status;
-	void *frame_header;
-	struct smp_resp *rsp_hdr = &sci_req->smp.rsp;
-	ssize_t word_cnt = SMP_RESP_HDR_SZ / sizeof(u32);
-
-	status = scic_sds_unsolicited_frame_control_get_header(
-		&(scic_sds_request_get_controller(sci_req)->uf_control),
-		frame_index,
-		&frame_header);
-
-	/* byte swap the header. */
-	sci_swab32_cpy(rsp_hdr, frame_header, word_cnt);
-
-	if (rsp_hdr->frame_type == SMP_RESPONSE) {
-		void *smp_resp;
-
-		status = scic_sds_unsolicited_frame_control_get_buffer(
-			&(scic_sds_request_get_controller(sci_req)->uf_control),
-			frame_index,
-			&smp_resp);
-
-		word_cnt = (sizeof(struct smp_req) - SMP_RESP_HDR_SZ) /
-			sizeof(u32);
-
-		sci_swab32_cpy(((u8 *) rsp_hdr) + SMP_RESP_HDR_SZ,
-			       smp_resp, word_cnt);
-
-		scic_sds_request_set_status(
-			sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS);
-
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION);
-	} else {
-		/* This was not a response frame why did it get forwarded? */
-		dev_err(scic_to_dev(sci_req->owning_controller),
-			"%s: SCIC SMP Request 0x%p received unexpected frame "
-			"%d type 0x%02x\n",
-			__func__,
-			sci_req,
-			frame_index,
-			rsp_hdr->frame_type);
-
-		scic_sds_request_set_status(
-			sci_req,
-			SCU_TASK_DONE_SMP_FRM_TYPE_ERR,
-			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
-
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
-	}
-
-	scic_sds_controller_release_frame(sci_req->owning_controller,
-					  frame_index);
-
-	return SCI_SUCCESS;
-}
-
 /**
  * This method processes the completions transport layer (TL) status to
  *    determine if the SMP request was sent successfully. If the SMP request
@@ -1668,76 +1444,6 @@ static enum sci_status scic_sds_stp_request_non_data_await_h2d_tc_completion_han
 	return SCI_SUCCESS;
 }
 
-/**
- *
- * @request: This parameter specifies the request for which a frame has been
- *    received.
- * @frame_index: This parameter specifies the index of the frame that has been
- *    received.
- *
- * This method processes frames received from the target while waiting for a
- * device to host register FIS.  If a non-register FIS is received during this
- * time, it is treated as a protocol violation from an IO perspective. Indicate
- * if the received frame was processed successfully.
- */
-static enum sci_status scic_sds_stp_request_non_data_await_d2h_frame_handler(
-	struct scic_sds_request *sci_req,
-	u32 frame_index)
-{
-	enum sci_status status;
-	struct dev_to_host_fis *frame_header;
-	u32 *frame_buffer;
-	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
-	struct scic_sds_controller *scic = sci_req->owning_controller;
-
-	status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
-							       frame_index,
-							       (void **)&frame_header);
-
-	if (status != SCI_SUCCESS) {
-		dev_err(scic_to_dev(sci_req->owning_controller),
-			"%s: SCIC IO Request 0x%p could not get frame header "
-			"for frame index %d, status %x\n",
-			__func__, stp_req, frame_index, status);
-
-		return status;
-	}
-
-	switch (frame_header->fis_type) {
-	case FIS_REGD2H:
-		scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
-							      frame_index,
-							      (void **)&frame_buffer);
-
-		scic_sds_controller_copy_sata_response(&sci_req->stp.rsp,
-						       frame_header,
-						       frame_buffer);
-
-		/* The command has completed with error */
-		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_CHECK_RESPONSE,
-					    SCI_FAILURE_IO_RESPONSE_VALID);
-		break;
-
-	default:
-		dev_warn(scic_to_dev(scic),
-			 "%s: IO Request:0x%p Frame Id:%d protocol "
-			  "violation occurred\n", __func__, stp_req,
-			  frame_index);
-
-		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_UNEXP_FIS,
-					    SCI_FAILURE_PROTOCOL_VIOLATION);
-		break;
-	}
-
-	sci_base_state_machine_change_state(&sci_req->state_machine,
-					    SCI_BASE_REQUEST_STATE_COMPLETED);
-
-	/* Frame has been decoded return it to the controller */
-	scic_sds_controller_release_frame(scic, frame_index);
-
-	return status;
-}
-
 #define SCU_MAX_FRAME_BUFFER_SIZE  0x400  /* 1K is the maximum SCU frame data payload */
 
 /* transmit DATA_FIS from (current sgl + offset) for input
@@ -1952,248 +1658,58 @@ static enum sci_status scic_sds_stp_request_pio_await_h2d_completion_tc_completi
 	return status;
 }
 
-static enum sci_status scic_sds_stp_request_pio_await_frame_frame_handler(struct scic_sds_request *sci_req,
-									  u32 frame_index)
+static enum sci_status scic_sds_stp_request_pio_data_out_await_data_transmit_completion_tc_completion_handler(
+
+	struct scic_sds_request *sci_req,
+	u32 completion_code)
 {
-	struct scic_sds_controller *scic = sci_req->owning_controller;
+	enum sci_status status = SCI_SUCCESS;
+	bool all_frames_transferred = false;
 	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
-	struct isci_request *ireq = sci_req_to_ireq(sci_req);
-	struct sas_task *task = isci_request_access_task(ireq);
-	struct dev_to_host_fis *frame_header;
-	enum sci_status status;
-	u32 *frame_buffer;
-
-	status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
-							       frame_index,
-							       (void **)&frame_header);
-
-	if (status != SCI_SUCCESS) {
-		dev_err(scic_to_dev(scic),
-			"%s: SCIC IO Request 0x%p could not get frame header "
-			"for frame index %d, status %x\n",
-			__func__, stp_req, frame_index, status);
-		return status;
-	}
 
-	switch (frame_header->fis_type) {
-	case FIS_PIO_SETUP:
-		/* Get from the frame buffer the PIO Setup Data */
-		scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
-							      frame_index,
-							      (void **)&frame_buffer);
-
-		/* Get the data from the PIO Setup The SCU Hardware returns
-		 * first word in the frame_header and the rest of the data is in
-		 * the frame buffer so we need to back up one dword
-		 */
-
-		/* transfer_count: first 16bits in the 4th dword */
-		stp_req->type.pio.pio_transfer_bytes = frame_buffer[3] & 0xffff;
-
-		/* ending_status: 4th byte in the 3rd dword */
-		stp_req->type.pio.ending_status = (frame_buffer[2] >> 24) & 0xff;
-
-		scic_sds_controller_copy_sata_response(&sci_req->stp.rsp,
-						       frame_header,
-						       frame_buffer);
-
-		sci_req->stp.rsp.status = stp_req->type.pio.ending_status;
-
-		/* The next state is dependent on whether the
-		 * request was PIO Data-in or Data out
-		 */
-		if (task->data_dir == DMA_FROM_DEVICE) {
-			sci_base_state_machine_change_state(&sci_req->state_machine,
-							    SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE);
-		} else if (task->data_dir == DMA_TO_DEVICE) {
-			/* Transmit data */
+	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
+		/* Transmit data */
+		if (stp_req->type.pio.pio_transfer_bytes != 0) {
 			status = scic_sds_stp_request_pio_data_out_transmit_data(sci_req);
-			if (status != SCI_SUCCESS)
-				break;
-			sci_base_state_machine_change_state(&sci_req->state_machine,
-							    SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE);
-		}
-		break;
-	case FIS_SETDEVBITS:
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE);
-		break;
-	case FIS_REGD2H:
-		if (frame_header->status & ATA_BUSY) {
-			/* Now why is the drive sending a D2H Register FIS when
-			 * it is still busy?  Do nothing since we are still in
-			 * the right state.
+			if (status == SCI_SUCCESS) {
+				if (stp_req->type.pio.pio_transfer_bytes == 0)
+					all_frames_transferred = true;
+			}
+		} else if (stp_req->type.pio.pio_transfer_bytes == 0) {
+			/*
+			 * this will happen if the all data is written at the
+			 * first time after the pio setup fis is received
 			 */
-			dev_dbg(scic_to_dev(scic),
-				"%s: SCIC PIO Request 0x%p received "
-				"D2H Register FIS with BSY status "
-				"0x%x\n", __func__, stp_req,
-				frame_header->status);
-			break;
+			all_frames_transferred  = true;
 		}
 
-		scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
-							      frame_index,
-							      (void **)&frame_buffer);
-
-		scic_sds_controller_copy_sata_response(&sci_req->stp.req,
-						       frame_header,
-						       frame_buffer);
-
-		scic_sds_request_set_status(sci_req,
-					    SCU_TASK_DONE_CHECK_RESPONSE,
-					    SCI_FAILURE_IO_RESPONSE_VALID);
-
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		/* all data transferred. */
+		if (all_frames_transferred) {
+			/*
+			 * Change the state to SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_FRAME_SUBSTATE
+			 * and wait for PIO_SETUP fis / or D2H REg fis. */
+			sci_base_state_machine_change_state(
+				&sci_req->state_machine,
+				SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE
+				);
+		}
 		break;
+
 	default:
-		/* FIXME: what do we do here? */
-		break;
-	}
-
-	/* Frame is decoded return it to the controller */
-	scic_sds_controller_release_frame(scic, frame_index);
-
-	return status;
-}
-
-static enum sci_status scic_sds_stp_request_pio_data_in_await_data_frame_handler(struct scic_sds_request *sci_req,
-										 u32 frame_index)
-{
-	enum sci_status status;
-	struct dev_to_host_fis *frame_header;
-	struct sata_fis_data *frame_buffer;
-	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
-	struct scic_sds_controller *scic = sci_req->owning_controller;
-
-	status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
-							       frame_index,
-							       (void **)&frame_header);
-
-	if (status != SCI_SUCCESS) {
-		dev_err(scic_to_dev(scic),
-			"%s: SCIC IO Request 0x%p could not get frame header "
-			"for frame index %d, status %x\n",
-			__func__, stp_req, frame_index, status);
-		return status;
-	}
-
-	if (frame_header->fis_type == FIS_DATA) {
-		if (stp_req->type.pio.request_current.sgl_pair == NULL) {
-			sci_req->saved_rx_frame_index = frame_index;
-			stp_req->type.pio.pio_transfer_bytes = 0;
-		} else {
-			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
-								      frame_index,
-								      (void **)&frame_buffer);
-
-			status = scic_sds_stp_request_pio_data_in_copy_data(stp_req,
-									    (u8 *)frame_buffer);
-
-			/* Frame is decoded return it to the controller */
-			scic_sds_controller_release_frame(scic, frame_index);
-		}
-
-		/* Check for the end of the transfer, are there more
-		 * bytes remaining for this data transfer
-		 */
-		if (status != SCI_SUCCESS ||
-		    stp_req->type.pio.pio_transfer_bytes != 0)
-			return status;
-
-		if ((stp_req->type.pio.ending_status & ATA_BUSY) == 0) {
-			scic_sds_request_set_status(sci_req,
-						    SCU_TASK_DONE_CHECK_RESPONSE,
-						    SCI_FAILURE_IO_RESPONSE_VALID);
-
-			sci_base_state_machine_change_state(&sci_req->state_machine,
-							    SCI_BASE_REQUEST_STATE_COMPLETED);
-		} else {
-			sci_base_state_machine_change_state(&sci_req->state_machine,
-							    SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE);
-		}
-	} else {
-		dev_err(scic_to_dev(scic),
-			"%s: SCIC PIO Request 0x%p received frame %d "
-			"with fis type 0x%02x when expecting a data "
-			"fis.\n", __func__, stp_req, frame_index,
-			frame_header->fis_type);
-
-		scic_sds_request_set_status(sci_req,
-					    SCU_TASK_DONE_GOOD,
-					    SCI_FAILURE_IO_REQUIRES_SCSI_ABORT);
-
-		sci_base_state_machine_change_state(&sci_req->state_machine,
-						    SCI_BASE_REQUEST_STATE_COMPLETED);
-
-		/* Frame is decoded return it to the controller */
-		scic_sds_controller_release_frame(scic, frame_index);
-	}
-
-	return status;
-}
-
-
-/**
- *
- * @sci_req:
- * @completion_code:
- *
- * enum sci_status
- */
-static enum sci_status scic_sds_stp_request_pio_data_out_await_data_transmit_completion_tc_completion_handler(
-
-	struct scic_sds_request *sci_req,
-	u32 completion_code)
-{
-	enum sci_status status = SCI_SUCCESS;
-	bool all_frames_transferred = false;
-	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
-
-	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
-	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		/* Transmit data */
-		if (stp_req->type.pio.pio_transfer_bytes != 0) {
-			status = scic_sds_stp_request_pio_data_out_transmit_data(sci_req);
-			if (status == SCI_SUCCESS) {
-				if (stp_req->type.pio.pio_transfer_bytes == 0)
-					all_frames_transferred = true;
-			}
-		} else if (stp_req->type.pio.pio_transfer_bytes == 0) {
-			/*
-			 * this will happen if the all data is written at the
-			 * first time after the pio setup fis is received
-			 */
-			all_frames_transferred  = true;
-		}
-
-		/* all data transferred. */
-		if (all_frames_transferred) {
-			/*
-			 * Change the state to SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_FRAME_SUBSTATE
-			 * and wait for PIO_SETUP fis / or D2H REg fis. */
-			sci_base_state_machine_change_state(
-				&sci_req->state_machine,
-				SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE
-				);
-		}
-		break;
-
-	default:
-		/*
-		 * All other completion status cause the IO to be complete.  If a NAK
-		 * was received, then it is up to the user to retry the request. */
-		scic_sds_request_set_status(
-			sci_req,
-			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
-			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
-			);
-
-		sci_base_state_machine_change_state(
-			&sci_req->state_machine,
-			SCI_BASE_REQUEST_STATE_COMPLETED
-			);
+		/*
+		 * All other completion status cause the IO to be complete.  If a NAK
+		 * was received, then it is up to the user to retry the request. */
+		scic_sds_request_set_status(
+			sci_req,
+			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
+			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
+			);
+
+		sci_base_state_machine_change_state(
+			&sci_req->state_machine,
+			SCI_BASE_REQUEST_STATE_COMPLETED
+			);
 		break;
 	}
 
@@ -2280,6 +1796,422 @@ static enum sci_status scic_sds_stp_request_udma_general_frame_handler(struct sc
 	return status;
 }
 
+enum sci_status scic_sds_io_request_frame_handler(struct scic_sds_request *sci_req,
+						  u32 frame_index)
+{
+	struct scic_sds_controller *scic = sci_req->owning_controller;
+	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
+	enum sci_base_request_states state;
+	enum sci_status status;
+	ssize_t word_cnt;
+
+	state = sci_req->state_machine.current_state_id;
+	switch (state)  {
+	case SCI_BASE_REQUEST_STATE_STARTED: {
+		struct ssp_frame_hdr ssp_hdr;
+		void *frame_header;
+
+		scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+							      frame_index,
+							      &frame_header);
+
+		word_cnt = sizeof(struct ssp_frame_hdr) / sizeof(u32);
+		sci_swab32_cpy(&ssp_hdr, frame_header, word_cnt);
+
+		if (ssp_hdr.frame_type == SSP_RESPONSE) {
+			struct ssp_response_iu *resp_iu;
+			ssize_t word_cnt = SSP_RESP_IU_MAX_SIZE / sizeof(u32);
+
+			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+								      frame_index,
+								      (void **)&resp_iu);
+
+			sci_swab32_cpy(&sci_req->ssp.rsp, resp_iu, word_cnt);
+
+			resp_iu = &sci_req->ssp.rsp;
+
+			if (resp_iu->datapres == 0x01 ||
+			    resp_iu->datapres == 0x02) {
+				scic_sds_request_set_status(sci_req,
+							    SCU_TASK_DONE_CHECK_RESPONSE,
+							    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
+			} else
+				scic_sds_request_set_status(sci_req,
+							    SCU_TASK_DONE_GOOD,
+							    SCI_SUCCESS);
+		} else {
+			/* not a response frame, why did it get forwarded? */
+			dev_err(scic_to_dev(scic),
+				"%s: SCIC IO Request 0x%p received unexpected "
+				"frame %d type 0x%02x\n", __func__, sci_req,
+				frame_index, ssp_hdr.frame_type);
+		}
+
+		/*
+		 * In any case we are done with this frame buffer return it to the
+		 * controller
+		 */
+		scic_sds_controller_release_frame(scic, frame_index);
+
+		return SCI_SUCCESS;
+	}
+	case SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE:
+		scic_sds_io_request_copy_response(sci_req);
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		scic_sds_controller_release_frame(scic,frame_index);
+		return SCI_SUCCESS;
+	case SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE: {
+		struct smp_resp *rsp_hdr = &sci_req->smp.rsp;
+		void *frame_header;
+
+		scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+							      frame_index,
+							      &frame_header);
+
+		/* byte swap the header. */
+		word_cnt = SMP_RESP_HDR_SZ / sizeof(u32);
+		sci_swab32_cpy(rsp_hdr, frame_header, word_cnt);
+
+		if (rsp_hdr->frame_type == SMP_RESPONSE) {
+			void *smp_resp;
+
+			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+								      frame_index,
+								      &smp_resp);
+
+			word_cnt = (sizeof(struct smp_req) - SMP_RESP_HDR_SZ) /
+				sizeof(u32);
+
+			sci_swab32_cpy(((u8 *) rsp_hdr) + SMP_RESP_HDR_SZ,
+				       smp_resp, word_cnt);
+
+			scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
+						    SCI_SUCCESS);
+
+			sci_base_state_machine_change_state(&sci_req->state_machine,
+							    SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION);
+		} else {
+			/* This was not a response frame why did it get forwarded? */
+			dev_err(scic_to_dev(scic),
+				"%s: SCIC SMP Request 0x%p received unexpected frame "
+				"%d type 0x%02x\n", __func__, sci_req,
+				frame_index, rsp_hdr->frame_type);
+
+			scic_sds_request_set_status(sci_req,
+						    SCU_TASK_DONE_SMP_FRM_TYPE_ERR,
+						    SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
+
+			sci_base_state_machine_change_state(&sci_req->state_machine,
+							    SCI_BASE_REQUEST_STATE_COMPLETED);
+		}
+
+		scic_sds_controller_release_frame(scic, frame_index);
+
+		return SCI_SUCCESS;
+	}
+	case SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE:
+		return scic_sds_stp_request_udma_general_frame_handler(sci_req, frame_index);
+	case SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE:
+		/* Use the general frame handler to copy the resposne data */
+		status = scic_sds_stp_request_udma_general_frame_handler(sci_req, frame_index);
+
+		if (status != SCI_SUCCESS)
+			return status;
+
+		scic_sds_stp_request_udma_complete_request(sci_req,
+							   SCU_TASK_DONE_CHECK_RESPONSE,
+							   SCI_FAILURE_IO_RESPONSE_VALID);
+		return SCI_SUCCESS;
+	case SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE: {
+		struct dev_to_host_fis *frame_header;
+		u32 *frame_buffer;
+
+		status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+								       frame_index,
+								       (void **)&frame_header);
+
+		if (status != SCI_SUCCESS) {
+			dev_err(scic_to_dev(scic),
+				"%s: SCIC IO Request 0x%p could not get frame header "
+				"for frame index %d, status %x\n",
+				__func__, stp_req, frame_index, status);
+
+			return status;
+		}
+
+		switch (frame_header->fis_type) {
+		case FIS_REGD2H:
+			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+								      frame_index,
+								      (void **)&frame_buffer);
+
+			scic_sds_controller_copy_sata_response(&sci_req->stp.rsp,
+							       frame_header,
+							       frame_buffer);
+
+			/* The command has completed with error */
+			scic_sds_request_set_status(sci_req, SCU_TASK_DONE_CHECK_RESPONSE,
+						    SCI_FAILURE_IO_RESPONSE_VALID);
+			break;
+
+		default:
+			dev_warn(scic_to_dev(scic),
+				 "%s: IO Request:0x%p Frame Id:%d protocol "
+				  "violation occurred\n", __func__, stp_req,
+				  frame_index);
+
+			scic_sds_request_set_status(sci_req, SCU_TASK_DONE_UNEXP_FIS,
+						    SCI_FAILURE_PROTOCOL_VIOLATION);
+			break;
+		}
+
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
+
+		/* Frame has been decoded return it to the controller */
+		scic_sds_controller_release_frame(scic, frame_index);
+
+		return status;
+	}
+	case SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE: {
+		struct isci_request *ireq = sci_req_to_ireq(sci_req);
+		struct sas_task *task = isci_request_access_task(ireq);
+		struct dev_to_host_fis *frame_header;
+		u32 *frame_buffer;
+
+		status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+								       frame_index,
+								       (void **)&frame_header);
+
+		if (status != SCI_SUCCESS) {
+			dev_err(scic_to_dev(scic),
+				"%s: SCIC IO Request 0x%p could not get frame header "
+				"for frame index %d, status %x\n",
+				__func__, stp_req, frame_index, status);
+			return status;
+		}
+
+		switch (frame_header->fis_type) {
+		case FIS_PIO_SETUP:
+			/* Get from the frame buffer the PIO Setup Data */
+			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+								      frame_index,
+								      (void **)&frame_buffer);
+
+			/* Get the data from the PIO Setup The SCU Hardware returns
+			 * first word in the frame_header and the rest of the data is in
+			 * the frame buffer so we need to back up one dword
+			 */
+
+			/* transfer_count: first 16bits in the 4th dword */
+			stp_req->type.pio.pio_transfer_bytes = frame_buffer[3] & 0xffff;
+
+			/* ending_status: 4th byte in the 3rd dword */
+			stp_req->type.pio.ending_status = (frame_buffer[2] >> 24) & 0xff;
+
+			scic_sds_controller_copy_sata_response(&sci_req->stp.rsp,
+							       frame_header,
+							       frame_buffer);
+
+			sci_req->stp.rsp.status = stp_req->type.pio.ending_status;
+
+			/* The next state is dependent on whether the
+			 * request was PIO Data-in or Data out
+			 */
+			if (task->data_dir == DMA_FROM_DEVICE) {
+				sci_base_state_machine_change_state(&sci_req->state_machine,
+								    SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE);
+			} else if (task->data_dir == DMA_TO_DEVICE) {
+				/* Transmit data */
+				status = scic_sds_stp_request_pio_data_out_transmit_data(sci_req);
+				if (status != SCI_SUCCESS)
+					break;
+				sci_base_state_machine_change_state(&sci_req->state_machine,
+								    SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE);
+			}
+			break;
+		case FIS_SETDEVBITS:
+			sci_base_state_machine_change_state(&sci_req->state_machine,
+							    SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE);
+			break;
+		case FIS_REGD2H:
+			if (frame_header->status & ATA_BUSY) {
+				/* Now why is the drive sending a D2H Register FIS when
+				 * it is still busy?  Do nothing since we are still in
+				 * the right state.
+				 */
+				dev_dbg(scic_to_dev(scic),
+					"%s: SCIC PIO Request 0x%p received "
+					"D2H Register FIS with BSY status "
+					"0x%x\n", __func__, stp_req,
+					frame_header->status);
+				break;
+			}
+
+			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+								      frame_index,
+								      (void **)&frame_buffer);
+
+			scic_sds_controller_copy_sata_response(&sci_req->stp.req,
+							       frame_header,
+							       frame_buffer);
+
+			scic_sds_request_set_status(sci_req,
+						    SCU_TASK_DONE_CHECK_RESPONSE,
+						    SCI_FAILURE_IO_RESPONSE_VALID);
+
+			sci_base_state_machine_change_state(&sci_req->state_machine,
+							    SCI_BASE_REQUEST_STATE_COMPLETED);
+			break;
+		default:
+			/* FIXME: what do we do here? */
+			break;
+		}
+
+		/* Frame is decoded return it to the controller */
+		scic_sds_controller_release_frame(scic, frame_index);
+
+		return status;
+	}
+	case SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE: {
+		struct dev_to_host_fis *frame_header;
+		struct sata_fis_data *frame_buffer;
+
+		status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+								       frame_index,
+								       (void **)&frame_header);
+
+		if (status != SCI_SUCCESS) {
+			dev_err(scic_to_dev(scic),
+				"%s: SCIC IO Request 0x%p could not get frame header "
+				"for frame index %d, status %x\n",
+				__func__, stp_req, frame_index, status);
+			return status;
+		}
+
+		if (frame_header->fis_type != FIS_DATA) {
+			dev_err(scic_to_dev(scic),
+				"%s: SCIC PIO Request 0x%p received frame %d "
+				"with fis type 0x%02x when expecting a data "
+				"fis.\n", __func__, stp_req, frame_index,
+				frame_header->fis_type);
+
+			scic_sds_request_set_status(sci_req,
+						    SCU_TASK_DONE_GOOD,
+						    SCI_FAILURE_IO_REQUIRES_SCSI_ABORT);
+
+			sci_base_state_machine_change_state(&sci_req->state_machine,
+							    SCI_BASE_REQUEST_STATE_COMPLETED);
+
+			/* Frame is decoded return it to the controller */
+			scic_sds_controller_release_frame(scic, frame_index);
+			return status;
+		}
+
+		if (stp_req->type.pio.request_current.sgl_pair == NULL) {
+			sci_req->saved_rx_frame_index = frame_index;
+			stp_req->type.pio.pio_transfer_bytes = 0;
+		} else {
+			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+								      frame_index,
+								      (void **)&frame_buffer);
+
+			status = scic_sds_stp_request_pio_data_in_copy_data(stp_req,
+									    (u8 *)frame_buffer);
+
+			/* Frame is decoded return it to the controller */
+			scic_sds_controller_release_frame(scic, frame_index);
+		}
+
+		/* Check for the end of the transfer, are there more
+		 * bytes remaining for this data transfer
+		 */
+		if (status != SCI_SUCCESS ||
+		    stp_req->type.pio.pio_transfer_bytes != 0)
+			return status;
+
+		if ((stp_req->type.pio.ending_status & ATA_BUSY) == 0) {
+			scic_sds_request_set_status(sci_req,
+						    SCU_TASK_DONE_CHECK_RESPONSE,
+						    SCI_FAILURE_IO_RESPONSE_VALID);
+
+			sci_base_state_machine_change_state(&sci_req->state_machine,
+							    SCI_BASE_REQUEST_STATE_COMPLETED);
+		} else {
+			sci_base_state_machine_change_state(&sci_req->state_machine,
+							    SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE);
+		}
+		return status;
+	}
+	case SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE: {
+		struct dev_to_host_fis *frame_header;
+		u32 *frame_buffer;
+
+		status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+								       frame_index,
+								       (void **)&frame_header);
+		if (status != SCI_SUCCESS) {
+			dev_err(scic_to_dev(scic),
+				"%s: SCIC IO Request 0x%p could not get frame header "
+				"for frame index %d, status %x\n",
+				__func__, stp_req, frame_index, status);
+			return status;
+		}
+
+		switch (frame_header->fis_type) {
+		case FIS_REGD2H:
+			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+								      frame_index,
+								      (void **)&frame_buffer);
+
+			scic_sds_controller_copy_sata_response(&sci_req->stp.rsp,
+							       frame_header,
+							       frame_buffer);
+
+			/* The command has completed with error */
+			scic_sds_request_set_status(sci_req,
+						    SCU_TASK_DONE_CHECK_RESPONSE,
+						    SCI_FAILURE_IO_RESPONSE_VALID);
+			break;
+		default:
+			dev_warn(scic_to_dev(scic),
+				 "%s: IO Request:0x%p Frame Id:%d protocol "
+				 "violation occurred\n", __func__, stp_req,
+				 frame_index);
+
+			scic_sds_request_set_status(sci_req, SCU_TASK_DONE_UNEXP_FIS,
+						    SCI_FAILURE_PROTOCOL_VIOLATION);
+			break;
+		}
+
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
+
+		/* Frame has been decoded return it to the controller */
+		scic_sds_controller_release_frame(scic, frame_index);
+
+		return status;
+	}
+	case SCI_BASE_REQUEST_STATE_ABORTING:
+		/* TODO: Is it even possible to get an unsolicited frame in the
+		 * aborting state?
+		 */
+		scic_sds_controller_release_frame(scic, frame_index);
+		return SCI_SUCCESS;
+	default:
+		dev_warn(scic_to_dev(scic),
+			 "%s: SCIC IO Request given unexpected frame %x while in "
+			 "state %d\n", __func__, frame_index, state);
+
+		scic_sds_controller_release_frame(scic, frame_index);
+		return SCI_FAILURE_INVALID_STATE;
+	}
+}
+
+
+
+
 static enum sci_status scic_sds_stp_request_udma_await_tc_completion_tc_completion_handler(
 	struct scic_sds_request *sci_req,
 	u32 completion_code)
@@ -2336,32 +2268,6 @@ static enum sci_status scic_sds_stp_request_udma_await_tc_completion_tc_completi
 	return status;
 }
 
-static enum sci_status scic_sds_stp_request_udma_await_d2h_reg_fis_frame_handler(
-	struct scic_sds_request *sci_req,
-	u32 frame_index)
-{
-	enum sci_status status;
-
-	/* Use the general frame handler to copy the resposne data */
-	status = scic_sds_stp_request_udma_general_frame_handler(sci_req, frame_index);
-
-	if (status != SCI_SUCCESS)
-		return status;
-
-	scic_sds_stp_request_udma_complete_request(sci_req,
-						   SCU_TASK_DONE_CHECK_RESPONSE,
-						   SCI_FAILURE_IO_RESPONSE_VALID);
-
-	return status;
-}
-
-enum sci_status scic_sds_stp_udma_request_construct(struct scic_sds_request *sci_req,
-						    u32 len,
-						    enum dma_data_direction dir)
-{
-	return SCI_SUCCESS;
-}
-
 /**
  *
  * @sci_req:
@@ -2447,117 +2353,36 @@ static enum sci_status scic_sds_stp_request_soft_reset_await_h2d_diagnostic_tc_c
 	return SCI_SUCCESS;
 }
 
-/**
- *
- * @request: This parameter specifies the request for which a frame has been
- *    received.
- * @frame_index: This parameter specifies the index of the frame that has been
- *    received.
- *
- * This method processes frames received from the target while waiting for a
- * device to host register FIS.  If a non-register FIS is received during this
- * time, it is treated as a protocol violation from an IO perspective. Indicate
- * if the received frame was processed successfully.
- */
-static enum sci_status scic_sds_stp_request_soft_reset_await_d2h_frame_handler(
-	struct scic_sds_request *sci_req,
-	u32 frame_index)
-{
-	enum sci_status status;
-	struct dev_to_host_fis *frame_header;
-	u32 *frame_buffer;
-	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
-	struct scic_sds_controller *scic = sci_req->owning_controller;
-
-	status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
-							       frame_index,
-							       (void **)&frame_header);
-	if (status != SCI_SUCCESS) {
-		dev_err(scic_to_dev(scic),
-			"%s: SCIC IO Request 0x%p could not get frame header "
-			"for frame index %d, status %x\n",
-			__func__, stp_req, frame_index, status);
-		return status;
-	}
-
-	switch (frame_header->fis_type) {
-	case FIS_REGD2H:
-		scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
-							      frame_index,
-							      (void **)&frame_buffer);
-
-		scic_sds_controller_copy_sata_response(&sci_req->stp.rsp,
-						       frame_header,
-						       frame_buffer);
-
-		/* The command has completed with error */
-		scic_sds_request_set_status(sci_req,
-					    SCU_TASK_DONE_CHECK_RESPONSE,
-					    SCI_FAILURE_IO_RESPONSE_VALID);
-		break;
-
-	default:
-		dev_warn(scic_to_dev(scic),
-			 "%s: IO Request:0x%p Frame Id:%d protocol "
-			 "violation occurred\n", __func__, stp_req,
-			 frame_index);
-
-		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_UNEXP_FIS,
-					    SCI_FAILURE_PROTOCOL_VIOLATION);
-		break;
-	}
-
-	sci_base_state_machine_change_state(&sci_req->state_machine,
-					    SCI_BASE_REQUEST_STATE_COMPLETED);
-
-	/* Frame has been decoded return it to the controller */
-	scic_sds_controller_release_frame(scic, frame_index);
-
-	return status;
-}
-
 static const struct scic_sds_io_request_state_handler scic_sds_request_state_handler_table[] = {
 	[SCI_BASE_REQUEST_STATE_INITIAL] = {},
 	[SCI_BASE_REQUEST_STATE_CONSTRUCTED] = {},
 	[SCI_BASE_REQUEST_STATE_STARTED] = {
 		.tc_completion_handler	= scic_sds_request_started_state_tc_completion_handler,
-		.frame_handler		= scic_sds_request_started_state_frame_handler,
 	},
 	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION] = {
 		.tc_completion_handler	= scic_sds_ssp_task_request_await_tc_completion_tc_completion_handler,
 	},
-	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE] = {
-		.frame_handler		= scic_sds_ssp_task_request_await_tc_response_frame_handler,
-	},
+	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE] = { },
 	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE] = {
 		.tc_completion_handler	= scic_sds_smp_request_await_response_tc_completion_handler,
-		.frame_handler		= scic_sds_smp_request_await_response_frame_handler,
 	},
 	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION] = {
 		.tc_completion_handler	=  scic_sds_smp_request_await_tc_completion_tc_completion_handler,
 	},
 	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE] = {
 		.tc_completion_handler	= scic_sds_stp_request_udma_await_tc_completion_tc_completion_handler,
-		.frame_handler		= scic_sds_stp_request_udma_general_frame_handler,
-	},
-	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE] = {
-		.frame_handler		= scic_sds_stp_request_udma_await_d2h_reg_fis_frame_handler,
 	},
+	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE] = { },
 	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE] = {
 		.tc_completion_handler	= scic_sds_stp_request_non_data_await_h2d_tc_completion_handler,
 	},
-	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE] = {
-		.frame_handler		= scic_sds_stp_request_non_data_await_d2h_frame_handler,
-	},
+	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE] = { },
 	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE] = {
 		.tc_completion_handler	= scic_sds_stp_request_pio_await_h2d_completion_tc_completion_handler,
 	},
-	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE] = {
-		.frame_handler		= scic_sds_stp_request_pio_await_frame_frame_handler
-	},
+	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE] = { },
 	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE] = {
 		.event_handler		= scic_sds_stp_request_pio_data_in_await_data_event_handler,
-		.frame_handler		= scic_sds_stp_request_pio_data_in_await_data_frame_handler
 	},
 	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE] = {
 		.tc_completion_handler	= scic_sds_stp_request_pio_data_out_await_data_transmit_completion_tc_completion_handler,
@@ -2568,15 +2393,12 @@ static const struct scic_sds_io_request_state_handler scic_sds_request_state_han
 	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE] = {
 		.tc_completion_handler	= scic_sds_stp_request_soft_reset_await_h2d_diagnostic_tc_completion_handler,
 	},
-	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE] = {
-		.frame_handler		= scic_sds_stp_request_soft_reset_await_d2h_frame_handler,
-	},
+	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE] = { },
 	[SCI_BASE_REQUEST_STATE_COMPLETED] = {
 		.complete_handler	= scic_sds_request_completed_state_complete_handler,
 	},
 	[SCI_BASE_REQUEST_STATE_ABORTING] = {
 		.tc_completion_handler	= scic_sds_request_aborting_state_tc_completion_handler,
-		.frame_handler		= scic_sds_request_aborting_state_frame_handler,
 	},
 	[SCI_BASE_REQUEST_STATE_FINAL] = { },
 };

commit f4636a7b2ab8288466b83a8459d47c43143a70dc
Author: Piotr Sawicki <piotr.sawicki@intel.com>
Date:   Tue May 10 23:50:32 2011 +0000

    isci: unify request start handlers
    
    Unify the implementation in scic_sds_request_start and kill the state
    handler.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Piotr Sawicki <piotr.sawicki@intel.com>
    [remove scic_sds_request_constructed_state_start_handler]
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 69688636347e..41a418d8b337 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -757,23 +757,80 @@ static u32 sci_req_tx_bytes(struct scic_sds_request *sci_req)
 	return ret_val;
 }
 
-enum sci_status
-scic_sds_request_start(struct scic_sds_request *request)
+enum sci_status scic_sds_request_start(struct scic_sds_request *sci_req)
 {
-	if (request->device_sequence !=
-	    scic_sds_remote_device_get_sequence(request->target_device))
+	struct scic_sds_controller *scic = sci_req->owning_controller;
+	struct scu_task_context *task_context;
+	enum sci_base_request_states state;
+
+	if (sci_req->device_sequence !=
+	    scic_sds_remote_device_get_sequence(sci_req->target_device))
 		return SCI_FAILURE;
 
-	if (request->state_handlers->start_handler)
-		return request->state_handlers->start_handler(request);
+	state = sci_req->state_machine.current_state_id;
+	if (state != SCI_BASE_REQUEST_STATE_CONSTRUCTED) {
+		dev_warn(scic_to_dev(scic),
+			"%s: SCIC IO Request requested to start while in wrong "
+			 "state %d\n", __func__, state);
+		return SCI_FAILURE_INVALID_STATE;
+	}
 
-	dev_warn(scic_to_dev(request->owning_controller),
-		 "%s: SCIC IO Request requested to start while in wrong "
-		 "state %d\n",
-		 __func__,
-		 sci_base_state_machine_get_state(&request->state_machine));
+	/* if necessary, allocate a TCi for the io request object and then will,
+	 * if necessary, copy the constructed TC data into the actual TC buffer.
+	 * If everything is successful the post context field is updated with
+	 * the TCi so the controller can post the request to the hardware.
+	 */
+	if (sci_req->io_tag == SCI_CONTROLLER_INVALID_IO_TAG)
+		sci_req->io_tag = scic_controller_allocate_io_tag(scic);
 
-	return SCI_FAILURE_INVALID_STATE;
+	/* Record the IO Tag in the request */
+	if (sci_req->io_tag != SCI_CONTROLLER_INVALID_IO_TAG) {
+		task_context = sci_req->task_context_buffer;
+
+		task_context->task_index = scic_sds_io_tag_get_index(sci_req->io_tag);
+
+		switch (task_context->protocol_type) {
+		case SCU_TASK_CONTEXT_PROTOCOL_SMP:
+		case SCU_TASK_CONTEXT_PROTOCOL_SSP:
+			/* SSP/SMP Frame */
+			task_context->type.ssp.tag = sci_req->io_tag;
+			task_context->type.ssp.target_port_transfer_tag =
+				0xFFFF;
+			break;
+
+		case SCU_TASK_CONTEXT_PROTOCOL_STP:
+			/* STP/SATA Frame
+			 * task_context->type.stp.ncq_tag = sci_req->ncq_tag;
+			 */
+			break;
+
+		case SCU_TASK_CONTEXT_PROTOCOL_NONE:
+			/* / @todo When do we set no protocol type? */
+			break;
+
+		default:
+			/* This should never happen since we build the IO
+			 * requests */
+			break;
+		}
+
+		/*
+		 * Check to see if we need to copy the task context buffer
+		 * or have been building into the task context buffer */
+		if (sci_req->was_tag_assigned_by_user == false)
+			scic_sds_controller_copy_task_context(scic, sci_req);
+
+		/* Add to the post_context the io tag value */
+		sci_req->post_context |= scic_sds_io_tag_get_index(sci_req->io_tag);
+
+		/* Everything is good go ahead and change state */
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_STARTED);
+
+		return SCI_SUCCESS;
+	}
+
+	return SCI_FAILURE_INSUFFICIENT_RESOURCES;
 }
 
 enum sci_status
@@ -903,75 +960,6 @@ static void scic_sds_io_request_copy_response(struct scic_sds_request *sci_req)
 	memcpy(resp_buf, ssp_response->resp_data, len);
 }
 
-/*
- * This method implements the action taken when a constructed
- * SCIC_SDS_IO_REQUEST_T object receives a scic_sds_request_start() request.
- * This method will, if necessary, allocate a TCi for the io request object and
- * then will, if necessary, copy the constructed TC data into the actual TC
- * buffer.  If everything is successful the post context field is updated with
- * the TCi so the controller can post the request to the hardware. enum sci_status
- * SCI_SUCCESS SCI_FAILURE_INSUFFICIENT_RESOURCES
- */
-static enum sci_status scic_sds_request_constructed_state_start_handler(
-	struct scic_sds_request *request)
-{
-	struct scu_task_context *task_context;
-
-	if (request->io_tag == SCI_CONTROLLER_INVALID_IO_TAG) {
-		request->io_tag =
-			scic_controller_allocate_io_tag(request->owning_controller);
-	}
-
-	/* Record the IO Tag in the request */
-	if (request->io_tag != SCI_CONTROLLER_INVALID_IO_TAG) {
-		task_context = request->task_context_buffer;
-
-		task_context->task_index = scic_sds_io_tag_get_index(request->io_tag);
-
-		switch (task_context->protocol_type) {
-		case SCU_TASK_CONTEXT_PROTOCOL_SMP:
-		case SCU_TASK_CONTEXT_PROTOCOL_SSP:
-			/* SSP/SMP Frame */
-			task_context->type.ssp.tag = request->io_tag;
-			task_context->type.ssp.target_port_transfer_tag = 0xFFFF;
-			break;
-
-		case SCU_TASK_CONTEXT_PROTOCOL_STP:
-			/*
-			 * STP/SATA Frame
-			 * task_context->type.stp.ncq_tag = request->ncq_tag; */
-			break;
-
-		case SCU_TASK_CONTEXT_PROTOCOL_NONE:
-			/* / @todo When do we set no protocol type? */
-			break;
-
-		default:
-			/* This should never happen since we build the IO requests */
-			break;
-		}
-
-		/*
-		 * Check to see if we need to copy the task context buffer
-		 * or have been building into the task context buffer */
-		if (request->was_tag_assigned_by_user == false) {
-			scic_sds_controller_copy_task_context(
-				request->owning_controller, request);
-		}
-
-		/* Add to the post_context the io tag value */
-		request->post_context |= scic_sds_io_tag_get_index(request->io_tag);
-
-		/* Everything is good go ahead and change state */
-		sci_base_state_machine_change_state(&request->state_machine,
-						    SCI_BASE_REQUEST_STATE_STARTED);
-
-		return SCI_SUCCESS;
-	}
-
-	return SCI_FAILURE_INSUFFICIENT_RESOURCES;
-}
-
 /*
  * scic_sds_request_started_state_tc_completion_handler() - This method process
  *    TC (task context) completions for normal IO request (i.e. Task/Abort
@@ -2529,10 +2517,8 @@ static enum sci_status scic_sds_stp_request_soft_reset_await_d2h_frame_handler(
 }
 
 static const struct scic_sds_io_request_state_handler scic_sds_request_state_handler_table[] = {
-	[SCI_BASE_REQUEST_STATE_INITIAL] = { },
-	[SCI_BASE_REQUEST_STATE_CONSTRUCTED] = {
-		.start_handler		= scic_sds_request_constructed_state_start_handler,
-	},
+	[SCI_BASE_REQUEST_STATE_INITIAL] = {},
+	[SCI_BASE_REQUEST_STATE_CONSTRUCTED] = {},
 	[SCI_BASE_REQUEST_STATE_STARTED] = {
 		.tc_completion_handler	= scic_sds_request_started_state_tc_completion_handler,
 		.frame_handler		= scic_sds_request_started_state_frame_handler,

commit f00e6ba4996a34f098fe50c78077f0568fd838ec
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue May 10 02:39:11 2011 -0700

    isci: unify request abort handlers
    
    Unify the implementation in scic_sds_io_request_terminate and kill the state
    handler.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index f503e3e18d8f..69688636347e 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -777,16 +777,58 @@ scic_sds_request_start(struct scic_sds_request *request)
 }
 
 enum sci_status
-scic_sds_io_request_terminate(struct scic_sds_request *request)
+scic_sds_io_request_terminate(struct scic_sds_request *sci_req)
 {
-	if (request->state_handlers->abort_handler)
-		return request->state_handlers->abort_handler(request);
+	enum sci_base_request_states state;
 
-	dev_warn(scic_to_dev(request->owning_controller),
-		"%s: SCIC IO Request requested to abort while in wrong "
-		"state %d\n",
-		__func__,
-		sci_base_state_machine_get_state(&request->state_machine));
+	state = sci_req->state_machine.current_state_id;
+
+	switch (state) {
+	case SCI_BASE_REQUEST_STATE_CONSTRUCTED:
+		scic_sds_request_set_status(sci_req,
+			SCU_TASK_DONE_TASK_ABORT,
+			SCI_FAILURE_IO_TERMINATED);
+
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		return SCI_SUCCESS;
+	case SCI_BASE_REQUEST_STATE_STARTED:
+	case SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION:
+	case SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE:
+	case SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION:
+	case SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE:
+	case SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE:
+	case SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE:
+	case SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE:
+	case SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE:
+	case SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE:
+	case SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE:
+	case SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE:
+	case SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_ASSERTED_COMPLETION_SUBSTATE:
+	case SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE:
+	case SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE:
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_ABORTING);
+		return SCI_SUCCESS;
+	case SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE:
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_ABORTING);
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		return SCI_SUCCESS;
+	case SCI_BASE_REQUEST_STATE_ABORTING:
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		return SCI_SUCCESS;
+	case SCI_BASE_REQUEST_STATE_COMPLETED:
+	default:
+		dev_warn(scic_to_dev(sci_req->owning_controller),
+			 "%s: SCIC IO Request requested to abort while in wrong "
+			 "state %d\n",
+			 __func__,
+			 sci_base_state_machine_get_state(&sci_req->state_machine));
+		break;
+	}
 
 	return SCI_FAILURE_INVALID_STATE;
 }
@@ -930,34 +972,6 @@ static enum sci_status scic_sds_request_constructed_state_start_handler(
 	return SCI_FAILURE_INSUFFICIENT_RESOURCES;
 }
 
-/*
- * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
- * object receives a scic_sds_request_terminate() request. Since the request
- * has not yet been posted to the hardware the request transitions to the
- * completed state. enum sci_status SCI_SUCCESS
- */
-static enum sci_status scic_sds_request_constructed_state_abort_handler(
-	struct scic_sds_request *request)
-{
-	/*
-	 * This request has been terminated by the user make sure that the correct
-	 * status code is returned */
-	scic_sds_request_set_status(request,
-		SCU_TASK_DONE_TASK_ABORT,
-		SCI_FAILURE_IO_TERMINATED);
-
-	sci_base_state_machine_change_state(&request->state_machine,
-					    SCI_BASE_REQUEST_STATE_COMPLETED);
-	return SCI_SUCCESS;
-}
-
-static enum sci_status scic_sds_request_started_state_abort_handler(struct scic_sds_request *sci_req)
-{
-	sci_base_state_machine_change_state(&sci_req->state_machine,
-					    SCI_BASE_REQUEST_STATE_ABORTING);
-	return SCI_SUCCESS;
-}
-
 /*
  * scic_sds_request_started_state_tc_completion_handler() - This method process
  *    TC (task context) completions for normal IO request (i.e. Task/Abort
@@ -1247,26 +1261,6 @@ static enum sci_status scic_sds_request_completed_state_complete_handler(
 	return SCI_SUCCESS;
 }
 
-/*
- * *****************************************************************************
- * *  ABORTING STATE HANDLERS
- * ***************************************************************************** */
-
-/*
- * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
- * object receives a scic_sds_request_terminate() request. This method is the
- * io request aborting state abort handlers.  On receipt of a multiple
- * terminate requests the io request will transition to the completed state.
- * This should not happen in normal operation. enum sci_status SCI_SUCCESS
- */
-static enum sci_status scic_sds_request_aborting_state_abort_handler(
-	struct scic_sds_request *request)
-{
-	sci_base_state_machine_change_state(&request->state_machine,
-					    SCI_BASE_REQUEST_STATE_COMPLETED);
-	return SCI_SUCCESS;
-}
-
 /*
  * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
  * object receives a scic_sds_request_task_completion() request. This method
@@ -1378,28 +1372,6 @@ static enum sci_status scic_sds_ssp_task_request_await_tc_completion_tc_completi
 	return SCI_SUCCESS;
 }
 
-/**
- * This method is responsible for processing a terminate/abort request for this
- *    TC while the request is waiting for the task management response
- *    unsolicited frame.
- * @sci_req: This parameter specifies the request for which the
- *    termination was requested.
- *
- * This method returns an indication as to whether the abort request was
- * successfully handled. need to update to ensure the received UF doesn't cause
- * damage to subsequent requests (i.e. put the extended tag in a holding
- * pattern for this particular device).
- */
-static enum sci_status scic_sds_ssp_task_request_await_tc_response_abort_handler(
-	struct scic_sds_request *request)
-{
-	sci_base_state_machine_change_state(&request->state_machine,
-					    SCI_BASE_REQUEST_STATE_ABORTING);
-	sci_base_state_machine_change_state(&request->state_machine,
-					    SCI_BASE_REQUEST_STATE_COMPLETED);
-	return SCI_SUCCESS;
-}
-
 /**
  * This method processes an unsolicited frame while the task mgmt request is
  *    waiting for a response frame.  It will copy the response data, release
@@ -2560,81 +2532,63 @@ static const struct scic_sds_io_request_state_handler scic_sds_request_state_han
 	[SCI_BASE_REQUEST_STATE_INITIAL] = { },
 	[SCI_BASE_REQUEST_STATE_CONSTRUCTED] = {
 		.start_handler		= scic_sds_request_constructed_state_start_handler,
-		.abort_handler		= scic_sds_request_constructed_state_abort_handler,
 	},
 	[SCI_BASE_REQUEST_STATE_STARTED] = {
-		.abort_handler		= scic_sds_request_started_state_abort_handler,
 		.tc_completion_handler	= scic_sds_request_started_state_tc_completion_handler,
 		.frame_handler		= scic_sds_request_started_state_frame_handler,
 	},
 	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION] = {
-		.abort_handler		= scic_sds_request_started_state_abort_handler,
 		.tc_completion_handler	= scic_sds_ssp_task_request_await_tc_completion_tc_completion_handler,
 	},
 	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE] = {
-		.abort_handler		= scic_sds_ssp_task_request_await_tc_response_abort_handler,
 		.frame_handler		= scic_sds_ssp_task_request_await_tc_response_frame_handler,
 	},
 	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE] = {
-		.abort_handler		= scic_sds_request_started_state_abort_handler,
 		.tc_completion_handler	= scic_sds_smp_request_await_response_tc_completion_handler,
 		.frame_handler		= scic_sds_smp_request_await_response_frame_handler,
 	},
 	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION] = {
-		.abort_handler		= scic_sds_request_started_state_abort_handler,
 		.tc_completion_handler	=  scic_sds_smp_request_await_tc_completion_tc_completion_handler,
 	},
 	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE] = {
-		.abort_handler		= scic_sds_request_started_state_abort_handler,
 		.tc_completion_handler	= scic_sds_stp_request_udma_await_tc_completion_tc_completion_handler,
 		.frame_handler		= scic_sds_stp_request_udma_general_frame_handler,
 	},
 	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE] = {
-		.abort_handler		= scic_sds_request_started_state_abort_handler,
 		.frame_handler		= scic_sds_stp_request_udma_await_d2h_reg_fis_frame_handler,
 	},
 	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE] = {
-		.abort_handler		= scic_sds_request_started_state_abort_handler,
 		.tc_completion_handler	= scic_sds_stp_request_non_data_await_h2d_tc_completion_handler,
 	},
 	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE] = {
-		.abort_handler		= scic_sds_request_started_state_abort_handler,
 		.frame_handler		= scic_sds_stp_request_non_data_await_d2h_frame_handler,
 	},
 	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE] = {
-		.abort_handler		= scic_sds_request_started_state_abort_handler,
 		.tc_completion_handler	= scic_sds_stp_request_pio_await_h2d_completion_tc_completion_handler,
 	},
 	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE] = {
-		.abort_handler		= scic_sds_request_started_state_abort_handler,
 		.frame_handler		= scic_sds_stp_request_pio_await_frame_frame_handler
 	},
 	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE] = {
-		.abort_handler		= scic_sds_request_started_state_abort_handler,
 		.event_handler		= scic_sds_stp_request_pio_data_in_await_data_event_handler,
 		.frame_handler		= scic_sds_stp_request_pio_data_in_await_data_frame_handler
 	},
 	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE] = {
-		.abort_handler		= scic_sds_request_started_state_abort_handler,
 		.tc_completion_handler	= scic_sds_stp_request_pio_data_out_await_data_transmit_completion_tc_completion_handler,
 	},
 	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_ASSERTED_COMPLETION_SUBSTATE] = {
-		.abort_handler		= scic_sds_request_started_state_abort_handler,
 		.tc_completion_handler	= scic_sds_stp_request_soft_reset_await_h2d_asserted_tc_completion_handler,
 	},
 	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE] = {
-		.abort_handler		= scic_sds_request_started_state_abort_handler,
 		.tc_completion_handler	= scic_sds_stp_request_soft_reset_await_h2d_diagnostic_tc_completion_handler,
 	},
 	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE] = {
-		.abort_handler		= scic_sds_request_started_state_abort_handler,
 		.frame_handler		= scic_sds_stp_request_soft_reset_await_d2h_frame_handler,
 	},
 	[SCI_BASE_REQUEST_STATE_COMPLETED] = {
 		.complete_handler	= scic_sds_request_completed_state_complete_handler,
 	},
 	[SCI_BASE_REQUEST_STATE_ABORTING] = {
-		.abort_handler		= scic_sds_request_aborting_state_abort_handler,
 		.tc_completion_handler	= scic_sds_request_aborting_state_tc_completion_handler,
 		.frame_handler		= scic_sds_request_aborting_state_frame_handler,
 	},

commit 5dec6f4e41340196d223caf922578c44dfe2295a
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue May 10 02:28:49 2011 -0700

    isci: merge stp request substates into primary state machine
    
    Remove usage of the request substate machine for stp requests, and kill
    the request substate infrastructure.
    
    Similar to the previous conversions this adds the substates to the
    primary state machine and arranges for the 'started' state to transition
    to the proper stp substate.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 5201dc58a191..f503e3e18d8f 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -58,6 +58,7 @@
 #include "request.h"
 #include "sata.h"
 #include "scu_completion_codes.h"
+#include "scu_event_codes.h"
 #include "sas.h"
 
 /**
@@ -92,7 +93,7 @@ static struct scu_sgl_element_pair *scic_sds_request_get_sgl_element_pair(
  *    the Scatter-Gather List.
  *
  */
-void scic_sds_request_build_sgl(struct scic_sds_request *sds_request)
+static void scic_sds_request_build_sgl(struct scic_sds_request *sds_request)
 {
 	struct isci_request *isci_request = sci_req_to_ireq(sds_request);
 	struct isci_host *isci_host = isci_request->isci_host;
@@ -366,27 +367,214 @@ static void scu_ssp_task_request_construct_task_context(
 		sizeof(struct ssp_task_iu) / sizeof(u32);
 }
 
+/**
+ * This method is will fill in the SCU Task Context for any type of SATA
+ *    request.  This is called from the various SATA constructors.
+ * @sci_req: The general IO request object which is to be used in
+ *    constructing the SCU task context.
+ * @task_context: The buffer pointer for the SCU task context which is being
+ *    constructed.
+ *
+ * The general io request construction is complete. The buffer assignment for
+ * the command buffer is complete. none Revisit task context construction to
+ * determine what is common for SSP/SMP/STP task context structures.
+ */
+static void scu_sata_reqeust_construct_task_context(
+	struct scic_sds_request *sci_req,
+	struct scu_task_context *task_context)
+{
+	dma_addr_t dma_addr;
+	struct scic_sds_controller *controller;
+	struct scic_sds_remote_device *target_device;
+	struct scic_sds_port *target_port;
+
+	controller = scic_sds_request_get_controller(sci_req);
+	target_device = scic_sds_request_get_device(sci_req);
+	target_port = scic_sds_request_get_port(sci_req);
+
+	/* Fill in the TC with the its required data */
+	task_context->abort = 0;
+	task_context->priority = SCU_TASK_PRIORITY_NORMAL;
+	task_context->initiator_request = 1;
+	task_context->connection_rate = target_device->connection_rate;
+	task_context->protocol_engine_index =
+		scic_sds_controller_get_protocol_engine_group(controller);
+	task_context->logical_port_index =
+		scic_sds_port_get_index(target_port);
+	task_context->protocol_type = SCU_TASK_CONTEXT_PROTOCOL_STP;
+	task_context->valid = SCU_TASK_CONTEXT_VALID;
+	task_context->context_type = SCU_TASK_CONTEXT_TYPE;
+
+	task_context->remote_node_index =
+		scic_sds_remote_device_get_index(sci_req->target_device);
+	task_context->command_code = 0;
+
+	task_context->link_layer_control = 0;
+	task_context->do_not_dma_ssp_good_response = 1;
+	task_context->strict_ordering = 0;
+	task_context->control_frame = 0;
+	task_context->timeout_enable = 0;
+	task_context->block_guard_enable = 0;
+
+	task_context->address_modifier = 0;
+	task_context->task_phase = 0x01;
+
+	task_context->ssp_command_iu_length =
+		(sizeof(struct host_to_dev_fis) - sizeof(u32)) / sizeof(u32);
+
+	/* Set the first word of the H2D REG FIS */
+	task_context->type.words[0] = *(u32 *)&sci_req->stp.cmd;
+
+	if (sci_req->was_tag_assigned_by_user) {
+		/*
+		 * Build the task context now since we have already read
+		 * the data
+		 */
+		sci_req->post_context =
+			(SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
+			 (scic_sds_controller_get_protocol_engine_group(
+							controller) <<
+			  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
+			 (scic_sds_port_get_index(target_port) <<
+			  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
+			 scic_sds_io_tag_get_index(sci_req->io_tag));
+	} else {
+		/*
+		 * Build the task context now since we have already read
+		 * the data.
+		 * I/O tag index is not assigned because we have to wait
+		 * until we get a TCi.
+		 */
+		sci_req->post_context =
+			(SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
+			 (scic_sds_controller_get_protocol_engine_group(
+							controller) <<
+			  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
+			 (scic_sds_port_get_index(target_port) <<
+			  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT));
+	}
+
+	/*
+	 * Copy the physical address for the command buffer to the SCU Task
+	 * Context. We must offset the command buffer by 4 bytes because the
+	 * first 4 bytes are transfered in the body of the TC.
+	 */
+	dma_addr = scic_io_request_get_dma_addr(sci_req,
+						((char *) &sci_req->stp.cmd) +
+						sizeof(u32));
+
+	task_context->command_iu_upper = upper_32_bits(dma_addr);
+	task_context->command_iu_lower = lower_32_bits(dma_addr);
+
+	/* SATA Requests do not have a response buffer */
+	task_context->response_iu_upper = 0;
+	task_context->response_iu_lower = 0;
+}
+
+
 
 /**
- * This method constructs the SSP Command IU data for this ssp passthrough
- *    comand request object.
- * @sci_req: This parameter specifies the request object for which the SSP
- *    command information unit is being built.
+ * scu_stp_raw_request_construct_task_context -
+ * @sci_req: This parameter specifies the STP request object for which to
+ *    construct a RAW command frame task context.
+ * @task_context: This parameter specifies the SCU specific task context buffer
+ *    to construct.
  *
- * enum sci_status, returns invalid parameter is cdb > 16
+ * This method performs the operations common to all SATA/STP requests
+ * utilizing the raw frame method. none
  */
+static void scu_stp_raw_request_construct_task_context(struct scic_sds_stp_request *stp_req,
+						       struct scu_task_context *task_context)
+{
+	struct scic_sds_request *sci_req = to_sci_req(stp_req);
+
+	scu_sata_reqeust_construct_task_context(sci_req, task_context);
+
+	task_context->control_frame         = 0;
+	task_context->priority              = SCU_TASK_PRIORITY_NORMAL;
+	task_context->task_type             = SCU_TASK_TYPE_SATA_RAW_FRAME;
+	task_context->type.stp.fis_type     = FIS_REGH2D;
+	task_context->transfer_length_bytes = sizeof(struct host_to_dev_fis) - sizeof(u32);
+}
+
+static enum sci_status
+scic_sds_stp_pio_request_construct(struct scic_sds_request *sci_req,
+				   bool copy_rx_frame)
+{
+	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
+	struct scic_sds_stp_pio_request *pio = &stp_req->type.pio;
+
+	scu_stp_raw_request_construct_task_context(stp_req,
+						   sci_req->task_context_buffer);
+
+	pio->current_transfer_bytes = 0;
+	pio->ending_error = 0;
+	pio->ending_status = 0;
+
+	pio->request_current.sgl_offset = 0;
+	pio->request_current.sgl_set = SCU_SGL_ELEMENT_PAIR_A;
+
+	if (copy_rx_frame) {
+		scic_sds_request_build_sgl(sci_req);
+		/* Since the IO request copy of the TC contains the same data as
+		 * the actual TC this pointer is vaild for either.
+		 */
+		pio->request_current.sgl_pair = &sci_req->task_context_buffer->sgl_pair_ab;
+	} else {
+		/* The user does not want the data copied to the SGL buffer location */
+		pio->request_current.sgl_pair = NULL;
+	}
 
+	return SCI_SUCCESS;
+}
 
 /**
- * This method constructs the SATA request object.
- * @sci_req:
- * @sat_protocol:
- * @transfer_length:
- * @data_direction:
- * @copy_rx_frame:
  *
- * enum sci_status
+ * @sci_req: This parameter specifies the request to be constructed as an
+ *    optimized request.
+ * @optimized_task_type: This parameter specifies whether the request is to be
+ *    an UDMA request or a NCQ request. - A value of 0 indicates UDMA. - A
+ *    value of 1 indicates NCQ.
+ *
+ * This method will perform request construction common to all types of STP
+ * requests that are optimized by the silicon (i.e. UDMA, NCQ). This method
+ * returns an indication as to whether the construction was successful.
  */
+static void scic_sds_stp_optimized_request_construct(struct scic_sds_request *sci_req,
+						     u8 optimized_task_type,
+						     u32 len,
+						     enum dma_data_direction dir)
+{
+	struct scu_task_context *task_context = sci_req->task_context_buffer;
+
+	/* Build the STP task context structure */
+	scu_sata_reqeust_construct_task_context(sci_req, task_context);
+
+	/* Copy over the SGL elements */
+	scic_sds_request_build_sgl(sci_req);
+
+	/* Copy over the number of bytes to be transfered */
+	task_context->transfer_length_bytes = len;
+
+	if (dir == DMA_TO_DEVICE) {
+		/*
+		 * The difference between the DMA IN and DMA OUT request task type
+		 * values are consistent with the difference between FPDMA READ
+		 * and FPDMA WRITE values.  Add the supplied task type parameter
+		 * to this difference to set the task type properly for this
+		 * DATA OUT (WRITE) case. */
+		task_context->task_type = optimized_task_type + (SCU_TASK_TYPE_DMA_OUT
+								 - SCU_TASK_TYPE_DMA_IN);
+	} else {
+		/*
+		 * For the DATA IN (READ) case, simply save the supplied
+		 * optimized task type. */
+		task_context->task_type = optimized_task_type;
+	}
+}
+
+
+
 static enum sci_status
 scic_io_request_construct_sata(struct scic_sds_request *sci_req,
 			       u32 len,
@@ -402,9 +590,11 @@ scic_io_request_construct_sata(struct scic_sds_request *sci_req,
 		struct isci_tmf *tmf = isci_request_access_tmf(ireq);
 
 		if (tmf->tmf_code == isci_tmf_sata_srst_high ||
-		    tmf->tmf_code == isci_tmf_sata_srst_low)
-			return scic_sds_stp_soft_reset_request_construct(sci_req);
-		else {
+		    tmf->tmf_code == isci_tmf_sata_srst_low) {
+			scu_stp_raw_request_construct_task_context(&sci_req->stp.req,
+								   sci_req->task_context_buffer);
+			return SCI_SUCCESS;
+		} else {
 			dev_err(scic_to_dev(sci_req->owning_controller),
 				"%s: Request 0x%p received un-handled SAT "
 				"management protocol 0x%x.\n",
@@ -424,17 +614,27 @@ scic_io_request_construct_sata(struct scic_sds_request *sci_req,
 	}
 
 	/* non data */
-	if (task->data_dir == DMA_NONE)
-		return scic_sds_stp_non_data_request_construct(sci_req);
+	if (task->data_dir == DMA_NONE) {
+		scu_stp_raw_request_construct_task_context(&sci_req->stp.req,
+							   sci_req->task_context_buffer);
+		return SCI_SUCCESS;
+	}
 
 	/* NCQ */
-	if (task->ata_task.use_ncq)
-		return scic_sds_stp_ncq_request_construct(sci_req, len, dir);
+	if (task->ata_task.use_ncq) {
+		scic_sds_stp_optimized_request_construct(sci_req,
+							 SCU_TASK_TYPE_FPDMAQ_READ,
+							 len, dir);
+		return SCI_SUCCESS;
+	}
 
 	/* DMA */
-	if (task->ata_task.dma_xfer)
-		return scic_sds_stp_udma_request_construct(sci_req, len, dir);
-	else /* PIO */
+	if (task->ata_task.dma_xfer) {
+		scic_sds_stp_optimized_request_construct(sci_req,
+							 SCU_TASK_TYPE_DMA_IN,
+							 len, dir);
+		return SCI_SUCCESS;
+	} else /* PIO */
 		return scic_sds_stp_pio_request_construct(sci_req, copy);
 
 	return status;
@@ -453,9 +653,8 @@ static enum sci_status scic_io_request_construct_basic_ssp(struct scic_sds_reque
 
 	scic_sds_io_request_build_ssp_command_iu(sci_req);
 
-	sci_base_state_machine_change_state(
-			&sci_req->state_machine,
-			SCI_BASE_REQUEST_STATE_CONSTRUCTED);
+	sci_base_state_machine_change_state(&sci_req->state_machine,
+					    SCI_BASE_REQUEST_STATE_CONSTRUCTED);
 
 	return SCI_SUCCESS;
 }
@@ -470,12 +669,11 @@ enum sci_status scic_task_request_construct_ssp(
 	scic_sds_task_request_build_ssp_task_iu(sci_req);
 
 	sci_base_state_machine_change_state(&sci_req->state_machine,
-		SCI_BASE_REQUEST_STATE_CONSTRUCTED);
+					    SCI_BASE_REQUEST_STATE_CONSTRUCTED);
 
 	return SCI_SUCCESS;
 }
 
-
 static enum sci_status scic_io_request_construct_basic_sata(struct scic_sds_request *sci_req)
 {
 	enum sci_status status;
@@ -496,12 +694,11 @@ static enum sci_status scic_io_request_construct_basic_sata(struct scic_sds_requ
 
 	if (status == SCI_SUCCESS)
 		sci_base_state_machine_change_state(&sci_req->state_machine,
-			SCI_BASE_REQUEST_STATE_CONSTRUCTED);
+						    SCI_BASE_REQUEST_STATE_CONSTRUCTED);
 
 	return status;
 }
 
-
 enum sci_status scic_task_request_construct_sata(struct scic_sds_request *sci_req)
 {
 	enum sci_status status = SCI_SUCCESS;
@@ -513,7 +710,8 @@ enum sci_status scic_task_request_construct_sata(struct scic_sds_request *sci_re
 
 		if (tmf->tmf_code == isci_tmf_sata_srst_high ||
 		    tmf->tmf_code == isci_tmf_sata_srst_low) {
-			status = scic_sds_stp_soft_reset_request_construct(sci_req);
+			scu_stp_raw_request_construct_task_context(&sci_req->stp.req,
+								   sci_req->task_context_buffer);
 		} else {
 			dev_err(scic_to_dev(sci_req->owning_controller),
 				"%s: Request 0x%p received un-handled SAT "
@@ -524,10 +722,10 @@ enum sci_status scic_task_request_construct_sata(struct scic_sds_request *sci_re
 		}
 	}
 
-	if (status == SCI_SUCCESS)
-		sci_base_state_machine_change_state(
-				&sci_req->state_machine,
-				SCI_BASE_REQUEST_STATE_CONSTRUCTED);
+	if (status != SCI_SUCCESS)
+		return status;
+	sci_base_state_machine_change_state(&sci_req->state_machine,
+					    SCI_BASE_REQUEST_STATE_CONSTRUCTED);
 
 	return status;
 }
@@ -724,7 +922,7 @@ static enum sci_status scic_sds_request_constructed_state_start_handler(
 
 		/* Everything is good go ahead and change state */
 		sci_base_state_machine_change_state(&request->state_machine,
-			SCI_BASE_REQUEST_STATE_STARTED);
+						    SCI_BASE_REQUEST_STATE_STARTED);
 
 		return SCI_SUCCESS;
 	}
@@ -749,29 +947,14 @@ static enum sci_status scic_sds_request_constructed_state_abort_handler(
 		SCI_FAILURE_IO_TERMINATED);
 
 	sci_base_state_machine_change_state(&request->state_machine,
-		SCI_BASE_REQUEST_STATE_COMPLETED);
+					    SCI_BASE_REQUEST_STATE_COMPLETED);
 	return SCI_SUCCESS;
 }
 
-/*
- * *****************************************************************************
- * *  STARTED STATE HANDLERS
- * ***************************************************************************** */
-
-/*
- * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
- * object receives a scic_sds_request_terminate() request. Since the request
- * has been posted to the hardware the io request state is changed to the
- * aborting state. enum sci_status SCI_SUCCESS
- */
-enum sci_status scic_sds_request_started_state_abort_handler(
-	struct scic_sds_request *request)
+static enum sci_status scic_sds_request_started_state_abort_handler(struct scic_sds_request *sci_req)
 {
-	if (request->has_started_substate_machine)
-		sci_base_state_machine_stop(&request->started_substate_machine);
-
-	sci_base_state_machine_change_state(&request->state_machine,
-		SCI_BASE_REQUEST_STATE_ABORTING);
+	sci_base_state_machine_change_state(&sci_req->state_machine,
+					    SCI_BASE_REQUEST_STATE_ABORTING);
 	return SCI_SUCCESS;
 }
 
@@ -943,19 +1126,15 @@ scic_sds_request_started_state_tc_completion_handler(struct scic_sds_request *sc
 	 */
 
 	/* In all cases we will treat this as the completion of the IO req. */
-	sci_base_state_machine_change_state(
-			&sci_req->state_machine,
-			SCI_BASE_REQUEST_STATE_COMPLETED);
+	sci_base_state_machine_change_state(&sci_req->state_machine,
+					    SCI_BASE_REQUEST_STATE_COMPLETED);
 	return SCI_SUCCESS;
 }
 
 enum sci_status
 scic_sds_io_request_tc_completion(struct scic_sds_request *request, u32 completion_code)
 {
-	if (request->state_machine.current_state_id == SCI_BASE_REQUEST_STATE_STARTED &&
-	    request->has_started_substate_machine == false)
-		return scic_sds_request_started_state_tc_completion_handler(request, completion_code);
-	else if (request->state_handlers->tc_completion_handler)
+	if (request->state_handlers->tc_completion_handler)
 		return request->state_handlers->tc_completion_handler(request, completion_code);
 
 	dev_warn(scic_to_dev(request->owning_controller),
@@ -1064,7 +1243,7 @@ static enum sci_status scic_sds_request_completed_state_complete_handler(
 	}
 
 	sci_base_state_machine_change_state(&request->state_machine,
-		SCI_BASE_REQUEST_STATE_FINAL);
+					    SCI_BASE_REQUEST_STATE_FINAL);
 	return SCI_SUCCESS;
 }
 
@@ -1084,7 +1263,7 @@ static enum sci_status scic_sds_request_aborting_state_abort_handler(
 	struct scic_sds_request *request)
 {
 	sci_base_state_machine_change_state(&request->state_machine,
-		SCI_BASE_REQUEST_STATE_COMPLETED);
+					    SCI_BASE_REQUEST_STATE_COMPLETED);
 	return SCI_SUCCESS;
 }
 
@@ -1107,7 +1286,7 @@ static enum sci_status scic_sds_request_aborting_state_tc_completion_handler(
 			);
 
 		sci_base_state_machine_change_state(&sci_req->state_machine,
-			SCI_BASE_REQUEST_STATE_COMPLETED);
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
 		break;
 
 	default:
@@ -1161,7 +1340,7 @@ static enum sci_status scic_sds_ssp_task_request_await_tc_completion_tc_completi
 					    SCI_SUCCESS);
 
 		sci_base_state_machine_change_state(&sci_req->state_machine,
-			SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE);
+						    SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE);
 		break;
 
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_ACK_NAK_TO):
@@ -1178,7 +1357,7 @@ static enum sci_status scic_sds_ssp_task_request_await_tc_completion_tc_completi
 			 completion_code);
 
 		sci_base_state_machine_change_state(&sci_req->state_machine,
-			SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE);
+						    SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE);
 		break;
 
 	default:
@@ -1192,7 +1371,7 @@ static enum sci_status scic_sds_ssp_task_request_await_tc_completion_tc_completi
 			);
 
 		sci_base_state_machine_change_state(&sci_req->state_machine,
-			SCI_BASE_REQUEST_STATE_COMPLETED);
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
 		break;
 	}
 
@@ -1215,9 +1394,9 @@ static enum sci_status scic_sds_ssp_task_request_await_tc_response_abort_handler
 	struct scic_sds_request *request)
 {
 	sci_base_state_machine_change_state(&request->state_machine,
-			SCI_BASE_REQUEST_STATE_ABORTING);
+					    SCI_BASE_REQUEST_STATE_ABORTING);
 	sci_base_state_machine_change_state(&request->state_machine,
-			SCI_BASE_REQUEST_STATE_COMPLETED);
+					    SCI_BASE_REQUEST_STATE_COMPLETED);
 	return SCI_SUCCESS;
 }
 
@@ -1243,7 +1422,7 @@ static enum sci_status scic_sds_ssp_task_request_await_tc_response_frame_handler
 	scic_sds_io_request_copy_response(request);
 
 	sci_base_state_machine_change_state(&request->state_machine,
-		SCI_BASE_REQUEST_STATE_COMPLETED);
+					    SCI_BASE_REQUEST_STATE_COMPLETED);
 	scic_sds_controller_release_frame(request->owning_controller,
 			frame_index);
 	return SCI_SUCCESS;
@@ -1270,13 +1449,11 @@ static enum sci_status scic_sds_smp_request_await_response_tc_completion_handler
 		/*
 		 * In the AWAIT RESPONSE state, any TC completion is unexpected.
 		 * but if the TC has success status, we complete the IO anyway. */
-		scic_sds_request_set_status(
-			sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS
-			);
+		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
+					    SCI_SUCCESS);
 
-		sci_base_state_machine_change_state(
-			&sci_req->state_machine,
-			SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
 		break;
 
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_RESP_TO_ERR):
@@ -1288,13 +1465,11 @@ static enum sci_status scic_sds_smp_request_await_response_tc_completion_handler
 		 * is not able to send smp response within 2 ms. This causes our hardware
 		 * break the connection and set TC completion with one of these SMP_XXX_XX_ERR
 		 * status. For these type of error, we ask scic user to retry the request. */
-		scic_sds_request_set_status(
-			sci_req, SCU_TASK_DONE_SMP_RESP_TO_ERR, SCI_FAILURE_RETRY_REQUIRED
-			);
+		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_SMP_RESP_TO_ERR,
+					    SCI_FAILURE_RETRY_REQUIRED);
 
-		sci_base_state_machine_change_state(
-			&sci_req->state_machine,
-			SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
 		break;
 
 	default:
@@ -1307,9 +1482,8 @@ static enum sci_status scic_sds_smp_request_await_response_tc_completion_handler
 			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
 			);
 
-		sci_base_state_machine_change_state(
-			&sci_req->state_machine,
-			SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
 		break;
 	}
 
@@ -1365,7 +1539,7 @@ scic_sds_smp_request_await_response_frame_handler(struct scic_sds_request *sci_r
 			sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS);
 
 		sci_base_state_machine_change_state(&sci_req->state_machine,
-			SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION);
+						    SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION);
 	} else {
 		/* This was not a response frame why did it get forwarded? */
 		dev_err(scic_to_dev(sci_req->owning_controller),
@@ -1378,46 +1552,921 @@ scic_sds_smp_request_await_response_frame_handler(struct scic_sds_request *sci_r
 
 		scic_sds_request_set_status(
 			sci_req,
-			SCU_TASK_DONE_SMP_FRM_TYPE_ERR,
-			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
+			SCU_TASK_DONE_SMP_FRM_TYPE_ERR,
+			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
+
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
+	}
+
+	scic_sds_controller_release_frame(sci_req->owning_controller,
+					  frame_index);
+
+	return SCI_SUCCESS;
+}
+
+/**
+ * This method processes the completions transport layer (TL) status to
+ *    determine if the SMP request was sent successfully. If the SMP request
+ *    was sent successfully, then the state for the SMP request transits to
+ *    waiting for a response frame.
+ * @sci_req: This parameter specifies the request for which the TC
+ *    completion was received.
+ * @completion_code: This parameter indicates the completion status information
+ *    for the TC.
+ *
+ * Indicate if the tc completion handler was successful. SCI_SUCCESS currently
+ * this method always returns success.
+ */
+static enum sci_status scic_sds_smp_request_await_tc_completion_tc_completion_handler(
+	struct scic_sds_request *sci_req,
+	u32 completion_code)
+{
+	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
+		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
+					    SCI_SUCCESS);
+
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		break;
+
+	default:
+		/*
+		 * All other completion status cause the IO to be complete.  If a NAK
+		 * was received, then it is up to the user to retry the request. */
+		scic_sds_request_set_status(
+			sci_req,
+			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
+			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
+			);
+
+		sci_base_state_machine_change_state(
+			&sci_req->state_machine,
+			SCI_BASE_REQUEST_STATE_COMPLETED);
+		break;
+	}
+
+	return SCI_SUCCESS;
+}
+
+void scic_stp_io_request_set_ncq_tag(struct scic_sds_request *req,
+				     u16 ncq_tag)
+{
+	/**
+	 * @note This could be made to return an error to the user if the user
+	 *       attempts to set the NCQ tag in the wrong state.
+	 */
+	req->task_context_buffer->type.stp.ncq_tag = ncq_tag;
+}
+
+/**
+ *
+ * @sci_req:
+ *
+ * Get the next SGL element from the request. - Check on which SGL element pair
+ * we are working - if working on SLG pair element A - advance to element B -
+ * else - check to see if there are more SGL element pairs for this IO request
+ * - if there are more SGL element pairs - advance to the next pair and return
+ * element A struct scu_sgl_element*
+ */
+static struct scu_sgl_element *scic_sds_stp_request_pio_get_next_sgl(struct scic_sds_stp_request *stp_req)
+{
+	struct scu_sgl_element *current_sgl;
+	struct scic_sds_request *sci_req = to_sci_req(stp_req);
+	struct scic_sds_request_pio_sgl *pio_sgl = &stp_req->type.pio.request_current;
+
+	if (pio_sgl->sgl_set == SCU_SGL_ELEMENT_PAIR_A) {
+		if (pio_sgl->sgl_pair->B.address_lower == 0 &&
+		    pio_sgl->sgl_pair->B.address_upper == 0) {
+			current_sgl = NULL;
+		} else {
+			pio_sgl->sgl_set = SCU_SGL_ELEMENT_PAIR_B;
+			current_sgl = &pio_sgl->sgl_pair->B;
+		}
+	} else {
+		if (pio_sgl->sgl_pair->next_pair_lower == 0 &&
+		    pio_sgl->sgl_pair->next_pair_upper == 0) {
+			current_sgl = NULL;
+		} else {
+			u64 phys_addr;
+
+			phys_addr = pio_sgl->sgl_pair->next_pair_upper;
+			phys_addr <<= 32;
+			phys_addr |= pio_sgl->sgl_pair->next_pair_lower;
+
+			pio_sgl->sgl_pair = scic_request_get_virt_addr(sci_req, phys_addr);
+			pio_sgl->sgl_set = SCU_SGL_ELEMENT_PAIR_A;
+			current_sgl = &pio_sgl->sgl_pair->A;
+		}
+	}
+
+	return current_sgl;
+}
+
+/**
+ *
+ * @sci_req:
+ * @completion_code:
+ *
+ * This method processes a TC completion.  The expected TC completion is for
+ * the transmission of the H2D register FIS containing the SATA/STP non-data
+ * request. This method always successfully processes the TC completion.
+ * SCI_SUCCESS This value is always returned.
+ */
+static enum sci_status scic_sds_stp_request_non_data_await_h2d_tc_completion_handler(
+	struct scic_sds_request *sci_req,
+	u32 completion_code)
+{
+	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
+		scic_sds_request_set_status(
+			sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS
+			);
+
+		sci_base_state_machine_change_state(
+			&sci_req->state_machine,
+			SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE
+			);
+		break;
+
+	default:
+		/*
+		 * All other completion status cause the IO to be complete.  If a NAK
+		 * was received, then it is up to the user to retry the request. */
+		scic_sds_request_set_status(
+			sci_req,
+			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
+			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
+			);
+
+		sci_base_state_machine_change_state(
+			&sci_req->state_machine, SCI_BASE_REQUEST_STATE_COMPLETED);
+		break;
+	}
+
+	return SCI_SUCCESS;
+}
+
+/**
+ *
+ * @request: This parameter specifies the request for which a frame has been
+ *    received.
+ * @frame_index: This parameter specifies the index of the frame that has been
+ *    received.
+ *
+ * This method processes frames received from the target while waiting for a
+ * device to host register FIS.  If a non-register FIS is received during this
+ * time, it is treated as a protocol violation from an IO perspective. Indicate
+ * if the received frame was processed successfully.
+ */
+static enum sci_status scic_sds_stp_request_non_data_await_d2h_frame_handler(
+	struct scic_sds_request *sci_req,
+	u32 frame_index)
+{
+	enum sci_status status;
+	struct dev_to_host_fis *frame_header;
+	u32 *frame_buffer;
+	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
+	struct scic_sds_controller *scic = sci_req->owning_controller;
+
+	status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+							       frame_index,
+							       (void **)&frame_header);
+
+	if (status != SCI_SUCCESS) {
+		dev_err(scic_to_dev(sci_req->owning_controller),
+			"%s: SCIC IO Request 0x%p could not get frame header "
+			"for frame index %d, status %x\n",
+			__func__, stp_req, frame_index, status);
+
+		return status;
+	}
+
+	switch (frame_header->fis_type) {
+	case FIS_REGD2H:
+		scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+							      frame_index,
+							      (void **)&frame_buffer);
+
+		scic_sds_controller_copy_sata_response(&sci_req->stp.rsp,
+						       frame_header,
+						       frame_buffer);
+
+		/* The command has completed with error */
+		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_CHECK_RESPONSE,
+					    SCI_FAILURE_IO_RESPONSE_VALID);
+		break;
+
+	default:
+		dev_warn(scic_to_dev(scic),
+			 "%s: IO Request:0x%p Frame Id:%d protocol "
+			  "violation occurred\n", __func__, stp_req,
+			  frame_index);
+
+		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_UNEXP_FIS,
+					    SCI_FAILURE_PROTOCOL_VIOLATION);
+		break;
+	}
+
+	sci_base_state_machine_change_state(&sci_req->state_machine,
+					    SCI_BASE_REQUEST_STATE_COMPLETED);
+
+	/* Frame has been decoded return it to the controller */
+	scic_sds_controller_release_frame(scic, frame_index);
+
+	return status;
+}
+
+#define SCU_MAX_FRAME_BUFFER_SIZE  0x400  /* 1K is the maximum SCU frame data payload */
+
+/* transmit DATA_FIS from (current sgl + offset) for input
+ * parameter length. current sgl and offset is alreay stored in the IO request
+ */
+static enum sci_status scic_sds_stp_request_pio_data_out_trasmit_data_frame(
+	struct scic_sds_request *sci_req,
+	u32 length)
+{
+	struct scic_sds_controller *scic = sci_req->owning_controller;
+	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
+	struct scu_task_context *task_context;
+	struct scu_sgl_element *current_sgl;
+
+	/* Recycle the TC and reconstruct it for sending out DATA FIS containing
+	 * for the data from current_sgl+offset for the input length
+	 */
+	task_context = scic_sds_controller_get_task_context_buffer(scic,
+								   sci_req->io_tag);
+
+	if (stp_req->type.pio.request_current.sgl_set == SCU_SGL_ELEMENT_PAIR_A)
+		current_sgl = &stp_req->type.pio.request_current.sgl_pair->A;
+	else
+		current_sgl = &stp_req->type.pio.request_current.sgl_pair->B;
+
+	/* update the TC */
+	task_context->command_iu_upper = current_sgl->address_upper;
+	task_context->command_iu_lower = current_sgl->address_lower;
+	task_context->transfer_length_bytes = length;
+	task_context->type.stp.fis_type = FIS_DATA;
+
+	/* send the new TC out. */
+	return scic_controller_continue_io(sci_req);
+}
+
+static enum sci_status scic_sds_stp_request_pio_data_out_transmit_data(struct scic_sds_request *sci_req)
+{
+
+	struct scu_sgl_element *current_sgl;
+	u32 sgl_offset;
+	u32 remaining_bytes_in_current_sgl = 0;
+	enum sci_status status = SCI_SUCCESS;
+	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
+
+	sgl_offset = stp_req->type.pio.request_current.sgl_offset;
+
+	if (stp_req->type.pio.request_current.sgl_set == SCU_SGL_ELEMENT_PAIR_A) {
+		current_sgl = &(stp_req->type.pio.request_current.sgl_pair->A);
+		remaining_bytes_in_current_sgl = stp_req->type.pio.request_current.sgl_pair->A.length - sgl_offset;
+	} else {
+		current_sgl = &(stp_req->type.pio.request_current.sgl_pair->B);
+		remaining_bytes_in_current_sgl = stp_req->type.pio.request_current.sgl_pair->B.length - sgl_offset;
+	}
+
+
+	if (stp_req->type.pio.pio_transfer_bytes > 0) {
+		if (stp_req->type.pio.pio_transfer_bytes >= remaining_bytes_in_current_sgl) {
+			/* recycle the TC and send the H2D Data FIS from (current sgl + sgl_offset) and length = remaining_bytes_in_current_sgl */
+			status = scic_sds_stp_request_pio_data_out_trasmit_data_frame(sci_req, remaining_bytes_in_current_sgl);
+			if (status == SCI_SUCCESS) {
+				stp_req->type.pio.pio_transfer_bytes -= remaining_bytes_in_current_sgl;
+
+				/* update the current sgl, sgl_offset and save for future */
+				current_sgl = scic_sds_stp_request_pio_get_next_sgl(stp_req);
+				sgl_offset = 0;
+			}
+		} else if (stp_req->type.pio.pio_transfer_bytes < remaining_bytes_in_current_sgl) {
+			/* recycle the TC and send the H2D Data FIS from (current sgl + sgl_offset) and length = type.pio.pio_transfer_bytes */
+			scic_sds_stp_request_pio_data_out_trasmit_data_frame(sci_req, stp_req->type.pio.pio_transfer_bytes);
+
+			if (status == SCI_SUCCESS) {
+				/* Sgl offset will be adjusted and saved for future */
+				sgl_offset += stp_req->type.pio.pio_transfer_bytes;
+				current_sgl->address_lower += stp_req->type.pio.pio_transfer_bytes;
+				stp_req->type.pio.pio_transfer_bytes = 0;
+			}
+		}
+	}
+
+	if (status == SCI_SUCCESS) {
+		stp_req->type.pio.request_current.sgl_offset = sgl_offset;
+	}
+
+	return status;
+}
+
+/**
+ *
+ * @stp_request: The request that is used for the SGL processing.
+ * @data_buffer: The buffer of data to be copied.
+ * @length: The length of the data transfer.
+ *
+ * Copy the data from the buffer for the length specified to the IO reqeust SGL
+ * specified data region. enum sci_status
+ */
+static enum sci_status
+scic_sds_stp_request_pio_data_in_copy_data_buffer(struct scic_sds_stp_request *stp_req,
+						  u8 *data_buf, u32 len)
+{
+	struct scic_sds_request *sci_req;
+	struct isci_request *ireq;
+	u8 *src_addr;
+	int copy_len;
+	struct sas_task *task;
+	struct scatterlist *sg;
+	void *kaddr;
+	int total_len = len;
+
+	sci_req = to_sci_req(stp_req);
+	ireq = sci_req_to_ireq(sci_req);
+	task = isci_request_access_task(ireq);
+	src_addr = data_buf;
+
+	if (task->num_scatter > 0) {
+		sg = task->scatter;
+
+		while (total_len > 0) {
+			struct page *page = sg_page(sg);
+
+			copy_len = min_t(int, total_len, sg_dma_len(sg));
+			kaddr = kmap_atomic(page, KM_IRQ0);
+			memcpy(kaddr + sg->offset, src_addr, copy_len);
+			kunmap_atomic(kaddr, KM_IRQ0);
+			total_len -= copy_len;
+			src_addr += copy_len;
+			sg = sg_next(sg);
+		}
+	} else {
+		BUG_ON(task->total_xfer_len < total_len);
+		memcpy(task->scatter, src_addr, total_len);
+	}
+
+	return SCI_SUCCESS;
+}
+
+/**
+ *
+ * @sci_req: The PIO DATA IN request that is to receive the data.
+ * @data_buffer: The buffer to copy from.
+ *
+ * Copy the data buffer to the io request data region. enum sci_status
+ */
+static enum sci_status scic_sds_stp_request_pio_data_in_copy_data(
+	struct scic_sds_stp_request *sci_req,
+	u8 *data_buffer)
+{
+	enum sci_status status;
+
+	/*
+	 * If there is less than 1K remaining in the transfer request
+	 * copy just the data for the transfer */
+	if (sci_req->type.pio.pio_transfer_bytes < SCU_MAX_FRAME_BUFFER_SIZE) {
+		status = scic_sds_stp_request_pio_data_in_copy_data_buffer(
+			sci_req, data_buffer, sci_req->type.pio.pio_transfer_bytes);
+
+		if (status == SCI_SUCCESS)
+			sci_req->type.pio.pio_transfer_bytes = 0;
+	} else {
+		/* We are transfering the whole frame so copy */
+		status = scic_sds_stp_request_pio_data_in_copy_data_buffer(
+			sci_req, data_buffer, SCU_MAX_FRAME_BUFFER_SIZE);
+
+		if (status == SCI_SUCCESS)
+			sci_req->type.pio.pio_transfer_bytes -= SCU_MAX_FRAME_BUFFER_SIZE;
+	}
+
+	return status;
+}
+
+/**
+ *
+ * @sci_req:
+ * @completion_code:
+ *
+ * enum sci_status
+ */
+static enum sci_status scic_sds_stp_request_pio_await_h2d_completion_tc_completion_handler(
+	struct scic_sds_request *sci_req,
+	u32 completion_code)
+{
+	enum sci_status status = SCI_SUCCESS;
+
+	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
+		scic_sds_request_set_status(
+			sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS
+			);
+
+		sci_base_state_machine_change_state(
+			&sci_req->state_machine,
+			SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE
+			);
+		break;
+
+	default:
+		/*
+		 * All other completion status cause the IO to be complete.  If a NAK
+		 * was received, then it is up to the user to retry the request. */
+		scic_sds_request_set_status(
+			sci_req,
+			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
+			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
+			);
+
+		sci_base_state_machine_change_state(
+			&sci_req->state_machine,
+			SCI_BASE_REQUEST_STATE_COMPLETED
+			);
+		break;
+	}
+
+	return status;
+}
+
+static enum sci_status scic_sds_stp_request_pio_await_frame_frame_handler(struct scic_sds_request *sci_req,
+									  u32 frame_index)
+{
+	struct scic_sds_controller *scic = sci_req->owning_controller;
+	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
+	struct isci_request *ireq = sci_req_to_ireq(sci_req);
+	struct sas_task *task = isci_request_access_task(ireq);
+	struct dev_to_host_fis *frame_header;
+	enum sci_status status;
+	u32 *frame_buffer;
+
+	status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+							       frame_index,
+							       (void **)&frame_header);
+
+	if (status != SCI_SUCCESS) {
+		dev_err(scic_to_dev(scic),
+			"%s: SCIC IO Request 0x%p could not get frame header "
+			"for frame index %d, status %x\n",
+			__func__, stp_req, frame_index, status);
+		return status;
+	}
+
+	switch (frame_header->fis_type) {
+	case FIS_PIO_SETUP:
+		/* Get from the frame buffer the PIO Setup Data */
+		scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+							      frame_index,
+							      (void **)&frame_buffer);
+
+		/* Get the data from the PIO Setup The SCU Hardware returns
+		 * first word in the frame_header and the rest of the data is in
+		 * the frame buffer so we need to back up one dword
+		 */
+
+		/* transfer_count: first 16bits in the 4th dword */
+		stp_req->type.pio.pio_transfer_bytes = frame_buffer[3] & 0xffff;
+
+		/* ending_status: 4th byte in the 3rd dword */
+		stp_req->type.pio.ending_status = (frame_buffer[2] >> 24) & 0xff;
+
+		scic_sds_controller_copy_sata_response(&sci_req->stp.rsp,
+						       frame_header,
+						       frame_buffer);
+
+		sci_req->stp.rsp.status = stp_req->type.pio.ending_status;
+
+		/* The next state is dependent on whether the
+		 * request was PIO Data-in or Data out
+		 */
+		if (task->data_dir == DMA_FROM_DEVICE) {
+			sci_base_state_machine_change_state(&sci_req->state_machine,
+							    SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE);
+		} else if (task->data_dir == DMA_TO_DEVICE) {
+			/* Transmit data */
+			status = scic_sds_stp_request_pio_data_out_transmit_data(sci_req);
+			if (status != SCI_SUCCESS)
+				break;
+			sci_base_state_machine_change_state(&sci_req->state_machine,
+							    SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE);
+		}
+		break;
+	case FIS_SETDEVBITS:
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE);
+		break;
+	case FIS_REGD2H:
+		if (frame_header->status & ATA_BUSY) {
+			/* Now why is the drive sending a D2H Register FIS when
+			 * it is still busy?  Do nothing since we are still in
+			 * the right state.
+			 */
+			dev_dbg(scic_to_dev(scic),
+				"%s: SCIC PIO Request 0x%p received "
+				"D2H Register FIS with BSY status "
+				"0x%x\n", __func__, stp_req,
+				frame_header->status);
+			break;
+		}
+
+		scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+							      frame_index,
+							      (void **)&frame_buffer);
+
+		scic_sds_controller_copy_sata_response(&sci_req->stp.req,
+						       frame_header,
+						       frame_buffer);
+
+		scic_sds_request_set_status(sci_req,
+					    SCU_TASK_DONE_CHECK_RESPONSE,
+					    SCI_FAILURE_IO_RESPONSE_VALID);
+
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
+		break;
+	default:
+		/* FIXME: what do we do here? */
+		break;
+	}
+
+	/* Frame is decoded return it to the controller */
+	scic_sds_controller_release_frame(scic, frame_index);
+
+	return status;
+}
+
+static enum sci_status scic_sds_stp_request_pio_data_in_await_data_frame_handler(struct scic_sds_request *sci_req,
+										 u32 frame_index)
+{
+	enum sci_status status;
+	struct dev_to_host_fis *frame_header;
+	struct sata_fis_data *frame_buffer;
+	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
+	struct scic_sds_controller *scic = sci_req->owning_controller;
+
+	status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+							       frame_index,
+							       (void **)&frame_header);
+
+	if (status != SCI_SUCCESS) {
+		dev_err(scic_to_dev(scic),
+			"%s: SCIC IO Request 0x%p could not get frame header "
+			"for frame index %d, status %x\n",
+			__func__, stp_req, frame_index, status);
+		return status;
+	}
+
+	if (frame_header->fis_type == FIS_DATA) {
+		if (stp_req->type.pio.request_current.sgl_pair == NULL) {
+			sci_req->saved_rx_frame_index = frame_index;
+			stp_req->type.pio.pio_transfer_bytes = 0;
+		} else {
+			scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+								      frame_index,
+								      (void **)&frame_buffer);
+
+			status = scic_sds_stp_request_pio_data_in_copy_data(stp_req,
+									    (u8 *)frame_buffer);
+
+			/* Frame is decoded return it to the controller */
+			scic_sds_controller_release_frame(scic, frame_index);
+		}
+
+		/* Check for the end of the transfer, are there more
+		 * bytes remaining for this data transfer
+		 */
+		if (status != SCI_SUCCESS ||
+		    stp_req->type.pio.pio_transfer_bytes != 0)
+			return status;
+
+		if ((stp_req->type.pio.ending_status & ATA_BUSY) == 0) {
+			scic_sds_request_set_status(sci_req,
+						    SCU_TASK_DONE_CHECK_RESPONSE,
+						    SCI_FAILURE_IO_RESPONSE_VALID);
+
+			sci_base_state_machine_change_state(&sci_req->state_machine,
+							    SCI_BASE_REQUEST_STATE_COMPLETED);
+		} else {
+			sci_base_state_machine_change_state(&sci_req->state_machine,
+							    SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE);
+		}
+	} else {
+		dev_err(scic_to_dev(scic),
+			"%s: SCIC PIO Request 0x%p received frame %d "
+			"with fis type 0x%02x when expecting a data "
+			"fis.\n", __func__, stp_req, frame_index,
+			frame_header->fis_type);
+
+		scic_sds_request_set_status(sci_req,
+					    SCU_TASK_DONE_GOOD,
+					    SCI_FAILURE_IO_REQUIRES_SCSI_ABORT);
+
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+						    SCI_BASE_REQUEST_STATE_COMPLETED);
+
+		/* Frame is decoded return it to the controller */
+		scic_sds_controller_release_frame(scic, frame_index);
+	}
+
+	return status;
+}
+
+
+/**
+ *
+ * @sci_req:
+ * @completion_code:
+ *
+ * enum sci_status
+ */
+static enum sci_status scic_sds_stp_request_pio_data_out_await_data_transmit_completion_tc_completion_handler(
+
+	struct scic_sds_request *sci_req,
+	u32 completion_code)
+{
+	enum sci_status status = SCI_SUCCESS;
+	bool all_frames_transferred = false;
+	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
+
+	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
+		/* Transmit data */
+		if (stp_req->type.pio.pio_transfer_bytes != 0) {
+			status = scic_sds_stp_request_pio_data_out_transmit_data(sci_req);
+			if (status == SCI_SUCCESS) {
+				if (stp_req->type.pio.pio_transfer_bytes == 0)
+					all_frames_transferred = true;
+			}
+		} else if (stp_req->type.pio.pio_transfer_bytes == 0) {
+			/*
+			 * this will happen if the all data is written at the
+			 * first time after the pio setup fis is received
+			 */
+			all_frames_transferred  = true;
+		}
+
+		/* all data transferred. */
+		if (all_frames_transferred) {
+			/*
+			 * Change the state to SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_FRAME_SUBSTATE
+			 * and wait for PIO_SETUP fis / or D2H REg fis. */
+			sci_base_state_machine_change_state(
+				&sci_req->state_machine,
+				SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE
+				);
+		}
+		break;
+
+	default:
+		/*
+		 * All other completion status cause the IO to be complete.  If a NAK
+		 * was received, then it is up to the user to retry the request. */
+		scic_sds_request_set_status(
+			sci_req,
+			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
+			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
+			);
+
+		sci_base_state_machine_change_state(
+			&sci_req->state_machine,
+			SCI_BASE_REQUEST_STATE_COMPLETED
+			);
+		break;
+	}
+
+	return status;
+}
+
+/**
+ *
+ * @request: This is the request which is receiving the event.
+ * @event_code: This is the event code that the request on which the request is
+ *    expected to take action.
+ *
+ * This method will handle any link layer events while waiting for the data
+ * frame. enum sci_status SCI_SUCCESS SCI_FAILURE
+ */
+static enum sci_status scic_sds_stp_request_pio_data_in_await_data_event_handler(
+	struct scic_sds_request *request,
+	u32 event_code)
+{
+	enum sci_status status;
+
+	switch (scu_get_event_specifier(event_code)) {
+	case SCU_TASK_DONE_CRC_ERR << SCU_EVENT_SPECIFIC_CODE_SHIFT:
+		/*
+		 * We are waiting for data and the SCU has R_ERR the data frame.
+		 * Go back to waiting for the D2H Register FIS */
+		sci_base_state_machine_change_state(
+			&request->state_machine,
+			SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE
+			);
+
+		status = SCI_SUCCESS;
+		break;
+
+	default:
+		dev_err(scic_to_dev(request->owning_controller),
+			"%s: SCIC PIO Request 0x%p received unexpected "
+			"event 0x%08x\n",
+			__func__, request, event_code);
+
+		/* / @todo Should we fail the PIO request when we get an unexpected event? */
+		status = SCI_FAILURE;
+		break;
+	}
+
+	return status;
+}
+
+static void scic_sds_stp_request_udma_complete_request(
+	struct scic_sds_request *request,
+	u32 scu_status,
+	enum sci_status sci_status)
+{
+	scic_sds_request_set_status(request, scu_status, sci_status);
+	sci_base_state_machine_change_state(&request->state_machine,
+		SCI_BASE_REQUEST_STATE_COMPLETED);
+}
+
+static enum sci_status scic_sds_stp_request_udma_general_frame_handler(struct scic_sds_request *sci_req,
+								       u32 frame_index)
+{
+	struct scic_sds_controller *scic = sci_req->owning_controller;
+	struct dev_to_host_fis *frame_header;
+	enum sci_status status;
+	u32 *frame_buffer;
+
+	status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+							       frame_index,
+							       (void **)&frame_header);
+
+	if ((status == SCI_SUCCESS) &&
+	    (frame_header->fis_type == FIS_REGD2H)) {
+		scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+							      frame_index,
+							      (void **)&frame_buffer);
+
+		scic_sds_controller_copy_sata_response(&sci_req->stp.rsp,
+						       frame_header,
+						       frame_buffer);
+	}
+
+	scic_sds_controller_release_frame(scic, frame_index);
+
+	return status;
+}
+
+static enum sci_status scic_sds_stp_request_udma_await_tc_completion_tc_completion_handler(
+	struct scic_sds_request *sci_req,
+	u32 completion_code)
+{
+	enum sci_status status = SCI_SUCCESS;
+
+	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
+		scic_sds_stp_request_udma_complete_request(sci_req,
+							   SCU_TASK_DONE_GOOD,
+							   SCI_SUCCESS);
+		break;
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_UNEXP_FIS):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_REG_ERR):
+		/*
+		 * We must check ther response buffer to see if the D2H Register FIS was
+		 * received before we got the TC completion. */
+		if (sci_req->stp.rsp.fis_type == FIS_REGD2H) {
+			scic_sds_remote_device_suspend(sci_req->target_device,
+				SCU_EVENT_SPECIFIC(SCU_NORMALIZE_COMPLETION_STATUS(completion_code)));
+
+			scic_sds_stp_request_udma_complete_request(sci_req,
+								   SCU_TASK_DONE_CHECK_RESPONSE,
+								   SCI_FAILURE_IO_RESPONSE_VALID);
+		} else {
+			/*
+			 * If we have an error completion status for the TC then we can expect a
+			 * D2H register FIS from the device so we must change state to wait for it */
+			sci_base_state_machine_change_state(&sci_req->state_machine,
+				SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE);
+		}
+		break;
+
+	/*
+	 * / @todo Check to see if any of these completion status need to wait for
+	 * /       the device to host register fis. */
+	/* / @todo We can retry the command for SCU_TASK_DONE_CMD_LL_R_ERR - this comes only for B0 */
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_INV_FIS_LEN):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_MAX_PLD_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_LL_R_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_CMD_LL_R_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_CRC_ERR):
+		scic_sds_remote_device_suspend(sci_req->target_device,
+			SCU_EVENT_SPECIFIC(SCU_NORMALIZE_COMPLETION_STATUS(completion_code)));
+	/* Fall through to the default case */
+	default:
+		/* All other completion status cause the IO to be complete. */
+		scic_sds_stp_request_udma_complete_request(sci_req,
+					SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
+					SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
+		break;
+	}
+
+	return status;
+}
+
+static enum sci_status scic_sds_stp_request_udma_await_d2h_reg_fis_frame_handler(
+	struct scic_sds_request *sci_req,
+	u32 frame_index)
+{
+	enum sci_status status;
+
+	/* Use the general frame handler to copy the resposne data */
+	status = scic_sds_stp_request_udma_general_frame_handler(sci_req, frame_index);
+
+	if (status != SCI_SUCCESS)
+		return status;
+
+	scic_sds_stp_request_udma_complete_request(sci_req,
+						   SCU_TASK_DONE_CHECK_RESPONSE,
+						   SCI_FAILURE_IO_RESPONSE_VALID);
+
+	return status;
+}
+
+enum sci_status scic_sds_stp_udma_request_construct(struct scic_sds_request *sci_req,
+						    u32 len,
+						    enum dma_data_direction dir)
+{
+	return SCI_SUCCESS;
+}
+
+/**
+ *
+ * @sci_req:
+ * @completion_code:
+ *
+ * This method processes a TC completion.  The expected TC completion is for
+ * the transmission of the H2D register FIS containing the SATA/STP non-data
+ * request. This method always successfully processes the TC completion.
+ * SCI_SUCCESS This value is always returned.
+ */
+static enum sci_status scic_sds_stp_request_soft_reset_await_h2d_asserted_tc_completion_handler(
+	struct scic_sds_request *sci_req,
+	u32 completion_code)
+{
+	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
+		scic_sds_request_set_status(
+			sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS
+			);
+
+		sci_base_state_machine_change_state(
+			&sci_req->state_machine,
+			SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE
+			);
+		break;
+
+	default:
+		/*
+		 * All other completion status cause the IO to be complete.  If a NAK
+		 * was received, then it is up to the user to retry the request. */
+		scic_sds_request_set_status(
+			sci_req,
+			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
+			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
+			);
 
 		sci_base_state_machine_change_state(
-			&sci_req->state_machine,
-			SCI_BASE_REQUEST_STATE_COMPLETED);
+			&sci_req->state_machine, SCI_BASE_REQUEST_STATE_COMPLETED);
+		break;
 	}
 
-	scic_sds_controller_release_frame(sci_req->owning_controller,
-					  frame_index);
-
 	return SCI_SUCCESS;
 }
 
 /**
- * This method processes the completions transport layer (TL) status to
- *    determine if the SMP request was sent successfully. If the SMP request
- *    was sent successfully, then the state for the SMP request transits to
- *    waiting for a response frame.
- * @sci_req: This parameter specifies the request for which the TC
- *    completion was received.
- * @completion_code: This parameter indicates the completion status information
- *    for the TC.
  *
- * Indicate if the tc completion handler was successful. SCI_SUCCESS currently
- * this method always returns success.
+ * @sci_req:
+ * @completion_code:
+ *
+ * This method processes a TC completion.  The expected TC completion is for
+ * the transmission of the H2D register FIS containing the SATA/STP non-data
+ * request. This method always successfully processes the TC completion.
+ * SCI_SUCCESS This value is always returned.
  */
-static enum sci_status scic_sds_smp_request_await_tc_completion_tc_completion_handler(
+static enum sci_status scic_sds_stp_request_soft_reset_await_h2d_diagnostic_tc_completion_handler(
 	struct scic_sds_request *sci_req,
 	u32 completion_code)
 {
 	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
 	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
-		scic_sds_request_set_status(
-			sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS
-			);
+		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
+					    SCI_SUCCESS);
 
-		sci_base_state_machine_change_state(
-			&sci_req->state_machine,
-			SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+			SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE);
 		break;
 
 	default:
@@ -1430,15 +2479,83 @@ static enum sci_status scic_sds_smp_request_await_tc_completion_tc_completion_ha
 			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
 			);
 
-		sci_base_state_machine_change_state(
-			&sci_req->state_machine,
-			SCI_BASE_REQUEST_STATE_COMPLETED);
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+				SCI_BASE_REQUEST_STATE_COMPLETED);
 		break;
 	}
 
 	return SCI_SUCCESS;
 }
 
+/**
+ *
+ * @request: This parameter specifies the request for which a frame has been
+ *    received.
+ * @frame_index: This parameter specifies the index of the frame that has been
+ *    received.
+ *
+ * This method processes frames received from the target while waiting for a
+ * device to host register FIS.  If a non-register FIS is received during this
+ * time, it is treated as a protocol violation from an IO perspective. Indicate
+ * if the received frame was processed successfully.
+ */
+static enum sci_status scic_sds_stp_request_soft_reset_await_d2h_frame_handler(
+	struct scic_sds_request *sci_req,
+	u32 frame_index)
+{
+	enum sci_status status;
+	struct dev_to_host_fis *frame_header;
+	u32 *frame_buffer;
+	struct scic_sds_stp_request *stp_req = &sci_req->stp.req;
+	struct scic_sds_controller *scic = sci_req->owning_controller;
+
+	status = scic_sds_unsolicited_frame_control_get_header(&scic->uf_control,
+							       frame_index,
+							       (void **)&frame_header);
+	if (status != SCI_SUCCESS) {
+		dev_err(scic_to_dev(scic),
+			"%s: SCIC IO Request 0x%p could not get frame header "
+			"for frame index %d, status %x\n",
+			__func__, stp_req, frame_index, status);
+		return status;
+	}
+
+	switch (frame_header->fis_type) {
+	case FIS_REGD2H:
+		scic_sds_unsolicited_frame_control_get_buffer(&scic->uf_control,
+							      frame_index,
+							      (void **)&frame_buffer);
+
+		scic_sds_controller_copy_sata_response(&sci_req->stp.rsp,
+						       frame_header,
+						       frame_buffer);
+
+		/* The command has completed with error */
+		scic_sds_request_set_status(sci_req,
+					    SCU_TASK_DONE_CHECK_RESPONSE,
+					    SCI_FAILURE_IO_RESPONSE_VALID);
+		break;
+
+	default:
+		dev_warn(scic_to_dev(scic),
+			 "%s: IO Request:0x%p Frame Id:%d protocol "
+			 "violation occurred\n", __func__, stp_req,
+			 frame_index);
+
+		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_UNEXP_FIS,
+					    SCI_FAILURE_PROTOCOL_VIOLATION);
+		break;
+	}
+
+	sci_base_state_machine_change_state(&sci_req->state_machine,
+					    SCI_BASE_REQUEST_STATE_COMPLETED);
+
+	/* Frame has been decoded return it to the controller */
+	scic_sds_controller_release_frame(scic, frame_index);
+
+	return status;
+}
+
 static const struct scic_sds_io_request_state_handler scic_sds_request_state_handler_table[] = {
 	[SCI_BASE_REQUEST_STATE_INITIAL] = { },
 	[SCI_BASE_REQUEST_STATE_CONSTRUCTED] = {
@@ -1467,6 +2584,52 @@ static const struct scic_sds_io_request_state_handler scic_sds_request_state_han
 		.abort_handler		= scic_sds_request_started_state_abort_handler,
 		.tc_completion_handler	=  scic_sds_smp_request_await_tc_completion_tc_completion_handler,
 	},
+	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE] = {
+		.abort_handler		= scic_sds_request_started_state_abort_handler,
+		.tc_completion_handler	= scic_sds_stp_request_udma_await_tc_completion_tc_completion_handler,
+		.frame_handler		= scic_sds_stp_request_udma_general_frame_handler,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE] = {
+		.abort_handler		= scic_sds_request_started_state_abort_handler,
+		.frame_handler		= scic_sds_stp_request_udma_await_d2h_reg_fis_frame_handler,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE] = {
+		.abort_handler		= scic_sds_request_started_state_abort_handler,
+		.tc_completion_handler	= scic_sds_stp_request_non_data_await_h2d_tc_completion_handler,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE] = {
+		.abort_handler		= scic_sds_request_started_state_abort_handler,
+		.frame_handler		= scic_sds_stp_request_non_data_await_d2h_frame_handler,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE] = {
+		.abort_handler		= scic_sds_request_started_state_abort_handler,
+		.tc_completion_handler	= scic_sds_stp_request_pio_await_h2d_completion_tc_completion_handler,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE] = {
+		.abort_handler		= scic_sds_request_started_state_abort_handler,
+		.frame_handler		= scic_sds_stp_request_pio_await_frame_frame_handler
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE] = {
+		.abort_handler		= scic_sds_request_started_state_abort_handler,
+		.event_handler		= scic_sds_stp_request_pio_data_in_await_data_event_handler,
+		.frame_handler		= scic_sds_stp_request_pio_data_in_await_data_frame_handler
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE] = {
+		.abort_handler		= scic_sds_request_started_state_abort_handler,
+		.tc_completion_handler	= scic_sds_stp_request_pio_data_out_await_data_transmit_completion_tc_completion_handler,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_ASSERTED_COMPLETION_SUBSTATE] = {
+		.abort_handler		= scic_sds_request_started_state_abort_handler,
+		.tc_completion_handler	= scic_sds_stp_request_soft_reset_await_h2d_asserted_tc_completion_handler,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE] = {
+		.abort_handler		= scic_sds_request_started_state_abort_handler,
+		.tc_completion_handler	= scic_sds_stp_request_soft_reset_await_h2d_diagnostic_tc_completion_handler,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE] = {
+		.abort_handler		= scic_sds_request_started_state_abort_handler,
+		.frame_handler		= scic_sds_stp_request_soft_reset_await_d2h_frame_handler,
+	},
 	[SCI_BASE_REQUEST_STATE_COMPLETED] = {
 		.complete_handler	= scic_sds_request_completed_state_complete_handler,
 	},
@@ -2210,15 +3373,6 @@ static void scic_sds_request_constructed_state_enter(void *object)
 		);
 }
 
-/**
- * scic_sds_request_started_state_enter() -
- * @object: This parameter specifies the base object for which the state
- *    transition is occurring.  This is cast into a SCIC_SDS_IO_REQUEST object.
- *
- * This method implements the actions taken when entering the
- * SCI_BASE_REQUEST_STATE_STARTED state. If the io request object type is a
- * SCSI Task request we must enter the started substate machine. none
- */
 static void scic_sds_request_started_state_enter(void *object)
 {
 	struct scic_sds_request *sci_req = object;
@@ -2238,39 +3392,35 @@ static void scic_sds_request_started_state_enter(void *object)
 		SCI_BASE_REQUEST_STATE_STARTED
 		);
 
-	/* Most of the request state machines have a started substate machine so
-	 * start its execution on the entry to the started state.
+	/* all unaccelerated request types (non ssp or ncq) handled with
+	 * substates
 	 */
-	if (sci_req->has_started_substate_machine == true)
-		sci_base_state_machine_start(&sci_req->started_substate_machine);
-
 	if (!task && dev->dev_type == SAS_END_DEV) {
 		sci_base_state_machine_change_state(sm,
 			SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION);
+	} else if (!task &&
+		   (isci_request_access_tmf(ireq)->tmf_code == isci_tmf_sata_srst_high ||
+		    isci_request_access_tmf(ireq)->tmf_code == isci_tmf_sata_srst_low)) {
+		sci_base_state_machine_change_state(sm,
+			SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_ASSERTED_COMPLETION_SUBSTATE);
 	} else if (task && task->task_proto == SAS_PROTOCOL_SMP) {
 		sci_base_state_machine_change_state(sm,
 			SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE);
+	} else if (task && sas_protocol_ata(task->task_proto) &&
+		   !task->ata_task.use_ncq) {
+		u32 state;
+
+		if (task->data_dir == DMA_NONE)
+			 state = SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE;
+		else if (task->ata_task.dma_xfer)
+			state = SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE;
+		else /* PIO */
+			state = SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE;
+
+		sci_base_state_machine_change_state(sm, state);
 	}
 }
 
-/**
- * scic_sds_request_started_state_exit() -
- * @object: This parameter specifies the base object for which the state
- *    transition is occurring.  This object is cast into a SCIC_SDS_IO_REQUEST
- *    object.
- *
- * This method implements the actions taken when exiting the
- * SCI_BASE_REQUEST_STATE_STARTED state. For task requests the action will be
- * to stop the started substate machine. none
- */
-static void scic_sds_request_started_state_exit(void *object)
-{
-	struct scic_sds_request *sci_req = object;
-
-	if (sci_req->has_started_substate_machine == true)
-		sci_base_state_machine_stop(&sci_req->started_substate_machine);
-}
-
 /**
  * scic_sds_request_completed_state_enter() -
  * @object: This parameter specifies the base object for which the state
@@ -2392,6 +3542,175 @@ static void scic_sds_smp_request_started_await_tc_completion_substate_enter(void
 		);
 }
 
+static void scic_sds_stp_request_started_non_data_await_h2d_completion_enter(
+	void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE
+		);
+
+	scic_sds_remote_device_set_working_request(
+		sci_req->target_device, sci_req
+		);
+}
+
+static void scic_sds_stp_request_started_non_data_await_d2h_enter(void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE
+		);
+}
+
+
+
+static void scic_sds_stp_request_started_pio_await_h2d_completion_enter(
+	void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE
+		);
+
+	scic_sds_remote_device_set_working_request(
+		sci_req->target_device, sci_req);
+}
+
+static void scic_sds_stp_request_started_pio_await_frame_enter(void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE
+		);
+}
+
+static void scic_sds_stp_request_started_pio_data_in_await_data_enter(
+	void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE
+		);
+}
+
+static void scic_sds_stp_request_started_pio_data_out_transmit_data_enter(
+	void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE
+		);
+}
+
+
+
+static void scic_sds_stp_request_started_udma_await_tc_completion_enter(
+	void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE
+		);
+}
+
+/**
+ *
+ *
+ * This state is entered when there is an TC completion failure.  The hardware
+ * received an unexpected condition while processing the IO request and now
+ * will UF the D2H register FIS to complete the IO.
+ */
+static void scic_sds_stp_request_started_udma_await_d2h_reg_fis_enter(
+	void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE
+		);
+}
+
+
+
+static void scic_sds_stp_request_started_soft_reset_await_h2d_asserted_completion_enter(
+	void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_ASSERTED_COMPLETION_SUBSTATE
+		);
+
+	scic_sds_remote_device_set_working_request(
+		sci_req->target_device, sci_req
+		);
+}
+
+static void scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter(
+	void *object)
+{
+	struct scic_sds_request *sci_req = object;
+	struct scu_task_context *task_context;
+	struct host_to_dev_fis *h2d_fis;
+	enum sci_status status;
+
+	/* Clear the SRST bit */
+	h2d_fis = &sci_req->stp.cmd;
+	h2d_fis->control = 0;
+
+	/* Clear the TC control bit */
+	task_context = scic_sds_controller_get_task_context_buffer(
+		sci_req->owning_controller, sci_req->io_tag);
+	task_context->control_frame = 0;
+
+	status = scic_controller_continue_io(sci_req);
+	if (status == SCI_SUCCESS) {
+		SET_STATE_HANDLER(
+			sci_req,
+			scic_sds_request_state_handler_table,
+			SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE
+			);
+	}
+}
+
+static void scic_sds_stp_request_started_soft_reset_await_d2h_response_enter(
+	void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE
+		);
+}
+
 static const struct sci_base_state scic_sds_request_state_table[] = {
 	[SCI_BASE_REQUEST_STATE_INITIAL] = {
 		.enter_state = scic_sds_request_initial_state_enter,
@@ -2401,7 +3720,39 @@ static const struct sci_base_state scic_sds_request_state_table[] = {
 	},
 	[SCI_BASE_REQUEST_STATE_STARTED] = {
 		.enter_state = scic_sds_request_started_state_enter,
-		.exit_state  = scic_sds_request_started_state_exit
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_H2D_COMPLETION_SUBSTATE] = {
+		.enter_state = scic_sds_stp_request_started_non_data_await_h2d_completion_enter,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_NON_DATA_AWAIT_D2H_SUBSTATE] = {
+		.enter_state = scic_sds_stp_request_started_non_data_await_d2h_enter,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_H2D_COMPLETION_SUBSTATE] = {
+		.enter_state = scic_sds_stp_request_started_pio_await_h2d_completion_enter,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_PIO_AWAIT_FRAME_SUBSTATE] = {
+		.enter_state = scic_sds_stp_request_started_pio_await_frame_enter,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_IN_AWAIT_DATA_SUBSTATE] = {
+		.enter_state = scic_sds_stp_request_started_pio_data_in_await_data_enter,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_PIO_DATA_OUT_TRANSMIT_DATA_SUBSTATE] = {
+		.enter_state = scic_sds_stp_request_started_pio_data_out_transmit_data_enter,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_TC_COMPLETION_SUBSTATE] = {
+		.enter_state = scic_sds_stp_request_started_udma_await_tc_completion_enter,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_UDMA_AWAIT_D2H_REG_FIS_SUBSTATE] = {
+		.enter_state = scic_sds_stp_request_started_udma_await_d2h_reg_fis_enter,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_ASSERTED_COMPLETION_SUBSTATE] = {
+		.enter_state = scic_sds_stp_request_started_soft_reset_await_h2d_asserted_completion_enter,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_H2D_DIAGNOSTIC_COMPLETION_SUBSTATE] = {
+		.enter_state = scic_sds_stp_request_started_soft_reset_await_h2d_diagnostic_completion_enter,
+	},
+	[SCIC_SDS_STP_REQUEST_STARTED_SOFT_RESET_AWAIT_D2H_RESPONSE_FRAME_SUBSTATE] = {
+		.enter_state = scic_sds_stp_request_started_soft_reset_await_d2h_response_enter,
 	},
 	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION] = {
 		.enter_state = scic_sds_io_request_started_task_mgmt_await_tc_completion_substate_enter,
@@ -2437,7 +3788,6 @@ static void scic_sds_general_request_construct(struct scic_sds_controller *scic,
 	sci_req->io_tag = io_tag;
 	sci_req->owning_controller = scic;
 	sci_req->target_device = sci_dev;
-	sci_req->has_started_substate_machine = false;
 	sci_req->protocol = SCIC_NO_PROTOCOL;
 	sci_req->saved_rx_frame_index = SCU_INVALID_FRAME_INDEX;
 	sci_req->device_sequence = scic_sds_remote_device_get_sequence(sci_dev);
@@ -3065,6 +4415,3 @@ int isci_request_execute(
 	*isci_request = request;
 	return ret;
 }
-
-
-

commit c72086e3c2897eaca5b99c005dd9844fdc784981
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue May 10 02:28:48 2011 -0700

    isci: merge smp request substates into primary state machine
    
    Remove usage of the request substate machine for smp requests identified by:
            task->task_proto == SAS_PROTOCOL_SMP
    
    While merging over the smp_request infrastructure noticed that all the
    assign buffer implementations are now equal, so moved it to
    scic_sds_general_request_construct.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 5f5168110556..5201dc58a191 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -158,12 +158,6 @@ void scic_sds_request_build_sgl(struct scic_sds_request *sds_request)
 	}
 }
 
-static void scic_sds_ssp_io_request_assign_buffers(struct scic_sds_request *sci_req)
-{
-	if (sci_req->was_tag_assigned_by_user == false)
-		sci_req->task_context_buffer = &sci_req->tc;
-}
-
 static void scic_sds_io_request_build_ssp_command_iu(struct scic_sds_request *sci_req)
 {
 	struct ssp_cmd_iu *cmd_iu;
@@ -341,12 +335,6 @@ static void scu_ssp_io_request_construct_task_context(
 		scic_sds_request_build_sgl(sci_req);
 }
 
-static void scic_sds_ssp_task_request_assign_buffers(struct scic_sds_request *sci_req)
-{
-	if (sci_req->was_tag_assigned_by_user == false)
-		sci_req->task_context_buffer = &sci_req->tc;
-}
-
 /**
  * This method will fill in the SCU Task Context for a SSP Task request.  The
  *    following important settings are utilized: -# priority ==
@@ -1261,6 +1249,196 @@ static enum sci_status scic_sds_ssp_task_request_await_tc_response_frame_handler
 	return SCI_SUCCESS;
 }
 
+/**
+ * This method processes an abnormal TC completion while the SMP request is
+ *    waiting for a response frame.  It decides what happened to the IO based
+ *    on TC completion status.
+ * @sci_req: This parameter specifies the request for which the TC
+ *    completion was received.
+ * @completion_code: This parameter indicates the completion status information
+ *    for the TC.
+ *
+ * Indicate if the tc completion handler was successful. SCI_SUCCESS currently
+ * this method always returns success.
+ */
+static enum sci_status scic_sds_smp_request_await_response_tc_completion_handler(
+	struct scic_sds_request *sci_req,
+	u32 completion_code)
+{
+	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
+		/*
+		 * In the AWAIT RESPONSE state, any TC completion is unexpected.
+		 * but if the TC has success status, we complete the IO anyway. */
+		scic_sds_request_set_status(
+			sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS
+			);
+
+		sci_base_state_machine_change_state(
+			&sci_req->state_machine,
+			SCI_BASE_REQUEST_STATE_COMPLETED);
+		break;
+
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_RESP_TO_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_UFI_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_FRM_TYPE_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_LL_RX_ERR):
+		/*
+		 * These status has been seen in a specific LSI expander, which sometimes
+		 * is not able to send smp response within 2 ms. This causes our hardware
+		 * break the connection and set TC completion with one of these SMP_XXX_XX_ERR
+		 * status. For these type of error, we ask scic user to retry the request. */
+		scic_sds_request_set_status(
+			sci_req, SCU_TASK_DONE_SMP_RESP_TO_ERR, SCI_FAILURE_RETRY_REQUIRED
+			);
+
+		sci_base_state_machine_change_state(
+			&sci_req->state_machine,
+			SCI_BASE_REQUEST_STATE_COMPLETED);
+		break;
+
+	default:
+		/*
+		 * All other completion status cause the IO to be complete.  If a NAK
+		 * was received, then it is up to the user to retry the request. */
+		scic_sds_request_set_status(
+			sci_req,
+			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
+			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
+			);
+
+		sci_base_state_machine_change_state(
+			&sci_req->state_machine,
+			SCI_BASE_REQUEST_STATE_COMPLETED);
+		break;
+	}
+
+	return SCI_SUCCESS;
+}
+
+/*
+ * This function processes an unsolicited frame while the SMP request is waiting
+ *    for a response frame.  It will copy the response data, release the
+ *    unsolicited frame, and transition the request to the
+ *    SCI_BASE_REQUEST_STATE_COMPLETED state.
+ * @sci_req: This parameter specifies the request for which the
+ *    unsolicited frame was received.
+ * @frame_index: This parameter indicates the unsolicited frame index that
+ *    should contain the response.
+ *
+ * This function returns an indication of whether the response frame was handled
+ * successfully or not. SCI_SUCCESS Currently this value is always returned and
+ * indicates successful processing of the TC response.
+ */
+static enum sci_status
+scic_sds_smp_request_await_response_frame_handler(struct scic_sds_request *sci_req,
+						  u32 frame_index)
+{
+	enum sci_status status;
+	void *frame_header;
+	struct smp_resp *rsp_hdr = &sci_req->smp.rsp;
+	ssize_t word_cnt = SMP_RESP_HDR_SZ / sizeof(u32);
+
+	status = scic_sds_unsolicited_frame_control_get_header(
+		&(scic_sds_request_get_controller(sci_req)->uf_control),
+		frame_index,
+		&frame_header);
+
+	/* byte swap the header. */
+	sci_swab32_cpy(rsp_hdr, frame_header, word_cnt);
+
+	if (rsp_hdr->frame_type == SMP_RESPONSE) {
+		void *smp_resp;
+
+		status = scic_sds_unsolicited_frame_control_get_buffer(
+			&(scic_sds_request_get_controller(sci_req)->uf_control),
+			frame_index,
+			&smp_resp);
+
+		word_cnt = (sizeof(struct smp_req) - SMP_RESP_HDR_SZ) /
+			sizeof(u32);
+
+		sci_swab32_cpy(((u8 *) rsp_hdr) + SMP_RESP_HDR_SZ,
+			       smp_resp, word_cnt);
+
+		scic_sds_request_set_status(
+			sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS);
+
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+			SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION);
+	} else {
+		/* This was not a response frame why did it get forwarded? */
+		dev_err(scic_to_dev(sci_req->owning_controller),
+			"%s: SCIC SMP Request 0x%p received unexpected frame "
+			"%d type 0x%02x\n",
+			__func__,
+			sci_req,
+			frame_index,
+			rsp_hdr->frame_type);
+
+		scic_sds_request_set_status(
+			sci_req,
+			SCU_TASK_DONE_SMP_FRM_TYPE_ERR,
+			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
+
+		sci_base_state_machine_change_state(
+			&sci_req->state_machine,
+			SCI_BASE_REQUEST_STATE_COMPLETED);
+	}
+
+	scic_sds_controller_release_frame(sci_req->owning_controller,
+					  frame_index);
+
+	return SCI_SUCCESS;
+}
+
+/**
+ * This method processes the completions transport layer (TL) status to
+ *    determine if the SMP request was sent successfully. If the SMP request
+ *    was sent successfully, then the state for the SMP request transits to
+ *    waiting for a response frame.
+ * @sci_req: This parameter specifies the request for which the TC
+ *    completion was received.
+ * @completion_code: This parameter indicates the completion status information
+ *    for the TC.
+ *
+ * Indicate if the tc completion handler was successful. SCI_SUCCESS currently
+ * this method always returns success.
+ */
+static enum sci_status scic_sds_smp_request_await_tc_completion_tc_completion_handler(
+	struct scic_sds_request *sci_req,
+	u32 completion_code)
+{
+	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
+		scic_sds_request_set_status(
+			sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS
+			);
+
+		sci_base_state_machine_change_state(
+			&sci_req->state_machine,
+			SCI_BASE_REQUEST_STATE_COMPLETED);
+		break;
+
+	default:
+		/*
+		 * All other completion status cause the IO to be complete.  If a NAK
+		 * was received, then it is up to the user to retry the request. */
+		scic_sds_request_set_status(
+			sci_req,
+			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
+			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
+			);
+
+		sci_base_state_machine_change_state(
+			&sci_req->state_machine,
+			SCI_BASE_REQUEST_STATE_COMPLETED);
+		break;
+	}
+
+	return SCI_SUCCESS;
+}
+
 static const struct scic_sds_io_request_state_handler scic_sds_request_state_handler_table[] = {
 	[SCI_BASE_REQUEST_STATE_INITIAL] = { },
 	[SCI_BASE_REQUEST_STATE_CONSTRUCTED] = {
@@ -1280,6 +1458,15 @@ static const struct scic_sds_io_request_state_handler scic_sds_request_state_han
 		.abort_handler		= scic_sds_ssp_task_request_await_tc_response_abort_handler,
 		.frame_handler		= scic_sds_ssp_task_request_await_tc_response_frame_handler,
 	},
+	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE] = {
+		.abort_handler		= scic_sds_request_started_state_abort_handler,
+		.tc_completion_handler	= scic_sds_smp_request_await_response_tc_completion_handler,
+		.frame_handler		= scic_sds_smp_request_await_response_frame_handler,
+	},
+	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION] = {
+		.abort_handler		= scic_sds_request_started_state_abort_handler,
+		.tc_completion_handler	=  scic_sds_smp_request_await_tc_completion_tc_completion_handler,
+	},
 	[SCI_BASE_REQUEST_STATE_COMPLETED] = {
 		.complete_handler	= scic_sds_request_completed_state_complete_handler,
 	},
@@ -2038,6 +2225,12 @@ static void scic_sds_request_started_state_enter(void *object)
 	struct sci_base_state_machine *sm = &sci_req->state_machine;
 	struct isci_request *ireq = sci_req_to_ireq(sci_req);
 	struct domain_device *dev = sci_dev_to_domain(sci_req->target_device);
+	struct sas_task *task;
+
+	/* XXX as hch said always creating an internal sas_task for tmf
+	 * requests would simplify the driver
+	 */
+	task = ireq->ttype == io_task ? isci_request_access_task(ireq) : NULL;
 
 	SET_STATE_HANDLER(
 		sci_req,
@@ -2045,15 +2238,19 @@ static void scic_sds_request_started_state_enter(void *object)
 		SCI_BASE_REQUEST_STATE_STARTED
 		);
 
-	if (ireq->ttype == tmf_task && dev->dev_type == SAS_END_DEV)
-		sci_base_state_machine_change_state(sm,
-			SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION);
-
 	/* Most of the request state machines have a started substate machine so
 	 * start its execution on the entry to the started state.
 	 */
 	if (sci_req->has_started_substate_machine == true)
 		sci_base_state_machine_start(&sci_req->started_substate_machine);
+
+	if (!task && dev->dev_type == SAS_END_DEV) {
+		sci_base_state_machine_change_state(sm,
+			SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION);
+	} else if (task && task->task_proto == SAS_PROTOCOL_SMP) {
+		sci_base_state_machine_change_state(sm,
+			SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE);
+	}
 }
 
 /**
@@ -2173,6 +2370,28 @@ static void scic_sds_io_request_started_task_mgmt_await_task_response_substate_e
 		);
 }
 
+static void scic_sds_smp_request_started_await_response_substate_enter(void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE
+		);
+}
+
+static void scic_sds_smp_request_started_await_tc_completion_substate_enter(void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION
+		);
+}
+
 static const struct sci_base_state scic_sds_request_state_table[] = {
 	[SCI_BASE_REQUEST_STATE_INITIAL] = {
 		.enter_state = scic_sds_request_initial_state_enter,
@@ -2190,6 +2409,12 @@ static const struct sci_base_state scic_sds_request_state_table[] = {
 	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE] = {
 		.enter_state = scic_sds_io_request_started_task_mgmt_await_task_response_substate_enter,
 	},
+	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_RESPONSE] = {
+		.enter_state = scic_sds_smp_request_started_await_response_substate_enter,
+	},
+	[SCIC_SDS_SMP_REQUEST_STARTED_SUBSTATE_AWAIT_TC_COMPLETION] = {
+		.enter_state = scic_sds_smp_request_started_await_tc_completion_substate_enter,
+	},
 	[SCI_BASE_REQUEST_STATE_COMPLETED] = {
 		.enter_state = scic_sds_request_completed_state_enter,
 	},
@@ -2225,7 +2450,7 @@ static void scic_sds_general_request_construct(struct scic_sds_controller *scic,
 
 	if (io_tag == SCI_CONTROLLER_INVALID_IO_TAG) {
 		sci_req->was_tag_assigned_by_user = false;
-		sci_req->task_context_buffer = NULL;
+		sci_req->task_context_buffer = &sci_req->tc;
 	} else {
 		sci_req->was_tag_assigned_by_user = true;
 
@@ -2245,26 +2470,20 @@ scic_io_request_construct(struct scic_sds_controller *scic,
 	/* Build the common part of the request */
 	scic_sds_general_request_construct(scic, sci_dev, io_tag, sci_req);
 
-	if (sci_dev->rnc.remote_node_index ==
-			SCIC_SDS_REMOTE_NODE_CONTEXT_INVALID_INDEX)
+	if (sci_dev->rnc.remote_node_index == SCIC_SDS_REMOTE_NODE_CONTEXT_INVALID_INDEX)
 		return SCI_FAILURE_INVALID_REMOTE_DEVICE;
 
 	if (dev->dev_type == SAS_END_DEV)
-		scic_sds_ssp_io_request_assign_buffers(sci_req);
-	else if ((dev->dev_type == SATA_DEV) ||
-		 (dev->tproto & SAS_PROTOCOL_STP)) {
-		scic_sds_stp_request_assign_buffers(sci_req);
+		/* pass */;
+	else if (dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP))
 		memset(&sci_req->stp.cmd, 0, sizeof(sci_req->stp.cmd));
-	} else if (dev_is_expander(dev)) {
-		scic_sds_smp_request_assign_buffers(sci_req);
+	else if (dev_is_expander(dev))
 		memset(&sci_req->smp.cmd, 0, sizeof(sci_req->smp.cmd));
-	} else
-		status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;
+	else
+		return SCI_FAILURE_UNSUPPORTED_PROTOCOL;
 
-	if (status == SCI_SUCCESS) {
-		memset(sci_req->task_context_buffer, 0,
-		       offsetof(struct scu_task_context, sgl_pair_ab));
-	}
+	memset(sci_req->task_context_buffer, 0,
+	       offsetof(struct scu_task_context, sgl_pair_ab));
 
 	return status;
 }
@@ -2279,17 +2498,12 @@ enum sci_status scic_task_request_construct(struct scic_sds_controller *scic,
 	/* Build the common part of the request */
 	scic_sds_general_request_construct(scic, sci_dev, io_tag, sci_req);
 
-	if (dev->dev_type == SAS_END_DEV)
-		scic_sds_ssp_task_request_assign_buffers(sci_req);
-	else if (dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP))
-		scic_sds_stp_request_assign_buffers(sci_req);
-	else
-		status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;
-
-	if (status == SCI_SUCCESS) {
+	if (dev->dev_type == SAS_END_DEV ||
+	    dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP)) {
 		sci_req->is_task_management_request = true;
 		memset(sci_req->task_context_buffer, 0, sizeof(struct scu_task_context));
-	}
+	} else
+		status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;
 
 	return status;
 }
@@ -2340,6 +2554,174 @@ static enum sci_status isci_request_stp_request_construct(
 	return status;
 }
 
+/*
+ * This function will fill in the SCU Task Context for a SMP request. The
+ *    following important settings are utilized: -# task_type ==
+ *    SCU_TASK_TYPE_SMP.  This simply indicates that a normal request type
+ *    (i.e. non-raw frame) is being utilized to perform task management. -#
+ *    control_frame == 1.  This ensures that the proper endianess is set so
+ *    that the bytes are transmitted in the right order for a smp request frame.
+ * @sci_req: This parameter specifies the smp request object being
+ *    constructed.
+ *
+ */
+static void
+scu_smp_request_construct_task_context(struct scic_sds_request *sci_req,
+				       struct smp_req *smp_req)
+{
+	dma_addr_t dma_addr;
+	struct scic_sds_controller *scic;
+	struct scic_sds_remote_device *sci_dev;
+	struct scic_sds_port *sci_port;
+	struct scu_task_context *task_context;
+	ssize_t word_cnt = sizeof(struct smp_req) / sizeof(u32);
+
+	/* byte swap the smp request. */
+	sci_swab32_cpy(&sci_req->smp.cmd, smp_req,
+		       word_cnt);
+
+	task_context = scic_sds_request_get_task_context(sci_req);
+
+	scic = scic_sds_request_get_controller(sci_req);
+	sci_dev = scic_sds_request_get_device(sci_req);
+	sci_port = scic_sds_request_get_port(sci_req);
+
+	/*
+	 * Fill in the TC with the its required data
+	 * 00h
+	 */
+	task_context->priority = 0;
+	task_context->initiator_request = 1;
+	task_context->connection_rate = sci_dev->connection_rate;
+	task_context->protocol_engine_index =
+		scic_sds_controller_get_protocol_engine_group(scic);
+	task_context->logical_port_index = scic_sds_port_get_index(sci_port);
+	task_context->protocol_type = SCU_TASK_CONTEXT_PROTOCOL_SMP;
+	task_context->abort = 0;
+	task_context->valid = SCU_TASK_CONTEXT_VALID;
+	task_context->context_type = SCU_TASK_CONTEXT_TYPE;
+
+	/* 04h */
+	task_context->remote_node_index = sci_dev->rnc.remote_node_index;
+	task_context->command_code = 0;
+	task_context->task_type = SCU_TASK_TYPE_SMP_REQUEST;
+
+	/* 08h */
+	task_context->link_layer_control = 0;
+	task_context->do_not_dma_ssp_good_response = 1;
+	task_context->strict_ordering = 0;
+	task_context->control_frame = 1;
+	task_context->timeout_enable = 0;
+	task_context->block_guard_enable = 0;
+
+	/* 0ch */
+	task_context->address_modifier = 0;
+
+	/* 10h */
+	task_context->ssp_command_iu_length = smp_req->req_len;
+
+	/* 14h */
+	task_context->transfer_length_bytes = 0;
+
+	/*
+	 * 18h ~ 30h, protocol specific
+	 * since commandIU has been build by framework at this point, we just
+	 * copy the frist DWord from command IU to this location. */
+	memcpy(&task_context->type.smp, &sci_req->smp.cmd, sizeof(u32));
+
+	/*
+	 * 40h
+	 * "For SMP you could program it to zero. We would prefer that way
+	 * so that done code will be consistent." - Venki
+	 */
+	task_context->task_phase = 0;
+
+	if (sci_req->was_tag_assigned_by_user) {
+		/*
+		 * Build the task context now since we have already read
+		 * the data
+		 */
+		sci_req->post_context =
+			(SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
+			 (scic_sds_controller_get_protocol_engine_group(scic) <<
+			  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
+			 (scic_sds_port_get_index(sci_port) <<
+			  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
+			 scic_sds_io_tag_get_index(sci_req->io_tag));
+	} else {
+		/*
+		 * Build the task context now since we have already read
+		 * the data.
+		 * I/O tag index is not assigned because we have to wait
+		 * until we get a TCi.
+		 */
+		sci_req->post_context =
+			(SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
+			 (scic_sds_controller_get_protocol_engine_group(scic) <<
+			  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
+			 (scic_sds_port_get_index(sci_port) <<
+			  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT));
+	}
+
+	/*
+	 * Copy the physical address for the command buffer to the SCU Task
+	 * Context command buffer should not contain command header.
+	 */
+	dma_addr = scic_io_request_get_dma_addr(sci_req,
+						((char *) &sci_req->smp.cmd) +
+						sizeof(u32));
+
+	task_context->command_iu_upper = upper_32_bits(dma_addr);
+	task_context->command_iu_lower = lower_32_bits(dma_addr);
+
+	/* SMP response comes as UF, so no need to set response IU address. */
+	task_context->response_iu_upper = 0;
+	task_context->response_iu_lower = 0;
+}
+
+static enum sci_status scic_io_request_construct_smp(struct scic_sds_request *sci_req)
+{
+	struct smp_req *smp_req = kmalloc(sizeof(*smp_req), GFP_KERNEL);
+
+	if (!smp_req)
+		return SCI_FAILURE_INSUFFICIENT_RESOURCES;
+
+	sci_req->protocol = SCIC_SMP_PROTOCOL;
+
+	/* Construct the SMP SCU Task Context */
+	memcpy(smp_req, &sci_req->smp.cmd, sizeof(*smp_req));
+
+	/*
+	 * Look at the SMP requests' header fields; for certain SAS 1.x SMP
+	 * functions under SAS 2.0, a zero request length really indicates
+	 * a non-zero default length. */
+	if (smp_req->req_len == 0) {
+		switch (smp_req->func) {
+		case SMP_DISCOVER:
+		case SMP_REPORT_PHY_ERR_LOG:
+		case SMP_REPORT_PHY_SATA:
+		case SMP_REPORT_ROUTE_INFO:
+			smp_req->req_len = 2;
+			break;
+		case SMP_CONF_ROUTE_INFO:
+		case SMP_PHY_CONTROL:
+		case SMP_PHY_TEST_FUNCTION:
+			smp_req->req_len = 9;
+			break;
+			/* Default - zero is a valid default for 2.0. */
+		}
+	}
+
+	scu_smp_request_construct_task_context(sci_req, smp_req);
+
+	sci_base_state_machine_change_state(&sci_req->state_machine,
+		SCI_BASE_REQUEST_STATE_CONSTRUCTED);
+
+	kfree(smp_req);
+
+	return SCI_SUCCESS;
+}
+
 /*
  * isci_smp_request_build() - This function builds the smp request.
  * @ireq: This parameter points to the isci_request allocated in the

commit f139303d17c47eff4c5b5407dee0a6d43e8fd146
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue May 10 02:28:47 2011 -0700

    isci: merge ssp task management substates into primary state machine
    
    Remove usage of the request substate machine for ssp task management
    requests identified by:
            ireq->ttype == tmf_task && dev->dev_type == SAS_END_DEV;
    
    The only routine that checks the base 'started' state is
    scic_sds_io_request_tc_completion which calls the substate machine
    handler if we are not in the 'started' state or we are 'started' and no
    substate machine is defined.  This routine requires no conversion
    because we have transitioned out of 'started' and the substate routine
    will be called naturally as a result.
    
    There are also no side effects of this conversion on exiting the
    'started', state because it only stops the substate machine, which is no
    longer relevant for this transaction type.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 48e2dac72528..5f5168110556 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -656,7 +656,7 @@ enum sci_status scic_sds_io_request_frame_handler(
  * @sci_req: This parameter specifies the request object for which to copy
  *    the response data.
  */
-void scic_sds_io_request_copy_response(struct scic_sds_request *sci_req)
+static void scic_sds_io_request_copy_response(struct scic_sds_request *sci_req)
 {
 	void *resp_buf;
 	u32 len;
@@ -978,7 +978,6 @@ scic_sds_io_request_tc_completion(struct scic_sds_request *request, u32 completi
 		sci_base_state_machine_get_state(&request->state_machine));
 
 	return SCI_FAILURE_INVALID_STATE;
-
 }
 
 /*
@@ -1151,9 +1150,119 @@ static enum sci_status scic_sds_request_aborting_state_frame_handler(
 	return SCI_SUCCESS;
 }
 
+/**
+ * This method processes the completions transport layer (TL) status to
+ *    determine if the RAW task management frame was sent successfully. If the
+ *    raw frame was sent successfully, then the state for the task request
+ *    transitions to waiting for a response frame.
+ * @sci_req: This parameter specifies the request for which the TC
+ *    completion was received.
+ * @completion_code: This parameter indicates the completion status information
+ *    for the TC.
+ *
+ * Indicate if the tc completion handler was successful. SCI_SUCCESS currently
+ * this method always returns success.
+ */
+static enum sci_status scic_sds_ssp_task_request_await_tc_completion_tc_completion_handler(
+	struct scic_sds_request *sci_req,
+	u32 completion_code)
+{
+	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
+		scic_sds_request_set_status(sci_req, SCU_TASK_DONE_GOOD,
+					    SCI_SUCCESS);
+
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+			SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE);
+		break;
+
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_ACK_NAK_TO):
+		/*
+		 * Currently, the decision is to simply allow the task request to
+		 * timeout if the task IU wasn't received successfully.
+		 * There is a potential for receiving multiple task responses if we
+		 * decide to send the task IU again. */
+		dev_warn(scic_to_dev(sci_req->owning_controller),
+			 "%s: TaskRequest:0x%p CompletionCode:%x - "
+			 "ACK/NAK timeout\n",
+			 __func__,
+			 sci_req,
+			 completion_code);
+
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+			SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE);
+		break;
+
+	default:
+		/*
+		 * All other completion status cause the IO to be complete.  If a NAK
+		 * was received, then it is up to the user to retry the request. */
+		scic_sds_request_set_status(
+			sci_req,
+			SCU_NORMALIZE_COMPLETION_STATUS(completion_code),
+			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR
+			);
+
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+			SCI_BASE_REQUEST_STATE_COMPLETED);
+		break;
+	}
+
+	return SCI_SUCCESS;
+}
+
+/**
+ * This method is responsible for processing a terminate/abort request for this
+ *    TC while the request is waiting for the task management response
+ *    unsolicited frame.
+ * @sci_req: This parameter specifies the request for which the
+ *    termination was requested.
+ *
+ * This method returns an indication as to whether the abort request was
+ * successfully handled. need to update to ensure the received UF doesn't cause
+ * damage to subsequent requests (i.e. put the extended tag in a holding
+ * pattern for this particular device).
+ */
+static enum sci_status scic_sds_ssp_task_request_await_tc_response_abort_handler(
+	struct scic_sds_request *request)
+{
+	sci_base_state_machine_change_state(&request->state_machine,
+			SCI_BASE_REQUEST_STATE_ABORTING);
+	sci_base_state_machine_change_state(&request->state_machine,
+			SCI_BASE_REQUEST_STATE_COMPLETED);
+	return SCI_SUCCESS;
+}
+
+/**
+ * This method processes an unsolicited frame while the task mgmt request is
+ *    waiting for a response frame.  It will copy the response data, release
+ *    the unsolicited frame, and transition the request to the
+ *    SCI_BASE_REQUEST_STATE_COMPLETED state.
+ * @sci_req: This parameter specifies the request for which the
+ *    unsolicited frame was received.
+ * @frame_index: This parameter indicates the unsolicited frame index that
+ *    should contain the response.
+ *
+ * This method returns an indication of whether the TC response frame was
+ * handled successfully or not. SCI_SUCCESS Currently this value is always
+ * returned and indicates successful processing of the TC response. Should
+ * probably update to check frame type and make sure it is a response frame.
+ */
+static enum sci_status scic_sds_ssp_task_request_await_tc_response_frame_handler(
+	struct scic_sds_request *request,
+	u32 frame_index)
+{
+	scic_sds_io_request_copy_response(request);
+
+	sci_base_state_machine_change_state(&request->state_machine,
+		SCI_BASE_REQUEST_STATE_COMPLETED);
+	scic_sds_controller_release_frame(request->owning_controller,
+			frame_index);
+	return SCI_SUCCESS;
+}
+
 static const struct scic_sds_io_request_state_handler scic_sds_request_state_handler_table[] = {
-	[SCI_BASE_REQUEST_STATE_INITIAL] = {
-	},
+	[SCI_BASE_REQUEST_STATE_INITIAL] = { },
 	[SCI_BASE_REQUEST_STATE_CONSTRUCTED] = {
 		.start_handler		= scic_sds_request_constructed_state_start_handler,
 		.abort_handler		= scic_sds_request_constructed_state_abort_handler,
@@ -1163,6 +1272,14 @@ static const struct scic_sds_io_request_state_handler scic_sds_request_state_han
 		.tc_completion_handler	= scic_sds_request_started_state_tc_completion_handler,
 		.frame_handler		= scic_sds_request_started_state_frame_handler,
 	},
+	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION] = {
+		.abort_handler		= scic_sds_request_started_state_abort_handler,
+		.tc_completion_handler	= scic_sds_ssp_task_request_await_tc_completion_tc_completion_handler,
+	},
+	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE] = {
+		.abort_handler		= scic_sds_ssp_task_request_await_tc_response_abort_handler,
+		.frame_handler		= scic_sds_ssp_task_request_await_tc_response_frame_handler,
+	},
 	[SCI_BASE_REQUEST_STATE_COMPLETED] = {
 		.complete_handler	= scic_sds_request_completed_state_complete_handler,
 	},
@@ -1171,8 +1288,7 @@ static const struct scic_sds_io_request_state_handler scic_sds_request_state_han
 		.tc_completion_handler	= scic_sds_request_aborting_state_tc_completion_handler,
 		.frame_handler		= scic_sds_request_aborting_state_frame_handler,
 	},
-	[SCI_BASE_REQUEST_STATE_FINAL] = {
-	},
+	[SCI_BASE_REQUEST_STATE_FINAL] = { },
 };
 
 
@@ -1919,6 +2035,9 @@ static void scic_sds_request_constructed_state_enter(void *object)
 static void scic_sds_request_started_state_enter(void *object)
 {
 	struct scic_sds_request *sci_req = object;
+	struct sci_base_state_machine *sm = &sci_req->state_machine;
+	struct isci_request *ireq = sci_req_to_ireq(sci_req);
+	struct domain_device *dev = sci_dev_to_domain(sci_req->target_device);
 
 	SET_STATE_HANDLER(
 		sci_req,
@@ -1926,9 +2045,13 @@ static void scic_sds_request_started_state_enter(void *object)
 		SCI_BASE_REQUEST_STATE_STARTED
 		);
 
-	/*
-	 * Most of the request state machines have a started substate machine so
-	 * start its execution on the entry to the started state. */
+	if (ireq->ttype == tmf_task && dev->dev_type == SAS_END_DEV)
+		sci_base_state_machine_change_state(sm,
+			SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION);
+
+	/* Most of the request state machines have a started substate machine so
+	 * start its execution on the entry to the started state.
+	 */
 	if (sci_req->has_started_substate_machine == true)
 		sci_base_state_machine_start(&sci_req->started_substate_machine);
 }
@@ -2026,6 +2149,30 @@ static void scic_sds_request_final_state_enter(void *object)
 		);
 }
 
+static void scic_sds_io_request_started_task_mgmt_await_tc_completion_substate_enter(
+	void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION
+		);
+}
+
+static void scic_sds_io_request_started_task_mgmt_await_task_response_substate_enter(
+	void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE
+		);
+}
+
 static const struct sci_base_state scic_sds_request_state_table[] = {
 	[SCI_BASE_REQUEST_STATE_INITIAL] = {
 		.enter_state = scic_sds_request_initial_state_enter,
@@ -2037,6 +2184,12 @@ static const struct sci_base_state scic_sds_request_state_table[] = {
 		.enter_state = scic_sds_request_started_state_enter,
 		.exit_state  = scic_sds_request_started_state_exit
 	},
+	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION] = {
+		.enter_state = scic_sds_io_request_started_task_mgmt_await_tc_completion_substate_enter,
+	},
+	[SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_RESPONSE] = {
+		.enter_state = scic_sds_io_request_started_task_mgmt_await_task_response_substate_enter,
+	},
 	[SCI_BASE_REQUEST_STATE_COMPLETED] = {
 		.enter_state = scic_sds_request_completed_state_enter,
 	},
@@ -2126,19 +2279,9 @@ enum sci_status scic_task_request_construct(struct scic_sds_controller *scic,
 	/* Build the common part of the request */
 	scic_sds_general_request_construct(scic, sci_dev, io_tag, sci_req);
 
-	if (dev->dev_type == SAS_END_DEV) {
+	if (dev->dev_type == SAS_END_DEV)
 		scic_sds_ssp_task_request_assign_buffers(sci_req);
-
-		sci_req->has_started_substate_machine = true;
-
-		/* Construct the started sub-state machine. */
-		sci_base_state_machine_construct(
-			&sci_req->started_substate_machine,
-			sci_req,
-			scic_sds_io_request_started_task_mgmt_substate_table,
-			SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION
-			);
-	} else if (dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP))
+	else if (dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP))
 		scic_sds_stp_request_assign_buffers(sci_req);
 	else
 		status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;

commit e2f8db509fdd354bb7a68c86515e9d2d8909ccc9
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue May 10 02:28:46 2011 -0700

    isci: uplevel port infrastructure
    
    * Move port configuration agent implementation
    * Merge core/scic_sds_port.[ch] into port.[ch]
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 857ad067f11c..48e2dac72528 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -54,7 +54,6 @@
  */
 
 #include "isci.h"
-#include "scic_port.h"
 #include "task.h"
 #include "request.h"
 #include "sata.h"

commit f1f52e75939b56c40b3d153ae99faf2720250242
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue May 10 02:28:45 2011 -0700

    isci: uplevel request infrastructure
    
    * Consolidate tiny header files
    * Move files out of core/ (drop core/scic_sds_ prefix)
    * Merge core/scic_sds_request.[ch] into request.[ch]
    * Cleanup request.c namespace (clean forward declarations and global
      namespace pollution)
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 4961ee347091..857ad067f11c 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -54,898 +54,1286 @@
  */
 
 #include "isci.h"
-#include "scic_io_request.h"
-#include "scic_task_request.h"
 #include "scic_port.h"
 #include "task.h"
 #include "request.h"
 #include "sata.h"
 #include "scu_completion_codes.h"
-#include "scic_sds_request.h"
 #include "sas.h"
 
-static enum sci_status isci_request_ssp_request_construct(
-	struct isci_request *request)
-{
-	enum sci_status status;
+/**
+ * This method returns the sgl element pair for the specificed sgl_pair index.
+ * @sci_req: This parameter specifies the IO request for which to retrieve
+ *    the Scatter-Gather List element pair.
+ * @sgl_pair_index: This parameter specifies the index into the SGL element
+ *    pair to be retrieved.
+ *
+ * This method returns a pointer to an struct scu_sgl_element_pair.
+ */
+static struct scu_sgl_element_pair *scic_sds_request_get_sgl_element_pair(
+	struct scic_sds_request *sci_req,
+	u32 sgl_pair_index
+	) {
+	struct scu_task_context *task_context;
+
+	task_context = (struct scu_task_context *)sci_req->task_context_buffer;
+
+	if (sgl_pair_index == 0) {
+		return &task_context->sgl_pair_ab;
+	} else if (sgl_pair_index == 1) {
+		return &task_context->sgl_pair_cd;
+	}
 
-	dev_dbg(&request->isci_host->pdev->dev,
-		"%s: request = %p\n",
-		__func__,
-		request);
-	status = scic_io_request_construct_basic_ssp(&request->sci);
-	return status;
+	return &sci_req->sg_table[sgl_pair_index - 2];
 }
 
-static enum sci_status isci_request_stp_request_construct(
-	struct isci_request *request)
+/**
+ * This function will build the SGL list for an IO request.
+ * @sci_req: This parameter specifies the IO request for which to build
+ *    the Scatter-Gather List.
+ *
+ */
+void scic_sds_request_build_sgl(struct scic_sds_request *sds_request)
 {
-	struct sas_task *task = isci_request_access_task(request);
-	enum sci_status status;
-	struct host_to_dev_fis *register_fis;
-
-	dev_dbg(&request->isci_host->pdev->dev,
-		"%s: request = %p\n",
-		__func__,
-		request);
+	struct isci_request *isci_request = sci_req_to_ireq(sds_request);
+	struct isci_host *isci_host = isci_request->isci_host;
+	struct sas_task *task = isci_request_access_task(isci_request);
+	struct scatterlist *sg = NULL;
+	dma_addr_t dma_addr;
+	u32 sg_idx = 0;
+	struct scu_sgl_element_pair *scu_sg   = NULL;
+	struct scu_sgl_element_pair *prev_sg  = NULL;
+
+	if (task->num_scatter > 0) {
+		sg = task->scatter;
+
+		while (sg) {
+			scu_sg = scic_sds_request_get_sgl_element_pair(
+					sds_request,
+					sg_idx);
+
+			SCU_SGL_COPY(scu_sg->A, sg);
+
+			sg = sg_next(sg);
+
+			if (sg) {
+				SCU_SGL_COPY(scu_sg->B, sg);
+				sg = sg_next(sg);
+			} else
+				SCU_SGL_ZERO(scu_sg->B);
+
+			if (prev_sg) {
+				dma_addr =
+					scic_io_request_get_dma_addr(
+							sds_request,
+							scu_sg);
+
+				prev_sg->next_pair_upper =
+					upper_32_bits(dma_addr);
+				prev_sg->next_pair_lower =
+					lower_32_bits(dma_addr);
+			}
+
+			prev_sg = scu_sg;
+			sg_idx++;
+		}
+	} else {	/* handle when no sg */
+		scu_sg = scic_sds_request_get_sgl_element_pair(sds_request,
+							       sg_idx);
 
-	/* Get the host_to_dev_fis from the core and copy
-	 * the fis from the task into it.
-	 */
-	register_fis = isci_sata_task_to_fis_copy(task);
+		dma_addr = dma_map_single(&isci_host->pdev->dev,
+					  task->scatter,
+					  task->total_xfer_len,
+					  task->data_dir);
 
-	status = scic_io_request_construct_basic_sata(&request->sci);
+		isci_request->zero_scatter_daddr = dma_addr;
 
-	/* Set the ncq tag in the fis, from the queue
-	 * command in the task.
-	 */
-	if (isci_sata_is_task_ncq(task)) {
+		scu_sg->A.length = task->total_xfer_len;
+		scu_sg->A.address_upper = upper_32_bits(dma_addr);
+		scu_sg->A.address_lower = lower_32_bits(dma_addr);
+	}
 
-		isci_sata_set_ncq_tag(
-			register_fis,
-			task
-			);
+	if (scu_sg) {
+		scu_sg->next_pair_upper = 0;
+		scu_sg->next_pair_lower = 0;
 	}
+}
 
-	return status;
+static void scic_sds_ssp_io_request_assign_buffers(struct scic_sds_request *sci_req)
+{
+	if (sci_req->was_tag_assigned_by_user == false)
+		sci_req->task_context_buffer = &sci_req->tc;
 }
 
-/*
- * isci_smp_request_build() - This function builds the smp request.
- * @ireq: This parameter points to the isci_request allocated in the
- *    request construct function.
- *
- * SCI_SUCCESS on successfull completion, or specific failure code.
- */
-static enum sci_status isci_smp_request_build(struct isci_request *ireq)
+static void scic_sds_io_request_build_ssp_command_iu(struct scic_sds_request *sci_req)
 {
-	enum sci_status status = SCI_FAILURE;
+	struct ssp_cmd_iu *cmd_iu;
+	struct isci_request *ireq = sci_req_to_ireq(sci_req);
 	struct sas_task *task = isci_request_access_task(ireq);
-	struct scic_sds_request *sci_req = &ireq->sci;
 
-	dev_dbg(&ireq->isci_host->pdev->dev,
-		"%s: request = %p\n", __func__, ireq);
+	cmd_iu = &sci_req->ssp.cmd;
 
-	dev_dbg(&ireq->isci_host->pdev->dev,
-		"%s: smp_req len = %d\n",
-		__func__,
-		task->smp_task.smp_req.length);
+	memcpy(cmd_iu->LUN, task->ssp_task.LUN, 8);
+	cmd_iu->add_cdb_len = 0;
+	cmd_iu->_r_a = 0;
+	cmd_iu->_r_b = 0;
+	cmd_iu->en_fburst = 0; /* unsupported */
+	cmd_iu->task_prio = task->ssp_task.task_prio;
+	cmd_iu->task_attr = task->ssp_task.task_attr;
+	cmd_iu->_r_c = 0;
 
-	/* copy the smp_command to the address; */
-	sg_copy_to_buffer(&task->smp_task.smp_req, 1,
-			  &sci_req->smp.cmd,
-			  sizeof(struct smp_req));
+	sci_swab32_cpy(&cmd_iu->cdb, task->ssp_task.cdb,
+		       sizeof(task->ssp_task.cdb) / sizeof(u32));
+}
 
-	status = scic_io_request_construct_smp(sci_req);
-	if (status != SCI_SUCCESS)
-		dev_warn(&ireq->isci_host->pdev->dev,
-			 "%s: failed with status = %d\n",
-			 __func__,
-			 status);
+static void scic_sds_task_request_build_ssp_task_iu(struct scic_sds_request *sci_req)
+{
+	struct ssp_task_iu *task_iu;
+	struct isci_request *ireq = sci_req_to_ireq(sci_req);
+	struct sas_task *task = isci_request_access_task(ireq);
+	struct isci_tmf *isci_tmf = isci_request_access_tmf(ireq);
 
-	return status;
+	task_iu = &sci_req->ssp.tmf;
+
+	memset(task_iu, 0, sizeof(struct ssp_task_iu));
+
+	memcpy(task_iu->LUN, task->ssp_task.LUN, 8);
+
+	task_iu->task_func = isci_tmf->tmf_code;
+	task_iu->task_tag =
+		(ireq->ttype == tmf_task) ?
+		isci_tmf->io_tag :
+		SCI_CONTROLLER_INVALID_IO_TAG;
 }
 
 /**
- * isci_io_request_build() - This function builds the io request object.
- * @isci_host: This parameter specifies the ISCI host object
- * @request: This parameter points to the isci_request object allocated in the
- *    request construct function.
- * @sci_device: This parameter is the handle for the sci core's remote device
- *    object that is the destination for this request.
+ * This method is will fill in the SCU Task Context for any type of SSP request.
+ * @sci_req:
+ * @task_context:
  *
- * SCI_SUCCESS on successfull completion, or specific failure code.
  */
-static enum sci_status isci_io_request_build(
-	struct isci_host *isci_host,
-	struct isci_request *request,
-	struct isci_remote_device *isci_device)
+static void scu_ssp_reqeust_construct_task_context(
+	struct scic_sds_request *sds_request,
+	struct scu_task_context *task_context)
 {
-	enum sci_status status = SCI_SUCCESS;
-	struct sas_task *task = isci_request_access_task(request);
-	struct scic_sds_remote_device *sci_device = &isci_device->sci;
+	dma_addr_t dma_addr;
+	struct scic_sds_controller *controller;
+	struct scic_sds_remote_device *target_device;
+	struct scic_sds_port *target_port;
+
+	controller = scic_sds_request_get_controller(sds_request);
+	target_device = scic_sds_request_get_device(sds_request);
+	target_port = scic_sds_request_get_port(sds_request);
+
+	/* Fill in the TC with the its required data */
+	task_context->abort = 0;
+	task_context->priority = 0;
+	task_context->initiator_request = 1;
+	task_context->connection_rate = target_device->connection_rate;
+	task_context->protocol_engine_index =
+		scic_sds_controller_get_protocol_engine_group(controller);
+	task_context->logical_port_index =
+		scic_sds_port_get_index(target_port);
+	task_context->protocol_type = SCU_TASK_CONTEXT_PROTOCOL_SSP;
+	task_context->valid = SCU_TASK_CONTEXT_VALID;
+	task_context->context_type = SCU_TASK_CONTEXT_TYPE;
+
+	task_context->remote_node_index =
+		scic_sds_remote_device_get_index(sds_request->target_device);
+	task_context->command_code = 0;
+
+	task_context->link_layer_control = 0;
+	task_context->do_not_dma_ssp_good_response = 1;
+	task_context->strict_ordering = 0;
+	task_context->control_frame = 0;
+	task_context->timeout_enable = 0;
+	task_context->block_guard_enable = 0;
+
+	task_context->address_modifier = 0;
+
+	/* task_context->type.ssp.tag = sci_req->io_tag; */
+	task_context->task_phase = 0x01;
+
+	if (sds_request->was_tag_assigned_by_user) {
+		/*
+		 * Build the task context now since we have already read
+		 * the data
+		 */
+		sds_request->post_context =
+			(SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
+			 (scic_sds_controller_get_protocol_engine_group(
+							controller) <<
+			  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
+			 (scic_sds_port_get_index(target_port) <<
+			  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT) |
+			 scic_sds_io_tag_get_index(sds_request->io_tag));
+	} else {
+		/*
+		 * Build the task context now since we have already read
+		 * the data
+		 *
+		 * I/O tag index is not assigned because we have to wait
+		 * until we get a TCi
+		 */
+		sds_request->post_context =
+			(SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
+			 (scic_sds_controller_get_protocol_engine_group(
+							owning_controller) <<
+			  SCU_CONTEXT_COMMAND_PROTOCOL_ENGINE_GROUP_SHIFT) |
+			 (scic_sds_port_get_index(target_port) <<
+			  SCU_CONTEXT_COMMAND_LOGICAL_PORT_SHIFT));
+	}
 
-	dev_dbg(&isci_host->pdev->dev,
-		"%s: isci_device = 0x%p; request = %p, "
-		"num_scatter = %d\n",
-		__func__,
-		isci_device,
-		request,
-		task->num_scatter);
+	/*
+	 * Copy the physical address for the command buffer to the
+	 * SCU Task Context
+	 */
+	dma_addr = scic_io_request_get_dma_addr(sds_request,
+						&sds_request->ssp.cmd);
 
-	/* map the sgl addresses, if present.
-	 * libata does the mapping for sata devices
-	 * before we get the request.
+	task_context->command_iu_upper = upper_32_bits(dma_addr);
+	task_context->command_iu_lower = lower_32_bits(dma_addr);
+
+	/*
+	 * Copy the physical address for the response buffer to the
+	 * SCU Task Context
 	 */
-	if (task->num_scatter &&
-	    !sas_protocol_ata(task->task_proto) &&
-	    !(SAS_PROTOCOL_SMP & task->task_proto)) {
+	dma_addr = scic_io_request_get_dma_addr(sds_request,
+						&sds_request->ssp.rsp);
 
-		request->num_sg_entries = dma_map_sg(
-			&isci_host->pdev->dev,
-			task->scatter,
-			task->num_scatter,
-			task->data_dir
-			);
+	task_context->response_iu_upper = upper_32_bits(dma_addr);
+	task_context->response_iu_lower = lower_32_bits(dma_addr);
+}
 
-		if (request->num_sg_entries == 0)
-			return SCI_FAILURE_INSUFFICIENT_RESOURCES;
-	}
+/**
+ * This method is will fill in the SCU Task Context for a SSP IO request.
+ * @sci_req:
+ *
+ */
+static void scu_ssp_io_request_construct_task_context(
+	struct scic_sds_request *sci_req,
+	enum dma_data_direction dir,
+	u32 len)
+{
+	struct scu_task_context *task_context;
 
-	/* build the common request object. For now,
-	 * we will let the core allocate the IO tag.
-	 */
-	status = scic_io_request_construct(&isci_host->sci, sci_device,
-					   SCI_CONTROLLER_INVALID_IO_TAG,
-					   &request->sci);
+	task_context = scic_sds_request_get_task_context(sci_req);
 
-	if (status != SCI_SUCCESS) {
-		dev_warn(&isci_host->pdev->dev,
-			 "%s: failed request construct\n",
-			 __func__);
-		return SCI_FAILURE;
-	}
+	scu_ssp_reqeust_construct_task_context(sci_req, task_context);
 
-	switch (task->task_proto) {
-	case SAS_PROTOCOL_SMP:
-		status = isci_smp_request_build(request);
-		break;
-	case SAS_PROTOCOL_SSP:
-		status = isci_request_ssp_request_construct(request);
+	task_context->ssp_command_iu_length =
+		sizeof(struct ssp_cmd_iu) / sizeof(u32);
+	task_context->type.ssp.frame_type = SSP_COMMAND;
+
+	switch (dir) {
+	case DMA_FROM_DEVICE:
+	case DMA_NONE:
+	default:
+		task_context->task_type = SCU_TASK_TYPE_IOREAD;
 		break;
-	case SAS_PROTOCOL_SATA:
-	case SAS_PROTOCOL_STP:
-	case SAS_PROTOCOL_SATA | SAS_PROTOCOL_STP:
-		status = isci_request_stp_request_construct(request);
+	case DMA_TO_DEVICE:
+		task_context->task_type = SCU_TASK_TYPE_IOWRITE;
 		break;
-	default:
-		dev_warn(&isci_host->pdev->dev,
-			 "%s: unknown protocol\n", __func__);
-		return SCI_FAILURE;
 	}
 
-	return SCI_SUCCESS;
+	task_context->transfer_length_bytes = len;
+
+	if (task_context->transfer_length_bytes > 0)
+		scic_sds_request_build_sgl(sci_req);
 }
 
+static void scic_sds_ssp_task_request_assign_buffers(struct scic_sds_request *sci_req)
+{
+	if (sci_req->was_tag_assigned_by_user == false)
+		sci_req->task_context_buffer = &sci_req->tc;
+}
 
 /**
- * isci_request_alloc_core() - This function gets the request object from the
- *    isci_host dma cache.
- * @isci_host: This parameter specifies the ISCI host object
- * @isci_request: This parameter will contain the pointer to the new
- *    isci_request object.
- * @isci_device: This parameter is the pointer to the isci remote device object
- *    that is the destination for this request.
- * @gfp_flags: This parameter specifies the os allocation flags.
+ * This method will fill in the SCU Task Context for a SSP Task request.  The
+ *    following important settings are utilized: -# priority ==
+ *    SCU_TASK_PRIORITY_HIGH.  This ensures that the task request is issued
+ *    ahead of other task destined for the same Remote Node. -# task_type ==
+ *    SCU_TASK_TYPE_IOREAD.  This simply indicates that a normal request type
+ *    (i.e. non-raw frame) is being utilized to perform task management. -#
+ *    control_frame == 1.  This ensures that the proper endianess is set so
+ *    that the bytes are transmitted in the right order for a task frame.
+ * @sci_req: This parameter specifies the task request object being
+ *    constructed.
  *
- * SCI_SUCCESS on successfull completion, or specific failure code.
  */
-static int isci_request_alloc_core(
-	struct isci_host *isci_host,
-	struct isci_request **isci_request,
-	struct isci_remote_device *isci_device,
-	gfp_t gfp_flags)
+static void scu_ssp_task_request_construct_task_context(
+	struct scic_sds_request *sci_req)
 {
-	int ret = 0;
-	dma_addr_t handle;
-	struct isci_request *request;
-
-
-	/* get pointer to dma memory. This actually points
-	 * to both the isci_remote_device object and the
-	 * sci object. The isci object is at the beginning
-	 * of the memory allocated here.
-	 */
-	request = dma_pool_alloc(isci_host->dma_pool, gfp_flags, &handle);
-	if (!request) {
-		dev_warn(&isci_host->pdev->dev,
-			 "%s: dma_pool_alloc returned NULL\n", __func__);
-		return -ENOMEM;
-	}
-
-	/* initialize the request object.	*/
-	spin_lock_init(&request->state_lock);
-	request->request_daddr = handle;
-	request->isci_host = isci_host;
-	request->isci_device = isci_device;
-	request->io_request_completion = NULL;
-	request->terminated = false;
-
-	request->num_sg_entries = 0;
-
-	request->complete_in_target = false;
+	struct scu_task_context *task_context;
 
-	INIT_LIST_HEAD(&request->completed_node);
-	INIT_LIST_HEAD(&request->dev_node);
+	task_context = scic_sds_request_get_task_context(sci_req);
 
-	*isci_request = request;
-	isci_request_change_state(request, allocated);
+	scu_ssp_reqeust_construct_task_context(sci_req, task_context);
 
-	return ret;
+	task_context->control_frame                = 1;
+	task_context->priority                     = SCU_TASK_PRIORITY_HIGH;
+	task_context->task_type                    = SCU_TASK_TYPE_RAW_FRAME;
+	task_context->transfer_length_bytes        = 0;
+	task_context->type.ssp.frame_type          = SSP_TASK;
+	task_context->ssp_command_iu_length =
+		sizeof(struct ssp_task_iu) / sizeof(u32);
 }
 
-static int isci_request_alloc_io(
-	struct isci_host *isci_host,
-	struct sas_task *task,
-	struct isci_request **isci_request,
-	struct isci_remote_device *isci_device,
-	gfp_t gfp_flags)
-{
-	int retval = isci_request_alloc_core(isci_host, isci_request,
-					     isci_device, gfp_flags);
 
-	if (!retval) {
-		(*isci_request)->ttype_ptr.io_task_ptr = task;
-		(*isci_request)->ttype                 = io_task;
+/**
+ * This method constructs the SSP Command IU data for this ssp passthrough
+ *    comand request object.
+ * @sci_req: This parameter specifies the request object for which the SSP
+ *    command information unit is being built.
+ *
+ * enum sci_status, returns invalid parameter is cdb > 16
+ */
 
-		task->lldd_task = *isci_request;
-	}
-	return retval;
-}
 
 /**
- * isci_request_alloc_tmf() - This function gets the request object from the
- *    isci_host dma cache and initializes the relevant fields as a sas_task.
- * @isci_host: This parameter specifies the ISCI host object
- * @sas_task: This parameter is the task struct from the upper layer driver.
- * @isci_request: This parameter will contain the pointer to the new
- *    isci_request object.
- * @isci_device: This parameter is the pointer to the isci remote device object
- *    that is the destination for this request.
- * @gfp_flags: This parameter specifies the os allocation flags.
+ * This method constructs the SATA request object.
+ * @sci_req:
+ * @sat_protocol:
+ * @transfer_length:
+ * @data_direction:
+ * @copy_rx_frame:
  *
- * SCI_SUCCESS on successfull completion, or specific failure code.
+ * enum sci_status
  */
-int isci_request_alloc_tmf(
-	struct isci_host *isci_host,
-	struct isci_tmf *isci_tmf,
-	struct isci_request **isci_request,
-	struct isci_remote_device *isci_device,
-	gfp_t gfp_flags)
+static enum sci_status
+scic_io_request_construct_sata(struct scic_sds_request *sci_req,
+			       u32 len,
+			       enum dma_data_direction dir,
+			       bool copy)
 {
-	int retval = isci_request_alloc_core(isci_host, isci_request,
-					     isci_device, gfp_flags);
+	enum sci_status status = SCI_SUCCESS;
+	struct isci_request *ireq = sci_req_to_ireq(sci_req);
+	struct sas_task *task = isci_request_access_task(ireq);
 
-	if (!retval) {
+	/* check for management protocols */
+	if (ireq->ttype == tmf_task) {
+		struct isci_tmf *tmf = isci_request_access_tmf(ireq);
 
-		(*isci_request)->ttype_ptr.tmf_task_ptr = isci_tmf;
-		(*isci_request)->ttype = tmf_task;
+		if (tmf->tmf_code == isci_tmf_sata_srst_high ||
+		    tmf->tmf_code == isci_tmf_sata_srst_low)
+			return scic_sds_stp_soft_reset_request_construct(sci_req);
+		else {
+			dev_err(scic_to_dev(sci_req->owning_controller),
+				"%s: Request 0x%p received un-handled SAT "
+				"management protocol 0x%x.\n",
+				__func__, sci_req, tmf->tmf_code);
+
+			return SCI_FAILURE;
+		}
 	}
-	return retval;
-}
 
-/**
- * isci_request_execute() - This function allocates the isci_request object,
- *    all fills in some common fields.
- * @isci_host: This parameter specifies the ISCI host object
- * @sas_task: This parameter is the task struct from the upper layer driver.
- * @isci_request: This parameter will contain the pointer to the new
- *    isci_request object.
- * @gfp_flags: This parameter specifies the os allocation flags.
- *
- * SCI_SUCCESS on successfull completion, or specific failure code.
- */
-int isci_request_execute(
-	struct isci_host *isci_host,
-	struct sas_task *task,
-	struct isci_request **isci_request,
-	gfp_t gfp_flags)
+	if (!sas_protocol_ata(task->task_proto)) {
+		dev_err(scic_to_dev(sci_req->owning_controller),
+			"%s: Non-ATA protocol in SATA path: 0x%x\n",
+			__func__,
+			task->task_proto);
+		return SCI_FAILURE;
+
+	}
+
+	/* non data */
+	if (task->data_dir == DMA_NONE)
+		return scic_sds_stp_non_data_request_construct(sci_req);
+
+	/* NCQ */
+	if (task->ata_task.use_ncq)
+		return scic_sds_stp_ncq_request_construct(sci_req, len, dir);
+
+	/* DMA */
+	if (task->ata_task.dma_xfer)
+		return scic_sds_stp_udma_request_construct(sci_req, len, dir);
+	else /* PIO */
+		return scic_sds_stp_pio_request_construct(sci_req, copy);
+
+	return status;
+}
+
+static enum sci_status scic_io_request_construct_basic_ssp(struct scic_sds_request *sci_req)
 {
-	int ret = 0;
-	struct scic_sds_remote_device *sci_device;
-	enum sci_status status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;
-	struct isci_remote_device *isci_device;
-	struct isci_request *request;
-	unsigned long flags;
+	struct isci_request *ireq = sci_req_to_ireq(sci_req);
+	struct sas_task *task = isci_request_access_task(ireq);
 
-	isci_device = task->dev->lldd_dev;
-	sci_device = &isci_device->sci;
+	sci_req->protocol = SCIC_SSP_PROTOCOL;
 
-	/* do common allocation and init of request object. */
-	ret = isci_request_alloc_io(
-		isci_host,
-		task,
-		&request,
-		isci_device,
-		gfp_flags
-		);
+	scu_ssp_io_request_construct_task_context(sci_req,
+						  task->data_dir,
+						  task->total_xfer_len);
 
-	if (ret)
-		goto out;
+	scic_sds_io_request_build_ssp_command_iu(sci_req);
 
-	status = isci_io_request_build(isci_host, request, isci_device);
-	if (status != SCI_SUCCESS) {
-		dev_warn(&isci_host->pdev->dev,
-			 "%s: request_construct failed - status = 0x%x\n",
-			 __func__,
-			 status);
-		goto out;
-	}
+	sci_base_state_machine_change_state(
+			&sci_req->state_machine,
+			SCI_BASE_REQUEST_STATE_CONSTRUCTED);
 
-	spin_lock_irqsave(&isci_host->scic_lock, flags);
+	return SCI_SUCCESS;
+}
 
-	/* send the request, let the core assign the IO TAG.	*/
-	status = scic_controller_start_io(&isci_host->sci, sci_device,
-					  &request->sci,
-					  SCI_CONTROLLER_INVALID_IO_TAG);
-	if (status != SCI_SUCCESS &&
-	    status != SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
-		dev_warn(&isci_host->pdev->dev,
-			 "%s: failed request start (0x%x)\n",
-			 __func__, status);
-		spin_unlock_irqrestore(&isci_host->scic_lock, flags);
-		goto out;
-	}
+enum sci_status scic_task_request_construct_ssp(
+	struct scic_sds_request *sci_req)
+{
+	/* Construct the SSP Task SCU Task Context */
+	scu_ssp_task_request_construct_task_context(sci_req);
 
-	/* Either I/O started OK, or the core has signaled that
-	 * the device needs a target reset.
-	 *
-	 * In either case, hold onto the I/O for later.
-	 *
-	 * Update it's status and add it to the list in the
-	 * remote device object.
-	 */
-	isci_request_change_state(request, started);
-	list_add(&request->dev_node, &isci_device->reqs_in_process);
+	/* Fill in the SSP Task IU */
+	scic_sds_task_request_build_ssp_task_iu(sci_req);
 
-	if (status == SCI_SUCCESS) {
-		/* Save the tag for possible task mgmt later. */
-		request->io_tag = scic_io_request_get_io_tag(&request->sci);
-	} else {
-		/* The request did not really start in the
-		 * hardware, so clear the request handle
-		 * here so no terminations will be done.
-		 */
-		request->terminated = true;
-	}
-	spin_unlock_irqrestore(&isci_host->scic_lock, flags);
+	sci_base_state_machine_change_state(&sci_req->state_machine,
+		SCI_BASE_REQUEST_STATE_CONSTRUCTED);
 
-	if (status ==
-	    SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
-		/* Signal libsas that we need the SCSI error
-		* handler thread to work on this I/O and that
-		* we want a device reset.
-		*/
-		spin_lock_irqsave(&task->task_state_lock, flags);
-		task->task_state_flags |= SAS_TASK_NEED_DEV_RESET;
-		spin_unlock_irqrestore(&task->task_state_lock, flags);
+	return SCI_SUCCESS;
+}
 
-		/* Cause this task to be scheduled in the SCSI error
-		* handler thread.
-		*/
-		isci_execpath_callback(isci_host, task,
-				       sas_task_abort);
 
-		/* Change the status, since we are holding
-		* the I/O until it is managed by the SCSI
-		* error handler.
-		*/
-		status = SCI_SUCCESS;
-	}
+static enum sci_status scic_io_request_construct_basic_sata(struct scic_sds_request *sci_req)
+{
+	enum sci_status status;
+	struct scic_sds_stp_request *stp_req;
+	bool copy = false;
+	struct isci_request *isci_request = sci_req_to_ireq(sci_req);
+	struct sas_task *task = isci_request_access_task(isci_request);
 
- out:
-	if (status != SCI_SUCCESS) {
-		/* release dma memory on failure. */
-		isci_request_free(isci_host, request);
-		request = NULL;
-		ret = SCI_FAILURE;
-	}
+	stp_req = &sci_req->stp.req;
+	sci_req->protocol = SCIC_STP_PROTOCOL;
 
-	*isci_request = request;
-	return ret;
+	copy = (task->data_dir == DMA_NONE) ? false : true;
+
+	status = scic_io_request_construct_sata(sci_req,
+						task->total_xfer_len,
+						task->data_dir,
+						copy);
+
+	if (status == SCI_SUCCESS)
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+			SCI_BASE_REQUEST_STATE_CONSTRUCTED);
+
+	return status;
 }
 
 
+enum sci_status scic_task_request_construct_sata(struct scic_sds_request *sci_req)
+{
+	enum sci_status status = SCI_SUCCESS;
+	struct isci_request *ireq = sci_req_to_ireq(sci_req);
+
+	/* check for management protocols */
+	if (ireq->ttype == tmf_task) {
+		struct isci_tmf *tmf = isci_request_access_tmf(ireq);
+
+		if (tmf->tmf_code == isci_tmf_sata_srst_high ||
+		    tmf->tmf_code == isci_tmf_sata_srst_low) {
+			status = scic_sds_stp_soft_reset_request_construct(sci_req);
+		} else {
+			dev_err(scic_to_dev(sci_req->owning_controller),
+				"%s: Request 0x%p received un-handled SAT "
+				"Protocol 0x%x.\n",
+				__func__, sci_req, tmf->tmf_code);
+
+			return SCI_FAILURE;
+		}
+	}
+
+	if (status == SCI_SUCCESS)
+		sci_base_state_machine_change_state(
+				&sci_req->state_machine,
+				SCI_BASE_REQUEST_STATE_CONSTRUCTED);
+
+	return status;
+}
+
 /**
- * isci_request_process_response_iu() - This function sets the status and
- *    response iu, in the task struct, from the request object for the upper
- *    layer driver.
- * @sas_task: This parameter is the task struct from the upper layer driver.
- * @resp_iu: This parameter points to the response iu of the completed request.
- * @dev: This parameter specifies the linux device struct.
- *
- * none.
+ * sci_req_tx_bytes - bytes transferred when reply underruns request
+ * @sci_req: request that was terminated early
  */
-static void isci_request_process_response_iu(
-	struct sas_task *task,
-	struct ssp_response_iu *resp_iu,
-	struct device *dev)
+#define SCU_TASK_CONTEXT_SRAM 0x200000
+static u32 sci_req_tx_bytes(struct scic_sds_request *sci_req)
 {
-	dev_dbg(dev,
-		"%s: resp_iu = %p "
-		"resp_iu->status = 0x%x,\nresp_iu->datapres = %d "
-		"resp_iu->response_data_len = %x, "
-		"resp_iu->sense_data_len = %x\nrepsonse data: ",
+	struct scic_sds_controller *scic = sci_req->owning_controller;
+	u32 ret_val = 0;
+
+	if (readl(&scic->smu_registers->address_modifier) == 0) {
+		void __iomem *scu_reg_base = scic->scu_registers;
+
+		/* get the bytes of data from the Address == BAR1 + 20002Ch + (256*TCi) where
+		 *   BAR1 is the scu_registers
+		 *   0x20002C = 0x200000 + 0x2c
+		 *            = start of task context SRAM + offset of (type.ssp.data_offset)
+		 *   TCi is the io_tag of struct scic_sds_request
+		 */
+		ret_val = readl(scu_reg_base +
+				(SCU_TASK_CONTEXT_SRAM + offsetof(struct scu_task_context, type.ssp.data_offset)) +
+				((sizeof(struct scu_task_context)) * scic_sds_io_tag_get_index(sci_req->io_tag)));
+	}
+
+	return ret_val;
+}
+
+enum sci_status
+scic_sds_request_start(struct scic_sds_request *request)
+{
+	if (request->device_sequence !=
+	    scic_sds_remote_device_get_sequence(request->target_device))
+		return SCI_FAILURE;
+
+	if (request->state_handlers->start_handler)
+		return request->state_handlers->start_handler(request);
+
+	dev_warn(scic_to_dev(request->owning_controller),
+		 "%s: SCIC IO Request requested to start while in wrong "
+		 "state %d\n",
+		 __func__,
+		 sci_base_state_machine_get_state(&request->state_machine));
+
+	return SCI_FAILURE_INVALID_STATE;
+}
+
+enum sci_status
+scic_sds_io_request_terminate(struct scic_sds_request *request)
+{
+	if (request->state_handlers->abort_handler)
+		return request->state_handlers->abort_handler(request);
+
+	dev_warn(scic_to_dev(request->owning_controller),
+		"%s: SCIC IO Request requested to abort while in wrong "
+		"state %d\n",
 		__func__,
-		resp_iu,
-		resp_iu->status,
-		resp_iu->datapres,
-		resp_iu->response_data_len,
-		resp_iu->sense_data_len);
+		sci_base_state_machine_get_state(&request->state_machine));
 
-	task->task_status.stat = resp_iu->status;
+	return SCI_FAILURE_INVALID_STATE;
+}
 
-	/* libsas updates the task status fields based on the response iu. */
-	sas_ssp_task_response(dev, task, resp_iu);
+enum sci_status scic_sds_io_request_event_handler(
+	struct scic_sds_request *request,
+	u32 event_code)
+{
+	if (request->state_handlers->event_handler)
+		return request->state_handlers->event_handler(request, event_code);
+
+	dev_warn(scic_to_dev(request->owning_controller),
+		 "%s: SCIC IO Request given event code notification %x while "
+		 "in wrong state %d\n",
+		 __func__,
+		 event_code,
+		 sci_base_state_machine_get_state(&request->state_machine));
+
+	return SCI_FAILURE_INVALID_STATE;
 }
 
 /**
- * isci_request_set_open_reject_status() - This function prepares the I/O
- *    completion for OPEN_REJECT conditions.
- * @request: This parameter is the completed isci_request object.
- * @response_ptr: This parameter specifies the service response for the I/O.
- * @status_ptr: This parameter specifies the exec status for the I/O.
- * @complete_to_host_ptr: This parameter specifies the action to be taken by
- *    the LLDD with respect to completing this request or forcing an abort
- *    condition on the I/O.
- * @open_rej_reason: This parameter specifies the encoded reason for the
- *    abandon-class reject.
  *
- * none.
+ * @sci_req: The SCIC_SDS_IO_REQUEST_T object for which the start
+ *    operation is to be executed.
+ * @frame_index: The frame index returned by the hardware for the reqeust
+ *    object.
+ *
+ * This method invokes the core state frame handler for the
+ * SCIC_SDS_IO_REQUEST_T object. enum sci_status
  */
-static void isci_request_set_open_reject_status(
-	struct isci_request *request,
-	struct sas_task *task,
-	enum service_response *response_ptr,
-	enum exec_status *status_ptr,
-	enum isci_completion_selection *complete_to_host_ptr,
-	enum sas_open_rej_reason open_rej_reason)
+enum sci_status scic_sds_io_request_frame_handler(
+	struct scic_sds_request *request,
+	u32 frame_index)
 {
-	/* Task in the target is done. */
-	request->complete_in_target       = true;
-	*response_ptr                     = SAS_TASK_UNDELIVERED;
-	*status_ptr                       = SAS_OPEN_REJECT;
-	*complete_to_host_ptr             = isci_perform_normal_io_completion;
-	task->task_status.open_rej_reason = open_rej_reason;
+	if (request->state_handlers->frame_handler)
+		return request->state_handlers->frame_handler(request, frame_index);
+
+	dev_warn(scic_to_dev(request->owning_controller),
+		 "%s: SCIC IO Request given unexpected frame %x while in "
+		 "state %d\n",
+		 __func__,
+		 frame_index,
+		 sci_base_state_machine_get_state(&request->state_machine));
+
+	scic_sds_controller_release_frame(request->owning_controller, frame_index);
+	return SCI_FAILURE_INVALID_STATE;
 }
 
-/**
- * isci_request_handle_controller_specific_errors() - This function decodes
- *    controller-specific I/O completion error conditions.
- * @request: This parameter is the completed isci_request object.
- * @response_ptr: This parameter specifies the service response for the I/O.
- * @status_ptr: This parameter specifies the exec status for the I/O.
- * @complete_to_host_ptr: This parameter specifies the action to be taken by
- *    the LLDD with respect to completing this request or forcing an abort
- *    condition on the I/O.
- *
- * none.
+/*
+ * This function copies response data for requests returning response data
+ *    instead of sense data.
+ * @sci_req: This parameter specifies the request object for which to copy
+ *    the response data.
  */
-static void isci_request_handle_controller_specific_errors(
-	struct isci_remote_device *isci_device,
-	struct isci_request *request,
-	struct sas_task *task,
-	enum service_response *response_ptr,
-	enum exec_status *status_ptr,
-	enum isci_completion_selection *complete_to_host_ptr)
+void scic_sds_io_request_copy_response(struct scic_sds_request *sci_req)
 {
-	unsigned int cstatus;
+	void *resp_buf;
+	u32 len;
+	struct ssp_response_iu *ssp_response;
+	struct isci_request *ireq = sci_req_to_ireq(sci_req);
+	struct isci_tmf *isci_tmf = isci_request_access_tmf(ireq);
 
-	cstatus = scic_request_get_controller_status(&request->sci);
+	ssp_response = &sci_req->ssp.rsp;
 
-	dev_dbg(&request->isci_host->pdev->dev,
-		"%s: %p SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR "
-		"- controller status = 0x%x\n",
-		__func__, request, cstatus);
+	resp_buf = &isci_tmf->resp.resp_iu;
 
-	/* Decode the controller-specific errors; most
-	 * important is to recognize those conditions in which
-	 * the target may still have a task outstanding that
-	 * must be aborted.
-	 *
-	 * Note that there are SCU completion codes being
-	 * named in the decode below for which SCIC has already
-	 * done work to handle them in a way other than as
-	 * a controller-specific completion code; these are left
-	 * in the decode below for completeness sake.
-	 */
-	switch (cstatus) {
-	case SCU_TASK_DONE_DMASETUP_DIRERR:
-	/* Also SCU_TASK_DONE_SMP_FRM_TYPE_ERR: */
-	case SCU_TASK_DONE_XFERCNT_ERR:
-		/* Also SCU_TASK_DONE_SMP_UFI_ERR: */
-		if (task->task_proto == SAS_PROTOCOL_SMP) {
-			/* SCU_TASK_DONE_SMP_UFI_ERR == Task Done. */
-			*response_ptr = SAS_TASK_COMPLETE;
+	len = min_t(u32,
+		    SSP_RESP_IU_MAX_SIZE,
+		    be32_to_cpu(ssp_response->response_data_len));
 
-			/* See if the device has been/is being stopped. Note
-			 * that we ignore the quiesce state, since we are
-			 * concerned about the actual device state.
-			 */
-			if ((isci_device->status == isci_stopping) ||
-			    (isci_device->status == isci_stopped))
-				*status_ptr = SAS_DEVICE_UNKNOWN;
-			else
-				*status_ptr = SAS_ABORTED_TASK;
+	memcpy(resp_buf, ssp_response->resp_data, len);
+}
 
-			request->complete_in_target = true;
+/*
+ * This method implements the action taken when a constructed
+ * SCIC_SDS_IO_REQUEST_T object receives a scic_sds_request_start() request.
+ * This method will, if necessary, allocate a TCi for the io request object and
+ * then will, if necessary, copy the constructed TC data into the actual TC
+ * buffer.  If everything is successful the post context field is updated with
+ * the TCi so the controller can post the request to the hardware. enum sci_status
+ * SCI_SUCCESS SCI_FAILURE_INSUFFICIENT_RESOURCES
+ */
+static enum sci_status scic_sds_request_constructed_state_start_handler(
+	struct scic_sds_request *request)
+{
+	struct scu_task_context *task_context;
 
-			*complete_to_host_ptr =
-				isci_perform_normal_io_completion;
-		} else {
-			/* Task in the target is not done. */
-			*response_ptr = SAS_TASK_UNDELIVERED;
+	if (request->io_tag == SCI_CONTROLLER_INVALID_IO_TAG) {
+		request->io_tag =
+			scic_controller_allocate_io_tag(request->owning_controller);
+	}
 
-			if ((isci_device->status == isci_stopping) ||
-			    (isci_device->status == isci_stopped))
-				*status_ptr = SAS_DEVICE_UNKNOWN;
-			else
-				*status_ptr = SAM_STAT_TASK_ABORTED;
+	/* Record the IO Tag in the request */
+	if (request->io_tag != SCI_CONTROLLER_INVALID_IO_TAG) {
+		task_context = request->task_context_buffer;
 
-			request->complete_in_target = false;
+		task_context->task_index = scic_sds_io_tag_get_index(request->io_tag);
 
-			*complete_to_host_ptr =
-				isci_perform_error_io_completion;
-		}
+		switch (task_context->protocol_type) {
+		case SCU_TASK_CONTEXT_PROTOCOL_SMP:
+		case SCU_TASK_CONTEXT_PROTOCOL_SSP:
+			/* SSP/SMP Frame */
+			task_context->type.ssp.tag = request->io_tag;
+			task_context->type.ssp.target_port_transfer_tag = 0xFFFF;
+			break;
 
-		break;
+		case SCU_TASK_CONTEXT_PROTOCOL_STP:
+			/*
+			 * STP/SATA Frame
+			 * task_context->type.stp.ncq_tag = request->ncq_tag; */
+			break;
 
-	case SCU_TASK_DONE_CRC_ERR:
-	case SCU_TASK_DONE_NAK_CMD_ERR:
-	case SCU_TASK_DONE_EXCESS_DATA:
-	case SCU_TASK_DONE_UNEXP_FIS:
-	/* Also SCU_TASK_DONE_UNEXP_RESP: */
-	case SCU_TASK_DONE_VIIT_ENTRY_NV:       /* TODO - conditions? */
-	case SCU_TASK_DONE_IIT_ENTRY_NV:        /* TODO - conditions? */
-	case SCU_TASK_DONE_RNCNV_OUTBOUND:      /* TODO - conditions? */
-		/* These are conditions in which the target
-		 * has completed the task, so that no cleanup
-		 * is necessary.
-		 */
-		*response_ptr = SAS_TASK_COMPLETE;
+		case SCU_TASK_CONTEXT_PROTOCOL_NONE:
+			/* / @todo When do we set no protocol type? */
+			break;
 
-		/* See if the device has been/is being stopped. Note
-		 * that we ignore the quiesce state, since we are
-		 * concerned about the actual device state.
-		 */
-		if ((isci_device->status == isci_stopping) ||
-		    (isci_device->status == isci_stopped))
-			*status_ptr = SAS_DEVICE_UNKNOWN;
-		else
-			*status_ptr = SAS_ABORTED_TASK;
+		default:
+			/* This should never happen since we build the IO requests */
+			break;
+		}
 
-		request->complete_in_target = true;
+		/*
+		 * Check to see if we need to copy the task context buffer
+		 * or have been building into the task context buffer */
+		if (request->was_tag_assigned_by_user == false) {
+			scic_sds_controller_copy_task_context(
+				request->owning_controller, request);
+		}
 
-		*complete_to_host_ptr = isci_perform_normal_io_completion;
-		break;
+		/* Add to the post_context the io tag value */
+		request->post_context |= scic_sds_io_tag_get_index(request->io_tag);
 
+		/* Everything is good go ahead and change state */
+		sci_base_state_machine_change_state(&request->state_machine,
+			SCI_BASE_REQUEST_STATE_STARTED);
 
-	/* Note that the only open reject completion codes seen here will be
-	 * abandon-class codes; all others are automatically retried in the SCU.
-	 */
-	case SCU_TASK_OPEN_REJECT_WRONG_DESTINATION:
+		return SCI_SUCCESS;
+	}
 
-		isci_request_set_open_reject_status(
-			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_WRONG_DEST);
-		break;
+	return SCI_FAILURE_INSUFFICIENT_RESOURCES;
+}
 
-	case SCU_TASK_OPEN_REJECT_ZONE_VIOLATION:
+/*
+ * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
+ * object receives a scic_sds_request_terminate() request. Since the request
+ * has not yet been posted to the hardware the request transitions to the
+ * completed state. enum sci_status SCI_SUCCESS
+ */
+static enum sci_status scic_sds_request_constructed_state_abort_handler(
+	struct scic_sds_request *request)
+{
+	/*
+	 * This request has been terminated by the user make sure that the correct
+	 * status code is returned */
+	scic_sds_request_set_status(request,
+		SCU_TASK_DONE_TASK_ABORT,
+		SCI_FAILURE_IO_TERMINATED);
+
+	sci_base_state_machine_change_state(&request->state_machine,
+		SCI_BASE_REQUEST_STATE_COMPLETED);
+	return SCI_SUCCESS;
+}
 
-		/* Note - the return of AB0 will change when
-		 * libsas implements detection of zone violations.
-		 */
-		isci_request_set_open_reject_status(
-			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_RESV_AB0);
-		break;
+/*
+ * *****************************************************************************
+ * *  STARTED STATE HANDLERS
+ * ***************************************************************************** */
 
-	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_1:
+/*
+ * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
+ * object receives a scic_sds_request_terminate() request. Since the request
+ * has been posted to the hardware the io request state is changed to the
+ * aborting state. enum sci_status SCI_SUCCESS
+ */
+enum sci_status scic_sds_request_started_state_abort_handler(
+	struct scic_sds_request *request)
+{
+	if (request->has_started_substate_machine)
+		sci_base_state_machine_stop(&request->started_substate_machine);
 
-		isci_request_set_open_reject_status(
-			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_RESV_AB1);
-		break;
+	sci_base_state_machine_change_state(&request->state_machine,
+		SCI_BASE_REQUEST_STATE_ABORTING);
+	return SCI_SUCCESS;
+}
 
-	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_2:
+/*
+ * scic_sds_request_started_state_tc_completion_handler() - This method process
+ *    TC (task context) completions for normal IO request (i.e. Task/Abort
+ *    Completions of type 0).  This method will update the
+ *    SCIC_SDS_IO_REQUEST_T::status field.
+ * @sci_req: This parameter specifies the request for which a completion
+ *    occurred.
+ * @completion_code: This parameter specifies the completion code received from
+ *    the SCU.
+ *
+ */
+static enum sci_status
+scic_sds_request_started_state_tc_completion_handler(struct scic_sds_request *sci_req,
+						     u32 completion_code)
+{
+	u8 datapres;
+	struct ssp_response_iu *resp_iu;
 
-		isci_request_set_open_reject_status(
-			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_RESV_AB2);
+	/*
+	 * TODO: Any SDMA return code of other than 0 is bad
+	 *       decode 0x003C0000 to determine SDMA status
+	 */
+	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
+		scic_sds_request_set_status(sci_req,
+					    SCU_TASK_DONE_GOOD,
+					    SCI_SUCCESS);
 		break;
 
-	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_3:
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_EARLY_RESP):
+	{
+		/*
+		 * There are times when the SCU hardware will return an early
+		 * response because the io request specified more data than is
+		 * returned by the target device (mode pages, inquiry data,
+		 * etc.).  We must check the response stats to see if this is
+		 * truly a failed request or a good request that just got
+		 * completed early.
+		 */
+		struct ssp_response_iu *resp = &sci_req->ssp.rsp;
+		ssize_t word_cnt = SSP_RESP_IU_MAX_SIZE / sizeof(u32);
+
+		sci_swab32_cpy(&sci_req->ssp.rsp,
+			       &sci_req->ssp.rsp,
+			       word_cnt);
+
+		if (resp->status == 0) {
+			scic_sds_request_set_status(
+				sci_req,
+				SCU_TASK_DONE_GOOD,
+				SCI_SUCCESS_IO_DONE_EARLY);
+		} else {
+			scic_sds_request_set_status(
+				sci_req,
+				SCU_TASK_DONE_CHECK_RESPONSE,
+				SCI_FAILURE_IO_RESPONSE_VALID);
+		}
+	}
+	break;
 
-		isci_request_set_open_reject_status(
-			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_RESV_AB3);
-		break;
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_CHECK_RESPONSE):
+	{
+		ssize_t word_cnt = SSP_RESP_IU_MAX_SIZE / sizeof(u32);
 
-	case SCU_TASK_OPEN_REJECT_BAD_DESTINATION:
+		sci_swab32_cpy(&sci_req->ssp.rsp,
+			       &sci_req->ssp.rsp,
+			       word_cnt);
 
-		isci_request_set_open_reject_status(
-			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_BAD_DEST);
+		scic_sds_request_set_status(sci_req,
+					    SCU_TASK_DONE_CHECK_RESPONSE,
+					    SCI_FAILURE_IO_RESPONSE_VALID);
 		break;
+	}
 
-	case SCU_TASK_OPEN_REJECT_STP_RESOURCES_BUSY:
-
-		isci_request_set_open_reject_status(
-			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_STP_NORES);
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_RESP_LEN_ERR):
+		/*
+		 * / @todo With TASK_DONE_RESP_LEN_ERR is the response frame
+		 * guaranteed to be received before this completion status is
+		 * posted?
+		 */
+		resp_iu = &sci_req->ssp.rsp;
+		datapres = resp_iu->datapres;
+
+		if ((datapres == 0x01) || (datapres == 0x02)) {
+			scic_sds_request_set_status(
+				sci_req,
+				SCU_TASK_DONE_CHECK_RESPONSE,
+				SCI_FAILURE_IO_RESPONSE_VALID);
+		} else
+			scic_sds_request_set_status(
+				sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS);
 		break;
 
-	case SCU_TASK_OPEN_REJECT_PROTOCOL_NOT_SUPPORTED:
-
-		isci_request_set_open_reject_status(
-			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_EPROTO);
+	/* only stp device gets suspended. */
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_ACK_NAK_TO):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_LL_PERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_NAK_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_DATA_LEN_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_LL_ABORT_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_XR_WD_LEN):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_MAX_PLD_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_UNEXP_RESP):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_UNEXP_SDBFIS):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_REG_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SDB_ERR):
+		if (sci_req->protocol == SCIC_STP_PROTOCOL) {
+			scic_sds_request_set_status(
+				sci_req,
+				SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
+				SCU_COMPLETION_TL_STATUS_SHIFT,
+				SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED);
+		} else {
+			scic_sds_request_set_status(
+				sci_req,
+				SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
+				SCU_COMPLETION_TL_STATUS_SHIFT,
+				SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
+		}
 		break;
 
-	case SCU_TASK_OPEN_REJECT_CONNECTION_RATE_NOT_SUPPORTED:
-
-		isci_request_set_open_reject_status(
-			request, task, response_ptr, status_ptr,
-			complete_to_host_ptr, SAS_OREJ_CONN_RATE);
+	/* both stp/ssp device gets suspended */
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_LF_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_WRONG_DESTINATION):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_1):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_2):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_3):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_BAD_DESTINATION):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_ZONE_VIOLATION):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_STP_RESOURCES_BUSY):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_PROTOCOL_NOT_SUPPORTED):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_CONNECTION_RATE_NOT_SUPPORTED):
+		scic_sds_request_set_status(
+			sci_req,
+			SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
+			SCU_COMPLETION_TL_STATUS_SHIFT,
+			SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED);
 		break;
 
-	case SCU_TASK_DONE_LL_R_ERR:
-	/* Also SCU_TASK_DONE_ACK_NAK_TO: */
-	case SCU_TASK_DONE_LL_PERR:
-	case SCU_TASK_DONE_LL_SY_TERM:
-	/* Also SCU_TASK_DONE_NAK_ERR:*/
-	case SCU_TASK_DONE_LL_LF_TERM:
-	/* Also SCU_TASK_DONE_DATA_LEN_ERR: */
-	case SCU_TASK_DONE_LL_ABORT_ERR:
-	case SCU_TASK_DONE_SEQ_INV_TYPE:
-	/* Also SCU_TASK_DONE_UNEXP_XR: */
-	case SCU_TASK_DONE_XR_IU_LEN_ERR:
-	case SCU_TASK_DONE_INV_FIS_LEN:
-	/* Also SCU_TASK_DONE_XR_WD_LEN: */
-	case SCU_TASK_DONE_SDMA_ERR:
-	case SCU_TASK_DONE_OFFSET_ERR:
-	case SCU_TASK_DONE_MAX_PLD_ERR:
-	case SCU_TASK_DONE_LF_ERR:
-	case SCU_TASK_DONE_SMP_RESP_TO_ERR:  /* Escalate to dev reset? */
-	case SCU_TASK_DONE_SMP_LL_RX_ERR:
-	case SCU_TASK_DONE_UNEXP_DATA:
-	case SCU_TASK_DONE_UNEXP_SDBFIS:
-	case SCU_TASK_DONE_REG_ERR:
-	case SCU_TASK_DONE_SDB_ERR:
-	case SCU_TASK_DONE_TASK_ABORT:
+	/* neither ssp nor stp gets suspended. */
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_NAK_CMD_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_UNEXP_XR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_XR_IU_LEN_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SDMA_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_OFFSET_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_EXCESS_DATA):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_RESP_TO_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_UFI_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_FRM_TYPE_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_LL_RX_ERR):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_UNEXP_DATA):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_OPEN_FAIL):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_VIIT_ENTRY_NV):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_IIT_ENTRY_NV):
+	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_RNCNV_OUTBOUND):
 	default:
-		/* Task in the target is not done. */
-		*response_ptr = SAS_TASK_UNDELIVERED;
-		*status_ptr = SAM_STAT_TASK_ABORTED;
-		request->complete_in_target = false;
-
-		*complete_to_host_ptr = isci_perform_error_io_completion;
+		scic_sds_request_set_status(
+			sci_req,
+			SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
+			SCU_COMPLETION_TL_STATUS_SHIFT,
+			SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
 		break;
 	}
+
+	/*
+	 * TODO: This is probably wrong for ACK/NAK timeout conditions
+	 */
+
+	/* In all cases we will treat this as the completion of the IO req. */
+	sci_base_state_machine_change_state(
+			&sci_req->state_machine,
+			SCI_BASE_REQUEST_STATE_COMPLETED);
+	return SCI_SUCCESS;
 }
 
-/**
- * isci_task_save_for_upper_layer_completion() - This function saves the
- *    request for later completion to the upper layer driver.
- * @host: This parameter is a pointer to the host on which the the request
- *    should be queued (either as an error or success).
- * @request: This parameter is the completed request.
- * @response: This parameter is the response code for the completed task.
- * @status: This parameter is the status code for the completed task.
- *
- * none.
- */
-static void isci_task_save_for_upper_layer_completion(
-	struct isci_host *host,
-	struct isci_request *request,
-	enum service_response response,
-	enum exec_status status,
-	enum isci_completion_selection task_notification_selection)
+enum sci_status
+scic_sds_io_request_tc_completion(struct scic_sds_request *request, u32 completion_code)
 {
-	struct sas_task *task = isci_request_access_task(request);
-
-	task_notification_selection
-		= isci_task_set_completion_status(task, response, status,
-						  task_notification_selection);
+	if (request->state_machine.current_state_id == SCI_BASE_REQUEST_STATE_STARTED &&
+	    request->has_started_substate_machine == false)
+		return scic_sds_request_started_state_tc_completion_handler(request, completion_code);
+	else if (request->state_handlers->tc_completion_handler)
+		return request->state_handlers->tc_completion_handler(request, completion_code);
+
+	dev_warn(scic_to_dev(request->owning_controller),
+		"%s: SCIC IO Request given task completion notification %x "
+		"while in wrong state %d\n",
+		__func__,
+		completion_code,
+		sci_base_state_machine_get_state(&request->state_machine));
 
-	/* Tasks aborted specifically by a call to the lldd_abort_task
-	 * function should not be completed to the host in the regular path.
-	 */
-	switch (task_notification_selection) {
+	return SCI_FAILURE_INVALID_STATE;
 
-	case isci_perform_normal_io_completion:
+}
 
-		/* Normal notification (task_done) */
-		dev_dbg(&host->pdev->dev,
-			"%s: Normal - task = %p, response=%d (%d), status=%d (%d)\n",
+/*
+ * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
+ * object receives a scic_sds_request_frame_handler() request. This method
+ * first determines the frame type received.  If this is a response frame then
+ * the response data is copied to the io request response buffer for processing
+ * at completion time. If the frame type is not a response buffer an error is
+ * logged. enum sci_status SCI_SUCCESS SCI_FAILURE_INVALID_PARAMETER_VALUE
+ */
+static enum sci_status
+scic_sds_request_started_state_frame_handler(struct scic_sds_request *sci_req,
+					     u32 frame_index)
+{
+	enum sci_status status;
+	u32 *frame_header;
+	struct ssp_frame_hdr ssp_hdr;
+	ssize_t word_cnt;
+
+	status = scic_sds_unsolicited_frame_control_get_header(
+		&(scic_sds_request_get_controller(sci_req)->uf_control),
+		frame_index,
+		(void **)&frame_header);
+
+	word_cnt = sizeof(struct ssp_frame_hdr) / sizeof(u32);
+	sci_swab32_cpy(&ssp_hdr, frame_header, word_cnt);
+
+	if (ssp_hdr.frame_type == SSP_RESPONSE) {
+		struct ssp_response_iu *resp_iu;
+		ssize_t word_cnt = SSP_RESP_IU_MAX_SIZE / sizeof(u32);
+
+		status = scic_sds_unsolicited_frame_control_get_buffer(
+			&(scic_sds_request_get_controller(sci_req)->uf_control),
+			frame_index,
+			(void **)&resp_iu);
+
+		sci_swab32_cpy(&sci_req->ssp.rsp,
+			       resp_iu, word_cnt);
+
+		resp_iu = &sci_req->ssp.rsp;
+
+		if ((resp_iu->datapres == 0x01) ||
+		    (resp_iu->datapres == 0x02)) {
+			scic_sds_request_set_status(
+				sci_req,
+				SCU_TASK_DONE_CHECK_RESPONSE,
+				SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR);
+		} else
+			scic_sds_request_set_status(
+				sci_req, SCU_TASK_DONE_GOOD, SCI_SUCCESS);
+	} else {
+		/* This was not a response frame why did it get forwarded? */
+		dev_err(scic_to_dev(sci_req->owning_controller),
+			"%s: SCIC IO Request 0x%p received unexpected "
+			"frame %d type 0x%02x\n",
 			__func__,
-			task,
-			task->task_status.resp, response,
-			task->task_status.stat, status);
-		/* Add to the completed list. */
-		list_add(&request->completed_node,
-			 &host->requests_to_complete);
+			sci_req,
+			frame_index,
+			ssp_hdr.frame_type);
+	}
 
-		/* Take the request off the device's pending request list. */
-		list_del_init(&request->dev_node);
-		break;
+	/*
+	 * In any case we are done with this frame buffer return it to the
+	 * controller
+	 */
+	scic_sds_controller_release_frame(
+		sci_req->owning_controller, frame_index);
 
-	case isci_perform_aborted_io_completion:
-		/* No notification to libsas because this request is
-		 * already in the abort path.
-		 */
-		dev_warn(&host->pdev->dev,
-			 "%s: Aborted - task = %p, response=%d (%d), status=%d (%d)\n",
-			 __func__,
-			 task,
-			 task->task_status.resp, response,
-			 task->task_status.stat, status);
+	return SCI_SUCCESS;
+}
 
-		/* Wake up whatever process was waiting for this
-		 * request to complete.
-		 */
-		WARN_ON(request->io_request_completion == NULL);
+/*
+ * *****************************************************************************
+ * *  COMPLETED STATE HANDLERS
+ * ***************************************************************************** */
 
-		if (request->io_request_completion != NULL) {
 
-			/* Signal whoever is waiting that this
-			* request is complete.
-			*/
-			complete(request->io_request_completion);
-		}
-		break;
+/*
+ * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
+ * object receives a scic_sds_request_complete() request. This method frees up
+ * any io request resources that have been allocated and transitions the
+ * request to its final state. Consider stopping the state machine instead of
+ * transitioning to the final state? enum sci_status SCI_SUCCESS
+ */
+static enum sci_status scic_sds_request_completed_state_complete_handler(
+	struct scic_sds_request *request)
+{
+	if (request->was_tag_assigned_by_user != true) {
+		scic_controller_free_io_tag(
+			request->owning_controller, request->io_tag);
+	}
 
-	case isci_perform_error_io_completion:
-		/* Use sas_task_abort */
-		dev_warn(&host->pdev->dev,
-			 "%s: Error - task = %p, response=%d (%d), status=%d (%d)\n",
-			 __func__,
-			 task,
-			 task->task_status.resp, response,
-			 task->task_status.stat, status);
-		/* Add to the aborted list. */
-		list_add(&request->completed_node,
-			 &host->requests_to_errorback);
-		break;
+	if (request->saved_rx_frame_index != SCU_INVALID_FRAME_INDEX) {
+		scic_sds_controller_release_frame(
+			request->owning_controller, request->saved_rx_frame_index);
+	}
 
-	default:
-		dev_warn(&host->pdev->dev,
-			 "%s: Unknown - task = %p, response=%d (%d), status=%d (%d)\n",
-			 __func__,
-			 task,
-			 task->task_status.resp, response,
-			 task->task_status.stat, status);
+	sci_base_state_machine_change_state(&request->state_machine,
+		SCI_BASE_REQUEST_STATE_FINAL);
+	return SCI_SUCCESS;
+}
 
-		/* Add to the error to libsas list. */
-		list_add(&request->completed_node,
-			 &host->requests_to_errorback);
+/*
+ * *****************************************************************************
+ * *  ABORTING STATE HANDLERS
+ * ***************************************************************************** */
+
+/*
+ * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
+ * object receives a scic_sds_request_terminate() request. This method is the
+ * io request aborting state abort handlers.  On receipt of a multiple
+ * terminate requests the io request will transition to the completed state.
+ * This should not happen in normal operation. enum sci_status SCI_SUCCESS
+ */
+static enum sci_status scic_sds_request_aborting_state_abort_handler(
+	struct scic_sds_request *request)
+{
+	sci_base_state_machine_change_state(&request->state_machine,
+		SCI_BASE_REQUEST_STATE_COMPLETED);
+	return SCI_SUCCESS;
+}
+
+/*
+ * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
+ * object receives a scic_sds_request_task_completion() request. This method
+ * decodes the completion type waiting for the abort task complete
+ * notification. When the abort task complete is received the io request
+ * transitions to the completed state. enum sci_status SCI_SUCCESS
+ */
+static enum sci_status scic_sds_request_aborting_state_tc_completion_handler(
+	struct scic_sds_request *sci_req,
+	u32 completion_code)
+{
+	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
+	case (SCU_TASK_DONE_GOOD << SCU_COMPLETION_TL_STATUS_SHIFT):
+	case (SCU_TASK_DONE_TASK_ABORT << SCU_COMPLETION_TL_STATUS_SHIFT):
+		scic_sds_request_set_status(
+			sci_req, SCU_TASK_DONE_TASK_ABORT, SCI_FAILURE_IO_TERMINATED
+			);
+
+		sci_base_state_machine_change_state(&sci_req->state_machine,
+			SCI_BASE_REQUEST_STATE_COMPLETED);
+		break;
+
+	default:
+		/*
+		 * Unless we get some strange error wait for the task abort to complete
+		 * TODO: Should there be a state change for this completion? */
 		break;
 	}
+
+	return SCI_SUCCESS;
+}
+
+/*
+ * This method implements the action to be taken when an SCIC_SDS_IO_REQUEST_T
+ * object receives a scic_sds_request_frame_handler() request. This method
+ * discards the unsolicited frame since we are waiting for the abort task
+ * completion. enum sci_status SCI_SUCCESS
+ */
+static enum sci_status scic_sds_request_aborting_state_frame_handler(
+	struct scic_sds_request *sci_req,
+	u32 frame_index)
+{
+	/* TODO: Is it even possible to get an unsolicited frame in the aborting state? */
+
+	scic_sds_controller_release_frame(
+		sci_req->owning_controller, frame_index);
+
+	return SCI_SUCCESS;
 }
 
+static const struct scic_sds_io_request_state_handler scic_sds_request_state_handler_table[] = {
+	[SCI_BASE_REQUEST_STATE_INITIAL] = {
+	},
+	[SCI_BASE_REQUEST_STATE_CONSTRUCTED] = {
+		.start_handler		= scic_sds_request_constructed_state_start_handler,
+		.abort_handler		= scic_sds_request_constructed_state_abort_handler,
+	},
+	[SCI_BASE_REQUEST_STATE_STARTED] = {
+		.abort_handler		= scic_sds_request_started_state_abort_handler,
+		.tc_completion_handler	= scic_sds_request_started_state_tc_completion_handler,
+		.frame_handler		= scic_sds_request_started_state_frame_handler,
+	},
+	[SCI_BASE_REQUEST_STATE_COMPLETED] = {
+		.complete_handler	= scic_sds_request_completed_state_complete_handler,
+	},
+	[SCI_BASE_REQUEST_STATE_ABORTING] = {
+		.abort_handler		= scic_sds_request_aborting_state_abort_handler,
+		.tc_completion_handler	= scic_sds_request_aborting_state_tc_completion_handler,
+		.frame_handler		= scic_sds_request_aborting_state_frame_handler,
+	},
+	[SCI_BASE_REQUEST_STATE_FINAL] = {
+	},
+};
+
+
 /**
- * isci_request_io_request_complete() - This function is called by the sci core
- *    when an io request completes.
- * @isci_host: This parameter specifies the ISCI host object
- * @request: This parameter is the completed isci_request object.
- * @completion_status: This parameter specifies the completion status from the
- *    sci core.
+ * isci_request_process_response_iu() - This function sets the status and
+ *    response iu, in the task struct, from the request object for the upper
+ *    layer driver.
+ * @sas_task: This parameter is the task struct from the upper layer driver.
+ * @resp_iu: This parameter points to the response iu of the completed request.
+ * @dev: This parameter specifies the linux device struct.
  *
  * none.
  */
-void isci_request_io_request_complete(
-	struct        isci_host *isci_host,
-	struct        isci_request *request,
-	enum sci_io_status completion_status)
+static void isci_request_process_response_iu(
+	struct sas_task *task,
+	struct ssp_response_iu *resp_iu,
+	struct device *dev)
 {
-	struct sas_task *task = isci_request_access_task(request);
-	struct ssp_response_iu *resp_iu;
-	void *resp_buf;
-	unsigned long task_flags;
-	struct isci_remote_device *isci_device   = request->isci_device;
-	enum service_response response       = SAS_TASK_UNDELIVERED;
-	enum exec_status status         = SAS_ABORTED_TASK;
-	enum isci_request_status request_status;
-	enum isci_completion_selection complete_to_host
-		= isci_perform_normal_io_completion;
-
-	dev_dbg(&isci_host->pdev->dev,
-		"%s: request = %p, task = %p,\n"
-		"task->data_dir = %d completion_status = 0x%x\n",
+	dev_dbg(dev,
+		"%s: resp_iu = %p "
+		"resp_iu->status = 0x%x,\nresp_iu->datapres = %d "
+		"resp_iu->response_data_len = %x, "
+		"resp_iu->sense_data_len = %x\nrepsonse data: ",
 		__func__,
-		request,
-		task,
-		task->data_dir,
-		completion_status);
+		resp_iu,
+		resp_iu->status,
+		resp_iu->datapres,
+		resp_iu->response_data_len,
+		resp_iu->sense_data_len);
 
-	spin_lock(&request->state_lock);
-	request_status = isci_request_get_state(request);
+	task->task_status.stat = resp_iu->status;
 
-	/* Decode the request status.  Note that if the request has been
-	 * aborted by a task management function, we don't care
-	 * what the status is.
-	 */
-	switch (request_status) {
+	/* libsas updates the task status fields based on the response iu. */
+	sas_ssp_task_response(dev, task, resp_iu);
+}
 
-	case aborted:
-		/* "aborted" indicates that the request was aborted by a task
-		 * management function, since once a task management request is
-		 * perfomed by the device, the request only completes because
-		 * of the subsequent driver terminate.
-		 *
-		 * Aborted also means an external thread is explicitly managing
-		 * this request, so that we do not complete it up the stack.
-		 *
-		 * The target is still there (since the TMF was successful).
-		 */
-		request->complete_in_target = true;
-		response = SAS_TASK_COMPLETE;
+/**
+ * isci_request_set_open_reject_status() - This function prepares the I/O
+ *    completion for OPEN_REJECT conditions.
+ * @request: This parameter is the completed isci_request object.
+ * @response_ptr: This parameter specifies the service response for the I/O.
+ * @status_ptr: This parameter specifies the exec status for the I/O.
+ * @complete_to_host_ptr: This parameter specifies the action to be taken by
+ *    the LLDD with respect to completing this request or forcing an abort
+ *    condition on the I/O.
+ * @open_rej_reason: This parameter specifies the encoded reason for the
+ *    abandon-class reject.
+ *
+ * none.
+ */
+static void isci_request_set_open_reject_status(
+	struct isci_request *request,
+	struct sas_task *task,
+	enum service_response *response_ptr,
+	enum exec_status *status_ptr,
+	enum isci_completion_selection *complete_to_host_ptr,
+	enum sas_open_rej_reason open_rej_reason)
+{
+	/* Task in the target is done. */
+	request->complete_in_target       = true;
+	*response_ptr                     = SAS_TASK_UNDELIVERED;
+	*status_ptr                       = SAS_OPEN_REJECT;
+	*complete_to_host_ptr             = isci_perform_normal_io_completion;
+	task->task_status.open_rej_reason = open_rej_reason;
+}
 
-		/* See if the device has been/is being stopped. Note
-		 * that we ignore the quiesce state, since we are
-		 * concerned about the actual device state.
-		 */
-		if ((isci_device->status == isci_stopping)
-		    || (isci_device->status == isci_stopped)
-		    )
-			status = SAS_DEVICE_UNKNOWN;
-		else
-			status = SAS_ABORTED_TASK;
+/**
+ * isci_request_handle_controller_specific_errors() - This function decodes
+ *    controller-specific I/O completion error conditions.
+ * @request: This parameter is the completed isci_request object.
+ * @response_ptr: This parameter specifies the service response for the I/O.
+ * @status_ptr: This parameter specifies the exec status for the I/O.
+ * @complete_to_host_ptr: This parameter specifies the action to be taken by
+ *    the LLDD with respect to completing this request or forcing an abort
+ *    condition on the I/O.
+ *
+ * none.
+ */
+static void isci_request_handle_controller_specific_errors(
+	struct isci_remote_device *isci_device,
+	struct isci_request *request,
+	struct sas_task *task,
+	enum service_response *response_ptr,
+	enum exec_status *status_ptr,
+	enum isci_completion_selection *complete_to_host_ptr)
+{
+	unsigned int cstatus;
 
-		complete_to_host = isci_perform_aborted_io_completion;
-		/* This was an aborted request. */
+	cstatus = request->sci.scu_status;
 
-		spin_unlock(&request->state_lock);
-		break;
+	dev_dbg(&request->isci_host->pdev->dev,
+		"%s: %p SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR "
+		"- controller status = 0x%x\n",
+		__func__, request, cstatus);
 
-	case aborting:
-		/* aborting means that the task management function tried and
-		 * failed to abort the request. We need to note the request
-		 * as SAS_TASK_UNDELIVERED, so that the scsi mid layer marks the
-		 * target as down.
-		 *
-		 * Aborting also means an external thread is explicitly managing
-		 * this request, so that we do not complete it up the stack.
-		 */
-		request->complete_in_target = true;
-		response = SAS_TASK_UNDELIVERED;
+	/* Decode the controller-specific errors; most
+	 * important is to recognize those conditions in which
+	 * the target may still have a task outstanding that
+	 * must be aborted.
+	 *
+	 * Note that there are SCU completion codes being
+	 * named in the decode below for which SCIC has already
+	 * done work to handle them in a way other than as
+	 * a controller-specific completion code; these are left
+	 * in the decode below for completeness sake.
+	 */
+	switch (cstatus) {
+	case SCU_TASK_DONE_DMASETUP_DIRERR:
+	/* Also SCU_TASK_DONE_SMP_FRM_TYPE_ERR: */
+	case SCU_TASK_DONE_XFERCNT_ERR:
+		/* Also SCU_TASK_DONE_SMP_UFI_ERR: */
+		if (task->task_proto == SAS_PROTOCOL_SMP) {
+			/* SCU_TASK_DONE_SMP_UFI_ERR == Task Done. */
+			*response_ptr = SAS_TASK_COMPLETE;
 
-		if ((isci_device->status == isci_stopping) ||
-		    (isci_device->status == isci_stopped))
-			/* The device has been /is being stopped. Note that
-			 * we ignore the quiesce state, since we are
+			/* See if the device has been/is being stopped. Note
+			 * that we ignore the quiesce state, since we are
 			 * concerned about the actual device state.
 			 */
-			status = SAS_DEVICE_UNKNOWN;
-		else
-			status = SAS_PHY_DOWN;
+			if ((isci_device->status == isci_stopping) ||
+			    (isci_device->status == isci_stopped))
+				*status_ptr = SAS_DEVICE_UNKNOWN;
+			else
+				*status_ptr = SAS_ABORTED_TASK;
 
-		complete_to_host = isci_perform_aborted_io_completion;
+			request->complete_in_target = true;
 
-		/* This was an aborted request. */
+			*complete_to_host_ptr =
+				isci_perform_normal_io_completion;
+		} else {
+			/* Task in the target is not done. */
+			*response_ptr = SAS_TASK_UNDELIVERED;
 
-		spin_unlock(&request->state_lock);
-		break;
+			if ((isci_device->status == isci_stopping) ||
+			    (isci_device->status == isci_stopped))
+				*status_ptr = SAS_DEVICE_UNKNOWN;
+			else
+				*status_ptr = SAM_STAT_TASK_ABORTED;
 
-	case terminating:
+			request->complete_in_target = false;
 
-		/* This was an terminated request.  This happens when
-		 * the I/O is being terminated because of an action on
-		 * the device (reset, tear down, etc.), and the I/O needs
-		 * to be completed up the stack.
+			*complete_to_host_ptr =
+				isci_perform_error_io_completion;
+		}
+
+		break;
+
+	case SCU_TASK_DONE_CRC_ERR:
+	case SCU_TASK_DONE_NAK_CMD_ERR:
+	case SCU_TASK_DONE_EXCESS_DATA:
+	case SCU_TASK_DONE_UNEXP_FIS:
+	/* Also SCU_TASK_DONE_UNEXP_RESP: */
+	case SCU_TASK_DONE_VIIT_ENTRY_NV:       /* TODO - conditions? */
+	case SCU_TASK_DONE_IIT_ENTRY_NV:        /* TODO - conditions? */
+	case SCU_TASK_DONE_RNCNV_OUTBOUND:      /* TODO - conditions? */
+		/* These are conditions in which the target
+		 * has completed the task, so that no cleanup
+		 * is necessary.
 		 */
-		request->complete_in_target = true;
-		response = SAS_TASK_UNDELIVERED;
+		*response_ptr = SAS_TASK_COMPLETE;
 
 		/* See if the device has been/is being stopped. Note
 		 * that we ignore the quiesce state, since we are
@@ -953,208 +1341,1206 @@ void isci_request_io_request_complete(
 		 */
 		if ((isci_device->status == isci_stopping) ||
 		    (isci_device->status == isci_stopped))
-			status = SAS_DEVICE_UNKNOWN;
+			*status_ptr = SAS_DEVICE_UNKNOWN;
 		else
-			status = SAS_ABORTED_TASK;
-
-		complete_to_host = isci_perform_aborted_io_completion;
+			*status_ptr = SAS_ABORTED_TASK;
 
-		/* This was a terminated request. */
+		request->complete_in_target = true;
 
-		spin_unlock(&request->state_lock);
+		*complete_to_host_ptr = isci_perform_normal_io_completion;
 		break;
 
-	default:
 
-		/* The request is done from an SCU HW perspective. */
-		request->status = completed;
+	/* Note that the only open reject completion codes seen here will be
+	 * abandon-class codes; all others are automatically retried in the SCU.
+	 */
+	case SCU_TASK_OPEN_REJECT_WRONG_DESTINATION:
 
-		spin_unlock(&request->state_lock);
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_WRONG_DEST);
+		break;
 
-		/* This is an active request being completed from the core. */
-		switch (completion_status) {
+	case SCU_TASK_OPEN_REJECT_ZONE_VIOLATION:
 
-		case SCI_IO_FAILURE_RESPONSE_VALID:
-			dev_dbg(&isci_host->pdev->dev,
-				"%s: SCI_IO_FAILURE_RESPONSE_VALID (%p/%p)\n",
-				__func__,
-				request,
-				task);
+		/* Note - the return of AB0 will change when
+		 * libsas implements detection of zone violations.
+		 */
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_RESV_AB0);
+		break;
 
-			if (sas_protocol_ata(task->task_proto)) {
-				resp_buf = &request->sci.stp.rsp;
-				isci_request_process_stp_response(task,
-								  resp_buf);
-			} else if (SAS_PROTOCOL_SSP == task->task_proto) {
+	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_1:
 
-				/* crack the iu response buffer. */
-				resp_iu = &request->sci.ssp.rsp;
-				isci_request_process_response_iu(task, resp_iu,
-								 &isci_host->pdev->dev);
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_RESV_AB1);
+		break;
 
-			} else if (SAS_PROTOCOL_SMP == task->task_proto) {
+	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_2:
 
-				dev_err(&isci_host->pdev->dev,
-					"%s: SCI_IO_FAILURE_RESPONSE_VALID: "
-					"SAS_PROTOCOL_SMP protocol\n",
-					__func__);
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_RESV_AB2);
+		break;
 
-			} else
-				dev_err(&isci_host->pdev->dev,
-					"%s: unknown protocol\n", __func__);
+	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_3:
 
-			/* use the task status set in the task struct by the
-			 * isci_request_process_response_iu call.
-			 */
-			request->complete_in_target = true;
-			response = task->task_status.resp;
-			status = task->task_status.stat;
-			break;
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_RESV_AB3);
+		break;
 
-		case SCI_IO_SUCCESS:
-		case SCI_IO_SUCCESS_IO_DONE_EARLY:
+	case SCU_TASK_OPEN_REJECT_BAD_DESTINATION:
 
-			response = SAS_TASK_COMPLETE;
-			status   = SAM_STAT_GOOD;
-			request->complete_in_target = true;
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_BAD_DEST);
+		break;
 
-			if (task->task_proto == SAS_PROTOCOL_SMP) {
-				void *rsp = &request->sci.smp.rsp;
+	case SCU_TASK_OPEN_REJECT_STP_RESOURCES_BUSY:
 
-				dev_dbg(&isci_host->pdev->dev,
-					"%s: SMP protocol completion\n",
-					__func__);
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_STP_NORES);
+		break;
 
-				sg_copy_from_buffer(
-					&task->smp_task.smp_resp, 1,
-					rsp, sizeof(struct smp_resp));
-			} else if (completion_status
-				   == SCI_IO_SUCCESS_IO_DONE_EARLY) {
+	case SCU_TASK_OPEN_REJECT_PROTOCOL_NOT_SUPPORTED:
 
-				/* This was an SSP / STP / SATA transfer.
-				 * There is a possibility that less data than
-				 * the maximum was transferred.
-				 */
-				u32 transferred_length
-					= scic_io_request_get_number_of_bytes_transferred(&request->sci);
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_EPROTO);
+		break;
 
-				task->task_status.residual
-					= task->total_xfer_len - transferred_length;
+	case SCU_TASK_OPEN_REJECT_CONNECTION_RATE_NOT_SUPPORTED:
 
-				/* If there were residual bytes, call this an
-				 * underrun.
-				 */
-				if (task->task_status.residual != 0)
-					status = SAS_DATA_UNDERRUN;
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_CONN_RATE);
+		break;
 
-				dev_dbg(&isci_host->pdev->dev,
-					"%s: SCI_IO_SUCCESS_IO_DONE_EARLY %d\n",
-					__func__,
-					status);
+	case SCU_TASK_DONE_LL_R_ERR:
+	/* Also SCU_TASK_DONE_ACK_NAK_TO: */
+	case SCU_TASK_DONE_LL_PERR:
+	case SCU_TASK_DONE_LL_SY_TERM:
+	/* Also SCU_TASK_DONE_NAK_ERR:*/
+	case SCU_TASK_DONE_LL_LF_TERM:
+	/* Also SCU_TASK_DONE_DATA_LEN_ERR: */
+	case SCU_TASK_DONE_LL_ABORT_ERR:
+	case SCU_TASK_DONE_SEQ_INV_TYPE:
+	/* Also SCU_TASK_DONE_UNEXP_XR: */
+	case SCU_TASK_DONE_XR_IU_LEN_ERR:
+	case SCU_TASK_DONE_INV_FIS_LEN:
+	/* Also SCU_TASK_DONE_XR_WD_LEN: */
+	case SCU_TASK_DONE_SDMA_ERR:
+	case SCU_TASK_DONE_OFFSET_ERR:
+	case SCU_TASK_DONE_MAX_PLD_ERR:
+	case SCU_TASK_DONE_LF_ERR:
+	case SCU_TASK_DONE_SMP_RESP_TO_ERR:  /* Escalate to dev reset? */
+	case SCU_TASK_DONE_SMP_LL_RX_ERR:
+	case SCU_TASK_DONE_UNEXP_DATA:
+	case SCU_TASK_DONE_UNEXP_SDBFIS:
+	case SCU_TASK_DONE_REG_ERR:
+	case SCU_TASK_DONE_SDB_ERR:
+	case SCU_TASK_DONE_TASK_ABORT:
+	default:
+		/* Task in the target is not done. */
+		*response_ptr = SAS_TASK_UNDELIVERED;
+		*status_ptr = SAM_STAT_TASK_ABORTED;
+		request->complete_in_target = false;
 
-			} else
-				dev_dbg(&isci_host->pdev->dev,
-					"%s: SCI_IO_SUCCESS\n",
-					__func__);
+		*complete_to_host_ptr = isci_perform_error_io_completion;
+		break;
+	}
+}
 
-			break;
+/**
+ * isci_task_save_for_upper_layer_completion() - This function saves the
+ *    request for later completion to the upper layer driver.
+ * @host: This parameter is a pointer to the host on which the the request
+ *    should be queued (either as an error or success).
+ * @request: This parameter is the completed request.
+ * @response: This parameter is the response code for the completed task.
+ * @status: This parameter is the status code for the completed task.
+ *
+ * none.
+ */
+static void isci_task_save_for_upper_layer_completion(
+	struct isci_host *host,
+	struct isci_request *request,
+	enum service_response response,
+	enum exec_status status,
+	enum isci_completion_selection task_notification_selection)
+{
+	struct sas_task *task = isci_request_access_task(request);
 
-		case SCI_IO_FAILURE_TERMINATED:
-			dev_dbg(&isci_host->pdev->dev,
-				"%s: SCI_IO_FAILURE_TERMINATED (%p/%p)\n",
-				__func__,
-				request,
-				task);
+	task_notification_selection
+		= isci_task_set_completion_status(task, response, status,
+						  task_notification_selection);
 
-			/* The request was terminated explicitly.  No handling
-			 * is needed in the SCSI error handler path.
-			 */
-			request->complete_in_target = true;
-			response = SAS_TASK_UNDELIVERED;
+	/* Tasks aborted specifically by a call to the lldd_abort_task
+	 * function should not be completed to the host in the regular path.
+	 */
+	switch (task_notification_selection) {
 
-			/* See if the device has been/is being stopped. Note
-			 * that we ignore the quiesce state, since we are
-			 * concerned about the actual device state.
-			 */
-			if ((isci_device->status == isci_stopping) ||
-			    (isci_device->status == isci_stopped))
-				status = SAS_DEVICE_UNKNOWN;
-			else
-				status = SAS_ABORTED_TASK;
+	case isci_perform_normal_io_completion:
 
-			complete_to_host = isci_perform_normal_io_completion;
-			break;
+		/* Normal notification (task_done) */
+		dev_dbg(&host->pdev->dev,
+			"%s: Normal - task = %p, response=%d (%d), status=%d (%d)\n",
+			__func__,
+			task,
+			task->task_status.resp, response,
+			task->task_status.stat, status);
+		/* Add to the completed list. */
+		list_add(&request->completed_node,
+			 &host->requests_to_complete);
 
-		case SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR:
+		/* Take the request off the device's pending request list. */
+		list_del_init(&request->dev_node);
+		break;
 
-			isci_request_handle_controller_specific_errors(
-				isci_device, request, task, &response, &status,
-				&complete_to_host);
+	case isci_perform_aborted_io_completion:
+		/* No notification to libsas because this request is
+		 * already in the abort path.
+		 */
+		dev_warn(&host->pdev->dev,
+			 "%s: Aborted - task = %p, response=%d (%d), status=%d (%d)\n",
+			 __func__,
+			 task,
+			 task->task_status.resp, response,
+			 task->task_status.stat, status);
 
-			break;
+		/* Wake up whatever process was waiting for this
+		 * request to complete.
+		 */
+		WARN_ON(request->io_request_completion == NULL);
 
-		case SCI_IO_FAILURE_REMOTE_DEVICE_RESET_REQUIRED:
-			/* This is a special case, in that the I/O completion
-			 * is telling us that the device needs a reset.
-			 * In order for the device reset condition to be
-			 * noticed, the I/O has to be handled in the error
-			 * handler.  Set the reset flag and cause the
-			 * SCSI error thread to be scheduled.
-			 */
-			spin_lock_irqsave(&task->task_state_lock, task_flags);
-			task->task_state_flags |= SAS_TASK_NEED_DEV_RESET;
+		if (request->io_request_completion != NULL) {
+
+			/* Signal whoever is waiting that this
+			* request is complete.
+			*/
+			complete(request->io_request_completion);
+		}
+		break;
+
+	case isci_perform_error_io_completion:
+		/* Use sas_task_abort */
+		dev_warn(&host->pdev->dev,
+			 "%s: Error - task = %p, response=%d (%d), status=%d (%d)\n",
+			 __func__,
+			 task,
+			 task->task_status.resp, response,
+			 task->task_status.stat, status);
+		/* Add to the aborted list. */
+		list_add(&request->completed_node,
+			 &host->requests_to_errorback);
+		break;
+
+	default:
+		dev_warn(&host->pdev->dev,
+			 "%s: Unknown - task = %p, response=%d (%d), status=%d (%d)\n",
+			 __func__,
+			 task,
+			 task->task_status.resp, response,
+			 task->task_status.stat, status);
+
+		/* Add to the error to libsas list. */
+		list_add(&request->completed_node,
+			 &host->requests_to_errorback);
+		break;
+	}
+}
+
+static void isci_request_io_request_complete(struct isci_host *isci_host,
+					     struct isci_request *request,
+					     enum sci_io_status completion_status)
+{
+	struct sas_task *task = isci_request_access_task(request);
+	struct ssp_response_iu *resp_iu;
+	void *resp_buf;
+	unsigned long task_flags;
+	struct isci_remote_device *isci_device   = request->isci_device;
+	enum service_response response       = SAS_TASK_UNDELIVERED;
+	enum exec_status status         = SAS_ABORTED_TASK;
+	enum isci_request_status request_status;
+	enum isci_completion_selection complete_to_host
+		= isci_perform_normal_io_completion;
+
+	dev_dbg(&isci_host->pdev->dev,
+		"%s: request = %p, task = %p,\n"
+		"task->data_dir = %d completion_status = 0x%x\n",
+		__func__,
+		request,
+		task,
+		task->data_dir,
+		completion_status);
+
+	spin_lock(&request->state_lock);
+	request_status = isci_request_get_state(request);
+
+	/* Decode the request status.  Note that if the request has been
+	 * aborted by a task management function, we don't care
+	 * what the status is.
+	 */
+	switch (request_status) {
+
+	case aborted:
+		/* "aborted" indicates that the request was aborted by a task
+		 * management function, since once a task management request is
+		 * perfomed by the device, the request only completes because
+		 * of the subsequent driver terminate.
+		 *
+		 * Aborted also means an external thread is explicitly managing
+		 * this request, so that we do not complete it up the stack.
+		 *
+		 * The target is still there (since the TMF was successful).
+		 */
+		request->complete_in_target = true;
+		response = SAS_TASK_COMPLETE;
+
+		/* See if the device has been/is being stopped. Note
+		 * that we ignore the quiesce state, since we are
+		 * concerned about the actual device state.
+		 */
+		if ((isci_device->status == isci_stopping)
+		    || (isci_device->status == isci_stopped)
+		    )
+			status = SAS_DEVICE_UNKNOWN;
+		else
+			status = SAS_ABORTED_TASK;
+
+		complete_to_host = isci_perform_aborted_io_completion;
+		/* This was an aborted request. */
+
+		spin_unlock(&request->state_lock);
+		break;
+
+	case aborting:
+		/* aborting means that the task management function tried and
+		 * failed to abort the request. We need to note the request
+		 * as SAS_TASK_UNDELIVERED, so that the scsi mid layer marks the
+		 * target as down.
+		 *
+		 * Aborting also means an external thread is explicitly managing
+		 * this request, so that we do not complete it up the stack.
+		 */
+		request->complete_in_target = true;
+		response = SAS_TASK_UNDELIVERED;
+
+		if ((isci_device->status == isci_stopping) ||
+		    (isci_device->status == isci_stopped))
+			/* The device has been /is being stopped. Note that
+			 * we ignore the quiesce state, since we are
+			 * concerned about the actual device state.
+			 */
+			status = SAS_DEVICE_UNKNOWN;
+		else
+			status = SAS_PHY_DOWN;
+
+		complete_to_host = isci_perform_aborted_io_completion;
+
+		/* This was an aborted request. */
+
+		spin_unlock(&request->state_lock);
+		break;
+
+	case terminating:
+
+		/* This was an terminated request.  This happens when
+		 * the I/O is being terminated because of an action on
+		 * the device (reset, tear down, etc.), and the I/O needs
+		 * to be completed up the stack.
+		 */
+		request->complete_in_target = true;
+		response = SAS_TASK_UNDELIVERED;
+
+		/* See if the device has been/is being stopped. Note
+		 * that we ignore the quiesce state, since we are
+		 * concerned about the actual device state.
+		 */
+		if ((isci_device->status == isci_stopping) ||
+		    (isci_device->status == isci_stopped))
+			status = SAS_DEVICE_UNKNOWN;
+		else
+			status = SAS_ABORTED_TASK;
+
+		complete_to_host = isci_perform_aborted_io_completion;
+
+		/* This was a terminated request. */
+
+		spin_unlock(&request->state_lock);
+		break;
+
+	default:
+
+		/* The request is done from an SCU HW perspective. */
+		request->status = completed;
+
+		spin_unlock(&request->state_lock);
+
+		/* This is an active request being completed from the core. */
+		switch (completion_status) {
+
+		case SCI_IO_FAILURE_RESPONSE_VALID:
+			dev_dbg(&isci_host->pdev->dev,
+				"%s: SCI_IO_FAILURE_RESPONSE_VALID (%p/%p)\n",
+				__func__,
+				request,
+				task);
+
+			if (sas_protocol_ata(task->task_proto)) {
+				resp_buf = &request->sci.stp.rsp;
+				isci_request_process_stp_response(task,
+								  resp_buf);
+			} else if (SAS_PROTOCOL_SSP == task->task_proto) {
+
+				/* crack the iu response buffer. */
+				resp_iu = &request->sci.ssp.rsp;
+				isci_request_process_response_iu(task, resp_iu,
+								 &isci_host->pdev->dev);
+
+			} else if (SAS_PROTOCOL_SMP == task->task_proto) {
+
+				dev_err(&isci_host->pdev->dev,
+					"%s: SCI_IO_FAILURE_RESPONSE_VALID: "
+					"SAS_PROTOCOL_SMP protocol\n",
+					__func__);
+
+			} else
+				dev_err(&isci_host->pdev->dev,
+					"%s: unknown protocol\n", __func__);
+
+			/* use the task status set in the task struct by the
+			 * isci_request_process_response_iu call.
+			 */
+			request->complete_in_target = true;
+			response = task->task_status.resp;
+			status = task->task_status.stat;
+			break;
+
+		case SCI_IO_SUCCESS:
+		case SCI_IO_SUCCESS_IO_DONE_EARLY:
+
+			response = SAS_TASK_COMPLETE;
+			status   = SAM_STAT_GOOD;
+			request->complete_in_target = true;
+
+			if (task->task_proto == SAS_PROTOCOL_SMP) {
+				void *rsp = &request->sci.smp.rsp;
+
+				dev_dbg(&isci_host->pdev->dev,
+					"%s: SMP protocol completion\n",
+					__func__);
+
+				sg_copy_from_buffer(
+					&task->smp_task.smp_resp, 1,
+					rsp, sizeof(struct smp_resp));
+			} else if (completion_status
+				   == SCI_IO_SUCCESS_IO_DONE_EARLY) {
+
+				/* This was an SSP / STP / SATA transfer.
+				 * There is a possibility that less data than
+				 * the maximum was transferred.
+				 */
+				u32 transferred_length = sci_req_tx_bytes(&request->sci);
+
+				task->task_status.residual
+					= task->total_xfer_len - transferred_length;
+
+				/* If there were residual bytes, call this an
+				 * underrun.
+				 */
+				if (task->task_status.residual != 0)
+					status = SAS_DATA_UNDERRUN;
+
+				dev_dbg(&isci_host->pdev->dev,
+					"%s: SCI_IO_SUCCESS_IO_DONE_EARLY %d\n",
+					__func__,
+					status);
+
+			} else
+				dev_dbg(&isci_host->pdev->dev,
+					"%s: SCI_IO_SUCCESS\n",
+					__func__);
+
+			break;
+
+		case SCI_IO_FAILURE_TERMINATED:
+			dev_dbg(&isci_host->pdev->dev,
+				"%s: SCI_IO_FAILURE_TERMINATED (%p/%p)\n",
+				__func__,
+				request,
+				task);
+
+			/* The request was terminated explicitly.  No handling
+			 * is needed in the SCSI error handler path.
+			 */
+			request->complete_in_target = true;
+			response = SAS_TASK_UNDELIVERED;
+
+			/* See if the device has been/is being stopped. Note
+			 * that we ignore the quiesce state, since we are
+			 * concerned about the actual device state.
+			 */
+			if ((isci_device->status == isci_stopping) ||
+			    (isci_device->status == isci_stopped))
+				status = SAS_DEVICE_UNKNOWN;
+			else
+				status = SAS_ABORTED_TASK;
+
+			complete_to_host = isci_perform_normal_io_completion;
+			break;
+
+		case SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR:
+
+			isci_request_handle_controller_specific_errors(
+				isci_device, request, task, &response, &status,
+				&complete_to_host);
+
+			break;
+
+		case SCI_IO_FAILURE_REMOTE_DEVICE_RESET_REQUIRED:
+			/* This is a special case, in that the I/O completion
+			 * is telling us that the device needs a reset.
+			 * In order for the device reset condition to be
+			 * noticed, the I/O has to be handled in the error
+			 * handler.  Set the reset flag and cause the
+			 * SCSI error thread to be scheduled.
+			 */
+			spin_lock_irqsave(&task->task_state_lock, task_flags);
+			task->task_state_flags |= SAS_TASK_NEED_DEV_RESET;
 			spin_unlock_irqrestore(&task->task_state_lock, task_flags);
 
-			/* Fail the I/O. */
-			response = SAS_TASK_UNDELIVERED;
-			status = SAM_STAT_TASK_ABORTED;
+			/* Fail the I/O. */
+			response = SAS_TASK_UNDELIVERED;
+			status = SAM_STAT_TASK_ABORTED;
+
+			complete_to_host = isci_perform_error_io_completion;
+			request->complete_in_target = false;
+			break;
+
+		default:
+			/* Catch any otherwise unhandled error codes here. */
+			dev_warn(&isci_host->pdev->dev,
+				 "%s: invalid completion code: 0x%x - "
+				 "isci_request = %p\n",
+				 __func__, completion_status, request);
+
+			response = SAS_TASK_UNDELIVERED;
+
+			/* See if the device has been/is being stopped. Note
+			 * that we ignore the quiesce state, since we are
+			 * concerned about the actual device state.
+			 */
+			if ((isci_device->status == isci_stopping) ||
+			    (isci_device->status == isci_stopped))
+				status = SAS_DEVICE_UNKNOWN;
+			else
+				status = SAS_ABORTED_TASK;
+
+			complete_to_host = isci_perform_error_io_completion;
+			request->complete_in_target = false;
+			break;
+		}
+		break;
+	}
+
+	isci_request_unmap_sgl(request, isci_host->pdev);
+
+	/* Put the completed request on the correct list */
+	isci_task_save_for_upper_layer_completion(isci_host, request, response,
+						  status, complete_to_host
+						  );
+
+	/* complete the io request to the core. */
+	scic_controller_complete_io(&isci_host->sci,
+				    &isci_device->sci,
+				    &request->sci);
+	/* set terminated handle so it cannot be completed or
+	 * terminated again, and to cause any calls into abort
+	 * task to recognize the already completed case.
+	 */
+	request->terminated = true;
+
+	isci_host_can_dequeue(isci_host, 1);
+}
+
+/**
+ * scic_sds_request_initial_state_enter() -
+ * @object: This parameter specifies the base object for which the state
+ *    transition is occurring.
+ *
+ * This method implements the actions taken when entering the
+ * SCI_BASE_REQUEST_STATE_INITIAL state. This state is entered when the initial
+ * base request is constructed. Entry into the initial state sets all handlers
+ * for the io request object to their default handlers. none
+ */
+static void scic_sds_request_initial_state_enter(void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCI_BASE_REQUEST_STATE_INITIAL
+		);
+}
+
+/**
+ * scic_sds_request_constructed_state_enter() -
+ * @object: The io request object that is to enter the constructed state.
+ *
+ * This method implements the actions taken when entering the
+ * SCI_BASE_REQUEST_STATE_CONSTRUCTED state. The method sets the state handlers
+ * for the the constructed state. none
+ */
+static void scic_sds_request_constructed_state_enter(void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCI_BASE_REQUEST_STATE_CONSTRUCTED
+		);
+}
+
+/**
+ * scic_sds_request_started_state_enter() -
+ * @object: This parameter specifies the base object for which the state
+ *    transition is occurring.  This is cast into a SCIC_SDS_IO_REQUEST object.
+ *
+ * This method implements the actions taken when entering the
+ * SCI_BASE_REQUEST_STATE_STARTED state. If the io request object type is a
+ * SCSI Task request we must enter the started substate machine. none
+ */
+static void scic_sds_request_started_state_enter(void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCI_BASE_REQUEST_STATE_STARTED
+		);
+
+	/*
+	 * Most of the request state machines have a started substate machine so
+	 * start its execution on the entry to the started state. */
+	if (sci_req->has_started_substate_machine == true)
+		sci_base_state_machine_start(&sci_req->started_substate_machine);
+}
+
+/**
+ * scic_sds_request_started_state_exit() -
+ * @object: This parameter specifies the base object for which the state
+ *    transition is occurring.  This object is cast into a SCIC_SDS_IO_REQUEST
+ *    object.
+ *
+ * This method implements the actions taken when exiting the
+ * SCI_BASE_REQUEST_STATE_STARTED state. For task requests the action will be
+ * to stop the started substate machine. none
+ */
+static void scic_sds_request_started_state_exit(void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	if (sci_req->has_started_substate_machine == true)
+		sci_base_state_machine_stop(&sci_req->started_substate_machine);
+}
+
+/**
+ * scic_sds_request_completed_state_enter() -
+ * @object: This parameter specifies the base object for which the state
+ *    transition is occurring.  This object is cast into a SCIC_SDS_IO_REQUEST
+ *    object.
+ *
+ * This method implements the actions taken when entering the
+ * SCI_BASE_REQUEST_STATE_COMPLETED state.  This state is entered when the
+ * SCIC_SDS_IO_REQUEST has completed.  The method will decode the request
+ * completion status and convert it to an enum sci_status to return in the
+ * completion callback function. none
+ */
+static void scic_sds_request_completed_state_enter(void *object)
+{
+	struct scic_sds_request *sci_req = object;
+	struct scic_sds_controller *scic =
+		scic_sds_request_get_controller(sci_req);
+	struct isci_host *ihost = scic_to_ihost(scic);
+	struct isci_request *ireq = sci_req_to_ireq(sci_req);
+
+	SET_STATE_HANDLER(sci_req,
+			  scic_sds_request_state_handler_table,
+			  SCI_BASE_REQUEST_STATE_COMPLETED);
+
+	/* Tell the SCI_USER that the IO request is complete */
+	if (sci_req->is_task_management_request == false)
+		isci_request_io_request_complete(ihost, ireq,
+						 sci_req->sci_status);
+	else
+		isci_task_request_complete(ihost, ireq, sci_req->sci_status);
+}
+
+/**
+ * scic_sds_request_aborting_state_enter() -
+ * @object: This parameter specifies the base object for which the state
+ *    transition is occurring.  This object is cast into a SCIC_SDS_IO_REQUEST
+ *    object.
+ *
+ * This method implements the actions taken when entering the
+ * SCI_BASE_REQUEST_STATE_ABORTING state. none
+ */
+static void scic_sds_request_aborting_state_enter(void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	/* Setting the abort bit in the Task Context is required by the silicon. */
+	sci_req->task_context_buffer->abort = 1;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCI_BASE_REQUEST_STATE_ABORTING
+		);
+}
+
+/**
+ * scic_sds_request_final_state_enter() -
+ * @object: This parameter specifies the base object for which the state
+ *    transition is occurring.  This is cast into a SCIC_SDS_IO_REQUEST object.
+ *
+ * This method implements the actions taken when entering the
+ * SCI_BASE_REQUEST_STATE_FINAL state. The only action required is to put the
+ * state handlers in place. none
+ */
+static void scic_sds_request_final_state_enter(void *object)
+{
+	struct scic_sds_request *sci_req = object;
+
+	SET_STATE_HANDLER(
+		sci_req,
+		scic_sds_request_state_handler_table,
+		SCI_BASE_REQUEST_STATE_FINAL
+		);
+}
+
+static const struct sci_base_state scic_sds_request_state_table[] = {
+	[SCI_BASE_REQUEST_STATE_INITIAL] = {
+		.enter_state = scic_sds_request_initial_state_enter,
+	},
+	[SCI_BASE_REQUEST_STATE_CONSTRUCTED] = {
+		.enter_state = scic_sds_request_constructed_state_enter,
+	},
+	[SCI_BASE_REQUEST_STATE_STARTED] = {
+		.enter_state = scic_sds_request_started_state_enter,
+		.exit_state  = scic_sds_request_started_state_exit
+	},
+	[SCI_BASE_REQUEST_STATE_COMPLETED] = {
+		.enter_state = scic_sds_request_completed_state_enter,
+	},
+	[SCI_BASE_REQUEST_STATE_ABORTING] = {
+		.enter_state = scic_sds_request_aborting_state_enter,
+	},
+	[SCI_BASE_REQUEST_STATE_FINAL] = {
+		.enter_state = scic_sds_request_final_state_enter,
+	},
+};
+
+static void scic_sds_general_request_construct(struct scic_sds_controller *scic,
+					       struct scic_sds_remote_device *sci_dev,
+					       u16 io_tag, struct scic_sds_request *sci_req)
+{
+	sci_base_state_machine_construct(&sci_req->state_machine, sci_req,
+			scic_sds_request_state_table, SCI_BASE_REQUEST_STATE_INITIAL);
+	sci_base_state_machine_start(&sci_req->state_machine);
+
+	sci_req->io_tag = io_tag;
+	sci_req->owning_controller = scic;
+	sci_req->target_device = sci_dev;
+	sci_req->has_started_substate_machine = false;
+	sci_req->protocol = SCIC_NO_PROTOCOL;
+	sci_req->saved_rx_frame_index = SCU_INVALID_FRAME_INDEX;
+	sci_req->device_sequence = scic_sds_remote_device_get_sequence(sci_dev);
+
+	sci_req->sci_status   = SCI_SUCCESS;
+	sci_req->scu_status   = 0;
+	sci_req->post_context = 0xFFFFFFFF;
+
+	sci_req->is_task_management_request = false;
+
+	if (io_tag == SCI_CONTROLLER_INVALID_IO_TAG) {
+		sci_req->was_tag_assigned_by_user = false;
+		sci_req->task_context_buffer = NULL;
+	} else {
+		sci_req->was_tag_assigned_by_user = true;
+
+		sci_req->task_context_buffer =
+			scic_sds_controller_get_task_context_buffer(scic, io_tag);
+	}
+}
+
+static enum sci_status
+scic_io_request_construct(struct scic_sds_controller *scic,
+			  struct scic_sds_remote_device *sci_dev,
+			  u16 io_tag, struct scic_sds_request *sci_req)
+{
+	struct domain_device *dev = sci_dev_to_domain(sci_dev);
+	enum sci_status status = SCI_SUCCESS;
+
+	/* Build the common part of the request */
+	scic_sds_general_request_construct(scic, sci_dev, io_tag, sci_req);
+
+	if (sci_dev->rnc.remote_node_index ==
+			SCIC_SDS_REMOTE_NODE_CONTEXT_INVALID_INDEX)
+		return SCI_FAILURE_INVALID_REMOTE_DEVICE;
+
+	if (dev->dev_type == SAS_END_DEV)
+		scic_sds_ssp_io_request_assign_buffers(sci_req);
+	else if ((dev->dev_type == SATA_DEV) ||
+		 (dev->tproto & SAS_PROTOCOL_STP)) {
+		scic_sds_stp_request_assign_buffers(sci_req);
+		memset(&sci_req->stp.cmd, 0, sizeof(sci_req->stp.cmd));
+	} else if (dev_is_expander(dev)) {
+		scic_sds_smp_request_assign_buffers(sci_req);
+		memset(&sci_req->smp.cmd, 0, sizeof(sci_req->smp.cmd));
+	} else
+		status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;
+
+	if (status == SCI_SUCCESS) {
+		memset(sci_req->task_context_buffer, 0,
+		       offsetof(struct scu_task_context, sgl_pair_ab));
+	}
+
+	return status;
+}
+
+enum sci_status scic_task_request_construct(struct scic_sds_controller *scic,
+					    struct scic_sds_remote_device *sci_dev,
+					    u16 io_tag, struct scic_sds_request *sci_req)
+{
+	struct domain_device *dev = sci_dev_to_domain(sci_dev);
+	enum sci_status status = SCI_SUCCESS;
+
+	/* Build the common part of the request */
+	scic_sds_general_request_construct(scic, sci_dev, io_tag, sci_req);
+
+	if (dev->dev_type == SAS_END_DEV) {
+		scic_sds_ssp_task_request_assign_buffers(sci_req);
+
+		sci_req->has_started_substate_machine = true;
+
+		/* Construct the started sub-state machine. */
+		sci_base_state_machine_construct(
+			&sci_req->started_substate_machine,
+			sci_req,
+			scic_sds_io_request_started_task_mgmt_substate_table,
+			SCIC_SDS_IO_REQUEST_STARTED_TASK_MGMT_SUBSTATE_AWAIT_TC_COMPLETION
+			);
+	} else if (dev->dev_type == SATA_DEV || (dev->tproto & SAS_PROTOCOL_STP))
+		scic_sds_stp_request_assign_buffers(sci_req);
+	else
+		status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;
+
+	if (status == SCI_SUCCESS) {
+		sci_req->is_task_management_request = true;
+		memset(sci_req->task_context_buffer, 0, sizeof(struct scu_task_context));
+	}
+
+	return status;
+}
+
+static enum sci_status isci_request_ssp_request_construct(
+	struct isci_request *request)
+{
+	enum sci_status status;
+
+	dev_dbg(&request->isci_host->pdev->dev,
+		"%s: request = %p\n",
+		__func__,
+		request);
+	status = scic_io_request_construct_basic_ssp(&request->sci);
+	return status;
+}
+
+static enum sci_status isci_request_stp_request_construct(
+	struct isci_request *request)
+{
+	struct sas_task *task = isci_request_access_task(request);
+	enum sci_status status;
+	struct host_to_dev_fis *register_fis;
+
+	dev_dbg(&request->isci_host->pdev->dev,
+		"%s: request = %p\n",
+		__func__,
+		request);
+
+	/* Get the host_to_dev_fis from the core and copy
+	 * the fis from the task into it.
+	 */
+	register_fis = isci_sata_task_to_fis_copy(task);
+
+	status = scic_io_request_construct_basic_sata(&request->sci);
+
+	/* Set the ncq tag in the fis, from the queue
+	 * command in the task.
+	 */
+	if (isci_sata_is_task_ncq(task)) {
+
+		isci_sata_set_ncq_tag(
+			register_fis,
+			task
+			);
+	}
+
+	return status;
+}
+
+/*
+ * isci_smp_request_build() - This function builds the smp request.
+ * @ireq: This parameter points to the isci_request allocated in the
+ *    request construct function.
+ *
+ * SCI_SUCCESS on successfull completion, or specific failure code.
+ */
+static enum sci_status isci_smp_request_build(struct isci_request *ireq)
+{
+	enum sci_status status = SCI_FAILURE;
+	struct sas_task *task = isci_request_access_task(ireq);
+	struct scic_sds_request *sci_req = &ireq->sci;
+
+	dev_dbg(&ireq->isci_host->pdev->dev,
+		"%s: request = %p\n", __func__, ireq);
+
+	dev_dbg(&ireq->isci_host->pdev->dev,
+		"%s: smp_req len = %d\n",
+		__func__,
+		task->smp_task.smp_req.length);
+
+	/* copy the smp_command to the address; */
+	sg_copy_to_buffer(&task->smp_task.smp_req, 1,
+			  &sci_req->smp.cmd,
+			  sizeof(struct smp_req));
+
+	status = scic_io_request_construct_smp(sci_req);
+	if (status != SCI_SUCCESS)
+		dev_warn(&ireq->isci_host->pdev->dev,
+			 "%s: failed with status = %d\n",
+			 __func__,
+			 status);
+
+	return status;
+}
+
+/**
+ * isci_io_request_build() - This function builds the io request object.
+ * @isci_host: This parameter specifies the ISCI host object
+ * @request: This parameter points to the isci_request object allocated in the
+ *    request construct function.
+ * @sci_device: This parameter is the handle for the sci core's remote device
+ *    object that is the destination for this request.
+ *
+ * SCI_SUCCESS on successfull completion, or specific failure code.
+ */
+static enum sci_status isci_io_request_build(
+	struct isci_host *isci_host,
+	struct isci_request *request,
+	struct isci_remote_device *isci_device)
+{
+	enum sci_status status = SCI_SUCCESS;
+	struct sas_task *task = isci_request_access_task(request);
+	struct scic_sds_remote_device *sci_device = &isci_device->sci;
+
+	dev_dbg(&isci_host->pdev->dev,
+		"%s: isci_device = 0x%p; request = %p, "
+		"num_scatter = %d\n",
+		__func__,
+		isci_device,
+		request,
+		task->num_scatter);
+
+	/* map the sgl addresses, if present.
+	 * libata does the mapping for sata devices
+	 * before we get the request.
+	 */
+	if (task->num_scatter &&
+	    !sas_protocol_ata(task->task_proto) &&
+	    !(SAS_PROTOCOL_SMP & task->task_proto)) {
+
+		request->num_sg_entries = dma_map_sg(
+			&isci_host->pdev->dev,
+			task->scatter,
+			task->num_scatter,
+			task->data_dir
+			);
+
+		if (request->num_sg_entries == 0)
+			return SCI_FAILURE_INSUFFICIENT_RESOURCES;
+	}
+
+	/* build the common request object. For now,
+	 * we will let the core allocate the IO tag.
+	 */
+	status = scic_io_request_construct(&isci_host->sci, sci_device,
+					   SCI_CONTROLLER_INVALID_IO_TAG,
+					   &request->sci);
+
+	if (status != SCI_SUCCESS) {
+		dev_warn(&isci_host->pdev->dev,
+			 "%s: failed request construct\n",
+			 __func__);
+		return SCI_FAILURE;
+	}
+
+	switch (task->task_proto) {
+	case SAS_PROTOCOL_SMP:
+		status = isci_smp_request_build(request);
+		break;
+	case SAS_PROTOCOL_SSP:
+		status = isci_request_ssp_request_construct(request);
+		break;
+	case SAS_PROTOCOL_SATA:
+	case SAS_PROTOCOL_STP:
+	case SAS_PROTOCOL_SATA | SAS_PROTOCOL_STP:
+		status = isci_request_stp_request_construct(request);
+		break;
+	default:
+		dev_warn(&isci_host->pdev->dev,
+			 "%s: unknown protocol\n", __func__);
+		return SCI_FAILURE;
+	}
+
+	return SCI_SUCCESS;
+}
+
+/**
+ * isci_request_alloc_core() - This function gets the request object from the
+ *    isci_host dma cache.
+ * @isci_host: This parameter specifies the ISCI host object
+ * @isci_request: This parameter will contain the pointer to the new
+ *    isci_request object.
+ * @isci_device: This parameter is the pointer to the isci remote device object
+ *    that is the destination for this request.
+ * @gfp_flags: This parameter specifies the os allocation flags.
+ *
+ * SCI_SUCCESS on successfull completion, or specific failure code.
+ */
+static int isci_request_alloc_core(
+	struct isci_host *isci_host,
+	struct isci_request **isci_request,
+	struct isci_remote_device *isci_device,
+	gfp_t gfp_flags)
+{
+	int ret = 0;
+	dma_addr_t handle;
+	struct isci_request *request;
+
 
-			complete_to_host = isci_perform_error_io_completion;
-			request->complete_in_target = false;
-			break;
+	/* get pointer to dma memory. This actually points
+	 * to both the isci_remote_device object and the
+	 * sci object. The isci object is at the beginning
+	 * of the memory allocated here.
+	 */
+	request = dma_pool_alloc(isci_host->dma_pool, gfp_flags, &handle);
+	if (!request) {
+		dev_warn(&isci_host->pdev->dev,
+			 "%s: dma_pool_alloc returned NULL\n", __func__);
+		return -ENOMEM;
+	}
 
-		default:
-			/* Catch any otherwise unhandled error codes here. */
-			dev_warn(&isci_host->pdev->dev,
-				 "%s: invalid completion code: 0x%x - "
-				 "isci_request = %p\n",
-				 __func__, completion_status, request);
+	/* initialize the request object.	*/
+	spin_lock_init(&request->state_lock);
+	request->request_daddr = handle;
+	request->isci_host = isci_host;
+	request->isci_device = isci_device;
+	request->io_request_completion = NULL;
+	request->terminated = false;
 
-			response = SAS_TASK_UNDELIVERED;
+	request->num_sg_entries = 0;
 
-			/* See if the device has been/is being stopped. Note
-			 * that we ignore the quiesce state, since we are
-			 * concerned about the actual device state.
-			 */
-			if ((isci_device->status == isci_stopping) ||
-			    (isci_device->status == isci_stopped))
-				status = SAS_DEVICE_UNKNOWN;
-			else
-				status = SAS_ABORTED_TASK;
+	request->complete_in_target = false;
 
-			complete_to_host = isci_perform_error_io_completion;
-			request->complete_in_target = false;
-			break;
-		}
-		break;
+	INIT_LIST_HEAD(&request->completed_node);
+	INIT_LIST_HEAD(&request->dev_node);
+
+	*isci_request = request;
+	isci_request_change_state(request, allocated);
+
+	return ret;
+}
+
+static int isci_request_alloc_io(
+	struct isci_host *isci_host,
+	struct sas_task *task,
+	struct isci_request **isci_request,
+	struct isci_remote_device *isci_device,
+	gfp_t gfp_flags)
+{
+	int retval = isci_request_alloc_core(isci_host, isci_request,
+					     isci_device, gfp_flags);
+
+	if (!retval) {
+		(*isci_request)->ttype_ptr.io_task_ptr = task;
+		(*isci_request)->ttype                 = io_task;
+
+		task->lldd_task = *isci_request;
 	}
+	return retval;
+}
 
-	isci_request_unmap_sgl(request, isci_host->pdev);
+/**
+ * isci_request_alloc_tmf() - This function gets the request object from the
+ *    isci_host dma cache and initializes the relevant fields as a sas_task.
+ * @isci_host: This parameter specifies the ISCI host object
+ * @sas_task: This parameter is the task struct from the upper layer driver.
+ * @isci_request: This parameter will contain the pointer to the new
+ *    isci_request object.
+ * @isci_device: This parameter is the pointer to the isci remote device object
+ *    that is the destination for this request.
+ * @gfp_flags: This parameter specifies the os allocation flags.
+ *
+ * SCI_SUCCESS on successfull completion, or specific failure code.
+ */
+int isci_request_alloc_tmf(
+	struct isci_host *isci_host,
+	struct isci_tmf *isci_tmf,
+	struct isci_request **isci_request,
+	struct isci_remote_device *isci_device,
+	gfp_t gfp_flags)
+{
+	int retval = isci_request_alloc_core(isci_host, isci_request,
+					     isci_device, gfp_flags);
 
-	/* Put the completed request on the correct list */
-	isci_task_save_for_upper_layer_completion(isci_host, request, response,
-						  status, complete_to_host
-						  );
+	if (!retval) {
 
-	/* complete the io request to the core. */
-	scic_controller_complete_io(&isci_host->sci,
-				    &isci_device->sci,
-				    &request->sci);
-	/* set terminated handle so it cannot be completed or
-	 * terminated again, and to cause any calls into abort
-	 * task to recognize the already completed case.
+		(*isci_request)->ttype_ptr.tmf_task_ptr = isci_tmf;
+		(*isci_request)->ttype = tmf_task;
+	}
+	return retval;
+}
+
+/**
+ * isci_request_execute() - This function allocates the isci_request object,
+ *    all fills in some common fields.
+ * @isci_host: This parameter specifies the ISCI host object
+ * @sas_task: This parameter is the task struct from the upper layer driver.
+ * @isci_request: This parameter will contain the pointer to the new
+ *    isci_request object.
+ * @gfp_flags: This parameter specifies the os allocation flags.
+ *
+ * SCI_SUCCESS on successfull completion, or specific failure code.
+ */
+int isci_request_execute(
+	struct isci_host *isci_host,
+	struct sas_task *task,
+	struct isci_request **isci_request,
+	gfp_t gfp_flags)
+{
+	int ret = 0;
+	struct scic_sds_remote_device *sci_device;
+	enum sci_status status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;
+	struct isci_remote_device *isci_device;
+	struct isci_request *request;
+	unsigned long flags;
+
+	isci_device = task->dev->lldd_dev;
+	sci_device = &isci_device->sci;
+
+	/* do common allocation and init of request object. */
+	ret = isci_request_alloc_io(
+		isci_host,
+		task,
+		&request,
+		isci_device,
+		gfp_flags
+		);
+
+	if (ret)
+		goto out;
+
+	status = isci_io_request_build(isci_host, request, isci_device);
+	if (status != SCI_SUCCESS) {
+		dev_warn(&isci_host->pdev->dev,
+			 "%s: request_construct failed - status = 0x%x\n",
+			 __func__,
+			 status);
+		goto out;
+	}
+
+	spin_lock_irqsave(&isci_host->scic_lock, flags);
+
+	/* send the request, let the core assign the IO TAG.	*/
+	status = scic_controller_start_io(&isci_host->sci, sci_device,
+					  &request->sci,
+					  SCI_CONTROLLER_INVALID_IO_TAG);
+	if (status != SCI_SUCCESS &&
+	    status != SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
+		dev_warn(&isci_host->pdev->dev,
+			 "%s: failed request start (0x%x)\n",
+			 __func__, status);
+		spin_unlock_irqrestore(&isci_host->scic_lock, flags);
+		goto out;
+	}
+
+	/* Either I/O started OK, or the core has signaled that
+	 * the device needs a target reset.
+	 *
+	 * In either case, hold onto the I/O for later.
+	 *
+	 * Update it's status and add it to the list in the
+	 * remote device object.
 	 */
-	request->terminated = true;
+	isci_request_change_state(request, started);
+	list_add(&request->dev_node, &isci_device->reqs_in_process);
 
-	isci_host_can_dequeue(isci_host, 1);
+	if (status == SCI_SUCCESS) {
+		/* Save the tag for possible task mgmt later. */
+		request->io_tag = request->sci.io_tag;
+	} else {
+		/* The request did not really start in the
+		 * hardware, so clear the request handle
+		 * here so no terminations will be done.
+		 */
+		request->terminated = true;
+	}
+	spin_unlock_irqrestore(&isci_host->scic_lock, flags);
+
+	if (status ==
+	    SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
+		/* Signal libsas that we need the SCSI error
+		* handler thread to work on this I/O and that
+		* we want a device reset.
+		*/
+		spin_lock_irqsave(&task->task_state_lock, flags);
+		task->task_state_flags |= SAS_TASK_NEED_DEV_RESET;
+		spin_unlock_irqrestore(&task->task_state_lock, flags);
+
+		/* Cause this task to be scheduled in the SCSI error
+		* handler thread.
+		*/
+		isci_execpath_callback(isci_host, task,
+				       sas_task_abort);
+
+		/* Change the status, since we are holding
+		* the I/O until it is managed by the SCSI
+		* error handler.
+		*/
+		status = SCI_SUCCESS;
+	}
+
+ out:
+	if (status != SCI_SUCCESS) {
+		/* release dma memory on failure. */
+		isci_request_free(isci_host, request);
+		request = NULL;
+		ret = SCI_FAILURE;
+	}
+
+	*isci_request = request;
+	return ret;
 }
+
+
+

commit cc9203bf381a465cd115762b9cf7c9a313c874bc
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sun May 8 17:34:44 2011 -0700

    isci: move core/controller to host
    
    Now that the data structures are unified unify the implementation in
    host.[ch] and cleanup namespace pollution.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index a58072807a37..4961ee347091 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -62,7 +62,6 @@
 #include "sata.h"
 #include "scu_completion_codes.h"
 #include "scic_sds_request.h"
-#include "scic_controller.h"
 #include "sas.h"
 
 static enum sci_status isci_request_ssp_request_construct(

commit ce2b3261b6765c3b80fda95426c73e8d3bb1b035
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sun May 8 15:49:15 2011 -0700

    isci: unify constants
    
    cross driver constants are spread out over multiple header files, consolidate
    them into isci.h, and push some includes out to the source files that need
    them.
    
    TODO: remove SCI_MODE_SIZE infrastructure.
    TODO: task.h is full of inlines that are too large
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 4961ee347091..a58072807a37 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -62,6 +62,7 @@
 #include "sata.h"
 #include "scu_completion_codes.h"
 #include "scic_sds_request.h"
+#include "scic_controller.h"
 #include "sas.h"
 
 static enum sci_status isci_request_ssp_request_construct(

commit 67ea838d17acdad3331aeae848683c768df96aaa
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sun May 8 11:47:15 2011 -0700

    isci: unify request data structures
    
    Make scic_sds_request a proper member of isci_request.  Also let's us
    get rid of the dma pool object size tracking since we now know that all
    requests are sizeof(isci_request).  While cleaning up the construct
    routine incidentally replaced SCI_FIELD_OFFSET with offsetof.
    
    Reported-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index a5b9b22d3b3a..4961ee347091 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -73,9 +73,7 @@ static enum sci_status isci_request_ssp_request_construct(
 		"%s: request = %p\n",
 		__func__,
 		request);
-	status = scic_io_request_construct_basic_ssp(
-		request->sci_request_handle
-		);
+	status = scic_io_request_construct_basic_ssp(&request->sci);
 	return status;
 }
 
@@ -96,9 +94,7 @@ static enum sci_status isci_request_stp_request_construct(
 	 */
 	register_fis = isci_sata_task_to_fis_copy(task);
 
-	status = scic_io_request_construct_basic_sata(
-		request->sci_request_handle
-		);
+	status = scic_io_request_construct_basic_sata(&request->sci);
 
 	/* Set the ncq tag in the fis, from the queue
 	 * command in the task.
@@ -125,7 +121,7 @@ static enum sci_status isci_smp_request_build(struct isci_request *ireq)
 {
 	enum sci_status status = SCI_FAILURE;
 	struct sas_task *task = isci_request_access_task(ireq);
-	struct scic_sds_request *sci_req = ireq->sci_request_handle;
+	struct scic_sds_request *sci_req = &ireq->sci;
 
 	dev_dbg(&ireq->isci_host->pdev->dev,
 		"%s: request = %p\n", __func__, ireq);
@@ -201,8 +197,7 @@ static enum sci_status isci_io_request_build(
 	 */
 	status = scic_io_request_construct(&isci_host->sci, sci_device,
 					   SCI_CONTROLLER_INVALID_IO_TAG,
-					   request, request->sci_req,
-					   &request->sci_request_handle);
+					   &request->sci);
 
 	if (status != SCI_SUCCESS) {
 		dev_warn(&isci_host->pdev->dev,
@@ -211,8 +206,6 @@ static enum sci_status isci_io_request_build(
 		return SCI_FAILURE;
 	}
 
-	request->sci_request_handle->ireq = request;
-
 	switch (task->task_proto) {
 	case SAS_PROTOCOL_SMP:
 		status = isci_smp_request_build(request);
@@ -276,8 +269,8 @@ static int isci_request_alloc_core(
 	request->isci_host = isci_host;
 	request->isci_device = isci_device;
 	request->io_request_completion = NULL;
+	request->terminated = false;
 
-	request->request_alloc_size = isci_host->dma_pool_alloc_size;
 	request->num_sg_entries = 0;
 
 	request->complete_in_target = false;
@@ -381,80 +374,74 @@ int isci_request_execute(
 		goto out;
 
 	status = isci_io_request_build(isci_host, request, isci_device);
-	if (status == SCI_SUCCESS) {
-
-		spin_lock_irqsave(&isci_host->scic_lock, flags);
-
-		/* send the request, let the core assign the IO TAG.	*/
-		status = scic_controller_start_io(
-			&isci_host->sci,
-			sci_device,
-			request->sci_request_handle,
-			SCI_CONTROLLER_INVALID_IO_TAG
-			);
-
-		if (status == SCI_SUCCESS ||
-		    status == SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
-
-			/* Either I/O started OK, or the core has signaled that
-			 * the device needs a target reset.
-			 *
-			 * In either case, hold onto the I/O for later.
-			 *
-			 * Update it's status and add it to the list in the
-			 * remote device object.
-			 */
-			isci_request_change_state(request, started);
-			list_add(&request->dev_node,
-				 &isci_device->reqs_in_process);
-
-			if (status == SCI_SUCCESS) {
-				/* Save the tag for possible task mgmt later. */
-				request->io_tag = scic_io_request_get_io_tag(
-						     request->sci_request_handle);
-			} else {
-				/* The request did not really start in the
-				 * hardware, so clear the request handle
-				 * here so no terminations will be done.
-				 */
-				request->sci_request_handle = NULL;
-			}
+	if (status != SCI_SUCCESS) {
+		dev_warn(&isci_host->pdev->dev,
+			 "%s: request_construct failed - status = 0x%x\n",
+			 __func__,
+			 status);
+		goto out;
+	}
 
-		} else
-			dev_warn(&isci_host->pdev->dev,
-				 "%s: failed request start (0x%x)\n",
-				 __func__, status);
+	spin_lock_irqsave(&isci_host->scic_lock, flags);
 
+	/* send the request, let the core assign the IO TAG.	*/
+	status = scic_controller_start_io(&isci_host->sci, sci_device,
+					  &request->sci,
+					  SCI_CONTROLLER_INVALID_IO_TAG);
+	if (status != SCI_SUCCESS &&
+	    status != SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
+		dev_warn(&isci_host->pdev->dev,
+			 "%s: failed request start (0x%x)\n",
+			 __func__, status);
 		spin_unlock_irqrestore(&isci_host->scic_lock, flags);
+		goto out;
+	}
 
-		if (status ==
-		    SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
-			/* Signal libsas that we need the SCSI error
-			* handler thread to work on this I/O and that
-			* we want a device reset.
-			*/
-			spin_lock_irqsave(&task->task_state_lock, flags);
-			task->task_state_flags |= SAS_TASK_NEED_DEV_RESET;
-			spin_unlock_irqrestore(&task->task_state_lock, flags);
-
-			/* Cause this task to be scheduled in the SCSI error
-			* handler thread.
-			*/
-			isci_execpath_callback(isci_host, task,
-					       sas_task_abort);
-
-			/* Change the status, since we are holding
-			* the I/O until it is managed by the SCSI
-			* error handler.
-			*/
-			status = SCI_SUCCESS;
-		}
+	/* Either I/O started OK, or the core has signaled that
+	 * the device needs a target reset.
+	 *
+	 * In either case, hold onto the I/O for later.
+	 *
+	 * Update it's status and add it to the list in the
+	 * remote device object.
+	 */
+	isci_request_change_state(request, started);
+	list_add(&request->dev_node, &isci_device->reqs_in_process);
 
-	} else
-		dev_warn(&isci_host->pdev->dev,
-			 "%s: request_construct failed - status = 0x%x\n",
-			 __func__,
-			 status);
+	if (status == SCI_SUCCESS) {
+		/* Save the tag for possible task mgmt later. */
+		request->io_tag = scic_io_request_get_io_tag(&request->sci);
+	} else {
+		/* The request did not really start in the
+		 * hardware, so clear the request handle
+		 * here so no terminations will be done.
+		 */
+		request->terminated = true;
+	}
+	spin_unlock_irqrestore(&isci_host->scic_lock, flags);
+
+	if (status ==
+	    SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
+		/* Signal libsas that we need the SCSI error
+		* handler thread to work on this I/O and that
+		* we want a device reset.
+		*/
+		spin_lock_irqsave(&task->task_state_lock, flags);
+		task->task_state_flags |= SAS_TASK_NEED_DEV_RESET;
+		spin_unlock_irqrestore(&task->task_state_lock, flags);
+
+		/* Cause this task to be scheduled in the SCSI error
+		* handler thread.
+		*/
+		isci_execpath_callback(isci_host, task,
+				       sas_task_abort);
+
+		/* Change the status, since we are holding
+		* the I/O until it is managed by the SCSI
+		* error handler.
+		*/
+		status = SCI_SUCCESS;
+	}
 
  out:
 	if (status != SCI_SUCCESS) {
@@ -554,9 +541,7 @@ static void isci_request_handle_controller_specific_errors(
 {
 	unsigned int cstatus;
 
-	cstatus = scic_request_get_controller_status(
-		request->sci_request_handle
-		);
+	cstatus = scic_request_get_controller_status(&request->sci);
 
 	dev_dbg(&request->isci_host->pdev->dev,
 		"%s: %p SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR "
@@ -997,13 +982,13 @@ void isci_request_io_request_complete(
 				task);
 
 			if (sas_protocol_ata(task->task_proto)) {
-				resp_buf = &request->sci_request_handle->stp.rsp;
+				resp_buf = &request->sci.stp.rsp;
 				isci_request_process_stp_response(task,
 								  resp_buf);
 			} else if (SAS_PROTOCOL_SSP == task->task_proto) {
 
 				/* crack the iu response buffer. */
-				resp_iu = &request->sci_request_handle->ssp.rsp;
+				resp_iu = &request->sci.ssp.rsp;
 				isci_request_process_response_iu(task, resp_iu,
 								 &isci_host->pdev->dev);
 
@@ -1034,7 +1019,7 @@ void isci_request_io_request_complete(
 			request->complete_in_target = true;
 
 			if (task->task_proto == SAS_PROTOCOL_SMP) {
-				void *rsp = &request->sci_request_handle->smp.rsp;
+				void *rsp = &request->sci.smp.rsp;
 
 				dev_dbg(&isci_host->pdev->dev,
 					"%s: SMP protocol completion\n",
@@ -1051,8 +1036,7 @@ void isci_request_io_request_complete(
 				 * the maximum was transferred.
 				 */
 				u32 transferred_length
-					= scic_io_request_get_number_of_bytes_transferred(
-					request->sci_request_handle);
+					= scic_io_request_get_number_of_bytes_transferred(&request->sci);
 
 				task->task_status.residual
 					= task->total_xfer_len - transferred_length;
@@ -1165,12 +1149,12 @@ void isci_request_io_request_complete(
 	/* complete the io request to the core. */
 	scic_controller_complete_io(&isci_host->sci,
 				    &isci_device->sci,
-				    request->sci_request_handle);
-	/* NULL the request handle so it cannot be completed or
+				    &request->sci);
+	/* set terminated handle so it cannot be completed or
 	 * terminated again, and to cause any calls into abort
 	 * task to recognize the already completed case.
 	 */
-	request->sci_request_handle = NULL;
+	request->terminated = true;
 
 	isci_host_can_dequeue(isci_host, 1);
 }

commit b7645818cff1536038c0b21407eefb6b9d5755e6
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sun May 8 02:35:32 2011 -0700

    isci: make command/response iu explicit request object members
    
    Final elimination of the anonymous data at the end of the request
    structure.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 9dd971a3fbb2..a5b9b22d3b3a 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -126,7 +126,6 @@ static enum sci_status isci_smp_request_build(struct isci_request *ireq)
 	enum sci_status status = SCI_FAILURE;
 	struct sas_task *task = isci_request_access_task(ireq);
 	struct scic_sds_request *sci_req = ireq->sci_request_handle;
-	void *cmd_iu = sci_req->command_buffer;
 
 	dev_dbg(&ireq->isci_host->pdev->dev,
 		"%s: request = %p\n", __func__, ireq);
@@ -138,7 +137,7 @@ static enum sci_status isci_smp_request_build(struct isci_request *ireq)
 
 	/* copy the smp_command to the address; */
 	sg_copy_to_buffer(&task->smp_task.smp_req, 1,
-			  (char *)cmd_iu,
+			  &sci_req->smp.cmd,
 			  sizeof(struct smp_req));
 
 	status = scic_io_request_construct_smp(sci_req);
@@ -998,25 +997,15 @@ void isci_request_io_request_complete(
 				task);
 
 			if (sas_protocol_ata(task->task_proto)) {
-				resp_buf
-					= scic_stp_io_request_get_d2h_reg_address(
-					request->sci_request_handle
-					);
+				resp_buf = &request->sci_request_handle->stp.rsp;
 				isci_request_process_stp_response(task,
-								  resp_buf
-								  );
-
+								  resp_buf);
 			} else if (SAS_PROTOCOL_SSP == task->task_proto) {
 
 				/* crack the iu response buffer. */
-				resp_iu
-					= scic_io_request_get_response_iu_address(
-					request->sci_request_handle
-					);
-
+				resp_iu = &request->sci_request_handle->ssp.rsp;
 				isci_request_process_response_iu(task, resp_iu,
-								 &isci_host->pdev->dev
-								 );
+								 &isci_host->pdev->dev);
 
 			} else if (SAS_PROTOCOL_SMP == task->task_proto) {
 
@@ -1045,11 +1034,7 @@ void isci_request_io_request_complete(
 			request->complete_in_target = true;
 
 			if (task->task_proto == SAS_PROTOCOL_SMP) {
-
-				u8 *command_iu_address
-					= scic_io_request_get_command_iu_address(
-					request->sci_request_handle
-					);
+				void *rsp = &request->sci_request_handle->smp.rsp;
 
 				dev_dbg(&isci_host->pdev->dev,
 					"%s: SMP protocol completion\n",
@@ -1057,9 +1042,7 @@ void isci_request_io_request_complete(
 
 				sg_copy_from_buffer(
 					&task->smp_task.smp_resp, 1,
-					command_iu_address
-					+ sizeof(struct smp_req),
-					sizeof(struct smp_resp));
+					rsp, sizeof(struct smp_resp));
 			} else if (completion_status
 				   == SCI_IO_SUCCESS_IO_DONE_EARLY) {
 

commit 0d84366fbef557f92ef82ac9a224c57ffb3318bc
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sun May 8 01:56:57 2011 -0700

    isci: make sgl explicit/aligned request object member
    
    Towards unifying request objects we need all members to be defined in the
    object and not carved out of anonymous buffer space.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index e01c2c98f4e9..9dd971a3fbb2 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -200,14 +200,10 @@ static enum sci_status isci_io_request_build(
 	/* build the common request object. For now,
 	 * we will let the core allocate the IO tag.
 	 */
-	status = scic_io_request_construct(
-		&isci_host->sci,
-		sci_device,
-		SCI_CONTROLLER_INVALID_IO_TAG,
-		request,
-		request->sci_request_mem_ptr,
-		(struct scic_sds_request **)&request->sci_request_handle
-		);
+	status = scic_io_request_construct(&isci_host->sci, sci_device,
+					   SCI_CONTROLLER_INVALID_IO_TAG,
+					   request, request->sci_req,
+					   &request->sci_request_handle);
 
 	if (status != SCI_SUCCESS) {
 		dev_warn(&isci_host->pdev->dev,
@@ -277,8 +273,6 @@ static int isci_request_alloc_core(
 
 	/* initialize the request object.	*/
 	spin_lock_init(&request->state_lock);
-	request->sci_request_mem_ptr = ((u8 *)request) +
-				       sizeof(struct isci_request);
 	request->request_daddr = handle;
 	request->isci_host = isci_host;
 	request->isci_device = isci_device;

commit 9286a1959ce7f3df3c1a8e33eb9b210078318dc8
Author: Dave Jiang <dave.jiang@intel.com>
Date:   Fri May 6 02:17:37 2011 +0000

    isci: Removing unnecessary functions in request.c
    
    No need for wrappers, just access sas_task directly.
    
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 0521c045d43b..e01c2c98f4e9 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -1197,37 +1197,3 @@ void isci_request_io_request_complete(
 
 	isci_host_can_dequeue(isci_host, 1);
 }
-
-/**
- * isci_request_io_request_get_transfer_length() - This function is called by
- *    the sci core to retrieve the transfer length for a given request.
- * @request: This parameter is the isci_request object.
- *
- * length of transfer for specified request.
- */
-u32 isci_request_io_request_get_transfer_length(struct isci_request *request)
-{
-	struct sas_task *task = isci_request_access_task(request);
-
-	dev_dbg(&request->isci_host->pdev->dev,
-		"%s: total_xfer_len: %d\n",
-		__func__,
-		task->total_xfer_len);
-	return task->total_xfer_len;
-}
-
-
-/**
- * isci_request_io_request_get_data_direction() - This function is called by
- *    the sci core to retrieve the data direction for a given request.
- * @request: This parameter is the isci_request object.
- *
- * data direction for specified request.
- */
-enum dma_data_direction isci_request_io_request_get_data_direction(
-	struct isci_request *request)
-{
-	struct sas_task *task = isci_request_access_task(request);
-
-	return task->data_dir;
-}

commit cc3dbd0a9178865d4444f8e28b51715808e9ac85
Author: Artur Wojcik <artur.wojcik@intel.com>
Date:   Wed May 4 07:58:16 2011 +0000

    isci: unify isci_host data structures
    
    Make it explicit that isci_host and scic_sds_controller are one in the same
    object.
    
    Signed-off-by: Artur Wojcik <artur.wojcik@intel.com>
    [removed ->ihost back pointer]
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 36adc1589efa..0521c045d43b 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -201,7 +201,7 @@ static enum sci_status isci_io_request_build(
 	 * we will let the core allocate the IO tag.
 	 */
 	status = scic_io_request_construct(
-		isci_host->core_controller,
+		&isci_host->sci,
 		sci_device,
 		SCI_CONTROLLER_INVALID_IO_TAG,
 		request,
@@ -394,7 +394,7 @@ int isci_request_execute(
 
 		/* send the request, let the core assign the IO TAG.	*/
 		status = scic_controller_start_io(
-			isci_host->core_controller,
+			&isci_host->sci,
 			sci_device,
 			request->sci_request_handle,
 			SCI_CONTROLLER_INVALID_IO_TAG
@@ -1186,7 +1186,7 @@ void isci_request_io_request_complete(
 						  );
 
 	/* complete the io request to the core. */
-	scic_controller_complete_io(isci_host->core_controller,
+	scic_controller_complete_io(&isci_host->sci,
 				    &isci_device->sci,
 				    request->sci_request_handle);
 	/* NULL the request handle so it cannot be completed or

commit 2ec53eb4d5b301e5c9c386da5685894d572772a5
Author: Dave Jiang <dave.jiang@intel.com>
Date:   Wed May 4 18:01:22 2011 -0700

    isci: Fixup of smp request
    
    The struct smp_request data structure has be fixed up for Linux consumption.
    This probably should go to scsi/sas.h eventually.
    
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 501df3ca4280..36adc1589efa 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -61,7 +61,8 @@
 #include "request.h"
 #include "sata.h"
 #include "scu_completion_codes.h"
-#include "core/scic_sds_request.h"
+#include "scic_sds_request.h"
+#include "sas.h"
 
 static enum sci_status isci_request_ssp_request_construct(
 	struct isci_request *request)
@@ -113,47 +114,37 @@ static enum sci_status isci_request_stp_request_construct(
 	return status;
 }
 
-/**
- * isci_smp_request_build() - This function builds the smp request object.
- * @isci_host: This parameter specifies the ISCI host object
- * @request: This parameter points to the isci_request object allocated in the
+/*
+ * isci_smp_request_build() - This function builds the smp request.
+ * @ireq: This parameter points to the isci_request allocated in the
  *    request construct function.
- * @sci_device: This parameter is the handle for the sci core's remote device
- *    object that is the destination for this request.
  *
  * SCI_SUCCESS on successfull completion, or specific failure code.
  */
-static enum sci_status isci_smp_request_build(
-	struct isci_request *request)
+static enum sci_status isci_smp_request_build(struct isci_request *ireq)
 {
 	enum sci_status status = SCI_FAILURE;
-	struct sas_task *task = isci_request_access_task(request);
+	struct sas_task *task = isci_request_access_task(ireq);
+	struct scic_sds_request *sci_req = ireq->sci_request_handle;
+	void *cmd_iu = sci_req->command_buffer;
 
-	void *command_iu_address =
-		scic_io_request_get_command_iu_address(
-			request->sci_request_handle
-			);
+	dev_dbg(&ireq->isci_host->pdev->dev,
+		"%s: request = %p\n", __func__, ireq);
 
-	dev_dbg(&request->isci_host->pdev->dev,
-		"%s: request = %p\n",
-		__func__,
-		request);
-	dev_dbg(&request->isci_host->pdev->dev,
+	dev_dbg(&ireq->isci_host->pdev->dev,
 		"%s: smp_req len = %d\n",
 		__func__,
 		task->smp_task.smp_req.length);
 
 	/* copy the smp_command to the address; */
 	sg_copy_to_buffer(&task->smp_task.smp_req, 1,
-			  (char *)command_iu_address,
-			  sizeof(struct smp_request)
-			  );
+			  (char *)cmd_iu,
+			  sizeof(struct smp_req));
 
-	status = scic_io_request_construct_smp(request->sci_request_handle);
+	status = scic_io_request_construct_smp(sci_req);
 	if (status != SCI_SUCCESS)
-		dev_warn(&request->isci_host->pdev->dev,
-			 "%s: scic_io_request_construct_smp failed with "
-			 "status = %d\n",
+		dev_warn(&ireq->isci_host->pdev->dev,
+			 "%s: failed with status = %d\n",
 			 __func__,
 			 status);
 
@@ -1073,9 +1064,8 @@ void isci_request_io_request_complete(
 				sg_copy_from_buffer(
 					&task->smp_task.smp_resp, 1,
 					command_iu_address
-					+ sizeof(struct smp_request),
-					sizeof(struct smp_resp)
-					);
+					+ sizeof(struct smp_req),
+					sizeof(struct smp_resp));
 			} else if (completion_status
 				   == SCI_IO_SUCCESS_IO_DONE_EARLY) {
 

commit 0cfa890e5a8a9e3b01b75c17a7856cf96e026e27
Author: Dave Jiang <dave.jiang@intel.com>
Date:   Wed May 4 17:44:54 2011 -0700

    isci: Fixup SSP command IU and task IU
    
    Fixup of SSP command IU and SSP task IU to something that looks like Linux
    
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index c45e78e41f27..501df3ca4280 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -1241,124 +1241,3 @@ enum dma_data_direction isci_request_io_request_get_data_direction(
 
 	return task->data_dir;
 }
-
-/**
- * isci_request_sge_get_address_field() - This function is called by the sci
- *    core to retrieve the address field contents for a given sge.
- * @request: This parameter is the isci_request object.
- * @sge_address: This parameter is the sge.
- *
- * physical address in the specified sge.
- */
-
-
-/**
- * isci_request_sge_get_length_field() - This function is called by the sci
- *    core to retrieve the length field contents for a given sge.
- * @request: This parameter is the isci_request object.
- * @sge_address: This parameter is the sge.
- *
- * length field value in the specified sge.
- */
-
-
-/**
- * isci_request_ssp_io_request_get_cdb_address() - This function is called by
- *    the sci core to retrieve the cdb address for a given request.
- * @request: This parameter is the isci_request object.
- *
- * cdb address for specified request.
- */
-void *isci_request_ssp_io_request_get_cdb_address(
-	struct isci_request *request)
-{
-	struct sas_task *task = isci_request_access_task(request);
-
-	dev_dbg(&request->isci_host->pdev->dev,
-		"%s: request->task->ssp_task.cdb = %p\n",
-		__func__,
-		task->ssp_task.cdb);
-	return task->ssp_task.cdb;
-}
-
-
-/**
- * isci_request_ssp_io_request_get_cdb_length() - This function is called by
- *    the sci core to retrieve the cdb length for a given request.
- * @request: This parameter is the isci_request object.
- *
- * cdb length for specified request.
- */
-u32 isci_request_ssp_io_request_get_cdb_length(
-	struct isci_request *request)
-{
-	return 16;
-}
-
-
-/**
- * isci_request_ssp_io_request_get_lun() - This function is called by the sci
- *    core to retrieve the lun for a given request.
- * @request: This parameter is the isci_request object.
- *
- * lun for specified request.
- */
-u32 isci_request_ssp_io_request_get_lun(
-	struct isci_request *request)
-{
-	struct sas_task *task = isci_request_access_task(request);
-
-#ifdef DEBUG
-	int i;
-
-	for (i = 0; i < 8; i++)
-		dev_dbg(&request->isci_host->pdev->dev,
-			"%s: task->ssp_task.LUN[%d] = %x\n",
-			__func__, i, task->ssp_task.LUN[i]);
-
-#endif
-
-	return task->ssp_task.LUN[0];
-}
-
-
-/**
- * isci_request_ssp_io_request_get_task_attribute() - This function is called
- *    by the sci core to retrieve the task attribute for a given request.
- * @request: This parameter is the isci_request object.
- *
- * task attribute for specified request.
- */
-u32 isci_request_ssp_io_request_get_task_attribute(
-	struct isci_request *request)
-{
-	struct sas_task *task = isci_request_access_task(request);
-
-	dev_dbg(&request->isci_host->pdev->dev,
-		"%s: request->task->ssp_task.task_attr = %x\n",
-		__func__,
-		task->ssp_task.task_attr);
-
-	return task->ssp_task.task_attr;
-}
-
-
-/**
- * isci_request_ssp_io_request_get_command_priority() - This function is called
- *    by the sci core to retrieve the command priority for a given request.
- * @request: This parameter is the isci_request object.
- *
- * command priority for specified request.
- */
-u32 isci_request_ssp_io_request_get_command_priority(
-	struct isci_request *request)
-{
-	struct sas_task *task = isci_request_access_task(request);
-
-	dev_dbg(&request->isci_host->pdev->dev,
-		"%s: request->task->ssp_task.task_prio = %x\n",
-		__func__,
-		task->ssp_task.task_prio);
-
-	return task->ssp_task.task_prio;
-}

commit 890cae9b8a7defd87feb1ec77a2affd25bd59cce
Author: Maciej Patelczyk <maciej.patelczyk@intel.com>
Date:   Thu Apr 28 22:06:31 2011 +0000

    isci: Removed sci_base_object from scic_sds_request.
    
    The 'struct sci_base_object' was removed from the struct
    scic_sds_request and was replaced by a pointer to
    struct isci_request.
    
    Signed-off-by: Maciej Patelczyk <maciej.patelczyk@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 281a556f5eeb..c45e78e41f27 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -61,7 +61,7 @@
 #include "request.h"
 #include "sata.h"
 #include "scu_completion_codes.h"
-
+#include "core/scic_sds_request.h"
 
 static enum sci_status isci_request_ssp_request_construct(
 	struct isci_request *request)
@@ -225,7 +225,7 @@ static enum sci_status isci_io_request_build(
 		return SCI_FAILURE;
 	}
 
-	sci_object_set_association(request->sci_request_handle, request);
+	request->sci_request_handle->ireq = request;
 
 	switch (task->task_proto) {
 	case SAS_PROTOCOL_SMP:

commit a1a113b0a1ea437daf099b44f8a39e93a02a3f47
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Apr 21 18:44:45 2011 -0700

    isci: kill smp_discover_response_protocols in favor of domain_device.dev_type
    
    This is step 1 of removing the contortions to:
    1/ unparse expander phy data into a smp discover frame
    2/ open-code-parse the smp discover fram into a domain_device.dev_type equivalent
    
    libsas has already spent cycles determining the dev_type, so now that
    scic_sds_remote_device is unified with isci_remote_device we can
    directly reference dev_type.
    
    This might also change multi-level expander detection as we previously only
    looked at dev_type == EDGE_DEV and we did not consider the FANOUT_DEV case.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index ff5c05a19543..281a556f5eeb 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -175,7 +175,6 @@ static enum sci_status isci_io_request_build(
 	struct isci_request *request,
 	struct isci_remote_device *isci_device)
 {
-	struct smp_discover_response_protocols dev_protocols;
 	enum sci_status status = SCI_SUCCESS;
 	struct sas_task *task = isci_request_access_task(request);
 	struct scic_sds_remote_device *sci_device = &isci_device->sci;
@@ -228,15 +227,19 @@ static enum sci_status isci_io_request_build(
 
 	sci_object_set_association(request->sci_request_handle, request);
 
-	/* Determine protocol and call the appropriate basic constructor */
-	scic_remote_device_get_protocols(sci_device, &dev_protocols);
-	if (dev_protocols.u.bits.attached_ssp_target)
+	switch (task->task_proto) {
+	case SAS_PROTOCOL_SMP:
+		status = isci_smp_request_build(request);
+		break;
+	case SAS_PROTOCOL_SSP:
 		status = isci_request_ssp_request_construct(request);
-	else if (dev_protocols.u.bits.attached_stp_target)
+		break;
+	case SAS_PROTOCOL_SATA:
+	case SAS_PROTOCOL_STP:
+	case SAS_PROTOCOL_SATA | SAS_PROTOCOL_STP:
 		status = isci_request_stp_request_construct(request);
-	else if (dev_protocols.u.bits.attached_smp_target)
-		status = isci_smp_request_build(request);
-	else {
+		break;
+	default:
 		dev_warn(&isci_host->pdev->dev,
 			 "%s: unknown protocol\n", __func__);
 		return SCI_FAILURE;

commit 88f3b62ac131e2549b6c262cacbd47e8cca42d6e
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Apr 22 19:18:03 2011 -0700

    isci: move remote_device handling out of the core
    
    Now that the core/lldd remote_device data structures are nominally unified
    merge the corresponding sources into the top-level directory.  Also move the
    remote_node_context infrastructure which has no analog at the lldd level.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 8d2125b520ea..ff5c05a19543 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -54,7 +54,6 @@
  */
 
 #include "isci.h"
-#include "scic_remote_device.h"
 #include "scic_io_request.h"
 #include "scic_task_request.h"
 #include "scic_port.h"

commit 57f20f4ed6fb702339be2ef4dea9d15e6a7d0d07
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Apr 21 18:14:45 2011 -0700

    isci: unify remote_device data structures
    
    Make it explicit that isci_remote_device and scic_sds_remote_device are
    one in the same object.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index a90c299b723a..8d2125b520ea 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -179,7 +179,7 @@ static enum sci_status isci_io_request_build(
 	struct smp_discover_response_protocols dev_protocols;
 	enum sci_status status = SCI_SUCCESS;
 	struct sas_task *task = isci_request_access_task(request);
-	struct scic_sds_remote_device *sci_device = to_sci_dev(isci_device);
+	struct scic_sds_remote_device *sci_device = &isci_device->sci;
 
 	dev_dbg(&isci_host->pdev->dev,
 		"%s: isci_device = 0x%p; request = %p, "
@@ -380,7 +380,7 @@ int isci_request_execute(
 	unsigned long flags;
 
 	isci_device = task->dev->lldd_dev;
-	sci_device = to_sci_dev(isci_device);
+	sci_device = &isci_device->sci;
 
 	/* do common allocation and init of request object. */
 	ret = isci_request_alloc_io(
@@ -1194,11 +1194,9 @@ void isci_request_io_request_complete(
 						  );
 
 	/* complete the io request to the core. */
-	scic_controller_complete_io(
-		isci_host->core_controller,
-		to_sci_dev(isci_device),
-		request->sci_request_handle
-		);
+	scic_controller_complete_io(isci_host->core_controller,
+				    &isci_device->sci,
+				    request->sci_request_handle);
 	/* NULL the request handle so it cannot be completed or
 	 * terminated again, and to cause any calls into abort
 	 * task to recognize the already completed case.

commit 6cb4d6b382be6345c2d0c4b1b90dfdf9af32da7e
Author: Bartosz Barcinski <Bartosz.Barcinski@intel.com>
Date:   Tue Apr 12 17:28:43 2011 -0700

    isci: audit usage of BUG_ON macro in isci driver
    
    Removes unnecessary usage of BUG_ON macro, excluding core directory.
    In some cases macro is unnecesary, check is done in caller function.
    In other cases macro is replaced by if construction with
    appropriate warning.
    
    Signed-off-by: Maciej Patelczyk <maciej.patelczyk@intel.com>
    [changed some survivable bug conditions to WARN_ONCE]
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 37ffedc94ac0..a90c299b723a 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -472,7 +472,6 @@ int isci_request_execute(
 
  out:
 	if (status != SCI_SUCCESS) {
-
 		/* release dma memory on failure. */
 		isci_request_free(isci_host, request);
 		request = NULL;

commit 4393aa4e6b9517a666f0ef6b774fd421a9dc4c68
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Mar 31 13:10:44 2011 -0700

    isci: fix fragile/conditional isci_host lookups
    
    A domain_device can always reference back to ->lldd_ha unlike local lldd
    structures.  Fix up cases where the driver uses local objects to look up the
    isci_host.  This also changes the calling conventions of some routines to
    expect a valid isci_host parameter rather than re-lookup the pointer on entry.
    
    Incidentally cleans up some macros that are longer to type than the open-coded
    equivalent:
      isci_host_from_sas_ha
      isci_dev_from_domain_dev
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index b519373597a5..37ffedc94ac0 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -379,7 +379,7 @@ int isci_request_execute(
 	struct isci_request *request;
 	unsigned long flags;
 
-	isci_device = isci_dev_from_domain_dev(task->dev);
+	isci_device = task->dev->lldd_dev;
 	sci_device = to_sci_dev(isci_device);
 
 	/* do common allocation and init of request object. */

commit ed8a72d108bd951909b28fa4a89aad6489f414e1
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Thu Mar 31 13:10:40 2011 -0700

    isci: Qualify when the host lock is managed for STP/SATA callbacks.
    
    In the case of internal discovery related STP/SATA I/O started
    through sas_execute_task the host lock is not taken by libsas before
    calling lldd_execute_task, so the lock should not be managed before
    calling back to libsas through task->task_done or sas_task_abort.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 946caaeb66c6..b519373597a5 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -53,7 +53,6 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
-#include <scsi/sas_ata.h>
 #include "isci.h"
 #include "scic_remote_device.h"
 #include "scic_io_request.h"
@@ -452,22 +451,11 @@ int isci_request_execute(
 			task->task_state_flags |= SAS_TASK_NEED_DEV_RESET;
 			spin_unlock_irqrestore(&task->task_state_lock, flags);
 
-			/* Cause this task to be scheduled in the SCSI error handler
-			* thread.
+			/* Cause this task to be scheduled in the SCSI error
+			* handler thread.
 			*/
-			if (dev_is_sata(task->dev)) {
-				/* Since we are still in the submit path, and since
-				* libsas takes the host lock on behalf of SATA
-				* devices before I/O starts, we need to unlock
-				* before we can put the task in the error path.
-				*/
-				raw_local_irq_save(flags);
-				spin_unlock(isci_host->shost->host_lock);
-				sas_task_abort(task);
-				spin_lock(isci_host->shost->host_lock);
-				raw_local_irq_restore(flags);
-			} else
-				sas_task_abort(task);
+			isci_execpath_callback(isci_host, task,
+					       sas_task_abort);
 
 			/* Change the status, since we are holding
 			* the I/O until it is managed by the SCSI

commit ce4f75def3999fbe454da9aa733ed322bc671b06
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Thu Mar 31 13:10:36 2011 -0700

    isci: Free host lock for SATA/STP abort escalation at submission time.
    
    In the case of I/O requests that fail at submit time because of a
    pending reset condition, the host lock for SATA/STP devices must be
    managed for any SCSI-initiated I/O before sas_task_abort is called.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index c6ce9d0c50c2..946caaeb66c6 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -53,6 +53,7 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
+#include <scsi/sas_ata.h>
 #include "isci.h"
 #include "scic_remote_device.h"
 #include "scic_io_request.h"
@@ -355,33 +356,6 @@ int isci_request_alloc_tmf(
 	return retval;
 }
 
-/**
- * isci_request_signal_device_reset() - This function will set the "device
- *    needs target reset" flag in the given sas_tasks' task_state_flags, and
- *    then cause the task to be added into the SCSI error handler queue which
- *    will eventually be escalated to a target reset.
- *
- *
- */
-static void isci_request_signal_device_reset(
-	struct isci_request *isci_request)
-{
-	unsigned long flags;
-	struct sas_task *task = isci_request_access_task(isci_request);
-
-	dev_dbg(&isci_request->isci_host->pdev->dev,
-		"%s: request=%p, task=%p\n", __func__, isci_request, task);
-
-	spin_lock_irqsave(&task->task_state_lock, flags);
-	task->task_state_flags |= SAS_TASK_NEED_DEV_RESET;
-	spin_unlock_irqrestore(&task->task_state_lock, flags);
-
-	/* Cause this task to be scheduled in the SCSI error handler
-	 * thread.
-	 */
-	sas_task_abort(task);
-}
-
 /**
  * isci_request_execute() - This function allocates the isci_request object,
  *    all fills in some common fields.
@@ -453,11 +427,18 @@ int isci_request_execute(
 				/* Save the tag for possible task mgmt later. */
 				request->io_tag = scic_io_request_get_io_tag(
 						     request->sci_request_handle);
+			} else {
+				/* The request did not really start in the
+				 * hardware, so clear the request handle
+				 * here so no terminations will be done.
+				 */
+				request->sci_request_handle = NULL;
 			}
+
 		} else
 			dev_warn(&isci_host->pdev->dev,
-				 "%s: failed request start\n",
-				 __func__);
+				 "%s: failed request start (0x%x)\n",
+				 __func__, status);
 
 		spin_unlock_irqrestore(&isci_host->scic_lock, flags);
 
@@ -467,7 +448,26 @@ int isci_request_execute(
 			* handler thread to work on this I/O and that
 			* we want a device reset.
 			*/
-			isci_request_signal_device_reset(request);
+			spin_lock_irqsave(&task->task_state_lock, flags);
+			task->task_state_flags |= SAS_TASK_NEED_DEV_RESET;
+			spin_unlock_irqrestore(&task->task_state_lock, flags);
+
+			/* Cause this task to be scheduled in the SCSI error handler
+			* thread.
+			*/
+			if (dev_is_sata(task->dev)) {
+				/* Since we are still in the submit path, and since
+				* libsas takes the host lock on behalf of SATA
+				* devices before I/O starts, we need to unlock
+				* before we can put the task in the error path.
+				*/
+				raw_local_irq_save(flags);
+				spin_unlock(isci_host->shost->host_lock);
+				sas_task_abort(task);
+				spin_lock(isci_host->shost->host_lock);
+				raw_local_irq_restore(flags);
+			} else
+				sas_task_abort(task);
 
 			/* Change the status, since we are holding
 			* the I/O until it is managed by the SCSI

commit 35173d579a08c0d145b3020039d3ba33fbf2c184
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sat Mar 26 16:43:01 2011 -0700

    isci: namespacecheck cleanups
    
    * mark needlessly global routines static
    * delete unused functions
    * move kernel-doc blocks from header files to source
    * reorder some functions to delete declarations
    * more default handler cleanups phy
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index eba8e0b3c873..c6ce9d0c50c2 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -1263,47 +1263,6 @@ enum dma_data_direction isci_request_io_request_get_data_direction(
  *
  * physical address in the specified sge.
  */
-dma_addr_t isci_request_sge_get_address_field(
-	struct isci_request *request,
-	void *sge_address)
-{
-	struct sas_task *task = isci_request_access_task(request);
-	dma_addr_t ret;
-	struct isci_host *isci_host = isci_host_from_sas_ha(
-		task->dev->port->ha);
-
-	dev_dbg(&isci_host->pdev->dev,
-		"%s: request = %p, sge_address = %p\n",
-		__func__,
-		request,
-		sge_address);
-
-	if (task->data_dir == PCI_DMA_NONE)
-		return 0;
-
-	/* the case where num_scatter == 0 is special, in that
-	 * task->scatter is the actual buffer address, not an sgl.
-	 * so a map single is required here.
-	 */
-	if ((task->num_scatter == 0) &&
-	    !sas_protocol_ata(task->task_proto)) {
-		ret = dma_map_single(
-			&isci_host->pdev->dev,
-			task->scatter,
-			task->total_xfer_len,
-			task->data_dir
-			);
-		request->zero_scatter_daddr = ret;
-	} else
-		ret = sg_dma_address(((struct scatterlist *)sge_address));
-
-	dev_dbg(&isci_host->pdev->dev,
-		"%s: bus address = %lx\n",
-		__func__,
-		(unsigned long)ret);
-
-	return ret;
-}
 
 
 /**
@@ -1314,38 +1273,6 @@ dma_addr_t isci_request_sge_get_address_field(
  *
  * length field value in the specified sge.
  */
-u32 isci_request_sge_get_length_field(
-	struct isci_request *request,
-	void *sge_address)
-{
-	struct sas_task *task = isci_request_access_task(request);
-	int ret;
-
-	dev_dbg(&request->isci_host->pdev->dev,
-		"%s: request = %p, sge_address = %p\n",
-		__func__,
-		request,
-		sge_address);
-
-	if (task->data_dir == PCI_DMA_NONE)
-		return 0;
-
-	/* the case where num_scatter == 0 is special, in that
-	 * task->scatter is the actual buffer address, not an sgl.
-	 * so we return total_xfer_len here.
-	 */
-	if (task->num_scatter == 0)
-		ret = task->total_xfer_len;
-	else
-		ret = sg_dma_len((struct scatterlist *)sge_address);
-
-	dev_dbg(&request->isci_host->pdev->dev,
-		"%s: len = %d\n",
-		__func__,
-		ret);
-
-	return ret;
-}
 
 
 /**

commit c4b9e24c4be67aeed44cd46ef5ea92948d02a426
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Wed Mar 16 09:41:59 2011 -0700

    isci: don't hold scic_lock over calls to sas_task_abort()
    
    In the case where submitted I/Os fail with the status code
    SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED, the execute function now waits
    until scic_lock is cleared before calling the helper function
    "isci_request_signal_device_reset" which sets the flag for the pending
    reset condition on the I/O.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 015643104311..eba8e0b3c873 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -449,26 +449,11 @@ int isci_request_execute(
 			list_add(&request->dev_node,
 				 &isci_device->reqs_in_process);
 
-			if (status ==
-				SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
-				/* Signal libsas that we need the SCSI error
-				 * handler thread to work on this I/O and that
-				 * we want a device reset.
-				 */
-				isci_request_signal_device_reset(request);
-
-				/* Change the status, since we are holding
-				 * the I/O until it is managed by the SCSI
-				 * error handler.
-				 */
-				status = SCI_SUCCESS;
-			}
-			else
+			if (status == SCI_SUCCESS) {
 				/* Save the tag for possible task mgmt later. */
 				request->io_tag = scic_io_request_get_io_tag(
 						     request->sci_request_handle);
-
-
+			}
 		} else
 			dev_warn(&isci_host->pdev->dev,
 				 "%s: failed request start\n",
@@ -476,6 +461,21 @@ int isci_request_execute(
 
 		spin_unlock_irqrestore(&isci_host->scic_lock, flags);
 
+		if (status ==
+		    SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
+			/* Signal libsas that we need the SCSI error
+			* handler thread to work on this I/O and that
+			* we want a device reset.
+			*/
+			isci_request_signal_device_reset(request);
+
+			/* Change the status, since we are holding
+			* the I/O until it is managed by the SCSI
+			* error handler.
+			*/
+			status = SCI_SUCCESS;
+		}
+
 	} else
 		dev_warn(&isci_host->pdev->dev,
 			 "%s: request_construct failed - status = 0x%x\n",

commit aa14510295d3d87431c915c0b2bc5dd3af7f2c35
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Mon Mar 7 16:40:47 2011 -0700

    isci: Always set response/status for requests going into the error path.
    
    In the case of I/O requests being failed because of a required device
    reset condition, set the response and status to indicate an I/O failure.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index f19a952754b9..015643104311 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -809,11 +809,11 @@ static void isci_task_save_for_upper_layer_completion(
 
 		/* Normal notification (task_done) */
 		dev_dbg(&host->pdev->dev,
-			"%s: Normal - task = %p, response=%d, status=%d\n",
+			"%s: Normal - task = %p, response=%d (%d), status=%d (%d)\n",
 			__func__,
 			task,
-			response,
-			status);
+			task->task_status.resp, response,
+			task->task_status.stat, status);
 		/* Add to the completed list. */
 		list_add(&request->completed_node,
 			 &host->requests_to_complete);
@@ -827,11 +827,11 @@ static void isci_task_save_for_upper_layer_completion(
 		 * already in the abort path.
 		 */
 		dev_warn(&host->pdev->dev,
-			 "%s: Aborted - task = %p, response=%d, status=%d\n",
+			 "%s: Aborted - task = %p, response=%d (%d), status=%d (%d)\n",
 			 __func__,
 			 task,
-			 response,
-			 status);
+			 task->task_status.resp, response,
+			 task->task_status.stat, status);
 
 		/* Wake up whatever process was waiting for this
 		 * request to complete.
@@ -850,11 +850,11 @@ static void isci_task_save_for_upper_layer_completion(
 	case isci_perform_error_io_completion:
 		/* Use sas_task_abort */
 		dev_warn(&host->pdev->dev,
-			 "%s: Error - task = %p, response=%d, status=%d\n",
+			 "%s: Error - task = %p, response=%d (%d), status=%d (%d)\n",
 			 __func__,
 			 task,
-			 response,
-			 status);
+			 task->task_status.resp, response,
+			 task->task_status.stat, status);
 		/* Add to the aborted list. */
 		list_add(&request->completed_node,
 			 &host->requests_to_errorback);
@@ -862,11 +862,11 @@ static void isci_task_save_for_upper_layer_completion(
 
 	default:
 		dev_warn(&host->pdev->dev,
-			 "%s: Unknown - task = %p, response=%d, status=%d\n",
+			 "%s: Unknown - task = %p, response=%d (%d), status=%d (%d)\n",
 			 __func__,
 			 task,
-			 response,
-			 status);
+			 task->task_status.resp, response,
+			 task->task_status.stat, status);
 
 		/* Add to the error to libsas list. */
 		list_add(&request->completed_node,
@@ -1165,6 +1165,10 @@ void isci_request_io_request_complete(
 			task->task_state_flags |= SAS_TASK_NEED_DEV_RESET;
 			spin_unlock_irqrestore(&task->task_state_lock, task_flags);
 
+			/* Fail the I/O. */
+			response = SAS_TASK_UNDELIVERED;
+			status = SAM_STAT_TASK_ABORTED;
+
 			complete_to_host = isci_perform_error_io_completion;
 			request->complete_in_target = false;
 			break;

commit 1fad9e934a43407c1ba397b1b6b8882aa8a2cafd
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Fri Mar 4 14:06:46 2011 -0800

    isci: save the i/o tag outside the scic request structure.
    
    The pointer to the core representation of a request is marked NULL at
    completion, but we need to save the i/o tag for task management.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Jacek Danecki <Jacek.Danecki@intel.com>
    [revise changelog]
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 6cd80bbdae15..f19a952754b9 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -463,6 +463,12 @@ int isci_request_execute(
 				 */
 				status = SCI_SUCCESS;
 			}
+			else
+				/* Save the tag for possible task mgmt later. */
+				request->io_tag = scic_io_request_get_io_tag(
+						     request->sci_request_handle);
+
+
 		} else
 			dev_warn(&isci_host->pdev->dev,
 				 "%s: failed request start\n",

commit ec6c9638b0d0537430f78a3e20503b5e68a537b6
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Fri Mar 4 14:06:44 2011 -0800

    isci: Any reset indicated on an I/O completion escalates it to the error path.
    
    If there is a pending device reset, the I/O is used to accomplish the reset by setting the
    RESET bit in the task status, and then putting the task into the error handler
    path using sas abort task.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Jacek Danecki <Jacek.Danecki@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index c88e270b2b40..6cd80bbdae15 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -790,9 +790,9 @@ static void isci_task_save_for_upper_layer_completion(
 {
 	struct sas_task *task = isci_request_access_task(request);
 
-	isci_task_set_completion_status(task, response, status,
-					 task_notification_selection);
-
+	task_notification_selection
+		= isci_task_set_completion_status(task, response, status,
+						  task_notification_selection);
 
 	/* Tasks aborted specifically by a call to the lldd_abort_task
 	 * function should not be completed to the host in the regular path.
@@ -811,6 +811,9 @@ static void isci_task_save_for_upper_layer_completion(
 		/* Add to the completed list. */
 		list_add(&request->completed_node,
 			 &host->requests_to_complete);
+
+		/* Take the request off the device's pending request list. */
+		list_del_init(&request->dev_node);
 		break;
 
 	case isci_perform_aborted_io_completion:

commit a5fde225364df30507ba1a5aafeec85e595000d3
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Fri Mar 4 14:06:42 2011 -0800

    isci: fix completion / abort path.
    
    Corrected use of the request state_lock in the completion callback.
    
    In the case where an abort (or reset) thread is trying to terminate an
    I/O request, it sets the request state to "aborting" (or "terminating")
    if the state is still "starting".  One of the bugs was to never set the
    state to "completed".  Another was to not correctly recognize the
    situation where the I/O had completed but the sas_task was still pending
    callback to task_done - this was typically a problem in the LUN and
    device reset cases.
    
    It is now possible that we leave isci_task_abort_task() with
    request->io_request_completion pointing to localy allocated
    aborted_io_completion struct. It may result in a system crash.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Maciej Trela <Maciej.Trela@intel.com>
    Signed-off-by: Jacek Danecki <Jacek.Danecki@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 8039f1c72f72..c88e270b2b40 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -814,9 +814,8 @@ static void isci_task_save_for_upper_layer_completion(
 		break;
 
 	case isci_perform_aborted_io_completion:
-		/*
-		 * No notification because this request is already
-		 * in the abort path.
+		/* No notification to libsas because this request is
+		 * already in the abort path.
 		 */
 		dev_warn(&host->pdev->dev,
 			 "%s: Aborted - task = %p, response=%d, status=%d\n",
@@ -824,6 +823,19 @@ static void isci_task_save_for_upper_layer_completion(
 			 task,
 			 response,
 			 status);
+
+		/* Wake up whatever process was waiting for this
+		 * request to complete.
+		 */
+		WARN_ON(request->io_request_completion == NULL);
+
+		if (request->io_request_completion != NULL) {
+
+			/* Signal whoever is waiting that this
+			* request is complete.
+			*/
+			complete(request->io_request_completion);
+		}
 		break;
 
 	case isci_perform_error_io_completion:
@@ -847,7 +859,7 @@ static void isci_task_save_for_upper_layer_completion(
 			 response,
 			 status);
 
-		/* Add to the aborted list. */
+		/* Add to the error to libsas list. */
 		list_add(&request->completed_node,
 			 &host->requests_to_errorback);
 		break;
@@ -873,8 +885,6 @@ void isci_request_io_request_complete(
 	struct ssp_response_iu *resp_iu;
 	void *resp_buf;
 	unsigned long task_flags;
-	unsigned long state_flags;
-	struct completion *io_request_completion;
 	struct isci_remote_device *isci_device   = request->isci_device;
 	enum service_response response       = SAS_TASK_UNDELIVERED;
 	enum exec_status status         = SAS_ABORTED_TASK;
@@ -891,9 +901,8 @@ void isci_request_io_request_complete(
 		task->data_dir,
 		completion_status);
 
-	spin_lock_irqsave(&request->state_lock, state_flags);
+	spin_lock(&request->state_lock);
 	request_status = isci_request_get_state(request);
-	spin_unlock_irqrestore(&request->state_lock, state_flags);
 
 	/* Decode the request status.  Note that if the request has been
 	 * aborted by a task management function, we don't care
@@ -928,6 +937,8 @@ void isci_request_io_request_complete(
 
 		complete_to_host = isci_perform_aborted_io_completion;
 		/* This was an aborted request. */
+
+		spin_unlock(&request->state_lock);
 		break;
 
 	case aborting:
@@ -955,6 +966,8 @@ void isci_request_io_request_complete(
 		complete_to_host = isci_perform_aborted_io_completion;
 
 		/* This was an aborted request. */
+
+		spin_unlock(&request->state_lock);
 		break;
 
 	case terminating:
@@ -977,13 +990,20 @@ void isci_request_io_request_complete(
 		else
 			status = SAS_ABORTED_TASK;
 
-		complete_to_host = isci_perform_normal_io_completion;
+		complete_to_host = isci_perform_aborted_io_completion;
 
 		/* This was a terminated request. */
+
+		spin_unlock(&request->state_lock);
 		break;
 
 	default:
 
+		/* The request is done from an SCU HW perspective. */
+		request->status = completed;
+
+		spin_unlock(&request->state_lock);
+
 		/* This is an active request being completed from the core. */
 		switch (completion_status) {
 
@@ -1185,20 +1205,6 @@ void isci_request_io_request_complete(
 	 */
 	request->sci_request_handle = NULL;
 
-	/* Save possible completion ptr. */
-	io_request_completion = request->io_request_completion;
-
-	if (io_request_completion) {
-
-		/* This is inherantly a regular I/O request,
-		 * since we are currently in the regular
-		 * I/O completion callback function.
-		 * Signal whoever is waiting that this
-		 * request is complete.
-		 */
-		complete(io_request_completion);
-	}
-
 	isci_host_can_dequeue(isci_host, 1);
 }
 

commit 11b00c194cfbd0eb0d90f32c096508b2bb8be6ec
Author: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
Date:   Fri Mar 4 14:06:40 2011 -0800

    isci: Changes in isci_host_completion_routine
    
    Changes to move management of the reqs_in_process entry for the request here.
    Made changes to note when the task is already in the abort path and
    cannot be completed through callbacks.
    
    Signed-off-by: Jeff Skirvin <jeffrey.d.skirvin@intel.com>
    Signed-off-by: Jacek Danecki <Jacek.Danecki@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 6b0863e73f22..8039f1c72f72 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -836,7 +836,7 @@ static void isci_task_save_for_upper_layer_completion(
 			 status);
 		/* Add to the aborted list. */
 		list_add(&request->completed_node,
-			 &host->requests_to_abort);
+			 &host->requests_to_errorback);
 		break;
 
 	default:
@@ -849,7 +849,7 @@ static void isci_task_save_for_upper_layer_completion(
 
 		/* Add to the aborted list. */
 		list_add(&request->completed_node,
-			 &host->requests_to_abort);
+			 &host->requests_to_errorback);
 		break;
 	}
 }
@@ -1185,14 +1185,6 @@ void isci_request_io_request_complete(
 	 */
 	request->sci_request_handle = NULL;
 
-	/* Only remove the request from the remote device list
-	 * of pending requests if we have not requested error
-	 * handling on this request.
-	 */
-	if (complete_to_host != isci_perform_error_io_completion)
-		list_del_init(&request->dev_node);
-
-
 	/* Save possible completion ptr. */
 	io_request_completion = request->io_request_completion;
 

commit 3a97eec6d7876c541950e23811efd40e0bcd04a0
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Mar 4 11:51:43 2011 -0800

    isci: remove sci_device_handle
    
    It belies the fact that isci_remote_device and scic_sds_remote_device
    are one in same object with the same lifetime rules.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index 81a77335fdb3..6b0863e73f22 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -179,8 +179,7 @@ static enum sci_status isci_io_request_build(
 	struct smp_discover_response_protocols dev_protocols;
 	enum sci_status status = SCI_SUCCESS;
 	struct sas_task *task = isci_request_access_task(request);
-	struct scic_sds_remote_device *sci_device =
-		isci_device->sci_device_handle;
+	struct scic_sds_remote_device *sci_device = to_sci_dev(isci_device);
 
 	dev_dbg(&isci_host->pdev->dev,
 		"%s: isci_device = 0x%p; request = %p, "
@@ -408,7 +407,7 @@ int isci_request_execute(
 	unsigned long flags;
 
 	isci_device = isci_dev_from_domain_dev(task->dev);
-	sci_device = isci_device->sci_device_handle;
+	sci_device = to_sci_dev(isci_device);
 
 	/* do common allocation and init of request object. */
 	ret = isci_request_alloc_io(
@@ -1177,7 +1176,7 @@ void isci_request_io_request_complete(
 	/* complete the io request to the core. */
 	scic_controller_complete_io(
 		isci_host->core_controller,
-		isci_device->sci_device_handle,
+		to_sci_dev(isci_device),
 		request->sci_request_handle
 		);
 	/* NULL the request handle so it cannot be completed or

commit 83f5eeef59581faed6f002432bafe24da8cbf401
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Fri Feb 18 09:25:15 2011 -0800

    isci: debug fixes
    
    Some of the chain walks to get back to our dev are invalid.
    
    isci_remote_device_change_state: delete rather than adding conditional deref
    chain walking
    isci_request_change_state: fix, it was being called too early
    isci_request_ssp_io_request_get_lun: fix compile breakage hidden by ifdef DEBUG
    
    Signed-off-by: Maciej Trela <maciej.trela@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index f7ba047d64ce..81a77335fdb3 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -285,7 +285,6 @@ static int isci_request_alloc_core(
 
 	/* initialize the request object.	*/
 	spin_lock_init(&request->state_lock);
-	isci_request_change_state(request, allocated);
 	request->sci_request_mem_ptr = ((u8 *)request) +
 				       sizeof(struct isci_request);
 	request->request_daddr = handle;
@@ -302,6 +301,7 @@ static int isci_request_alloc_core(
 	INIT_LIST_HEAD(&request->dev_node);
 
 	*isci_request = request;
+	isci_request_change_state(request, allocated);
 
 	return ret;
 }
@@ -1389,8 +1389,8 @@ u32 isci_request_ssp_io_request_get_lun(
 
 	for (i = 0; i < 8; i++)
 		dev_dbg(&request->isci_host->pdev->dev,
-			"%s: request->task->ssp_task.LUN[%d] = %x\n",
-			__func__, i, request->task->ssp_task.LUN[i]);
+			"%s: task->ssp_task.LUN[%d] = %x\n",
+			__func__, i, task->ssp_task.LUN[i]);
 
 #endif
 

commit 82d29928c1c1c6a6605895f8240a9943394244d7
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Feb 8 17:53:10 2011 -0800

    isci: kill SCI_IO_REQUEST_DATA_DIRECTION
    
    It's an unnecessary typedef that mirrors the kernel's enum
    dma_data_direction.
    
    Also cleanup some long variable names along the way.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
index e564121b6726..f7ba047d64ce 100644
--- a/drivers/scsi/isci/request.c
+++ b/drivers/scsi/isci/request.c
@@ -1237,44 +1237,12 @@ u32 isci_request_io_request_get_transfer_length(struct isci_request *request)
  *
  * data direction for specified request.
  */
-SCI_IO_REQUEST_DATA_DIRECTION isci_request_io_request_get_data_direction(
+enum dma_data_direction isci_request_io_request_get_data_direction(
 	struct isci_request *request)
 {
 	struct sas_task *task = isci_request_access_task(request);
-	SCI_IO_REQUEST_DATA_DIRECTION ret;
 
-	switch (task->data_dir) {
-
-	case DMA_FROM_DEVICE:
-		ret = SCI_IO_REQUEST_DATA_IN;
-		dev_dbg(&request->isci_host->pdev->dev,
-			"%s: request=%p, FROM_DEVICE\n",
-			__func__,
-			request);
-		break;
-
-	case DMA_TO_DEVICE:
-		ret = SCI_IO_REQUEST_DATA_OUT;
-		dev_dbg(&request->isci_host->pdev->dev,
-			"%s: request=%p, TO_DEVICE\n",
-			__func__,
-			request);
-		break;
-
-	case DMA_BIDIRECTIONAL:
-	case DMA_NONE:
-	default:
-		ret = SCI_IO_REQUEST_NO_DATA;
-		dev_dbg(&request->isci_host->pdev->dev,
-			"%s: request=%p, unhandled direction case, "
-			"data_dir=%d\n",
-			__func__,
-			request,
-			task->data_dir);
-		break;
-
-	}
-	return ret;
+	return task->data_dir;
 }
 
 /**

commit 6f231dda68080759f1aed3769896e94c73099f0f
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sat Jul 2 22:56:22 2011 -0700

    isci: Intel(R) C600 Series Chipset Storage Control Unit Driver
    
    Support for the up to 2x4-port 6Gb/s SAS controllers embedded in the
    chipset.
    
    This is a snapshot of the first publicly available version of the driver,
    commit 4c1db2d0 in the 'historical' branch.
    
       git://git.kernel.org/pub/scm/linux/kernel/git/djbw/isci.git historical
    
    Signed-off-by: Maciej Trela <maciej.trela@intel.com>
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    Signed-off-by: Edmund Nadolski <edmund.nadolski@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/drivers/scsi/isci/request.c b/drivers/scsi/isci/request.c
new file mode 100644
index 000000000000..e564121b6726
--- /dev/null
+++ b/drivers/scsi/isci/request.c
@@ -0,0 +1,1472 @@
+/*
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ * The full GNU General Public License is included in this distribution
+ * in the file called LICENSE.GPL.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "isci.h"
+#include "scic_remote_device.h"
+#include "scic_io_request.h"
+#include "scic_task_request.h"
+#include "scic_port.h"
+#include "task.h"
+#include "request.h"
+#include "sata.h"
+#include "scu_completion_codes.h"
+
+
+static enum sci_status isci_request_ssp_request_construct(
+	struct isci_request *request)
+{
+	enum sci_status status;
+
+	dev_dbg(&request->isci_host->pdev->dev,
+		"%s: request = %p\n",
+		__func__,
+		request);
+	status = scic_io_request_construct_basic_ssp(
+		request->sci_request_handle
+		);
+	return status;
+}
+
+static enum sci_status isci_request_stp_request_construct(
+	struct isci_request *request)
+{
+	struct sas_task *task = isci_request_access_task(request);
+	enum sci_status status;
+	struct host_to_dev_fis *register_fis;
+
+	dev_dbg(&request->isci_host->pdev->dev,
+		"%s: request = %p\n",
+		__func__,
+		request);
+
+	/* Get the host_to_dev_fis from the core and copy
+	 * the fis from the task into it.
+	 */
+	register_fis = isci_sata_task_to_fis_copy(task);
+
+	status = scic_io_request_construct_basic_sata(
+		request->sci_request_handle
+		);
+
+	/* Set the ncq tag in the fis, from the queue
+	 * command in the task.
+	 */
+	if (isci_sata_is_task_ncq(task)) {
+
+		isci_sata_set_ncq_tag(
+			register_fis,
+			task
+			);
+	}
+
+	return status;
+}
+
+/**
+ * isci_smp_request_build() - This function builds the smp request object.
+ * @isci_host: This parameter specifies the ISCI host object
+ * @request: This parameter points to the isci_request object allocated in the
+ *    request construct function.
+ * @sci_device: This parameter is the handle for the sci core's remote device
+ *    object that is the destination for this request.
+ *
+ * SCI_SUCCESS on successfull completion, or specific failure code.
+ */
+static enum sci_status isci_smp_request_build(
+	struct isci_request *request)
+{
+	enum sci_status status = SCI_FAILURE;
+	struct sas_task *task = isci_request_access_task(request);
+
+	void *command_iu_address =
+		scic_io_request_get_command_iu_address(
+			request->sci_request_handle
+			);
+
+	dev_dbg(&request->isci_host->pdev->dev,
+		"%s: request = %p\n",
+		__func__,
+		request);
+	dev_dbg(&request->isci_host->pdev->dev,
+		"%s: smp_req len = %d\n",
+		__func__,
+		task->smp_task.smp_req.length);
+
+	/* copy the smp_command to the address; */
+	sg_copy_to_buffer(&task->smp_task.smp_req, 1,
+			  (char *)command_iu_address,
+			  sizeof(struct smp_request)
+			  );
+
+	status = scic_io_request_construct_smp(request->sci_request_handle);
+	if (status != SCI_SUCCESS)
+		dev_warn(&request->isci_host->pdev->dev,
+			 "%s: scic_io_request_construct_smp failed with "
+			 "status = %d\n",
+			 __func__,
+			 status);
+
+	return status;
+}
+
+/**
+ * isci_io_request_build() - This function builds the io request object.
+ * @isci_host: This parameter specifies the ISCI host object
+ * @request: This parameter points to the isci_request object allocated in the
+ *    request construct function.
+ * @sci_device: This parameter is the handle for the sci core's remote device
+ *    object that is the destination for this request.
+ *
+ * SCI_SUCCESS on successfull completion, or specific failure code.
+ */
+static enum sci_status isci_io_request_build(
+	struct isci_host *isci_host,
+	struct isci_request *request,
+	struct isci_remote_device *isci_device)
+{
+	struct smp_discover_response_protocols dev_protocols;
+	enum sci_status status = SCI_SUCCESS;
+	struct sas_task *task = isci_request_access_task(request);
+	struct scic_sds_remote_device *sci_device =
+		isci_device->sci_device_handle;
+
+	dev_dbg(&isci_host->pdev->dev,
+		"%s: isci_device = 0x%p; request = %p, "
+		"num_scatter = %d\n",
+		__func__,
+		isci_device,
+		request,
+		task->num_scatter);
+
+	/* map the sgl addresses, if present.
+	 * libata does the mapping for sata devices
+	 * before we get the request.
+	 */
+	if (task->num_scatter &&
+	    !sas_protocol_ata(task->task_proto) &&
+	    !(SAS_PROTOCOL_SMP & task->task_proto)) {
+
+		request->num_sg_entries = dma_map_sg(
+			&isci_host->pdev->dev,
+			task->scatter,
+			task->num_scatter,
+			task->data_dir
+			);
+
+		if (request->num_sg_entries == 0)
+			return SCI_FAILURE_INSUFFICIENT_RESOURCES;
+	}
+
+	/* build the common request object. For now,
+	 * we will let the core allocate the IO tag.
+	 */
+	status = scic_io_request_construct(
+		isci_host->core_controller,
+		sci_device,
+		SCI_CONTROLLER_INVALID_IO_TAG,
+		request,
+		request->sci_request_mem_ptr,
+		(struct scic_sds_request **)&request->sci_request_handle
+		);
+
+	if (status != SCI_SUCCESS) {
+		dev_warn(&isci_host->pdev->dev,
+			 "%s: failed request construct\n",
+			 __func__);
+		return SCI_FAILURE;
+	}
+
+	sci_object_set_association(request->sci_request_handle, request);
+
+	/* Determine protocol and call the appropriate basic constructor */
+	scic_remote_device_get_protocols(sci_device, &dev_protocols);
+	if (dev_protocols.u.bits.attached_ssp_target)
+		status = isci_request_ssp_request_construct(request);
+	else if (dev_protocols.u.bits.attached_stp_target)
+		status = isci_request_stp_request_construct(request);
+	else if (dev_protocols.u.bits.attached_smp_target)
+		status = isci_smp_request_build(request);
+	else {
+		dev_warn(&isci_host->pdev->dev,
+			 "%s: unknown protocol\n", __func__);
+		return SCI_FAILURE;
+	}
+
+	return SCI_SUCCESS;
+}
+
+
+/**
+ * isci_request_alloc_core() - This function gets the request object from the
+ *    isci_host dma cache.
+ * @isci_host: This parameter specifies the ISCI host object
+ * @isci_request: This parameter will contain the pointer to the new
+ *    isci_request object.
+ * @isci_device: This parameter is the pointer to the isci remote device object
+ *    that is the destination for this request.
+ * @gfp_flags: This parameter specifies the os allocation flags.
+ *
+ * SCI_SUCCESS on successfull completion, or specific failure code.
+ */
+static int isci_request_alloc_core(
+	struct isci_host *isci_host,
+	struct isci_request **isci_request,
+	struct isci_remote_device *isci_device,
+	gfp_t gfp_flags)
+{
+	int ret = 0;
+	dma_addr_t handle;
+	struct isci_request *request;
+
+
+	/* get pointer to dma memory. This actually points
+	 * to both the isci_remote_device object and the
+	 * sci object. The isci object is at the beginning
+	 * of the memory allocated here.
+	 */
+	request = dma_pool_alloc(isci_host->dma_pool, gfp_flags, &handle);
+	if (!request) {
+		dev_warn(&isci_host->pdev->dev,
+			 "%s: dma_pool_alloc returned NULL\n", __func__);
+		return -ENOMEM;
+	}
+
+	/* initialize the request object.	*/
+	spin_lock_init(&request->state_lock);
+	isci_request_change_state(request, allocated);
+	request->sci_request_mem_ptr = ((u8 *)request) +
+				       sizeof(struct isci_request);
+	request->request_daddr = handle;
+	request->isci_host = isci_host;
+	request->isci_device = isci_device;
+	request->io_request_completion = NULL;
+
+	request->request_alloc_size = isci_host->dma_pool_alloc_size;
+	request->num_sg_entries = 0;
+
+	request->complete_in_target = false;
+
+	INIT_LIST_HEAD(&request->completed_node);
+	INIT_LIST_HEAD(&request->dev_node);
+
+	*isci_request = request;
+
+	return ret;
+}
+
+static int isci_request_alloc_io(
+	struct isci_host *isci_host,
+	struct sas_task *task,
+	struct isci_request **isci_request,
+	struct isci_remote_device *isci_device,
+	gfp_t gfp_flags)
+{
+	int retval = isci_request_alloc_core(isci_host, isci_request,
+					     isci_device, gfp_flags);
+
+	if (!retval) {
+		(*isci_request)->ttype_ptr.io_task_ptr = task;
+		(*isci_request)->ttype                 = io_task;
+
+		task->lldd_task = *isci_request;
+	}
+	return retval;
+}
+
+/**
+ * isci_request_alloc_tmf() - This function gets the request object from the
+ *    isci_host dma cache and initializes the relevant fields as a sas_task.
+ * @isci_host: This parameter specifies the ISCI host object
+ * @sas_task: This parameter is the task struct from the upper layer driver.
+ * @isci_request: This parameter will contain the pointer to the new
+ *    isci_request object.
+ * @isci_device: This parameter is the pointer to the isci remote device object
+ *    that is the destination for this request.
+ * @gfp_flags: This parameter specifies the os allocation flags.
+ *
+ * SCI_SUCCESS on successfull completion, or specific failure code.
+ */
+int isci_request_alloc_tmf(
+	struct isci_host *isci_host,
+	struct isci_tmf *isci_tmf,
+	struct isci_request **isci_request,
+	struct isci_remote_device *isci_device,
+	gfp_t gfp_flags)
+{
+	int retval = isci_request_alloc_core(isci_host, isci_request,
+					     isci_device, gfp_flags);
+
+	if (!retval) {
+
+		(*isci_request)->ttype_ptr.tmf_task_ptr = isci_tmf;
+		(*isci_request)->ttype = tmf_task;
+	}
+	return retval;
+}
+
+/**
+ * isci_request_signal_device_reset() - This function will set the "device
+ *    needs target reset" flag in the given sas_tasks' task_state_flags, and
+ *    then cause the task to be added into the SCSI error handler queue which
+ *    will eventually be escalated to a target reset.
+ *
+ *
+ */
+static void isci_request_signal_device_reset(
+	struct isci_request *isci_request)
+{
+	unsigned long flags;
+	struct sas_task *task = isci_request_access_task(isci_request);
+
+	dev_dbg(&isci_request->isci_host->pdev->dev,
+		"%s: request=%p, task=%p\n", __func__, isci_request, task);
+
+	spin_lock_irqsave(&task->task_state_lock, flags);
+	task->task_state_flags |= SAS_TASK_NEED_DEV_RESET;
+	spin_unlock_irqrestore(&task->task_state_lock, flags);
+
+	/* Cause this task to be scheduled in the SCSI error handler
+	 * thread.
+	 */
+	sas_task_abort(task);
+}
+
+/**
+ * isci_request_execute() - This function allocates the isci_request object,
+ *    all fills in some common fields.
+ * @isci_host: This parameter specifies the ISCI host object
+ * @sas_task: This parameter is the task struct from the upper layer driver.
+ * @isci_request: This parameter will contain the pointer to the new
+ *    isci_request object.
+ * @gfp_flags: This parameter specifies the os allocation flags.
+ *
+ * SCI_SUCCESS on successfull completion, or specific failure code.
+ */
+int isci_request_execute(
+	struct isci_host *isci_host,
+	struct sas_task *task,
+	struct isci_request **isci_request,
+	gfp_t gfp_flags)
+{
+	int ret = 0;
+	struct scic_sds_remote_device *sci_device;
+	enum sci_status status = SCI_FAILURE_UNSUPPORTED_PROTOCOL;
+	struct isci_remote_device *isci_device;
+	struct isci_request *request;
+	unsigned long flags;
+
+	isci_device = isci_dev_from_domain_dev(task->dev);
+	sci_device = isci_device->sci_device_handle;
+
+	/* do common allocation and init of request object. */
+	ret = isci_request_alloc_io(
+		isci_host,
+		task,
+		&request,
+		isci_device,
+		gfp_flags
+		);
+
+	if (ret)
+		goto out;
+
+	status = isci_io_request_build(isci_host, request, isci_device);
+	if (status == SCI_SUCCESS) {
+
+		spin_lock_irqsave(&isci_host->scic_lock, flags);
+
+		/* send the request, let the core assign the IO TAG.	*/
+		status = scic_controller_start_io(
+			isci_host->core_controller,
+			sci_device,
+			request->sci_request_handle,
+			SCI_CONTROLLER_INVALID_IO_TAG
+			);
+
+		if (status == SCI_SUCCESS ||
+		    status == SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
+
+			/* Either I/O started OK, or the core has signaled that
+			 * the device needs a target reset.
+			 *
+			 * In either case, hold onto the I/O for later.
+			 *
+			 * Update it's status and add it to the list in the
+			 * remote device object.
+			 */
+			isci_request_change_state(request, started);
+			list_add(&request->dev_node,
+				 &isci_device->reqs_in_process);
+
+			if (status ==
+				SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
+				/* Signal libsas that we need the SCSI error
+				 * handler thread to work on this I/O and that
+				 * we want a device reset.
+				 */
+				isci_request_signal_device_reset(request);
+
+				/* Change the status, since we are holding
+				 * the I/O until it is managed by the SCSI
+				 * error handler.
+				 */
+				status = SCI_SUCCESS;
+			}
+		} else
+			dev_warn(&isci_host->pdev->dev,
+				 "%s: failed request start\n",
+				 __func__);
+
+		spin_unlock_irqrestore(&isci_host->scic_lock, flags);
+
+	} else
+		dev_warn(&isci_host->pdev->dev,
+			 "%s: request_construct failed - status = 0x%x\n",
+			 __func__,
+			 status);
+
+ out:
+	if (status != SCI_SUCCESS) {
+
+		/* release dma memory on failure. */
+		isci_request_free(isci_host, request);
+		request = NULL;
+		ret = SCI_FAILURE;
+	}
+
+	*isci_request = request;
+	return ret;
+}
+
+
+/**
+ * isci_request_process_response_iu() - This function sets the status and
+ *    response iu, in the task struct, from the request object for the upper
+ *    layer driver.
+ * @sas_task: This parameter is the task struct from the upper layer driver.
+ * @resp_iu: This parameter points to the response iu of the completed request.
+ * @dev: This parameter specifies the linux device struct.
+ *
+ * none.
+ */
+static void isci_request_process_response_iu(
+	struct sas_task *task,
+	struct ssp_response_iu *resp_iu,
+	struct device *dev)
+{
+	dev_dbg(dev,
+		"%s: resp_iu = %p "
+		"resp_iu->status = 0x%x,\nresp_iu->datapres = %d "
+		"resp_iu->response_data_len = %x, "
+		"resp_iu->sense_data_len = %x\nrepsonse data: ",
+		__func__,
+		resp_iu,
+		resp_iu->status,
+		resp_iu->datapres,
+		resp_iu->response_data_len,
+		resp_iu->sense_data_len);
+
+	task->task_status.stat = resp_iu->status;
+
+	/* libsas updates the task status fields based on the response iu. */
+	sas_ssp_task_response(dev, task, resp_iu);
+}
+
+/**
+ * isci_request_set_open_reject_status() - This function prepares the I/O
+ *    completion for OPEN_REJECT conditions.
+ * @request: This parameter is the completed isci_request object.
+ * @response_ptr: This parameter specifies the service response for the I/O.
+ * @status_ptr: This parameter specifies the exec status for the I/O.
+ * @complete_to_host_ptr: This parameter specifies the action to be taken by
+ *    the LLDD with respect to completing this request or forcing an abort
+ *    condition on the I/O.
+ * @open_rej_reason: This parameter specifies the encoded reason for the
+ *    abandon-class reject.
+ *
+ * none.
+ */
+static void isci_request_set_open_reject_status(
+	struct isci_request *request,
+	struct sas_task *task,
+	enum service_response *response_ptr,
+	enum exec_status *status_ptr,
+	enum isci_completion_selection *complete_to_host_ptr,
+	enum sas_open_rej_reason open_rej_reason)
+{
+	/* Task in the target is done. */
+	request->complete_in_target       = true;
+	*response_ptr                     = SAS_TASK_UNDELIVERED;
+	*status_ptr                       = SAS_OPEN_REJECT;
+	*complete_to_host_ptr             = isci_perform_normal_io_completion;
+	task->task_status.open_rej_reason = open_rej_reason;
+}
+
+/**
+ * isci_request_handle_controller_specific_errors() - This function decodes
+ *    controller-specific I/O completion error conditions.
+ * @request: This parameter is the completed isci_request object.
+ * @response_ptr: This parameter specifies the service response for the I/O.
+ * @status_ptr: This parameter specifies the exec status for the I/O.
+ * @complete_to_host_ptr: This parameter specifies the action to be taken by
+ *    the LLDD with respect to completing this request or forcing an abort
+ *    condition on the I/O.
+ *
+ * none.
+ */
+static void isci_request_handle_controller_specific_errors(
+	struct isci_remote_device *isci_device,
+	struct isci_request *request,
+	struct sas_task *task,
+	enum service_response *response_ptr,
+	enum exec_status *status_ptr,
+	enum isci_completion_selection *complete_to_host_ptr)
+{
+	unsigned int cstatus;
+
+	cstatus = scic_request_get_controller_status(
+		request->sci_request_handle
+		);
+
+	dev_dbg(&request->isci_host->pdev->dev,
+		"%s: %p SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR "
+		"- controller status = 0x%x\n",
+		__func__, request, cstatus);
+
+	/* Decode the controller-specific errors; most
+	 * important is to recognize those conditions in which
+	 * the target may still have a task outstanding that
+	 * must be aborted.
+	 *
+	 * Note that there are SCU completion codes being
+	 * named in the decode below for which SCIC has already
+	 * done work to handle them in a way other than as
+	 * a controller-specific completion code; these are left
+	 * in the decode below for completeness sake.
+	 */
+	switch (cstatus) {
+	case SCU_TASK_DONE_DMASETUP_DIRERR:
+	/* Also SCU_TASK_DONE_SMP_FRM_TYPE_ERR: */
+	case SCU_TASK_DONE_XFERCNT_ERR:
+		/* Also SCU_TASK_DONE_SMP_UFI_ERR: */
+		if (task->task_proto == SAS_PROTOCOL_SMP) {
+			/* SCU_TASK_DONE_SMP_UFI_ERR == Task Done. */
+			*response_ptr = SAS_TASK_COMPLETE;
+
+			/* See if the device has been/is being stopped. Note
+			 * that we ignore the quiesce state, since we are
+			 * concerned about the actual device state.
+			 */
+			if ((isci_device->status == isci_stopping) ||
+			    (isci_device->status == isci_stopped))
+				*status_ptr = SAS_DEVICE_UNKNOWN;
+			else
+				*status_ptr = SAS_ABORTED_TASK;
+
+			request->complete_in_target = true;
+
+			*complete_to_host_ptr =
+				isci_perform_normal_io_completion;
+		} else {
+			/* Task in the target is not done. */
+			*response_ptr = SAS_TASK_UNDELIVERED;
+
+			if ((isci_device->status == isci_stopping) ||
+			    (isci_device->status == isci_stopped))
+				*status_ptr = SAS_DEVICE_UNKNOWN;
+			else
+				*status_ptr = SAM_STAT_TASK_ABORTED;
+
+			request->complete_in_target = false;
+
+			*complete_to_host_ptr =
+				isci_perform_error_io_completion;
+		}
+
+		break;
+
+	case SCU_TASK_DONE_CRC_ERR:
+	case SCU_TASK_DONE_NAK_CMD_ERR:
+	case SCU_TASK_DONE_EXCESS_DATA:
+	case SCU_TASK_DONE_UNEXP_FIS:
+	/* Also SCU_TASK_DONE_UNEXP_RESP: */
+	case SCU_TASK_DONE_VIIT_ENTRY_NV:       /* TODO - conditions? */
+	case SCU_TASK_DONE_IIT_ENTRY_NV:        /* TODO - conditions? */
+	case SCU_TASK_DONE_RNCNV_OUTBOUND:      /* TODO - conditions? */
+		/* These are conditions in which the target
+		 * has completed the task, so that no cleanup
+		 * is necessary.
+		 */
+		*response_ptr = SAS_TASK_COMPLETE;
+
+		/* See if the device has been/is being stopped. Note
+		 * that we ignore the quiesce state, since we are
+		 * concerned about the actual device state.
+		 */
+		if ((isci_device->status == isci_stopping) ||
+		    (isci_device->status == isci_stopped))
+			*status_ptr = SAS_DEVICE_UNKNOWN;
+		else
+			*status_ptr = SAS_ABORTED_TASK;
+
+		request->complete_in_target = true;
+
+		*complete_to_host_ptr = isci_perform_normal_io_completion;
+		break;
+
+
+	/* Note that the only open reject completion codes seen here will be
+	 * abandon-class codes; all others are automatically retried in the SCU.
+	 */
+	case SCU_TASK_OPEN_REJECT_WRONG_DESTINATION:
+
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_WRONG_DEST);
+		break;
+
+	case SCU_TASK_OPEN_REJECT_ZONE_VIOLATION:
+
+		/* Note - the return of AB0 will change when
+		 * libsas implements detection of zone violations.
+		 */
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_RESV_AB0);
+		break;
+
+	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_1:
+
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_RESV_AB1);
+		break;
+
+	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_2:
+
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_RESV_AB2);
+		break;
+
+	case SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_3:
+
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_RESV_AB3);
+		break;
+
+	case SCU_TASK_OPEN_REJECT_BAD_DESTINATION:
+
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_BAD_DEST);
+		break;
+
+	case SCU_TASK_OPEN_REJECT_STP_RESOURCES_BUSY:
+
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_STP_NORES);
+		break;
+
+	case SCU_TASK_OPEN_REJECT_PROTOCOL_NOT_SUPPORTED:
+
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_EPROTO);
+		break;
+
+	case SCU_TASK_OPEN_REJECT_CONNECTION_RATE_NOT_SUPPORTED:
+
+		isci_request_set_open_reject_status(
+			request, task, response_ptr, status_ptr,
+			complete_to_host_ptr, SAS_OREJ_CONN_RATE);
+		break;
+
+	case SCU_TASK_DONE_LL_R_ERR:
+	/* Also SCU_TASK_DONE_ACK_NAK_TO: */
+	case SCU_TASK_DONE_LL_PERR:
+	case SCU_TASK_DONE_LL_SY_TERM:
+	/* Also SCU_TASK_DONE_NAK_ERR:*/
+	case SCU_TASK_DONE_LL_LF_TERM:
+	/* Also SCU_TASK_DONE_DATA_LEN_ERR: */
+	case SCU_TASK_DONE_LL_ABORT_ERR:
+	case SCU_TASK_DONE_SEQ_INV_TYPE:
+	/* Also SCU_TASK_DONE_UNEXP_XR: */
+	case SCU_TASK_DONE_XR_IU_LEN_ERR:
+	case SCU_TASK_DONE_INV_FIS_LEN:
+	/* Also SCU_TASK_DONE_XR_WD_LEN: */
+	case SCU_TASK_DONE_SDMA_ERR:
+	case SCU_TASK_DONE_OFFSET_ERR:
+	case SCU_TASK_DONE_MAX_PLD_ERR:
+	case SCU_TASK_DONE_LF_ERR:
+	case SCU_TASK_DONE_SMP_RESP_TO_ERR:  /* Escalate to dev reset? */
+	case SCU_TASK_DONE_SMP_LL_RX_ERR:
+	case SCU_TASK_DONE_UNEXP_DATA:
+	case SCU_TASK_DONE_UNEXP_SDBFIS:
+	case SCU_TASK_DONE_REG_ERR:
+	case SCU_TASK_DONE_SDB_ERR:
+	case SCU_TASK_DONE_TASK_ABORT:
+	default:
+		/* Task in the target is not done. */
+		*response_ptr = SAS_TASK_UNDELIVERED;
+		*status_ptr = SAM_STAT_TASK_ABORTED;
+		request->complete_in_target = false;
+
+		*complete_to_host_ptr = isci_perform_error_io_completion;
+		break;
+	}
+}
+
+/**
+ * isci_task_save_for_upper_layer_completion() - This function saves the
+ *    request for later completion to the upper layer driver.
+ * @host: This parameter is a pointer to the host on which the the request
+ *    should be queued (either as an error or success).
+ * @request: This parameter is the completed request.
+ * @response: This parameter is the response code for the completed task.
+ * @status: This parameter is the status code for the completed task.
+ *
+ * none.
+ */
+static void isci_task_save_for_upper_layer_completion(
+	struct isci_host *host,
+	struct isci_request *request,
+	enum service_response response,
+	enum exec_status status,
+	enum isci_completion_selection task_notification_selection)
+{
+	struct sas_task *task = isci_request_access_task(request);
+
+	isci_task_set_completion_status(task, response, status,
+					 task_notification_selection);
+
+
+	/* Tasks aborted specifically by a call to the lldd_abort_task
+	 * function should not be completed to the host in the regular path.
+	 */
+	switch (task_notification_selection) {
+
+	case isci_perform_normal_io_completion:
+
+		/* Normal notification (task_done) */
+		dev_dbg(&host->pdev->dev,
+			"%s: Normal - task = %p, response=%d, status=%d\n",
+			__func__,
+			task,
+			response,
+			status);
+		/* Add to the completed list. */
+		list_add(&request->completed_node,
+			 &host->requests_to_complete);
+		break;
+
+	case isci_perform_aborted_io_completion:
+		/*
+		 * No notification because this request is already
+		 * in the abort path.
+		 */
+		dev_warn(&host->pdev->dev,
+			 "%s: Aborted - task = %p, response=%d, status=%d\n",
+			 __func__,
+			 task,
+			 response,
+			 status);
+		break;
+
+	case isci_perform_error_io_completion:
+		/* Use sas_task_abort */
+		dev_warn(&host->pdev->dev,
+			 "%s: Error - task = %p, response=%d, status=%d\n",
+			 __func__,
+			 task,
+			 response,
+			 status);
+		/* Add to the aborted list. */
+		list_add(&request->completed_node,
+			 &host->requests_to_abort);
+		break;
+
+	default:
+		dev_warn(&host->pdev->dev,
+			 "%s: Unknown - task = %p, response=%d, status=%d\n",
+			 __func__,
+			 task,
+			 response,
+			 status);
+
+		/* Add to the aborted list. */
+		list_add(&request->completed_node,
+			 &host->requests_to_abort);
+		break;
+	}
+}
+
+/**
+ * isci_request_io_request_complete() - This function is called by the sci core
+ *    when an io request completes.
+ * @isci_host: This parameter specifies the ISCI host object
+ * @request: This parameter is the completed isci_request object.
+ * @completion_status: This parameter specifies the completion status from the
+ *    sci core.
+ *
+ * none.
+ */
+void isci_request_io_request_complete(
+	struct        isci_host *isci_host,
+	struct        isci_request *request,
+	enum sci_io_status completion_status)
+{
+	struct sas_task *task = isci_request_access_task(request);
+	struct ssp_response_iu *resp_iu;
+	void *resp_buf;
+	unsigned long task_flags;
+	unsigned long state_flags;
+	struct completion *io_request_completion;
+	struct isci_remote_device *isci_device   = request->isci_device;
+	enum service_response response       = SAS_TASK_UNDELIVERED;
+	enum exec_status status         = SAS_ABORTED_TASK;
+	enum isci_request_status request_status;
+	enum isci_completion_selection complete_to_host
+		= isci_perform_normal_io_completion;
+
+	dev_dbg(&isci_host->pdev->dev,
+		"%s: request = %p, task = %p,\n"
+		"task->data_dir = %d completion_status = 0x%x\n",
+		__func__,
+		request,
+		task,
+		task->data_dir,
+		completion_status);
+
+	spin_lock_irqsave(&request->state_lock, state_flags);
+	request_status = isci_request_get_state(request);
+	spin_unlock_irqrestore(&request->state_lock, state_flags);
+
+	/* Decode the request status.  Note that if the request has been
+	 * aborted by a task management function, we don't care
+	 * what the status is.
+	 */
+	switch (request_status) {
+
+	case aborted:
+		/* "aborted" indicates that the request was aborted by a task
+		 * management function, since once a task management request is
+		 * perfomed by the device, the request only completes because
+		 * of the subsequent driver terminate.
+		 *
+		 * Aborted also means an external thread is explicitly managing
+		 * this request, so that we do not complete it up the stack.
+		 *
+		 * The target is still there (since the TMF was successful).
+		 */
+		request->complete_in_target = true;
+		response = SAS_TASK_COMPLETE;
+
+		/* See if the device has been/is being stopped. Note
+		 * that we ignore the quiesce state, since we are
+		 * concerned about the actual device state.
+		 */
+		if ((isci_device->status == isci_stopping)
+		    || (isci_device->status == isci_stopped)
+		    )
+			status = SAS_DEVICE_UNKNOWN;
+		else
+			status = SAS_ABORTED_TASK;
+
+		complete_to_host = isci_perform_aborted_io_completion;
+		/* This was an aborted request. */
+		break;
+
+	case aborting:
+		/* aborting means that the task management function tried and
+		 * failed to abort the request. We need to note the request
+		 * as SAS_TASK_UNDELIVERED, so that the scsi mid layer marks the
+		 * target as down.
+		 *
+		 * Aborting also means an external thread is explicitly managing
+		 * this request, so that we do not complete it up the stack.
+		 */
+		request->complete_in_target = true;
+		response = SAS_TASK_UNDELIVERED;
+
+		if ((isci_device->status == isci_stopping) ||
+		    (isci_device->status == isci_stopped))
+			/* The device has been /is being stopped. Note that
+			 * we ignore the quiesce state, since we are
+			 * concerned about the actual device state.
+			 */
+			status = SAS_DEVICE_UNKNOWN;
+		else
+			status = SAS_PHY_DOWN;
+
+		complete_to_host = isci_perform_aborted_io_completion;
+
+		/* This was an aborted request. */
+		break;
+
+	case terminating:
+
+		/* This was an terminated request.  This happens when
+		 * the I/O is being terminated because of an action on
+		 * the device (reset, tear down, etc.), and the I/O needs
+		 * to be completed up the stack.
+		 */
+		request->complete_in_target = true;
+		response = SAS_TASK_UNDELIVERED;
+
+		/* See if the device has been/is being stopped. Note
+		 * that we ignore the quiesce state, since we are
+		 * concerned about the actual device state.
+		 */
+		if ((isci_device->status == isci_stopping) ||
+		    (isci_device->status == isci_stopped))
+			status = SAS_DEVICE_UNKNOWN;
+		else
+			status = SAS_ABORTED_TASK;
+
+		complete_to_host = isci_perform_normal_io_completion;
+
+		/* This was a terminated request. */
+		break;
+
+	default:
+
+		/* This is an active request being completed from the core. */
+		switch (completion_status) {
+
+		case SCI_IO_FAILURE_RESPONSE_VALID:
+			dev_dbg(&isci_host->pdev->dev,
+				"%s: SCI_IO_FAILURE_RESPONSE_VALID (%p/%p)\n",
+				__func__,
+				request,
+				task);
+
+			if (sas_protocol_ata(task->task_proto)) {
+				resp_buf
+					= scic_stp_io_request_get_d2h_reg_address(
+					request->sci_request_handle
+					);
+				isci_request_process_stp_response(task,
+								  resp_buf
+								  );
+
+			} else if (SAS_PROTOCOL_SSP == task->task_proto) {
+
+				/* crack the iu response buffer. */
+				resp_iu
+					= scic_io_request_get_response_iu_address(
+					request->sci_request_handle
+					);
+
+				isci_request_process_response_iu(task, resp_iu,
+								 &isci_host->pdev->dev
+								 );
+
+			} else if (SAS_PROTOCOL_SMP == task->task_proto) {
+
+				dev_err(&isci_host->pdev->dev,
+					"%s: SCI_IO_FAILURE_RESPONSE_VALID: "
+					"SAS_PROTOCOL_SMP protocol\n",
+					__func__);
+
+			} else
+				dev_err(&isci_host->pdev->dev,
+					"%s: unknown protocol\n", __func__);
+
+			/* use the task status set in the task struct by the
+			 * isci_request_process_response_iu call.
+			 */
+			request->complete_in_target = true;
+			response = task->task_status.resp;
+			status = task->task_status.stat;
+			break;
+
+		case SCI_IO_SUCCESS:
+		case SCI_IO_SUCCESS_IO_DONE_EARLY:
+
+			response = SAS_TASK_COMPLETE;
+			status   = SAM_STAT_GOOD;
+			request->complete_in_target = true;
+
+			if (task->task_proto == SAS_PROTOCOL_SMP) {
+
+				u8 *command_iu_address
+					= scic_io_request_get_command_iu_address(
+					request->sci_request_handle
+					);
+
+				dev_dbg(&isci_host->pdev->dev,
+					"%s: SMP protocol completion\n",
+					__func__);
+
+				sg_copy_from_buffer(
+					&task->smp_task.smp_resp, 1,
+					command_iu_address
+					+ sizeof(struct smp_request),
+					sizeof(struct smp_resp)
+					);
+			} else if (completion_status
+				   == SCI_IO_SUCCESS_IO_DONE_EARLY) {
+
+				/* This was an SSP / STP / SATA transfer.
+				 * There is a possibility that less data than
+				 * the maximum was transferred.
+				 */
+				u32 transferred_length
+					= scic_io_request_get_number_of_bytes_transferred(
+					request->sci_request_handle);
+
+				task->task_status.residual
+					= task->total_xfer_len - transferred_length;
+
+				/* If there were residual bytes, call this an
+				 * underrun.
+				 */
+				if (task->task_status.residual != 0)
+					status = SAS_DATA_UNDERRUN;
+
+				dev_dbg(&isci_host->pdev->dev,
+					"%s: SCI_IO_SUCCESS_IO_DONE_EARLY %d\n",
+					__func__,
+					status);
+
+			} else
+				dev_dbg(&isci_host->pdev->dev,
+					"%s: SCI_IO_SUCCESS\n",
+					__func__);
+
+			break;
+
+		case SCI_IO_FAILURE_TERMINATED:
+			dev_dbg(&isci_host->pdev->dev,
+				"%s: SCI_IO_FAILURE_TERMINATED (%p/%p)\n",
+				__func__,
+				request,
+				task);
+
+			/* The request was terminated explicitly.  No handling
+			 * is needed in the SCSI error handler path.
+			 */
+			request->complete_in_target = true;
+			response = SAS_TASK_UNDELIVERED;
+
+			/* See if the device has been/is being stopped. Note
+			 * that we ignore the quiesce state, since we are
+			 * concerned about the actual device state.
+			 */
+			if ((isci_device->status == isci_stopping) ||
+			    (isci_device->status == isci_stopped))
+				status = SAS_DEVICE_UNKNOWN;
+			else
+				status = SAS_ABORTED_TASK;
+
+			complete_to_host = isci_perform_normal_io_completion;
+			break;
+
+		case SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR:
+
+			isci_request_handle_controller_specific_errors(
+				isci_device, request, task, &response, &status,
+				&complete_to_host);
+
+			break;
+
+		case SCI_IO_FAILURE_REMOTE_DEVICE_RESET_REQUIRED:
+			/* This is a special case, in that the I/O completion
+			 * is telling us that the device needs a reset.
+			 * In order for the device reset condition to be
+			 * noticed, the I/O has to be handled in the error
+			 * handler.  Set the reset flag and cause the
+			 * SCSI error thread to be scheduled.
+			 */
+			spin_lock_irqsave(&task->task_state_lock, task_flags);
+			task->task_state_flags |= SAS_TASK_NEED_DEV_RESET;
+			spin_unlock_irqrestore(&task->task_state_lock, task_flags);
+
+			complete_to_host = isci_perform_error_io_completion;
+			request->complete_in_target = false;
+			break;
+
+		default:
+			/* Catch any otherwise unhandled error codes here. */
+			dev_warn(&isci_host->pdev->dev,
+				 "%s: invalid completion code: 0x%x - "
+				 "isci_request = %p\n",
+				 __func__, completion_status, request);
+
+			response = SAS_TASK_UNDELIVERED;
+
+			/* See if the device has been/is being stopped. Note
+			 * that we ignore the quiesce state, since we are
+			 * concerned about the actual device state.
+			 */
+			if ((isci_device->status == isci_stopping) ||
+			    (isci_device->status == isci_stopped))
+				status = SAS_DEVICE_UNKNOWN;
+			else
+				status = SAS_ABORTED_TASK;
+
+			complete_to_host = isci_perform_error_io_completion;
+			request->complete_in_target = false;
+			break;
+		}
+		break;
+	}
+
+	isci_request_unmap_sgl(request, isci_host->pdev);
+
+	/* Put the completed request on the correct list */
+	isci_task_save_for_upper_layer_completion(isci_host, request, response,
+						  status, complete_to_host
+						  );
+
+	/* complete the io request to the core. */
+	scic_controller_complete_io(
+		isci_host->core_controller,
+		isci_device->sci_device_handle,
+		request->sci_request_handle
+		);
+	/* NULL the request handle so it cannot be completed or
+	 * terminated again, and to cause any calls into abort
+	 * task to recognize the already completed case.
+	 */
+	request->sci_request_handle = NULL;
+
+	/* Only remove the request from the remote device list
+	 * of pending requests if we have not requested error
+	 * handling on this request.
+	 */
+	if (complete_to_host != isci_perform_error_io_completion)
+		list_del_init(&request->dev_node);
+
+
+	/* Save possible completion ptr. */
+	io_request_completion = request->io_request_completion;
+
+	if (io_request_completion) {
+
+		/* This is inherantly a regular I/O request,
+		 * since we are currently in the regular
+		 * I/O completion callback function.
+		 * Signal whoever is waiting that this
+		 * request is complete.
+		 */
+		complete(io_request_completion);
+	}
+
+	isci_host_can_dequeue(isci_host, 1);
+}
+
+/**
+ * isci_request_io_request_get_transfer_length() - This function is called by
+ *    the sci core to retrieve the transfer length for a given request.
+ * @request: This parameter is the isci_request object.
+ *
+ * length of transfer for specified request.
+ */
+u32 isci_request_io_request_get_transfer_length(struct isci_request *request)
+{
+	struct sas_task *task = isci_request_access_task(request);
+
+	dev_dbg(&request->isci_host->pdev->dev,
+		"%s: total_xfer_len: %d\n",
+		__func__,
+		task->total_xfer_len);
+	return task->total_xfer_len;
+}
+
+
+/**
+ * isci_request_io_request_get_data_direction() - This function is called by
+ *    the sci core to retrieve the data direction for a given request.
+ * @request: This parameter is the isci_request object.
+ *
+ * data direction for specified request.
+ */
+SCI_IO_REQUEST_DATA_DIRECTION isci_request_io_request_get_data_direction(
+	struct isci_request *request)
+{
+	struct sas_task *task = isci_request_access_task(request);
+	SCI_IO_REQUEST_DATA_DIRECTION ret;
+
+	switch (task->data_dir) {
+
+	case DMA_FROM_DEVICE:
+		ret = SCI_IO_REQUEST_DATA_IN;
+		dev_dbg(&request->isci_host->pdev->dev,
+			"%s: request=%p, FROM_DEVICE\n",
+			__func__,
+			request);
+		break;
+
+	case DMA_TO_DEVICE:
+		ret = SCI_IO_REQUEST_DATA_OUT;
+		dev_dbg(&request->isci_host->pdev->dev,
+			"%s: request=%p, TO_DEVICE\n",
+			__func__,
+			request);
+		break;
+
+	case DMA_BIDIRECTIONAL:
+	case DMA_NONE:
+	default:
+		ret = SCI_IO_REQUEST_NO_DATA;
+		dev_dbg(&request->isci_host->pdev->dev,
+			"%s: request=%p, unhandled direction case, "
+			"data_dir=%d\n",
+			__func__,
+			request,
+			task->data_dir);
+		break;
+
+	}
+	return ret;
+}
+
+/**
+ * isci_request_sge_get_address_field() - This function is called by the sci
+ *    core to retrieve the address field contents for a given sge.
+ * @request: This parameter is the isci_request object.
+ * @sge_address: This parameter is the sge.
+ *
+ * physical address in the specified sge.
+ */
+dma_addr_t isci_request_sge_get_address_field(
+	struct isci_request *request,
+	void *sge_address)
+{
+	struct sas_task *task = isci_request_access_task(request);
+	dma_addr_t ret;
+	struct isci_host *isci_host = isci_host_from_sas_ha(
+		task->dev->port->ha);
+
+	dev_dbg(&isci_host->pdev->dev,
+		"%s: request = %p, sge_address = %p\n",
+		__func__,
+		request,
+		sge_address);
+
+	if (task->data_dir == PCI_DMA_NONE)
+		return 0;
+
+	/* the case where num_scatter == 0 is special, in that
+	 * task->scatter is the actual buffer address, not an sgl.
+	 * so a map single is required here.
+	 */
+	if ((task->num_scatter == 0) &&
+	    !sas_protocol_ata(task->task_proto)) {
+		ret = dma_map_single(
+			&isci_host->pdev->dev,
+			task->scatter,
+			task->total_xfer_len,
+			task->data_dir
+			);
+		request->zero_scatter_daddr = ret;
+	} else
+		ret = sg_dma_address(((struct scatterlist *)sge_address));
+
+	dev_dbg(&isci_host->pdev->dev,
+		"%s: bus address = %lx\n",
+		__func__,
+		(unsigned long)ret);
+
+	return ret;
+}
+
+
+/**
+ * isci_request_sge_get_length_field() - This function is called by the sci
+ *    core to retrieve the length field contents for a given sge.
+ * @request: This parameter is the isci_request object.
+ * @sge_address: This parameter is the sge.
+ *
+ * length field value in the specified sge.
+ */
+u32 isci_request_sge_get_length_field(
+	struct isci_request *request,
+	void *sge_address)
+{
+	struct sas_task *task = isci_request_access_task(request);
+	int ret;
+
+	dev_dbg(&request->isci_host->pdev->dev,
+		"%s: request = %p, sge_address = %p\n",
+		__func__,
+		request,
+		sge_address);
+
+	if (task->data_dir == PCI_DMA_NONE)
+		return 0;
+
+	/* the case where num_scatter == 0 is special, in that
+	 * task->scatter is the actual buffer address, not an sgl.
+	 * so we return total_xfer_len here.
+	 */
+	if (task->num_scatter == 0)
+		ret = task->total_xfer_len;
+	else
+		ret = sg_dma_len((struct scatterlist *)sge_address);
+
+	dev_dbg(&request->isci_host->pdev->dev,
+		"%s: len = %d\n",
+		__func__,
+		ret);
+
+	return ret;
+}
+
+
+/**
+ * isci_request_ssp_io_request_get_cdb_address() - This function is called by
+ *    the sci core to retrieve the cdb address for a given request.
+ * @request: This parameter is the isci_request object.
+ *
+ * cdb address for specified request.
+ */
+void *isci_request_ssp_io_request_get_cdb_address(
+	struct isci_request *request)
+{
+	struct sas_task *task = isci_request_access_task(request);
+
+	dev_dbg(&request->isci_host->pdev->dev,
+		"%s: request->task->ssp_task.cdb = %p\n",
+		__func__,
+		task->ssp_task.cdb);
+	return task->ssp_task.cdb;
+}
+
+
+/**
+ * isci_request_ssp_io_request_get_cdb_length() - This function is called by
+ *    the sci core to retrieve the cdb length for a given request.
+ * @request: This parameter is the isci_request object.
+ *
+ * cdb length for specified request.
+ */
+u32 isci_request_ssp_io_request_get_cdb_length(
+	struct isci_request *request)
+{
+	return 16;
+}
+
+
+/**
+ * isci_request_ssp_io_request_get_lun() - This function is called by the sci
+ *    core to retrieve the lun for a given request.
+ * @request: This parameter is the isci_request object.
+ *
+ * lun for specified request.
+ */
+u32 isci_request_ssp_io_request_get_lun(
+	struct isci_request *request)
+{
+	struct sas_task *task = isci_request_access_task(request);
+
+#ifdef DEBUG
+	int i;
+
+	for (i = 0; i < 8; i++)
+		dev_dbg(&request->isci_host->pdev->dev,
+			"%s: request->task->ssp_task.LUN[%d] = %x\n",
+			__func__, i, request->task->ssp_task.LUN[i]);
+
+#endif
+
+	return task->ssp_task.LUN[0];
+}
+
+
+/**
+ * isci_request_ssp_io_request_get_task_attribute() - This function is called
+ *    by the sci core to retrieve the task attribute for a given request.
+ * @request: This parameter is the isci_request object.
+ *
+ * task attribute for specified request.
+ */
+u32 isci_request_ssp_io_request_get_task_attribute(
+	struct isci_request *request)
+{
+	struct sas_task *task = isci_request_access_task(request);
+
+	dev_dbg(&request->isci_host->pdev->dev,
+		"%s: request->task->ssp_task.task_attr = %x\n",
+		__func__,
+		task->ssp_task.task_attr);
+
+	return task->ssp_task.task_attr;
+}
+
+
+/**
+ * isci_request_ssp_io_request_get_command_priority() - This function is called
+ *    by the sci core to retrieve the command priority for a given request.
+ * @request: This parameter is the isci_request object.
+ *
+ * command priority for specified request.
+ */
+u32 isci_request_ssp_io_request_get_command_priority(
+	struct isci_request *request)
+{
+	struct sas_task *task = isci_request_access_task(request);
+
+	dev_dbg(&request->isci_host->pdev->dev,
+		"%s: request->task->ssp_task.task_prio = %x\n",
+		__func__,
+		task->ssp_task.task_prio);
+
+	return task->ssp_task.task_prio;
+}
