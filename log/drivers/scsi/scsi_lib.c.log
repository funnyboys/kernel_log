commit 818dbde78e0f4f11c9f804c36913a7ccfc2e87ad
Merge: 242b23319809 22617e216331
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jun 5 15:11:50 2020 -0700

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     :This series consists of the usual driver updates (qla2xxx, ufs, zfcp,
      target, scsi_debug, lpfc, qedi, qedf, hisi_sas, mpt3sas) plus a host
      of other minor updates.
    
      There are no major core changes in this series apart from a
      refactoring in scsi_lib.c"
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (207 commits)
      scsi: ufs: ti-j721e-ufs: Fix unwinding of pm_runtime changes
      scsi: cxgb3i: Fix some leaks in init_act_open()
      scsi: ibmvscsi: Make some functions static
      scsi: iscsi: Fix deadlock on recovery path during GFP_IO reclaim
      scsi: ufs: Fix WriteBooster flush during runtime suspend
      scsi: ufs: Fix index of attributes query for WriteBooster feature
      scsi: ufs: Allow WriteBooster on UFS 2.2 devices
      scsi: ufs: Remove unnecessary memset for dev_info
      scsi: ufs-qcom: Fix scheduling while atomic issue
      scsi: mpt3sas: Fix reply queue count in non RDPQ mode
      scsi: lpfc: Fix lpfc_nodelist leak when processing unsolicited event
      scsi: target: tcmu: Fix a use after free in tcmu_check_expired_queue_cmd()
      scsi: vhost: Notify TCM about the maximum sg entries supported per command
      scsi: qla2xxx: Remove return value from qla_nvme_ls()
      scsi: qla2xxx: Remove an unused function
      scsi: iscsi: Register sysfs for iscsi workqueue
      scsi: scsi_debug: Parser tables and code interaction
      scsi: core: Refactor scsi_mq_setup_tags function
      scsi: core: Fix incorrect usage of shost_for_each_device
      scsi: qla2xxx: Fix endianness annotations in source files
      ...

commit 750a02ab8d3c49ca7d23102be90d3d1db19e2827
Merge: 1966391fa576 abb30460bda2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jun 2 15:29:19 2020 -0700

    Merge tag 'for-5.8/block-2020-06-01' of git://git.kernel.dk/linux-block
    
    Pull block updates from Jens Axboe:
     "Core block changes that have been queued up for this release:
    
       - Remove dead blk-throttle and blk-wbt code (Guoqing)
    
       - Include pid in blktrace note traces (Jan)
    
       - Don't spew I/O errors on wouldblock termination (me)
    
       - Zone append addition (Johannes, Keith, Damien)
    
       - IO accounting improvements (Konstantin, Christoph)
    
       - blk-mq hardware map update improvements (Ming)
    
       - Scheduler dispatch improvement (Salman)
    
       - Inline block encryption support (Satya)
    
       - Request map fixes and improvements (Weiping)
    
       - blk-iocost tweaks (Tejun)
    
       - Fix for timeout failing with error injection (Keith)
    
       - Queue re-run fixes (Douglas)
    
       - CPU hotplug improvements (Christoph)
    
       - Queue entry/exit improvements (Christoph)
    
       - Move DMA drain handling to the few drivers that use it (Christoph)
    
       - Partition handling cleanups (Christoph)"
    
    * tag 'for-5.8/block-2020-06-01' of git://git.kernel.dk/linux-block: (127 commits)
      block: mark bio_wouldblock_error() bio with BIO_QUIET
      blk-wbt: rename __wbt_update_limits to wbt_update_limits
      blk-wbt: remove wbt_update_limits
      blk-throttle: remove tg_drain_bios
      blk-throttle: remove blk_throtl_drain
      null_blk: force complete for timeout request
      blk-mq: drain I/O when all CPUs in a hctx are offline
      blk-mq: add blk_mq_all_tag_iter
      blk-mq: open code __blk_mq_alloc_request in blk_mq_alloc_request_hctx
      blk-mq: use BLK_MQ_NO_TAG in more places
      blk-mq: rename BLK_MQ_TAG_FAIL to BLK_MQ_NO_TAG
      blk-mq: move more request initialization to blk_mq_rq_ctx_init
      blk-mq: simplify the blk_mq_get_request calling convention
      blk-mq: remove the bio argument to ->prepare_request
      nvme: force complete cancelled requests
      blk-mq: blk-mq: provide forced completion method
      block: fix a warning when blkdev.h is included for !CONFIG_BLOCK builds
      block: blk-crypto-fallback: remove redundant initialization of variable err
      block: reduce part_stat_lock() scope
      block: use __this_cpu_add() instead of access by smp_processor_id()
      ...

commit 840e1b55bb752c6617a85eb01d15432bebe8c559
Author: Ye Bin <yebin10@huawei.com>
Date:   Mon May 18 15:47:32 2020 +0800

    scsi: core: Refactor scsi_mq_setup_tags function
    
    shost->tag_set is used too many times, introduce temporary parameter
    tag_set instead of &shost->tag_set.
    
    Link: https://lore.kernel.org/r/20200518074732.39679-1-yebin10@huawei.com
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Ye Bin <yebin10@huawei.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4ed694b9f99b..c163fa22267c 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1849,6 +1849,7 @@ struct request_queue *scsi_mq_alloc_queue(struct scsi_device *sdev)
 int scsi_mq_setup_tags(struct Scsi_Host *shost)
 {
 	unsigned int cmd_size, sgl_size;
+	struct blk_mq_tag_set *tag_set = &shost->tag_set;
 
 	sgl_size = max_t(unsigned int, sizeof(struct scatterlist),
 				scsi_mq_inline_sgl_size(shost));
@@ -1857,21 +1858,21 @@ int scsi_mq_setup_tags(struct Scsi_Host *shost)
 		cmd_size += sizeof(struct scsi_data_buffer) +
 			sizeof(struct scatterlist) * SCSI_INLINE_PROT_SG_CNT;
 
-	memset(&shost->tag_set, 0, sizeof(shost->tag_set));
+	memset(tag_set, 0, sizeof(*tag_set));
 	if (shost->hostt->commit_rqs)
-		shost->tag_set.ops = &scsi_mq_ops;
+		tag_set->ops = &scsi_mq_ops;
 	else
-		shost->tag_set.ops = &scsi_mq_ops_no_commit;
-	shost->tag_set.nr_hw_queues = shost->nr_hw_queues ? : 1;
-	shost->tag_set.queue_depth = shost->can_queue;
-	shost->tag_set.cmd_size = cmd_size;
-	shost->tag_set.numa_node = NUMA_NO_NODE;
-	shost->tag_set.flags = BLK_MQ_F_SHOULD_MERGE;
-	shost->tag_set.flags |=
+		tag_set->ops = &scsi_mq_ops_no_commit;
+	tag_set->nr_hw_queues = shost->nr_hw_queues ? : 1;
+	tag_set->queue_depth = shost->can_queue;
+	tag_set->cmd_size = cmd_size;
+	tag_set->numa_node = NUMA_NO_NODE;
+	tag_set->flags = BLK_MQ_F_SHOULD_MERGE;
+	tag_set->flags |=
 		BLK_ALLOC_POLICY_TO_MQ_FLAG(shost->hostt->tag_alloc_policy);
-	shost->tag_set.driver_data = shost;
+	tag_set->driver_data = shost;
 
-	return blk_mq_alloc_tag_set(&shost->tag_set);
+	return blk_mq_alloc_tag_set(tag_set);
 }
 
 void scsi_mq_destroy_tags(struct Scsi_Host *shost)

commit 4dea170f4fb225984b4f2f1cf0a41d485177b905
Author: Ye Bin <yebin10@huawei.com>
Date:   Mon May 18 15:44:20 2020 +0800

    scsi: core: Fix incorrect usage of shost_for_each_device
    
    shost_for_each_device(sdev, shost) \
            for ((sdev) = __scsi_iterate_devices((shost), NULL); \
                 (sdev); \
                 (sdev) = __scsi_iterate_devices((shost), (sdev)))
    
    When terminating shost_for_each_device() iteration with break or return,
    scsi_device_put() should be used to prevent stale scsi device references
    from being left behind.
    
    Link: https://lore.kernel.org/r/20200518074420.39275-1-yebin10@huawei.com
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Ye Bin <yebin10@huawei.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 01d229ea4e1c..4ed694b9f99b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2835,8 +2835,10 @@ scsi_host_unblock(struct Scsi_Host *shost, int new_state)
 
 	shost_for_each_device(sdev, shost) {
 		ret = scsi_internal_device_unblock(sdev, new_state);
-		if (ret)
+		if (ret) {
+			scsi_device_put(sdev);
 			break;
+		}
 	}
 	return ret;
 }

commit 0512a75b98f847c2e9a4b664013424e603e202f7
Author: Keith Busch <kbusch@kernel.org>
Date:   Tue May 12 17:55:47 2020 +0900

    block: Introduce REQ_OP_ZONE_APPEND
    
    Define REQ_OP_ZONE_APPEND to append-write sectors to a zone of a zoned
    block device. This is a no-merge write operation.
    
    A zone append write BIO must:
    * Target a zoned block device
    * Have a sector position indicating the start sector of the target zone
    * The target zone must be a sequential write zone
    * The BIO must not cross a zone boundary
    * The BIO size must not be split to ensure that a single range of LBAs
      is written with a single command.
    
    Implement these checks in generic_make_request_checks() using the
    helper function blk_check_zone_append(). To avoid write append BIO
    splitting, introduce the new max_zone_append_sectors queue limit
    attribute and ensure that a BIO size is always lower than this limit.
    Export this new limit through sysfs and check these limits in bio_full().
    
    Also when a LLDD can't dispatch a request to a specific zone, it
    will return BLK_STS_ZONE_RESOURCE indicating this request needs to
    be delayed, e.g.  because the zone it will be dispatched to is still
    write-locked. If this happens set the request aside in a local list
    to continue trying dispatching requests such as READ requests or a
    WRITE/ZONE_APPEND requests targetting other zones. This way we can
    still keep a high queue depth without starving other requests even if
    one request can't be served due to zone write-locking.
    
    Finally, make sure that the bio sector position indicates the actual
    write position as indicated by the device on completion.
    
    Signed-off-by: Keith Busch <kbusch@kernel.org>
    [ jth: added zone-append specific add_page and merge_page helpers ]
    Signed-off-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0a73230a8f16..82ad0244b3d0 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1706,6 +1706,7 @@ static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	case BLK_STS_OK:
 		break;
 	case BLK_STS_RESOURCE:
+	case BLK_STS_ZONE_RESOURCE:
 		if (atomic_read(&sdev->device_busy) ||
 		    scsi_device_blocked(sdev))
 			ret = BLK_STS_DEV_RESOURCE;

commit 20a66f2bf280277ab5bb22e27445153b4eb0ac88
Author: Johannes Thumshirn <johannes.thumshirn@wdc.com>
Date:   Tue Apr 28 19:45:55 2020 +0900

    scsi: core: free sgtables in case command setup fails
    
    In case scsi_setup_fs_cmnd() fails we're not freeing the sgtables allocated
    by scsi_init_io(), thus we leak the allocated memory.
    
    Free the sgtables allocated by scsi_init_io() in case scsi_setup_fs_cmnd()
    fails.
    
    Technically scsi_setup_scsi_cmnd() does not suffer from this problem as it
    can only fail if scsi_init_io() fails, so it does not have sgtables
    allocated. But to maintain symmetry and as a measure of defensive
    programming, free the sgtables on scsi_setup_scsi_cmnd() failure as well.
    scsi_mq_free_sgtables() has safeguards against double-freeing of memory so
    this is safe to do.
    
    While we're at it, rename scsi_mq_free_sgtables() to scsi_free_sgtables().
    
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=205595
    Link: https://lore.kernel.org/r/20200428104605.8143-2-johannes.thumshirn@wdc.com
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Daniel Wagner <dwagner@suse.de>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 53b9ff12e030..01d229ea4e1c 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -531,7 +531,7 @@ static void scsi_uninit_cmd(struct scsi_cmnd *cmd)
 	}
 }
 
-static void scsi_mq_free_sgtables(struct scsi_cmnd *cmd)
+static void scsi_free_sgtables(struct scsi_cmnd *cmd)
 {
 	if (cmd->sdb.table.nents)
 		sg_free_table_chained(&cmd->sdb.table,
@@ -543,7 +543,7 @@ static void scsi_mq_free_sgtables(struct scsi_cmnd *cmd)
 
 static void scsi_mq_uninit_cmd(struct scsi_cmnd *cmd)
 {
-	scsi_mq_free_sgtables(cmd);
+	scsi_free_sgtables(cmd);
 	scsi_uninit_cmd(cmd);
 }
 
@@ -1032,7 +1032,7 @@ blk_status_t scsi_init_io(struct scsi_cmnd *cmd)
 
 	return BLK_STS_OK;
 out_free_sgtables:
-	scsi_mq_free_sgtables(cmd);
+	scsi_free_sgtables(cmd);
 	return ret;
 }
 EXPORT_SYMBOL(scsi_init_io);
@@ -1163,6 +1163,7 @@ static blk_status_t scsi_setup_cmnd(struct scsi_device *sdev,
 		struct request *req)
 {
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
+	blk_status_t ret;
 
 	if (!blk_rq_bytes(req))
 		cmd->sc_data_direction = DMA_NONE;
@@ -1172,9 +1173,14 @@ static blk_status_t scsi_setup_cmnd(struct scsi_device *sdev,
 		cmd->sc_data_direction = DMA_FROM_DEVICE;
 
 	if (blk_rq_is_scsi(req))
-		return scsi_setup_scsi_cmnd(sdev, req);
+		ret = scsi_setup_scsi_cmnd(sdev, req);
 	else
-		return scsi_setup_fs_cmnd(sdev, req);
+		ret = scsi_setup_fs_cmnd(sdev, req);
+
+	if (ret != BLK_STS_OK)
+		scsi_free_sgtables(cmd);
+
+	return ret;
 }
 
 static blk_status_t

commit ea941016abf7e6f81b130f8eb792e9ad0971237a
Author: André Almeida <andrealmeid@collabora.com>
Date:   Sun Apr 19 02:01:48 2020 -0300

    scsi: core: doc: Change function comments to kernel-doc style
    
    Despite of functions being documented, they are not in the kernel-doc
    specification, and could not be included in kernel documentation. Change
    the style of functions comments to be compliant to the kernel-doc style.
    When the function comments are outdated, update then.
    
    [mkp: a few edits]
    
    Link: https://lore.kernel.org/r/20200419050148.33371-1-andrealmeid@collabora.com
    Signed-off-by: André Almeida <andrealmeid@collabora.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ff0449fbe3a0..53b9ff12e030 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -202,24 +202,17 @@ static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, bool unbusy)
 	blk_mq_requeue_request(cmd->request, true);
 }
 
-/*
- * Function:    scsi_queue_insert()
- *
- * Purpose:     Insert a command in the midlevel queue.
- *
- * Arguments:   cmd    - command that we are adding to queue.
- *              reason - why we are inserting command to queue.
- *
- * Lock status: Assumed that lock is not held upon entry.
+/**
+ * scsi_queue_insert - Reinsert a command in the queue.
+ * @cmd:    command that we are adding to queue.
+ * @reason: why we are inserting command to queue.
  *
- * Returns:     Nothing.
+ * We do this for one of two cases. Either the host is busy and it cannot accept
+ * any more commands for the time being, or the device returned QUEUE_FULL and
+ * can accept no more commands.
  *
- * Notes:       We do this for one of two cases.  Either the host is busy
- *              and it cannot accept any more commands for the time being,
- *              or the device returned QUEUE_FULL and can accept no more
- *              commands.
- * Notes:       This could be called either from an interrupt context or a
- *              normal process context.
+ * Context: This could be called either from an interrupt context or a normal
+ * process context.
  */
 void scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 {
@@ -301,16 +294,12 @@ int __scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 }
 EXPORT_SYMBOL(__scsi_execute);
 
-/*
- * Function:    scsi_init_cmd_errh()
- *
- * Purpose:     Initialize cmd fields related to error handling.
- *
- * Arguments:   cmd	- command that is ready to be queued.
+/**
+ * scsi_init_cmd_errh - Initialize cmd fields related to error handling.
+ * @cmd:  command that is ready to be queued.
  *
- * Notes:       This function has the job of initializing a number of
- *              fields related to error handling.   Typically this will
- *              be called once for each command, as required.
+ * This function has the job of initializing a number of fields related to error
+ * handling. Typically this will be called once for each command, as required.
  */
 static void scsi_init_cmd_errh(struct scsi_cmnd *cmd)
 {
@@ -496,17 +485,11 @@ static void scsi_starved_list_run(struct Scsi_Host *shost)
 	spin_unlock_irqrestore(shost->host_lock, flags);
 }
 
-/*
- * Function:   scsi_run_queue()
- *
- * Purpose:    Select a proper request queue to serve next
- *
- * Arguments:  q       - last request's queue
- *
- * Returns:     Nothing
+/**
+ * scsi_run_queue - Select a proper request queue to serve next.
+ * @q:  last request's queue
  *
- * Notes:      The previous command was completely finished, start
- *             a new one if possible.
+ * The previous command was completely finished, start a new one if possible.
  */
 static void scsi_run_queue(struct request_queue *q)
 {
@@ -896,34 +879,27 @@ static int scsi_io_completion_nz_result(struct scsi_cmnd *cmd, int result,
 	return result;
 }
 
-/*
- * Function:    scsi_io_completion()
- *
- * Purpose:     Completion processing for block device I/O requests.
- *
- * Arguments:   cmd   - command that is finished.
- *
- * Lock status: Assumed that no lock is held upon entry.
- *
- * Returns:     Nothing
- *
- * Notes:       We will finish off the specified number of sectors.  If we
- *		are done, the command block will be released and the queue
- *		function will be goosed.  If we are not done then we have to
- *		figure out what to do next:
- *
- *		a) We can call scsi_requeue_command().  The request
- *		   will be unprepared and put back on the queue.  Then
- *		   a new command will be created for it.  This should
- *		   be used if we made forward progress, or if we want
- *		   to switch from READ(10) to READ(6) for example.
- *
- *		b) We can call __scsi_queue_insert().  The request will
- *		   be put back on the queue and retried using the same
- *		   command as before, possibly after a delay.
- *
- *		c) We can call scsi_end_request() with blk_stat other than
- *		   BLK_STS_OK, to fail the remainder of the request.
+/**
+ * scsi_io_completion - Completion processing for SCSI commands.
+ * @cmd:	command that is finished.
+ * @good_bytes:	number of processed bytes.
+ *
+ * We will finish off the specified number of sectors. If we are done, the
+ * command block will be released and the queue function will be goosed. If we
+ * are not done then we have to figure out what to do next:
+ *
+ *   a) We can call scsi_io_completion_reprep().  The request will be
+ *	unprepared and put back on the queue.  Then a new command will
+ *	be created for it.  This should be used if we made forward
+ *	progress, or if we want to switch from READ(10) to READ(6) for
+ *	example.
+ *
+ *   b) We can call scsi_io_completion_action().  The request will be
+ *	put back on the queue and retried using the same command as
+ *	before, possibly after a delay.
+ *
+ *   c) We can call scsi_end_request() with blk_stat other than
+ *	BLK_STS_OK, to fail the remainder of the request.
  */
 void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 {
@@ -951,8 +927,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		blk_rq_sectors(req), good_bytes));
 
 	/*
-	 * Next deal with any sectors which we were able to correctly
-	 * handle. Failed, zero length commands always need to drop down
+	 * Failed, zero length commands always need to drop down
 	 * to retry code. Fast path should return in this block.
 	 */
 	if (likely(blk_rq_bytes(req) > 0 || blk_stat == BLK_STS_OK)) {
@@ -1002,16 +977,14 @@ static blk_status_t scsi_init_sgtable(struct request *req,
 	return BLK_STS_OK;
 }
 
-/*
- * Function:    scsi_init_io()
- *
- * Purpose:     SCSI I/O initialize function.
- *
- * Arguments:   cmd   - Command descriptor we wish to initialize
+/**
+ * scsi_init_io - SCSI I/O initialization function.
+ * @cmd:  command descriptor we wish to initialize
  *
- * Returns:     BLK_STS_OK on success
- *		BLK_STS_RESOURCE if the failure is retryable
- *		BLK_STS_IOERR if the failure is fatal
+ * Returns:
+ * * BLK_STS_OK       - on success
+ * * BLK_STS_RESOURCE - if the failure is retryable
+ * * BLK_STS_IOERR    - if the failure is fatal
  */
 blk_status_t scsi_init_io(struct scsi_cmnd *cmd)
 {
@@ -1921,21 +1894,13 @@ struct scsi_device *scsi_device_from_queue(struct request_queue *q)
 }
 EXPORT_SYMBOL_GPL(scsi_device_from_queue);
 
-/*
- * Function:    scsi_block_requests()
- *
- * Purpose:     Utility function used by low-level drivers to prevent further
- *		commands from being queued to the device.
- *
- * Arguments:   shost       - Host in question
- *
- * Returns:     Nothing
- *
- * Lock status: No locks are assumed held.
+/**
+ * scsi_block_requests - Utility function used by low-level drivers to prevent
+ * further commands from being queued to the device.
+ * @shost:  host in question
  *
- * Notes:       There is no timer nor any other means by which the requests
- *		get unblocked other than the low-level driver calling
- *		scsi_unblock_requests().
+ * There is no timer nor any other means by which the requests get unblocked
+ * other than the low-level driver calling scsi_unblock_requests().
  */
 void scsi_block_requests(struct Scsi_Host *shost)
 {
@@ -1943,25 +1908,15 @@ void scsi_block_requests(struct Scsi_Host *shost)
 }
 EXPORT_SYMBOL(scsi_block_requests);
 
-/*
- * Function:    scsi_unblock_requests()
- *
- * Purpose:     Utility function used by low-level drivers to allow further
- *		commands from being queued to the device.
- *
- * Arguments:   shost       - Host in question
- *
- * Returns:     Nothing
- *
- * Lock status: No locks are assumed held.
- *
- * Notes:       There is no timer nor any other means by which the requests
- *		get unblocked other than the low-level driver calling
- *		scsi_unblock_requests().
- *
- *		This is done as an API function so that changes to the
- *		internals of the scsi mid-layer won't require wholesale
- *		changes to drivers that use this feature.
+/**
+ * scsi_unblock_requests - Utility function used by low-level drivers to allow
+ * further commands to be queued to the device.
+ * @shost:  host in question
+ *
+ * There is no timer nor any other means by which the requests get unblocked
+ * other than the low-level driver calling scsi_unblock_requests(). This is done
+ * as an API function so that changes to the internals of the scsi mid-layer
+ * won't require wholesale changes to drivers that use this feature.
  */
 void scsi_unblock_requests(struct Scsi_Host *shost)
 {

commit f983622ae60516d634008c7b1ff9ffff4f7bb8ae
Author: Ming Lei <ming.lei@redhat.com>
Date:   Thu Apr 23 10:07:13 2020 +0800

    scsi: core: Avoid calling synchronize_rcu() for each device in scsi_host_block()
    
    scsi_host_block() calls scsi_internal_device_block() for each scsi_device and
    scsi_internal_device_block() calls blk_mq_quiesce_queue() for each LUN.
    
    Since synchronize_rcu() is called from blk_mq_quiesce_queue(), this can cause
    substantial slowdowns on systems with many LUNs.
    
    Use scsi_internal_device_block_nowait() to implement scsi_host_block() so it
    is sufficient to run synchronize_rcu() once. This is safe since SCSI does not
    set the BLK_MQ_F_BLOCKING flag.
    
    [mkp: commit desc and comment tweaks]
    
    Link: https://lore.kernel.org/r/20200423020713.332743-1-ming.lei@redhat.com
    Cc: Steffen Maier <maier@linux.ibm.com>
    Cc: Bart Van Assche <bvanassche@acm.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Dexuan Cui <decui@microsoft.com>
    Cc: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 47835c4b4ee0..ff0449fbe3a0 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2841,11 +2841,27 @@ scsi_host_block(struct Scsi_Host *shost)
 	struct scsi_device *sdev;
 	int ret = 0;
 
+	/*
+	 * Call scsi_internal_device_block_nowait so we can avoid
+	 * calling synchronize_rcu() for each LUN.
+	 */
 	shost_for_each_device(sdev, shost) {
-		ret = scsi_internal_device_block(sdev);
+		mutex_lock(&sdev->state_mutex);
+		ret = scsi_internal_device_block_nowait(sdev);
+		mutex_unlock(&sdev->state_mutex);
 		if (ret)
 			break;
 	}
+
+	/*
+	 * SCSI never enables blk-mq's BLK_MQ_F_BLOCKING flag so
+	 * calling synchronize_rcu() once is enough.
+	 */
+	WARN_ON_ONCE(shost->tag_set.flags & BLK_MQ_F_BLOCKING);
+
+	if (!ret)
+		synchronize_rcu();
+
 	return ret;
 }
 EXPORT_SYMBOL_GPL(scsi_host_block);

commit bdf8710d69f82ee6fd41b0166300c3306898b3c1
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Apr 14 09:42:25 2020 +0200

    block: move dma_pad handling from blk_rq_map_sg into the callers
    
    There are only two callers of blk_rq_map_sg/__blk_rq_map_sg that set
    the dma_pad value in the queue.  Move the handling into those callers
    instead of burdening the common code, and move the ->extra_len field
    from struct request to struct scsi_cmnd.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 88cac92fc153..0a73230a8f16 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1030,13 +1030,21 @@ blk_status_t scsi_init_io(struct scsi_cmnd *cmd)
 	 */
 	count = __blk_rq_map_sg(rq->q, rq, cmd->sdb.table.sgl, &last_sg);
 
+	if (blk_rq_bytes(rq) & rq->q->dma_pad_mask) {
+		unsigned int pad_len =
+			(rq->q->dma_pad_mask & ~blk_rq_bytes(rq)) + 1;
+
+		last_sg->length += pad_len;
+		cmd->extra_len += pad_len;
+	}
+
 	if (need_drain) {
 		sg_unmark_end(last_sg);
 		last_sg = sg_next(last_sg);
 		sg_set_buf(last_sg, sdev->dma_drain_buf, sdev->dma_drain_len);
 		sg_mark_end(last_sg);
 
-		rq->extra_len += sdev->dma_drain_len;
+		cmd->extra_len += sdev->dma_drain_len;
 		count++;
 	}
 

commit cc97923a5bccc776851c242b61015faf288d5c22
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Apr 14 09:42:24 2020 +0200

    block: move dma drain handling to scsi
    
    Don't burden the common block code with with specifics of the libata DMA
    draining mechanism.  Instead move most of the code to the scsi midlayer.
    
    That also means the nr_phys_segments adjustments in the blk-mq fast path
    can go away entirely, given that SCSI never looks at nr_phys_segments
    after mapping the request to a scatterlist.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4e42acbb3f32..88cac92fc153 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -978,6 +978,14 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		scsi_io_completion_action(cmd, result);
 }
 
+static inline bool scsi_cmd_needs_dma_drain(struct scsi_device *sdev,
+		struct request *rq)
+{
+	return sdev->dma_drain_len && blk_rq_is_passthrough(rq) &&
+	       !op_is_write(req_op(rq)) &&
+	       sdev->host->hostt->dma_need_drain(rq);
+}
+
 /*
  * Function:    scsi_init_io()
  *
@@ -991,26 +999,47 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
  */
 blk_status_t scsi_init_io(struct scsi_cmnd *cmd)
 {
+	struct scsi_device *sdev = cmd->device;
 	struct request *rq = cmd->request;
+	unsigned short nr_segs = blk_rq_nr_phys_segments(rq);
+	struct scatterlist *last_sg = NULL;
 	blk_status_t ret;
+	bool need_drain = scsi_cmd_needs_dma_drain(sdev, rq);
 	int count;
 
-	if (WARN_ON_ONCE(!blk_rq_nr_phys_segments(rq)))
+	if (WARN_ON_ONCE(!nr_segs))
 		return BLK_STS_IOERR;
 
+	/*
+	 * Make sure there is space for the drain.  The driver must adjust
+	 * max_hw_segments to be prepared for this.
+	 */
+	if (need_drain)
+		nr_segs++;
+
 	/*
 	 * If sg table allocation fails, requeue request later.
 	 */
-	if (unlikely(sg_alloc_table_chained(&cmd->sdb.table,
-			blk_rq_nr_phys_segments(rq), cmd->sdb.table.sgl,
-			SCSI_INLINE_SG_CNT)))
+	if (unlikely(sg_alloc_table_chained(&cmd->sdb.table, nr_segs,
+			cmd->sdb.table.sgl, SCSI_INLINE_SG_CNT)))
 		return BLK_STS_RESOURCE;
 
 	/*
 	 * Next, walk the list, and fill in the addresses and sizes of
 	 * each segment.
 	 */
-	count = blk_rq_map_sg(rq->q, rq, cmd->sdb.table.sgl);
+	count = __blk_rq_map_sg(rq->q, rq, cmd->sdb.table.sgl, &last_sg);
+
+	if (need_drain) {
+		sg_unmark_end(last_sg);
+		last_sg = sg_next(last_sg);
+		sg_set_buf(last_sg, sdev->dma_drain_buf, sdev->dma_drain_len);
+		sg_mark_end(last_sg);
+
+		rq->extra_len += sdev->dma_drain_len;
+		count++;
+	}
+
 	BUG_ON(count > cmd->sdb.table.nents);
 	cmd->sdb.table.nents = count;
 	cmd->sdb.length = blk_rq_payload_bytes(rq);

commit 0475bd6c65976c390e3805a1e5f10fc30ca8def2
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Apr 14 09:42:23 2020 +0200

    scsi: merge scsi_init_sgtable into scsi_init_io
    
    scsi_init_io is the only caller of scsi_init_sgtable.  Merge the two
    function to make upcoming changes a little easier.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ea18f618dc66..4e42acbb3f32 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -978,30 +978,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		scsi_io_completion_action(cmd, result);
 }
 
-static blk_status_t scsi_init_sgtable(struct request *req,
-		struct scsi_data_buffer *sdb)
-{
-	int count;
-
-	/*
-	 * If sg table allocation fails, requeue request later.
-	 */
-	if (unlikely(sg_alloc_table_chained(&sdb->table,
-			blk_rq_nr_phys_segments(req), sdb->table.sgl,
-			SCSI_INLINE_SG_CNT)))
-		return BLK_STS_RESOURCE;
-
-	/* 
-	 * Next, walk the list, and fill in the addresses and sizes of
-	 * each segment.
-	 */
-	count = blk_rq_map_sg(req->q, req, sdb->table.sgl);
-	BUG_ON(count > sdb->table.nents);
-	sdb->table.nents = count;
-	sdb->length = blk_rq_payload_bytes(req);
-	return BLK_STS_OK;
-}
-
 /*
  * Function:    scsi_init_io()
  *
@@ -1017,17 +993,31 @@ blk_status_t scsi_init_io(struct scsi_cmnd *cmd)
 {
 	struct request *rq = cmd->request;
 	blk_status_t ret;
+	int count;
 
 	if (WARN_ON_ONCE(!blk_rq_nr_phys_segments(rq)))
 		return BLK_STS_IOERR;
 
-	ret = scsi_init_sgtable(rq, &cmd->sdb);
-	if (ret)
-		return ret;
+	/*
+	 * If sg table allocation fails, requeue request later.
+	 */
+	if (unlikely(sg_alloc_table_chained(&cmd->sdb.table,
+			blk_rq_nr_phys_segments(rq), cmd->sdb.table.sgl,
+			SCSI_INLINE_SG_CNT)))
+		return BLK_STS_RESOURCE;
+
+	/*
+	 * Next, walk the list, and fill in the addresses and sizes of
+	 * each segment.
+	 */
+	count = blk_rq_map_sg(rq->q, rq, cmd->sdb.table.sgl);
+	BUG_ON(count > cmd->sdb.table.nents);
+	cmd->sdb.table.nents = count;
+	cmd->sdb.length = blk_rq_payload_bytes(rq);
 
 	if (blk_integrity_rq(rq)) {
 		struct scsi_data_buffer *prot_sdb = cmd->prot_sdb;
-		int ivecs, count;
+		int ivecs;
 
 		if (WARN_ON_ONCE(!prot_sdb)) {
 			/*

commit 6cbb7aeded716b8660ee5d4b3dc082f791cdebaa
Author: Dexuan Cui <decui@microsoft.com>
Date:   Fri Apr 17 17:40:45 2020 -0700

    scsi: core: Allow the state change from SDEV_QUIESCE to SDEV_BLOCK
    
    The APIs scsi_host_block()/scsi_host_unblock() were recently added by
    commit 2bb955840c1d ("scsi: core: add scsi_host_(block,unblock) helper
    function") and so far the APIs are only used by: commit 3d3ca53b1639
    ("scsi: aacraid: use scsi_host_(block,unblock) to block I/O").
    
    However, from reading the code, I think the APIs don't really work for
    aacraid, because, in the resume path of hibernation, when aac_suspend() ->
    scsi_host_block() is called, scsi_device_quiesce() has set the state to
    SDEV_QUIESCE, so aac_suspend() -> scsi_host_block() returns -EINVAL.
    
    Fix the issue by allowing the state change.
    
    Link: https://lore.kernel.org/r/1587170445-50013-1-git-send-email-decui@microsoft.com
    Fixes: 2bb955840c1d ("scsi: core: add scsi_host_(block,unblock) helper function")
    Reviewed-by: Ewan D. Milne <emilne@redhat.com>
    Reviewed-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Dexuan Cui <decui@microsoft.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 47835c4b4ee0..06c260f6cdae 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2284,6 +2284,7 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 		switch (oldstate) {
 		case SDEV_RUNNING:
 		case SDEV_CREATED_BLOCK:
+		case SDEV_QUIESCE:
 		case SDEV_OFFLINE:
 			break;
 		default:

commit b4fd63f42647110c963d4bfcd526ac48f5a5faff
Author: Douglas Anderson <dianders@chromium.org>
Date:   Mon Apr 20 09:24:54 2020 -0700

    Revert "scsi: core: run queue if SCSI device queue isn't ready and queue is idle"
    
    This reverts commit 7e70aa789d4a0c89dbfbd2c8a974a4df717475ec.
    
    Now that we have the patches ("blk-mq: In blk_mq_dispatch_rq_list()
    "no budget" is a reason to kick") and ("blk-mq: Rerun dispatching in
    the case of budget contention") we should no longer need the fix in
    the SCSI code.  Revert it, resolving conflicts with other patches that
    have touched this code.
    
    With this revert (and the two new patches) I can run the script that
    was in commit 7e70aa789d4a ("scsi: core: run queue if SCSI device
    queue isn't ready and queue is idle") in a loop with no failure.  If I
    do this revert without the two new patches I can easily get a failure.
    
    Signed-off-by: Douglas Anderson <dianders@chromium.org>
    Reviewed-by: Ming Lei <ming.lei@redhat.com>
    Acked-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 47835c4b4ee0..ea18f618dc66 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1610,12 +1610,7 @@ static bool scsi_mq_get_budget(struct blk_mq_hw_ctx *hctx)
 	struct request_queue *q = hctx->queue;
 	struct scsi_device *sdev = q->queuedata;
 
-	if (scsi_dev_queue_ready(q, sdev))
-		return true;
-
-	if (atomic_read(&sdev->device_busy) == 0 && !scsi_device_blocked(sdev))
-		blk_mq_delay_run_hw_queue(hctx, SCSI_QUEUE_DELAY);
-	return false;
+	return scsi_dev_queue_ready(q, sdev);
 }
 
 static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,

commit b0962c53bde9a485c8ebc401fa1dbe821a76bc3e
Author: Ewan D. Milne <emilne@redhat.com>
Date:   Wed Mar 11 10:39:30 2020 -0400

    scsi: core: avoid repetitive logging of device offline messages
    
    Large queues of I/O to offline devices that are eventually submitted when
    devices are unblocked result in a many repeated "rejecting I/O to offline
    device" messages.  These messages can fill up the dmesg buffer in crash
    dumps so no useful prior messages remain.  In addition, if a serial console
    is used, the flood of messages can cause a hard lockup in the console code.
    
    Introduce a flag indicating the message has already been logged for the
    device, and reset the flag when scsi_device_set_state() changes the device
    state.
    
    Link: https://lore.kernel.org/r/20200311143930.20674-1-emilne@redhat.com
    Reviewed-by: Bart van Assche <bvanassche@acm.org>
    Signed-off-by: Ewan D. Milne <emilne@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9f201194c46a..47835c4b4ee0 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1215,8 +1215,11 @@ scsi_prep_state_check(struct scsi_device *sdev, struct request *req)
 		 * commands.  The device must be brought online
 		 * before trying any recovery commands.
 		 */
-		sdev_printk(KERN_ERR, sdev,
-			    "rejecting I/O to offline device\n");
+		if (!sdev->offline_already) {
+			sdev->offline_already = true;
+			sdev_printk(KERN_ERR, sdev,
+				    "rejecting I/O to offline device\n");
+		}
 		return BLK_STS_IOERR;
 	case SDEV_DEL:
 		/*
@@ -2326,6 +2329,7 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 		break;
 
 	}
+	sdev->offline_already = false;
 	sdev->sdev_state = state;
 	return 0;
 

commit 65ca846a53149a1a72cd8d02e7b2e73dd545b834
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Wed Jan 22 19:56:34 2020 -0800

    scsi: core: Introduce {init,exit}_cmd_priv()
    
    The current behavior of the SCSI core is to clear driver-private data
    before preparing a request for submission to the SCSI LLD. Make it possible
    for SCSI LLDs to disable clearing of driver-private data.
    
    These hooks will be used by a later patch, namely "scsi: ufs: Let the SCSI
    core allocate per-command UFS data".
    
    Link: https://lore.kernel.org/r/20200123035637.21848-2-bvanassche@acm.org
    Cc: Tomas Winkler <tomas.winkler@intel.com>
    Cc: Stanley Chu <stanley.chu@mediatek.com>
    Cc: Bean Huo <beanhuo@micron.com>
    Cc: Avri Altman <avri.altman@wdc.com>
    Cc: Can Guo <cang@codeaurora.org>
    Cc: Ming Lei <ming.lei@redhat.com>
    Cc: Johannes Thumshirn <jth@kernel.org>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 258a428a0a3f..9f201194c46a 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1097,7 +1097,7 @@ static void scsi_cleanup_rq(struct request *rq)
 	}
 }
 
-/* Called after a request has been started. */
+/* Called before a request is prepared. See also scsi_mq_prep_fn(). */
 void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 {
 	void *buf = cmd->sense_buffer;
@@ -1105,7 +1105,7 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 	struct request *rq = blk_mq_rq_from_pdu(cmd);
 	unsigned int flags = cmd->flags & SCMD_PRESERVED_FLAGS;
 	unsigned long jiffies_at_alloc;
-	int retries;
+	int retries, to_clear;
 	bool in_flight;
 
 	if (!blk_rq_is_scsi(rq) && !(flags & SCMD_INITIALIZED)) {
@@ -1116,9 +1116,15 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 	jiffies_at_alloc = cmd->jiffies_at_alloc;
 	retries = cmd->retries;
 	in_flight = test_bit(SCMD_STATE_INFLIGHT, &cmd->state);
-	/* zero out the cmd, except for the embedded scsi_request */
-	memset((char *)cmd + sizeof(cmd->req), 0,
-		sizeof(*cmd) - sizeof(cmd->req) + dev->host->hostt->cmd_size);
+	/*
+	 * Zero out the cmd, except for the embedded scsi_request. Only clear
+	 * the driver-private command data if the LLD does not supply a
+	 * function to initialize that data.
+	 */
+	to_clear = sizeof(*cmd) - sizeof(cmd->req);
+	if (!dev->host->hostt->init_cmd_priv)
+		to_clear += dev->host->hostt->cmd_size;
+	memset((char *)cmd + sizeof(cmd->req), 0, to_clear);
 
 	cmd->device = dev;
 	cmd->sense_buffer = buf;
@@ -1711,6 +1717,7 @@ static int scsi_mq_init_request(struct blk_mq_tag_set *set, struct request *rq,
 	const bool unchecked_isa_dma = shost->unchecked_isa_dma;
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
 	struct scatterlist *sg;
+	int ret = 0;
 
 	if (unchecked_isa_dma)
 		cmd->flags |= SCMD_UNCHECKED_ISA_DMA;
@@ -1726,14 +1733,24 @@ static int scsi_mq_init_request(struct blk_mq_tag_set *set, struct request *rq,
 		cmd->prot_sdb = (void *)sg + scsi_mq_inline_sgl_size(shost);
 	}
 
-	return 0;
+	if (shost->hostt->init_cmd_priv) {
+		ret = shost->hostt->init_cmd_priv(shost, cmd);
+		if (ret < 0)
+			scsi_free_sense_buffer(unchecked_isa_dma,
+					       cmd->sense_buffer);
+	}
+
+	return ret;
 }
 
 static void scsi_mq_exit_request(struct blk_mq_tag_set *set, struct request *rq,
 				 unsigned int hctx_idx)
 {
+	struct Scsi_Host *shost = set->driver_data;
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
 
+	if (shost->hostt->exit_cmd_priv)
+		shost->hostt->exit_cmd_priv(shost, cmd);
 	scsi_free_sense_buffer(cmd->flags & SCMD_UNCHECKED_ISA_DMA,
 			       cmd->sense_buffer);
 }

commit c5a9707672fe22865d90fc04ac2fbc4f812666f3
Author: Hannes Reinecke <hare@suse.de>
Date:   Fri Feb 28 08:53:18 2020 +0100

    scsi: core: Remove cmd_list functionality
    
    Remove cmd_list functionality; no users left.  With that the
    scsi_put_command() becomes empty, so remove that one, too.
    
    Link: https://lore.kernel.org/r/20200228075318.91255-14-hare@suse.de
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Bart van Assche <bvanassche@acm.org>
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a48a5727831b..258a428a0a3f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -562,7 +562,6 @@ static void scsi_mq_uninit_cmd(struct scsi_cmnd *cmd)
 {
 	scsi_mq_free_sgtables(cmd);
 	scsi_uninit_cmd(cmd);
-	scsi_del_cmd_from_list(cmd);
 }
 
 /* Returns false when no more bytes to process, true if there are more */
@@ -1098,35 +1097,6 @@ static void scsi_cleanup_rq(struct request *rq)
 	}
 }
 
-/* Add a command to the list used by the aacraid and dpt_i2o drivers */
-void scsi_add_cmd_to_list(struct scsi_cmnd *cmd)
-{
-	struct scsi_device *sdev = cmd->device;
-	struct Scsi_Host *shost = sdev->host;
-	unsigned long flags;
-
-	if (shost->use_cmd_list) {
-		spin_lock_irqsave(&sdev->list_lock, flags);
-		list_add_tail(&cmd->list, &sdev->cmd_list);
-		spin_unlock_irqrestore(&sdev->list_lock, flags);
-	}
-}
-
-/* Remove a command from the list used by the aacraid and dpt_i2o drivers */
-void scsi_del_cmd_from_list(struct scsi_cmnd *cmd)
-{
-	struct scsi_device *sdev = cmd->device;
-	struct Scsi_Host *shost = sdev->host;
-	unsigned long flags;
-
-	if (shost->use_cmd_list) {
-		spin_lock_irqsave(&sdev->list_lock, flags);
-		BUG_ON(list_empty(&cmd->list));
-		list_del_init(&cmd->list);
-		spin_unlock_irqrestore(&sdev->list_lock, flags);
-	}
-}
-
 /* Called after a request has been started. */
 void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 {
@@ -1160,7 +1130,6 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 	if (in_flight)
 		__set_bit(SCMD_STATE_INFLIGHT, &cmd->state);
 
-	scsi_add_cmd_to_list(cmd);
 }
 
 static blk_status_t scsi_setup_scsi_cmnd(struct scsi_device *sdev,

commit 2bb955840c1dc44746af8a7873d9a0ba70debbd6
Author: Hannes Reinecke <hare@suse.de>
Date:   Fri Feb 28 08:53:13 2020 +0100

    scsi: core: add scsi_host_(block,unblock) helper function
    
    Add helper functions to call scsi_internal_device_block()/
    scsi_internal_device_unblock() for all attached devices on a SCSI host.
    
    Link: https://lore.kernel.org/r/20200228075318.91255-9-hare@suse.de
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 610ee41fa54c..a48a5727831b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2845,6 +2845,36 @@ scsi_target_unblock(struct device *dev, enum scsi_device_state new_state)
 }
 EXPORT_SYMBOL_GPL(scsi_target_unblock);
 
+int
+scsi_host_block(struct Scsi_Host *shost)
+{
+	struct scsi_device *sdev;
+	int ret = 0;
+
+	shost_for_each_device(sdev, shost) {
+		ret = scsi_internal_device_block(sdev);
+		if (ret)
+			break;
+	}
+	return ret;
+}
+EXPORT_SYMBOL_GPL(scsi_host_block);
+
+int
+scsi_host_unblock(struct Scsi_Host *shost, int new_state)
+{
+	struct scsi_device *sdev;
+	int ret = 0;
+
+	shost_for_each_device(sdev, shost) {
+		ret = scsi_internal_device_unblock(sdev, new_state);
+		if (ret)
+			break;
+	}
+	return ret;
+}
+EXPORT_SYMBOL_GPL(scsi_host_unblock);
+
 /**
  * scsi_kmap_atomic_sg - find and atomically map an sg-elemnt
  * @sgl:	scatter-gather list

commit 0ec96913344de9efdb388720247ea9f207bdc3aa
Author: Can Guo <cang@codeaurora.org>
Date:   Thu Dec 5 02:14:25 2019 +0000

    scsi: core: Adjust DBD setting in MODE SENSE for caching mode page per LLD
    
    UFS JEDEC standards require DBD field to be set to 1 in mode sense
    command.  This patch allows LLD to define the setting of DBD, if
    required.
    
    Link: https://lore.kernel.org/r/0101016ed3d643f9-ffd45d6c-c593-4a13-a18f-a32da3d3bb97-000000@us-west-2.amazonses.com
    Reviewed-by: Avri Altman <avri.altman@wdc.com>
    Signed-off-by: Can Guo <cang@codeaurora.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 3e7a45d0daca..610ee41fa54c 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2108,6 +2108,8 @@ scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
 
 	memset(data, 0, sizeof(*data));
 	memset(&cmd[0], 0, 12);
+
+	dbd = sdev->set_dbd_for_ms ? 8 : dbd;
 	cmd[1] = dbd & 0x18;	/* allows DBD and LLBA bits */
 	cmd[2] = modepage;
 

commit ef2cc88e2a205b8a11a19e78db63a70d3728cdf5
Merge: 937d6eefc716 65309ef6b258
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Dec 2 13:37:02 2019 -0800

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This is mostly update of the usual drivers: aacraid, ufs, zfcp,
      NCR5380, lpfc, qla2xxx, smartpqi, hisi_sas, target, mpt3sas, pm80xx
      plus a whole load of minor updates and fixes.
    
      The major core changes are Al Viro's reworking of sg's handling of
      copy to/from user, Ming Lei's removal of the host busy counter to
      avoid contention in the multiqueue case and Damien Le Moal's fixing of
      residual tracking across error handling"
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (251 commits)
      scsi: bnx2fc: timeout calculation invalid for bnx2fc_eh_abort()
      scsi: target: core: Fix a pr_debug() argument
      scsi: iscsi: Don't send data to unbound connection
      scsi: target: iscsi: Wait for all commands to finish before freeing a session
      scsi: target: core: Release SPC-2 reservations when closing a session
      scsi: target: core: Document target_cmd_size_check()
      scsi: bnx2i: fix potential use after free
      Revert "scsi: qla2xxx: Fix memory leak when sending I/O fails"
      scsi: NCR5380: Add disconnect_mask module parameter
      scsi: NCR5380: Unconditionally clear ICR after do_abort()
      scsi: NCR5380: Call scsi_set_resid() on command completion
      scsi: scsi_debug: num_tgts must be >= 0
      scsi: lpfc: use hdwq assigned cpu for allocation
      scsi: arcmsr: fix indentation issues
      scsi: qla4xxx: fix double free bug
      scsi: pm80xx: Modified the logic to collect fatal dump
      scsi: pm80xx: Tie the interrupt name to the module instance
      scsi: pm80xx: Controller fatal error through sysfs
      scsi: pm80xx: Do not request 12G sas speeds
      scsi: pm80xx: Cleanup command when a reset times out
      ...

commit 72d5ac679e246c15d94a00d53a6289e142cfcf86
Merge: 31f4f5b495a6 9393c8de628c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 11 09:14:36 2019 -0800

    Merge tag 'scsi-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI fixes from James Bottomley:
     "Three small changes: two in the core and one in the qla2xxx driver.
    
      The sg_tablesize fix affects a thinko in the migration to blk-mq of
      certain legacy drivers which could cause an oops and the sd core
      change should only affect zoned block devices which were wrongly
      suppressing error messages for reset all zones"
    
    * tag 'scsi-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi:
      scsi: core: Handle drivers which set sg_tablesize to zero
      scsi: qla2xxx: fix NPIV tear down process
      scsi: sd_zbc: Fix sd_zbc_complete()

commit 9393c8de628cf0968d81a17cc11841e42191e041
Author: Michael Schmitz <schmitzmic@gmail.com>
Date:   Tue Nov 5 15:49:10 2019 +1300

    scsi: core: Handle drivers which set sg_tablesize to zero
    
    In scsi_mq_setup_tags(), cmd_size is calculated based on zero size for the
    scatter-gather list in case the low level driver uses SG_NONE in its host
    template.
    
    cmd_size is passed on to the block layer for calculation of the request
    size, and we've seen NULL pointer dereference errors from the block layer
    in drivers where SG_NONE is used and a mq IO scheduler is active,
    apparently as a consequence of this (see commit 68ab2d76e4be ("scsi:
    cxlflash: Set sg_tablesize to 1 instead of SG_NONE"), and a recent patch by
    Finn Thain converting the three m68k NFR5380 drivers to avoid setting
    SG_NONE).
    
    Try to avoid these errors by accounting for at least one sg list entry when
    calculating cmd_size, regardless of whether the low level driver set a zero
    sg_tablesize.
    
    Tested on 030 m68k with the atari_scsi driver - setting sg_tablesize to
    SG_NONE no longer results in a crash when loading this driver.
    
    CC: Finn Thain <fthain@telegraphics.com.au>
    Link: https://lore.kernel.org/r/1572922150-4358-1-git-send-email-schmitzmic@gmail.com
    Signed-off-by: Michael Schmitz <schmitzmic@gmail.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index dc210b9d4896..3a352a4601b1 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1882,7 +1882,8 @@ int scsi_mq_setup_tags(struct Scsi_Host *shost)
 {
 	unsigned int cmd_size, sgl_size;
 
-	sgl_size = scsi_mq_inline_sgl_size(shost);
+	sgl_size = max_t(unsigned int, sizeof(struct scatterlist),
+				scsi_mq_inline_sgl_size(shost));
 	cmd_size = sizeof(struct scsi_cmnd) + shost->hostt->cmd_size + sgl_size;
 	if (scsi_host_get_prot(shost))
 		cmd_size += sizeof(struct scsi_data_buffer) +

commit 6eb045e092efefafc6687409a6fa6d1dabf0fb69
Author: Ming Lei <ming.lei@redhat.com>
Date:   Fri Oct 25 14:58:55 2019 +0800

    scsi: core: avoid host-wide host_busy counter for scsi_mq
    
    It isn't necessary to check the host depth in scsi_queue_rq() any more
    since it has been respected by blk-mq before calling scsi_queue_rq() via
    getting driver tag.
    
    Lots of LUNs may attach to same host and per-host IOPS may reach millions,
    so we should avoid expensive atomic operations on the host-wide counter in
    the IO path.
    
    This patch implements scsi_host_busy() via blk_mq_tagset_busy_iter() with
    one scsi command state for reading the count of busy IOs for scsi_mq.
    
    It is observed that IOPS is increased by 15% in IO test on scsi_debug (32
    LUNs, 32 submit queues, 1024 can_queue, libaio/dio) in a dual-socket
    system.
    
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Ewan D. Milne <emilne@redhat.com>
    Cc: Omar Sandoval <osandov@fb.com>,
    Cc: "Martin K. Petersen" <martin.petersen@oracle.com>,
    Cc: James Bottomley <james.bottomley@hansenpartnership.com>,
    Cc: Christoph Hellwig <hch@lst.de>,
    Cc: Kashyap Desai <kashyap.desai@broadcom.com>
    Cc: Hannes Reinecke <hare@suse.de>
    Cc: Laurence Oberman <loberman@redhat.com>
    Cc: Bart Van Assche <bvanassche@acm.org>
    Link: https://lore.kernel.org/r/20191025065855.6309-1-ming.lei@redhat.com
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Reviewed-by: Jens Axboe <axboe@kernel.dk>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index dc210b9d4896..2563b061f56b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -189,7 +189,7 @@ static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, bool unbusy)
 	 * active on the host/device.
 	 */
 	if (unbusy)
-		scsi_device_unbusy(device);
+		scsi_device_unbusy(device, cmd);
 
 	/*
 	 * Requeue this command.  It will go before all other commands
@@ -321,20 +321,20 @@ static void scsi_init_cmd_errh(struct scsi_cmnd *cmd)
 }
 
 /*
- * Decrement the host_busy counter and wake up the error handler if necessary.
- * Avoid as follows that the error handler is not woken up if shost->host_busy
- * == shost->host_failed: use call_rcu() in scsi_eh_scmd_add() in combination
- * with an RCU read lock in this function to ensure that this function in its
- * entirety either finishes before scsi_eh_scmd_add() increases the
+ * Wake up the error handler if necessary. Avoid as follows that the error
+ * handler is not woken up if host in-flight requests number ==
+ * shost->host_failed: use call_rcu() in scsi_eh_scmd_add() in combination
+ * with an RCU read lock in this function to ensure that this function in
+ * its entirety either finishes before scsi_eh_scmd_add() increases the
  * host_failed counter or that it notices the shost state change made by
  * scsi_eh_scmd_add().
  */
-static void scsi_dec_host_busy(struct Scsi_Host *shost)
+static void scsi_dec_host_busy(struct Scsi_Host *shost, struct scsi_cmnd *cmd)
 {
 	unsigned long flags;
 
 	rcu_read_lock();
-	atomic_dec(&shost->host_busy);
+	__clear_bit(SCMD_STATE_INFLIGHT, &cmd->state);
 	if (unlikely(scsi_host_in_recovery(shost))) {
 		spin_lock_irqsave(shost->host_lock, flags);
 		if (shost->host_failed || shost->host_eh_scheduled)
@@ -344,12 +344,12 @@ static void scsi_dec_host_busy(struct Scsi_Host *shost)
 	rcu_read_unlock();
 }
 
-void scsi_device_unbusy(struct scsi_device *sdev)
+void scsi_device_unbusy(struct scsi_device *sdev, struct scsi_cmnd *cmd)
 {
 	struct Scsi_Host *shost = sdev->host;
 	struct scsi_target *starget = scsi_target(sdev);
 
-	scsi_dec_host_busy(shost);
+	scsi_dec_host_busy(shost, cmd);
 
 	if (starget->can_queue > 0)
 		atomic_dec(&starget->target_busy);
@@ -430,9 +430,6 @@ static inline bool scsi_target_is_busy(struct scsi_target *starget)
 
 static inline bool scsi_host_is_busy(struct Scsi_Host *shost)
 {
-	if (shost->can_queue > 0 &&
-	    atomic_read(&shost->host_busy) >= shost->can_queue)
-		return true;
 	if (atomic_read(&shost->host_blocked) > 0)
 		return true;
 	if (shost->host_self_blocked)
@@ -1139,6 +1136,7 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 	unsigned int flags = cmd->flags & SCMD_PRESERVED_FLAGS;
 	unsigned long jiffies_at_alloc;
 	int retries;
+	bool in_flight;
 
 	if (!blk_rq_is_scsi(rq) && !(flags & SCMD_INITIALIZED)) {
 		flags |= SCMD_INITIALIZED;
@@ -1147,6 +1145,7 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 
 	jiffies_at_alloc = cmd->jiffies_at_alloc;
 	retries = cmd->retries;
+	in_flight = test_bit(SCMD_STATE_INFLIGHT, &cmd->state);
 	/* zero out the cmd, except for the embedded scsi_request */
 	memset((char *)cmd + sizeof(cmd->req), 0,
 		sizeof(*cmd) - sizeof(cmd->req) + dev->host->hostt->cmd_size);
@@ -1158,6 +1157,8 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 	INIT_DELAYED_WORK(&cmd->abort_work, scmd_eh_abort_handler);
 	cmd->jiffies_at_alloc = jiffies_at_alloc;
 	cmd->retries = retries;
+	if (in_flight)
+		__set_bit(SCMD_STATE_INFLIGHT, &cmd->state);
 
 	scsi_add_cmd_to_list(cmd);
 }
@@ -1367,16 +1368,14 @@ static inline int scsi_target_queue_ready(struct Scsi_Host *shost,
  */
 static inline int scsi_host_queue_ready(struct request_queue *q,
 				   struct Scsi_Host *shost,
-				   struct scsi_device *sdev)
+				   struct scsi_device *sdev,
+				   struct scsi_cmnd *cmd)
 {
-	unsigned int busy;
-
 	if (scsi_host_in_recovery(shost))
 		return 0;
 
-	busy = atomic_inc_return(&shost->host_busy) - 1;
 	if (atomic_read(&shost->host_blocked) > 0) {
-		if (busy)
+		if (scsi_host_busy(shost) > 0)
 			goto starved;
 
 		/*
@@ -1390,8 +1389,6 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 				     "unblocking host at zero depth\n"));
 	}
 
-	if (shost->can_queue > 0 && busy >= shost->can_queue)
-		goto starved;
 	if (shost->host_self_blocked)
 		goto starved;
 
@@ -1403,6 +1400,8 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 		spin_unlock_irq(shost->host_lock);
 	}
 
+	__set_bit(SCMD_STATE_INFLIGHT, &cmd->state);
+
 	return 1;
 
 starved:
@@ -1411,7 +1410,7 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 		list_add_tail(&sdev->starved_entry, &shost->starved_list);
 	spin_unlock_irq(shost->host_lock);
 out_dec:
-	scsi_dec_host_busy(shost);
+	scsi_dec_host_busy(shost, cmd);
 	return 0;
 }
 
@@ -1665,7 +1664,7 @@ static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	ret = BLK_STS_RESOURCE;
 	if (!scsi_target_queue_ready(shost, sdev))
 		goto out_put_budget;
-	if (!scsi_host_queue_ready(q, shost, sdev))
+	if (!scsi_host_queue_ready(q, shost, sdev, cmd))
 		goto out_dec_target_busy;
 
 	if (!(req->rq_flags & RQF_DONTPREP)) {
@@ -1697,7 +1696,7 @@ static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	return BLK_STS_OK;
 
 out_dec_host_busy:
-	scsi_dec_host_busy(shost);
+	scsi_dec_host_busy(shost, cmd);
 out_dec_target_busy:
 	if (scsi_target(sdev)->can_queue > 0)
 		atomic_dec(&scsi_target(sdev)->target_busy);

commit 6b6fa7a5c86e1269d9f0c9a5b902072351317387
Author: Steffen Maier <maier@linux.ibm.com>
Date:   Wed Aug 7 16:49:48 2019 +0200

    scsi: core: fix dh and multipathing for SCSI hosts without request batching
    
    This was missing from scsi_device_from_queue() due to the introduction of
    another new scsi_mq_ops_no_commit of linux-next commit 8930a6c20791 ("scsi:
    core: add support for request batching") from Martin's scsi/5.4/scsi-queue
    or James' scsi/misc.
    
    Only devicehandler code seems to call scsi_device_from_queue():
    *** drivers/scsi/scsi_dh.c:
    scsi_dh_activate[255]          sdev = scsi_device_from_queue(q);
    scsi_dh_set_params[302]        sdev = scsi_device_from_queue(q);
    scsi_dh_attach[325]            sdev = scsi_device_from_queue(q);
    scsi_dh_attached_handler_name[363] sdev = scsi_device_from_queue(q);
    
    Fixes multipath tools follow-on errors:
    
    $ multipath -v6
    ...
    libdevmapper: ioctl/libdm-iface.c(1887): device-mapper: reload ioctl on mpatha  failed: No such device
    ...
    mpatha: failed to load map, error 19
    ...
    
    showing also as kernel messages:
    
    device-mapper: table: 252:0: multipath: error attaching hardware handler
    device-mapper: ioctl: error adding target to table
    
    Signed-off-by: Steffen Maier <maier@linux.ibm.com>
    Fixes: 8930a6c20791 ("scsi: core: add support for request batching")
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 12db0c13a927..5447738906ac 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1922,7 +1922,8 @@ struct scsi_device *scsi_device_from_queue(struct request_queue *q)
 {
 	struct scsi_device *sdev = NULL;
 
-	if (q->mq_ops == &scsi_mq_ops)
+	if (q->mq_ops == &scsi_mq_ops_no_commit ||
+	    q->mq_ops == &scsi_mq_ops)
 		sdev = q->queuedata;
 	if (!sdev || !get_device(&sdev->sdev_gendev))
 		sdev = NULL;

commit 82a9ac7130cf51c2640800fb0ef19d3a05cb8fff
Author: Steffen Maier <maier@linux.ibm.com>
Date:   Wed Aug 7 16:49:47 2019 +0200

    scsi: core: fix missing .cleanup_rq for SCSI hosts without request batching
    
    This was missing from scsi_mq_ops_no_commit of linux-next commit
    8930a6c20791 ("scsi: core: add support for request batching") from Martin's
    scsi/5.4/scsi-queue or James' scsi/misc.
    
    See also linux-next commit b7e9e1fb7a92 ("scsi: implement .cleanup_rq
    callback") from block/for-next.
    
    Signed-off-by: Steffen Maier <maier@linux.ibm.com>
    Fixes: 8930a6c20791 ("scsi: core: add support for request batching")
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Ming Lei <ming.lei@redhat.com>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index dc210b9d4896..12db0c13a927 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1834,6 +1834,7 @@ static const struct blk_mq_ops scsi_mq_ops_no_commit = {
 	.init_request	= scsi_mq_init_request,
 	.exit_request	= scsi_mq_exit_request,
 	.initialize_rq_fn = scsi_initialize_rq,
+	.cleanup_rq	= scsi_cleanup_rq,
 	.busy		= scsi_mq_lld_busy,
 	.map_queues	= scsi_map_queues,
 };

commit 10fd71780f7d155f4e35fecfad0ebd4a725a244b
Merge: 3e414b5bd28f e74006edd0d4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Sep 21 10:50:15 2019 -0700

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This is mostly update of the usual drivers: qla2xxx, ufs, smartpqi,
      lpfc, hisi_sas, qedf, mpt3sas; plus a whole load of minor updates. The
      only core change this time around is the addition of request batching
      for virtio. Since batching requires an additional flag to use, it
      should be invisible to the rest of the drivers"
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (264 commits)
      scsi: hisi_sas: Fix the conflict between device gone and host reset
      scsi: hisi_sas: Add BIST support for phy loopback
      scsi: hisi_sas: Add hisi_sas_debugfs_alloc() to centralise allocation
      scsi: hisi_sas: Remove some unused function arguments
      scsi: hisi_sas: Remove redundant work declaration
      scsi: hisi_sas: Remove hisi_sas_hw.slot_complete
      scsi: hisi_sas: Assign NCQ tag for all NCQ commands
      scsi: hisi_sas: Update all the registers after suspend and resume
      scsi: hisi_sas: Retry 3 times TMF IO for SAS disks when init device
      scsi: hisi_sas: Remove sleep after issue phy reset if sas_smp_phy_control() fails
      scsi: hisi_sas: Directly return when running I_T_nexus reset if phy disabled
      scsi: hisi_sas: Use true/false as input parameter of sas_phy_reset()
      scsi: hisi_sas: add debugfs auto-trigger for internal abort time out
      scsi: virtio_scsi: unplug LUNs when events missed
      scsi: scsi_dh_rdac: zero cdb in send_mode_select()
      scsi: fcoe: fix null-ptr-deref Read in fc_release_transport
      scsi: ufs-hisi: use devm_platform_ioremap_resource() to simplify code
      scsi: ufshcd: use devm_platform_ioremap_resource() to simplify code
      scsi: hisi_sas: use devm_platform_ioremap_resource() to simplify code
      scsi: ufs: Use kmemdup in ufshcd_read_string_desc()
      ...

commit 94ef80a5f0d72376a0dd2cfed0bd123123b405e2
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Thu Aug 1 15:38:13 2019 -0700

    scsi: core: Complain if scsi_target_block() fails
    
    If scsi_target_block() fails that can break the code that calls this
    function. Hence complain loudly if scsi_target_block() fails.
    
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Cc: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 7a4ac7a8e907..d47d637e6be2 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2772,7 +2772,12 @@ static int scsi_internal_device_unblock(struct scsi_device *sdev,
 static void
 device_block(struct scsi_device *sdev, void *data)
 {
-	scsi_internal_device_block(sdev);
+	int ret;
+
+	ret = scsi_internal_device_block(sdev);
+
+	WARN_ONCE(ret, "scsi_internal_device_block(%s) failed: ret = %d\n",
+		  dev_name(&sdev->sdev_gendev), ret);
 }
 
 static int

commit 09addb1d169ed2e67a0314e6275b42e7b8605d79
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Thu Aug 1 15:38:12 2019 -0700

    scsi: core: Make scsi_internal_device_unblock_nowait() reject invalid new_state
    
    The only 'new_state' values passed by upstream kernel code to
    scsi_internal_device_unblock_nowait() are SDEV_RUNNING and
    SDEV_TRANSPORT_OFFLINE. These are the only values that should be passed to
    this function. Hence check the value of the 'new_state' argument to avoid
    that scsi_internal_device_unblock_nowait() would be used to trigger an
    illegal SCSI device state transition. In this context 'illegal' means not
    allowed by scsi_device_set_state().
    
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Cc: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c72bce2f0cf1..7a4ac7a8e907 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2707,6 +2707,14 @@ void scsi_start_queue(struct scsi_device *sdev)
 int scsi_internal_device_unblock_nowait(struct scsi_device *sdev,
 					enum scsi_device_state new_state)
 {
+	switch (new_state) {
+	case SDEV_RUNNING:
+	case SDEV_TRANSPORT_OFFLINE:
+		break;
+	default:
+		return -EINVAL;
+	}
+
 	/*
 	 * Try to transition the scsi device to SDEV_RUNNING or one of the
 	 * offlined states and goose the device queue if successful.

commit b7e9e1fb7a9227be34ad4a5e778022c3164494cf
Author: Ming Lei <ming.lei@redhat.com>
Date:   Thu Jul 25 10:05:00 2019 +0800

    scsi: implement .cleanup_rq callback
    
    Implement .cleanup_rq() callback for freeing driver private part
    of the request. Then we can avoid to leak this part if the request isn't
    completed by SCSI, and freed by blk-mq or upper layer(such as dm-rq) finally.
    
    Cc: Ewan D. Milne <emilne@redhat.com>
    Cc: Bart Van Assche <bvanassche@acm.org>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: dm-devel@redhat.com
    Cc: <stable@vger.kernel.org>
    Fixes: 396eaf21ee17 ("blk-mq: improve DM's blk-mq IO merging via blk_insert_cloned_request feedback")
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 11e64b50497f..4e88d7e9cf9a 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1089,6 +1089,18 @@ static void scsi_initialize_rq(struct request *rq)
 	cmd->retries = 0;
 }
 
+/*
+ * Only called when the request isn't completed by SCSI, and not freed by
+ * SCSI
+ */
+static void scsi_cleanup_rq(struct request *rq)
+{
+	if (rq->rq_flags & RQF_DONTPREP) {
+		scsi_mq_uninit_cmd(blk_mq_rq_to_pdu(rq));
+		rq->rq_flags &= ~RQF_DONTPREP;
+	}
+}
+
 /* Add a command to the list used by the aacraid and dpt_i2o drivers */
 void scsi_add_cmd_to_list(struct scsi_cmnd *cmd)
 {
@@ -1821,6 +1833,7 @@ static const struct blk_mq_ops scsi_mq_ops = {
 	.init_request	= scsi_mq_init_request,
 	.exit_request	= scsi_mq_exit_request,
 	.initialize_rq_fn = scsi_initialize_rq,
+	.cleanup_rq	= scsi_cleanup_rq,
 	.busy		= scsi_mq_lld_busy,
 	.map_queues	= scsi_map_queues,
 };

commit 1b5d9a6e98350e0713b4faa1b04e8f239f63b581
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jul 22 11:20:38 2019 +0200

    scsi: core: fix the dma_max_mapping_size call
    
    We should only call dma_max_mapping_size for devices that have a DMA mask
    set, otherwise we can run into a NULL pointer dereference that will crash
    the system.
    
    Also we need to do right shift to get the sectors from the size in bytes,
    not a left shift.
    
    Fixes: bdd17bdef7d8 ("scsi: core: take the DMA max mapping size into account")
    Reported-by: Bart Van Assche <bvanassche@acm.org>
    Reported-by: Ming Lei <tom.leiming@gmail.com>
    Tested-by: Guilherme G. Piccoli <gpiccoli@canonical.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9381171c2fc0..11e64b50497f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1784,8 +1784,10 @@ void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 		blk_queue_max_integrity_segments(q, shost->sg_prot_tablesize);
 	}
 
-	shost->max_sectors = min_t(unsigned int, shost->max_sectors,
-			dma_max_mapping_size(dev) << SECTOR_SHIFT);
+	if (dev->dma_mask) {
+		shost->max_sectors = min_t(unsigned int, shost->max_sectors,
+				dma_max_mapping_size(dev) >> SECTOR_SHIFT);
+	}
 	blk_queue_max_hw_sectors(q, shost->max_sectors);
 	if (shost->unchecked_isa_dma)
 		blk_queue_bounce_limit(q, BLK_BOUNCE_ISA);

commit 8930a6c207918d5a5675eedab06a71096b1a3d47
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Thu May 30 13:28:10 2019 +0200

    scsi: core: add support for request batching
    
    This allows a list of requests to be issued, with the LLD only writing the
    hardware doorbell when necessary, after the last request was prepared.
    This is more efficient if we have lists of requests to issue, particularly
    on virtualized hardware, where writing the doorbell is more expensive than
    on real hardware.
    
    The use case for this is plugged IO, where blk-mq flushes a batch of
    requests all at once.
    
    The API is the same as for blk-mq, just with blk-mq concepts tweaked to
    fit the SCSI subsystem API: the "last" flag in blk_mq_queue_data becomes a
    flag in scsi_cmnd, while the queue_num in the commit_rqs callback is
    extracted from the hctx and passed as a parameter.
    
    The only complication is that blk-mq uses different plugging heuristics
    depending on whether commit_rqs is present or not.  So we have two
    different sets of blk_mq_ops and pick one depending on whether the
    scsi_host template uses commit_rqs or not.
    
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Ming Lei <ming.lei@redhat.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9381171c2fc0..c72bce2f0cf1 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1666,10 +1666,11 @@ static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 		blk_mq_start_request(req);
 	}
 
+	cmd->flags &= SCMD_PRESERVED_FLAGS;
 	if (sdev->simple_tags)
 		cmd->flags |= SCMD_TAGGED;
-	else
-		cmd->flags &= ~SCMD_TAGGED;
+	if (bd->last)
+		cmd->flags |= SCMD_LAST;
 
 	scsi_init_cmd_errh(cmd);
 	cmd->scsi_done = scsi_mq_done;
@@ -1807,10 +1808,37 @@ void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 }
 EXPORT_SYMBOL_GPL(__scsi_init_queue);
 
+static const struct blk_mq_ops scsi_mq_ops_no_commit = {
+	.get_budget	= scsi_mq_get_budget,
+	.put_budget	= scsi_mq_put_budget,
+	.queue_rq	= scsi_queue_rq,
+	.complete	= scsi_softirq_done,
+	.timeout	= scsi_timeout,
+#ifdef CONFIG_BLK_DEBUG_FS
+	.show_rq	= scsi_show_rq,
+#endif
+	.init_request	= scsi_mq_init_request,
+	.exit_request	= scsi_mq_exit_request,
+	.initialize_rq_fn = scsi_initialize_rq,
+	.busy		= scsi_mq_lld_busy,
+	.map_queues	= scsi_map_queues,
+};
+
+
+static void scsi_commit_rqs(struct blk_mq_hw_ctx *hctx)
+{
+	struct request_queue *q = hctx->queue;
+	struct scsi_device *sdev = q->queuedata;
+	struct Scsi_Host *shost = sdev->host;
+
+	shost->hostt->commit_rqs(shost, hctx->queue_num);
+}
+
 static const struct blk_mq_ops scsi_mq_ops = {
 	.get_budget	= scsi_mq_get_budget,
 	.put_budget	= scsi_mq_put_budget,
 	.queue_rq	= scsi_queue_rq,
+	.commit_rqs	= scsi_commit_rqs,
 	.complete	= scsi_softirq_done,
 	.timeout	= scsi_timeout,
 #ifdef CONFIG_BLK_DEBUG_FS
@@ -1846,7 +1874,10 @@ int scsi_mq_setup_tags(struct Scsi_Host *shost)
 			sizeof(struct scatterlist) * SCSI_INLINE_PROT_SG_CNT;
 
 	memset(&shost->tag_set, 0, sizeof(shost->tag_set));
-	shost->tag_set.ops = &scsi_mq_ops;
+	if (shost->hostt->commit_rqs)
+		shost->tag_set.ops = &scsi_mq_ops;
+	else
+		shost->tag_set.ops = &scsi_mq_ops_no_commit;
 	shost->tag_set.nr_hw_queues = shost->nr_hw_queues ? : 1;
 	shost->tag_set.queue_depth = shost->can_queue;
 	shost->tag_set.cmd_size = cmd_size;

commit f65420df914a85e33b2c8b1cab310858b2abb7c0
Merge: 168c79971b4a 07d9aa143464
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 20 10:04:58 2019 -0700

    Merge tag 'scsi-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI fixes from James Bottomley:
     "This is the final round of mostly small fixes in our initial submit.
    
      It's mostly minor fixes and driver updates. The only change of note is
      adding a virt_boundary_mask to the SCSI host and host template to
      parametrise this for NVMe devices instead of having them do a call in
      slave_alloc. It's a fairly straightforward conversion except in the
      two NVMe handling drivers that didn't set it who now have a virtual
      infinity parameter added"
    
    * tag 'scsi-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (24 commits)
      scsi: megaraid_sas: set an unlimited max_segment_size
      scsi: mpt3sas: set an unlimited max_segment_size for SAS 3.0 HBAs
      scsi: IB/srp: set virt_boundary_mask in the scsi host
      scsi: IB/iser: set virt_boundary_mask in the scsi host
      scsi: storvsc: set virt_boundary_mask in the scsi host template
      scsi: ufshcd: set max_segment_size in the scsi host template
      scsi: core: take the DMA max mapping size into account
      scsi: core: add a host / host template field for the virt boundary
      scsi: core: Fix race on creating sense cache
      scsi: sd_zbc: Fix compilation warning
      scsi: libfc: fix null pointer dereference on a null lport
      scsi: zfcp: fix GCC compiler warning emitted with -Wmaybe-uninitialized
      scsi: zfcp: fix request object use-after-free in send path causing wrong traces
      scsi: zfcp: fix request object use-after-free in send path causing seqno errors
      scsi: megaraid_sas: Update driver version to 07.710.50.00
      scsi: megaraid_sas: Add module parameter for FW Async event logging
      scsi: megaraid_sas: Enable msix_load_balance for Invader and later controllers
      scsi: megaraid_sas: Fix calculation of target ID
      scsi: lpfc: reduce stack size with CONFIG_GCC_PLUGIN_STRUCTLEAK_VERBOSE
      scsi: devinfo: BLIST_TRY_VPD_PAGES for SanDisk Cruzer Blade
      ...

commit bdd17bdef7d8da4d8eee254abb4c92d8a566bdc1
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jun 17 14:19:54 2019 +0200

    scsi: core: take the DMA max mapping size into account
    
    We need to limit the device's max_sectors to what the DMA mapping
    implementation can support.  If not, we risk running out of swiotlb
    buffers easily.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 404e5e28ef62..699623f81dde 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1784,6 +1784,8 @@ void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 		blk_queue_max_integrity_segments(q, shost->sg_prot_tablesize);
 	}
 
+	shost->max_sectors = min_t(unsigned int, shost->max_sectors,
+			dma_max_mapping_size(dev) << SECTOR_SHIFT);
 	blk_queue_max_hw_sectors(q, shost->max_sectors);
 	if (shost->unchecked_isa_dma)
 		blk_queue_bounce_limit(q, BLK_BOUNCE_ISA);

commit 7ad388d8e4c703980b7018b938cdeec58832d78d
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jun 17 14:19:53 2019 +0200

    scsi: core: add a host / host template field for the virt boundary
    
    This allows drivers setting it up easily instead of branching out to block
    layer calls in slave_alloc, and ensures the upgraded max_segment_size
    setting gets picked up by the DMA layer.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Kashyap Desai < kashyap.desai@broadcom.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 420e2354b36b..404e5e28ef62 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1791,7 +1791,8 @@ void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 	dma_set_seg_boundary(dev, shost->dma_boundary);
 
 	blk_queue_max_segment_size(q, shost->max_segment_size);
-	dma_set_max_seg_size(dev, shost->max_segment_size);
+	blk_queue_virt_boundary(q, shost->virt_boundary_mask);
+	dma_set_max_seg_size(dev, queue_max_segment_size(q));
 
 	/*
 	 * Set a reasonable default alignment:  The larger of 32-byte (dword),

commit f9b0530fa02e0c73f31a49ef743e8f44eb8e32cc
Author: Ming Lei <ming.lei@redhat.com>
Date:   Fri Jul 12 10:08:19 2019 +0800

    scsi: core: Fix race on creating sense cache
    
    When scsi_init_sense_cache(host) is called concurrently from different
    hosts, each code path may find that no cache has been created and
    allocate a new one. The lack of locking can lead to potentially
    overriding a cache allocated by a different host.
    
    Fix the issue by moving 'mutex_lock(&scsi_sense_cache_mutex)' before
    scsi_select_sense_cache().
    
    Fixes: 0a6ac4ee7c21 ("scsi: respect unchecked_isa_dma for blk-mq")
    Cc: Stable <stable@vger.kernel.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Ewan D. Milne <emilne@redhat.com>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ae1c989ef08e..420e2354b36b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -84,11 +84,11 @@ int scsi_init_sense_cache(struct Scsi_Host *shost)
 	struct kmem_cache *cache;
 	int ret = 0;
 
+	mutex_lock(&scsi_sense_cache_mutex);
 	cache = scsi_select_sense_cache(shost->unchecked_isa_dma);
 	if (cache)
-		return 0;
+		goto exit;
 
-	mutex_lock(&scsi_sense_cache_mutex);
 	if (shost->unchecked_isa_dma) {
 		scsi_sense_isadma_cache =
 			kmem_cache_create("scsi_sense_cache(DMA)",
@@ -104,7 +104,7 @@ int scsi_init_sense_cache(struct Scsi_Host *shost)
 		if (!scsi_sense_cache)
 			ret = -ENOMEM;
 	}
-
+ exit:
 	mutex_unlock(&scsi_sense_cache_mutex);
 	return ret;
 }

commit 463cdad83823830dd59572fb81ac243f6a44b589
Author: Maurizio Lombardi <mlombard@redhat.com>
Date:   Tue Jul 2 13:27:05 2019 +0200

    scsi: core: use scmd_printk() to print which command timed out
    
    With a possibly faulty disk the following messages may appear in the logs:
    
    kernel: sd 0:0:9:0: timing out command, waited 180s
    kernel: sd 0:0:9:0: timing out command, waited 20s
    kernel: sd 0:0:9:0: timing out command, waited 20s
    kernel: sd 0:0:9:0: timing out command, waited 60s
    kernel: sd 0:0:9:0: timing out command, waited 20s
    
    This is not very informative because it's not possible to identify the
    command that timed out.
    
    This patch replaces sdev_printk() with scmd_printk().
    
    Signed-off-by: Maurizio Lombardi <mlombard@redhat.com>
    Reviewed-by: Ewan D. Milne <emilne@redhat.com>
    Reviewed-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 83d6dd8067d6..ae1c989ef08e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1452,7 +1452,7 @@ static void scsi_softirq_done(struct request *rq)
 	disposition = scsi_decide_disposition(cmd);
 	if (disposition != SUCCESS &&
 	    time_before(cmd->jiffies_at_alloc + wait_for, jiffies)) {
-		sdev_printk(KERN_ERR, cmd->device,
+		scmd_printk(KERN_ERR, cmd,
 			    "timing out command, waited %lus\n",
 			    wait_for/HZ);
 		disposition = SUCCESS;

commit 1f7563f743d7081710a9d186a8b203997d09f383
Merge: ba6d10ab8014 3e99b3b13a1f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 11 15:17:41 2019 -0700

    Merge tag 'scsi-sg' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI scatter-gather list updates from James Bottomley:
     "This topic branch covers a fundamental change in how our sg lists are
      allocated to make mq more efficient by reducing the size of the
      preallocated sg list.
    
      This necessitates a large number of driver changes because the
      previous guarantee that if a driver specified SG_ALL as the size of
      its scatter list, it would get a non-chained list and didn't need to
      bother with scatterlist iterators is now broken and every driver
      *must* use scatterlist iterators.
    
      This was broken out as a separate topic because we need to convert all
      the drivers before pulling the trigger and unconverted drivers kept
      being found, necessitating a rebase"
    
    * tag 'scsi-sg' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (21 commits)
      scsi: core: don't preallocate small SGL in case of NO_SG_CHAIN
      scsi: lib/sg_pool.c: clear 'first_chunk' in case of no preallocation
      scsi: core: avoid preallocating big SGL for data
      scsi: core: avoid preallocating big SGL for protection information
      scsi: lib/sg_pool.c: improve APIs for allocating sg pool
      scsi: esp: use sg helper to iterate over scatterlist
      scsi: NCR5380: use sg helper to iterate over scatterlist
      scsi: wd33c93: use sg helper to iterate over scatterlist
      scsi: ppa: use sg helper to iterate over scatterlist
      scsi: pcmcia: nsp_cs: use sg helper to iterate over scatterlist
      scsi: imm: use sg helper to iterate over scatterlist
      scsi: aha152x: use sg helper to iterate over scatterlist
      scsi: s390: zfcp_fc: use sg helper to iterate over scatterlist
      scsi: staging: unisys: visorhba: use sg helper to iterate over scatterlist
      scsi: usb: image: microtek: use sg helper to iterate over scatterlist
      scsi: pmcraid: use sg helper to iterate over scatterlist
      scsi: ipr: use sg helper to iterate over scatterlist
      scsi: mvumi: use sg helper to iterate over scatterlist
      scsi: lpfc: use sg helper to iterate over scatterlist
      scsi: advansys: use sg helper to iterate over scatterlist
      ...

commit ba6d10ab8014ac10d25ca513352b6665e73b5785
Merge: 64b08df460cf baf23eddbf2a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 11 15:14:01 2019 -0700

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This is mostly update of the usual drivers: qla2xxx, hpsa, lpfc, ufs,
      mpt3sas, ibmvscsi, megaraid_sas, bnx2fc and hisi_sas as well as the
      removal of the osst driver (I heard from Willem privately that he
      would like the driver removed because all his test hardware has
      failed). Plus number of minor changes, spelling fixes and other
      trivia.
    
      The big merge conflict this time around is the SPDX licence tags.
      Following discussion on linux-next, we believe our version to be more
      accurate than the one in the tree, so the resolution is to take our
      version for all the SPDX conflicts"
    
    Note on the SPDX license tag conversion conflicts: the SCSI tree had
    done its own SPDX conversion, which in some cases conflicted with the
    treewide ones done by Thomas & co.
    
    In almost all cases, the conflicts were purely syntactic: the SCSI tree
    used the old-style SPDX tags ("GPL-2.0" and "GPL-2.0+") while the
    treewide conversion had used the new-style ones ("GPL-2.0-only" and
    "GPL-2.0-or-later").
    
    In these cases I picked the new-style one.
    
    In a few cases, the SPDX conversion was actually different, though.  As
    explained by James above, and in more detail in a pre-pull-request
    thread:
    
     "The other problem is actually substantive: In the libsas code Luben
      Tuikov originally specified gpl 2.0 only by dint of stating:
    
      * This file is licensed under GPLv2.
    
      In all the libsas files, but then muddied the water by quoting GPLv2
      verbatim (which includes the or later than language). So for these
      files Christoph did the conversion to v2 only SPDX tags and Thomas
      converted to v2 or later tags"
    
    So in those cases, where the spdx tag substantially mattered, I took the
    SCSI tree conversion of it, but then also took the opportunity to turn
    the old-style "GPL-2.0" into a new-style "GPL-2.0-only" tag.
    
    Similarly, when there were whitespace differences or other differences
    to the comments around the copyright notices, I took the version from
    the SCSI tree as being the more specific conversion.
    
    Finally, in the spdx conversions that had no conflicts (because the
    treewide ones hadn't been done for those files), I just took the SCSI
    tree version as-is, even if it was old-style.  The old-style conversions
    are perfectly valid, even if the "-only" and "-or-later" versions are
    perhaps more descriptive.
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (185 commits)
      scsi: qla2xxx: move IO flush to the front of NVME rport unregistration
      scsi: qla2xxx: Fix NVME cmd and LS cmd timeout race condition
      scsi: qla2xxx: on session delete, return nvme cmd
      scsi: qla2xxx: Fix kernel crash after disconnecting NVMe devices
      scsi: megaraid_sas: Update driver version to 07.710.06.00-rc1
      scsi: megaraid_sas: Introduce various Aero performance modes
      scsi: megaraid_sas: Use high IOPS queues based on IO workload
      scsi: megaraid_sas: Set affinity for high IOPS reply queues
      scsi: megaraid_sas: Enable coalescing for high IOPS queues
      scsi: megaraid_sas: Add support for High IOPS queues
      scsi: megaraid_sas: Add support for MPI toolbox commands
      scsi: megaraid_sas: Offload Aero RAID5/6 division calculations to driver
      scsi: megaraid_sas: RAID1 PCI bandwidth limit algorithm is applicable for only Ventura
      scsi: megaraid_sas: megaraid_sas: Add check for count returned by HOST_DEVICE_LIST DCMD
      scsi: megaraid_sas: Handle sequence JBOD map failure at driver level
      scsi: megaraid_sas: Don't send FPIO to RL Bypass queue
      scsi: megaraid_sas: In probe context, retry IOC INIT once if firmware is in fault
      scsi: megaraid_sas: Release Mutex lock before OCR in case of DCMD timeout
      scsi: megaraid_sas: Call disable_irq from process IRQ poll
      scsi: megaraid_sas: Remove few debug counters from IO path
      ...

commit 893ca250edfcd0489a49446048aa0d900d6862fc
Merge: baf23eddbf2a 3e99b3b13a1f
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Thu Jun 27 00:19:33 2019 -0400

    Merge branch '5.3/scsi-sg' into scsi-next

commit bbe9fb0d04b96dda1fd7bd973e094004978b2166
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Mon Jun 17 08:18:19 2019 -0700

    scsi: Avoid that .queuecommand() gets called for a blocked SCSI device
    
    Several SCSI transport and LLD drivers surround code that does not
    tolerate concurrent calls of .queuecommand() with scsi_target_block() /
    scsi_target_unblock(). These last two functions use
    blk_mq_quiesce_queue() / blk_mq_unquiesce_queue() for scsi-mq request
    queues to prevent concurrent .queuecommand() calls. However, that is
    not sufficient to prevent .queuecommand() calls from scsi_send_eh_cmnd().
    Hence surround the .queuecommand() call from the SCSI error handler with
    code that avoids that .queuecommand() gets called in the blocked state.
    
    Note: converting the .queuecommand() call in scsi_send_eh_cmnd() into
    code that calls blk_get_request() + blk_execute_rq() is not an option
    since scsi_send_eh_cmnd() must be able to make forward progress even
    if all requests have been allocated.
    
    Cc: Ming Lei <ming.lei@redhat.com>
    Cc: Hannes Reinecke <hare@suse.de>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b1b1a1aaa353..6c84edc53f05 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2616,10 +2616,6 @@ EXPORT_SYMBOL_GPL(scsi_internal_device_block_nowait);
  * a legal transition). When the device is in this state, command processing
  * is paused until the device leaves the SDEV_BLOCK state. See also
  * scsi_internal_device_unblock().
- *
- * To do: avoid that scsi_send_eh_cmnd() calls queuecommand() after
- * scsi_internal_device_block() has blocked a SCSI device and also
- * remove the rport mutex lock and unlock calls from srp_queuecommand().
  */
 static int scsi_internal_device_block(struct scsi_device *sdev)
 {

commit 3e99b3b13a1fc8f7354edaee4c04f73a07faba69
Author: Ming Lei <ming.lei@redhat.com>
Date:   Thu Jun 6 16:34:09 2019 +0800

    scsi: core: don't preallocate small SGL in case of NO_SG_CHAIN
    
    The preallocated small SGL depends on SG_CHAIN so if the ARCH doesn't
    support SG_CHAIN, preallocation of small SGL can't work at all.
    
    Fix this issue by not using small preallocation in case of NO_SG_CHAIN.
    
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Bart Van Assche <bvanassche@acm.org>
    Cc: Ewan D. Milne <emilne@redhat.com>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Guenter Roeck <linux@roeck-us.net>
    Reported-by: Guenter Roeck <linux@roeck-us.net>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Tested-by: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 45b43e97505c..30cbea57ea08 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -43,9 +43,13 @@
  * Size of integrity metadata is usually small, 1 inline sg should
  * cover normal cases.
  */
+#ifdef CONFIG_ARCH_NO_SG_CHAIN
+#define  SCSI_INLINE_PROT_SG_CNT  0
+#define  SCSI_INLINE_SG_CNT  0
+#else
 #define  SCSI_INLINE_PROT_SG_CNT  1
-
 #define  SCSI_INLINE_SG_CNT  2
+#endif
 
 static struct kmem_cache *scsi_sdb_cache;
 static struct kmem_cache *scsi_sense_cache;

commit 3dccdf53c2f38399b11085ded4447ce1467f006c
Author: Ming Lei <ming.lei@redhat.com>
Date:   Sun Apr 28 15:39:32 2019 +0800

    scsi: core: avoid preallocating big SGL for data
    
    scsi_mq_setup_tags() preallocates a big buffer for the IO SGL. The size is
    based on scsi_mq_sgl_size() which is determined based on
    shost->sg_tablesize and SG_CHUNK_SIZE.
    
    Modern DMA engines are often capable of dealing with very big segments so
    the resulting scsi_mq_sgl_size() is often too big. SG_CHUNK_SIZE results in
    a static 4KB SGL allocation per command.
    
    If an HBA has lots of deep queues, preallocation for the sg list can
    consume substantial amounts of memory. For lpfc, nr_hw_queues can be 70
    and each queue's depth 3781. This means the resulting preallocation for
    the data SGL is 70*3781*2K = 517MB.
    
    Switch to runtime allocation for SGL for lists longer than 2 entries. This
    is the approach used by NVMe PCI so it should be reasonable for SCSI as
    well. Runtime SGL allocation has always been the case for the legacy I/O
    path so this is nothing new.
    
    [mkp: attempted to clarify commit desc]
    
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Bart Van Assche <bvanassche@acm.org>
    Cc: Ewan D. Milne <emilne@redhat.com>
    Cc: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c115458c835e..45b43e97505c 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -45,6 +45,8 @@
  */
 #define  SCSI_INLINE_PROT_SG_CNT  1
 
+#define  SCSI_INLINE_SG_CNT  2
+
 static struct kmem_cache *scsi_sdb_cache;
 static struct kmem_cache *scsi_sense_cache;
 static struct kmem_cache *scsi_sense_isadma_cache;
@@ -547,7 +549,8 @@ static void scsi_uninit_cmd(struct scsi_cmnd *cmd)
 static void scsi_mq_free_sgtables(struct scsi_cmnd *cmd)
 {
 	if (cmd->sdb.table.nents)
-		sg_free_table_chained(&cmd->sdb.table, SG_CHUNK_SIZE);
+		sg_free_table_chained(&cmd->sdb.table,
+				SCSI_INLINE_SG_CNT);
 	if (scsi_prot_sg_count(cmd))
 		sg_free_table_chained(&cmd->prot_sdb->table,
 				SCSI_INLINE_PROT_SG_CNT);
@@ -984,7 +987,7 @@ static blk_status_t scsi_init_sgtable(struct request *req,
 	 */
 	if (unlikely(sg_alloc_table_chained(&sdb->table,
 			blk_rq_nr_phys_segments(req), sdb->table.sgl,
-			SG_CHUNK_SIZE)))
+			SCSI_INLINE_SG_CNT)))
 		return BLK_STS_RESOURCE;
 
 	/* 
@@ -1550,9 +1553,9 @@ static int scsi_dispatch_cmd(struct scsi_cmnd *cmd)
 }
 
 /* Size in bytes of the sg-list stored in the scsi-mq command-private data. */
-static unsigned int scsi_mq_sgl_size(struct Scsi_Host *shost)
+static unsigned int scsi_mq_inline_sgl_size(struct Scsi_Host *shost)
 {
-	return min_t(unsigned int, shost->sg_tablesize, SG_CHUNK_SIZE) *
+	return min_t(unsigned int, shost->sg_tablesize, SCSI_INLINE_SG_CNT) *
 		sizeof(struct scatterlist);
 }
 
@@ -1734,7 +1737,7 @@ static int scsi_mq_init_request(struct blk_mq_tag_set *set, struct request *rq,
 	if (scsi_host_get_prot(shost)) {
 		sg = (void *)cmd + sizeof(struct scsi_cmnd) +
 			shost->hostt->cmd_size;
-		cmd->prot_sdb = (void *)sg + scsi_mq_sgl_size(shost);
+		cmd->prot_sdb = (void *)sg + scsi_mq_inline_sgl_size(shost);
 	}
 
 	return 0;
@@ -1828,7 +1831,7 @@ int scsi_mq_setup_tags(struct Scsi_Host *shost)
 {
 	unsigned int cmd_size, sgl_size;
 
-	sgl_size = scsi_mq_sgl_size(shost);
+	sgl_size = scsi_mq_inline_sgl_size(shost);
 	cmd_size = sizeof(struct scsi_cmnd) + shost->hostt->cmd_size + sgl_size;
 	if (scsi_host_get_prot(shost))
 		cmd_size += sizeof(struct scsi_data_buffer) +

commit 92524fa12312d1f082a473e14c590c48b4ef3fe5
Author: Ming Lei <ming.lei@redhat.com>
Date:   Sun Apr 28 15:39:31 2019 +0800

    scsi: core: avoid preallocating big SGL for protection information
    
    scsi_mq_setup_tags() currently preallocates a big buffer for protection
    SGL entries. scsi_mq_sgl_size() is used to determine the size for both data
    and protection information scatterlists but the protection buffer is
    usually much smaller. For example, one 512-byte sector needs 8 bytes of
    protection information. Given that the maximum number of sectors for one
    request is 2560 (BLK_DEF_MAX_SECTORS) sectors, the max protection
    information buffer size is just 20K.
    
    The protection information segment count generally matches the number of
    bios in the request. As a result, the typical actual number of segments
    won't be very big. And should the need arise, allocating a bigger SGL from
    slab is fast enough.
    
    Pre-allocate only one SGL entry for protection information and switch to
    runtime allocation in case that the protection information segment number
    is bigger than 1. This reduces memory tied up by static command
    allocations. For example, 500+ MB is saved on single lpfc HBA.
    
    [mkp: attempted to clarify commit desc]
    
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Bart Van Assche <bvanassche@acm.org>
    Cc: Ewan D. Milne <emilne@redhat.com>
    Cc: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index acc0f7080f18..c115458c835e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -39,6 +39,12 @@
 #include "scsi_priv.h"
 #include "scsi_logging.h"
 
+/*
+ * Size of integrity metadata is usually small, 1 inline sg should
+ * cover normal cases.
+ */
+#define  SCSI_INLINE_PROT_SG_CNT  1
+
 static struct kmem_cache *scsi_sdb_cache;
 static struct kmem_cache *scsi_sense_cache;
 static struct kmem_cache *scsi_sense_isadma_cache;
@@ -543,7 +549,8 @@ static void scsi_mq_free_sgtables(struct scsi_cmnd *cmd)
 	if (cmd->sdb.table.nents)
 		sg_free_table_chained(&cmd->sdb.table, SG_CHUNK_SIZE);
 	if (scsi_prot_sg_count(cmd))
-		sg_free_table_chained(&cmd->prot_sdb->table, SG_CHUNK_SIZE);
+		sg_free_table_chained(&cmd->prot_sdb->table,
+				SCSI_INLINE_PROT_SG_CNT);
 }
 
 static void scsi_mq_uninit_cmd(struct scsi_cmnd *cmd)
@@ -1032,7 +1039,7 @@ blk_status_t scsi_init_io(struct scsi_cmnd *cmd)
 
 		if (sg_alloc_table_chained(&prot_sdb->table, ivecs,
 				prot_sdb->table.sgl,
-				SG_CHUNK_SIZE)) {
+				SCSI_INLINE_PROT_SG_CNT)) {
 			ret = BLK_STS_RESOURCE;
 			goto out_free_sgtables;
 		}
@@ -1824,7 +1831,8 @@ int scsi_mq_setup_tags(struct Scsi_Host *shost)
 	sgl_size = scsi_mq_sgl_size(shost);
 	cmd_size = sizeof(struct scsi_cmnd) + shost->hostt->cmd_size + sgl_size;
 	if (scsi_host_get_prot(shost))
-		cmd_size += sizeof(struct scsi_data_buffer) + sgl_size;
+		cmd_size += sizeof(struct scsi_data_buffer) +
+			sizeof(struct scatterlist) * SCSI_INLINE_PROT_SG_CNT;
 
 	memset(&shost->tag_set, 0, sizeof(shost->tag_set));
 	shost->tag_set.ops = &scsi_mq_ops;

commit 4635873c561ac57b66adfcc2487c38106b1c916c
Author: Ming Lei <ming.lei@redhat.com>
Date:   Sun Apr 28 15:39:30 2019 +0800

    scsi: lib/sg_pool.c: improve APIs for allocating sg pool
    
    sg_alloc_table_chained() currently allows the caller to provide one
    preallocated SGL and returns if the requested number isn't bigger than
    size of that SGL. This is used to inline an SGL for an IO request.
    
    However, scattergather code only allows that size of the 1st preallocated
    SGL to be SG_CHUNK_SIZE(128). This means a substantial amount of memory
    (4KB) is claimed for the SGL for each IO request. If the I/O is small, it
    would be prudent to allocate a smaller SGL.
    
    Introduce an extra parameter to sg_alloc_table_chained() and
    sg_free_table_chained() for specifying size of the preallocated SGL.
    
    Both __sg_free_table() and __sg_alloc_table() assume that each SGL has the
    same size except for the last one.  Change the code to allow both functions
    to accept a variable size for the 1st preallocated SGL.
    
    [mkp: attempted to clarify commit desc]
    
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Bart Van Assche <bvanassche@acm.org>
    Cc: Ewan D. Milne <emilne@redhat.com>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Sagi Grimberg <sagi@grimberg.me>
    Cc: Chuck Lever <chuck.lever@oracle.com>
    Cc: netdev@vger.kernel.org
    Cc: linux-nvme@lists.infradead.org
    Suggested-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0916bd6d22b0..acc0f7080f18 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -541,9 +541,9 @@ static void scsi_uninit_cmd(struct scsi_cmnd *cmd)
 static void scsi_mq_free_sgtables(struct scsi_cmnd *cmd)
 {
 	if (cmd->sdb.table.nents)
-		sg_free_table_chained(&cmd->sdb.table, true);
+		sg_free_table_chained(&cmd->sdb.table, SG_CHUNK_SIZE);
 	if (scsi_prot_sg_count(cmd))
-		sg_free_table_chained(&cmd->prot_sdb->table, true);
+		sg_free_table_chained(&cmd->prot_sdb->table, SG_CHUNK_SIZE);
 }
 
 static void scsi_mq_uninit_cmd(struct scsi_cmnd *cmd)
@@ -976,7 +976,8 @@ static blk_status_t scsi_init_sgtable(struct request *req,
 	 * If sg table allocation fails, requeue request later.
 	 */
 	if (unlikely(sg_alloc_table_chained(&sdb->table,
-			blk_rq_nr_phys_segments(req), sdb->table.sgl)))
+			blk_rq_nr_phys_segments(req), sdb->table.sgl,
+			SG_CHUNK_SIZE)))
 		return BLK_STS_RESOURCE;
 
 	/* 
@@ -1030,7 +1031,8 @@ blk_status_t scsi_init_io(struct scsi_cmnd *cmd)
 		ivecs = blk_rq_count_integrity_sg(rq->q, rq->bio);
 
 		if (sg_alloc_table_chained(&prot_sdb->table, ivecs,
-				prot_sdb->table.sgl)) {
+				prot_sdb->table.sgl,
+				SG_CHUNK_SIZE)) {
 			ret = BLK_STS_RESOURCE;
 			goto out_free_sgtables;
 		}

commit 026104bfa591709689e12434c1bb3b485bf5bfa0
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 1 12:13:54 2019 -0400

    scsi: core: add SPDX tags to scsi midlayer files missing licensing information
    
    Add the default kernel GPLv2 annotation to SCSI midlayer files missing any
    licensing information.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0916bd6d22b0..b1b1a1aaa353 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * Copyright (C) 1999 Eric Youngdale
  * Copyright (C) 2014 Christoph Hellwig

commit 457c89965399115e5cd8bf38f9c597293405703d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun May 19 13:08:55 2019 +0100

    treewide: Add SPDX license identifier for missed files
    
    Add SPDX license identifiers to all files which:
    
     - Have no license information of any form
    
     - Have EXPORT_.*_SYMBOL_GPL inside which was used in the
       initial scan/conversion to ignore the file
    
    These files fall under the project license, GPL v2 only. The resulting SPDX
    license identifier is:
    
      GPL-2.0-only
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0916bd6d22b0..65d0a10c76ad 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * Copyright (C) 1999 Eric Youngdale
  * Copyright (C) 2014 Christoph Hellwig

commit d1cd7c85f9e29740fddec6f25d8bf061937bf58d
Merge: b3a5e648f591 d4023db71108
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 8 10:12:46 2019 -0700

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This is mostly update of the usual drivers: qla2xxx, qedf, smartpqi,
      hpsa, lpfc, ufs, mpt3sas, ibmvfc and hisi_sas. Plus number of minor
      changes, spelling fixes and other trivia"
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (298 commits)
      scsi: qla2xxx: Avoid that lockdep complains about unsafe locking in tcm_qla2xxx_close_session()
      scsi: qla2xxx: Avoid that qlt_send_resp_ctio() corrupts memory
      scsi: qla2xxx: Fix hardirq-unsafe locking
      scsi: qla2xxx: Complain loudly about reference count underflow
      scsi: qla2xxx: Use __le64 instead of uint32_t[2] for sending DMA addresses to firmware
      scsi: qla2xxx: Introduce the dsd32 and dsd64 data structures
      scsi: qla2xxx: Check the size of firmware data structures at compile time
      scsi: qla2xxx: Pass little-endian values to the firmware
      scsi: qla2xxx: Fix race conditions in the code for aborting SCSI commands
      scsi: qla2xxx: Use an on-stack completion in qla24xx_control_vp()
      scsi: qla2xxx: Make qla24xx_async_abort_cmd() static
      scsi: qla2xxx: Remove unnecessary locking from the target code
      scsi: qla2xxx: Remove qla_tgt_cmd.released
      scsi: qla2xxx: Complain if a command is released that is owned by the firmware
      scsi: qla2xxx: target: Fix offline port handling and host reset handling
      scsi: qla2xxx: Fix abort handling in tcm_qla2xxx_write_pending()
      scsi: qla2xxx: Fix error handling in qlt_alloc_qfull_cmd()
      scsi: qla2xxx: Simplify qlt_send_term_imm_notif()
      scsi: qla2xxx: Fix use-after-free issues in qla2xxx_qpair_sp_free_dma()
      scsi: qla2xxx: Fix a qla24xx_enable_msix() error path
      ...

commit be549d49115422f846b6d96ee8fd7173a5f7ceb0
Author: Jaesoo Lee <jalee@purestorage.com>
Date:   Tue Apr 9 17:02:22 2019 -0700

    scsi: core: set result when the command cannot be dispatched
    
    When SCSI blk-mq is enabled, there is a bug in handling errors in
    scsi_queue_rq.  Specifically, the bug is not setting result field of
    scsi_request correctly when the dispatch of the command has been
    failed. Since the upper layer code including the sg_io ioctl expects to
    receive any error status from result field of scsi_request, the error is
    silently ignored and this could cause data corruptions for some
    applications.
    
    Fixes: d285203cf647 ("scsi: add support for a blk-mq based I/O path.")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Jaesoo Lee <jalee@purestorage.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 601b9f1de267..07dfc17d4824 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1706,8 +1706,12 @@ static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 			ret = BLK_STS_DEV_RESOURCE;
 		break;
 	default:
+		if (unlikely(!scsi_device_online(sdev)))
+			scsi_req(req)->result = DID_NO_CONNECT << 16;
+		else
+			scsi_req(req)->result = DID_ERROR << 16;
 		/*
-		 * Make sure to release all allocated ressources when
+		 * Make sure to release all allocated resources when
 		 * we hit an error, as we will never see this command
 		 * again.
 		 */

commit 18c4f0a42b08ced680aa287a9cf3c94b6f9a752f
Author: Ming Lei <ming.lei@redhat.com>
Date:   Fri Apr 12 11:30:32 2019 +0800

    scsi: core: don't hold device refcount in IO path
    
    scsi_device's refcount is always grabbed in IO path.
    
    Turns out it isn't necessary, because blk_queue_cleanup() will drain any
    in-flight IOs, then cancel timeout/requeue work, and SCSI's requeue_work is
    canceled too in __scsi_remove_device().
    
    Also scsi_device won't go away until blk_cleanup_queue() is done.
    
    So don't hold the refcount in IO path, especially the refcount isn't
    required in IO path since blk_queue_enter() / blk_queue_exit() is
    introduced in the legacy block layer.
    
    Cc: Dongli Zhang <dongli.zhang@oracle.com>
    Cc: James Smart <james.smart@broadcom.com>
    Cc: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: linux-scsi@vger.kernel.org,
    Cc: Martin K . Petersen <martin.petersen@oracle.com>,
    Cc: Christoph Hellwig <hch@lst.de>,
    Cc: James E . J . Bottomley <jejb@linux.vnet.ibm.com>,
    Cc: jianchao wang <jianchao.w.wang@oracle.com>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d4bd6cd9d373..6b2570a5642d 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -141,8 +141,6 @@ scsi_set_blocked(struct scsi_cmnd *cmd, int reason)
 
 static void scsi_mq_requeue_cmd(struct scsi_cmnd *cmd)
 {
-	struct scsi_device *sdev = cmd->device;
-
 	if (cmd->request->rq_flags & RQF_DONTPREP) {
 		cmd->request->rq_flags &= ~RQF_DONTPREP;
 		scsi_mq_uninit_cmd(cmd);
@@ -150,7 +148,6 @@ static void scsi_mq_requeue_cmd(struct scsi_cmnd *cmd)
 		WARN_ON_ONCE(true);
 	}
 	blk_mq_requeue_request(cmd->request, true);
-	put_device(&sdev->sdev_gendev);
 }
 
 /**
@@ -189,19 +186,7 @@ static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, bool unbusy)
 	 */
 	cmd->result = 0;
 
-	/*
-	 * Before a SCSI command is dispatched,
-	 * get_device(&sdev->sdev_gendev) is called and the host,
-	 * target and device busy counters are increased. Since
-	 * requeuing a request causes these actions to be repeated and
-	 * since scsi_device_unbusy() has already been called,
-	 * put_device(&device->sdev_gendev) must still be called. Call
-	 * put_device() after blk_mq_requeue_request() to avoid that
-	 * removal of the SCSI device can start before requeueing has
-	 * happened.
-	 */
 	blk_mq_requeue_request(cmd->request, true);
-	put_device(&device->sdev_gendev);
 }
 
 /*
@@ -619,7 +604,6 @@ static bool scsi_end_request(struct request *req, blk_status_t error,
 		blk_mq_run_hw_queues(q, true);
 
 	percpu_ref_put(&q->q_usage_counter);
-	put_device(&sdev->sdev_gendev);
 	return false;
 }
 
@@ -1613,7 +1597,6 @@ static void scsi_mq_put_budget(struct blk_mq_hw_ctx *hctx)
 	struct scsi_device *sdev = q->queuedata;
 
 	atomic_dec(&sdev->device_busy);
-	put_device(&sdev->sdev_gendev);
 }
 
 static bool scsi_mq_get_budget(struct blk_mq_hw_ctx *hctx)
@@ -1621,16 +1604,9 @@ static bool scsi_mq_get_budget(struct blk_mq_hw_ctx *hctx)
 	struct request_queue *q = hctx->queue;
 	struct scsi_device *sdev = q->queuedata;
 
-	if (!get_device(&sdev->sdev_gendev))
-		goto out;
-	if (!scsi_dev_queue_ready(q, sdev))
-		goto out_put_device;
-
-	return true;
+	if (scsi_dev_queue_ready(q, sdev))
+		return true;
 
-out_put_device:
-	put_device(&sdev->sdev_gendev);
-out:
 	if (atomic_read(&sdev->device_busy) == 0 && !scsi_device_blocked(sdev))
 		blk_mq_delay_run_hw_queue(hctx, SCSI_QUEUE_DELAY);
 	return false;

commit 17631462cd49f3dfa9db38a9e578c59f71ccf414
Merge: 4b3766ec0e18 5c2442fd7899
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Fri Apr 12 21:27:23 2019 -0400

    Merge branch '5.1/scsi-fixes' into 5.2/merge
    
    We have a few submissions for 5.2 that depend on fixes merged post
    5.1-rc1. Merge the fixes branch into queue.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

commit 99bbf484c6df831290ef27435fd39f45beb4462e
Author: Dongli Zhang <dongli.zhang@oracle.com>
Date:   Tue Mar 12 09:00:28 2019 +0800

    scsi: core: Use HCTX_TYPE_DEFAULT for blk_mq_tag_set->map
    
    Use HCTX_TYPE_DEFAULT instead of 0 to avoid hardcoding.
    
    Signed-off-by: Dongli Zhang <dongli.zhang@oracle.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 20189675677a..985cfc217524 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1759,7 +1759,7 @@ static int scsi_map_queues(struct blk_mq_tag_set *set)
 
 	if (shost->hostt->map_queues)
 		return shost->hostt->map_queues(shost);
-	return blk_mq_map_queues(&set->map[0]);
+	return blk_mq_map_queues(&set->map[HCTX_TYPE_DEFAULT]);
 }
 
 void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)

commit 17605afaae825b0291f80c62a7f6565879edaa8a
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Fri Mar 15 16:27:58 2019 -0700

    scsi: core: Avoid that a kernel warning appears during system resume
    
    Since scsi_device_quiesce() skips SCSI devices that have another state than
    RUNNING, OFFLINE or TRANSPORT_OFFLINE, scsi_device_resume() should not
    complain about SCSI devices that have been skipped. Hence this patch.  This
    patch avoids that the following warning appears during resume:
    
    WARNING: CPU: 3 PID: 1039 at blk_clear_pm_only+0x2a/0x30
    CPU: 3 PID: 1039 Comm: kworker/u8:49 Not tainted 5.0.0+ #1
    Hardware name: LENOVO 4180F42/4180F42, BIOS 83ET75WW (1.45 ) 05/10/2013
    Workqueue: events_unbound async_run_entry_fn
    RIP: 0010:blk_clear_pm_only+0x2a/0x30
    Call Trace:
     ? scsi_device_resume+0x28/0x50
     ? scsi_dev_type_resume+0x2b/0x80
     ? async_run_entry_fn+0x2c/0xd0
     ? process_one_work+0x1f0/0x3f0
     ? worker_thread+0x28/0x3c0
     ? process_one_work+0x3f0/0x3f0
     ? kthread+0x10c/0x130
     ? __kthread_create_on_node+0x150/0x150
     ? ret_from_fork+0x1f/0x30
    
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Ming Lei <ming.lei@redhat.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Cc: Oleksandr Natalenko <oleksandr@natalenko.name>
    Cc: Martin Steigerwald <martin@lichtvoll.de>
    Cc: <stable@vger.kernel.org>
    Reported-by: Jisheng Zhang <Jisheng.Zhang@synaptics.com>
    Tested-by: Jisheng Zhang <Jisheng.Zhang@synaptics.com>
    Fixes: 3a0a529971ec ("block, scsi: Make SCSI quiesce and resume work reliably") # v4.15
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f0db2dd0be75..601b9f1de267 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2548,8 +2548,10 @@ void scsi_device_resume(struct scsi_device *sdev)
 	 * device deleted during suspend)
 	 */
 	mutex_lock(&sdev->state_mutex);
-	sdev->quiesced_by = NULL;
-	blk_clear_pm_only(sdev->request_queue);
+	if (sdev->quiesced_by) {
+		sdev->quiesced_by = NULL;
+		blk_clear_pm_only(sdev->request_queue);
+	}
 	if (sdev->sdev_state == SDEV_QUIESCE)
 		scsi_device_set_state(sdev, SDEV_RUNNING);
 	mutex_unlock(&sdev->state_mutex);

commit db983f6eef57a9d78af79bc32389b7e60eb3c47d
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Mon Mar 18 09:29:26 2019 -0700

    scsi: core: Also call destroy_rcu_head() for passthrough requests
    
    cmd->rcu is initialized by scsi_initialize_rq(). For passthrough
    requests, blk_get_request() calls scsi_initialize_rq(). For filesystem
    requests, scsi_init_command() calls scsi_initialize_rq(). Make sure
    that destroy_rcu_head() is called for passthrough requests.
    
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Ewan D. Milne <emilne@redhat.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Reported-by: Ewan D. Milne <emilne@redhat.com>
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 20189675677a..f0db2dd0be75 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -585,9 +585,16 @@ static bool scsi_end_request(struct request *req, blk_status_t error,
 	if (!blk_rq_is_scsi(req)) {
 		WARN_ON_ONCE(!(cmd->flags & SCMD_INITIALIZED));
 		cmd->flags &= ~SCMD_INITIALIZED;
-		destroy_rcu_head(&cmd->rcu);
 	}
 
+	/*
+	 * Calling rcu_barrier() is not necessary here because the
+	 * SCSI error handler guarantees that the function called by
+	 * call_rcu() has been called before scsi_end_request() is
+	 * called.
+	 */
+	destroy_rcu_head(&cmd->rcu);
+
 	/*
 	 * In the MQ case the command gets freed by __blk_mq_end_request,
 	 * so we have to do all cleanup that depends on it earlier.

commit 92fff53b7191cae566be9ca6752069426c7f8241
Merge: a50243b1ddcd 26af1a368e40
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Mar 9 16:53:47 2019 -0800

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This is mostly update of the usual drivers: arcmsr, qla2xxx, lpfc,
      hisi_sas, target/iscsi and target/core.
    
      Additionally Christoph refactored gdth as part of the dma changes. The
      major mid-layer change this time is the removal of bidi commands and
      with them the whole of the osd/exofs driver and filesystem. This is a
      major simplification for block and mq in particular"
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (240 commits)
      scsi: cxgb4i: validate tcp sequence number only if chip version <= T5
      scsi: cxgb4i: get pf number from lldi->pf
      scsi: core: replace GFP_ATOMIC with GFP_KERNEL in scsi_scan.c
      scsi: mpt3sas: Add missing breaks in switch statements
      scsi: aacraid: Fix missing break in switch statement
      scsi: kill command serial number
      scsi: csiostor: drop serial_number usage
      scsi: mvumi: use request tag instead of serial_number
      scsi: dpt_i2o: remove serial number usage
      scsi: st: osst: Remove negative constant left-shifts
      scsi: ufs-bsg: Allow reading descriptors
      scsi: ufs: Allow reading descriptor via raw upiu
      scsi: ufs-bsg: Change the calling convention for write descriptor
      scsi: ufs: Remove unused device quirks
      Revert "scsi: ufs: disable vccq if it's not needed by UFS device"
      scsi: megaraid_sas: Remove a bunch of set but not used variables
      scsi: clean obsolete return values of eh_timed_out
      scsi: sd: Optimal I/O size should be a multiple of physical block size
      scsi: MAINTAINERS: SCSI initiator and target tweaks
      scsi: fcoe: make use of fip_mode enum complete
      ...

commit 80201fe175cbf7f3e372f53eba0a881a702ad926
Merge: 4221b807d1f7 aaeee62c841c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Mar 8 14:12:17 2019 -0800

    Merge tag 'for-5.1/block-20190302' of git://git.kernel.dk/linux-block
    
    Pull block layer updates from Jens Axboe:
     "Not a huge amount of changes in this round, the biggest one is that we
      finally have Mings multi-page bvec support merged. Apart from that,
      this pull request contains:
    
       - Small series that avoids quiescing the queue for sysfs changes that
         match what we currently have (Aleksei)
    
       - Series of bcache fixes (via Coly)
    
       - Series of lightnvm fixes (via Mathias)
    
       - NVMe pull request from Christoph. Nothing major, just SPDX/license
         cleanups, RR mp policy (Hannes), and little fixes (Bart,
         Chaitanya).
    
       - BFQ series (Paolo)
    
       - Save blk-mq cpu -> hw queue mapping, removing a pointer indirection
         for the fast path (Jianchao)
    
       - fops->iopoll() added for async IO polling, this is a feature that
         the upcoming io_uring interface will use (Christoph, me)
    
       - Partition scan loop fixes (Dongli)
    
       - mtip32xx conversion from managed resource API (Christoph)
    
       - cdrom registration race fix (Guenter)
    
       - MD pull from Song, two minor fixes.
    
       - Various documentation fixes (Marcos)
    
       - Multi-page bvec feature. This brings a lot of nice improvements
         with it, like more efficient splitting, larger IOs can be supported
         without growing the bvec table size, and so on. (Ming)
    
       - Various little fixes to core and drivers"
    
    * tag 'for-5.1/block-20190302' of git://git.kernel.dk/linux-block: (117 commits)
      block: fix updating bio's front segment size
      block: Replace function name in string with __func__
      nbd: propagate genlmsg_reply return code
      floppy: remove set but not used variable 'q'
      null_blk: fix checking for REQ_FUA
      block: fix NULL pointer dereference in register_disk
      fs: fix guard_bio_eod to check for real EOD errors
      blk-mq: use HCTX_TYPE_DEFAULT but not 0 to index blk_mq_tag_set->map
      block: optimize bvec iteration in bvec_iter_advance
      block: introduce mp_bvec_for_each_page() for iterating over page
      block: optimize blk_bio_segment_split for single-page bvec
      block: optimize __blk_segment_map_sg() for single-page bvec
      block: introduce bvec_nth_page()
      iomap: wire up the iopoll method
      block: add bio_set_polled() helper
      block: wire up block device iopoll method
      fs: add an iopoll method to struct file_operations
      loop: set GENHD_FL_NO_PART_SCAN after blkdev_reread_part()
      loop: do not print warn message if partition scan is successful
      block: bounce: make sure that bvec table is updated
      ...

commit b9cef50921eb018917e3c60b0c7f4ae1e113ad03
Author: Hannes Reinecke <hare@suse.com>
Date:   Tue Feb 26 15:56:42 2019 +0100

    scsi: kill command serial number
    
    No users left, kill it.
    
    Signed-off-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c77cb0d31dbc..95466a5bf6d6 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -316,7 +316,6 @@ EXPORT_SYMBOL(__scsi_execute);
  */
 static void scsi_init_cmd_errh(struct scsi_cmnd *cmd)
 {
-	cmd->serial_number = 0;
 	scsi_set_resid(cmd, 0);
 	memset(cmd->sense_buffer, 0, SCSI_SENSE_BUFFERSIZE);
 	if (cmd->cmd_len == 0)

commit 388b4e6a00bb3097278ed1648ac5a1cb48c894e6
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Tue Feb 26 16:35:26 2019 -0800

    scsi: core: Avoid that system resume triggers a kernel warning
    
    scsi_device_quiesce() and scsi_device_resume() are called during
    system-wide suspend and resume. scsi_device_quiesce() only succeeds for
    SCSI devices that are in one of the RUNNING, OFFLINE or TRANSPORT_OFFLINE
    states (see also scsi_set_device_state()).  This patch avoids that the
    following warning is triggered when resuming a system for which quiescing a
    SCSI device failed:
    
    WARNING: CPU: 2 PID: 11303 at drivers/scsi/scsi_lib.c:2600 scsi_device_resume+0x4f/0x58
    CPU: 2 PID: 11303 Comm: kworker/u8:70 Not tainted 5.0.0-rc1+ #50
    Hardware name: LENOVO 80E3/Lancer 5B2, BIOS A2CN45WW(V2.13) 08/04/2016
    Workqueue: events_unbound async_run_entry_fn
    Call Trace:
     scsi_dev_type_resume+0x2e/0x60
     async_run_entry_fn+0x32/0xd8
     process_one_work+0x1f4/0x420
     worker_thread+0x28/0x3c0
     kthread+0x118/0x130
     ret_from_fork+0x22/0x40
    
    Cc: Przemek Socha <soprwa@gmail.com>
    Reported-by: Przemek Socha <soprwa@gmail.com>
    Fixes: 3a0a529971ec ("block, scsi: Make SCSI quiesce and resume work reliably") # v4.15
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f8d51c3d5582..a6828391d6b3 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2598,7 +2598,6 @@ void scsi_device_resume(struct scsi_device *sdev)
 	 * device deleted during suspend)
 	 */
 	mutex_lock(&sdev->state_mutex);
-	WARN_ON_ONCE(!sdev->quiesced_by);
 	sdev->quiesced_by = NULL;
 	blk_clear_pm_only(sdev->request_queue);
 	if (sdev->sdev_state == SDEV_QUIESCE)

commit 4a067cf823d9d8e50d41cfb618011c0d4a969c72
Author: Martin Wilck <mwilck@suse.com>
Date:   Thu Feb 14 22:57:41 2019 +0100

    scsi: core: reset host byte in DID_NEXUS_FAILURE case
    
    Up to 4.12, __scsi_error_from_host_byte() would reset the host byte to
    DID_OK for various cases including DID_NEXUS_FAILURE.  Commit
    2a842acab109 ("block: introduce new block status code type") replaced this
    function with scsi_result_to_blk_status() and removed the host-byte
    resetting code for the DID_NEXUS_FAILURE case.  As the line
    set_host_byte(cmd, DID_OK) was preserved for the other cases, I suppose
    this was an editing mistake.
    
    The fact that the host byte remains set after 4.13 is causing problems with
    the sg_persist tool, which now returns success rather then exit status 24
    when a RESERVATION CONFLICT error is encountered.
    
    Fixes: 2a842acab109 "block: introduce new block status code type"
    Signed-off-by: Martin Wilck <mwilck@suse.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 6d65ac584eba..f8d51c3d5582 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -655,6 +655,7 @@ static blk_status_t scsi_result_to_blk_status(struct scsi_cmnd *cmd, int result)
 		set_host_byte(cmd, DID_OK);
 		return BLK_STS_TARGET;
 	case DID_NEXUS_FAILURE:
+		set_host_byte(cmd, DID_OK);
 		return BLK_STS_NEXUS;
 	case DID_ALLOC_FAILURE:
 		set_host_byte(cmd, DID_OK);

commit 56d18f62f556b80105e38e7975975cf7465aae3e
Author: Ming Lei <ming.lei@redhat.com>
Date:   Fri Feb 15 19:13:24 2019 +0800

    block: kill BLK_MQ_F_SG_MERGE
    
    QUEUE_FLAG_NO_SG_MERGE has been killed, so kill BLK_MQ_F_SG_MERGE too.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 6d65ac584eba..6cadbe945bdb 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1899,7 +1899,7 @@ int scsi_mq_setup_tags(struct Scsi_Host *shost)
 	shost->tag_set.queue_depth = shost->can_queue;
 	shost->tag_set.cmd_size = cmd_size;
 	shost->tag_set.numa_node = NUMA_NO_NODE;
-	shost->tag_set.flags = BLK_MQ_F_SHOULD_MERGE | BLK_MQ_F_SG_MERGE;
+	shost->tag_set.flags = BLK_MQ_F_SHOULD_MERGE;
 	shost->tag_set.flags |=
 		BLK_ALLOC_POLICY_TO_MQ_FLAG(shost->hostt->tag_alloc_policy);
 	shost->tag_set.driver_data = shost;

commit 9fa505adf9f2914637e4e81620f62dcdaa575f71
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Fri Feb 8 13:25:03 2019 -0800

    scsi: core: Move resid from scsi_data_buffer to scsi_cmnd
    
    This patch does not change any functionality but reduces the size of
    struct scsi_cmnd.
    
    Cc: Douglas Gilbert <dgilbert@interlog.com>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d25101c5e3b8..c77cb0d31dbc 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -938,7 +938,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		 * scsi_result_to_blk_status may have reset the host_byte
 		 */
 		scsi_req(req)->result = cmd->result;
-		scsi_req(req)->resid_len = scsi_get_resid(cmd);
 	}
 
 	/*

commit b9f91992991b27e72d93113095b9b92919ed0b71
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Nov 8 09:32:43 2018 +0100

    scsi: stop setting up request->special
    
    No more need in a blk-mq world where the scsi command and request are
    allocated together.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 2667bb95a441..d25101c5e3b8 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1566,10 +1566,7 @@ static blk_status_t scsi_mq_prep_fn(struct request *req)
 
 	scsi_init_command(sdev, cmd);
 
-	req->special = cmd;
-
 	cmd->request = req;
-
 	cmd->tag = req->tag;
 	cmd->prot_op = SCSI_PROT_NORMAL;
 

commit ae3d56d81507c33024ba7c1eae2ef433aa9bc0d5
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Jan 29 09:33:07 2019 +0100

    scsi: remove bidirectional command support
    
    No real need for bidi support once the OSD code is gone.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 00cd365fb7d2..2667bb95a441 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -556,15 +556,8 @@ static void scsi_uninit_cmd(struct scsi_cmnd *cmd)
 
 static void scsi_mq_free_sgtables(struct scsi_cmnd *cmd)
 {
-	struct scsi_data_buffer *sdb;
-
 	if (cmd->sdb.table.nents)
 		sg_free_table_chained(&cmd->sdb.table, true);
-	if (cmd->request->next_rq) {
-		sdb = cmd->request->next_rq->special;
-		if (sdb)
-			sg_free_table_chained(&sdb->table, true);
-	}
 	if (scsi_prot_sg_count(cmd))
 		sg_free_table_chained(&cmd->prot_sdb->table, true);
 }
@@ -578,7 +571,7 @@ static void scsi_mq_uninit_cmd(struct scsi_cmnd *cmd)
 
 /* Returns false when no more bytes to process, true if there are more */
 static bool scsi_end_request(struct request *req, blk_status_t error,
-		unsigned int bytes, unsigned int bidi_bytes)
+		unsigned int bytes)
 {
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
 	struct scsi_device *sdev = cmd->device;
@@ -587,11 +580,6 @@ static bool scsi_end_request(struct request *req, blk_status_t error,
 	if (blk_update_request(req, error, bytes))
 		return true;
 
-	/* Bidi request must be completed as a whole */
-	if (unlikely(bidi_bytes) &&
-	    blk_update_request(req->next_rq, error, bidi_bytes))
-		return true;
-
 	if (blk_queue_add_random(q))
 		add_disk_randomness(req->rq_disk);
 
@@ -816,7 +804,7 @@ static void scsi_io_completion_action(struct scsi_cmnd *cmd, int result)
 				scsi_print_command(cmd);
 			}
 		}
-		if (!scsi_end_request(req, blk_stat, blk_rq_err_bytes(req), 0))
+		if (!scsi_end_request(req, blk_stat, blk_rq_err_bytes(req)))
 			return;
 		/*FALLTHRU*/
 	case ACTION_REPREP:
@@ -951,29 +939,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		 */
 		scsi_req(req)->result = cmd->result;
 		scsi_req(req)->resid_len = scsi_get_resid(cmd);
-
-		if (unlikely(scsi_bidi_cmnd(cmd))) {
-			/*
-			 * Bidi commands Must be complete as a whole,
-			 * both sides at once.
-			 */
-			scsi_req(req->next_rq)->resid_len = scsi_in(cmd)->resid;
-			if (scsi_end_request(req, BLK_STS_OK, blk_rq_bytes(req),
-					blk_rq_bytes(req->next_rq)))
-				WARN_ONCE(true,
-					  "Bidi command with remaining bytes");
-			return;
-		}
-	}
-
-	/* no bidi support yet, other than in pass-through */
-	if (unlikely(blk_bidi_rq(req))) {
-		WARN_ONCE(true, "Only support bidi command in passthrough");
-		scmd_printk(KERN_ERR, cmd, "Killing bidi command\n");
-		if (scsi_end_request(req, BLK_STS_IOERR, blk_rq_bytes(req),
-				     blk_rq_bytes(req->next_rq)))
-			WARN_ONCE(true, "Bidi command with remaining bytes");
-		return;
 	}
 
 	/*
@@ -990,13 +955,13 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	 * to retry code. Fast path should return in this block.
 	 */
 	if (likely(blk_rq_bytes(req) > 0 || blk_stat == BLK_STS_OK)) {
-		if (likely(!scsi_end_request(req, blk_stat, good_bytes, 0)))
+		if (likely(!scsi_end_request(req, blk_stat, good_bytes)))
 			return; /* no bytes remaining */
 	}
 
 	/* Kill remainder if no retries. */
 	if (unlikely(blk_stat && scsi_noretry_cmd(cmd))) {
-		if (scsi_end_request(req, blk_stat, blk_rq_bytes(req), 0))
+		if (scsi_end_request(req, blk_stat, blk_rq_bytes(req)))
 			WARN_ONCE(true,
 			    "Bytes remaining after failed, no-retry command");
 		return;
@@ -1058,12 +1023,6 @@ blk_status_t scsi_init_io(struct scsi_cmnd *cmd)
 	if (ret)
 		return ret;
 
-	if (blk_bidi_rq(rq)) {
-		ret = scsi_init_sgtable(rq->next_rq, rq->next_rq->special);
-		if (ret)
-			goto out_free_sgtables;
-	}
-
 	if (blk_integrity_rq(rq)) {
 		struct scsi_data_buffer *prot_sdb = cmd->prot_sdb;
 		int ivecs, count;
@@ -1624,17 +1583,6 @@ static blk_status_t scsi_mq_prep_fn(struct request *req)
 			(struct scatterlist *)(cmd->prot_sdb + 1);
 	}
 
-	if (blk_bidi_rq(req)) {
-		struct request *next_rq = req->next_rq;
-		struct scsi_data_buffer *bidi_sdb = blk_mq_rq_to_pdu(next_rq);
-
-		memset(bidi_sdb, 0, sizeof(struct scsi_data_buffer));
-		bidi_sdb->table.sgl =
-			(struct scatterlist *)(bidi_sdb + 1);
-
-		next_rq->special = bidi_sdb;
-	}
-
 	blk_mq_start_request(req);
 
 	return scsi_setup_cmnd(sdev, req);

commit cd464d838041b3a69464c0dd3938c1f912487bd3
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Tue Jan 15 16:50:03 2019 -0800

    scsi: core: Remove an atomic instruction from the hot path
    
    From scsi_init_command(), a function called by scsi_mq_prep_fn():
    
            /* zero out the cmd, except for the embedded scsi_request */
            memset((char *)cmd + sizeof(cmd->req), 0,
                    sizeof(*cmd) - sizeof(cmd->req) + dev->host->hostt->cmd_size);
    
    In other words, scsi_mq_prep_fn() clears scsi_cmnd.flags. Hence move the
    clear_bit() call into the else branch, the only branch in which this code
    is necessary.
    
    See also commit f1342709d18a ("scsi: Do not rely on blk-mq for double
    completions").
    
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Keith Busch <keith.busch@intel.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b13cc9288ba0..00cd365fb7d2 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1712,13 +1712,13 @@ static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	if (!scsi_host_queue_ready(q, shost, sdev))
 		goto out_dec_target_busy;
 
-	clear_bit(SCMD_STATE_COMPLETE, &cmd->state);
 	if (!(req->rq_flags & RQF_DONTPREP)) {
 		ret = scsi_mq_prep_fn(req);
 		if (ret != BLK_STS_OK)
 			goto out_dec_host_busy;
 		req->rq_flags |= RQF_DONTPREP;
 	} else {
+		clear_bit(SCMD_STATE_COMPLETE, &cmd->state);
 		blk_mq_start_request(req);
 	}
 

commit a8cf59a6692c9c55a5a10257de97919fae6edef8
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jan 16 17:12:15 2019 +0100

    scsi: communicate max segment size to the DMA mapping code
    
    When a host driver sets a maximum segment size we should not only propagate
    that setting to the block layer, which can merge segments, but also to the
    DMA mapping layer which can merge segments as well.
    
    Fixes: 50c2e9107f ("scsi: introduce a max_segment_size host_template parameters")
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b13cc9288ba0..6d65ac584eba 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1842,8 +1842,8 @@ void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 	blk_queue_segment_boundary(q, shost->dma_boundary);
 	dma_set_seg_boundary(dev, shost->dma_boundary);
 
-	blk_queue_max_segment_size(q,
-		min(shost->max_segment_size, dma_get_max_seg_size(dev)));
+	blk_queue_max_segment_size(q, shost->max_segment_size);
+	dma_set_max_seg_size(dev, shost->max_segment_size);
 
 	/*
 	 * Set a reasonable default alignment:  The larger of 32-byte (dword),

commit 938edb8a31b976c9a92eb0cd4ff481e93f76c1f1
Merge: af7ddd8a627c da7903092b88
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Dec 28 14:48:06 2018 -0800

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This is mostly update of the usual drivers: smarpqi, lpfc, qedi,
      megaraid_sas, libsas, zfcp, mpt3sas, hisi_sas.
    
      Additionally, we have a pile of annotation, unused variable and minor
      updates.
    
      The big API change is the updates for Christoph's DMA rework which
      include removing the DISABLE_CLUSTERING flag.
    
      And finally there are a couple of target tree updates"
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (259 commits)
      scsi: isci: request: mark expected switch fall-through
      scsi: isci: remote_node_context: mark expected switch fall-throughs
      scsi: isci: remote_device: Mark expected switch fall-throughs
      scsi: isci: phy: Mark expected switch fall-through
      scsi: iscsi: Capture iscsi debug messages using tracepoints
      scsi: myrb: Mark expected switch fall-throughs
      scsi: megaraid: fix out-of-bound array accesses
      scsi: mpt3sas: mpt3sas_scsih: Mark expected switch fall-through
      scsi: fcoe: remove set but not used variable 'port'
      scsi: smartpqi: call pqi_free_interrupts() in pqi_shutdown()
      scsi: smartpqi: fix build warnings
      scsi: smartpqi: update driver version
      scsi: smartpqi: add ofa support
      scsi: smartpqi: increase fw status register read timeout
      scsi: smartpqi: bump driver version
      scsi: smartpqi: add smp_utils support
      scsi: smartpqi: correct lun reset issues
      scsi: smartpqi: correct volume status
      scsi: smartpqi: do not offline disks for transient did no connect conditions
      scsi: smartpqi: allow for larger raid maps
      ...

commit 4af14d113bcf95c12d1462ba623b7e7117bd3fb3
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Dec 13 16:17:09 2018 +0100

    scsi: remove the use_clustering flag
    
    The same effects can be achieved by setting the dma_boundary to
    PAGE_SIZE - 1 and the max_segment_size to PAGE_SIZE, so shift those
    settings into the drivers.  Note that in many cases the setting might
    be bogus, but this keeps the status quo.
    
    [mkp: fix myrs and myrb]
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 2d4fd6b4bd92..966b7cfebdf8 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2230,9 +2230,6 @@ void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 	blk_queue_max_segment_size(q,
 		min(shost->max_segment_size, dma_get_max_seg_size(dev)));
 
-	if (shost->use_clustering == DISABLE_CLUSTERING)
-		q->limits.cluster = 0;
-
 	/*
 	 * Set a reasonable default alignment:  The larger of 32-byte (dword),
 	 * which is a common minimum for HBAs, and the minimum DMA alignment,

commit 50c2e9107f176a82e14567b39c5d0f2a208cc82c
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Dec 13 16:17:03 2018 +0100

    scsi: introduce a max_segment_size host_template parameters
    
    This allows the host driver to indicate the maximum supported
    segment size in a nice an easy way, so that the driver doesn't
    have to worry about DMA-layer imposed limitations.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f6900e0b3024..2d4fd6b4bd92 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2227,7 +2227,8 @@ void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 	blk_queue_segment_boundary(q, shost->dma_boundary);
 	dma_set_seg_boundary(dev, shost->dma_boundary);
 
-	blk_queue_max_segment_size(q, dma_get_max_seg_size(dev));
+	blk_queue_max_segment_size(q,
+		min(shost->max_segment_size, dma_get_max_seg_size(dev)));
 
 	if (shost->use_clustering == DISABLE_CLUSTERING)
 		q->limits.cluster = 0;

commit 2a3d4eb8e228061c09d5ca8bf39e7f00c2091213
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Dec 13 16:17:02 2018 +0100

    scsi: flip the default on use_clustering
    
    Most SCSI drivers want to enable "clustering", that is merging of
    segments so that they might span more than a single page.  Remove the
    ENABLE_CLUSTERING define, and require drivers to explicitly set
    DISABLE_CLUSTERING to disable this feature.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c7fccbb8f554..f6900e0b3024 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2229,7 +2229,7 @@ void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 
 	blk_queue_max_segment_size(q, dma_get_max_seg_size(dev));
 
-	if (!shost->use_clustering)
+	if (shost->use_clustering == DISABLE_CLUSTERING)
 		q->limits.cluster = 0;
 
 	/*

commit f1342709d18af97b0e71449d5696b8873d1a456c
Author: Keith Busch <keith.busch@intel.com>
Date:   Mon Nov 26 09:54:29 2018 -0700

    scsi: Do not rely on blk-mq for double completions
    
    The scsi timeout error handling had been directly updating the block
    layer's request state to prevent a error handling and a natural completion
    from completing the same request twice. Fix this layering violation
    by having scsi control the fate of its commands with scsi owned flags
    rather than use blk-mq's.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Keith Busch <keith.busch@intel.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0df15cb738d2..0dbf25512778 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1642,8 +1642,18 @@ static blk_status_t scsi_mq_prep_fn(struct request *req)
 
 static void scsi_mq_done(struct scsi_cmnd *cmd)
 {
+	if (unlikely(test_and_set_bit(SCMD_STATE_COMPLETE, &cmd->state)))
+		return;
 	trace_scsi_dispatch_cmd_done(cmd);
-	blk_mq_complete_request(cmd->request);
+
+	/*
+	 * If the block layer didn't complete the request due to a timeout
+	 * injection, scsi must clear its internal completed state so that the
+	 * timeout handler will see it needs to escalate its own error
+	 * recovery.
+	 */
+	if (unlikely(!blk_mq_complete_request(cmd->request)))
+		clear_bit(SCMD_STATE_COMPLETE, &cmd->state);
 }
 
 static void scsi_mq_put_budget(struct blk_mq_hw_ctx *hctx)
@@ -1702,6 +1712,7 @@ static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	if (!scsi_host_queue_ready(q, shost, sdev))
 		goto out_dec_target_busy;
 
+	clear_bit(SCMD_STATE_COMPLETE, &cmd->state);
 	if (!(req->rq_flags & RQF_DONTPREP)) {
 		ret = scsi_mq_prep_fn(req);
 		if (ret != BLK_STS_OK)

commit a78b03bc7300e4f17b1e510884bea1095d92b17b
Merge: fce15a609f8f 9ff01193a20d
Author: Jens Axboe <axboe@kernel.dk>
Date:   Sun Nov 18 15:46:03 2018 -0700

    Merge tag 'v4.20-rc3' into for-4.21/block
    
    Merge in -rc3 to resolve a few conflicts, but also to get a few
    important fixes that have gone into mainline since the block
    4.21 branch was forked off (most notably the SCSI queue issue,
    which is both a conflict AND needed fix).
    
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

commit 8dc765d438f1e42b3e8227b3b09fad7d73f4ec9a
Author: Ming Lei <ming.lei@redhat.com>
Date:   Wed Nov 14 16:25:51 2018 +0800

    SCSI: fix queue cleanup race before queue initialization is done
    
    c2856ae2f315d ("blk-mq: quiesce queue before freeing queue") has
    already fixed this race, however the implied synchronize_rcu()
    in blk_mq_quiesce_queue() can slow down LUN probe a lot, so caused
    performance regression.
    
    Then 1311326cf4755c7 ("blk-mq: avoid to synchronize rcu inside blk_cleanup_queue()")
    tried to quiesce queue for avoiding unnecessary synchronize_rcu()
    only when queue initialization is done, because it is usual to see
    lots of inexistent LUNs which need to be probed.
    
    However, turns out it isn't safe to quiesce queue only when queue
    initialization is done. Because when one SCSI command is completed,
    the user of sending command can be waken up immediately, then the
    scsi device may be removed, meantime the run queue in scsi_end_request()
    is still in-progress, so kernel panic can be caused.
    
    In Red Hat QE lab, there are several reports about this kind of kernel
    panic triggered during kernel booting.
    
    This patch tries to address the issue by grabing one queue usage
    counter during freeing one request and the following run queue.
    
    Fixes: 1311326cf4755c7 ("blk-mq: avoid to synchronize rcu inside blk_cleanup_queue()")
    Cc: Andrew Jones <drjones@redhat.com>
    Cc: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: linux-scsi@vger.kernel.org
    Cc: Martin K. Petersen <martin.petersen@oracle.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: James E.J. Bottomley <jejb@linux.vnet.ibm.com>
    Cc: stable <stable@vger.kernel.org>
    Cc: jianchao.wang <jianchao.w.wang@oracle.com>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c7fccbb8f554..fa6e0c3b3aa6 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -697,6 +697,12 @@ static bool scsi_end_request(struct request *req, blk_status_t error,
 		 */
 		scsi_mq_uninit_cmd(cmd);
 
+		/*
+		 * queue is still alive, so grab the ref for preventing it
+		 * from being cleaned up during running queue.
+		 */
+		percpu_ref_get(&q->q_usage_counter);
+
 		__blk_mq_end_request(req, error);
 
 		if (scsi_target(sdev)->single_lun ||
@@ -704,6 +710,8 @@ static bool scsi_end_request(struct request *req, blk_status_t error,
 			kblockd_schedule_work(&sdev->requeue_work);
 		else
 			blk_mq_run_hw_queues(q, true);
+
+		percpu_ref_put(&q->q_usage_counter);
 	} else {
 		unsigned long flags;
 

commit 4c1cb67c03511a4a404aaaeb206222d5bebdc4ca
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Nov 9 14:42:40 2018 +0100

    scsi: return blk_status_t from device handler ->prep_fn
    
    Remove the last use of the old BLKPREP_* values, which get converted
    to BLK_STS_* later anyway.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 3e3bdeee8f14..5d83a162d03b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1177,18 +1177,6 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 	scsi_add_cmd_to_list(cmd);
 }
 
-static inline blk_status_t prep_to_mq(int ret)
-{
-	switch (ret) {
-	case BLKPREP_OK:
-		return BLK_STS_OK;
-	case BLKPREP_DEFER:
-		return BLK_STS_RESOURCE;
-	default:
-		return BLK_STS_IOERR;
-	}
-}
-
 static blk_status_t scsi_setup_scsi_cmnd(struct scsi_device *sdev,
 		struct request *req)
 {
@@ -1227,9 +1215,9 @@ static blk_status_t scsi_setup_fs_cmnd(struct scsi_device *sdev,
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
 
 	if (unlikely(sdev->handler && sdev->handler->prep_fn)) {
-		int ret = sdev->handler->prep_fn(sdev, req);
-		if (ret != BLKPREP_OK)
-			return prep_to_mq(ret);
+		blk_status_t ret = sdev->handler->prep_fn(sdev, req);
+		if (ret != BLK_STS_OK)
+			return ret;
 	}
 
 	cmd->cmnd = scsi_req(req)->cmd = scsi_req(req)->__cmd;

commit 159b2cbf59f44f2a0c005c1f323f8f05fb0a19f8
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Nov 9 14:42:39 2018 +0100

    scsi: return blk_status_t from scsi_init_io and ->init_command
    
    Replace the old BLKPREP_* values with the BLK_STS_ ones that they are
    converted to later anyway.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1f84e2cec57b..3e3bdeee8f14 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1005,7 +1005,8 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		scsi_io_completion_action(cmd, result);
 }
 
-static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb)
+static blk_status_t scsi_init_sgtable(struct request *req,
+		struct scsi_data_buffer *sdb)
 {
 	int count;
 
@@ -1014,7 +1015,7 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb)
 	 */
 	if (unlikely(sg_alloc_table_chained(&sdb->table,
 			blk_rq_nr_phys_segments(req), sdb->table.sgl)))
-		return BLKPREP_DEFER;
+		return BLK_STS_RESOURCE;
 
 	/* 
 	 * Next, walk the list, and fill in the addresses and sizes of
@@ -1024,7 +1025,7 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb)
 	BUG_ON(count > sdb->table.nents);
 	sdb->table.nents = count;
 	sdb->length = blk_rq_payload_bytes(req);
-	return BLKPREP_OK;
+	return BLK_STS_OK;
 }
 
 /*
@@ -1034,25 +1035,25 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb)
  *
  * Arguments:   cmd   - Command descriptor we wish to initialize
  *
- * Returns:     0 on success
- *		BLKPREP_DEFER if the failure is retryable
- *		BLKPREP_KILL if the failure is fatal
+ * Returns:     BLK_STS_OK on success
+ *		BLK_STS_RESOURCE if the failure is retryable
+ *		BLK_STS_IOERR if the failure is fatal
  */
-int scsi_init_io(struct scsi_cmnd *cmd)
+blk_status_t scsi_init_io(struct scsi_cmnd *cmd)
 {
 	struct request *rq = cmd->request;
-	int error = BLKPREP_KILL;
+	blk_status_t ret;
 
 	if (WARN_ON_ONCE(!blk_rq_nr_phys_segments(rq)))
-		return BLKPREP_KILL;
+		return BLK_STS_IOERR;
 
-	error = scsi_init_sgtable(rq, &cmd->sdb);
-	if (error)
-		return error;
+	ret = scsi_init_sgtable(rq, &cmd->sdb);
+	if (ret)
+		return ret;
 
 	if (blk_bidi_rq(rq)) {
-		error = scsi_init_sgtable(rq->next_rq, rq->next_rq->special);
-		if (error)
+		ret = scsi_init_sgtable(rq->next_rq, rq->next_rq->special);
+		if (ret)
 			goto out_free_sgtables;
 	}
 
@@ -1066,7 +1067,7 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 			 * queues a command to a device on an adapter
 			 * that does not support DIX.
 			 */
-			error = BLKPREP_KILL;
+			ret = BLK_STS_IOERR;
 			goto out_free_sgtables;
 		}
 
@@ -1074,7 +1075,7 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 
 		if (sg_alloc_table_chained(&prot_sdb->table, ivecs,
 				prot_sdb->table.sgl)) {
-			error = BLKPREP_DEFER;
+			ret = BLK_STS_RESOURCE;
 			goto out_free_sgtables;
 		}
 
@@ -1087,10 +1088,10 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 		cmd->prot_sdb->table.nents = count;
 	}
 
-	return BLKPREP_OK;
+	return BLK_STS_OK;
 out_free_sgtables:
 	scsi_mq_free_sgtables(cmd);
-	return error;
+	return ret;
 }
 EXPORT_SYMBOL(scsi_init_io);
 
@@ -1200,9 +1201,9 @@ static blk_status_t scsi_setup_scsi_cmnd(struct scsi_device *sdev,
 	 * submit a request without an attached bio.
 	 */
 	if (req->bio) {
-		int ret = scsi_init_io(cmd);
-		if (unlikely(ret))
-			return prep_to_mq(ret);
+		blk_status_t ret = scsi_init_io(cmd);
+		if (unlikely(ret != BLK_STS_OK))
+			return ret;
 	} else {
 		BUG_ON(blk_rq_bytes(req));
 
@@ -1233,7 +1234,7 @@ static blk_status_t scsi_setup_fs_cmnd(struct scsi_device *sdev,
 
 	cmd->cmnd = scsi_req(req)->cmd = scsi_req(req)->__cmd;
 	memset(cmd->cmnd, 0, BLK_MAX_CDB);
-	return prep_to_mq(scsi_cmd_to_driver(cmd)->init_command(cmd));
+	return scsi_cmd_to_driver(cmd)->init_command(cmd);
 }
 
 static blk_status_t scsi_setup_cmnd(struct scsi_device *sdev,

commit 14784565f740e862adae4b1d7c91f51b4038c4f5
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Nov 9 14:42:38 2018 +0100

    scsi: clean up error handling in scsi_init_io
    
    There is no need to call scsi_mq_free_sgtables until we have actually
    allocated sgtables.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e665c25da144..1f84e2cec57b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1044,31 +1044,30 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 	int error = BLKPREP_KILL;
 
 	if (WARN_ON_ONCE(!blk_rq_nr_phys_segments(rq)))
-		goto err_exit;
+		return BLKPREP_KILL;
 
 	error = scsi_init_sgtable(rq, &cmd->sdb);
 	if (error)
-		goto err_exit;
+		return error;
 
 	if (blk_bidi_rq(rq)) {
 		error = scsi_init_sgtable(rq->next_rq, rq->next_rq->special);
 		if (error)
-			goto err_exit;
+			goto out_free_sgtables;
 	}
 
 	if (blk_integrity_rq(rq)) {
 		struct scsi_data_buffer *prot_sdb = cmd->prot_sdb;
 		int ivecs, count;
 
-		if (prot_sdb == NULL) {
+		if (WARN_ON_ONCE(!prot_sdb)) {
 			/*
 			 * This can happen if someone (e.g. multipath)
 			 * queues a command to a device on an adapter
 			 * that does not support DIX.
 			 */
-			WARN_ON_ONCE(1);
 			error = BLKPREP_KILL;
-			goto err_exit;
+			goto out_free_sgtables;
 		}
 
 		ivecs = blk_rq_count_integrity_sg(rq->q, rq->bio);
@@ -1076,7 +1075,7 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 		if (sg_alloc_table_chained(&prot_sdb->table, ivecs,
 				prot_sdb->table.sgl)) {
 			error = BLKPREP_DEFER;
-			goto err_exit;
+			goto out_free_sgtables;
 		}
 
 		count = blk_rq_map_integrity_sg(rq->q, rq->bio,
@@ -1089,7 +1088,7 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 	}
 
 	return BLKPREP_OK;
-err_exit:
+out_free_sgtables:
 	scsi_mq_free_sgtables(cmd);
 	return error;
 }

commit 785ba83b4f3e4fde236f03205dd1cd98fd6a5255
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Nov 9 14:42:37 2018 +0100

    scsi: push blk_status_t up into scsi_setup_{fs,scsi}_cmnd
    
    This just moves the prep_to_mq calls up in preparation of further removal
    of BLKPREP_* usage.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 5ecabb3e77b7..e665c25da144 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1177,7 +1177,20 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 	scsi_add_cmd_to_list(cmd);
 }
 
-static int scsi_setup_scsi_cmnd(struct scsi_device *sdev, struct request *req)
+static inline blk_status_t prep_to_mq(int ret)
+{
+	switch (ret) {
+	case BLKPREP_OK:
+		return BLK_STS_OK;
+	case BLKPREP_DEFER:
+		return BLK_STS_RESOURCE;
+	default:
+		return BLK_STS_IOERR;
+	}
+}
+
+static blk_status_t scsi_setup_scsi_cmnd(struct scsi_device *sdev,
+		struct request *req)
 {
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
 
@@ -1190,7 +1203,7 @@ static int scsi_setup_scsi_cmnd(struct scsi_device *sdev, struct request *req)
 	if (req->bio) {
 		int ret = scsi_init_io(cmd);
 		if (unlikely(ret))
-			return ret;
+			return prep_to_mq(ret);
 	} else {
 		BUG_ON(blk_rq_bytes(req));
 
@@ -1201,29 +1214,31 @@ static int scsi_setup_scsi_cmnd(struct scsi_device *sdev, struct request *req)
 	cmd->cmnd = scsi_req(req)->cmd;
 	cmd->transfersize = blk_rq_bytes(req);
 	cmd->allowed = scsi_req(req)->retries;
-	return BLKPREP_OK;
+	return BLK_STS_OK;
 }
 
 /*
  * Setup a normal block command.  These are simple request from filesystems
  * that still need to be translated to SCSI CDBs from the ULD.
  */
-static int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
+static blk_status_t scsi_setup_fs_cmnd(struct scsi_device *sdev,
+		struct request *req)
 {
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
 
 	if (unlikely(sdev->handler && sdev->handler->prep_fn)) {
 		int ret = sdev->handler->prep_fn(sdev, req);
 		if (ret != BLKPREP_OK)
-			return ret;
+			return prep_to_mq(ret);
 	}
 
 	cmd->cmnd = scsi_req(req)->cmd = scsi_req(req)->__cmd;
 	memset(cmd->cmnd, 0, BLK_MAX_CDB);
-	return scsi_cmd_to_driver(cmd)->init_command(cmd);
+	return prep_to_mq(scsi_cmd_to_driver(cmd)->init_command(cmd));
 }
 
-static int scsi_setup_cmnd(struct scsi_device *sdev, struct request *req)
+static blk_status_t scsi_setup_cmnd(struct scsi_device *sdev,
+		struct request *req)
 {
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
 
@@ -1581,18 +1596,6 @@ static int scsi_dispatch_cmd(struct scsi_cmnd *cmd)
 	return 0;
 }
 
-static inline blk_status_t prep_to_mq(int ret)
-{
-	switch (ret) {
-	case BLKPREP_OK:
-		return BLK_STS_OK;
-	case BLKPREP_DEFER:
-		return BLK_STS_RESOURCE;
-	default:
-		return BLK_STS_IOERR;
-	}
-}
-
 /* Size in bytes of the sg-list stored in the scsi-mq command-private data. */
 static unsigned int scsi_mq_sgl_size(struct Scsi_Host *shost)
 {
@@ -1600,7 +1603,7 @@ static unsigned int scsi_mq_sgl_size(struct Scsi_Host *shost)
 		sizeof(struct scatterlist);
 }
 
-static int scsi_mq_prep_fn(struct request *req)
+static blk_status_t scsi_mq_prep_fn(struct request *req)
 {
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
 	struct scsi_device *sdev = req->q->queuedata;
@@ -1705,7 +1708,7 @@ static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 		goto out_dec_target_busy;
 
 	if (!(req->rq_flags & RQF_DONTPREP)) {
-		ret = prep_to_mq(scsi_mq_prep_fn(req));
+		ret = scsi_mq_prep_fn(req);
 		if (ret != BLK_STS_OK)
 			goto out_dec_host_busy;
 		req->rq_flags |= RQF_DONTPREP;

commit c092d4ec53c9c7e690ad517b414078db4da6870b
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Nov 9 14:42:36 2018 +0100

    scsi: simplify scsi_prep_state_check
    
    Return a blk_status_t directly, and make the code a little more compact
    by handling the fast path in the caller.
    
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ed81b8e74cfe..5ecabb3e77b7 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1240,60 +1240,48 @@ static int scsi_setup_cmnd(struct scsi_device *sdev, struct request *req)
 		return scsi_setup_fs_cmnd(sdev, req);
 }
 
-static int
+static blk_status_t
 scsi_prep_state_check(struct scsi_device *sdev, struct request *req)
 {
-	int ret = BLKPREP_OK;
-
-	/*
-	 * If the device is not in running state we will reject some
-	 * or all commands.
-	 */
-	if (unlikely(sdev->sdev_state != SDEV_RUNNING)) {
-		switch (sdev->sdev_state) {
-		case SDEV_OFFLINE:
-		case SDEV_TRANSPORT_OFFLINE:
-			/*
-			 * If the device is offline we refuse to process any
-			 * commands.  The device must be brought online
-			 * before trying any recovery commands.
-			 */
-			sdev_printk(KERN_ERR, sdev,
-				    "rejecting I/O to offline device\n");
-			ret = BLKPREP_KILL;
-			break;
-		case SDEV_DEL:
-			/*
-			 * If the device is fully deleted, we refuse to
-			 * process any commands as well.
-			 */
-			sdev_printk(KERN_ERR, sdev,
-				    "rejecting I/O to dead device\n");
-			ret = BLKPREP_KILL;
-			break;
-		case SDEV_BLOCK:
-		case SDEV_CREATED_BLOCK:
-			ret = BLKPREP_DEFER;
-			break;
-		case SDEV_QUIESCE:
-			/*
-			 * If the devices is blocked we defer normal commands.
-			 */
-			if (req && !(req->rq_flags & RQF_PREEMPT))
-				ret = BLKPREP_DEFER;
-			break;
-		default:
-			/*
-			 * For any other not fully online state we only allow
-			 * special commands.  In particular any user initiated
-			 * command is not allowed.
-			 */
-			if (req && !(req->rq_flags & RQF_PREEMPT))
-				ret = BLKPREP_KILL;
-			break;
-		}
+	switch (sdev->sdev_state) {
+	case SDEV_OFFLINE:
+	case SDEV_TRANSPORT_OFFLINE:
+		/*
+		 * If the device is offline we refuse to process any
+		 * commands.  The device must be brought online
+		 * before trying any recovery commands.
+		 */
+		sdev_printk(KERN_ERR, sdev,
+			    "rejecting I/O to offline device\n");
+		return BLK_STS_IOERR;
+	case SDEV_DEL:
+		/*
+		 * If the device is fully deleted, we refuse to
+		 * process any commands as well.
+		 */
+		sdev_printk(KERN_ERR, sdev,
+			    "rejecting I/O to dead device\n");
+		return BLK_STS_IOERR;
+	case SDEV_BLOCK:
+	case SDEV_CREATED_BLOCK:
+		return BLK_STS_RESOURCE;
+	case SDEV_QUIESCE:
+		/*
+		 * If the devices is blocked we defer normal commands.
+		 */
+		if (req && !(req->rq_flags & RQF_PREEMPT))
+			return BLK_STS_RESOURCE;
+		return BLK_STS_OK;
+	default:
+		/*
+		 * For any other not fully online state we only allow
+		 * special commands.  In particular any user initiated
+		 * command is not allowed.
+		 */
+		if (req && !(req->rq_flags & RQF_PREEMPT))
+			return BLK_STS_IOERR;
+		return BLK_STS_OK;
 	}
-	return ret;
 }
 
 /*
@@ -1700,9 +1688,15 @@ static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	blk_status_t ret;
 	int reason;
 
-	ret = prep_to_mq(scsi_prep_state_check(sdev, req));
-	if (ret != BLK_STS_OK)
-		goto out_put_budget;
+	/*
+	 * If the device is not in running state we will reject some or all
+	 * commands.
+	 */
+	if (unlikely(sdev->sdev_state != SDEV_RUNNING)) {
+		ret = scsi_prep_state_check(sdev, req);
+		if (ret != BLK_STS_OK)
+			goto out_put_budget;
+	}
 
 	ret = BLK_STS_RESOURCE;
 	if (!scsi_target_queue_ready(shost, sdev))

commit ed76e329d74a4b15ac0f5fd3adbd52ec0178a134
Author: Jens Axboe <axboe@kernel.dk>
Date:   Mon Oct 29 13:06:14 2018 -0600

    blk-mq: abstract out queue map
    
    This is in preparation for allowing multiple sets of maps per
    queue, if so desired.
    
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Keith Busch <keith.busch@intel.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 651be30ba96a..ed81b8e74cfe 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1812,7 +1812,7 @@ static int scsi_map_queues(struct blk_mq_tag_set *set)
 
 	if (shost->hostt->map_queues)
 		return shost->hostt->map_queues(shost);
-	return blk_mq_map_queues(set);
+	return blk_mq_map_queues(&set->map[0]);
 }
 
 void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)

commit f664a3cc17b7d0a2bc3b3ab96181e1029b0ec0e6
Author: Jens Axboe <axboe@kernel.dk>
Date:   Thu Nov 1 16:36:27 2018 -0600

    scsi: kill off the legacy IO path
    
    This removes the legacy (non-mq) IO path for SCSI.
    
    Cc: linux-scsi@vger.kernel.org
    Acked-by: Himanshu Madhani <himanshu.madhani@cavium.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Tested-by: Ming Lei <ming.lei@redhat.com>
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Acked-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 8b0345924a92..651be30ba96a 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -168,8 +168,6 @@ static void scsi_mq_requeue_cmd(struct scsi_cmnd *cmd)
 static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, bool unbusy)
 {
 	struct scsi_device *device = cmd->device;
-	struct request_queue *q = device->request_queue;
-	unsigned long flags;
 
 	SCSI_LOG_MLQUEUE(1, scmd_printk(KERN_INFO, cmd,
 		"Inserting command %p into mlqueue\n", cmd));
@@ -190,26 +188,20 @@ static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, bool unbusy)
 	 * before blk_cleanup_queue() finishes.
 	 */
 	cmd->result = 0;
-	if (q->mq_ops) {
-		/*
-		 * Before a SCSI command is dispatched,
-		 * get_device(&sdev->sdev_gendev) is called and the host,
-		 * target and device busy counters are increased. Since
-		 * requeuing a request causes these actions to be repeated and
-		 * since scsi_device_unbusy() has already been called,
-		 * put_device(&device->sdev_gendev) must still be called. Call
-		 * put_device() after blk_mq_requeue_request() to avoid that
-		 * removal of the SCSI device can start before requeueing has
-		 * happened.
-		 */
-		blk_mq_requeue_request(cmd->request, true);
-		put_device(&device->sdev_gendev);
-		return;
-	}
-	spin_lock_irqsave(q->queue_lock, flags);
-	blk_requeue_request(q, cmd->request);
-	kblockd_schedule_work(&device->requeue_work);
-	spin_unlock_irqrestore(q->queue_lock, flags);
+
+	/*
+	 * Before a SCSI command is dispatched,
+	 * get_device(&sdev->sdev_gendev) is called and the host,
+	 * target and device busy counters are increased. Since
+	 * requeuing a request causes these actions to be repeated and
+	 * since scsi_device_unbusy() has already been called,
+	 * put_device(&device->sdev_gendev) must still be called. Call
+	 * put_device() after blk_mq_requeue_request() to avoid that
+	 * removal of the SCSI device can start before requeueing has
+	 * happened.
+	 */
+	blk_mq_requeue_request(cmd->request, true);
+	put_device(&device->sdev_gendev);
 }
 
 /*
@@ -370,10 +362,7 @@ void scsi_device_unbusy(struct scsi_device *sdev)
 
 static void scsi_kick_queue(struct request_queue *q)
 {
-	if (q->mq_ops)
-		blk_mq_run_hw_queues(q, false);
-	else
-		blk_run_queue(q);
+	blk_mq_run_hw_queues(q, false);
 }
 
 /*
@@ -534,10 +523,7 @@ static void scsi_run_queue(struct request_queue *q)
 	if (!list_empty(&sdev->host->starved_list))
 		scsi_starved_list_run(sdev->host);
 
-	if (q->mq_ops)
-		blk_mq_run_hw_queues(q, false);
-	else
-		blk_run_queue(q);
+	blk_mq_run_hw_queues(q, false);
 }
 
 void scsi_requeue_run_queue(struct work_struct *work)
@@ -550,42 +536,6 @@ void scsi_requeue_run_queue(struct work_struct *work)
 	scsi_run_queue(q);
 }
 
-/*
- * Function:	scsi_requeue_command()
- *
- * Purpose:	Handle post-processing of completed commands.
- *
- * Arguments:	q	- queue to operate on
- *		cmd	- command that may need to be requeued.
- *
- * Returns:	Nothing
- *
- * Notes:	After command completion, there may be blocks left
- *		over which weren't finished by the previous command
- *		this can be for a number of reasons - the main one is
- *		I/O errors in the middle of the request, in which case
- *		we need to request the blocks that come after the bad
- *		sector.
- * Notes:	Upon return, cmd is a stale pointer.
- */
-static void scsi_requeue_command(struct request_queue *q, struct scsi_cmnd *cmd)
-{
-	struct scsi_device *sdev = cmd->device;
-	struct request *req = cmd->request;
-	unsigned long flags;
-
-	spin_lock_irqsave(q->queue_lock, flags);
-	blk_unprep_request(req);
-	req->special = NULL;
-	scsi_put_command(cmd);
-	blk_requeue_request(q, req);
-	spin_unlock_irqrestore(q->queue_lock, flags);
-
-	scsi_run_queue(q);
-
-	put_device(&sdev->sdev_gendev);
-}
-
 void scsi_run_host_queues(struct Scsi_Host *shost)
 {
 	struct scsi_device *sdev;
@@ -626,42 +576,6 @@ static void scsi_mq_uninit_cmd(struct scsi_cmnd *cmd)
 	scsi_del_cmd_from_list(cmd);
 }
 
-/*
- * Function:    scsi_release_buffers()
- *
- * Purpose:     Free resources allocate for a scsi_command.
- *
- * Arguments:   cmd	- command that we are bailing.
- *
- * Lock status: Assumed that no lock is held upon entry.
- *
- * Returns:     Nothing
- *
- * Notes:       In the event that an upper level driver rejects a
- *		command, we must release resources allocated during
- *		the __init_io() function.  Primarily this would involve
- *		the scatter-gather table.
- */
-static void scsi_release_buffers(struct scsi_cmnd *cmd)
-{
-	if (cmd->sdb.table.nents)
-		sg_free_table_chained(&cmd->sdb.table, false);
-
-	memset(&cmd->sdb, 0, sizeof(cmd->sdb));
-
-	if (scsi_prot_sg_count(cmd))
-		sg_free_table_chained(&cmd->prot_sdb->table, false);
-}
-
-static void scsi_release_bidi_buffers(struct scsi_cmnd *cmd)
-{
-	struct scsi_data_buffer *bidi_sdb = cmd->request->next_rq->special;
-
-	sg_free_table_chained(&bidi_sdb->table, false);
-	kmem_cache_free(scsi_sdb_cache, bidi_sdb);
-	cmd->request->next_rq->special = NULL;
-}
-
 /* Returns false when no more bytes to process, true if there are more */
 static bool scsi_end_request(struct request *req, blk_status_t error,
 		unsigned int bytes, unsigned int bidi_bytes)
@@ -687,37 +601,22 @@ static bool scsi_end_request(struct request *req, blk_status_t error,
 		destroy_rcu_head(&cmd->rcu);
 	}
 
-	if (req->mq_ctx) {
-		/*
-		 * In the MQ case the command gets freed by __blk_mq_end_request,
-		 * so we have to do all cleanup that depends on it earlier.
-		 *
-		 * We also can't kick the queues from irq context, so we
-		 * will have to defer it to a workqueue.
-		 */
-		scsi_mq_uninit_cmd(cmd);
-
-		__blk_mq_end_request(req, error);
-
-		if (scsi_target(sdev)->single_lun ||
-		    !list_empty(&sdev->host->starved_list))
-			kblockd_schedule_work(&sdev->requeue_work);
-		else
-			blk_mq_run_hw_queues(q, true);
-	} else {
-		unsigned long flags;
-
-		if (bidi_bytes)
-			scsi_release_bidi_buffers(cmd);
-		scsi_release_buffers(cmd);
-		scsi_put_command(cmd);
+	/*
+	 * In the MQ case the command gets freed by __blk_mq_end_request,
+	 * so we have to do all cleanup that depends on it earlier.
+	 *
+	 * We also can't kick the queues from irq context, so we
+	 * will have to defer it to a workqueue.
+	 */
+	scsi_mq_uninit_cmd(cmd);
 
-		spin_lock_irqsave(q->queue_lock, flags);
-		blk_finish_request(req, error);
-		spin_unlock_irqrestore(q->queue_lock, flags);
+	__blk_mq_end_request(req, error);
 
-		scsi_run_queue(q);
-	}
+	if (scsi_target(sdev)->single_lun ||
+	    !list_empty(&sdev->host->starved_list))
+		kblockd_schedule_work(&sdev->requeue_work);
+	else
+		blk_mq_run_hw_queues(q, true);
 
 	put_device(&sdev->sdev_gendev);
 	return false;
@@ -766,13 +665,7 @@ static void scsi_io_completion_reprep(struct scsi_cmnd *cmd,
 				      struct request_queue *q)
 {
 	/* A new command will be prepared and issued. */
-	if (q->mq_ops) {
-		scsi_mq_requeue_cmd(cmd);
-	} else {
-		/* Unprep request and put it back at head of the queue. */
-		scsi_release_buffers(cmd);
-		scsi_requeue_command(q, cmd);
-	}
+	scsi_mq_requeue_cmd(cmd);
 }
 
 /* Helper for scsi_io_completion() when special action required. */
@@ -1147,9 +1040,7 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb)
  */
 int scsi_init_io(struct scsi_cmnd *cmd)
 {
-	struct scsi_device *sdev = cmd->device;
 	struct request *rq = cmd->request;
-	bool is_mq = (rq->mq_ctx != NULL);
 	int error = BLKPREP_KILL;
 
 	if (WARN_ON_ONCE(!blk_rq_nr_phys_segments(rq)))
@@ -1160,17 +1051,6 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 		goto err_exit;
 
 	if (blk_bidi_rq(rq)) {
-		if (!rq->q->mq_ops) {
-			struct scsi_data_buffer *bidi_sdb =
-				kmem_cache_zalloc(scsi_sdb_cache, GFP_ATOMIC);
-			if (!bidi_sdb) {
-				error = BLKPREP_DEFER;
-				goto err_exit;
-			}
-
-			rq->next_rq->special = bidi_sdb;
-		}
-
 		error = scsi_init_sgtable(rq->next_rq, rq->next_rq->special);
 		if (error)
 			goto err_exit;
@@ -1210,14 +1090,7 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 
 	return BLKPREP_OK;
 err_exit:
-	if (is_mq) {
-		scsi_mq_free_sgtables(cmd);
-	} else {
-		scsi_release_buffers(cmd);
-		cmd->request->special = NULL;
-		scsi_put_command(cmd);
-		put_device(&sdev->sdev_gendev);
-	}
+	scsi_mq_free_sgtables(cmd);
 	return error;
 }
 EXPORT_SYMBOL(scsi_init_io);
@@ -1423,75 +1296,6 @@ scsi_prep_state_check(struct scsi_device *sdev, struct request *req)
 	return ret;
 }
 
-static int
-scsi_prep_return(struct request_queue *q, struct request *req, int ret)
-{
-	struct scsi_device *sdev = q->queuedata;
-
-	switch (ret) {
-	case BLKPREP_KILL:
-	case BLKPREP_INVALID:
-		scsi_req(req)->result = DID_NO_CONNECT << 16;
-		/* release the command and kill it */
-		if (req->special) {
-			struct scsi_cmnd *cmd = req->special;
-			scsi_release_buffers(cmd);
-			scsi_put_command(cmd);
-			put_device(&sdev->sdev_gendev);
-			req->special = NULL;
-		}
-		break;
-	case BLKPREP_DEFER:
-		/*
-		 * If we defer, the blk_peek_request() returns NULL, but the
-		 * queue must be restarted, so we schedule a callback to happen
-		 * shortly.
-		 */
-		if (atomic_read(&sdev->device_busy) == 0)
-			blk_delay_queue(q, SCSI_QUEUE_DELAY);
-		break;
-	default:
-		req->rq_flags |= RQF_DONTPREP;
-	}
-
-	return ret;
-}
-
-static int scsi_prep_fn(struct request_queue *q, struct request *req)
-{
-	struct scsi_device *sdev = q->queuedata;
-	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
-	int ret;
-
-	ret = scsi_prep_state_check(sdev, req);
-	if (ret != BLKPREP_OK)
-		goto out;
-
-	if (!req->special) {
-		/* Bail if we can't get a reference to the device */
-		if (unlikely(!get_device(&sdev->sdev_gendev))) {
-			ret = BLKPREP_DEFER;
-			goto out;
-		}
-
-		scsi_init_command(sdev, cmd);
-		req->special = cmd;
-	}
-
-	cmd->tag = req->tag;
-	cmd->request = req;
-	cmd->prot_op = SCSI_PROT_NORMAL;
-
-	ret = scsi_setup_cmnd(sdev, req);
-out:
-	return scsi_prep_return(q, req, ret);
-}
-
-static void scsi_unprep_fn(struct request_queue *q, struct request *req)
-{
-	scsi_uninit_cmd(blk_mq_rq_to_pdu(req));
-}
-
 /*
  * scsi_dev_queue_ready: if we can send requests to sdev, return 1 else
  * return 0.
@@ -1511,14 +1315,8 @@ static inline int scsi_dev_queue_ready(struct request_queue *q,
 		/*
 		 * unblock after device_blocked iterates to zero
 		 */
-		if (atomic_dec_return(&sdev->device_blocked) > 0) {
-			/*
-			 * For the MQ case we take care of this in the caller.
-			 */
-			if (!q->mq_ops)
-				blk_delay_queue(q, SCSI_QUEUE_DELAY);
+		if (atomic_dec_return(&sdev->device_blocked) > 0)
 			goto out_dec;
-		}
 		SCSI_LOG_MLQUEUE(3, sdev_printk(KERN_INFO, sdev,
 				   "unblocking device at zero depth\n"));
 	}
@@ -1653,13 +1451,13 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
  * needs to return 'not busy'. Otherwise, request stacking drivers
  * may hold requests forever.
  */
-static int scsi_lld_busy(struct request_queue *q)
+static bool scsi_mq_lld_busy(struct request_queue *q)
 {
 	struct scsi_device *sdev = q->queuedata;
 	struct Scsi_Host *shost;
 
 	if (blk_queue_dying(q))
-		return 0;
+		return false;
 
 	shost = sdev->host;
 
@@ -1670,48 +1468,9 @@ static int scsi_lld_busy(struct request_queue *q)
 	 * in SCSI layer.
 	 */
 	if (scsi_host_in_recovery(shost) || scsi_device_is_busy(sdev))
-		return 1;
-
-	return 0;
-}
-
-static bool scsi_mq_lld_busy(struct request_queue *q)
-{
-	return scsi_lld_busy(q);
-}
-
-/*
- * Kill a request for a dead device
- */
-static void scsi_kill_request(struct request *req, struct request_queue *q)
-{
-	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
-	struct scsi_device *sdev;
-	struct scsi_target *starget;
-	struct Scsi_Host *shost;
-
-	blk_start_request(req);
-
-	scmd_printk(KERN_INFO, cmd, "killing request\n");
-
-	sdev = cmd->device;
-	starget = scsi_target(sdev);
-	shost = sdev->host;
-	scsi_init_cmd_errh(cmd);
-	cmd->result = DID_NO_CONNECT << 16;
-	atomic_inc(&cmd->device->iorequest_cnt);
-
-	/*
-	 * SCSI request completion path will do scsi_device_unbusy(),
-	 * bump busy counts.  To bump the counters, we need to dance
-	 * with the locks as normal issue path does.
-	 */
-	atomic_inc(&sdev->device_busy);
-	atomic_inc(&shost->host_busy);
-	if (starget->can_queue > 0)
-		atomic_inc(&starget->target_busy);
+		return true;
 
-	blk_complete_request(req);
+	return false;
 }
 
 static void scsi_softirq_done(struct request *rq)
@@ -1834,158 +1593,6 @@ static int scsi_dispatch_cmd(struct scsi_cmnd *cmd)
 	return 0;
 }
 
-/**
- * scsi_done - Invoke completion on finished SCSI command.
- * @cmd: The SCSI Command for which a low-level device driver (LLDD) gives
- * ownership back to SCSI Core -- i.e. the LLDD has finished with it.
- *
- * Description: This function is the mid-level's (SCSI Core) interrupt routine,
- * which regains ownership of the SCSI command (de facto) from a LLDD, and
- * calls blk_complete_request() for further processing.
- *
- * This function is interrupt context safe.
- */
-static void scsi_done(struct scsi_cmnd *cmd)
-{
-	trace_scsi_dispatch_cmd_done(cmd);
-	blk_complete_request(cmd->request);
-}
-
-/*
- * Function:    scsi_request_fn()
- *
- * Purpose:     Main strategy routine for SCSI.
- *
- * Arguments:   q       - Pointer to actual queue.
- *
- * Returns:     Nothing
- *
- * Lock status: request queue lock assumed to be held when called.
- *
- * Note: See sd_zbc.c sd_zbc_write_lock_zone() for write order
- * protection for ZBC disks.
- */
-static void scsi_request_fn(struct request_queue *q)
-	__releases(q->queue_lock)
-	__acquires(q->queue_lock)
-{
-	struct scsi_device *sdev = q->queuedata;
-	struct Scsi_Host *shost;
-	struct scsi_cmnd *cmd;
-	struct request *req;
-
-	/*
-	 * To start with, we keep looping until the queue is empty, or until
-	 * the host is no longer able to accept any more requests.
-	 */
-	shost = sdev->host;
-	for (;;) {
-		int rtn;
-		/*
-		 * get next queueable request.  We do this early to make sure
-		 * that the request is fully prepared even if we cannot
-		 * accept it.
-		 */
-		req = blk_peek_request(q);
-		if (!req)
-			break;
-
-		if (unlikely(!scsi_device_online(sdev))) {
-			sdev_printk(KERN_ERR, sdev,
-				    "rejecting I/O to offline device\n");
-			scsi_kill_request(req, q);
-			continue;
-		}
-
-		if (!scsi_dev_queue_ready(q, sdev))
-			break;
-
-		/*
-		 * Remove the request from the request list.
-		 */
-		if (!(blk_queue_tagged(q) && !blk_queue_start_tag(q, req)))
-			blk_start_request(req);
-
-		spin_unlock_irq(q->queue_lock);
-		cmd = blk_mq_rq_to_pdu(req);
-		if (cmd != req->special) {
-			printk(KERN_CRIT "impossible request in %s.\n"
-					 "please mail a stack trace to "
-					 "linux-scsi@vger.kernel.org\n",
-					 __func__);
-			blk_dump_rq_flags(req, "foo");
-			BUG();
-		}
-
-		/*
-		 * We hit this when the driver is using a host wide
-		 * tag map. For device level tag maps the queue_depth check
-		 * in the device ready fn would prevent us from trying
-		 * to allocate a tag. Since the map is a shared host resource
-		 * we add the dev to the starved list so it eventually gets
-		 * a run when a tag is freed.
-		 */
-		if (blk_queue_tagged(q) && !(req->rq_flags & RQF_QUEUED)) {
-			spin_lock_irq(shost->host_lock);
-			if (list_empty(&sdev->starved_entry))
-				list_add_tail(&sdev->starved_entry,
-					      &shost->starved_list);
-			spin_unlock_irq(shost->host_lock);
-			goto not_ready;
-		}
-
-		if (!scsi_target_queue_ready(shost, sdev))
-			goto not_ready;
-
-		if (!scsi_host_queue_ready(q, shost, sdev))
-			goto host_not_ready;
-	
-		if (sdev->simple_tags)
-			cmd->flags |= SCMD_TAGGED;
-		else
-			cmd->flags &= ~SCMD_TAGGED;
-
-		/*
-		 * Finally, initialize any error handling parameters, and set up
-		 * the timers for timeouts.
-		 */
-		scsi_init_cmd_errh(cmd);
-
-		/*
-		 * Dispatch the command to the low-level driver.
-		 */
-		cmd->scsi_done = scsi_done;
-		rtn = scsi_dispatch_cmd(cmd);
-		if (rtn) {
-			scsi_queue_insert(cmd, rtn);
-			spin_lock_irq(q->queue_lock);
-			goto out_delay;
-		}
-		spin_lock_irq(q->queue_lock);
-	}
-
-	return;
-
- host_not_ready:
-	if (scsi_target(sdev)->can_queue > 0)
-		atomic_dec(&scsi_target(sdev)->target_busy);
- not_ready:
-	/*
-	 * lock q, handle tag, requeue req, and decrement device_busy. We
-	 * must return with queue_lock held.
-	 *
-	 * Decrementing device_busy without checking it is OK, as all such
-	 * cases (host limits or settings) should run the queue at some
-	 * later time.
-	 */
-	spin_lock_irq(q->queue_lock);
-	blk_requeue_request(q, req);
-	atomic_dec(&sdev->device_busy);
-out_delay:
-	if (!atomic_read(&sdev->device_busy) && !scsi_device_blocked(sdev))
-		blk_delay_queue(q, SCSI_QUEUE_DELAY);
-}
-
 static inline blk_status_t prep_to_mq(int ret)
 {
 	switch (ret) {
@@ -2248,77 +1855,6 @@ void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 }
 EXPORT_SYMBOL_GPL(__scsi_init_queue);
 
-static int scsi_old_init_rq(struct request_queue *q, struct request *rq,
-			    gfp_t gfp)
-{
-	struct Scsi_Host *shost = q->rq_alloc_data;
-	const bool unchecked_isa_dma = shost->unchecked_isa_dma;
-	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
-
-	memset(cmd, 0, sizeof(*cmd));
-
-	if (unchecked_isa_dma)
-		cmd->flags |= SCMD_UNCHECKED_ISA_DMA;
-	cmd->sense_buffer = scsi_alloc_sense_buffer(unchecked_isa_dma, gfp,
-						    NUMA_NO_NODE);
-	if (!cmd->sense_buffer)
-		goto fail;
-	cmd->req.sense = cmd->sense_buffer;
-
-	if (scsi_host_get_prot(shost) >= SHOST_DIX_TYPE0_PROTECTION) {
-		cmd->prot_sdb = kmem_cache_zalloc(scsi_sdb_cache, gfp);
-		if (!cmd->prot_sdb)
-			goto fail_free_sense;
-	}
-
-	return 0;
-
-fail_free_sense:
-	scsi_free_sense_buffer(unchecked_isa_dma, cmd->sense_buffer);
-fail:
-	return -ENOMEM;
-}
-
-static void scsi_old_exit_rq(struct request_queue *q, struct request *rq)
-{
-	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
-
-	if (cmd->prot_sdb)
-		kmem_cache_free(scsi_sdb_cache, cmd->prot_sdb);
-	scsi_free_sense_buffer(cmd->flags & SCMD_UNCHECKED_ISA_DMA,
-			       cmd->sense_buffer);
-}
-
-struct request_queue *scsi_old_alloc_queue(struct scsi_device *sdev)
-{
-	struct Scsi_Host *shost = sdev->host;
-	struct request_queue *q;
-
-	q = blk_alloc_queue_node(GFP_KERNEL, NUMA_NO_NODE, NULL);
-	if (!q)
-		return NULL;
-	q->cmd_size = sizeof(struct scsi_cmnd) + shost->hostt->cmd_size;
-	q->rq_alloc_data = shost;
-	q->request_fn = scsi_request_fn;
-	q->init_rq_fn = scsi_old_init_rq;
-	q->exit_rq_fn = scsi_old_exit_rq;
-	q->initialize_rq_fn = scsi_initialize_rq;
-
-	if (blk_init_allocated_queue(q) < 0) {
-		blk_cleanup_queue(q);
-		return NULL;
-	}
-
-	__scsi_init_queue(shost, q);
-	blk_queue_flag_set(QUEUE_FLAG_SCSI_PASSTHROUGH, q);
-	blk_queue_prep_rq(q, scsi_prep_fn);
-	blk_queue_unprep_rq(q, scsi_unprep_fn);
-	blk_queue_softirq_done(q, scsi_softirq_done);
-	blk_queue_rq_timed_out(q, scsi_times_out);
-	blk_queue_lld_busy(q, scsi_lld_busy);
-	return q;
-}
-
 static const struct blk_mq_ops scsi_mq_ops = {
 	.get_budget	= scsi_mq_get_budget,
 	.put_budget	= scsi_mq_put_budget,
@@ -2386,10 +1922,7 @@ struct scsi_device *scsi_device_from_queue(struct request_queue *q)
 {
 	struct scsi_device *sdev = NULL;
 
-	if (q->mq_ops) {
-		if (q->mq_ops == &scsi_mq_ops)
-			sdev = q->queuedata;
-	} else if (q->request_fn == scsi_request_fn)
+	if (q->mq_ops == &scsi_mq_ops)
 		sdev = q->queuedata;
 	if (!sdev || !get_device(&sdev->sdev_gendev))
 		sdev = NULL;
@@ -2992,39 +2525,6 @@ void sdev_evt_send_simple(struct scsi_device *sdev,
 }
 EXPORT_SYMBOL_GPL(sdev_evt_send_simple);
 
-/**
- * scsi_request_fn_active() - number of kernel threads inside scsi_request_fn()
- * @sdev: SCSI device to count the number of scsi_request_fn() callers for.
- */
-static int scsi_request_fn_active(struct scsi_device *sdev)
-{
-	struct request_queue *q = sdev->request_queue;
-	int request_fn_active;
-
-	WARN_ON_ONCE(sdev->host->use_blk_mq);
-
-	spin_lock_irq(q->queue_lock);
-	request_fn_active = q->request_fn_active;
-	spin_unlock_irq(q->queue_lock);
-
-	return request_fn_active;
-}
-
-/**
- * scsi_wait_for_queuecommand() - wait for ongoing queuecommand() calls
- * @sdev: SCSI device pointer.
- *
- * Wait until the ongoing shost->hostt->queuecommand() calls that are
- * invoked from scsi_request_fn() have finished.
- */
-static void scsi_wait_for_queuecommand(struct scsi_device *sdev)
-{
-	WARN_ON_ONCE(sdev->host->use_blk_mq);
-
-	while (scsi_request_fn_active(sdev))
-		msleep(20);
-}
-
 /**
  *	scsi_device_quiesce - Block user issued commands.
  *	@sdev:	scsi device to quiesce.
@@ -3148,7 +2648,6 @@ EXPORT_SYMBOL(scsi_target_resume);
 int scsi_internal_device_block_nowait(struct scsi_device *sdev)
 {
 	struct request_queue *q = sdev->request_queue;
-	unsigned long flags;
 	int err = 0;
 
 	err = scsi_device_set_state(sdev, SDEV_BLOCK);
@@ -3164,14 +2663,7 @@ int scsi_internal_device_block_nowait(struct scsi_device *sdev)
 	 * block layer from calling the midlayer with this device's
 	 * request queue. 
 	 */
-	if (q->mq_ops) {
-		blk_mq_quiesce_queue_nowait(q);
-	} else {
-		spin_lock_irqsave(q->queue_lock, flags);
-		blk_stop_queue(q);
-		spin_unlock_irqrestore(q->queue_lock, flags);
-	}
-
+	blk_mq_quiesce_queue_nowait(q);
 	return 0;
 }
 EXPORT_SYMBOL_GPL(scsi_internal_device_block_nowait);
@@ -3202,12 +2694,8 @@ static int scsi_internal_device_block(struct scsi_device *sdev)
 
 	mutex_lock(&sdev->state_mutex);
 	err = scsi_internal_device_block_nowait(sdev);
-	if (err == 0) {
-		if (q->mq_ops)
-			blk_mq_quiesce_queue(q);
-		else
-			scsi_wait_for_queuecommand(sdev);
-	}
+	if (err == 0)
+		blk_mq_quiesce_queue(q);
 	mutex_unlock(&sdev->state_mutex);
 
 	return err;
@@ -3216,15 +2704,8 @@ static int scsi_internal_device_block(struct scsi_device *sdev)
 void scsi_start_queue(struct scsi_device *sdev)
 {
 	struct request_queue *q = sdev->request_queue;
-	unsigned long flags;
 
-	if (q->mq_ops) {
-		blk_mq_unquiesce_queue(q);
-	} else {
-		spin_lock_irqsave(q->queue_lock, flags);
-		blk_start_queue(q);
-		spin_unlock_irqrestore(q->queue_lock, flags);
-	}
+	blk_mq_unquiesce_queue(q);
 }
 
 /**

commit 3a7ea2c483a53fc89e336f69c6ee1d7defe00811
Author: Jens Axboe <axboe@kernel.dk>
Date:   Mon Oct 29 10:17:28 2018 -0600

    scsi: provide mq_ops->busy() hook
    
    Only the SCSI legacy path provides a way to check if target is
    currently busy, provide the same for the MQ path.
    
    Cc: linux-scsi@vger.kernel.org
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Tested-by: Ming Lei <ming.lei@redhat.com>
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Acked-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c7fccbb8f554..8b0345924a92 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1675,6 +1675,11 @@ static int scsi_lld_busy(struct request_queue *q)
 	return 0;
 }
 
+static bool scsi_mq_lld_busy(struct request_queue *q)
+{
+	return scsi_lld_busy(q);
+}
+
 /*
  * Kill a request for a dead device
  */
@@ -2326,6 +2331,7 @@ static const struct blk_mq_ops scsi_mq_ops = {
 	.init_request	= scsi_mq_init_request,
 	.exit_request	= scsi_mq_exit_request,
 	.initialize_rq_fn = scsi_initialize_rq,
+	.busy		= scsi_mq_lld_busy,
 	.map_queues	= scsi_map_queues,
 };
 

commit d49f8a52b15bf35db778035340d8a673149f9f93
Merge: bd6bf7c10484 a0db8a7516d9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 25 07:40:30 2018 -0700

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This is mostly updates of the usual drivers: UFS, esp_scsi, NCR5380,
      qla2xxx, lpfc, libsas, hisi_sas.
    
      In addition there's a set of mostly small updates to the target
      subsystem a set of conversions to the generic DMA API, which do have
      some potential for issues in the older drivers but we'll handle those
      as case by case fixes.
    
      A new myrs driver for the DAC960/mylex raid controllers to replace the
      block based DAC960 which is also being removed by Jens in this merge
      window.
    
      Plus the usual slew of trivial changes"
    
    [ "myrs" stands for "MYlex Raid Scsi". Obviously. Silly of me to even
      wonder. There's also a "myrb" driver, where the 'b' stands for
      'block'. Truly, somebody has got mad naming skillz. - Linus ]
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (237 commits)
      scsi: myrs: Fix the processor absent message in processor_show()
      scsi: myrs: Fix a logical vs bitwise bug
      scsi: hisi_sas: Fix NULL pointer dereference
      scsi: myrs: fix build failure on 32 bit
      scsi: fnic: replace gross legacy tag hack with blk-mq hack
      scsi: mesh: switch to generic DMA API
      scsi: ips: switch to generic DMA API
      scsi: smartpqi: fully convert to the generic DMA API
      scsi: vmw_pscsi: switch to generic DMA API
      scsi: snic: switch to generic DMA API
      scsi: qla4xxx: fully convert to the generic DMA API
      scsi: qla2xxx: fully convert to the generic DMA API
      scsi: qla1280: switch to generic DMA API
      scsi: qedi: fully convert to the generic DMA API
      scsi: qedf: fully convert to the generic DMA API
      scsi: pm8001: switch to generic DMA API
      scsi: nsp32: switch to generic DMA API
      scsi: mvsas: fully convert to the generic DMA API
      scsi: mvumi: switch to generic DMA API
      scsi: mpt3sas: switch to generic DMA API
      ...

commit a33e5bfb29721015349a3864c91abe11f6195d5c
Author: Hannes Reinecke <hare@suse.com>
Date:   Sun Oct 7 10:35:35 2018 +0200

    scsi: core: Allow state transitions from OFFLINE to BLOCKED
    
    When an RSCN gets delayed (or not being sent at all), the transport class
    will detect an error, EH kicks in, and eventually will be setting the
    device to offline.  If we receive an RSCN after that, the device will
    stay in 'offline'.  This patch allows for an 'offline' to 'blocked'
    transition, thereby allowing the device to become active again.
    
    Signed-off-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index aaa1819b0a69..7db3c5fae469 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2764,6 +2764,7 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 		switch (oldstate) {
 		case SDEV_RUNNING:
 		case SDEV_CREATED_BLOCK:
+		case SDEV_OFFLINE:
 			break;
 		default:
 			goto illegal;

commit cd84a62e0078dce09f4ed349bec84f86c9d54b30
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Wed Sep 26 14:01:04 2018 -0700

    block, scsi: Change the preempt-only flag into a counter
    
    The RQF_PREEMPT flag is used for three purposes:
    - In the SCSI core, for making sure that power management requests
      are executed even if a device is in the "quiesced" state.
    - For domain validation by SCSI drivers that use the parallel port.
    - In the IDE driver, for IDE preempt requests.
    Rename "preempt-only" into "pm-only" because the primary purpose of
    this mode is power management. Since the power management core may
    but does not have to resume a runtime suspended device before
    performing system-wide suspend and since a later patch will set
    "pm-only" mode as long as a block device is runtime suspended, make
    it possible to set "pm-only" mode from more than one context. Since
    with this change scsi_device_quiesce() is no longer idempotent, make
    that function return early if it is called for a quiesced queue.
    
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Acked-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Ming Lei <ming.lei@redhat.com>
    Cc: Jianchao Wang <jianchao.w.wang@oracle.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Cc: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index eb97d2dd3651..62348412ed1b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -3046,11 +3046,14 @@ scsi_device_quiesce(struct scsi_device *sdev)
 	 */
 	WARN_ON_ONCE(sdev->quiesced_by && sdev->quiesced_by != current);
 
-	blk_set_preempt_only(q);
+	if (sdev->quiesced_by == current)
+		return 0;
+
+	blk_set_pm_only(q);
 
 	blk_mq_freeze_queue(q);
 	/*
-	 * Ensure that the effect of blk_set_preempt_only() will be visible
+	 * Ensure that the effect of blk_set_pm_only() will be visible
 	 * for percpu_ref_tryget() callers that occur after the queue
 	 * unfreeze even if the queue was already frozen before this function
 	 * was called. See also https://lwn.net/Articles/573497/.
@@ -3063,7 +3066,7 @@ scsi_device_quiesce(struct scsi_device *sdev)
 	if (err == 0)
 		sdev->quiesced_by = current;
 	else
-		blk_clear_preempt_only(q);
+		blk_clear_pm_only(q);
 	mutex_unlock(&sdev->state_mutex);
 
 	return err;
@@ -3088,7 +3091,7 @@ void scsi_device_resume(struct scsi_device *sdev)
 	mutex_lock(&sdev->state_mutex);
 	WARN_ON_ONCE(!sdev->quiesced_by);
 	sdev->quiesced_by = NULL;
-	blk_clear_preempt_only(sdev->request_queue);
+	blk_clear_pm_only(sdev->request_queue);
 	if (sdev->sdev_state == SDEV_QUIESCE)
 		scsi_device_set_state(sdev, SDEV_RUNNING);
 	mutex_unlock(&sdev->state_mutex);

commit 6f1d8a5327c52570720de9c251bbbe0301903882
Author: Igor Stoppa <igor.stoppa@gmail.com>
Date:   Wed Sep 5 23:47:20 2018 +0300

    scsi: core: remove unnecessary unlikely()
    
    BUG_ON() already contains an unlikely(), there is no need for another one.
    
    Signed-off-by: Igor Stoppa <igor.stoppa@huawei.com>
    Cc: "Martin K. Petersen" <martin.petersen@oracle.com>
    Cc: "James E.J. Bottomley" <jejb@linux.vnet.ibm.com>
    Cc: linux-scsi@vger.kernel.org
    CC: linux-kernel@vger.kernel.org
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0adfb3bce0fd..aaa1819b0a69 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1207,8 +1207,8 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 
 		count = blk_rq_map_integrity_sg(rq->q, rq->bio,
 						prot_sdb->table.sgl);
-		BUG_ON(unlikely(count > ivecs));
-		BUG_ON(unlikely(count > queue_max_integrity_segments(rq->q)));
+		BUG_ON(count > ivecs);
+		BUG_ON(count > queue_max_integrity_segments(rq->q));
 
 		cmd->prot_sdb = prot_sdb;
 		cmd->prot_sdb->table.nents = count;

commit d772a65d8a6c45c376a8200a38f7f82fb480af6a
Author: Ming Lei <ming.lei@redhat.com>
Date:   Mon Aug 27 15:24:43 2018 +0800

    Revert "scsi: core: avoid host-wide host_busy counter for scsi_mq"
    
    This reverts commit 328728630d9f2bf14b82ca30b5e47489beefe361.
    
    There is fundamental issue in commit 328728630d9f2bf1 (scsi: core: avoid
    host-wide host_busy counter for scsi_mq) because SCSI's host busy counter
    may not be same with counter of blk-mq's inflight tags, especially in case
    of none io scheduler.
    
    We may switch to other approach for addressing this scsi_mq's performance
    issue, such as percpu counter or kind of ways, so revert this commit first
    for fixing this kind of issue in EH path, as reported by Jens.
    
    Cc: Omar Sandoval <osandov@fb.com>,
    Cc: "Martin K. Petersen" <martin.petersen@oracle.com>,
    Cc: James Bottomley <james.bottomley@hansenpartnership.com>,
    Cc: Christoph Hellwig <hch@lst.de>,
    Cc: Don Brace <don.brace@microsemi.com>
    Cc: Kashyap Desai <kashyap.desai@broadcom.com>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: Hannes Reinecke <hare@suse.de>
    Cc: Laurence Oberman <loberman@redhat.com>
    Cc: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Reported-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1046679f5473..eb97d2dd3651 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -345,8 +345,7 @@ static void scsi_dec_host_busy(struct Scsi_Host *shost)
 	unsigned long flags;
 
 	rcu_read_lock();
-	if (!shost->use_blk_mq)
-		atomic_dec(&shost->host_busy);
+	atomic_dec(&shost->host_busy);
 	if (unlikely(scsi_host_in_recovery(shost))) {
 		spin_lock_irqsave(shost->host_lock, flags);
 		if (shost->host_failed || shost->host_eh_scheduled)
@@ -445,12 +444,7 @@ static inline bool scsi_target_is_busy(struct scsi_target *starget)
 
 static inline bool scsi_host_is_busy(struct Scsi_Host *shost)
 {
-	/*
-	 * blk-mq can handle host queue busy efficiently via host-wide driver
-	 * tag allocation
-	 */
-
-	if (!shost->use_blk_mq && shost->can_queue > 0 &&
+	if (shost->can_queue > 0 &&
 	    atomic_read(&shost->host_busy) >= shost->can_queue)
 		return true;
 	if (atomic_read(&shost->host_blocked) > 0)
@@ -1606,12 +1600,9 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 	if (scsi_host_in_recovery(shost))
 		return 0;
 
-	if (!shost->use_blk_mq)
-		busy = atomic_inc_return(&shost->host_busy) - 1;
-	else
-		busy = 0;
+	busy = atomic_inc_return(&shost->host_busy) - 1;
 	if (atomic_read(&shost->host_blocked) > 0) {
-		if (busy || scsi_host_busy(shost))
+		if (busy)
 			goto starved;
 
 		/*
@@ -1625,7 +1616,7 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 				     "unblocking host at zero depth\n"));
 	}
 
-	if (!shost->use_blk_mq && shost->can_queue > 0 && busy >= shost->can_queue)
+	if (shost->can_queue > 0 && busy >= shost->can_queue)
 		goto starved;
 	if (shost->host_self_blocked)
 		goto starved;
@@ -1711,9 +1702,7 @@ static void scsi_kill_request(struct request *req, struct request_queue *q)
 	 * with the locks as normal issue path does.
 	 */
 	atomic_inc(&sdev->device_busy);
-
-	if (!shost->use_blk_mq)
-		atomic_inc(&shost->host_busy);
+	atomic_inc(&shost->host_busy);
 	if (starget->can_queue > 0)
 		atomic_inc(&starget->target_busy);
 

commit 23aa8e69f2c6ceb0bdca52f4450ad1f45675ca73
Author: Ming Lei <ming.lei@redhat.com>
Date:   Mon Aug 27 15:24:42 2018 +0800

    Revert "scsi: core: fix scsi_host_queue_ready"
    
    This reverts commit 265d59aacbce7e50bdc1f5d25033c38dd70b3767.
    
    There is fundamental issue in commit 328728630d9f2bf1 (scsi: core: avoid
    host-wide host_busy counter for scsi_mq) because SCSI's host busy counter
    may not be same with counter of blk-mq's inflight tags, especially in case
    of none io scheduler.
    
    So revert this commit first.
    
    Cc: Omar Sandoval <osandov@fb.com>,
    Cc: "Martin K. Petersen" <martin.petersen@oracle.com>,
    Cc: James Bottomley <james.bottomley@hansenpartnership.com>,
    Cc: Christoph Hellwig <hch@lst.de>,
    Cc: Don Brace <don.brace@microsemi.com>
    Cc: Kashyap Desai <kashyap.desai@broadcom.com>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: Hannes Reinecke <hare@suse.de>
    Cc: Laurence Oberman <loberman@redhat.com>
    Cc: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: Guenter Roeck <linux@roeck-us.net>
    Cc: Jens Axboe <axboe@kernel.dk>
    Reported-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0adfb3bce0fd..1046679f5473 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1611,7 +1611,7 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 	else
 		busy = 0;
 	if (atomic_read(&shost->host_blocked) > 0) {
-		if (busy)
+		if (busy || scsi_host_busy(shost))
 			goto starved;
 
 		/*

commit 72f02ba66bd83b54054da20eae550123de84da6f
Merge: db06f826ec12 51372570ac3c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Aug 15 22:06:26 2018 -0700

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This is mostly updates to the usual drivers: mpt3sas, lpfc, qla2xxx,
      hisi_sas, smartpqi, megaraid_sas, arcmsr.
    
      In addition, with the continuing absence of Nic we have target updates
      for tcmu and target core (all with reviews and acks).
    
      The biggest observable change is going to be that we're (again) trying
      to switch to mulitqueue as the default (a user can still override the
      setting on the kernel command line).
    
      Other major core stuff is the removal of the remaining Microchannel
      drivers, an update of the internal timers and some reworks of
      completion and result handling"
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (203 commits)
      scsi: core: use blk_mq_run_hw_queues in scsi_kick_queue
      scsi: ufs: remove unnecessary query(DM) UPIU trace
      scsi: qla2xxx: Fix issue reported by static checker for qla2x00_els_dcmd2_sp_done()
      scsi: aacraid: Spelling fix in comment
      scsi: mpt3sas: Fix calltrace observed while running IO & reset
      scsi: aic94xx: fix an error code in aic94xx_init()
      scsi: st: remove redundant pointer STbuffer
      scsi: qla2xxx: Update driver version to 10.00.00.08-k
      scsi: qla2xxx: Migrate NVME N2N handling into state machine
      scsi: qla2xxx: Save frame payload size from ICB
      scsi: qla2xxx: Fix stalled relogin
      scsi: qla2xxx: Fix race between switch cmd completion and timeout
      scsi: qla2xxx: Fix Management Server NPort handle reservation logic
      scsi: qla2xxx: Flush mailbox commands on chip reset
      scsi: qla2xxx: Fix unintended Logout
      scsi: qla2xxx: Fix session state stuck in Get Port DB
      scsi: qla2xxx: Fix redundant fc_rport registration
      scsi: qla2xxx: Silent erroneous message
      scsi: qla2xxx: Prevent sysfs access when chip is down
      scsi: qla2xxx: Add longer window for chip reset
      ...

commit 51372570ac3c919b036e760f4ca449e81cf8e995
Author: Jianchao Wang <jianchao.w.wang@oracle.com>
Date:   Wed Aug 8 14:24:59 2018 +0800

    scsi: core: use blk_mq_run_hw_queues in scsi_kick_queue
    
    We don't use blk-mq start/stop hw queue any more, so no reason to use
    blk_mq_start_hw_queues which does clear_bit, replace it with
    blk_mq_run_hw_queues.
    
    Signed-off-by: Jianchao Wang <jianchao.w.wang@oracle.com>
    Reviewed-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 93cf2ec2d13b..57201d8bdce4 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -372,7 +372,7 @@ void scsi_device_unbusy(struct scsi_device *sdev)
 static void scsi_kick_queue(struct request_queue *q)
 {
 	if (q->mq_ops)
-		blk_mq_start_hw_queues(q);
+		blk_mq_run_hw_queues(q, false);
 	else
 		blk_run_queue(q);
 }

commit 704f83928c8e7da6e06144569efb15dec73278e8
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Jul 31 12:51:54 2018 -0700

    scsi: Check sense buffer size at build time
    
    To avoid introducing problems like those fixed in commit f7068114d45e
    ("sr: pass down correctly sized SCSI sense buffer"), this creates a macro
    wrapper for scsi_execute() that verifies the size of the sense buffer
    similar to what was done for command string sizes in commit 3756f6401c30
    ("exec: avoid gcc-8 warning for get_task_comm").
    
    Another solution could be to add a length argument to scsi_execute(),
    but this function already takes a lot of arguments and Jens was not fond
    of that approach.
    
    Additionally, this moves the SCSI_SENSE_BUFFERSIZE definition into
    scsi_device.h, and removes a redundant include for scsi_device.h from
    scsi_cmnd.h.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 41e9ac9fc138..9cb9a166fa0c 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -238,7 +238,7 @@ void scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 
 
 /**
- * scsi_execute - insert request and wait for the result
+ * __scsi_execute - insert request and wait for the result
  * @sdev:	scsi device
  * @cmd:	scsi command
  * @data_direction: data direction
@@ -255,7 +255,7 @@ void scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
  * Returns the scsi_cmnd result field if a command was executed, or a negative
  * Linux error code if we didn't get that far.
  */
-int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
+int __scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 		 int data_direction, void *buffer, unsigned bufflen,
 		 unsigned char *sense, struct scsi_sense_hdr *sshdr,
 		 int timeout, int retries, u64 flags, req_flags_t rq_flags,
@@ -309,7 +309,7 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 
 	return ret;
 }
-EXPORT_SYMBOL(scsi_execute);
+EXPORT_SYMBOL(__scsi_execute);
 
 /*
  * Function:    scsi_init_cmd_errh()

commit 265d59aacbce7e50bdc1f5d25033c38dd70b3767
Author: Ming Lei <ming.lei@redhat.com>
Date:   Sat Jun 30 09:27:24 2018 +0800

    scsi: core: fix scsi_host_queue_ready
    
    328728630d9f ("scsi: avoid to hold host-wide counter of host_busy for
    scsi_mq") adds one extra check on scsi_host_busy(shost) in
    scsi_host_queue_ready(), which is wrong and not necessary, can causes
    booting stall on LSI53c895A.
    
    So remove the check.
    
    Cc: Omar Sandoval <osandov@fb.com>,
    Cc: "Martin K. Petersen" <martin.petersen@oracle.com>,
    Cc: James Bottomley <james.bottomley@hansenpartnership.com>,
    Cc: Christoph Hellwig <hch@lst.de>,
    Cc: Don Brace <don.brace@microsemi.com>
    Cc: Kashyap Desai <kashyap.desai@broadcom.com>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: Hannes Reinecke <hare@suse.de>
    Cc: Laurence Oberman <loberman@redhat.com>
    Cc: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: Guenter Roeck <linux@roeck-us.net>
    Reported-by: Guenter Roeck <linux@roeck-us.net>
    Fixes: 328728630d9f ("scsi: avoid to hold host-wide counter of host_busy for scsi_mq")
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Tested-by: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 600c78065d62..93cf2ec2d13b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1611,7 +1611,7 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 	else
 		busy = 0;
 	if (atomic_read(&shost->host_blocked) > 0) {
-		if (busy || scsi_host_busy(shost))
+		if (busy)
 			goto starved;
 
 		/*

commit 328728630d9f2bf14b82ca30b5e47489beefe361
Author: Ming Lei <ming.lei@redhat.com>
Date:   Sun Jun 24 22:03:27 2018 +0800

    scsi: core: avoid host-wide host_busy counter for scsi_mq
    
    It isn't necessary to check the host depth in scsi_queue_rq() any more
    since it has been respected by blk-mq before calling scsi_queue_rq() via
    getting driver tag.
    
    Lots of LUNs may attach to same host and per-host IOPS may reach millions,
    so we should avoid expensive atomic operations on the host-wide counter in
    the IO path.
    
    This patch implements scsi_host_busy() via blk_mq_tagset_busy_iter() for
    reading the count of busy IOs for scsi_mq.
    
    It is observed that IOPS is increased by 15% in IO test on scsi_debug (32
    LUNs, 32 submit queues, 1024 can_queue, libaio/dio) in a dual-socket
    system.
    
    [mkp: clarified commit message]
    
    Cc: Omar Sandoval <osandov@fb.com>,
    Cc: "Martin K. Petersen" <martin.petersen@oracle.com>,
    Cc: James Bottomley <james.bottomley@hansenpartnership.com>,
    Cc: Christoph Hellwig <hch@lst.de>,
    Cc: Don Brace <don.brace@microsemi.com>
    Cc: Kashyap Desai <kashyap.desai@broadcom.com>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: Hannes Reinecke <hare@suse.de>
    Cc: Laurence Oberman <loberman@redhat.com>
    Cc: Bart Van Assche <bart.vanassche@wdc.com>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Reviewed-by: Bart Van Assche <bart.vanassche@wdc.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a1a0a2903263..600c78065d62 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -345,7 +345,8 @@ static void scsi_dec_host_busy(struct Scsi_Host *shost)
 	unsigned long flags;
 
 	rcu_read_lock();
-	atomic_dec(&shost->host_busy);
+	if (!shost->use_blk_mq)
+		atomic_dec(&shost->host_busy);
 	if (unlikely(scsi_host_in_recovery(shost))) {
 		spin_lock_irqsave(shost->host_lock, flags);
 		if (shost->host_failed || shost->host_eh_scheduled)
@@ -444,7 +445,12 @@ static inline bool scsi_target_is_busy(struct scsi_target *starget)
 
 static inline bool scsi_host_is_busy(struct Scsi_Host *shost)
 {
-	if (shost->can_queue > 0 &&
+	/*
+	 * blk-mq can handle host queue busy efficiently via host-wide driver
+	 * tag allocation
+	 */
+
+	if (!shost->use_blk_mq && shost->can_queue > 0 &&
 	    atomic_read(&shost->host_busy) >= shost->can_queue)
 		return true;
 	if (atomic_read(&shost->host_blocked) > 0)
@@ -1600,9 +1606,12 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 	if (scsi_host_in_recovery(shost))
 		return 0;
 
-	busy = atomic_inc_return(&shost->host_busy) - 1;
+	if (!shost->use_blk_mq)
+		busy = atomic_inc_return(&shost->host_busy) - 1;
+	else
+		busy = 0;
 	if (atomic_read(&shost->host_blocked) > 0) {
-		if (busy)
+		if (busy || scsi_host_busy(shost))
 			goto starved;
 
 		/*
@@ -1616,7 +1625,7 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 				     "unblocking host at zero depth\n"));
 	}
 
-	if (shost->can_queue > 0 && busy >= shost->can_queue)
+	if (!shost->use_blk_mq && shost->can_queue > 0 && busy >= shost->can_queue)
 		goto starved;
 	if (shost->host_self_blocked)
 		goto starved;
@@ -1702,7 +1711,9 @@ static void scsi_kill_request(struct request *req, struct request_queue *q)
 	 * with the locks as normal issue path does.
 	 */
 	atomic_inc(&sdev->device_busy);
-	atomic_inc(&shost->host_busy);
+
+	if (!shost->use_blk_mq)
+		atomic_inc(&shost->host_busy);
 	if (starget->can_queue > 0)
 		atomic_inc(&starget->target_busy);
 

commit c65be1a63f1df224c8f22d72b9ec824241ada585
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Mon Jun 25 13:20:58 2018 +0200

    scsi: core: check for equality of result byte values
    
    When evaluating a SCSI command's result using the field access macros,
    check for equality of the fields and not if a specific bit is set.
    
    This is a preparation patch, for reworking the results field in the
    SCSI command.
    
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Bart Van Assche <bart.vanassche@wdc.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 252edd61a688..a1a0a2903263 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -911,7 +911,7 @@ static void scsi_io_completion_action(struct scsi_cmnd *cmd, int result)
 			 */
 			if (!level && __ratelimit(&_rs)) {
 				scsi_print_result(cmd, NULL, FAILED);
-				if (driver_byte(result) & DRIVER_SENSE)
+				if (driver_byte(result) == DRIVER_SENSE)
 					scsi_print_sense(cmd);
 				scsi_print_command(cmd);
 			}
@@ -2605,7 +2605,7 @@ scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
 	 * ILLEGAL REQUEST if the code page isn't supported */
 
 	if (use_10_for_ms && !scsi_status_is_good(result) &&
-	    (driver_byte(result) & DRIVER_SENSE)) {
+	    driver_byte(result) == DRIVER_SENSE) {
 		if (scsi_sense_valid(sshdr)) {
 			if ((sshdr->sense_key == ILLEGAL_REQUEST) &&
 			    (sshdr->asc == 0x20) && (sshdr->ascq == 0)) {

commit 8e1695a07c7b28e2eb1c02cc01e2b8f5dd28bf87
Author: Douglas Gilbert <dgilbert@interlog.com>
Date:   Sat Jun 23 12:22:20 2018 +0200

    scsi: core: scsi_io_completion convert BUGs to WARNs
    
    The scsi_io_completion function contains three BUG() and BUG_ON() calls.
    Replace them with WARN variants.
    
    Signed-off-by: Douglas Gilbert <dgilbert@interlog.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Bart Van Assche <bart.vanassche@wdc.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 19ed11abe886..252edd61a688 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1060,13 +1060,21 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			scsi_req(req->next_rq)->resid_len = scsi_in(cmd)->resid;
 			if (scsi_end_request(req, BLK_STS_OK, blk_rq_bytes(req),
 					blk_rq_bytes(req->next_rq)))
-				BUG();
+				WARN_ONCE(true,
+					  "Bidi command with remaining bytes");
 			return;
 		}
 	}
 
 	/* no bidi support yet, other than in pass-through */
-	BUG_ON(blk_bidi_rq(req));
+	if (unlikely(blk_bidi_rq(req))) {
+		WARN_ONCE(true, "Only support bidi command in passthrough");
+		scmd_printk(KERN_ERR, cmd, "Killing bidi command\n");
+		if (scsi_end_request(req, BLK_STS_IOERR, blk_rq_bytes(req),
+				     blk_rq_bytes(req->next_rq)))
+			WARN_ONCE(true, "Bidi command with remaining bytes");
+		return;
+	}
 
 	/*
 	 * Next deal with any sectors which we were able to correctly
@@ -1089,7 +1097,8 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	/* Kill remainder if no retries. */
 	if (unlikely(blk_stat && scsi_noretry_cmd(cmd))) {
 		if (scsi_end_request(req, blk_stat, blk_rq_bytes(req), 0))
-			BUG();
+			WARN_ONCE(true,
+			    "Bytes remaining after failed, no-retry command");
 		return;
 	}
 

commit 0d437906f6dca6167b37c8e1f6f6ec395bde6230
Author: Douglas Gilbert <dgilbert@interlog.com>
Date:   Sat Jun 23 12:22:19 2018 +0200

    scsi: core: scsi_io_completion hints on fastpath
    
    Add likely() and unlikely() hints to conditionals on or near the fastpath.
    
    Signed-off-by: Douglas Gilbert <dgilbert@interlog.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Bart Van Assche <bart.vanassche@wdc.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 63dcb2a94e5d..19ed11abe886 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1042,17 +1042,17 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	struct request *req = cmd->request;
 	blk_status_t blk_stat = BLK_STS_OK;
 
-	if (result)	/* does not necessarily mean there is an error */
+	if (unlikely(result))	/* a nz result may or may not be an error */
 		result = scsi_io_completion_nz_result(cmd, result, &blk_stat);
 
-	if (blk_rq_is_passthrough(req)) {
+	if (unlikely(blk_rq_is_passthrough(req))) {
 		/*
 		 * scsi_result_to_blk_status may have reset the host_byte
 		 */
 		scsi_req(req)->result = cmd->result;
 		scsi_req(req)->resid_len = scsi_get_resid(cmd);
 
-		if (scsi_bidi_cmnd(cmd)) {
+		if (unlikely(scsi_bidi_cmnd(cmd))) {
 			/*
 			 * Bidi commands Must be complete as a whole,
 			 * both sides at once.
@@ -1065,7 +1065,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		}
 	}
 
-	/* no bidi support for !blk_rq_is_passthrough yet */
+	/* no bidi support yet, other than in pass-through */
 	BUG_ON(blk_bidi_rq(req));
 
 	/*
@@ -1081,13 +1081,13 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	 * handle. Failed, zero length commands always need to drop down
 	 * to retry code. Fast path should return in this block.
 	 */
-	if (blk_rq_bytes(req) > 0 || blk_stat == BLK_STS_OK) {
-		if (!scsi_end_request(req, blk_stat, good_bytes, 0))
+	if (likely(blk_rq_bytes(req) > 0 || blk_stat == BLK_STS_OK)) {
+		if (likely(!scsi_end_request(req, blk_stat, good_bytes, 0)))
 			return; /* no bytes remaining */
 	}
 
-	 /* Kill remainder if no retries. */
-	if (blk_stat && scsi_noretry_cmd(cmd)) {
+	/* Kill remainder if no retries. */
+	if (unlikely(blk_stat && scsi_noretry_cmd(cmd))) {
 		if (scsi_end_request(req, blk_stat, blk_rq_bytes(req), 0))
 			BUG();
 		return;
@@ -1097,7 +1097,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	 * If there had been no error, but we have leftover bytes in the
 	 * requeues just queue the command up again.
 	 */
-	if (result == 0)
+	if (likely(result == 0))
 		scsi_io_completion_reprep(cmd, q);
 	else
 		scsi_io_completion_action(cmd, result);

commit 4ae61c68f7d72d98e7e41a8d4ec21bbaa46b63d4
Author: Douglas Gilbert <dgilbert@interlog.com>
Date:   Sat Jun 23 12:22:18 2018 +0200

    scsi: core: add scsi_io_completion_reprep helper
    
    Since the action "reprep" is called from two places, rather than repeat the
    code, make a new scsi_io_completion helper with "reprep" as its suffix.
    
    Signed-off-by: Douglas Gilbert <dgilbert@interlog.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Bart Van Assche <bart.vanassche@wdc.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 16a7e6846cac..63dcb2a94e5d 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -761,6 +761,20 @@ static blk_status_t scsi_result_to_blk_status(struct scsi_cmnd *cmd, int result)
 	}
 }
 
+/* Helper for scsi_io_completion() when "reprep" action required. */
+static void scsi_io_completion_reprep(struct scsi_cmnd *cmd,
+				      struct request_queue *q)
+{
+	/* A new command will be prepared and issued. */
+	if (q->mq_ops) {
+		scsi_mq_requeue_cmd(cmd);
+	} else {
+		/* Unprep request and put it back at head of the queue. */
+		scsi_release_buffers(cmd);
+		scsi_requeue_command(q, cmd);
+	}
+}
+
 /* Helper for scsi_io_completion() when special action required. */
 static void scsi_io_completion_action(struct scsi_cmnd *cmd, int result)
 {
@@ -906,15 +920,7 @@ static void scsi_io_completion_action(struct scsi_cmnd *cmd, int result)
 			return;
 		/*FALLTHRU*/
 	case ACTION_REPREP:
-		/* Unprep the request and put it back at the head of the queue.
-		 * A new command will be prepared and issued.
-		 */
-		if (q->mq_ops) {
-			scsi_mq_requeue_cmd(cmd);
-		} else {
-			scsi_release_buffers(cmd);
-			scsi_requeue_command(q, cmd);
-		}
+		scsi_io_completion_reprep(cmd, q);
 		break;
 	case ACTION_RETRY:
 		/* Retry the same command immediately */
@@ -1091,20 +1097,9 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	 * If there had been no error, but we have leftover bytes in the
 	 * requeues just queue the command up again.
 	 */
-	if (result == 0) {
-		/*
-		 * Unprep the request and put it back at the head of the
-		 * queue. A new command will be prepared and issued.
-		 * This block is the same as case ACTION_REPREP in
-		 * scsi_io_completion_action() above.
-		 */
-		if (q->mq_ops) {
-			scsi_mq_requeue_cmd(cmd);
-		} else {
-			scsi_release_buffers(cmd);
-			scsi_requeue_command(q, cmd);
-		}
-	} else
+	if (result == 0)
+		scsi_io_completion_reprep(cmd, q);
+	else
 		scsi_io_completion_action(cmd, result);
 }
 

commit da32baea17e36b2bd95cf38b07d1297daf1d98cf
Author: Douglas Gilbert <dgilbert@interlog.com>
Date:   Sat Jun 23 12:22:17 2018 +0200

    scsi: core: add scsi_io_completion_action helper
    
    Place scsi_io_completion()'s complex error processing associated with a
    local enumeration into a static helper function. That enumeration's values
    start with "ACTION_" so use the suffix "_action" in the helper function's
    name.
    
    Signed-off-by: Douglas Gilbert <dgilbert@interlog.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Bart Van Assche <bart.vanassche@wdc.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 02892408962b..16a7e6846cac 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -761,6 +761,172 @@ static blk_status_t scsi_result_to_blk_status(struct scsi_cmnd *cmd, int result)
 	}
 }
 
+/* Helper for scsi_io_completion() when special action required. */
+static void scsi_io_completion_action(struct scsi_cmnd *cmd, int result)
+{
+	struct request_queue *q = cmd->device->request_queue;
+	struct request *req = cmd->request;
+	int level = 0;
+	enum {ACTION_FAIL, ACTION_REPREP, ACTION_RETRY,
+	      ACTION_DELAYED_RETRY} action;
+	unsigned long wait_for = (cmd->allowed + 1) * req->timeout;
+	struct scsi_sense_hdr sshdr;
+	bool sense_valid;
+	bool sense_current = true;      /* false implies "deferred sense" */
+	blk_status_t blk_stat;
+
+	sense_valid = scsi_command_normalize_sense(cmd, &sshdr);
+	if (sense_valid)
+		sense_current = !scsi_sense_is_deferred(&sshdr);
+
+	blk_stat = scsi_result_to_blk_status(cmd, result);
+
+	if (host_byte(result) == DID_RESET) {
+		/* Third party bus reset or reset for error recovery
+		 * reasons.  Just retry the command and see what
+		 * happens.
+		 */
+		action = ACTION_RETRY;
+	} else if (sense_valid && sense_current) {
+		switch (sshdr.sense_key) {
+		case UNIT_ATTENTION:
+			if (cmd->device->removable) {
+				/* Detected disc change.  Set a bit
+				 * and quietly refuse further access.
+				 */
+				cmd->device->changed = 1;
+				action = ACTION_FAIL;
+			} else {
+				/* Must have been a power glitch, or a
+				 * bus reset.  Could not have been a
+				 * media change, so we just retry the
+				 * command and see what happens.
+				 */
+				action = ACTION_RETRY;
+			}
+			break;
+		case ILLEGAL_REQUEST:
+			/* If we had an ILLEGAL REQUEST returned, then
+			 * we may have performed an unsupported
+			 * command.  The only thing this should be
+			 * would be a ten byte read where only a six
+			 * byte read was supported.  Also, on a system
+			 * where READ CAPACITY failed, we may have
+			 * read past the end of the disk.
+			 */
+			if ((cmd->device->use_10_for_rw &&
+			    sshdr.asc == 0x20 && sshdr.ascq == 0x00) &&
+			    (cmd->cmnd[0] == READ_10 ||
+			     cmd->cmnd[0] == WRITE_10)) {
+				/* This will issue a new 6-byte command. */
+				cmd->device->use_10_for_rw = 0;
+				action = ACTION_REPREP;
+			} else if (sshdr.asc == 0x10) /* DIX */ {
+				action = ACTION_FAIL;
+				blk_stat = BLK_STS_PROTECTION;
+			/* INVALID COMMAND OPCODE or INVALID FIELD IN CDB */
+			} else if (sshdr.asc == 0x20 || sshdr.asc == 0x24) {
+				action = ACTION_FAIL;
+				blk_stat = BLK_STS_TARGET;
+			} else
+				action = ACTION_FAIL;
+			break;
+		case ABORTED_COMMAND:
+			action = ACTION_FAIL;
+			if (sshdr.asc == 0x10) /* DIF */
+				blk_stat = BLK_STS_PROTECTION;
+			break;
+		case NOT_READY:
+			/* If the device is in the process of becoming
+			 * ready, or has a temporary blockage, retry.
+			 */
+			if (sshdr.asc == 0x04) {
+				switch (sshdr.ascq) {
+				case 0x01: /* becoming ready */
+				case 0x04: /* format in progress */
+				case 0x05: /* rebuild in progress */
+				case 0x06: /* recalculation in progress */
+				case 0x07: /* operation in progress */
+				case 0x08: /* Long write in progress */
+				case 0x09: /* self test in progress */
+				case 0x14: /* space allocation in progress */
+				case 0x1a: /* start stop unit in progress */
+				case 0x1b: /* sanitize in progress */
+				case 0x1d: /* configuration in progress */
+				case 0x24: /* depopulation in progress */
+					action = ACTION_DELAYED_RETRY;
+					break;
+				default:
+					action = ACTION_FAIL;
+					break;
+				}
+			} else
+				action = ACTION_FAIL;
+			break;
+		case VOLUME_OVERFLOW:
+			/* See SSC3rXX or current. */
+			action = ACTION_FAIL;
+			break;
+		default:
+			action = ACTION_FAIL;
+			break;
+		}
+	} else
+		action = ACTION_FAIL;
+
+	if (action != ACTION_FAIL &&
+	    time_before(cmd->jiffies_at_alloc + wait_for, jiffies))
+		action = ACTION_FAIL;
+
+	switch (action) {
+	case ACTION_FAIL:
+		/* Give up and fail the remainder of the request */
+		if (!(req->rq_flags & RQF_QUIET)) {
+			static DEFINE_RATELIMIT_STATE(_rs,
+					DEFAULT_RATELIMIT_INTERVAL,
+					DEFAULT_RATELIMIT_BURST);
+
+			if (unlikely(scsi_logging_level))
+				level =
+				     SCSI_LOG_LEVEL(SCSI_LOG_MLCOMPLETE_SHIFT,
+						    SCSI_LOG_MLCOMPLETE_BITS);
+
+			/*
+			 * if logging is enabled the failure will be printed
+			 * in scsi_log_completion(), so avoid duplicate messages
+			 */
+			if (!level && __ratelimit(&_rs)) {
+				scsi_print_result(cmd, NULL, FAILED);
+				if (driver_byte(result) & DRIVER_SENSE)
+					scsi_print_sense(cmd);
+				scsi_print_command(cmd);
+			}
+		}
+		if (!scsi_end_request(req, blk_stat, blk_rq_err_bytes(req), 0))
+			return;
+		/*FALLTHRU*/
+	case ACTION_REPREP:
+		/* Unprep the request and put it back at the head of the queue.
+		 * A new command will be prepared and issued.
+		 */
+		if (q->mq_ops) {
+			scsi_mq_requeue_cmd(cmd);
+		} else {
+			scsi_release_buffers(cmd);
+			scsi_requeue_command(q, cmd);
+		}
+		break;
+	case ACTION_RETRY:
+		/* Retry the same command immediately */
+		__scsi_queue_insert(cmd, SCSI_MLQUEUE_EH_RETRY, false);
+		break;
+	case ACTION_DELAYED_RETRY:
+		/* Retry the same command after a delay */
+		__scsi_queue_insert(cmd, SCSI_MLQUEUE_DEVICE_BUSY, false);
+		break;
+	}
+}
+
 /*
  * Helper for scsi_io_completion() when cmd->result is non-zero. Returns a
  * new result that may suppress further error checking. Also modifies
@@ -869,20 +1035,9 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	struct request_queue *q = cmd->device->request_queue;
 	struct request *req = cmd->request;
 	blk_status_t blk_stat = BLK_STS_OK;
-	struct scsi_sense_hdr sshdr;
-	bool sense_valid = false;
-	bool sense_current = true;	/* false implies "deferred sense" */
-	int level = 0;
-	enum {ACTION_FAIL, ACTION_REPREP, ACTION_RETRY,
-	      ACTION_DELAYED_RETRY} action;
-	unsigned long wait_for = (cmd->allowed + 1) * req->timeout;
 
-	if (result) {	/* does not necessarily mean there is an error */
-		sense_valid = scsi_command_normalize_sense(cmd, &sshdr);
-		if (sense_valid)
-			sense_current = !scsi_sense_is_deferred(&sshdr);
+	if (result)	/* does not necessarily mean there is an error */
 		result = scsi_io_completion_nz_result(cmd, result, &blk_stat);
-	}
 
 	if (blk_rq_is_passthrough(req)) {
 		/*
@@ -936,138 +1091,12 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	 * If there had been no error, but we have leftover bytes in the
 	 * requeues just queue the command up again.
 	 */
-	if (result == 0)
-		goto requeue;
-
-	blk_stat = scsi_result_to_blk_status(cmd, result);
-
-	if (host_byte(result) == DID_RESET) {
-		/* Third party bus reset or reset for error recovery
-		 * reasons.  Just retry the command and see what
-		 * happens.
-		 */
-		action = ACTION_RETRY;
-	} else if (sense_valid && sense_current) {
-		switch (sshdr.sense_key) {
-		case UNIT_ATTENTION:
-			if (cmd->device->removable) {
-				/* Detected disc change.  Set a bit
-				 * and quietly refuse further access.
-				 */
-				cmd->device->changed = 1;
-				action = ACTION_FAIL;
-			} else {
-				/* Must have been a power glitch, or a
-				 * bus reset.  Could not have been a
-				 * media change, so we just retry the
-				 * command and see what happens.
-				 */
-				action = ACTION_RETRY;
-			}
-			break;
-		case ILLEGAL_REQUEST:
-			/* If we had an ILLEGAL REQUEST returned, then
-			 * we may have performed an unsupported
-			 * command.  The only thing this should be
-			 * would be a ten byte read where only a six
-			 * byte read was supported.  Also, on a system
-			 * where READ CAPACITY failed, we may have
-			 * read past the end of the disk.
-			 */
-			if ((cmd->device->use_10_for_rw &&
-			    sshdr.asc == 0x20 && sshdr.ascq == 0x00) &&
-			    (cmd->cmnd[0] == READ_10 ||
-			     cmd->cmnd[0] == WRITE_10)) {
-				/* This will issue a new 6-byte command. */
-				cmd->device->use_10_for_rw = 0;
-				action = ACTION_REPREP;
-			} else if (sshdr.asc == 0x10) /* DIX */ {
-				action = ACTION_FAIL;
-				blk_stat = BLK_STS_PROTECTION;
-			/* INVALID COMMAND OPCODE or INVALID FIELD IN CDB */
-			} else if (sshdr.asc == 0x20 || sshdr.asc == 0x24) {
-				action = ACTION_FAIL;
-				blk_stat = BLK_STS_TARGET;
-			} else
-				action = ACTION_FAIL;
-			break;
-		case ABORTED_COMMAND:
-			action = ACTION_FAIL;
-			if (sshdr.asc == 0x10) /* DIF */
-				blk_stat = BLK_STS_PROTECTION;
-			break;
-		case NOT_READY:
-			/* If the device is in the process of becoming
-			 * ready, or has a temporary blockage, retry.
-			 */
-			if (sshdr.asc == 0x04) {
-				switch (sshdr.ascq) {
-				case 0x01: /* becoming ready */
-				case 0x04: /* format in progress */
-				case 0x05: /* rebuild in progress */
-				case 0x06: /* recalculation in progress */
-				case 0x07: /* operation in progress */
-				case 0x08: /* Long write in progress */
-				case 0x09: /* self test in progress */
-				case 0x14: /* space allocation in progress */
-				case 0x1a: /* start stop unit in progress */
-				case 0x1b: /* sanitize in progress */
-				case 0x1d: /* configuration in progress */
-				case 0x24: /* depopulation in progress */
-					action = ACTION_DELAYED_RETRY;
-					break;
-				default:
-					action = ACTION_FAIL;
-					break;
-				}
-			} else
-				action = ACTION_FAIL;
-			break;
-		case VOLUME_OVERFLOW:
-			/* See SSC3rXX or current. */
-			action = ACTION_FAIL;
-			break;
-		default:
-			action = ACTION_FAIL;
-			break;
-		}
-	} else
-		action = ACTION_FAIL;
-
-	if (action != ACTION_FAIL &&
-	    time_before(cmd->jiffies_at_alloc + wait_for, jiffies))
-		action = ACTION_FAIL;
-
-	switch (action) {
-	case ACTION_FAIL:
-		/* Give up and fail the remainder of the request */
-		if (!(req->rq_flags & RQF_QUIET)) {
-			static DEFINE_RATELIMIT_STATE(_rs,
-					DEFAULT_RATELIMIT_INTERVAL,
-					DEFAULT_RATELIMIT_BURST);
-
-			if (unlikely(scsi_logging_level))
-				level = SCSI_LOG_LEVEL(SCSI_LOG_MLCOMPLETE_SHIFT,
-						       SCSI_LOG_MLCOMPLETE_BITS);
-
-			/*
-			 * if logging is enabled the failure will be printed
-			 * in scsi_log_completion(), so avoid duplicate messages
-			 */
-			if (!level && __ratelimit(&_rs)) {
-				scsi_print_result(cmd, NULL, FAILED);
-				if (driver_byte(result) & DRIVER_SENSE)
-					scsi_print_sense(cmd);
-				scsi_print_command(cmd);
-			}
-		}
-		if (!scsi_end_request(req, blk_stat, blk_rq_err_bytes(req), 0))
-			return;
-		/*FALLTHRU*/
-	case ACTION_REPREP:
-	requeue:
-		/* Unprep the request and put it back at the head of the queue.
-		 * A new command will be prepared and issued.
+	if (result == 0) {
+		/*
+		 * Unprep the request and put it back at the head of the
+		 * queue. A new command will be prepared and issued.
+		 * This block is the same as case ACTION_REPREP in
+		 * scsi_io_completion_action() above.
 		 */
 		if (q->mq_ops) {
 			scsi_mq_requeue_cmd(cmd);
@@ -1075,16 +1104,8 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			scsi_release_buffers(cmd);
 			scsi_requeue_command(q, cmd);
 		}
-		break;
-	case ACTION_RETRY:
-		/* Retry the same command immediately */
-		__scsi_queue_insert(cmd, SCSI_MLQUEUE_EH_RETRY, false);
-		break;
-	case ACTION_DELAYED_RETRY:
-		/* Retry the same command after a delay */
-		__scsi_queue_insert(cmd, SCSI_MLQUEUE_DEVICE_BUSY, false);
-		break;
-	}
+	} else
+		scsi_io_completion_action(cmd, result);
 }
 
 static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb)

commit ab83108460a2a0d71c5bb22830036c4646e94e63
Author: Douglas Gilbert <dgilbert@interlog.com>
Date:   Sat Jun 23 12:22:16 2018 +0200

    scsi: core: add scsi_io_completion_nz_result function
    
    Break out several intertwined paths when cmd->result is non zero and place
    them in the scsi_io_completion_nz_result helper function. The logic is not
    changed.
    
    Signed-off-by: Douglas Gilbert <dgilbert@interlog.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Bart Van Assche <bart.vanassche@wdc.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1da1ff46c496..02892408962b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -761,6 +761,79 @@ static blk_status_t scsi_result_to_blk_status(struct scsi_cmnd *cmd, int result)
 	}
 }
 
+/*
+ * Helper for scsi_io_completion() when cmd->result is non-zero. Returns a
+ * new result that may suppress further error checking. Also modifies
+ * *blk_statp in some cases.
+ */
+static int scsi_io_completion_nz_result(struct scsi_cmnd *cmd, int result,
+					blk_status_t *blk_statp)
+{
+	bool sense_valid;
+	bool sense_current = true;	/* false implies "deferred sense" */
+	struct request *req = cmd->request;
+	struct scsi_sense_hdr sshdr;
+
+	sense_valid = scsi_command_normalize_sense(cmd, &sshdr);
+	if (sense_valid)
+		sense_current = !scsi_sense_is_deferred(&sshdr);
+
+	if (blk_rq_is_passthrough(req)) {
+		if (sense_valid) {
+			/*
+			 * SG_IO wants current and deferred errors
+			 */
+			scsi_req(req)->sense_len =
+				min(8 + cmd->sense_buffer[7],
+				    SCSI_SENSE_BUFFERSIZE);
+		}
+		if (sense_current)
+			*blk_statp = scsi_result_to_blk_status(cmd, result);
+	} else if (blk_rq_bytes(req) == 0 && sense_current) {
+		/*
+		 * Flush commands do not transfers any data, and thus cannot use
+		 * good_bytes != blk_rq_bytes(req) as the signal for an error.
+		 * This sets *blk_statp explicitly for the problem case.
+		 */
+		*blk_statp = scsi_result_to_blk_status(cmd, result);
+	}
+	/*
+	 * Recovered errors need reporting, but they're always treated as
+	 * success, so fiddle the result code here.  For passthrough requests
+	 * we already took a copy of the original into sreq->result which
+	 * is what gets returned to the user
+	 */
+	if (sense_valid && (sshdr.sense_key == RECOVERED_ERROR)) {
+		bool do_print = true;
+		/*
+		 * if ATA PASS-THROUGH INFORMATION AVAILABLE [0x0, 0x1d]
+		 * skip print since caller wants ATA registers. Only occurs
+		 * on SCSI ATA PASS_THROUGH commands when CK_COND=1
+		 */
+		if ((sshdr.asc == 0x0) && (sshdr.ascq == 0x1d))
+			do_print = false;
+		else if (req->rq_flags & RQF_QUIET)
+			do_print = false;
+		if (do_print)
+			scsi_print_sense(cmd);
+		result = 0;
+		/* for passthrough, *blk_statp may be set */
+		*blk_statp = BLK_STS_OK;
+	}
+	/*
+	 * Another corner case: the SCSI status byte is non-zero but 'good'.
+	 * Example: PRE-FETCH command returns SAM_STAT_CONDITION_MET when
+	 * it is able to fit nominated LBs in its cache (and SAM_STAT_GOOD
+	 * if it can't fit). Treat SAM_STAT_CONDITION_MET and the related
+	 * intermediate statuses (both obsolete in SAM-4) as good.
+	 */
+	if (status_byte(result) && scsi_status_is_good(result)) {
+		result = 0;
+		*blk_statp = BLK_STS_OK;
+	}
+	return result;
+}
+
 /*
  * Function:    scsi_io_completion()
  *
@@ -804,26 +877,14 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	      ACTION_DELAYED_RETRY} action;
 	unsigned long wait_for = (cmd->allowed + 1) * req->timeout;
 
-	if (result) {
+	if (result) {	/* does not necessarily mean there is an error */
 		sense_valid = scsi_command_normalize_sense(cmd, &sshdr);
 		if (sense_valid)
 			sense_current = !scsi_sense_is_deferred(&sshdr);
+		result = scsi_io_completion_nz_result(cmd, result, &blk_stat);
 	}
 
 	if (blk_rq_is_passthrough(req)) {
-		if (result) {
-			if (sense_valid) {
-				/*
-				 * SG_IO wants current and deferred errors
-				 */
-				scsi_req(req)->sense_len =
-					min(8 + cmd->sense_buffer[7],
-					    SCSI_SENSE_BUFFERSIZE);
-			}
-			if (sense_current)
-				blk_stat = scsi_result_to_blk_status(cmd,
-								       result);
-		}
 		/*
 		 * scsi_result_to_blk_status may have reset the host_byte
 		 */
@@ -841,13 +902,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				BUG();
 			return;
 		}
-	} else if (blk_rq_bytes(req) == 0 && result && sense_current) {
-		/*
-		 * Flush commands do not transfers any data, and thus cannot use
-		 * good_bytes != blk_rq_bytes(req) as the signal for an error.
-		 * This sets blk_stat explicitly for the problem case.
-		 */
-		blk_stat = scsi_result_to_blk_status(cmd, result);
 	}
 
 	/* no bidi support for !blk_rq_is_passthrough yet */
@@ -861,42 +915,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		"%u sectors total, %d bytes done.\n",
 		blk_rq_sectors(req), good_bytes));
 
-	/*
-	 * Recovered errors need reporting, but they're always treated as
-	 * success, so fiddle the result code here.  For passthrough requests
-	 * we already took a copy of the original into sreq->result which
-	 * is what gets returned to the user
-	 */
-	if (sense_valid && (sshdr.sense_key == RECOVERED_ERROR)) {
-		bool do_print = true;
-
-		/*
-		 * If ATA PASS-THROUGH INFORMATION AVAILABLE skip
-		 * print since caller wants ATA registers. Only occurs on
-		 * SCSI ATA PASS_THROUGH commands when CK_COND=1
-		 */
-		if ((sshdr.asc == 0x0) && (sshdr.ascq == 0x1d))
-			do_print = false;
-		else if (req->rq_flags & RQF_QUIET)
-			do_print = false;
-		if (do_print)
-			scsi_print_sense(cmd);
-		result = 0;
-		/* for passthrough, blk_stat may be set */
-		blk_stat = BLK_STS_OK;
-	}
-	/*
-	 * Another corner case: the SCSI status byte is non-zero but 'good'.
-	 * Example: PRE-FETCH command returns SAM_STAT_CONDITION_MET when
-	 * it is able to fit nominated LBs in its cache (and SAM_STAT_GOOD
-	 * if it can't fit). Treat SAM_STAT_CONDITION_MET and the related
-	 * intermediate statuses (both obsolete in SAM-4) as good.
-	 */
-	if (status_byte(result) && scsi_status_is_good(result)) {
-		result = 0;
-		blk_stat = BLK_STS_OK;
-	}
-
 	/*
 	 * Next deal with any sectors which we were able to correctly
 	 * handle. Failed, zero length commands always need to drop down

commit 1f7cbb8e4b04fd33325a5cb279693861e549c03b
Author: Douglas Gilbert <dgilbert@interlog.com>
Date:   Sat Jun 23 12:22:15 2018 +0200

    scsi: core: scsi_io_completion: rename variables
    
    Change and add some variable names, adjust some associated comments for
    clarity. Correct some misleading comments.
    
    Signed-off-by: Douglas Gilbert <dgilbert@interlog.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Bart Van Assche <bart.vanassche@wdc.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 8ac2fa6256da..1da1ff46c496 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -787,18 +787,19 @@ static blk_status_t scsi_result_to_blk_status(struct scsi_cmnd *cmd, int result)
  *		   be put back on the queue and retried using the same
  *		   command as before, possibly after a delay.
  *
- *		c) We can call scsi_end_request() with -EIO to fail
- *		   the remainder of the request.
+ *		c) We can call scsi_end_request() with blk_stat other than
+ *		   BLK_STS_OK, to fail the remainder of the request.
  */
 void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 {
 	int result = cmd->result;
 	struct request_queue *q = cmd->device->request_queue;
 	struct request *req = cmd->request;
-	blk_status_t error = BLK_STS_OK;
+	blk_status_t blk_stat = BLK_STS_OK;
 	struct scsi_sense_hdr sshdr;
 	bool sense_valid = false;
-	int sense_deferred = 0, level = 0;
+	bool sense_current = true;	/* false implies "deferred sense" */
+	int level = 0;
 	enum {ACTION_FAIL, ACTION_REPREP, ACTION_RETRY,
 	      ACTION_DELAYED_RETRY} action;
 	unsigned long wait_for = (cmd->allowed + 1) * req->timeout;
@@ -806,7 +807,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	if (result) {
 		sense_valid = scsi_command_normalize_sense(cmd, &sshdr);
 		if (sense_valid)
-			sense_deferred = scsi_sense_is_deferred(&sshdr);
+			sense_current = !scsi_sense_is_deferred(&sshdr);
 	}
 
 	if (blk_rq_is_passthrough(req)) {
@@ -819,8 +820,9 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 					min(8 + cmd->sense_buffer[7],
 					    SCSI_SENSE_BUFFERSIZE);
 			}
-			if (!sense_deferred)
-				error = scsi_result_to_blk_status(cmd, result);
+			if (sense_current)
+				blk_stat = scsi_result_to_blk_status(cmd,
+								       result);
 		}
 		/*
 		 * scsi_result_to_blk_status may have reset the host_byte
@@ -839,13 +841,13 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				BUG();
 			return;
 		}
-	} else if (blk_rq_bytes(req) == 0 && result && !sense_deferred) {
+	} else if (blk_rq_bytes(req) == 0 && result && sense_current) {
 		/*
 		 * Flush commands do not transfers any data, and thus cannot use
 		 * good_bytes != blk_rq_bytes(req) as the signal for an error.
-		 * This sets the error explicitly for the problem case.
+		 * This sets blk_stat explicitly for the problem case.
 		 */
-		error = scsi_result_to_blk_status(cmd, result);
+		blk_stat = scsi_result_to_blk_status(cmd, result);
 	}
 
 	/* no bidi support for !blk_rq_is_passthrough yet */
@@ -866,17 +868,22 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	 * is what gets returned to the user
 	 */
 	if (sense_valid && (sshdr.sense_key == RECOVERED_ERROR)) {
-		/* if ATA PASS-THROUGH INFORMATION AVAILABLE skip
+		bool do_print = true;
+
+		/*
+		 * If ATA PASS-THROUGH INFORMATION AVAILABLE skip
 		 * print since caller wants ATA registers. Only occurs on
 		 * SCSI ATA PASS_THROUGH commands when CK_COND=1
 		 */
 		if ((sshdr.asc == 0x0) && (sshdr.ascq == 0x1d))
-			;
-		else if (!(req->rq_flags & RQF_QUIET))
+			do_print = false;
+		else if (req->rq_flags & RQF_QUIET)
+			do_print = false;
+		if (do_print)
 			scsi_print_sense(cmd);
 		result = 0;
-		/* for passthrough error may be set */
-		error = BLK_STS_OK;
+		/* for passthrough, blk_stat may be set */
+		blk_stat = BLK_STS_OK;
 	}
 	/*
 	 * Another corner case: the SCSI status byte is non-zero but 'good'.
@@ -887,23 +894,22 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	 */
 	if (status_byte(result) && scsi_status_is_good(result)) {
 		result = 0;
-		error = BLK_STS_OK;
+		blk_stat = BLK_STS_OK;
 	}
 
 	/*
-	 * special case: failed zero length commands always need to
-	 * drop down into the retry code. Otherwise, if we finished
-	 * all bytes in the request we are done now.
+	 * Next deal with any sectors which we were able to correctly
+	 * handle. Failed, zero length commands always need to drop down
+	 * to retry code. Fast path should return in this block.
 	 */
-	if (!(blk_rq_bytes(req) == 0 && error) &&
-	    !scsi_end_request(req, error, good_bytes, 0))
-		return;
+	if (blk_rq_bytes(req) > 0 || blk_stat == BLK_STS_OK) {
+		if (!scsi_end_request(req, blk_stat, good_bytes, 0))
+			return; /* no bytes remaining */
+	}
 
-	/*
-	 * Kill remainder if no retrys.
-	 */
-	if (error && scsi_noretry_cmd(cmd)) {
-		if (scsi_end_request(req, error, blk_rq_bytes(req), 0))
+	 /* Kill remainder if no retries. */
+	if (blk_stat && scsi_noretry_cmd(cmd)) {
+		if (scsi_end_request(req, blk_stat, blk_rq_bytes(req), 0))
 			BUG();
 		return;
 	}
@@ -915,7 +921,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	if (result == 0)
 		goto requeue;
 
-	error = scsi_result_to_blk_status(cmd, result);
+	blk_stat = scsi_result_to_blk_status(cmd, result);
 
 	if (host_byte(result) == DID_RESET) {
 		/* Third party bus reset or reset for error recovery
@@ -923,7 +929,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		 * happens.
 		 */
 		action = ACTION_RETRY;
-	} else if (sense_valid && !sense_deferred) {
+	} else if (sense_valid && sense_current) {
 		switch (sshdr.sense_key) {
 		case UNIT_ATTENTION:
 			if (cmd->device->removable) {
@@ -959,18 +965,18 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				action = ACTION_REPREP;
 			} else if (sshdr.asc == 0x10) /* DIX */ {
 				action = ACTION_FAIL;
-				error = BLK_STS_PROTECTION;
+				blk_stat = BLK_STS_PROTECTION;
 			/* INVALID COMMAND OPCODE or INVALID FIELD IN CDB */
 			} else if (sshdr.asc == 0x20 || sshdr.asc == 0x24) {
 				action = ACTION_FAIL;
-				error = BLK_STS_TARGET;
+				blk_stat = BLK_STS_TARGET;
 			} else
 				action = ACTION_FAIL;
 			break;
 		case ABORTED_COMMAND:
 			action = ACTION_FAIL;
 			if (sshdr.asc == 0x10) /* DIF */
-				error = BLK_STS_PROTECTION;
+				blk_stat = BLK_STS_PROTECTION;
 			break;
 		case NOT_READY:
 			/* If the device is in the process of becoming
@@ -1037,7 +1043,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				scsi_print_command(cmd);
 			}
 		}
-		if (!scsi_end_request(req, error, blk_rq_err_bytes(req), 0))
+		if (!scsi_end_request(req, blk_stat, blk_rq_err_bytes(req), 0))
 			return;
 		/*FALLTHRU*/
 	case ACTION_REPREP:

commit 7e63b5a4a68309383868b3582e92c217ad8a5347
Author: Douglas Gilbert <dgilbert@interlog.com>
Date:   Sat Jun 23 12:22:14 2018 +0200

    scsi: core: scsi_io_completion: comment on end_request return
    
    scsi_end_request() is called multiple times from scsi_io_completion() which
    branches on its bool returned value. Add comment before the static
    definition of scsi_end_request() about the meaning of that return.
    
    Signed-off-by: Douglas Gilbert <dgilbert@interlog.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Bart Van Assche <bart.vanassche@wdc.com>
    
    Signed-off-by: Douglas Gilbert <dgilbert@interlog.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 41e9ac9fc138..8ac2fa6256da 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -662,6 +662,7 @@ static void scsi_release_bidi_buffers(struct scsi_cmnd *cmd)
 	cmd->request->next_rq->special = NULL;
 }
 
+/* Returns false when no more bytes to process, true if there are more */
 static bool scsi_end_request(struct request *req, blk_status_t error,
 		unsigned int bytes, unsigned int bidi_bytes)
 {

commit 5f85942c2ea2ed59d8f19c954bbb0f5c1a2ebdd1
Merge: 0c14e43a42e4 1b5c2cb19668
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jun 10 13:01:12 2018 -0700

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This is mostly updates to the usual drivers: ufs, qedf, mpt3sas, lpfc,
      xfcp, hisi_sas, cxlflash, qla2xxx.
    
      In the absence of Nic, we're also taking target updates which are
      mostly minor except for the tcmu refactor.
    
      The only real core change to worry about is the removal of high page
      bouncing (in sas, storvsc and iscsi). This has been well tested and no
      problems have shown up so far"
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (268 commits)
      scsi: lpfc: update driver version to 12.0.0.4
      scsi: lpfc: Fix port initialization failure.
      scsi: lpfc: Fix 16gb hbas failing cq create.
      scsi: lpfc: Fix crash in blk_mq layer when executing modprobe -r lpfc
      scsi: lpfc: correct oversubscription of nvme io requests for an adapter
      scsi: lpfc: Fix MDS diagnostics failure (Rx < Tx)
      scsi: hisi_sas: Mark PHY as in reset for nexus reset
      scsi: hisi_sas: Fix return value when get_free_slot() failed
      scsi: hisi_sas: Terminate STP reject quickly for v2 hw
      scsi: hisi_sas: Add v2 hw force PHY function for internal ATA command
      scsi: hisi_sas: Include TMF elements in struct hisi_sas_slot
      scsi: hisi_sas: Try wait commands before before controller reset
      scsi: hisi_sas: Init disks after controller reset
      scsi: hisi_sas: Create a scsi_host_template per HW module
      scsi: hisi_sas: Reset disks when discovered
      scsi: hisi_sas: Add LED feature for v3 hw
      scsi: hisi_sas: Change common allocation mode of device id
      scsi: hisi_sas: change slot index allocation mode
      scsi: hisi_sas: Introduce hisi_sas_phy_set_linkrate()
      scsi: hisi_sas: fix a typo in hisi_sas_task_prep()
      ...

commit e5a594643a3444d39c1467040e638bf08a4e0db8
Merge: f956d08a5673 2550bbfd4952
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jun 4 10:58:12 2018 -0700

    Merge tag 'dma-mapping-4.18' of git://git.infradead.org/users/hch/dma-mapping
    
    Pull dma-mapping updates from Christoph Hellwig:
    
     - replace the force_dma flag with a dma_configure bus method. (Nipun
       Gupta, although one patch is іncorrectly attributed to me due to a
       git rebase bug)
    
     - use GFP_DMA32 more agressively in dma-direct. (Takashi Iwai)
    
     - remove PCI_DMA_BUS_IS_PHYS and rely on the dma-mapping API to do the
       right thing for bounce buffering.
    
     - move dma-debug initialization to common code, and apply a few
       cleanups to the dma-debug code.
    
     - cleanup the Kconfig mess around swiotlb selection
    
     - swiotlb comment fixup (Yisheng Xie)
    
     - a trivial swiotlb fix. (Dan Carpenter)
    
     - support swiotlb on RISC-V. (based on a patch from Palmer Dabbelt)
    
     - add a new generic dma-noncoherent dma_map_ops implementation and use
       it for arc, c6x and nds32.
    
     - improve scatterlist validity checking in dma-debug. (Robin Murphy)
    
     - add a struct device quirk to limit the dma-mask to 32-bit due to
       bridge/system issues, and switch x86 to use it instead of a local
       hack for VIA bridges.
    
     - handle devices without a dma_mask more gracefully in the dma-direct
       code.
    
    * tag 'dma-mapping-4.18' of git://git.infradead.org/users/hch/dma-mapping: (48 commits)
      dma-direct: don't crash on device without dma_mask
      nds32: use generic dma_noncoherent_ops
      nds32: implement the unmap_sg DMA operation
      nds32: consolidate DMA cache maintainance routines
      x86/pci-dma: switch the VIA 32-bit DMA quirk to use the struct device flag
      x86/pci-dma: remove the explicit nodac and allowdac option
      x86/pci-dma: remove the experimental forcesac boot option
      Documentation/x86: remove a stray reference to pci-nommu.c
      core, dma-direct: add a flag 32-bit dma limits
      dma-mapping: remove unused gfp_t parameter to arch_dma_alloc_attrs
      dma-debug: check scatterlist segments
      c6x: use generic dma_noncoherent_ops
      arc: use generic dma_noncoherent_ops
      arc: fix arc_dma_{map,unmap}_page
      arc: fix arc_dma_sync_sg_for_{cpu,device}
      arc: simplify arc_dma_sync_single_for_{cpu,device}
      dma-mapping: provide a generic dma-noncoherent implementation
      dma-mapping: simplify Kconfig dependencies
      riscv: add swiotlb support
      riscv: only enable ZONE_DMA32 for 64-bit
      ...

commit e37c7d9a0341a3577a071f4ac55912f38be229e2
Author: Douglas Gilbert <dgilbert@interlog.com>
Date:   Fri May 18 19:25:47 2018 -0400

    scsi: core: sanitize++ in progress
    
    Commit 505aa4b6a883 ("scsi: sd: Defer spinning up drive while SANITIZE is
    in progress") may not be sufficient, especially if the SCSI SANITIZE
    command is sent via the bsg or sg pass-throughs, since they don't use the
    sd driver.
    
    Add "Sanitize in progress" plus some other recent "... in progress"
    additional sense codes into the scsi mid-level so they are treated in a
    similar fashion to "Format in progress".
    
    [mkp: checkpatch]
    
    Signed-off-by: Douglas Gilbert <dgilbert@interlog.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e9b4f279d29c..9df5fbdbc854 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -985,6 +985,10 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				case 0x08: /* Long write in progress */
 				case 0x09: /* self test in progress */
 				case 0x14: /* space allocation in progress */
+				case 0x1a: /* start stop unit in progress */
+				case 0x1b: /* sanitize in progress */
+				case 0x1d: /* configuration in progress */
+				case 0x24: /* depopulation in progress */
 					action = ACTION_DELAYED_RETRY;
 					break;
 				default:

commit 0eb0b63c1d1a851b4c1606f4170691835d3616a2
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 9 09:54:08 2018 +0200

    block: consistently use GFP_NOIO instead of __GFP_NORECLAIM
    
    Same numerical value (for now at least), but a much better documentation
    of intent.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 6b0f3ec487bd..f125fd71c0f2 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -273,7 +273,7 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	rq = scsi_req(req);
 
 	if (bufflen &&	blk_rq_map_kern(sdev->request_queue, req,
-					buffer, bufflen, __GFP_RECLAIM))
+					buffer, bufflen, GFP_NOIO))
 		goto out;
 
 	rq->cmd_len = COMMAND_SIZE(cmd[0]);

commit ff005a066240efb73ae29a2bb9269ae726bc2eae
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 9 09:54:05 2018 +0200

    block: sanitize blk_get_request calling conventions
    
    Switch everyone to blk_get_request_flags, and then rename
    blk_get_request_flags to blk_get_request.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e9b4f279d29c..6b0f3ec487bd 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -265,7 +265,7 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	struct scsi_request *rq;
 	int ret = DRIVER_ERROR << 24;
 
-	req = blk_get_request_flags(sdev->request_queue,
+	req = blk_get_request(sdev->request_queue,
 			data_direction == DMA_TO_DEVICE ?
 			REQ_OP_SCSI_OUT : REQ_OP_SCSI_IN, BLK_MQ_REQ_PREEMPT);
 	if (IS_ERR(req))

commit 21e07dba9fb1179148089d611fc9e6e70d1887c3
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Apr 3 19:09:59 2018 +0200

    scsi: reduce use of block bounce buffers
    
    We can rely on the dma-mapping code to handle any DMA limits that is
    bigger than the ISA DMA mask for us (either using an iommu or swiotlb),
    so remove setting the block layer bounce limit for anything but the
    unchecked_isa_dma case, or the bouncing for highmem pages.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e9b4f279d29c..e0b614c0b1e6 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2149,27 +2149,6 @@ static int scsi_map_queues(struct blk_mq_tag_set *set)
 	return blk_mq_map_queues(set);
 }
 
-static u64 scsi_calculate_bounce_limit(struct Scsi_Host *shost)
-{
-	struct device *host_dev;
-	u64 bounce_limit = 0xffffffff;
-
-	if (shost->unchecked_isa_dma)
-		return BLK_BOUNCE_ISA;
-	/*
-	 * Platforms with virtual-DMA translation
-	 * hardware have no practical limit.
-	 */
-	if (!PCI_DMA_BUS_IS_PHYS)
-		return BLK_BOUNCE_ANY;
-
-	host_dev = scsi_get_device(shost);
-	if (host_dev && host_dev->dma_mask)
-		bounce_limit = (u64)dma_max_pfn(host_dev) << PAGE_SHIFT;
-
-	return bounce_limit;
-}
-
 void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 {
 	struct device *dev = shost->dma_dev;
@@ -2189,7 +2168,8 @@ void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 	}
 
 	blk_queue_max_hw_sectors(q, shost->max_sectors);
-	blk_queue_bounce_limit(q, scsi_calculate_bounce_limit(shost));
+	if (shost->unchecked_isa_dma)
+		blk_queue_bounce_limit(q, BLK_BOUNCE_ISA);
 	blk_queue_segment_boundary(q, shost->dma_boundary);
 	dma_set_seg_boundary(dev, shost->dma_boundary);
 

commit f4abab3f182b6b01e3e0f052721b4721a269a133
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Thu Apr 5 10:33:01 2018 -0700

    scsi: core: Make scsi_result_to_blk_status() recognize CONDITION MET
    
    Ensure that CONDITION MET and other non-zero status values that indicate
    success are translated into BLK_STS_OK.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Douglas Gilbert <dgilbert@interlog.com>
    Cc: Damien Le Moal <damien.lemoal@wdc.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Lee Duncan <lduncan@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ca5a6dfbe239..e9b4f279d29c 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -733,6 +733,15 @@ static bool scsi_end_request(struct request *req, blk_status_t error,
 static blk_status_t scsi_result_to_blk_status(struct scsi_cmnd *cmd, int result)
 {
 	switch (host_byte(result)) {
+	case DID_OK:
+		/*
+		 * Also check the other bytes than the status byte in result
+		 * to handle the case when a SCSI LLD sets result to
+		 * DRIVER_SENSE << 24 without setting SAM_STAT_CHECK_CONDITION.
+		 */
+		if (scsi_status_is_good(result) && (result & ~0xff) == 0)
+			return BLK_STS_OK;
+		return BLK_STS_IOERR;
 	case DID_TRANSPORT_FAILFAST:
 		return BLK_STS_TRANSPORT;
 	case DID_TARGET_FAILURE:

commit a77b32d8b1ed7365d8b2a35b188b059d211b658b
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Thu Apr 5 10:33:00 2018 -0700

    scsi: core: Rename __scsi_error_from_host_byte() into scsi_result_to_blk_status()
    
    Since the next patch will modify this function such that it checks more than
    just the host byte of the SCSI result, rename __scsi_error_from_host_byte()
    into scsi_result_to_blk_status().  This patch does not change any
    functionality.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Douglas Gilbert <dgilbert@interlog.com>
    Cc: Damien Le Moal <damien.lemoal@wdc.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Lee Duncan <lduncan@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b1631ac9eca3..ca5a6dfbe239 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -723,14 +723,14 @@ static bool scsi_end_request(struct request *req, blk_status_t error,
 }
 
 /**
- * __scsi_error_from_host_byte - translate SCSI error code into errno
- * @cmd:	SCSI command (unused)
+ * scsi_result_to_blk_status - translate a SCSI result code into blk_status_t
+ * @cmd:	SCSI command
  * @result:	scsi error code
  *
- * Translate SCSI error code into block errors.
+ * Translate a SCSI result code into a blk_status_t value. May reset the host
+ * byte of @cmd->result.
  */
-static blk_status_t __scsi_error_from_host_byte(struct scsi_cmnd *cmd,
-		int result)
+static blk_status_t scsi_result_to_blk_status(struct scsi_cmnd *cmd, int result)
 {
 	switch (host_byte(result)) {
 	case DID_TRANSPORT_FAILFAST:
@@ -810,10 +810,10 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 					    SCSI_SENSE_BUFFERSIZE);
 			}
 			if (!sense_deferred)
-				error = __scsi_error_from_host_byte(cmd, result);
+				error = scsi_result_to_blk_status(cmd, result);
 		}
 		/*
-		 * __scsi_error_from_host_byte may have reset the host_byte
+		 * scsi_result_to_blk_status may have reset the host_byte
 		 */
 		scsi_req(req)->result = cmd->result;
 		scsi_req(req)->resid_len = scsi_get_resid(cmd);
@@ -835,7 +835,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		 * good_bytes != blk_rq_bytes(req) as the signal for an error.
 		 * This sets the error explicitly for the problem case.
 		 */
-		error = __scsi_error_from_host_byte(cmd, result);
+		error = scsi_result_to_blk_status(cmd, result);
 	}
 
 	/* no bidi support for !blk_rq_is_passthrough yet */
@@ -905,7 +905,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	if (result == 0)
 		goto requeue;
 
-	error = __scsi_error_from_host_byte(cmd, result);
+	error = scsi_result_to_blk_status(cmd, result);
 
 	if (host_byte(result) == DID_RESET) {
 		/* Third party bus reset or reset for error recovery

commit cbe095e2b584623b882ebaf6c18e0b9077baa3f7
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Thu Apr 5 10:32:59 2018 -0700

    Revert "scsi: core: return BLK_STS_OK for DID_OK in __scsi_error_from_host_byte()"
    
    The description of commit e39a97353e53 is wrong: it mentions that commit
    2a842acab109 introduced a bug in __scsi_error_from_host_byte() although that
    commit did not change the behavior of that function.  Additionally, commit
    e39a97353e53 introduced a bug: it causes commands that fail with
    hostbyte=DID_OK and driverbyte=DRIVER_SENSE to be completed with
    BLK_STS_OK. Hence revert that commit.
    
    Fixes: e39a97353e53 ("scsi: core: return BLK_STS_OK for DID_OK in __scsi_error_from_host_byte()")
    Reported-by: Damien Le Moal <damien.lemoal@wdc.com>
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Douglas Gilbert <dgilbert@interlog.com>
    Cc: Damien Le Moal <damien.lemoal@wdc.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Lee Duncan <lduncan@suse.com>
    Cc: stable@vger.kernel.org
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0dfec0dedd5e..b1631ac9eca3 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -733,8 +733,6 @@ static blk_status_t __scsi_error_from_host_byte(struct scsi_cmnd *cmd,
 		int result)
 {
 	switch (host_byte(result)) {
-	case DID_OK:
-		return BLK_STS_OK;
 	case DID_TRANSPORT_FAILFAST:
 		return BLK_STS_TRANSPORT;
 	case DID_TARGET_FAILURE:

commit 052c220da392c4dcbc628852d04970447a315683
Merge: 3526dd0c7832 2e1f44f6ad80
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Apr 5 15:05:53 2018 -0700

    Merge tag 'scsi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This is mostly updates of the usual drivers: arcmsr, qla2xx, lpfc,
      ufs, mpt3sas, hisi_sas.
    
      In addition we have removed several really old drivers: sym53c416,
      NCR53c406a, fdomain, fdomain_cs and removed the old scsi_module.c
      initialization from all remaining drivers.
    
      Plus an assortment of bug fixes, initialization errors and other minor
      fixes"
    
    * tag 'scsi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (168 commits)
      scsi: ufs: Add support for Auto-Hibernate Idle Timer
      scsi: ufs: sysfs: reworking of the rpm_lvl and spm_lvl entries
      scsi: qla2xxx: fx00 copypaste typo
      scsi: qla2xxx: fix error message on <qla2400
      scsi: smartpqi: update driver version
      scsi: smartpqi: workaround fw bug for oq deletion
      scsi: arcmsr: Change driver version to v1.40.00.05-20180309
      scsi: arcmsr: Sleep to avoid CPU stuck too long for waiting adapter ready
      scsi: arcmsr: Handle adapter removed due to thunderbolt cable disconnection.
      scsi: arcmsr: Rename ACB_F_BUS_HANG_ON to ACB_F_ADAPTER_REMOVED for adapter hot-plug
      scsi: qla2xxx: Update driver version to 10.00.00.06-k
      scsi: qla2xxx: Fix Async GPN_FT for FCP and FC-NVMe scan
      scsi: qla2xxx: Cleanup code to improve FC-NVMe error handling
      scsi: qla2xxx: Fix FC-NVMe IO abort during driver reset
      scsi: qla2xxx: Fix retry for PRLI RJT with reason of BUSY
      scsi: qla2xxx: Remove nvme_done_list
      scsi: qla2xxx: Return busy if rport going away
      scsi: qla2xxx: Fix n2n_ae flag to prevent dev_loss on PDB change
      scsi: qla2xxx: Add FC-NVMe abort processing
      scsi: qla2xxx: Add changes for devloss timeout in driver
      ...

commit 3526dd0c7832f1011a0477cc6d903662bae05ea8
Merge: dd972f924df6 bc6d65e6dc89
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Apr 5 14:27:02 2018 -0700

    Merge tag 'for-4.17/block-20180402' of git://git.kernel.dk/linux-block
    
    Pull block layer updates from Jens Axboe:
     "It's a pretty quiet round this time, which is nice. This contains:
    
       - series from Bart, cleaning up the way we set/test/clear atomic
         queue flags.
    
       - series from Bart, fixing races between gendisk and queue
         registration and removal.
    
       - set of bcache fixes and improvements from various folks, by way of
         Michael Lyle.
    
       - set of lightnvm updates from Matias, most of it being the 1.2 to
         2.0 transition.
    
       - removal of unused DIO flags from Nikolay.
    
       - blk-mq/sbitmap memory ordering fixes from Omar.
    
       - divide-by-zero fix for BFQ from Paolo.
    
       - minor documentation patches from Randy.
    
       - timeout fix from Tejun.
    
       - Alpha "can't write a char atomically" fix from Mikulas.
    
       - set of NVMe fixes by way of Keith.
    
       - bsg and bsg-lib improvements from Christoph.
    
       - a few sed-opal fixes from Jonas.
    
       - cdrom check-disk-change deadlock fix from Maurizio.
    
       - various little fixes, comment fixes, etc from various folks"
    
    * tag 'for-4.17/block-20180402' of git://git.kernel.dk/linux-block: (139 commits)
      blk-mq: Directly schedule q->timeout_work when aborting a request
      blktrace: fix comment in blktrace_api.h
      lightnvm: remove function name in strings
      lightnvm: pblk: remove some unnecessary NULL checks
      lightnvm: pblk: don't recover unwritten lines
      lightnvm: pblk: implement 2.0 support
      lightnvm: pblk: implement get log report chunk
      lightnvm: pblk: rename ppaf* to addrf*
      lightnvm: pblk: check for supported version
      lightnvm: implement get log report chunk helpers
      lightnvm: make address conversions depend on generic device
      lightnvm: add support for 2.0 address format
      lightnvm: normalize geometry nomenclature
      lightnvm: complete geo structure with maxoc*
      lightnvm: add shorten OCSSD version in geo
      lightnvm: add minor version to generic geometry
      lightnvm: simplify geometry structure
      lightnvm: pblk: refactor init/exit sequences
      lightnvm: Avoid validation of default op value
      lightnvm: centralize permission check for lightnvm ioctl
      ...

commit 2e1f44f6ad8008be353c7c99286f7a747b4b3cf4
Merge: ad448378825f 3f6c9be27ae1
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Tue Mar 27 12:27:34 2018 -0400

    Merge branch 'fixes' into misc
    
    Somewhat nasty merge due to conflicts between "33b28357dd00 scsi:
    qla2xxx: Fix Async GPN_FT for FCP and FC-NVMe scan" and "2b5b96473efc
    scsi: qla2xxx: Fix FC-NVMe LUN discovery"
    
    Merge is non-trivial and has been verified by Qlogic (Cavium)
    
    Signed-off-by: James E.J. Bottomley <jejb@linux.vnet.ibm.com>

commit 17cb960f29c29ee07bf6848ada3265f4be55972e
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Mar 13 17:28:41 2018 +0100

    bsg: split handling of SCSI CDBs vs transport requeues
    
    The current BSG design tries to shoe-horn the transport-specific
    passthrough commands into the overall framework for SCSI passthrough
    requests.  This has a couple problems:
    
     - each passthrough queue has to set the QUEUE_FLAG_SCSI_PASSTHROUGH flag
       despite not dealing with SCSI commands at all.  Because of that these
       queues could also incorrectly accept SCSI commands from in-kernel
       users or through the legacy SCSI_IOCTL_SEND_COMMAND ioctl.
     - the real SCSI bsg queues also incorrectly accept bsg requests of the
       BSG_SUB_PROTOCOL_SCSI_TRANSPORT type
     - the bsg transport code is almost unredable because it tries to reuse
       different SCSI concepts for its own purpose.
    
    This patch instead adds a new bsg_ops structure to handle the two cases
    differently, and thus solves all of the above problems.  Another side
    effect is that the bsg-lib queues also don't need to embedd a
    struct scsi_request anymore.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 538152f3528e..37c1d63e847e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2140,8 +2140,6 @@ void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 {
 	struct device *dev = shost->dma_dev;
 
-	blk_queue_flag_set(QUEUE_FLAG_SCSI_PASSTHROUGH, q);
-
 	/*
 	 * this limit is imposed by hardware restrictions
 	 */
@@ -2239,6 +2237,7 @@ struct request_queue *scsi_old_alloc_queue(struct scsi_device *sdev)
 	}
 
 	__scsi_init_queue(shost, q);
+	blk_queue_flag_set(QUEUE_FLAG_SCSI_PASSTHROUGH, q);
 	blk_queue_prep_rq(q, scsi_prep_fn);
 	blk_queue_unprep_rq(q, scsi_unprep_fn);
 	blk_queue_softirq_done(q, scsi_softirq_done);
@@ -2270,6 +2269,7 @@ struct request_queue *scsi_mq_alloc_queue(struct scsi_device *sdev)
 
 	sdev->request_queue->queuedata = sdev;
 	__scsi_init_queue(sdev->host, sdev->request_queue);
+	blk_queue_flag_set(QUEUE_FLAG_SCSI_PASSTHROUGH, sdev->request_queue);
 	return sdev->request_queue;
 }
 

commit 1875ede02ed5e176a18dccbca84abc28d5b3e141
Author: Douglas Gilbert <dgilbert@interlog.com>
Date:   Tue Mar 6 22:19:49 2018 -0500

    scsi: core: Make SCSI Status CONDITION MET equivalent to GOOD
    
    The SCSI PRE-FETCH (10 or 16) command is present both on hard disks
    and some SSDs. It is useful when the address of the next block(s) to
    be read is known but it is not following the LBA of the current READ
    (so read-ahead won't help). It returns two "good" SCSI Status values.
    If the requested blocks have fitted (or will most likely fit (when
    the IMMED bit is set)) into the disk's cache, it returns CONDITION
    MET. If it didn't (or will not) fit then it returns GOOD status.
    
    The goal of this patch is to stop the SCSI subsystem treating the
    CONDITION MET SCSI status as an error. The current state makes the
    PRE-FETCH command effectively unusable via pass-throughs.
    
    Signed-off-by: Douglas Gilbert <dgilbert@interlog.com>
    Reviewed-by: Bart Van Assche <bart.vanassche@wdc.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 10430d500792..393f9db8f41b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -867,6 +867,17 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		/* for passthrough error may be set */
 		error = BLK_STS_OK;
 	}
+	/*
+	 * Another corner case: the SCSI status byte is non-zero but 'good'.
+	 * Example: PRE-FETCH command returns SAM_STAT_CONDITION_MET when
+	 * it is able to fit nominated LBs in its cache (and SAM_STAT_GOOD
+	 * if it can't fit). Treat SAM_STAT_CONDITION_MET and the related
+	 * intermediate statuses (both obsolete in SAM-4) as good.
+	 */
+	if (status_byte(result) && scsi_status_is_good(result)) {
+		result = 0;
+		error = BLK_STS_OK;
+	}
 
 	/*
 	 * special case: failed zero length commands always need to

commit 8b904b5b6b58b9a29dcf3f82d936d9e7fd69fda6
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Wed Mar 7 17:10:10 2018 -0800

    block: Use blk_queue_flag_*() in drivers instead of queue_flag_*()
    
    This patch has been generated as follows:
    
    for verb in set_unlocked clear_unlocked set clear; do
      replace-in-files queue_flag_${verb} blk_queue_flag_${verb%_unlocked} \
        $(git grep -lw queue_flag_${verb} drivers block/bsg*)
    done
    
    Except for protecting all queue flag changes with the queue lock
    this patch does not change any functionality.
    
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: Shaohua Li <shli@fb.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.de>
    Cc: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Acked-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 71d1135f94d0..538152f3528e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2140,7 +2140,7 @@ void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 {
 	struct device *dev = shost->dma_dev;
 
-	queue_flag_set_unlocked(QUEUE_FLAG_SCSI_PASSTHROUGH, q);
+	blk_queue_flag_set(QUEUE_FLAG_SCSI_PASSTHROUGH, q);
 
 	/*
 	 * this limit is imposed by hardware restrictions

commit be75b1b8bc0814b8f76e4e7bb970c76d05ddf3b1
Merge: 86f84779d8e9 967823d6c398
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 7 10:50:15 2018 -0800

    Merge tag 'scsi-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI fixes from James Bottomley:
     "This is mostly fixes for driver specific issues (nine of them) and the
      storvsc performance improvement with interrupt handling which was
      dropped from the previous fixes pull request.
    
      We also have two regressions: one is a double call_rcu() in ATA error
      handling and the other is a missed conversion to BLK_STS_OK in
      __scsi_error_from_host_byte()"
    
    * tag 'scsi-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi:
      scsi: qedi: Fix kernel crash during port toggle
      scsi: qla2xxx: Fix FC-NVMe LUN discovery
      scsi: core: return BLK_STS_OK for DID_OK in __scsi_error_from_host_byte()
      scsi: core: Avoid that ATA error handling can trigger a kernel hang or oops
      scsi: qla2xxx: ensure async flags are reset correctly
      scsi: qla2xxx: do not check login_state if no loop id is assigned
      scsi: qla2xxx: Fixup locking for session deletion
      scsi: qla2xxx: Fix NULL pointer crash due to active timer for ABTS
      scsi: mpt3sas: wait for and flush running commands on shutdown/unload
      scsi: mpt3sas: fix oops in error handlers after shutdown/unload
      scsi: storvsc: Spread interrupts when picking a channel for I/O requests
      scsi: megaraid_sas: Do not use 32-bit atomic request descriptor for Ventura controllers

commit 2f793a27d58f0fb302f8e162b46fe4b366bbdedd
Author: Jianchao Wang <jianchao.w.wang@oracle.com>
Date:   Sat Mar 3 09:54:09 2018 +0800

    scsi: core: use blk_mq_requeue_request in __scsi_queue_insert
    
    In scsi core, __scsi_queue_insert should just put request back on the
    queue and retry using the same command as before. However, for blk-mq,
    scsi_mq_requeue_cmd is employed here which will unprepare the
    request. To align with the semantics of __scsi_queue_insert, use
    blk_mq_requeue_request with kick_requeue_list == true and put the
    reference of scsi_device.
    
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jianchao Wang <jianchao.w.wang@oracle.com>
    Reviewed-by: Bart Van Assche <bart.vanassche@wdc.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index aea5a1ae318b..10430d500792 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -191,7 +191,19 @@ static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, bool unbusy)
 	 */
 	cmd->result = 0;
 	if (q->mq_ops) {
-		scsi_mq_requeue_cmd(cmd);
+		/*
+		 * Before a SCSI command is dispatched,
+		 * get_device(&sdev->sdev_gendev) is called and the host,
+		 * target and device busy counters are increased. Since
+		 * requeuing a request causes these actions to be repeated and
+		 * since scsi_device_unbusy() has already been called,
+		 * put_device(&device->sdev_gendev) must still be called. Call
+		 * put_device() after blk_mq_requeue_request() to avoid that
+		 * removal of the SCSI device can start before requeueing has
+		 * happened.
+		 */
+		blk_mq_requeue_request(cmd->request, true);
+		put_device(&device->sdev_gendev);
 		return;
 	}
 	spin_lock_irqsave(q->queue_lock, flags);

commit e39a97353e5378eb46bf01679799c5704d397f32
Author: Hannes Reinecke <hare@suse.de>
Date:   Mon Feb 26 08:39:59 2018 +0100

    scsi: core: return BLK_STS_OK for DID_OK in __scsi_error_from_host_byte()
    
    When converting __scsi_error_from_host_byte() to BLK_STS error codes the
    case DID_OK was forgotten, resulting in it always returning an error.
    
    Fixes: 2a842acab109 ("block: introduce new block status code type")
    Cc: Doug Gilbert <dgilbert@interlog.com>
    Signed-off-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Douglas Gilbert <dgilbert@interlog.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4af1682f5ff5..c9844043504e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -720,6 +720,8 @@ static blk_status_t __scsi_error_from_host_byte(struct scsi_cmnd *cmd,
 		int result)
 {
 	switch (host_byte(result)) {
+	case DID_OK:
+		return BLK_STS_OK;
 	case DID_TRANSPORT_FAILFAST:
 		return BLK_STS_TRANSPORT;
 	case DID_TARGET_FAILURE:

commit 3be8828fc507cdafe7040a3dcf361a2bcd8e305b
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Thu Feb 22 11:30:20 2018 -0800

    scsi: core: Avoid that ATA error handling can trigger a kernel hang or oops
    
    Avoid that the recently introduced call_rcu() call in the SCSI core
    triggers a double call_rcu() call.
    
    Reported-by: Natanael Copa <ncopa@alpinelinux.org>
    Reported-by: Damien Le Moal <damien.lemoal@wdc.com>
    References: https://bugzilla.kernel.org/show_bug.cgi?id=198861
    Fixes: 3bd6f43f5cb3 ("scsi: core: Ensure that the SCSI error handler gets woken up")
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Reviewed-by: Damien Le Moal <damien.lemoal@wdc.com>
    Tested-by: Damien Le Moal <damien.lemoal@wdc.com>
    Cc: Natanael Copa <ncopa@alpinelinux.org>
    Cc: Damien Le Moal <damien.lemoal@wdc.com>
    Cc: Alexandre Oliva <oliva@gnu.org>
    Cc: Pavel Tikhomirov <ptikhomirov@virtuozzo.com>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 5cbc69b2b1ae..4af1682f5ff5 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -670,6 +670,7 @@ static bool scsi_end_request(struct request *req, blk_status_t error,
 	if (!blk_rq_is_scsi(req)) {
 		WARN_ON_ONCE(!(cmd->flags & SCMD_INITIALIZED));
 		cmd->flags &= ~SCMD_INITIALIZED;
+		destroy_rcu_head(&cmd->rcu);
 	}
 
 	if (req->mq_ctx) {
@@ -1150,6 +1151,7 @@ static void scsi_initialize_rq(struct request *rq)
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
 
 	scsi_req_init(&cmd->req);
+	init_rcu_head(&cmd->rcu);
 	cmd->jiffies_at_alloc = jiffies;
 	cmd->retries = 0;
 }

commit 5ee0524ba137fe928a88b440d014e3c8451fb32c
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Wed Feb 28 10:15:31 2018 -0800

    block: Add 'lock' as third argument to blk_alloc_queue_node()
    
    This patch does not change any functionality.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Reviewed-by: Joseph Qi <joseph.qi@linux.alibaba.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Philipp Reisner <philipp.reisner@linbit.com>
    Cc: Ulf Hansson <ulf.hansson@linaro.org>
    Cc: Kees Cook <keescook@chromium.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a86df9ca7d1c..71d1135f94d0 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2223,7 +2223,7 @@ struct request_queue *scsi_old_alloc_queue(struct scsi_device *sdev)
 	struct Scsi_Host *shost = sdev->host;
 	struct request_queue *q;
 
-	q = blk_alloc_queue_node(GFP_KERNEL, NUMA_NO_NODE);
+	q = blk_alloc_queue_node(GFP_KERNEL, NUMA_NO_NODE, NULL);
 	if (!q)
 		return NULL;
 	q->cmd_size = sizeof(struct scsi_cmnd) + shost->hostt->cmd_size;

commit 9b91fd34b46ded81232de3ce41b9b662ec74b07f
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Mon Feb 12 10:57:52 2018 -0800

    scsi: core: Reduce number of scsi_test_unit_ready() retries
    
    Make scsi_test_unit_ready() send at most as many TURs as specified in
    the 'retries' argument instead of retries * (retries + 1) / 2.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a86df9ca7d1c..aea5a1ae318b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2607,7 +2607,7 @@ scsi_test_unit_ready(struct scsi_device *sdev, int timeout, int retries,
 	/* try to eat the UNIT_ATTENTION if there are enough retries */
 	do {
 		result = scsi_execute_req(sdev, cmd, DMA_NONE, NULL, 0, sshdr,
-					  timeout, retries, NULL);
+					  timeout, 1, NULL);
 		if (sdev->removable && scsi_sense_valid(sshdr) &&
 		    sshdr->sense_key == UNIT_ATTENTION)
 			sdev->changed = 1;

commit 64b28683deba132f301d1cecfc25c32e295f53a1
Merge: d3658c226601 1d5187757879
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Feb 4 11:16:35 2018 -0800

    Merge tag 'for-linus-20180204' of git://git.kernel.dk/linux-block
    
    Pull more block updates from Jens Axboe:
     "Most of this is fixes and not new code/features:
    
       - skd fix from Arnd, fixing a build error dependent on sla allocator
         type.
    
       - blk-mq scheduler discard merging fixes, one from me and one from
         Keith. This fixes a segment miscalculation for blk-mq-sched, where
         we mistakenly think two segments are physically contigious even
         though the request isn't carrying real data. Also fixes a bio-to-rq
         merge case.
    
       - Don't re-set a bit on the buffer_head flags, if it's already set.
         This can cause scalability concerns on bigger machines and
         workloads. From Kemi Wang.
    
       - Add BLK_STS_DEV_RESOURCE return value to blk-mq, allowing us to
         distuingish between a local (device related) resource starvation
         and a global one. The latter might happen without IO being in
         flight, so it has to be handled a bit differently. From Ming"
    
    * tag 'for-linus-20180204' of git://git.kernel.dk/linux-block:
      block: skd: fix incorrect linux/slab_def.h inclusion
      buffer: Avoid setting buffer bits that are already set
      blk-mq-sched: Enable merging discard bio into request
      blk-mq: fix discard merge with scheduler attached
      blk-mq: introduce BLK_STS_DEV_RESOURCE

commit 617aebe6a97efa539cc4b8a52adccd89596e6be0
Merge: 0771ad44a20b e47e311843de
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Feb 3 16:25:42 2018 -0800

    Merge tag 'usercopy-v4.16-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/kees/linux
    
    Pull hardened usercopy whitelisting from Kees Cook:
     "Currently, hardened usercopy performs dynamic bounds checking on slab
      cache objects. This is good, but still leaves a lot of kernel memory
      available to be copied to/from userspace in the face of bugs.
    
      To further restrict what memory is available for copying, this creates
      a way to whitelist specific areas of a given slab cache object for
      copying to/from userspace, allowing much finer granularity of access
      control.
    
      Slab caches that are never exposed to userspace can declare no
      whitelist for their objects, thereby keeping them unavailable to
      userspace via dynamic copy operations. (Note, an implicit form of
      whitelisting is the use of constant sizes in usercopy operations and
      get_user()/put_user(); these bypass all hardened usercopy checks since
      these sizes cannot change at runtime.)
    
      This new check is WARN-by-default, so any mistakes can be found over
      the next several releases without breaking anyone's system.
    
      The series has roughly the following sections:
       - remove %p and improve reporting with offset
       - prepare infrastructure and whitelist kmalloc
       - update VFS subsystem with whitelists
       - update SCSI subsystem with whitelists
       - update network subsystem with whitelists
       - update process memory with whitelists
       - update per-architecture thread_struct with whitelists
       - update KVM with whitelists and fix ioctl bug
       - mark all other allocations as not whitelisted
       - update lkdtm for more sensible test overage"
    
    * tag 'usercopy-v4.16-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/kees/linux: (38 commits)
      lkdtm: Update usercopy tests for whitelisting
      usercopy: Restrict non-usercopy caches to size 0
      kvm: x86: fix KVM_XEN_HVM_CONFIG ioctl
      kvm: whitelist struct kvm_vcpu_arch
      arm: Implement thread_struct whitelist for hardened usercopy
      arm64: Implement thread_struct whitelist for hardened usercopy
      x86: Implement thread_struct whitelist for hardened usercopy
      fork: Provide usercopy whitelisting for task_struct
      fork: Define usercopy region in thread_stack slab caches
      fork: Define usercopy region in mm_struct slab caches
      net: Restrict unwhitelisted proto caches to size 0
      sctp: Copy struct sctp_sock.autoclose to userspace using put_user()
      sctp: Define usercopy region in SCTP proto slab cache
      caif: Define usercopy region in caif proto slab cache
      ip: Define usercopy region in IP proto slab cache
      net: Define usercopy region in struct proto slab cache
      scsi: Define usercopy region in scsi_sense_cache slab cache
      cifs: Define usercopy region in cifs_request slab cache
      vxfs: Define usercopy region in vxfs_inode slab cache
      ufs: Define usercopy region in ufs_inode_cache slab cache
      ...

commit 28bc6fb9596fe1e577d09fc17ee6e1bb051c6ba3
Merge: 0be600a5add7 a2390348c19d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 31 11:23:28 2018 -0800

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This is mostly updates of the usual driver suspects: arcmsr,
      scsi_debug, mpt3sas, lpfc, cxlflash, qla2xxx, aacraid, megaraid_sas,
      hisi_sas.
    
      We also have a rework of the libsas hotplug handling to make it more
      robust, a slew of 32 bit time conversions and fixes, and a host of the
      usual minor updates and style changes. The biggest potential for
      regressions is the libsas hotplug changes, but so far they seem stable
      under testing"
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (313 commits)
      scsi: qla2xxx: Fix logo flag for qlt_free_session_done()
      scsi: arcmsr: avoid do_gettimeofday
      scsi: core: Add VENDOR_SPECIFIC sense code definitions
      scsi: qedi: Drop cqe response during connection recovery
      scsi: fas216: fix sense buffer initialization
      scsi: ibmvfc: Remove unneeded semicolons
      scsi: hisi_sas: fix a bug in hisi_sas_dev_gone()
      scsi: hisi_sas: directly attached disk LED feature for v2 hw
      scsi: hisi_sas: devicetree: bindings: add LED feature for v2 hw
      scsi: megaraid_sas: NVMe passthrough command support
      scsi: megaraid: use ktime_get_real for firmware time
      scsi: fnic: use 64-bit timestamps
      scsi: qedf: Fix error return code in __qedf_probe()
      scsi: devinfo: fix format of the device list
      scsi: qla2xxx: Update driver version to 10.00.00.05-k
      scsi: qla2xxx: Add XCB counters to debugfs
      scsi: qla2xxx: Fix queue ID for async abort with Multiqueue
      scsi: qla2xxx: Fix warning for code intentation in __qla24xx_handle_gpdb_event()
      scsi: qla2xxx: Fix warning during port_name debug print
      scsi: qla2xxx: Fix warning in qla2x00_async_iocb_timeout()
      ...

commit 86ff7c2a80cd357f6156a53b354f6a0b357dc0c9
Author: Ming Lei <ming.lei@redhat.com>
Date:   Tue Jan 30 22:04:57 2018 -0500

    blk-mq: introduce BLK_STS_DEV_RESOURCE
    
    This status is returned from driver to block layer if device related
    resource is unavailable, but driver can guarantee that IO dispatch
    will be triggered in future when the resource is available.
    
    Convert some drivers to return BLK_STS_DEV_RESOURCE.  Also, if driver
    returns BLK_STS_RESOURCE and SCHED_RESTART is set, rerun queue after
    a delay (BLK_MQ_DELAY_QUEUE) to avoid IO stalls.  BLK_MQ_DELAY_QUEUE is
    3 ms because both scsi-mq and nvmefc are using that magic value.
    
    If a driver can make sure there is in-flight IO, it is safe to return
    BLK_STS_DEV_RESOURCE because:
    
    1) If all in-flight IOs complete before examining SCHED_RESTART in
    blk_mq_dispatch_rq_list(), SCHED_RESTART must be cleared, so queue
    is run immediately in this case by blk_mq_dispatch_rq_list();
    
    2) if there is any in-flight IO after/when examining SCHED_RESTART
    in blk_mq_dispatch_rq_list():
    - if SCHED_RESTART isn't set, queue is run immediately as handled in 1)
    - otherwise, this request will be dispatched after any in-flight IO is
      completed via blk_mq_sched_restart()
    
    3) if SCHED_RESTART is set concurently in context because of
    BLK_STS_RESOURCE, blk_mq_delay_run_hw_queue() will cover the above two
    cases and make sure IO hang can be avoided.
    
    One invariant is that queue will be rerun if SCHED_RESTART is set.
    
    Suggested-by: Jens Axboe <axboe@kernel.dk>
    Tested-by: Laurence Oberman <loberman@redhat.com>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d9ca1dfab154..55be2550c555 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2030,9 +2030,9 @@ static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	case BLK_STS_OK:
 		break;
 	case BLK_STS_RESOURCE:
-		if (atomic_read(&sdev->device_busy) == 0 &&
-		    !scsi_device_blocked(sdev))
-			blk_mq_delay_run_hw_queue(hctx, SCSI_QUEUE_DELAY);
+		if (atomic_read(&sdev->device_busy) ||
+		    scsi_device_blocked(sdev))
+			ret = BLK_STS_DEV_RESOURCE;
 		break;
 	default:
 		/*

commit 0afe76e88c57d91ef5697720aed380a339e3df70
Author: David Windsor <dave@nullcore.net>
Date:   Sat Jun 10 22:50:45 2017 -0400

    scsi: Define usercopy region in scsi_sense_cache slab cache
    
    SCSI sense buffers, stored in struct scsi_cmnd.sense and therefore
    contained in the scsi_sense_cache slab cache, need to be copied to/from
    userspace.
    
    cache object allocation:
        drivers/scsi/scsi_lib.c:
            scsi_select_sense_cache(...):
                return ... ? scsi_sense_isadma_cache : scsi_sense_cache
    
            scsi_alloc_sense_buffer(...):
                return kmem_cache_alloc_node(scsi_select_sense_cache(), ...);
    
            scsi_init_request(...):
                ...
                cmd->sense_buffer = scsi_alloc_sense_buffer(...);
                ...
                cmd->req.sense = cmd->sense_buffer
    
    example usage trace:
    
        block/scsi_ioctl.c:
            (inline from sg_io)
            blk_complete_sghdr_rq(...):
                struct scsi_request *req = scsi_req(rq);
                ...
                copy_to_user(..., req->sense, len)
    
            scsi_cmd_ioctl(...):
                sg_io(...);
    
    In support of usercopy hardening, this patch defines a region in
    the scsi_sense_cache slab cache in which userspace copy operations
    are allowed.
    
    This region is known as the slab cache's usercopy region. Slab caches
    can now check that each dynamically sized copy operation involving
    cache-managed memory falls entirely within the slab's usercopy region.
    
    Signed-off-by: David Windsor <dave@nullcore.net>
    [kees: adjust commit log, provide usage trace]
    Cc: "James E.J. Bottomley" <jejb@linux.vnet.ibm.com>
    Cc: "Martin K. Petersen" <martin.petersen@oracle.com>
    Cc: linux-scsi@vger.kernel.org
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1cbc497e00bd..164d062c4d94 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -79,14 +79,15 @@ int scsi_init_sense_cache(struct Scsi_Host *shost)
 	if (shost->unchecked_isa_dma) {
 		scsi_sense_isadma_cache =
 			kmem_cache_create("scsi_sense_cache(DMA)",
-			SCSI_SENSE_BUFFERSIZE, 0,
-			SLAB_HWCACHE_ALIGN | SLAB_CACHE_DMA, NULL);
+				SCSI_SENSE_BUFFERSIZE, 0,
+				SLAB_HWCACHE_ALIGN | SLAB_CACHE_DMA, NULL);
 		if (!scsi_sense_isadma_cache)
 			ret = -ENOMEM;
 	} else {
 		scsi_sense_cache =
-			kmem_cache_create("scsi_sense_cache",
-			SCSI_SENSE_BUFFERSIZE, 0, SLAB_HWCACHE_ALIGN, NULL);
+			kmem_cache_create_usercopy("scsi_sense_cache",
+				SCSI_SENSE_BUFFERSIZE, 0, SLAB_HWCACHE_ALIGN,
+				0, SCSI_SENSE_BUFFERSIZE, NULL);
 		if (!scsi_sense_cache)
 			ret = -ENOMEM;
 	}

commit 08640e81dc33e02405b909bb289fcf91de663443
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Wed Jan 10 14:41:45 2018 -0800

    scsi: core: Change third __scsi_queue_insert() argument from int to bool
    
    This patch does not change any functionality but makes the SCSI core
    source code slightly easier to read.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.de>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c3fc4353af3c..5cbc69b2b1ae 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -164,7 +164,7 @@ static void scsi_mq_requeue_cmd(struct scsi_cmnd *cmd)
  * for a requeue after completion, which should only occur in this
  * file.
  */
-static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
+static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, bool unbusy)
 {
 	struct scsi_device *device = cmd->device;
 	struct request_queue *q = device->request_queue;
@@ -220,7 +220,7 @@ static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
  */
 void scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 {
-	__scsi_queue_insert(cmd, reason, 1);
+	__scsi_queue_insert(cmd, reason, true);
 }
 
 
@@ -1015,11 +1015,11 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		break;
 	case ACTION_RETRY:
 		/* Retry the same command immediately */
-		__scsi_queue_insert(cmd, SCSI_MLQUEUE_EH_RETRY, 0);
+		__scsi_queue_insert(cmd, SCSI_MLQUEUE_EH_RETRY, false);
 		break;
 	case ACTION_DELAYED_RETRY:
 		/* Retry the same command after a delay */
-		__scsi_queue_insert(cmd, SCSI_MLQUEUE_DEVICE_BUSY, 0);
+		__scsi_queue_insert(cmd, SCSI_MLQUEUE_DEVICE_BUSY, false);
 		break;
 	}
 }

commit e4c9470b9f21a0ee3b4625f6d29792c240b71c67
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Thu Dec 7 15:59:31 2017 -0800

    scsi: core: Unexport scsi_initialize_rq()
    
    Commit 651a01364994 ("scsi: scsi_transport_sas: switch to bsg-lib for
    SMP passthrough") removed the only call to scsi_initialize_rq() from
    outside the SCSI core. Hence unexport scsi_initialize_rq().
    
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1827956b33c9..c3fc4353af3c 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1145,7 +1145,7 @@ EXPORT_SYMBOL(scsi_init_io);
  * Called from inside blk_get_request() for pass-through requests and from
  * inside scsi_init_command() for filesystem requests.
  */
-void scsi_initialize_rq(struct request *rq)
+static void scsi_initialize_rq(struct request *rq)
 {
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
 
@@ -1153,7 +1153,6 @@ void scsi_initialize_rq(struct request *rq)
 	cmd->jiffies_at_alloc = jiffies;
 	cmd->retries = 0;
 }
-EXPORT_SYMBOL(scsi_initialize_rq);
 
 /* Add a command to the list used by the aacraid and dpt_i2o drivers */
 void scsi_add_cmd_to_list(struct scsi_cmnd *cmd)

commit 3bd6f43f5cb3714f70c591514f344389df593501
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Mon Dec 4 10:06:23 2017 -0800

    scsi: core: Ensure that the SCSI error handler gets woken up
    
    If scsi_eh_scmd_add() is called concurrently with
    scsi_host_queue_ready() while shost->host_blocked > 0 then it can
    happen that neither function wakes up the SCSI error handler. Fix
    this by making every function that decreases the host_busy counter
    wake up the error handler if necessary and by protecting the
    host_failed checks with the SCSI host lock.
    
    Reported-by: Pavel Tikhomirov <ptikhomirov@virtuozzo.com>
    References: https://marc.info/?l=linux-kernel&m=150461610630736
    Fixes: commit 746650160866 ("scsi: convert host_busy to atomic_t")
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Reviewed-by: Pavel Tikhomirov <ptikhomirov@virtuozzo.com>
    Tested-by: Stuart Hayes <stuart.w.hayes@gmail.com>
    Cc: Konstantin Khorenko <khorenko@virtuozzo.com>
    Cc: Stuart Hayes <stuart.w.hayes@gmail.com>
    Cc: Pavel Tikhomirov <ptikhomirov@virtuozzo.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1cbc497e00bd..1827956b33c9 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -318,22 +318,39 @@ static void scsi_init_cmd_errh(struct scsi_cmnd *cmd)
 		cmd->cmd_len = scsi_command_size(cmd->cmnd);
 }
 
-void scsi_device_unbusy(struct scsi_device *sdev)
+/*
+ * Decrement the host_busy counter and wake up the error handler if necessary.
+ * Avoid as follows that the error handler is not woken up if shost->host_busy
+ * == shost->host_failed: use call_rcu() in scsi_eh_scmd_add() in combination
+ * with an RCU read lock in this function to ensure that this function in its
+ * entirety either finishes before scsi_eh_scmd_add() increases the
+ * host_failed counter or that it notices the shost state change made by
+ * scsi_eh_scmd_add().
+ */
+static void scsi_dec_host_busy(struct Scsi_Host *shost)
 {
-	struct Scsi_Host *shost = sdev->host;
-	struct scsi_target *starget = scsi_target(sdev);
 	unsigned long flags;
 
+	rcu_read_lock();
 	atomic_dec(&shost->host_busy);
-	if (starget->can_queue > 0)
-		atomic_dec(&starget->target_busy);
-
-	if (unlikely(scsi_host_in_recovery(shost) &&
-		     (shost->host_failed || shost->host_eh_scheduled))) {
+	if (unlikely(scsi_host_in_recovery(shost))) {
 		spin_lock_irqsave(shost->host_lock, flags);
-		scsi_eh_wakeup(shost);
+		if (shost->host_failed || shost->host_eh_scheduled)
+			scsi_eh_wakeup(shost);
 		spin_unlock_irqrestore(shost->host_lock, flags);
 	}
+	rcu_read_unlock();
+}
+
+void scsi_device_unbusy(struct scsi_device *sdev)
+{
+	struct Scsi_Host *shost = sdev->host;
+	struct scsi_target *starget = scsi_target(sdev);
+
+	scsi_dec_host_busy(shost);
+
+	if (starget->can_queue > 0)
+		atomic_dec(&starget->target_busy);
 
 	atomic_dec(&sdev->device_busy);
 }
@@ -1532,7 +1549,7 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 		list_add_tail(&sdev->starved_entry, &shost->starved_list);
 	spin_unlock_irq(shost->host_lock);
 out_dec:
-	atomic_dec(&shost->host_busy);
+	scsi_dec_host_busy(shost);
 	return 0;
 }
 
@@ -2018,7 +2035,7 @@ static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	return BLK_STS_OK;
 
 out_dec_host_busy:
-       atomic_dec(&shost->host_busy);
+	scsi_dec_host_busy(shost);
 out_dec_target_busy:
 	if (scsi_target(sdev)->can_queue > 0)
 		atomic_dec(&scsi_target(sdev)->target_busy);

commit 7e70aa789d4a0c89dbfbd2c8a974a4df717475ec
Author: Ming Lei <ming.lei@redhat.com>
Date:   Tue Dec 5 15:52:56 2017 +0800

    scsi: core: run queue if SCSI device queue isn't ready and queue is idle
    
    Before commit 0df21c86bdbf ("scsi: implement .get_budget and .put_budget
    for blk-mq"), we run queue after 3ms if queue is idle and SCSI device
    queue isn't ready, which is done in handling BLK_STS_RESOURCE. After
    commit 0df21c86bdbf is introduced, queue won't be run any more under
    this situation.
    
    IO hang is observed when timeout happened, and this patch fixes the IO
    hang issue by running queue after delay in scsi_dev_queue_ready, just
    like non-mq. This issue can be triggered by the following script[1].
    
    There is another issue which can be covered by running idle queue: when
    .get_budget() is called on request coming from hctx->dispatch_list, if
    one request just completes during .get_budget(), we can't depend on
    SCSI's restart to make progress any more. This patch fixes the race too.
    
    With this patch, we basically recover to previous behaviour (before
    commit 0df21c86bdbf) of handling idle queue when running out of
    resource.
    
    [1] script for test/verify SCSI timeout
    rmmod scsi_debug
    modprobe scsi_debug max_queue=1
    
    DEVICE=`ls -d /sys/bus/pseudo/drivers/scsi_debug/adapter*/host*/target*/*/block/* | head -1 | xargs basename`
    DISK_DIR=`ls -d /sys/block/$DEVICE/device/scsi_disk/*`
    
    echo "using scsi device $DEVICE"
    echo "-1" >/sys/bus/pseudo/drivers/scsi_debug/every_nth
    echo "temporary write through" >$DISK_DIR/cache_type
    echo "128" >/sys/bus/pseudo/drivers/scsi_debug/opts
    echo none > /sys/block/$DEVICE/queue/scheduler
    dd if=/dev/$DEVICE of=/dev/null bs=1M iflag=direct count=1 &
    sleep 5
    echo "0" >/sys/bus/pseudo/drivers/scsi_debug/opts
    wait
    echo "SUCCESS"
    
    Fixes: 0df21c86bdbf ("scsi: implement .get_budget and .put_budget for blk-mq")
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Tested-by: Holger Hoffstätte <holger@applied-asynchrony.com>
    Reviewed-by: Bart Van Assche <bart.vanassche@wdc.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 00742c50cd44..d9ca1dfab154 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1967,6 +1967,8 @@ static bool scsi_mq_get_budget(struct blk_mq_hw_ctx *hctx)
 out_put_device:
 	put_device(&sdev->sdev_gendev);
 out:
+	if (atomic_read(&sdev->device_busy) == 0 && !scsi_device_blocked(sdev))
+		blk_mq_delay_run_hw_queue(hctx, SCSI_QUEUE_DELAY);
 	return false;
 }
 

commit 90addc6b3c9cda0146fbd62a08e234c2b224a80c
Author: Huacai Chen <chenhc@lemote.com>
Date:   Tue Nov 21 14:23:38 2017 +0100

    scsi: use dma_get_cache_alignment() as minimum DMA alignment
    
    In non-coherent DMA mode, kernel uses cache flushing operations to
    maintain I/O coherency, so scsi's block queue should be aligned to the
    value returned by dma_get_cache_alignment().  Otherwise, If a DMA buffer
    and a kernel structure share a same cache line, and if the kernel
    structure has dirty data, cache_invalidate (no writeback) will cause
    data corruption.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Huacai Chen <chenhc@lemote.com>
    [hch: rebased and updated the comment and changelog]
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1cbc497e00bd..00742c50cd44 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2148,11 +2148,13 @@ void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 		q->limits.cluster = 0;
 
 	/*
-	 * set a reasonable default alignment on word boundaries: the
-	 * host and device may alter it using
-	 * blk_queue_update_dma_alignment() later.
+	 * Set a reasonable default alignment:  The larger of 32-byte (dword),
+	 * which is a common minimum for HBAs, and the minimum DMA alignment,
+	 * which is set by the platform.
+	 *
+	 * Devices that require a bigger alignment can increase it later.
 	 */
-	blk_queue_dma_alignment(q, 0x03);
+	blk_queue_dma_alignment(q, max(4, dma_get_cache_alignment()) - 1);
 }
 EXPORT_SYMBOL_GPL(__scsi_init_queue);
 

commit 670ffccb2f9183eb6cb32fe92257aea52b3f8a7d
Merge: 47f521ba1819 341b2aa83368
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 14 16:23:44 2017 -0800

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This is mostly updates of the usual suspects: lpfc, qla2xxx, hisi_sas,
      megaraid_sas, pm80xx, mpt3sas, be2iscsi, hpsa. and a host of minor
      updates.
    
      There's no major behaviour change or additions to the core in all of
      this, so the potential for regressions should be small (biggest
      potential being in the scsi error handler changes)"
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (203 commits)
      scsi: lpfc: Fix hard lock up NMI in els timeout handling.
      scsi: mpt3sas: remove a stray KERN_INFO
      scsi: mpt3sas: cleanup _scsih_pcie_enumeration_event()
      scsi: aacraid: use timespec64 instead of timeval
      scsi: scsi_transport_fc: add 64GBIT and 128GBIT port speed definitions
      scsi: qla2xxx: Suppress a kernel complaint in qla_init_base_qpair()
      scsi: mpt3sas: fix dma_addr_t casts
      scsi: be2iscsi: Use kasprintf
      scsi: storvsc: Avoid excessive host scan on controller change
      scsi: lpfc: fix kzalloc-simple.cocci warnings
      scsi: mpt3sas: Update mpt3sas driver version.
      scsi: mpt3sas: Fix sparse warnings
      scsi: mpt3sas: Fix nvme drives checking for tlr.
      scsi: mpt3sas: NVMe drive support for BTDHMAPPING ioctl command and log info
      scsi: mpt3sas: Add-Task-management-debug-info-for-NVMe-drives.
      scsi: mpt3sas: scan and add nvme device after controller reset
      scsi: mpt3sas: Set NVMe device queue depth as 128
      scsi: mpt3sas: Handle NVMe PCIe device related events generated from firmware.
      scsi: mpt3sas: API's to remove nvme drive from sml
      scsi: mpt3sas: API 's to support NVMe drive addition to SML
      ...

commit e2c5923c349c1738fe8fda980874d93f6fb2e5b6
Merge: abc36be23635 a04b5de5050a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 14 15:32:19 2017 -0800

    Merge branch 'for-4.15/block' of git://git.kernel.dk/linux-block
    
    Pull core block layer updates from Jens Axboe:
     "This is the main pull request for block storage for 4.15-rc1.
    
      Nothing out of the ordinary in here, and no API changes or anything
      like that. Just various new features for drivers, core changes, etc.
      In particular, this pull request contains:
    
       - A patch series from Bart, closing the whole on blk/scsi-mq queue
         quescing.
    
       - A series from Christoph, building towards hidden gendisks (for
         multipath) and ability to move bio chains around.
    
       - NVMe
            - Support for native multipath for NVMe (Christoph).
            - Userspace notifications for AENs (Keith).
            - Command side-effects support (Keith).
            - SGL support (Chaitanya Kulkarni)
            - FC fixes and improvements (James Smart)
            - Lots of fixes and tweaks (Various)
    
       - bcache
            - New maintainer (Michael Lyle)
            - Writeback control improvements (Michael)
            - Various fixes (Coly, Elena, Eric, Liang, et al)
    
       - lightnvm updates, mostly centered around the pblk interface
         (Javier, Hans, and Rakesh).
    
       - Removal of unused bio/bvec kmap atomic interfaces (me, Christoph)
    
       - Writeback series that fix the much discussed hundreds of millions
         of sync-all units. This goes all the way, as discussed previously
         (me).
    
       - Fix for missing wakeup on writeback timer adjustments (Yafang
         Shao).
    
       - Fix laptop mode on blk-mq (me).
    
       - {mq,name} tupple lookup for IO schedulers, allowing us to have
         alias names. This means you can use 'deadline' on both !mq and on
         mq (where it's called mq-deadline). (me).
    
       - blktrace race fix, oopsing on sg load (me).
    
       - blk-mq optimizations (me).
    
       - Obscure waitqueue race fix for kyber (Omar).
    
       - NBD fixes (Josef).
    
       - Disable writeback throttling by default on bfq, like we do on cfq
         (Luca Miccio).
    
       - Series from Ming that enable us to treat flush requests on blk-mq
         like any other request. This is a really nice cleanup.
    
       - Series from Ming that improves merging on blk-mq with schedulers,
         getting us closer to flipping the switch on scsi-mq again.
    
       - BFQ updates (Paolo).
    
       - blk-mq atomic flags memory ordering fixes (Peter Z).
    
       - Loop cgroup support (Shaohua).
    
       - Lots of minor fixes from lots of different folks, both for core and
         driver code"
    
    * 'for-4.15/block' of git://git.kernel.dk/linux-block: (294 commits)
      nvme: fix visibility of "uuid" ns attribute
      blk-mq: fixup some comment typos and lengths
      ide: ide-atapi: fix compile error with defining macro DEBUG
      blk-mq: improve tag waiting setup for non-shared tags
      brd: remove unused brd_mutex
      blk-mq: only run the hardware queue if IO is pending
      block: avoid null pointer dereference on null disk
      fs: guard_bio_eod() needs to consider partitions
      xtensa/simdisk: fix compile error
      nvme: expose subsys attribute to sysfs
      nvme: create 'slaves' and 'holders' entries for hidden controllers
      block: create 'slaves' and 'holders' entries for hidden gendisks
      nvme: also expose the namespace identification sysfs files for mpath nodes
      nvme: implement multipath access to nvme subsystems
      nvme: track shared namespaces
      nvme: introduce a nvme_ns_ids structure
      nvme: track subsystems
      block, nvme: Introduce blk_mq_req_flags_t
      block, scsi: Make SCSI quiesce and resume work reliably
      block: Add the QUEUE_FLAG_PREEMPT_ONLY request queue flag
      ...

commit 3a0a529971ec4e2d933e9c7798db101dfb6b1aec
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Thu Nov 9 10:49:58 2017 -0800

    block, scsi: Make SCSI quiesce and resume work reliably
    
    The contexts from which a SCSI device can be quiesced or resumed are:
    * Writing into /sys/class/scsi_device/*/device/state.
    * SCSI parallel (SPI) domain validation.
    * The SCSI device power management methods. See also scsi_bus_pm_ops.
    
    It is essential during suspend and resume that neither the filesystem
    state nor the filesystem metadata in RAM changes. This is why while
    the hibernation image is being written or restored that SCSI devices
    are quiesced. The SCSI core quiesces devices through scsi_device_quiesce()
    and scsi_device_resume(). In the SDEV_QUIESCE state execution of
    non-preempt requests is deferred. This is realized by returning
    BLKPREP_DEFER from inside scsi_prep_state_check() for quiesced SCSI
    devices. Avoid that a full queue prevents power management requests
    to be submitted by deferring allocation of non-preempt requests for
    devices in the quiesced state. This patch has been tested by running
    the following commands and by verifying that after each resume the
    fio job was still running:
    
    for ((i=0; i<10; i++)); do
      (
        cd /sys/block/md0/md &&
        while true; do
          [ "$(<sync_action)" = "idle" ] && echo check > sync_action
          sleep 1
        done
      ) &
      pids=($!)
      for d in /sys/class/block/sd*[a-z]; do
        bdev=${d#/sys/class/block/}
        hcil=$(readlink "$d/device")
        hcil=${hcil#../../../}
        echo 4 > "$d/queue/nr_requests"
        echo 1 > "/sys/class/scsi_device/$hcil/device/queue_depth"
        fio --name="$bdev" --filename="/dev/$bdev" --buffered=0 --bs=512 \
          --rw=randread --ioengine=libaio --numjobs=4 --iodepth=16       \
          --iodepth_batch=1 --thread --loops=$((2**31)) &
        pids+=($!)
      done
      sleep 1
      echo "$(date) Hibernating ..." >>hibernate-test-log.txt
      systemctl hibernate
      sleep 10
      kill "${pids[@]}"
      echo idle > /sys/block/md0/md/sync_action
      wait
      echo "$(date) Done." >>hibernate-test-log.txt
    done
    
    Reported-by: Oleksandr Natalenko <oleksandr@natalenko.name>
    References: "I/O hangs after resuming from suspend-to-ram" (https://marc.info/?l=linux-block&m=150340235201348).
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Tested-by: Martin Steigerwald <martin@lichtvoll.de>
    Tested-by: Oleksandr Natalenko <oleksandr@natalenko.name>
    Cc: Martin K. Petersen <martin.petersen@oracle.com>
    Cc: Ming Lei <ming.lei@redhat.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index eb129dfc2ebe..f907e2f8c1dd 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2947,21 +2947,37 @@ static void scsi_wait_for_queuecommand(struct scsi_device *sdev)
 int
 scsi_device_quiesce(struct scsi_device *sdev)
 {
+	struct request_queue *q = sdev->request_queue;
 	int err;
 
+	/*
+	 * It is allowed to call scsi_device_quiesce() multiple times from
+	 * the same context but concurrent scsi_device_quiesce() calls are
+	 * not allowed.
+	 */
+	WARN_ON_ONCE(sdev->quiesced_by && sdev->quiesced_by != current);
+
+	blk_set_preempt_only(q);
+
+	blk_mq_freeze_queue(q);
+	/*
+	 * Ensure that the effect of blk_set_preempt_only() will be visible
+	 * for percpu_ref_tryget() callers that occur after the queue
+	 * unfreeze even if the queue was already frozen before this function
+	 * was called. See also https://lwn.net/Articles/573497/.
+	 */
+	synchronize_rcu();
+	blk_mq_unfreeze_queue(q);
+
 	mutex_lock(&sdev->state_mutex);
 	err = scsi_device_set_state(sdev, SDEV_QUIESCE);
+	if (err == 0)
+		sdev->quiesced_by = current;
+	else
+		blk_clear_preempt_only(q);
 	mutex_unlock(&sdev->state_mutex);
 
-	if (err)
-		return err;
-
-	scsi_run_queue(sdev->request_queue);
-	while (atomic_read(&sdev->device_busy)) {
-		msleep_interruptible(200);
-		scsi_run_queue(sdev->request_queue);
-	}
-	return 0;
+	return err;
 }
 EXPORT_SYMBOL(scsi_device_quiesce);
 
@@ -2981,9 +2997,11 @@ void scsi_device_resume(struct scsi_device *sdev)
 	 * device deleted during suspend)
 	 */
 	mutex_lock(&sdev->state_mutex);
-	if (sdev->sdev_state == SDEV_QUIESCE &&
-	    scsi_device_set_state(sdev, SDEV_RUNNING) == 0)
-		scsi_run_queue(sdev->request_queue);
+	WARN_ON_ONCE(!sdev->quiesced_by);
+	sdev->quiesced_by = NULL;
+	blk_clear_preempt_only(sdev->request_queue);
+	if (sdev->sdev_state == SDEV_QUIESCE)
+		scsi_device_set_state(sdev, SDEV_RUNNING);
 	mutex_unlock(&sdev->state_mutex);
 }
 EXPORT_SYMBOL(scsi_device_resume);

commit 039c635f4e666b647df2100038de276a83fb3fca
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Thu Nov 9 10:49:56 2017 -0800

    ide, scsi: Tell the block layer at request allocation time about preempt requests
    
    Convert blk_get_request(q, op, __GFP_RECLAIM) into
    blk_get_request_flags(q, op, BLK_MQ_PREEMPT). This patch does not
    change any functionality.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Tested-by: Martin Steigerwald <martin@lichtvoll.de>
    Acked-by: David S. Miller <davem@davemloft.net> [ for IDE ]
    Acked-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Tested-by: Oleksandr Natalenko <oleksandr@natalenko.name>
    Cc: Ming Lei <ming.lei@redhat.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 286ea983c9e3..eb129dfc2ebe 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -252,9 +252,9 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	struct scsi_request *rq;
 	int ret = DRIVER_ERROR << 24;
 
-	req = blk_get_request(sdev->request_queue,
+	req = blk_get_request_flags(sdev->request_queue,
 			data_direction == DMA_TO_DEVICE ?
-			REQ_OP_SCSI_OUT : REQ_OP_SCSI_IN, __GFP_RECLAIM);
+			REQ_OP_SCSI_OUT : REQ_OP_SCSI_IN, BLK_MQ_REQ_PREEMPT);
 	if (IS_ERR(req))
 		return ret;
 	rq = scsi_req(req);
@@ -268,7 +268,7 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	rq->retries = retries;
 	req->timeout = timeout;
 	req->cmd_flags |= flags;
-	req->rq_flags |= rq_flags | RQF_QUIET | RQF_PREEMPT;
+	req->rq_flags |= rq_flags | RQF_QUIET;
 
 	/*
 	 * head injection *required* here otherwise quiesce won't work

commit a817e73fe693f0718b6210f4b959478877fb2e2f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 7 09:04:32 2017 -0800

    Revert "scsi: make 'state' device attribute pollable"
    
    This reverts commit 8a97712e5314aefe16b3ffb4583a34deaa49de04.
    
    This commit added a call to sysfs_notify() from within
    scsi_device_set_state(), which in turn turns out to make libata very
    unhappy, because ata_eh_detach_dev() does
    
            spin_lock_irqsave(ap->lock, flags);
            ..
            if (ata_scsi_offline_dev(dev)) {
                    dev->flags |= ATA_DFLAG_DETACHED;
                    ap->pflags |= ATA_PFLAG_SCSI_HOTPLUG;
            }
    
    and ata_scsi_offline_dev() then does that scsi_device_set_state() to set
    it offline.
    
    So now we called sysfs_notify() from within a spinlocked region, which
    really doesn't work.  The 0day robot reported this as:
    
       BUG: sleeping function called from invalid context at kernel/locking/mutex.c:238
    
    because sysfs_notify() ends up calling kernfs_find_and_get_ns() which
    then does mutex_lock(&kernfs_mutex)..
    
    The pollability of the device state isn't critical, so revert this all
    for now, and maybe we'll do it differently in the future.
    
    Reported-by: Fengguang Wu <fengguang.wu@intel.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Acked-by: Martin K. Petersen <martin.petersen@oracle.com>
    Acked-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ad3ea24f0885..bcc1694cebcd 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2685,7 +2685,6 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 
 	}
 	sdev->sdev_state = state;
-	sysfs_notify(&sdev->sdev_gendev.kobj, NULL, "state");
 	return 0;
 
  illegal:
@@ -3109,7 +3108,6 @@ int scsi_internal_device_unblock_nowait(struct scsi_device *sdev,
 	case SDEV_BLOCK:
 	case SDEV_TRANSPORT_OFFLINE:
 		sdev->sdev_state = new_state;
-		sysfs_notify(&sdev->sdev_gendev.kobj, NULL, "state");
 		break;
 	case SDEV_CREATED_BLOCK:
 		if (new_state == SDEV_TRANSPORT_OFFLINE ||
@@ -3117,7 +3115,6 @@ int scsi_internal_device_unblock_nowait(struct scsi_device *sdev,
 			sdev->sdev_state = new_state;
 		else
 			sdev->sdev_state = SDEV_CREATED;
-		sysfs_notify(&sdev->sdev_gendev.kobj, NULL, "state");
 		break;
 	case SDEV_CANCEL:
 	case SDEV_OFFLINE:

commit 88022d7201e96b43f1754b0358fc6bcd8dbdcde1
Author: Ming Lei <ming.lei@redhat.com>
Date:   Sun Nov 5 02:21:12 2017 +0800

    blk-mq: don't handle failure in .get_budget
    
    It is enough to just check if we can get the budget via .get_budget().
    And we don't need to deal with device state change in .get_budget().
    
    For SCSI, one issue to be fixed is that we have to call
    scsi_mq_uninit_cmd() to free allocated ressources if SCSI device fails
    to handle the request. And it isn't enough to simply call
    blk_mq_end_request() to do that if this request is marked as
    RQF_DONTPREP.
    
    Fixes: 0df21c86bdbf(scsi: implement .get_budget and .put_budget for blk-mq)
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 22a7e4c47207..286ea983c9e3 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1955,27 +1955,22 @@ static void scsi_mq_put_budget(struct blk_mq_hw_ctx *hctx)
 	put_device(&sdev->sdev_gendev);
 }
 
-static blk_status_t scsi_mq_get_budget(struct blk_mq_hw_ctx *hctx)
+static bool scsi_mq_get_budget(struct blk_mq_hw_ctx *hctx)
 {
 	struct request_queue *q = hctx->queue;
 	struct scsi_device *sdev = q->queuedata;
-	blk_status_t ret;
-
-	ret = prep_to_mq(scsi_prep_state_check(sdev, NULL));
-	if (ret == BLK_STS_RESOURCE || ret != BLK_STS_OK)
-		return ret;
 
 	if (!get_device(&sdev->sdev_gendev))
 		goto out;
 	if (!scsi_dev_queue_ready(q, sdev))
 		goto out_put_device;
 
-	return BLK_STS_OK;
+	return true;
 
 out_put_device:
 	put_device(&sdev->sdev_gendev);
 out:
-	return BLK_STS_RESOURCE;
+	return false;
 }
 
 static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,

commit 826a70a08b1210bbfdbda812ab43eb986e25b5c2
Author: Ming Lei <ming.lei@redhat.com>
Date:   Sat Nov 4 09:55:34 2017 +0800

    SCSI: don't get target/host busy_count in scsi_mq_get_budget()
    
    It is very expensive to atomic_inc/atomic_dec the host wide counter of
    host->busy_count, and it should have been avoided via blk-mq's mechanism
    of getting driver tag, which uses the more efficient way of sbitmap queue.
    
    Also we don't check atomic_read(&sdev->device_busy) in scsi_mq_get_budget()
    and don't run queue if the counter becomes zero, so IO hang may be caused
    if all requests are completed just before the current SCSI device
    is added to shost->starved_list.
    
    Fixes: 0df21c86bdbf(scsi: implement .get_budget and .put_budget for blk-mq)
    Reported-by: Bart Van Assche <bart.vanassche@wdc.com>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 6f10afaca25b..22a7e4c47207 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1950,11 +1950,7 @@ static void scsi_mq_put_budget(struct blk_mq_hw_ctx *hctx)
 {
 	struct request_queue *q = hctx->queue;
 	struct scsi_device *sdev = q->queuedata;
-	struct Scsi_Host *shost = sdev->host;
 
-	atomic_dec(&shost->host_busy);
-	if (scsi_target(sdev)->can_queue > 0)
-		atomic_dec(&scsi_target(sdev)->target_busy);
 	atomic_dec(&sdev->device_busy);
 	put_device(&sdev->sdev_gendev);
 }
@@ -1963,7 +1959,6 @@ static blk_status_t scsi_mq_get_budget(struct blk_mq_hw_ctx *hctx)
 {
 	struct request_queue *q = hctx->queue;
 	struct scsi_device *sdev = q->queuedata;
-	struct Scsi_Host *shost = sdev->host;
 	blk_status_t ret;
 
 	ret = prep_to_mq(scsi_prep_state_check(sdev, NULL));
@@ -1974,18 +1969,9 @@ static blk_status_t scsi_mq_get_budget(struct blk_mq_hw_ctx *hctx)
 		goto out;
 	if (!scsi_dev_queue_ready(q, sdev))
 		goto out_put_device;
-	if (!scsi_target_queue_ready(shost, sdev))
-		goto out_dec_device_busy;
-	if (!scsi_host_queue_ready(q, shost, sdev))
-		goto out_dec_target_busy;
 
 	return BLK_STS_OK;
 
-out_dec_target_busy:
-	if (scsi_target(sdev)->can_queue > 0)
-		atomic_dec(&scsi_target(sdev)->target_busy);
-out_dec_device_busy:
-	atomic_dec(&sdev->device_busy);
 out_put_device:
 	put_device(&sdev->sdev_gendev);
 out:
@@ -1998,6 +1984,7 @@ static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	struct request *req = bd->rq;
 	struct request_queue *q = req->q;
 	struct scsi_device *sdev = q->queuedata;
+	struct Scsi_Host *shost = sdev->host;
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
 	blk_status_t ret;
 	int reason;
@@ -2007,10 +1994,15 @@ static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 		goto out_put_budget;
 
 	ret = BLK_STS_RESOURCE;
+	if (!scsi_target_queue_ready(shost, sdev))
+		goto out_put_budget;
+	if (!scsi_host_queue_ready(q, shost, sdev))
+		goto out_dec_target_busy;
+
 	if (!(req->rq_flags & RQF_DONTPREP)) {
 		ret = prep_to_mq(scsi_mq_prep_fn(req));
 		if (ret != BLK_STS_OK)
-			goto out_put_budget;
+			goto out_dec_host_busy;
 		req->rq_flags |= RQF_DONTPREP;
 	} else {
 		blk_mq_start_request(req);
@@ -2028,11 +2020,16 @@ static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	if (reason) {
 		scsi_set_blocked(cmd, reason);
 		ret = BLK_STS_RESOURCE;
-		goto out_put_budget;
+		goto out_dec_host_busy;
 	}
 
 	return BLK_STS_OK;
 
+out_dec_host_busy:
+       atomic_dec(&shost->host_busy);
+out_dec_target_busy:
+	if (scsi_target(sdev)->can_queue > 0)
+		atomic_dec(&scsi_target(sdev)->target_busy);
 out_put_budget:
 	scsi_mq_put_budget(hctx);
 	switch (ret) {

commit 0df21c86bdbfd17dec9ab898312af9bfb74d5d86
Author: Ming Lei <ming.lei@redhat.com>
Date:   Sat Oct 14 17:22:32 2017 +0800

    scsi: implement .get_budget and .put_budget for blk-mq
    
    We need to tell blk-mq to reserve resources before queuing one request,
    so implement these two callbacks. Then blk-mq can avoid to dequeue
    request too early, and IO merging can be improved a lot.
    
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d159bb085714..6f10afaca25b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1946,25 +1946,32 @@ static void scsi_mq_done(struct scsi_cmnd *cmd)
 	blk_mq_complete_request(cmd->request);
 }
 
-static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
-			 const struct blk_mq_queue_data *bd)
+static void scsi_mq_put_budget(struct blk_mq_hw_ctx *hctx)
 {
-	struct request *req = bd->rq;
-	struct request_queue *q = req->q;
+	struct request_queue *q = hctx->queue;
+	struct scsi_device *sdev = q->queuedata;
+	struct Scsi_Host *shost = sdev->host;
+
+	atomic_dec(&shost->host_busy);
+	if (scsi_target(sdev)->can_queue > 0)
+		atomic_dec(&scsi_target(sdev)->target_busy);
+	atomic_dec(&sdev->device_busy);
+	put_device(&sdev->sdev_gendev);
+}
+
+static blk_status_t scsi_mq_get_budget(struct blk_mq_hw_ctx *hctx)
+{
+	struct request_queue *q = hctx->queue;
 	struct scsi_device *sdev = q->queuedata;
 	struct Scsi_Host *shost = sdev->host;
-	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
 	blk_status_t ret;
-	int reason;
 
-	ret = prep_to_mq(scsi_prep_state_check(sdev, req));
-	if (ret != BLK_STS_OK)
-		goto out;
+	ret = prep_to_mq(scsi_prep_state_check(sdev, NULL));
+	if (ret == BLK_STS_RESOURCE || ret != BLK_STS_OK)
+		return ret;
 
-	ret = BLK_STS_RESOURCE;
 	if (!get_device(&sdev->sdev_gendev))
 		goto out;
-
 	if (!scsi_dev_queue_ready(q, sdev))
 		goto out_put_device;
 	if (!scsi_target_queue_ready(shost, sdev))
@@ -1972,10 +1979,38 @@ static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	if (!scsi_host_queue_ready(q, shost, sdev))
 		goto out_dec_target_busy;
 
+	return BLK_STS_OK;
+
+out_dec_target_busy:
+	if (scsi_target(sdev)->can_queue > 0)
+		atomic_dec(&scsi_target(sdev)->target_busy);
+out_dec_device_busy:
+	atomic_dec(&sdev->device_busy);
+out_put_device:
+	put_device(&sdev->sdev_gendev);
+out:
+	return BLK_STS_RESOURCE;
+}
+
+static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
+			 const struct blk_mq_queue_data *bd)
+{
+	struct request *req = bd->rq;
+	struct request_queue *q = req->q;
+	struct scsi_device *sdev = q->queuedata;
+	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
+	blk_status_t ret;
+	int reason;
+
+	ret = prep_to_mq(scsi_prep_state_check(sdev, req));
+	if (ret != BLK_STS_OK)
+		goto out_put_budget;
+
+	ret = BLK_STS_RESOURCE;
 	if (!(req->rq_flags & RQF_DONTPREP)) {
 		ret = prep_to_mq(scsi_mq_prep_fn(req));
 		if (ret != BLK_STS_OK)
-			goto out_dec_host_busy;
+			goto out_put_budget;
 		req->rq_flags |= RQF_DONTPREP;
 	} else {
 		blk_mq_start_request(req);
@@ -1993,21 +2028,13 @@ static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	if (reason) {
 		scsi_set_blocked(cmd, reason);
 		ret = BLK_STS_RESOURCE;
-		goto out_dec_host_busy;
+		goto out_put_budget;
 	}
 
 	return BLK_STS_OK;
 
-out_dec_host_busy:
-	atomic_dec(&shost->host_busy);
-out_dec_target_busy:
-	if (scsi_target(sdev)->can_queue > 0)
-		atomic_dec(&scsi_target(sdev)->target_busy);
-out_dec_device_busy:
-	atomic_dec(&sdev->device_busy);
-out_put_device:
-	put_device(&sdev->sdev_gendev);
-out:
+out_put_budget:
+	scsi_mq_put_budget(hctx);
 	switch (ret) {
 	case BLK_STS_OK:
 		break;
@@ -2211,6 +2238,8 @@ struct request_queue *scsi_old_alloc_queue(struct scsi_device *sdev)
 }
 
 static const struct blk_mq_ops scsi_mq_ops = {
+	.get_budget	= scsi_mq_get_budget,
+	.put_budget	= scsi_mq_put_budget,
 	.queue_rq	= scsi_queue_rq,
 	.complete	= scsi_softirq_done,
 	.timeout	= scsi_timeout,

commit aeec77629a4ac6f8c248f3a82e80d4170a881f22
Author: Ming Lei <ming.lei@redhat.com>
Date:   Sat Oct 14 17:22:31 2017 +0800

    scsi: allow passing in null rq to scsi_prep_state_check()
    
    In the following patch, we will implement scsi_get_budget()
    which need to call scsi_prep_state_check() when rq isn't
    dequeued yet.
    
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9cf6a80fe297..d159bb085714 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1301,7 +1301,7 @@ scsi_prep_state_check(struct scsi_device *sdev, struct request *req)
 			/*
 			 * If the devices is blocked we defer normal commands.
 			 */
-			if (!(req->rq_flags & RQF_PREEMPT))
+			if (req && !(req->rq_flags & RQF_PREEMPT))
 				ret = BLKPREP_DEFER;
 			break;
 		default:
@@ -1310,7 +1310,7 @@ scsi_prep_state_check(struct scsi_device *sdev, struct request *req)
 			 * special commands.  In particular any user initiated
 			 * command is not allowed.
 			 */
-			if (!(req->rq_flags & RQF_PREEMPT))
+			if (req && !(req->rq_flags & RQF_PREEMPT))
 				ret = BLKPREP_KILL;
 			break;
 		}

commit 8fe8ffb12c81b36877984274db184953c337db73
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Fri Oct 20 11:46:45 2017 -0700

    scsi: Suppress a kernel warning in case the prep function returns BLKPREP_DEFER
    
    The legacy block layer handles requests as follows:
    - If the prep function returns BLKPREP_OK, let blk_peek_request()
      return the pointer to that request.
    - If the prep function returns BLKPREP_DEFER, keep the RQF_STARTED
      flag and retry calling the prep function later.
    - If the prep function returns BLKPREP_KILL or BLKPREP_INVALID, end
      the request.
    
    In none of these cases it is correct to clear the SCMD_INITIALIZED
    flag from inside scsi_prep_fn(). Since scsi_prep_fn() already
    guarantees that scsi_init_command() will be called once even if
    scsi_prep_fn() is called multiple times, remove the code that clears
    SCMD_INITIALIZED from scsi_prep_fn().
    
    The scsi-mq code handles requests as follows:
    - If scsi_mq_prep_fn() returns BLKPREP_OK, set the RQF_DONTPREP flag
      and submit the request to the SCSI LLD.
    - If scsi_mq_prep_fn() returns BLKPREP_DEFER, call
      blk_mq_delay_run_hw_queue() and return BLK_STS_RESOURCE.
    - If the prep function returns BLKPREP_KILL or BLKPREP_INVALID, call
      scsi_mq_uninit_cmd() and let the blk-mq core end the request.
    
    In none of these cases scsi_mq_prep_fn() should clear the
    SCMD_INITIALIZED flag. Hence remove the code from scsi_mq_prep_fn()
    function that clears that flag.
    
    This patch avoids that the following warning is triggered when using
    the legacy block layer:
    
    ------------[ cut here ]------------
    WARNING: CPU: 1 PID: 4198 at drivers/scsi/scsi_lib.c:654 scsi_end_request+0x1de/0x220
    CPU: 1 PID: 4198 Comm: mkfs.f2fs Not tainted 4.14.0-rc5+ #1
    task: ffff91c147a4b800 task.stack: ffffb282c37b8000
    RIP: 0010:scsi_end_request+0x1de/0x220
    Call Trace:
    <IRQ>
    scsi_io_completion+0x204/0x5e0
    scsi_finish_command+0xce/0xe0
    scsi_softirq_done+0x126/0x130
    blk_done_softirq+0x6e/0x80
    __do_softirq+0xcf/0x2a8
    irq_exit+0xab/0xb0
    do_IRQ+0x7b/0xc0
    common_interrupt+0x90/0x90
    </IRQ>
    RIP: 0010:_raw_spin_unlock_irqrestore+0x9/0x10
    __test_set_page_writeback+0xc7/0x2c0
    __block_write_full_page+0x158/0x3b0
    block_write_full_page+0xc4/0xd0
    blkdev_writepage+0x13/0x20
    __writepage+0x12/0x40
    write_cache_pages+0x204/0x500
    generic_writepages+0x48/0x70
    blkdev_writepages+0x9/0x10
    do_writepages+0x34/0xc0
    __filemap_fdatawrite_range+0x6c/0x90
    file_write_and_wait_range+0x31/0x90
    blkdev_fsync+0x16/0x40
    vfs_fsync_range+0x44/0xa0
    do_fsync+0x38/0x60
    SyS_fsync+0xb/0x10
    entry_SYSCALL_64_fastpath+0x13/0x94
    ---[ end trace 86e8ef85a4a6c1d1 ]---
    
    Fixes: commit 64104f703212 ("scsi: Call scsi_initialize_rq() for filesystem requests")
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: Damien Le Moal <damien.lemoal@wdc.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Damien Le Moal <damien.lemoal@wdc.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9cf6a80fe297..ad3ea24f0885 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1379,8 +1379,6 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 
 	ret = scsi_setup_cmnd(sdev, req);
 out:
-	if (ret != BLKPREP_OK)
-		cmd->flags &= ~SCMD_INITIALIZED;
 	return scsi_prep_return(q, req, ret);
 }
 
@@ -1900,7 +1898,6 @@ static int scsi_mq_prep_fn(struct request *req)
 	struct scsi_device *sdev = req->q->queuedata;
 	struct Scsi_Host *shost = sdev->host;
 	struct scatterlist *sg;
-	int ret;
 
 	scsi_init_command(sdev, cmd);
 
@@ -1934,10 +1931,7 @@ static int scsi_mq_prep_fn(struct request *req)
 
 	blk_mq_start_request(req);
 
-	ret = scsi_setup_cmnd(sdev, req);
-	if (ret != BLK_STS_OK)
-		cmd->flags &= ~SCMD_INITIALIZED;
-	return ret;
+	return scsi_setup_cmnd(sdev, req);
 }
 
 static void scsi_mq_done(struct scsi_cmnd *cmd)

commit cf3431bba1df3b4f25b04900cb804d7e6e5eb6a9
Author: Hannes Reinecke <hare@suse.de>
Date:   Tue Oct 17 09:11:24 2017 +0200

    scsi: scsi_error: Handle power-on reset unit attention
    
    As per SAM there is a status precedence, with any sense code 29/XX
    taking second place just after an ACA ACTIVE status.  Additionally, each
    target might prefer to not queue any unit attention conditions, but just
    report one.  Due to the above, this will be that one with the highest
    precedence.  This results in the sense code 29/XX effectively
    overwriting any other unit attention.  Hence we should report the
    power-on reset to userland so that it can take appropriate action.
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c72b97a74906..e5fcfa867045 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2743,6 +2743,9 @@ static void scsi_evt_emit(struct scsi_device *sdev, struct scsi_event *evt)
 	case SDEV_EVT_ALUA_STATE_CHANGE_REPORTED:
 		envp[idx++] = "SDEV_UA=ASYMMETRIC_ACCESS_STATE_CHANGED";
 		break;
+	case SDEV_EVT_POWER_ON_RESET_OCCURRED:
+		envp[idx++] = "SDEV_UA=POWER_ON_RESET_OCCURRED";
+		break;
 	default:
 		/* do nothing */
 		break;
@@ -2847,6 +2850,7 @@ struct scsi_event *sdev_evt_alloc(enum scsi_device_event evt_type,
 	case SDEV_EVT_MODE_PARAMETER_CHANGE_REPORTED:
 	case SDEV_EVT_LUN_CHANGE_REPORTED:
 	case SDEV_EVT_ALUA_STATE_CHANGE_REPORTED:
+	case SDEV_EVT_POWER_ON_RESET_OCCURRED:
 	default:
 		/* do nothing */
 		break;

commit e98f42bcad202a7e89be37be556383b5de0a65d5
Author: Damien Le Moal <damien.lemoal@wdc.com>
Date:   Wed Oct 11 05:54:22 2017 +0900

    scsi: sd_zbc: Fix comments and indentation
    
    Fix comments style (use kernel-doc style) and content to clarify some
    functions. Also fix some functions signature indentation and remove a
    useless blank line in sd_zbc_read_zones().
    
    No functional change is introduced by this patch.
    
    Signed-off-by: Damien Le Moal <damien.lemoal@wdc.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9cf6a80fe297..c72b97a74906 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1752,7 +1752,10 @@ static void scsi_done(struct scsi_cmnd *cmd)
  *
  * Returns:     Nothing
  *
- * Lock status: IO request lock assumed to be held when called.
+ * Lock status: request queue lock assumed to be held when called.
+ *
+ * Note: See sd_zbc.c sd_zbc_write_lock_zone() for write order
+ * protection for ZBC disks.
  */
 static void scsi_request_fn(struct request_queue *q)
 	__releases(q->queue_lock)

commit a45a1f3614182267803baadba657b59e2ddc0545
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Wed Aug 30 16:58:42 2017 -0700

    scsi: scsi-mq: Always unprepare before requeuing a request
    
    One of the two scsi-mq functions that requeue a request unprepares a
    request before requeueing (scsi_io_completion()) but the other function
    not (__scsi_queue_insert()). Make sure that a request is unprepared
    before requeuing it.
    
    Fixes: commit d285203cf647 ("scsi: add support for a blk-mq based I/O path.")
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Damien Le Moal <damien.lemoal@wdc.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 6085377643ae..9cf6a80fe297 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -44,6 +44,8 @@ static struct kmem_cache *scsi_sense_cache;
 static struct kmem_cache *scsi_sense_isadma_cache;
 static DEFINE_MUTEX(scsi_sense_cache_mutex);
 
+static void scsi_mq_uninit_cmd(struct scsi_cmnd *cmd);
+
 static inline struct kmem_cache *
 scsi_select_sense_cache(bool unchecked_isa_dma)
 {
@@ -140,6 +142,12 @@ static void scsi_mq_requeue_cmd(struct scsi_cmnd *cmd)
 {
 	struct scsi_device *sdev = cmd->device;
 
+	if (cmd->request->rq_flags & RQF_DONTPREP) {
+		cmd->request->rq_flags &= ~RQF_DONTPREP;
+		scsi_mq_uninit_cmd(cmd);
+	} else {
+		WARN_ON_ONCE(true);
+	}
 	blk_mq_requeue_request(cmd->request, true);
 	put_device(&sdev->sdev_gendev);
 }
@@ -982,8 +990,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		 * A new command will be prepared and issued.
 		 */
 		if (q->mq_ops) {
-			cmd->request->rq_flags &= ~RQF_DONTPREP;
-			scsi_mq_uninit_cmd(cmd);
 			scsi_mq_requeue_cmd(cmd);
 		} else {
 			scsi_release_buffers(cmd);

commit 832889f5ed45ec90c76f6eb97e64baf845929007
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Wed Aug 30 16:58:40 2017 -0700

    scsi: Improve requeuing behavior
    
    Requests are unprepared and reprepared when being requeued.  Avoid that
    requeuing resets .jiffies_at_alloc and .retries by initializing these
    two member variables from inside scsi_initialize_rq() and by preserving
    both member variables when preparing a request. This patch affects the
    requeuing behavior of both the legacy scsi and the scsi-mq code paths.
    
    Reported-by: Brian King <brking@linux.vnet.ibm.com>
    References: https://lkml.org/lkml/2017/8/18/923 ("Re: [BUG][bisected 270065e] linux-next fails to boot on powerpc")
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Brian King <brking@linux.vnet.ibm.com>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4bfe0df35823..6085377643ae 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1112,9 +1112,13 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 EXPORT_SYMBOL(scsi_init_io);
 
 /**
- * scsi_initialize_rq - initialize struct scsi_cmnd.req
+ * scsi_initialize_rq - initialize struct scsi_cmnd partially
  * @rq: Request associated with the SCSI command to be initialized.
  *
+ * This function initializes the members of struct scsi_cmnd that must be
+ * initialized before request processing starts and that won't be
+ * reinitialized if a SCSI command is requeued.
+ *
  * Called from inside blk_get_request() for pass-through requests and from
  * inside scsi_init_command() for filesystem requests.
  */
@@ -1123,6 +1127,8 @@ void scsi_initialize_rq(struct request *rq)
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
 
 	scsi_req_init(&cmd->req);
+	cmd->jiffies_at_alloc = jiffies;
+	cmd->retries = 0;
 }
 EXPORT_SYMBOL(scsi_initialize_rq);
 
@@ -1162,12 +1168,16 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 	void *prot = cmd->prot_sdb;
 	struct request *rq = blk_mq_rq_from_pdu(cmd);
 	unsigned int flags = cmd->flags & SCMD_PRESERVED_FLAGS;
+	unsigned long jiffies_at_alloc;
+	int retries;
 
 	if (!blk_rq_is_scsi(rq) && !(flags & SCMD_INITIALIZED)) {
 		flags |= SCMD_INITIALIZED;
 		scsi_initialize_rq(rq);
 	}
 
+	jiffies_at_alloc = cmd->jiffies_at_alloc;
+	retries = cmd->retries;
 	/* zero out the cmd, except for the embedded scsi_request */
 	memset((char *)cmd + sizeof(cmd->req), 0,
 		sizeof(*cmd) - sizeof(cmd->req) + dev->host->hostt->cmd_size);
@@ -1177,7 +1187,8 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 	cmd->prot_sdb = prot;
 	cmd->flags = flags;
 	INIT_DELAYED_WORK(&cmd->abort_work, scmd_eh_abort_handler);
-	cmd->jiffies_at_alloc = jiffies;
+	cmd->jiffies_at_alloc = jiffies_at_alloc;
+	cmd->retries = retries;
 
 	scsi_add_cmd_to_list(cmd);
 }

commit 64104f703212ff50e855bb2e2fa80d71db62c521
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Wed Aug 30 16:58:39 2017 -0700

    scsi: Call scsi_initialize_rq() for filesystem requests
    
    If a pass-through request is submitted then blk_get_request()
    initializes that request by calling scsi_initialize_rq(). Also call this
    function for filesystem requests. Introduce CMD_INITIALIZED to keep
    track of whether or not a request has already been initialized.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Brian King <brking@linux.vnet.ibm.com>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 938a7e398cd4..4bfe0df35823 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -642,6 +642,11 @@ static bool scsi_end_request(struct request *req, blk_status_t error,
 	if (blk_queue_add_random(q))
 		add_disk_randomness(req->rq_disk);
 
+	if (!blk_rq_is_scsi(req)) {
+		WARN_ON_ONCE(!(cmd->flags & SCMD_INITIALIZED));
+		cmd->flags &= ~SCMD_INITIALIZED;
+	}
+
 	if (req->mq_ctx) {
 		/*
 		 * In the MQ case the command gets freed by __blk_mq_end_request,
@@ -1110,7 +1115,8 @@ EXPORT_SYMBOL(scsi_init_io);
  * scsi_initialize_rq - initialize struct scsi_cmnd.req
  * @rq: Request associated with the SCSI command to be initialized.
  *
- * Called from inside blk_get_request().
+ * Called from inside blk_get_request() for pass-through requests and from
+ * inside scsi_init_command() for filesystem requests.
  */
 void scsi_initialize_rq(struct request *rq)
 {
@@ -1154,7 +1160,13 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 {
 	void *buf = cmd->sense_buffer;
 	void *prot = cmd->prot_sdb;
-	unsigned int unchecked_isa_dma = cmd->flags & SCMD_UNCHECKED_ISA_DMA;
+	struct request *rq = blk_mq_rq_from_pdu(cmd);
+	unsigned int flags = cmd->flags & SCMD_PRESERVED_FLAGS;
+
+	if (!blk_rq_is_scsi(rq) && !(flags & SCMD_INITIALIZED)) {
+		flags |= SCMD_INITIALIZED;
+		scsi_initialize_rq(rq);
+	}
 
 	/* zero out the cmd, except for the embedded scsi_request */
 	memset((char *)cmd + sizeof(cmd->req), 0,
@@ -1163,7 +1175,7 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 	cmd->device = dev;
 	cmd->sense_buffer = buf;
 	cmd->prot_sdb = prot;
-	cmd->flags = unchecked_isa_dma;
+	cmd->flags = flags;
 	INIT_DELAYED_WORK(&cmd->abort_work, scmd_eh_abort_handler);
 	cmd->jiffies_at_alloc = jiffies;
 
@@ -1350,6 +1362,8 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 
 	ret = scsi_setup_cmnd(sdev, req);
 out:
+	if (ret != BLKPREP_OK)
+		cmd->flags &= ~SCMD_INITIALIZED;
 	return scsi_prep_return(q, req, ret);
 }
 
@@ -1869,6 +1883,7 @@ static int scsi_mq_prep_fn(struct request *req)
 	struct scsi_device *sdev = req->q->queuedata;
 	struct Scsi_Host *shost = sdev->host;
 	struct scatterlist *sg;
+	int ret;
 
 	scsi_init_command(sdev, cmd);
 
@@ -1902,7 +1917,10 @@ static int scsi_mq_prep_fn(struct request *req)
 
 	blk_mq_start_request(req);
 
-	return scsi_setup_cmnd(sdev, req);
+	ret = scsi_setup_cmnd(sdev, req);
+	if (ret != BLK_STS_OK)
+		cmd->flags &= ~SCMD_INITIALIZED;
+	return ret;
 }
 
 static void scsi_mq_done(struct scsi_cmnd *cmd)

commit ccf1e0045eea8f98d60fc9327bcb14c958d2e4c7
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Tue Aug 29 08:50:13 2017 -0700

    scsi: Rework handling of scsi_device.vpd_pg8[03]
    
    Introduce struct scsi_vpd for the VPD page length, data and the RCU head
    that will be used to free the VPD data. Use kfree_rcu() instead of
    kfree() to free VPD data. Move the VPD buffer pointer check inside the
    RCU read lock in the sysfs code. Only annotate pointers that are shared
    across threads with __rcu. Use rcu_dereference() when dereferencing an
    RCU pointer. This patch suppresses about twenty sparse complaints about
    the vpd_pg8[03] pointers. This patch also fixes a race condition, namely
    that updating of the VPD pointers and length variables in struct
    scsi_device was not atomic with reference to the code reading these
    variables. See also "Does the update code tolerate concurrent accesses?"
    in Documentation/RCU/checklist.txt.
    
    Fixes: commit 09e2b0b14690 ("scsi: rescan VPD attributes")
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Acked-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Shane Seymour <shane.seymour@hpe.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Cc: Shane Seymour <shane.seymour@hpe.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 696d2eae0ba6..938a7e398cd4 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -3272,8 +3272,8 @@ int scsi_vpd_lun_id(struct scsi_device *sdev, char *id, size_t id_len)
 {
 	u8 cur_id_type = 0xff;
 	u8 cur_id_size = 0;
-	unsigned char *d, *cur_id_str;
-	unsigned char __rcu *vpd_pg83;
+	const unsigned char *d, *cur_id_str;
+	const struct scsi_vpd *vpd_pg83;
 	int id_size = -EINVAL;
 
 	rcu_read_lock();
@@ -3304,8 +3304,8 @@ int scsi_vpd_lun_id(struct scsi_device *sdev, char *id, size_t id_len)
 	}
 
 	memset(id, 0, id_len);
-	d = vpd_pg83 + 4;
-	while (d < vpd_pg83 + sdev->vpd_pg83_len) {
+	d = vpd_pg83->data + 4;
+	while (d < vpd_pg83->data + vpd_pg83->len) {
 		/* Skip designators not referring to the LUN */
 		if ((d[1] & 0x30) != 0x00)
 			goto next_desig;
@@ -3421,8 +3421,8 @@ EXPORT_SYMBOL(scsi_vpd_lun_id);
  */
 int scsi_vpd_tpg_id(struct scsi_device *sdev, int *rel_id)
 {
-	unsigned char *d;
-	unsigned char __rcu *vpd_pg83;
+	const unsigned char *d;
+	const struct scsi_vpd *vpd_pg83;
 	int group_id = -EAGAIN, rel_port = -1;
 
 	rcu_read_lock();
@@ -3432,8 +3432,8 @@ int scsi_vpd_tpg_id(struct scsi_device *sdev, int *rel_id)
 		return -ENXIO;
 	}
 
-	d = sdev->vpd_pg83 + 4;
-	while (d < sdev->vpd_pg83 + sdev->vpd_pg83_len) {
+	d = vpd_pg83->data + 4;
+	while (d < vpd_pg83->data + vpd_pg83->len) {
 		switch (d[1] & 0xf) {
 		case 0x4:
 			/* Relative target port */

commit 35c0506f27f6e3f278592d631901163cbccce28d
Author: Jonathan Corbet <corbet@lwn.net>
Date:   Thu Aug 24 16:11:09 2017 -0600

    scsi: Fix the kerneldoc for scsi_initialize_rq()
    
    The kerneldoc comment for scsi_initialize_rq() neglected to document the
    "rq" parameter, leading to this docs build warning:
    
      ./drivers/scsi/scsi_lib.c:1116: warning: No description found for parameter 'rq'
    
    Document the parameter and make the build slightly quieter.
    
    [mkp: used wording suggested by Bart]
    
    Signed-off-by: Jonathan Corbet <corbet@lwn.net>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 76adec714189..696d2eae0ba6 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1108,6 +1108,7 @@ EXPORT_SYMBOL(scsi_init_io);
 
 /**
  * scsi_initialize_rq - initialize struct scsi_cmnd.req
+ * @rq: Request associated with the SCSI command to be initialized.
  *
  * Called from inside blk_get_request().
  */

commit 23cb27fd679cec8322a376c046dc79b47c30bbd4
Author: Hannes Reinecke <hare@suse.de>
Date:   Fri Aug 25 13:56:56 2017 +0200

    scsi: fix comment in scsi_device_set_state()
    
    The function returns '0' if successful; with the original comment
    the function doesn't have a way to indicate success ...
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Bart van Assche <bvanassche@wdc.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0270b35f7680..76adec714189 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2548,7 +2548,7 @@ EXPORT_SYMBOL(scsi_test_unit_ready);
  *	@sdev:	scsi device to change the state of.
  *	@state:	state to change to.
  *
- *	Returns zero if unsuccessful or an error if the requested 
+ *	Returns zero if successful or an error if the requested
  *	transition is illegal.
  */
 int

commit bed2213d01de474eb8a6f3891070eec6be6fe772
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Fri Aug 25 13:46:32 2017 -0700

    scsi: Use blk_mq_rq_to_pdu() to convert a request to a SCSI command pointer
    
    Since commit e9c787e65c0c ("scsi: allocate scsi_cmnd structures as
    part of struct request") struct request and struct scsi_cmnd are
    adjacent. This means that there is now an alternative to reading
    req->special to convert a pointer to a prepared request into a
    SCSI command pointer, namely by using blk_mq_rq_to_pdu(). Make
    this change where appropriate. Although this patch does not
    change any functionality, it slightly improves performance and
    slightly improves readability.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9e8ce0d66c5a..0270b35f7680 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -627,7 +627,7 @@ static void scsi_release_bidi_buffers(struct scsi_cmnd *cmd)
 static bool scsi_end_request(struct request *req, blk_status_t error,
 		unsigned int bytes, unsigned int bidi_bytes)
 {
-	struct scsi_cmnd *cmd = req->special;
+	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
 	struct scsi_device *sdev = cmd->device;
 	struct request_queue *q = sdev->request_queue;
 
@@ -1171,7 +1171,7 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 
 static int scsi_setup_scsi_cmnd(struct scsi_device *sdev, struct request *req)
 {
-	struct scsi_cmnd *cmd = req->special;
+	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
 
 	/*
 	 * Passthrough requests may transfer data, in which case they must
@@ -1202,7 +1202,7 @@ static int scsi_setup_scsi_cmnd(struct scsi_device *sdev, struct request *req)
  */
 static int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
 {
-	struct scsi_cmnd *cmd = req->special;
+	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
 
 	if (unlikely(sdev->handler && sdev->handler->prep_fn)) {
 		int ret = sdev->handler->prep_fn(sdev, req);
@@ -1217,7 +1217,7 @@ static int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
 
 static int scsi_setup_cmnd(struct scsi_device *sdev, struct request *req)
 {
-	struct scsi_cmnd *cmd = req->special;
+	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
 
 	if (!blk_rq_bytes(req))
 		cmd->sc_data_direction = DMA_NONE;
@@ -1354,7 +1354,7 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 
 static void scsi_unprep_fn(struct request_queue *q, struct request *req)
 {
-	scsi_uninit_cmd(req->special);
+	scsi_uninit_cmd(blk_mq_rq_to_pdu(req));
 }
 
 /*
@@ -1545,7 +1545,7 @@ static int scsi_lld_busy(struct request_queue *q)
  */
 static void scsi_kill_request(struct request *req, struct request_queue *q)
 {
-	struct scsi_cmnd *cmd = req->special;
+	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
 	struct scsi_device *sdev;
 	struct scsi_target *starget;
 	struct Scsi_Host *shost;
@@ -1576,7 +1576,7 @@ static void scsi_kill_request(struct request *req, struct request_queue *q)
 
 static void scsi_softirq_done(struct request *rq)
 {
-	struct scsi_cmnd *cmd = rq->special;
+	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
 	unsigned long wait_for = (cmd->allowed + 1) * rq->timeout;
 	int disposition;
 
@@ -1764,8 +1764,8 @@ static void scsi_request_fn(struct request_queue *q)
 			blk_start_request(req);
 
 		spin_unlock_irq(q->queue_lock);
-		cmd = req->special;
-		if (unlikely(cmd == NULL)) {
+		cmd = blk_mq_rq_to_pdu(req);
+		if (cmd != req->special) {
 			printk(KERN_CRIT "impossible request in %s.\n"
 					 "please mail a stack trace to "
 					 "linux-scsi@vger.kernel.org\n",

commit e7008ff5c61a13e673344d3048baaf8e0652fa87
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Fri Aug 25 13:46:31 2017 -0700

    scsi: Document which queue type a function is intended for
    
    Rename several functions to make it easy to see which queue type a
    function is intended for.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 2afca92445c9..9e8ce0d66c5a 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2001,8 +2001,8 @@ static enum blk_eh_timer_return scsi_timeout(struct request *req,
 	return scsi_times_out(req);
 }
 
-static int scsi_init_request(struct blk_mq_tag_set *set, struct request *rq,
-		unsigned int hctx_idx, unsigned int numa_node)
+static int scsi_mq_init_request(struct blk_mq_tag_set *set, struct request *rq,
+				unsigned int hctx_idx, unsigned int numa_node)
 {
 	struct Scsi_Host *shost = set->driver_data;
 	const bool unchecked_isa_dma = shost->unchecked_isa_dma;
@@ -2026,8 +2026,8 @@ static int scsi_init_request(struct blk_mq_tag_set *set, struct request *rq,
 	return 0;
 }
 
-static void scsi_exit_request(struct blk_mq_tag_set *set, struct request *rq,
-		unsigned int hctx_idx)
+static void scsi_mq_exit_request(struct blk_mq_tag_set *set, struct request *rq,
+				 unsigned int hctx_idx)
 {
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
 
@@ -2104,7 +2104,8 @@ void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 }
 EXPORT_SYMBOL_GPL(__scsi_init_queue);
 
-static int scsi_init_rq(struct request_queue *q, struct request *rq, gfp_t gfp)
+static int scsi_old_init_rq(struct request_queue *q, struct request *rq,
+			    gfp_t gfp)
 {
 	struct Scsi_Host *shost = q->rq_alloc_data;
 	const bool unchecked_isa_dma = shost->unchecked_isa_dma;
@@ -2134,7 +2135,7 @@ static int scsi_init_rq(struct request_queue *q, struct request *rq, gfp_t gfp)
 	return -ENOMEM;
 }
 
-static void scsi_exit_rq(struct request_queue *q, struct request *rq)
+static void scsi_old_exit_rq(struct request_queue *q, struct request *rq)
 {
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
 
@@ -2144,7 +2145,7 @@ static void scsi_exit_rq(struct request_queue *q, struct request *rq)
 			       cmd->sense_buffer);
 }
 
-struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
+struct request_queue *scsi_old_alloc_queue(struct scsi_device *sdev)
 {
 	struct Scsi_Host *shost = sdev->host;
 	struct request_queue *q;
@@ -2155,8 +2156,8 @@ struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
 	q->cmd_size = sizeof(struct scsi_cmnd) + shost->hostt->cmd_size;
 	q->rq_alloc_data = shost;
 	q->request_fn = scsi_request_fn;
-	q->init_rq_fn = scsi_init_rq;
-	q->exit_rq_fn = scsi_exit_rq;
+	q->init_rq_fn = scsi_old_init_rq;
+	q->exit_rq_fn = scsi_old_exit_rq;
 	q->initialize_rq_fn = scsi_initialize_rq;
 
 	if (blk_init_allocated_queue(q) < 0) {
@@ -2180,8 +2181,8 @@ static const struct blk_mq_ops scsi_mq_ops = {
 #ifdef CONFIG_BLK_DEBUG_FS
 	.show_rq	= scsi_show_rq,
 #endif
-	.init_request	= scsi_init_request,
-	.exit_request	= scsi_exit_request,
+	.init_request	= scsi_mq_init_request,
+	.exit_request	= scsi_mq_exit_request,
 	.initialize_rq_fn = scsi_initialize_rq,
 	.map_queues	= scsi_map_queues,
 };

commit 8a97712e5314aefe16b3ffb4583a34deaa49de04
Author: Hannes Reinecke <hare@suse.de>
Date:   Fri Aug 11 08:53:47 2017 +0200

    scsi: make 'state' device attribute pollable
    
    While the 'state' attribute can (and will) change occasionally,
    calling 'poll()' or 'select()' on it fails as sysfs is never
    notified that the state has changed.
    With this patch calling 'poll()' or 'select()' will work
    properly.
    
    Signed-off-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4a295a630848..2afca92445c9 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2654,6 +2654,7 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 
 	}
 	sdev->sdev_state = state;
+	sysfs_notify(&sdev->sdev_gendev.kobj, NULL, "state");
 	return 0;
 
  illegal:
@@ -3077,6 +3078,7 @@ int scsi_internal_device_unblock_nowait(struct scsi_device *sdev,
 	case SDEV_BLOCK:
 	case SDEV_TRANSPORT_OFFLINE:
 		sdev->sdev_state = new_state;
+		sysfs_notify(&sdev->sdev_gendev.kobj, NULL, "state");
 		break;
 	case SDEV_CREATED_BLOCK:
 		if (new_state == SDEV_TRANSPORT_OFFLINE ||
@@ -3084,6 +3086,7 @@ int scsi_internal_device_unblock_nowait(struct scsi_device *sdev,
 			sdev->sdev_state = new_state;
 		else
 			sdev->sdev_state = SDEV_CREATED;
+		sysfs_notify(&sdev->sdev_gendev.kobj, NULL, "state");
 		break;
 	case SDEV_CANCEL:
 	case SDEV_OFFLINE:

commit 8cd1ec78ca15f1016f6c3c683c21b3383b5cb966
Author: Hannes Reinecke <hare@suse.de>
Date:   Fri Aug 11 08:53:46 2017 +0200

    scsi: scsi_lib: rework scsi_internal_device_unblock_nowait()
    
    Rework scsi_internal_device_unblock_nowait() into using a switch
    statement. No functional changes.
    
    Signed-off-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f6097b89d5d3..4a295a630848 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -3073,19 +3073,24 @@ int scsi_internal_device_unblock_nowait(struct scsi_device *sdev,
 	 * Try to transition the scsi device to SDEV_RUNNING or one of the
 	 * offlined states and goose the device queue if successful.
 	 */
-	if ((sdev->sdev_state == SDEV_BLOCK) ||
-	    (sdev->sdev_state == SDEV_TRANSPORT_OFFLINE))
+	switch (sdev->sdev_state) {
+	case SDEV_BLOCK:
+	case SDEV_TRANSPORT_OFFLINE:
 		sdev->sdev_state = new_state;
-	else if (sdev->sdev_state == SDEV_CREATED_BLOCK) {
+		break;
+	case SDEV_CREATED_BLOCK:
 		if (new_state == SDEV_TRANSPORT_OFFLINE ||
 		    new_state == SDEV_OFFLINE)
 			sdev->sdev_state = new_state;
 		else
 			sdev->sdev_state = SDEV_CREATED;
-	} else if (sdev->sdev_state != SDEV_CANCEL &&
-		 sdev->sdev_state != SDEV_OFFLINE)
+		break;
+	case SDEV_CANCEL:
+	case SDEV_OFFLINE:
+		break;
+	default:
 		return -EINVAL;
-
+	}
 	scsi_start_queue(sdev);
 
 	return 0;

commit 90311148415ab23f5767fbb577a012d4405f12e5
Merge: 3a564bb3a8a6 c345c6ca1382
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 6 12:10:33 2017 -0700

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This is mostly updates of the usual suspects: lpfc, qla2xxx, bnx2fc,
      qedf, hpsa, hisi_sas, smartpqi, cxlflash, aacraid, csiostor along with
      a host of minor and miscellaneous changes"
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (276 commits)
      qla2xxx: Fix NVMe entry_type for iocb packet on BE system
      scsi: qla2xxx: avoid unused-function warning
      scsi: snic: fix a couple of spelling mistakes/typos
      scsi: qla2xxx: fix a bunch of typos and spelling mistakes
      scsi: lpfc: don't double count abort errors
      scsi: lpfc: spin_lock_irq() is not nestable
      scsi: hisi_sas: optimise DMA slot memory
      scsi: ibmvfc: constify dev_pm_ops structures.
      scsi: ibmvscsi: constify dev_pm_ops structures.
      scsi: cxlflash: Update debug prints in reset handlers
      scsi: cxlflash: Update send_tmf() parameters
      scsi: cxlflash: Avoid double free of character device
      scsi: Add STARGET_CREATED_REMOVE state to scsi_target_state
      scsi: ses: do not add a device to an enclosure if enclosure_add_links() fails.
      scsi: ufs: flush eh_work when eh_work scheduled.
      scsi: qla2xxx: Protect access to qpair members with qpair->qp_lock
      scsi: sun_esp: fix device reference leaks
      scsi: fnic: changing queue command to return result DID_IMM_RETRY when rport is init
      scsi: fnic: correct speed display and add support for 25,40 and 100G
      scsi: fnic: added timestamp reporting in fnic debug stats
      ...

commit c8d9cf22cf0f89d1249a57ade5a1949c62075ce6
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Tue Jun 20 11:15:42 2017 -0700

    block: Change argument type of scsi_req_init()
    
    Since scsi_req_init() works on a struct scsi_request, change the
    argument type into struct scsi_request *.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 301a7f706c9a..550e29f903b7 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1123,7 +1123,9 @@ EXPORT_SYMBOL(scsi_init_io);
  */
 void scsi_initialize_rq(struct request *rq)
 {
-	scsi_req_init(rq);
+	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
+
+	scsi_req_init(&cmd->req);
 }
 EXPORT_SYMBOL(scsi_initialize_rq);
 

commit ca18d6f769d22e931d3ba1e8d1ae81953547a417
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Tue Jun 20 11:15:41 2017 -0700

    block: Make most scsi_req_init() calls implicit
    
    Instead of explicitly calling scsi_req_init() after blk_get_request(),
    call that function from inside blk_get_request(). Add an
    .initialize_rq_fn() callback function to the block drivers that need
    it. Merge the IDE .init_rq_fn() function into .initialize_rq_fn()
    because it is too small to keep it as a separate function. Keep the
    scsi_req_init() call in ide_prep_sense() because it follows a
    blk_rq_init() call.
    
    References: commit 82ed4db499b8 ("block: split scsi_request out of struct request")
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Omar Sandoval <osandov@fb.com>
    Cc: Nicholas Bellinger <nab@linux-iscsi.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index fb18ed284e55..301a7f706c9a 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -250,7 +250,6 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	if (IS_ERR(req))
 		return ret;
 	rq = scsi_req(req);
-	scsi_req_init(req);
 
 	if (bufflen &&	blk_rq_map_kern(sdev->request_queue, req,
 					buffer, bufflen, __GFP_RECLAIM))
@@ -1117,6 +1116,18 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 }
 EXPORT_SYMBOL(scsi_init_io);
 
+/**
+ * scsi_initialize_rq - initialize struct scsi_cmnd.req
+ *
+ * Called from inside blk_get_request().
+ */
+void scsi_initialize_rq(struct request *rq)
+{
+	scsi_req_init(rq);
+}
+EXPORT_SYMBOL(scsi_initialize_rq);
+
+/* Called after a request has been started. */
 void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 {
 	void *buf = cmd->sense_buffer;
@@ -2124,6 +2135,7 @@ struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
 	q->request_fn = scsi_request_fn;
 	q->init_rq_fn = scsi_init_rq;
 	q->exit_rq_fn = scsi_exit_rq;
+	q->initialize_rq_fn = scsi_initialize_rq;
 
 	if (blk_init_allocated_queue(q) < 0) {
 		blk_cleanup_queue(q);
@@ -2148,6 +2160,7 @@ static const struct blk_mq_ops scsi_mq_ops = {
 #endif
 	.init_request	= scsi_init_request,
 	.exit_request	= scsi_exit_request,
+	.initialize_rq_fn = scsi_initialize_rq,
 	.map_queues	= scsi_map_queues,
 };
 

commit f660174e8bcdb2bf99129f9f7c86e5fc0e830f85
Author: Ming Lei <ming.lei@redhat.com>
Date:   Tue Jun 6 23:22:04 2017 +0800

    blk-mq: use the introduced blk_mq_unquiesce_queue()
    
    blk_mq_unquiesce_queue() is used for unquiescing the
    queue explicitly, so replace blk_mq_start_stopped_hw_queues()
    with it.
    
    For the scsi part, this patch takes Bart's suggestion to
    switch to block quiesce/unquiesce API completely.
    
    Cc: linux-nvme@lists.infradead.org
    Cc: linux-scsi@vger.kernel.org
    Cc: dm-devel@redhat.com
    Reviewed-by: Bart Van Assche <Bart.VanAssche@sandisk.com>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b5f310b9e910..fb18ed284e55 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2962,7 +2962,7 @@ scsi_internal_device_block(struct scsi_device *sdev, bool wait)
 		if (wait)
 			blk_mq_quiesce_queue(q);
 		else
-			blk_mq_stop_hw_queues(q);
+			blk_mq_quiesce_queue_nowait(q);
 	} else {
 		spin_lock_irqsave(q->queue_lock, flags);
 		blk_stop_queue(q);
@@ -3016,7 +3016,7 @@ scsi_internal_device_unblock(struct scsi_device *sdev,
 		return -EINVAL;
 
 	if (q->mq_ops) {
-		blk_mq_start_stopped_hw_queues(q, false);
+		blk_mq_unquiesce_queue(q);
 	} else {
 		spin_lock_irqsave(q->queue_lock, flags);
 		blk_start_queue(q);

commit 08f784364fef627650e471c7ae342f1da1c57bbf
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Fri Jun 2 14:22:00 2017 -0700

    scsi: Make scsi_mq_prep_fn() call scsi_init_command()
    
    This patch reduces code duplication. There are two functional changes in
    this patch:
    
    - It causes scsi_mq_prep_fn() to clear driver-private command data, just
      like the already upstream commit 1bad6c4a57ef ("scsi: zero per-cmd
      private driver data for each MQ I/O").
    
    - The initialization of .prot_sdb is moved from scsi_mq_prep_fn() into
      scsi_init_request().
    
    [mkp: applied by hand]
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c2a9601bd302..41c19c75dab4 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1871,36 +1871,21 @@ static int scsi_mq_prep_fn(struct request *req)
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
 	struct scsi_device *sdev = req->q->queuedata;
 	struct Scsi_Host *shost = sdev->host;
-	unsigned char *sense_buf = cmd->sense_buffer;
-	unsigned int unchecked_isa_dma = cmd->flags & SCMD_UNCHECKED_ISA_DMA;
 	struct scatterlist *sg;
 
-	/* zero out the cmd, except for the embedded scsi_request */
-	memset((char *)cmd + sizeof(cmd->req), 0,
-		sizeof(*cmd) - sizeof(cmd->req) + shost->hostt->cmd_size);
+	scsi_init_command(sdev, cmd);
 
 	req->special = cmd;
 
 	cmd->request = req;
-	cmd->device = sdev;
-	cmd->sense_buffer = sense_buf;
-	cmd->flags = unchecked_isa_dma;
 
 	cmd->tag = req->tag;
-
 	cmd->prot_op = SCSI_PROT_NORMAL;
 
-	INIT_LIST_HEAD(&cmd->list);
-	INIT_DELAYED_WORK(&cmd->abort_work, scmd_eh_abort_handler);
-	cmd->jiffies_at_alloc = jiffies;
-
-	scsi_add_cmd_to_list(cmd);
-
 	sg = (void *)cmd + sizeof(struct scsi_cmnd) + shost->hostt->cmd_size;
 	cmd->sdb.table.sgl = sg;
 
 	if (scsi_host_get_prot(shost)) {
-		cmd->prot_sdb = (void *)sg + scsi_mq_sgl_size(shost);
 		memset(cmd->prot_sdb, 0, sizeof(struct scsi_data_buffer));
 
 		cmd->prot_sdb->table.sgl =
@@ -2026,6 +2011,7 @@ static int scsi_init_request(struct blk_mq_tag_set *set, struct request *rq,
 	struct Scsi_Host *shost = set->driver_data;
 	const bool unchecked_isa_dma = shost->unchecked_isa_dma;
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
+	struct scatterlist *sg;
 
 	if (unchecked_isa_dma)
 		cmd->flags |= SCMD_UNCHECKED_ISA_DMA;
@@ -2034,6 +2020,13 @@ static int scsi_init_request(struct blk_mq_tag_set *set, struct request *rq,
 	if (!cmd->sense_buffer)
 		return -ENOMEM;
 	cmd->req.sense = cmd->sense_buffer;
+
+	if (scsi_host_get_prot(shost)) {
+		sg = (void *)cmd + sizeof(struct scsi_cmnd) +
+			shost->hostt->cmd_size;
+		cmd->prot_sdb = (void *)sg + scsi_mq_sgl_size(shost);
+	}
+
 	return 0;
 }
 

commit be4c186c80113f95a5946594687a8e70f876e857
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Fri Jun 2 14:21:59 2017 -0700

    scsi: Introduce scsi_mq_sgl_size()
    
    This patch does not change any functionality but makes the next patch
    easier to read.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1470c93a87e7..c2a9601bd302 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1859,6 +1859,13 @@ static inline int prep_to_mq(int ret)
 	}
 }
 
+/* Size in bytes of the sg-list stored in the scsi-mq command-private data. */
+static unsigned int scsi_mq_sgl_size(struct Scsi_Host *shost)
+{
+	return min_t(unsigned int, shost->sg_tablesize, SG_CHUNK_SIZE) *
+		sizeof(struct scatterlist);
+}
+
 static int scsi_mq_prep_fn(struct request *req)
 {
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
@@ -1893,10 +1900,7 @@ static int scsi_mq_prep_fn(struct request *req)
 	cmd->sdb.table.sgl = sg;
 
 	if (scsi_host_get_prot(shost)) {
-		cmd->prot_sdb = (void *)sg +
-			min_t(unsigned int,
-			      shost->sg_tablesize, SG_CHUNK_SIZE) *
-			sizeof(struct scatterlist);
+		cmd->prot_sdb = (void *)sg + scsi_mq_sgl_size(shost);
 		memset(cmd->prot_sdb, 0, sizeof(struct scsi_data_buffer));
 
 		cmd->prot_sdb->table.sgl =
@@ -2202,12 +2206,9 @@ struct request_queue *scsi_mq_alloc_queue(struct scsi_device *sdev)
 
 int scsi_mq_setup_tags(struct Scsi_Host *shost)
 {
-	unsigned int cmd_size, sgl_size, tbl_size;
+	unsigned int cmd_size, sgl_size;
 
-	tbl_size = shost->sg_tablesize;
-	if (tbl_size > SG_CHUNK_SIZE)
-		tbl_size = SG_CHUNK_SIZE;
-	sgl_size = tbl_size * sizeof(struct scatterlist);
+	sgl_size = scsi_mq_sgl_size(shost);
 	cmd_size = sizeof(struct scsi_cmnd) + shost->hostt->cmd_size + sgl_size;
 	if (scsi_host_get_prot(shost))
 		cmd_size += sizeof(struct scsi_data_buffer) + sgl_size;

commit 2dd6fb5957a75cd926089bb4434449e6181ca5c5
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Fri Jun 2 14:21:58 2017 -0700

    scsi: Only add commands to the device command list if required by the LLD
    
    Just like for the scsi-mq code path, in the single queue SCSI code path
    only add commands to the per-device command list if required by the SCSI
    LLD. This patch will make it easier to merge the single-queue and
    multiqueue command initialization code.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0554a6a7ea55..1470c93a87e7 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -584,19 +584,9 @@ static void scsi_mq_free_sgtables(struct scsi_cmnd *cmd)
 
 static void scsi_mq_uninit_cmd(struct scsi_cmnd *cmd)
 {
-	struct scsi_device *sdev = cmd->device;
-	struct Scsi_Host *shost = sdev->host;
-	unsigned long flags;
-
 	scsi_mq_free_sgtables(cmd);
 	scsi_uninit_cmd(cmd);
-
-	if (shost->use_cmd_list) {
-		BUG_ON(list_empty(&cmd->list));
-		spin_lock_irqsave(&sdev->list_lock, flags);
-		list_del_init(&cmd->list);
-		spin_unlock_irqrestore(&sdev->list_lock, flags);
-	}
+	scsi_del_cmd_from_list(cmd);
 }
 
 /*
@@ -1134,12 +1124,40 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 }
 EXPORT_SYMBOL(scsi_init_io);
 
+/* Add a command to the list used by the aacraid and dpt_i2o drivers */
+void scsi_add_cmd_to_list(struct scsi_cmnd *cmd)
+{
+	struct scsi_device *sdev = cmd->device;
+	struct Scsi_Host *shost = sdev->host;
+	unsigned long flags;
+
+	if (shost->use_cmd_list) {
+		spin_lock_irqsave(&sdev->list_lock, flags);
+		list_add_tail(&cmd->list, &sdev->cmd_list);
+		spin_unlock_irqrestore(&sdev->list_lock, flags);
+	}
+}
+
+/* Remove a command from the list used by the aacraid and dpt_i2o drivers */
+void scsi_del_cmd_from_list(struct scsi_cmnd *cmd)
+{
+	struct scsi_device *sdev = cmd->device;
+	struct Scsi_Host *shost = sdev->host;
+	unsigned long flags;
+
+	if (shost->use_cmd_list) {
+		spin_lock_irqsave(&sdev->list_lock, flags);
+		BUG_ON(list_empty(&cmd->list));
+		list_del_init(&cmd->list);
+		spin_unlock_irqrestore(&sdev->list_lock, flags);
+	}
+}
+
 void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 {
 	void *buf = cmd->sense_buffer;
 	void *prot = cmd->prot_sdb;
 	unsigned int unchecked_isa_dma = cmd->flags & SCMD_UNCHECKED_ISA_DMA;
-	unsigned long flags;
 
 	/* zero out the cmd, except for the embedded scsi_request */
 	memset((char *)cmd + sizeof(cmd->req), 0,
@@ -1152,9 +1170,7 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 	INIT_DELAYED_WORK(&cmd->abort_work, scmd_eh_abort_handler);
 	cmd->jiffies_at_alloc = jiffies;
 
-	spin_lock_irqsave(&dev->list_lock, flags);
-	list_add_tail(&cmd->list, &dev->cmd_list);
-	spin_unlock_irqrestore(&dev->list_lock, flags);
+	scsi_add_cmd_to_list(cmd);
 }
 
 static int scsi_setup_scsi_cmnd(struct scsi_device *sdev, struct request *req)
@@ -1871,11 +1887,7 @@ static int scsi_mq_prep_fn(struct request *req)
 	INIT_DELAYED_WORK(&cmd->abort_work, scmd_eh_abort_handler);
 	cmd->jiffies_at_alloc = jiffies;
 
-	if (shost->use_cmd_list) {
-		spin_lock_irq(&sdev->list_lock);
-		list_add_tail(&cmd->list, &sdev->cmd_list);
-		spin_unlock_irq(&sdev->list_lock);
-	}
+	scsi_add_cmd_to_list(cmd);
 
 	sg = (void *)cmd + sizeof(struct scsi_cmnd) + shost->hostt->cmd_size;
 	cmd->sdb.table.sgl = sg;

commit 255ee9320e5dc46173bb94dbcd68e32f11fc10a9
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Fri Jun 2 14:21:57 2017 -0700

    scsi: Make __scsi_remove_device go straight from BLOCKED to DEL
    
    If a device is blocked, make __scsi_remove_device() cause it to
    transition to the DEL state. This means that all the commands issued in
    .shutdown() will error in the mid-layer, thus making the removal proceed
    without being stopped.
    
    This patch is a slightly modified version of a patch from James
    Bottomley. This patch avoids that the following lockup occurs:
    
    Call Trace:
     schedule+0x35/0x80
     schedule_timeout+0x237/0x2d0
     io_schedule_timeout+0xa6/0x110
     wait_for_completion_io+0xa3/0x110
     blk_execute_rq+0xdf/0x120
     scsi_execute+0xce/0x150 [scsi_mod]
     scsi_execute_req_flags+0x8f/0xf0 [scsi_mod]
     sd_sync_cache+0xa9/0x190 [sd_mod]
     sd_shutdown+0x6a/0x100 [sd_mod]
     sd_remove+0x64/0xc0 [sd_mod]
     __device_release_driver+0x8d/0x120
     device_release_driver+0x1e/0x30
     bus_remove_device+0xf9/0x170
     device_del+0x127/0x240
     __scsi_remove_device+0xc1/0xd0 [scsi_mod]
     scsi_forget_host+0x57/0x60 [scsi_mod]
     scsi_remove_host+0x72/0x110 [scsi_mod]
     srp_remove_work+0x8b/0x200 [ib_srp]
    
    Reported-by: Israel Rukshin <israelr@mellanox.com>
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Cc: Israel Rukshin <israelr@mellanox.com>
    Cc: Max Gurtovoy <maxg@mellanox.com>
    Cc: Benjamin Block <bblock@linux.vnet.ibm.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ed744668b984..0554a6a7ea55 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2625,7 +2625,6 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 		case SDEV_QUIESCE:
 		case SDEV_OFFLINE:
 		case SDEV_TRANSPORT_OFFLINE:
-		case SDEV_BLOCK:
 			break;
 		default:
 			goto illegal;
@@ -2639,6 +2638,7 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 		case SDEV_OFFLINE:
 		case SDEV_TRANSPORT_OFFLINE:
 		case SDEV_CANCEL:
+		case SDEV_BLOCK:
 		case SDEV_CREATED_BLOCK:
 			break;
 		default:

commit 66483a4a9f34427e3d6ec87d8e583f5d2a7cbb76
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Fri Jun 2 14:21:56 2017 -0700

    scsi: Introduce scsi_start_queue()
    
    This patch does not change any functionality.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Cc: Israel Rukshin <israelr@mellanox.com>
    Cc: Max Gurtovoy <maxg@mellanox.com>
    Cc: Benjamin Block <bblock@linux.vnet.ibm.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4b0bac3ac6ab..ed744668b984 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -3031,6 +3031,20 @@ static int scsi_internal_device_block(struct scsi_device *sdev)
 	return err;
 }
  
+void scsi_start_queue(struct scsi_device *sdev)
+{
+	struct request_queue *q = sdev->request_queue;
+	unsigned long flags;
+
+	if (q->mq_ops) {
+		blk_mq_start_stopped_hw_queues(q, false);
+	} else {
+		spin_lock_irqsave(q->queue_lock, flags);
+		blk_start_queue(q);
+		spin_unlock_irqrestore(q->queue_lock, flags);
+	}
+}
+
 /**
  * scsi_internal_device_unblock_nowait - resume a device after a block request
  * @sdev:	device to resume
@@ -3049,9 +3063,6 @@ static int scsi_internal_device_block(struct scsi_device *sdev)
 int scsi_internal_device_unblock_nowait(struct scsi_device *sdev,
 					enum scsi_device_state new_state)
 {
-	struct request_queue *q = sdev->request_queue; 
-	unsigned long flags;
-
 	/*
 	 * Try to transition the scsi device to SDEV_RUNNING or one of the
 	 * offlined states and goose the device queue if successful.
@@ -3069,13 +3080,7 @@ int scsi_internal_device_unblock_nowait(struct scsi_device *sdev,
 		 sdev->sdev_state != SDEV_OFFLINE)
 		return -EINVAL;
 
-	if (q->mq_ops) {
-		blk_mq_start_stopped_hw_queues(q, false);
-	} else {
-		spin_lock_irqsave(q->queue_lock, flags);
-		blk_start_queue(q);
-		spin_unlock_irqrestore(q->queue_lock, flags);
-	}
+	scsi_start_queue(sdev);
 
 	return 0;
 }

commit 0db6ca8a5e1ea585795db3643ec7d50fc8cb1aff
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Fri Jun 2 14:21:55 2017 -0700

    scsi: Protect SCSI device state changes with a mutex
    
    Serializing SCSI device state changes avoids that two state changes can
    occur concurrently, e.g. the state changes in scsi_target_block() and
    __scsi_remove_device(). This serialization is essential to make patch
    "Make __scsi_remove_device go straight from BLOCKED to DEL" work
    reliably.
    
    Enable this mechanism for all scsi_target_*block() callers but not for
    the scsi_internal_device_unblock() calls from the mpt3sas driver because
    that driver can call scsi_internal_device_unblock() from atomic context.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f0eb55744513..4b0bac3ac6ab 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2882,7 +2882,12 @@ static void scsi_wait_for_queuecommand(struct scsi_device *sdev)
 int
 scsi_device_quiesce(struct scsi_device *sdev)
 {
-	int err = scsi_device_set_state(sdev, SDEV_QUIESCE);
+	int err;
+
+	mutex_lock(&sdev->state_mutex);
+	err = scsi_device_set_state(sdev, SDEV_QUIESCE);
+	mutex_unlock(&sdev->state_mutex);
+
 	if (err)
 		return err;
 
@@ -2910,10 +2915,11 @@ void scsi_device_resume(struct scsi_device *sdev)
 	 * so assume the state is being managed elsewhere (for example
 	 * device deleted during suspend)
 	 */
-	if (sdev->sdev_state != SDEV_QUIESCE ||
-	    scsi_device_set_state(sdev, SDEV_RUNNING))
-		return;
-	scsi_run_queue(sdev->request_queue);
+	mutex_lock(&sdev->state_mutex);
+	if (sdev->sdev_state == SDEV_QUIESCE &&
+	    scsi_device_set_state(sdev, SDEV_RUNNING) == 0)
+		scsi_run_queue(sdev->request_queue);
+	mutex_unlock(&sdev->state_mutex);
 }
 EXPORT_SYMBOL(scsi_device_resume);
 
@@ -3012,6 +3018,7 @@ static int scsi_internal_device_block(struct scsi_device *sdev)
 	struct request_queue *q = sdev->request_queue;
 	int err;
 
+	mutex_lock(&sdev->state_mutex);
 	err = scsi_internal_device_block_nowait(sdev);
 	if (err == 0) {
 		if (q->mq_ops)
@@ -3019,6 +3026,8 @@ static int scsi_internal_device_block(struct scsi_device *sdev)
 		else
 			scsi_wait_for_queuecommand(sdev);
 	}
+	mutex_unlock(&sdev->state_mutex);
+
 	return err;
 }
  
@@ -3089,7 +3098,13 @@ EXPORT_SYMBOL_GPL(scsi_internal_device_unblock_nowait);
 static int scsi_internal_device_unblock(struct scsi_device *sdev,
 					enum scsi_device_state new_state)
 {
-	return scsi_internal_device_unblock_nowait(sdev, new_state);
+	int ret;
+
+	mutex_lock(&sdev->state_mutex);
+	ret = scsi_internal_device_unblock_nowait(sdev, new_state);
+	mutex_unlock(&sdev->state_mutex);
+
+	return ret;
 }
 
 static void

commit 43f7571be077ee4673466cbcba115427d68440e1
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Fri Jun 2 14:21:54 2017 -0700

    scsi: Create two versions of scsi_internal_device_unblock()
    
    This will make it easier to serialize SCSI device state changes through
    a mutex.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Cc: Sreekanth Reddy <sreekanth.reddy@broadcom.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index fc8f394eb854..f0eb55744513 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -3023,24 +3023,22 @@ static int scsi_internal_device_block(struct scsi_device *sdev)
 }
  
 /**
- * scsi_internal_device_unblock - resume a device after a block request
+ * scsi_internal_device_unblock_nowait - resume a device after a block request
  * @sdev:	device to resume
- * @new_state:	state to set devices to after unblocking
+ * @new_state:	state to set the device to after unblocking
  *
- * Called by scsi lld's or the midlayer to restart the device queue
- * for the previously suspended scsi device.  Called from interrupt or
- * normal process context.
+ * Restart the device queue for a previously suspended SCSI device. Does not
+ * sleep.
  *
- * Returns zero if successful or error if not.
+ * Returns zero if successful or a negative error code upon failure.
  *
- * Notes:       
- *	This routine transitions the device to the SDEV_RUNNING state
- *	or to one of the offline states (which must be a legal transition)
- *	allowing the midlayer to goose the queue for this device.
+ * Notes:
+ * This routine transitions the device to the SDEV_RUNNING state or to one of
+ * the offline states (which must be a legal transition) allowing the midlayer
+ * to goose the queue for this device.
  */
-int
-scsi_internal_device_unblock(struct scsi_device *sdev,
-			     enum scsi_device_state new_state)
+int scsi_internal_device_unblock_nowait(struct scsi_device *sdev,
+					enum scsi_device_state new_state)
 {
 	struct request_queue *q = sdev->request_queue; 
 	unsigned long flags;
@@ -3072,7 +3070,27 @@ scsi_internal_device_unblock(struct scsi_device *sdev,
 
 	return 0;
 }
-EXPORT_SYMBOL_GPL(scsi_internal_device_unblock);
+EXPORT_SYMBOL_GPL(scsi_internal_device_unblock_nowait);
+
+/**
+ * scsi_internal_device_unblock - resume a device after a block request
+ * @sdev:	device to resume
+ * @new_state:	state to set the device to after unblocking
+ *
+ * Restart the device queue for a previously suspended SCSI device. May sleep.
+ *
+ * Returns zero if successful or a negative error code upon failure.
+ *
+ * Notes:
+ * This routine transitions the device to the SDEV_RUNNING state or to one of
+ * the offline states (which must be a legal transition) allowing the midlayer
+ * to goose the queue for this device.
+ */
+static int scsi_internal_device_unblock(struct scsi_device *sdev,
+					enum scsi_device_state new_state)
+{
+	return scsi_internal_device_unblock_nowait(sdev, new_state);
+}
 
 static void
 device_block(struct scsi_device *sdev, void *data)

commit 551eb598e5ea52996eb821f43740496a78a97b68
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Fri Jun 2 14:21:53 2017 -0700

    scsi: Split scsi_internal_device_block()
    
    Instead of passing a "wait" argument to scsi_internal_device_block(),
    split this function into a function that waits and a function that
    doesn't wait. This will make it easier to serialize SCSI device state
    changes through a mutex.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Cc: Sreekanth Reddy <sreekanth.reddy@broadcom.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a95eb022fb89..fc8f394eb854 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2944,28 +2944,20 @@ scsi_target_resume(struct scsi_target *starget)
 EXPORT_SYMBOL(scsi_target_resume);
 
 /**
- * scsi_internal_device_block - internal function to put a device temporarily into the SDEV_BLOCK state
- * @sdev:	device to block
- * @wait:	Whether or not to wait until ongoing .queuecommand() /
- *		.queue_rq() calls have finished.
+ * scsi_internal_device_block_nowait - try to transition to the SDEV_BLOCK state
+ * @sdev: device to block
  *
- * Block request made by scsi lld's to temporarily stop all
- * scsi commands on the specified device. May sleep.
+ * Pause SCSI command processing on the specified device. Does not sleep.
  *
- * Returns zero if successful or error if not
+ * Returns zero if successful or a negative error code upon failure.
  *
- * Notes:       
- *	This routine transitions the device to the SDEV_BLOCK state
- *	(which must be a legal transition).  When the device is in this
- *	state, all commands are deferred until the scsi lld reenables
- *	the device with scsi_device_unblock or device_block_tmo fires.
- *
- * To do: avoid that scsi_send_eh_cmnd() calls queuecommand() after
- * scsi_internal_device_block() has blocked a SCSI device and also
- * remove the rport mutex lock and unlock calls from srp_queuecommand().
+ * Notes:
+ * This routine transitions the device to the SDEV_BLOCK state (which must be
+ * a legal transition). When the device is in this state, command processing
+ * is paused until the device leaves the SDEV_BLOCK state. See also
+ * scsi_internal_device_unblock_nowait().
  */
-int
-scsi_internal_device_block(struct scsi_device *sdev, bool wait)
+int scsi_internal_device_block_nowait(struct scsi_device *sdev)
 {
 	struct request_queue *q = sdev->request_queue;
 	unsigned long flags;
@@ -2985,21 +2977,50 @@ scsi_internal_device_block(struct scsi_device *sdev, bool wait)
 	 * request queue. 
 	 */
 	if (q->mq_ops) {
-		if (wait)
-			blk_mq_quiesce_queue(q);
-		else
-			blk_mq_stop_hw_queues(q);
+		blk_mq_stop_hw_queues(q);
 	} else {
 		spin_lock_irqsave(q->queue_lock, flags);
 		blk_stop_queue(q);
 		spin_unlock_irqrestore(q->queue_lock, flags);
-		if (wait)
-			scsi_wait_for_queuecommand(sdev);
 	}
 
 	return 0;
 }
-EXPORT_SYMBOL_GPL(scsi_internal_device_block);
+EXPORT_SYMBOL_GPL(scsi_internal_device_block_nowait);
+
+/**
+ * scsi_internal_device_block - try to transition to the SDEV_BLOCK state
+ * @sdev: device to block
+ *
+ * Pause SCSI command processing on the specified device and wait until all
+ * ongoing scsi_request_fn() / scsi_queue_rq() calls have finished. May sleep.
+ *
+ * Returns zero if successful or a negative error code upon failure.
+ *
+ * Note:
+ * This routine transitions the device to the SDEV_BLOCK state (which must be
+ * a legal transition). When the device is in this state, command processing
+ * is paused until the device leaves the SDEV_BLOCK state. See also
+ * scsi_internal_device_unblock().
+ *
+ * To do: avoid that scsi_send_eh_cmnd() calls queuecommand() after
+ * scsi_internal_device_block() has blocked a SCSI device and also
+ * remove the rport mutex lock and unlock calls from srp_queuecommand().
+ */
+static int scsi_internal_device_block(struct scsi_device *sdev)
+{
+	struct request_queue *q = sdev->request_queue;
+	int err;
+
+	err = scsi_internal_device_block_nowait(sdev);
+	if (err == 0) {
+		if (q->mq_ops)
+			blk_mq_quiesce_queue(q);
+		else
+			scsi_wait_for_queuecommand(sdev);
+	}
+	return err;
+}
  
 /**
  * scsi_internal_device_unblock - resume a device after a block request
@@ -3056,7 +3077,7 @@ EXPORT_SYMBOL_GPL(scsi_internal_device_unblock);
 static void
 device_block(struct scsi_device *sdev, void *data)
 {
-	scsi_internal_device_block(sdev, true);
+	scsi_internal_device_block(sdev);
 }
 
 static int

commit 8e6882545d8c06f99e9e117741cc87f3338b0bef
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Fri Jun 2 14:21:52 2017 -0700

    scsi: Avoid that scsi_exit_rq() triggers a use-after-free
    
    Dereferencing shost from scsi_exit_rq() is not safe because the SCSI
    host may already have been freed when scsi_exit_rq() is called.
    Increasing the shost reference count in scsi_init_rq() and dropping that
    reference in scsi_exit_rq() is nontrivial since scsi_host_dev_release()
    may sleep and since scsi_exit_rq() may be called from interrupt
    context. Since scsi_exit_rq() only needs a single bit from shost, copy
    that bit into struct scsi_cmnd.
    
    Reported-by: Scott Bauer <scott.bauer@intel.com>
    Fixes: e9c787e65c0c ("scsi: allocate scsi_cmnd structures as part of struct request")
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Scott Bauer <scott.bauer@intel.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 99e16ac479e3..a95eb022fb89 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -45,23 +45,23 @@ static struct kmem_cache *scsi_sense_isadma_cache;
 static DEFINE_MUTEX(scsi_sense_cache_mutex);
 
 static inline struct kmem_cache *
-scsi_select_sense_cache(struct Scsi_Host *shost)
+scsi_select_sense_cache(bool unchecked_isa_dma)
 {
-	return shost->unchecked_isa_dma ?
-		scsi_sense_isadma_cache : scsi_sense_cache;
+	return unchecked_isa_dma ? scsi_sense_isadma_cache : scsi_sense_cache;
 }
 
-static void scsi_free_sense_buffer(struct Scsi_Host *shost,
-		unsigned char *sense_buffer)
+static void scsi_free_sense_buffer(bool unchecked_isa_dma,
+				   unsigned char *sense_buffer)
 {
-	kmem_cache_free(scsi_select_sense_cache(shost), sense_buffer);
+	kmem_cache_free(scsi_select_sense_cache(unchecked_isa_dma),
+			sense_buffer);
 }
 
-static unsigned char *scsi_alloc_sense_buffer(struct Scsi_Host *shost,
+static unsigned char *scsi_alloc_sense_buffer(bool unchecked_isa_dma,
 	gfp_t gfp_mask, int numa_node)
 {
-	return kmem_cache_alloc_node(scsi_select_sense_cache(shost), gfp_mask,
-			numa_node);
+	return kmem_cache_alloc_node(scsi_select_sense_cache(unchecked_isa_dma),
+				     gfp_mask, numa_node);
 }
 
 int scsi_init_sense_cache(struct Scsi_Host *shost)
@@ -69,7 +69,7 @@ int scsi_init_sense_cache(struct Scsi_Host *shost)
 	struct kmem_cache *cache;
 	int ret = 0;
 
-	cache = scsi_select_sense_cache(shost);
+	cache = scsi_select_sense_cache(shost->unchecked_isa_dma);
 	if (cache)
 		return 0;
 
@@ -1138,6 +1138,7 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 {
 	void *buf = cmd->sense_buffer;
 	void *prot = cmd->prot_sdb;
+	unsigned int unchecked_isa_dma = cmd->flags & SCMD_UNCHECKED_ISA_DMA;
 	unsigned long flags;
 
 	/* zero out the cmd, except for the embedded scsi_request */
@@ -1147,6 +1148,7 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 	cmd->device = dev;
 	cmd->sense_buffer = buf;
 	cmd->prot_sdb = prot;
+	cmd->flags = unchecked_isa_dma;
 	INIT_DELAYED_WORK(&cmd->abort_work, scmd_eh_abort_handler);
 	cmd->jiffies_at_alloc = jiffies;
 
@@ -1847,6 +1849,7 @@ static int scsi_mq_prep_fn(struct request *req)
 	struct scsi_device *sdev = req->q->queuedata;
 	struct Scsi_Host *shost = sdev->host;
 	unsigned char *sense_buf = cmd->sense_buffer;
+	unsigned int unchecked_isa_dma = cmd->flags & SCMD_UNCHECKED_ISA_DMA;
 	struct scatterlist *sg;
 
 	/* zero out the cmd, except for the embedded scsi_request */
@@ -1858,6 +1861,7 @@ static int scsi_mq_prep_fn(struct request *req)
 	cmd->request = req;
 	cmd->device = sdev;
 	cmd->sense_buffer = sense_buf;
+	cmd->flags = unchecked_isa_dma;
 
 	cmd->tag = req->tag;
 
@@ -2004,10 +2008,13 @@ static int scsi_init_request(struct blk_mq_tag_set *set, struct request *rq,
 		unsigned int hctx_idx, unsigned int numa_node)
 {
 	struct Scsi_Host *shost = set->driver_data;
+	const bool unchecked_isa_dma = shost->unchecked_isa_dma;
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
 
-	cmd->sense_buffer =
-		scsi_alloc_sense_buffer(shost, GFP_KERNEL, numa_node);
+	if (unchecked_isa_dma)
+		cmd->flags |= SCMD_UNCHECKED_ISA_DMA;
+	cmd->sense_buffer = scsi_alloc_sense_buffer(unchecked_isa_dma,
+						    GFP_KERNEL, numa_node);
 	if (!cmd->sense_buffer)
 		return -ENOMEM;
 	cmd->req.sense = cmd->sense_buffer;
@@ -2017,10 +2024,10 @@ static int scsi_init_request(struct blk_mq_tag_set *set, struct request *rq,
 static void scsi_exit_request(struct blk_mq_tag_set *set, struct request *rq,
 		unsigned int hctx_idx)
 {
-	struct Scsi_Host *shost = set->driver_data;
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
 
-	scsi_free_sense_buffer(shost, cmd->sense_buffer);
+	scsi_free_sense_buffer(cmd->flags & SCMD_UNCHECKED_ISA_DMA,
+			       cmd->sense_buffer);
 }
 
 static int scsi_map_queues(struct blk_mq_tag_set *set)
@@ -2093,11 +2100,15 @@ EXPORT_SYMBOL_GPL(__scsi_init_queue);
 static int scsi_init_rq(struct request_queue *q, struct request *rq, gfp_t gfp)
 {
 	struct Scsi_Host *shost = q->rq_alloc_data;
+	const bool unchecked_isa_dma = shost->unchecked_isa_dma;
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
 
 	memset(cmd, 0, sizeof(*cmd));
 
-	cmd->sense_buffer = scsi_alloc_sense_buffer(shost, gfp, NUMA_NO_NODE);
+	if (unchecked_isa_dma)
+		cmd->flags |= SCMD_UNCHECKED_ISA_DMA;
+	cmd->sense_buffer = scsi_alloc_sense_buffer(unchecked_isa_dma, gfp,
+						    NUMA_NO_NODE);
 	if (!cmd->sense_buffer)
 		goto fail;
 	cmd->req.sense = cmd->sense_buffer;
@@ -2111,19 +2122,19 @@ static int scsi_init_rq(struct request_queue *q, struct request *rq, gfp_t gfp)
 	return 0;
 
 fail_free_sense:
-	scsi_free_sense_buffer(shost, cmd->sense_buffer);
+	scsi_free_sense_buffer(unchecked_isa_dma, cmd->sense_buffer);
 fail:
 	return -ENOMEM;
 }
 
 static void scsi_exit_rq(struct request_queue *q, struct request *rq)
 {
-	struct Scsi_Host *shost = q->rq_alloc_data;
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
 
 	if (cmd->prot_sdb)
 		kmem_cache_free(scsi_sdb_cache, cmd->prot_sdb);
-	scsi_free_sense_buffer(shost, cmd->sense_buffer);
+	scsi_free_sense_buffer(cmd->flags & SCMD_UNCHECKED_ISA_DMA,
+			       cmd->sense_buffer);
 }
 
 struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)

commit fc17b6534eb8395f0b3133eb31d87deec32c642b
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 3 09:38:05 2017 +0200

    blk-mq: switch ->queue_rq return value to blk_status_t
    
    Use the same values for use for request completion errors as the return
    value from ->queue_rq.  BLK_STS_RESOURCE is special cased to cause
    a requeue, and all the others are completed as-is.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 67a67191520f..b5f310b9e910 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1812,15 +1812,15 @@ static void scsi_request_fn(struct request_queue *q)
 		blk_delay_queue(q, SCSI_QUEUE_DELAY);
 }
 
-static inline int prep_to_mq(int ret)
+static inline blk_status_t prep_to_mq(int ret)
 {
 	switch (ret) {
 	case BLKPREP_OK:
-		return BLK_MQ_RQ_QUEUE_OK;
+		return BLK_STS_OK;
 	case BLKPREP_DEFER:
-		return BLK_MQ_RQ_QUEUE_BUSY;
+		return BLK_STS_RESOURCE;
 	default:
-		return BLK_MQ_RQ_QUEUE_ERROR;
+		return BLK_STS_IOERR;
 	}
 }
 
@@ -1892,7 +1892,7 @@ static void scsi_mq_done(struct scsi_cmnd *cmd)
 	blk_mq_complete_request(cmd->request);
 }
 
-static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
+static blk_status_t scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 			 const struct blk_mq_queue_data *bd)
 {
 	struct request *req = bd->rq;
@@ -1900,14 +1900,14 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	struct scsi_device *sdev = q->queuedata;
 	struct Scsi_Host *shost = sdev->host;
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
-	int ret;
+	blk_status_t ret;
 	int reason;
 
 	ret = prep_to_mq(scsi_prep_state_check(sdev, req));
-	if (ret != BLK_MQ_RQ_QUEUE_OK)
+	if (ret != BLK_STS_OK)
 		goto out;
 
-	ret = BLK_MQ_RQ_QUEUE_BUSY;
+	ret = BLK_STS_RESOURCE;
 	if (!get_device(&sdev->sdev_gendev))
 		goto out;
 
@@ -1920,7 +1920,7 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 
 	if (!(req->rq_flags & RQF_DONTPREP)) {
 		ret = prep_to_mq(scsi_mq_prep_fn(req));
-		if (ret != BLK_MQ_RQ_QUEUE_OK)
+		if (ret != BLK_STS_OK)
 			goto out_dec_host_busy;
 		req->rq_flags |= RQF_DONTPREP;
 	} else {
@@ -1938,11 +1938,11 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	reason = scsi_dispatch_cmd(cmd);
 	if (reason) {
 		scsi_set_blocked(cmd, reason);
-		ret = BLK_MQ_RQ_QUEUE_BUSY;
+		ret = BLK_STS_RESOURCE;
 		goto out_dec_host_busy;
 	}
 
-	return BLK_MQ_RQ_QUEUE_OK;
+	return BLK_STS_OK;
 
 out_dec_host_busy:
 	atomic_dec(&shost->host_busy);
@@ -1955,12 +1955,14 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	put_device(&sdev->sdev_gendev);
 out:
 	switch (ret) {
-	case BLK_MQ_RQ_QUEUE_BUSY:
+	case BLK_STS_OK:
+		break;
+	case BLK_STS_RESOURCE:
 		if (atomic_read(&sdev->device_busy) == 0 &&
 		    !scsi_device_blocked(sdev))
 			blk_mq_delay_run_hw_queue(hctx, SCSI_QUEUE_DELAY);
 		break;
-	case BLK_MQ_RQ_QUEUE_ERROR:
+	default:
 		/*
 		 * Make sure to release all allocated ressources when
 		 * we hit an error, as we will never see this command
@@ -1969,8 +1971,6 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 		if (req->rq_flags & RQF_DONTPREP)
 			scsi_mq_uninit_cmd(cmd);
 		break;
-	default:
-		break;
 	}
 	return ret;
 }

commit 2a842acab109f40f0d7d10b38e9ca88390628996
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 3 09:38:04 2017 +0200

    block: introduce new block status code type
    
    Currently we use nornal Linux errno values in the block layer, and while
    we accept any error a few have overloaded magic meanings.  This patch
    instead introduces a new  blk_status_t value that holds block layer specific
    status codes and explicitly explains their meaning.  Helpers to convert from
    and to the previous special meanings are provided for now, but I suspect
    we want to get rid of them in the long run - those drivers that have a
    errno input (e.g. networking) usually get errnos that don't know about
    the special block layer overloads, and similarly returning them to userspace
    will usually return somethings that strictly speaking isn't correct
    for file system operations, but that's left as an exercise for later.
    
    For now the set of errors is a very limited set that closely corresponds
    to the previous overloaded errno values, but there is some low hanging
    fruite to improve it.
    
    blk_status_t (ab)uses the sparse __bitwise annotations to allow for sparse
    typechecking, so that we can easily catch places passing the wrong values.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 884aaa84c2dd..67a67191520f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -635,7 +635,7 @@ static void scsi_release_bidi_buffers(struct scsi_cmnd *cmd)
 	cmd->request->next_rq->special = NULL;
 }
 
-static bool scsi_end_request(struct request *req, int error,
+static bool scsi_end_request(struct request *req, blk_status_t error,
 		unsigned int bytes, unsigned int bidi_bytes)
 {
 	struct scsi_cmnd *cmd = req->special;
@@ -694,45 +694,28 @@ static bool scsi_end_request(struct request *req, int error,
  * @cmd:	SCSI command (unused)
  * @result:	scsi error code
  *
- * Translate SCSI error code into standard UNIX errno.
- * Return values:
- * -ENOLINK	temporary transport failure
- * -EREMOTEIO	permanent target failure, do not retry
- * -EBADE	permanent nexus failure, retry on other path
- * -ENOSPC	No write space available
- * -ENODATA	Medium error
- * -EIO		unspecified I/O error
+ * Translate SCSI error code into block errors.
  */
-static int __scsi_error_from_host_byte(struct scsi_cmnd *cmd, int result)
+static blk_status_t __scsi_error_from_host_byte(struct scsi_cmnd *cmd,
+		int result)
 {
-	int error = 0;
-
-	switch(host_byte(result)) {
+	switch (host_byte(result)) {
 	case DID_TRANSPORT_FAILFAST:
-		error = -ENOLINK;
-		break;
+		return BLK_STS_TRANSPORT;
 	case DID_TARGET_FAILURE:
 		set_host_byte(cmd, DID_OK);
-		error = -EREMOTEIO;
-		break;
+		return BLK_STS_TARGET;
 	case DID_NEXUS_FAILURE:
-		set_host_byte(cmd, DID_OK);
-		error = -EBADE;
-		break;
+		return BLK_STS_NEXUS;
 	case DID_ALLOC_FAILURE:
 		set_host_byte(cmd, DID_OK);
-		error = -ENOSPC;
-		break;
+		return BLK_STS_NOSPC;
 	case DID_MEDIUM_ERROR:
 		set_host_byte(cmd, DID_OK);
-		error = -ENODATA;
-		break;
+		return BLK_STS_MEDIUM;
 	default:
-		error = -EIO;
-		break;
+		return BLK_STS_IOERR;
 	}
-
-	return error;
 }
 
 /*
@@ -769,7 +752,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	int result = cmd->result;
 	struct request_queue *q = cmd->device->request_queue;
 	struct request *req = cmd->request;
-	int error = 0;
+	blk_status_t error = BLK_STS_OK;
 	struct scsi_sense_hdr sshdr;
 	bool sense_valid = false;
 	int sense_deferred = 0, level = 0;
@@ -808,7 +791,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			 * both sides at once.
 			 */
 			scsi_req(req->next_rq)->resid_len = scsi_in(cmd)->resid;
-			if (scsi_end_request(req, 0, blk_rq_bytes(req),
+			if (scsi_end_request(req, BLK_STS_OK, blk_rq_bytes(req),
 					blk_rq_bytes(req->next_rq)))
 				BUG();
 			return;
@@ -850,7 +833,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			scsi_print_sense(cmd);
 		result = 0;
 		/* for passthrough error may be set */
-		error = 0;
+		error = BLK_STS_OK;
 	}
 
 	/*
@@ -922,18 +905,18 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				action = ACTION_REPREP;
 			} else if (sshdr.asc == 0x10) /* DIX */ {
 				action = ACTION_FAIL;
-				error = -EILSEQ;
+				error = BLK_STS_PROTECTION;
 			/* INVALID COMMAND OPCODE or INVALID FIELD IN CDB */
 			} else if (sshdr.asc == 0x20 || sshdr.asc == 0x24) {
 				action = ACTION_FAIL;
-				error = -EREMOTEIO;
+				error = BLK_STS_TARGET;
 			} else
 				action = ACTION_FAIL;
 			break;
 		case ABORTED_COMMAND:
 			action = ACTION_FAIL;
 			if (sshdr.asc == 0x10) /* DIF */
-				error = -EILSEQ;
+				error = BLK_STS_PROTECTION;
 			break;
 		case NOT_READY:
 			/* If the device is in the process of becoming

commit 9efc160f4bbd69b17b48edec53067537d04e62b7
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Wed May 31 14:43:46 2017 -0700

    block: Introduce queue flag QUEUE_FLAG_SCSI_PASSTHROUGH
    
    From the context where a SCSI command is submitted it is not always
    possible to figure out whether or not the queue the command is
    submitted to has struct scsi_request as the first member of its
    private data. Hence introduce the flag QUEUE_FLAG_SCSI_PASSTHROUGH.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Cc: Omar Sandoval <osandov@fb.com>
    Cc: Don Brace <don.brace@microsemi.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 99e16ac479e3..884aaa84c2dd 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2057,6 +2057,8 @@ void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 {
 	struct device *dev = shost->dma_dev;
 
+	queue_flag_set_unlocked(QUEUE_FLAG_SCSI_PASSTHROUGH, q);
+
 	/*
 	 * this limit is imposed by hardware restrictions
 	 */

commit 1bad6c4a57efda0d5f5bf8a2403b21b1ed24875c
Author: Long Li <longli@microsoft.com>
Date:   Thu May 18 15:40:05 2017 -0700

    scsi: zero per-cmd private driver data for each MQ I/O
    
    In lower layer driver's (LLD) scsi_host_template, the driver may
    optionally ask SCSI to allocate its private driver memory for each
    command, by specifying cmd_size. This memory is allocated at the end of
    scsi_cmnd by SCSI.  Later when SCSI queues a command, the LLD can use
    scsi_cmd_priv to get to its private data.
    
    Some LLD, e.g. hv_storvsc, doesn't clear its private data before use. In
    this case, the LLD may get to stale or uninitialized data in its private
    driver memory. This may result in unexpected driver and hardware
    behavior.
    
    Fix this problem by also zeroing the private driver memory before
    passing them to LLD.
    
    Signed-off-by: Long Li <longli@microsoft.com>
    Reviewed-by: Bart Van Assche <Bart.VanAssche@sandisk.com>
    Reviewed-by: KY Srinivasan <kys@microsoft.com>
    Reviewed-by: Christoph Hellwig <hch@infradead.org>
    CC: <stable@vger.kernel.org> # 4.11+
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e31f1cc90b81..99e16ac479e3 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1851,7 +1851,7 @@ static int scsi_mq_prep_fn(struct request *req)
 
 	/* zero out the cmd, except for the embedded scsi_request */
 	memset((char *)cmd + sizeof(cmd->req), 0,
-		sizeof(*cmd) - sizeof(cmd->req));
+		sizeof(*cmd) - sizeof(cmd->req) + shost->hostt->cmd_size);
 
 	req->special = cmd;
 

commit 7aa686d35598cbe58b3f7ce32e4ec17649190f3d
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Tue May 2 10:45:03 2017 -0700

    scsi: scsi_lib: Add #include <scsi/scsi_transport.h>
    
    This patch avoids that when building with W=1 the compiler complains
    that __scsi_init_queue() has not been declared.  See also commit
    d48777a633d6 ("scsi: remove __scsi_alloc_queue").
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 814a4bd8405d..e31f1cc90b81 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -30,6 +30,7 @@
 #include <scsi/scsi_driver.h>
 #include <scsi/scsi_eh.h>
 #include <scsi/scsi_host.h>
+#include <scsi/scsi_transport.h> /* __scsi_init_queue() */
 #include <scsi/scsi_dh.h>
 
 #include <trace/events/scsi.h>

commit 044f1daaaaf7c86bc4fcf433848b7baae236946b
Merge: d557d1b58b35 daaadb3e9453
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat May 6 11:25:08 2017 -0700

    Merge branch 'for-linus' of git://git.kernel.dk/linux-block
    
    Pull block fixes and updates from Jens Axboe:
     "Some fixes and followup features/changes that should go in, in this
      merge window. This contains:
    
       - Two fixes for lightnvm from Javier, fixing problems in the new code
         merge previously in this merge window.
    
       - A fix from Jan for the backing device changes, fixing an issue in
         NFS that causes a failure to mount on certain setups.
    
       - A change from Christoph, cleaning up the blk-mq init and exit
         request paths.
    
       - Remove elevator_change(), which is now unused. From Bart.
    
       - A fix for queue operation invocation on a dead queue, from Bart.
    
       - A series fixing up mtip32xx for blk-mq scheduling, removing a
         bandaid we previously had in place for this. From me.
    
       - A regression fix for this series, fixing a case where we wait on
         workqueue flushing from an invalid (non-blocking) context. From me.
    
       - A fix/optimization from Ming, ensuring that we don't both quiesce
         and freeze a queue at the same time.
    
       - A fix from Peter on lock ordering for CPU hotplug. Not a real
         problem right now, but will be once the CPU hotplug rework goes in.
    
       - A series from Omar, cleaning up out blk-mq debugfs support, and
         adding support for exporting info from schedulers in debugfs as
         well. This is really useful in debugging stalls or livelocks. From
         Omar"
    
    * 'for-linus' of git://git.kernel.dk/linux-block: (28 commits)
      mq-deadline: add debugfs attributes
      kyber: add debugfs attributes
      blk-mq-debugfs: allow schedulers to register debugfs attributes
      blk-mq: untangle debugfs and sysfs
      blk-mq: move debugfs declarations to a separate header file
      blk-mq: Do not invoke queue operations on a dead queue
      blk-mq-debugfs: get rid of a bunch of boilerplate
      blk-mq-debugfs: rename hw queue directories from <n> to hctx<n>
      blk-mq-debugfs: don't open code strstrip()
      blk-mq-debugfs: error on long write to queue "state" file
      blk-mq-debugfs: clean up flag definitions
      blk-mq-debugfs: separate flags with |
      nfs: Fix bdi handling for cloned superblocks
      block/mq: Cure cpu hotplug lock inversion
      lightnvm: fix bad back free on error path
      lightnvm: create cmd before allocating request
      blk-mq: don't use sync workqueue flushing from drivers
      mtip32xx: convert internal commands to regular block infrastructure
      mtip32xx: cleanup internal tag assumptions
      block: don't call blk_mq_quiesce_queue() after queue is frozen
      ...

commit 8d5e72dfdf0fa29a21143fd72746c6f43295ce9f
Merge: 2bd804017435 e7731da36f10
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu May 4 12:19:44 2017 -0700

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This update includes the usual round of major driver updates
      (hisi_sas, ufs, fnic, cxlflash, be2iscsi, ipr, stex). There's also the
      usual amount of cosmetic and spelling stuff"
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (155 commits)
      scsi: qla4xxx: fix spelling mistake: "Tempalate" -> "Template"
      scsi: stex: make S6flag static
      scsi: mac_esp: fix to pass correct device identity to free_irq()
      scsi: aacraid: pci_alloc_consistent() failures on ARM64
      scsi: ufs: make ufshcd_get_lists_status() register operation obvious
      scsi: ufs: use MASK_EE_STATUS
      scsi: mac_esp: Replace bogus memory barrier with spinlock
      scsi: fcoe: make fcoe_e_d_tov and fcoe_r_a_tov static
      scsi: sd_zbc: Do not write lock zones for reset
      scsi: sd_zbc: Remove superfluous assignments
      scsi: sd: sd_zbc: Rename sd_zbc_setup_write_cmnd
      scsi: Improve scsi_get_sense_info_fld
      scsi: sd: Cleanup sd_done sense data handling
      scsi: sd: Improve sd_completed_bytes
      scsi: sd: Fix function descriptions
      scsi: mpt3sas: remove redundant wmb
      scsi: mpt: Move scsi_remove_host() out of mptscsih_remove_host()
      scsi: sg: reset 'res_in_use' after unlinking reserved array
      scsi: mvumi: remove code handling zero scsi_sg_count(scmd) case
      scsi: fusion: fix spelling mistake: "Persistancy" -> "Persistency"
      ...

commit d6296d39e90c9075bc2fc15f1e86dac44930d4b5
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon May 1 10:19:08 2017 -0600

    blk-mq: update ->init_request and ->exit_request prototypes
    
    Remove the request_idx parameter, which can't be used safely now that we
    support I/O schedulers with blk-mq.  Except for a superflous check in
    mtip32xx it was unused anyway.
    
    Also pass the tag_set instead of just the driver data - this allows drivers
    to avoid some code duplication in a follow on cleanup.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1c3e87d6c48f..327b10206d63 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1999,11 +1999,10 @@ static enum blk_eh_timer_return scsi_timeout(struct request *req,
 	return scsi_times_out(req);
 }
 
-static int scsi_init_request(void *data, struct request *rq,
-		unsigned int hctx_idx, unsigned int request_idx,
-		unsigned int numa_node)
+static int scsi_init_request(struct blk_mq_tag_set *set, struct request *rq,
+		unsigned int hctx_idx, unsigned int numa_node)
 {
-	struct Scsi_Host *shost = data;
+	struct Scsi_Host *shost = set->driver_data;
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
 
 	cmd->sense_buffer =
@@ -2014,10 +2013,10 @@ static int scsi_init_request(void *data, struct request *rq,
 	return 0;
 }
 
-static void scsi_exit_request(void *data, struct request *rq,
-		unsigned int hctx_idx, unsigned int request_idx)
+static void scsi_exit_request(struct blk_mq_tag_set *set, struct request *rq,
+		unsigned int hctx_idx)
 {
-	struct Scsi_Host *shost = data;
+	struct Scsi_Host *shost = set->driver_data;
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
 
 	scsi_free_sense_buffer(shost, cmd->sense_buffer);

commit 694752922b12bd318aa80191bd9d8c3dcfb39055
Merge: a351e9b9fc24 9438b3e080be
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 1 10:39:57 2017 -0700

    Merge branch 'for-4.12/block' of git://git.kernel.dk/linux-block
    
    Pull block layer updates from Jens Axboe:
    
     - Add BFQ IO scheduler under the new blk-mq scheduling framework. BFQ
       was initially a fork of CFQ, but subsequently changed to implement
       fairness based on B-WF2Q+, a modified variant of WF2Q. BFQ is meant
       to be used on desktop type single drives, providing good fairness.
       From Paolo.
    
     - Add Kyber IO scheduler. This is a full multiqueue aware scheduler,
       using a scalable token based algorithm that throttles IO based on
       live completion IO stats, similary to blk-wbt. From Omar.
    
     - A series from Jan, moving users to separately allocated backing
       devices. This continues the work of separating backing device life
       times, solving various problems with hot removal.
    
     - A series of updates for lightnvm, mostly from Javier. Includes a
       'pblk' target that exposes an open channel SSD as a physical block
       device.
    
     - A series of fixes and improvements for nbd from Josef.
    
     - A series from Omar, removing queue sharing between devices on mostly
       legacy drivers. This helps us clean up other bits, if we know that a
       queue only has a single device backing. This has been overdue for
       more than a decade.
    
     - Fixes for the blk-stats, and improvements to unify the stats and user
       windows. This both improves blk-wbt, and enables other users to
       register a need to receive IO stats for a device. From Omar.
    
     - blk-throttle improvements from Shaohua. This provides a scalable
       framework for implementing scalable priotization - particularly for
       blk-mq, but applicable to any type of block device. The interface is
       marked experimental for now.
    
     - Bucketized IO stats for IO polling from Stephen Bates. This improves
       efficiency of polled workloads in the presence of mixed block size
       IO.
    
     - A few fixes for opal, from Scott.
    
     - A few pulls for NVMe, including a lot of fixes for NVMe-over-fabrics.
       From a variety of folks, mostly Sagi and James Smart.
    
     - A series from Bart, improving our exposed info and capabilities from
       the blk-mq debugfs support.
    
     - A series from Christoph, cleaning up how handle WRITE_ZEROES.
    
     - A series from Christoph, cleaning up the block layer handling of how
       we track errors in a request. On top of being a nice cleanup, it also
       shrinks the size of struct request a bit.
    
     - Removal of mg_disk and hd (sorry Linus) by Christoph. The former was
       never used by platforms, and the latter has outlived it's usefulness.
    
     - Various little bug fixes and cleanups from a wide variety of folks.
    
    * 'for-4.12/block' of git://git.kernel.dk/linux-block: (329 commits)
      block: hide badblocks attribute by default
      blk-mq: unify hctx delay_work and run_work
      block: add kblock_mod_delayed_work_on()
      blk-mq: unify hctx delayed_run_work and run_work
      nbd: fix use after free on module unload
      MAINTAINERS: bfq: Add Paolo as maintainer for the BFQ I/O scheduler
      blk-mq-sched: alloate reserved tags out of normal pool
      mtip32xx: use runtime tag to initialize command header
      scsi: Implement blk_mq_ops.show_rq()
      blk-mq: Add blk_mq_ops.show_rq()
      blk-mq: Show operation, cmd_flags and rq_flags names
      blk-mq: Make blk_flags_show() callers append a newline character
      blk-mq: Move the "state" debugfs attribute one level down
      blk-mq: Unregister debugfs attributes earlier
      blk-mq: Only unregister hctxs for which registration succeeded
      blk-mq-debugfs: Rename functions for registering and unregistering the mq directory
      blk-mq: Let blk_mq_debugfs_register() look up the queue name
      blk-mq: Register <dev>/queue/mq after having registered <dev>/queue
      ide-pm: always pass 0 error to ide_complete_rq in ide_do_devset
      ide-pm: always pass 0 error to __blk_end_request_all
      ..

commit 0eebd005dd07c162e6af053be0ab440dd766b1d5
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Wed Apr 26 13:47:57 2017 -0700

    scsi: Implement blk_mq_ops.show_rq()
    
    Show the SCSI CDB for pending SCSI commands in
    /sys/kernel/debug/block/*/mq/*/dispatch and */rq_list. An example
    of how SCSI commands are displayed by this code:
    
    ffff8801703245c0 {.op=READ, .cmd_flags=META PRIO, .rq_flags=DONTPREP IO_STAT STATS, .tag=14, .internal_tag=-1, .cmd=Read(10) 28 00 2a 81 1b 30 00 00 08 00}
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Omar Sandoval <osandov@fb.com>
    Cc: Martin K. Petersen <martin.petersen@oracle.com>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: <linux-scsi@vger.kernel.org>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4a20e6098f7c..91455dabbfef 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -34,6 +34,7 @@
 
 #include <trace/events/scsi.h>
 
+#include "scsi_debugfs.h"
 #include "scsi_priv.h"
 #include "scsi_logging.h"
 
@@ -2157,6 +2158,9 @@ static const struct blk_mq_ops scsi_mq_ops = {
 	.queue_rq	= scsi_queue_rq,
 	.complete	= scsi_softirq_done,
 	.timeout	= scsi_timeout,
+#ifdef CONFIG_BLK_DEBUG_FS
+	.show_rq	= scsi_show_rq,
+#endif
 	.init_request	= scsi_init_request,
 	.exit_request	= scsi_exit_request,
 	.map_queues	= scsi_map_queues,

commit 8f9cedc76fc7d9bc916127f8fe1287a249891d40
Merge: 3d339d337041 ca855a5e2679
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Apr 24 13:31:08 2017 -0700

    Merge tag 'scsi-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI fix from James Bottomley:
     "Our final fix before the 4.12 release (hopefully).
    
      It's an error leg again: the fix to not bug on empty DMA transfers is
      returning the wrong code and confusing the block layer"
    
    * tag 'scsi-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi:
      scsi: return correct blkprep status code in case scsi_init_io() fails.

commit 08e0029aa2a4acdd365613ce88a1184e5351a8a1
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Apr 20 16:03:09 2017 +0200

    blk-mq: remove the error argument to blk_mq_complete_request
    
    Now that all drivers that call blk_mq_complete_requests have a
    ->complete callback we can remove the direct call to blk_mq_end_request,
    as well as the error argument to blk_mq_complete_request.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Bart Van Assche <Bart.VanAssche@sandisk.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b9298a499e19..4a20e6098f7c 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1904,7 +1904,7 @@ static int scsi_mq_prep_fn(struct request *req)
 static void scsi_mq_done(struct scsi_cmnd *cmd)
 {
 	trace_scsi_dispatch_cmd_done(cmd);
-	blk_mq_complete_request(cmd->request, 0);
+	blk_mq_complete_request(cmd->request);
 }
 
 static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,

commit 17d5363b83f8c73ef9109f75a4a9b578f31d842f
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Apr 20 16:03:01 2017 +0200

    scsi: introduce a result field in struct scsi_request
    
    This passes on the scsi_cmnd result field to users of passthrough
    requests.  Currently we abuse req->errors for this purpose, but that
    field will go away in its current form.
    
    Note that the old IDE code abuses the errors field in very creative
    ways and stores all kinds of different values in it.  I didn't dare
    to touch this magic, so the abuses are brought forward 1:1.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Bart Van Assche <Bart.VanAssche@sandisk.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 7bc4513bf4e4..b9298a499e19 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -229,8 +229,8 @@ void scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
  * @rq_flags:	flags for ->rq_flags
  * @resid:	optional residual length
  *
- * returns the req->errors value which is the scsi_cmnd result
- * field.
+ * Returns the scsi_cmnd result field if a command was executed, or a negative
+ * Linux error code if we didn't get that far.
  */
 int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 		 int data_direction, void *buffer, unsigned bufflen,
@@ -281,7 +281,7 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 		memcpy(sense, rq->sense, SCSI_SENSE_BUFFERSIZE);
 	if (sshdr)
 		scsi_normalize_sense(rq->sense, rq->sense_len, sshdr);
-	ret = req->errors;
+	ret = rq->result;
  out:
 	blk_put_request(req);
 
@@ -797,8 +797,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		/*
 		 * __scsi_error_from_host_byte may have reset the host_byte
 		 */
-		req->errors = cmd->result;
-
+		scsi_req(req)->result = cmd->result;
 		scsi_req(req)->resid_len = scsi_get_resid(cmd);
 
 		if (scsi_bidi_cmnd(cmd)) {
@@ -835,7 +834,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	/*
 	 * Recovered errors need reporting, but they're always treated as
 	 * success, so fiddle the result code here.  For passthrough requests
-	 * we already took a copy of the original into rq->errors which
+	 * we already took a copy of the original into sreq->result which
 	 * is what gets returned to the user
 	 */
 	if (sense_valid && (sshdr.sense_key == RECOVERED_ERROR)) {
@@ -1281,7 +1280,7 @@ scsi_prep_return(struct request_queue *q, struct request *req, int ret)
 	switch (ret) {
 	case BLKPREP_KILL:
 	case BLKPREP_INVALID:
-		req->errors = DID_NO_CONNECT << 16;
+		scsi_req(req)->result = DID_NO_CONNECT << 16;
 		/* release the command and kill it */
 		if (req->special) {
 			struct scsi_cmnd *cmd = req->special;
@@ -1905,7 +1904,7 @@ static int scsi_mq_prep_fn(struct request *req)
 static void scsi_mq_done(struct scsi_cmnd *cmd)
 {
 	trace_scsi_dispatch_cmd_done(cmd);
-	blk_mq_complete_request(cmd->request, cmd->request->errors);
+	blk_mq_complete_request(cmd->request, 0);
 }
 
 static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,

commit ca855a5e2679e9e571dfb0e64f4484b36f1992a8
Merge: 0e1bfea999da e7661a8e5ce1
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Sat Apr 15 09:36:06 2017 -0700

    Merge remote-tracking branch 'mkp-scsi/4.11/scsi-fixes' into fixes

commit e7661a8e5ce10b5321882d0bbaf3f81070903319
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Wed Apr 12 09:21:19 2017 +0200

    scsi: return correct blkprep status code in case scsi_init_io() fails.
    
    When instrumenting the SCSI layer to run into the
    !blk_rq_nr_phys_segments(rq) case the following warning emitted from the
    block layer:
    
    blk_peek_request: bad return=-22
    
    This happens because since commit fd3fc0b4d730 ("scsi: don't BUG_ON()
    empty DMA transfers") we return the wrong error value from
    scsi_prep_fn() back to the block layer.
    
    [mkp: silenced checkpatch]
    
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Fixes: fd3fc0b4d730 scsi: don't BUG_ON() empty DMA transfers
    Cc: <stable@vger.kernel.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f41e6b84a1bd..eecc005099b2 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1061,10 +1061,10 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 	struct scsi_device *sdev = cmd->device;
 	struct request *rq = cmd->request;
 	bool is_mq = (rq->mq_ctx != NULL);
-	int error;
+	int error = BLKPREP_KILL;
 
 	if (WARN_ON_ONCE(!blk_rq_nr_phys_segments(rq)))
-		return -EINVAL;
+		goto err_exit;
 
 	error = scsi_init_sgtable(rq, &cmd->sdb);
 	if (error)

commit 65f619d2535197d97067eeeef75a40f25b552e69
Merge: fbbaf700e7b1 6d8c6c0f97ad
Author: Jens Axboe <axboe@fb.com>
Date:   Fri Apr 7 12:45:20 2017 -0600

    Merge branch 'for-linus' into for-4.12/block
    
    We've added a considerable amount of fixes for stalls and issues
    with the blk-mq scheduling in the 4.11 series since forking
    off the for-4.12/block branch. We need to do improvements on
    top of that for 4.12, so pull in the previous fixes to make
    our lives easier going forward.
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

commit 36e3cf273977da34a760d513e1bef8431a9abaa0
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Fri Apr 7 11:16:53 2017 -0700

    scsi: Avoid that SCSI queues get stuck
    
    If a .queue_rq() function returns BLK_MQ_RQ_QUEUE_BUSY then the block
    driver that implements that function is responsible for rerunning the
    hardware queue once requests can be queued again successfully.
    
    commit 52d7f1b5c2f3 ("blk-mq: Avoid that requeueing starts stopped
    queues") removed the blk_mq_stop_hw_queue() call from scsi_queue_rq()
    for the BLK_MQ_RQ_QUEUE_BUSY case. Hence change all calls to functions
    that are intended to rerun a busy queue such that these examine all
    hardware queues instead of only stopped queues.
    
    Since no other functions than scsi_internal_device_block() and
    scsi_internal_device_unblock() should ever stop or restart a SCSI
    queue, change the blk_mq_delay_queue() call into a
    blk_mq_delay_run_hw_queue() call.
    
    Fixes: commit 52d7f1b5c2f3 ("blk-mq: Avoid that requeueing starts stopped queues")
    Fixes: commit 7e79dadce222 ("blk-mq: stop hardware queue in blk_mq_delay_queue()")
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Cc: Martin K. Petersen <martin.petersen@oracle.com>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.de>
    Cc: Sagi Grimberg <sagi@grimberg.me>
    Cc: Long Li <longli@microsoft.com>
    Cc: K. Y. Srinivasan <kys@microsoft.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 19125d72f322..e5a2d590a104 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -496,7 +496,7 @@ static void scsi_run_queue(struct request_queue *q)
 		scsi_starved_list_run(sdev->host);
 
 	if (q->mq_ops)
-		blk_mq_start_stopped_hw_queues(q, false);
+		blk_mq_run_hw_queues(q, false);
 	else
 		blk_run_queue(q);
 }
@@ -667,7 +667,7 @@ static bool scsi_end_request(struct request *req, int error,
 		    !list_empty(&sdev->host->starved_list))
 			kblockd_schedule_work(&sdev->requeue_work);
 		else
-			blk_mq_start_stopped_hw_queues(q, true);
+			blk_mq_run_hw_queues(q, true);
 	} else {
 		unsigned long flags;
 
@@ -1974,7 +1974,7 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	case BLK_MQ_RQ_QUEUE_BUSY:
 		if (atomic_read(&sdev->device_busy) == 0 &&
 		    !scsi_device_blocked(sdev))
-			blk_mq_delay_queue(hctx, SCSI_QUEUE_DELAY);
+			blk_mq_delay_run_hw_queue(hctx, SCSI_QUEUE_DELAY);
 		break;
 	case BLK_MQ_RQ_QUEUE_ERROR:
 		/*

commit a06586325f371c0f0f6095454b5beca0602eaab4
Author: Hannes Reinecke <hare@suse.de>
Date:   Thu Apr 6 15:36:35 2017 +0200

    scsi: make asynchronous aborts mandatory
    
    There hasn't been any reports for HBAs where asynchronous abort
    would not work, so we should make it mandatory and remove
    the fallback.
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ba8da904e774..9822fdeed0ce 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1593,7 +1593,7 @@ static void scsi_softirq_done(struct request *rq)
 			scsi_queue_insert(cmd, SCSI_MLQUEUE_DEVICE_BUSY);
 			break;
 		default:
-			scsi_eh_scmd_add(cmd, 0);
+			scsi_eh_scmd_add(cmd);
 			break;
 	}
 }

commit 2171b6d08bf8c2b826922b94e24ba36b00cb78b3
Author: Hannes Reinecke <hare@suse.de>
Date:   Thu Apr 6 15:36:34 2017 +0200

    scsi: make scsi_eh_scmd_add() always succeed
    
    scsi_eh_scmd_add() currently only will fail if no
    error handler thread is started (which will never be the
    case) or if the state machine encounters an illegal transition.
    
    But if we're encountering an invalid state transition
    chances is we cannot fixup things with the error handler.
    So better add a WARN_ON for illegal host states and
    make scsi_dh_scmd_add() a void function.
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ba2286652ff6..ba8da904e774 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1593,8 +1593,8 @@ static void scsi_softirq_done(struct request *rq)
 			scsi_queue_insert(cmd, SCSI_MLQUEUE_DEVICE_BUSY);
 			break;
 		default:
-			if (!scsi_eh_scmd_add(cmd, 0))
-				scsi_finish_command(cmd);
+			scsi_eh_scmd_add(cmd, 0);
+			break;
 	}
 }
 

commit 64c7f1d1572cacadfc0a4ca5a937aeffa486de58
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Apr 5 19:18:12 2017 +0200

    block, scsi: move the retries field to struct scsi_request
    
    Instead of bloating the generic struct request with it.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c1519660824b..11972d1075f1 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -256,7 +256,7 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 
 	rq->cmd_len = COMMAND_SIZE(cmd[0]);
 	memcpy(rq->cmd, cmd, rq->cmd_len);
-	req->retries = retries;
+	rq->retries = retries;
 	req->timeout = timeout;
 	req->cmd_flags |= flags;
 	req->rq_flags |= rq_flags | RQF_QUIET | RQF_PREEMPT;
@@ -1177,7 +1177,7 @@ static int scsi_setup_scsi_cmnd(struct scsi_device *sdev, struct request *req)
 	cmd->cmd_len = scsi_req(req)->cmd_len;
 	cmd->cmnd = scsi_req(req)->cmd;
 	cmd->transfersize = blk_rq_bytes(req);
-	cmd->allowed = req->retries;
+	cmd->allowed = scsi_req(req)->retries;
 	return BLKPREP_OK;
 }
 

commit f363b089be0a39fe4282c688118a51d21f952bc7
Author: Eric Biggers <ebiggers@google.com>
Date:   Thu Mar 30 13:39:16 2017 -0700

    blk-mq: constify struct blk_mq_ops
    
    Constify all instances of blk_mq_ops, as they are never modified.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 19125d72f322..c1519660824b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2154,7 +2154,7 @@ struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
 	return q;
 }
 
-static struct blk_mq_ops scsi_mq_ops = {
+static const struct blk_mq_ops scsi_mq_ops = {
 	.queue_rq	= scsi_queue_rq,
 	.complete	= scsi_softirq_done,
 	.timeout	= scsi_timeout,

commit e2a3a67302fbe2431fc6d7c313073da5b2b4c293
Merge: c1ae3cfa0e89 eeb810849a20
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Tue Mar 7 15:13:02 2017 -0800

    Merge remote-tracking branch 'mkp-scsi/fixes' into fixes

commit a3b4924b027f9a4b95ce89a914c1e0459e76f18a
Merge: 0b94da8dfc26 42a70abddd90
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Mar 3 21:36:56 2017 -0800

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull more SCSI updates from James Bottomley:
     "This is the set of stuff that didn't quite make the initial pull and a
      set of fixes for stuff which did.
    
      The new stuff is basically lpfc (nvme), qedi and aacraid. The fixes
      cover a lot of previously submitted stuff, the most important of which
      probably covers some of the failing irq vectors allocation and other
      fallout from having the SCSI command allocated as part of the block
      allocation functions"
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (59 commits)
      scsi: qedi: Fix memory leak in tmf response processing.
      scsi: aacraid: remove redundant zero check on ret
      scsi: lpfc: use proper format string for dma_addr_t
      scsi: lpfc: use div_u64 for 64-bit division
      scsi: mac_scsi: Fix MAC_SCSI=m option when SCSI=m
      scsi: cciss: correct check map error.
      scsi: qla2xxx: fix spelling mistake: "seperator" -> "separator"
      scsi: aacraid: Fixed expander hotplug for SMART family
      scsi: mpt3sas: switch to pci_alloc_irq_vectors
      scsi: qedf: fixup compilation warning about atomic_t usage
      scsi: remove scsi_execute_req_flags
      scsi: merge __scsi_execute into scsi_execute
      scsi: simplify scsi_execute_req_flags
      scsi: make the sense header argument to scsi_test_unit_ready mandatory
      scsi: sd: improve TUR handling in sd_check_events
      scsi: always zero sshdr in scsi_normalize_sense
      scsi: scsi_dh_emc: return success in clariion_std_inquiry()
      scsi: fix memory leak of sdpk on when gd fails to allocate
      scsi: sd: make sd_devt_release() static
      scsi: qedf: Add QLogic FastLinQ offload FCoE driver framework.
      ...

commit 8893cf6cb1cf56334c05120e23092dbfc9423ebb
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Wed Mar 1 09:00:36 2017 -0800

    scsi: mpt3sas: Avoid sleeping in interrupt context
    
    Commit 669f044170d8 ("scsi: srp_transport: Move queuecommand() wait code
    to SCSI core") can make scsi_internal_device_block() sleep.  However,
    the mpt3sas driver can call this function from an interrupt
    handler. Hence add a second argument to scsi_internal_device_block()
    that restores the old behavior of this function for the mpt3sas handler.
    
    The call chain that triggered an "IRQ handler enabled interrupts"
    complaint is as follows:
    
    _base_interrupt()
    -> _base_async_event()
       -> mpt3sas_scsih_event_callback()
          -> _scsih_check_topo_delete_events()
             -> _scsih_block_io_to_children_attached_directly()
                -> _scsih_block_io_device()
                   -> _scsih_internal_device_block()
                      -> scsi_internal_device_block()
    
    Reported-by: Omar Sandoval <osandov@osandov.com>
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Cc: Omar Sandoval <osandov@osandov.com>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Sagi Grimberg <sagi@grimberg.me>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Sathya Prakash <sathya.prakash@broadcom.com>
    Cc: Chaitra P B <chaitra.basappa@broadcom.com>
    Cc: Suganath Prabu Subramani <suganath-prabu.subramani@broadcom.com>
    Cc: Sreekanth Reddy <Sreekanth.Reddy@broadcom.com>
    Cc: <stable@vger.kernel.org> # v4.10+
    Tested-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f5e45a252485..f41e6b84a1bd 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2932,6 +2932,8 @@ EXPORT_SYMBOL(scsi_target_resume);
 /**
  * scsi_internal_device_block - internal function to put a device temporarily into the SDEV_BLOCK state
  * @sdev:	device to block
+ * @wait:	Whether or not to wait until ongoing .queuecommand() /
+ *		.queue_rq() calls have finished.
  *
  * Block request made by scsi lld's to temporarily stop all
  * scsi commands on the specified device. May sleep.
@@ -2949,7 +2951,7 @@ EXPORT_SYMBOL(scsi_target_resume);
  * remove the rport mutex lock and unlock calls from srp_queuecommand().
  */
 int
-scsi_internal_device_block(struct scsi_device *sdev)
+scsi_internal_device_block(struct scsi_device *sdev, bool wait)
 {
 	struct request_queue *q = sdev->request_queue;
 	unsigned long flags;
@@ -2969,12 +2971,16 @@ scsi_internal_device_block(struct scsi_device *sdev)
 	 * request queue. 
 	 */
 	if (q->mq_ops) {
-		blk_mq_quiesce_queue(q);
+		if (wait)
+			blk_mq_quiesce_queue(q);
+		else
+			blk_mq_stop_hw_queues(q);
 	} else {
 		spin_lock_irqsave(q->queue_lock, flags);
 		blk_stop_queue(q);
 		spin_unlock_irqrestore(q->queue_lock, flags);
-		scsi_wait_for_queuecommand(sdev);
+		if (wait)
+			scsi_wait_for_queuecommand(sdev);
 	}
 
 	return 0;
@@ -3036,7 +3042,7 @@ EXPORT_SYMBOL_GPL(scsi_internal_device_unblock);
 static void
 device_block(struct scsi_device *sdev, void *data)
 {
-	scsi_internal_device_block(sdev);
+	scsi_internal_device_block(sdev, true);
 }
 
 static int

commit fcbfffe2c5cbec0c1721b2261c316b961ad50208
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Feb 23 16:02:37 2017 +0100

    scsi: remove scsi_execute_req_flags
    
    And switch all callers to use scsi_execute instead.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b0cb3e0713f3..f5e45a252485 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -289,17 +289,6 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 }
 EXPORT_SYMBOL(scsi_execute);
 
-int scsi_execute_req_flags(struct scsi_device *sdev, const unsigned char *cmd,
-		     int data_direction, void *buffer, unsigned bufflen,
-		     struct scsi_sense_hdr *sshdr, int timeout, int retries,
-		     int *resid, u64 flags, req_flags_t rq_flags)
-{
-	return scsi_execute(sdev, cmd, data_direction, buffer, bufflen,
-			      NULL, sshdr, timeout, retries, flags, rq_flags,
-			      resid);
-}
-EXPORT_SYMBOL(scsi_execute_req_flags);
-
 /*
  * Function:    scsi_init_cmd_errh()
  *

commit 76aaf87b4cdc7f7115a32e4fda88310d42ce7fde
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Feb 23 16:02:36 2017 +0100

    scsi: merge __scsi_execute into scsi_execute
    
    All but one caller want the decoded sense header, so offer the existing
    __scsi_execute helper as the public scsi_execute API to simply the
    callers.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 5f661486cf6e..b0cb3e0713f3 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -213,7 +213,26 @@ void scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 	__scsi_queue_insert(cmd, reason, 1);
 }
 
-static int __scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
+
+/**
+ * scsi_execute - insert request and wait for the result
+ * @sdev:	scsi device
+ * @cmd:	scsi command
+ * @data_direction: data direction
+ * @buffer:	data buffer
+ * @bufflen:	len of buffer
+ * @sense:	optional sense buffer
+ * @sshdr:	optional decoded sense header
+ * @timeout:	request timeout in seconds
+ * @retries:	number of times to retry request
+ * @flags:	flags for ->cmd_flags
+ * @rq_flags:	flags for ->rq_flags
+ * @resid:	optional residual length
+ *
+ * returns the req->errors value which is the scsi_cmnd result
+ * field.
+ */
+int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 		 int data_direction, void *buffer, unsigned bufflen,
 		 unsigned char *sense, struct scsi_sense_hdr *sshdr,
 		 int timeout, int retries, u64 flags, req_flags_t rq_flags,
@@ -268,31 +287,6 @@ static int __scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 
 	return ret;
 }
-
-/**
- * scsi_execute - insert request and wait for the result
- * @sdev:	scsi device
- * @cmd:	scsi command
- * @data_direction: data direction
- * @buffer:	data buffer
- * @bufflen:	len of buffer
- * @sense:	optional sense buffer
- * @timeout:	request timeout in seconds
- * @retries:	number of times to retry request
- * @flags:	or into request flags;
- * @resid:	optional residual length
- *
- * returns the req->errors value which is the scsi_cmnd result
- * field.
- */
-int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
-		 int data_direction, void *buffer, unsigned bufflen,
-		 unsigned char *sense, int timeout, int retries, u64 flags,
-		 int *resid)
-{
-	return __scsi_execute(sdev, cmd, data_direction, buffer, bufflen, sense,
-			NULL, timeout, retries, flags, 0, resid);
-}
 EXPORT_SYMBOL(scsi_execute);
 
 int scsi_execute_req_flags(struct scsi_device *sdev, const unsigned char *cmd,
@@ -300,7 +294,7 @@ int scsi_execute_req_flags(struct scsi_device *sdev, const unsigned char *cmd,
 		     struct scsi_sense_hdr *sshdr, int timeout, int retries,
 		     int *resid, u64 flags, req_flags_t rq_flags)
 {
-	return __scsi_execute(sdev, cmd, data_direction, buffer, bufflen,
+	return scsi_execute(sdev, cmd, data_direction, buffer, bufflen,
 			      NULL, sshdr, timeout, retries, flags, rq_flags,
 			      resid);
 }

commit 3949e2f04262495f6c8795b148aa26dffccba646
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Feb 14 20:15:58 2017 +0100

    scsi: simplify scsi_execute_req_flags
    
    Add a sshdr argument to __scsi_execute so that we can decode the sense
    data directly into the sense header instead of needing a copy of it.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a3c7ec1795c9..5f661486cf6e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -215,8 +215,9 @@ void scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 
 static int __scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 		 int data_direction, void *buffer, unsigned bufflen,
-		 unsigned char *sense, int timeout, int retries, u64 flags,
-		 req_flags_t rq_flags, int *resid)
+		 unsigned char *sense, struct scsi_sense_hdr *sshdr,
+		 int timeout, int retries, u64 flags, req_flags_t rq_flags,
+		 int *resid)
 {
 	struct request *req;
 	struct scsi_request *rq;
@@ -259,6 +260,8 @@ static int __scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 		*resid = rq->resid_len;
 	if (sense && rq->sense_len)
 		memcpy(sense, rq->sense, SCSI_SENSE_BUFFERSIZE);
+	if (sshdr)
+		scsi_normalize_sense(rq->sense, rq->sense_len, sshdr);
 	ret = req->errors;
  out:
 	blk_put_request(req);
@@ -288,7 +291,7 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 		 int *resid)
 {
 	return __scsi_execute(sdev, cmd, data_direction, buffer, bufflen, sense,
-			timeout, retries, flags, 0, resid);
+			NULL, timeout, retries, flags, 0, resid);
 }
 EXPORT_SYMBOL(scsi_execute);
 
@@ -297,21 +300,9 @@ int scsi_execute_req_flags(struct scsi_device *sdev, const unsigned char *cmd,
 		     struct scsi_sense_hdr *sshdr, int timeout, int retries,
 		     int *resid, u64 flags, req_flags_t rq_flags)
 {
-	char *sense = NULL;
-	int result;
-	
-	if (sshdr) {
-		sense = kzalloc(SCSI_SENSE_BUFFERSIZE, GFP_NOIO);
-		if (!sense)
-			return DRIVER_ERROR << 24;
-	}
-	result = __scsi_execute(sdev, cmd, data_direction, buffer, bufflen,
-			      sense, timeout, retries, flags, rq_flags, resid);
-	if (sshdr)
-		scsi_normalize_sense(sense, SCSI_SENSE_BUFFERSIZE, sshdr);
-
-	kfree(sense);
-	return result;
+	return __scsi_execute(sdev, cmd, data_direction, buffer, bufflen,
+			      NULL, sshdr, timeout, retries, flags, rq_flags,
+			      resid);
 }
 EXPORT_SYMBOL(scsi_execute_req_flags);
 

commit 74a78ebda4fa5c5ae87fc501152863ee31c17da4
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Feb 14 20:15:57 2017 +0100

    scsi: make the sense header argument to scsi_test_unit_ready mandatory
    
    It's a tiny structure that can be allocated on the stack, don't
    complicate the code by making it optional.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 39b2d727f033..a3c7ec1795c9 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2520,28 +2520,20 @@ EXPORT_SYMBOL(scsi_mode_sense);
  *	@sdev:	scsi device to change the state of.
  *	@timeout: command timeout
  *	@retries: number of retries before failing
- *	@sshdr_external: Optional pointer to struct scsi_sense_hdr for
- *		returning sense. Make sure that this is cleared before passing
- *		in.
+ *	@sshdr: outpout pointer for decoded sense information.
  *
  *	Returns zero if unsuccessful or an error if TUR failed.  For
  *	removable media, UNIT_ATTENTION sets ->changed flag.
  **/
 int
 scsi_test_unit_ready(struct scsi_device *sdev, int timeout, int retries,
-		     struct scsi_sense_hdr *sshdr_external)
+		     struct scsi_sense_hdr *sshdr)
 {
 	char cmd[] = {
 		TEST_UNIT_READY, 0, 0, 0, 0, 0,
 	};
-	struct scsi_sense_hdr *sshdr;
 	int result;
 
-	if (!sshdr_external)
-		sshdr = kzalloc(sizeof(*sshdr), GFP_KERNEL);
-	else
-		sshdr = sshdr_external;
-
 	/* try to eat the UNIT_ATTENTION if there are enough retries */
 	do {
 		result = scsi_execute_req(sdev, cmd, DMA_NONE, NULL, 0, sshdr,
@@ -2552,8 +2544,6 @@ scsi_test_unit_ready(struct scsi_device *sdev, int timeout, int retries,
 	} while (scsi_sense_valid(sshdr) &&
 		 sshdr->sense_key == UNIT_ATTENTION && --retries);
 
-	if (!sshdr_external)
-		kfree(sshdr);
 	return result;
 }
 EXPORT_SYMBOL(scsi_test_unit_ready);

commit 857de6e00778738dc3d61f75acbac35bdc48e533
Author: Hannes Reinecke <hare@suse.de>
Date:   Fri Feb 17 09:02:45 2017 +0100

    scsi: use 'scsi_device_from_queue()' for scsi_dh
    
    The device handler needs to check if a given queue belongs to a scsi
    device; only then does it make sense to attach a device handler.
    
    [mkp: dropped flags]
    
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 912fbc3b4543..39b2d727f033 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2231,6 +2231,29 @@ void scsi_mq_destroy_tags(struct Scsi_Host *shost)
 	blk_mq_free_tag_set(&shost->tag_set);
 }
 
+/**
+ * scsi_device_from_queue - return sdev associated with a request_queue
+ * @q: The request queue to return the sdev from
+ *
+ * Return the sdev associated with a request queue or NULL if the
+ * request_queue does not reference a SCSI device.
+ */
+struct scsi_device *scsi_device_from_queue(struct request_queue *q)
+{
+	struct scsi_device *sdev = NULL;
+
+	if (q->mq_ops) {
+		if (q->mq_ops == &scsi_mq_ops)
+			sdev = q->queuedata;
+	} else if (q->request_fn == scsi_request_fn)
+		sdev = q->queuedata;
+	if (!sdev || !get_device(&sdev->sdev_gendev))
+		sdev = NULL;
+
+	return sdev;
+}
+EXPORT_SYMBOL_GPL(scsi_device_from_queue);
+
 /*
  * Function:    scsi_block_requests()
  *

commit ee5242360424b9b967454e9183767323d10cf985
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Feb 21 10:04:55 2017 +0100

    scsi: zero per-cmd driver data before each I/O
    
    Without this drivers that don't clear the state themselves can see off
    effects.  For example Hyper-V VMs using the storvsc driver will often
    hang during boot due to uncleared Test Unit Ready failures.
    
    Fixes: e9c787e6 ("scsi: allocate scsi_cmnd structures as part of struct request")
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reported-by: Dexuan Cui <decui@microsoft.com>
    Tested-by: Dexuan Cui <decui@microsoft.com>
    Reviewed-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 912fbc3b4543..3e32dc954c3c 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1167,7 +1167,7 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 
 	/* zero out the cmd, except for the embedded scsi_request */
 	memset((char *)cmd + sizeof(cmd->req), 0,
-		sizeof(*cmd) - sizeof(cmd->req));
+		sizeof(*cmd) - sizeof(cmd->req) + dev->host->hostt->cmd_size);
 
 	cmd->device = dev;
 	cmd->sense_buffer = buf;

commit 772c8f6f3bbd3ceb94a89373473083e3e1113554
Merge: fd4a61e08aa7 818551e2b2c6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 21 10:57:33 2017 -0800

    Merge tag 'for-4.11/linus-merge-signed' of git://git.kernel.dk/linux-block
    
    Pull block layer updates from Jens Axboe:
    
     - blk-mq scheduling framework from me and Omar, with a port of the
       deadline scheduler for this framework. A port of BFQ from Paolo is in
       the works, and should be ready for 4.12.
    
     - Various fixups and improvements to the above scheduling framework
       from Omar, Paolo, Bart, me, others.
    
     - Cleanup of the exported sysfs blk-mq data into debugfs, from Omar.
       This allows us to export more information that helps debug hangs or
       performance issues, without cluttering or abusing the sysfs API.
    
     - Fixes for the sbitmap code, the scalable bitmap code that was
       migrated from blk-mq, from Omar.
    
     - Removal of the BLOCK_PC support in struct request, and refactoring of
       carrying SCSI payloads in the block layer. This cleans up the code
       nicely, and enables us to kill the SCSI specific parts of struct
       request, shrinking it down nicely. From Christoph mainly, with help
       from Hannes.
    
     - Support for ranged discard requests and discard merging, also from
       Christoph.
    
     - Support for OPAL in the block layer, and for NVMe as well. Mainly
       from Scott Bauer, with fixes/updates from various others folks.
    
     - Error code fixup for gdrom from Christophe.
    
     - cciss pci irq allocation cleanup from Christoph.
    
     - Making the cdrom device operations read only, from Kees Cook.
    
     - Fixes for duplicate bdi registrations and bdi/queue life time
       problems from Jan and Dan.
    
     - Set of fixes and updates for lightnvm, from Matias and Javier.
    
     - A few fixes for nbd from Josef, using idr to name devices and a
       workqueue deadlock fix on receive. Also marks Josef as the current
       maintainer of nbd.
    
     - Fix from Josef, overwriting queue settings when the number of
       hardware queues is updated for a blk-mq device.
    
     - NVMe fix from Keith, ensuring that we don't repeatedly mark and IO
       aborted, if we didn't end up aborting it.
    
     - SG gap merging fix from Ming Lei for block.
    
     - Loop fix also from Ming, fixing a race and crash between setting loop
       status and IO.
    
     - Two block race fixes from Tahsin, fixing request list iteration and
       fixing a race between device registration and udev device add
       notifiations.
    
     - Double free fix from cgroup writeback, from Tejun.
    
     - Another double free fix in blkcg, from Hou Tao.
    
     - Partition overflow fix for EFI from Alden Tondettar.
    
    * tag 'for-4.11/linus-merge-signed' of git://git.kernel.dk/linux-block: (156 commits)
      nvme: Check for Security send/recv support before issuing commands.
      block/sed-opal: allocate struct opal_dev dynamically
      block/sed-opal: tone down not supported warnings
      block: don't defer flushes on blk-mq + scheduling
      blk-mq-sched: ask scheduler for work, if we failed dispatching leftovers
      blk-mq: don't special case flush inserts for blk-mq-sched
      blk-mq-sched: don't add flushes to the head of requeue queue
      blk-mq: have blk_mq_dispatch_rq_list() return if we queued IO or not
      block: do not allow updates through sysfs until registration completes
      lightnvm: set default lun range when no luns are specified
      lightnvm: fix off-by-one error on target initialization
      Maintainers: Modify SED list from nvme to block
      Move stack parameters for sed_ioctl to prevent oversized stack with CONFIG_KASAN
      uapi: sed-opal fix IOW for activate lsp to use correct struct
      cdrom: Make device operations read-only
      elevator: fix loading wrong elevator type for blk-mq devices
      cciss: switch to pci_irq_alloc_vectors
      block/loop: fix race between I/O and set_status
      blk-mq-sched: don't hold queue_lock when calling exit_icq
      block: set make_request_fn manually in blk_mq_update_nr_hw_queues
      ...

commit fd3fc0b4d7305fa7246622dcc0dec69c42443f45
Author: Johannes Thumshirn <jthumshirn@suse.de>
Date:   Tue Jan 31 10:16:00 2017 +0100

    scsi: don't BUG_ON() empty DMA transfers
    
    Don't crash the machine just because of an empty transfer. Use WARN_ON()
    combined with returning an error.
    
    Found by Dmitry Vyukov and syzkaller.
    
    [ Changed to "WARN_ON_ONCE()". Al has a patch that should fix the root
      cause, but a BUG_ON() is not acceptable in any case, and a WARN_ON()
      might still be a cause of excessive log spamming.
    
      NOTE! If this warning ever triggers, we may end up leaking resources,
      since this doesn't bother to try to clean the command up. So this
      WARN_ON_ONCE() triggering does imply real problems. But BUG_ON() is
      much worse.
    
      People really need to stop using BUG_ON() for "this shouldn't ever
      happen". It makes pretty much any bug worse.     - Linus ]
    
    Signed-off-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Cc: James Bottomley <jejb@linux.vnet.ibm.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: stable@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e9e1e141af9c..78db07fd8055 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1040,7 +1040,8 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 	bool is_mq = (rq->mq_ctx != NULL);
 	int error;
 
-	BUG_ON(!blk_rq_nr_phys_segments(rq));
+	if (WARN_ON_ONCE(!blk_rq_nr_phys_segments(rq)))
+		return -EINVAL;
 
 	error = scsi_init_sgtable(rq, &cmd->sdb);
 	if (error)

commit aebf526b53aea164508730427597d45f3e06b376
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Jan 31 16:57:31 2017 +0100

    block: fold cmd_type into the REQ_OP_ space
    
    Instead of keeping two levels of indirection for requests types, fold it
    all into the operations.  The little caveat here is that previously
    cmd_type only applied to struct request, while the request and bio op
    fields were set to plain REQ_OP_READ/WRITE even for passthrough
    operations.
    
    Instead this patch adds new REQ_OP_* for SCSI passthrough and driver
    private requests, althought it has to add two for each so that we
    can communicate the data in/out nature of the request.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 31629a7b728d..90f65c8f487a 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -219,11 +219,12 @@ static int __scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 		 req_flags_t rq_flags, int *resid)
 {
 	struct request *req;
-	int write = (data_direction == DMA_TO_DEVICE);
 	struct scsi_request *rq;
 	int ret = DRIVER_ERROR << 24;
 
-	req = blk_get_request(sdev->request_queue, write, __GFP_RECLAIM);
+	req = blk_get_request(sdev->request_queue,
+			data_direction == DMA_TO_DEVICE ?
+			REQ_OP_SCSI_OUT : REQ_OP_SCSI_IN, __GFP_RECLAIM);
 	if (IS_ERR(req))
 		return ret;
 	rq = scsi_req(req);
@@ -839,8 +840,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		}
 	} else if (blk_rq_bytes(req) == 0 && result && !sense_deferred) {
 		/*
-		 * Certain non BLOCK_PC requests are commands that don't
-		 * actually transfer anything (FLUSH), so cannot use
+		 * Flush commands do not transfers any data, and thus cannot use
 		 * good_bytes != blk_rq_bytes(req) as the signal for an error.
 		 * This sets the error explicitly for the problem case.
 		 */
@@ -859,8 +859,8 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		blk_rq_sectors(req), good_bytes));
 
 	/*
-	 * Recovered errors need reporting, but they're always treated
-	 * as success, so fiddle the result code here.  For BLOCK_PC
+	 * Recovered errors need reporting, but they're always treated as
+	 * success, so fiddle the result code here.  For passthrough requests
 	 * we already took a copy of the original into rq->errors which
 	 * is what gets returned to the user
 	 */
@@ -874,7 +874,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		else if (!(req->rq_flags & RQF_QUIET))
 			scsi_print_sense(cmd);
 		result = 0;
-		/* BLOCK_PC may have set error */
+		/* for passthrough error may be set */
 		error = 0;
 	}
 
@@ -1179,12 +1179,12 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 	spin_unlock_irqrestore(&dev->list_lock, flags);
 }
 
-static int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
+static int scsi_setup_scsi_cmnd(struct scsi_device *sdev, struct request *req)
 {
 	struct scsi_cmnd *cmd = req->special;
 
 	/*
-	 * BLOCK_PC requests may transfer data, in which case they must
+	 * Passthrough requests may transfer data, in which case they must
 	 * a bio attached to them.  Or they might contain a SCSI command
 	 * that does not transfer data, in which case they may optionally
 	 * submit a request without an attached bio.
@@ -1207,7 +1207,7 @@ static int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 }
 
 /*
- * Setup a REQ_TYPE_FS command.  These are simple request from filesystems
+ * Setup a normal block command.  These are simple request from filesystems
  * that still need to be translated to SCSI CDBs from the ULD.
  */
 static int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
@@ -1236,14 +1236,10 @@ static int scsi_setup_cmnd(struct scsi_device *sdev, struct request *req)
 	else
 		cmd->sc_data_direction = DMA_FROM_DEVICE;
 
-	switch (req->cmd_type) {
-	case REQ_TYPE_FS:
+	if (blk_rq_is_scsi(req))
+		return scsi_setup_scsi_cmnd(sdev, req);
+	else
 		return scsi_setup_fs_cmnd(sdev, req);
-	case REQ_TYPE_BLOCK_PC:
-		return scsi_setup_blk_pc_cmnd(sdev, req);
-	default:
-		return BLKPREP_KILL;
-	}
 }
 
 static int

commit 57292b58ddb58689e8c3b4c6eadbef10d9ca44dd
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Jan 31 16:57:29 2017 +0100

    block: introduce blk_rq_is_passthrough
    
    This can be used to check for fs vs non-fs requests and basically
    removes all knowledge of BLOCK_PC specific from the block layer,
    as well as preparing for removing the cmd_type field in struct request.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 8188e5c71f75..31629a7b728d 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -582,7 +582,7 @@ void scsi_run_host_queues(struct Scsi_Host *shost)
 
 static void scsi_uninit_cmd(struct scsi_cmnd *cmd)
 {
-	if (cmd->request->cmd_type == REQ_TYPE_FS) {
+	if (!blk_rq_is_passthrough(cmd->request)) {
 		struct scsi_driver *drv = scsi_cmd_to_driver(cmd);
 
 		if (drv->uninit_command)
@@ -806,7 +806,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			sense_deferred = scsi_sense_is_deferred(&sshdr);
 	}
 
-	if (req->cmd_type == REQ_TYPE_BLOCK_PC) { /* SG_IO ioctl from block level */
+	if (blk_rq_is_passthrough(req)) {
 		if (result) {
 			if (sense_valid) {
 				/*
@@ -847,7 +847,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		error = __scsi_error_from_host_byte(cmd, result);
 	}
 
-	/* no bidi support for !REQ_TYPE_BLOCK_PC yet */
+	/* no bidi support for !blk_rq_is_passthrough yet */
 	BUG_ON(blk_bidi_rq(req));
 
 	/*

commit 82ed4db499b8598f16f8871261bff088d6b0597f
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jan 27 09:46:29 2017 +0100

    block: split scsi_request out of struct request
    
    And require all drivers that want to support BLOCK_PC to allocate it
    as the first thing of their private data.  To support this the legacy
    IDE and BSG code is switched to set cmd_size on their queues to let
    the block layer allocate the additional space.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 81ff5ad23b83..8188e5c71f75 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -220,21 +220,21 @@ static int __scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 {
 	struct request *req;
 	int write = (data_direction == DMA_TO_DEVICE);
+	struct scsi_request *rq;
 	int ret = DRIVER_ERROR << 24;
 
 	req = blk_get_request(sdev->request_queue, write, __GFP_RECLAIM);
 	if (IS_ERR(req))
 		return ret;
-	blk_rq_set_block_pc(req);
+	rq = scsi_req(req);
+	scsi_req_init(req);
 
 	if (bufflen &&	blk_rq_map_kern(sdev->request_queue, req,
 					buffer, bufflen, __GFP_RECLAIM))
 		goto out;
 
-	req->cmd_len = COMMAND_SIZE(cmd[0]);
-	memcpy(req->cmd, cmd, req->cmd_len);
-	req->sense = sense;
-	req->sense_len = 0;
+	rq->cmd_len = COMMAND_SIZE(cmd[0]);
+	memcpy(rq->cmd, cmd, rq->cmd_len);
 	req->retries = retries;
 	req->timeout = timeout;
 	req->cmd_flags |= flags;
@@ -251,11 +251,13 @@ static int __scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	 * is invalid.  Prevent the garbage from being misinterpreted
 	 * and prevent security leaks by zeroing out the excess data.
 	 */
-	if (unlikely(req->resid_len > 0 && req->resid_len <= bufflen))
-		memset(buffer + (bufflen - req->resid_len), 0, req->resid_len);
+	if (unlikely(rq->resid_len > 0 && rq->resid_len <= bufflen))
+		memset(buffer + (bufflen - rq->resid_len), 0, rq->resid_len);
 
 	if (resid)
-		*resid = req->resid_len;
+		*resid = rq->resid_len;
+	if (sense && rq->sense_len)
+		memcpy(sense, rq->sense, SCSI_SENSE_BUFFERSIZE);
 	ret = req->errors;
  out:
 	blk_put_request(req);
@@ -806,16 +808,13 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 
 	if (req->cmd_type == REQ_TYPE_BLOCK_PC) { /* SG_IO ioctl from block level */
 		if (result) {
-			if (sense_valid && req->sense) {
+			if (sense_valid) {
 				/*
 				 * SG_IO wants current and deferred errors
 				 */
-				int len = 8 + cmd->sense_buffer[7];
-
-				if (len > SCSI_SENSE_BUFFERSIZE)
-					len = SCSI_SENSE_BUFFERSIZE;
-				memcpy(req->sense, cmd->sense_buffer,  len);
-				req->sense_len = len;
+				scsi_req(req)->sense_len =
+					min(8 + cmd->sense_buffer[7],
+					    SCSI_SENSE_BUFFERSIZE);
 			}
 			if (!sense_deferred)
 				error = __scsi_error_from_host_byte(cmd, result);
@@ -825,14 +824,14 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		 */
 		req->errors = cmd->result;
 
-		req->resid_len = scsi_get_resid(cmd);
+		scsi_req(req)->resid_len = scsi_get_resid(cmd);
 
 		if (scsi_bidi_cmnd(cmd)) {
 			/*
 			 * Bidi commands Must be complete as a whole,
 			 * both sides at once.
 			 */
-			req->next_rq->resid_len = scsi_in(cmd)->resid;
+			scsi_req(req->next_rq)->resid_len = scsi_in(cmd)->resid;
 			if (scsi_end_request(req, 0, blk_rq_bytes(req),
 					blk_rq_bytes(req->next_rq)))
 				BUG();
@@ -1165,7 +1164,10 @@ void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 	void *prot = cmd->prot_sdb;
 	unsigned long flags;
 
-	memset(cmd, 0, sizeof(*cmd));
+	/* zero out the cmd, except for the embedded scsi_request */
+	memset((char *)cmd + sizeof(cmd->req), 0,
+		sizeof(*cmd) - sizeof(cmd->req));
+
 	cmd->device = dev;
 	cmd->sense_buffer = buf;
 	cmd->prot_sdb = prot;
@@ -1197,7 +1199,8 @@ static int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 		memset(&cmd->sdb, 0, sizeof(cmd->sdb));
 	}
 
-	cmd->cmd_len = req->cmd_len;
+	cmd->cmd_len = scsi_req(req)->cmd_len;
+	cmd->cmnd = scsi_req(req)->cmd;
 	cmd->transfersize = blk_rq_bytes(req);
 	cmd->allowed = req->retries;
 	return BLKPREP_OK;
@@ -1217,6 +1220,7 @@ static int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
 			return ret;
 	}
 
+	cmd->cmnd = scsi_req(req)->cmd = scsi_req(req)->__cmd;
 	memset(cmd->cmnd, 0, BLK_MAX_CDB);
 	return scsi_cmd_to_driver(cmd)->init_command(cmd);
 }
@@ -1355,7 +1359,6 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 
 	cmd->tag = req->tag;
 	cmd->request = req;
-	cmd->cmnd = req->cmd;
 	cmd->prot_op = SCSI_PROT_NORMAL;
 
 	ret = scsi_setup_cmnd(sdev, req);
@@ -1874,7 +1877,9 @@ static int scsi_mq_prep_fn(struct request *req)
 	unsigned char *sense_buf = cmd->sense_buffer;
 	struct scatterlist *sg;
 
-	memset(cmd, 0, sizeof(struct scsi_cmnd));
+	/* zero out the cmd, except for the embedded scsi_request */
+	memset((char *)cmd + sizeof(cmd->req), 0,
+		sizeof(*cmd) - sizeof(cmd->req));
 
 	req->special = cmd;
 
@@ -1884,7 +1889,6 @@ static int scsi_mq_prep_fn(struct request *req)
 
 	cmd->tag = req->tag;
 
-	cmd->cmnd = req->cmd;
 	cmd->prot_op = SCSI_PROT_NORMAL;
 
 	INIT_LIST_HEAD(&cmd->list);
@@ -1959,7 +1963,6 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	if (!scsi_host_queue_ready(q, shost, sdev))
 		goto out_dec_target_busy;
 
-
 	if (!(req->rq_flags & RQF_DONTPREP)) {
 		ret = prep_to_mq(scsi_mq_prep_fn(req));
 		if (ret != BLK_MQ_RQ_QUEUE_OK)
@@ -2036,6 +2039,7 @@ static int scsi_init_request(void *data, struct request *rq,
 		scsi_alloc_sense_buffer(shost, GFP_KERNEL, numa_node);
 	if (!cmd->sense_buffer)
 		return -ENOMEM;
+	cmd->req.sense = cmd->sense_buffer;
 	return 0;
 }
 
@@ -2125,6 +2129,7 @@ static int scsi_init_rq(struct request_queue *q, struct request *rq, gfp_t gfp)
 	cmd->sense_buffer = scsi_alloc_sense_buffer(shost, gfp, NUMA_NO_NODE);
 	if (!cmd->sense_buffer)
 		goto fail;
+	cmd->req.sense = cmd->sense_buffer;
 
 	if (scsi_host_get_prot(shost) >= SHOST_DIX_TYPE0_PROTECTION) {
 		cmd->prot_sdb = kmem_cache_zalloc(scsi_sdb_cache, gfp);

commit e9c787e65c0c36529745be47d490d998b4b6e589
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jan 2 21:55:26 2017 +0300

    scsi: allocate scsi_cmnd structures as part of struct request
    
    Rely on the new block layer functionality to allocate additional driver
    specific data behind struct request instead of implementing it in SCSI
    itѕelf.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 79505169e740..81ff5ad23b83 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -37,8 +37,7 @@
 #include "scsi_priv.h"
 #include "scsi_logging.h"
 
-
-struct kmem_cache *scsi_sdb_cache;
+static struct kmem_cache *scsi_sdb_cache;
 static struct kmem_cache *scsi_sense_cache;
 static struct kmem_cache *scsi_sense_isadma_cache;
 static DEFINE_MUTEX(scsi_sense_cache_mutex);
@@ -50,14 +49,14 @@ scsi_select_sense_cache(struct Scsi_Host *shost)
 		scsi_sense_isadma_cache : scsi_sense_cache;
 }
 
-void scsi_free_sense_buffer(struct Scsi_Host *shost,
+static void scsi_free_sense_buffer(struct Scsi_Host *shost,
 		unsigned char *sense_buffer)
 {
 	kmem_cache_free(scsi_select_sense_cache(shost), sense_buffer);
 }
 
-unsigned char *scsi_alloc_sense_buffer(struct Scsi_Host *shost, gfp_t gfp_mask,
-		int numa_node)
+static unsigned char *scsi_alloc_sense_buffer(struct Scsi_Host *shost,
+	gfp_t gfp_mask, int numa_node)
 {
 	return kmem_cache_alloc_node(scsi_select_sense_cache(shost), gfp_mask,
 			numa_node);
@@ -697,14 +696,13 @@ static bool scsi_end_request(struct request *req, int error,
 
 		if (bidi_bytes)
 			scsi_release_bidi_buffers(cmd);
+		scsi_release_buffers(cmd);
+		scsi_put_command(cmd);
 
 		spin_lock_irqsave(q->queue_lock, flags);
 		blk_finish_request(req, error);
 		spin_unlock_irqrestore(q->queue_lock, flags);
 
-		scsi_release_buffers(cmd);
-
-		scsi_put_command(cmd);
 		scsi_run_queue(q);
 	}
 
@@ -1161,34 +1159,22 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 }
 EXPORT_SYMBOL(scsi_init_io);
 
-static struct scsi_cmnd *scsi_get_cmd_from_req(struct scsi_device *sdev,
-		struct request *req)
+void scsi_init_command(struct scsi_device *dev, struct scsi_cmnd *cmd)
 {
-	struct scsi_cmnd *cmd;
-
-	if (!req->special) {
-		/* Bail if we can't get a reference to the device */
-		if (!get_device(&sdev->sdev_gendev))
-			return NULL;
-
-		cmd = scsi_get_command(sdev, GFP_ATOMIC);
-		if (unlikely(!cmd)) {
-			put_device(&sdev->sdev_gendev);
-			return NULL;
-		}
-		req->special = cmd;
-	} else {
-		cmd = req->special;
-	}
-
-	/* pull a tag out of the request if we have one */
-	cmd->tag = req->tag;
-	cmd->request = req;
+	void *buf = cmd->sense_buffer;
+	void *prot = cmd->prot_sdb;
+	unsigned long flags;
 
-	cmd->cmnd = req->cmd;
-	cmd->prot_op = SCSI_PROT_NORMAL;
+	memset(cmd, 0, sizeof(*cmd));
+	cmd->device = dev;
+	cmd->sense_buffer = buf;
+	cmd->prot_sdb = prot;
+	INIT_DELAYED_WORK(&cmd->abort_work, scmd_eh_abort_handler);
+	cmd->jiffies_at_alloc = jiffies;
 
-	return cmd;
+	spin_lock_irqsave(&dev->list_lock, flags);
+	list_add_tail(&cmd->list, &dev->cmd_list);
+	spin_unlock_irqrestore(&dev->list_lock, flags);
 }
 
 static int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
@@ -1349,19 +1335,29 @@ scsi_prep_return(struct request_queue *q, struct request *req, int ret)
 static int scsi_prep_fn(struct request_queue *q, struct request *req)
 {
 	struct scsi_device *sdev = q->queuedata;
-	struct scsi_cmnd *cmd;
+	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
 	int ret;
 
 	ret = scsi_prep_state_check(sdev, req);
 	if (ret != BLKPREP_OK)
 		goto out;
 
-	cmd = scsi_get_cmd_from_req(sdev, req);
-	if (unlikely(!cmd)) {
-		ret = BLKPREP_DEFER;
-		goto out;
+	if (!req->special) {
+		/* Bail if we can't get a reference to the device */
+		if (unlikely(!get_device(&sdev->sdev_gendev))) {
+			ret = BLKPREP_DEFER;
+			goto out;
+		}
+
+		scsi_init_command(sdev, cmd);
+		req->special = cmd;
 	}
 
+	cmd->tag = req->tag;
+	cmd->request = req;
+	cmd->cmnd = req->cmd;
+	cmd->prot_op = SCSI_PROT_NORMAL;
+
 	ret = scsi_setup_cmnd(sdev, req);
 out:
 	return scsi_prep_return(q, req, ret);
@@ -2119,15 +2115,61 @@ void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 }
 EXPORT_SYMBOL_GPL(__scsi_init_queue);
 
+static int scsi_init_rq(struct request_queue *q, struct request *rq, gfp_t gfp)
+{
+	struct Scsi_Host *shost = q->rq_alloc_data;
+	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
+
+	memset(cmd, 0, sizeof(*cmd));
+
+	cmd->sense_buffer = scsi_alloc_sense_buffer(shost, gfp, NUMA_NO_NODE);
+	if (!cmd->sense_buffer)
+		goto fail;
+
+	if (scsi_host_get_prot(shost) >= SHOST_DIX_TYPE0_PROTECTION) {
+		cmd->prot_sdb = kmem_cache_zalloc(scsi_sdb_cache, gfp);
+		if (!cmd->prot_sdb)
+			goto fail_free_sense;
+	}
+
+	return 0;
+
+fail_free_sense:
+	scsi_free_sense_buffer(shost, cmd->sense_buffer);
+fail:
+	return -ENOMEM;
+}
+
+static void scsi_exit_rq(struct request_queue *q, struct request *rq)
+{
+	struct Scsi_Host *shost = q->rq_alloc_data;
+	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
+
+	if (cmd->prot_sdb)
+		kmem_cache_free(scsi_sdb_cache, cmd->prot_sdb);
+	scsi_free_sense_buffer(shost, cmd->sense_buffer);
+}
+
 struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
 {
+	struct Scsi_Host *shost = sdev->host;
 	struct request_queue *q;
 
-	q = blk_init_queue(scsi_request_fn, NULL);
+	q = blk_alloc_queue_node(GFP_KERNEL, NUMA_NO_NODE);
 	if (!q)
 		return NULL;
+	q->cmd_size = sizeof(struct scsi_cmnd) + shost->hostt->cmd_size;
+	q->rq_alloc_data = shost;
+	q->request_fn = scsi_request_fn;
+	q->init_rq_fn = scsi_init_rq;
+	q->exit_rq_fn = scsi_exit_rq;
+
+	if (blk_init_allocated_queue(q) < 0) {
+		blk_cleanup_queue(q);
+		return NULL;
+	}
 
-	__scsi_init_queue(sdev->host, q);
+	__scsi_init_queue(shost, q);
 	blk_queue_prep_rq(q, scsi_prep_fn);
 	blk_queue_unprep_rq(q, scsi_unprep_fn);
 	blk_queue_softirq_done(q, scsi_softirq_done);

commit d48777a633d6fa7ccde0f0e6509f0c01fbfc5299
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jan 2 21:52:10 2017 +0300

    scsi: remove __scsi_alloc_queue
    
    Instead do an internal export of __scsi_init_queue for the transport
    classes that export BSG nodes.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 3d6b364a8d82..79505169e740 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2082,7 +2082,7 @@ static u64 scsi_calculate_bounce_limit(struct Scsi_Host *shost)
 	return bounce_limit;
 }
 
-static void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
+void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 {
 	struct device *dev = shost->dma_dev;
 
@@ -2117,28 +2117,17 @@ static void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 	 */
 	blk_queue_dma_alignment(q, 0x03);
 }
-
-struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
-					 request_fn_proc *request_fn)
-{
-	struct request_queue *q;
-
-	q = blk_init_queue(request_fn, NULL);
-	if (!q)
-		return NULL;
-	__scsi_init_queue(shost, q);
-	return q;
-}
-EXPORT_SYMBOL(__scsi_alloc_queue);
+EXPORT_SYMBOL_GPL(__scsi_init_queue);
 
 struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
 {
 	struct request_queue *q;
 
-	q = __scsi_alloc_queue(sdev->host, scsi_request_fn);
+	q = blk_init_queue(scsi_request_fn, NULL);
 	if (!q)
 		return NULL;
 
+	__scsi_init_queue(sdev->host, q);
 	blk_queue_prep_rq(q, scsi_prep_fn);
 	blk_queue_unprep_rq(q, scsi_unprep_fn);
 	blk_queue_softirq_done(q, scsi_softirq_done);

commit 0a6ac4ee7c21098cb0e41cc4053b9d9ddc9e70a1
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Jan 3 08:28:41 2017 +0300

    scsi: respect unchecked_isa_dma for blk-mq
    
    Currently blk-mq always allocates the sense buffer using normal GFP_KERNEL
    allocation.  Refactor the cmd pool code to split the cmd and sense allocation
    and share the code to allocate the sense buffers as well as the sense buffer
    slab caches between the legacy and blk-mq path.
    
    Note that this switches to lazy allocation of the sense slab caches - the
    slab caches (not the actual allocations) won't be destroy until the scsi
    module is unloaded instead of keeping track of hosts using them.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Acked-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e9e1e141af9c..3d6b364a8d82 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -39,6 +39,58 @@
 
 
 struct kmem_cache *scsi_sdb_cache;
+static struct kmem_cache *scsi_sense_cache;
+static struct kmem_cache *scsi_sense_isadma_cache;
+static DEFINE_MUTEX(scsi_sense_cache_mutex);
+
+static inline struct kmem_cache *
+scsi_select_sense_cache(struct Scsi_Host *shost)
+{
+	return shost->unchecked_isa_dma ?
+		scsi_sense_isadma_cache : scsi_sense_cache;
+}
+
+void scsi_free_sense_buffer(struct Scsi_Host *shost,
+		unsigned char *sense_buffer)
+{
+	kmem_cache_free(scsi_select_sense_cache(shost), sense_buffer);
+}
+
+unsigned char *scsi_alloc_sense_buffer(struct Scsi_Host *shost, gfp_t gfp_mask,
+		int numa_node)
+{
+	return kmem_cache_alloc_node(scsi_select_sense_cache(shost), gfp_mask,
+			numa_node);
+}
+
+int scsi_init_sense_cache(struct Scsi_Host *shost)
+{
+	struct kmem_cache *cache;
+	int ret = 0;
+
+	cache = scsi_select_sense_cache(shost);
+	if (cache)
+		return 0;
+
+	mutex_lock(&scsi_sense_cache_mutex);
+	if (shost->unchecked_isa_dma) {
+		scsi_sense_isadma_cache =
+			kmem_cache_create("scsi_sense_cache(DMA)",
+			SCSI_SENSE_BUFFERSIZE, 0,
+			SLAB_HWCACHE_ALIGN | SLAB_CACHE_DMA, NULL);
+		if (!scsi_sense_isadma_cache)
+			ret = -ENOMEM;
+	} else {
+		scsi_sense_cache =
+			kmem_cache_create("scsi_sense_cache",
+			SCSI_SENSE_BUFFERSIZE, 0, SLAB_HWCACHE_ALIGN, NULL);
+		if (!scsi_sense_cache)
+			ret = -ENOMEM;
+	}
+
+	mutex_unlock(&scsi_sense_cache_mutex);
+	return ret;
+}
 
 /*
  * When to reinvoke queueing after a resource shortage. It's 3 msecs to
@@ -1981,10 +2033,11 @@ static int scsi_init_request(void *data, struct request *rq,
 		unsigned int hctx_idx, unsigned int request_idx,
 		unsigned int numa_node)
 {
+	struct Scsi_Host *shost = data;
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
 
-	cmd->sense_buffer = kzalloc_node(SCSI_SENSE_BUFFERSIZE, GFP_KERNEL,
-			numa_node);
+	cmd->sense_buffer =
+		scsi_alloc_sense_buffer(shost, GFP_KERNEL, numa_node);
 	if (!cmd->sense_buffer)
 		return -ENOMEM;
 	return 0;
@@ -1993,9 +2046,10 @@ static int scsi_init_request(void *data, struct request *rq,
 static void scsi_exit_request(void *data, struct request *rq,
 		unsigned int hctx_idx, unsigned int request_idx)
 {
+	struct Scsi_Host *shost = data;
 	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
 
-	kfree(cmd->sense_buffer);
+	scsi_free_sense_buffer(shost, cmd->sense_buffer);
 }
 
 static int scsi_map_queues(struct blk_mq_tag_set *set)
@@ -2208,6 +2262,8 @@ int __init scsi_init_queue(void)
 
 void scsi_exit_queue(void)
 {
+	kmem_cache_destroy(scsi_sense_cache);
+	kmem_cache_destroy(scsi_sense_isadma_cache);
 	kmem_cache_destroy(scsi_sdb_cache);
 }
 

commit 34241af77b8696120a9735bb2579ec7044199a8b
Merge: f0ad17712b9f bef13315e990
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jan 14 17:07:04 2017 -0800

    Merge branch 'for-linus' of git://git.kernel.dk/linux-block
    
    Pull block fixes from Jens Axboe:
    
     - the virtio_blk stack DMA corruption fix from Christoph, fixing and
       issue with VMAP stacks.
    
     - O_DIRECT blkbits calculation fix from Chandan.
    
     - discard regression fix from Christoph.
    
     - queue init error handling fixes for nbd and virtio_blk, from Omar and
       Jeff.
    
     - two small nvme fixes, from Christoph and Guilherme.
    
     - rename of blk_queue_zone_size and bdev_zone_size to _sectors instead,
       to more closely follow what we do in other places in the block layer.
       This interface is new for this series, so let's get the naming right
       before releasing a kernel with this feature. From Damien.
    
    * 'for-linus' of git://git.kernel.dk/linux-block:
      block: don't try to discard from __blkdev_issue_zeroout
      sd: remove __data_len hack for WRITE SAME
      nvme: use blk_rq_payload_bytes
      scsi: use blk_rq_payload_bytes
      block: add blk_rq_payload_bytes
      block: Rename blk_queue_zone_size and bdev_zone_size
      nvme: apply DELAY_BEFORE_CHK_RDY quirk at probe time too
      nvme-rdma: fix nvme_rdma_queue_is_ready
      virtio_blk: fix panic in initialization error path
      nbd: blk_mq_init_queue returns an error code on failure, not NULL
      virtio_blk: avoid DMA to stack for the sense buffer
      do_direct_IO: Use inode->i_blkbits to compute block count to be cleaned

commit fd102b125e174edbea34e6e7a2d371bc7901c53d
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jan 13 12:29:11 2017 +0100

    scsi: use blk_rq_payload_bytes
    
    Without that we'll pass a wrong payload size in cmd->sdb, which
    can lead to hangs with drivers that need the total transfer size.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reported-by: Chris Valean <v-chvale@microsoft.com>
    Reported-by: Dexuan Cui <decui@microsoft.com>
    Fixes: f9d03f96 ("block: improve handling of the magic discard payload")
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c35b6de4ca64..ad4ff8fcd4dd 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1018,7 +1018,7 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb)
 	count = blk_rq_map_sg(req->q, req, sdb->table.sgl);
 	BUG_ON(count > sdb->table.nents);
 	sdb->table.nents = count;
-	sdb->length = blk_rq_bytes(req);
+	sdb->length = blk_rq_payload_bytes(req);
 	return BLKPREP_OK;
 }
 

commit 7dbbf0fa1bf14c17900bb8057986b06db3822239
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Tue Nov 22 16:17:50 2016 -0800

    scsi: scsi-mq: Wait for .queue_rq() if necessary
    
    Ensure that if scsi-mq is enabled that scsi_internal_device_block()
    waits until ongoing shost->hostt->queuecommand() calls have finished.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Cc: James Bottomley <jejb@linux.vnet.ibm.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Doug Ledford <dledford@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c35b6de4ca64..9fd9a977c695 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2893,7 +2893,7 @@ scsi_internal_device_block(struct scsi_device *sdev)
 	 * request queue. 
 	 */
 	if (q->mq_ops) {
-		blk_mq_stop_hw_queues(q);
+		blk_mq_quiesce_queue(q);
 	} else {
 		spin_lock_irqsave(q->queue_lock, flags);
 		blk_stop_queue(q);

commit a829a8445f09036404060f4d6489cb13433f4304
Merge: 84b607913442 f5b893c94715
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Dec 14 10:49:33 2016 -0800

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This update includes the usual round of major driver updates (ncr5380,
      lpfc, hisi_sas, megaraid_sas, ufs, ibmvscsis, mpt3sas).
    
      There's also an assortment of minor fixes, mostly in error legs or
      other not very user visible stuff. The major change is the
      pci_alloc_irq_vectors replacement for the old pci_msix_.. calls; this
      effectively makes IRQ mapping generic for the drivers and allows
      blk_mq to use the information"
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (256 commits)
      scsi: qla4xxx: switch to pci_alloc_irq_vectors
      scsi: hisi_sas: support deferred probe for v2 hw
      scsi: megaraid_sas: switch to pci_alloc_irq_vectors
      scsi: scsi_devinfo: remove synchronous ALUA for NETAPP devices
      scsi: be2iscsi: set errno on error path
      scsi: be2iscsi: set errno on error path
      scsi: hpsa: fallback to use legacy REPORT PHYS command
      scsi: scsi_dh_alua: Fix RCU annotations
      scsi: hpsa: use %phN for short hex dumps
      scsi: hisi_sas: fix free'ing in probe and remove
      scsi: isci: switch to pci_alloc_irq_vectors
      scsi: ipr: Fix runaway IRQs when falling back from MSI to LSI
      scsi: dpt_i2o: double free on error path
      scsi: cxlflash: Migrate scsi command pointer to AFU command
      scsi: cxlflash: Migrate IOARRIN specific routines to function pointers
      scsi: cxlflash: Cleanup queuecommand()
      scsi: cxlflash: Cleanup send_tmf()
      scsi: cxlflash: Remove AFU command lock
      scsi: cxlflash: Wait for active AFU commands to timeout upon tear down
      scsi: cxlflash: Remove private command pool
      ...

commit f9d03f96b988002027d4b28ea1b7a24729a4c9b5
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Dec 8 15:20:32 2016 -0700

    block: improve handling of the magic discard payload
    
    Instead of allocating a single unused biovec for discard requests, send
    them down without any payload.  Instead we allow the driver to add a
    "special" payload using a biovec embedded into struct request (unioned
    over other fields never used while in the driver), and overloading
    the number of segments for this case.
    
    This has a couple of advantages:
    
     - we don't have to allocate the bio_vec
     - the amount of special casing for discard requests in the block
       layer is significantly reduced
     - using this same scheme for other request types is trivial,
       which will be important for implementing the new WRITE_ZEROES
       op on devices where it actually requires a payload (e.g. SCSI)
     - we can get rid of playing games with the request length, as
       we'll never touch it and completions will work just fine
     - it will allow us to support ranged discard operations in the
       future by merging non-contiguous discard bios into a single
       request
     - last but not least it removes a lot of code
    
    This patch is the common base for my WIP series for ranges discards and to
    remove discard_zeroes_data in favor of always using REQ_OP_WRITE_ZEROES,
    so it would be good to get it in quickly.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 47a5c8783b89..9a8ccff1121f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1007,8 +1007,8 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb)
 	/*
 	 * If sg table allocation fails, requeue request later.
 	 */
-	if (unlikely(sg_alloc_table_chained(&sdb->table, req->nr_phys_segments,
-					sdb->table.sgl)))
+	if (unlikely(sg_alloc_table_chained(&sdb->table,
+			blk_rq_nr_phys_segments(req), sdb->table.sgl)))
 		return BLKPREP_DEFER;
 
 	/* 
@@ -1040,7 +1040,7 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 	bool is_mq = (rq->mq_ctx != NULL);
 	int error;
 
-	BUG_ON(!rq->nr_phys_segments);
+	BUG_ON(!blk_rq_nr_phys_segments(rq));
 
 	error = scsi_init_sgtable(rq, &cmd->sdb);
 	if (error)

commit 669f044170d8933c3d66d231b69ea97cb8447338
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Tue Nov 22 16:17:13 2016 -0800

    scsi: srp_transport: Move queuecommand() wait code to SCSI core
    
    Additionally, rename srp_wait_for_queuecommand() into
    scsi_wait_for_queuecommand() and add a comment about the queuecommand()
    call from scsi_send_eh_cmnd().
    
    Note: this patch changes scsi_internal_device_block from a function that
    did not sleep into a function that may sleep. This is fine for all
    callers of this function:
    
    * scsi_internal_device_block() is called from the mpt3sas device while
      that driver holds the ioc->dm_cmds.mutex. This means that the mpt3sas
      driver calls this function from thread context.
    * scsi_target_block() is called by __iscsi_block_session() from
      kernel thread context and with IRQs enabled.
    * The SRP transport code also calls scsi_target_block() from kernel
      thread context while sleeping is allowed.
    * The snic driver also calls scsi_target_block() from a context from
      which sleeping is allowed. The scsi_target_block() call namely occurs
      immediately after a scsi_flush_work() call.
    
    [mkp: s/shost/sdev/]
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Cc: James Bottomley <jejb@linux.vnet.ibm.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Doug Ledford <dledford@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f23ec240cab0..0f81add6025e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2733,6 +2733,39 @@ void sdev_evt_send_simple(struct scsi_device *sdev,
 }
 EXPORT_SYMBOL_GPL(sdev_evt_send_simple);
 
+/**
+ * scsi_request_fn_active() - number of kernel threads inside scsi_request_fn()
+ * @sdev: SCSI device to count the number of scsi_request_fn() callers for.
+ */
+static int scsi_request_fn_active(struct scsi_device *sdev)
+{
+	struct request_queue *q = sdev->request_queue;
+	int request_fn_active;
+
+	WARN_ON_ONCE(sdev->host->use_blk_mq);
+
+	spin_lock_irq(q->queue_lock);
+	request_fn_active = q->request_fn_active;
+	spin_unlock_irq(q->queue_lock);
+
+	return request_fn_active;
+}
+
+/**
+ * scsi_wait_for_queuecommand() - wait for ongoing queuecommand() calls
+ * @sdev: SCSI device pointer.
+ *
+ * Wait until the ongoing shost->hostt->queuecommand() calls that are
+ * invoked from scsi_request_fn() have finished.
+ */
+static void scsi_wait_for_queuecommand(struct scsi_device *sdev)
+{
+	WARN_ON_ONCE(sdev->host->use_blk_mq);
+
+	while (scsi_request_fn_active(sdev))
+		msleep(20);
+}
+
 /**
  *	scsi_device_quiesce - Block user issued commands.
  *	@sdev:	scsi device to quiesce.
@@ -2817,8 +2850,7 @@ EXPORT_SYMBOL(scsi_target_resume);
  * @sdev:	device to block
  *
  * Block request made by scsi lld's to temporarily stop all
- * scsi commands on the specified device.  Called from interrupt
- * or normal process context.
+ * scsi commands on the specified device. May sleep.
  *
  * Returns zero if successful or error if not
  *
@@ -2827,6 +2859,10 @@ EXPORT_SYMBOL(scsi_target_resume);
  *	(which must be a legal transition).  When the device is in this
  *	state, all commands are deferred until the scsi lld reenables
  *	the device with scsi_device_unblock or device_block_tmo fires.
+ *
+ * To do: avoid that scsi_send_eh_cmnd() calls queuecommand() after
+ * scsi_internal_device_block() has blocked a SCSI device and also
+ * remove the rport mutex lock and unlock calls from srp_queuecommand().
  */
 int
 scsi_internal_device_block(struct scsi_device *sdev)
@@ -2854,6 +2890,7 @@ scsi_internal_device_block(struct scsi_device *sdev)
 		spin_lock_irqsave(q->queue_lock, flags);
 		blk_stop_queue(q);
 		spin_unlock_irqrestore(q->queue_lock, flags);
+		scsi_wait_for_queuecommand(sdev);
 	}
 
 	return 0;

commit 2868f13c303e1472bfd3941c62916c1f4128a713
Author: Omar Sandoval <osandov@fb.com>
Date:   Tue Nov 15 11:11:59 2016 -0800

    scsi_lib: untangle 0 and BLK_MQ_RQ_QUEUE_OK
    
    Let's not depend on any of the BLK_MQ_RQ_QUEUE_* constants having
    specific values. No functional change.
    
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 2e35132f8be1..47a5c8783b89 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1810,7 +1810,7 @@ static inline int prep_to_mq(int ret)
 {
 	switch (ret) {
 	case BLKPREP_OK:
-		return 0;
+		return BLK_MQ_RQ_QUEUE_OK;
 	case BLKPREP_DEFER:
 		return BLK_MQ_RQ_QUEUE_BUSY;
 	default:
@@ -1897,7 +1897,7 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 	int reason;
 
 	ret = prep_to_mq(scsi_prep_state_check(sdev, req));
-	if (ret)
+	if (ret != BLK_MQ_RQ_QUEUE_OK)
 		goto out;
 
 	ret = BLK_MQ_RQ_QUEUE_BUSY;
@@ -1914,7 +1914,7 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 
 	if (!(req->rq_flags & RQF_DONTPREP)) {
 		ret = prep_to_mq(scsi_mq_prep_fn(req));
-		if (ret)
+		if (ret != BLK_MQ_RQ_QUEUE_OK)
 			goto out_dec_host_busy;
 		req->rq_flags |= RQF_DONTPREP;
 	} else {

commit 2d9c5c20c93eacc00642f6ce10ce47f31fa0b6ac
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Nov 1 08:12:48 2016 -0600

    scsi: allow LLDDs to expose the queue mapping to blk-mq
    
    Just hand through the blk-mq map_queues method in the host template.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 2cca9cffc63f..f23ec240cab0 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1990,6 +1990,15 @@ static void scsi_exit_request(void *data, struct request *rq,
 	kfree(cmd->sense_buffer);
 }
 
+static int scsi_map_queues(struct blk_mq_tag_set *set)
+{
+	struct Scsi_Host *shost = container_of(set, struct Scsi_Host, tag_set);
+
+	if (shost->hostt->map_queues)
+		return shost->hostt->map_queues(shost);
+	return blk_mq_map_queues(set);
+}
+
 static u64 scsi_calculate_bounce_limit(struct Scsi_Host *shost)
 {
 	struct device *host_dev;
@@ -2082,6 +2091,7 @@ static struct blk_mq_ops scsi_mq_ops = {
 	.timeout	= scsi_timeout,
 	.init_request	= scsi_init_request,
 	.exit_request	= scsi_exit_request,
+	.map_queues	= scsi_map_queues,
 };
 
 struct request_queue *scsi_mq_alloc_queue(struct scsi_device *sdev)

commit 2b053aca76b48e681be57b34ca3a8c2c10b275c5
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Fri Oct 28 17:21:41 2016 -0700

    blk-mq: Add a kick_requeue_list argument to blk_mq_requeue_request()
    
    Most blk_mq_requeue_request() and blk_mq_add_to_requeue_list() calls
    are followed by kicking the requeue list. Hence add an argument to
    these two functions that allows to kick the requeue list. This was
    proposed by Christoph Hellwig.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Cc: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 2b78ff12bf3c..2e35132f8be1 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -86,10 +86,8 @@ scsi_set_blocked(struct scsi_cmnd *cmd, int reason)
 static void scsi_mq_requeue_cmd(struct scsi_cmnd *cmd)
 {
 	struct scsi_device *sdev = cmd->device;
-	struct request_queue *q = cmd->request->q;
 
-	blk_mq_requeue_request(cmd->request);
-	blk_mq_kick_requeue_list(q);
+	blk_mq_requeue_request(cmd->request, true);
 	put_device(&sdev->sdev_gendev);
 }
 

commit 52d7f1b5c2f33b5d34dc2b6af5175fb6a44999f6
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Fri Oct 28 17:20:32 2016 -0700

    blk-mq: Avoid that requeueing starts stopped queues
    
    Since blk_mq_requeue_work() starts stopped queues and since
    execution of this function can be scheduled after a queue has
    been stopped it is not possible to stop queues without using
    an additional state variable to track whether or not the queue
    has been stopped. Hence modify blk_mq_requeue_work() such that it
    does not start stopped queues. My conclusion after a review of
    the blk_mq_stop_hw_queues() and blk_mq_{delay_,}kick_requeue_list()
    callers is as follows:
    * In the dm driver starting and stopping queues should only happen
      if __dm_suspend() or __dm_resume() is called and not if the
      requeue list is processed.
    * In the SCSI core queue stopping and starting should only be
      performed by the scsi_internal_device_block() and
      scsi_internal_device_unblock() functions but not by any other
      function. Although the blk_mq_stop_hw_queue() call in
      scsi_queue_rq() may help to reduce CPU load if a LLD queue is
      full, figuring out whether or not a queue should be restarted
      when requeueing a command would require to introduce additional
      locking in scsi_mq_requeue_cmd() to avoid a race with
      scsi_internal_device_block(). Avoid this complexity by removing
      the blk_mq_stop_hw_queue() call from scsi_queue_rq().
    * In the NVMe core only the functions that call
      blk_mq_start_stopped_hw_queues() explicitly should start stopped
      queues.
    * A blk_mq_start_stopped_hwqueues() call must be added in the
      xen-blkfront driver in its blkif_recover() function.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Roger Pau Monné <roger.pau@citrix.com>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: James Bottomley <jejb@linux.vnet.ibm.com>
    Cc: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 8c52622ac257..2b78ff12bf3c 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1952,7 +1952,6 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 out:
 	switch (ret) {
 	case BLK_MQ_RQ_QUEUE_BUSY:
-		blk_mq_stop_hw_queue(hctx);
 		if (atomic_read(&sdev->device_busy) == 0 &&
 		    !scsi_device_blocked(sdev))
 			blk_mq_delay_queue(hctx, SCSI_QUEUE_DELAY);

commit e806402130c9c494e22c73ae9ead4e79d2a5811c
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Oct 20 15:12:13 2016 +0200

    block: split out request-only flags into a new namespace
    
    A lot of the REQ_* flags are only used on struct requests, and only of
    use to the block layer and a few drivers that dig into struct request
    internals.
    
    This patch adds a new req_flags_t rq_flags field to struct request for
    them, and thus dramatically shrinks the number of common requests.  It
    also removes the unfortunate situation where we have to fit the fields
    from the same enum into 32 bits for struct bio and 64 bits for
    struct request.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Shaun Tancheff <shaun.tancheff@seagate.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 2cca9cffc63f..8c52622ac257 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -163,26 +163,11 @@ void scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 {
 	__scsi_queue_insert(cmd, reason, 1);
 }
-/**
- * scsi_execute - insert request and wait for the result
- * @sdev:	scsi device
- * @cmd:	scsi command
- * @data_direction: data direction
- * @buffer:	data buffer
- * @bufflen:	len of buffer
- * @sense:	optional sense buffer
- * @timeout:	request timeout in seconds
- * @retries:	number of times to retry request
- * @flags:	or into request flags;
- * @resid:	optional residual length
- *
- * returns the req->errors value which is the scsi_cmnd result
- * field.
- */
-int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
+
+static int __scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 		 int data_direction, void *buffer, unsigned bufflen,
 		 unsigned char *sense, int timeout, int retries, u64 flags,
-		 int *resid)
+		 req_flags_t rq_flags, int *resid)
 {
 	struct request *req;
 	int write = (data_direction == DMA_TO_DEVICE);
@@ -203,7 +188,8 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	req->sense_len = 0;
 	req->retries = retries;
 	req->timeout = timeout;
-	req->cmd_flags |= flags | REQ_QUIET | REQ_PREEMPT;
+	req->cmd_flags |= flags;
+	req->rq_flags |= rq_flags | RQF_QUIET | RQF_PREEMPT;
 
 	/*
 	 * head injection *required* here otherwise quiesce won't work
@@ -227,12 +213,37 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 
 	return ret;
 }
+
+/**
+ * scsi_execute - insert request and wait for the result
+ * @sdev:	scsi device
+ * @cmd:	scsi command
+ * @data_direction: data direction
+ * @buffer:	data buffer
+ * @bufflen:	len of buffer
+ * @sense:	optional sense buffer
+ * @timeout:	request timeout in seconds
+ * @retries:	number of times to retry request
+ * @flags:	or into request flags;
+ * @resid:	optional residual length
+ *
+ * returns the req->errors value which is the scsi_cmnd result
+ * field.
+ */
+int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
+		 int data_direction, void *buffer, unsigned bufflen,
+		 unsigned char *sense, int timeout, int retries, u64 flags,
+		 int *resid)
+{
+	return __scsi_execute(sdev, cmd, data_direction, buffer, bufflen, sense,
+			timeout, retries, flags, 0, resid);
+}
 EXPORT_SYMBOL(scsi_execute);
 
 int scsi_execute_req_flags(struct scsi_device *sdev, const unsigned char *cmd,
 		     int data_direction, void *buffer, unsigned bufflen,
 		     struct scsi_sense_hdr *sshdr, int timeout, int retries,
-		     int *resid, u64 flags)
+		     int *resid, u64 flags, req_flags_t rq_flags)
 {
 	char *sense = NULL;
 	int result;
@@ -242,8 +253,8 @@ int scsi_execute_req_flags(struct scsi_device *sdev, const unsigned char *cmd,
 		if (!sense)
 			return DRIVER_ERROR << 24;
 	}
-	result = scsi_execute(sdev, cmd, data_direction, buffer, bufflen,
-			      sense, timeout, retries, flags, resid);
+	result = __scsi_execute(sdev, cmd, data_direction, buffer, bufflen,
+			      sense, timeout, retries, flags, rq_flags, resid);
 	if (sshdr)
 		scsi_normalize_sense(sense, SCSI_SENSE_BUFFERSIZE, sshdr);
 
@@ -813,7 +824,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		 */
 		if ((sshdr.asc == 0x0) && (sshdr.ascq == 0x1d))
 			;
-		else if (!(req->cmd_flags & REQ_QUIET))
+		else if (!(req->rq_flags & RQF_QUIET))
 			scsi_print_sense(cmd);
 		result = 0;
 		/* BLOCK_PC may have set error */
@@ -943,7 +954,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	switch (action) {
 	case ACTION_FAIL:
 		/* Give up and fail the remainder of the request */
-		if (!(req->cmd_flags & REQ_QUIET)) {
+		if (!(req->rq_flags & RQF_QUIET)) {
 			static DEFINE_RATELIMIT_STATE(_rs,
 					DEFAULT_RATELIMIT_INTERVAL,
 					DEFAULT_RATELIMIT_BURST);
@@ -972,7 +983,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		 * A new command will be prepared and issued.
 		 */
 		if (q->mq_ops) {
-			cmd->request->cmd_flags &= ~REQ_DONTPREP;
+			cmd->request->rq_flags &= ~RQF_DONTPREP;
 			scsi_mq_uninit_cmd(cmd);
 			scsi_mq_requeue_cmd(cmd);
 		} else {
@@ -1234,7 +1245,7 @@ scsi_prep_state_check(struct scsi_device *sdev, struct request *req)
 			/*
 			 * If the devices is blocked we defer normal commands.
 			 */
-			if (!(req->cmd_flags & REQ_PREEMPT))
+			if (!(req->rq_flags & RQF_PREEMPT))
 				ret = BLKPREP_DEFER;
 			break;
 		default:
@@ -1243,7 +1254,7 @@ scsi_prep_state_check(struct scsi_device *sdev, struct request *req)
 			 * special commands.  In particular any user initiated
 			 * command is not allowed.
 			 */
-			if (!(req->cmd_flags & REQ_PREEMPT))
+			if (!(req->rq_flags & RQF_PREEMPT))
 				ret = BLKPREP_KILL;
 			break;
 		}
@@ -1279,7 +1290,7 @@ scsi_prep_return(struct request_queue *q, struct request *req, int ret)
 			blk_delay_queue(q, SCSI_QUEUE_DELAY);
 		break;
 	default:
-		req->cmd_flags |= REQ_DONTPREP;
+		req->rq_flags |= RQF_DONTPREP;
 	}
 
 	return ret;
@@ -1736,7 +1747,7 @@ static void scsi_request_fn(struct request_queue *q)
 		 * we add the dev to the starved list so it eventually gets
 		 * a run when a tag is freed.
 		 */
-		if (blk_queue_tagged(q) && !(req->cmd_flags & REQ_QUEUED)) {
+		if (blk_queue_tagged(q) && !(req->rq_flags & RQF_QUEUED)) {
 			spin_lock_irq(shost->host_lock);
 			if (list_empty(&sdev->starved_entry))
 				list_add_tail(&sdev->starved_entry,
@@ -1903,11 +1914,11 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 		goto out_dec_target_busy;
 
 
-	if (!(req->cmd_flags & REQ_DONTPREP)) {
+	if (!(req->rq_flags & RQF_DONTPREP)) {
 		ret = prep_to_mq(scsi_mq_prep_fn(req));
 		if (ret)
 			goto out_dec_host_busy;
-		req->cmd_flags |= REQ_DONTPREP;
+		req->rq_flags |= RQF_DONTPREP;
 	} else {
 		blk_mq_start_request(req);
 	}
@@ -1952,7 +1963,7 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
 		 * we hit an error, as we will never see this command
 		 * again.
 		 */
-		if (req->cmd_flags & REQ_DONTPREP)
+		if (req->rq_flags & RQF_DONTPREP)
 			scsi_mq_uninit_cmd(cmd);
 		break;
 	default:

commit 7d7e0f90b70f6c5367c2d1c9a7e87dd228bd0816
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Sep 14 16:18:54 2016 +0200

    blk-mq: remove ->map_queue
    
    All drivers use the default, so provide an inline version of it.  If we
    ever need other queue mapping we can add an optional method back,
    although supporting will also require major changes to the queue setup
    code.
    
    This provides better code generation, and better debugability as well.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Keith Busch <keith.busch@intel.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c71344aebdbb..2cca9cffc63f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2077,7 +2077,6 @@ struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
 }
 
 static struct blk_mq_ops scsi_mq_ops = {
-	.map_queue	= blk_mq_map_queue,
 	.queue_rq	= scsi_queue_rq,
 	.complete	= scsi_softirq_done,
 	.timeout	= scsi_timeout,

commit a621bac3044ed6f7ec5fa0326491b2d4838bfa93
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Fri May 13 12:04:06 2016 -0700

    scsi_lib: correctly retry failed zero length REQ_TYPE_FS commands
    
    When SCSI was written, all commands coming from the filesystem
    (REQ_TYPE_FS commands) had data.  This meant that our signal for needing
    to complete the command was the number of bytes completed being equal to
    the number of bytes in the request.  Unfortunately, with the advent of
    flush barriers, we can now get zero length REQ_TYPE_FS commands, which
    confuse this logic because they satisfy the condition every time.  This
    means they never get retried even for retryable conditions, like UNIT
    ATTENTION because we complete them early assuming they're done.  Fix
    this by special casing the early completion condition to recognise zero
    length commands with errors and let them drop through to the retry code.
    
    Cc: stable@vger.kernel.org
    Reported-by: Sebastian Parschauer <s.parschauer@gmx.de>
    Signed-off-by: James E.J. Bottomley <jejb@linux.vnet.ibm.com>
    Tested-by: Jack Wang <jinpu.wang@profitbricks.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b2e332af0f51..c71344aebdbb 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -821,9 +821,12 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	}
 
 	/*
-	 * If we finished all bytes in the request we are done now.
+	 * special case: failed zero length commands always need to
+	 * drop down into the retry code. Otherwise, if we finished
+	 * all bytes in the request we are done now.
 	 */
-	if (!scsi_end_request(req, error, good_bytes, 0))
+	if (!(blk_rq_bytes(req) == 0 && error) &&
+	    !scsi_end_request(req, error, good_bytes, 0))
 		return;
 
 	/*

commit d230823a1c4c3e97afd4c934b86b3975d5e20249
Author: Hannes Reinecke <hare@suse.de>
Date:   Mon May 9 09:14:29 2016 +0200

    scsi_lib: Decode T10 vendor IDs
    
    Some arrays / HBAs will only present T10 vendor IDs, so we should be
    decoding them, too.
    
    [mkp: Fixed T10 spelling]
    
    Suggested-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Hannes Reinecke <hare@suse.com>
    Tested-by: Paul Mackerras <paulus@ozlabs.org>
    Reviewed-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b920c5dabf60..b2e332af0f51 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -3064,6 +3064,7 @@ int scsi_vpd_lun_id(struct scsi_device *sdev, char *id, size_t id_len)
 	 * - EUI-64 based 12-byte
 	 * - NAA IEEE Registered
 	 * - NAA IEEE Extended
+	 * - T10 Vendor ID
 	 * as longer descriptors reduce the likelyhood
 	 * of identification clashes.
 	 */
@@ -3082,6 +3083,21 @@ int scsi_vpd_lun_id(struct scsi_device *sdev, char *id, size_t id_len)
 			goto next_desig;
 
 		switch (d[1] & 0xf) {
+		case 0x1:
+			/* T10 Vendor ID */
+			if (cur_id_size > d[3])
+				break;
+			/* Prefer anything */
+			if (cur_id_type > 0x01 && cur_id_type != 0xff)
+				break;
+			cur_id_size = d[3];
+			if (cur_id_size + 4 > id_len)
+				cur_id_size = id_len - 4;
+			cur_id_str = d + 4;
+			cur_id_type = d[1] & 0xf;
+			id_size = snprintf(id, id_len, "t10.%*pE",
+					   cur_id_size, cur_id_str);
+			break;
 		case 0x2:
 			/* EUI-64 */
 			if (cur_id_size > d[3])

commit 9b1d6c8950021ab007608d455fc9c398ecd25476
Author: Ming Lin <ming.l@ssi.samsung.com>
Date:   Mon Apr 4 14:48:11 2016 -0700

    lib: scatterlist: move SG pool code from SCSI driver to lib/sg_pool.c
    
    Now it's ready to move the mempool based SG chained allocator code from
    SCSI driver to lib/sg_pool.c, which will be compiled only based on a Kconfig
    symbol CONFIG_SG_POOL.
    
    SCSI selects CONFIG_SG_POOL.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Ming Lin <ming.l@ssi.samsung.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 8f776f1e95ce..b920c5dabf60 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -14,8 +14,6 @@
 #include <linux/completion.h>
 #include <linux/kernel.h>
 #include <linux/export.h>
-#include <linux/mempool.h>
-#include <linux/slab.h>
 #include <linux/init.h>
 #include <linux/pci.h>
 #include <linux/delay.h>
@@ -40,39 +38,6 @@
 #include "scsi_logging.h"
 
 
-#define SG_MEMPOOL_NR		ARRAY_SIZE(sg_pools)
-#define SG_MEMPOOL_SIZE		2
-
-struct sg_pool {
-	size_t		size;
-	char		*name;
-	struct kmem_cache	*slab;
-	mempool_t	*pool;
-};
-
-#define SP(x) { .size = x, "sgpool-" __stringify(x) }
-#if (SG_CHUNK_SIZE < 32)
-#error SG_CHUNK_SIZE is too small (must be 32 or greater)
-#endif
-static struct sg_pool sg_pools[] = {
-	SP(8),
-	SP(16),
-#if (SG_CHUNK_SIZE > 32)
-	SP(32),
-#if (SG_CHUNK_SIZE > 64)
-	SP(64),
-#if (SG_CHUNK_SIZE > 128)
-	SP(128),
-#if (SG_CHUNK_SIZE > 256)
-#error SG_CHUNK_SIZE is too large (256 MAX)
-#endif
-#endif
-#endif
-#endif
-	SP(SG_CHUNK_SIZE)
-};
-#undef SP
-
 struct kmem_cache *scsi_sdb_cache;
 
 /*
@@ -553,65 +518,6 @@ void scsi_run_host_queues(struct Scsi_Host *shost)
 		scsi_run_queue(sdev->request_queue);
 }
 
-static inline unsigned int sg_pool_index(unsigned short nents)
-{
-	unsigned int index;
-
-	BUG_ON(nents > SG_CHUNK_SIZE);
-
-	if (nents <= 8)
-		index = 0;
-	else
-		index = get_count_order(nents) - 3;
-
-	return index;
-}
-
-static void sg_pool_free(struct scatterlist *sgl, unsigned int nents)
-{
-	struct sg_pool *sgp;
-
-	sgp = sg_pools + sg_pool_index(nents);
-	mempool_free(sgl, sgp->pool);
-}
-
-static struct scatterlist *sg_pool_alloc(unsigned int nents, gfp_t gfp_mask)
-{
-	struct sg_pool *sgp;
-
-	sgp = sg_pools + sg_pool_index(nents);
-	return mempool_alloc(sgp->pool, gfp_mask);
-}
-
-static void sg_free_table_chained(struct sg_table *table, bool first_chunk)
-{
-	if (first_chunk && table->orig_nents <= SG_CHUNK_SIZE)
-		return;
-	__sg_free_table(table, SG_CHUNK_SIZE, first_chunk, sg_pool_free);
-}
-
-static int sg_alloc_table_chained(struct sg_table *table, int nents,
-		struct scatterlist *first_chunk)
-{
-	int ret;
-
-	BUG_ON(!nents);
-
-	if (first_chunk) {
-		if (nents <= SG_CHUNK_SIZE) {
-			table->nents = table->orig_nents = nents;
-			sg_init_table(table->sgl, nents);
-			return 0;
-		}
-	}
-
-	ret = __sg_alloc_table(table, nents, SG_CHUNK_SIZE,
-			       first_chunk, GFP_ATOMIC, sg_pool_alloc);
-	if (unlikely(ret))
-		sg_free_table_chained(table, (bool)first_chunk);
-	return ret;
-}
-
 static void scsi_uninit_cmd(struct scsi_cmnd *cmd)
 {
 	if (cmd->request->cmd_type == REQ_TYPE_FS) {
@@ -2269,8 +2175,6 @@ EXPORT_SYMBOL(scsi_unblock_requests);
 
 int __init scsi_init_queue(void)
 {
-	int i;
-
 	scsi_sdb_cache = kmem_cache_create("scsi_data_buffer",
 					   sizeof(struct scsi_data_buffer),
 					   0, 0, NULL);
@@ -2279,53 +2183,12 @@ int __init scsi_init_queue(void)
 		return -ENOMEM;
 	}
 
-	for (i = 0; i < SG_MEMPOOL_NR; i++) {
-		struct sg_pool *sgp = sg_pools + i;
-		int size = sgp->size * sizeof(struct scatterlist);
-
-		sgp->slab = kmem_cache_create(sgp->name, size, 0,
-				SLAB_HWCACHE_ALIGN, NULL);
-		if (!sgp->slab) {
-			printk(KERN_ERR "SCSI: can't init sg slab %s\n",
-					sgp->name);
-			goto cleanup_sdb;
-		}
-
-		sgp->pool = mempool_create_slab_pool(SG_MEMPOOL_SIZE,
-						     sgp->slab);
-		if (!sgp->pool) {
-			printk(KERN_ERR "SCSI: can't init sg mempool %s\n",
-					sgp->name);
-			goto cleanup_sdb;
-		}
-	}
-
 	return 0;
-
-cleanup_sdb:
-	for (i = 0; i < SG_MEMPOOL_NR; i++) {
-		struct sg_pool *sgp = sg_pools + i;
-		if (sgp->pool)
-			mempool_destroy(sgp->pool);
-		if (sgp->slab)
-			kmem_cache_destroy(sgp->slab);
-	}
-	kmem_cache_destroy(scsi_sdb_cache);
-
-	return -ENOMEM;
 }
 
 void scsi_exit_queue(void)
 {
-	int i;
-
 	kmem_cache_destroy(scsi_sdb_cache);
-
-	for (i = 0; i < SG_MEMPOOL_NR; i++) {
-		struct sg_pool *sgp = sg_pools + i;
-		mempool_destroy(sgp->pool);
-		kmem_cache_destroy(sgp->slab);
-	}
 }
 
 /**

commit 65e8617fba17732b4c68d3369a621725838b6f28
Author: Ming Lin <ming.l@ssi.samsung.com>
Date:   Mon Apr 4 14:48:10 2016 -0700

    scsi: rename SCSI_MAX_{SG, SG_CHAIN}_SEGMENTS
    
    Rename SCSI_MAX_SG_SEGMENTS to SG_CHUNK_SIZE, which means the amount
    we fit into a single scatterlist chunk.
    
    Rename SCSI_MAX_SG_CHAIN_SEGMENTS to SG_MAX_SEGMENTS.
    
    Will move these 2 generic definitions to scatterlist.h later.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Bart Van Assche <bart.vanassche@sandisk.com> (for ib_srp changes)
    Signed-off-by: Ming Lin <ming.l@ssi.samsung.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 08134f621450..8f776f1e95ce 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -51,25 +51,25 @@ struct sg_pool {
 };
 
 #define SP(x) { .size = x, "sgpool-" __stringify(x) }
-#if (SCSI_MAX_SG_SEGMENTS < 32)
-#error SCSI_MAX_SG_SEGMENTS is too small (must be 32 or greater)
+#if (SG_CHUNK_SIZE < 32)
+#error SG_CHUNK_SIZE is too small (must be 32 or greater)
 #endif
 static struct sg_pool sg_pools[] = {
 	SP(8),
 	SP(16),
-#if (SCSI_MAX_SG_SEGMENTS > 32)
+#if (SG_CHUNK_SIZE > 32)
 	SP(32),
-#if (SCSI_MAX_SG_SEGMENTS > 64)
+#if (SG_CHUNK_SIZE > 64)
 	SP(64),
-#if (SCSI_MAX_SG_SEGMENTS > 128)
+#if (SG_CHUNK_SIZE > 128)
 	SP(128),
-#if (SCSI_MAX_SG_SEGMENTS > 256)
-#error SCSI_MAX_SG_SEGMENTS is too large (256 MAX)
+#if (SG_CHUNK_SIZE > 256)
+#error SG_CHUNK_SIZE is too large (256 MAX)
 #endif
 #endif
 #endif
 #endif
-	SP(SCSI_MAX_SG_SEGMENTS)
+	SP(SG_CHUNK_SIZE)
 };
 #undef SP
 
@@ -557,7 +557,7 @@ static inline unsigned int sg_pool_index(unsigned short nents)
 {
 	unsigned int index;
 
-	BUG_ON(nents > SCSI_MAX_SG_SEGMENTS);
+	BUG_ON(nents > SG_CHUNK_SIZE);
 
 	if (nents <= 8)
 		index = 0;
@@ -585,9 +585,9 @@ static struct scatterlist *sg_pool_alloc(unsigned int nents, gfp_t gfp_mask)
 
 static void sg_free_table_chained(struct sg_table *table, bool first_chunk)
 {
-	if (first_chunk && table->orig_nents <= SCSI_MAX_SG_SEGMENTS)
+	if (first_chunk && table->orig_nents <= SG_CHUNK_SIZE)
 		return;
-	__sg_free_table(table, SCSI_MAX_SG_SEGMENTS, first_chunk, sg_pool_free);
+	__sg_free_table(table, SG_CHUNK_SIZE, first_chunk, sg_pool_free);
 }
 
 static int sg_alloc_table_chained(struct sg_table *table, int nents,
@@ -598,14 +598,14 @@ static int sg_alloc_table_chained(struct sg_table *table, int nents,
 	BUG_ON(!nents);
 
 	if (first_chunk) {
-		if (nents <= SCSI_MAX_SG_SEGMENTS) {
+		if (nents <= SG_CHUNK_SIZE) {
 			table->nents = table->orig_nents = nents;
 			sg_init_table(table->sgl, nents);
 			return 0;
 		}
 	}
 
-	ret = __sg_alloc_table(table, nents, SCSI_MAX_SG_SEGMENTS,
+	ret = __sg_alloc_table(table, nents, SG_CHUNK_SIZE,
 			       first_chunk, GFP_ATOMIC, sg_pool_alloc);
 	if (unlikely(ret))
 		sg_free_table_chained(table, (bool)first_chunk);
@@ -1937,7 +1937,7 @@ static int scsi_mq_prep_fn(struct request *req)
 	if (scsi_host_get_prot(shost)) {
 		cmd->prot_sdb = (void *)sg +
 			min_t(unsigned int,
-			      shost->sg_tablesize, SCSI_MAX_SG_SEGMENTS) *
+			      shost->sg_tablesize, SG_CHUNK_SIZE) *
 			sizeof(struct scatterlist);
 		memset(cmd->prot_sdb, 0, sizeof(struct scsi_data_buffer));
 
@@ -2110,7 +2110,7 @@ static void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 	 * this limit is imposed by hardware restrictions
 	 */
 	blk_queue_max_segments(q, min_t(unsigned short, shost->sg_tablesize,
-					SCSI_MAX_SG_CHAIN_SEGMENTS));
+					SG_MAX_SEGMENTS));
 
 	if (scsi_host_prot_dma(shost)) {
 		shost->sg_prot_tablesize =
@@ -2192,8 +2192,8 @@ int scsi_mq_setup_tags(struct Scsi_Host *shost)
 	unsigned int cmd_size, sgl_size, tbl_size;
 
 	tbl_size = shost->sg_tablesize;
-	if (tbl_size > SCSI_MAX_SG_SEGMENTS)
-		tbl_size = SCSI_MAX_SG_SEGMENTS;
+	if (tbl_size > SG_CHUNK_SIZE)
+		tbl_size = SG_CHUNK_SIZE;
 	sgl_size = tbl_size * sizeof(struct scatterlist);
 	cmd_size = sizeof(struct scsi_cmnd) + shost->hostt->cmd_size + sgl_size;
 	if (scsi_host_get_prot(shost))

commit 001d63be61c3b5a0413a46bacafbfc60c353951a
Author: Ming Lin <ming.l@ssi.samsung.com>
Date:   Mon Apr 4 14:48:09 2016 -0700

    scsi: rename SG related struct and functions
    
    Rename SCSI specific struct and functions to more genenic names.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Ming Lin <ming.l@ssi.samsung.com>
    Reviewed-by: Sagi Grimberg <sgi@grimberg.me>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9675353770e9..08134f621450 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -40,10 +40,10 @@
 #include "scsi_logging.h"
 
 
-#define SG_MEMPOOL_NR		ARRAY_SIZE(scsi_sg_pools)
+#define SG_MEMPOOL_NR		ARRAY_SIZE(sg_pools)
 #define SG_MEMPOOL_SIZE		2
 
-struct scsi_host_sg_pool {
+struct sg_pool {
 	size_t		size;
 	char		*name;
 	struct kmem_cache	*slab;
@@ -54,7 +54,7 @@ struct scsi_host_sg_pool {
 #if (SCSI_MAX_SG_SEGMENTS < 32)
 #error SCSI_MAX_SG_SEGMENTS is too small (must be 32 or greater)
 #endif
-static struct scsi_host_sg_pool scsi_sg_pools[] = {
+static struct sg_pool sg_pools[] = {
 	SP(8),
 	SP(16),
 #if (SCSI_MAX_SG_SEGMENTS > 32)
@@ -553,7 +553,7 @@ void scsi_run_host_queues(struct Scsi_Host *shost)
 		scsi_run_queue(sdev->request_queue);
 }
 
-static inline unsigned int scsi_sgtable_index(unsigned short nents)
+static inline unsigned int sg_pool_index(unsigned short nents)
 {
 	unsigned int index;
 
@@ -567,30 +567,30 @@ static inline unsigned int scsi_sgtable_index(unsigned short nents)
 	return index;
 }
 
-static void scsi_sg_free(struct scatterlist *sgl, unsigned int nents)
+static void sg_pool_free(struct scatterlist *sgl, unsigned int nents)
 {
-	struct scsi_host_sg_pool *sgp;
+	struct sg_pool *sgp;
 
-	sgp = scsi_sg_pools + scsi_sgtable_index(nents);
+	sgp = sg_pools + sg_pool_index(nents);
 	mempool_free(sgl, sgp->pool);
 }
 
-static struct scatterlist *scsi_sg_alloc(unsigned int nents, gfp_t gfp_mask)
+static struct scatterlist *sg_pool_alloc(unsigned int nents, gfp_t gfp_mask)
 {
-	struct scsi_host_sg_pool *sgp;
+	struct sg_pool *sgp;
 
-	sgp = scsi_sg_pools + scsi_sgtable_index(nents);
+	sgp = sg_pools + sg_pool_index(nents);
 	return mempool_alloc(sgp->pool, gfp_mask);
 }
 
-static void scsi_free_sgtable(struct sg_table *table, bool first_chunk)
+static void sg_free_table_chained(struct sg_table *table, bool first_chunk)
 {
 	if (first_chunk && table->orig_nents <= SCSI_MAX_SG_SEGMENTS)
 		return;
-	__sg_free_table(table, SCSI_MAX_SG_SEGMENTS, first_chunk, scsi_sg_free);
+	__sg_free_table(table, SCSI_MAX_SG_SEGMENTS, first_chunk, sg_pool_free);
 }
 
-static int scsi_alloc_sgtable(struct sg_table *table, int nents,
+static int sg_alloc_table_chained(struct sg_table *table, int nents,
 		struct scatterlist *first_chunk)
 {
 	int ret;
@@ -606,9 +606,9 @@ static int scsi_alloc_sgtable(struct sg_table *table, int nents,
 	}
 
 	ret = __sg_alloc_table(table, nents, SCSI_MAX_SG_SEGMENTS,
-			       first_chunk, GFP_ATOMIC, scsi_sg_alloc);
+			       first_chunk, GFP_ATOMIC, sg_pool_alloc);
 	if (unlikely(ret))
-		scsi_free_sgtable(table, (bool)first_chunk);
+		sg_free_table_chained(table, (bool)first_chunk);
 	return ret;
 }
 
@@ -627,14 +627,14 @@ static void scsi_mq_free_sgtables(struct scsi_cmnd *cmd)
 	struct scsi_data_buffer *sdb;
 
 	if (cmd->sdb.table.nents)
-		scsi_free_sgtable(&cmd->sdb.table, true);
+		sg_free_table_chained(&cmd->sdb.table, true);
 	if (cmd->request->next_rq) {
 		sdb = cmd->request->next_rq->special;
 		if (sdb)
-			scsi_free_sgtable(&sdb->table, true);
+			sg_free_table_chained(&sdb->table, true);
 	}
 	if (scsi_prot_sg_count(cmd))
-		scsi_free_sgtable(&cmd->prot_sdb->table, true);
+		sg_free_table_chained(&cmd->prot_sdb->table, true);
 }
 
 static void scsi_mq_uninit_cmd(struct scsi_cmnd *cmd)
@@ -673,19 +673,19 @@ static void scsi_mq_uninit_cmd(struct scsi_cmnd *cmd)
 static void scsi_release_buffers(struct scsi_cmnd *cmd)
 {
 	if (cmd->sdb.table.nents)
-		scsi_free_sgtable(&cmd->sdb.table, false);
+		sg_free_table_chained(&cmd->sdb.table, false);
 
 	memset(&cmd->sdb, 0, sizeof(cmd->sdb));
 
 	if (scsi_prot_sg_count(cmd))
-		scsi_free_sgtable(&cmd->prot_sdb->table, false);
+		sg_free_table_chained(&cmd->prot_sdb->table, false);
 }
 
 static void scsi_release_bidi_buffers(struct scsi_cmnd *cmd)
 {
 	struct scsi_data_buffer *bidi_sdb = cmd->request->next_rq->special;
 
-	scsi_free_sgtable(&bidi_sdb->table, false);
+	sg_free_table_chained(&bidi_sdb->table, false);
 	kmem_cache_free(scsi_sdb_cache, bidi_sdb);
 	cmd->request->next_rq->special = NULL;
 }
@@ -1089,7 +1089,7 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb)
 	/*
 	 * If sg table allocation fails, requeue request later.
 	 */
-	if (unlikely(scsi_alloc_sgtable(&sdb->table, req->nr_phys_segments,
+	if (unlikely(sg_alloc_table_chained(&sdb->table, req->nr_phys_segments,
 					sdb->table.sgl)))
 		return BLKPREP_DEFER;
 
@@ -1162,7 +1162,7 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 
 		ivecs = blk_rq_count_integrity_sg(rq->q, rq->bio);
 
-		if (scsi_alloc_sgtable(&prot_sdb->table, ivecs,
+		if (sg_alloc_table_chained(&prot_sdb->table, ivecs,
 				prot_sdb->table.sgl)) {
 			error = BLKPREP_DEFER;
 			goto err_exit;
@@ -2280,7 +2280,7 @@ int __init scsi_init_queue(void)
 	}
 
 	for (i = 0; i < SG_MEMPOOL_NR; i++) {
-		struct scsi_host_sg_pool *sgp = scsi_sg_pools + i;
+		struct sg_pool *sgp = sg_pools + i;
 		int size = sgp->size * sizeof(struct scatterlist);
 
 		sgp->slab = kmem_cache_create(sgp->name, size, 0,
@@ -2304,7 +2304,7 @@ int __init scsi_init_queue(void)
 
 cleanup_sdb:
 	for (i = 0; i < SG_MEMPOOL_NR; i++) {
-		struct scsi_host_sg_pool *sgp = scsi_sg_pools + i;
+		struct sg_pool *sgp = sg_pools + i;
 		if (sgp->pool)
 			mempool_destroy(sgp->pool);
 		if (sgp->slab)
@@ -2322,7 +2322,7 @@ void scsi_exit_queue(void)
 	kmem_cache_destroy(scsi_sdb_cache);
 
 	for (i = 0; i < SG_MEMPOOL_NR; i++) {
-		struct scsi_host_sg_pool *sgp = scsi_sg_pools + i;
+		struct sg_pool *sgp = sg_pools + i;
 		mempool_destroy(sgp->pool);
 		kmem_cache_destroy(sgp->slab);
 	}

commit 22cc3d4c6f4c529f4bf17445c60893b13e7611fb
Author: Ming Lin <ming.l@ssi.samsung.com>
Date:   Mon Apr 4 14:48:08 2016 -0700

    scsi: replace "mq" with "first_chunk" in SG functions
    
    Parameter "bool mq" is block driver specific.
    Change it to "first_chunk" to make it more generic.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Ming Lin <ming.l@ssi.samsung.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4229c183648b..9675353770e9 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -583,33 +583,32 @@ static struct scatterlist *scsi_sg_alloc(unsigned int nents, gfp_t gfp_mask)
 	return mempool_alloc(sgp->pool, gfp_mask);
 }
 
-static void scsi_free_sgtable(struct sg_table *table, bool mq)
+static void scsi_free_sgtable(struct sg_table *table, bool first_chunk)
 {
-	if (mq && table->orig_nents <= SCSI_MAX_SG_SEGMENTS)
+	if (first_chunk && table->orig_nents <= SCSI_MAX_SG_SEGMENTS)
 		return;
-	__sg_free_table(table, SCSI_MAX_SG_SEGMENTS, mq, scsi_sg_free);
+	__sg_free_table(table, SCSI_MAX_SG_SEGMENTS, first_chunk, scsi_sg_free);
 }
 
-static int scsi_alloc_sgtable(struct sg_table *table, int nents, bool mq)
+static int scsi_alloc_sgtable(struct sg_table *table, int nents,
+		struct scatterlist *first_chunk)
 {
-	struct scatterlist *first_chunk = NULL;
 	int ret;
 
 	BUG_ON(!nents);
 
-	if (mq) {
+	if (first_chunk) {
 		if (nents <= SCSI_MAX_SG_SEGMENTS) {
 			table->nents = table->orig_nents = nents;
 			sg_init_table(table->sgl, nents);
 			return 0;
 		}
-		first_chunk = table->sgl;
 	}
 
 	ret = __sg_alloc_table(table, nents, SCSI_MAX_SG_SEGMENTS,
 			       first_chunk, GFP_ATOMIC, scsi_sg_alloc);
 	if (unlikely(ret))
-		scsi_free_sgtable(table, mq);
+		scsi_free_sgtable(table, (bool)first_chunk);
 	return ret;
 }
 
@@ -1091,7 +1090,7 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb)
 	 * If sg table allocation fails, requeue request later.
 	 */
 	if (unlikely(scsi_alloc_sgtable(&sdb->table, req->nr_phys_segments,
-					req->mq_ctx != NULL)))
+					sdb->table.sgl)))
 		return BLKPREP_DEFER;
 
 	/* 
@@ -1163,7 +1162,8 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 
 		ivecs = blk_rq_count_integrity_sg(rq->q, rq->bio);
 
-		if (scsi_alloc_sgtable(&prot_sdb->table, ivecs, is_mq)) {
+		if (scsi_alloc_sgtable(&prot_sdb->table, ivecs,
+				prot_sdb->table.sgl)) {
 			error = BLKPREP_DEFER;
 			goto err_exit;
 		}

commit 91dbc08d64fba7c1426a32be4c57ebb63c4be124
Author: Ming Lin <ming.l@ssi.samsung.com>
Date:   Mon Apr 4 14:48:07 2016 -0700

    scsi: replace "scsi_data_buffer" with "sg_table" in SG functions
    
    Replace parameter "struct scsi_data_buffer" with "struct sg_table" in
    SG alloc/free functions to make them generic.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Ming Lin <ming.l@ssi.samsung.com>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 8106515d1df8..4229c183648b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -583,14 +583,14 @@ static struct scatterlist *scsi_sg_alloc(unsigned int nents, gfp_t gfp_mask)
 	return mempool_alloc(sgp->pool, gfp_mask);
 }
 
-static void scsi_free_sgtable(struct scsi_data_buffer *sdb, bool mq)
+static void scsi_free_sgtable(struct sg_table *table, bool mq)
 {
-	if (mq && sdb->table.orig_nents <= SCSI_MAX_SG_SEGMENTS)
+	if (mq && table->orig_nents <= SCSI_MAX_SG_SEGMENTS)
 		return;
-	__sg_free_table(&sdb->table, SCSI_MAX_SG_SEGMENTS, mq, scsi_sg_free);
+	__sg_free_table(table, SCSI_MAX_SG_SEGMENTS, mq, scsi_sg_free);
 }
 
-static int scsi_alloc_sgtable(struct scsi_data_buffer *sdb, int nents, bool mq)
+static int scsi_alloc_sgtable(struct sg_table *table, int nents, bool mq)
 {
 	struct scatterlist *first_chunk = NULL;
 	int ret;
@@ -599,17 +599,17 @@ static int scsi_alloc_sgtable(struct scsi_data_buffer *sdb, int nents, bool mq)
 
 	if (mq) {
 		if (nents <= SCSI_MAX_SG_SEGMENTS) {
-			sdb->table.nents = sdb->table.orig_nents = nents;
-			sg_init_table(sdb->table.sgl, nents);
+			table->nents = table->orig_nents = nents;
+			sg_init_table(table->sgl, nents);
 			return 0;
 		}
-		first_chunk = sdb->table.sgl;
+		first_chunk = table->sgl;
 	}
 
-	ret = __sg_alloc_table(&sdb->table, nents, SCSI_MAX_SG_SEGMENTS,
+	ret = __sg_alloc_table(table, nents, SCSI_MAX_SG_SEGMENTS,
 			       first_chunk, GFP_ATOMIC, scsi_sg_alloc);
 	if (unlikely(ret))
-		scsi_free_sgtable(sdb, mq);
+		scsi_free_sgtable(table, mq);
 	return ret;
 }
 
@@ -625,12 +625,17 @@ static void scsi_uninit_cmd(struct scsi_cmnd *cmd)
 
 static void scsi_mq_free_sgtables(struct scsi_cmnd *cmd)
 {
+	struct scsi_data_buffer *sdb;
+
 	if (cmd->sdb.table.nents)
-		scsi_free_sgtable(&cmd->sdb, true);
-	if (cmd->request->next_rq && cmd->request->next_rq->special)
-		scsi_free_sgtable(cmd->request->next_rq->special, true);
+		scsi_free_sgtable(&cmd->sdb.table, true);
+	if (cmd->request->next_rq) {
+		sdb = cmd->request->next_rq->special;
+		if (sdb)
+			scsi_free_sgtable(&sdb->table, true);
+	}
 	if (scsi_prot_sg_count(cmd))
-		scsi_free_sgtable(cmd->prot_sdb, true);
+		scsi_free_sgtable(&cmd->prot_sdb->table, true);
 }
 
 static void scsi_mq_uninit_cmd(struct scsi_cmnd *cmd)
@@ -669,19 +674,19 @@ static void scsi_mq_uninit_cmd(struct scsi_cmnd *cmd)
 static void scsi_release_buffers(struct scsi_cmnd *cmd)
 {
 	if (cmd->sdb.table.nents)
-		scsi_free_sgtable(&cmd->sdb, false);
+		scsi_free_sgtable(&cmd->sdb.table, false);
 
 	memset(&cmd->sdb, 0, sizeof(cmd->sdb));
 
 	if (scsi_prot_sg_count(cmd))
-		scsi_free_sgtable(cmd->prot_sdb, false);
+		scsi_free_sgtable(&cmd->prot_sdb->table, false);
 }
 
 static void scsi_release_bidi_buffers(struct scsi_cmnd *cmd)
 {
 	struct scsi_data_buffer *bidi_sdb = cmd->request->next_rq->special;
 
-	scsi_free_sgtable(bidi_sdb, false);
+	scsi_free_sgtable(&bidi_sdb->table, false);
 	kmem_cache_free(scsi_sdb_cache, bidi_sdb);
 	cmd->request->next_rq->special = NULL;
 }
@@ -1085,7 +1090,7 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb)
 	/*
 	 * If sg table allocation fails, requeue request later.
 	 */
-	if (unlikely(scsi_alloc_sgtable(sdb, req->nr_phys_segments,
+	if (unlikely(scsi_alloc_sgtable(&sdb->table, req->nr_phys_segments,
 					req->mq_ctx != NULL)))
 		return BLKPREP_DEFER;
 
@@ -1158,7 +1163,7 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 
 		ivecs = blk_rq_count_integrity_sg(rq->q, rq->bio);
 
-		if (scsi_alloc_sgtable(prot_sdb, ivecs, is_mq)) {
+		if (scsi_alloc_sgtable(&prot_sdb->table, ivecs, is_mq)) {
 			error = BLKPREP_DEFER;
 			goto err_exit;
 		}

commit a7dee8f45fa2948b74d8e84ba24e435c87fd0acf
Merge: 7ee7895c93d1 5ecee0a3ee8d
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Tue Mar 15 15:24:44 2016 -0700

    Merge branch 'fixes' into misc

commit e1cd3911170eda37fd9501e81ee1c2eb63803fd0
Author: jiangyiwen <jiangyiwen@huawei.com>
Date:   Tue Feb 16 20:14:13 2016 +0800

    SCSI: Free resources when we return BLKPREP_INVALID
    
    When called scsi_prep_fn return BLKPREP_INVALID, we should use the same
    code with BLKPREP_KILL in scsi_prep_return.
    
    Signed-off-by: Yiwen Jiang <jiangyiwen@huawei.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index fa6b2c4eb7a2..8c6e31874171 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1344,6 +1344,7 @@ scsi_prep_return(struct request_queue *q, struct request *req, int ret)
 
 	switch (ret) {
 	case BLKPREP_KILL:
+	case BLKPREP_INVALID:
 		req->errors = DID_NO_CONNECT << 16;
 		/* release the command and kill it */
 		if (req->special) {

commit d3d328919f278eda489a482541583f79987ad0e2
Author: Hannes Reinecke <hare@suse.de>
Date:   Fri Feb 19 09:17:16 2016 +0100

    scsi_dh: add 'rescan' callback
    
    If a device needs to be rescanned the device_handler might need
    to be rechecked, too.
    So add a 'rescan' callback to the device handler and call it
    upon scsi_rescan_device(). The rescan callback will be invoked
    from the Unit Attention handling of ASC/ASCQ 3F 03
    (INQUIRY DATA HAS CHANGED).
    
    Reviewed-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index fa6b2c4eb7a2..d46193a5e246 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2699,6 +2699,7 @@ static void scsi_evt_emit(struct scsi_device *sdev, struct scsi_event *evt)
 		envp[idx++] = "SDEV_MEDIA_CHANGE=1";
 		break;
 	case SDEV_EVT_INQUIRY_CHANGE_REPORTED:
+		scsi_rescan_device(&sdev->sdev_gendev);
 		envp[idx++] = "SDEV_UA=INQUIRY_DATA_HAS_CHANGED";
 		break;
 	case SDEV_EVT_CAPACITY_CHANGE_REPORTED:

commit a8aa3978588a4fa2d9edabc151adedd97bbed091
Author: Hannes Reinecke <hare@suse.de>
Date:   Tue Dec 1 10:16:57 2015 +0100

    scsi: Add scsi_vpd_tpg_id()
    
    Implement scsi_vpd_tpg_id() to extract the target
    port group id and the relative port id from
    SCSI VPD page 0x83.
    
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e352c2b7deaf..fa6b2c4eb7a2 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -23,6 +23,7 @@
 #include <linux/scatterlist.h>
 #include <linux/blk-mq.h>
 #include <linux/ratelimit.h>
+#include <asm/unaligned.h>
 
 #include <scsi/scsi.h>
 #include <scsi/scsi_cmnd.h>
@@ -3294,3 +3295,50 @@ int scsi_vpd_lun_id(struct scsi_device *sdev, char *id, size_t id_len)
 	return id_size;
 }
 EXPORT_SYMBOL(scsi_vpd_lun_id);
+
+/*
+ * scsi_vpd_tpg_id - return a target port group identifier
+ * @sdev: SCSI device
+ *
+ * Returns the Target Port Group identifier from the information
+ * froom VPD page 0x83 of the device.
+ *
+ * Returns the identifier or error on failure.
+ */
+int scsi_vpd_tpg_id(struct scsi_device *sdev, int *rel_id)
+{
+	unsigned char *d;
+	unsigned char __rcu *vpd_pg83;
+	int group_id = -EAGAIN, rel_port = -1;
+
+	rcu_read_lock();
+	vpd_pg83 = rcu_dereference(sdev->vpd_pg83);
+	if (!vpd_pg83) {
+		rcu_read_unlock();
+		return -ENXIO;
+	}
+
+	d = sdev->vpd_pg83 + 4;
+	while (d < sdev->vpd_pg83 + sdev->vpd_pg83_len) {
+		switch (d[1] & 0xf) {
+		case 0x4:
+			/* Relative target port */
+			rel_port = get_unaligned_be16(&d[6]);
+			break;
+		case 0x5:
+			/* Target port group */
+			group_id = get_unaligned_be16(&d[6]);
+			break;
+		default:
+			break;
+		}
+		d += d[3] + 4;
+	}
+	rcu_read_unlock();
+
+	if (group_id >= 0 && rel_id && rel_port != -1)
+		*rel_id = rel_port;
+
+	return group_id;
+}
+EXPORT_SYMBOL(scsi_vpd_tpg_id);

commit 9983bed3907c379d1d30b7509bb0a871ed655f9d
Author: Hannes Reinecke <hare@suse.de>
Date:   Tue Dec 1 10:16:55 2015 +0100

    scsi: Add scsi_vpd_lun_id()
    
    Add a function scsi_vpd_lun_id() to return a unique device
    identifcation based on the designation descriptors of
    VPD page 0x83.
    
    As devices might implement several descriptors the order
    of preference is:
    - NAA IEE Registered Extended
    - EUI-64 based 16-byte
    - EUI-64 based 12-byte
    - NAA IEEE Registered
    - NAA IEEE Extended
    A SCSI name string descriptor is preferred to all of them
    if the identification is longer than 16 bytes.
    
    The returned unique device identification will be formatted
    as a SCSI Name string to avoid clashes between different
    designator types.
    
    [mkp: Fixed up kernel doc comment from Johannes]
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Ewan Milne <emilne@redhat.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index dd8ad2a44510..e352c2b7deaf 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -3154,3 +3154,143 @@ void sdev_enable_disk_events(struct scsi_device *sdev)
 	atomic_dec(&sdev->disk_events_disable_depth);
 }
 EXPORT_SYMBOL(sdev_enable_disk_events);
+
+/**
+ * scsi_vpd_lun_id - return a unique device identification
+ * @sdev: SCSI device
+ * @id:   buffer for the identification
+ * @id_len:  length of the buffer
+ *
+ * Copies a unique device identification into @id based
+ * on the information in the VPD page 0x83 of the device.
+ * The string will be formatted as a SCSI name string.
+ *
+ * Returns the length of the identification or error on failure.
+ * If the identifier is longer than the supplied buffer the actual
+ * identifier length is returned and the buffer is not zero-padded.
+ */
+int scsi_vpd_lun_id(struct scsi_device *sdev, char *id, size_t id_len)
+{
+	u8 cur_id_type = 0xff;
+	u8 cur_id_size = 0;
+	unsigned char *d, *cur_id_str;
+	unsigned char __rcu *vpd_pg83;
+	int id_size = -EINVAL;
+
+	rcu_read_lock();
+	vpd_pg83 = rcu_dereference(sdev->vpd_pg83);
+	if (!vpd_pg83) {
+		rcu_read_unlock();
+		return -ENXIO;
+	}
+
+	/*
+	 * Look for the correct descriptor.
+	 * Order of preference for lun descriptor:
+	 * - SCSI name string
+	 * - NAA IEEE Registered Extended
+	 * - EUI-64 based 16-byte
+	 * - EUI-64 based 12-byte
+	 * - NAA IEEE Registered
+	 * - NAA IEEE Extended
+	 * as longer descriptors reduce the likelyhood
+	 * of identification clashes.
+	 */
+
+	/* The id string must be at least 20 bytes + terminating NULL byte */
+	if (id_len < 21) {
+		rcu_read_unlock();
+		return -EINVAL;
+	}
+
+	memset(id, 0, id_len);
+	d = vpd_pg83 + 4;
+	while (d < vpd_pg83 + sdev->vpd_pg83_len) {
+		/* Skip designators not referring to the LUN */
+		if ((d[1] & 0x30) != 0x00)
+			goto next_desig;
+
+		switch (d[1] & 0xf) {
+		case 0x2:
+			/* EUI-64 */
+			if (cur_id_size > d[3])
+				break;
+			/* Prefer NAA IEEE Registered Extended */
+			if (cur_id_type == 0x3 &&
+			    cur_id_size == d[3])
+				break;
+			cur_id_size = d[3];
+			cur_id_str = d + 4;
+			cur_id_type = d[1] & 0xf;
+			switch (cur_id_size) {
+			case 8:
+				id_size = snprintf(id, id_len,
+						   "eui.%8phN",
+						   cur_id_str);
+				break;
+			case 12:
+				id_size = snprintf(id, id_len,
+						   "eui.%12phN",
+						   cur_id_str);
+				break;
+			case 16:
+				id_size = snprintf(id, id_len,
+						   "eui.%16phN",
+						   cur_id_str);
+				break;
+			default:
+				cur_id_size = 0;
+				break;
+			}
+			break;
+		case 0x3:
+			/* NAA */
+			if (cur_id_size > d[3])
+				break;
+			cur_id_size = d[3];
+			cur_id_str = d + 4;
+			cur_id_type = d[1] & 0xf;
+			switch (cur_id_size) {
+			case 8:
+				id_size = snprintf(id, id_len,
+						   "naa.%8phN",
+						   cur_id_str);
+				break;
+			case 16:
+				id_size = snprintf(id, id_len,
+						   "naa.%16phN",
+						   cur_id_str);
+				break;
+			default:
+				cur_id_size = 0;
+				break;
+			}
+			break;
+		case 0x8:
+			/* SCSI name string */
+			if (cur_id_size + 4 > d[3])
+				break;
+			/* Prefer others for truncated descriptor */
+			if (cur_id_size && d[3] > id_len)
+				break;
+			cur_id_size = id_size = d[3];
+			cur_id_str = d + 4;
+			cur_id_type = d[1] & 0xf;
+			if (cur_id_size >= id_len)
+				cur_id_size = id_len - 1;
+			memcpy(id, cur_id_str, cur_id_size);
+			/* Decrease priority for truncated descriptor */
+			if (cur_id_size != id_size)
+				cur_id_size = 6;
+			break;
+		default:
+			break;
+		}
+next_desig:
+		d += d[3] + 4;
+	}
+	rcu_read_unlock();
+
+	return id_size;
+}
+EXPORT_SYMBOL(scsi_vpd_lun_id);

commit 71baba4b92dc1fa1bc461742c6ab1942ec6034e9
Author: Mel Gorman <mgorman@techsingularity.net>
Date:   Fri Nov 6 16:28:28 2015 -0800

    mm, page_alloc: rename __GFP_WAIT to __GFP_RECLAIM
    
    __GFP_WAIT was used to signal that the caller was in atomic context and
    could not sleep.  Now it is possible to distinguish between true atomic
    context and callers that are not willing to sleep.  The latter should
    clear __GFP_DIRECT_RECLAIM so kswapd will still wake.  As clearing
    __GFP_WAIT behaves differently, there is a risk that people will clear the
    wrong flags.  This patch renames __GFP_WAIT to __GFP_RECLAIM to clearly
    indicate what it does -- setting it allows all reclaim activity, clearing
    them prevents it.
    
    [akpm@linux-foundation.org: fix build]
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Mel Gorman <mgorman@techsingularity.net>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Christoph Lameter <cl@linux.com>
    Acked-by: David Rientjes <rientjes@google.com>
    Cc: Vitaly Wool <vitalywool@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 126a48c6431e..dd8ad2a44510 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -222,13 +222,13 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	int write = (data_direction == DMA_TO_DEVICE);
 	int ret = DRIVER_ERROR << 24;
 
-	req = blk_get_request(sdev->request_queue, write, __GFP_WAIT);
+	req = blk_get_request(sdev->request_queue, write, __GFP_RECLAIM);
 	if (IS_ERR(req))
 		return ret;
 	blk_rq_set_block_pc(req);
 
 	if (bufflen &&	blk_rq_map_kern(sdev->request_queue, req,
-					buffer, bufflen, __GFP_WAIT))
+					buffer, bufflen, __GFP_RECLAIM))
 		goto out;
 
 	req->cmd_len = COMMAND_SIZE(cmd[0]);

commit f4829a9b7a61e159367350008a608b062c4f6840
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Sep 27 21:01:50 2015 +0200

    blk-mq: fix racy updates of rq->errors
    
    blk_mq_complete_request may be a no-op if the request has already
    been completed by others means (e.g. a timeout or cancellation), but
    currently drivers have to set rq->errors before calling
    blk_mq_complete_request, which might leave us with the wrong error value.
    
    Add an error parameter to blk_mq_complete_request so that we can
    defer setting rq->errors until we known we won the race to complete the
    request.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Sagi Grimberg <sagig@mellanox.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index cbfc5990052b..126a48c6431e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1957,7 +1957,7 @@ static int scsi_mq_prep_fn(struct request *req)
 static void scsi_mq_done(struct scsi_cmnd *cmd)
 {
 	trace_scsi_dispatch_cmd_done(cmd);
-	blk_mq_complete_request(cmd->request);
+	blk_mq_complete_request(cmd->request, cmd->request->errors);
 }
 
 static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,

commit ee14c674e8fc57251223054fb52dc0ecfe711028
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Aug 27 14:16:59 2015 +0200

    scsi_dh: kill struct scsi_dh_data
    
    Add a ->handler and a ->handler_data field to struct scsi_device and kill
    this indirection.  Also move struct scsi_device_handler to scsi_dh.h so that
    changes to it don't require rebuilding every SCSI LLDD.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: James Bottomley <JBottomley@Odin.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 882864f5cbae..cbfc5990052b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -31,6 +31,7 @@
 #include <scsi/scsi_driver.h>
 #include <scsi/scsi_eh.h>
 #include <scsi/scsi_host.h>
+#include <scsi/scsi_dh.h>
 
 #include <trace/events/scsi.h>
 
@@ -1248,9 +1249,8 @@ static int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
 {
 	struct scsi_cmnd *cmd = req->special;
 
-	if (unlikely(sdev->scsi_dh_data && sdev->scsi_dh_data->scsi_dh
-			 && sdev->scsi_dh_data->scsi_dh->prep_fn)) {
-		int ret = sdev->scsi_dh_data->scsi_dh->prep_fn(sdev, req);
+	if (unlikely(sdev->handler && sdev->handler->prep_fn)) {
+		int ret = sdev->handler->prep_fn(sdev, req);
 		if (ret != BLKPREP_OK)
 			return ret;
 	}

commit 14c3e677df9fa2e4bf87b9de683452fc140934b2
Author: Hannes Reinecke <hare@suse.de>
Date:   Mon Jul 6 13:41:53 2015 +0200

    scsi: Add ALUA state change UA handling
    
    Log the ALUA state change unit attention correctly with
    the message log and emit an event to allow user-space
    tools to react to it.
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Ewan D. Milne <emilne@redhat.com>
    Reviewed-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Signed-off-by: James Bottomley <JBottomley@Odin.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index dffa91c67f5b..882864f5cbae 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2712,6 +2712,9 @@ static void scsi_evt_emit(struct scsi_device *sdev, struct scsi_event *evt)
 	case SDEV_EVT_LUN_CHANGE_REPORTED:
 		envp[idx++] = "SDEV_UA=REPORTED_LUNS_DATA_HAS_CHANGED";
 		break;
+	case SDEV_EVT_ALUA_STATE_CHANGE_REPORTED:
+		envp[idx++] = "SDEV_UA=ASYMMETRIC_ACCESS_STATE_CHANGED";
+		break;
 	default:
 		/* do nothing */
 		break;
@@ -2815,6 +2818,7 @@ struct scsi_event *sdev_evt_alloc(enum scsi_device_event evt_type,
 	case SDEV_EVT_SOFT_THRESHOLD_REACHED_REPORTED:
 	case SDEV_EVT_MODE_PARAMETER_CHANGE_REPORTED:
 	case SDEV_EVT_LUN_CHANGE_REPORTED:
+	case SDEV_EVT_ALUA_STATE_CHANGE_REPORTED:
 	default:
 		/* do nothing */
 		break;

commit 0ae80ba91f57726f31b5b5890cb7c5173e624ca4
Author: Hannes Reinecke <hare@suse.de>
Date:   Fri Jun 12 16:12:48 2015 +0200

    scsi: retry MODE SENSE on unit attention
    
    The 'sd' driver is calling scsi_mode_sense() to figure out
    internal details. But scsi_mode_sense() never checks for
    any pending unit attentions, so we're getting annoying error
    messages like:
    
    MODE SENSE: unimplemented page/subpage: 0x00/0x00
    
    and a possible wrong decision for device cache handling.
    
    Reviewed-by: Ewan Milne <emilne@redhat.com>
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: James Bottomley <JBottomley@Odin.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 448ebdaa3d69..dffa91c67f5b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2423,7 +2423,7 @@ scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
 	unsigned char cmd[12];
 	int use_10_for_ms;
 	int header_length;
-	int result;
+	int result, retry_count = retries;
 	struct scsi_sense_hdr my_sshdr;
 
 	memset(data, 0, sizeof(*data));
@@ -2502,6 +2502,11 @@ scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
 			data->block_descriptor_length = buffer[3];
 		}
 		data->header_length = header_length;
+	} else if ((status_byte(result) == CHECK_CONDITION) &&
+		   scsi_sense_valid(sshdr) &&
+		   sshdr->sense_key == UNIT_ATTENTION && retry_count) {
+		retry_count--;
+		goto retry;
 	}
 
 	return result;

commit 0c958ecc69c277b25f38f72bc6d18ab145e8167c
Author: Tony Battersby <tonyb@cybernetics.com>
Date:   Thu Jul 16 11:40:41 2015 -0400

    scsi: fix memory leak with scsi-mq
    
    Fix a memory leak with scsi-mq triggered by commands with large data
    transfer length.
    
    __sg_alloc_table() sets both table->nents and table->orig_nents to the
    same value.  When the scatterlist is DMA-mapped, table->nents is
    overwritten with the (possibly smaller) size of the DMA-mapped
    scatterlist, while table->orig_nents retains the original size of the
    allocated scatterlist.  scsi_free_sgtable() should therefore check
    orig_nents instead of nents, and all code that initializes sdb->table
    without calling __sg_alloc_table() should set both nents and orig_nents.
    
    Fixes: d285203cf647 ("scsi: add support for a blk-mq based I/O path.")
    Cc: <stable@vger.kernel.org> # 3.17+
    Signed-off-by: Tony Battersby <tonyb@cybernetics.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Ewan D. Milne <emilne@redhat.com>
    Signed-off-by: James Bottomley <JBottomley@Odin.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b1a263137a23..448ebdaa3d69 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -583,7 +583,7 @@ static struct scatterlist *scsi_sg_alloc(unsigned int nents, gfp_t gfp_mask)
 
 static void scsi_free_sgtable(struct scsi_data_buffer *sdb, bool mq)
 {
-	if (mq && sdb->table.nents <= SCSI_MAX_SG_SEGMENTS)
+	if (mq && sdb->table.orig_nents <= SCSI_MAX_SG_SEGMENTS)
 		return;
 	__sg_free_table(&sdb->table, SCSI_MAX_SG_SEGMENTS, mq, scsi_sg_free);
 }
@@ -597,8 +597,8 @@ static int scsi_alloc_sgtable(struct scsi_data_buffer *sdb, int nents, bool mq)
 
 	if (mq) {
 		if (nents <= SCSI_MAX_SG_SEGMENTS) {
-			sdb->table.nents = nents;
-			sg_init_table(sdb->table.sgl, sdb->table.nents);
+			sdb->table.nents = sdb->table.orig_nents = nents;
+			sg_init_table(sdb->table.sgl, nents);
 			return 0;
 		}
 		first_chunk = sdb->table.sgl;

commit bba0bdd7ad4713d82338bcd9b72d57e9335a664b
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Wed Mar 4 10:31:47 2015 +0100

    Defer processing of REQ_PREEMPT requests for blocked devices
    
    SCSI transport drivers and SCSI LLDs block a SCSI device if the
    transport layer is not operational. This means that in this state
    no requests should be processed, even if the REQ_PREEMPT flag has
    been set. This patch avoids that a rescan shortly after a cable
    pull sporadically triggers the following kernel oops:
    
    BUG: unable to handle kernel paging request at ffffc9001a6bc084
    IP: [<ffffffffa04e08f2>] mlx4_ib_post_send+0xd2/0xb30 [mlx4_ib]
    Process rescan-scsi-bus (pid: 9241, threadinfo ffff88053484a000, task ffff880534aae100)
    Call Trace:
     [<ffffffffa0718135>] srp_post_send+0x65/0x70 [ib_srp]
     [<ffffffffa071b9df>] srp_queuecommand+0x1cf/0x3e0 [ib_srp]
     [<ffffffffa0001ff1>] scsi_dispatch_cmd+0x101/0x280 [scsi_mod]
     [<ffffffffa0009ad1>] scsi_request_fn+0x411/0x4d0 [scsi_mod]
     [<ffffffff81223b37>] __blk_run_queue+0x27/0x30
     [<ffffffff8122a8d2>] blk_execute_rq_nowait+0x82/0x110
     [<ffffffff8122a9c2>] blk_execute_rq+0x62/0xf0
     [<ffffffffa000b0e8>] scsi_execute+0xe8/0x190 [scsi_mod]
     [<ffffffffa000b2f3>] scsi_execute_req+0xa3/0x130 [scsi_mod]
     [<ffffffffa000c1aa>] scsi_probe_lun+0x17a/0x450 [scsi_mod]
     [<ffffffffa000ce86>] scsi_probe_and_add_lun+0x156/0x480 [scsi_mod]
     [<ffffffffa000dc2f>] __scsi_scan_target+0xdf/0x1f0 [scsi_mod]
     [<ffffffffa000dfa3>] scsi_scan_host_selected+0x183/0x1c0 [scsi_mod]
     [<ffffffffa000edfb>] scsi_scan+0xdb/0xe0 [scsi_mod]
     [<ffffffffa000ee13>] store_scan+0x13/0x20 [scsi_mod]
     [<ffffffff811c8d9b>] sysfs_write_file+0xcb/0x160
     [<ffffffff811589de>] vfs_write+0xce/0x140
     [<ffffffff81158b53>] sys_write+0x53/0xa0
     [<ffffffff81464592>] system_call_fastpath+0x16/0x1b
     [<00007f611c9d9300>] 0x7f611c9d92ff
    
    Reported-by: Max Gurtuvoy <maxg@mellanox.com>
    Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Reviewed-by: Mike Christie <michaelc@cs.wisc.edu>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: James Bottomley <JBottomley@Odin.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 54d7a6cbb98a..b1a263137a23 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1311,9 +1311,11 @@ scsi_prep_state_check(struct scsi_device *sdev, struct request *req)
 				    "rejecting I/O to dead device\n");
 			ret = BLKPREP_KILL;
 			break;
-		case SDEV_QUIESCE:
 		case SDEV_BLOCK:
 		case SDEV_CREATED_BLOCK:
+			ret = BLKPREP_DEFER;
+			break;
+		case SDEV_QUIESCE:
 			/*
 			 * If the devices is blocked we defer normal commands.
 			 */

commit 3e12cefbe143b4947171ff92dd50024c4841e291
Merge: 6bec00352861 d427e3c82ef4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Feb 12 14:13:23 2015 -0800

    Merge branch 'for-3.20/core' of git://git.kernel.dk/linux-block
    
    Pull core block IO changes from Jens Axboe:
     "This contains:
    
       - A series from Christoph that cleans up and refactors various parts
         of the REQ_BLOCK_PC handling.  Contributions in that series from
         Dongsu Park and Kent Overstreet as well.
    
       - CFQ:
            - A bug fix for cfq for realtime IO scheduling from Jeff Moyer.
            - A stable patch fixing a potential crash in CFQ in OOM
              situations.  From Konstantin Khlebnikov.
    
       - blk-mq:
            - Add support for tag allocation policies, from Shaohua. This is
              a prep patch enabling libata (and other SCSI parts) to use the
              blk-mq tagging, instead of rolling their own.
            - Various little tweaks from Keith and Mike, in preparation for
              DM blk-mq support.
            - Minor little fixes or tweaks from me.
            - A double free error fix from Tony Battersby.
    
       - The partition 4k issue fixes from Matthew and Boaz.
    
       - Add support for zero+unprovision for blkdev_issue_zeroout() from
         Martin"
    
    * 'for-3.20/core' of git://git.kernel.dk/linux-block: (27 commits)
      block: remove unused function blk_bio_map_sg
      block: handle the null_mapped flag correctly in blk_rq_map_user_iov
      blk-mq: fix double-free in error path
      block: prevent request-to-request merging with gaps if not allowed
      blk-mq: make blk_mq_run_queues() static
      dm: fix multipath regression due to initializing wrong request
      cfq-iosched: handle failure of cfq group allocation
      block: Quiesce zeroout wrapper
      block: rewrite and split __bio_copy_iov()
      block: merge __bio_map_user_iov into bio_map_user_iov
      block: merge __bio_map_kern into bio_map_kern
      block: pass iov_iter to the BLOCK_PC mapping functions
      block: add a helper to free bio bounce buffer pages
      block: use blk_rq_map_user_iov to implement blk_rq_map_user
      block: simplify bio_map_kern
      block: mark blk-mq devices as stackable
      block: keep established cmd_flags when cloning into a blk-mq request
      block: add blk-mq support to blk_insert_cloned_request()
      block: require blk_rq_prep_clone() be given an initialized clone request
      blk-mq: add tag allocation policy
      ...

commit 24391c0dc57c3756a219defaa781e68637d6ab7d
Author: Shaohua Li <shli@fb.com>
Date:   Fri Jan 23 14:18:00 2015 -0700

    blk-mq: add tag allocation policy
    
    This is the blk-mq part to support tag allocation policy. The default
    allocation policy isn't changed (though it's not a strict FIFO). The new
    policy is round-robin for libata. But it's a try-best implementation. If
    multiple tasks are competing, the tags returned will be mixed (which is
    unavoidable even with !mq, as requests from different tasks can be
    mixed in queue)
    
    Cc: Jens Axboe <axboe@fb.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Shaohua Li <shli@fb.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9ea95dd3e260..49ab11508286 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2188,6 +2188,8 @@ int scsi_mq_setup_tags(struct Scsi_Host *shost)
 	shost->tag_set.cmd_size = cmd_size;
 	shost->tag_set.numa_node = NUMA_NO_NODE;
 	shost->tag_set.flags = BLK_MQ_F_SHOULD_MERGE | BLK_MQ_F_SG_MERGE;
+	shost->tag_set.flags |=
+		BLK_ALLOC_POLICY_TO_MQ_FLAG(shost->hostt->tag_alloc_policy);
 	shost->tag_set.driver_data = shost;
 
 	return blk_mq_alloc_tag_set(&shost->tag_set);

commit 91724c20613484555ba7e7b3d8549dac1e24f7a8
Author: Ewan D. Milne <emilne@redhat.com>
Date:   Thu Jan 15 10:02:12 2015 -0500

    scsi: Avoid crashing if device uses DIX but adapter does not support it
    
    This can happen if a multipathed device uses DIX and another path is
    added via an adapter that does not support it.  Multipath should not
    allow this path to be added, but we should not depend upon that to avoid
    crashing.
    
    Signed-off-by: Ewan D. Milne <emilne@redhat.com>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 6d5c0b8cb0bb..17bb541f7cc2 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1143,7 +1143,17 @@ int scsi_init_io(struct scsi_cmnd *cmd)
 		struct scsi_data_buffer *prot_sdb = cmd->prot_sdb;
 		int ivecs, count;
 
-		BUG_ON(prot_sdb == NULL);
+		if (prot_sdb == NULL) {
+			/*
+			 * This can happen if someone (e.g. multipath)
+			 * queues a command to a device on an adapter
+			 * that does not support DIX.
+			 */
+			WARN_ON_ONCE(1);
+			error = BLKPREP_KILL;
+			goto err_exit;
+		}
+
 		ivecs = blk_rq_count_integrity_sg(rq->q, rq->bio);
 
 		if (scsi_alloc_sgtable(prot_sdb, ivecs, is_mq)) {

commit 70a0f2c1898c6abf53670e55642b6e840b003892
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jan 5 20:29:38 2015 +0100

    scsi: ->queue_rq can't sleep
    
    The blk-mq ->queue_rq method is always called from process context,
    but might have preemption disabled.  This means we still always
    have to use GFP_ATOMIC for memory allocations, and thus need to
    revert part of commit 3c356bde1 ("scsi: stop passing a gfp_mask
    argument down the command setup path").
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reported-by: Sasha Levin <sasha.levin@oracle.com>
    Reviewed-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Tested-by: Alexei Starovoitov <alexei.starovoitov@gmail.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9ea95dd3e260..6d5c0b8cb0bb 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -591,7 +591,6 @@ static void scsi_free_sgtable(struct scsi_data_buffer *sdb, bool mq)
 static int scsi_alloc_sgtable(struct scsi_data_buffer *sdb, int nents, bool mq)
 {
 	struct scatterlist *first_chunk = NULL;
-	gfp_t gfp_mask = mq ? GFP_NOIO : GFP_ATOMIC;
 	int ret;
 
 	BUG_ON(!nents);
@@ -606,7 +605,7 @@ static int scsi_alloc_sgtable(struct scsi_data_buffer *sdb, int nents, bool mq)
 	}
 
 	ret = __sg_alloc_table(&sdb->table, nents, SCSI_MAX_SG_SEGMENTS,
-			       first_chunk, gfp_mask, scsi_sg_alloc);
+			       first_chunk, GFP_ATOMIC, scsi_sg_alloc);
 	if (unlikely(ret))
 		scsi_free_sgtable(sdb, mq);
 	return ret;

commit 120bb3e1e36da9c1ae6b978c825a28b944a5d7c5
Author: Tony Battersby <tonyb@cybernetics.com>
Date:   Mon Dec 8 17:20:52 2014 -0500

    scsi: fix random memory corruption with scsi-mq + T10 PI
    
    This fixes random memory corruption triggered when all three of the
    following are true:
    
    * scsi-mq enabled
    * T10 Protection Information (DIF) enabled
    * SCSI host with sg_tablesize > SCSI_MAX_SG_SEGMENTS (128)
    
    The symptoms of this bug are unpredictable memory corruption, BUG()s,
    oopses, lockups, etc., any of which may appear to be completely
    unrelated to the root cause.
    
    Cc: <stable@vger.kernel.org> # 3.17.x, 3.18.x
    Signed-off-by: Tony Battersby <tonyb@cybernetics.com>
    Reviewed-by: Nicholas Bellinger <nab@linux-iscsi.org>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 43318d556cbc..9ea95dd3e260 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1918,7 +1918,9 @@ static int scsi_mq_prep_fn(struct request *req)
 
 	if (scsi_host_get_prot(shost)) {
 		cmd->prot_sdb = (void *)sg +
-			shost->sg_tablesize * sizeof(struct scatterlist);
+			min_t(unsigned int,
+			      shost->sg_tablesize, SCSI_MAX_SG_SEGMENTS) *
+			sizeof(struct scatterlist);
 		memset(cmd->prot_sdb, 0, sizeof(struct scsi_data_buffer));
 
 		cmd->prot_sdb->table.sgl =

commit caf292ae5bb9d57198ce001d8b762f7abae3a94d
Merge: 8f4385d590d4 fcbf6a087a7e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 13 14:14:23 2014 -0800

    Merge branch 'for-3.19/core' of git://git.kernel.dk/linux-block
    
    Pull block driver core update from Jens Axboe:
     "This is the pull request for the core block IO changes for 3.19.  Not
      a huge round this time, mostly lots of little good fixes:
    
       - Fix a bug in sysfs blktrace interface causing a NULL pointer
         dereference, when enabled/disabled through that API.  From Arianna
         Avanzini.
    
       - Various updates/fixes/improvements for blk-mq:
    
            - A set of updates from Bart, mostly fixing buts in the tag
              handling.
    
            - Cleanup/code consolidation from Christoph.
    
            - Extend queue_rq API to be able to handle batching issues of IO
              requests. NVMe will utilize this shortly. From me.
    
            - A few tag and request handling updates from me.
    
            - Cleanup of the preempt handling for running queues from Paolo.
    
            - Prevent running of unmapped hardware queues from Ming Lei.
    
            - Move the kdump memory limiting check to be in the correct
              location, from Shaohua.
    
            - Initialize all software queues at init time from Takashi. This
              prevents a kobject warning when CPUs are brought online that
              weren't online when a queue was registered.
    
       - Single writeback fix for I_DIRTY clearing from Tejun.  Queued with
         the core IO changes, since it's just a single fix.
    
       - Version X of the __bio_add_page() segment addition retry from
         Maurizio.  Hope the Xth time is the charm.
    
       - Documentation fixup for IO scheduler merging from Jan.
    
       - Introduce (and use) generic IO stat accounting helpers for non-rq
         drivers, from Gu Zheng.
    
       - Kill off artificial limiting of max sectors in a request from
         Christoph"
    
    * 'for-3.19/core' of git://git.kernel.dk/linux-block: (26 commits)
      bio: modify __bio_add_page() to accept pages that don't start a new segment
      blk-mq: Fix uninitialized kobject at CPU hotplugging
      blktrace: don't let the sysfs interface remove trace from running list
      blk-mq: Use all available hardware queues
      blk-mq: Micro-optimize bt_get()
      blk-mq: Fix a race between bt_clear_tag() and bt_get()
      blk-mq: Avoid that __bt_get_word() wraps multiple times
      blk-mq: Fix a use-after-free
      blk-mq: prevent unmapped hw queue from being scheduled
      blk-mq: re-check for available tags after running the hardware queue
      blk-mq: fix hang in bt_get()
      blk-mq: move the kdump check to blk_mq_alloc_tag_set
      blk-mq: cleanup tag free handling
      blk-mq: use 'nr_cpu_ids' as highest CPU ID count for hwq <-> cpu map
      blk: introduce generic io stat accounting help function
      blk-mq: handle the single queue case in blk_mq_hctx_next_cpu
      genhd: check for int overflow in disk_expand_part_tbl()
      blk-mq: add blk_mq_free_hctx_request()
      blk-mq: export blk_mq_free_request()
      blk-mq: use get_cpu/put_cpu instead of preempt_disable/preempt_enable
      ...

commit 82042a2cdb55cd8402207f14a6e2c24d7a5febe8
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Sep 5 18:23:07 2014 -0700

    scsi: move scsi_dispatch_cmd to scsi_lib.c
    
    scsi_lib.c is where the rest of the I/O submission path lives, so move
    scsi_dispatch_cmd there and mark it static.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Hannes Reinecke <hare@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index fcdc585278bf..7e3d954c9cac 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1640,6 +1640,87 @@ static void scsi_softirq_done(struct request *rq)
 	}
 }
 
+/**
+ * scsi_dispatch_command - Dispatch a command to the low-level driver.
+ * @cmd: command block we are dispatching.
+ *
+ * Return: nonzero return request was rejected and device's queue needs to be
+ * plugged.
+ */
+static int scsi_dispatch_cmd(struct scsi_cmnd *cmd)
+{
+	struct Scsi_Host *host = cmd->device->host;
+	int rtn = 0;
+
+	atomic_inc(&cmd->device->iorequest_cnt);
+
+	/* check if the device is still usable */
+	if (unlikely(cmd->device->sdev_state == SDEV_DEL)) {
+		/* in SDEV_DEL we error all commands. DID_NO_CONNECT
+		 * returns an immediate error upwards, and signals
+		 * that the device is no longer present */
+		cmd->result = DID_NO_CONNECT << 16;
+		goto done;
+	}
+
+	/* Check to see if the scsi lld made this device blocked. */
+	if (unlikely(scsi_device_blocked(cmd->device))) {
+		/*
+		 * in blocked state, the command is just put back on
+		 * the device queue.  The suspend state has already
+		 * blocked the queue so future requests should not
+		 * occur until the device transitions out of the
+		 * suspend state.
+		 */
+		SCSI_LOG_MLQUEUE(3, scmd_printk(KERN_INFO, cmd,
+			"queuecommand : device blocked\n"));
+		return SCSI_MLQUEUE_DEVICE_BUSY;
+	}
+
+	/* Store the LUN value in cmnd, if needed. */
+	if (cmd->device->lun_in_cdb)
+		cmd->cmnd[1] = (cmd->cmnd[1] & 0x1f) |
+			       (cmd->device->lun << 5 & 0xe0);
+
+	scsi_log_send(cmd);
+
+	/*
+	 * Before we queue this command, check if the command
+	 * length exceeds what the host adapter can handle.
+	 */
+	if (cmd->cmd_len > cmd->device->host->max_cmd_len) {
+		SCSI_LOG_MLQUEUE(3, scmd_printk(KERN_INFO, cmd,
+			       "queuecommand : command too long. "
+			       "cdb_size=%d host->max_cmd_len=%d\n",
+			       cmd->cmd_len, cmd->device->host->max_cmd_len));
+		cmd->result = (DID_ABORT << 16);
+		goto done;
+	}
+
+	if (unlikely(host->shost_state == SHOST_DEL)) {
+		cmd->result = (DID_NO_CONNECT << 16);
+		goto done;
+
+	}
+
+	trace_scsi_dispatch_cmd_start(cmd);
+	rtn = host->hostt->queuecommand(host, cmd);
+	if (rtn) {
+		trace_scsi_dispatch_cmd_error(cmd, rtn);
+		if (rtn != SCSI_MLQUEUE_DEVICE_BUSY &&
+		    rtn != SCSI_MLQUEUE_TARGET_BUSY)
+			rtn = SCSI_MLQUEUE_HOST_BUSY;
+
+		SCSI_LOG_MLQUEUE(3, scmd_printk(KERN_INFO, cmd,
+			"queuecommand : request rejected\n"));
+	}
+
+	return rtn;
+ done:
+	cmd->scsi_done(cmd);
+	return 0;
+}
+
 /**
  * scsi_done - Invoke completion on finished SCSI command.
  * @cmd: The SCSI Command for which a low-level device driver (LLDD) gives

commit 3c356bde19e9a728b26a231a23099c8057dbe881
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Sep 5 18:20:23 2014 -0700

    scsi: stop passing a gfp_mask argument down the command setup path
    
    There is no reason for ULDs to pass in a flag on how to allocate the S/G
    lists.  While we don't need GFP_ATOMIC for the blk-mq case because we
    don't hold locks, that decision can be made way down the chain without
    having to pass a pointless gfp_mask argument.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Hannes Reinecke <hare@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 2179851cdaf3..fcdc585278bf 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -588,10 +588,10 @@ static void scsi_free_sgtable(struct scsi_data_buffer *sdb, bool mq)
 	__sg_free_table(&sdb->table, SCSI_MAX_SG_SEGMENTS, mq, scsi_sg_free);
 }
 
-static int scsi_alloc_sgtable(struct scsi_data_buffer *sdb, int nents,
-			      gfp_t gfp_mask, bool mq)
+static int scsi_alloc_sgtable(struct scsi_data_buffer *sdb, int nents, bool mq)
 {
 	struct scatterlist *first_chunk = NULL;
+	gfp_t gfp_mask = mq ? GFP_NOIO : GFP_ATOMIC;
 	int ret;
 
 	BUG_ON(!nents);
@@ -1077,8 +1077,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	}
 }
 
-static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb,
-			     gfp_t gfp_mask)
+static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb)
 {
 	int count;
 
@@ -1086,7 +1085,7 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb,
 	 * If sg table allocation fails, requeue request later.
 	 */
 	if (unlikely(scsi_alloc_sgtable(sdb, req->nr_phys_segments,
-					gfp_mask, req->mq_ctx != NULL)))
+					req->mq_ctx != NULL)))
 		return BLKPREP_DEFER;
 
 	/* 
@@ -1111,7 +1110,7 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb,
  *		BLKPREP_DEFER if the failure is retryable
  *		BLKPREP_KILL if the failure is fatal
  */
-int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
+int scsi_init_io(struct scsi_cmnd *cmd)
 {
 	struct scsi_device *sdev = cmd->device;
 	struct request *rq = cmd->request;
@@ -1120,7 +1119,7 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 
 	BUG_ON(!rq->nr_phys_segments);
 
-	error = scsi_init_sgtable(rq, &cmd->sdb, gfp_mask);
+	error = scsi_init_sgtable(rq, &cmd->sdb);
 	if (error)
 		goto err_exit;
 
@@ -1136,8 +1135,7 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 			rq->next_rq->special = bidi_sdb;
 		}
 
-		error = scsi_init_sgtable(rq->next_rq, rq->next_rq->special,
-					  GFP_ATOMIC);
+		error = scsi_init_sgtable(rq->next_rq, rq->next_rq->special);
 		if (error)
 			goto err_exit;
 	}
@@ -1149,7 +1147,7 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 		BUG_ON(prot_sdb == NULL);
 		ivecs = blk_rq_count_integrity_sg(rq->q, rq->bio);
 
-		if (scsi_alloc_sgtable(prot_sdb, ivecs, gfp_mask, is_mq)) {
+		if (scsi_alloc_sgtable(prot_sdb, ivecs, is_mq)) {
 			error = BLKPREP_DEFER;
 			goto err_exit;
 		}
@@ -1218,7 +1216,7 @@ static int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 	 * submit a request without an attached bio.
 	 */
 	if (req->bio) {
-		int ret = scsi_init_io(cmd, GFP_ATOMIC);
+		int ret = scsi_init_io(cmd);
 		if (unlikely(ret))
 			return ret;
 	} else {

commit bb3ec62a179922b501535d5bd210cb8ba2ad069b
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Sep 5 18:02:09 2014 -0700

    scsi: remove scsi_next_command
    
    There's only one caller left, so inline it and reduce the blk-mq vs !blk-mq
    diff a litte bit.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Hannes Reinecke <hare@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 994eb083fff9..2179851cdaf3 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -543,17 +543,6 @@ static void scsi_requeue_command(struct request_queue *q, struct scsi_cmnd *cmd)
 	put_device(&sdev->sdev_gendev);
 }
 
-void scsi_next_command(struct scsi_cmnd *cmd)
-{
-	struct scsi_device *sdev = cmd->device;
-	struct request_queue *q = sdev->request_queue;
-
-	scsi_put_command(cmd);
-	scsi_run_queue(q);
-
-	put_device(&sdev->sdev_gendev);
-}
-
 void scsi_run_host_queues(struct Scsi_Host *shost)
 {
 	struct scsi_device *sdev;
@@ -731,8 +720,6 @@ static bool scsi_end_request(struct request *req, int error,
 			kblockd_schedule_work(&sdev->requeue_work);
 		else
 			blk_mq_start_stopped_hw_queues(q, true);
-
-		put_device(&sdev->sdev_gendev);
 	} else {
 		unsigned long flags;
 
@@ -744,9 +731,12 @@ static bool scsi_end_request(struct request *req, int error,
 		spin_unlock_irqrestore(q->queue_lock, flags);
 
 		scsi_release_buffers(cmd);
-		scsi_next_command(cmd);
+
+		scsi_put_command(cmd);
+		scsi_run_queue(q);
 	}
 
+	put_device(&sdev->sdev_gendev);
 	return false;
 }
 

commit 125c99bc8b6b108d251169a86324a7ed3c6f3cce
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Nov 3 12:47:47 2014 +0100

    scsi: add new scsi-command flag for tagged commands
    
    Currently scsi piggy backs on the block layer to define the concept
    of a tagged command.  But we want to be able to have block-level host-wide
    tags assigned even for untagged commands like the initial INQUIRY, so add
    a new SCSI-level flag for commands that are tagged at the scsi level, so
    that even commands without that set can have tags assigned to them.  Note
    that this alredy is the case for the blk-mq code path, and this just lets
    the old path catch up with it.
    
    We also set this flag based upon sdev->simple_tags instead of the block
    queue flag, so that it is entirely independent of the block layer tagging,
    and thus always correct even if a driver doesn't use block level tagging
    yet.
    
    Also remove the old blk_rq_tagged; it was only used by SCSI drivers, and
    removing it forces them to look for the proper replacement.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Mike Christie <michaelc@cs.wisc.edu>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 38f8c85957b6..994eb083fff9 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1740,7 +1740,7 @@ static void scsi_request_fn(struct request_queue *q)
 		 * we add the dev to the starved list so it eventually gets
 		 * a run when a tag is freed.
 		 */
-		if (blk_queue_tagged(q) && !blk_rq_tagged(req)) {
+		if (blk_queue_tagged(q) && !(req->cmd_flags & REQ_QUEUED)) {
 			spin_lock_irq(shost->host_lock);
 			if (list_empty(&sdev->starved_entry))
 				list_add_tail(&sdev->starved_entry,
@@ -1754,6 +1754,11 @@ static void scsi_request_fn(struct request_queue *q)
 
 		if (!scsi_host_queue_ready(q, shost, sdev))
 			goto host_not_ready;
+	
+		if (sdev->simple_tags)
+			cmd->flags |= SCMD_TAGGED;
+		else
+			cmd->flags &= ~SCMD_TAGGED;
 
 		/*
 		 * Finally, initialize any error handling parameters, and set up
@@ -1908,10 +1913,10 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx, struct request *req,
 		blk_mq_start_request(req);
 	}
 
-	if (blk_queue_tagged(q))
-		req->cmd_flags |= REQ_QUEUED;
+	if (sdev->simple_tags)
+		cmd->flags |= SCMD_TAGGED;
 	else
-		req->cmd_flags &= ~REQ_QUEUED;
+		cmd->flags &= ~SCMD_TAGGED;
 
 	scsi_init_cmd_errh(cmd);
 	cmd->scsi_done = scsi_mq_done;

commit efec4b90f1a9b4c80827e4b8c0863334e13b0bf1
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Thu Oct 30 14:45:36 2014 +0100

    scsi: add support for multiple hardware queues
    
    Allow a SCSI LLD to declare how many hardware queues it supports
    by setting Scsi_Host.nr_hw_queues before calling scsi_add_host().
    
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Sagi Grimberg <sagig@mellanox.com>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index fc0a8a0c0a34..38f8c85957b6 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2106,7 +2106,7 @@ int scsi_mq_setup_tags(struct Scsi_Host *shost)
 
 	memset(&shost->tag_set, 0, sizeof(shost->tag_set));
 	shost->tag_set.ops = &scsi_mq_ops;
-	shost->tag_set.nr_hw_queues = 1;
+	shost->tag_set.nr_hw_queues = shost->nr_hw_queues ? : 1;
 	shost->tag_set.queue_depth = shost->can_queue;
 	shost->tag_set.cmd_size = cmd_size;
 	shost->tag_set.numa_node = NUMA_NO_NODE;

commit f1569ff1d5ae0ca8598956be632947a88f540e2a
Author: Hannes Reinecke <hare@suse.de>
Date:   Fri Oct 24 14:27:07 2014 +0200

    scsi: ratelimit I/O error messages
    
    There can be quite a lot of I/O error messages, even on smaller
    machines. So we need to ratelimit them to not overwhelm logging.
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Tested-by: Robert Elliott <elliott@hp.com>
    Reviewed-by: Robert Elliott <elliott@hp.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 26a57faf885b..fc0a8a0c0a34 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -22,6 +22,7 @@
 #include <linux/hardirq.h>
 #include <linux/scatterlist.h>
 #include <linux/blk-mq.h>
+#include <linux/ratelimit.h>
 
 #include <scsi/scsi.h>
 #include <scsi/scsi_cmnd.h>
@@ -1038,18 +1039,25 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	switch (action) {
 	case ACTION_FAIL:
 		/* Give up and fail the remainder of the request */
-		if (unlikely(scsi_logging_level))
-			level = SCSI_LOG_LEVEL(SCSI_LOG_MLQUEUE_SHIFT,
-					       SCSI_LOG_MLQUEUE_BITS);
-		/*
-		 * if logging is enabled the failure will be printed
-		 * in scsi_log_completion(), so avoid duplicate messages
-		 */
-		if (!level && !(req->cmd_flags & REQ_QUIET)) {
-			scsi_print_result(cmd, NULL, FAILED);
-			if (driver_byte(result) & DRIVER_SENSE)
-				scsi_print_sense(cmd);
-			scsi_print_command(cmd);
+		if (!(req->cmd_flags & REQ_QUIET)) {
+			static DEFINE_RATELIMIT_STATE(_rs,
+					DEFAULT_RATELIMIT_INTERVAL,
+					DEFAULT_RATELIMIT_BURST);
+
+			if (unlikely(scsi_logging_level))
+				level = SCSI_LOG_LEVEL(SCSI_LOG_MLCOMPLETE_SHIFT,
+						       SCSI_LOG_MLCOMPLETE_BITS);
+
+			/*
+			 * if logging is enabled the failure will be printed
+			 * in scsi_log_completion(), so avoid duplicate messages
+			 */
+			if (!level && __ratelimit(&_rs)) {
+				scsi_print_result(cmd, NULL, FAILED);
+				if (driver_byte(result) & DRIVER_SENSE)
+					scsi_print_sense(cmd);
+				scsi_print_command(cmd);
+			}
 		}
 		if (!scsi_end_request(req, error, blk_rq_err_bytes(req), 0))
 			return;

commit c11c004b1c052fae77d3d0d14462d1f3a4e88d06
Author: Hannes Reinecke <hare@suse.de>
Date:   Fri Oct 24 14:27:01 2014 +0200

    scsi: simplify scsi_log_(send|completion)
    
    Simplify scsi_log_(send|completion) by externalizing
    scsi_mlreturn_string() and always print the command address.
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Robert Elliott <elliott@hp.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 30f51c11a279..26a57faf885b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -832,7 +832,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	int error = 0;
 	struct scsi_sense_hdr sshdr;
 	bool sense_valid = false;
-	int sense_deferred = 0;
+	int sense_deferred = 0, level = 0;
 	enum {ACTION_FAIL, ACTION_REPREP, ACTION_RETRY,
 	      ACTION_DELAYED_RETRY} action;
 	unsigned long wait_for = (cmd->allowed + 1) * req->timeout;
@@ -1038,8 +1038,15 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	switch (action) {
 	case ACTION_FAIL:
 		/* Give up and fail the remainder of the request */
-		if (!(req->cmd_flags & REQ_QUIET)) {
-			scsi_print_result(cmd);
+		if (unlikely(scsi_logging_level))
+			level = SCSI_LOG_LEVEL(SCSI_LOG_MLQUEUE_SHIFT,
+					       SCSI_LOG_MLQUEUE_BITS);
+		/*
+		 * if logging is enabled the failure will be printed
+		 * in scsi_log_completion(), so avoid duplicate messages
+		 */
+		if (!level && !(req->cmd_flags & REQ_QUIET)) {
+			scsi_print_result(cmd, NULL, FAILED);
 			if (driver_byte(result) & DRIVER_SENSE)
 				scsi_print_sense(cmd);
 			scsi_print_command(cmd);

commit 4753cbc0a1286a60d2f859a7056f8e4873f494c8
Author: Hannes Reinecke <hare@suse.de>
Date:   Fri Oct 24 14:26:52 2014 +0200

    scsi: use 'bool' as return value for scsi_normalize_sense()
    
    Convert scsi_normalize_sense() and friends to return 'bool'
    instead of an integer.
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Robert Elliott <elliott@hp.com>
    Reviewed-by: Yoshihiro Yunomae <yoshihiro.yunomae.ez@hitachi.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 3c96e3923520..30f51c11a279 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -831,7 +831,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	struct request *req = cmd->request;
 	int error = 0;
 	struct scsi_sense_hdr sshdr;
-	int sense_valid = 0;
+	bool sense_valid = false;
 	int sense_deferred = 0;
 	enum {ACTION_FAIL, ACTION_REPREP, ACTION_RETRY,
 	      ACTION_DELAYED_RETRY} action;

commit d811b848ebb78a1135658aa20a80e31994df47f7
Author: Hannes Reinecke <hare@suse.de>
Date:   Fri Oct 24 14:26:45 2014 +0200

    scsi: use sdev as argument for sense code printing
    
    We should be using the standard dev_printk() variants for
    sense code printing.
    
    [hch: remove __scsi_print_sense call in xen-scsiback, Acked by Juergen]
    [hch: folded bracing fix from Dan Carpenter]
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Robert Elliott <elliott@hp.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 389bc6fd19ae..3c96e3923520 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -912,7 +912,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		if ((sshdr.asc == 0x0) && (sshdr.ascq == 0x1d))
 			;
 		else if (!(req->cmd_flags & REQ_QUIET))
-			scsi_print_sense("", cmd);
+			scsi_print_sense(cmd);
 		result = 0;
 		/* BLOCK_PC may have set error */
 		error = 0;
@@ -1041,7 +1041,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		if (!(req->cmd_flags & REQ_QUIET)) {
 			scsi_print_result(cmd);
 			if (driver_byte(result) & DRIVER_SENSE)
-				scsi_print_sense("", cmd);
+				scsi_print_sense(cmd);
 			scsi_print_command(cmd);
 		}
 		if (!scsi_end_request(req, error, blk_rq_err_bytes(req), 0))

commit 037e6d8654469051e6a75d64e6c2d6727130fe4c
Author: Mark Rustad <mark.d.rustad@intel.com>
Date:   Tue Oct 14 06:38:53 2014 -0700

    scsi: resolve some missing-field-initializers warnings
    
    Resolve some missing-field-initializers warnings by using
    designated initialization.
    
    [hch: W=2 with modern gcc warns about this.  Pretty pointless to me, but
     I'd prefer to keep us warning free]
    
    Signed-off-by: Mark Rustad <mark.d.rustad@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 50a6e1ac8d9c..389bc6fd19ae 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -47,7 +47,7 @@ struct scsi_host_sg_pool {
 	mempool_t	*pool;
 };
 
-#define SP(x) { x, "sgpool-" __stringify(x) }
+#define SP(x) { .size = x, "sgpool-" __stringify(x) }
 #if (SCSI_MAX_SG_SEGMENTS < 32)
 #error SCSI_MAX_SG_SEGMENTS is too small (must be 32 or greater)
 #endif

commit 74c450521dd8d245b982da62592a18aa6f88b045
Author: Jens Axboe <axboe@fb.com>
Date:   Wed Oct 29 11:14:52 2014 -0600

    blk-mq: add a 'list' parameter to ->queue_rq()
    
    Since we have the notion of a 'last' request in a chain, we can use
    this to have the hardware optimize the issuing of requests. Add
    a list_head parameter to queue_rq that the driver can use to
    temporarily store hw commands for issue when 'last' is true. If we
    are doing a chain of requests, pass in a NULL list for the first
    request to force issue of that immediately, then batch the remainder
    for deferred issue until the last request has been sent.
    
    Instead of adding yet another argument to the hot ->queue_rq path,
    encapsulate the passed arguments in a blk_mq_queue_data structure.
    This is passed as a constant, and has been tested as faster than
    passing 4 (or even 3) args through ->queue_rq. Update drivers for
    the new ->queue_rq() prototype. There are no functional changes
    in this patch for drivers - if they don't use the passed in list,
    then they will just queue requests individually like before.
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9eff8a375132..161dcc93ac75 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1858,9 +1858,10 @@ static void scsi_mq_done(struct scsi_cmnd *cmd)
 	blk_mq_complete_request(cmd->request);
 }
 
-static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx, struct request *req,
-		bool last)
+static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx,
+			 const struct blk_mq_queue_data *bd)
 {
+	struct request *req = bd->rq;
 	struct request_queue *q = req->q;
 	struct scsi_device *sdev = q->queuedata;
 	struct Scsi_Host *shost = sdev->host;

commit b1dd2aac4cc0892b82ec60232ed37e3b0af776cc
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Oct 19 17:13:58 2014 +0200

    scsi: set REQ_QUEUE for the blk-mq case
    
    To generate the right SPI tag messages we need to properly set
    QUEUE_FLAG_QUEUED in the request_queue and mirror it to the
    request.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Acked-by: Jens Axboe <axboe@kernel.dk>
    Reported-by: Meelis Roos <mroos@linux.ee>
    Tested-by: Meelis Roos <mroos@linux.ee>
    Cc: stable@vger.kernel.org

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9eff8a375132..50a6e1ac8d9c 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1893,6 +1893,11 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx, struct request *req,
 		blk_mq_start_request(req);
 	}
 
+	if (blk_queue_tagged(q))
+		req->cmd_flags |= REQ_QUEUED;
+	else
+		req->cmd_flags &= ~REQ_QUEUED;
+
 	scsi_init_cmd_errh(cmd);
 	cmd->scsi_done = scsi_mq_done;
 

commit d3dc366bbaf07c125561e90d6da4bb147741101a
Merge: 511c41d9e666 e19a8a0ad2d2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Oct 18 11:53:51 2014 -0700

    Merge branch 'for-3.18/core' of git://git.kernel.dk/linux-block
    
    Pull core block layer changes from Jens Axboe:
     "This is the core block IO pull request for 3.18.  Apart from the new
      and improved flush machinery for blk-mq, this is all mostly bug fixes
      and cleanups.
    
       - blk-mq timeout updates and fixes from Christoph.
    
       - Removal of REQ_END, also from Christoph.  We pass it through the
         ->queue_rq() hook for blk-mq instead, freeing up one of the request
         bits.  The space was overly tight on 32-bit, so Martin also killed
         REQ_KERNEL since it's no longer used.
    
       - blk integrity updates and fixes from Martin and Gu Zheng.
    
       - Update to the flush machinery for blk-mq from Ming Lei.  Now we
         have a per hardware context flush request, which both cleans up the
         code should scale better for flush intensive workloads on blk-mq.
    
       - Improve the error printing, from Rob Elliott.
    
       - Backing device improvements and cleanups from Tejun.
    
       - Fixup of a misplaced rq_complete() tracepoint from Hannes.
    
       - Make blk_get_request() return error pointers, fixing up issues
         where we NULL deref when a device goes bad or missing.  From Joe
         Lawrence.
    
       - Prep work for drastically reducing the memory consumption of dm
         devices from Junichi Nomura.  This allows creating clone bio sets
         without preallocating a lot of memory.
    
       - Fix a blk-mq hang on certain combinations of queue depths and
         hardware queues from me.
    
       - Limit memory consumption for blk-mq devices for crash dump
         scenarios and drivers that use crazy high depths (certain SCSI
         shared tag setups).  We now just use a single queue and limited
         depth for that"
    
    * 'for-3.18/core' of git://git.kernel.dk/linux-block: (58 commits)
      block: Remove REQ_KERNEL
      blk-mq: allocate cpumask on the home node
      bio-integrity: remove the needless fail handle of bip_slab creating
      block: include func name in __get_request prints
      block: make blk_update_request print prefix match ratelimited prefix
      blk-merge: don't compute bi_phys_segments from bi_vcnt for cloned bio
      block: fix alignment_offset math that assumes io_min is a power-of-2
      blk-mq: Make bt_clear_tag() easier to read
      blk-mq: fix potential hang if rolling wakeup depth is too high
      block: add bioset_create_nobvec()
      block: use bio_clone_fast() in blk_rq_prep_clone()
      block: misplaced rq_complete tracepoint
      sd: Honor block layer integrity handling flags
      block: Replace strnicmp with strncasecmp
      block: Add T10 Protection Information functions
      block: Don't merge requests if integrity flags differ
      block: Integrity checksum flag
      block: Relocate bio integrity flags
      block: Add a disk flag to block integrity profile
      block: Add prefix to block integrity profile flags
      ...

commit 9a50aaefc1b896e734bf7faf3d085f71a360ce97
Merge: 1e345ac6869c 19ac97ff701a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 7 21:29:18 2014 -0400

    Merge tag 'scsi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This patch set consists of the usual driver updates (megaraid_sas,
      arcmsr, be2iscsi, lpfc, mpt2sas, mpt3sas, qla2xxx, ufs) plus several
      assorted fixes and miscellaneous updates (including the
      pci_msix_enable_range() changes that have been pending for a while)"
    
    * tag 'scsi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (202 commits)
      scsi: add a CONFIG_SCSI_MQ_DEFAULT option
      ufs: definitions for phy interface
      ufs: tune bkops while power managment events
      ufs: Add support for clock scaling using devfreq framework
      ufs: Add freq-table-hz property for UFS device
      ufs: Add support for clock gating
      ufs: refactor configuring power mode
      ufs: add UFS power management support
      ufs: introduce well known logical unit in ufs
      ufs: manually add well known logical units
      ufs: Active Power Mode - configuring bActiveICCLevel
      ufs: improve init sequence
      ufs: refactor query descriptor API support
      ufs: add voting support for host controller power
      ufs: Add clock initialization support
      ufs: Add regulator enable support
      ufs: Allow vendor specific initialization
      scsi: don't add scsi_device if its already visible
      scsi: fix the type for well known LUs
      scsi: fix comment in struct Scsi_Host definition
      ...

commit fe052529e465daff25225aac769828baa88b7252
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Sep 22 15:59:31 2014 +0200

    scsi: move blk_mq_start_request call earlier
    
    Some ATA drivers need the dma drain size workaround, and thus need to
    call blk_mq_start_request before the S/G mapping.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 86b1156edb82..5c5617ec834f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1846,6 +1846,8 @@ static int scsi_mq_prep_fn(struct request *req)
 		next_rq->special = bidi_sdb;
 	}
 
+	blk_mq_start_request(req);
+
 	return scsi_setup_cmnd(sdev, req);
 }
 
@@ -1880,17 +1882,19 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx, struct request *req,
 	if (!scsi_host_queue_ready(q, shost, sdev))
 		goto out_dec_target_busy;
 
+
 	if (!(req->cmd_flags & REQ_DONTPREP)) {
 		ret = prep_to_mq(scsi_mq_prep_fn(req));
 		if (ret)
 			goto out_dec_host_busy;
 		req->cmd_flags |= REQ_DONTPREP;
+	} else {
+		blk_mq_start_request(req);
 	}
 
 	scsi_init_cmd_errh(cmd);
 	cmd->scsi_done = scsi_mq_done;
 
-	blk_mq_start_request(req);
 	reason = scsi_dispatch_cmd(cmd);
 	if (reason) {
 		scsi_set_blocked(cmd, reason);

commit 0152fb6b57c4fae769ee75ea2ae670f4ff39fba9
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Sep 13 16:40:13 2014 -0700

    blk-mq: pass a reserved argument to the timeout handler
    
    Allow blk-mq to pass an argument to the timeout handler to indicate
    if we're timing out a reserved or regular command.  For many drivers
    those need to be handled different.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 73ce7d27f5c8..86b1156edb82 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1932,6 +1932,14 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx, struct request *req,
 	return ret;
 }
 
+static enum blk_eh_timer_return scsi_timeout(struct request *req,
+		bool reserved)
+{
+	if (reserved)
+		return BLK_EH_RESET_TIMER;
+	return scsi_times_out(req);
+}
+
 static int scsi_init_request(void *data, struct request *rq,
 		unsigned int hctx_idx, unsigned int request_idx,
 		unsigned int numa_node)
@@ -2043,7 +2051,7 @@ static struct blk_mq_ops scsi_mq_ops = {
 	.map_queue	= blk_mq_map_queue,
 	.queue_rq	= scsi_queue_rq,
 	.complete	= scsi_softirq_done,
-	.timeout	= scsi_times_out,
+	.timeout	= scsi_timeout,
 	.init_request	= scsi_init_request,
 	.exit_request	= scsi_exit_request,
 };

commit c8a446ad695ada43a885ec12b38411dbd190a11b
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Sep 13 16:40:10 2014 -0700

    blk-mq: rename blk_mq_end_io to blk_mq_end_request
    
    Now that we've changed the driver API on the submission side use the
    opportunity to fix up the name on the completion side to fit into the
    general scheme.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 2dcd9078de48..73ce7d27f5c8 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -713,7 +713,7 @@ static bool scsi_end_request(struct request *req, int error,
 
 	if (req->mq_ctx) {
 		/*
-		 * In the MQ case the command gets freed by __blk_mq_end_io,
+		 * In the MQ case the command gets freed by __blk_mq_end_request,
 		 * so we have to do all cleanup that depends on it earlier.
 		 *
 		 * We also can't kick the queues from irq context, so we
@@ -721,7 +721,7 @@ static bool scsi_end_request(struct request *req, int error,
 		 */
 		scsi_mq_uninit_cmd(cmd);
 
-		__blk_mq_end_io(req, error);
+		__blk_mq_end_request(req, error);
 
 		if (scsi_target(sdev)->single_lun ||
 		    !list_empty(&sdev->host->starved_list))

commit e2490073cd7c3d6f6ef6e029a208edd4d38efac4
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Sep 13 16:40:09 2014 -0700

    blk-mq: call blk_mq_start_request from ->queue_rq
    
    When we call blk_mq_start_request from the core blk-mq code before calling into
    ->queue_rq there is a racy window where the timeout handler can hit before we've
    fully set up the driver specific part of the command.
    
    Move the call to blk_mq_start_request into the driver so the driver can start
    the request only once it is fully set up.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f1df41168391..2dcd9078de48 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1890,6 +1890,7 @@ static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx, struct request *req,
 	scsi_init_cmd_errh(cmd);
 	cmd->scsi_done = scsi_mq_done;
 
+	blk_mq_start_request(req);
 	reason = scsi_dispatch_cmd(cmd);
 	if (reason) {
 		scsi_set_blocked(cmd, reason);

commit bf57229745f849e500ba69ff91e35bc8160a7373
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Sep 13 16:40:08 2014 -0700

    blk-mq: remove REQ_END
    
    Pass an explicit parameter for the last request in a batch to ->queue_rq
    instead of using a request flag.  Besides being a cleaner and non-stateful
    interface this is also required for the next patch, which fixes the blk-mq
    I/O submission code to not start a time too early.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1f2bae475cb7..f1df41168391 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1855,7 +1855,8 @@ static void scsi_mq_done(struct scsi_cmnd *cmd)
 	blk_mq_complete_request(cmd->request);
 }
 
-static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx, struct request *req)
+static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx, struct request *req,
+		bool last)
 {
 	struct request_queue *q = req->q;
 	struct scsi_device *sdev = q->queuedata;

commit f81426a84bef870d26e5e752772d8ca203cd4aed
Author: Daniel Gryniewicz <dang@linuxbox.com>
Date:   Tue Sep 16 10:41:13 2014 -0400

    [SCSI] fix for bidi use after free
    
    When ending a bi-directionional SCSI request, blk_finish_request()
    cleans up and frees the request, but scsi_release_bidi_buffers() tries
    to indirect through the request to find it's data buffers.  This causes
    a panic due to a null pointer dereference.
    
    Move the call to scsi_release_bidi_buffers() before the call to
    blk_finish_request().
    
    Signed-off-by: Daniel Gryniewicz <dang@linuxbox.com>
    Reviewed-by: Webb Scales <webbnh@hp.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d837dc180522..aaea4b98af16 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -733,12 +733,13 @@ static bool scsi_end_request(struct request *req, int error,
 	} else {
 		unsigned long flags;
 
+		if (bidi_bytes)
+			scsi_release_bidi_buffers(cmd);
+
 		spin_lock_irqsave(q->queue_lock, flags);
 		blk_finish_request(req, error);
 		spin_unlock_irqrestore(q->queue_lock, flags);
 
-		if (bidi_bytes)
-			scsi_release_bidi_buffers(cmd);
 		scsi_release_buffers(cmd);
 		scsi_next_command(cmd);
 	}

commit 64bdcbc449105377dd60c8da97cfc1663b39562c
Author: Kashyap.Desai@avagotech.com <Kashyap.Desai@avagotech.com>
Date:   Wed Aug 20 19:24:33 2014 +0530

    scsi: add use_cmd_list flag
    
    Add a use_cmd_list flag in struct Scsi_Host to request keeping track of
    all outstanding commands per device.
    
    Default behaviour is not to keep track of cmd_list per sdev, as this may
    introduce lock contention. (overhead is more on multi-node NUMA.), and
    only enable it on the two drivers that need it.
    
    Signed-off-by: Kashyap Desai <kashyap.desai@avagotech.com>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d837dc180522..b9a8ddd77eef 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -645,16 +645,18 @@ static void scsi_mq_free_sgtables(struct scsi_cmnd *cmd)
 static void scsi_mq_uninit_cmd(struct scsi_cmnd *cmd)
 {
 	struct scsi_device *sdev = cmd->device;
+	struct Scsi_Host *shost = sdev->host;
 	unsigned long flags;
 
-	BUG_ON(list_empty(&cmd->list));
-
 	scsi_mq_free_sgtables(cmd);
 	scsi_uninit_cmd(cmd);
 
-	spin_lock_irqsave(&sdev->list_lock, flags);
-	list_del_init(&cmd->list);
-	spin_unlock_irqrestore(&sdev->list_lock, flags);
+	if (shost->use_cmd_list) {
+		BUG_ON(list_empty(&cmd->list));
+		spin_lock_irqsave(&sdev->list_lock, flags);
+		list_del_init(&cmd->list);
+		spin_unlock_irqrestore(&sdev->list_lock, flags);
+	}
 }
 
 /*
@@ -1815,13 +1817,11 @@ static int scsi_mq_prep_fn(struct request *req)
 	INIT_DELAYED_WORK(&cmd->abort_work, scmd_eh_abort_handler);
 	cmd->jiffies_at_alloc = jiffies;
 
-	/*
-	 * XXX: cmd_list lookups are only used by two drivers, try to get
-	 * rid of this list in common code.
-	 */
-	spin_lock_irq(&sdev->list_lock);
-	list_add_tail(&cmd->list, &sdev->cmd_list);
-	spin_unlock_irq(&sdev->list_lock);
+	if (shost->use_cmd_list) {
+		spin_lock_irq(&sdev->list_lock);
+		list_add_tail(&cmd->list, &sdev->cmd_list);
+		spin_unlock_irq(&sdev->list_lock);
+	}
 
 	sg = (void *)cmd + sizeof(struct scsi_cmnd) + shost->hostt->cmd_size;
 	cmd->sdb.table.sgl = sg;

commit b207892b061da7608878e273ae22ba9bf9be264b
Merge: 018a17bdc865 a516440542af
Author: Jens Axboe <axboe@fb.com>
Date:   Thu Sep 11 09:31:18 2014 -0600

    Merge branch 'for-linus' into for-3.18/core
    
    A bit of churn on the for-linus side that would be nice to have
    in the core bits for 3.18, so pull it in to catch us up and make
    forward progress easier.
    
    Signed-off-by: Jens Axboe <axboe@fb.com>
    
    Conflicts:
            block/scsi_ioctl.c

commit 522a15db959f934ac096673e0c4600db0af5b337
Merge: 9e36c633951a 7b5af5cffce5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Aug 29 11:21:48 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.dk/linux-block
    
    Pull block layer fixes from Jens Axboe:
     "A smaller collection of fixes that have come up since the initial
      merge window pull request.  This contains:
    
       - error handling cleanup and support for larger than 16 byte cdbs in
         sg_io() from Christoph.  The latter just matches what bsg and
         friends support, sg_io() got left out in the merge.
    
       - an option for brd to expose partitions in /proc/partitions.  They
         are hidden by default for compat reasons.  From Dmitry Monakhov.
    
       - a few blk-mq fixes from me - killing a dead/unused flag, fix for
         merging happening even if turned off, and correction of a few
         comments.
    
       - removal of unnecessary ->owner setting in systemace.  From Michal
         Simek.
    
       - two related fixes for a problem with nesting freezing of queues in
         blk-mq.  One from Ming Lei removing an unecessary freeze operation,
         and another from Tejun fixing the nesting regression introduced in
         the merge window.
    
       - fix for a BUG_ON() at bio_endio time when protection info is
         attached and the IO has an error.  From Sagi Grimberg.
    
       - two scsi_ioctl bug fixes for regressions with scsi-mq from Tony
         Battersby.
    
       - a cfq weight update fix and subsequent comment update from Toshiaki
         Makita"
    
    * 'for-linus' of git://git.kernel.dk/linux-block:
      cfq-iosched: Add comments on update timing of weight
      cfq-iosched: Fix wrong children_weight calculation
      block: fix error handling in sg_io
      fix regression in SCSI_IOCTL_SEND_COMMAND
      scsi-mq: fix requests that use a separate CDB buffer
      block: support > 16 byte CDBs for SG_IO
      block: cleanup error handling in sg_io
      brd: add ram disk visibility option
      block: systemace: Remove .owner field for driver
      blk-mq: blk_mq_freeze_queue() should allow nesting
      blk-mq: correct a few wrong/bad comments
      block: Fix BUG_ON when pi errors occur
      blk-mq: don't allow merges if turned off for the queue
      blk-mq: get rid of unused BLK_MQ_F_SHOULD_SORT flag
      blk-mq: fix WARNING "percpu_ref_kill() called more than once!"

commit a492f075450f3ba87de36e5ffe92a9d0c7af9723
Author: Joe Lawrence <joe.lawrence@stratus.com>
Date:   Thu Aug 28 08:15:21 2014 -0600

    block,scsi: fixup blk_get_request dead queue scenarios
    
    The blk_get_request function may fail in low-memory conditions or during
    device removal (even if __GFP_WAIT is set). To distinguish between these
    errors, modify the blk_get_request call stack to return the appropriate
    ERR_PTR. Verify that all callers check the return status and consider
    IS_ERR instead of a simple NULL pointer check.
    
    For consistency, make a similar change to the blk_mq_alloc_request leg
    of blk_get_request.  It may fail if the queue is dead, or the caller was
    unwilling to wait.
    
    Signed-off-by: Joe Lawrence <joe.lawrence@stratus.com>
    Acked-by: Jiri Kosina <jkosina@suse.cz> [for pktdvd]
    Acked-by: Boaz Harrosh <bharrosh@panasas.com> [for osd]
    Reviewed-by: Jeff Moyer <jmoyer@redhat.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ce62e8798cc8..972d0a8adf2e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -221,7 +221,7 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	int ret = DRIVER_ERROR << 24;
 
 	req = blk_get_request(sdev->request_queue, write, __GFP_WAIT);
-	if (!req)
+	if (IS_ERR(req))
 		return ret;
 	blk_rq_set_block_pc(req);
 

commit 6f4a16266fb3e58cd3e200eab51d2220ef92d604
Author: Tony Battersby <tonyb@cybernetics.com>
Date:   Fri Aug 22 15:53:39 2014 -0400

    scsi-mq: fix requests that use a separate CDB buffer
    
    This patch fixes code such as the following with scsi-mq enabled:
    
        rq = blk_get_request(...);
        blk_rq_set_block_pc(rq);
    
        rq->cmd = my_cmd_buffer; /* separate CDB buffer */
    
        blk_execute_rq_nowait(...);
    
    Code like this appears in e.g. sg_start_req() in drivers/scsi/sg.c (for
    large CDBs only).  Without this patch, scsi_mq_prep_fn() will set
    rq->cmd back to rq->__cmd, causing the wrong CDB to be sent to the device.
    
    Signed-off-by: Tony Battersby <tonyb@cybernetics.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9c44392b748f..d86808f051e0 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1808,7 +1808,6 @@ static int scsi_mq_prep_fn(struct request *req)
 
 	cmd->tag = req->tag;
 
-	req->cmd = req->__cmd;
 	cmd->cmnd = req->cmd;
 	cmd->prot_op = SCSI_PROT_NORMAL;
 

commit 480cadc2b7e0fa2bbab20141efb547dfe0c3707c
Author: Guenter Roeck <linux@roeck-us.net>
Date:   Sun Aug 10 05:54:25 2014 -0700

    scsi: Fix qemu boot hang problem
    
    The latest kernel fails to boot qemu arm images when using scsi
    for disk access. Boot gets stuck after the following messages.
    
    brd: module loaded
    sym53c8xx 0000:00:0c.0: enabling device (0100 -> 0103)
    sym0: <895a> rev 0x0 at pci 0000:00:0c.0 irq 93
    sym0: No NVRAM, ID 7, Fast-40, LVD, parity checking
    sym0: SCSI BUS has been reset.
    scsi host0: sym-2.2.3
    
    Bisect points to commit 71e75c97f97a ("scsi: convert device_busy to
    atomic_t"). Code inspection shows the following suspicious change
    in scsi_request_fn.
    
    out_delay:
    -       if (sdev->device_busy == 0 && !scsi_device_blocked(sdev))
    +       if (atomic_read(&sdev->device_busy) && !scsi_device_blocked(sdev))
                    blk_delay_queue(q, SCSI_QUEUE_DELAY);
            }
    
    'sdev->device_busy == 0' was replaced with 'atomic_read(&sdev->device_busy)',
    meaning the logic was reversed. Changing this expression to
    '!atomic_read(&sdev->device_busy)' fixes the problem.
    
    Signed-off-by: Guenter Roeck <linux@roeck-us.net>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Acked-by: Jens Axboe <axboe@fb.com>
    Reviewed-by: Venkatesh Srinivas <venkateshs@google.com>
    Reviewed-by: Webb Scales <webbnh@hp.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9c44392b748f..ce62e8798cc8 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1774,7 +1774,7 @@ static void scsi_request_fn(struct request_queue *q)
 	blk_requeue_request(q, req);
 	atomic_dec(&sdev->device_busy);
 out_delay:
-	if (atomic_read(&sdev->device_busy) && !scsi_device_blocked(sdev))
+	if (!atomic_read(&sdev->device_busy) && !scsi_device_blocked(sdev))
 		blk_delay_queue(q, SCSI_QUEUE_DELAY);
 }
 

commit d285203cf647d7c97db3a1c33794315c9008593f
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jan 17 12:06:53 2014 +0100

    scsi: add support for a blk-mq based I/O path.
    
    This patch adds support for an alternate I/O path in the scsi midlayer
    which uses the blk-mq infrastructure instead of the legacy request code.
    
    Use of blk-mq is fully transparent to drivers, although for now a host
    template field is provided to opt out of blk-mq usage in case any unforseen
    incompatibilities arise.
    
    In general replacing the legacy request code with blk-mq is a simple and
    mostly mechanical transformation.  The biggest exception is the new code
    that deals with the fact the I/O submissions in blk-mq must happen from
    process context, which slightly complicates the I/O completion handler.
    The second biggest differences is that blk-mq is build around the concept
    of preallocated requests that also include driver specific data, which
    in SCSI context means the scsi_cmnd structure.  This completely avoids
    dynamic memory allocations for the fast path through I/O submission.
    
    Due the preallocated requests the MQ code path exclusively uses the
    host-wide shared tag allocator instead of a per-LUN one.  This only
    affects drivers actually using the block layer provided tag allocator
    instead of their own.  Unlike the old path blk-mq always provides a tag,
    although drivers don't have to use it.
    
    For now the blk-mq path is disable by defauly and must be enabled using
    the "use_blk_mq" module parameter.  Once the remaining work in the block
    layer to make blk-mq more suitable for slow devices is complete I hope
    to make it the default and eventually even remove the old code path.
    
    Based on the earlier scsi-mq prototype by Nicholas Bellinger.
    
    Thanks to Bart Van Assche and Robert Elliot for testing, benchmarking and
    various sugestions and code contributions.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Webb Scales <webbnh@hp.com>
    Acked-by: Jens Axboe <axboe@kernel.dk>
    Tested-by: Bart Van Assche <bvanassche@acm.org>
    Tested-by: Robert Elliott <elliott@hp.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index bbd7a0a08692..9c44392b748f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1,5 +1,6 @@
 /*
- *  scsi_lib.c Copyright (C) 1999 Eric Youngdale
+ * Copyright (C) 1999 Eric Youngdale
+ * Copyright (C) 2014 Christoph Hellwig
  *
  *  SCSI queueing library.
  *      Initial versions: Eric Youngdale (eric@andante.org).
@@ -20,6 +21,7 @@
 #include <linux/delay.h>
 #include <linux/hardirq.h>
 #include <linux/scatterlist.h>
+#include <linux/blk-mq.h>
 
 #include <scsi/scsi.h>
 #include <scsi/scsi_cmnd.h>
@@ -113,6 +115,16 @@ scsi_set_blocked(struct scsi_cmnd *cmd, int reason)
 	}
 }
 
+static void scsi_mq_requeue_cmd(struct scsi_cmnd *cmd)
+{
+	struct scsi_device *sdev = cmd->device;
+	struct request_queue *q = cmd->request->q;
+
+	blk_mq_requeue_request(cmd->request);
+	blk_mq_kick_requeue_list(q);
+	put_device(&sdev->sdev_gendev);
+}
+
 /**
  * __scsi_queue_insert - private queue insertion
  * @cmd: The SCSI command being requeued
@@ -150,6 +162,10 @@ static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
 	 * before blk_cleanup_queue() finishes.
 	 */
 	cmd->result = 0;
+	if (q->mq_ops) {
+		scsi_mq_requeue_cmd(cmd);
+		return;
+	}
 	spin_lock_irqsave(q->queue_lock, flags);
 	blk_requeue_request(q, cmd->request);
 	kblockd_schedule_work(&device->requeue_work);
@@ -308,6 +324,14 @@ void scsi_device_unbusy(struct scsi_device *sdev)
 	atomic_dec(&sdev->device_busy);
 }
 
+static void scsi_kick_queue(struct request_queue *q)
+{
+	if (q->mq_ops)
+		blk_mq_start_hw_queues(q);
+	else
+		blk_run_queue(q);
+}
+
 /*
  * Called for single_lun devices on IO completion. Clear starget_sdev_user,
  * and call blk_run_queue for all the scsi_devices on the target -
@@ -332,7 +356,7 @@ static void scsi_single_lun_run(struct scsi_device *current_sdev)
 	 * but in most cases, we will be first. Ideally, each LU on the
 	 * target would get some limited time or requests on the target.
 	 */
-	blk_run_queue(current_sdev->request_queue);
+	scsi_kick_queue(current_sdev->request_queue);
 
 	spin_lock_irqsave(shost->host_lock, flags);
 	if (starget->starget_sdev_user)
@@ -345,7 +369,7 @@ static void scsi_single_lun_run(struct scsi_device *current_sdev)
 			continue;
 
 		spin_unlock_irqrestore(shost->host_lock, flags);
-		blk_run_queue(sdev->request_queue);
+		scsi_kick_queue(sdev->request_queue);
 		spin_lock_irqsave(shost->host_lock, flags);
 	
 		scsi_device_put(sdev);
@@ -435,7 +459,7 @@ static void scsi_starved_list_run(struct Scsi_Host *shost)
 			continue;
 		spin_unlock_irqrestore(shost->host_lock, flags);
 
-		blk_run_queue(slq);
+		scsi_kick_queue(slq);
 		blk_put_queue(slq);
 
 		spin_lock_irqsave(shost->host_lock, flags);
@@ -466,7 +490,10 @@ static void scsi_run_queue(struct request_queue *q)
 	if (!list_empty(&sdev->host->starved_list))
 		scsi_starved_list_run(sdev->host);
 
-	blk_run_queue(q);
+	if (q->mq_ops)
+		blk_mq_start_stopped_hw_queues(q, false);
+	else
+		blk_run_queue(q);
 }
 
 void scsi_requeue_run_queue(struct work_struct *work)
@@ -564,25 +591,72 @@ static struct scatterlist *scsi_sg_alloc(unsigned int nents, gfp_t gfp_mask)
 	return mempool_alloc(sgp->pool, gfp_mask);
 }
 
-static void scsi_free_sgtable(struct scsi_data_buffer *sdb)
+static void scsi_free_sgtable(struct scsi_data_buffer *sdb, bool mq)
 {
-	__sg_free_table(&sdb->table, SCSI_MAX_SG_SEGMENTS, false, scsi_sg_free);
+	if (mq && sdb->table.nents <= SCSI_MAX_SG_SEGMENTS)
+		return;
+	__sg_free_table(&sdb->table, SCSI_MAX_SG_SEGMENTS, mq, scsi_sg_free);
 }
 
 static int scsi_alloc_sgtable(struct scsi_data_buffer *sdb, int nents,
-			      gfp_t gfp_mask)
+			      gfp_t gfp_mask, bool mq)
 {
+	struct scatterlist *first_chunk = NULL;
 	int ret;
 
 	BUG_ON(!nents);
 
+	if (mq) {
+		if (nents <= SCSI_MAX_SG_SEGMENTS) {
+			sdb->table.nents = nents;
+			sg_init_table(sdb->table.sgl, sdb->table.nents);
+			return 0;
+		}
+		first_chunk = sdb->table.sgl;
+	}
+
 	ret = __sg_alloc_table(&sdb->table, nents, SCSI_MAX_SG_SEGMENTS,
-			       NULL, gfp_mask, scsi_sg_alloc);
+			       first_chunk, gfp_mask, scsi_sg_alloc);
 	if (unlikely(ret))
-		scsi_free_sgtable(sdb);
+		scsi_free_sgtable(sdb, mq);
 	return ret;
 }
 
+static void scsi_uninit_cmd(struct scsi_cmnd *cmd)
+{
+	if (cmd->request->cmd_type == REQ_TYPE_FS) {
+		struct scsi_driver *drv = scsi_cmd_to_driver(cmd);
+
+		if (drv->uninit_command)
+			drv->uninit_command(cmd);
+	}
+}
+
+static void scsi_mq_free_sgtables(struct scsi_cmnd *cmd)
+{
+	if (cmd->sdb.table.nents)
+		scsi_free_sgtable(&cmd->sdb, true);
+	if (cmd->request->next_rq && cmd->request->next_rq->special)
+		scsi_free_sgtable(cmd->request->next_rq->special, true);
+	if (scsi_prot_sg_count(cmd))
+		scsi_free_sgtable(cmd->prot_sdb, true);
+}
+
+static void scsi_mq_uninit_cmd(struct scsi_cmnd *cmd)
+{
+	struct scsi_device *sdev = cmd->device;
+	unsigned long flags;
+
+	BUG_ON(list_empty(&cmd->list));
+
+	scsi_mq_free_sgtables(cmd);
+	scsi_uninit_cmd(cmd);
+
+	spin_lock_irqsave(&sdev->list_lock, flags);
+	list_del_init(&cmd->list);
+	spin_unlock_irqrestore(&sdev->list_lock, flags);
+}
+
 /*
  * Function:    scsi_release_buffers()
  *
@@ -602,19 +676,19 @@ static int scsi_alloc_sgtable(struct scsi_data_buffer *sdb, int nents,
 static void scsi_release_buffers(struct scsi_cmnd *cmd)
 {
 	if (cmd->sdb.table.nents)
-		scsi_free_sgtable(&cmd->sdb);
+		scsi_free_sgtable(&cmd->sdb, false);
 
 	memset(&cmd->sdb, 0, sizeof(cmd->sdb));
 
 	if (scsi_prot_sg_count(cmd))
-		scsi_free_sgtable(cmd->prot_sdb);
+		scsi_free_sgtable(cmd->prot_sdb, false);
 }
 
 static void scsi_release_bidi_buffers(struct scsi_cmnd *cmd)
 {
 	struct scsi_data_buffer *bidi_sdb = cmd->request->next_rq->special;
 
-	scsi_free_sgtable(bidi_sdb);
+	scsi_free_sgtable(bidi_sdb, false);
 	kmem_cache_free(scsi_sdb_cache, bidi_sdb);
 	cmd->request->next_rq->special = NULL;
 }
@@ -625,8 +699,6 @@ static bool scsi_end_request(struct request *req, int error,
 	struct scsi_cmnd *cmd = req->special;
 	struct scsi_device *sdev = cmd->device;
 	struct request_queue *q = sdev->request_queue;
-	unsigned long flags;
-
 
 	if (blk_update_request(req, error, bytes))
 		return true;
@@ -639,14 +711,38 @@ static bool scsi_end_request(struct request *req, int error,
 	if (blk_queue_add_random(q))
 		add_disk_randomness(req->rq_disk);
 
-	spin_lock_irqsave(q->queue_lock, flags);
-	blk_finish_request(req, error);
-	spin_unlock_irqrestore(q->queue_lock, flags);
+	if (req->mq_ctx) {
+		/*
+		 * In the MQ case the command gets freed by __blk_mq_end_io,
+		 * so we have to do all cleanup that depends on it earlier.
+		 *
+		 * We also can't kick the queues from irq context, so we
+		 * will have to defer it to a workqueue.
+		 */
+		scsi_mq_uninit_cmd(cmd);
+
+		__blk_mq_end_io(req, error);
+
+		if (scsi_target(sdev)->single_lun ||
+		    !list_empty(&sdev->host->starved_list))
+			kblockd_schedule_work(&sdev->requeue_work);
+		else
+			blk_mq_start_stopped_hw_queues(q, true);
+
+		put_device(&sdev->sdev_gendev);
+	} else {
+		unsigned long flags;
+
+		spin_lock_irqsave(q->queue_lock, flags);
+		blk_finish_request(req, error);
+		spin_unlock_irqrestore(q->queue_lock, flags);
+
+		if (bidi_bytes)
+			scsi_release_bidi_buffers(cmd);
+		scsi_release_buffers(cmd);
+		scsi_next_command(cmd);
+	}
 
-	if (bidi_bytes)
-		scsi_release_bidi_buffers(cmd);
-	scsi_release_buffers(cmd);
-	scsi_next_command(cmd);
 	return false;
 }
 
@@ -953,8 +1049,14 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		/* Unprep the request and put it back at the head of the queue.
 		 * A new command will be prepared and issued.
 		 */
-		scsi_release_buffers(cmd);
-		scsi_requeue_command(q, cmd);
+		if (q->mq_ops) {
+			cmd->request->cmd_flags &= ~REQ_DONTPREP;
+			scsi_mq_uninit_cmd(cmd);
+			scsi_mq_requeue_cmd(cmd);
+		} else {
+			scsi_release_buffers(cmd);
+			scsi_requeue_command(q, cmd);
+		}
 		break;
 	case ACTION_RETRY:
 		/* Retry the same command immediately */
@@ -976,9 +1078,8 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb,
 	 * If sg table allocation fails, requeue request later.
 	 */
 	if (unlikely(scsi_alloc_sgtable(sdb, req->nr_phys_segments,
-					gfp_mask))) {
+					gfp_mask, req->mq_ctx != NULL)))
 		return BLKPREP_DEFER;
-	}
 
 	/* 
 	 * Next, walk the list, and fill in the addresses and sizes of
@@ -1006,6 +1107,7 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 {
 	struct scsi_device *sdev = cmd->device;
 	struct request *rq = cmd->request;
+	bool is_mq = (rq->mq_ctx != NULL);
 	int error;
 
 	BUG_ON(!rq->nr_phys_segments);
@@ -1015,15 +1117,19 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 		goto err_exit;
 
 	if (blk_bidi_rq(rq)) {
-		struct scsi_data_buffer *bidi_sdb = kmem_cache_zalloc(
-			scsi_sdb_cache, GFP_ATOMIC);
-		if (!bidi_sdb) {
-			error = BLKPREP_DEFER;
-			goto err_exit;
+		if (!rq->q->mq_ops) {
+			struct scsi_data_buffer *bidi_sdb =
+				kmem_cache_zalloc(scsi_sdb_cache, GFP_ATOMIC);
+			if (!bidi_sdb) {
+				error = BLKPREP_DEFER;
+				goto err_exit;
+			}
+
+			rq->next_rq->special = bidi_sdb;
 		}
 
-		rq->next_rq->special = bidi_sdb;
-		error = scsi_init_sgtable(rq->next_rq, bidi_sdb, GFP_ATOMIC);
+		error = scsi_init_sgtable(rq->next_rq, rq->next_rq->special,
+					  GFP_ATOMIC);
 		if (error)
 			goto err_exit;
 	}
@@ -1035,7 +1141,7 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 		BUG_ON(prot_sdb == NULL);
 		ivecs = blk_rq_count_integrity_sg(rq->q, rq->bio);
 
-		if (scsi_alloc_sgtable(prot_sdb, ivecs, gfp_mask)) {
+		if (scsi_alloc_sgtable(prot_sdb, ivecs, gfp_mask, is_mq)) {
 			error = BLKPREP_DEFER;
 			goto err_exit;
 		}
@@ -1049,13 +1155,16 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 		cmd->prot_sdb->table.nents = count;
 	}
 
-	return BLKPREP_OK ;
-
+	return BLKPREP_OK;
 err_exit:
-	scsi_release_buffers(cmd);
-	cmd->request->special = NULL;
-	scsi_put_command(cmd);
-	put_device(&sdev->sdev_gendev);
+	if (is_mq) {
+		scsi_mq_free_sgtables(cmd);
+	} else {
+		scsi_release_buffers(cmd);
+		cmd->request->special = NULL;
+		scsi_put_command(cmd);
+		put_device(&sdev->sdev_gendev);
+	}
 	return error;
 }
 EXPORT_SYMBOL(scsi_init_io);
@@ -1266,13 +1375,7 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 
 static void scsi_unprep_fn(struct request_queue *q, struct request *req)
 {
-	if (req->cmd_type == REQ_TYPE_FS) {
-		struct scsi_cmnd *cmd = req->special;
-		struct scsi_driver *drv = scsi_cmd_to_driver(cmd);
-
-		if (drv->uninit_command)
-			drv->uninit_command(cmd);
-	}
+	scsi_uninit_cmd(req->special);
 }
 
 /*
@@ -1295,7 +1398,11 @@ static inline int scsi_dev_queue_ready(struct request_queue *q,
 		 * unblock after device_blocked iterates to zero
 		 */
 		if (atomic_dec_return(&sdev->device_blocked) > 0) {
-			blk_delay_queue(q, SCSI_QUEUE_DELAY);
+			/*
+			 * For the MQ case we take care of this in the caller.
+			 */
+			if (!q->mq_ops)
+				blk_delay_queue(q, SCSI_QUEUE_DELAY);
 			goto out_dec;
 		}
 		SCSI_LOG_MLQUEUE(3, sdev_printk(KERN_INFO, sdev,
@@ -1671,6 +1778,180 @@ static void scsi_request_fn(struct request_queue *q)
 		blk_delay_queue(q, SCSI_QUEUE_DELAY);
 }
 
+static inline int prep_to_mq(int ret)
+{
+	switch (ret) {
+	case BLKPREP_OK:
+		return 0;
+	case BLKPREP_DEFER:
+		return BLK_MQ_RQ_QUEUE_BUSY;
+	default:
+		return BLK_MQ_RQ_QUEUE_ERROR;
+	}
+}
+
+static int scsi_mq_prep_fn(struct request *req)
+{
+	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
+	struct scsi_device *sdev = req->q->queuedata;
+	struct Scsi_Host *shost = sdev->host;
+	unsigned char *sense_buf = cmd->sense_buffer;
+	struct scatterlist *sg;
+
+	memset(cmd, 0, sizeof(struct scsi_cmnd));
+
+	req->special = cmd;
+
+	cmd->request = req;
+	cmd->device = sdev;
+	cmd->sense_buffer = sense_buf;
+
+	cmd->tag = req->tag;
+
+	req->cmd = req->__cmd;
+	cmd->cmnd = req->cmd;
+	cmd->prot_op = SCSI_PROT_NORMAL;
+
+	INIT_LIST_HEAD(&cmd->list);
+	INIT_DELAYED_WORK(&cmd->abort_work, scmd_eh_abort_handler);
+	cmd->jiffies_at_alloc = jiffies;
+
+	/*
+	 * XXX: cmd_list lookups are only used by two drivers, try to get
+	 * rid of this list in common code.
+	 */
+	spin_lock_irq(&sdev->list_lock);
+	list_add_tail(&cmd->list, &sdev->cmd_list);
+	spin_unlock_irq(&sdev->list_lock);
+
+	sg = (void *)cmd + sizeof(struct scsi_cmnd) + shost->hostt->cmd_size;
+	cmd->sdb.table.sgl = sg;
+
+	if (scsi_host_get_prot(shost)) {
+		cmd->prot_sdb = (void *)sg +
+			shost->sg_tablesize * sizeof(struct scatterlist);
+		memset(cmd->prot_sdb, 0, sizeof(struct scsi_data_buffer));
+
+		cmd->prot_sdb->table.sgl =
+			(struct scatterlist *)(cmd->prot_sdb + 1);
+	}
+
+	if (blk_bidi_rq(req)) {
+		struct request *next_rq = req->next_rq;
+		struct scsi_data_buffer *bidi_sdb = blk_mq_rq_to_pdu(next_rq);
+
+		memset(bidi_sdb, 0, sizeof(struct scsi_data_buffer));
+		bidi_sdb->table.sgl =
+			(struct scatterlist *)(bidi_sdb + 1);
+
+		next_rq->special = bidi_sdb;
+	}
+
+	return scsi_setup_cmnd(sdev, req);
+}
+
+static void scsi_mq_done(struct scsi_cmnd *cmd)
+{
+	trace_scsi_dispatch_cmd_done(cmd);
+	blk_mq_complete_request(cmd->request);
+}
+
+static int scsi_queue_rq(struct blk_mq_hw_ctx *hctx, struct request *req)
+{
+	struct request_queue *q = req->q;
+	struct scsi_device *sdev = q->queuedata;
+	struct Scsi_Host *shost = sdev->host;
+	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(req);
+	int ret;
+	int reason;
+
+	ret = prep_to_mq(scsi_prep_state_check(sdev, req));
+	if (ret)
+		goto out;
+
+	ret = BLK_MQ_RQ_QUEUE_BUSY;
+	if (!get_device(&sdev->sdev_gendev))
+		goto out;
+
+	if (!scsi_dev_queue_ready(q, sdev))
+		goto out_put_device;
+	if (!scsi_target_queue_ready(shost, sdev))
+		goto out_dec_device_busy;
+	if (!scsi_host_queue_ready(q, shost, sdev))
+		goto out_dec_target_busy;
+
+	if (!(req->cmd_flags & REQ_DONTPREP)) {
+		ret = prep_to_mq(scsi_mq_prep_fn(req));
+		if (ret)
+			goto out_dec_host_busy;
+		req->cmd_flags |= REQ_DONTPREP;
+	}
+
+	scsi_init_cmd_errh(cmd);
+	cmd->scsi_done = scsi_mq_done;
+
+	reason = scsi_dispatch_cmd(cmd);
+	if (reason) {
+		scsi_set_blocked(cmd, reason);
+		ret = BLK_MQ_RQ_QUEUE_BUSY;
+		goto out_dec_host_busy;
+	}
+
+	return BLK_MQ_RQ_QUEUE_OK;
+
+out_dec_host_busy:
+	atomic_dec(&shost->host_busy);
+out_dec_target_busy:
+	if (scsi_target(sdev)->can_queue > 0)
+		atomic_dec(&scsi_target(sdev)->target_busy);
+out_dec_device_busy:
+	atomic_dec(&sdev->device_busy);
+out_put_device:
+	put_device(&sdev->sdev_gendev);
+out:
+	switch (ret) {
+	case BLK_MQ_RQ_QUEUE_BUSY:
+		blk_mq_stop_hw_queue(hctx);
+		if (atomic_read(&sdev->device_busy) == 0 &&
+		    !scsi_device_blocked(sdev))
+			blk_mq_delay_queue(hctx, SCSI_QUEUE_DELAY);
+		break;
+	case BLK_MQ_RQ_QUEUE_ERROR:
+		/*
+		 * Make sure to release all allocated ressources when
+		 * we hit an error, as we will never see this command
+		 * again.
+		 */
+		if (req->cmd_flags & REQ_DONTPREP)
+			scsi_mq_uninit_cmd(cmd);
+		break;
+	default:
+		break;
+	}
+	return ret;
+}
+
+static int scsi_init_request(void *data, struct request *rq,
+		unsigned int hctx_idx, unsigned int request_idx,
+		unsigned int numa_node)
+{
+	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
+
+	cmd->sense_buffer = kzalloc_node(SCSI_SENSE_BUFFERSIZE, GFP_KERNEL,
+			numa_node);
+	if (!cmd->sense_buffer)
+		return -ENOMEM;
+	return 0;
+}
+
+static void scsi_exit_request(void *data, struct request *rq,
+		unsigned int hctx_idx, unsigned int request_idx)
+{
+	struct scsi_cmnd *cmd = blk_mq_rq_to_pdu(rq);
+
+	kfree(cmd->sense_buffer);
+}
+
 static u64 scsi_calculate_bounce_limit(struct Scsi_Host *shost)
 {
 	struct device *host_dev;
@@ -1692,16 +1973,10 @@ static u64 scsi_calculate_bounce_limit(struct Scsi_Host *shost)
 	return bounce_limit;
 }
 
-struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
-					 request_fn_proc *request_fn)
+static void __scsi_init_queue(struct Scsi_Host *shost, struct request_queue *q)
 {
-	struct request_queue *q;
 	struct device *dev = shost->dma_dev;
 
-	q = blk_init_queue(request_fn, NULL);
-	if (!q)
-		return NULL;
-
 	/*
 	 * this limit is imposed by hardware restrictions
 	 */
@@ -1732,7 +2007,17 @@ struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
 	 * blk_queue_update_dma_alignment() later.
 	 */
 	blk_queue_dma_alignment(q, 0x03);
+}
 
+struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
+					 request_fn_proc *request_fn)
+{
+	struct request_queue *q;
+
+	q = blk_init_queue(request_fn, NULL);
+	if (!q)
+		return NULL;
+	__scsi_init_queue(shost, q);
 	return q;
 }
 EXPORT_SYMBOL(__scsi_alloc_queue);
@@ -1753,6 +2038,55 @@ struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
 	return q;
 }
 
+static struct blk_mq_ops scsi_mq_ops = {
+	.map_queue	= blk_mq_map_queue,
+	.queue_rq	= scsi_queue_rq,
+	.complete	= scsi_softirq_done,
+	.timeout	= scsi_times_out,
+	.init_request	= scsi_init_request,
+	.exit_request	= scsi_exit_request,
+};
+
+struct request_queue *scsi_mq_alloc_queue(struct scsi_device *sdev)
+{
+	sdev->request_queue = blk_mq_init_queue(&sdev->host->tag_set);
+	if (IS_ERR(sdev->request_queue))
+		return NULL;
+
+	sdev->request_queue->queuedata = sdev;
+	__scsi_init_queue(sdev->host, sdev->request_queue);
+	return sdev->request_queue;
+}
+
+int scsi_mq_setup_tags(struct Scsi_Host *shost)
+{
+	unsigned int cmd_size, sgl_size, tbl_size;
+
+	tbl_size = shost->sg_tablesize;
+	if (tbl_size > SCSI_MAX_SG_SEGMENTS)
+		tbl_size = SCSI_MAX_SG_SEGMENTS;
+	sgl_size = tbl_size * sizeof(struct scatterlist);
+	cmd_size = sizeof(struct scsi_cmnd) + shost->hostt->cmd_size + sgl_size;
+	if (scsi_host_get_prot(shost))
+		cmd_size += sizeof(struct scsi_data_buffer) + sgl_size;
+
+	memset(&shost->tag_set, 0, sizeof(shost->tag_set));
+	shost->tag_set.ops = &scsi_mq_ops;
+	shost->tag_set.nr_hw_queues = 1;
+	shost->tag_set.queue_depth = shost->can_queue;
+	shost->tag_set.cmd_size = cmd_size;
+	shost->tag_set.numa_node = NUMA_NO_NODE;
+	shost->tag_set.flags = BLK_MQ_F_SHOULD_MERGE | BLK_MQ_F_SG_MERGE;
+	shost->tag_set.driver_data = shost;
+
+	return blk_mq_alloc_tag_set(&shost->tag_set);
+}
+
+void scsi_mq_destroy_tags(struct Scsi_Host *shost)
+{
+	blk_mq_free_tag_set(&shost->tag_set);
+}
+
 /*
  * Function:    scsi_block_requests()
  *
@@ -2498,9 +2832,13 @@ scsi_internal_device_block(struct scsi_device *sdev)
 	 * block layer from calling the midlayer with this device's
 	 * request queue. 
 	 */
-	spin_lock_irqsave(q->queue_lock, flags);
-	blk_stop_queue(q);
-	spin_unlock_irqrestore(q->queue_lock, flags);
+	if (q->mq_ops) {
+		blk_mq_stop_hw_queues(q);
+	} else {
+		spin_lock_irqsave(q->queue_lock, flags);
+		blk_stop_queue(q);
+		spin_unlock_irqrestore(q->queue_lock, flags);
+	}
 
 	return 0;
 }
@@ -2546,9 +2884,13 @@ scsi_internal_device_unblock(struct scsi_device *sdev,
 		 sdev->sdev_state != SDEV_OFFLINE)
 		return -EINVAL;
 
-	spin_lock_irqsave(q->queue_lock, flags);
-	blk_start_queue(q);
-	spin_unlock_irqrestore(q->queue_lock, flags);
+	if (q->mq_ops) {
+		blk_mq_start_stopped_hw_queues(q, false);
+	} else {
+		spin_lock_irqsave(q->queue_lock, flags);
+		blk_start_queue(q);
+		spin_unlock_irqrestore(q->queue_lock, flags);
+	}
 
 	return 0;
 }

commit c53c6d6a68b13b1dff2892551b56cfdc07887d9e
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Apr 15 14:38:31 2014 +0200

    scatterlist: allow chaining to preallocated chunks
    
    Blk-mq drivers usually preallocate their S/G list as part of the request,
    but if we want to support the very large S/G lists currently supported by
    the SCSI code that would tie up a lot of memory in the preallocated request
    pool.  Add support to the scatterlist code so that it can initialize a
    S/G list that uses a preallocated first chunks and dynamically allocated
    additional chunks.  That way the scsi-mq code can preallocate a first
    page worth of S/G entries as part of the request, and dynamically extend
    the S/G list when needed.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Webb Scales <webbnh@hp.com>
    Acked-by: Jens Axboe <axboe@kernel.dk>
    Tested-by: Bart Van Assche <bvanassche@acm.org>
    Tested-by: Robert Elliott <elliott@hp.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 8723abeb018e..bbd7a0a08692 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -564,6 +564,11 @@ static struct scatterlist *scsi_sg_alloc(unsigned int nents, gfp_t gfp_mask)
 	return mempool_alloc(sgp->pool, gfp_mask);
 }
 
+static void scsi_free_sgtable(struct scsi_data_buffer *sdb)
+{
+	__sg_free_table(&sdb->table, SCSI_MAX_SG_SEGMENTS, false, scsi_sg_free);
+}
+
 static int scsi_alloc_sgtable(struct scsi_data_buffer *sdb, int nents,
 			      gfp_t gfp_mask)
 {
@@ -572,19 +577,12 @@ static int scsi_alloc_sgtable(struct scsi_data_buffer *sdb, int nents,
 	BUG_ON(!nents);
 
 	ret = __sg_alloc_table(&sdb->table, nents, SCSI_MAX_SG_SEGMENTS,
-			       gfp_mask, scsi_sg_alloc);
+			       NULL, gfp_mask, scsi_sg_alloc);
 	if (unlikely(ret))
-		__sg_free_table(&sdb->table, SCSI_MAX_SG_SEGMENTS,
-				scsi_sg_free);
-
+		scsi_free_sgtable(sdb);
 	return ret;
 }
 
-static void scsi_free_sgtable(struct scsi_data_buffer *sdb)
-{
-	__sg_free_table(&sdb->table, SCSI_MAX_SG_SEGMENTS, scsi_sg_free);
-}
-
 /*
  * Function:    scsi_release_buffers()
  *

commit f6d47e74fcb2814225e429c94355ad1c551daffb
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Feb 16 06:16:13 2014 -0800

    scsi: unwind blk_end_request_all and blk_end_request_err calls
    
    Replace the calls to the various blk_end_request variants with opencode
    equivalents.  Blk-mq is using a model that gives the driver control
    between the bio updates and the actual completion, and making the old
    code follow that same model allows us to keep the code more similar for
    both paths.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Webb Scales <webbnh@hp.com>
    Acked-by: Jens Axboe <axboe@kernel.dk>
    Tested-by: Bart Van Assche <bvanassche@acm.org>
    Tested-by: Robert Elliott <elliott@hp.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a643353584b5..8723abeb018e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -621,6 +621,37 @@ static void scsi_release_bidi_buffers(struct scsi_cmnd *cmd)
 	cmd->request->next_rq->special = NULL;
 }
 
+static bool scsi_end_request(struct request *req, int error,
+		unsigned int bytes, unsigned int bidi_bytes)
+{
+	struct scsi_cmnd *cmd = req->special;
+	struct scsi_device *sdev = cmd->device;
+	struct request_queue *q = sdev->request_queue;
+	unsigned long flags;
+
+
+	if (blk_update_request(req, error, bytes))
+		return true;
+
+	/* Bidi request must be completed as a whole */
+	if (unlikely(bidi_bytes) &&
+	    blk_update_request(req->next_rq, error, bidi_bytes))
+		return true;
+
+	if (blk_queue_add_random(q))
+		add_disk_randomness(req->rq_disk);
+
+	spin_lock_irqsave(q->queue_lock, flags);
+	blk_finish_request(req, error);
+	spin_unlock_irqrestore(q->queue_lock, flags);
+
+	if (bidi_bytes)
+		scsi_release_bidi_buffers(cmd);
+	scsi_release_buffers(cmd);
+	scsi_next_command(cmd);
+	return false;
+}
+
 /**
  * __scsi_error_from_host_byte - translate SCSI error code into errno
  * @cmd:	SCSI command (unused)
@@ -693,7 +724,7 @@ static int __scsi_error_from_host_byte(struct scsi_cmnd *cmd, int result)
  *		   be put back on the queue and retried using the same
  *		   command as before, possibly after a delay.
  *
- *		c) We can call blk_end_request() with -EIO to fail
+ *		c) We can call scsi_end_request() with -EIO to fail
  *		   the remainder of the request.
  */
 void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
@@ -744,13 +775,9 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			 * both sides at once.
 			 */
 			req->next_rq->resid_len = scsi_in(cmd)->resid;
-
-			scsi_release_buffers(cmd);
-			scsi_release_bidi_buffers(cmd);
-
-			blk_end_request_all(req, 0);
-
-			scsi_next_command(cmd);
+			if (scsi_end_request(req, 0, blk_rq_bytes(req),
+					blk_rq_bytes(req->next_rq)))
+				BUG();
 			return;
 		}
 	} else if (blk_rq_bytes(req) == 0 && result && !sense_deferred) {
@@ -797,15 +824,16 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	/*
 	 * If we finished all bytes in the request we are done now.
 	 */
-	if (!blk_end_request(req, error, good_bytes))
-		goto next_command;
+	if (!scsi_end_request(req, error, good_bytes, 0))
+		return;
 
 	/*
 	 * Kill remainder if no retrys.
 	 */
 	if (error && scsi_noretry_cmd(cmd)) {
-		blk_end_request_all(req, error);
-		goto next_command;
+		if (scsi_end_request(req, error, blk_rq_bytes(req), 0))
+			BUG();
+		return;
 	}
 
 	/*
@@ -919,8 +947,8 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				scsi_print_sense("", cmd);
 			scsi_print_command(cmd);
 		}
-		if (!blk_end_request_err(req, error))
-			goto next_command;
+		if (!scsi_end_request(req, error, blk_rq_err_bytes(req), 0))
+			return;
 		/*FALLTHRU*/
 	case ACTION_REPREP:
 	requeue:
@@ -939,11 +967,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		__scsi_queue_insert(cmd, SCSI_MLQUEUE_DEVICE_BUSY, 0);
 		break;
 	}
-	return;
-
-next_command:
-	scsi_release_buffers(cmd);
-	scsi_next_command(cmd);
 }
 
 static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb,

commit 2ccbb00808465338b57c39f38c0b1e7ce69e2bb1
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Mar 26 10:35:00 2014 +0100

    scsi: only maintain target_blocked if the driver has a target queue limit
    
    This saves us an atomic operation for each I/O submission and completion
    for the usual case where the driver doesn't set a per-target can_queue
    value.  Only a few iscsi hardware offload drivers set the per-target
    can_queue value at the moment.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Webb Scales <webbnh@hp.com>
    Acked-by: Jens Axboe <axboe@kernel.dk>
    Tested-by: Bart Van Assche <bvanassche@acm.org>
    Tested-by: Robert Elliott <elliott@hp.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 69da4cb5cb13..a643353584b5 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -295,7 +295,8 @@ void scsi_device_unbusy(struct scsi_device *sdev)
 	unsigned long flags;
 
 	atomic_dec(&shost->host_busy);
-	atomic_dec(&starget->target_busy);
+	if (starget->can_queue > 0)
+		atomic_dec(&starget->target_busy);
 
 	if (unlikely(scsi_host_in_recovery(shost) &&
 		     (shost->host_failed || shost->host_eh_scheduled))) {
@@ -364,11 +365,12 @@ static inline bool scsi_device_is_busy(struct scsi_device *sdev)
 
 static inline bool scsi_target_is_busy(struct scsi_target *starget)
 {
-	if (starget->can_queue > 0 &&
-	    atomic_read(&starget->target_busy) >= starget->can_queue)
-		return true;
-	if (atomic_read(&starget->target_blocked) > 0)
-		return true;
+	if (starget->can_queue > 0) {
+		if (atomic_read(&starget->target_busy) >= starget->can_queue)
+			return true;
+		if (atomic_read(&starget->target_blocked) > 0)
+			return true;
+	}
 	return false;
 }
 
@@ -1309,6 +1311,9 @@ static inline int scsi_target_queue_ready(struct Scsi_Host *shost,
 		spin_unlock_irq(shost->host_lock);
 	}
 
+	if (starget->can_queue <= 0)
+		return 1;
+
 	busy = atomic_inc_return(&starget->target_busy) - 1;
 	if (atomic_read(&starget->target_blocked) > 0) {
 		if (busy)
@@ -1324,7 +1329,7 @@ static inline int scsi_target_queue_ready(struct Scsi_Host *shost,
 				 "unblocking target at zero depth\n"));
 	}
 
-	if (starget->can_queue > 0 && busy >= starget->can_queue)
+	if (busy >= starget->can_queue)
 		goto starved;
 
 	return 1;
@@ -1334,7 +1339,8 @@ static inline int scsi_target_queue_ready(struct Scsi_Host *shost,
 	list_move_tail(&sdev->starved_entry, &shost->starved_list);
 	spin_unlock_irq(shost->host_lock);
 out_dec:
-	atomic_dec(&starget->target_busy);
+	if (starget->can_queue > 0)
+		atomic_dec(&starget->target_busy);
 	return 0;
 }
 
@@ -1455,7 +1461,8 @@ static void scsi_kill_request(struct request *req, struct request_queue *q)
 	 */
 	atomic_inc(&sdev->device_busy);
 	atomic_inc(&shost->host_busy);
-	atomic_inc(&starget->target_busy);
+	if (starget->can_queue > 0)
+		atomic_inc(&starget->target_busy);
 
 	blk_complete_request(req);
 }
@@ -1624,7 +1631,8 @@ static void scsi_request_fn(struct request_queue *q)
 	return;
 
  host_not_ready:
-	atomic_dec(&scsi_target(sdev)->target_busy);
+	if (scsi_target(sdev)->can_queue > 0)
+		atomic_dec(&scsi_target(sdev)->target_busy);
  not_ready:
 	/*
 	 * lock q, handle tag, requeue req, and decrement device_busy. We

commit cd9070c9c512ff7995f9019392e0ae548df3a088
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Jan 23 12:07:41 2014 +0100

    scsi: fix the {host,target,device}_blocked counter mess
    
    Seems like these counters are missing any sort of synchronization for
    updates, as a over 10 year old comment from me noted.  Fix this by
    using atomic counters, and while we're at it also make sure they are
    in the same cacheline as the _busy counters and not needlessly stored
    to in every I/O completion.
    
    With the new model the _busy counters can temporarily go negative,
    so all the readers are updated to check for > 0 values.  Longer
    term every successful I/O completion will reset the counters to zero,
    so the temporarily negative values will not cause any harm.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Webb Scales <webbnh@hp.com>
    Acked-by: Jens Axboe <axboe@kernel.dk>
    Tested-by: Bart Van Assche <bvanassche@acm.org>
    Tested-by: Robert Elliott <elliott@hp.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1ddf0fb43b59..69da4cb5cb13 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -99,14 +99,16 @@ scsi_set_blocked(struct scsi_cmnd *cmd, int reason)
 	 */
 	switch (reason) {
 	case SCSI_MLQUEUE_HOST_BUSY:
-		host->host_blocked = host->max_host_blocked;
+		atomic_set(&host->host_blocked, host->max_host_blocked);
 		break;
 	case SCSI_MLQUEUE_DEVICE_BUSY:
 	case SCSI_MLQUEUE_EH_RETRY:
-		device->device_blocked = device->max_device_blocked;
+		atomic_set(&device->device_blocked,
+			   device->max_device_blocked);
 		break;
 	case SCSI_MLQUEUE_TARGET_BUSY:
-		starget->target_blocked = starget->max_target_blocked;
+		atomic_set(&starget->target_blocked,
+			   starget->max_target_blocked);
 		break;
 	}
 }
@@ -351,29 +353,35 @@ static void scsi_single_lun_run(struct scsi_device *current_sdev)
 	spin_unlock_irqrestore(shost->host_lock, flags);
 }
 
-static inline int scsi_device_is_busy(struct scsi_device *sdev)
+static inline bool scsi_device_is_busy(struct scsi_device *sdev)
 {
-	if (atomic_read(&sdev->device_busy) >= sdev->queue_depth ||
-	    sdev->device_blocked)
-		return 1;
-	return 0;
+	if (atomic_read(&sdev->device_busy) >= sdev->queue_depth)
+		return true;
+	if (atomic_read(&sdev->device_blocked) > 0)
+		return true;
+	return false;
 }
 
-static inline int scsi_target_is_busy(struct scsi_target *starget)
+static inline bool scsi_target_is_busy(struct scsi_target *starget)
 {
-	return ((starget->can_queue > 0 &&
-		 atomic_read(&starget->target_busy) >= starget->can_queue) ||
-		 starget->target_blocked);
+	if (starget->can_queue > 0 &&
+	    atomic_read(&starget->target_busy) >= starget->can_queue)
+		return true;
+	if (atomic_read(&starget->target_blocked) > 0)
+		return true;
+	return false;
 }
 
-static inline int scsi_host_is_busy(struct Scsi_Host *shost)
+static inline bool scsi_host_is_busy(struct Scsi_Host *shost)
 {
-	if ((shost->can_queue > 0 &&
-	     atomic_read(&shost->host_busy) >= shost->can_queue) ||
-	    shost->host_blocked || shost->host_self_blocked)
-		return 1;
-
-	return 0;
+	if (shost->can_queue > 0 &&
+	    atomic_read(&shost->host_busy) >= shost->can_queue)
+		return true;
+	if (atomic_read(&shost->host_blocked) > 0)
+		return true;
+	if (shost->host_self_blocked)
+		return true;
+	return false;
 }
 
 static void scsi_starved_list_run(struct Scsi_Host *shost)
@@ -1256,14 +1264,14 @@ static inline int scsi_dev_queue_ready(struct request_queue *q,
 	unsigned int busy;
 
 	busy = atomic_inc_return(&sdev->device_busy) - 1;
-	if (sdev->device_blocked) {
+	if (atomic_read(&sdev->device_blocked)) {
 		if (busy)
 			goto out_dec;
 
 		/*
 		 * unblock after device_blocked iterates to zero
 		 */
-		if (--sdev->device_blocked != 0) {
+		if (atomic_dec_return(&sdev->device_blocked) > 0) {
 			blk_delay_queue(q, SCSI_QUEUE_DELAY);
 			goto out_dec;
 		}
@@ -1302,19 +1310,15 @@ static inline int scsi_target_queue_ready(struct Scsi_Host *shost,
 	}
 
 	busy = atomic_inc_return(&starget->target_busy) - 1;
-	if (starget->target_blocked) {
+	if (atomic_read(&starget->target_blocked) > 0) {
 		if (busy)
 			goto starved;
 
 		/*
 		 * unblock after target_blocked iterates to zero
 		 */
-		spin_lock_irq(shost->host_lock);
-		if (--starget->target_blocked != 0) {
-			spin_unlock_irq(shost->host_lock);
+		if (atomic_dec_return(&starget->target_blocked) > 0)
 			goto out_dec;
-		}
-		spin_unlock_irq(shost->host_lock);
 
 		SCSI_LOG_MLQUEUE(3, starget_printk(KERN_INFO, starget,
 				 "unblocking target at zero depth\n"));
@@ -1349,19 +1353,15 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 		return 0;
 
 	busy = atomic_inc_return(&shost->host_busy) - 1;
-	if (shost->host_blocked) {
+	if (atomic_read(&shost->host_blocked) > 0) {
 		if (busy)
 			goto starved;
 
 		/*
 		 * unblock after host_blocked iterates to zero
 		 */
-		spin_lock_irq(shost->host_lock);
-		if (--shost->host_blocked != 0) {
-			spin_unlock_irq(shost->host_lock);
+		if (atomic_dec_return(&shost->host_blocked) > 0)
 			goto out_dec;
-		}
-		spin_unlock_irq(shost->host_lock);
 
 		SCSI_LOG_MLQUEUE(3,
 			shost_printk(KERN_INFO, shost,

commit 71e75c97f97a9645d25fbf3d8e4165a558f18747
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Apr 11 19:07:01 2014 +0200

    scsi: convert device_busy to atomic_t
    
    Avoid taking the queue_lock to check the per-device queue limit.  Instead
    we do an atomic_inc_return early on to grab our slot in the queue,
    and if necessary decrement it after finishing all checks.
    
    Unlike the host and target busy counters this doesn't allow us to avoid the
    queue_lock in the request_fn due to the way the interface works, but it'll
    allow us to prepare for using the blk-mq code, which doesn't use the
    queue_lock at all, and it at least avoids a queue_lock round trip in
    scsi_device_unbusy, which is still important given how busy the queue_lock
    is.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Webb Scales <webbnh@hp.com>
    Acked-by: Jens Axboe <axboe@kernel.dk>
    Tested-by: Bart Van Assche <bvanassche@acm.org>
    Tested-by: Robert Elliott <elliott@hp.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d0bd7e0ab7a8..1ddf0fb43b59 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -302,9 +302,7 @@ void scsi_device_unbusy(struct scsi_device *sdev)
 		spin_unlock_irqrestore(shost->host_lock, flags);
 	}
 
-	spin_lock_irqsave(sdev->request_queue->queue_lock, flags);
-	sdev->device_busy--;
-	spin_unlock_irqrestore(sdev->request_queue->queue_lock, flags);
+	atomic_dec(&sdev->device_busy);
 }
 
 /*
@@ -355,9 +353,9 @@ static void scsi_single_lun_run(struct scsi_device *current_sdev)
 
 static inline int scsi_device_is_busy(struct scsi_device *sdev)
 {
-	if (sdev->device_busy >= sdev->queue_depth || sdev->device_blocked)
+	if (atomic_read(&sdev->device_busy) >= sdev->queue_depth ||
+	    sdev->device_blocked)
 		return 1;
-
 	return 0;
 }
 
@@ -1204,7 +1202,7 @@ scsi_prep_return(struct request_queue *q, struct request *req, int ret)
 		 * queue must be restarted, so we schedule a callback to happen
 		 * shortly.
 		 */
-		if (sdev->device_busy == 0)
+		if (atomic_read(&sdev->device_busy) == 0)
 			blk_delay_queue(q, SCSI_QUEUE_DELAY);
 		break;
 	default:
@@ -1255,26 +1253,33 @@ static void scsi_unprep_fn(struct request_queue *q, struct request *req)
 static inline int scsi_dev_queue_ready(struct request_queue *q,
 				  struct scsi_device *sdev)
 {
-	if (sdev->device_busy == 0 && sdev->device_blocked) {
+	unsigned int busy;
+
+	busy = atomic_inc_return(&sdev->device_busy) - 1;
+	if (sdev->device_blocked) {
+		if (busy)
+			goto out_dec;
+
 		/*
 		 * unblock after device_blocked iterates to zero
 		 */
-		if (--sdev->device_blocked == 0) {
-			SCSI_LOG_MLQUEUE(3,
-				   sdev_printk(KERN_INFO, sdev,
-				   "unblocking device at zero depth\n"));
-		} else {
+		if (--sdev->device_blocked != 0) {
 			blk_delay_queue(q, SCSI_QUEUE_DELAY);
-			return 0;
+			goto out_dec;
 		}
+		SCSI_LOG_MLQUEUE(3, sdev_printk(KERN_INFO, sdev,
+				   "unblocking device at zero depth\n"));
 	}
-	if (scsi_device_is_busy(sdev))
-		return 0;
+
+	if (busy >= sdev->queue_depth)
+		goto out_dec;
 
 	return 1;
+out_dec:
+	atomic_dec(&sdev->device_busy);
+	return 0;
 }
 
-
 /*
  * scsi_target_queue_ready: checks if there we can send commands to target
  * @sdev: scsi device on starget to check.
@@ -1448,7 +1453,7 @@ static void scsi_kill_request(struct request *req, struct request_queue *q)
 	 * bump busy counts.  To bump the counters, we need to dance
 	 * with the locks as normal issue path does.
 	 */
-	sdev->device_busy++;
+	atomic_inc(&sdev->device_busy);
 	atomic_inc(&shost->host_busy);
 	atomic_inc(&starget->target_busy);
 
@@ -1544,7 +1549,7 @@ static void scsi_request_fn(struct request_queue *q)
 		 * accept it.
 		 */
 		req = blk_peek_request(q);
-		if (!req || !scsi_dev_queue_ready(q, sdev))
+		if (!req)
 			break;
 
 		if (unlikely(!scsi_device_online(sdev))) {
@@ -1554,13 +1559,14 @@ static void scsi_request_fn(struct request_queue *q)
 			continue;
 		}
 
+		if (!scsi_dev_queue_ready(q, sdev))
+			break;
 
 		/*
 		 * Remove the request from the request list.
 		 */
 		if (!(blk_queue_tagged(q) && !blk_queue_start_tag(q, req)))
 			blk_start_request(req);
-		sdev->device_busy++;
 
 		spin_unlock_irq(q->queue_lock);
 		cmd = req->special;
@@ -1630,9 +1636,9 @@ static void scsi_request_fn(struct request_queue *q)
 	 */
 	spin_lock_irq(q->queue_lock);
 	blk_requeue_request(q, req);
-	sdev->device_busy--;
+	atomic_dec(&sdev->device_busy);
 out_delay:
-	if (sdev->device_busy == 0 && !scsi_device_blocked(sdev))
+	if (atomic_read(&sdev->device_busy) && !scsi_device_blocked(sdev))
 		blk_delay_queue(q, SCSI_QUEUE_DELAY);
 }
 
@@ -2371,7 +2377,7 @@ scsi_device_quiesce(struct scsi_device *sdev)
 		return err;
 
 	scsi_run_queue(sdev->request_queue);
-	while (sdev->device_busy) {
+	while (atomic_read(&sdev->device_busy)) {
 		msleep_interruptible(200);
 		scsi_run_queue(sdev->request_queue);
 	}

commit 74665016086615bbaa3fa6f83af410a0a4e029ee
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jan 22 15:29:29 2014 +0100

    scsi: convert host_busy to atomic_t
    
    Avoid taking the host-wide host_lock to check the per-host queue limit.
    Instead we do an atomic_inc_return early on to grab our slot in the queue,
    and if necessary decrement it after finishing all checks.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Webb Scales <webbnh@hp.com>
    Acked-by: Jens Axboe <axboe@kernel.dk>
    Tested-by: Bart Van Assche <bvanassche@acm.org>
    Tested-by: Robert Elliott <elliott@hp.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0580711c2c57..d0bd7e0ab7a8 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -292,14 +292,17 @@ void scsi_device_unbusy(struct scsi_device *sdev)
 	struct scsi_target *starget = scsi_target(sdev);
 	unsigned long flags;
 
-	spin_lock_irqsave(shost->host_lock, flags);
-	shost->host_busy--;
+	atomic_dec(&shost->host_busy);
 	atomic_dec(&starget->target_busy);
+
 	if (unlikely(scsi_host_in_recovery(shost) &&
-		     (shost->host_failed || shost->host_eh_scheduled)))
+		     (shost->host_failed || shost->host_eh_scheduled))) {
+		spin_lock_irqsave(shost->host_lock, flags);
 		scsi_eh_wakeup(shost);
-	spin_unlock(shost->host_lock);
-	spin_lock(sdev->request_queue->queue_lock);
+		spin_unlock_irqrestore(shost->host_lock, flags);
+	}
+
+	spin_lock_irqsave(sdev->request_queue->queue_lock, flags);
 	sdev->device_busy--;
 	spin_unlock_irqrestore(sdev->request_queue->queue_lock, flags);
 }
@@ -367,7 +370,8 @@ static inline int scsi_target_is_busy(struct scsi_target *starget)
 
 static inline int scsi_host_is_busy(struct Scsi_Host *shost)
 {
-	if ((shost->can_queue > 0 && shost->host_busy >= shost->can_queue) ||
+	if ((shost->can_queue > 0 &&
+	     atomic_read(&shost->host_busy) >= shost->can_queue) ||
 	    shost->host_blocked || shost->host_self_blocked)
 		return 1;
 
@@ -1334,38 +1338,54 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 				   struct Scsi_Host *shost,
 				   struct scsi_device *sdev)
 {
-	int ret = 0;
-
-	spin_lock_irq(shost->host_lock);
+	unsigned int busy;
 
 	if (scsi_host_in_recovery(shost))
-		goto out;
-	if (shost->host_busy == 0 && shost->host_blocked) {
+		return 0;
+
+	busy = atomic_inc_return(&shost->host_busy) - 1;
+	if (shost->host_blocked) {
+		if (busy)
+			goto starved;
+
 		/*
 		 * unblock after host_blocked iterates to zero
 		 */
-		if (--shost->host_blocked != 0)
-			goto out;
+		spin_lock_irq(shost->host_lock);
+		if (--shost->host_blocked != 0) {
+			spin_unlock_irq(shost->host_lock);
+			goto out_dec;
+		}
+		spin_unlock_irq(shost->host_lock);
 
 		SCSI_LOG_MLQUEUE(3,
 			shost_printk(KERN_INFO, shost,
 				     "unblocking host at zero depth\n"));
 	}
-	if (scsi_host_is_busy(shost)) {
-		if (list_empty(&sdev->starved_entry))
-			list_add_tail(&sdev->starved_entry, &shost->starved_list);
-		goto out;
-	}
+
+	if (shost->can_queue > 0 && busy >= shost->can_queue)
+		goto starved;
+	if (shost->host_self_blocked)
+		goto starved;
 
 	/* We're OK to process the command, so we can't be starved */
-	if (!list_empty(&sdev->starved_entry))
-		list_del_init(&sdev->starved_entry);
+	if (!list_empty(&sdev->starved_entry)) {
+		spin_lock_irq(shost->host_lock);
+		if (!list_empty(&sdev->starved_entry))
+			list_del_init(&sdev->starved_entry);
+		spin_unlock_irq(shost->host_lock);
+	}
 
-	shost->host_busy++;
-	ret = 1;
-out:
+	return 1;
+
+starved:
+	spin_lock_irq(shost->host_lock);
+	if (list_empty(&sdev->starved_entry))
+		list_add_tail(&sdev->starved_entry, &shost->starved_list);
 	spin_unlock_irq(shost->host_lock);
-	return ret;
+out_dec:
+	atomic_dec(&shost->host_busy);
+	return 0;
 }
 
 /*
@@ -1429,12 +1449,8 @@ static void scsi_kill_request(struct request *req, struct request_queue *q)
 	 * with the locks as normal issue path does.
 	 */
 	sdev->device_busy++;
-	spin_unlock(sdev->request_queue->queue_lock);
-	spin_lock(shost->host_lock);
-	shost->host_busy++;
+	atomic_inc(&shost->host_busy);
 	atomic_inc(&starget->target_busy);
-	spin_unlock(shost->host_lock);
-	spin_lock(sdev->request_queue->queue_lock);
 
 	blk_complete_request(req);
 }

commit 7ae65c0f9646c29432b69580b80e08632e6cd813
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jan 22 14:49:41 2014 +0100

    scsi: convert target_busy to an atomic_t
    
    Avoid taking the host-wide host_lock to check the per-target queue limit.
    Instead we do an atomic_inc_return early on to grab our slot in the queue,
    and if necessary decrement it after finishing all checks.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Webb Scales <webbnh@hp.com>
    Acked-by: Jens Axboe <axboe@kernel.dk>
    Tested-by: Bart Van Assche <bvanassche@acm.org>
    Tested-by: Robert Elliott <elliott@hp.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 112c737884c3..0580711c2c57 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -294,7 +294,7 @@ void scsi_device_unbusy(struct scsi_device *sdev)
 
 	spin_lock_irqsave(shost->host_lock, flags);
 	shost->host_busy--;
-	starget->target_busy--;
+	atomic_dec(&starget->target_busy);
 	if (unlikely(scsi_host_in_recovery(shost) &&
 		     (shost->host_failed || shost->host_eh_scheduled)))
 		scsi_eh_wakeup(shost);
@@ -361,7 +361,7 @@ static inline int scsi_device_is_busy(struct scsi_device *sdev)
 static inline int scsi_target_is_busy(struct scsi_target *starget)
 {
 	return ((starget->can_queue > 0 &&
-		 starget->target_busy >= starget->can_queue) ||
+		 atomic_read(&starget->target_busy) >= starget->can_queue) ||
 		 starget->target_blocked);
 }
 
@@ -1279,37 +1279,50 @@ static inline int scsi_target_queue_ready(struct Scsi_Host *shost,
 					   struct scsi_device *sdev)
 {
 	struct scsi_target *starget = scsi_target(sdev);
-	int ret = 0;
+	unsigned int busy;
 
-	spin_lock_irq(shost->host_lock);
 	if (starget->single_lun) {
+		spin_lock_irq(shost->host_lock);
 		if (starget->starget_sdev_user &&
-		    starget->starget_sdev_user != sdev)
-			goto out;
+		    starget->starget_sdev_user != sdev) {
+			spin_unlock_irq(shost->host_lock);
+			return 0;
+		}
 		starget->starget_sdev_user = sdev;
+		spin_unlock_irq(shost->host_lock);
 	}
 
-	if (starget->target_busy == 0 && starget->target_blocked) {
+	busy = atomic_inc_return(&starget->target_busy) - 1;
+	if (starget->target_blocked) {
+		if (busy)
+			goto starved;
+
 		/*
 		 * unblock after target_blocked iterates to zero
 		 */
-		if (--starget->target_blocked != 0)
-			goto out;
+		spin_lock_irq(shost->host_lock);
+		if (--starget->target_blocked != 0) {
+			spin_unlock_irq(shost->host_lock);
+			goto out_dec;
+		}
+		spin_unlock_irq(shost->host_lock);
 
 		SCSI_LOG_MLQUEUE(3, starget_printk(KERN_INFO, starget,
 				 "unblocking target at zero depth\n"));
 	}
 
-	if (scsi_target_is_busy(starget)) {
-		list_move_tail(&sdev->starved_entry, &shost->starved_list);
-		goto out;
-	}
+	if (starget->can_queue > 0 && busy >= starget->can_queue)
+		goto starved;
 
-	scsi_target(sdev)->target_busy++;
-	ret = 1;
-out:
+	return 1;
+
+starved:
+	spin_lock_irq(shost->host_lock);
+	list_move_tail(&sdev->starved_entry, &shost->starved_list);
 	spin_unlock_irq(shost->host_lock);
-	return ret;
+out_dec:
+	atomic_dec(&starget->target_busy);
+	return 0;
 }
 
 /*
@@ -1419,7 +1432,7 @@ static void scsi_kill_request(struct request *req, struct request_queue *q)
 	spin_unlock(sdev->request_queue->queue_lock);
 	spin_lock(shost->host_lock);
 	shost->host_busy++;
-	starget->target_busy++;
+	atomic_inc(&starget->target_busy);
 	spin_unlock(shost->host_lock);
 	spin_lock(sdev->request_queue->queue_lock);
 
@@ -1589,9 +1602,7 @@ static void scsi_request_fn(struct request_queue *q)
 	return;
 
  host_not_ready:
-	spin_lock_irq(shost->host_lock);
-	scsi_target(sdev)->target_busy--;
-	spin_unlock_irq(shost->host_lock);
+	atomic_dec(&scsi_target(sdev)->target_busy);
  not_ready:
 	/*
 	 * lock q, handle tag, requeue req, and decrement device_busy. We

commit cf68d334dd3a323624f6399dc807d34d8b816391
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jan 22 14:36:32 2014 +0100

    scsi: push host_lock down into scsi_{host,target}_queue_ready
    
    Prepare for not taking a host-wide lock in the dispatch path by pushing
    the lock down into the places that actually need it.  Note that this
    patch is just a preparation step, as it will actually increase lock
    roundtrips and thus decrease performance on its own.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Webb Scales <webbnh@hp.com>
    Acked-by: Jens Axboe <axboe@kernel.dk>
    Tested-by: Bart Van Assche <bvanassche@acm.org>
    Tested-by: Robert Elliott <elliott@hp.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b83269689542..112c737884c3 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1274,18 +1274,18 @@ static inline int scsi_dev_queue_ready(struct request_queue *q,
 /*
  * scsi_target_queue_ready: checks if there we can send commands to target
  * @sdev: scsi device on starget to check.
- *
- * Called with the host lock held.
  */
 static inline int scsi_target_queue_ready(struct Scsi_Host *shost,
 					   struct scsi_device *sdev)
 {
 	struct scsi_target *starget = scsi_target(sdev);
+	int ret = 0;
 
+	spin_lock_irq(shost->host_lock);
 	if (starget->single_lun) {
 		if (starget->starget_sdev_user &&
 		    starget->starget_sdev_user != sdev)
-			return 0;
+			goto out;
 		starget->starget_sdev_user = sdev;
 	}
 
@@ -1293,57 +1293,66 @@ static inline int scsi_target_queue_ready(struct Scsi_Host *shost,
 		/*
 		 * unblock after target_blocked iterates to zero
 		 */
-		if (--starget->target_blocked == 0) {
-			SCSI_LOG_MLQUEUE(3, starget_printk(KERN_INFO, starget,
-					 "unblocking target at zero depth\n"));
-		} else
-			return 0;
+		if (--starget->target_blocked != 0)
+			goto out;
+
+		SCSI_LOG_MLQUEUE(3, starget_printk(KERN_INFO, starget,
+				 "unblocking target at zero depth\n"));
 	}
 
 	if (scsi_target_is_busy(starget)) {
 		list_move_tail(&sdev->starved_entry, &shost->starved_list);
-		return 0;
+		goto out;
 	}
 
-	return 1;
+	scsi_target(sdev)->target_busy++;
+	ret = 1;
+out:
+	spin_unlock_irq(shost->host_lock);
+	return ret;
 }
 
 /*
  * scsi_host_queue_ready: if we can send requests to shost, return 1 else
  * return 0. We must end up running the queue again whenever 0 is
  * returned, else IO can hang.
- *
- * Called with host_lock held.
  */
 static inline int scsi_host_queue_ready(struct request_queue *q,
 				   struct Scsi_Host *shost,
 				   struct scsi_device *sdev)
 {
+	int ret = 0;
+
+	spin_lock_irq(shost->host_lock);
+
 	if (scsi_host_in_recovery(shost))
-		return 0;
+		goto out;
 	if (shost->host_busy == 0 && shost->host_blocked) {
 		/*
 		 * unblock after host_blocked iterates to zero
 		 */
-		if (--shost->host_blocked == 0) {
-			SCSI_LOG_MLQUEUE(3,
-				shost_printk(KERN_INFO, shost,
-					     "unblocking host at zero depth\n"));
-		} else {
-			return 0;
-		}
+		if (--shost->host_blocked != 0)
+			goto out;
+
+		SCSI_LOG_MLQUEUE(3,
+			shost_printk(KERN_INFO, shost,
+				     "unblocking host at zero depth\n"));
 	}
 	if (scsi_host_is_busy(shost)) {
 		if (list_empty(&sdev->starved_entry))
 			list_add_tail(&sdev->starved_entry, &shost->starved_list);
-		return 0;
+		goto out;
 	}
 
 	/* We're OK to process the command, so we can't be starved */
 	if (!list_empty(&sdev->starved_entry))
 		list_del_init(&sdev->starved_entry);
 
-	return 1;
+	shost->host_busy++;
+	ret = 1;
+out:
+	spin_unlock_irq(shost->host_lock);
+	return ret;
 }
 
 /*
@@ -1524,7 +1533,7 @@ static void scsi_request_fn(struct request_queue *q)
 			blk_start_request(req);
 		sdev->device_busy++;
 
-		spin_unlock(q->queue_lock);
+		spin_unlock_irq(q->queue_lock);
 		cmd = req->special;
 		if (unlikely(cmd == NULL)) {
 			printk(KERN_CRIT "impossible request in %s.\n"
@@ -1534,7 +1543,6 @@ static void scsi_request_fn(struct request_queue *q)
 			blk_dump_rq_flags(req, "foo");
 			BUG();
 		}
-		spin_lock(shost->host_lock);
 
 		/*
 		 * We hit this when the driver is using a host wide
@@ -1545,9 +1553,11 @@ static void scsi_request_fn(struct request_queue *q)
 		 * a run when a tag is freed.
 		 */
 		if (blk_queue_tagged(q) && !blk_rq_tagged(req)) {
+			spin_lock_irq(shost->host_lock);
 			if (list_empty(&sdev->starved_entry))
 				list_add_tail(&sdev->starved_entry,
 					      &shost->starved_list);
+			spin_unlock_irq(shost->host_lock);
 			goto not_ready;
 		}
 
@@ -1555,16 +1565,7 @@ static void scsi_request_fn(struct request_queue *q)
 			goto not_ready;
 
 		if (!scsi_host_queue_ready(q, shost, sdev))
-			goto not_ready;
-
-		scsi_target(sdev)->target_busy++;
-		shost->host_busy++;
-
-		/*
-		 * XXX(hch): This is rather suboptimal, scsi_dispatch_cmd will
-		 *		take the lock again.
-		 */
-		spin_unlock_irq(shost->host_lock);
+			goto host_not_ready;
 
 		/*
 		 * Finally, initialize any error handling parameters, and set up
@@ -1587,9 +1588,11 @@ static void scsi_request_fn(struct request_queue *q)
 
 	return;
 
- not_ready:
+ host_not_ready:
+	spin_lock_irq(shost->host_lock);
+	scsi_target(sdev)->target_busy--;
 	spin_unlock_irq(shost->host_lock);
-
+ not_ready:
 	/*
 	 * lock q, handle tag, requeue req, and decrement device_busy. We
 	 * must return with queue_lock held.

commit 3b5382c459b709845f43361225a2e3284e50752e
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue May 6 12:25:40 2014 +0200

    scsi: set ->scsi_done before calling scsi_dispatch_cmd
    
    The blk-mq code path will set this to a different function, so make the
    code simpler by setting it up in a legacy-request specific place.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Webb Scales <webbnh@hp.com>
    Acked-by: Jens Axboe <axboe@kernel.dk>
    Tested-by: Bart Van Assche <bvanassche@acm.org>
    Tested-by: Robert Elliott <elliott@hp.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index bf7342748f32..b83269689542 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -29,6 +29,8 @@
 #include <scsi/scsi_eh.h>
 #include <scsi/scsi_host.h>
 
+#include <trace/events/scsi.h>
+
 #include "scsi_priv.h"
 #include "scsi_logging.h"
 
@@ -1454,6 +1456,23 @@ static void scsi_softirq_done(struct request *rq)
 	}
 }
 
+/**
+ * scsi_done - Invoke completion on finished SCSI command.
+ * @cmd: The SCSI Command for which a low-level device driver (LLDD) gives
+ * ownership back to SCSI Core -- i.e. the LLDD has finished with it.
+ *
+ * Description: This function is the mid-level's (SCSI Core) interrupt routine,
+ * which regains ownership of the SCSI command (de facto) from a LLDD, and
+ * calls blk_complete_request() for further processing.
+ *
+ * This function is interrupt context safe.
+ */
+static void scsi_done(struct scsi_cmnd *cmd)
+{
+	trace_scsi_dispatch_cmd_done(cmd);
+	blk_complete_request(cmd->request);
+}
+
 /*
  * Function:    scsi_request_fn()
  *
@@ -1556,6 +1575,7 @@ static void scsi_request_fn(struct request_queue *q)
 		/*
 		 * Dispatch the command to the low-level driver.
 		 */
+		cmd->scsi_done = scsi_done;
 		rtn = scsi_dispatch_cmd(cmd);
 		if (rtn) {
 			scsi_queue_insert(cmd, rtn);

commit d0d3bbf96ec21167e55a48ebb31912918a674e0d
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jan 22 18:39:04 2014 +0100

    scsi: centralize command re-queueing in scsi_dispatch_fn
    
    Make sure we only have the logic for requeing commands in one place.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Webb Scales <webbnh@hp.com>
    Acked-by: Jens Axboe <axboe@kernel.dk>
    Tested-by: Bart Van Assche <bvanassche@acm.org>
    Tested-by: Robert Elliott <elliott@hp.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 3ac677c48168..bf7342748f32 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1557,9 +1557,12 @@ static void scsi_request_fn(struct request_queue *q)
 		 * Dispatch the command to the low-level driver.
 		 */
 		rtn = scsi_dispatch_cmd(cmd);
-		spin_lock_irq(q->queue_lock);
-		if (rtn)
+		if (rtn) {
+			scsi_queue_insert(cmd, rtn);
+			spin_lock_irq(q->queue_lock);
 			goto out_delay;
+		}
+		spin_lock_irq(q->queue_lock);
 	}
 
 	return;
@@ -1579,7 +1582,7 @@ static void scsi_request_fn(struct request_queue *q)
 	blk_requeue_request(q, req);
 	sdev->device_busy--;
 out_delay:
-	if (sdev->device_busy == 0)
+	if (sdev->device_busy == 0 && !scsi_device_blocked(sdev))
 		blk_delay_queue(q, SCSI_QUEUE_DELAY);
 }
 

commit de3e8bf3315c9c7c7ffd2f9b2f299b4205feefb9
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Jan 23 13:55:38 2014 +0100

    scsi: split __scsi_queue_insert
    
    Factor out a helper to set the _blocked values, which we'll reuse for the
    blk-mq code path.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Webb Scales <webbnh@hp.com>
    Acked-by: Jens Axboe <axboe@kernel.dk>
    Tested-by: Bart Van Assche <bvanassche@acm.org>
    Tested-by: Robert Elliott <elliott@hp.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 04c368470c8a..3ac677c48168 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -75,28 +75,12 @@ struct kmem_cache *scsi_sdb_cache;
  */
 #define SCSI_QUEUE_DELAY	3
 
-/**
- * __scsi_queue_insert - private queue insertion
- * @cmd: The SCSI command being requeued
- * @reason:  The reason for the requeue
- * @unbusy: Whether the queue should be unbusied
- *
- * This is a private queue insertion.  The public interface
- * scsi_queue_insert() always assumes the queue should be unbusied
- * because it's always called before the completion.  This function is
- * for a requeue after completion, which should only occur in this
- * file.
- */
-static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
+static void
+scsi_set_blocked(struct scsi_cmnd *cmd, int reason)
 {
 	struct Scsi_Host *host = cmd->device->host;
 	struct scsi_device *device = cmd->device;
 	struct scsi_target *starget = scsi_target(device);
-	struct request_queue *q = device->request_queue;
-	unsigned long flags;
-
-	SCSI_LOG_MLQUEUE(1, scmd_printk(KERN_INFO, cmd,
-		"Inserting command %p into mlqueue\n", cmd));
 
 	/*
 	 * Set the appropriate busy bit for the device/host.
@@ -123,6 +107,30 @@ static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
 		starget->target_blocked = starget->max_target_blocked;
 		break;
 	}
+}
+
+/**
+ * __scsi_queue_insert - private queue insertion
+ * @cmd: The SCSI command being requeued
+ * @reason:  The reason for the requeue
+ * @unbusy: Whether the queue should be unbusied
+ *
+ * This is a private queue insertion.  The public interface
+ * scsi_queue_insert() always assumes the queue should be unbusied
+ * because it's always called before the completion.  This function is
+ * for a requeue after completion, which should only occur in this
+ * file.
+ */
+static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
+{
+	struct scsi_device *device = cmd->device;
+	struct request_queue *q = device->request_queue;
+	unsigned long flags;
+
+	SCSI_LOG_MLQUEUE(1, scmd_printk(KERN_INFO, cmd,
+		"Inserting command %p into mlqueue\n", cmd));
+
+	scsi_set_blocked(cmd, reason);
 
 	/*
 	 * Decrement the counters, since these commands are no longer

commit 6af7a4ffa2775c452c77eccc6bb6a4e2b71c2371
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Jul 8 13:16:17 2014 +0200

    scsi: add scsi_setup_cmnd helper
    
    Factor out command setup code that will be shared with the blk-mq code path.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Webb Scales <webbnh@hp.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 85cf0ef843f6..04c368470c8a 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1092,6 +1092,27 @@ static int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
 	return scsi_cmd_to_driver(cmd)->init_command(cmd);
 }
 
+static int scsi_setup_cmnd(struct scsi_device *sdev, struct request *req)
+{
+	struct scsi_cmnd *cmd = req->special;
+
+	if (!blk_rq_bytes(req))
+		cmd->sc_data_direction = DMA_NONE;
+	else if (rq_data_dir(req) == WRITE)
+		cmd->sc_data_direction = DMA_TO_DEVICE;
+	else
+		cmd->sc_data_direction = DMA_FROM_DEVICE;
+
+	switch (req->cmd_type) {
+	case REQ_TYPE_FS:
+		return scsi_setup_fs_cmnd(sdev, req);
+	case REQ_TYPE_BLOCK_PC:
+		return scsi_setup_blk_pc_cmnd(sdev, req);
+	default:
+		return BLKPREP_KILL;
+	}
+}
+
 static int
 scsi_prep_state_check(struct scsi_device *sdev, struct request *req)
 {
@@ -1195,24 +1216,7 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 		goto out;
 	}
 
-	if (!blk_rq_bytes(req))
-		cmd->sc_data_direction = DMA_NONE;
-	else if (rq_data_dir(req) == WRITE)
-		cmd->sc_data_direction = DMA_TO_DEVICE;
-	else
-		cmd->sc_data_direction = DMA_FROM_DEVICE;
-
-	switch (req->cmd_type) {
-	case REQ_TYPE_FS:
-		ret = scsi_setup_fs_cmnd(sdev, req);
-		break;
-	case REQ_TYPE_BLOCK_PC:
-		ret = scsi_setup_blk_pc_cmnd(sdev, req);
-		break;
-	default:
-		ret = BLKPREP_KILL;
-	}
-
+	ret = scsi_setup_cmnd(sdev, req);
 out:
 	return scsi_prep_return(q, req, ret);
 }

commit 4f1e57657548d7afb4a6b62097765282f3b03c6e
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 28 12:36:28 2014 +0200

    scsi: mark scsi_setup_blk_pc_cmnd static
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4e15a3a5ad29..85cf0ef843f6 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1047,7 +1047,7 @@ static struct scsi_cmnd *scsi_get_cmd_from_req(struct scsi_device *sdev,
 	return cmd;
 }
 
-int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
+static int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 {
 	struct scsi_cmnd *cmd = req->special;
 
@@ -1072,7 +1072,6 @@ int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 	cmd->allowed = req->retries;
 	return BLKPREP_OK;
 }
-EXPORT_SYMBOL(scsi_setup_blk_pc_cmnd);
 
 /*
  * Setup a REQ_TYPE_FS command.  These are simple request from filesystems

commit 5158a899d8f24f74cad29b6aaad2b0f86499e5d5
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 28 16:41:43 2014 +0200

    scsi: set sc_data_direction in common code
    
    The data direction fiel in the SCSI command is derived only from the block
    request structure.  Move setting it up into common code instead of
    duplicating it in the ULDs.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 2afb96b801cb..4e15a3a5ad29 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1068,13 +1068,6 @@ int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 	}
 
 	cmd->cmd_len = req->cmd_len;
-	if (!blk_rq_bytes(req))
-		cmd->sc_data_direction = DMA_NONE;
-	else if (rq_data_dir(req) == WRITE)
-		cmd->sc_data_direction = DMA_TO_DEVICE;
-	else
-		cmd->sc_data_direction = DMA_FROM_DEVICE;
-	
 	cmd->transfersize = blk_rq_bytes(req);
 	cmd->allowed = req->retries;
 	return BLKPREP_OK;
@@ -1203,6 +1196,13 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 		goto out;
 	}
 
+	if (!blk_rq_bytes(req))
+		cmd->sc_data_direction = DMA_NONE;
+	else if (rq_data_dir(req) == WRITE)
+		cmd->sc_data_direction = DMA_TO_DEVICE;
+	else
+		cmd->sc_data_direction = DMA_FROM_DEVICE;
+
 	switch (req->cmd_type) {
 	case REQ_TYPE_FS:
 		ret = scsi_setup_fs_cmnd(sdev, req);

commit 3868cf8ea70a57fc3f927872d8296f287ce4b96a
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 28 11:58:42 2014 +0200

    scsi: restructure command initialization for TYPE_FS requests
    
    We should call the device handler prep_fn for all TYPE_FS requests,
    not just simple read/write calls that are handled by the disk driver.
    
    Restructure the common I/O code to call the prep_fn handler and zero
    out the CDB, and just leave the call to scsi_init_io to the ULDs.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 150d7bb675a1..2afb96b801cb 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1082,11 +1082,10 @@ int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 EXPORT_SYMBOL(scsi_setup_blk_pc_cmnd);
 
 /*
- * Setup a REQ_TYPE_FS command.  These are simple read/write request
- * from filesystems that still need to be translated to SCSI CDBs from
- * the ULD.
+ * Setup a REQ_TYPE_FS command.  These are simple request from filesystems
+ * that still need to be translated to SCSI CDBs from the ULD.
  */
-int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
+static int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
 {
 	struct scsi_cmnd *cmd = req->special;
 
@@ -1098,9 +1097,8 @@ int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
 	}
 
 	memset(cmd->cmnd, 0, BLK_MAX_CDB);
-	return scsi_init_io(cmd, GFP_ATOMIC);
+	return scsi_cmd_to_driver(cmd)->init_command(cmd);
 }
-EXPORT_SYMBOL(scsi_setup_fs_cmnd);
 
 static int
 scsi_prep_state_check(struct scsi_device *sdev, struct request *req)
@@ -1205,12 +1203,16 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 		goto out;
 	}
 
-	if (req->cmd_type == REQ_TYPE_FS)
-		ret = scsi_cmd_to_driver(cmd)->init_command(cmd);
-	else if (req->cmd_type == REQ_TYPE_BLOCK_PC)
+	switch (req->cmd_type) {
+	case REQ_TYPE_FS:
+		ret = scsi_setup_fs_cmnd(sdev, req);
+		break;
+	case REQ_TYPE_BLOCK_PC:
 		ret = scsi_setup_blk_pc_cmnd(sdev, req);
-	else
+		break;
+	default:
 		ret = BLKPREP_KILL;
+	}
 
 out:
 	return scsi_prep_return(q, req, ret);

commit 635d98b1d0cfc2ba3426a701725d31a6102c059a
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 28 11:51:01 2014 +0200

    scsi: move the nr_phys_segments assert into scsi_init_io
    
    scsi_init_io should only be called for requests that transfer data,
    so move the assert that a request has segments from the callers into
    scsi_init_io.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 03076b2b5deb..150d7bb675a1 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -963,8 +963,11 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 {
 	struct scsi_device *sdev = cmd->device;
 	struct request *rq = cmd->request;
+	int error;
 
-	int error = scsi_init_sgtable(rq, &cmd->sdb, gfp_mask);
+	BUG_ON(!rq->nr_phys_segments);
+
+	error = scsi_init_sgtable(rq, &cmd->sdb, gfp_mask);
 	if (error)
 		goto err_exit;
 
@@ -1055,11 +1058,7 @@ int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 	 * submit a request without an attached bio.
 	 */
 	if (req->bio) {
-		int ret;
-
-		BUG_ON(!req->nr_phys_segments);
-
-		ret = scsi_init_io(cmd, GFP_ATOMIC);
+		int ret = scsi_init_io(cmd, GFP_ATOMIC);
 		if (unlikely(ret))
 			return ret;
 	} else {
@@ -1098,11 +1097,6 @@ int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
 			return ret;
 	}
 
-	/*
-	 * Filesystem requests must transfer data.
-	 */
-	BUG_ON(!req->nr_phys_segments);
-
 	memset(cmd->cmnd, 0, BLK_MAX_CDB);
 	return scsi_init_io(cmd, GFP_ATOMIC);
 }

commit e6c11dbb8da81c599ca09ef2f6311220e068acd8
Author: Maurizio Lombardi <mlombard@redhat.com>
Date:   Thu Jul 10 09:41:53 2014 +0200

    scsi_lib: remove the description string in scsi_io_completion()
    
    During IO with fabric faults, one generally sees several "Unhandled error
    code" messages in the syslog as shown below:
    
    sd 4:0:6:2: [sdbw] Unhandled error code
    sd 4:0:6:2: [sdbw] Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK
    sd 4:0:6:2: [sdbw] CDB: Read(10): 28 00 00 00 00 00 00 00 08 00
    end_request: I/O error, dev sdbw, sector 0
    
    This comes from scsi_io_completion (in scsi_lib.c) while handling error
    codes other than DID_RESET or not deferred sense keys i.e. this is
    actually handled by the SCSI mid layer. But what gets displayed here is
    "Unhandled error code" which is quite misleading as it indicates
    something that is not addressed by the mid layer.
    
    The description string is based on the sense key and sometimes on the
    additional sense code;
    since the ACTION_FAIL case always prints the sense key and the
    additional sense code, this patch removes the description string
    completely because it does not add useful information.
    
    Signed-off-by: Maurizio Lombardi <mlombard@redhat.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index db7b7f2c14b8..03076b2b5deb 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -685,7 +685,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	int sense_deferred = 0;
 	enum {ACTION_FAIL, ACTION_REPREP, ACTION_RETRY,
 	      ACTION_DELAYED_RETRY} action;
-	char *description = NULL;
 	unsigned long wait_for = (cmd->allowed + 1) * req->timeout;
 
 	if (result) {
@@ -810,7 +809,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				 * and quietly refuse further access.
 				 */
 				cmd->device->changed = 1;
-				description = "Media Changed";
 				action = ACTION_FAIL;
 			} else {
 				/* Must have been a power glitch, or a
@@ -838,27 +836,10 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				cmd->device->use_10_for_rw = 0;
 				action = ACTION_REPREP;
 			} else if (sshdr.asc == 0x10) /* DIX */ {
-				description = "Host Data Integrity Failure";
 				action = ACTION_FAIL;
 				error = -EILSEQ;
 			/* INVALID COMMAND OPCODE or INVALID FIELD IN CDB */
 			} else if (sshdr.asc == 0x20 || sshdr.asc == 0x24) {
-				switch (cmd->cmnd[0]) {
-				case UNMAP:
-					description = "Discard failure";
-					break;
-				case WRITE_SAME:
-				case WRITE_SAME_16:
-					if (cmd->cmnd[1] & 0x8)
-						description = "Discard failure";
-					else
-						description =
-							"Write same failure";
-					break;
-				default:
-					description = "Invalid command failure";
-					break;
-				}
 				action = ACTION_FAIL;
 				error = -EREMOTEIO;
 			} else
@@ -866,10 +847,8 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			break;
 		case ABORTED_COMMAND:
 			action = ACTION_FAIL;
-			if (sshdr.asc == 0x10) { /* DIF */
-				description = "Target Data Integrity Failure";
+			if (sshdr.asc == 0x10) /* DIF */
 				error = -EILSEQ;
-			}
 			break;
 		case NOT_READY:
 			/* If the device is in the process of becoming
@@ -888,42 +867,31 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 					action = ACTION_DELAYED_RETRY;
 					break;
 				default:
-					description = "Device not ready";
 					action = ACTION_FAIL;
 					break;
 				}
-			} else {
-				description = "Device not ready";
+			} else
 				action = ACTION_FAIL;
-			}
 			break;
 		case VOLUME_OVERFLOW:
 			/* See SSC3rXX or current. */
 			action = ACTION_FAIL;
 			break;
 		default:
-			description = "Unhandled sense code";
 			action = ACTION_FAIL;
 			break;
 		}
-	} else {
-		description = "Unhandled error code";
+	} else
 		action = ACTION_FAIL;
-	}
 
 	if (action != ACTION_FAIL &&
-	    time_before(cmd->jiffies_at_alloc + wait_for, jiffies)) {
+	    time_before(cmd->jiffies_at_alloc + wait_for, jiffies))
 		action = ACTION_FAIL;
-		description = "Command timed out";
-	}
 
 	switch (action) {
 	case ACTION_FAIL:
 		/* Give up and fail the remainder of the request */
 		if (!(req->cmd_flags & REQ_QUIET)) {
-			if (description)
-				scmd_printk(KERN_INFO, cmd, "%s\n",
-					    description);
 			scsi_print_result(cmd);
 			if (driver_byte(result) & DRIVER_SENSE)
 				scsi_print_sense("", cmd);

commit f1bea55d5afa371c311b61946c58b2cd4e78fb2d
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Apr 15 12:26:54 2014 +0200

    scsi: remove various exports that were only used by scsi_tgt
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Reviewed-by: Hannes Reinecke <hare@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 093e63207dc6..db7b7f2c14b8 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -579,7 +579,7 @@ static void scsi_free_sgtable(struct scsi_data_buffer *sdb)
  *		the __init_io() function.  Primarily this would involve
  *		the scatter-gather table.
  */
-void scsi_release_buffers(struct scsi_cmnd *cmd)
+static void scsi_release_buffers(struct scsi_cmnd *cmd)
 {
 	if (cmd->sdb.table.nents)
 		scsi_free_sgtable(&cmd->sdb);
@@ -589,7 +589,6 @@ void scsi_release_buffers(struct scsi_cmnd *cmd)
 	if (scsi_prot_sg_count(cmd))
 		scsi_free_sgtable(cmd->prot_sdb);
 }
-EXPORT_SYMBOL(scsi_release_buffers);
 
 static void scsi_release_bidi_buffers(struct scsi_cmnd *cmd)
 {
@@ -1609,7 +1608,7 @@ static void scsi_request_fn(struct request_queue *q)
 		blk_delay_queue(q, SCSI_QUEUE_DELAY);
 }
 
-u64 scsi_calculate_bounce_limit(struct Scsi_Host *shost)
+static u64 scsi_calculate_bounce_limit(struct Scsi_Host *shost)
 {
 	struct device *host_dev;
 	u64 bounce_limit = 0xffffffff;
@@ -1629,7 +1628,6 @@ u64 scsi_calculate_bounce_limit(struct Scsi_Host *shost)
 
 	return bounce_limit;
 }
-EXPORT_SYMBOL(scsi_calculate_bounce_limit);
 
 struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
 					 request_fn_proc *request_fn)

commit 91921e016a2199e7afe5933c94bd9f723d946598
Author: Hannes Reinecke <hare@suse.de>
Date:   Wed Jun 25 16:39:59 2014 +0200

    scsi: use dev_printk variants where possible
    
    Using dev_printk variants prefixes the logging message with
    the originating device, which makes debugging easier.
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 3f50dfcb3227..093e63207dc6 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -95,8 +95,8 @@ static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
 	struct request_queue *q = device->request_queue;
 	unsigned long flags;
 
-	SCSI_LOG_MLQUEUE(1,
-		 printk("Inserting command %p into mlqueue\n", cmd));
+	SCSI_LOG_MLQUEUE(1, scmd_printk(KERN_INFO, cmd,
+		"Inserting command %p into mlqueue\n", cmd));
 
 	/*
 	 * Set the appropriate busy bit for the device/host.
@@ -750,9 +750,9 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	 * Next deal with any sectors which we were able to correctly
 	 * handle.
 	 */
-	SCSI_LOG_HLCOMPLETE(1, printk("%u sectors total, "
-				      "%d bytes done.\n",
-				      blk_rq_sectors(req), good_bytes));
+	SCSI_LOG_HLCOMPLETE(1, scmd_printk(KERN_INFO, cmd,
+		"%u sectors total, %d bytes done.\n",
+		blk_rq_sectors(req), good_bytes));
 
 	/*
 	 * Recovered errors need reporting, but they're always treated
@@ -1351,8 +1351,8 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 		 */
 		if (--shost->host_blocked == 0) {
 			SCSI_LOG_MLQUEUE(3,
-				printk("scsi%d unblocking host at zero depth\n",
-					shost->host_no));
+				shost_printk(KERN_INFO, shost,
+					     "unblocking host at zero depth\n"));
 		} else {
 			return 0;
 		}
@@ -1461,7 +1461,7 @@ static void scsi_softirq_done(struct request *rq)
 			    wait_for/HZ);
 		disposition = SUCCESS;
 	}
-			
+
 	scsi_log_completion(cmd, disposition);
 
 	switch (disposition) {
@@ -1509,7 +1509,7 @@ static void scsi_request_fn(struct request_queue *q)
 		int rtn;
 		/*
 		 * get next queueable request.  We do this early to make sure
-		 * that the request is fully prepared even if we cannot 
+		 * that the request is fully prepared even if we cannot
 		 * accept it.
 		 */
 		req = blk_peek_request(q);
@@ -2147,9 +2147,9 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 	return 0;
 
  illegal:
-	SCSI_LOG_ERROR_RECOVERY(1, 
+	SCSI_LOG_ERROR_RECOVERY(1,
 				sdev_printk(KERN_ERR, sdev,
-					    "Illegal state transition %s->%s\n",
+					    "Illegal state transition %s->%s",
 					    scsi_device_state_name(oldstate),
 					    scsi_device_state_name(state))
 				);

commit 89fb4cd1f717a871ef79fa7debbe840e3225cd54
Author: James Bottomley <JBottomley@Parallels.com>
Date:   Thu Jul 3 19:17:34 2014 +0200

    scsi: handle flush errors properly
    
    Flush commands don't transfer data and thus need to be special cased
    in the I/O completion handler so that we can propagate errors to
    the block layer and filesystem.
    
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>
    Reported-by: Steven Haber <steven@qumulo.com>
    Tested-by: Steven Haber <steven@qumulo.com>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f7e316368c99..3f50dfcb3227 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -733,6 +733,14 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			scsi_next_command(cmd);
 			return;
 		}
+	} else if (blk_rq_bytes(req) == 0 && result && !sense_deferred) {
+		/*
+		 * Certain non BLOCK_PC requests are commands that don't
+		 * actually transfer anything (FLUSH), so cannot use
+		 * good_bytes != blk_rq_bytes(req) as the signal for an error.
+		 * This sets the error explicitly for the problem case.
+		 */
+		error = __scsi_error_from_host_byte(cmd, result);
 	}
 
 	/* no bidi support for !REQ_TYPE_BLOCK_PC yet */

commit 23d4ed53b7342bf5999b3ea227d9f69e75e5a625
Merge: e413a19a8ef4 a2d445d44000
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jun 11 08:41:17 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.dk/linux-block
    
    Pull block layer fixes from Jens Axboe:
     "Final small batch of fixes to be included before -rc1.  Some general
      cleanups in here as well, but some of the blk-mq fixes we need for the
      NVMe conversion and/or scsi-mq.  The pull request contains:
    
       - Support for not merging across a specified "chunk size", if set by
         the driver.  Some NVMe devices perform poorly for IO that crosses
         such a chunk, so we need to support it generically as part of
         request merging avoid having to do complicated split logic.  From
         me.
    
       - Bump max tag depth to 10Ki tags.  Some scsi devices have a huge
         shared tag space.  Before we failed with EINVAL if a too large tag
         depth was specified, now we truncate it and pass back the actual
         value.  From me.
    
       - Various blk-mq rq init fixes from me and others.
    
       - A fix for enter on a dying queue for blk-mq from Keith.  This is
         needed to prevent oopsing on hot device removal.
    
       - Fixup for blk-mq timer addition from Ming Lei.
    
       - Small round of performance fixes for mtip32xx from Sam Bradshaw.
    
       - Minor stack leak fix from Rickard Strandqvist.
    
       - Two __init annotations from Fabian Frederick"
    
    * 'for-linus' of git://git.kernel.dk/linux-block:
      block: add __init to blkcg_policy_register
      block: add __init to elv_register
      block: ensure that bio_add_page() always accepts a page for an empty bio
      blk-mq: add timer in blk_mq_start_request
      blk-mq: always initialize request->start_time
      block: blk-exec.c: Cleaning up local variable address returnd
      mtip32xx: minor performance enhancements
      blk-mq: ->timeout should be cleared in blk_mq_rq_ctx_init()
      blk-mq: don't allow queue entering for a dying queue
      blk-mq: bump max tag depth to 10K tags
      block: add blk_rq_set_block_pc()
      block: add notion of a chunk size for request merging

commit 1c54fc1efe6922b4e7ffd591739d72050976ccd6
Merge: f4f9b8fc73f9 b4c43993f448
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jun 9 18:54:06 2014 -0700

    Merge tag 'scsi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi
    
    Pull SCSI updates from James Bottomley:
     "This patch consists of the usual driver updates (qla2xxx, qla4xxx,
      lpfc, be2iscsi, fnic, ufs, NCR5380) The NCR5380 is the addition to
      maintained status of a long neglected driver for older hardware.  In
      addition there are a lot of minor fixes and cleanups and some more
      updates to make scsi mq ready"
    
    * tag 'scsi-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi: (130 commits)
      include/scsi/osd_protocol.h: remove unnecessary __constant
      mvsas: Recognise device/subsystem 9485/9485 as 88SE9485
      Revert "be2iscsi: Fix processing cqe for cxn whose endpoint is freed"
      mptfusion: fix msgContext in mptctl_hp_hostinfo
      acornscsi: remove linked command support
      scsi/NCR5380: dprintk macro
      fusion: Remove use of DEF_SCSI_QCMD
      fusion: Add free msg frames to the head, not tail of list
      mpt2sas: Add free smids to the head, not tail of list
      mpt2sas: Remove use of DEF_SCSI_QCMD
      mpt2sas: Remove uses of serial_number
      mpt3sas: Remove use of DEF_SCSI_QCMD
      mpt3sas: Remove uses of serial_number
      qla2xxx: Use kmemdup instead of kmalloc + memcpy
      qla4xxx: Use kmemdup instead of kmalloc + memcpy
      qla2xxx: fix incorrect debug printk
      be2iscsi: Bump the driver version
      be2iscsi: Fix processing cqe for cxn whose endpoint is freed
      be2iscsi: Fix destroy MCC-CQ before MCC-EQ is destroyed
      be2iscsi: Fix memory corruption in MBX path
      ...

commit f27b087b81b70513b8c61ec20596c868f7b93474
Author: Jens Axboe <axboe@fb.com>
Date:   Fri Jun 6 07:57:37 2014 -0600

    block: add blk_rq_set_block_pc()
    
    With the optimizations around not clearing the full request at alloc
    time, we are leaving some of the needed init for REQ_TYPE_BLOCK_PC
    up to the user allocating the request.
    
    Add a blk_rq_set_block_pc() that sets the command type to
    REQ_TYPE_BLOCK_PC, and properly initializes the members associated
    with this type of request. Update callers to use this function instead
    of manipulating rq->cmd_type directly.
    
    Includes fixes from Christoph Hellwig <hch@lst.de> for my half-assed
    attempt.
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a0c95cac91f0..c3c1697b143e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -195,6 +195,7 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	req = blk_get_request(sdev->request_queue, write, __GFP_WAIT);
 	if (!req)
 		return ret;
+	blk_rq_set_block_pc(req);
 
 	if (bufflen &&	blk_rq_map_kern(sdev->request_queue, req,
 					buffer, bufflen, __GFP_WAIT))
@@ -206,7 +207,6 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	req->sense_len = 0;
 	req->retries = retries;
 	req->timeout = timeout;
-	req->cmd_type = REQ_TYPE_BLOCK_PC;
 	req->cmd_flags |= flags | REQ_QUIET | REQ_PREEMPT;
 
 	/*

commit 681a2895486243a82547d8c9f53043eb54b53da0
Merge: 6c52486dedbb ed851860b455
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jun 2 09:29:34 2014 -0700

    Merge branch 'for-3.16/core' of git://git.kernel.dk/linux-block into next
    
    Pull block core updates from Jens Axboe:
     "It's a big(ish) round this time, lots of development effort has gone
      into blk-mq in the last 3 months.  Generally we're heading to where
      3.16 will be a feature complete and performant blk-mq.  scsi-mq is
      progressing nicely and will hopefully be in 3.17.  A nvme port is in
      progress, and the Micron pci-e flash driver, mtip32xx, is converted
      and will be sent in with the driver pull request for 3.16.
    
      This pull request contains:
    
       - Lots of prep and support patches for scsi-mq have been integrated.
         All from Christoph.
    
       - API and code cleanups for blk-mq from Christoph.
    
       - Lots of good corner case and error handling cleanup fixes for
         blk-mq from Ming Lei.
    
       - A flew of blk-mq updates from me:
    
         * Provide strict mappings so that the driver can rely on the CPU
           to queue mapping.  This enables optimizations in the driver.
    
         * Provided a bitmap tagging instead of percpu_ida, which never
           really worked well for blk-mq.  percpu_ida relies on the fact
           that we have a lot more tags available than we really need, it
           fails miserably for cases where we exhaust (or are close to
           exhausting) the tag space.
    
         * Provide sane support for shared tag maps, as utilized by scsi-mq
    
         * Various fixes for IO timeouts.
    
         * API cleanups, and lots of perf tweaks and optimizations.
    
       - Remove 'buffer' from struct request.  This is ancient code, from
         when requests were always virtually mapped.  Kill it, to reclaim
         some space in struct request.  From me.
    
       - Remove 'magic' from blk_plug.  Since we store these on the stack
         and since we've never caught any actual bugs with this, lets just
         get rid of it.  From me.
    
       - Only call part_in_flight() once for IO completion, as includes two
         atomic reads.  Hopefully we'll get a better implementation soon, as
         the part IO stats are now one of the more expensive parts of doing
         IO on blk-mq.  From me.
    
       - File migration of block code from {mm,fs}/ to block/.  This
         includes bio.c, bio-integrity.c, bounce.c, and ioprio.c.  From me,
         from a discussion on lkml.
    
      That should describe the meat of the pull request.  Also has various
      little fixes and cleanups from Dave Jones, Shaohua Li, Duan Jiong,
      Fengguang Wu, Fabian Frederick, Randy Dunlap, Robert Elliott, and Sam
      Bradshaw"
    
    * 'for-3.16/core' of git://git.kernel.dk/linux-block: (100 commits)
      blk-mq: push IPI or local end_io decision to __blk_mq_complete_request()
      blk-mq: remember to start timeout handler for direct queue
      block: ensure that the timer is always added
      blk-mq: blk_mq_unregister_hctx() can be static
      blk-mq: make the sysfs mq/ layout reflect current mappings
      blk-mq: blk_mq_tag_to_rq should handle flush request
      block: remove dead code in scsi_ioctl:blk_verify_command
      blk-mq: request initialization optimizations
      block: add queue flag for disabling SG merging
      block: remove 'magic' from struct blk_plug
      blk-mq: remove alloc_hctx and free_hctx methods
      blk-mq: add file comments and update copyright notices
      blk-mq: remove blk_mq_alloc_request_pinned
      blk-mq: do not use blk_mq_alloc_request_pinned in blk_mq_map_request
      blk-mq: remove blk_mq_wait_for_tags
      blk-mq: initialize request in __blk_mq_alloc_request
      blk-mq: merge blk_mq_alloc_reserved_request into blk_mq_alloc_request
      blk-mq: add helper to insert requests from irq context
      blk-mq: remove stale comment for blk_mq_complete_request()
      blk-mq: allow non-softirq completions
      ...

commit a1b73fc194e73ed33c8b77bf09374cb05b58151b
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu May 1 16:51:04 2014 +0200

    scsi: reintroduce scsi_driver.init_command
    
    Instead of letting the ULD play games with the prep_fn move back to
    the model of a central prep_fn with a callback to the ULD.  This
    already cleans up and shortens the code by itself, and will be required
    to properly support blk-mq in the SCSI midlayer.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Nicholas Bellinger <nab@linux-iscsi.org>
    Reviewed-by: Mike Christie <michaelc@cs.wisc.edu>
    Reviewed-by: Hannes Reinecke <hare@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 045822befad9..9f841df6add8 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1073,15 +1073,7 @@ static struct scsi_cmnd *scsi_get_cmd_from_req(struct scsi_device *sdev,
 
 int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 {
-	struct scsi_cmnd *cmd;
-	int ret = scsi_prep_state_check(sdev, req);
-
-	if (ret != BLKPREP_OK)
-		return ret;
-
-	cmd = scsi_get_cmd_from_req(sdev, req);
-	if (unlikely(!cmd))
-		return BLKPREP_DEFER;
+	struct scsi_cmnd *cmd = req->special;
 
 	/*
 	 * BLOCK_PC requests may transfer data, in which case they must
@@ -1125,15 +1117,11 @@ EXPORT_SYMBOL(scsi_setup_blk_pc_cmnd);
  */
 int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
 {
-	struct scsi_cmnd *cmd;
-	int ret = scsi_prep_state_check(sdev, req);
-
-	if (ret != BLKPREP_OK)
-		return ret;
+	struct scsi_cmnd *cmd = req->special;
 
 	if (unlikely(sdev->scsi_dh_data && sdev->scsi_dh_data->scsi_dh
 			 && sdev->scsi_dh_data->scsi_dh->prep_fn)) {
-		ret = sdev->scsi_dh_data->scsi_dh->prep_fn(sdev, req);
+		int ret = sdev->scsi_dh_data->scsi_dh->prep_fn(sdev, req);
 		if (ret != BLKPREP_OK)
 			return ret;
 	}
@@ -1143,16 +1131,13 @@ int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
 	 */
 	BUG_ON(!req->nr_phys_segments);
 
-	cmd = scsi_get_cmd_from_req(sdev, req);
-	if (unlikely(!cmd))
-		return BLKPREP_DEFER;
-
 	memset(cmd->cmnd, 0, BLK_MAX_CDB);
 	return scsi_init_io(cmd, GFP_ATOMIC);
 }
 EXPORT_SYMBOL(scsi_setup_fs_cmnd);
 
-int scsi_prep_state_check(struct scsi_device *sdev, struct request *req)
+static int
+scsi_prep_state_check(struct scsi_device *sdev, struct request *req)
 {
 	int ret = BLKPREP_OK;
 
@@ -1204,9 +1189,9 @@ int scsi_prep_state_check(struct scsi_device *sdev, struct request *req)
 	}
 	return ret;
 }
-EXPORT_SYMBOL(scsi_prep_state_check);
 
-int scsi_prep_return(struct request_queue *q, struct request *req, int ret)
+static int
+scsi_prep_return(struct request_queue *q, struct request *req, int ret)
 {
 	struct scsi_device *sdev = q->queuedata;
 
@@ -1237,18 +1222,44 @@ int scsi_prep_return(struct request_queue *q, struct request *req, int ret)
 
 	return ret;
 }
-EXPORT_SYMBOL(scsi_prep_return);
 
-int scsi_prep_fn(struct request_queue *q, struct request *req)
+static int scsi_prep_fn(struct request_queue *q, struct request *req)
 {
 	struct scsi_device *sdev = q->queuedata;
-	int ret = BLKPREP_KILL;
+	struct scsi_cmnd *cmd;
+	int ret;
 
-	if (req->cmd_type == REQ_TYPE_BLOCK_PC)
+	ret = scsi_prep_state_check(sdev, req);
+	if (ret != BLKPREP_OK)
+		goto out;
+
+	cmd = scsi_get_cmd_from_req(sdev, req);
+	if (unlikely(!cmd)) {
+		ret = BLKPREP_DEFER;
+		goto out;
+	}
+
+	if (req->cmd_type == REQ_TYPE_FS)
+		ret = scsi_cmd_to_driver(cmd)->init_command(cmd);
+	else if (req->cmd_type == REQ_TYPE_BLOCK_PC)
 		ret = scsi_setup_blk_pc_cmnd(sdev, req);
+	else
+		ret = BLKPREP_KILL;
+
+out:
 	return scsi_prep_return(q, req, ret);
 }
-EXPORT_SYMBOL(scsi_prep_fn);
+
+static void scsi_unprep_fn(struct request_queue *q, struct request *req)
+{
+	if (req->cmd_type == REQ_TYPE_FS) {
+		struct scsi_cmnd *cmd = req->special;
+		struct scsi_driver *drv = scsi_cmd_to_driver(cmd);
+
+		if (drv->uninit_command)
+			drv->uninit_command(cmd);
+	}
+}
 
 /*
  * scsi_dev_queue_ready: if we can send requests to sdev, return 1 else
@@ -1669,6 +1680,7 @@ struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
 		return NULL;
 
 	blk_queue_prep_rq(q, scsi_prep_fn);
+	blk_queue_unprep_rq(q, scsi_unprep_fn);
 	blk_queue_softirq_done(q, scsi_softirq_done);
 	blk_queue_rq_timed_out(q, scsi_times_out);
 	blk_queue_lld_busy(q, scsi_lld_busy);

commit bc85dc500f9df9b2eec15077e5046672c46adeaa
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu May 1 16:51:03 2014 +0200

    scsi: remove scsi_end_request
    
    By folding scsi_end_request into its only caller we can significantly clean
    up the completion logic.  We can use simple goto labels now to only have
    a single place to finish or requeue command there instead of the previous
    convoluted logic.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Nicholas Bellinger <nab@linux-iscsi.org>
    Reviewed-by: Mike Christie <michaelc@cs.wisc.edu>
    Reviewed-by: Hannes Reinecke <hare@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f416b5932a45..045822befad9 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -512,66 +512,6 @@ void scsi_run_host_queues(struct Scsi_Host *shost)
 		scsi_run_queue(sdev->request_queue);
 }
 
-/*
- * Function:    scsi_end_request()
- *
- * Purpose:     Post-processing of completed commands (usually invoked at end
- *		of upper level post-processing and scsi_io_completion).
- *
- * Arguments:   cmd	 - command that is complete.
- *              error    - 0 if I/O indicates success, < 0 for I/O error.
- *              bytes    - number of bytes of completed I/O
- *		requeue  - indicates whether we should requeue leftovers.
- *
- * Lock status: Assumed that lock is not held upon entry.
- *
- * Returns:     cmd if requeue required, NULL otherwise.
- *
- * Notes:       This is called for block device requests in order to
- *              mark some number of sectors as complete.
- * 
- *		We are guaranteeing that the request queue will be goosed
- *		at some point during this call.
- * Notes:	If cmd was requeued, upon return it will be a stale pointer.
- */
-static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int error,
-					  int bytes, int requeue)
-{
-	struct request_queue *q = cmd->device->request_queue;
-	struct request *req = cmd->request;
-
-	/*
-	 * If there are blocks left over at the end, set up the command
-	 * to queue the remainder of them.
-	 */
-	if (blk_end_request(req, error, bytes)) {
-		/* kill remainder if no retrys */
-		if (error && scsi_noretry_cmd(cmd))
-			blk_end_request_all(req, error);
-		else {
-			if (requeue) {
-				/*
-				 * Bleah.  Leftovers again.  Stick the
-				 * leftovers in the front of the
-				 * queue, and goose the queue again.
-				 */
-				scsi_release_buffers(cmd);
-				scsi_requeue_command(q, cmd);
-				cmd = NULL;
-			}
-			return cmd;
-		}
-	}
-
-	/*
-	 * This will goose the queue request function at the end, so we don't
-	 * need to worry about launching another command.
-	 */
-	scsi_release_buffers(cmd);
-	scsi_next_command(cmd);
-	return NULL;
-}
-
 static inline unsigned int scsi_sgtable_index(unsigned short nents)
 {
 	unsigned int index;
@@ -717,16 +657,9 @@ static int __scsi_error_from_host_byte(struct scsi_cmnd *cmd, int result)
  *
  * Returns:     Nothing
  *
- * Notes:       This function is matched in terms of capabilities to
- *              the function that created the scatter-gather list.
- *              In other words, if there are no bounce buffers
- *              (the normal case for most drivers), we don't need
- *              the logic to deal with cleaning up afterwards.
- *
- *		We must call scsi_end_request().  This will finish off
- *		the specified number of sectors.  If we are done, the
- *		command block will be released and the queue function
- *		will be goosed.  If we are not done then we have to
+ * Notes:       We will finish off the specified number of sectors.  If we
+ *		are done, the command block will be released and the queue
+ *		function will be goosed.  If we are not done then we have to
  *		figure out what to do next:
  *
  *		a) We can call scsi_requeue_command().  The request
@@ -735,7 +668,7 @@ static int __scsi_error_from_host_byte(struct scsi_cmnd *cmd, int result)
  *		   be used if we made forward progress, or if we want
  *		   to switch from READ(10) to READ(6) for example.
  *
- *		b) We can call scsi_queue_insert().  The request will
+ *		b) We can call __scsi_queue_insert().  The request will
  *		   be put back on the queue and retried using the same
  *		   command as before, possibly after a delay.
  *
@@ -794,6 +727,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 
 			scsi_release_buffers(cmd);
 			scsi_release_bidi_buffers(cmd);
+
 			blk_end_request_all(req, 0);
 
 			scsi_next_command(cmd);
@@ -833,12 +767,25 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	}
 
 	/*
-	 * A number of bytes were successfully read.  If there
-	 * are leftovers and there is some kind of error
-	 * (result != 0), retry the rest.
+	 * If we finished all bytes in the request we are done now.
 	 */
-	if (scsi_end_request(cmd, error, good_bytes, result == 0) == NULL)
-		return;
+	if (!blk_end_request(req, error, good_bytes))
+		goto next_command;
+
+	/*
+	 * Kill remainder if no retrys.
+	 */
+	if (error && scsi_noretry_cmd(cmd)) {
+		blk_end_request_all(req, error);
+		goto next_command;
+	}
+
+	/*
+	 * If there had been no error, but we have leftover bytes in the
+	 * requeues just queue the command up again.
+	 */
+	if (result == 0)
+		goto requeue;
 
 	error = __scsi_error_from_host_byte(cmd, result);
 
@@ -966,7 +913,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	switch (action) {
 	case ACTION_FAIL:
 		/* Give up and fail the remainder of the request */
-		scsi_release_buffers(cmd);
 		if (!(req->cmd_flags & REQ_QUIET)) {
 			if (description)
 				scmd_printk(KERN_INFO, cmd, "%s\n",
@@ -976,12 +922,11 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				scsi_print_sense("", cmd);
 			scsi_print_command(cmd);
 		}
-		if (blk_end_request_err(req, error))
-			scsi_requeue_command(q, cmd);
-		else
-			scsi_next_command(cmd);
-		break;
+		if (!blk_end_request_err(req, error))
+			goto next_command;
+		/*FALLTHRU*/
 	case ACTION_REPREP:
+	requeue:
 		/* Unprep the request and put it back at the head of the queue.
 		 * A new command will be prepared and issued.
 		 */
@@ -997,6 +942,11 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		__scsi_queue_insert(cmd, SCSI_MLQUEUE_DEVICE_BUSY, 0);
 		break;
 	}
+	return;
+
+next_command:
+	scsi_release_buffers(cmd);
+	scsi_next_command(cmd);
 }
 
 static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb,

commit c682adf3e1176095a665716a0b62fead8f4b8f5c
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu May 1 16:51:02 2014 +0200

    scsi: explicitly release bidi buffers
    
    Instead of trying to guess when we have a BIDI buffer in scsi_release_buffers
    add a function to explicitly free the BIDI ressoures in the one place that
    handles them.  This avoids needing a special __scsi_release_buffers for the
    case where we already have freed the request as well.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Mike Christie <michaelc@cs.wisc.edu>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9db097a28a74..f416b5932a45 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -512,8 +512,6 @@ void scsi_run_host_queues(struct Scsi_Host *shost)
 		scsi_run_queue(sdev->request_queue);
 }
 
-static void __scsi_release_buffers(struct scsi_cmnd *, int);
-
 /*
  * Function:    scsi_end_request()
  *
@@ -569,7 +567,7 @@ static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int error,
 	 * This will goose the queue request function at the end, so we don't
 	 * need to worry about launching another command.
 	 */
-	__scsi_release_buffers(cmd, 0);
+	scsi_release_buffers(cmd);
 	scsi_next_command(cmd);
 	return NULL;
 }
@@ -625,30 +623,10 @@ static void scsi_free_sgtable(struct scsi_data_buffer *sdb)
 	__sg_free_table(&sdb->table, SCSI_MAX_SG_SEGMENTS, scsi_sg_free);
 }
 
-static void __scsi_release_buffers(struct scsi_cmnd *cmd, int do_bidi_check)
-{
-
-	if (cmd->sdb.table.nents)
-		scsi_free_sgtable(&cmd->sdb);
-
-	memset(&cmd->sdb, 0, sizeof(cmd->sdb));
-
-	if (do_bidi_check && scsi_bidi_cmnd(cmd)) {
-		struct scsi_data_buffer *bidi_sdb =
-			cmd->request->next_rq->special;
-		scsi_free_sgtable(bidi_sdb);
-		kmem_cache_free(scsi_sdb_cache, bidi_sdb);
-		cmd->request->next_rq->special = NULL;
-	}
-
-	if (scsi_prot_sg_count(cmd))
-		scsi_free_sgtable(cmd->prot_sdb);
-}
-
 /*
  * Function:    scsi_release_buffers()
  *
- * Purpose:     Completion processing for block device I/O requests.
+ * Purpose:     Free resources allocate for a scsi_command.
  *
  * Arguments:   cmd	- command that we are bailing.
  *
@@ -659,15 +637,29 @@ static void __scsi_release_buffers(struct scsi_cmnd *cmd, int do_bidi_check)
  * Notes:       In the event that an upper level driver rejects a
  *		command, we must release resources allocated during
  *		the __init_io() function.  Primarily this would involve
- *		the scatter-gather table, and potentially any bounce
- *		buffers.
+ *		the scatter-gather table.
  */
 void scsi_release_buffers(struct scsi_cmnd *cmd)
 {
-	__scsi_release_buffers(cmd, 1);
+	if (cmd->sdb.table.nents)
+		scsi_free_sgtable(&cmd->sdb);
+
+	memset(&cmd->sdb, 0, sizeof(cmd->sdb));
+
+	if (scsi_prot_sg_count(cmd))
+		scsi_free_sgtable(cmd->prot_sdb);
 }
 EXPORT_SYMBOL(scsi_release_buffers);
 
+static void scsi_release_bidi_buffers(struct scsi_cmnd *cmd)
+{
+	struct scsi_data_buffer *bidi_sdb = cmd->request->next_rq->special;
+
+	scsi_free_sgtable(bidi_sdb);
+	kmem_cache_free(scsi_sdb_cache, bidi_sdb);
+	cmd->request->next_rq->special = NULL;
+}
+
 /**
  * __scsi_error_from_host_byte - translate SCSI error code into errno
  * @cmd:	SCSI command (unused)
@@ -801,6 +793,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			req->next_rq->resid_len = scsi_in(cmd)->resid;
 
 			scsi_release_buffers(cmd);
+			scsi_release_bidi_buffers(cmd);
 			blk_end_request_all(req, 0);
 
 			scsi_next_command(cmd);

commit 644373a4219add42123df69c8b7ce6a918475ccd
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Fri Mar 28 10:51:15 2014 -0700

    [SCSI] Fix command result state propagation
    
    We're seeing a case where the contents of scmd->result isn't being reset after
    a SCSI command encounters an error, is resubmitted, times out and then gets
    handled.  The error handler acts on the stale result of the previous error
    instead of the timeout.  Fix this by properly zeroing the scmd->status before
    the command is resubmitted.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 7fa54fe51f63..9db097a28a74 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -137,6 +137,7 @@ static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
 	 * lock such that the kblockd_schedule_work() call happens
 	 * before blk_cleanup_queue() finishes.
 	 */
+	cmd->result = 0;
 	spin_lock_irqsave(q->queue_lock, flags);
 	blk_requeue_request(q, cmd->request);
 	kblockd_schedule_work(q, &device->requeue_work);

commit 68c03d9193f55dad93036f439b94912c5003a173
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Apr 15 12:24:56 2014 +0200

    [SCSI] don't reference freed command in scsi_prep_return
    
    Patch
    
    commit 0479633686d370303e3430256ace4bd5f7f138dc
    Author: Christoph Hellwig <hch@infradead.org>
    Date:   Thu Feb 20 14:20:55 2014 -0800
    
        [SCSI] do not manipulate device reference counts in scsi_get/put_command
    
    Introduced a use after free:I in the kill case of scsi_prep_return we have to
    release our device reference, but we do this trying to reference the just
    freed command.  Use the local sdev pointer instead.
    
    Fixes: 0479633686d370303e3430256ace4bd5f7f138dc
    Reported-by: Joe Lawrence <joe.lawrence@stratus.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 54eff6a79fb8..7fa54fe51f63 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1274,7 +1274,7 @@ int scsi_prep_return(struct request_queue *q, struct request *req, int ret)
 			struct scsi_cmnd *cmd = req->special;
 			scsi_release_buffers(cmd);
 			scsi_put_command(cmd);
-			put_device(&cmd->device->sdev_gendev);
+			put_device(&sdev->sdev_gendev);
 			req->special = NULL;
 		}
 		break;

commit 5e012aad85f2ee31d7de5c21d63ccd2702d63db2
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Apr 15 12:24:55 2014 +0200

    [SCSI] don't reference freed command in scsi_init_sgtable
    
    Patch
    
    commit 0479633686d370303e3430256ace4bd5f7f138dc
    Author: Christoph Hellwig <hch@infradead.org>
    Date:   Thu Feb 20 14:20:55 2014 -0800
    
        [SCSI] do not manipulate device reference counts in scsi_get/put_command
    
    Introduced a use after free: when scsi_init_io fails we have to release our
    device reference, but we do this trying to reference the just freed command.
    Add a local scsi_device pointer to fix this.
    
    Fixes: 0479633686d370303e3430256ace4bd5f7f138dc
    Reported-by: Sander Eikelenboom <linux@eikelenboom.it>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 65a123d9c676..54eff6a79fb8 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1044,6 +1044,7 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb,
  */
 int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 {
+	struct scsi_device *sdev = cmd->device;
 	struct request *rq = cmd->request;
 
 	int error = scsi_init_sgtable(rq, &cmd->sdb, gfp_mask);
@@ -1091,7 +1092,7 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 	scsi_release_buffers(cmd);
 	cmd->request->special = NULL;
 	scsi_put_command(cmd);
-	put_device(&cmd->device->sdev_gendev);
+	put_device(&sdev->sdev_gendev);
 	return error;
 }
 EXPORT_SYMBOL(scsi_init_io);

commit b4f42e2831ff9b9fa19252265d7c8985d47eefb9
Author: Jens Axboe <axboe@fb.com>
Date:   Thu Apr 10 09:46:28 2014 -0600

    block: remove struct request buffer member
    
    This was used in the olden days, back when onions were proper
    yellow. Basically it mapped to the current buffer to be
    transferred. With highmem being added more than a decade ago,
    most drivers map pages out of a bio, and rq->buffer isn't
    pointing at anything valid.
    
    Convert old style drivers to just use bio_data().
    
    For the discard payload use case, just reference the page
    in the bio.
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0f3bddcb6b1a..3cc82d3dec78 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1018,8 +1018,6 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb,
 		return BLKPREP_DEFER;
 	}
 
-	req->buffer = NULL;
-
 	/* 
 	 * Next, walk the list, and fill in the addresses and sizes of
 	 * each segment.
@@ -1156,7 +1154,6 @@ int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 		BUG_ON(blk_rq_bytes(req));
 
 		memset(&cmd->sdb, 0, sizeof(cmd->sdb));
-		req->buffer = NULL;
 	}
 
 	cmd->cmd_len = req->cmd_len;

commit f89e0dd9d1a72fdf6b8958bcadfa6abf84f3cae0
Merge: 21f9fcd81593 c9eaa447e77e
Author: Jens Axboe <axboe@fb.com>
Date:   Tue Apr 15 14:02:24 2014 -0600

    Merge tag 'v3.15-rc1' into for-3.16/core
    
    We don't like this, but things have diverged with the blk-mq fixes
    in 3.15-rc1. So merge it in.

commit 2bfad21ecc6f837de29743f4419f47dee3fac9e2
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Wed Apr 9 22:20:48 2014 -0400

    scsi: Make sure cmd_flags are 64-bit
    
    cmd_flags in struct request is now 64 bits wide but the scsi_execute
    functions truncated arguments passed to int leading to errors. Make sure
    the flags parameters are u64.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Cc: Jens Axboe <axboe@fb.com>
    CC: Jan Kara <jack@suse.cz>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 5681c05ac506..65a123d9c676 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -184,7 +184,7 @@ void scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
  */
 int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 		 int data_direction, void *buffer, unsigned bufflen,
-		 unsigned char *sense, int timeout, int retries, int flags,
+		 unsigned char *sense, int timeout, int retries, u64 flags,
 		 int *resid)
 {
 	struct request *req;
@@ -235,7 +235,7 @@ EXPORT_SYMBOL(scsi_execute);
 int scsi_execute_req_flags(struct scsi_device *sdev, const unsigned char *cmd,
 		     int data_direction, void *buffer, unsigned bufflen,
 		     struct scsi_sense_hdr *sshdr, int timeout, int retries,
-		     int *resid, int flags)
+		     int *resid, u64 flags)
 {
 	char *sense = NULL;
 	int result;

commit 59c3d45e487315e6e05a3f2310b61109f8e503e7
Author: Jens Axboe <axboe@fb.com>
Date:   Tue Apr 8 09:15:35 2014 -0600

    block: remove 'q' parameter from kblockd_schedule_*_work()
    
    The queue parameter is never used, just get rid of it.
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 5681c05ac506..91f99f4ce2e8 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -139,7 +139,7 @@ static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
 	 */
 	spin_lock_irqsave(q->queue_lock, flags);
 	blk_requeue_request(q, cmd->request);
-	kblockd_schedule_work(q, &device->requeue_work);
+	kblockd_schedule_work(&device->requeue_work);
 	spin_unlock_irqrestore(q->queue_lock, flags);
 }
 

commit 134997a041f70d4aa5434d2833c8a3cf33697899
Author: Christoph Hellwig <hch@infradead.org>
Date:   Thu Feb 20 14:20:58 2014 -0800

    [SCSI] remove a useless get/put_device pair in scsi_requeue_command
    
    Avoid a spurious device get/put pair by cleaning up scsi_requeue_command
    and folding scsi_unprep_request into it.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index eba8044d0b11..5681c05ac506 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -75,29 +75,6 @@ struct kmem_cache *scsi_sdb_cache;
  */
 #define SCSI_QUEUE_DELAY	3
 
-/*
- * Function:	scsi_unprep_request()
- *
- * Purpose:	Remove all preparation done for a request, including its
- *		associated scsi_cmnd, so that it can be requeued.
- *
- * Arguments:	req	- request to unprepare
- *
- * Lock status:	Assumed that no locks are held upon entry.
- *
- * Returns:	Nothing.
- */
-static void scsi_unprep_request(struct request *req)
-{
-	struct scsi_cmnd *cmd = req->special;
-
-	blk_unprep_request(req);
-	req->special = NULL;
-
-	scsi_put_command(cmd);
-	put_device(&cmd->device->sdev_gendev);
-}
-
 /**
  * __scsi_queue_insert - private queue insertion
  * @cmd: The SCSI command being requeued
@@ -503,16 +480,10 @@ static void scsi_requeue_command(struct request_queue *q, struct scsi_cmnd *cmd)
 	struct request *req = cmd->request;
 	unsigned long flags;
 
-	/*
-	 * We need to hold a reference on the device to avoid the queue being
-	 * killed after the unlock and before scsi_run_queue is invoked which
-	 * may happen because scsi_unprep_request() puts the command which
-	 * releases its reference on the device.
-	 */
-	get_device(&sdev->sdev_gendev);
-
 	spin_lock_irqsave(q->queue_lock, flags);
-	scsi_unprep_request(req);
+	blk_unprep_request(req);
+	req->special = NULL;
+	scsi_put_command(cmd);
 	blk_requeue_request(q, req);
 	spin_unlock_irqrestore(q->queue_lock, flags);
 

commit 27e9e0f12acb5a76c72c3eed31ad3336e1970717
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Thu Feb 20 14:20:57 2014 -0800

    [SCSI] remove a useless get/put_device pair in scsi_next_command
    
    Eliminate a get_device() / put_device() pair from scsi_next_command().
    Both are atomic operations hence removing these slightly improves
    performance.
    
    [hch: slight changes due to different context]
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f8a8765a7979..eba8044d0b11 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -526,14 +526,9 @@ void scsi_next_command(struct scsi_cmnd *cmd)
 	struct scsi_device *sdev = cmd->device;
 	struct request_queue *q = sdev->request_queue;
 
-	/* need to hold a reference on the device before we let go of the cmd */
-	get_device(&sdev->sdev_gendev);
-
 	scsi_put_command(cmd);
-	put_device(&sdev->sdev_gendev);
 	scsi_run_queue(q);
 
-	/* ok to remove device now */
 	put_device(&sdev->sdev_gendev);
 }
 

commit 613be1f626e602c6744101a003e8fc5c180e1af9
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Thu Feb 20 14:20:56 2014 -0800

    [SCSI] remove a useless get/put_device pair in scsi_request_fn
    
    SCSI devices may only be removed by calling scsi_remove_device().
    That function must invoke blk_cleanup_queue() before the final put
    of sdev->sdev_gendev. Since blk_cleanup_queue() waits for the
    block queue to drain and then tears it down, scsi_request_fn cannot
    be active anymore after blk_cleanup_queue() has returned and hence
    the get_device()/put_device() pair in scsi_request_fn is unnecessary.
    
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 007e979fa437..f8a8765a7979 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1565,16 +1565,14 @@ static void scsi_softirq_done(struct request *rq)
  * Lock status: IO request lock assumed to be held when called.
  */
 static void scsi_request_fn(struct request_queue *q)
+	__releases(q->queue_lock)
+	__acquires(q->queue_lock)
 {
 	struct scsi_device *sdev = q->queuedata;
 	struct Scsi_Host *shost;
 	struct scsi_cmnd *cmd;
 	struct request *req;
 
-	if(!get_device(&sdev->sdev_gendev))
-		/* We must be tearing the block queue down already */
-		return;
-
 	/*
 	 * To start with, we keep looping until the queue is empty, or until
 	 * the host is no longer able to accept any more requests.
@@ -1663,7 +1661,7 @@ static void scsi_request_fn(struct request_queue *q)
 			goto out_delay;
 	}
 
-	goto out;
+	return;
 
  not_ready:
 	spin_unlock_irq(shost->host_lock);
@@ -1682,12 +1680,6 @@ static void scsi_request_fn(struct request_queue *q)
 out_delay:
 	if (sdev->device_busy == 0)
 		blk_delay_queue(q, SCSI_QUEUE_DELAY);
-out:
-	/* must be careful here...if we trigger the ->remove() function
-	 * we cannot be holding the q lock */
-	spin_unlock_irq(q->queue_lock);
-	put_device(&sdev->sdev_gendev);
-	spin_lock_irq(q->queue_lock);
 }
 
 u64 scsi_calculate_bounce_limit(struct Scsi_Host *shost)

commit 0479633686d370303e3430256ace4bd5f7f138dc
Author: Christoph Hellwig <hch@infradead.org>
Date:   Thu Feb 20 14:20:55 2014 -0800

    [SCSI] do not manipulate device reference counts in scsi_get/put_command
    
    Many callers won't need this and we can optimize them away.  In addition
    the handling in the __-prefixed variants was inconsistant to start with.
    
    Based on an earlier patch from Bart Van Assche.
    
    [jejb: fix kerneldoc probelm picked up by Fengguang Wu]
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 492071ca45d1..007e979fa437 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -95,6 +95,7 @@ static void scsi_unprep_request(struct request *req)
 	req->special = NULL;
 
 	scsi_put_command(cmd);
+	put_device(&cmd->device->sdev_gendev);
 }
 
 /**
@@ -529,6 +530,7 @@ void scsi_next_command(struct scsi_cmnd *cmd)
 	get_device(&sdev->sdev_gendev);
 
 	scsi_put_command(cmd);
+	put_device(&sdev->sdev_gendev);
 	scsi_run_queue(q);
 
 	/* ok to remove device now */
@@ -1123,6 +1125,7 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 	scsi_release_buffers(cmd);
 	cmd->request->special = NULL;
 	scsi_put_command(cmd);
+	put_device(&cmd->device->sdev_gendev);
 	return error;
 }
 EXPORT_SYMBOL(scsi_init_io);
@@ -1133,9 +1136,15 @@ static struct scsi_cmnd *scsi_get_cmd_from_req(struct scsi_device *sdev,
 	struct scsi_cmnd *cmd;
 
 	if (!req->special) {
+		/* Bail if we can't get a reference to the device */
+		if (!get_device(&sdev->sdev_gendev))
+			return NULL;
+
 		cmd = scsi_get_command(sdev, GFP_ATOMIC);
-		if (unlikely(!cmd))
+		if (unlikely(!cmd)) {
+			put_device(&sdev->sdev_gendev);
 			return NULL;
+		}
 		req->special = cmd;
 	} else {
 		cmd = req->special;
@@ -1298,6 +1307,7 @@ int scsi_prep_return(struct request_queue *q, struct request *req, int ret)
 			struct scsi_cmnd *cmd = req->special;
 			scsi_release_buffers(cmd);
 			scsi_put_command(cmd);
+			put_device(&cmd->device->sdev_gendev);
 			req->special = NULL;
 		}
 		break;

commit 21a05df547dd0ac532d3a89e241dc504018eb881
Author: Christoph Hellwig <hch@infradead.org>
Date:   Thu Feb 20 14:20:54 2014 -0800

    [SCSI] avoid taking host_lock in scsi_run_queue unless nessecary
    
    If we don't have starved devices we don't need to take the host lock
    to iterate over them.  Also split the function up to be more clear.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f97a1a609ad0..492071ca45d1 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -385,29 +385,12 @@ static inline int scsi_host_is_busy(struct Scsi_Host *shost)
 	return 0;
 }
 
-/*
- * Function:	scsi_run_queue()
- *
- * Purpose:	Select a proper request queue to serve next
- *
- * Arguments:	q	- last request's queue
- *
- * Returns:     Nothing
- *
- * Notes:	The previous command was completely finished, start
- *		a new one if possible.
- */
-static void scsi_run_queue(struct request_queue *q)
+static void scsi_starved_list_run(struct Scsi_Host *shost)
 {
-	struct scsi_device *sdev = q->queuedata;
-	struct Scsi_Host *shost;
 	LIST_HEAD(starved_list);
+	struct scsi_device *sdev;
 	unsigned long flags;
 
-	shost = sdev->host;
-	if (scsi_target(sdev)->single_lun)
-		scsi_single_lun_run(sdev);
-
 	spin_lock_irqsave(shost->host_lock, flags);
 	list_splice_init(&shost->starved_list, &starved_list);
 
@@ -459,6 +442,28 @@ static void scsi_run_queue(struct request_queue *q)
 	/* put any unprocessed entries back */
 	list_splice(&starved_list, &shost->starved_list);
 	spin_unlock_irqrestore(shost->host_lock, flags);
+}
+
+/*
+ * Function:   scsi_run_queue()
+ *
+ * Purpose:    Select a proper request queue to serve next
+ *
+ * Arguments:  q       - last request's queue
+ *
+ * Returns:     Nothing
+ *
+ * Notes:      The previous command was completely finished, start
+ *             a new one if possible.
+ */
+static void scsi_run_queue(struct request_queue *q)
+{
+	struct scsi_device *sdev = q->queuedata;
+
+	if (scsi_target(sdev)->single_lun)
+		scsi_single_lun_run(sdev);
+	if (!list_empty(&sdev->host->starved_list))
+		scsi_starved_list_run(sdev->host);
 
 	blk_run_queue(q);
 }

commit ee60b2c52ec8ecdcbcd2f85cc117b525f649441f
Author: Eiichi Tsukata <eiichi.tsukata.xh@hitachi.com>
Date:   Tue Feb 11 14:29:52 2014 +0900

    [SCSI] Add timeout to avoid infinite command retry
    
    Currently, scsi error handling in scsi_io_completion() tries to
    unconditionally requeue scsi command when device keeps some error state.
    For example, UNIT_ATTENTION causes infinite retry with
    action == ACTION_RETRY.
    This is because retryable errors are thought to be temporary and the scsi
    device will soon recover from those errors. Normally, such retry policy is
    appropriate because the device will soon recover from temporary error state.
    
    But there is no guarantee that device is able to recover from error state
    immediately. Some hardware error can prevent device from recovering.
    
    This patch adds timeout in scsi_io_completion() to avoid infinite command
    retry in scsi_io_completion(). Once scsi command retry time is longer than
    this timeout, the command is treated as failure.
    
    Signed-off-by: Eiichi Tsukata <eiichi.tsukata.xh@hitachi.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 62ec84b42e31..f97a1a609ad0 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -788,6 +788,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	enum {ACTION_FAIL, ACTION_REPREP, ACTION_RETRY,
 	      ACTION_DELAYED_RETRY} action;
 	char *description = NULL;
+	unsigned long wait_for = (cmd->allowed + 1) * req->timeout;
 
 	if (result) {
 		sense_valid = scsi_command_normalize_sense(cmd, &sshdr);
@@ -989,6 +990,12 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		action = ACTION_FAIL;
 	}
 
+	if (action != ACTION_FAIL &&
+	    time_before(cmd->jiffies_at_alloc + wait_for, jiffies)) {
+		action = ACTION_FAIL;
+		description = "Command timed out";
+	}
+
 	switch (action) {
 	case ACTION_FAIL:
 		/* Give up and fail the remainder of the request */

commit e83b366487b5582274374f8226e489cb214ae5a6
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Tue Feb 11 17:11:04 2014 +0000

    Fix uses of dma_max_pfn() when converting to a limiting address
    
    We must use a 64-bit for this, otherwise overflowed bits get lost, and
    that can result in a lower than intended value set.
    
    Fixes: 8e0cb8a1f6ac ("ARM: 7797/1: mmc: Use dma_max_pfn(dev) helper for bounce_limit calculations")
    Fixes: 7d35496dd982 ("ARM: 7796/1: scsi: Use dma_max_pfn(dev) helper for bounce_limit calculations")
    Tested-Acked-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 7bd7f0d5f050..62ec84b42e31 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1684,7 +1684,7 @@ u64 scsi_calculate_bounce_limit(struct Scsi_Host *shost)
 
 	host_dev = scsi_get_device(shost);
 	if (host_dev && host_dev->dma_mask)
-		bounce_limit = dma_max_pfn(host_dev) << PAGE_SHIFT;
+		bounce_limit = (u64)dma_max_pfn(host_dev) << PAGE_SHIFT;
 
 	return bounce_limit;
 }

commit 7d35496dd98229cdf923238367fd3b3833fbde52
Author: Santosh Shilimkar <santosh.shilimkar@ti.com>
Date:   Mon Jul 29 14:19:42 2013 +0100

    ARM: 7796/1: scsi: Use dma_max_pfn(dev) helper for bounce_limit calculations
    
    DMA bounce limit is the maximum direct DMA'able memory beyond which
    bounce buffers has to be used to perform dma operations. SCSI driver
    relies on dma_mask but its calculation is based on max_*pfn which
    don't have uniform meaning across architectures. So make use of
    dma_max_pfn() which is expected to return the DMAable maximum pfn
    value across architectures.
    
    Cc: linux-scsi@vger.kernel.org
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d1549b74e2d1..7bd7f0d5f050 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1684,7 +1684,7 @@ u64 scsi_calculate_bounce_limit(struct Scsi_Host *shost)
 
 	host_dev = scsi_get_device(shost);
 	if (host_dev && host_dev->dma_mask)
-		bounce_limit = *host_dev->dma_mask;
+		bounce_limit = dma_max_pfn(host_dev) << PAGE_SHIFT;
 
 	return bounce_limit;
 }

commit 357397a14117f0c2eeafcac06a1f8412a02aa6af
Merge: 9ee52a1633a7 86a565e61bcb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 3 18:19:53 2013 -0700

    Merge branch 'for-3.12' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/libata
    
    Pull libata changes from Tejun Heo:
     "Two interesting changes.
    
       - libata acpi handling has been restructured so that the association
         between ata devices and ACPI handles are less convoluted.  This
         change shouldn't change visible behavior.
    
       - Queued TRIM support, which enables sending TRIM to the device
         without draining in-flight RW commands, is added.  Currently only
         enabled for ahci (and likely to stay that way for the foreseeable
         future).
    
      Other changes are driver-specific updates / fixes"
    
    * 'for-3.12' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/libata:
      libata: bugfix: Remove __le32 in ata_tf_to_fis()
      libata: acpi: Remove ata_dev_acpi_handle stub in libata.h
      libata: Add support for queued DSM TRIM
      libata: Add support for SEND/RECEIVE FPDMA QUEUED
      libata: Add H2D FIS "auxiliary" port flag
      libata: Populate host-to-device FIS "auxiliary" field
      ata: acpi: rework the ata acpi bind support
      sata, highbank: send extra clock cycles in SGPIO patterns
      sata, highbank: set tx_atten override bits
      devicetree: create a separate binding description for sata_highbank
      drivers/ata/sata_rcar.c: simplify use of devm_ioremap_resource
      sata highbank: enable 64-bit DMA mask when using LPAE
      ata: pata_samsung_cf: add missing __iomem annotation
      ata: pata_arasan: Staticize local symbols
      sata_mv: Remove unneeded CONFIG_HAVE_CLK ifdefs
      ata: use dev_get_platdata()
      sata_mv: Remove unneeded forward declaration
      libata: acpi: remove dead code for ata_acpi_(un)bind
      libata: move 'struct ata_taskfile' and friends from ata.h to libata.h

commit 279afdfe78a020b4b1a68bffd0009b961b12982e
Author: Ewan D. Milne <emilne@redhat.com>
Date:   Thu Aug 8 15:07:48 2013 -0400

    [SCSI] Generate uevents on certain unit attention codes
    
    Generate a uevent when the following Unit Attention ASC/ASCQ
    codes are received:
    
        2A/01  MODE PARAMETERS CHANGED
        2A/09  CAPACITY DATA HAS CHANGED
        38/07  THIN PROVISIONING SOFT THRESHOLD REACHED
        3F/03  INQUIRY DATA HAS CHANGED
        3F/0E  REPORTED LUNS DATA HAS CHANGED
    
    Log kernel messages when the following Unit Attention ASC/ASCQ
    codes are received that are not as specific as those above:
    
        2A/xx  PARAMETERS CHANGED
        3F/xx  TARGET OPERATING CONDITIONS HAVE CHANGED
    
    Added logic to set expecting_lun_change for other LUNs on the target
    after REPORTED LUNS DATA HAS CHANGED is received, so that duplicate
    uevents are not generated, and clear expecting_lun_change when a
    REPORT LUNS command completes, in accordance with the SPC-3
    specification regarding reporting of the 3F 0E ASC/ASCQ UA.
    
    [jejb: remove SPC3 test in scsi_report_lun_change and some docbook fixes and
           unused variable fix, both reported by Fengguang Wu]
    Signed-off-by: Ewan D. Milne <emilne@redhat.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 36b5c898db9d..d545931c85eb 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2253,7 +2253,21 @@ static void scsi_evt_emit(struct scsi_device *sdev, struct scsi_event *evt)
 	case SDEV_EVT_MEDIA_CHANGE:
 		envp[idx++] = "SDEV_MEDIA_CHANGE=1";
 		break;
-
+	case SDEV_EVT_INQUIRY_CHANGE_REPORTED:
+		envp[idx++] = "SDEV_UA=INQUIRY_DATA_HAS_CHANGED";
+		break;
+	case SDEV_EVT_CAPACITY_CHANGE_REPORTED:
+		envp[idx++] = "SDEV_UA=CAPACITY_DATA_HAS_CHANGED";
+		break;
+	case SDEV_EVT_SOFT_THRESHOLD_REACHED_REPORTED:
+	       envp[idx++] = "SDEV_UA=THIN_PROVISIONING_SOFT_THRESHOLD_REACHED";
+		break;
+	case SDEV_EVT_MODE_PARAMETER_CHANGE_REPORTED:
+		envp[idx++] = "SDEV_UA=MODE_PARAMETERS_CHANGED";
+		break;
+	case SDEV_EVT_LUN_CHANGE_REPORTED:
+		envp[idx++] = "SDEV_UA=REPORTED_LUNS_DATA_HAS_CHANGED";
+		break;
 	default:
 		/* do nothing */
 		break;
@@ -2274,10 +2288,15 @@ static void scsi_evt_emit(struct scsi_device *sdev, struct scsi_event *evt)
 void scsi_evt_thread(struct work_struct *work)
 {
 	struct scsi_device *sdev;
+	enum scsi_device_event evt_type;
 	LIST_HEAD(event_list);
 
 	sdev = container_of(work, struct scsi_device, event_work);
 
+	for (evt_type = SDEV_EVT_FIRST; evt_type <= SDEV_EVT_LAST; evt_type++)
+		if (test_and_clear_bit(evt_type, sdev->pending_events))
+			sdev_evt_send_simple(sdev, evt_type, GFP_KERNEL);
+
 	while (1) {
 		struct scsi_event *evt;
 		struct list_head *this, *tmp;
@@ -2347,6 +2366,11 @@ struct scsi_event *sdev_evt_alloc(enum scsi_device_event evt_type,
 	/* evt_type-specific initialization, if any */
 	switch (evt_type) {
 	case SDEV_EVT_MEDIA_CHANGE:
+	case SDEV_EVT_INQUIRY_CHANGE_REPORTED:
+	case SDEV_EVT_CAPACITY_CHANGE_REPORTED:
+	case SDEV_EVT_SOFT_THRESHOLD_REACHED_REPORTED:
+	case SDEV_EVT_MODE_PARAMETER_CHANGE_REPORTED:
+	case SDEV_EVT_LUN_CHANGE_REPORTED:
 	default:
 		/* do nothing */
 		break;

commit 7e782af57649f8a8e943d80104c946a5cd7af7cc
Author: Hannes Reinecke <hare@suse.de>
Date:   Mon Jul 1 15:16:26 2013 +0200

    [SCSI] Return ENODATA on medium error
    
    When a medium error is detected the SCSI stack should return
    ENODATA to the upper layers.
    
    [jejb: fix whitespace error]
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 49020d52d685..36b5c898db9d 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -727,6 +727,7 @@ EXPORT_SYMBOL(scsi_release_buffers);
  * -EREMOTEIO	permanent target failure, do not retry
  * -EBADE	permanent nexus failure, retry on other path
  * -ENOSPC	No write space available
+ * -ENODATA	Medium error
  * -EIO		unspecified I/O error
  */
 static int __scsi_error_from_host_byte(struct scsi_cmnd *cmd, int result)
@@ -749,6 +750,10 @@ static int __scsi_error_from_host_byte(struct scsi_cmnd *cmd, int result)
 		set_host_byte(cmd, DID_OK);
 		error = -ENOSPC;
 		break;
+	case DID_MEDIUM_ERROR:
+		set_host_byte(cmd, DID_OK);
+		error = -ENODATA;
+		break;
 	default:
 		error = -EIO;
 		break;

commit a9d6ceb838755c24dde8a0ca02c3378926fc63db
Author: Hannes Reinecke <hare@suse.de>
Date:   Mon Jul 1 15:16:25 2013 +0200

    [SCSI] return ENOSPC on thin provisioning failure
    
    When the thin provisioning hard threshold is reached we
    should return ENOSPC to inform upper layers about this fact.
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e2af8ae0d0ca..49020d52d685 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -726,6 +726,7 @@ EXPORT_SYMBOL(scsi_release_buffers);
  * -ENOLINK	temporary transport failure
  * -EREMOTEIO	permanent target failure, do not retry
  * -EBADE	permanent nexus failure, retry on other path
+ * -ENOSPC	No write space available
  * -EIO		unspecified I/O error
  */
 static int __scsi_error_from_host_byte(struct scsi_cmnd *cmd, int result)
@@ -744,6 +745,10 @@ static int __scsi_error_from_host_byte(struct scsi_cmnd *cmd, int result)
 		set_host_byte(cmd, DID_OK);
 		error = -EBADE;
 		break;
+	case DID_ALLOC_FAILURE:
+		set_host_byte(cmd, DID_OK);
+		error = -ENOSPC;
+		break;
 	default:
 		error = -EIO;
 		break;

commit 0f7f6234d360341d74cfd6e77fcb315daf9905fd
Author: Hannes Reinecke <hare@suse.de>
Date:   Mon Jul 1 15:16:23 2013 +0200

    [SCSI] Document enhanced error codes
    
    Document the various error codes returned on I/O failure.
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 124392f3091e..e2af8ae0d0ca 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -716,6 +716,18 @@ void scsi_release_buffers(struct scsi_cmnd *cmd)
 }
 EXPORT_SYMBOL(scsi_release_buffers);
 
+/**
+ * __scsi_error_from_host_byte - translate SCSI error code into errno
+ * @cmd:	SCSI command (unused)
+ * @result:	scsi error code
+ *
+ * Translate SCSI error code into standard UNIX errno.
+ * Return values:
+ * -ENOLINK	temporary transport failure
+ * -EREMOTEIO	permanent target failure, do not retry
+ * -EBADE	permanent nexus failure, retry on other path
+ * -EIO		unspecified I/O error
+ */
 static int __scsi_error_from_host_byte(struct scsi_cmnd *cmd, int result)
 {
 	int error = 0;

commit f1bc1e4c44b1b78fe34431936c60759b5aad5e3f
Author: Aaron Lu <aaron.lu@intel.com>
Date:   Fri Aug 23 10:17:54 2013 +0800

    ata: acpi: rework the ata acpi bind support
    
    Binding ACPI handle to SCSI device has several drawbacks, namely:
    1 During ATA device initialization time, ACPI handle will be needed
      while SCSI devices are not created yet. So each time ACPI handle is
      needed, instead of retrieving the handle by ACPI_HANDLE macro,
      a namespace scan is performed to find the handle for the corresponding
      ATA device. This is inefficient, and also expose a restriction on
      calling path not holding any lock.
    2 The binding to SCSI device tree makes code complex, while at the same
      time doesn't bring us any benefit. All ACPI handlings are still done
      in ATA module, not in SCSI.
    
    Rework the ATA ACPI binding code to bind ACPI handle to ATA transport
    devices(ATA port and ATA device). The binding needs to be done only once,
    since the ATA transport devices do not go away with hotplug. And due to
    this, the flush_work call in hotplug handler for ATA bay is no longer
    needed.
    
    Tested on an Intel test platform for binding and runtime power off for
    ODD(ZPODD) and hard disk; on an ASUS S400C for binding and normal boot
    and S3, where its SATA port node has _SDD and _GTF control methods when
    configured as an AHCI controller and its PATA device node has _GTF
    control method when configured as an IDE controller. SATA PMP binding
    and ATA hotplug is not tested.
    
    Signed-off-by: Aaron Lu <aaron.lu@intel.com>
    Tested-by: Dirk Griesbach <spamthis@freenet.de>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 124392f3091e..f0ddc7dd06d3 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -68,28 +68,6 @@ static struct scsi_host_sg_pool scsi_sg_pools[] = {
 
 struct kmem_cache *scsi_sdb_cache;
 
-#ifdef CONFIG_ACPI
-#include <acpi/acpi_bus.h>
-
-static bool acpi_scsi_bus_match(struct device *dev)
-{
-	return dev->bus == &scsi_bus_type;
-}
-
-int scsi_register_acpi_bus_type(struct acpi_bus_type *bus)
-{
-        bus->match = acpi_scsi_bus_match;
-        return register_acpi_bus_type(bus);
-}
-EXPORT_SYMBOL_GPL(scsi_register_acpi_bus_type);
-
-void scsi_unregister_acpi_bus_type(struct acpi_bus_type *bus)
-{
-	unregister_acpi_bus_type(bus);
-}
-EXPORT_SYMBOL_GPL(scsi_unregister_acpi_bus_type);
-#endif
-
 /*
  * When to reinvoke queueing after a resource shortage. It's 3 msecs to
  * not change behaviour from the previous unplug mechanism, experimentation

commit 0516c08d10835a8f9169051504cbc9929b3a7f3e
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Tue Jul 2 15:06:33 2013 +0200

    [SCSI] enable destruction of blocked devices which fail LUN scanning
    
    If something goes wrong during LUN scanning, e.g. a transport layer
    failure occurs, then __scsi_remove_device() can get invoked by the
    LUN scanning code for a SCSI device in state SDEV_CREATED_BLOCK and
    before the SCSI device has been added to sysfs (is_visible == 0).
    Make sure that even in this case the transition into state SDEV_DEL
    occurs. This avoids that __scsi_remove_device() can get invoked a
    second time by scsi_forget_host() if this last function is invoked
    from another thread than the thread that performs LUN scanning.
    
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index df8bd5ab3c0b..124392f3091e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2193,6 +2193,7 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 		case SDEV_OFFLINE:
 		case SDEV_TRANSPORT_OFFLINE:
 		case SDEV_CANCEL:
+		case SDEV_CREATED_BLOCK:
 			break;
 		default:
 			goto illegal;

commit e2eb7244bc9e4fd130fc8a961224968e22ba48ee
Author: James Bottomley <JBottomley@Parallels.com>
Date:   Tue Jul 2 15:05:26 2013 +0200

    [SCSI] Fix race between starved list and device removal
    
    scsi_run_queue() examines all SCSI devices that are present on
    the starved list. Since scsi_run_queue() unlocks the SCSI host
    lock a SCSI device can get removed after it has been removed
    from the starved list and before its queue is run. Protect
    against that race condition by holding a reference on the
    queue while running it.
    
    Reported-by: Chanho Min <chanho.min@lge.com>
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 86d522004a20..df8bd5ab3c0b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -434,6 +434,8 @@ static void scsi_run_queue(struct request_queue *q)
 	list_splice_init(&shost->starved_list, &starved_list);
 
 	while (!list_empty(&starved_list)) {
+		struct request_queue *slq;
+
 		/*
 		 * As long as shost is accepting commands and we have
 		 * starved queues, call blk_run_queue. scsi_request_fn
@@ -456,11 +458,25 @@ static void scsi_run_queue(struct request_queue *q)
 			continue;
 		}
 
-		spin_unlock(shost->host_lock);
-		spin_lock(sdev->request_queue->queue_lock);
-		__blk_run_queue(sdev->request_queue);
-		spin_unlock(sdev->request_queue->queue_lock);
-		spin_lock(shost->host_lock);
+		/*
+		 * Once we drop the host lock, a racing scsi_remove_device()
+		 * call may remove the sdev from the starved list and destroy
+		 * it and the queue.  Mitigate by taking a reference to the
+		 * queue and never touching the sdev again after we drop the
+		 * host lock.  Note: if __scsi_remove_device() invokes
+		 * blk_cleanup_queue() before the queue is run from this
+		 * function then blk_run_queue() will return immediately since
+		 * blk_cleanup_queue() marks the queue with QUEUE_FLAG_DYING.
+		 */
+		slq = sdev->request_queue;
+		if (!blk_get_queue(slq))
+			continue;
+		spin_unlock_irqrestore(shost->host_lock, flags);
+
+		blk_run_queue(slq);
+		blk_put_queue(slq);
+
+		spin_lock_irqsave(shost->host_lock, flags);
 	}
 	/* put any unprocessed entries back */
 	list_splice(&starved_list, &shost->starved_list);

commit 9b21493c4520970f8f404e0265f48e37f9cffaf5
Author: Lin Ming <ming.m.lin@intel.com>
Date:   Sat Mar 23 11:42:25 2013 +0800

    [SCSI] sd: use REQ_PM in sd's runtime suspend operation
    
    With the introduction of REQ_PM, modify sd's runtime suspend operation
    functions to use that flag so that the operations to put the device into
    runtime suspended state(i.e. sync cache and stop device) will not affect
    its runtime PM status.
    
    Signed-off-by: Lin Ming <ming.m.lin@intel.com>
    Signed-off-by: Aaron Lu <aaron.lu@intel.com>
    Acked-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c31187d79343..86d522004a20 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -276,11 +276,10 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 }
 EXPORT_SYMBOL(scsi_execute);
 
-
-int scsi_execute_req(struct scsi_device *sdev, const unsigned char *cmd,
+int scsi_execute_req_flags(struct scsi_device *sdev, const unsigned char *cmd,
 		     int data_direction, void *buffer, unsigned bufflen,
 		     struct scsi_sense_hdr *sshdr, int timeout, int retries,
-		     int *resid)
+		     int *resid, int flags)
 {
 	char *sense = NULL;
 	int result;
@@ -291,14 +290,14 @@ int scsi_execute_req(struct scsi_device *sdev, const unsigned char *cmd,
 			return DRIVER_ERROR << 24;
 	}
 	result = scsi_execute(sdev, cmd, data_direction, buffer, bufflen,
-			      sense, timeout, retries, 0, resid);
+			      sense, timeout, retries, flags, resid);
 	if (sshdr)
 		scsi_normalize_sense(sense, SCSI_SENSE_BUFFERSIZE, sshdr);
 
 	kfree(sense);
 	return result;
 }
-EXPORT_SYMBOL(scsi_execute_req);
+EXPORT_SYMBOL(scsi_execute_req_flags);
 
 /*
  * Function:    scsi_init_cmd_errh()

commit 53540098b23c3884b4a0b4f220b9d977bc496af3
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Sun Mar 3 22:35:20 2013 +0100

    ACPI / glue: Add .match() callback to struct acpi_bus_type
    
    USB uses the .find_bridge() callback from struct acpi_bus_type
    incorrectly, because as a result of the way it is used by USB every
    device in the system that doesn't have a bus type or parent is
    passed to usb_acpi_find_device() for inspection.
    
    What USB actually needs, though, is to call usb_acpi_find_device()
    for USB ports that don't have a bus type defined, but have
    usb_port_device_type as their device type, as well as for USB
    devices.
    
    To fix that replace the struct bus_type pointer in struct
    acpi_bus_type used for matching devices to specific subsystems
    with a .match() callback to be used for this purpose and update
    the users of struct acpi_bus_type, including USB, accordingly.
    Define the .match() callback routine for USB, usb_acpi_bus_match(),
    in such a way that it will cover both USB devices and USB ports
    and remove the now redundant .find_bridge() callback pointer from
    usb_acpi_bus.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Acked-by: Yinghai Lu <yinghai@kernel.org>
    Acked-by: Jeff Garzik <jgarzik@pobox.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 765398c063c7..c31187d79343 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -71,9 +71,14 @@ struct kmem_cache *scsi_sdb_cache;
 #ifdef CONFIG_ACPI
 #include <acpi/acpi_bus.h>
 
+static bool acpi_scsi_bus_match(struct device *dev)
+{
+	return dev->bus == &scsi_bus_type;
+}
+
 int scsi_register_acpi_bus_type(struct acpi_bus_type *bus)
 {
-        bus->bus = &scsi_bus_type;
+        bus->match = acpi_scsi_bus_match;
         return register_acpi_bus_type(bus);
 }
 EXPORT_SYMBOL_GPL(scsi_register_acpi_bus_type);

commit 6f4c827e68a78731c6c75df69bf7b75b029ec70c
Author: Aaron Lu <aaron.lu@intel.com>
Date:   Wed Jan 23 15:09:32 2013 +0800

    [libata] scsi: no poll when ODD is powered off
    
    When the ODD is powered off, any action the user did to the ODD that
    would generate a media event will trigger an ACPI interrupt, so the
    poll for media event is no longer necessary. And the poll will also
    cause a runtime status change, which will stop the ODD from staying in
    powered off state, so the poll should better be stopped.
    
    But since we don't have access to the gendisk structure in LLDs, here
    comes the disk_events_disable_depth for scsi device. This field is a
    hint set by LLDs to convey information to upper layer drivers. A value
    of 0 means media poll is necessary for the device, while values above 0
    means media poll is not needed and should better be skipped. So we can
    increase its value when we are to power off the ODD in ATA layer and
    decrease its value when the ODD is powered on, effectively silence the
    media events poll.
    
    Signed-off-by: Aaron Lu <aaron.lu@intel.com>
    Signed-off-by: Jeff Garzik <jgarzik@redhat.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f1bf5aff68ed..765398c063c7 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2617,3 +2617,17 @@ void scsi_kunmap_atomic_sg(void *virt)
 	kunmap_atomic(virt);
 }
 EXPORT_SYMBOL(scsi_kunmap_atomic_sg);
+
+void sdev_disable_disk_events(struct scsi_device *sdev)
+{
+	atomic_inc(&sdev->disk_events_disable_depth);
+}
+EXPORT_SYMBOL(sdev_disable_disk_events);
+
+void sdev_enable_disk_events(struct scsi_device *sdev)
+{
+	if (WARN_ON_ONCE(atomic_read(&sdev->disk_events_disable_depth) <= 0))
+		return;
+	atomic_dec(&sdev->disk_events_disable_depth);
+}
+EXPORT_SYMBOL(sdev_enable_disk_events);

commit 60da5bf47dd3d301a1d3bd4f0a4b9e29a184515c
Merge: 3c2e81ef344a cbae8d45d61f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Dec 17 08:27:23 2012 -0800

    Merge branch 'for-3.8/core' of git://git.kernel.dk/linux-block
    
    Pull block layer core updates from Jens Axboe:
     "Here are the core block IO bits for 3.8.  The branch contains:
    
       - The final version of the surprise device removal fixups from Bart.
    
       - Don't hide EFI partitions under advanced partition types.  It's
         fairly wide spread these days.  This is especially dangerous for
         systems that have both msdos and efi partition tables, where you
         want to keep them in sync.
    
       - Cleanup of using -1 instead of the proper NUMA_NO_NODE
    
       - Export control of bdi flusher thread CPU mask and default to using
         the home node (if known) from Jeff.
    
       - Export unplug tracepoint for MD.
    
       - Core improvements from Shaohua.  Reinstate the recursive merge, as
         the original bug has been fixed.  Add plugging for discard and also
         fix a problem handling non pow-of-2 discard limits.
    
      There's a trivial merge in block/blk-exec.c due to a fix that went
      into 3.7-rc at a later point than -rc4 where this is based."
    
    * 'for-3.8/core' of git://git.kernel.dk/linux-block:
      block: export block_unplug tracepoint
      block: add plug for blkdev_issue_discard
      block: discard granularity might not be power of 2
      deadline: Allow 0ms deadline latency, increase the read speed
      partitions: enable EFI/GPT support by default
      bsg: Remove unused function bsg_goose_queue()
      block: Make blk_cleanup_queue() wait until request_fn finished
      block: Avoid scheduling delayed work on a dead queue
      block: Avoid that request_fn is invoked on a dead queue
      block: Let blk_drain_queue() caller obtain the queue lock
      block: Rename queue dead flag
      bdi: add a user-tunable cpu_list for the bdi flusher threads
      block: use NUMA_NO_NODE instead of -1
      block: recursive merge requests
      block CFQ: avoid moving request to different queue

commit 3f3299d5c0268d6cc3f47b446e8aca436e4a5651
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Wed Nov 28 13:42:38 2012 +0100

    block: Rename queue dead flag
    
    QUEUE_FLAG_DEAD is used to indicate that queuing new requests must
    stop. After this flag has been set queue draining starts. However,
    during the queue draining phase it is still safe to invoke the
    queue's request_fn, so QUEUE_FLAG_DYING is a better name for this
    flag.
    
    This patch has been generated by running the following command
    over the kernel source tree:
    
    git grep -lEw 'blk_queue_dead|QUEUE_FLAG_DEAD' |
        xargs sed -i.tmp -e 's/blk_queue_dead/blk_queue_dying/g'      \
            -e 's/QUEUE_FLAG_DEAD/QUEUE_FLAG_DYING/g';                \
    sed -i.tmp -e "s/QUEUE_FLAG_DYING$(printf \\t)*5/QUEUE_FLAG_DYING$(printf \\t)5/g" \
        include/linux/blkdev.h;                                       \
    sed -i.tmp -e 's/ DEAD/ DYING/g' -e 's/dead queue/a dying queue/' \
        -e 's/Dead queue/A dying queue/' block/blk-core.c
    
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Acked-by: Tejun Heo <tj@kernel.org>
    Cc: James Bottomley <JBottomley@Parallels.com>
    Cc: Mike Christie <michaelc@cs.wisc.edu>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Chanho Min <chanho.min@lge.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index da36a3a81a9e..f29a1a9b54d2 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1406,7 +1406,7 @@ static int scsi_lld_busy(struct request_queue *q)
 	struct scsi_device *sdev = q->queuedata;
 	struct Scsi_Host *shost;
 
-	if (blk_queue_dead(q))
+	if (blk_queue_dying(q))
 		return 0;
 
 	shost = sdev->host;

commit 5db44863b6ebbb400c5e61d56ebe8f21ef48b1bd
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Tue Sep 18 12:19:32 2012 -0400

    [SCSI] sd: Implement support for WRITE SAME
    
    Implement support for WRITE SAME(10) and WRITE SAME(16) in the SCSI disk
    driver.
    
     - We set the default maximum to 0xFFFF because there are several
       devices out there that only support two-byte block counts even with
       WRITE SAME(16). We only enable transfers bigger than 0xFFFF if the
       device explicitly reports MAXIMUM WRITE SAME LENGTH in the BLOCK
       LIMITS VPD.
    
     - max_write_same_blocks can be overriden per-device basis in sysfs.
    
     - The UNMAP discovery heuristics remain unchanged but the discard
       limits are tweaked to match the "real" WRITE SAME commands.
    
     - In the error handling logic we now distinguish between WRITE SAME
       with and without UNMAP set.
    
    The discovery process heuristics are:
    
     - If the device reports a SCSI level of SPC-3 or greater we'll issue
       READ SUPPORTED OPERATION CODES to find out whether WRITE SAME(16) is
       supported. If that's the case we will use it.
    
     - If the device supports the block limits VPD and reports a MAXIMUM
       WRITE SAME LENGTH bigger than 0xFFFF we will use WRITE SAME(16).
    
     - Otherwise we will use WRITE SAME(10) unless the target LBA is beyond
       0xFFFFFFFF or the block count exceeds 0xFFFF.
    
     - no_write_same is set for ATA, FireWire and USB.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Reviewed-by: Mike Snitzer <snitzer@redhat.com>
    Reviewed-by: Jeff Garzik <jgarzik@redhat.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index da36a3a81a9e..9032e910bca3 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -900,11 +900,23 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				action = ACTION_FAIL;
 				error = -EILSEQ;
 			/* INVALID COMMAND OPCODE or INVALID FIELD IN CDB */
-			} else if ((sshdr.asc == 0x20 || sshdr.asc == 0x24) &&
-				   (cmd->cmnd[0] == UNMAP ||
-				    cmd->cmnd[0] == WRITE_SAME_16 ||
-				    cmd->cmnd[0] == WRITE_SAME)) {
-				description = "Discard failure";
+			} else if (sshdr.asc == 0x20 || sshdr.asc == 0x24) {
+				switch (cmd->cmnd[0]) {
+				case UNMAP:
+					description = "Discard failure";
+					break;
+				case WRITE_SAME:
+				case WRITE_SAME_16:
+					if (cmd->cmnd[1] & 0x8)
+						description = "Discard failure";
+					else
+						description =
+							"Write same failure";
+					break;
+				default:
+					description = "Invalid command failure";
+					break;
+				}
 				action = ACTION_FAIL;
 				error = -EREMOTEIO;
 			} else

commit fe709ed827d370e6b0c0a9f9456da1c22bdcd118
Merge: 1c4cf1d5845b 0644f5393e91
Author: James Bottomley <JBottomley@Parallels.com>
Date:   Tue Oct 2 08:55:12 2012 +0100

    Merge SCSI misc branch into isci-for-3.6 tag

commit 0e58076b376824875e7e509b8dd352377a41cbbc
Author: Vikas Chaudhary <vikas.chaudhary@qlogic.com>
Date:   Thu Aug 9 04:51:30 2012 -0400

    [SCSI] scsi_lib: Set the device state from transport-offline to running
    
    FC and iSCSI class set SCSI devices to transport-offline state after
    fast_io_fail/replacement_timeout has fired, but after relogin, function
    scsi_internal_device_unblock() is not setting scsi device state to running.
    Due to this the devices even after being relogged in remain offline.
    
    Signed-off-by: Vikas Chaudhary <vikas.chaudhary@qlogic.com>
    Reviewed-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ffd77739ae3e..4ba37198e069 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2470,7 +2470,8 @@ scsi_internal_device_unblock(struct scsi_device *sdev,
 	 * Try to transition the scsi device to SDEV_RUNNING or one of the
 	 * offlined states and goose the device queue if successful.
 	 */
-	if (sdev->sdev_state == SDEV_BLOCK)
+	if ((sdev->sdev_state == SDEV_BLOCK) ||
+	    (sdev->sdev_state == SDEV_TRANSPORT_OFFLINE))
 		sdev->sdev_state = new_state;
 	else if (sdev->sdev_state == SDEV_CREATED_BLOCK) {
 		if (new_state == SDEV_TRANSPORT_OFFLINE ||

commit 27c419739b67decced4650440829b8d51bef954b
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Thu May 31 15:05:33 2012 -0400

    [SCSI] scsi_lib: fix scsi_io_completion's SG_IO error propagation
    
    The following v3.4-rc1 commit unmasked an existing bug in scsi_io_completion's
    SG_IO error handling: 47ac56d [SCSI] scsi_error: classify some ILLEGAL_REQUEST
    sense as a permanent TARGET_ERROR
    
    Given that certain ILLEGAL_REQUEST are now properly categorized as
    TARGET_ERROR the host_byte is being set (before host_byte wasn't ever
    set for these ILLEGAL_REQUEST).
    
    In scsi_io_completion, initialize req->errors with cmd->result _after_
    the SG_IO block that calls __scsi_error_from_host_byte (which may
    modify the host_byte).
    
    Before this fix:
    
        cdb to send: 12 01 01 00 00 00
    ioctl(3, SG_IO, {'S', SG_DXFER_NONE, cmd[6]=[12, 01, 01, 00, 00, 00],
        mx_sb_len=32, iovec_count=0, dxfer_len=0, timeout=20000, flags=0,
        status=02, masked_status=01, sb[19]=[70, 00, 05, 00, 00, 00, 00, 0b,
        00, 00, 00, 00, 24, 00, 00, 00, 00, 00, 00], host_status=0x10,
        driver_status=0x8, resid=0, duration=0, info=0x1}) = 0
    SCSI Status: Check Condition
    
    Sense Information:
    sense buffer empty
    
    After:
    
        cdb to send: 12 01 01 00 00 00
    ioctl(3, SG_IO, {'S', SG_DXFER_NONE, cmd[6]=[12, 01, 01, 00, 00, 00],
        mx_sb_len=32, iovec_count=0, dxfer_len=0, timeout=20000, flags=0,
        status=02, masked_status=01, sb[19]=[70, 00, 05, 00, 00, 00, 00, 0b,
        00, 00, 00, 00, 24, 00, 00, 00, 00, 00, 00], host_status=0,
        driver_status=0x8, resid=0, duration=0, info=0x1}) = 0
    SCSI Status: Check Condition
    
    Sense Information:
     Fixed format, current;  Sense key: Illegal Request
     Additional sense: Invalid field in cdb
     Raw sense data (in hex):
            70 00 05 00 00 00 00 0b  00 00 00 00 24 00 00 00
            00 00 00
    
    Reported-by: Paolo Bonzini <pbonzini@redhat.com>
    Tested-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Reviewed-by: Babu Moger <babu.moger@netapp.com>
    Cc: stable@vger.kernel.org # 3.4
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ffd77739ae3e..faa790fba134 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -776,7 +776,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	}
 
 	if (req->cmd_type == REQ_TYPE_BLOCK_PC) { /* SG_IO ioctl from block level */
-		req->errors = result;
 		if (result) {
 			if (sense_valid && req->sense) {
 				/*
@@ -792,6 +791,10 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			if (!sense_deferred)
 				error = __scsi_error_from_host_byte(cmd, result);
 		}
+		/*
+		 * __scsi_error_from_host_byte may have reset the host_byte
+		 */
+		req->errors = cmd->result;
 
 		req->resid_len = scsi_get_resid(cmd);
 

commit 8407884dd9164ec18ed2afc00f56b87e36c51fcf
Merge: dc7f71f486f4 bdc0077af574
Author: Jeff Garzik <jeff@garzik.org>
Date:   Wed Jul 25 15:58:48 2012 -0400

    Merge branch 'master' [vanilla Linus master] into libata-dev.git/upstream
    
    Two bits were appended to the end of the bitfield
    list in struct scsi_device.  Resolve that conflict
    by including both bits.
    
    Conflicts:
            include/scsi/scsi_device.h

commit b485462aca7df4e32bcf7efb6f84a69e8b640243
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Fri Jun 29 15:36:07 2012 +0000

    [SCSI] Stop accepting SCSI requests before removing a device
    
    Avoid that the code for requeueing SCSI requests triggers a
    crash by making sure that that code isn't scheduled anymore
    after a device has been removed.
    
    Also, source code inspection of __scsi_remove_device() revealed
    a race condition in this function: no new SCSI requests must be
    accepted for a SCSI device after device removal started.
    
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Mike Christie <michaelc@cs.wisc.edu>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 8af6a6497c4f..b58327758c58 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -155,13 +155,14 @@ static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
 
 	/*
 	 * Requeue this command.  It will go before all other commands
-	 * that are already in the queue.
+	 * that are already in the queue. Schedule requeue work under
+	 * lock such that the kblockd_schedule_work() call happens
+	 * before blk_cleanup_queue() finishes.
 	 */
 	spin_lock_irqsave(q->queue_lock, flags);
 	blk_requeue_request(q, cmd->request);
-	spin_unlock_irqrestore(q->queue_lock, flags);
-
 	kblockd_schedule_work(q, &device->requeue_work);
+	spin_unlock_irqrestore(q->queue_lock, flags);
 }
 
 /*

commit 84feb1664e5e6823105414df77740fda70846b99
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Fri Jun 29 15:35:05 2012 +0000

    [SCSI] Change return type of scsi_queue_insert() into void
    
    The return value of scsi_queue_insert() is ignored by all its
    callers, hence change the return type of this function into
    void.
    
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Mike Christie <michaelc@cs.wisc.edu>
    Reviewed-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0e52ff035135..8af6a6497c4f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -109,7 +109,7 @@ static void scsi_unprep_request(struct request *req)
  * for a requeue after completion, which should only occur in this
  * file.
  */
-static int __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
+static void __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
 {
 	struct Scsi_Host *host = cmd->device->host;
 	struct scsi_device *device = cmd->device;
@@ -162,8 +162,6 @@ static int __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
 	spin_unlock_irqrestore(q->queue_lock, flags);
 
 	kblockd_schedule_work(q, &device->requeue_work);
-
-	return 0;
 }
 
 /*
@@ -185,9 +183,9 @@ static int __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
  * Notes:       This could be called either from an interrupt context or a
  *              normal process context.
  */
-int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
+void scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 {
-	return __scsi_queue_insert(cmd, reason, 1);
+	__scsi_queue_insert(cmd, reason, 1);
 }
 /**
  * scsi_execute - insert request and wait for the result

commit 940f5d47e2f2e1fa00443921a0abf4822335b54d
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Fri Jun 29 15:34:26 2012 +0000

    [SCSI] Avoid dangling pointer in scsi_requeue_command()
    
    When we call scsi_unprep_request() the command associated with the request
    gets destroyed and therefore drops its reference on the device.  If this was
    the only reference, the device may get released and we end up with a NULL
    pointer deref when we call blk_requeue_request.
    
    Reported-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Mike Christie <michaelc@cs.wisc.edu>
    Reviewed-by: Tejun Heo <tj@kernel.org>
    Cc: <stable@kernel.org>
    [jejb: enhance commend and add commit log for stable]
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4acf5c284c2e..0e52ff035135 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -479,15 +479,26 @@ void scsi_requeue_run_queue(struct work_struct *work)
  */
 static void scsi_requeue_command(struct request_queue *q, struct scsi_cmnd *cmd)
 {
+	struct scsi_device *sdev = cmd->device;
 	struct request *req = cmd->request;
 	unsigned long flags;
 
+	/*
+	 * We need to hold a reference on the device to avoid the queue being
+	 * killed after the unlock and before scsi_run_queue is invoked which
+	 * may happen because scsi_unprep_request() puts the command which
+	 * releases its reference on the device.
+	 */
+	get_device(&sdev->sdev_gendev);
+
 	spin_lock_irqsave(q->queue_lock, flags);
 	scsi_unprep_request(req);
 	blk_requeue_request(q, req);
 	spin_unlock_irqrestore(q->queue_lock, flags);
 
 	scsi_run_queue(q);
+
+	put_device(&sdev->sdev_gendev);
 }
 
 void scsi_next_command(struct scsi_cmnd *cmd)

commit 67bd94130015c507011af37858989b199c52e1de
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Fri Jun 29 15:33:22 2012 +0000

    [SCSI] Fix device removal NULL pointer dereference
    
    Use blk_queue_dead() to test whether the queue is dead instead
    of !sdev. Since scsi_prep_fn() may be invoked concurrently with
    __scsi_remove_device(), keep the queuedata (sdev) pointer in
    __scsi_remove_device(). This patch fixes a kernel oops that
    can be triggered by USB device removal. See also
    http://www.spinics.net/lists/linux-scsi/msg56254.html.
    
    Other changes included in this patch:
    - Swap the blk_cleanup_queue() and kfree() calls in
      scsi_host_dev_release() to make that code easier to grasp.
    - Remove the queue dead check from scsi_run_queue() since the
      queue state can change anyway at any point in that function
      where the queue lock is not held.
    - Remove the queue dead check from the start of scsi_request_fn()
      since it is redundant with the scsi_device_online() check.
    
    Reported-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Reviewed-by: Mike Christie <michaelc@cs.wisc.edu>
    Reviewed-by: Tejun Heo <tj@kernel.org>
    Cc: <stable@kernel.org>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9f00c128e4d1..4acf5c284c2e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -406,10 +406,6 @@ static void scsi_run_queue(struct request_queue *q)
 	LIST_HEAD(starved_list);
 	unsigned long flags;
 
-	/* if the device is dead, sdev will be NULL, so no queue to run */
-	if (!sdev)
-		return;
-
 	shost = sdev->host;
 	if (scsi_target(sdev)->single_lun)
 		scsi_single_lun_run(sdev);
@@ -1371,16 +1367,16 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
  * may be changed after request stacking drivers call the function,
  * regardless of taking lock or not.
  *
- * When scsi can't dispatch I/Os anymore and needs to kill I/Os
- * (e.g. !sdev), scsi needs to return 'not busy'.
- * Otherwise, request stacking drivers may hold requests forever.
+ * When scsi can't dispatch I/Os anymore and needs to kill I/Os scsi
+ * needs to return 'not busy'. Otherwise, request stacking drivers
+ * may hold requests forever.
  */
 static int scsi_lld_busy(struct request_queue *q)
 {
 	struct scsi_device *sdev = q->queuedata;
 	struct Scsi_Host *shost;
 
-	if (!sdev)
+	if (blk_queue_dead(q))
 		return 0;
 
 	shost = sdev->host;
@@ -1491,12 +1487,6 @@ static void scsi_request_fn(struct request_queue *q)
 	struct scsi_cmnd *cmd;
 	struct request *req;
 
-	if (!sdev) {
-		while ((req = blk_peek_request(q)) != NULL)
-			scsi_kill_request(req, q);
-		return;
-	}
-
 	if(!get_device(&sdev->sdev_gendev))
 		/* We must be tearing the block queue down already */
 		return;
@@ -1698,20 +1688,6 @@ struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
 	return q;
 }
 
-void scsi_free_queue(struct request_queue *q)
-{
-	unsigned long flags;
-
-	WARN_ON(q->queuedata);
-
-	/* cause scsi_request_fn() to kill all non-finished requests */
-	spin_lock_irqsave(q->queue_lock, flags);
-	q->request_fn(q);
-	spin_unlock_irqrestore(q->queue_lock, flags);
-
-	blk_cleanup_queue(q);
-}
-
 /*
  * Function:    scsi_block_requests()
  *

commit d075498c987623107f7bface4dad72fe9260a0d3
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Thu May 17 23:56:58 2012 -0500

    [SCSI] remove old comment from block/unblock functions
    
    We do not hold the host lock when calling these functions,
    so remove comment.
    
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 36521a0ac54b..9f00c128e4d1 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2411,7 +2411,6 @@ EXPORT_SYMBOL(scsi_target_resume);
  *	(which must be a legal transition).  When the device is in this
  *	state, all commands are deferred until the scsi lld reenables
  *	the device with scsi_device_unblock or device_block_tmo fires.
- *	This routine assumes the host_lock is held on entry.
  */
 int
 scsi_internal_device_block(struct scsi_device *sdev)
@@ -2455,8 +2454,7 @@ EXPORT_SYMBOL_GPL(scsi_internal_device_block);
  * Notes:       
  *	This routine transitions the device to the SDEV_RUNNING state
  *	or to one of the offline states (which must be a legal transition)
- *	allowing the midlayer to goose the queue for this device. This
- *	routine assumes the host_lock is held upon entry.
+ *	allowing the midlayer to goose the queue for this device.
  */
 int
 scsi_internal_device_unblock(struct scsi_device *sdev,

commit 5d9fb5cc1b88277bb28a2a54e51b34cacaa123c2
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Thu May 17 23:56:57 2012 -0500

    [SCSI] core, classes, mpt2sas: have scsi_internal_device_unblock take new state
    
    This has scsi_internal_device_unblock/scsi_target_unblock take
    the new state to set the devices as an argument instead of
    always setting to running. The patch also converts users of these
    functions.
    
    This allows the FC and iSCSI class to transition devices from blocked
    to transport-offline, so that when fast_io_fail/replacement_timeout
    has fired we do not set the devices back to running. Instead, we
    set them to SDEV_TRANSPORT_OFFLINE.
    
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 340c569d4535..36521a0ac54b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2444,6 +2444,7 @@ EXPORT_SYMBOL_GPL(scsi_internal_device_block);
 /**
  * scsi_internal_device_unblock - resume a device after a block request
  * @sdev:	device to resume
+ * @new_state:	state to set devices to after unblocking
  *
  * Called by scsi lld's or the midlayer to restart the device queue
  * for the previously suspended scsi device.  Called from interrupt or
@@ -2453,25 +2454,30 @@ EXPORT_SYMBOL_GPL(scsi_internal_device_block);
  *
  * Notes:       
  *	This routine transitions the device to the SDEV_RUNNING state
- *	(which must be a legal transition) allowing the midlayer to
- *	goose the queue for this device.  This routine assumes the 
- *	host_lock is held upon entry.
+ *	or to one of the offline states (which must be a legal transition)
+ *	allowing the midlayer to goose the queue for this device. This
+ *	routine assumes the host_lock is held upon entry.
  */
 int
-scsi_internal_device_unblock(struct scsi_device *sdev)
+scsi_internal_device_unblock(struct scsi_device *sdev,
+			     enum scsi_device_state new_state)
 {
 	struct request_queue *q = sdev->request_queue; 
 	unsigned long flags;
-	
-	/* 
-	 * Try to transition the scsi device to SDEV_RUNNING
-	 * and goose the device queue if successful.  
+
+	/*
+	 * Try to transition the scsi device to SDEV_RUNNING or one of the
+	 * offlined states and goose the device queue if successful.
 	 */
 	if (sdev->sdev_state == SDEV_BLOCK)
-		sdev->sdev_state = SDEV_RUNNING;
-	else if (sdev->sdev_state == SDEV_CREATED_BLOCK)
-		sdev->sdev_state = SDEV_CREATED;
-	else if (sdev->sdev_state != SDEV_CANCEL &&
+		sdev->sdev_state = new_state;
+	else if (sdev->sdev_state == SDEV_CREATED_BLOCK) {
+		if (new_state == SDEV_TRANSPORT_OFFLINE ||
+		    new_state == SDEV_OFFLINE)
+			sdev->sdev_state = new_state;
+		else
+			sdev->sdev_state = SDEV_CREATED;
+	} else if (sdev->sdev_state != SDEV_CANCEL &&
 		 sdev->sdev_state != SDEV_OFFLINE)
 		return -EINVAL;
 
@@ -2512,26 +2518,26 @@ EXPORT_SYMBOL_GPL(scsi_target_block);
 static void
 device_unblock(struct scsi_device *sdev, void *data)
 {
-	scsi_internal_device_unblock(sdev);
+	scsi_internal_device_unblock(sdev, *(enum scsi_device_state *)data);
 }
 
 static int
 target_unblock(struct device *dev, void *data)
 {
 	if (scsi_is_target_device(dev))
-		starget_for_each_device(to_scsi_target(dev), NULL,
+		starget_for_each_device(to_scsi_target(dev), data,
 					device_unblock);
 	return 0;
 }
 
 void
-scsi_target_unblock(struct device *dev)
+scsi_target_unblock(struct device *dev, enum scsi_device_state new_state)
 {
 	if (scsi_is_target_device(dev))
-		starget_for_each_device(to_scsi_target(dev), NULL,
+		starget_for_each_device(to_scsi_target(dev), &new_state,
 					device_unblock);
 	else
-		device_for_each_child(dev, NULL, target_unblock);
+		device_for_each_child(dev, &new_state, target_unblock);
 }
 EXPORT_SYMBOL_GPL(scsi_target_unblock);
 

commit 1b8d26206134458044b0689f48194af00c96d406
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Thu May 17 23:56:56 2012 -0500

    [SCSI] add new SDEV_TRANSPORT_OFFLINE state
    
    This patch adds a new state SDEV_TRANSPORT_OFFLINE. It will
    be used by transport classes to offline devices for cases like
    when the fast_io_fail/recovery_tmo fires. In those cases we
    want all IO to fail, and we have not yet escalated to dev_loss_tmo
    behavior where we are removing the devices.
    
    Currently to handle this state, transport classes are setting
    the scsi_device's state to running, setting their internal
    session/port structs state to something that indicates failed,
    and then failing IO from some transport check in the queuecommand.
    
    The reason for the new value is so that users can distinguish
    between a device failure that is a result of a transport problem
    vs the wide range of errors that devices get offlined for
    when a scsi command times out and we offline the devices there.
    It also fixes the confusion as to why the transport class is
    failing IO, but has set the device state from blocked to running.
    
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 6dfb9785d345..340c569d4535 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1173,6 +1173,7 @@ int scsi_prep_state_check(struct scsi_device *sdev, struct request *req)
 	if (unlikely(sdev->sdev_state != SDEV_RUNNING)) {
 		switch (sdev->sdev_state) {
 		case SDEV_OFFLINE:
+		case SDEV_TRANSPORT_OFFLINE:
 			/*
 			 * If the device is offline we refuse to process any
 			 * commands.  The device must be brought online
@@ -2081,6 +2082,7 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 		switch (oldstate) {
 		case SDEV_CREATED:
 		case SDEV_OFFLINE:
+		case SDEV_TRANSPORT_OFFLINE:
 		case SDEV_QUIESCE:
 		case SDEV_BLOCK:
 			break;
@@ -2093,6 +2095,7 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 		switch (oldstate) {
 		case SDEV_RUNNING:
 		case SDEV_OFFLINE:
+		case SDEV_TRANSPORT_OFFLINE:
 			break;
 		default:
 			goto illegal;
@@ -2100,6 +2103,7 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 		break;
 
 	case SDEV_OFFLINE:
+	case SDEV_TRANSPORT_OFFLINE:
 		switch (oldstate) {
 		case SDEV_CREATED:
 		case SDEV_RUNNING:
@@ -2136,6 +2140,7 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 		case SDEV_RUNNING:
 		case SDEV_QUIESCE:
 		case SDEV_OFFLINE:
+		case SDEV_TRANSPORT_OFFLINE:
 		case SDEV_BLOCK:
 			break;
 		default:
@@ -2148,6 +2153,7 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 		case SDEV_CREATED:
 		case SDEV_RUNNING:
 		case SDEV_OFFLINE:
+		case SDEV_TRANSPORT_OFFLINE:
 		case SDEV_CANCEL:
 			break;
 		default:

commit de50ada55b6b83b54b817911ec42dc590e1c1738
Author: Holger Macht <holger@homac.de>
Date:   Mon Jun 25 16:13:02 2012 +0800

    [SCSI] add wrapper to access and set scsi_bus_type in struct acpi_bus_type
    
    For being able to bind ata devices against acpi devices, scsi_bus_type
    needs to be set as bus in struct acpi_bus_type. So add wrapper to
    scsi_lib to accomplish that.
    
    Signed-off-by: Holger Macht <holger@homac.de>
    Signed-off-by: Lin Ming <ming.m.lin@intel.com>
    Signed-off-by: Jeff Garzik <jgarzik@redhat.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 6dfb9785d345..08f1e297c735 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -68,6 +68,23 @@ static struct scsi_host_sg_pool scsi_sg_pools[] = {
 
 struct kmem_cache *scsi_sdb_cache;
 
+#ifdef CONFIG_ACPI
+#include <acpi/acpi_bus.h>
+
+int scsi_register_acpi_bus_type(struct acpi_bus_type *bus)
+{
+        bus->bus = &scsi_bus_type;
+        return register_acpi_bus_type(bus);
+}
+EXPORT_SYMBOL_GPL(scsi_register_acpi_bus_type);
+
+void scsi_unregister_acpi_bus_type(struct acpi_bus_type *bus)
+{
+	unregister_acpi_bus_type(bus);
+}
+EXPORT_SYMBOL_GPL(scsi_unregister_acpi_bus_type);
+#endif
+
 /*
  * When to reinvoke queueing after a resource shortage. It's 3 msecs to
  * not change behaviour from the previous unplug mechanism, experimentation

commit b7e94a1686c5daef4f649f7f4f839cc294f07710
Author: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
Date:   Tue May 22 18:57:17 2012 +0900

    [SCSI] Fix dm-multipath starvation when scsi host is busy
    
    block congestion control doesn't have any concept of fairness across
    multiple queues.  This means that if SCSI reports the host as busy in
    the queue congestion control it can result in an unfair starvation
    situation in dm-mp if there are multiple multipath devices on the same
    host.  For example:
    http://www.redhat.com/archives/dm-devel/2012-May/msg00123.html
    
    The fix for this is to report only the sdev busy state (and ignore the
    host busy state) in the block congestion control call back.
    The host is still congested, but the SCSI subsystem will sort out the
    congestion in a fair way because it knows the relation between the
    queues and the host.
    
    [jejb: fixed up trailing whitespace]
    Reported-by: Bernd Schubert <bernd.schubert@itwm.fraunhofer.de>
    Tested-by: Bernd Schubert <bernd.schubert@itwm.fraunhofer.de>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 62ddfd31d4ce..6dfb9785d345 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1378,16 +1378,19 @@ static int scsi_lld_busy(struct request_queue *q)
 {
 	struct scsi_device *sdev = q->queuedata;
 	struct Scsi_Host *shost;
-	struct scsi_target *starget;
 
 	if (!sdev)
 		return 0;
 
 	shost = sdev->host;
-	starget = scsi_target(sdev);
 
-	if (scsi_host_in_recovery(shost) || scsi_host_is_busy(shost) ||
-	    scsi_target_is_busy(starget) || scsi_device_is_busy(sdev))
+	/*
+	 * Ignore host/starget busy state.
+	 * Since block layer does not have a concept of fairness across
+	 * multiple queues, congestion of host/starget needs to be handled
+	 * in SCSI layer.
+	 */
+	if (scsi_host_in_recovery(shost) || scsi_device_is_busy(sdev))
 		return 1;
 
 	return 0;

commit e34693336564f02b3e2cc09d8b872aef22a154e9
Merge: 76b311fdbdd2 de2eb4d5c5c2
Author: James Bottomley <JBottomley@Parallels.com>
Date:   Mon May 21 12:17:30 2012 +0100

    Merge tag 'isci-for-3.5' into misc
    
    isci update for 3.5
    
    1/ Rework remote-node-context (RNC) handling for proper management of
       the silicon state machine in error handling and hot-plug conditions.
       Further details below, suffice to say if the RNC is mismanaged the
       silicon state machines may lock up.
    
    2/ Refactor the initialization code to be reused for suspend/resume support
    
    3/ Miscellaneous bug fixes to address discovery issues and hardware
       compatibility.
    
    RNC rework details from Jeff Skirvin:
    
    In the controller, devices as they appear on a SAS domain (or
    direct-attached SATA devices) are represented by memory structures known
    as "Remote Node Contexts" (RNCs).  These structures are transferred from
    main memory to the controller using a set of register commands; these
    commands include setting up the context ("posting"), removing the
    context ("invalidating"), and commands to control the scheduling of
    commands and connections to that remote device ("suspensions" and
    "resumptions").  There is a similar path to control RNC scheduling from
    the protocol engine, which interprets the results of command and data
    transmission and reception.
    
    In general, the controller chooses among non-suspended RNCs to find one
    that has work requiring scheduling the transmission of command and data
    frames to a target.  Likewise, when a target tries to return data back
    to the initiator, the state of the RNC is used by the controller to
    determine how to treat the incoming request. As an example, if the RNC
    is in the state "TX/RX Suspended", incoming SSP connection requests from
    the target will be rejected by the controller hardware.  When an RNC is
    "TX Suspended", it will not be selected by the controller hardware to
    start outgoing command or data operations (with certain priority-based
    exceptions).
    
    As mentioned above, there are two sources for management of the RNC
    states: commands from driver software, and the result of transmission
    and reception conditions of commands and data signaled by the controller
    hardware.  As an example of the latter, if an outgoing SSP command ends
    with a OPEN_REJECT(BAD_DESTINATION) status, the RNC state will
    transition to the "TX Suspended" state, and this is signaled by the
    controller hardware in the status to the completion of the pending
    command as well as signaled in a controller hardware event.  Examples of
    the former are included in the patch changelogs.
    
    Driver software is required to suspend the RNC in a "TX/RX Suspended"
    condition before any outstanding commands can be terminated.  Failure to
    guarantee this can lead to a complete hardware hang condition.  Earlier
    versions of the driver software did not guarantee that an RNC was
    correctly managed before I/O termination, and so operated in an unsafe
    way.
    
    Further, the driver performed unnecessary contortions to preserve the
    remote device command state and so was more complicated than it needed
    to be.  A simplifying driver assumption is that once an I/O has entered
    the error handler path without having completed in the target, the
    requirement on the driver is that all use of the sas_task must end.
    Beyond that, recovery of operation is dependent on libsas and other
    components to reset, rediscover and reconfigure the device before normal
    operation can restart.  In the driver, this simplifying assumption meant
    that the RNC management could be reduced to entry into the suspended
    state, terminating the targeted I/O request, and resuming the RNC as
    needed for device-specific management such as an SSP Abort Task or LUN
    Reset Management request.

commit a7a20d103994fd760766e6c9d494daa569cbfe06
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Thu Mar 22 17:05:11 2012 -0700

    [SCSI] sd: limit the scope of the async probe domain
    
    sd injects and synchronizes probe work on the global kernel-wide domain.
    This runs into conflict with PM that wants to perform resume actions in
    async context:
    
    [  494.237079] INFO: task kworker/u:3:554 blocked for more than 120 seconds.
    [  494.294396] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [  494.360809] kworker/u:3     D 0000000000000000     0   554      2 0x00000000
    [  494.420739]  ffff88012e4d3af0 0000000000000046 ffff88013200c160 ffff88012e4d3fd8
    [  494.484392]  ffff88012e4d3fd8 0000000000012500 ffff8801394ea0b0 ffff88013200c160
    [  494.548038]  ffff88012e4d3ae0 00000000000001e3 ffffffff81a249e0 ffff8801321c5398
    [  494.611685] Call Trace:
    [  494.632649]  [<ffffffff8149dd25>] schedule+0x5a/0x5c
    [  494.674687]  [<ffffffff8104b968>] async_synchronize_cookie_domain+0xb6/0x112
    [  494.734177]  [<ffffffff810461ff>] ? __init_waitqueue_head+0x50/0x50
    [  494.787134]  [<ffffffff8131a224>] ? scsi_remove_target+0x48/0x48
    [  494.837900]  [<ffffffff8104b9d9>] async_synchronize_cookie+0x15/0x17
    [  494.891567]  [<ffffffff8104ba49>] async_synchronize_full+0x54/0x70  <-- here we wait for async contexts to complete
    [  494.943783]  [<ffffffff8104b9f5>] ? async_synchronize_full_domain+0x1a/0x1a
    [  495.002547]  [<ffffffffa00114b1>] sd_remove+0x2c/0xa2 [sd_mod]
    [  495.051861]  [<ffffffff812fe94f>] __device_release_driver+0x86/0xcf
    [  495.104807]  [<ffffffff812fe9bd>] device_release_driver+0x25/0x32  <-- here we take device_lock()
    
    [  853.511341] INFO: task kworker/u:4:549 blocked for more than 120 seconds.
    [  853.568693] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [  853.635119] kworker/u:4     D ffff88013097b5d0     0   549      2 0x00000000
    [  853.695129]  ffff880132773c40 0000000000000046 ffff880130790000 ffff880132773fd8
    [  853.758990]  ffff880132773fd8 0000000000012500 ffff88013288a0b0 ffff880130790000
    [  853.822796]  0000000000000246 0000000000000040 ffff88013097b5c8 ffff880130790000
    [  853.886633] Call Trace:
    [  853.907631]  [<ffffffff8149dd25>] schedule+0x5a/0x5c
    [  853.949670]  [<ffffffff8149cc44>] __mutex_lock_common+0x220/0x351
    [  854.001225]  [<ffffffff81304bd7>] ? device_resume+0x58/0x1c4
    [  854.049082]  [<ffffffff81304bd7>] ? device_resume+0x58/0x1c4
    [  854.097011]  [<ffffffff8149ce48>] mutex_lock_nested+0x2f/0x36   <-- here we wait for device_lock()
    [  854.145591]  [<ffffffff81304bd7>] device_resume+0x58/0x1c4
    [  854.192066]  [<ffffffff81304d61>] async_resume+0x1e/0x45
    [  854.237019]  [<ffffffff8104bc93>] async_run_entry_fn+0xc6/0x173  <-- ...while running in async context
    
    Provide a 'scsi_sd_probe_domain' so that async probe actions actions can
    be flushed without regard for the state of PM, and allow for the resume
    path to handle devices that have transitioned from SDEV_QUIESCE to
    SDEV_DEL prior to resume.
    
    Acked-by: Alan Stern <stern@rowland.harvard.edu>
    [alan: uplevel scsi_sd_probe_domain, clarify scsi_device_resume]
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    [jejb: remove unneeded config guards in include file]
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ead6405f3e51..dbe43924d7ae 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2348,10 +2348,14 @@ EXPORT_SYMBOL(scsi_device_quiesce);
  *
  *	Must be called with user context, may sleep.
  */
-void
-scsi_device_resume(struct scsi_device *sdev)
+void scsi_device_resume(struct scsi_device *sdev)
 {
-	if(scsi_device_set_state(sdev, SDEV_RUNNING))
+	/* check if the device state was mutated prior to resume, and if
+	 * so assume the state is being managed elsewhere (for example
+	 * device deleted during suspend)
+	 */
+	if (sdev->sdev_state != SDEV_QUIESCE ||
+	    scsi_device_set_state(sdev, SDEV_RUNNING))
 		return;
 	scsi_run_queue(sdev->request_queue);
 }

commit 6f381fa344911d5a234b13574433cf23036f9467
Author: Lin Ming <ming.m.lin@intel.com>
Date:   Thu Apr 12 13:50:38 2012 +0800

    [SCSI] scsi_lib: use correct DMA device in __scsi_alloc_queue
    
    Currently, __scsi_alloc_queue uses SCSI host's parent device
    as DMA device to set segment boundary. But the parent device may not
    refer to the DMA device. For example, for ATA disk, SCSI host's parent
    device now refers to ATA port.
    
    Since commit d139b9b([SCSI] scsi_lib_dma: fix bug with dma maps on
    nested scsi objects), a new field Scsi_Host->dma_dev was introduced
    to refer to the real DMA device.
    
    Use ->dma_dev in __scsi_alloc_queue to correctly set segment
    boundary.
    
    Bug report: http://marc.info/?l=linux-ide&m=133177818318187&w=2
    
    Reported-and-tested-by: Jörg Sommer <joerg@alea.gnuu.de>
    Signed-off-by: Lin Ming <ming.m.lin@intel.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ead6405f3e51..5dfd7495d1a1 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1638,7 +1638,7 @@ struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
 					 request_fn_proc *request_fn)
 {
 	struct request_queue *q;
-	struct device *dev = shost->shost_gendev.parent;
+	struct device *dev = shost->dma_dev;
 
 	q = blk_init_queue(request_fn, NULL);
 	if (!q)

commit 424a6f6ef990b7e9f56f6627bfc6c46b493faeb4
Merge: 1ab142d49929 cd8df932d894
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 22 12:55:29 2012 -0700

    Merge tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6
    
    SCSI updates from James Bottomley:
     "The update includes the usual assortment of driver updates (lpfc,
      qla2xxx, qla4xxx, bfa, bnx2fc, bnx2i, isci, fcoe, hpsa) plus a huge
      amount of infrastructure work in the SAS library and transport class
      as well as an iSCSI update.  There's also a new SCSI based virtio
      driver."
    
    * tag 'scsi-misc' of git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6: (177 commits)
      [SCSI] qla4xxx: Update driver version to 5.02.00-k15
      [SCSI] qla4xxx: trivial cleanup
      [SCSI] qla4xxx: Fix sparse warning
      [SCSI] qla4xxx: Add support for multiple session per host.
      [SCSI] qla4xxx: Export CHAP index as sysfs attribute
      [SCSI] scsi_transport: Export CHAP index as sysfs attribute
      [SCSI] qla4xxx: Add support to display CHAP list and delete CHAP entry
      [SCSI] iscsi_transport: Add support to display CHAP list and delete CHAP entry
      [SCSI] pm8001: fix endian issue with code optimization.
      [SCSI] pm8001: Fix possible racing condition.
      [SCSI] pm8001: Fix bogus interrupt state flag issue.
      [SCSI] ipr: update PCI ID definitions for new adapters
      [SCSI] qla2xxx: handle default case in qla2x00_request_firmware()
      [SCSI] isci: improvements in driver unloading routine
      [SCSI] isci: improve phy event warnings
      [SCSI] isci: debug, provide state-enum-to-string conversions
      [SCSI] scsi_transport_sas: 'enable' phys on reset
      [SCSI] libsas: don't recover end devices attached to disabled phys
      [SCSI] libsas: fixup target_port_protocols for expanders that don't report sata
      [SCSI] libsas: set attached device type and target protocols for local phys
      ...

commit 77dfce076cbd76c04e90abff188d058cdbff78dd
Author: Cong Wang <amwang@redhat.com>
Date:   Fri Nov 25 23:14:23 2011 +0800

    scsi: remove the second argument of k[un]map_atomic()
    
    Signed-off-by: Cong Wang <amwang@redhat.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b2c95dbe9d65..a33b2b66da67 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2567,7 +2567,7 @@ void *scsi_kmap_atomic_sg(struct scatterlist *sgl, int sg_count,
 	if (*len > sg_len)
 		*len = sg_len;
 
-	return kmap_atomic(page, KM_BIO_SRC_IRQ);
+	return kmap_atomic(page);
 }
 EXPORT_SYMBOL(scsi_kmap_atomic_sg);
 
@@ -2577,6 +2577,6 @@ EXPORT_SYMBOL(scsi_kmap_atomic_sg);
  */
 void scsi_kunmap_atomic_sg(void *virt)
 {
-	kunmap_atomic(virt, KM_BIO_SRC_IRQ);
+	kunmap_atomic(virt);
 }
 EXPORT_SYMBOL(scsi_kunmap_atomic_sg);

commit 66a651aa7a48b7c6181aff556937454c87bb9feb
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Mon Feb 13 15:38:22 2012 -0500

    [SCSI] Ensure discard failure gets treated as a target problem
    
    The error reported up the stack for a discard failure did not clearly
    indicate that the command was processed and subsequently failed by the
    target device.
    
    Return -EREMOTEIO so multipathing does not classify this condition as a
    path failure.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Acked-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 5b770e9e82c2..b4833deffd3b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -880,6 +880,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				    cmd->cmnd[0] == WRITE_SAME)) {
 				description = "Discard failure";
 				action = ACTION_FAIL;
+				error = -EREMOTEIO;
 			} else
 				action = ACTION_FAIL;
 			break;

commit 2082ebc45af9c9c648383b8cde0dc1948eadbf31
Author: Moger, Babu <Babu.Moger@netapp.com>
Date:   Tue Jan 24 20:38:46 2012 +0000

    [SCSI] fix the new host byte settings (DID_TARGET_FAILURE and DID_NEXUS_FAILURE)
    
    This patch fixes the host byte settings DID_TARGET_FAILURE and
    DID_NEXUS_FAILURE.  The function __scsi_error_from_host_byte, tries to reset
    the host byte to DID_OK. But that does not happen because of the OR operation.
    
    Here is the flow.
    
    scsi_softirq_done-> scsi_decide_disposition -> __scsi_error_from_host_byte
    
    Let's take an example with DID_NEXUS_FAILURE. In scsi_decide_disposition,
    result will be set as DID_NEXUS_FAILURE (=0x11). Then in
    __scsi_error_from_host_byte, when we do OR with DID_OK.  Purpose is to reset
    it back to DID_OK. But that does not happen.  This patch fixes this issue.
    
    Signed-off-by: Babu Moger <babu.moger@netapp.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b2c95dbe9d65..5b770e9e82c2 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -682,11 +682,11 @@ static int __scsi_error_from_host_byte(struct scsi_cmnd *cmd, int result)
 		error = -ENOLINK;
 		break;
 	case DID_TARGET_FAILURE:
-		cmd->result |= (DID_OK << 16);
+		set_host_byte(cmd, DID_OK);
 		error = -EREMOTEIO;
 		break;
 	case DID_NEXUS_FAILURE:
-		cmd->result |= (DID_OK << 16);
+		set_host_byte(cmd, DID_OK);
 		error = -EBADE;
 		break;
 	default:

commit 466c08c71a7dc19528e9b336c5bfa5ec41730c7c
Author: Shaohua Li <shaohua.li@intel.com>
Date:   Tue Jan 10 11:27:01 2012 +0800

    [SCSI] don't change sdev starvation list order without request dispatched
    
    The sdev is deleted from starved list and then try to dispatch from this
    device. It's quite possible the sdev can't eventually dispatch a request,
    then the sdev will be in starved list tail. This isn't fair.
    There are two cases here:
    1. unplug path. scsi_request_fn() calls to scsi_target_queue_ready(), then
    the dev is removed from starved list, but quite possible host queue isn't
    ready, the dev is moved to starved list without dispatching any request.
    2. scsi_run_queue path. It deletes the dev from starved list first (both
    global and local starved lists), then handles the dev. Then we could have
    the same process like case 1.
    
    This patch fixes the first case. Case 2 isn't fixed, because there is a
    rare case scsi_run_queue finds host isn't busy but scsi_request_fn finds
    host is busy (other CPU is faster to get host queue depth). Not deleting
    the dev from starved list in scsi_run_queue will keep scsi_run_queue
    looping (though this is very rare case, because host will become busy).
    Fortunately fixing case 1 already gives big improvement for starvation in
    my test. In a 12 disk JBOD setup, running file creation under EXT4, this
    gives 12% more throughput.
    
    Signed-off-by: Shaohua Li <shaohua.li@intel.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f85cfa6c47b5..b2c95dbe9d65 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1316,15 +1316,10 @@ static inline int scsi_target_queue_ready(struct Scsi_Host *shost,
 	}
 
 	if (scsi_target_is_busy(starget)) {
-		if (list_empty(&sdev->starved_entry))
-			list_add_tail(&sdev->starved_entry,
-				      &shost->starved_list);
+		list_move_tail(&sdev->starved_entry, &shost->starved_list);
 		return 0;
 	}
 
-	/* We're OK to process the command, so we can't be starved */
-	if (!list_empty(&sdev->starved_entry))
-		list_del_init(&sdev->starved_entry);
 	return 1;
 }
 

commit 745718132c3c7cac98a622b610e239dcd5217f71
Author: Hannes Reinecke <hare@suse.de>
Date:   Wed Nov 9 08:39:24 2011 +0100

    [SCSI] Silencing 'killing requests for dead queue'
    
    When we tear down a device we try to flush all outstanding
    commands in scsi_free_queue(). However the check in
    scsi_request_fn() is imperfect as it only signals that
    we _might start_ aborting commands, not that we've actually
    aborted some.
    So move the printk inside the scsi_kill_request function,
    this will also give us a hint about which commands are aborted.
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 06bc26554a67..f85cfa6c47b5 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1409,6 +1409,8 @@ static void scsi_kill_request(struct request *req, struct request_queue *q)
 
 	blk_start_request(req);
 
+	scmd_printk(KERN_INFO, cmd, "killing request\n");
+
 	sdev = cmd->device;
 	starget = scsi_target(sdev);
 	shost = sdev->host;
@@ -1490,7 +1492,6 @@ static void scsi_request_fn(struct request_queue *q)
 	struct request *req;
 
 	if (!sdev) {
-		printk("scsi: killing requests for dead queue\n");
 		while ((req = blk_peek_request(q)) != NULL)
 			scsi_kill_request(req, q);
 		return;

commit 32aaeffbd4a7457bf2f7448b33b5946ff2a960eb
Merge: 208bca086040 67b84999b1a8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Nov 6 19:44:47 2011 -0800

    Merge branch 'modsplit-Oct31_2011' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux
    
    * 'modsplit-Oct31_2011' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux: (230 commits)
      Revert "tracing: Include module.h in define_trace.h"
      irq: don't put module.h into irq.h for tracking irqgen modules.
      bluetooth: macroize two small inlines to avoid module.h
      ip_vs.h: fix implicit use of module_get/module_put from module.h
      nf_conntrack.h: fix up fallout from implicit moduleparam.h presence
      include: replace linux/module.h with "struct module" wherever possible
      include: convert various register fcns to macros to avoid include chaining
      crypto.h: remove unused crypto_tfm_alg_modname() inline
      uwb.h: fix implicit use of asm/page.h for PAGE_SIZE
      pm_runtime.h: explicitly requires notifier.h
      linux/dmaengine.h: fix implicit use of bitmap.h and asm/page.h
      miscdevice.h: fix up implicit use of lists and types
      stop_machine.h: fix implicit use of smp.h for smp_processor_id
      of: fix implicit use of errno.h in include/linux/of.h
      of_platform.h: delete needless include <linux/module.h>
      acpi: remove module.h include from platform/aclinux.h
      miscdevice.h: delete unnecessary inclusion of module.h
      device_cgroup.h: delete needless include <linux/module.h>
      net: sch_generic remove redundant use of <linux/module.h>
      net: inet_timewait_sock doesnt need <linux/module.h>
      ...
    
    Fix up trivial conflicts (other header files, and  removal of the ab3550 mfd driver) in
     - drivers/media/dvb/frontends/dibx000_common.c
     - drivers/media/video/{mt9m111.c,ov6650.c}
     - drivers/mfd/ab3550-core.c
     - include/linux/dmaengine.h

commit 09703660edf83b8b6d175440bf745f30580d85ab
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Fri May 27 09:37:25 2011 -0400

    scsi: Add export.h for EXPORT_SYMBOL/THIS_MODULE as required
    
    For the basic SCSI infrastructure files that are exporting symbols
    but not modules themselves, add in the basic export.h header file
    to allow the exports.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index fc3f168decb4..cdd3436f2ecb 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -12,6 +12,7 @@
 #include <linux/blkdev.h>
 #include <linux/completion.h>
 #include <linux/kernel.h>
+#include <linux/export.h>
 #include <linux/mempool.h>
 #include <linux/slab.h>
 #include <linux/init.h>

commit 3308511c93e6ad0d3c58984ecd6e5e57f96b12c8
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Fri Sep 23 19:48:18 2011 +0200

    [SCSI] Make scsi_free_queue() kill pending SCSI commands
    
    Make sure that SCSI device removal via scsi_remove_host() does finish
    all pending SCSI commands. Currently that's not the case and hence
    removal of a SCSI host during I/O can cause a deadlock. See also
    "blkdev_issue_discard() hangs forever if underlying storage device is
    removed" (http://bugzilla.kernel.org/show_bug.cgi?id=40472). See also
    http://lkml.org/lkml/2011/8/27/6.
    
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Cc: <stable@kernel.org>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index fc3f168decb4..b4d43ae76132 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1698,6 +1698,15 @@ struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
 
 void scsi_free_queue(struct request_queue *q)
 {
+	unsigned long flags;
+
+	WARN_ON(q->queuedata);
+
+	/* cause scsi_request_fn() to kill all non-finished requests */
+	spin_lock_irqsave(q->queue_lock, flags);
+	q->request_fn(q);
+	spin_unlock_irqrestore(q->queue_lock, flags);
+
 	blk_cleanup_queue(q);
 }
 

commit 573e5913536a1393362265cfea9e708aa10fdf16
Author: James Smart <james.smart@emulex.com>
Date:   Wed Jul 6 12:45:17 2011 -0400

    [SCSI] scsi_lib: pause between error retries
    
    During cable pull tests on our 16G FC adapter, we are seeing errors,
    typically reads to close targets, which fail due to CRC or framing
    errors caused by the cable being pull (return status DID_ERROR).
    The adapter detects the error on one of the first frames received,
    marks the FC exchange as dead (further frames go to bit bucket) and
    signals the host of the error. This action is so quick, and coupled
    with fast host CPUs, creates a scenario in which the midlayer sees
    the failure and retries the io almost immediately. We've seen link
    traces with the retry on the link while the original i/o is still
    being processed by the target. We're also seeing the time window
    for the "link to pull-apart" and the physical interface to report
    disconnected to be in the few millisecond range. Which means, we're
    encountering scenarios where the full retry count is exhausted
    (all with error) by the midlayer before the link disconnect state
    is detected.
    
    We looked at 8G FC behavior and occasionally see the same behavior,
    but as the link was slower, it rarely could exhaust all retries
    before the link reported disconnect.
    
    What is needed is a slight delay between io retries due to DID_ERROR
    to cover this error.  It is inappropriate to put this delay in the
    driver, as the error is indistinguishable from other link-related errors,
    nor does the driver track whether the io is a retry or not. This is also
    easier than tracking between-io-error bursts that are seen in this
    scenario.
    
    The patch below updates the retry path so that it inserts a delay as
    if the target was busy.  The busy delay is on the order of 6ms. This
    delay is sufficient to ensure the link down condition is reported
    before the retry count is exhausted (at most 1 retry is seen).
    
    Signed-off-by: Alex Iannicelli <alex.iannicelli@emulex.com>
    Signed-off-by: James Smart <james.smart@emulex.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 28d9c9d6b4b4..fc3f168decb4 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -137,6 +137,7 @@ static int __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
 		host->host_blocked = host->max_host_blocked;
 		break;
 	case SCSI_MLQUEUE_DEVICE_BUSY:
+	case SCSI_MLQUEUE_EH_RETRY:
 		device->device_blocked = device->max_device_blocked;
 		break;
 	case SCSI_MLQUEUE_TARGET_BUSY:

commit bfe159a51203c15d23cb3158fffdc25ec4b4dda1
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Thu Jul 7 15:45:40 2011 -0500

    [SCSI] fix crash in scsi_dispatch_cmd()
    
    USB surprise removal of sr is triggering an oops in
    scsi_dispatch_command().  What seems to be happening is that USB is
    hanging on to a queue reference until the last close of the upper
    device, so the crash is caused by surprise remove of a mounted CD
    followed by attempted unmount.
    
    The problem is that USB doesn't issue its final commands as part of
    the SCSI teardown path, but on last close when the block queue is long
    gone.  The long term fix is probably to make sr do the teardown in the
    same way as sd (so remove all the lower bits on ejection, but keep the
    upper disk alive until last close of user space).  However, the
    current oops can be simply fixed by not allowing any commands to be
    sent to a dead queue.
    
    Cc: stable@kernel.org
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ec1803a48723..28d9c9d6b4b4 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -213,6 +213,8 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	int ret = DRIVER_ERROR << 24;
 
 	req = blk_get_request(sdev->request_queue, write, __GFP_WAIT);
+	if (!req)
+		return ret;
 
 	if (bufflen &&	blk_rq_map_kern(sdev->request_queue, req,
 					buffer, bufflen, __GFP_WAIT))

commit a2b9c1f6208126e6df6c02428c501f8853685812
Merge: 2e9521fd656f 3ec717b7ca4e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 18 06:49:02 2011 -0700

    Merge branch 'for-linus' of git://git.kernel.dk/linux-2.6-block
    
    * 'for-linus' of git://git.kernel.dk/linux-2.6-block:
      block: don't delay blk_run_queue_async
      scsi: remove performance regression due to async queue run
      blk-throttle: Use task_subsys_state() to determine a task's blkio_cgroup
      block: rescan partitions on invalidated devices on -ENOMEDIA too
      cdrom: always check_disk_change() on open
      block: unexport DISK_EVENT_MEDIA_CHANGE for legacy/fringe drivers

commit 9937a5e2f32892db0dbeefc2b3bc74b3ae3ea9c7
Author: Jens Axboe <jaxboe@fusionio.com>
Date:   Tue May 17 11:04:44 2011 +0200

    scsi: remove performance regression due to async queue run
    
    Commit c21e6beb removed our queue request_fn re-enter
    protection, and defaulted to always running the queues from
    kblockd to be safe. This was a known potential slow down,
    but should be safe.
    
    Unfortunately this is causing big performance regressions for
    some, so we need to improve this logic. Looking into the details
    of the re-enter, the real issue is on requeue of requests.
    
    Requeue of requests upon seeing a BUSY condition from the device
    ends up re-running the queue, causing traces like this:
    
    scsi_request_fn()
            scsi_dispatch_cmd()
                    scsi_queue_insert()
                            __scsi_queue_insert()
                                    scsi_run_queue()
                                            scsi_request_fn()
                                                    ...
    
    potentially causing the issue we want to avoid. So special
    case the requeue re-run of the queue, but improve it to offload
    the entire run of local queue and starved queue from a single
    workqueue callback. This is a lot better than potentially
    kicking off a workqueue run for each device seen.
    
    This also fixes the issue of the local device going into recursion,
    since the above mentioned commit never moved that queue run out
    of line.
    
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e9901b8f8443..01e4e51c4b68 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -74,8 +74,6 @@ struct kmem_cache *scsi_sdb_cache;
  */
 #define SCSI_QUEUE_DELAY	3
 
-static void scsi_run_queue(struct request_queue *q);
-
 /*
  * Function:	scsi_unprep_request()
  *
@@ -161,7 +159,7 @@ static int __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
 	blk_requeue_request(q, cmd->request);
 	spin_unlock_irqrestore(q->queue_lock, flags);
 
-	scsi_run_queue(q);
+	kblockd_schedule_work(q, &device->requeue_work);
 
 	return 0;
 }
@@ -433,7 +431,11 @@ static void scsi_run_queue(struct request_queue *q)
 			continue;
 		}
 
-		blk_run_queue_async(sdev->request_queue);
+		spin_unlock(shost->host_lock);
+		spin_lock(sdev->request_queue->queue_lock);
+		__blk_run_queue(sdev->request_queue);
+		spin_unlock(sdev->request_queue->queue_lock);
+		spin_lock(shost->host_lock);
 	}
 	/* put any unprocessed entries back */
 	list_splice(&starved_list, &shost->starved_list);
@@ -442,6 +444,16 @@ static void scsi_run_queue(struct request_queue *q)
 	blk_run_queue(q);
 }
 
+void scsi_requeue_run_queue(struct work_struct *work)
+{
+	struct scsi_device *sdev;
+	struct request_queue *q;
+
+	sdev = container_of(work, struct scsi_device, requeue_work);
+	q = sdev->request_queue;
+	scsi_run_queue(q);
+}
+
 /*
  * Function:	scsi_requeue_command()
  *

commit c055f5b2614b4f758ae6cc86733f31fa4c2c5844
Author: James Bottomley <James.Bottomley@suse.de>
Date:   Sun May 1 09:42:07 2011 -0500

    [SCSI] fix oops in scsi_run_queue()
    
    The recent commit closing the race window in device teardown:
    
    commit 86cbfb5607d4b81b1a993ff689bbd2addd5d3a9b
    Author: James Bottomley <James.Bottomley@suse.de>
    Date:   Fri Apr 22 10:39:59 2011 -0500
    
        [SCSI] put stricter guards on queue dead checks
    
    is causing a potential NULL deref in scsi_run_queue() because the
    q->queuedata may already be NULL by the time this function is called.
    Since we shouldn't be running a queue that is being torn down, simply
    add a NULL check in scsi_run_queue() to forestall this.
    
    Tested-by: Jim Schutt <jaschut@sandia.gov>
    Cc: stable@kernel.org
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e9901b8f8443..0bac91e72370 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -400,10 +400,15 @@ static inline int scsi_host_is_busy(struct Scsi_Host *shost)
 static void scsi_run_queue(struct request_queue *q)
 {
 	struct scsi_device *sdev = q->queuedata;
-	struct Scsi_Host *shost = sdev->host;
+	struct Scsi_Host *shost;
 	LIST_HEAD(starved_list);
 	unsigned long flags;
 
+	/* if the device is dead, sdev will be NULL, so no queue to run */
+	if (!sdev)
+		return;
+
+	shost = sdev->host;
 	if (scsi_target(sdev)->single_lun)
 		scsi_single_lun_run(sdev);
 

commit c21e6beba8835d09bb80e34961430b13e60381c5
Author: Jens Axboe <jaxboe@fusionio.com>
Date:   Tue Apr 19 13:32:46 2011 +0200

    block: get rid of QUEUE_FLAG_REENTER
    
    We are currently using this flag to check whether it's safe
    to call into ->request_fn(). If it is set, we punt to kblockd.
    But we get a lot of false positives and excessive punts to
    kblockd, which hurts performance.
    
    The only real abuser of this infrastructure is SCSI. So export
    the async queue run and convert SCSI over to use that. There's
    room for improvement in that SCSI need not always use the async
    call, but this fixes our performance issue and they can fix that
    up in due time.
    
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ab55c2fa7ce2..e9901b8f8443 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -411,8 +411,6 @@ static void scsi_run_queue(struct request_queue *q)
 	list_splice_init(&shost->starved_list, &starved_list);
 
 	while (!list_empty(&starved_list)) {
-		int flagset;
-
 		/*
 		 * As long as shost is accepting commands and we have
 		 * starved queues, call blk_run_queue. scsi_request_fn
@@ -435,20 +433,7 @@ static void scsi_run_queue(struct request_queue *q)
 			continue;
 		}
 
-		spin_unlock(shost->host_lock);
-
-		spin_lock(sdev->request_queue->queue_lock);
-		flagset = test_bit(QUEUE_FLAG_REENTER, &q->queue_flags) &&
-				!test_bit(QUEUE_FLAG_REENTER,
-					&sdev->request_queue->queue_flags);
-		if (flagset)
-			queue_flag_set(QUEUE_FLAG_REENTER, sdev->request_queue);
-		__blk_run_queue(sdev->request_queue);
-		if (flagset)
-			queue_flag_clear(QUEUE_FLAG_REENTER, sdev->request_queue);
-		spin_unlock(sdev->request_queue->queue_lock);
-
-		spin_lock(shost->host_lock);
+		blk_run_queue_async(sdev->request_queue);
 	}
 	/* put any unprocessed entries back */
 	list_splice(&starved_list, &shost->starved_list);

commit 24ecfbe27f65563909b14492afda2f1c21f7c044
Author: Christoph Hellwig <hch@infradead.org>
Date:   Mon Apr 18 11:41:33 2011 +0200

    block: add blk_run_queue_async
    
    Instead of overloading __blk_run_queue to force an offload to kblockd
    add a new blk_run_queue_async helper to do it explicitly.  I've kept
    the blk_queue_stopped check for now, but I suspect it's not needed
    as the check we do when the workqueue items runs should be enough.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 6d5c7ff43f5b..ab55c2fa7ce2 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -443,7 +443,7 @@ static void scsi_run_queue(struct request_queue *q)
 					&sdev->request_queue->queue_flags);
 		if (flagset)
 			queue_flag_set(QUEUE_FLAG_REENTER, sdev->request_queue);
-		__blk_run_queue(sdev->request_queue, false);
+		__blk_run_queue(sdev->request_queue);
 		if (flagset)
 			queue_flag_clear(QUEUE_FLAG_REENTER, sdev->request_queue);
 		spin_unlock(sdev->request_queue->queue_lock);

commit 6c5103890057b1bb781b26b7aae38d33e4c517d8
Merge: 3dab04e6978e 9d2e157d970a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 24 10:16:26 2011 -0700

    Merge branch 'for-2.6.39/core' of git://git.kernel.dk/linux-2.6-block
    
    * 'for-2.6.39/core' of git://git.kernel.dk/linux-2.6-block: (65 commits)
      Documentation/iostats.txt: bit-size reference etc.
      cfq-iosched: removing unnecessary think time checking
      cfq-iosched: Don't clear queue stats when preempt.
      blk-throttle: Reset group slice when limits are changed
      blk-cgroup: Only give unaccounted_time under debug
      cfq-iosched: Don't set active queue in preempt
      block: fix non-atomic access to genhd inflight structures
      block: attempt to merge with existing requests on plug flush
      block: NULL dereference on error path in __blkdev_get()
      cfq-iosched: Don't update group weights when on service tree
      fs: assign sb->s_bdi to default_backing_dev_info if the bdi is going away
      block: Require subsystems to explicitly allocate bio_set integrity mempool
      jbd2: finish conversion from WRITE_SYNC_PLUG to WRITE_SYNC and explicit plugging
      jbd: finish conversion from WRITE_SYNC_PLUG to WRITE_SYNC and explicit plugging
      fs: make fsync_buffers_list() plug
      mm: make generic_writepages() use plugging
      blk-cgroup: Add unaccounted time to timeslice_used.
      block: fixup plugging stubs for !CONFIG_BLOCK
      block: remove obsolete comments for blkdev_issue_zeroout.
      blktrace: Use rq->cmd_flags directly in blk_add_trace_rq.
      ...
    
    Fix up conflicts in fs/{aio.c,super.c}

commit c55d267de274d308927b60c3e740c1a826832317
Merge: 61ef46fd45c3 bc898c97f7ba
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 17 17:54:40 2011 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6: (170 commits)
      [SCSI] scsi_dh_rdac: Add MD36xxf into device list
      [SCSI] scsi_debug: add consecutive medium errors
      [SCSI] libsas: fix ata list corruption issue
      [SCSI] hpsa: export resettable host attribute
      [SCSI] hpsa: move device attributes to avoid forward declarations
      [SCSI] scsi_debug: Logical Block Provisioning (SBC3r26)
      [SCSI] sd: Logical Block Provisioning update
      [SCSI] Include protection operation in SCSI command trace
      [SCSI] hpsa: fix incorrect PCI IDs and add two new ones (2nd try)
      [SCSI] target: Fix volume size misreporting for volumes > 2TB
      [SCSI] bnx2fc: Broadcom FCoE offload driver
      [SCSI] fcoe: fix broken fcoe interface reset
      [SCSI] fcoe: precedence bug in fcoe_filter_frames()
      [SCSI] libfcoe: Remove stale fcoe-netdev entries
      [SCSI] libfcoe: Move FCOE_MTU definition from fcoe.h to libfcoe.h
      [SCSI] libfc: introduce __fc_fill_fc_hdr that accepts fc_hdr as an argument
      [SCSI] fcoe, libfc: initialize EM anchors list and then update npiv EMs
      [SCSI] Revert "[SCSI] libfc: fix exchange being deleted when the abort itself is timed out"
      [SCSI] libfc: Fixing a memory leak when destroying an interface
      [SCSI] megaraid_sas: Version and Changelog update
      ...
    
    Fix up trivial conflicts due to whitespace differences in
    drivers/scsi/libsas/{sas_ata.c,sas_scsi_host.c}

commit c98a0eb0e90d1caa8a92913cd45462102cbd5eaf
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Tue Mar 8 02:07:15 2011 -0500

    [SCSI] sd: Logical Block Provisioning update
    
    SBC3r26 contains many changes to the Logical Block Provisioning
    interfaces (formerly known as Thin Provisioning ditto). This patch
    implements support for both the old and new schemes using the same
    heuristic as before (whether the LBP VPD page is present).
    
    The new code also allows the provisioning mode (i.e. choice of command)
    to be overridden on a per-device basis via sysfs. Two additional modes
    are supported in this version:
    
     - WRITE SAME(10) with the UNMAP bit set
    
     - WRITE SAME(10) without the UNMAP bit set. This allows us to support
       devices that predate the TP/LBP enhancements in SBC3 and which work
       by way zero-detection
    
    Switching between modes has been consolidated in a helper function that
    also updates the block layer topology according to the limitations of
    the chosen command.
    
    I experimented with trying WRITE SAME(16) if UNMAP fails, WRITE SAME(10)
    if WRITE SAME(16) fails, etc. but found several devices that got
    cranky. So for now we'll disable discard if one of the commands
    fail. The user still has the option of selecting a different mode in
    sysfs.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e531acfd98a2..3829bf058aef 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -867,6 +867,13 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				description = "Host Data Integrity Failure";
 				action = ACTION_FAIL;
 				error = -EILSEQ;
+			/* INVALID COMMAND OPCODE or INVALID FIELD IN CDB */
+			} else if ((sshdr.asc == 0x20 || sshdr.asc == 0x24) &&
+				   (cmd->cmnd[0] == UNMAP ||
+				    cmd->cmnd[0] == WRITE_SAME_16 ||
+				    cmd->cmnd[0] == WRITE_SAME)) {
+				description = "Discard failure";
+				action = ACTION_FAIL;
 			} else
 				action = ACTION_FAIL;
 			break;

commit 72f7d322fd60ce1a0579136dec7b26b0801ded4b
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Tue Mar 8 02:03:59 2011 -0500

    [SCSI] Include protection operation in SCSI command trace
    
    When debugging DIF/DIX it is very helpful to be able to see which DIX
    operation is associated with the scsi_cmnd. Include the protection op in
    the SCSI command trace.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 8d4ef8efa3cd..e531acfd98a2 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1062,6 +1062,7 @@ static struct scsi_cmnd *scsi_get_cmd_from_req(struct scsi_device *sdev,
 	cmd->request = req;
 
 	cmd->cmnd = req->cmd;
+	cmd->prot_op = SCSI_PROT_NORMAL;
 
 	return cmd;
 }

commit 4c63f5646e405b5010cc9499419060bf2e838f5b
Merge: cafb0bfca1a7 69d60eb96ae8
Author: Jens Axboe <jaxboe@fusionio.com>
Date:   Thu Mar 10 08:58:35 2011 +0100

    Merge branch 'for-2.6.39/stack-plug' into for-2.6.39/core
    
    Conflicts:
            block/blk-core.c
            block/blk-flush.c
            drivers/md/raid1.c
            drivers/md/raid10.c
            drivers/md/raid5.c
            fs/nilfs2/btnode.c
            fs/nilfs2/mdt.c
    
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

commit a488e74976bf0a9bccecdd094378394942dacef1
Author: Jens Axboe <jaxboe@fusionio.com>
Date:   Fri Apr 16 21:13:15 2010 +0200

    scsi: convert to blk_delay_queue()
    
    It was always abuse to reuse the plugging infrastructure for this,
    convert it to the (new) real API for delaying queueing a bit. A
    default delay of 3 msec is defined, to match the previous
    behaviour.
    
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9045c52abd25..5a0ae7a944ce 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -67,6 +67,13 @@ static struct scsi_host_sg_pool scsi_sg_pools[] = {
 
 struct kmem_cache *scsi_sdb_cache;
 
+/*
+ * When to reinvoke queueing after a resource shortage. It's 3 msecs to
+ * not change behaviour from the previous unplug mechanism, experimentation
+ * may prove this needs changing.
+ */
+#define SCSI_QUEUE_DELAY	3
+
 static void scsi_run_queue(struct request_queue *q);
 
 /*
@@ -149,14 +156,7 @@ static int __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
 	/*
 	 * Requeue this command.  It will go before all other commands
 	 * that are already in the queue.
-	 *
-	 * NOTE: there is magic here about the way the queue is plugged if
-	 * we have no outstanding commands.
-	 * 
-	 * Although we *don't* plug the queue, we call the request
-	 * function.  The SCSI request function detects the blocked condition
-	 * and plugs the queue appropriately.
-         */
+	 */
 	spin_lock_irqsave(q->queue_lock, flags);
 	blk_requeue_request(q, cmd->request);
 	spin_unlock_irqrestore(q->queue_lock, flags);
@@ -1194,11 +1194,11 @@ int scsi_prep_return(struct request_queue *q, struct request *req, int ret)
 	case BLKPREP_DEFER:
 		/*
 		 * If we defer, the blk_peek_request() returns NULL, but the
-		 * queue must be restarted, so we plug here if no returning
-		 * command will automatically do that.
+		 * queue must be restarted, so we schedule a callback to happen
+		 * shortly.
 		 */
 		if (sdev->device_busy == 0)
-			blk_plug_device(q);
+			blk_delay_queue(q, SCSI_QUEUE_DELAY);
 		break;
 	default:
 		req->cmd_flags |= REQ_DONTPREP;
@@ -1237,7 +1237,7 @@ static inline int scsi_dev_queue_ready(struct request_queue *q,
 				   sdev_printk(KERN_INFO, sdev,
 				   "unblocking device at zero depth\n"));
 		} else {
-			blk_plug_device(q);
+			blk_delay_queue(q, SCSI_QUEUE_DELAY);
 			return 0;
 		}
 	}
@@ -1467,7 +1467,7 @@ static void scsi_request_fn(struct request_queue *q)
 	 * the host is no longer able to accept any more requests.
 	 */
 	shost = sdev->host;
-	while (!blk_queue_plugged(q)) {
+	for (;;) {
 		int rtn;
 		/*
 		 * get next queueable request.  We do this early to make sure
@@ -1546,15 +1546,8 @@ static void scsi_request_fn(struct request_queue *q)
 		 */
 		rtn = scsi_dispatch_cmd(cmd);
 		spin_lock_irq(q->queue_lock);
-		if(rtn) {
-			/* we're refusing the command; because of
-			 * the way locks get dropped, we need to 
-			 * check here if plugging is required */
-			if(sdev->device_busy == 0)
-				blk_plug_device(q);
-
-			break;
-		}
+		if (rtn)
+			goto out_delay;
 	}
 
 	goto out;
@@ -1573,9 +1566,10 @@ static void scsi_request_fn(struct request_queue *q)
 	spin_lock_irq(q->queue_lock);
 	blk_requeue_request(q, req);
 	sdev->device_busy--;
-	if(sdev->device_busy == 0)
-		blk_plug_device(q);
- out:
+out_delay:
+	if (sdev->device_busy == 0)
+		blk_delay_queue(q, SCSI_QUEUE_DELAY);
+out:
 	/* must be careful here...if we trigger the ->remove() function
 	 * we cannot be holding the q lock */
 	spin_unlock_irq(q->queue_lock);

commit 1654e7411a1ad4999fe7890ef51d2a2bbb1fcf76
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 2 08:48:05 2011 -0500

    block: add @force_kblockd to __blk_run_queue()
    
    __blk_run_queue() automatically either calls q->request_fn() directly
    or schedules kblockd depending on whether the function is recursed.
    blk-flush implementation needs to be able to explicitly choose
    kblockd.  Add @force_kblockd.
    
    All the current users are converted to specify %false for the
    parameter and this patch doesn't introduce any behavior change.
    
    stable: This is prerequisite for fixing ide oops caused by the new
            blk-flush implementation.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Jan Beulich <JBeulich@novell.com>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Cc: stable@kernel.org
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9045c52abd25..fb2bb35c62cb 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -443,7 +443,7 @@ static void scsi_run_queue(struct request_queue *q)
 					&sdev->request_queue->queue_flags);
 		if (flagset)
 			queue_flag_set(QUEUE_FLAG_REENTER, sdev->request_queue);
-		__blk_run_queue(sdev->request_queue);
+		__blk_run_queue(sdev->request_queue, false);
 		if (flagset)
 			queue_flag_clear(QUEUE_FLAG_REENTER, sdev->request_queue);
 		spin_unlock(sdev->request_queue->queue_lock);

commit 63583cca745f440167bf27877182dc13e19d4bcf
Author: Hannes Reinecke <hare@suse.de>
Date:   Tue Jan 18 10:13:11 2011 +0100

    [SCSI] Add detailed SCSI I/O errors
    
    Instead of just passing 'EIO' for any I/O error we should be
    notifying the upper layers with more details about the cause
    of this error.
    
    Update the possible I/O errors to:
    
    - ENOLINK: Link failure between host and target
    - EIO: Retryable I/O error
    - EREMOTEIO: Non-retryable I/O error
    - EBADE: I/O error restricted to the I_T_L nexus
    
    'Retryable' in this context means that an I/O error _might_ be
    restricted to the I_T_L nexus (vulgo: path), so retrying on another
    nexus / path might succeed.
    
    'Non-retryable' in general refers to a target failure, so this
    error will always be generated regardless of the I_T_L nexus
    it was send on.
    
    I/O errors restricted to the I_T_L nexus might be retried
    on another nexus / path, but they should _not_ be queued
    if no paths are available.
    
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9045c52abd25..8d4ef8efa3cd 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -667,6 +667,30 @@ void scsi_release_buffers(struct scsi_cmnd *cmd)
 }
 EXPORT_SYMBOL(scsi_release_buffers);
 
+static int __scsi_error_from_host_byte(struct scsi_cmnd *cmd, int result)
+{
+	int error = 0;
+
+	switch(host_byte(result)) {
+	case DID_TRANSPORT_FAILFAST:
+		error = -ENOLINK;
+		break;
+	case DID_TARGET_FAILURE:
+		cmd->result |= (DID_OK << 16);
+		error = -EREMOTEIO;
+		break;
+	case DID_NEXUS_FAILURE:
+		cmd->result |= (DID_OK << 16);
+		error = -EBADE;
+		break;
+	default:
+		error = -EIO;
+		break;
+	}
+
+	return error;
+}
+
 /*
  * Function:    scsi_io_completion()
  *
@@ -737,7 +761,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				req->sense_len = len;
 			}
 			if (!sense_deferred)
-				error = -EIO;
+				error = __scsi_error_from_host_byte(cmd, result);
 		}
 
 		req->resid_len = scsi_get_resid(cmd);
@@ -796,7 +820,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	if (scsi_end_request(cmd, error, good_bytes, result == 0) == NULL)
 		return;
 
-	error = -EIO;
+	error = __scsi_error_from_host_byte(cmd, result);
 
 	if (host_byte(result) == DID_RESET) {
 		/* Third party bus reset or reset for error recovery

commit 275220f0fcff1adf28a717076e00f575edf05fda
Merge: fe3c560b8a22 81c5e2ae33c4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 13 10:45:01 2011 -0800

    Merge branch 'for-2.6.38/core' of git://git.kernel.dk/linux-2.6-block
    
    * 'for-2.6.38/core' of git://git.kernel.dk/linux-2.6-block: (43 commits)
      block: ensure that completion error gets properly traced
      blktrace: add missing probe argument to block_bio_complete
      block cfq: don't use atomic_t for cfq_group
      block cfq: don't use atomic_t for cfq_queue
      block: trace event block fix unassigned field
      block: add internal hd part table references
      block: fix accounting bug on cross partition merges
      kref: add kref_test_and_get
      bio-integrity: mark kintegrityd_wq highpri and CPU intensive
      block: make kblockd_workqueue smarter
      Revert "sd: implement sd_check_events()"
      block: Clean up exit_io_context() source code.
      Fix compile warnings due to missing removal of a 'ret' variable
      fs/block: type signature of major_to_index(int) to major_to_index(unsigned)
      block: convert !IS_ERR(p) && p to !IS_ERR_NOR_NULL(p)
      cfq-iosched: don't check cfqg in choose_service_tree()
      fs/splice: Pull buf->ops->confirm() from splice_from_pipe actors
      cdrom: export cdrom_check_events()
      sd: implement sd_check_events()
      sr: implement sr_check_events()
      ...

commit da40d036fd716f0efb2917076220814b1e927ae1
Merge: aa58abc20fa8 c32e061fa198
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 7 12:47:02 2011 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6: (147 commits)
      [SCSI] arcmsr: fix write to device check
      [SCSI] lpfc: lower stack use in lpfc_fc_frame_check
      [SCSI] eliminate an unnecessary local variable from scsi_remove_target()
      [SCSI] libiscsi: use bh locking instead of irq with session lock
      [SCSI] libiscsi: do not take host lock in queuecommand
      [SCSI] be2iscsi: fix null ptr when accessing task hdr
      [SCSI] be2iscsi: fix gfp use in alloc_pdu
      [SCSI] libiscsi: add more informative failure message during iscsi scsi eh
      [SCSI] gdth: Add missing call to gdth_ioctl_free
      [SCSI] bfa: remove unused defintions and misc cleanups
      [SCSI] bfa: remove inactive functions
      [SCSI] bfa: replace bfa_assert with WARN_ON
      [SCSI] qla2xxx: Use sg_next to fetch next sg element while walking sg list.
      [SCSI] qla2xxx: Fix to avoid recursive lock failure during BSG timeout.
      [SCSI] qla2xxx: Remove code to not reset ISP82xx on failure.
      [SCSI] qla2xxx: Display mailbox register 4 during 8012 AEN for ISP82XX parts.
      [SCSI] qla2xxx: Don't perform a BIG_HAMMER if Get-ID (0x20) mailbox command fails on CNAs.
      [SCSI] qla2xxx: Remove redundant module parameter permission bits
      [SCSI] qla2xxx: Add sysfs node for displaying board temperature.
      [SCSI] qla2xxx: Code cleanup to remove unwanted comments and code.
      ...

commit fd01a6632da253210c3dbc7814bc6eceda96623d
Author: Hillf Danton <dhillf@gmail.com>
Date:   Thu Dec 16 14:26:37 2010 -0600

    [SCSI] fix the return value of scsi_target_queue_read()
    
    It seems that zero should be returned if scsi_target_is_busy(starget) is
    true, no matter if sdev is on the starved list.
    
    Signed-off-by: Hillf Danton <dhillf@gmail.com>
    Reviewed-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 5b6bbaea59fe..0ed7a66cdded 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1278,11 +1278,10 @@ static inline int scsi_target_queue_ready(struct Scsi_Host *shost,
 	}
 
 	if (scsi_target_is_busy(starget)) {
-		if (list_empty(&sdev->starved_entry)) {
+		if (list_empty(&sdev->starved_entry))
 			list_add_tail(&sdev->starved_entry,
 				      &shost->starved_list);
-			return 0;
-		}
+		return 0;
 	}
 
 	/* We're OK to process the command, so we can't be starved */

commit 7f8635cc9e66a26d7280ba680b044fa2f65104af
Merge: 3cb50ddf97a0 0fc13c8995cd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Dec 20 09:19:46 2010 -0800

    Merge branch 'for-linus' of git://git.kernel.dk/linux-2.6-block
    
    * 'for-linus' of git://git.kernel.dk/linux-2.6-block:
      cciss: fix cciss_revalidate panic
      block: max hardware sectors limit wrapper
      block: Deprecate QUEUE_FLAG_CLUSTER and use queue_limits instead
      blk-throttle: Correct the placement of smp_rmb()
      blk-throttle: Trim/adjust slice_end once a bio has been dispatched
      block: check for proper length of iov entries earlier in blk_rq_map_user_iov()
      drbd: fix for spin_lock_irqsave in endio callback
      drbd: don't recvmsg with zero length

commit e692cb668fdd5a712c6ed2a2d6f2a36ee83997b4
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Wed Dec 1 19:41:49 2010 +0100

    block: Deprecate QUEUE_FLAG_CLUSTER and use queue_limits instead
    
    When stacking devices, a request_queue is not always available. This
    forced us to have a no_cluster flag in the queue_limits that could be
    used as a carrier until the request_queue had been set up for a
    metadevice.
    
    There were several problems with that approach. First of all it was up
    to the stacking device to remember to set queue flag after stacking had
    completed. Also, the queue flag and the queue limits had to be kept in
    sync at all times. We got that wrong, which could lead to us issuing
    commands that went beyond the max scatterlist limit set by the driver.
    
    The proper fix is to avoid having two flags for tracking the same thing.
    We deprecate QUEUE_FLAG_CLUSTER and use the queue limit directly in the
    block layer merging functions. The queue_limit 'no_cluster' is turned
    into 'cluster' to avoid double negatives and to ease stacking.
    Clustering defaults to being enabled as before. The queue flag logic is
    removed from the stacking function, and explicitly setting the cluster
    flag is no longer necessary in DM and MD.
    
    Reported-by: Ed Lin <ed.lin@promise.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Acked-by: Mike Snitzer <snitzer@redhat.com>
    Cc: stable@kernel.org
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index eafeeda6e194..9d7ba07dc5ef 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1642,9 +1642,8 @@ struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
 
 	blk_queue_max_segment_size(q, dma_get_max_seg_size(dev));
 
-	/* New queue, no concurrency on queue_flags */
 	if (!shost->use_clustering)
-		queue_flag_clear_unlocked(QUEUE_FLAG_CLUSTER, q);
+		q->limits.cluster = 0;
 
 	/*
 	 * set a reasonable default alignment on word boundaries: the

commit 9f8a2c23c6c1140f515f601265c4dff7522110b7
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Dec 8 20:57:40 2010 +0100

    scsi: replace sr_test_unit_ready() with scsi_test_unit_ready()
    
    The usage of TUR has been confusing involving several different
    commits updating different parts over time.  Currently, the only
    differences between scsi_test_unit_ready() and sr_test_unit_ready()
    are,
    
    * scsi_test_unit_ready() also sets sdev->changed on NOT_READY.
    
    * scsi_test_unit_ready() returns 0 if TUR ended with UNIT_ATTENTION or
      NOT_READY.
    
    Due to the above two differences, sr is using its own
    sr_test_unit_ready(), but sd - the sole user of the above extra
    handling - doesn't even need them.
    
    Where scsi_test_unit_ready() is used in sd_media_changed(), the code
    is looking for device ready w/ media present state which is true iff
    TUR succeeds w/o sense data or UA, and when the device is not ready
    for whatever reason sd_media_changed() explicitly marks media as
    missing so there's no reason to set sdev->changed automatically from
    scsi_test_unit_ready() on NOT_READY.
    
    Drop both special handlings from scsi_test_unit_ready(), which makes
    it equivalant to sr_test_unit_ready(), and replace
    sr_test_unit_ready() with scsi_test_unit_ready().  Also, drop the
    unnecessary explicit NOT_READY check from sd_media_changed().
    Checking return value is enough for testing device readiness.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index eafeeda6e194..13bf89145b18 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1984,8 +1984,7 @@ EXPORT_SYMBOL(scsi_mode_sense);
  *		in.
  *
  *	Returns zero if unsuccessful or an error if TUR failed.  For
- *	removable media, a return of NOT_READY or UNIT_ATTENTION is
- *	translated to success, with the ->changed flag updated.
+ *	removable media, UNIT_ATTENTION sets ->changed flag.
  **/
 int
 scsi_test_unit_ready(struct scsi_device *sdev, int timeout, int retries,
@@ -2012,16 +2011,6 @@ scsi_test_unit_ready(struct scsi_device *sdev, int timeout, int retries,
 	} while (scsi_sense_valid(sshdr) &&
 		 sshdr->sense_key == UNIT_ATTENTION && --retries);
 
-	if (!sshdr)
-		/* could not allocate sense buffer, so can't process it */
-		return result;
-
-	if (sdev->removable && scsi_sense_valid(sshdr) &&
-	    (sshdr->sense_key == UNIT_ATTENTION ||
-	     sshdr->sense_key == NOT_READY)) {
-		sdev->changed = 1;
-		result = 0;
-	}
 	if (!sshdr_external)
 		kfree(sshdr);
 	return result;

commit 459dbf72e4d2b4aa13620e6b70d54f098547bf13
Author: James Bottomley <James.Bottomley@suse.de>
Date:   Wed Nov 17 10:10:57 2010 -0600

    [SCSI] Eliminate error handler overload of the SCSI serial number
    
    The error handler is using the test cmd->serial_number == 0 in the
    abort routines to signal that the command to be aborted has already
    completed normally.  This design was to close a race window in the
    original error handler where a command could go through the normal
    completion routines after it timed out but before error handling was
    started.
    
    Mike Anderson pointed out that when we converted our timeout and
    softirq completions, we picked up atomicity here because the block
    layer now mediates this with the REQ_ATOM_COMPLETE flag and guarantees
    that *either* the command times out or our done routine is called, but
    ensures we can't get both occurring.  That makes the serial number
    zero check redundant and it can be removed.
    
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index eafeeda6e194..5b6bbaea59fe 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1403,11 +1403,6 @@ static void scsi_softirq_done(struct request *rq)
 
 	INIT_LIST_HEAD(&cmd->eh_entry);
 
-	/*
-	 * Set the serial numbers back to zero
-	 */
-	cmd->serial_number = 0;
-
 	atomic_inc(&cmd->device->iodone_cnt);
 	if (cmd->result)
 		atomic_inc(&cmd->device->ioerr_cnt);

commit 986fe6c7f50974e871b8ab5a800f5310ea25b361
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Wed Oct 6 03:10:59 2010 -0500

    [SCSI] Fix regressions in scsi_internal_device_block
    
    Deleting a SCSI device on a blocked fc_remote_port (before
    fast_io_fail_tmo fires) results in a hanging thread:
    
      STACK:
      0 schedule+1108 [0x5cac48]
      1 schedule_timeout+528 [0x5cb7fc]
      2 wait_for_common+266 [0x5ca6be]
      3 blk_execute_rq+160 [0x354054]
      4 scsi_execute+324 [0x3b7ef4]
      5 scsi_execute_req+162 [0x3b80ca]
      6 sd_sync_cache+138 [0x3cf662]
      7 sd_shutdown+138 [0x3cf91a]
      8 sd_remove+112 [0x3cfe4c]
      9 __device_release_driver+124 [0x3a08b8]
    10 device_release_driver+60 [0x3a0a5c]
    11 bus_remove_device+266 [0x39fa76]
    12 device_del+340 [0x39d818]
    13 __scsi_remove_device+204 [0x3bcc48]
    14 scsi_remove_device+66 [0x3bcc8e]
    15 sysfs_schedule_callback_work+50 [0x260d66]
    16 worker_thread+622 [0x162326]
    17 kthread+160 [0x1680b0]
    18 kernel_thread_starter+6 [0x10aaea]
    
    During the delete, the SCSI device is in moved to SDEV_CANCEL.  When
    the FC transport class later calls scsi_target_unblock, this has no
    effect, since scsi_internal_device_unblock ignores SCSI devics in this
    state.
    
    It looks like all these are regressions caused by:
    5c10e63c943b4c67561ddc6bf61e01d4141f881f
    [SCSI] limit state transitions in scsi_internal_device_unblock
    
    Fix by rejecting offline and cancel in the state transition.
    
    Signed-off-by: Christof Schmitt <christof.schmitt@de.ibm.com>
    [jejb: Original patch by Christof Schmitt, modified by Mike Christie]
    Cc: Stable Tree <stable@kernel.org>
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 8041fe1ab179..eafeeda6e194 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2438,7 +2438,8 @@ scsi_internal_device_unblock(struct scsi_device *sdev)
 		sdev->sdev_state = SDEV_RUNNING;
 	else if (sdev->sdev_state == SDEV_CREATED_BLOCK)
 		sdev->sdev_state = SDEV_CREATED;
-	else
+	else if (sdev->sdev_state != SDEV_CANCEL &&
+		 sdev->sdev_state != SDEV_OFFLINE)
 		return -EINVAL;
 
 	spin_lock_irqsave(q->queue_lock, flags);

commit e9dd2b6837e26fe202708cce5ea4bb4ee3e3482e
Merge: 4f3a29dadaf9 b4627321e185
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 22 17:00:32 2010 -0700

    Merge branch 'for-2.6.37/core' of git://git.kernel.dk/linux-2.6-block
    
    * 'for-2.6.37/core' of git://git.kernel.dk/linux-2.6-block: (39 commits)
      cfq-iosched: Fix a gcc 4.5 warning and put some comments
      block: Turn bvec_k{un,}map_irq() into static inline functions
      block: fix accounting bug on cross partition merges
      block: Make the integrity mapped property a bio flag
      block: Fix double free in blk_integrity_unregister
      block: Ensure physical block size is unsigned int
      blkio-throttle: Fix possible multiplication overflow in iops calculations
      blkio-throttle: limit max iops value to UINT_MAX
      blkio-throttle: There is no need to convert jiffies to milli seconds
      blkio-throttle: Fix link failure failure on i386
      blkio: Recalculate the throttled bio dispatch time upon throttle limit change
      blkio: Add root group to td->tg_list
      blkio: deletion of a cgroup was causes oops
      blkio: Do not export throttle files if CONFIG_BLK_DEV_THROTTLING=n
      block: set the bounce_pfn to the actual DMA limit rather than to max memory
      block: revert bad fix for memory hotplug causing bounces
      Fix compile error in blk-exec.c for !CONFIG_DETECT_HUNG_TASK
      block: set the bounce_pfn to the actual DMA limit rather than to max memory
      block: Prevent hang_check firing during long I/O
      cfq: improve fsync performance for small files
      ...
    
    Fix up trivial conflicts due to __rcu sparse annotation in include/linux/genhd.h

commit 13f05c8d8e98bbdce89158bfdb2e380940695a88
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Fri Sep 10 20:50:10 2010 +0200

    block/scsi: Provide a limit on the number of integrity segments
    
    Some controllers have a hardware limit on the number of protection
    information scatter-gather list segments they can handle.
    
    Introduce a max_integrity_segments limit in the block layer and provide
    a new scsi_host_template setting that allows HBA drivers to provide a
    value suitable for the hardware.
    
    Add support for honoring the integrity segment limit when merging both
    bios and requests.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Jens Axboe <axboe@carl.home.kernel.dk>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9ade720422c6..861c0b937ac9 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -968,11 +968,13 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb,
  */
 int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 {
-	int error = scsi_init_sgtable(cmd->request, &cmd->sdb, gfp_mask);
+	struct request *rq = cmd->request;
+
+	int error = scsi_init_sgtable(rq, &cmd->sdb, gfp_mask);
 	if (error)
 		goto err_exit;
 
-	if (blk_bidi_rq(cmd->request)) {
+	if (blk_bidi_rq(rq)) {
 		struct scsi_data_buffer *bidi_sdb = kmem_cache_zalloc(
 			scsi_sdb_cache, GFP_ATOMIC);
 		if (!bidi_sdb) {
@@ -980,28 +982,28 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 			goto err_exit;
 		}
 
-		cmd->request->next_rq->special = bidi_sdb;
-		error = scsi_init_sgtable(cmd->request->next_rq, bidi_sdb,
-								    GFP_ATOMIC);
+		rq->next_rq->special = bidi_sdb;
+		error = scsi_init_sgtable(rq->next_rq, bidi_sdb, GFP_ATOMIC);
 		if (error)
 			goto err_exit;
 	}
 
-	if (blk_integrity_rq(cmd->request)) {
+	if (blk_integrity_rq(rq)) {
 		struct scsi_data_buffer *prot_sdb = cmd->prot_sdb;
 		int ivecs, count;
 
 		BUG_ON(prot_sdb == NULL);
-		ivecs = blk_rq_count_integrity_sg(cmd->request);
+		ivecs = blk_rq_count_integrity_sg(rq->q, rq->bio);
 
 		if (scsi_alloc_sgtable(prot_sdb, ivecs, gfp_mask)) {
 			error = BLKPREP_DEFER;
 			goto err_exit;
 		}
 
-		count = blk_rq_map_integrity_sg(cmd->request,
+		count = blk_rq_map_integrity_sg(rq->q, rq->bio,
 						prot_sdb->table.sgl);
 		BUG_ON(unlikely(count > ivecs));
+		BUG_ON(unlikely(count > queue_max_integrity_segments(rq->q)));
 
 		cmd->prot_sdb = prot_sdb;
 		cmd->prot_sdb->table.nents = count;
@@ -1625,6 +1627,14 @@ struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
 	blk_queue_max_segments(q, min_t(unsigned short, shost->sg_tablesize,
 					SCSI_MAX_SG_CHAIN_SEGMENTS));
 
+	if (scsi_host_prot_dma(shost)) {
+		shost->sg_prot_tablesize =
+			min_not_zero(shost->sg_prot_tablesize,
+				     (unsigned short)SCSI_MAX_PROT_SG_SEGMENTS);
+		BUG_ON(shost->sg_prot_tablesize < shost->sg_tablesize);
+		blk_queue_max_integrity_segments(q, shost->sg_prot_tablesize);
+	}
+
 	blk_queue_max_hw_sectors(q, shost->max_sectors);
 	blk_queue_bounce_limit(q, scsi_calculate_bounce_limit(shost));
 	blk_queue_segment_boundary(q, shost->dma_boundary);

commit 3a5c19c23db65a554f2e4f5df5f307c668277056
Author: James Bottomley <James.Bottomley@suse.de>
Date:   Mon Aug 16 10:06:26 2010 -0500

    [SCSI] fix use-after-free in scsi_init_io()
    
    we're using a pointer through a freed command to reset the request,
    which has shown up as an oops with slab poisoning:
    
    Reported-by: Tejun Heo <tj@kernel.org>
    Reported-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9ade720422c6..ee02d3838a0a 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1011,8 +1011,8 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 
 err_exit:
 	scsi_release_buffers(cmd);
-	scsi_put_command(cmd);
 	cmd->request->special = NULL;
+	scsi_put_command(cmd);
 	return error;
 }
 EXPORT_SYMBOL(scsi_init_io);

commit d6e9fb46cd9e60946dc3e89ad8e32dd251dcc05d
Author: Bartlomiej Zolnierkiewicz <bzolnier@gmail.com>
Date:   Tue Aug 10 18:01:19 2010 -0700

    scsi: remove superfluous NULL pointer check from scsi_kill_request()
    
    Dan's list included:
    
    drivers/scsi/scsi_lib.c +1365 scsi_kill_request(9) warning: variable derefenced in initializer 'cmd'
    drivers/scsi/scsi_lib.c +1365 scsi_kill_request(9) warning: variable derefenced before check 'cmd'
    
    We dereference cmd (and possible OOPS if cmd == NULL) before starting the
    request so just remove the superfluous debugging code altogether.
    
    [ bart: the potential NULL pointer dereference was finally fixed in
      (much later than mine) commit 03b1470 but my patch is still valid ]
    
    Reported-by: Dan Carpenter <error27@gmail.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Eugene Teo <eteo@redhat.com>
    Signed-off-by: Bartlomiej Zolnierkiewicz <bzolnier@gmail.com>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b8de389636f8..9ade720422c6 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1370,12 +1370,6 @@ static void scsi_kill_request(struct request *req, struct request_queue *q)
 
 	blk_start_request(req);
 
-	if (unlikely(cmd == NULL)) {
-		printk(KERN_CRIT "impossible request in %s.\n",
-				 __func__);
-		BUG();
-	}
-
 	sdev = cmd->device;
 	starget = scsi_target(sdev);
 	shost = sdev->host;

commit 610a63498f7f366031a6327eaaa9963ffa110b2b
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Thu Jul 8 10:16:17 2010 +0200

    scsi: fix discard page leak
    
    We leak a page allocated for discard on some error conditions
    (e.g. scsi_prep_state_check returns BLKPREP_DEFER in
    scsi_setup_blk_pc_cmnd).
    
    We unprep on requests that weren't prepped in the error path of
    scsi_init_io. It makes the error path to clean up scsi commands messy.
    
    Let's strictly apply the rule that we can't unprep on a request that
    wasn't prepped.
    
    Calling just scsi_put_command() in the error path of scsi_init_io() is
    enough. We don't set REQ_DONTPREP yet.
    
    scsi_setup_discard_cmnd can safely free a page on the error case with
    the above rule.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ee836193f531..b8de389636f8 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1011,11 +1011,8 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 
 err_exit:
 	scsi_release_buffers(cmd);
-	if (error == BLKPREP_KILL)
-		scsi_put_command(cmd);
-	else /* BLKPREP_DEFER */
-		scsi_unprep_request(cmd->request);
-
+	scsi_put_command(cmd);
+	cmd->request->special = NULL;
 	return error;
 }
 EXPORT_SYMBOL(scsi_init_io);

commit 28018c242a4ec7017bbbf81d2d3952f820a27118
Author: James Bottomley <James.Bottomley@suse.de>
Date:   Thu Jul 1 19:49:17 2010 +0900

    block: implement an unprep function corresponding directly to prep
    
    Reviewed-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 5f1160841b0e..ee836193f531 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -85,7 +85,7 @@ static void scsi_unprep_request(struct request *req)
 {
 	struct scsi_cmnd *cmd = req->special;
 
-	req->cmd_flags &= ~REQ_DONTPREP;
+	blk_unprep_request(req);
 	req->special = NULL;
 
 	scsi_put_command(cmd);

commit 33659ebbae262228eef4e0fe990f393d1f0ed941
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Aug 7 18:17:56 2010 +0200

    block: remove wrappers for request type/flags
    
    Remove all the trivial wrappers for the cmd_type and cmd_flags fields in
    struct requests.  This allows much easier grepping for different request
    types instead of unwinding through macros.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1646fe7cbd4b..5f1160841b0e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -722,7 +722,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			sense_deferred = scsi_sense_is_deferred(&sshdr);
 	}
 
-	if (blk_pc_request(req)) { /* SG_IO ioctl from block level */
+	if (req->cmd_type == REQ_TYPE_BLOCK_PC) { /* SG_IO ioctl from block level */
 		req->errors = result;
 		if (result) {
 			if (sense_valid && req->sense) {
@@ -757,7 +757,8 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		}
 	}
 
-	BUG_ON(blk_bidi_rq(req)); /* bidi not support for !blk_pc_request yet */
+	/* no bidi support for !REQ_TYPE_BLOCK_PC yet */
+	BUG_ON(blk_bidi_rq(req));
 
 	/*
 	 * Next deal with any sectors which we were able to correctly

commit b1bf9368407ae7e89d8a005bb40beb70a41df539
Merge: 524df5572521 4671a1322052
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Mar 1 09:00:29 2010 -0800

    Merge branch 'for-2.6.34' of git://git.kernel.dk/linux-2.6-block
    
    * 'for-2.6.34' of git://git.kernel.dk/linux-2.6-block: (38 commits)
      block: don't access jiffies when initialising io_context
      cfq: remove 8 bytes of padding from cfq_rb_root on 64 bit builds
      block: fix for "Consolidate phys_segment and hw_segment limits"
      cfq-iosched: quantum check tweak
      blktrace: perform cleanup after setup error
      blkdev: fix merge_bvec_fn return value checks
      cfq-iosched: requests "in flight" vs "in driver" clarification
      cciss: Fix problem with scatter gather elements in the scsi half of the driver
      cciss: eliminate unnecessary pointer use in cciss scsi code
      cciss: do not use void pointer for scsi hba data
      cciss: factor out scatter gather chain block mapping code
      cciss: fix scatter gather chain block dma direction kludge
      cciss: simplify scatter gather code
      cciss: factor out scatter gather chain block allocation and freeing
      cciss: detect bad alignment of scsi commands at build time
      cciss: clarify command list padding calculation
      cfq-iosched: rethink seeky detection for SSDs
      cfq-iosched: rework seeky detection
      block: remove padding from io_context on 64bit builds
      block: Consolidate phys_segment and hw_segment limits
      ...

commit 8a78362c4eefc1deddbefe2c7f38aabbc2429d6b
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Fri Feb 26 00:20:39 2010 -0500

    block: Consolidate phys_segment and hw_segment limits
    
    Except for SCSI no device drivers distinguish between physical and
    hardware segment limits.  Consolidate the two into a single segment
    limit.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ac3cca74bdfb..f8fbf47377ae 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1624,8 +1624,8 @@ struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
 	/*
 	 * this limit is imposed by hardware restrictions
 	 */
-	blk_queue_max_hw_segments(q, shost->sg_tablesize);
-	blk_queue_max_phys_segments(q, SCSI_MAX_SG_CHAIN_SEGMENTS);
+	blk_queue_max_segments(q, min_t(unsigned short, shost->sg_tablesize,
+					SCSI_MAX_SG_CHAIN_SEGMENTS));
 
 	blk_queue_max_hw_sectors(q, shost->max_sectors);
 	blk_queue_bounce_limit(q, scsi_calculate_bounce_limit(shost));

commit 086fa5ff0854c676ec333760f4c0154b3b242616
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Fri Feb 26 00:20:38 2010 -0500

    block: Rename blk_queue_max_sectors to blk_queue_max_hw_sectors
    
    The block layer calling convention is blk_queue_<limit name>.
    blk_queue_max_sectors predates this practice, leading to some confusion.
    Rename the function to appropriately reflect that its intended use is to
    set max_hw_sectors.
    
    Also introduce a temporary wrapper for backwards compability.  This can
    be removed after the merge window is closed.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c6642423cc67..ac3cca74bdfb 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1627,7 +1627,7 @@ struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
 	blk_queue_max_hw_segments(q, shost->sg_tablesize);
 	blk_queue_max_phys_segments(q, SCSI_MAX_SG_CHAIN_SEGMENTS);
 
-	blk_queue_max_sectors(q, shost->max_sectors);
+	blk_queue_max_hw_sectors(q, shost->max_sectors);
 	blk_queue_bounce_limit(q, scsi_calculate_bounce_limit(shost));
 	blk_queue_segment_boundary(q, shost->dma_boundary);
 	dma_set_seg_boundary(dev, shost->dma_boundary);

commit e7efe5932b1d3916c79326a4221693ea90a900e2
Author: Douglas Gilbert <dgilbert@interlog.com>
Date:   Sun Jan 3 13:51:15 2010 -0500

    [SCSI] skip sense logging for some ATA PASS-THROUGH cdbs
    
    Further to the lsml thread titled:
    "does scsi_io_completion need to dump sense data for ata pass through (ck_cond =
    1) ?"
    
    This is a patch to skip logging when the sense data is
    associated with a SENSE_KEY of "RECOVERED_ERROR" and the
    additional sense code is "ATA PASS-THROUGH INFORMATION
    AVAILABLE". This only occurs with the SAT ATA PASS-THROUGH
    commands when CK_COND=1 (in the cdb). It indicates that
    the sense data contains ATA registers.
    
    Smartmontools uses such commands on ATA disks connected via
    SAT. Periodic checks such as those done by smartd cause
    nuisance entries into logs that are:
        - neither errors nor warnings
        - pointless unless the cdb that caused them are also logged
    
    Signed-off-by: Douglas Gilbert <dgilbert@interlog.com>
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c6642423cc67..56977097de9f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -773,8 +773,14 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	 * we already took a copy of the original into rq->errors which
 	 * is what gets returned to the user
 	 */
-	if (sense_valid && sshdr.sense_key == RECOVERED_ERROR) {
-		if (!(req->cmd_flags & REQ_QUIET))
+	if (sense_valid && (sshdr.sense_key == RECOVERED_ERROR)) {
+		/* if ATA PASS-THROUGH INFORMATION AVAILABLE skip
+		 * print since caller wants ATA registers. Only occurs on
+		 * SCSI ATA PASS_THROUGH commands when CK_COND=1
+		 */
+		if ((sshdr.asc == 0x0) && (sshdr.ascq == 0x1d))
+			;
+		else if (!(req->cmd_flags & REQ_QUIET))
 			scsi_print_sense("", cmd);
 		result = 0;
 		/* BLOCK_PC may have set error */

commit 63c43b0ec1765b74c734d465ba6345ef4f434df8
Author: Boaz Harrosh <bharrosh@panasas.com>
Date:   Tue Dec 15 17:25:43 2009 +0200

    [SCSI] scsi_lib: Fix bug in completion of bidi commands
    
    Because of the terrible structuring of scsi-bidi-commands
    it breaks some of the life time rules of a scsi-command.
    It is now not allowed to free up the block-request before
    cleanup and partial deallocation of the scsi-command. (Which
    is not so for none bidi commands)
    
    The right fix to this problem would be to make bidi command
    a first citizen by allocating a scsi_sdb pointer at scsi command
    just like cmd->prot_sdb. The bidi sdb should be allocated/deallocated
    as part of the get/put_command (Again like the prot_sdb) and the
    current decoupling of scsi_cmnd and blk-request should be kept.
    
    For now make sure scsi_release_buffers() is called before the
    call to blk_end_request_all() which might cause the suicide of
    the block requests. At best the leak of bidi buffers, at worse
    a crash, as there is a race between the existence of the bidi_request
    and the free of the associated bidi_sdb.
    
    The reason this was never hit before is because only OSD has the potential
    of doing asynchronous bidi commands. (So does bsg but it is never used)
    And OSD clients just happen to do all their bidi commands synchronously, up
    until recently.
    
    CC: Stable Tree <stable@kernel.org>
    Signed-off-by: Boaz Harrosh <bharrosh@panasas.com>
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d8927681ec88..c6642423cc67 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -749,9 +749,9 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			 */
 			req->next_rq->resid_len = scsi_in(cmd)->resid;
 
+			scsi_release_buffers(cmd);
 			blk_end_request_all(req, 0);
 
-			scsi_release_buffers(cmd);
 			scsi_next_command(cmd);
 			return;
 		}

commit d8705f11d89cfabf4a9f0ea234d4809b22abb33e
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Thu Nov 26 12:00:41 2009 -0500

    [SCSI] Correctly handle thin provisioning write error
    
    A thin provisioned device may temporarily be out of sufficient
    allocation units to fulfill a write request.  In that case it will
    return a space allocation in progress error.  Wait a bit and retry the
    write.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e495d3813948..d8927681ec88 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -859,6 +859,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				case 0x07: /* operation in progress */
 				case 0x08: /* Long write in progress */
 				case 0x09: /* self test in progress */
+				case 0x14: /* space allocation in progress */
 					action = ACTION_DELAYED_RETRY;
 					break;
 				default:

commit 03b147083a2f9a2a3fbbd2505fa88ffa3c6ab194
Author: Jiri Slaby <jirislaby@gmail.com>
Date:   Wed Sep 23 16:15:35 2009 +0200

    [SCSI] scsi_lib: fix potential NULL dereference
    
    Stanse found a potential NULL dereference in scsi_kill_request.
    
    Instead of triggering BUG() in 'if (unlikely(cmd == NULL))' branch,
    the kernel will Oops earlier on cmd dereference.
    
    Move the dereferences after the if.
    
    Signed-off-by: Jiri Slaby <jirislaby@gmail.com>
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 108655230b59..e495d3813948 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1359,9 +1359,9 @@ static int scsi_lld_busy(struct request_queue *q)
 static void scsi_kill_request(struct request *req, struct request_queue *q)
 {
 	struct scsi_cmnd *cmd = req->special;
-	struct scsi_device *sdev = cmd->device;
-	struct scsi_target *starget = scsi_target(sdev);
-	struct Scsi_Host *shost = sdev->host;
+	struct scsi_device *sdev;
+	struct scsi_target *starget;
+	struct Scsi_Host *shost;
 
 	blk_start_request(req);
 
@@ -1371,6 +1371,9 @@ static void scsi_kill_request(struct request *req, struct request_queue *q)
 		BUG();
 	}
 
+	sdev = cmd->device;
+	starget = scsi_target(sdev);
+	shost = sdev->host;
 	scsi_init_cmd_errh(cmd);
 	cmd->result = DID_NO_CONNECT << 16;
 	atomic_inc(&cmd->device->iorequest_cnt);

commit ad63082626f99651d261ccd8698ce4e997362f7e
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Mon Sep 28 15:50:52 2009 -0500

    [SCSI] fix propogation of integrity errors
    
    When the Integrity check is done in scsi_io_completion it will
    set error to -EILSEQ. However, at this point error is no longer
    used, and blk_end_request_err has -EIO hardcoded.
    
    It looks like there was just porting mistake with this patch
    http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commitdiff;h=3e695f89c5debb735e4ff051e9e58d8fb4e95110
    and we meant to send error upwards, so this patch changes the hard
    coded EIO to the error variable.
    
    I have only boot tested this patch.
    
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Acked-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 5987da857103..108655230b59 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -898,7 +898,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				scsi_print_sense("", cmd);
 			scsi_print_command(cmd);
 		}
-		if (blk_end_request_err(req, -EIO))
+		if (blk_end_request_err(req, error))
 			scsi_requeue_command(q, cmd);
 		else
 			scsi_next_command(cmd);

commit 355bbd8cb82e60a592f6cd86ce6dbe5677615cf4
Merge: 39695224bd84 746cd1e7e4a5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Sep 14 17:55:15 2009 -0700

    Merge branch 'for-2.6.32' of git://git.kernel.dk/linux-2.6-block
    
    * 'for-2.6.32' of git://git.kernel.dk/linux-2.6-block: (29 commits)
      block: use blkdev_issue_discard in blk_ioctl_discard
      Make DISCARD_BARRIER and DISCARD_NOBARRIER writes instead of reads
      block: don't assume device has a request list backing in nr_requests store
      block: Optimal I/O limit wrapper
      cfq: choose a new next_req when a request is dispatched
      Seperate read and write statistics of in_flight requests
      aoe: end barrier bios with EOPNOTSUPP
      block: trace bio queueing trial only when it occurs
      block: enable rq CPU completion affinity by default
      cfq: fix the log message after dispatched a request
      block: use printk_once
      cciss: memory leak in cciss_init_one()
      splice: update mtime and atime on files
      block: make blk_iopoll_prep_sched() follow normal 0/1 return convention
      cfq-iosched: get rid of must_alloc flag
      block: use interrupts disabled version of raise_softirq_irqoff()
      block: fix comment in blk-iopoll.c
      block: adjust default budget for blk-iopoll
      block: fix long lines in block/blk-iopoll.c
      block: add blk-iopoll, a NAPI like approach for block devices
      ...

commit da6c5c720c52cc717124f8f0830b710ea6a092fd
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Sep 11 14:26:40 2009 +0200

    scsi,block: update SCSI to handle mixed merge failures
    
    Update scsi_io_completion() such that it only fails requests till the
    next error boundary and retry the leftover.  This enables block layer
    to merge requests with different failfast settings and still behave
    correctly on errors.  Allow merge of requests of different failfast
    settings.
    
    As SCSI is currently the only subsystem which follows failfast status,
    there's no need to worry about other block drivers for now.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Niel Lambrechts <niel.lambrechts@gmail.com>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f3c40898fc7d..90c94da8baa4 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -897,8 +897,10 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			if (driver_byte(result) & DRIVER_SENSE)
 				scsi_print_sense("", cmd);
 		}
-		blk_end_request_all(req, -EIO);
-		scsi_next_command(cmd);
+		if (blk_end_request_err(req, -EIO))
+			scsi_requeue_command(q, cmd);
+		else
+			scsi_next_command(cmd);
 		break;
 	case ACTION_REPREP:
 		/* Unprep the request and put it back at the head of the queue.

commit 002b1eb2c03ccec36bf6e7b719cccedf57d83402
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Sat May 23 11:45:07 2009 -0400

    [SCSI] Print failed commands
    
    When a request fails we print the sense data but not the actual command
    that failed.  Add a printout of the operation + CDB for failed commands.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f3c40898fc7d..662024d86949 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -896,6 +896,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			scsi_print_result(cmd);
 			if (driver_byte(result) & DRIVER_SENSE)
 				scsi_print_sense("", cmd);
+			scsi_print_command(cmd);
 		}
 		blk_end_request_all(req, -EIO);
 		scsi_next_command(cmd);

commit b391277a56b9eaaff4474339c703e574ed7fab5b
Author: Hannes Reinecke <hare@suse.de>
Date:   Thu Jun 18 09:57:18 2009 +0200

    sd, sr: fix Driver 'sd' needs updating message
    
    If a SCSI ULD driver sets blk_queue_prep_rq(), it should clean it
    up itself on remove(), and not from the bus callbacks. This
    removes the need to hook into bus->remove(), which should not
    be used at the same time as driver->remove().
    
    [jejb: fix sdkp initialisation problem due to mismerge]
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Kay Sievers <kay.sievers@vrfy.org>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 30f3275e119e..f3c40898fc7d 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1207,6 +1207,7 @@ int scsi_prep_fn(struct request_queue *q, struct request *req)
 		ret = scsi_setup_blk_pc_cmnd(sdev, req);
 	return scsi_prep_return(q, req, ret);
 }
+EXPORT_SYMBOL(scsi_prep_fn);
 
 /*
  * scsi_dev_queue_ready: if we can send requests to sdev, return 1 else

commit 82681a318f9f028ea64e61f24bbd9ac535531921
Merge: 3860c97bd60a 8ebf975608aa
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Fri Jun 12 10:02:03 2009 -0500

    [SCSI] Merge branch 'linus'
    
    Conflicts:
            drivers/message/fusion/mptsas.c
    
    fixed up conflict between req->data_len accessors and mptsas driver updates.
    
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

commit 5c10e63c943b4c67561ddc6bf61e01d4141f881f
Author: Takahiro Yasui <tyasui@redhat.com>
Date:   Wed Apr 29 12:13:02 2009 -0400

    [SCSI] limit state transitions in scsi_internal_device_unblock
    
    scsi timeout on two or more devices may cause extremely long execution
    time for user applications because SDEV_OFFLINE state is changed to
    SDEV_RUNNING state during scsi error recovery procedures triggered by
    a bus reset or a host reset of scsi LLD, and scsi timeout can happens
    on the same devices many times.
    
    This happens because scsi_internal_device_unblock() changes device's
    state to SDEV_RUNNING even if a device in other states than SDEV_BLOCK,
    while the following two transitions are required in this function.
    
      SDEV_BLOCK -> SDEV_RUNNING
      SDEV_CREATED_BLOCK -> SDEV_CREATED
    
    Otherwise, it returns -EINVAL.
    
    Signed-off-by: Takahiro Yasui <tyasui@redhat.com>
    [matthew@wil.cx: supplied rewritten base for patch]
    Signed-off-by: Matthew Wilcox <matthew@wil.cx>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index bb218c8b6e98..27dbf2e8e34a 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2441,20 +2441,18 @@ int
 scsi_internal_device_unblock(struct scsi_device *sdev)
 {
 	struct request_queue *q = sdev->request_queue; 
-	int err;
 	unsigned long flags;
 	
 	/* 
 	 * Try to transition the scsi device to SDEV_RUNNING
 	 * and goose the device queue if successful.  
 	 */
-	err = scsi_device_set_state(sdev, SDEV_RUNNING);
-	if (err) {
-		err = scsi_device_set_state(sdev, SDEV_CREATED);
-
-		if (err)
-			return err;
-	}
+	if (sdev->sdev_state == SDEV_BLOCK)
+		sdev->sdev_state = SDEV_RUNNING;
+	else if (sdev->sdev_state == SDEV_CREATED_BLOCK)
+		sdev->sdev_state = SDEV_CREATED;
+	else
+		return -EINVAL;
 
 	spin_lock_irqsave(q->queue_lock, flags);
 	blk_start_queue(q);

commit e4b636366c00738b9609cda307014d71b1225b7f
Merge: b9ed7252d219 279e677faa77
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Fri May 22 20:25:34 2009 +0200

    Merge branch 'master' into for-2.6.31
    
    Conflicts:
            drivers/block/hd.c
            drivers/block/mg_disk.c
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

commit ac36552a52a6ec8563ac0a109e2a0935673f4abb
Author: Boaz Harrosh <bharrosh@panasas.com>
Date:   Tue May 19 19:54:09 2009 +0200

    scsi_lib: remove unused variable
    
    The last request completion cleanup in scsi_lib left an unused
    this_count variable in scsi_io_completion().
    (It was used before in a code segment that now uses blk_end_request_all())
    
    Signed-off-by: Boaz Harrosh <bharrosh@panasas.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Acked-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e410d667910d..d7c6c752e0a6 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -706,7 +706,6 @@ EXPORT_SYMBOL(scsi_release_buffers);
 void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 {
 	int result = cmd->result;
-	int this_count;
 	struct request_queue *q = cmd->device->request_queue;
 	struct request *req = cmd->request;
 	int error = 0;
@@ -789,7 +788,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	 */
 	if (scsi_end_request(cmd, error, good_bytes, result == 0) == NULL)
 		return;
-	this_count = blk_rq_bytes(req);
 
 	error = -EIO;
 

commit e458824f9d32e9bf7700d1eb0d201749af48eee0
Author: Tejun Heo <tj@kernel.org>
Date:   Tue May 12 08:49:32 2009 +0200

    scsi: fix resid_len mis-conversion in scsi_end_request()
    
    Commit c3a4d78c580de4edc9ef0f7c59812fb02ceb037f introduced
    rq->data_len and converted residual count users to it.  While
    converting, it mistakenly converted scsi_end_request() to finish
    requests with residual count when it wants to do is fully complete the
    request.  Fix it by using blk_end_request_all() instead.
    
    This bug was spotted by Boaz Harrosh.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Spotted-by: Boaz Harrosh <bharrosh@panasas.com>
    Cc: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a54bec994386..e410d667910d 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -546,14 +546,9 @@ static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int error,
 	 * to queue the remainder of them.
 	 */
 	if (blk_end_request(req, error, bytes)) {
-		int leftover = blk_rq_bytes(req);
-
-		if (blk_pc_request(req))
-			leftover = req->resid_len;
-
 		/* kill remainder if no retrys */
 		if (error && scsi_noretry_cmd(cmd))
-			blk_end_request(req, error, leftover);
+			blk_end_request_all(req, error);
 		else {
 			if (requeue) {
 				/*

commit e6bb7a96c2c36f20c05ef648f15bd3c2b1834c78
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Mon May 11 17:56:08 2009 +0900

    scsi: simplify the bidi completion
    
    Let's use blk_end_request_all() instead of blk_end_bidi_request().
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b12750f82169..a54bec994386 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -672,33 +672,6 @@ void scsi_release_buffers(struct scsi_cmnd *cmd)
 }
 EXPORT_SYMBOL(scsi_release_buffers);
 
-/*
- * Bidi commands Must be complete as a whole, both sides at once.  If
- * part of the bytes were written and lld returned scsi_in()->resid
- * and/or scsi_out()->resid this information will be left in
- * req->resid_len and req->next_rq->resid_len. The upper-layer driver
- * can decide what to do with this information.
- */
-static void scsi_end_bidi_request(struct scsi_cmnd *cmd)
-{
-	struct request *req = cmd->request;
-
-	req->resid_len = scsi_out(cmd)->resid;
-	req->next_rq->resid_len = scsi_in(cmd)->resid;
-
-	/* The req and req->next_rq have not been completed */
-	BUG_ON(blk_end_bidi_request(req, 0, blk_rq_bytes(req),
-				    blk_rq_bytes(req->next_rq)));
-
-	scsi_release_buffers(cmd);
-
-	/*
-	 * This will goose the queue request function at the end, so we don't
-	 * need to worry about launching another command.
-	 */
-	scsi_next_command(cmd);
-}
-
 /*
  * Function:    scsi_io_completion()
  *
@@ -772,12 +745,22 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			if (!sense_deferred)
 				error = -EIO;
 		}
+
+		req->resid_len = scsi_get_resid(cmd);
+
 		if (scsi_bidi_cmnd(cmd)) {
-			/* will also release_buffers */
-			scsi_end_bidi_request(cmd);
+			/*
+			 * Bidi commands Must be complete as a whole,
+			 * both sides at once.
+			 */
+			req->next_rq->resid_len = scsi_in(cmd)->resid;
+
+			blk_end_request_all(req, 0);
+
+			scsi_release_buffers(cmd);
+			scsi_next_command(cmd);
 			return;
 		}
-		req->resid_len = scsi_get_resid(cmd);
 	}
 
 	BUG_ON(blk_bidi_rq(req)); /* bidi not support for !blk_pc_request yet */

commit 9934c8c04561413609d2bc38c6b9f268cba774a4
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 8 11:54:16 2009 +0900

    block: implement and enforce request peek/start/fetch
    
    Till now block layer allowed two separate modes of request execution.
    A request is always acquired from the request queue via
    elv_next_request().  After that, drivers are free to either dequeue it
    or process it without dequeueing.  Dequeue allows elv_next_request()
    to return the next request so that multiple requests can be in flight.
    
    Executing requests without dequeueing has its merits mostly in
    allowing drivers for simpler devices which can't do sg to deal with
    segments only without considering request boundary.  However, the
    benefit this brings is dubious and declining while the cost of the API
    ambiguity is increasing.  Segment based drivers are usually for very
    old or limited devices and as converting to dequeueing model isn't
    difficult, it doesn't justify the API overhead it puts on block layer
    and its more modern users.
    
    Previous patches converted all block low level drivers to dequeueing
    model.  This patch completes the API transition by...
    
    * renaming elv_next_request() to blk_peek_request()
    
    * renaming blkdev_dequeue_request() to blk_start_request()
    
    * adding blk_fetch_request() which is combination of peek and start
    
    * disallowing completion of queued (not started) requests
    
    * applying new API to all LLDs
    
    Renamings are for consistency and to break out of tree code so that
    it's apparent that out of tree drivers need updating.
    
    [ Impact: block request issue API cleanup, no functional change ]
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Cc: Mike Miller <mike.miller@hp.com>
    Cc: unsik Kim <donari75@gmail.com>
    Cc: Paul Clements <paul.clements@steeleye.com>
    Cc: Tim Waugh <tim@cyberelk.net>
    Cc: Geert Uytterhoeven <Geert.Uytterhoeven@sonycom.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Laurent Vivier <Laurent@lvivier.info>
    Cc: Jeff Garzik <jgarzik@pobox.com>
    Cc: Jeremy Fitzhardinge <jeremy@xensource.com>
    Cc: Grant Likely <grant.likely@secretlab.ca>
    Cc: Adrian McMenamin <adrian@mcmen.demon.co.uk>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Cc: Bartlomiej Zolnierkiewicz <bzolnier@gmail.com>
    Cc: Borislav Petkov <petkovbb@googlemail.com>
    Cc: Sergei Shtylyov <sshtylyov@ru.mvista.com>
    Cc: Alex Dubov <oakad@yahoo.com>
    Cc: Pierre Ossman <drzeus@drzeus.cx>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Markus Lidel <Markus.Lidel@shadowconnect.com>
    Cc: Stefan Weinhuber <wein@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Pete Zaitcev <zaitcev@redhat.com>
    Cc: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ee308f6f7982..b12750f82169 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1207,7 +1207,7 @@ int scsi_prep_return(struct request_queue *q, struct request *req, int ret)
 		break;
 	case BLKPREP_DEFER:
 		/*
-		 * If we defer, the elv_next_request() returns NULL, but the
+		 * If we defer, the blk_peek_request() returns NULL, but the
 		 * queue must be restarted, so we plug here if no returning
 		 * command will automatically do that.
 		 */
@@ -1385,7 +1385,7 @@ static void scsi_kill_request(struct request *req, struct request_queue *q)
 	struct scsi_target *starget = scsi_target(sdev);
 	struct Scsi_Host *shost = sdev->host;
 
-	blkdev_dequeue_request(req);
+	blk_start_request(req);
 
 	if (unlikely(cmd == NULL)) {
 		printk(KERN_CRIT "impossible request in %s.\n",
@@ -1477,7 +1477,7 @@ static void scsi_request_fn(struct request_queue *q)
 
 	if (!sdev) {
 		printk("scsi: killing requests for dead queue\n");
-		while ((req = elv_next_request(q)) != NULL)
+		while ((req = blk_peek_request(q)) != NULL)
 			scsi_kill_request(req, q);
 		return;
 	}
@@ -1498,7 +1498,7 @@ static void scsi_request_fn(struct request_queue *q)
 		 * that the request is fully prepared even if we cannot 
 		 * accept it.
 		 */
-		req = elv_next_request(q);
+		req = blk_peek_request(q);
 		if (!req || !scsi_dev_queue_ready(q, sdev))
 			break;
 
@@ -1514,7 +1514,7 @@ static void scsi_request_fn(struct request_queue *q)
 		 * Remove the request from the request list.
 		 */
 		if (!(blk_queue_tagged(q) && !blk_queue_start_tag(q, req)))
-			blkdev_dequeue_request(req);
+			blk_start_request(req);
 		sdev->device_busy++;
 
 		spin_unlock(q->queue_lock);

commit 1011c1b9f2e45ce7c6e38888d2b83936aec38771
Author: Tejun Heo <tj@kernel.org>
Date:   Thu May 7 22:24:45 2009 +0900

    block: blk_rq_[cur_]_{sectors|bytes}() usage cleanup
    
    With the previous changes, the followings are now guaranteed for all
    requests in any valid state.
    
    * blk_rq_sectors() == blk_rq_bytes() >> 9
    * blk_rq_cur_sectors() == blk_rq_cur_bytes() >> 9
    
    Clean up accessor usages.  Notable changes are
    
    * nbd,i2o_block: end_all used instead of explicit byte count
    * scsi_lib: unnecessary conditional on request type removed
    
    [ Impact: cleanup ]
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Paul Clements <paul.clements@steeleye.com>
    Cc: Pete Zaitcev <zaitcev@redhat.com>
    Cc: Alex Dubov <oakad@yahoo.com>
    Cc: Markus Lidel <Markus.Lidel@shadowconnect.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Cc: Boaz Harrosh <bharrosh@panasas.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 3d16c70fbde0..ee308f6f7982 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -546,7 +546,7 @@ static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int error,
 	 * to queue the remainder of them.
 	 */
 	if (blk_end_request(req, error, bytes)) {
-		int leftover = blk_rq_sectors(req) << 9;
+		int leftover = blk_rq_bytes(req);
 
 		if (blk_pc_request(req))
 			leftover = req->resid_len;
@@ -964,10 +964,7 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb,
 	count = blk_rq_map_sg(req->q, req, sdb->table.sgl);
 	BUG_ON(count > sdb->table.nents);
 	sdb->table.nents = count;
-	if (blk_pc_request(req))
-		sdb->length = blk_rq_bytes(req);
-	else
-		sdb->length = blk_rq_sectors(req) << 9;
+	sdb->length = blk_rq_bytes(req);
 	return BLKPREP_OK;
 }
 

commit b0790410300abaaf4f25f702803beff701baebf1
Author: Tejun Heo <tj@kernel.org>
Date:   Thu May 7 22:24:42 2009 +0900

    block: cleanup rq->data_len usages
    
    With recent unification of fields, it's now guaranteed that
    rq->data_len always equals blk_rq_bytes().  Convert all non-IDE direct
    users to accessors.  IDE will be converted in a separate patch.
    
    Boaz: spotted incorrect data_len/resid_len conversion in osd.
    
    [ Impact: convert direct rq->data_len usages to blk_rq_bytes() ]
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Sergei Shtylyov <sshtylyov@ru.mvista.com>
    Cc: Pete Zaitcev <zaitcev@redhat.com>
    Cc: Eric Moore <Eric.Moore@lsi.com>
    Cc: Markus Lidel <Markus.Lidel@shadowconnect.com>
    Cc: Darrick J. Wong <djwong@us.ibm.com>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Cc: Eric Moore <Eric.Moore@lsi.com>
    Cc: Boaz Harrosh <bharrosh@panasas.com>
    Cc: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 39b3acfc0ddf..3d16c70fbde0 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -682,14 +682,13 @@ EXPORT_SYMBOL(scsi_release_buffers);
 static void scsi_end_bidi_request(struct scsi_cmnd *cmd)
 {
 	struct request *req = cmd->request;
-	unsigned int dlen = req->data_len;
-	unsigned int next_dlen = req->next_rq->data_len;
 
 	req->resid_len = scsi_out(cmd)->resid;
 	req->next_rq->resid_len = scsi_in(cmd)->resid;
 
 	/* The req and req->next_rq have not been completed */
-	BUG_ON(blk_end_bidi_request(req, 0, dlen, next_dlen));
+	BUG_ON(blk_end_bidi_request(req, 0, blk_rq_bytes(req),
+				    blk_rq_bytes(req->next_rq)));
 
 	scsi_release_buffers(cmd);
 
@@ -966,7 +965,7 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb,
 	BUG_ON(count > sdb->table.nents);
 	sdb->table.nents = count;
 	if (blk_pc_request(req))
-		sdb->length = req->data_len;
+		sdb->length = blk_rq_bytes(req);
 	else
 		sdb->length = blk_rq_sectors(req) << 9;
 	return BLKPREP_OK;
@@ -1087,21 +1086,21 @@ int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 		if (unlikely(ret))
 			return ret;
 	} else {
-		BUG_ON(req->data_len);
+		BUG_ON(blk_rq_bytes(req));
 
 		memset(&cmd->sdb, 0, sizeof(cmd->sdb));
 		req->buffer = NULL;
 	}
 
 	cmd->cmd_len = req->cmd_len;
-	if (!req->data_len)
+	if (!blk_rq_bytes(req))
 		cmd->sc_data_direction = DMA_NONE;
 	else if (rq_data_dir(req) == WRITE)
 		cmd->sc_data_direction = DMA_TO_DEVICE;
 	else
 		cmd->sc_data_direction = DMA_FROM_DEVICE;
 	
-	cmd->transfersize = req->data_len;
+	cmd->transfersize = blk_rq_bytes(req);
 	cmd->allowed = req->retries;
 	return BLKPREP_OK;
 }

commit 83096ebf1263b2c1ee5e653ba37d993d02e3eb7b
Author: Tejun Heo <tj@kernel.org>
Date:   Thu May 7 22:24:39 2009 +0900

    block: convert to pos and nr_sectors accessors
    
    With recent cleanups, there is no place where low level driver
    directly manipulates request fields.  This means that the 'hard'
    request fields always equal the !hard fields.  Convert all
    rq->sectors, nr_sectors and current_nr_sectors references to
    accessors.
    
    While at it, drop superflous blk_rq_pos() < 0 test in swim.c.
    
    [ Impact: use pos and nr_sectors accessors ]
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Geert Uytterhoeven <Geert.Uytterhoeven@sonycom.com>
    Tested-by: Grant Likely <grant.likely@secretlab.ca>
    Acked-by: Grant Likely <grant.likely@secretlab.ca>
    Tested-by: Adrian McMenamin <adrian@mcmen.demon.co.uk>
    Acked-by: Adrian McMenamin <adrian@mcmen.demon.co.uk>
    Acked-by: Mike Miller <mike.miller@hp.com>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Cc: Bartlomiej Zolnierkiewicz <bzolnier@gmail.com>
    Cc: Borislav Petkov <petkovbb@googlemail.com>
    Cc: Sergei Shtylyov <sshtylyov@ru.mvista.com>
    Cc: Eric Moore <Eric.Moore@lsi.com>
    Cc: Alan Stern <stern@rowland.harvard.edu>
    Cc: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Cc: Pete Zaitcev <zaitcev@redhat.com>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Cc: Paul Clements <paul.clements@steeleye.com>
    Cc: Tim Waugh <tim@cyberelk.net>
    Cc: Jeff Garzik <jgarzik@pobox.com>
    Cc: Jeremy Fitzhardinge <jeremy@xensource.com>
    Cc: Alex Dubov <oakad@yahoo.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Dario Ballabio <ballabio_dario@emc.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: unsik Kim <donari75@gmail.com>
    Cc: Laurent Vivier <Laurent@lvivier.info>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9ff0ca9988a9..39b3acfc0ddf 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -787,9 +787,9 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	 * Next deal with any sectors which we were able to correctly
 	 * handle.
 	 */
-	SCSI_LOG_HLCOMPLETE(1, printk("%ld sectors total, "
+	SCSI_LOG_HLCOMPLETE(1, printk("%u sectors total, "
 				      "%d bytes done.\n",
-				      req->nr_sectors, good_bytes));
+				      blk_rq_sectors(req), good_bytes));
 
 	/*
 	 * Recovered errors need reporting, but they're always treated
@@ -968,7 +968,7 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb,
 	if (blk_pc_request(req))
 		sdb->length = req->data_len;
 	else
-		sdb->length = req->nr_sectors << 9;
+		sdb->length = blk_rq_sectors(req) << 9;
 	return BLKPREP_OK;
 }
 

commit 5b93629b4509c03ffa87a9316412fedf6f58cb37
Author: Tejun Heo <tj@kernel.org>
Date:   Thu May 7 22:24:38 2009 +0900

    block: implement blk_rq_pos/[cur_]sectors() and convert obvious ones
    
    Implement accessors - blk_rq_pos(), blk_rq_sectors() and
    blk_rq_cur_sectors() which return rq->hard_sector, rq->hard_nr_sectors
    and rq->hard_cur_sectors respectively and convert direct references of
    the said fields to the accessors.
    
    This is in preparation of request data length handling cleanup.
    
    Geert   : suggested adding const to struct request * parameter to accessors
    Sergei  : spotted error in patch description
    
    [ Impact: cleanup ]
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Geert Uytterhoeven <Geert.Uytterhoeven@sonycom.com>
    Acked-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Tested-by: Grant Likely <grant.likely@secretlab.ca>
    Acked-by: Grant Likely <grant.likely@secretlab.ca>
    Ackec-by: Sergei Shtylyov <sshtylyov@ru.mvista.com>
    Cc: Bartlomiej Zolnierkiewicz <bzolnier@gmail.com>
    Cc: Borislav Petkov <petkovbb@googlemail.com>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 7d49ef589f33..9ff0ca9988a9 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -546,7 +546,7 @@ static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int error,
 	 * to queue the remainder of them.
 	 */
 	if (blk_end_request(req, error, bytes)) {
-		int leftover = (req->hard_nr_sectors << 9);
+		int leftover = blk_rq_sectors(req) << 9;
 
 		if (blk_pc_request(req))
 			leftover = req->resid_len;

commit c3a4d78c580de4edc9ef0f7c59812fb02ceb037f
Author: Tejun Heo <tj@kernel.org>
Date:   Thu May 7 22:24:37 2009 +0900

    block: add rq->resid_len
    
    rq->data_len served two purposes - the length of data buffer on issue
    and the residual count on completion.  This duality creates some
    headaches.
    
    First of all, block layer and low level drivers can't really determine
    what rq->data_len contains while a request is executing.  It could be
    the total request length or it coulde be anything else one of the
    lower layers is using to keep track of residual count.  This
    complicates things because blk_rq_bytes() and thus
    [__]blk_end_request_all() relies on rq->data_len for PC commands.
    Drivers which want to report residual count should first cache the
    total request length, update rq->data_len and then complete the
    request with the cached data length.
    
    Secondly, it makes requests default to reporting full residual count,
    ie. reporting that no data transfer occurred.  The residual count is
    an exception not the norm; however, the driver should clear
    rq->data_len to zero to signify the normal cases while leaving it
    alone means no data transfer occurred at all.  This reverse default
    behavior complicates code unnecessarily and renders block PC on some
    drivers (ide-tape/floppy) unuseable.
    
    This patch adds rq->resid_len which is used only for residual count.
    
    While at it, remove now unnecessasry blk_rq_bytes() caching in
    ide_pc_intr() as rq->data_len is not changed anymore.
    
    Boaz    : spotted missing conversion in osd
    Sergei  : spotted too early conversion to blk_rq_bytes() in ide-tape
    
    [ Impact: cleanup residual count handling, report 0 resid by default ]
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Cc: Bartlomiej Zolnierkiewicz <bzolnier@gmail.com>
    Cc: Borislav Petkov <petkovbb@googlemail.com>
    Cc: Sergei Shtylyov <sshtylyov@ru.mvista.com>
    Cc: Mike Miller <mike.miller@hp.com>
    Cc: Eric Moore <Eric.Moore@lsi.com>
    Cc: Alan Stern <stern@rowland.harvard.edu>
    Cc: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Cc: Doug Gilbert <dgilbert@interlog.com>
    Cc: Mike Miller <mike.miller@hp.com>
    Cc: Eric Moore <Eric.Moore@lsi.com>
    Cc: Darrick J. Wong <djwong@us.ibm.com>
    Cc: Pete Zaitcev <zaitcev@redhat.com>
    Cc: Boaz Harrosh <bharrosh@panasas.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index aa9fc572e45f..7d49ef589f33 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -240,11 +240,11 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	 * is invalid.  Prevent the garbage from being misinterpreted
 	 * and prevent security leaks by zeroing out the excess data.
 	 */
-	if (unlikely(req->data_len > 0 && req->data_len <= bufflen))
-		memset(buffer + (bufflen - req->data_len), 0, req->data_len);
+	if (unlikely(req->resid_len > 0 && req->resid_len <= bufflen))
+		memset(buffer + (bufflen - req->resid_len), 0, req->resid_len);
 
 	if (resid)
-		*resid = req->data_len;
+		*resid = req->resid_len;
 	ret = req->errors;
  out:
 	blk_put_request(req);
@@ -549,7 +549,7 @@ static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int error,
 		int leftover = (req->hard_nr_sectors << 9);
 
 		if (blk_pc_request(req))
-			leftover = req->data_len;
+			leftover = req->resid_len;
 
 		/* kill remainder if no retrys */
 		if (error && scsi_noretry_cmd(cmd))
@@ -673,11 +673,11 @@ void scsi_release_buffers(struct scsi_cmnd *cmd)
 EXPORT_SYMBOL(scsi_release_buffers);
 
 /*
- * Bidi commands Must be complete as a whole, both sides at once.
- * If part of the bytes were written and lld returned
- * scsi_in()->resid and/or scsi_out()->resid this information will be left
- * in req->data_len and req->next_rq->data_len. The upper-layer driver can
- * decide what to do with this information.
+ * Bidi commands Must be complete as a whole, both sides at once.  If
+ * part of the bytes were written and lld returned scsi_in()->resid
+ * and/or scsi_out()->resid this information will be left in
+ * req->resid_len and req->next_rq->resid_len. The upper-layer driver
+ * can decide what to do with this information.
  */
 static void scsi_end_bidi_request(struct scsi_cmnd *cmd)
 {
@@ -685,8 +685,8 @@ static void scsi_end_bidi_request(struct scsi_cmnd *cmd)
 	unsigned int dlen = req->data_len;
 	unsigned int next_dlen = req->next_rq->data_len;
 
-	req->data_len = scsi_out(cmd)->resid;
-	req->next_rq->data_len = scsi_in(cmd)->resid;
+	req->resid_len = scsi_out(cmd)->resid;
+	req->next_rq->resid_len = scsi_in(cmd)->resid;
 
 	/* The req and req->next_rq have not been completed */
 	BUG_ON(blk_end_bidi_request(req, 0, dlen, next_dlen));
@@ -778,7 +778,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			scsi_end_bidi_request(cmd);
 			return;
 		}
-		req->data_len = scsi_get_resid(cmd);
+		req->resid_len = scsi_get_resid(cmd);
 	}
 
 	BUG_ON(blk_bidi_rq(req)); /* bidi not support for !blk_pc_request yet */

commit 731ec497e5888c6792ad62613ae9be97eebcd7ca
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Apr 23 11:05:20 2009 +0900

    block: kill rq->data
    
    Now that all block request data transfer is done via bio, rq->data
    isn't used.  Kill it.
    
    While at it, make the roles of rq->special and buffer clear.
    
    [ Impact: drop now unncessary field from struct request ]
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Boaz Harrosh <bharrosh@panasas.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 756ac7c93de0..aa9fc572e45f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1088,7 +1088,6 @@ int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 			return ret;
 	} else {
 		BUG_ON(req->data_len);
-		BUG_ON(req->data);
 
 		memset(&cmd->sdb, 0, sizeof(cmd->sdb));
 		req->buffer = NULL;

commit 40cbbb781d3eba5d6ac0860db078af490e5c7c6b
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Apr 23 11:05:19 2009 +0900

    block: implement and use [__]blk_end_request_all()
    
    There are many [__]blk_end_request() call sites which call it with
    full request length and expect full completion.  Many of them ensure
    that the request actually completes by doing BUG_ON() the return
    value, which is awkward and error-prone.
    
    This patch adds [__]blk_end_request_all() which takes @rq and @error
    and fully completes the request.  BUG_ON() is added to to ensure that
    this actually happens.
    
    Most conversions are simple but there are a few noteworthy ones.
    
    * cdrom/viocd: viocd_end_request() replaced with direct calls to
      __blk_end_request_all().
    
    * s390/block/dasd: dasd_end_request() replaced with direct calls to
      __blk_end_request_all().
    
    * s390/char/tape_block: tapeblock_end_request() replaced with direct
      calls to blk_end_request_all().
    
    [ Impact: cleanup ]
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Cc: Mike Miller <mike.miller@hp.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Jeff Garzik <jgarzik@pobox.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Jeremy Fitzhardinge <jeremy@xensource.com>
    Cc: Alex Dubov <oakad@yahoo.com>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d1cb64ad1a3f..756ac7c93de0 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -922,7 +922,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			if (driver_byte(result) & DRIVER_SENSE)
 				scsi_print_sense("", cmd);
 		}
-		blk_end_request(req, -EIO, blk_rq_bytes(req));
+		blk_end_request_all(req, -EIO);
 		scsi_next_command(cmd);
 		break;
 	case ACTION_REPREP:

commit b4efdd586bc08cdf5977cad0a90091f44546a930
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Thu Apr 9 15:57:10 2009 -0500

    [SCSI] fix q->lock not held warning when target is busy
    
    We cannot call blk_plug_device from scsi_target_queue_ready
    because the q lock is not held. And we do not need to call
    it from there because when we return 0, the scsi_request_fn
    not_ready handling will plug the queue for us if needed.
    
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d1cb64ad1a3f..bb218c8b6e98 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1291,10 +1291,8 @@ static inline int scsi_target_queue_ready(struct Scsi_Host *shost,
 		if (--starget->target_blocked == 0) {
 			SCSI_LOG_MLQUEUE(3, starget_printk(KERN_INFO, starget,
 					 "unblocking target at zero depth\n"));
-		} else {
-			blk_plug_device(sdev->request_queue);
+		} else
 			return 0;
-		}
 	}
 
 	if (scsi_target_is_busy(starget)) {

commit a9bddd74630b2a1f2dedc537417c372b2d9edc76
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Mon Mar 30 16:55:51 2009 +0000

    [SCSI] fix recovered error handling
    
    We have a problem with recovered error handling in that any command
    which goes down as BLOCK_PC but which returns a sense code of RECOVERED
    ERROR gets completed with -EIO.  For actual SG_IO commands, this doesn't
    matter at all, since the error return code gets dropped in favour of
    req->errors which contain the SCSI completion code.
    
    However, if this command is part of the block system, then it will pay
    attention to the returned error code.  In particularly if a SYNCHRONIZE
    CACHE from a barrier command completes with RECOVERED ERROR, the
    resulting -EIO on the barrier causes block to error the request and
    return it to the filesystem.  Fix this by converting the -EIO for
    recovered error to zero, plus remove the printing of this from sd and sr
    so the message isn't double printed.
    
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4b13e36d3aa0..d1cb64ad1a3f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -791,7 +791,22 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				      "%d bytes done.\n",
 				      req->nr_sectors, good_bytes));
 
-	/* A number of bytes were successfully read.  If there
+	/*
+	 * Recovered errors need reporting, but they're always treated
+	 * as success, so fiddle the result code here.  For BLOCK_PC
+	 * we already took a copy of the original into rq->errors which
+	 * is what gets returned to the user
+	 */
+	if (sense_valid && sshdr.sense_key == RECOVERED_ERROR) {
+		if (!(req->cmd_flags & REQ_QUIET))
+			scsi_print_sense("", cmd);
+		result = 0;
+		/* BLOCK_PC may have set error */
+		error = 0;
+	}
+
+	/*
+	 * A number of bytes were successfully read.  If there
 	 * are leftovers and there is some kind of error
 	 * (result != 0), retry the rest.
 	 */

commit f078727b250c2653fc9a564f15547c17ebac3f99
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Sun Dec 14 01:23:45 2008 +0900

    [SCSI] remove scsi_req_map_sg
    
    No one uses scsi_execute_async with data transfer now. We can remove
    scsi_req_map_sg.
    
    Only scsi_eh_lock_door uses scsi_execute_async. scsi_eh_lock_door
    doesn't handle sense and the callback. So we can remove
    scsi_io_context too.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b82ffd90632e..4b13e36d3aa0 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -277,196 +277,6 @@ int scsi_execute_req(struct scsi_device *sdev, const unsigned char *cmd,
 }
 EXPORT_SYMBOL(scsi_execute_req);
 
-struct scsi_io_context {
-	void *data;
-	void (*done)(void *data, char *sense, int result, int resid);
-	char sense[SCSI_SENSE_BUFFERSIZE];
-};
-
-static struct kmem_cache *scsi_io_context_cache;
-
-static void scsi_end_async(struct request *req, int uptodate)
-{
-	struct scsi_io_context *sioc = req->end_io_data;
-
-	if (sioc->done)
-		sioc->done(sioc->data, sioc->sense, req->errors, req->data_len);
-
-	kmem_cache_free(scsi_io_context_cache, sioc);
-	__blk_put_request(req->q, req);
-}
-
-static int scsi_merge_bio(struct request *rq, struct bio *bio)
-{
-	struct request_queue *q = rq->q;
-
-	bio->bi_flags &= ~(1 << BIO_SEG_VALID);
-	if (rq_data_dir(rq) == WRITE)
-		bio->bi_rw |= (1 << BIO_RW);
-	blk_queue_bounce(q, &bio);
-
-	return blk_rq_append_bio(q, rq, bio);
-}
-
-static void scsi_bi_endio(struct bio *bio, int error)
-{
-	bio_put(bio);
-}
-
-/**
- * scsi_req_map_sg - map a scatterlist into a request
- * @rq:		request to fill
- * @sgl:	scatterlist
- * @nsegs:	number of elements
- * @bufflen:	len of buffer
- * @gfp:	memory allocation flags
- *
- * scsi_req_map_sg maps a scatterlist into a request so that the
- * request can be sent to the block layer. We do not trust the scatterlist
- * sent to use, as some ULDs use that struct to only organize the pages.
- */
-static int scsi_req_map_sg(struct request *rq, struct scatterlist *sgl,
-			   int nsegs, unsigned bufflen, gfp_t gfp)
-{
-	struct request_queue *q = rq->q;
-	int nr_pages = (bufflen + sgl[0].offset + PAGE_SIZE - 1) >> PAGE_SHIFT;
-	unsigned int data_len = bufflen, len, bytes, off;
-	struct scatterlist *sg;
-	struct page *page;
-	struct bio *bio = NULL;
-	int i, err, nr_vecs = 0;
-
-	for_each_sg(sgl, sg, nsegs, i) {
-		page = sg_page(sg);
-		off = sg->offset;
-		len = sg->length;
-
-		while (len > 0 && data_len > 0) {
-			/*
-			 * sg sends a scatterlist that is larger than
-			 * the data_len it wants transferred for certain
-			 * IO sizes
-			 */
-			bytes = min_t(unsigned int, len, PAGE_SIZE - off);
-			bytes = min(bytes, data_len);
-
-			if (!bio) {
-				nr_vecs = min_t(int, BIO_MAX_PAGES, nr_pages);
-				nr_pages -= nr_vecs;
-
-				bio = bio_alloc(gfp, nr_vecs);
-				if (!bio) {
-					err = -ENOMEM;
-					goto free_bios;
-				}
-				bio->bi_end_io = scsi_bi_endio;
-			}
-
-			if (bio_add_pc_page(q, bio, page, bytes, off) !=
-			    bytes) {
-				bio_put(bio);
-				err = -EINVAL;
-				goto free_bios;
-			}
-
-			if (bio->bi_vcnt >= nr_vecs) {
-				err = scsi_merge_bio(rq, bio);
-				if (err) {
-					bio_endio(bio, 0);
-					goto free_bios;
-				}
-				bio = NULL;
-			}
-
-			page++;
-			len -= bytes;
-			data_len -=bytes;
-			off = 0;
-		}
-	}
-
-	rq->buffer = rq->data = NULL;
-	rq->data_len = bufflen;
-	return 0;
-
-free_bios:
-	while ((bio = rq->bio) != NULL) {
-		rq->bio = bio->bi_next;
-		/*
-		 * call endio instead of bio_put incase it was bounced
-		 */
-		bio_endio(bio, 0);
-	}
-
-	return err;
-}
-
-/**
- * scsi_execute_async - insert request
- * @sdev:	scsi device
- * @cmd:	scsi command
- * @cmd_len:	length of scsi cdb
- * @data_direction: DMA_TO_DEVICE, DMA_FROM_DEVICE, or DMA_NONE
- * @buffer:	data buffer (this can be a kernel buffer or scatterlist)
- * @bufflen:	len of buffer
- * @use_sg:	if buffer is a scatterlist this is the number of elements
- * @timeout:	request timeout in seconds
- * @retries:	number of times to retry request
- * @privdata:	data passed to done()
- * @done:	callback function when done
- * @gfp:	memory allocation flags
- */
-int scsi_execute_async(struct scsi_device *sdev, const unsigned char *cmd,
-		       int cmd_len, int data_direction, void *buffer, unsigned bufflen,
-		       int use_sg, int timeout, int retries, void *privdata,
-		       void (*done)(void *, char *, int, int), gfp_t gfp)
-{
-	struct request *req;
-	struct scsi_io_context *sioc;
-	int err = 0;
-	int write = (data_direction == DMA_TO_DEVICE);
-
-	sioc = kmem_cache_zalloc(scsi_io_context_cache, gfp);
-	if (!sioc)
-		return DRIVER_ERROR << 24;
-
-	req = blk_get_request(sdev->request_queue, write, gfp);
-	if (!req)
-		goto free_sense;
-	req->cmd_type = REQ_TYPE_BLOCK_PC;
-	req->cmd_flags |= REQ_QUIET;
-
-	if (use_sg)
-		err = scsi_req_map_sg(req, buffer, use_sg, bufflen, gfp);
-	else if (bufflen)
-		err = blk_rq_map_kern(req->q, req, buffer, bufflen, gfp);
-
-	if (err)
-		goto free_req;
-
-	req->cmd_len = cmd_len;
-	memset(req->cmd, 0, BLK_MAX_CDB); /* ATAPI hates garbage after CDB */
-	memcpy(req->cmd, cmd, req->cmd_len);
-	req->sense = sioc->sense;
-	req->sense_len = 0;
-	req->timeout = timeout;
-	req->retries = retries;
-	req->end_io_data = sioc;
-
-	sioc->data = privdata;
-	sioc->done = done;
-
-	blk_execute_rq_nowait(req->q, NULL, req, 1, scsi_end_async);
-	return 0;
-
-free_req:
-	blk_put_request(req);
-free_sense:
-	kmem_cache_free(scsi_io_context_cache, sioc);
-	return DRIVER_ERROR << 24;
-}
-EXPORT_SYMBOL_GPL(scsi_execute_async);
-
 /*
  * Function:    scsi_init_cmd_errh()
  *
@@ -1920,20 +1730,12 @@ int __init scsi_init_queue(void)
 {
 	int i;
 
-	scsi_io_context_cache = kmem_cache_create("scsi_io_context",
-					sizeof(struct scsi_io_context),
-					0, 0, NULL);
-	if (!scsi_io_context_cache) {
-		printk(KERN_ERR "SCSI: can't init scsi io context cache\n");
-		return -ENOMEM;
-	}
-
 	scsi_sdb_cache = kmem_cache_create("scsi_data_buffer",
 					   sizeof(struct scsi_data_buffer),
 					   0, 0, NULL);
 	if (!scsi_sdb_cache) {
 		printk(KERN_ERR "SCSI: can't init scsi sdb cache\n");
-		goto cleanup_io_context;
+		return -ENOMEM;
 	}
 
 	for (i = 0; i < SG_MEMPOOL_NR; i++) {
@@ -1968,8 +1770,6 @@ int __init scsi_init_queue(void)
 			kmem_cache_destroy(sgp->slab);
 	}
 	kmem_cache_destroy(scsi_sdb_cache);
-cleanup_io_context:
-	kmem_cache_destroy(scsi_io_context_cache);
 
 	return -ENOMEM;
 }
@@ -1978,7 +1778,6 @@ void scsi_exit_queue(void)
 {
 	int i;
 
-	kmem_cache_destroy(scsi_io_context_cache);
 	kmem_cache_destroy(scsi_sdb_cache);
 
 	for (i = 0; i < SG_MEMPOOL_NR; i++) {

commit 126c098296c8f96cf7f6ca0fdb47265ac7994f00
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Thu Feb 19 21:48:54 2009 +0000

    [SCSI] fix ABORTED_COMMAND looping forever problem
    
    Instead of terminating after five retries, commands terminated by
    ABORTED_COMMAND sense are retrying forever.  The problem was
    introduced by:
    
    commit b60af5b0adf0da24c673598c8d3fb4d4189a15ce
    Author: Alan Stern <stern@rowland.harvard.edu>
    Date:   Mon Nov 3 15:56:47 2008 -0500
    
        [SCSI] simplify scsi_io_completion()
    
    Which introduced an error whereby ABORTED_COMMAND now gets erroneously
    retried in scsi_io_completion.  Fix this by returning the behaviour
    back to the default no retry.
    
    Reported-by: Sitsofe Wheeler <sitsofe@yahoo.com>
    Tested-by: Sitsofe Wheeler <sitsofe@yahoo.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 940dc32ff0dc..b82ffd90632e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1040,12 +1040,11 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				action = ACTION_FAIL;
 			break;
 		case ABORTED_COMMAND:
+			action = ACTION_FAIL;
 			if (sshdr.asc == 0x10) { /* DIF */
 				description = "Target Data Integrity Failure";
-				action = ACTION_FAIL;
 				error = -EILSEQ;
-			} else
-				action = ACTION_RETRY;
+			}
 			break;
 		case NOT_READY:
 			/* If the device is in the process of becoming

commit 79ed24297236b7430d6ce0a1511ff70cf5b6015a
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Tue Jan 6 13:15:20 2009 -0600

    [SCSI] scsi_lib: fix DID_RESET status problems
    
    Andrew Vaszquez said:
    > There's a problem that is causing commands returned by the LLD with
    > a DID_RESET status to be reissued with cleared cmd->sdb data which
    > in our tests are manifesting in firmware detected overruns.  Here's
    > a snippet of a READ_10 scsi_cmnd upon completion by the storage
    
    The problem is caused by:
    
    commit b60af5b0adf0da24c673598c8d3fb4d4189a15ce
    Author: Alan Stern <stern@rowland.harvard.edu>
    Date:   Mon Nov 3 15:56:47 2008 -0500
    
        [SCSI] simplify scsi_io_completion()
    
    Because scsi_release_buffers() is called before commands that go
    through the ACTION_RETRY and ACTION_DELAYED_RETRY legs are requeued.
    However, they're not re-prepared, so nothing ever reallocates the
    buffer resources to them.  Fix this by releasing the buffers only if
    we're not going to go down these legs (but scsi_release_buffers() on
    all legs including two in scsi_end_request(); this latter needs a
    special version __scsi_release_buffers() because the final one can be
    called after the request has been freed, so the bidi test in
    scsi_release_buffers(), which touches the request has to be skipped).
    
    Reported-by: Andrew Vasquez <andrew.vasquez@qlogic.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index cc613bae4ad3..940dc32ff0dc 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -701,6 +701,8 @@ void scsi_run_host_queues(struct Scsi_Host *shost)
 		scsi_run_queue(sdev->request_queue);
 }
 
+static void __scsi_release_buffers(struct scsi_cmnd *, int);
+
 /*
  * Function:    scsi_end_request()
  *
@@ -749,6 +751,7 @@ static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int error,
 				 * leftovers in the front of the
 				 * queue, and goose the queue again.
 				 */
+				scsi_release_buffers(cmd);
 				scsi_requeue_command(q, cmd);
 				cmd = NULL;
 			}
@@ -760,6 +763,7 @@ static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int error,
 	 * This will goose the queue request function at the end, so we don't
 	 * need to worry about launching another command.
 	 */
+	__scsi_release_buffers(cmd, 0);
 	scsi_next_command(cmd);
 	return NULL;
 }
@@ -815,6 +819,26 @@ static void scsi_free_sgtable(struct scsi_data_buffer *sdb)
 	__sg_free_table(&sdb->table, SCSI_MAX_SG_SEGMENTS, scsi_sg_free);
 }
 
+static void __scsi_release_buffers(struct scsi_cmnd *cmd, int do_bidi_check)
+{
+
+	if (cmd->sdb.table.nents)
+		scsi_free_sgtable(&cmd->sdb);
+
+	memset(&cmd->sdb, 0, sizeof(cmd->sdb));
+
+	if (do_bidi_check && scsi_bidi_cmnd(cmd)) {
+		struct scsi_data_buffer *bidi_sdb =
+			cmd->request->next_rq->special;
+		scsi_free_sgtable(bidi_sdb);
+		kmem_cache_free(scsi_sdb_cache, bidi_sdb);
+		cmd->request->next_rq->special = NULL;
+	}
+
+	if (scsi_prot_sg_count(cmd))
+		scsi_free_sgtable(cmd->prot_sdb);
+}
+
 /*
  * Function:    scsi_release_buffers()
  *
@@ -834,21 +858,7 @@ static void scsi_free_sgtable(struct scsi_data_buffer *sdb)
  */
 void scsi_release_buffers(struct scsi_cmnd *cmd)
 {
-	if (cmd->sdb.table.nents)
-		scsi_free_sgtable(&cmd->sdb);
-
-	memset(&cmd->sdb, 0, sizeof(cmd->sdb));
-
-	if (scsi_bidi_cmnd(cmd)) {
-		struct scsi_data_buffer *bidi_sdb =
-			cmd->request->next_rq->special;
-		scsi_free_sgtable(bidi_sdb);
-		kmem_cache_free(scsi_sdb_cache, bidi_sdb);
-		cmd->request->next_rq->special = NULL;
-	}
-
-	if (scsi_prot_sg_count(cmd))
-		scsi_free_sgtable(cmd->prot_sdb);
+	__scsi_release_buffers(cmd, 1);
 }
 EXPORT_SYMBOL(scsi_release_buffers);
 
@@ -962,7 +972,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	}
 
 	BUG_ON(blk_bidi_rq(req)); /* bidi not support for !blk_pc_request yet */
-	scsi_release_buffers(cmd);
 
 	/*
 	 * Next deal with any sectors which we were able to correctly
@@ -1080,6 +1089,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	switch (action) {
 	case ACTION_FAIL:
 		/* Give up and fail the remainder of the request */
+		scsi_release_buffers(cmd);
 		if (!(req->cmd_flags & REQ_QUIET)) {
 			if (description)
 				scmd_printk(KERN_INFO, cmd, "%s\n",
@@ -1095,6 +1105,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		/* Unprep the request and put it back at the head of the queue.
 		 * A new command will be prepared and issued.
 		 */
+		scsi_release_buffers(cmd);
 		scsi_requeue_command(q, cmd);
 		break;
 	case ACTION_RETRY:

commit 3e695f89c5debb735e4ff051e9e58d8fb4e95110
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Sun Jan 4 03:04:31 2009 -0500

    [SCSI] Fix error handling for DIF/DIX
    
    patch
    
    commit b60af5b0adf0da24c673598c8d3fb4d4189a15ce
    Author: Alan Stern <stern@rowland.harvard.edu>
    Date:   Mon Nov 3 15:56:47 2008 -0500
    
        [SCSI] simplify scsi_io_completion()
    
    broke DIX error handling.  Also, we are now using EILSEQ to indicate
    integrity errors to the upper layers (as opposed to regular EIO
    failures).  This allows filesystems to inspect buffers and decide
    whether to retry the I/O.  Update scsi_io_completion() accordingly.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 911514c1fea7..cc613bae4ad3 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -980,6 +980,8 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		return;
 	this_count = blk_rq_bytes(req);
 
+	error = -EIO;
+
 	if (host_byte(result) == DID_RESET) {
 		/* Third party bus reset or reset for error recovery
 		 * reasons.  Just retry the command and see what
@@ -1021,13 +1023,18 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				/* This will issue a new 6-byte command. */
 				cmd->device->use_10_for_rw = 0;
 				action = ACTION_REPREP;
+			} else if (sshdr.asc == 0x10) /* DIX */ {
+				description = "Host Data Integrity Failure";
+				action = ACTION_FAIL;
+				error = -EILSEQ;
 			} else
 				action = ACTION_FAIL;
 			break;
 		case ABORTED_COMMAND:
 			if (sshdr.asc == 0x10) { /* DIF */
+				description = "Target Data Integrity Failure";
 				action = ACTION_FAIL;
-				description = "Data Integrity Failure";
+				error = -EILSEQ;
 			} else
 				action = ACTION_RETRY;
 			break;

commit 4f5299ac4e3a03d5c596c00d726fa932c600609d
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Fri Jan 2 10:42:21 2009 -0600

    [SCSI] scsi_lib: don't decrement busy counters when inserting commands
    
    A bug was introduced by
    
    commit b60af5b0adf0da24c673598c8d3fb4d4189a15ce
    Author: Alan Stern <stern@rowland.harvard.edu>
    Date:   Mon Nov 3 15:56:47 2008 -0500
    
        [SCSI] simplify scsi_io_completion()
    
    because the simplification uses scsi_queue_insert().  The problem with
    this function is that it expects to be called from the completion path
    while the command is still outstanding, so it decrements the device
    and host busy counts to do the requeue.  The problem is that
    scsi_io_completion() is a path executed well after these counts have
    *already* been decremented, leading to a double decrement if the
    command goes down any error path leading to ACTION_DELAYED_RETRY.
    
    The fix is to allow a private function __scsi_queue_insert() with a
    flag to say whether the busy counters should be decremented.  This is
    made static to scsi_lib.c to discourage other use.
    
    Reported-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 8c73bb4e0a2f..911514c1fea7 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -91,26 +91,19 @@ static void scsi_unprep_request(struct request *req)
 	scsi_put_command(cmd);
 }
 
-/*
- * Function:    scsi_queue_insert()
- *
- * Purpose:     Insert a command in the midlevel queue.
- *
- * Arguments:   cmd    - command that we are adding to queue.
- *              reason - why we are inserting command to queue.
- *
- * Lock status: Assumed that lock is not held upon entry.
- *
- * Returns:     Nothing.
- *
- * Notes:       We do this for one of two cases.  Either the host is busy
- *              and it cannot accept any more commands for the time being,
- *              or the device returned QUEUE_FULL and can accept no more
- *              commands.
- * Notes:       This could be called either from an interrupt context or a
- *              normal process context.
+/**
+ * __scsi_queue_insert - private queue insertion
+ * @cmd: The SCSI command being requeued
+ * @reason:  The reason for the requeue
+ * @unbusy: Whether the queue should be unbusied
+ *
+ * This is a private queue insertion.  The public interface
+ * scsi_queue_insert() always assumes the queue should be unbusied
+ * because it's always called before the completion.  This function is
+ * for a requeue after completion, which should only occur in this
+ * file.
  */
-int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
+static int __scsi_queue_insert(struct scsi_cmnd *cmd, int reason, int unbusy)
 {
 	struct Scsi_Host *host = cmd->device->host;
 	struct scsi_device *device = cmd->device;
@@ -150,7 +143,8 @@ int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 	 * Decrement the counters, since these commands are no longer
 	 * active on the host/device.
 	 */
-	scsi_device_unbusy(device);
+	if (unbusy)
+		scsi_device_unbusy(device);
 
 	/*
 	 * Requeue this command.  It will go before all other commands
@@ -172,6 +166,29 @@ int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 	return 0;
 }
 
+/*
+ * Function:    scsi_queue_insert()
+ *
+ * Purpose:     Insert a command in the midlevel queue.
+ *
+ * Arguments:   cmd    - command that we are adding to queue.
+ *              reason - why we are inserting command to queue.
+ *
+ * Lock status: Assumed that lock is not held upon entry.
+ *
+ * Returns:     Nothing.
+ *
+ * Notes:       We do this for one of two cases.  Either the host is busy
+ *              and it cannot accept any more commands for the time being,
+ *              or the device returned QUEUE_FULL and can accept no more
+ *              commands.
+ * Notes:       This could be called either from an interrupt context or a
+ *              normal process context.
+ */
+int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
+{
+	return __scsi_queue_insert(cmd, reason, 1);
+}
 /**
  * scsi_execute - insert request and wait for the result
  * @sdev:	scsi device
@@ -1075,11 +1092,11 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		break;
 	case ACTION_RETRY:
 		/* Retry the same command immediately */
-		scsi_queue_insert(cmd, SCSI_MLQUEUE_EH_RETRY);
+		__scsi_queue_insert(cmd, SCSI_MLQUEUE_EH_RETRY, 0);
 		break;
 	case ACTION_DELAYED_RETRY:
 		/* Retry the same command after a delay */
-		scsi_queue_insert(cmd, SCSI_MLQUEUE_DEVICE_BUSY);
+		__scsi_queue_insert(cmd, SCSI_MLQUEUE_DEVICE_BUSY, 0);
 		break;
 	}
 }

commit 3dbf6a54046052d79743822c9206af191e582ab0
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Mon Dec 15 10:31:28 2008 -0500

    [SCSI] Fix uninitialized variable error in scsi_io_completion
    
    This patch (as1191) adds a missing "default" case in
    scsi_io_completion(), thereby fixing an "uninitialized variable"
    error.  It also adds a missing newline to a log entry.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f2f51e0333eb..8c73bb4e0a2f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1029,6 +1029,10 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				case 0x09: /* self test in progress */
 					action = ACTION_DELAYED_RETRY;
 					break;
+				default:
+					description = "Device not ready";
+					action = ACTION_FAIL;
+					break;
 				}
 			} else {
 				description = "Device not ready";
@@ -1054,7 +1058,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		/* Give up and fail the remainder of the request */
 		if (!(req->cmd_flags & REQ_QUIET)) {
 			if (description)
-				scmd_printk(KERN_INFO, cmd, "%s",
+				scmd_printk(KERN_INFO, cmd, "%s\n",
 					    description);
 			scsi_print_result(cmd);
 			if (driver_byte(result) & DRIVER_SENSE)

commit f4f4e47e4af6b02dd1c425b931c65d0165356e33
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Thu Dec 4 14:24:39 2008 +0900

    [SCSI] add residual argument to scsi_execute and scsi_execute_req
    
    scsi_execute() and scsi_execute_req() discard the residual length
    information. Some callers need it. This adds residual argument
    (optional) to scsi_execute and scsi_execute_req.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ecfbbd30dce5..f2f51e0333eb 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -183,13 +183,15 @@ int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
  * @timeout:	request timeout in seconds
  * @retries:	number of times to retry request
  * @flags:	or into request flags;
+ * @resid:	optional residual length
  *
  * returns the req->errors value which is the scsi_cmnd result
  * field.
  */
 int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 		 int data_direction, void *buffer, unsigned bufflen,
-		 unsigned char *sense, int timeout, int retries, int flags)
+		 unsigned char *sense, int timeout, int retries, int flags,
+		 int *resid)
 {
 	struct request *req;
 	int write = (data_direction == DMA_TO_DEVICE);
@@ -224,6 +226,8 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	if (unlikely(req->data_len > 0 && req->data_len <= bufflen))
 		memset(buffer + (bufflen - req->data_len), 0, req->data_len);
 
+	if (resid)
+		*resid = req->data_len;
 	ret = req->errors;
  out:
 	blk_put_request(req);
@@ -235,7 +239,8 @@ EXPORT_SYMBOL(scsi_execute);
 
 int scsi_execute_req(struct scsi_device *sdev, const unsigned char *cmd,
 		     int data_direction, void *buffer, unsigned bufflen,
-		     struct scsi_sense_hdr *sshdr, int timeout, int retries)
+		     struct scsi_sense_hdr *sshdr, int timeout, int retries,
+		     int *resid)
 {
 	char *sense = NULL;
 	int result;
@@ -246,7 +251,7 @@ int scsi_execute_req(struct scsi_device *sdev, const unsigned char *cmd,
 			return DRIVER_ERROR << 24;
 	}
 	result = scsi_execute(sdev, cmd, data_direction, buffer, bufflen,
-			      sense, timeout, retries, 0);
+			      sense, timeout, retries, 0, resid);
 	if (sshdr)
 		scsi_normalize_sense(sense, SCSI_SENSE_BUFFERSIZE, sshdr);
 
@@ -2016,7 +2021,7 @@ scsi_mode_select(struct scsi_device *sdev, int pf, int sp, int modepage,
 	}
 
 	ret = scsi_execute_req(sdev, cmd, DMA_TO_DEVICE, real_buffer, len,
-			       sshdr, timeout, retries);
+			       sshdr, timeout, retries, NULL);
 	kfree(real_buffer);
 	return ret;
 }
@@ -2081,7 +2086,7 @@ scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
 	memset(buffer, 0, len);
 
 	result = scsi_execute_req(sdev, cmd, DMA_FROM_DEVICE, buffer, len,
-				  sshdr, timeout, retries);
+				  sshdr, timeout, retries, NULL);
 
 	/* This code looks awful: what it's doing is making sure an
 	 * ILLEGAL REQUEST sense return identifies the actual command
@@ -2163,7 +2168,7 @@ scsi_test_unit_ready(struct scsi_device *sdev, int timeout, int retries,
 	/* try to eat the UNIT_ATTENTION if there are enough retries */
 	do {
 		result = scsi_execute_req(sdev, cmd, DMA_NONE, NULL, 0, sshdr,
-					  timeout, retries);
+					  timeout, retries, NULL);
 		if (sdev->removable && scsi_sense_valid(sshdr) &&
 		    sshdr->sense_key == UNIT_ATTENTION)
 			sdev->changed = 1;

commit b60af5b0adf0da24c673598c8d3fb4d4189a15ce
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Mon Nov 3 15:56:47 2008 -0500

    [SCSI] simplify scsi_io_completion()
    
    This patch (as1142b) consolidates a lot of repetitious code in
    scsi_io_completion().  It also fixes a few comments.  Most
    importantly, however, it clearly distinguishes among the three sorts
    of retries that can be done when a command fails to complete:
    
            Unprepare the request and resubmit it, so that a new
            command will be created for it.
    
            Requeue the request directly so that it will be retried
            immediately using the same command.
    
            Requeue the request so that it will be retried following
            a short delay.
    
            Complete the remainder of the request with an I/O error.
    
    [jejb: Updates
         1. For several error conditions, we would now print the sense twice
            in slightly different ways, so unify the location of sense
            printing.
         2. I added more descriptions to actual failure conditions for
            better debugging
         3. according to spec, ABORTED_COMMAND is supposed to be retried
            (except on DIF failure).  Our old behaviour of erroring it looks
            to be a bug.
         4. I'd prefer not to default initialise the action variable because
            that ensures that every leg of the error handler has an
            associated action and the compiler will warn if someone later
            accidentally misses one or removes one.
    ]
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 148d3af92aef..ecfbbd30dce5 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -875,16 +875,24 @@ static void scsi_end_bidi_request(struct scsi_cmnd *cmd)
  *              (the normal case for most drivers), we don't need
  *              the logic to deal with cleaning up afterwards.
  *
- *		We must do one of several things here:
- *
- *		a) Call scsi_end_request.  This will finish off the
- *		   specified number of sectors.  If we are done, the
- *		   command block will be released, and the queue
- *		   function will be goosed.  If we are not done, then
- *		   scsi_end_request will directly goose the queue.
- *
- *		b) We can just use scsi_requeue_command() here.  This would
- *		   be used if we just wanted to retry, for example.
+ *		We must call scsi_end_request().  This will finish off
+ *		the specified number of sectors.  If we are done, the
+ *		command block will be released and the queue function
+ *		will be goosed.  If we are not done then we have to
+ *		figure out what to do next:
+ *
+ *		a) We can call scsi_requeue_command().  The request
+ *		   will be unprepared and put back on the queue.  Then
+ *		   a new command will be created for it.  This should
+ *		   be used if we made forward progress, or if we want
+ *		   to switch from READ(10) to READ(6) for example.
+ *
+ *		b) We can call scsi_queue_insert().  The request will
+ *		   be put back on the queue and retried using the same
+ *		   command as before, possibly after a delay.
+ *
+ *		c) We can call blk_end_request() with -EIO to fail
+ *		   the remainder of the request.
  */
 void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 {
@@ -896,6 +904,9 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	struct scsi_sense_hdr sshdr;
 	int sense_valid = 0;
 	int sense_deferred = 0;
+	enum {ACTION_FAIL, ACTION_REPREP, ACTION_RETRY,
+	      ACTION_DELAYED_RETRY} action;
+	char *description = NULL;
 
 	if (result) {
 		sense_valid = scsi_command_normalize_sense(cmd, &sshdr);
@@ -947,10 +958,13 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		return;
 	this_count = blk_rq_bytes(req);
 
-	/* good_bytes = 0, or (inclusive) there were leftovers and
-	 * result = 0, so scsi_end_request couldn't retry.
-	 */
-	if (sense_valid && !sense_deferred) {
+	if (host_byte(result) == DID_RESET) {
+		/* Third party bus reset or reset for error recovery
+		 * reasons.  Just retry the command and see what
+		 * happens.
+		 */
+		action = ACTION_RETRY;
+	} else if (sense_valid && !sense_deferred) {
 		switch (sshdr.sense_key) {
 		case UNIT_ATTENTION:
 			if (cmd->device->removable) {
@@ -958,16 +972,15 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				 * and quietly refuse further access.
 				 */
 				cmd->device->changed = 1;
-				scsi_end_request(cmd, -EIO, this_count, 1);
-				return;
+				description = "Media Changed";
+				action = ACTION_FAIL;
 			} else {
 				/* Must have been a power glitch, or a
 				 * bus reset.  Could not have been a
 				 * media change, so we just retry the
-				 * request and see what happens.
+				 * command and see what happens.
 				 */
-				scsi_requeue_command(q, cmd);
-				return;
+				action = ACTION_RETRY;
 			}
 			break;
 		case ILLEGAL_REQUEST:
@@ -983,21 +996,18 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			    sshdr.asc == 0x20 && sshdr.ascq == 0x00) &&
 			    (cmd->cmnd[0] == READ_10 ||
 			     cmd->cmnd[0] == WRITE_10)) {
+				/* This will issue a new 6-byte command. */
 				cmd->device->use_10_for_rw = 0;
-				/* This will cause a retry with a
-				 * 6-byte command.
-				 */
-				scsi_requeue_command(q, cmd);
-			} else if (sshdr.asc == 0x10) /* DIX */
-				scsi_end_request(cmd, -EIO, this_count, 0);
-			else
-				scsi_end_request(cmd, -EIO, this_count, 1);
-			return;
+				action = ACTION_REPREP;
+			} else
+				action = ACTION_FAIL;
+			break;
 		case ABORTED_COMMAND:
 			if (sshdr.asc == 0x10) { /* DIF */
-				scsi_end_request(cmd, -EIO, this_count, 0);
-				return;
-			}
+				action = ACTION_FAIL;
+				description = "Data Integrity Failure";
+			} else
+				action = ACTION_RETRY;
 			break;
 		case NOT_READY:
 			/* If the device is in the process of becoming
@@ -1012,49 +1022,57 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				case 0x07: /* operation in progress */
 				case 0x08: /* Long write in progress */
 				case 0x09: /* self test in progress */
-					scsi_requeue_command(q, cmd);
-					return;
-				default:
+					action = ACTION_DELAYED_RETRY;
 					break;
 				}
+			} else {
+				description = "Device not ready";
+				action = ACTION_FAIL;
 			}
-			if (!(req->cmd_flags & REQ_QUIET))
-				scsi_cmd_print_sense_hdr(cmd,
-							 "Device not ready",
-							 &sshdr);
-
-			scsi_end_request(cmd, -EIO, this_count, 1);
-			return;
+			break;
 		case VOLUME_OVERFLOW:
-			if (!(req->cmd_flags & REQ_QUIET)) {
-				scmd_printk(KERN_INFO, cmd,
-					    "Volume overflow, CDB: ");
-				__scsi_print_command(cmd->cmnd);
-				scsi_print_sense("", cmd);
-			}
 			/* See SSC3rXX or current. */
-			scsi_end_request(cmd, -EIO, this_count, 1);
-			return;
+			action = ACTION_FAIL;
+			break;
 		default:
+			description = "Unhandled sense code";
+			action = ACTION_FAIL;
 			break;
 		}
+	} else {
+		description = "Unhandled error code";
+		action = ACTION_FAIL;
 	}
-	if (host_byte(result) == DID_RESET) {
-		/* Third party bus reset or reset for error recovery
-		 * reasons.  Just retry the request and see what
-		 * happens.
-		 */
-		scsi_requeue_command(q, cmd);
-		return;
-	}
-	if (result) {
+
+	switch (action) {
+	case ACTION_FAIL:
+		/* Give up and fail the remainder of the request */
 		if (!(req->cmd_flags & REQ_QUIET)) {
+			if (description)
+				scmd_printk(KERN_INFO, cmd, "%s",
+					    description);
 			scsi_print_result(cmd);
 			if (driver_byte(result) & DRIVER_SENSE)
 				scsi_print_sense("", cmd);
 		}
+		blk_end_request(req, -EIO, blk_rq_bytes(req));
+		scsi_next_command(cmd);
+		break;
+	case ACTION_REPREP:
+		/* Unprep the request and put it back at the head of the queue.
+		 * A new command will be prepared and issued.
+		 */
+		scsi_requeue_command(q, cmd);
+		break;
+	case ACTION_RETRY:
+		/* Retry the same command immediately */
+		scsi_queue_insert(cmd, SCSI_MLQUEUE_EH_RETRY);
+		break;
+	case ACTION_DELAYED_RETRY:
+		/* Retry the same command after a delay */
+		scsi_queue_insert(cmd, SCSI_MLQUEUE_DEVICE_BUSY);
+		break;
 	}
-	scsi_end_request(cmd, -EIO, this_count, !result);
 }
 
 static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb,

commit 02bd3499a3be984f1e88821c3ed252c8c49c498e
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Fri Dec 12 13:28:29 2008 -0600

    [SCSI] scsi_lib: only call scsi_unprep_request() under queue lock
    
    It's called under that lock everywhere else and it does alter the
    request state, so it should be.
    
    This one occurance in scsi_requeue_command() could open a window where
    req->special is set to NULL while the requests is going through either
    timeout or completion processing leading to NULL pointer derefs of the
    sort complained of in bugzillas 12020 and 12195.
    
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index fa45a1a66867..148d3af92aef 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -648,8 +648,8 @@ static void scsi_requeue_command(struct request_queue *q, struct scsi_cmnd *cmd)
 	struct request *req = cmd->request;
 	unsigned long flags;
 
-	scsi_unprep_request(req);
 	spin_lock_irqsave(q->queue_lock, flags);
+	scsi_unprep_request(req);
 	blk_requeue_request(q, req);
 	spin_unlock_irqrestore(q->queue_lock, flags);
 

commit 2a3a59e5c977654d3aad5bc11cc0aca2303a7f44
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Tue Nov 11 13:42:35 2008 -0600

    [SCSI] Fix hang in starved list processing
    
    Close possible infinite loop with interrupts off when devices are
    added back to the starved list.
    
    Fixes: http://bugzilla.kernel.org/show_bug.cgi?id=11898
    
    Reported-by: <alex.shi@intel.com>
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f5d3b96890dc..fa45a1a66867 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -567,15 +567,18 @@ static inline int scsi_host_is_busy(struct Scsi_Host *shost)
  */
 static void scsi_run_queue(struct request_queue *q)
 {
-	struct scsi_device *starved_head = NULL, *sdev = q->queuedata;
+	struct scsi_device *sdev = q->queuedata;
 	struct Scsi_Host *shost = sdev->host;
+	LIST_HEAD(starved_list);
 	unsigned long flags;
 
 	if (scsi_target(sdev)->single_lun)
 		scsi_single_lun_run(sdev);
 
 	spin_lock_irqsave(shost->host_lock, flags);
-	while (!list_empty(&shost->starved_list) && !scsi_host_is_busy(shost)) {
+	list_splice_init(&shost->starved_list, &starved_list);
+
+	while (!list_empty(&starved_list)) {
 		int flagset;
 
 		/*
@@ -588,24 +591,18 @@ static void scsi_run_queue(struct request_queue *q)
 		 * scsi_request_fn must get the host_lock before checking
 		 * or modifying starved_list or starved_entry.
 		 */
-		sdev = list_entry(shost->starved_list.next,
-					  struct scsi_device, starved_entry);
-		/*
-		 * The *queue_ready functions can add a device back onto the
-		 * starved list's tail, so we must check for a infinite loop.
-		 */
-		if (sdev == starved_head)
+		if (scsi_host_is_busy(shost))
 			break;
-		if (!starved_head)
-			starved_head = sdev;
 
+		sdev = list_entry(starved_list.next,
+				  struct scsi_device, starved_entry);
+		list_del_init(&sdev->starved_entry);
 		if (scsi_target_is_busy(scsi_target(sdev))) {
 			list_move_tail(&sdev->starved_entry,
 				       &shost->starved_list);
 			continue;
 		}
 
-		list_del_init(&sdev->starved_entry);
 		spin_unlock(shost->host_lock);
 
 		spin_lock(sdev->request_queue->queue_lock);
@@ -621,6 +618,8 @@ static void scsi_run_queue(struct request_queue *q)
 
 		spin_lock(shost->host_lock);
 	}
+	/* put any unprocessed entries back */
+	list_splice(&starved_list, &shost->starved_list);
 	spin_unlock_irqrestore(shost->host_lock, flags);
 
 	blk_run_queue(q);

commit 6c5121b78ba5c70a9990e2af6cb4d6bbffe0d4d8
Author: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
Date:   Sat Oct 4 14:11:35 2008 -0400

    [SCSI] export busy state via q->lld_busy_fn()
    
    This patch implements q->lld_busy_fn() for scsi mid layer to export
    its busy state for request stacking drivers.
    
    For efficiency, no lock is taken to check the busy state of
    shost/starget/sdev, since the returned value is not guaranteed and
    may be changed after request stacking drivers call the function,
    regardless of taking lock or not.
    
    When scsi can't dispatch I/Os anymore and needs to kill I/Os
    (e.g. !sdev), scsi needs to return 'not busy'.
    Otherwise, request stacking drivers may hold requests forever.
    
    Signed-off-by: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1e7c9e9ef772..f5d3b96890dc 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1464,6 +1464,37 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 	return 1;
 }
 
+/*
+ * Busy state exporting function for request stacking drivers.
+ *
+ * For efficiency, no lock is taken to check the busy state of
+ * shost/starget/sdev, since the returned value is not guaranteed and
+ * may be changed after request stacking drivers call the function,
+ * regardless of taking lock or not.
+ *
+ * When scsi can't dispatch I/Os anymore and needs to kill I/Os
+ * (e.g. !sdev), scsi needs to return 'not busy'.
+ * Otherwise, request stacking drivers may hold requests forever.
+ */
+static int scsi_lld_busy(struct request_queue *q)
+{
+	struct scsi_device *sdev = q->queuedata;
+	struct Scsi_Host *shost;
+	struct scsi_target *starget;
+
+	if (!sdev)
+		return 0;
+
+	shost = sdev->host;
+	starget = scsi_target(sdev);
+
+	if (scsi_host_in_recovery(shost) || scsi_host_is_busy(shost) ||
+	    scsi_target_is_busy(starget) || scsi_device_is_busy(sdev))
+		return 1;
+
+	return 0;
+}
+
 /*
  * Kill a request for a dead device
  */
@@ -1767,6 +1798,7 @@ struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
 	blk_queue_prep_rq(q, scsi_prep_fn);
 	blk_queue_softirq_done(q, scsi_softirq_done);
 	blk_queue_rq_timed_out(q, scsi_times_out);
+	blk_queue_lld_busy(q, scsi_lld_busy);
 	return q;
 }
 

commit 9d11251709f31d49c8167a619d4475fdf6cd7f73
Author: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
Date:   Sat Oct 4 14:11:06 2008 -0400

    [SCSI] refactor sdev/starget/shost busy checking
    
    This patch refactors the busy checking codes of scsi_device,
    Scsi_Host and scsi_target.  There should be no functional change.
    
    This is a preparation for another patch which exports scsi's busy
    state to the block layer for request stacking drivers.
    
    Signed-off-by: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f35a0951e469..1e7c9e9ef772 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -529,6 +529,14 @@ static void scsi_single_lun_run(struct scsi_device *current_sdev)
 	spin_unlock_irqrestore(shost->host_lock, flags);
 }
 
+static inline int scsi_device_is_busy(struct scsi_device *sdev)
+{
+	if (sdev->device_busy >= sdev->queue_depth || sdev->device_blocked)
+		return 1;
+
+	return 0;
+}
+
 static inline int scsi_target_is_busy(struct scsi_target *starget)
 {
 	return ((starget->can_queue > 0 &&
@@ -536,6 +544,15 @@ static inline int scsi_target_is_busy(struct scsi_target *starget)
 		 starget->target_blocked);
 }
 
+static inline int scsi_host_is_busy(struct Scsi_Host *shost)
+{
+	if ((shost->can_queue > 0 && shost->host_busy >= shost->can_queue) ||
+	    shost->host_blocked || shost->host_self_blocked)
+		return 1;
+
+	return 0;
+}
+
 /*
  * Function:	scsi_run_queue()
  *
@@ -558,11 +575,7 @@ static void scsi_run_queue(struct request_queue *q)
 		scsi_single_lun_run(sdev);
 
 	spin_lock_irqsave(shost->host_lock, flags);
-	while (!list_empty(&shost->starved_list) &&
-	       !shost->host_blocked && !shost->host_self_blocked &&
-		!((shost->can_queue > 0) &&
-		  (shost->host_busy >= shost->can_queue))) {
-
+	while (!list_empty(&shost->starved_list) && !scsi_host_is_busy(shost)) {
 		int flagset;
 
 		/*
@@ -1348,8 +1361,6 @@ int scsi_prep_fn(struct request_queue *q, struct request *req)
 static inline int scsi_dev_queue_ready(struct request_queue *q,
 				  struct scsi_device *sdev)
 {
-	if (sdev->device_busy >= sdev->queue_depth)
-		return 0;
 	if (sdev->device_busy == 0 && sdev->device_blocked) {
 		/*
 		 * unblock after device_blocked iterates to zero
@@ -1363,7 +1374,7 @@ static inline int scsi_dev_queue_ready(struct request_queue *q,
 			return 0;
 		}
 	}
-	if (sdev->device_blocked)
+	if (scsi_device_is_busy(sdev))
 		return 0;
 
 	return 1;
@@ -1440,8 +1451,7 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 			return 0;
 		}
 	}
-	if ((shost->can_queue > 0 && shost->host_busy >= shost->can_queue) ||
-	    shost->host_blocked || shost->host_self_blocked) {
+	if (scsi_host_is_busy(shost)) {
 		if (list_empty(&sdev->starved_entry))
 			list_add_tail(&sdev->starved_entry, &shost->starved_list);
 		return 0;

commit 32c356d76d7e13dcd0675189d8e9c64ef66aa561
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Wed Aug 20 00:58:13 2008 +0200

    [SCSI] fix removable device inability to detect disk changes
    
    On Tue, 12 Aug 2008 15:08:14 +0200
    Giuliano Pochini <pochini@shiny.it> wrote:
    
    > Fujitsu magneto-optical drive, Adaptec 29160 and
    > Linux Jay 2.6.26 #7 SMP Sun Aug 10 18:34:22 CEST 2008 ppc 7455, altivec supported PowerMac3,6 GNU/Linux
    >
    > When I insert a disk and I mount it, scsi_test_unit_ready() is called and
    > the do-while loop gets sshdr->sense_key == UNIT_ATTENTION in the first
    > cycle and 0 in the second one. So the if below misses the UNIT_ATTENTION
    > and sdev->changed = 1 is not executed. At this point bad things can
    > happen... I'm not sure how to fix this. Any clue ?
    
    The problem is essentially caused by us eating UNIT_ATTENTION
    conditions in scsi_test_unit_ready().  Fix by updating the ->changed
    flag when this happens if the media is removable.
    
    [pochini@shiny.it: updates to tidy up patch]
    Signed-off-by: Giuliano Pochini <pochini@shiny.it>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e5a9526d2037..f35a0951e469 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2105,22 +2105,21 @@ scsi_test_unit_ready(struct scsi_device *sdev, int timeout, int retries,
 	do {
 		result = scsi_execute_req(sdev, cmd, DMA_NONE, NULL, 0, sshdr,
 					  timeout, retries);
-	} while ((driver_byte(result) & DRIVER_SENSE) &&
-		 sshdr && sshdr->sense_key == UNIT_ATTENTION &&
-		 --retries);
+		if (sdev->removable && scsi_sense_valid(sshdr) &&
+		    sshdr->sense_key == UNIT_ATTENTION)
+			sdev->changed = 1;
+	} while (scsi_sense_valid(sshdr) &&
+		 sshdr->sense_key == UNIT_ATTENTION && --retries);
 
 	if (!sshdr)
 		/* could not allocate sense buffer, so can't process it */
 		return result;
 
-	if ((driver_byte(result) & DRIVER_SENSE) && sdev->removable) {
-
-		if ((scsi_sense_valid(sshdr)) &&
-		    ((sshdr->sense_key == UNIT_ATTENTION) ||
-		     (sshdr->sense_key == NOT_READY))) {
-			sdev->changed = 1;
-			result = 0;
-		}
+	if (sdev->removable && scsi_sense_valid(sshdr) &&
+	    (sshdr->sense_key == UNIT_ATTENTION ||
+	     sshdr->sense_key == NOT_READY)) {
+		sdev->changed = 1;
+		result = 0;
 	}
 	if (!sshdr_external)
 		kfree(sshdr);

commit 4a27446f3e39b06c28d1c8e31d33a5340826ed5c
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Tue Aug 19 18:45:31 2008 -0500

    [SCSI] modify scsi to handle new fail fast flags.
    
    This checks the errors the scsi-ml determined were retryable
    and returns if we should fast fail it based on the request
    fail fast flags.
    
    Without the patch, drivers like lpfc, qla2xxx and fcoe would return
    DID_ERROR for what it determines is a temporary communication problem.
    There is no loss of connectivity at that time and the driver thinks
    that it would be fast to retry at the driver level. SCSI-ml will however
    sees fast fail on the request and DID_ERROR and will fast fail the io.
    This will then cause dm-multipath to fail the path and possibley switch
    target controllers when we should be retrying at the scsi layer.
    
    We also were fast failing device errors to dm multiapth when
    unless the scsi_dh modules think otherwis we want to retry at
    the scsi layer because multipath can only retry the IO like scsi
    should have done. multipath is a little dumber though because it
    does not what the error was for and assumes that it should fail
    the paths.
    
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 91c74c55aa5e..e5a9526d2037 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -706,7 +706,7 @@ static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int error,
 			leftover = req->data_len;
 
 		/* kill remainder if no retrys */
-		if (error && blk_noretry_request(req))
+		if (error && scsi_noretry_cmd(cmd))
 			blk_end_request(req, error, leftover);
 		else {
 			if (requeue) {

commit f0c0a376d0fcd4c5579ecf5e95f88387cba85211
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Sun Aug 17 15:24:38 2008 -0500

    [SCSI] Add helper code so transport classes/driver can control queueing (v3)
    
    SCSI-ml manages the queueing limits for the device and host, but
    does not do so at the target level. However something something similar
    can come in userful when a driver is transitioning a transport object to
    the the blocked state, becuase at that time we do not want to queue
    io and we do not want the queuecommand to be called again.
    
    The patch adds code similar to the exisiting SCSI_ML_*BUSY handlers.
    You can now return SCSI_MLQUEUE_TARGET_BUSY when we hit
    a transport level queueing issue like the hw cannot allocate some
    resource at the iscsi session/connection level, or the target has temporarily
    closed or shrunk the queueing window, or if we are transitioning
    to the blocked state.
    
    bnx2i, when they rework their firmware according to netdev
    developers requests, will also need to be able to limit queueing at this
    level. bnx2i will hook into libiscsi, but will allocate a scsi host per
    netdevice/hba, so unlike pure software iscsi/iser which is allocating
    a host per session, it cannot set the scsi_host->can_queue and return
    SCSI_MLQUEUE_HOST_BUSY to reflect queueing limits on the transport.
    
    The iscsi class/driver can also set a scsi_target->can_queue value which
    reflects the max commands the driver/class can support. For iscsi this
    reflects the number of commands we can support for each session due to
    session/connection hw limits, driver limits, and to also reflect the
    session/targets's queueing window.
    
    Changes:
    v1 - initial patch.
    v2 - Fix scsi_run_queue handling of multiple blocked targets.
    Previously we would break from the main loop if a device was added back on
    the starved list. We now run over the list and check if any target is
    blocked.
    v3 - Rediff for scsi-misc.
    
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 98ee55ced592..91c74c55aa5e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -114,6 +114,7 @@ int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 {
 	struct Scsi_Host *host = cmd->device->host;
 	struct scsi_device *device = cmd->device;
+	struct scsi_target *starget = scsi_target(device);
 	struct request_queue *q = device->request_queue;
 	unsigned long flags;
 
@@ -133,10 +134,17 @@ int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 	 * if a command is requeued with no other commands outstanding
 	 * either for the device or for the host.
 	 */
-	if (reason == SCSI_MLQUEUE_HOST_BUSY)
+	switch (reason) {
+	case SCSI_MLQUEUE_HOST_BUSY:
 		host->host_blocked = host->max_host_blocked;
-	else if (reason == SCSI_MLQUEUE_DEVICE_BUSY)
+		break;
+	case SCSI_MLQUEUE_DEVICE_BUSY:
 		device->device_blocked = device->max_device_blocked;
+		break;
+	case SCSI_MLQUEUE_TARGET_BUSY:
+		starget->target_blocked = starget->max_target_blocked;
+		break;
+	}
 
 	/*
 	 * Decrement the counters, since these commands are no longer
@@ -460,10 +468,12 @@ static void scsi_init_cmd_errh(struct scsi_cmnd *cmd)
 void scsi_device_unbusy(struct scsi_device *sdev)
 {
 	struct Scsi_Host *shost = sdev->host;
+	struct scsi_target *starget = scsi_target(sdev);
 	unsigned long flags;
 
 	spin_lock_irqsave(shost->host_lock, flags);
 	shost->host_busy--;
+	starget->target_busy--;
 	if (unlikely(scsi_host_in_recovery(shost) &&
 		     (shost->host_failed || shost->host_eh_scheduled)))
 		scsi_eh_wakeup(shost);
@@ -519,6 +529,13 @@ static void scsi_single_lun_run(struct scsi_device *current_sdev)
 	spin_unlock_irqrestore(shost->host_lock, flags);
 }
 
+static inline int scsi_target_is_busy(struct scsi_target *starget)
+{
+	return ((starget->can_queue > 0 &&
+		 starget->target_busy >= starget->can_queue) ||
+		 starget->target_blocked);
+}
+
 /*
  * Function:	scsi_run_queue()
  *
@@ -533,7 +550,7 @@ static void scsi_single_lun_run(struct scsi_device *current_sdev)
  */
 static void scsi_run_queue(struct request_queue *q)
 {
-	struct scsi_device *sdev = q->queuedata;
+	struct scsi_device *starved_head = NULL, *sdev = q->queuedata;
 	struct Scsi_Host *shost = sdev->host;
 	unsigned long flags;
 
@@ -560,6 +577,21 @@ static void scsi_run_queue(struct request_queue *q)
 		 */
 		sdev = list_entry(shost->starved_list.next,
 					  struct scsi_device, starved_entry);
+		/*
+		 * The *queue_ready functions can add a device back onto the
+		 * starved list's tail, so we must check for a infinite loop.
+		 */
+		if (sdev == starved_head)
+			break;
+		if (!starved_head)
+			starved_head = sdev;
+
+		if (scsi_target_is_busy(scsi_target(sdev))) {
+			list_move_tail(&sdev->starved_entry,
+				       &shost->starved_list);
+			continue;
+		}
+
 		list_del_init(&sdev->starved_entry);
 		spin_unlock(shost->host_lock);
 
@@ -575,13 +607,6 @@ static void scsi_run_queue(struct request_queue *q)
 		spin_unlock(sdev->request_queue->queue_lock);
 
 		spin_lock(shost->host_lock);
-		if (unlikely(!list_empty(&sdev->starved_entry)))
-			/*
-			 * sdev lost a race, and was put back on the
-			 * starved list. This is unlikely but without this
-			 * in theory we could loop forever.
-			 */
-			break;
 	}
 	spin_unlock_irqrestore(shost->host_lock, flags);
 
@@ -1344,6 +1369,52 @@ static inline int scsi_dev_queue_ready(struct request_queue *q,
 	return 1;
 }
 
+
+/*
+ * scsi_target_queue_ready: checks if there we can send commands to target
+ * @sdev: scsi device on starget to check.
+ *
+ * Called with the host lock held.
+ */
+static inline int scsi_target_queue_ready(struct Scsi_Host *shost,
+					   struct scsi_device *sdev)
+{
+	struct scsi_target *starget = scsi_target(sdev);
+
+	if (starget->single_lun) {
+		if (starget->starget_sdev_user &&
+		    starget->starget_sdev_user != sdev)
+			return 0;
+		starget->starget_sdev_user = sdev;
+	}
+
+	if (starget->target_busy == 0 && starget->target_blocked) {
+		/*
+		 * unblock after target_blocked iterates to zero
+		 */
+		if (--starget->target_blocked == 0) {
+			SCSI_LOG_MLQUEUE(3, starget_printk(KERN_INFO, starget,
+					 "unblocking target at zero depth\n"));
+		} else {
+			blk_plug_device(sdev->request_queue);
+			return 0;
+		}
+	}
+
+	if (scsi_target_is_busy(starget)) {
+		if (list_empty(&sdev->starved_entry)) {
+			list_add_tail(&sdev->starved_entry,
+				      &shost->starved_list);
+			return 0;
+		}
+	}
+
+	/* We're OK to process the command, so we can't be starved */
+	if (!list_empty(&sdev->starved_entry))
+		list_del_init(&sdev->starved_entry);
+	return 1;
+}
+
 /*
  * scsi_host_queue_ready: if we can send requests to shost, return 1 else
  * return 0. We must end up running the queue again whenever 0 is
@@ -1390,6 +1461,7 @@ static void scsi_kill_request(struct request *req, struct request_queue *q)
 {
 	struct scsi_cmnd *cmd = req->special;
 	struct scsi_device *sdev = cmd->device;
+	struct scsi_target *starget = scsi_target(sdev);
 	struct Scsi_Host *shost = sdev->host;
 
 	blkdev_dequeue_request(req);
@@ -1413,6 +1485,7 @@ static void scsi_kill_request(struct request *req, struct request_queue *q)
 	spin_unlock(sdev->request_queue->queue_lock);
 	spin_lock(shost->host_lock);
 	shost->host_busy++;
+	starget->target_busy++;
 	spin_unlock(shost->host_lock);
 	spin_lock(sdev->request_queue->queue_lock);
 
@@ -1550,14 +1623,13 @@ static void scsi_request_fn(struct request_queue *q)
 			goto not_ready;
 		}
 
+		if (!scsi_target_queue_ready(shost, sdev))
+			goto not_ready;
+
 		if (!scsi_host_queue_ready(q, shost, sdev))
 			goto not_ready;
-		if (scsi_target(sdev)->single_lun) {
-			if (scsi_target(sdev)->starget_sdev_user &&
-			    scsi_target(sdev)->starget_sdev_user != sdev)
-				goto not_ready;
-			scsi_target(sdev)->starget_sdev_user = sdev;
-		}
+
+		scsi_target(sdev)->target_busy++;
 		shost->host_busy++;
 
 		/*

commit ef5bef357cdf49f3a386c7102dbf3be5f7e5c913
Merge: e26feff647ef 41bfcf901016
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 10 10:53:26 2008 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6: (37 commits)
      [SCSI] zfcp: fix double dbf id usage
      [SCSI] zfcp: wait on SCSI work to be finished before proceeding with init dev
      [SCSI] zfcp: fix erp list usage without using locks
      [SCSI] zfcp: prevent fc_remote_port_delete calls for unregistered rport
      [SCSI] zfcp: fix deadlock caused by shared work queue tasks
      [SCSI] zfcp: put threshold data in hba trace
      [SCSI] zfcp: Simplify zfcp data structures
      [SCSI] zfcp: Simplify get_adapter_by_busid
      [SCSI] zfcp: remove all typedefs and replace them with standards
      [SCSI] zfcp: attach and release SAN nameserver port on demand
      [SCSI] zfcp: remove unused references, declarations and flags
      [SCSI] zfcp: Update message with input from review
      [SCSI] zfcp: add queue_full sysfs attribute
      [SCSI] scsi_dh: suppress comparison warning
      [SCSI] scsi_dh: add Dell product information into rdac device handler
      [SCSI] qla2xxx: remove the unused SCSI_QLOGIC_FC_FIRMWARE option
      [SCSI] qla2xxx: fix printk format warnings
      [SCSI] qla2xxx: Update version number to 8.02.01-k8.
      [SCSI] qla2xxx: Ignore payload reserved-bits during RSCN processing.
      [SCSI] qla2xxx: Additional residual-count corrections during UNDERRUN handling.
      ...

commit 242f9dcb8ba6f68fcd217a119a7648a4f69290e9
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Sun Sep 14 05:55:09 2008 -0700

    block: unify request timeout handling
    
    Right now SCSI and others do their own command timeout handling.
    Move those bits to the block layer.
    
    Instead of having a timer per command, we try to be a bit more clever
    and simply have one per-queue. This avoids the overhead of having to
    tear down and setup a timer for each command, so it will result in a lot
    less timer fiddling.
    
    Signed-off-by: Mike Anderson <andmike@linux.vnet.ibm.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 62307bd794a9..e7686500e9dd 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1181,7 +1181,6 @@ int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 	
 	cmd->transfersize = req->data_len;
 	cmd->allowed = req->retries;
-	cmd->timeout_per_command = req->timeout;
 	return BLKPREP_OK;
 }
 EXPORT_SYMBOL(scsi_setup_blk_pc_cmnd);
@@ -1416,17 +1415,26 @@ static void scsi_kill_request(struct request *req, struct request_queue *q)
 	spin_unlock(shost->host_lock);
 	spin_lock(sdev->request_queue->queue_lock);
 
-	__scsi_done(cmd);
+	blk_complete_request(req);
 }
 
 static void scsi_softirq_done(struct request *rq)
 {
-	struct scsi_cmnd *cmd = rq->completion_data;
-	unsigned long wait_for = (cmd->allowed + 1) * cmd->timeout_per_command;
+	struct scsi_cmnd *cmd = rq->special;
+	unsigned long wait_for = (cmd->allowed + 1) * rq->timeout;
 	int disposition;
 
 	INIT_LIST_HEAD(&cmd->eh_entry);
 
+	/*
+	 * Set the serial numbers back to zero
+	 */
+	cmd->serial_number = 0;
+
+	atomic_inc(&cmd->device->iodone_cnt);
+	if (cmd->result)
+		atomic_inc(&cmd->device->ioerr_cnt);
+
 	disposition = scsi_decide_disposition(cmd);
 	if (disposition != SUCCESS &&
 	    time_before(cmd->jiffies_at_alloc + wait_for, jiffies)) {
@@ -1675,6 +1683,7 @@ struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
 
 	blk_queue_prep_rq(q, scsi_prep_fn);
 	blk_queue_softirq_done(q, scsi_softirq_done);
+	blk_queue_rq_timed_out(q, scsi_times_out);
 	return q;
 }
 

commit 6f4267e3bd1211b3d09130e626b0b3d885077610
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Fri Aug 22 16:53:31 2008 -0500

    [SCSI] Update the SCSI state model to allow blocking in the created state
    
    Brian King <brking@linux.vnet.ibm.com> reported that fibre channel
    devices can oops during scanning if their ports block (because the
    device goes from CREATED -> BLOCK -> RUNNING rather than CREATED ->
    BLOCK -> CREATED).
    
    Fix this by adding a new state: CREATED_BLOCK which can only transition
    back to CREATED and disallow the CREATED -> BLOCK transition.  Now both
    the created and blocked states that the mid-layer recognises can include
    CREATED_BLOCK.
    
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 62307bd794a9..d2884bffa1b9 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1251,6 +1251,7 @@ int scsi_prep_state_check(struct scsi_device *sdev, struct request *req)
 			break;
 		case SDEV_QUIESCE:
 		case SDEV_BLOCK:
+		case SDEV_CREATED_BLOCK:
 			/*
 			 * If the devices is blocked we defer normal commands.
 			 */
@@ -2064,10 +2065,13 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 
 	switch (state) {
 	case SDEV_CREATED:
-		/* There are no legal states that come back to
-		 * created.  This is the manually initialised start
-		 * state */
-		goto illegal;
+		switch (oldstate) {
+		case SDEV_CREATED_BLOCK:
+			break;
+		default:
+			goto illegal;
+		}
+		break;
 			
 	case SDEV_RUNNING:
 		switch (oldstate) {
@@ -2105,8 +2109,17 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 
 	case SDEV_BLOCK:
 		switch (oldstate) {
-		case SDEV_CREATED:
 		case SDEV_RUNNING:
+		case SDEV_CREATED_BLOCK:
+			break;
+		default:
+			goto illegal;
+		}
+		break;
+
+	case SDEV_CREATED_BLOCK:
+		switch (oldstate) {
+		case SDEV_CREATED:
 			break;
 		default:
 			goto illegal;
@@ -2394,8 +2407,12 @@ scsi_internal_device_block(struct scsi_device *sdev)
 	int err = 0;
 
 	err = scsi_device_set_state(sdev, SDEV_BLOCK);
-	if (err)
-		return err;
+	if (err) {
+		err = scsi_device_set_state(sdev, SDEV_CREATED_BLOCK);
+
+		if (err)
+			return err;
+	}
 
 	/* 
 	 * The device has transitioned to SDEV_BLOCK.  Stop the
@@ -2438,8 +2455,12 @@ scsi_internal_device_unblock(struct scsi_device *sdev)
 	 * and goose the device queue if successful.  
 	 */
 	err = scsi_device_set_state(sdev, SDEV_RUNNING);
-	if (err)
-		return err;
+	if (err) {
+		err = scsi_device_set_state(sdev, SDEV_CREATED);
+
+		if (err)
+			return err;
+	}
 
 	spin_lock_irqsave(q->queue_lock, flags);
 	blk_start_queue(q);

commit 44ea91c597ae4641d9ac21b8bbba0795d2f4261e
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Sat Sep 20 00:31:50 2008 +0000

    [SCSI] Fix hang with split requests
    
    Sometimes, particularly for USB devices with the last sector bug,
    requests get completed in chunks.  There's a bug in this in that if
    one of the chunks gets an error, we complete that chunk with an error
    but never move on to the remaining ones, leading to the request
    hanging (because it's not fully completed).
    
    Fix this by completing all remaining chunks if an error is encountered.
    
    Cc: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ff5d56b3ee4d..62307bd794a9 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -852,7 +852,7 @@ static void scsi_end_bidi_request(struct scsi_cmnd *cmd)
 void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 {
 	int result = cmd->result;
-	int this_count = scsi_bufflen(cmd);
+	int this_count;
 	struct request_queue *q = cmd->device->request_queue;
 	struct request *req = cmd->request;
 	int error = 0;
@@ -908,6 +908,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	 */
 	if (scsi_end_request(cmd, error, good_bytes, result == 0) == NULL)
 		return;
+	this_count = blk_rq_bytes(req);
 
 	/* good_bytes = 0, or (inclusive) there were leftovers and
 	 * result = 0, so scsi_end_request couldn't retry.

commit cadbd4a5e36dde7e6c49b587b2c419103c0b7218
Author: Harvey Harrison <harvey.harrison@gmail.com>
Date:   Thu Jul 3 23:47:27 2008 -0700

    [SCSI] replace __FUNCTION__ with __func__
    
    [jejb: fixed up a ton of missed conversions.
    
     All of you are on notice this has happened, driver trees will now
     need to be rebased]
    
    Signed-off-by: Harvey Harrison <harvey.harrison@gmail.com>
    Cc: SCSI List <linux-scsi@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 6d62be664d55..ff5d56b3ee4d 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1395,7 +1395,7 @@ static void scsi_kill_request(struct request *req, struct request_queue *q)
 
 	if (unlikely(cmd == NULL)) {
 		printk(KERN_CRIT "impossible request in %s.\n",
-				 __FUNCTION__);
+				 __func__);
 		BUG();
 	}
 
@@ -1519,7 +1519,7 @@ static void scsi_request_fn(struct request_queue *q)
 			printk(KERN_CRIT "impossible request in %s.\n"
 					 "please mail a stack trace to "
 					 "linux-scsi@vger.kernel.org\n",
-					 __FUNCTION__);
+					 __func__);
 			blk_dump_rq_flags(req, "foo");
 			BUG();
 		}
@@ -2529,7 +2529,7 @@ void *scsi_kmap_atomic_sg(struct scatterlist *sgl, int sg_count,
 	if (unlikely(i == sg_count)) {
 		printk(KERN_ERR "%s: Bytes in sg: %zu, requested offset %zu, "
 			"elements %d\n",
-		       __FUNCTION__, sg_len, *offset, sg_count);
+		       __func__, sg_len, *offset, sg_count);
 		WARN_ON(1);
 		return NULL;
 	}

commit 6bd522f6a226f435508433d24e0de4619e016a9d
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Tue Jul 22 15:34:38 2008 -0500

    [SCSI] scsi_lib: use blk_rq_tagged in scsi_request_fn
    
    I goofed and did not see the macro for checking if a request is tagged.
    This patch has us use blk_rq_tagged instead of digging into the req->tag.
    
    Patch was made over scsi-misc.
    
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a20730c48020..6d62be664d55 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1533,7 +1533,7 @@ static void scsi_request_fn(struct request_queue *q)
 		 * we add the dev to the starved list so it eventually gets
 		 * a run when a tag is freed.
 		 */
-		if (blk_queue_tagged(q) && (req->tag == -1)) {
+		if (blk_queue_tagged(q) && !blk_rq_tagged(req)) {
 			if (list_empty(&sdev->starved_entry))
 				list_add_tail(&sdev->starved_entry,
 					      &shost->starved_list);

commit 511e44f42e3239a4df77b8e0e46d294d98a768ad
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Thu Jul 17 04:28:33 2008 -0400

    [SCSI] Do not retry a request whose data integrity check failed
    
    If initiator or target reject the I/O due to DIF errors there is no
    point in retrying.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a47c05d7829a..a20730c48020 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -950,9 +950,14 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				 * 6-byte command.
 				 */
 				scsi_requeue_command(q, cmd);
-				return;
-			} else {
+			} else if (sshdr.asc == 0x10) /* DIX */
+				scsi_end_request(cmd, -EIO, this_count, 0);
+			else
 				scsi_end_request(cmd, -EIO, this_count, 1);
+			return;
+		case ABORTED_COMMAND:
+			if (sshdr.asc == 0x10) { /* DIF */
+				scsi_end_request(cmd, -EIO, this_count, 0);
 				return;
 			}
 			break;

commit 7027ad72a689797475973c6feb5f0b673382f779
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Thu Jul 17 17:08:48 2008 -0400

    [SCSI] Support devices with protection information
    
    Implement support for DMA of protection information for devices that
    are data integrity capable.
    
     - Add support for mapping an extra scatter-gather list containing
       the protection information.
    
     - Allocate protection scsi_data_buffer if host is DIX (integrity DMA)
       capable.
    
     - Accessor function for checking whether a device has protection
       enabled.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index fe77ccacf319..a47c05d7829a 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -65,7 +65,7 @@ static struct scsi_host_sg_pool scsi_sg_pools[] = {
 };
 #undef SP
 
-static struct kmem_cache *scsi_sdb_cache;
+struct kmem_cache *scsi_sdb_cache;
 
 static void scsi_run_queue(struct request_queue *q);
 
@@ -787,6 +787,9 @@ void scsi_release_buffers(struct scsi_cmnd *cmd)
 		kmem_cache_free(scsi_sdb_cache, bidi_sdb);
 		cmd->request->next_rq->special = NULL;
 	}
+
+	if (scsi_prot_sg_count(cmd))
+		scsi_free_sgtable(cmd->prot_sdb);
 }
 EXPORT_SYMBOL(scsi_release_buffers);
 
@@ -1072,6 +1075,26 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 			goto err_exit;
 	}
 
+	if (blk_integrity_rq(cmd->request)) {
+		struct scsi_data_buffer *prot_sdb = cmd->prot_sdb;
+		int ivecs, count;
+
+		BUG_ON(prot_sdb == NULL);
+		ivecs = blk_rq_count_integrity_sg(cmd->request);
+
+		if (scsi_alloc_sgtable(prot_sdb, ivecs, gfp_mask)) {
+			error = BLKPREP_DEFER;
+			goto err_exit;
+		}
+
+		count = blk_rq_map_integrity_sg(cmd->request,
+						prot_sdb->table.sgl);
+		BUG_ON(unlikely(count > ivecs));
+
+		cmd->prot_sdb = prot_sdb;
+		cmd->prot_sdb->table.nents = count;
+	}
+
 	return BLKPREP_OK ;
 
 err_exit:

commit ecefe8a97577d6c1a68d14ab6fb19bce99448af2
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Fri Jul 11 19:50:35 2008 -0500

    [SCSI] fix shared tag map tag allocation
    
    When drivers use a shared tag map we can end up with more requests
    than tags, because the tag map is shost->can_queue tags and there
    can be sdevs * sdev->queue_depth requests. In scsi_request_fn
    if tag allocation fails we just drop down to just dequeueing the
    tag without a tag. The problem is that drivers using the shared tag
    map rely on a valid tag always being set, because it will use the
    tag number to lookup commands later.
    
    This patch has us check if we got a valid tag when the host lock
    is held right before we check if the host queue is ready. We do the
    check here because to allocate the tag we need the q lock, but
    if the tag is bad we want to add the device/q onto the starved list
    which requires the host lock.
    
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 88d1b5f44e59..fe77ccacf319 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1497,6 +1497,21 @@ static void scsi_request_fn(struct request_queue *q)
 		}
 		spin_lock(shost->host_lock);
 
+		/*
+		 * We hit this when the driver is using a host wide
+		 * tag map. For device level tag maps the queue_depth check
+		 * in the device ready fn would prevent us from trying
+		 * to allocate a tag. Since the map is a shared host resource
+		 * we add the dev to the starved list so it eventually gets
+		 * a run when a tag is freed.
+		 */
+		if (blk_queue_tagged(q) && (req->tag == -1)) {
+			if (list_empty(&sdev->starved_entry))
+				list_add_tail(&sdev->starved_entry,
+					      &shost->starved_list);
+			goto not_ready;
+		}
+
 		if (!scsi_host_queue_ready(q, shost, sdev))
 			goto not_ready;
 		if (scsi_target(sdev)->single_lun) {

commit 89a93f2f4834f8c126e8d9dd6b368d0b9e21ec3d
Merge: 260eddf4391f fe9233fb6914
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 15 18:58:04 2008 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6: (102 commits)
      [SCSI] scsi_dh: fix kconfig related build errors
      [SCSI] sym53c8xx: Fix bogus sym_que_entry re-implementation of container_of
      [SCSI] scsi_cmnd.h: remove double inclusion of linux/blkdev.h
      [SCSI] make struct scsi_{host,target}_type static
      [SCSI] fix locking in host use of blk_plug_device()
      [SCSI] zfcp: Cleanup external header file
      [SCSI] zfcp: Cleanup code in zfcp_erp.c
      [SCSI] zfcp: zfcp_fsf cleanup.
      [SCSI] zfcp: consolidate sysfs things into one file.
      [SCSI] zfcp: Cleanup of code in zfcp_aux.c
      [SCSI] zfcp: Cleanup of code in zfcp_scsi.c
      [SCSI] zfcp: Move status accessors from zfcp to SCSI include file.
      [SCSI] zfcp: Small QDIO cleanups
      [SCSI] zfcp: Adapter reopen for large number of unsolicited status
      [SCSI] zfcp: Fix error checking for ELS ADISC requests
      [SCSI] zfcp: wait until adapter is finished with ERP during auto-port
      [SCSI] ibmvfc: IBM Power Virtual Fibre Channel Adapter Client Driver
      [SCSI] sg: Add target reset support
      [SCSI] lib: Add support for the T10 (SCSI) Data Integrity Field CRC
      [SCSI] sd: Move scsi_disk() accessor function to sd.h
      ...

commit 2476b4d0426e1d6d4a42b2f7ae08f668b2cfe510
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Thu Jul 3 11:31:55 2008 -0500

    [SCSI] fix locking in host use of blk_plug_device()
    
    scsi_lib.c:scsi_host_queue_ready() plugs the device with incorrect
    locking.  It should actually have the queue lock held, but it's
    holding the host lock.  Fix this by eliminating the call.  The host
    ready has no need to plug the queue because if it returns 0 in
    scsi_request_function control transfers to not_ready which acquires
    the queue lock and plugs the device if its at zero depth.
    
    Reported-by: Elias Oltmanns <eo@nebensachen.de>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index aa8d5de58839..0451903452e6 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1328,7 +1328,6 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 				printk("scsi%d unblocking host at zero depth\n",
 					shost->host_no));
 		} else {
-			blk_plug_device(q);
 			return 0;
 		}
 	}

commit 6362abd3e00d3161affad996fa53cc69a01fc6d1
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Thu Jun 5 23:30:03 2008 -0400

    [SCSI] Rename scsi_bidi_sdb_cache
    
    The data integrity changes need to dynamically allocate
    scsi_data_buffers too.  Rename scsi_bidi_sdb_cache for clarity.
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 033c58a65f50..aa8d5de58839 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -65,7 +65,7 @@ static struct scsi_host_sg_pool scsi_sg_pools[] = {
 };
 #undef SP
 
-static struct kmem_cache *scsi_bidi_sdb_cache;
+static struct kmem_cache *scsi_sdb_cache;
 
 static void scsi_run_queue(struct request_queue *q);
 
@@ -775,7 +775,7 @@ void scsi_release_buffers(struct scsi_cmnd *cmd)
 		struct scsi_data_buffer *bidi_sdb =
 			cmd->request->next_rq->special;
 		scsi_free_sgtable(bidi_sdb);
-		kmem_cache_free(scsi_bidi_sdb_cache, bidi_sdb);
+		kmem_cache_free(scsi_sdb_cache, bidi_sdb);
 		cmd->request->next_rq->special = NULL;
 	}
 }
@@ -1050,7 +1050,7 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 
 	if (blk_bidi_rq(cmd->request)) {
 		struct scsi_data_buffer *bidi_sdb = kmem_cache_zalloc(
-			scsi_bidi_sdb_cache, GFP_ATOMIC);
+			scsi_sdb_cache, GFP_ATOMIC);
 		if (!bidi_sdb) {
 			error = BLKPREP_DEFER;
 			goto err_exit;
@@ -1692,11 +1692,11 @@ int __init scsi_init_queue(void)
 		return -ENOMEM;
 	}
 
-	scsi_bidi_sdb_cache = kmem_cache_create("scsi_bidi_sdb",
-					sizeof(struct scsi_data_buffer),
-					0, 0, NULL);
-	if (!scsi_bidi_sdb_cache) {
-		printk(KERN_ERR "SCSI: can't init scsi bidi sdb cache\n");
+	scsi_sdb_cache = kmem_cache_create("scsi_data_buffer",
+					   sizeof(struct scsi_data_buffer),
+					   0, 0, NULL);
+	if (!scsi_sdb_cache) {
+		printk(KERN_ERR "SCSI: can't init scsi sdb cache\n");
 		goto cleanup_io_context;
 	}
 
@@ -1709,7 +1709,7 @@ int __init scsi_init_queue(void)
 		if (!sgp->slab) {
 			printk(KERN_ERR "SCSI: can't init sg slab %s\n",
 					sgp->name);
-			goto cleanup_bidi_sdb;
+			goto cleanup_sdb;
 		}
 
 		sgp->pool = mempool_create_slab_pool(SG_MEMPOOL_SIZE,
@@ -1717,13 +1717,13 @@ int __init scsi_init_queue(void)
 		if (!sgp->pool) {
 			printk(KERN_ERR "SCSI: can't init sg mempool %s\n",
 					sgp->name);
-			goto cleanup_bidi_sdb;
+			goto cleanup_sdb;
 		}
 	}
 
 	return 0;
 
-cleanup_bidi_sdb:
+cleanup_sdb:
 	for (i = 0; i < SG_MEMPOOL_NR; i++) {
 		struct scsi_host_sg_pool *sgp = scsi_sg_pools + i;
 		if (sgp->pool)
@@ -1731,7 +1731,7 @@ int __init scsi_init_queue(void)
 		if (sgp->slab)
 			kmem_cache_destroy(sgp->slab);
 	}
-	kmem_cache_destroy(scsi_bidi_sdb_cache);
+	kmem_cache_destroy(scsi_sdb_cache);
 cleanup_io_context:
 	kmem_cache_destroy(scsi_io_context_cache);
 
@@ -1743,7 +1743,7 @@ void scsi_exit_queue(void)
 	int i;
 
 	kmem_cache_destroy(scsi_io_context_cache);
-	kmem_cache_destroy(scsi_bidi_sdb_cache);
+	kmem_cache_destroy(scsi_sdb_cache);
 
 	for (i = 0; i < SG_MEMPOOL_NR; i++) {
 		struct scsi_host_sg_pool *sgp = scsi_sg_pools + i;

commit bdb2b8cab4392ce41ddfbd6773a3da3334daf836
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Tue Jun 24 14:03:14 2008 -0400

    [SCSI] erase invalid data returned by device
    
    This patch (as1108) fixes a problem that can occur with certain USB
    mass-storage devices: They return invalid data together with a residue
    indicating that the data should be ignored.  Rather than leave the
    invalid data in a transfer buffer, where it can get misinterpreted,
    the patch clears the invalid portion of the buffer.
    
    This solves a problem (wrong write-protect setting detected) reported
    by Maciej Rutecki and Peter Teoh.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Tested-by: Peter Teoh <htmldeveloper@gmail.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a82d2fe80fb5..cbf55d59a54c 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -207,6 +207,15 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	 */
 	blk_execute_rq(req->q, NULL, req, 1);
 
+	/*
+	 * Some devices (USB mass-storage in particular) may transfer
+	 * garbage data together with a residue indicating that the data
+	 * is invalid.  Prevent the garbage from being misinterpreted
+	 * and prevent security leaks by zeroing out the excess data.
+	 */
+	if (unlikely(req->data_len > 0 && req->data_len <= bufflen))
+		memset(buffer + (bufflen - req->data_len), 0, req->data_len);
+
 	ret = req->errors;
  out:
 	blk_put_request(req);

commit a6a8d9f87eb8510a8f53672ea87703f62185d75f
Author: Chandra Seetharaman <sekharan@us.ibm.com>
Date:   Thu May 1 14:49:46 2008 -0700

    [SCSI] scsi_dh: add infrastructure for SCSI Device Handlers
    
    Some of the storage devices (that can be accessed through multiple paths),
    do need some special handling for
            1. Activating the passive path of the storage access.
            2. Decode and handle the special sense codes returned by the devices.
            3. Handle the I/Os being sent to the passive path, especially
               during the device probe time.
    when accessed through multiple paths.
    
    As of today this special device handling is done at the dm-multipath
    layer using dm-handlers. That works well for (1); for (2) to be handled
    at dm layer, scsi sense information need to be exported from SCSI to dm-layer,
    which is not very attractive; (3) cannot be done at all at the dm layer.
    
    Device handler has been moved to SCSI mainly to handle (2) and (3) properly.
    
    Signed-off-by: Chandra Seetharaman <sekharan@us.ibm.com>
    Signed-off-by: Mike Anderson <andmike@linux.vnet.ibm.com>
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a82d2fe80fb5..033c58a65f50 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1160,6 +1160,14 @@ int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
 
 	if (ret != BLKPREP_OK)
 		return ret;
+
+	if (unlikely(sdev->scsi_dh_data && sdev->scsi_dh_data->scsi_dh
+			 && sdev->scsi_dh_data->scsi_dh->prep_fn)) {
+		ret = sdev->scsi_dh_data->scsi_dh->prep_fn(sdev, req);
+		if (ret != BLKPREP_OK)
+			return ret;
+	}
+
 	/*
 	 * Filesystem requests must transfer data.
 	 */

commit d626e3bf728c47746f2129aa00c775d4e8c2a73b
Merge: b66e1f11ebc4 7ad4a485002c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 2 13:52:35 2008 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6:
      [SCSI] aic94xx: fix section mismatch
      [SCSI] u14-34f: Fix 32bit only problem
      [SCSI] dpt_i2o: sysfs code
      [SCSI] dpt_i2o: 64 bit support
      [SCSI] dpt_i2o: move from virt_to_bus/bus_to_virt to dma_alloc_coherent
      [SCSI] dpt_i2o: use standard __init / __exit code
      [SCSI] megaraid_sas: fix suspend/resume sections
      [SCSI] aacraid: Add Power Management support
      [SCSI] aacraid: Fix jbod operations scan issues
      [SCSI] aacraid: Fix warning about macro side-effects
      [SCSI] add support for variable length extended commands
      [SCSI] Let scsi_cmnd->cmnd use request->cmd buffer
      [SCSI] bsg: add large command support
      [SCSI] aacraid: Fix down_interruptible() to check the return value correctly
      [SCSI] megaraid_sas; Update the Version and Changelog
      [SCSI] ibmvscsi: Handle non SCSI error status
      [SCSI] bug fix for free list handling
      [SCSI] ipr: Rename ipr's state scsi host attribute to prevent collisions
      [SCSI] megaraid_mbox: fix Dell CERC firmware problem

commit db4742dd8f0aa9125b74f9b2516336a75f3d9106
Author: Boaz Harrosh <bharrosh@panasas.com>
Date:   Wed Apr 30 11:27:26 2008 +0300

    [SCSI] add support for variable length extended commands
    
    Add support for variable-length, extended, and vendor specific
    CDBs to scsi-ml. It is now possible for initiators and ULD's
    to issue these types of commands. LLDs need not change much.
    All they need is to raise the .max_cmd_len to the longest command
    they support (see iscsi patch).
    
    - clean-up some code paths that did not expect commands to be
      larger than 16, and change cmd_len members' type to short as
      char is not enough.
    
    Signed-off-by: Boaz Harrosh <bharrosh@panasas.com>
    Signed-off-by: Benny Halevy <bhalevy@panasas.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 325270b520e1..ba7e8ad76d04 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -445,7 +445,7 @@ static void scsi_init_cmd_errh(struct scsi_cmnd *cmd)
 	scsi_set_resid(cmd, 0);
 	memset(cmd->sense_buffer, 0, SCSI_SENSE_BUFFERSIZE);
 	if (cmd->cmd_len == 0)
-		cmd->cmd_len = COMMAND_SIZE(cmd->cmnd[0]);
+		cmd->cmd_len = scsi_command_size(cmd->cmnd);
 }
 
 void scsi_device_unbusy(struct scsi_device *sdev)

commit 64a87b244b9297667ca80264aab849a36f494884
Author: Boaz Harrosh <bharrosh@panasas.com>
Date:   Wed Apr 30 11:19:47 2008 +0300

    [SCSI] Let scsi_cmnd->cmnd use request->cmd buffer
    
     - struct scsi_cmnd had a 16 bytes command buffer of its own.
       This is an unnecessary duplication and copy of request's
       cmd. It is probably left overs from the time that scsi_cmnd
       could function without a request attached. So clean that up.
    
     - Once above is done, few places, apart from scsi-ml, needed
       adjustments due to changing the data type of scsi_cmnd->cmnd.
    
     - Lots of drivers still use MAX_COMMAND_SIZE. So I have left
       that #define but equate it to BLK_MAX_CDB. The way I see it
       and is reflected in the patch below is.
       MAX_COMMAND_SIZE - means: The longest fixed-length (*) SCSI CDB
                          as per the SCSI standard and is not related
                          to the implementation.
       BLK_MAX_CDB.     - The allocated space at the request level
    
     - I have audit all ISA drivers and made sure none use ->cmnd in a DMA
       Operation. Same audit was done by Andi Kleen.
    
    (*)fixed-length here means commands that their size can be determined
       by their opcode and the CDB does not carry a length specifier, (unlike
       the VARIABLE_LENGTH_CMD(0x7f) command). This is actually not exactly
       true and the SCSI standard also defines extended commands and
       vendor specific commands that can be bigger than 16 bytes. The kernel
       will support these using the same infrastructure used for VARLEN CDB's.
       So in effect MAX_COMMAND_SIZE means the maximum size command
       scsi-ml supports without specifying a cmd_len by ULD's
    
    Signed-off-by: Boaz Harrosh <bharrosh@panasas.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 67f412bb4974..325270b520e1 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1090,6 +1090,8 @@ static struct scsi_cmnd *scsi_get_cmd_from_req(struct scsi_device *sdev,
 	cmd->tag = req->tag;
 	cmd->request = req;
 
+	cmd->cmnd = req->cmd;
+
 	return cmd;
 }
 
@@ -1127,8 +1129,6 @@ int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 		req->buffer = NULL;
 	}
 
-	BUILD_BUG_ON(sizeof(req->cmd) > sizeof(cmd->cmnd));
-	memcpy(cmd->cmnd, req->cmd, sizeof(cmd->cmnd));
 	cmd->cmd_len = req->cmd_len;
 	if (!req->data_len)
 		cmd->sc_data_direction = DMA_NONE;
@@ -1165,6 +1165,7 @@ int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
 	if (unlikely(!cmd))
 		return BLKPREP_DEFER;
 
+	memset(cmd->cmnd, 0, BLK_MAX_CDB);
 	return scsi_init_io(cmd, GFP_ATOMIC);
 }
 EXPORT_SYMBOL(scsi_setup_fs_cmnd);

commit 75ad23bc0fcb4f992a5d06982bf0857ab1738e9e
Author: Nick Piggin <npiggin@suse.de>
Date:   Tue Apr 29 14:48:33 2008 +0200

    block: make queue flags non-atomic
    
    We can save some atomic ops in the IO path, if we clearly define
    the rules of how to modify the queue flags.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 67f412bb4974..d545ad1cf47a 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -536,6 +536,9 @@ static void scsi_run_queue(struct request_queue *q)
 	       !shost->host_blocked && !shost->host_self_blocked &&
 		!((shost->can_queue > 0) &&
 		  (shost->host_busy >= shost->can_queue))) {
+
+		int flagset;
+
 		/*
 		 * As long as shost is accepting commands and we have
 		 * starved queues, call blk_run_queue. scsi_request_fn
@@ -549,19 +552,20 @@ static void scsi_run_queue(struct request_queue *q)
 		sdev = list_entry(shost->starved_list.next,
 					  struct scsi_device, starved_entry);
 		list_del_init(&sdev->starved_entry);
-		spin_unlock_irqrestore(shost->host_lock, flags);
-
+		spin_unlock(shost->host_lock);
+
+		spin_lock(sdev->request_queue->queue_lock);
+		flagset = test_bit(QUEUE_FLAG_REENTER, &q->queue_flags) &&
+				!test_bit(QUEUE_FLAG_REENTER,
+					&sdev->request_queue->queue_flags);
+		if (flagset)
+			queue_flag_set(QUEUE_FLAG_REENTER, sdev->request_queue);
+		__blk_run_queue(sdev->request_queue);
+		if (flagset)
+			queue_flag_clear(QUEUE_FLAG_REENTER, sdev->request_queue);
+		spin_unlock(sdev->request_queue->queue_lock);
 
-		if (test_bit(QUEUE_FLAG_REENTER, &q->queue_flags) &&
-		    !test_and_set_bit(QUEUE_FLAG_REENTER,
-				      &sdev->request_queue->queue_flags)) {
-			blk_run_queue(sdev->request_queue);
-			clear_bit(QUEUE_FLAG_REENTER,
-				  &sdev->request_queue->queue_flags);
-		} else
-			blk_run_queue(sdev->request_queue);
-
-		spin_lock_irqsave(shost->host_lock, flags);
+		spin_lock(shost->host_lock);
 		if (unlikely(!list_empty(&sdev->starved_entry)))
 			/*
 			 * sdev lost a race, and was put back on the
@@ -1585,8 +1589,9 @@ struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
 
 	blk_queue_max_segment_size(q, dma_get_max_seg_size(dev));
 
+	/* New queue, no concurrency on queue_flags */
 	if (!shost->use_clustering)
-		clear_bit(QUEUE_FLAG_CLUSTER, &q->queue_flags);
+		queue_flag_clear_unlocked(QUEUE_FLAG_CLUSTER, q);
 
 	/*
 	 * set a reasonable default alignment on word boundaries: the

commit fa8e36c39b00a219d2c37250e493c3421e0e67e9
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Wed Apr 2 18:11:52 2008 -0500

    [SCSI] fix barrier failure issue
    
    Currently, if the barrier command fails, the error return isn't seen
    by the block layer and it proceeds on regardless.  The problem is that
    SCSI always returns no error for REQ_TYPE_BLOCK_PC ... it expects the
    submitter to pick the errors out of req->errors, which the block
    barrier functions don't do.
    
    Since it appears that the way SG_IO and scsi_execute_request() work
    they discard the block error return and always use req->errors, the
    best fix for this is to have the SCSI layer return an error to block
    if one actually occurred (this also allows us to filter out spurious
    errors, like deferred sense).
    
    This patch is a bug fix that will need backporting to stable, but it's
    also quite a big change and in need of testing, so we'll incubate in
    the main kernel tree and backport at the -rc2 or so stage if no
    problems turn up.
    
    Acked-by: Jens Axboe <jens.axboe@oracle.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1b199e15ce9b..67f412bb4974 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -839,7 +839,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	int this_count = scsi_bufflen(cmd);
 	struct request_queue *q = cmd->device->request_queue;
 	struct request *req = cmd->request;
-	int clear_errors = 1;
+	int error = 0;
 	struct scsi_sense_hdr sshdr;
 	int sense_valid = 0;
 	int sense_deferred = 0;
@@ -853,7 +853,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	if (blk_pc_request(req)) { /* SG_IO ioctl from block level */
 		req->errors = result;
 		if (result) {
-			clear_errors = 0;
 			if (sense_valid && req->sense) {
 				/*
 				 * SG_IO wants current and deferred errors
@@ -865,6 +864,8 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				memcpy(req->sense, cmd->sense_buffer,  len);
 				req->sense_len = len;
 			}
+			if (!sense_deferred)
+				error = -EIO;
 		}
 		if (scsi_bidi_cmnd(cmd)) {
 			/* will also release_buffers */
@@ -885,14 +886,11 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				      "%d bytes done.\n",
 				      req->nr_sectors, good_bytes));
 
-	if (clear_errors)
-		req->errors = 0;
-
 	/* A number of bytes were successfully read.  If there
 	 * are leftovers and there is some kind of error
 	 * (result != 0), retry the rest.
 	 */
-	if (scsi_end_request(cmd, 0, good_bytes, result == 0) == NULL)
+	if (scsi_end_request(cmd, error, good_bytes, result == 0) == NULL)
 		return;
 
 	/* good_bytes = 0, or (inclusive) there were leftovers and

commit 8c5e03d3cf70161413aaf7152dafa96daca5bb2f
Author: Adrian Bunk <bunk@kernel.org>
Date:   Mon Mar 31 01:53:55 2008 +0300

    [SCSI] make scsi_end_bidi_request() static
    
    This patch makes the needlessly global scsi_end_bidi_request() static.
    
    Signed-off-by: Adrian Bunk <bunk@kernel.org>
    Acked-by: Boaz Harrosh <bharrosh@panasas.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f40898dc2d14..1b199e15ce9b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -784,7 +784,7 @@ EXPORT_SYMBOL(scsi_release_buffers);
  * in req->data_len and req->next_rq->data_len. The upper-layer driver can
  * decide what to do with this information.
  */
-void scsi_end_bidi_request(struct scsi_cmnd *cmd)
+static void scsi_end_bidi_request(struct scsi_cmnd *cmd)
 {
 	struct request *req = cmd->request;
 	unsigned int dlen = req->data_len;

commit 4d1566ed2100d074ccc654e5cf2e44cdea3a01d0
Author: Kay Sievers <kay.sievers@vrfy.org>
Date:   Wed Mar 19 13:04:47 2008 +0100

    [SCSI] fix media change events for polled devices
    
    Commit:
      a341cd0f (SCSI: add asynchronous event notification API)
    breaks:
      285e9670 (sr,sd: send media state change modification events)
    by introducing an event filter, which is removed here, to make
    events, we are depending on, happen again.
    
    Fix this by removing the event filter.  It's pretty much broken at the
    moment, since a user can't set it (the attribute being read only).  A
    proper fix will be to make the event discriminator distinguish between
    AN and Polled media change events.
    
    Cc: David Zeuthen <david@fubar.dk>
    Cc: kristen accardi <kaccardi@gmail.com>
    Cc: Jeff Garzik <jeff@garzik.org>
    Signed-off-by: Kay Sievers <kay.sievers@vrfy.org>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ba21d97d1855..f40898dc2d14 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2162,10 +2162,15 @@ void sdev_evt_send(struct scsi_device *sdev, struct scsi_event *evt)
 {
 	unsigned long flags;
 
+#if 0
+	/* FIXME: currently this check eliminates all media change events
+	 * for polled devices.  Need to update to discriminate between AN
+	 * and polled events */
 	if (!test_bit(evt->evt_type, sdev->supported_events)) {
 		kfree(evt);
 		return;
 	}
+#endif
 
 	spin_lock_irqsave(&sdev->list_lock, flags);
 	list_add_tail(&evt->node, &sdev->event_list);

commit 6b00769fe1502b4ad97bb327ef7ac971b208bfb5
Author: Tejun Heo <htejun@gmail.com>
Date:   Tue Feb 19 11:36:35 2008 +0100

    block: add request->raw_data_len
    
    With padding and draining moved into it, block layer now may extend
    requests as directed by queue parameters, so now a request has two
    sizes - the original request size and the extended size which matches
    the size of area pointed to by bios and later by sgs.  The latter size
    is what lower layers are primarily interested in when allocating,
    filling up DMA tables and setting up the controller.
    
    Both padding and draining extend the data area to accomodate
    controller characteristics.  As any controller which speaks SCSI can
    handle underflows, feeding larger data area is safe.
    
    So, this patch makes the primary data length field, request->data_len,
    indicate the size of full data area and add a separate length field,
    request->raw_data_len, for the unmodified request size.  The latter is
    used to report to higher layer (userland) and where the original
    request size should be fed to the controller or device.
    
    Signed-off-by: Tejun Heo <htejun@gmail.com>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 135c1d054701..ba21d97d1855 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1014,10 +1014,6 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb,
 	}
 
 	req->buffer = NULL;
-	if (blk_pc_request(req))
-		sdb->length = req->data_len;
-	else
-		sdb->length = req->nr_sectors << 9;
 
 	/* 
 	 * Next, walk the list, and fill in the addresses and sizes of
@@ -1026,6 +1022,10 @@ static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb,
 	count = blk_rq_map_sg(req->q, req, sdb->table.sgl);
 	BUG_ON(count > sdb->table.nents);
 	sdb->table.nents = count;
+	if (blk_pc_request(req))
+		sdb->length = req->data_len;
+	else
+		sdb->length = req->nr_sectors << 9;
 	return BLKPREP_OK;
 }
 

commit 4d2de3a50ce19af2008a90636436a1bf5b3b697b
Author: Tony Battersby <tonyb@cybernetics.com>
Date:   Tue Feb 5 10:36:10 2008 -0500

    [SCSI] fix BUG when sum(scatterlist) > bufflen
    
    When sending a SCSI command to a tape drive via the SCSI Generic (sg)
    driver, if the command has a data transfer length more than
    scatter_elem_sz (32 KB default) and not a multiple of 512, then I either
    hit BUG_ON(!valid_dma_direction(direction)) in dma_unmap_sg() or else
    the command never completes (depending on the LLDD).
    
    When constructing scatterlists, the sg driver rounds up the scatterlist
    element sizes to be a multiple of 512.  This can result in
    sum(scatterlist lengths) > bufflen.  In this case, scsi_req_map_sg()
    incorrectly sets bio->bi_size to sum(scatterlist lengths) rather than to
    bufflen.  When the command completes, req_bio_endio() detects that
    bio->bi_size != 0, and so it doesn't call bio_endio().  This causes the
    command to be resubmitted, resulting in BUG_ON or the command never
    completing.
    
    This patch makes scsi_req_map_sg() set bio->bi_size to bufflen rather
    than to sum(scatterlist lengths), which fixes the problem.
    
    Signed-off-by: Tony Battersby <tonyb@cybernetics.com>
    Acked-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f243fc30c908..135c1d054701 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -301,7 +301,6 @@ static int scsi_req_map_sg(struct request *rq, struct scatterlist *sgl,
 		page = sg_page(sg);
 		off = sg->offset;
 		len = sg->length;
- 		data_len += len;
 
 		while (len > 0 && data_len > 0) {
 			/*

commit 99c84dbdc73d158a1ab955a4a5f74c18074796a3
Author: FUJITA Tomonori <tomof@acm.org>
Date:   Mon Feb 4 22:28:17 2008 -0800

    iommu sg merging: call dma_set_seg_boundary in __scsi_alloc_queue()
    
    This is a one-line patch to add the following to __scsi_alloc_queue():
    
    dma_set_seg_boundary(dev, shost->dma_boundary);
    
    This is the simplest approach but the result looks odd,
    __scsi_alloc_queue() does:
    
    blk_queue_segment_boundary(q, shost->dma_boundary);
    dma_set_seg_boundary(dev, shost->dma_boundary);
    blk_queue_max_segment_size(q, dma_get_max_seg_size(dev));
    
    I think that it would be better to set up segment boundary in the same
    way as we did for the maximum segment size. That is, removing
    shost->dma_boundary and LLDs call pci_set_dma_seg_boundary (or its
    friends).
    
    Then __scsi_alloc_queue() can set up both limits in the same way:
    
    blk_queue_segment_boundary(q, dma_get_seg_boundary(dev));
    blk_queue_max_segment_size(q, dma_get_max_seg_size(dev));
    
    killing dma_boundary in scsi_host_template needs a large patch for
    libata (dma_boundary is used by only libata and sym53c8xx). I'll send
    a patch to do that if it is acceptable. James and Jeff?
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Cc: James Bottomley <James.Bottomley@steeleye.com>
    Cc: Jens Axboe <jens.axboe@oracle.com>
    Cc: Greg KH <greg@kroah.com>
    Cc: Jeff Garzik <jeff@garzik.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 68e424f09acb..f243fc30c908 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1584,6 +1584,7 @@ struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
 	blk_queue_max_sectors(q, shost->max_sectors);
 	blk_queue_bounce_limit(q, scsi_calculate_bounce_limit(shost));
 	blk_queue_segment_boundary(q, shost->dma_boundary);
+	dma_set_seg_boundary(dev, shost->dma_boundary);
 
 	blk_queue_max_segment_size(q, dma_get_max_seg_size(dev));
 

commit 860ac568e825b623b0b335ca277dd47d1d7fd5d0
Author: FUJITA Tomonori <tomof@acm.org>
Date:   Mon Feb 4 22:28:05 2008 -0800

    iommu sg merging: call blk_queue_segment_boundary in __scsi_alloc_queue
    
    request_queue and device struct must have the same value of a segment
    size limit. This patch adds blk_queue_segment_boundary in
    __scsi_alloc_queue so LLDs don't need to call both
    blk_queue_segment_boundary and set_dma_max_seg_size. A LLD can change
    the default value (64KB) can call device_dma_parameters accessors like
    pci_set_dma_max_seg_size when allocating scsi_host.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Acked-by: Jeff Garzik <jeff@garzik.org>
    Cc: James Bottomley <James.Bottomley@steeleye.com>
    Acked-by: Jens Axboe <jens.axboe@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b12fb310e399..68e424f09acb 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1569,6 +1569,7 @@ struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
 					 request_fn_proc *request_fn)
 {
 	struct request_queue *q;
+	struct device *dev = shost->shost_gendev.parent;
 
 	q = blk_init_queue(request_fn, NULL);
 	if (!q)
@@ -1584,6 +1585,8 @@ struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
 	blk_queue_bounce_limit(q, scsi_calculate_bounce_limit(shost));
 	blk_queue_segment_boundary(q, shost->dma_boundary);
 
+	blk_queue_max_segment_size(q, dma_get_max_seg_size(dev));
+
 	if (!shost->use_clustering)
 		clear_bit(QUEUE_FLAG_CLUSTER, &q->queue_flags);
 

commit 3d9dd6eef888658d26ebea0cc24d15d2a93ab015
Author: FUJITA Tomonori <tomof@acm.org>
Date:   Fri Jan 25 23:25:14 2008 +0900

    [SCSI] handle scsi_init_queue failure properly
    
    scsi_init_queue is expected to clean up allocated things when it
    fails.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 7bfec7e7a8a0..b12fb310e399 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1682,7 +1682,7 @@ int __init scsi_init_queue(void)
 					0, 0, NULL);
 	if (!scsi_bidi_sdb_cache) {
 		printk(KERN_ERR "SCSI: can't init scsi bidi sdb cache\n");
-		return -ENOMEM;
+		goto cleanup_io_context;
 	}
 
 	for (i = 0; i < SG_MEMPOOL_NR; i++) {
@@ -1694,6 +1694,7 @@ int __init scsi_init_queue(void)
 		if (!sgp->slab) {
 			printk(KERN_ERR "SCSI: can't init sg slab %s\n",
 					sgp->name);
+			goto cleanup_bidi_sdb;
 		}
 
 		sgp->pool = mempool_create_slab_pool(SG_MEMPOOL_SIZE,
@@ -1701,10 +1702,25 @@ int __init scsi_init_queue(void)
 		if (!sgp->pool) {
 			printk(KERN_ERR "SCSI: can't init sg mempool %s\n",
 					sgp->name);
+			goto cleanup_bidi_sdb;
 		}
 	}
 
 	return 0;
+
+cleanup_bidi_sdb:
+	for (i = 0; i < SG_MEMPOOL_NR; i++) {
+		struct scsi_host_sg_pool *sgp = scsi_sg_pools + i;
+		if (sgp->pool)
+			mempool_destroy(sgp->pool);
+		if (sgp->slab)
+			kmem_cache_destroy(sgp->slab);
+	}
+	kmem_cache_destroy(scsi_bidi_sdb_cache);
+cleanup_io_context:
+	kmem_cache_destroy(scsi_io_context_cache);
+
+	return -ENOMEM;
 }
 
 void scsi_exit_queue(void)

commit b172b6e99e948b6abb180082cfeb8f9b1450ebff
Author: FUJITA Tomonori <tomof@acm.org>
Date:   Fri Jan 25 23:25:13 2008 +0900

    [SCSI] destroy scsi_bidi_sdb_cache in scsi_exit_queue
    
    Needs to call kmem_cache_destroy for scsi_bidi_sdb_cache in
    scsi_exit_queue.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e1c7eebfe907..7bfec7e7a8a0 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1712,6 +1712,7 @@ void scsi_exit_queue(void)
 	int i;
 
 	kmem_cache_destroy(scsi_io_context_cache);
+	kmem_cache_destroy(scsi_bidi_sdb_cache);
 
 	for (i = 0; i < SG_MEMPOOL_NR; i++) {
 		struct scsi_host_sg_pool *sgp = scsi_sg_pools + i;

commit d3f46f39b7092594b498abc12f0c73b0b9913bde
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Tue Jan 15 11:11:46 2008 -0600

    [SCSI] remove use_sg_chaining
    
    With the sg table code, every SCSI driver is now either chain capable
    or broken (or has sg_tablesize set so chaining is never activated), so
    there's no need to have a check in the host template.
    
    Also tidy up the code by moving the scatterlist size defines into the
    SCSI includes and permit the last entry of the scatterlist pools not
    to be a power of two.
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4560713ecb14..e1c7eebfe907 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -8,6 +8,7 @@
  */
 
 #include <linux/bio.h>
+#include <linux/bitops.h>
 #include <linux/blkdev.h>
 #include <linux/completion.h>
 #include <linux/kernel.h>
@@ -34,13 +35,6 @@
 #define SG_MEMPOOL_NR		ARRAY_SIZE(scsi_sg_pools)
 #define SG_MEMPOOL_SIZE		2
 
-/*
- * The maximum number of SG segments that we will put inside a scatterlist
- * (unless chaining is used). Should ideally fit inside a single page, to
- * avoid a higher order allocation.
- */
-#define SCSI_MAX_SG_SEGMENTS	128
-
 struct scsi_host_sg_pool {
 	size_t		size;
 	char		*name;
@@ -48,19 +42,26 @@ struct scsi_host_sg_pool {
 	mempool_t	*pool;
 };
 
-#define SP(x) { x, "sgpool-" #x }
+#define SP(x) { x, "sgpool-" __stringify(x) }
+#if (SCSI_MAX_SG_SEGMENTS < 32)
+#error SCSI_MAX_SG_SEGMENTS is too small (must be 32 or greater)
+#endif
 static struct scsi_host_sg_pool scsi_sg_pools[] = {
 	SP(8),
 	SP(16),
-#if (SCSI_MAX_SG_SEGMENTS > 16)
-	SP(32),
 #if (SCSI_MAX_SG_SEGMENTS > 32)
-	SP(64),
+	SP(32),
 #if (SCSI_MAX_SG_SEGMENTS > 64)
+	SP(64),
+#if (SCSI_MAX_SG_SEGMENTS > 128)
 	SP(128),
+#if (SCSI_MAX_SG_SEGMENTS > 256)
+#error SCSI_MAX_SG_SEGMENTS is too large (256 MAX)
 #endif
 #endif
 #endif
+#endif
+	SP(SCSI_MAX_SG_SEGMENTS)
 };
 #undef SP
 
@@ -692,42 +693,16 @@ static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int error,
 	return NULL;
 }
 
-/*
- * Like SCSI_MAX_SG_SEGMENTS, but for archs that have sg chaining. This limit
- * is totally arbitrary, a setting of 2048 will get you at least 8mb ios.
- */
-#define SCSI_MAX_SG_CHAIN_SEGMENTS	2048
-
 static inline unsigned int scsi_sgtable_index(unsigned short nents)
 {
 	unsigned int index;
 
-	switch (nents) {
-	case 1 ... 8:
+	BUG_ON(nents > SCSI_MAX_SG_SEGMENTS);
+
+	if (nents <= 8)
 		index = 0;
-		break;
-	case 9 ... 16:
-		index = 1;
-		break;
-#if (SCSI_MAX_SG_SEGMENTS > 16)
-	case 17 ... 32:
-		index = 2;
-		break;
-#if (SCSI_MAX_SG_SEGMENTS > 32)
-	case 33 ... 64:
-		index = 3;
-		break;
-#if (SCSI_MAX_SG_SEGMENTS > 64)
-	case 65 ... 128:
-		index = 4;
-		break;
-#endif
-#endif
-#endif
-	default:
-		printk(KERN_ERR "scsi: bad segment count=%d\n", nents);
-		BUG();
-	}
+	else
+		index = get_count_order(nents) - 3;
 
 	return index;
 }
@@ -1603,20 +1578,7 @@ struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
 	 * this limit is imposed by hardware restrictions
 	 */
 	blk_queue_max_hw_segments(q, shost->sg_tablesize);
-
-	/*
-	 * In the future, sg chaining support will be mandatory and this
-	 * ifdef can then go away. Right now we don't have all archs
-	 * converted, so better keep it safe.
-	 */
-#ifdef ARCH_HAS_SG_CHAIN
-	if (shost->use_sg_chaining)
-		blk_queue_max_phys_segments(q, SCSI_MAX_SG_CHAIN_SEGMENTS);
-	else
-		blk_queue_max_phys_segments(q, SCSI_MAX_SG_SEGMENTS);
-#else
-	blk_queue_max_phys_segments(q, SCSI_MAX_SG_SEGMENTS);
-#endif
+	blk_queue_max_phys_segments(q, SCSI_MAX_SG_CHAIN_SEGMENTS);
 
 	blk_queue_max_sectors(q, shost->max_sectors);
 	blk_queue_bounce_limit(q, scsi_calculate_bounce_limit(shost));

commit b8de16318410f6f8611a879678a531237e4aadc9
Author: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
Date:   Fri Jan 18 12:02:15 2008 -0500

    [SCSI] bidirectional: fix up for the new blk_end_request code
    
    Signed-off-by: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 681ed1b830f5..4560713ecb14 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -812,8 +812,16 @@ EXPORT_SYMBOL(scsi_release_buffers);
  */
 void scsi_end_bidi_request(struct scsi_cmnd *cmd)
 {
-	blk_end_bidi_request(cmd->request, 0, scsi_out(cmd)->resid,
-							scsi_in(cmd)->resid);
+	struct request *req = cmd->request;
+	unsigned int dlen = req->data_len;
+	unsigned int next_dlen = req->next_rq->data_len;
+
+	req->data_len = scsi_out(cmd)->resid;
+	req->next_rq->data_len = scsi_in(cmd)->resid;
+
+	/* The req and req->next_rq have not been completed */
+	BUG_ON(blk_end_bidi_request(req, 0, dlen, next_dlen));
+
 	scsi_release_buffers(cmd);
 
 	/*

commit 6f9a35e2dafa0f855ab051c11bdbf739745ff6f5
Author: Boaz Harrosh <bharrosh@panasas.com>
Date:   Thu Dec 13 13:50:53 2007 +0200

    [SCSI] bidirectional command support
    
    At the block level bidi request uses req->next_rq pointer for a second
    bidi_read request.
    At Scsi-midlayer a second scsi_data_buffer structure is used for the
    bidi_read part. This bidi scsi_data_buffer is put on
    request->next_rq->special. Struct scsi_cmnd is not changed.
    
    - Define scsi_bidi_cmnd() to return true if it is a bidi request and a
      second sgtable was allocated.
    
    - Define scsi_in()/scsi_out() to return the in or out scsi_data_buffer
      from this command This API is to isolate users from the mechanics of
      bidi.
    
    - Define scsi_end_bidi_request() to do what scsi_end_request() does but
      for a bidi request. This is necessary because bidi commands are a bit
      tricky here. (See comments in body)
    
    - scsi_release_buffers() will also release the bidi_read scsi_data_buffer
    
    - scsi_io_completion() on bidi commands will now call
      scsi_end_bidi_request() and return.
    
    - The previous work done in scsi_init_io() is now done in a new
      scsi_init_sgtable() (which is 99% identical to old scsi_init_io())
      The new scsi_init_io() will call the above twice if needed also for
      the bidi_read command. Only at this point is a command bidi.
    
    - In scsi_error.c at scsi_eh_prep/restore_cmnd() make sure bidi-lld is not
      confused by a get-sense command that looks like bidi. This is done
      by puting NULL at request->next_rq, and restoring.
    
    [jejb: update to sg_table and resolve conflicts
    also update to blk-end-request and resolve conflicts]
    
    Signed-off-by: Boaz Harrosh <bharrosh@panasas.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d5e77e9b3a9c..681ed1b830f5 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -64,6 +64,8 @@ static struct scsi_host_sg_pool scsi_sg_pools[] = {
 };
 #undef SP
 
+static struct kmem_cache *scsi_bidi_sdb_cache;
+
 static void scsi_run_queue(struct request_queue *q);
 
 /*
@@ -790,9 +792,37 @@ void scsi_release_buffers(struct scsi_cmnd *cmd)
 		scsi_free_sgtable(&cmd->sdb);
 
 	memset(&cmd->sdb, 0, sizeof(cmd->sdb));
+
+	if (scsi_bidi_cmnd(cmd)) {
+		struct scsi_data_buffer *bidi_sdb =
+			cmd->request->next_rq->special;
+		scsi_free_sgtable(bidi_sdb);
+		kmem_cache_free(scsi_bidi_sdb_cache, bidi_sdb);
+		cmd->request->next_rq->special = NULL;
+	}
 }
 EXPORT_SYMBOL(scsi_release_buffers);
 
+/*
+ * Bidi commands Must be complete as a whole, both sides at once.
+ * If part of the bytes were written and lld returned
+ * scsi_in()->resid and/or scsi_out()->resid this information will be left
+ * in req->data_len and req->next_rq->data_len. The upper-layer driver can
+ * decide what to do with this information.
+ */
+void scsi_end_bidi_request(struct scsi_cmnd *cmd)
+{
+	blk_end_bidi_request(cmd->request, 0, scsi_out(cmd)->resid,
+							scsi_in(cmd)->resid);
+	scsi_release_buffers(cmd);
+
+	/*
+	 * This will goose the queue request function at the end, so we don't
+	 * need to worry about launching another command.
+	 */
+	scsi_next_command(cmd);
+}
+
 /*
  * Function:    scsi_io_completion()
  *
@@ -854,9 +884,15 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				req->sense_len = len;
 			}
 		}
+		if (scsi_bidi_cmnd(cmd)) {
+			/* will also release_buffers */
+			scsi_end_bidi_request(cmd);
+			return;
+		}
 		req->data_len = scsi_get_resid(cmd);
 	}
 
+	BUG_ON(blk_bidi_rq(req)); /* bidi not support for !blk_pc_request yet */
 	scsi_release_buffers(cmd);
 
 	/*
@@ -982,28 +1018,16 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	scsi_end_request(cmd, -EIO, this_count, !result);
 }
 
-/*
- * Function:    scsi_init_io()
- *
- * Purpose:     SCSI I/O initialize function.
- *
- * Arguments:   cmd   - Command descriptor we wish to initialize
- *
- * Returns:     0 on success
- *		BLKPREP_DEFER if the failure is retryable
- */
-int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
+static int scsi_init_sgtable(struct request *req, struct scsi_data_buffer *sdb,
+			     gfp_t gfp_mask)
 {
-	struct request     *req = cmd->request;
-	int		   count;
-	struct scsi_data_buffer *sdb = &cmd->sdb;
+	int count;
 
 	/*
 	 * If sg table allocation fails, requeue request later.
 	 */
 	if (unlikely(scsi_alloc_sgtable(sdb, req->nr_phys_segments,
 					gfp_mask))) {
-		scsi_unprep_request(req);
 		return BLKPREP_DEFER;
 	}
 
@@ -1022,6 +1046,50 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 	sdb->table.nents = count;
 	return BLKPREP_OK;
 }
+
+/*
+ * Function:    scsi_init_io()
+ *
+ * Purpose:     SCSI I/O initialize function.
+ *
+ * Arguments:   cmd   - Command descriptor we wish to initialize
+ *
+ * Returns:     0 on success
+ *		BLKPREP_DEFER if the failure is retryable
+ *		BLKPREP_KILL if the failure is fatal
+ */
+int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
+{
+	int error = scsi_init_sgtable(cmd->request, &cmd->sdb, gfp_mask);
+	if (error)
+		goto err_exit;
+
+	if (blk_bidi_rq(cmd->request)) {
+		struct scsi_data_buffer *bidi_sdb = kmem_cache_zalloc(
+			scsi_bidi_sdb_cache, GFP_ATOMIC);
+		if (!bidi_sdb) {
+			error = BLKPREP_DEFER;
+			goto err_exit;
+		}
+
+		cmd->request->next_rq->special = bidi_sdb;
+		error = scsi_init_sgtable(cmd->request->next_rq, bidi_sdb,
+								    GFP_ATOMIC);
+		if (error)
+			goto err_exit;
+	}
+
+	return BLKPREP_OK ;
+
+err_exit:
+	scsi_release_buffers(cmd);
+	if (error == BLKPREP_KILL)
+		scsi_put_command(cmd);
+	else /* BLKPREP_DEFER */
+		scsi_unprep_request(cmd->request);
+
+	return error;
+}
 EXPORT_SYMBOL(scsi_init_io);
 
 static struct scsi_cmnd *scsi_get_cmd_from_req(struct scsi_device *sdev,
@@ -1639,6 +1707,14 @@ int __init scsi_init_queue(void)
 		return -ENOMEM;
 	}
 
+	scsi_bidi_sdb_cache = kmem_cache_create("scsi_bidi_sdb",
+					sizeof(struct scsi_data_buffer),
+					0, 0, NULL);
+	if (!scsi_bidi_sdb_cache) {
+		printk(KERN_ERR "SCSI: can't init scsi bidi sdb cache\n");
+		return -ENOMEM;
+	}
+
 	for (i = 0; i < SG_MEMPOOL_NR; i++) {
 		struct scsi_host_sg_pool *sgp = scsi_sg_pools + i;
 		int size = sgp->size * sizeof(struct scatterlist);

commit 30b0c37b27485a9cb897bfe3824f6f517b8c80d6
Author: Boaz Harrosh <bharrosh@panasas.com>
Date:   Thu Dec 13 13:47:40 2007 +0200

    [SCSI] implement scsi_data_buffer
    
    In preparation for bidi we abstract all IO members of scsi_cmnd,
    that will need to duplicate, into a substructure.
    
    - Group all IO members of scsi_cmnd into a scsi_data_buffer
      structure.
    - Adjust accessors to new members.
    - scsi_{alloc,free}_sgtable receive a scsi_data_buffer instead of
      scsi_cmnd. And work on it.
    - Adjust scsi_init_io() and  scsi_release_buffers() for above
      change.
    - Fix other parts of scsi_lib/scsi.c to members migration. Use
      accessors where appropriate.
    
    - fix Documentation about scsi_cmnd in scsi_host.h
    
    - scsi_error.c
      * Changed needed members of struct scsi_eh_save.
      * Careful considerations in scsi_eh_prep/restore_cmnd.
    
    - sd.c and sr.c
      * sd and sr would adjust IO size to align on device's block
        size so code needs to change once we move to scsi_data_buff
        implementation.
      * Convert code to use scsi_for_each_sg
      * Use data accessors where appropriate.
    
    - tgt: convert libsrp to use scsi_data_buffer
    
    - isd200: This driver still bangs on scsi_cmnd IO members,
      so need changing
    
    [jejb: rebased on top of sg_table patches fixed up conflicts
    and used the synergy to eliminate use_sg and sg_count]
    
    Signed-off-by: Boaz Harrosh <bharrosh@panasas.com>
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 69fd62183bab..d5e77e9b3a9c 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -440,7 +440,7 @@ EXPORT_SYMBOL_GPL(scsi_execute_async);
 static void scsi_init_cmd_errh(struct scsi_cmnd *cmd)
 {
 	cmd->serial_number = 0;
-	cmd->resid = 0;
+	scsi_set_resid(cmd, 0);
 	memset(cmd->sense_buffer, 0, SCSI_SENSE_BUFFERSIZE);
 	if (cmd->cmd_len == 0)
 		cmd->cmd_len = COMMAND_SIZE(cmd->cmnd[0]);
@@ -746,25 +746,25 @@ static struct scatterlist *scsi_sg_alloc(unsigned int nents, gfp_t gfp_mask)
 	return mempool_alloc(sgp->pool, gfp_mask);
 }
 
-static int scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
+static int scsi_alloc_sgtable(struct scsi_data_buffer *sdb, int nents,
+			      gfp_t gfp_mask)
 {
 	int ret;
 
-	BUG_ON(!cmd->use_sg);
+	BUG_ON(!nents);
 
-	ret = __sg_alloc_table(&cmd->sg_table, cmd->use_sg,
-			       SCSI_MAX_SG_SEGMENTS, gfp_mask, scsi_sg_alloc);
+	ret = __sg_alloc_table(&sdb->table, nents, SCSI_MAX_SG_SEGMENTS,
+			       gfp_mask, scsi_sg_alloc);
 	if (unlikely(ret))
-		__sg_free_table(&cmd->sg_table, SCSI_MAX_SG_SEGMENTS,
+		__sg_free_table(&sdb->table, SCSI_MAX_SG_SEGMENTS,
 				scsi_sg_free);
 
-	cmd->request_buffer = cmd->sg_table.sgl;
 	return ret;
 }
 
-static void scsi_free_sgtable(struct scsi_cmnd *cmd)
+static void scsi_free_sgtable(struct scsi_data_buffer *sdb)
 {
-	__sg_free_table(&cmd->sg_table, SCSI_MAX_SG_SEGMENTS, scsi_sg_free);
+	__sg_free_table(&sdb->table, SCSI_MAX_SG_SEGMENTS, scsi_sg_free);
 }
 
 /*
@@ -786,15 +786,10 @@ static void scsi_free_sgtable(struct scsi_cmnd *cmd)
  */
 void scsi_release_buffers(struct scsi_cmnd *cmd)
 {
-	if (cmd->use_sg)
-		scsi_free_sgtable(cmd);
+	if (cmd->sdb.table.nents)
+		scsi_free_sgtable(&cmd->sdb);
 
-	/*
-	 * Zero these out.  They now point to freed memory, and it is
-	 * dangerous to hang onto the pointers.
-	 */
-	cmd->request_buffer = NULL;
-	cmd->request_bufflen = 0;
+	memset(&cmd->sdb, 0, sizeof(cmd->sdb));
 }
 EXPORT_SYMBOL(scsi_release_buffers);
 
@@ -829,7 +824,7 @@ EXPORT_SYMBOL(scsi_release_buffers);
 void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 {
 	int result = cmd->result;
-	int this_count = cmd->request_bufflen;
+	int this_count = scsi_bufflen(cmd);
 	struct request_queue *q = cmd->device->request_queue;
 	struct request *req = cmd->request;
 	int clear_errors = 1;
@@ -837,8 +832,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	int sense_valid = 0;
 	int sense_deferred = 0;
 
-	scsi_release_buffers(cmd);
-
 	if (result) {
 		sense_valid = scsi_command_normalize_sense(cmd, &sshdr);
 		if (sense_valid)
@@ -861,9 +854,11 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				req->sense_len = len;
 			}
 		}
-		req->data_len = cmd->resid;
+		req->data_len = scsi_get_resid(cmd);
 	}
 
+	scsi_release_buffers(cmd);
+
 	/*
 	 * Next deal with any sectors which we were able to correctly
 	 * handle.
@@ -871,7 +866,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	SCSI_LOG_HLCOMPLETE(1, printk("%ld sectors total, "
 				      "%d bytes done.\n",
 				      req->nr_sectors, good_bytes));
-	SCSI_LOG_HLCOMPLETE(1, printk("use_sg is %d\n", cmd->use_sg));
 
 	if (clear_errors)
 		req->errors = 0;
@@ -1002,35 +996,30 @@ int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 {
 	struct request     *req = cmd->request;
 	int		   count;
-
-	/*
-	 * We used to not use scatter-gather for single segment request,
-	 * but now we do (it makes highmem I/O easier to support without
-	 * kmapping pages)
-	 */
-	cmd->use_sg = req->nr_phys_segments;
+	struct scsi_data_buffer *sdb = &cmd->sdb;
 
 	/*
 	 * If sg table allocation fails, requeue request later.
 	 */
-	if (unlikely(scsi_alloc_sgtable(cmd, gfp_mask))) {
+	if (unlikely(scsi_alloc_sgtable(sdb, req->nr_phys_segments,
+					gfp_mask))) {
 		scsi_unprep_request(req);
 		return BLKPREP_DEFER;
 	}
 
 	req->buffer = NULL;
 	if (blk_pc_request(req))
-		cmd->request_bufflen = req->data_len;
+		sdb->length = req->data_len;
 	else
-		cmd->request_bufflen = req->nr_sectors << 9;
+		sdb->length = req->nr_sectors << 9;
 
 	/* 
 	 * Next, walk the list, and fill in the addresses and sizes of
 	 * each segment.
 	 */
-	count = blk_rq_map_sg(req->q, req, cmd->request_buffer);
-	BUG_ON(count > cmd->use_sg);
-	cmd->use_sg = count;
+	count = blk_rq_map_sg(req->q, req, sdb->table.sgl);
+	BUG_ON(count > sdb->table.nents);
+	sdb->table.nents = count;
 	return BLKPREP_OK;
 }
 EXPORT_SYMBOL(scsi_init_io);
@@ -1086,9 +1075,7 @@ int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 		BUG_ON(req->data_len);
 		BUG_ON(req->data);
 
-		cmd->request_bufflen = 0;
-		cmd->request_buffer = NULL;
-		cmd->use_sg = 0;
+		memset(&cmd->sdb, 0, sizeof(cmd->sdb));
 		req->buffer = NULL;
 	}
 

commit bb52d82f45df3a2661d88befba7c79a7db8be496
Author: Boaz Harrosh <bharrosh@panasas.com>
Date:   Thu Dec 13 16:14:27 2007 -0800

    [SCSI] tgt: use scsi_init_io instead of scsi_alloc_sgtable
    
    If we export scsi_init_io()/scsi_release_buffers() instead of
    scsi_{alloc,free}_sgtable() from scsi_lib than tgt code is much more
    insulated from scsi_lib changes. As a bonus it will also gain bidi
    capability when it comes.
    
    [jejb: rebase on to sg_table and fix up rejections]
    
    Signed-off-by: Boaz Harrosh <bharrosh@panasas.com>
    Acked-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 7c4c889c5221..69fd62183bab 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -746,7 +746,7 @@ static struct scatterlist *scsi_sg_alloc(unsigned int nents, gfp_t gfp_mask)
 	return mempool_alloc(sgp->pool, gfp_mask);
 }
 
-int scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
+static int scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 {
 	int ret;
 
@@ -762,15 +762,11 @@ int scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 	return ret;
 }
 
-EXPORT_SYMBOL(scsi_alloc_sgtable);
-
-void scsi_free_sgtable(struct scsi_cmnd *cmd)
+static void scsi_free_sgtable(struct scsi_cmnd *cmd)
 {
 	__sg_free_table(&cmd->sg_table, SCSI_MAX_SG_SEGMENTS, scsi_sg_free);
 }
 
-EXPORT_SYMBOL(scsi_free_sgtable);
-
 /*
  * Function:    scsi_release_buffers()
  *
@@ -788,7 +784,7 @@ EXPORT_SYMBOL(scsi_free_sgtable);
  *		the scatter-gather table, and potentially any bounce
  *		buffers.
  */
-static void scsi_release_buffers(struct scsi_cmnd *cmd)
+void scsi_release_buffers(struct scsi_cmnd *cmd)
 {
 	if (cmd->use_sg)
 		scsi_free_sgtable(cmd);
@@ -800,6 +796,7 @@ static void scsi_release_buffers(struct scsi_cmnd *cmd)
 	cmd->request_buffer = NULL;
 	cmd->request_bufflen = 0;
 }
+EXPORT_SYMBOL(scsi_release_buffers);
 
 /*
  * Function:    scsi_io_completion()
@@ -1001,7 +998,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
  * Returns:     0 on success
  *		BLKPREP_DEFER if the failure is retryable
  */
-static int scsi_init_io(struct scsi_cmnd *cmd)
+int scsi_init_io(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 {
 	struct request     *req = cmd->request;
 	int		   count;
@@ -1016,7 +1013,7 @@ static int scsi_init_io(struct scsi_cmnd *cmd)
 	/*
 	 * If sg table allocation fails, requeue request later.
 	 */
-	if (unlikely(scsi_alloc_sgtable(cmd, GFP_ATOMIC))) {
+	if (unlikely(scsi_alloc_sgtable(cmd, gfp_mask))) {
 		scsi_unprep_request(req);
 		return BLKPREP_DEFER;
 	}
@@ -1036,6 +1033,7 @@ static int scsi_init_io(struct scsi_cmnd *cmd)
 	cmd->use_sg = count;
 	return BLKPREP_OK;
 }
+EXPORT_SYMBOL(scsi_init_io);
 
 static struct scsi_cmnd *scsi_get_cmd_from_req(struct scsi_device *sdev,
 		struct request *req)
@@ -1081,7 +1079,7 @@ int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 
 		BUG_ON(!req->nr_phys_segments);
 
-		ret = scsi_init_io(cmd);
+		ret = scsi_init_io(cmd, GFP_ATOMIC);
 		if (unlikely(ret))
 			return ret;
 	} else {
@@ -1132,7 +1130,7 @@ int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
 	if (unlikely(!cmd))
 		return BLKPREP_DEFER;
 
-	return scsi_init_io(cmd);
+	return scsi_init_io(cmd, GFP_ATOMIC);
 }
 EXPORT_SYMBOL(scsi_setup_fs_cmnd);
 

commit f0f0052069989b80d2a3e50c9cd2f2a650bc1aea
Merge: 68fbda7de07e a65b58663d98
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jan 29 08:51:32 2008 +1100

    Merge branch 'blk-end-request' of git://git.kernel.dk/linux-2.6-block
    
    * 'blk-end-request' of git://git.kernel.dk/linux-2.6-block: (30 commits)
      blk_end_request: changing xsysace (take 4)
      blk_end_request: changing ub (take 4)
      blk_end_request: cleanup of request completion (take 4)
      blk_end_request: cleanup 'uptodate' related code (take 4)
      blk_end_request: remove/unexport end_that_request_* (take 4)
      blk_end_request: changing scsi (take 4)
      blk_end_request: add bidi completion interface (take 4)
      blk_end_request: changing ide-cd (take 4)
      blk_end_request: add callback feature (take 4)
      blk_end_request: changing ide normal caller (take 4)
      blk_end_request: changing cpqarray (take 4)
      blk_end_request: changing cciss (take 4)
      blk_end_request: changing ide-scsi (take 4)
      blk_end_request: changing s390 (take 4)
      blk_end_request: changing mmc (take 4)
      blk_end_request: changing i2o_block (take 4)
      blk_end_request: changing viocd (take 4)
      blk_end_request: changing xen-blkfront (take 4)
      blk_end_request: changing viodasd (take 4)
      blk_end_request: changing sx8 (take 4)
      ...

commit 7cedb1f17fb7f4374d11501f61656ae9d3ba47e9
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Sun Jan 13 14:15:28 2008 -0600

    SG: work with the SCSI fixed maximum allocations.
    
    SCSI sg table allocation has a maximum size (of SCSI_MAX_SG_SEGMENTS,
    currently 128) and this will cause a BUG_ON() in SCSI if something
    tries an allocation over it.  This patch adds a size limit to the
    chaining allocator to allow the specification of the maximum
    allocation size for chaining, so we always chain in units of the
    maximum SCSI allocation size.
    
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 3b5121c4c081..eb4911a61641 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -761,9 +761,11 @@ int scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 
 	BUG_ON(!cmd->use_sg);
 
-	ret = __sg_alloc_table(&cmd->sg_table, cmd->use_sg, gfp_mask, scsi_sg_alloc);
+	ret = __sg_alloc_table(&cmd->sg_table, cmd->use_sg,
+			       SCSI_MAX_SG_SEGMENTS, gfp_mask, scsi_sg_alloc);
 	if (unlikely(ret))
-		__sg_free_table(&cmd->sg_table, scsi_sg_free);
+		__sg_free_table(&cmd->sg_table, SCSI_MAX_SG_SEGMENTS,
+				scsi_sg_free);
 
 	cmd->request_buffer = cmd->sg_table.sgl;
 	return ret;
@@ -773,7 +775,7 @@ EXPORT_SYMBOL(scsi_alloc_sgtable);
 
 void scsi_free_sgtable(struct scsi_cmnd *cmd)
 {
-	__sg_free_table(&cmd->sg_table, scsi_sg_free);
+	__sg_free_table(&cmd->sg_table, SCSI_MAX_SG_SEGMENTS, scsi_sg_free);
 }
 
 EXPORT_SYMBOL(scsi_free_sgtable);

commit 610d8b0c972e3b75493efef8e96175518fd736d3
Author: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
Date:   Tue Dec 11 17:52:09 2007 -0500

    blk_end_request: changing scsi (take 4)
    
    This patch converts scsi mid-layer to use blk_end_request interfaces.
    Related 'uptodate' arguments are converted to 'error'.
    
    As a result, the interface of internal function, scsi_end_request(),
    is changed.
    
    Cc: James Bottomley <James.Bottomley@SteelEye.com>
    Cc: Boaz Harrosh <bharrosh@panasas.com>
    Signed-off-by: Kiyoshi Ueda <k-ueda@ct.jp.nec.com>
    Signed-off-by: Jun'ichi Nomura <j-nomura@ce.jp.nec.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4cf902efbdbf..f44ab801119b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -634,7 +634,7 @@ void scsi_run_host_queues(struct Scsi_Host *shost)
  *		of upper level post-processing and scsi_io_completion).
  *
  * Arguments:   cmd	 - command that is complete.
- *              uptodate - 1 if I/O indicates success, <= 0 for I/O error.
+ *              error    - 0 if I/O indicates success, < 0 for I/O error.
  *              bytes    - number of bytes of completed I/O
  *		requeue  - indicates whether we should requeue leftovers.
  *
@@ -649,26 +649,25 @@ void scsi_run_host_queues(struct Scsi_Host *shost)
  *		at some point during this call.
  * Notes:	If cmd was requeued, upon return it will be a stale pointer.
  */
-static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int uptodate,
+static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int error,
 					  int bytes, int requeue)
 {
 	struct request_queue *q = cmd->device->request_queue;
 	struct request *req = cmd->request;
-	unsigned long flags;
 
 	/*
 	 * If there are blocks left over at the end, set up the command
 	 * to queue the remainder of them.
 	 */
-	if (end_that_request_chunk(req, uptodate, bytes)) {
+	if (blk_end_request(req, error, bytes)) {
 		int leftover = (req->hard_nr_sectors << 9);
 
 		if (blk_pc_request(req))
 			leftover = req->data_len;
 
 		/* kill remainder if no retrys */
-		if (!uptodate && blk_noretry_request(req))
-			end_that_request_chunk(req, 0, leftover);
+		if (error && blk_noretry_request(req))
+			blk_end_request(req, error, leftover);
 		else {
 			if (requeue) {
 				/*
@@ -683,14 +682,6 @@ static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int uptodate,
 		}
 	}
 
-	add_disk_randomness(req->rq_disk);
-
-	spin_lock_irqsave(q->queue_lock, flags);
-	if (blk_rq_tagged(req))
-		blk_queue_end_tag(q, req);
-	end_that_request_last(req, uptodate);
-	spin_unlock_irqrestore(q->queue_lock, flags);
-
 	/*
 	 * This will goose the queue request function at the end, so we don't
 	 * need to worry about launching another command.
@@ -987,7 +978,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	 * are leftovers and there is some kind of error
 	 * (result != 0), retry the rest.
 	 */
-	if (scsi_end_request(cmd, 1, good_bytes, result == 0) == NULL)
+	if (scsi_end_request(cmd, 0, good_bytes, result == 0) == NULL)
 		return;
 
 	/* good_bytes = 0, or (inclusive) there were leftovers and
@@ -1001,7 +992,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				 * and quietly refuse further access.
 				 */
 				cmd->device->changed = 1;
-				scsi_end_request(cmd, 0, this_count, 1);
+				scsi_end_request(cmd, -EIO, this_count, 1);
 				return;
 			} else {
 				/* Must have been a power glitch, or a
@@ -1033,7 +1024,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				scsi_requeue_command(q, cmd);
 				return;
 			} else {
-				scsi_end_request(cmd, 0, this_count, 1);
+				scsi_end_request(cmd, -EIO, this_count, 1);
 				return;
 			}
 			break;
@@ -1061,7 +1052,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 							 "Device not ready",
 							 &sshdr);
 
-			scsi_end_request(cmd, 0, this_count, 1);
+			scsi_end_request(cmd, -EIO, this_count, 1);
 			return;
 		case VOLUME_OVERFLOW:
 			if (!(req->cmd_flags & REQ_QUIET)) {
@@ -1071,7 +1062,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				scsi_print_sense("", cmd);
 			}
 			/* See SSC3rXX or current. */
-			scsi_end_request(cmd, 0, this_count, 1);
+			scsi_end_request(cmd, -EIO, this_count, 1);
 			return;
 		default:
 			break;
@@ -1092,7 +1083,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				scsi_print_sense("", cmd);
 		}
 	}
-	scsi_end_request(cmd, 0, this_count, !result);
+	scsi_end_request(cmd, -EIO, this_count, !result);
 }
 
 /*

commit 5ed7959ede0936c55e50421a53f153b17080e876
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Thu Nov 15 09:13:11 2007 +0100

    SG: Convert SCSI to use scatterlist helpers for sg chaining
    
    Also change scsi_alloc_sgtable() to just return 0/failure, since it
    maps to the command passed in. ->request_buffer is now no longer needed,
    once drivers are adapted to use scsi_sglist() it can be killed.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4cf902efbdbf..3b5121c4c081 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -739,138 +739,41 @@ static inline unsigned int scsi_sgtable_index(unsigned short nents)
 	return index;
 }
 
-struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
+static void scsi_sg_free(struct scatterlist *sgl, unsigned int nents)
 {
 	struct scsi_host_sg_pool *sgp;
-	struct scatterlist *sgl, *prev, *ret;
-	unsigned int index;
-	int this, left;
-
-	BUG_ON(!cmd->use_sg);
-
-	left = cmd->use_sg;
-	ret = prev = NULL;
-	do {
-		this = left;
-		if (this > SCSI_MAX_SG_SEGMENTS) {
-			this = SCSI_MAX_SG_SEGMENTS - 1;
-			index = SG_MEMPOOL_NR - 1;
-		} else
-			index = scsi_sgtable_index(this);
 
-		left -= this;
-
-		sgp = scsi_sg_pools + index;
+	sgp = scsi_sg_pools + scsi_sgtable_index(nents);
+	mempool_free(sgl, sgp->pool);
+}
 
-		sgl = mempool_alloc(sgp->pool, gfp_mask);
-		if (unlikely(!sgl))
-			goto enomem;
+static struct scatterlist *scsi_sg_alloc(unsigned int nents, gfp_t gfp_mask)
+{
+	struct scsi_host_sg_pool *sgp;
 
-		sg_init_table(sgl, sgp->size);
+	sgp = scsi_sg_pools + scsi_sgtable_index(nents);
+	return mempool_alloc(sgp->pool, gfp_mask);
+}
 
-		/*
-		 * first loop through, set initial index and return value
-		 */
-		if (!ret)
-			ret = sgl;
+int scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
+{
+	int ret;
 
-		/*
-		 * chain previous sglist, if any. we know the previous
-		 * sglist must be the biggest one, or we would not have
-		 * ended up doing another loop.
-		 */
-		if (prev)
-			sg_chain(prev, SCSI_MAX_SG_SEGMENTS, sgl);
+	BUG_ON(!cmd->use_sg);
 
-		/*
-		 * if we have nothing left, mark the last segment as
-		 * end-of-list
-		 */
-		if (!left)
-			sg_mark_end(&sgl[this - 1]);
+	ret = __sg_alloc_table(&cmd->sg_table, cmd->use_sg, gfp_mask, scsi_sg_alloc);
+	if (unlikely(ret))
+		__sg_free_table(&cmd->sg_table, scsi_sg_free);
 
-		/*
-		 * don't allow subsequent mempool allocs to sleep, it would
-		 * violate the mempool principle.
-		 */
-		gfp_mask &= ~__GFP_WAIT;
-		gfp_mask |= __GFP_HIGH;
-		prev = sgl;
-	} while (left);
-
-	/*
-	 * ->use_sg may get modified after dma mapping has potentially
-	 * shrunk the number of segments, so keep a copy of it for free.
-	 */
-	cmd->__use_sg = cmd->use_sg;
+	cmd->request_buffer = cmd->sg_table.sgl;
 	return ret;
-enomem:
-	if (ret) {
-		/*
-		 * Free entries chained off ret. Since we were trying to
-		 * allocate another sglist, we know that all entries are of
-		 * the max size.
-		 */
-		sgp = scsi_sg_pools + SG_MEMPOOL_NR - 1;
-		prev = ret;
-		ret = &ret[SCSI_MAX_SG_SEGMENTS - 1];
-
-		while ((sgl = sg_chain_ptr(ret)) != NULL) {
-			ret = &sgl[SCSI_MAX_SG_SEGMENTS - 1];
-			mempool_free(sgl, sgp->pool);
-		}
-
-		mempool_free(prev, sgp->pool);
-	}
-	return NULL;
 }
 
 EXPORT_SYMBOL(scsi_alloc_sgtable);
 
 void scsi_free_sgtable(struct scsi_cmnd *cmd)
 {
-	struct scatterlist *sgl = cmd->request_buffer;
-	struct scsi_host_sg_pool *sgp;
-
-	/*
-	 * if this is the biggest size sglist, check if we have
-	 * chained parts we need to free
-	 */
-	if (cmd->__use_sg > SCSI_MAX_SG_SEGMENTS) {
-		unsigned short this, left;
-		struct scatterlist *next;
-		unsigned int index;
-
-		left = cmd->__use_sg - (SCSI_MAX_SG_SEGMENTS - 1);
-		next = sg_chain_ptr(&sgl[SCSI_MAX_SG_SEGMENTS - 1]);
-		while (left && next) {
-			sgl = next;
-			this = left;
-			if (this > SCSI_MAX_SG_SEGMENTS) {
-				this = SCSI_MAX_SG_SEGMENTS - 1;
-				index = SG_MEMPOOL_NR - 1;
-			} else
-				index = scsi_sgtable_index(this);
-
-			left -= this;
-
-			sgp = scsi_sg_pools + index;
-
-			if (left)
-				next = sg_chain_ptr(&sgl[sgp->size - 1]);
-
-			mempool_free(sgl, sgp->pool);
-		}
-
-		/*
-		 * Restore original, will be freed below
-		 */
-		sgl = cmd->request_buffer;
-		sgp = scsi_sg_pools + SG_MEMPOOL_NR - 1;
-	} else
-		sgp = scsi_sg_pools + scsi_sgtable_index(cmd->__use_sg);
-
-	mempool_free(sgl, sgp->pool);
+	__sg_free_table(&cmd->sg_table, scsi_sg_free);
 }
 
 EXPORT_SYMBOL(scsi_free_sgtable);
@@ -1120,8 +1023,7 @@ static int scsi_init_io(struct scsi_cmnd *cmd)
 	/*
 	 * If sg table allocation fails, requeue request later.
 	 */
-	cmd->request_buffer = scsi_alloc_sgtable(cmd, GFP_ATOMIC);
-	if (unlikely(!cmd->request_buffer)) {
+	if (unlikely(scsi_alloc_sgtable(cmd, GFP_ATOMIC))) {
 		scsi_unprep_request(req);
 		return BLKPREP_DEFER;
 	}

commit b80ca4f7ee36c26d300c5a8f429e73372d153379
Author: FUJITA Tomonori <tomof@acm.org>
Date:   Sun Jan 13 15:46:13 2008 +0900

    [SCSI] replace sizeof sense_buffer with SCSI_SENSE_BUFFERSIZE
    
    This replaces sizeof sense_buffer with SCSI_SENSE_BUFFERSIZE in
    several LLDs. It's a preparation for the future changes to remove
    sense_buffer array in scsi_cmnd structure.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index de601370c05b..4cf902efbdbf 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -441,7 +441,7 @@ static void scsi_init_cmd_errh(struct scsi_cmnd *cmd)
 {
 	cmd->serial_number = 0;
 	cmd->resid = 0;
-	memset(cmd->sense_buffer, 0, sizeof cmd->sense_buffer);
+	memset(cmd->sense_buffer, 0, SCSI_SENSE_BUFFERSIZE);
 	if (cmd->cmd_len == 0)
 		cmd->cmd_len = COMMAND_SIZE(cmd->cmnd[0]);
 }

commit 465ff3185e0cb76d46137335a4d21d0d9d3ac8a2
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Tue Jan 1 10:00:10 2008 -0600

    [SCSI] relax scsi dma alignment
    
    This patch relaxes the default SCSI DMA alignment from 512 bytes to 4
    bytes.  I remember from previous discussions that usb and firewire have
    sector size alignment requirements, so I upped their alignments in the
    respective slave allocs.
    
    The reason for doing this is so that we don't get such a huge amount of
    copy overhead in bio_copy_user() for udev.  (basically all inquiries it
    issues can now be directly mapped).
    
    Acked-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index db52222885b7..de601370c05b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1668,6 +1668,14 @@ struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
 
 	if (!shost->use_clustering)
 		clear_bit(QUEUE_FLAG_CLUSTER, &q->queue_flags);
+
+	/*
+	 * set a reasonable default alignment on word boundaries: the
+	 * host and device may alter it using
+	 * blk_queue_update_dma_alignment() later.
+	 */
+	blk_queue_dma_alignment(q, 0x03);
+
 	return q;
 }
 EXPORT_SYMBOL(__scsi_alloc_queue);

commit 001aac257cf8adbe90cdcba6e07f8d12dfc8fa6b
Author: James Bottomley <James.Bottomley@SteelEye.com>
Date:   Sun Dec 2 19:10:40 2007 +0200

    [SCSI] sd,sr: add early detection of medium not present
    
    The current scsi_test_unit_ready() is updated to return sense code
    information (in struct scsi_sense_hdr).  The sd and sr drivers are
    changed to interpret the sense code return asc 0x3a as no media and
    adjust the device status accordingly.
    
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index aa17e718666e..db52222885b7 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1973,27 +1973,57 @@ scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
 }
 EXPORT_SYMBOL(scsi_mode_sense);
 
+/**
+ *	scsi_test_unit_ready - test if unit is ready
+ *	@sdev:	scsi device to change the state of.
+ *	@timeout: command timeout
+ *	@retries: number of retries before failing
+ *	@sshdr_external: Optional pointer to struct scsi_sense_hdr for
+ *		returning sense. Make sure that this is cleared before passing
+ *		in.
+ *
+ *	Returns zero if unsuccessful or an error if TUR failed.  For
+ *	removable media, a return of NOT_READY or UNIT_ATTENTION is
+ *	translated to success, with the ->changed flag updated.
+ **/
 int
-scsi_test_unit_ready(struct scsi_device *sdev, int timeout, int retries)
+scsi_test_unit_ready(struct scsi_device *sdev, int timeout, int retries,
+		     struct scsi_sense_hdr *sshdr_external)
 {
 	char cmd[] = {
 		TEST_UNIT_READY, 0, 0, 0, 0, 0,
 	};
-	struct scsi_sense_hdr sshdr;
+	struct scsi_sense_hdr *sshdr;
 	int result;
-	
-	result = scsi_execute_req(sdev, cmd, DMA_NONE, NULL, 0, &sshdr,
-				  timeout, retries);
+
+	if (!sshdr_external)
+		sshdr = kzalloc(sizeof(*sshdr), GFP_KERNEL);
+	else
+		sshdr = sshdr_external;
+
+	/* try to eat the UNIT_ATTENTION if there are enough retries */
+	do {
+		result = scsi_execute_req(sdev, cmd, DMA_NONE, NULL, 0, sshdr,
+					  timeout, retries);
+	} while ((driver_byte(result) & DRIVER_SENSE) &&
+		 sshdr && sshdr->sense_key == UNIT_ATTENTION &&
+		 --retries);
+
+	if (!sshdr)
+		/* could not allocate sense buffer, so can't process it */
+		return result;
 
 	if ((driver_byte(result) & DRIVER_SENSE) && sdev->removable) {
 
-		if ((scsi_sense_valid(&sshdr)) &&
-		    ((sshdr.sense_key == UNIT_ATTENTION) ||
-		     (sshdr.sense_key == NOT_READY))) {
+		if ((scsi_sense_valid(sshdr)) &&
+		    ((sshdr->sense_key == UNIT_ATTENTION) ||
+		     (sshdr->sense_key == NOT_READY))) {
 			sdev->changed = 1;
 			result = 0;
 		}
 	}
+	if (!sshdr_external)
+		kfree(sshdr);
 	return result;
 }
 EXPORT_SYMBOL(scsi_test_unit_ready);

commit 4a03d90e35bc5273d27301fa669d4b2103196f94
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Mon Nov 19 11:28:48 2007 +1100

    [SCSI] BUG_ON() impossible condition in sg list counting
    
    If blk_rq_map_sg wrote more than was allocated in the scatterlist,
    BUG_ON() is probably the right thing to do.
    
    [jejb: rejections fixed up]
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Acked-by: Jens Axboe <jens.axboe@oracle.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b0c59ae63a2f..aa17e718666e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1104,7 +1104,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
  *
  * Returns:     0 on success
  *		BLKPREP_DEFER if the failure is retryable
- *		BLKPREP_KILL if the failure is fatal
  */
 static int scsi_init_io(struct scsi_cmnd *cmd)
 {
@@ -1138,17 +1137,9 @@ static int scsi_init_io(struct scsi_cmnd *cmd)
 	 * each segment.
 	 */
 	count = blk_rq_map_sg(req->q, req, cmd->request_buffer);
-	if (likely(count <= cmd->use_sg)) {
-		cmd->use_sg = count;
-		return BLKPREP_OK;
-	}
-
-	printk(KERN_ERR "Incorrect number of segments after building list\n");
-	printk(KERN_ERR "counted %d, received %d\n", count, cmd->use_sg);
-	printk(KERN_ERR "req nr_sec %lu, cur_nr_sec %u\n", req->nr_sectors,
-			req->current_nr_sectors);
-
-	return BLKPREP_KILL;
+	BUG_ON(count > cmd->use_sg);
+	cmd->use_sg = count;
+	return BLKPREP_OK;
 }
 
 static struct scsi_cmnd *scsi_get_cmd_from_req(struct scsi_device *sdev,

commit 25d7c363f2663fe399e623c9bd819258c9760bdc
Author: Tony Battersby <tonyb@cybernetics.com>
Date:   Mon Nov 12 10:00:44 2007 -0500

    [SCSI] move single_lun flag from scsi_device to scsi_target
    
    Some SCSI tape medium changers that need the BLIST_SINGLELUN flag have
    the medium changer at one LUN and the tape drive at a different LUN.
    The inquiry string of the tape drive may be different from that of the
    medium changer.  In order for single_lun to be effective, every
    scsi_device under a given scsi_target must have it set.  This means that
    there needs to be a blacklist entry for BOTH the medium changer AND the
    tape drive, which is impractical because some medium changers may be
    paired with a variety of different tape drive models.  It makes more
    sense to put the single_lun flag in scsi_target instead of scsi_device,
    which causes every device at a given target ID to inherit the single_lun
    flag from one LUN.  This makes it possible to blacklist just the medium
    changer and not the tape drive.
    
    Signed-off-by: Tony Battersby <tonyb@cybernetics.com>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 199b02452259..b0c59ae63a2f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -526,7 +526,7 @@ static void scsi_run_queue(struct request_queue *q)
 	struct Scsi_Host *shost = sdev->host;
 	unsigned long flags;
 
-	if (sdev->single_lun)
+	if (scsi_target(sdev)->single_lun)
 		scsi_single_lun_run(sdev);
 
 	spin_lock_irqsave(shost->host_lock, flags);
@@ -1559,7 +1559,7 @@ static void scsi_request_fn(struct request_queue *q)
 
 		if (!scsi_host_queue_ready(q, shost, sdev))
 			goto not_ready;
-		if (sdev->single_lun) {
+		if (scsi_target(sdev)->single_lun) {
 			if (scsi_target(sdev)->starget_sdev_user &&
 			    scsi_target(sdev)->starget_sdev_user != sdev)
 				goto not_ready;

commit eb44820c28bc9a042e1157b41c677018a8fdfc74
Author: Rob Landley <rob@landley.net>
Date:   Sat Nov 3 13:30:39 2007 -0500

    [SCSI] Add Documentation and integrate into docbook build
    
    Add Documentation/DocBook/scsi_midlayer.tmpl, add to Makefile, and update
    lots of kerneldoc comments in drivers/scsi/*.
    
    Updated with comments from Stefan Richter, Stephen M. Cameron,
     James Bottomley and Randy Dunlap.
    
    Signed-off-by: Rob Landley <rob@landley.net>
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a9ac5b1b1667..199b02452259 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -175,7 +175,7 @@ int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
  *
  * returns the req->errors value which is the scsi_cmnd result
  * field.
- **/
+ */
 int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 		 int data_direction, void *buffer, unsigned bufflen,
 		 unsigned char *sense, int timeout, int retries, int flags)
@@ -274,7 +274,7 @@ static void scsi_bi_endio(struct bio *bio, int error)
 /**
  * scsi_req_map_sg - map a scatterlist into a request
  * @rq:		request to fill
- * @sg:		scatterlist
+ * @sgl:	scatterlist
  * @nsegs:	number of elements
  * @bufflen:	len of buffer
  * @gfp:	memory allocation flags
@@ -365,14 +365,16 @@ static int scsi_req_map_sg(struct request *rq, struct scatterlist *sgl,
  * @sdev:	scsi device
  * @cmd:	scsi command
  * @cmd_len:	length of scsi cdb
- * @data_direction: data direction
+ * @data_direction: DMA_TO_DEVICE, DMA_FROM_DEVICE, or DMA_NONE
  * @buffer:	data buffer (this can be a kernel buffer or scatterlist)
  * @bufflen:	len of buffer
  * @use_sg:	if buffer is a scatterlist this is the number of elements
  * @timeout:	request timeout in seconds
  * @retries:	number of times to retry request
- * @flags:	or into request flags
- **/
+ * @privdata:	data passed to done()
+ * @done:	callback function when done
+ * @gfp:	memory allocation flags
+ */
 int scsi_execute_async(struct scsi_device *sdev, const unsigned char *cmd,
 		       int cmd_len, int data_direction, void *buffer, unsigned bufflen,
 		       int use_sg, int timeout, int retries, void *privdata,
@@ -1804,7 +1806,7 @@ void scsi_exit_queue(void)
  *	@timeout: command timeout
  *	@retries: number of retries before failing
  *	@data: returns a structure abstracting the mode header data
- *	@sense: place to put sense data (or NULL if no sense to be collected).
+ *	@sshdr: place to put sense data (or NULL if no sense to be collected).
  *		must be SCSI_SENSE_BUFFERSIZE big.
  *
  *	Returns zero if successful; negative error number or scsi
@@ -1871,8 +1873,7 @@ scsi_mode_select(struct scsi_device *sdev, int pf, int sp, int modepage,
 EXPORT_SYMBOL_GPL(scsi_mode_select);
 
 /**
- *	scsi_mode_sense - issue a mode sense, falling back from 10 to 
- *		six bytes if necessary.
+ *	scsi_mode_sense - issue a mode sense, falling back from 10 to six bytes if necessary.
  *	@sdev:	SCSI device to be queried
  *	@dbd:	set if mode sense will allow block descriptors to be returned
  *	@modepage: mode page being requested
@@ -1881,13 +1882,13 @@ EXPORT_SYMBOL_GPL(scsi_mode_select);
  *	@timeout: command timeout
  *	@retries: number of retries before failing
  *	@data: returns a structure abstracting the mode header data
- *	@sense: place to put sense data (or NULL if no sense to be collected).
+ *	@sshdr: place to put sense data (or NULL if no sense to be collected).
  *		must be SCSI_SENSE_BUFFERSIZE big.
  *
  *	Returns zero if unsuccessful, or the header offset (either 4
  *	or 8 depending on whether a six or ten byte command was
  *	issued) if successful.
- **/
+ */
 int
 scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
 		  unsigned char *buffer, int len, int timeout, int retries,
@@ -2007,14 +2008,13 @@ scsi_test_unit_ready(struct scsi_device *sdev, int timeout, int retries)
 EXPORT_SYMBOL(scsi_test_unit_ready);
 
 /**
- *	scsi_device_set_state - Take the given device through the device
- *		state model.
+ *	scsi_device_set_state - Take the given device through the device state model.
  *	@sdev:	scsi device to change the state of.
  *	@state:	state to change to.
  *
  *	Returns zero if unsuccessful or an error if the requested 
  *	transition is illegal.
- **/
+ */
 int
 scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 {
@@ -2264,7 +2264,7 @@ EXPORT_SYMBOL_GPL(sdev_evt_send_simple);
  *	Must be called with user context, may sleep.
  *
  *	Returns zero if unsuccessful or an error if not.
- **/
+ */
 int
 scsi_device_quiesce(struct scsi_device *sdev)
 {
@@ -2289,7 +2289,7 @@ EXPORT_SYMBOL(scsi_device_quiesce);
  *	queues.
  *
  *	Must be called with user context, may sleep.
- **/
+ */
 void
 scsi_device_resume(struct scsi_device *sdev)
 {
@@ -2326,8 +2326,7 @@ scsi_target_resume(struct scsi_target *starget)
 EXPORT_SYMBOL(scsi_target_resume);
 
 /**
- * scsi_internal_device_block - internal function to put a device
- *				temporarily into the SDEV_BLOCK state
+ * scsi_internal_device_block - internal function to put a device temporarily into the SDEV_BLOCK state
  * @sdev:	device to block
  *
  * Block request made by scsi lld's to temporarily stop all
@@ -2342,7 +2341,7 @@ EXPORT_SYMBOL(scsi_target_resume);
  *	state, all commands are deferred until the scsi lld reenables
  *	the device with scsi_device_unblock or device_block_tmo fires.
  *	This routine assumes the host_lock is held on entry.
- **/
+ */
 int
 scsi_internal_device_block(struct scsi_device *sdev)
 {
@@ -2382,7 +2381,7 @@ EXPORT_SYMBOL_GPL(scsi_internal_device_block);
  *	(which must be a legal transition) allowing the midlayer to
  *	goose the queue for this device.  This routine assumes the 
  *	host_lock is held upon entry.
- **/
+ */
 int
 scsi_internal_device_unblock(struct scsi_device *sdev)
 {
@@ -2460,7 +2459,7 @@ EXPORT_SYMBOL_GPL(scsi_target_unblock);
 
 /**
  * scsi_kmap_atomic_sg - find and atomically map an sg-elemnt
- * @sg:		scatter-gather list
+ * @sgl:	scatter-gather list
  * @sg_count:	number of segments in sg
  * @offset:	offset in bytes into sg, on return offset into the mapped area
  * @len:	bytes to map, on return number of bytes mapped
@@ -2509,8 +2508,7 @@ void *scsi_kmap_atomic_sg(struct scatterlist *sgl, int sg_count,
 EXPORT_SYMBOL(scsi_kmap_atomic_sg);
 
 /**
- * scsi_kunmap_atomic_sg - atomically unmap a virtual address, previously
- *			   mapped with scsi_kmap_atomic_sg
+ * scsi_kunmap_atomic_sg - atomically unmap a virtual address, previously mapped with scsi_kmap_atomic_sg
  * @virt:	virtual address to be unmapped
  */
 void scsi_kunmap_atomic_sg(void *virt)

commit 7b3d9545f9ac8b31528dd2d6d8ec8d19922917b8
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Sun Jan 6 10:17:12 2008 -0800

    Revert "scsi: revert "[SCSI] Get rid of scsi_cmnd->done""
    
    This reverts commit ac40532ef0b8649e6f7f83859ea0de1c4ed08a19, which gets
    us back the original cleanup of 6f5391c283d7fdcf24bf40786ea79061919d1e1d.
    
    It turns out that the bug that was triggered by that commit was
    apparently not actually triggered by that commit at all, and just the
    testing conditions had changed enough to make it appear to be due to it.
    
    The real problem seems to have been found by Peter Osterlund:
    
      "pktcdvd sets it [block device size] when opening the /dev/pktcdvd
       device, but when the drive is later opened as /dev/scd0, there is
       nothing that sets it back.  (Btw, 40944 is possible if the disk is a
       CDRW that was formatted with "cdrwtool -m 10236".)
    
       The problem is that pktcdvd opens the cd device in non-blocking mode
       when pktsetup is run, and doesn't close it again until pktsetup -d is
       run.  The effect is that if you meanwhile open the cd device,
       blkdev.c:do_open() doesn't call bd_set_size() because
       bdev->bd_openers is non-zero."
    
    In particular, to repeat the bug (regardless of whether commit
    6f5391c283d7fdcf24bf40786ea79061919d1e1d is applied or not):
    
      " 1. Start with an empty drive.
        2. pktsetup 0 /dev/scd0
        3. Insert a CD containing an isofs filesystem.
        4. mount /dev/pktcdvd/0 /mnt/tmp
        5. umount /mnt/tmp
        6. Press the eject button.
        7. Insert a DVD containing a non-writable filesystem.
        8. mount /dev/scd0 /mnt/tmp
        9. find /mnt/tmp -type f -print0 | xargs -0 sha1sum >/dev/null
        10. If the DVD contains data beyond the physical size of a CD, you
            get I/O errors in the terminal, and dmesg reports lots of
            "attempt to access beyond end of device" errors."
    
    which in turn is because the nested open after the media change won't
    cause the size to be set properly (because the original open still holds
    the block device, and we only do the bd_set_size() when we don't have
    other people holding the device open).
    
    The proper fix for that is probably to just do something like
    
            bdev->bd_inode->i_size = (loff_t)get_capacity(disk)<<9;
    
    in fs/block_dev.c:do_open() even for the cases where we're not the
    original opener (but *not* call bd_set_size(), since that will also
    change the block size of the device).
    
    Cc: Peter Osterlund <petero2@telia.com>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Cc: Matthew Wilcox <matthew@wil.cx>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 60f77c4b3946..a9ac5b1b1667 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1092,7 +1092,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	}
 	scsi_end_request(cmd, 0, this_count, !result);
 }
-EXPORT_SYMBOL(scsi_io_completion);
 
 /*
  * Function:    scsi_init_io()
@@ -1171,18 +1170,6 @@ static struct scsi_cmnd *scsi_get_cmd_from_req(struct scsi_device *sdev,
 	return cmd;
 }
 
-static void scsi_blk_pc_done(struct scsi_cmnd *cmd)
-{
-	BUG_ON(!blk_pc_request(cmd->request));
-	/*
-	 * This will complete the whole command with uptodate=1 so
-	 * as far as the block layer is concerned the command completed
-	 * successfully. Since this is a REQ_BLOCK_PC command the
-	 * caller should check the request's errors value
-	 */
-	scsi_io_completion(cmd, cmd->request_bufflen);
-}
-
 int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 {
 	struct scsi_cmnd *cmd;
@@ -1232,7 +1219,6 @@ int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 	cmd->transfersize = req->data_len;
 	cmd->allowed = req->retries;
 	cmd->timeout_per_command = req->timeout;
-	cmd->done = scsi_blk_pc_done;
 	return BLKPREP_OK;
 }
 EXPORT_SYMBOL(scsi_setup_blk_pc_cmnd);

commit 3a62b5f3cdaa00413e25fa6d6b6816e2c67f92f6
Merge: b8c9a18712f7 751bf4d7865e
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Thu Jan 3 11:59:27 2008 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-rc-fixes-2.6
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi-rc-fixes-2.6:
      [SCSI] scsi_sysfs: restore prep_fn when ULD is removed

commit ac40532ef0b8649e6f7f83859ea0de1c4ed08a19
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Jan 2 17:25:34 2008 +0100

    scsi: revert "[SCSI] Get rid of scsi_cmnd->done"
    
    This reverts commit 6f5391c283d7fdcf24bf40786ea79061919d1e1d ("[SCSI]
    Get rid of scsi_cmnd->done") that was supposed to be a cleanup commit,
    but apparently it causes regressions:
    
      Bug 9370 - v2.6.24-rc2-409-g9418d5d: attempt to access beyond end of device
      http://bugzilla.kernel.org/show_bug.cgi?id=9370
    
    this patch should be reintroduced in a more split-up form to make
    testing of it easier.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Matthew Wilcox <matthew@wil.cx>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0e81e4cf8876..8df8267ce316 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1092,6 +1092,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	}
 	scsi_end_request(cmd, 0, this_count, !result);
 }
+EXPORT_SYMBOL(scsi_io_completion);
 
 /*
  * Function:    scsi_init_io()
@@ -1170,6 +1171,18 @@ static struct scsi_cmnd *scsi_get_cmd_from_req(struct scsi_device *sdev,
 	return cmd;
 }
 
+static void scsi_blk_pc_done(struct scsi_cmnd *cmd)
+{
+	BUG_ON(!blk_pc_request(cmd->request));
+	/*
+	 * This will complete the whole command with uptodate=1 so
+	 * as far as the block layer is concerned the command completed
+	 * successfully. Since this is a REQ_BLOCK_PC command the
+	 * caller should check the request's errors value
+	 */
+	scsi_io_completion(cmd, cmd->request_bufflen);
+}
+
 int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 {
 	struct scsi_cmnd *cmd;
@@ -1219,6 +1232,7 @@ int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 	cmd->transfersize = req->data_len;
 	cmd->allowed = req->retries;
 	cmd->timeout_per_command = req->timeout;
+	cmd->done = scsi_blk_pc_done;
 	return BLKPREP_OK;
 }
 EXPORT_SYMBOL(scsi_setup_blk_pc_cmnd);

commit 751bf4d7865e4ced406be93b04c7436d866d3684
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Wed Jan 2 11:14:30 2008 -0600

    [SCSI] scsi_sysfs: restore prep_fn when ULD is removed
    
    A recent bug report:
    
    http://bugzilla.kernel.org/show_bug.cgi?id=9674
    
    Was caused because the ULDs now set their own prep functions, but
    don't necessarily reset the prep function back to the SCSI default
    when they are removed.  This leads to panics if commands are sent to
    the device after the module is removed because the prep_fn is still
    pointing to the old module code.  The fix for this is to implement a
    bus remove method that resets the prep_fn pointer correctly before
    calling the ULD specific driver remove method.
    
    Signed-off-by: James Bottomley <James.Bottomley@HansenPartnership.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0e81e4cf8876..a9ac5b1b1667 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1332,7 +1332,7 @@ int scsi_prep_return(struct request_queue *q, struct request *req, int ret)
 }
 EXPORT_SYMBOL(scsi_prep_return);
 
-static int scsi_prep_fn(struct request_queue *q, struct request *req)
+int scsi_prep_fn(struct request_queue *q, struct request *req)
 {
 	struct scsi_device *sdev = q->queuedata;
 	int ret = BLKPREP_KILL;

commit a341cd0f6a0fde1f85fec9aa8f81f824ea4a3f92
Author: Jeff Garzik <jeff@garzik.org>
Date:   Mon Oct 29 17:15:22 2007 -0400

    SCSI: add asynchronous event notification API
    
    Originally based on a patch by Kristen Carlson Accardi @ Intel.
    Copious input from James Bottomley.
    
    Signed-off-by: Jeff Garzik <jgarzik@redhat.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 88de771d3569..0e81e4cf8876 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2114,6 +2114,142 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 }
 EXPORT_SYMBOL(scsi_device_set_state);
 
+/**
+ * 	sdev_evt_emit - emit a single SCSI device uevent
+ *	@sdev: associated SCSI device
+ *	@evt: event to emit
+ *
+ *	Send a single uevent (scsi_event) to the associated scsi_device.
+ */
+static void scsi_evt_emit(struct scsi_device *sdev, struct scsi_event *evt)
+{
+	int idx = 0;
+	char *envp[3];
+
+	switch (evt->evt_type) {
+	case SDEV_EVT_MEDIA_CHANGE:
+		envp[idx++] = "SDEV_MEDIA_CHANGE=1";
+		break;
+
+	default:
+		/* do nothing */
+		break;
+	}
+
+	envp[idx++] = NULL;
+
+	kobject_uevent_env(&sdev->sdev_gendev.kobj, KOBJ_CHANGE, envp);
+}
+
+/**
+ * 	sdev_evt_thread - send a uevent for each scsi event
+ *	@work: work struct for scsi_device
+ *
+ *	Dispatch queued events to their associated scsi_device kobjects
+ *	as uevents.
+ */
+void scsi_evt_thread(struct work_struct *work)
+{
+	struct scsi_device *sdev;
+	LIST_HEAD(event_list);
+
+	sdev = container_of(work, struct scsi_device, event_work);
+
+	while (1) {
+		struct scsi_event *evt;
+		struct list_head *this, *tmp;
+		unsigned long flags;
+
+		spin_lock_irqsave(&sdev->list_lock, flags);
+		list_splice_init(&sdev->event_list, &event_list);
+		spin_unlock_irqrestore(&sdev->list_lock, flags);
+
+		if (list_empty(&event_list))
+			break;
+
+		list_for_each_safe(this, tmp, &event_list) {
+			evt = list_entry(this, struct scsi_event, node);
+			list_del(&evt->node);
+			scsi_evt_emit(sdev, evt);
+			kfree(evt);
+		}
+	}
+}
+
+/**
+ * 	sdev_evt_send - send asserted event to uevent thread
+ *	@sdev: scsi_device event occurred on
+ *	@evt: event to send
+ *
+ *	Assert scsi device event asynchronously.
+ */
+void sdev_evt_send(struct scsi_device *sdev, struct scsi_event *evt)
+{
+	unsigned long flags;
+
+	if (!test_bit(evt->evt_type, sdev->supported_events)) {
+		kfree(evt);
+		return;
+	}
+
+	spin_lock_irqsave(&sdev->list_lock, flags);
+	list_add_tail(&evt->node, &sdev->event_list);
+	schedule_work(&sdev->event_work);
+	spin_unlock_irqrestore(&sdev->list_lock, flags);
+}
+EXPORT_SYMBOL_GPL(sdev_evt_send);
+
+/**
+ * 	sdev_evt_alloc - allocate a new scsi event
+ *	@evt_type: type of event to allocate
+ *	@gfpflags: GFP flags for allocation
+ *
+ *	Allocates and returns a new scsi_event.
+ */
+struct scsi_event *sdev_evt_alloc(enum scsi_device_event evt_type,
+				  gfp_t gfpflags)
+{
+	struct scsi_event *evt = kzalloc(sizeof(struct scsi_event), gfpflags);
+	if (!evt)
+		return NULL;
+
+	evt->evt_type = evt_type;
+	INIT_LIST_HEAD(&evt->node);
+
+	/* evt_type-specific initialization, if any */
+	switch (evt_type) {
+	case SDEV_EVT_MEDIA_CHANGE:
+	default:
+		/* do nothing */
+		break;
+	}
+
+	return evt;
+}
+EXPORT_SYMBOL_GPL(sdev_evt_alloc);
+
+/**
+ * 	sdev_evt_send_simple - send asserted event to uevent thread
+ *	@sdev: scsi_device event occurred on
+ *	@evt_type: type of event to send
+ *	@gfpflags: GFP flags for allocation
+ *
+ *	Assert scsi device event asynchronously, given an event type.
+ */
+void sdev_evt_send_simple(struct scsi_device *sdev,
+			  enum scsi_device_event evt_type, gfp_t gfpflags)
+{
+	struct scsi_event *evt = sdev_evt_alloc(evt_type, gfpflags);
+	if (!evt) {
+		sdev_printk(KERN_ERR, sdev, "event %d eaten due to OOM\n",
+			    evt_type);
+		return;
+	}
+
+	sdev_evt_send(sdev, evt);
+}
+EXPORT_SYMBOL_GPL(sdev_evt_send_simple);
+
 /**
  *	scsi_device_quiesce - Block user issued commands.
  *	@sdev:	scsi device to quiesce.

commit c46f2334c84c2b26baa64d42d75ddc5fab38c3dc
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Wed Oct 31 12:06:37 2007 +0100

    [SG] Get rid of __sg_mark_end()
    
    sg_mark_end() overwrites the page_link information, but all users want
    __sg_mark_end() behaviour where we just set the end bit. That is the most
    natural way to use the sg list, since you'll fill it in and then mark the
    end point.
    
    So change sg_mark_end() to only set the termination bit. Add a sg_magic
    debug check as well, and clear a chain pointer if it is set.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 61fdaf02f251..88de771d3569 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -785,7 +785,7 @@ struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 		 * end-of-list
 		 */
 		if (!left)
-			sg_mark_end(sgl, this);
+			sg_mark_end(&sgl[this - 1]);
 
 		/*
 		 * don't allow subsequent mempool allocs to sleep, it would

commit 45711f1af6eff1a6d010703b4862e0d2b9afd056
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Mon Oct 22 21:19:53 2007 +0200

    [SG] Update drivers to use sg helpers
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index aac8a02cbe80..61fdaf02f251 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -295,7 +295,7 @@ static int scsi_req_map_sg(struct request *rq, struct scatterlist *sgl,
 	int i, err, nr_vecs = 0;
 
 	for_each_sg(sgl, sg, nsegs, i) {
-		page = sg->page;
+		page = sg_page(sg);
 		off = sg->offset;
 		len = sg->length;
  		data_len += len;
@@ -764,7 +764,7 @@ struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 		if (unlikely(!sgl))
 			goto enomem;
 
-		memset(sgl, 0, sizeof(*sgl) * sgp->size);
+		sg_init_table(sgl, sgp->size);
 
 		/*
 		 * first loop through, set initial index and return value
@@ -780,6 +780,13 @@ struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 		if (prev)
 			sg_chain(prev, SCSI_MAX_SG_SEGMENTS, sgl);
 
+		/*
+		 * if we have nothing left, mark the last segment as
+		 * end-of-list
+		 */
+		if (!left)
+			sg_mark_end(sgl, this);
+
 		/*
 		 * don't allow subsequent mempool allocs to sleep, it would
 		 * violate the mempool principle.
@@ -2353,7 +2360,7 @@ void *scsi_kmap_atomic_sg(struct scatterlist *sgl, int sg_count,
 	*offset = *offset - len_complete + sg->offset;
 
 	/* Assumption: contiguous pages can be accessed as "page + i" */
-	page = nth_page(sg->page, (*offset >> PAGE_SHIFT));
+	page = nth_page(sg_page(sg), (*offset >> PAGE_SHIFT));
 	*offset &= ~PAGE_MASK;
 
 	/* Bytes in this sg-entry from *offset to the end of the page */

commit a3bec5c5aea0da263111c4d8f8eabc1f8560d7bf
Author: Jens Axboe <axboe@carl.home.kernel.dk>
Date:   Wed Oct 17 19:33:05 2007 +0200

    Revert "[SCSI] Remove full sg table memset()"
    
    A bit too eager - we definitely need to clear the sg table
    initially, so that we don't accidentally have ->page & 0x01
    true and think that is a chain pointer.
    
    This reverts commit f5c0dde4c66421a3a2d7d6fa604a712c9b0744e5.

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0c86be71bb33..aac8a02cbe80 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -764,6 +764,8 @@ struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 		if (unlikely(!sgl))
 			goto enomem;
 
+		memset(sgl, 0, sizeof(*sgl) * sgp->size);
+
 		/*
 		 * first loop through, set initial index and return value
 		 */

commit f5c0dde4c66421a3a2d7d6fa604a712c9b0744e5
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Wed Oct 17 13:42:11 2007 +0200

    [SCSI] Remove full sg table memset()
    
    We don't need to do that anymore, since blk_rq_map_sg() clears
    individual entries.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index aac8a02cbe80..0c86be71bb33 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -764,8 +764,6 @@ struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 		if (unlikely(!sgl))
 			goto enomem;
 
-		memset(sgl, 0, sizeof(*sgl) * sgp->size);
-
 		/*
 		 * first loop through, set initial index and return value
 		 */

commit 2a7c59e79ce060c746358b08521de0acbca6a4f1
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Tue Sep 18 12:17:28 2007 +0200

    remove sglist_len
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1a7e8d811a08..aac8a02cbe80 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -769,10 +769,8 @@ struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 		/*
 		 * first loop through, set initial index and return value
 		 */
-		if (!ret) {
-			cmd->sglist_len = index;
+		if (!ret)
 			ret = sgl;
-		}
 
 		/*
 		 * chain previous sglist, if any. we know the previous
@@ -825,8 +823,6 @@ void scsi_free_sgtable(struct scsi_cmnd *cmd)
 	struct scatterlist *sgl = cmd->request_buffer;
 	struct scsi_host_sg_pool *sgp;
 
-	BUG_ON(cmd->sglist_len >= SG_MEMPOOL_NR);
-
 	/*
 	 * if this is the biggest size sglist, check if we have
 	 * chained parts we need to free
@@ -861,9 +857,10 @@ void scsi_free_sgtable(struct scsi_cmnd *cmd)
 		 * Restore original, will be freed below
 		 */
 		sgl = cmd->request_buffer;
-	}
+		sgp = scsi_sg_pools + SG_MEMPOOL_NR - 1;
+	} else
+		sgp = scsi_sg_pools + scsi_sgtable_index(cmd->__use_sg);
 
-	sgp = scsi_sg_pools + cmd->sglist_len;
 	mempool_free(sgl, sgp->pool);
 }
 

commit fd820f405574a30aacf9a859886e173d641f080b
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Tue Sep 18 12:14:37 2007 +0200

    revert sg segment size ifdefs
    
    This reverts sg segment size ifdefs that the current code has in order
    to provide a way to reduce sgpool memory consumption.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b6e6d801768b..1a7e8d811a08 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -34,6 +34,13 @@
 #define SG_MEMPOOL_NR		ARRAY_SIZE(scsi_sg_pools)
 #define SG_MEMPOOL_SIZE		2
 
+/*
+ * The maximum number of SG segments that we will put inside a scatterlist
+ * (unless chaining is used). Should ideally fit inside a single page, to
+ * avoid a higher order allocation.
+ */
+#define SCSI_MAX_SG_SEGMENTS	128
+
 struct scsi_host_sg_pool {
 	size_t		size;
 	char		*name;
@@ -45,9 +52,15 @@ struct scsi_host_sg_pool {
 static struct scsi_host_sg_pool scsi_sg_pools[] = {
 	SP(8),
 	SP(16),
+#if (SCSI_MAX_SG_SEGMENTS > 16)
 	SP(32),
+#if (SCSI_MAX_SG_SEGMENTS > 32)
 	SP(64),
+#if (SCSI_MAX_SG_SEGMENTS > 64)
 	SP(128),
+#endif
+#endif
+#endif
 };
 #undef SP
 
@@ -684,13 +697,6 @@ static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int uptodate,
 	return NULL;
 }
 
-/*
- * The maximum number of SG segments that we will put inside a scatterlist
- * (unless chaining is used). Should ideally fit inside a single page, to
- * avoid a higher order allocation.
- */
-#define SCSI_MAX_SG_SEGMENTS	128
-
 /*
  * Like SCSI_MAX_SG_SEGMENTS, but for archs that have sg chaining. This limit
  * is totally arbitrary, a setting of 2048 will get you at least 8mb ios.
@@ -708,15 +714,21 @@ static inline unsigned int scsi_sgtable_index(unsigned short nents)
 	case 9 ... 16:
 		index = 1;
 		break;
+#if (SCSI_MAX_SG_SEGMENTS > 16)
 	case 17 ... 32:
 		index = 2;
 		break;
+#if (SCSI_MAX_SG_SEGMENTS > 32)
 	case 33 ... 64:
 		index = 3;
 		break;
-	case 65 ... SCSI_MAX_SG_SEGMENTS:
+#if (SCSI_MAX_SG_SEGMENTS > 64)
+	case 65 ... 128:
 		index = 4;
 		break;
+#endif
+#endif
+#endif
 	default:
 		printk(KERN_ERR "scsi: bad segment count=%d\n", nents);
 		BUG();

commit 9cb83c7529d929c00f37d821daed1942a1b20602
Author: FUJITA Tomonori <tomof@acm.org>
Date:   Tue Oct 16 11:24:32 2007 +0200

    [SCSI] add use_sg_chaining option to scsi_host_template
    
    This option is true if a low-level driver can support sg
    chaining. This will be removed eventually when all the drivers are
    converted to support sg chaining. q->max_phys_segments is set to
    SCSI_MAX_SG_SEGMENTS if false.
    
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c75cb6ad6d94..b6e6d801768b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1645,7 +1645,10 @@ struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
 	 * converted, so better keep it safe.
 	 */
 #ifdef ARCH_HAS_SG_CHAIN
-	blk_queue_max_phys_segments(q, SCSI_MAX_SG_CHAIN_SEGMENTS);
+	if (shost->use_sg_chaining)
+		blk_queue_max_phys_segments(q, SCSI_MAX_SG_CHAIN_SEGMENTS);
+	else
+		blk_queue_max_phys_segments(q, SCSI_MAX_SG_SEGMENTS);
 #else
 	blk_queue_max_phys_segments(q, SCSI_MAX_SG_SEGMENTS);
 #endif

commit a8474ce23a73185dd2bae4c884b1716474032d31
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Tue Aug 7 09:02:51 2007 +0200

    SCSI: support for allocating large scatterlists
    
    This is what enables large commands. If we need to allocate an
    sgtable that doesn't fit in a single page, allocate several
    SCSI_MAX_SG_SEGMENTS sized tables and chain them together.
    
    SCSI defaults to large chained sg tables, if the arch supports it.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 7e1dcc57f115..c75cb6ad6d94 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -36,33 +36,19 @@
 
 struct scsi_host_sg_pool {
 	size_t		size;
-	char		*name; 
+	char		*name;
 	struct kmem_cache	*slab;
 	mempool_t	*pool;
 };
 
-#if (SCSI_MAX_PHYS_SEGMENTS < 32)
-#error SCSI_MAX_PHYS_SEGMENTS is too small
-#endif
-
-#define SP(x) { x, "sgpool-" #x } 
+#define SP(x) { x, "sgpool-" #x }
 static struct scsi_host_sg_pool scsi_sg_pools[] = {
 	SP(8),
 	SP(16),
 	SP(32),
-#if (SCSI_MAX_PHYS_SEGMENTS > 32)
 	SP(64),
-#if (SCSI_MAX_PHYS_SEGMENTS > 64)
 	SP(128),
-#if (SCSI_MAX_PHYS_SEGMENTS > 128)
-	SP(256),
-#if (SCSI_MAX_PHYS_SEGMENTS > 256)
-#error SCSI_MAX_PHYS_SEGMENTS is too large
-#endif
-#endif
-#endif
-#endif
-}; 	
+};
 #undef SP
 
 static void scsi_run_queue(struct request_queue *q);
@@ -698,45 +684,126 @@ static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int uptodate,
 	return NULL;
 }
 
-struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
-{
-	struct scsi_host_sg_pool *sgp;
-	struct scatterlist *sgl;
+/*
+ * The maximum number of SG segments that we will put inside a scatterlist
+ * (unless chaining is used). Should ideally fit inside a single page, to
+ * avoid a higher order allocation.
+ */
+#define SCSI_MAX_SG_SEGMENTS	128
 
-	BUG_ON(!cmd->use_sg);
+/*
+ * Like SCSI_MAX_SG_SEGMENTS, but for archs that have sg chaining. This limit
+ * is totally arbitrary, a setting of 2048 will get you at least 8mb ios.
+ */
+#define SCSI_MAX_SG_CHAIN_SEGMENTS	2048
 
-	switch (cmd->use_sg) {
+static inline unsigned int scsi_sgtable_index(unsigned short nents)
+{
+	unsigned int index;
+
+	switch (nents) {
 	case 1 ... 8:
-		cmd->sglist_len = 0;
+		index = 0;
 		break;
 	case 9 ... 16:
-		cmd->sglist_len = 1;
+		index = 1;
 		break;
 	case 17 ... 32:
-		cmd->sglist_len = 2;
+		index = 2;
 		break;
-#if (SCSI_MAX_PHYS_SEGMENTS > 32)
 	case 33 ... 64:
-		cmd->sglist_len = 3;
+		index = 3;
 		break;
-#if (SCSI_MAX_PHYS_SEGMENTS > 64)
-	case 65 ... 128:
-		cmd->sglist_len = 4;
+	case 65 ... SCSI_MAX_SG_SEGMENTS:
+		index = 4;
 		break;
-#if (SCSI_MAX_PHYS_SEGMENTS  > 128)
-	case 129 ... 256:
-		cmd->sglist_len = 5;
-		break;
-#endif
-#endif
-#endif
 	default:
-		return NULL;
+		printk(KERN_ERR "scsi: bad segment count=%d\n", nents);
+		BUG();
 	}
 
-	sgp = scsi_sg_pools + cmd->sglist_len;
-	sgl = mempool_alloc(sgp->pool, gfp_mask);
-	return sgl;
+	return index;
+}
+
+struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
+{
+	struct scsi_host_sg_pool *sgp;
+	struct scatterlist *sgl, *prev, *ret;
+	unsigned int index;
+	int this, left;
+
+	BUG_ON(!cmd->use_sg);
+
+	left = cmd->use_sg;
+	ret = prev = NULL;
+	do {
+		this = left;
+		if (this > SCSI_MAX_SG_SEGMENTS) {
+			this = SCSI_MAX_SG_SEGMENTS - 1;
+			index = SG_MEMPOOL_NR - 1;
+		} else
+			index = scsi_sgtable_index(this);
+
+		left -= this;
+
+		sgp = scsi_sg_pools + index;
+
+		sgl = mempool_alloc(sgp->pool, gfp_mask);
+		if (unlikely(!sgl))
+			goto enomem;
+
+		memset(sgl, 0, sizeof(*sgl) * sgp->size);
+
+		/*
+		 * first loop through, set initial index and return value
+		 */
+		if (!ret) {
+			cmd->sglist_len = index;
+			ret = sgl;
+		}
+
+		/*
+		 * chain previous sglist, if any. we know the previous
+		 * sglist must be the biggest one, or we would not have
+		 * ended up doing another loop.
+		 */
+		if (prev)
+			sg_chain(prev, SCSI_MAX_SG_SEGMENTS, sgl);
+
+		/*
+		 * don't allow subsequent mempool allocs to sleep, it would
+		 * violate the mempool principle.
+		 */
+		gfp_mask &= ~__GFP_WAIT;
+		gfp_mask |= __GFP_HIGH;
+		prev = sgl;
+	} while (left);
+
+	/*
+	 * ->use_sg may get modified after dma mapping has potentially
+	 * shrunk the number of segments, so keep a copy of it for free.
+	 */
+	cmd->__use_sg = cmd->use_sg;
+	return ret;
+enomem:
+	if (ret) {
+		/*
+		 * Free entries chained off ret. Since we were trying to
+		 * allocate another sglist, we know that all entries are of
+		 * the max size.
+		 */
+		sgp = scsi_sg_pools + SG_MEMPOOL_NR - 1;
+		prev = ret;
+		ret = &ret[SCSI_MAX_SG_SEGMENTS - 1];
+
+		while ((sgl = sg_chain_ptr(ret)) != NULL) {
+			ret = &sgl[SCSI_MAX_SG_SEGMENTS - 1];
+			mempool_free(sgl, sgp->pool);
+		}
+
+		mempool_free(prev, sgp->pool);
+	}
+	return NULL;
 }
 
 EXPORT_SYMBOL(scsi_alloc_sgtable);
@@ -748,6 +815,42 @@ void scsi_free_sgtable(struct scsi_cmnd *cmd)
 
 	BUG_ON(cmd->sglist_len >= SG_MEMPOOL_NR);
 
+	/*
+	 * if this is the biggest size sglist, check if we have
+	 * chained parts we need to free
+	 */
+	if (cmd->__use_sg > SCSI_MAX_SG_SEGMENTS) {
+		unsigned short this, left;
+		struct scatterlist *next;
+		unsigned int index;
+
+		left = cmd->__use_sg - (SCSI_MAX_SG_SEGMENTS - 1);
+		next = sg_chain_ptr(&sgl[SCSI_MAX_SG_SEGMENTS - 1]);
+		while (left && next) {
+			sgl = next;
+			this = left;
+			if (this > SCSI_MAX_SG_SEGMENTS) {
+				this = SCSI_MAX_SG_SEGMENTS - 1;
+				index = SG_MEMPOOL_NR - 1;
+			} else
+				index = scsi_sgtable_index(this);
+
+			left -= this;
+
+			sgp = scsi_sg_pools + index;
+
+			if (left)
+				next = sg_chain_ptr(&sgl[sgp->size - 1]);
+
+			mempool_free(sgl, sgp->pool);
+		}
+
+		/*
+		 * Restore original, will be freed below
+		 */
+		sgl = cmd->request_buffer;
+	}
+
 	sgp = scsi_sg_pools + cmd->sglist_len;
 	mempool_free(sgl, sgp->pool);
 }
@@ -988,7 +1091,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 static int scsi_init_io(struct scsi_cmnd *cmd)
 {
 	struct request     *req = cmd->request;
-	struct scatterlist *sgpnt;
 	int		   count;
 
 	/*
@@ -1001,14 +1103,13 @@ static int scsi_init_io(struct scsi_cmnd *cmd)
 	/*
 	 * If sg table allocation fails, requeue request later.
 	 */
-	sgpnt = scsi_alloc_sgtable(cmd, GFP_ATOMIC);
-	if (unlikely(!sgpnt)) {
+	cmd->request_buffer = scsi_alloc_sgtable(cmd, GFP_ATOMIC);
+	if (unlikely(!cmd->request_buffer)) {
 		scsi_unprep_request(req);
 		return BLKPREP_DEFER;
 	}
 
 	req->buffer = NULL;
-	cmd->request_buffer = (char *) sgpnt;
 	if (blk_pc_request(req))
 		cmd->request_bufflen = req->data_len;
 	else
@@ -1533,8 +1634,22 @@ struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
 	if (!q)
 		return NULL;
 
+	/*
+	 * this limit is imposed by hardware restrictions
+	 */
 	blk_queue_max_hw_segments(q, shost->sg_tablesize);
-	blk_queue_max_phys_segments(q, SCSI_MAX_PHYS_SEGMENTS);
+
+	/*
+	 * In the future, sg chaining support will be mandatory and this
+	 * ifdef can then go away. Right now we don't have all archs
+	 * converted, so better keep it safe.
+	 */
+#ifdef ARCH_HAS_SG_CHAIN
+	blk_queue_max_phys_segments(q, SCSI_MAX_SG_CHAIN_SEGMENTS);
+#else
+	blk_queue_max_phys_segments(q, SCSI_MAX_SG_SEGMENTS);
+#endif
+
 	blk_queue_max_sectors(q, shost->max_sectors);
 	blk_queue_bounce_limit(q, scsi_calculate_bounce_limit(shost));
 	blk_queue_segment_boundary(q, shost->dma_boundary);

commit 0cde8d9510e242c73b2d68f9949cd3c456c863b4
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Tue Oct 16 11:12:37 2007 +0200

    scsi: simplify scsi_free_sgtable()
    
    Just pass in the command, no point in passing in the scatterlist
    and scatterlist pool index seperately.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 960f949b8f8f..7e1dcc57f115 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -741,13 +741,14 @@ struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 
 EXPORT_SYMBOL(scsi_alloc_sgtable);
 
-void scsi_free_sgtable(struct scatterlist *sgl, int index)
+void scsi_free_sgtable(struct scsi_cmnd *cmd)
 {
+	struct scatterlist *sgl = cmd->request_buffer;
 	struct scsi_host_sg_pool *sgp;
 
-	BUG_ON(index >= SG_MEMPOOL_NR);
+	BUG_ON(cmd->sglist_len >= SG_MEMPOOL_NR);
 
-	sgp = scsi_sg_pools + index;
+	sgp = scsi_sg_pools + cmd->sglist_len;
 	mempool_free(sgl, sgp->pool);
 }
 
@@ -773,7 +774,7 @@ EXPORT_SYMBOL(scsi_free_sgtable);
 static void scsi_release_buffers(struct scsi_cmnd *cmd)
 {
 	if (cmd->use_sg)
-		scsi_free_sgtable(cmd->request_buffer, cmd->sglist_len);
+		scsi_free_sgtable(cmd);
 
 	/*
 	 * Zero these out.  They now point to freed memory, and it is

commit c6132da1704be252ee6c923f47501083d835c238
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Tue Oct 16 11:08:49 2007 +0200

    scsi: convert to using sg helpers
    
    This converts the SCSI mid layer to using the sg helpers for looking up
    sg elements, instead of doing it manually.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 207f1aa08869..960f949b8f8f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -17,6 +17,7 @@
 #include <linux/pci.h>
 #include <linux/delay.h>
 #include <linux/hardirq.h>
+#include <linux/scatterlist.h>
 
 #include <scsi/scsi.h>
 #include <scsi/scsi_cmnd.h>
@@ -289,14 +290,16 @@ static int scsi_req_map_sg(struct request *rq, struct scatterlist *sgl,
 	struct request_queue *q = rq->q;
 	int nr_pages = (bufflen + sgl[0].offset + PAGE_SIZE - 1) >> PAGE_SHIFT;
 	unsigned int data_len = bufflen, len, bytes, off;
+	struct scatterlist *sg;
 	struct page *page;
 	struct bio *bio = NULL;
 	int i, err, nr_vecs = 0;
 
-	for (i = 0; i < nsegs; i++) {
-		page = sgl[i].page;
-		off = sgl[i].offset;
-		len = sgl[i].length;
+	for_each_sg(sgl, sg, nsegs, i) {
+		page = sg->page;
+		off = sg->offset;
+		len = sg->length;
+ 		data_len += len;
 
 		while (len > 0 && data_len > 0) {
 			/*
@@ -2193,18 +2196,19 @@ EXPORT_SYMBOL_GPL(scsi_target_unblock);
  *
  * Returns virtual address of the start of the mapped page
  */
-void *scsi_kmap_atomic_sg(struct scatterlist *sg, int sg_count,
+void *scsi_kmap_atomic_sg(struct scatterlist *sgl, int sg_count,
 			  size_t *offset, size_t *len)
 {
 	int i;
 	size_t sg_len = 0, len_complete = 0;
+	struct scatterlist *sg;
 	struct page *page;
 
 	WARN_ON(!irqs_disabled());
 
-	for (i = 0; i < sg_count; i++) {
+	for_each_sg(sgl, sg, sg_count, i) {
 		len_complete = sg_len; /* Complete sg-entries */
-		sg_len += sg[i].length;
+		sg_len += sg->length;
 		if (sg_len > *offset)
 			break;
 	}
@@ -2218,10 +2222,10 @@ void *scsi_kmap_atomic_sg(struct scatterlist *sg, int sg_count,
 	}
 
 	/* Offset starting from the beginning of first page in this sg-entry */
-	*offset = *offset - len_complete + sg[i].offset;
+	*offset = *offset - len_complete + sg->offset;
 
 	/* Assumption: contiguous pages can be accessed as "page + i" */
-	page = nth_page(sg[i].page, (*offset >> PAGE_SHIFT));
+	page = nth_page(sg->page, (*offset >> PAGE_SHIFT));
 	*offset &= ~PAGE_MASK;
 
 	/* Bytes in this sg-entry from *offset to the end of the page */

commit df3d80f5a5c74168be42788364d13cf6c83c7b9c
Merge: 3d06f7a5f74a c8e91b0a8fc8
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Mon Oct 15 08:19:33 2007 -0700

    Merge master.kernel.org:/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6
    
    * master.kernel.org:/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6: (207 commits)
      [SCSI] gdth: fix CONFIG_ISA build failure
      [SCSI] esp_scsi: remove __dev{init,exit}
      [SCSI] gdth: !use_sg cleanup and use of scsi accessors
      [SCSI] gdth: Move members from SCp to gdth_cmndinfo, stage 2
      [SCSI] gdth: Setup proper per-command private data
      [SCSI] gdth: Remove gdth_ctr_tab[]
      [SCSI] gdth: switch to modern scsi host registration
      [SCSI] gdth: gdth_interrupt() gdth_get_status() & gdth_wait() fixes
      [SCSI] gdth: clean up host private data
      [SCSI] gdth: Remove virt hosts
      [SCSI] gdth: Reorder scsi_host_template intitializers
      [SCSI] gdth: kill gdth_{read,write}[bwl] wrappers
      [SCSI] gdth: Remove 2.4.x support, in-kernel changelog
      [SCSI] gdth: split out pci probing
      [SCSI] gdth: split out eisa probing
      [SCSI] gdth: split out isa probing
      gdth: Make one abuse of scsi_cmnd less obvious
      [SCSI] NCR5380: Use scsi_eh API for REQUEST_SENSE invocation
      [SCSI] usb storage: use scsi_eh API in REQUEST_SENSE execution
      [SCSI] scsi_error: Refactoring scsi_error to facilitate in synchronous REQUEST_SENSE
      ...

commit 6f5391c283d7fdcf24bf40786ea79061919d1e1d
Author: Matthew Wilcox <matthew@wil.cx>
Date:   Tue Sep 25 12:42:04 2007 -0400

    [SCSI] Get rid of scsi_cmnd->done
    
    The ULD ->done callback moves into the scsi_driver.  By moving the call
    to scsi_io_completion() from scsi_blk_pc_done() to scsi_finish_command(),
    we can eliminate the latter entirely.  By returning 'good_bytes' from
    the ->done callback (rather than invoking scsi_io_completion()), we can
    stop exporting scsi_io_completion().
    
    Also move the prototypes from sd.h to sd.c as they're all internal anyway.
    Rename sd_rw_intr to sd_done and rw_intr to sr_done.
    
    Inspired-by: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 86fd3abe731a..fac34293bef7 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -982,7 +982,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	}
 	scsi_end_request(cmd, 0, this_count, !result);
 }
-EXPORT_SYMBOL(scsi_io_completion);
 
 /*
  * Function:    scsi_init_io()
@@ -1063,18 +1062,6 @@ static struct scsi_cmnd *scsi_get_cmd_from_req(struct scsi_device *sdev,
 	return cmd;
 }
 
-static void scsi_blk_pc_done(struct scsi_cmnd *cmd)
-{
-	BUG_ON(!blk_pc_request(cmd->request));
-	/*
-	 * This will complete the whole command with uptodate=1 so
-	 * as far as the block layer is concerned the command completed
-	 * successfully. Since this is a REQ_BLOCK_PC command the
-	 * caller should check the request's errors value
-	 */
-	scsi_io_completion(cmd, cmd->request_bufflen);
-}
-
 int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 {
 	struct scsi_cmnd *cmd;
@@ -1124,7 +1111,6 @@ int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 	cmd->transfersize = req->data_len;
 	cmd->allowed = req->retries;
 	cmd->timeout_per_command = req->timeout;
-	cmd->done = scsi_blk_pc_done;
 	return BLKPREP_OK;
 }
 EXPORT_SYMBOL(scsi_setup_blk_pc_cmnd);

commit 311b581e1d87be87f78e6e17fc50f468f2dec561
Author: James Bottomley <James.Bottomley@steeleye.com>
Date:   Sun Sep 23 09:08:46 2007 -0500

    [SCSI] Fix device not ready printk
    
    Because scsi_print_sense_hdr prefixes with KERN_INFO, the output from
    scsi_io_completion looks like:
    
    sd 0:0:0:0: [sdb] Device not ready: <6>: Sense Key : 0x2 [current]
    : ASC=0x4 ASCQ=0x3
    
    By using scsi_show_sense_hdr, we can get the much more appealing output:
    
    sd 0:0:0:0: [sdb] Device not ready: Sense Key : 0x2 [current]
    sd 0:0:0:0: [sdb] Device not ready: ASC=0x4 ASCQ=0x3
    
    Acked-by: Matthew Wilcox <willy@linux.intel.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 94d82cb96626..86fd3abe731a 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -944,11 +944,11 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 					break;
 				}
 			}
-			if (!(req->cmd_flags & REQ_QUIET)) {
-				scmd_printk(KERN_INFO, cmd,
-					    "Device not ready: ");
-				scsi_print_sense_hdr("", &sshdr);
-			}
+			if (!(req->cmd_flags & REQ_QUIET))
+				scsi_cmd_print_sense_hdr(cmd,
+							 "Device not ready",
+							 &sshdr);
+
 			scsi_end_request(cmd, 0, this_count, 1);
 			return;
 		case VOLUME_OVERFLOW:

commit 7f9a6bc4e9d59e7fcf03ed23f60cd81ca5d80b65
Author: James Bottomley <James.Bottomley@steeleye.com>
Date:   Sat Aug 4 10:06:25 2007 -0500

    [SCSI] move ULD attachment into the prep function
    
    One of the intents of the block prep function was to allow ULDs to use
    it for preprocessing.  The original SCSI model was to have a single prep
    function and add a pointer indirect filter to build the necessary
    commands.  This patch reverses that, does away with the init_command
    field of the scsi_driver structure and makes ULDs attach directly to the
    prep function instead.  The value is really that it allows us to begin
    to separate the ULDs from the SCSI mid layer (as long as they don't use
    any core functions---which is hard at the moment---a ULD doesn't even
    need SCSI to bind).
    
    Acked-by: Jens Axboe <jens.axboe@oracle.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 47d3cdd6ddf1..94d82cb96626 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1039,9 +1039,6 @@ static int scsi_init_io(struct scsi_cmnd *cmd)
 	printk(KERN_ERR "req nr_sec %lu, cur_nr_sec %u\n", req->nr_sectors,
 			req->current_nr_sectors);
 
-	/* release the command and kill it */
-	scsi_release_buffers(cmd);
-	scsi_put_command(cmd);
 	return BLKPREP_KILL;
 }
 
@@ -1078,9 +1075,13 @@ static void scsi_blk_pc_done(struct scsi_cmnd *cmd)
 	scsi_io_completion(cmd, cmd->request_bufflen);
 }
 
-static int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
+int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 {
 	struct scsi_cmnd *cmd;
+	int ret = scsi_prep_state_check(sdev, req);
+
+	if (ret != BLKPREP_OK)
+		return ret;
 
 	cmd = scsi_get_cmd_from_req(sdev, req);
 	if (unlikely(!cmd))
@@ -1126,18 +1127,20 @@ static int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 	cmd->done = scsi_blk_pc_done;
 	return BLKPREP_OK;
 }
+EXPORT_SYMBOL(scsi_setup_blk_pc_cmnd);
 
 /*
  * Setup a REQ_TYPE_FS command.  These are simple read/write request
  * from filesystems that still need to be translated to SCSI CDBs from
  * the ULD.
  */
-static int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
+int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
 {
 	struct scsi_cmnd *cmd;
-	struct scsi_driver *drv;
-	int ret;
+	int ret = scsi_prep_state_check(sdev, req);
 
+	if (ret != BLKPREP_OK)
+		return ret;
 	/*
 	 * Filesystem requests must transfer data.
 	 */
@@ -1147,26 +1150,12 @@ static int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
 	if (unlikely(!cmd))
 		return BLKPREP_DEFER;
 
-	ret = scsi_init_io(cmd);
-	if (unlikely(ret))
-		return ret;
-
-	/*
-	 * Initialize the actual SCSI command for this request.
-	 */
-	drv = *(struct scsi_driver **)req->rq_disk->private_data;
-	if (unlikely(!drv->init_command(cmd))) {
-		scsi_release_buffers(cmd);
-		scsi_put_command(cmd);
-		return BLKPREP_KILL;
-	}
-
-	return BLKPREP_OK;
+	return scsi_init_io(cmd);
 }
+EXPORT_SYMBOL(scsi_setup_fs_cmnd);
 
-static int scsi_prep_fn(struct request_queue *q, struct request *req)
+int scsi_prep_state_check(struct scsi_device *sdev, struct request *req)
 {
-	struct scsi_device *sdev = q->queuedata;
 	int ret = BLKPREP_OK;
 
 	/*
@@ -1212,35 +1201,25 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 				ret = BLKPREP_KILL;
 			break;
 		}
-
-		if (ret != BLKPREP_OK)
-			goto out;
 	}
+	return ret;
+}
+EXPORT_SYMBOL(scsi_prep_state_check);
 
-	switch (req->cmd_type) {
-	case REQ_TYPE_BLOCK_PC:
-		ret = scsi_setup_blk_pc_cmnd(sdev, req);
-		break;
-	case REQ_TYPE_FS:
-		ret = scsi_setup_fs_cmnd(sdev, req);
-		break;
-	default:
-		/*
-		 * All other command types are not supported.
-		 *
-		 * Note that these days the SCSI subsystem does not use
-		 * REQ_TYPE_SPECIAL requests anymore.  These are only used
-		 * (directly or via blk_insert_request) by non-SCSI drivers.
-		 */
-		blk_dump_rq_flags(req, "SCSI bad req");
-		ret = BLKPREP_KILL;
-		break;
-	}
+int scsi_prep_return(struct request_queue *q, struct request *req, int ret)
+{
+	struct scsi_device *sdev = q->queuedata;
 
- out:
 	switch (ret) {
 	case BLKPREP_KILL:
 		req->errors = DID_NO_CONNECT << 16;
+		/* release the command and kill it */
+		if (req->special) {
+			struct scsi_cmnd *cmd = req->special;
+			scsi_release_buffers(cmd);
+			scsi_put_command(cmd);
+			req->special = NULL;
+		}
 		break;
 	case BLKPREP_DEFER:
 		/*
@@ -1257,6 +1236,17 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 
 	return ret;
 }
+EXPORT_SYMBOL(scsi_prep_return);
+
+static int scsi_prep_fn(struct request_queue *q, struct request *req)
+{
+	struct scsi_device *sdev = q->queuedata;
+	int ret = BLKPREP_KILL;
+
+	if (req->cmd_type == REQ_TYPE_BLOCK_PC)
+		ret = scsi_setup_blk_pc_cmnd(sdev, req);
+	return scsi_prep_return(q, req, ret);
+}
 
 /*
  * scsi_dev_queue_ready: if we can send requests to sdev, return 1 else

commit 52aeeca9001d1b4037a8e5d0c001ebb5fdc61b37
Author: Michael Reed <mdr@sgi.com>
Date:   Mon Sep 17 15:11:39 2007 -0700

    [SCSI] stale residual returned on write following BUSY retry
    
    A BUSY status returned on a write request results in a stale residual
    being returned when the write ultimately successfully completes.
    
    This can be reproduced as follows:
    
    1) issue immediate mode rewind to scsi tape drive
    2) issue write request
    
    The tape drive returns busy.  The low level driver detects underrun and
    sets the residual into the scsi command.  The low level driver responds
    with (DID_OK << 16) | scsi_status.  scsi_status is 8, hence
    status_byte(result) == 4, i.e., BUSY.
    
    scsi_softirq_done() calls scsi_decide_disposition() which returns
    ADD_TO_MLQUEUE.  scsi_softirq_done() then calls scsi_queue_insert()
    which, on the way to resubmitting the request to the driver, calls
    scsi_init_cmd_errh().
    
    The attached patch modifies scsi_init_cmd_errh() to clear the resid
    field.  This prevents a "stale" residual from being returned when the
    scsi command finally completes without a BUSY status.
    
    Signed-off-by: Michael Reed <mdr@sgi.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 277f1b64e9ac..47d3cdd6ddf1 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -449,6 +449,7 @@ EXPORT_SYMBOL_GPL(scsi_execute_async);
 static void scsi_init_cmd_errh(struct scsi_cmnd *cmd)
 {
 	cmd->serial_number = 0;
+	cmd->resid = 0;
 	memset(cmd->sense_buffer, 0, sizeof cmd->sense_buffer);
 	if (cmd->cmd_len == 0)
 		cmd->cmd_len = COMMAND_SIZE(cmd->cmnd[0]);

commit bd441deaf341c524b28fd72831ebf6fef88f1c41
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Tue Mar 13 12:52:29 2007 -0500

    [SCSI] fix write buffer length in scsi_req_map_sg()
    
    sg's may have setup a the buffer with a different length than
    the transfer length so we should be using the bufflen passed
    in as the request's data len.
    
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a417a6ff9f97..277f1b64e9ac 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -301,7 +301,7 @@ static int scsi_req_map_sg(struct request *rq, struct scatterlist *sgl,
 {
 	struct request_queue *q = rq->q;
 	int nr_pages = (bufflen + sgl[0].offset + PAGE_SIZE - 1) >> PAGE_SHIFT;
-	unsigned int data_len = 0, len, bytes, off;
+	unsigned int data_len = bufflen, len, bytes, off;
 	struct page *page;
 	struct bio *bio = NULL;
 	int i, err, nr_vecs = 0;
@@ -310,10 +310,15 @@ static int scsi_req_map_sg(struct request *rq, struct scatterlist *sgl,
 		page = sgl[i].page;
 		off = sgl[i].offset;
 		len = sgl[i].length;
-		data_len += len;
 
-		while (len > 0) {
+		while (len > 0 && data_len > 0) {
+			/*
+			 * sg sends a scatterlist that is larger than
+			 * the data_len it wants transferred for certain
+			 * IO sizes
+			 */
 			bytes = min_t(unsigned int, len, PAGE_SIZE - off);
+			bytes = min(bytes, data_len);
 
 			if (!bio) {
 				nr_vecs = min_t(int, BIO_MAX_PAGES, nr_pages);
@@ -345,12 +350,13 @@ static int scsi_req_map_sg(struct request *rq, struct scatterlist *sgl,
 
 			page++;
 			len -= bytes;
+			data_len -=bytes;
 			off = 0;
 		}
 	}
 
 	rq->buffer = rq->data = NULL;
-	rq->data_len = data_len;
+	rq->data_len = bufflen;
 	return 0;
 
 free_bios:

commit 6712ecf8f648118c3363c142196418f89a510b90
Author: NeilBrown <neilb@suse.de>
Date:   Thu Sep 27 12:47:43 2007 +0200

    Drop 'size' argument from bio_endio and bi_end_io
    
    As bi_end_io is only called once when the reqeust is complete,
    the 'size' argument is now redundant.  Remove it.
    
    Now there is no need for bio_endio to subtract the size completed
    from bi_size.  So don't do that either.
    
    While we are at it, change bi_end_io to return void.
    
    Signed-off-by: Neil Brown <neilb@suse.de>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 59b398530295..604f4d717933 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -266,13 +266,9 @@ static int scsi_merge_bio(struct request *rq, struct bio *bio)
 	return blk_rq_append_bio(q, rq, bio);
 }
 
-static int scsi_bi_endio(struct bio *bio, unsigned int bytes_done, int error)
+static void scsi_bi_endio(struct bio *bio, int error)
 {
-	if (bio->bi_size)
-		return 1;
-
 	bio_put(bio);
-	return 0;
 }
 
 /**
@@ -328,7 +324,7 @@ static int scsi_req_map_sg(struct request *rq, struct scatterlist *sgl,
 			if (bio->bi_vcnt >= nr_vecs) {
 				err = scsi_merge_bio(rq, bio);
 				if (err) {
-					bio_endio(bio, bio->bi_size, 0);
+					bio_endio(bio, 0);
 					goto free_bios;
 				}
 				bio = NULL;
@@ -350,7 +346,7 @@ static int scsi_req_map_sg(struct request *rq, struct scatterlist *sgl,
 		/*
 		 * call endio instead of bio_put incase it was bounced
 		 */
-		bio_endio(bio, bio->bi_size, 0);
+		bio_endio(bio, 0);
 	}
 
 	return err;

commit 3001ca77128273cc5634d79f5306ce2e5a14ec41
Author: NeilBrown <neilb@suse.de>
Date:   Thu Aug 16 13:31:27 2007 +0200

    New function blk_req_append_bio
    
    ll_back_merge_fn is currently exported to SCSI where is it used,
    together with blk_rq_bio_prep, in exactly the same way these
    functions are used in __blk_rq_map_user.
    
    So move the common code into a new function (blk_rq_append_bio), and
    don't export ll_back_merge_fn any longer.
    
    Signed-off-by: Neil Brown <neilb@suse.de>
    
    diff .prev/block/ll_rw_blk.c ./block/ll_rw_blk.c
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a417a6ff9f97..59b398530295 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -263,16 +263,7 @@ static int scsi_merge_bio(struct request *rq, struct bio *bio)
 		bio->bi_rw |= (1 << BIO_RW);
 	blk_queue_bounce(q, &bio);
 
-	if (!rq->bio)
-		blk_rq_bio_prep(q, rq, bio);
-	else if (!ll_back_merge_fn(q, rq, bio))
-		return -EINVAL;
-	else {
-		rq->biotail->bi_next = bio;
-		rq->biotail = bio;
-	}
-
-	return 0;
+	return blk_rq_append_bio(q, rq, bio);
 }
 
 static int scsi_bi_endio(struct bio *bio, unsigned int bytes_done, int error)

commit 03a5743a12b58e10eaa936a02498539db645ba4e
Author: James Bottomley <James.Bottomley@steeleye.com>
Date:   Fri Aug 3 16:41:11 2007 -0500

    [SCSI] sd: disentangle barriers in SCSI
    
    Our current implementation has a generic set of barrier functions that
    go through the SCSI driver model.  Realistically, this is unnecessary,
    because the only device that can use barriers (sd) can set the flush
    functions up at probe or revalidate time.  This patch pulls the barrier
    functions out of the mid layer and scsi driver model and relocates them
    directly in sd.
    
    Acked-by: Tejun Heo <htejun@gmail.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 21c075d44db1..a417a6ff9f97 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1038,22 +1038,6 @@ static int scsi_init_io(struct scsi_cmnd *cmd)
 	return BLKPREP_KILL;
 }
 
-static int scsi_issue_flush_fn(struct request_queue *q, struct gendisk *disk,
-			       sector_t *error_sector)
-{
-	struct scsi_device *sdev = q->queuedata;
-	struct scsi_driver *drv;
-
-	if (sdev->sdev_state != SDEV_RUNNING)
-		return -ENXIO;
-
-	drv = *(struct scsi_driver **) disk->private_data;
-	if (drv->issue_flush)
-		return drv->issue_flush(&sdev->sdev_gendev, error_sector);
-
-	return -EOPNOTSUPP;
-}
-
 static struct scsi_cmnd *scsi_get_cmd_from_req(struct scsi_device *sdev,
 		struct request *req)
 {
@@ -1596,7 +1580,6 @@ struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
 		return NULL;
 
 	blk_queue_prep_rq(q, scsi_prep_fn);
-	blk_queue_issue_flush_fn(q, scsi_issue_flush_fn);
 	blk_queue_softirq_done(q, scsi_softirq_done);
 	return q;
 }

commit 165125e1e480f9510a5ffcfbfee4e3ee38c05f23
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Tue Jul 24 09:28:11 2007 +0200

    [BLOCK] Get rid of request_queue_t typedef
    
    Some of the code has been gradually transitioned to using the proper
    struct request_queue, but there's lots left. So do a full sweet of
    the kernel and get rid of this typedef and replace its uses with
    the proper type.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index da63c544919b..21c075d44db1 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -654,7 +654,7 @@ void scsi_run_host_queues(struct Scsi_Host *shost)
 static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int uptodate,
 					  int bytes, int requeue)
 {
-	request_queue_t *q = cmd->device->request_queue;
+	struct request_queue *q = cmd->device->request_queue;
 	struct request *req = cmd->request;
 	unsigned long flags;
 
@@ -818,7 +818,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 {
 	int result = cmd->result;
 	int this_count = cmd->request_bufflen;
-	request_queue_t *q = cmd->device->request_queue;
+	struct request_queue *q = cmd->device->request_queue;
 	struct request *req = cmd->request;
 	int clear_errors = 1;
 	struct scsi_sense_hdr sshdr;
@@ -1038,7 +1038,7 @@ static int scsi_init_io(struct scsi_cmnd *cmd)
 	return BLKPREP_KILL;
 }
 
-static int scsi_issue_flush_fn(request_queue_t *q, struct gendisk *disk,
+static int scsi_issue_flush_fn(struct request_queue *q, struct gendisk *disk,
 			       sector_t *error_sector)
 {
 	struct scsi_device *sdev = q->queuedata;
@@ -1340,7 +1340,7 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 /*
  * Kill a request for a dead device
  */
-static void scsi_kill_request(struct request *req, request_queue_t *q)
+static void scsi_kill_request(struct request *req, struct request_queue *q)
 {
 	struct scsi_cmnd *cmd = req->special;
 	struct scsi_device *sdev = cmd->device;
@@ -2119,7 +2119,7 @@ EXPORT_SYMBOL(scsi_target_resume);
 int
 scsi_internal_device_block(struct scsi_device *sdev)
 {
-	request_queue_t *q = sdev->request_queue;
+	struct request_queue *q = sdev->request_queue;
 	unsigned long flags;
 	int err = 0;
 
@@ -2159,7 +2159,7 @@ EXPORT_SYMBOL_GPL(scsi_internal_device_block);
 int
 scsi_internal_device_unblock(struct scsi_device *sdev)
 {
-	request_queue_t *q = sdev->request_queue; 
+	struct request_queue *q = sdev->request_queue; 
 	int err;
 	unsigned long flags;
 	

commit 20c2df83d25c6a95affe6157a4c9cac4cf5ffaac
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Fri Jul 20 10:11:58 2007 +0900

    mm: Remove slab destructors from kmem_cache_create().
    
    Slab destructors were no longer supported after Christoph's
    c59def9f222d44bb7e2f0a559f2906191a0862d7 change. They've been
    BUGs for both slab and slub, and slob never supported them
    either.
    
    This rips out support for the dtor pointer from kmem_cache_create()
    completely and fixes up every single callsite in the kernel (there were
    about 224, not including the slab allocator definitions themselves,
    or the documentation references).
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1f5a07bf2a75..da63c544919b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1661,7 +1661,7 @@ int __init scsi_init_queue(void)
 
 	scsi_io_context_cache = kmem_cache_create("scsi_io_context",
 					sizeof(struct scsi_io_context),
-					0, 0, NULL, NULL);
+					0, 0, NULL);
 	if (!scsi_io_context_cache) {
 		printk(KERN_ERR "SCSI: can't init scsi io context cache\n");
 		return -ENOMEM;
@@ -1672,7 +1672,7 @@ int __init scsi_init_queue(void)
 		int size = sgp->size * sizeof(struct scatterlist);
 
 		sgp->slab = kmem_cache_create(sgp->name, size, 0,
-				SLAB_HWCACHE_ALIGN, NULL, NULL);
+				SLAB_HWCACHE_ALIGN, NULL);
 		if (!sgp->slab) {
 			printk(KERN_ERR "SCSI: can't init sg slab %s\n",
 					sgp->name);

commit 59c51591a0ac7568824f541f57de967e88adaa07
Author: Michael Opdenacker <michael@free-electrons.com>
Date:   Wed May 9 08:57:56 2007 +0200

    Fix occurrences of "the the "
    
    Signed-off-by: Michael Opdenacker <michael@free-electrons.com>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 61fbcdcbb009..1f5a07bf2a75 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -173,7 +173,7 @@ int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
  * @retries:	number of times to retry request
  * @flags:	or into request flags;
  *
- * returns the req->errors value which is the the scsi_cmnd result
+ * returns the req->errors value which is the scsi_cmnd result
  * field.
  **/
 int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,

commit 4f7a307dc6e4d8bfeb56f7cf7231b08cb845687c
Merge: fabb5c4e4a47 729782458175
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Sat May 5 13:30:44 2007 -0700

    Merge master.kernel.org:/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6
    
    * master.kernel.org:/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6: (87 commits)
      [SCSI] fusion: fix domain validation loops
      [SCSI] qla2xxx: fix regression on sparc64
      [SCSI] modalias for scsi devices
      [SCSI] sg: cap reserved_size values at max_sectors
      [SCSI] BusLogic: stop using check_region
      [SCSI] tgt: fix rdma transfer bugs
      [SCSI] aacraid: fix aacraid not finding device
      [SCSI] aacraid: Correct SMC products in aacraid.txt
      [SCSI] scsi_error.c: Add EH Start Unit retry
      [SCSI] aacraid: [Fastboot] Panics for AACRAID driver during 'insmod' for kexec test.
      [SCSI] ipr: Driver version to 2.3.2
      [SCSI] ipr: Faster sg list fetch
      [SCSI] ipr: Return better qc_issue errors
      [SCSI] ipr: Disrupt device error
      [SCSI] ipr: Improve async error logging level control
      [SCSI] ipr: PCI unblock config access fix
      [SCSI] ipr: Fix for oops following SATA request sense
      [SCSI] ipr: Log error for SAS dual path switch
      [SCSI] ipr: Enable logging of debug error data for all devices
      [SCSI] ipr: Add new PCI-E IDs to device table
      ...

commit 5972511b77809cb7c9ccdb79b825c54921c5c546
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Mon Apr 2 10:06:42 2007 +0200

    [BLOCK] Don't pin lots of memory in mempools
    
    Currently we scale the mempool sizes depending on memory installed
    in the machine, except for the bio pool itself which sits at a fixed
    256 entry pre-allocation.
    
    There's really no point in "optimizing" this OOM path, we just need
    enough preallocated to make progress. A single unit is enough, lets
    scale it down to 2 just to be on the safe side.
    
    This patch saves ~150kb of pinned kernel memory on a 32-bit box.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9f7482d0b594..05d79af5ab90 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -31,7 +31,7 @@
 
 
 #define SG_MEMPOOL_NR		ARRAY_SIZE(scsi_sg_pools)
-#define SG_MEMPOOL_SIZE		32
+#define SG_MEMPOOL_SIZE		2
 
 struct scsi_host_sg_pool {
 	size_t		size;

commit b22f687dd28a7a8886b918294b4d558ef175c07d
Author: Pete Wyckoff <pw@osc.edu>
Date:   Tue Mar 13 16:53:28 2007 -0400

    [SCSI] set resid in scsi_io_completion() even for check condition
    
    Some targets can return both valid data and sense information.
    Always update the request data_len from the SCSI command residual.
    Callers should interpret sense data to determine what parts of the
    data are valid in case of a CHECK CONDITION status.
    
    Signed-off-by: Pete Wyckoff <pw@osc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 5f955707d902..be8e6558b89e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -848,8 +848,8 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 				memcpy(req->sense, cmd->sense_buffer,  len);
 				req->sense_len = len;
 			}
-		} else
-			req->data_len = cmd->resid;
+		}
+		req->data_len = cmd->resid;
 	}
 
 	/*

commit a4d04a4cd9881e89fdc62107b6b57053438f2b30
Author: Martin K. Petersen <martin.petersen@oracle.com>
Date:   Tue Feb 27 22:40:27 2007 -0500

    [SCSI] Make error printing more verbose
    
    This patch enhances SCSI error printing by:
    
     - Making use of scsi_print_result() in the completion functions.
    
     - Having scmd_printk() output the disk name (when applicable).
    
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9f7482d0b594..5f955707d902 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -968,9 +968,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	}
 	if (result) {
 		if (!(req->cmd_flags & REQ_QUIET)) {
-			scmd_printk(KERN_INFO, cmd,
-				    "SCSI error: return code = 0x%08x\n",
-				    result);
+			scsi_print_result(cmd);
 			if (driver_byte(result) & DRIVER_SENSE)
 				scsi_print_sense("", cmd);
 		}

commit 5f0b1437e0708772b6fecae5900c01c3b5f9b512
Merge: 574009c1a895 81b7bbd1932a
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Sun Feb 11 11:44:25 2007 -0800

    Merge master.kernel.org:/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6
    
    * master.kernel.org:/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6: (97 commits)
      [SCSI] zfcp: removed wrong comment
      [SCSI] zfcp: use of uninitialized variable
      [SCSI] zfcp: Invalid locking order
      [SCSI] aic79xx: use dma_get_required_mask()
      [SCSI] aic79xx: fix bracket mismatch in unused macro
      [SCSI] BusLogic: Replace 'boolean' by 'bool'
      [SCSI] advansys: clean up warnings
      [SCSI] 53c7xx: brackets fix in uncompiled code
      [SCSI] nsp_cs: remove old scsi code
      [SCSI] aic79xx: make ahd_match_scb() static
      [SCSI] DAC960: kmalloc->kzalloc/Casting cleanups
      [SCSI] scsi_kmap_atomic_sg(): check that local irqs are disabled
      [SCSI] Buslogic: local_irq_disable() is redundant after local_irq_save()
      [SCSI] aic94xx: update for v28 firmware
      [SCSI] scsi_error: Fix lost EH commands
      [SCSI] aic94xx: Add default bus reset handler
      [SCSI] aic94xx: Remove TMF result code munging
      [SCSI] libsas: Add an LU reset mechanism to the error handler
      [SCSI] libsas: Don't BUG when connecting two expanders via wide port
      [SCSI] st: fix Tape dies if wrong block size used, bug 7919
      ...

commit c376222960ae91d5ffb9197ee36771aaed1d9f90
Author: Robert P. J. Day <rpjday@mindspring.com>
Date:   Sat Feb 10 01:45:03 2007 -0800

    [PATCH] Transform kmem_cache_alloc()+memset(0) -> kmem_cache_zalloc().
    
    Replace appropriate pairs of "kmem_cache_alloc()" + "memset(0)" with the
    corresponding "kmem_cache_zalloc()" call.
    
    Signed-off-by: Robert P. J. Day <rpjday@mindspring.com>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Andi Kleen <ak@muc.de>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: James Bottomley <James.Bottomley@steeleye.com>
    Cc: Greg KH <greg@kroah.com>
    Acked-by: Joel Becker <Joel.Becker@oracle.com>
    Cc: Steven Whitehouse <swhiteho@redhat.com>
    Cc: Jan Kara <jack@ucw.cz>
    Cc: Michael Halcrow <mhalcrow@us.ibm.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Cc: James Morris <jmorris@namei.org>
    Cc: Chris Wright <chrisw@sous-sol.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f02f48a882a9..a1cd6e6a292a 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -388,10 +388,9 @@ int scsi_execute_async(struct scsi_device *sdev, const unsigned char *cmd,
 	int err = 0;
 	int write = (data_direction == DMA_TO_DEVICE);
 
-	sioc = kmem_cache_alloc(scsi_io_context_cache, gfp);
+	sioc = kmem_cache_zalloc(scsi_io_context_cache, gfp);
 	if (!sioc)
 		return DRIVER_ERROR << 24;
-	memset(sioc, 0, sizeof(*sioc));
 
 	req = blk_get_request(sdev->request_queue, write, gfp);
 	if (!req)

commit 22cfefb56b53103a99908ec63311e61c217eaffe
Author: Andrew Morton <akpm@osdl.org>
Date:   Mon Feb 5 16:39:03 2007 -0800

    [SCSI] scsi_kmap_atomic_sg(): check that local irqs are disabled
    
    The KM_BIO_SRC_IRQ kmap slot must be taken with local irqs disabled.  Add a
    check into scsi for this.
    
    Cc: James Bottomley <James.Bottomley@steeleye.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 503f09c2f05f..0f9b6c275417 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2250,6 +2250,8 @@ void *scsi_kmap_atomic_sg(struct scatterlist *sg, int sg_count,
 	size_t sg_len = 0, len_complete = 0;
 	struct page *page;
 
+	WARN_ON(!irqs_disabled());
+
 	for (i = 0; i < sg_count; i++) {
 		len_complete = sg_len; /* Complete sg-entries */
 		sg_len += sg[i].length;

commit 596f482a90ae27ea1b3da6a12ee42909045fbfd0
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Jan 2 12:56:00 2007 +0100

    [SCSI] kill scsi_rety_command
    
    scsi_retry_command only has a single caller, so there is no point
    in having this function.  Additionally the memset of the sense
    buffer it does is entirely superflous as scsi_request_fn already
    calls scsi_init_cmd_errh to perform this memset before the command
    is reissued.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f02f48a882a9..503f09c2f05f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1400,7 +1400,7 @@ static void scsi_softirq_done(struct request *rq)
 			scsi_finish_command(cmd);
 			break;
 		case NEEDS_RETRY:
-			scsi_retry_command(cmd);
+			scsi_queue_insert(cmd, SCSI_MLQUEUE_EH_RETRY);
 			break;
 		case ADD_TO_MLQUEUE:
 			scsi_queue_insert(cmd, SCSI_MLQUEUE_DEVICE_BUSY);

commit 1aa4f24fe96938cabe7a1e9da8bc3bfbd1dfe3fa
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Tue Dec 19 08:33:11 2006 +0100

    [PATCH] Remove queue merging hooks
    
    We have full flexibility of merging parameters now, so we can remove the
    hooks that define back/front/request merge strategies. Nobody is using
    them anymore.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 41a2ea32a300..f02f48a882a9 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -265,7 +265,7 @@ static int scsi_merge_bio(struct request *rq, struct bio *bio)
 
 	if (!rq->bio)
 		blk_rq_bio_prep(q, rq, bio);
-	else if (!q->back_merge_fn(q, rq, bio))
+	else if (!ll_back_merge_fn(q, rq, bio))
 		return -EINVAL;
 	else {
 		rq->biotail->bi_next = bio;

commit 2985259b0e3928d4cd0723ac5aad0d1190ab7717
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Tue Dec 19 08:27:31 2006 +0100

    [PATCH] ->nr_sectors and ->hard_nr_sectors are not used for BLOCK_PC requests
    
    It's a file system thing, for block requests the only size used in the
    io paths is ->data_len as it is in bytes, not sectors.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1748e27501cd..41a2ea32a300 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -270,8 +270,6 @@ static int scsi_merge_bio(struct request *rq, struct bio *bio)
 	else {
 		rq->biotail->bi_next = bio;
 		rq->biotail = bio;
-		rq->hard_nr_sectors += bio_sectors(bio);
-		rq->nr_sectors = rq->hard_nr_sectors;
 	}
 
 	return 0;

commit e18b890bb0881bbab6f4f1a6cd20d9c60d66b003
Author: Christoph Lameter <clameter@sgi.com>
Date:   Wed Dec 6 20:33:20 2006 -0800

    [PATCH] slab: remove kmem_cache_t
    
    Replace all uses of kmem_cache_t with struct kmem_cache.
    
    The patch was generated using the following script:
    
            #!/bin/sh
            #
            # Replace one string by another in all the kernel sources.
            #
    
            set -e
    
            for file in `find * -name "*.c" -o -name "*.h"|xargs grep -l $1`; do
                    quilt add $file
                    sed -e "1,\$s/$1/$2/g" $file >/tmp/$$
                    mv /tmp/$$ $file
                    quilt refresh
            done
    
    The script was run like this
    
            sh replace kmem_cache_t "struct kmem_cache"
    
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index fb616c69151f..1748e27501cd 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -36,7 +36,7 @@
 struct scsi_host_sg_pool {
 	size_t		size;
 	char		*name; 
-	kmem_cache_t	*slab;
+	struct kmem_cache	*slab;
 	mempool_t	*pool;
 };
 
@@ -241,7 +241,7 @@ struct scsi_io_context {
 	char sense[SCSI_SENSE_BUFFERSIZE];
 };
 
-static kmem_cache_t *scsi_io_context_cache;
+static struct kmem_cache *scsi_io_context_cache;
 
 static void scsi_end_async(struct request *req, int uptodate)
 {

commit b58d91547fb17c65ad621f3f98b1f2c228c812a5
Author: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date:   Thu Nov 16 19:24:10 2006 +0900

    [SCSI] export scsi-ml functions needed by tgt_scsi_lib and its LLDs
    
    This patch contains the needed changes to the scsi-ml for the target
    mode support.
    
    Note, per the last review we moved almost all the fields we added
    to the scsi_cmnd to our internal data structure which we are going
    to try and kill off when we can replace it with support from other
    parts of the kernel.
    
    The one field we left on was the offset variable. This is needed to handle
    the case where the target gets request that is so large that it cannot
    execute it in one dma operation. So max_secotors or a segment limit may
    limit the size of the transfer. In this case our tgt core code will
    break up the command into managable transfers and send them to the
    LLD one at a time. The offset is then used to tell the LLD where in
    the command we are at. Is there another field on the scsi_cmd for
    that?
    
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 2f12f9f12fcb..fb616c69151f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -704,7 +704,7 @@ static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int uptodate,
 	return NULL;
 }
 
-static struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
+struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 {
 	struct scsi_host_sg_pool *sgp;
 	struct scatterlist *sgl;
@@ -745,7 +745,9 @@ static struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_m
 	return sgl;
 }
 
-static void scsi_free_sgtable(struct scatterlist *sgl, int index)
+EXPORT_SYMBOL(scsi_alloc_sgtable);
+
+void scsi_free_sgtable(struct scatterlist *sgl, int index)
 {
 	struct scsi_host_sg_pool *sgp;
 
@@ -755,6 +757,8 @@ static void scsi_free_sgtable(struct scatterlist *sgl, int index)
 	mempool_free(sgl, sgp->pool);
 }
 
+EXPORT_SYMBOL(scsi_free_sgtable);
+
 /*
  * Function:    scsi_release_buffers()
  *
@@ -1567,29 +1571,40 @@ u64 scsi_calculate_bounce_limit(struct Scsi_Host *shost)
 }
 EXPORT_SYMBOL(scsi_calculate_bounce_limit);
 
-struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
+struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
+					 request_fn_proc *request_fn)
 {
-	struct Scsi_Host *shost = sdev->host;
 	struct request_queue *q;
 
-	q = blk_init_queue(scsi_request_fn, NULL);
+	q = blk_init_queue(request_fn, NULL);
 	if (!q)
 		return NULL;
 
-	blk_queue_prep_rq(q, scsi_prep_fn);
-
 	blk_queue_max_hw_segments(q, shost->sg_tablesize);
 	blk_queue_max_phys_segments(q, SCSI_MAX_PHYS_SEGMENTS);
 	blk_queue_max_sectors(q, shost->max_sectors);
 	blk_queue_bounce_limit(q, scsi_calculate_bounce_limit(shost));
 	blk_queue_segment_boundary(q, shost->dma_boundary);
-	blk_queue_issue_flush_fn(q, scsi_issue_flush_fn);
-	blk_queue_softirq_done(q, scsi_softirq_done);
 
 	if (!shost->use_clustering)
 		clear_bit(QUEUE_FLAG_CLUSTER, &q->queue_flags);
 	return q;
 }
+EXPORT_SYMBOL(__scsi_alloc_queue);
+
+struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
+{
+	struct request_queue *q;
+
+	q = __scsi_alloc_queue(sdev->host, scsi_request_fn);
+	if (!q)
+		return NULL;
+
+	blk_queue_prep_rq(q, scsi_prep_fn);
+	blk_queue_issue_flush_fn(q, scsi_issue_flush_fn);
+	blk_queue_softirq_done(q, scsi_softirq_done);
+	return q;
+}
 
 void scsi_free_queue(struct request_queue *q)
 {

commit 0bd2af46839ad6262d25714a6ec0365db9d6b98f
Merge: e138a5d23567 f26b90440cd7
Author: James Bottomley <jejb@mulgrave.il.steeleye.com>
Date:   Wed Nov 22 12:06:44 2006 -0600

    Merge ../scsi-rc-fixes-2.6

commit 097b8457dafe7efc22201b4062e2d1e82e494067
Author: Tejun Heo <htejun@gmail.com>
Date:   Thu Nov 16 01:19:31 2006 -0800

    [PATCH] scsi: clear garbage after CDBs on SG_IO
    
    ATAPI devices transfer fixed number of bytes for CDBs (12 or 16).  Some
    ATAPI devices choke when shorter CDB is used and the left bytes contain
    garbage.  Block SG_IO cleared left bytes but SCSI SG_IO didn't.  This patch
    makes SCSI SG_IO clear it and simplify CDB clearing in block SG_IO.
    
    Signed-off-by: Tejun Heo <htejun@gmail.com>
    Cc: Mathieu Fluhr <mfluhr@nero.com>
    Cc: James Bottomley <James.Bottomley@steeleye.com>
    Cc: Douglas Gilbert <dougg@torque.net>
    Acked-by: Jens Axboe <jens.axboe@oracle.com>
    Cc: <stable@kernel.org>
    Acked-by: Jeff Garzik <jgarzik@pobox.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d2c02df12fdc..3ac4890ce086 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -410,6 +410,7 @@ int scsi_execute_async(struct scsi_device *sdev, const unsigned char *cmd,
 		goto free_req;
 
 	req->cmd_len = cmd_len;
+	memset(req->cmd, 0, BLK_MAX_CDB); /* ATAPI hates garbage after CDB */
 	memcpy(req->cmd, cmd, req->cmd_len);
 	req->sense = sioc->sense;
 	req->sense_len = 0;

commit 3b00315799d78f76531b71435fbc2643cd71ae4c
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Nov 4 20:10:55 2006 +0100

    [SCSI] untangle scsi_prep_fn
    
    I wanted to add some BUG checks to scsi_prep_fn to make sure no one
    sends us a non-sg command, but this function is a horrible mess.
    
    So I decided to detangle the function and document what the valid
    cases are.  While doing that I found that REQ_TYPE_SPECIAL commands
    aren't used by the SCSI layer anymore and we can get rid of the code
    handling them.
    
    The new structure of scsi_prep_fn is:
    
     (1) check if we're allowed to send this command
     (2) big switch on cmd_type.  For the two valid types call into
         a function to set the command up, else error
     (3) code to handle error cases
    
    Because FS and BLOCK_PC commands are handled entirely separate after
    the patch this introduces a tiny amount of code duplication.  This
    improves readabiulity though and will help to avoid the bidi command
    overhead for FS commands so it's a good thing.
    
    I've tested this on both sata and mptsas.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 743f67ed7640..ee35a62bb7a2 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -995,25 +995,14 @@ static int scsi_init_io(struct scsi_cmnd *cmd)
 	int		   count;
 
 	/*
-	 * if this is a rq->data based REQ_BLOCK_PC, setup for a non-sg xfer
-	 */
-	if (blk_pc_request(req) && !req->bio) {
-		cmd->request_bufflen = req->data_len;
-		cmd->request_buffer = req->data;
-		req->buffer = req->data;
-		cmd->use_sg = 0;
-		return 0;
-	}
-
-	/*
-	 * we used to not use scatter-gather for single segment request,
+	 * We used to not use scatter-gather for single segment request,
 	 * but now we do (it makes highmem I/O easier to support without
 	 * kmapping pages)
 	 */
 	cmd->use_sg = req->nr_phys_segments;
 
 	/*
-	 * if sg table allocation fails, requeue request later.
+	 * If sg table allocation fails, requeue request later.
 	 */
 	sgpnt = scsi_alloc_sgtable(cmd, GFP_ATOMIC);
 	if (unlikely(!sgpnt)) {
@@ -1021,24 +1010,21 @@ static int scsi_init_io(struct scsi_cmnd *cmd)
 		return BLKPREP_DEFER;
 	}
 
+	req->buffer = NULL;
 	cmd->request_buffer = (char *) sgpnt;
-	cmd->request_bufflen = req->nr_sectors << 9;
 	if (blk_pc_request(req))
 		cmd->request_bufflen = req->data_len;
-	req->buffer = NULL;
+	else
+		cmd->request_bufflen = req->nr_sectors << 9;
 
 	/* 
 	 * Next, walk the list, and fill in the addresses and sizes of
 	 * each segment.
 	 */
 	count = blk_rq_map_sg(req->q, req, cmd->request_buffer);
-
-	/*
-	 * mapped well, send it off
-	 */
 	if (likely(count <= cmd->use_sg)) {
 		cmd->use_sg = count;
-		return 0;
+		return BLKPREP_OK;
 	}
 
 	printk(KERN_ERR "Incorrect number of segments after building list\n");
@@ -1068,6 +1054,27 @@ static int scsi_issue_flush_fn(request_queue_t *q, struct gendisk *disk,
 	return -EOPNOTSUPP;
 }
 
+static struct scsi_cmnd *scsi_get_cmd_from_req(struct scsi_device *sdev,
+		struct request *req)
+{
+	struct scsi_cmnd *cmd;
+
+	if (!req->special) {
+		cmd = scsi_get_command(sdev, GFP_ATOMIC);
+		if (unlikely(!cmd))
+			return NULL;
+		req->special = cmd;
+	} else {
+		cmd = req->special;
+	}
+
+	/* pull a tag out of the request if we have one */
+	cmd->tag = req->tag;
+	cmd->request = req;
+
+	return cmd;
+}
+
 static void scsi_blk_pc_done(struct scsi_cmnd *cmd)
 {
 	BUG_ON(!blk_pc_request(cmd->request));
@@ -1080,9 +1087,37 @@ static void scsi_blk_pc_done(struct scsi_cmnd *cmd)
 	scsi_io_completion(cmd, cmd->request_bufflen);
 }
 
-static void scsi_setup_blk_pc_cmnd(struct scsi_cmnd *cmd)
+static int scsi_setup_blk_pc_cmnd(struct scsi_device *sdev, struct request *req)
 {
-	struct request *req = cmd->request;
+	struct scsi_cmnd *cmd;
+
+	cmd = scsi_get_cmd_from_req(sdev, req);
+	if (unlikely(!cmd))
+		return BLKPREP_DEFER;
+
+	/*
+	 * BLOCK_PC requests may transfer data, in which case they must
+	 * a bio attached to them.  Or they might contain a SCSI command
+	 * that does not transfer data, in which case they may optionally
+	 * submit a request without an attached bio.
+	 */
+	if (req->bio) {
+		int ret;
+
+		BUG_ON(!req->nr_phys_segments);
+
+		ret = scsi_init_io(cmd);
+		if (unlikely(ret))
+			return ret;
+	} else {
+		BUG_ON(req->data_len);
+		BUG_ON(req->data);
+
+		cmd->request_bufflen = 0;
+		cmd->request_buffer = NULL;
+		cmd->use_sg = 0;
+		req->buffer = NULL;
+	}
 
 	BUG_ON(sizeof(req->cmd) > sizeof(cmd->cmnd));
 	memcpy(cmd->cmnd, req->cmd, sizeof(cmd->cmnd));
@@ -1098,154 +1133,138 @@ static void scsi_setup_blk_pc_cmnd(struct scsi_cmnd *cmd)
 	cmd->allowed = req->retries;
 	cmd->timeout_per_command = req->timeout;
 	cmd->done = scsi_blk_pc_done;
+	return BLKPREP_OK;
 }
 
-static int scsi_prep_fn(struct request_queue *q, struct request *req)
+/*
+ * Setup a REQ_TYPE_FS command.  These are simple read/write request
+ * from filesystems that still need to be translated to SCSI CDBs from
+ * the ULD.
+ */
+static int scsi_setup_fs_cmnd(struct scsi_device *sdev, struct request *req)
 {
-	struct scsi_device *sdev = q->queuedata;
 	struct scsi_cmnd *cmd;
-	int specials_only = 0;
+	struct scsi_driver *drv;
+	int ret;
 
 	/*
-	 * Just check to see if the device is online.  If it isn't, we
-	 * refuse to process any commands.  The device must be brought
-	 * online before trying any recovery commands
+	 * Filesystem requests must transfer data.
 	 */
-	if (unlikely(!scsi_device_online(sdev))) {
-		sdev_printk(KERN_ERR, sdev,
-			    "rejecting I/O to offline device\n");
-		goto kill;
-	}
-	if (unlikely(sdev->sdev_state != SDEV_RUNNING)) {
-		/* OK, we're not in a running state don't prep
-		 * user commands */
-		if (sdev->sdev_state == SDEV_DEL) {
-			/* Device is fully deleted, no commands
-			 * at all allowed down */
-			sdev_printk(KERN_ERR, sdev,
-				    "rejecting I/O to dead device\n");
-			goto kill;
-		}
-		/* OK, we only allow special commands (i.e. not
-		 * user initiated ones */
-		specials_only = sdev->sdev_state;
+	BUG_ON(!req->nr_phys_segments);
+
+	cmd = scsi_get_cmd_from_req(sdev, req);
+	if (unlikely(!cmd))
+		return BLKPREP_DEFER;
+
+	ret = scsi_init_io(cmd);
+	if (unlikely(ret))
+		return ret;
+
+	/*
+	 * Initialize the actual SCSI command for this request.
+	 */
+	drv = *(struct scsi_driver **)req->rq_disk->private_data;
+	if (unlikely(!drv->init_command(cmd))) {
+		scsi_release_buffers(cmd);
+		scsi_put_command(cmd);
+		return BLKPREP_KILL;
 	}
 
+	return BLKPREP_OK;
+}
+
+static int scsi_prep_fn(struct request_queue *q, struct request *req)
+{
+	struct scsi_device *sdev = q->queuedata;
+	int ret = BLKPREP_OK;
+
 	/*
-	 * Find the actual device driver associated with this command.
-	 * The SPECIAL requests are things like character device or
-	 * ioctls, which did not originate from ll_rw_blk.  Note that
-	 * the special field is also used to indicate the cmd for
-	 * the remainder of a partially fulfilled request that can 
-	 * come up when there is a medium error.  We have to treat
-	 * these two cases differently.  We differentiate by looking
-	 * at request->cmd, as this tells us the real story.
+	 * If the device is not in running state we will reject some
+	 * or all commands.
 	 */
-	if (blk_special_request(req) && req->special)
-		cmd = req->special;
-	else if (blk_pc_request(req) || blk_fs_request(req)) {
-		if (unlikely(specials_only) && !(req->cmd_flags & REQ_PREEMPT)){
-			if (specials_only == SDEV_QUIESCE ||
-			    specials_only == SDEV_BLOCK)
-				goto defer;
-			
+	if (unlikely(sdev->sdev_state != SDEV_RUNNING)) {
+		switch (sdev->sdev_state) {
+		case SDEV_OFFLINE:
+			/*
+			 * If the device is offline we refuse to process any
+			 * commands.  The device must be brought online
+			 * before trying any recovery commands.
+			 */
 			sdev_printk(KERN_ERR, sdev,
-				    "rejecting I/O to device being removed\n");
-			goto kill;
+				    "rejecting I/O to offline device\n");
+			ret = BLKPREP_KILL;
+			break;
+		case SDEV_DEL:
+			/*
+			 * If the device is fully deleted, we refuse to
+			 * process any commands as well.
+			 */
+			sdev_printk(KERN_ERR, sdev,
+				    "rejecting I/O to dead device\n");
+			ret = BLKPREP_KILL;
+			break;
+		case SDEV_QUIESCE:
+		case SDEV_BLOCK:
+			/*
+			 * If the devices is blocked we defer normal commands.
+			 */
+			if (!(req->cmd_flags & REQ_PREEMPT))
+				ret = BLKPREP_DEFER;
+			break;
+		default:
+			/*
+			 * For any other not fully online state we only allow
+			 * special commands.  In particular any user initiated
+			 * command is not allowed.
+			 */
+			if (!(req->cmd_flags & REQ_PREEMPT))
+				ret = BLKPREP_KILL;
+			break;
 		}
-			
-		/*
-		 * Now try and find a command block that we can use.
-		 */
-		if (!req->special) {
-			cmd = scsi_get_command(sdev, GFP_ATOMIC);
-			if (unlikely(!cmd))
-				goto defer;
-		} else
-			cmd = req->special;
-		
-		/* pull a tag out of the request if we have one */
-		cmd->tag = req->tag;
-	} else {
-		blk_dump_rq_flags(req, "SCSI bad req");
-		goto kill;
+
+		if (ret != BLKPREP_OK)
+			goto out;
 	}
-	
-	/* note the overloading of req->special.  When the tag
-	 * is active it always means cmd.  If the tag goes
-	 * back for re-queueing, it may be reset */
-	req->special = cmd;
-	cmd->request = req;
-	
-	/*
-	 * FIXME: drop the lock here because the functions below
-	 * expect to be called without the queue lock held.  Also,
-	 * previously, we dequeued the request before dropping the
-	 * lock.  We hope REQ_STARTED prevents anything untoward from
-	 * happening now.
-	 */
-	if (blk_fs_request(req) || blk_pc_request(req)) {
-		int ret;
 
+	switch (req->cmd_type) {
+	case REQ_TYPE_BLOCK_PC:
+		ret = scsi_setup_blk_pc_cmnd(sdev, req);
+		break;
+	case REQ_TYPE_FS:
+		ret = scsi_setup_fs_cmnd(sdev, req);
+		break;
+	default:
 		/*
-		 * This will do a couple of things:
-		 *  1) Fill in the actual SCSI command.
-		 *  2) Fill in any other upper-level specific fields
-		 * (timeout).
+		 * All other command types are not supported.
 		 *
-		 * If this returns 0, it means that the request failed
-		 * (reading past end of disk, reading offline device,
-		 * etc).   This won't actually talk to the device, but
-		 * some kinds of consistency checking may cause the	
-		 * request to be rejected immediately.
+		 * Note that these days the SCSI subsystem does not use
+		 * REQ_TYPE_SPECIAL requests anymore.  These are only used
+		 * (directly or via blk_insert_request) by non-SCSI drivers.
 		 */
+		blk_dump_rq_flags(req, "SCSI bad req");
+		ret = BLKPREP_KILL;
+		break;
+	}
 
-		/* 
-		 * This sets up the scatter-gather table (allocating if
-		 * required).
-		 */
-		ret = scsi_init_io(cmd);
-		switch(ret) {
-			/* For BLKPREP_KILL/DEFER the cmd was released */
-		case BLKPREP_KILL:
-			goto kill;
-		case BLKPREP_DEFER:
-			goto defer;
-		}
-		
+ out:
+	switch (ret) {
+	case BLKPREP_KILL:
+		req->errors = DID_NO_CONNECT << 16;
+		break;
+	case BLKPREP_DEFER:
 		/*
-		 * Initialize the actual SCSI command for this request.
+		 * If we defer, the elv_next_request() returns NULL, but the
+		 * queue must be restarted, so we plug here if no returning
+		 * command will automatically do that.
 		 */
-		if (blk_pc_request(req)) {
-			scsi_setup_blk_pc_cmnd(cmd);
-		} else if (req->rq_disk) {
-			struct scsi_driver *drv;
-
-			drv = *(struct scsi_driver **)req->rq_disk->private_data;
-			if (unlikely(!drv->init_command(cmd))) {
-				scsi_release_buffers(cmd);
-				scsi_put_command(cmd);
-				goto kill;
-			}
-		}
+		if (sdev->device_busy == 0)
+			blk_plug_device(q);
+		break;
+	default:
+		req->cmd_flags |= REQ_DONTPREP;
 	}
 
-	/*
-	 * The request is now prepped, no need to come back here
-	 */
-	req->cmd_flags |= REQ_DONTPREP;
-	return BLKPREP_OK;
-
- defer:
-	/* If we defer, the elv_next_request() returns NULL, but the
-	 * queue must be restarted, so we plug here if no returning
-	 * command will automatically do that. */
-	if (sdev->device_busy == 0)
-		blk_plug_device(q);
-	return BLKPREP_DEFER;
- kill:
-	req->errors = DID_NO_CONNECT << 16;
-	return BLKPREP_KILL;
+	return ret;
 }
 
 /*

commit 46c43db1eabcdc46ad9a3d711edff1d698ecd21f
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Sun Oct 8 15:55:55 2006 +0400

    [SCSI] scsi_lib.c: use BUILD_BUG_ON
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 743f67ed7640..d2c02df12fdc 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1084,7 +1084,7 @@ static void scsi_setup_blk_pc_cmnd(struct scsi_cmnd *cmd)
 {
 	struct request *req = cmd->request;
 
-	BUG_ON(sizeof(req->cmd) > sizeof(cmd->cmnd));
+	BUILD_BUG_ON(sizeof(req->cmd) > sizeof(cmd->cmnd));
 	memcpy(cmd->cmnd, req->cmd, sizeof(cmd->cmnd));
 	cmd->cmd_len = req->cmd_len;
 	if (!req->data_len)

commit 97d41e90fe61399b99d74820cb7f2d6e0fbac91d
Merge: 3bdc9d0b408e afaf5a2d341d
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Wed Oct 4 18:57:35 2006 -0700

    Merge master.kernel.org:/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6
    
    * master.kernel.org:/pub/scm/linux/kernel/git/jejb/scsi-misc-2.6: (54 commits)
      [SCSI] Initial Commit of qla4xxx
      [SCSI] raid class: handle component-add errors
      [SCSI] SCSI megaraid_sas: handle thrown errors
      [SCSI] SCSI aic94xx: handle sysfs errors
      [SCSI] SCSI st: fix error handling in module init, sysfs
      [SCSI] SCSI sd: fix module init/exit error handling
      [SCSI] SCSI osst: add error handling to module init, sysfs
      [SCSI] scsi: remove hosts.h
      [SCSI] scsi: Scsi_Cmnd convertion in aic7xxx_old.c
      [SCSI] megaraid_sas: sets ioctl timeout and updates version,changelog
      [SCSI] megaraid_sas: adds tasklet for cmd completion
      [SCSI] megaraid_sas: prints pending cmds before setting hw_crit_error
      [SCSI] megaraid_sas: function pointer for disable interrupt
      [SCSI] megaraid_sas: frame count optimization
      [SCSI] megaraid_sas: FW transition and q size changes
      [SCSI] qla2xxx: Update version number to 8.01.07-k2.
      [SCSI] qla2xxx: Stall mid-layer error handlers while rport is blocked.
      [SCSI] qla2xxx: Add MODULE_FIRMWARE tags.
      [SCSI] qla2xxx: Add support for host port state FC transport attribute.
      [SCSI] qla2xxx: Add support for fabric name FC transport attribute.
      ...

commit 6470f2ba641cf93d357854cdc63a65350352bb97
Author: Arne Redlich <arne.redlich@xiranet.com>
Date:   Sat Sep 30 15:49:40 2006 +0200

    [SCSI] trivial scsi_execute_async fix
    
    In scsi_execute_async()'s error path, a struct scsi_io_context
    allocated with kmem_cache_alloc() is kfree()'d. Obviously
    kmem_cache_free() should be used instead.
    
    Signed-off-by: Arne Redlich <arne.redlich@xiranet.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d6743b959a72..8ada93ae34f7 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -424,7 +424,7 @@ int scsi_execute_async(struct scsi_device *sdev, const unsigned char *cmd,
 free_req:
 	blk_put_request(req);
 free_sense:
-	kfree(sioc);
+	kmem_cache_free(scsi_io_context_cache, sioc);
 	return DRIVER_ERROR << 24;
 }
 EXPORT_SYMBOL_GPL(scsi_execute_async);

commit 4aff5e2333c9a1609662f2091f55c3f6fffdad36
Author: Jens Axboe <axboe@suse.de>
Date:   Thu Aug 10 08:44:47 2006 +0200

    [PATCH] Split struct request ->flags into two parts
    
    Right now ->flags is a bit of a mess: some are request types, and
    others are just modifiers. Clean this up by splitting it into
    ->cmd_type and ->cmd_flags. This allows introduction of generic
    Linux block message types, useful for sending generic Linux commands
    to block devices.
    
    Signed-off-by: Jens Axboe <axboe@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d6743b959a72..71084728eb42 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -82,7 +82,7 @@ static void scsi_unprep_request(struct request *req)
 {
 	struct scsi_cmnd *cmd = req->special;
 
-	req->flags &= ~REQ_DONTPREP;
+	req->cmd_flags &= ~REQ_DONTPREP;
 	req->special = NULL;
 
 	scsi_put_command(cmd);
@@ -196,7 +196,8 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	req->sense_len = 0;
 	req->retries = retries;
 	req->timeout = timeout;
-	req->flags |= flags | REQ_BLOCK_PC | REQ_SPECIAL | REQ_QUIET;
+	req->cmd_type = REQ_TYPE_BLOCK_PC;
+	req->cmd_flags |= flags | REQ_QUIET | REQ_PREEMPT;
 
 	/*
 	 * head injection *required* here otherwise quiesce won't work
@@ -397,7 +398,8 @@ int scsi_execute_async(struct scsi_device *sdev, const unsigned char *cmd,
 	req = blk_get_request(sdev->request_queue, write, gfp);
 	if (!req)
 		goto free_sense;
-	req->flags |= REQ_BLOCK_PC | REQ_QUIET;
+	req->cmd_type = REQ_TYPE_BLOCK_PC;
+	req->cmd_flags |= REQ_QUIET;
 
 	if (use_sg)
 		err = scsi_req_map_sg(req, buffer, use_sg, bufflen, gfp);
@@ -933,7 +935,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 					break;
 				}
 			}
-			if (!(req->flags & REQ_QUIET)) {
+			if (!(req->cmd_flags & REQ_QUIET)) {
 				scmd_printk(KERN_INFO, cmd,
 					    "Device not ready: ");
 				scsi_print_sense_hdr("", &sshdr);
@@ -941,7 +943,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			scsi_end_request(cmd, 0, this_count, 1);
 			return;
 		case VOLUME_OVERFLOW:
-			if (!(req->flags & REQ_QUIET)) {
+			if (!(req->cmd_flags & REQ_QUIET)) {
 				scmd_printk(KERN_INFO, cmd,
 					    "Volume overflow, CDB: ");
 				__scsi_print_command(cmd->cmnd);
@@ -963,7 +965,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 		return;
 	}
 	if (result) {
-		if (!(req->flags & REQ_QUIET)) {
+		if (!(req->cmd_flags & REQ_QUIET)) {
 			scmd_printk(KERN_INFO, cmd,
 				    "SCSI error: return code = 0x%08x\n",
 				    result);
@@ -995,7 +997,7 @@ static int scsi_init_io(struct scsi_cmnd *cmd)
 	/*
 	 * if this is a rq->data based REQ_BLOCK_PC, setup for a non-sg xfer
 	 */
-	if ((req->flags & REQ_BLOCK_PC) && !req->bio) {
+	if (blk_pc_request(req) && !req->bio) {
 		cmd->request_bufflen = req->data_len;
 		cmd->request_buffer = req->data;
 		req->buffer = req->data;
@@ -1139,13 +1141,12 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 	 * these two cases differently.  We differentiate by looking
 	 * at request->cmd, as this tells us the real story.
 	 */
-	if (req->flags & REQ_SPECIAL && req->special) {
+	if (blk_special_request(req) && req->special)
 		cmd = req->special;
-	} else if (req->flags & (REQ_CMD | REQ_BLOCK_PC)) {
-
-		if(unlikely(specials_only) && !(req->flags & REQ_SPECIAL)) {
-			if(specials_only == SDEV_QUIESCE ||
-					specials_only == SDEV_BLOCK)
+	else if (blk_pc_request(req) || blk_fs_request(req)) {
+		if (unlikely(specials_only) && !(req->cmd_flags & REQ_PREEMPT)){
+			if (specials_only == SDEV_QUIESCE ||
+			    specials_only == SDEV_BLOCK)
 				goto defer;
 			
 			sdev_printk(KERN_ERR, sdev,
@@ -1153,7 +1154,6 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 			goto kill;
 		}
 			
-			
 		/*
 		 * Now try and find a command block that we can use.
 		 */
@@ -1184,7 +1184,7 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 	 * lock.  We hope REQ_STARTED prevents anything untoward from
 	 * happening now.
 	 */
-	if (req->flags & (REQ_CMD | REQ_BLOCK_PC)) {
+	if (blk_fs_request(req) || blk_pc_request(req)) {
 		int ret;
 
 		/*
@@ -1216,7 +1216,7 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 		/*
 		 * Initialize the actual SCSI command for this request.
 		 */
-		if (req->flags & REQ_BLOCK_PC) {
+		if (blk_pc_request(req)) {
 			scsi_setup_blk_pc_cmnd(cmd);
 		} else if (req->rq_disk) {
 			struct scsi_driver *drv;
@@ -1233,7 +1233,7 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 	/*
 	 * The request is now prepped, no need to come back here
 	 */
-	req->flags |= REQ_DONTPREP;
+	req->cmd_flags |= REQ_DONTPREP;
 	return BLKPREP_OK;
 
  defer:
@@ -1454,8 +1454,9 @@ static void scsi_request_fn(struct request_queue *q)
 		if (unlikely(cmd == NULL)) {
 			printk(KERN_CRIT "impossible request in %s.\n"
 					 "please mail a stack trace to "
-					 "linux-scsi@vger.kernel.org",
+					 "linux-scsi@vger.kernel.org\n",
 					 __FUNCTION__);
+			blk_dump_rq_flags(req, "foo");
 			BUG();
 		}
 		spin_lock(shost->host_lock);

commit 04846f25920d4b05d6040c531cc601049260db52
Author: Andreas Herrmann <aherrman@de.ibm.com>
Date:   Wed Aug 9 17:31:16 2006 +0200

    [SCSI] limit recursion when flushing shost->starved_list
    
    Attached is a patch that should limit a possible recursion that can
    lead to a stack overflow like follows:
    
    Kernel stack overflow.
    CPU:    3    Not tainted
    Process zfcperp0.0.d819
    (pid: 13897, task: 000000003e0d8cc8, ksp: 000000003499dbb8)
    Krnl PSW : 0404000180000000 000000000030f8b2 (get_device+0x12/0x48)
    Krnl GPRS: 00000000135a1980 000000000030f758 000000003ed6c1e8 0000000000000005
               0000000000000000 000000000044a780 000000003dbf7000 0000000034e15800
               000000003621c048 070000003499c108 000000003499c1a0 000000003ed6c000
               0000000040895000 00000000408ab630 000000003499c0a0 000000003499c0a0
    Krnl Code: a7 fb ff e8 a7 19 00 00 b9 02 00 22 e3 e0 f0 98 00 24 a7 84
    Call Trace:
    ([<000000004089edc2>] scsi_request_fn+0x13e/0x650 [scsi_mod])
     [<00000000002c5ff4>] blk_run_queue+0xd4/0x1a4
     [<000000004089ff8c>] scsi_queue_insert+0x22c/0x2a4 [scsi_mod]
     [<000000004089779a>] scsi_dispatch_cmd+0x8a/0x3d0 [scsi_mod]
     [<000000004089f1ec>] scsi_request_fn+0x568/0x650 [scsi_mod]
    ...
     [<000000004089f1ec>] scsi_request_fn+0x568/0x650 [scsi_mod]
     [<00000000002c5ff4>] blk_run_queue+0xd4/0x1a4
     [<000000004089ff8c>] scsi_queue_insert+0x22c/0x2a4 [scsi_mod]
     [<000000004089779a>] scsi_dispatch_cmd+0x8a/0x3d0 [scsi_mod]
     [<000000004089f1ec>] scsi_request_fn+0x568/0x650 [scsi_mod]
     [<00000000002c5ff4>] blk_run_queue+0xd4/0x1a4
     [<000000004089fa9e>] scsi_run_host_queues+0x196/0x230 [scsi_mod]
     [<00000000409eba28>] zfcp_erp_thread+0x2638/0x3080 [zfcp]
     [<0000000000107462>] kernel_thread_starter+0x6/0xc
     [<000000000010745c>] kernel_thread_starter+0x0/0xc
    <0>Kernel panic - not syncing: Corrupt kernel stack, can't continue.
    
    This stack overflow occurred during tests on s390 using zfcp.
    Recursion depth for this panic was 19.
    
    Usually recursion between blk_run_queue and a request_fn is avoided
    using QUEUE_FLAG_REENTER. But this does not help if the scsi stack
    tries to flush the starved_list of a scsi_host.
    
    Limit recursion depth when flushing the starved_list
    of a scsi_host.
    
    Signed-off-by: Andreas Herrmann <aherrman@de.ibm.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 077c1c691210..d6743b959a72 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -551,7 +551,15 @@ static void scsi_run_queue(struct request_queue *q)
 		list_del_init(&sdev->starved_entry);
 		spin_unlock_irqrestore(shost->host_lock, flags);
 
-		blk_run_queue(sdev->request_queue);
+
+		if (test_bit(QUEUE_FLAG_REENTER, &q->queue_flags) &&
+		    !test_and_set_bit(QUEUE_FLAG_REENTER,
+				      &sdev->request_queue->queue_flags)) {
+			blk_run_queue(sdev->request_queue);
+			clear_bit(QUEUE_FLAG_REENTER,
+				  &sdev->request_queue->queue_flags);
+		} else
+			blk_run_queue(sdev->request_queue);
 
 		spin_lock_irqsave(shost->host_lock, flags);
 		if (unlikely(!list_empty(&sdev->starved_entry)))

commit 631c228cd09bd5b93090fa60bd9803ec14aa0586
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jul 8 20:42:15 2006 +0200

    [SCSI] hide EH backup data outside the scsi_cmnd
    
    Currently struct scsi_cmnd has various fields that are used to backup
    original data after the corresponding fields have been overridden for
    EH commands.  This means drivers can easily get at it and misuse it.
    Due to the old_ naming this doesn't happen for most of them, but two
    that have different names have been used wrong a lot (see previous
    patch).  Another downside is that they unessecarily bloat the scsi_cmnd
    size.
    
    This patch moves them onstack in scsi_send_eh_cmnd to fix those two
    issues aswell as allowing future EH fixes like moving the EH command
    submissions to use SG lists like everything else.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 08af9aae7df3..077c1c691210 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -436,60 +436,16 @@ EXPORT_SYMBOL_GPL(scsi_execute_async);
  *
  * Arguments:   cmd	- command that is ready to be queued.
  *
- * Returns:     Nothing
- *
  * Notes:       This function has the job of initializing a number of
  *              fields related to error handling.   Typically this will
  *              be called once for each command, as required.
  */
-static int scsi_init_cmd_errh(struct scsi_cmnd *cmd)
+static void scsi_init_cmd_errh(struct scsi_cmnd *cmd)
 {
 	cmd->serial_number = 0;
-
 	memset(cmd->sense_buffer, 0, sizeof cmd->sense_buffer);
-
 	if (cmd->cmd_len == 0)
 		cmd->cmd_len = COMMAND_SIZE(cmd->cmnd[0]);
-
-	/*
-	 * We need saved copies of a number of fields - this is because
-	 * error handling may need to overwrite these with different values
-	 * to run different commands, and once error handling is complete,
-	 * we will need to restore these values prior to running the actual
-	 * command.
-	 */
-	cmd->old_use_sg = cmd->use_sg;
-	cmd->old_cmd_len = cmd->cmd_len;
-	cmd->sc_old_data_direction = cmd->sc_data_direction;
-	cmd->old_underflow = cmd->underflow;
-	memcpy(cmd->data_cmnd, cmd->cmnd, sizeof(cmd->cmnd));
-	cmd->buffer = cmd->request_buffer;
-	cmd->bufflen = cmd->request_bufflen;
-
-	return 1;
-}
-
-/*
- * Function:   scsi_setup_cmd_retry()
- *
- * Purpose:    Restore the command state for a retry
- *
- * Arguments:  cmd	- command to be restored
- *
- * Returns:    Nothing
- *
- * Notes:      Immediately prior to retrying a command, we need
- *             to restore certain fields that we saved above.
- */
-void scsi_setup_cmd_retry(struct scsi_cmnd *cmd)
-{
-	memcpy(cmd->cmnd, cmd->data_cmnd, sizeof(cmd->data_cmnd));
-	cmd->request_buffer = cmd->buffer;
-	cmd->request_bufflen = cmd->bufflen;
-	cmd->use_sg = cmd->old_use_sg;
-	cmd->cmd_len = cmd->old_cmd_len;
-	cmd->sc_data_direction = cmd->sc_old_data_direction;
-	cmd->underflow = cmd->old_underflow;
 }
 
 void scsi_device_unbusy(struct scsi_device *sdev)
@@ -807,22 +763,13 @@ static void scsi_free_sgtable(struct scatterlist *sgl, int index)
  */
 static void scsi_release_buffers(struct scsi_cmnd *cmd)
 {
-	struct request *req = cmd->request;
-
-	/*
-	 * Free up any indirection buffers we allocated for DMA purposes. 
-	 */
 	if (cmd->use_sg)
 		scsi_free_sgtable(cmd->request_buffer, cmd->sglist_len);
-	else if (cmd->request_buffer != req->buffer)
-		kfree(cmd->request_buffer);
 
 	/*
 	 * Zero these out.  They now point to freed memory, and it is
 	 * dangerous to hang onto the pointers.
 	 */
-	cmd->buffer  = NULL;
-	cmd->bufflen = 0;
 	cmd->request_buffer = NULL;
 	cmd->request_bufflen = 0;
 }
@@ -858,7 +805,7 @@ static void scsi_release_buffers(struct scsi_cmnd *cmd)
 void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 {
 	int result = cmd->result;
-	int this_count = cmd->bufflen;
+	int this_count = cmd->request_bufflen;
 	request_queue_t *q = cmd->device->request_queue;
 	struct request *req = cmd->request;
 	int clear_errors = 1;
@@ -866,28 +813,14 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	int sense_valid = 0;
 	int sense_deferred = 0;
 
-	/*
-	 * Free up any indirection buffers we allocated for DMA purposes. 
-	 * For the case of a READ, we need to copy the data out of the
-	 * bounce buffer and into the real buffer.
-	 */
-	if (cmd->use_sg)
-		scsi_free_sgtable(cmd->buffer, cmd->sglist_len);
-	else if (cmd->buffer != req->buffer) {
-		if (rq_data_dir(req) == READ) {
-			unsigned long flags;
-			char *to = bio_kmap_irq(req->bio, &flags);
-			memcpy(to, cmd->buffer, cmd->bufflen);
-			bio_kunmap_irq(to, &flags);
-		}
-		kfree(cmd->buffer);
-	}
+	scsi_release_buffers(cmd);
 
 	if (result) {
 		sense_valid = scsi_command_normalize_sense(cmd, &sshdr);
 		if (sense_valid)
 			sense_deferred = scsi_sense_is_deferred(&sshdr);
 	}
+
 	if (blk_pc_request(req)) { /* SG_IO ioctl from block level */
 		req->errors = result;
 		if (result) {
@@ -907,15 +840,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			req->data_len = cmd->resid;
 	}
 
-	/*
-	 * Zero these out.  They now point to freed memory, and it is
-	 * dangerous to hang onto the pointers.
-	 */
-	cmd->buffer  = NULL;
-	cmd->bufflen = 0;
-	cmd->request_buffer = NULL;
-	cmd->request_bufflen = 0;
-
 	/*
 	 * Next deal with any sectors which we were able to correctly
 	 * handle.
@@ -1012,7 +936,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 			if (!(req->flags & REQ_QUIET)) {
 				scmd_printk(KERN_INFO, cmd,
 					    "Volume overflow, CDB: ");
-				__scsi_print_command(cmd->data_cmnd);
+				__scsi_print_command(cmd->cmnd);
 				scsi_print_sense("", cmd);
 			}
 			/* See SSC3rXX or current. */
@@ -1143,7 +1067,7 @@ static void scsi_blk_pc_done(struct scsi_cmnd *cmd)
 	 * successfully. Since this is a REQ_BLOCK_PC command the
 	 * caller should check the request's errors value
 	 */
-	scsi_io_completion(cmd, cmd->bufflen);
+	scsi_io_completion(cmd, cmd->request_bufflen);
 }
 
 static void scsi_setup_blk_pc_cmnd(struct scsi_cmnd *cmd)

commit d6b0c53723753fc0cfda63f56735b225c43e1e9a
Author: James Bottomley <James.Bottomley@steeleye.com>
Date:   Sun Jul 2 10:06:28 2006 -0500

    [SCSI] fix error handling in scsi_io_completion
    
    There was a logic fault in scsi_io_completion() where zero transfer
    commands that complete successfully were sent to the block layer as
    not up to date.  This patch removes the if (good_bytes > 0) gate
    around the successful completion, since zero transfer commands do have
    good_bytes == 0.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index bf5191f6aaa1..08af9aae7df3 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -920,22 +920,20 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 	 * Next deal with any sectors which we were able to correctly
 	 * handle.
 	 */
-	if (good_bytes > 0) {
-		SCSI_LOG_HLCOMPLETE(1, printk("%ld sectors total, "
-					      "%d bytes done.\n",
-					      req->nr_sectors, good_bytes));
-		SCSI_LOG_HLCOMPLETE(1, printk("use_sg is %d\n", cmd->use_sg));
-
-		if (clear_errors)
-			req->errors = 0;
-
-		/* A number of bytes were successfully read.  If there
-		 * is leftovers and there is some kind of error
-		 * (result != 0), retry the rest.
-		 */
-		if (scsi_end_request(cmd, 1, good_bytes, !!result) == NULL)
-			return;
-	}
+	SCSI_LOG_HLCOMPLETE(1, printk("%ld sectors total, "
+				      "%d bytes done.\n",
+				      req->nr_sectors, good_bytes));
+	SCSI_LOG_HLCOMPLETE(1, printk("use_sg is %d\n", cmd->use_sg));
+
+	if (clear_errors)
+		req->errors = 0;
+
+	/* A number of bytes were successfully read.  If there
+	 * are leftovers and there is some kind of error
+	 * (result != 0), retry the rest.
+	 */
+	if (scsi_end_request(cmd, 1, good_bytes, result == 0) == NULL)
+		return;
 
 	/* good_bytes = 0, or (inclusive) there were leftovers and
 	 * result = 0, so scsi_end_request couldn't retry.

commit 309bd271211caa5a04a8137649cebd7691376351
Author: Brian King <brking@us.ibm.com>
Date:   Tue Jun 27 11:10:43 2006 -0500

    [SCSI] scsi: Device scanning oops for offlined devices (resend)
    
    If a device gets offlined as a result of the Inquiry sent
    during scanning, the following oops can occur. After the
    disk gets put into the SDEV_OFFLINE state, the error handler
    sends back the failed inquiry, which wakes the thread doing
    the scan. This starts a race between the scanning thread
    freeing the scsi device and the error handler calling
    scsi_run_host_queues to restart the host. Since the disk
    is in the SDEV_OFFLINE state, scsi_device_get will still
    work, which results in __scsi_iterate_devices getting
    a reference to the scsi disk when it shouldn't.
    
    The following execution thread causes the oops:
    
    CPU 0 (scan)                            CPU 1 (eh)
    
    ---------------------------------------------------------
    scsi_probe_and_add_lun
                            ....
                                            scsi_eh_offline_sdevs
                                            scsi_eh_flush_done_q
    scsi_destroy_sdev
    scsi_device_dev_release
                                            scsi_restart_operations
                                             scsi_run_host_queues
                                              __scsi_iterate_devices
                                               get_device
    scsi_device_dev_release_usercontext
                                              scsi_run_queue
                                                <---OOPS--->
    
    The patch fixes this by changing the state of the sdev to SDEV_DEL
    before doing the final put_device, which should prevent the race
    from occurring.
    
    Original oops follows:
    
    Badness in kref_get at lib/kref.c:32
    Call Trace:
    [C00000002F4476D0] [C00000000000EE20] .show_stack+0x68/0x1b0 (unreliable)
    [C00000002F447770] [C00000000037515C] .program_check_exception+0x1cc/0x5a8
    [C00000002F447840] [C00000000000446C] program_check_common+0xec/0x100
     Exception: 700 at .kref_get+0x10/0x28
        LR = .kobject_get+0x20/0x3c
    [C00000002F447B30] [C00000002F447BC0] 0xc00000002f447bc0 (unreliable)
    [C00000002F447BB0] [C000000000254BDC] .get_device+0x20/0x3c
    [C00000002F447C30] [D000000000063188] .scsi_device_get+0x34/0xdc [scsi_mod]
    [C00000002F447CC0] [D0000000000633EC] .__scsi_iterate_devices+0x50/0xbc [scsi_mod]
    [C00000002F447D60] [D00000000006A910] .scsi_run_host_queues+0x34/0x5c [scsi_mod]
    [C00000002F447DF0] [D000000000069054] .scsi_error_handler+0xdb4/0xe44 [scsi_mod]
    [C00000002F447EE0] [C00000000007B4E0] .kthread+0x128/0x178
    [C00000002F447F90] [C000000000025E84] .kernel_thread+0x4c/0x68
    Unable to handle kernel paging request for <7>PCI: Enabling device: (0002:41:01.1), cmd 143
    data at address 0x000001b8
    Faulting instruction address: 0xd0000000000698e4
    sym1: <1010-66> rev 0x1 at pci 0002:41:01.1 irq 216
    sym1: No NVRAM, ID 7, Fast-80, LVD, parity checking
    sym1: SCSI BUS has been reset.
    scsi2 : sym-2.2.2
    cpu 0x0: Vector: 300 (Data Access) at [c00000002f447a30]
        pc: d0000000000698e4: .scsi_run_queue+0x2c/0x218 [scsi_mod]
        lr: d00000000006a904: .scsi_run_host_queues+0x28/0x5c [scsi_mod]
        sp: c00000002f447cb0
       msr: 9000000000009032
       dar: 1b8
     dsisr: 40000000
      current = 0xc0000000045fecd0
      paca    = 0xc00000000048ee80
        pid   = 1123, comm = scsi_eh_1
    enter ? for help
    [c00000002f447d60] d00000000006a904 .scsi_run_host_queues+0x28/0x5c [scsi_mod]
    [c00000002f447df0] d000000000069054 .scsi_error_handler+0xdb4/0xe44 [scsi_mod]
    [c00000002f447ee0] c00000000007b4e0 .kthread+0x128/0x178
    [c00000002f447f90] c000000000025e84 .kernel_thread+0x4c/0x68
    
    Signed-off-by: Brian King <brking@us.ibm.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 68e0d7dbe6ce..bf5191f6aaa1 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2037,6 +2037,9 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 
 	case SDEV_DEL:
 		switch (oldstate) {
+		case SDEV_CREATED:
+		case SDEV_RUNNING:
+		case SDEV_OFFLINE:
 		case SDEV_CANCEL:
 			break;
 		default:

commit 9ea7290902abcf22f796e9aeae4dc2e71d3f7e67
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Fri Jun 23 14:25:34 2006 -0400

    [SCSI] SCSI core: Allow QUIESCE -> CANCEL sdev transition
    
    We have to be able to remove SCSI devices even when they are suspended, so
    QUIESCE -> CANCEL must be a legal state transition.  This patch (as727)
    adds the transition to the state machine.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4c4add53d69b..68e0d7dbe6ce 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2026,6 +2026,7 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 		switch (oldstate) {
 		case SDEV_CREATED:
 		case SDEV_RUNNING:
+		case SDEV_QUIESCE:
 		case SDEV_OFFLINE:
 		case SDEV_BLOCK:
 			break;

commit 03aba2f79594ca94d159c8bab454de9bcc385b76
Author: Luben Tuikov <ltuikov@yahoo.com>
Date:   Fri Jun 23 09:39:09 2006 -0700

    [SCSI] sd/scsi_lib simplify sd_rw_intr and scsi_io_completion
    
    This patch simplifies "good_bytes" computation in sd_rw_intr().
    sd: "good_bytes" computation is always done in terms of the resolution
    of the device's medium, since after that it is the number of good bytes
    we pass around and other layers/contexts (as opposed ot sd) can translate
    that to their own resolution (block layer:512).  It also makes
    scsi_io_completion() processing more straightforward, eliminating the
    3rd argument to the function.
    
    It also fixes a couple of bugs like not checking return value,
    using "break" instead of "return;", etc.
    
    I've been running with this patch for some time now on a
    test (do-it-all) system.
    
    Signed-off-by: Luben Tuikov <ltuikov@yahoo.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 3d04a9f386ac..4c4add53d69b 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -855,8 +855,7 @@ static void scsi_release_buffers(struct scsi_cmnd *cmd)
  *		b) We can just use scsi_requeue_command() here.  This would
  *		   be used if we just wanted to retry, for example.
  */
-void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
-			unsigned int block_bytes)
+void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
 {
 	int result = cmd->result;
 	int this_count = cmd->bufflen;
@@ -921,87 +920,72 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 	 * Next deal with any sectors which we were able to correctly
 	 * handle.
 	 */
-	if (good_bytes >= 0) {
-		SCSI_LOG_HLCOMPLETE(1, printk("%ld sectors total, %d bytes done.\n",
+	if (good_bytes > 0) {
+		SCSI_LOG_HLCOMPLETE(1, printk("%ld sectors total, "
+					      "%d bytes done.\n",
 					      req->nr_sectors, good_bytes));
 		SCSI_LOG_HLCOMPLETE(1, printk("use_sg is %d\n", cmd->use_sg));
 
 		if (clear_errors)
 			req->errors = 0;
-		/*
-		 * If multiple sectors are requested in one buffer, then
-		 * they will have been finished off by the first command.
-		 * If not, then we have a multi-buffer command.
-		 *
-		 * If block_bytes != 0, it means we had a medium error
-		 * of some sort, and that we want to mark some number of
-		 * sectors as not uptodate.  Thus we want to inhibit
-		 * requeueing right here - we will requeue down below
-		 * when we handle the bad sectors.
-		 */
 
-		/*
-		 * If the command completed without error, then either
-		 * finish off the rest of the command, or start a new one.
+		/* A number of bytes were successfully read.  If there
+		 * is leftovers and there is some kind of error
+		 * (result != 0), retry the rest.
 		 */
-		if (scsi_end_request(cmd, 1, good_bytes, result == 0) == NULL)
+		if (scsi_end_request(cmd, 1, good_bytes, !!result) == NULL)
 			return;
 	}
-	/*
-	 * Now, if we were good little boys and girls, Santa left us a request
-	 * sense buffer.  We can extract information from this, so we
-	 * can choose a block to remap, etc.
+
+	/* good_bytes = 0, or (inclusive) there were leftovers and
+	 * result = 0, so scsi_end_request couldn't retry.
 	 */
 	if (sense_valid && !sense_deferred) {
 		switch (sshdr.sense_key) {
 		case UNIT_ATTENTION:
 			if (cmd->device->removable) {
-				/* detected disc change.  set a bit 
+				/* Detected disc change.  Set a bit
 				 * and quietly refuse further access.
 				 */
 				cmd->device->changed = 1;
-				scsi_end_request(cmd, 0,
-						this_count, 1);
+				scsi_end_request(cmd, 0, this_count, 1);
 				return;
 			} else {
-				/*
-				* Must have been a power glitch, or a
-				* bus reset.  Could not have been a
-				* media change, so we just retry the
-				* request and see what happens.  
-				*/
+				/* Must have been a power glitch, or a
+				 * bus reset.  Could not have been a
+				 * media change, so we just retry the
+				 * request and see what happens.
+				 */
 				scsi_requeue_command(q, cmd);
 				return;
 			}
 			break;
 		case ILLEGAL_REQUEST:
-			/*
-		 	* If we had an ILLEGAL REQUEST returned, then we may
-		 	* have performed an unsupported command.  The only
-		 	* thing this should be would be a ten byte read where
-			* only a six byte read was supported.  Also, on a
-			* system where READ CAPACITY failed, we may have read
-			* past the end of the disk.
-		 	*/
+			/* If we had an ILLEGAL REQUEST returned, then
+			 * we may have performed an unsupported
+			 * command.  The only thing this should be
+			 * would be a ten byte read where only a six
+			 * byte read was supported.  Also, on a system
+			 * where READ CAPACITY failed, we may have
+			 * read past the end of the disk.
+			 */
 			if ((cmd->device->use_10_for_rw &&
 			    sshdr.asc == 0x20 && sshdr.ascq == 0x00) &&
 			    (cmd->cmnd[0] == READ_10 ||
 			     cmd->cmnd[0] == WRITE_10)) {
 				cmd->device->use_10_for_rw = 0;
-				/*
-				 * This will cause a retry with a 6-byte
-				 * command.
+				/* This will cause a retry with a
+				 * 6-byte command.
 				 */
 				scsi_requeue_command(q, cmd);
-				result = 0;
+				return;
 			} else {
 				scsi_end_request(cmd, 0, this_count, 1);
 				return;
 			}
 			break;
 		case NOT_READY:
-			/*
-			 * If the device is in the process of becoming
+			/* If the device is in the process of becoming
 			 * ready, or has a temporary blockage, retry.
 			 */
 			if (sshdr.asc == 0x04) {
@@ -1021,7 +1005,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 			}
 			if (!(req->flags & REQ_QUIET)) {
 				scmd_printk(KERN_INFO, cmd,
-					   "Device not ready: ");
+					    "Device not ready: ");
 				scsi_print_sense_hdr("", &sshdr);
 			}
 			scsi_end_request(cmd, 0, this_count, 1);
@@ -1029,21 +1013,21 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 		case VOLUME_OVERFLOW:
 			if (!(req->flags & REQ_QUIET)) {
 				scmd_printk(KERN_INFO, cmd,
-					   "Volume overflow, CDB: ");
+					    "Volume overflow, CDB: ");
 				__scsi_print_command(cmd->data_cmnd);
 				scsi_print_sense("", cmd);
 			}
-			scsi_end_request(cmd, 0, block_bytes, 1);
+			/* See SSC3rXX or current. */
+			scsi_end_request(cmd, 0, this_count, 1);
 			return;
 		default:
 			break;
 		}
-	}			/* driver byte != 0 */
+	}
 	if (host_byte(result) == DID_RESET) {
-		/*
-		 * Third party bus reset or reset for error
-		 * recovery reasons.  Just retry the request
-		 * and see what happens.  
+		/* Third party bus reset or reset for error recovery
+		 * reasons.  Just retry the request and see what
+		 * happens.
 		 */
 		scsi_requeue_command(q, cmd);
 		return;
@@ -1051,21 +1035,13 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 	if (result) {
 		if (!(req->flags & REQ_QUIET)) {
 			scmd_printk(KERN_INFO, cmd,
-				   "SCSI error: return code = 0x%x\n", result);
-
+				    "SCSI error: return code = 0x%08x\n",
+				    result);
 			if (driver_byte(result) & DRIVER_SENSE)
 				scsi_print_sense("", cmd);
 		}
-		/*
-		 * Mark a single buffer as not uptodate.  Queue the remainder.
-		 * We sometimes get this cruft in the event that a medium error
-		 * isn't properly reported.
-		 */
-		block_bytes = req->hard_cur_sectors << 9;
-		if (!block_bytes)
-			block_bytes = req->data_len;
-		scsi_end_request(cmd, 0, block_bytes, 1);
 	}
+	scsi_end_request(cmd, 0, this_count, !result);
 }
 EXPORT_SYMBOL(scsi_io_completion);
 
@@ -1169,7 +1145,7 @@ static void scsi_blk_pc_done(struct scsi_cmnd *cmd)
 	 * successfully. Since this is a REQ_BLOCK_PC command the
 	 * caller should check the request's errors value
 	 */
-	scsi_io_completion(cmd, cmd->bufflen, 0);
+	scsi_io_completion(cmd, cmd->bufflen);
 }
 
 static void scsi_setup_blk_pc_cmnd(struct scsi_cmnd *cmd)

commit 71d530cd1b6d97094481002a04c77fea1c8e1c22
Merge: d7a80dad2fe1 d588fcbe5a7b
Author: Jeff Garzik <jeff@garzik.org>
Date:   Thu Jun 22 22:11:56 2006 -0400

    Merge branch 'master' into upstream
    
    Conflicts:
    
            drivers/scsi/libata-core.c
            drivers/scsi/libata-scsi.c
            include/linux/pci_ids.h

commit fec69a97489f961026e24536dbb7b86ac663948c
Merge: 1049cb478783 2f9719b61e1f
Author: Jeff Garzik <jeff@garzik.org>
Date:   Sun Jun 11 23:04:37 2006 -0400

    Merge branch 'upstream-fixes' into upstream
    
    Conflicts:
    
            drivers/scsi/sata_sil24.c

commit beb40487508290f5d6565598c60a3f44261beef2
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 10 18:01:03 2006 +0200

    [SCSI] remove scsi_request infrastructure
    
    With Achim patch the last user (gdth) is switched away from scsi_request
    so we an kill it now.  Also disables some code in i2o_scsi that was
    broken since the sg driver stopped using scsi_requests.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index bdce9d1f5b71..3302d8068c41 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -19,12 +19,12 @@
 #include <linux/hardirq.h>
 
 #include <scsi/scsi.h>
+#include <scsi/scsi_cmnd.h>
 #include <scsi/scsi_dbg.h>
 #include <scsi/scsi_device.h>
 #include <scsi/scsi_driver.h>
 #include <scsi/scsi_eh.h>
 #include <scsi/scsi_host.h>
-#include <scsi/scsi_request.h>
 
 #include "scsi_priv.h"
 #include "scsi_logging.h"
@@ -83,7 +83,7 @@ static void scsi_unprep_request(struct request *req)
 	struct scsi_cmnd *cmd = req->special;
 
 	req->flags &= ~REQ_DONTPREP;
-	req->special = (req->flags & REQ_SPECIAL) ? cmd->sc_request : NULL;
+	req->special = NULL;
 
 	scsi_put_command(cmd);
 }
@@ -161,72 +161,6 @@ int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 	return 0;
 }
 
-/*
- * Function:    scsi_do_req
- *
- * Purpose:     Queue a SCSI request
- *
- * Arguments:   sreq	  - command descriptor.
- *              cmnd      - actual SCSI command to be performed.
- *              buffer    - data buffer.
- *              bufflen   - size of data buffer.
- *              done      - completion function to be run.
- *              timeout   - how long to let it run before timeout.
- *              retries   - number of retries we allow.
- *
- * Lock status: No locks held upon entry.
- *
- * Returns:     Nothing.
- *
- * Notes:	This function is only used for queueing requests for things
- *		like ioctls and character device requests - this is because
- *		we essentially just inject a request into the queue for the
- *		device.
- *
- *		In order to support the scsi_device_quiesce function, we
- *		now inject requests on the *head* of the device queue
- *		rather than the tail.
- */
-void scsi_do_req(struct scsi_request *sreq, const void *cmnd,
-		 void *buffer, unsigned bufflen,
-		 void (*done)(struct scsi_cmnd *),
-		 int timeout, int retries)
-{
-	/*
-	 * If the upper level driver is reusing these things, then
-	 * we should release the low-level block now.  Another one will
-	 * be allocated later when this request is getting queued.
-	 */
-	__scsi_release_request(sreq);
-
-	/*
-	 * Our own function scsi_done (which marks the host as not busy,
-	 * disables the timeout counter, etc) will be called by us or by the
-	 * scsi_hosts[host].queuecommand() function needs to also call
-	 * the completion function for the high level driver.
-	 */
-	memcpy(sreq->sr_cmnd, cmnd, sizeof(sreq->sr_cmnd));
-	sreq->sr_bufflen = bufflen;
-	sreq->sr_buffer = buffer;
-	sreq->sr_allowed = retries;
-	sreq->sr_done = done;
-	sreq->sr_timeout_per_command = timeout;
-
-	if (sreq->sr_cmd_len == 0)
-		sreq->sr_cmd_len = COMMAND_SIZE(sreq->sr_cmnd[0]);
-
-	/*
-	 * head injection *required* here otherwise quiesce won't work
-	 *
-	 * Because users of this function are apt to reuse requests with no
-	 * modification, we have to sanitise the request flags here
-	 */
-	sreq->sr_request->flags &= ~REQ_DONTPREP;
-	blk_insert_request(sreq->sr_device->request_queue, sreq->sr_request,
-		       	   1, sreq);
-}
-EXPORT_SYMBOL(scsi_do_req);
-
 /**
  * scsi_execute - insert request and wait for the result
  * @sdev:	scsi device
@@ -1300,15 +1234,7 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 	 * at request->cmd, as this tells us the real story.
 	 */
 	if (req->flags & REQ_SPECIAL && req->special) {
-		struct scsi_request *sreq = req->special;
-
-		if (sreq->sr_magic == SCSI_REQ_MAGIC) {
-			cmd = scsi_get_command(sreq->sr_device, GFP_ATOMIC);
-			if (unlikely(!cmd))
-				goto defer;
-			scsi_init_cmd_from_req(cmd, sreq);
-		} else
-			cmd = req->special;
+		cmd = req->special;
 	} else if (req->flags & (REQ_CMD | REQ_BLOCK_PC)) {
 
 		if(unlikely(specials_only) && !(req->flags & REQ_SPECIAL)) {

commit f0cd91a68acdc9b49d7f6738b514a426da627649
Merge: 60eef25701d2 128e6ced247c
Author: James Bottomley <jejb@mulgrave.il.steeleye.com>
Date:   Sat Jun 10 13:47:26 2006 -0500

    Merge ../linux-2.6

commit 6391a11375de5e2bb1eb8481e54619761dc65d9f
Author: Tobias Klauser <tklauser@nuerscht.ch>
Date:   Thu Jun 8 22:23:48 2006 -0700

    [SCSI] drivers/scsi: Use ARRAY_SIZE macro
    
    Use ARRAY_SIZE macro instead of sizeof(x)/sizeof(x[0]) and remove
    duplicates of the macro.
    
    Signed-off-by: Tobias Klauser <tklauser@nuerscht.ch>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 68d413c444f9..3ca7b9d3086c 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -30,7 +30,7 @@
 #include "scsi_logging.h"
 
 
-#define SG_MEMPOOL_NR		(sizeof(scsi_sg_pools)/sizeof(struct scsi_host_sg_pool))
+#define SG_MEMPOOL_NR		ARRAY_SIZE(scsi_sg_pools)
 #define SG_MEMPOOL_SIZE		32
 
 struct scsi_host_sg_pool {

commit f52359622fa25783cf1a08c0772048d2ed1a7434
Author: Bryan Holty <lgeek@frontiernet.net>
Date:   Wed Mar 22 06:35:39 2006 -0600

    [SCSI] scsi_lib.c: properly count the number of pages in scsi_req_map_sg()
    
    The calculation of nr_pages in scsi_req_map_sg() doesn't account for
    the fact that the first page could have an offset that pushes the end
    of the buffer onto a new page.
    
    Signed-off-by: Bryan Holty <lgeek@frontiernet.net>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 764a8b375ead..faee4757c03a 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -367,7 +367,7 @@ static int scsi_req_map_sg(struct request *rq, struct scatterlist *sgl,
 			   int nsegs, unsigned bufflen, gfp_t gfp)
 {
 	struct request_queue *q = rq->q;
-	int nr_pages = (bufflen + PAGE_SIZE - 1) >> PAGE_SHIFT;
+	int nr_pages = (bufflen + sgl[0].offset + PAGE_SIZE - 1) >> PAGE_SHIFT;
 	unsigned int data_len = 0, len, bytes, off;
 	struct page *page;
 	struct bio *bio = NULL;

commit efa6e7e9d40fe01406d889a5bed62f2e0da49bff
Merge: 5006ecc2d507 aee10a03eb3e
Author: Jeff Garzik <jeff@garzik.org>
Date:   Mon May 15 11:26:53 2006 -0400

    Merge branch 'for-jeff' of git://htj.dyndns.org/libata-tj into tejun-merge

commit ee7863bc68fa6ad6fe7cfcc0e5ebe9efe0c0664e
Author: Tejun Heo <htejun@gmail.com>
Date:   Mon May 15 20:57:20 2006 +0900

    [PATCH] SCSI: implement shost->host_eh_scheduled
    
    libata needs to invoke EH without scmd.  This patch adds
    shost->host_eh_scheduled to implement such behavior.
    
    Currently the only user of this feature is libata and no general
    interface is defined.  This patch simply adds handling for
    host_eh_scheduled where needed and exports scsi_eh_wakeup() to
    modules.  The rest is upto libata.  This is the result of the
    following discussion.
    
    http://thread.gmane.org/gmane.linux.scsi/23853/focus=9760
    
    In short, SCSI host is not supposed to know about exceptions unrelated
    to specific device or command.  Such exceptions should be handled by
    transport layer proper.  However, the distinction is not essential to
    ATA and libata is planning to depart from SCSI, so, for the time
    being, libata will be using SCSI EH to handle such exceptions.
    
    Signed-off-by: Tejun Heo <htejun@gmail.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 7b0f9a3810d2..c55d195b6f4f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -566,7 +566,7 @@ void scsi_device_unbusy(struct scsi_device *sdev)
 	spin_lock_irqsave(shost->host_lock, flags);
 	shost->host_busy--;
 	if (unlikely(scsi_host_in_recovery(shost) &&
-		     shost->host_failed))
+		     (shost->host_failed || shost->host_eh_scheduled)))
 		scsi_eh_wakeup(shost);
 	spin_unlock(shost->host_lock);
 	spin_lock(sdev->request_queue->queue_lock);

commit f3e93f735321ea75108b41cb654c16f92d3f264c
Author: James Bottomley <James.Bottomley@steeleye.com>
Date:   Tue Apr 25 16:48:30 2006 -0500

    [SCSI] Fix DVD burning issues.
    
    Some pioneer DVDs are apparently returning odd "not ready" status
    codes that the mid-layer doesn't recognise and so passes back to the
    user as errors.
    
    This patch overhauls our not-ready handling and adds transparent retries for:
    
    format in progress
    rebuild in progress
    recalculation in progress
    operation in progress
    Long write in progress
    self test in progress
    
    The Pioneer was actually returning "long write in progress"
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 7b0f9a3810d2..764a8b375ead 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1067,16 +1067,29 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 			break;
 		case NOT_READY:
 			/*
-			 * If the device is in the process of becoming ready,
-			 * retry.
+			 * If the device is in the process of becoming
+			 * ready, or has a temporary blockage, retry.
 			 */
-			if (sshdr.asc == 0x04 && sshdr.ascq == 0x01) {
-				scsi_requeue_command(q, cmd);
-				return;
+			if (sshdr.asc == 0x04) {
+				switch (sshdr.ascq) {
+				case 0x01: /* becoming ready */
+				case 0x04: /* format in progress */
+				case 0x05: /* rebuild in progress */
+				case 0x06: /* recalculation in progress */
+				case 0x07: /* operation in progress */
+				case 0x08: /* Long write in progress */
+				case 0x09: /* self test in progress */
+					scsi_requeue_command(q, cmd);
+					return;
+				default:
+					break;
+				}
 			}
-			if (!(req->flags & REQ_QUIET))
+			if (!(req->flags & REQ_QUIET)) {
 				scmd_printk(KERN_INFO, cmd,
-					   "Device not ready.\n");
+					   "Device not ready: ");
+				scsi_print_sense_hdr("", &sshdr);
+			}
 			scsi_end_request(cmd, 0, this_count, 1);
 			return;
 		case VOLUME_OVERFLOW:

commit 169e1a2a8a789fa84254695ec6a56fc410bb19a9
Author: Andrew Morton <akpm@osdl.org>
Date:   Tue Apr 18 21:09:08 2006 -0700

    [SCSI] scsi_lib.c: fix warning in scsi_kmap_atomic_sg
    
    drivers/scsi/scsi_lib.c: In function `scsi_kmap_atomic_sg':
    drivers/scsi/scsi_lib.c:2394: warning: unsigned int format, different type arg (arg 3)
    drivers/scsi/scsi_lib.c:2394: warning: unsigned int format, different type arg (arg 4)
    
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 57453ca09700..68d413c444f9 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2375,7 +2375,8 @@ void *scsi_kmap_atomic_sg(struct scatterlist *sg, int sg_count,
 	}
 
 	if (unlikely(i == sg_count)) {
-		printk(KERN_ERR "%s: Bytes in sg: %u, requested offset %u, elements %d\n",
+		printk(KERN_ERR "%s: Bytes in sg: %zu, requested offset %zu, "
+			"elements %d\n",
 		       __FUNCTION__, sg_len, *offset, sg_count);
 		WARN_ON(1);
 		return NULL;

commit cdb8c2a6d848deb9eeefffff42974478fbb51b8c
Author: Guennadi Liakhovetski <g.liakhovetski@gmx.de>
Date:   Sun Apr 2 21:57:43 2006 +0200

    [SCSI] dc395x: dynamically map scatter-gather for PIO
    
    The current dc395x driver uses PIO to transfer up to 4 bytes which do not
    get transferred by DMA (under unclear circumstances). For this the driver
    uses page_address() which is broken on highmem. Apart from this the
    actual calculation of the virtual address is wrong (even without highmem).
    So, e.g., for reading it reads bytes from the driver to a wrong address
    and returns wrong data, I guess, for writing it would just output random
    data to the device.
    
    The proper fix, as suggested by many, is to dynamically map data using
    kmap_atomic(page, KM_BIO_SRC_IRQ) / kunmap_atomic(virt). The reason why it
    has not been done until now, although I've done some preliminary patches
    more than a year ago was that nobody interested in fixing this problem was
    able to reliably reproduce it. Now it changed - with the help from
    Sebastian Frei (CC'ed) I was able to trigger the PIO path. Thus, I was
    also able to test and debug it.
    
    There are 4 cases when PIO is used in dc395x - data-in / -out with and
    without scatter-gather. I was able to reproduce and test only data-in with
    and without SG. So, the data-out path is still untested, but it is also
    somewhat simpler than the data-in. Fredrik Roubert (also CC'ed) also had
    PIO triggering on his system, and in his case it was data-out without SG.
    It would be great if he could test the attached patch on his system, but
    even if he cannot, I would still request to apply the patch and just wait
    if anybody cries...
    
    Implementation: I put 2 new functions in scsi_lib.c and their declarations
    in scsi_cmnd.h. I exported them without _GPL, although, I don't feel
    strongly about that - not many drivers are likely to use them. But there
    is at least one more - I want to use them in tmscsim.c. Whether these are
    the right files for the functions and their declarations - not sure
    either. Actually, they are not scsi-specific, so, might go somewhere
    around other scattergather magic? They are not platform specific either,
    and most SG functions are defined under arch/*/... As these issues were
    discussed previously there were some more routines suggested to manipulate
    scattergather buffers, I think, some of them were needed around
    crypto code... So, might be a common place reasonable, like
    lib/scattergather.c? I am open here.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 7b0f9a3810d2..57453ca09700 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2350,3 +2350,60 @@ scsi_target_unblock(struct device *dev)
 		device_for_each_child(dev, NULL, target_unblock);
 }
 EXPORT_SYMBOL_GPL(scsi_target_unblock);
+
+/**
+ * scsi_kmap_atomic_sg - find and atomically map an sg-elemnt
+ * @sg:		scatter-gather list
+ * @sg_count:	number of segments in sg
+ * @offset:	offset in bytes into sg, on return offset into the mapped area
+ * @len:	bytes to map, on return number of bytes mapped
+ *
+ * Returns virtual address of the start of the mapped page
+ */
+void *scsi_kmap_atomic_sg(struct scatterlist *sg, int sg_count,
+			  size_t *offset, size_t *len)
+{
+	int i;
+	size_t sg_len = 0, len_complete = 0;
+	struct page *page;
+
+	for (i = 0; i < sg_count; i++) {
+		len_complete = sg_len; /* Complete sg-entries */
+		sg_len += sg[i].length;
+		if (sg_len > *offset)
+			break;
+	}
+
+	if (unlikely(i == sg_count)) {
+		printk(KERN_ERR "%s: Bytes in sg: %u, requested offset %u, elements %d\n",
+		       __FUNCTION__, sg_len, *offset, sg_count);
+		WARN_ON(1);
+		return NULL;
+	}
+
+	/* Offset starting from the beginning of first page in this sg-entry */
+	*offset = *offset - len_complete + sg[i].offset;
+
+	/* Assumption: contiguous pages can be accessed as "page + i" */
+	page = nth_page(sg[i].page, (*offset >> PAGE_SHIFT));
+	*offset &= ~PAGE_MASK;
+
+	/* Bytes in this sg-entry from *offset to the end of the page */
+	sg_len = PAGE_SIZE - *offset;
+	if (*len > sg_len)
+		*len = sg_len;
+
+	return kmap_atomic(page, KM_BIO_SRC_IRQ);
+}
+EXPORT_SYMBOL(scsi_kmap_atomic_sg);
+
+/**
+ * scsi_kunmap_atomic_sg - atomically unmap a virtual address, previously
+ *			   mapped with scsi_kmap_atomic_sg
+ * @virt:	virtual address to be unmapped
+ */
+void scsi_kunmap_atomic_sg(void *virt)
+{
+	kunmap_atomic(virt, KM_BIO_SRC_IRQ);
+}
+EXPORT_SYMBOL(scsi_kunmap_atomic_sg);

commit e36e0c80137af8f012528938dab2970c26d5ec4c
Author: Tejun Heo <htejun@gmail.com>
Date:   Tue Apr 11 17:27:53 2006 +0900

    [SCSI] SCSI: fix scsi_kill_request() busy count handling
    
    scsi_kill_request() completes requests via normal SCSI completion path
    which decrements busy counts; however, requests which get passed to
    scsi_kill_request() aren't holding busy counts and scsi_kill_request()
    don't increment them before invoking completion path resulting in
    incorrect busy counts.  Bump up busy counts before invoking completion
    path.
    
    Signed-off-by: Tejun Heo <htejun@gmail.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 8f010a314a3d..7b0f9a3810d2 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1479,6 +1479,8 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 static void scsi_kill_request(struct request *req, request_queue_t *q)
 {
 	struct scsi_cmnd *cmd = req->special;
+	struct scsi_device *sdev = cmd->device;
+	struct Scsi_Host *shost = sdev->host;
 
 	blkdev_dequeue_request(req);
 
@@ -1491,6 +1493,19 @@ static void scsi_kill_request(struct request *req, request_queue_t *q)
 	scsi_init_cmd_errh(cmd);
 	cmd->result = DID_NO_CONNECT << 16;
 	atomic_inc(&cmd->device->iorequest_cnt);
+
+	/*
+	 * SCSI request completion path will do scsi_device_unbusy(),
+	 * bump busy counts.  To bump the counters, we need to dance
+	 * with the locks as normal issue path does.
+	 */
+	sdev->device_busy++;
+	spin_unlock(sdev->request_queue->queue_lock);
+	spin_lock(shost->host_lock);
+	shost->host_busy++;
+	spin_unlock(shost->host_lock);
+	spin_lock(sdev->request_queue->queue_lock);
+
 	__scsi_done(cmd);
 }
 

commit 93d2341c750cda0df48a6cc67b35fe25f1ec47df
Author: Matthew Dobson <colpatch@us.ibm.com>
Date:   Sun Mar 26 01:37:50 2006 -0800

    [PATCH] mempool: use mempool_create_slab_pool()
    
    Modify well over a dozen mempool users to call mempool_create_slab_pool()
    rather than calling mempool_create() with extra arguments, saving about 30
    lines of code and increasing readability.
    
    Signed-off-by: Matthew Dobson <colpatch@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ede158d08d9d..8f010a314a3d 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1787,9 +1787,8 @@ int __init scsi_init_queue(void)
 					sgp->name);
 		}
 
-		sgp->pool = mempool_create(SG_MEMPOOL_SIZE,
-				mempool_alloc_slab, mempool_free_slab,
-				sgp->slab);
+		sgp->pool = mempool_create_slab_pool(SG_MEMPOOL_SIZE,
+						     sgp->slab);
 		if (!sgp->pool) {
 			printk(KERN_ERR "SCSI: can't init sg mempool %s\n",
 					sgp->name);

commit 5baba830e93732e802dc7e0a362eb730e1917f58
Author: James Bottomley <James.Bottomley@steeleye.com>
Date:   Sat Mar 18 14:10:35 2006 -0600

    [SCSI] add scsi_mode_select to scsi_lib.c
    
    This complements the scsi_mode_sense() function
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9a05076f9cf4..ede158d08d9d 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1811,6 +1811,84 @@ void scsi_exit_queue(void)
 		kmem_cache_destroy(sgp->slab);
 	}
 }
+
+/**
+ *	scsi_mode_select - issue a mode select
+ *	@sdev:	SCSI device to be queried
+ *	@pf:	Page format bit (1 == standard, 0 == vendor specific)
+ *	@sp:	Save page bit (0 == don't save, 1 == save)
+ *	@modepage: mode page being requested
+ *	@buffer: request buffer (may not be smaller than eight bytes)
+ *	@len:	length of request buffer.
+ *	@timeout: command timeout
+ *	@retries: number of retries before failing
+ *	@data: returns a structure abstracting the mode header data
+ *	@sense: place to put sense data (or NULL if no sense to be collected).
+ *		must be SCSI_SENSE_BUFFERSIZE big.
+ *
+ *	Returns zero if successful; negative error number or scsi
+ *	status on error
+ *
+ */
+int
+scsi_mode_select(struct scsi_device *sdev, int pf, int sp, int modepage,
+		 unsigned char *buffer, int len, int timeout, int retries,
+		 struct scsi_mode_data *data, struct scsi_sense_hdr *sshdr)
+{
+	unsigned char cmd[10];
+	unsigned char *real_buffer;
+	int ret;
+
+	memset(cmd, 0, sizeof(cmd));
+	cmd[1] = (pf ? 0x10 : 0) | (sp ? 0x01 : 0);
+
+	if (sdev->use_10_for_ms) {
+		if (len > 65535)
+			return -EINVAL;
+		real_buffer = kmalloc(8 + len, GFP_KERNEL);
+		if (!real_buffer)
+			return -ENOMEM;
+		memcpy(real_buffer + 8, buffer, len);
+		len += 8;
+		real_buffer[0] = 0;
+		real_buffer[1] = 0;
+		real_buffer[2] = data->medium_type;
+		real_buffer[3] = data->device_specific;
+		real_buffer[4] = data->longlba ? 0x01 : 0;
+		real_buffer[5] = 0;
+		real_buffer[6] = data->block_descriptor_length >> 8;
+		real_buffer[7] = data->block_descriptor_length;
+
+		cmd[0] = MODE_SELECT_10;
+		cmd[7] = len >> 8;
+		cmd[8] = len;
+	} else {
+		if (len > 255 || data->block_descriptor_length > 255 ||
+		    data->longlba)
+			return -EINVAL;
+
+		real_buffer = kmalloc(4 + len, GFP_KERNEL);
+		if (!real_buffer)
+			return -ENOMEM;
+		memcpy(real_buffer + 4, buffer, len);
+		len += 4;
+		real_buffer[0] = 0;
+		real_buffer[1] = data->medium_type;
+		real_buffer[2] = data->device_specific;
+		real_buffer[3] = data->block_descriptor_length;
+		
+
+		cmd[0] = MODE_SELECT;
+		cmd[4] = len;
+	}
+
+	ret = scsi_execute_req(sdev, cmd, DMA_TO_DEVICE, real_buffer, len,
+			       sshdr, timeout, retries);
+	kfree(real_buffer);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(scsi_mode_select);
+
 /**
  *	scsi_mode_sense - issue a mode sense, falling back from 10 to 
  *		six bytes if necessary.
@@ -1832,7 +1910,8 @@ void scsi_exit_queue(void)
 int
 scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
 		  unsigned char *buffer, int len, int timeout, int retries,
-		  struct scsi_mode_data *data, struct scsi_sense_hdr *sshdr) {
+		  struct scsi_mode_data *data, struct scsi_sense_hdr *sshdr)
+{
 	unsigned char cmd[12];
 	int use_10_for_ms;
 	int header_length;

commit f33b5d783b4f56be5ace6a1c98fb5f76b2d2d07d
Merge: e935d5da8e5d 67963132638e
Author: James Bottomley <jejb@mulgrave.il.steeleye.com>
Date:   Tue Mar 14 14:18:01 2006 -0600

    Merge ../linux-2.6

commit ffedb4522571ac170f941678d138a31bc0884ab4
Author: James Bottomley <James.Bottomley@steeleye.com>
Date:   Thu Feb 23 14:27:18 2006 -0600

    [SCSI] fix scsi process problems and clean up the target reap issues
    
    In order to use the new execute_in_process_context() API, you have to
    provide it with the work storage, which I do in SCSI in scsi_device and
    scsi_target, but which also means that we can no longer queue up the
    target reaps, so instead I moved the target to a state model which
    allows target_alloc to detect if we've received a dying target and wait
    for it to be gone.  Hopefully, this should also solve the target
    namespace race.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index eab303d148d8..3042520c413c 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -2257,61 +2257,3 @@ scsi_target_unblock(struct device *dev)
 		device_for_each_child(dev, NULL, target_unblock);
 }
 EXPORT_SYMBOL_GPL(scsi_target_unblock);
-
-
-struct work_queue_work {
-	struct work_struct	work;
-	void			(*fn)(void *);
-	void			*data;
-};
-
-static void execute_in_process_context_work(void *data)
-{
-	void (*fn)(void *data);
-	struct work_queue_work *wqw = data;
-
-	fn = wqw->fn;
-	data = wqw->data;
-
-	kfree(wqw);
-
-	fn(data);
-}
-
-/**
- * scsi_execute_in_process_context - reliably execute the routine with user context
- * @fn:		the function to execute
- * @data:	data to pass to the function
- *
- * Executes the function immediately if process context is available,
- * otherwise schedules the function for delayed execution.
- *
- * Returns:	0 - function was executed
- *		1 - function was scheduled for execution
- *		<0 - error
- */
-int scsi_execute_in_process_context(void (*fn)(void *data), void *data)
-{
-	struct work_queue_work *wqw;
-
-	if (!in_interrupt()) {
-		fn(data);
-		return 0;
-	}
-
-	wqw = kmalloc(sizeof(struct work_queue_work), GFP_ATOMIC);
-
-	if (unlikely(!wqw)) {
-		printk(KERN_ERR "Failed to allocate memory\n");
-		WARN_ON(1);
-		return -ENOMEM;
-	}
-
-	INIT_WORK(&wqw->work, execute_in_process_context_work, wqw);
-	wqw->fn = fn;
-	wqw->data = data;
-	schedule_work(&wqw->work);
-
-	return 1;
-}
-EXPORT_SYMBOL_GPL(scsi_execute_in_process_context);

commit 6d73c8514da241c6b1b8d710a6294786604d7142
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Thu Feb 23 02:03:16 2006 +0100

    [SCSI] scsi_lib: fix recognition of cache type of Initio SBP-2 bridges
    
    Regardless what mode page was asked for, Initio INIC-14x0 and
    INIC-2430 always return page 6 without mode page headers.  Try to
    recognise this as a special case in scsi_mode_sense and setting the
    mode sense headers accordingly.
    
    Signed-off-by: Al Viro <viro@ftp.linux.org.uk>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1fe4fd83e305..eab303d148d8 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1892,8 +1892,16 @@ scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
 	}
 
 	if(scsi_status_is_good(result)) {
-		data->header_length = header_length;
-		if(use_10_for_ms) {
+		if (unlikely(buffer[0] == 0x86 && buffer[1] == 0x0b &&
+			     (modepage == 6 || modepage == 8))) {
+			/* Initio breakage? */
+			header_length = 0;
+			data->length = 13;
+			data->medium_type = 0;
+			data->device_specific = 0;
+			data->longlba = 0;
+			data->block_descriptor_length = 0;
+		} else if(use_10_for_ms) {
 			data->length = buffer[0]*256 + buffer[1] + 2;
 			data->medium_type = buffer[2];
 			data->device_specific = buffer[3];
@@ -1906,6 +1914,7 @@ scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
 			data->device_specific = buffer[2];
 			data->block_descriptor_length = buffer[3];
 		}
+		data->header_length = header_length;
 	}
 
 	return result;

commit 24669f75a3231fa37444977c92d1f4838bec1233
Author: Jes Sorensen <jes@sgi.com>
Date:   Mon Jan 16 10:31:18 2006 -0500

    [SCSI] SCSI core kmalloc2kzalloc
    
    Change the core SCSI code to use kzalloc rather than kmalloc+memset
    where possible.
    
    Signed-off-by: Jes Sorensen <jes@sgi.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4362dcde74af..1fe4fd83e305 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -286,13 +286,12 @@ int scsi_execute_req(struct scsi_device *sdev, const unsigned char *cmd,
 	int result;
 	
 	if (sshdr) {
-		sense = kmalloc(SCSI_SENSE_BUFFERSIZE, GFP_NOIO);
+		sense = kzalloc(SCSI_SENSE_BUFFERSIZE, GFP_NOIO);
 		if (!sense)
 			return DRIVER_ERROR << 24;
-		memset(sense, 0, SCSI_SENSE_BUFFERSIZE);
 	}
 	result = scsi_execute(sdev, cmd, data_direction, buffer, bufflen,
-				  sense, timeout, retries, 0);
+			      sense, timeout, retries, 0);
 	if (sshdr)
 		scsi_normalize_sense(sense, SCSI_SENSE_BUFFERSIZE, sshdr);
 

commit 8884efab1516613215816d48132dd724508970bf
Author: Brian King <brking@us.ibm.com>
Date:   Fri Feb 24 17:10:04 2006 -0600

    [SCSI] scsi: scsi command retries off by one fix
    
    Fix up an off by one error in calculating retries for scsi
    commands. This bug was discovered when an SG_IO request
    was sent to scsi core with retries = 0, causing the overall
    timeout check to go off in scsi_softirq_done.
    
    Signed-off-by: Brian King <brking@us.ibm.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4362dcde74af..701a328f7beb 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1498,7 +1498,7 @@ static void scsi_kill_request(struct request *req, request_queue_t *q)
 static void scsi_softirq_done(struct request *rq)
 {
 	struct scsi_cmnd *cmd = rq->completion_data;
-	unsigned long wait_for = cmd->allowed * cmd->timeout_per_command;
+	unsigned long wait_for = (cmd->allowed + 1) * cmd->timeout_per_command;
 	int disposition;
 
 	INIT_LIST_HEAD(&cmd->eh_entry);

commit faead26d7a06605add627f29aee73ba654ce11f9
Author: James Bottomley <James.Bottomley@steeleye.com>
Date:   Tue Feb 14 10:42:07 2006 -0600

    [PATCH] add scsi_execute_in_process_context() API
    
    We have several points in the SCSI stack (primarily for our device
    functions) where we need to guarantee process context, but (given the
    place where the last reference was released) we cannot guarantee this.
    
    This API gets around the issue by executing the function directly if
    the caller has process context, but scheduling a workqueue to execute
    in process context if the caller doesn't have it.  Unfortunately, it
    requires memory allocation in interrupt context, but it's better than
    what we have previously.  The true solution will require a bit of
    re-engineering, so isn't appropriate for 2.6.16.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4a602853a98e..4362dcde74af 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -16,6 +16,7 @@
 #include <linux/init.h>
 #include <linux/pci.h>
 #include <linux/delay.h>
+#include <linux/hardirq.h>
 
 #include <scsi/scsi.h>
 #include <scsi/scsi_dbg.h>
@@ -2248,3 +2249,61 @@ scsi_target_unblock(struct device *dev)
 		device_for_each_child(dev, NULL, target_unblock);
 }
 EXPORT_SYMBOL_GPL(scsi_target_unblock);
+
+
+struct work_queue_work {
+	struct work_struct	work;
+	void			(*fn)(void *);
+	void			*data;
+};
+
+static void execute_in_process_context_work(void *data)
+{
+	void (*fn)(void *data);
+	struct work_queue_work *wqw = data;
+
+	fn = wqw->fn;
+	data = wqw->data;
+
+	kfree(wqw);
+
+	fn(data);
+}
+
+/**
+ * scsi_execute_in_process_context - reliably execute the routine with user context
+ * @fn:		the function to execute
+ * @data:	data to pass to the function
+ *
+ * Executes the function immediately if process context is available,
+ * otherwise schedules the function for delayed execution.
+ *
+ * Returns:	0 - function was executed
+ *		1 - function was scheduled for execution
+ *		<0 - error
+ */
+int scsi_execute_in_process_context(void (*fn)(void *data), void *data)
+{
+	struct work_queue_work *wqw;
+
+	if (!in_interrupt()) {
+		fn(data);
+		return 0;
+	}
+
+	wqw = kmalloc(sizeof(struct work_queue_work), GFP_ATOMIC);
+
+	if (unlikely(!wqw)) {
+		printk(KERN_ERR "Failed to allocate memory\n");
+		WARN_ON(1);
+		return -ENOMEM;
+	}
+
+	INIT_WORK(&wqw->work, execute_in_process_context_work, wqw);
+	wqw->fn = fn;
+	wqw->data = data;
+	schedule_work(&wqw->work);
+
+	return 1;
+}
+EXPORT_SYMBOL_GPL(scsi_execute_in_process_context);

commit bb1d1073a10fdc8547e3eb821ee2488260094b39
Author: brking@us.ibm.com <brking@us.ibm.com>
Date:   Mon Jan 23 15:03:22 2006 -0600

    [SCSI] Prevent scsi_execute_async from guessing cdb length
    
    When the scsi_execute_async interface was added it ended up reducing
    the flexibility of userspace to send arbitrary scsi commands through
    sg using SG_IO. The SG_IO interface allows userspace to specify the
    CDB length. This is now ignored in scsi_execute_async and it is
    guessed using the COMMAND_SIZE macro, which is not always correct,
    particularly for vendor specific commands. This patch adds a cmd_len
    parameter to the scsi_execute_async interface to allow the caller
    to specify the length of the CDB.
    
    Signed-off-by: Brian King <brking@us.ibm.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 3574ba935af8..4a602853a98e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -436,6 +436,7 @@ static int scsi_req_map_sg(struct request *rq, struct scatterlist *sgl,
  * scsi_execute_async - insert request
  * @sdev:	scsi device
  * @cmd:	scsi command
+ * @cmd_len:	length of scsi cdb
  * @data_direction: data direction
  * @buffer:	data buffer (this can be a kernel buffer or scatterlist)
  * @bufflen:	len of buffer
@@ -445,7 +446,7 @@ static int scsi_req_map_sg(struct request *rq, struct scatterlist *sgl,
  * @flags:	or into request flags
  **/
 int scsi_execute_async(struct scsi_device *sdev, const unsigned char *cmd,
-		       int data_direction, void *buffer, unsigned bufflen,
+		       int cmd_len, int data_direction, void *buffer, unsigned bufflen,
 		       int use_sg, int timeout, int retries, void *privdata,
 		       void (*done)(void *, char *, int, int), gfp_t gfp)
 {
@@ -472,7 +473,7 @@ int scsi_execute_async(struct scsi_device *sdev, const unsigned char *cmd,
 	if (err)
 		goto free_req;
 
-	req->cmd_len = COMMAND_SIZE(cmd[0]);
+	req->cmd_len = cmd_len;
 	memcpy(req->cmd, cmd, req->cmd_len);
 	req->sense = sioc->sense;
 	req->sense_len = 0;

commit 776b23a0363d99ca402edc1aba1db8099b747b33
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Jan 6 18:34:07 2006 +0100

    [SCSI] always handle REQ_BLOCK_PC requests in common code
    
    LLDDs should never see REQ_BLOCK_PC requests, we can handle them just
    fine in the core code.  There is a small behaviour change in that some
    check in sr's rw_intr are bypassed, but I consider the old behaviour
    a bug.
    
    Mike found this cleanup opportunity and provdided early patches, so all
    the credit goes to him, even if I redid the patches from scratch beause
    that was easier than forward-porting the old patches.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 00c9bf383e23..3574ba935af8 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1212,7 +1212,7 @@ static int scsi_issue_flush_fn(request_queue_t *q, struct gendisk *disk,
 	return -EOPNOTSUPP;
 }
 
-static void scsi_generic_done(struct scsi_cmnd *cmd)
+static void scsi_blk_pc_done(struct scsi_cmnd *cmd)
 {
 	BUG_ON(!blk_pc_request(cmd->request));
 	/*
@@ -1224,7 +1224,7 @@ static void scsi_generic_done(struct scsi_cmnd *cmd)
 	scsi_io_completion(cmd, cmd->bufflen, 0);
 }
 
-void scsi_setup_blk_pc_cmnd(struct scsi_cmnd *cmd)
+static void scsi_setup_blk_pc_cmnd(struct scsi_cmnd *cmd)
 {
 	struct request *req = cmd->request;
 
@@ -1241,8 +1241,8 @@ void scsi_setup_blk_pc_cmnd(struct scsi_cmnd *cmd)
 	cmd->transfersize = req->data_len;
 	cmd->allowed = req->retries;
 	cmd->timeout_per_command = req->timeout;
+	cmd->done = scsi_blk_pc_done;
 }
-EXPORT_SYMBOL_GPL(scsi_setup_blk_pc_cmnd);
 
 static int scsi_prep_fn(struct request_queue *q, struct request *req)
 {
@@ -1339,7 +1339,6 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 	 * happening now.
 	 */
 	if (req->flags & (REQ_CMD | REQ_BLOCK_PC)) {
-		struct scsi_driver *drv;
 		int ret;
 
 		/*
@@ -1371,16 +1370,17 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 		/*
 		 * Initialize the actual SCSI command for this request.
 		 */
-		if (req->rq_disk) {
+		if (req->flags & REQ_BLOCK_PC) {
+			scsi_setup_blk_pc_cmnd(cmd);
+		} else if (req->rq_disk) {
+			struct scsi_driver *drv;
+
 			drv = *(struct scsi_driver **)req->rq_disk->private_data;
 			if (unlikely(!drv->init_command(cmd))) {
 				scsi_release_buffers(cmd);
 				scsi_put_command(cmd);
 				goto kill;
 			}
-		} else {
-			scsi_setup_blk_pc_cmnd(cmd);
-			cmd->done = scsi_generic_done;
 		}
 	}
 

commit 1aea6434eebd25e532d2e5ddabf2733af4e1ff0b
Author: Jens Axboe <axboe@suse.de>
Date:   Mon Jan 9 16:03:03 2006 +0100

    [SCSI] Kill the SCSI softirq handling
    
    This patch moves the SCSI softirq handling to the block layer version.
    There should be no functional changes.
    
    Signed-off-by: Jens Axboe <axboe@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ba93d6e66d48..00c9bf383e23 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1493,6 +1493,41 @@ static void scsi_kill_request(struct request *req, request_queue_t *q)
 	__scsi_done(cmd);
 }
 
+static void scsi_softirq_done(struct request *rq)
+{
+	struct scsi_cmnd *cmd = rq->completion_data;
+	unsigned long wait_for = cmd->allowed * cmd->timeout_per_command;
+	int disposition;
+
+	INIT_LIST_HEAD(&cmd->eh_entry);
+
+	disposition = scsi_decide_disposition(cmd);
+	if (disposition != SUCCESS &&
+	    time_before(cmd->jiffies_at_alloc + wait_for, jiffies)) {
+		sdev_printk(KERN_ERR, cmd->device,
+			    "timing out command, waited %lus\n",
+			    wait_for/HZ);
+		disposition = SUCCESS;
+	}
+			
+	scsi_log_completion(cmd, disposition);
+
+	switch (disposition) {
+		case SUCCESS:
+			scsi_finish_command(cmd);
+			break;
+		case NEEDS_RETRY:
+			scsi_retry_command(cmd);
+			break;
+		case ADD_TO_MLQUEUE:
+			scsi_queue_insert(cmd, SCSI_MLQUEUE_DEVICE_BUSY);
+			break;
+		default:
+			if (!scsi_eh_scmd_add(cmd, 0))
+				scsi_finish_command(cmd);
+	}
+}
+
 /*
  * Function:    scsi_request_fn()
  *
@@ -1667,6 +1702,7 @@ struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
 	blk_queue_bounce_limit(q, scsi_calculate_bounce_limit(shost));
 	blk_queue_segment_boundary(q, shost->dma_boundary);
 	blk_queue_issue_flush_fn(q, scsi_issue_flush_fn);
+	blk_queue_softirq_done(q, scsi_softirq_done);
 
 	if (!shost->use_clustering)
 		clear_bit(QUEUE_FLAG_CLUSTER, &q->queue_flags);

commit e650c305ec3178818b317dad37a6d9c7fa8ba28d
Author: Jens Axboe <axboe@suse.de>
Date:   Fri Jan 6 12:38:30 2006 +0100

    [SCSI] scsi_end_async() needs to take an uptodate parameter
    
    Signed-off-by: Jens Axboe <axboe@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 7a38b101976c..ba93d6e66d48 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -308,7 +308,7 @@ struct scsi_io_context {
 
 static kmem_cache_t *scsi_io_context_cache;
 
-static void scsi_end_async(struct request *req)
+static void scsi_end_async(struct request *req, int uptodate)
 {
 	struct scsi_io_context *sioc = req->end_io_data;
 

commit 461d4e90c8cd049718884cd17c955e231140d3be
Author: Tejun Heo <htejun@gmail.com>
Date:   Fri Jan 6 09:52:55 2006 +0100

    [BLOCK] update SCSI to use new blk_ordered for barriers
    
    All ordered request related stuff delegated to HLD.  Midlayer
    now doens't deal with ordered setting or prepare_flush
    callback.  sd.c updated to deal with blk_queue_ordered
    setting.  Currently, ordered tag isn't used as SCSI midlayer
    cannot guarantee request ordering.
    
    Signed-off-by: Tejun Heo <htejun@gmail.com>
    Signed-off-by: Jens Axboe <axboe@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 53551f1dfe21..7a38b101976c 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -932,9 +932,6 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 	int sense_valid = 0;
 	int sense_deferred = 0;
 
-	if (blk_complete_barrier_rq(q, req, good_bytes >> 9))
-		return;
-
 	/*
 	 * Free up any indirection buffers we allocated for DMA purposes. 
 	 * For the case of a READ, we need to copy the data out of the
@@ -1199,38 +1196,6 @@ static int scsi_init_io(struct scsi_cmnd *cmd)
 	return BLKPREP_KILL;
 }
 
-static int scsi_prepare_flush_fn(request_queue_t *q, struct request *rq)
-{
-	struct scsi_device *sdev = q->queuedata;
-	struct scsi_driver *drv;
-
-	if (sdev->sdev_state == SDEV_RUNNING) {
-		drv = *(struct scsi_driver **) rq->rq_disk->private_data;
-
-		if (drv->prepare_flush)
-			return drv->prepare_flush(q, rq);
-	}
-
-	return 0;
-}
-
-static void scsi_end_flush_fn(request_queue_t *q, struct request *rq)
-{
-	struct scsi_device *sdev = q->queuedata;
-	struct request *flush_rq = rq->end_io_data;
-	struct scsi_driver *drv;
-
-	if (flush_rq->errors) {
-		printk("scsi: barrier error, disabling flush support\n");
-		blk_queue_ordered(q, QUEUE_ORDERED_NONE);
-	}
-
-	if (sdev->sdev_state == SDEV_RUNNING) {
-		drv = *(struct scsi_driver **) rq->rq_disk->private_data;
-		drv->end_flush(q, rq);
-	}
-}
-
 static int scsi_issue_flush_fn(request_queue_t *q, struct gendisk *disk,
 			       sector_t *error_sector)
 {
@@ -1703,17 +1668,6 @@ struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
 	blk_queue_segment_boundary(q, shost->dma_boundary);
 	blk_queue_issue_flush_fn(q, scsi_issue_flush_fn);
 
-	/*
-	 * ordered tags are superior to flush ordering
-	 */
-	if (shost->ordered_tag)
-		blk_queue_ordered(q, QUEUE_ORDERED_TAG);
-	else if (shost->ordered_flush) {
-		blk_queue_ordered(q, QUEUE_ORDERED_FLUSH);
-		q->prepare_flush_fn = scsi_prepare_flush_fn;
-		q->end_flush_fn = scsi_end_flush_fn;
-	}
-
 	if (!shost->use_clustering)
 		clear_bit(QUEUE_FLAG_CLUSTER, &q->queue_flags);
 	return q;

commit 8ffdc6550c47f75ca4e6c9f30a2a89063e035cf2
Author: Tejun Heo <htejun@gmail.com>
Date:   Fri Jan 6 09:49:03 2006 +0100

    [BLOCK] add @uptodate to end_that_request_last() and @error to rq_end_io_fn()
    
    add @uptodate argument to end_that_request_last() and @error
    to rq_end_io_fn().  there's no generic way to pass error code
    to request completion function, making generic error handling
    of non-fs request difficult (rq->errors is driver-specific and
    each driver uses it differently).  this patch adds @uptodate
    to end_that_request_last() and @error to rq_end_io_fn().
    
    for fs requests, this doesn't really matter, so just using the
    same uptodate argument used in the last call to
    end_that_request_first() should suffice.  imho, this can also
    help the generic command-carrying request jens is working on.
    
    Signed-off-by: tejun heo <htejun@gmail.com>
    Signed-Off-By: Jens Axboe <axboe@suse.de>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index a7f3f0c84db7..53551f1dfe21 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -791,7 +791,7 @@ static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int uptodate,
 	spin_lock_irqsave(q->queue_lock, flags);
 	if (blk_rq_tagged(req))
 		blk_queue_end_tag(q, req);
-	end_that_request_last(req);
+	end_that_request_last(req, uptodate);
 	spin_unlock_irqrestore(q->queue_lock, flags);
 
 	/*

commit 7b16318dea8d9840dac567a2ae8c50ecdea36aea
Author: James Bottomley <jejb@titanic.(none)>
Date:   Thu Dec 15 20:17:02 2005 -0600

    Fix up SCSI mismerge
    
    I forgot to do a git-update-cache on the merged files ...

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 14ad2a785a34..a7f3f0c84db7 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1259,6 +1259,26 @@ static void scsi_generic_done(struct scsi_cmnd *cmd)
 	scsi_io_completion(cmd, cmd->bufflen, 0);
 }
 
+void scsi_setup_blk_pc_cmnd(struct scsi_cmnd *cmd)
+{
+	struct request *req = cmd->request;
+
+	BUG_ON(sizeof(req->cmd) > sizeof(cmd->cmnd));
+	memcpy(cmd->cmnd, req->cmd, sizeof(cmd->cmnd));
+	cmd->cmd_len = req->cmd_len;
+	if (!req->data_len)
+		cmd->sc_data_direction = DMA_NONE;
+	else if (rq_data_dir(req) == WRITE)
+		cmd->sc_data_direction = DMA_TO_DEVICE;
+	else
+		cmd->sc_data_direction = DMA_FROM_DEVICE;
+	
+	cmd->transfersize = req->data_len;
+	cmd->allowed = req->retries;
+	cmd->timeout_per_command = req->timeout;
+}
+EXPORT_SYMBOL_GPL(scsi_setup_blk_pc_cmnd);
+
 static int scsi_prep_fn(struct request_queue *q, struct request *req)
 {
 	struct scsi_device *sdev = q->queuedata;
@@ -1394,18 +1414,7 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 				goto kill;
 			}
 		} else {
-			memcpy(cmd->cmnd, req->cmd, sizeof(cmd->cmnd));
-			cmd->cmd_len = req->cmd_len;
-			if (rq_data_dir(req) == WRITE)
-				cmd->sc_data_direction = DMA_TO_DEVICE;
-			else if (req->data_len)
-				cmd->sc_data_direction = DMA_FROM_DEVICE;
-			else
-				cmd->sc_data_direction = DMA_NONE;
-			
-			cmd->transfersize = req->data_len;
-			cmd->allowed = req->retries;
-			cmd->timeout_per_command = req->timeout;
+			scsi_setup_blk_pc_cmnd(cmd);
 			cmd->done = scsi_generic_done;
 		}
 	}

commit defd94b75409b983f94548ea2f52ff5787ddb848
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Mon Dec 5 02:37:06 2005 -0600

    [SCSI] seperate max_sectors from max_hw_sectors
    
    - export __blk_put_request and blk_execute_rq_nowait
    needed for async REQ_BLOCK_PC requests
    - seperate max_hw_sectors and max_sectors for block/scsi_ioctl.c and
    SG_IO bio.c helpers per Jens's last comments. Since block/scsi_ioctl.c SG_IO was
    already testing against max_sectors and SCSI-ml was setting max_sectors and
    max_hw_sectors to the same value this does not change any scsi SG_IO behavior. It only
    prepares ll_rw_blk.c, scsi_ioctl.c and bio.c for when SCSI-ml begins to set
    a valid max_hw_sectors for all LLDs. Today if a LLD does not set it
    SCSI-ml sets it to a safe default and some LLDs set it to a artificial low
    value to overcome memory and feedback issues.
    
    Note: Since we now cap max_sectors to BLK_DEF_MAX_SECTORS, which is 1024,
    drivers that used to call blk_queue_max_sectors with a large value of
    max_sectors will now see the fs requests capped to BLK_DEF_MAX_SECTORS.
    
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 54a72f197487..14ad2a785a34 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -462,6 +462,7 @@ int scsi_execute_async(struct scsi_device *sdev, const unsigned char *cmd,
 	req = blk_get_request(sdev->request_queue, write, gfp);
 	if (!req)
 		goto free_sense;
+	req->flags |= REQ_BLOCK_PC | REQ_QUIET;
 
 	if (use_sg)
 		err = scsi_req_map_sg(req, buffer, use_sg, bufflen, gfp);
@@ -477,7 +478,6 @@ int scsi_execute_async(struct scsi_device *sdev, const unsigned char *cmd,
 	req->sense_len = 0;
 	req->timeout = timeout;
 	req->retries = retries;
-	req->flags |= REQ_BLOCK_PC | REQ_QUIET;
 	req->end_io_data = sioc;
 
 	sioc->data = privdata;

commit aa7b5cd750c766f66a92c9f78ba176bc77512b7e
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Fri Nov 11 05:31:41 2005 -0600

    [SCSI] add kmemcache for scsi_io_context
    
    Add kmemcache of scsi io contexts.
    
    In the future when we finalize on where these functions will live
    we can add a mempool for it and do a bioset for out REQ_BLOCK_PC
    bios. This is needed becuase the dm-multipath handlers will
    want to use the scsi_exectute* functions for failover and we cannot
    have them and the bio device allocating from the same mempool.
    
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 3e136bfe4219..54a72f197487 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -306,6 +306,8 @@ struct scsi_io_context {
 	char sense[SCSI_SENSE_BUFFERSIZE];
 };
 
+static kmem_cache_t *scsi_io_context_cache;
+
 static void scsi_end_async(struct request *req)
 {
 	struct scsi_io_context *sioc = req->end_io_data;
@@ -313,7 +315,7 @@ static void scsi_end_async(struct request *req)
 	if (sioc->done)
 		sioc->done(sioc->data, sioc->sense, req->errors, req->data_len);
 
-	kfree(sioc);
+	kmem_cache_free(scsi_io_context_cache, sioc);
 	__blk_put_request(req->q, req);
 }
 
@@ -452,9 +454,10 @@ int scsi_execute_async(struct scsi_device *sdev, const unsigned char *cmd,
 	int err = 0;
 	int write = (data_direction == DMA_TO_DEVICE);
 
-	sioc = kzalloc(sizeof(*sioc), gfp);
+	sioc = kmem_cache_alloc(scsi_io_context_cache, gfp);
 	if (!sioc)
 		return DRIVER_ERROR << 24;
+	memset(sioc, 0, sizeof(*sioc));
 
 	req = blk_get_request(sdev->request_queue, write, gfp);
 	if (!req)
@@ -1765,6 +1768,14 @@ int __init scsi_init_queue(void)
 {
 	int i;
 
+	scsi_io_context_cache = kmem_cache_create("scsi_io_context",
+					sizeof(struct scsi_io_context),
+					0, 0, NULL, NULL);
+	if (!scsi_io_context_cache) {
+		printk(KERN_ERR "SCSI: can't init scsi io context cache\n");
+		return -ENOMEM;
+	}
+
 	for (i = 0; i < SG_MEMPOOL_NR; i++) {
 		struct scsi_host_sg_pool *sgp = scsi_sg_pools + i;
 		int size = sgp->size * sizeof(struct scatterlist);
@@ -1792,6 +1803,8 @@ void scsi_exit_queue(void)
 {
 	int i;
 
+	kmem_cache_destroy(scsi_io_context_cache);
+
 	for (i = 0; i < SG_MEMPOOL_NR; i++) {
 		struct scsi_host_sg_pool *sgp = scsi_sg_pools + i;
 		mempool_destroy(sgp->pool);

commit 0d95716d6a1308c465d8c17ed1a217628936bb0c
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Fri Nov 11 05:31:40 2005 -0600

    [SCSI] complete the whole command when it is REQ_BLOCK_PC
    
    sd does not allow scsi_io_completion to retry commands for
    SG_IO requests, and it make sense that it should not happen for st
    SG_IO commands too. If for st we hit the bottom of scsi_io_completion
    we will probably screw things up pretty bad. This patch returns to the
    block layer that the whole command completed and relies on the caller to check
    the request errors field. For initialization commands like in sd, this adds
    the previous behavior where scsi_io_completion did not process the error.
    
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 365843a1561f..3e136bfe4219 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1247,7 +1247,13 @@ static int scsi_issue_flush_fn(request_queue_t *q, struct gendisk *disk,
 static void scsi_generic_done(struct scsi_cmnd *cmd)
 {
 	BUG_ON(!blk_pc_request(cmd->request));
-	scsi_io_completion(cmd, cmd->result == 0 ? cmd->bufflen : 0, 0);
+	/*
+	 * This will complete the whole command with uptodate=1 so
+	 * as far as the block layer is concerned the command completed
+	 * successfully. Since this is a REQ_BLOCK_PC command the
+	 * caller should check the request's errors value
+	 */
+	scsi_io_completion(cmd, cmd->bufflen, 0);
 }
 
 static int scsi_prep_fn(struct request_queue *q, struct request *req)

commit 17e01f216b611fc46956dcd9063aec4de75991e3
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Fri Nov 11 05:31:37 2005 -0600

    [SCSI] add retries field to request for REQ_BLOCK_PC use
    
    For tape we need to control the retries. This patch adds a retries
    counter on the request for REQ_BLOCK_PC commands originating from
    scsi_execute* to use. REQ_BLOCK_PC commands comming from the block
    layer SG_IO path continue to use the retires set in the ULD init_command.
    (scsi_execute* does not set the gendisk so we do not execute
    the init_command in that path).
    
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index eb0cfbfbcf8f..365843a1561f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -259,6 +259,7 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	memcpy(req->cmd, cmd, req->cmd_len);
 	req->sense = sense;
 	req->sense_len = 0;
+	req->retries = retries;
 	req->timeout = timeout;
 	req->flags |= flags | REQ_BLOCK_PC | REQ_SPECIAL | REQ_QUIET;
 
@@ -472,6 +473,7 @@ int scsi_execute_async(struct scsi_device *sdev, const unsigned char *cmd,
 	req->sense = sioc->sense;
 	req->sense_len = 0;
 	req->timeout = timeout;
+	req->retries = retries;
 	req->flags |= REQ_BLOCK_PC | REQ_QUIET;
 	req->end_io_data = sioc;
 
@@ -1393,7 +1395,7 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 				cmd->sc_data_direction = DMA_NONE;
 			
 			cmd->transfersize = req->data_len;
-			cmd->allowed = 3;
+			cmd->allowed = req->retries;
 			cmd->timeout_per_command = req->timeout;
 			cmd->done = scsi_generic_done;
 		}

commit 6e68af666f5336254b5715dca591026b7324499a
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Fri Nov 11 05:30:27 2005 -0600

    [SCSI] Convert SCSI mid-layer to scsi_execute_async
    
    Add scsi helpers to create really-large-requests and convert
    scsi-ml to scsi_execute_async().
    
    Per Jens's previous comments, I placed this function in scsi_lib.c.
    I made it follow all the queue's limits - I think I did at least :), so
    I removed the warning on the function header.
    
    I think the scsi_execute_* functions should eventually take a request_queue
    and be placed some place where the dm-multipath hw_handler can use them
    if that failover code is going to stay in the kernel. That conversion
    patch will be sent in another mail though.
    
    Signed-off-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 1f2782767ca9..eb0cfbfbcf8f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -63,39 +63,6 @@ static struct scsi_host_sg_pool scsi_sg_pools[] = {
 }; 	
 #undef SP
 
-
-/*
- * Function:    scsi_insert_special_req()
- *
- * Purpose:     Insert pre-formed request into request queue.
- *
- * Arguments:   sreq	- request that is ready to be queued.
- *              at_head	- boolean.  True if we should insert at head
- *                        of queue, false if we should insert at tail.
- *
- * Lock status: Assumed that lock is not held upon entry.
- *
- * Returns:     Nothing
- *
- * Notes:       This function is called from character device and from
- *              ioctl types of functions where the caller knows exactly
- *              what SCSI command needs to be issued.   The idea is that
- *              we merely inject the command into the queue (at the head
- *              for now), and then call the queue request function to actually
- *              process it.
- */
-int scsi_insert_special_req(struct scsi_request *sreq, int at_head)
-{
-	/*
-	 * Because users of this function are apt to reuse requests with no
-	 * modification, we have to sanitise the request flags here
-	 */
-	sreq->sr_request->flags &= ~REQ_DONTPREP;
-	blk_insert_request(sreq->sr_device->request_queue, sreq->sr_request,
-		       	   at_head, sreq);
-	return 0;
-}
-
 static void scsi_run_queue(struct request_queue *q);
 
 /*
@@ -249,8 +216,13 @@ void scsi_do_req(struct scsi_request *sreq, const void *cmnd,
 
 	/*
 	 * head injection *required* here otherwise quiesce won't work
+	 *
+	 * Because users of this function are apt to reuse requests with no
+	 * modification, we have to sanitise the request flags here
 	 */
-	scsi_insert_special_req(sreq, 1);
+	sreq->sr_request->flags &= ~REQ_DONTPREP;
+	blk_insert_request(sreq->sr_device->request_queue, sreq->sr_request,
+		       	   1, sreq);
 }
 EXPORT_SYMBOL(scsi_do_req);
 
@@ -327,6 +299,196 @@ int scsi_execute_req(struct scsi_device *sdev, const unsigned char *cmd,
 }
 EXPORT_SYMBOL(scsi_execute_req);
 
+struct scsi_io_context {
+	void *data;
+	void (*done)(void *data, char *sense, int result, int resid);
+	char sense[SCSI_SENSE_BUFFERSIZE];
+};
+
+static void scsi_end_async(struct request *req)
+{
+	struct scsi_io_context *sioc = req->end_io_data;
+
+	if (sioc->done)
+		sioc->done(sioc->data, sioc->sense, req->errors, req->data_len);
+
+	kfree(sioc);
+	__blk_put_request(req->q, req);
+}
+
+static int scsi_merge_bio(struct request *rq, struct bio *bio)
+{
+	struct request_queue *q = rq->q;
+
+	bio->bi_flags &= ~(1 << BIO_SEG_VALID);
+	if (rq_data_dir(rq) == WRITE)
+		bio->bi_rw |= (1 << BIO_RW);
+	blk_queue_bounce(q, &bio);
+
+	if (!rq->bio)
+		blk_rq_bio_prep(q, rq, bio);
+	else if (!q->back_merge_fn(q, rq, bio))
+		return -EINVAL;
+	else {
+		rq->biotail->bi_next = bio;
+		rq->biotail = bio;
+		rq->hard_nr_sectors += bio_sectors(bio);
+		rq->nr_sectors = rq->hard_nr_sectors;
+	}
+
+	return 0;
+}
+
+static int scsi_bi_endio(struct bio *bio, unsigned int bytes_done, int error)
+{
+	if (bio->bi_size)
+		return 1;
+
+	bio_put(bio);
+	return 0;
+}
+
+/**
+ * scsi_req_map_sg - map a scatterlist into a request
+ * @rq:		request to fill
+ * @sg:		scatterlist
+ * @nsegs:	number of elements
+ * @bufflen:	len of buffer
+ * @gfp:	memory allocation flags
+ *
+ * scsi_req_map_sg maps a scatterlist into a request so that the
+ * request can be sent to the block layer. We do not trust the scatterlist
+ * sent to use, as some ULDs use that struct to only organize the pages.
+ */
+static int scsi_req_map_sg(struct request *rq, struct scatterlist *sgl,
+			   int nsegs, unsigned bufflen, gfp_t gfp)
+{
+	struct request_queue *q = rq->q;
+	int nr_pages = (bufflen + PAGE_SIZE - 1) >> PAGE_SHIFT;
+	unsigned int data_len = 0, len, bytes, off;
+	struct page *page;
+	struct bio *bio = NULL;
+	int i, err, nr_vecs = 0;
+
+	for (i = 0; i < nsegs; i++) {
+		page = sgl[i].page;
+		off = sgl[i].offset;
+		len = sgl[i].length;
+		data_len += len;
+
+		while (len > 0) {
+			bytes = min_t(unsigned int, len, PAGE_SIZE - off);
+
+			if (!bio) {
+				nr_vecs = min_t(int, BIO_MAX_PAGES, nr_pages);
+				nr_pages -= nr_vecs;
+
+				bio = bio_alloc(gfp, nr_vecs);
+				if (!bio) {
+					err = -ENOMEM;
+					goto free_bios;
+				}
+				bio->bi_end_io = scsi_bi_endio;
+			}
+
+			if (bio_add_pc_page(q, bio, page, bytes, off) !=
+			    bytes) {
+				bio_put(bio);
+				err = -EINVAL;
+				goto free_bios;
+			}
+
+			if (bio->bi_vcnt >= nr_vecs) {
+				err = scsi_merge_bio(rq, bio);
+				if (err) {
+					bio_endio(bio, bio->bi_size, 0);
+					goto free_bios;
+				}
+				bio = NULL;
+			}
+
+			page++;
+			len -= bytes;
+			off = 0;
+		}
+	}
+
+	rq->buffer = rq->data = NULL;
+	rq->data_len = data_len;
+	return 0;
+
+free_bios:
+	while ((bio = rq->bio) != NULL) {
+		rq->bio = bio->bi_next;
+		/*
+		 * call endio instead of bio_put incase it was bounced
+		 */
+		bio_endio(bio, bio->bi_size, 0);
+	}
+
+	return err;
+}
+
+/**
+ * scsi_execute_async - insert request
+ * @sdev:	scsi device
+ * @cmd:	scsi command
+ * @data_direction: data direction
+ * @buffer:	data buffer (this can be a kernel buffer or scatterlist)
+ * @bufflen:	len of buffer
+ * @use_sg:	if buffer is a scatterlist this is the number of elements
+ * @timeout:	request timeout in seconds
+ * @retries:	number of times to retry request
+ * @flags:	or into request flags
+ **/
+int scsi_execute_async(struct scsi_device *sdev, const unsigned char *cmd,
+		       int data_direction, void *buffer, unsigned bufflen,
+		       int use_sg, int timeout, int retries, void *privdata,
+		       void (*done)(void *, char *, int, int), gfp_t gfp)
+{
+	struct request *req;
+	struct scsi_io_context *sioc;
+	int err = 0;
+	int write = (data_direction == DMA_TO_DEVICE);
+
+	sioc = kzalloc(sizeof(*sioc), gfp);
+	if (!sioc)
+		return DRIVER_ERROR << 24;
+
+	req = blk_get_request(sdev->request_queue, write, gfp);
+	if (!req)
+		goto free_sense;
+
+	if (use_sg)
+		err = scsi_req_map_sg(req, buffer, use_sg, bufflen, gfp);
+	else if (bufflen)
+		err = blk_rq_map_kern(req->q, req, buffer, bufflen, gfp);
+
+	if (err)
+		goto free_req;
+
+	req->cmd_len = COMMAND_SIZE(cmd[0]);
+	memcpy(req->cmd, cmd, req->cmd_len);
+	req->sense = sioc->sense;
+	req->sense_len = 0;
+	req->timeout = timeout;
+	req->flags |= REQ_BLOCK_PC | REQ_QUIET;
+	req->end_io_data = sioc;
+
+	sioc->data = privdata;
+	sioc->done = done;
+
+	blk_execute_rq_nowait(req->q, NULL, req, 1, scsi_end_async);
+	return 0;
+
+free_req:
+	blk_put_request(req);
+free_sense:
+	kfree(sioc);
+	return DRIVER_ERROR << 24;
+}
+EXPORT_SYMBOL_GPL(scsi_execute_async);
+
 /*
  * Function:    scsi_init_cmd_errh()
  *

commit 26a68019c86e1d1782984a7a5babff762cde1501
Author: Jens Axboe <axboe@suse.de>
Date:   Tue Nov 29 21:03:34 2005 +0100

    [SCSI] scsi_lib: stricter checks for clearing use_10_for_rw
    
    Check the asc and ascq for being "invalid command opcode" as well.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ce9d73a292e2..1f2782767ca9 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -884,7 +884,8 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 			* system where READ CAPACITY failed, we may have read
 			* past the end of the disk.
 		 	*/
-			if (cmd->device->use_10_for_rw &&
+			if ((cmd->device->use_10_for_rw &&
+			    sshdr.asc == 0x20 && sshdr.ascq == 0x00) &&
 			    (cmd->cmnd[0] == READ_10 ||
 			     cmd->cmnd[0] == WRITE_10)) {
 				cmd->device->use_10_for_rw = 0;

commit 49d7bc64283970ee83d2c954d04ba00d04e5943d
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Mon Dec 12 11:25:04 2005 -0800

    Revert revert of "[SCSI] fix usb storage oops"
    
    This reverts commit 1b0997f561bf46689cc6e0903f342e9bf2506bf1, which in
    turn reverted 34ea80ec6a02ad02e6b9c75c478c18e5880d6713 (which is thus
    re-instated).
    
    Quoth James Bottomley:
    
      "All it's doing is deferring the device_put() from the
       scsi_put_command() to after the scsi_run_queue(), which doesn't fix
       the sleep while atomic problem of the device release method.  In both
       cases we still get the semaphore in atomic context problem which is
       caused by scsi_reap_target() doing a device_del(), which I assumed
       (wrongly) was valid from atomic context."
    
    who also promised to fix scsi_reap_target().
    
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4afef5cdcb17..ce9d73a292e2 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -542,10 +542,17 @@ static void scsi_requeue_command(struct request_queue *q, struct scsi_cmnd *cmd)
 
 void scsi_next_command(struct scsi_cmnd *cmd)
 {
-	struct request_queue *q = cmd->device->request_queue;
+	struct scsi_device *sdev = cmd->device;
+	struct request_queue *q = sdev->request_queue;
+
+	/* need to hold a reference on the device before we let go of the cmd */
+	get_device(&sdev->sdev_gendev);
 
 	scsi_put_command(cmd);
 	scsi_run_queue(q);
+
+	/* ok to remove device now */
+	put_device(&sdev->sdev_gendev);
 }
 
 void scsi_run_host_queues(struct Scsi_Host *shost)

commit 1b0997f561bf46689cc6e0903f342e9bf2506bf1
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Fri Dec 2 15:54:37 2005 -0800

    Revert "[SCSI] fix usb storage oops"
    
    This reverts commit 34ea80ec6a02ad02e6b9c75c478c18e5880d6713.
    
    It does a put_device() from softirq context, which is bad since it gets
    a semaphore for reading.
    
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index ce9d73a292e2..4afef5cdcb17 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -542,17 +542,10 @@ static void scsi_requeue_command(struct request_queue *q, struct scsi_cmnd *cmd)
 
 void scsi_next_command(struct scsi_cmnd *cmd)
 {
-	struct scsi_device *sdev = cmd->device;
-	struct request_queue *q = sdev->request_queue;
-
-	/* need to hold a reference on the device before we let go of the cmd */
-	get_device(&sdev->sdev_gendev);
+	struct request_queue *q = cmd->device->request_queue;
 
 	scsi_put_command(cmd);
 	scsi_run_queue(q);
-
-	/* ok to remove device now */
-	put_device(&sdev->sdev_gendev);
 }
 
 void scsi_run_host_queues(struct Scsi_Host *shost)

commit 34ea80ec6a02ad02e6b9c75c478c18e5880d6713
Author: goggin, edward <egoggin@emc.com>
Date:   Tue Nov 8 15:02:23 2005 -0500

    [SCSI] fix usb storage oops
    
    The problem is that scsi_run_queue is called from scsi_next_command()
    after doing a scsi_put_command.  If the command was the only thing
    holding the reference on the scsi_device then the resulting device put
    will tear down the block queue.  Fix this by taking a reference to the
    device and holding it around scsi_run_queue()
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 4afef5cdcb17..ce9d73a292e2 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -542,10 +542,17 @@ static void scsi_requeue_command(struct request_queue *q, struct scsi_cmnd *cmd)
 
 void scsi_next_command(struct scsi_cmnd *cmd)
 {
-	struct request_queue *q = cmd->device->request_queue;
+	struct scsi_device *sdev = cmd->device;
+	struct request_queue *q = sdev->request_queue;
+
+	/* need to hold a reference on the device before we let go of the cmd */
+	get_device(&sdev->sdev_gendev);
 
 	scsi_put_command(cmd);
 	scsi_run_queue(q);
+
+	/* ok to remove device now */
+	put_device(&sdev->sdev_gendev);
 }
 
 void scsi_run_host_queues(struct Scsi_Host *shost)

commit 262eef663b579f9b495c7392ac7d2d3f34ecc9fe
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Oct 29 01:09:12 2005 +0200

    [SCSI] remove scsi_wait_req
    
    This function has been superceeded by the block request based interfaces
    and is unused (except for the uncompilable cpqfc driver).
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index e40c8b66da40..4afef5cdcb17 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -254,55 +254,6 @@ void scsi_do_req(struct scsi_request *sreq, const void *cmnd,
 }
 EXPORT_SYMBOL(scsi_do_req);
 
-/* This is the end routine we get to if a command was never attached
- * to the request.  Simply complete the request without changing
- * rq_status; this will cause a DRIVER_ERROR. */
-static void scsi_wait_req_end_io(struct request *req)
-{
-	BUG_ON(!req->waiting);
-
-	complete(req->waiting);
-}
-
-void scsi_wait_req(struct scsi_request *sreq, const void *cmnd, void *buffer,
-		   unsigned bufflen, int timeout, int retries)
-{
-	DECLARE_COMPLETION(wait);
-	int write = (sreq->sr_data_direction == DMA_TO_DEVICE);
-	struct request *req;
-
-	req = blk_get_request(sreq->sr_device->request_queue, write,
-			      __GFP_WAIT);
-	if (bufflen && blk_rq_map_kern(sreq->sr_device->request_queue, req,
-				       buffer, bufflen, __GFP_WAIT)) {
-		sreq->sr_result = DRIVER_ERROR << 24;
-		blk_put_request(req);
-		return;
-	}
-
-	req->flags |= REQ_NOMERGE;
-	req->waiting = &wait;
-	req->end_io = scsi_wait_req_end_io;
-	req->cmd_len = COMMAND_SIZE(((u8 *)cmnd)[0]);
-	req->sense = sreq->sr_sense_buffer;
-	req->sense_len = 0;
-	memcpy(req->cmd, cmnd, req->cmd_len);
-	req->timeout = timeout;
-	req->flags |= REQ_BLOCK_PC;
-	req->rq_disk = NULL;
-	blk_insert_request(sreq->sr_device->request_queue, req,
-			   sreq->sr_data_direction == DMA_TO_DEVICE, NULL);
-	wait_for_completion(&wait);
-	sreq->sr_request->waiting = NULL;
-	sreq->sr_result = req->errors;
-	if (req->errors)
-		sreq->sr_result |= (DRIVER_ERROR << 24);
-
-	blk_put_request(req);
-}
-
-EXPORT_SYMBOL(scsi_wait_req);
-
 /**
  * scsi_execute - insert request and wait for the result
  * @sdev:	scsi device

commit 3bf743e7c891d8be8295650b7a6a9b5af083b096
Author: Jeff Garzik <jgarzik@pobox.com>
Date:   Mon Oct 24 18:04:06 2005 -0400

    [SCSI] use {sdev,scmd,starget,shost}_printk in generic code
    
    rejections fixed and
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 19ac888001e6..e40c8b66da40 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -951,16 +951,14 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 				return;
 			}
 			if (!(req->flags & REQ_QUIET))
-				sdev_printk(KERN_INFO,
-					    cmd->device,
-					    "Device not ready.\n");
+				scmd_printk(KERN_INFO, cmd,
+					   "Device not ready.\n");
 			scsi_end_request(cmd, 0, this_count, 1);
 			return;
 		case VOLUME_OVERFLOW:
 			if (!(req->flags & REQ_QUIET)) {
-				sdev_printk(KERN_INFO,
-					    cmd->device,
-					    "Volume overflow, CDB: ");
+				scmd_printk(KERN_INFO, cmd,
+					   "Volume overflow, CDB: ");
 				__scsi_print_command(cmd->data_cmnd);
 				scsi_print_sense("", cmd);
 			}
@@ -981,9 +979,8 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 	}
 	if (result) {
 		if (!(req->flags & REQ_QUIET)) {
-			sdev_printk(KERN_INFO, cmd->device,
-				    "SCSI error: return code = 0x%x\n",
-				    result);
+			scmd_printk(KERN_INFO, cmd,
+				   "SCSI error: return code = 0x%x\n", result);
 
 			if (driver_byte(result) & DRIVER_SENSE)
 				scsi_print_sense("", cmd);

commit 9ccfc756a70d454dfa82f48897e2883560c01a0e
Author: James Bottomley <James.Bottomley@steeleye.com>
Date:   Sun Oct 2 11:45:08 2005 -0500

    [SCSI] move the mid-layer printk's over to shost/starget/sdev_printk
    
    This should eliminate (at least in the mid layer) to make numeric
    assumptions about any of the enumeration variables.  As a side effect,
    it will also make all the messages consistent and line us up nicely for
    the error logging strategy (if it ever shows itself again).
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 3ff538809786..19ac888001e6 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -951,16 +951,16 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 				return;
 			}
 			if (!(req->flags & REQ_QUIET))
-				dev_printk(KERN_INFO,
-					   &cmd->device->sdev_gendev,
-					   "Device not ready.\n");
+				sdev_printk(KERN_INFO,
+					    cmd->device,
+					    "Device not ready.\n");
 			scsi_end_request(cmd, 0, this_count, 1);
 			return;
 		case VOLUME_OVERFLOW:
 			if (!(req->flags & REQ_QUIET)) {
-				dev_printk(KERN_INFO,
-					   &cmd->device->sdev_gendev,
-					   "Volume overflow, CDB: ");
+				sdev_printk(KERN_INFO,
+					    cmd->device,
+					    "Volume overflow, CDB: ");
 				__scsi_print_command(cmd->data_cmnd);
 				scsi_print_sense("", cmd);
 			}
@@ -981,8 +981,9 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 	}
 	if (result) {
 		if (!(req->flags & REQ_QUIET)) {
-			dev_printk(KERN_INFO, &cmd->device->sdev_gendev,
-				   "SCSI error: return code = 0x%x\n", result);
+			sdev_printk(KERN_INFO, cmd->device,
+				    "SCSI error: return code = 0x%x\n",
+				    result);
 
 			if (driver_byte(result) & DRIVER_SENSE)
 				scsi_print_sense("", cmd);
@@ -1141,8 +1142,8 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 	 * online before trying any recovery commands
 	 */
 	if (unlikely(!scsi_device_online(sdev))) {
-		printk(KERN_ERR "scsi%d (%d:%d): rejecting I/O to offline device\n",
-		       sdev->host->host_no, sdev->id, sdev->lun);
+		sdev_printk(KERN_ERR, sdev,
+			    "rejecting I/O to offline device\n");
 		goto kill;
 	}
 	if (unlikely(sdev->sdev_state != SDEV_RUNNING)) {
@@ -1151,8 +1152,8 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 		if (sdev->sdev_state == SDEV_DEL) {
 			/* Device is fully deleted, no commands
 			 * at all allowed down */
-			printk(KERN_ERR "scsi%d (%d:%d): rejecting I/O to dead device\n",
-			       sdev->host->host_no, sdev->id, sdev->lun);
+			sdev_printk(KERN_ERR, sdev,
+				    "rejecting I/O to dead device\n");
 			goto kill;
 		}
 		/* OK, we only allow special commands (i.e. not
@@ -1187,8 +1188,8 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 					specials_only == SDEV_BLOCK)
 				goto defer;
 			
-			printk(KERN_ERR "scsi%d (%d:%d): rejecting I/O to device being removed\n",
-			       sdev->host->host_no, sdev->id, sdev->lun);
+			sdev_printk(KERN_ERR, sdev,
+				    "rejecting I/O to device being removed\n");
 			goto kill;
 		}
 			
@@ -1315,9 +1316,8 @@ static inline int scsi_dev_queue_ready(struct request_queue *q,
 		 */
 		if (--sdev->device_blocked == 0) {
 			SCSI_LOG_MLQUEUE(3,
-				printk("scsi%d (%d:%d) unblocking device at"
-				       " zero depth\n", sdev->host->host_no,
-				       sdev->id, sdev->lun));
+				   sdev_printk(KERN_INFO, sdev,
+				   "unblocking device at zero depth\n"));
 		} else {
 			blk_plug_device(q);
 			return 0;
@@ -1436,8 +1436,8 @@ static void scsi_request_fn(struct request_queue *q)
 			break;
 
 		if (unlikely(!scsi_device_online(sdev))) {
-			printk(KERN_ERR "scsi%d (%d:%d): rejecting I/O to offline device\n",
-			       sdev->host->host_no, sdev->id, sdev->lun);
+			sdev_printk(KERN_ERR, sdev,
+				    "rejecting I/O to offline device\n");
 			scsi_kill_request(req, q);
 			continue;
 		}
@@ -1893,10 +1893,10 @@ scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
 
  illegal:
 	SCSI_LOG_ERROR_RECOVERY(1, 
-				dev_printk(KERN_ERR, &sdev->sdev_gendev,
-					   "Illegal state transition %s->%s\n",
-					   scsi_device_state_name(oldstate),
-					   scsi_device_state_name(state))
+				sdev_printk(KERN_ERR, sdev,
+					    "Illegal state transition %s->%s\n",
+					    scsi_device_state_name(oldstate),
+					    scsi_device_state_name(state))
 				);
 	return -EINVAL;
 }

commit c53033f6b0bd7cc133b7f433083f0394cf29ac70
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Oct 21 03:22:08 2005 -0400

    [PATCH] gfp_t: drivers/scsi
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0074f28c37b2..3ff538809786 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -677,7 +677,7 @@ static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int uptodate,
 	return NULL;
 }
 
-static struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, int gfp_mask)
+static struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
 {
 	struct scsi_host_sg_pool *sgp;
 	struct scatterlist *sgl;

commit 7c72ce81870ded9365f4bc5caa98ef1591dd18dd
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Fri Oct 14 11:23:27 2005 -0400

    [SCSI] Fix leak of Scsi_Cmnds
    
    When a request is deferred in scsi_init_io because the sg table could not
    be allocated, the associated scsi_cmnd is not released and the request is
    not marked with REQ_DONTPREP.  When the command is retried, if
    scsi_prep_fn decides to kill it then the scsi_cmnd will never be released.
    
    This patch (as573) changes scsi_init_io so that it calls scsi_put_command
    before deferring a request.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index dc9c772bc874..0074f28c37b2 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -97,7 +97,6 @@ int scsi_insert_special_req(struct scsi_request *sreq, int at_head)
 }
 
 static void scsi_run_queue(struct request_queue *q);
-static void scsi_release_buffers(struct scsi_cmnd *cmd);
 
 /*
  * Function:	scsi_unprep_request()
@@ -1040,8 +1039,10 @@ static int scsi_init_io(struct scsi_cmnd *cmd)
 	 * if sg table allocation fails, requeue request later.
 	 */
 	sgpnt = scsi_alloc_sgtable(cmd, GFP_ATOMIC);
-	if (unlikely(!sgpnt))
+	if (unlikely(!sgpnt)) {
+		scsi_unprep_request(req);
 		return BLKPREP_DEFER;
+	}
 
 	cmd->request_buffer = (char *) sgpnt;
 	cmd->request_bufflen = req->nr_sectors << 9;
@@ -1245,8 +1246,8 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 		 */
 		ret = scsi_init_io(cmd);
 		switch(ret) {
+			/* For BLKPREP_KILL/DEFER the cmd was released */
 		case BLKPREP_KILL:
-			/* BLKPREP_KILL return also releases the command */
 			goto kill;
 		case BLKPREP_DEFER:
 			goto defer;

commit 939647ee308e0ad924e776657704c7bedd498664
Author: James Bottomley <James.Bottomley@steeleye.com>
Date:   Sun Sep 18 15:05:20 2005 -0500

    [SCSI] fix oops on usb storage device disconnect
    
    We fix the oops by enforcing the host state model.  There have also
    been two extra states added: SHOST_CANCEL_RECOVERY and
    SHOST_DEL_RECOVERY so we can take the model through host removal while
    the recovery thread is active.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f065cbc1a6e5..dc9c772bc874 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -447,7 +447,7 @@ void scsi_device_unbusy(struct scsi_device *sdev)
 
 	spin_lock_irqsave(shost->host_lock, flags);
 	shost->host_busy--;
-	if (unlikely((shost->shost_state == SHOST_RECOVERY) &&
+	if (unlikely(scsi_host_in_recovery(shost) &&
 		     shost->host_failed))
 		scsi_eh_wakeup(shost);
 	spin_unlock(shost->host_lock);
@@ -1339,7 +1339,7 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 				   struct Scsi_Host *shost,
 				   struct scsi_device *sdev)
 {
-	if (shost->shost_state == SHOST_RECOVERY)
+	if (scsi_host_in_recovery(shost))
 		return 0;
 	if (shost->host_busy == 0 && shost->host_blocked) {
 		/*

commit b95be99d52ce4f9db9ff0bd5f10e9e2066da6d2e
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Thu Sep 15 13:52:51 2005 -0400

    [SCSI] fix oops in scsi_release_buffers()
    
    I found one other thing that needs to be fixed.  The call to
    scsi_release_buffers in scsi_unprep_request causes an oops, because the
    sgtable has already been freed in scsi_io_completion.  The following patch
    is needed.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0c6924eecf59..f065cbc1a6e5 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -118,7 +118,6 @@ static void scsi_unprep_request(struct request *req)
 	req->flags &= ~REQ_DONTPREP;
 	req->special = (req->flags & REQ_SPECIAL) ? cmd->sc_request : NULL;
 
-	scsi_release_buffers(cmd);
 	scsi_put_command(cmd);
 }
 
@@ -1512,7 +1511,6 @@ static void scsi_request_fn(struct request_queue *q)
 	 * cases (host limits or settings) should run the queue at some
 	 * later time.
 	 */
-	scsi_unprep_request(req);
 	spin_lock_irq(q->queue_lock);
 	blk_requeue_request(q, req);
 	sdev->device_busy--;

commit 59897dad98d63ac15e1e36fcc3a107c892b1826c
Author: James Bottomley <James.Bottomley@steeleye.com>
Date:   Wed Sep 14 12:57:42 2005 -0400

    [SCSI] fix sym scsi boot hang
    
    On Wed, 2005-09-14 at 18:06 +1000, Anton Blanchard wrote:
    > And in particular it looks like the scsi_unprep_request in
    > scsi_queue_insert is causing it. The following patch fixes the boot
    > problems on the vscsi machine:
    
    OK, my fault.  Your fix is almost correct .. I was going to do this
    eventually, honest, because there's no need to unprep and reprep a
    command that comes in through scsi_queue_insert().
    
    However, I decided to leave it in to exercise the scsi_unprep_request()
    path just to make sure it was working.  What's happening, I think, is
    that we also use this path for retries.  Since we kill and reget the
    command each time, the retries decrement is never seen, so we're
    retrying forever.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index f9026d08532a..0c6924eecf59 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -140,14 +140,12 @@ static void scsi_unprep_request(struct request *req)
  *              commands.
  * Notes:       This could be called either from an interrupt context or a
  *              normal process context.
- * Notes:	Upon return, cmd is a stale pointer.
  */
 int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 {
 	struct Scsi_Host *host = cmd->device->host;
 	struct scsi_device *device = cmd->device;
 	struct request_queue *q = device->request_queue;
-	struct request *req = cmd->request;
 	unsigned long flags;
 
 	SCSI_LOG_MLQUEUE(1,
@@ -188,9 +186,8 @@ int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 	 * function.  The SCSI request function detects the blocked condition
 	 * and plugs the queue appropriately.
          */
-	scsi_unprep_request(req);
 	spin_lock_irqsave(q->queue_lock, flags);
-	blk_requeue_request(q, req);
+	blk_requeue_request(q, cmd->request);
 	spin_unlock_irqrestore(q->queue_lock, flags);
 
 	scsi_run_queue(q);

commit 186d330e682210100c671355580a8592e4a21692
Author: Timothy Thelin <Timothy.Thelin@wdc.com>
Date:   Tue Sep 13 19:56:28 2005 -0700

    [SCSI] scsi: sd, sr, st, and scsi_lib all fail to copy cmd_len to new cmd
    
    This fixes an issue in scsi command initialization from a request
    where sd, sr, st, and scsi_lib all fail to copy the request's
    cmd_len to the scsi command's cmd_len field.
    
    Signed-off-by: Timothy Thelin <timothy.thelin@wdc.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 863bb6495daa..f9026d08532a 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1268,6 +1268,7 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 			}
 		} else {
 			memcpy(cmd->cmnd, req->cmd, sizeof(cmd->cmnd));
+			cmd->cmd_len = req->cmd_len;
 			if (rq_data_dir(req) == WRITE)
 				cmd->sc_data_direction = DMA_TO_DEVICE;
 			else if (req->data_len)

commit 6f16b5359ceb96780eac4178393b0e8a3c8aa1ea
Author: Mike Christie <michaelc@cs.wisc.edu>
Date:   Sat Sep 10 16:45:35 2005 -0500

    [SCSI] set error value when failing commands in prep_fn
    
    set DID_NO_CONNECT for the BLKPREP_KILL case and correct a few
    BLKPREP_DEFER cases that weren't checking for the need to plug the
    queue.
    
    Signed-Off-By: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d8d984841534..863bb6495daa 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1146,7 +1146,7 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 	if (unlikely(!scsi_device_online(sdev))) {
 		printk(KERN_ERR "scsi%d (%d:%d): rejecting I/O to offline device\n",
 		       sdev->host->host_no, sdev->id, sdev->lun);
-		return BLKPREP_KILL;
+		goto kill;
 	}
 	if (unlikely(sdev->sdev_state != SDEV_RUNNING)) {
 		/* OK, we're not in a running state don't prep
@@ -1156,7 +1156,7 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 			 * at all allowed down */
 			printk(KERN_ERR "scsi%d (%d:%d): rejecting I/O to dead device\n",
 			       sdev->host->host_no, sdev->id, sdev->lun);
-			return BLKPREP_KILL;
+			goto kill;
 		}
 		/* OK, we only allow special commands (i.e. not
 		 * user initiated ones */
@@ -1188,11 +1188,11 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 		if(unlikely(specials_only) && !(req->flags & REQ_SPECIAL)) {
 			if(specials_only == SDEV_QUIESCE ||
 					specials_only == SDEV_BLOCK)
-				return BLKPREP_DEFER;
+				goto defer;
 			
 			printk(KERN_ERR "scsi%d (%d:%d): rejecting I/O to device being removed\n",
 			       sdev->host->host_no, sdev->id, sdev->lun);
-			return BLKPREP_KILL;
+			goto kill;
 		}
 			
 			
@@ -1210,7 +1210,7 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 		cmd->tag = req->tag;
 	} else {
 		blk_dump_rq_flags(req, "SCSI bad req");
-		return BLKPREP_KILL;
+		goto kill;
 	}
 	
 	/* note the overloading of req->special.  When the tag
@@ -1248,8 +1248,13 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 		 * required).
 		 */
 		ret = scsi_init_io(cmd);
-		if (ret)	/* BLKPREP_KILL return also releases the command */
-			return ret;
+		switch(ret) {
+		case BLKPREP_KILL:
+			/* BLKPREP_KILL return also releases the command */
+			goto kill;
+		case BLKPREP_DEFER:
+			goto defer;
+		}
 		
 		/*
 		 * Initialize the actual SCSI command for this request.
@@ -1259,7 +1264,7 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 			if (unlikely(!drv->init_command(cmd))) {
 				scsi_release_buffers(cmd);
 				scsi_put_command(cmd);
-				return BLKPREP_KILL;
+				goto kill;
 			}
 		} else {
 			memcpy(cmd->cmnd, req->cmd, sizeof(cmd->cmnd));
@@ -1290,6 +1295,9 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 	if (sdev->device_busy == 0)
 		blk_plug_device(q);
 	return BLKPREP_DEFER;
+ kill:
+	req->errors = DID_NO_CONNECT << 16;
+	return BLKPREP_KILL;
 }
 
 /*

commit 788ce43aa1ad7158f894b6bb3df8ba2f63794c20
Author: James Bottomley <James.Bottomley@steeleye.com>
Date:   Fri Sep 9 13:40:23 2005 -0500

    [SCSI] SCSI core: fix leakage of scsi_cmnd's
    
    Actually, just one problem and one cosmetic fix:
    
    1) We need to dequeue for the loop and kill case (it seems easiest
    simply to dequeue in the scsi_kill_request() routine)
    2) There's no real need to drop the queue lock.  __scsi_done() is lock
    agnostic, so since there's no requirement, let's just leave it in to
    avoid any locking issues.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 003f8cf47cf1..d8d984841534 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1370,7 +1370,8 @@ static void scsi_kill_request(struct request *req, request_queue_t *q)
 {
 	struct scsi_cmnd *cmd = req->special;
 
-	spin_unlock(q->queue_lock);
+	blkdev_dequeue_request(req);
+
 	if (unlikely(cmd == NULL)) {
 		printk(KERN_CRIT "impossible request in %s.\n",
 				 __FUNCTION__);
@@ -1381,7 +1382,6 @@ static void scsi_kill_request(struct request *req, request_queue_t *q)
 	cmd->result = DID_NO_CONNECT << 16;
 	atomic_inc(&cmd->device->iorequest_cnt);
 	__scsi_done(cmd);
-	spin_lock(q->queue_lock);
 }
 
 /*
@@ -1432,7 +1432,6 @@ static void scsi_request_fn(struct request_queue *q)
 		if (unlikely(!scsi_device_online(sdev))) {
 			printk(KERN_ERR "scsi%d (%d:%d): rejecting I/O to offline device\n",
 			       sdev->host->host_no, sdev->id, sdev->lun);
-			blkdev_dequeue_request(req);
 			scsi_kill_request(req, q);
 			continue;
 		}

commit e91442b635be776ea205fba233bdd5bc74b62bc3
Author: James Bottomley <jejb@mulgrave.(none)>
Date:   Fri Sep 9 10:44:16 2005 -0500

    [SCSI] SCSI core: fix leakage of scsi_cmnd's
    
    From:   Alan Stern <stern@rowland.harvard.edu>
    
    This patch (as559b) adds a new routine, scsi_unprep_request, which
    gets called every place a request is requeued.  (That includes
    scsi_queue_insert as well as scsi_requeue_command.)  It also changes
    scsi_kill_requests to make it call __scsi_done with result equal to
    DID_NO_CONNECT << 16.  (I'm not sure if it's necessary to call
    scsi_init_cmd_errh here; maybe you can check on that.)  Finally, the
    patch changes the return value from scsi_end_request, to avoid
    returning a stale pointer in the case where the request was requeued.
    Fortunately the return value is used in only place, and the change
    actually simplified it.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    
    Rejections fixed up and
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 2ad60f1dbc63..003f8cf47cf1 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -97,6 +97,30 @@ int scsi_insert_special_req(struct scsi_request *sreq, int at_head)
 }
 
 static void scsi_run_queue(struct request_queue *q);
+static void scsi_release_buffers(struct scsi_cmnd *cmd);
+
+/*
+ * Function:	scsi_unprep_request()
+ *
+ * Purpose:	Remove all preparation done for a request, including its
+ *		associated scsi_cmnd, so that it can be requeued.
+ *
+ * Arguments:	req	- request to unprepare
+ *
+ * Lock status:	Assumed that no locks are held upon entry.
+ *
+ * Returns:	Nothing.
+ */
+static void scsi_unprep_request(struct request *req)
+{
+	struct scsi_cmnd *cmd = req->special;
+
+	req->flags &= ~REQ_DONTPREP;
+	req->special = (req->flags & REQ_SPECIAL) ? cmd->sc_request : NULL;
+
+	scsi_release_buffers(cmd);
+	scsi_put_command(cmd);
+}
 
 /*
  * Function:    scsi_queue_insert()
@@ -116,12 +140,14 @@ static void scsi_run_queue(struct request_queue *q);
  *              commands.
  * Notes:       This could be called either from an interrupt context or a
  *              normal process context.
+ * Notes:	Upon return, cmd is a stale pointer.
  */
 int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 {
 	struct Scsi_Host *host = cmd->device->host;
 	struct scsi_device *device = cmd->device;
 	struct request_queue *q = device->request_queue;
+	struct request *req = cmd->request;
 	unsigned long flags;
 
 	SCSI_LOG_MLQUEUE(1,
@@ -162,8 +188,9 @@ int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 	 * function.  The SCSI request function detects the blocked condition
 	 * and plugs the queue appropriately.
          */
+	scsi_unprep_request(req);
 	spin_lock_irqsave(q->queue_lock, flags);
-	blk_requeue_request(q, cmd->request);
+	blk_requeue_request(q, req);
 	spin_unlock_irqrestore(q->queue_lock, flags);
 
 	scsi_run_queue(q);
@@ -552,15 +579,16 @@ static void scsi_run_queue(struct request_queue *q)
  *		I/O errors in the middle of the request, in which case
  *		we need to request the blocks that come after the bad
  *		sector.
+ * Notes:	Upon return, cmd is a stale pointer.
  */
 static void scsi_requeue_command(struct request_queue *q, struct scsi_cmnd *cmd)
 {
+	struct request *req = cmd->request;
 	unsigned long flags;
 
-	cmd->request->flags &= ~REQ_DONTPREP;
-
+	scsi_unprep_request(req);
 	spin_lock_irqsave(q->queue_lock, flags);
-	blk_requeue_request(q, cmd->request);
+	blk_requeue_request(q, req);
 	spin_unlock_irqrestore(q->queue_lock, flags);
 
 	scsi_run_queue(q);
@@ -595,13 +623,14 @@ void scsi_run_host_queues(struct Scsi_Host *shost)
  *
  * Lock status: Assumed that lock is not held upon entry.
  *
- * Returns:     cmd if requeue done or required, NULL otherwise
+ * Returns:     cmd if requeue required, NULL otherwise.
  *
  * Notes:       This is called for block device requests in order to
  *              mark some number of sectors as complete.
  * 
  *		We are guaranteeing that the request queue will be goosed
  *		at some point during this call.
+ * Notes:	If cmd was requeued, upon return it will be a stale pointer.
  */
 static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int uptodate,
 					  int bytes, int requeue)
@@ -624,14 +653,15 @@ static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int uptodate,
 		if (!uptodate && blk_noretry_request(req))
 			end_that_request_chunk(req, 0, leftover);
 		else {
-			if (requeue)
+			if (requeue) {
 				/*
 				 * Bleah.  Leftovers again.  Stick the
 				 * leftovers in the front of the
 				 * queue, and goose the queue again.
 				 */
 				scsi_requeue_command(q, cmd);
-
+				cmd = NULL;
+			}
 			return cmd;
 		}
 	}
@@ -857,15 +887,13 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 		 * requeueing right here - we will requeue down below
 		 * when we handle the bad sectors.
 		 */
-		cmd = scsi_end_request(cmd, 1, good_bytes, result == 0);
 
 		/*
-		 * If the command completed without error, then either finish off the
-		 * rest of the command, or start a new one.
+		 * If the command completed without error, then either
+		 * finish off the rest of the command, or start a new one.
 		 */
-		if (result == 0 || cmd == NULL ) {
+		if (scsi_end_request(cmd, 1, good_bytes, result == 0) == NULL)
 			return;
-		}
 	}
 	/*
 	 * Now, if we were good little boys and girls, Santa left us a request
@@ -880,7 +908,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 				 * and quietly refuse further access.
 				 */
 				cmd->device->changed = 1;
-				cmd = scsi_end_request(cmd, 0,
+				scsi_end_request(cmd, 0,
 						this_count, 1);
 				return;
 			} else {
@@ -914,7 +942,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 				scsi_requeue_command(q, cmd);
 				result = 0;
 			} else {
-				cmd = scsi_end_request(cmd, 0, this_count, 1);
+				scsi_end_request(cmd, 0, this_count, 1);
 				return;
 			}
 			break;
@@ -931,7 +959,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 				dev_printk(KERN_INFO,
 					   &cmd->device->sdev_gendev,
 					   "Device not ready.\n");
-			cmd = scsi_end_request(cmd, 0, this_count, 1);
+			scsi_end_request(cmd, 0, this_count, 1);
 			return;
 		case VOLUME_OVERFLOW:
 			if (!(req->flags & REQ_QUIET)) {
@@ -941,7 +969,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 				__scsi_print_command(cmd->data_cmnd);
 				scsi_print_sense("", cmd);
 			}
-			cmd = scsi_end_request(cmd, 0, block_bytes, 1);
+			scsi_end_request(cmd, 0, block_bytes, 1);
 			return;
 		default:
 			break;
@@ -972,7 +1000,7 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 		block_bytes = req->hard_cur_sectors << 9;
 		if (!block_bytes)
 			block_bytes = req->data_len;
-		cmd = scsi_end_request(cmd, 0, block_bytes, 1);
+		scsi_end_request(cmd, 0, block_bytes, 1);
 	}
 }
 EXPORT_SYMBOL(scsi_io_completion);
@@ -1336,19 +1364,24 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 }
 
 /*
- * Kill requests for a dead device
+ * Kill a request for a dead device
  */
-static void scsi_kill_requests(request_queue_t *q)
+static void scsi_kill_request(struct request *req, request_queue_t *q)
 {
-	struct request *req;
+	struct scsi_cmnd *cmd = req->special;
 
-	while ((req = elv_next_request(q)) != NULL) {
-		blkdev_dequeue_request(req);
-		req->flags |= REQ_QUIET;
-		while (end_that_request_first(req, 0, req->nr_sectors))
-			;
-		end_that_request_last(req);
+	spin_unlock(q->queue_lock);
+	if (unlikely(cmd == NULL)) {
+		printk(KERN_CRIT "impossible request in %s.\n",
+				 __FUNCTION__);
+		BUG();
 	}
+
+	scsi_init_cmd_errh(cmd);
+	cmd->result = DID_NO_CONNECT << 16;
+	atomic_inc(&cmd->device->iorequest_cnt);
+	__scsi_done(cmd);
+	spin_lock(q->queue_lock);
 }
 
 /*
@@ -1371,7 +1404,8 @@ static void scsi_request_fn(struct request_queue *q)
 
 	if (!sdev) {
 		printk("scsi: killing requests for dead queue\n");
-		scsi_kill_requests(q);
+		while ((req = elv_next_request(q)) != NULL)
+			scsi_kill_request(req, q);
 		return;
 	}
 
@@ -1399,10 +1433,7 @@ static void scsi_request_fn(struct request_queue *q)
 			printk(KERN_ERR "scsi%d (%d:%d): rejecting I/O to offline device\n",
 			       sdev->host->host_no, sdev->id, sdev->lun);
 			blkdev_dequeue_request(req);
-			req->flags |= REQ_QUIET;
-			while (end_that_request_first(req, 0, req->nr_sectors))
-				;
-			end_that_request_last(req);
+			scsi_kill_request(req, q);
 			continue;
 		}
 
@@ -1415,6 +1446,14 @@ static void scsi_request_fn(struct request_queue *q)
 		sdev->device_busy++;
 
 		spin_unlock(q->queue_lock);
+		cmd = req->special;
+		if (unlikely(cmd == NULL)) {
+			printk(KERN_CRIT "impossible request in %s.\n"
+					 "please mail a stack trace to "
+					 "linux-scsi@vger.kernel.org",
+					 __FUNCTION__);
+			BUG();
+		}
 		spin_lock(shost->host_lock);
 
 		if (!scsi_host_queue_ready(q, shost, sdev))
@@ -1433,15 +1472,6 @@ static void scsi_request_fn(struct request_queue *q)
 		 */
 		spin_unlock_irq(shost->host_lock);
 
-		cmd = req->special;
-		if (unlikely(cmd == NULL)) {
-			printk(KERN_CRIT "impossible request in %s.\n"
-					 "please mail a stack trace to "
-					 "linux-scsi@vger.kernel.org",
-					 __FUNCTION__);
-			BUG();
-		}
-
 		/*
 		 * Finally, initialize any error handling parameters, and set up
 		 * the timers for timeouts.
@@ -1477,6 +1507,7 @@ static void scsi_request_fn(struct request_queue *q)
 	 * cases (host limits or settings) should run the queue at some
 	 * later time.
 	 */
+	scsi_unprep_request(req);
 	spin_lock_irq(q->queue_lock);
 	blk_requeue_request(q, req);
 	sdev->device_busy--;

commit 286f3e13a1dc7f32407629fbd7aabc8ea78c62b5
Author: Neil Brown <neilb@suse.de>
Date:   Fri Sep 2 13:13:54 2005 +1000

    [SCSI] fix possible deadlock in scsi_lib.c
    
      If a filesystem, while writing out data, decides that it is good
    to issue a cache flush on a SCSI drive (or other 'sd' device), it will
    call blkdev_issue_flush which calls ->issue_flush_fn which is
    scsi_issue_flush_fn.
    This calls sd_issue_flush which calls sd_sync_cache, which calls
    scsi_execute_request.
    This will (as sshdr != NULL) call
        kmalloc(SCSI_SENSE_BUFFERSIZE, GFP_KERNEL)
    
    If memory is tight, the presence of GFP_KERNEL may cause write
    requests to be sent to some filesystem to free up memory, however if
    that filesystem is waiting for the issue_flush_fn to complete, you
    could get a deadlock.
    
    I wonder if it might be more appropriate to use GFP_NOIO as in the
    following patch.
    
    I wonder if it might be even more appropriate to cope better with a
    kmalloc failure, especially as in this use, sd_sync_cache only will
    use the sense information to print out a more informative error
    message.
    
    Signed-off-by: Neil Brown <neilb@suse.de>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 77f2d444f7e0..2ad60f1dbc63 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -339,7 +339,7 @@ int scsi_execute_req(struct scsi_device *sdev, const unsigned char *cmd,
 	int result;
 	
 	if (sshdr) {
-		sense = kmalloc(SCSI_SENSE_BUFFERSIZE, GFP_KERNEL);
+		sense = kmalloc(SCSI_SENSE_BUFFERSIZE, GFP_NOIO);
 		if (!sense)
 			return DRIVER_ERROR << 24;
 		memset(sense, 0, SCSI_SENSE_BUFFERSIZE);

commit 3173d8c342971a03857d8af749a3f57da7d06b57
Author: James Bottomley <James.Bottomley@steeleye.com>
Date:   Sun Sep 4 11:32:05 2005 -0500

    [SCSI] quieten messages on scsi_execute commands
    
    scsi_io_completion() can be a bit noisy about certain conditions.
    Previously this wasn't a problem for internally generated commands,
    since they never hit it.  However, since we do all SCSI commands via
    bios, now they do.  user CD testers like magicdev are now getting not
    ready messages every time they touch the CD to see if there's anything
    in it.
    
    Fix this by making all scsi_execute commands REQ_QUIET and making
    scsi_finish_io() not say anything for REQ_QUIET.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 72a47ce7a1d3..77f2d444f7e0 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -315,7 +315,7 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 	req->sense = sense;
 	req->sense_len = 0;
 	req->timeout = timeout;
-	req->flags |= flags | REQ_BLOCK_PC | REQ_SPECIAL;
+	req->flags |= flags | REQ_BLOCK_PC | REQ_SPECIAL | REQ_QUIET;
 
 	/*
 	 * head injection *required* here otherwise quiesce won't work
@@ -927,17 +927,20 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 				scsi_requeue_command(q, cmd);
 				return;
 			}
-			printk(KERN_INFO "Device %s not ready.\n",
-			       req->rq_disk ? req->rq_disk->disk_name : "");
+			if (!(req->flags & REQ_QUIET))
+				dev_printk(KERN_INFO,
+					   &cmd->device->sdev_gendev,
+					   "Device not ready.\n");
 			cmd = scsi_end_request(cmd, 0, this_count, 1);
 			return;
 		case VOLUME_OVERFLOW:
-			printk(KERN_INFO "Volume overflow <%d %d %d %d> CDB: ",
-			       cmd->device->host->host_no,
-			       (int)cmd->device->channel,
-			       (int)cmd->device->id, (int)cmd->device->lun);
-			__scsi_print_command(cmd->data_cmnd);
-			scsi_print_sense("", cmd);
+			if (!(req->flags & REQ_QUIET)) {
+				dev_printk(KERN_INFO,
+					   &cmd->device->sdev_gendev,
+					   "Volume overflow, CDB: ");
+				__scsi_print_command(cmd->data_cmnd);
+				scsi_print_sense("", cmd);
+			}
 			cmd = scsi_end_request(cmd, 0, block_bytes, 1);
 			return;
 		default:
@@ -954,15 +957,13 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 		return;
 	}
 	if (result) {
-		if (!(req->flags & REQ_SPECIAL))
-			printk(KERN_INFO "SCSI error : <%d %d %d %d> return code "
-			       "= 0x%x\n", cmd->device->host->host_no,
-			       cmd->device->channel,
-			       cmd->device->id,
-			       cmd->device->lun, result);
-
-		if (driver_byte(result) & DRIVER_SENSE)
-			scsi_print_sense("", cmd);
+		if (!(req->flags & REQ_QUIET)) {
+			dev_printk(KERN_INFO, &cmd->device->sdev_gendev,
+				   "SCSI error: return code = 0x%x\n", result);
+
+			if (driver_byte(result) & DRIVER_SENSE)
+				scsi_print_sense("", cmd);
+		}
 		/*
 		 * Mark a single buffer as not uptodate.  Queue the remainder.
 		 * We sometimes get this cruft in the event that a medium error

commit e514385be2b355c1f3fc6385a98a6a0fc04235ae
Author: James Bottomley <James.Bottomley@steeleye.com>
Date:   Tue Aug 9 11:55:36 2005 -0500

    [SCSI] fix sense buffer length handling problem
    
    The new bio code was incorrectly converted from stack allocated to
    kmalloc'd buffer handling.  There are two places where it incorrectly
    uses sizeof(*sense) to get the size of the sense buffer.  This
    actually produces one, so no sense data was ever getting back, causing
    failure in things like disk spin up.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 58da7f64c22f..72a47ce7a1d3 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -342,12 +342,12 @@ int scsi_execute_req(struct scsi_device *sdev, const unsigned char *cmd,
 		sense = kmalloc(SCSI_SENSE_BUFFERSIZE, GFP_KERNEL);
 		if (!sense)
 			return DRIVER_ERROR << 24;
-		memset(sense, 0, sizeof(*sense));
+		memset(sense, 0, SCSI_SENSE_BUFFERSIZE);
 	}
 	result = scsi_execute(sdev, cmd, data_direction, buffer, bufflen,
 				  sense, timeout, retries, 0);
 	if (sshdr)
-		scsi_normalize_sense(sense, sizeof(*sense), sshdr);
+		scsi_normalize_sense(sense, SCSI_SENSE_BUFFERSIZE, sshdr);
 
 	kfree(sense);
 	return result;

commit 1ccb48bb163853c24840c0a50c2a6df1affe029c
Author: akpm@osdl.org <akpm@osdl.org>
Date:   Sun Jun 26 00:12:51 2005 -0700

    [SCSI] fix C syntax problem in scsi_lib.c
    
    Older gcc's require variable definitions at the beginning of a block.
    
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index bdea26b56dc4..58da7f64c22f 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -336,14 +336,15 @@ int scsi_execute_req(struct scsi_device *sdev, const unsigned char *cmd,
 		     struct scsi_sense_hdr *sshdr, int timeout, int retries)
 {
 	char *sense = NULL;
-		
+	int result;
+	
 	if (sshdr) {
 		sense = kmalloc(SCSI_SENSE_BUFFERSIZE, GFP_KERNEL);
 		if (!sense)
 			return DRIVER_ERROR << 24;
 		memset(sense, 0, sizeof(*sense));
 	}
-	int result = scsi_execute(sdev, cmd, data_direction, buffer, bufflen,
+	result = scsi_execute(sdev, cmd, data_direction, buffer, bufflen,
 				  sense, timeout, retries, 0);
 	if (sshdr)
 		scsi_normalize_sense(sense, sizeof(*sense), sshdr);

commit ea73a9f23906c374b697cd5b0d64f6dceced63de
Author: James Bottomley <jejb@titanic.(none)>
Date:   Sun Aug 28 11:33:52 2005 -0500

    [SCSI] convert sd to scsi_execute_req (and update the scsi_execute_req API)
    
    This one removes struct scsi_request entirely from sd.  In the process,
    I noticed we have no callers of scsi_wait_req who don't immediately
    normalise the sense, so I updated the API to make it take a struct
    scsi_sense_hdr instead of simply a big sense buffer.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 42edf29223ab..bdea26b56dc4 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -293,8 +293,8 @@ EXPORT_SYMBOL(scsi_wait_req);
  * @retries:	number of times to retry request
  * @flags:	or into request flags;
  *
- * scsi_execute_req returns the req->errors value which is the
- * the scsi_cmnd result field.
+ * returns the req->errors value which is the the scsi_cmnd result
+ * field.
  **/
 int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 		 int data_direction, void *buffer, unsigned bufflen,
@@ -328,9 +328,31 @@ int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
 
 	return ret;
 }
-
 EXPORT_SYMBOL(scsi_execute);
 
+
+int scsi_execute_req(struct scsi_device *sdev, const unsigned char *cmd,
+		     int data_direction, void *buffer, unsigned bufflen,
+		     struct scsi_sense_hdr *sshdr, int timeout, int retries)
+{
+	char *sense = NULL;
+		
+	if (sshdr) {
+		sense = kmalloc(SCSI_SENSE_BUFFERSIZE, GFP_KERNEL);
+		if (!sense)
+			return DRIVER_ERROR << 24;
+		memset(sense, 0, sizeof(*sense));
+	}
+	int result = scsi_execute(sdev, cmd, data_direction, buffer, bufflen,
+				  sense, timeout, retries, 0);
+	if (sshdr)
+		scsi_normalize_sense(sense, sizeof(*sense), sshdr);
+
+	kfree(sense);
+	return result;
+}
+EXPORT_SYMBOL(scsi_execute_req);
+
 /*
  * Function:    scsi_init_cmd_errh()
  *
@@ -1614,7 +1636,7 @@ void scsi_exit_queue(void)
 	}
 }
 /**
- *	__scsi_mode_sense - issue a mode sense, falling back from 10 to 
+ *	scsi_mode_sense - issue a mode sense, falling back from 10 to 
  *		six bytes if necessary.
  *	@sdev:	SCSI device to be queried
  *	@dbd:	set if mode sense will allow block descriptors to be returned
@@ -1634,26 +1656,22 @@ void scsi_exit_queue(void)
 int
 scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
 		  unsigned char *buffer, int len, int timeout, int retries,
-		  struct scsi_mode_data *data, char *sense) {
+		  struct scsi_mode_data *data, struct scsi_sense_hdr *sshdr) {
 	unsigned char cmd[12];
 	int use_10_for_ms;
 	int header_length;
 	int result;
-	char *sense_buffer = NULL;
+	struct scsi_sense_hdr my_sshdr;
 
 	memset(data, 0, sizeof(*data));
 	memset(&cmd[0], 0, 12);
 	cmd[1] = dbd & 0x18;	/* allows DBD and LLBA bits */
 	cmd[2] = modepage;
 
-	if (!sense) {
-		sense_buffer = kmalloc(SCSI_SENSE_BUFFERSIZE, GFP_KERNEL);
-		if (!sense_buffer) {
-			dev_printk(KERN_ERR, &sdev->sdev_gendev, "failed to allocate sense buffer\n");
-			return 0;
-		}
-		sense = sense_buffer;
-	}
+	/* caller might not be interested in sense, but we need it */
+	if (!sshdr)
+		sshdr = &my_sshdr;
+
  retry:
 	use_10_for_ms = sdev->use_10_for_ms;
 
@@ -1673,12 +1691,10 @@ scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
 		header_length = 4;
 	}
 
-	memset(sense, 0, SCSI_SENSE_BUFFERSIZE);
-
 	memset(buffer, 0, len);
 
 	result = scsi_execute_req(sdev, cmd, DMA_FROM_DEVICE, buffer, len,
-				  sense, timeout, retries);
+				  sshdr, timeout, retries);
 
 	/* This code looks awful: what it's doing is making sure an
 	 * ILLEGAL REQUEST sense return identifies the actual command
@@ -1687,11 +1703,9 @@ scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
 
 	if (use_10_for_ms && !scsi_status_is_good(result) &&
 	    (driver_byte(result) & DRIVER_SENSE)) {
-		struct scsi_sense_hdr sshdr;
-
-		if (scsi_normalize_sense(sense, SCSI_SENSE_BUFFERSIZE, &sshdr)) {
-			if ((sshdr.sense_key == ILLEGAL_REQUEST) &&
-			    (sshdr.asc == 0x20) && (sshdr.ascq == 0)) {
+		if (scsi_sense_valid(sshdr)) {
+			if ((sshdr->sense_key == ILLEGAL_REQUEST) &&
+			    (sshdr->asc == 0x20) && (sshdr->ascq == 0)) {
 				/* 
 				 * Invalid command operation code
 				 */
@@ -1718,7 +1732,6 @@ scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
 		}
 	}
 
-	kfree(sense_buffer);
 	return result;
 }
 EXPORT_SYMBOL(scsi_mode_sense);
@@ -1729,17 +1742,15 @@ scsi_test_unit_ready(struct scsi_device *sdev, int timeout, int retries)
 	char cmd[] = {
 		TEST_UNIT_READY, 0, 0, 0, 0, 0,
 	};
-	char sense[SCSI_SENSE_BUFFERSIZE];
+	struct scsi_sense_hdr sshdr;
 	int result;
 	
-	result = scsi_execute_req(sdev, cmd, DMA_NONE, NULL, 0, sense,
+	result = scsi_execute_req(sdev, cmd, DMA_NONE, NULL, 0, &sshdr,
 				  timeout, retries);
 
 	if ((driver_byte(result) & DRIVER_SENSE) && sdev->removable) {
-		struct scsi_sense_hdr sshdr;
 
-		if ((scsi_normalize_sense(sense, SCSI_SENSE_BUFFERSIZE,
-					  &sshdr)) &&
+		if ((scsi_sense_valid(&sshdr)) &&
 		    ((sshdr.sense_key == UNIT_ATTENTION) ||
 		     (sshdr.sense_key == NOT_READY))) {
 			sdev->changed = 1;

commit 33aa687db90dd8541bd5e9a762eebf880eaee767
Author: James Bottomley <jejb@titanic.(none)>
Date:   Sun Aug 28 11:31:14 2005 -0500

    [SCSI] convert SPI transport class to scsi_execute
    
    This one's slightly more difficult.  The transport class uses
    REQ_FAILFAST, so another interface (scsi_execute) had to be invented to
    take the extra flag.  Also, the sense functions are shifted around to
    allow spi_execute to place data directly into a struct scsi_sense_hdr.
    With this change, there's probably a lot of unnecessary sense buffer
    allocation going on which we can fix later.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 3f3accd6cd46..42edf29223ab 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -282,7 +282,7 @@ void scsi_wait_req(struct scsi_request *sreq, const void *cmnd, void *buffer,
 EXPORT_SYMBOL(scsi_wait_req);
 
 /**
- * scsi_execute_req - insert request and wait for the result
+ * scsi_execute - insert request and wait for the result
  * @sdev:	scsi device
  * @cmd:	scsi command
  * @data_direction: data direction
@@ -291,13 +291,14 @@ EXPORT_SYMBOL(scsi_wait_req);
  * @sense:	optional sense buffer
  * @timeout:	request timeout in seconds
  * @retries:	number of times to retry request
+ * @flags:	or into request flags;
  *
  * scsi_execute_req returns the req->errors value which is the
  * the scsi_cmnd result field.
  **/
-int scsi_execute_req(struct scsi_device *sdev, unsigned char *cmd,
-		     int data_direction, void *buffer, unsigned bufflen,
-		     unsigned char *sense, int timeout, int retries)
+int scsi_execute(struct scsi_device *sdev, const unsigned char *cmd,
+		 int data_direction, void *buffer, unsigned bufflen,
+		 unsigned char *sense, int timeout, int retries, int flags)
 {
 	struct request *req;
 	int write = (data_direction == DMA_TO_DEVICE);
@@ -314,7 +315,7 @@ int scsi_execute_req(struct scsi_device *sdev, unsigned char *cmd,
 	req->sense = sense;
 	req->sense_len = 0;
 	req->timeout = timeout;
-	req->flags |= REQ_BLOCK_PC | REQ_SPECIAL;
+	req->flags |= flags | REQ_BLOCK_PC | REQ_SPECIAL;
 
 	/*
 	 * head injection *required* here otherwise quiesce won't work
@@ -328,7 +329,7 @@ int scsi_execute_req(struct scsi_device *sdev, unsigned char *cmd,
 	return ret;
 }
 
-EXPORT_SYMBOL(scsi_execute_req);
+EXPORT_SYMBOL(scsi_execute);
 
 /*
  * Function:    scsi_init_cmd_errh()

commit 1cf72699c1530c3e4ac3d58344f6a6a40a2f46d3
Author: James Bottomley <jejb@titanic.(none)>
Date:   Sun Aug 28 11:27:01 2005 -0500

    [SCSI] convert the remaining mid-layer pieces to scsi_execute_req
    
    After this, we just have some drivers, all the ULDs and the SPI
    transport class using scsi_wait_req().
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 278e0c99b2ae..3f3accd6cd46 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1615,7 +1615,7 @@ void scsi_exit_queue(void)
 /**
  *	__scsi_mode_sense - issue a mode sense, falling back from 10 to 
  *		six bytes if necessary.
- *	@sreq:	SCSI request to fill in with the MODE_SENSE
+ *	@sdev:	SCSI device to be queried
  *	@dbd:	set if mode sense will allow block descriptors to be returned
  *	@modepage: mode page being requested
  *	@buffer: request buffer (may not be smaller than eight bytes)
@@ -1623,26 +1623,38 @@ void scsi_exit_queue(void)
  *	@timeout: command timeout
  *	@retries: number of retries before failing
  *	@data: returns a structure abstracting the mode header data
+ *	@sense: place to put sense data (or NULL if no sense to be collected).
+ *		must be SCSI_SENSE_BUFFERSIZE big.
  *
  *	Returns zero if unsuccessful, or the header offset (either 4
  *	or 8 depending on whether a six or ten byte command was
  *	issued) if successful.
  **/
 int
-__scsi_mode_sense(struct scsi_request *sreq, int dbd, int modepage,
+scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
 		  unsigned char *buffer, int len, int timeout, int retries,
-		  struct scsi_mode_data *data) {
+		  struct scsi_mode_data *data, char *sense) {
 	unsigned char cmd[12];
 	int use_10_for_ms;
 	int header_length;
+	int result;
+	char *sense_buffer = NULL;
 
 	memset(data, 0, sizeof(*data));
 	memset(&cmd[0], 0, 12);
 	cmd[1] = dbd & 0x18;	/* allows DBD and LLBA bits */
 	cmd[2] = modepage;
 
+	if (!sense) {
+		sense_buffer = kmalloc(SCSI_SENSE_BUFFERSIZE, GFP_KERNEL);
+		if (!sense_buffer) {
+			dev_printk(KERN_ERR, &sdev->sdev_gendev, "failed to allocate sense buffer\n");
+			return 0;
+		}
+		sense = sense_buffer;
+	}
  retry:
-	use_10_for_ms = sreq->sr_device->use_10_for_ms;
+	use_10_for_ms = sdev->use_10_for_ms;
 
 	if (use_10_for_ms) {
 		if (len < 8)
@@ -1660,36 +1672,35 @@ __scsi_mode_sense(struct scsi_request *sreq, int dbd, int modepage,
 		header_length = 4;
 	}
 
-	sreq->sr_cmd_len = 0;
-	memset(sreq->sr_sense_buffer, 0, sizeof(sreq->sr_sense_buffer));
-	sreq->sr_data_direction = DMA_FROM_DEVICE;
+	memset(sense, 0, SCSI_SENSE_BUFFERSIZE);
 
 	memset(buffer, 0, len);
 
-	scsi_wait_req(sreq, cmd, buffer, len, timeout, retries);
+	result = scsi_execute_req(sdev, cmd, DMA_FROM_DEVICE, buffer, len,
+				  sense, timeout, retries);
 
 	/* This code looks awful: what it's doing is making sure an
 	 * ILLEGAL REQUEST sense return identifies the actual command
 	 * byte as the problem.  MODE_SENSE commands can return
 	 * ILLEGAL REQUEST if the code page isn't supported */
 
-	if (use_10_for_ms && !scsi_status_is_good(sreq->sr_result) &&
-	    (driver_byte(sreq->sr_result) & DRIVER_SENSE)) {
+	if (use_10_for_ms && !scsi_status_is_good(result) &&
+	    (driver_byte(result) & DRIVER_SENSE)) {
 		struct scsi_sense_hdr sshdr;
 
-		if (scsi_request_normalize_sense(sreq, &sshdr)) {
+		if (scsi_normalize_sense(sense, SCSI_SENSE_BUFFERSIZE, &sshdr)) {
 			if ((sshdr.sense_key == ILLEGAL_REQUEST) &&
 			    (sshdr.asc == 0x20) && (sshdr.ascq == 0)) {
 				/* 
 				 * Invalid command operation code
 				 */
-				sreq->sr_device->use_10_for_ms = 0;
+				sdev->use_10_for_ms = 0;
 				goto retry;
 			}
 		}
 	}
 
-	if(scsi_status_is_good(sreq->sr_result)) {
+	if(scsi_status_is_good(result)) {
 		data->header_length = header_length;
 		if(use_10_for_ms) {
 			data->length = buffer[0]*256 + buffer[1] + 2;
@@ -1706,73 +1717,34 @@ __scsi_mode_sense(struct scsi_request *sreq, int dbd, int modepage,
 		}
 	}
 
-	return sreq->sr_result;
-}
-EXPORT_SYMBOL(__scsi_mode_sense);
-
-/**
- *	scsi_mode_sense - issue a mode sense, falling back from 10 to 
- *		six bytes if necessary.
- *	@sdev:	scsi device to send command to.
- *	@dbd:	set if mode sense will disable block descriptors in the return
- *	@modepage: mode page being requested
- *	@buffer: request buffer (may not be smaller than eight bytes)
- *	@len:	length of request buffer.
- *	@timeout: command timeout
- *	@retries: number of retries before failing
- *
- *	Returns zero if unsuccessful, or the header offset (either 4
- *	or 8 depending on whether a six or ten byte command was
- *	issued) if successful.
- **/
-int
-scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
-		unsigned char *buffer, int len, int timeout, int retries,
-		struct scsi_mode_data *data)
-{
-	struct scsi_request *sreq = scsi_allocate_request(sdev, GFP_KERNEL);
-	int ret;
-
-	if (!sreq)
-		return -1;
-
-	ret = __scsi_mode_sense(sreq, dbd, modepage, buffer, len,
-				timeout, retries, data);
-
-	scsi_release_request(sreq);
-
-	return ret;
+	kfree(sense_buffer);
+	return result;
 }
 EXPORT_SYMBOL(scsi_mode_sense);
 
 int
 scsi_test_unit_ready(struct scsi_device *sdev, int timeout, int retries)
 {
-	struct scsi_request *sreq;
 	char cmd[] = {
 		TEST_UNIT_READY, 0, 0, 0, 0, 0,
 	};
+	char sense[SCSI_SENSE_BUFFERSIZE];
 	int result;
 	
-	sreq = scsi_allocate_request(sdev, GFP_KERNEL);
-	if (!sreq)
-		return -ENOMEM;
-
-	sreq->sr_data_direction = DMA_NONE;
-	scsi_wait_req(sreq, cmd, NULL, 0, timeout, retries);
+	result = scsi_execute_req(sdev, cmd, DMA_NONE, NULL, 0, sense,
+				  timeout, retries);
 
-	if ((driver_byte(sreq->sr_result) & DRIVER_SENSE) && sdev->removable) {
+	if ((driver_byte(result) & DRIVER_SENSE) && sdev->removable) {
 		struct scsi_sense_hdr sshdr;
 
-		if ((scsi_request_normalize_sense(sreq, &sshdr)) &&
+		if ((scsi_normalize_sense(sense, SCSI_SENSE_BUFFERSIZE,
+					  &sshdr)) &&
 		    ((sshdr.sense_key == UNIT_ATTENTION) ||
 		     (sshdr.sense_key == NOT_READY))) {
 			sdev->changed = 1;
-			sreq->sr_result = 0;
+			result = 0;
 		}
 	}
-	result = sreq->sr_result;
-	scsi_release_request(sreq);
 	return result;
 }
 EXPORT_SYMBOL(scsi_test_unit_ready);

commit 7a93aef7fbac6f4db40b6fec5c0c6b654ae7a93c
Merge: 392160335c79 8224bfa84d51
Author: James Bottomley <jejb@titanic.(none)>
Date:   Sun Aug 28 11:18:35 2005 -0500

    Merge HEAD from ../scsi-misc-2.6-tmp

commit 392160335c798bbe94ab3aae6ea0c85d32b81bbc
Author: James Bottomley <jejb@titanic.(none)>
Date:   Wed Jun 15 18:48:29 2005 -0500

    [SCSI] use scatter lists for all block pc requests and simplify hw handlers
    
    Original From: Mike Christie <michaelc@cs.wisc.edu>
    
    Add scsi_execute_req() as a replacement for scsi_wait_req()
    
    Fixed up various pieces (added REQ_SPECIAL and caught req use after
    free)
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 60f07b6a5ffc..b8212c563fed 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -246,7 +246,7 @@ void scsi_wait_req(struct scsi_request *sreq, const void *cmnd, void *buffer,
 		   unsigned bufflen, int timeout, int retries)
 {
 	DECLARE_COMPLETION(wait);
-	int write = sreq->sr_data_direction == DMA_TO_DEVICE;
+	int write = (sreq->sr_data_direction == DMA_TO_DEVICE);
 	struct request *req;
 
 	req = blk_get_request(sreq->sr_device->request_queue, write,
@@ -281,6 +281,55 @@ void scsi_wait_req(struct scsi_request *sreq, const void *cmnd, void *buffer,
 
 EXPORT_SYMBOL(scsi_wait_req);
 
+/**
+ * scsi_execute_req - insert request and wait for the result
+ * @sdev:	scsi device
+ * @cmd:	scsi command
+ * @data_direction: data direction
+ * @buffer:	data buffer
+ * @bufflen:	len of buffer
+ * @sense:	optional sense buffer
+ * @timeout:	request timeout in seconds
+ * @retries:	number of times to retry request
+ *
+ * scsi_execute_req returns the req->errors value which is the
+ * the scsi_cmnd result field.
+ **/
+int scsi_execute_req(struct scsi_device *sdev, unsigned char *cmd,
+		     int data_direction, void *buffer, unsigned bufflen,
+		     unsigned char *sense, int timeout, int retries)
+{
+	struct request *req;
+	int write = (data_direction == DMA_TO_DEVICE);
+	int ret = DRIVER_ERROR << 24;
+
+	req = blk_get_request(sdev->request_queue, write, __GFP_WAIT);
+
+	if (bufflen &&	blk_rq_map_kern(sdev->request_queue, req,
+					buffer, bufflen, __GFP_WAIT))
+		goto out;
+
+	req->cmd_len = COMMAND_SIZE(cmd[0]);
+	memcpy(req->cmd, cmd, req->cmd_len);
+	req->sense = sense;
+	req->sense_len = 0;
+	req->timeout = timeout;
+	req->flags |= REQ_BLOCK_PC | REQ_SPECIAL;
+
+	/*
+	 * head injection *required* here otherwise quiesce won't work
+	 */
+	blk_execute_rq(req->q, NULL, req, 1);
+
+	ret = req->errors;
+ out:
+	blk_put_request(req);
+
+	return ret;
+}
+
+EXPORT_SYMBOL(scsi_execute_req);
+
 /*
  * Function:    scsi_init_cmd_errh()
  *

commit 8e6401187ef7fb1edc2740832b48bf47ed2c90f2
Author: James Bottomley <jejb@titanic.(none)>
Date:   Wed Jun 15 18:16:09 2005 -0500

    update scsi_wait_req to new format for blk_rq_map_kern()
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 253c1a98d159..60f07b6a5ffc 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -246,15 +246,18 @@ void scsi_wait_req(struct scsi_request *sreq, const void *cmnd, void *buffer,
 		   unsigned bufflen, int timeout, int retries)
 {
 	DECLARE_COMPLETION(wait);
+	int write = sreq->sr_data_direction == DMA_TO_DEVICE;
 	struct request *req;
 
-	if (bufflen)
-		req = blk_rq_map_kern(sreq->sr_device->request_queue,
-				      sreq->sr_data_direction == DMA_TO_DEVICE,
-				      buffer, bufflen, __GFP_WAIT);
-	else
-		req = blk_get_request(sreq->sr_device->request_queue, READ,
-				      __GFP_WAIT);
+	req = blk_get_request(sreq->sr_device->request_queue, write,
+			      __GFP_WAIT);
+	if (bufflen && blk_rq_map_kern(sreq->sr_device->request_queue, req,
+				       buffer, bufflen, __GFP_WAIT)) {
+		sreq->sr_result = DRIVER_ERROR << 24;
+		blk_put_request(req);
+		return;
+	}
+
 	req->flags |= REQ_NOMERGE;
 	req->waiting = &wait;
 	req->end_io = scsi_wait_req_end_io;

commit e537a36d528053f6b9dbe6c88e763e835c0d3517
Author: James Bottomley <James.Bottomley@steeleye.com>
Date:   Sun Jun 5 02:07:14 2005 -0500

    [SCSI] use scatter lists for all block pc requests and simplify hw handlers
    
    Here's the proof of concept for this one.  It converts scsi_wait_req to
    do correct REQ_BLOCK_PC submission (and works nicely in my setup).
    
    The final goal should be to eliminate struct scsi_request, but that
    can't be done until the character submission paths of sg and st are also
    modified.
    
    There's some loss of functionality to this: retries are no longer
    controllable (except by setting REQ_FASTFAIL) and the wait_req API needs
    to be altered, but it looks very nice.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 7a91ca3d32a6..253c1a98d159 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -232,23 +232,6 @@ void scsi_do_req(struct scsi_request *sreq, const void *cmnd,
 }
 EXPORT_SYMBOL(scsi_do_req);
 
-static void scsi_wait_done(struct scsi_cmnd *cmd)
-{
-	struct request *req = cmd->request;
-	struct request_queue *q = cmd->device->request_queue;
-	unsigned long flags;
-
-	req->rq_status = RQ_SCSI_DONE;	/* Busy, but indicate request done */
-
-	spin_lock_irqsave(q->queue_lock, flags);
-	if (blk_rq_tagged(req))
-		blk_queue_end_tag(q, req);
-	spin_unlock_irqrestore(q->queue_lock, flags);
-
-	if (req->waiting)
-		complete(req->waiting);
-}
-
 /* This is the end routine we get to if a command was never attached
  * to the request.  Simply complete the request without changing
  * rq_status; this will cause a DRIVER_ERROR. */
@@ -263,19 +246,36 @@ void scsi_wait_req(struct scsi_request *sreq, const void *cmnd, void *buffer,
 		   unsigned bufflen, int timeout, int retries)
 {
 	DECLARE_COMPLETION(wait);
-	
-	sreq->sr_request->waiting = &wait;
-	sreq->sr_request->rq_status = RQ_SCSI_BUSY;
-	sreq->sr_request->end_io = scsi_wait_req_end_io;
-	scsi_do_req(sreq, cmnd, buffer, bufflen, scsi_wait_done,
-			timeout, retries);
+	struct request *req;
+
+	if (bufflen)
+		req = blk_rq_map_kern(sreq->sr_device->request_queue,
+				      sreq->sr_data_direction == DMA_TO_DEVICE,
+				      buffer, bufflen, __GFP_WAIT);
+	else
+		req = blk_get_request(sreq->sr_device->request_queue, READ,
+				      __GFP_WAIT);
+	req->flags |= REQ_NOMERGE;
+	req->waiting = &wait;
+	req->end_io = scsi_wait_req_end_io;
+	req->cmd_len = COMMAND_SIZE(((u8 *)cmnd)[0]);
+	req->sense = sreq->sr_sense_buffer;
+	req->sense_len = 0;
+	memcpy(req->cmd, cmnd, req->cmd_len);
+	req->timeout = timeout;
+	req->flags |= REQ_BLOCK_PC;
+	req->rq_disk = NULL;
+	blk_insert_request(sreq->sr_device->request_queue, req,
+			   sreq->sr_data_direction == DMA_TO_DEVICE, NULL);
 	wait_for_completion(&wait);
 	sreq->sr_request->waiting = NULL;
-	if (sreq->sr_request->rq_status != RQ_SCSI_DONE)
+	sreq->sr_result = req->errors;
+	if (req->errors)
 		sreq->sr_result |= (DRIVER_ERROR << 24);
 
-	__scsi_release_request(sreq);
+	blk_put_request(req);
 }
+
 EXPORT_SYMBOL(scsi_wait_req);
 
 /*
@@ -878,11 +878,12 @@ void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
 		return;
 	}
 	if (result) {
-		printk(KERN_INFO "SCSI error : <%d %d %d %d> return code "
-		       "= 0x%x\n", cmd->device->host->host_no,
-		       cmd->device->channel,
-		       cmd->device->id,
-		       cmd->device->lun, result);
+		if (!(req->flags & REQ_SPECIAL))
+			printk(KERN_INFO "SCSI error : <%d %d %d %d> return code "
+			       "= 0x%x\n", cmd->device->host->host_no,
+			       cmd->device->channel,
+			       cmd->device->id,
+			       cmd->device->lun, result);
 
 		if (driver_byte(result) & DRIVER_SENSE)
 			scsi_print_sense("", cmd);
@@ -1020,6 +1021,12 @@ static int scsi_issue_flush_fn(request_queue_t *q, struct gendisk *disk,
 	return -EOPNOTSUPP;
 }
 
+static void scsi_generic_done(struct scsi_cmnd *cmd)
+{
+	BUG_ON(!blk_pc_request(cmd->request));
+	scsi_io_completion(cmd, cmd->result == 0 ? cmd->bufflen : 0, 0);
+}
+
 static int scsi_prep_fn(struct request_queue *q, struct request *req)
 {
 	struct scsi_device *sdev = q->queuedata;
@@ -1061,7 +1068,7 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 	 * these two cases differently.  We differentiate by looking
 	 * at request->cmd, as this tells us the real story.
 	 */
-	if (req->flags & REQ_SPECIAL) {
+	if (req->flags & REQ_SPECIAL && req->special) {
 		struct scsi_request *sreq = req->special;
 
 		if (sreq->sr_magic == SCSI_REQ_MAGIC) {
@@ -1073,7 +1080,7 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 			cmd = req->special;
 	} else if (req->flags & (REQ_CMD | REQ_BLOCK_PC)) {
 
-		if(unlikely(specials_only)) {
+		if(unlikely(specials_only) && !(req->flags & REQ_SPECIAL)) {
 			if(specials_only == SDEV_QUIESCE ||
 					specials_only == SDEV_BLOCK)
 				return BLKPREP_DEFER;
@@ -1142,11 +1149,26 @@ static int scsi_prep_fn(struct request_queue *q, struct request *req)
 		/*
 		 * Initialize the actual SCSI command for this request.
 		 */
-		drv = *(struct scsi_driver **)req->rq_disk->private_data;
-		if (unlikely(!drv->init_command(cmd))) {
-			scsi_release_buffers(cmd);
-			scsi_put_command(cmd);
-			return BLKPREP_KILL;
+		if (req->rq_disk) {
+			drv = *(struct scsi_driver **)req->rq_disk->private_data;
+			if (unlikely(!drv->init_command(cmd))) {
+				scsi_release_buffers(cmd);
+				scsi_put_command(cmd);
+				return BLKPREP_KILL;
+			}
+		} else {
+			memcpy(cmd->cmnd, req->cmd, sizeof(cmd->cmnd));
+			if (rq_data_dir(req) == WRITE)
+				cmd->sc_data_direction = DMA_TO_DEVICE;
+			else if (req->data_len)
+				cmd->sc_data_direction = DMA_FROM_DEVICE;
+			else
+				cmd->sc_data_direction = DMA_NONE;
+			
+			cmd->transfersize = req->data_len;
+			cmd->allowed = 3;
+			cmd->timeout_per_command = req->timeout;
+			cmd->done = scsi_generic_done;
 		}
 	}
 

commit d3301874083874f8a0ac88aa1bb7da6b62df34d2
Author: Mike Anderson <andmike@us.ibm.com>
Date:   Thu Jun 16 11:12:38 2005 -0700

    [SCSI] host state model update: replace old host bitmap state
    
    Migrate the current SCSI host state model to a model like SCSI
    device is using.
    
    Signed-off-by: Mike Anderson <andmike@us.ibm.com>
    
    Rejections fixed up and
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 7a91ca3d32a6..060010bccabc 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -348,7 +348,7 @@ void scsi_device_unbusy(struct scsi_device *sdev)
 
 	spin_lock_irqsave(shost->host_lock, flags);
 	shost->host_busy--;
-	if (unlikely(test_bit(SHOST_RECOVERY, &shost->shost_state) &&
+	if (unlikely((shost->shost_state == SHOST_RECOVERY) &&
 		     shost->host_failed))
 		scsi_eh_wakeup(shost);
 	spin_unlock(shost->host_lock);
@@ -1207,7 +1207,7 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 				   struct Scsi_Host *shost,
 				   struct scsi_device *sdev)
 {
-	if (test_bit(SHOST_RECOVERY, &shost->shost_state))
+	if (shost->shost_state == SHOST_RECOVERY)
 		return 0;
 	if (shost->host_busy == 0 && shost->host_blocked) {
 		/*

commit 2d986010ad13a00b83851238d52601d6092df40e
Merge: 6b6a93c6876e e10fb91c4dc8
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Tue Jul 26 13:28:47 2005 -0700

    Merge master.kernel.org:/pub/scm/linux/kernel/git/jejb/scsi-for-linus-2.6

commit 0f34e3f53378a11c9ecba0f8165da50e8b01d53f
Author: Chen, Kenneth W <kenneth.w.chen@intel.com>
Date:   Tue Jul 12 17:06:14 2005 -0700

    [SCSI] Redundant memset in scsi_alloc_sgtable
    
    scsi_init_io calls scsi_alloc_sgtable and then calls blk_rq_map_sg
    to initialize the scatterlist structure.  blk_rq_map_sg() already
    memset the structure for every new segment.  That makes the memset
    in scsi_alloc_sgtable unnecessary.
    
    Patch to delete the extra memset in scsi_alloc_sgtable.  Tested on
    a x86_64 machine.  Looks stable to me.
    
    Signed-off-by: Ken Chen <kenneth.w.chen@intel.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 58dcb0534a26..cab535809d0d 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -614,8 +614,6 @@ static struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, int gfp_mas
 
 	sgp = scsi_sg_pools + cmd->sglist_len;
 	sgl = mempool_alloc(sgp->pool, gfp_mask);
-	if (sgl)
-		memset(sgl, 0, sgp->size);
 	return sgl;
 }
 

commit a77e3362a224212d9d3b9e6fdec44df2eef6cf92
Author: KAMBAROV, ZAUR <kambarov@berkeley.edu>
Date:   Tue Jun 28 20:45:06 2005 -0700

    [PATCH] coverity: i386: scsi_lib buffer overrun fix
    
    The check in
    
    627             BUG_ON(index > SG_MEMPOOL_NR);
    
    with SG_MEMPOOL_NR defined in
    
    32      #define SG_MEMPOOL_NR           (sizeof(scsi_sg_pools)/sizeof(struct scsi_host_sg_pool))
    
    was not sufficient.
    
    sgp, set in
    
    629             sgp = scsi_sg_pools + index;
    
    is dereferenced in
    
    630             mempool_free(sgl, sgp->pool);
    
    Signed-off-by: Zaur Kambarov <zkambarov@coverity.com>
    Cc: <linux-scsi@vger.kernel.org>
    Cc: James Bottomley <James.Bottomley@steeleye.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 621dee8b8cb2..10506f9cd0c9 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -632,7 +632,7 @@ static void scsi_free_sgtable(struct scatterlist *sgl, int index)
 {
 	struct scsi_host_sg_pool *sgp;
 
-	BUG_ON(index > SG_MEMPOOL_NR);
+	BUG_ON(index >= SG_MEMPOOL_NR);
 
 	sgp = scsi_sg_pools + index;
 	mempool_free(sgl, sgp->pool);

commit 8d115f845a0bd59cd263e791f739964f42b7b0e8
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Jun 19 13:42:05 2005 +0200

    [SCSI] remove scsi_cmnd->state
    
    We never look at it except for the old megaraid driver that abuses it
    for sending internal commands.  That usage can be fixed easily because
    those internal commands are single-threaded by a mutex and we can easily
    use a completion there.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 912cea081119..58dcb0534a26 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -145,11 +145,6 @@ int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 	else if (reason == SCSI_MLQUEUE_DEVICE_BUSY)
 		device->device_blocked = device->max_device_blocked;
 
-	/*
-	 * Register the fact that we own the thing for now.
-	 */
-	cmd->state = SCSI_STATE_MLQUEUE;
-
 	/*
 	 * Decrement the counters, since these commands are no longer
 	 * active on the host/device.

commit b4edcbcafdecc80ef5356ff6452768b1b926ea76
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Jun 19 13:40:52 2005 +0200

    [SCSI] remove scsi_cmnd->owner
    
    never checked anywhere
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index b4f320854d66..912cea081119 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -149,7 +149,6 @@ int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 	 * Register the fact that we own the thing for now.
 	 */
 	cmd->state = SCSI_STATE_MLQUEUE;
-	cmd->owner = SCSI_OWNER_MIDLEVEL;
 
 	/*
 	 * Decrement the counters, since these commands are no longer
@@ -299,7 +298,6 @@ EXPORT_SYMBOL(scsi_wait_req);
  */
 static int scsi_init_cmd_errh(struct scsi_cmnd *cmd)
 {
-	cmd->owner = SCSI_OWNER_MIDLEVEL;
 	cmd->serial_number = 0;
 
 	memset(cmd->sense_buffer, 0, sizeof cmd->sense_buffer);

commit f5ad56145d43cdb68760bba3e14655ff6ae726aa
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Jun 19 13:40:08 2005 +0200

    [SCSI] remove scsi_cmnd->abort_reason
    
    Never used for anything but printing it out in debug routines.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 621dee8b8cb2..b4f320854d66 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -301,7 +301,6 @@ static int scsi_init_cmd_errh(struct scsi_cmnd *cmd)
 {
 	cmd->owner = SCSI_OWNER_MIDLEVEL;
 	cmd->serial_number = 0;
-	cmd->abort_reason = 0;
 
 	memset(cmd->sense_buffer, 0, sizeof cmd->sense_buffer);
 
@@ -322,7 +321,6 @@ static int scsi_init_cmd_errh(struct scsi_cmnd *cmd)
 	memcpy(cmd->data_cmnd, cmd->cmnd, sizeof(cmd->cmnd));
 	cmd->buffer = cmd->request_buffer;
 	cmd->bufflen = cmd->request_bufflen;
-	cmd->abort_reason = 0;
 
 	return 1;
 }

commit 52c1da39534fb382c061de58b65f678ad74b59f5
Author: Adrian Bunk <bunk@stusta.de>
Date:   Thu Jun 23 22:05:33 2005 -0700

    [PATCH] make various thing static
    
    Another rollup of patches which give various symbols static scope
    
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 9f996499fa9d..621dee8b8cb2 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -44,7 +44,7 @@ struct scsi_host_sg_pool {
 #endif
 
 #define SP(x) { x, "sgpool-" #x } 
-struct scsi_host_sg_pool scsi_sg_pools[] = { 
+static struct scsi_host_sg_pool scsi_sg_pools[] = {
 	SP(8),
 	SP(16),
 	SP(32),

commit d8c37e7b9a619855e05d5d4e56c68f799b1f539c
Author: Tejun Heo <htejun@gmail.com>
Date:   Sat May 14 00:46:08 2005 +0900

    [SCSI] remove a timer race in scsi_queue_insert()
    
    scsi_queue_insert() has four callers.  Three callers call with
    timer disabled and one (the second invocation in
    scsi_dispatch_cmd()) calls with timer activated.
    scsi_queue_insert() used to always call scsi_delete_timer()
    and ignore the return value.  This results in race with timer
    expiration.  Remove scsi_delete_timer() call from
    scsi_queue_insert() and make the caller delete timer and check
    the return value.
    
    Signed-off-by: Tejun Heo <htejun@gmail.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index c3bb28c3feef..9f996499fa9d 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -128,13 +128,7 @@ int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 		 printk("Inserting command %p into mlqueue\n", cmd));
 
 	/*
-	 * We are inserting the command into the ml queue.  First, we
-	 * cancel the timer, so it doesn't time out.
-	 */
-	scsi_delete_timer(cmd);
-
-	/*
-	 * Next, set the appropriate busy bit for the device/host.
+	 * Set the appropriate busy bit for the device/host.
 	 *
 	 * If the host/device isn't busy, assume that something actually
 	 * completed, and that we should be able to queue a command now.

commit a1bf9d1d9272708922e83e465104106131f6415f
Author: Tejun Heo <htejun@gmail.com>
Date:   Sun Apr 24 02:08:52 2005 -0500

    [SCSI] make scsi_queue_insert() use blk_requeue_request()
    
    scsi_queue_insert() used to use blk_insert_request() for requeueing
    requests.  This depends on the unobvious behavior of
    blk_insert_request() setting REQ_SPECIAL and REQ_SOFTBARRIER when
    requeueing.  This patch makes scsi_queue_insert() use
    blk_requeue_request().  As REQ_SPECIAL means special requests and
    REQ_SOFTBARRIER is automatically handled by blk layer now, no flag
    needs to be set.
    
    Note that scsi_queue_insert() now calls scsi_run_queue() itself, and
    the prototype of the function is added right above
    scsi_queue_insert().  This is temporary, as later requeue path
    consolidation patchset removes scsi_queue_insert().  By adding
    temporary prototype, we can do away with unnecessarily moving
    functions.
    
    Signed-off-by: Tejun Heo <htejun@gmail.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 0b33e4f1a51e..c3bb28c3feef 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -96,6 +96,8 @@ int scsi_insert_special_req(struct scsi_request *sreq, int at_head)
 	return 0;
 }
 
+static void scsi_run_queue(struct request_queue *q);
+
 /*
  * Function:    scsi_queue_insert()
  *
@@ -119,6 +121,8 @@ int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 {
 	struct Scsi_Host *host = cmd->device->host;
 	struct scsi_device *device = cmd->device;
+	struct request_queue *q = device->request_queue;
+	unsigned long flags;
 
 	SCSI_LOG_MLQUEUE(1,
 		 printk("Inserting command %p into mlqueue\n", cmd));
@@ -160,17 +164,22 @@ int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
 	scsi_device_unbusy(device);
 
 	/*
-	 * Insert this command at the head of the queue for it's device.
-	 * It will go before all other commands that are already in the queue.
+	 * Requeue this command.  It will go before all other commands
+	 * that are already in the queue.
 	 *
 	 * NOTE: there is magic here about the way the queue is plugged if
 	 * we have no outstanding commands.
 	 * 
-	 * Although this *doesn't* plug the queue, it does call the request
+	 * Although we *don't* plug the queue, we call the request
 	 * function.  The SCSI request function detects the blocked condition
 	 * and plugs the queue appropriately.
-	 */
-	blk_insert_request(device->request_queue, cmd->request, 1, cmd, 1);
+         */
+	spin_lock_irqsave(q->queue_lock, flags);
+	blk_requeue_request(q, cmd->request);
+	spin_unlock_irqrestore(q->queue_lock, flags);
+
+	scsi_run_queue(q);
+
 	return 0;
 }
 

commit 283369ccc26705bd9585a0e533c92bd7364c28d1
Author: Tejun Heo <htejun@gmail.com>
Date:   Sun Apr 24 02:06:36 2005 -0500

    [SCSI] make scsi_requeue_request() use blk_requeue_request()
    
    scsi_requeue_request() used to use blk_insert_request() for requeueing
    requests.  This depends on the unobvious behavior of
    blk_insert_request() setting REQ_SPECIAL and REQ_SOFTBARRIER when
    requeueing.  This patch makes scsi_queue_insert() use
    blk_requeue_request().  As REQ_SPECIAL means special requests and
    REQ_SOFTBARRIER is automatically handled by blk layer now, no flag
    needs to be set.
    
    Signed-off-by: Tejun Heo <htejun@gmail.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 47a4ad40bf4e..0b33e4f1a51e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -485,8 +485,13 @@ static void scsi_run_queue(struct request_queue *q)
  */
 static void scsi_requeue_command(struct request_queue *q, struct scsi_cmnd *cmd)
 {
+	unsigned long flags;
+
 	cmd->request->flags &= ~REQ_DONTPREP;
-	blk_insert_request(q, cmd->request, 1, cmd, 1);
+
+	spin_lock_irqsave(q->queue_lock, flags);
+	blk_requeue_request(q, cmd->request);
+	spin_unlock_irqrestore(q->queue_lock, flags);
 
 	scsi_run_queue(q);
 }

commit 867d1191fca388a79e4bb500dd85a9e871c96b99
Author: Tejun Heo <htejun@gmail.com>
Date:   Sun Apr 24 02:06:05 2005 -0500

    [SCSI] remove requeue feature from blk_insert_request()
    
    blk_insert_request() has a unobivous feature of requeuing a
    request setting REQ_SPECIAL|REQ_SOFTBARRIER.  SCSI midlayer
    was the only user and as previous patches removed the usage,
    remove the feature from blk_insert_request().  Only special
    requests should be queued with blk_insert_request().  All
    requeueing should go through blk_requeue_request().
    
    Signed-off-by: Tejun Heo <htejun@gmail.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 861d5f5c9722..47a4ad40bf4e 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -92,7 +92,7 @@ int scsi_insert_special_req(struct scsi_request *sreq, int at_head)
 	 */
 	sreq->sr_request->flags &= ~REQ_DONTPREP;
 	blk_insert_request(sreq->sr_device->request_queue, sreq->sr_request,
-		       	   at_head, sreq, 0);
+		       	   at_head, sreq);
 	return 0;
 }
 

commit beb6617d994161a6b12c5f69afc6fb154f085447
Author: Tejun Heo <htejun@gmail.com>
Date:   Sun Apr 24 02:04:53 2005 -0500

    [SCSI] remove REQ_SPECIAL in scsi_init_io()
    
    scsi_init_io() used to set REQ_SPECIAL when it fails sg
    allocation before requeueing the request by returning
    BLKPREP_DEFER.  REQ_SPECIAL is being updated to mean special
    requests.  So, remove REQ_SPECIAL setting.
    
    Signed-off-by: Tejun Heo <htejun@gmail.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d18da21c9c57..861d5f5c9722 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -941,10 +941,8 @@ static int scsi_init_io(struct scsi_cmnd *cmd)
 	 * if sg table allocation fails, requeue request later.
 	 */
 	sgpnt = scsi_alloc_sgtable(cmd, GFP_ATOMIC);
-	if (unlikely(!sgpnt)) {
-		req->flags |= REQ_SPECIAL;
+	if (unlikely(!sgpnt))
 		return BLKPREP_DEFER;
-	}
 
 	cmd->request_buffer = (char *) sgpnt;
 	cmd->request_bufflen = req->nr_sectors << 9;

commit c46f2ffb9e7fce7208c2639790e1ade42e00b146
Merge: c2a9331c6221 f59114b7b5dc
Author: James Bottomley <jejb@titanic>
Date:   Mon Apr 18 13:45:00 2005 -0500

    merge by hand (scsi_device.h)

commit c6295cdf656de63d6d1123def71daba6cd91939c
Author:  <htejun@gmail.com>
Date:   Sun Apr 3 14:59:11 2005 -0500

    [PATCH] scsi: remove meaningless scsi_cmnd->serial_number_at_timeout field
    
    scsi_cmnd->serial_number_at_timeout doesn't serve any purpose
    anymore.  All serial_number == serial_number_at_timeout tests
    are always true in abort callbacks.  Kill the field.  Also, as
    ->pid always equals ->serial_number and ->serial_number
    doesn't have any special meaning anymore, update comments
    above ->serial_number accordingly.  Once we remove all uses of
    this field from all lldd's, this field should go.
    
    Signed-off-by: Tejun Heo <htejun@gmail.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 19dd911d9f7a..619d3fb7a2f0 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -298,7 +298,6 @@ static int scsi_init_cmd_errh(struct scsi_cmnd *cmd)
 {
 	cmd->owner = SCSI_OWNER_MIDLEVEL;
 	cmd->serial_number = 0;
-	cmd->serial_number_at_timeout = 0;
 	cmd->abort_reason = 0;
 
 	memset(cmd->sense_buffer, 0, sizeof cmd->sense_buffer);

commit d3a933dc9851e74581f9f4c8e703e77901ae8d01
Author:  <htejun@gmail.com>
Date:   Sun Apr 3 14:55:06 2005 -0500

    [PATCH] scsi: remove unused scsi_cmnd->internal_timeout field
    
    scsi_cmnd->internal_timeout field doesn't have any meaning
    anymore.  Kill the field.
    
    Signed-off-by: Tejun Heo <htejun@gmail.com>
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 7cbc4127fb5a..19dd911d9f7a 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -320,7 +320,6 @@ static int scsi_init_cmd_errh(struct scsi_cmnd *cmd)
 	memcpy(cmd->data_cmnd, cmd->cmnd, sizeof(cmd->cmnd));
 	cmd->buffer = cmd->request_buffer;
 	cmd->bufflen = cmd->request_bufflen;
-	cmd->internal_timeout = NORMAL_TIMEOUT;
 	cmd->abort_reason = 0;
 
 	return 1;

commit 152587deb8903c0edf483a5b889f975bc6bea7e0
Author:  <axboe@suse.de>
Date:   Tue Apr 12 16:22:06 2005 -0500

    [PATCH] fix NMI lockup with CFQ scheduler
    
    The current problem seen is that the queue lock is actually in the
    SCSI device structure, so when that structure is freed on device
    release, we go boom if the queue tries to access the lock again.
    
    The fix here is to move the lock from the scsi_device to the queue.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index 7cbc4127fb5a..d230c699c728 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -360,9 +360,9 @@ void scsi_device_unbusy(struct scsi_device *sdev)
 		     shost->host_failed))
 		scsi_eh_wakeup(shost);
 	spin_unlock(shost->host_lock);
-	spin_lock(&sdev->sdev_lock);
+	spin_lock(sdev->request_queue->queue_lock);
 	sdev->device_busy--;
-	spin_unlock_irqrestore(&sdev->sdev_lock, flags);
+	spin_unlock_irqrestore(sdev->request_queue->queue_lock, flags);
 }
 
 /*
@@ -1425,7 +1425,7 @@ struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
 	struct Scsi_Host *shost = sdev->host;
 	struct request_queue *q;
 
-	q = blk_init_queue(scsi_request_fn, &sdev->sdev_lock);
+	q = blk_init_queue(scsi_request_fn, NULL);
 	if (!q)
 		return NULL;
 

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
new file mode 100644
index 000000000000..7cbc4127fb5a
--- /dev/null
+++ b/drivers/scsi/scsi_lib.c
@@ -0,0 +1,2023 @@
+/*
+ *  scsi_lib.c Copyright (C) 1999 Eric Youngdale
+ *
+ *  SCSI queueing library.
+ *      Initial versions: Eric Youngdale (eric@andante.org).
+ *                        Based upon conversations with large numbers
+ *                        of people at Linux Expo.
+ */
+
+#include <linux/bio.h>
+#include <linux/blkdev.h>
+#include <linux/completion.h>
+#include <linux/kernel.h>
+#include <linux/mempool.h>
+#include <linux/slab.h>
+#include <linux/init.h>
+#include <linux/pci.h>
+#include <linux/delay.h>
+
+#include <scsi/scsi.h>
+#include <scsi/scsi_dbg.h>
+#include <scsi/scsi_device.h>
+#include <scsi/scsi_driver.h>
+#include <scsi/scsi_eh.h>
+#include <scsi/scsi_host.h>
+#include <scsi/scsi_request.h>
+
+#include "scsi_priv.h"
+#include "scsi_logging.h"
+
+
+#define SG_MEMPOOL_NR		(sizeof(scsi_sg_pools)/sizeof(struct scsi_host_sg_pool))
+#define SG_MEMPOOL_SIZE		32
+
+struct scsi_host_sg_pool {
+	size_t		size;
+	char		*name; 
+	kmem_cache_t	*slab;
+	mempool_t	*pool;
+};
+
+#if (SCSI_MAX_PHYS_SEGMENTS < 32)
+#error SCSI_MAX_PHYS_SEGMENTS is too small
+#endif
+
+#define SP(x) { x, "sgpool-" #x } 
+struct scsi_host_sg_pool scsi_sg_pools[] = { 
+	SP(8),
+	SP(16),
+	SP(32),
+#if (SCSI_MAX_PHYS_SEGMENTS > 32)
+	SP(64),
+#if (SCSI_MAX_PHYS_SEGMENTS > 64)
+	SP(128),
+#if (SCSI_MAX_PHYS_SEGMENTS > 128)
+	SP(256),
+#if (SCSI_MAX_PHYS_SEGMENTS > 256)
+#error SCSI_MAX_PHYS_SEGMENTS is too large
+#endif
+#endif
+#endif
+#endif
+}; 	
+#undef SP
+
+
+/*
+ * Function:    scsi_insert_special_req()
+ *
+ * Purpose:     Insert pre-formed request into request queue.
+ *
+ * Arguments:   sreq	- request that is ready to be queued.
+ *              at_head	- boolean.  True if we should insert at head
+ *                        of queue, false if we should insert at tail.
+ *
+ * Lock status: Assumed that lock is not held upon entry.
+ *
+ * Returns:     Nothing
+ *
+ * Notes:       This function is called from character device and from
+ *              ioctl types of functions where the caller knows exactly
+ *              what SCSI command needs to be issued.   The idea is that
+ *              we merely inject the command into the queue (at the head
+ *              for now), and then call the queue request function to actually
+ *              process it.
+ */
+int scsi_insert_special_req(struct scsi_request *sreq, int at_head)
+{
+	/*
+	 * Because users of this function are apt to reuse requests with no
+	 * modification, we have to sanitise the request flags here
+	 */
+	sreq->sr_request->flags &= ~REQ_DONTPREP;
+	blk_insert_request(sreq->sr_device->request_queue, sreq->sr_request,
+		       	   at_head, sreq, 0);
+	return 0;
+}
+
+/*
+ * Function:    scsi_queue_insert()
+ *
+ * Purpose:     Insert a command in the midlevel queue.
+ *
+ * Arguments:   cmd    - command that we are adding to queue.
+ *              reason - why we are inserting command to queue.
+ *
+ * Lock status: Assumed that lock is not held upon entry.
+ *
+ * Returns:     Nothing.
+ *
+ * Notes:       We do this for one of two cases.  Either the host is busy
+ *              and it cannot accept any more commands for the time being,
+ *              or the device returned QUEUE_FULL and can accept no more
+ *              commands.
+ * Notes:       This could be called either from an interrupt context or a
+ *              normal process context.
+ */
+int scsi_queue_insert(struct scsi_cmnd *cmd, int reason)
+{
+	struct Scsi_Host *host = cmd->device->host;
+	struct scsi_device *device = cmd->device;
+
+	SCSI_LOG_MLQUEUE(1,
+		 printk("Inserting command %p into mlqueue\n", cmd));
+
+	/*
+	 * We are inserting the command into the ml queue.  First, we
+	 * cancel the timer, so it doesn't time out.
+	 */
+	scsi_delete_timer(cmd);
+
+	/*
+	 * Next, set the appropriate busy bit for the device/host.
+	 *
+	 * If the host/device isn't busy, assume that something actually
+	 * completed, and that we should be able to queue a command now.
+	 *
+	 * Note that the prior mid-layer assumption that any host could
+	 * always queue at least one command is now broken.  The mid-layer
+	 * will implement a user specifiable stall (see
+	 * scsi_host.max_host_blocked and scsi_device.max_device_blocked)
+	 * if a command is requeued with no other commands outstanding
+	 * either for the device or for the host.
+	 */
+	if (reason == SCSI_MLQUEUE_HOST_BUSY)
+		host->host_blocked = host->max_host_blocked;
+	else if (reason == SCSI_MLQUEUE_DEVICE_BUSY)
+		device->device_blocked = device->max_device_blocked;
+
+	/*
+	 * Register the fact that we own the thing for now.
+	 */
+	cmd->state = SCSI_STATE_MLQUEUE;
+	cmd->owner = SCSI_OWNER_MIDLEVEL;
+
+	/*
+	 * Decrement the counters, since these commands are no longer
+	 * active on the host/device.
+	 */
+	scsi_device_unbusy(device);
+
+	/*
+	 * Insert this command at the head of the queue for it's device.
+	 * It will go before all other commands that are already in the queue.
+	 *
+	 * NOTE: there is magic here about the way the queue is plugged if
+	 * we have no outstanding commands.
+	 * 
+	 * Although this *doesn't* plug the queue, it does call the request
+	 * function.  The SCSI request function detects the blocked condition
+	 * and plugs the queue appropriately.
+	 */
+	blk_insert_request(device->request_queue, cmd->request, 1, cmd, 1);
+	return 0;
+}
+
+/*
+ * Function:    scsi_do_req
+ *
+ * Purpose:     Queue a SCSI request
+ *
+ * Arguments:   sreq	  - command descriptor.
+ *              cmnd      - actual SCSI command to be performed.
+ *              buffer    - data buffer.
+ *              bufflen   - size of data buffer.
+ *              done      - completion function to be run.
+ *              timeout   - how long to let it run before timeout.
+ *              retries   - number of retries we allow.
+ *
+ * Lock status: No locks held upon entry.
+ *
+ * Returns:     Nothing.
+ *
+ * Notes:	This function is only used for queueing requests for things
+ *		like ioctls and character device requests - this is because
+ *		we essentially just inject a request into the queue for the
+ *		device.
+ *
+ *		In order to support the scsi_device_quiesce function, we
+ *		now inject requests on the *head* of the device queue
+ *		rather than the tail.
+ */
+void scsi_do_req(struct scsi_request *sreq, const void *cmnd,
+		 void *buffer, unsigned bufflen,
+		 void (*done)(struct scsi_cmnd *),
+		 int timeout, int retries)
+{
+	/*
+	 * If the upper level driver is reusing these things, then
+	 * we should release the low-level block now.  Another one will
+	 * be allocated later when this request is getting queued.
+	 */
+	__scsi_release_request(sreq);
+
+	/*
+	 * Our own function scsi_done (which marks the host as not busy,
+	 * disables the timeout counter, etc) will be called by us or by the
+	 * scsi_hosts[host].queuecommand() function needs to also call
+	 * the completion function for the high level driver.
+	 */
+	memcpy(sreq->sr_cmnd, cmnd, sizeof(sreq->sr_cmnd));
+	sreq->sr_bufflen = bufflen;
+	sreq->sr_buffer = buffer;
+	sreq->sr_allowed = retries;
+	sreq->sr_done = done;
+	sreq->sr_timeout_per_command = timeout;
+
+	if (sreq->sr_cmd_len == 0)
+		sreq->sr_cmd_len = COMMAND_SIZE(sreq->sr_cmnd[0]);
+
+	/*
+	 * head injection *required* here otherwise quiesce won't work
+	 */
+	scsi_insert_special_req(sreq, 1);
+}
+EXPORT_SYMBOL(scsi_do_req);
+
+static void scsi_wait_done(struct scsi_cmnd *cmd)
+{
+	struct request *req = cmd->request;
+	struct request_queue *q = cmd->device->request_queue;
+	unsigned long flags;
+
+	req->rq_status = RQ_SCSI_DONE;	/* Busy, but indicate request done */
+
+	spin_lock_irqsave(q->queue_lock, flags);
+	if (blk_rq_tagged(req))
+		blk_queue_end_tag(q, req);
+	spin_unlock_irqrestore(q->queue_lock, flags);
+
+	if (req->waiting)
+		complete(req->waiting);
+}
+
+/* This is the end routine we get to if a command was never attached
+ * to the request.  Simply complete the request without changing
+ * rq_status; this will cause a DRIVER_ERROR. */
+static void scsi_wait_req_end_io(struct request *req)
+{
+	BUG_ON(!req->waiting);
+
+	complete(req->waiting);
+}
+
+void scsi_wait_req(struct scsi_request *sreq, const void *cmnd, void *buffer,
+		   unsigned bufflen, int timeout, int retries)
+{
+	DECLARE_COMPLETION(wait);
+	
+	sreq->sr_request->waiting = &wait;
+	sreq->sr_request->rq_status = RQ_SCSI_BUSY;
+	sreq->sr_request->end_io = scsi_wait_req_end_io;
+	scsi_do_req(sreq, cmnd, buffer, bufflen, scsi_wait_done,
+			timeout, retries);
+	wait_for_completion(&wait);
+	sreq->sr_request->waiting = NULL;
+	if (sreq->sr_request->rq_status != RQ_SCSI_DONE)
+		sreq->sr_result |= (DRIVER_ERROR << 24);
+
+	__scsi_release_request(sreq);
+}
+EXPORT_SYMBOL(scsi_wait_req);
+
+/*
+ * Function:    scsi_init_cmd_errh()
+ *
+ * Purpose:     Initialize cmd fields related to error handling.
+ *
+ * Arguments:   cmd	- command that is ready to be queued.
+ *
+ * Returns:     Nothing
+ *
+ * Notes:       This function has the job of initializing a number of
+ *              fields related to error handling.   Typically this will
+ *              be called once for each command, as required.
+ */
+static int scsi_init_cmd_errh(struct scsi_cmnd *cmd)
+{
+	cmd->owner = SCSI_OWNER_MIDLEVEL;
+	cmd->serial_number = 0;
+	cmd->serial_number_at_timeout = 0;
+	cmd->abort_reason = 0;
+
+	memset(cmd->sense_buffer, 0, sizeof cmd->sense_buffer);
+
+	if (cmd->cmd_len == 0)
+		cmd->cmd_len = COMMAND_SIZE(cmd->cmnd[0]);
+
+	/*
+	 * We need saved copies of a number of fields - this is because
+	 * error handling may need to overwrite these with different values
+	 * to run different commands, and once error handling is complete,
+	 * we will need to restore these values prior to running the actual
+	 * command.
+	 */
+	cmd->old_use_sg = cmd->use_sg;
+	cmd->old_cmd_len = cmd->cmd_len;
+	cmd->sc_old_data_direction = cmd->sc_data_direction;
+	cmd->old_underflow = cmd->underflow;
+	memcpy(cmd->data_cmnd, cmd->cmnd, sizeof(cmd->cmnd));
+	cmd->buffer = cmd->request_buffer;
+	cmd->bufflen = cmd->request_bufflen;
+	cmd->internal_timeout = NORMAL_TIMEOUT;
+	cmd->abort_reason = 0;
+
+	return 1;
+}
+
+/*
+ * Function:   scsi_setup_cmd_retry()
+ *
+ * Purpose:    Restore the command state for a retry
+ *
+ * Arguments:  cmd	- command to be restored
+ *
+ * Returns:    Nothing
+ *
+ * Notes:      Immediately prior to retrying a command, we need
+ *             to restore certain fields that we saved above.
+ */
+void scsi_setup_cmd_retry(struct scsi_cmnd *cmd)
+{
+	memcpy(cmd->cmnd, cmd->data_cmnd, sizeof(cmd->data_cmnd));
+	cmd->request_buffer = cmd->buffer;
+	cmd->request_bufflen = cmd->bufflen;
+	cmd->use_sg = cmd->old_use_sg;
+	cmd->cmd_len = cmd->old_cmd_len;
+	cmd->sc_data_direction = cmd->sc_old_data_direction;
+	cmd->underflow = cmd->old_underflow;
+}
+
+void scsi_device_unbusy(struct scsi_device *sdev)
+{
+	struct Scsi_Host *shost = sdev->host;
+	unsigned long flags;
+
+	spin_lock_irqsave(shost->host_lock, flags);
+	shost->host_busy--;
+	if (unlikely(test_bit(SHOST_RECOVERY, &shost->shost_state) &&
+		     shost->host_failed))
+		scsi_eh_wakeup(shost);
+	spin_unlock(shost->host_lock);
+	spin_lock(&sdev->sdev_lock);
+	sdev->device_busy--;
+	spin_unlock_irqrestore(&sdev->sdev_lock, flags);
+}
+
+/*
+ * Called for single_lun devices on IO completion. Clear starget_sdev_user,
+ * and call blk_run_queue for all the scsi_devices on the target -
+ * including current_sdev first.
+ *
+ * Called with *no* scsi locks held.
+ */
+static void scsi_single_lun_run(struct scsi_device *current_sdev)
+{
+	struct Scsi_Host *shost = current_sdev->host;
+	struct scsi_device *sdev, *tmp;
+	struct scsi_target *starget = scsi_target(current_sdev);
+	unsigned long flags;
+
+	spin_lock_irqsave(shost->host_lock, flags);
+	starget->starget_sdev_user = NULL;
+	spin_unlock_irqrestore(shost->host_lock, flags);
+
+	/*
+	 * Call blk_run_queue for all LUNs on the target, starting with
+	 * current_sdev. We race with others (to set starget_sdev_user),
+	 * but in most cases, we will be first. Ideally, each LU on the
+	 * target would get some limited time or requests on the target.
+	 */
+	blk_run_queue(current_sdev->request_queue);
+
+	spin_lock_irqsave(shost->host_lock, flags);
+	if (starget->starget_sdev_user)
+		goto out;
+	list_for_each_entry_safe(sdev, tmp, &starget->devices,
+			same_target_siblings) {
+		if (sdev == current_sdev)
+			continue;
+		if (scsi_device_get(sdev))
+			continue;
+
+		spin_unlock_irqrestore(shost->host_lock, flags);
+		blk_run_queue(sdev->request_queue);
+		spin_lock_irqsave(shost->host_lock, flags);
+	
+		scsi_device_put(sdev);
+	}
+ out:
+	spin_unlock_irqrestore(shost->host_lock, flags);
+}
+
+/*
+ * Function:	scsi_run_queue()
+ *
+ * Purpose:	Select a proper request queue to serve next
+ *
+ * Arguments:	q	- last request's queue
+ *
+ * Returns:     Nothing
+ *
+ * Notes:	The previous command was completely finished, start
+ *		a new one if possible.
+ */
+static void scsi_run_queue(struct request_queue *q)
+{
+	struct scsi_device *sdev = q->queuedata;
+	struct Scsi_Host *shost = sdev->host;
+	unsigned long flags;
+
+	if (sdev->single_lun)
+		scsi_single_lun_run(sdev);
+
+	spin_lock_irqsave(shost->host_lock, flags);
+	while (!list_empty(&shost->starved_list) &&
+	       !shost->host_blocked && !shost->host_self_blocked &&
+		!((shost->can_queue > 0) &&
+		  (shost->host_busy >= shost->can_queue))) {
+		/*
+		 * As long as shost is accepting commands and we have
+		 * starved queues, call blk_run_queue. scsi_request_fn
+		 * drops the queue_lock and can add us back to the
+		 * starved_list.
+		 *
+		 * host_lock protects the starved_list and starved_entry.
+		 * scsi_request_fn must get the host_lock before checking
+		 * or modifying starved_list or starved_entry.
+		 */
+		sdev = list_entry(shost->starved_list.next,
+					  struct scsi_device, starved_entry);
+		list_del_init(&sdev->starved_entry);
+		spin_unlock_irqrestore(shost->host_lock, flags);
+
+		blk_run_queue(sdev->request_queue);
+
+		spin_lock_irqsave(shost->host_lock, flags);
+		if (unlikely(!list_empty(&sdev->starved_entry)))
+			/*
+			 * sdev lost a race, and was put back on the
+			 * starved list. This is unlikely but without this
+			 * in theory we could loop forever.
+			 */
+			break;
+	}
+	spin_unlock_irqrestore(shost->host_lock, flags);
+
+	blk_run_queue(q);
+}
+
+/*
+ * Function:	scsi_requeue_command()
+ *
+ * Purpose:	Handle post-processing of completed commands.
+ *
+ * Arguments:	q	- queue to operate on
+ *		cmd	- command that may need to be requeued.
+ *
+ * Returns:	Nothing
+ *
+ * Notes:	After command completion, there may be blocks left
+ *		over which weren't finished by the previous command
+ *		this can be for a number of reasons - the main one is
+ *		I/O errors in the middle of the request, in which case
+ *		we need to request the blocks that come after the bad
+ *		sector.
+ */
+static void scsi_requeue_command(struct request_queue *q, struct scsi_cmnd *cmd)
+{
+	cmd->request->flags &= ~REQ_DONTPREP;
+	blk_insert_request(q, cmd->request, 1, cmd, 1);
+
+	scsi_run_queue(q);
+}
+
+void scsi_next_command(struct scsi_cmnd *cmd)
+{
+	struct request_queue *q = cmd->device->request_queue;
+
+	scsi_put_command(cmd);
+	scsi_run_queue(q);
+}
+
+void scsi_run_host_queues(struct Scsi_Host *shost)
+{
+	struct scsi_device *sdev;
+
+	shost_for_each_device(sdev, shost)
+		scsi_run_queue(sdev->request_queue);
+}
+
+/*
+ * Function:    scsi_end_request()
+ *
+ * Purpose:     Post-processing of completed commands (usually invoked at end
+ *		of upper level post-processing and scsi_io_completion).
+ *
+ * Arguments:   cmd	 - command that is complete.
+ *              uptodate - 1 if I/O indicates success, <= 0 for I/O error.
+ *              bytes    - number of bytes of completed I/O
+ *		requeue  - indicates whether we should requeue leftovers.
+ *
+ * Lock status: Assumed that lock is not held upon entry.
+ *
+ * Returns:     cmd if requeue done or required, NULL otherwise
+ *
+ * Notes:       This is called for block device requests in order to
+ *              mark some number of sectors as complete.
+ * 
+ *		We are guaranteeing that the request queue will be goosed
+ *		at some point during this call.
+ */
+static struct scsi_cmnd *scsi_end_request(struct scsi_cmnd *cmd, int uptodate,
+					  int bytes, int requeue)
+{
+	request_queue_t *q = cmd->device->request_queue;
+	struct request *req = cmd->request;
+	unsigned long flags;
+
+	/*
+	 * If there are blocks left over at the end, set up the command
+	 * to queue the remainder of them.
+	 */
+	if (end_that_request_chunk(req, uptodate, bytes)) {
+		int leftover = (req->hard_nr_sectors << 9);
+
+		if (blk_pc_request(req))
+			leftover = req->data_len;
+
+		/* kill remainder if no retrys */
+		if (!uptodate && blk_noretry_request(req))
+			end_that_request_chunk(req, 0, leftover);
+		else {
+			if (requeue)
+				/*
+				 * Bleah.  Leftovers again.  Stick the
+				 * leftovers in the front of the
+				 * queue, and goose the queue again.
+				 */
+				scsi_requeue_command(q, cmd);
+
+			return cmd;
+		}
+	}
+
+	add_disk_randomness(req->rq_disk);
+
+	spin_lock_irqsave(q->queue_lock, flags);
+	if (blk_rq_tagged(req))
+		blk_queue_end_tag(q, req);
+	end_that_request_last(req);
+	spin_unlock_irqrestore(q->queue_lock, flags);
+
+	/*
+	 * This will goose the queue request function at the end, so we don't
+	 * need to worry about launching another command.
+	 */
+	scsi_next_command(cmd);
+	return NULL;
+}
+
+static struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, int gfp_mask)
+{
+	struct scsi_host_sg_pool *sgp;
+	struct scatterlist *sgl;
+
+	BUG_ON(!cmd->use_sg);
+
+	switch (cmd->use_sg) {
+	case 1 ... 8:
+		cmd->sglist_len = 0;
+		break;
+	case 9 ... 16:
+		cmd->sglist_len = 1;
+		break;
+	case 17 ... 32:
+		cmd->sglist_len = 2;
+		break;
+#if (SCSI_MAX_PHYS_SEGMENTS > 32)
+	case 33 ... 64:
+		cmd->sglist_len = 3;
+		break;
+#if (SCSI_MAX_PHYS_SEGMENTS > 64)
+	case 65 ... 128:
+		cmd->sglist_len = 4;
+		break;
+#if (SCSI_MAX_PHYS_SEGMENTS  > 128)
+	case 129 ... 256:
+		cmd->sglist_len = 5;
+		break;
+#endif
+#endif
+#endif
+	default:
+		return NULL;
+	}
+
+	sgp = scsi_sg_pools + cmd->sglist_len;
+	sgl = mempool_alloc(sgp->pool, gfp_mask);
+	if (sgl)
+		memset(sgl, 0, sgp->size);
+	return sgl;
+}
+
+static void scsi_free_sgtable(struct scatterlist *sgl, int index)
+{
+	struct scsi_host_sg_pool *sgp;
+
+	BUG_ON(index > SG_MEMPOOL_NR);
+
+	sgp = scsi_sg_pools + index;
+	mempool_free(sgl, sgp->pool);
+}
+
+/*
+ * Function:    scsi_release_buffers()
+ *
+ * Purpose:     Completion processing for block device I/O requests.
+ *
+ * Arguments:   cmd	- command that we are bailing.
+ *
+ * Lock status: Assumed that no lock is held upon entry.
+ *
+ * Returns:     Nothing
+ *
+ * Notes:       In the event that an upper level driver rejects a
+ *		command, we must release resources allocated during
+ *		the __init_io() function.  Primarily this would involve
+ *		the scatter-gather table, and potentially any bounce
+ *		buffers.
+ */
+static void scsi_release_buffers(struct scsi_cmnd *cmd)
+{
+	struct request *req = cmd->request;
+
+	/*
+	 * Free up any indirection buffers we allocated for DMA purposes. 
+	 */
+	if (cmd->use_sg)
+		scsi_free_sgtable(cmd->request_buffer, cmd->sglist_len);
+	else if (cmd->request_buffer != req->buffer)
+		kfree(cmd->request_buffer);
+
+	/*
+	 * Zero these out.  They now point to freed memory, and it is
+	 * dangerous to hang onto the pointers.
+	 */
+	cmd->buffer  = NULL;
+	cmd->bufflen = 0;
+	cmd->request_buffer = NULL;
+	cmd->request_bufflen = 0;
+}
+
+/*
+ * Function:    scsi_io_completion()
+ *
+ * Purpose:     Completion processing for block device I/O requests.
+ *
+ * Arguments:   cmd   - command that is finished.
+ *
+ * Lock status: Assumed that no lock is held upon entry.
+ *
+ * Returns:     Nothing
+ *
+ * Notes:       This function is matched in terms of capabilities to
+ *              the function that created the scatter-gather list.
+ *              In other words, if there are no bounce buffers
+ *              (the normal case for most drivers), we don't need
+ *              the logic to deal with cleaning up afterwards.
+ *
+ *		We must do one of several things here:
+ *
+ *		a) Call scsi_end_request.  This will finish off the
+ *		   specified number of sectors.  If we are done, the
+ *		   command block will be released, and the queue
+ *		   function will be goosed.  If we are not done, then
+ *		   scsi_end_request will directly goose the queue.
+ *
+ *		b) We can just use scsi_requeue_command() here.  This would
+ *		   be used if we just wanted to retry, for example.
+ */
+void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes,
+			unsigned int block_bytes)
+{
+	int result = cmd->result;
+	int this_count = cmd->bufflen;
+	request_queue_t *q = cmd->device->request_queue;
+	struct request *req = cmd->request;
+	int clear_errors = 1;
+	struct scsi_sense_hdr sshdr;
+	int sense_valid = 0;
+	int sense_deferred = 0;
+
+	if (blk_complete_barrier_rq(q, req, good_bytes >> 9))
+		return;
+
+	/*
+	 * Free up any indirection buffers we allocated for DMA purposes. 
+	 * For the case of a READ, we need to copy the data out of the
+	 * bounce buffer and into the real buffer.
+	 */
+	if (cmd->use_sg)
+		scsi_free_sgtable(cmd->buffer, cmd->sglist_len);
+	else if (cmd->buffer != req->buffer) {
+		if (rq_data_dir(req) == READ) {
+			unsigned long flags;
+			char *to = bio_kmap_irq(req->bio, &flags);
+			memcpy(to, cmd->buffer, cmd->bufflen);
+			bio_kunmap_irq(to, &flags);
+		}
+		kfree(cmd->buffer);
+	}
+
+	if (result) {
+		sense_valid = scsi_command_normalize_sense(cmd, &sshdr);
+		if (sense_valid)
+			sense_deferred = scsi_sense_is_deferred(&sshdr);
+	}
+	if (blk_pc_request(req)) { /* SG_IO ioctl from block level */
+		req->errors = result;
+		if (result) {
+			clear_errors = 0;
+			if (sense_valid && req->sense) {
+				/*
+				 * SG_IO wants current and deferred errors
+				 */
+				int len = 8 + cmd->sense_buffer[7];
+
+				if (len > SCSI_SENSE_BUFFERSIZE)
+					len = SCSI_SENSE_BUFFERSIZE;
+				memcpy(req->sense, cmd->sense_buffer,  len);
+				req->sense_len = len;
+			}
+		} else
+			req->data_len = cmd->resid;
+	}
+
+	/*
+	 * Zero these out.  They now point to freed memory, and it is
+	 * dangerous to hang onto the pointers.
+	 */
+	cmd->buffer  = NULL;
+	cmd->bufflen = 0;
+	cmd->request_buffer = NULL;
+	cmd->request_bufflen = 0;
+
+	/*
+	 * Next deal with any sectors which we were able to correctly
+	 * handle.
+	 */
+	if (good_bytes >= 0) {
+		SCSI_LOG_HLCOMPLETE(1, printk("%ld sectors total, %d bytes done.\n",
+					      req->nr_sectors, good_bytes));
+		SCSI_LOG_HLCOMPLETE(1, printk("use_sg is %d\n", cmd->use_sg));
+
+		if (clear_errors)
+			req->errors = 0;
+		/*
+		 * If multiple sectors are requested in one buffer, then
+		 * they will have been finished off by the first command.
+		 * If not, then we have a multi-buffer command.
+		 *
+		 * If block_bytes != 0, it means we had a medium error
+		 * of some sort, and that we want to mark some number of
+		 * sectors as not uptodate.  Thus we want to inhibit
+		 * requeueing right here - we will requeue down below
+		 * when we handle the bad sectors.
+		 */
+		cmd = scsi_end_request(cmd, 1, good_bytes, result == 0);
+
+		/*
+		 * If the command completed without error, then either finish off the
+		 * rest of the command, or start a new one.
+		 */
+		if (result == 0 || cmd == NULL ) {
+			return;
+		}
+	}
+	/*
+	 * Now, if we were good little boys and girls, Santa left us a request
+	 * sense buffer.  We can extract information from this, so we
+	 * can choose a block to remap, etc.
+	 */
+	if (sense_valid && !sense_deferred) {
+		switch (sshdr.sense_key) {
+		case UNIT_ATTENTION:
+			if (cmd->device->removable) {
+				/* detected disc change.  set a bit 
+				 * and quietly refuse further access.
+				 */
+				cmd->device->changed = 1;
+				cmd = scsi_end_request(cmd, 0,
+						this_count, 1);
+				return;
+			} else {
+				/*
+				* Must have been a power glitch, or a
+				* bus reset.  Could not have been a
+				* media change, so we just retry the
+				* request and see what happens.  
+				*/
+				scsi_requeue_command(q, cmd);
+				return;
+			}
+			break;
+		case ILLEGAL_REQUEST:
+			/*
+		 	* If we had an ILLEGAL REQUEST returned, then we may
+		 	* have performed an unsupported command.  The only
+		 	* thing this should be would be a ten byte read where
+			* only a six byte read was supported.  Also, on a
+			* system where READ CAPACITY failed, we may have read
+			* past the end of the disk.
+		 	*/
+			if (cmd->device->use_10_for_rw &&
+			    (cmd->cmnd[0] == READ_10 ||
+			     cmd->cmnd[0] == WRITE_10)) {
+				cmd->device->use_10_for_rw = 0;
+				/*
+				 * This will cause a retry with a 6-byte
+				 * command.
+				 */
+				scsi_requeue_command(q, cmd);
+				result = 0;
+			} else {
+				cmd = scsi_end_request(cmd, 0, this_count, 1);
+				return;
+			}
+			break;
+		case NOT_READY:
+			/*
+			 * If the device is in the process of becoming ready,
+			 * retry.
+			 */
+			if (sshdr.asc == 0x04 && sshdr.ascq == 0x01) {
+				scsi_requeue_command(q, cmd);
+				return;
+			}
+			printk(KERN_INFO "Device %s not ready.\n",
+			       req->rq_disk ? req->rq_disk->disk_name : "");
+			cmd = scsi_end_request(cmd, 0, this_count, 1);
+			return;
+		case VOLUME_OVERFLOW:
+			printk(KERN_INFO "Volume overflow <%d %d %d %d> CDB: ",
+			       cmd->device->host->host_no,
+			       (int)cmd->device->channel,
+			       (int)cmd->device->id, (int)cmd->device->lun);
+			__scsi_print_command(cmd->data_cmnd);
+			scsi_print_sense("", cmd);
+			cmd = scsi_end_request(cmd, 0, block_bytes, 1);
+			return;
+		default:
+			break;
+		}
+	}			/* driver byte != 0 */
+	if (host_byte(result) == DID_RESET) {
+		/*
+		 * Third party bus reset or reset for error
+		 * recovery reasons.  Just retry the request
+		 * and see what happens.  
+		 */
+		scsi_requeue_command(q, cmd);
+		return;
+	}
+	if (result) {
+		printk(KERN_INFO "SCSI error : <%d %d %d %d> return code "
+		       "= 0x%x\n", cmd->device->host->host_no,
+		       cmd->device->channel,
+		       cmd->device->id,
+		       cmd->device->lun, result);
+
+		if (driver_byte(result) & DRIVER_SENSE)
+			scsi_print_sense("", cmd);
+		/*
+		 * Mark a single buffer as not uptodate.  Queue the remainder.
+		 * We sometimes get this cruft in the event that a medium error
+		 * isn't properly reported.
+		 */
+		block_bytes = req->hard_cur_sectors << 9;
+		if (!block_bytes)
+			block_bytes = req->data_len;
+		cmd = scsi_end_request(cmd, 0, block_bytes, 1);
+	}
+}
+EXPORT_SYMBOL(scsi_io_completion);
+
+/*
+ * Function:    scsi_init_io()
+ *
+ * Purpose:     SCSI I/O initialize function.
+ *
+ * Arguments:   cmd   - Command descriptor we wish to initialize
+ *
+ * Returns:     0 on success
+ *		BLKPREP_DEFER if the failure is retryable
+ *		BLKPREP_KILL if the failure is fatal
+ */
+static int scsi_init_io(struct scsi_cmnd *cmd)
+{
+	struct request     *req = cmd->request;
+	struct scatterlist *sgpnt;
+	int		   count;
+
+	/*
+	 * if this is a rq->data based REQ_BLOCK_PC, setup for a non-sg xfer
+	 */
+	if ((req->flags & REQ_BLOCK_PC) && !req->bio) {
+		cmd->request_bufflen = req->data_len;
+		cmd->request_buffer = req->data;
+		req->buffer = req->data;
+		cmd->use_sg = 0;
+		return 0;
+	}
+
+	/*
+	 * we used to not use scatter-gather for single segment request,
+	 * but now we do (it makes highmem I/O easier to support without
+	 * kmapping pages)
+	 */
+	cmd->use_sg = req->nr_phys_segments;
+
+	/*
+	 * if sg table allocation fails, requeue request later.
+	 */
+	sgpnt = scsi_alloc_sgtable(cmd, GFP_ATOMIC);
+	if (unlikely(!sgpnt)) {
+		req->flags |= REQ_SPECIAL;
+		return BLKPREP_DEFER;
+	}
+
+	cmd->request_buffer = (char *) sgpnt;
+	cmd->request_bufflen = req->nr_sectors << 9;
+	if (blk_pc_request(req))
+		cmd->request_bufflen = req->data_len;
+	req->buffer = NULL;
+
+	/* 
+	 * Next, walk the list, and fill in the addresses and sizes of
+	 * each segment.
+	 */
+	count = blk_rq_map_sg(req->q, req, cmd->request_buffer);
+
+	/*
+	 * mapped well, send it off
+	 */
+	if (likely(count <= cmd->use_sg)) {
+		cmd->use_sg = count;
+		return 0;
+	}
+
+	printk(KERN_ERR "Incorrect number of segments after building list\n");
+	printk(KERN_ERR "counted %d, received %d\n", count, cmd->use_sg);
+	printk(KERN_ERR "req nr_sec %lu, cur_nr_sec %u\n", req->nr_sectors,
+			req->current_nr_sectors);
+
+	/* release the command and kill it */
+	scsi_release_buffers(cmd);
+	scsi_put_command(cmd);
+	return BLKPREP_KILL;
+}
+
+static int scsi_prepare_flush_fn(request_queue_t *q, struct request *rq)
+{
+	struct scsi_device *sdev = q->queuedata;
+	struct scsi_driver *drv;
+
+	if (sdev->sdev_state == SDEV_RUNNING) {
+		drv = *(struct scsi_driver **) rq->rq_disk->private_data;
+
+		if (drv->prepare_flush)
+			return drv->prepare_flush(q, rq);
+	}
+
+	return 0;
+}
+
+static void scsi_end_flush_fn(request_queue_t *q, struct request *rq)
+{
+	struct scsi_device *sdev = q->queuedata;
+	struct request *flush_rq = rq->end_io_data;
+	struct scsi_driver *drv;
+
+	if (flush_rq->errors) {
+		printk("scsi: barrier error, disabling flush support\n");
+		blk_queue_ordered(q, QUEUE_ORDERED_NONE);
+	}
+
+	if (sdev->sdev_state == SDEV_RUNNING) {
+		drv = *(struct scsi_driver **) rq->rq_disk->private_data;
+		drv->end_flush(q, rq);
+	}
+}
+
+static int scsi_issue_flush_fn(request_queue_t *q, struct gendisk *disk,
+			       sector_t *error_sector)
+{
+	struct scsi_device *sdev = q->queuedata;
+	struct scsi_driver *drv;
+
+	if (sdev->sdev_state != SDEV_RUNNING)
+		return -ENXIO;
+
+	drv = *(struct scsi_driver **) disk->private_data;
+	if (drv->issue_flush)
+		return drv->issue_flush(&sdev->sdev_gendev, error_sector);
+
+	return -EOPNOTSUPP;
+}
+
+static int scsi_prep_fn(struct request_queue *q, struct request *req)
+{
+	struct scsi_device *sdev = q->queuedata;
+	struct scsi_cmnd *cmd;
+	int specials_only = 0;
+
+	/*
+	 * Just check to see if the device is online.  If it isn't, we
+	 * refuse to process any commands.  The device must be brought
+	 * online before trying any recovery commands
+	 */
+	if (unlikely(!scsi_device_online(sdev))) {
+		printk(KERN_ERR "scsi%d (%d:%d): rejecting I/O to offline device\n",
+		       sdev->host->host_no, sdev->id, sdev->lun);
+		return BLKPREP_KILL;
+	}
+	if (unlikely(sdev->sdev_state != SDEV_RUNNING)) {
+		/* OK, we're not in a running state don't prep
+		 * user commands */
+		if (sdev->sdev_state == SDEV_DEL) {
+			/* Device is fully deleted, no commands
+			 * at all allowed down */
+			printk(KERN_ERR "scsi%d (%d:%d): rejecting I/O to dead device\n",
+			       sdev->host->host_no, sdev->id, sdev->lun);
+			return BLKPREP_KILL;
+		}
+		/* OK, we only allow special commands (i.e. not
+		 * user initiated ones */
+		specials_only = sdev->sdev_state;
+	}
+
+	/*
+	 * Find the actual device driver associated with this command.
+	 * The SPECIAL requests are things like character device or
+	 * ioctls, which did not originate from ll_rw_blk.  Note that
+	 * the special field is also used to indicate the cmd for
+	 * the remainder of a partially fulfilled request that can 
+	 * come up when there is a medium error.  We have to treat
+	 * these two cases differently.  We differentiate by looking
+	 * at request->cmd, as this tells us the real story.
+	 */
+	if (req->flags & REQ_SPECIAL) {
+		struct scsi_request *sreq = req->special;
+
+		if (sreq->sr_magic == SCSI_REQ_MAGIC) {
+			cmd = scsi_get_command(sreq->sr_device, GFP_ATOMIC);
+			if (unlikely(!cmd))
+				goto defer;
+			scsi_init_cmd_from_req(cmd, sreq);
+		} else
+			cmd = req->special;
+	} else if (req->flags & (REQ_CMD | REQ_BLOCK_PC)) {
+
+		if(unlikely(specials_only)) {
+			if(specials_only == SDEV_QUIESCE ||
+					specials_only == SDEV_BLOCK)
+				return BLKPREP_DEFER;
+			
+			printk(KERN_ERR "scsi%d (%d:%d): rejecting I/O to device being removed\n",
+			       sdev->host->host_no, sdev->id, sdev->lun);
+			return BLKPREP_KILL;
+		}
+			
+			
+		/*
+		 * Now try and find a command block that we can use.
+		 */
+		if (!req->special) {
+			cmd = scsi_get_command(sdev, GFP_ATOMIC);
+			if (unlikely(!cmd))
+				goto defer;
+		} else
+			cmd = req->special;
+		
+		/* pull a tag out of the request if we have one */
+		cmd->tag = req->tag;
+	} else {
+		blk_dump_rq_flags(req, "SCSI bad req");
+		return BLKPREP_KILL;
+	}
+	
+	/* note the overloading of req->special.  When the tag
+	 * is active it always means cmd.  If the tag goes
+	 * back for re-queueing, it may be reset */
+	req->special = cmd;
+	cmd->request = req;
+	
+	/*
+	 * FIXME: drop the lock here because the functions below
+	 * expect to be called without the queue lock held.  Also,
+	 * previously, we dequeued the request before dropping the
+	 * lock.  We hope REQ_STARTED prevents anything untoward from
+	 * happening now.
+	 */
+	if (req->flags & (REQ_CMD | REQ_BLOCK_PC)) {
+		struct scsi_driver *drv;
+		int ret;
+
+		/*
+		 * This will do a couple of things:
+		 *  1) Fill in the actual SCSI command.
+		 *  2) Fill in any other upper-level specific fields
+		 * (timeout).
+		 *
+		 * If this returns 0, it means that the request failed
+		 * (reading past end of disk, reading offline device,
+		 * etc).   This won't actually talk to the device, but
+		 * some kinds of consistency checking may cause the	
+		 * request to be rejected immediately.
+		 */
+
+		/* 
+		 * This sets up the scatter-gather table (allocating if
+		 * required).
+		 */
+		ret = scsi_init_io(cmd);
+		if (ret)	/* BLKPREP_KILL return also releases the command */
+			return ret;
+		
+		/*
+		 * Initialize the actual SCSI command for this request.
+		 */
+		drv = *(struct scsi_driver **)req->rq_disk->private_data;
+		if (unlikely(!drv->init_command(cmd))) {
+			scsi_release_buffers(cmd);
+			scsi_put_command(cmd);
+			return BLKPREP_KILL;
+		}
+	}
+
+	/*
+	 * The request is now prepped, no need to come back here
+	 */
+	req->flags |= REQ_DONTPREP;
+	return BLKPREP_OK;
+
+ defer:
+	/* If we defer, the elv_next_request() returns NULL, but the
+	 * queue must be restarted, so we plug here if no returning
+	 * command will automatically do that. */
+	if (sdev->device_busy == 0)
+		blk_plug_device(q);
+	return BLKPREP_DEFER;
+}
+
+/*
+ * scsi_dev_queue_ready: if we can send requests to sdev, return 1 else
+ * return 0.
+ *
+ * Called with the queue_lock held.
+ */
+static inline int scsi_dev_queue_ready(struct request_queue *q,
+				  struct scsi_device *sdev)
+{
+	if (sdev->device_busy >= sdev->queue_depth)
+		return 0;
+	if (sdev->device_busy == 0 && sdev->device_blocked) {
+		/*
+		 * unblock after device_blocked iterates to zero
+		 */
+		if (--sdev->device_blocked == 0) {
+			SCSI_LOG_MLQUEUE(3,
+				printk("scsi%d (%d:%d) unblocking device at"
+				       " zero depth\n", sdev->host->host_no,
+				       sdev->id, sdev->lun));
+		} else {
+			blk_plug_device(q);
+			return 0;
+		}
+	}
+	if (sdev->device_blocked)
+		return 0;
+
+	return 1;
+}
+
+/*
+ * scsi_host_queue_ready: if we can send requests to shost, return 1 else
+ * return 0. We must end up running the queue again whenever 0 is
+ * returned, else IO can hang.
+ *
+ * Called with host_lock held.
+ */
+static inline int scsi_host_queue_ready(struct request_queue *q,
+				   struct Scsi_Host *shost,
+				   struct scsi_device *sdev)
+{
+	if (test_bit(SHOST_RECOVERY, &shost->shost_state))
+		return 0;
+	if (shost->host_busy == 0 && shost->host_blocked) {
+		/*
+		 * unblock after host_blocked iterates to zero
+		 */
+		if (--shost->host_blocked == 0) {
+			SCSI_LOG_MLQUEUE(3,
+				printk("scsi%d unblocking host at zero depth\n",
+					shost->host_no));
+		} else {
+			blk_plug_device(q);
+			return 0;
+		}
+	}
+	if ((shost->can_queue > 0 && shost->host_busy >= shost->can_queue) ||
+	    shost->host_blocked || shost->host_self_blocked) {
+		if (list_empty(&sdev->starved_entry))
+			list_add_tail(&sdev->starved_entry, &shost->starved_list);
+		return 0;
+	}
+
+	/* We're OK to process the command, so we can't be starved */
+	if (!list_empty(&sdev->starved_entry))
+		list_del_init(&sdev->starved_entry);
+
+	return 1;
+}
+
+/*
+ * Kill requests for a dead device
+ */
+static void scsi_kill_requests(request_queue_t *q)
+{
+	struct request *req;
+
+	while ((req = elv_next_request(q)) != NULL) {
+		blkdev_dequeue_request(req);
+		req->flags |= REQ_QUIET;
+		while (end_that_request_first(req, 0, req->nr_sectors))
+			;
+		end_that_request_last(req);
+	}
+}
+
+/*
+ * Function:    scsi_request_fn()
+ *
+ * Purpose:     Main strategy routine for SCSI.
+ *
+ * Arguments:   q       - Pointer to actual queue.
+ *
+ * Returns:     Nothing
+ *
+ * Lock status: IO request lock assumed to be held when called.
+ */
+static void scsi_request_fn(struct request_queue *q)
+{
+	struct scsi_device *sdev = q->queuedata;
+	struct Scsi_Host *shost;
+	struct scsi_cmnd *cmd;
+	struct request *req;
+
+	if (!sdev) {
+		printk("scsi: killing requests for dead queue\n");
+		scsi_kill_requests(q);
+		return;
+	}
+
+	if(!get_device(&sdev->sdev_gendev))
+		/* We must be tearing the block queue down already */
+		return;
+
+	/*
+	 * To start with, we keep looping until the queue is empty, or until
+	 * the host is no longer able to accept any more requests.
+	 */
+	shost = sdev->host;
+	while (!blk_queue_plugged(q)) {
+		int rtn;
+		/*
+		 * get next queueable request.  We do this early to make sure
+		 * that the request is fully prepared even if we cannot 
+		 * accept it.
+		 */
+		req = elv_next_request(q);
+		if (!req || !scsi_dev_queue_ready(q, sdev))
+			break;
+
+		if (unlikely(!scsi_device_online(sdev))) {
+			printk(KERN_ERR "scsi%d (%d:%d): rejecting I/O to offline device\n",
+			       sdev->host->host_no, sdev->id, sdev->lun);
+			blkdev_dequeue_request(req);
+			req->flags |= REQ_QUIET;
+			while (end_that_request_first(req, 0, req->nr_sectors))
+				;
+			end_that_request_last(req);
+			continue;
+		}
+
+
+		/*
+		 * Remove the request from the request list.
+		 */
+		if (!(blk_queue_tagged(q) && !blk_queue_start_tag(q, req)))
+			blkdev_dequeue_request(req);
+		sdev->device_busy++;
+
+		spin_unlock(q->queue_lock);
+		spin_lock(shost->host_lock);
+
+		if (!scsi_host_queue_ready(q, shost, sdev))
+			goto not_ready;
+		if (sdev->single_lun) {
+			if (scsi_target(sdev)->starget_sdev_user &&
+			    scsi_target(sdev)->starget_sdev_user != sdev)
+				goto not_ready;
+			scsi_target(sdev)->starget_sdev_user = sdev;
+		}
+		shost->host_busy++;
+
+		/*
+		 * XXX(hch): This is rather suboptimal, scsi_dispatch_cmd will
+		 *		take the lock again.
+		 */
+		spin_unlock_irq(shost->host_lock);
+
+		cmd = req->special;
+		if (unlikely(cmd == NULL)) {
+			printk(KERN_CRIT "impossible request in %s.\n"
+					 "please mail a stack trace to "
+					 "linux-scsi@vger.kernel.org",
+					 __FUNCTION__);
+			BUG();
+		}
+
+		/*
+		 * Finally, initialize any error handling parameters, and set up
+		 * the timers for timeouts.
+		 */
+		scsi_init_cmd_errh(cmd);
+
+		/*
+		 * Dispatch the command to the low-level driver.
+		 */
+		rtn = scsi_dispatch_cmd(cmd);
+		spin_lock_irq(q->queue_lock);
+		if(rtn) {
+			/* we're refusing the command; because of
+			 * the way locks get dropped, we need to 
+			 * check here if plugging is required */
+			if(sdev->device_busy == 0)
+				blk_plug_device(q);
+
+			break;
+		}
+	}
+
+	goto out;
+
+ not_ready:
+	spin_unlock_irq(shost->host_lock);
+
+	/*
+	 * lock q, handle tag, requeue req, and decrement device_busy. We
+	 * must return with queue_lock held.
+	 *
+	 * Decrementing device_busy without checking it is OK, as all such
+	 * cases (host limits or settings) should run the queue at some
+	 * later time.
+	 */
+	spin_lock_irq(q->queue_lock);
+	blk_requeue_request(q, req);
+	sdev->device_busy--;
+	if(sdev->device_busy == 0)
+		blk_plug_device(q);
+ out:
+	/* must be careful here...if we trigger the ->remove() function
+	 * we cannot be holding the q lock */
+	spin_unlock_irq(q->queue_lock);
+	put_device(&sdev->sdev_gendev);
+	spin_lock_irq(q->queue_lock);
+}
+
+u64 scsi_calculate_bounce_limit(struct Scsi_Host *shost)
+{
+	struct device *host_dev;
+	u64 bounce_limit = 0xffffffff;
+
+	if (shost->unchecked_isa_dma)
+		return BLK_BOUNCE_ISA;
+	/*
+	 * Platforms with virtual-DMA translation
+	 * hardware have no practical limit.
+	 */
+	if (!PCI_DMA_BUS_IS_PHYS)
+		return BLK_BOUNCE_ANY;
+
+	host_dev = scsi_get_device(shost);
+	if (host_dev && host_dev->dma_mask)
+		bounce_limit = *host_dev->dma_mask;
+
+	return bounce_limit;
+}
+EXPORT_SYMBOL(scsi_calculate_bounce_limit);
+
+struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
+{
+	struct Scsi_Host *shost = sdev->host;
+	struct request_queue *q;
+
+	q = blk_init_queue(scsi_request_fn, &sdev->sdev_lock);
+	if (!q)
+		return NULL;
+
+	blk_queue_prep_rq(q, scsi_prep_fn);
+
+	blk_queue_max_hw_segments(q, shost->sg_tablesize);
+	blk_queue_max_phys_segments(q, SCSI_MAX_PHYS_SEGMENTS);
+	blk_queue_max_sectors(q, shost->max_sectors);
+	blk_queue_bounce_limit(q, scsi_calculate_bounce_limit(shost));
+	blk_queue_segment_boundary(q, shost->dma_boundary);
+	blk_queue_issue_flush_fn(q, scsi_issue_flush_fn);
+
+	/*
+	 * ordered tags are superior to flush ordering
+	 */
+	if (shost->ordered_tag)
+		blk_queue_ordered(q, QUEUE_ORDERED_TAG);
+	else if (shost->ordered_flush) {
+		blk_queue_ordered(q, QUEUE_ORDERED_FLUSH);
+		q->prepare_flush_fn = scsi_prepare_flush_fn;
+		q->end_flush_fn = scsi_end_flush_fn;
+	}
+
+	if (!shost->use_clustering)
+		clear_bit(QUEUE_FLAG_CLUSTER, &q->queue_flags);
+	return q;
+}
+
+void scsi_free_queue(struct request_queue *q)
+{
+	blk_cleanup_queue(q);
+}
+
+/*
+ * Function:    scsi_block_requests()
+ *
+ * Purpose:     Utility function used by low-level drivers to prevent further
+ *		commands from being queued to the device.
+ *
+ * Arguments:   shost       - Host in question
+ *
+ * Returns:     Nothing
+ *
+ * Lock status: No locks are assumed held.
+ *
+ * Notes:       There is no timer nor any other means by which the requests
+ *		get unblocked other than the low-level driver calling
+ *		scsi_unblock_requests().
+ */
+void scsi_block_requests(struct Scsi_Host *shost)
+{
+	shost->host_self_blocked = 1;
+}
+EXPORT_SYMBOL(scsi_block_requests);
+
+/*
+ * Function:    scsi_unblock_requests()
+ *
+ * Purpose:     Utility function used by low-level drivers to allow further
+ *		commands from being queued to the device.
+ *
+ * Arguments:   shost       - Host in question
+ *
+ * Returns:     Nothing
+ *
+ * Lock status: No locks are assumed held.
+ *
+ * Notes:       There is no timer nor any other means by which the requests
+ *		get unblocked other than the low-level driver calling
+ *		scsi_unblock_requests().
+ *
+ *		This is done as an API function so that changes to the
+ *		internals of the scsi mid-layer won't require wholesale
+ *		changes to drivers that use this feature.
+ */
+void scsi_unblock_requests(struct Scsi_Host *shost)
+{
+	shost->host_self_blocked = 0;
+	scsi_run_host_queues(shost);
+}
+EXPORT_SYMBOL(scsi_unblock_requests);
+
+int __init scsi_init_queue(void)
+{
+	int i;
+
+	for (i = 0; i < SG_MEMPOOL_NR; i++) {
+		struct scsi_host_sg_pool *sgp = scsi_sg_pools + i;
+		int size = sgp->size * sizeof(struct scatterlist);
+
+		sgp->slab = kmem_cache_create(sgp->name, size, 0,
+				SLAB_HWCACHE_ALIGN, NULL, NULL);
+		if (!sgp->slab) {
+			printk(KERN_ERR "SCSI: can't init sg slab %s\n",
+					sgp->name);
+		}
+
+		sgp->pool = mempool_create(SG_MEMPOOL_SIZE,
+				mempool_alloc_slab, mempool_free_slab,
+				sgp->slab);
+		if (!sgp->pool) {
+			printk(KERN_ERR "SCSI: can't init sg mempool %s\n",
+					sgp->name);
+		}
+	}
+
+	return 0;
+}
+
+void scsi_exit_queue(void)
+{
+	int i;
+
+	for (i = 0; i < SG_MEMPOOL_NR; i++) {
+		struct scsi_host_sg_pool *sgp = scsi_sg_pools + i;
+		mempool_destroy(sgp->pool);
+		kmem_cache_destroy(sgp->slab);
+	}
+}
+/**
+ *	__scsi_mode_sense - issue a mode sense, falling back from 10 to 
+ *		six bytes if necessary.
+ *	@sreq:	SCSI request to fill in with the MODE_SENSE
+ *	@dbd:	set if mode sense will allow block descriptors to be returned
+ *	@modepage: mode page being requested
+ *	@buffer: request buffer (may not be smaller than eight bytes)
+ *	@len:	length of request buffer.
+ *	@timeout: command timeout
+ *	@retries: number of retries before failing
+ *	@data: returns a structure abstracting the mode header data
+ *
+ *	Returns zero if unsuccessful, or the header offset (either 4
+ *	or 8 depending on whether a six or ten byte command was
+ *	issued) if successful.
+ **/
+int
+__scsi_mode_sense(struct scsi_request *sreq, int dbd, int modepage,
+		  unsigned char *buffer, int len, int timeout, int retries,
+		  struct scsi_mode_data *data) {
+	unsigned char cmd[12];
+	int use_10_for_ms;
+	int header_length;
+
+	memset(data, 0, sizeof(*data));
+	memset(&cmd[0], 0, 12);
+	cmd[1] = dbd & 0x18;	/* allows DBD and LLBA bits */
+	cmd[2] = modepage;
+
+ retry:
+	use_10_for_ms = sreq->sr_device->use_10_for_ms;
+
+	if (use_10_for_ms) {
+		if (len < 8)
+			len = 8;
+
+		cmd[0] = MODE_SENSE_10;
+		cmd[8] = len;
+		header_length = 8;
+	} else {
+		if (len < 4)
+			len = 4;
+
+		cmd[0] = MODE_SENSE;
+		cmd[4] = len;
+		header_length = 4;
+	}
+
+	sreq->sr_cmd_len = 0;
+	memset(sreq->sr_sense_buffer, 0, sizeof(sreq->sr_sense_buffer));
+	sreq->sr_data_direction = DMA_FROM_DEVICE;
+
+	memset(buffer, 0, len);
+
+	scsi_wait_req(sreq, cmd, buffer, len, timeout, retries);
+
+	/* This code looks awful: what it's doing is making sure an
+	 * ILLEGAL REQUEST sense return identifies the actual command
+	 * byte as the problem.  MODE_SENSE commands can return
+	 * ILLEGAL REQUEST if the code page isn't supported */
+
+	if (use_10_for_ms && !scsi_status_is_good(sreq->sr_result) &&
+	    (driver_byte(sreq->sr_result) & DRIVER_SENSE)) {
+		struct scsi_sense_hdr sshdr;
+
+		if (scsi_request_normalize_sense(sreq, &sshdr)) {
+			if ((sshdr.sense_key == ILLEGAL_REQUEST) &&
+			    (sshdr.asc == 0x20) && (sshdr.ascq == 0)) {
+				/* 
+				 * Invalid command operation code
+				 */
+				sreq->sr_device->use_10_for_ms = 0;
+				goto retry;
+			}
+		}
+	}
+
+	if(scsi_status_is_good(sreq->sr_result)) {
+		data->header_length = header_length;
+		if(use_10_for_ms) {
+			data->length = buffer[0]*256 + buffer[1] + 2;
+			data->medium_type = buffer[2];
+			data->device_specific = buffer[3];
+			data->longlba = buffer[4] & 0x01;
+			data->block_descriptor_length = buffer[6]*256
+				+ buffer[7];
+		} else {
+			data->length = buffer[0] + 1;
+			data->medium_type = buffer[1];
+			data->device_specific = buffer[2];
+			data->block_descriptor_length = buffer[3];
+		}
+	}
+
+	return sreq->sr_result;
+}
+EXPORT_SYMBOL(__scsi_mode_sense);
+
+/**
+ *	scsi_mode_sense - issue a mode sense, falling back from 10 to 
+ *		six bytes if necessary.
+ *	@sdev:	scsi device to send command to.
+ *	@dbd:	set if mode sense will disable block descriptors in the return
+ *	@modepage: mode page being requested
+ *	@buffer: request buffer (may not be smaller than eight bytes)
+ *	@len:	length of request buffer.
+ *	@timeout: command timeout
+ *	@retries: number of retries before failing
+ *
+ *	Returns zero if unsuccessful, or the header offset (either 4
+ *	or 8 depending on whether a six or ten byte command was
+ *	issued) if successful.
+ **/
+int
+scsi_mode_sense(struct scsi_device *sdev, int dbd, int modepage,
+		unsigned char *buffer, int len, int timeout, int retries,
+		struct scsi_mode_data *data)
+{
+	struct scsi_request *sreq = scsi_allocate_request(sdev, GFP_KERNEL);
+	int ret;
+
+	if (!sreq)
+		return -1;
+
+	ret = __scsi_mode_sense(sreq, dbd, modepage, buffer, len,
+				timeout, retries, data);
+
+	scsi_release_request(sreq);
+
+	return ret;
+}
+EXPORT_SYMBOL(scsi_mode_sense);
+
+int
+scsi_test_unit_ready(struct scsi_device *sdev, int timeout, int retries)
+{
+	struct scsi_request *sreq;
+	char cmd[] = {
+		TEST_UNIT_READY, 0, 0, 0, 0, 0,
+	};
+	int result;
+	
+	sreq = scsi_allocate_request(sdev, GFP_KERNEL);
+	if (!sreq)
+		return -ENOMEM;
+
+	sreq->sr_data_direction = DMA_NONE;
+	scsi_wait_req(sreq, cmd, NULL, 0, timeout, retries);
+
+	if ((driver_byte(sreq->sr_result) & DRIVER_SENSE) && sdev->removable) {
+		struct scsi_sense_hdr sshdr;
+
+		if ((scsi_request_normalize_sense(sreq, &sshdr)) &&
+		    ((sshdr.sense_key == UNIT_ATTENTION) ||
+		     (sshdr.sense_key == NOT_READY))) {
+			sdev->changed = 1;
+			sreq->sr_result = 0;
+		}
+	}
+	result = sreq->sr_result;
+	scsi_release_request(sreq);
+	return result;
+}
+EXPORT_SYMBOL(scsi_test_unit_ready);
+
+/**
+ *	scsi_device_set_state - Take the given device through the device
+ *		state model.
+ *	@sdev:	scsi device to change the state of.
+ *	@state:	state to change to.
+ *
+ *	Returns zero if unsuccessful or an error if the requested 
+ *	transition is illegal.
+ **/
+int
+scsi_device_set_state(struct scsi_device *sdev, enum scsi_device_state state)
+{
+	enum scsi_device_state oldstate = sdev->sdev_state;
+
+	if (state == oldstate)
+		return 0;
+
+	switch (state) {
+	case SDEV_CREATED:
+		/* There are no legal states that come back to
+		 * created.  This is the manually initialised start
+		 * state */
+		goto illegal;
+			
+	case SDEV_RUNNING:
+		switch (oldstate) {
+		case SDEV_CREATED:
+		case SDEV_OFFLINE:
+		case SDEV_QUIESCE:
+		case SDEV_BLOCK:
+			break;
+		default:
+			goto illegal;
+		}
+		break;
+
+	case SDEV_QUIESCE:
+		switch (oldstate) {
+		case SDEV_RUNNING:
+		case SDEV_OFFLINE:
+			break;
+		default:
+			goto illegal;
+		}
+		break;
+
+	case SDEV_OFFLINE:
+		switch (oldstate) {
+		case SDEV_CREATED:
+		case SDEV_RUNNING:
+		case SDEV_QUIESCE:
+		case SDEV_BLOCK:
+			break;
+		default:
+			goto illegal;
+		}
+		break;
+
+	case SDEV_BLOCK:
+		switch (oldstate) {
+		case SDEV_CREATED:
+		case SDEV_RUNNING:
+			break;
+		default:
+			goto illegal;
+		}
+		break;
+
+	case SDEV_CANCEL:
+		switch (oldstate) {
+		case SDEV_CREATED:
+		case SDEV_RUNNING:
+		case SDEV_OFFLINE:
+		case SDEV_BLOCK:
+			break;
+		default:
+			goto illegal;
+		}
+		break;
+
+	case SDEV_DEL:
+		switch (oldstate) {
+		case SDEV_CANCEL:
+			break;
+		default:
+			goto illegal;
+		}
+		break;
+
+	}
+	sdev->sdev_state = state;
+	return 0;
+
+ illegal:
+	SCSI_LOG_ERROR_RECOVERY(1, 
+				dev_printk(KERN_ERR, &sdev->sdev_gendev,
+					   "Illegal state transition %s->%s\n",
+					   scsi_device_state_name(oldstate),
+					   scsi_device_state_name(state))
+				);
+	return -EINVAL;
+}
+EXPORT_SYMBOL(scsi_device_set_state);
+
+/**
+ *	scsi_device_quiesce - Block user issued commands.
+ *	@sdev:	scsi device to quiesce.
+ *
+ *	This works by trying to transition to the SDEV_QUIESCE state
+ *	(which must be a legal transition).  When the device is in this
+ *	state, only special requests will be accepted, all others will
+ *	be deferred.  Since special requests may also be requeued requests,
+ *	a successful return doesn't guarantee the device will be 
+ *	totally quiescent.
+ *
+ *	Must be called with user context, may sleep.
+ *
+ *	Returns zero if unsuccessful or an error if not.
+ **/
+int
+scsi_device_quiesce(struct scsi_device *sdev)
+{
+	int err = scsi_device_set_state(sdev, SDEV_QUIESCE);
+	if (err)
+		return err;
+
+	scsi_run_queue(sdev->request_queue);
+	while (sdev->device_busy) {
+		msleep_interruptible(200);
+		scsi_run_queue(sdev->request_queue);
+	}
+	return 0;
+}
+EXPORT_SYMBOL(scsi_device_quiesce);
+
+/**
+ *	scsi_device_resume - Restart user issued commands to a quiesced device.
+ *	@sdev:	scsi device to resume.
+ *
+ *	Moves the device from quiesced back to running and restarts the
+ *	queues.
+ *
+ *	Must be called with user context, may sleep.
+ **/
+void
+scsi_device_resume(struct scsi_device *sdev)
+{
+	if(scsi_device_set_state(sdev, SDEV_RUNNING))
+		return;
+	scsi_run_queue(sdev->request_queue);
+}
+EXPORT_SYMBOL(scsi_device_resume);
+
+static void
+device_quiesce_fn(struct scsi_device *sdev, void *data)
+{
+	scsi_device_quiesce(sdev);
+}
+
+void
+scsi_target_quiesce(struct scsi_target *starget)
+{
+	starget_for_each_device(starget, NULL, device_quiesce_fn);
+}
+EXPORT_SYMBOL(scsi_target_quiesce);
+
+static void
+device_resume_fn(struct scsi_device *sdev, void *data)
+{
+	scsi_device_resume(sdev);
+}
+
+void
+scsi_target_resume(struct scsi_target *starget)
+{
+	starget_for_each_device(starget, NULL, device_resume_fn);
+}
+EXPORT_SYMBOL(scsi_target_resume);
+
+/**
+ * scsi_internal_device_block - internal function to put a device
+ *				temporarily into the SDEV_BLOCK state
+ * @sdev:	device to block
+ *
+ * Block request made by scsi lld's to temporarily stop all
+ * scsi commands on the specified device.  Called from interrupt
+ * or normal process context.
+ *
+ * Returns zero if successful or error if not
+ *
+ * Notes:       
+ *	This routine transitions the device to the SDEV_BLOCK state
+ *	(which must be a legal transition).  When the device is in this
+ *	state, all commands are deferred until the scsi lld reenables
+ *	the device with scsi_device_unblock or device_block_tmo fires.
+ *	This routine assumes the host_lock is held on entry.
+ **/
+int
+scsi_internal_device_block(struct scsi_device *sdev)
+{
+	request_queue_t *q = sdev->request_queue;
+	unsigned long flags;
+	int err = 0;
+
+	err = scsi_device_set_state(sdev, SDEV_BLOCK);
+	if (err)
+		return err;
+
+	/* 
+	 * The device has transitioned to SDEV_BLOCK.  Stop the
+	 * block layer from calling the midlayer with this device's
+	 * request queue. 
+	 */
+	spin_lock_irqsave(q->queue_lock, flags);
+	blk_stop_queue(q);
+	spin_unlock_irqrestore(q->queue_lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(scsi_internal_device_block);
+ 
+/**
+ * scsi_internal_device_unblock - resume a device after a block request
+ * @sdev:	device to resume
+ *
+ * Called by scsi lld's or the midlayer to restart the device queue
+ * for the previously suspended scsi device.  Called from interrupt or
+ * normal process context.
+ *
+ * Returns zero if successful or error if not.
+ *
+ * Notes:       
+ *	This routine transitions the device to the SDEV_RUNNING state
+ *	(which must be a legal transition) allowing the midlayer to
+ *	goose the queue for this device.  This routine assumes the 
+ *	host_lock is held upon entry.
+ **/
+int
+scsi_internal_device_unblock(struct scsi_device *sdev)
+{
+	request_queue_t *q = sdev->request_queue; 
+	int err;
+	unsigned long flags;
+	
+	/* 
+	 * Try to transition the scsi device to SDEV_RUNNING
+	 * and goose the device queue if successful.  
+	 */
+	err = scsi_device_set_state(sdev, SDEV_RUNNING);
+	if (err)
+		return err;
+
+	spin_lock_irqsave(q->queue_lock, flags);
+	blk_start_queue(q);
+	spin_unlock_irqrestore(q->queue_lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(scsi_internal_device_unblock);
+
+static void
+device_block(struct scsi_device *sdev, void *data)
+{
+	scsi_internal_device_block(sdev);
+}
+
+static int
+target_block(struct device *dev, void *data)
+{
+	if (scsi_is_target_device(dev))
+		starget_for_each_device(to_scsi_target(dev), NULL,
+					device_block);
+	return 0;
+}
+
+void
+scsi_target_block(struct device *dev)
+{
+	if (scsi_is_target_device(dev))
+		starget_for_each_device(to_scsi_target(dev), NULL,
+					device_block);
+	else
+		device_for_each_child(dev, NULL, target_block);
+}
+EXPORT_SYMBOL_GPL(scsi_target_block);
+
+static void
+device_unblock(struct scsi_device *sdev, void *data)
+{
+	scsi_internal_device_unblock(sdev);
+}
+
+static int
+target_unblock(struct device *dev, void *data)
+{
+	if (scsi_is_target_device(dev))
+		starget_for_each_device(to_scsi_target(dev), NULL,
+					device_unblock);
+	return 0;
+}
+
+void
+scsi_target_unblock(struct device *dev)
+{
+	if (scsi_is_target_device(dev))
+		starget_for_each_device(to_scsi_target(dev), NULL,
+					device_unblock);
+	else
+		device_for_each_child(dev, NULL, target_unblock);
+}
+EXPORT_SYMBOL_GPL(scsi_target_unblock);
