commit 3172204a39c98367728d05ab27e2e96cf324a5a8
Author: Kyoungho Koo <rnrudgh@gmail.com>
Date:   Sat Apr 25 18:07:17 2020 +0900

    Staging: gasket: fix typo in gasket_page_table.c comments.
    
    I have found double typed comments "the the". So i modified it to
    one "the".
    
    Signed-off-by: Kyoungho Koo <rnrudgh@gmail.com>
    Link: https://lore.kernel.org/r/20200425090714.GA2105@koo-Z370-HD3
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index f6d715787da8..f3dbe0fe2a67 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -898,7 +898,7 @@ static int gasket_alloc_extended_subtable(struct gasket_page_table *pg_tbl,
  *
  * Note that memory for second level page tables is allocated as needed, but
  * that memory is only freed on the final close	of the device file, when the
- * page tables are repartitioned, or the the device is removed.  If there is an
+ * page tables are repartitioned, or the device is removed.  If there is an
  * error or if the full range of slots is not available, any memory
  * allocated for second level page tables remains allocated until final close,
  * repartition, or device removal.

commit 1b96f846db31e18e062ae4eb9e22ae58d6588c2f
Author: Tianzheng Li <ltz0302@gmail.com>
Date:   Fri May 24 13:31:05 2019 +0200

    staging/gasket: Fix string split
    
    This patch removes unnecessary quoted string splits.
    
    Co-developed-by: Jie Zhang <zhangjie.cnde@gmail.com>
    Signed-off-by: Jie Zhang <zhangjie.cnde@gmail.com>
    Signed-off-by: Tianzheng Li <ltz0302@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index d35c4fb19e28..f6d715787da8 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -237,8 +237,8 @@ int gasket_page_table_init(struct gasket_page_table **ppg_tbl,
 	 * hardware register that contains the page table size.
 	 */
 	if (total_entries == ULONG_MAX) {
-		dev_dbg(device, "Error reading page table size. "
-			"Initializing page table with size 0\n");
+		dev_dbg(device,
+			"Error reading page table size. Initializing page table with size 0\n");
 		total_entries = 0;
 	}
 
@@ -491,8 +491,7 @@ static int gasket_perform_mapping(struct gasket_page_table *pg_tbl,
 
 			if (ret <= 0) {
 				dev_err(pg_tbl->device,
-					"get user pages failed for addr=0x%lx, "
-					"offset=0x%lx [ret=%d]\n",
+					"get user pages failed for addr=0x%lx, offset=0x%lx [ret=%d]\n",
 					page_addr, offset, ret);
 				return ret ? ret : -ENOMEM;
 			}
@@ -779,8 +778,8 @@ static bool gasket_is_extended_dev_addr_bad(struct gasket_page_table *pg_tbl,
 
 	if (page_lvl0_idx >= pg_tbl->num_extended_entries) {
 		dev_err(pg_tbl->device,
-			"starting level 0 slot at %lu is too large, max is < "
-			"%u\n", page_lvl0_idx, pg_tbl->num_extended_entries);
+			"starting level 0 slot at %lu is too large, max is < %u\n",
+			page_lvl0_idx, pg_tbl->num_extended_entries);
 		return true;
 	}
 
@@ -965,8 +964,7 @@ static int gasket_map_extended_pages(struct gasket_page_table *pg_tbl,
 	if (ret) {
 		dev_addr_end = dev_addr + (num_pages / PAGE_SIZE) - 1;
 		dev_err(pg_tbl->device,
-			"page table slots (%lu,%lu) (@ 0x%lx) to (%lu,%lu) are "
-			"not available\n",
+			"page table slots (%lu,%lu) (@ 0x%lx) to (%lu,%lu) are not available\n",
 			gasket_extended_lvl0_page_idx(pg_tbl, dev_addr),
 			dev_addr,
 			gasket_extended_lvl1_page_idx(pg_tbl, dev_addr),

commit 73b0140bf0fe9df90fb267c00673c4b9bf285430
Author: Ira Weiny <ira.weiny@intel.com>
Date:   Mon May 13 17:17:11 2019 -0700

    mm/gup: change GUP fast to use flags rather than a write 'bool'
    
    To facilitate additional options to get_user_pages_fast() change the
    singular write parameter to be gup_flags.
    
    This patch does not change any functionality.  New functionality will
    follow in subsequent patches.
    
    Some of the get_user_pages_fast() call sites were unchanged because they
    already passed FOLL_WRITE or 0 for the write parameter.
    
    NOTE: It was suggested to change the ordering of the get_user_pages_fast()
    arguments to ensure that callers were converted.  This breaks the current
    GUP call site convention of having the returned pages be the final
    parameter.  So the suggestion was rejected.
    
    Link: http://lkml.kernel.org/r/20190328084422.29911-4-ira.weiny@intel.com
    Link: http://lkml.kernel.org/r/20190317183438.2057-4-ira.weiny@intel.com
    Signed-off-by: Ira Weiny <ira.weiny@intel.com>
    Reviewed-by: Mike Marshall <hubcap@omnibond.com>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: Jason Gunthorpe <jgg@ziepe.ca>
    Cc: John Hubbard <jhubbard@nvidia.com>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 600928f63577..d35c4fb19e28 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -486,8 +486,8 @@ static int gasket_perform_mapping(struct gasket_page_table *pg_tbl,
 			ptes[i].dma_addr = pg_tbl->coherent_pages[0].paddr +
 					   off + i * PAGE_SIZE;
 		} else {
-			ret = get_user_pages_fast(page_addr - offset, 1, 1,
-						  &page);
+			ret = get_user_pages_fast(page_addr - offset, 1,
+						  FOLL_WRITE, &page);
 
 			if (ret <= 0) {
 				dev_err(pg_tbl->device,

commit 740a998d58eecf00e0ba7bbe8cf1c0351a91a331
Author: Madhumitha Prabakaran <madhumithabiw@gmail.com>
Date:   Wed Apr 3 10:06:43 2019 -0500

    Staging: gasket: Use DIV_ROUND_UP
    
    Use DIV_ROUND_UP in-kernel function to make code simple and more
    understandable.
    
    Issue found using Coccinelle.
    
    Signed-off-by: Madhumitha Prabakaran <madhumithabiw@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 26755d9ca41d..600928f63577 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -768,8 +768,7 @@ static bool gasket_is_extended_dev_addr_bad(struct gasket_page_table *pg_tbl,
 	page_lvl0_idx = gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
 
 	/* Get the count of affected level 0 pages. */
-	num_lvl0_pages = (num_pages + GASKET_PAGES_PER_SUBTABLE - 1) /
-		GASKET_PAGES_PER_SUBTABLE;
+	num_lvl0_pages = DIV_ROUND_UP(num_pages, GASKET_PAGES_PER_SUBTABLE);
 
 	if (gasket_components_to_dev_address(pg_tbl, 0, page_global_idx,
 					     page_offset) != dev_addr) {
@@ -1258,7 +1257,7 @@ int gasket_alloc_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 	dma_addr_t handle;
 	void *mem;
 	int j;
-	unsigned int num_pages = (size + PAGE_SIZE - 1) / PAGE_SIZE;
+	unsigned int num_pages = DIV_ROUND_UP(size, PAGE_SIZE);
 	const struct gasket_driver_desc *driver_desc =
 		gasket_get_driver_desc(gasket_dev);
 

commit dc19d43f5738c05103fea828e6c15516d1ae49b5
Author: Robert Deal <robert.edward.deal@gmail.com>
Date:   Sat Nov 10 00:04:34 2018 -0500

    staging: gasket: formatting fixes
    
    Reformat arguments in a few functions in gasket_page_table.c to better
    follow linux kernel formatting standards.
    
    Signed-off-by: Robert Deal <robert.edward.deal@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index f5253ba9a430..26755d9ca41d 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -1088,9 +1088,9 @@ void gasket_page_table_reset(struct gasket_page_table *pg_tbl)
 }
 
 /* See gasket_page_table.h for description. */
-int gasket_page_table_lookup_page(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, struct page **ppage,
-	ulong *poffset)
+int gasket_page_table_lookup_page(struct gasket_page_table *pg_tbl,
+				  ulong dev_addr, struct page **ppage,
+				  ulong *poffset)
 {
 	uint page_num;
 	struct gasket_page_table_entry *pte;
@@ -1134,9 +1134,9 @@ int gasket_page_table_lookup_page(
 }
 
 /* See gasket_page_table.h for description. */
-bool gasket_page_table_are_addrs_bad(
-	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
-	ulong bytes)
+bool gasket_page_table_are_addrs_bad(struct gasket_page_table *pg_tbl,
+				     ulong host_addr, ulong dev_addr,
+				     ulong bytes)
 {
 	if (host_addr & (PAGE_SIZE - 1)) {
 		dev_err(pg_tbl->device,
@@ -1150,8 +1150,8 @@ bool gasket_page_table_are_addrs_bad(
 EXPORT_SYMBOL(gasket_page_table_are_addrs_bad);
 
 /* See gasket_page_table.h for description. */
-bool gasket_page_table_is_dev_addr_bad(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, ulong bytes)
+bool gasket_page_table_is_dev_addr_bad(struct gasket_page_table *pg_tbl,
+				       ulong dev_addr, ulong bytes)
 {
 	uint num_pages = bytes / PAGE_SIZE;
 
@@ -1226,9 +1226,8 @@ int gasket_page_table_system_status(struct gasket_page_table *page_table)
 }
 
 /* Record the host_addr to coherent dma memory mapping. */
-int gasket_set_user_virt(
-	struct gasket_dev *gasket_dev, u64 size, dma_addr_t dma_address,
-	ulong vma)
+int gasket_set_user_virt(struct gasket_dev *gasket_dev, u64 size,
+			 dma_addr_t dma_address, ulong vma)
 {
 	int j;
 	struct gasket_page_table *pg_tbl;
@@ -1346,8 +1345,7 @@ int gasket_free_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 }
 
 /* Release all coherent memory. */
-void gasket_free_coherent_memory_all(
-	struct gasket_dev *gasket_dev, u64 index)
+void gasket_free_coherent_memory_all(struct gasket_dev *gasket_dev, u64 index)
 {
 	if (!gasket_dev->page_table[index])
 		return;

commit cd27f56fce4fedc975663ecebb8166444a80b75c
Author: Kimberly Brown <kimbrownkd@gmail.com>
Date:   Thu Oct 25 20:04:55 2018 -0400

    staging: gasket: use sizeof(*p) for memory allocation
    
    Use sizeof(*p) instead of sizeof(struct P) for memory allocation. This
    change complies with the Linux kernel coding style. It improves
    readability and decreases the opportunity for bugs if the pointer
    variable type is changed. Issue found by checkpatch.
    
    Signed-off-by: Kimberly Brown <kimbrownkd@gmail.com>
    Acked-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index b7d460cf15fb..f5253ba9a430 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -1278,7 +1278,8 @@ int gasket_alloc_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 
 	/* allocate the physical memory block */
 	gasket_dev->page_table[index]->coherent_pages =
-		kcalloc(num_pages, sizeof(struct gasket_coherent_page_entry),
+		kcalloc(num_pages,
+			sizeof(*gasket_dev->page_table[index]->coherent_pages),
 			GFP_KERNEL);
 	if (!gasket_dev->page_table[index]->coherent_pages)
 		goto nomem;

commit e21d5cca3a1bc1e7c1f61796e71c060704bfe863
Author: Todd Poynor <toddpoynor@google.com>
Date:   Tue Oct 16 05:03:08 2018 -0700

    staging: gasket: remove debug logs in page table mapping calls
    
    Remove very noisy debug logs that also contain typos and incorrect
    output formats.
    
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 5b398b7ba81d..b7d460cf15fb 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -477,7 +477,6 @@ static int gasket_perform_mapping(struct gasket_page_table *pg_tbl,
 	for (i = 0; i < num_pages; i++) {
 		page_addr = host_addr + i * PAGE_SIZE;
 		offset = page_addr & (PAGE_SIZE - 1);
-		dev_dbg(pg_tbl->device, "%s i %d\n", __func__, i);
 		if (is_coherent(pg_tbl, host_addr)) {
 			u64 off =
 				(u64)host_addr -
@@ -506,22 +505,9 @@ static int gasket_perform_mapping(struct gasket_page_table *pg_tbl,
 			ptes[i].dma_addr =
 				dma_map_page(pg_tbl->device, page, 0, PAGE_SIZE,
 					     DMA_BIDIRECTIONAL);
-			dev_dbg(pg_tbl->device,
-				"%s i %d pte %p pfn %p -> mapped %llx\n",
-				__func__, i, &ptes[i],
-				(void *)page_to_pfn(page),
-				(unsigned long long)ptes[i].dma_addr);
 
 			if (dma_mapping_error(pg_tbl->device,
 					      ptes[i].dma_addr)) {
-				dev_dbg(pg_tbl->device,
-					"%s i %d -> fail to map page %llx "
-					"[pfn %p ohys %p]\n",
-					__func__, i,
-					(unsigned long long)ptes[i].dma_addr,
-					(void *)page_to_pfn(page),
-					(void *)page_to_phys(page));
-
 				if (gasket_release_page(ptes[i].page))
 					--pg_tbl->num_active_pages;
 
@@ -892,11 +878,6 @@ static int gasket_alloc_extended_subtable(struct gasket_page_table *pg_tbl,
 	pte->dma_addr = dma_map_page(pg_tbl->device, pte->page, 0, PAGE_SIZE,
 				     DMA_TO_DEVICE);
 	if (dma_mapping_error(pg_tbl->device, pte->dma_addr)) {
-		dev_dbg(pg_tbl->device,
-			"%s: fail to map page [pfn %lx phys %llx]\n",
-			__func__, page_to_pfn(pte->page),
-			page_to_phys(pte->page));
-
 		free_page(page_addr);
 		vfree(pte->sublevel);
 		memset(pte, 0, sizeof(struct gasket_page_table_entry));
@@ -1050,11 +1031,6 @@ int gasket_page_table_map(struct gasket_page_table *pg_tbl, ulong host_addr,
 	}
 
 	mutex_unlock(&pg_tbl->mutex);
-
-	dev_dbg(pg_tbl->device,
-		"%s done: ha %llx daddr %llx num %d, ret %d\n",
-		__func__, (unsigned long long)host_addr,
-		(unsigned long long)dev_addr, num_pages, ret);
 	return ret;
 }
 EXPORT_SYMBOL(gasket_page_table_map);

commit c2aed5648fe02324f8a4567bb611c289202d9f07
Author: Nick Ewalt <nicholasewalt@google.com>
Date:   Sun Oct 14 21:59:27 2018 -0700

    staging: gasket: Update device virtual address comment
    
    Add that number of page table entries and extended address bit offset
    are configurable. Update example virtual address format to be more
    consistent with typical usage.
    
    Signed-off-by: Nick Ewalt <nicholasewalt@google.com>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index c2fbab74194f..5b398b7ba81d 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -10,10 +10,18 @@
  *
  * This file assumes 4kB pages throughout; can be factored out when necessary.
  *
- * Address format is as follows:
+ * There is a configurable number of page table entries, as well as a
+ * configurable bit index for the extended address flag. Both of these are
+ * specified in gasket_page_table_init through the page_table_config parameter.
+ *
+ * The following example assumes:
+ *   page_table_config->total_entries = 8192
+ *   page_table_config->extended_bit = 63
+ *
+ * Address format:
  * Simple addresses - those whose containing pages are directly placed in the
  * device's address translation registers - are laid out as:
- * [ 63 - 40: Unused | 39 - 28: 0 | 27 - 12: page index | 11 - 0: page offset ]
+ * [ 63 - 25: 0 | 24 - 12: page index | 11 - 0: page offset ]
  * page index:  The index of the containing page in the device's address
  *              translation registers.
  * page offset: The index of the address into the containing page.
@@ -21,7 +29,7 @@
  * Extended address - those whose containing pages are contained in a second-
  * level page table whose address is present in the device's address translation
  * registers - are laid out as:
- * [ 63 - 40: Unused | 39: flag | 38 - 37: 0 | 36 - 21: dev/level 0 index |
+ * [ 63: flag | 62 - 34: 0 | 33 - 21: dev/level 0 index |
  *   20 - 12: host/level 1 index | 11 - 0: page offset ]
  * flag:        Marker indicating that this is an extended address. Always 1.
  * dev index:   The index of the first-level page in the device's extended

commit 4a966fa24a5a7e236db8ac1e58e04107db1c1930
Author: Nick Ewalt <nicholasewalt@google.com>
Date:   Sun Oct 14 21:59:24 2018 -0700

    staging: gasket: page_table: simplify gasket_components_to_dev_address
    
    Refactor gasket_components_to_dev_address to be faster and easier to
    understand. The old implementation was unnecessarily complex and masked
    the page_index for simple addresses but not extended ones. It makes the
    most sense for this function to perform no such masking.
    
    Signed-off-by: Nick Ewalt <nicholasewalt@google.com>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index ec9359576ea7..c2fbab74194f 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -699,26 +699,9 @@ static ulong gasket_components_to_dev_address(struct gasket_page_table *pg_tbl,
 					      int is_simple, uint page_index,
 					      uint offset)
 {
-	ulong lvl0_index, lvl1_index;
+	ulong dev_addr = (page_index << GASKET_SIMPLE_PAGE_SHIFT) | offset;
 
-	if (is_simple) {
-		/* Return simple addresses directly. */
-		lvl0_index = page_index & (pg_tbl->config.total_entries - 1);
-		return (lvl0_index << GASKET_SIMPLE_PAGE_SHIFT) | offset;
-	}
-
-	/*
-	 * This could be compressed into fewer statements, but
-	 * A) the compiler should optimize it
-	 * B) this is not slow
-	 * C) this is an uncommon operation
-	 * D) this is actually readable this way.
-	 */
-	lvl0_index = page_index / GASKET_PAGES_PER_SUBTABLE;
-	lvl1_index = page_index & (GASKET_PAGES_PER_SUBTABLE - 1);
-	return (pg_tbl)->extended_flag |
-	       (lvl0_index << GASKET_EXTENDED_LVL0_SHIFT) |
-	       (lvl1_index << GASKET_EXTENDED_LVL1_SHIFT) | offset;
+	return is_simple ? dev_addr : (pg_tbl->extended_flag | dev_addr);
 }
 
 /*

commit bae54fb8121da9d52cd6919758defb24639901cf
Author: Nick Ewalt <nicholasewalt@google.com>
Date:   Sun Oct 14 21:59:23 2018 -0700

    staging: gasket: page_table: fix comment in components_to_dev_address
    
    Comments in components_to_dev_address() describing examples are
    inconsistent, fix these to be accurate.
    
    Signed-off-by: Nick Ewalt <nicholasewalt@google.com>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index a88f2ae0cee8..ec9359576ea7 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -687,13 +687,13 @@ static inline bool gasket_addr_is_simple(struct gasket_page_table *pg_tbl,
  * Convert (simple, page, offset) into a device address.
  * Examples:
  * Simple page 0, offset 32:
- *  Input (0, 0, 32), Output 0x20
+ *  Input (1, 0, 32), Output 0x20
  * Simple page 1000, offset 511:
- *  Input (0, 1000, 512), Output 0x3E81FF
+ *  Input (1, 1000, 511), Output 0x3E81FF
  * Extended page 0, offset 32:
  *  Input (0, 0, 32), Output 0x8000000020
  * Extended page 1000, offset 511:
- *  Input (1, 1000, 512), Output 0x8003E81FF
+ *  Input (0, 1000, 511), Output 0x8003E81FF
  */
 static ulong gasket_components_to_dev_address(struct gasket_page_table *pg_tbl,
 					      int is_simple, uint page_index,

commit 54be7ec98875e3061e6ae788d6e7088cffa5ed2e
Author: Nick Ewalt <nicholasewalt@google.com>
Date:   Sun Oct 14 21:59:22 2018 -0700

    staging: gasket: page table: fixup error path allocating coherent mem
    
    Correctly clean up data structure state in gasket_alloc_coherent_memory
    error path, to ensure no double free on the stale pointer value.
    
    Signed-off-by: Nick Ewalt <nicholasewalt@google.com>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 9c2f8671216b..a88f2ae0cee8 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -1332,9 +1332,13 @@ int gasket_alloc_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 	return 0;
 
 nomem:
-	if (mem)
+	if (mem) {
 		dma_free_coherent(gasket_get_device(gasket_dev),
 				  num_pages * PAGE_SIZE, mem, handle);
+		gasket_dev->coherent_buffer.length_bytes = 0;
+		gasket_dev->coherent_buffer.virt_base = NULL;
+		gasket_dev->coherent_buffer.phys_base = 0;
+	}
 
 	kfree(gasket_dev->page_table[index]->coherent_pages);
 	gasket_dev->page_table[index]->coherent_pages = NULL;

commit 53f8a81d465b10aabaf6e0ffc99e7ea2c25bef5a
Author: Nick Ewalt <nicholasewalt@google.com>
Date:   Sun Oct 14 21:59:21 2018 -0700

    staging: gasket: page_table: rearrange gasket_page_table_entry
    
    Rearrange gasket_page_table entry to reduce padding slop.
    
    Signed-off-by: Nick Ewalt <nicholasewalt@google.com>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index d2e115d2dba3..9c2f8671216b 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -103,12 +103,6 @@ struct gasket_page_table_entry {
 	/* The status of this entry/slot: free or in use. */
 	enum pte_status status;
 
-	/* Address of the page in DMA space. */
-	dma_addr_t dma_addr;
-
-	/* Linux page descriptor for the page described by this structure. */
-	struct page *page;
-
 	/*
 	 * Index for alignment into host vaddrs.
 	 * When a user specifies a host address for a mapping, that address may
@@ -119,6 +113,12 @@ struct gasket_page_table_entry {
 	 */
 	int offset;
 
+	/* Address of the page in DMA space. */
+	dma_addr_t dma_addr;
+
+	/* Linux page descriptor for the page described by this structure. */
+	struct page *page;
+
 	/*
 	 * If this is an extended and first-level entry, sublevel points
 	 * to the second-level entries underneath this entry.

commit efa5dcfa8f9ded669da15e29e69e13f56b6bb524
Author: Nick Ewalt <nicholasewalt@google.com>
Date:   Sun Oct 14 21:59:20 2018 -0700

    staging: gasket: page_table: remove unnecessary PTE status set to free
    
    Remove unnecessary ptes[i].status update in gasket_perform_unmapping.
    The vaaue will be cleared in the following memset.
    
    Signed-off-by: Nick Ewalt <nicholasewalt@google.com>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 985a3a93499d..d2e115d2dba3 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -623,7 +623,6 @@ static void gasket_perform_unmapping(struct gasket_page_table *pg_tbl,
 			if (gasket_release_page(ptes[i].page))
 				--pg_tbl->num_active_pages;
 		}
-		ptes[i].status = PTE_FREE;
 
 		/* and clear the PTE. */
 		memset(&ptes[i], 0, sizeof(struct gasket_page_table_entry));

commit 02d37186331d389bb19257e330c1ed47afe178ba
Author: Todd Poynor <toddpoynor@google.com>
Date:   Sun Oct 14 21:59:19 2018 -0700

    staging: gasket: page table: remove dead code in coherent mem alloc
    
    gasket_alloc_coherent_memory() has some unnecessary code related to out
    of memory checking that will never hit the condition checked, remove.
    
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 2e1de8ad4a2c..985a3a93499d 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -1316,7 +1316,6 @@ int gasket_alloc_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 			GFP_KERNEL);
 	if (!gasket_dev->page_table[index]->coherent_pages)
 		goto nomem;
-	*dma_address = 0;
 
 	gasket_dev->coherent_buffer.length_bytes =
 		PAGE_SIZE * (num_pages);
@@ -1331,15 +1330,12 @@ int gasket_alloc_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 			(u64)mem + j * PAGE_SIZE;
 	}
 
-	if (*dma_address == 0)
-		goto nomem;
 	return 0;
 
 nomem:
-	if (mem) {
+	if (mem)
 		dma_free_coherent(gasket_get_device(gasket_dev),
 				  num_pages * PAGE_SIZE, mem, handle);
-	}
 
 	kfree(gasket_dev->page_table[index]->coherent_pages);
 	gasket_dev->page_table[index]->coherent_pages = NULL;

commit b1004491c9c2a62a8ca4d939e35b3c21abc8f28a
Author: Todd Poynor <toddpoynor@google.com>
Date:   Sun Oct 14 21:59:18 2018 -0700

    staging: gasket: page table: return valid error code on map fail
    
    Return -EINVAL on mapping failures, instead of -1, which triggers a
    checkpatch error.
    
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 964146f0df52..2e1de8ad4a2c 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -514,13 +514,12 @@ static int gasket_perform_mapping(struct gasket_page_table *pg_tbl,
 					(void *)page_to_pfn(page),
 					(void *)page_to_phys(page));
 
-				/* clean up */
 				if (gasket_release_page(ptes[i].page))
 					--pg_tbl->num_active_pages;
 
 				memset(&ptes[i], 0,
 				       sizeof(struct gasket_page_table_entry));
-				return -1;
+				return -EINVAL;
 			}
 		}
 
@@ -1165,7 +1164,7 @@ int gasket_page_table_lookup_page(
 	*ppage = NULL;
 	*poffset = 0;
 	mutex_unlock(&pg_tbl->mutex);
-	return -1;
+	return -EINVAL;
 }
 
 /* See gasket_page_table.h for description. */

commit 08b6b28801cc5226283a3a1e1fbd3ea4c9ade7c9
Author: Nick Ewalt <nicholasewalt@google.com>
Date:   Mon Sep 17 05:39:05 2018 -0700

    staging: gasket: page_table: handle failed dma_map_page
    
    Handle dma_map_page failing in gasket_alloc_extended_subtable: free
    memory, don't add invalid page table entry.
    
    Signed-off-by: Nick Ewalt <nicholasewalt@google.com>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 8364b49f147c..964146f0df52 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -902,6 +902,17 @@ static int gasket_alloc_extended_subtable(struct gasket_page_table *pg_tbl,
 	/* Map the page into DMA space. */
 	pte->dma_addr = dma_map_page(pg_tbl->device, pte->page, 0, PAGE_SIZE,
 				     DMA_TO_DEVICE);
+	if (dma_mapping_error(pg_tbl->device, pte->dma_addr)) {
+		dev_dbg(pg_tbl->device,
+			"%s: fail to map page [pfn %lx phys %llx]\n",
+			__func__, page_to_pfn(pte->page),
+			page_to_phys(pte->page));
+
+		free_page(page_addr);
+		vfree(pte->sublevel);
+		memset(pte, 0, sizeof(struct gasket_page_table_entry));
+		return -ENOMEM;
+	}
 
 	/* make the addresses available to the device */
 	dma_addr = (pte->dma_addr + pte->offset) | GASKET_VALID_SLOT_FLAG;

commit 0eaf57fb6150ac6a416cec471ab9db98740501fd
Author: Nick Ewalt <nicholasewalt@google.com>
Date:   Mon Sep 17 05:39:04 2018 -0700

    staging: gasket: page_table: use total_entries for max ext lvl0 page idx
    
    The maximum number of entries in the page table is configurable at
    initialization time and should be used in gasket_extended_lvl0_page_idx.
    
    Signed-off-by: Nick Ewalt <nicholasewalt@google.com>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 779ad2f23ef9..8364b49f147c 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -562,7 +562,7 @@ static ulong gasket_extended_lvl0_page_idx(struct gasket_page_table *pg_tbl,
 					   ulong dev_addr)
 {
 	return (dev_addr >> GASKET_EXTENDED_LVL0_SHIFT) &
-	       ((1 << GASKET_EXTENDED_LVL0_WIDTH) - 1);
+		(pg_tbl->config.total_entries - 1);
 }
 
 /*

commit 863739bda25b2e08afce65caf2762f173e78f481
Author: Nick Ewalt <nicholasewalt@google.com>
Date:   Mon Sep 17 05:39:03 2018 -0700

    staging: gasket: cleanup if dma_map_page fails in gasket_perform_mapping
    
    Previously pages would have never been unmapped in this case.
    
    Signed-off-by: Nick Ewalt <nicholasewalt@google.com>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index c1ce8f984f8e..779ad2f23ef9 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -433,6 +433,19 @@ static int is_coherent(struct gasket_page_table *pg_tbl, ulong host_addr)
 	return min <= host_addr && host_addr < max;
 }
 
+/* Safely return a page to the OS. */
+static bool gasket_release_page(struct page *page)
+{
+	if (!page)
+		return false;
+
+	if (!PageReserved(page))
+		SetPageDirty(page);
+	put_page(page);
+
+	return true;
+}
+
 /*
  * Get and map last level page table buffers.
  *
@@ -500,6 +513,13 @@ static int gasket_perform_mapping(struct gasket_page_table *pg_tbl,
 					(unsigned long long)ptes[i].dma_addr,
 					(void *)page_to_pfn(page),
 					(void *)page_to_phys(page));
+
+				/* clean up */
+				if (gasket_release_page(ptes[i].page))
+					--pg_tbl->num_active_pages;
+
+				memset(&ptes[i], 0,
+				       sizeof(struct gasket_page_table_entry));
 				return -1;
 			}
 		}
@@ -571,19 +591,6 @@ static int gasket_alloc_simple_entries(struct gasket_page_table *pg_tbl,
 	return 0;
 }
 
-/* Safely return a page to the OS. */
-static bool gasket_release_page(struct page *page)
-{
-	if (!page)
-		return false;
-
-	if (!PageReserved(page))
-		SetPageDirty(page);
-	put_page(page);
-
-	return true;
-}
-
 /*
  * Unmap and release mapped pages.
  * The page table mutex must be held by the caller.

commit c3873a5c741f75847ae50a3f566fea2c171c1054
Author: Nick Ewalt <nicholasewalt@google.com>
Date:   Mon Sep 17 05:39:02 2018 -0700

    staging: gasket: fix gasket_free_coherent_memory metadata frees
    
    Free gasket_coherent_page_entries metadata memory, update data
    structures accordingly.
    
    Signed-off-by: Nick Ewalt <nicholasewalt@google.com>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 33d98043953a..c1ce8f984f8e 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -1353,6 +1353,11 @@ int gasket_free_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 		gasket_dev->coherent_buffer.virt_base = NULL;
 		gasket_dev->coherent_buffer.phys_base = 0;
 	}
+
+	kfree(gasket_dev->page_table[index]->coherent_pages);
+	gasket_dev->page_table[index]->coherent_pages = NULL;
+	gasket_dev->page_table[index]->num_coherent_pages = 0;
+
 	return 0;
 }
 

commit f8b6a076610f4eb44b0b02c110b7e6f981d7cdc2
Author: Nick Ewalt <nicholasewalt@google.com>
Date:   Mon Sep 17 05:39:01 2018 -0700

    staging: gasket: page_table: don't unmap coherent pages
    
    Only call dma_unmap_page if there was an associated dma_map_page call.
    
    Signed-off-by: Nick Ewalt <nicholasewalt@google.com>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 8fe27e7d1b53..33d98043953a 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -610,7 +610,7 @@ static void gasket_perform_unmapping(struct gasket_page_table *pg_tbl,
 
 		/* release the address from the driver, */
 		if (ptes[i].status == PTE_INUSE) {
-			if (ptes[i].dma_addr) {
+			if (ptes[i].page && ptes[i].dma_addr) {
 				dma_unmap_page(pg_tbl->device, ptes[i].dma_addr,
 					       PAGE_SIZE, DMA_BIDIRECTIONAL);
 			}

commit d2118f8e93dfc41ab660fb97593dbd6ebdd11f7e
Author: Nick Ewalt <nicholasewalt@google.com>
Date:   Mon Sep 17 05:39:00 2018 -0700

    staging: gasket: fix data page unmap DMA direction
    
    The DMA direction supplied to dma_unmap_page should match the
    corresponding dma_map_page call, which is mapped bi-directional.
    
    Signed-off-by: Nick Ewalt <nicholasewalt@google.com>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index e86bdc5fc79d..8fe27e7d1b53 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -612,7 +612,7 @@ static void gasket_perform_unmapping(struct gasket_page_table *pg_tbl,
 		if (ptes[i].status == PTE_INUSE) {
 			if (ptes[i].dma_addr) {
 				dma_unmap_page(pg_tbl->device, ptes[i].dma_addr,
-					       PAGE_SIZE, DMA_FROM_DEVICE);
+					       PAGE_SIZE, DMA_BIDIRECTIONAL);
 			}
 			if (gasket_release_page(ptes[i].page))
 				--pg_tbl->num_active_pages;

commit 912b8a811cc1bf26334840e9f532136072569b17
Author: Nick Ewalt <nicholasewalt@google.com>
Date:   Mon Sep 17 05:38:59 2018 -0700

    staging: gasket: fix DMA direction for extended page tables
    
    Extended page tables should be mapped as DMA_TO_DEVICE, not
    bi-directional.
    
    Signed-off-by: Nick Ewalt <nicholasewalt@google.com>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 71b77da2e18c..e86bdc5fc79d 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -320,7 +320,7 @@ static void gasket_free_extended_subtable(struct gasket_page_table *pg_tbl,
 
 	if (pte->dma_addr)
 		dma_unmap_page(pg_tbl->device, pte->dma_addr, PAGE_SIZE,
-			       DMA_BIDIRECTIONAL);
+			       DMA_TO_DEVICE);
 
 	vfree(pte->sublevel);
 
@@ -894,7 +894,7 @@ static int gasket_alloc_extended_subtable(struct gasket_page_table *pg_tbl,
 
 	/* Map the page into DMA space. */
 	pte->dma_addr = dma_map_page(pg_tbl->device, pte->page, 0, PAGE_SIZE,
-				     DMA_BIDIRECTIONAL);
+				     DMA_TO_DEVICE);
 
 	/* make the addresses available to the device */
 	dma_addr = (pte->dma_addr + pte->offset) | GASKET_VALID_SLOT_FLAG;

commit 45dd9954d903310f1fd8d5ac90d7faeca0694415
Author: Todd Poynor <toddpoynor@google.com>
Date:   Mon Sep 17 05:38:58 2018 -0700

    staging: gasket: page table: use GFP_KERNEL for dma_alloc_coherent
    
    Flags should be specified for dma_alloc_coherent() call.  Use
    GFP_KERNEL, it's fine to sleep here.
    
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 53492f4fad6a..71b77da2e18c 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -1287,7 +1287,7 @@ int gasket_alloc_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 		return -EINVAL;
 
 	mem = dma_alloc_coherent(gasket_get_device(gasket_dev),
-				 num_pages * PAGE_SIZE, &handle, 0);
+				 num_pages * PAGE_SIZE, &handle, GFP_KERNEL);
 	if (!mem)
 		goto nomem;
 

commit 7b49682bdc6cf6f7d55e7c7e74415c2b101a9671
Author: Todd Poynor <toddpoynor@google.com>
Date:   Thu Aug 9 20:21:05 2018 -0700

    staging: gasket: page table: remove extraneous memory barriers
    
    Some explicit memory barriers in the page table code are not necessary,
    either because:
    
    (a) The barrier follows a non-relaxed MMIO access that already performs
    a read or write memory barrier.
    
    (b) The barrier follows DMA API calls for which the device-visible
    effects of IOMMU programming are guaranteed to be flushed to the IOMMU
    prior to the call returning, and doesn't need to sync with normal memory
    access.
    
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 4d2499269499..53492f4fad6a 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -317,8 +317,6 @@ static void gasket_free_extended_subtable(struct gasket_page_table *pg_tbl,
 
 	/* Release the page table from the device */
 	writeq(0, slot);
-	/* Force sync around the address release. */
-	mb();
 
 	if (pte->dma_addr)
 		dma_unmap_page(pg_tbl->device, pte->dma_addr, PAGE_SIZE,
@@ -504,8 +502,6 @@ static int gasket_perform_mapping(struct gasket_page_table *pg_tbl,
 					(void *)page_to_phys(page));
 				return -1;
 			}
-			/* Wait until the page is mapped. */
-			mb();
 		}
 
 		/* Make the DMA-space address available to the device. */
@@ -604,12 +600,13 @@ static void gasket_perform_unmapping(struct gasket_page_table *pg_tbl,
 	 */
 	for (i = 0; i < num_pages; i++) {
 		/* release the address from the device, */
-		if (is_simple_mapping || ptes[i].status == PTE_INUSE)
+		if (is_simple_mapping || ptes[i].status == PTE_INUSE) {
 			writeq(0, &slots[i]);
-		else
+		} else {
 			((u64 __force *)slots)[i] = 0;
-		/* Force sync around the address release. */
-		mb();
+			/* sync above PTE update before updating mappings */
+			wmb();
+		}
 
 		/* release the address from the driver, */
 		if (ptes[i].status == PTE_INUSE) {
@@ -898,8 +895,6 @@ static int gasket_alloc_extended_subtable(struct gasket_page_table *pg_tbl,
 	/* Map the page into DMA space. */
 	pte->dma_addr = dma_map_page(pg_tbl->device, pte->page, 0, PAGE_SIZE,
 				     DMA_BIDIRECTIONAL);
-	/* Wait until the page is mapped. */
-	mb();
 
 	/* make the addresses available to the device */
 	dma_addr = (pte->dma_addr + pte->offset) | GASKET_VALID_SLOT_FLAG;

commit 6c258edc64ae3d655a37abb773c21492a5196bf2
Author: Todd Poynor <toddpoynor@google.com>
Date:   Thu Aug 9 20:21:03 2018 -0700

    staging: gasket: page table: use dma_mapping_error for error detection
    
    gasket_perform_mapping() call dma_mapping_error() to determine if
    mapping failed.
    
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index bd921dc6094d..4d2499269499 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -493,7 +493,8 @@ static int gasket_perform_mapping(struct gasket_page_table *pg_tbl,
 				(void *)page_to_pfn(page),
 				(unsigned long long)ptes[i].dma_addr);
 
-			if (ptes[i].dma_addr == -1) {
+			if (dma_mapping_error(pg_tbl->device,
+					      ptes[i].dma_addr)) {
 				dev_dbg(pg_tbl->device,
 					"%s i %d -> fail to map page %llx "
 					"[pfn %p ohys %p]\n",

commit 3c0971939e5682bf8c20bdf240900d5014107b57
Author: Sumit Kumar <sumit686215@gmail.com>
Date:   Sun Aug 12 12:38:19 2018 +0530

    staging: gasket: remove null ptr check before kfree
    
    Remove null ptr check before kfree because kfree is null ptr safe.
    Issue found by checkpatch.
    
    Signed-off-by: Sumit Kumar <sumit686215@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index d4c5f8aa7dd3..bd921dc6094d 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -1328,10 +1328,8 @@ int gasket_alloc_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 				  num_pages * PAGE_SIZE, mem, handle);
 	}
 
-	if (gasket_dev->page_table[index]->coherent_pages) {
-		kfree(gasket_dev->page_table[index]->coherent_pages);
-		gasket_dev->page_table[index]->coherent_pages = NULL;
-	}
+	kfree(gasket_dev->page_table[index]->coherent_pages);
+	gasket_dev->page_table[index]->coherent_pages = NULL;
 	gasket_dev->page_table[index]->num_coherent_pages = 0;
 	return -ENOMEM;
 }

commit 8d84a9c1d29dbad517228e7e64d07b4d86dc7f59
Author: Sumit Pundir <pundirsumit11@gmail.com>
Date:   Tue Aug 7 16:14:28 2018 +0530

    staging: gasket: fix code indent for conditional statement
    
    Fixed a coding style issue related to indentation. Reported by
    checkpatch.pl
    
    Signed-off-by: Sumit Pundir <pundirsumit11@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index ed6ab3c5f038..d4c5f8aa7dd3 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -1311,7 +1311,7 @@ int gasket_alloc_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 	gasket_dev->coherent_buffer.virt_base = mem;
 
 	*dma_address = driver_desc->coherent_buffer_description.base;
-		for (j = 0; j < num_pages; j++) {
+	for (j = 0; j < num_pages; j++) {
 		gasket_dev->page_table[index]->coherent_pages[j].paddr =
 			handle + j * PAGE_SIZE;
 		gasket_dev->page_table[index]->coherent_pages[j].kernel_virt =

commit d29f6c19b0d4f71ee72e4e2b387c3d08666a6a18
Author: Todd Poynor <toddpoynor@google.com>
Date:   Tue Jul 31 13:24:47 2018 -0700

    Revert "staging: gasket: page table: hold references to device and pci_dev"
    
    gasket_free_dev() is called only from driver PCI probe and remove
    function. It is guaranteed that that pci_dev structure is not going
    anywhere during that time; there is no need to take this additional
    reference.
    
    This reverts commit dd9d1502feea3c23d412f289aad79e1d4e86d45d.
    
    Reported-by: Dmitry Torokhov <dtor@chromium.org>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 13e1d0952a47..ed6ab3c5f038 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -280,7 +280,7 @@ int gasket_page_table_init(struct gasket_page_table **ppg_tbl,
 	pg_tbl->extended_offset_reg =
 		(u64 __iomem *)&bar_data->virt_base[page_table_config->extended_reg];
 	pg_tbl->device = get_device(device);
-	pg_tbl->pci_dev = pci_dev_get(pci_dev);
+	pg_tbl->pci_dev = pci_dev;
 
 	dev_dbg(device, "Page table initialized successfully\n");
 
@@ -378,7 +378,6 @@ void gasket_page_table_cleanup(struct gasket_page_table *pg_tbl)
 	pg_tbl->entries = NULL;
 
 	put_device(pg_tbl->device);
-	pci_dev_put(pg_tbl->pci_dev);
 	kfree(pg_tbl);
 }
 

commit e8c7f19981dce9e8661b0b1e277bda4c322f9af7
Author: Todd Poynor <toddpoynor@google.com>
Date:   Tue Jul 31 13:24:41 2018 -0700

    staging: gasket: page table: fix function param line continuation style
    
    Fix multi-line alignment formatting to look like:
          int ret = long_function_name(device, VARIABLE1, VARIABLE2,
                                       VARIABLE3, VARIABLE4);
    
    Many of these TODO items were previously cleaned up during the conversion
    to standard logging functions.
    
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index aa036b2e8193..13e1d0952a47 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -215,11 +215,10 @@ struct gasket_page_table {
 };
 
 /* See gasket_page_table.h for description. */
-int gasket_page_table_init(
-	struct gasket_page_table **ppg_tbl,
-	const struct gasket_bar_data *bar_data,
-	const struct gasket_page_table_config *page_table_config,
-	struct device *device, struct pci_dev *pci_dev)
+int gasket_page_table_init(struct gasket_page_table **ppg_tbl,
+			   const struct gasket_bar_data *bar_data,
+			   const struct gasket_page_table_config *page_table_config,
+			   struct device *device, struct pci_dev *pci_dev)
 {
 	ulong bytes;
 	struct gasket_page_table *pg_tbl;
@@ -276,10 +275,10 @@ int gasket_page_table_init(
 		pg_tbl->extended_flag = 0;
 	}
 	pg_tbl->num_active_pages = 0;
-	pg_tbl->base_slot = (u64 __iomem *)&(
-		bar_data->virt_base[page_table_config->base_reg]);
-	pg_tbl->extended_offset_reg = (u64 __iomem *)&(
-		bar_data->virt_base[page_table_config->extended_reg]);
+	pg_tbl->base_slot =
+		(u64 __iomem *)&bar_data->virt_base[page_table_config->base_reg];
+	pg_tbl->extended_offset_reg =
+		(u64 __iomem *)&bar_data->virt_base[page_table_config->extended_reg];
 	pg_tbl->device = get_device(device);
 	pg_tbl->pci_dev = pci_dev_get(pci_dev);
 
@@ -292,8 +291,8 @@ int gasket_page_table_init(
  * Check if a range of PTEs is free.
  * The page table mutex must be held by the caller.
  */
-static bool gasket_is_pte_range_free(
-	struct gasket_page_table_entry *ptes, uint num_entries)
+static bool gasket_is_pte_range_free(struct gasket_page_table_entry *ptes,
+				     uint num_entries)
 {
 	int i;
 
@@ -309,9 +308,9 @@ static bool gasket_is_pte_range_free(
  * Free a second level page [sub]table.
  * The page table mutex must be held before this call.
  */
-static void gasket_free_extended_subtable(
-	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *pte,
-	u64 __iomem *slot)
+static void gasket_free_extended_subtable(struct gasket_page_table *pg_tbl,
+					  struct gasket_page_table_entry *pte,
+					  u64 __iomem *slot)
 {
 	/* Release the page table from the driver */
 	pte->status = PTE_FREE;
@@ -337,8 +336,8 @@ static void gasket_free_extended_subtable(
  * Actually perform collection.
  * The page table mutex must be held by the caller.
  */
-static void gasket_page_table_garbage_collect_nolock(
-	struct gasket_page_table *pg_tbl)
+static void
+gasket_page_table_garbage_collect_nolock(struct gasket_page_table *pg_tbl)
 {
 	struct gasket_page_table_entry *pte;
 	u64 __iomem *slot;
@@ -351,10 +350,10 @@ static void gasket_page_table_garbage_collect_nolock(
 	     pte < pg_tbl->entries + pg_tbl->config.total_entries;
 	     pte++, slot++) {
 		if (pte->status == PTE_INUSE) {
-			if (gasket_is_pte_range_free(
-				    pte->sublevel, GASKET_PAGES_PER_SUBTABLE))
-				gasket_free_extended_subtable(
-					pg_tbl, pte, slot);
+			if (gasket_is_pte_range_free(pte->sublevel,
+						     GASKET_PAGES_PER_SUBTABLE))
+				gasket_free_extended_subtable(pg_tbl, pte,
+							      slot);
 		}
 	}
 }
@@ -384,8 +383,8 @@ void gasket_page_table_cleanup(struct gasket_page_table *pg_tbl)
 }
 
 /* See gasket_page_table.h for description. */
-int gasket_page_table_partition(
-	struct gasket_page_table *pg_tbl, uint num_simple_entries)
+int gasket_page_table_partition(struct gasket_page_table *pg_tbl,
+				uint num_simple_entries)
 {
 	int i, start;
 
@@ -445,10 +444,10 @@ static int is_coherent(struct gasket_page_table *pg_tbl, ulong host_addr)
  * an extended mapping, these will be within a second-level page table
  * allocated by the host and so must have their __iomem attribute casted away.
  */
-static int gasket_perform_mapping(
-	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *ptes,
-	u64 __iomem *slots, ulong host_addr, uint num_pages,
-	int is_simple_mapping)
+static int gasket_perform_mapping(struct gasket_page_table *pg_tbl,
+				  struct gasket_page_table_entry *ptes,
+				  u64 __iomem *slots, ulong host_addr,
+				  uint num_pages, int is_simple_mapping)
 {
 	int ret;
 	ulong offset;
@@ -470,8 +469,8 @@ static int gasket_perform_mapping(
 			ptes[i].dma_addr = pg_tbl->coherent_pages[0].paddr +
 					   off + i * PAGE_SIZE;
 		} else {
-			ret = get_user_pages_fast(
-				page_addr - offset, 1, 1, &page);
+			ret = get_user_pages_fast(page_addr - offset, 1, 1,
+						  &page);
 
 			if (ret <= 0) {
 				dev_err(pg_tbl->device,
@@ -532,8 +531,8 @@ static int gasket_perform_mapping(
  * Return the index of the page for the address in the simple table.
  * Does not perform validity checking.
  */
-static int gasket_simple_page_idx(
-	struct gasket_page_table *pg_tbl, ulong dev_addr)
+static int gasket_simple_page_idx(struct gasket_page_table *pg_tbl,
+				  ulong dev_addr)
 {
 	return (dev_addr >> GASKET_SIMPLE_PAGE_SHIFT) &
 		(pg_tbl->config.total_entries - 1);
@@ -543,8 +542,8 @@ static int gasket_simple_page_idx(
  * Return the level 0 page index for the given address.
  * Does not perform validity checking.
  */
-static ulong gasket_extended_lvl0_page_idx(
-	struct gasket_page_table *pg_tbl, ulong dev_addr)
+static ulong gasket_extended_lvl0_page_idx(struct gasket_page_table *pg_tbl,
+					   ulong dev_addr)
 {
 	return (dev_addr >> GASKET_EXTENDED_LVL0_SHIFT) &
 	       ((1 << GASKET_EXTENDED_LVL0_WIDTH) - 1);
@@ -554,8 +553,8 @@ static ulong gasket_extended_lvl0_page_idx(
  * Return the level 1 page index for the given address.
  * Does not perform validity checking.
  */
-static ulong gasket_extended_lvl1_page_idx(
-	struct gasket_page_table *pg_tbl, ulong dev_addr)
+static ulong gasket_extended_lvl1_page_idx(struct gasket_page_table *pg_tbl,
+					   ulong dev_addr)
 {
 	return (dev_addr >> GASKET_EXTENDED_LVL1_SHIFT) &
 	       (GASKET_PAGES_PER_SUBTABLE - 1);
@@ -565,12 +564,12 @@ static ulong gasket_extended_lvl1_page_idx(
  * Allocate page table entries in a simple table.
  * The page table mutex must be held by the caller.
  */
-static int gasket_alloc_simple_entries(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+static int gasket_alloc_simple_entries(struct gasket_page_table *pg_tbl,
+				       ulong dev_addr, uint num_pages)
 {
-	if (!gasket_is_pte_range_free(
-		    pg_tbl->entries + gasket_simple_page_idx(pg_tbl, dev_addr),
-		    num_pages))
+	if (!gasket_is_pte_range_free(pg_tbl->entries +
+				      gasket_simple_page_idx(pg_tbl, dev_addr),
+				      num_pages))
 		return -EBUSY;
 
 	return 0;
@@ -593,9 +592,10 @@ static bool gasket_release_page(struct page *page)
  * Unmap and release mapped pages.
  * The page table mutex must be held by the caller.
  */
-static void gasket_perform_unmapping(
-	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *ptes,
-	u64 __iomem *slots, uint num_pages, int is_simple_mapping)
+static void gasket_perform_unmapping(struct gasket_page_table *pg_tbl,
+				     struct gasket_page_table_entry *ptes,
+				     u64 __iomem *slots, uint num_pages,
+				     int is_simple_mapping)
 {
 	int i;
 	/*
@@ -631,8 +631,8 @@ static void gasket_perform_unmapping(
  * Unmap and release pages mapped to simple addresses.
  * The page table mutex must be held by the caller.
  */
-static void gasket_unmap_simple_pages(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+static void gasket_unmap_simple_pages(struct gasket_page_table *pg_tbl,
+				      ulong dev_addr, uint num_pages)
 {
 	uint slot = gasket_simple_page_idx(pg_tbl, dev_addr);
 
@@ -644,8 +644,8 @@ static void gasket_unmap_simple_pages(
  * Unmap and release buffers to extended addresses.
  * The page table mutex must be held by the caller.
  */
-static void gasket_unmap_extended_pages(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+static void gasket_unmap_extended_pages(struct gasket_page_table *pg_tbl,
+					ulong dev_addr, uint num_pages)
 {
 	uint slot_idx, remain, len;
 	struct gasket_page_table_entry *pte;
@@ -663,9 +663,9 @@ static void gasket_unmap_extended_pages(
 		if (pte->status == PTE_INUSE) {
 			slot_base = (u64 __iomem *)(page_address(pte->page) +
 						    pte->offset);
-			gasket_perform_unmapping(
-				pg_tbl, pte->sublevel + slot_idx,
-				slot_base + slot_idx, len, 0);
+			gasket_perform_unmapping(pg_tbl,
+						 pte->sublevel + slot_idx,
+						 slot_base + slot_idx, len, 0);
 		}
 
 		remain -= len;
@@ -675,8 +675,8 @@ static void gasket_unmap_extended_pages(
 }
 
 /* Evaluates to nonzero if the specified virtual address is simple. */
-static inline bool gasket_addr_is_simple(
-	struct gasket_page_table *pg_tbl, ulong addr)
+static inline bool gasket_addr_is_simple(struct gasket_page_table *pg_tbl,
+					 ulong addr)
 {
 	return !((addr) & (pg_tbl)->extended_flag);
 }
@@ -693,9 +693,9 @@ static inline bool gasket_addr_is_simple(
  * Extended page 1000, offset 511:
  *  Input (1, 1000, 512), Output 0x8003E81FF
  */
-static ulong gasket_components_to_dev_address(
-	struct gasket_page_table *pg_tbl, int is_simple, uint page_index,
-	uint offset)
+static ulong gasket_components_to_dev_address(struct gasket_page_table *pg_tbl,
+					      int is_simple, uint page_index,
+					      uint offset)
 {
 	ulong lvl0_index, lvl1_index;
 
@@ -726,15 +726,15 @@ static ulong gasket_components_to_dev_address(
  * and that the requested page range starts and ends within the set of
  * currently-partitioned simple pages.
  */
-static bool gasket_is_simple_dev_addr_bad(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+static bool gasket_is_simple_dev_addr_bad(struct gasket_page_table *pg_tbl,
+					  ulong dev_addr, uint num_pages)
 {
 	ulong page_offset = dev_addr & (PAGE_SIZE - 1);
 	ulong page_index =
 		(dev_addr / PAGE_SIZE) & (pg_tbl->config.total_entries - 1);
 
-	if (gasket_components_to_dev_address(
-		pg_tbl, 1, page_index, page_offset) != dev_addr) {
+	if (gasket_components_to_dev_address(pg_tbl, 1, page_index,
+					     page_offset) != dev_addr) {
 		dev_err(pg_tbl->device, "address is invalid, 0x%lX\n",
 			dev_addr);
 		return true;
@@ -764,8 +764,8 @@ static bool gasket_is_simple_dev_addr_bad(
  * offset) and that the requested page range starts and ends within the set of
  * currently-partitioned extended pages.
  */
-static bool gasket_is_extended_dev_addr_bad(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+static bool gasket_is_extended_dev_addr_bad(struct gasket_page_table *pg_tbl,
+					    ulong dev_addr, uint num_pages)
 {
 	/* Starting byte index of dev_addr into the first mapped page */
 	ulong page_offset = dev_addr & (PAGE_SIZE - 1);
@@ -792,8 +792,8 @@ static bool gasket_is_extended_dev_addr_bad(
 	num_lvl0_pages = (num_pages + GASKET_PAGES_PER_SUBTABLE - 1) /
 		GASKET_PAGES_PER_SUBTABLE;
 
-	if (gasket_components_to_dev_address(
-		pg_tbl, 0, page_global_idx, page_offset) != dev_addr) {
+	if (gasket_components_to_dev_address(pg_tbl, 0, page_global_idx,
+					     page_offset) != dev_addr) {
 		dev_err(pg_tbl->device, "address is invalid: 0x%lx\n",
 			dev_addr);
 		return true;
@@ -821,8 +821,8 @@ static bool gasket_is_extended_dev_addr_bad(
  * Non-locking entry to unmapping routines.
  * The page table mutex must be held by the caller.
  */
-static void gasket_page_table_unmap_nolock(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+static void gasket_page_table_unmap_nolock(struct gasket_page_table *pg_tbl,
+					   ulong dev_addr, uint num_pages)
 {
 	if (!num_pages)
 		return;
@@ -837,9 +837,9 @@ static void gasket_page_table_unmap_nolock(
  * Allocate and map pages to simple addresses.
  * If there is an error, no pages are mapped.
  */
-static int gasket_map_simple_pages(
-	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
-	uint num_pages)
+static int gasket_map_simple_pages(struct gasket_page_table *pg_tbl,
+				   ulong host_addr, ulong dev_addr,
+				   uint num_pages)
 {
 	int ret;
 	uint slot_idx = gasket_simple_page_idx(pg_tbl, dev_addr);
@@ -852,9 +852,9 @@ static int gasket_map_simple_pages(
 		return ret;
 	}
 
-	ret = gasket_perform_mapping(
-		pg_tbl, pg_tbl->entries + slot_idx,
-		pg_tbl->base_slot + slot_idx, host_addr, num_pages, 1);
+	ret = gasket_perform_mapping(pg_tbl, pg_tbl->entries + slot_idx,
+				     pg_tbl->base_slot + slot_idx, host_addr,
+				     num_pages, 1);
 
 	if (ret) {
 		gasket_page_table_unmap_nolock(pg_tbl, dev_addr, num_pages);
@@ -867,9 +867,9 @@ static int gasket_map_simple_pages(
  * Allocate a second level page table.
  * The page table mutex must be held by the caller.
  */
-static int gasket_alloc_extended_subtable(
-	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *pte,
-	u64 __iomem *slot)
+static int gasket_alloc_extended_subtable(struct gasket_page_table *pg_tbl,
+					  struct gasket_page_table_entry *pte,
+					  u64 __iomem *slot)
 {
 	ulong page_addr, subtable_bytes;
 	dma_addr_t dma_addr;
@@ -924,8 +924,8 @@ static int gasket_alloc_extended_subtable(
  *
  * The page table mutex must be held by the caller.
  */
-static int gasket_alloc_extended_entries(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_entries)
+static int gasket_alloc_extended_entries(struct gasket_page_table *pg_tbl,
+					 ulong dev_addr, uint num_entries)
 {
 	int ret = 0;
 	uint remain, subtable_slot_idx, len;
@@ -951,8 +951,8 @@ static int gasket_alloc_extended_entries(
 				return ret;
 			}
 		} else {
-			if (!gasket_is_pte_range_free(
-				    pte->sublevel + subtable_slot_idx, len))
+			if (!gasket_is_pte_range_free(pte->sublevel +
+						      subtable_slot_idx, len))
 				return -EBUSY;
 		}
 
@@ -969,9 +969,9 @@ static int gasket_alloc_extended_entries(
  * gasket_map_extended_pages - Get and map buffers to extended addresses.
  * If there is an error, no pages are mapped.
  */
-static int gasket_map_extended_pages(
-	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
-	uint num_pages)
+static int gasket_map_extended_pages(struct gasket_page_table *pg_tbl,
+				     ulong host_addr, ulong dev_addr,
+				     uint num_pages)
 {
 	int ret;
 	ulong dev_addr_end;
@@ -1003,12 +1003,12 @@ static int gasket_map_extended_pages(
 
 		slot_base =
 			(u64 __iomem *)(page_address(pte->page) + pte->offset);
-		ret = gasket_perform_mapping(
-			pg_tbl, pte->sublevel + slot_idx, slot_base + slot_idx,
-			host_addr, len, 0);
+		ret = gasket_perform_mapping(pg_tbl, pte->sublevel + slot_idx,
+					     slot_base + slot_idx, host_addr,
+					     len, 0);
 		if (ret) {
-			gasket_page_table_unmap_nolock(
-				pg_tbl, dev_addr, num_pages);
+			gasket_page_table_unmap_nolock(pg_tbl, dev_addr,
+						       num_pages);
 			return ret;
 		}
 
@@ -1029,9 +1029,8 @@ static int gasket_map_extended_pages(
  *
  * The page table mutex is held for the entire operation.
  */
-int gasket_page_table_map(
-	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
-	uint num_pages)
+int gasket_page_table_map(struct gasket_page_table *pg_tbl, ulong host_addr,
+			  ulong dev_addr, uint num_pages)
 {
 	int ret;
 
@@ -1041,11 +1040,11 @@ int gasket_page_table_map(
 	mutex_lock(&pg_tbl->mutex);
 
 	if (gasket_addr_is_simple(pg_tbl, dev_addr)) {
-		ret = gasket_map_simple_pages(
-			pg_tbl, host_addr, dev_addr, num_pages);
+		ret = gasket_map_simple_pages(pg_tbl, host_addr, dev_addr,
+					      num_pages);
 	} else {
-		ret = gasket_map_extended_pages(
-			pg_tbl, host_addr, dev_addr, num_pages);
+		ret = gasket_map_extended_pages(pg_tbl, host_addr, dev_addr,
+						num_pages);
 	}
 
 	mutex_unlock(&pg_tbl->mutex);
@@ -1067,8 +1066,8 @@ EXPORT_SYMBOL(gasket_page_table_map);
  *
  * The page table mutex is held for the entire operation.
  */
-void gasket_page_table_unmap(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+void gasket_page_table_unmap(struct gasket_page_table *pg_tbl, ulong dev_addr,
+			     uint num_pages)
 {
 	if (!num_pages)
 		return;
@@ -1081,12 +1080,15 @@ EXPORT_SYMBOL(gasket_page_table_unmap);
 
 static void gasket_page_table_unmap_all_nolock(struct gasket_page_table *pg_tbl)
 {
-	gasket_unmap_simple_pages(
-		pg_tbl, gasket_components_to_dev_address(pg_tbl, 1, 0, 0),
-		pg_tbl->num_simple_entries);
-	gasket_unmap_extended_pages(
-		pg_tbl, gasket_components_to_dev_address(pg_tbl, 0, 0, 0),
-		pg_tbl->num_extended_entries * GASKET_PAGES_PER_SUBTABLE);
+	gasket_unmap_simple_pages(pg_tbl,
+				  gasket_components_to_dev_address(pg_tbl, 1, 0,
+								   0),
+				  pg_tbl->num_simple_entries);
+	gasket_unmap_extended_pages(pg_tbl,
+				    gasket_components_to_dev_address(pg_tbl, 0,
+								     0, 0),
+				    pg_tbl->num_extended_entries *
+				    GASKET_PAGES_PER_SUBTABLE);
 }
 
 /* See gasket_page_table.h for description. */
@@ -1189,8 +1191,8 @@ bool gasket_page_table_is_dev_addr_bad(
 	}
 
 	if (gasket_addr_is_simple(pg_tbl, dev_addr))
-		return gasket_is_simple_dev_addr_bad(
-			pg_tbl, dev_addr, num_pages);
+		return gasket_is_simple_dev_addr_bad(pg_tbl, dev_addr,
+						     num_pages);
 	return gasket_is_extended_dev_addr_bad(pg_tbl, dev_addr, num_pages);
 }
 EXPORT_SYMBOL(gasket_page_table_is_dev_addr_bad);

commit 00b60c8d9ed7e9505b70143af04497625d5ef019
Author: Todd Poynor <toddpoynor@google.com>
Date:   Tue Jul 31 13:24:37 2018 -0700

    staging: gasket: pg tbl: remove static function forward declarations
    
    Remove forward declarations of static functions, move code to avoid
    forward references, for kernel style.
    
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index b42f6637b909..aa036b2e8193 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -214,71 +214,6 @@ struct gasket_page_table {
 	struct gasket_coherent_page_entry *coherent_pages;
 };
 
-/* Mapping declarations */
-static int gasket_map_simple_pages(
-	struct gasket_page_table *pg_tbl, ulong host_addr,
-	ulong dev_addr, uint num_pages);
-static int gasket_map_extended_pages(
-	struct gasket_page_table *pg_tbl, ulong host_addr,
-	ulong dev_addr, uint num_pages);
-static int gasket_perform_mapping(
-	struct gasket_page_table *pg_tbl,
-	struct gasket_page_table_entry *pte_base, u64 __iomem *att_base,
-	ulong host_addr, uint num_pages, int is_simple_mapping);
-
-static int gasket_alloc_simple_entries(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages);
-static int gasket_alloc_extended_entries(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_entries);
-static int gasket_alloc_extended_subtable(
-	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *pte,
-	u64 __iomem *att_reg);
-
-/* Unmapping declarations */
-static void gasket_page_table_unmap_nolock(
-	struct gasket_page_table *pg_tbl, ulong start_addr, uint num_pages);
-static void gasket_page_table_unmap_all_nolock(
-	struct gasket_page_table *pg_tbl);
-static void gasket_unmap_simple_pages(
-	struct gasket_page_table *pg_tbl, ulong start_addr, uint num_pages);
-static void gasket_unmap_extended_pages(
-	struct gasket_page_table *pg_tbl, ulong start_addr, uint num_pages);
-static void gasket_perform_unmapping(
-	struct gasket_page_table *pg_tbl,
-	struct gasket_page_table_entry *pte_base, u64 __iomem *att_base,
-	uint num_pages, int is_simple_mapping);
-
-static void gasket_free_extended_subtable(
-	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *pte,
-	u64 __iomem *att_reg);
-static bool gasket_release_page(struct page *page);
-
-/* Other/utility declarations */
-static inline bool gasket_addr_is_simple(
-	struct gasket_page_table *pg_tbl, ulong addr);
-static bool gasket_is_simple_dev_addr_bad(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages);
-static bool gasket_is_extended_dev_addr_bad(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages);
-static bool gasket_is_pte_range_free(
-	struct gasket_page_table_entry *pte, uint num_entries);
-static void gasket_page_table_garbage_collect_nolock(
-	struct gasket_page_table *pg_tbl);
-
-/* Address format declarations */
-static ulong gasket_components_to_dev_address(
-	struct gasket_page_table *pg_tbl, int is_simple, uint page_index,
-	uint offset);
-static int gasket_simple_page_idx(
-	struct gasket_page_table *pg_tbl, ulong dev_addr);
-static ulong gasket_extended_lvl0_page_idx(
-	struct gasket_page_table *pg_tbl, ulong dev_addr);
-static ulong gasket_extended_lvl1_page_idx(
-	struct gasket_page_table *pg_tbl, ulong dev_addr);
-
-static int is_coherent(struct gasket_page_table *pg_tbl, ulong host_addr);
-
-/* Public/exported functions */
 /* See gasket_page_table.h for description. */
 int gasket_page_table_init(
 	struct gasket_page_table **ppg_tbl,
@@ -353,6 +288,85 @@ int gasket_page_table_init(
 	return 0;
 }
 
+/*
+ * Check if a range of PTEs is free.
+ * The page table mutex must be held by the caller.
+ */
+static bool gasket_is_pte_range_free(
+	struct gasket_page_table_entry *ptes, uint num_entries)
+{
+	int i;
+
+	for (i = 0; i < num_entries; i++) {
+		if (ptes[i].status != PTE_FREE)
+			return false;
+	}
+
+	return true;
+}
+
+/*
+ * Free a second level page [sub]table.
+ * The page table mutex must be held before this call.
+ */
+static void gasket_free_extended_subtable(
+	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *pte,
+	u64 __iomem *slot)
+{
+	/* Release the page table from the driver */
+	pte->status = PTE_FREE;
+
+	/* Release the page table from the device */
+	writeq(0, slot);
+	/* Force sync around the address release. */
+	mb();
+
+	if (pte->dma_addr)
+		dma_unmap_page(pg_tbl->device, pte->dma_addr, PAGE_SIZE,
+			       DMA_BIDIRECTIONAL);
+
+	vfree(pte->sublevel);
+
+	if (pte->page)
+		free_page((ulong)page_address(pte->page));
+
+	memset(pte, 0, sizeof(struct gasket_page_table_entry));
+}
+
+/*
+ * Actually perform collection.
+ * The page table mutex must be held by the caller.
+ */
+static void gasket_page_table_garbage_collect_nolock(
+	struct gasket_page_table *pg_tbl)
+{
+	struct gasket_page_table_entry *pte;
+	u64 __iomem *slot;
+
+	/* XXX FIX ME XXX -- more efficient to keep a usage count */
+	/* rather than scanning the second level page tables */
+
+	for (pte = pg_tbl->entries + pg_tbl->num_simple_entries,
+	     slot = pg_tbl->base_slot + pg_tbl->num_simple_entries;
+	     pte < pg_tbl->entries + pg_tbl->config.total_entries;
+	     pte++, slot++) {
+		if (pte->status == PTE_INUSE) {
+			if (gasket_is_pte_range_free(
+				    pte->sublevel, GASKET_PAGES_PER_SUBTABLE))
+				gasket_free_extended_subtable(
+					pg_tbl, pte, slot);
+		}
+	}
+}
+
+/* See gasket_page_table.h for description. */
+void gasket_page_table_garbage_collect(struct gasket_page_table *pg_tbl)
+{
+	mutex_lock(&pg_tbl->mutex);
+	gasket_page_table_garbage_collect_nolock(pg_tbl);
+	mutex_unlock(&pg_tbl->mutex);
+}
+
 /* See gasket_page_table.h for description. */
 void gasket_page_table_cleanup(struct gasket_page_table *pg_tbl)
 {
@@ -404,500 +418,467 @@ int gasket_page_table_partition(
 EXPORT_SYMBOL(gasket_page_table_partition);
 
 /*
- * See gasket_page_table.h for general description.
- *
- * gasket_page_table_map calls either gasket_map_simple_pages() or
- * gasket_map_extended_pages() to actually perform the mapping.
+ * Return whether a host buffer was mapped as coherent memory.
  *
- * The page table mutex is held for the entire operation.
+ * A Gasket page_table currently support one contiguous dma range, mapped to one
+ * contiguous virtual memory range. Check if the host_addr is within that range.
  */
-int gasket_page_table_map(
-	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
-	uint num_pages)
+static int is_coherent(struct gasket_page_table *pg_tbl, ulong host_addr)
 {
-	int ret;
+	u64 min, max;
 
-	if (!num_pages)
+	/* whether the host address is within user virt range */
+	if (!pg_tbl->coherent_pages)
 		return 0;
 
-	mutex_lock(&pg_tbl->mutex);
-
-	if (gasket_addr_is_simple(pg_tbl, dev_addr)) {
-		ret = gasket_map_simple_pages(
-			pg_tbl, host_addr, dev_addr, num_pages);
-	} else {
-		ret = gasket_map_extended_pages(
-			pg_tbl, host_addr, dev_addr, num_pages);
-	}
-
-	mutex_unlock(&pg_tbl->mutex);
+	min = (u64)pg_tbl->coherent_pages[0].user_virt;
+	max = min + PAGE_SIZE * pg_tbl->num_coherent_pages;
 
-	dev_dbg(pg_tbl->device,
-		"%s done: ha %llx daddr %llx num %d, ret %d\n",
-		__func__, (unsigned long long)host_addr,
-		(unsigned long long)dev_addr, num_pages, ret);
-	return ret;
+	return min <= host_addr && host_addr < max;
 }
-EXPORT_SYMBOL(gasket_page_table_map);
 
 /*
- * See gasket_page_table.h for general description.
- *
- * gasket_page_table_unmap takes the page table lock and calls either
- * gasket_unmap_simple_pages() or gasket_unmap_extended_pages() to
- * actually unmap the pages from device space.
+ * Get and map last level page table buffers.
  *
- * The page table mutex is held for the entire operation.
+ * slots is the location(s) to write device-mapped page address. If this is a
+ * simple mapping, these will be address translation registers. If this is
+ * an extended mapping, these will be within a second-level page table
+ * allocated by the host and so must have their __iomem attribute casted away.
  */
-void gasket_page_table_unmap(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+static int gasket_perform_mapping(
+	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *ptes,
+	u64 __iomem *slots, ulong host_addr, uint num_pages,
+	int is_simple_mapping)
 {
-	if (!num_pages)
-		return;
+	int ret;
+	ulong offset;
+	struct page *page;
+	dma_addr_t dma_addr;
+	ulong page_addr;
+	int i;
 
-	mutex_lock(&pg_tbl->mutex);
-	gasket_page_table_unmap_nolock(pg_tbl, dev_addr, num_pages);
-	mutex_unlock(&pg_tbl->mutex);
-}
-EXPORT_SYMBOL(gasket_page_table_unmap);
+	for (i = 0; i < num_pages; i++) {
+		page_addr = host_addr + i * PAGE_SIZE;
+		offset = page_addr & (PAGE_SIZE - 1);
+		dev_dbg(pg_tbl->device, "%s i %d\n", __func__, i);
+		if (is_coherent(pg_tbl, host_addr)) {
+			u64 off =
+				(u64)host_addr -
+				(u64)pg_tbl->coherent_pages[0].user_virt;
+			ptes[i].page = NULL;
+			ptes[i].offset = offset;
+			ptes[i].dma_addr = pg_tbl->coherent_pages[0].paddr +
+					   off + i * PAGE_SIZE;
+		} else {
+			ret = get_user_pages_fast(
+				page_addr - offset, 1, 1, &page);
 
-static void gasket_page_table_unmap_all_nolock(struct gasket_page_table *pg_tbl)
-{
-	gasket_unmap_simple_pages(
-		pg_tbl, gasket_components_to_dev_address(pg_tbl, 1, 0, 0),
-		pg_tbl->num_simple_entries);
-	gasket_unmap_extended_pages(
-		pg_tbl, gasket_components_to_dev_address(pg_tbl, 0, 0, 0),
-		pg_tbl->num_extended_entries * GASKET_PAGES_PER_SUBTABLE);
-}
+			if (ret <= 0) {
+				dev_err(pg_tbl->device,
+					"get user pages failed for addr=0x%lx, "
+					"offset=0x%lx [ret=%d]\n",
+					page_addr, offset, ret);
+				return ret ? ret : -ENOMEM;
+			}
+			++pg_tbl->num_active_pages;
 
-/* See gasket_page_table.h for description. */
-void gasket_page_table_unmap_all(struct gasket_page_table *pg_tbl)
-{
-	mutex_lock(&pg_tbl->mutex);
-	gasket_page_table_unmap_all_nolock(pg_tbl);
-	mutex_unlock(&pg_tbl->mutex);
-}
-EXPORT_SYMBOL(gasket_page_table_unmap_all);
+			ptes[i].page = page;
+			ptes[i].offset = offset;
 
-/* See gasket_page_table.h for description. */
-void gasket_page_table_reset(struct gasket_page_table *pg_tbl)
-{
-	mutex_lock(&pg_tbl->mutex);
-	gasket_page_table_unmap_all_nolock(pg_tbl);
-	writeq(pg_tbl->config.total_entries, pg_tbl->extended_offset_reg);
-	mutex_unlock(&pg_tbl->mutex);
-}
+			/* Map the page into DMA space. */
+			ptes[i].dma_addr =
+				dma_map_page(pg_tbl->device, page, 0, PAGE_SIZE,
+					     DMA_BIDIRECTIONAL);
+			dev_dbg(pg_tbl->device,
+				"%s i %d pte %p pfn %p -> mapped %llx\n",
+				__func__, i, &ptes[i],
+				(void *)page_to_pfn(page),
+				(unsigned long long)ptes[i].dma_addr);
 
-/* See gasket_page_table.h for description. */
-void gasket_page_table_garbage_collect(struct gasket_page_table *pg_tbl)
-{
-	mutex_lock(&pg_tbl->mutex);
-	gasket_page_table_garbage_collect_nolock(pg_tbl);
-	mutex_unlock(&pg_tbl->mutex);
-}
+			if (ptes[i].dma_addr == -1) {
+				dev_dbg(pg_tbl->device,
+					"%s i %d -> fail to map page %llx "
+					"[pfn %p ohys %p]\n",
+					__func__, i,
+					(unsigned long long)ptes[i].dma_addr,
+					(void *)page_to_pfn(page),
+					(void *)page_to_phys(page));
+				return -1;
+			}
+			/* Wait until the page is mapped. */
+			mb();
+		}
 
-/* See gasket_page_table.h for description. */
-int gasket_page_table_lookup_page(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, struct page **ppage,
-	ulong *poffset)
-{
-	uint page_num;
-	struct gasket_page_table_entry *pte;
-
-	mutex_lock(&pg_tbl->mutex);
-	if (gasket_addr_is_simple(pg_tbl, dev_addr)) {
-		page_num = gasket_simple_page_idx(pg_tbl, dev_addr);
-		if (page_num >= pg_tbl->num_simple_entries)
-			goto fail;
-
-		pte = pg_tbl->entries + page_num;
-		if (pte->status != PTE_INUSE)
-			goto fail;
-	} else {
-		/* Find the level 0 entry, */
-		page_num = gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
-		if (page_num >= pg_tbl->num_extended_entries)
-			goto fail;
-
-		pte = pg_tbl->entries + pg_tbl->num_simple_entries + page_num;
-		if (pte->status != PTE_INUSE)
-			goto fail;
+		/* Make the DMA-space address available to the device. */
+		dma_addr = (ptes[i].dma_addr + offset) | GASKET_VALID_SLOT_FLAG;
 
-		/* and its contained level 1 entry. */
-		page_num = gasket_extended_lvl1_page_idx(pg_tbl, dev_addr);
-		pte = pte->sublevel + page_num;
-		if (pte->status != PTE_INUSE)
-			goto fail;
+		if (is_simple_mapping) {
+			writeq(dma_addr, &slots[i]);
+		} else {
+			((u64 __force *)slots)[i] = dma_addr;
+			/* Extended page table vectors are in DRAM,
+			 * and so need to be synced each time they are updated.
+			 */
+			dma_map_single(pg_tbl->device,
+				       (void *)&((u64 __force *)slots)[i],
+				       sizeof(u64), DMA_TO_DEVICE);
+		}
+		ptes[i].status = PTE_INUSE;
 	}
-
-	*ppage = pte->page;
-	*poffset = pte->offset;
-	mutex_unlock(&pg_tbl->mutex);
 	return 0;
-
-fail:
-	*ppage = NULL;
-	*poffset = 0;
-	mutex_unlock(&pg_tbl->mutex);
-	return -1;
-}
-
-/* See gasket_page_table.h for description. */
-bool gasket_page_table_are_addrs_bad(
-	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
-	ulong bytes)
-{
-	if (host_addr & (PAGE_SIZE - 1)) {
-		dev_err(pg_tbl->device,
-			"host mapping address 0x%lx must be page aligned\n",
-			host_addr);
-		return true;
-	}
-
-	return gasket_page_table_is_dev_addr_bad(pg_tbl, dev_addr, bytes);
 }
-EXPORT_SYMBOL(gasket_page_table_are_addrs_bad);
 
-/* See gasket_page_table.h for description. */
-bool gasket_page_table_is_dev_addr_bad(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, ulong bytes)
+/*
+ * Return the index of the page for the address in the simple table.
+ * Does not perform validity checking.
+ */
+static int gasket_simple_page_idx(
+	struct gasket_page_table *pg_tbl, ulong dev_addr)
 {
-	uint num_pages = bytes / PAGE_SIZE;
-
-	if (bytes & (PAGE_SIZE - 1)) {
-		dev_err(pg_tbl->device,
-			"mapping size 0x%lX must be page aligned\n", bytes);
-		return true;
-	}
-
-	if (num_pages == 0) {
-		dev_err(pg_tbl->device,
-			"requested mapping is less than one page: %lu / %lu\n",
-			bytes, PAGE_SIZE);
-		return true;
-	}
-
-	if (gasket_addr_is_simple(pg_tbl, dev_addr))
-		return gasket_is_simple_dev_addr_bad(
-			pg_tbl, dev_addr, num_pages);
-	return gasket_is_extended_dev_addr_bad(pg_tbl, dev_addr, num_pages);
+	return (dev_addr >> GASKET_SIMPLE_PAGE_SHIFT) &
+		(pg_tbl->config.total_entries - 1);
 }
-EXPORT_SYMBOL(gasket_page_table_is_dev_addr_bad);
 
-/* See gasket_page_table.h for description. */
-uint gasket_page_table_max_size(struct gasket_page_table *page_table)
+/*
+ * Return the level 0 page index for the given address.
+ * Does not perform validity checking.
+ */
+static ulong gasket_extended_lvl0_page_idx(
+	struct gasket_page_table *pg_tbl, ulong dev_addr)
 {
-	if (!page_table)
-		return 0;
-	return page_table->config.total_entries;
+	return (dev_addr >> GASKET_EXTENDED_LVL0_SHIFT) &
+	       ((1 << GASKET_EXTENDED_LVL0_WIDTH) - 1);
 }
-EXPORT_SYMBOL(gasket_page_table_max_size);
 
-/* See gasket_page_table.h for description. */
-uint gasket_page_table_num_entries(struct gasket_page_table *pg_tbl)
+/*
+ * Return the level 1 page index for the given address.
+ * Does not perform validity checking.
+ */
+static ulong gasket_extended_lvl1_page_idx(
+	struct gasket_page_table *pg_tbl, ulong dev_addr)
 {
-	if (!pg_tbl)
-		return 0;
-	return pg_tbl->num_simple_entries + pg_tbl->num_extended_entries;
+	return (dev_addr >> GASKET_EXTENDED_LVL1_SHIFT) &
+	       (GASKET_PAGES_PER_SUBTABLE - 1);
 }
-EXPORT_SYMBOL(gasket_page_table_num_entries);
 
-/* See gasket_page_table.h for description. */
-uint gasket_page_table_num_simple_entries(struct gasket_page_table *pg_tbl)
+/*
+ * Allocate page table entries in a simple table.
+ * The page table mutex must be held by the caller.
+ */
+static int gasket_alloc_simple_entries(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
 {
-	if (!pg_tbl)
-		return 0;
-	return pg_tbl->num_simple_entries;
-}
-EXPORT_SYMBOL(gasket_page_table_num_simple_entries);
+	if (!gasket_is_pte_range_free(
+		    pg_tbl->entries + gasket_simple_page_idx(pg_tbl, dev_addr),
+		    num_pages))
+		return -EBUSY;
 
-/* See gasket_page_table.h for description. */
-uint gasket_page_table_num_active_pages(struct gasket_page_table *pg_tbl)
-{
-	if (!pg_tbl)
-		return 0;
-	return pg_tbl->num_active_pages;
+	return 0;
 }
-EXPORT_SYMBOL(gasket_page_table_num_active_pages);
 
-/* See gasket_page_table.h */
-int gasket_page_table_system_status(struct gasket_page_table *page_table)
+/* Safely return a page to the OS. */
+static bool gasket_release_page(struct page *page)
 {
-	if (!page_table)
-		return GASKET_STATUS_LAMED;
+	if (!page)
+		return false;
 
-	if (gasket_page_table_num_entries(page_table) == 0) {
-		dev_dbg(page_table->device, "Page table size is 0\n");
-		return GASKET_STATUS_LAMED;
-	}
+	if (!PageReserved(page))
+		SetPageDirty(page);
+	put_page(page);
 
-	return GASKET_STATUS_ALIVE;
+	return true;
 }
 
 /*
- * Allocate and map pages to simple addresses.
- * If there is an error, no pages are mapped.
+ * Unmap and release mapped pages.
+ * The page table mutex must be held by the caller.
  */
-static int gasket_map_simple_pages(
-	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
-	uint num_pages)
+static void gasket_perform_unmapping(
+	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *ptes,
+	u64 __iomem *slots, uint num_pages, int is_simple_mapping)
 {
-	int ret;
-	uint slot_idx = gasket_simple_page_idx(pg_tbl, dev_addr);
+	int i;
+	/*
+	 * For each page table entry and corresponding entry in the device's
+	 * address translation table:
+	 */
+	for (i = 0; i < num_pages; i++) {
+		/* release the address from the device, */
+		if (is_simple_mapping || ptes[i].status == PTE_INUSE)
+			writeq(0, &slots[i]);
+		else
+			((u64 __force *)slots)[i] = 0;
+		/* Force sync around the address release. */
+		mb();
 
-	ret = gasket_alloc_simple_entries(pg_tbl, dev_addr, num_pages);
-	if (ret) {
-		dev_err(pg_tbl->device,
-			"page table slots %u (@ 0x%lx) to %u are not available\n",
-			slot_idx, dev_addr, slot_idx + num_pages - 1);
-		return ret;
+		/* release the address from the driver, */
+		if (ptes[i].status == PTE_INUSE) {
+			if (ptes[i].dma_addr) {
+				dma_unmap_page(pg_tbl->device, ptes[i].dma_addr,
+					       PAGE_SIZE, DMA_FROM_DEVICE);
+			}
+			if (gasket_release_page(ptes[i].page))
+				--pg_tbl->num_active_pages;
+		}
+		ptes[i].status = PTE_FREE;
+
+		/* and clear the PTE. */
+		memset(&ptes[i], 0, sizeof(struct gasket_page_table_entry));
 	}
+}
 
-	ret = gasket_perform_mapping(
-		pg_tbl, pg_tbl->entries + slot_idx,
-		pg_tbl->base_slot + slot_idx, host_addr, num_pages, 1);
+/*
+ * Unmap and release pages mapped to simple addresses.
+ * The page table mutex must be held by the caller.
+ */
+static void gasket_unmap_simple_pages(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+{
+	uint slot = gasket_simple_page_idx(pg_tbl, dev_addr);
 
-	if (ret) {
-		gasket_page_table_unmap_nolock(pg_tbl, dev_addr, num_pages);
-		dev_err(pg_tbl->device, "gasket_perform_mapping %d\n", ret);
-	}
-	return ret;
+	gasket_perform_unmapping(pg_tbl, pg_tbl->entries + slot,
+				 pg_tbl->base_slot + slot, num_pages, 1);
 }
 
 /*
- * gasket_map_extended_pages - Get and map buffers to extended addresses.
- * If there is an error, no pages are mapped.
+ * Unmap and release buffers to extended addresses.
+ * The page table mutex must be held by the caller.
  */
-static int gasket_map_extended_pages(
-	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
-	uint num_pages)
+static void gasket_unmap_extended_pages(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
 {
-	int ret;
-	ulong dev_addr_end;
 	uint slot_idx, remain, len;
 	struct gasket_page_table_entry *pte;
 	u64 __iomem *slot_base;
 
-	ret = gasket_alloc_extended_entries(pg_tbl, dev_addr, num_pages);
-	if (ret) {
-		dev_addr_end = dev_addr + (num_pages / PAGE_SIZE) - 1;
-		dev_err(pg_tbl->device,
-			"page table slots (%lu,%lu) (@ 0x%lx) to (%lu,%lu) are "
-			"not available\n",
-			gasket_extended_lvl0_page_idx(pg_tbl, dev_addr),
-			dev_addr,
-			gasket_extended_lvl1_page_idx(pg_tbl, dev_addr),
-			gasket_extended_lvl0_page_idx(pg_tbl, dev_addr_end),
-			gasket_extended_lvl1_page_idx(pg_tbl, dev_addr_end));
-		return ret;
-	}
-
 	remain = num_pages;
 	slot_idx = gasket_extended_lvl1_page_idx(pg_tbl, dev_addr);
 	pte = pg_tbl->entries + pg_tbl->num_simple_entries +
 	      gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
 
 	while (remain > 0) {
+		/* TODO: Add check to ensure pte remains valid? */
 		len = min(remain, GASKET_PAGES_PER_SUBTABLE - slot_idx);
 
-		slot_base =
-			(u64 __iomem *)(page_address(pte->page) + pte->offset);
-		ret = gasket_perform_mapping(
-			pg_tbl, pte->sublevel + slot_idx, slot_base + slot_idx,
-			host_addr, len, 0);
-		if (ret) {
-			gasket_page_table_unmap_nolock(
-				pg_tbl, dev_addr, num_pages);
-			return ret;
+		if (pte->status == PTE_INUSE) {
+			slot_base = (u64 __iomem *)(page_address(pte->page) +
+						    pte->offset);
+			gasket_perform_unmapping(
+				pg_tbl, pte->sublevel + slot_idx,
+				slot_base + slot_idx, len, 0);
 		}
 
 		remain -= len;
 		slot_idx = 0;
 		pte++;
-		host_addr += len * PAGE_SIZE;
 	}
-
-	return 0;
 }
 
-/*
- * Get and map last level page table buffers.
- *
- * slots is the location(s) to write device-mapped page address. If this is a
- * simple mapping, these will be address translation registers. If this is
- * an extended mapping, these will be within a second-level page table
- * allocated by the host and so must have their __iomem attribute casted away.
- */
-static int gasket_perform_mapping(
-	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *ptes,
-	u64 __iomem *slots, ulong host_addr, uint num_pages,
-	int is_simple_mapping)
+/* Evaluates to nonzero if the specified virtual address is simple. */
+static inline bool gasket_addr_is_simple(
+	struct gasket_page_table *pg_tbl, ulong addr)
 {
-	int ret;
-	ulong offset;
-	struct page *page;
-	dma_addr_t dma_addr;
-	ulong page_addr;
-	int i;
-
-	for (i = 0; i < num_pages; i++) {
-		page_addr = host_addr + i * PAGE_SIZE;
-		offset = page_addr & (PAGE_SIZE - 1);
-		dev_dbg(pg_tbl->device, "%s i %d\n", __func__, i);
-		if (is_coherent(pg_tbl, host_addr)) {
-			u64 off =
-				(u64)host_addr -
-				(u64)pg_tbl->coherent_pages[0].user_virt;
-			ptes[i].page = NULL;
-			ptes[i].offset = offset;
-			ptes[i].dma_addr = pg_tbl->coherent_pages[0].paddr +
-					   off + i * PAGE_SIZE;
-		} else {
-			ret = get_user_pages_fast(
-				page_addr - offset, 1, 1, &page);
-
-			if (ret <= 0) {
-				dev_err(pg_tbl->device,
-					"get user pages failed for addr=0x%lx, "
-					"offset=0x%lx [ret=%d]\n",
-					page_addr, offset, ret);
-				return ret ? ret : -ENOMEM;
-			}
-			++pg_tbl->num_active_pages;
-
-			ptes[i].page = page;
-			ptes[i].offset = offset;
-
-			/* Map the page into DMA space. */
-			ptes[i].dma_addr =
-				dma_map_page(pg_tbl->device, page, 0, PAGE_SIZE,
-					     DMA_BIDIRECTIONAL);
-			dev_dbg(pg_tbl->device,
-				"%s i %d pte %p pfn %p -> mapped %llx\n",
-				__func__, i, &ptes[i],
-				(void *)page_to_pfn(page),
-				(unsigned long long)ptes[i].dma_addr);
-
-			if (ptes[i].dma_addr == -1) {
-				dev_dbg(pg_tbl->device,
-					"%s i %d -> fail to map page %llx "
-					"[pfn %p ohys %p]\n",
-					__func__, i,
-					(unsigned long long)ptes[i].dma_addr,
-					(void *)page_to_pfn(page),
-					(void *)page_to_phys(page));
-				return -1;
-			}
-			/* Wait until the page is mapped. */
-			mb();
-		}
-
-		/* Make the DMA-space address available to the device. */
-		dma_addr = (ptes[i].dma_addr + offset) | GASKET_VALID_SLOT_FLAG;
-
-		if (is_simple_mapping) {
-			writeq(dma_addr, &slots[i]);
-		} else {
-			((u64 __force *)slots)[i] = dma_addr;
-			/* Extended page table vectors are in DRAM,
-			 * and so need to be synced each time they are updated.
-			 */
-			dma_map_single(pg_tbl->device,
-				       (void *)&((u64 __force *)slots)[i],
-				       sizeof(u64), DMA_TO_DEVICE);
-		}
-		ptes[i].status = PTE_INUSE;
-	}
-	return 0;
+	return !((addr) & (pg_tbl)->extended_flag);
 }
 
 /*
- * Allocate page table entries in a simple table.
- * The page table mutex must be held by the caller.
+ * Convert (simple, page, offset) into a device address.
+ * Examples:
+ * Simple page 0, offset 32:
+ *  Input (0, 0, 32), Output 0x20
+ * Simple page 1000, offset 511:
+ *  Input (0, 1000, 512), Output 0x3E81FF
+ * Extended page 0, offset 32:
+ *  Input (0, 0, 32), Output 0x8000000020
+ * Extended page 1000, offset 511:
+ *  Input (1, 1000, 512), Output 0x8003E81FF
  */
-static int gasket_alloc_simple_entries(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+static ulong gasket_components_to_dev_address(
+	struct gasket_page_table *pg_tbl, int is_simple, uint page_index,
+	uint offset)
 {
-	if (!gasket_is_pte_range_free(
-		    pg_tbl->entries + gasket_simple_page_idx(pg_tbl, dev_addr),
-		    num_pages))
-		return -EBUSY;
+	ulong lvl0_index, lvl1_index;
 
-	return 0;
+	if (is_simple) {
+		/* Return simple addresses directly. */
+		lvl0_index = page_index & (pg_tbl->config.total_entries - 1);
+		return (lvl0_index << GASKET_SIMPLE_PAGE_SHIFT) | offset;
+	}
+
+	/*
+	 * This could be compressed into fewer statements, but
+	 * A) the compiler should optimize it
+	 * B) this is not slow
+	 * C) this is an uncommon operation
+	 * D) this is actually readable this way.
+	 */
+	lvl0_index = page_index / GASKET_PAGES_PER_SUBTABLE;
+	lvl1_index = page_index & (GASKET_PAGES_PER_SUBTABLE - 1);
+	return (pg_tbl)->extended_flag |
+	       (lvl0_index << GASKET_EXTENDED_LVL0_SHIFT) |
+	       (lvl1_index << GASKET_EXTENDED_LVL1_SHIFT) | offset;
 }
 
 /*
- * Allocate slots in an extended page table.  Check to see if a range of page
- * table slots are available. If necessary, memory is allocated for second level
- * page tables.
- *
- * Note that memory for second level page tables is allocated as needed, but
- * that memory is only freed on the final close	of the device file, when the
- * page tables are repartitioned, or the the device is removed.  If there is an
- * error or if the full range of slots is not available, any memory
- * allocated for second level page tables remains allocated until final close,
- * repartition, or device removal.
+ * Validity checking for simple addresses.
  *
- * The page table mutex must be held by the caller.
+ * Verify that address translation commutes (from address to/from page + offset)
+ * and that the requested page range starts and ends within the set of
+ * currently-partitioned simple pages.
  */
-static int gasket_alloc_extended_entries(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_entries)
+static bool gasket_is_simple_dev_addr_bad(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
 {
-	int ret = 0;
-	uint remain, subtable_slot_idx, len;
-	struct gasket_page_table_entry *pte;
-	u64 __iomem *slot;
-
-	remain = num_entries;
-	subtable_slot_idx = gasket_extended_lvl1_page_idx(pg_tbl, dev_addr);
-	pte = pg_tbl->entries + pg_tbl->num_simple_entries +
-	      gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
-	slot = pg_tbl->base_slot + pg_tbl->num_simple_entries +
-	       gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
+	ulong page_offset = dev_addr & (PAGE_SIZE - 1);
+	ulong page_index =
+		(dev_addr / PAGE_SIZE) & (pg_tbl->config.total_entries - 1);
 
-	while (remain > 0) {
-		len = min(remain,
-			  GASKET_PAGES_PER_SUBTABLE - subtable_slot_idx);
+	if (gasket_components_to_dev_address(
+		pg_tbl, 1, page_index, page_offset) != dev_addr) {
+		dev_err(pg_tbl->device, "address is invalid, 0x%lX\n",
+			dev_addr);
+		return true;
+	}
 
-		if (pte->status == PTE_FREE) {
-			ret = gasket_alloc_extended_subtable(pg_tbl, pte, slot);
-			if (ret) {
-				dev_err(pg_tbl->device,
-					"no memory for extended addr subtable\n");
-				return ret;
-			}
-		} else {
-			if (!gasket_is_pte_range_free(
-				    pte->sublevel + subtable_slot_idx, len))
-				return -EBUSY;
-		}
+	if (page_index >= pg_tbl->num_simple_entries) {
+		dev_err(pg_tbl->device,
+			"starting slot at %lu is too large, max is < %u\n",
+			page_index, pg_tbl->num_simple_entries);
+		return true;
+	}
 
-		remain -= len;
-		subtable_slot_idx = 0;
-		pte++;
-		slot++;
+	if (page_index + num_pages > pg_tbl->num_simple_entries) {
+		dev_err(pg_tbl->device,
+			"ending slot at %lu is too large, max is <= %u\n",
+			page_index + num_pages, pg_tbl->num_simple_entries);
+		return true;
 	}
 
-	return 0;
+	return false;
 }
 
 /*
- * Allocate a second level page table.
- * The page table mutex must be held by the caller.
+ * Validity checking for extended addresses.
+ *
+ * Verify that address translation commutes (from address to/from page +
+ * offset) and that the requested page range starts and ends within the set of
+ * currently-partitioned extended pages.
  */
-static int gasket_alloc_extended_subtable(
-	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *pte,
-	u64 __iomem *slot)
+static bool gasket_is_extended_dev_addr_bad(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
 {
-	ulong page_addr, subtable_bytes;
-	dma_addr_t dma_addr;
+	/* Starting byte index of dev_addr into the first mapped page */
+	ulong page_offset = dev_addr & (PAGE_SIZE - 1);
+	ulong page_global_idx, page_lvl0_idx;
+	ulong num_lvl0_pages;
+	ulong addr;
 
-	/* XXX FIX ME XXX this is inefficient for non-4K page sizes */
+	/* check if the device address is out of bound */
+	addr = dev_addr & ~((pg_tbl)->extended_flag);
+	if (addr >> (GASKET_EXTENDED_LVL0_WIDTH + GASKET_EXTENDED_LVL0_SHIFT)) {
+		dev_err(pg_tbl->device, "device address out of bounds: 0x%lx\n",
+			dev_addr);
+		return true;
+	}
 
-	/* GFP_DMA flag must be passed to architectures for which
-	 * part of the memory range is not considered DMA'able.
-	 * This seems to be the case for Juno board with 4.5.0 Linaro kernel
+	/* Find the starting sub-page index in the space of all sub-pages. */
+	page_global_idx = (dev_addr / PAGE_SIZE) &
+		(pg_tbl->config.total_entries * GASKET_PAGES_PER_SUBTABLE - 1);
+
+	/* Find the starting level 0 index. */
+	page_lvl0_idx = gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
+
+	/* Get the count of affected level 0 pages. */
+	num_lvl0_pages = (num_pages + GASKET_PAGES_PER_SUBTABLE - 1) /
+		GASKET_PAGES_PER_SUBTABLE;
+
+	if (gasket_components_to_dev_address(
+		pg_tbl, 0, page_global_idx, page_offset) != dev_addr) {
+		dev_err(pg_tbl->device, "address is invalid: 0x%lx\n",
+			dev_addr);
+		return true;
+	}
+
+	if (page_lvl0_idx >= pg_tbl->num_extended_entries) {
+		dev_err(pg_tbl->device,
+			"starting level 0 slot at %lu is too large, max is < "
+			"%u\n", page_lvl0_idx, pg_tbl->num_extended_entries);
+		return true;
+	}
+
+	if (page_lvl0_idx + num_lvl0_pages > pg_tbl->num_extended_entries) {
+		dev_err(pg_tbl->device,
+			"ending level 0 slot at %lu is too large, max is <= %u\n",
+			page_lvl0_idx + num_lvl0_pages,
+			pg_tbl->num_extended_entries);
+		return true;
+	}
+
+	return false;
+}
+
+/*
+ * Non-locking entry to unmapping routines.
+ * The page table mutex must be held by the caller.
+ */
+static void gasket_page_table_unmap_nolock(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+{
+	if (!num_pages)
+		return;
+
+	if (gasket_addr_is_simple(pg_tbl, dev_addr))
+		gasket_unmap_simple_pages(pg_tbl, dev_addr, num_pages);
+	else
+		gasket_unmap_extended_pages(pg_tbl, dev_addr, num_pages);
+}
+
+/*
+ * Allocate and map pages to simple addresses.
+ * If there is an error, no pages are mapped.
+ */
+static int gasket_map_simple_pages(
+	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
+	uint num_pages)
+{
+	int ret;
+	uint slot_idx = gasket_simple_page_idx(pg_tbl, dev_addr);
+
+	ret = gasket_alloc_simple_entries(pg_tbl, dev_addr, num_pages);
+	if (ret) {
+		dev_err(pg_tbl->device,
+			"page table slots %u (@ 0x%lx) to %u are not available\n",
+			slot_idx, dev_addr, slot_idx + num_pages - 1);
+		return ret;
+	}
+
+	ret = gasket_perform_mapping(
+		pg_tbl, pg_tbl->entries + slot_idx,
+		pg_tbl->base_slot + slot_idx, host_addr, num_pages, 1);
+
+	if (ret) {
+		gasket_page_table_unmap_nolock(pg_tbl, dev_addr, num_pages);
+		dev_err(pg_tbl->device, "gasket_perform_mapping %d\n", ret);
+	}
+	return ret;
+}
+
+/*
+ * Allocate a second level page table.
+ * The page table mutex must be held by the caller.
+ */
+static int gasket_alloc_extended_subtable(
+	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *pte,
+	u64 __iomem *slot)
+{
+	ulong page_addr, subtable_bytes;
+	dma_addr_t dma_addr;
+
+	/* XXX FIX ME XXX this is inefficient for non-4K page sizes */
+
+	/* GFP_DMA flag must be passed to architectures for which
+	 * part of the memory range is not considered DMA'able.
+	 * This seems to be the case for Juno board with 4.5.0 Linaro kernel
 	 */
 	page_addr = get_zeroed_page(GFP_KERNEL | GFP_DMA);
 	if (!page_addr)
@@ -930,384 +911,338 @@ static int gasket_alloc_extended_subtable(
 }
 
 /*
- * Non-locking entry to unmapping routines.
+ * Allocate slots in an extended page table.  Check to see if a range of page
+ * table slots are available. If necessary, memory is allocated for second level
+ * page tables.
+ *
+ * Note that memory for second level page tables is allocated as needed, but
+ * that memory is only freed on the final close	of the device file, when the
+ * page tables are repartitioned, or the the device is removed.  If there is an
+ * error or if the full range of slots is not available, any memory
+ * allocated for second level page tables remains allocated until final close,
+ * repartition, or device removal.
+ *
  * The page table mutex must be held by the caller.
  */
-static void gasket_page_table_unmap_nolock(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+static int gasket_alloc_extended_entries(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_entries)
 {
-	if (!num_pages)
-		return;
+	int ret = 0;
+	uint remain, subtable_slot_idx, len;
+	struct gasket_page_table_entry *pte;
+	u64 __iomem *slot;
 
-	if (gasket_addr_is_simple(pg_tbl, dev_addr))
-		gasket_unmap_simple_pages(pg_tbl, dev_addr, num_pages);
-	else
-		gasket_unmap_extended_pages(pg_tbl, dev_addr, num_pages);
-}
+	remain = num_entries;
+	subtable_slot_idx = gasket_extended_lvl1_page_idx(pg_tbl, dev_addr);
+	pte = pg_tbl->entries + pg_tbl->num_simple_entries +
+	      gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
+	slot = pg_tbl->base_slot + pg_tbl->num_simple_entries +
+	       gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
 
-/*
- * Unmap and release pages mapped to simple addresses.
- * The page table mutex must be held by the caller.
- */
-static void gasket_unmap_simple_pages(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
-{
-	uint slot = gasket_simple_page_idx(pg_tbl, dev_addr);
+	while (remain > 0) {
+		len = min(remain,
+			  GASKET_PAGES_PER_SUBTABLE - subtable_slot_idx);
 
-	gasket_perform_unmapping(pg_tbl, pg_tbl->entries + slot,
-				 pg_tbl->base_slot + slot, num_pages, 1);
+		if (pte->status == PTE_FREE) {
+			ret = gasket_alloc_extended_subtable(pg_tbl, pte, slot);
+			if (ret) {
+				dev_err(pg_tbl->device,
+					"no memory for extended addr subtable\n");
+				return ret;
+			}
+		} else {
+			if (!gasket_is_pte_range_free(
+				    pte->sublevel + subtable_slot_idx, len))
+				return -EBUSY;
+		}
+
+		remain -= len;
+		subtable_slot_idx = 0;
+		pte++;
+		slot++;
+	}
+
+	return 0;
 }
 
 /*
- * Unmap and release buffers to extended addresses.
- * The page table mutex must be held by the caller.
+ * gasket_map_extended_pages - Get and map buffers to extended addresses.
+ * If there is an error, no pages are mapped.
  */
-static void gasket_unmap_extended_pages(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+static int gasket_map_extended_pages(
+	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
+	uint num_pages)
 {
+	int ret;
+	ulong dev_addr_end;
 	uint slot_idx, remain, len;
 	struct gasket_page_table_entry *pte;
 	u64 __iomem *slot_base;
 
+	ret = gasket_alloc_extended_entries(pg_tbl, dev_addr, num_pages);
+	if (ret) {
+		dev_addr_end = dev_addr + (num_pages / PAGE_SIZE) - 1;
+		dev_err(pg_tbl->device,
+			"page table slots (%lu,%lu) (@ 0x%lx) to (%lu,%lu) are "
+			"not available\n",
+			gasket_extended_lvl0_page_idx(pg_tbl, dev_addr),
+			dev_addr,
+			gasket_extended_lvl1_page_idx(pg_tbl, dev_addr),
+			gasket_extended_lvl0_page_idx(pg_tbl, dev_addr_end),
+			gasket_extended_lvl1_page_idx(pg_tbl, dev_addr_end));
+		return ret;
+	}
+
 	remain = num_pages;
 	slot_idx = gasket_extended_lvl1_page_idx(pg_tbl, dev_addr);
 	pte = pg_tbl->entries + pg_tbl->num_simple_entries +
 	      gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
 
 	while (remain > 0) {
-		/* TODO: Add check to ensure pte remains valid? */
 		len = min(remain, GASKET_PAGES_PER_SUBTABLE - slot_idx);
 
-		if (pte->status == PTE_INUSE) {
-			slot_base = (u64 __iomem *)(page_address(pte->page) +
-						    pte->offset);
-			gasket_perform_unmapping(
-				pg_tbl, pte->sublevel + slot_idx,
-				slot_base + slot_idx, len, 0);
+		slot_base =
+			(u64 __iomem *)(page_address(pte->page) + pte->offset);
+		ret = gasket_perform_mapping(
+			pg_tbl, pte->sublevel + slot_idx, slot_base + slot_idx,
+			host_addr, len, 0);
+		if (ret) {
+			gasket_page_table_unmap_nolock(
+				pg_tbl, dev_addr, num_pages);
+			return ret;
 		}
 
 		remain -= len;
 		slot_idx = 0;
 		pte++;
+		host_addr += len * PAGE_SIZE;
 	}
+
+	return 0;
 }
 
 /*
- * Unmap and release mapped pages.
- * The page table mutex must be held by the caller.
+ * See gasket_page_table.h for general description.
+ *
+ * gasket_page_table_map calls either gasket_map_simple_pages() or
+ * gasket_map_extended_pages() to actually perform the mapping.
+ *
+ * The page table mutex is held for the entire operation.
  */
-static void gasket_perform_unmapping(
-	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *ptes,
-	u64 __iomem *slots, uint num_pages, int is_simple_mapping)
+int gasket_page_table_map(
+	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
+	uint num_pages)
 {
-	int i;
-	/*
-	 * For each page table entry and corresponding entry in the device's
-	 * address translation table:
-	 */
-	for (i = 0; i < num_pages; i++) {
-		/* release the address from the device, */
-		if (is_simple_mapping || ptes[i].status == PTE_INUSE)
-			writeq(0, &slots[i]);
-		else
-			((u64 __force *)slots)[i] = 0;
-		/* Force sync around the address release. */
-		mb();
+	int ret;
 
-		/* release the address from the driver, */
-		if (ptes[i].status == PTE_INUSE) {
-			if (ptes[i].dma_addr) {
-				dma_unmap_page(pg_tbl->device, ptes[i].dma_addr,
-					       PAGE_SIZE, DMA_FROM_DEVICE);
-			}
-			if (gasket_release_page(ptes[i].page))
-				--pg_tbl->num_active_pages;
-		}
-		ptes[i].status = PTE_FREE;
+	if (!num_pages)
+		return 0;
 
-		/* and clear the PTE. */
-		memset(&ptes[i], 0, sizeof(struct gasket_page_table_entry));
-	}
-}
+	mutex_lock(&pg_tbl->mutex);
 
-/*
- * Free a second level page [sub]table.
- * The page table mutex must be held before this call.
- */
-static void gasket_free_extended_subtable(
-	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *pte,
-	u64 __iomem *slot)
-{
-	/* Release the page table from the driver */
-	pte->status = PTE_FREE;
-
-	/* Release the page table from the device */
-	writeq(0, slot);
-	/* Force sync around the address release. */
-	mb();
+	if (gasket_addr_is_simple(pg_tbl, dev_addr)) {
+		ret = gasket_map_simple_pages(
+			pg_tbl, host_addr, dev_addr, num_pages);
+	} else {
+		ret = gasket_map_extended_pages(
+			pg_tbl, host_addr, dev_addr, num_pages);
+	}
 
-	if (pte->dma_addr)
-		dma_unmap_page(pg_tbl->device, pte->dma_addr, PAGE_SIZE,
-			       DMA_BIDIRECTIONAL);
+	mutex_unlock(&pg_tbl->mutex);
 
-	vfree(pte->sublevel);
+	dev_dbg(pg_tbl->device,
+		"%s done: ha %llx daddr %llx num %d, ret %d\n",
+		__func__, (unsigned long long)host_addr,
+		(unsigned long long)dev_addr, num_pages, ret);
+	return ret;
+}
+EXPORT_SYMBOL(gasket_page_table_map);
 
-	if (pte->page)
-		free_page((ulong)page_address(pte->page));
+/*
+ * See gasket_page_table.h for general description.
+ *
+ * gasket_page_table_unmap takes the page table lock and calls either
+ * gasket_unmap_simple_pages() or gasket_unmap_extended_pages() to
+ * actually unmap the pages from device space.
+ *
+ * The page table mutex is held for the entire operation.
+ */
+void gasket_page_table_unmap(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+{
+	if (!num_pages)
+		return;
 
-	memset(pte, 0, sizeof(struct gasket_page_table_entry));
+	mutex_lock(&pg_tbl->mutex);
+	gasket_page_table_unmap_nolock(pg_tbl, dev_addr, num_pages);
+	mutex_unlock(&pg_tbl->mutex);
 }
+EXPORT_SYMBOL(gasket_page_table_unmap);
 
-/* Safely return a page to the OS. */
-static bool gasket_release_page(struct page *page)
+static void gasket_page_table_unmap_all_nolock(struct gasket_page_table *pg_tbl)
 {
-	if (!page)
-		return false;
-
-	if (!PageReserved(page))
-		SetPageDirty(page);
-	put_page(page);
+	gasket_unmap_simple_pages(
+		pg_tbl, gasket_components_to_dev_address(pg_tbl, 1, 0, 0),
+		pg_tbl->num_simple_entries);
+	gasket_unmap_extended_pages(
+		pg_tbl, gasket_components_to_dev_address(pg_tbl, 0, 0, 0),
+		pg_tbl->num_extended_entries * GASKET_PAGES_PER_SUBTABLE);
+}
 
-	return true;
+/* See gasket_page_table.h for description. */
+void gasket_page_table_unmap_all(struct gasket_page_table *pg_tbl)
+{
+	mutex_lock(&pg_tbl->mutex);
+	gasket_page_table_unmap_all_nolock(pg_tbl);
+	mutex_unlock(&pg_tbl->mutex);
 }
+EXPORT_SYMBOL(gasket_page_table_unmap_all);
 
-/* Evaluates to nonzero if the specified virtual address is simple. */
-static inline bool gasket_addr_is_simple(
-	struct gasket_page_table *pg_tbl, ulong addr)
+/* See gasket_page_table.h for description. */
+void gasket_page_table_reset(struct gasket_page_table *pg_tbl)
 {
-	return !((addr) & (pg_tbl)->extended_flag);
+	mutex_lock(&pg_tbl->mutex);
+	gasket_page_table_unmap_all_nolock(pg_tbl);
+	writeq(pg_tbl->config.total_entries, pg_tbl->extended_offset_reg);
+	mutex_unlock(&pg_tbl->mutex);
 }
 
-/*
- * Validity checking for simple addresses.
- *
- * Verify that address translation commutes (from address to/from page + offset)
- * and that the requested page range starts and ends within the set of
- * currently-partitioned simple pages.
- */
-static bool gasket_is_simple_dev_addr_bad(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+/* See gasket_page_table.h for description. */
+int gasket_page_table_lookup_page(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, struct page **ppage,
+	ulong *poffset)
 {
-	ulong page_offset = dev_addr & (PAGE_SIZE - 1);
-	ulong page_index =
-		(dev_addr / PAGE_SIZE) & (pg_tbl->config.total_entries - 1);
+	uint page_num;
+	struct gasket_page_table_entry *pte;
 
-	if (gasket_components_to_dev_address(
-		pg_tbl, 1, page_index, page_offset) != dev_addr) {
-		dev_err(pg_tbl->device, "address is invalid, 0x%lX\n",
-			dev_addr);
-		return true;
-	}
+	mutex_lock(&pg_tbl->mutex);
+	if (gasket_addr_is_simple(pg_tbl, dev_addr)) {
+		page_num = gasket_simple_page_idx(pg_tbl, dev_addr);
+		if (page_num >= pg_tbl->num_simple_entries)
+			goto fail;
 
-	if (page_index >= pg_tbl->num_simple_entries) {
-		dev_err(pg_tbl->device,
-			"starting slot at %lu is too large, max is < %u\n",
-			page_index, pg_tbl->num_simple_entries);
-		return true;
-	}
+		pte = pg_tbl->entries + page_num;
+		if (pte->status != PTE_INUSE)
+			goto fail;
+	} else {
+		/* Find the level 0 entry, */
+		page_num = gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
+		if (page_num >= pg_tbl->num_extended_entries)
+			goto fail;
 
-	if (page_index + num_pages > pg_tbl->num_simple_entries) {
-		dev_err(pg_tbl->device,
-			"ending slot at %lu is too large, max is <= %u\n",
-			page_index + num_pages, pg_tbl->num_simple_entries);
-		return true;
+		pte = pg_tbl->entries + pg_tbl->num_simple_entries + page_num;
+		if (pte->status != PTE_INUSE)
+			goto fail;
+
+		/* and its contained level 1 entry. */
+		page_num = gasket_extended_lvl1_page_idx(pg_tbl, dev_addr);
+		pte = pte->sublevel + page_num;
+		if (pte->status != PTE_INUSE)
+			goto fail;
 	}
 
-	return false;
+	*ppage = pte->page;
+	*poffset = pte->offset;
+	mutex_unlock(&pg_tbl->mutex);
+	return 0;
+
+fail:
+	*ppage = NULL;
+	*poffset = 0;
+	mutex_unlock(&pg_tbl->mutex);
+	return -1;
 }
 
-/*
- * Validity checking for extended addresses.
- *
- * Verify that address translation commutes (from address to/from page +
- * offset) and that the requested page range starts and ends within the set of
- * currently-partitioned extended pages.
- */
-static bool gasket_is_extended_dev_addr_bad(
-	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+/* See gasket_page_table.h for description. */
+bool gasket_page_table_are_addrs_bad(
+	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
+	ulong bytes)
 {
-	/* Starting byte index of dev_addr into the first mapped page */
-	ulong page_offset = dev_addr & (PAGE_SIZE - 1);
-	ulong page_global_idx, page_lvl0_idx;
-	ulong num_lvl0_pages;
-	ulong addr;
-
-	/* check if the device address is out of bound */
-	addr = dev_addr & ~((pg_tbl)->extended_flag);
-	if (addr >> (GASKET_EXTENDED_LVL0_WIDTH + GASKET_EXTENDED_LVL0_SHIFT)) {
-		dev_err(pg_tbl->device, "device address out of bounds: 0x%lx\n",
-			dev_addr);
+	if (host_addr & (PAGE_SIZE - 1)) {
+		dev_err(pg_tbl->device,
+			"host mapping address 0x%lx must be page aligned\n",
+			host_addr);
 		return true;
 	}
 
-	/* Find the starting sub-page index in the space of all sub-pages. */
-	page_global_idx = (dev_addr / PAGE_SIZE) &
-		(pg_tbl->config.total_entries * GASKET_PAGES_PER_SUBTABLE - 1);
-
-	/* Find the starting level 0 index. */
-	page_lvl0_idx = gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
-
-	/* Get the count of affected level 0 pages. */
-	num_lvl0_pages = (num_pages + GASKET_PAGES_PER_SUBTABLE - 1) /
-		GASKET_PAGES_PER_SUBTABLE;
+	return gasket_page_table_is_dev_addr_bad(pg_tbl, dev_addr, bytes);
+}
+EXPORT_SYMBOL(gasket_page_table_are_addrs_bad);
 
-	if (gasket_components_to_dev_address(
-		pg_tbl, 0, page_global_idx, page_offset) != dev_addr) {
-		dev_err(pg_tbl->device, "address is invalid: 0x%lx\n",
-			dev_addr);
-		return true;
-	}
+/* See gasket_page_table.h for description. */
+bool gasket_page_table_is_dev_addr_bad(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, ulong bytes)
+{
+	uint num_pages = bytes / PAGE_SIZE;
 
-	if (page_lvl0_idx >= pg_tbl->num_extended_entries) {
+	if (bytes & (PAGE_SIZE - 1)) {
 		dev_err(pg_tbl->device,
-			"starting level 0 slot at %lu is too large, max is < "
-			"%u\n", page_lvl0_idx, pg_tbl->num_extended_entries);
+			"mapping size 0x%lX must be page aligned\n", bytes);
 		return true;
 	}
 
-	if (page_lvl0_idx + num_lvl0_pages > pg_tbl->num_extended_entries) {
+	if (num_pages == 0) {
 		dev_err(pg_tbl->device,
-			"ending level 0 slot at %lu is too large, max is <= %u\n",
-			page_lvl0_idx + num_lvl0_pages,
-			pg_tbl->num_extended_entries);
+			"requested mapping is less than one page: %lu / %lu\n",
+			bytes, PAGE_SIZE);
 		return true;
 	}
 
-	return false;
-}
-
-/*
- * Check if a range of PTEs is free.
- * The page table mutex must be held by the caller.
- */
-static bool gasket_is_pte_range_free(
-	struct gasket_page_table_entry *ptes, uint num_entries)
-{
-	int i;
-
-	for (i = 0; i < num_entries; i++) {
-		if (ptes[i].status != PTE_FREE)
-			return false;
-	}
-
-	return true;
-}
-
-/*
- * Actually perform collection.
- * The page table mutex must be held by the caller.
- */
-static void gasket_page_table_garbage_collect_nolock(
-	struct gasket_page_table *pg_tbl)
-{
-	struct gasket_page_table_entry *pte;
-	u64 __iomem *slot;
-
-	/* XXX FIX ME XXX -- more efficient to keep a usage count */
-	/* rather than scanning the second level page tables */
-
-	for (pte = pg_tbl->entries + pg_tbl->num_simple_entries,
-	     slot = pg_tbl->base_slot + pg_tbl->num_simple_entries;
-	     pte < pg_tbl->entries + pg_tbl->config.total_entries;
-	     pte++, slot++) {
-		if (pte->status == PTE_INUSE) {
-			if (gasket_is_pte_range_free(
-				    pte->sublevel, GASKET_PAGES_PER_SUBTABLE))
-				gasket_free_extended_subtable(
-					pg_tbl, pte, slot);
-		}
-	}
+	if (gasket_addr_is_simple(pg_tbl, dev_addr))
+		return gasket_is_simple_dev_addr_bad(
+			pg_tbl, dev_addr, num_pages);
+	return gasket_is_extended_dev_addr_bad(pg_tbl, dev_addr, num_pages);
 }
+EXPORT_SYMBOL(gasket_page_table_is_dev_addr_bad);
 
-/*
- * Convert (simple, page, offset) into a device address.
- * Examples:
- * Simple page 0, offset 32:
- *  Input (0, 0, 32), Output 0x20
- * Simple page 1000, offset 511:
- *  Input (0, 1000, 512), Output 0x3E81FF
- * Extended page 0, offset 32:
- *  Input (0, 0, 32), Output 0x8000000020
- * Extended page 1000, offset 511:
- *  Input (1, 1000, 512), Output 0x8003E81FF
- */
-static ulong gasket_components_to_dev_address(
-	struct gasket_page_table *pg_tbl, int is_simple, uint page_index,
-	uint offset)
+/* See gasket_page_table.h for description. */
+uint gasket_page_table_max_size(struct gasket_page_table *page_table)
 {
-	ulong lvl0_index, lvl1_index;
-
-	if (is_simple) {
-		/* Return simple addresses directly. */
-		lvl0_index = page_index & (pg_tbl->config.total_entries - 1);
-		return (lvl0_index << GASKET_SIMPLE_PAGE_SHIFT) | offset;
-	}
-
-	/*
-	 * This could be compressed into fewer statements, but
-	 * A) the compiler should optimize it
-	 * B) this is not slow
-	 * C) this is an uncommon operation
-	 * D) this is actually readable this way.
-	 */
-	lvl0_index = page_index / GASKET_PAGES_PER_SUBTABLE;
-	lvl1_index = page_index & (GASKET_PAGES_PER_SUBTABLE - 1);
-	return (pg_tbl)->extended_flag |
-	       (lvl0_index << GASKET_EXTENDED_LVL0_SHIFT) |
-	       (lvl1_index << GASKET_EXTENDED_LVL1_SHIFT) | offset;
+	if (!page_table)
+		return 0;
+	return page_table->config.total_entries;
 }
+EXPORT_SYMBOL(gasket_page_table_max_size);
 
-/*
- * Return the index of the page for the address in the simple table.
- * Does not perform validity checking.
- */
-static int gasket_simple_page_idx(
-	struct gasket_page_table *pg_tbl, ulong dev_addr)
+/* See gasket_page_table.h for description. */
+uint gasket_page_table_num_entries(struct gasket_page_table *pg_tbl)
 {
-	return (dev_addr >> GASKET_SIMPLE_PAGE_SHIFT) &
-		(pg_tbl->config.total_entries - 1);
+	if (!pg_tbl)
+		return 0;
+	return pg_tbl->num_simple_entries + pg_tbl->num_extended_entries;
 }
+EXPORT_SYMBOL(gasket_page_table_num_entries);
 
-/*
- * Return the level 0 page index for the given address.
- * Does not perform validity checking.
- */
-static ulong gasket_extended_lvl0_page_idx(
-	struct gasket_page_table *pg_tbl, ulong dev_addr)
+/* See gasket_page_table.h for description. */
+uint gasket_page_table_num_simple_entries(struct gasket_page_table *pg_tbl)
 {
-	return (dev_addr >> GASKET_EXTENDED_LVL0_SHIFT) &
-	       ((1 << GASKET_EXTENDED_LVL0_WIDTH) - 1);
+	if (!pg_tbl)
+		return 0;
+	return pg_tbl->num_simple_entries;
 }
+EXPORT_SYMBOL(gasket_page_table_num_simple_entries);
 
-/*
- * Return the level 1 page index for the given address.
- * Does not perform validity checking.
- */
-static ulong gasket_extended_lvl1_page_idx(
-	struct gasket_page_table *pg_tbl, ulong dev_addr)
+/* See gasket_page_table.h for description. */
+uint gasket_page_table_num_active_pages(struct gasket_page_table *pg_tbl)
 {
-	return (dev_addr >> GASKET_EXTENDED_LVL1_SHIFT) &
-	       (GASKET_PAGES_PER_SUBTABLE - 1);
+	if (!pg_tbl)
+		return 0;
+	return pg_tbl->num_active_pages;
 }
+EXPORT_SYMBOL(gasket_page_table_num_active_pages);
 
-/*
- * Return whether a host buffer was mapped as coherent memory.
- *
- * A Gasket page_table currently support one contiguous dma range, mapped to one
- * contiguous virtual memory range. Check if the host_addr is within that range.
- */
-static int is_coherent(struct gasket_page_table *pg_tbl, ulong host_addr)
+/* See gasket_page_table.h */
+int gasket_page_table_system_status(struct gasket_page_table *page_table)
 {
-	u64 min, max;
-
-	/* whether the host address is within user virt range */
-	if (!pg_tbl->coherent_pages)
-		return 0;
+	if (!page_table)
+		return GASKET_STATUS_LAMED;
 
-	min = (u64)pg_tbl->coherent_pages[0].user_virt;
-	max = min + PAGE_SIZE * pg_tbl->num_coherent_pages;
+	if (gasket_page_table_num_entries(page_table) == 0) {
+		dev_dbg(page_table->device, "Page table size is 0\n");
+		return GASKET_STATUS_LAMED;
+	}
 
-	return min <= host_addr && host_addr < max;
+	return GASKET_STATUS_ALIVE;
 }
 
 /* Record the host_addr to coherent dma memory mapping. */

commit 480884860158a0942aa4147c40c56dc9a1d985af
Author: Todd Poynor <toddpoynor@google.com>
Date:   Sun Jul 29 12:36:41 2018 -0700

    staging: gasket: page table: simplify comments for static functions
    
    Static functions don't need kernel doc formatting, can be simplified.
    Reformat comments that can be single-line.  Remove extraneous text.
    
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 6b946a155ee3..b42f6637b909 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -635,27 +635,9 @@ int gasket_page_table_system_status(struct gasket_page_table *page_table)
 	return GASKET_STATUS_ALIVE;
 }
 
-/* Internal functions */
-
-/* Mapping functions */
 /*
  * Allocate and map pages to simple addresses.
- * @pg_tbl: Gasket page table pointer.
- * @host_addr: Starting host virtual memory address of the pages.
- * @dev_addr: Starting device address of the pages.
- * @cnt: Count of the number of device pages to map.
- *
- * Description: gasket_map_simple_pages calls gasket_simple_alloc_pages() to
- *		allocate the page table slots, then calls
- *		gasket_perform_mapping() to actually do the work of mapping the
- *		pages into the the simple page table (device translation table
- *		registers).
- *
- *		The sd_mutex must be held when gasket_map_simple_pages() is
- *		called.
- *
- *		Returns 0 if successful or a non-zero error number otherwise.
- *		If there is an error, no pages are mapped.
+ * If there is an error, no pages are mapped.
  */
 static int gasket_map_simple_pages(
 	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
@@ -685,22 +667,7 @@ static int gasket_map_simple_pages(
 
 /*
  * gasket_map_extended_pages - Get and map buffers to extended addresses.
- * @pg_tbl: Gasket page table pointer.
- * @host_addr: Starting host virtual memory address of the pages.
- * @dev_addr: Starting device address of the pages.
- * @num_pages: The number of device pages to map.
- *
- * Description: gasket_map_extended_buffers calls
- *		gasket_alloc_extended_entries() to allocate the page table
- *		slots, then loops over the level 0 page table entries, and for
- *		each calls gasket_perform_mapping() to map the buffers into the
- *		level 1 page table for that level 0 entry.
- *
- *		The page table mutex must be held when
- *		gasket_map_extended_pages() is called.
- *
- *		Returns 0 if successful or a non-zero error number otherwise.
- *		If there is an error, no pages are mapped.
+ * If there is an error, no pages are mapped.
  */
 static int gasket_map_extended_pages(
 	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
@@ -756,32 +723,11 @@ static int gasket_map_extended_pages(
 
 /*
  * Get and map last level page table buffers.
- * @pg_tbl: Gasket page table pointer.
- * @ptes: Array of page table entries to describe this mapping, one per
- *        page to map.
- * @slots: Location(s) to write device-mapped page address. If this is a simple
- *	   mapping, these will be address translation registers. If this is
- *	   an extended mapping, these will be within a second-level page table
- *	   allocated by the host and so must have their __iomem attribute
- *	   casted away.
- * @host_addr: Starting [host] virtual memory address of the buffers.
- * @num_pages: The number of device pages to map.
- * @is_simple_mapping: 1 if this is a simple mapping, 0 otherwise.
- *
- * Description: gasket_perform_mapping calls get_user_pages() to get pages
- *		of user memory and pin them.  It then calls dma_map_page() to
- *		map them for DMA.  Finally, the mapped DMA addresses are written
- *		into the page table.
  *
- *		This function expects that the page table entries are
- *		already allocated.  The level argument determines how the
- *		final page table entries are written: either into PCIe memory
- *		mapped space for a level 0 page table or into kernel memory
- *		for a level 1 page table.
- *
- *		The page pointers are saved for later releasing the pages.
- *
- *		Returns 0 if successful or a non-zero error number otherwise.
+ * slots is the location(s) to write device-mapped page address. If this is a
+ * simple mapping, these will be address translation registers. If this is
+ * an extended mapping, these will be within a second-level page table
+ * allocated by the host and so must have their __iomem attribute casted away.
  */
 static int gasket_perform_mapping(
 	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *ptes,
@@ -866,21 +812,9 @@ static int gasket_perform_mapping(
 	return 0;
 }
 
-/**
+/*
  * Allocate page table entries in a simple table.
- * @pg_tbl: Gasket page table pointer.
- * @dev_addr: Starting device address for the (eventual) mappings.
- * @num_pages: Count of pages to be mapped.
- *
- * Description: gasket_alloc_simple_entries checks to see if a range of page
- *		table slots are available.  As long as the sd_mutex is
- *		held, the slots will be available.
- *
- *		The page table mutex must be held when
- *		gasket_alloc_simple entries() is called.
- *
- *		Returns 0 if successful, or non-zero if the requested device
- *		addresses are not available.
+ * The page table mutex must be held by the caller.
  */
 static int gasket_alloc_simple_entries(
 	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
@@ -893,29 +827,19 @@ static int gasket_alloc_simple_entries(
 	return 0;
 }
 
-/**
- * Allocate slots in an extended page table.
- * @pg_tbl: Gasket page table pointer.
- * @dev_addr: Starting device address for the (eventual) mappings.
- * @num_pages: Count of pages to be mapped.
- *
- * Description: gasket_alloc_extended_entries checks to see if a range of page
- *		table slots are available. If necessary, memory is allocated for
- *		second level page tables.
- *
- *		Note that memory for second level page tables is allocated
- *		as needed, but that memory is only freed on the final close
- *		of the device file, when the page tables are repartitioned,
- *		or the the device is removed.  If there is an error or if
- *		the full range of slots is not available, any memory
- *		allocated for second level page tables remains allocated
- *		until final close, repartition, or device removal.
+/*
+ * Allocate slots in an extended page table.  Check to see if a range of page
+ * table slots are available. If necessary, memory is allocated for second level
+ * page tables.
  *
- *		The page table mutex must be held when
- *		gasket_alloc_extended_entries() is called.
+ * Note that memory for second level page tables is allocated as needed, but
+ * that memory is only freed on the final close	of the device file, when the
+ * page tables are repartitioned, or the the device is removed.  If there is an
+ * error or if the full range of slots is not available, any memory
+ * allocated for second level page tables remains allocated until final close,
+ * repartition, or device removal.
  *
- *		Returns 0 if successful, or non-zero if the slots are
- *		not available.
+ * The page table mutex must be held by the caller.
  */
 static int gasket_alloc_extended_entries(
 	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_entries)
@@ -958,21 +882,9 @@ static int gasket_alloc_extended_entries(
 	return 0;
 }
 
-/**
+/*
  * Allocate a second level page table.
- * @pg_tbl: Gasket page table pointer.
- * @pte: Extended page table entry under/for which to allocate a second level.
- * @slot: [Device] slot corresponding to pte.
- *
- * Description: Allocate the memory for a second level page table (subtable) at
- *	        the given level 0 entry.  Then call dma_map_page() to map the
- *		second level page table for DMA.  Finally, write the
- *		mapped DMA address into the device page table.
- *
- *		The page table mutex must be held when
- *		gasket_alloc_extended_subtable() is called.
- *
- *		Returns 0 if successful, or a non-zero error otherwise.
+ * The page table mutex must be held by the caller.
  */
 static int gasket_alloc_extended_subtable(
 	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *pte,
@@ -1017,15 +929,9 @@ static int gasket_alloc_extended_subtable(
 	return 0;
 }
 
-/* Unmapping functions */
 /*
  * Non-locking entry to unmapping routines.
- * @pg_tbl: Gasket page table structure.
- * @dev_addr: Starting device address of the pages to unmap.
- * @num_pages: The number of device pages to unmap.
- *
- * Description: Version of gasket_unmap_pages that assumes the page table lock
- *              is held.
+ * The page table mutex must be held by the caller.
  */
 static void gasket_page_table_unmap_nolock(
 	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
@@ -1041,14 +947,7 @@ static void gasket_page_table_unmap_nolock(
 
 /*
  * Unmap and release pages mapped to simple addresses.
- * @pg_tbl: Gasket page table pointer.
- * @dev_addr: Starting device address of the buffers.
- * @num_pages: The number of device pages to unmap.
- *
- * Description: gasket_simple_unmap_pages calls gasket_perform_unmapping() to
- * unmap and release the buffers in the level 0 page table.
- *
- * The sd_mutex must be held when gasket_unmap_simple_pages() is called.
+ * The page table mutex must be held by the caller.
  */
 static void gasket_unmap_simple_pages(
 	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
@@ -1059,20 +958,9 @@ static void gasket_unmap_simple_pages(
 				 pg_tbl->base_slot + slot, num_pages, 1);
 }
 
-/**
+/*
  * Unmap and release buffers to extended addresses.
- * @pg_tbl: Gasket page table pointer.
- * @dev_addr: Starting device address of the pages to unmap.
- * @addr: Starting device address of the buffers.
- * @num_pages: The number of device pages to unmap.
- *
- * Description: gasket_extended_unmap_pages loops over the level 0 page table
- *		entries, and for each calls gasket_perform_unmapping() to unmap
- *		the buffers from the level 1 page [sub]table for that level 0
- *		entry.
- *
- *		The page table mutex must be held when
- *		gasket_unmap_extended_pages() is called.
+ * The page table mutex must be held by the caller.
  */
 static void gasket_unmap_extended_pages(
 	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
@@ -1106,28 +994,7 @@ static void gasket_unmap_extended_pages(
 
 /*
  * Unmap and release mapped pages.
- * @pg_tbl: Gasket page table pointer.
- * @ptes: Array of page table entries to describe the mapped range, one per
- *        page to unmap.
- * @slots: Device slots corresponding to the mappings described by "ptes".
- *         As with ptes, one element per page to unmap.
- *         If these are simple mappings, these will be address translation
- *         registers. If these are extended mappings, these will be witin a
- *         second-level page table allocated on the host, and so must have
- *	   their __iomem attribute casted away.
- * @num_pages: Number of pages to unmap.
- * @is_simple_mapping: 1 if this is a simple mapping, 0 otherwise.
- *
- * Description: gasket_perform_unmapping() loops through the metadata entries
- *		in a last level page table (simple table or extended subtable),
- *		and for each page:
- *		 - Unmaps the page from DMA space (dma_unmap_page),
- *		 - Returns the page to the OS (gasket_release_page),
- *		The entry in the page table is written to 0. The metadata
- *		type is set to PTE_FREE and the metadata is all reset
- *		to 0.
- *
- *		The page table mutex must be held when this function is called.
+ * The page table mutex must be held by the caller.
  */
 static void gasket_perform_unmapping(
 	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *ptes,
@@ -1165,17 +1032,6 @@ static void gasket_perform_unmapping(
 
 /*
  * Free a second level page [sub]table.
- * @pg_tbl: Gasket page table pointer.
- * @pte: Page table entry _pointing_to_ the subtable to free.
- * @slot: Device slot holding a pointer to the sublevel's contents.
- *
- * Description: Safely deallocates a second-level [sub]table by:
- *  - Marking the containing first-level PTE as free
- *  - Setting the corresponding [extended] device slot as NULL
- *  - Unmapping the PTE from DMA space.
- *  - Freeing the subtable's memory.
- *  - Deallocating the page and clearing out the PTE.
- *
  * The page table mutex must be held before this call.
  */
 static void gasket_free_extended_subtable(
@@ -1202,12 +1058,7 @@ static void gasket_free_extended_subtable(
 	memset(pte, 0, sizeof(struct gasket_page_table_entry));
 }
 
-/*
- * Safely return a page to the OS.
- * @page: The page to return to the OS.
- * Returns true if the page was released, false if it was
- * ignored.
- */
+/* Safely return a page to the OS. */
 static bool gasket_release_page(struct page *page)
 {
 	if (!page)
@@ -1229,13 +1080,10 @@ static inline bool gasket_addr_is_simple(
 
 /*
  * Validity checking for simple addresses.
- * @pg_tbl: Gasket page table pointer.
- * @dev_addr: The device address to which the pages will be mapped.
- * @num_pages: The number of pages in the range to consider.
  *
- * Description: This call verifies that address translation commutes (from
- * address to/from page + offset) and that the requested page range starts and
- * ends within the set of currently-partitioned simple pages.
+ * Verify that address translation commutes (from address to/from page + offset)
+ * and that the requested page range starts and ends within the set of
+ * currently-partitioned simple pages.
  */
 static bool gasket_is_simple_dev_addr_bad(
 	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
@@ -1269,13 +1117,11 @@ static bool gasket_is_simple_dev_addr_bad(
 }
 
 /*
- * Verifies that address translation commutes (from address to/from page +
- * offset) and that the requested page range starts and ends within the set of
- * currently-partitioned simple pages.
+ * Validity checking for extended addresses.
  *
- * @pg_tbl: Gasket page table pointer.
- * @dev_addr: The device address to which the pages will be mapped.
- * @num_pages: The number of second-level/sub pages in the range to consider.
+ * Verify that address translation commutes (from address to/from page +
+ * offset) and that the requested page range starts and ends within the set of
+ * currently-partitioned extended pages.
  */
 static bool gasket_is_extended_dev_addr_bad(
 	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
@@ -1331,15 +1177,8 @@ static bool gasket_is_extended_dev_addr_bad(
 }
 
 /*
- * Checks if a range of PTEs is free.
- * @ptes: The set of PTEs to check.
- * @num_entries: The number of PTEs to check.
- *
- * Description: Iterates over the input PTEs to determine if all have been
- * marked as FREE or if any are INUSE. In the former case, 1/true is returned.
- * Otherwise, 0/false is returned.
- *
- * The page table mutex must be held before this call.
+ * Check if a range of PTEs is free.
+ * The page table mutex must be held by the caller.
  */
 static bool gasket_is_pte_range_free(
 	struct gasket_page_table_entry *ptes, uint num_entries)
@@ -1356,10 +1195,7 @@ static bool gasket_is_pte_range_free(
 
 /*
  * Actually perform collection.
- * @pg_tbl: Gasket page table structure.
- *
- * Description: Version of gasket_page_table_garbage_collect that assumes the
- *		page table lock is held.
+ * The page table mutex must be held by the caller.
  */
 static void gasket_page_table_garbage_collect_nolock(
 	struct gasket_page_table *pg_tbl)
@@ -1384,14 +1220,7 @@ static void gasket_page_table_garbage_collect_nolock(
 }
 
 /*
- * Converts components to a device address.
- * @pg_tbl: Gasket page table structure.
- * @is_simple: nonzero if this should be a simple entry, zero otherwise.
- * @page_index: The page index into the respective table.
- * @offset: The offset within the requested page.
- *
- * Simple utility function to convert (simple, page, offset) into a device
- * address.
+ * Convert (simple, page, offset) into a device address.
  * Examples:
  * Simple page 0, offset 32:
  *  Input (0, 0, 32), Output 0x20
@@ -1429,14 +1258,7 @@ static ulong gasket_components_to_dev_address(
 }
 
 /*
- * Gets the index of the address' page in the simple table.
- * @pg_tbl: Gasket page table structure.
- * @dev_addr: The address whose page index to retrieve.
- *
- * Description: Treats the input address as a simple address and determines the
- * index of its underlying page in the simple page table (i.e., device address
- * translation registers.
- *
+ * Return the index of the page for the address in the simple table.
  * Does not perform validity checking.
  */
 static int gasket_simple_page_idx(
@@ -1447,14 +1269,7 @@ static int gasket_simple_page_idx(
 }
 
 /*
- * Gets the level 0 page index for the given address.
- * @pg_tbl: Gasket page table structure.
- * @dev_addr: The address whose page index to retrieve.
- *
- * Description: Treats the input address as an extended address and determines
- * the index of its underlying page in the first-level extended page table
- * (i.e., device extended address translation registers).
- *
+ * Return the level 0 page index for the given address.
  * Does not perform validity checking.
  */
 static ulong gasket_extended_lvl0_page_idx(
@@ -1465,14 +1280,7 @@ static ulong gasket_extended_lvl0_page_idx(
 }
 
 /*
- * Gets the level 1 page index for the given address.
- * @pg_tbl: Gasket page table structure.
- * @dev_addr: The address whose page index to retrieve.
- *
- * Description: Treats the input address as an extended address and determines
- * the index of its underlying page in the second-level extended page table
- * (i.e., host memory pointed to by a first-level page table entry).
- *
+ * Return the level 1 page index for the given address.
  * Does not perform validity checking.
  */
 static ulong gasket_extended_lvl1_page_idx(
@@ -1483,13 +1291,10 @@ static ulong gasket_extended_lvl1_page_idx(
 }
 
 /*
- * Determines whether a host buffer was mapped as coherent memory.
- * @pg_tbl: gasket_page_table structure tracking the host buffer mapping
- * @host_addr: user virtual address within a host buffer
+ * Return whether a host buffer was mapped as coherent memory.
  *
- * Description: A Gasket page_table currently support one contiguous
- * dma range, mapped to one contiguous virtual memory range. Check if the
- * host_addr is within start of page 0, and end of last page, for that range.
+ * A Gasket page_table currently support one contiguous dma range, mapped to one
+ * contiguous virtual memory range. Check if the host_addr is within that range.
  */
 static int is_coherent(struct gasket_page_table *pg_tbl, ulong host_addr)
 {
@@ -1505,16 +1310,7 @@ static int is_coherent(struct gasket_page_table *pg_tbl, ulong host_addr)
 	return min <= host_addr && host_addr < max;
 }
 
-/*
- * Records the host_addr to coherent dma memory mapping.
- * @gasket_dev: Gasket Device.
- * @size: Size of the virtual address range to map.
- * @dma_address: Dma address within the coherent memory range.
- * @vma: Virtual address we wish to map to coherent memory.
- *
- * Description: For each page in the virtual address range, record the
- * coherent page mgasket_pretapping.
- */
+/* Record the host_addr to coherent dma memory mapping. */
 int gasket_set_user_virt(
 	struct gasket_dev *gasket_dev, u64 size, dma_addr_t dma_address,
 	ulong vma)
@@ -1541,16 +1337,7 @@ int gasket_set_user_virt(
 	return 0;
 }
 
-/*
- * Allocate a block of coherent memory.
- * @gasket_dev: Gasket Device.
- * @size: Size of the memory block.
- * @dma_address: Dma address allocated by the kernel.
- * @index: Index of the gasket_page_table within this Gasket device
- *
- * Description: Allocate a contiguous coherent memory block, DMA'ble
- * by this device.
- */
+/* Allocate a block of coherent memory. */
 int gasket_alloc_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 				 dma_addr_t *dma_address, u64 index)
 {
@@ -1613,15 +1400,7 @@ int gasket_alloc_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 	return -ENOMEM;
 }
 
-/*
- * Free a block of coherent memory.
- * @gasket_dev: Gasket Device.
- * @size: Size of the memory block.
- * @dma_address: Dma address allocated by the kernel.
- * @index: Index of the gasket_page_table within this Gasket device
- *
- * Description: Release memory allocated thru gasket_alloc_coherent_memory.
- */
+/* Free a block of coherent memory. */
 int gasket_free_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 				dma_addr_t dma_address, u64 index)
 {
@@ -1647,13 +1426,7 @@ int gasket_free_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 	return 0;
 }
 
-/*
- * Release all coherent memory.
- * @gasket_dev: Gasket Device.
- * @index: Index of the gasket_page_table within this Gasket device
- *
- * Description: Release all memory allocated thru gasket_alloc_coherent_memory.
- */
+/* Release all coherent memory. */
 void gasket_free_coherent_memory_all(
 	struct gasket_dev *gasket_dev, u64 index)
 {

commit dd9d1502feea3c23d412f289aad79e1d4e86d45d
Author: Todd Poynor <toddpoynor@google.com>
Date:   Sun Jul 29 12:36:36 2018 -0700

    staging: gasket: page table: hold references to device and pci_dev
    
    Hold references to the struct device and the pci_dev for the page table
    while the data structures contian pointers to these.
    
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index b9304d221722..6b946a155ee3 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -345,8 +345,8 @@ int gasket_page_table_init(
 		bar_data->virt_base[page_table_config->base_reg]);
 	pg_tbl->extended_offset_reg = (u64 __iomem *)&(
 		bar_data->virt_base[page_table_config->extended_reg]);
-	pg_tbl->device = device;
-	pg_tbl->pci_dev = pci_dev;
+	pg_tbl->device = get_device(device);
+	pg_tbl->pci_dev = pci_dev_get(pci_dev);
 
 	dev_dbg(device, "Page table initialized successfully\n");
 
@@ -364,6 +364,8 @@ void gasket_page_table_cleanup(struct gasket_page_table *pg_tbl)
 	vfree(pg_tbl->entries);
 	pg_tbl->entries = NULL;
 
+	put_device(pg_tbl->device);
+	pci_dev_put(pg_tbl->pci_dev);
 	kfree(pg_tbl);
 }
 

commit bb8a14a3d8203f3af45f84c6169cc09ef56156a3
Author: Dmitriy Cherkasov <dmitriy@oss-tech.org>
Date:   Sat Jul 28 22:55:24 2018 +0000

    staging: gasket: use NULL instead of 0 for null pointer
    
    Fixes sparse warning: Using plain integer as NULL pointer
    
    Signed-off-by: Dmitriy Cherkasov <dmitriy@oss-tech.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 722839603f20..b9304d221722 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -1605,7 +1605,7 @@ int gasket_alloc_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 
 	if (gasket_dev->page_table[index]->coherent_pages) {
 		kfree(gasket_dev->page_table[index]->coherent_pages);
-		gasket_dev->page_table[index]->coherent_pages = 0;
+		gasket_dev->page_table[index]->coherent_pages = NULL;
 	}
 	gasket_dev->page_table[index]->num_coherent_pages = 0;
 	return -ENOMEM;

commit 758c579ec631ce5efd8de3d3d35483416ae2cad1
Author: Todd Poynor <toddpoynor@google.com>
Date:   Fri Jul 27 22:21:59 2018 -0700

    staging: gasket: page table: remove code for "no dma_ops"
    
    Remove code with TODOs on it for working around apparent problems
    previously seen in a qemu environment where dma_ops was not set
    correctly.  There is no user of this in the current code.
    
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 32f1c1e10c7e..722839603f20 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -212,12 +212,6 @@ struct gasket_page_table {
 	 * gasket_mmap function, so user_virt belongs in the driver anyhow.
 	 */
 	struct gasket_coherent_page_entry *coherent_pages;
-
-	/*
-	 * Whether the page table uses arch specific dma_ops or
-	 * whether the driver is supplying its own.
-	 */
-	bool dma_ops;
 };
 
 /* Mapping declarations */
@@ -290,7 +284,7 @@ int gasket_page_table_init(
 	struct gasket_page_table **ppg_tbl,
 	const struct gasket_bar_data *bar_data,
 	const struct gasket_page_table_config *page_table_config,
-	struct device *device, struct pci_dev *pci_dev, bool has_dma_ops)
+	struct device *device, struct pci_dev *pci_dev)
 {
 	ulong bytes;
 	struct gasket_page_table *pg_tbl;
@@ -353,7 +347,6 @@ int gasket_page_table_init(
 		bar_data->virt_base[page_table_config->extended_reg]);
 	pg_tbl->device = device;
 	pg_tbl->pci_dev = pci_dev;
-	pg_tbl->dma_ops = has_dma_ops;
 
 	dev_dbg(device, "Page table initialized successfully\n");
 
@@ -759,33 +752,6 @@ static int gasket_map_extended_pages(
 	return 0;
 }
 
-/*
- * TODO: dma_map_page() is not plugged properly when running under qemu. i.e.
- * dma_ops are not set properly, which causes the kernel to assert.
- *
- * This temporary hack allows the driver to work on qemu, but need to be fixed:
- * - either manually set the dma_ops for the architecture (which incidentally
- * can't be done in an out-of-tree module) - or get qemu to fill the device tree
- * properly so as linux plug the proper dma_ops or so as the driver can detect
- * that it is runnig on qemu
- */
-static inline dma_addr_t _no_op_dma_map_page(
-	struct device *dev, struct page *page, size_t offset, size_t size,
-	enum dma_data_direction dir)
-{
-	/*
-	 * struct dma_map_ops *ops = get_dma_ops(dev);
-	 * dma_addr_t addr;
-	 *
-	 * kmemcheck_mark_initialized(page_address(page) + offset, size);
-	 * BUG_ON(!valid_dma_direction(dir));
-	 * addr = ops->map_page(dev, page, offset, size, dir, NULL);
-	 * debug_dma_map_page(dev, page, offset, size, dir, addr, false);
-	 */
-
-	return page_to_phys(page);
-}
-
 /*
  * Get and map last level page table buffers.
  * @pg_tbl: Gasket page table pointer.
@@ -856,16 +822,9 @@ static int gasket_perform_mapping(
 			ptes[i].offset = offset;
 
 			/* Map the page into DMA space. */
-			if (pg_tbl->dma_ops) {
-				/* hook in to kernel map functions */
-				ptes[i].dma_addr = dma_map_page(pg_tbl->device,
-					page, 0, PAGE_SIZE, DMA_BIDIRECTIONAL);
-			} else {
-				ptes[i].dma_addr = _no_op_dma_map_page(
-					pg_tbl->device, page, 0, PAGE_SIZE,
-					DMA_BIDIRECTIONAL);
-			}
-
+			ptes[i].dma_addr =
+				dma_map_page(pg_tbl->device, page, 0, PAGE_SIZE,
+					     DMA_BIDIRECTIONAL);
 			dev_dbg(pg_tbl->device,
 				"%s i %d pte %p pfn %p -> mapped %llx\n",
 				__func__, i, &ptes[i],
@@ -1042,13 +1001,8 @@ static int gasket_alloc_extended_subtable(
 	}
 
 	/* Map the page into DMA space. */
-	if (pg_tbl->dma_ops) {
-		pte->dma_addr = dma_map_page(pg_tbl->device, pte->page, 0,
-			PAGE_SIZE, DMA_BIDIRECTIONAL);
-	} else {
-		pte->dma_addr = _no_op_dma_map_page(pg_tbl->device, pte->page,
-			0, PAGE_SIZE, DMA_BIDIRECTIONAL);
-	}
+	pte->dma_addr = dma_map_page(pg_tbl->device, pte->page, 0, PAGE_SIZE,
+				     DMA_BIDIRECTIONAL);
 	/* Wait until the page is mapped. */
 	mb();
 

commit 330e5f2425ad6857eb2505b0ca435057c8310c9a
Author: Todd Poynor <toddpoynor@google.com>
Date:   Thu Jul 26 20:07:37 2018 -0700

    staging: gasket: don't print device addresses as kernel pointers
    
    Print device addresses as unsigned long, not as kernel pointers.
    
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 8ea8ea1c5174..32f1c1e10c7e 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -1333,8 +1333,8 @@ static bool gasket_is_extended_dev_addr_bad(
 	/* check if the device address is out of bound */
 	addr = dev_addr & ~((pg_tbl)->extended_flag);
 	if (addr >> (GASKET_EXTENDED_LVL0_WIDTH + GASKET_EXTENDED_LVL0_SHIFT)) {
-		dev_err(pg_tbl->device, "device address out of bound, 0x%p\n",
-			(void *)dev_addr);
+		dev_err(pg_tbl->device, "device address out of bounds: 0x%lx\n",
+			dev_addr);
 		return true;
 	}
 
@@ -1351,8 +1351,8 @@ static bool gasket_is_extended_dev_addr_bad(
 
 	if (gasket_components_to_dev_address(
 		pg_tbl, 0, page_global_idx, page_offset) != dev_addr) {
-		dev_err(pg_tbl->device, "address is invalid, 0x%p\n",
-			(void *)dev_addr);
+		dev_err(pg_tbl->device, "address is invalid: 0x%lx\n",
+			dev_addr);
 		return true;
 	}
 

commit c423d3447874929fd8ec0211a54085b1f1446b45
Author: Todd Poynor <toddpoynor@google.com>
Date:   Thu Jul 26 20:07:32 2018 -0700

    staging: gasket: page table: convert to standard logging
    
    Replace gasket logging calls with standard logging calls.
    
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 55ab59303247..8ea8ea1c5174 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -33,6 +33,7 @@
  */
 #include "gasket_page_table.h"
 
+#include <linux/device.h>
 #include <linux/file.h>
 #include <linux/init.h>
 #include <linux/kernel.h>
@@ -43,7 +44,6 @@
 
 #include "gasket_constants.h"
 #include "gasket_core.h"
-#include "gasket_logging.h"
 
 /* Constants & utility macros */
 /* The number of pages that can be mapped into each second-level page table. */
@@ -79,11 +79,6 @@
  */
 #define GASKET_EXTENDED_LVL1_SHIFT 12
 
-/* Page-table specific error logging. */
-#define gasket_pg_tbl_error(pg_tbl, format, arg...)                            \
-	gasket_dev_log(err, (pg_tbl)->device, (struct pci_dev *)NULL, format,  \
-		##arg)
-
 /* Type declarations */
 /* Valid states for a struct gasket_page_table_entry. */
 enum pte_status {
@@ -306,24 +301,23 @@ int gasket_page_table_init(
 	 * hardware register that contains the page table size.
 	 */
 	if (total_entries == ULONG_MAX) {
-		gasket_nodev_debug(
-			"Error reading page table size. "
-			"Initializing page table with size 0.");
+		dev_dbg(device, "Error reading page table size. "
+			"Initializing page table with size 0\n");
 		total_entries = 0;
 	}
 
-	gasket_nodev_debug(
-		"Attempting to initialize page table of size 0x%lx.",
+	dev_dbg(device,
+		"Attempting to initialize page table of size 0x%lx\n",
 		total_entries);
 
-	gasket_nodev_debug(
-		"Table has base reg 0x%x, extended offset reg 0x%x.",
+	dev_dbg(device,
+		"Table has base reg 0x%x, extended offset reg 0x%x\n",
 		page_table_config->base_reg,
 		page_table_config->extended_reg);
 
 	*ppg_tbl = kzalloc(sizeof(**ppg_tbl), GFP_KERNEL);
 	if (!*ppg_tbl) {
-		gasket_nodev_debug("No memory for page table.");
+		dev_dbg(device, "No memory for page table\n");
 		return -ENOMEM;
 	}
 
@@ -332,8 +326,8 @@ int gasket_page_table_init(
 	if (bytes != 0) {
 		pg_tbl->entries = vzalloc(bytes);
 		if (!pg_tbl->entries) {
-			gasket_nodev_debug(
-				"No memory for address translation metadata.");
+			dev_dbg(device,
+				"No memory for address translation metadata\n");
 			kfree(pg_tbl);
 			*ppg_tbl = NULL;
 			return -ENOMEM;
@@ -361,7 +355,7 @@ int gasket_page_table_init(
 	pg_tbl->pci_dev = pci_dev;
 	pg_tbl->dma_ops = has_dma_ops;
 
-	gasket_nodev_debug("Page table initialized successfully.");
+	dev_dbg(device, "Page table initialized successfully\n");
 
 	return 0;
 }
@@ -398,7 +392,7 @@ int gasket_page_table_partition(
 
 	for (i = start; i < pg_tbl->config.total_entries; i++) {
 		if (pg_tbl->entries[i].status != PTE_FREE) {
-			gasket_pg_tbl_error(pg_tbl, "entry %d is not free", i);
+			dev_err(pg_tbl->device, "entry %d is not free\n", i);
 			mutex_unlock(&pg_tbl->mutex);
 			return -EBUSY;
 		}
@@ -443,11 +437,9 @@ int gasket_page_table_map(
 
 	mutex_unlock(&pg_tbl->mutex);
 
-	gasket_nodev_debug(
-		"%s done: ha %llx daddr %llx num %d, "
-		"ret %d\n",
-		__func__,
-		(unsigned long long)host_addr,
+	dev_dbg(pg_tbl->device,
+		"%s done: ha %llx daddr %llx num %d, ret %d\n",
+		__func__, (unsigned long long)host_addr,
 		(unsigned long long)dev_addr, num_pages, ret);
 	return ret;
 }
@@ -562,9 +554,8 @@ bool gasket_page_table_are_addrs_bad(
 	ulong bytes)
 {
 	if (host_addr & (PAGE_SIZE - 1)) {
-		gasket_pg_tbl_error(
-			pg_tbl,
-			"host mapping address 0x%lx must be page aligned",
+		dev_err(pg_tbl->device,
+			"host mapping address 0x%lx must be page aligned\n",
 			host_addr);
 		return true;
 	}
@@ -580,16 +571,14 @@ bool gasket_page_table_is_dev_addr_bad(
 	uint num_pages = bytes / PAGE_SIZE;
 
 	if (bytes & (PAGE_SIZE - 1)) {
-		gasket_pg_tbl_error(
-			pg_tbl,
-			"mapping size 0x%lX must be page aligned", bytes);
+		dev_err(pg_tbl->device,
+			"mapping size 0x%lX must be page aligned\n", bytes);
 		return true;
 	}
 
 	if (num_pages == 0) {
-		gasket_pg_tbl_error(
-			pg_tbl,
-			"requested mapping is less than one page: %lu / %lu",
+		dev_err(pg_tbl->device,
+			"requested mapping is less than one page: %lu / %lu\n",
 			bytes, PAGE_SIZE);
 		return true;
 	}
@@ -644,7 +633,7 @@ int gasket_page_table_system_status(struct gasket_page_table *page_table)
 		return GASKET_STATUS_LAMED;
 
 	if (gasket_page_table_num_entries(page_table) == 0) {
-		gasket_nodev_debug("Page table size is 0.");
+		dev_dbg(page_table->device, "Page table size is 0\n");
 		return GASKET_STATUS_LAMED;
 	}
 
@@ -682,9 +671,8 @@ static int gasket_map_simple_pages(
 
 	ret = gasket_alloc_simple_entries(pg_tbl, dev_addr, num_pages);
 	if (ret) {
-		gasket_pg_tbl_error(
-			pg_tbl,
-			"page table slots %u (@ 0x%lx) to %u are not available",
+		dev_err(pg_tbl->device,
+			"page table slots %u (@ 0x%lx) to %u are not available\n",
 			slot_idx, dev_addr, slot_idx + num_pages - 1);
 		return ret;
 	}
@@ -695,7 +683,7 @@ static int gasket_map_simple_pages(
 
 	if (ret) {
 		gasket_page_table_unmap_nolock(pg_tbl, dev_addr, num_pages);
-		gasket_pg_tbl_error(pg_tbl, "gasket_perform_mapping %d.", ret);
+		dev_err(pg_tbl->device, "gasket_perform_mapping %d\n", ret);
 	}
 	return ret;
 }
@@ -732,10 +720,9 @@ static int gasket_map_extended_pages(
 	ret = gasket_alloc_extended_entries(pg_tbl, dev_addr, num_pages);
 	if (ret) {
 		dev_addr_end = dev_addr + (num_pages / PAGE_SIZE) - 1;
-		gasket_pg_tbl_error(
-			pg_tbl,
+		dev_err(pg_tbl->device,
 			"page table slots (%lu,%lu) (@ 0x%lx) to (%lu,%lu) are "
-			"not available",
+			"not available\n",
 			gasket_extended_lvl0_page_idx(pg_tbl, dev_addr),
 			dev_addr,
 			gasket_extended_lvl1_page_idx(pg_tbl, dev_addr),
@@ -843,7 +830,7 @@ static int gasket_perform_mapping(
 	for (i = 0; i < num_pages; i++) {
 		page_addr = host_addr + i * PAGE_SIZE;
 		offset = page_addr & (PAGE_SIZE - 1);
-		gasket_nodev_debug("%s i %d\n", __func__, i);
+		dev_dbg(pg_tbl->device, "%s i %d\n", __func__, i);
 		if (is_coherent(pg_tbl, host_addr)) {
 			u64 off =
 				(u64)host_addr -
@@ -857,10 +844,9 @@ static int gasket_perform_mapping(
 				page_addr - offset, 1, 1, &page);
 
 			if (ret <= 0) {
-				gasket_pg_tbl_error(
-					pg_tbl,
+				dev_err(pg_tbl->device,
 					"get user pages failed for addr=0x%lx, "
-					"offset=0x%lx [ret=%d]",
+					"offset=0x%lx [ret=%d]\n",
 					page_addr, offset, ret);
 				return ret ? ret : -ENOMEM;
 			}
@@ -880,21 +866,17 @@ static int gasket_perform_mapping(
 					DMA_BIDIRECTIONAL);
 			}
 
-			gasket_nodev_debug(
-				"%s dev %p "
-				"i %d pte %p pfn %p -> mapped %llx\n",
-				__func__,
-				pg_tbl->device, i, &ptes[i],
+			dev_dbg(pg_tbl->device,
+				"%s i %d pte %p pfn %p -> mapped %llx\n",
+				__func__, i, &ptes[i],
 				(void *)page_to_pfn(page),
 				(unsigned long long)ptes[i].dma_addr);
 
 			if (ptes[i].dma_addr == -1) {
-				gasket_nodev_debug(
-					"%s i %d"
-					" -> fail to map page %llx "
+				dev_dbg(pg_tbl->device,
+					"%s i %d -> fail to map page %llx "
 					"[pfn %p ohys %p]\n",
-					__func__,
-					i,
+					__func__, i,
 					(unsigned long long)ptes[i].dma_addr,
 					(void *)page_to_pfn(page),
 					(void *)page_to_phys(page));
@@ -996,9 +978,8 @@ static int gasket_alloc_extended_entries(
 		if (pte->status == PTE_FREE) {
 			ret = gasket_alloc_extended_subtable(pg_tbl, pte, slot);
 			if (ret) {
-				gasket_pg_tbl_error(
-					pg_tbl,
-					"no memory for extended addr subtable");
+				dev_err(pg_tbl->device,
+					"no memory for extended addr subtable\n");
 				return ret;
 			}
 		} else {
@@ -1309,23 +1290,21 @@ static bool gasket_is_simple_dev_addr_bad(
 
 	if (gasket_components_to_dev_address(
 		pg_tbl, 1, page_index, page_offset) != dev_addr) {
-		gasket_pg_tbl_error(
-			pg_tbl, "address is invalid, 0x%lX", dev_addr);
+		dev_err(pg_tbl->device, "address is invalid, 0x%lX\n",
+			dev_addr);
 		return true;
 	}
 
 	if (page_index >= pg_tbl->num_simple_entries) {
-		gasket_pg_tbl_error(
-			pg_tbl,
-			"starting slot at %lu is too large, max is < %u",
+		dev_err(pg_tbl->device,
+			"starting slot at %lu is too large, max is < %u\n",
 			page_index, pg_tbl->num_simple_entries);
 		return true;
 	}
 
 	if (page_index + num_pages > pg_tbl->num_simple_entries) {
-		gasket_pg_tbl_error(
-			pg_tbl,
-			"ending slot at %lu is too large, max is <= %u",
+		dev_err(pg_tbl->device,
+			"ending slot at %lu is too large, max is <= %u\n",
 			page_index + num_pages, pg_tbl->num_simple_entries);
 		return true;
 	}
@@ -1354,8 +1333,8 @@ static bool gasket_is_extended_dev_addr_bad(
 	/* check if the device address is out of bound */
 	addr = dev_addr & ~((pg_tbl)->extended_flag);
 	if (addr >> (GASKET_EXTENDED_LVL0_WIDTH + GASKET_EXTENDED_LVL0_SHIFT)) {
-		gasket_pg_tbl_error(pg_tbl, "device address out of bound, 0x%p",
-				    (void *)dev_addr);
+		dev_err(pg_tbl->device, "device address out of bound, 0x%p\n",
+			(void *)dev_addr);
 		return true;
 	}
 
@@ -1372,23 +1351,21 @@ static bool gasket_is_extended_dev_addr_bad(
 
 	if (gasket_components_to_dev_address(
 		pg_tbl, 0, page_global_idx, page_offset) != dev_addr) {
-		gasket_pg_tbl_error(
-			pg_tbl, "address is invalid, 0x%p", (void *)dev_addr);
+		dev_err(pg_tbl->device, "address is invalid, 0x%p\n",
+			(void *)dev_addr);
 		return true;
 	}
 
 	if (page_lvl0_idx >= pg_tbl->num_extended_entries) {
-		gasket_pg_tbl_error(
-			pg_tbl,
+		dev_err(pg_tbl->device,
 			"starting level 0 slot at %lu is too large, max is < "
-			"%u", page_lvl0_idx, pg_tbl->num_extended_entries);
+			"%u\n", page_lvl0_idx, pg_tbl->num_extended_entries);
 		return true;
 	}
 
 	if (page_lvl0_idx + num_lvl0_pages > pg_tbl->num_extended_entries) {
-		gasket_pg_tbl_error(
-			pg_tbl,
-			"ending level 0 slot at %lu is too large, max is <= %u",
+		dev_err(pg_tbl->device,
+			"ending level 0 slot at %lu is too large, max is <= %u\n",
 			page_lvl0_idx + num_lvl0_pages,
 			pg_tbl->num_extended_entries);
 		return true;
@@ -1597,8 +1574,8 @@ int gasket_set_user_virt(
 	 */
 	pg_tbl = gasket_dev->page_table[0];
 	if (!pg_tbl) {
-		gasket_nodev_debug(
-			"%s: invalid page table index", __func__);
+		dev_dbg(gasket_dev->dev, "%s: invalid page table index\n",
+			__func__);
 		return 0;
 	}
 	for (j = 0; j < num_pages; j++) {

commit 24b9bdff8d0848029dba1c80b196b43e80b39463
Author: Ivan Bornyakov <brnkv.i1@gmail.com>
Date:   Mon Jul 23 21:30:25 2018 +0300

    staging: gasket: use vzalloc instead of vmalloc/memset
    
    Use vzalloc instead of vmalloc followed by memset with 0.
    
    Signed-off-by: Ivan Bornyakov <brnkv.i1@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 4f2ff7700658..55ab59303247 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -330,7 +330,7 @@ int gasket_page_table_init(
 	pg_tbl = *ppg_tbl;
 	bytes = total_entries * sizeof(struct gasket_page_table_entry);
 	if (bytes != 0) {
-		pg_tbl->entries = vmalloc(bytes);
+		pg_tbl->entries = vzalloc(bytes);
 		if (!pg_tbl->entries) {
 			gasket_nodev_debug(
 				"No memory for address translation metadata.");
@@ -338,7 +338,6 @@ int gasket_page_table_init(
 			*ppg_tbl = NULL;
 			return -ENOMEM;
 		}
-		memset(pg_tbl->entries, 0, bytes);
 	}
 
 	mutex_init(&pg_tbl->mutex);
@@ -1054,13 +1053,12 @@ static int gasket_alloc_extended_subtable(
 
 	subtable_bytes = sizeof(struct gasket_page_table_entry) *
 		GASKET_PAGES_PER_SUBTABLE;
-	pte->sublevel = vmalloc(subtable_bytes);
+	pte->sublevel = vzalloc(subtable_bytes);
 	if (!pte->sublevel) {
 		free_page(page_addr);
 		memset(pte, 0, sizeof(struct gasket_page_table_entry));
 		return -ENOMEM;
 	}
-	memset(pte->sublevel, 0, subtable_bytes);
 
 	/* Map the page into DMA space. */
 	if (pg_tbl->dma_ops) {

commit 0322bad3b507a74e9fed302c875bc3371df0dca8
Author: Todd Poynor <toddpoynor@google.com>
Date:   Sat Jul 21 06:35:06 2018 -0700

    staging: gasket: page table: remove unnecessary logs
    
    Some error logs in page table handling code could only be hit in
    cases of programming errors not expected in the current code base, and
    aren't likely to be useful on their own.  Remove these.
    
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index f0c4884cb4bc..4f2ff7700658 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -605,10 +605,8 @@ EXPORT_SYMBOL(gasket_page_table_is_dev_addr_bad);
 /* See gasket_page_table.h for description. */
 uint gasket_page_table_max_size(struct gasket_page_table *page_table)
 {
-	if (!page_table) {
-		gasket_nodev_error("Passed a null page table.");
+	if (!page_table)
 		return 0;
-	}
 	return page_table->config.total_entries;
 }
 EXPORT_SYMBOL(gasket_page_table_max_size);
@@ -616,11 +614,8 @@ EXPORT_SYMBOL(gasket_page_table_max_size);
 /* See gasket_page_table.h for description. */
 uint gasket_page_table_num_entries(struct gasket_page_table *pg_tbl)
 {
-	if (!pg_tbl) {
-		gasket_nodev_error("Passed a null page table.");
+	if (!pg_tbl)
 		return 0;
-	}
-
 	return pg_tbl->num_simple_entries + pg_tbl->num_extended_entries;
 }
 EXPORT_SYMBOL(gasket_page_table_num_entries);
@@ -628,11 +623,8 @@ EXPORT_SYMBOL(gasket_page_table_num_entries);
 /* See gasket_page_table.h for description. */
 uint gasket_page_table_num_simple_entries(struct gasket_page_table *pg_tbl)
 {
-	if (!pg_tbl) {
-		gasket_nodev_error("Passed a null page table.");
+	if (!pg_tbl)
 		return 0;
-	}
-
 	return pg_tbl->num_simple_entries;
 }
 EXPORT_SYMBOL(gasket_page_table_num_simple_entries);
@@ -640,11 +632,8 @@ EXPORT_SYMBOL(gasket_page_table_num_simple_entries);
 /* See gasket_page_table.h for description. */
 uint gasket_page_table_num_active_pages(struct gasket_page_table *pg_tbl)
 {
-	if (!pg_tbl) {
-		gasket_nodev_error("Passed a null page table.");
+	if (!pg_tbl)
 		return 0;
-	}
-
 	return pg_tbl->num_active_pages;
 }
 EXPORT_SYMBOL(gasket_page_table_num_active_pages);
@@ -652,10 +641,8 @@ EXPORT_SYMBOL(gasket_page_table_num_active_pages);
 /* See gasket_page_table.h */
 int gasket_page_table_system_status(struct gasket_page_table *page_table)
 {
-	if (!page_table) {
-		gasket_nodev_error("Passed a null page table.");
+	if (!page_table)
 		return GASKET_STATUS_LAMED;
-	}
 
 	if (gasket_page_table_num_entries(page_table) == 0) {
 		gasket_nodev_debug("Page table size is 0.");

commit 37d7b0efabc56338370ca37a77ce69387b0a4373
Author: Todd Poynor <toddpoynor@google.com>
Date:   Sat Jul 21 06:35:05 2018 -0700

    staging: gasket: page table: convert various logs to debug level
    
    Debugging information is improperly logged at non-debug log level in a
    number of places, and some logs regarding error conditions may be
    generated too frequently, such that these could cause performance
    problems and/or obscure other logs.  Convert these to debug log level.
    
    Signed-off-by: Zhongze Hu <frankhu@chromium.org>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 9f8116112e0a..f0c4884cb4bc 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -306,7 +306,7 @@ int gasket_page_table_init(
 	 * hardware register that contains the page table size.
 	 */
 	if (total_entries == ULONG_MAX) {
-		gasket_nodev_error(
+		gasket_nodev_debug(
 			"Error reading page table size. "
 			"Initializing page table with size 0.");
 		total_entries = 0;
@@ -323,7 +323,7 @@ int gasket_page_table_init(
 
 	*ppg_tbl = kzalloc(sizeof(**ppg_tbl), GFP_KERNEL);
 	if (!*ppg_tbl) {
-		gasket_nodev_error("No memory for page table.");
+		gasket_nodev_debug("No memory for page table.");
 		return -ENOMEM;
 	}
 
@@ -332,7 +332,7 @@ int gasket_page_table_init(
 	if (bytes != 0) {
 		pg_tbl->entries = vmalloc(bytes);
 		if (!pg_tbl->entries) {
-			gasket_nodev_error(
+			gasket_nodev_debug(
 				"No memory for address translation metadata.");
 			kfree(pg_tbl);
 			*ppg_tbl = NULL;
@@ -658,7 +658,7 @@ int gasket_page_table_system_status(struct gasket_page_table *page_table)
 	}
 
 	if (gasket_page_table_num_entries(page_table) == 0) {
-		gasket_nodev_error("Page table size is 0.");
+		gasket_nodev_debug("Page table size is 0.");
 		return GASKET_STATUS_LAMED;
 	}
 
@@ -903,7 +903,7 @@ static int gasket_perform_mapping(
 				(unsigned long long)ptes[i].dma_addr);
 
 			if (ptes[i].dma_addr == -1) {
-				gasket_nodev_error(
+				gasket_nodev_debug(
 					"%s i %d"
 					" -> fail to map page %llx "
 					"[pfn %p ohys %p]\n",
@@ -1612,7 +1612,7 @@ int gasket_set_user_virt(
 	 */
 	pg_tbl = gasket_dev->page_table[0];
 	if (!pg_tbl) {
-		gasket_nodev_error(
+		gasket_nodev_debug(
 			"%s: invalid page table index", __func__);
 		return 0;
 	}

commit 0b184cc86542cf6938e82c61b0951e799ceceb9b
Author: Todd Poynor <toddpoynor@google.com>
Date:   Thu Jul 19 20:49:12 2018 -0700

    staging: gasket: remove unnecessary parens in page table code
    
    gasket_alloc_coherent_memory() extra parentheses in statement.
    
    Reported-by: Guenter Roeck <groeck@chromium.org>
    Signed-off-by: Simon Que <sque@chromium.org>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 617d602b8b44..9f8116112e0a 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -1639,7 +1639,7 @@ int gasket_alloc_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 	dma_addr_t handle;
 	void *mem;
 	int j;
-	unsigned int num_pages = (size + PAGE_SIZE - 1) / (PAGE_SIZE);
+	unsigned int num_pages = (size + PAGE_SIZE - 1) / PAGE_SIZE;
 	const struct gasket_driver_desc *driver_desc =
 		gasket_get_driver_desc(gasket_dev);
 

commit 6d8a1d564bc01b1f3402d229acb98f779440c5e3
Author: Todd Poynor <toddpoynor@google.com>
Date:   Thu Jul 19 20:49:10 2018 -0700

    staging: gasket: remove else clause after return in if clause
    
    Else after return is unnecessary and may cause static code checkers to
    complain.
    
    Reported-by: Guenter Roeck <groeck@chromium.org>
    Signed-off-by: Simon Que <sque@chromium.org>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 2a27db658a4e..617d602b8b44 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -598,9 +598,7 @@ bool gasket_page_table_is_dev_addr_bad(
 	if (gasket_addr_is_simple(pg_tbl, dev_addr))
 		return gasket_is_simple_dev_addr_bad(
 			pg_tbl, dev_addr, num_pages);
-	else
-		return gasket_is_extended_dev_addr_bad(
-			pg_tbl, dev_addr, num_pages);
+	return gasket_is_extended_dev_addr_bad(pg_tbl, dev_addr, num_pages);
 }
 EXPORT_SYMBOL(gasket_page_table_is_dev_addr_bad);
 

commit c5172a29d7386753e19f4860351b0fda06863d47
Author: Todd Poynor <toddpoynor@google.com>
Date:   Thu Jul 19 20:49:09 2018 -0700

    staging: gasket: gasket page table functions use bool return type
    
    Convert from int to bool return type for gasket page table functions
    that return values used as booleans.
    
    Reported-by: Guenter Roeck <groeck@chromium.org>
    Signed-off-by: Simon Que <sque@chromium.org>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 36a560c87af3..2a27db658a4e 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -262,16 +262,16 @@ static void gasket_perform_unmapping(
 static void gasket_free_extended_subtable(
 	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *pte,
 	u64 __iomem *att_reg);
-static int gasket_release_page(struct page *page);
+static bool gasket_release_page(struct page *page);
 
 /* Other/utility declarations */
-static inline int gasket_addr_is_simple(
+static inline bool gasket_addr_is_simple(
 	struct gasket_page_table *pg_tbl, ulong addr);
-static int gasket_is_simple_dev_addr_bad(
+static bool gasket_is_simple_dev_addr_bad(
 	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages);
-static int gasket_is_extended_dev_addr_bad(
+static bool gasket_is_extended_dev_addr_bad(
 	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages);
-static int gasket_is_pte_range_free(
+static bool gasket_is_pte_range_free(
 	struct gasket_page_table_entry *pte, uint num_entries);
 static void gasket_page_table_garbage_collect_nolock(
 	struct gasket_page_table *pg_tbl);
@@ -558,7 +558,7 @@ int gasket_page_table_lookup_page(
 }
 
 /* See gasket_page_table.h for description. */
-int gasket_page_table_are_addrs_bad(
+bool gasket_page_table_are_addrs_bad(
 	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
 	ulong bytes)
 {
@@ -567,7 +567,7 @@ int gasket_page_table_are_addrs_bad(
 			pg_tbl,
 			"host mapping address 0x%lx must be page aligned",
 			host_addr);
-		return 1;
+		return true;
 	}
 
 	return gasket_page_table_is_dev_addr_bad(pg_tbl, dev_addr, bytes);
@@ -575,7 +575,7 @@ int gasket_page_table_are_addrs_bad(
 EXPORT_SYMBOL(gasket_page_table_are_addrs_bad);
 
 /* See gasket_page_table.h for description. */
-int gasket_page_table_is_dev_addr_bad(
+bool gasket_page_table_is_dev_addr_bad(
 	struct gasket_page_table *pg_tbl, ulong dev_addr, ulong bytes)
 {
 	uint num_pages = bytes / PAGE_SIZE;
@@ -584,7 +584,7 @@ int gasket_page_table_is_dev_addr_bad(
 		gasket_pg_tbl_error(
 			pg_tbl,
 			"mapping size 0x%lX must be page aligned", bytes);
-		return 1;
+		return true;
 	}
 
 	if (num_pages == 0) {
@@ -592,7 +592,7 @@ int gasket_page_table_is_dev_addr_bad(
 			pg_tbl,
 			"requested mapping is less than one page: %lu / %lu",
 			bytes, PAGE_SIZE);
-		return 1;
+		return true;
 	}
 
 	if (gasket_addr_is_simple(pg_tbl, dev_addr))
@@ -1285,23 +1285,23 @@ static void gasket_free_extended_subtable(
 /*
  * Safely return a page to the OS.
  * @page: The page to return to the OS.
- * Returns 1 if the page was released, 0 if it was
+ * Returns true if the page was released, false if it was
  * ignored.
  */
-static int gasket_release_page(struct page *page)
+static bool gasket_release_page(struct page *page)
 {
 	if (!page)
-		return 0;
+		return false;
 
 	if (!PageReserved(page))
 		SetPageDirty(page);
 	put_page(page);
 
-	return 1;
+	return true;
 }
 
 /* Evaluates to nonzero if the specified virtual address is simple. */
-static inline int gasket_addr_is_simple(
+static inline bool gasket_addr_is_simple(
 	struct gasket_page_table *pg_tbl, ulong addr)
 {
 	return !((addr) & (pg_tbl)->extended_flag);
@@ -1317,7 +1317,7 @@ static inline int gasket_addr_is_simple(
  * address to/from page + offset) and that the requested page range starts and
  * ends within the set of currently-partitioned simple pages.
  */
-static int gasket_is_simple_dev_addr_bad(
+static bool gasket_is_simple_dev_addr_bad(
 	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
 {
 	ulong page_offset = dev_addr & (PAGE_SIZE - 1);
@@ -1328,7 +1328,7 @@ static int gasket_is_simple_dev_addr_bad(
 		pg_tbl, 1, page_index, page_offset) != dev_addr) {
 		gasket_pg_tbl_error(
 			pg_tbl, "address is invalid, 0x%lX", dev_addr);
-		return 1;
+		return true;
 	}
 
 	if (page_index >= pg_tbl->num_simple_entries) {
@@ -1336,7 +1336,7 @@ static int gasket_is_simple_dev_addr_bad(
 			pg_tbl,
 			"starting slot at %lu is too large, max is < %u",
 			page_index, pg_tbl->num_simple_entries);
-		return 1;
+		return true;
 	}
 
 	if (page_index + num_pages > pg_tbl->num_simple_entries) {
@@ -1344,10 +1344,10 @@ static int gasket_is_simple_dev_addr_bad(
 			pg_tbl,
 			"ending slot at %lu is too large, max is <= %u",
 			page_index + num_pages, pg_tbl->num_simple_entries);
-		return 1;
+		return true;
 	}
 
-	return 0;
+	return false;
 }
 
 /*
@@ -1359,7 +1359,7 @@ static int gasket_is_simple_dev_addr_bad(
  * @dev_addr: The device address to which the pages will be mapped.
  * @num_pages: The number of second-level/sub pages in the range to consider.
  */
-static int gasket_is_extended_dev_addr_bad(
+static bool gasket_is_extended_dev_addr_bad(
 	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
 {
 	/* Starting byte index of dev_addr into the first mapped page */
@@ -1373,7 +1373,7 @@ static int gasket_is_extended_dev_addr_bad(
 	if (addr >> (GASKET_EXTENDED_LVL0_WIDTH + GASKET_EXTENDED_LVL0_SHIFT)) {
 		gasket_pg_tbl_error(pg_tbl, "device address out of bound, 0x%p",
 				    (void *)dev_addr);
-		return 1;
+		return true;
 	}
 
 	/* Find the starting sub-page index in the space of all sub-pages. */
@@ -1391,7 +1391,7 @@ static int gasket_is_extended_dev_addr_bad(
 		pg_tbl, 0, page_global_idx, page_offset) != dev_addr) {
 		gasket_pg_tbl_error(
 			pg_tbl, "address is invalid, 0x%p", (void *)dev_addr);
-		return 1;
+		return true;
 	}
 
 	if (page_lvl0_idx >= pg_tbl->num_extended_entries) {
@@ -1399,7 +1399,7 @@ static int gasket_is_extended_dev_addr_bad(
 			pg_tbl,
 			"starting level 0 slot at %lu is too large, max is < "
 			"%u", page_lvl0_idx, pg_tbl->num_extended_entries);
-		return 1;
+		return true;
 	}
 
 	if (page_lvl0_idx + num_lvl0_pages > pg_tbl->num_extended_entries) {
@@ -1408,10 +1408,10 @@ static int gasket_is_extended_dev_addr_bad(
 			"ending level 0 slot at %lu is too large, max is <= %u",
 			page_lvl0_idx + num_lvl0_pages,
 			pg_tbl->num_extended_entries);
-		return 1;
+		return true;
 	}
 
-	return 0;
+	return false;
 }
 
 /*
@@ -1425,17 +1425,17 @@ static int gasket_is_extended_dev_addr_bad(
  *
  * The page table mutex must be held before this call.
  */
-static int gasket_is_pte_range_free(
+static bool gasket_is_pte_range_free(
 	struct gasket_page_table_entry *ptes, uint num_entries)
 {
 	int i;
 
 	for (i = 0; i < num_entries; i++) {
 		if (ptes[i].status != PTE_FREE)
-			return 0;
+			return false;
 	}
 
-	return 1;
+	return true;
 }
 
 /*

commit b17cef4d08ac9866f8996015d3bf396f51488a25
Author: Todd Poynor <toddpoynor@google.com>
Date:   Tue Jul 17 13:56:44 2018 -0700

    staging: gasket: whitespace fix in gasket_page_table_init
    
    Tab replaced with space.
    
    Signed-off-by: Zhongze Hu <frankhu@chromium.org>
    Signed-off-by: Todd Poynor <toddpoynor@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index dcd52e141f95..36a560c87af3 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -347,7 +347,7 @@ int gasket_page_table_init(
 	    pg_tbl->config.mode == GASKET_PAGE_TABLE_MODE_SIMPLE) {
 		pg_tbl->num_simple_entries = total_entries;
 		pg_tbl->num_extended_entries = 0;
-		pg_tbl->extended_flag =	1ull << page_table_config->extended_bit;
+		pg_tbl->extended_flag = 1ull << page_table_config->extended_bit;
 	} else {
 		pg_tbl->num_simple_entries = 0;
 		pg_tbl->num_extended_entries = total_entries;

commit af3abc4414cb94929be4940f3d9c02fea3f0b5c8
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Fri Jul 13 12:05:55 2018 +0200

    staging: gasket: remove gasket_page_table_num_extended_entries()
    
    It is exported, yet no one calls it so just remove the dead code.
    
    Cc: Rob Springer <rspringer@google.com>
    Cc: John Joseph <jnjoseph@google.com>
    Cc: Ben Chan <benchan@chromium.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 3de7f8c400c9..dcd52e141f95 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -640,17 +640,6 @@ uint gasket_page_table_num_simple_entries(struct gasket_page_table *pg_tbl)
 EXPORT_SYMBOL(gasket_page_table_num_simple_entries);
 
 /* See gasket_page_table.h for description. */
-uint gasket_page_table_num_extended_entries(struct gasket_page_table *pg_tbl)
-{
-	if (!pg_tbl) {
-		gasket_nodev_error("Passed a null page table.");
-		return 0;
-	}
-
-	return pg_tbl->num_extended_entries;
-}
-EXPORT_SYMBOL(gasket_page_table_num_extended_entries);
-
 uint gasket_page_table_num_active_pages(struct gasket_page_table *pg_tbl)
 {
 	if (!pg_tbl) {

commit 948fd537bd3d6f347ff1c87b82479873d1fcc77f
Author: Felix Siegel <felix.siegel@posteo.de>
Date:   Fri Jul 13 00:58:49 2018 +0200

    staging: gasket: Use __func__ instead of hardcoded string - Style
    
    Changed logging statements to use %s and __func__ instead of hard coding
    the function name in a string.
    
    Signed-off-by: Felix Siegel <felix.siegel@posteo.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index f00a8f1d07e1..3de7f8c400c9 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -445,8 +445,9 @@ int gasket_page_table_map(
 	mutex_unlock(&pg_tbl->mutex);
 
 	gasket_nodev_debug(
-		"gasket_page_table_map done: ha %llx daddr %llx num %d, "
+		"%s done: ha %llx daddr %llx num %d, "
 		"ret %d\n",
+		__func__,
 		(unsigned long long)host_addr,
 		(unsigned long long)dev_addr, num_pages, ret);
 	return ret;
@@ -869,7 +870,7 @@ static int gasket_perform_mapping(
 	for (i = 0; i < num_pages; i++) {
 		page_addr = host_addr + i * PAGE_SIZE;
 		offset = page_addr & (PAGE_SIZE - 1);
-		gasket_nodev_debug("gasket_perform_mapping i %d\n", i);
+		gasket_nodev_debug("%s i %d\n", __func__, i);
 		if (is_coherent(pg_tbl, host_addr)) {
 			u64 off =
 				(u64)host_addr -
@@ -907,17 +908,19 @@ static int gasket_perform_mapping(
 			}
 
 			gasket_nodev_debug(
-				"    gasket_perform_mapping dev %p "
+				"%s dev %p "
 				"i %d pte %p pfn %p -> mapped %llx\n",
+				__func__,
 				pg_tbl->device, i, &ptes[i],
 				(void *)page_to_pfn(page),
 				(unsigned long long)ptes[i].dma_addr);
 
 			if (ptes[i].dma_addr == -1) {
 				gasket_nodev_error(
-					"gasket_perform_mapping i %d"
+					"%s i %d"
 					" -> fail to map page %llx "
 					"[pfn %p ohys %p]\n",
+					__func__,
 					i,
 					(unsigned long long)ptes[i].dma_addr,
 					(void *)page_to_pfn(page),
@@ -1623,7 +1626,7 @@ int gasket_set_user_virt(
 	pg_tbl = gasket_dev->page_table[0];
 	if (!pg_tbl) {
 		gasket_nodev_error(
-			"gasket_set_user_virt: invalid page table index");
+			"%s: invalid page table index", __func__);
 		return 0;
 	}
 	for (j = 0; j < num_pages; j++) {

commit bf9c7a8673831acd67ad4a92b6acd85ffcde174c
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Jul 11 13:39:11 2018 +0200

    staging: gasket: remove redundant license information
    
    Now that the SPDX tag is in all gasket files, that identifies the
    license in a specific and legally-defined manner.  So the extra GPL text
    wording can be removed as it is no longer needed at all.
    
    This is done on a quest to remove the 700+ different ways that files in
    the kernel describe the GPL license text.  And there's unneeded stuff
    like the address (sometimes incorrect) for the FSF which is never
    needed.
    
    Cc: Rob Springer <rspringer@google.com>
    Cc: John Joseph <jnjoseph@google.com>
    Cc: Ben Chan <benchan@chromium.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index e86c160c167b..f00a8f1d07e1 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -1,16 +1,8 @@
 // SPDX-License-Identifier: GPL-2.0
-/* Implementation of Gasket page table support.
+/*
+ * Implementation of Gasket page table support.
  *
  * Copyright (C) 2018 Google, Inc.
- *
- * This software is licensed under the terms of the GNU General Public
- * License version 2, as published by the Free Software Foundation, and
- * may be copied, distributed, and modified under those terms.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
  */
 
 /*

commit 2dec0644e0c8083e0a9d3bbdd11aad2d850859e9
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Jul 11 13:39:10 2018 +0200

    staging: gasket: add SPDX identifiers to all files.
    
    It's good to have SPDX identifiers in all files to make it easier to
    audit the kernel tree for correct licenses.
    
    Fix up the all of the staging gasket files to have a proper SPDX
    identifier, based on the license text in the file itself.  The SPDX
    identifier is a legally binding shorthand, which can be used instead of
    the full boiler plate text.
    
    Cc: Rob Springer <rspringer@google.com>
    Cc: John Joseph <jnjoseph@google.com>
    Cc: Ben Chan <benchan@chromium.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 5d3d33cac12f..e86c160c167b 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /* Implementation of Gasket page table support.
  *
  * Copyright (C) 2018 Google, Inc.

commit eff2eb5bd57f3ddda47bedd87662d8cd9bd8b2a0
Author: Ivan Bornyakov <brnkv.i1@gmail.com>
Date:   Wed Jul 11 14:13:34 2018 +0300

    staging: gasket: fix plain integer as NULL pointer warning
    
    Trivial fix to remove sparse warnings:
    
      drivers/staging/gasket/gasket_page_table.c:884:40: warning: Using plain integer as NULL pointer
      drivers/staging/gasket/gasket_page_table.c:1743:57: warning: Using plain integer as NULL pointer
      drivers/staging/gasket/gasket_page_table.c:1768:57: warning: Using plain integer as NULL pointer
    
    Signed-off-by: Ivan Bornyakov <brnkv.i1@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index c5390a860f86..5d3d33cac12f 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -881,7 +881,7 @@ static int gasket_perform_mapping(
 			u64 off =
 				(u64)host_addr -
 				(u64)pg_tbl->coherent_pages[0].user_virt;
-			ptes[i].page = 0;
+			ptes[i].page = NULL;
 			ptes[i].offset = offset;
 			ptes[i].dma_addr = pg_tbl->coherent_pages[0].paddr +
 					   off + i * PAGE_SIZE;
@@ -1740,7 +1740,7 @@ int gasket_free_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 				  gasket_dev->coherent_buffer.virt_base,
 				  gasket_dev->coherent_buffer.phys_base);
 		gasket_dev->coherent_buffer.length_bytes = 0;
-		gasket_dev->coherent_buffer.virt_base = 0;
+		gasket_dev->coherent_buffer.virt_base = NULL;
 		gasket_dev->coherent_buffer.phys_base = 0;
 	}
 	return 0;
@@ -1765,7 +1765,7 @@ void gasket_free_coherent_memory_all(
 				  gasket_dev->coherent_buffer.virt_base,
 				  gasket_dev->coherent_buffer.phys_base);
 		gasket_dev->coherent_buffer.length_bytes = 0;
-		gasket_dev->coherent_buffer.virt_base = 0;
+		gasket_dev->coherent_buffer.virt_base = NULL;
 		gasket_dev->coherent_buffer.phys_base = 0;
 	}
 }

commit 9f2378d94d0f026389fff351848f2adc484650fe
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Jul 4 10:31:25 2018 -0700

    drivers/staging/gasket: Use 2-factor allocator calls
    
    As already done treewide, switch from open-coded multiplication to using
    2-factor allocator helpers.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
index 6dc10508b15e..c5390a860f86 100644
--- a/drivers/staging/gasket/gasket_page_table.c
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -1674,9 +1674,9 @@ int gasket_alloc_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
 	gasket_dev->page_table[index]->num_coherent_pages = num_pages;
 
 	/* allocate the physical memory block */
-	gasket_dev->page_table[index]->coherent_pages = kzalloc(
-		num_pages * sizeof(struct gasket_coherent_page_entry),
-		GFP_KERNEL);
+	gasket_dev->page_table[index]->coherent_pages =
+		kcalloc(num_pages, sizeof(struct gasket_coherent_page_entry),
+			GFP_KERNEL);
 	if (!gasket_dev->page_table[index]->coherent_pages)
 		goto nomem;
 	*dma_address = 0;

commit 9a69f5087ccc20bb411025decab455836df04168
Author: Simon Que <sque@chromium.org>
Date:   Fri Jun 29 22:49:38 2018 -0400

    drivers/staging: Gasket driver framework + Apex driver
    
    The Gasket (Google ASIC Software, Kernel Extensions, and Tools) kernel
    framework is a generic, flexible system that supports thin kernel
    drivers. Gasket kernel drivers are expected to handle opening and
    closing devices, mmap'ing BAR space as requested, a small selection of
    ioctls, and handling page table translation (covered below). Any other
    functions should be handled by userspace code.
    
    The Gasket common module is not enough to run a device. In order to
    customize the Gasket code for a given piece of hardware, a device
    specific module must be created. At a minimum, this module must define a
    struct gasket_driver_desc containing the device-specific data for use by
    the framework; in addition, the module must declare an __init function
    that calls gasket_register_device with the module's gasket_driver_desc
    struct. Finally, the driver must define an exit function that calls
    gasket_unregister_device with the module's gasket_driver_desc struct.
    
    One of the core assumptions of the Gasket framework is that precisely
    one process is allowed to have an open write handle to the device node
    at any given time. (That process may, once it has one write handle, open
    any number of additional write handles.) This is accomplished by
    tracking open and close data for each driver instance.
    
    Signed-off-by: Rob Springer <rspringer@google.com>
    Signed-off-by: John Joseph <jnjoseph@google.com>
    Signed-off-by: Simon Que <sque@chromium.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/staging/gasket/gasket_page_table.c b/drivers/staging/gasket/gasket_page_table.c
new file mode 100644
index 000000000000..6dc10508b15e
--- /dev/null
+++ b/drivers/staging/gasket/gasket_page_table.c
@@ -0,0 +1,1771 @@
+/* Implementation of Gasket page table support.
+ *
+ * Copyright (C) 2018 Google, Inc.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+/*
+ * Implementation of Gasket page table support.
+ *
+ * This file assumes 4kB pages throughout; can be factored out when necessary.
+ *
+ * Address format is as follows:
+ * Simple addresses - those whose containing pages are directly placed in the
+ * device's address translation registers - are laid out as:
+ * [ 63 - 40: Unused | 39 - 28: 0 | 27 - 12: page index | 11 - 0: page offset ]
+ * page index:  The index of the containing page in the device's address
+ *              translation registers.
+ * page offset: The index of the address into the containing page.
+ *
+ * Extended address - those whose containing pages are contained in a second-
+ * level page table whose address is present in the device's address translation
+ * registers - are laid out as:
+ * [ 63 - 40: Unused | 39: flag | 38 - 37: 0 | 36 - 21: dev/level 0 index |
+ *   20 - 12: host/level 1 index | 11 - 0: page offset ]
+ * flag:        Marker indicating that this is an extended address. Always 1.
+ * dev index:   The index of the first-level page in the device's extended
+ *              address translation registers.
+ * host index:  The index of the containing page in the [host-resident] second-
+ *              level page table.
+ * page offset: The index of the address into the containing [second-level]
+ *              page.
+ */
+#include "gasket_page_table.h"
+
+#include <linux/file.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/pagemap.h>
+#include <linux/vmalloc.h>
+
+#include "gasket_constants.h"
+#include "gasket_core.h"
+#include "gasket_logging.h"
+
+/* Constants & utility macros */
+/* The number of pages that can be mapped into each second-level page table. */
+#define GASKET_PAGES_PER_SUBTABLE 512
+
+/* The starting position of the page index in a simple virtual address. */
+#define GASKET_SIMPLE_PAGE_SHIFT 12
+
+/* Flag indicating that a [device] slot is valid for use. */
+#define GASKET_VALID_SLOT_FLAG 1
+
+/*
+ * The starting position of the level 0 page index (i.e., the entry in the
+ * device's extended address registers) in an extended address.
+ * Also can be thought of as (log2(PAGE_SIZE) + log2(PAGES_PER_SUBTABLE)),
+ * or (12 + 9).
+ */
+#define GASKET_EXTENDED_LVL0_SHIFT 21
+
+/*
+ * Number of first level pages that Gasket chips support. Equivalent to
+ * log2(NUM_LVL0_PAGE_TABLES)
+ *
+ * At a maximum, allowing for a 34 bits address space (or 16GB)
+ *   = GASKET_EXTENDED_LVL0_WIDTH + (log2(PAGE_SIZE) + log2(PAGES_PER_SUBTABLE)
+ * or, = 13 + 9 + 12
+ */
+#define GASKET_EXTENDED_LVL0_WIDTH 13
+
+/*
+ * The starting position of the level 1 page index (i.e., the entry in the
+ * host second-level/sub- table) in an extended address.
+ */
+#define GASKET_EXTENDED_LVL1_SHIFT 12
+
+/* Page-table specific error logging. */
+#define gasket_pg_tbl_error(pg_tbl, format, arg...)                            \
+	gasket_dev_log(err, (pg_tbl)->device, (struct pci_dev *)NULL, format,  \
+		##arg)
+
+/* Type declarations */
+/* Valid states for a struct gasket_page_table_entry. */
+enum pte_status {
+	PTE_FREE,
+	PTE_INUSE,
+};
+
+/*
+ * Mapping metadata for a single page.
+ *
+ * In this file, host-side page table entries are referred to as that (or PTEs).
+ * Where device vs. host entries are differentiated, device-side or -visible
+ * entries are called "slots". A slot may be either an entry in the device's
+ * address translation table registers or an entry in a second-level page
+ * table ("subtable").
+ *
+ * The full data in this structure is visible on the host [of course]. Only
+ * the address contained in dma_addr is communicated to the device; that points
+ * to the actual page mapped and described by this structure.
+ */
+struct gasket_page_table_entry {
+	/* The status of this entry/slot: free or in use. */
+	enum pte_status status;
+
+	/* Address of the page in DMA space. */
+	dma_addr_t dma_addr;
+
+	/* Linux page descriptor for the page described by this structure. */
+	struct page *page;
+
+	/*
+	 * Index for alignment into host vaddrs.
+	 * When a user specifies a host address for a mapping, that address may
+	 * not be page-aligned. Offset is the index into the containing page of
+	 * the host address (i.e., host_vaddr & (PAGE_SIZE - 1)).
+	 * This is necessary for translating between user-specified addresses
+	 * and page-aligned addresses.
+	 */
+	int offset;
+
+	/*
+	 * If this is an extended and first-level entry, sublevel points
+	 * to the second-level entries underneath this entry.
+	 */
+	struct gasket_page_table_entry *sublevel;
+};
+
+/*
+ * Maintains virtual to physical address mapping for a coherent page that is
+ * allocated by this module for a given device.
+ * Note that coherent pages mappings virt mapping cannot be tracked by the
+ * Linux kernel, and coherent pages don't have a struct page associated,
+ * hence Linux kernel cannot perform a get_user_page_xx() on a phys address
+ * that was allocated coherent.
+ * This structure trivially implements this mechanism.
+ */
+struct gasket_coherent_page_entry {
+	/* Phys address, dma'able by the owner device */
+	dma_addr_t paddr;
+
+	/* Kernel virtual address */
+	u64 user_virt;
+
+	/* User virtual address that was mapped by the mmap kernel subsystem */
+	u64 kernel_virt;
+
+	/*
+	 * Whether this page has been mapped into a user land process virtual
+	 * space
+	 */
+	u32 in_use;
+};
+
+/*
+ * [Host-side] page table descriptor.
+ *
+ * This structure tracks the metadata necessary to manage both simple and
+ * extended page tables.
+ */
+struct gasket_page_table {
+	/* The config used to create this page table. */
+	struct gasket_page_table_config config;
+
+	/* The number of simple (single-level) entries in the page table. */
+	uint num_simple_entries;
+
+	/* The number of extended (two-level) entries in the page table. */
+	uint num_extended_entries;
+
+	/* Array of [host-side] page table entries. */
+	struct gasket_page_table_entry *entries;
+
+	/* Number of actively mapped kernel pages in this table. */
+	uint num_active_pages;
+
+	/* Device register: base of/first slot in the page table. */
+	u64 __iomem *base_slot;
+
+	/* Device register: holds the offset indicating the start of the
+	 * extended address region of the device's address translation table.
+	 */
+	u64 __iomem *extended_offset_reg;
+
+	/* Device structure for the underlying device. Only used for logging. */
+	struct device *device;
+
+	/* PCI system descriptor for the underlying device. */
+	struct pci_dev *pci_dev;
+
+	/* Location of the extended address bit for this Gasket device. */
+	u64 extended_flag;
+
+	/* Mutex to protect page table internals. */
+	struct mutex mutex;
+
+	/* Number of coherent pages accessible thru by this page table */
+	int num_coherent_pages;
+
+	/*
+	 * List of coherent memory (physical) allocated for a device.
+	 *
+	 * This structure also remembers the user virtual mapping, this is
+	 * hacky, but we need to do this because the kernel doesn't keep track
+	 * of the user coherent pages (pfn pages), and virt to coherent page
+	 * mapping.
+	 * TODO: use find_vma() APIs to convert host address to vm_area, to
+	 * dma_addr_t instead of storing user virtu address in
+	 * gasket_coherent_page_entry
+	 *
+	 * Note that the user virtual mapping is created by the driver, in
+	 * gasket_mmap function, so user_virt belongs in the driver anyhow.
+	 */
+	struct gasket_coherent_page_entry *coherent_pages;
+
+	/*
+	 * Whether the page table uses arch specific dma_ops or
+	 * whether the driver is supplying its own.
+	 */
+	bool dma_ops;
+};
+
+/* Mapping declarations */
+static int gasket_map_simple_pages(
+	struct gasket_page_table *pg_tbl, ulong host_addr,
+	ulong dev_addr, uint num_pages);
+static int gasket_map_extended_pages(
+	struct gasket_page_table *pg_tbl, ulong host_addr,
+	ulong dev_addr, uint num_pages);
+static int gasket_perform_mapping(
+	struct gasket_page_table *pg_tbl,
+	struct gasket_page_table_entry *pte_base, u64 __iomem *att_base,
+	ulong host_addr, uint num_pages, int is_simple_mapping);
+
+static int gasket_alloc_simple_entries(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages);
+static int gasket_alloc_extended_entries(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_entries);
+static int gasket_alloc_extended_subtable(
+	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *pte,
+	u64 __iomem *att_reg);
+
+/* Unmapping declarations */
+static void gasket_page_table_unmap_nolock(
+	struct gasket_page_table *pg_tbl, ulong start_addr, uint num_pages);
+static void gasket_page_table_unmap_all_nolock(
+	struct gasket_page_table *pg_tbl);
+static void gasket_unmap_simple_pages(
+	struct gasket_page_table *pg_tbl, ulong start_addr, uint num_pages);
+static void gasket_unmap_extended_pages(
+	struct gasket_page_table *pg_tbl, ulong start_addr, uint num_pages);
+static void gasket_perform_unmapping(
+	struct gasket_page_table *pg_tbl,
+	struct gasket_page_table_entry *pte_base, u64 __iomem *att_base,
+	uint num_pages, int is_simple_mapping);
+
+static void gasket_free_extended_subtable(
+	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *pte,
+	u64 __iomem *att_reg);
+static int gasket_release_page(struct page *page);
+
+/* Other/utility declarations */
+static inline int gasket_addr_is_simple(
+	struct gasket_page_table *pg_tbl, ulong addr);
+static int gasket_is_simple_dev_addr_bad(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages);
+static int gasket_is_extended_dev_addr_bad(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages);
+static int gasket_is_pte_range_free(
+	struct gasket_page_table_entry *pte, uint num_entries);
+static void gasket_page_table_garbage_collect_nolock(
+	struct gasket_page_table *pg_tbl);
+
+/* Address format declarations */
+static ulong gasket_components_to_dev_address(
+	struct gasket_page_table *pg_tbl, int is_simple, uint page_index,
+	uint offset);
+static int gasket_simple_page_idx(
+	struct gasket_page_table *pg_tbl, ulong dev_addr);
+static ulong gasket_extended_lvl0_page_idx(
+	struct gasket_page_table *pg_tbl, ulong dev_addr);
+static ulong gasket_extended_lvl1_page_idx(
+	struct gasket_page_table *pg_tbl, ulong dev_addr);
+
+static int is_coherent(struct gasket_page_table *pg_tbl, ulong host_addr);
+
+/* Public/exported functions */
+/* See gasket_page_table.h for description. */
+int gasket_page_table_init(
+	struct gasket_page_table **ppg_tbl,
+	const struct gasket_bar_data *bar_data,
+	const struct gasket_page_table_config *page_table_config,
+	struct device *device, struct pci_dev *pci_dev, bool has_dma_ops)
+{
+	ulong bytes;
+	struct gasket_page_table *pg_tbl;
+	ulong total_entries = page_table_config->total_entries;
+
+	/*
+	 * TODO: Verify config->total_entries against value read from the
+	 * hardware register that contains the page table size.
+	 */
+	if (total_entries == ULONG_MAX) {
+		gasket_nodev_error(
+			"Error reading page table size. "
+			"Initializing page table with size 0.");
+		total_entries = 0;
+	}
+
+	gasket_nodev_debug(
+		"Attempting to initialize page table of size 0x%lx.",
+		total_entries);
+
+	gasket_nodev_debug(
+		"Table has base reg 0x%x, extended offset reg 0x%x.",
+		page_table_config->base_reg,
+		page_table_config->extended_reg);
+
+	*ppg_tbl = kzalloc(sizeof(**ppg_tbl), GFP_KERNEL);
+	if (!*ppg_tbl) {
+		gasket_nodev_error("No memory for page table.");
+		return -ENOMEM;
+	}
+
+	pg_tbl = *ppg_tbl;
+	bytes = total_entries * sizeof(struct gasket_page_table_entry);
+	if (bytes != 0) {
+		pg_tbl->entries = vmalloc(bytes);
+		if (!pg_tbl->entries) {
+			gasket_nodev_error(
+				"No memory for address translation metadata.");
+			kfree(pg_tbl);
+			*ppg_tbl = NULL;
+			return -ENOMEM;
+		}
+		memset(pg_tbl->entries, 0, bytes);
+	}
+
+	mutex_init(&pg_tbl->mutex);
+	memcpy(&pg_tbl->config, page_table_config, sizeof(*page_table_config));
+	if (pg_tbl->config.mode == GASKET_PAGE_TABLE_MODE_NORMAL ||
+	    pg_tbl->config.mode == GASKET_PAGE_TABLE_MODE_SIMPLE) {
+		pg_tbl->num_simple_entries = total_entries;
+		pg_tbl->num_extended_entries = 0;
+		pg_tbl->extended_flag =	1ull << page_table_config->extended_bit;
+	} else {
+		pg_tbl->num_simple_entries = 0;
+		pg_tbl->num_extended_entries = total_entries;
+		pg_tbl->extended_flag = 0;
+	}
+	pg_tbl->num_active_pages = 0;
+	pg_tbl->base_slot = (u64 __iomem *)&(
+		bar_data->virt_base[page_table_config->base_reg]);
+	pg_tbl->extended_offset_reg = (u64 __iomem *)&(
+		bar_data->virt_base[page_table_config->extended_reg]);
+	pg_tbl->device = device;
+	pg_tbl->pci_dev = pci_dev;
+	pg_tbl->dma_ops = has_dma_ops;
+
+	gasket_nodev_debug("Page table initialized successfully.");
+
+	return 0;
+}
+
+/* See gasket_page_table.h for description. */
+void gasket_page_table_cleanup(struct gasket_page_table *pg_tbl)
+{
+	/* Deallocate free second-level tables. */
+	gasket_page_table_garbage_collect(pg_tbl);
+
+	/* TODO: Check that all PTEs have been freed? */
+
+	vfree(pg_tbl->entries);
+	pg_tbl->entries = NULL;
+
+	kfree(pg_tbl);
+}
+
+/* See gasket_page_table.h for description. */
+int gasket_page_table_partition(
+	struct gasket_page_table *pg_tbl, uint num_simple_entries)
+{
+	int i, start;
+
+	mutex_lock(&pg_tbl->mutex);
+	if (num_simple_entries > pg_tbl->config.total_entries) {
+		mutex_unlock(&pg_tbl->mutex);
+		return -EINVAL;
+	}
+
+	gasket_page_table_garbage_collect_nolock(pg_tbl);
+
+	start = min(pg_tbl->num_simple_entries, num_simple_entries);
+
+	for (i = start; i < pg_tbl->config.total_entries; i++) {
+		if (pg_tbl->entries[i].status != PTE_FREE) {
+			gasket_pg_tbl_error(pg_tbl, "entry %d is not free", i);
+			mutex_unlock(&pg_tbl->mutex);
+			return -EBUSY;
+		}
+	}
+
+	pg_tbl->num_simple_entries = num_simple_entries;
+	pg_tbl->num_extended_entries =
+		pg_tbl->config.total_entries - num_simple_entries;
+	writeq(num_simple_entries, pg_tbl->extended_offset_reg);
+
+	mutex_unlock(&pg_tbl->mutex);
+	return 0;
+}
+EXPORT_SYMBOL(gasket_page_table_partition);
+
+/*
+ * See gasket_page_table.h for general description.
+ *
+ * gasket_page_table_map calls either gasket_map_simple_pages() or
+ * gasket_map_extended_pages() to actually perform the mapping.
+ *
+ * The page table mutex is held for the entire operation.
+ */
+int gasket_page_table_map(
+	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
+	uint num_pages)
+{
+	int ret;
+
+	if (!num_pages)
+		return 0;
+
+	mutex_lock(&pg_tbl->mutex);
+
+	if (gasket_addr_is_simple(pg_tbl, dev_addr)) {
+		ret = gasket_map_simple_pages(
+			pg_tbl, host_addr, dev_addr, num_pages);
+	} else {
+		ret = gasket_map_extended_pages(
+			pg_tbl, host_addr, dev_addr, num_pages);
+	}
+
+	mutex_unlock(&pg_tbl->mutex);
+
+	gasket_nodev_debug(
+		"gasket_page_table_map done: ha %llx daddr %llx num %d, "
+		"ret %d\n",
+		(unsigned long long)host_addr,
+		(unsigned long long)dev_addr, num_pages, ret);
+	return ret;
+}
+EXPORT_SYMBOL(gasket_page_table_map);
+
+/*
+ * See gasket_page_table.h for general description.
+ *
+ * gasket_page_table_unmap takes the page table lock and calls either
+ * gasket_unmap_simple_pages() or gasket_unmap_extended_pages() to
+ * actually unmap the pages from device space.
+ *
+ * The page table mutex is held for the entire operation.
+ */
+void gasket_page_table_unmap(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+{
+	if (!num_pages)
+		return;
+
+	mutex_lock(&pg_tbl->mutex);
+	gasket_page_table_unmap_nolock(pg_tbl, dev_addr, num_pages);
+	mutex_unlock(&pg_tbl->mutex);
+}
+EXPORT_SYMBOL(gasket_page_table_unmap);
+
+static void gasket_page_table_unmap_all_nolock(struct gasket_page_table *pg_tbl)
+{
+	gasket_unmap_simple_pages(
+		pg_tbl, gasket_components_to_dev_address(pg_tbl, 1, 0, 0),
+		pg_tbl->num_simple_entries);
+	gasket_unmap_extended_pages(
+		pg_tbl, gasket_components_to_dev_address(pg_tbl, 0, 0, 0),
+		pg_tbl->num_extended_entries * GASKET_PAGES_PER_SUBTABLE);
+}
+
+/* See gasket_page_table.h for description. */
+void gasket_page_table_unmap_all(struct gasket_page_table *pg_tbl)
+{
+	mutex_lock(&pg_tbl->mutex);
+	gasket_page_table_unmap_all_nolock(pg_tbl);
+	mutex_unlock(&pg_tbl->mutex);
+}
+EXPORT_SYMBOL(gasket_page_table_unmap_all);
+
+/* See gasket_page_table.h for description. */
+void gasket_page_table_reset(struct gasket_page_table *pg_tbl)
+{
+	mutex_lock(&pg_tbl->mutex);
+	gasket_page_table_unmap_all_nolock(pg_tbl);
+	writeq(pg_tbl->config.total_entries, pg_tbl->extended_offset_reg);
+	mutex_unlock(&pg_tbl->mutex);
+}
+
+/* See gasket_page_table.h for description. */
+void gasket_page_table_garbage_collect(struct gasket_page_table *pg_tbl)
+{
+	mutex_lock(&pg_tbl->mutex);
+	gasket_page_table_garbage_collect_nolock(pg_tbl);
+	mutex_unlock(&pg_tbl->mutex);
+}
+
+/* See gasket_page_table.h for description. */
+int gasket_page_table_lookup_page(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, struct page **ppage,
+	ulong *poffset)
+{
+	uint page_num;
+	struct gasket_page_table_entry *pte;
+
+	mutex_lock(&pg_tbl->mutex);
+	if (gasket_addr_is_simple(pg_tbl, dev_addr)) {
+		page_num = gasket_simple_page_idx(pg_tbl, dev_addr);
+		if (page_num >= pg_tbl->num_simple_entries)
+			goto fail;
+
+		pte = pg_tbl->entries + page_num;
+		if (pte->status != PTE_INUSE)
+			goto fail;
+	} else {
+		/* Find the level 0 entry, */
+		page_num = gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
+		if (page_num >= pg_tbl->num_extended_entries)
+			goto fail;
+
+		pte = pg_tbl->entries + pg_tbl->num_simple_entries + page_num;
+		if (pte->status != PTE_INUSE)
+			goto fail;
+
+		/* and its contained level 1 entry. */
+		page_num = gasket_extended_lvl1_page_idx(pg_tbl, dev_addr);
+		pte = pte->sublevel + page_num;
+		if (pte->status != PTE_INUSE)
+			goto fail;
+	}
+
+	*ppage = pte->page;
+	*poffset = pte->offset;
+	mutex_unlock(&pg_tbl->mutex);
+	return 0;
+
+fail:
+	*ppage = NULL;
+	*poffset = 0;
+	mutex_unlock(&pg_tbl->mutex);
+	return -1;
+}
+
+/* See gasket_page_table.h for description. */
+int gasket_page_table_are_addrs_bad(
+	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
+	ulong bytes)
+{
+	if (host_addr & (PAGE_SIZE - 1)) {
+		gasket_pg_tbl_error(
+			pg_tbl,
+			"host mapping address 0x%lx must be page aligned",
+			host_addr);
+		return 1;
+	}
+
+	return gasket_page_table_is_dev_addr_bad(pg_tbl, dev_addr, bytes);
+}
+EXPORT_SYMBOL(gasket_page_table_are_addrs_bad);
+
+/* See gasket_page_table.h for description. */
+int gasket_page_table_is_dev_addr_bad(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, ulong bytes)
+{
+	uint num_pages = bytes / PAGE_SIZE;
+
+	if (bytes & (PAGE_SIZE - 1)) {
+		gasket_pg_tbl_error(
+			pg_tbl,
+			"mapping size 0x%lX must be page aligned", bytes);
+		return 1;
+	}
+
+	if (num_pages == 0) {
+		gasket_pg_tbl_error(
+			pg_tbl,
+			"requested mapping is less than one page: %lu / %lu",
+			bytes, PAGE_SIZE);
+		return 1;
+	}
+
+	if (gasket_addr_is_simple(pg_tbl, dev_addr))
+		return gasket_is_simple_dev_addr_bad(
+			pg_tbl, dev_addr, num_pages);
+	else
+		return gasket_is_extended_dev_addr_bad(
+			pg_tbl, dev_addr, num_pages);
+}
+EXPORT_SYMBOL(gasket_page_table_is_dev_addr_bad);
+
+/* See gasket_page_table.h for description. */
+uint gasket_page_table_max_size(struct gasket_page_table *page_table)
+{
+	if (!page_table) {
+		gasket_nodev_error("Passed a null page table.");
+		return 0;
+	}
+	return page_table->config.total_entries;
+}
+EXPORT_SYMBOL(gasket_page_table_max_size);
+
+/* See gasket_page_table.h for description. */
+uint gasket_page_table_num_entries(struct gasket_page_table *pg_tbl)
+{
+	if (!pg_tbl) {
+		gasket_nodev_error("Passed a null page table.");
+		return 0;
+	}
+
+	return pg_tbl->num_simple_entries + pg_tbl->num_extended_entries;
+}
+EXPORT_SYMBOL(gasket_page_table_num_entries);
+
+/* See gasket_page_table.h for description. */
+uint gasket_page_table_num_simple_entries(struct gasket_page_table *pg_tbl)
+{
+	if (!pg_tbl) {
+		gasket_nodev_error("Passed a null page table.");
+		return 0;
+	}
+
+	return pg_tbl->num_simple_entries;
+}
+EXPORT_SYMBOL(gasket_page_table_num_simple_entries);
+
+/* See gasket_page_table.h for description. */
+uint gasket_page_table_num_extended_entries(struct gasket_page_table *pg_tbl)
+{
+	if (!pg_tbl) {
+		gasket_nodev_error("Passed a null page table.");
+		return 0;
+	}
+
+	return pg_tbl->num_extended_entries;
+}
+EXPORT_SYMBOL(gasket_page_table_num_extended_entries);
+
+uint gasket_page_table_num_active_pages(struct gasket_page_table *pg_tbl)
+{
+	if (!pg_tbl) {
+		gasket_nodev_error("Passed a null page table.");
+		return 0;
+	}
+
+	return pg_tbl->num_active_pages;
+}
+EXPORT_SYMBOL(gasket_page_table_num_active_pages);
+
+/* See gasket_page_table.h */
+int gasket_page_table_system_status(struct gasket_page_table *page_table)
+{
+	if (!page_table) {
+		gasket_nodev_error("Passed a null page table.");
+		return GASKET_STATUS_LAMED;
+	}
+
+	if (gasket_page_table_num_entries(page_table) == 0) {
+		gasket_nodev_error("Page table size is 0.");
+		return GASKET_STATUS_LAMED;
+	}
+
+	return GASKET_STATUS_ALIVE;
+}
+
+/* Internal functions */
+
+/* Mapping functions */
+/*
+ * Allocate and map pages to simple addresses.
+ * @pg_tbl: Gasket page table pointer.
+ * @host_addr: Starting host virtual memory address of the pages.
+ * @dev_addr: Starting device address of the pages.
+ * @cnt: Count of the number of device pages to map.
+ *
+ * Description: gasket_map_simple_pages calls gasket_simple_alloc_pages() to
+ *		allocate the page table slots, then calls
+ *		gasket_perform_mapping() to actually do the work of mapping the
+ *		pages into the the simple page table (device translation table
+ *		registers).
+ *
+ *		The sd_mutex must be held when gasket_map_simple_pages() is
+ *		called.
+ *
+ *		Returns 0 if successful or a non-zero error number otherwise.
+ *		If there is an error, no pages are mapped.
+ */
+static int gasket_map_simple_pages(
+	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
+	uint num_pages)
+{
+	int ret;
+	uint slot_idx = gasket_simple_page_idx(pg_tbl, dev_addr);
+
+	ret = gasket_alloc_simple_entries(pg_tbl, dev_addr, num_pages);
+	if (ret) {
+		gasket_pg_tbl_error(
+			pg_tbl,
+			"page table slots %u (@ 0x%lx) to %u are not available",
+			slot_idx, dev_addr, slot_idx + num_pages - 1);
+		return ret;
+	}
+
+	ret = gasket_perform_mapping(
+		pg_tbl, pg_tbl->entries + slot_idx,
+		pg_tbl->base_slot + slot_idx, host_addr, num_pages, 1);
+
+	if (ret) {
+		gasket_page_table_unmap_nolock(pg_tbl, dev_addr, num_pages);
+		gasket_pg_tbl_error(pg_tbl, "gasket_perform_mapping %d.", ret);
+	}
+	return ret;
+}
+
+/*
+ * gasket_map_extended_pages - Get and map buffers to extended addresses.
+ * @pg_tbl: Gasket page table pointer.
+ * @host_addr: Starting host virtual memory address of the pages.
+ * @dev_addr: Starting device address of the pages.
+ * @num_pages: The number of device pages to map.
+ *
+ * Description: gasket_map_extended_buffers calls
+ *		gasket_alloc_extended_entries() to allocate the page table
+ *		slots, then loops over the level 0 page table entries, and for
+ *		each calls gasket_perform_mapping() to map the buffers into the
+ *		level 1 page table for that level 0 entry.
+ *
+ *		The page table mutex must be held when
+ *		gasket_map_extended_pages() is called.
+ *
+ *		Returns 0 if successful or a non-zero error number otherwise.
+ *		If there is an error, no pages are mapped.
+ */
+static int gasket_map_extended_pages(
+	struct gasket_page_table *pg_tbl, ulong host_addr, ulong dev_addr,
+	uint num_pages)
+{
+	int ret;
+	ulong dev_addr_end;
+	uint slot_idx, remain, len;
+	struct gasket_page_table_entry *pte;
+	u64 __iomem *slot_base;
+
+	ret = gasket_alloc_extended_entries(pg_tbl, dev_addr, num_pages);
+	if (ret) {
+		dev_addr_end = dev_addr + (num_pages / PAGE_SIZE) - 1;
+		gasket_pg_tbl_error(
+			pg_tbl,
+			"page table slots (%lu,%lu) (@ 0x%lx) to (%lu,%lu) are "
+			"not available",
+			gasket_extended_lvl0_page_idx(pg_tbl, dev_addr),
+			dev_addr,
+			gasket_extended_lvl1_page_idx(pg_tbl, dev_addr),
+			gasket_extended_lvl0_page_idx(pg_tbl, dev_addr_end),
+			gasket_extended_lvl1_page_idx(pg_tbl, dev_addr_end));
+		return ret;
+	}
+
+	remain = num_pages;
+	slot_idx = gasket_extended_lvl1_page_idx(pg_tbl, dev_addr);
+	pte = pg_tbl->entries + pg_tbl->num_simple_entries +
+	      gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
+
+	while (remain > 0) {
+		len = min(remain, GASKET_PAGES_PER_SUBTABLE - slot_idx);
+
+		slot_base =
+			(u64 __iomem *)(page_address(pte->page) + pte->offset);
+		ret = gasket_perform_mapping(
+			pg_tbl, pte->sublevel + slot_idx, slot_base + slot_idx,
+			host_addr, len, 0);
+		if (ret) {
+			gasket_page_table_unmap_nolock(
+				pg_tbl, dev_addr, num_pages);
+			return ret;
+		}
+
+		remain -= len;
+		slot_idx = 0;
+		pte++;
+		host_addr += len * PAGE_SIZE;
+	}
+
+	return 0;
+}
+
+/*
+ * TODO: dma_map_page() is not plugged properly when running under qemu. i.e.
+ * dma_ops are not set properly, which causes the kernel to assert.
+ *
+ * This temporary hack allows the driver to work on qemu, but need to be fixed:
+ * - either manually set the dma_ops for the architecture (which incidentally
+ * can't be done in an out-of-tree module) - or get qemu to fill the device tree
+ * properly so as linux plug the proper dma_ops or so as the driver can detect
+ * that it is runnig on qemu
+ */
+static inline dma_addr_t _no_op_dma_map_page(
+	struct device *dev, struct page *page, size_t offset, size_t size,
+	enum dma_data_direction dir)
+{
+	/*
+	 * struct dma_map_ops *ops = get_dma_ops(dev);
+	 * dma_addr_t addr;
+	 *
+	 * kmemcheck_mark_initialized(page_address(page) + offset, size);
+	 * BUG_ON(!valid_dma_direction(dir));
+	 * addr = ops->map_page(dev, page, offset, size, dir, NULL);
+	 * debug_dma_map_page(dev, page, offset, size, dir, addr, false);
+	 */
+
+	return page_to_phys(page);
+}
+
+/*
+ * Get and map last level page table buffers.
+ * @pg_tbl: Gasket page table pointer.
+ * @ptes: Array of page table entries to describe this mapping, one per
+ *        page to map.
+ * @slots: Location(s) to write device-mapped page address. If this is a simple
+ *	   mapping, these will be address translation registers. If this is
+ *	   an extended mapping, these will be within a second-level page table
+ *	   allocated by the host and so must have their __iomem attribute
+ *	   casted away.
+ * @host_addr: Starting [host] virtual memory address of the buffers.
+ * @num_pages: The number of device pages to map.
+ * @is_simple_mapping: 1 if this is a simple mapping, 0 otherwise.
+ *
+ * Description: gasket_perform_mapping calls get_user_pages() to get pages
+ *		of user memory and pin them.  It then calls dma_map_page() to
+ *		map them for DMA.  Finally, the mapped DMA addresses are written
+ *		into the page table.
+ *
+ *		This function expects that the page table entries are
+ *		already allocated.  The level argument determines how the
+ *		final page table entries are written: either into PCIe memory
+ *		mapped space for a level 0 page table or into kernel memory
+ *		for a level 1 page table.
+ *
+ *		The page pointers are saved for later releasing the pages.
+ *
+ *		Returns 0 if successful or a non-zero error number otherwise.
+ */
+static int gasket_perform_mapping(
+	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *ptes,
+	u64 __iomem *slots, ulong host_addr, uint num_pages,
+	int is_simple_mapping)
+{
+	int ret;
+	ulong offset;
+	struct page *page;
+	dma_addr_t dma_addr;
+	ulong page_addr;
+	int i;
+
+	for (i = 0; i < num_pages; i++) {
+		page_addr = host_addr + i * PAGE_SIZE;
+		offset = page_addr & (PAGE_SIZE - 1);
+		gasket_nodev_debug("gasket_perform_mapping i %d\n", i);
+		if (is_coherent(pg_tbl, host_addr)) {
+			u64 off =
+				(u64)host_addr -
+				(u64)pg_tbl->coherent_pages[0].user_virt;
+			ptes[i].page = 0;
+			ptes[i].offset = offset;
+			ptes[i].dma_addr = pg_tbl->coherent_pages[0].paddr +
+					   off + i * PAGE_SIZE;
+		} else {
+			ret = get_user_pages_fast(
+				page_addr - offset, 1, 1, &page);
+
+			if (ret <= 0) {
+				gasket_pg_tbl_error(
+					pg_tbl,
+					"get user pages failed for addr=0x%lx, "
+					"offset=0x%lx [ret=%d]",
+					page_addr, offset, ret);
+				return ret ? ret : -ENOMEM;
+			}
+			++pg_tbl->num_active_pages;
+
+			ptes[i].page = page;
+			ptes[i].offset = offset;
+
+			/* Map the page into DMA space. */
+			if (pg_tbl->dma_ops) {
+				/* hook in to kernel map functions */
+				ptes[i].dma_addr = dma_map_page(pg_tbl->device,
+					page, 0, PAGE_SIZE, DMA_BIDIRECTIONAL);
+			} else {
+				ptes[i].dma_addr = _no_op_dma_map_page(
+					pg_tbl->device, page, 0, PAGE_SIZE,
+					DMA_BIDIRECTIONAL);
+			}
+
+			gasket_nodev_debug(
+				"    gasket_perform_mapping dev %p "
+				"i %d pte %p pfn %p -> mapped %llx\n",
+				pg_tbl->device, i, &ptes[i],
+				(void *)page_to_pfn(page),
+				(unsigned long long)ptes[i].dma_addr);
+
+			if (ptes[i].dma_addr == -1) {
+				gasket_nodev_error(
+					"gasket_perform_mapping i %d"
+					" -> fail to map page %llx "
+					"[pfn %p ohys %p]\n",
+					i,
+					(unsigned long long)ptes[i].dma_addr,
+					(void *)page_to_pfn(page),
+					(void *)page_to_phys(page));
+				return -1;
+			}
+			/* Wait until the page is mapped. */
+			mb();
+		}
+
+		/* Make the DMA-space address available to the device. */
+		dma_addr = (ptes[i].dma_addr + offset) | GASKET_VALID_SLOT_FLAG;
+
+		if (is_simple_mapping) {
+			writeq(dma_addr, &slots[i]);
+		} else {
+			((u64 __force *)slots)[i] = dma_addr;
+			/* Extended page table vectors are in DRAM,
+			 * and so need to be synced each time they are updated.
+			 */
+			dma_map_single(pg_tbl->device,
+				       (void *)&((u64 __force *)slots)[i],
+				       sizeof(u64), DMA_TO_DEVICE);
+		}
+		ptes[i].status = PTE_INUSE;
+	}
+	return 0;
+}
+
+/**
+ * Allocate page table entries in a simple table.
+ * @pg_tbl: Gasket page table pointer.
+ * @dev_addr: Starting device address for the (eventual) mappings.
+ * @num_pages: Count of pages to be mapped.
+ *
+ * Description: gasket_alloc_simple_entries checks to see if a range of page
+ *		table slots are available.  As long as the sd_mutex is
+ *		held, the slots will be available.
+ *
+ *		The page table mutex must be held when
+ *		gasket_alloc_simple entries() is called.
+ *
+ *		Returns 0 if successful, or non-zero if the requested device
+ *		addresses are not available.
+ */
+static int gasket_alloc_simple_entries(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+{
+	if (!gasket_is_pte_range_free(
+		    pg_tbl->entries + gasket_simple_page_idx(pg_tbl, dev_addr),
+		    num_pages))
+		return -EBUSY;
+
+	return 0;
+}
+
+/**
+ * Allocate slots in an extended page table.
+ * @pg_tbl: Gasket page table pointer.
+ * @dev_addr: Starting device address for the (eventual) mappings.
+ * @num_pages: Count of pages to be mapped.
+ *
+ * Description: gasket_alloc_extended_entries checks to see if a range of page
+ *		table slots are available. If necessary, memory is allocated for
+ *		second level page tables.
+ *
+ *		Note that memory for second level page tables is allocated
+ *		as needed, but that memory is only freed on the final close
+ *		of the device file, when the page tables are repartitioned,
+ *		or the the device is removed.  If there is an error or if
+ *		the full range of slots is not available, any memory
+ *		allocated for second level page tables remains allocated
+ *		until final close, repartition, or device removal.
+ *
+ *		The page table mutex must be held when
+ *		gasket_alloc_extended_entries() is called.
+ *
+ *		Returns 0 if successful, or non-zero if the slots are
+ *		not available.
+ */
+static int gasket_alloc_extended_entries(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_entries)
+{
+	int ret = 0;
+	uint remain, subtable_slot_idx, len;
+	struct gasket_page_table_entry *pte;
+	u64 __iomem *slot;
+
+	remain = num_entries;
+	subtable_slot_idx = gasket_extended_lvl1_page_idx(pg_tbl, dev_addr);
+	pte = pg_tbl->entries + pg_tbl->num_simple_entries +
+	      gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
+	slot = pg_tbl->base_slot + pg_tbl->num_simple_entries +
+	       gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
+
+	while (remain > 0) {
+		len = min(remain,
+			  GASKET_PAGES_PER_SUBTABLE - subtable_slot_idx);
+
+		if (pte->status == PTE_FREE) {
+			ret = gasket_alloc_extended_subtable(pg_tbl, pte, slot);
+			if (ret) {
+				gasket_pg_tbl_error(
+					pg_tbl,
+					"no memory for extended addr subtable");
+				return ret;
+			}
+		} else {
+			if (!gasket_is_pte_range_free(
+				    pte->sublevel + subtable_slot_idx, len))
+				return -EBUSY;
+		}
+
+		remain -= len;
+		subtable_slot_idx = 0;
+		pte++;
+		slot++;
+	}
+
+	return 0;
+}
+
+/**
+ * Allocate a second level page table.
+ * @pg_tbl: Gasket page table pointer.
+ * @pte: Extended page table entry under/for which to allocate a second level.
+ * @slot: [Device] slot corresponding to pte.
+ *
+ * Description: Allocate the memory for a second level page table (subtable) at
+ *	        the given level 0 entry.  Then call dma_map_page() to map the
+ *		second level page table for DMA.  Finally, write the
+ *		mapped DMA address into the device page table.
+ *
+ *		The page table mutex must be held when
+ *		gasket_alloc_extended_subtable() is called.
+ *
+ *		Returns 0 if successful, or a non-zero error otherwise.
+ */
+static int gasket_alloc_extended_subtable(
+	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *pte,
+	u64 __iomem *slot)
+{
+	ulong page_addr, subtable_bytes;
+	dma_addr_t dma_addr;
+
+	/* XXX FIX ME XXX this is inefficient for non-4K page sizes */
+
+	/* GFP_DMA flag must be passed to architectures for which
+	 * part of the memory range is not considered DMA'able.
+	 * This seems to be the case for Juno board with 4.5.0 Linaro kernel
+	 */
+	page_addr = get_zeroed_page(GFP_KERNEL | GFP_DMA);
+	if (!page_addr)
+		return -ENOMEM;
+	pte->page = virt_to_page((void *)page_addr);
+	pte->offset = 0;
+
+	subtable_bytes = sizeof(struct gasket_page_table_entry) *
+		GASKET_PAGES_PER_SUBTABLE;
+	pte->sublevel = vmalloc(subtable_bytes);
+	if (!pte->sublevel) {
+		free_page(page_addr);
+		memset(pte, 0, sizeof(struct gasket_page_table_entry));
+		return -ENOMEM;
+	}
+	memset(pte->sublevel, 0, subtable_bytes);
+
+	/* Map the page into DMA space. */
+	if (pg_tbl->dma_ops) {
+		pte->dma_addr = dma_map_page(pg_tbl->device, pte->page, 0,
+			PAGE_SIZE, DMA_BIDIRECTIONAL);
+	} else {
+		pte->dma_addr = _no_op_dma_map_page(pg_tbl->device, pte->page,
+			0, PAGE_SIZE, DMA_BIDIRECTIONAL);
+	}
+	/* Wait until the page is mapped. */
+	mb();
+
+	/* make the addresses available to the device */
+	dma_addr = (pte->dma_addr + pte->offset) | GASKET_VALID_SLOT_FLAG;
+	writeq(dma_addr, slot);
+
+	pte->status = PTE_INUSE;
+
+	return 0;
+}
+
+/* Unmapping functions */
+/*
+ * Non-locking entry to unmapping routines.
+ * @pg_tbl: Gasket page table structure.
+ * @dev_addr: Starting device address of the pages to unmap.
+ * @num_pages: The number of device pages to unmap.
+ *
+ * Description: Version of gasket_unmap_pages that assumes the page table lock
+ *              is held.
+ */
+static void gasket_page_table_unmap_nolock(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+{
+	if (!num_pages)
+		return;
+
+	if (gasket_addr_is_simple(pg_tbl, dev_addr))
+		gasket_unmap_simple_pages(pg_tbl, dev_addr, num_pages);
+	else
+		gasket_unmap_extended_pages(pg_tbl, dev_addr, num_pages);
+}
+
+/*
+ * Unmap and release pages mapped to simple addresses.
+ * @pg_tbl: Gasket page table pointer.
+ * @dev_addr: Starting device address of the buffers.
+ * @num_pages: The number of device pages to unmap.
+ *
+ * Description: gasket_simple_unmap_pages calls gasket_perform_unmapping() to
+ * unmap and release the buffers in the level 0 page table.
+ *
+ * The sd_mutex must be held when gasket_unmap_simple_pages() is called.
+ */
+static void gasket_unmap_simple_pages(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+{
+	uint slot = gasket_simple_page_idx(pg_tbl, dev_addr);
+
+	gasket_perform_unmapping(pg_tbl, pg_tbl->entries + slot,
+				 pg_tbl->base_slot + slot, num_pages, 1);
+}
+
+/**
+ * Unmap and release buffers to extended addresses.
+ * @pg_tbl: Gasket page table pointer.
+ * @dev_addr: Starting device address of the pages to unmap.
+ * @addr: Starting device address of the buffers.
+ * @num_pages: The number of device pages to unmap.
+ *
+ * Description: gasket_extended_unmap_pages loops over the level 0 page table
+ *		entries, and for each calls gasket_perform_unmapping() to unmap
+ *		the buffers from the level 1 page [sub]table for that level 0
+ *		entry.
+ *
+ *		The page table mutex must be held when
+ *		gasket_unmap_extended_pages() is called.
+ */
+static void gasket_unmap_extended_pages(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+{
+	uint slot_idx, remain, len;
+	struct gasket_page_table_entry *pte;
+	u64 __iomem *slot_base;
+
+	remain = num_pages;
+	slot_idx = gasket_extended_lvl1_page_idx(pg_tbl, dev_addr);
+	pte = pg_tbl->entries + pg_tbl->num_simple_entries +
+	      gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
+
+	while (remain > 0) {
+		/* TODO: Add check to ensure pte remains valid? */
+		len = min(remain, GASKET_PAGES_PER_SUBTABLE - slot_idx);
+
+		if (pte->status == PTE_INUSE) {
+			slot_base = (u64 __iomem *)(page_address(pte->page) +
+						    pte->offset);
+			gasket_perform_unmapping(
+				pg_tbl, pte->sublevel + slot_idx,
+				slot_base + slot_idx, len, 0);
+		}
+
+		remain -= len;
+		slot_idx = 0;
+		pte++;
+	}
+}
+
+/*
+ * Unmap and release mapped pages.
+ * @pg_tbl: Gasket page table pointer.
+ * @ptes: Array of page table entries to describe the mapped range, one per
+ *        page to unmap.
+ * @slots: Device slots corresponding to the mappings described by "ptes".
+ *         As with ptes, one element per page to unmap.
+ *         If these are simple mappings, these will be address translation
+ *         registers. If these are extended mappings, these will be witin a
+ *         second-level page table allocated on the host, and so must have
+ *	   their __iomem attribute casted away.
+ * @num_pages: Number of pages to unmap.
+ * @is_simple_mapping: 1 if this is a simple mapping, 0 otherwise.
+ *
+ * Description: gasket_perform_unmapping() loops through the metadata entries
+ *		in a last level page table (simple table or extended subtable),
+ *		and for each page:
+ *		 - Unmaps the page from DMA space (dma_unmap_page),
+ *		 - Returns the page to the OS (gasket_release_page),
+ *		The entry in the page table is written to 0. The metadata
+ *		type is set to PTE_FREE and the metadata is all reset
+ *		to 0.
+ *
+ *		The page table mutex must be held when this function is called.
+ */
+static void gasket_perform_unmapping(
+	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *ptes,
+	u64 __iomem *slots, uint num_pages, int is_simple_mapping)
+{
+	int i;
+	/*
+	 * For each page table entry and corresponding entry in the device's
+	 * address translation table:
+	 */
+	for (i = 0; i < num_pages; i++) {
+		/* release the address from the device, */
+		if (is_simple_mapping || ptes[i].status == PTE_INUSE)
+			writeq(0, &slots[i]);
+		else
+			((u64 __force *)slots)[i] = 0;
+		/* Force sync around the address release. */
+		mb();
+
+		/* release the address from the driver, */
+		if (ptes[i].status == PTE_INUSE) {
+			if (ptes[i].dma_addr) {
+				dma_unmap_page(pg_tbl->device, ptes[i].dma_addr,
+					       PAGE_SIZE, DMA_FROM_DEVICE);
+			}
+			if (gasket_release_page(ptes[i].page))
+				--pg_tbl->num_active_pages;
+		}
+		ptes[i].status = PTE_FREE;
+
+		/* and clear the PTE. */
+		memset(&ptes[i], 0, sizeof(struct gasket_page_table_entry));
+	}
+}
+
+/*
+ * Free a second level page [sub]table.
+ * @pg_tbl: Gasket page table pointer.
+ * @pte: Page table entry _pointing_to_ the subtable to free.
+ * @slot: Device slot holding a pointer to the sublevel's contents.
+ *
+ * Description: Safely deallocates a second-level [sub]table by:
+ *  - Marking the containing first-level PTE as free
+ *  - Setting the corresponding [extended] device slot as NULL
+ *  - Unmapping the PTE from DMA space.
+ *  - Freeing the subtable's memory.
+ *  - Deallocating the page and clearing out the PTE.
+ *
+ * The page table mutex must be held before this call.
+ */
+static void gasket_free_extended_subtable(
+	struct gasket_page_table *pg_tbl, struct gasket_page_table_entry *pte,
+	u64 __iomem *slot)
+{
+	/* Release the page table from the driver */
+	pte->status = PTE_FREE;
+
+	/* Release the page table from the device */
+	writeq(0, slot);
+	/* Force sync around the address release. */
+	mb();
+
+	if (pte->dma_addr)
+		dma_unmap_page(pg_tbl->device, pte->dma_addr, PAGE_SIZE,
+			       DMA_BIDIRECTIONAL);
+
+	vfree(pte->sublevel);
+
+	if (pte->page)
+		free_page((ulong)page_address(pte->page));
+
+	memset(pte, 0, sizeof(struct gasket_page_table_entry));
+}
+
+/*
+ * Safely return a page to the OS.
+ * @page: The page to return to the OS.
+ * Returns 1 if the page was released, 0 if it was
+ * ignored.
+ */
+static int gasket_release_page(struct page *page)
+{
+	if (!page)
+		return 0;
+
+	if (!PageReserved(page))
+		SetPageDirty(page);
+	put_page(page);
+
+	return 1;
+}
+
+/* Evaluates to nonzero if the specified virtual address is simple. */
+static inline int gasket_addr_is_simple(
+	struct gasket_page_table *pg_tbl, ulong addr)
+{
+	return !((addr) & (pg_tbl)->extended_flag);
+}
+
+/*
+ * Validity checking for simple addresses.
+ * @pg_tbl: Gasket page table pointer.
+ * @dev_addr: The device address to which the pages will be mapped.
+ * @num_pages: The number of pages in the range to consider.
+ *
+ * Description: This call verifies that address translation commutes (from
+ * address to/from page + offset) and that the requested page range starts and
+ * ends within the set of currently-partitioned simple pages.
+ */
+static int gasket_is_simple_dev_addr_bad(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+{
+	ulong page_offset = dev_addr & (PAGE_SIZE - 1);
+	ulong page_index =
+		(dev_addr / PAGE_SIZE) & (pg_tbl->config.total_entries - 1);
+
+	if (gasket_components_to_dev_address(
+		pg_tbl, 1, page_index, page_offset) != dev_addr) {
+		gasket_pg_tbl_error(
+			pg_tbl, "address is invalid, 0x%lX", dev_addr);
+		return 1;
+	}
+
+	if (page_index >= pg_tbl->num_simple_entries) {
+		gasket_pg_tbl_error(
+			pg_tbl,
+			"starting slot at %lu is too large, max is < %u",
+			page_index, pg_tbl->num_simple_entries);
+		return 1;
+	}
+
+	if (page_index + num_pages > pg_tbl->num_simple_entries) {
+		gasket_pg_tbl_error(
+			pg_tbl,
+			"ending slot at %lu is too large, max is <= %u",
+			page_index + num_pages, pg_tbl->num_simple_entries);
+		return 1;
+	}
+
+	return 0;
+}
+
+/*
+ * Verifies that address translation commutes (from address to/from page +
+ * offset) and that the requested page range starts and ends within the set of
+ * currently-partitioned simple pages.
+ *
+ * @pg_tbl: Gasket page table pointer.
+ * @dev_addr: The device address to which the pages will be mapped.
+ * @num_pages: The number of second-level/sub pages in the range to consider.
+ */
+static int gasket_is_extended_dev_addr_bad(
+	struct gasket_page_table *pg_tbl, ulong dev_addr, uint num_pages)
+{
+	/* Starting byte index of dev_addr into the first mapped page */
+	ulong page_offset = dev_addr & (PAGE_SIZE - 1);
+	ulong page_global_idx, page_lvl0_idx;
+	ulong num_lvl0_pages;
+	ulong addr;
+
+	/* check if the device address is out of bound */
+	addr = dev_addr & ~((pg_tbl)->extended_flag);
+	if (addr >> (GASKET_EXTENDED_LVL0_WIDTH + GASKET_EXTENDED_LVL0_SHIFT)) {
+		gasket_pg_tbl_error(pg_tbl, "device address out of bound, 0x%p",
+				    (void *)dev_addr);
+		return 1;
+	}
+
+	/* Find the starting sub-page index in the space of all sub-pages. */
+	page_global_idx = (dev_addr / PAGE_SIZE) &
+		(pg_tbl->config.total_entries * GASKET_PAGES_PER_SUBTABLE - 1);
+
+	/* Find the starting level 0 index. */
+	page_lvl0_idx = gasket_extended_lvl0_page_idx(pg_tbl, dev_addr);
+
+	/* Get the count of affected level 0 pages. */
+	num_lvl0_pages = (num_pages + GASKET_PAGES_PER_SUBTABLE - 1) /
+		GASKET_PAGES_PER_SUBTABLE;
+
+	if (gasket_components_to_dev_address(
+		pg_tbl, 0, page_global_idx, page_offset) != dev_addr) {
+		gasket_pg_tbl_error(
+			pg_tbl, "address is invalid, 0x%p", (void *)dev_addr);
+		return 1;
+	}
+
+	if (page_lvl0_idx >= pg_tbl->num_extended_entries) {
+		gasket_pg_tbl_error(
+			pg_tbl,
+			"starting level 0 slot at %lu is too large, max is < "
+			"%u", page_lvl0_idx, pg_tbl->num_extended_entries);
+		return 1;
+	}
+
+	if (page_lvl0_idx + num_lvl0_pages > pg_tbl->num_extended_entries) {
+		gasket_pg_tbl_error(
+			pg_tbl,
+			"ending level 0 slot at %lu is too large, max is <= %u",
+			page_lvl0_idx + num_lvl0_pages,
+			pg_tbl->num_extended_entries);
+		return 1;
+	}
+
+	return 0;
+}
+
+/*
+ * Checks if a range of PTEs is free.
+ * @ptes: The set of PTEs to check.
+ * @num_entries: The number of PTEs to check.
+ *
+ * Description: Iterates over the input PTEs to determine if all have been
+ * marked as FREE or if any are INUSE. In the former case, 1/true is returned.
+ * Otherwise, 0/false is returned.
+ *
+ * The page table mutex must be held before this call.
+ */
+static int gasket_is_pte_range_free(
+	struct gasket_page_table_entry *ptes, uint num_entries)
+{
+	int i;
+
+	for (i = 0; i < num_entries; i++) {
+		if (ptes[i].status != PTE_FREE)
+			return 0;
+	}
+
+	return 1;
+}
+
+/*
+ * Actually perform collection.
+ * @pg_tbl: Gasket page table structure.
+ *
+ * Description: Version of gasket_page_table_garbage_collect that assumes the
+ *		page table lock is held.
+ */
+static void gasket_page_table_garbage_collect_nolock(
+	struct gasket_page_table *pg_tbl)
+{
+	struct gasket_page_table_entry *pte;
+	u64 __iomem *slot;
+
+	/* XXX FIX ME XXX -- more efficient to keep a usage count */
+	/* rather than scanning the second level page tables */
+
+	for (pte = pg_tbl->entries + pg_tbl->num_simple_entries,
+	     slot = pg_tbl->base_slot + pg_tbl->num_simple_entries;
+	     pte < pg_tbl->entries + pg_tbl->config.total_entries;
+	     pte++, slot++) {
+		if (pte->status == PTE_INUSE) {
+			if (gasket_is_pte_range_free(
+				    pte->sublevel, GASKET_PAGES_PER_SUBTABLE))
+				gasket_free_extended_subtable(
+					pg_tbl, pte, slot);
+		}
+	}
+}
+
+/*
+ * Converts components to a device address.
+ * @pg_tbl: Gasket page table structure.
+ * @is_simple: nonzero if this should be a simple entry, zero otherwise.
+ * @page_index: The page index into the respective table.
+ * @offset: The offset within the requested page.
+ *
+ * Simple utility function to convert (simple, page, offset) into a device
+ * address.
+ * Examples:
+ * Simple page 0, offset 32:
+ *  Input (0, 0, 32), Output 0x20
+ * Simple page 1000, offset 511:
+ *  Input (0, 1000, 512), Output 0x3E81FF
+ * Extended page 0, offset 32:
+ *  Input (0, 0, 32), Output 0x8000000020
+ * Extended page 1000, offset 511:
+ *  Input (1, 1000, 512), Output 0x8003E81FF
+ */
+static ulong gasket_components_to_dev_address(
+	struct gasket_page_table *pg_tbl, int is_simple, uint page_index,
+	uint offset)
+{
+	ulong lvl0_index, lvl1_index;
+
+	if (is_simple) {
+		/* Return simple addresses directly. */
+		lvl0_index = page_index & (pg_tbl->config.total_entries - 1);
+		return (lvl0_index << GASKET_SIMPLE_PAGE_SHIFT) | offset;
+	}
+
+	/*
+	 * This could be compressed into fewer statements, but
+	 * A) the compiler should optimize it
+	 * B) this is not slow
+	 * C) this is an uncommon operation
+	 * D) this is actually readable this way.
+	 */
+	lvl0_index = page_index / GASKET_PAGES_PER_SUBTABLE;
+	lvl1_index = page_index & (GASKET_PAGES_PER_SUBTABLE - 1);
+	return (pg_tbl)->extended_flag |
+	       (lvl0_index << GASKET_EXTENDED_LVL0_SHIFT) |
+	       (lvl1_index << GASKET_EXTENDED_LVL1_SHIFT) | offset;
+}
+
+/*
+ * Gets the index of the address' page in the simple table.
+ * @pg_tbl: Gasket page table structure.
+ * @dev_addr: The address whose page index to retrieve.
+ *
+ * Description: Treats the input address as a simple address and determines the
+ * index of its underlying page in the simple page table (i.e., device address
+ * translation registers.
+ *
+ * Does not perform validity checking.
+ */
+static int gasket_simple_page_idx(
+	struct gasket_page_table *pg_tbl, ulong dev_addr)
+{
+	return (dev_addr >> GASKET_SIMPLE_PAGE_SHIFT) &
+		(pg_tbl->config.total_entries - 1);
+}
+
+/*
+ * Gets the level 0 page index for the given address.
+ * @pg_tbl: Gasket page table structure.
+ * @dev_addr: The address whose page index to retrieve.
+ *
+ * Description: Treats the input address as an extended address and determines
+ * the index of its underlying page in the first-level extended page table
+ * (i.e., device extended address translation registers).
+ *
+ * Does not perform validity checking.
+ */
+static ulong gasket_extended_lvl0_page_idx(
+	struct gasket_page_table *pg_tbl, ulong dev_addr)
+{
+	return (dev_addr >> GASKET_EXTENDED_LVL0_SHIFT) &
+	       ((1 << GASKET_EXTENDED_LVL0_WIDTH) - 1);
+}
+
+/*
+ * Gets the level 1 page index for the given address.
+ * @pg_tbl: Gasket page table structure.
+ * @dev_addr: The address whose page index to retrieve.
+ *
+ * Description: Treats the input address as an extended address and determines
+ * the index of its underlying page in the second-level extended page table
+ * (i.e., host memory pointed to by a first-level page table entry).
+ *
+ * Does not perform validity checking.
+ */
+static ulong gasket_extended_lvl1_page_idx(
+	struct gasket_page_table *pg_tbl, ulong dev_addr)
+{
+	return (dev_addr >> GASKET_EXTENDED_LVL1_SHIFT) &
+	       (GASKET_PAGES_PER_SUBTABLE - 1);
+}
+
+/*
+ * Determines whether a host buffer was mapped as coherent memory.
+ * @pg_tbl: gasket_page_table structure tracking the host buffer mapping
+ * @host_addr: user virtual address within a host buffer
+ *
+ * Description: A Gasket page_table currently support one contiguous
+ * dma range, mapped to one contiguous virtual memory range. Check if the
+ * host_addr is within start of page 0, and end of last page, for that range.
+ */
+static int is_coherent(struct gasket_page_table *pg_tbl, ulong host_addr)
+{
+	u64 min, max;
+
+	/* whether the host address is within user virt range */
+	if (!pg_tbl->coherent_pages)
+		return 0;
+
+	min = (u64)pg_tbl->coherent_pages[0].user_virt;
+	max = min + PAGE_SIZE * pg_tbl->num_coherent_pages;
+
+	return min <= host_addr && host_addr < max;
+}
+
+/*
+ * Records the host_addr to coherent dma memory mapping.
+ * @gasket_dev: Gasket Device.
+ * @size: Size of the virtual address range to map.
+ * @dma_address: Dma address within the coherent memory range.
+ * @vma: Virtual address we wish to map to coherent memory.
+ *
+ * Description: For each page in the virtual address range, record the
+ * coherent page mgasket_pretapping.
+ */
+int gasket_set_user_virt(
+	struct gasket_dev *gasket_dev, u64 size, dma_addr_t dma_address,
+	ulong vma)
+{
+	int j;
+	struct gasket_page_table *pg_tbl;
+
+	unsigned int num_pages = size / PAGE_SIZE;
+
+	/*
+	 * TODO: for future chipset, better handling of the case where multiple
+	 * page tables are supported on a given device
+	 */
+	pg_tbl = gasket_dev->page_table[0];
+	if (!pg_tbl) {
+		gasket_nodev_error(
+			"gasket_set_user_virt: invalid page table index");
+		return 0;
+	}
+	for (j = 0; j < num_pages; j++) {
+		pg_tbl->coherent_pages[j].user_virt =
+			(u64)vma + j * PAGE_SIZE;
+	}
+	return 0;
+}
+
+/*
+ * Allocate a block of coherent memory.
+ * @gasket_dev: Gasket Device.
+ * @size: Size of the memory block.
+ * @dma_address: Dma address allocated by the kernel.
+ * @index: Index of the gasket_page_table within this Gasket device
+ *
+ * Description: Allocate a contiguous coherent memory block, DMA'ble
+ * by this device.
+ */
+int gasket_alloc_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
+				 dma_addr_t *dma_address, u64 index)
+{
+	dma_addr_t handle;
+	void *mem;
+	int j;
+	unsigned int num_pages = (size + PAGE_SIZE - 1) / (PAGE_SIZE);
+	const struct gasket_driver_desc *driver_desc =
+		gasket_get_driver_desc(gasket_dev);
+
+	if (!gasket_dev->page_table[index])
+		return -EFAULT;
+
+	if (num_pages == 0)
+		return -EINVAL;
+
+	mem = dma_alloc_coherent(gasket_get_device(gasket_dev),
+				 num_pages * PAGE_SIZE, &handle, 0);
+	if (!mem)
+		goto nomem;
+
+	gasket_dev->page_table[index]->num_coherent_pages = num_pages;
+
+	/* allocate the physical memory block */
+	gasket_dev->page_table[index]->coherent_pages = kzalloc(
+		num_pages * sizeof(struct gasket_coherent_page_entry),
+		GFP_KERNEL);
+	if (!gasket_dev->page_table[index]->coherent_pages)
+		goto nomem;
+	*dma_address = 0;
+
+	gasket_dev->coherent_buffer.length_bytes =
+		PAGE_SIZE * (num_pages);
+	gasket_dev->coherent_buffer.phys_base = handle;
+	gasket_dev->coherent_buffer.virt_base = mem;
+
+	*dma_address = driver_desc->coherent_buffer_description.base;
+		for (j = 0; j < num_pages; j++) {
+		gasket_dev->page_table[index]->coherent_pages[j].paddr =
+			handle + j * PAGE_SIZE;
+		gasket_dev->page_table[index]->coherent_pages[j].kernel_virt =
+			(u64)mem + j * PAGE_SIZE;
+	}
+
+	if (*dma_address == 0)
+		goto nomem;
+	return 0;
+
+nomem:
+	if (mem) {
+		dma_free_coherent(gasket_get_device(gasket_dev),
+				  num_pages * PAGE_SIZE, mem, handle);
+	}
+
+	if (gasket_dev->page_table[index]->coherent_pages) {
+		kfree(gasket_dev->page_table[index]->coherent_pages);
+		gasket_dev->page_table[index]->coherent_pages = 0;
+	}
+	gasket_dev->page_table[index]->num_coherent_pages = 0;
+	return -ENOMEM;
+}
+
+/*
+ * Free a block of coherent memory.
+ * @gasket_dev: Gasket Device.
+ * @size: Size of the memory block.
+ * @dma_address: Dma address allocated by the kernel.
+ * @index: Index of the gasket_page_table within this Gasket device
+ *
+ * Description: Release memory allocated thru gasket_alloc_coherent_memory.
+ */
+int gasket_free_coherent_memory(struct gasket_dev *gasket_dev, u64 size,
+				dma_addr_t dma_address, u64 index)
+{
+	const struct gasket_driver_desc *driver_desc;
+
+	if (!gasket_dev->page_table[index])
+		return -EFAULT;
+
+	driver_desc = gasket_get_driver_desc(gasket_dev);
+
+	if (driver_desc->coherent_buffer_description.base != dma_address)
+		return -EADDRNOTAVAIL;
+
+	if (gasket_dev->coherent_buffer.length_bytes) {
+		dma_free_coherent(gasket_get_device(gasket_dev),
+				  gasket_dev->coherent_buffer.length_bytes,
+				  gasket_dev->coherent_buffer.virt_base,
+				  gasket_dev->coherent_buffer.phys_base);
+		gasket_dev->coherent_buffer.length_bytes = 0;
+		gasket_dev->coherent_buffer.virt_base = 0;
+		gasket_dev->coherent_buffer.phys_base = 0;
+	}
+	return 0;
+}
+
+/*
+ * Release all coherent memory.
+ * @gasket_dev: Gasket Device.
+ * @index: Index of the gasket_page_table within this Gasket device
+ *
+ * Description: Release all memory allocated thru gasket_alloc_coherent_memory.
+ */
+void gasket_free_coherent_memory_all(
+	struct gasket_dev *gasket_dev, u64 index)
+{
+	if (!gasket_dev->page_table[index])
+		return;
+
+	if (gasket_dev->coherent_buffer.length_bytes) {
+		dma_free_coherent(gasket_get_device(gasket_dev),
+				  gasket_dev->coherent_buffer.length_bytes,
+				  gasket_dev->coherent_buffer.virt_base,
+				  gasket_dev->coherent_buffer.phys_base);
+		gasket_dev->coherent_buffer.length_bytes = 0;
+		gasket_dev->coherent_buffer.virt_base = 0;
+		gasket_dev->coherent_buffer.phys_base = 0;
+	}
+}
