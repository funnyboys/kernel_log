commit 37613fa5b762a73073de3c2e23baa4a1da337e71
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Thu Apr 25 20:06:18 2019 +0200

    regmap: add proper SPDX identifiers on files that did not have them.
    
    There were a few files in the regmap code that did not have SPDX
    identifiers on them, so fix that up.  At the same time, remove the "free
    form" text that specified the license of the file, as that is impossible
    for any tool to properly parse.
    
    Also, as Mark loves // comment markers, convert all of the headers to be
    the same to make things look consistent :)
    
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Mark Brown <broonie@kernel.org>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 9cbb4b0cd01b..cfa29dc89bbf 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -1,14 +1,10 @@
-/*
- * Register cache access API - rbtree caching support
- *
- * Copyright 2011 Wolfson Microelectronics plc
- *
- * Author: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- */
+// SPDX-License-Identifier: GPL-2.0
+//
+// Register cache access API - rbtree caching support
+//
+// Copyright 2011 Wolfson Microelectronics plc
+//
+// Author: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
 
 #include <linux/debugfs.h>
 #include <linux/device.h>

commit 435bba0f11f06789be59757719c161915e92f889
Author: Mathieu Malaterre <malat@debian.org>
Date:   Thu Jan 24 19:06:24 2019 +0100

    regmap: Remove attribute packed from struct 'regcache_rbtree_node'
    
    On one hand commit 28644c809f44 ("regmap: Add the rbtree cache support")
    added 'regcache_rbtree_node' as packed structure, while on the other hand
    commit e977145aeaad ("[RBTREE] Add explicit alignment to sizeof(long)
    for struct rb_node.") declared struct 'rb_node' as aligned.
    
    Solve the ambiguity of placing aligned structure in a packed one by
    removing the packed attribute from struct. This seems to be the behavior
    of gcc anyway.
    
    This removes the following warning (W=1):
    
      drivers/base/regmap/regcache-rbtree.c:36:1: warning: alignment 1 of 'struct regcache_rbtree_node' is less than 4 [-Wpacked-not-aligned]
    
    Cc: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Signed-off-by: Mathieu Malaterre <malat@debian.org>
    Signed-off-by: Mark Brown <broonie@kernel.org>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 2e8f0144f9ab..9cbb4b0cd01b 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -33,7 +33,7 @@ struct regcache_rbtree_node {
 	unsigned int blklen;
 	/* the actual rbtree node holding this block */
 	struct rb_node node;
-} __attribute__ ((packed));
+};
 
 struct regcache_rbtree_ctx {
 	struct rb_root root;

commit 32fa7b852feaf838a145ac0408ad0a14d24d2eec
Author: Yangtao Li <tiny.windzz@gmail.com>
Date:   Sat Dec 15 03:38:37 2018 -0500

    regmap: rbtree: convert to DEFINE_SHOW_ATTRIBUTE
    
    Use DEFINE_SHOW_ATTRIBUTE macro to simplify the code.
    
    Signed-off-by: Yangtao Li <tiny.windzz@gmail.com>
    Signed-off-by: Mark Brown <broonie@kernel.org>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index b1e9aae9a5d0..2e8f0144f9ab 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -177,17 +177,7 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 	return 0;
 }
 
-static int rbtree_open(struct inode *inode, struct file *file)
-{
-	return single_open(file, rbtree_show, inode->i_private);
-}
-
-static const struct file_operations rbtree_fops = {
-	.open		= rbtree_open,
-	.read		= seq_read,
-	.llseek		= seq_lseek,
-	.release	= single_release,
-};
+DEFINE_SHOW_ATTRIBUTE(rbtree);
 
 static void rbtree_debugfs_init(struct regmap *map)
 {

commit 671a911bb9aea07360cb253e98acb4b7e6fbdd07
Author: Geliang Tang <geliangtang@gmail.com>
Date:   Mon Dec 19 22:40:25 2016 +0800

    regmap: use rb_entry()
    
    To make the code clearer, use rb_entry() instead of container_of() to
    deal with rbtree.
    
    Signed-off-by: Geliang Tang <geliangtang@gmail.com>
    Signed-off-by: Mark Brown <broonie@kernel.org>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index b11af3f2c1db..b1e9aae9a5d0 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -81,7 +81,7 @@ static struct regcache_rbtree_node *regcache_rbtree_lookup(struct regmap *map,
 
 	node = rbtree_ctx->root.rb_node;
 	while (node) {
-		rbnode = container_of(node, struct regcache_rbtree_node, node);
+		rbnode = rb_entry(node, struct regcache_rbtree_node, node);
 		regcache_rbtree_get_base_top_reg(map, rbnode, &base_reg,
 						 &top_reg);
 		if (reg >= base_reg && reg <= top_reg) {
@@ -108,8 +108,7 @@ static int regcache_rbtree_insert(struct regmap *map, struct rb_root *root,
 	parent = NULL;
 	new = &root->rb_node;
 	while (*new) {
-		rbnode_tmp = container_of(*new, struct regcache_rbtree_node,
-					  node);
+		rbnode_tmp = rb_entry(*new, struct regcache_rbtree_node, node);
 		/* base and top registers of the current rbnode */
 		regcache_rbtree_get_base_top_reg(map, rbnode_tmp, &base_reg_tmp,
 						 &top_reg_tmp);
@@ -152,7 +151,7 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 
 	for (node = rb_first(&rbtree_ctx->root); node != NULL;
 	     node = rb_next(node)) {
-		n = container_of(node, struct regcache_rbtree_node, node);
+		n = rb_entry(node, struct regcache_rbtree_node, node);
 		mem_size += sizeof(*n);
 		mem_size += (n->blklen * map->cache_word_size);
 		mem_size += BITS_TO_LONGS(n->blklen) * sizeof(long);

commit 1bc8da4e143c0fd8807e061a66d91d5972601ab1
Author: Lars-Peter Clausen <lars@metafoo.de>
Date:   Thu Aug 4 17:22:16 2016 +0200

    regmap: rbtree: Avoid overlapping nodes
    
    When searching for a suitable node that should be used for inserting a new
    register, which does not fall within the range of any existing node, we not
    only looks for nodes which are directly adjacent to the new register, but
    for nodes within a certain proximity. This is done to avoid creating lots
    of small nodes with just a few registers spacing in between, which would
    increase memory usage as well as tree traversal time.
    
    This means there might be multiple node candidates which fall within the
    proximity range of the new register. If we choose the first node we
    encounter, under certain register insertion patterns it is possible to end
    up with overlapping ranges. This will break order in the rbtree and can
    cause the cached register value to become corrupted.
    
    E.g. take the simplified example where the proximity range is 2 and the
    register insertion sequence is 1, 4, 2, 3, 5.
     * Insert of register 1 creates a new node, this is the root of the rbtree
     * Insert of register 4 creates a new node, which is inserted to the right
       of the root.
     * Insert of register 2 gets inserted to the first node
     * Insert of register 3 gets inserted to the first node
     * Insert of register 5 also gets inserted into the first node since
       this is the first node encountered and it is within the proximity range.
       Now there are two overlapping nodes.
    
    To avoid this always choose the node that is closest to the new register.
    This will ensure that nodes will not overlap. The tree traversal is still
    done as a binary search, we just don't stop at the first node found. So the
    complexity of the algorithm stays within the same order.
    
    Ideally if a new register is in the range of two adjacent blocks those
    blocks should be merged, but that is a much more invasive change and left
    for later.
    
    The issue was initially introduced in commit 472fdec7380c ("regmap: rbtree:
    Reduce number of nodes, take 2"), but became much more exposed by commit
    6399aea629b0 ("regmap: rbtree: When adding a reg do a bsearch for target
    node") which changed the order in which nodes are looked-up.
    
    Fixes: 6399aea629b0 ("regmap: rbtree: When adding a reg do a bsearch for target node")
    Signed-off-by: Lars-Peter Clausen <lars@metafoo.de>
    Signed-off-by: Mark Brown <broonie@kernel.org>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index aa56af87d941..b11af3f2c1db 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -404,6 +404,7 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 		unsigned int new_base_reg, new_top_reg;
 		unsigned int min, max;
 		unsigned int max_dist;
+		unsigned int dist, best_dist = UINT_MAX;
 
 		max_dist = map->reg_stride * sizeof(*rbnode_tmp) /
 			map->cache_word_size;
@@ -423,24 +424,41 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 				&base_reg, &top_reg);
 
 			if (base_reg <= max && top_reg >= min) {
-				new_base_reg = min(reg, base_reg);
-				new_top_reg = max(reg, top_reg);
-			} else {
-				if (max < base_reg)
-					node = node->rb_left;
+				if (reg < base_reg)
+					dist = base_reg - reg;
+				else if (reg > top_reg)
+					dist = reg - top_reg;
 				else
-					node = node->rb_right;
-
-				continue;
+					dist = 0;
+				if (dist < best_dist) {
+					rbnode = rbnode_tmp;
+					best_dist = dist;
+					new_base_reg = min(reg, base_reg);
+					new_top_reg = max(reg, top_reg);
+				}
 			}
 
-			ret = regcache_rbtree_insert_to_block(map, rbnode_tmp,
+			/*
+			 * Keep looking, we want to choose the closest block,
+			 * otherwise we might end up creating overlapping
+			 * blocks, which breaks the rbtree.
+			 */
+			if (reg < base_reg)
+				node = node->rb_left;
+			else if (reg > top_reg)
+				node = node->rb_right;
+			else
+				break;
+		}
+
+		if (rbnode) {
+			ret = regcache_rbtree_insert_to_block(map, rbnode,
 							      new_base_reg,
 							      new_top_reg, reg,
 							      value);
 			if (ret)
 				return ret;
-			rbtree_ctx->cached_rbnode = rbnode_tmp;
+			rbtree_ctx->cached_rbnode = rbnode;
 			return 0;
 		}
 

commit 6cb07abcc318be8dfbec5d19bc982536d64106a9
Merge: a8d99344c9eb 75fb0aaea18d 6399aea629b0 8da61f24cc4a
Author: Mark Brown <broonie@kernel.org>
Date:   Tue Jan 5 19:07:18 2016 +0000

    Merge remote-tracking branches 'regmap/topic/mmio', 'regmap/topic/rbtree' and 'regmap/topic/seq' into regmap-next

commit 549e08a0a93442ab62e0aee8aeb8ae6a7f2b5273
Author: lixiubo <lixiubo@cmss.chinamobile.com>
Date:   Fri Nov 20 18:06:30 2015 +0800

    regmap: replace kmalloc with kmalloc_array
    
    Replace kmalloc with specialized function kmalloc_array when the size
    is a multiplication of : number * size
    
    Signed-off-by: lixiubo <lixiubo@cmss.chinamobile.com>
    Signed-off-by: Mark Brown <broonie@kernel.org>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 3b6cfede2fd9..9d7ced559cba 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -361,8 +361,8 @@ regcache_rbtree_node_alloc(struct regmap *map, unsigned int reg)
 		rbnode->base_reg = reg;
 	}
 
-	rbnode->block = kmalloc(rbnode->blklen * map->cache_word_size,
-				GFP_KERNEL);
+	rbnode->block = kmalloc_array(rbnode->blklen, map->cache_word_size,
+				      GFP_KERNEL);
 	if (!rbnode->block)
 		goto err_free;
 

commit eeda1bd69d5d8a020ce191f717b94ca99707daad
Author: lixiubo <lixiubo@cmss.chinamobile.com>
Date:   Fri Nov 20 18:06:29 2015 +0800

    regmap: replace kzalloc with kcalloc
    
    Replace kzalloc with specialized function kcalloc when the size is
    a multiplication of : number * sizeof
    
    Signed-off-by: lixiubo <lixiubo@cmss.chinamobile.com>
    Signed-off-by: Mark Brown <broonie@kernel.org>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 56486d92c4e7..3b6cfede2fd9 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -366,8 +366,9 @@ regcache_rbtree_node_alloc(struct regmap *map, unsigned int reg)
 	if (!rbnode->block)
 		goto err_free;
 
-	rbnode->cache_present = kzalloc(BITS_TO_LONGS(rbnode->blklen) *
-		sizeof(*rbnode->cache_present), GFP_KERNEL);
+	rbnode->cache_present = kcalloc(BITS_TO_LONGS(rbnode->blklen),
+					sizeof(*rbnode->cache_present),
+					GFP_KERNEL);
 	if (!rbnode->cache_present)
 		goto err_free_block;
 

commit 6399aea629b02a23364efcb6eea1319b8e9d1abf
Author: Nikesh Oswal <Nikesh.Oswal@wolfsonmicro.com>
Date:   Wed Oct 21 14:16:14 2015 +0100

    regmap: rbtree: When adding a reg do a bsearch for target node
    
    A binary search is much more efficient rather than iterating
    over the rbtree in ascending order which the current code is
    doing.
    
    During initialisation the reg defaults are written to the
    cache in a large chunk and these are always sorted in the
    ascending order so for this situation ideally we should have
    iterated the rbtree in descending order.
    
    But at runtime the drivers may write into the cache in any
    random order so this patch selects to use a bsearch to give
    an optimal runtime performance and also at initialisation
    time when reg defaults are written the performance of binary
    search would be much better than iterating in ascending order
    which the current code was doing.
    
    Signed-off-by: Nikesh Oswal <Nikesh.Oswal@wolfsonmicro.com>
    Signed-off-by: Mark Brown <broonie@kernel.org>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 56486d92c4e7..353f60236ce0 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -413,8 +413,8 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 		max = reg + max_dist;
 
 		/* look for an adjacent register to the one we are about to add */
-		for (node = rb_first(&rbtree_ctx->root); node;
-		     node = rb_next(node)) {
+		node = rbtree_ctx->root.rb_node;
+		while (node) {
 			rbnode_tmp = rb_entry(node, struct regcache_rbtree_node,
 					      node);
 
@@ -425,6 +425,11 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 				new_base_reg = min(reg, base_reg);
 				new_top_reg = max(reg, top_reg);
 			} else {
+				if (max < base_reg)
+					node = node->rb_left;
+				else
+					node = node->rb_right;
+
 				continue;
 			}
 

commit 8ef9724bf9718af81cfc5132253372f79c71b7e2
Author: Guenter Roeck <linux@roeck-us.net>
Date:   Sun Jul 26 21:34:50 2015 -0700

    regmap: regcache-rbtree: Clean new present bits on present bitmap resize
    
    When inserting a new register into a block, the present bit map size is
    increased using krealloc. krealloc does not clear the additionally
    allocated memory, leaving it filled with random values. Result is that
    some registers are considered cached even though this is not the case.
    
    Fix the problem by clearing the additionally allocated memory. Also, if
    the bitmap size does not increase, do not reallocate the bitmap at all
    to reduce overhead.
    
    Fixes: 3f4ff561bc88 ("regmap: rbtree: Make cache_present bitmap per node")
    Signed-off-by: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Mark Brown <broonie@kernel.org>
    Cc: stable@vger.kernel.org

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 81751a49d8bf..56486d92c4e7 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -296,11 +296,20 @@ static int regcache_rbtree_insert_to_block(struct regmap *map,
 	if (!blk)
 		return -ENOMEM;
 
-	present = krealloc(rbnode->cache_present,
-		    BITS_TO_LONGS(blklen) * sizeof(*present), GFP_KERNEL);
-	if (!present) {
-		kfree(blk);
-		return -ENOMEM;
+	if (BITS_TO_LONGS(blklen) > BITS_TO_LONGS(rbnode->blklen)) {
+		present = krealloc(rbnode->cache_present,
+				   BITS_TO_LONGS(blklen) * sizeof(*present),
+				   GFP_KERNEL);
+		if (!present) {
+			kfree(blk);
+			return -ENOMEM;
+		}
+
+		memset(present + BITS_TO_LONGS(rbnode->blklen), 0,
+		       (BITS_TO_LONGS(blklen) - BITS_TO_LONGS(rbnode->blklen))
+		       * sizeof(*present));
+	} else {
+		present = rbnode->cache_present;
 	}
 
 	/* insert the register value in the correct place in the rbnode block */

commit 328f494d95aac8bd4896aea2328bc281053bcb71
Author: Lars-Peter Clausen <lars@metafoo.de>
Date:   Sat Mar 7 17:10:01 2015 +0100

    regmap: regcache-rbtree: Fix present bitmap resize
    
    When inserting a new register into a block at the lower end the present
    bitmap is currently shifted into the wrong direction. The effect of this is
    that the bitmap becomes corrupted and registers which are present might be
    reported as not present and vice versa.
    
    Fix this by shifting left rather than right.
    
    Fixes: 472fdec7380c("regmap: rbtree: Reduce number of nodes, take 2")
    Reported-by: Daniel Baluta <daniel.baluta@gmail.com>
    Signed-off-by: Lars-Peter Clausen <lars@metafoo.de>
    Signed-off-by: Mark Brown <broonie@kernel.org>
    Cc: stable@vger.kernel.org

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index d453a2c98ad0..81751a49d8bf 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -307,7 +307,7 @@ static int regcache_rbtree_insert_to_block(struct regmap *map,
 	if (pos == 0) {
 		memmove(blk + offset * map->cache_word_size,
 			blk, rbnode->blklen * map->cache_word_size);
-		bitmap_shift_right(present, present, offset, blklen);
+		bitmap_shift_left(present, present, offset, blklen);
 	}
 
 	/* update the rbnode block, its size and the base register */

commit e39be3a31b8f16d92fff096e92b593a9bffecb93
Author: Xiubo Li <Li.Xiubo@freescale.com>
Date:   Thu Oct 9 17:02:52 2014 +0800

    regmap: cache: Sort include headers alphabetically
    
    If the inlcude headers aren't sorted alphabetically, then the
    logical choice is to append new ones, however that creates a
    lot of potential for conflicts or duplicates because every change
    will then add new includes in the same location.
    
    Signed-off-by: Xiubo Li <Li.Xiubo@freescale.com>
    Signed-off-by: Mark Brown <broonie@kernel.org>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index f3e8fe0cc650..d453a2c98ad0 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -10,11 +10,11 @@
  * published by the Free Software Foundation.
  */
 
-#include <linux/slab.h>
-#include <linux/device.h>
 #include <linux/debugfs.h>
+#include <linux/device.h>
 #include <linux/rbtree.h>
 #include <linux/seq_file.h>
+#include <linux/slab.h>
 
 #include "internal.h"
 

commit 5e0cbe78762b5f02986bf9e59a188dad2f6e0be1
Author: Lars-Peter Clausen <lars@metafoo.de>
Date:   Sun Aug 24 15:32:27 2014 +0200

    regmap: Fix regcache debugfs initialization
    
    Commit 6cfec04bcc05 ("regmap: Separate regmap dev initialization") moved the
    regmap debugfs initialization after regcache initialization. This means
    that the regmap debugfs directory is not created yet when the cache
    initialization runs and so any debugfs files registered by the regcache are
    created in the debugfs root directory rather than the debugfs directory of
    the regmap instance. Fix this by adding a separate callback for the
    regcache debugfs initialization which will be called after the parent
    debugfs entry has been created.
    
    Fixes: 6cfec04bcc05 (regmap: Separate regmap dev initialization)
    Signed-off-by: Lars-Peter Clausen <lars@metafoo.de>
    Signed-off-by: Mark Brown <broonie@linaro.org>
    Cc: stable@vger.kernel.org

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 6a7e4fa12854..f3e8fe0cc650 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -194,10 +194,6 @@ static void rbtree_debugfs_init(struct regmap *map)
 {
 	debugfs_create_file("rbtree", 0400, map->debugfs, map, &rbtree_fops);
 }
-#else
-static void rbtree_debugfs_init(struct regmap *map)
-{
-}
 #endif
 
 static int regcache_rbtree_init(struct regmap *map)
@@ -222,8 +218,6 @@ static int regcache_rbtree_init(struct regmap *map)
 			goto err;
 	}
 
-	rbtree_debugfs_init(map);
-
 	return 0;
 
 err:
@@ -532,6 +526,9 @@ struct regcache_ops regcache_rbtree_ops = {
 	.name = "rbtree",
 	.init = regcache_rbtree_init,
 	.exit = regcache_rbtree_exit,
+#ifdef CONFIG_DEBUG_FS
+	.debugfs_init = rbtree_debugfs_init,
+#endif
 	.read = regcache_rbtree_read,
 	.write = regcache_rbtree_write,
 	.sync = regcache_rbtree_sync,

commit 70d383b7fefc40179da3eadbeb79c222d21987df
Author: Jean-Christophe PINCE <jean-christophe.pince@intel.com>
Date:   Tue Apr 1 13:26:48 2014 -0700

    regmap: rbtree: improve 64bits memory alignment
    
    Change regcache_rbtree_node strcuture fields order to align the pointers on
    64bits architectures.
    
    Signed-off-by: Jean-Christophe PINCE <jean-christophe.pince@intel.com>
    Signed-off-by: David Cohen <david.a.cohen@linux.intel.com>
    Signed-off-by: Mark Brown <broonie@linaro.org>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 930cad4e5df8..6a7e4fa12854 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -23,16 +23,16 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 static int regcache_rbtree_exit(struct regmap *map);
 
 struct regcache_rbtree_node {
-	/* the actual rbtree node holding this block */
-	struct rb_node node;
-	/* base register handled by this block */
-	unsigned int base_reg;
 	/* block of adjacent registers */
 	void *block;
 	/* Which registers are present */
 	long *cache_present;
+	/* base register handled by this block */
+	unsigned int base_reg;
 	/* number of registers available in the block */
 	unsigned int blklen;
+	/* the actual rbtree node holding this block */
+	struct rb_node node;
 } __attribute__ ((packed));
 
 struct regcache_rbtree_ctx {

commit 8243b7f5dc1dced123145566291015704f2b4ba7
Merge: fc6d0b037678 365c9ee0731d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 3 10:07:40 2013 -0700

    Merge tag 'regmap-v3.12' of git://git.kernel.org/pub/scm/linux/kernel/git/broonie/regmap
    
    Pull regmap updates from Mark Brown:
     "A quiet release for regmap, some cleanups, fixes and:
    
       - Improved node coalescing for rbtree, reducing memory usage and
         improving performance during syncs.
       - Support for registering multiple register patches.
       - A quirk for handling interrupts that need to be clear when masked
         in regmap-irq"
    
    * tag 'regmap-v3.12' of git://git.kernel.org/pub/scm/linux/kernel/git/broonie/regmap:
      regmap: rbtree: Make cache_present bitmap per node
      regmap: rbtree: Reduce number of nodes, take 2
      regmap: rbtree: Simplify adjacent node look-up
      regmap: debugfs: Fix continued read from registers file
      regcache-rbtree: Fix reg_stride != 1
      regmap: Allow multiple patches to be registered
      regmap: regcache: allow read-only regs to be cached
      regmap: fix regcache_reg_present() for empty cache
      regmap: core: allow a virtual range to cover its own data window
      regmap: irq: document mask/wake_invert flags
      regmap: irq: make flags bool and put them in a bitfield
      regmap: irq: Allow to acknowledge masked interrupts during initialization
      regmap: Provide __acquires/__releases annotations

commit 3f4ff561bc88b074d5e868dde4012d89cbb06c87
Author: Lars-Peter Clausen <lars@metafoo.de>
Date:   Thu Aug 29 10:26:34 2013 +0200

    regmap: rbtree: Make cache_present bitmap per node
    
    With devices which have a dense and small register map but placed at a large
    offset the global cache_present bitmap imposes a huge memory overhead. Making
    the cache_present per rbtree node avoids the issue and easily reduces the memory
    footprint by a factor of ten. For devices with a more sparse map or without a
    large base register offset the memory usage might increase slightly by a few
    bytes, but not significantly. E.g. for a device which has ~50 registers at
    offset 0x4000 the memory footprint of the register cache goes down form 2496
    bytes to 175 bytes.
    
    Moving the bitmap to a per node basis means that the handling of the bitmap is
    now cache implementation specific and can no longer be managed by the core. The
    regcache_sync_block() function is extended by a additional parameter so that the
    cache implementation can tell the core which registers in the block are set and
    which are not. The parameter is optional and if NULL the core assumes that all
    registers are set. The rbtree cache also needs to implement its own drop
    callback instead of relying on the core to handle this.
    
    Signed-off-by: Lars-Peter Clausen <lars@metafoo.de>
    Signed-off-by: Mark Brown <broonie@linaro.org>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index c06478c364b6..e9a2261a383b 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -29,6 +29,8 @@ struct regcache_rbtree_node {
 	unsigned int base_reg;
 	/* block of adjacent registers */
 	void *block;
+	/* Which registers are present */
+	long *cache_present;
 	/* number of registers available in the block */
 	unsigned int blklen;
 } __attribute__ ((packed));
@@ -57,6 +59,7 @@ static void regcache_rbtree_set_register(struct regmap *map,
 					 struct regcache_rbtree_node *rbnode,
 					 unsigned int idx, unsigned int val)
 {
+	set_bit(idx, rbnode->cache_present);
 	regcache_set_val(map, rbnode->block, idx, val);
 }
 
@@ -146,13 +149,13 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 	map->lock(map->lock_arg);
 
 	mem_size = sizeof(*rbtree_ctx);
-	mem_size += BITS_TO_LONGS(map->cache_present_nbits) * sizeof(long);
 
 	for (node = rb_first(&rbtree_ctx->root); node != NULL;
 	     node = rb_next(node)) {
 		n = container_of(node, struct regcache_rbtree_node, node);
 		mem_size += sizeof(*n);
 		mem_size += (n->blklen * map->cache_word_size);
+		mem_size += BITS_TO_LONGS(n->blklen) * sizeof(long);
 
 		regcache_rbtree_get_base_top_reg(map, n, &base, &top);
 		this_registers = ((top - base) / map->reg_stride) + 1;
@@ -245,6 +248,7 @@ static int regcache_rbtree_exit(struct regmap *map)
 		rbtree_node = rb_entry(next, struct regcache_rbtree_node, node);
 		next = rb_next(&rbtree_node->node);
 		rb_erase(&rbtree_node->node, &rbtree_ctx->root);
+		kfree(rbtree_node->cache_present);
 		kfree(rbtree_node->block);
 		kfree(rbtree_node);
 	}
@@ -265,7 +269,7 @@ static int regcache_rbtree_read(struct regmap *map,
 	rbnode = regcache_rbtree_lookup(map, reg);
 	if (rbnode) {
 		reg_tmp = (reg - rbnode->base_reg) / map->reg_stride;
-		if (!regcache_reg_present(map, reg))
+		if (!test_bit(reg_tmp, rbnode->cache_present))
 			return -ENOENT;
 		*value = regcache_rbtree_get_register(map, rbnode, reg_tmp);
 	} else {
@@ -285,6 +289,7 @@ static int regcache_rbtree_insert_to_block(struct regmap *map,
 {
 	unsigned int blklen;
 	unsigned int pos, offset;
+	unsigned long *present;
 	u8 *blk;
 
 	blklen = (top_reg - base_reg) / map->reg_stride + 1;
@@ -297,15 +302,25 @@ static int regcache_rbtree_insert_to_block(struct regmap *map,
 	if (!blk)
 		return -ENOMEM;
 
+	present = krealloc(rbnode->cache_present,
+		    BITS_TO_LONGS(blklen) * sizeof(*present), GFP_KERNEL);
+	if (!present) {
+		kfree(blk);
+		return -ENOMEM;
+	}
+
 	/* insert the register value in the correct place in the rbnode block */
-	if (pos == 0)
+	if (pos == 0) {
 		memmove(blk + offset * map->cache_word_size,
 			blk, rbnode->blklen * map->cache_word_size);
+		bitmap_shift_right(present, present, offset, blklen);
+	}
 
 	/* update the rbnode block, its size and the base register */
 	rbnode->block = blk;
 	rbnode->blklen = blklen;
 	rbnode->base_reg = base_reg;
+	rbnode->cache_present = present;
 
 	regcache_rbtree_set_register(map, rbnode, pos, value);
 	return 0;
@@ -345,12 +360,21 @@ regcache_rbtree_node_alloc(struct regmap *map, unsigned int reg)
 
 	rbnode->block = kmalloc(rbnode->blklen * map->cache_word_size,
 				GFP_KERNEL);
-	if (!rbnode->block) {
-		kfree(rbnode);
-		return NULL;
-	}
+	if (!rbnode->block)
+		goto err_free;
+
+	rbnode->cache_present = kzalloc(BITS_TO_LONGS(rbnode->blklen) *
+		sizeof(*rbnode->cache_present), GFP_KERNEL);
+	if (!rbnode->cache_present)
+		goto err_free_block;
 
 	return rbnode;
+
+err_free_block:
+	kfree(rbnode->block);
+err_free:
+	kfree(rbnode);
+	return NULL;
 }
 
 static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
@@ -363,10 +387,6 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 	int ret;
 
 	rbtree_ctx = map->cache;
-	/* update the reg_present bitmap, make space if necessary */
-	ret = regcache_set_reg_present(map, reg);
-	if (ret < 0)
-		return ret;
 
 	/* if we can't locate it in the cached rbnode we'll have
 	 * to traverse the rbtree looking for it.
@@ -461,8 +481,9 @@ static int regcache_rbtree_sync(struct regmap *map, unsigned int min,
 		else
 			end = rbnode->blklen;
 
-		ret = regcache_sync_block(map, rbnode->block, rbnode->base_reg,
-					  start, end);
+		ret = regcache_sync_block(map, rbnode->block,
+					  rbnode->cache_present,
+					  rbnode->base_reg, start, end);
 		if (ret != 0)
 			return ret;
 	}
@@ -470,6 +491,42 @@ static int regcache_rbtree_sync(struct regmap *map, unsigned int min,
 	return regmap_async_complete(map);
 }
 
+static int regcache_rbtree_drop(struct regmap *map, unsigned int min,
+				unsigned int max)
+{
+	struct regcache_rbtree_ctx *rbtree_ctx;
+	struct regcache_rbtree_node *rbnode;
+	struct rb_node *node;
+	unsigned int base_reg, top_reg;
+	unsigned int start, end;
+
+	rbtree_ctx = map->cache;
+	for (node = rb_first(&rbtree_ctx->root); node; node = rb_next(node)) {
+		rbnode = rb_entry(node, struct regcache_rbtree_node, node);
+
+		regcache_rbtree_get_base_top_reg(map, rbnode, &base_reg,
+			&top_reg);
+		if (base_reg > max)
+			break;
+		if (top_reg < min)
+			continue;
+
+		if (min > base_reg)
+			start = (min - base_reg) / map->reg_stride;
+		else
+			start = 0;
+
+		if (max < top_reg)
+			end = (max - base_reg) / map->reg_stride + 1;
+		else
+			end = rbnode->blklen;
+
+		bitmap_clear(rbnode->cache_present, start, end - start);
+	}
+
+	return 0;
+}
+
 struct regcache_ops regcache_rbtree_ops = {
 	.type = REGCACHE_RBTREE,
 	.name = "rbtree",
@@ -477,5 +534,6 @@ struct regcache_ops regcache_rbtree_ops = {
 	.exit = regcache_rbtree_exit,
 	.read = regcache_rbtree_read,
 	.write = regcache_rbtree_write,
-	.sync = regcache_rbtree_sync
+	.sync = regcache_rbtree_sync,
+	.drop = regcache_rbtree_drop,
 };

commit 472fdec7380cec483e241fa696d9b90bc37ddd4c
Author: Lars-Peter Clausen <lars@metafoo.de>
Date:   Thu Aug 29 10:26:33 2013 +0200

    regmap: rbtree: Reduce number of nodes, take 2
    
    Support for reducing the number of nodes and memory consumption of the rbtree
    cache by allowing for small unused holes in the node's register cache block was
    initially added in commit 0c7ed856 ("regmap: Cut down on the average # of nodes
    in the rbtree cache"). But the commit had problems and so its effect was
    reverted again in commit 4e67fb5 ("regmap: rbtree: Fix overlapping rbnodes.").
    This patch brings the feature back of reducing the average number of nodes,
    which will speedup node look-up, while at the same time also reducing the memory
    usage of the rbtree cache. This patch takes a slightly different approach than
    the original patch though. It modifies the adjacent node look-up to not only
    consider nodes that are just one to the left or the right of the register but
    any node that falls in a certain range around the register. The range is
    calculated based on how much memory it would take to allocate a new node
    compared to how much memory it takes adding a set of unused registers to an
    existing node. E.g. if a node takes up 24 bytes and each register in a block
    uses 1 byte the range will be from the register address - 24 to the register
    address + 24. If we find a node that falls within this range it is cheaper or as
    expensive to add the register to the existing node and have a couple of unused
    registers in the node's cache compared to allocating a new node.
    
    Signed-off-by: Lars-Peter Clausen <lars@metafoo.de>
    Signed-off-by: Mark Brown <broonie@linaro.org>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index dbe5ea12c79b..c06478c364b6 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -278,27 +278,34 @@ static int regcache_rbtree_read(struct regmap *map,
 
 static int regcache_rbtree_insert_to_block(struct regmap *map,
 					   struct regcache_rbtree_node *rbnode,
-					   unsigned int pos, unsigned int reg,
+					   unsigned int base_reg,
+					   unsigned int top_reg,
+					   unsigned int reg,
 					   unsigned int value)
 {
+	unsigned int blklen;
+	unsigned int pos, offset;
 	u8 *blk;
 
+	blklen = (top_reg - base_reg) / map->reg_stride + 1;
+	pos = (reg - base_reg) / map->reg_stride;
+	offset = (rbnode->base_reg - base_reg) / map->reg_stride;
+
 	blk = krealloc(rbnode->block,
-		       (rbnode->blklen + 1) * map->cache_word_size,
+		       blklen * map->cache_word_size,
 		       GFP_KERNEL);
 	if (!blk)
 		return -ENOMEM;
 
 	/* insert the register value in the correct place in the rbnode block */
-	memmove(blk + (pos + 1) * map->cache_word_size,
-		blk + pos * map->cache_word_size,
-		(rbnode->blklen - pos) * map->cache_word_size);
+	if (pos == 0)
+		memmove(blk + offset * map->cache_word_size,
+			blk, rbnode->blklen * map->cache_word_size);
 
 	/* update the rbnode block, its size and the base register */
 	rbnode->block = blk;
-	rbnode->blklen++;
-	if (!pos)
-		rbnode->base_reg = reg;
+	rbnode->blklen = blklen;
+	rbnode->base_reg = base_reg;
 
 	regcache_rbtree_set_register(map, rbnode, pos, value);
 	return 0;
@@ -352,9 +359,7 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 	struct regcache_rbtree_ctx *rbtree_ctx;
 	struct regcache_rbtree_node *rbnode, *rbnode_tmp;
 	struct rb_node *node;
-	unsigned int base_reg, top_reg;
 	unsigned int reg_tmp;
-	unsigned int pos;
 	int ret;
 
 	rbtree_ctx = map->cache;
@@ -371,6 +376,19 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 		reg_tmp = (reg - rbnode->base_reg) / map->reg_stride;
 		regcache_rbtree_set_register(map, rbnode, reg_tmp, value);
 	} else {
+		unsigned int base_reg, top_reg;
+		unsigned int new_base_reg, new_top_reg;
+		unsigned int min, max;
+		unsigned int max_dist;
+
+		max_dist = map->reg_stride * sizeof(*rbnode_tmp) /
+			map->cache_word_size;
+		if (reg < max_dist)
+			min = 0;
+		else
+			min = reg - max_dist;
+		max = reg + max_dist;
+
 		/* look for an adjacent register to the one we are about to add */
 		for (node = rb_first(&rbtree_ctx->root); node;
 		     node = rb_next(node)) {
@@ -380,16 +398,17 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 			regcache_rbtree_get_base_top_reg(map, rbnode_tmp,
 				&base_reg, &top_reg);
 
-			/* decide where in the block to place our register */
-			if (base_reg > 0 && reg == base_reg - map->reg_stride)
-				pos = 0;
-			else if (reg > 0 && reg - map->reg_stride == top_reg)
-				pos = rbnode_tmp->blklen;
-			else
+			if (base_reg <= max && top_reg >= min) {
+				new_base_reg = min(reg, base_reg);
+				new_top_reg = max(reg, top_reg);
+			} else {
 				continue;
+			}
 
 			ret = regcache_rbtree_insert_to_block(map, rbnode_tmp,
-							      pos, reg, value);
+							      new_base_reg,
+							      new_top_reg, reg,
+							      value);
 			if (ret)
 				return ret;
 			rbtree_ctx->cached_rbnode = rbnode_tmp;

commit 194c753a214ba7f1497552dd530021884d164146
Author: Lars-Peter Clausen <lars@metafoo.de>
Date:   Thu Aug 29 10:26:32 2013 +0200

    regmap: rbtree: Simplify adjacent node look-up
    
    A register which is adjacent to a node will either be left to the first
    register or right to the last register. It will not be within the node's range,
    so there is no point in checking for each register cached by the node whether
    the new register is next to it. It is sufficient to check whether the register
    comes before the first register or after the last register of the node.
    
    Signed-off-by: Lars-Peter Clausen <lars@metafoo.de>
    Signed-off-by: Mark Brown <broonie@linaro.org>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index f2384a816cc4..dbe5ea12c79b 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -352,9 +352,9 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 	struct regcache_rbtree_ctx *rbtree_ctx;
 	struct regcache_rbtree_node *rbnode, *rbnode_tmp;
 	struct rb_node *node;
+	unsigned int base_reg, top_reg;
 	unsigned int reg_tmp;
 	unsigned int pos;
-	int i;
 	int ret;
 
 	rbtree_ctx = map->cache;
@@ -376,25 +376,24 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 		     node = rb_next(node)) {
 			rbnode_tmp = rb_entry(node, struct regcache_rbtree_node,
 					      node);
-			for (i = 0; i < rbnode_tmp->blklen; i++) {
-				reg_tmp = rbnode_tmp->base_reg +
-						(i * map->reg_stride);
-				if (abs(reg_tmp - reg) != map->reg_stride)
-					continue;
-				/* decide where in the block to place our register */
-				if (reg_tmp + map->reg_stride == reg)
-					pos = i + 1;
-				else
-					pos = i;
-				ret = regcache_rbtree_insert_to_block(map,
-								      rbnode_tmp,
-								      pos, reg,
-								      value);
-				if (ret)
-					return ret;
-				rbtree_ctx->cached_rbnode = rbnode_tmp;
-				return 0;
-			}
+
+			regcache_rbtree_get_base_top_reg(map, rbnode_tmp,
+				&base_reg, &top_reg);
+
+			/* decide where in the block to place our register */
+			if (base_reg > 0 && reg == base_reg - map->reg_stride)
+				pos = 0;
+			else if (reg > 0 && reg - map->reg_stride == top_reg)
+				pos = rbnode_tmp->blklen;
+			else
+				continue;
+
+			ret = regcache_rbtree_insert_to_block(map, rbnode_tmp,
+							      pos, reg, value);
+			if (ret)
+				return ret;
+			rbtree_ctx->cached_rbnode = rbnode_tmp;
+			return 0;
 		}
 
 		/* We did not manage to find a place to insert it in

commit b6752123ccef4eec3c70c20dbdfc05d1674319c5
Author: Lars-Peter Clausen <lars@metafoo.de>
Date:   Tue Aug 27 13:03:03 2013 +0200

    regcache-rbtree: Fix reg_stride != 1
    
    There are a couple of calculations, which convert between register addresses and
    block indices, in regcache_rbtree_sync() and regcache_rbtree_node_alloc() which
    assume that reg_stride is 1. This will break the rb cache for configurations
    which do not use a reg_stride of 1.
    
    Also rename 'base' in regcache_rbtree_sync() to 'start' to avoid confusion with
    'base_reg'.
    
    Signed-off-by: Lars-Peter Clausen <lars@metafoo.de>
    Signed-off-by: Mark Brown <broonie@linaro.org>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 5c1435c4e210..f2384a816cc4 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -325,8 +325,8 @@ regcache_rbtree_node_alloc(struct regmap *map, unsigned int reg)
 
 		if (i != map->rd_table->n_yes_ranges) {
 			range = &map->rd_table->yes_ranges[i];
-			rbnode->blklen = range->range_max - range->range_min
-				+ 1;
+			rbnode->blklen = (range->range_max - range->range_min) /
+				map->reg_stride	+ 1;
 			rbnode->base_reg = range->range_min;
 		}
 	}
@@ -418,30 +418,33 @@ static int regcache_rbtree_sync(struct regmap *map, unsigned int min,
 	struct regcache_rbtree_ctx *rbtree_ctx;
 	struct rb_node *node;
 	struct regcache_rbtree_node *rbnode;
+	unsigned int base_reg, top_reg;
+	unsigned int start, end;
 	int ret;
-	int base, end;
 
 	rbtree_ctx = map->cache;
 	for (node = rb_first(&rbtree_ctx->root); node; node = rb_next(node)) {
 		rbnode = rb_entry(node, struct regcache_rbtree_node, node);
 
-		if (rbnode->base_reg > max)
+		regcache_rbtree_get_base_top_reg(map, rbnode, &base_reg,
+			&top_reg);
+		if (base_reg > max)
 			break;
-		if (rbnode->base_reg + rbnode->blklen < min)
+		if (top_reg < min)
 			continue;
 
-		if (min > rbnode->base_reg)
-			base = min - rbnode->base_reg;
+		if (min > base_reg)
+			start = (min - base_reg) / map->reg_stride;
 		else
-			base = 0;
+			start = 0;
 
-		if (max < rbnode->base_reg + rbnode->blklen)
-			end = max - rbnode->base_reg + 1;
+		if (max < top_reg)
+			end = (max - base_reg) / map->reg_stride + 1;
 		else
 			end = rbnode->blklen;
 
 		ret = regcache_sync_block(map, rbnode->block, rbnode->base_reg,
-					  base, end);
+					  start, end);
 		if (ret != 0)
 			return ret;
 	}

commit 4e67fb5f5e336250db944921e3c68057d6203034
Author: David Jander <david@protonic.nl>
Date:   Wed Aug 21 17:37:22 2013 +0200

    regmap: rbtree: Fix overlapping rbnodes.
    
    Avoid overlapping register regions by making the initial blklen of a new
    node 1. If a register write occurs to a yet uncached register, that is
    lower than but near an existing node's base_reg, a new node is created
    and it's blklen is set to an arbitrary value (sizeof(*rbnode)). That may
    cause this node to overlap with another node. Those nodes should be merged,
    but this merge doesn't happen yet, so this patch at least makes the initial
    blklen small enough to avoid hitting the wrong node, which may otherwise
    lead to severe breakage.
    
    Signed-off-by: David Jander <david@protonic.nl>
    Signed-off-by: Mark Brown <broonie@linaro.org>
    Cc: stable@vger.kernel.org

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 5c1435c4e210..0fccc99881fd 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -332,7 +332,7 @@ regcache_rbtree_node_alloc(struct regmap *map, unsigned int reg)
 	}
 
 	if (!rbnode->blklen) {
-		rbnode->blklen = sizeof(*rbnode);
+		rbnode->blklen = 1;
 		rbnode->base_reg = reg;
 	}
 

commit feff98f5507f98c0422252caec41c3be9e6b6399
Merge: 9e895ace5d82 d6814a7dafa5
Author: Mark Brown <broonie@linaro.org>
Date:   Sun Jun 30 12:40:01 2013 +0100

    Merge remote-tracking branch 'regmap/topic/cache' into regmap-next

commit f3284f91535cc2e1406b7efe27a1de96c96c19b4
Author: Maarten ter Huurne <maarten@treewalker.org>
Date:   Fri May 31 16:45:13 2013 +0200

    regmap: rbtree: Fixed node range check on sync
    
    A node starting before the minimum register is no reason to reject it,
    since its end could be in range. The check for the end already exists
    two lines lower, so we can just remove the incorrect check.
    
    Signed-off-by: Maarten ter Huurne <maarten@treewalker.org>
    Signed-off-by: Mark Brown <broonie@linaro.org>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index b4e343b64c83..02f490bad30f 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -391,8 +391,6 @@ static int regcache_rbtree_sync(struct regmap *map, unsigned int min,
 	for (node = rb_first(&rbtree_ctx->root); node; node = rb_next(node)) {
 		rbnode = rb_entry(node, struct regcache_rbtree_node, node);
 
-		if (rbnode->base_reg < min)
-			continue;
 		if (rbnode->base_reg > max)
 			break;
 		if (rbnode->base_reg + rbnode->blklen < min)

commit f20c783c3ae33c30fd7cf0616db18d30cb6e802b
Author: Lars-Peter Clausen <lars@metafoo.de>
Date:   Thu May 23 17:23:49 2013 +0200

    regmap: regcache: Fixup locking for custom lock callbacks
    
    The parameter passed to the regmap lock/unlock callbacks needs to be
    map->lock_arg, regcache passes just map. This works fine in the case that no
    custom locking callbacks are used since in this case map->lock_arg equals map,
    but will break when custom locking callbacks are used. The issue was introduced
    in commit 0d4529c5("regmap: make lock/unlock functions customizable") and is
    fixed by this patch.
    
    Signed-off-by: Lars-Peter Clausen <lars@metafoo.de>
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index aa0875f6f1b7..b4e343b64c83 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -143,7 +143,7 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 	int registers = 0;
 	int this_registers, average;
 
-	map->lock(map);
+	map->lock(map->lock_arg);
 
 	mem_size = sizeof(*rbtree_ctx);
 	mem_size += BITS_TO_LONGS(map->cache_present_nbits) * sizeof(long);
@@ -170,7 +170,7 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 	seq_printf(s, "%d nodes, %d registers, average %d registers, used %zu bytes\n",
 		   nodes, registers, average, mem_size);
 
-	map->unlock(map);
+	map->unlock(map->lock_arg);
 
 	return 0;
 }

commit 81485f5220770c381ac076573642ac44f13723af
Author: Lars-Peter Clausen <lars@metafoo.de>
Date:   Thu May 23 15:06:15 2013 +0200

    regmap: regcache: Fixup locking for custom lock callbacks
    
    The parameter passed to the regmap lock/unlock callbacks needs to be
    map->lock_arg, regcache passes just map. This works fine in the case that no
    custom locking callbacks are used, since in this case map->lock_arg equals map,
    but will break when custom locking callbacks are used. The issue was introduced
    in commit 0d4529c5 ("regmap: make lock/unlock functions customizable") and is
    fixed by this patch.
    
    Signed-off-by: Lars-Peter Clausen <lars@metafoo.de>
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 4e131c5df844..69b443f204ac 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -143,7 +143,7 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 	int registers = 0;
 	int this_registers, average;
 
-	map->lock(map);
+	map->lock(map->lock_arg);
 
 	mem_size = sizeof(*rbtree_ctx);
 	mem_size += BITS_TO_LONGS(map->cache_present_nbits) * sizeof(long);
@@ -170,7 +170,7 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 	seq_printf(s, "%d nodes, %d registers, average %d registers, used %zu bytes\n",
 		   nodes, registers, average, mem_size);
 
-	map->unlock(map);
+	map->unlock(map->lock_arg);
 
 	return 0;
 }

commit 7278af5fb3eb7247449fd4489dacb75b9ba86f73
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Wed May 8 13:55:25 2013 +0100

    regmap: rbtree: Use range information to allocate nodes
    
    If range information has been provided then when we allocate a rbnode
    within a range allocate the entire range. The goal is to minimise the
    number of reallocations done when combining or extending blocks. At
    present only readability and yes_ranges are taken into account, this is
    expected to cover most cases efficiently.
    
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 3a000145ac6e..4e131c5df844 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -308,13 +308,34 @@ static struct regcache_rbtree_node *
 regcache_rbtree_node_alloc(struct regmap *map, unsigned int reg)
 {
 	struct regcache_rbtree_node *rbnode;
+	const struct regmap_range *range;
+	int i;
 
 	rbnode = kzalloc(sizeof(*rbnode), GFP_KERNEL);
 	if (!rbnode)
 		return NULL;
 
-	rbnode->blklen = sizeof(*rbnode);
-	rbnode->base_reg = reg;
+	/* If there is a read table then use it to guess at an allocation */
+	if (map->rd_table) {
+		for (i = 0; i < map->rd_table->n_yes_ranges; i++) {
+			if (regmap_reg_in_range(reg,
+						&map->rd_table->yes_ranges[i]))
+				break;
+		}
+
+		if (i != map->rd_table->n_yes_ranges) {
+			range = &map->rd_table->yes_ranges[i];
+			rbnode->blklen = range->range_max - range->range_min
+				+ 1;
+			rbnode->base_reg = range->range_min;
+		}
+	}
+
+	if (!rbnode->blklen) {
+		rbnode->blklen = sizeof(*rbnode);
+		rbnode->base_reg = reg;
+	}
+
 	rbnode->block = kmalloc(rbnode->blklen * map->cache_word_size,
 				GFP_KERNEL);
 	if (!rbnode->block) {

commit 0186645d2549f94c3a8067c97cad261c678d6718
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Wed May 8 13:55:24 2013 +0100

    regmap: rbtree: Factor out node allocation
    
    In preparation for being slightly smarter about how we allocate memory
    factor out the node allocation.
    
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index aa0875f6f1b7..3a000145ac6e 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -304,6 +304,27 @@ static int regcache_rbtree_insert_to_block(struct regmap *map,
 	return 0;
 }
 
+static struct regcache_rbtree_node *
+regcache_rbtree_node_alloc(struct regmap *map, unsigned int reg)
+{
+	struct regcache_rbtree_node *rbnode;
+
+	rbnode = kzalloc(sizeof(*rbnode), GFP_KERNEL);
+	if (!rbnode)
+		return NULL;
+
+	rbnode->blklen = sizeof(*rbnode);
+	rbnode->base_reg = reg;
+	rbnode->block = kmalloc(rbnode->blklen * map->cache_word_size,
+				GFP_KERNEL);
+	if (!rbnode->block) {
+		kfree(rbnode);
+		return NULL;
+	}
+
+	return rbnode;
+}
+
 static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 				 unsigned int value)
 {
@@ -354,23 +375,15 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 				return 0;
 			}
 		}
-		/* we did not manage to find a place to insert it in an existing
-		 * block so create a new rbnode with a single register in its block.
-		 * This block will get populated further if any other adjacent
-		 * registers get modified in the future.
+
+		/* We did not manage to find a place to insert it in
+		 * an existing block so create a new rbnode.
 		 */
-		rbnode = kzalloc(sizeof *rbnode, GFP_KERNEL);
+		rbnode = regcache_rbtree_node_alloc(map, reg);
 		if (!rbnode)
 			return -ENOMEM;
-		rbnode->blklen = sizeof(*rbnode);
-		rbnode->base_reg = reg;
-		rbnode->block = kmalloc(rbnode->blklen * map->cache_word_size,
-					GFP_KERNEL);
-		if (!rbnode->block) {
-			kfree(rbnode);
-			return -ENOMEM;
-		}
-		regcache_rbtree_set_register(map, rbnode, 0, value);
+		regcache_rbtree_set_register(map, rbnode,
+					     reg - rbnode->base_reg, value);
 		regcache_rbtree_insert(map, &rbtree_ctx->root, rbnode);
 		rbtree_ctx->cached_rbnode = rbnode;
 	}

commit 60f7110e36ff7858182e8990a2d19fa3df7e05f5
Merge: 9659293c1784 41ef2d5678d8
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Tue Apr 16 16:02:41 2013 +0100

    Merge tag 'v3.9-rc7' into regmap-cache
    
    Linux 3.9-rc7

commit f8bd822cbf953299b2957b45f6a43c08e7931ddc
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Fri Mar 29 19:32:28 2013 +0000

    regmap: cache: Factor out block sync
    
    The idea of holding blocks of registers in device format is shared between
    at least rbtree and lzo cache formats so split out the loop that does the
    sync from the rbtree code so optimisations on it can be reused.
    
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>
    Reviewed-by: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 00c3506f542f..1fdd8ec6af23 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -53,12 +53,6 @@ static unsigned int regcache_rbtree_get_register(struct regmap *map,
 	return regcache_get_val(map, rbnode->block, idx);
 }
 
-static const void *regcache_rbtree_get_reg_addr(struct regmap *map,
-	struct regcache_rbtree_node *rbnode, unsigned int idx)
-{
-	return regcache_get_val_addr(map, rbnode->block, idx);
-}
-
 static void regcache_rbtree_set_register(struct regmap *map,
 					 struct regcache_rbtree_node *rbnode,
 					 unsigned int idx, unsigned int val)
@@ -390,11 +384,8 @@ static int regcache_rbtree_sync(struct regmap *map, unsigned int min,
 	struct regcache_rbtree_ctx *rbtree_ctx;
 	struct rb_node *node;
 	struct regcache_rbtree_node *rbnode;
-	unsigned int regtmp;
-	unsigned int val;
-	const void *addr;
 	int ret;
-	int i, base, end;
+	int base, end;
 
 	rbtree_ctx = map->cache;
 	for (node = rb_first(&rbtree_ctx->root); node; node = rb_next(node)) {
@@ -417,40 +408,13 @@ static int regcache_rbtree_sync(struct regmap *map, unsigned int min,
 		else
 			end = rbnode->blklen;
 
-		for (i = base; i < end; i++) {
-			regtmp = rbnode->base_reg + (i * map->reg_stride);
-
-			if (!regcache_reg_present(map, regtmp))
-				continue;
-
-			val = regcache_rbtree_get_register(map, rbnode, i);
-
-			/* Is this the hardware default?  If so skip. */
-			ret = regcache_lookup_reg(map, regtmp);
-			if (ret >= 0 && val == map->reg_defaults[ret].def)
-				continue;
-
-			map->cache_bypass = 1;
-
-			if (regmap_can_raw_write(map)) {
-				addr = regcache_rbtree_get_reg_addr(map,
-								    rbnode, i);
-				ret = _regmap_raw_write(map, regtmp, addr,
-							map->format.val_bytes,
-							false);
-			} else {
-				ret = _regmap_write(map, regtmp, val);
-			}
-
-			map->cache_bypass = 0;
-			if (ret)
-				return ret;
-			dev_dbg(map->dev, "Synced register %#x, value %#x\n",
-				regtmp, val);
-		}
+		ret = regcache_sync_block(map, rbnode->block, rbnode->base_reg,
+					  base, end);
+		if (ret != 0)
+			return ret;
 	}
 
-	return 0;
+	return regmap_async_complete(map);
 }
 
 struct regcache_ops regcache_rbtree_ops = {

commit 78493f2d7b51d6f6d03982cee559c62dfab4c292
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Fri Mar 29 19:18:59 2013 +0000

    regmap: cache: Factor out reg_present support from rbtree cache
    
    The idea of maintaining a bitmap of present registers is something that
    can usefully be used by other cache types that maintain blocks of cached
    registers so move the code out of the rbtree cache and into the generic
    regcache code.
    
    Refactor the interface slightly as we go to wrap the set bit and enlarge
    bitmap operations (since we never do one without the other) and make it
    more robust for reads of uncached registers by bounds checking before we
    look at the bitmap.
    
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>
    Reviewed-by: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 382a6deb3ca8..00c3506f542f 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -36,8 +36,6 @@ struct regcache_rbtree_node {
 struct regcache_rbtree_ctx {
 	struct rb_root root;
 	struct regcache_rbtree_node *cached_rbnode;
-	unsigned long *reg_present;
-	unsigned int reg_present_nbits;
 };
 
 static inline void regcache_rbtree_get_base_top_reg(
@@ -154,7 +152,7 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 	map->lock(map);
 
 	mem_size = sizeof(*rbtree_ctx);
-	mem_size += BITS_TO_LONGS(rbtree_ctx->reg_present_nbits) * sizeof(long);
+	mem_size += BITS_TO_LONGS(map->cache_present_nbits) * sizeof(long);
 
 	for (node = rb_first(&rbtree_ctx->root); node != NULL;
 	     node = rb_next(node)) {
@@ -205,44 +203,6 @@ static void rbtree_debugfs_init(struct regmap *map)
 }
 #endif
 
-static int enlarge_reg_present_bitmap(struct regmap *map, unsigned int reg)
-{
-	struct regcache_rbtree_ctx *rbtree_ctx;
-	unsigned long *reg_present;
-	unsigned int reg_present_size;
-	unsigned int nregs;
-	int i;
-
-	rbtree_ctx = map->cache;
-	nregs = reg + 1;
-	reg_present_size = BITS_TO_LONGS(nregs);
-	reg_present_size *= sizeof(long);
-
-	if (!rbtree_ctx->reg_present) {
-		reg_present = kmalloc(reg_present_size, GFP_KERNEL);
-		if (!reg_present)
-			return -ENOMEM;
-		bitmap_zero(reg_present, nregs);
-		rbtree_ctx->reg_present = reg_present;
-		rbtree_ctx->reg_present_nbits = nregs;
-		return 0;
-	}
-
-	if (nregs > rbtree_ctx->reg_present_nbits) {
-		reg_present = krealloc(rbtree_ctx->reg_present,
-				       reg_present_size, GFP_KERNEL);
-		if (!reg_present)
-			return -ENOMEM;
-		for (i = 0; i < nregs; i++)
-			if (i >= rbtree_ctx->reg_present_nbits)
-				clear_bit(i, reg_present);
-		rbtree_ctx->reg_present = reg_present;
-		rbtree_ctx->reg_present_nbits = nregs;
-	}
-
-	return 0;
-}
-
 static int regcache_rbtree_init(struct regmap *map)
 {
 	struct regcache_rbtree_ctx *rbtree_ctx;
@@ -256,8 +216,6 @@ static int regcache_rbtree_init(struct regmap *map)
 	rbtree_ctx = map->cache;
 	rbtree_ctx->root = RB_ROOT;
 	rbtree_ctx->cached_rbnode = NULL;
-	rbtree_ctx->reg_present = NULL;
-	rbtree_ctx->reg_present_nbits = 0;
 
 	for (i = 0; i < map->num_reg_defaults; i++) {
 		ret = regcache_rbtree_write(map,
@@ -287,8 +245,6 @@ static int regcache_rbtree_exit(struct regmap *map)
 	if (!rbtree_ctx)
 		return 0;
 
-	kfree(rbtree_ctx->reg_present);
-
 	/* free up the rbtree */
 	next = rb_first(&rbtree_ctx->root);
 	while (next) {
@@ -306,17 +262,6 @@ static int regcache_rbtree_exit(struct regmap *map)
 	return 0;
 }
 
-static int regcache_reg_present(struct regmap *map, unsigned int reg)
-{
-	struct regcache_rbtree_ctx *rbtree_ctx;
-
-	rbtree_ctx = map->cache;
-	if (!(rbtree_ctx->reg_present[BIT_WORD(reg)] & BIT_MASK(reg)))
-		return 0;
-	return 1;
-
-}
-
 static int regcache_rbtree_read(struct regmap *map,
 				unsigned int reg, unsigned int *value)
 {
@@ -378,10 +323,9 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 
 	rbtree_ctx = map->cache;
 	/* update the reg_present bitmap, make space if necessary */
-	ret = enlarge_reg_present_bitmap(map, reg);
+	ret = regcache_set_reg_present(map, reg);
 	if (ret < 0)
 		return ret;
-	set_bit(reg, rbtree_ctx->reg_present);
 
 	/* if we can't locate it in the cached rbnode we'll have
 	 * to traverse the rbtree looking for it.

commit 137b833457864091610ca01d7443a67028a2b3ce
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Tue Mar 26 21:26:19 2013 +0000

    regmap: cache: Use raw I/O to sync rbtrees if we can
    
    This will bring no meaningful benefit by itself, it is done as a separate
    commit to aid bisection if there are problems with the following commits
    adding support for coalescing adjacent writes.
    
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 792a760c8ab1..382a6deb3ca8 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -55,6 +55,12 @@ static unsigned int regcache_rbtree_get_register(struct regmap *map,
 	return regcache_get_val(map, rbnode->block, idx);
 }
 
+static const void *regcache_rbtree_get_reg_addr(struct regmap *map,
+	struct regcache_rbtree_node *rbnode, unsigned int idx)
+{
+	return regcache_get_val_addr(map, rbnode->block, idx);
+}
+
 static void regcache_rbtree_set_register(struct regmap *map,
 					 struct regcache_rbtree_node *rbnode,
 					 unsigned int idx, unsigned int val)
@@ -442,6 +448,7 @@ static int regcache_rbtree_sync(struct regmap *map, unsigned int min,
 	struct regcache_rbtree_node *rbnode;
 	unsigned int regtmp;
 	unsigned int val;
+	const void *addr;
 	int ret;
 	int i, base, end;
 
@@ -480,7 +487,17 @@ static int regcache_rbtree_sync(struct regmap *map, unsigned int min,
 				continue;
 
 			map->cache_bypass = 1;
-			ret = _regmap_write(map, regtmp, val);
+
+			if (regmap_can_raw_write(map)) {
+				addr = regcache_rbtree_get_reg_addr(map,
+								    rbnode, i);
+				ret = _regmap_raw_write(map, regtmp, addr,
+							map->format.val_bytes,
+							false);
+			} else {
+				ret = _regmap_write(map, regtmp, val);
+			}
+
 			map->cache_bypass = 0;
 			if (ret)
 				return ret;

commit 0c7ed8563a0282c032936ae1c667498d59691593
Author: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
Date:   Fri Mar 15 14:54:35 2013 +0000

    regmap: Cut down on the average # of nodes in the rbtree cache
    
    This patch aims to bring down the average number of nodes
    in the rbtree cache and increase the average number of registers
    per node.  This should improve general lookup and traversal times.
    This is achieved by setting the minimum size of a block within the
    rbnode to the size of the rbnode itself.  This will essentially
    cache possibly non-existent registers so to combat this scenario,
    we keep a separate bitmap in memory which keeps track of which register
    exists.  The memory overhead of this change is likely in the order of
    ~5-10%, possibly less depending on the register file layout.  On my test
    system with a bitmap of ~4300 bits and a relatively sparse register
    layout, the memory requirements for the entire cache did not increase
    (the cutting down of nodes which was about 50% of the original number
    compensated the situation).
    
    A second patch that can be built on top of this can look at the
    ratio `sizeof(*rbnode) / map->cache_word_size' in order to suitably
    adjust the block length of each block.
    
    Signed-off-by: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 045319615608..792a760c8ab1 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -36,6 +36,8 @@ struct regcache_rbtree_node {
 struct regcache_rbtree_ctx {
 	struct rb_root root;
 	struct regcache_rbtree_node *cached_rbnode;
+	unsigned long *reg_present;
+	unsigned int reg_present_nbits;
 };
 
 static inline void regcache_rbtree_get_base_top_reg(
@@ -146,6 +148,7 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 	map->lock(map);
 
 	mem_size = sizeof(*rbtree_ctx);
+	mem_size += BITS_TO_LONGS(rbtree_ctx->reg_present_nbits) * sizeof(long);
 
 	for (node = rb_first(&rbtree_ctx->root); node != NULL;
 	     node = rb_next(node)) {
@@ -196,6 +199,44 @@ static void rbtree_debugfs_init(struct regmap *map)
 }
 #endif
 
+static int enlarge_reg_present_bitmap(struct regmap *map, unsigned int reg)
+{
+	struct regcache_rbtree_ctx *rbtree_ctx;
+	unsigned long *reg_present;
+	unsigned int reg_present_size;
+	unsigned int nregs;
+	int i;
+
+	rbtree_ctx = map->cache;
+	nregs = reg + 1;
+	reg_present_size = BITS_TO_LONGS(nregs);
+	reg_present_size *= sizeof(long);
+
+	if (!rbtree_ctx->reg_present) {
+		reg_present = kmalloc(reg_present_size, GFP_KERNEL);
+		if (!reg_present)
+			return -ENOMEM;
+		bitmap_zero(reg_present, nregs);
+		rbtree_ctx->reg_present = reg_present;
+		rbtree_ctx->reg_present_nbits = nregs;
+		return 0;
+	}
+
+	if (nregs > rbtree_ctx->reg_present_nbits) {
+		reg_present = krealloc(rbtree_ctx->reg_present,
+				       reg_present_size, GFP_KERNEL);
+		if (!reg_present)
+			return -ENOMEM;
+		for (i = 0; i < nregs; i++)
+			if (i >= rbtree_ctx->reg_present_nbits)
+				clear_bit(i, reg_present);
+		rbtree_ctx->reg_present = reg_present;
+		rbtree_ctx->reg_present_nbits = nregs;
+	}
+
+	return 0;
+}
+
 static int regcache_rbtree_init(struct regmap *map)
 {
 	struct regcache_rbtree_ctx *rbtree_ctx;
@@ -209,6 +250,8 @@ static int regcache_rbtree_init(struct regmap *map)
 	rbtree_ctx = map->cache;
 	rbtree_ctx->root = RB_ROOT;
 	rbtree_ctx->cached_rbnode = NULL;
+	rbtree_ctx->reg_present = NULL;
+	rbtree_ctx->reg_present_nbits = 0;
 
 	for (i = 0; i < map->num_reg_defaults; i++) {
 		ret = regcache_rbtree_write(map,
@@ -238,6 +281,8 @@ static int regcache_rbtree_exit(struct regmap *map)
 	if (!rbtree_ctx)
 		return 0;
 
+	kfree(rbtree_ctx->reg_present);
+
 	/* free up the rbtree */
 	next = rb_first(&rbtree_ctx->root);
 	while (next) {
@@ -255,6 +300,17 @@ static int regcache_rbtree_exit(struct regmap *map)
 	return 0;
 }
 
+static int regcache_reg_present(struct regmap *map, unsigned int reg)
+{
+	struct regcache_rbtree_ctx *rbtree_ctx;
+
+	rbtree_ctx = map->cache;
+	if (!(rbtree_ctx->reg_present[BIT_WORD(reg)] & BIT_MASK(reg)))
+		return 0;
+	return 1;
+
+}
+
 static int regcache_rbtree_read(struct regmap *map,
 				unsigned int reg, unsigned int *value)
 {
@@ -264,6 +320,8 @@ static int regcache_rbtree_read(struct regmap *map,
 	rbnode = regcache_rbtree_lookup(map, reg);
 	if (rbnode) {
 		reg_tmp = (reg - rbnode->base_reg) / map->reg_stride;
+		if (!regcache_reg_present(map, reg))
+			return -ENOENT;
 		*value = regcache_rbtree_get_register(map, rbnode, reg_tmp);
 	} else {
 		return -ENOENT;
@@ -313,6 +371,12 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 	int ret;
 
 	rbtree_ctx = map->cache;
+	/* update the reg_present bitmap, make space if necessary */
+	ret = enlarge_reg_present_bitmap(map, reg);
+	if (ret < 0)
+		return ret;
+	set_bit(reg, rbtree_ctx->reg_present);
+
 	/* if we can't locate it in the cached rbnode we'll have
 	 * to traverse the rbtree looking for it.
 	 */
@@ -354,7 +418,7 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 		rbnode = kzalloc(sizeof *rbnode, GFP_KERNEL);
 		if (!rbnode)
 			return -ENOMEM;
-		rbnode->blklen = 1;
+		rbnode->blklen = sizeof(*rbnode);
 		rbnode->base_reg = reg;
 		rbnode->block = kmalloc(rbnode->blklen * map->cache_word_size,
 					GFP_KERNEL);
@@ -404,6 +468,10 @@ static int regcache_rbtree_sync(struct regmap *map, unsigned int min,
 
 		for (i = base; i < end; i++) {
 			regtmp = rbnode->base_reg + (i * map->reg_stride);
+
+			if (!regcache_reg_present(map, regtmp))
+				continue;
+
 			val = regcache_rbtree_get_register(map, rbnode, i);
 
 			/* Is this the hardware default?  If so skip. */

commit 8abac3ba51b5525354e9b2ec0eed1c9e95c905d9
Author: Lars-Peter Clausen <lars@metafoo.de>
Date:   Wed Mar 13 16:38:33 2013 +0100

    regmap: cache Fix regcache-rbtree sync
    
    The last register block, which falls into the specified range, is not handled
    correctly. The formula which calculates the number of register which should be
    synced is inverse (and off by one). E.g. if all registers in that block should
    be synced only one is synced, and if only one should be synced all (but one) are
    synced. To calculate the number of registers that need to be synced we need to
    subtract the number of the first register in the block from the max register
    number and add one. This patch updates the code accordingly.
    
    The issue was introduced in commit ac8d91c ("regmap: Supply ranges to the sync
    operations").
    
    Signed-off-by: Lars-Peter Clausen <lars@metafoo.de>
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>
    Cc: stable@vger.kernel.org

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index e6732cf7c06e..79f4fca9877a 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -398,7 +398,7 @@ static int regcache_rbtree_sync(struct regmap *map, unsigned int min,
 			base = 0;
 
 		if (max < rbnode->base_reg + rbnode->blklen)
-			end = rbnode->base_reg + rbnode->blklen - max;
+			end = max - rbnode->base_reg + 1;
 		else
 			end = rbnode->blklen;
 

commit a42277c739c29b06cb27502347f557e11fed8b0e
Author: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
Date:   Tue Mar 12 17:26:49 2013 +0000

    regmap: rbtree Expose total memory consumption in the rbtree debugfs entry
    
    Provide a feel of how much overhead the rbtree cache adds to
    the game.
    
    [Slightly reworded output in debugfs -- broonie]
    
    Signed-off-by: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 461cff888bb1..045319615608 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -138,15 +138,20 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 	struct regcache_rbtree_node *n;
 	struct rb_node *node;
 	unsigned int base, top;
+	size_t mem_size;
 	int nodes = 0;
 	int registers = 0;
 	int this_registers, average;
 
 	map->lock(map);
 
+	mem_size = sizeof(*rbtree_ctx);
+
 	for (node = rb_first(&rbtree_ctx->root); node != NULL;
 	     node = rb_next(node)) {
 		n = container_of(node, struct regcache_rbtree_node, node);
+		mem_size += sizeof(*n);
+		mem_size += (n->blklen * map->cache_word_size);
 
 		regcache_rbtree_get_base_top_reg(map, n, &base, &top);
 		this_registers = ((top - base) / map->reg_stride) + 1;
@@ -161,8 +166,8 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 	else
 		average = 0;
 
-	seq_printf(s, "%d nodes, %d registers, average %d registers\n",
-		   nodes, registers, average);
+	seq_printf(s, "%d nodes, %d registers, average %d registers, used %zu bytes\n",
+		   nodes, registers, average, mem_size);
 
 	map->unlock(map);
 

commit 879082c9fe6e8fbddf787170eee605e4be138d0f
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Thu Feb 21 18:03:13 2013 +0000

    regmap: cache: Pass the map rather than the word size when updating values
    
    It's more idiomatic to pass the map structure around and this means we
    can use other bits of information from the map.
    
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 3f21c6ab296f..461cff888bb1 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -47,22 +47,21 @@ static inline void regcache_rbtree_get_base_top_reg(
 	*top = rbnode->base_reg + ((rbnode->blklen - 1) * map->reg_stride);
 }
 
-static unsigned int regcache_rbtree_get_register(
-	struct regcache_rbtree_node *rbnode, unsigned int idx,
-	unsigned int word_size)
+static unsigned int regcache_rbtree_get_register(struct regmap *map,
+	struct regcache_rbtree_node *rbnode, unsigned int idx)
 {
-	return regcache_get_val(rbnode->block, idx, word_size);
+	return regcache_get_val(map, rbnode->block, idx);
 }
 
-static void regcache_rbtree_set_register(struct regcache_rbtree_node *rbnode,
-					 unsigned int idx, unsigned int val,
-					 unsigned int word_size)
+static void regcache_rbtree_set_register(struct regmap *map,
+					 struct regcache_rbtree_node *rbnode,
+					 unsigned int idx, unsigned int val)
 {
-	regcache_set_val(rbnode->block, idx, val, word_size);
+	regcache_set_val(map, rbnode->block, idx, val);
 }
 
 static struct regcache_rbtree_node *regcache_rbtree_lookup(struct regmap *map,
-	unsigned int reg)
+							   unsigned int reg)
 {
 	struct regcache_rbtree_ctx *rbtree_ctx = map->cache;
 	struct rb_node *node;
@@ -260,8 +259,7 @@ static int regcache_rbtree_read(struct regmap *map,
 	rbnode = regcache_rbtree_lookup(map, reg);
 	if (rbnode) {
 		reg_tmp = (reg - rbnode->base_reg) / map->reg_stride;
-		*value = regcache_rbtree_get_register(rbnode, reg_tmp,
-						      map->cache_word_size);
+		*value = regcache_rbtree_get_register(map, rbnode, reg_tmp);
 	} else {
 		return -ENOENT;
 	}
@@ -270,21 +268,23 @@ static int regcache_rbtree_read(struct regmap *map,
 }
 
 
-static int regcache_rbtree_insert_to_block(struct regcache_rbtree_node *rbnode,
+static int regcache_rbtree_insert_to_block(struct regmap *map,
+					   struct regcache_rbtree_node *rbnode,
 					   unsigned int pos, unsigned int reg,
-					   unsigned int value, unsigned int word_size)
+					   unsigned int value)
 {
 	u8 *blk;
 
 	blk = krealloc(rbnode->block,
-		       (rbnode->blklen + 1) * word_size, GFP_KERNEL);
+		       (rbnode->blklen + 1) * map->cache_word_size,
+		       GFP_KERNEL);
 	if (!blk)
 		return -ENOMEM;
 
 	/* insert the register value in the correct place in the rbnode block */
-	memmove(blk + (pos + 1) * word_size,
-		blk + pos * word_size,
-		(rbnode->blklen - pos) * word_size);
+	memmove(blk + (pos + 1) * map->cache_word_size,
+		blk + pos * map->cache_word_size,
+		(rbnode->blklen - pos) * map->cache_word_size);
 
 	/* update the rbnode block, its size and the base register */
 	rbnode->block = blk;
@@ -292,7 +292,7 @@ static int regcache_rbtree_insert_to_block(struct regcache_rbtree_node *rbnode,
 	if (!pos)
 		rbnode->base_reg = reg;
 
-	regcache_rbtree_set_register(rbnode, pos, value, word_size);
+	regcache_rbtree_set_register(map, rbnode, pos, value);
 	return 0;
 }
 
@@ -314,8 +314,7 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 	rbnode = regcache_rbtree_lookup(map, reg);
 	if (rbnode) {
 		reg_tmp = (reg - rbnode->base_reg) / map->reg_stride;
-		regcache_rbtree_set_register(rbnode, reg_tmp, value,
-					     map->cache_word_size);
+		regcache_rbtree_set_register(map, rbnode, reg_tmp, value);
 	} else {
 		/* look for an adjacent register to the one we are about to add */
 		for (node = rb_first(&rbtree_ctx->root); node;
@@ -332,9 +331,10 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 					pos = i + 1;
 				else
 					pos = i;
-				ret = regcache_rbtree_insert_to_block(rbnode_tmp, pos,
-								      reg, value,
-								      map->cache_word_size);
+				ret = regcache_rbtree_insert_to_block(map,
+								      rbnode_tmp,
+								      pos, reg,
+								      value);
 				if (ret)
 					return ret;
 				rbtree_ctx->cached_rbnode = rbnode_tmp;
@@ -357,7 +357,7 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 			kfree(rbnode);
 			return -ENOMEM;
 		}
-		regcache_rbtree_set_register(rbnode, 0, value, map->cache_word_size);
+		regcache_rbtree_set_register(map, rbnode, 0, value);
 		regcache_rbtree_insert(map, &rbtree_ctx->root, rbnode);
 		rbtree_ctx->cached_rbnode = rbnode;
 	}
@@ -399,8 +399,7 @@ static int regcache_rbtree_sync(struct regmap *map, unsigned int min,
 
 		for (i = base; i < end; i++) {
 			regtmp = rbnode->base_reg + (i * map->reg_stride);
-			val = regcache_rbtree_get_register(rbnode, i,
-							   map->cache_word_size);
+			val = regcache_rbtree_get_register(map, rbnode, i);
 
 			/* Is this the hardware default?  If so skip. */
 			ret = regcache_lookup_reg(map, regtmp);

commit 66baf407571662f7e2a22dd0764cbe279559446c
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Thu Feb 21 18:01:54 2013 +0000

    regmap: rbtree: Don't bother checking for noop updates
    
    If we're updating a value in place it's more work to read the value and
    compare the value with what we're about to set than it is to just write
    the value into the cache; there are no further operations after writing
    in the code even though there's an early return here.
    
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index e6732cf7c06e..3f21c6ab296f 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -302,7 +302,6 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 	struct regcache_rbtree_ctx *rbtree_ctx;
 	struct regcache_rbtree_node *rbnode, *rbnode_tmp;
 	struct rb_node *node;
-	unsigned int val;
 	unsigned int reg_tmp;
 	unsigned int pos;
 	int i;
@@ -315,10 +314,6 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 	rbnode = regcache_rbtree_lookup(map, reg);
 	if (rbnode) {
 		reg_tmp = (reg - rbnode->base_reg) / map->reg_stride;
-		val = regcache_rbtree_get_register(rbnode, reg_tmp,
-						   map->cache_word_size);
-		if (val == value)
-			return 0;
 		regcache_rbtree_set_register(rbnode, reg_tmp, value,
 					     map->cache_word_size);
 	} else {

commit f01ee60fffa4dc6c77122121233a793f7f696e67
Author: Stephen Warren <swarren@nvidia.com>
Date:   Mon Apr 9 13:40:24 2012 -0600

    regmap: implement register striding
    
    regmap_config.reg_stride is introduced. All extant register addresses
    are a multiple of this value. Users of serial-oriented regmap busses will
    typically set this to 1. Users of the MMIO regmap bus will typically set
    this based on the value size of their registers, in bytes, so 4 for a
    32-bit register.
    
    Throughout the regmap code, actual register addresses are used. Wherever
    the register address is used to index some array of values, the address
    is divided by the stride to determine the index, or vice-versa. Error-
    checking is added to all entry-points for register address data to ensure
    that register addresses actually satisfy the specified stride. The MMIO
    bus ensures that the specified stride is large enough for the register
    size.
    
    Signed-off-by: Stephen Warren <swarren@nvidia.com>
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index e49e71fab184..e6732cf7c06e 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -39,11 +39,12 @@ struct regcache_rbtree_ctx {
 };
 
 static inline void regcache_rbtree_get_base_top_reg(
+	struct regmap *map,
 	struct regcache_rbtree_node *rbnode,
 	unsigned int *base, unsigned int *top)
 {
 	*base = rbnode->base_reg;
-	*top = rbnode->base_reg + rbnode->blklen - 1;
+	*top = rbnode->base_reg + ((rbnode->blklen - 1) * map->reg_stride);
 }
 
 static unsigned int regcache_rbtree_get_register(
@@ -70,7 +71,8 @@ static struct regcache_rbtree_node *regcache_rbtree_lookup(struct regmap *map,
 
 	rbnode = rbtree_ctx->cached_rbnode;
 	if (rbnode) {
-		regcache_rbtree_get_base_top_reg(rbnode, &base_reg, &top_reg);
+		regcache_rbtree_get_base_top_reg(map, rbnode, &base_reg,
+						 &top_reg);
 		if (reg >= base_reg && reg <= top_reg)
 			return rbnode;
 	}
@@ -78,7 +80,8 @@ static struct regcache_rbtree_node *regcache_rbtree_lookup(struct regmap *map,
 	node = rbtree_ctx->root.rb_node;
 	while (node) {
 		rbnode = container_of(node, struct regcache_rbtree_node, node);
-		regcache_rbtree_get_base_top_reg(rbnode, &base_reg, &top_reg);
+		regcache_rbtree_get_base_top_reg(map, rbnode, &base_reg,
+						 &top_reg);
 		if (reg >= base_reg && reg <= top_reg) {
 			rbtree_ctx->cached_rbnode = rbnode;
 			return rbnode;
@@ -92,7 +95,7 @@ static struct regcache_rbtree_node *regcache_rbtree_lookup(struct regmap *map,
 	return NULL;
 }
 
-static int regcache_rbtree_insert(struct rb_root *root,
+static int regcache_rbtree_insert(struct regmap *map, struct rb_root *root,
 				  struct regcache_rbtree_node *rbnode)
 {
 	struct rb_node **new, *parent;
@@ -106,7 +109,7 @@ static int regcache_rbtree_insert(struct rb_root *root,
 		rbnode_tmp = container_of(*new, struct regcache_rbtree_node,
 					  node);
 		/* base and top registers of the current rbnode */
-		regcache_rbtree_get_base_top_reg(rbnode_tmp, &base_reg_tmp,
+		regcache_rbtree_get_base_top_reg(map, rbnode_tmp, &base_reg_tmp,
 						 &top_reg_tmp);
 		/* base register of the rbnode to be added */
 		base_reg = rbnode->base_reg;
@@ -138,7 +141,7 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 	unsigned int base, top;
 	int nodes = 0;
 	int registers = 0;
-	int average;
+	int this_registers, average;
 
 	map->lock(map);
 
@@ -146,11 +149,12 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 	     node = rb_next(node)) {
 		n = container_of(node, struct regcache_rbtree_node, node);
 
-		regcache_rbtree_get_base_top_reg(n, &base, &top);
-		seq_printf(s, "%x-%x (%d)\n", base, top, top - base + 1);
+		regcache_rbtree_get_base_top_reg(map, n, &base, &top);
+		this_registers = ((top - base) / map->reg_stride) + 1;
+		seq_printf(s, "%x-%x (%d)\n", base, top, this_registers);
 
 		nodes++;
-		registers += top - base + 1;
+		registers += this_registers;
 	}
 
 	if (nodes)
@@ -255,7 +259,7 @@ static int regcache_rbtree_read(struct regmap *map,
 
 	rbnode = regcache_rbtree_lookup(map, reg);
 	if (rbnode) {
-		reg_tmp = reg - rbnode->base_reg;
+		reg_tmp = (reg - rbnode->base_reg) / map->reg_stride;
 		*value = regcache_rbtree_get_register(rbnode, reg_tmp,
 						      map->cache_word_size);
 	} else {
@@ -310,7 +314,7 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 	 */
 	rbnode = regcache_rbtree_lookup(map, reg);
 	if (rbnode) {
-		reg_tmp = reg - rbnode->base_reg;
+		reg_tmp = (reg - rbnode->base_reg) / map->reg_stride;
 		val = regcache_rbtree_get_register(rbnode, reg_tmp,
 						   map->cache_word_size);
 		if (val == value)
@@ -321,13 +325,15 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 		/* look for an adjacent register to the one we are about to add */
 		for (node = rb_first(&rbtree_ctx->root); node;
 		     node = rb_next(node)) {
-			rbnode_tmp = rb_entry(node, struct regcache_rbtree_node, node);
+			rbnode_tmp = rb_entry(node, struct regcache_rbtree_node,
+					      node);
 			for (i = 0; i < rbnode_tmp->blklen; i++) {
-				reg_tmp = rbnode_tmp->base_reg + i;
-				if (abs(reg_tmp - reg) != 1)
+				reg_tmp = rbnode_tmp->base_reg +
+						(i * map->reg_stride);
+				if (abs(reg_tmp - reg) != map->reg_stride)
 					continue;
 				/* decide where in the block to place our register */
-				if (reg_tmp + 1 == reg)
+				if (reg_tmp + map->reg_stride == reg)
 					pos = i + 1;
 				else
 					pos = i;
@@ -357,7 +363,7 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 			return -ENOMEM;
 		}
 		regcache_rbtree_set_register(rbnode, 0, value, map->cache_word_size);
-		regcache_rbtree_insert(&rbtree_ctx->root, rbnode);
+		regcache_rbtree_insert(map, &rbtree_ctx->root, rbnode);
 		rbtree_ctx->cached_rbnode = rbnode;
 	}
 
@@ -397,7 +403,7 @@ static int regcache_rbtree_sync(struct regmap *map, unsigned int min,
 			end = rbnode->blklen;
 
 		for (i = base; i < end; i++) {
-			regtmp = rbnode->base_reg + i;
+			regtmp = rbnode->base_reg + (i * map->reg_stride);
 			val = regcache_rbtree_get_register(rbnode, i,
 							   map->cache_word_size);
 

commit c0cc6fe1d09e3f1baecbdf8922473c8e7d3a5317
Merge: 0034102808e0 d939fb9a78b4 851960ba7cb3 abec95adefae
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Tue Apr 10 11:01:07 2012 +0100

    Merge branches 'regmap-core', 'regmap-mmio' and 'regmap-naming' into regmap-stride

commit f4e52e7ffdea791c89494752b175b991090f0920
Merge: a3fac0808513 c04c1b9ee8f3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Apr 7 09:56:00 2012 -0700

    Merge tag 'regmap-3.4-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/broonie/regmap
    
    Pull two more small regmap fixes from Mark Brown:
     - Now we have users for it that aren't running Android it turns out
       that regcache_sync_region() is much more useful to drivers if it's
       exported for use by modules.  Who knew?
     - Make sure we don't divide by zero when doing debugfs dumps of
       rbtrees, not visible up until now because everything was providing at
       least some cache on startup.
    
    * tag 'regmap-3.4-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/broonie/regmap:
      regmap: prevent division by zero in rbtree_show
      regmap: Export regcache_sync_region()

commit bacdbe077342ecc9e7b3e374cc5a41995116706a
Author: Stephen Warren <swarren@nvidia.com>
Date:   Wed Apr 4 15:48:28 2012 -0600

    regmap: introduce fast_io busses, and use a spinlock for them
    
    Some bus types have very fast IO. For these, acquiring a mutex for every
    IO operation is a significant overhead. Allow busses to indicate their IO
    is fast, and enhance regmap to use a spinlock for those busses.
    
    [Currently limited to native endian registers -- broonie]
    
    Signed-off-by: Stephen Warren <swarren@nvidia.com>
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 5157fa04c2f0..cca46007d969 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -139,7 +139,7 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 	int nodes = 0;
 	int registers = 0;
 
-	mutex_lock(&map->lock);
+	map->lock(map);
 
 	for (node = rb_first(&rbtree_ctx->root); node != NULL;
 	     node = rb_next(node)) {
@@ -155,7 +155,7 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 	seq_printf(s, "%d nodes, %d registers, average %d registers\n",
 		   nodes, registers, registers / nodes);
 
-	mutex_unlock(&map->lock);
+	map->unlock(map);
 
 	return 0;
 }

commit c04c1b9ee8f30c7a3a25e20e406247003f634ebe
Author: Stephen Warren <swarren@nvidia.com>
Date:   Wed Apr 4 15:48:33 2012 -0600

    regmap: prevent division by zero in rbtree_show
    
    If there are no nodes in the cache, nodes will be 0, so calculating
    "registers / nodes" will cause division by zero.
    
    Signed-off-by: Stephen Warren <swarren@nvidia.com>
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>
    Cc: stable@vger.kernel.org

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 5157fa04c2f0..ea76a90630bf 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -138,6 +138,7 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 	unsigned int base, top;
 	int nodes = 0;
 	int registers = 0;
+	int average;
 
 	mutex_lock(&map->lock);
 
@@ -152,8 +153,13 @@ static int rbtree_show(struct seq_file *s, void *ignored)
 		registers += top - base + 1;
 	}
 
+	if (nodes)
+		average = registers / nodes;
+	else
+		average = 0;
+
 	seq_printf(s, "%d nodes, %d registers, average %d registers\n",
-		   nodes, registers, registers / nodes);
+		   nodes, registers, average);
 
 	mutex_unlock(&map->lock);
 

commit 4b4e9e43fd210e0cd2a5d29357e7c000e13e08ae
Author: Lars-Peter Clausen <lars@metafoo.de>
Date:   Fri Mar 23 11:04:57 2012 +0100

    regmap: rbtree: Fix register default look-up in sync
    
    The code currently passes the register offset in the current block to
    regcache_lookup_reg. This works fine as long as there is only one block and with
    base register of 0, but in all other cases it will look-up the default for a
    wrong register, which can cause unnecessary register writes. This patch fixes
    it by passing the actual register number to regcache_lookup_reg.
    
    Signed-off-by: Lars-Peter Clausen <lars@metafoo.de>
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>
    Cc: <stable@vger.kernel.org>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 5157fa04c2f0..fb14a6343d4f 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -396,7 +396,7 @@ static int regcache_rbtree_sync(struct regmap *map, unsigned int min,
 							   map->cache_word_size);
 
 			/* Is this the hardware default?  If so skip. */
-			ret = regcache_lookup_reg(map, i);
+			ret = regcache_lookup_reg(map, regtmp);
 			if (ret >= 0 && val == map->reg_defaults[ret].def)
 				continue;
 

commit 250f6715a4112d6686670c5a62ceb9305da94616
Merge: 11bcb32848dd 313162d0b838
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Mar 24 10:41:37 2012 -0700

    Merge tag 'device-for-3.4' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux
    
    Pull <linux/device.h> avoidance patches from Paul Gortmaker:
     "Nearly every subsystem has some kind of header with a proto like:
    
            void foo(struct device *dev);
    
      and yet there is no reason for most of these guys to care about the
      sub fields within the device struct.  This allows us to significantly
      reduce the scope of headers including headers.  For this instance, a
      reduction of about 40% is achieved by replacing the include with the
      simple fact that the device is some kind of a struct.
    
      Unlike the much larger module.h cleanup, this one is simply two
      commits.  One to fix the implicit <linux/device.h> users, and then one
      to delete the device.h includes from the linux/include/ dir wherever
      possible."
    
    * tag 'device-for-3.4' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux:
      device.h: audit and cleanup users in main include dir
      device.h: cleanup users outside of linux/include (C files)

commit 4a6be7bb7474500a69f6d8f25899b8038491bdbb
Merge: 7d9aca39dcac f9353e70bceb
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Wed Mar 14 13:14:24 2012 +0000

    Merge remote-tracking branches 'regmap/topic/patch' and 'regmap/topic/sync' into regmap-next

commit 51990e825431089747f8896244b5c17d3a6423f1
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Sun Jan 22 11:23:42 2012 -0500

    device.h: cleanup users outside of linux/include (C files)
    
    For files that are actively using linux/device.h, make sure
    that they call it out.  This will allow us to clean up some
    of the implicit uses of linux/device.h within include/*
    without introducing build regressions.
    
    Yes, this was created by "cheating" -- i.e. the headers were
    cleaned up, and then the fallout was found and fixed, and then
    the two commits were reordered.  This ensures we don't introduce
    build regressions into the git history.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 32620c4f1683..b487c29a67dc 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -11,6 +11,7 @@
  */
 
 #include <linux/slab.h>
+#include <linux/device.h>
 #include <linux/debugfs.h>
 #include <linux/rbtree.h>
 #include <linux/seq_file.h>

commit f9353e70bcebd00cd182d946083afd7d8eddd259
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Mon Mar 5 23:28:49 2012 +0000

    regmap: Fix rbtree block base in sync
    
    Otherwise we'll end up running with bogus register numbers.
    
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index bae183c6bcb1..313c20f8cc28 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -379,7 +379,7 @@ static int regcache_rbtree_sync(struct regmap *map, unsigned int min,
 		if (rbnode->base_reg + rbnode->blklen < min)
 			continue;
 
-		if (min < rbnode->base_reg + rbnode->blklen)
+		if (min > rbnode->base_reg)
 			base = min - rbnode->base_reg;
 		else
 			base = 0;

commit 994f5db65ef4b83db0321842bd43c6bc0a51f000
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Mon Mar 5 23:31:39 2012 +0000

    regcache: Make sure we sync register 0 in an rbtree cache
    
    Most of the current users have register 0 as a volatile register or don't
    have a register 0 so it's not been apparent that it's not getting synced.
    
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 32620c4f1683..861ad2c81dff 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -377,7 +377,7 @@ static int regcache_rbtree_sync(struct regmap *map)
 
 			/* Is this the hardware default?  If so skip. */
 			ret = regcache_lookup_reg(map, i);
-			if (ret > 0 && val == map->reg_defaults[ret].def)
+			if (ret >= 0 && val == map->reg_defaults[ret].def)
 				continue;
 
 			map->cache_bypass = 1;

commit ac8d91c801905a061ca883dca427a5e19602a1e7
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Thu Feb 23 19:31:04 2012 +0000

    regmap: Supply ranges to the sync operations
    
    In order to allow us to support partial sync operations add minimum and
    maximum register arguments to the sync operation and update the rbtree
    and lzo caches to use this new information. The LZO implementation is
    obviously not good, we could exit the iteration earlier, but there may
    be room for more wide reaching optimisation there.
    
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 32620c4f1683..bae183c6bcb1 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -357,7 +357,8 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 	return 0;
 }
 
-static int regcache_rbtree_sync(struct regmap *map)
+static int regcache_rbtree_sync(struct regmap *map, unsigned int min,
+				unsigned int max)
 {
 	struct regcache_rbtree_ctx *rbtree_ctx;
 	struct rb_node *node;
@@ -365,12 +366,30 @@ static int regcache_rbtree_sync(struct regmap *map)
 	unsigned int regtmp;
 	unsigned int val;
 	int ret;
-	int i;
+	int i, base, end;
 
 	rbtree_ctx = map->cache;
 	for (node = rb_first(&rbtree_ctx->root); node; node = rb_next(node)) {
 		rbnode = rb_entry(node, struct regcache_rbtree_node, node);
-		for (i = 0; i < rbnode->blklen; i++) {
+
+		if (rbnode->base_reg < min)
+			continue;
+		if (rbnode->base_reg > max)
+			break;
+		if (rbnode->base_reg + rbnode->blklen < min)
+			continue;
+
+		if (min < rbnode->base_reg + rbnode->blklen)
+			base = min - rbnode->base_reg;
+		else
+			base = 0;
+
+		if (max < rbnode->base_reg + rbnode->blklen)
+			end = rbnode->base_reg + rbnode->blklen - max;
+		else
+			end = rbnode->blklen;
+
+		for (i = base; i < end; i++) {
 			regtmp = rbnode->base_reg + i;
 			val = regcache_rbtree_get_register(rbnode, i,
 							   map->cache_word_size);

commit cce585ce1ebd5307c9709e24758d5eb8a1e087a7
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Tue Nov 22 11:33:31 2011 +0000

    regmap: Fix rbtreee build when not using debugfs
    
    The debugfs functions don't stub themselves out quite so well as might
    be desirable so provide functions which do do this stubbing.
    
    Reported-by: Uwe Kleine-König <u.kleine-koenig@pengutronix.de>
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 7767cbb8d15a..32620c4f1683 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -170,6 +170,15 @@ static const struct file_operations rbtree_fops = {
 	.llseek		= seq_lseek,
 	.release	= single_release,
 };
+
+static void rbtree_debugfs_init(struct regmap *map)
+{
+	debugfs_create_file("rbtree", 0400, map->debugfs, map, &rbtree_fops);
+}
+#else
+static void rbtree_debugfs_init(struct regmap *map)
+{
+}
 #endif
 
 static int regcache_rbtree_init(struct regmap *map)
@@ -194,7 +203,7 @@ static int regcache_rbtree_init(struct regmap *map)
 			goto err;
 	}
 
-	debugfs_create_file("rbtree", 0400, map->debugfs, map, &rbtree_fops);
+	rbtree_debugfs_init(map);
 
 	return 0;
 

commit bad2ab4b6d938482c2b0bdcf80a8d14dbef4e8f5
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Mon Nov 21 19:44:44 2011 +0000

    regmap: Provide debugfs dump of the rbtree cache data
    
    Show the register ranges we have in each rbtree node in debugfs, plus
    some statistics on how big each node is and the total number of nodes.
    It may also be worth collecting data on the ranges of dirty registers
    to see if there's much mileage in trying to coalesce writes on sync.
    
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index e71320f61d18..7767cbb8d15a 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -11,7 +11,9 @@
  */
 
 #include <linux/slab.h>
+#include <linux/debugfs.h>
 #include <linux/rbtree.h>
+#include <linux/seq_file.h>
 
 #include "internal.h"
 
@@ -125,6 +127,51 @@ static int regcache_rbtree_insert(struct rb_root *root,
 	return 1;
 }
 
+#ifdef CONFIG_DEBUG_FS
+static int rbtree_show(struct seq_file *s, void *ignored)
+{
+	struct regmap *map = s->private;
+	struct regcache_rbtree_ctx *rbtree_ctx = map->cache;
+	struct regcache_rbtree_node *n;
+	struct rb_node *node;
+	unsigned int base, top;
+	int nodes = 0;
+	int registers = 0;
+
+	mutex_lock(&map->lock);
+
+	for (node = rb_first(&rbtree_ctx->root); node != NULL;
+	     node = rb_next(node)) {
+		n = container_of(node, struct regcache_rbtree_node, node);
+
+		regcache_rbtree_get_base_top_reg(n, &base, &top);
+		seq_printf(s, "%x-%x (%d)\n", base, top, top - base + 1);
+
+		nodes++;
+		registers += top - base + 1;
+	}
+
+	seq_printf(s, "%d nodes, %d registers, average %d registers\n",
+		   nodes, registers, registers / nodes);
+
+	mutex_unlock(&map->lock);
+
+	return 0;
+}
+
+static int rbtree_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, rbtree_show, inode->i_private);
+}
+
+static const struct file_operations rbtree_fops = {
+	.open		= rbtree_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+#endif
+
 static int regcache_rbtree_init(struct regmap *map)
 {
 	struct regcache_rbtree_ctx *rbtree_ctx;
@@ -147,6 +194,8 @@ static int regcache_rbtree_init(struct regmap *map)
 			goto err;
 	}
 
+	debugfs_create_file("rbtree", 0400, map->debugfs, map, &rbtree_fops);
+
 	return 0;
 
 err:

commit 462a185c5cea7063348003c1644b70a6f6780f01
Author: Lars-Peter Clausen <lars@metafoo.de>
Date:   Tue Nov 15 13:34:40 2011 +0100

    regmap: Do not call regcache_exit from regcache_rbtree_init error path
    
    Calling regcache_exit from regcache_rbtree_init is first of all a layering
    violation and secondly will cause double frees. regcache_exit will free buffers
    allocated by the core, but the core will also free the same buffers when the
    cacheops init callback returns an error. Thus we end up with a double free.
    Fix this by not calling regcache_exit but only free those buffers which, have
    been allocated in this function.
    
    Signed-off-by: Lars-Peter Clausen <lars@metafoo.de>
    Acked-by: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index e31498499b0f..e71320f61d18 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -17,6 +17,7 @@
 
 static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 				 unsigned int value);
+static int regcache_rbtree_exit(struct regmap *map);
 
 struct regcache_rbtree_node {
 	/* the actual rbtree node holding this block */
@@ -149,7 +150,7 @@ static int regcache_rbtree_init(struct regmap *map)
 	return 0;
 
 err:
-	regcache_exit(map);
+	regcache_rbtree_exit(map);
 	return ret;
 }
 

commit b03622a80d2206c4179d6a41a0dc5cfbdfc853ee
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Sun Oct 9 12:54:25 2011 +0100

    regmap: Ensure rbtree syncs registers set to zero properly
    
    Simplify the check for registers set at their default value by avoiding
    picking a default value in the case where we don't have one. Instead we
    only compare the current value to the current value when we looked one
    up. This fixes the case where we don't have a default stored but the value
    was set to zero when that isn't the chip default.
    
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>
    Acked-by: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 52511f95857a..e31498499b0f 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -304,7 +304,7 @@ static int regcache_rbtree_sync(struct regmap *map)
 	struct rb_node *node;
 	struct regcache_rbtree_node *rbnode;
 	unsigned int regtmp;
-	unsigned int val, def;
+	unsigned int val;
 	int ret;
 	int i;
 
@@ -315,13 +315,12 @@ static int regcache_rbtree_sync(struct regmap *map)
 			regtmp = rbnode->base_reg + i;
 			val = regcache_rbtree_get_register(rbnode, i,
 							   map->cache_word_size);
+
+			/* Is this the hardware default?  If so skip. */
 			ret = regcache_lookup_reg(map, i);
-			if (ret < 0)
-				def = 0;
-			else
-				def = map->reg_defaults[ret].def;
-			if (val == def)
+			if (ret > 0 && val == map->reg_defaults[ret].def)
 				continue;
+
 			map->cache_bypass = 1;
 			ret = _regmap_write(map, regtmp, val);
 			map->cache_bypass = 0;

commit e42c5a9a4230c38ceba0a890b30a2d0dd9314bff
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Sun Oct 9 14:30:02 2011 +0100

    regmap: Allow rbtree to cache zero default values
    
    Ensure that when we start up in cache only mode we can store defaults of
    zero, otherwise if the hardware is unavailable we won't be able to read.
    
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>
    Acked-by: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 887dbce63aff..52511f95857a 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -252,9 +252,6 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 		regcache_rbtree_set_register(rbnode, reg_tmp, value,
 					     map->cache_word_size);
 	} else {
-		/* bail out early, no need to create the rbnode yet */
-		if (!value)
-			return 0;
 		/* look for an adjacent register to the one we are about to add */
 		for (node = rb_first(&rbtree_ctx->root); node;
 		     node = rb_next(node)) {

commit 6e6ace00a045251bd172b9b9c2379857bbff3dc7
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Sun Oct 9 13:23:31 2011 +0100

    regmap: Return a sensible error code if we fail to read the cache
    
    If a register isn't cached then let callers know that so they can fall
    back or error handle appropriately.
    
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>
    Acked-by: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 40f23dd8478c..887dbce63aff 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -193,8 +193,7 @@ static int regcache_rbtree_read(struct regmap *map,
 		*value = regcache_rbtree_get_register(rbnode, reg_tmp,
 						      map->cache_word_size);
 	} else {
-		/* uninitialized registers default to 0 */
-		*value = 0;
+		return -ENOENT;
 	}
 
 	return 0;

commit 13753a9088af23c61e2f5c10a8f3ea136d8ebab5
Author: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
Date:   Thu Sep 29 14:36:25 2011 +0100

    regmap: Lock the sync path, ensure we use the lockless _regmap_write()
    
    Signed-off-by: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index de32ced1917a..40f23dd8478c 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -327,7 +327,7 @@ static int regcache_rbtree_sync(struct regmap *map)
 			if (val == def)
 				continue;
 			map->cache_bypass = 1;
-			ret = regmap_write(map, regtmp, val);
+			ret = _regmap_write(map, regtmp, val);
 			map->cache_bypass = 0;
 			if (ret)
 				return ret;

commit 3405addd220a0cf2e3a8ffb9051afe766e5f52e8
Author: Lars-Peter Clausen <lars@metafoo.de>
Date:   Tue Sep 27 20:15:38 2011 +0200

    regmap: rbtree-cache: Move cached rbnode handling into lookup function
    
    Move the handling of the cached rbnode into regcache_rbtree_lookup. This allows
    us to remove of some duplicated code sections in regcache_rbtree_read and
    regcache_rbtree_write.
    
    Signed-off-by: Lars-Peter Clausen <lars@metafoo.de>
    Acked-by: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 52669dec73b3..de32ced1917a 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -56,23 +56,33 @@ static void regcache_rbtree_set_register(struct regcache_rbtree_node *rbnode,
 	regcache_set_val(rbnode->block, idx, val, word_size);
 }
 
-static struct regcache_rbtree_node *regcache_rbtree_lookup(
-	struct rb_root *root, unsigned int reg)
+static struct regcache_rbtree_node *regcache_rbtree_lookup(struct regmap *map,
+	unsigned int reg)
 {
+	struct regcache_rbtree_ctx *rbtree_ctx = map->cache;
 	struct rb_node *node;
 	struct regcache_rbtree_node *rbnode;
 	unsigned int base_reg, top_reg;
 
-	node = root->rb_node;
+	rbnode = rbtree_ctx->cached_rbnode;
+	if (rbnode) {
+		regcache_rbtree_get_base_top_reg(rbnode, &base_reg, &top_reg);
+		if (reg >= base_reg && reg <= top_reg)
+			return rbnode;
+	}
+
+	node = rbtree_ctx->root.rb_node;
 	while (node) {
 		rbnode = container_of(node, struct regcache_rbtree_node, node);
 		regcache_rbtree_get_base_top_reg(rbnode, &base_reg, &top_reg);
-		if (reg >= base_reg && reg <= top_reg)
+		if (reg >= base_reg && reg <= top_reg) {
+			rbtree_ctx->cached_rbnode = rbnode;
 			return rbnode;
-		else if (reg > top_reg)
+		} else if (reg > top_reg) {
 			node = node->rb_right;
-		else if (reg < base_reg)
+		} else if (reg < base_reg) {
 			node = node->rb_left;
+		}
 	}
 
 	return NULL;
@@ -174,32 +184,14 @@ static int regcache_rbtree_exit(struct regmap *map)
 static int regcache_rbtree_read(struct regmap *map,
 				unsigned int reg, unsigned int *value)
 {
-	struct regcache_rbtree_ctx *rbtree_ctx;
 	struct regcache_rbtree_node *rbnode;
-	unsigned int base_reg, top_reg;
 	unsigned int reg_tmp;
 
-	rbtree_ctx = map->cache;
-	/* look up the required register in the cached rbnode */
-	rbnode = rbtree_ctx->cached_rbnode;
-	if (rbnode) {
-		regcache_rbtree_get_base_top_reg(rbnode, &base_reg, &top_reg);
-		if (reg >= base_reg && reg <= top_reg) {
-			reg_tmp = reg - base_reg;
-			*value = regcache_rbtree_get_register(rbnode, reg_tmp,
-							      map->cache_word_size);
-			return 0;
-		}
-	}
-	/* if we can't locate it in the cached rbnode we'll have
-	 * to traverse the rbtree looking for it.
-	 */
-	rbnode = regcache_rbtree_lookup(&rbtree_ctx->root, reg);
+	rbnode = regcache_rbtree_lookup(map, reg);
 	if (rbnode) {
 		reg_tmp = reg - rbnode->base_reg;
 		*value = regcache_rbtree_get_register(rbnode, reg_tmp,
 						      map->cache_word_size);
-		rbtree_ctx->cached_rbnode = rbnode;
 	} else {
 		/* uninitialized registers default to 0 */
 		*value = 0;
@@ -243,31 +235,15 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 	struct rb_node *node;
 	unsigned int val;
 	unsigned int reg_tmp;
-	unsigned int base_reg, top_reg;
 	unsigned int pos;
 	int i;
 	int ret;
 
 	rbtree_ctx = map->cache;
-	/* look up the required register in the cached rbnode */
-	rbnode = rbtree_ctx->cached_rbnode;
-	if (rbnode) {
-		regcache_rbtree_get_base_top_reg(rbnode, &base_reg, &top_reg);
-		if (reg >= base_reg && reg <= top_reg) {
-			reg_tmp = reg - base_reg;
-			val = regcache_rbtree_get_register(rbnode, reg_tmp,
-							   map->cache_word_size);
-			if (val == value)
-				return 0;
-			regcache_rbtree_set_register(rbnode, reg_tmp, value,
-						     map->cache_word_size);
-			return 0;
-		}
-	}
 	/* if we can't locate it in the cached rbnode we'll have
 	 * to traverse the rbtree looking for it.
 	 */
-	rbnode = regcache_rbtree_lookup(&rbtree_ctx->root, reg);
+	rbnode = regcache_rbtree_lookup(map, reg);
 	if (rbnode) {
 		reg_tmp = reg - rbnode->base_reg;
 		val = regcache_rbtree_get_register(rbnode, reg_tmp,
@@ -276,7 +252,6 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 			return 0;
 		regcache_rbtree_set_register(rbnode, reg_tmp, value,
 					     map->cache_word_size);
-		rbtree_ctx->cached_rbnode = rbnode;
 	} else {
 		/* bail out early, no need to create the rbnode yet */
 		if (!value)

commit c5713004b304e89c8c5117d8f226d5a1603571dc
Author: Lars-Peter Clausen <lars@metafoo.de>
Date:   Tue Sep 27 20:15:37 2011 +0200

    regmap: regcache_rbtree_{set,get}_register: Use regcache_{set,get}_val
    
    Use regcache_{set,get}_val in regcache_rbtree_{set,get}_register instead of
    re-implementing its functionality.
    
    Signed-off-by: Lars-Peter Clausen <lars@metafoo.de>
    Acked-by: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index dd1b937a0d84..52669dec73b3 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -46,45 +46,14 @@ static unsigned int regcache_rbtree_get_register(
 	struct regcache_rbtree_node *rbnode, unsigned int idx,
 	unsigned int word_size)
 {
-	unsigned int val;
-
-	switch (word_size) {
-	case 1: {
-		u8 *p = rbnode->block;
-		val = p[idx];
-		return val;
-	}
-	case 2: {
-		u16 *p = rbnode->block;
-		val = p[idx];
-		return val;
-	}
-	default:
-		BUG();
-		break;
-	}
-	return -1;
+	return regcache_get_val(rbnode->block, idx, word_size);
 }
 
 static void regcache_rbtree_set_register(struct regcache_rbtree_node *rbnode,
 					 unsigned int idx, unsigned int val,
 					 unsigned int word_size)
 {
-	switch (word_size) {
-	case 1: {
-		u8 *p = rbnode->block;
-		p[idx] = val;
-		break;
-	}
-	case 2: {
-		u16 *p = rbnode->block;
-		p[idx] = val;
-		break;
-	}
-	default:
-		BUG();
-		break;
-	}
+	regcache_set_val(rbnode->block, idx, val, word_size);
 }
 
 static struct regcache_rbtree_node *regcache_rbtree_lookup(

commit 25ed1156ddf99f6d8feb87d0992b2ecb1fef667a
Author: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
Date:   Tue Sep 27 11:25:07 2011 +0100

    regmap: Remove redundant member `word_size' from regcache_rbtree_node
    
    Signed-off-by: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
index 4d7ba4511755..dd1b937a0d84 100644
--- a/drivers/base/regmap/regcache-rbtree.c
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -23,8 +23,6 @@ struct regcache_rbtree_node {
 	struct rb_node node;
 	/* base register handled by this block */
 	unsigned int base_reg;
-	/* number of bytes needed to represent the register index */
-	unsigned int word_size;
 	/* block of adjacent registers */
 	void *block;
 	/* number of registers available in the block */
@@ -45,11 +43,12 @@ static inline void regcache_rbtree_get_base_top_reg(
 }
 
 static unsigned int regcache_rbtree_get_register(
-	struct regcache_rbtree_node *rbnode, unsigned int idx)
+	struct regcache_rbtree_node *rbnode, unsigned int idx,
+	unsigned int word_size)
 {
 	unsigned int val;
 
-	switch (rbnode->word_size) {
+	switch (word_size) {
 	case 1: {
 		u8 *p = rbnode->block;
 		val = p[idx];
@@ -68,9 +67,10 @@ static unsigned int regcache_rbtree_get_register(
 }
 
 static void regcache_rbtree_set_register(struct regcache_rbtree_node *rbnode,
-					 unsigned int idx, unsigned int val)
+					 unsigned int idx, unsigned int val,
+					 unsigned int word_size)
 {
-	switch (rbnode->word_size) {
+	switch (word_size) {
 	case 1: {
 		u8 *p = rbnode->block;
 		p[idx] = val;
@@ -217,7 +217,8 @@ static int regcache_rbtree_read(struct regmap *map,
 		regcache_rbtree_get_base_top_reg(rbnode, &base_reg, &top_reg);
 		if (reg >= base_reg && reg <= top_reg) {
 			reg_tmp = reg - base_reg;
-			*value = regcache_rbtree_get_register(rbnode, reg_tmp);
+			*value = regcache_rbtree_get_register(rbnode, reg_tmp,
+							      map->cache_word_size);
 			return 0;
 		}
 	}
@@ -227,7 +228,8 @@ static int regcache_rbtree_read(struct regmap *map,
 	rbnode = regcache_rbtree_lookup(&rbtree_ctx->root, reg);
 	if (rbnode) {
 		reg_tmp = reg - rbnode->base_reg;
-		*value = regcache_rbtree_get_register(rbnode, reg_tmp);
+		*value = regcache_rbtree_get_register(rbnode, reg_tmp,
+						      map->cache_word_size);
 		rbtree_ctx->cached_rbnode = rbnode;
 	} else {
 		/* uninitialized registers default to 0 */
@@ -240,19 +242,19 @@ static int regcache_rbtree_read(struct regmap *map,
 
 static int regcache_rbtree_insert_to_block(struct regcache_rbtree_node *rbnode,
 					   unsigned int pos, unsigned int reg,
-					   unsigned int value)
+					   unsigned int value, unsigned int word_size)
 {
 	u8 *blk;
 
 	blk = krealloc(rbnode->block,
-		       (rbnode->blklen + 1) * rbnode->word_size, GFP_KERNEL);
+		       (rbnode->blklen + 1) * word_size, GFP_KERNEL);
 	if (!blk)
 		return -ENOMEM;
 
 	/* insert the register value in the correct place in the rbnode block */
-	memmove(blk + (pos + 1) * rbnode->word_size,
-		blk + pos * rbnode->word_size,
-		(rbnode->blklen - pos) * rbnode->word_size);
+	memmove(blk + (pos + 1) * word_size,
+		blk + pos * word_size,
+		(rbnode->blklen - pos) * word_size);
 
 	/* update the rbnode block, its size and the base register */
 	rbnode->block = blk;
@@ -260,7 +262,7 @@ static int regcache_rbtree_insert_to_block(struct regcache_rbtree_node *rbnode,
 	if (!pos)
 		rbnode->base_reg = reg;
 
-	regcache_rbtree_set_register(rbnode, pos, value);
+	regcache_rbtree_set_register(rbnode, pos, value, word_size);
 	return 0;
 }
 
@@ -284,10 +286,12 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 		regcache_rbtree_get_base_top_reg(rbnode, &base_reg, &top_reg);
 		if (reg >= base_reg && reg <= top_reg) {
 			reg_tmp = reg - base_reg;
-			val = regcache_rbtree_get_register(rbnode, reg_tmp);
+			val = regcache_rbtree_get_register(rbnode, reg_tmp,
+							   map->cache_word_size);
 			if (val == value)
 				return 0;
-			regcache_rbtree_set_register(rbnode, reg_tmp, value);
+			regcache_rbtree_set_register(rbnode, reg_tmp, value,
+						     map->cache_word_size);
 			return 0;
 		}
 	}
@@ -297,10 +301,12 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 	rbnode = regcache_rbtree_lookup(&rbtree_ctx->root, reg);
 	if (rbnode) {
 		reg_tmp = reg - rbnode->base_reg;
-		val = regcache_rbtree_get_register(rbnode, reg_tmp);
+		val = regcache_rbtree_get_register(rbnode, reg_tmp,
+						   map->cache_word_size);
 		if (val == value)
 			return 0;
-		regcache_rbtree_set_register(rbnode, reg_tmp, value);
+		regcache_rbtree_set_register(rbnode, reg_tmp, value,
+					     map->cache_word_size);
 		rbtree_ctx->cached_rbnode = rbnode;
 	} else {
 		/* bail out early, no need to create the rbnode yet */
@@ -320,7 +326,8 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 				else
 					pos = i;
 				ret = regcache_rbtree_insert_to_block(rbnode_tmp, pos,
-								      reg, value);
+								      reg, value,
+								      map->cache_word_size);
 				if (ret)
 					return ret;
 				rbtree_ctx->cached_rbnode = rbnode_tmp;
@@ -337,14 +344,13 @@ static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
 			return -ENOMEM;
 		rbnode->blklen = 1;
 		rbnode->base_reg = reg;
-		rbnode->word_size = map->cache_word_size;
-		rbnode->block = kmalloc(rbnode->blklen * rbnode->word_size,
+		rbnode->block = kmalloc(rbnode->blklen * map->cache_word_size,
 					GFP_KERNEL);
 		if (!rbnode->block) {
 			kfree(rbnode);
 			return -ENOMEM;
 		}
-		regcache_rbtree_set_register(rbnode, 0, value);
+		regcache_rbtree_set_register(rbnode, 0, value, map->cache_word_size);
 		regcache_rbtree_insert(&rbtree_ctx->root, rbnode);
 		rbtree_ctx->cached_rbnode = rbnode;
 	}
@@ -367,7 +373,8 @@ static int regcache_rbtree_sync(struct regmap *map)
 		rbnode = rb_entry(node, struct regcache_rbtree_node, node);
 		for (i = 0; i < rbnode->blklen; i++) {
 			regtmp = rbnode->base_reg + i;
-			val = regcache_rbtree_get_register(rbnode, i);
+			val = regcache_rbtree_get_register(rbnode, i,
+							   map->cache_word_size);
 			ret = regcache_lookup_reg(map, i);
 			if (ret < 0)
 				def = 0;

commit 28644c809f44498b8cd91d00b4cdb09e63b99843
Author: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
Date:   Mon Sep 19 14:34:02 2011 +0100

    regmap: Add the rbtree cache support
    
    This patch adds support for the rbtree cache compression type.
    
    Each rbnode manages a variable length block of registers.  There can be no
    two nodes with overlapping blocks.  Each block has a base register and a
    currently top register, all the other registers, if any, lie in between these
    two and in ascending order.
    
    The reasoning behind the construction of this rbtree is simple.  In the
    snd_soc_rbtree_cache_init() function, we iterate over the register defaults
    provided by the regcache core.  For each register value that is non-zero we
    insert it in the rbtree.  In order to determine in which rbnode we need
    to add the register, we first look if there is another register already
    added that is adjacent to the one we are about to add.  If that is the case
    we append it in that rbnode block, otherwise we create a new rbnode
    with a single register in its block and add it to the tree.
    
    There are various optimizations across the implementation to speed up lookups
    by caching the most recently used rbnode.
    
    Signed-off-by: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
    Tested-by: Lars-Peter Clausen <lars@metafoo.de>
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>

diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c
new file mode 100644
index 000000000000..4d7ba4511755
--- /dev/null
+++ b/drivers/base/regmap/regcache-rbtree.c
@@ -0,0 +1,399 @@
+/*
+ * Register cache access API - rbtree caching support
+ *
+ * Copyright 2011 Wolfson Microelectronics plc
+ *
+ * Author: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include <linux/slab.h>
+#include <linux/rbtree.h>
+
+#include "internal.h"
+
+static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
+				 unsigned int value);
+
+struct regcache_rbtree_node {
+	/* the actual rbtree node holding this block */
+	struct rb_node node;
+	/* base register handled by this block */
+	unsigned int base_reg;
+	/* number of bytes needed to represent the register index */
+	unsigned int word_size;
+	/* block of adjacent registers */
+	void *block;
+	/* number of registers available in the block */
+	unsigned int blklen;
+} __attribute__ ((packed));
+
+struct regcache_rbtree_ctx {
+	struct rb_root root;
+	struct regcache_rbtree_node *cached_rbnode;
+};
+
+static inline void regcache_rbtree_get_base_top_reg(
+	struct regcache_rbtree_node *rbnode,
+	unsigned int *base, unsigned int *top)
+{
+	*base = rbnode->base_reg;
+	*top = rbnode->base_reg + rbnode->blklen - 1;
+}
+
+static unsigned int regcache_rbtree_get_register(
+	struct regcache_rbtree_node *rbnode, unsigned int idx)
+{
+	unsigned int val;
+
+	switch (rbnode->word_size) {
+	case 1: {
+		u8 *p = rbnode->block;
+		val = p[idx];
+		return val;
+	}
+	case 2: {
+		u16 *p = rbnode->block;
+		val = p[idx];
+		return val;
+	}
+	default:
+		BUG();
+		break;
+	}
+	return -1;
+}
+
+static void regcache_rbtree_set_register(struct regcache_rbtree_node *rbnode,
+					 unsigned int idx, unsigned int val)
+{
+	switch (rbnode->word_size) {
+	case 1: {
+		u8 *p = rbnode->block;
+		p[idx] = val;
+		break;
+	}
+	case 2: {
+		u16 *p = rbnode->block;
+		p[idx] = val;
+		break;
+	}
+	default:
+		BUG();
+		break;
+	}
+}
+
+static struct regcache_rbtree_node *regcache_rbtree_lookup(
+	struct rb_root *root, unsigned int reg)
+{
+	struct rb_node *node;
+	struct regcache_rbtree_node *rbnode;
+	unsigned int base_reg, top_reg;
+
+	node = root->rb_node;
+	while (node) {
+		rbnode = container_of(node, struct regcache_rbtree_node, node);
+		regcache_rbtree_get_base_top_reg(rbnode, &base_reg, &top_reg);
+		if (reg >= base_reg && reg <= top_reg)
+			return rbnode;
+		else if (reg > top_reg)
+			node = node->rb_right;
+		else if (reg < base_reg)
+			node = node->rb_left;
+	}
+
+	return NULL;
+}
+
+static int regcache_rbtree_insert(struct rb_root *root,
+				  struct regcache_rbtree_node *rbnode)
+{
+	struct rb_node **new, *parent;
+	struct regcache_rbtree_node *rbnode_tmp;
+	unsigned int base_reg_tmp, top_reg_tmp;
+	unsigned int base_reg;
+
+	parent = NULL;
+	new = &root->rb_node;
+	while (*new) {
+		rbnode_tmp = container_of(*new, struct regcache_rbtree_node,
+					  node);
+		/* base and top registers of the current rbnode */
+		regcache_rbtree_get_base_top_reg(rbnode_tmp, &base_reg_tmp,
+						 &top_reg_tmp);
+		/* base register of the rbnode to be added */
+		base_reg = rbnode->base_reg;
+		parent = *new;
+		/* if this register has already been inserted, just return */
+		if (base_reg >= base_reg_tmp &&
+		    base_reg <= top_reg_tmp)
+			return 0;
+		else if (base_reg > top_reg_tmp)
+			new = &((*new)->rb_right);
+		else if (base_reg < base_reg_tmp)
+			new = &((*new)->rb_left);
+	}
+
+	/* insert the node into the rbtree */
+	rb_link_node(&rbnode->node, parent, new);
+	rb_insert_color(&rbnode->node, root);
+
+	return 1;
+}
+
+static int regcache_rbtree_init(struct regmap *map)
+{
+	struct regcache_rbtree_ctx *rbtree_ctx;
+	int i;
+	int ret;
+
+	map->cache = kmalloc(sizeof *rbtree_ctx, GFP_KERNEL);
+	if (!map->cache)
+		return -ENOMEM;
+
+	rbtree_ctx = map->cache;
+	rbtree_ctx->root = RB_ROOT;
+	rbtree_ctx->cached_rbnode = NULL;
+
+	for (i = 0; i < map->num_reg_defaults; i++) {
+		ret = regcache_rbtree_write(map,
+					    map->reg_defaults[i].reg,
+					    map->reg_defaults[i].def);
+		if (ret)
+			goto err;
+	}
+
+	return 0;
+
+err:
+	regcache_exit(map);
+	return ret;
+}
+
+static int regcache_rbtree_exit(struct regmap *map)
+{
+	struct rb_node *next;
+	struct regcache_rbtree_ctx *rbtree_ctx;
+	struct regcache_rbtree_node *rbtree_node;
+
+	/* if we've already been called then just return */
+	rbtree_ctx = map->cache;
+	if (!rbtree_ctx)
+		return 0;
+
+	/* free up the rbtree */
+	next = rb_first(&rbtree_ctx->root);
+	while (next) {
+		rbtree_node = rb_entry(next, struct regcache_rbtree_node, node);
+		next = rb_next(&rbtree_node->node);
+		rb_erase(&rbtree_node->node, &rbtree_ctx->root);
+		kfree(rbtree_node->block);
+		kfree(rbtree_node);
+	}
+
+	/* release the resources */
+	kfree(map->cache);
+	map->cache = NULL;
+
+	return 0;
+}
+
+static int regcache_rbtree_read(struct regmap *map,
+				unsigned int reg, unsigned int *value)
+{
+	struct regcache_rbtree_ctx *rbtree_ctx;
+	struct regcache_rbtree_node *rbnode;
+	unsigned int base_reg, top_reg;
+	unsigned int reg_tmp;
+
+	rbtree_ctx = map->cache;
+	/* look up the required register in the cached rbnode */
+	rbnode = rbtree_ctx->cached_rbnode;
+	if (rbnode) {
+		regcache_rbtree_get_base_top_reg(rbnode, &base_reg, &top_reg);
+		if (reg >= base_reg && reg <= top_reg) {
+			reg_tmp = reg - base_reg;
+			*value = regcache_rbtree_get_register(rbnode, reg_tmp);
+			return 0;
+		}
+	}
+	/* if we can't locate it in the cached rbnode we'll have
+	 * to traverse the rbtree looking for it.
+	 */
+	rbnode = regcache_rbtree_lookup(&rbtree_ctx->root, reg);
+	if (rbnode) {
+		reg_tmp = reg - rbnode->base_reg;
+		*value = regcache_rbtree_get_register(rbnode, reg_tmp);
+		rbtree_ctx->cached_rbnode = rbnode;
+	} else {
+		/* uninitialized registers default to 0 */
+		*value = 0;
+	}
+
+	return 0;
+}
+
+
+static int regcache_rbtree_insert_to_block(struct regcache_rbtree_node *rbnode,
+					   unsigned int pos, unsigned int reg,
+					   unsigned int value)
+{
+	u8 *blk;
+
+	blk = krealloc(rbnode->block,
+		       (rbnode->blklen + 1) * rbnode->word_size, GFP_KERNEL);
+	if (!blk)
+		return -ENOMEM;
+
+	/* insert the register value in the correct place in the rbnode block */
+	memmove(blk + (pos + 1) * rbnode->word_size,
+		blk + pos * rbnode->word_size,
+		(rbnode->blklen - pos) * rbnode->word_size);
+
+	/* update the rbnode block, its size and the base register */
+	rbnode->block = blk;
+	rbnode->blklen++;
+	if (!pos)
+		rbnode->base_reg = reg;
+
+	regcache_rbtree_set_register(rbnode, pos, value);
+	return 0;
+}
+
+static int regcache_rbtree_write(struct regmap *map, unsigned int reg,
+				 unsigned int value)
+{
+	struct regcache_rbtree_ctx *rbtree_ctx;
+	struct regcache_rbtree_node *rbnode, *rbnode_tmp;
+	struct rb_node *node;
+	unsigned int val;
+	unsigned int reg_tmp;
+	unsigned int base_reg, top_reg;
+	unsigned int pos;
+	int i;
+	int ret;
+
+	rbtree_ctx = map->cache;
+	/* look up the required register in the cached rbnode */
+	rbnode = rbtree_ctx->cached_rbnode;
+	if (rbnode) {
+		regcache_rbtree_get_base_top_reg(rbnode, &base_reg, &top_reg);
+		if (reg >= base_reg && reg <= top_reg) {
+			reg_tmp = reg - base_reg;
+			val = regcache_rbtree_get_register(rbnode, reg_tmp);
+			if (val == value)
+				return 0;
+			regcache_rbtree_set_register(rbnode, reg_tmp, value);
+			return 0;
+		}
+	}
+	/* if we can't locate it in the cached rbnode we'll have
+	 * to traverse the rbtree looking for it.
+	 */
+	rbnode = regcache_rbtree_lookup(&rbtree_ctx->root, reg);
+	if (rbnode) {
+		reg_tmp = reg - rbnode->base_reg;
+		val = regcache_rbtree_get_register(rbnode, reg_tmp);
+		if (val == value)
+			return 0;
+		regcache_rbtree_set_register(rbnode, reg_tmp, value);
+		rbtree_ctx->cached_rbnode = rbnode;
+	} else {
+		/* bail out early, no need to create the rbnode yet */
+		if (!value)
+			return 0;
+		/* look for an adjacent register to the one we are about to add */
+		for (node = rb_first(&rbtree_ctx->root); node;
+		     node = rb_next(node)) {
+			rbnode_tmp = rb_entry(node, struct regcache_rbtree_node, node);
+			for (i = 0; i < rbnode_tmp->blklen; i++) {
+				reg_tmp = rbnode_tmp->base_reg + i;
+				if (abs(reg_tmp - reg) != 1)
+					continue;
+				/* decide where in the block to place our register */
+				if (reg_tmp + 1 == reg)
+					pos = i + 1;
+				else
+					pos = i;
+				ret = regcache_rbtree_insert_to_block(rbnode_tmp, pos,
+								      reg, value);
+				if (ret)
+					return ret;
+				rbtree_ctx->cached_rbnode = rbnode_tmp;
+				return 0;
+			}
+		}
+		/* we did not manage to find a place to insert it in an existing
+		 * block so create a new rbnode with a single register in its block.
+		 * This block will get populated further if any other adjacent
+		 * registers get modified in the future.
+		 */
+		rbnode = kzalloc(sizeof *rbnode, GFP_KERNEL);
+		if (!rbnode)
+			return -ENOMEM;
+		rbnode->blklen = 1;
+		rbnode->base_reg = reg;
+		rbnode->word_size = map->cache_word_size;
+		rbnode->block = kmalloc(rbnode->blklen * rbnode->word_size,
+					GFP_KERNEL);
+		if (!rbnode->block) {
+			kfree(rbnode);
+			return -ENOMEM;
+		}
+		regcache_rbtree_set_register(rbnode, 0, value);
+		regcache_rbtree_insert(&rbtree_ctx->root, rbnode);
+		rbtree_ctx->cached_rbnode = rbnode;
+	}
+
+	return 0;
+}
+
+static int regcache_rbtree_sync(struct regmap *map)
+{
+	struct regcache_rbtree_ctx *rbtree_ctx;
+	struct rb_node *node;
+	struct regcache_rbtree_node *rbnode;
+	unsigned int regtmp;
+	unsigned int val, def;
+	int ret;
+	int i;
+
+	rbtree_ctx = map->cache;
+	for (node = rb_first(&rbtree_ctx->root); node; node = rb_next(node)) {
+		rbnode = rb_entry(node, struct regcache_rbtree_node, node);
+		for (i = 0; i < rbnode->blklen; i++) {
+			regtmp = rbnode->base_reg + i;
+			val = regcache_rbtree_get_register(rbnode, i);
+			ret = regcache_lookup_reg(map, i);
+			if (ret < 0)
+				def = 0;
+			else
+				def = map->reg_defaults[ret].def;
+			if (val == def)
+				continue;
+			map->cache_bypass = 1;
+			ret = regmap_write(map, regtmp, val);
+			map->cache_bypass = 0;
+			if (ret)
+				return ret;
+			dev_dbg(map->dev, "Synced register %#x, value %#x\n",
+				regtmp, val);
+		}
+	}
+
+	return 0;
+}
+
+struct regcache_ops regcache_rbtree_ops = {
+	.type = REGCACHE_RBTREE,
+	.name = "rbtree",
+	.init = regcache_rbtree_init,
+	.exit = regcache_rbtree_exit,
+	.read = regcache_rbtree_read,
+	.write = regcache_rbtree_write,
+	.sync = regcache_rbtree_sync
+};
